{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix_quick as confusion_matrix_quick\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number = \"1-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bert2_400',\n",
       " 1: 'Bert2_832',\n",
       " 2: 'Bert2_832_400_200_100',\n",
       " 3: 'Bert2_832_600_400_200',\n",
       " 4: 'Bert_300',\n",
       " 5: 'Bert_300_300_200',\n",
       " 6: 'Bert_768',\n",
       " 7: 'Fasttext2',\n",
       " 8: 'Fasttext2_150',\n",
       " 9: 'Fasttext2_200_200',\n",
       " 10: 'Fasttext2_200_200_100',\n",
       " 11: 'Fasttext2_200_200_200',\n",
       " 12: 'Fasttext2_200_200_200_100',\n",
       " 13: 'Fasttext2_200_200_200_100_relu',\n",
       " 14: 'Fasttext2_300_250_200_150',\n",
       " 15: 'Fasttext2_364',\n",
       " 16: 'Fasttext2_364_200_100',\n",
       " 17: 'Fasttext2_364_200_100_relu',\n",
       " 18: 'Fasttext2_364_300_200_100',\n",
       " 19: 'Fasttext2_364_300_200_100_relu',\n",
       " 20: 'Fasttext2_364_300_250_200',\n",
       " 21: 'Fasttext2_364_364_364',\n",
       " 22: 'Fasttext2_364_nn',\n",
       " 23: 'Fasttext2_3GCN_300_250_200_150',\n",
       " 24: 'Fasttext2_728',\n",
       " 25: 'Fasttext2_728364',\n",
       " 26: 'Fasttext2_728_364',\n",
       " 27: 'Fasttext2d_300_250_200_150',\n",
       " 28: 'Fasttext2d_364',\n",
       " 29: 'Fasttext2d_364_364_364',\n",
       " 30: 'Fasttext2d_728_364',\n",
       " 31: 'Fasttext3GCN_300',\n",
       " 32: 'FasttextSum_150',\n",
       " 33: 'FasttextSum_300_250_200_150',\n",
       " 34: 'FasttextSum_364',\n",
       " 35: 'FasttextSum_364_200_100',\n",
       " 36: 'FasttextSum_364_300_200_100',\n",
       " 37: 'FasttextSumd_150',\n",
       " 38: 'FasttextSumd_300_250_200_150',\n",
       " 39: 'Fasttext_150',\n",
       " 40: 'Fasttext_150_150_100',\n",
       " 41: 'Fasttext_200_200_200_100',\n",
       " 42: 'Fasttext_300',\n",
       " 43: 'Fasttext_300_200_100',\n",
       " 44: 'Fasttext_300_250_200_150',\n",
       " 45: 'Fasttext_300_300_300',\n",
       " 46: 'Fasttext_3GCN',\n",
       " 47: 'Fasttext_600_300',\n",
       " 48: 'Fasttext_simple_300_300'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24175, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.164, tt:10.164\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.23914, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:10.448, tt:20.897\n",
      "Ep:2, loss:0.00059, loss_test:0.23365, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:10.697, tt:32.091\n",
      "Ep:3, loss:0.00056, loss_test:0.22270, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:11.334, tt:45.335\n",
      "Ep:4, loss:0.00049, loss_test:0.20208, lr:9.22e-03, fs:0.66667 (r=0.970,p=0.508),  time:12.223, tt:61.114\n",
      "Ep:5, loss:0.00041, loss_test:0.18897, lr:9.04e-03, fs:0.69804 (r=0.899,p=0.571),  time:13.575, tt:81.449\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.19404, lr:8.86e-03, fs:0.71489 (r=0.848,p=0.618),  time:15.764, tt:110.347\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.19694, lr:8.68e-03, fs:0.70796 (r=0.808,p=0.630),  time:17.699, tt:141.595\n",
      "Ep:8, loss:0.00031, loss_test:0.18608, lr:8.51e-03, fs:0.70690 (r=0.828,p=0.617),  time:19.502, tt:175.515\n",
      "Ep:9, loss:0.00029, loss_test:0.18426, lr:8.34e-03, fs:0.71493 (r=0.798,p=0.648),  time:20.903, tt:209.031\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00029, loss_test:0.17600, lr:8.17e-03, fs:0.73832 (r=0.798,p=0.687),  time:22.124, tt:243.361\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.17086, lr:8.01e-03, fs:0.75113 (r=0.838,p=0.680),  time:23.158, tt:277.899\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.17229, lr:7.85e-03, fs:0.74208 (r=0.828,p=0.672),  time:23.991, tt:311.877\n",
      "Ep:13, loss:0.00027, loss_test:0.17322, lr:7.69e-03, fs:0.73973 (r=0.818,p=0.675),  time:24.724, tt:346.141\n",
      "Ep:14, loss:0.00026, loss_test:0.16954, lr:7.54e-03, fs:0.76991 (r=0.879,p=0.685),  time:25.353, tt:380.293\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.16696, lr:7.39e-03, fs:0.77064 (r=0.848,p=0.706),  time:25.781, tt:412.495\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.17036, lr:7.24e-03, fs:0.76712 (r=0.848,p=0.700),  time:26.234, tt:445.972\n",
      "Ep:17, loss:0.00024, loss_test:0.15952, lr:7.09e-03, fs:0.76923 (r=0.909,p=0.667),  time:26.720, tt:480.953\n",
      "Ep:18, loss:0.00024, loss_test:0.15596, lr:6.95e-03, fs:0.78341 (r=0.859,p=0.720),  time:27.160, tt:516.040\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.16625, lr:6.81e-03, fs:0.78873 (r=0.848,p=0.737),  time:27.507, tt:550.150\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.15784, lr:6.68e-03, fs:0.77056 (r=0.899,p=0.674),  time:27.764, tt:583.044\n",
      "Ep:21, loss:0.00022, loss_test:0.15201, lr:6.54e-03, fs:0.82028 (r=0.899,p=0.754),  time:28.171, tt:619.767\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.15279, lr:6.41e-03, fs:0.81081 (r=0.909,p=0.732),  time:28.448, tt:654.309\n",
      "Ep:23, loss:0.00021, loss_test:0.15519, lr:6.28e-03, fs:0.81223 (r=0.939,p=0.715),  time:28.657, tt:687.769\n",
      "Ep:24, loss:0.00021, loss_test:0.15375, lr:6.16e-03, fs:0.83412 (r=0.889,p=0.786),  time:28.948, tt:723.688\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.14690, lr:6.03e-03, fs:0.82883 (r=0.929,p=0.748),  time:29.207, tt:759.373\n",
      "Ep:26, loss:0.00020, loss_test:0.14852, lr:5.91e-03, fs:0.81545 (r=0.960,p=0.709),  time:29.417, tt:794.248\n",
      "Ep:27, loss:0.00019, loss_test:0.14592, lr:5.80e-03, fs:0.85185 (r=0.929,p=0.786),  time:29.578, tt:828.191\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.14403, lr:5.68e-03, fs:0.84018 (r=0.929,p=0.767),  time:29.753, tt:862.825\n",
      "Ep:29, loss:0.00019, loss_test:0.15111, lr:5.57e-03, fs:0.81579 (r=0.939,p=0.721),  time:29.918, tt:897.536\n",
      "Ep:30, loss:0.00018, loss_test:0.14136, lr:5.45e-03, fs:0.83700 (r=0.960,p=0.742),  time:30.072, tt:932.240\n",
      "Ep:31, loss:0.00018, loss_test:0.14265, lr:5.35e-03, fs:0.84932 (r=0.939,p=0.775),  time:30.212, tt:966.779\n",
      "Ep:32, loss:0.00018, loss_test:0.14381, lr:5.24e-03, fs:0.84018 (r=0.929,p=0.767),  time:30.317, tt:1000.458\n",
      "Ep:33, loss:0.00017, loss_test:0.13857, lr:5.13e-03, fs:0.84163 (r=0.939,p=0.762),  time:30.453, tt:1035.394\n",
      "Ep:34, loss:0.00017, loss_test:0.14159, lr:5.03e-03, fs:0.85202 (r=0.960,p=0.766),  time:30.523, tt:1068.289\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00016, loss_test:0.14430, lr:4.93e-03, fs:0.85981 (r=0.929,p=0.800),  time:30.640, tt:1103.046\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00016, loss_test:0.13852, lr:4.83e-03, fs:0.83843 (r=0.970,p=0.738),  time:30.718, tt:1136.579\n",
      "Ep:37, loss:0.00016, loss_test:0.14167, lr:4.74e-03, fs:0.86099 (r=0.970,p=0.774),  time:30.781, tt:1169.683\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00016, loss_test:0.14077, lr:4.64e-03, fs:0.85714 (r=0.939,p=0.788),  time:30.826, tt:1202.232\n",
      "Ep:39, loss:0.00015, loss_test:0.13570, lr:4.55e-03, fs:0.85463 (r=0.980,p=0.758),  time:30.934, tt:1237.364\n",
      "Ep:40, loss:0.00015, loss_test:0.13404, lr:4.46e-03, fs:0.88889 (r=0.970,p=0.821),  time:30.981, tt:1270.231\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00014, loss_test:0.13286, lr:4.37e-03, fs:0.87671 (r=0.970,p=0.800),  time:31.022, tt:1302.924\n",
      "Ep:42, loss:0.00015, loss_test:0.13203, lr:4.28e-03, fs:0.85463 (r=0.980,p=0.758),  time:31.082, tt:1336.516\n",
      "Ep:43, loss:0.00014, loss_test:0.13266, lr:4.19e-03, fs:0.89302 (r=0.970,p=0.828),  time:31.144, tt:1370.336\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00014, loss_test:0.12802, lr:4.11e-03, fs:0.88073 (r=0.970,p=0.807),  time:31.189, tt:1403.521\n",
      "Ep:45, loss:0.00013, loss_test:0.12734, lr:4.03e-03, fs:0.87273 (r=0.970,p=0.793),  time:31.267, tt:1438.288\n",
      "Ep:46, loss:0.00013, loss_test:0.13368, lr:3.95e-03, fs:0.89302 (r=0.970,p=0.828),  time:31.311, tt:1471.615\n",
      "Ep:47, loss:0.00013, loss_test:0.12673, lr:3.87e-03, fs:0.86996 (r=0.980,p=0.782),  time:31.366, tt:1505.586\n",
      "Ep:48, loss:0.00013, loss_test:0.12154, lr:3.79e-03, fs:0.89401 (r=0.980,p=0.822),  time:31.445, tt:1540.817\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00013, loss_test:0.12594, lr:3.72e-03, fs:0.90654 (r=0.980,p=0.843),  time:31.476, tt:1573.782\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00013, loss_test:0.12500, lr:3.64e-03, fs:0.88584 (r=0.980,p=0.808),  time:31.504, tt:1606.719\n",
      "Ep:51, loss:0.00012, loss_test:0.12395, lr:3.57e-03, fs:0.87671 (r=0.970,p=0.800),  time:31.549, tt:1640.547\n",
      "Ep:52, loss:0.00012, loss_test:0.12886, lr:3.50e-03, fs:0.89302 (r=0.970,p=0.828),  time:31.572, tt:1673.312\n",
      "Ep:53, loss:0.00012, loss_test:0.12038, lr:3.43e-03, fs:0.88584 (r=0.980,p=0.808),  time:31.574, tt:1705.002\n",
      "Ep:54, loss:0.00011, loss_test:0.11653, lr:3.36e-03, fs:0.86222 (r=0.980,p=0.770),  time:31.615, tt:1738.821\n",
      "Ep:55, loss:0.00011, loss_test:0.12489, lr:3.29e-03, fs:0.88889 (r=0.970,p=0.821),  time:31.669, tt:1773.440\n",
      "Ep:56, loss:0.00011, loss_test:0.12473, lr:3.23e-03, fs:0.90141 (r=0.970,p=0.842),  time:31.738, tt:1809.051\n",
      "Ep:57, loss:0.00011, loss_test:0.11910, lr:3.16e-03, fs:0.85965 (r=0.990,p=0.760),  time:31.768, tt:1842.519\n",
      "Ep:58, loss:0.00011, loss_test:0.11797, lr:3.10e-03, fs:0.87387 (r=0.980,p=0.789),  time:31.817, tt:1877.182\n",
      "Ep:59, loss:0.00011, loss_test:0.11984, lr:3.04e-03, fs:0.90995 (r=0.970,p=0.857),  time:31.851, tt:1911.043\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00010, loss_test:0.11462, lr:2.98e-03, fs:0.88991 (r=0.980,p=0.815),  time:31.908, tt:1946.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00011, loss_test:0.11859, lr:2.92e-03, fs:0.90566 (r=0.970,p=0.850),  time:31.953, tt:1981.103\n",
      "Ep:62, loss:0.00010, loss_test:0.12164, lr:2.86e-03, fs:0.91429 (r=0.970,p=0.865),  time:32.016, tt:2017.014\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00010, loss_test:0.11671, lr:2.80e-03, fs:0.86996 (r=0.980,p=0.782),  time:32.055, tt:2051.495\n",
      "Ep:64, loss:0.00010, loss_test:0.11491, lr:2.74e-03, fs:0.88182 (r=0.980,p=0.802),  time:32.082, tt:2085.318\n",
      "Ep:65, loss:0.00010, loss_test:0.12246, lr:2.69e-03, fs:0.91346 (r=0.960,p=0.872),  time:32.111, tt:2119.301\n",
      "Ep:66, loss:0.00010, loss_test:0.11594, lr:2.64e-03, fs:0.91080 (r=0.980,p=0.851),  time:32.112, tt:2151.504\n",
      "Ep:67, loss:0.00010, loss_test:0.11315, lr:2.58e-03, fs:0.90323 (r=0.990,p=0.831),  time:32.141, tt:2185.584\n",
      "Ep:68, loss:0.00010, loss_test:0.12012, lr:2.53e-03, fs:0.91429 (r=0.970,p=0.865),  time:32.114, tt:2215.836\n",
      "Ep:69, loss:0.00009, loss_test:0.11943, lr:2.48e-03, fs:0.91866 (r=0.970,p=0.873),  time:32.162, tt:2251.360\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00009, loss_test:0.11256, lr:2.43e-03, fs:0.91080 (r=0.980,p=0.851),  time:32.169, tt:2283.966\n",
      "Ep:71, loss:0.00009, loss_test:0.11508, lr:2.38e-03, fs:0.92019 (r=0.990,p=0.860),  time:32.182, tt:2317.094\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00009, loss_test:0.11583, lr:2.33e-03, fs:0.91080 (r=0.980,p=0.851),  time:32.197, tt:2350.410\n",
      "Ep:73, loss:0.00009, loss_test:0.11216, lr:2.29e-03, fs:0.90654 (r=0.980,p=0.843),  time:32.233, tt:2385.215\n",
      "Ep:74, loss:0.00009, loss_test:0.11739, lr:2.24e-03, fs:0.91943 (r=0.980,p=0.866),  time:32.243, tt:2418.231\n",
      "Ep:75, loss:0.00009, loss_test:0.11746, lr:2.20e-03, fs:0.92823 (r=0.980,p=0.882),  time:32.267, tt:2452.327\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00009, loss_test:0.11204, lr:2.15e-03, fs:0.91509 (r=0.980,p=0.858),  time:32.295, tt:2486.693\n",
      "Ep:77, loss:0.00009, loss_test:0.11482, lr:2.11e-03, fs:0.90566 (r=0.970,p=0.850),  time:32.295, tt:2518.984\n",
      "Ep:78, loss:0.00008, loss_test:0.11913, lr:2.07e-03, fs:0.91176 (r=0.939,p=0.886),  time:32.325, tt:2553.675\n",
      "Ep:79, loss:0.00008, loss_test:0.11439, lr:2.03e-03, fs:0.91509 (r=0.980,p=0.858),  time:32.333, tt:2586.602\n",
      "Ep:80, loss:0.00008, loss_test:0.11200, lr:1.99e-03, fs:0.91589 (r=0.990,p=0.852),  time:32.322, tt:2618.074\n",
      "Ep:81, loss:0.00008, loss_test:0.11412, lr:1.95e-03, fs:0.91429 (r=0.970,p=0.865),  time:32.349, tt:2652.591\n",
      "Ep:82, loss:0.00008, loss_test:0.11271, lr:1.91e-03, fs:0.92823 (r=0.980,p=0.882),  time:32.380, tt:2687.551\n",
      "Ep:83, loss:0.00008, loss_test:0.11077, lr:1.87e-03, fs:0.92823 (r=0.980,p=0.882),  time:32.385, tt:2720.372\n",
      "Ep:84, loss:0.00008, loss_test:0.11353, lr:1.83e-03, fs:0.92823 (r=0.980,p=0.882),  time:32.414, tt:2755.203\n",
      "Ep:85, loss:0.00008, loss_test:0.11539, lr:1.80e-03, fs:0.91346 (r=0.960,p=0.872),  time:32.425, tt:2788.575\n",
      "Ep:86, loss:0.00008, loss_test:0.11261, lr:1.76e-03, fs:0.91943 (r=0.980,p=0.866),  time:32.429, tt:2821.346\n",
      "Ep:87, loss:0.00008, loss_test:0.11119, lr:1.72e-03, fs:0.91866 (r=0.970,p=0.873),  time:32.438, tt:2854.524\n",
      "Ep:88, loss:0.00008, loss_test:0.11182, lr:1.69e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.457, tt:2888.700\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00008, loss_test:0.11139, lr:1.66e-03, fs:0.91866 (r=0.970,p=0.873),  time:32.473, tt:2922.588\n",
      "Ep:90, loss:0.00007, loss_test:0.11296, lr:1.62e-03, fs:0.92381 (r=0.980,p=0.874),  time:32.480, tt:2955.666\n",
      "Ep:91, loss:0.00007, loss_test:0.11320, lr:1.59e-03, fs:0.93269 (r=0.980,p=0.890),  time:32.495, tt:2989.517\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00008, loss_test:0.11289, lr:1.56e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.510, tt:3023.453\n",
      "Ep:93, loss:0.00007, loss_test:0.11040, lr:1.53e-03, fs:0.93269 (r=0.980,p=0.890),  time:32.516, tt:3056.500\n",
      "Ep:94, loss:0.00007, loss_test:0.11111, lr:1.50e-03, fs:0.92823 (r=0.980,p=0.882),  time:32.521, tt:3089.499\n",
      "Ep:95, loss:0.00007, loss_test:0.11063, lr:1.47e-03, fs:0.93780 (r=0.990,p=0.891),  time:32.529, tt:3122.806\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00007, loss_test:0.11054, lr:1.44e-03, fs:0.93333 (r=0.990,p=0.883),  time:32.511, tt:3153.559\n",
      "Ep:97, loss:0.00007, loss_test:0.10918, lr:1.41e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.526, tt:3187.503\n",
      "Ep:98, loss:0.00007, loss_test:0.10896, lr:1.38e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.526, tt:3220.074\n",
      "Ep:99, loss:0.00007, loss_test:0.11022, lr:1.35e-03, fs:0.92308 (r=0.970,p=0.881),  time:32.538, tt:3253.804\n",
      "Ep:100, loss:0.00007, loss_test:0.11072, lr:1.33e-03, fs:0.92754 (r=0.970,p=0.889),  time:32.531, tt:3285.644\n",
      "Ep:101, loss:0.00007, loss_test:0.11141, lr:1.30e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.550, tt:3320.111\n",
      "Ep:102, loss:0.00006, loss_test:0.10867, lr:1.27e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.549, tt:3352.581\n",
      "Ep:103, loss:0.00007, loss_test:0.10703, lr:1.25e-03, fs:0.92453 (r=0.990,p=0.867),  time:32.534, tt:3383.546\n",
      "Ep:104, loss:0.00006, loss_test:0.10754, lr:1.22e-03, fs:0.92019 (r=0.990,p=0.860),  time:32.537, tt:3416.407\n",
      "Ep:105, loss:0.00006, loss_test:0.10832, lr:1.20e-03, fs:0.92754 (r=0.970,p=0.889),  time:32.531, tt:3448.274\n",
      "Ep:106, loss:0.00006, loss_test:0.10805, lr:1.17e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.526, tt:3480.293\n",
      "Ep:107, loss:0.00006, loss_test:0.10811, lr:1.15e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.535, tt:3513.752\n",
      "Ep:108, loss:0.00006, loss_test:0.10981, lr:1.13e-03, fs:0.92308 (r=0.970,p=0.881),  time:32.531, tt:3545.887\n",
      "Ep:109, loss:0.00006, loss_test:0.10924, lr:1.11e-03, fs:0.92754 (r=0.970,p=0.889),  time:32.524, tt:3577.643\n",
      "Ep:110, loss:0.00006, loss_test:0.10746, lr:1.08e-03, fs:0.92754 (r=0.970,p=0.889),  time:32.521, tt:3609.810\n",
      "Ep:111, loss:0.00006, loss_test:0.10683, lr:1.06e-03, fs:0.92754 (r=0.970,p=0.889),  time:32.511, tt:3641.197\n",
      "Ep:112, loss:0.00006, loss_test:0.10839, lr:1.04e-03, fs:0.93204 (r=0.970,p=0.897),  time:32.511, tt:3673.776\n",
      "Ep:113, loss:0.00006, loss_test:0.10927, lr:1.02e-03, fs:0.93333 (r=0.990,p=0.883),  time:32.495, tt:3704.389\n",
      "Ep:114, loss:0.00006, loss_test:0.10756, lr:9.99e-04, fs:0.92453 (r=0.990,p=0.867),  time:32.497, tt:3737.180\n",
      "Ep:115, loss:0.00006, loss_test:0.10716, lr:9.79e-04, fs:0.93204 (r=0.970,p=0.897),  time:32.501, tt:3770.092\n",
      "Ep:116, loss:0.00006, loss_test:0.10667, lr:9.60e-04, fs:0.93204 (r=0.970,p=0.897),  time:32.501, tt:3802.587\n",
      "Ep:117, loss:0.00006, loss_test:0.10825, lr:9.41e-04, fs:0.93204 (r=0.970,p=0.897),  time:32.492, tt:3834.075\n",
      "Ep:118, loss:0.00007, loss_test:0.10847, lr:9.22e-04, fs:0.93204 (r=0.970,p=0.897),  time:32.480, tt:3865.122\n",
      "Ep:119, loss:0.00006, loss_test:0.10767, lr:9.03e-04, fs:0.93269 (r=0.980,p=0.890),  time:32.473, tt:3896.814\n",
      "Ep:120, loss:0.00006, loss_test:0.10656, lr:8.85e-04, fs:0.93720 (r=0.980,p=0.898),  time:32.464, tt:3928.126\n",
      "Ep:121, loss:0.00006, loss_test:0.10446, lr:8.68e-04, fs:0.93659 (r=0.970,p=0.906),  time:32.456, tt:3959.586\n",
      "Ep:122, loss:0.00006, loss_test:0.10462, lr:8.50e-04, fs:0.93659 (r=0.970,p=0.906),  time:32.441, tt:3990.206\n",
      "Ep:123, loss:0.00006, loss_test:0.10620, lr:8.33e-04, fs:0.93659 (r=0.970,p=0.906),  time:32.464, tt:4025.485\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24186, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.275, tt:31.275\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.23904, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:29.961, tt:59.922\n",
      "Ep:2, loss:0.00059, loss_test:0.23300, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:30.195, tt:90.584\n",
      "Ep:3, loss:0.00056, loss_test:0.22139, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:29.093, tt:116.371\n",
      "Ep:4, loss:0.00050, loss_test:0.20087, lr:9.22e-03, fs:0.66207 (r=0.970,p=0.503),  time:29.439, tt:147.195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00040, loss_test:0.19138, lr:9.04e-03, fs:0.67442 (r=0.879,p=0.547),  time:29.133, tt:174.799\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.19369, lr:8.86e-03, fs:0.67797 (r=0.808,p=0.584),  time:28.923, tt:202.461\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.19051, lr:8.68e-03, fs:0.68966 (r=0.808,p=0.602),  time:29.031, tt:232.246\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00031, loss_test:0.19028, lr:8.51e-03, fs:0.71053 (r=0.818,p=0.628),  time:29.059, tt:261.528\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.18733, lr:8.34e-03, fs:0.70536 (r=0.798,p=0.632),  time:29.312, tt:293.118\n",
      "Ep:10, loss:0.00030, loss_test:0.18451, lr:8.17e-03, fs:0.72646 (r=0.818,p=0.653),  time:29.553, tt:325.081\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.17623, lr:8.01e-03, fs:0.72889 (r=0.828,p=0.651),  time:29.760, tt:357.115\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.17431, lr:7.85e-03, fs:0.74775 (r=0.838,p=0.675),  time:30.052, tt:390.681\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00027, loss_test:0.17431, lr:7.69e-03, fs:0.74107 (r=0.838,p=0.664),  time:30.153, tt:422.147\n",
      "Ep:14, loss:0.00026, loss_test:0.17668, lr:7.54e-03, fs:0.75113 (r=0.838,p=0.680),  time:30.297, tt:454.458\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.16590, lr:7.39e-03, fs:0.74667 (r=0.848,p=0.667),  time:30.402, tt:486.432\n",
      "Ep:16, loss:0.00024, loss_test:0.16382, lr:7.24e-03, fs:0.75676 (r=0.848,p=0.683),  time:30.628, tt:520.683\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.16552, lr:7.09e-03, fs:0.74775 (r=0.838,p=0.675),  time:30.731, tt:553.160\n",
      "Ep:18, loss:0.00024, loss_test:0.16224, lr:6.95e-03, fs:0.76786 (r=0.869,p=0.688),  time:30.878, tt:586.686\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.15914, lr:6.81e-03, fs:0.76712 (r=0.848,p=0.700),  time:30.968, tt:619.362\n",
      "Ep:20, loss:0.00023, loss_test:0.15730, lr:6.68e-03, fs:0.75799 (r=0.838,p=0.692),  time:31.017, tt:651.366\n",
      "Ep:21, loss:0.00023, loss_test:0.15826, lr:6.54e-03, fs:0.76233 (r=0.859,p=0.685),  time:31.110, tt:684.426\n",
      "Ep:22, loss:0.00022, loss_test:0.15465, lr:6.41e-03, fs:0.77273 (r=0.859,p=0.702),  time:31.148, tt:716.402\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.15161, lr:6.28e-03, fs:0.75439 (r=0.869,p=0.667),  time:31.174, tt:748.176\n",
      "Ep:24, loss:0.00021, loss_test:0.15077, lr:6.16e-03, fs:0.76856 (r=0.889,p=0.677),  time:31.229, tt:780.719\n",
      "Ep:25, loss:0.00021, loss_test:0.14982, lr:6.03e-03, fs:0.77273 (r=0.859,p=0.702),  time:31.337, tt:814.775\n",
      "Ep:26, loss:0.00020, loss_test:0.14545, lr:5.91e-03, fs:0.78222 (r=0.889,p=0.698),  time:31.444, tt:848.978\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.14359, lr:5.80e-03, fs:0.78970 (r=0.929,p=0.687),  time:31.522, tt:882.623\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.14651, lr:5.68e-03, fs:0.80889 (r=0.919,p=0.722),  time:31.575, tt:915.684\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00019, loss_test:0.14475, lr:5.57e-03, fs:0.80374 (r=0.869,p=0.748),  time:31.631, tt:948.941\n",
      "Ep:30, loss:0.00018, loss_test:0.13957, lr:5.45e-03, fs:0.80365 (r=0.889,p=0.733),  time:31.700, tt:982.691\n",
      "Ep:31, loss:0.00018, loss_test:0.14109, lr:5.35e-03, fs:0.80000 (r=0.929,p=0.702),  time:31.733, tt:1015.470\n",
      "Ep:32, loss:0.00017, loss_test:0.13803, lr:5.24e-03, fs:0.80543 (r=0.899,p=0.730),  time:31.799, tt:1049.377\n",
      "Ep:33, loss:0.00017, loss_test:0.13601, lr:5.13e-03, fs:0.82511 (r=0.929,p=0.742),  time:31.868, tt:1083.502\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00016, loss_test:0.13690, lr:5.03e-03, fs:0.82883 (r=0.929,p=0.748),  time:31.936, tt:1117.759\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00017, loss_test:0.13342, lr:4.93e-03, fs:0.82511 (r=0.929,p=0.742),  time:31.969, tt:1150.901\n",
      "Ep:36, loss:0.00016, loss_test:0.13289, lr:4.83e-03, fs:0.82609 (r=0.960,p=0.725),  time:32.026, tt:1184.957\n",
      "Ep:37, loss:0.00016, loss_test:0.13729, lr:4.74e-03, fs:0.81081 (r=0.909,p=0.732),  time:32.066, tt:1218.512\n",
      "Ep:38, loss:0.00015, loss_test:0.13399, lr:4.64e-03, fs:0.82301 (r=0.939,p=0.732),  time:32.132, tt:1253.163\n",
      "Ep:39, loss:0.00015, loss_test:0.12942, lr:4.55e-03, fs:0.81938 (r=0.939,p=0.727),  time:32.201, tt:1288.050\n",
      "Ep:40, loss:0.00015, loss_test:0.13309, lr:4.46e-03, fs:0.81481 (r=0.889,p=0.752),  time:32.233, tt:1321.561\n",
      "Ep:41, loss:0.00015, loss_test:0.13139, lr:4.37e-03, fs:0.82906 (r=0.980,p=0.719),  time:32.286, tt:1356.032\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00014, loss_test:0.12494, lr:4.28e-03, fs:0.81385 (r=0.949,p=0.712),  time:32.348, tt:1390.945\n",
      "Ep:43, loss:0.00015, loss_test:0.12915, lr:4.19e-03, fs:0.82727 (r=0.919,p=0.752),  time:32.394, tt:1425.320\n",
      "Ep:44, loss:0.00014, loss_test:0.12915, lr:4.11e-03, fs:0.82511 (r=0.929,p=0.742),  time:32.446, tt:1460.060\n",
      "Ep:45, loss:0.00013, loss_test:0.12517, lr:4.03e-03, fs:0.83408 (r=0.939,p=0.750),  time:32.486, tt:1494.363\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00013, loss_test:0.12644, lr:3.95e-03, fs:0.84018 (r=0.929,p=0.767),  time:32.536, tt:1529.209\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00013, loss_test:0.12461, lr:3.87e-03, fs:0.84483 (r=0.990,p=0.737),  time:32.571, tt:1563.389\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00013, loss_test:0.12056, lr:3.79e-03, fs:0.85068 (r=0.949,p=0.770),  time:32.636, tt:1599.142\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00013, loss_test:0.12005, lr:3.72e-03, fs:0.85463 (r=0.980,p=0.758),  time:32.710, tt:1635.507\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00012, loss_test:0.12105, lr:3.64e-03, fs:0.84444 (r=0.960,p=0.754),  time:32.747, tt:1670.115\n",
      "Ep:51, loss:0.00012, loss_test:0.12032, lr:3.57e-03, fs:0.82949 (r=0.909,p=0.763),  time:32.797, tt:1705.432\n",
      "Ep:52, loss:0.00012, loss_test:0.12022, lr:3.50e-03, fs:0.82629 (r=0.889,p=0.772),  time:32.816, tt:1739.233\n",
      "Ep:53, loss:0.00012, loss_test:0.11765, lr:3.43e-03, fs:0.85841 (r=0.980,p=0.764),  time:32.833, tt:1772.963\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00012, loss_test:0.11662, lr:3.36e-03, fs:0.85202 (r=0.960,p=0.766),  time:32.872, tt:1807.968\n",
      "Ep:55, loss:0.00012, loss_test:0.11503, lr:3.29e-03, fs:0.86364 (r=0.960,p=0.785),  time:32.864, tt:1840.358\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00011, loss_test:0.11456, lr:3.23e-03, fs:0.85714 (r=1.000,p=0.750),  time:32.894, tt:1874.953\n",
      "Ep:57, loss:0.00011, loss_test:0.11710, lr:3.16e-03, fs:0.86486 (r=0.970,p=0.780),  time:32.931, tt:1910.016\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00012, loss_test:0.11672, lr:3.10e-03, fs:0.85581 (r=0.929,p=0.793),  time:32.933, tt:1943.067\n",
      "Ep:59, loss:0.00011, loss_test:0.11385, lr:3.04e-03, fs:0.86726 (r=0.990,p=0.772),  time:32.962, tt:1977.730\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00011, loss_test:0.11372, lr:2.98e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.000, tt:2013.013\n",
      "Ep:61, loss:0.00010, loss_test:0.11503, lr:2.92e-03, fs:0.85714 (r=0.939,p=0.788),  time:32.990, tt:2045.377\n",
      "Ep:62, loss:0.00011, loss_test:0.11430, lr:2.86e-03, fs:0.84793 (r=0.929,p=0.780),  time:33.015, tt:2079.944\n",
      "Ep:63, loss:0.00010, loss_test:0.11247, lr:2.80e-03, fs:0.86364 (r=0.960,p=0.785),  time:33.049, tt:2115.160\n",
      "Ep:64, loss:0.00010, loss_test:0.11174, lr:2.74e-03, fs:0.87442 (r=0.949,p=0.810),  time:33.078, tt:2150.040\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00010, loss_test:0.11235, lr:2.69e-03, fs:0.86512 (r=0.939,p=0.802),  time:33.090, tt:2183.917\n",
      "Ep:66, loss:0.00010, loss_test:0.11451, lr:2.64e-03, fs:0.84018 (r=0.929,p=0.767),  time:33.108, tt:2218.225\n",
      "Ep:67, loss:0.00010, loss_test:0.11378, lr:2.58e-03, fs:0.87156 (r=0.960,p=0.798),  time:33.103, tt:2250.982\n",
      "Ep:68, loss:0.00010, loss_test:0.11155, lr:2.53e-03, fs:0.88372 (r=0.960,p=0.819),  time:33.121, tt:2285.321\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00010, loss_test:0.11137, lr:2.48e-03, fs:0.88785 (r=0.960,p=0.826),  time:33.162, tt:2321.329\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00009, loss_test:0.11016, lr:2.43e-03, fs:0.86239 (r=0.949,p=0.790),  time:33.153, tt:2353.871\n",
      "Ep:71, loss:0.00010, loss_test:0.10967, lr:2.38e-03, fs:0.88584 (r=0.980,p=0.808),  time:33.146, tt:2386.484\n",
      "Ep:72, loss:0.00009, loss_test:0.10988, lr:2.33e-03, fs:0.88372 (r=0.960,p=0.819),  time:33.164, tt:2420.996\n",
      "Ep:73, loss:0.00009, loss_test:0.10863, lr:2.29e-03, fs:0.87442 (r=0.949,p=0.810),  time:33.159, tt:2453.784\n",
      "Ep:74, loss:0.00009, loss_test:0.11122, lr:2.24e-03, fs:0.87442 (r=0.949,p=0.810),  time:33.185, tt:2488.863\n",
      "Ep:75, loss:0.00009, loss_test:0.10962, lr:2.20e-03, fs:0.87850 (r=0.949,p=0.817),  time:33.189, tt:2522.374\n",
      "Ep:76, loss:0.00009, loss_test:0.10689, lr:2.15e-03, fs:0.86512 (r=0.939,p=0.802),  time:33.182, tt:2555.037\n",
      "Ep:77, loss:0.00009, loss_test:0.10970, lr:2.11e-03, fs:0.87850 (r=0.949,p=0.817),  time:33.207, tt:2590.130\n",
      "Ep:78, loss:0.00009, loss_test:0.11208, lr:2.07e-03, fs:0.87558 (r=0.960,p=0.805),  time:33.218, tt:2624.252\n",
      "Ep:79, loss:0.00009, loss_test:0.10886, lr:2.03e-03, fs:0.87963 (r=0.960,p=0.812),  time:33.249, tt:2659.947\n",
      "Ep:80, loss:0.00009, loss_test:0.10676, lr:1.99e-03, fs:0.86512 (r=0.939,p=0.802),  time:33.258, tt:2693.908\n",
      "Ep:81, loss:0.00009, loss_test:0.10972, lr:1.95e-03, fs:0.87442 (r=0.949,p=0.810),  time:33.266, tt:2727.779\n",
      "Ep:82, loss:0.00008, loss_test:0.11099, lr:1.91e-03, fs:0.87963 (r=0.960,p=0.812),  time:33.278, tt:2762.038\n",
      "Ep:83, loss:0.00009, loss_test:0.10642, lr:1.87e-03, fs:0.87037 (r=0.949,p=0.803),  time:33.284, tt:2795.825\n",
      "Ep:84, loss:0.00008, loss_test:0.10585, lr:1.83e-03, fs:0.87037 (r=0.949,p=0.803),  time:33.285, tt:2829.251\n",
      "Ep:85, loss:0.00008, loss_test:0.10906, lr:1.80e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.301, tt:2863.907\n",
      "Ep:86, loss:0.00008, loss_test:0.11144, lr:1.76e-03, fs:0.87037 (r=0.949,p=0.803),  time:33.312, tt:2898.130\n",
      "Ep:87, loss:0.00008, loss_test:0.10776, lr:1.72e-03, fs:0.87037 (r=0.949,p=0.803),  time:33.323, tt:2932.426\n",
      "Ep:88, loss:0.00008, loss_test:0.10471, lr:1.69e-03, fs:0.88073 (r=0.970,p=0.807),  time:33.325, tt:2965.917\n",
      "Ep:89, loss:0.00008, loss_test:0.10528, lr:1.66e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.339, tt:3000.469\n",
      "Ep:90, loss:0.00008, loss_test:0.10649, lr:1.62e-03, fs:0.87850 (r=0.949,p=0.817),  time:33.353, tt:3035.132\n",
      "Ep:91, loss:0.00008, loss_test:0.10706, lr:1.59e-03, fs:0.87037 (r=0.949,p=0.803),  time:33.373, tt:3070.307\n",
      "Ep:92, loss:0.00008, loss_test:0.10631, lr:1.56e-03, fs:0.87037 (r=0.949,p=0.803),  time:33.389, tt:3105.216\n",
      "Ep:93, loss:0.00007, loss_test:0.10479, lr:1.53e-03, fs:0.87558 (r=0.960,p=0.805),  time:33.404, tt:3139.954\n",
      "Ep:94, loss:0.00008, loss_test:0.10563, lr:1.50e-03, fs:0.88372 (r=0.960,p=0.819),  time:33.418, tt:3174.726\n",
      "Ep:95, loss:0.00008, loss_test:0.10624, lr:1.47e-03, fs:0.88372 (r=0.960,p=0.819),  time:33.413, tt:3207.609\n",
      "Ep:96, loss:0.00007, loss_test:0.10609, lr:1.44e-03, fs:0.87442 (r=0.949,p=0.810),  time:33.424, tt:3242.101\n",
      "Ep:97, loss:0.00007, loss_test:0.10569, lr:1.41e-03, fs:0.87850 (r=0.949,p=0.817),  time:33.407, tt:3273.909\n",
      "Ep:98, loss:0.00008, loss_test:0.10537, lr:1.38e-03, fs:0.89100 (r=0.949,p=0.839),  time:33.403, tt:3306.889\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00007, loss_test:0.10394, lr:1.35e-03, fs:0.88679 (r=0.949,p=0.832),  time:33.401, tt:3340.072\n",
      "Ep:100, loss:0.00007, loss_test:0.10410, lr:1.33e-03, fs:0.87850 (r=0.949,p=0.817),  time:33.414, tt:3374.803\n",
      "Ep:101, loss:0.00007, loss_test:0.10511, lr:1.30e-03, fs:0.88372 (r=0.960,p=0.819),  time:33.409, tt:3407.690\n",
      "Ep:102, loss:0.00007, loss_test:0.10479, lr:1.27e-03, fs:0.88785 (r=0.960,p=0.826),  time:33.397, tt:3439.917\n",
      "Ep:103, loss:0.00007, loss_test:0.10391, lr:1.25e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.395, tt:3473.042\n",
      "Ep:104, loss:0.00007, loss_test:0.10435, lr:1.22e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.400, tt:3506.976\n",
      "Ep:105, loss:0.00007, loss_test:0.10538, lr:1.20e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.388, tt:3539.127\n",
      "Ep:106, loss:0.00007, loss_test:0.10553, lr:1.17e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.390, tt:3572.766\n",
      "Ep:107, loss:0.00007, loss_test:0.10484, lr:1.15e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.404, tt:3607.618\n",
      "Ep:108, loss:0.00007, loss_test:0.10409, lr:1.13e-03, fs:0.88152 (r=0.939,p=0.830),  time:33.404, tt:3641.029\n",
      "Ep:109, loss:0.00007, loss_test:0.10398, lr:1.11e-03, fs:0.88152 (r=0.939,p=0.830),  time:33.392, tt:3673.121\n",
      "Ep:110, loss:0.00007, loss_test:0.10439, lr:1.08e-03, fs:0.87736 (r=0.939,p=0.823),  time:33.384, tt:3705.656\n",
      "Ep:111, loss:0.00007, loss_test:0.10430, lr:1.06e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.370, tt:3737.439\n",
      "Ep:112, loss:0.00007, loss_test:0.10315, lr:1.04e-03, fs:0.88263 (r=0.949,p=0.825),  time:33.390, tt:3773.042\n",
      "Ep:113, loss:0.00007, loss_test:0.10256, lr:1.02e-03, fs:0.88785 (r=0.960,p=0.826),  time:33.398, tt:3807.350\n",
      "Ep:114, loss:0.00007, loss_test:0.10303, lr:9.99e-04, fs:0.88679 (r=0.949,p=0.832),  time:33.402, tt:3841.201\n",
      "Ep:115, loss:0.00007, loss_test:0.10379, lr:9.79e-04, fs:0.88571 (r=0.939,p=0.838),  time:33.411, tt:3875.715\n",
      "Ep:116, loss:0.00007, loss_test:0.10432, lr:9.60e-04, fs:0.90291 (r=0.939,p=0.869),  time:33.427, tt:3910.942\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00007, loss_test:0.10334, lr:9.41e-04, fs:0.88995 (r=0.939,p=0.845),  time:33.436, tt:3945.498\n",
      "Ep:118, loss:0.00007, loss_test:0.10187, lr:9.22e-04, fs:0.88372 (r=0.960,p=0.819),  time:33.440, tt:3979.331\n",
      "Ep:119, loss:0.00007, loss_test:0.10217, lr:9.03e-04, fs:0.88372 (r=0.960,p=0.819),  time:33.446, tt:4013.514\n",
      "Ep:120, loss:0.00006, loss_test:0.10309, lr:8.85e-04, fs:0.88785 (r=0.960,p=0.826),  time:33.446, tt:4046.930\n",
      "Ep:121, loss:0.00007, loss_test:0.10343, lr:8.68e-04, fs:0.89202 (r=0.960,p=0.833),  time:33.445, tt:4080.262\n",
      "Ep:122, loss:0.00006, loss_test:0.10319, lr:8.50e-04, fs:0.89623 (r=0.960,p=0.841),  time:33.445, tt:4113.705\n",
      "Ep:123, loss:0.00006, loss_test:0.10260, lr:8.33e-04, fs:0.88785 (r=0.960,p=0.826),  time:33.454, tt:4148.320\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24361, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.168, tt:33.168\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24110, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.129, tt:64.259\n",
      "Ep:2, loss:0.00059, loss_test:0.23573, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.778, tt:98.334\n",
      "Ep:3, loss:0.00055, loss_test:0.22437, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.336, tt:125.345\n",
      "Ep:4, loss:0.00048, loss_test:0.20733, lr:9.22e-03, fs:0.67128 (r=0.980,p=0.511),  time:31.573, tt:157.865\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.19849, lr:9.04e-03, fs:0.68217 (r=0.889,p=0.553),  time:31.589, tt:189.532\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.20095, lr:8.86e-03, fs:0.67241 (r=0.788,p=0.586),  time:31.083, tt:217.578\n",
      "Ep:7, loss:0.00031, loss_test:0.20345, lr:8.68e-03, fs:0.65236 (r=0.768,p=0.567),  time:31.133, tt:249.061\n",
      "Ep:8, loss:0.00030, loss_test:0.20528, lr:8.51e-03, fs:0.64840 (r=0.717,p=0.592),  time:31.308, tt:281.777\n",
      "Ep:9, loss:0.00029, loss_test:0.20363, lr:8.34e-03, fs:0.64789 (r=0.697,p=0.605),  time:31.301, tt:313.005\n",
      "Ep:10, loss:0.00028, loss_test:0.19646, lr:8.17e-03, fs:0.65403 (r=0.697,p=0.616),  time:31.496, tt:346.458\n",
      "Ep:11, loss:0.00027, loss_test:0.19253, lr:8.01e-03, fs:0.65385 (r=0.687,p=0.624),  time:31.734, tt:380.813\n",
      "Ep:12, loss:0.00027, loss_test:0.18987, lr:7.85e-03, fs:0.66981 (r=0.717,p=0.628),  time:31.759, tt:412.869\n",
      "Ep:13, loss:0.00026, loss_test:0.18881, lr:7.69e-03, fs:0.67299 (r=0.717,p=0.634),  time:31.935, tt:447.096\n",
      "Ep:14, loss:0.00026, loss_test:0.19384, lr:7.54e-03, fs:0.67327 (r=0.687,p=0.660),  time:32.008, tt:480.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00025, loss_test:0.18794, lr:7.39e-03, fs:0.66038 (r=0.707,p=0.619),  time:31.980, tt:511.688\n",
      "Ep:16, loss:0.00024, loss_test:0.18798, lr:7.24e-03, fs:0.66029 (r=0.697,p=0.627),  time:32.120, tt:546.040\n",
      "Ep:17, loss:0.00024, loss_test:0.18957, lr:7.09e-03, fs:0.66019 (r=0.687,p=0.636),  time:32.219, tt:579.946\n",
      "Ep:18, loss:0.00023, loss_test:0.18202, lr:6.95e-03, fs:0.68203 (r=0.747,p=0.627),  time:32.188, tt:611.575\n",
      "Ep:19, loss:0.00023, loss_test:0.18478, lr:6.81e-03, fs:0.67943 (r=0.717,p=0.645),  time:32.195, tt:643.907\n",
      "Ep:20, loss:0.00022, loss_test:0.18853, lr:6.68e-03, fs:0.66667 (r=0.687,p=0.648),  time:32.159, tt:675.334\n",
      "Ep:21, loss:0.00021, loss_test:0.17744, lr:6.54e-03, fs:0.69811 (r=0.747,p=0.655),  time:32.188, tt:708.147\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.18247, lr:6.41e-03, fs:0.67943 (r=0.717,p=0.645),  time:32.254, tt:741.835\n",
      "Ep:23, loss:0.00021, loss_test:0.18793, lr:6.28e-03, fs:0.66332 (r=0.667,p=0.660),  time:32.271, tt:774.510\n",
      "Ep:24, loss:0.00020, loss_test:0.17818, lr:6.16e-03, fs:0.67943 (r=0.717,p=0.645),  time:32.281, tt:807.017\n",
      "Ep:25, loss:0.00020, loss_test:0.18410, lr:6.03e-03, fs:0.67980 (r=0.697,p=0.663),  time:32.297, tt:839.721\n",
      "Ep:26, loss:0.00019, loss_test:0.18176, lr:5.91e-03, fs:0.68627 (r=0.707,p=0.667),  time:32.302, tt:872.164\n",
      "Ep:27, loss:0.00019, loss_test:0.17822, lr:5.80e-03, fs:0.69484 (r=0.747,p=0.649),  time:32.329, tt:905.203\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-072c7752a036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,124,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.23802, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.450, tt:37.450\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.23070, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.401, tt:74.803\n",
      "Ep:2, loss:0.00055, loss_test:0.21580, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.537, tt:112.611\n",
      "Ep:3, loss:0.00048, loss_test:0.19497, lr:9.70e-03, fs:0.66667 (r=0.949,p=0.514),  time:37.233, tt:148.934\n",
      "Ep:4, loss:0.00037, loss_test:0.19028, lr:9.61e-03, fs:0.69323 (r=0.879,p=0.572),  time:37.264, tt:186.322\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.19343, lr:9.51e-03, fs:0.71489 (r=0.848,p=0.618),  time:37.336, tt:224.014\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.18900, lr:9.41e-03, fs:0.74107 (r=0.838,p=0.664),  time:37.697, tt:263.876\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.18554, lr:9.32e-03, fs:0.73303 (r=0.818,p=0.664),  time:38.054, tt:304.432\n",
      "Ep:8, loss:0.00030, loss_test:0.17712, lr:9.23e-03, fs:0.74667 (r=0.848,p=0.667),  time:38.485, tt:346.368\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.17458, lr:9.14e-03, fs:0.75113 (r=0.838,p=0.680),  time:38.757, tt:387.574\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.16730, lr:9.04e-03, fs:0.76106 (r=0.869,p=0.677),  time:38.605, tt:424.656\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.16826, lr:8.95e-03, fs:0.76712 (r=0.848,p=0.700),  time:38.560, tt:462.724\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.15927, lr:8.86e-03, fs:0.77679 (r=0.879,p=0.696),  time:38.436, tt:499.674\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.16172, lr:8.78e-03, fs:0.77729 (r=0.899,p=0.685),  time:38.343, tt:536.800\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.15962, lr:8.69e-03, fs:0.78070 (r=0.899,p=0.690),  time:38.231, tt:573.460\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.15251, lr:8.60e-03, fs:0.76151 (r=0.919,p=0.650),  time:38.199, tt:611.178\n",
      "Ep:16, loss:0.00024, loss_test:0.16310, lr:8.51e-03, fs:0.77193 (r=0.889,p=0.682),  time:38.431, tt:653.321\n",
      "Ep:17, loss:0.00023, loss_test:0.15105, lr:8.43e-03, fs:0.79452 (r=0.879,p=0.725),  time:38.559, tt:694.057\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.14823, lr:8.35e-03, fs:0.80176 (r=0.919,p=0.711),  time:38.812, tt:737.435\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.14955, lr:8.26e-03, fs:0.81223 (r=0.939,p=0.715),  time:38.910, tt:778.202\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.14513, lr:8.18e-03, fs:0.82096 (r=0.949,p=0.723),  time:38.833, tt:815.503\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.14535, lr:8.10e-03, fs:0.80687 (r=0.949,p=0.701),  time:38.769, tt:852.915\n",
      "Ep:22, loss:0.00020, loss_test:0.14400, lr:8.02e-03, fs:0.83408 (r=0.939,p=0.750),  time:38.737, tt:890.942\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.15171, lr:7.94e-03, fs:0.80508 (r=0.960,p=0.693),  time:38.778, tt:930.673\n",
      "Ep:24, loss:0.00020, loss_test:0.14110, lr:7.86e-03, fs:0.83186 (r=0.949,p=0.740),  time:38.735, tt:968.374\n",
      "Ep:25, loss:0.00019, loss_test:0.14326, lr:7.78e-03, fs:0.81897 (r=0.960,p=0.714),  time:38.638, tt:1004.594\n",
      "Ep:26, loss:0.00019, loss_test:0.13803, lr:7.70e-03, fs:0.83929 (r=0.949,p=0.752),  time:38.620, tt:1042.732\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.13685, lr:7.62e-03, fs:0.82403 (r=0.970,p=0.716),  time:38.710, tt:1083.884\n",
      "Ep:28, loss:0.00018, loss_test:0.13397, lr:7.55e-03, fs:0.84305 (r=0.949,p=0.758),  time:38.854, tt:1126.775\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00018, loss_test:0.14595, lr:7.47e-03, fs:0.83556 (r=0.949,p=0.746),  time:38.811, tt:1164.345\n",
      "Ep:30, loss:0.00017, loss_test:0.13116, lr:7.40e-03, fs:0.80498 (r=0.980,p=0.683),  time:38.752, tt:1201.308\n",
      "Ep:31, loss:0.00016, loss_test:0.13061, lr:7.32e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.716, tt:1238.902\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.13369, lr:7.25e-03, fs:0.83404 (r=0.990,p=0.721),  time:38.644, tt:1275.236\n",
      "Ep:33, loss:0.00016, loss_test:0.12546, lr:7.18e-03, fs:0.83621 (r=0.980,p=0.729),  time:38.558, tt:1310.961\n",
      "Ep:34, loss:0.00016, loss_test:0.13240, lr:7.11e-03, fs:0.85217 (r=0.990,p=0.748),  time:38.506, tt:1347.700\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00015, loss_test:0.12595, lr:7.03e-03, fs:0.87111 (r=0.990,p=0.778),  time:38.436, tt:1383.680\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00015, loss_test:0.13216, lr:6.96e-03, fs:0.84615 (r=1.000,p=0.733),  time:38.483, tt:1423.856\n",
      "Ep:37, loss:0.00014, loss_test:0.12654, lr:6.89e-03, fs:0.87111 (r=0.990,p=0.778),  time:38.552, tt:1464.967\n",
      "Ep:38, loss:0.00014, loss_test:0.12709, lr:6.83e-03, fs:0.86726 (r=0.990,p=0.772),  time:38.607, tt:1505.683\n",
      "Ep:39, loss:0.00013, loss_test:0.12080, lr:6.76e-03, fs:0.87892 (r=0.990,p=0.790),  time:38.583, tt:1543.339\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.12111, lr:6.69e-03, fs:0.86087 (r=1.000,p=0.756),  time:38.531, tt:1579.764\n",
      "Ep:41, loss:0.00013, loss_test:0.12312, lr:6.62e-03, fs:0.89815 (r=0.980,p=0.829),  time:37.897, tt:1591.664\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00013, loss_test:0.11819, lr:6.56e-03, fs:0.87611 (r=1.000,p=0.780),  time:37.297, tt:1603.783\n",
      "Ep:43, loss:0.00012, loss_test:0.12278, lr:6.49e-03, fs:0.89189 (r=1.000,p=0.805),  time:36.722, tt:1615.748\n",
      "Ep:44, loss:0.00012, loss_test:0.11412, lr:6.43e-03, fs:0.88789 (r=1.000,p=0.798),  time:36.178, tt:1628.019\n",
      "Ep:45, loss:0.00012, loss_test:0.12141, lr:6.36e-03, fs:0.91667 (r=1.000,p=0.846),  time:35.662, tt:1640.448\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00011, loss_test:0.11765, lr:6.30e-03, fs:0.89189 (r=1.000,p=0.805),  time:35.191, tt:1653.978\n",
      "Ep:47, loss:0.00011, loss_test:0.11673, lr:6.24e-03, fs:0.91244 (r=1.000,p=0.839),  time:34.731, tt:1667.092\n",
      "Ep:48, loss:0.00010, loss_test:0.11835, lr:6.17e-03, fs:0.90411 (r=1.000,p=0.825),  time:34.279, tt:1679.689\n",
      "Ep:49, loss:0.00010, loss_test:0.11320, lr:6.11e-03, fs:0.89593 (r=1.000,p=0.811),  time:33.831, tt:1691.552\n",
      "Ep:50, loss:0.00010, loss_test:0.11355, lr:6.05e-03, fs:0.91244 (r=1.000,p=0.839),  time:33.403, tt:1703.528\n",
      "Ep:51, loss:0.00010, loss_test:0.11295, lr:5.99e-03, fs:0.88393 (r=1.000,p=0.792),  time:32.993, tt:1715.660\n",
      "Ep:52, loss:0.00010, loss_test:0.11059, lr:5.93e-03, fs:0.91589 (r=0.990,p=0.852),  time:32.609, tt:1728.256\n",
      "Ep:53, loss:0.00010, loss_test:0.11366, lr:5.87e-03, fs:0.88000 (r=1.000,p=0.786),  time:32.227, tt:1740.260\n",
      "Ep:54, loss:0.00009, loss_test:0.11221, lr:5.81e-03, fs:0.92958 (r=1.000,p=0.868),  time:31.874, tt:1753.050\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00009, loss_test:0.10870, lr:5.75e-03, fs:0.89189 (r=1.000,p=0.805),  time:31.537, tt:1766.049\n",
      "Ep:56, loss:0.00009, loss_test:0.10897, lr:5.70e-03, fs:0.92958 (r=1.000,p=0.868),  time:31.203, tt:1778.554\n",
      "Ep:57, loss:0.00009, loss_test:0.10633, lr:5.64e-03, fs:0.91667 (r=1.000,p=0.846),  time:30.917, tt:1793.187\n",
      "Ep:58, loss:0.00008, loss_test:0.10916, lr:5.58e-03, fs:0.88000 (r=1.000,p=0.786),  time:30.601, tt:1805.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00008, loss_test:0.10988, lr:5.53e-03, fs:0.94737 (r=1.000,p=0.900),  time:30.294, tt:1817.621\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00008, loss_test:0.10373, lr:5.47e-03, fs:0.90000 (r=1.000,p=0.818),  time:29.997, tt:1829.831\n",
      "Ep:61, loss:0.00008, loss_test:0.10720, lr:5.42e-03, fs:0.92523 (r=1.000,p=0.861),  time:29.712, tt:1842.169\n",
      "Ep:62, loss:0.00007, loss_test:0.10643, lr:5.36e-03, fs:0.92523 (r=1.000,p=0.861),  time:29.436, tt:1854.455\n",
      "Ep:63, loss:0.00007, loss_test:0.10872, lr:5.31e-03, fs:0.92958 (r=1.000,p=0.868),  time:29.175, tt:1867.184\n",
      "Ep:64, loss:0.00007, loss_test:0.09874, lr:5.26e-03, fs:0.92958 (r=1.000,p=0.868),  time:28.937, tt:1880.907\n",
      "Ep:65, loss:0.00006, loss_test:0.09965, lr:5.20e-03, fs:0.91244 (r=1.000,p=0.839),  time:28.705, tt:1894.527\n",
      "Ep:66, loss:0.00007, loss_test:0.09952, lr:5.15e-03, fs:0.93780 (r=0.990,p=0.891),  time:28.469, tt:1907.439\n",
      "Ep:67, loss:0.00006, loss_test:0.10062, lr:5.10e-03, fs:0.90411 (r=1.000,p=0.825),  time:28.232, tt:1919.774\n",
      "Ep:68, loss:0.00006, loss_test:0.09997, lr:5.05e-03, fs:0.94286 (r=1.000,p=0.892),  time:27.998, tt:1931.863\n",
      "Ep:69, loss:0.00006, loss_test:0.09828, lr:5.00e-03, fs:0.94231 (r=0.990,p=0.899),  time:27.776, tt:1944.286\n",
      "Ep:70, loss:0.00006, loss_test:0.10184, lr:4.95e-03, fs:0.92093 (r=1.000,p=0.853),  time:27.563, tt:1956.988\n",
      "Ep:71, loss:0.00005, loss_test:0.09435, lr:4.85e-03, fs:0.93839 (r=1.000,p=0.884),  time:27.355, tt:1969.532\n",
      "Ep:72, loss:0.00006, loss_test:0.09521, lr:4.75e-03, fs:0.94286 (r=1.000,p=0.892),  time:27.159, tt:1982.607\n",
      "Ep:73, loss:0.00005, loss_test:0.09885, lr:4.66e-03, fs:0.93780 (r=0.990,p=0.891),  time:26.975, tt:1996.149\n",
      "Ep:74, loss:0.00005, loss_test:0.09711, lr:4.57e-03, fs:0.93780 (r=0.990,p=0.891),  time:26.795, tt:2009.645\n",
      "Ep:75, loss:0.00005, loss_test:0.09513, lr:4.48e-03, fs:0.92958 (r=1.000,p=0.868),  time:26.607, tt:2022.163\n",
      "Ep:76, loss:0.00005, loss_test:0.09138, lr:4.39e-03, fs:0.93269 (r=0.980,p=0.890),  time:26.422, tt:2034.495\n",
      "Ep:77, loss:0.00005, loss_test:0.09813, lr:4.30e-03, fs:0.93396 (r=1.000,p=0.876),  time:26.242, tt:2046.872\n",
      "Ep:78, loss:0.00005, loss_test:0.09287, lr:4.21e-03, fs:0.93396 (r=1.000,p=0.876),  time:26.065, tt:2059.099\n",
      "Ep:79, loss:0.00005, loss_test:0.09338, lr:4.13e-03, fs:0.93204 (r=0.970,p=0.897),  time:25.894, tt:2071.535\n",
      "Ep:80, loss:0.00004, loss_test:0.09969, lr:4.05e-03, fs:0.92523 (r=1.000,p=0.861),  time:25.726, tt:2083.814\n",
      "Ep:81, loss:0.00005, loss_test:0.09116, lr:3.97e-03, fs:0.93269 (r=0.980,p=0.890),  time:25.577, tt:2097.310\n",
      "Ep:82, loss:0.00005, loss_test:0.09805, lr:3.89e-03, fs:0.97059 (r=1.000,p=0.943),  time:25.431, tt:2110.765\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00005, loss_test:0.09498, lr:3.85e-03, fs:0.94737 (r=1.000,p=0.900),  time:25.284, tt:2123.869\n",
      "Ep:84, loss:0.00004, loss_test:0.09281, lr:3.81e-03, fs:0.93204 (r=0.970,p=0.897),  time:25.131, tt:2136.165\n",
      "Ep:85, loss:0.00004, loss_test:0.10203, lr:3.77e-03, fs:0.95567 (r=0.980,p=0.933),  time:24.982, tt:2148.413\n",
      "Ep:86, loss:0.00004, loss_test:0.09598, lr:3.73e-03, fs:0.95192 (r=1.000,p=0.908),  time:24.834, tt:2160.549\n",
      "Ep:87, loss:0.00004, loss_test:0.09079, lr:3.70e-03, fs:0.92453 (r=0.990,p=0.867),  time:24.697, tt:2173.320\n",
      "Ep:88, loss:0.00004, loss_test:0.09380, lr:3.66e-03, fs:0.93269 (r=0.980,p=0.890),  time:24.557, tt:2185.540\n",
      "Ep:89, loss:0.00004, loss_test:0.09302, lr:3.62e-03, fs:0.95610 (r=0.990,p=0.925),  time:24.417, tt:2197.548\n",
      "Ep:90, loss:0.00004, loss_test:0.09278, lr:3.59e-03, fs:0.94686 (r=0.990,p=0.907),  time:24.290, tt:2210.355\n",
      "Ep:91, loss:0.00004, loss_test:0.09377, lr:3.55e-03, fs:0.93659 (r=0.970,p=0.906),  time:24.169, tt:2223.585\n",
      "Ep:92, loss:0.00004, loss_test:0.09577, lr:3.52e-03, fs:0.95050 (r=0.970,p=0.932),  time:24.055, tt:2237.137\n",
      "Ep:93, loss:0.00004, loss_test:0.08931, lr:3.48e-03, fs:0.94231 (r=0.990,p=0.899),  time:23.933, tt:2249.710\n",
      "Ep:94, loss:0.00003, loss_test:0.08990, lr:3.41e-03, fs:0.94737 (r=1.000,p=0.900),  time:23.811, tt:2262.083\n",
      "Ep:95, loss:0.00004, loss_test:0.09057, lr:3.34e-03, fs:0.95000 (r=0.960,p=0.941),  time:23.691, tt:2274.366\n",
      "Ep:96, loss:0.00004, loss_test:0.09141, lr:3.28e-03, fs:0.94059 (r=0.960,p=0.922),  time:23.574, tt:2286.709\n",
      "Ep:97, loss:0.00003, loss_test:0.09312, lr:3.21e-03, fs:0.94175 (r=0.980,p=0.907),  time:23.461, tt:2299.185\n",
      "Ep:98, loss:0.00004, loss_test:0.09164, lr:3.15e-03, fs:0.94059 (r=0.960,p=0.922),  time:23.348, tt:2311.413\n",
      "Ep:99, loss:0.00003, loss_test:0.09099, lr:3.09e-03, fs:0.95098 (r=0.980,p=0.924),  time:23.248, tt:2324.777\n",
      "Ep:100, loss:0.00004, loss_test:0.08966, lr:3.02e-03, fs:0.93659 (r=0.970,p=0.906),  time:23.162, tt:2339.408\n",
      "Ep:101, loss:0.00003, loss_test:0.08892, lr:2.96e-03, fs:0.93659 (r=0.970,p=0.906),  time:23.068, tt:2352.980\n",
      "Ep:102, loss:0.00003, loss_test:0.09142, lr:2.90e-03, fs:0.94634 (r=0.980,p=0.915),  time:22.970, tt:2365.909\n",
      "Ep:103, loss:0.00003, loss_test:0.09102, lr:2.85e-03, fs:0.95098 (r=0.980,p=0.924),  time:22.870, tt:2378.521\n",
      "Ep:104, loss:0.00003, loss_test:0.08998, lr:2.79e-03, fs:0.95050 (r=0.970,p=0.932),  time:22.771, tt:2390.980\n",
      "Ep:105, loss:0.00003, loss_test:0.08894, lr:2.73e-03, fs:0.95567 (r=0.980,p=0.933),  time:22.676, tt:2403.639\n",
      "Ep:106, loss:0.00003, loss_test:0.08702, lr:2.68e-03, fs:0.94059 (r=0.960,p=0.922),  time:22.581, tt:2416.174\n",
      "Ep:107, loss:0.00003, loss_test:0.08768, lr:2.63e-03, fs:0.95098 (r=0.980,p=0.924),  time:22.488, tt:2428.655\n",
      "Ep:108, loss:0.00003, loss_test:0.08977, lr:2.57e-03, fs:0.95146 (r=0.990,p=0.916),  time:22.410, tt:2442.657\n",
      "Ep:109, loss:0.00003, loss_test:0.08843, lr:2.52e-03, fs:0.94118 (r=0.970,p=0.914),  time:22.329, tt:2456.139\n",
      "Ep:110, loss:0.00003, loss_test:0.08975, lr:2.47e-03, fs:0.94118 (r=0.970,p=0.914),  time:22.254, tt:2470.174\n",
      "Ep:111, loss:0.00003, loss_test:0.08935, lr:2.42e-03, fs:0.95567 (r=0.980,p=0.933),  time:22.164, tt:2482.364\n",
      "Ep:112, loss:0.00003, loss_test:0.08721, lr:2.38e-03, fs:0.94059 (r=0.960,p=0.922),  time:22.078, tt:2494.784\n",
      "Ep:113, loss:0.00003, loss_test:0.08747, lr:2.33e-03, fs:0.94581 (r=0.970,p=0.923),  time:21.992, tt:2507.128\n",
      "Ep:114, loss:0.00003, loss_test:0.08855, lr:2.28e-03, fs:0.94581 (r=0.970,p=0.923),  time:21.911, tt:2519.733\n",
      "Ep:115, loss:0.00003, loss_test:0.09034, lr:2.24e-03, fs:0.96000 (r=0.970,p=0.950),  time:21.831, tt:2532.377\n",
      "Ep:116, loss:0.00003, loss_test:0.08967, lr:2.19e-03, fs:0.96000 (r=0.970,p=0.950),  time:21.749, tt:2544.658\n",
      "Ep:117, loss:0.00003, loss_test:0.08672, lr:2.15e-03, fs:0.94527 (r=0.960,p=0.931),  time:21.681, tt:2558.361\n",
      "Ep:118, loss:0.00003, loss_test:0.08718, lr:2.11e-03, fs:0.94634 (r=0.980,p=0.915),  time:21.612, tt:2571.834\n",
      "Ep:119, loss:0.00002, loss_test:0.08751, lr:2.06e-03, fs:0.95522 (r=0.970,p=0.941),  time:21.546, tt:2585.468\n",
      "Ep:120, loss:0.00003, loss_test:0.08852, lr:2.02e-03, fs:0.96447 (r=0.960,p=0.969),  time:21.471, tt:2597.938\n",
      "Ep:121, loss:0.00003, loss_test:0.08854, lr:1.98e-03, fs:0.95522 (r=0.970,p=0.941),  time:21.401, tt:2610.899\n",
      "Ep:122, loss:0.00003, loss_test:0.08800, lr:1.94e-03, fs:0.96000 (r=0.970,p=0.950),  time:21.326, tt:2623.106\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.23838, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.276, tt:12.276\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.23232, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:12.420, tt:24.840\n",
      "Ep:2, loss:0.00055, loss_test:0.21964, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:12.791, tt:38.372\n",
      "Ep:3, loss:0.00049, loss_test:0.20089, lr:9.70e-03, fs:0.66431 (r=0.949,p=0.511),  time:13.046, tt:52.184\n",
      "Ep:4, loss:0.00039, loss_test:0.19295, lr:9.61e-03, fs:0.68000 (r=0.859,p=0.563),  time:13.135, tt:65.676\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.19154, lr:9.51e-03, fs:0.69828 (r=0.818,p=0.609),  time:12.982, tt:77.891\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00032, loss_test:0.18764, lr:9.41e-03, fs:0.69231 (r=0.818,p=0.600),  time:12.893, tt:90.254\n",
      "Ep:7, loss:0.00031, loss_test:0.19087, lr:9.32e-03, fs:0.69333 (r=0.788,p=0.619),  time:12.833, tt:102.662\n",
      "Ep:8, loss:0.00030, loss_test:0.18397, lr:9.23e-03, fs:0.71245 (r=0.838,p=0.619),  time:12.804, tt:115.233\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00029, loss_test:0.17296, lr:9.14e-03, fs:0.73913 (r=0.859,p=0.649),  time:12.734, tt:127.338\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.17023, lr:9.04e-03, fs:0.73913 (r=0.859,p=0.649),  time:12.703, tt:139.735\n",
      "Ep:11, loss:0.00027, loss_test:0.16587, lr:8.95e-03, fs:0.74561 (r=0.859,p=0.659),  time:12.778, tt:153.340\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.16707, lr:8.86e-03, fs:0.76018 (r=0.848,p=0.689),  time:12.831, tt:166.808\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.16384, lr:8.78e-03, fs:0.76577 (r=0.859,p=0.691),  time:12.889, tt:180.444\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00026, loss_test:0.15595, lr:8.69e-03, fs:0.76364 (r=0.848,p=0.694),  time:12.860, tt:192.896\n",
      "Ep:15, loss:0.00024, loss_test:0.16006, lr:8.60e-03, fs:0.74576 (r=0.889,p=0.642),  time:12.830, tt:205.277\n",
      "Ep:16, loss:0.00023, loss_test:0.15424, lr:8.51e-03, fs:0.75983 (r=0.879,p=0.669),  time:12.804, tt:217.666\n",
      "Ep:17, loss:0.00024, loss_test:0.15931, lr:8.43e-03, fs:0.76923 (r=0.859,p=0.697),  time:12.776, tt:229.962\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.15801, lr:8.35e-03, fs:0.79812 (r=0.859,p=0.746),  time:12.764, tt:242.523\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.14987, lr:8.26e-03, fs:0.76652 (r=0.879,p=0.680),  time:12.761, tt:255.221\n",
      "Ep:20, loss:0.00022, loss_test:0.15543, lr:8.18e-03, fs:0.76395 (r=0.899,p=0.664),  time:12.799, tt:268.774\n",
      "Ep:21, loss:0.00022, loss_test:0.14951, lr:8.10e-03, fs:0.80734 (r=0.889,p=0.739),  time:12.818, tt:281.993\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.14658, lr:8.02e-03, fs:0.78603 (r=0.909,p=0.692),  time:12.825, tt:294.964\n",
      "Ep:23, loss:0.00021, loss_test:0.14518, lr:7.94e-03, fs:0.80717 (r=0.909,p=0.726),  time:12.796, tt:307.112\n",
      "Ep:24, loss:0.00020, loss_test:0.13470, lr:7.86e-03, fs:0.81057 (r=0.929,p=0.719),  time:12.781, tt:319.535\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00020, loss_test:0.14432, lr:7.78e-03, fs:0.79825 (r=0.919,p=0.705),  time:12.768, tt:331.971\n",
      "Ep:26, loss:0.00019, loss_test:0.13791, lr:7.70e-03, fs:0.81448 (r=0.909,p=0.738),  time:12.747, tt:344.156\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.13384, lr:7.62e-03, fs:0.81081 (r=0.909,p=0.732),  time:12.734, tt:356.540\n",
      "Ep:28, loss:0.00019, loss_test:0.13741, lr:7.55e-03, fs:0.80889 (r=0.919,p=0.722),  time:12.720, tt:368.876\n",
      "Ep:29, loss:0.00018, loss_test:0.13142, lr:7.47e-03, fs:0.83105 (r=0.919,p=0.758),  time:12.739, tt:382.184\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.13172, lr:7.40e-03, fs:0.81513 (r=0.980,p=0.698),  time:12.769, tt:395.843\n",
      "Ep:31, loss:0.00017, loss_test:0.13085, lr:7.32e-03, fs:0.82883 (r=0.929,p=0.748),  time:12.785, tt:409.123\n",
      "Ep:32, loss:0.00016, loss_test:0.12764, lr:7.25e-03, fs:0.80172 (r=0.939,p=0.699),  time:12.767, tt:421.315\n",
      "Ep:33, loss:0.00016, loss_test:0.12717, lr:7.18e-03, fs:0.83258 (r=0.929,p=0.754),  time:12.752, tt:433.579\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00016, loss_test:0.12649, lr:7.11e-03, fs:0.83721 (r=0.909,p=0.776),  time:12.740, tt:445.895\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00016, loss_test:0.12702, lr:7.03e-03, fs:0.80498 (r=0.980,p=0.683),  time:12.728, tt:458.203\n",
      "Ep:36, loss:0.00015, loss_test:0.12639, lr:6.96e-03, fs:0.84793 (r=0.929,p=0.780),  time:12.728, tt:470.921\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00015, loss_test:0.12403, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:12.725, tt:483.561\n",
      "Ep:38, loss:0.00014, loss_test:0.12036, lr:6.83e-03, fs:0.83636 (r=0.929,p=0.760),  time:12.749, tt:497.208\n",
      "Ep:39, loss:0.00014, loss_test:0.12143, lr:6.76e-03, fs:0.83186 (r=0.949,p=0.740),  time:12.760, tt:510.394\n",
      "Ep:40, loss:0.00013, loss_test:0.11781, lr:6.69e-03, fs:0.85455 (r=0.949,p=0.777),  time:12.772, tt:523.649\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00013, loss_test:0.12089, lr:6.62e-03, fs:0.86385 (r=0.929,p=0.807),  time:12.766, tt:536.170\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.11619, lr:6.56e-03, fs:0.85586 (r=0.960,p=0.772),  time:12.754, tt:548.409\n",
      "Ep:43, loss:0.00012, loss_test:0.11639, lr:6.49e-03, fs:0.83478 (r=0.970,p=0.733),  time:12.748, tt:560.926\n",
      "Ep:44, loss:0.00011, loss_test:0.11532, lr:6.43e-03, fs:0.86364 (r=0.960,p=0.785),  time:12.740, tt:573.306\n",
      "Ep:45, loss:0.00011, loss_test:0.11231, lr:6.36e-03, fs:0.84956 (r=0.970,p=0.756),  time:12.733, tt:585.710\n",
      "Ep:46, loss:0.00011, loss_test:0.11373, lr:6.30e-03, fs:0.85714 (r=0.970,p=0.768),  time:12.732, tt:598.400\n",
      "Ep:47, loss:0.00010, loss_test:0.11031, lr:6.24e-03, fs:0.86364 (r=0.960,p=0.785),  time:12.745, tt:611.768\n",
      "Ep:48, loss:0.00010, loss_test:0.10686, lr:6.17e-03, fs:0.85714 (r=0.970,p=0.768),  time:12.760, tt:625.257\n",
      "Ep:49, loss:0.00010, loss_test:0.11006, lr:6.11e-03, fs:0.87156 (r=0.960,p=0.798),  time:12.779, tt:638.948\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00010, loss_test:0.10713, lr:6.05e-03, fs:0.86636 (r=0.949,p=0.797),  time:12.773, tt:651.408\n",
      "Ep:51, loss:0.00009, loss_test:0.10676, lr:5.99e-03, fs:0.85714 (r=0.970,p=0.768),  time:12.767, tt:663.900\n",
      "Ep:52, loss:0.00009, loss_test:0.10746, lr:5.93e-03, fs:0.88263 (r=0.949,p=0.825),  time:12.761, tt:676.332\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.10417, lr:5.87e-03, fs:0.87111 (r=0.990,p=0.778),  time:12.752, tt:688.631\n",
      "Ep:54, loss:0.00009, loss_test:0.10528, lr:5.81e-03, fs:0.88263 (r=0.949,p=0.825),  time:12.748, tt:701.136\n",
      "Ep:55, loss:0.00008, loss_test:0.10289, lr:5.75e-03, fs:0.86099 (r=0.970,p=0.774),  time:12.743, tt:713.623\n",
      "Ep:56, loss:0.00008, loss_test:0.10101, lr:5.70e-03, fs:0.88479 (r=0.970,p=0.814),  time:12.735, tt:725.867\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00008, loss_test:0.10176, lr:5.64e-03, fs:0.84956 (r=0.970,p=0.756),  time:12.737, tt:738.747\n",
      "Ep:58, loss:0.00008, loss_test:0.10305, lr:5.58e-03, fs:0.88263 (r=0.949,p=0.825),  time:12.748, tt:752.127\n",
      "Ep:59, loss:0.00008, loss_test:0.10153, lr:5.53e-03, fs:0.89202 (r=0.960,p=0.833),  time:12.737, tt:764.235\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00008, loss_test:0.09740, lr:5.47e-03, fs:0.87963 (r=0.960,p=0.812),  time:12.725, tt:776.238\n",
      "Ep:61, loss:0.00007, loss_test:0.09665, lr:5.42e-03, fs:0.90566 (r=0.970,p=0.850),  time:12.713, tt:788.203\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.09825, lr:5.36e-03, fs:0.88263 (r=0.949,p=0.825),  time:12.710, tt:800.714\n",
      "Ep:63, loss:0.00007, loss_test:0.10003, lr:5.31e-03, fs:0.88571 (r=0.939,p=0.838),  time:12.702, tt:812.906\n",
      "Ep:64, loss:0.00006, loss_test:0.09709, lr:5.26e-03, fs:0.90141 (r=0.970,p=0.842),  time:12.703, tt:825.684\n",
      "Ep:65, loss:0.00006, loss_test:0.09951, lr:5.20e-03, fs:0.90047 (r=0.960,p=0.848),  time:12.710, tt:838.848\n",
      "Ep:66, loss:0.00006, loss_test:0.10012, lr:5.15e-03, fs:0.89423 (r=0.939,p=0.853),  time:12.714, tt:851.858\n",
      "Ep:67, loss:0.00006, loss_test:0.09560, lr:5.10e-03, fs:0.88479 (r=0.970,p=0.814),  time:12.718, tt:864.831\n",
      "Ep:68, loss:0.00006, loss_test:0.09724, lr:5.05e-03, fs:0.90821 (r=0.949,p=0.870),  time:12.712, tt:877.161\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00006, loss_test:0.09518, lr:5.00e-03, fs:0.89952 (r=0.949,p=0.855),  time:12.703, tt:889.237\n",
      "Ep:70, loss:0.00005, loss_test:0.09523, lr:4.95e-03, fs:0.88679 (r=0.949,p=0.832),  time:12.695, tt:901.372\n",
      "Ep:71, loss:0.00006, loss_test:0.09683, lr:4.90e-03, fs:0.90566 (r=0.970,p=0.850),  time:12.690, tt:913.715\n",
      "Ep:72, loss:0.00005, loss_test:0.09284, lr:4.85e-03, fs:0.90047 (r=0.960,p=0.848),  time:12.684, tt:925.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00005, loss_test:0.09687, lr:4.80e-03, fs:0.90566 (r=0.970,p=0.850),  time:12.683, tt:938.526\n",
      "Ep:74, loss:0.00005, loss_test:0.09229, lr:4.75e-03, fs:0.90566 (r=0.970,p=0.850),  time:12.714, tt:953.519\n",
      "Ep:75, loss:0.00005, loss_test:0.09543, lr:4.71e-03, fs:0.90476 (r=0.960,p=0.856),  time:12.718, tt:966.544\n",
      "Ep:76, loss:0.00005, loss_test:0.10123, lr:4.66e-03, fs:0.90196 (r=0.929,p=0.876),  time:12.725, tt:979.802\n",
      "Ep:77, loss:0.00005, loss_test:0.09229, lr:4.61e-03, fs:0.90995 (r=0.970,p=0.857),  time:12.715, tt:991.766\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00005, loss_test:0.10136, lr:4.57e-03, fs:0.92611 (r=0.949,p=0.904),  time:12.708, tt:1003.903\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00005, loss_test:0.10124, lr:4.52e-03, fs:0.90291 (r=0.939,p=0.869),  time:12.700, tt:1016.017\n",
      "Ep:80, loss:0.00004, loss_test:0.09243, lr:4.48e-03, fs:0.90476 (r=0.960,p=0.856),  time:12.693, tt:1028.128\n",
      "Ep:81, loss:0.00005, loss_test:0.09461, lr:4.43e-03, fs:0.89623 (r=0.960,p=0.841),  time:12.688, tt:1040.419\n",
      "Ep:82, loss:0.00004, loss_test:0.09860, lr:4.39e-03, fs:0.91176 (r=0.939,p=0.886),  time:12.685, tt:1052.870\n",
      "Ep:83, loss:0.00004, loss_test:0.10088, lr:4.34e-03, fs:0.90256 (r=0.889,p=0.917),  time:12.692, tt:1066.153\n",
      "Ep:84, loss:0.00004, loss_test:0.09212, lr:4.30e-03, fs:0.90385 (r=0.949,p=0.862),  time:12.697, tt:1079.235\n",
      "Ep:85, loss:0.00004, loss_test:0.09758, lr:4.26e-03, fs:0.91707 (r=0.949,p=0.887),  time:12.698, tt:1092.021\n",
      "Ep:86, loss:0.00004, loss_test:0.10270, lr:4.21e-03, fs:0.89231 (r=0.879,p=0.906),  time:12.691, tt:1104.101\n",
      "Ep:87, loss:0.00004, loss_test:0.09123, lr:4.17e-03, fs:0.89423 (r=0.939,p=0.853),  time:12.686, tt:1116.397\n",
      "Ep:88, loss:0.00004, loss_test:0.09586, lr:4.13e-03, fs:0.94059 (r=0.960,p=0.922),  time:12.685, tt:1128.940\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.09704, lr:4.09e-03, fs:0.92683 (r=0.960,p=0.896),  time:12.691, tt:1142.193\n",
      "Ep:90, loss:0.00004, loss_test:0.09327, lr:4.05e-03, fs:0.92537 (r=0.939,p=0.912),  time:12.717, tt:1157.233\n",
      "Ep:91, loss:0.00004, loss_test:0.09316, lr:4.01e-03, fs:0.92079 (r=0.939,p=0.903),  time:12.761, tt:1174.047\n",
      "Ep:92, loss:0.00003, loss_test:0.09288, lr:3.97e-03, fs:0.93069 (r=0.949,p=0.913),  time:12.824, tt:1192.595\n",
      "Ep:93, loss:0.00003, loss_test:0.09543, lr:3.93e-03, fs:0.93000 (r=0.939,p=0.921),  time:12.932, tt:1215.579\n",
      "Ep:94, loss:0.00003, loss_test:0.09368, lr:3.89e-03, fs:0.93939 (r=0.939,p=0.939),  time:13.129, tt:1247.285\n",
      "Ep:95, loss:0.00003, loss_test:0.09401, lr:3.85e-03, fs:0.94059 (r=0.960,p=0.922),  time:13.341, tt:1280.719\n",
      "Ep:96, loss:0.00003, loss_test:0.09877, lr:3.81e-03, fs:0.91371 (r=0.909,p=0.918),  time:13.583, tt:1317.515\n",
      "Ep:97, loss:0.00003, loss_test:0.09074, lr:3.77e-03, fs:0.91787 (r=0.960,p=0.880),  time:13.865, tt:1358.753\n",
      "Ep:98, loss:0.00003, loss_test:0.09605, lr:3.73e-03, fs:0.93000 (r=0.939,p=0.921),  time:14.113, tt:1397.149\n",
      "Ep:99, loss:0.00003, loss_test:0.09215, lr:3.70e-03, fs:0.93596 (r=0.960,p=0.913),  time:14.396, tt:1439.601\n",
      "Ep:100, loss:0.00003, loss_test:0.09171, lr:3.62e-03, fs:0.93137 (r=0.960,p=0.905),  time:14.644, tt:1479.012\n",
      "Ep:101, loss:0.00003, loss_test:0.09650, lr:3.55e-03, fs:0.92537 (r=0.939,p=0.912),  time:14.936, tt:1523.484\n",
      "Ep:102, loss:0.00003, loss_test:0.09374, lr:3.48e-03, fs:0.92462 (r=0.929,p=0.920),  time:15.209, tt:1566.485\n",
      "Ep:103, loss:0.00003, loss_test:0.09393, lr:3.41e-03, fs:0.93069 (r=0.949,p=0.913),  time:15.481, tt:1610.001\n",
      "Ep:104, loss:0.00003, loss_test:0.09776, lr:3.34e-03, fs:0.92386 (r=0.919,p=0.929),  time:15.744, tt:1653.144\n",
      "Ep:105, loss:0.00003, loss_test:0.09647, lr:3.28e-03, fs:0.92462 (r=0.929,p=0.920),  time:15.998, tt:1695.813\n",
      "Ep:106, loss:0.00003, loss_test:0.09181, lr:3.21e-03, fs:0.94527 (r=0.960,p=0.931),  time:16.224, tt:1735.963\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00003, loss_test:0.09456, lr:3.18e-03, fs:0.94059 (r=0.960,p=0.922),  time:16.460, tt:1777.707\n",
      "Ep:108, loss:0.00003, loss_test:0.09381, lr:3.15e-03, fs:0.94000 (r=0.949,p=0.931),  time:16.686, tt:1818.810\n",
      "Ep:109, loss:0.00002, loss_test:0.09827, lr:3.12e-03, fs:0.93401 (r=0.929,p=0.939),  time:16.878, tt:1856.605\n",
      "Ep:110, loss:0.00002, loss_test:0.09589, lr:3.09e-03, fs:0.93000 (r=0.939,p=0.921),  time:17.102, tt:1898.349\n",
      "Ep:111, loss:0.00002, loss_test:0.09367, lr:3.05e-03, fs:0.94000 (r=0.949,p=0.931),  time:17.334, tt:1941.436\n",
      "Ep:112, loss:0.00002, loss_test:0.09890, lr:3.02e-03, fs:0.92386 (r=0.919,p=0.929),  time:17.579, tt:1986.416\n",
      "Ep:113, loss:0.00002, loss_test:0.09746, lr:2.99e-03, fs:0.93939 (r=0.939,p=0.939),  time:17.791, tt:2028.151\n",
      "Ep:114, loss:0.00002, loss_test:0.09270, lr:2.96e-03, fs:0.93532 (r=0.949,p=0.922),  time:18.031, tt:2073.594\n",
      "Ep:115, loss:0.00002, loss_test:0.09065, lr:2.93e-03, fs:0.93069 (r=0.949,p=0.913),  time:18.244, tt:2116.303\n",
      "Ep:116, loss:0.00002, loss_test:0.09734, lr:2.90e-03, fs:0.92929 (r=0.929,p=0.929),  time:18.428, tt:2156.026\n",
      "Ep:117, loss:0.00002, loss_test:0.09784, lr:2.88e-03, fs:0.94472 (r=0.949,p=0.940),  time:18.609, tt:2195.889\n",
      "Ep:118, loss:0.00002, loss_test:0.09667, lr:2.82e-03, fs:0.94000 (r=0.949,p=0.931),  time:18.796, tt:2236.692\n",
      "Ep:119, loss:0.00002, loss_test:0.09627, lr:2.76e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.948, tt:2273.760\n",
      "Ep:120, loss:0.00002, loss_test:0.09537, lr:2.71e-03, fs:0.92386 (r=0.919,p=0.929),  time:19.119, tt:2313.391\n",
      "Ep:121, loss:0.00002, loss_test:0.09546, lr:2.65e-03, fs:0.93939 (r=0.939,p=0.939),  time:19.304, tt:2355.110\n",
      "Ep:122, loss:0.00002, loss_test:0.09857, lr:2.60e-03, fs:0.93939 (r=0.939,p=0.939),  time:19.487, tt:2396.950\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24045, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.661, tt:38.661\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.23459, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:39.126, tt:78.251\n",
      "Ep:2, loss:0.00054, loss_test:0.22306, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:39.365, tt:118.094\n",
      "Ep:3, loss:0.00046, loss_test:0.20585, lr:9.70e-03, fs:0.66667 (r=0.929,p=0.520),  time:39.308, tt:157.232\n",
      "Ep:4, loss:0.00038, loss_test:0.19980, lr:9.61e-03, fs:0.68000 (r=0.859,p=0.563),  time:39.400, tt:196.999\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.20298, lr:9.51e-03, fs:0.68696 (r=0.798,p=0.603),  time:39.489, tt:236.932\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.20342, lr:9.41e-03, fs:0.68493 (r=0.758,p=0.625),  time:39.896, tt:279.269\n",
      "Ep:7, loss:0.00030, loss_test:0.20299, lr:9.32e-03, fs:0.67890 (r=0.747,p=0.622),  time:39.994, tt:319.953\n",
      "Ep:8, loss:0.00030, loss_test:0.19230, lr:9.23e-03, fs:0.68376 (r=0.808,p=0.593),  time:40.471, tt:364.236\n",
      "Ep:9, loss:0.00028, loss_test:0.19024, lr:9.14e-03, fs:0.66981 (r=0.717,p=0.628),  time:40.689, tt:406.887\n",
      "Ep:10, loss:0.00027, loss_test:0.19181, lr:9.04e-03, fs:0.69811 (r=0.747,p=0.655),  time:40.579, tt:446.373\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.19199, lr:8.95e-03, fs:0.69951 (r=0.717,p=0.683),  time:40.461, tt:485.534\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.18165, lr:8.86e-03, fs:0.75238 (r=0.798,p=0.712),  time:40.243, tt:523.156\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.18153, lr:8.78e-03, fs:0.70531 (r=0.737,p=0.676),  time:40.061, tt:560.854\n",
      "Ep:14, loss:0.00024, loss_test:0.17713, lr:8.69e-03, fs:0.69811 (r=0.747,p=0.655),  time:39.917, tt:598.757\n",
      "Ep:15, loss:0.00023, loss_test:0.17414, lr:8.60e-03, fs:0.71963 (r=0.778,p=0.670),  time:39.910, tt:638.553\n",
      "Ep:16, loss:0.00023, loss_test:0.17525, lr:8.51e-03, fs:0.70244 (r=0.727,p=0.679),  time:39.904, tt:678.376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00022, loss_test:0.17522, lr:8.43e-03, fs:0.71220 (r=0.737,p=0.689),  time:40.075, tt:721.359\n",
      "Ep:18, loss:0.00022, loss_test:0.17023, lr:8.35e-03, fs:0.72115 (r=0.758,p=0.688),  time:40.246, tt:764.678\n",
      "Ep:19, loss:0.00021, loss_test:0.17148, lr:8.26e-03, fs:0.72906 (r=0.747,p=0.712),  time:40.236, tt:804.730\n",
      "Ep:20, loss:0.00021, loss_test:0.16803, lr:8.18e-03, fs:0.72897 (r=0.788,p=0.678),  time:40.158, tt:843.313\n",
      "Ep:21, loss:0.00020, loss_test:0.16975, lr:8.10e-03, fs:0.73529 (r=0.758,p=0.714),  time:40.035, tt:880.769\n",
      "Ep:22, loss:0.00019, loss_test:0.17190, lr:8.02e-03, fs:0.72906 (r=0.747,p=0.712),  time:39.939, tt:918.596\n",
      "Ep:23, loss:0.00019, loss_test:0.16395, lr:7.94e-03, fs:0.73934 (r=0.788,p=0.696),  time:39.844, tt:956.260\n",
      "Ep:24, loss:0.00019, loss_test:0.17253, lr:7.78e-03, fs:0.70707 (r=0.707,p=0.707),  time:39.845, tt:996.128\n",
      "Ep:25, loss:0.00018, loss_test:0.16463, lr:7.62e-03, fs:0.75362 (r=0.788,p=0.722),  time:39.817, tt:1035.234\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.16109, lr:7.55e-03, fs:0.76777 (r=0.818,p=0.723),  time:40.003, tt:1080.088\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.16845, lr:7.47e-03, fs:0.72637 (r=0.737,p=0.716),  time:40.065, tt:1121.830\n",
      "Ep:28, loss:0.00017, loss_test:0.16273, lr:7.40e-03, fs:0.74257 (r=0.758,p=0.728),  time:40.189, tt:1165.493\n",
      "Ep:29, loss:0.00017, loss_test:0.15937, lr:7.32e-03, fs:0.77209 (r=0.838,p=0.716),  time:40.236, tt:1207.066\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.16400, lr:7.25e-03, fs:0.73196 (r=0.717,p=0.747),  time:40.274, tt:1248.508\n",
      "Ep:31, loss:0.00016, loss_test:0.15523, lr:7.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:40.300, tt:1289.615\n",
      "Ep:32, loss:0.00016, loss_test:0.16404, lr:7.11e-03, fs:0.75258 (r=0.737,p=0.768),  time:40.299, tt:1329.864\n",
      "Ep:33, loss:0.00015, loss_test:0.16045, lr:7.03e-03, fs:0.78049 (r=0.808,p=0.755),  time:40.341, tt:1371.579\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.15373, lr:6.96e-03, fs:0.75962 (r=0.798,p=0.725),  time:40.355, tt:1412.410\n",
      "Ep:35, loss:0.00014, loss_test:0.15487, lr:6.89e-03, fs:0.79000 (r=0.798,p=0.782),  time:40.371, tt:1453.345\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.15698, lr:6.83e-03, fs:0.76531 (r=0.758,p=0.773),  time:40.488, tt:1498.073\n",
      "Ep:37, loss:0.00014, loss_test:0.15695, lr:6.76e-03, fs:0.75248 (r=0.768,p=0.738),  time:40.556, tt:1541.112\n",
      "Ep:38, loss:0.00013, loss_test:0.15460, lr:6.69e-03, fs:0.79412 (r=0.818,p=0.771),  time:40.581, tt:1582.659\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.15478, lr:6.62e-03, fs:0.78173 (r=0.778,p=0.786),  time:40.635, tt:1625.419\n",
      "Ep:40, loss:0.00012, loss_test:0.15736, lr:6.56e-03, fs:0.75510 (r=0.747,p=0.763),  time:40.588, tt:1664.115\n",
      "Ep:41, loss:0.00012, loss_test:0.15263, lr:6.49e-03, fs:0.81000 (r=0.818,p=0.802),  time:40.571, tt:1703.991\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.15715, lr:6.43e-03, fs:0.79592 (r=0.788,p=0.804),  time:40.535, tt:1742.986\n",
      "Ep:43, loss:0.00011, loss_test:0.15573, lr:6.36e-03, fs:0.79592 (r=0.788,p=0.804),  time:40.498, tt:1781.925\n",
      "Ep:44, loss:0.00011, loss_test:0.14920, lr:6.30e-03, fs:0.81159 (r=0.848,p=0.778),  time:40.477, tt:1821.456\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00011, loss_test:0.15595, lr:6.24e-03, fs:0.77320 (r=0.758,p=0.789),  time:40.471, tt:1861.665\n",
      "Ep:46, loss:0.00011, loss_test:0.15383, lr:6.17e-03, fs:0.79592 (r=0.788,p=0.804),  time:40.521, tt:1904.469\n",
      "Ep:47, loss:0.00010, loss_test:0.14891, lr:6.11e-03, fs:0.79188 (r=0.788,p=0.796),  time:40.584, tt:1948.024\n",
      "Ep:48, loss:0.00011, loss_test:0.15091, lr:6.05e-03, fs:0.77778 (r=0.778,p=0.778),  time:40.639, tt:1991.300\n",
      "Ep:49, loss:0.00010, loss_test:0.15390, lr:5.99e-03, fs:0.80000 (r=0.808,p=0.792),  time:40.650, tt:2032.502\n",
      "Ep:50, loss:0.00010, loss_test:0.15498, lr:5.93e-03, fs:0.79381 (r=0.778,p=0.811),  time:40.618, tt:2071.530\n",
      "Ep:51, loss:0.00009, loss_test:0.15109, lr:5.87e-03, fs:0.78788 (r=0.788,p=0.788),  time:40.573, tt:2109.773\n",
      "Ep:52, loss:0.00010, loss_test:0.15351, lr:5.81e-03, fs:0.79381 (r=0.778,p=0.811),  time:40.554, tt:2149.364\n",
      "Ep:53, loss:0.00009, loss_test:0.15540, lr:5.75e-03, fs:0.75000 (r=0.727,p=0.774),  time:40.528, tt:2188.538\n",
      "Ep:54, loss:0.00009, loss_test:0.14780, lr:5.70e-03, fs:0.80402 (r=0.808,p=0.800),  time:40.508, tt:2227.942\n",
      "Ep:55, loss:0.00009, loss_test:0.14617, lr:5.64e-03, fs:0.82353 (r=0.848,p=0.800),  time:40.505, tt:2268.258\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00008, loss_test:0.15445, lr:5.58e-03, fs:0.75132 (r=0.717,p=0.789),  time:40.518, tt:2309.522\n",
      "Ep:57, loss:0.00008, loss_test:0.15611, lr:5.53e-03, fs:0.76757 (r=0.717,p=0.826),  time:40.540, tt:2351.308\n",
      "Ep:58, loss:0.00008, loss_test:0.14408, lr:5.47e-03, fs:0.81951 (r=0.848,p=0.792),  time:40.575, tt:2393.931\n",
      "Ep:59, loss:0.00008, loss_test:0.14620, lr:5.42e-03, fs:0.81407 (r=0.818,p=0.810),  time:40.545, tt:2432.675\n",
      "Ep:60, loss:0.00007, loss_test:0.15418, lr:5.36e-03, fs:0.75676 (r=0.707,p=0.814),  time:40.525, tt:2472.009\n",
      "Ep:61, loss:0.00008, loss_test:0.14787, lr:5.31e-03, fs:0.79798 (r=0.798,p=0.798),  time:40.530, tt:2512.860\n",
      "Ep:62, loss:0.00007, loss_test:0.14567, lr:5.26e-03, fs:0.81218 (r=0.808,p=0.816),  time:40.503, tt:2551.659\n",
      "Ep:63, loss:0.00007, loss_test:0.15361, lr:5.20e-03, fs:0.76344 (r=0.717,p=0.816),  time:40.503, tt:2592.165\n",
      "Ep:64, loss:0.00007, loss_test:0.14863, lr:5.15e-03, fs:0.79365 (r=0.758,p=0.833),  time:40.497, tt:2632.336\n",
      "Ep:65, loss:0.00007, loss_test:0.14487, lr:5.10e-03, fs:0.77487 (r=0.747,p=0.804),  time:40.516, tt:2674.031\n",
      "Ep:66, loss:0.00007, loss_test:0.14750, lr:5.05e-03, fs:0.79581 (r=0.768,p=0.826),  time:40.562, tt:2717.686\n",
      "Ep:67, loss:0.00007, loss_test:0.15052, lr:4.95e-03, fs:0.75269 (r=0.707,p=0.805),  time:40.618, tt:2762.002\n",
      "Ep:68, loss:0.00006, loss_test:0.14468, lr:4.85e-03, fs:0.77895 (r=0.747,p=0.813),  time:40.664, tt:2805.817\n",
      "Ep:69, loss:0.00006, loss_test:0.13819, lr:4.75e-03, fs:0.82412 (r=0.828,p=0.820),  time:40.671, tt:2847.000\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.14678, lr:4.71e-03, fs:0.77249 (r=0.737,p=0.811),  time:40.663, tt:2887.067\n",
      "Ep:71, loss:0.00006, loss_test:0.15125, lr:4.66e-03, fs:0.76503 (r=0.707,p=0.833),  time:40.630, tt:2925.358\n",
      "Ep:72, loss:0.00006, loss_test:0.14384, lr:4.61e-03, fs:0.77419 (r=0.727,p=0.828),  time:40.614, tt:2964.857\n",
      "Ep:73, loss:0.00005, loss_test:0.14180, lr:4.57e-03, fs:0.78351 (r=0.768,p=0.800),  time:40.590, tt:3003.660\n",
      "Ep:74, loss:0.00005, loss_test:0.14731, lr:4.52e-03, fs:0.77838 (r=0.727,p=0.837),  time:40.583, tt:3043.739\n",
      "Ep:75, loss:0.00006, loss_test:0.14638, lr:4.48e-03, fs:0.77005 (r=0.727,p=0.818),  time:40.617, tt:3086.870\n",
      "Ep:76, loss:0.00005, loss_test:0.14314, lr:4.43e-03, fs:0.76190 (r=0.727,p=0.800),  time:40.639, tt:3129.241\n",
      "Ep:77, loss:0.00005, loss_test:0.14294, lr:4.39e-03, fs:0.78919 (r=0.737,p=0.849),  time:40.661, tt:3171.528\n",
      "Ep:78, loss:0.00005, loss_test:0.14847, lr:4.34e-03, fs:0.77174 (r=0.717,p=0.835),  time:40.680, tt:3213.692\n",
      "Ep:79, loss:0.00005, loss_test:0.15042, lr:4.30e-03, fs:0.77005 (r=0.727,p=0.818),  time:40.668, tt:3253.419\n",
      "Ep:80, loss:0.00005, loss_test:0.14319, lr:4.26e-03, fs:0.77419 (r=0.727,p=0.828),  time:40.651, tt:3292.744\n",
      "Ep:81, loss:0.00005, loss_test:0.14446, lr:4.17e-03, fs:0.75936 (r=0.717,p=0.807),  time:40.635, tt:3332.089\n",
      "Ep:82, loss:0.00005, loss_test:0.14672, lr:4.09e-03, fs:0.76757 (r=0.717,p=0.826),  time:40.629, tt:3372.240\n",
      "Ep:83, loss:0.00004, loss_test:0.14596, lr:4.01e-03, fs:0.77174 (r=0.717,p=0.835),  time:40.640, tt:3413.775\n",
      "Ep:84, loss:0.00004, loss_test:0.14368, lr:3.93e-03, fs:0.77596 (r=0.717,p=0.845),  time:40.617, tt:3452.419\n",
      "Ep:85, loss:0.00004, loss_test:0.14383, lr:3.85e-03, fs:0.77596 (r=0.717,p=0.845),  time:40.634, tt:3494.533\n",
      "Ep:86, loss:0.00004, loss_test:0.14620, lr:3.77e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.683, tt:3539.437\n",
      "Ep:87, loss:0.00004, loss_test:0.14331, lr:3.70e-03, fs:0.76503 (r=0.707,p=0.833),  time:40.725, tt:3583.802\n",
      "Ep:88, loss:0.00004, loss_test:0.14545, lr:3.62e-03, fs:0.77174 (r=0.717,p=0.835),  time:40.712, tt:3623.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00004, loss_test:0.14766, lr:3.55e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.690, tt:3662.057\n",
      "Ep:90, loss:0.00004, loss_test:0.14255, lr:3.48e-03, fs:0.77174 (r=0.717,p=0.835),  time:40.682, tt:3702.056\n",
      "Ep:91, loss:0.00004, loss_test:0.14314, lr:3.41e-03, fs:0.77596 (r=0.717,p=0.845),  time:40.654, tt:3740.135\n",
      "Ep:92, loss:0.00004, loss_test:0.14134, lr:3.34e-03, fs:0.77838 (r=0.727,p=0.837),  time:40.662, tt:3781.587\n",
      "Ep:93, loss:0.00003, loss_test:0.14105, lr:3.28e-03, fs:0.77174 (r=0.717,p=0.835),  time:40.585, tt:3814.981\n",
      "Ep:94, loss:0.00004, loss_test:0.14781, lr:3.21e-03, fs:0.78022 (r=0.717,p=0.855),  time:40.526, tt:3849.965\n",
      "Ep:95, loss:0.00004, loss_test:0.14445, lr:3.15e-03, fs:0.78022 (r=0.717,p=0.855),  time:40.468, tt:3884.960\n",
      "Ep:96, loss:0.00004, loss_test:0.13942, lr:3.09e-03, fs:0.77419 (r=0.727,p=0.828),  time:40.463, tt:3924.943\n",
      "Ep:97, loss:0.00003, loss_test:0.14120, lr:3.02e-03, fs:0.77838 (r=0.727,p=0.837),  time:40.480, tt:3967.039\n",
      "Ep:98, loss:0.00003, loss_test:0.14467, lr:2.96e-03, fs:0.77596 (r=0.717,p=0.845),  time:40.509, tt:4010.438\n",
      "Ep:99, loss:0.00004, loss_test:0.14624, lr:2.90e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.504, tt:4050.377\n",
      "Ep:100, loss:0.00003, loss_test:0.14085, lr:2.85e-03, fs:0.77419 (r=0.727,p=0.828),  time:40.486, tt:4089.124\n",
      "Ep:101, loss:0.00003, loss_test:0.14017, lr:2.79e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.483, tt:4129.300\n",
      "Ep:102, loss:0.00003, loss_test:0.14115, lr:2.73e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.475, tt:4168.948\n",
      "Ep:103, loss:0.00003, loss_test:0.14123, lr:2.68e-03, fs:0.78689 (r=0.727,p=0.857),  time:40.476, tt:4209.551\n",
      "Ep:104, loss:0.00003, loss_test:0.13909, lr:2.63e-03, fs:0.77838 (r=0.727,p=0.837),  time:40.487, tt:4251.146\n",
      "Ep:105, loss:0.00003, loss_test:0.13987, lr:2.57e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.526, tt:4295.753\n",
      "Ep:106, loss:0.00003, loss_test:0.14176, lr:2.52e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.565, tt:4340.468\n",
      "Ep:107, loss:0.00003, loss_test:0.14196, lr:2.47e-03, fs:0.78453 (r=0.717,p=0.866),  time:40.599, tt:4384.731\n",
      "Ep:108, loss:0.00003, loss_test:0.14242, lr:2.42e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.630, tt:4428.671\n",
      "Ep:109, loss:0.00003, loss_test:0.14128, lr:2.38e-03, fs:0.77838 (r=0.727,p=0.837),  time:40.667, tt:4473.358\n",
      "Ep:110, loss:0.00003, loss_test:0.14203, lr:2.33e-03, fs:0.77596 (r=0.717,p=0.845),  time:40.659, tt:4513.166\n",
      "Ep:111, loss:0.00003, loss_test:0.14723, lr:2.28e-03, fs:0.76836 (r=0.687,p=0.872),  time:40.672, tt:4555.268\n",
      "Ep:112, loss:0.00003, loss_test:0.14510, lr:2.24e-03, fs:0.78453 (r=0.717,p=0.866),  time:40.670, tt:4595.763\n",
      "Ep:113, loss:0.00003, loss_test:0.13763, lr:2.19e-03, fs:0.78689 (r=0.727,p=0.857),  time:40.648, tt:4633.873\n",
      "Ep:114, loss:0.00003, loss_test:0.13676, lr:2.15e-03, fs:0.78261 (r=0.727,p=0.847),  time:40.645, tt:4674.225\n",
      "Ep:115, loss:0.00003, loss_test:0.14251, lr:2.11e-03, fs:0.78689 (r=0.727,p=0.857),  time:40.676, tt:4718.404\n",
      "Ep:116, loss:0.00003, loss_test:0.14844, lr:2.06e-03, fs:0.79558 (r=0.727,p=0.878),  time:40.692, tt:4760.995\n",
      "Ep:117, loss:0.00003, loss_test:0.14519, lr:2.02e-03, fs:0.78409 (r=0.697,p=0.896),  time:40.701, tt:4802.756\n",
      "Ep:118, loss:0.00003, loss_test:0.13927, lr:1.98e-03, fs:0.79558 (r=0.727,p=0.878),  time:40.712, tt:4844.711\n",
      "Ep:119, loss:0.00002, loss_test:0.13678, lr:1.94e-03, fs:0.77419 (r=0.727,p=0.828),  time:40.696, tt:4883.495\n",
      "Ep:120, loss:0.00003, loss_test:0.13799, lr:1.90e-03, fs:0.78689 (r=0.727,p=0.857),  time:40.693, tt:4923.878\n",
      "Ep:121, loss:0.00002, loss_test:0.14110, lr:1.87e-03, fs:0.80000 (r=0.727,p=0.889),  time:40.688, tt:4963.969\n",
      "Ep:122, loss:0.00003, loss_test:0.14390, lr:1.83e-03, fs:0.79558 (r=0.727,p=0.878),  time:40.673, tt:5002.808\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24522, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.757, tt:42.757\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.24270, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:43.745, tt:87.491\n",
      "Ep:2, loss:0.00055, loss_test:0.23867, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:43.928, tt:131.785\n",
      "Ep:3, loss:0.00047, loss_test:0.23370, lr:9.70e-03, fs:0.63273 (r=0.879,p=0.494),  time:43.948, tt:175.793\n",
      "Ep:4, loss:0.00037, loss_test:0.22809, lr:9.61e-03, fs:0.61479 (r=0.798,p=0.500),  time:43.737, tt:218.684\n",
      "Ep:5, loss:0.00033, loss_test:0.22880, lr:9.51e-03, fs:0.60086 (r=0.707,p=0.522),  time:43.314, tt:259.883\n",
      "Ep:6, loss:0.00031, loss_test:0.22374, lr:9.41e-03, fs:0.62712 (r=0.747,p=0.540),  time:43.120, tt:301.842\n",
      "Ep:7, loss:0.00030, loss_test:0.21511, lr:9.32e-03, fs:0.63348 (r=0.707,p=0.574),  time:43.012, tt:344.098\n",
      "Ep:8, loss:0.00030, loss_test:0.20831, lr:9.23e-03, fs:0.62500 (r=0.707,p=0.560),  time:42.899, tt:386.087\n",
      "Ep:9, loss:0.00028, loss_test:0.20906, lr:9.14e-03, fs:0.66364 (r=0.737,p=0.603),  time:42.809, tt:428.091\n",
      "Ep:10, loss:0.00026, loss_test:0.20129, lr:9.04e-03, fs:0.65778 (r=0.747,p=0.587),  time:43.094, tt:474.038\n",
      "Ep:11, loss:0.00026, loss_test:0.19890, lr:8.95e-03, fs:0.68837 (r=0.747,p=0.638),  time:43.292, tt:519.509\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.19274, lr:8.86e-03, fs:0.69124 (r=0.758,p=0.636),  time:43.465, tt:565.043\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.18818, lr:8.78e-03, fs:0.70852 (r=0.798,p=0.637),  time:43.600, tt:610.399\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.18608, lr:8.69e-03, fs:0.71233 (r=0.788,p=0.650),  time:43.316, tt:649.737\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.18254, lr:8.60e-03, fs:0.71749 (r=0.808,p=0.645),  time:43.151, tt:690.420\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.18512, lr:8.51e-03, fs:0.69159 (r=0.747,p=0.643),  time:43.173, tt:733.948\n",
      "Ep:17, loss:0.00022, loss_test:0.18127, lr:8.43e-03, fs:0.70093 (r=0.758,p=0.652),  time:43.019, tt:774.343\n",
      "Ep:18, loss:0.00022, loss_test:0.17467, lr:8.35e-03, fs:0.73128 (r=0.838,p=0.648),  time:42.982, tt:816.649\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.17669, lr:8.26e-03, fs:0.71889 (r=0.788,p=0.661),  time:42.880, tt:857.607\n",
      "Ep:20, loss:0.00021, loss_test:0.17222, lr:8.18e-03, fs:0.73303 (r=0.818,p=0.664),  time:42.972, tt:902.415\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.16891, lr:8.10e-03, fs:0.75576 (r=0.828,p=0.695),  time:43.066, tt:947.453\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.16726, lr:8.02e-03, fs:0.75472 (r=0.808,p=0.708),  time:43.132, tt:992.036\n",
      "Ep:23, loss:0.00020, loss_test:0.16464, lr:7.94e-03, fs:0.76364 (r=0.848,p=0.694),  time:43.138, tt:1035.306\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.16303, lr:7.86e-03, fs:0.75701 (r=0.818,p=0.704),  time:43.022, tt:1075.562\n",
      "Ep:25, loss:0.00018, loss_test:0.16175, lr:7.78e-03, fs:0.77982 (r=0.859,p=0.714),  time:42.929, tt:1116.155\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.15573, lr:7.70e-03, fs:0.77056 (r=0.899,p=0.674),  time:42.840, tt:1156.687\n",
      "Ep:27, loss:0.00018, loss_test:0.17078, lr:7.62e-03, fs:0.74257 (r=0.758,p=0.728),  time:42.767, tt:1197.469\n",
      "Ep:28, loss:0.00017, loss_test:0.15896, lr:7.55e-03, fs:0.76712 (r=0.848,p=0.700),  time:42.647, tt:1236.756\n",
      "Ep:29, loss:0.00017, loss_test:0.15436, lr:7.47e-03, fs:0.77679 (r=0.879,p=0.696),  time:42.588, tt:1277.643\n",
      "Ep:30, loss:0.00016, loss_test:0.15627, lr:7.40e-03, fs:0.78873 (r=0.848,p=0.737),  time:42.628, tt:1321.462\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.15806, lr:7.32e-03, fs:0.79070 (r=0.859,p=0.733),  time:42.681, tt:1365.783\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00016, loss_test:0.14721, lr:7.25e-03, fs:0.78603 (r=0.909,p=0.692),  time:42.720, tt:1409.764\n",
      "Ep:33, loss:0.00015, loss_test:0.15631, lr:7.18e-03, fs:0.76777 (r=0.818,p=0.723),  time:42.700, tt:1451.799\n",
      "Ep:34, loss:0.00015, loss_test:0.14941, lr:7.11e-03, fs:0.77419 (r=0.848,p=0.712),  time:42.617, tt:1491.582\n",
      "Ep:35, loss:0.00014, loss_test:0.14926, lr:7.03e-03, fs:0.78899 (r=0.869,p=0.723),  time:42.497, tt:1529.903\n",
      "Ep:36, loss:0.00014, loss_test:0.15447, lr:6.96e-03, fs:0.78641 (r=0.818,p=0.757),  time:42.431, tt:1569.938\n",
      "Ep:37, loss:0.00014, loss_test:0.14139, lr:6.89e-03, fs:0.81614 (r=0.919,p=0.734),  time:42.352, tt:1609.360\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00014, loss_test:0.14666, lr:6.83e-03, fs:0.79817 (r=0.879,p=0.731),  time:42.314, tt:1650.253\n",
      "Ep:39, loss:0.00013, loss_test:0.14792, lr:6.76e-03, fs:0.78899 (r=0.869,p=0.723),  time:42.237, tt:1689.492\n",
      "Ep:40, loss:0.00014, loss_test:0.14663, lr:6.69e-03, fs:0.79630 (r=0.869,p=0.735),  time:42.243, tt:1731.982\n",
      "Ep:41, loss:0.00013, loss_test:0.14030, lr:6.62e-03, fs:0.81818 (r=0.909,p=0.744),  time:42.225, tt:1773.465\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00013, loss_test:0.14326, lr:6.56e-03, fs:0.81308 (r=0.879,p=0.757),  time:42.260, tt:1817.164\n",
      "Ep:43, loss:0.00012, loss_test:0.14631, lr:6.49e-03, fs:0.79426 (r=0.838,p=0.755),  time:42.267, tt:1859.727\n",
      "Ep:44, loss:0.00012, loss_test:0.14256, lr:6.43e-03, fs:0.82524 (r=0.859,p=0.794),  time:42.201, tt:1899.059\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00012, loss_test:0.14266, lr:6.36e-03, fs:0.79808 (r=0.838,p=0.761),  time:42.189, tt:1940.678\n",
      "Ep:46, loss:0.00012, loss_test:0.13997, lr:6.30e-03, fs:0.80556 (r=0.879,p=0.744),  time:42.146, tt:1980.867\n",
      "Ep:47, loss:0.00011, loss_test:0.14422, lr:6.24e-03, fs:0.78846 (r=0.828,p=0.752),  time:42.077, tt:2019.675\n",
      "Ep:48, loss:0.00011, loss_test:0.13618, lr:6.17e-03, fs:0.81106 (r=0.889,p=0.746),  time:42.041, tt:2060.014\n",
      "Ep:49, loss:0.00011, loss_test:0.13722, lr:6.11e-03, fs:0.81905 (r=0.869,p=0.775),  time:42.035, tt:2101.738\n",
      "Ep:50, loss:0.00010, loss_test:0.13655, lr:6.05e-03, fs:0.80751 (r=0.869,p=0.754),  time:42.071, tt:2145.634\n",
      "Ep:51, loss:0.00010, loss_test:0.14119, lr:5.99e-03, fs:0.80976 (r=0.838,p=0.783),  time:42.070, tt:2187.649\n",
      "Ep:52, loss:0.00010, loss_test:0.14065, lr:5.93e-03, fs:0.80392 (r=0.828,p=0.781),  time:42.075, tt:2229.999\n",
      "Ep:53, loss:0.00010, loss_test:0.13849, lr:5.87e-03, fs:0.80569 (r=0.859,p=0.759),  time:42.010, tt:2268.562\n",
      "Ep:54, loss:0.00009, loss_test:0.13721, lr:5.81e-03, fs:0.80583 (r=0.838,p=0.776),  time:41.930, tt:2306.156\n",
      "Ep:55, loss:0.00009, loss_test:0.13828, lr:5.75e-03, fs:0.80392 (r=0.828,p=0.781),  time:41.839, tt:2342.999\n",
      "Ep:56, loss:0.00009, loss_test:0.13992, lr:5.64e-03, fs:0.80000 (r=0.808,p=0.792),  time:41.794, tt:2382.261\n",
      "Ep:57, loss:0.00008, loss_test:0.13751, lr:5.53e-03, fs:0.80392 (r=0.828,p=0.781),  time:41.672, tt:2416.985\n",
      "Ep:58, loss:0.00009, loss_test:0.13447, lr:5.42e-03, fs:0.81132 (r=0.869,p=0.761),  time:41.585, tt:2453.508\n",
      "Ep:59, loss:0.00009, loss_test:0.14105, lr:5.31e-03, fs:0.79397 (r=0.798,p=0.790),  time:41.525, tt:2491.475\n",
      "Ep:60, loss:0.00008, loss_test:0.13365, lr:5.20e-03, fs:0.81132 (r=0.869,p=0.761),  time:41.468, tt:2529.526\n",
      "Ep:61, loss:0.00008, loss_test:0.14186, lr:5.10e-03, fs:0.79803 (r=0.818,p=0.779),  time:41.407, tt:2567.241\n",
      "Ep:62, loss:0.00008, loss_test:0.13988, lr:5.00e-03, fs:0.82178 (r=0.838,p=0.806),  time:41.340, tt:2604.400\n",
      "Ep:63, loss:0.00008, loss_test:0.13180, lr:4.90e-03, fs:0.82243 (r=0.889,p=0.765),  time:41.312, tt:2643.989\n",
      "Ep:64, loss:0.00008, loss_test:0.14790, lr:4.80e-03, fs:0.78788 (r=0.788,p=0.788),  time:41.241, tt:2680.664\n",
      "Ep:65, loss:0.00007, loss_test:0.14082, lr:4.71e-03, fs:0.80392 (r=0.828,p=0.781),  time:41.209, tt:2719.827\n",
      "Ep:66, loss:0.00007, loss_test:0.13428, lr:4.61e-03, fs:0.81308 (r=0.879,p=0.757),  time:41.158, tt:2757.566\n",
      "Ep:67, loss:0.00007, loss_test:0.14223, lr:4.52e-03, fs:0.80808 (r=0.808,p=0.808),  time:41.128, tt:2796.694\n",
      "Ep:68, loss:0.00007, loss_test:0.13366, lr:4.43e-03, fs:0.80952 (r=0.859,p=0.766),  time:41.111, tt:2836.684\n",
      "Ep:69, loss:0.00007, loss_test:0.13970, lr:4.34e-03, fs:0.77778 (r=0.778,p=0.778),  time:41.067, tt:2874.687\n",
      "Ep:70, loss:0.00007, loss_test:0.14213, lr:4.26e-03, fs:0.79592 (r=0.788,p=0.804),  time:41.043, tt:2914.020\n",
      "Ep:71, loss:0.00007, loss_test:0.13868, lr:4.17e-03, fs:0.79227 (r=0.828,p=0.759),  time:41.013, tt:2952.971\n",
      "Ep:72, loss:0.00006, loss_test:0.14148, lr:4.09e-03, fs:0.78000 (r=0.788,p=0.772),  time:40.966, tt:2990.485\n",
      "Ep:73, loss:0.00007, loss_test:0.14326, lr:4.01e-03, fs:0.77320 (r=0.758,p=0.789),  time:40.901, tt:3026.660\n",
      "Ep:74, loss:0.00007, loss_test:0.14352, lr:3.93e-03, fs:0.78571 (r=0.778,p=0.794),  time:40.883, tt:3066.239\n",
      "Ep:75, loss:0.00006, loss_test:0.13697, lr:3.85e-03, fs:0.81159 (r=0.848,p=0.778),  time:40.825, tt:3102.669\n",
      "Ep:76, loss:0.00006, loss_test:0.14372, lr:3.77e-03, fs:0.76042 (r=0.737,p=0.785),  time:40.781, tt:3140.134\n",
      "Ep:77, loss:0.00006, loss_test:0.14172, lr:3.70e-03, fs:0.78571 (r=0.778,p=0.794),  time:40.741, tt:3177.829\n",
      "Ep:78, loss:0.00006, loss_test:0.14028, lr:3.62e-03, fs:0.76617 (r=0.778,p=0.755),  time:40.712, tt:3216.236\n",
      "Ep:79, loss:0.00006, loss_test:0.14617, lr:3.55e-03, fs:0.74346 (r=0.717,p=0.772),  time:40.680, tt:3254.392\n",
      "Ep:80, loss:0.00006, loss_test:0.14761, lr:3.48e-03, fs:0.74737 (r=0.717,p=0.780),  time:40.660, tt:3293.463\n",
      "Ep:81, loss:0.00006, loss_test:0.14141, lr:3.41e-03, fs:0.73958 (r=0.717,p=0.763),  time:40.634, tt:3331.981\n",
      "Ep:82, loss:0.00006, loss_test:0.14233, lr:3.34e-03, fs:0.73575 (r=0.717,p=0.755),  time:40.601, tt:3369.882\n",
      "Ep:83, loss:0.00005, loss_test:0.14345, lr:3.28e-03, fs:0.73958 (r=0.717,p=0.763),  time:40.575, tt:3408.266\n",
      "Ep:84, loss:0.00005, loss_test:0.14349, lr:3.21e-03, fs:0.75393 (r=0.727,p=0.783),  time:40.532, tt:3445.218\n",
      "Ep:85, loss:0.00005, loss_test:0.14688, lr:3.15e-03, fs:0.75789 (r=0.727,p=0.791),  time:40.481, tt:3481.388\n",
      "Ep:86, loss:0.00005, loss_test:0.14048, lr:3.09e-03, fs:0.74872 (r=0.737,p=0.760),  time:40.469, tt:3520.775\n",
      "Ep:87, loss:0.00005, loss_test:0.14189, lr:3.02e-03, fs:0.73196 (r=0.717,p=0.747),  time:40.472, tt:3561.566\n",
      "Ep:88, loss:0.00005, loss_test:0.15080, lr:2.96e-03, fs:0.74194 (r=0.697,p=0.793),  time:40.412, tt:3596.705\n",
      "Ep:89, loss:0.00005, loss_test:0.14202, lr:2.90e-03, fs:0.74346 (r=0.717,p=0.772),  time:40.328, tt:3629.484\n",
      "Ep:90, loss:0.00005, loss_test:0.14274, lr:2.85e-03, fs:0.75258 (r=0.737,p=0.768),  time:40.334, tt:3670.380\n",
      "Ep:91, loss:0.00005, loss_test:0.15202, lr:2.79e-03, fs:0.72632 (r=0.697,p=0.758),  time:40.328, tt:3710.182\n",
      "Ep:92, loss:0.00005, loss_test:0.14794, lr:2.73e-03, fs:0.73684 (r=0.707,p=0.769),  time:40.304, tt:3748.313\n",
      "Ep:93, loss:0.00005, loss_test:0.14747, lr:2.68e-03, fs:0.74468 (r=0.707,p=0.787),  time:40.267, tt:3785.093\n",
      "Ep:94, loss:0.00004, loss_test:0.14931, lr:2.63e-03, fs:0.74468 (r=0.707,p=0.787),  time:40.221, tt:3820.956\n",
      "Ep:95, loss:0.00005, loss_test:0.14408, lr:2.57e-03, fs:0.73575 (r=0.717,p=0.755),  time:40.162, tt:3855.523\n",
      "Ep:96, loss:0.00005, loss_test:0.14650, lr:2.52e-03, fs:0.73958 (r=0.717,p=0.763),  time:40.042, tt:3884.065\n",
      "Ep:97, loss:0.00005, loss_test:0.14850, lr:2.47e-03, fs:0.74737 (r=0.717,p=0.780),  time:40.005, tt:3920.509\n",
      "Ep:98, loss:0.00004, loss_test:0.14539, lr:2.42e-03, fs:0.74346 (r=0.717,p=0.772),  time:40.008, tt:3960.802\n",
      "Ep:99, loss:0.00004, loss_test:0.14762, lr:2.38e-03, fs:0.73684 (r=0.707,p=0.769),  time:40.002, tt:4000.185\n",
      "Ep:100, loss:0.00005, loss_test:0.14849, lr:2.33e-03, fs:0.74074 (r=0.707,p=0.778),  time:39.999, tt:4039.886\n",
      "Ep:101, loss:0.00005, loss_test:0.14706, lr:2.28e-03, fs:0.74346 (r=0.717,p=0.772),  time:39.992, tt:4079.229\n",
      "Ep:102, loss:0.00004, loss_test:0.14877, lr:2.24e-03, fs:0.73958 (r=0.717,p=0.763),  time:39.976, tt:4117.521\n",
      "Ep:103, loss:0.00004, loss_test:0.15083, lr:2.19e-03, fs:0.73684 (r=0.707,p=0.769),  time:39.963, tt:4156.186\n",
      "Ep:104, loss:0.00004, loss_test:0.15040, lr:2.15e-03, fs:0.74074 (r=0.707,p=0.778),  time:39.960, tt:4195.803\n",
      "Ep:105, loss:0.00005, loss_test:0.14828, lr:2.11e-03, fs:0.74346 (r=0.717,p=0.772),  time:39.946, tt:4234.310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00004, loss_test:0.14479, lr:2.06e-03, fs:0.74346 (r=0.717,p=0.772),  time:39.932, tt:4272.692\n",
      "Ep:107, loss:0.00004, loss_test:0.15123, lr:2.02e-03, fs:0.74866 (r=0.707,p=0.795),  time:39.927, tt:4312.096\n",
      "Ep:108, loss:0.00004, loss_test:0.15004, lr:1.98e-03, fs:0.75936 (r=0.717,p=0.807),  time:39.924, tt:4351.664\n",
      "Ep:109, loss:0.00004, loss_test:0.14605, lr:1.94e-03, fs:0.74737 (r=0.717,p=0.780),  time:39.926, tt:4391.888\n",
      "Ep:110, loss:0.00004, loss_test:0.14855, lr:1.90e-03, fs:0.74737 (r=0.717,p=0.780),  time:39.925, tt:4431.648\n",
      "Ep:111, loss:0.00004, loss_test:0.15201, lr:1.87e-03, fs:0.73797 (r=0.697,p=0.784),  time:39.935, tt:4472.690\n",
      "Ep:112, loss:0.00004, loss_test:0.15295, lr:1.83e-03, fs:0.74866 (r=0.707,p=0.795),  time:39.934, tt:4512.529\n",
      "Ep:113, loss:0.00004, loss_test:0.15049, lr:1.79e-03, fs:0.74074 (r=0.707,p=0.778),  time:39.911, tt:4549.849\n",
      "Ep:114, loss:0.00004, loss_test:0.15066, lr:1.76e-03, fs:0.75132 (r=0.717,p=0.789),  time:39.899, tt:4588.396\n",
      "Ep:115, loss:0.00004, loss_test:0.15293, lr:1.72e-03, fs:0.74468 (r=0.707,p=0.787),  time:39.898, tt:4628.183\n",
      "Ep:116, loss:0.00004, loss_test:0.15527, lr:1.69e-03, fs:0.74194 (r=0.697,p=0.793),  time:39.900, tt:4668.271\n",
      "Ep:117, loss:0.00004, loss_test:0.15323, lr:1.65e-03, fs:0.74468 (r=0.707,p=0.787),  time:39.891, tt:4707.114\n",
      "Ep:118, loss:0.00004, loss_test:0.15224, lr:1.62e-03, fs:0.74866 (r=0.707,p=0.795),  time:39.873, tt:4744.921\n",
      "Ep:119, loss:0.00004, loss_test:0.15389, lr:1.59e-03, fs:0.74194 (r=0.697,p=0.793),  time:39.877, tt:4785.192\n",
      "Ep:120, loss:0.00004, loss_test:0.15482, lr:1.56e-03, fs:0.74468 (r=0.707,p=0.787),  time:39.876, tt:4824.999\n",
      "Ep:121, loss:0.00004, loss_test:0.15684, lr:1.53e-03, fs:0.74194 (r=0.697,p=0.793),  time:39.852, tt:4861.968\n",
      "Ep:122, loss:0.00004, loss_test:0.15317, lr:1.50e-03, fs:0.75269 (r=0.707,p=0.805),  time:39.841, tt:4900.488\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24010, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.167, tt:40.167\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.23424, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.311, tt:80.622\n",
      "Ep:2, loss:0.00055, loss_test:0.22151, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.239, tt:120.717\n",
      "Ep:3, loss:0.00048, loss_test:0.20202, lr:9.70e-03, fs:0.67368 (r=0.970,p=0.516),  time:40.674, tt:162.696\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00039, loss_test:0.19043, lr:9.61e-03, fs:0.67954 (r=0.889,p=0.550),  time:40.259, tt:201.294\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.19104, lr:9.51e-03, fs:0.68908 (r=0.828,p=0.590),  time:40.157, tt:240.945\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.18999, lr:9.41e-03, fs:0.70485 (r=0.808,p=0.625),  time:40.096, tt:280.674\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.18854, lr:9.32e-03, fs:0.72146 (r=0.798,p=0.658),  time:40.071, tt:320.568\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.18189, lr:9.23e-03, fs:0.71795 (r=0.848,p=0.622),  time:40.008, tt:360.070\n",
      "Ep:9, loss:0.00029, loss_test:0.17975, lr:9.14e-03, fs:0.72727 (r=0.848,p=0.636),  time:39.927, tt:399.269\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.18053, lr:9.04e-03, fs:0.72889 (r=0.828,p=0.651),  time:39.818, tt:438.003\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.17445, lr:8.95e-03, fs:0.75576 (r=0.828,p=0.695),  time:39.545, tt:474.539\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.17298, lr:8.86e-03, fs:0.75576 (r=0.828,p=0.695),  time:39.678, tt:515.812\n",
      "Ep:13, loss:0.00025, loss_test:0.16405, lr:8.78e-03, fs:0.75676 (r=0.848,p=0.683),  time:39.525, tt:553.352\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.17039, lr:8.69e-03, fs:0.75117 (r=0.808,p=0.702),  time:39.505, tt:592.570\n",
      "Ep:15, loss:0.00024, loss_test:0.16769, lr:8.60e-03, fs:0.76190 (r=0.808,p=0.721),  time:39.344, tt:629.501\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.16173, lr:8.51e-03, fs:0.77358 (r=0.828,p=0.726),  time:39.317, tt:668.391\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.16277, lr:8.43e-03, fs:0.75926 (r=0.828,p=0.701),  time:39.194, tt:705.492\n",
      "Ep:18, loss:0.00022, loss_test:0.15992, lr:8.35e-03, fs:0.78095 (r=0.828,p=0.739),  time:39.202, tt:744.834\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.15471, lr:8.26e-03, fs:0.80000 (r=0.869,p=0.741),  time:39.163, tt:783.250\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.15927, lr:8.18e-03, fs:0.77570 (r=0.838,p=0.722),  time:39.154, tt:822.228\n",
      "Ep:21, loss:0.00021, loss_test:0.15731, lr:8.10e-03, fs:0.77934 (r=0.838,p=0.728),  time:39.142, tt:861.132\n",
      "Ep:22, loss:0.00020, loss_test:0.15669, lr:8.02e-03, fs:0.79227 (r=0.828,p=0.759),  time:39.143, tt:900.283\n",
      "Ep:23, loss:0.00019, loss_test:0.15817, lr:7.94e-03, fs:0.81159 (r=0.848,p=0.778),  time:39.008, tt:936.185\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.14737, lr:7.86e-03, fs:0.83105 (r=0.919,p=0.758),  time:39.023, tt:975.567\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.15226, lr:7.78e-03, fs:0.82126 (r=0.859,p=0.787),  time:39.006, tt:1014.143\n",
      "Ep:26, loss:0.00019, loss_test:0.14769, lr:7.70e-03, fs:0.80383 (r=0.848,p=0.764),  time:38.997, tt:1052.923\n",
      "Ep:27, loss:0.00017, loss_test:0.14552, lr:7.62e-03, fs:0.80556 (r=0.879,p=0.744),  time:38.970, tt:1091.154\n",
      "Ep:28, loss:0.00017, loss_test:0.14926, lr:7.55e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.972, tt:1130.185\n",
      "Ep:29, loss:0.00017, loss_test:0.14365, lr:7.47e-03, fs:0.81132 (r=0.869,p=0.761),  time:38.958, tt:1168.737\n",
      "Ep:30, loss:0.00016, loss_test:0.14194, lr:7.40e-03, fs:0.82791 (r=0.899,p=0.767),  time:38.850, tt:1204.344\n",
      "Ep:31, loss:0.00017, loss_test:0.14599, lr:7.32e-03, fs:0.84058 (r=0.879,p=0.806),  time:38.801, tt:1241.647\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.13632, lr:7.25e-03, fs:0.85333 (r=0.970,p=0.762),  time:38.794, tt:1280.187\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.13458, lr:7.18e-03, fs:0.82791 (r=0.899,p=0.767),  time:38.785, tt:1318.700\n",
      "Ep:34, loss:0.00015, loss_test:0.14205, lr:7.11e-03, fs:0.83412 (r=0.889,p=0.786),  time:38.737, tt:1355.781\n",
      "Ep:35, loss:0.00015, loss_test:0.13832, lr:7.03e-03, fs:0.86256 (r=0.919,p=0.812),  time:38.733, tt:1394.397\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.13249, lr:6.96e-03, fs:0.85202 (r=0.960,p=0.766),  time:38.745, tt:1433.578\n",
      "Ep:37, loss:0.00014, loss_test:0.13481, lr:6.89e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.751, tt:1472.524\n",
      "Ep:38, loss:0.00014, loss_test:0.13334, lr:6.83e-03, fs:0.87736 (r=0.939,p=0.823),  time:38.694, tt:1509.049\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.12954, lr:6.76e-03, fs:0.86385 (r=0.929,p=0.807),  time:38.671, tt:1546.844\n",
      "Ep:40, loss:0.00013, loss_test:0.13921, lr:6.69e-03, fs:0.83810 (r=0.889,p=0.793),  time:38.650, tt:1584.633\n",
      "Ep:41, loss:0.00013, loss_test:0.12837, lr:6.62e-03, fs:0.86099 (r=0.970,p=0.774),  time:38.693, tt:1625.087\n",
      "Ep:42, loss:0.00012, loss_test:0.12715, lr:6.56e-03, fs:0.87850 (r=0.949,p=0.817),  time:38.680, tt:1663.239\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00012, loss_test:0.13048, lr:6.49e-03, fs:0.86408 (r=0.899,p=0.832),  time:38.690, tt:1702.379\n",
      "Ep:44, loss:0.00012, loss_test:0.12464, lr:6.43e-03, fs:0.87037 (r=0.949,p=0.803),  time:38.671, tt:1740.177\n",
      "Ep:45, loss:0.00011, loss_test:0.12974, lr:6.36e-03, fs:0.85577 (r=0.899,p=0.817),  time:38.645, tt:1777.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00011, loss_test:0.12361, lr:6.30e-03, fs:0.88263 (r=0.949,p=0.825),  time:38.616, tt:1814.945\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.12265, lr:6.24e-03, fs:0.89623 (r=0.960,p=0.841),  time:38.611, tt:1853.347\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00010, loss_test:0.12778, lr:6.17e-03, fs:0.88995 (r=0.939,p=0.845),  time:38.600, tt:1891.414\n",
      "Ep:49, loss:0.00010, loss_test:0.12100, lr:6.11e-03, fs:0.89202 (r=0.960,p=0.833),  time:38.610, tt:1930.493\n",
      "Ep:50, loss:0.00010, loss_test:0.11868, lr:6.05e-03, fs:0.88785 (r=0.960,p=0.826),  time:38.565, tt:1966.793\n",
      "Ep:51, loss:0.00009, loss_test:0.12426, lr:5.99e-03, fs:0.89952 (r=0.949,p=0.855),  time:38.553, tt:2004.748\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00009, loss_test:0.12489, lr:5.93e-03, fs:0.89855 (r=0.939,p=0.861),  time:38.583, tt:2044.890\n",
      "Ep:53, loss:0.00009, loss_test:0.11893, lr:5.87e-03, fs:0.87255 (r=0.899,p=0.848),  time:38.579, tt:2083.245\n",
      "Ep:54, loss:0.00009, loss_test:0.11760, lr:5.81e-03, fs:0.91346 (r=0.960,p=0.872),  time:38.554, tt:2120.445\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.12338, lr:5.75e-03, fs:0.91262 (r=0.949,p=0.879),  time:38.552, tt:2158.894\n",
      "Ep:56, loss:0.00009, loss_test:0.11947, lr:5.70e-03, fs:0.88038 (r=0.929,p=0.836),  time:38.527, tt:2196.033\n",
      "Ep:57, loss:0.00008, loss_test:0.11859, lr:5.64e-03, fs:0.90385 (r=0.949,p=0.862),  time:38.519, tt:2234.111\n",
      "Ep:58, loss:0.00008, loss_test:0.11961, lr:5.58e-03, fs:0.90732 (r=0.939,p=0.877),  time:38.486, tt:2270.673\n",
      "Ep:59, loss:0.00008, loss_test:0.11491, lr:5.53e-03, fs:0.89952 (r=0.949,p=0.855),  time:38.453, tt:2307.203\n",
      "Ep:60, loss:0.00008, loss_test:0.11971, lr:5.47e-03, fs:0.91707 (r=0.949,p=0.887),  time:38.454, tt:2345.666\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00007, loss_test:0.12367, lr:5.42e-03, fs:0.89000 (r=0.899,p=0.881),  time:38.458, tt:2384.383\n",
      "Ep:62, loss:0.00007, loss_test:0.11955, lr:5.36e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.454, tt:2422.626\n",
      "Ep:63, loss:0.00007, loss_test:0.12057, lr:5.31e-03, fs:0.90640 (r=0.929,p=0.885),  time:38.455, tt:2461.121\n",
      "Ep:64, loss:0.00007, loss_test:0.11454, lr:5.26e-03, fs:0.90476 (r=0.960,p=0.856),  time:38.443, tt:2498.793\n",
      "Ep:65, loss:0.00007, loss_test:0.11470, lr:5.20e-03, fs:0.89000 (r=0.899,p=0.881),  time:38.429, tt:2536.318\n",
      "Ep:66, loss:0.00006, loss_test:0.11557, lr:5.15e-03, fs:0.86869 (r=0.869,p=0.869),  time:38.424, tt:2574.382\n",
      "Ep:67, loss:0.00006, loss_test:0.11576, lr:5.10e-03, fs:0.87923 (r=0.919,p=0.843),  time:38.414, tt:2612.125\n",
      "Ep:68, loss:0.00006, loss_test:0.12376, lr:5.05e-03, fs:0.87629 (r=0.859,p=0.895),  time:38.411, tt:2650.380\n",
      "Ep:69, loss:0.00006, loss_test:0.11705, lr:5.00e-03, fs:0.86869 (r=0.869,p=0.869),  time:38.413, tt:2688.891\n",
      "Ep:70, loss:0.00006, loss_test:0.11763, lr:4.95e-03, fs:0.86154 (r=0.848,p=0.875),  time:38.420, tt:2727.817\n",
      "Ep:71, loss:0.00006, loss_test:0.11389, lr:4.90e-03, fs:0.90099 (r=0.919,p=0.883),  time:38.442, tt:2767.824\n",
      "Ep:72, loss:0.00005, loss_test:0.11475, lr:4.80e-03, fs:0.91089 (r=0.929,p=0.893),  time:38.429, tt:2805.345\n",
      "Ep:73, loss:0.00005, loss_test:0.12296, lr:4.71e-03, fs:0.88542 (r=0.859,p=0.914),  time:38.408, tt:2842.164\n",
      "Ep:74, loss:0.00005, loss_test:0.12157, lr:4.61e-03, fs:0.88542 (r=0.859,p=0.914),  time:38.424, tt:2881.781\n",
      "Ep:75, loss:0.00005, loss_test:0.11452, lr:4.52e-03, fs:0.90000 (r=0.909,p=0.891),  time:38.421, tt:2919.984\n",
      "Ep:76, loss:0.00005, loss_test:0.11716, lr:4.43e-03, fs:0.86869 (r=0.869,p=0.869),  time:38.421, tt:2958.403\n",
      "Ep:77, loss:0.00005, loss_test:0.11982, lr:4.34e-03, fs:0.91542 (r=0.929,p=0.902),  time:38.411, tt:2996.086\n",
      "Ep:78, loss:0.00005, loss_test:0.11689, lr:4.26e-03, fs:0.90355 (r=0.899,p=0.908),  time:38.427, tt:3035.748\n",
      "Ep:79, loss:0.00005, loss_test:0.11812, lr:4.17e-03, fs:0.87047 (r=0.848,p=0.894),  time:38.418, tt:3073.407\n",
      "Ep:80, loss:0.00004, loss_test:0.12046, lr:4.09e-03, fs:0.87368 (r=0.838,p=0.912),  time:38.408, tt:3111.027\n",
      "Ep:81, loss:0.00005, loss_test:0.12147, lr:4.01e-03, fs:0.86911 (r=0.838,p=0.902),  time:38.406, tt:3149.270\n",
      "Ep:82, loss:0.00004, loss_test:0.12488, lr:3.93e-03, fs:0.87701 (r=0.828,p=0.932),  time:38.410, tt:3188.018\n",
      "Ep:83, loss:0.00004, loss_test:0.12293, lr:3.85e-03, fs:0.86772 (r=0.828,p=0.911),  time:38.409, tt:3226.342\n",
      "Ep:84, loss:0.00004, loss_test:0.11572, lr:3.77e-03, fs:0.85859 (r=0.859,p=0.859),  time:38.386, tt:3262.826\n",
      "Ep:85, loss:0.00004, loss_test:0.11820, lr:3.70e-03, fs:0.86010 (r=0.838,p=0.883),  time:38.391, tt:3301.589\n",
      "Ep:86, loss:0.00004, loss_test:0.12479, lr:3.62e-03, fs:0.86316 (r=0.828,p=0.901),  time:38.378, tt:3338.856\n",
      "Ep:87, loss:0.00004, loss_test:0.12603, lr:3.55e-03, fs:0.86316 (r=0.828,p=0.901),  time:38.392, tt:3378.519\n",
      "Ep:88, loss:0.00004, loss_test:0.11927, lr:3.48e-03, fs:0.86010 (r=0.838,p=0.883),  time:38.404, tt:3417.914\n",
      "Ep:89, loss:0.00004, loss_test:0.12028, lr:3.41e-03, fs:0.85417 (r=0.828,p=0.882),  time:38.348, tt:3451.305\n",
      "Ep:90, loss:0.00004, loss_test:0.11961, lr:3.34e-03, fs:0.86911 (r=0.838,p=0.902),  time:38.372, tt:3491.817\n",
      "Ep:91, loss:0.00004, loss_test:0.11911, lr:3.28e-03, fs:0.85567 (r=0.838,p=0.874),  time:38.386, tt:3531.474\n",
      "Ep:92, loss:0.00003, loss_test:0.12143, lr:3.21e-03, fs:0.85567 (r=0.838,p=0.874),  time:38.407, tt:3571.820\n",
      "Ep:93, loss:0.00004, loss_test:0.12310, lr:3.15e-03, fs:0.85714 (r=0.818,p=0.900),  time:38.399, tt:3609.463\n",
      "Ep:94, loss:0.00003, loss_test:0.12515, lr:3.09e-03, fs:0.85864 (r=0.828,p=0.891),  time:38.375, tt:3645.599\n",
      "Ep:95, loss:0.00003, loss_test:0.12306, lr:3.02e-03, fs:0.85417 (r=0.828,p=0.882),  time:38.384, tt:3684.818\n",
      "Ep:96, loss:0.00003, loss_test:0.12717, lr:2.96e-03, fs:0.85714 (r=0.818,p=0.900),  time:38.305, tt:3715.605\n",
      "Ep:97, loss:0.00003, loss_test:0.13083, lr:2.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:38.294, tt:3752.852\n",
      "Ep:98, loss:0.00003, loss_test:0.12632, lr:2.85e-03, fs:0.86631 (r=0.818,p=0.920),  time:38.282, tt:3789.943\n",
      "Ep:99, loss:0.00003, loss_test:0.12392, lr:2.79e-03, fs:0.85714 (r=0.818,p=0.900),  time:38.298, tt:3829.842\n",
      "Ep:100, loss:0.00003, loss_test:0.12390, lr:2.73e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.322, tt:3870.501\n",
      "Ep:101, loss:0.00003, loss_test:0.12480, lr:2.68e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.320, tt:3908.621\n",
      "Ep:102, loss:0.00003, loss_test:0.12417, lr:2.63e-03, fs:0.86316 (r=0.828,p=0.901),  time:38.339, tt:3948.952\n",
      "Ep:103, loss:0.00003, loss_test:0.12233, lr:2.57e-03, fs:0.86316 (r=0.828,p=0.901),  time:38.331, tt:3986.419\n",
      "Ep:104, loss:0.00003, loss_test:0.12950, lr:2.52e-03, fs:0.86486 (r=0.808,p=0.930),  time:38.322, tt:4023.758\n",
      "Ep:105, loss:0.00003, loss_test:0.12971, lr:2.47e-03, fs:0.87097 (r=0.818,p=0.931),  time:38.317, tt:4061.598\n",
      "Ep:106, loss:0.00003, loss_test:0.12814, lr:2.42e-03, fs:0.87097 (r=0.818,p=0.931),  time:38.322, tt:4100.454\n",
      "Ep:107, loss:0.00003, loss_test:0.12712, lr:2.38e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.313, tt:4137.854\n",
      "Ep:108, loss:0.00003, loss_test:0.12770, lr:2.33e-03, fs:0.86486 (r=0.808,p=0.930),  time:38.335, tt:4178.473\n",
      "Ep:109, loss:0.00003, loss_test:0.12647, lr:2.28e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.338, tt:4217.183\n",
      "Ep:110, loss:0.00003, loss_test:0.12471, lr:2.24e-03, fs:0.87097 (r=0.818,p=0.931),  time:38.328, tt:4254.438\n",
      "Ep:111, loss:0.00003, loss_test:0.12419, lr:2.19e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.318, tt:4291.605\n",
      "Ep:112, loss:0.00003, loss_test:0.12511, lr:2.15e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.310, tt:4328.976\n",
      "Ep:113, loss:0.00003, loss_test:0.12508, lr:2.11e-03, fs:0.86170 (r=0.818,p=0.910),  time:38.307, tt:4366.979\n",
      "Ep:114, loss:0.00003, loss_test:0.12676, lr:2.06e-03, fs:0.85106 (r=0.808,p=0.899),  time:38.301, tt:4404.586\n",
      "Ep:115, loss:0.00003, loss_test:0.13065, lr:2.02e-03, fs:0.86486 (r=0.808,p=0.930),  time:38.287, tt:4441.345\n",
      "Ep:116, loss:0.00003, loss_test:0.13079, lr:1.98e-03, fs:0.86631 (r=0.818,p=0.920),  time:38.281, tt:4478.868\n",
      "Ep:117, loss:0.00003, loss_test:0.12903, lr:1.94e-03, fs:0.86486 (r=0.808,p=0.930),  time:38.280, tt:4517.019\n",
      "Ep:118, loss:0.00002, loss_test:0.12797, lr:1.90e-03, fs:0.86486 (r=0.808,p=0.930),  time:38.279, tt:4555.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00002, loss_test:0.12787, lr:1.87e-03, fs:0.87097 (r=0.818,p=0.931),  time:38.285, tt:4594.152\n",
      "Ep:120, loss:0.00003, loss_test:0.12919, lr:1.83e-03, fs:0.86631 (r=0.818,p=0.920),  time:38.288, tt:4632.818\n",
      "Ep:121, loss:0.00002, loss_test:0.12992, lr:1.79e-03, fs:0.86022 (r=0.808,p=0.920),  time:38.278, tt:4669.937\n",
      "Ep:122, loss:0.00002, loss_test:0.13090, lr:1.76e-03, fs:0.86486 (r=0.808,p=0.930),  time:38.274, tt:4707.693\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24132, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.389, tt:38.389\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.23580, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.756, tt:75.511\n",
      "Ep:2, loss:0.00055, loss_test:0.22427, lr:9.80e-03, fs:0.67119 (r=1.000,p=0.505),  time:38.011, tt:114.033\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.21420, lr:9.70e-03, fs:0.65683 (r=0.899,p=0.517),  time:38.209, tt:152.835\n",
      "Ep:4, loss:0.00039, loss_test:0.21209, lr:9.61e-03, fs:0.63710 (r=0.798,p=0.530),  time:38.655, tt:193.274\n",
      "Ep:5, loss:0.00033, loss_test:0.21471, lr:9.51e-03, fs:0.67873 (r=0.758,p=0.615),  time:38.720, tt:232.317\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00030, loss_test:0.21721, lr:9.41e-03, fs:0.65366 (r=0.677,p=0.632),  time:38.610, tt:270.267\n",
      "Ep:7, loss:0.00030, loss_test:0.21351, lr:9.32e-03, fs:0.68246 (r=0.727,p=0.643),  time:38.696, tt:309.566\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.20362, lr:9.23e-03, fs:0.68778 (r=0.768,p=0.623),  time:38.616, tt:347.548\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.20131, lr:9.14e-03, fs:0.70370 (r=0.768,p=0.650),  time:38.439, tt:384.389\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.20130, lr:9.04e-03, fs:0.68599 (r=0.717,p=0.657),  time:38.389, tt:422.283\n",
      "Ep:11, loss:0.00025, loss_test:0.19642, lr:8.95e-03, fs:0.71028 (r=0.768,p=0.661),  time:38.366, tt:460.394\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.19576, lr:8.86e-03, fs:0.68657 (r=0.697,p=0.676),  time:38.372, tt:498.833\n",
      "Ep:13, loss:0.00024, loss_test:0.19301, lr:8.78e-03, fs:0.66986 (r=0.707,p=0.636),  time:38.361, tt:537.053\n",
      "Ep:14, loss:0.00024, loss_test:0.18958, lr:8.69e-03, fs:0.71698 (r=0.768,p=0.673),  time:38.385, tt:575.780\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.18779, lr:8.60e-03, fs:0.71498 (r=0.747,p=0.685),  time:38.334, tt:613.339\n",
      "Ep:16, loss:0.00023, loss_test:0.18153, lr:8.51e-03, fs:0.70093 (r=0.758,p=0.652),  time:38.298, tt:651.065\n",
      "Ep:17, loss:0.00021, loss_test:0.18581, lr:8.43e-03, fs:0.72362 (r=0.727,p=0.720),  time:38.212, tt:687.812\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.17777, lr:8.35e-03, fs:0.79452 (r=0.879,p=0.725),  time:38.107, tt:724.040\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1230bd3a7753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m#naive way of testing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mth_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mthreshold_acc\u001b[0;34m(model, g, features, mask, loss, print_details, threshold_dist, threshold_cos, path)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m#mask = np.array([x for x in mask if x[2]==1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m#dist() | max(0, m - dist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,123,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 18272 Test samples: 108\n",
      "Train positive samples: 489 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24110, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.344, tt:13.344\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.23660, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:13.536, tt:27.072\n",
      "Ep:2, loss:0.00056, loss_test:0.22630, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:13.792, tt:41.375\n",
      "Ep:3, loss:0.00050, loss_test:0.20690, lr:9.70e-03, fs:0.65385 (r=0.944,p=0.500),  time:13.851, tt:55.403\n",
      "Ep:4, loss:0.00041, loss_test:0.18920, lr:9.61e-03, fs:0.67606 (r=0.889,p=0.545),  time:14.030, tt:70.152\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00032, loss_test:0.19066, lr:9.51e-03, fs:0.71875 (r=0.852,p=0.622),  time:14.001, tt:84.007\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.18850, lr:9.41e-03, fs:0.72000 (r=0.833,p=0.634),  time:14.068, tt:98.479\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.18470, lr:9.32e-03, fs:0.72581 (r=0.833,p=0.643),  time:14.151, tt:113.205\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.18131, lr:9.23e-03, fs:0.72269 (r=0.796,p=0.662),  time:14.185, tt:127.664\n",
      "Ep:9, loss:0.00028, loss_test:0.17555, lr:9.14e-03, fs:0.71667 (r=0.796,p=0.652),  time:14.249, tt:142.495\n",
      "Ep:10, loss:0.00026, loss_test:0.17212, lr:9.04e-03, fs:0.70000 (r=0.778,p=0.636),  time:14.253, tt:156.778\n",
      "Ep:11, loss:0.00026, loss_test:0.16951, lr:8.95e-03, fs:0.72414 (r=0.778,p=0.677),  time:14.289, tt:171.466\n",
      "Ep:12, loss:0.00025, loss_test:0.16648, lr:8.86e-03, fs:0.73684 (r=0.778,p=0.700),  time:14.347, tt:186.515\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.16339, lr:8.78e-03, fs:0.75000 (r=0.833,p=0.682),  time:14.420, tt:201.879\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.16015, lr:8.69e-03, fs:0.76667 (r=0.852,p=0.697),  time:14.461, tt:216.910\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.15743, lr:8.60e-03, fs:0.77311 (r=0.852,p=0.708),  time:14.488, tt:231.801\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.15441, lr:8.51e-03, fs:0.77686 (r=0.870,p=0.701),  time:14.478, tt:246.122\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.14771, lr:8.43e-03, fs:0.81667 (r=0.907,p=0.742),  time:14.508, tt:261.136\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.14521, lr:8.35e-03, fs:0.80992 (r=0.907,p=0.731),  time:14.542, tt:276.294\n",
      "Ep:19, loss:0.00022, loss_test:0.14348, lr:8.26e-03, fs:0.81356 (r=0.889,p=0.750),  time:14.562, tt:291.234\n",
      "Ep:20, loss:0.00021, loss_test:0.14005, lr:8.18e-03, fs:0.80000 (r=0.889,p=0.727),  time:14.557, tt:305.696\n",
      "Ep:21, loss:0.00020, loss_test:0.14211, lr:8.10e-03, fs:0.81739 (r=0.870,p=0.770),  time:14.562, tt:320.371\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.13878, lr:8.02e-03, fs:0.79339 (r=0.889,p=0.716),  time:14.571, tt:335.132\n",
      "Ep:23, loss:0.00020, loss_test:0.13803, lr:7.94e-03, fs:0.84483 (r=0.907,p=0.790),  time:14.595, tt:350.269\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.13019, lr:7.86e-03, fs:0.81600 (r=0.944,p=0.718),  time:14.593, tt:364.829\n",
      "Ep:25, loss:0.00019, loss_test:0.12805, lr:7.78e-03, fs:0.83051 (r=0.907,p=0.766),  time:14.597, tt:379.516\n",
      "Ep:26, loss:0.00018, loss_test:0.12649, lr:7.70e-03, fs:0.78125 (r=0.926,p=0.676),  time:14.625, tt:394.871\n",
      "Ep:27, loss:0.00017, loss_test:0.12842, lr:7.62e-03, fs:0.83761 (r=0.907,p=0.778),  time:14.610, tt:409.081\n",
      "Ep:28, loss:0.00017, loss_test:0.12347, lr:7.55e-03, fs:0.83333 (r=0.926,p=0.758),  time:14.609, tt:423.667\n",
      "Ep:29, loss:0.00017, loss_test:0.12290, lr:7.47e-03, fs:0.84211 (r=0.889,p=0.800),  time:14.614, tt:438.414\n",
      "Ep:30, loss:0.00017, loss_test:0.11933, lr:7.40e-03, fs:0.85470 (r=0.926,p=0.794),  time:14.617, tt:453.121\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.11509, lr:7.32e-03, fs:0.81890 (r=0.963,p=0.712),  time:14.591, tt:466.907\n",
      "Ep:32, loss:0.00015, loss_test:0.11655, lr:7.25e-03, fs:0.85714 (r=0.889,p=0.828),  time:14.586, tt:481.339\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.11137, lr:7.18e-03, fs:0.84298 (r=0.944,p=0.761),  time:14.589, tt:496.037\n",
      "Ep:34, loss:0.00014, loss_test:0.11039, lr:7.11e-03, fs:0.86441 (r=0.944,p=0.797),  time:14.597, tt:510.889\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.10800, lr:7.03e-03, fs:0.82258 (r=0.944,p=0.729),  time:14.579, tt:524.836\n",
      "Ep:36, loss:0.00014, loss_test:0.10524, lr:6.96e-03, fs:0.86441 (r=0.944,p=0.797),  time:14.581, tt:539.507\n",
      "Ep:37, loss:0.00013, loss_test:0.10508, lr:6.89e-03, fs:0.89076 (r=0.981,p=0.815),  time:14.580, tt:554.058\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.10367, lr:6.83e-03, fs:0.87719 (r=0.926,p=0.833),  time:14.574, tt:568.389\n",
      "Ep:39, loss:0.00012, loss_test:0.09920, lr:6.76e-03, fs:0.87395 (r=0.963,p=0.800),  time:14.568, tt:582.720\n",
      "Ep:40, loss:0.00012, loss_test:0.09798, lr:6.69e-03, fs:0.88136 (r=0.963,p=0.812),  time:14.555, tt:596.739\n",
      "Ep:41, loss:0.00011, loss_test:0.09605, lr:6.62e-03, fs:0.87603 (r=0.981,p=0.791),  time:14.553, tt:611.235\n",
      "Ep:42, loss:0.00011, loss_test:0.09209, lr:6.56e-03, fs:0.88333 (r=0.981,p=0.803),  time:14.548, tt:625.562\n",
      "Ep:43, loss:0.00011, loss_test:0.08835, lr:6.49e-03, fs:0.87603 (r=0.981,p=0.791),  time:14.540, tt:639.776\n",
      "Ep:44, loss:0.00010, loss_test:0.08543, lr:6.43e-03, fs:0.88333 (r=0.981,p=0.803),  time:14.541, tt:654.363\n",
      "Ep:45, loss:0.00010, loss_test:0.08757, lr:6.36e-03, fs:0.89831 (r=0.981,p=0.828),  time:14.538, tt:668.727\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.08336, lr:6.30e-03, fs:0.87603 (r=0.981,p=0.791),  time:14.539, tt:683.333\n",
      "Ep:47, loss:0.00009, loss_test:0.08031, lr:6.24e-03, fs:0.91379 (r=0.981,p=0.855),  time:14.529, tt:697.415\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.07796, lr:6.17e-03, fs:0.90598 (r=0.981,p=0.841),  time:14.521, tt:711.515\n",
      "Ep:49, loss:0.00008, loss_test:0.07716, lr:6.11e-03, fs:0.89831 (r=0.981,p=0.828),  time:14.517, tt:725.846\n",
      "Ep:50, loss:0.00008, loss_test:0.07476, lr:6.05e-03, fs:0.91379 (r=0.981,p=0.855),  time:14.496, tt:739.315\n",
      "Ep:51, loss:0.00008, loss_test:0.07202, lr:5.99e-03, fs:0.90435 (r=0.963,p=0.852),  time:14.489, tt:753.429\n",
      "Ep:52, loss:0.00007, loss_test:0.07077, lr:5.93e-03, fs:0.89831 (r=0.981,p=0.828),  time:14.482, tt:767.564\n",
      "Ep:53, loss:0.00007, loss_test:0.06837, lr:5.87e-03, fs:0.90435 (r=0.963,p=0.852),  time:14.478, tt:781.813\n",
      "Ep:54, loss:0.00007, loss_test:0.06752, lr:5.81e-03, fs:0.91379 (r=0.981,p=0.855),  time:14.471, tt:795.920\n",
      "Ep:55, loss:0.00007, loss_test:0.06395, lr:5.75e-03, fs:0.91228 (r=0.963,p=0.867),  time:14.458, tt:809.637\n",
      "Ep:56, loss:0.00007, loss_test:0.06316, lr:5.70e-03, fs:0.90598 (r=0.981,p=0.841),  time:14.440, tt:823.073\n",
      "Ep:57, loss:0.00006, loss_test:0.06274, lr:5.64e-03, fs:0.90598 (r=0.981,p=0.841),  time:14.416, tt:836.130\n",
      "Ep:58, loss:0.00006, loss_test:0.05889, lr:5.58e-03, fs:0.92982 (r=0.981,p=0.883),  time:14.398, tt:849.460\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.05822, lr:5.53e-03, fs:0.90435 (r=0.963,p=0.852),  time:14.381, tt:862.870\n",
      "Ep:60, loss:0.00005, loss_test:0.05836, lr:5.47e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.366, tt:876.308\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.05524, lr:5.42e-03, fs:0.92035 (r=0.963,p=0.881),  time:14.349, tt:889.639\n",
      "Ep:62, loss:0.00005, loss_test:0.05524, lr:5.36e-03, fs:0.90435 (r=0.963,p=0.852),  time:14.334, tt:903.014\n",
      "Ep:63, loss:0.00005, loss_test:0.05625, lr:5.31e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.309, tt:915.762\n",
      "Ep:64, loss:0.00005, loss_test:0.05444, lr:5.26e-03, fs:0.92982 (r=0.981,p=0.883),  time:14.296, tt:929.209\n",
      "Ep:65, loss:0.00005, loss_test:0.05371, lr:5.20e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.274, tt:942.074\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.05222, lr:5.15e-03, fs:0.92035 (r=0.963,p=0.881),  time:14.264, tt:955.686\n",
      "Ep:67, loss:0.00005, loss_test:0.05271, lr:5.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.248, tt:968.871\n",
      "Ep:68, loss:0.00004, loss_test:0.05121, lr:5.05e-03, fs:0.92035 (r=0.963,p=0.881),  time:14.235, tt:982.203\n",
      "Ep:69, loss:0.00004, loss_test:0.05082, lr:5.00e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.226, tt:995.791\n",
      "Ep:70, loss:0.00004, loss_test:0.04930, lr:4.95e-03, fs:0.92035 (r=0.963,p=0.881),  time:14.215, tt:1009.291\n",
      "Ep:71, loss:0.00004, loss_test:0.05030, lr:4.90e-03, fs:0.92857 (r=0.963,p=0.897),  time:14.193, tt:1021.918\n",
      "Ep:72, loss:0.00004, loss_test:0.04838, lr:4.85e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.181, tt:1035.204\n",
      "Ep:73, loss:0.00004, loss_test:0.04490, lr:4.80e-03, fs:0.92982 (r=0.981,p=0.883),  time:14.165, tt:1048.214\n",
      "Ep:74, loss:0.00004, loss_test:0.04626, lr:4.75e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.151, tt:1061.329\n",
      "Ep:75, loss:0.00003, loss_test:0.04372, lr:4.71e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.139, tt:1074.552\n",
      "Ep:76, loss:0.00004, loss_test:0.04565, lr:4.66e-03, fs:0.90598 (r=0.981,p=0.841),  time:14.125, tt:1087.603\n",
      "Ep:77, loss:0.00003, loss_test:0.04445, lr:4.57e-03, fs:0.92174 (r=0.981,p=0.869),  time:14.111, tt:1100.675\n",
      "Ep:78, loss:0.00003, loss_test:0.04428, lr:4.48e-03, fs:0.95413 (r=0.963,p=0.945),  time:14.099, tt:1113.806\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00003, loss_test:0.04145, lr:4.43e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.082, tt:1126.588\n",
      "Ep:80, loss:0.00003, loss_test:0.04312, lr:4.39e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.078, tt:1140.332\n",
      "Ep:81, loss:0.00003, loss_test:0.04344, lr:4.34e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.067, tt:1153.455\n",
      "Ep:82, loss:0.00003, loss_test:0.04209, lr:4.30e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.055, tt:1166.554\n",
      "Ep:83, loss:0.00003, loss_test:0.04112, lr:4.26e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.044, tt:1179.713\n",
      "Ep:84, loss:0.00003, loss_test:0.04169, lr:4.21e-03, fs:0.95413 (r=0.963,p=0.945),  time:14.034, tt:1192.893\n",
      "Ep:85, loss:0.00003, loss_test:0.04121, lr:4.17e-03, fs:0.93694 (r=0.963,p=0.912),  time:14.022, tt:1205.910\n",
      "Ep:86, loss:0.00003, loss_test:0.03853, lr:4.13e-03, fs:0.95413 (r=0.963,p=0.945),  time:14.013, tt:1219.156\n",
      "Ep:87, loss:0.00002, loss_test:0.03968, lr:4.09e-03, fs:0.94545 (r=0.963,p=0.929),  time:14.002, tt:1232.134\n",
      "Ep:88, loss:0.00003, loss_test:0.04118, lr:4.05e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.995, tt:1245.556\n",
      "Ep:89, loss:0.00002, loss_test:0.03810, lr:4.01e-03, fs:0.94545 (r=0.963,p=0.929),  time:13.986, tt:1258.785\n",
      "Ep:90, loss:0.00002, loss_test:0.04058, lr:3.93e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.983, tt:1272.480\n",
      "Ep:91, loss:0.00002, loss_test:0.03910, lr:3.85e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.971, tt:1285.316\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.03670, lr:3.81e-03, fs:0.93805 (r=0.981,p=0.898),  time:13.959, tt:1298.154\n",
      "Ep:93, loss:0.00002, loss_test:0.03939, lr:3.77e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.949, tt:1311.230\n",
      "Ep:94, loss:0.00002, loss_test:0.03979, lr:3.73e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.941, tt:1324.395\n",
      "Ep:95, loss:0.00002, loss_test:0.03767, lr:3.70e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.932, tt:1337.426\n",
      "Ep:96, loss:0.00002, loss_test:0.03742, lr:3.66e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.922, tt:1350.439\n",
      "Ep:97, loss:0.00002, loss_test:0.03846, lr:3.62e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.914, tt:1363.531\n",
      "Ep:98, loss:0.00002, loss_test:0.03658, lr:3.59e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.904, tt:1376.460\n",
      "Ep:99, loss:0.00002, loss_test:0.03663, lr:3.55e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.892, tt:1389.178\n",
      "Ep:100, loss:0.00002, loss_test:0.03559, lr:3.52e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.885, tt:1402.401\n",
      "Ep:101, loss:0.00002, loss_test:0.03575, lr:3.48e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.873, tt:1415.011\n",
      "Ep:102, loss:0.00002, loss_test:0.03555, lr:3.45e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.865, tt:1428.059\n",
      "Ep:103, loss:0.00002, loss_test:0.03594, lr:3.38e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.856, tt:1441.025\n",
      "Ep:104, loss:0.00002, loss_test:0.03588, lr:3.31e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.846, tt:1453.839\n",
      "Ep:105, loss:0.00002, loss_test:0.03475, lr:3.24e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.837, tt:1466.671\n",
      "Ep:106, loss:0.00001, loss_test:0.03472, lr:3.18e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.829, tt:1479.695\n",
      "Ep:107, loss:0.00001, loss_test:0.03566, lr:3.12e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.820, tt:1492.510\n",
      "Ep:108, loss:0.00002, loss_test:0.03425, lr:3.05e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.814, tt:1505.698\n",
      "Ep:109, loss:0.00002, loss_test:0.03574, lr:2.99e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.808, tt:1518.868\n",
      "Ep:110, loss:0.00001, loss_test:0.03585, lr:2.93e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.803, tt:1532.173\n",
      "Ep:111, loss:0.00001, loss_test:0.03400, lr:2.88e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.797, tt:1545.277\n",
      "Ep:112, loss:0.00001, loss_test:0.03544, lr:2.82e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.790, tt:1558.240\n",
      "Ep:113, loss:0.00001, loss_test:0.03538, lr:2.76e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.783, tt:1571.241\n",
      "Ep:114, loss:0.00001, loss_test:0.03339, lr:2.71e-03, fs:0.95413 (r=0.963,p=0.945),  time:13.773, tt:1583.950\n",
      "Ep:115, loss:0.00001, loss_test:0.03500, lr:2.65e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.766, tt:1596.845\n",
      "Ep:116, loss:0.00001, loss_test:0.03472, lr:2.60e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.758, tt:1609.667\n",
      "Ep:117, loss:0.00001, loss_test:0.03363, lr:2.55e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.753, tt:1622.807\n",
      "Ep:118, loss:0.00001, loss_test:0.03255, lr:2.50e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.747, tt:1635.918\n",
      "Ep:119, loss:0.00001, loss_test:0.03430, lr:2.45e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.743, tt:1649.127\n",
      "Ep:120, loss:0.00001, loss_test:0.03402, lr:2.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.738, tt:1662.315\n",
      "Ep:121, loss:0.00001, loss_test:0.03263, lr:2.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.731, tt:1675.187\n",
      "Ep:122, loss:0.00001, loss_test:0.03153, lr:2.31e-03, fs:0.96296 (r=0.963,p=0.963),  time:13.723, tt:1687.956\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,123,\"10-10\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.23945, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:11.854, tt:11.854\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23615, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:12.185, tt:24.370\n",
      "Ep:2, loss:0.00058, loss_test:0.22993, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:12.988, tt:38.964\n",
      "Ep:3, loss:0.00055, loss_test:0.21838, lr:8.00e-03, fs:0.66441 (r=0.990,p=0.500),  time:13.621, tt:54.482\n",
      "Ep:4, loss:0.00047, loss_test:0.19989, lr:8.00e-03, fs:0.66901 (r=0.960,p=0.514),  time:15.222, tt:76.110\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.19004, lr:8.00e-03, fs:0.69531 (r=0.899,p=0.567),  time:17.478, tt:104.868\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.18966, lr:8.00e-03, fs:0.69672 (r=0.859,p=0.586),  time:18.960, tt:132.721\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.18857, lr:8.00e-03, fs:0.69828 (r=0.818,p=0.609),  time:21.535, tt:172.282\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.18223, lr:8.00e-03, fs:0.70386 (r=0.828,p=0.612),  time:23.498, tt:211.484\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.17876, lr:8.00e-03, fs:0.70175 (r=0.808,p=0.620),  time:25.127, tt:251.269\n",
      "Ep:10, loss:0.00029, loss_test:0.17758, lr:8.00e-03, fs:0.71681 (r=0.818,p=0.638),  time:26.265, tt:288.916\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.17074, lr:8.00e-03, fs:0.72174 (r=0.838,p=0.634),  time:27.526, tt:330.314\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.16765, lr:8.00e-03, fs:0.70852 (r=0.798,p=0.637),  time:28.618, tt:372.031\n",
      "Ep:13, loss:0.00027, loss_test:0.16277, lr:8.00e-03, fs:0.73820 (r=0.869,p=0.642),  time:29.520, tt:413.283\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00026, loss_test:0.15767, lr:8.00e-03, fs:0.75000 (r=0.879,p=0.654),  time:30.316, tt:454.741\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.15639, lr:8.00e-03, fs:0.74439 (r=0.838,p=0.669),  time:30.834, tt:493.339\n",
      "Ep:16, loss:0.00025, loss_test:0.15640, lr:8.00e-03, fs:0.75536 (r=0.889,p=0.657),  time:31.188, tt:530.194\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.15204, lr:8.00e-03, fs:0.75439 (r=0.869,p=0.667),  time:31.638, tt:569.487\n",
      "Ep:18, loss:0.00023, loss_test:0.14859, lr:8.00e-03, fs:0.76106 (r=0.869,p=0.677),  time:31.885, tt:605.815\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.14374, lr:8.00e-03, fs:0.78151 (r=0.939,p=0.669),  time:31.994, tt:639.887\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.14477, lr:8.00e-03, fs:0.76233 (r=0.859,p=0.685),  time:32.345, tt:679.255\n",
      "Ep:21, loss:0.00022, loss_test:0.13851, lr:8.00e-03, fs:0.79111 (r=0.899,p=0.706),  time:32.741, tt:720.309\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.13401, lr:8.00e-03, fs:0.78112 (r=0.919,p=0.679),  time:33.089, tt:761.050\n",
      "Ep:23, loss:0.00021, loss_test:0.13916, lr:8.00e-03, fs:0.77391 (r=0.899,p=0.679),  time:33.380, tt:801.110\n",
      "Ep:24, loss:0.00020, loss_test:0.13406, lr:8.00e-03, fs:0.81416 (r=0.929,p=0.724),  time:33.617, tt:840.425\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00020, loss_test:0.12803, lr:8.00e-03, fs:0.79487 (r=0.939,p=0.689),  time:33.763, tt:877.826\n",
      "Ep:26, loss:0.00019, loss_test:0.12506, lr:8.00e-03, fs:0.82819 (r=0.949,p=0.734),  time:33.868, tt:914.425\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.12324, lr:8.00e-03, fs:0.79832 (r=0.960,p=0.683),  time:33.924, tt:949.860\n",
      "Ep:28, loss:0.00018, loss_test:0.12100, lr:8.00e-03, fs:0.81938 (r=0.939,p=0.727),  time:34.055, tt:987.595\n",
      "Ep:29, loss:0.00017, loss_test:0.11568, lr:8.00e-03, fs:0.81223 (r=0.939,p=0.715),  time:34.127, tt:1023.825\n",
      "Ep:30, loss:0.00017, loss_test:0.11936, lr:8.00e-03, fs:0.79167 (r=0.960,p=0.674),  time:34.336, tt:1064.420\n",
      "Ep:31, loss:0.00017, loss_test:0.11857, lr:8.00e-03, fs:0.89756 (r=0.929,p=0.868),  time:34.493, tt:1103.772\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00017, loss_test:0.11534, lr:8.00e-03, fs:0.80000 (r=0.970,p=0.681),  time:34.631, tt:1142.821\n",
      "Ep:33, loss:0.00016, loss_test:0.11810, lr:8.00e-03, fs:0.81545 (r=0.960,p=0.709),  time:34.740, tt:1181.165\n",
      "Ep:34, loss:0.00015, loss_test:0.11257, lr:8.00e-03, fs:0.81739 (r=0.949,p=0.718),  time:34.779, tt:1217.259\n",
      "Ep:35, loss:0.00015, loss_test:0.11216, lr:8.00e-03, fs:0.88263 (r=0.949,p=0.825),  time:34.836, tt:1254.082\n",
      "Ep:36, loss:0.00014, loss_test:0.11179, lr:8.00e-03, fs:0.87273 (r=0.970,p=0.793),  time:34.909, tt:1291.622\n",
      "Ep:37, loss:0.00014, loss_test:0.10857, lr:8.00e-03, fs:0.88995 (r=0.939,p=0.845),  time:34.988, tt:1329.549\n",
      "Ep:38, loss:0.00013, loss_test:0.10348, lr:8.00e-03, fs:0.86239 (r=0.949,p=0.790),  time:35.064, tt:1367.513\n",
      "Ep:39, loss:0.00013, loss_test:0.09687, lr:8.00e-03, fs:0.84071 (r=0.960,p=0.748),  time:35.144, tt:1405.756\n",
      "Ep:40, loss:0.00013, loss_test:0.10334, lr:8.00e-03, fs:0.90476 (r=0.960,p=0.856),  time:35.318, tt:1448.043\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00013, loss_test:0.12308, lr:8.00e-03, fs:0.86869 (r=0.869,p=0.869),  time:35.463, tt:1489.440\n",
      "Ep:42, loss:0.00012, loss_test:0.10677, lr:8.00e-03, fs:0.77165 (r=0.990,p=0.632),  time:35.583, tt:1530.075\n",
      "Ep:43, loss:0.00013, loss_test:0.10264, lr:8.00e-03, fs:0.89720 (r=0.970,p=0.835),  time:35.669, tt:1569.454\n",
      "Ep:44, loss:0.00012, loss_test:0.10490, lr:8.00e-03, fs:0.87324 (r=0.939,p=0.816),  time:35.714, tt:1607.122\n",
      "Ep:45, loss:0.00011, loss_test:0.11950, lr:8.00e-03, fs:0.82857 (r=0.879,p=0.784),  time:35.738, tt:1643.942\n",
      "Ep:46, loss:0.00013, loss_test:0.09922, lr:8.00e-03, fs:0.88571 (r=0.939,p=0.838),  time:35.816, tt:1683.342\n",
      "Ep:47, loss:0.00011, loss_test:0.09759, lr:8.00e-03, fs:0.88584 (r=0.980,p=0.808),  time:35.880, tt:1722.264\n",
      "Ep:48, loss:0.00010, loss_test:0.09340, lr:8.00e-03, fs:0.87273 (r=0.970,p=0.793),  time:35.962, tt:1762.132\n",
      "Ep:49, loss:0.00010, loss_test:0.09762, lr:8.00e-03, fs:0.86996 (r=0.980,p=0.782),  time:36.049, tt:1802.430\n",
      "Ep:50, loss:0.00011, loss_test:0.10786, lr:8.00e-03, fs:0.77291 (r=0.980,p=0.638),  time:36.204, tt:1846.413\n",
      "Ep:51, loss:0.00015, loss_test:0.10701, lr:8.00e-03, fs:0.83761 (r=0.990,p=0.726),  time:36.343, tt:1889.813\n",
      "Ep:52, loss:0.00015, loss_test:0.11139, lr:8.00e-03, fs:0.83621 (r=0.980,p=0.729),  time:36.470, tt:1932.912\n",
      "Ep:53, loss:0.00014, loss_test:0.10470, lr:8.00e-03, fs:0.90640 (r=0.929,p=0.885),  time:36.587, tt:1975.690\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00013, loss_test:0.10864, lr:8.00e-03, fs:0.82403 (r=0.970,p=0.716),  time:36.670, tt:2016.851\n",
      "Ep:55, loss:0.00014, loss_test:0.09255, lr:8.00e-03, fs:0.83761 (r=0.990,p=0.726),  time:36.734, tt:2057.090\n",
      "Ep:56, loss:0.00012, loss_test:0.10166, lr:8.00e-03, fs:0.82969 (r=0.960,p=0.731),  time:36.797, tt:2097.436\n",
      "Ep:57, loss:0.00011, loss_test:0.12226, lr:8.00e-03, fs:0.72263 (r=1.000,p=0.566),  time:36.882, tt:2139.135\n",
      "Ep:58, loss:0.00021, loss_test:0.13241, lr:8.00e-03, fs:0.76078 (r=0.980,p=0.622),  time:36.954, tt:2180.290\n",
      "Ep:59, loss:0.00022, loss_test:0.14586, lr:8.00e-03, fs:0.74803 (r=0.960,p=0.613),  time:37.038, tt:2222.305\n",
      "Ep:60, loss:0.00022, loss_test:0.14131, lr:8.00e-03, fs:0.81416 (r=0.929,p=0.724),  time:37.174, tt:2267.601\n",
      "Ep:61, loss:0.00018, loss_test:0.13027, lr:8.00e-03, fs:0.79476 (r=0.919,p=0.700),  time:37.311, tt:2313.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00017, loss_test:0.12595, lr:8.00e-03, fs:0.81739 (r=0.949,p=0.718),  time:37.467, tt:2360.412\n",
      "Ep:63, loss:0.00016, loss_test:0.10623, lr:8.00e-03, fs:0.84404 (r=0.929,p=0.773),  time:37.523, tt:2401.459\n",
      "Ep:64, loss:0.00015, loss_test:0.13795, lr:8.00e-03, fs:0.77477 (r=0.869,p=0.699),  time:37.589, tt:2443.271\n",
      "Ep:65, loss:0.00019, loss_test:0.11857, lr:8.00e-03, fs:0.79167 (r=0.960,p=0.674),  time:37.633, tt:2483.766\n",
      "Ep:66, loss:0.00016, loss_test:0.10469, lr:8.00e-03, fs:0.84685 (r=0.949,p=0.764),  time:37.709, tt:2526.481\n",
      "Ep:67, loss:0.00014, loss_test:0.09385, lr:7.92e-03, fs:0.88263 (r=0.949,p=0.825),  time:37.751, tt:2567.048\n",
      "Ep:68, loss:0.00015, loss_test:0.12445, lr:7.84e-03, fs:0.75969 (r=0.990,p=0.616),  time:37.791, tt:2607.550\n",
      "Ep:69, loss:0.00017, loss_test:0.13404, lr:7.76e-03, fs:0.71739 (r=1.000,p=0.559),  time:37.858, tt:2650.051\n",
      "Ep:70, loss:0.00032, loss_test:0.13442, lr:7.68e-03, fs:0.73408 (r=0.990,p=0.583),  time:37.948, tt:2694.342\n",
      "Ep:71, loss:0.00029, loss_test:0.13909, lr:7.61e-03, fs:0.78689 (r=0.970,p=0.662),  time:38.082, tt:2741.901\n",
      "Ep:72, loss:0.00023, loss_test:0.13323, lr:7.53e-03, fs:0.80162 (r=1.000,p=0.669),  time:38.180, tt:2787.108\n",
      "Ep:73, loss:0.00024, loss_test:0.14492, lr:7.46e-03, fs:0.78414 (r=0.899,p=0.695),  time:38.242, tt:2829.896\n",
      "Ep:74, loss:0.00021, loss_test:0.11494, lr:7.38e-03, fs:0.80851 (r=0.960,p=0.699),  time:38.279, tt:2870.959\n",
      "Ep:75, loss:0.00019, loss_test:0.11591, lr:7.31e-03, fs:0.81013 (r=0.970,p=0.696),  time:38.332, tt:2913.257\n",
      "Ep:76, loss:0.00018, loss_test:0.11173, lr:7.24e-03, fs:0.84018 (r=0.929,p=0.767),  time:38.382, tt:2955.377\n",
      "Ep:77, loss:0.00017, loss_test:0.11938, lr:7.16e-03, fs:0.81739 (r=0.949,p=0.718),  time:38.411, tt:2996.043\n",
      "Ep:78, loss:0.00020, loss_test:0.12794, lr:7.09e-03, fs:0.74157 (r=1.000,p=0.589),  time:38.442, tt:3036.941\n",
      "Ep:79, loss:0.00027, loss_test:0.12913, lr:7.02e-03, fs:0.76265 (r=0.990,p=0.620),  time:38.517, tt:3081.378\n",
      "Ep:80, loss:0.00021, loss_test:0.13503, lr:6.95e-03, fs:0.78008 (r=0.949,p=0.662),  time:38.565, tt:3123.754\n",
      "Ep:81, loss:0.00020, loss_test:0.13131, lr:6.88e-03, fs:0.82096 (r=0.949,p=0.723),  time:38.657, tt:3169.909\n",
      "Ep:82, loss:0.00018, loss_test:0.12528, lr:6.81e-03, fs:0.84956 (r=0.970,p=0.756),  time:38.742, tt:3215.592\n",
      "Ep:83, loss:0.00017, loss_test:0.12019, lr:6.74e-03, fs:0.84071 (r=0.960,p=0.748),  time:38.764, tt:3256.183\n",
      "Ep:84, loss:0.00016, loss_test:0.11358, lr:6.68e-03, fs:0.81481 (r=1.000,p=0.688),  time:38.784, tt:3296.678\n",
      "Ep:85, loss:0.00016, loss_test:0.13463, lr:6.61e-03, fs:0.83871 (r=0.919,p=0.771),  time:38.794, tt:3336.273\n",
      "Ep:86, loss:0.00015, loss_test:0.10706, lr:6.54e-03, fs:0.84071 (r=0.960,p=0.748),  time:38.796, tt:3375.245\n",
      "Ep:87, loss:0.00015, loss_test:0.12537, lr:6.48e-03, fs:0.85321 (r=0.939,p=0.782),  time:38.815, tt:3415.691\n",
      "Ep:88, loss:0.00012, loss_test:0.10182, lr:6.41e-03, fs:0.84211 (r=0.970,p=0.744),  time:38.830, tt:3455.910\n",
      "Ep:89, loss:0.00013, loss_test:0.13196, lr:6.35e-03, fs:0.82353 (r=0.919,p=0.746),  time:38.888, tt:3499.913\n",
      "Ep:90, loss:0.00011, loss_test:0.11953, lr:6.29e-03, fs:0.78378 (r=0.879,p=0.707),  time:38.968, tt:3546.113\n",
      "Ep:91, loss:0.00011, loss_test:0.09485, lr:6.22e-03, fs:0.85845 (r=0.949,p=0.783),  time:39.019, tt:3589.713\n",
      "Ep:92, loss:0.00010, loss_test:0.11442, lr:6.16e-03, fs:0.82143 (r=0.929,p=0.736),  time:39.052, tt:3631.876\n",
      "Ep:93, loss:0.00011, loss_test:0.14237, lr:6.10e-03, fs:0.75829 (r=0.808,p=0.714),  time:39.083, tt:3673.767\n",
      "Ep:94, loss:0.00011, loss_test:0.10257, lr:6.04e-03, fs:0.81481 (r=0.889,p=0.752),  time:39.127, tt:3717.067\n",
      "Ep:95, loss:0.00010, loss_test:0.09574, lr:5.98e-03, fs:0.84932 (r=0.939,p=0.775),  time:39.153, tt:3758.662\n",
      "Ep:96, loss:0.00010, loss_test:0.12895, lr:5.92e-03, fs:0.82629 (r=0.889,p=0.772),  time:39.157, tt:3798.228\n",
      "Ep:97, loss:0.00010, loss_test:0.09235, lr:5.86e-03, fs:0.84979 (r=1.000,p=0.739),  time:39.158, tt:3837.471\n",
      "Ep:98, loss:0.00011, loss_test:0.14546, lr:5.86e-03, fs:0.71910 (r=0.970,p=0.571),  time:39.159, tt:3876.738\n",
      "Ep:99, loss:0.00017, loss_test:0.12731, lr:5.86e-03, fs:0.78970 (r=0.929,p=0.687),  time:39.212, tt:3921.173\n",
      "Ep:100, loss:0.00013, loss_test:0.09944, lr:5.86e-03, fs:0.84545 (r=0.939,p=0.769),  time:39.256, tt:3964.880\n",
      "Ep:101, loss:0.00016, loss_test:0.13507, lr:5.86e-03, fs:0.77108 (r=0.970,p=0.640),  time:39.308, tt:4009.463\n",
      "Ep:102, loss:0.00018, loss_test:0.11437, lr:5.86e-03, fs:0.85965 (r=0.990,p=0.760),  time:39.346, tt:4052.678\n",
      "Ep:103, loss:0.00014, loss_test:0.13697, lr:5.86e-03, fs:0.78378 (r=0.879,p=0.707),  time:39.357, tt:4093.110\n",
      "Ep:104, loss:0.00014, loss_test:0.11045, lr:5.86e-03, fs:0.82969 (r=0.960,p=0.731),  time:39.371, tt:4133.993\n",
      "Ep:105, loss:0.00011, loss_test:0.11168, lr:5.86e-03, fs:0.84821 (r=0.960,p=0.760),  time:39.388, tt:4175.128\n",
      "Ep:106, loss:0.00011, loss_test:0.11974, lr:5.86e-03, fs:0.81197 (r=0.960,p=0.704),  time:39.410, tt:4216.869\n",
      "Ep:107, loss:0.00010, loss_test:0.09390, lr:5.86e-03, fs:0.86222 (r=0.980,p=0.770),  time:39.418, tt:4257.184\n",
      "Ep:108, loss:0.00009, loss_test:0.11653, lr:5.86e-03, fs:0.80543 (r=0.899,p=0.730),  time:39.426, tt:4297.426\n",
      "Ep:109, loss:0.00009, loss_test:0.10859, lr:5.80e-03, fs:0.80365 (r=0.889,p=0.733),  time:39.478, tt:4342.608\n",
      "Ep:110, loss:0.00010, loss_test:0.08806, lr:5.74e-03, fs:0.86087 (r=1.000,p=0.756),  time:39.507, tt:4385.305\n",
      "Ep:111, loss:0.00010, loss_test:0.09870, lr:5.74e-03, fs:0.81308 (r=0.879,p=0.757),  time:39.537, tt:4428.187\n",
      "Ep:112, loss:0.00009, loss_test:0.10759, lr:5.74e-03, fs:0.81481 (r=0.889,p=0.752),  time:39.556, tt:4469.815\n",
      "Ep:113, loss:0.00008, loss_test:0.08227, lr:5.74e-03, fs:0.88000 (r=1.000,p=0.786),  time:39.564, tt:4510.351\n",
      "Ep:114, loss:0.00008, loss_test:0.11507, lr:5.74e-03, fs:0.79808 (r=0.838,p=0.761),  time:39.577, tt:4551.321\n",
      "Ep:115, loss:0.00007, loss_test:0.09795, lr:5.74e-03, fs:0.84615 (r=0.889,p=0.807),  time:39.572, tt:4590.389\n",
      "Ep:116, loss:0.00006, loss_test:0.09161, lr:5.74e-03, fs:0.85167 (r=0.899,p=0.809),  time:39.578, tt:4630.587\n",
      "Ep:117, loss:0.00007, loss_test:0.12031, lr:5.74e-03, fs:0.81340 (r=0.859,p=0.773),  time:39.572, tt:4669.518\n",
      "Ep:118, loss:0.00006, loss_test:0.10535, lr:5.74e-03, fs:0.80769 (r=0.848,p=0.771),  time:39.603, tt:4712.813\n",
      "Ep:119, loss:0.00006, loss_test:0.10970, lr:5.74e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.626, tt:4755.157\n",
      "Ep:120, loss:0.00006, loss_test:0.11299, lr:5.74e-03, fs:0.79000 (r=0.798,p=0.782),  time:39.657, tt:4798.513\n",
      "Ep:121, loss:0.00005, loss_test:0.10962, lr:5.74e-03, fs:0.82524 (r=0.859,p=0.794),  time:39.686, tt:4841.680\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-355502d63c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_rebuild_tensor_v2\u001b[0;34m(storage, storage_offset, size, stride, requires_grad, backward_hooks)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_rebuild_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,122,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09163, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.285, tt:37.285\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.08850, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:50.480, tt:100.960\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00035, loss_test:0.08262, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:56.349, tt:169.047\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00033, loss_test:0.07466, lr:1.00e-02, fs:0.69597 (r=0.960,p=0.546),  time:60.376, tt:241.503\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07107, lr:1.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:63.261, tt:316.305\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00031, loss_test:0.06935, lr:1.00e-02, fs:0.69630 (r=0.949,p=0.550),  time:64.866, tt:389.194\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00030, loss_test:0.06698, lr:1.00e-02, fs:0.70849 (r=0.970,p=0.558),  time:65.679, tt:459.755\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.06460, lr:1.00e-02, fs:0.73563 (r=0.970,p=0.593),  time:66.997, tt:535.976\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00028, loss_test:0.06373, lr:1.00e-02, fs:0.72593 (r=0.990,p=0.573),  time:68.601, tt:617.413\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00027, loss_test:0.06193, lr:1.00e-02, fs:0.73208 (r=0.980,p=0.584),  time:69.702, tt:697.015\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00026, loss_test:0.06081, lr:1.00e-02, fs:0.73563 (r=0.970,p=0.593),  time:70.447, tt:774.919\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00025, loss_test:0.06005, lr:1.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:71.102, tt:853.218\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00024, loss_test:0.05902, lr:1.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:71.556, tt:930.227\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00024, loss_test:0.05772, lr:1.00e-02, fs:0.75676 (r=0.990,p=0.613),  time:71.605, tt:1002.474\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00023, loss_test:0.05787, lr:1.00e-02, fs:0.75096 (r=0.990,p=0.605),  time:71.529, tt:1072.941\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00022, loss_test:0.05576, lr:1.00e-02, fs:0.76078 (r=0.980,p=0.622),  time:71.593, tt:1145.488\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00022, loss_test:0.05549, lr:1.00e-02, fs:0.75676 (r=0.990,p=0.613),  time:71.845, tt:1221.368\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00021, loss_test:0.05484, lr:1.00e-02, fs:0.76265 (r=0.990,p=0.620),  time:72.307, tt:1301.526\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.05293, lr:1.00e-02, fs:0.77291 (r=0.980,p=0.638),  time:72.541, tt:1378.279\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.05298, lr:1.00e-02, fs:0.75969 (r=0.990,p=0.616),  time:72.793, tt:1455.851\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.05219, lr:1.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:73.037, tt:1533.782\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00019, loss_test:0.05120, lr:1.00e-02, fs:0.76378 (r=0.980,p=0.626),  time:73.313, tt:1612.896\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00018, loss_test:0.05034, lr:1.00e-02, fs:0.78543 (r=0.980,p=0.655),  time:73.374, tt:1687.610\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.05005, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:73.302, tt:1759.251\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00017, loss_test:0.04915, lr:1.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:73.281, tt:1832.028\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.04876, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:73.288, tt:1905.498\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00016, loss_test:0.04736, lr:1.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:73.538, tt:1985.513\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00016, loss_test:0.04790, lr:1.00e-02, fs:0.79668 (r=0.970,p=0.676),  time:73.712, tt:2063.931\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00015, loss_test:0.04630, lr:1.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:73.924, tt:2143.781\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.04602, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:74.118, tt:2223.550\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.04522, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:74.264, tt:2302.198\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00014, loss_test:0.04563, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:74.483, tt:2383.443\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.04421, lr:1.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:74.427, tt:2456.081\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00013, loss_test:0.04393, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:74.392, tt:2529.342\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.04372, lr:1.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:74.356, tt:2602.465\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.04321, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:74.396, tt:2678.264\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.04342, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:74.484, tt:2755.900\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.04212, lr:1.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:74.598, tt:2834.741\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.04290, lr:1.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:74.700, tt:2913.306\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.04162, lr:1.00e-02, fs:0.82700 (r=0.990,p=0.710),  time:74.796, tt:2991.859\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.04113, lr:1.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:74.897, tt:3070.797\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.04179, lr:1.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:74.911, tt:3146.270\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.04075, lr:1.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:74.864, tt:3219.166\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.04108, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:74.849, tt:3293.369\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.04010, lr:1.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:74.801, tt:3366.027\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.04053, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:74.888, tt:3444.826\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.03989, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:74.982, tt:3524.135\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.04028, lr:1.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:75.011, tt:3600.507\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.03973, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:75.097, tt:3679.748\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.03969, lr:1.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:75.161, tt:3758.043\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.03917, lr:1.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:75.231, tt:3836.770\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.03968, lr:1.00e-02, fs:0.86463 (r=1.000,p=0.762),  time:75.178, tt:3909.259\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.03913, lr:1.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:75.112, tt:3980.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.03837, lr:1.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:75.054, tt:4052.937\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.04015, lr:1.00e-02, fs:0.86087 (r=1.000,p=0.756),  time:75.050, tt:4127.743\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.03862, lr:1.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:75.141, tt:4207.897\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.03846, lr:1.00e-02, fs:0.88000 (r=1.000,p=0.786),  time:75.213, tt:4287.113\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.03870, lr:1.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:75.288, tt:4366.694\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.03806, lr:1.00e-02, fs:0.88000 (r=1.000,p=0.786),  time:75.386, tt:4447.769\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.03913, lr:1.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:75.403, tt:4524.182\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.03852, lr:1.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:75.378, tt:4598.064\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.03972, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:75.354, tt:4671.923\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.03899, lr:1.00e-02, fs:0.88393 (r=1.000,p=0.792),  time:75.325, tt:4745.498\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.03827, lr:1.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:75.294, tt:4818.789\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.03919, lr:1.00e-02, fs:0.87225 (r=1.000,p=0.773),  time:75.372, tt:4899.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.03789, lr:1.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:75.418, tt:4977.559\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.03833, lr:1.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:75.504, tt:5058.779\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.03841, lr:1.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:75.583, tt:5139.675\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.03804, lr:1.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:75.621, tt:5217.882\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.03804, lr:1.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:75.643, tt:5294.980\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.03790, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:75.591, tt:5366.989\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.03805, lr:1.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:75.555, tt:5439.991\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.03837, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:75.543, tt:5514.630\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.03771, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:75.581, tt:5592.969\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.03808, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.639, tt:5672.935\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.03788, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:75.715, tt:5754.353\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.03792, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.771, tt:5834.395\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.03867, lr:1.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:75.812, tt:5913.356\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.03787, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.826, tt:5990.281\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.03776, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:75.768, tt:6061.477\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.03839, lr:1.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:75.716, tt:6133.019\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.03854, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:75.671, tt:6204.982\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.03790, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:75.662, tt:6279.922\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.03892, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:75.693, tt:6358.229\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.03890, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:75.724, tt:6436.505\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.03825, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:75.762, tt:6515.500\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.03864, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:75.818, tt:6596.143\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.04019, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:75.885, tt:6677.854\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.03853, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:75.925, tt:6757.301\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.03907, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:75.911, tt:6831.978\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.03921, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:75.893, tt:6906.225\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.03964, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:75.877, tt:6980.712\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.03963, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:75.905, tt:7059.143\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.03984, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:75.944, tt:7138.710\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.03915, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:76.020, tt:7221.854\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.04034, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:76.070, tt:7302.689\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.03984, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:76.127, tt:7384.364\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.04002, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:76.192, tt:7466.768\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.04105, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:76.188, tt:7542.610\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.04043, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:76.175, tt:7617.517\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.04025, lr:9.90e-03, fs:0.89320 (r=0.929,p=0.860),  time:76.167, tt:7692.889\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.04010, lr:9.80e-03, fs:0.88235 (r=0.909,p=0.857),  time:76.146, tt:7766.842\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.04199, lr:9.70e-03, fs:0.90476 (r=0.960,p=0.856),  time:76.180, tt:7846.581\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.04014, lr:9.61e-03, fs:0.86700 (r=0.889,p=0.846),  time:76.220, tt:7926.917\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.04207, lr:9.51e-03, fs:0.88889 (r=0.929,p=0.852),  time:76.261, tt:8007.363\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.04117, lr:9.41e-03, fs:0.89320 (r=0.929,p=0.860),  time:76.277, tt:8085.334\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.04159, lr:9.32e-03, fs:0.87685 (r=0.899,p=0.856),  time:76.297, tt:8163.776\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.04159, lr:9.23e-03, fs:0.88350 (r=0.919,p=0.850),  time:76.335, tt:8244.179\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.04184, lr:9.14e-03, fs:0.88670 (r=0.909,p=0.865),  time:76.302, tt:8316.878\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.04110, lr:9.04e-03, fs:0.86700 (r=0.889,p=0.846),  time:76.267, tt:8389.341\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.04100, lr:8.95e-03, fs:0.88000 (r=0.889,p=0.871),  time:76.250, tt:8463.731\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.04154, lr:8.86e-03, fs:0.89952 (r=0.949,p=0.855),  time:76.238, tt:8538.686\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.04166, lr:8.78e-03, fs:0.87129 (r=0.889,p=0.854),  time:76.268, tt:8618.307\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.04209, lr:8.69e-03, fs:0.87255 (r=0.899,p=0.848),  time:76.302, tt:8698.406\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.04202, lr:8.60e-03, fs:0.88442 (r=0.889,p=0.880),  time:76.313, tt:8775.978\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.04202, lr:8.51e-03, fs:0.87255 (r=0.899,p=0.848),  time:76.335, tt:8854.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.04170, lr:8.43e-03, fs:0.88442 (r=0.889,p=0.880),  time:76.347, tt:8932.588\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.04175, lr:8.35e-03, fs:0.89952 (r=0.949,p=0.855),  time:76.339, tt:9007.983\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.04217, lr:8.26e-03, fs:0.87562 (r=0.889,p=0.863),  time:76.295, tt:9079.086\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.04196, lr:8.18e-03, fs:0.87129 (r=0.889,p=0.854),  time:76.270, tt:9152.456\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.04330, lr:8.10e-03, fs:0.88000 (r=0.889,p=0.871),  time:76.238, tt:9224.738\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09164, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:60.216, tt:60.216\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.08865, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:69.656, tt:139.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00035, loss_test:0.08301, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:73.031, tt:219.093\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00034, loss_test:0.07630, lr:1.00e-02, fs:0.67857 (r=0.960,p=0.525),  time:74.198, tt:296.791\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07346, lr:1.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:74.823, tt:374.117\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00031, loss_test:0.07152, lr:1.00e-02, fs:0.70111 (r=0.960,p=0.552),  time:74.827, tt:448.964\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00030, loss_test:0.06960, lr:1.00e-02, fs:0.70073 (r=0.970,p=0.549),  time:74.274, tt:519.915\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.06609, lr:1.00e-02, fs:0.71642 (r=0.970,p=0.568),  time:74.049, tt:592.394\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00027, loss_test:0.06468, lr:1.00e-02, fs:0.72659 (r=0.980,p=0.577),  time:74.041, tt:666.372\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00026, loss_test:0.06274, lr:1.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:74.684, tt:746.841\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00026, loss_test:0.06051, lr:1.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:75.152, tt:826.671\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00025, loss_test:0.05919, lr:1.00e-02, fs:0.73485 (r=0.980,p=0.588),  time:75.457, tt:905.490\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00024, loss_test:0.05845, lr:1.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:75.900, tt:986.694\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00023, loss_test:0.05798, lr:1.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:76.140, tt:1065.965\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.05681, lr:1.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:76.199, tt:1142.982\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00022, loss_test:0.05528, lr:1.00e-02, fs:0.76378 (r=0.980,p=0.626),  time:75.928, tt:1214.843\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00021, loss_test:0.05499, lr:1.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:75.802, tt:1288.632\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.05427, lr:1.00e-02, fs:0.76562 (r=0.990,p=0.624),  time:75.612, tt:1361.008\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.05311, lr:1.00e-02, fs:0.76863 (r=0.990,p=0.628),  time:75.572, tt:1435.868\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.05272, lr:1.00e-02, fs:0.76265 (r=0.990,p=0.620),  time:75.823, tt:1516.469\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.05182, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:76.019, tt:1596.408\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00019, loss_test:0.05076, lr:1.00e-02, fs:0.77165 (r=0.990,p=0.632),  time:76.156, tt:1675.440\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00018, loss_test:0.05033, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:76.325, tt:1755.475\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00018, loss_test:0.04949, lr:1.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:76.492, tt:1835.814\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00017, loss_test:0.04936, lr:1.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:76.500, tt:1912.492\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.04827, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:76.364, tt:1985.456\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00016, loss_test:0.04889, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:76.384, tt:2062.372\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00016, loss_test:0.04721, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:76.258, tt:2135.222\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00015, loss_test:0.04843, lr:1.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:76.440, tt:2216.773\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00015, loss_test:0.04718, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:76.551, tt:2296.542\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.04633, lr:1.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:76.659, tt:2376.418\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00014, loss_test:0.04724, lr:1.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:76.733, tt:2455.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.04494, lr:1.00e-02, fs:0.81818 (r=1.000,p=0.692),  time:76.763, tt:2533.194\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00013, loss_test:0.04713, lr:1.00e-02, fs:0.83193 (r=1.000,p=0.712),  time:76.832, tt:2612.281\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.04438, lr:1.00e-02, fs:0.82158 (r=1.000,p=0.697),  time:76.677, tt:2683.680\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.04632, lr:1.00e-02, fs:0.83544 (r=1.000,p=0.717),  time:76.588, tt:2757.163\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00012, loss_test:0.04397, lr:1.00e-02, fs:0.83193 (r=1.000,p=0.712),  time:76.487, tt:2830.020\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.04410, lr:1.00e-02, fs:0.84255 (r=1.000,p=0.728),  time:76.397, tt:2903.082\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.04380, lr:1.00e-02, fs:0.84979 (r=1.000,p=0.739),  time:76.454, tt:2981.688\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00011, loss_test:0.04304, lr:1.00e-02, fs:0.85714 (r=1.000,p=0.750),  time:76.513, tt:3060.508\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.04340, lr:1.00e-02, fs:0.83544 (r=1.000,p=0.717),  time:76.587, tt:3140.067\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.04198, lr:1.00e-02, fs:0.86463 (r=1.000,p=0.762),  time:76.671, tt:3220.171\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00010, loss_test:0.04211, lr:1.00e-02, fs:0.85714 (r=1.000,p=0.750),  time:76.713, tt:3298.655\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.04269, lr:1.00e-02, fs:0.85345 (r=1.000,p=0.744),  time:76.719, tt:3375.643\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.04114, lr:1.00e-02, fs:0.86842 (r=1.000,p=0.767),  time:76.619, tt:3447.858\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00009, loss_test:0.04142, lr:1.00e-02, fs:0.85714 (r=1.000,p=0.750),  time:76.512, tt:3519.540\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00009, loss_test:0.04142, lr:1.00e-02, fs:0.87225 (r=1.000,p=0.773),  time:76.401, tt:3590.847\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.04076, lr:1.00e-02, fs:0.85714 (r=1.000,p=0.750),  time:76.445, tt:3669.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.04106, lr:1.00e-02, fs:0.88393 (r=1.000,p=0.792),  time:76.508, tt:3748.870\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.04119, lr:1.00e-02, fs:0.83898 (r=1.000,p=0.723),  time:76.557, tt:3827.835\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.04054, lr:1.00e-02, fs:0.86463 (r=1.000,p=0.762),  time:76.618, tt:3907.499\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.03965, lr:1.00e-02, fs:0.87611 (r=1.000,p=0.780),  time:76.641, tt:3985.313\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.04081, lr:1.00e-02, fs:0.86842 (r=1.000,p=0.767),  time:76.717, tt:4066.000\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.04039, lr:1.00e-02, fs:0.89189 (r=1.000,p=0.805),  time:76.675, tt:4140.460\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.03856, lr:1.00e-02, fs:0.88000 (r=1.000,p=0.786),  time:76.575, tt:4211.630\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.04018, lr:1.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:76.487, tt:4283.271\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.03838, lr:1.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:76.433, tt:4356.660\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.03952, lr:1.00e-02, fs:0.89189 (r=1.000,p=0.805),  time:76.414, tt:4432.007\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.03915, lr:1.00e-02, fs:0.89593 (r=1.000,p=0.811),  time:76.513, tt:4514.286\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.03852, lr:1.00e-02, fs:0.89189 (r=1.000,p=0.805),  time:76.545, tt:4592.678\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.03931, lr:1.00e-02, fs:0.90000 (r=1.000,p=0.818),  time:76.598, tt:4672.505\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.03846, lr:1.00e-02, fs:0.90000 (r=1.000,p=0.818),  time:76.646, tt:4752.028\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.03923, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:76.681, tt:4830.872\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.03843, lr:1.00e-02, fs:0.90000 (r=1.000,p=0.818),  time:76.612, tt:4903.171\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.03972, lr:1.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:76.513, tt:4973.326\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.03738, lr:1.00e-02, fs:0.89189 (r=1.000,p=0.805),  time:76.450, tt:5045.697\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.03933, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:76.476, tt:5123.908\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.03858, lr:1.00e-02, fs:0.88789 (r=1.000,p=0.798),  time:76.535, tt:5204.371\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.03907, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:76.578, tt:5283.898\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.03857, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:76.607, tt:5362.480\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.03875, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:76.615, tt:5439.631\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.03836, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:76.660, tt:5519.498\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.03808, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:76.622, tt:5593.407\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.03928, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:76.606, tt:5668.878\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.03846, lr:1.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:76.562, tt:5742.133\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.03848, lr:1.00e-02, fs:0.89815 (r=0.980,p=0.829),  time:76.563, tt:5818.788\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.03986, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:76.630, tt:5900.503\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.03803, lr:1.00e-02, fs:0.90411 (r=1.000,p=0.825),  time:76.674, tt:5980.606\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.03955, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.732, tt:6061.838\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.03848, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:76.746, tt:6139.709\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.03907, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:76.776, tt:6218.858\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.03891, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:76.803, tt:6297.812\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.03820, lr:1.00e-02, fs:0.89498 (r=0.990,p=0.817),  time:76.769, tt:6371.815\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.03888, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.700, tt:6442.763\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.03942, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.672, tt:6517.122\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.03914, lr:1.00e-02, fs:0.90000 (r=1.000,p=0.818),  time:76.718, tt:6597.725\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.03909, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:76.791, tt:6680.804\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.03924, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:76.790, tt:6757.543\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.03923, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:76.859, tt:6840.446\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.03936, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:76.913, tt:6922.197\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.03848, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:76.969, tt:7004.177\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.03946, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.959, tt:7080.256\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.03842, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:76.930, tt:7154.515\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.03973, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:76.861, tt:7224.924\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.03940, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.839, tt:7299.676\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.03916, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:76.882, tt:7380.648\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.03966, lr:9.90e-03, fs:0.90141 (r=0.970,p=0.842),  time:76.920, tt:7461.199\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.03896, lr:9.80e-03, fs:0.90566 (r=0.970,p=0.850),  time:76.961, tt:7542.214\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.03915, lr:9.70e-03, fs:0.90909 (r=0.960,p=0.864),  time:76.988, tt:7621.817\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.03985, lr:9.61e-03, fs:0.90141 (r=0.970,p=0.842),  time:77.014, tt:7701.420\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.03887, lr:9.51e-03, fs:0.90476 (r=0.960,p=0.856),  time:77.015, tt:7778.522\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.03934, lr:9.41e-03, fs:0.89202 (r=0.960,p=0.833),  time:76.964, tt:7850.329\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.03873, lr:9.32e-03, fs:0.89720 (r=0.970,p=0.835),  time:76.910, tt:7921.775\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.03957, lr:9.23e-03, fs:0.90476 (r=0.960,p=0.856),  time:76.883, tt:7995.839\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.03943, lr:9.14e-03, fs:0.90909 (r=0.960,p=0.864),  time:76.897, tt:8074.210\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.03934, lr:9.04e-03, fs:0.89623 (r=0.960,p=0.841),  time:76.912, tt:8152.668\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.03972, lr:8.95e-03, fs:0.90476 (r=0.960,p=0.856),  time:76.920, tt:8230.447\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.03886, lr:8.86e-03, fs:0.90047 (r=0.960,p=0.848),  time:76.933, tt:8308.775\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.04100, lr:8.78e-03, fs:0.92233 (r=0.960,p=0.888),  time:76.964, tt:8389.054\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.04013, lr:8.78e-03, fs:0.90047 (r=0.960,p=0.848),  time:76.998, tt:8469.765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.03984, lr:8.78e-03, fs:0.90909 (r=0.960,p=0.864),  time:76.953, tt:8541.728\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.04001, lr:8.78e-03, fs:0.92233 (r=0.960,p=0.888),  time:76.910, tt:8613.892\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.04010, lr:8.78e-03, fs:0.90476 (r=0.960,p=0.856),  time:76.855, tt:8684.567\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.03978, lr:8.78e-03, fs:0.91787 (r=0.960,p=0.880),  time:76.854, tt:8761.347\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.03961, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:76.866, tt:8839.535\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.04098, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:76.876, tt:8917.622\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.03960, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:76.893, tt:8996.474\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.03993, lr:8.78e-03, fs:0.90909 (r=0.960,p=0.864),  time:76.886, tt:9072.537\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.04040, lr:8.78e-03, fs:0.90476 (r=0.960,p=0.856),  time:76.900, tt:9151.100\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.03974, lr:8.78e-03, fs:0.90909 (r=0.960,p=0.864),  time:76.875, tt:9225.002\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.03973, lr:8.69e-03, fs:0.90909 (r=0.960,p=0.864),  time:76.801, tt:9292.912\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09429, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.552, tt:62.552\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09174, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:71.149, tt:142.298\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08666, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:74.092, tt:222.277\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08150, lr:1.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:75.152, tt:300.609\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07869, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:76.301, tt:381.506\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.07661, lr:1.00e-02, fs:0.69504 (r=0.990,p=0.536),  time:76.327, tt:457.959\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.07364, lr:1.00e-02, fs:0.69534 (r=0.980,p=0.539),  time:76.159, tt:533.116\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.07058, lr:1.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:75.811, tt:606.490\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.06927, lr:1.00e-02, fs:0.71910 (r=0.970,p=0.571),  time:74.808, tt:673.270\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00026, loss_test:0.06849, lr:1.00e-02, fs:0.71852 (r=0.980,p=0.567),  time:74.389, tt:743.893\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00026, loss_test:0.06751, lr:1.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:74.236, tt:816.594\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00024, loss_test:0.06678, lr:1.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:74.581, tt:894.975\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.06625, lr:1.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:75.025, tt:975.322\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00023, loss_test:0.06533, lr:1.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:75.230, tt:1053.226\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.06466, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:75.474, tt:1132.105\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.06404, lr:1.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:75.749, tt:1211.979\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00021, loss_test:0.06337, lr:1.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:75.896, tt:1290.232\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.06294, lr:1.00e-02, fs:0.73846 (r=0.970,p=0.596),  time:75.577, tt:1360.392\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.06268, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:75.363, tt:1431.895\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.06188, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:75.259, tt:1505.180\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06117, lr:1.00e-02, fs:0.75591 (r=0.970,p=0.619),  time:75.393, tt:1583.248\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.06139, lr:1.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:75.615, tt:1663.520\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06085, lr:1.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:75.897, tt:1745.634\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.06126, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:76.166, tt:1827.989\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.06057, lr:1.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:76.371, tt:1909.278\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.06066, lr:1.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:76.538, tt:1990.001\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.05967, lr:1.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:76.542, tt:2066.630\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.06105, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:76.528, tt:2142.796\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.05977, lr:1.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:76.468, tt:2217.563\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.06003, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:76.388, tt:2291.644\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00013, loss_test:0.05971, lr:1.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:76.488, tt:2371.135\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.05998, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:76.523, tt:2448.739\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.05889, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:76.652, tt:2529.510\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.06082, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:76.732, tt:2608.888\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.05854, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:76.809, tt:2688.317\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.06010, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:76.892, tt:2768.104\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.06063, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:76.803, tt:2841.727\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.05892, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:76.726, tt:2915.578\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.06094, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:76.634, tt:2988.725\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.06015, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:76.673, tt:3066.917\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.06088, lr:9.90e-03, fs:0.76777 (r=0.818,p=0.723),  time:76.687, tt:3144.164\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.06175, lr:9.80e-03, fs:0.77143 (r=0.818,p=0.730),  time:76.743, tt:3223.207\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.06084, lr:9.70e-03, fs:0.77358 (r=0.828,p=0.726),  time:76.786, tt:3301.802\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.06231, lr:9.61e-03, fs:0.77143 (r=0.818,p=0.730),  time:76.820, tt:3380.070\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.06155, lr:9.51e-03, fs:0.78095 (r=0.828,p=0.739),  time:76.864, tt:3458.883\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.06225, lr:9.41e-03, fs:0.77512 (r=0.818,p=0.736),  time:76.839, tt:3534.598\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.06097, lr:9.32e-03, fs:0.77725 (r=0.828,p=0.732),  time:76.729, tt:3606.269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.06159, lr:9.23e-03, fs:0.77512 (r=0.818,p=0.736),  time:76.671, tt:3680.190\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.06346, lr:9.14e-03, fs:0.77295 (r=0.808,p=0.741),  time:76.589, tt:3752.842\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.06036, lr:9.04e-03, fs:0.77885 (r=0.818,p=0.743),  time:76.625, tt:3831.239\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.06368, lr:8.95e-03, fs:0.77451 (r=0.798,p=0.752),  time:76.682, tt:3910.784\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.06121, lr:8.86e-03, fs:0.78095 (r=0.828,p=0.739),  time:76.709, tt:3988.883\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.06141, lr:8.78e-03, fs:0.78261 (r=0.818,p=0.750),  time:76.815, tt:4071.201\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.06332, lr:8.69e-03, fs:0.78261 (r=0.818,p=0.750),  time:76.898, tt:4152.481\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.06203, lr:8.60e-03, fs:0.77885 (r=0.818,p=0.743),  time:76.925, tt:4230.869\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.06219, lr:8.51e-03, fs:0.78846 (r=0.828,p=0.752),  time:76.881, tt:4305.332\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.06177, lr:8.43e-03, fs:0.78846 (r=0.828,p=0.752),  time:76.808, tt:4378.047\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.06318, lr:8.35e-03, fs:0.78641 (r=0.818,p=0.757),  time:76.715, tt:4449.471\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.06140, lr:8.26e-03, fs:0.79227 (r=0.828,p=0.759),  time:76.711, tt:4525.978\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.06339, lr:8.18e-03, fs:0.79412 (r=0.818,p=0.771),  time:76.757, tt:4605.413\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.06223, lr:8.10e-03, fs:0.79227 (r=0.828,p=0.759),  time:76.796, tt:4684.575\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.06341, lr:8.02e-03, fs:0.79024 (r=0.818,p=0.764),  time:76.827, tt:4763.295\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00006, loss_test:0.06202, lr:7.94e-03, fs:0.78641 (r=0.818,p=0.757),  time:76.841, tt:4841.002\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.06364, lr:7.86e-03, fs:0.79024 (r=0.818,p=0.764),  time:76.883, tt:4920.481\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.06153, lr:7.78e-03, fs:0.80193 (r=0.838,p=0.769),  time:76.875, tt:4996.876\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.06305, lr:7.70e-03, fs:0.78818 (r=0.808,p=0.769),  time:76.828, tt:5070.679\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.06210, lr:7.62e-03, fs:0.79024 (r=0.818,p=0.764),  time:76.780, tt:5144.266\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.06290, lr:7.55e-03, fs:0.79024 (r=0.818,p=0.764),  time:76.691, tt:5214.957\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.06120, lr:7.47e-03, fs:0.79024 (r=0.818,p=0.764),  time:76.754, tt:5296.051\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00005, loss_test:0.06222, lr:7.40e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.785, tt:5374.966\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00005, loss_test:0.06434, lr:7.32e-03, fs:0.76768 (r=0.768,p=0.768),  time:76.841, tt:5455.725\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00005, loss_test:0.06080, lr:7.25e-03, fs:0.80583 (r=0.838,p=0.776),  time:76.900, tt:5536.793\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00005, loss_test:0.06350, lr:7.25e-03, fs:0.77387 (r=0.778,p=0.770),  time:76.928, tt:5615.722\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00005, loss_test:0.06287, lr:7.25e-03, fs:0.80597 (r=0.818,p=0.794),  time:76.964, tt:5695.306\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00005, loss_test:0.06371, lr:7.25e-03, fs:0.79000 (r=0.798,p=0.782),  time:76.916, tt:5768.693\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.06350, lr:7.25e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.878, tt:5842.761\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.06314, lr:7.25e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.855, tt:5917.836\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.06381, lr:7.25e-03, fs:0.78788 (r=0.788,p=0.788),  time:76.849, tt:5994.251\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.06356, lr:7.25e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.900, tt:6075.127\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.06317, lr:7.25e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.931, tt:6154.489\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.06341, lr:7.25e-03, fs:0.79000 (r=0.798,p=0.782),  time:76.941, tt:6232.222\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.06284, lr:7.25e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.972, tt:6311.664\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.06414, lr:7.25e-03, fs:0.78392 (r=0.788,p=0.780),  time:77.011, tt:6391.906\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00004, loss_test:0.06403, lr:7.25e-03, fs:0.80597 (r=0.818,p=0.794),  time:77.014, tt:6469.194\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00004, loss_test:0.06357, lr:7.25e-03, fs:0.80597 (r=0.818,p=0.794),  time:76.979, tt:6543.185\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00004, loss_test:0.06348, lr:7.18e-03, fs:0.78788 (r=0.788,p=0.788),  time:76.961, tt:6618.604\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00004, loss_test:0.06363, lr:7.11e-03, fs:0.80597 (r=0.818,p=0.794),  time:76.908, tt:6690.975\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00004, loss_test:0.06264, lr:7.03e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.932, tt:6770.018\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00004, loss_test:0.06478, lr:6.96e-03, fs:0.75000 (r=0.727,p=0.774),  time:76.972, tt:6850.497\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00004, loss_test:0.06301, lr:6.89e-03, fs:0.80597 (r=0.818,p=0.794),  time:77.013, tt:6931.129\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.06401, lr:6.83e-03, fs:0.75000 (r=0.727,p=0.774),  time:77.047, tt:7011.321\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.06340, lr:6.76e-03, fs:0.81000 (r=0.818,p=0.802),  time:77.106, tt:7093.768\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.06329, lr:6.76e-03, fs:0.78788 (r=0.788,p=0.788),  time:77.165, tt:7176.339\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.06327, lr:6.76e-03, fs:0.80597 (r=0.818,p=0.794),  time:77.107, tt:7248.050\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.06398, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:77.085, tt:7323.113\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.06497, lr:6.76e-03, fs:0.74737 (r=0.717,p=0.780),  time:77.044, tt:7396.236\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.06385, lr:6.76e-03, fs:0.77320 (r=0.758,p=0.789),  time:77.033, tt:7472.191\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.06332, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:77.075, tt:7553.363\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.06399, lr:6.76e-03, fs:0.77320 (r=0.758,p=0.789),  time:77.129, tt:7635.746\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.06504, lr:6.76e-03, fs:0.75393 (r=0.727,p=0.783),  time:77.181, tt:7718.068\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.06331, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:77.232, tt:7800.419\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00003, loss_test:0.06504, lr:6.76e-03, fs:0.74737 (r=0.717,p=0.780),  time:77.265, tt:7881.022\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00003, loss_test:0.06427, lr:6.76e-03, fs:0.78571 (r=0.778,p=0.794),  time:77.281, tt:7959.917\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00003, loss_test:0.06580, lr:6.69e-03, fs:0.74074 (r=0.707,p=0.778),  time:77.234, tt:8032.287\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00003, loss_test:0.06602, lr:6.62e-03, fs:0.74866 (r=0.707,p=0.795),  time:77.199, tt:8105.898\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00003, loss_test:0.06367, lr:6.56e-03, fs:0.79602 (r=0.808,p=0.784),  time:77.171, tt:8180.142\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00003, loss_test:0.06569, lr:6.49e-03, fs:0.75132 (r=0.717,p=0.789),  time:77.216, tt:8262.062\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00003, loss_test:0.06434, lr:6.43e-03, fs:0.79397 (r=0.798,p=0.790),  time:77.241, tt:8341.992\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00003, loss_test:0.06561, lr:6.36e-03, fs:0.75132 (r=0.717,p=0.789),  time:77.259, tt:8421.200\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00003, loss_test:0.06460, lr:6.30e-03, fs:0.77949 (r=0.768,p=0.792),  time:77.280, tt:8500.775\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00003, loss_test:0.06442, lr:6.24e-03, fs:0.80597 (r=0.818,p=0.794),  time:77.314, tt:8581.818\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00003, loss_test:0.06661, lr:6.17e-03, fs:0.74866 (r=0.707,p=0.795),  time:77.335, tt:8661.536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00003, loss_test:0.06502, lr:6.11e-03, fs:0.77320 (r=0.758,p=0.789),  time:77.296, tt:8734.412\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00003, loss_test:0.06485, lr:6.05e-03, fs:0.77778 (r=0.778,p=0.778),  time:77.285, tt:8810.495\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00003, loss_test:0.06521, lr:5.99e-03, fs:0.74611 (r=0.727,p=0.766),  time:77.252, tt:8883.927\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00003, loss_test:0.06521, lr:5.93e-03, fs:0.78571 (r=0.778,p=0.794),  time:77.230, tt:8958.654\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.06450, lr:5.87e-03, fs:0.74346 (r=0.717,p=0.772),  time:77.270, tt:9040.580\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00003, loss_test:0.06470, lr:5.81e-03, fs:0.74611 (r=0.727,p=0.766),  time:77.299, tt:9121.264\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00003, loss_test:0.06622, lr:5.75e-03, fs:0.75132 (r=0.717,p=0.789),  time:77.337, tt:9203.067\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00003, loss_test:0.06546, lr:5.70e-03, fs:0.75789 (r=0.727,p=0.791),  time:77.373, tt:9284.706\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00003, loss_test:0.06662, lr:5.64e-03, fs:0.74468 (r=0.707,p=0.787),  time:77.357, tt:9360.169\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09676, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:66.385, tt:66.385\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.09568, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:69.963, tt:139.926\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.09407, lr:1.00e-02, fs:0.63830 (r=0.909,p=0.492),  time:71.737, tt:215.212\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.09455, lr:1.00e-02, fs:0.61776 (r=0.808,p=0.500),  time:73.387, tt:293.548\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.09155, lr:1.00e-02, fs:0.62451 (r=0.798,p=0.513),  time:74.844, tt:374.218\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.08651, lr:1.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:75.720, tt:454.322\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.08379, lr:1.00e-02, fs:0.65169 (r=0.879,p=0.518),  time:76.366, tt:534.561\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.08272, lr:1.00e-02, fs:0.64093 (r=0.838,p=0.519),  time:76.904, tt:615.232\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.08149, lr:1.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:77.348, tt:696.135\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07889, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:77.270, tt:772.698\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07711, lr:1.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:76.925, tt:846.173\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00024, loss_test:0.07599, lr:1.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:76.548, tt:918.580\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.07382, lr:9.90e-03, fs:0.67460 (r=0.859,p=0.556),  time:76.341, tt:992.428\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00023, loss_test:0.07288, lr:9.90e-03, fs:0.69672 (r=0.859,p=0.586),  time:76.764, tt:1074.691\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.07165, lr:9.90e-03, fs:0.70204 (r=0.869,p=0.589),  time:77.057, tt:1155.856\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00022, loss_test:0.06999, lr:9.90e-03, fs:0.70732 (r=0.879,p=0.592),  time:77.435, tt:1238.967\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00021, loss_test:0.06978, lr:9.90e-03, fs:0.70782 (r=0.869,p=0.597),  time:77.732, tt:1321.443\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00020, loss_test:0.06714, lr:9.90e-03, fs:0.71545 (r=0.889,p=0.599),  time:77.960, tt:1403.288\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.06685, lr:9.90e-03, fs:0.73333 (r=0.889,p=0.624),  time:78.055, tt:1483.037\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.06634, lr:9.90e-03, fs:0.74576 (r=0.889,p=0.642),  time:77.807, tt:1556.142\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.06514, lr:9.90e-03, fs:0.73950 (r=0.889,p=0.633),  time:77.608, tt:1629.775\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.06432, lr:9.90e-03, fs:0.75745 (r=0.899,p=0.654),  time:77.417, tt:1703.175\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06410, lr:9.90e-03, fs:0.75424 (r=0.899,p=0.650),  time:77.397, tt:1780.138\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.06259, lr:9.90e-03, fs:0.75424 (r=0.899,p=0.650),  time:77.472, tt:1859.332\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00017, loss_test:0.06277, lr:9.90e-03, fs:0.75745 (r=0.899,p=0.654),  time:77.587, tt:1939.671\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.06220, lr:9.90e-03, fs:0.76724 (r=0.899,p=0.669),  time:77.635, tt:2018.502\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00016, loss_test:0.06130, lr:9.90e-03, fs:0.76395 (r=0.899,p=0.664),  time:77.621, tt:2095.763\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.06069, lr:9.90e-03, fs:0.76068 (r=0.899,p=0.659),  time:77.678, tt:2174.974\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00015, loss_test:0.06059, lr:9.90e-03, fs:0.77193 (r=0.889,p=0.682),  time:77.571, tt:2249.558\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.05924, lr:9.90e-03, fs:0.76724 (r=0.899,p=0.669),  time:77.392, tt:2321.761\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.06061, lr:9.90e-03, fs:0.77477 (r=0.869,p=0.699),  time:77.249, tt:2394.723\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00014, loss_test:0.05807, lr:9.90e-03, fs:0.77876 (r=0.889,p=0.693),  time:77.156, tt:2468.986\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.05966, lr:9.90e-03, fs:0.76147 (r=0.838,p=0.697),  time:77.236, tt:2548.797\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.05879, lr:9.90e-03, fs:0.78222 (r=0.889,p=0.698),  time:77.304, tt:2628.344\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00013, loss_test:0.05817, lr:9.90e-03, fs:0.78539 (r=0.869,p=0.717),  time:77.369, tt:2707.930\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.05749, lr:9.90e-03, fs:0.77626 (r=0.859,p=0.708),  time:77.449, tt:2788.170\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00012, loss_test:0.05744, lr:9.90e-03, fs:0.78704 (r=0.859,p=0.726),  time:77.476, tt:2866.613\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.05744, lr:9.90e-03, fs:0.77358 (r=0.828,p=0.726),  time:77.522, tt:2945.854\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.05825, lr:9.90e-03, fs:0.77358 (r=0.828,p=0.726),  time:77.401, tt:3018.622\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.05648, lr:9.90e-03, fs:0.78505 (r=0.848,p=0.730),  time:77.259, tt:3090.356\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.05667, lr:9.90e-03, fs:0.78302 (r=0.838,p=0.735),  time:77.152, tt:3163.231\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.05792, lr:9.90e-03, fs:0.76699 (r=0.798,p=0.738),  time:77.133, tt:3239.587\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05739, lr:9.90e-03, fs:0.76329 (r=0.798,p=0.731),  time:77.215, tt:3320.264\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.05708, lr:9.90e-03, fs:0.78641 (r=0.818,p=0.757),  time:77.287, tt:3400.611\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.05805, lr:9.90e-03, fs:0.76847 (r=0.788,p=0.750),  time:77.339, tt:3480.237\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00009, loss_test:0.05671, lr:9.90e-03, fs:0.78431 (r=0.808,p=0.762),  time:77.365, tt:3558.777\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00009, loss_test:0.05884, lr:9.90e-03, fs:0.77387 (r=0.778,p=0.770),  time:77.401, tt:3637.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.05645, lr:9.90e-03, fs:0.78431 (r=0.808,p=0.762),  time:77.305, tt:3710.657\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.05806, lr:9.80e-03, fs:0.77000 (r=0.778,p=0.762),  time:77.231, tt:3784.319\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.05742, lr:9.70e-03, fs:0.76617 (r=0.778,p=0.755),  time:77.126, tt:3856.296\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.05719, lr:9.61e-03, fs:0.77612 (r=0.788,p=0.765),  time:77.051, tt:3929.587\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.05831, lr:9.51e-03, fs:0.77551 (r=0.768,p=0.784),  time:77.116, tt:4010.035\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.05908, lr:9.41e-03, fs:0.78351 (r=0.768,p=0.800),  time:77.165, tt:4089.719\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.05841, lr:9.32e-03, fs:0.78351 (r=0.768,p=0.800),  time:77.157, tt:4166.458\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.05699, lr:9.23e-03, fs:0.77157 (r=0.768,p=0.776),  time:77.208, tt:4246.413\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.05977, lr:9.14e-03, fs:0.77157 (r=0.768,p=0.776),  time:77.230, tt:4324.901\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00007, loss_test:0.05649, lr:9.04e-03, fs:0.76382 (r=0.768,p=0.760),  time:77.278, tt:4404.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.05814, lr:8.95e-03, fs:0.78756 (r=0.768,p=0.809),  time:77.228, tt:4479.205\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.05959, lr:8.95e-03, fs:0.77720 (r=0.758,p=0.798),  time:77.120, tt:4550.057\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.05638, lr:8.95e-03, fs:0.78571 (r=0.778,p=0.794),  time:77.026, tt:4621.533\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.05981, lr:8.95e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.974, tt:4695.392\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.05742, lr:8.95e-03, fs:0.76923 (r=0.758,p=0.781),  time:76.997, tt:4773.815\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.05863, lr:8.95e-03, fs:0.78125 (r=0.758,p=0.806),  time:77.037, tt:4853.307\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00006, loss_test:0.05957, lr:8.95e-03, fs:0.77320 (r=0.758,p=0.789),  time:77.044, tt:4930.790\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.05982, lr:8.95e-03, fs:0.78534 (r=0.758,p=0.815),  time:77.069, tt:5009.461\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.05826, lr:8.95e-03, fs:0.78125 (r=0.758,p=0.806),  time:77.071, tt:5086.660\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.06136, lr:8.95e-03, fs:0.78534 (r=0.758,p=0.815),  time:77.012, tt:5159.816\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.05833, lr:8.95e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.906, tt:5229.600\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00005, loss_test:0.05976, lr:8.95e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.823, tt:5300.815\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00005, loss_test:0.06009, lr:8.86e-03, fs:0.78534 (r=0.758,p=0.815),  time:76.754, tt:5372.770\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00005, loss_test:0.06062, lr:8.78e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.725, tt:5447.496\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00005, loss_test:0.05994, lr:8.69e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.718, tt:5523.731\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.05943, lr:8.60e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.760, tt:5603.493\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00005, loss_test:0.06105, lr:8.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:76.766, tt:5680.709\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.05962, lr:8.51e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.767, tt:5757.495\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.06071, lr:8.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:76.770, tt:5834.529\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00004, loss_test:0.06015, lr:8.51e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.686, tt:5904.784\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00004, loss_test:0.06018, lr:8.51e-03, fs:0.78125 (r=0.758,p=0.806),  time:76.615, tt:5975.939\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00004, loss_test:0.06321, lr:8.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.551, tt:6047.491\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00004, loss_test:0.05844, lr:8.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:76.566, tt:6125.250\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00004, loss_test:0.06194, lr:8.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:76.636, tt:6207.518\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00004, loss_test:0.06137, lr:8.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:76.629, tt:6283.582\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00004, loss_test:0.06067, lr:8.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:76.655, tt:6362.368\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00004, loss_test:0.06184, lr:8.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:76.663, tt:6439.731\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00004, loss_test:0.06152, lr:8.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.704, tt:6519.798\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00004, loss_test:0.06126, lr:8.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:76.685, tt:6594.875\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00004, loss_test:0.06306, lr:8.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.633, tt:6667.056\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.06128, lr:8.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:76.600, tt:6740.781\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00004, loss_test:0.06322, lr:8.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.544, tt:6812.382\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.06233, lr:8.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.577, tt:6891.913\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.06113, lr:8.43e-03, fs:0.78947 (r=0.758,p=0.824),  time:76.587, tt:6969.444\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.06342, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.622, tt:7049.240\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.06229, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.637, tt:7127.214\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.06272, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.637, tt:7203.893\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.06297, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.661, tt:7282.791\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00003, loss_test:0.06273, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.608, tt:7354.354\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00003, loss_test:0.06470, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.580, tt:7428.271\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00003, loss_test:0.06330, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.546, tt:7501.530\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00003, loss_test:0.06390, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.529, tt:7576.325\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00003, loss_test:0.06341, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.550, tt:7654.952\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00003, loss_test:0.06327, lr:8.35e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.571, tt:7733.682\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00003, loss_test:0.06522, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.599, tt:7813.121\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00003, loss_test:0.06408, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.596, tt:7889.425\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00003, loss_test:0.06512, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.634, tt:7969.981\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00003, loss_test:0.06511, lr:8.35e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.596, tt:8042.617\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00003, loss_test:0.06519, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.530, tt:8112.152\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.06369, lr:8.35e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.504, tt:8185.892\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.06434, lr:8.35e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.448, tt:8256.351\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.06584, lr:8.35e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.472, tt:8335.414\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.06380, lr:8.35e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.506, tt:8415.634\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.06562, lr:8.35e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.512, tt:8492.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.06559, lr:8.35e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.524, tt:8570.648\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.06526, lr:8.26e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.555, tt:8650.723\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.06616, lr:8.26e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.573, tt:8729.350\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.06622, lr:8.26e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.521, tt:8799.889\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.06403, lr:8.26e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.473, tt:8870.900\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.06613, lr:8.26e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.430, tt:8942.365\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.06569, lr:8.26e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.399, tt:9015.053\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.06678, lr:8.26e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.414, tt:9093.284\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.06689, lr:8.26e-03, fs:0.80435 (r=0.747,p=0.871),  time:76.431, tt:9171.779\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.06624, lr:8.26e-03, fs:0.80000 (r=0.747,p=0.860),  time:76.327, tt:9235.577\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00037, loss_test:0.09193, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:67.547, tt:67.547\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00037, loss_test:0.08908, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:73.091, tt:146.181\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00035, loss_test:0.08391, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:72.444, tt:217.333\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00033, loss_test:0.07726, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:71.615, tt:286.461\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00032, loss_test:0.07404, lr:1.00e-02, fs:0.71042 (r=0.929,p=0.575),  time:70.964, tt:354.819\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00031, loss_test:0.07297, lr:1.00e-02, fs:0.69145 (r=0.939,p=0.547),  time:70.642, tt:423.854\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00030, loss_test:0.07068, lr:1.00e-02, fs:0.70370 (r=0.960,p=0.556),  time:70.636, tt:494.452\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.06776, lr:1.00e-02, fs:0.70992 (r=0.939,p=0.571),  time:70.449, tt:563.593\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00027, loss_test:0.06634, lr:1.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:70.273, tt:632.457\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00027, loss_test:0.06502, lr:1.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:70.071, tt:700.707\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00025, loss_test:0.06374, lr:1.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:70.066, tt:770.729\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00025, loss_test:0.06275, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:69.893, tt:838.721\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00024, loss_test:0.06181, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:69.782, tt:907.170\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00023, loss_test:0.06156, lr:1.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:69.815, tt:977.417\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.06103, lr:1.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:69.797, tt:1046.962\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00022, loss_test:0.06002, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:69.723, tt:1115.561\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00021, loss_test:0.05985, lr:1.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:69.791, tt:1186.443\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00021, loss_test:0.05868, lr:1.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:69.859, tt:1257.457\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00020, loss_test:0.05809, lr:1.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:69.873, tt:1327.594\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.05793, lr:1.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:69.948, tt:1398.960\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00019, loss_test:0.05771, lr:1.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:69.922, tt:1468.368\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.05747, lr:1.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:69.853, tt:1536.771\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00018, loss_test:0.05705, lr:1.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:69.785, tt:1605.045\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00018, loss_test:0.05662, lr:1.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:69.811, tt:1675.455\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00017, loss_test:0.05663, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:69.772, tt:1744.289\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.05616, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:69.759, tt:1813.724\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00016, loss_test:0.05654, lr:1.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:69.779, tt:1884.034\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.05513, lr:1.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:69.728, tt:1952.370\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00015, loss_test:0.05588, lr:1.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:69.803, tt:2024.299\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.05541, lr:1.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:69.766, tt:2092.971\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.05588, lr:1.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:69.814, tt:2164.231\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.05471, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:69.835, tt:2234.706\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00013, loss_test:0.05531, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:69.774, tt:2302.532\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.05435, lr:1.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:69.795, tt:2373.044\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.05461, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:69.787, tt:2442.562\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00012, loss_test:0.05384, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:69.791, tt:2512.486\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.05389, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:69.711, tt:2579.325\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00011, loss_test:0.05277, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:69.698, tt:2648.506\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00011, loss_test:0.05331, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:69.669, tt:2717.097\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.05403, lr:9.90e-03, fs:0.78899 (r=0.869,p=0.723),  time:69.624, tt:2784.979\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00010, loss_test:0.05201, lr:9.80e-03, fs:0.78899 (r=0.869,p=0.723),  time:69.644, tt:2855.386\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00010, loss_test:0.05303, lr:9.70e-03, fs:0.78341 (r=0.859,p=0.720),  time:69.696, tt:2927.242\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05336, lr:9.61e-03, fs:0.78704 (r=0.859,p=0.726),  time:69.649, tt:2994.892\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.05277, lr:9.51e-03, fs:0.79070 (r=0.859,p=0.733),  time:69.672, tt:3065.571\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00009, loss_test:0.05242, lr:9.41e-03, fs:0.80189 (r=0.859,p=0.752),  time:69.716, tt:3137.214\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00009, loss_test:0.05393, lr:9.41e-03, fs:0.78182 (r=0.869,p=0.711),  time:69.719, tt:3207.079\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.05092, lr:9.41e-03, fs:0.80569 (r=0.859,p=0.759),  time:69.758, tt:3278.639\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.05317, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:69.793, tt:3350.068\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00008, loss_test:0.05224, lr:9.41e-03, fs:0.80769 (r=0.848,p=0.771),  time:69.818, tt:3421.076\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00008, loss_test:0.05393, lr:9.41e-03, fs:0.79621 (r=0.848,p=0.750),  time:69.829, tt:3491.439\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.05139, lr:9.41e-03, fs:0.80383 (r=0.848,p=0.764),  time:69.875, tt:3563.601\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.05211, lr:9.41e-03, fs:0.80383 (r=0.848,p=0.764),  time:69.887, tt:3634.129\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00007, loss_test:0.05375, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:69.864, tt:3702.816\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00007, loss_test:0.05158, lr:9.41e-03, fs:0.81553 (r=0.848,p=0.785),  time:69.891, tt:3774.136\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00007, loss_test:0.05206, lr:9.41e-03, fs:0.80383 (r=0.848,p=0.764),  time:69.883, tt:3843.580\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00007, loss_test:0.05175, lr:9.41e-03, fs:0.80769 (r=0.848,p=0.771),  time:69.898, tt:3914.307\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.04997, lr:9.41e-03, fs:0.80769 (r=0.848,p=0.771),  time:69.906, tt:3984.662\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.05252, lr:9.41e-03, fs:0.81159 (r=0.848,p=0.778),  time:69.885, tt:4053.321\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00006, loss_test:0.05049, lr:9.41e-03, fs:0.81951 (r=0.848,p=0.792),  time:69.899, tt:4124.056\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00006, loss_test:0.05296, lr:9.41e-03, fs:0.82759 (r=0.848,p=0.808),  time:69.926, tt:4195.577\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00006, loss_test:0.05125, lr:9.41e-03, fs:0.81553 (r=0.848,p=0.785),  time:69.927, tt:4265.537\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00006, loss_test:0.05012, lr:9.41e-03, fs:0.84000 (r=0.848,p=0.832),  time:69.935, tt:4335.956\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00006, loss_test:0.05240, lr:9.41e-03, fs:0.82759 (r=0.848,p=0.808),  time:69.972, tt:4408.261\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00006, loss_test:0.05048, lr:9.41e-03, fs:0.83168 (r=0.848,p=0.816),  time:69.991, tt:4479.411\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.05068, lr:9.41e-03, fs:0.83168 (r=0.848,p=0.816),  time:69.982, tt:4548.822\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.05167, lr:9.41e-03, fs:0.83168 (r=0.848,p=0.816),  time:69.955, tt:4617.037\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.04982, lr:9.41e-03, fs:0.83168 (r=0.848,p=0.816),  time:69.951, tt:4686.705\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00005, loss_test:0.05060, lr:9.41e-03, fs:0.83168 (r=0.848,p=0.816),  time:69.979, tt:4758.594\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0307a213a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2, target)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_embedding_loss\u001b[0;34m(input1, input2, target, margin, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,121,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 50\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:0, loss:0.00063, loss_test:0.07939, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:35.930, tt:35.930\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:1, loss:0.00045, loss_test:0.08513, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:36.489, tt:72.979\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:2, loss:0.00040, loss_test:0.07850, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:36.407, tt:109.221\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:3, loss:0.00037, loss_test:0.08011, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:36.447, tt:145.786\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:4, loss:0.00034, loss_test:0.08109, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:36.520, tt:182.602\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:5, loss:0.00032, loss_test:0.07350, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:36.799, tt:220.795\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:6, loss:0.00030, loss_test:0.07739, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:36.967, tt:258.770\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:7, loss:0.00029, loss_test:0.07722, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:38.046, tt:304.365\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:8, loss:0.00028, loss_test:0.07214, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:39.976, tt:359.784\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:9, loss:0.00027, loss_test:0.08043, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:41.546, tt:415.461\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:10, loss:0.00025, loss_test:0.07383, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:43.205, tt:475.251\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:11, loss:0.00023, loss_test:0.07542, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:44.351, tt:532.209\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:12, loss:0.00022, loss_test:0.07983, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:45.393, tt:590.106\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:13, loss:0.00021, loss_test:0.07634, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:46.359, tt:649.025\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:14, loss:0.00020, loss_test:0.07344, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:47.221, tt:708.316\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:15, loss:0.00019, loss_test:0.08130, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:48.047, tt:768.751\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:16, loss:0.00018, loss_test:0.07799, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:48.583, tt:825.917\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:17, loss:0.00017, loss_test:0.07658, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:49.056, tt:883.012\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:18, loss:0.00016, loss_test:0.08034, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:49.384, tt:938.304\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:19, loss:0.00015, loss_test:0.07687, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:49.859, tt:997.177\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:20, loss:0.00014, loss_test:0.08141, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:50.113, tt:1052.381\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:21, loss:0.00013, loss_test:0.08265, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:50.361, tt:1107.942\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:22, loss:0.00013, loss_test:0.07382, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:50.702, tt:1166.146\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:23, loss:0.00013, loss_test:0.08521, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:50.917, tt:1222.001\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:24, loss:0.00012, loss_test:0.07877, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:51.191, tt:1279.768\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:25, loss:0.00011, loss_test:0.07530, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:51.462, tt:1338.015\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:26, loss:0.00011, loss_test:0.07998, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:51.677, tt:1395.287\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:27, loss:0.00010, loss_test:0.08157, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:51.929, tt:1454.003\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:28, loss:0.00010, loss_test:0.07634, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:52.104, tt:1511.028\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:29, loss:0.00009, loss_test:0.07942, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:52.266, tt:1567.990\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:30, loss:0.00009, loss_test:0.07905, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:52.359, tt:1623.118\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:31, loss:0.00009, loss_test:0.07436, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:52.518, tt:1680.591\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:32, loss:0.00008, loss_test:0.08257, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:52.682, tt:1738.498\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:33, loss:0.00008, loss_test:0.07656, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:52.798, tt:1795.131\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:34, loss:0.00008, loss_test:0.07562, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:52.912, tt:1851.927\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:35, loss:0.00007, loss_test:0.07943, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:53.011, tt:1908.391\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:36, loss:0.00007, loss_test:0.07771, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:53.079, tt:1963.914\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:37, loss:0.00007, loss_test:0.07676, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:53.187, tt:2021.125\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:38, loss:0.00006, loss_test:0.07548, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:53.372, tt:2081.506\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:39, loss:0.00006, loss_test:0.07676, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:53.522, tt:2140.872\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:40, loss:0.00006, loss_test:0.07842, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:53.566, tt:2196.186\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:41, loss:0.00006, loss_test:0.07628, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:53.702, tt:2255.466\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:42, loss:0.00006, loss_test:0.07601, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:53.863, tt:2316.105\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:43, loss:0.00005, loss_test:0.07764, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:54.030, tt:2377.317\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:44, loss:0.00005, loss_test:0.07954, lr:9.90e-03, fs:0.77838 (r=0.727,p=0.837),  time:54.129, tt:2435.796\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:45, loss:0.00005, loss_test:0.07955, lr:9.80e-03, fs:0.76344 (r=0.717,p=0.816),  time:54.164, tt:2491.548\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:46, loss:0.00005, loss_test:0.07646, lr:9.70e-03, fs:0.78022 (r=0.717,p=0.855),  time:54.211, tt:2547.911\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:47, loss:0.00005, loss_test:0.07858, lr:9.61e-03, fs:0.78022 (r=0.717,p=0.855),  time:54.225, tt:2602.803\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:48, loss:0.00005, loss_test:0.07864, lr:9.51e-03, fs:0.77005 (r=0.727,p=0.818),  time:54.234, tt:2657.474\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:49, loss:0.00005, loss_test:0.07492, lr:9.41e-03, fs:0.77895 (r=0.747,p=0.813),  time:54.264, tt:2713.223\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:50, loss:0.00004, loss_test:0.08138, lr:9.32e-03, fs:0.73563 (r=0.646,p=0.853),  time:54.393, tt:2774.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:51, loss:0.00004, loss_test:0.07565, lr:9.23e-03, fs:0.77249 (r=0.737,p=0.811),  time:54.474, tt:2832.661\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:52, loss:0.00004, loss_test:0.07872, lr:9.14e-03, fs:0.75978 (r=0.687,p=0.850),  time:54.560, tt:2891.672\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:53, loss:0.00004, loss_test:0.07813, lr:9.04e-03, fs:0.78022 (r=0.717,p=0.855),  time:54.616, tt:2949.276\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:54, loss:0.00004, loss_test:0.07968, lr:8.95e-03, fs:0.78652 (r=0.707,p=0.886),  time:54.903, tt:3019.683\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:55, loss:0.00004, loss_test:0.07997, lr:8.86e-03, fs:0.75862 (r=0.667,p=0.880),  time:55.543, tt:3110.407\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:56, loss:0.00004, loss_test:0.07764, lr:8.78e-03, fs:0.76757 (r=0.717,p=0.826),  time:56.085, tt:3196.827\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:57, loss:0.00004, loss_test:0.08310, lr:8.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.620, tt:3283.966\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:58, loss:0.00003, loss_test:0.07691, lr:8.60e-03, fs:0.76757 (r=0.717,p=0.826),  time:57.130, tt:3370.685\n",
      "1080\n",
      "1038\n",
      "1032\n",
      "1026\n",
      "1086\n",
      "66\n",
      "Ep:59, loss:0.00003, loss_test:0.07870, lr:8.51e-03, fs:0.76404 (r=0.687,p=0.861),  time:57.553, tt:3453.150\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"51-51\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 50\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:0, loss:0.00062, loss_test:0.08365, lr:1.00e-02, fs:0.64846 (r=0.960,p=0.490),  time:68.721, tt:68.721\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:1, loss:0.00059, loss_test:0.07621, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:74.421, tt:148.842\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:2, loss:0.00054, loss_test:0.07363, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:76.445, tt:229.334\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:3, loss:0.00050, loss_test:0.07159, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:78.871, tt:315.485\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:4, loss:0.00046, loss_test:0.07124, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:79.874, tt:399.370\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:5, loss:0.00043, loss_test:0.06926, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:81.064, tt:486.386\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:6, loss:0.00040, loss_test:0.06944, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:85.417, tt:597.916\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:7, loss:0.00037, loss_test:0.06761, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:89.821, tt:718.570\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:8, loss:0.00035, loss_test:0.06854, lr:1.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:93.482, tt:841.338\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:9, loss:0.00033, loss_test:0.06787, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:96.433, tt:964.333\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:10, loss:0.00031, loss_test:0.06799, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:97.984, tt:1077.828\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:11, loss:0.00029, loss_test:0.06780, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:98.346, tt:1180.150\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:12, loss:0.00028, loss_test:0.06788, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:97.692, tt:1270.001\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:13, loss:0.00026, loss_test:0.06835, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:99.278, tt:1389.886\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:14, loss:0.00024, loss_test:0.06792, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:100.965, tt:1514.479\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:15, loss:0.00023, loss_test:0.06811, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:101.498, tt:1623.970\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:16, loss:0.00022, loss_test:0.06774, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:101.797, tt:1730.549\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:17, loss:0.00020, loss_test:0.07120, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:102.035, tt:1836.633\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:18, loss:0.00019, loss_test:0.06939, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:102.500, tt:1947.497\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:19, loss:0.00018, loss_test:0.07047, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:102.729, tt:2054.588\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:20, loss:0.00017, loss_test:0.06914, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:103.061, tt:2164.287\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:21, loss:0.00015, loss_test:0.06927, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:103.108, tt:2268.378\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:22, loss:0.00015, loss_test:0.06993, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:103.382, tt:2377.793\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:23, loss:0.00014, loss_test:0.06832, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:103.607, tt:2486.579\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:24, loss:0.00013, loss_test:0.06849, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:103.828, tt:2595.698\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:25, loss:0.00013, loss_test:0.06791, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:104.076, tt:2705.987\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:26, loss:0.00012, loss_test:0.06824, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:104.203, tt:2813.480\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:27, loss:0.00012, loss_test:0.06849, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:104.472, tt:2925.212\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:28, loss:0.00012, loss_test:0.07302, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:104.703, tt:3036.399\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:29, loss:0.00011, loss_test:0.07377, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:104.905, tt:3147.141\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:30, loss:0.00011, loss_test:0.06988, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:105.104, tt:3258.214\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:31, loss:0.00010, loss_test:0.06922, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:105.159, tt:3365.093\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:32, loss:0.00010, loss_test:0.06904, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:105.356, tt:3476.735\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:33, loss:0.00010, loss_test:0.06981, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:105.441, tt:3584.980\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:34, loss:0.00010, loss_test:0.07005, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:103.658, tt:3628.017\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:35, loss:0.00009, loss_test:0.06980, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:101.985, tt:3671.453\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:36, loss:0.00008, loss_test:0.07013, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:100.402, tt:3714.860\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:37, loss:0.00008, loss_test:0.06971, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:98.896, tt:3758.042\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:38, loss:0.00008, loss_test:0.07611, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:97.481, tt:3801.774\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:39, loss:0.00008, loss_test:0.07467, lr:9.90e-03, fs:0.78723 (r=0.747,p=0.831),  time:96.190, tt:3847.612\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:40, loss:0.00007, loss_test:0.07076, lr:9.80e-03, fs:0.76531 (r=0.758,p=0.773),  time:94.912, tt:3891.392\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:41, loss:0.00007, loss_test:0.07065, lr:9.70e-03, fs:0.76289 (r=0.747,p=0.779),  time:93.681, tt:3934.583\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:42, loss:0.00007, loss_test:0.07006, lr:9.61e-03, fs:0.77895 (r=0.747,p=0.813),  time:92.510, tt:3977.911\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:43, loss:0.00007, loss_test:0.07504, lr:9.51e-03, fs:0.78919 (r=0.737,p=0.849),  time:91.400, tt:4021.588\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:44, loss:0.00006, loss_test:0.07386, lr:9.41e-03, fs:0.78495 (r=0.737,p=0.839),  time:90.328, tt:4064.774\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:45, loss:0.00006, loss_test:0.07216, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:89.311, tt:4108.310\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:46, loss:0.00006, loss_test:0.07395, lr:9.23e-03, fs:0.78075 (r=0.737,p=0.830),  time:88.338, tt:4151.869\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:47, loss:0.00006, loss_test:0.07212, lr:9.14e-03, fs:0.78495 (r=0.737,p=0.839),  time:87.412, tt:4195.777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:48, loss:0.00005, loss_test:0.07480, lr:9.04e-03, fs:0.78919 (r=0.737,p=0.849),  time:86.520, tt:4239.501\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:49, loss:0.00005, loss_test:0.07479, lr:8.95e-03, fs:0.79781 (r=0.737,p=0.869),  time:85.670, tt:4283.487\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:50, loss:0.00005, loss_test:0.07612, lr:8.86e-03, fs:0.79781 (r=0.737,p=0.869),  time:84.843, tt:4327.013\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:51, loss:0.00005, loss_test:0.07449, lr:8.78e-03, fs:0.78495 (r=0.737,p=0.839),  time:84.057, tt:4370.950\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:52, loss:0.00005, loss_test:0.07660, lr:8.69e-03, fs:0.79348 (r=0.737,p=0.859),  time:83.304, tt:4415.113\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:53, loss:0.00004, loss_test:0.07381, lr:8.60e-03, fs:0.77660 (r=0.737,p=0.820),  time:82.584, tt:4459.557\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:54, loss:0.00004, loss_test:0.07293, lr:8.51e-03, fs:0.78919 (r=0.737,p=0.849),  time:81.958, tt:4507.696\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:55, loss:0.00004, loss_test:0.07497, lr:8.43e-03, fs:0.78919 (r=0.737,p=0.849),  time:81.286, tt:4552.000\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:56, loss:0.00004, loss_test:0.07575, lr:8.35e-03, fs:0.79781 (r=0.737,p=0.869),  time:80.630, tt:4595.913\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:57, loss:0.00004, loss_test:0.07660, lr:8.26e-03, fs:0.79781 (r=0.737,p=0.869),  time:80.004, tt:4640.232\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:58, loss:0.00004, loss_test:0.07741, lr:8.18e-03, fs:0.78453 (r=0.717,p=0.866),  time:79.406, tt:4684.980\n",
      "1104\n",
      "1032\n",
      "1080\n",
      "1040\n",
      "1072\n",
      "1056\n",
      "720\n",
      "Ep:59, loss:0.00004, loss_test:0.07928, lr:8.10e-03, fs:0.74713 (r=0.657,p=0.867),  time:78.815, tt:4728.907\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"51-51\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 50\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:0, loss:0.00036, loss_test:0.09009, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.756, tt:23.756\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:1, loss:0.00035, loss_test:0.08532, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:24.658, tt:49.316\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:2, loss:0.00034, loss_test:0.07640, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:26.065, tt:78.196\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:3, loss:0.00032, loss_test:0.07559, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:26.634, tt:106.537\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:4, loss:0.00031, loss_test:0.07563, lr:1.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:27.124, tt:135.618\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:5, loss:0.00029, loss_test:0.07491, lr:1.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:27.752, tt:166.513\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:6, loss:0.00028, loss_test:0.07305, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:28.698, tt:200.889\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:7, loss:0.00027, loss_test:0.07258, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:30.517, tt:244.132\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:8, loss:0.00026, loss_test:0.07307, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:31.592, tt:284.327\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:9, loss:0.00025, loss_test:0.07230, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:33.393, tt:333.934\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:10, loss:0.00024, loss_test:0.07244, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:34.902, tt:383.920\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:11, loss:0.00023, loss_test:0.07116, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:36.176, tt:434.112\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:12, loss:0.00022, loss_test:0.07017, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:37.603, tt:488.835\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:13, loss:0.00022, loss_test:0.07122, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:37.931, tt:531.034\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:14, loss:0.00021, loss_test:0.07019, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:38.408, tt:576.121\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:15, loss:0.00021, loss_test:0.06996, lr:9.90e-03, fs:0.68644 (r=0.818,p=0.591),  time:38.806, tt:620.891\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:16, loss:0.00020, loss_test:0.06940, lr:9.80e-03, fs:0.68354 (r=0.818,p=0.587),  time:39.024, tt:663.416\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:17, loss:0.00019, loss_test:0.06979, lr:9.70e-03, fs:0.68354 (r=0.818,p=0.587),  time:39.527, tt:711.489\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:18, loss:0.00019, loss_test:0.07013, lr:9.61e-03, fs:0.70175 (r=0.808,p=0.620),  time:39.881, tt:757.732\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:19, loss:0.00018, loss_test:0.07046, lr:9.61e-03, fs:0.67797 (r=0.808,p=0.584),  time:40.356, tt:807.114\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:20, loss:0.00018, loss_test:0.06904, lr:9.61e-03, fs:0.70175 (r=0.808,p=0.620),  time:40.767, tt:856.102\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:21, loss:0.00017, loss_test:0.06991, lr:9.61e-03, fs:0.69912 (r=0.798,p=0.622),  time:41.040, tt:902.890\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:22, loss:0.00017, loss_test:0.06917, lr:9.61e-03, fs:0.69828 (r=0.818,p=0.609),  time:41.055, tt:944.260\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:23, loss:0.00016, loss_test:0.06891, lr:9.61e-03, fs:0.69565 (r=0.808,p=0.611),  time:41.178, tt:988.284\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:24, loss:0.00016, loss_test:0.06977, lr:9.61e-03, fs:0.70222 (r=0.798,p=0.627),  time:41.408, tt:1035.195\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:25, loss:0.00016, loss_test:0.07025, lr:9.61e-03, fs:0.71171 (r=0.798,p=0.642),  time:41.609, tt:1081.840\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:26, loss:0.00015, loss_test:0.06924, lr:9.61e-03, fs:0.71493 (r=0.798,p=0.648),  time:42.013, tt:1134.357\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:27, loss:0.00014, loss_test:0.06896, lr:9.61e-03, fs:0.70222 (r=0.798,p=0.627),  time:42.215, tt:1182.025\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:28, loss:0.00014, loss_test:0.06921, lr:9.61e-03, fs:0.72811 (r=0.798,p=0.669),  time:42.414, tt:1229.992\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:29, loss:0.00014, loss_test:0.07073, lr:9.61e-03, fs:0.72811 (r=0.798,p=0.669),  time:42.386, tt:1271.573\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:30, loss:0.00013, loss_test:0.06921, lr:9.61e-03, fs:0.71818 (r=0.798,p=0.653),  time:42.485, tt:1317.040\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:31, loss:0.00013, loss_test:0.07099, lr:9.61e-03, fs:0.73148 (r=0.798,p=0.675),  time:42.525, tt:1360.795\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:32, loss:0.00012, loss_test:0.06827, lr:9.61e-03, fs:0.71493 (r=0.798,p=0.648),  time:42.659, tt:1407.732\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:33, loss:0.00012, loss_test:0.07106, lr:9.61e-03, fs:0.74641 (r=0.788,p=0.709),  time:42.854, tt:1457.020\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:34, loss:0.00012, loss_test:0.06925, lr:9.61e-03, fs:0.73488 (r=0.798,p=0.681),  time:42.936, tt:1502.757\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:35, loss:0.00012, loss_test:0.07007, lr:9.61e-03, fs:0.73832 (r=0.798,p=0.687),  time:43.191, tt:1554.880\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:36, loss:0.00011, loss_test:0.07253, lr:9.61e-03, fs:0.75728 (r=0.788,p=0.729),  time:43.234, tt:1599.667\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:37, loss:0.00011, loss_test:0.07102, lr:9.61e-03, fs:0.75238 (r=0.798,p=0.712),  time:43.252, tt:1643.580\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:38, loss:0.00011, loss_test:0.06989, lr:9.61e-03, fs:0.73488 (r=0.798,p=0.681),  time:43.331, tt:1689.907\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:39, loss:0.00010, loss_test:0.07354, lr:9.61e-03, fs:0.76098 (r=0.788,p=0.736),  time:43.350, tt:1734.003\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:40, loss:0.00010, loss_test:0.07099, lr:9.61e-03, fs:0.73488 (r=0.798,p=0.681),  time:43.554, tt:1785.713\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:41, loss:0.00010, loss_test:0.07211, lr:9.61e-03, fs:0.75238 (r=0.798,p=0.712),  time:43.671, tt:1834.187\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:42, loss:0.00009, loss_test:0.07249, lr:9.61e-03, fs:0.73934 (r=0.788,p=0.696),  time:43.754, tt:1881.442\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:43, loss:0.00009, loss_test:0.07216, lr:9.61e-03, fs:0.75238 (r=0.798,p=0.712),  time:43.864, tt:1930.029\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:44, loss:0.00009, loss_test:0.07388, lr:9.61e-03, fs:0.74641 (r=0.788,p=0.709),  time:43.856, tt:1973.534\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:45, loss:0.00009, loss_test:0.07231, lr:9.61e-03, fs:0.75238 (r=0.798,p=0.712),  time:43.907, tt:2019.700\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:46, loss:0.00009, loss_test:0.07466, lr:9.61e-03, fs:0.73934 (r=0.788,p=0.696),  time:43.979, tt:2066.991\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:47, loss:0.00009, loss_test:0.07413, lr:9.61e-03, fs:0.76329 (r=0.798,p=0.731),  time:44.398, tt:2131.126\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:48, loss:0.00009, loss_test:0.07519, lr:9.61e-03, fs:0.73239 (r=0.788,p=0.684),  time:44.995, tt:2204.752\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:49, loss:0.00008, loss_test:0.07491, lr:9.61e-03, fs:0.76847 (r=0.788,p=0.750),  time:45.566, tt:2278.300\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:50, loss:0.00008, loss_test:0.07478, lr:9.61e-03, fs:0.72558 (r=0.788,p=0.672),  time:46.088, tt:2350.495\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:51, loss:0.00008, loss_test:0.07374, lr:9.61e-03, fs:0.77833 (r=0.798,p=0.760),  time:46.612, tt:2423.849\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:52, loss:0.00007, loss_test:0.07576, lr:9.61e-03, fs:0.72897 (r=0.788,p=0.678),  time:46.966, tt:2489.189\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:53, loss:0.00007, loss_test:0.07496, lr:9.61e-03, fs:0.78000 (r=0.788,p=0.772),  time:47.307, tt:2554.586\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:54, loss:0.00007, loss_test:0.07563, lr:9.61e-03, fs:0.71889 (r=0.788,p=0.661),  time:47.623, tt:2619.281\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:55, loss:0.00008, loss_test:0.07616, lr:9.61e-03, fs:0.76000 (r=0.768,p=0.752),  time:47.929, tt:2684.003\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:56, loss:0.00008, loss_test:0.07586, lr:9.61e-03, fs:0.71560 (r=0.788,p=0.655),  time:48.306, tt:2753.414\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:57, loss:0.00007, loss_test:0.07497, lr:9.61e-03, fs:0.75728 (r=0.788,p=0.729),  time:48.684, tt:2823.688\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:58, loss:0.00007, loss_test:0.07866, lr:9.61e-03, fs:0.75362 (r=0.788,p=0.722),  time:49.059, tt:2894.480\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:59, loss:0.00007, loss_test:0.07554, lr:9.61e-03, fs:0.76847 (r=0.788,p=0.750),  time:49.012, tt:2940.743\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:60, loss:0.00006, loss_test:0.07930, lr:9.61e-03, fs:0.76382 (r=0.768,p=0.760),  time:48.866, tt:2980.800\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:61, loss:0.00006, loss_test:0.07727, lr:9.61e-03, fs:0.78974 (r=0.778,p=0.802),  time:48.704, tt:3019.649\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:62, loss:0.00006, loss_test:0.07823, lr:9.61e-03, fs:0.75122 (r=0.778,p=0.726),  time:48.583, tt:3060.742\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:63, loss:0.00006, loss_test:0.07676, lr:9.61e-03, fs:0.78974 (r=0.778,p=0.802),  time:48.458, tt:3101.339\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:64, loss:0.00006, loss_test:0.07903, lr:9.61e-03, fs:0.74757 (r=0.778,p=0.720),  time:48.454, tt:3149.495\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:65, loss:0.00006, loss_test:0.07790, lr:9.61e-03, fs:0.78571 (r=0.778,p=0.794),  time:48.431, tt:3196.463\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:66, loss:0.00005, loss_test:0.07888, lr:9.61e-03, fs:0.75122 (r=0.778,p=0.726),  time:48.419, tt:3244.054\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:67, loss:0.00006, loss_test:0.07844, lr:9.61e-03, fs:0.78351 (r=0.768,p=0.800),  time:48.403, tt:3291.400\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:68, loss:0.00005, loss_test:0.07759, lr:9.61e-03, fs:0.76238 (r=0.778,p=0.748),  time:48.303, tt:3332.886\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:69, loss:0.00005, loss_test:0.07692, lr:9.61e-03, fs:0.78974 (r=0.778,p=0.802),  time:48.201, tt:3374.094\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:70, loss:0.00005, loss_test:0.07996, lr:9.61e-03, fs:0.79381 (r=0.778,p=0.811),  time:48.096, tt:3414.836\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:71, loss:0.00005, loss_test:0.07766, lr:9.61e-03, fs:0.78351 (r=0.768,p=0.800),  time:48.012, tt:3456.841\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:72, loss:0.00005, loss_test:0.07967, lr:9.61e-03, fs:0.78974 (r=0.778,p=0.802),  time:47.982, tt:3502.657\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:73, loss:0.00005, loss_test:0.07999, lr:9.61e-03, fs:0.78351 (r=0.768,p=0.800),  time:47.982, tt:3550.644\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:74, loss:0.00004, loss_test:0.07806, lr:9.61e-03, fs:0.78173 (r=0.778,p=0.786),  time:47.981, tt:3598.611\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:75, loss:0.00004, loss_test:0.08033, lr:9.61e-03, fs:0.78534 (r=0.758,p=0.815),  time:47.962, tt:3645.085\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:76, loss:0.00004, loss_test:0.07789, lr:9.61e-03, fs:0.78571 (r=0.778,p=0.794),  time:47.867, tt:3685.791\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:77, loss:0.00004, loss_test:0.07978, lr:9.61e-03, fs:0.78351 (r=0.768,p=0.800),  time:47.760, tt:3725.291\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:78, loss:0.00004, loss_test:0.07661, lr:9.61e-03, fs:0.78173 (r=0.778,p=0.786),  time:47.678, tt:3766.602\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:79, loss:0.00004, loss_test:0.08176, lr:9.61e-03, fs:0.79365 (r=0.758,p=0.833),  time:47.637, tt:3810.972\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:80, loss:0.00004, loss_test:0.07627, lr:9.61e-03, fs:0.78571 (r=0.778,p=0.794),  time:47.635, tt:3858.409\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:81, loss:0.00004, loss_test:0.08033, lr:9.61e-03, fs:0.78756 (r=0.768,p=0.809),  time:47.638, tt:3906.296\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:82, loss:0.00004, loss_test:0.07895, lr:9.51e-03, fs:0.79793 (r=0.778,p=0.819),  time:47.634, tt:3953.659\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:83, loss:0.00004, loss_test:0.08188, lr:9.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:47.589, tt:3997.475\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:84, loss:0.00004, loss_test:0.07847, lr:9.51e-03, fs:0.79381 (r=0.778,p=0.811),  time:47.495, tt:4037.074\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:85, loss:0.00004, loss_test:0.07979, lr:9.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:47.430, tt:4078.988\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:86, loss:0.00004, loss_test:0.08028, lr:9.51e-03, fs:0.79793 (r=0.778,p=0.819),  time:47.332, tt:4117.848\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:87, loss:0.00003, loss_test:0.08039, lr:9.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:47.310, tt:4163.238\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:88, loss:0.00003, loss_test:0.07870, lr:9.51e-03, fs:0.78173 (r=0.778,p=0.786),  time:47.292, tt:4208.998\n",
      "1056\n",
      "1044\n",
      "1036\n",
      "416\n",
      "Ep:89, loss:0.00004, loss_test:0.08114, lr:9.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:47.261, tt:4253.470\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,90,\"51-51\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:0, loss:0.00051, loss_test:0.07772, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:37.572, tt:37.572\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:1, loss:0.00026, loss_test:0.08264, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:52.937, tt:105.875\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:2, loss:0.00022, loss_test:0.08414, lr:1.00e-02, fs:0.68293 (r=0.707,p=0.660),  time:66.717, tt:200.150\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:3, loss:0.00020, loss_test:0.07904, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:72.393, tt:289.570\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:4, loss:0.00019, loss_test:0.07629, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:76.283, tt:381.417\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:5, loss:0.00018, loss_test:0.07267, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:78.825, tt:472.948\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:6, loss:0.00018, loss_test:0.07378, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:81.774, tt:572.421\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:7, loss:0.00017, loss_test:0.07047, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:84.063, tt:672.507\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:8, loss:0.00016, loss_test:0.06762, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:85.580, tt:770.220\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:9, loss:0.00016, loss_test:0.07344, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:86.631, tt:866.310\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:10, loss:0.00015, loss_test:0.06630, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:87.033, tt:957.360\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:11, loss:0.00015, loss_test:0.06450, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:87.117, tt:1045.404\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:12, loss:0.00014, loss_test:0.06570, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:87.382, tt:1135.968\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:13, loss:0.00013, loss_test:0.06479, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:87.917, tt:1230.844\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:14, loss:0.00013, loss_test:0.06151, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:88.601, tt:1329.012\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:15, loss:0.00012, loss_test:0.06247, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:89.092, tt:1425.477\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:16, loss:0.00012, loss_test:0.06158, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:89.275, tt:1517.668\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:17, loss:0.00011, loss_test:0.05931, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:89.330, tt:1607.943\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:18, loss:0.00011, loss_test:0.05768, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:89.309, tt:1696.871\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:19, loss:0.00011, loss_test:0.05869, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:89.488, tt:1789.752\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:20, loss:0.00010, loss_test:0.06354, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:89.853, tt:1886.906\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:21, loss:0.00010, loss_test:0.05439, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:90.215, tt:1984.731\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:22, loss:0.00010, loss_test:0.05463, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:90.520, tt:2081.959\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:23, loss:0.00009, loss_test:0.06186, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:90.568, tt:2173.621\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:24, loss:0.00009, loss_test:0.05175, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:90.451, tt:2261.263\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:25, loss:0.00009, loss_test:0.05453, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:90.446, tt:2351.587\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:26, loss:0.00009, loss_test:0.05709, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:90.540, tt:2444.590\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:27, loss:0.00008, loss_test:0.04984, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:90.799, tt:2542.365\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:28, loss:0.00008, loss_test:0.05407, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:91.019, tt:2639.545\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:29, loss:0.00007, loss_test:0.05444, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:91.157, tt:2734.698\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:30, loss:0.00007, loss_test:0.04799, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:91.178, tt:2826.505\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:31, loss:0.00007, loss_test:0.05398, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:91.155, tt:2916.960\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:32, loss:0.00007, loss_test:0.05056, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:91.123, tt:3007.073\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:33, loss:0.00007, loss_test:0.04793, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:91.289, tt:3103.831\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:34, loss:0.00006, loss_test:0.05191, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:91.520, tt:3203.206\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:35, loss:0.00006, loss_test:0.04737, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:91.706, tt:3301.417\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:36, loss:0.00006, loss_test:0.04920, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:91.836, tt:3397.923\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:37, loss:0.00006, loss_test:0.04868, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:91.852, tt:3490.374\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:38, loss:0.00006, loss_test:0.04679, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:91.760, tt:3578.645\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:39, loss:0.00005, loss_test:0.04847, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:91.705, tt:3668.196\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:40, loss:0.00005, loss_test:0.04436, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:91.857, tt:3766.153\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:41, loss:0.00005, loss_test:0.04851, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:91.990, tt:3863.568\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:42, loss:0.00005, loss_test:0.04666, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:92.164, tt:3963.048\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:43, loss:0.00005, loss_test:0.04424, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:92.221, tt:4057.731\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:44, loss:0.00005, loss_test:0.04646, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:92.152, tt:4146.828\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:45, loss:0.00005, loss_test:0.04646, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:92.051, tt:4234.362\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:46, loss:0.00005, loss_test:0.04582, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:92.003, tt:4324.130\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:47, loss:0.00004, loss_test:0.04239, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:92.082, tt:4419.957\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:48, loss:0.00004, loss_test:0.04682, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:92.214, tt:4518.465\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:49, loss:0.00004, loss_test:0.04262, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:92.252, tt:4612.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:50, loss:0.00004, loss_test:0.04295, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:92.264, tt:4705.452\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:51, loss:0.00004, loss_test:0.04435, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:92.182, tt:4793.482\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:52, loss:0.00004, loss_test:0.04384, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:92.075, tt:4879.996\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:53, loss:0.00004, loss_test:0.04062, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:92.110, tt:4973.940\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:54, loss:0.00004, loss_test:0.04458, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:92.150, tt:5068.275\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:55, loss:0.00004, loss_test:0.04298, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:92.223, tt:5164.488\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:56, loss:0.00004, loss_test:0.04125, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:92.301, tt:5261.173\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:57, loss:0.00003, loss_test:0.04169, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:92.256, tt:5350.848\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:58, loss:0.00003, loss_test:0.04087, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:92.247, tt:5442.587\n",
      "1080\n",
      "1030\n",
      "1035\n",
      "1030\n",
      "265\n",
      "Ep:59, loss:0.00003, loss_test:0.04287, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:92.220, tt:5533.226\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:0, loss:0.00052, loss_test:0.07880, lr:1.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:88.050, tt:88.050\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:1, loss:0.00026, loss_test:0.08201, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:86.703, tt:173.405\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:2, loss:0.00022, loss_test:0.08461, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:89.941, tt:269.822\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:3, loss:0.00021, loss_test:0.07600, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:91.430, tt:365.720\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:4, loss:0.00020, loss_test:0.07995, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:91.021, tt:455.106\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:5, loss:0.00019, loss_test:0.07317, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:90.597, tt:543.584\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:6, loss:0.00018, loss_test:0.07200, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:91.100, tt:637.701\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:7, loss:0.00017, loss_test:0.06819, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:92.046, tt:736.371\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:8, loss:0.00016, loss_test:0.06858, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:92.741, tt:834.673\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:9, loss:0.00015, loss_test:0.06730, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:93.393, tt:933.926\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:10, loss:0.00015, loss_test:0.06197, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:93.401, tt:1027.416\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:11, loss:0.00015, loss_test:0.06589, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:93.140, tt:1117.678\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:12, loss:0.00014, loss_test:0.06203, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:92.696, tt:1205.042\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:13, loss:0.00013, loss_test:0.05934, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:92.822, tt:1299.505\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:14, loss:0.00013, loss_test:0.06298, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:93.214, tt:1398.211\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:15, loss:0.00013, loss_test:0.05908, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:93.628, tt:1498.044\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:16, loss:0.00012, loss_test:0.06095, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:93.826, tt:1595.038\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:17, loss:0.00012, loss_test:0.05669, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:93.619, tt:1685.142\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:18, loss:0.00011, loss_test:0.05699, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:93.292, tt:1772.557\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:19, loss:0.00011, loss_test:0.06052, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:93.138, tt:1862.766\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:20, loss:0.00010, loss_test:0.05434, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:93.164, tt:1956.445\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:21, loss:0.00010, loss_test:0.05696, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:93.230, tt:2051.052\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:22, loss:0.00010, loss_test:0.05447, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:93.399, tt:2148.168\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:23, loss:0.00009, loss_test:0.05489, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:93.536, tt:2244.859\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:24, loss:0.00009, loss_test:0.05329, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:93.434, tt:2335.842\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:25, loss:0.00009, loss_test:0.05563, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:93.307, tt:2425.993\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:26, loss:0.00009, loss_test:0.05186, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:93.106, tt:2513.863\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:27, loss:0.00008, loss_test:0.05286, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:93.209, tt:2609.854\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:28, loss:0.00008, loss_test:0.05073, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:93.261, tt:2704.562\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:29, loss:0.00008, loss_test:0.05193, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:93.336, tt:2800.069\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:30, loss:0.00007, loss_test:0.05069, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:93.445, tt:2896.803\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:31, loss:0.00007, loss_test:0.04936, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:93.258, tt:2984.268\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:32, loss:0.00007, loss_test:0.04787, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:93.104, tt:3072.419\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:33, loss:0.00007, loss_test:0.05007, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:92.977, tt:3161.211\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:34, loss:0.00006, loss_test:0.04886, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:93.189, tt:3261.602\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:35, loss:0.00006, loss_test:0.04919, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:93.362, tt:3361.019\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:36, loss:0.00006, loss_test:0.04718, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:93.504, tt:3459.642\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:37, loss:0.00006, loss_test:0.04614, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:93.640, tt:3558.316\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:38, loss:0.00006, loss_test:0.04878, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:93.566, tt:3649.067\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:39, loss:0.00005, loss_test:0.04670, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:93.467, tt:3738.669\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:40, loss:0.00005, loss_test:0.04615, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:93.449, tt:3831.425\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:41, loss:0.00005, loss_test:0.04467, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:93.528, tt:3928.181\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:42, loss:0.00005, loss_test:0.04514, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:93.632, tt:4026.178\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:43, loss:0.00005, loss_test:0.04648, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:93.745, tt:4124.766\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:44, loss:0.00005, loss_test:0.04592, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:93.772, tt:4219.730\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:45, loss:0.00004, loss_test:0.04369, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:93.663, tt:4308.504\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:46, loss:0.00004, loss_test:0.04305, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:93.583, tt:4398.411\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:47, loss:0.00004, loss_test:0.04715, lr:1.00e-02, fs:0.92537 (r=0.939,p=0.912),  time:93.563, tt:4491.014\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:48, loss:0.00004, loss_test:0.04812, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:93.669, tt:4589.767\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:49, loss:0.00004, loss_test:0.03955, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:93.772, tt:4688.617\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:50, loss:0.00004, loss_test:0.05047, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:93.880, tt:4787.893\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:51, loss:0.00004, loss_test:0.04390, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:93.817, tt:4878.496\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:52, loss:0.00004, loss_test:0.04546, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:93.691, tt:4965.622\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:53, loss:0.00005, loss_test:0.04722, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:93.636, tt:5056.333\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:54, loss:0.00005, loss_test:0.04885, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:93.650, tt:5150.732\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:55, loss:0.00004, loss_test:0.04126, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:93.736, tt:5249.191\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:56, loss:0.00004, loss_test:0.04859, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:93.822, tt:5347.874\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:57, loss:0.00004, loss_test:0.04452, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:93.878, tt:5444.952\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:58, loss:0.00003, loss_test:0.04344, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:93.769, tt:5532.368\n",
      "1045\n",
      "1035\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:59, loss:0.00003, loss_test:0.04423, lr:9.90e-03, fs:0.88442 (r=0.889,p=0.880),  time:93.731, tt:5623.885\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1040\n",
      "1040\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:0, loss:0.00051, loss_test:0.08045, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:87.244, tt:87.244\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1040\n",
      "1030\n",
      "1025\n",
      "305\n",
      "Ep:1, loss:0.00025, loss_test:0.08772, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:85.761, tt:171.522\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1040\n",
      "1030\n",
      "1025\n",
      "305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e897897f90e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_ran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"isolation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for CV out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:0, loss:0.00034, loss_test:0.09176, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.671, tt:20.671\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:1, loss:0.00033, loss_test:0.08741, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:29.387, tt:58.774\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:2, loss:0.00029, loss_test:0.07839, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:35.577, tt:106.732\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:3, loss:0.00023, loss_test:0.08221, lr:1.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:41.362, tt:165.447\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:4, loss:0.00021, loss_test:0.08272, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:44.807, tt:224.037\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:5, loss:0.00020, loss_test:0.07556, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:47.379, tt:284.276\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:6, loss:0.00020, loss_test:0.07522, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:49.153, tt:344.070\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:7, loss:0.00019, loss_test:0.07370, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:50.614, tt:404.908\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:8, loss:0.00018, loss_test:0.06914, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:51.655, tt:464.898\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:9, loss:0.00017, loss_test:0.06918, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:52.307, tt:523.073\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:10, loss:0.00017, loss_test:0.06916, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:52.955, tt:582.504\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:11, loss:0.00016, loss_test:0.06621, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:53.508, tt:642.097\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:12, loss:0.00016, loss_test:0.06544, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:53.710, tt:698.232\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:13, loss:0.00015, loss_test:0.06416, lr:1.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:53.840, tt:753.763\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:14, loss:0.00015, loss_test:0.06319, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:53.902, tt:808.527\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:15, loss:0.00015, loss_test:0.06314, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:54.011, tt:864.178\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:16, loss:0.00015, loss_test:0.06204, lr:1.00e-02, fs:0.75536 (r=0.889,p=0.657),  time:54.175, tt:920.981\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:17, loss:0.00014, loss_test:0.06148, lr:1.00e-02, fs:0.78261 (r=0.909,p=0.687),  time:54.247, tt:976.441\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:18, loss:0.00014, loss_test:0.06132, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:54.323, tt:1032.138\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:19, loss:0.00014, loss_test:0.06022, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:54.308, tt:1086.154\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:20, loss:0.00013, loss_test:0.05981, lr:1.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:54.311, tt:1140.524\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:21, loss:0.00013, loss_test:0.05918, lr:1.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:54.395, tt:1196.693\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:22, loss:0.00013, loss_test:0.05814, lr:1.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:54.452, tt:1252.399\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:23, loss:0.00012, loss_test:0.05826, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:54.334, tt:1304.011\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:24, loss:0.00012, loss_test:0.05652, lr:1.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:54.386, tt:1359.642\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:25, loss:0.00012, loss_test:0.05755, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:54.342, tt:1412.892\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:26, loss:0.00012, loss_test:0.05702, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:54.340, tt:1467.168\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:27, loss:0.00011, loss_test:0.05599, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:54.363, tt:1522.167\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:28, loss:0.00011, loss_test:0.05572, lr:1.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:54.375, tt:1576.877\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:29, loss:0.00011, loss_test:0.05646, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:54.375, tt:1631.240\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:30, loss:0.00010, loss_test:0.05479, lr:1.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:54.331, tt:1684.273\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:31, loss:0.00010, loss_test:0.05507, lr:1.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:54.338, tt:1738.813\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:32, loss:0.00010, loss_test:0.05494, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:54.288, tt:1791.493\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:33, loss:0.00010, loss_test:0.05431, lr:1.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:54.309, tt:1846.517\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:34, loss:0.00010, loss_test:0.05440, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:54.316, tt:1901.076\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:35, loss:0.00009, loss_test:0.05297, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:54.363, tt:1957.051\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:36, loss:0.00009, loss_test:0.05369, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:54.308, tt:2009.404\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:37, loss:0.00009, loss_test:0.05199, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:54.254, tt:2061.661\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:38, loss:0.00009, loss_test:0.05269, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:54.257, tt:2116.007\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:39, loss:0.00009, loss_test:0.05118, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:54.228, tt:2169.129\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:40, loss:0.00008, loss_test:0.05206, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:54.217, tt:2222.876\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:41, loss:0.00008, loss_test:0.05025, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:54.204, tt:2276.569\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:42, loss:0.00008, loss_test:0.05349, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:54.209, tt:2330.999\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:43, loss:0.00008, loss_test:0.04998, lr:1.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:54.185, tt:2384.138\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:44, loss:0.00008, loss_test:0.05164, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:54.139, tt:2436.245\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:45, loss:0.00007, loss_test:0.04944, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:54.131, tt:2490.044\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:46, loss:0.00007, loss_test:0.05200, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:54.084, tt:2541.939\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:47, loss:0.00007, loss_test:0.04843, lr:1.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:54.116, tt:2597.570\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:48, loss:0.00007, loss_test:0.05225, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:54.132, tt:2652.492\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:49, loss:0.00007, loss_test:0.04770, lr:1.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:54.143, tt:2707.163\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:50, loss:0.00007, loss_test:0.05197, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:54.098, tt:2758.986\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:51, loss:0.00007, loss_test:0.04681, lr:1.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:54.111, tt:2813.796\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:52, loss:0.00006, loss_test:0.05029, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:54.153, tt:2870.119\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:53, loss:0.00006, loss_test:0.04695, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:54.179, tt:2925.666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:54, loss:0.00006, loss_test:0.04889, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:54.152, tt:2978.346\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:55, loss:0.00006, loss_test:0.04655, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:54.174, tt:3033.753\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:56, loss:0.00006, loss_test:0.04872, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:54.173, tt:3087.888\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:57, loss:0.00006, loss_test:0.04617, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:54.155, tt:3140.987\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:58, loss:0.00005, loss_test:0.04835, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:54.158, tt:3195.347\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:59, loss:0.00005, loss_test:0.04578, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:54.150, tt:3249.014\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:60, loss:0.00005, loss_test:0.04538, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:54.123, tt:3301.509\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:61, loss:0.00005, loss_test:0.04507, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:54.170, tt:3358.557\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:62, loss:0.00005, loss_test:0.04594, lr:9.90e-03, fs:0.90047 (r=0.960,p=0.848),  time:54.163, tt:3412.269\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:63, loss:0.00005, loss_test:0.04530, lr:9.80e-03, fs:0.90047 (r=0.960,p=0.848),  time:54.176, tt:3467.270\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:64, loss:0.00005, loss_test:0.04534, lr:9.70e-03, fs:0.90909 (r=0.960,p=0.864),  time:54.164, tt:3520.657\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:65, loss:0.00005, loss_test:0.04463, lr:9.61e-03, fs:0.89423 (r=0.939,p=0.853),  time:54.143, tt:3573.468\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:66, loss:0.00004, loss_test:0.04483, lr:9.51e-03, fs:0.90047 (r=0.960,p=0.848),  time:54.133, tt:3626.881\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:67, loss:0.00004, loss_test:0.04443, lr:9.41e-03, fs:0.89524 (r=0.949,p=0.847),  time:54.117, tt:3679.940\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:68, loss:0.00004, loss_test:0.04515, lr:9.32e-03, fs:0.90909 (r=0.960,p=0.864),  time:54.095, tt:3732.559\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:69, loss:0.00004, loss_test:0.04395, lr:9.23e-03, fs:0.89952 (r=0.949,p=0.855),  time:54.096, tt:3786.693\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:70, loss:0.00004, loss_test:0.04395, lr:9.14e-03, fs:0.90909 (r=0.960,p=0.864),  time:54.101, tt:3841.171\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:71, loss:0.00004, loss_test:0.04417, lr:9.04e-03, fs:0.90291 (r=0.939,p=0.869),  time:54.128, tt:3897.241\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:72, loss:0.00004, loss_test:0.04370, lr:8.95e-03, fs:0.90909 (r=0.960,p=0.864),  time:54.143, tt:3952.413\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:73, loss:0.00004, loss_test:0.04361, lr:8.86e-03, fs:0.91346 (r=0.960,p=0.872),  time:54.160, tt:4007.872\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:74, loss:0.00004, loss_test:0.04293, lr:8.78e-03, fs:0.91787 (r=0.960,p=0.880),  time:54.139, tt:4060.454\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:75, loss:0.00004, loss_test:0.04284, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:54.139, tt:4114.574\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:76, loss:0.00004, loss_test:0.04305, lr:8.78e-03, fs:0.92233 (r=0.960,p=0.888),  time:54.124, tt:4167.570\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:77, loss:0.00004, loss_test:0.04234, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:54.097, tt:4219.530\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:78, loss:0.00004, loss_test:0.04307, lr:8.78e-03, fs:0.90821 (r=0.949,p=0.870),  time:54.108, tt:4274.516\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:79, loss:0.00003, loss_test:0.04241, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:54.115, tt:4329.186\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:80, loss:0.00003, loss_test:0.04230, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:54.109, tt:4382.848\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:81, loss:0.00003, loss_test:0.04242, lr:8.78e-03, fs:0.91346 (r=0.960,p=0.872),  time:54.106, tt:4436.652\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:82, loss:0.00003, loss_test:0.04217, lr:8.78e-03, fs:0.90821 (r=0.949,p=0.870),  time:54.089, tt:4489.415\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:83, loss:0.00003, loss_test:0.04254, lr:8.78e-03, fs:0.91787 (r=0.960,p=0.880),  time:54.072, tt:4542.090\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:84, loss:0.00003, loss_test:0.04191, lr:8.78e-03, fs:0.91866 (r=0.970,p=0.873),  time:54.070, tt:4595.942\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:85, loss:0.00003, loss_test:0.04201, lr:8.78e-03, fs:0.91176 (r=0.939,p=0.886),  time:54.058, tt:4648.968\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:86, loss:0.00003, loss_test:0.04220, lr:8.78e-03, fs:0.91787 (r=0.960,p=0.880),  time:54.068, tt:4703.901\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:87, loss:0.00003, loss_test:0.04190, lr:8.78e-03, fs:0.90732 (r=0.939,p=0.877),  time:54.074, tt:4758.485\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:88, loss:0.00003, loss_test:0.04227, lr:8.69e-03, fs:0.93596 (r=0.960,p=0.913),  time:54.067, tt:4811.974\n",
      "##########Best model found so far##########\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:89, loss:0.00003, loss_test:0.04221, lr:8.69e-03, fs:0.89552 (r=0.909,p=0.882),  time:54.045, tt:4864.094\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:90, loss:0.00003, loss_test:0.04202, lr:8.69e-03, fs:0.93137 (r=0.960,p=0.905),  time:54.035, tt:4917.144\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:91, loss:0.00003, loss_test:0.04117, lr:8.69e-03, fs:0.90196 (r=0.929,p=0.876),  time:54.021, tt:4969.966\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:92, loss:0.00003, loss_test:0.04256, lr:8.69e-03, fs:0.93069 (r=0.949,p=0.913),  time:54.015, tt:5023.369\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:93, loss:0.00003, loss_test:0.04112, lr:8.69e-03, fs:0.88557 (r=0.899,p=0.873),  time:53.998, tt:5075.824\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:94, loss:0.00003, loss_test:0.04146, lr:8.69e-03, fs:0.90640 (r=0.929,p=0.885),  time:54.006, tt:5130.584\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:95, loss:0.00003, loss_test:0.04221, lr:8.69e-03, fs:0.88889 (r=0.889,p=0.889),  time:53.989, tt:5182.972\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:96, loss:0.00003, loss_test:0.04143, lr:8.69e-03, fs:0.88557 (r=0.899,p=0.873),  time:53.980, tt:5236.055\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:97, loss:0.00002, loss_test:0.04126, lr:8.69e-03, fs:0.90732 (r=0.939,p=0.877),  time:53.973, tt:5289.366\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:98, loss:0.00003, loss_test:0.04174, lr:8.69e-03, fs:0.88442 (r=0.889,p=0.880),  time:53.959, tt:5341.921\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:99, loss:0.00002, loss_test:0.04174, lr:8.69e-03, fs:0.89447 (r=0.899,p=0.890),  time:53.960, tt:5396.048\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:100, loss:0.00002, loss_test:0.04208, lr:8.60e-03, fs:0.87437 (r=0.879,p=0.870),  time:53.953, tt:5449.264\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:101, loss:0.00002, loss_test:0.04175, lr:8.51e-03, fs:0.92000 (r=0.929,p=0.911),  time:53.971, tt:5505.038\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:102, loss:0.00002, loss_test:0.04108, lr:8.43e-03, fs:0.88000 (r=0.889,p=0.871),  time:53.966, tt:5558.505\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:103, loss:0.00002, loss_test:0.04172, lr:8.35e-03, fs:0.90355 (r=0.899,p=0.908),  time:53.957, tt:5611.552\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:104, loss:0.00002, loss_test:0.04182, lr:8.26e-03, fs:0.87179 (r=0.859,p=0.885),  time:53.976, tt:5667.455\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:105, loss:0.00002, loss_test:0.04063, lr:8.18e-03, fs:0.89109 (r=0.909,p=0.874),  time:53.974, tt:5721.254\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:106, loss:0.00002, loss_test:0.04108, lr:8.10e-03, fs:0.87879 (r=0.879,p=0.879),  time:53.968, tt:5774.589\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:107, loss:0.00002, loss_test:0.04130, lr:8.02e-03, fs:0.89231 (r=0.879,p=0.906),  time:53.974, tt:5829.196\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:108, loss:0.00002, loss_test:0.04032, lr:7.94e-03, fs:0.88557 (r=0.899,p=0.873),  time:53.976, tt:5883.393\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:109, loss:0.00002, loss_test:0.04032, lr:7.86e-03, fs:0.89340 (r=0.889,p=0.898),  time:53.972, tt:5936.971\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:110, loss:0.00002, loss_test:0.04055, lr:7.78e-03, fs:0.86735 (r=0.859,p=0.876),  time:53.976, tt:5991.374\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:111, loss:0.00002, loss_test:0.04002, lr:7.70e-03, fs:0.88557 (r=0.899,p=0.873),  time:53.986, tt:6046.409\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:112, loss:0.00002, loss_test:0.04108, lr:7.62e-03, fs:0.88776 (r=0.879,p=0.897),  time:53.979, tt:6099.624\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:113, loss:0.00002, loss_test:0.04105, lr:7.55e-03, fs:0.87629 (r=0.859,p=0.895),  time:53.984, tt:6154.147\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:114, loss:0.00002, loss_test:0.04047, lr:7.47e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.009, tt:6211.070\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:115, loss:0.00002, loss_test:0.04019, lr:7.40e-03, fs:0.86869 (r=0.869,p=0.869),  time:54.007, tt:6264.817\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:116, loss:0.00002, loss_test:0.04006, lr:7.32e-03, fs:0.86294 (r=0.859,p=0.867),  time:54.025, tt:6320.879\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:117, loss:0.00002, loss_test:0.04070, lr:7.25e-03, fs:0.87629 (r=0.859,p=0.895),  time:54.022, tt:6374.639\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:118, loss:0.00002, loss_test:0.04009, lr:7.18e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.024, tt:6428.829\n",
      "1038\n",
      "1047\n",
      "579\n",
      "Ep:119, loss:0.00002, loss_test:0.03984, lr:7.11e-03, fs:0.88442 (r=0.889,p=0.880),  time:54.022, tt:6482.628\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:0, loss:0.00034, loss_test:0.09263, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.002, tt:43.002\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:1, loss:0.00033, loss_test:0.08849, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:43.192, tt:86.384\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:2, loss:0.00028, loss_test:0.07995, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:43.767, tt:131.301\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:3, loss:0.00023, loss_test:0.08645, lr:1.00e-02, fs:0.65179 (r=0.737,p=0.584),  time:46.365, tt:185.458\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:4, loss:0.00021, loss_test:0.08567, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:48.170, tt:240.849\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:5, loss:0.00020, loss_test:0.07949, lr:1.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:49.475, tt:296.852\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:6, loss:0.00020, loss_test:0.08078, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:50.006, tt:350.043\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:7, loss:0.00019, loss_test:0.07759, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:50.285, tt:402.279\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:8, loss:0.00018, loss_test:0.07175, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:50.826, tt:457.437\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:9, loss:0.00018, loss_test:0.07280, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:51.035, tt:510.347\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:10, loss:0.00017, loss_test:0.07178, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:51.388, tt:565.272\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:11, loss:0.00016, loss_test:0.06800, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:51.568, tt:618.814\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:12, loss:0.00016, loss_test:0.06866, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:51.837, tt:673.880\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:13, loss:0.00016, loss_test:0.06588, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:52.007, tt:728.094\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:14, loss:0.00015, loss_test:0.06610, lr:1.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:52.105, tt:781.573\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:15, loss:0.00015, loss_test:0.06718, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:52.154, tt:834.468\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:16, loss:0.00015, loss_test:0.06278, lr:1.00e-02, fs:0.75536 (r=0.889,p=0.657),  time:52.236, tt:888.011\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:17, loss:0.00014, loss_test:0.06369, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:52.371, tt:942.674\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:18, loss:0.00014, loss_test:0.06289, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:52.655, tt:1000.445\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:19, loss:0.00014, loss_test:0.06177, lr:1.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:52.831, tt:1056.627\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:20, loss:0.00013, loss_test:0.06298, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:52.971, tt:1112.390\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:21, loss:0.00013, loss_test:0.06029, lr:1.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:53.055, tt:1167.216\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:22, loss:0.00013, loss_test:0.06140, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:53.349, tt:1227.028\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:23, loss:0.00012, loss_test:0.06017, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:53.674, tt:1288.187\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:24, loss:0.00012, loss_test:0.05987, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:53.963, tt:1349.065\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:25, loss:0.00012, loss_test:0.06079, lr:1.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:54.162, tt:1408.220\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:26, loss:0.00012, loss_test:0.05914, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:54.379, tt:1468.221\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:27, loss:0.00011, loss_test:0.05888, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:54.542, tt:1527.168\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:28, loss:0.00011, loss_test:0.05891, lr:1.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:54.536, tt:1581.550\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:29, loss:0.00011, loss_test:0.05727, lr:1.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:54.654, tt:1639.629\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:30, loss:0.00011, loss_test:0.05732, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:54.642, tt:1693.901\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:31, loss:0.00010, loss_test:0.05653, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:54.680, tt:1749.761\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:32, loss:0.00010, loss_test:0.05575, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:54.889, tt:1811.337\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:33, loss:0.00010, loss_test:0.05688, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:55.034, tt:1871.140\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:34, loss:0.00010, loss_test:0.05513, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:55.234, tt:1933.201\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:35, loss:0.00010, loss_test:0.05603, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:55.426, tt:1995.321\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:36, loss:0.00009, loss_test:0.05418, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:55.578, tt:2056.369\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:37, loss:0.00009, loss_test:0.05524, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:55.603, tt:2112.918\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:38, loss:0.00009, loss_test:0.05291, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:55.598, tt:2168.313\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:39, loss:0.00008, loss_test:0.05424, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:55.632, tt:2225.291\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:40, loss:0.00009, loss_test:0.05235, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:55.662, tt:2282.142\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:41, loss:0.00008, loss_test:0.05346, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:55.675, tt:2338.367\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:42, loss:0.00008, loss_test:0.05120, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:55.828, tt:2400.623\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:43, loss:0.00008, loss_test:0.05247, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:55.951, tt:2461.826\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:44, loss:0.00008, loss_test:0.05129, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:56.121, tt:2525.425\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:45, loss:0.00007, loss_test:0.05179, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:56.264, tt:2588.143\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:46, loss:0.00007, loss_test:0.04969, lr:1.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:56.375, tt:2649.619\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:47, loss:0.00007, loss_test:0.05139, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:56.384, tt:2706.422\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:48, loss:0.00007, loss_test:0.04870, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:56.414, tt:2764.307\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:49, loss:0.00007, loss_test:0.05224, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:56.408, tt:2820.391\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:50, loss:0.00007, loss_test:0.04726, lr:1.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:56.413, tt:2877.078\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:51, loss:0.00007, loss_test:0.05200, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:56.453, tt:2935.549\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:52, loss:0.00006, loss_test:0.04646, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:56.531, tt:2996.132\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:53, loss:0.00006, loss_test:0.05111, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:56.589, tt:3055.782\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:54, loss:0.00006, loss_test:0.04694, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:56.661, tt:3116.337\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:55, loss:0.00006, loss_test:0.05109, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:56.707, tt:3175.577\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:56, loss:0.00006, loss_test:0.04610, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:56.790, tt:3237.047\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:57, loss:0.00006, loss_test:0.05130, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:56.776, tt:3293.034\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:58, loss:0.00006, loss_test:0.04610, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:56.741, tt:3347.705\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:59, loss:0.00005, loss_test:0.05018, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:56.675, tt:3400.472\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:60, loss:0.00005, loss_test:0.04653, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:56.679, tt:3457.407\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:61, loss:0.00005, loss_test:0.04668, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:56.741, tt:3517.926\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:62, loss:0.00005, loss_test:0.04795, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:56.801, tt:3578.458\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:63, loss:0.00005, loss_test:0.04575, lr:1.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:56.873, tt:3639.857\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:64, loss:0.00005, loss_test:0.04640, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:56.971, tt:3703.122\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:65, loss:0.00005, loss_test:0.04701, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:57.036, tt:3764.373\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:66, loss:0.00004, loss_test:0.04554, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:57.094, tt:3825.319\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:67, loss:0.00005, loss_test:0.04799, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:57.056, tt:3879.782\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:68, loss:0.00004, loss_test:0.04474, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:57.044, tt:3936.028\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:69, loss:0.00004, loss_test:0.04814, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:57.010, tt:3990.702\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:70, loss:0.00004, loss_test:0.04431, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:56.962, tt:4044.285\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:71, loss:0.00004, loss_test:0.04718, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:56.980, tt:4102.575\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:72, loss:0.00004, loss_test:0.04470, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:57.013, tt:4161.923\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:73, loss:0.00004, loss_test:0.04640, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:57.029, tt:4220.115\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:74, loss:0.00004, loss_test:0.04546, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:57.052, tt:4278.905\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:75, loss:0.00004, loss_test:0.04593, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:57.098, tt:4339.447\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:76, loss:0.00004, loss_test:0.04588, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:57.112, tt:4397.623\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:77, loss:0.00004, loss_test:0.04436, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:57.067, tt:4451.247\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:78, loss:0.00003, loss_test:0.04597, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:57.026, tt:4505.090\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:79, loss:0.00003, loss_test:0.04369, lr:9.90e-03, fs:0.84404 (r=0.929,p=0.773),  time:56.988, tt:4559.077\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:80, loss:0.00004, loss_test:0.04597, lr:9.80e-03, fs:0.85572 (r=0.869,p=0.843),  time:56.964, tt:4614.084\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:81, loss:0.00003, loss_test:0.04517, lr:9.70e-03, fs:0.88780 (r=0.919,p=0.858),  time:56.992, tt:4673.347\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:82, loss:0.00003, loss_test:0.04440, lr:9.70e-03, fs:0.87500 (r=0.919,p=0.835),  time:57.018, tt:4732.518\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:83, loss:0.00003, loss_test:0.04530, lr:9.70e-03, fs:0.86000 (r=0.869,p=0.851),  time:57.030, tt:4790.550\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:84, loss:0.00003, loss_test:0.04451, lr:9.70e-03, fs:0.87923 (r=0.919,p=0.843),  time:57.057, tt:4849.826\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:85, loss:0.00003, loss_test:0.04442, lr:9.70e-03, fs:0.87379 (r=0.909,p=0.841),  time:57.076, tt:4908.549\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:86, loss:0.00003, loss_test:0.04434, lr:9.70e-03, fs:0.87923 (r=0.919,p=0.843),  time:57.091, tt:4966.936\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:87, loss:0.00003, loss_test:0.04524, lr:9.70e-03, fs:0.86700 (r=0.889,p=0.846),  time:57.059, tt:5021.167\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:88, loss:0.00003, loss_test:0.04453, lr:9.70e-03, fs:0.87379 (r=0.909,p=0.841),  time:57.037, tt:5076.281\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:89, loss:0.00003, loss_test:0.04523, lr:9.70e-03, fs:0.85149 (r=0.869,p=0.835),  time:57.012, tt:5131.088\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:90, loss:0.00003, loss_test:0.04328, lr:9.70e-03, fs:0.86667 (r=0.919,p=0.820),  time:56.966, tt:5183.863\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:91, loss:0.00003, loss_test:0.04458, lr:9.70e-03, fs:0.87805 (r=0.909,p=0.849),  time:56.977, tt:5241.902\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:92, loss:0.00003, loss_test:0.04429, lr:9.70e-03, fs:0.86275 (r=0.889,p=0.838),  time:57.030, tt:5303.833\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:93, loss:0.00003, loss_test:0.04422, lr:9.61e-03, fs:0.86829 (r=0.899,p=0.840),  time:57.047, tt:5362.465\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:94, loss:0.00003, loss_test:0.04337, lr:9.51e-03, fs:0.87500 (r=0.919,p=0.835),  time:57.077, tt:5422.276\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:95, loss:0.00003, loss_test:0.04434, lr:9.41e-03, fs:0.86275 (r=0.889,p=0.838),  time:57.092, tt:5480.871\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:96, loss:0.00003, loss_test:0.04456, lr:9.32e-03, fs:0.87255 (r=0.899,p=0.848),  time:57.122, tt:5540.838\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:97, loss:0.00002, loss_test:0.04268, lr:9.23e-03, fs:0.86667 (r=0.919,p=0.820),  time:57.119, tt:5597.690\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:98, loss:0.00002, loss_test:0.04501, lr:9.14e-03, fs:0.86567 (r=0.879,p=0.853),  time:57.114, tt:5654.322\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:99, loss:0.00002, loss_test:0.04306, lr:9.04e-03, fs:0.86957 (r=0.909,p=0.833),  time:57.107, tt:5710.737\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:101, loss:0.00002, loss_test:0.04381, lr:8.86e-03, fs:0.87255 (r=0.899,p=0.848),  time:57.127, tt:5826.932\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:102, loss:0.00002, loss_test:0.04313, lr:8.78e-03, fs:0.87379 (r=0.909,p=0.841),  time:57.156, tt:5887.084\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:103, loss:0.00002, loss_test:0.04577, lr:8.69e-03, fs:0.84974 (r=0.828,p=0.872),  time:57.193, tt:5948.039\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:104, loss:0.00002, loss_test:0.04357, lr:8.60e-03, fs:0.88235 (r=0.909,p=0.857),  time:57.202, tt:6006.235\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:105, loss:0.00002, loss_test:0.04267, lr:8.51e-03, fs:0.86957 (r=0.909,p=0.833),  time:57.216, tt:6064.937\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:106, loss:0.00002, loss_test:0.04462, lr:8.43e-03, fs:0.86567 (r=0.879,p=0.853),  time:57.183, tt:6118.557\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:107, loss:0.00002, loss_test:0.04254, lr:8.35e-03, fs:0.86957 (r=0.909,p=0.833),  time:57.141, tt:6171.279\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:108, loss:0.00002, loss_test:0.04450, lr:8.26e-03, fs:0.87129 (r=0.889,p=0.854),  time:57.108, tt:6224.807\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:109, loss:0.00002, loss_test:0.04485, lr:8.18e-03, fs:0.86735 (r=0.859,p=0.876),  time:57.081, tt:6278.878\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:110, loss:0.00002, loss_test:0.04398, lr:8.10e-03, fs:0.87685 (r=0.899,p=0.856),  time:57.069, tt:6334.685\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:111, loss:0.00002, loss_test:0.04338, lr:8.02e-03, fs:0.85000 (r=0.859,p=0.842),  time:57.086, tt:6393.598\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:112, loss:0.00002, loss_test:0.04408, lr:7.94e-03, fs:0.87000 (r=0.879,p=0.861),  time:57.106, tt:6452.976\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:113, loss:0.00002, loss_test:0.04348, lr:7.86e-03, fs:0.87685 (r=0.899,p=0.856),  time:57.125, tt:6512.294\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:114, loss:0.00002, loss_test:0.04279, lr:7.78e-03, fs:0.86700 (r=0.889,p=0.846),  time:57.134, tt:6570.457\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:115, loss:0.00002, loss_test:0.04389, lr:7.70e-03, fs:0.87129 (r=0.889,p=0.854),  time:57.155, tt:6629.949\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:116, loss:0.00002, loss_test:0.04299, lr:7.62e-03, fs:0.86567 (r=0.879,p=0.853),  time:57.140, tt:6685.401\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:117, loss:0.00002, loss_test:0.04353, lr:7.55e-03, fs:0.86567 (r=0.879,p=0.853),  time:57.121, tt:6740.312\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:118, loss:0.00002, loss_test:0.04323, lr:7.47e-03, fs:0.86567 (r=0.879,p=0.853),  time:57.105, tt:6795.486\n",
      "1029\n",
      "1032\n",
      "603\n",
      "Ep:119, loss:0.00002, loss_test:0.04346, lr:7.40e-03, fs:0.87000 (r=0.879,p=0.861),  time:57.075, tt:6848.958\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:0, loss:0.00034, loss_test:0.09375, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.487, tt:57.487\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:1, loss:0.00032, loss_test:0.09022, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.055, tt:100.109\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:2, loss:0.00028, loss_test:0.08436, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:52.424, tt:157.271\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:3, loss:0.00022, loss_test:0.09432, lr:1.00e-02, fs:0.60302 (r=0.606,p=0.600),  time:54.466, tt:217.865\n",
      "1026\n",
      "1032\n",
      "606\n",
      "Ep:4, loss:0.00021, loss_test:0.09138, lr:1.00e-02, fs:0.61692 (r=0.626,p=0.608),  time:56.132, tt:280.658\n",
      "1026\n",
      "1032\n",
      "606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9884dd7af360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "ITERATION: 0\n",
      "ITERATION: 1\n",
      "ITERATION: 2\n",
      "ITERATION: 3\n",
      "ITERATION: 4\n",
      "ITERATION: 5\n",
      "ITERATION: 6\n",
      "ITERATION: 7\n",
      "ITERATION: 8\n",
      "ITERATION: 9\n",
      "ITERATION: 10\n",
      "ITERATION: 11\n",
      "ITERATION: 12\n",
      "ITERATION: 13\n",
      "ITERATION: 14\n",
      "ITERATION: 15\n",
      "ITERATION: 16\n",
      "ITERATION: 17\n",
      "ITERATION: 18\n",
      "ITERATION: 19\n",
      "ITERATION: 20\n",
      "ITERATION: 21\n",
      "ITERATION: 22\n",
      "ITERATION: 23\n",
      "ITERATION: 24\n",
      "ITERATION: 25\n",
      "ITERATION: 26\n",
      "ITERATION: 27\n",
      "ITERATION: 28\n",
      "ITERATION: 29\n",
      "ITERATION: 30\n",
      "ITERATION: 31\n",
      "ITERATION: 32\n",
      "ITERATION: 33\n",
      "ITERATION: 34\n",
      "ITERATION: 35\n",
      "ITERATION: 36\n",
      "ITERATION: 37\n",
      "ITERATION: 38\n",
      "ITERATION: 39\n",
      "ITERATION: 40\n",
      "ITERATION: 41\n",
      "ITERATION: 42\n",
      "ITERATION: 43\n",
      "ITERATION: 44\n",
      "ITERATION: 45\n",
      "ITERATION: 46\n",
      "ITERATION: 47\n",
      "ITERATION: 48\n",
      "ITERATION: 49\n",
      "ITERATION: 50\n",
      "ITERATION: 51\n",
      "ITERATION: 52\n",
      "ITERATION: 53\n",
      "ITERATION: 54\n",
      "ITERATION: 55\n",
      "ITERATION: 56\n",
      "ITERATION: 57\n",
      "ITERATION: 58\n",
      "ITERATION: 59\n",
      "ITERATION: 60\n",
      "ITERATION: 61\n",
      "ITERATION: 62\n",
      "ITERATION: 63\n",
      "ITERATION: 64\n",
      "ITERATION: 65\n",
      "ITERATION: 66\n",
      "ITERATION: 67\n",
      "ITERATION: 68\n",
      "ITERATION: 69\n",
      "ITERATION: 70\n",
      "ITERATION: 71\n",
      "ITERATION: 72\n",
      "ITERATION: 73\n",
      "ITERATION: 74\n",
      "ITERATION: 75\n",
      "ITERATION: 76\n",
      "ITERATION: 77\n",
      "ITERATION: 78\n",
      "ITERATION: 79\n",
      "ITERATION: 80\n",
      "ITERATION: 81\n",
      "ITERATION: 82\n",
      "ITERATION: 83\n",
      "ITERATION: 84\n",
      "ITERATION: 85\n",
      "ITERATION: 86\n",
      "ITERATION: 87\n",
      "ITERATION: 88\n",
      "ITERATION: 89\n",
      "ITERATION: 90\n",
      "ITERATION: 91\n",
      "ITERATION: 92\n",
      "ITERATION: 93\n",
      "ITERATION: 94\n",
      "ITERATION: 95\n",
      "ITERATION: 96\n",
      "ITERATION: 97\n",
      "ITERATION: 98\n",
      "ITERATION: 99\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00018, loss_test:0.09327, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.219, tt:30.219\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00018, loss_test:0.09209, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:32.087, tt:64.173\n",
      "Ep:2, loss:0.00018, loss_test:0.09025, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:32.400, tt:97.200\n",
      "Ep:3, loss:0.00017, loss_test:0.08799, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:33.321, tt:133.283\n",
      "Ep:4, loss:0.00016, loss_test:0.08571, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:33.647, tt:168.235\n",
      "Ep:5, loss:0.00016, loss_test:0.08466, lr:1.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:33.953, tt:203.718\n",
      "Ep:6, loss:0.00015, loss_test:0.08481, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:33.842, tt:236.894\n",
      "Ep:7, loss:0.00015, loss_test:0.08354, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:33.994, tt:271.950\n",
      "Ep:8, loss:0.00015, loss_test:0.08115, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:34.185, tt:307.666\n",
      "Ep:9, loss:0.00014, loss_test:0.07988, lr:1.00e-02, fs:0.66667 (r=0.879,p=0.537),  time:34.201, tt:342.014\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00014, loss_test:0.07898, lr:1.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:34.227, tt:376.502\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00014, loss_test:0.07826, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:34.215, tt:410.576\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00013, loss_test:0.07781, lr:1.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:34.167, tt:444.169\n",
      "Ep:13, loss:0.00013, loss_test:0.07694, lr:1.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:34.104, tt:477.455\n",
      "Ep:14, loss:0.00013, loss_test:0.07594, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:34.105, tt:511.574\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00013, loss_test:0.07500, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:34.114, tt:545.822\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00012, loss_test:0.07410, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:34.083, tt:579.419\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00012, loss_test:0.07349, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:34.047, tt:612.841\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00012, loss_test:0.07293, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:34.095, tt:647.810\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.07202, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:34.061, tt:681.225\n",
      "Ep:20, loss:0.00011, loss_test:0.07122, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:34.022, tt:714.468\n",
      "Ep:21, loss:0.00011, loss_test:0.07065, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:34.009, tt:748.192\n",
      "Ep:22, loss:0.00011, loss_test:0.07019, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:34.035, tt:782.804\n",
      "Ep:23, loss:0.00011, loss_test:0.06969, lr:1.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:34.050, tt:817.195\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.06913, lr:1.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:34.022, tt:850.555\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.06858, lr:1.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:34.003, tt:884.085\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.06826, lr:1.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:33.999, tt:917.964\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.06785, lr:1.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:33.970, tt:951.165\n",
      "Ep:28, loss:0.00010, loss_test:0.06737, lr:1.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:33.910, tt:983.386\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.06703, lr:1.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:33.898, tt:1016.936\n",
      "Ep:30, loss:0.00009, loss_test:0.06695, lr:1.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:33.889, tt:1050.550\n",
      "Ep:31, loss:0.00009, loss_test:0.06663, lr:1.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:33.896, tt:1084.673\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06640, lr:1.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:33.898, tt:1118.631\n",
      "Ep:33, loss:0.00009, loss_test:0.06587, lr:1.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:33.901, tt:1152.622\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.06573, lr:1.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:33.889, tt:1186.103\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06566, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:33.907, tt:1220.644\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.06531, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:33.889, tt:1253.877\n",
      "Ep:37, loss:0.00008, loss_test:0.06496, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:33.892, tt:1287.890\n",
      "Ep:38, loss:0.00008, loss_test:0.06475, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:33.873, tt:1321.041\n",
      "Ep:39, loss:0.00008, loss_test:0.06465, lr:1.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:33.868, tt:1354.724\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.06460, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:33.947, tt:1391.807\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.06428, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:33.944, tt:1425.664\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.06394, lr:1.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:33.943, tt:1459.532\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06380, lr:1.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:33.949, tt:1493.775\n",
      "Ep:44, loss:0.00008, loss_test:0.06368, lr:1.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:33.914, tt:1526.122\n",
      "Ep:45, loss:0.00007, loss_test:0.06339, lr:1.00e-02, fs:0.78571 (r=1.000,p=0.647),  time:33.914, tt:1560.041\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.06301, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:33.918, tt:1594.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00007, loss_test:0.06256, lr:1.00e-02, fs:0.78884 (r=1.000,p=0.651),  time:33.907, tt:1627.560\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.06246, lr:1.00e-02, fs:0.78571 (r=1.000,p=0.647),  time:33.945, tt:1663.308\n",
      "Ep:49, loss:0.00007, loss_test:0.06223, lr:1.00e-02, fs:0.78884 (r=1.000,p=0.651),  time:33.960, tt:1698.000\n",
      "Ep:50, loss:0.00007, loss_test:0.06186, lr:1.00e-02, fs:0.79200 (r=1.000,p=0.656),  time:34.011, tt:1734.572\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06185, lr:1.00e-02, fs:0.79200 (r=1.000,p=0.656),  time:34.055, tt:1770.852\n",
      "Ep:52, loss:0.00007, loss_test:0.06162, lr:1.00e-02, fs:0.79518 (r=1.000,p=0.660),  time:34.070, tt:1805.725\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.06135, lr:1.00e-02, fs:0.79518 (r=1.000,p=0.660),  time:34.093, tt:1841.013\n",
      "Ep:54, loss:0.00006, loss_test:0.06109, lr:1.00e-02, fs:0.79200 (r=1.000,p=0.656),  time:34.085, tt:1874.695\n",
      "Ep:55, loss:0.00006, loss_test:0.06118, lr:1.00e-02, fs:0.79839 (r=1.000,p=0.664),  time:34.086, tt:1908.825\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.06056, lr:1.00e-02, fs:0.79518 (r=1.000,p=0.660),  time:34.085, tt:1942.857\n",
      "Ep:57, loss:0.00006, loss_test:0.06030, lr:1.00e-02, fs:0.80162 (r=1.000,p=0.669),  time:34.113, tt:1978.564\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.06012, lr:1.00e-02, fs:0.80162 (r=1.000,p=0.669),  time:34.120, tt:2013.067\n",
      "Ep:59, loss:0.00006, loss_test:0.06014, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:34.138, tt:2048.263\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.05974, lr:1.00e-02, fs:0.80488 (r=1.000,p=0.673),  time:34.141, tt:2082.599\n",
      "Ep:61, loss:0.00006, loss_test:0.05961, lr:1.00e-02, fs:0.81148 (r=1.000,p=0.683),  time:34.167, tt:2118.330\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.05950, lr:1.00e-02, fs:0.82158 (r=1.000,p=0.697),  time:34.146, tt:2151.225\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.05925, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:34.145, tt:2185.309\n",
      "Ep:64, loss:0.00005, loss_test:0.05895, lr:1.00e-02, fs:0.81818 (r=1.000,p=0.692),  time:34.178, tt:2221.595\n",
      "Ep:65, loss:0.00005, loss_test:0.05898, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:34.172, tt:2255.342\n",
      "Ep:66, loss:0.00005, loss_test:0.05918, lr:1.00e-02, fs:0.82158 (r=1.000,p=0.697),  time:34.198, tt:2291.264\n",
      "Ep:67, loss:0.00005, loss_test:0.05840, lr:1.00e-02, fs:0.81148 (r=1.000,p=0.683),  time:34.224, tt:2327.247\n",
      "Ep:68, loss:0.00005, loss_test:0.05900, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:34.232, tt:2361.986\n",
      "Ep:69, loss:0.00005, loss_test:0.05913, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:34.215, tt:2395.053\n",
      "Ep:70, loss:0.00005, loss_test:0.05845, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:34.225, tt:2429.999\n",
      "Ep:71, loss:0.00005, loss_test:0.05882, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:34.246, tt:2465.696\n",
      "Ep:72, loss:0.00005, loss_test:0.05884, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:34.258, tt:2500.803\n",
      "Ep:73, loss:0.00005, loss_test:0.05869, lr:1.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:34.251, tt:2534.557\n",
      "Ep:74, loss:0.00005, loss_test:0.05815, lr:9.90e-03, fs:0.81328 (r=0.990,p=0.690),  time:34.258, tt:2569.335\n",
      "Ep:75, loss:0.00004, loss_test:0.05842, lr:9.80e-03, fs:0.81667 (r=0.990,p=0.695),  time:34.240, tt:2602.234\n",
      "Ep:76, loss:0.00004, loss_test:0.05867, lr:9.70e-03, fs:0.81172 (r=0.980,p=0.693),  time:34.238, tt:2636.301\n",
      "Ep:77, loss:0.00004, loss_test:0.05824, lr:9.61e-03, fs:0.80328 (r=0.990,p=0.676),  time:34.236, tt:2670.445\n",
      "Ep:78, loss:0.00004, loss_test:0.05838, lr:9.51e-03, fs:0.80833 (r=0.980,p=0.688),  time:34.250, tt:2705.740\n",
      "Ep:79, loss:0.00004, loss_test:0.05846, lr:9.41e-03, fs:0.81172 (r=0.980,p=0.693),  time:34.240, tt:2739.231\n",
      "Ep:80, loss:0.00004, loss_test:0.05802, lr:9.32e-03, fs:0.81328 (r=0.990,p=0.690),  time:34.235, tt:2773.022\n",
      "Ep:81, loss:0.00004, loss_test:0.05809, lr:9.23e-03, fs:0.81857 (r=0.980,p=0.703),  time:34.237, tt:2807.454\n",
      "Ep:82, loss:0.00004, loss_test:0.05800, lr:9.14e-03, fs:0.80833 (r=0.980,p=0.688),  time:34.256, tt:2843.244\n",
      "Ep:83, loss:0.00004, loss_test:0.05783, lr:9.04e-03, fs:0.81172 (r=0.980,p=0.693),  time:34.254, tt:2877.324\n",
      "Ep:84, loss:0.00004, loss_test:0.05748, lr:8.95e-03, fs:0.81857 (r=0.980,p=0.703),  time:34.249, tt:2911.160\n",
      "Ep:85, loss:0.00004, loss_test:0.05788, lr:8.86e-03, fs:0.80833 (r=0.980,p=0.688),  time:34.256, tt:2946.023\n",
      "Ep:86, loss:0.00004, loss_test:0.05794, lr:8.78e-03, fs:0.81013 (r=0.970,p=0.696),  time:34.274, tt:2981.806\n",
      "Ep:87, loss:0.00004, loss_test:0.05767, lr:8.69e-03, fs:0.81172 (r=0.980,p=0.693),  time:34.299, tt:3018.353\n",
      "Ep:88, loss:0.00004, loss_test:0.05788, lr:8.60e-03, fs:0.80833 (r=0.980,p=0.688),  time:34.300, tt:3052.733\n",
      "Ep:89, loss:0.00004, loss_test:0.05790, lr:8.51e-03, fs:0.81356 (r=0.970,p=0.701),  time:34.311, tt:3087.977\n",
      "Ep:90, loss:0.00004, loss_test:0.05734, lr:8.43e-03, fs:0.80672 (r=0.970,p=0.691),  time:34.307, tt:3121.948\n",
      "Ep:91, loss:0.00004, loss_test:0.05753, lr:8.35e-03, fs:0.80335 (r=0.970,p=0.686),  time:34.283, tt:3154.016\n",
      "Ep:92, loss:0.00004, loss_test:0.05794, lr:8.26e-03, fs:0.80687 (r=0.949,p=0.701),  time:34.276, tt:3187.687\n",
      "Ep:93, loss:0.00003, loss_test:0.05740, lr:8.18e-03, fs:0.80335 (r=0.970,p=0.686),  time:34.291, tt:3223.321\n",
      "Ep:94, loss:0.00003, loss_test:0.05761, lr:8.10e-03, fs:0.80335 (r=0.970,p=0.686),  time:34.260, tt:3254.678\n",
      "Ep:95, loss:0.00003, loss_test:0.05791, lr:8.02e-03, fs:0.79310 (r=0.929,p=0.692),  time:34.254, tt:3288.417\n",
      "Ep:96, loss:0.00003, loss_test:0.05727, lr:7.94e-03, fs:0.80169 (r=0.960,p=0.688),  time:34.253, tt:3322.568\n",
      "Ep:97, loss:0.00003, loss_test:0.05754, lr:7.86e-03, fs:0.79832 (r=0.960,p=0.683),  time:34.250, tt:3356.502\n",
      "Ep:98, loss:0.00003, loss_test:0.05735, lr:7.78e-03, fs:0.80000 (r=0.949,p=0.691),  time:34.240, tt:3389.712\n",
      "Ep:99, loss:0.00003, loss_test:0.05721, lr:7.70e-03, fs:0.79498 (r=0.960,p=0.679),  time:34.239, tt:3423.871\n",
      "Ep:100, loss:0.00003, loss_test:0.05746, lr:7.62e-03, fs:0.79310 (r=0.929,p=0.692),  time:34.235, tt:3457.746\n",
      "Ep:101, loss:0.00003, loss_test:0.05736, lr:7.55e-03, fs:0.78970 (r=0.929,p=0.687),  time:34.231, tt:3491.592\n",
      "Ep:102, loss:0.00003, loss_test:0.05687, lr:7.47e-03, fs:0.79167 (r=0.960,p=0.674),  time:34.230, tt:3525.679\n",
      "Ep:103, loss:0.00003, loss_test:0.05746, lr:7.40e-03, fs:0.79476 (r=0.919,p=0.700),  time:34.205, tt:3557.321\n",
      "Ep:104, loss:0.00003, loss_test:0.05722, lr:7.32e-03, fs:0.78112 (r=0.919,p=0.679),  time:34.201, tt:3591.061\n",
      "Ep:105, loss:0.00003, loss_test:0.05702, lr:7.25e-03, fs:0.78448 (r=0.919,p=0.684),  time:34.207, tt:3625.949\n",
      "Ep:106, loss:0.00003, loss_test:0.05705, lr:7.18e-03, fs:0.77778 (r=0.919,p=0.674),  time:34.200, tt:3659.420\n",
      "Ep:107, loss:0.00003, loss_test:0.05709, lr:7.11e-03, fs:0.79476 (r=0.919,p=0.700),  time:34.209, tt:3694.619\n",
      "Ep:108, loss:0.00003, loss_test:0.05673, lr:7.03e-03, fs:0.79325 (r=0.949,p=0.681),  time:34.204, tt:3728.201\n",
      "Ep:109, loss:0.00003, loss_test:0.05695, lr:6.96e-03, fs:0.79825 (r=0.919,p=0.705),  time:34.200, tt:3761.993\n",
      "Ep:110, loss:0.00003, loss_test:0.05699, lr:6.89e-03, fs:0.78112 (r=0.919,p=0.679),  time:34.204, tt:3796.596\n",
      "Ep:111, loss:0.00003, loss_test:0.05687, lr:6.83e-03, fs:0.79825 (r=0.919,p=0.705),  time:34.201, tt:3830.458\n",
      "Ep:112, loss:0.00003, loss_test:0.05666, lr:6.76e-03, fs:0.79130 (r=0.919,p=0.695),  time:34.205, tt:3865.169\n",
      "Ep:113, loss:0.00003, loss_test:0.05690, lr:6.69e-03, fs:0.78788 (r=0.919,p=0.689),  time:34.202, tt:3899.036\n",
      "Ep:114, loss:0.00003, loss_test:0.05685, lr:6.62e-03, fs:0.79825 (r=0.919,p=0.705),  time:34.185, tt:3931.312\n",
      "Ep:115, loss:0.00003, loss_test:0.05645, lr:6.56e-03, fs:0.78112 (r=0.919,p=0.679),  time:34.188, tt:3965.851\n",
      "Ep:116, loss:0.00003, loss_test:0.05677, lr:6.49e-03, fs:0.79825 (r=0.919,p=0.705),  time:34.204, tt:4001.870\n",
      "Ep:117, loss:0.00003, loss_test:0.05714, lr:6.43e-03, fs:0.79130 (r=0.919,p=0.695),  time:34.198, tt:4035.330\n",
      "Ep:118, loss:0.00003, loss_test:0.05683, lr:6.36e-03, fs:0.78112 (r=0.919,p=0.679),  time:34.208, tt:4070.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00003, loss_test:0.05690, lr:6.30e-03, fs:0.80000 (r=0.909,p=0.714),  time:34.219, tt:4106.260\n",
      "Ep:120, loss:0.00003, loss_test:0.05688, lr:6.24e-03, fs:0.78448 (r=0.919,p=0.684),  time:34.215, tt:4140.014\n",
      "Ep:121, loss:0.00003, loss_test:0.05673, lr:6.17e-03, fs:0.78788 (r=0.919,p=0.689),  time:34.220, tt:4174.797\n",
      "Ep:122, loss:0.00003, loss_test:0.05657, lr:6.11e-03, fs:0.79825 (r=0.919,p=0.705),  time:34.227, tt:4209.888\n",
      "Ep:123, loss:0.00003, loss_test:0.05665, lr:6.05e-03, fs:0.78448 (r=0.919,p=0.684),  time:34.240, tt:4245.777\n",
      "Ep:124, loss:0.00003, loss_test:0.05669, lr:5.99e-03, fs:0.79130 (r=0.919,p=0.695),  time:34.231, tt:4278.852\n",
      "Ep:125, loss:0.00003, loss_test:0.05664, lr:5.93e-03, fs:0.79130 (r=0.919,p=0.695),  time:34.227, tt:4312.546\n",
      "Ep:126, loss:0.00003, loss_test:0.05661, lr:5.87e-03, fs:0.79476 (r=0.919,p=0.700),  time:34.237, tt:4348.045\n",
      "Ep:127, loss:0.00002, loss_test:0.05679, lr:5.81e-03, fs:0.78603 (r=0.909,p=0.692),  time:34.228, tt:4381.212\n",
      "Ep:128, loss:0.00002, loss_test:0.05654, lr:5.75e-03, fs:0.78788 (r=0.919,p=0.689),  time:34.227, tt:4415.345\n",
      "Ep:129, loss:0.00002, loss_test:0.05658, lr:5.70e-03, fs:0.79295 (r=0.909,p=0.703),  time:34.220, tt:4448.633\n",
      "Ep:130, loss:0.00002, loss_test:0.05669, lr:5.64e-03, fs:0.77253 (r=0.909,p=0.672),  time:34.231, tt:4484.300\n",
      "Ep:131, loss:0.00002, loss_test:0.05669, lr:5.58e-03, fs:0.79295 (r=0.909,p=0.703),  time:34.241, tt:4519.848\n",
      "Ep:132, loss:0.00002, loss_test:0.05665, lr:5.53e-03, fs:0.79646 (r=0.909,p=0.709),  time:34.236, tt:4553.376\n",
      "Ep:133, loss:0.00002, loss_test:0.05675, lr:5.47e-03, fs:0.77922 (r=0.909,p=0.682),  time:34.239, tt:4588.089\n",
      "Ep:134, loss:0.00002, loss_test:0.05671, lr:5.42e-03, fs:0.79646 (r=0.909,p=0.709),  time:34.252, tt:4624.039\n",
      "Ep:135, loss:0.00002, loss_test:0.05677, lr:5.36e-03, fs:0.78603 (r=0.909,p=0.692),  time:34.261, tt:4659.473\n",
      "Ep:136, loss:0.00002, loss_test:0.05708, lr:5.31e-03, fs:0.79111 (r=0.899,p=0.706),  time:34.268, tt:4694.687\n",
      "Ep:137, loss:0.00002, loss_test:0.05703, lr:5.26e-03, fs:0.79111 (r=0.899,p=0.706),  time:34.278, tt:4730.302\n",
      "Ep:138, loss:0.00002, loss_test:0.05651, lr:5.20e-03, fs:0.77586 (r=0.909,p=0.677),  time:34.286, tt:4765.752\n",
      "Ep:139, loss:0.00002, loss_test:0.05668, lr:5.15e-03, fs:0.79646 (r=0.909,p=0.709),  time:34.293, tt:4801.079\n",
      "Ep:140, loss:0.00002, loss_test:0.05686, lr:5.10e-03, fs:0.78070 (r=0.899,p=0.690),  time:34.294, tt:4835.406\n",
      "Ep:141, loss:0.00002, loss_test:0.05672, lr:5.05e-03, fs:0.77922 (r=0.909,p=0.682),  time:34.306, tt:4871.405\n",
      "Ep:142, loss:0.00002, loss_test:0.05672, lr:5.00e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.304, tt:4905.499\n",
      "Ep:143, loss:0.00002, loss_test:0.05686, lr:4.95e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.306, tt:4940.082\n",
      "Ep:144, loss:0.00002, loss_test:0.05687, lr:4.90e-03, fs:0.78070 (r=0.899,p=0.690),  time:34.310, tt:4974.957\n",
      "Ep:145, loss:0.00002, loss_test:0.05650, lr:4.85e-03, fs:0.78261 (r=0.909,p=0.687),  time:34.316, tt:5010.125\n",
      "Ep:146, loss:0.00002, loss_test:0.05648, lr:4.80e-03, fs:0.77922 (r=0.909,p=0.682),  time:34.313, tt:5044.079\n",
      "Ep:147, loss:0.00002, loss_test:0.05693, lr:4.75e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.314, tt:5078.495\n",
      "Ep:148, loss:0.00002, loss_test:0.05669, lr:4.71e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.315, tt:5112.921\n",
      "Ep:149, loss:0.00002, loss_test:0.05642, lr:4.66e-03, fs:0.78261 (r=0.909,p=0.687),  time:34.305, tt:5145.728\n",
      "Ep:150, loss:0.00002, loss_test:0.05674, lr:4.61e-03, fs:0.78070 (r=0.899,p=0.690),  time:34.306, tt:5180.275\n",
      "Ep:151, loss:0.00002, loss_test:0.05678, lr:4.57e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.312, tt:5215.454\n",
      "Ep:152, loss:0.00002, loss_test:0.05663, lr:4.52e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.321, tt:5251.074\n",
      "Ep:153, loss:0.00002, loss_test:0.05670, lr:4.48e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.329, tt:5286.597\n",
      "Ep:154, loss:0.00002, loss_test:0.05685, lr:4.43e-03, fs:0.78414 (r=0.899,p=0.695),  time:34.325, tt:5320.348\n",
      "Ep:155, loss:0.00002, loss_test:0.05654, lr:4.39e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.325, tt:5354.735\n",
      "Ep:156, loss:0.00002, loss_test:0.05689, lr:4.34e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.327, tt:5389.410\n",
      "Ep:157, loss:0.00002, loss_test:0.05715, lr:4.30e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.319, tt:5422.456\n",
      "Ep:158, loss:0.00002, loss_test:0.05672, lr:4.26e-03, fs:0.77391 (r=0.899,p=0.679),  time:34.324, tt:5457.483\n",
      "Ep:159, loss:0.00002, loss_test:0.05662, lr:4.21e-03, fs:0.78761 (r=0.899,p=0.701),  time:34.332, tt:5493.046\n",
      "Ep:160, loss:0.00002, loss_test:0.05705, lr:4.17e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.340, tt:5528.669\n",
      "Ep:161, loss:0.00002, loss_test:0.05676, lr:4.13e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.342, tt:5563.368\n",
      "Ep:162, loss:0.00002, loss_test:0.05675, lr:4.09e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.342, tt:5597.697\n",
      "Ep:163, loss:0.00002, loss_test:0.05680, lr:4.05e-03, fs:0.77876 (r=0.889,p=0.693),  time:34.345, tt:5632.541\n",
      "Ep:164, loss:0.00002, loss_test:0.05663, lr:4.01e-03, fs:0.77729 (r=0.899,p=0.685),  time:34.344, tt:5666.791\n",
      "Ep:165, loss:0.00002, loss_test:0.05687, lr:3.97e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.350, tt:5702.118\n",
      "Ep:166, loss:0.00002, loss_test:0.05687, lr:3.93e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.359, tt:5737.969\n",
      "Ep:167, loss:0.00002, loss_test:0.05673, lr:3.89e-03, fs:0.77391 (r=0.899,p=0.679),  time:34.363, tt:5773.065\n",
      "Ep:168, loss:0.00002, loss_test:0.05683, lr:3.85e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.369, tt:5808.404\n",
      "Ep:169, loss:0.00002, loss_test:0.05688, lr:3.81e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.378, tt:5844.196\n",
      "Ep:170, loss:0.00002, loss_test:0.05658, lr:3.77e-03, fs:0.77391 (r=0.899,p=0.679),  time:34.386, tt:5880.088\n",
      "Ep:171, loss:0.00002, loss_test:0.05675, lr:3.73e-03, fs:0.76856 (r=0.889,p=0.677),  time:34.393, tt:5915.629\n",
      "Ep:172, loss:0.00002, loss_test:0.05718, lr:3.70e-03, fs:0.78733 (r=0.879,p=0.713),  time:34.402, tt:5951.521\n",
      "Ep:173, loss:0.00002, loss_test:0.05689, lr:3.66e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.397, tt:5985.067\n",
      "Ep:174, loss:0.00002, loss_test:0.05648, lr:3.62e-03, fs:0.77391 (r=0.899,p=0.679),  time:34.401, tt:6020.186\n",
      "Ep:175, loss:0.00002, loss_test:0.05665, lr:3.59e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.406, tt:6055.468\n",
      "Ep:176, loss:0.00002, loss_test:0.05696, lr:3.55e-03, fs:0.78027 (r=0.879,p=0.702),  time:34.405, tt:6089.643\n",
      "Ep:177, loss:0.00002, loss_test:0.05682, lr:3.52e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.405, tt:6124.073\n",
      "Ep:178, loss:0.00002, loss_test:0.05680, lr:3.48e-03, fs:0.78027 (r=0.879,p=0.702),  time:34.404, tt:6158.253\n",
      "Ep:179, loss:0.00002, loss_test:0.05662, lr:3.45e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.406, tt:6192.996\n",
      "Ep:180, loss:0.00002, loss_test:0.05668, lr:3.41e-03, fs:0.77876 (r=0.889,p=0.693),  time:34.403, tt:6226.974\n",
      "Ep:181, loss:0.00002, loss_test:0.05691, lr:3.38e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.406, tt:6261.953\n",
      "Ep:182, loss:0.00002, loss_test:0.05675, lr:3.34e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.407, tt:6296.520\n",
      "Ep:183, loss:0.00002, loss_test:0.05662, lr:3.31e-03, fs:0.77876 (r=0.889,p=0.693),  time:34.412, tt:6331.827\n",
      "Ep:184, loss:0.00002, loss_test:0.05677, lr:3.28e-03, fs:0.77876 (r=0.889,p=0.693),  time:34.417, tt:6367.202\n",
      "Ep:185, loss:0.00002, loss_test:0.05684, lr:3.24e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.419, tt:6401.895\n",
      "Ep:186, loss:0.00002, loss_test:0.05663, lr:3.21e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.421, tt:6436.817\n",
      "Ep:187, loss:0.00002, loss_test:0.05659, lr:3.18e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.423, tt:6471.484\n",
      "Ep:188, loss:0.00002, loss_test:0.05677, lr:3.15e-03, fs:0.77533 (r=0.889,p=0.688),  time:34.426, tt:6506.433\n",
      "Ep:189, loss:0.00002, loss_test:0.05690, lr:3.12e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.427, tt:6541.215\n",
      "Ep:190, loss:0.00002, loss_test:0.05671, lr:3.09e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.421, tt:6574.346\n",
      "Ep:191, loss:0.00002, loss_test:0.05655, lr:3.05e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.426, tt:6609.713\n",
      "Ep:192, loss:0.00002, loss_test:0.05685, lr:3.02e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.427, tt:6644.317\n",
      "Ep:193, loss:0.00002, loss_test:0.05683, lr:2.99e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.428, tt:6678.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:194, loss:0.00002, loss_test:0.05651, lr:2.96e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.433, tt:6714.346\n",
      "Ep:195, loss:0.00002, loss_test:0.05659, lr:2.93e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.435, tt:6749.201\n",
      "Ep:196, loss:0.00002, loss_test:0.05680, lr:2.90e-03, fs:0.77876 (r=0.889,p=0.693),  time:34.442, tt:6785.160\n",
      "Ep:197, loss:0.00002, loss_test:0.05669, lr:2.88e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.441, tt:6819.414\n",
      "Ep:198, loss:0.00002, loss_test:0.05655, lr:2.85e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.443, tt:6854.146\n",
      "Ep:199, loss:0.00002, loss_test:0.05680, lr:2.82e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.448, tt:6889.546\n",
      "Ep:200, loss:0.00002, loss_test:0.05689, lr:2.79e-03, fs:0.78027 (r=0.879,p=0.702),  time:34.456, tt:6925.733\n",
      "Ep:201, loss:0.00002, loss_test:0.05675, lr:2.76e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.464, tt:6961.812\n",
      "Ep:202, loss:0.00002, loss_test:0.05675, lr:2.73e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.470, tt:6997.435\n",
      "Ep:203, loss:0.00002, loss_test:0.05678, lr:2.71e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.470, tt:7031.878\n",
      "Ep:204, loss:0.00002, loss_test:0.05679, lr:2.68e-03, fs:0.78027 (r=0.879,p=0.702),  time:34.471, tt:7066.618\n",
      "Ep:205, loss:0.00002, loss_test:0.05673, lr:2.65e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.479, tt:7102.596\n",
      "Ep:206, loss:0.00002, loss_test:0.05667, lr:2.63e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.476, tt:7136.603\n",
      "Ep:207, loss:0.00002, loss_test:0.05673, lr:2.60e-03, fs:0.78222 (r=0.889,p=0.698),  time:34.486, tt:7173.000\n",
      "Ep:208, loss:0.00002, loss_test:0.05684, lr:2.57e-03, fs:0.78733 (r=0.879,p=0.713),  time:34.494, tt:7209.239\n",
      "Ep:209, loss:0.00002, loss_test:0.05676, lr:2.55e-03, fs:0.78733 (r=0.879,p=0.713),  time:34.492, tt:7243.424\n",
      "Ep:210, loss:0.00002, loss_test:0.05668, lr:2.52e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.489, tt:7277.180\n",
      "Ep:211, loss:0.00002, loss_test:0.05691, lr:2.50e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.481, tt:7310.055\n",
      "Ep:212, loss:0.00002, loss_test:0.05685, lr:2.47e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.476, tt:7343.442\n",
      "Ep:213, loss:0.00002, loss_test:0.05675, lr:2.45e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.467, tt:7375.913\n",
      "Ep:214, loss:0.00002, loss_test:0.05680, lr:2.42e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.464, tt:7409.824\n",
      "Ep:215, loss:0.00002, loss_test:0.05692, lr:2.40e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.462, tt:7443.879\n",
      "Ep:216, loss:0.00002, loss_test:0.05684, lr:2.38e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.460, tt:7477.830\n",
      "Ep:217, loss:0.00002, loss_test:0.05677, lr:2.35e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.460, tt:7512.182\n",
      "Ep:218, loss:0.00002, loss_test:0.05680, lr:2.33e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.456, tt:7545.755\n",
      "Ep:219, loss:0.00002, loss_test:0.05696, lr:2.31e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.462, tt:7581.592\n",
      "Ep:220, loss:0.00002, loss_test:0.05687, lr:2.28e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.459, tt:7615.435\n",
      "Ep:221, loss:0.00002, loss_test:0.05694, lr:2.26e-03, fs:0.78733 (r=0.879,p=0.713),  time:34.455, tt:7649.060\n",
      "Ep:222, loss:0.00002, loss_test:0.05691, lr:2.24e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.451, tt:7682.542\n",
      "Ep:223, loss:0.00002, loss_test:0.05685, lr:2.21e-03, fs:0.78571 (r=0.889,p=0.704),  time:34.453, tt:7717.534\n",
      "Ep:224, loss:0.00002, loss_test:0.05696, lr:2.19e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.452, tt:7751.773\n",
      "Ep:225, loss:0.00002, loss_test:0.05679, lr:2.17e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.450, tt:7785.773\n",
      "Ep:226, loss:0.00002, loss_test:0.05686, lr:2.15e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.442, tt:7818.340\n",
      "Ep:227, loss:0.00002, loss_test:0.05698, lr:2.13e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.439, tt:7852.047\n",
      "Ep:228, loss:0.00002, loss_test:0.05693, lr:2.11e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.434, tt:7885.345\n",
      "Ep:229, loss:0.00002, loss_test:0.05684, lr:2.08e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.429, tt:7918.631\n",
      "Ep:230, loss:0.00002, loss_test:0.05697, lr:2.06e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.424, tt:7951.860\n",
      "Ep:231, loss:0.00002, loss_test:0.05697, lr:2.04e-03, fs:0.78378 (r=0.879,p=0.707),  time:34.399, tt:7980.569\n",
      "Ep:232, loss:0.00002, loss_test:0.05683, lr:2.02e-03, fs:0.78924 (r=0.889,p=0.710),  time:34.354, tt:8004.384\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00018, loss_test:0.08940, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.755, tt:30.755\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00018, loss_test:0.08788, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.756, tt:63.512\n",
      "Ep:2, loss:0.00017, loss_test:0.08534, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:32.780, tt:98.341\n",
      "Ep:3, loss:0.00017, loss_test:0.08173, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:32.625, tt:130.500\n",
      "Ep:4, loss:0.00016, loss_test:0.07836, lr:1.00e-02, fs:0.67857 (r=0.960,p=0.525),  time:32.594, tt:162.968\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00016, loss_test:0.07621, lr:1.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:32.558, tt:195.346\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00015, loss_test:0.07504, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:32.755, tt:229.286\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00015, loss_test:0.07383, lr:1.00e-02, fs:0.71042 (r=0.929,p=0.575),  time:32.654, tt:261.228\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00015, loss_test:0.07283, lr:1.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:32.843, tt:295.587\n",
      "Ep:9, loss:0.00014, loss_test:0.07263, lr:1.00e-02, fs:0.69597 (r=0.960,p=0.546),  time:32.751, tt:327.513\n",
      "Ep:10, loss:0.00014, loss_test:0.07175, lr:1.00e-02, fs:0.70290 (r=0.980,p=0.548),  time:32.756, tt:360.320\n",
      "Ep:11, loss:0.00014, loss_test:0.06990, lr:1.00e-02, fs:0.70330 (r=0.970,p=0.552),  time:32.794, tt:393.531\n",
      "Ep:12, loss:0.00013, loss_test:0.06815, lr:1.00e-02, fs:0.71698 (r=0.960,p=0.572),  time:32.748, tt:425.730\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00013, loss_test:0.06703, lr:1.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:32.766, tt:458.728\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00013, loss_test:0.06624, lr:1.00e-02, fs:0.71698 (r=0.960,p=0.572),  time:32.872, tt:493.081\n",
      "Ep:15, loss:0.00013, loss_test:0.06574, lr:1.00e-02, fs:0.71795 (r=0.990,p=0.563),  time:32.897, tt:526.353\n",
      "Ep:16, loss:0.00012, loss_test:0.06485, lr:1.00e-02, fs:0.72059 (r=0.990,p=0.566),  time:32.874, tt:558.853\n",
      "Ep:17, loss:0.00012, loss_test:0.06367, lr:1.00e-02, fs:0.73684 (r=0.990,p=0.587),  time:32.864, tt:591.548\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00012, loss_test:0.06290, lr:1.00e-02, fs:0.74419 (r=0.970,p=0.604),  time:32.900, tt:625.097\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.06230, lr:1.00e-02, fs:0.75294 (r=0.970,p=0.615),  time:32.773, tt:655.466\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.06162, lr:1.00e-02, fs:0.76265 (r=0.990,p=0.620),  time:32.779, tt:688.367\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.06119, lr:1.00e-02, fs:0.75285 (r=1.000,p=0.604),  time:32.775, tt:721.056\n",
      "Ep:22, loss:0.00011, loss_test:0.06074, lr:1.00e-02, fs:0.75285 (r=1.000,p=0.604),  time:32.694, tt:751.952\n",
      "Ep:23, loss:0.00011, loss_test:0.06034, lr:1.00e-02, fs:0.77043 (r=1.000,p=0.627),  time:32.702, tt:784.839\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.05990, lr:1.00e-02, fs:0.77165 (r=0.990,p=0.632),  time:32.704, tt:817.600\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.05937, lr:1.00e-02, fs:0.76448 (r=1.000,p=0.619),  time:32.674, tt:849.532\n",
      "Ep:26, loss:0.00010, loss_test:0.05897, lr:1.00e-02, fs:0.77043 (r=1.000,p=0.627),  time:32.672, tt:882.150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00010, loss_test:0.05865, lr:1.00e-02, fs:0.77344 (r=1.000,p=0.631),  time:32.676, tt:914.924\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.05841, lr:1.00e-02, fs:0.77344 (r=1.000,p=0.631),  time:32.777, tt:950.526\n",
      "Ep:29, loss:0.00010, loss_test:0.05818, lr:1.00e-02, fs:0.77344 (r=1.000,p=0.631),  time:32.846, tt:985.382\n",
      "Ep:30, loss:0.00010, loss_test:0.05788, lr:1.00e-02, fs:0.77043 (r=1.000,p=0.627),  time:32.836, tt:1017.925\n",
      "Ep:31, loss:0.00009, loss_test:0.05733, lr:1.00e-02, fs:0.77344 (r=1.000,p=0.631),  time:32.882, tt:1052.208\n",
      "Ep:32, loss:0.00009, loss_test:0.05692, lr:1.00e-02, fs:0.77344 (r=1.000,p=0.631),  time:32.914, tt:1086.163\n",
      "Ep:33, loss:0.00009, loss_test:0.05662, lr:1.00e-02, fs:0.77470 (r=0.990,p=0.636),  time:32.944, tt:1120.111\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.05645, lr:1.00e-02, fs:0.77778 (r=0.990,p=0.641),  time:32.964, tt:1153.731\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.05622, lr:1.00e-02, fs:0.77778 (r=0.990,p=0.641),  time:32.964, tt:1186.686\n",
      "Ep:36, loss:0.00009, loss_test:0.05599, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:32.977, tt:1220.133\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.05575, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:32.985, tt:1253.448\n",
      "Ep:38, loss:0.00008, loss_test:0.05556, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:33.020, tt:1287.795\n",
      "Ep:39, loss:0.00008, loss_test:0.05531, lr:1.00e-02, fs:0.77778 (r=0.990,p=0.641),  time:33.041, tt:1321.621\n",
      "Ep:40, loss:0.00008, loss_test:0.05504, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:33.044, tt:1354.813\n",
      "Ep:41, loss:0.00008, loss_test:0.05492, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:33.024, tt:1387.029\n",
      "Ep:42, loss:0.00008, loss_test:0.05473, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:33.034, tt:1420.482\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.05457, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:33.049, tt:1454.167\n",
      "Ep:44, loss:0.00008, loss_test:0.05439, lr:1.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:33.072, tt:1488.226\n",
      "Ep:45, loss:0.00007, loss_test:0.05425, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:33.091, tt:1522.178\n",
      "Ep:46, loss:0.00007, loss_test:0.05386, lr:1.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:33.104, tt:1555.893\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.05348, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:33.114, tt:1589.470\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.05312, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:33.122, tt:1622.962\n",
      "Ep:49, loss:0.00007, loss_test:0.05307, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:33.131, tt:1656.570\n",
      "Ep:50, loss:0.00007, loss_test:0.05302, lr:1.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:33.138, tt:1690.020\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.05271, lr:1.00e-02, fs:0.79675 (r=0.990,p=0.667),  time:33.126, tt:1722.532\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.05261, lr:1.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:33.166, tt:1757.788\n",
      "Ep:53, loss:0.00007, loss_test:0.05231, lr:1.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:33.192, tt:1792.361\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.05209, lr:1.00e-02, fs:0.80328 (r=0.990,p=0.676),  time:33.216, tt:1826.872\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.05204, lr:1.00e-02, fs:0.79675 (r=0.990,p=0.667),  time:33.224, tt:1860.547\n",
      "Ep:56, loss:0.00006, loss_test:0.05178, lr:1.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:33.228, tt:1893.990\n",
      "Ep:57, loss:0.00006, loss_test:0.05155, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:33.250, tt:1928.514\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.05157, lr:1.00e-02, fs:0.79675 (r=0.990,p=0.667),  time:33.266, tt:1962.691\n",
      "Ep:59, loss:0.00006, loss_test:0.05143, lr:1.00e-02, fs:0.80328 (r=0.990,p=0.676),  time:33.284, tt:1997.013\n",
      "Ep:60, loss:0.00006, loss_test:0.05126, lr:1.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:33.284, tt:2030.348\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.05101, lr:1.00e-02, fs:0.80328 (r=0.990,p=0.676),  time:33.275, tt:2063.071\n",
      "Ep:62, loss:0.00006, loss_test:0.05082, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:33.280, tt:2096.638\n",
      "Ep:63, loss:0.00006, loss_test:0.05080, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:33.269, tt:2129.190\n",
      "Ep:64, loss:0.00005, loss_test:0.05056, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:33.261, tt:2161.993\n",
      "Ep:65, loss:0.00005, loss_test:0.05025, lr:1.00e-02, fs:0.80658 (r=0.990,p=0.681),  time:33.268, tt:2195.676\n",
      "Ep:66, loss:0.00005, loss_test:0.05028, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:33.269, tt:2229.022\n",
      "Ep:67, loss:0.00005, loss_test:0.04996, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:33.271, tt:2262.411\n",
      "Ep:68, loss:0.00005, loss_test:0.04985, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:33.258, tt:2294.778\n",
      "Ep:69, loss:0.00005, loss_test:0.04974, lr:1.00e-02, fs:0.81667 (r=0.990,p=0.695),  time:33.242, tt:2326.941\n",
      "Ep:70, loss:0.00005, loss_test:0.04958, lr:1.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:33.251, tt:2360.800\n",
      "Ep:71, loss:0.00005, loss_test:0.04936, lr:1.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:33.236, tt:2392.956\n",
      "Ep:72, loss:0.00005, loss_test:0.04924, lr:9.90e-03, fs:0.81328 (r=0.990,p=0.690),  time:33.223, tt:2425.307\n",
      "Ep:73, loss:0.00005, loss_test:0.04910, lr:9.80e-03, fs:0.81328 (r=0.990,p=0.690),  time:33.217, tt:2458.043\n",
      "Ep:74, loss:0.00005, loss_test:0.04907, lr:9.70e-03, fs:0.81857 (r=0.980,p=0.703),  time:33.220, tt:2491.487\n",
      "Ep:75, loss:0.00005, loss_test:0.04857, lr:9.61e-03, fs:0.81667 (r=0.990,p=0.695),  time:33.210, tt:2523.934\n",
      "Ep:76, loss:0.00005, loss_test:0.04855, lr:9.51e-03, fs:0.81667 (r=0.990,p=0.695),  time:33.194, tt:2555.945\n",
      "Ep:77, loss:0.00005, loss_test:0.04864, lr:9.41e-03, fs:0.82203 (r=0.980,p=0.708),  time:33.173, tt:2587.520\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00004, loss_test:0.04818, lr:9.41e-03, fs:0.82008 (r=0.990,p=0.700),  time:33.179, tt:2621.179\n",
      "Ep:79, loss:0.00004, loss_test:0.04799, lr:9.41e-03, fs:0.81667 (r=0.990,p=0.695),  time:33.181, tt:2654.480\n",
      "Ep:80, loss:0.00004, loss_test:0.04808, lr:9.41e-03, fs:0.82203 (r=0.980,p=0.708),  time:33.165, tt:2686.373\n",
      "Ep:81, loss:0.00004, loss_test:0.04806, lr:9.41e-03, fs:0.81857 (r=0.980,p=0.703),  time:33.137, tt:2717.267\n",
      "Ep:82, loss:0.00004, loss_test:0.04776, lr:9.41e-03, fs:0.81513 (r=0.980,p=0.698),  time:33.137, tt:2750.349\n",
      "Ep:83, loss:0.00004, loss_test:0.04775, lr:9.41e-03, fs:0.82553 (r=0.980,p=0.713),  time:33.130, tt:2782.940\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00004, loss_test:0.04753, lr:9.41e-03, fs:0.82906 (r=0.980,p=0.719),  time:33.123, tt:2815.486\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.04736, lr:9.41e-03, fs:0.81857 (r=0.980,p=0.703),  time:33.124, tt:2848.687\n",
      "Ep:86, loss:0.00004, loss_test:0.04733, lr:9.41e-03, fs:0.82553 (r=0.980,p=0.713),  time:33.131, tt:2882.409\n",
      "Ep:87, loss:0.00004, loss_test:0.04699, lr:9.41e-03, fs:0.82553 (r=0.980,p=0.713),  time:33.131, tt:2915.488\n",
      "Ep:88, loss:0.00004, loss_test:0.04708, lr:9.41e-03, fs:0.82906 (r=0.980,p=0.719),  time:33.121, tt:2947.731\n",
      "Ep:89, loss:0.00004, loss_test:0.04730, lr:9.41e-03, fs:0.82203 (r=0.980,p=0.708),  time:33.108, tt:2979.750\n",
      "Ep:90, loss:0.00004, loss_test:0.04676, lr:9.41e-03, fs:0.82906 (r=0.980,p=0.719),  time:33.122, tt:3014.093\n",
      "Ep:91, loss:0.00004, loss_test:0.04692, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.141, tt:3048.932\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.04666, lr:9.41e-03, fs:0.82906 (r=0.980,p=0.719),  time:33.156, tt:3083.475\n",
      "Ep:93, loss:0.00004, loss_test:0.04670, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.166, tt:3117.571\n",
      "Ep:94, loss:0.00004, loss_test:0.04640, lr:9.41e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.172, tt:3151.340\n",
      "Ep:95, loss:0.00004, loss_test:0.04626, lr:9.41e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.166, tt:3183.896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00004, loss_test:0.04629, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.173, tt:3217.782\n",
      "Ep:97, loss:0.00004, loss_test:0.04622, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.168, tt:3250.497\n",
      "Ep:98, loss:0.00003, loss_test:0.04607, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.191, tt:3285.940\n",
      "Ep:99, loss:0.00003, loss_test:0.04616, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.192, tt:3319.206\n",
      "Ep:100, loss:0.00003, loss_test:0.04598, lr:9.41e-03, fs:0.83262 (r=0.980,p=0.724),  time:33.195, tt:3352.736\n",
      "Ep:101, loss:0.00003, loss_test:0.04597, lr:9.41e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.209, tt:3387.309\n",
      "Ep:102, loss:0.00003, loss_test:0.04608, lr:9.41e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.222, tt:3421.825\n",
      "Ep:103, loss:0.00003, loss_test:0.04565, lr:9.32e-03, fs:0.83262 (r=0.980,p=0.724),  time:33.230, tt:3455.876\n",
      "Ep:104, loss:0.00003, loss_test:0.04546, lr:9.23e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.237, tt:3489.850\n",
      "Ep:105, loss:0.00003, loss_test:0.04586, lr:9.14e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.257, tt:3525.289\n",
      "Ep:106, loss:0.00003, loss_test:0.04579, lr:9.04e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.274, tt:3560.284\n",
      "Ep:107, loss:0.00003, loss_test:0.04534, lr:8.95e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.289, tt:3595.187\n",
      "Ep:108, loss:0.00003, loss_test:0.04532, lr:8.86e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.302, tt:3629.949\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00003, loss_test:0.04570, lr:8.86e-03, fs:0.83262 (r=0.980,p=0.724),  time:33.323, tt:3665.571\n",
      "Ep:110, loss:0.00003, loss_test:0.04522, lr:8.86e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.328, tt:3699.373\n",
      "Ep:111, loss:0.00003, loss_test:0.04507, lr:8.86e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.324, tt:3732.332\n",
      "Ep:112, loss:0.00003, loss_test:0.04523, lr:8.86e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.330, tt:3766.315\n",
      "Ep:113, loss:0.00003, loss_test:0.04499, lr:8.86e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.337, tt:3800.469\n",
      "Ep:114, loss:0.00003, loss_test:0.04489, lr:8.86e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.351, tt:3835.355\n",
      "Ep:115, loss:0.00003, loss_test:0.04514, lr:8.86e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.344, tt:3867.894\n",
      "Ep:116, loss:0.00003, loss_test:0.04509, lr:8.86e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.360, tt:3903.085\n",
      "Ep:117, loss:0.00003, loss_test:0.04460, lr:8.86e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.362, tt:3936.735\n",
      "Ep:118, loss:0.00003, loss_test:0.04472, lr:8.86e-03, fs:0.83761 (r=0.990,p=0.726),  time:33.380, tt:3972.242\n",
      "Ep:119, loss:0.00003, loss_test:0.04505, lr:8.86e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.395, tt:4007.342\n",
      "Ep:120, loss:0.00003, loss_test:0.04476, lr:8.78e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.411, tt:4042.705\n",
      "Ep:121, loss:0.00003, loss_test:0.04463, lr:8.69e-03, fs:0.83621 (r=0.980,p=0.729),  time:33.418, tt:4076.952\n",
      "Ep:122, loss:0.00003, loss_test:0.04481, lr:8.60e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.424, tt:4111.123\n",
      "Ep:123, loss:0.00003, loss_test:0.04473, lr:8.51e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.435, tt:4145.946\n",
      "Ep:124, loss:0.00003, loss_test:0.04436, lr:8.43e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.450, tt:4181.213\n",
      "Ep:125, loss:0.00003, loss_test:0.04466, lr:8.35e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.470, tt:4217.232\n",
      "Ep:126, loss:0.00003, loss_test:0.04468, lr:8.26e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.473, tt:4251.086\n",
      "Ep:127, loss:0.00003, loss_test:0.04449, lr:8.18e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.485, tt:4286.037\n",
      "Ep:128, loss:0.00003, loss_test:0.04439, lr:8.10e-03, fs:0.84120 (r=0.990,p=0.731),  time:33.487, tt:4319.781\n",
      "Ep:129, loss:0.00003, loss_test:0.04466, lr:8.02e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.491, tt:4353.831\n",
      "Ep:130, loss:0.00003, loss_test:0.04449, lr:7.94e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.506, tt:4389.236\n",
      "Ep:131, loss:0.00002, loss_test:0.04421, lr:7.86e-03, fs:0.83983 (r=0.980,p=0.735),  time:33.512, tt:4423.635\n",
      "Ep:132, loss:0.00002, loss_test:0.04441, lr:7.78e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.528, tt:4459.195\n",
      "Ep:133, loss:0.00002, loss_test:0.04449, lr:7.70e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.539, tt:4494.288\n",
      "Ep:134, loss:0.00002, loss_test:0.04399, lr:7.62e-03, fs:0.84120 (r=0.990,p=0.731),  time:33.544, tt:4528.427\n",
      "Ep:135, loss:0.00002, loss_test:0.04407, lr:7.55e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.553, tt:4563.194\n",
      "Ep:136, loss:0.00002, loss_test:0.04462, lr:7.47e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.548, tt:4596.010\n",
      "Ep:137, loss:0.00002, loss_test:0.04441, lr:7.40e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.550, tt:4629.867\n",
      "Ep:138, loss:0.00002, loss_test:0.04387, lr:7.32e-03, fs:0.84348 (r=0.980,p=0.740),  time:33.560, tt:4664.773\n",
      "Ep:139, loss:0.00002, loss_test:0.04413, lr:7.25e-03, fs:0.84716 (r=0.980,p=0.746),  time:33.569, tt:4699.709\n",
      "Ep:140, loss:0.00002, loss_test:0.04441, lr:7.18e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.582, tt:4735.036\n",
      "Ep:141, loss:0.00002, loss_test:0.04407, lr:7.11e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.587, tt:4769.304\n",
      "Ep:142, loss:0.00002, loss_test:0.04395, lr:7.03e-03, fs:0.84716 (r=0.980,p=0.746),  time:33.593, tt:4803.800\n",
      "Ep:143, loss:0.00002, loss_test:0.04429, lr:6.96e-03, fs:0.85463 (r=0.980,p=0.758),  time:33.596, tt:4837.843\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00002, loss_test:0.04389, lr:6.96e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.608, tt:4873.131\n",
      "Ep:145, loss:0.00002, loss_test:0.04361, lr:6.96e-03, fs:0.84848 (r=0.990,p=0.742),  time:33.609, tt:4906.871\n",
      "Ep:146, loss:0.00002, loss_test:0.04382, lr:6.96e-03, fs:0.85463 (r=0.980,p=0.758),  time:33.620, tt:4942.106\n",
      "Ep:147, loss:0.00002, loss_test:0.04421, lr:6.96e-03, fs:0.85841 (r=0.980,p=0.764),  time:33.622, tt:4976.090\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00002, loss_test:0.04372, lr:6.96e-03, fs:0.84716 (r=0.980,p=0.746),  time:33.630, tt:5010.851\n",
      "Ep:149, loss:0.00002, loss_test:0.04364, lr:6.96e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.643, tt:5046.442\n",
      "Ep:150, loss:0.00002, loss_test:0.04396, lr:6.96e-03, fs:0.86222 (r=0.980,p=0.770),  time:33.649, tt:5081.012\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00002, loss_test:0.04381, lr:6.96e-03, fs:0.85463 (r=0.980,p=0.758),  time:33.649, tt:5114.584\n",
      "Ep:152, loss:0.00002, loss_test:0.04354, lr:6.96e-03, fs:0.85463 (r=0.980,p=0.758),  time:33.661, tt:5150.187\n",
      "Ep:153, loss:0.00002, loss_test:0.04380, lr:6.96e-03, fs:0.86222 (r=0.980,p=0.770),  time:33.669, tt:5184.985\n",
      "Ep:154, loss:0.00002, loss_test:0.04384, lr:6.96e-03, fs:0.85463 (r=0.980,p=0.758),  time:33.683, tt:5220.828\n",
      "Ep:155, loss:0.00002, loss_test:0.04346, lr:6.96e-03, fs:0.85590 (r=0.990,p=0.754),  time:33.686, tt:5254.951\n",
      "Ep:156, loss:0.00002, loss_test:0.04364, lr:6.96e-03, fs:0.85841 (r=0.980,p=0.764),  time:33.691, tt:5289.486\n",
      "Ep:157, loss:0.00002, loss_test:0.04392, lr:6.96e-03, fs:0.86222 (r=0.980,p=0.770),  time:33.696, tt:5323.969\n",
      "Ep:158, loss:0.00002, loss_test:0.04368, lr:6.96e-03, fs:0.85841 (r=0.980,p=0.764),  time:33.700, tt:5358.241\n",
      "Ep:159, loss:0.00002, loss_test:0.04361, lr:6.96e-03, fs:0.85841 (r=0.980,p=0.764),  time:33.704, tt:5392.604\n",
      "Ep:160, loss:0.00002, loss_test:0.04384, lr:6.96e-03, fs:0.86222 (r=0.980,p=0.770),  time:33.709, tt:5427.147\n",
      "Ep:161, loss:0.00002, loss_test:0.04379, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.705, tt:5460.141\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00002, loss_test:0.04366, lr:6.96e-03, fs:0.86222 (r=0.980,p=0.770),  time:33.712, tt:5495.101\n",
      "Ep:163, loss:0.00002, loss_test:0.04382, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.722, tt:5530.463\n",
      "Ep:164, loss:0.00002, loss_test:0.04358, lr:6.96e-03, fs:0.86222 (r=0.980,p=0.770),  time:33.723, tt:5564.302\n",
      "Ep:165, loss:0.00002, loss_test:0.04349, lr:6.96e-03, fs:0.85841 (r=0.980,p=0.764),  time:33.725, tt:5598.353\n",
      "Ep:166, loss:0.00002, loss_test:0.04377, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.737, tt:5634.048\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00002, loss_test:0.04390, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.745, tt:5669.188\n",
      "Ep:168, loss:0.00002, loss_test:0.04363, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.741, tt:5702.213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:169, loss:0.00002, loss_test:0.04362, lr:6.96e-03, fs:0.85841 (r=0.980,p=0.764),  time:33.752, tt:5737.865\n",
      "Ep:170, loss:0.00002, loss_test:0.04383, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.764, tt:5773.668\n",
      "Ep:171, loss:0.00002, loss_test:0.04352, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.773, tt:5808.930\n",
      "Ep:172, loss:0.00002, loss_test:0.04364, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.783, tt:5844.478\n",
      "Ep:173, loss:0.00002, loss_test:0.04395, lr:6.96e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.784, tt:5878.438\n",
      "##########Best model found so far##########\n",
      "Ep:174, loss:0.00002, loss_test:0.04366, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.795, tt:5914.068\n",
      "Ep:175, loss:0.00002, loss_test:0.04368, lr:6.96e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.799, tt:5948.691\n",
      "Ep:176, loss:0.00002, loss_test:0.04364, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.808, tt:5984.013\n",
      "Ep:177, loss:0.00002, loss_test:0.04376, lr:6.96e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.814, tt:6018.864\n",
      "Ep:178, loss:0.00002, loss_test:0.04355, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.818, tt:6053.356\n",
      "Ep:179, loss:0.00002, loss_test:0.04376, lr:6.96e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.826, tt:6088.745\n",
      "Ep:180, loss:0.00002, loss_test:0.04400, lr:6.96e-03, fs:0.87783 (r=0.980,p=0.795),  time:33.832, tt:6123.564\n",
      "##########Best model found so far##########\n",
      "Ep:181, loss:0.00002, loss_test:0.04332, lr:6.96e-03, fs:0.87111 (r=0.990,p=0.778),  time:33.829, tt:6156.960\n",
      "Ep:182, loss:0.00002, loss_test:0.04357, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.828, tt:6190.517\n",
      "Ep:183, loss:0.00002, loss_test:0.04399, lr:6.96e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.836, tt:6225.896\n",
      "Ep:184, loss:0.00002, loss_test:0.04362, lr:6.96e-03, fs:0.86607 (r=0.980,p=0.776),  time:33.840, tt:6260.449\n",
      "Ep:185, loss:0.00002, loss_test:0.04361, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.828, tt:6292.029\n",
      "Ep:186, loss:0.00002, loss_test:0.04388, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.837, tt:6327.433\n",
      "Ep:187, loss:0.00002, loss_test:0.04365, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.839, tt:6361.652\n",
      "Ep:188, loss:0.00002, loss_test:0.04381, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.842, tt:6396.133\n",
      "Ep:189, loss:0.00002, loss_test:0.04384, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.846, tt:6430.752\n",
      "Ep:190, loss:0.00002, loss_test:0.04376, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.852, tt:6465.734\n",
      "Ep:191, loss:0.00002, loss_test:0.04374, lr:6.96e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.859, tt:6500.901\n",
      "Ep:192, loss:0.00002, loss_test:0.04386, lr:6.89e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.863, tt:6535.560\n",
      "Ep:193, loss:0.00002, loss_test:0.04355, lr:6.83e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.868, tt:6570.447\n",
      "Ep:194, loss:0.00002, loss_test:0.04379, lr:6.76e-03, fs:0.87783 (r=0.980,p=0.795),  time:33.875, tt:6605.582\n",
      "Ep:195, loss:0.00002, loss_test:0.04362, lr:6.69e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.876, tt:6639.734\n",
      "Ep:196, loss:0.00002, loss_test:0.04373, lr:6.62e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.886, tt:6675.449\n",
      "Ep:197, loss:0.00001, loss_test:0.04379, lr:6.56e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.897, tt:6711.513\n",
      "Ep:198, loss:0.00001, loss_test:0.04369, lr:6.49e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.908, tt:6747.772\n",
      "Ep:199, loss:0.00001, loss_test:0.04370, lr:6.43e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.912, tt:6782.370\n",
      "Ep:200, loss:0.00001, loss_test:0.04367, lr:6.36e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.921, tt:6818.181\n",
      "Ep:201, loss:0.00001, loss_test:0.04376, lr:6.30e-03, fs:0.87783 (r=0.980,p=0.795),  time:33.924, tt:6852.588\n",
      "Ep:202, loss:0.00001, loss_test:0.04353, lr:6.24e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.931, tt:6888.030\n",
      "Ep:203, loss:0.00001, loss_test:0.04370, lr:6.17e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.933, tt:6922.269\n",
      "Ep:204, loss:0.00001, loss_test:0.04408, lr:6.11e-03, fs:0.88182 (r=0.980,p=0.802),  time:33.942, tt:6958.016\n",
      "##########Best model found so far##########\n",
      "Ep:205, loss:0.00001, loss_test:0.04376, lr:6.11e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.950, tt:6993.791\n",
      "Ep:206, loss:0.00001, loss_test:0.04378, lr:6.11e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.964, tt:7030.650\n",
      "Ep:207, loss:0.00001, loss_test:0.04405, lr:6.11e-03, fs:0.87387 (r=0.980,p=0.789),  time:33.971, tt:7065.885\n",
      "Ep:208, loss:0.00001, loss_test:0.04379, lr:6.11e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.981, tt:7101.955\n",
      "Ep:209, loss:0.00001, loss_test:0.04363, lr:6.11e-03, fs:0.86996 (r=0.980,p=0.782),  time:33.987, tt:7137.261\n",
      "Ep:210, loss:0.00001, loss_test:0.04413, lr:6.11e-03, fs:0.87783 (r=0.980,p=0.795),  time:33.993, tt:7172.479\n",
      "Ep:211, loss:0.00001, loss_test:0.04427, lr:6.11e-03, fs:0.88182 (r=0.980,p=0.802),  time:34.013, tt:7210.713\n",
      "Ep:212, loss:0.00001, loss_test:0.04372, lr:6.11e-03, fs:0.86996 (r=0.980,p=0.782),  time:34.030, tt:7248.401\n",
      "Ep:213, loss:0.00001, loss_test:0.04399, lr:6.11e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.060, tt:7288.864\n",
      "Ep:214, loss:0.00001, loss_test:0.04406, lr:6.11e-03, fs:0.87783 (r=0.980,p=0.795),  time:34.075, tt:7326.190\n",
      "Ep:215, loss:0.00001, loss_test:0.04367, lr:6.11e-03, fs:0.86996 (r=0.980,p=0.782),  time:34.090, tt:7363.437\n",
      "Ep:216, loss:0.00001, loss_test:0.04403, lr:6.05e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.110, tt:7401.796\n",
      "Ep:217, loss:0.00001, loss_test:0.04398, lr:5.99e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.123, tt:7438.892\n",
      "Ep:218, loss:0.00001, loss_test:0.04391, lr:5.93e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.139, tt:7476.421\n",
      "Ep:219, loss:0.00001, loss_test:0.04389, lr:5.87e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.152, tt:7513.480\n",
      "Ep:220, loss:0.00001, loss_test:0.04419, lr:5.81e-03, fs:0.87783 (r=0.980,p=0.795),  time:34.167, tt:7550.967\n",
      "Ep:221, loss:0.00001, loss_test:0.04401, lr:5.75e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.185, tt:7588.960\n",
      "Ep:222, loss:0.00001, loss_test:0.04384, lr:5.70e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.213, tt:7629.463\n",
      "Ep:223, loss:0.00001, loss_test:0.04429, lr:5.64e-03, fs:0.87783 (r=0.980,p=0.795),  time:34.229, tt:7667.237\n",
      "Ep:224, loss:0.00001, loss_test:0.04408, lr:5.58e-03, fs:0.86996 (r=0.980,p=0.782),  time:34.241, tt:7704.232\n",
      "Ep:225, loss:0.00001, loss_test:0.04403, lr:5.53e-03, fs:0.87783 (r=0.980,p=0.795),  time:34.261, tt:7742.898\n",
      "Ep:226, loss:0.00001, loss_test:0.04412, lr:5.47e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.278, tt:7781.163\n",
      "Ep:227, loss:0.00001, loss_test:0.04398, lr:5.42e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.287, tt:7817.355\n",
      "Ep:228, loss:0.00001, loss_test:0.04404, lr:5.36e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.305, tt:7855.894\n",
      "Ep:229, loss:0.00001, loss_test:0.04412, lr:5.31e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.321, tt:7893.769\n",
      "Ep:230, loss:0.00001, loss_test:0.04416, lr:5.26e-03, fs:0.86878 (r=0.970,p=0.787),  time:34.322, tt:7928.408\n",
      "Ep:231, loss:0.00001, loss_test:0.04418, lr:5.20e-03, fs:0.87387 (r=0.980,p=0.789),  time:34.287, tt:7954.696\n",
      "Ep:232, loss:0.00001, loss_test:0.04428, lr:5.15e-03, fs:0.86486 (r=0.970,p=0.780),  time:34.198, tt:7968.036\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-666b066158c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m233\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;31m#convert from networkx to graph deep library format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid protocol version: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprotocol_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0m_sys_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,233,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00019, loss_test:0.09221, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.848, tt:9.848\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00018, loss_test:0.09137, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.588, tt:19.175\n",
      "Ep:2, loss:0.00018, loss_test:0.09001, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.554, tt:28.663\n",
      "Ep:3, loss:0.00018, loss_test:0.08806, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:9.487, tt:37.950\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00018, loss_test:0.08546, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:9.461, tt:47.304\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00017, loss_test:0.08210, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:9.447, tt:56.683\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00017, loss_test:0.07895, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:9.450, tt:66.149\n",
      "Ep:7, loss:0.00016, loss_test:0.07591, lr:1.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:9.445, tt:75.557\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00016, loss_test:0.07369, lr:1.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:9.444, tt:84.999\n",
      "Ep:9, loss:0.00015, loss_test:0.07196, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:9.458, tt:94.583\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00015, loss_test:0.07106, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:9.458, tt:104.037\n",
      "Ep:11, loss:0.00015, loss_test:0.07036, lr:1.00e-02, fs:0.70330 (r=0.970,p=0.552),  time:9.432, tt:113.180\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00014, loss_test:0.06837, lr:1.00e-02, fs:0.71642 (r=0.970,p=0.568),  time:9.452, tt:122.874\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00014, loss_test:0.06652, lr:1.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:9.464, tt:132.493\n",
      "Ep:14, loss:0.00014, loss_test:0.06524, lr:1.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:9.473, tt:142.092\n",
      "Ep:15, loss:0.00013, loss_test:0.06433, lr:1.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:9.479, tt:151.657\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00013, loss_test:0.06390, lr:1.00e-02, fs:0.71111 (r=0.970,p=0.561),  time:9.484, tt:161.223\n",
      "Ep:17, loss:0.00013, loss_test:0.06295, lr:1.00e-02, fs:0.71642 (r=0.970,p=0.568),  time:9.496, tt:170.926\n",
      "Ep:18, loss:0.00013, loss_test:0.06138, lr:1.00e-02, fs:0.73004 (r=0.970,p=0.585),  time:9.502, tt:180.536\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.06022, lr:1.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:9.508, tt:190.163\n",
      "Ep:20, loss:0.00012, loss_test:0.05978, lr:1.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:9.515, tt:199.810\n",
      "Ep:21, loss:0.00012, loss_test:0.05958, lr:1.00e-02, fs:0.73485 (r=0.980,p=0.588),  time:9.520, tt:209.435\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.05860, lr:1.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:9.524, tt:219.041\n",
      "Ep:23, loss:0.00011, loss_test:0.05740, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:9.523, tt:228.562\n",
      "Ep:24, loss:0.00011, loss_test:0.05677, lr:1.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:9.526, tt:238.141\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.05636, lr:1.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:9.532, tt:247.826\n",
      "Ep:26, loss:0.00011, loss_test:0.05564, lr:1.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:9.532, tt:257.371\n",
      "Ep:27, loss:0.00011, loss_test:0.05464, lr:1.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:9.538, tt:267.065\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.05395, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:9.540, tt:276.675\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.05381, lr:1.00e-02, fs:0.75486 (r=0.980,p=0.614),  time:9.543, tt:286.291\n",
      "Ep:30, loss:0.00010, loss_test:0.05289, lr:1.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:9.545, tt:295.890\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.05220, lr:1.00e-02, fs:0.77419 (r=0.970,p=0.644),  time:9.548, tt:305.551\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.05175, lr:1.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:9.553, tt:315.248\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.05124, lr:1.00e-02, fs:0.77953 (r=1.000,p=0.639),  time:9.552, tt:324.781\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.05070, lr:1.00e-02, fs:0.79518 (r=1.000,p=0.660),  time:9.555, tt:334.420\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.05024, lr:1.00e-02, fs:0.80162 (r=1.000,p=0.669),  time:9.556, tt:344.011\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.05000, lr:1.00e-02, fs:0.78884 (r=1.000,p=0.651),  time:9.556, tt:353.582\n",
      "Ep:37, loss:0.00009, loss_test:0.04955, lr:1.00e-02, fs:0.79518 (r=1.000,p=0.660),  time:9.574, tt:363.802\n",
      "Ep:38, loss:0.00009, loss_test:0.04915, lr:1.00e-02, fs:0.81818 (r=1.000,p=0.692),  time:9.573, tt:373.364\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.04881, lr:1.00e-02, fs:0.80162 (r=1.000,p=0.669),  time:9.573, tt:382.920\n",
      "Ep:40, loss:0.00008, loss_test:0.04838, lr:1.00e-02, fs:0.79839 (r=1.000,p=0.664),  time:9.574, tt:392.521\n",
      "Ep:41, loss:0.00008, loss_test:0.04793, lr:1.00e-02, fs:0.81818 (r=1.000,p=0.692),  time:9.573, tt:402.066\n",
      "Ep:42, loss:0.00008, loss_test:0.04767, lr:1.00e-02, fs:0.80488 (r=1.000,p=0.673),  time:9.575, tt:411.717\n",
      "Ep:43, loss:0.00008, loss_test:0.04747, lr:1.00e-02, fs:0.80162 (r=1.000,p=0.669),  time:9.576, tt:421.357\n",
      "Ep:44, loss:0.00008, loss_test:0.04710, lr:1.00e-02, fs:0.81818 (r=1.000,p=0.692),  time:9.578, tt:430.997\n",
      "Ep:45, loss:0.00008, loss_test:0.04674, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:9.577, tt:440.558\n",
      "Ep:46, loss:0.00008, loss_test:0.04644, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:9.577, tt:450.118\n",
      "Ep:47, loss:0.00008, loss_test:0.04634, lr:1.00e-02, fs:0.80816 (r=1.000,p=0.678),  time:9.577, tt:459.688\n",
      "Ep:48, loss:0.00007, loss_test:0.04614, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:9.576, tt:469.248\n",
      "Ep:49, loss:0.00007, loss_test:0.04578, lr:1.00e-02, fs:0.81148 (r=1.000,p=0.683),  time:9.578, tt:478.906\n",
      "Ep:50, loss:0.00007, loss_test:0.04544, lr:9.90e-03, fs:0.81148 (r=1.000,p=0.683),  time:9.579, tt:488.527\n",
      "Ep:51, loss:0.00007, loss_test:0.04508, lr:9.80e-03, fs:0.81667 (r=0.990,p=0.695),  time:9.579, tt:498.096\n",
      "Ep:52, loss:0.00007, loss_test:0.04483, lr:9.70e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.582, tt:507.855\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.04467, lr:9.70e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.583, tt:517.498\n",
      "Ep:54, loss:0.00007, loss_test:0.04451, lr:9.70e-03, fs:0.81667 (r=0.990,p=0.695),  time:9.583, tt:527.086\n",
      "Ep:55, loss:0.00007, loss_test:0.04418, lr:9.70e-03, fs:0.81667 (r=0.990,p=0.695),  time:9.583, tt:536.636\n",
      "Ep:56, loss:0.00007, loss_test:0.04390, lr:9.70e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.583, tt:546.208\n",
      "Ep:57, loss:0.00007, loss_test:0.04364, lr:9.70e-03, fs:0.81667 (r=0.990,p=0.695),  time:9.582, tt:555.778\n",
      "Ep:58, loss:0.00006, loss_test:0.04340, lr:9.70e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.583, tt:565.381\n",
      "Ep:59, loss:0.00006, loss_test:0.04308, lr:9.70e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.583, tt:574.962\n",
      "Ep:60, loss:0.00006, loss_test:0.04279, lr:9.70e-03, fs:0.82008 (r=0.990,p=0.700),  time:9.583, tt:584.569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.04261, lr:9.70e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.583, tt:594.139\n",
      "Ep:62, loss:0.00006, loss_test:0.04235, lr:9.70e-03, fs:0.82008 (r=0.990,p=0.700),  time:9.583, tt:603.703\n",
      "Ep:63, loss:0.00006, loss_test:0.04211, lr:9.70e-03, fs:0.82008 (r=0.990,p=0.700),  time:9.583, tt:613.290\n",
      "Ep:64, loss:0.00006, loss_test:0.04187, lr:9.61e-03, fs:0.82008 (r=0.990,p=0.700),  time:9.583, tt:622.877\n",
      "Ep:65, loss:0.00006, loss_test:0.04165, lr:9.51e-03, fs:0.82008 (r=0.990,p=0.700),  time:9.584, tt:632.549\n",
      "Ep:66, loss:0.00006, loss_test:0.04143, lr:9.41e-03, fs:0.82008 (r=0.990,p=0.700),  time:9.585, tt:642.177\n",
      "Ep:67, loss:0.00006, loss_test:0.04114, lr:9.32e-03, fs:0.82700 (r=0.990,p=0.710),  time:9.585, tt:651.768\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.04105, lr:9.32e-03, fs:0.82158 (r=1.000,p=0.697),  time:9.586, tt:661.402\n",
      "Ep:69, loss:0.00006, loss_test:0.04085, lr:9.32e-03, fs:0.84120 (r=0.990,p=0.731),  time:9.585, tt:670.973\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.04041, lr:9.32e-03, fs:0.83898 (r=1.000,p=0.723),  time:9.585, tt:680.537\n",
      "Ep:71, loss:0.00005, loss_test:0.04031, lr:9.32e-03, fs:0.83544 (r=1.000,p=0.717),  time:9.587, tt:690.265\n",
      "Ep:72, loss:0.00005, loss_test:0.04029, lr:9.32e-03, fs:0.84120 (r=0.990,p=0.731),  time:9.586, tt:699.785\n",
      "Ep:73, loss:0.00005, loss_test:0.03995, lr:9.32e-03, fs:0.82500 (r=1.000,p=0.702),  time:9.587, tt:709.470\n",
      "Ep:74, loss:0.00005, loss_test:0.03981, lr:9.32e-03, fs:0.84848 (r=0.990,p=0.742),  time:9.587, tt:719.053\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.03984, lr:9.32e-03, fs:0.85217 (r=0.990,p=0.748),  time:9.588, tt:728.666\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00005, loss_test:0.03951, lr:9.32e-03, fs:0.82845 (r=1.000,p=0.707),  time:9.588, tt:738.261\n",
      "Ep:77, loss:0.00005, loss_test:0.03958, lr:9.32e-03, fs:0.85965 (r=0.990,p=0.760),  time:9.589, tt:747.904\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00005, loss_test:0.03911, lr:9.32e-03, fs:0.85590 (r=0.990,p=0.754),  time:9.589, tt:757.528\n",
      "Ep:79, loss:0.00005, loss_test:0.03909, lr:9.32e-03, fs:0.84255 (r=1.000,p=0.728),  time:9.590, tt:767.183\n",
      "Ep:80, loss:0.00005, loss_test:0.03951, lr:9.32e-03, fs:0.86344 (r=0.990,p=0.766),  time:9.590, tt:776.794\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.03864, lr:9.32e-03, fs:0.84615 (r=1.000,p=0.733),  time:9.590, tt:786.403\n",
      "Ep:82, loss:0.00005, loss_test:0.03866, lr:9.32e-03, fs:0.85345 (r=1.000,p=0.744),  time:9.591, tt:796.032\n",
      "Ep:83, loss:0.00005, loss_test:0.03867, lr:9.32e-03, fs:0.85965 (r=0.990,p=0.760),  time:9.591, tt:805.659\n",
      "Ep:84, loss:0.00005, loss_test:0.03843, lr:9.32e-03, fs:0.85345 (r=1.000,p=0.744),  time:9.592, tt:815.286\n",
      "Ep:85, loss:0.00005, loss_test:0.03843, lr:9.32e-03, fs:0.85345 (r=1.000,p=0.744),  time:9.592, tt:824.898\n",
      "Ep:86, loss:0.00004, loss_test:0.03833, lr:9.32e-03, fs:0.85345 (r=1.000,p=0.744),  time:9.592, tt:834.468\n",
      "Ep:87, loss:0.00004, loss_test:0.03821, lr:9.32e-03, fs:0.86087 (r=1.000,p=0.756),  time:9.592, tt:844.066\n",
      "Ep:88, loss:0.00004, loss_test:0.03806, lr:9.32e-03, fs:0.85714 (r=1.000,p=0.750),  time:9.593, tt:853.745\n",
      "Ep:89, loss:0.00004, loss_test:0.03805, lr:9.32e-03, fs:0.86463 (r=1.000,p=0.762),  time:9.593, tt:863.395\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00004, loss_test:0.03785, lr:9.32e-03, fs:0.86087 (r=1.000,p=0.756),  time:9.594, tt:873.062\n",
      "Ep:91, loss:0.00004, loss_test:0.03778, lr:9.32e-03, fs:0.86463 (r=1.000,p=0.762),  time:9.594, tt:882.684\n",
      "Ep:92, loss:0.00004, loss_test:0.03766, lr:9.32e-03, fs:0.86087 (r=1.000,p=0.756),  time:9.595, tt:892.312\n",
      "Ep:93, loss:0.00004, loss_test:0.03789, lr:9.32e-03, fs:0.87500 (r=0.990,p=0.784),  time:9.596, tt:902.055\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00004, loss_test:0.03757, lr:9.32e-03, fs:0.86842 (r=1.000,p=0.767),  time:9.596, tt:911.621\n",
      "Ep:95, loss:0.00004, loss_test:0.03766, lr:9.32e-03, fs:0.87892 (r=0.990,p=0.790),  time:9.596, tt:921.248\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00004, loss_test:0.03716, lr:9.32e-03, fs:0.86087 (r=1.000,p=0.756),  time:9.596, tt:930.817\n",
      "Ep:97, loss:0.00004, loss_test:0.03758, lr:9.32e-03, fs:0.87892 (r=0.990,p=0.790),  time:9.596, tt:940.385\n",
      "Ep:98, loss:0.00004, loss_test:0.03725, lr:9.32e-03, fs:0.86087 (r=1.000,p=0.756),  time:9.597, tt:950.066\n",
      "Ep:99, loss:0.00004, loss_test:0.03737, lr:9.32e-03, fs:0.87500 (r=0.990,p=0.784),  time:9.597, tt:959.699\n",
      "Ep:100, loss:0.00004, loss_test:0.03724, lr:9.32e-03, fs:0.86842 (r=1.000,p=0.767),  time:9.597, tt:969.335\n",
      "Ep:101, loss:0.00004, loss_test:0.03713, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.597, tt:978.919\n",
      "Ep:102, loss:0.00004, loss_test:0.03717, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.597, tt:988.538\n",
      "Ep:103, loss:0.00004, loss_test:0.03707, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.597, tt:998.110\n",
      "Ep:104, loss:0.00004, loss_test:0.03692, lr:9.32e-03, fs:0.88000 (r=1.000,p=0.786),  time:9.598, tt:1007.741\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00003, loss_test:0.03680, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.598, tt:1017.411\n",
      "Ep:106, loss:0.00003, loss_test:0.03678, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.598, tt:1026.992\n",
      "Ep:107, loss:0.00003, loss_test:0.03657, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.598, tt:1036.540\n",
      "Ep:108, loss:0.00003, loss_test:0.03695, lr:9.32e-03, fs:0.87111 (r=0.990,p=0.778),  time:9.597, tt:1046.094\n",
      "Ep:109, loss:0.00003, loss_test:0.03647, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.597, tt:1055.686\n",
      "Ep:110, loss:0.00003, loss_test:0.03655, lr:9.32e-03, fs:0.88000 (r=1.000,p=0.786),  time:9.597, tt:1065.283\n",
      "Ep:111, loss:0.00003, loss_test:0.03660, lr:9.32e-03, fs:0.87111 (r=0.990,p=0.778),  time:9.598, tt:1074.934\n",
      "Ep:112, loss:0.00003, loss_test:0.03622, lr:9.32e-03, fs:0.88000 (r=1.000,p=0.786),  time:9.598, tt:1084.518\n",
      "Ep:113, loss:0.00003, loss_test:0.03655, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.598, tt:1094.128\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00003, loss_test:0.03623, lr:9.32e-03, fs:0.87611 (r=1.000,p=0.780),  time:9.597, tt:1103.651\n",
      "Ep:115, loss:0.00003, loss_test:0.03646, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.597, tt:1113.300\n",
      "Ep:116, loss:0.00003, loss_test:0.03607, lr:9.32e-03, fs:0.88393 (r=1.000,p=0.792),  time:9.598, tt:1122.936\n",
      "Ep:117, loss:0.00003, loss_test:0.03626, lr:9.32e-03, fs:0.88000 (r=1.000,p=0.786),  time:9.598, tt:1132.517\n",
      "Ep:118, loss:0.00003, loss_test:0.03608, lr:9.32e-03, fs:0.88393 (r=1.000,p=0.792),  time:9.597, tt:1142.069\n",
      "Ep:119, loss:0.00003, loss_test:0.03613, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.598, tt:1151.707\n",
      "Ep:120, loss:0.00003, loss_test:0.03611, lr:9.32e-03, fs:0.87500 (r=0.990,p=0.784),  time:9.597, tt:1161.295\n",
      "Ep:121, loss:0.00003, loss_test:0.03578, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.598, tt:1170.963\n",
      "Ep:122, loss:0.00003, loss_test:0.03611, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.598, tt:1180.531\n",
      "Ep:123, loss:0.00003, loss_test:0.03596, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.599, tt:1190.245\n",
      "Ep:124, loss:0.00003, loss_test:0.03580, lr:9.32e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.599, tt:1199.885\n",
      "Ep:125, loss:0.00003, loss_test:0.03583, lr:9.23e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.599, tt:1209.496\n",
      "Ep:126, loss:0.00003, loss_test:0.03566, lr:9.14e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.600, tt:1219.155\n",
      "Ep:127, loss:0.00003, loss_test:0.03606, lr:9.04e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.600, tt:1228.811\n",
      "Ep:128, loss:0.00003, loss_test:0.03529, lr:8.95e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.600, tt:1238.378\n",
      "Ep:129, loss:0.00003, loss_test:0.03568, lr:8.86e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.600, tt:1247.944\n",
      "Ep:130, loss:0.00003, loss_test:0.03551, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.599, tt:1257.524\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00003, loss_test:0.03568, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.600, tt:1267.140\n",
      "Ep:132, loss:0.00003, loss_test:0.03535, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.599, tt:1276.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00003, loss_test:0.03544, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.599, tt:1286.281\n",
      "Ep:134, loss:0.00003, loss_test:0.03536, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.599, tt:1295.930\n",
      "Ep:135, loss:0.00003, loss_test:0.03537, lr:8.78e-03, fs:0.88288 (r=0.990,p=0.797),  time:9.598, tt:1305.381\n",
      "Ep:136, loss:0.00003, loss_test:0.03538, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.598, tt:1314.927\n",
      "Ep:137, loss:0.00003, loss_test:0.03532, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.598, tt:1324.483\n",
      "Ep:138, loss:0.00002, loss_test:0.03521, lr:8.78e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.597, tt:1334.042\n",
      "Ep:139, loss:0.00002, loss_test:0.03535, lr:8.78e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.598, tt:1343.662\n",
      "Ep:140, loss:0.00002, loss_test:0.03546, lr:8.78e-03, fs:0.88288 (r=0.990,p=0.797),  time:9.598, tt:1353.299\n",
      "Ep:141, loss:0.00002, loss_test:0.03542, lr:8.78e-03, fs:0.89091 (r=0.990,p=0.810),  time:9.597, tt:1362.823\n",
      "Ep:142, loss:0.00002, loss_test:0.03486, lr:8.69e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.597, tt:1372.381\n",
      "Ep:143, loss:0.00002, loss_test:0.03552, lr:8.60e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.597, tt:1382.018\n",
      "Ep:144, loss:0.00002, loss_test:0.03473, lr:8.51e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.597, tt:1391.585\n",
      "Ep:145, loss:0.00002, loss_test:0.03554, lr:8.43e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.597, tt:1401.138\n",
      "Ep:146, loss:0.00002, loss_test:0.03514, lr:8.35e-03, fs:0.89091 (r=0.990,p=0.810),  time:9.597, tt:1410.705\n",
      "Ep:147, loss:0.00002, loss_test:0.03479, lr:8.26e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.597, tt:1420.324\n",
      "Ep:148, loss:0.00002, loss_test:0.03535, lr:8.18e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.597, tt:1429.880\n",
      "Ep:149, loss:0.00002, loss_test:0.03476, lr:8.10e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.597, tt:1439.526\n",
      "Ep:150, loss:0.00002, loss_test:0.03505, lr:8.02e-03, fs:0.89091 (r=0.990,p=0.810),  time:9.596, tt:1449.064\n",
      "Ep:151, loss:0.00002, loss_test:0.03506, lr:7.94e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.594, tt:1458.359\n",
      "Ep:152, loss:0.00002, loss_test:0.03456, lr:7.86e-03, fs:0.88789 (r=1.000,p=0.798),  time:9.592, tt:1467.638\n",
      "Ep:153, loss:0.00002, loss_test:0.03525, lr:7.78e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.591, tt:1477.065\n",
      "Ep:154, loss:0.00002, loss_test:0.03498, lr:7.70e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.591, tt:1486.554\n",
      "Ep:155, loss:0.00002, loss_test:0.03456, lr:7.62e-03, fs:0.89189 (r=1.000,p=0.805),  time:9.590, tt:1495.984\n",
      "Ep:156, loss:0.00002, loss_test:0.03518, lr:7.55e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.590, tt:1505.603\n",
      "Ep:157, loss:0.00002, loss_test:0.03473, lr:7.47e-03, fs:0.88288 (r=0.990,p=0.797),  time:9.589, tt:1515.030\n",
      "Ep:158, loss:0.00002, loss_test:0.03463, lr:7.40e-03, fs:0.89091 (r=0.990,p=0.810),  time:9.588, tt:1524.505\n",
      "Ep:159, loss:0.00002, loss_test:0.03479, lr:7.32e-03, fs:0.88288 (r=0.990,p=0.797),  time:9.587, tt:1533.933\n",
      "Ep:160, loss:0.00002, loss_test:0.03476, lr:7.25e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.586, tt:1543.410\n",
      "Ep:161, loss:0.00002, loss_test:0.03456, lr:7.18e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.585, tt:1552.730\n",
      "Ep:162, loss:0.00002, loss_test:0.03474, lr:7.11e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.585, tt:1562.281\n",
      "Ep:163, loss:0.00002, loss_test:0.03474, lr:7.03e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.585, tt:1571.867\n",
      "Ep:164, loss:0.00002, loss_test:0.03449, lr:6.96e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.584, tt:1581.300\n",
      "Ep:165, loss:0.00002, loss_test:0.03465, lr:6.89e-03, fs:0.87783 (r=0.980,p=0.795),  time:9.583, tt:1590.719\n",
      "Ep:166, loss:0.00002, loss_test:0.03456, lr:6.83e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.582, tt:1600.209\n",
      "Ep:167, loss:0.00002, loss_test:0.03453, lr:6.76e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.580, tt:1609.460\n",
      "Ep:168, loss:0.00002, loss_test:0.03470, lr:6.69e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.580, tt:1618.977\n",
      "Ep:169, loss:0.00002, loss_test:0.03466, lr:6.62e-03, fs:0.87783 (r=0.980,p=0.795),  time:9.579, tt:1628.400\n",
      "Ep:170, loss:0.00002, loss_test:0.03443, lr:6.56e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.579, tt:1637.927\n",
      "Ep:171, loss:0.00002, loss_test:0.03482, lr:6.49e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.578, tt:1647.400\n",
      "Ep:172, loss:0.00002, loss_test:0.03476, lr:6.43e-03, fs:0.87783 (r=0.980,p=0.795),  time:9.577, tt:1656.899\n",
      "Ep:173, loss:0.00002, loss_test:0.03439, lr:6.36e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.576, tt:1666.291\n",
      "Ep:174, loss:0.00002, loss_test:0.03466, lr:6.30e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.576, tt:1675.716\n",
      "Ep:175, loss:0.00002, loss_test:0.03465, lr:6.24e-03, fs:0.87783 (r=0.980,p=0.795),  time:9.575, tt:1685.211\n",
      "Ep:176, loss:0.00002, loss_test:0.03450, lr:6.17e-03, fs:0.88688 (r=0.990,p=0.803),  time:9.574, tt:1694.583\n",
      "Ep:177, loss:0.00002, loss_test:0.03472, lr:6.11e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.573, tt:1703.994\n",
      "Ep:178, loss:0.00002, loss_test:0.03459, lr:6.05e-03, fs:0.87783 (r=0.980,p=0.795),  time:9.573, tt:1713.529\n",
      "Ep:179, loss:0.00002, loss_test:0.03457, lr:5.99e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.572, tt:1723.027\n",
      "Ep:180, loss:0.00002, loss_test:0.03453, lr:5.93e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.572, tt:1732.503\n",
      "Ep:181, loss:0.00002, loss_test:0.03455, lr:5.87e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.571, tt:1741.926\n",
      "Ep:182, loss:0.00002, loss_test:0.03455, lr:5.81e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.571, tt:1751.484\n",
      "Ep:183, loss:0.00002, loss_test:0.03460, lr:5.75e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.571, tt:1761.024\n",
      "Ep:184, loss:0.00002, loss_test:0.03461, lr:5.70e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.570, tt:1770.458\n",
      "Ep:185, loss:0.00002, loss_test:0.03451, lr:5.64e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.570, tt:1779.981\n",
      "Ep:186, loss:0.00002, loss_test:0.03452, lr:5.58e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.569, tt:1789.481\n",
      "Ep:187, loss:0.00002, loss_test:0.03457, lr:5.53e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.568, tt:1798.835\n",
      "Ep:188, loss:0.00002, loss_test:0.03457, lr:5.47e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.567, tt:1808.239\n",
      "Ep:189, loss:0.00002, loss_test:0.03464, lr:5.42e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.567, tt:1817.754\n",
      "Ep:190, loss:0.00002, loss_test:0.03458, lr:5.36e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.567, tt:1827.203\n",
      "Ep:191, loss:0.00002, loss_test:0.03457, lr:5.31e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.566, tt:1836.722\n",
      "Ep:192, loss:0.00002, loss_test:0.03461, lr:5.26e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.565, tt:1846.006\n",
      "Ep:193, loss:0.00002, loss_test:0.03460, lr:5.20e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.564, tt:1855.506\n",
      "Ep:194, loss:0.00002, loss_test:0.03452, lr:5.15e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.564, tt:1864.961\n",
      "Ep:195, loss:0.00002, loss_test:0.03463, lr:5.10e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.564, tt:1874.502\n",
      "Ep:196, loss:0.00002, loss_test:0.03463, lr:5.05e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.569, tt:1885.150\n",
      "Ep:197, loss:0.00002, loss_test:0.03454, lr:5.00e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.574, tt:1895.682\n",
      "Ep:198, loss:0.00002, loss_test:0.03459, lr:4.95e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.580, tt:1906.378\n",
      "Ep:199, loss:0.00002, loss_test:0.03471, lr:4.90e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.585, tt:1916.992\n",
      "Ep:200, loss:0.00002, loss_test:0.03458, lr:4.85e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.589, tt:1927.365\n",
      "Ep:201, loss:0.00002, loss_test:0.03455, lr:4.80e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.594, tt:1937.939\n",
      "Ep:202, loss:0.00002, loss_test:0.03468, lr:4.75e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.599, tt:1948.547\n",
      "Ep:203, loss:0.00002, loss_test:0.03463, lr:4.71e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.603, tt:1959.038\n",
      "Ep:204, loss:0.00002, loss_test:0.03462, lr:4.66e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.608, tt:1969.586\n",
      "Ep:205, loss:0.00002, loss_test:0.03470, lr:4.61e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.612, tt:1980.094\n",
      "Ep:206, loss:0.00002, loss_test:0.03462, lr:4.57e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.617, tt:1990.693\n",
      "Ep:207, loss:0.00002, loss_test:0.03468, lr:4.52e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.621, tt:2001.223\n",
      "Ep:208, loss:0.00002, loss_test:0.03462, lr:4.48e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.626, tt:2011.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00002, loss_test:0.03469, lr:4.43e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.630, tt:2022.265\n",
      "Ep:210, loss:0.00002, loss_test:0.03473, lr:4.39e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.634, tt:2032.756\n",
      "Ep:211, loss:0.00002, loss_test:0.03458, lr:4.34e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.638, tt:2043.285\n",
      "Ep:212, loss:0.00002, loss_test:0.03465, lr:4.30e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.642, tt:2053.757\n",
      "Ep:213, loss:0.00002, loss_test:0.03478, lr:4.26e-03, fs:0.88073 (r=0.970,p=0.807),  time:9.646, tt:2064.280\n",
      "Ep:214, loss:0.00002, loss_test:0.03473, lr:4.21e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.650, tt:2074.853\n",
      "Ep:215, loss:0.00002, loss_test:0.03470, lr:4.17e-03, fs:0.88991 (r=0.980,p=0.815),  time:9.655, tt:2085.381\n",
      "Ep:216, loss:0.00002, loss_test:0.03475, lr:4.13e-03, fs:0.88991 (r=0.980,p=0.815),  time:9.658, tt:2095.736\n",
      "Ep:217, loss:0.00002, loss_test:0.03472, lr:4.09e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.662, tt:2106.226\n",
      "Ep:218, loss:0.00002, loss_test:0.03465, lr:4.05e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.666, tt:2116.752\n",
      "Ep:219, loss:0.00002, loss_test:0.03479, lr:4.01e-03, fs:0.88073 (r=0.970,p=0.807),  time:9.669, tt:2127.227\n",
      "Ep:220, loss:0.00002, loss_test:0.03475, lr:3.97e-03, fs:0.87671 (r=0.970,p=0.800),  time:9.673, tt:2137.753\n",
      "Ep:221, loss:0.00002, loss_test:0.03466, lr:3.93e-03, fs:0.88182 (r=0.980,p=0.802),  time:9.677, tt:2148.253\n",
      "Ep:222, loss:0.00002, loss_test:0.03467, lr:3.89e-03, fs:0.88991 (r=0.980,p=0.815),  time:9.681, tt:2158.772\n",
      "Ep:223, loss:0.00002, loss_test:0.03474, lr:3.85e-03, fs:0.87963 (r=0.960,p=0.812),  time:9.685, tt:2169.395\n",
      "Ep:224, loss:0.00002, loss_test:0.03471, lr:3.81e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.689, tt:2179.963\n",
      "Ep:225, loss:0.00001, loss_test:0.03473, lr:3.77e-03, fs:0.88584 (r=0.980,p=0.808),  time:9.692, tt:2190.451\n",
      "Ep:226, loss:0.00001, loss_test:0.03470, lr:3.73e-03, fs:0.87558 (r=0.960,p=0.805),  time:9.696, tt:2200.889\n",
      "Ep:227, loss:0.00001, loss_test:0.03469, lr:3.70e-03, fs:0.87671 (r=0.970,p=0.800),  time:9.700, tt:2211.628\n",
      "Ep:228, loss:0.00001, loss_test:0.03477, lr:3.66e-03, fs:0.87156 (r=0.960,p=0.798),  time:9.704, tt:2222.199\n",
      "Ep:229, loss:0.00001, loss_test:0.03475, lr:3.62e-03, fs:0.88479 (r=0.970,p=0.814),  time:9.707, tt:2232.718\n",
      "Ep:230, loss:0.00001, loss_test:0.03475, lr:3.59e-03, fs:0.87558 (r=0.960,p=0.805),  time:9.711, tt:2243.325\n",
      "Ep:231, loss:0.00001, loss_test:0.03466, lr:3.55e-03, fs:0.87156 (r=0.960,p=0.798),  time:9.715, tt:2253.976\n",
      "Ep:232, loss:0.00001, loss_test:0.03466, lr:3.52e-03, fs:0.87558 (r=0.960,p=0.805),  time:9.719, tt:2264.543\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits4\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,233,\"9-9\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "ITERATION: 0\n",
      "ITERATION: 1\n",
      "ITERATION: 2\n",
      "ITERATION: 3\n",
      "ITERATION: 4\n",
      "ITERATION: 5\n",
      "ITERATION: 6\n",
      "ITERATION: 7\n",
      "ITERATION: 8\n",
      "ITERATION: 9\n",
      "ITERATION: 10\n",
      "ITERATION: 11\n",
      "ITERATION: 12\n",
      "ITERATION: 13\n",
      "ITERATION: 14\n",
      "ITERATION: 15\n",
      "ITERATION: 16\n",
      "ITERATION: 17\n",
      "ITERATION: 18\n",
      "ITERATION: 19\n",
      "ITERATION: 20\n",
      "ITERATION: 21\n",
      "ITERATION: 22\n",
      "ITERATION: 23\n",
      "ITERATION: 24\n",
      "ITERATION: 25\n",
      "ITERATION: 26\n",
      "ITERATION: 27\n",
      "ITERATION: 28\n",
      "ITERATION: 29\n",
      "ITERATION: 30\n",
      "ITERATION: 31\n",
      "ITERATION: 32\n",
      "ITERATION: 33\n",
      "ITERATION: 34\n",
      "ITERATION: 35\n",
      "ITERATION: 36\n",
      "ITERATION: 37\n",
      "ITERATION: 38\n",
      "ITERATION: 39\n",
      "ITERATION: 40\n",
      "ITERATION: 41\n",
      "ITERATION: 42\n",
      "ITERATION: 43\n",
      "ITERATION: 44\n",
      "ITERATION: 45\n",
      "ITERATION: 46\n",
      "ITERATION: 47\n",
      "ITERATION: 48\n",
      "ITERATION: 49\n",
      "ITERATION: 50\n",
      "ITERATION: 51\n",
      "ITERATION: 52\n",
      "ITERATION: 53\n",
      "ITERATION: 54\n",
      "ITERATION: 55\n",
      "ITERATION: 56\n",
      "ITERATION: 57\n",
      "ITERATION: 58\n",
      "ITERATION: 59\n",
      "ITERATION: 60\n",
      "ITERATION: 61\n",
      "ITERATION: 62\n",
      "ITERATION: 63\n",
      "ITERATION: 64\n",
      "ITERATION: 65\n",
      "ITERATION: 66\n",
      "ITERATION: 67\n",
      "ITERATION: 68\n",
      "ITERATION: 69\n",
      "ITERATION: 70\n",
      "ITERATION: 71\n",
      "ITERATION: 72\n",
      "ITERATION: 73\n",
      "ITERATION: 74\n",
      "ITERATION: 75\n",
      "ITERATION: 76\n",
      "ITERATION: 77\n",
      "ITERATION: 78\n",
      "ITERATION: 79\n",
      "ITERATION: 80\n",
      "ITERATION: 81\n",
      "ITERATION: 82\n",
      "ITERATION: 83\n",
      "ITERATION: 84\n",
      "ITERATION: 85\n",
      "ITERATION: 86\n",
      "ITERATION: 87\n",
      "ITERATION: 88\n",
      "ITERATION: 89\n",
      "ITERATION: 90\n",
      "ITERATION: 91\n",
      "ITERATION: 92\n",
      "ITERATION: 93\n",
      "ITERATION: 94\n",
      "ITERATION: 95\n",
      "ITERATION: 96\n",
      "ITERATION: 97\n",
      "ITERATION: 98\n",
      "ITERATION: 99\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3996 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1038\n",
      "1074\n",
      "1081\n",
      "1050\n",
      "1051\n",
      "1072\n",
      "260\n",
      "Ep:0, loss:0.00063, loss_test:0.10375, lr:1.00e-02, fs:0.58824 (r=0.556,p=0.625),  time:37.121, tt:37.121\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1028\n",
      "1046\n",
      "1026\n",
      "1028\n",
      "1067\n",
      "399\n",
      "Ep:1, loss:0.00025, loss_test:0.11081, lr:1.00e-02, fs:0.55172 (r=0.485,p=0.640),  time:37.447, tt:74.893\n",
      "1090\n",
      "1057\n",
      "1041\n",
      "1073\n",
      "1058\n",
      "1055\n",
      "252\n",
      "Ep:2, loss:0.00022, loss_test:0.10795, lr:1.00e-02, fs:0.57831 (r=0.485,p=0.716),  time:37.388, tt:112.164\n",
      "1081\n",
      "1075\n",
      "1025\n",
      "1029\n",
      "1042\n",
      "1054\n",
      "320\n",
      "Ep:3, loss:0.00021, loss_test:0.10844, lr:1.00e-02, fs:0.57325 (r=0.455,p=0.776),  time:37.291, tt:149.164\n",
      "1028\n",
      "1025\n",
      "1074\n",
      "1057\n",
      "1035\n",
      "1058\n",
      "349\n",
      "Ep:4, loss:0.00020, loss_test:0.10290, lr:1.00e-02, fs:0.61350 (r=0.505,p=0.781),  time:37.312, tt:186.561\n",
      "##########Best model found so far##########\n",
      "1074\n",
      "1062\n",
      "1077\n",
      "1046\n",
      "1053\n",
      "1055\n",
      "259\n",
      "Ep:5, loss:0.00019, loss_test:0.10203, lr:1.00e-02, fs:0.60494 (r=0.495,p=0.778),  time:37.288, tt:223.728\n",
      "1057\n",
      "1025\n",
      "1064\n",
      "1077\n",
      "1055\n",
      "1076\n",
      "272\n",
      "Ep:6, loss:0.00018, loss_test:0.09562, lr:1.00e-02, fs:0.63529 (r=0.545,p=0.761),  time:37.306, tt:261.139\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1041\n",
      "1031\n",
      "1078\n",
      "1035\n",
      "1042\n",
      "354\n",
      "Ep:7, loss:0.00017, loss_test:0.10346, lr:1.00e-02, fs:0.63226 (r=0.495,p=0.875),  time:37.196, tt:297.568\n",
      "1032\n",
      "1065\n",
      "1056\n",
      "1035\n",
      "1067\n",
      "1027\n",
      "344\n",
      "Ep:8, loss:0.00016, loss_test:0.09729, lr:1.00e-02, fs:0.64242 (r=0.535,p=0.803),  time:37.312, tt:335.812\n",
      "##########Best model found so far##########\n",
      "1063\n",
      "1088\n",
      "1080\n",
      "1039\n",
      "1054\n",
      "1061\n",
      "241\n",
      "Ep:9, loss:0.00015, loss_test:0.09773, lr:1.00e-02, fs:0.62195 (r=0.515,p=0.785),  time:37.273, tt:372.732\n",
      "1049\n",
      "1071\n",
      "1090\n",
      "1048\n",
      "1033\n",
      "1083\n",
      "252\n",
      "Ep:10, loss:0.00015, loss_test:0.08840, lr:1.00e-02, fs:0.63953 (r=0.556,p=0.753),  time:37.251, tt:409.758\n",
      "1050\n",
      "1034\n",
      "1060\n",
      "1039\n",
      "1070\n",
      "1061\n",
      "312\n",
      "Ep:11, loss:0.00014, loss_test:0.09198, lr:1.00e-02, fs:0.64706 (r=0.556,p=0.775),  time:37.183, tt:446.196\n",
      "##########Best model found so far##########\n",
      "1087\n",
      "1078\n",
      "1060\n",
      "1026\n",
      "1039\n",
      "1059\n",
      "277\n",
      "Ep:12, loss:0.00013, loss_test:0.08934, lr:1.00e-02, fs:0.62791 (r=0.545,p=0.740),  time:37.159, tt:483.073\n",
      "1031\n",
      "1057\n",
      "1067\n",
      "1088\n",
      "1035\n",
      "1045\n",
      "303\n",
      "Ep:13, loss:0.00012, loss_test:0.09204, lr:1.00e-02, fs:0.64706 (r=0.556,p=0.775),  time:37.156, tt:520.187\n",
      "1087\n",
      "1049\n",
      "1086\n",
      "1073\n",
      "1039\n",
      "1035\n",
      "257\n",
      "Ep:14, loss:0.00011, loss_test:0.08605, lr:1.00e-02, fs:0.64000 (r=0.566,p=0.737),  time:37.162, tt:557.423\n",
      "1026\n",
      "1076\n",
      "1043\n",
      "1068\n",
      "1069\n",
      "1037\n",
      "307\n",
      "Ep:15, loss:0.00011, loss_test:0.08460, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:37.251, tt:596.009\n",
      "##########Best model found so far##########\n",
      "1055\n",
      "1024\n",
      "1067\n",
      "1053\n",
      "1048\n",
      "1047\n",
      "332\n",
      "Ep:16, loss:0.00011, loss_test:0.08780, lr:1.00e-02, fs:0.65143 (r=0.576,p=0.750),  time:37.267, tt:633.547\n",
      "1041\n",
      "1033\n",
      "1056\n",
      "1082\n",
      "1031\n",
      "1080\n",
      "303\n",
      "Ep:17, loss:0.00010, loss_test:0.08775, lr:1.00e-02, fs:0.61905 (r=0.525,p=0.754),  time:37.209, tt:669.755\n",
      "1046\n",
      "1071\n",
      "1065\n",
      "1077\n",
      "1073\n",
      "1041\n",
      "253\n",
      "Ep:18, loss:0.00009, loss_test:0.08313, lr:1.00e-02, fs:0.68132 (r=0.626,p=0.747),  time:37.208, tt:706.952\n",
      "1072\n",
      "1039\n",
      "1036\n",
      "1028\n",
      "1044\n",
      "1024\n",
      "383\n",
      "Ep:19, loss:0.00009, loss_test:0.08402, lr:1.00e-02, fs:0.64368 (r=0.566,p=0.747),  time:37.167, tt:743.342\n",
      "1049\n",
      "1086\n",
      "1059\n",
      "1045\n",
      "1040\n",
      "1028\n",
      "319\n",
      "Ep:20, loss:0.00009, loss_test:0.08678, lr:1.00e-02, fs:0.62275 (r=0.525,p=0.765),  time:37.177, tt:780.718\n",
      "1053\n",
      "1043\n",
      "1027\n",
      "1057\n",
      "1046\n",
      "1036\n",
      "364\n",
      "Ep:21, loss:0.00008, loss_test:0.08577, lr:1.00e-02, fs:0.63529 (r=0.545,p=0.761),  time:37.173, tt:817.812\n",
      "1033\n",
      "1024\n",
      "1040\n",
      "1035\n",
      "1029\n",
      "1043\n",
      "422\n",
      "Ep:22, loss:0.00008, loss_test:0.08332, lr:1.00e-02, fs:0.62791 (r=0.545,p=0.740),  time:37.208, tt:855.780\n",
      "1053\n",
      "1087\n",
      "1027\n",
      "1053\n",
      "1027\n",
      "1058\n",
      "321\n",
      "Ep:23, loss:0.00008, loss_test:0.08637, lr:1.00e-02, fs:0.64242 (r=0.535,p=0.803),  time:37.206, tt:892.940\n",
      "1066\n",
      "1041\n",
      "1036\n",
      "1073\n",
      "1090\n",
      "1069\n",
      "251\n",
      "Ep:24, loss:0.00007, loss_test:0.07880, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:37.189, tt:929.734\n",
      "##########Best model found so far##########\n",
      "1045\n",
      "1032\n",
      "1038\n",
      "1031\n",
      "1050\n",
      "1096\n",
      "334\n",
      "Ep:25, loss:0.00007, loss_test:0.08356, lr:1.00e-02, fs:0.65517 (r=0.576,p=0.760),  time:37.174, tt:966.534\n",
      "1086\n",
      "1046\n",
      "1036\n",
      "1063\n",
      "1079\n",
      "1071\n",
      "245\n",
      "Ep:26, loss:0.00007, loss_test:0.08148, lr:1.00e-02, fs:0.67797 (r=0.606,p=0.769),  time:37.170, tt:1003.594\n",
      "1026\n",
      "1050\n",
      "1083\n",
      "1061\n",
      "1026\n",
      "1077\n",
      "303\n",
      "Ep:27, loss:0.00006, loss_test:0.07923, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:37.164, tt:1040.601\n",
      "##########Best model found so far##########\n",
      "1051\n",
      "1026\n",
      "1081\n",
      "1040\n",
      "1064\n",
      "1043\n",
      "321\n",
      "Ep:28, loss:0.00006, loss_test:0.07783, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:37.165, tt:1077.796\n",
      "##########Best model found so far##########\n",
      "1074\n",
      "1030\n",
      "1057\n",
      "1077\n",
      "1044\n",
      "1041\n",
      "303\n",
      "Ep:29, loss:0.00006, loss_test:0.07952, lr:1.00e-02, fs:0.65497 (r=0.566,p=0.778),  time:37.162, tt:1114.849\n",
      "1024\n",
      "1075\n",
      "1083\n",
      "1050\n",
      "1040\n",
      "1030\n",
      "324\n",
      "Ep:30, loss:0.00006, loss_test:0.07963, lr:1.00e-02, fs:0.68182 (r=0.606,p=0.779),  time:37.157, tt:1151.876\n",
      "1028\n",
      "1080\n",
      "1033\n",
      "1031\n",
      "1050\n",
      "1027\n",
      "377\n",
      "Ep:31, loss:0.00005, loss_test:0.07892, lr:1.00e-02, fs:0.66286 (r=0.586,p=0.763),  time:37.146, tt:1188.669\n",
      "1081\n",
      "1044\n",
      "1052\n",
      "1064\n",
      "1058\n",
      "1064\n",
      "263\n",
      "Ep:32, loss:0.00005, loss_test:0.07821, lr:1.00e-02, fs:0.67816 (r=0.596,p=0.787),  time:37.135, tt:1225.449\n",
      "1073\n",
      "1046\n",
      "1050\n",
      "1073\n",
      "1030\n",
      "1048\n",
      "306\n",
      "Ep:33, loss:0.00005, loss_test:0.07897, lr:1.00e-02, fs:0.67797 (r=0.606,p=0.769),  time:37.133, tt:1262.508\n",
      "1049\n",
      "1049\n",
      "1034\n",
      "1088\n",
      "1028\n",
      "1048\n",
      "330\n",
      "Ep:34, loss:0.00005, loss_test:0.07829, lr:1.00e-02, fs:0.68208 (r=0.596,p=0.797),  time:37.151, tt:1300.288\n",
      "1043\n",
      "1068\n",
      "1037\n",
      "1092\n",
      "1026\n",
      "1028\n",
      "332\n",
      "Ep:35, loss:0.00005, loss_test:0.07767, lr:1.00e-02, fs:0.67797 (r=0.606,p=0.769),  time:37.142, tt:1337.110\n",
      "1053\n",
      "1062\n",
      "1035\n",
      "1036\n",
      "1030\n",
      "1042\n",
      "368\n",
      "Ep:36, loss:0.00004, loss_test:0.07499, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:37.152, tt:1374.617\n",
      "1087\n",
      "1034\n",
      "1056\n",
      "1094\n",
      "1069\n",
      "1033\n",
      "253\n",
      "Ep:37, loss:0.00004, loss_test:0.07513, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:37.159, tt:1412.052\n",
      "1030\n",
      "1091\n",
      "1027\n",
      "1052\n",
      "1031\n",
      "1084\n",
      "311\n",
      "Ep:38, loss:0.00004, loss_test:0.07820, lr:1.00e-02, fs:0.65497 (r=0.566,p=0.778),  time:37.154, tt:1449.025\n",
      "1031\n",
      "1037\n",
      "1044\n",
      "1081\n",
      "1049\n",
      "1077\n",
      "307\n",
      "Ep:39, loss:0.00004, loss_test:0.07663, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:37.148, tt:1485.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "1038\n",
      "1025\n",
      "1064\n",
      "1030\n",
      "1049\n",
      "378\n",
      "Ep:40, loss:0.00004, loss_test:0.07536, lr:9.90e-03, fs:0.65909 (r=0.586,p=0.753),  time:37.164, tt:1523.706\n",
      "1047\n",
      "1043\n",
      "1069\n",
      "1040\n",
      "1024\n",
      "1058\n",
      "345\n",
      "Ep:41, loss:0.00004, loss_test:0.07946, lr:9.80e-03, fs:0.66667 (r=0.576,p=0.792),  time:37.168, tt:1561.070\n",
      "1079\n",
      "1049\n",
      "1052\n",
      "1031\n",
      "1050\n",
      "1072\n",
      "293\n",
      "Ep:42, loss:0.00003, loss_test:0.07265, lr:9.70e-03, fs:0.68132 (r=0.626,p=0.747),  time:37.206, tt:1599.843\n",
      "1086\n",
      "1079\n",
      "1025\n",
      "1062\n",
      "1052\n",
      "1068\n",
      "254\n",
      "Ep:43, loss:0.00003, loss_test:0.07896, lr:9.61e-03, fs:0.65089 (r=0.556,p=0.786),  time:37.196, tt:1636.613\n",
      "1080\n",
      "1084\n",
      "1083\n",
      "1055\n",
      "1077\n",
      "1033\n",
      "214\n",
      "Ep:44, loss:0.00003, loss_test:0.07818, lr:9.51e-03, fs:0.65089 (r=0.556,p=0.786),  time:37.184, tt:1673.263\n",
      "1041\n",
      "1054\n",
      "1043\n",
      "1083\n",
      "1063\n",
      "1090\n",
      "252\n",
      "Ep:45, loss:0.00003, loss_test:0.07349, lr:9.41e-03, fs:0.65537 (r=0.586,p=0.744),  time:37.185, tt:1710.524\n",
      "1050\n",
      "1062\n",
      "1026\n",
      "1084\n",
      "1080\n",
      "1024\n",
      "300\n",
      "Ep:46, loss:0.00003, loss_test:0.07473, lr:9.32e-03, fs:0.66286 (r=0.586,p=0.763),  time:37.179, tt:1747.396\n",
      "1074\n",
      "1071\n",
      "1035\n",
      "1025\n",
      "1045\n",
      "1077\n",
      "299\n",
      "Ep:47, loss:0.00003, loss_test:0.07605, lr:9.23e-03, fs:0.67045 (r=0.596,p=0.766),  time:37.171, tt:1784.212\n",
      "1037\n",
      "1066\n",
      "1079\n",
      "1054\n",
      "1037\n",
      "1027\n",
      "326\n",
      "Ep:48, loss:0.00003, loss_test:0.07513, lr:9.14e-03, fs:0.65896 (r=0.576,p=0.770),  time:37.186, tt:1822.104\n",
      "1057\n",
      "1040\n",
      "1041\n",
      "1035\n",
      "1031\n",
      "1037\n",
      "385\n",
      "Ep:49, loss:0.00003, loss_test:0.07302, lr:9.04e-03, fs:0.65517 (r=0.576,p=0.760),  time:37.196, tt:1859.775\n",
      "1027\n",
      "1054\n",
      "1068\n",
      "1056\n",
      "1081\n",
      "1077\n",
      "263\n",
      "Ep:50, loss:0.00003, loss_test:0.08144, lr:8.95e-03, fs:0.67485 (r=0.556,p=0.859),  time:37.190, tt:1896.688\n",
      "1049\n",
      "1075\n",
      "1075\n",
      "1072\n",
      "1091\n",
      "1049\n",
      "215\n",
      "Ep:51, loss:0.00003, loss_test:0.07571, lr:8.86e-03, fs:0.65896 (r=0.576,p=0.770),  time:37.178, tt:1933.235\n",
      "1024\n",
      "1025\n",
      "1046\n",
      "1079\n",
      "1046\n",
      "1065\n",
      "341\n",
      "Ep:52, loss:0.00003, loss_test:0.07467, lr:8.78e-03, fs:0.64706 (r=0.556,p=0.775),  time:37.201, tt:1971.632\n",
      "1087\n",
      "1060\n",
      "1075\n",
      "1068\n",
      "1062\n",
      "1032\n",
      "242\n",
      "Ep:53, loss:0.00003, loss_test:0.07757, lr:8.69e-03, fs:0.66279 (r=0.576,p=0.781),  time:37.192, tt:2008.344\n",
      "1058\n",
      "1054\n",
      "1052\n",
      "1058\n",
      "1053\n",
      "1043\n",
      "308\n",
      "Ep:54, loss:0.00003, loss_test:0.07505, lr:8.60e-03, fs:0.63584 (r=0.556,p=0.743),  time:37.200, tt:2046.016\n",
      "1045\n",
      "1046\n",
      "1059\n",
      "1063\n",
      "1044\n",
      "1058\n",
      "311\n",
      "Ep:55, loss:0.00003, loss_test:0.07276, lr:8.51e-03, fs:0.66298 (r=0.606,p=0.732),  time:37.197, tt:2083.020\n",
      "1036\n",
      "1043\n",
      "1028\n",
      "1087\n",
      "1047\n",
      "1036\n",
      "349\n",
      "Ep:56, loss:0.00002, loss_test:0.07276, lr:8.43e-03, fs:0.66667 (r=0.596,p=0.756),  time:37.183, tt:2119.408\n",
      "1062\n",
      "1075\n",
      "1054\n",
      "1042\n",
      "1087\n",
      "1045\n",
      "261\n",
      "Ep:57, loss:0.00002, loss_test:0.07436, lr:8.35e-03, fs:0.66667 (r=0.586,p=0.773),  time:37.180, tt:2156.429\n",
      "1063\n",
      "1070\n",
      "1074\n",
      "1040\n",
      "1075\n",
      "1062\n",
      "242\n",
      "Ep:58, loss:0.00002, loss_test:0.07182, lr:8.26e-03, fs:0.67778 (r=0.616,p=0.753),  time:37.184, tt:2193.841\n",
      "1045\n",
      "1071\n",
      "1036\n",
      "1074\n",
      "1056\n",
      "1085\n",
      "259\n",
      "Ep:59, loss:0.00002, loss_test:0.07016, lr:8.18e-03, fs:0.67778 (r=0.616,p=0.753),  time:37.179, tt:2230.768\n",
      "1074\n",
      "1078\n",
      "1031\n",
      "1030\n",
      "1043\n",
      "1071\n",
      "299\n",
      "Ep:60, loss:0.00002, loss_test:0.07063, lr:8.10e-03, fs:0.68508 (r=0.626,p=0.756),  time:37.160, tt:2266.734\n",
      "1089\n",
      "1050\n",
      "1091\n",
      "1034\n",
      "1046\n",
      "1035\n",
      "281\n",
      "Ep:61, loss:0.00002, loss_test:0.07083, lr:8.02e-03, fs:0.68156 (r=0.616,p=0.762),  time:37.169, tt:2304.508\n",
      "1038\n",
      "1035\n",
      "1046\n",
      "1028\n",
      "1057\n",
      "1050\n",
      "372\n",
      "Ep:62, loss:0.00002, loss_test:0.07283, lr:7.94e-03, fs:0.66286 (r=0.586,p=0.763),  time:37.163, tt:2341.301\n",
      "1024\n",
      "1029\n",
      "1049\n",
      "1040\n",
      "1062\n",
      "1045\n",
      "377\n",
      "Ep:63, loss:0.00002, loss_test:0.07559, lr:7.86e-03, fs:0.65497 (r=0.566,p=0.778),  time:37.163, tt:2378.448\n",
      "1048\n",
      "1030\n",
      "1056\n",
      "1086\n",
      "1070\n",
      "1024\n",
      "312\n",
      "Ep:64, loss:0.00002, loss_test:0.07378, lr:7.78e-03, fs:0.67039 (r=0.606,p=0.750),  time:37.172, tt:2416.180\n",
      "1046\n",
      "1074\n",
      "1048\n",
      "1028\n",
      "1024\n",
      "1048\n",
      "358\n",
      "Ep:65, loss:0.00002, loss_test:0.07206, lr:7.70e-03, fs:0.66667 (r=0.596,p=0.756),  time:37.164, tt:2452.807\n",
      "1028\n",
      "1088\n",
      "1030\n",
      "1043\n",
      "1029\n",
      "1082\n",
      "326\n",
      "Ep:66, loss:0.00002, loss_test:0.07180, lr:7.62e-03, fs:0.67778 (r=0.616,p=0.753),  time:37.167, tt:2490.190\n",
      "1033\n",
      "1055\n",
      "1054\n",
      "1078\n",
      "1086\n",
      "1077\n",
      "243\n",
      "Ep:67, loss:0.00002, loss_test:0.07111, lr:7.55e-03, fs:0.68156 (r=0.616,p=0.762),  time:37.162, tt:2527.039\n",
      "1040\n",
      "1033\n",
      "1040\n",
      "1084\n",
      "1058\n",
      "1068\n",
      "303\n",
      "Ep:68, loss:0.00002, loss_test:0.07245, lr:7.47e-03, fs:0.68539 (r=0.616,p=0.772),  time:37.157, tt:2563.846\n",
      "1024\n",
      "1039\n",
      "1035\n",
      "1024\n",
      "1070\n",
      "1027\n",
      "407\n",
      "Ep:69, loss:0.00002, loss_test:0.07744, lr:7.40e-03, fs:0.64706 (r=0.556,p=0.775),  time:37.096, tt:2596.713\n",
      "1031\n",
      "1030\n",
      "1075\n",
      "1073\n",
      "1086\n",
      "1056\n",
      "275\n",
      "Ep:70, loss:0.00002, loss_test:0.07638, lr:7.32e-03, fs:0.67456 (r=0.576,p=0.814),  time:37.042, tt:2629.997\n",
      "1034\n",
      "1030\n",
      "1036\n",
      "1038\n",
      "1056\n",
      "1053\n",
      "379\n",
      "Ep:71, loss:0.00002, loss_test:0.07415, lr:7.25e-03, fs:0.65882 (r=0.566,p=0.789),  time:36.984, tt:2662.865\n",
      "1036\n",
      "1058\n",
      "1046\n",
      "1088\n",
      "1070\n",
      "1052\n",
      "276\n",
      "Ep:72, loss:0.00002, loss_test:0.07475, lr:7.18e-03, fs:0.64740 (r=0.566,p=0.757),  time:36.925, tt:2695.537\n",
      "1049\n",
      "1036\n",
      "1038\n",
      "1042\n",
      "1058\n",
      "1088\n",
      "315\n",
      "Ep:73, loss:0.00002, loss_test:0.07325, lr:7.11e-03, fs:0.65143 (r=0.576,p=0.750),  time:36.871, tt:2728.425\n",
      "1040\n",
      "1028\n",
      "1058\n",
      "1032\n",
      "1045\n",
      "1051\n",
      "372\n",
      "Ep:74, loss:0.00002, loss_test:0.07281, lr:7.03e-03, fs:0.66667 (r=0.596,p=0.756),  time:36.821, tt:2761.547\n",
      "1078\n",
      "1025\n",
      "1032\n",
      "1030\n",
      "1046\n",
      "1028\n",
      "387\n",
      "Ep:75, loss:0.00002, loss_test:0.07236, lr:6.96e-03, fs:0.65909 (r=0.586,p=0.753),  time:36.767, tt:2794.324\n",
      "1055\n",
      "1072\n",
      "1057\n",
      "1048\n",
      "1030\n",
      "1039\n",
      "325\n",
      "Ep:76, loss:0.00002, loss_test:0.07229, lr:6.89e-03, fs:0.67045 (r=0.596,p=0.766),  time:36.724, tt:2827.738\n",
      "1035\n",
      "1038\n",
      "1049\n",
      "1068\n",
      "1039\n",
      "1073\n",
      "324\n",
      "Ep:77, loss:0.00002, loss_test:0.07572, lr:6.83e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.674, tt:2860.606\n",
      "1052\n",
      "1070\n",
      "1062\n",
      "1037\n",
      "1029\n",
      "1041\n",
      "335\n",
      "Ep:78, loss:0.00002, loss_test:0.07585, lr:6.76e-03, fs:0.65882 (r=0.566,p=0.789),  time:36.623, tt:2893.232\n",
      "1047\n",
      "1054\n",
      "1055\n",
      "1036\n",
      "1081\n",
      "1033\n",
      "320\n",
      "Ep:79, loss:0.00002, loss_test:0.07136, lr:6.69e-03, fs:0.67778 (r=0.616,p=0.753),  time:36.579, tt:2926.353\n",
      "1036\n",
      "1056\n",
      "1051\n",
      "1050\n",
      "1071\n",
      "1025\n",
      "337\n",
      "Ep:80, loss:0.00002, loss_test:0.07584, lr:6.62e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.535, tt:2959.356\n",
      "1038\n",
      "1067\n",
      "1041\n",
      "1054\n",
      "1024\n",
      "1024\n",
      "378\n",
      "Ep:81, loss:0.00001, loss_test:0.07616, lr:6.56e-03, fs:0.65497 (r=0.566,p=0.778),  time:36.486, tt:2991.873\n",
      "1062\n",
      "1059\n",
      "1025\n",
      "1074\n",
      "1075\n",
      "1055\n",
      "276\n",
      "Ep:82, loss:0.00001, loss_test:0.07430, lr:6.49e-03, fs:0.65882 (r=0.566,p=0.789),  time:36.445, tt:3024.920\n",
      "1035\n",
      "1026\n",
      "1043\n",
      "1037\n",
      "1043\n",
      "1024\n",
      "418\n",
      "Ep:83, loss:0.00001, loss_test:0.07318, lr:6.43e-03, fs:0.64773 (r=0.576,p=0.740),  time:36.407, tt:3058.223\n",
      "1027\n",
      "1058\n",
      "1065\n",
      "1052\n",
      "1032\n",
      "1050\n",
      "342\n",
      "Ep:84, loss:0.00001, loss_test:0.07120, lr:6.36e-03, fs:0.67416 (r=0.606,p=0.759),  time:36.369, tt:3091.381\n",
      "1031\n",
      "1029\n",
      "1093\n",
      "1034\n",
      "1061\n",
      "1043\n",
      "335\n",
      "Ep:85, loss:0.00001, loss_test:0.07278, lr:6.30e-03, fs:0.67045 (r=0.596,p=0.766),  time:36.326, tt:3124.077\n",
      "1054\n",
      "1048\n",
      "1068\n",
      "1083\n",
      "1024\n",
      "1030\n",
      "319\n",
      "Ep:86, loss:0.00001, loss_test:0.07211, lr:6.24e-03, fs:0.65143 (r=0.576,p=0.750),  time:36.288, tt:3157.050\n",
      "1081\n",
      "1060\n",
      "1077\n",
      "1030\n",
      "1035\n",
      "1027\n",
      "316\n",
      "Ep:87, loss:0.00001, loss_test:0.07165, lr:6.17e-03, fs:0.66292 (r=0.596,p=0.747),  time:36.248, tt:3189.844\n",
      "1079\n",
      "1027\n",
      "1068\n",
      "1051\n",
      "1062\n",
      "1052\n",
      "287\n",
      "Ep:88, loss:0.00001, loss_test:0.07179, lr:6.11e-03, fs:0.66286 (r=0.586,p=0.763),  time:36.214, tt:3223.070\n",
      "1047\n",
      "1064\n",
      "1094\n",
      "1057\n",
      "1062\n",
      "1033\n",
      "269\n",
      "Ep:89, loss:0.00001, loss_test:0.07304, lr:6.05e-03, fs:0.66279 (r=0.576,p=0.781),  time:36.177, tt:3255.970\n",
      "1060\n",
      "1045\n",
      "1058\n",
      "1035\n",
      "1075\n",
      "1026\n",
      "327\n",
      "Ep:90, loss:0.00001, loss_test:0.07279, lr:5.99e-03, fs:0.65143 (r=0.576,p=0.750),  time:36.141, tt:3288.834\n",
      "1042\n",
      "1043\n",
      "1081\n",
      "1050\n",
      "1044\n",
      "1031\n",
      "335\n",
      "Ep:91, loss:0.00001, loss_test:0.07371, lr:5.93e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.103, tt:3321.469\n",
      "1089\n",
      "1024\n",
      "1074\n",
      "1059\n",
      "1059\n",
      "1036\n",
      "285\n",
      "Ep:92, loss:0.00001, loss_test:0.07527, lr:5.87e-03, fs:0.65476 (r=0.556,p=0.797),  time:36.069, tt:3354.446\n",
      "1026\n",
      "1025\n",
      "1071\n",
      "1062\n",
      "1047\n",
      "1054\n",
      "341\n",
      "Ep:93, loss:0.00001, loss_test:0.07242, lr:5.81e-03, fs:0.66667 (r=0.586,p=0.773),  time:36.032, tt:3387.000\n",
      "1041\n",
      "1091\n",
      "1078\n",
      "1073\n",
      "1078\n",
      "1029\n",
      "236\n",
      "Ep:94, loss:0.00001, loss_test:0.07258, lr:5.75e-03, fs:0.64773 (r=0.576,p=0.740),  time:35.996, tt:3419.609\n",
      "1039\n",
      "1053\n",
      "1033\n",
      "1029\n",
      "1058\n",
      "1032\n",
      "382\n",
      "Ep:95, loss:0.00001, loss_test:0.07161, lr:5.70e-03, fs:0.65909 (r=0.586,p=0.753),  time:35.968, tt:3452.955\n",
      "1089\n",
      "1059\n",
      "1057\n",
      "1042\n",
      "1086\n",
      "1031\n",
      "262\n",
      "Ep:96, loss:0.00001, loss_test:0.07200, lr:5.64e-03, fs:0.64773 (r=0.576,p=0.740),  time:35.935, tt:3485.705\n",
      "1043\n",
      "1035\n",
      "1071\n",
      "1073\n",
      "1033\n",
      "1083\n",
      "288\n",
      "Ep:97, loss:0.00001, loss_test:0.07193, lr:5.58e-03, fs:0.65896 (r=0.576,p=0.770),  time:35.899, tt:3518.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n",
      "1039\n",
      "1055\n",
      "1080\n",
      "1044\n",
      "1091\n",
      "279\n",
      "Ep:98, loss:0.00001, loss_test:0.07274, lr:5.53e-03, fs:0.65896 (r=0.576,p=0.770),  time:35.874, tt:3551.499\n",
      "1028\n",
      "1043\n",
      "1078\n",
      "1044\n",
      "1038\n",
      "1067\n",
      "328\n",
      "Ep:99, loss:0.00001, loss_test:0.07259, lr:5.47e-03, fs:0.66279 (r=0.576,p=0.781),  time:35.843, tt:3584.262\n",
      "1037\n",
      "1033\n",
      "1080\n",
      "1039\n",
      "1067\n",
      "1085\n",
      "285\n",
      "Ep:100, loss:0.00001, loss_test:0.07553, lr:5.42e-03, fs:0.65476 (r=0.556,p=0.797),  time:35.813, tt:3617.082\n",
      "1050\n",
      "1043\n",
      "1080\n",
      "1037\n",
      "1071\n",
      "1029\n",
      "316\n",
      "Ep:101, loss:0.00001, loss_test:0.07329, lr:5.36e-03, fs:0.65882 (r=0.566,p=0.789),  time:35.791, tt:3650.703\n",
      "1056\n",
      "1054\n",
      "1038\n",
      "1071\n",
      "1028\n",
      "1075\n",
      "304\n",
      "Ep:102, loss:0.00001, loss_test:0.07362, lr:5.31e-03, fs:0.66667 (r=0.576,p=0.792),  time:35.758, tt:3683.040\n",
      "1028\n",
      "1091\n",
      "1028\n",
      "1037\n",
      "1045\n",
      "1069\n",
      "328\n",
      "Ep:103, loss:0.00001, loss_test:0.07188, lr:5.26e-03, fs:0.64000 (r=0.566,p=0.737),  time:35.732, tt:3716.144\n",
      "1039\n",
      "1045\n",
      "1092\n",
      "1033\n",
      "1054\n",
      "1058\n",
      "305\n",
      "Ep:104, loss:0.00001, loss_test:0.07189, lr:5.20e-03, fs:0.65517 (r=0.576,p=0.760),  time:35.700, tt:3748.460\n",
      "1026\n",
      "1029\n",
      "1076\n",
      "1073\n",
      "1056\n",
      "1068\n",
      "298\n",
      "Ep:105, loss:0.00001, loss_test:0.07552, lr:5.15e-03, fs:0.66265 (r=0.556,p=0.821),  time:35.674, tt:3781.488\n",
      "1041\n",
      "1046\n",
      "1085\n",
      "1061\n",
      "1081\n",
      "1027\n",
      "285\n",
      "Ep:106, loss:0.00001, loss_test:0.07489, lr:5.10e-03, fs:0.66667 (r=0.566,p=0.812),  time:35.653, tt:3814.830\n",
      "1029\n",
      "1056\n",
      "1055\n",
      "1088\n",
      "1093\n",
      "1043\n",
      "262\n",
      "Ep:107, loss:0.00001, loss_test:0.07152, lr:5.05e-03, fs:0.65143 (r=0.576,p=0.750),  time:35.627, tt:3847.734\n",
      "1032\n",
      "1045\n",
      "1024\n",
      "1046\n",
      "1046\n",
      "1043\n",
      "390\n",
      "Ep:108, loss:0.00001, loss_test:0.07411, lr:5.00e-03, fs:0.65476 (r=0.556,p=0.797),  time:35.604, tt:3880.842\n",
      "1039\n",
      "1038\n",
      "1094\n",
      "1050\n",
      "1033\n",
      "1034\n",
      "338\n",
      "Ep:109, loss:0.00001, loss_test:0.07326, lr:4.95e-03, fs:0.66667 (r=0.576,p=0.792),  time:35.581, tt:3913.889\n",
      "1033\n",
      "1042\n",
      "1047\n",
      "1025\n",
      "1026\n",
      "1055\n",
      "398\n",
      "Ep:110, loss:0.00001, loss_test:0.07224, lr:4.90e-03, fs:0.66279 (r=0.576,p=0.781),  time:35.562, tt:3947.351\n",
      "1070\n",
      "1033\n",
      "1078\n",
      "1059\n",
      "1050\n",
      "1064\n",
      "272\n",
      "Ep:111, loss:0.00001, loss_test:0.07184, lr:4.85e-03, fs:0.64368 (r=0.566,p=0.747),  time:35.536, tt:3980.015\n",
      "1031\n",
      "1028\n",
      "1034\n",
      "1065\n",
      "1046\n",
      "1057\n",
      "365\n",
      "Ep:112, loss:0.00001, loss_test:0.07281, lr:4.80e-03, fs:0.65116 (r=0.566,p=0.767),  time:35.514, tt:4013.088\n",
      "1049\n",
      "1067\n",
      "1027\n",
      "1075\n",
      "1044\n",
      "1030\n",
      "334\n",
      "Ep:113, loss:0.00001, loss_test:0.07354, lr:4.75e-03, fs:0.65497 (r=0.566,p=0.778),  time:35.492, tt:4046.069\n",
      "1097\n",
      "1032\n",
      "1057\n",
      "1072\n",
      "1043\n",
      "1035\n",
      "290\n",
      "Ep:114, loss:0.00001, loss_test:0.07283, lr:4.71e-03, fs:0.64740 (r=0.566,p=0.757),  time:35.470, tt:4079.006\n",
      "1041\n",
      "1046\n",
      "1091\n",
      "1032\n",
      "1076\n",
      "1029\n",
      "311\n",
      "Ep:115, loss:0.00001, loss_test:0.07312, lr:4.66e-03, fs:0.65497 (r=0.566,p=0.778),  time:35.449, tt:4112.093\n",
      "1057\n",
      "1031\n",
      "1053\n",
      "1038\n",
      "1040\n",
      "1075\n",
      "332\n",
      "Ep:116, loss:0.00001, loss_test:0.07267, lr:4.61e-03, fs:0.64740 (r=0.566,p=0.757),  time:35.427, tt:4145.009\n",
      "1032\n",
      "1032\n",
      "1057\n",
      "1040\n",
      "1090\n",
      "1030\n",
      "345\n",
      "Ep:117, loss:0.00001, loss_test:0.07309, lr:4.57e-03, fs:0.64706 (r=0.556,p=0.775),  time:35.403, tt:4177.585\n",
      "1079\n",
      "1041\n",
      "1056\n",
      "1044\n",
      "1069\n",
      "1040\n",
      "297\n",
      "Ep:118, loss:0.00001, loss_test:0.07306, lr:4.52e-03, fs:0.64368 (r=0.566,p=0.747),  time:35.387, tt:4211.005\n",
      "1087\n",
      "1024\n",
      "1055\n",
      "1043\n",
      "1087\n",
      "1061\n",
      "269\n",
      "Ep:119, loss:0.00001, loss_test:0.07160, lr:4.48e-03, fs:0.65143 (r=0.576,p=0.750),  time:35.365, tt:4243.769\n",
      "1074\n",
      "1061\n",
      "1059\n",
      "1032\n",
      "1090\n",
      "1033\n",
      "277\n",
      "Ep:120, loss:0.00001, loss_test:0.07320, lr:4.43e-03, fs:0.65116 (r=0.566,p=0.767),  time:35.343, tt:4276.463\n",
      "1035\n",
      "1026\n",
      "1050\n",
      "1040\n",
      "1042\n",
      "1062\n",
      "371\n",
      "Ep:121, loss:0.00001, loss_test:0.07226, lr:4.39e-03, fs:0.65517 (r=0.576,p=0.760),  time:35.324, tt:4309.483\n",
      "1026\n",
      "1066\n",
      "1033\n",
      "1034\n",
      "1029\n",
      "1065\n",
      "373\n",
      "Ep:122, loss:0.00001, loss_test:0.07224, lr:4.34e-03, fs:0.65116 (r=0.566,p=0.767),  time:35.308, tt:4342.867\n",
      "1048\n",
      "1055\n",
      "1056\n",
      "1038\n",
      "1048\n",
      "1040\n",
      "341\n",
      "Ep:123, loss:0.00001, loss_test:0.07236, lr:4.30e-03, fs:0.64740 (r=0.566,p=0.757),  time:35.286, tt:4375.431\n",
      "1052\n",
      "1079\n",
      "1042\n",
      "1028\n",
      "1055\n",
      "1025\n",
      "345\n",
      "Ep:124, loss:0.00001, loss_test:0.07228, lr:4.26e-03, fs:0.64368 (r=0.566,p=0.747),  time:35.267, tt:4408.435\n",
      "1068\n",
      "1032\n",
      "1070\n",
      "1045\n",
      "1084\n",
      "1034\n",
      "293\n",
      "Ep:125, loss:0.00001, loss_test:0.07228, lr:4.21e-03, fs:0.64740 (r=0.566,p=0.757),  time:35.230, tt:4438.966\n",
      "1044\n",
      "1055\n",
      "1032\n",
      "1064\n",
      "1057\n",
      "1077\n",
      "297\n",
      "Ep:126, loss:0.00001, loss_test:0.07249, lr:4.17e-03, fs:0.64740 (r=0.566,p=0.757),  time:35.172, tt:4466.798\n",
      "1049\n",
      "1072\n",
      "1083\n",
      "1069\n",
      "1087\n",
      "1047\n",
      "219\n",
      "Ep:127, loss:0.00001, loss_test:0.07212, lr:4.13e-03, fs:0.64000 (r=0.566,p=0.737),  time:35.115, tt:4494.746\n",
      "1038\n",
      "1070\n",
      "1046\n",
      "1038\n",
      "1044\n",
      "1028\n",
      "362\n",
      "Ep:128, loss:0.00001, loss_test:0.07255, lr:4.09e-03, fs:0.65116 (r=0.566,p=0.767),  time:35.060, tt:4522.750\n",
      "1046\n",
      "1025\n",
      "1079\n",
      "1055\n",
      "1038\n",
      "1085\n",
      "298\n",
      "Ep:129, loss:0.00001, loss_test:0.07207, lr:4.05e-03, fs:0.65143 (r=0.576,p=0.750),  time:35.005, tt:4550.709\n",
      "1038\n",
      "1034\n",
      "1041\n",
      "1033\n",
      "1074\n",
      "1033\n",
      "373\n",
      "Ep:130, loss:0.00001, loss_test:0.07262, lr:4.01e-03, fs:0.65497 (r=0.566,p=0.778),  time:34.952, tt:4578.673\n",
      "1047\n",
      "1069\n",
      "1025\n",
      "1040\n",
      "1048\n",
      "1052\n",
      "345\n",
      "Ep:131, loss:0.00001, loss_test:0.07331, lr:3.97e-03, fs:0.64706 (r=0.556,p=0.775),  time:34.900, tt:4606.752\n",
      "1051\n",
      "1045\n",
      "1033\n",
      "1085\n",
      "1045\n",
      "1063\n",
      "304\n",
      "Ep:132, loss:0.00001, loss_test:0.07233, lr:3.93e-03, fs:0.65497 (r=0.566,p=0.778),  time:34.847, tt:4634.706\n",
      "1072\n",
      "1024\n",
      "1042\n",
      "1065\n",
      "1063\n",
      "1047\n",
      "313\n",
      "Ep:133, loss:0.00001, loss_test:0.07250, lr:3.89e-03, fs:0.64740 (r=0.566,p=0.757),  time:34.797, tt:4662.766\n",
      "1081\n",
      "1048\n",
      "1091\n",
      "1038\n",
      "1032\n",
      "1027\n",
      "309\n",
      "Ep:134, loss:0.00001, loss_test:0.07215, lr:3.85e-03, fs:0.64773 (r=0.576,p=0.740),  time:34.747, tt:4690.846\n",
      "1061\n",
      "1035\n",
      "1053\n",
      "1060\n",
      "1051\n",
      "1058\n",
      "308\n",
      "Ep:135, loss:0.00001, loss_test:0.07253, lr:3.81e-03, fs:0.65116 (r=0.566,p=0.767),  time:34.698, tt:4718.862\n",
      "1030\n",
      "1044\n",
      "1080\n",
      "1036\n",
      "1024\n",
      "1038\n",
      "374\n",
      "Ep:136, loss:0.00001, loss_test:0.07268, lr:3.77e-03, fs:0.64740 (r=0.566,p=0.757),  time:34.649, tt:4746.910\n",
      "1068\n",
      "1050\n",
      "1041\n",
      "1041\n",
      "1052\n",
      "1068\n",
      "306\n",
      "Ep:137, loss:0.00001, loss_test:0.07265, lr:3.73e-03, fs:0.65116 (r=0.566,p=0.767),  time:34.601, tt:4774.898\n",
      "1044\n",
      "1047\n",
      "1037\n",
      "1038\n",
      "1061\n",
      "1095\n",
      "304\n",
      "Ep:138, loss:0.00001, loss_test:0.07252, lr:3.70e-03, fs:0.64368 (r=0.566,p=0.747),  time:34.554, tt:4803.014\n",
      "1039\n",
      "1035\n",
      "1059\n",
      "1048\n",
      "1054\n",
      "1034\n",
      "357\n",
      "Ep:139, loss:0.00001, loss_test:0.07225, lr:3.66e-03, fs:0.64368 (r=0.566,p=0.747),  time:34.507, tt:4830.936\n",
      "1095\n",
      "1024\n",
      "1049\n",
      "1069\n",
      "1028\n",
      "1070\n",
      "291\n",
      "Ep:140, loss:0.00001, loss_test:0.07227, lr:3.62e-03, fs:0.65116 (r=0.566,p=0.767),  time:34.460, tt:4858.843\n",
      "1046\n",
      "1047\n",
      "1039\n",
      "1069\n",
      "1083\n",
      "1080\n",
      "262\n",
      "Ep:141, loss:0.00001, loss_test:0.07283, lr:3.59e-03, fs:0.65116 (r=0.566,p=0.767),  time:34.414, tt:4886.781\n",
      "1051\n",
      "1094\n",
      "1038\n",
      "1069\n",
      "1035\n",
      "1077\n",
      "262\n",
      "Ep:142, loss:0.00001, loss_test:0.07255, lr:3.55e-03, fs:0.64740 (r=0.566,p=0.757),  time:34.369, tt:4914.800\n",
      "1040\n",
      "1080\n",
      "1031\n",
      "1046\n",
      "1024\n",
      "1025\n",
      "380\n",
      "Ep:143, loss:0.00001, loss_test:0.07221, lr:3.52e-03, fs:0.65517 (r=0.576,p=0.760),  time:34.325, tt:4942.825\n",
      "1028\n",
      "1041\n",
      "1083\n",
      "1057\n",
      "1038\n",
      "1037\n",
      "342\n",
      "Ep:144, loss:0.00001, loss_test:0.07286, lr:3.48e-03, fs:0.65116 (r=0.566,p=0.767),  time:34.281, tt:4970.794\n",
      "1059\n",
      "1031\n",
      "1025\n",
      "1083\n",
      "1036\n",
      "1045\n",
      "347\n",
      "Ep:145, loss:0.00001, loss_test:0.07360, lr:3.45e-03, fs:0.65497 (r=0.566,p=0.778),  time:34.240, tt:4999.089\n",
      "1034\n",
      "1048\n",
      "1034\n",
      "1055\n",
      "1035\n",
      "1038\n",
      "382\n",
      "Ep:146, loss:0.00001, loss_test:0.07380, lr:3.41e-03, fs:0.64706 (r=0.556,p=0.775),  time:34.197, tt:5026.997\n",
      "1047\n",
      "1035\n",
      "1028\n",
      "1042\n",
      "1025\n",
      "1060\n",
      "389\n",
      "Ep:147, loss:0.00001, loss_test:0.07315, lr:3.38e-03, fs:0.64706 (r=0.556,p=0.775),  time:34.155, tt:5055.001\n",
      "1044\n",
      "1046\n",
      "1025\n",
      "1054\n",
      "1076\n",
      "1049\n",
      "332\n",
      "Ep:148, loss:0.00001, loss_test:0.07246, lr:3.34e-03, fs:0.65116 (r=0.566,p=0.767),  time:34.113, tt:5082.788\n",
      "1054\n",
      "1059\n",
      "1050\n",
      "1025\n",
      "1027\n",
      "1049\n",
      "362\n",
      "Ep:149, loss:0.00001, loss_test:0.07215, lr:3.31e-03, fs:0.65896 (r=0.576,p=0.770),  time:34.071, tt:5110.692\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits4\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,\"1-1\",4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 40\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00036, loss_test:0.09387, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.577, tt:17.577\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00035, loss_test:0.09155, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:18.259, tt:36.517\n",
      "Ep:2, loss:0.00034, loss_test:0.08760, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:18.422, tt:55.266\n",
      "Ep:3, loss:0.00033, loss_test:0.08356, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:18.457, tt:73.830\n",
      "Ep:4, loss:0.00032, loss_test:0.07964, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:18.509, tt:92.545\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00031, loss_test:0.07620, lr:1.00e-02, fs:0.69343 (r=0.960,p=0.543),  time:18.546, tt:111.275\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00029, loss_test:0.07511, lr:1.00e-02, fs:0.70330 (r=0.970,p=0.552),  time:18.629, tt:130.403\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00028, loss_test:0.07442, lr:1.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:18.687, tt:149.498\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00027, loss_test:0.07230, lr:1.00e-02, fs:0.71212 (r=0.949,p=0.570),  time:18.730, tt:168.572\n",
      "Ep:9, loss:0.00026, loss_test:0.07060, lr:1.00e-02, fs:0.71910 (r=0.970,p=0.571),  time:18.763, tt:187.626\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.06971, lr:1.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:18.794, tt:206.729\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.06909, lr:1.00e-02, fs:0.71698 (r=0.960,p=0.572),  time:18.807, tt:225.682\n",
      "Ep:12, loss:0.00023, loss_test:0.06834, lr:1.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:18.822, tt:244.683\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.06771, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:18.839, tt:263.745\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.06686, lr:1.00e-02, fs:0.75591 (r=0.970,p=0.619),  time:18.866, tt:282.985\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.06611, lr:1.00e-02, fs:0.75294 (r=0.970,p=0.615),  time:18.877, tt:302.033\n",
      "Ep:16, loss:0.00020, loss_test:0.06603, lr:1.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:18.882, tt:321.001\n",
      "Ep:17, loss:0.00020, loss_test:0.06579, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:18.896, tt:340.137\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.06568, lr:1.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:18.895, tt:359.009\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.06553, lr:1.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:18.893, tt:377.850\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.06560, lr:1.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:18.898, tt:396.868\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.06543, lr:1.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:18.897, tt:415.739\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.06527, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:18.906, tt:434.841\n",
      "Ep:23, loss:0.00016, loss_test:0.06519, lr:1.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:18.908, tt:453.782\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.06482, lr:1.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:18.913, tt:472.820\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.06517, lr:1.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:18.919, tt:491.907\n",
      "Ep:26, loss:0.00015, loss_test:0.06524, lr:1.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:18.908, tt:510.509\n",
      "Ep:27, loss:0.00014, loss_test:0.06566, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:18.893, tt:529.017\n",
      "Ep:28, loss:0.00014, loss_test:0.06579, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:18.890, tt:547.813\n",
      "Ep:29, loss:0.00013, loss_test:0.06656, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:18.885, tt:566.555\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.06576, lr:1.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:18.872, tt:585.028\n",
      "Ep:31, loss:0.00012, loss_test:0.06640, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:18.853, tt:603.284\n",
      "Ep:32, loss:0.00012, loss_test:0.06621, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:18.856, tt:622.262\n",
      "Ep:33, loss:0.00011, loss_test:0.06678, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:18.859, tt:641.202\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.06683, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:18.854, tt:659.894\n",
      "Ep:35, loss:0.00011, loss_test:0.06691, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:18.848, tt:678.538\n",
      "Ep:36, loss:0.00010, loss_test:0.06741, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:18.851, tt:697.475\n",
      "Ep:37, loss:0.00010, loss_test:0.06785, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:18.853, tt:716.409\n",
      "Ep:38, loss:0.00010, loss_test:0.06784, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:18.851, tt:735.172\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.06752, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:18.853, tt:754.131\n",
      "Ep:40, loss:0.00009, loss_test:0.06837, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:18.854, tt:773.021\n",
      "Ep:41, loss:0.00009, loss_test:0.06844, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:18.856, tt:791.945\n",
      "Ep:42, loss:0.00008, loss_test:0.06832, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:18.855, tt:810.780\n",
      "Ep:43, loss:0.00008, loss_test:0.06912, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:18.854, tt:829.565\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.06912, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:18.855, tt:848.484\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06904, lr:1.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:18.854, tt:867.293\n",
      "Ep:46, loss:0.00007, loss_test:0.07036, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:18.855, tt:886.177\n",
      "Ep:47, loss:0.00007, loss_test:0.06927, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:18.853, tt:904.924\n",
      "Ep:48, loss:0.00007, loss_test:0.06934, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:18.851, tt:923.707\n",
      "Ep:49, loss:0.00007, loss_test:0.07053, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:18.846, tt:942.291\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.06956, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:18.845, tt:961.087\n",
      "Ep:51, loss:0.00006, loss_test:0.06971, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:18.843, tt:979.846\n",
      "Ep:52, loss:0.00006, loss_test:0.07003, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:18.844, tt:998.736\n",
      "Ep:53, loss:0.00006, loss_test:0.06977, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:18.844, tt:1017.591\n",
      "Ep:54, loss:0.00006, loss_test:0.06982, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:18.841, tt:1036.279\n",
      "Ep:55, loss:0.00006, loss_test:0.07042, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:18.838, tt:1054.946\n",
      "Ep:56, loss:0.00005, loss_test:0.06917, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:18.843, tt:1074.025\n",
      "Ep:57, loss:0.00005, loss_test:0.07073, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:18.845, tt:1093.001\n",
      "Ep:58, loss:0.00005, loss_test:0.07025, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:18.846, tt:1111.917\n",
      "Ep:59, loss:0.00005, loss_test:0.06968, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:18.843, tt:1130.609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.07066, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:18.837, tt:1149.048\n",
      "Ep:61, loss:0.00005, loss_test:0.07100, lr:9.90e-03, fs:0.81517 (r=0.869,p=0.768),  time:18.835, tt:1167.790\n",
      "Ep:62, loss:0.00005, loss_test:0.07000, lr:9.80e-03, fs:0.81690 (r=0.879,p=0.763),  time:18.837, tt:1186.756\n",
      "Ep:63, loss:0.00005, loss_test:0.07097, lr:9.70e-03, fs:0.80569 (r=0.859,p=0.759),  time:18.839, tt:1205.697\n",
      "Ep:64, loss:0.00004, loss_test:0.07161, lr:9.61e-03, fs:0.80952 (r=0.859,p=0.766),  time:18.840, tt:1224.620\n",
      "Ep:65, loss:0.00004, loss_test:0.07041, lr:9.51e-03, fs:0.81517 (r=0.869,p=0.768),  time:18.840, tt:1243.415\n",
      "Ep:66, loss:0.00004, loss_test:0.07111, lr:9.41e-03, fs:0.80952 (r=0.859,p=0.766),  time:18.837, tt:1262.083\n",
      "Ep:67, loss:0.00004, loss_test:0.07202, lr:9.32e-03, fs:0.81731 (r=0.859,p=0.780),  time:18.842, tt:1281.250\n",
      "Ep:68, loss:0.00004, loss_test:0.07053, lr:9.23e-03, fs:0.82464 (r=0.879,p=0.777),  time:18.845, tt:1300.308\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.07107, lr:9.23e-03, fs:0.80769 (r=0.848,p=0.771),  time:18.850, tt:1319.483\n",
      "Ep:70, loss:0.00004, loss_test:0.07229, lr:9.23e-03, fs:0.82927 (r=0.859,p=0.802),  time:18.854, tt:1338.665\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.07089, lr:9.23e-03, fs:0.80193 (r=0.838,p=0.769),  time:18.857, tt:1357.727\n",
      "Ep:72, loss:0.00004, loss_test:0.07066, lr:9.23e-03, fs:0.81340 (r=0.859,p=0.773),  time:18.859, tt:1376.691\n",
      "Ep:73, loss:0.00004, loss_test:0.07256, lr:9.23e-03, fs:0.81951 (r=0.848,p=0.792),  time:18.860, tt:1395.626\n",
      "Ep:74, loss:0.00004, loss_test:0.07187, lr:9.23e-03, fs:0.80198 (r=0.818,p=0.786),  time:18.864, tt:1414.777\n",
      "Ep:75, loss:0.00003, loss_test:0.06984, lr:9.23e-03, fs:0.83019 (r=0.889,p=0.779),  time:18.865, tt:1433.713\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00003, loss_test:0.07282, lr:9.23e-03, fs:0.81773 (r=0.838,p=0.798),  time:18.865, tt:1452.616\n",
      "Ep:77, loss:0.00003, loss_test:0.07164, lr:9.23e-03, fs:0.80976 (r=0.838,p=0.783),  time:18.868, tt:1471.667\n",
      "Ep:78, loss:0.00003, loss_test:0.06996, lr:9.23e-03, fs:0.82857 (r=0.879,p=0.784),  time:18.871, tt:1490.788\n",
      "Ep:79, loss:0.00003, loss_test:0.07255, lr:9.23e-03, fs:0.82353 (r=0.848,p=0.800),  time:18.873, tt:1509.877\n",
      "Ep:84, loss:0.00003, loss_test:0.07089, lr:9.23e-03, fs:0.82692 (r=0.869,p=0.789),  time:18.883, tt:1605.035\n",
      "Ep:85, loss:0.00003, loss_test:0.07088, lr:9.23e-03, fs:0.81951 (r=0.848,p=0.792),  time:18.884, tt:1624.015\n",
      "Ep:86, loss:0.00003, loss_test:0.07219, lr:9.23e-03, fs:0.80402 (r=0.808,p=0.800),  time:18.886, tt:1643.057\n",
      "Ep:87, loss:0.00003, loss_test:0.07158, lr:9.14e-03, fs:0.83092 (r=0.869,p=0.796),  time:18.888, tt:1662.183\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.07104, lr:9.14e-03, fs:0.81373 (r=0.838,p=0.790),  time:18.891, tt:1681.324\n",
      "Ep:89, loss:0.00003, loss_test:0.07256, lr:9.14e-03, fs:0.79798 (r=0.798,p=0.798),  time:18.894, tt:1700.430\n",
      "Ep:90, loss:0.00003, loss_test:0.07182, lr:9.14e-03, fs:0.81188 (r=0.828,p=0.796),  time:18.897, tt:1719.587\n",
      "Ep:91, loss:0.00003, loss_test:0.07078, lr:9.14e-03, fs:0.80788 (r=0.828,p=0.788),  time:18.896, tt:1738.437\n",
      "Ep:92, loss:0.00003, loss_test:0.07315, lr:9.14e-03, fs:0.79188 (r=0.788,p=0.796),  time:18.898, tt:1757.495\n",
      "Ep:93, loss:0.00003, loss_test:0.07111, lr:9.14e-03, fs:0.81000 (r=0.818,p=0.802),  time:18.900, tt:1776.636\n",
      "Ep:94, loss:0.00002, loss_test:0.07130, lr:9.14e-03, fs:0.80000 (r=0.808,p=0.792),  time:18.903, tt:1795.811\n",
      "Ep:95, loss:0.00002, loss_test:0.07327, lr:9.14e-03, fs:0.76684 (r=0.747,p=0.787),  time:18.906, tt:1814.933\n",
      "Ep:96, loss:0.00002, loss_test:0.07190, lr:9.14e-03, fs:0.78571 (r=0.778,p=0.794),  time:18.907, tt:1833.976\n",
      "Ep:97, loss:0.00002, loss_test:0.07088, lr:9.14e-03, fs:0.81407 (r=0.818,p=0.810),  time:18.906, tt:1852.807\n",
      "Ep:98, loss:0.00002, loss_test:0.07349, lr:9.14e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.907, tt:1871.773\n",
      "Ep:99, loss:0.00002, loss_test:0.07251, lr:9.04e-03, fs:0.79381 (r=0.778,p=0.811),  time:18.909, tt:1890.938\n",
      "Ep:100, loss:0.00002, loss_test:0.07124, lr:8.95e-03, fs:0.79592 (r=0.788,p=0.804),  time:18.909, tt:1909.830\n",
      "Ep:101, loss:0.00002, loss_test:0.07420, lr:8.86e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.911, tt:1928.927\n",
      "Ep:102, loss:0.00002, loss_test:0.07097, lr:8.78e-03, fs:0.79381 (r=0.778,p=0.811),  time:18.913, tt:1948.072\n",
      "Ep:103, loss:0.00002, loss_test:0.07260, lr:8.69e-03, fs:0.78125 (r=0.758,p=0.806),  time:18.917, tt:1967.378\n",
      "Ep:104, loss:0.00002, loss_test:0.07278, lr:8.60e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.916, tt:1986.209\n",
      "Ep:105, loss:0.00002, loss_test:0.07171, lr:8.51e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.916, tt:2005.144\n",
      "Ep:106, loss:0.00002, loss_test:0.07347, lr:8.43e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.918, tt:2024.198\n",
      "Ep:107, loss:0.00002, loss_test:0.07227, lr:8.35e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.920, tt:2043.339\n",
      "Ep:108, loss:0.00002, loss_test:0.07223, lr:8.26e-03, fs:0.79167 (r=0.768,p=0.817),  time:18.922, tt:2062.545\n",
      "Ep:109, loss:0.00002, loss_test:0.07296, lr:8.18e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.924, tt:2081.652\n",
      "Ep:110, loss:0.00002, loss_test:0.07203, lr:8.10e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.923, tt:2100.452\n",
      "Ep:111, loss:0.00002, loss_test:0.07337, lr:8.02e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.924, tt:2119.545\n",
      "Ep:112, loss:0.00002, loss_test:0.07276, lr:7.94e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.927, tt:2138.735\n",
      "Ep:113, loss:0.00002, loss_test:0.07310, lr:7.86e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.926, tt:2157.552\n",
      "Ep:114, loss:0.00002, loss_test:0.07180, lr:7.78e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.928, tt:2176.679\n",
      "Ep:115, loss:0.00002, loss_test:0.07377, lr:7.70e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.929, tt:2195.776\n",
      "Ep:116, loss:0.00002, loss_test:0.07257, lr:7.62e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.931, tt:2214.885\n",
      "Ep:117, loss:0.00002, loss_test:0.07285, lr:7.55e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.932, tt:2234.022\n",
      "Ep:118, loss:0.00002, loss_test:0.07293, lr:7.47e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.932, tt:2252.918\n",
      "Ep:119, loss:0.00002, loss_test:0.07350, lr:7.40e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.933, tt:2271.959\n",
      "Ep:120, loss:0.00002, loss_test:0.07308, lr:7.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.934, tt:2290.961\n",
      "Ep:121, loss:0.00002, loss_test:0.07282, lr:7.25e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.935, tt:2310.013\n",
      "Ep:122, loss:0.00001, loss_test:0.07301, lr:7.18e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.937, tt:2329.209\n",
      "Ep:123, loss:0.00001, loss_test:0.07348, lr:7.11e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.937, tt:2348.137\n",
      "Ep:124, loss:0.00001, loss_test:0.07287, lr:7.03e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.937, tt:2367.100\n",
      "Ep:125, loss:0.00001, loss_test:0.07307, lr:6.96e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.936, tt:2385.913\n",
      "Ep:126, loss:0.00001, loss_test:0.07352, lr:6.89e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.936, tt:2404.889\n",
      "Ep:127, loss:0.00001, loss_test:0.07321, lr:6.83e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.937, tt:2423.908\n",
      "Ep:128, loss:0.00001, loss_test:0.07312, lr:6.76e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.936, tt:2442.739\n",
      "Ep:129, loss:0.00001, loss_test:0.07357, lr:6.69e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.937, tt:2461.806\n",
      "Ep:130, loss:0.00001, loss_test:0.07329, lr:6.62e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.938, tt:2480.863\n",
      "Ep:131, loss:0.00001, loss_test:0.07333, lr:6.56e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.932, tt:2499.047\n",
      "Ep:132, loss:0.00001, loss_test:0.07321, lr:6.49e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.910, tt:2515.087\n",
      "Ep:133, loss:0.00001, loss_test:0.07322, lr:6.43e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.889, tt:2531.095\n",
      "Ep:134, loss:0.00001, loss_test:0.07354, lr:6.36e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.868, tt:2547.159\n",
      "Ep:135, loss:0.00001, loss_test:0.07369, lr:6.30e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.847, tt:2563.195\n",
      "Ep:136, loss:0.00001, loss_test:0.07304, lr:6.24e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.827, tt:2579.332\n",
      "Ep:137, loss:0.00001, loss_test:0.07337, lr:6.17e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.807, tt:2595.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00001, loss_test:0.07369, lr:6.11e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.787, tt:2611.428\n",
      "Ep:139, loss:0.00001, loss_test:0.07288, lr:6.05e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.769, tt:2627.632\n",
      "Ep:140, loss:0.00001, loss_test:0.07358, lr:5.99e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.749, tt:2643.656\n",
      "Ep:141, loss:0.00001, loss_test:0.07371, lr:5.93e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.730, tt:2659.636\n",
      "Ep:142, loss:0.00001, loss_test:0.07274, lr:5.87e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.711, tt:2675.675\n",
      "Ep:143, loss:0.00001, loss_test:0.07411, lr:5.81e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.692, tt:2691.699\n",
      "Ep:144, loss:0.00001, loss_test:0.07318, lr:5.75e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.674, tt:2707.687\n",
      "Ep:145, loss:0.00001, loss_test:0.07377, lr:5.70e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.656, tt:2723.739\n",
      "Ep:146, loss:0.00001, loss_test:0.07383, lr:5.64e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.638, tt:2739.751\n",
      "Ep:147, loss:0.00001, loss_test:0.07330, lr:5.58e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.620, tt:2755.833\n",
      "Ep:148, loss:0.00001, loss_test:0.07373, lr:5.53e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.603, tt:2771.845\n",
      "Ep:149, loss:0.00001, loss_test:0.07337, lr:5.47e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.586, tt:2787.874\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits 2\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,\"41-41\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 40\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00036, loss_test:0.09276, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.241, tt:18.241\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00036, loss_test:0.09097, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:18.453, tt:36.906\n",
      "Ep:2, loss:0.00035, loss_test:0.08788, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:18.431, tt:55.293\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00033, loss_test:0.08391, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:18.470, tt:73.879\n",
      "Ep:4, loss:0.00032, loss_test:0.08163, lr:1.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:18.528, tt:92.641\n",
      "Ep:5, loss:0.00031, loss_test:0.07946, lr:1.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:18.558, tt:111.349\n",
      "Ep:6, loss:0.00030, loss_test:0.07823, lr:1.00e-02, fs:0.68345 (r=0.960,p=0.531),  time:18.568, tt:129.975\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.07617, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:18.562, tt:148.493\n",
      "Ep:8, loss:0.00028, loss_test:0.07418, lr:1.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:18.556, tt:167.005\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00027, loss_test:0.07338, lr:1.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:18.565, tt:185.650\n",
      "Ep:10, loss:0.00026, loss_test:0.07212, lr:1.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:18.534, tt:203.875\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.07111, lr:1.00e-02, fs:0.71042 (r=0.929,p=0.575),  time:18.554, tt:222.644\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.07081, lr:1.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:18.562, tt:241.300\n",
      "Ep:13, loss:0.00024, loss_test:0.07039, lr:1.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:18.569, tt:259.960\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.07005, lr:1.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:18.591, tt:278.871\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.07009, lr:1.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:18.589, tt:297.417\n",
      "Ep:16, loss:0.00022, loss_test:0.06979, lr:1.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:18.596, tt:316.137\n",
      "Ep:17, loss:0.00021, loss_test:0.06933, lr:1.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:18.620, tt:335.155\n",
      "Ep:18, loss:0.00020, loss_test:0.06911, lr:1.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:18.630, tt:353.964\n",
      "Ep:19, loss:0.00020, loss_test:0.06872, lr:1.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:18.620, tt:372.400\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.06880, lr:1.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:18.607, tt:390.751\n",
      "Ep:21, loss:0.00019, loss_test:0.06891, lr:1.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:18.603, tt:409.258\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.06896, lr:1.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:18.598, tt:427.762\n",
      "Ep:23, loss:0.00018, loss_test:0.06879, lr:1.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:18.592, tt:446.198\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.06868, lr:1.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:18.595, tt:464.868\n",
      "Ep:25, loss:0.00017, loss_test:0.06906, lr:1.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:18.591, tt:483.355\n",
      "Ep:26, loss:0.00016, loss_test:0.06902, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:18.584, tt:501.771\n",
      "Ep:27, loss:0.00015, loss_test:0.06887, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:18.592, tt:520.583\n",
      "Ep:28, loss:0.00015, loss_test:0.06915, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:18.590, tt:539.112\n",
      "Ep:29, loss:0.00015, loss_test:0.06884, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:18.598, tt:557.930\n",
      "Ep:30, loss:0.00014, loss_test:0.06887, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:18.595, tt:576.449\n",
      "Ep:31, loss:0.00014, loss_test:0.06863, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:18.600, tt:595.189\n",
      "Ep:32, loss:0.00013, loss_test:0.06853, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:18.602, tt:613.851\n",
      "Ep:33, loss:0.00013, loss_test:0.06830, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:18.596, tt:632.255\n",
      "Ep:34, loss:0.00012, loss_test:0.06808, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:18.608, tt:651.263\n",
      "Ep:35, loss:0.00012, loss_test:0.06815, lr:9.90e-03, fs:0.72489 (r=0.838,p=0.638),  time:18.606, tt:669.820\n",
      "Ep:36, loss:0.00012, loss_test:0.06789, lr:9.80e-03, fs:0.73362 (r=0.848,p=0.646),  time:18.608, tt:688.495\n",
      "Ep:37, loss:0.00011, loss_test:0.06790, lr:9.70e-03, fs:0.72566 (r=0.828,p=0.646),  time:18.611, tt:707.223\n",
      "Ep:38, loss:0.00011, loss_test:0.06789, lr:9.61e-03, fs:0.72321 (r=0.818,p=0.648),  time:18.610, tt:725.779\n",
      "Ep:39, loss:0.00011, loss_test:0.06764, lr:9.51e-03, fs:0.72321 (r=0.818,p=0.648),  time:18.621, tt:744.830\n",
      "Ep:40, loss:0.00010, loss_test:0.06808, lr:9.41e-03, fs:0.72398 (r=0.808,p=0.656),  time:18.621, tt:763.467\n",
      "Ep:41, loss:0.00010, loss_test:0.06730, lr:9.32e-03, fs:0.71749 (r=0.808,p=0.645),  time:18.625, tt:782.267\n",
      "Ep:42, loss:0.00010, loss_test:0.06784, lr:9.23e-03, fs:0.72398 (r=0.808,p=0.656),  time:18.629, tt:801.043\n",
      "Ep:43, loss:0.00010, loss_test:0.06788, lr:9.14e-03, fs:0.72727 (r=0.808,p=0.661),  time:18.625, tt:819.499\n",
      "Ep:44, loss:0.00009, loss_test:0.06770, lr:9.04e-03, fs:0.73059 (r=0.808,p=0.667),  time:18.625, tt:838.122\n",
      "Ep:45, loss:0.00009, loss_test:0.06785, lr:8.95e-03, fs:0.73059 (r=0.808,p=0.667),  time:18.623, tt:856.645\n",
      "Ep:46, loss:0.00009, loss_test:0.06771, lr:8.86e-03, fs:0.73059 (r=0.808,p=0.667),  time:18.626, tt:875.419\n",
      "Ep:47, loss:0.00009, loss_test:0.06788, lr:8.78e-03, fs:0.73059 (r=0.808,p=0.667),  time:18.622, tt:893.867\n",
      "Ep:48, loss:0.00008, loss_test:0.06818, lr:8.69e-03, fs:0.73394 (r=0.808,p=0.672),  time:18.625, tt:912.646\n",
      "Ep:49, loss:0.00008, loss_test:0.06816, lr:8.60e-03, fs:0.73733 (r=0.808,p=0.678),  time:18.624, tt:931.216\n",
      "Ep:50, loss:0.00008, loss_test:0.06796, lr:8.51e-03, fs:0.73394 (r=0.808,p=0.672),  time:18.621, tt:949.692\n",
      "Ep:51, loss:0.00008, loss_test:0.06821, lr:8.43e-03, fs:0.73394 (r=0.808,p=0.672),  time:18.615, tt:967.995\n",
      "Ep:52, loss:0.00007, loss_test:0.06829, lr:8.35e-03, fs:0.73394 (r=0.808,p=0.672),  time:18.611, tt:986.403\n",
      "Ep:53, loss:0.00007, loss_test:0.06815, lr:8.26e-03, fs:0.73733 (r=0.808,p=0.678),  time:18.613, tt:1005.127\n",
      "Ep:54, loss:0.00007, loss_test:0.06861, lr:8.18e-03, fs:0.74074 (r=0.808,p=0.684),  time:18.609, tt:1023.519\n",
      "Ep:55, loss:0.00007, loss_test:0.06837, lr:8.10e-03, fs:0.73733 (r=0.808,p=0.678),  time:18.602, tt:1041.731\n",
      "Ep:56, loss:0.00007, loss_test:0.06845, lr:8.02e-03, fs:0.74766 (r=0.808,p=0.696),  time:18.604, tt:1060.430\n",
      "Ep:57, loss:0.00007, loss_test:0.06876, lr:7.94e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.601, tt:1078.886\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.06860, lr:7.94e-03, fs:0.74882 (r=0.798,p=0.705),  time:18.603, tt:1097.571\n",
      "Ep:59, loss:0.00006, loss_test:0.06856, lr:7.94e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.598, tt:1115.903\n",
      "Ep:60, loss:0.00006, loss_test:0.06890, lr:7.94e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.599, tt:1134.560\n",
      "Ep:61, loss:0.00006, loss_test:0.06873, lr:7.94e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.601, tt:1153.255\n",
      "Ep:62, loss:0.00006, loss_test:0.06936, lr:7.94e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.603, tt:1172.011\n",
      "Ep:63, loss:0.00006, loss_test:0.06923, lr:7.94e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.608, tt:1190.906\n",
      "Ep:64, loss:0.00006, loss_test:0.06937, lr:7.94e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.608, tt:1209.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00006, loss_test:0.06927, lr:7.94e-03, fs:0.75962 (r=0.798,p=0.725),  time:18.608, tt:1228.146\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.06911, lr:7.94e-03, fs:0.76329 (r=0.798,p=0.731),  time:18.610, tt:1246.856\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.07001, lr:7.94e-03, fs:0.77073 (r=0.798,p=0.745),  time:18.613, tt:1265.710\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.06947, lr:7.94e-03, fs:0.76329 (r=0.798,p=0.731),  time:18.614, tt:1284.368\n",
      "Ep:69, loss:0.00005, loss_test:0.06978, lr:7.94e-03, fs:0.76699 (r=0.798,p=0.738),  time:18.609, tt:1302.659\n",
      "Ep:70, loss:0.00005, loss_test:0.06973, lr:7.94e-03, fs:0.76699 (r=0.798,p=0.738),  time:18.612, tt:1321.452\n",
      "Ep:71, loss:0.00005, loss_test:0.07002, lr:7.94e-03, fs:0.77451 (r=0.798,p=0.752),  time:18.616, tt:1340.339\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.07079, lr:7.94e-03, fs:0.77451 (r=0.798,p=0.752),  time:18.617, tt:1359.007\n",
      "Ep:73, loss:0.00005, loss_test:0.07058, lr:7.94e-03, fs:0.77451 (r=0.798,p=0.752),  time:18.612, tt:1377.314\n",
      "Ep:74, loss:0.00005, loss_test:0.07039, lr:7.94e-03, fs:0.77073 (r=0.798,p=0.745),  time:18.616, tt:1396.229\n",
      "Ep:75, loss:0.00005, loss_test:0.07054, lr:7.94e-03, fs:0.77451 (r=0.798,p=0.752),  time:18.617, tt:1414.877\n",
      "Ep:76, loss:0.00004, loss_test:0.07140, lr:7.94e-03, fs:0.77833 (r=0.798,p=0.760),  time:18.617, tt:1433.494\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.07090, lr:7.94e-03, fs:0.77451 (r=0.798,p=0.752),  time:18.622, tt:1452.481\n",
      "Ep:78, loss:0.00004, loss_test:0.07043, lr:7.94e-03, fs:0.77451 (r=0.798,p=0.752),  time:18.622, tt:1471.112\n",
      "Ep:79, loss:0.00004, loss_test:0.07184, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.623, tt:1489.865\n",
      "Ep:80, loss:0.00004, loss_test:0.07163, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.625, tt:1508.663\n",
      "Ep:81, loss:0.00004, loss_test:0.07132, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.625, tt:1527.258\n",
      "Ep:82, loss:0.00004, loss_test:0.07174, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.628, tt:1546.104\n",
      "Ep:83, loss:0.00004, loss_test:0.07246, lr:7.94e-03, fs:0.76617 (r=0.778,p=0.755),  time:18.627, tt:1564.628\n",
      "Ep:84, loss:0.00004, loss_test:0.07173, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.624, tt:1583.064\n",
      "Ep:85, loss:0.00004, loss_test:0.07240, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.628, tt:1601.984\n",
      "Ep:86, loss:0.00004, loss_test:0.07327, lr:7.94e-03, fs:0.74747 (r=0.747,p=0.747),  time:18.629, tt:1620.691\n",
      "Ep:87, loss:0.00004, loss_test:0.07269, lr:7.94e-03, fs:0.76000 (r=0.768,p=0.752),  time:18.630, tt:1639.435\n",
      "Ep:88, loss:0.00004, loss_test:0.07286, lr:7.86e-03, fs:0.77000 (r=0.778,p=0.762),  time:18.626, tt:1657.746\n",
      "Ep:89, loss:0.00004, loss_test:0.07358, lr:7.78e-03, fs:0.73469 (r=0.727,p=0.742),  time:18.626, tt:1676.304\n",
      "Ep:90, loss:0.00004, loss_test:0.07292, lr:7.70e-03, fs:0.74747 (r=0.747,p=0.747),  time:18.624, tt:1694.812\n",
      "Ep:91, loss:0.00003, loss_test:0.07346, lr:7.62e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.623, tt:1713.324\n",
      "Ep:92, loss:0.00003, loss_test:0.07398, lr:7.55e-03, fs:0.71204 (r=0.687,p=0.739),  time:18.623, tt:1731.933\n",
      "Ep:93, loss:0.00003, loss_test:0.07311, lr:7.47e-03, fs:0.74747 (r=0.747,p=0.747),  time:18.626, tt:1750.812\n",
      "Ep:94, loss:0.00003, loss_test:0.07386, lr:7.40e-03, fs:0.73469 (r=0.727,p=0.742),  time:18.627, tt:1769.530\n",
      "Ep:95, loss:0.00003, loss_test:0.07399, lr:7.32e-03, fs:0.70526 (r=0.677,p=0.736),  time:18.628, tt:1788.315\n",
      "Ep:96, loss:0.00003, loss_test:0.07372, lr:7.25e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.630, tt:1807.136\n",
      "Ep:97, loss:0.00003, loss_test:0.07433, lr:7.18e-03, fs:0.69841 (r=0.667,p=0.733),  time:18.630, tt:1825.735\n",
      "Ep:98, loss:0.00003, loss_test:0.07420, lr:7.11e-03, fs:0.69841 (r=0.667,p=0.733),  time:18.631, tt:1844.455\n",
      "Ep:99, loss:0.00003, loss_test:0.07403, lr:7.03e-03, fs:0.71875 (r=0.697,p=0.742),  time:18.629, tt:1862.862\n",
      "Ep:100, loss:0.00003, loss_test:0.07484, lr:6.96e-03, fs:0.68449 (r=0.646,p=0.727),  time:18.629, tt:1881.515\n",
      "Ep:101, loss:0.00003, loss_test:0.07494, lr:6.89e-03, fs:0.67027 (r=0.626,p=0.721),  time:18.632, tt:1900.425\n",
      "Ep:102, loss:0.00003, loss_test:0.07398, lr:6.83e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.631, tt:1918.969\n",
      "Ep:103, loss:0.00003, loss_test:0.07536, lr:6.76e-03, fs:0.65574 (r=0.606,p=0.714),  time:18.632, tt:1937.679\n",
      "Ep:104, loss:0.00003, loss_test:0.07497, lr:6.69e-03, fs:0.67391 (r=0.626,p=0.729),  time:18.632, tt:1956.391\n",
      "Ep:105, loss:0.00003, loss_test:0.07454, lr:6.62e-03, fs:0.68108 (r=0.636,p=0.733),  time:18.632, tt:1974.940\n",
      "Ep:106, loss:0.00003, loss_test:0.07599, lr:6.56e-03, fs:0.64088 (r=0.586,p=0.707),  time:18.633, tt:1993.681\n",
      "Ep:107, loss:0.00003, loss_test:0.07509, lr:6.49e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.631, tt:2012.159\n",
      "Ep:108, loss:0.00003, loss_test:0.07528, lr:6.43e-03, fs:0.65193 (r=0.596,p=0.720),  time:18.634, tt:2031.113\n",
      "Ep:109, loss:0.00003, loss_test:0.07592, lr:6.36e-03, fs:0.64088 (r=0.586,p=0.707),  time:18.634, tt:2049.693\n",
      "Ep:110, loss:0.00003, loss_test:0.07550, lr:6.30e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.631, tt:2068.049\n",
      "Ep:111, loss:0.00003, loss_test:0.07535, lr:6.24e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.631, tt:2086.665\n",
      "Ep:112, loss:0.00003, loss_test:0.07593, lr:6.17e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.633, tt:2105.571\n",
      "Ep:113, loss:0.00003, loss_test:0.07584, lr:6.11e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.632, tt:2124.070\n",
      "Ep:114, loss:0.00003, loss_test:0.07577, lr:6.05e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.631, tt:2142.618\n",
      "Ep:115, loss:0.00003, loss_test:0.07586, lr:5.99e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.631, tt:2161.165\n",
      "Ep:116, loss:0.00002, loss_test:0.07655, lr:5.93e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.631, tt:2179.833\n",
      "Ep:117, loss:0.00002, loss_test:0.07565, lr:5.87e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.608, tt:2195.745\n",
      "Ep:118, loss:0.00002, loss_test:0.07692, lr:5.81e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.586, tt:2211.681\n",
      "Ep:119, loss:0.00002, loss_test:0.07619, lr:5.75e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.563, tt:2227.533\n",
      "Ep:120, loss:0.00002, loss_test:0.07623, lr:5.70e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.541, tt:2243.451\n",
      "Ep:121, loss:0.00002, loss_test:0.07703, lr:5.64e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.519, tt:2259.335\n",
      "Ep:122, loss:0.00002, loss_test:0.07636, lr:5.58e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.497, tt:2275.159\n",
      "Ep:123, loss:0.00002, loss_test:0.07677, lr:5.53e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.476, tt:2291.022\n",
      "Ep:124, loss:0.00002, loss_test:0.07672, lr:5.47e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.454, tt:2306.799\n",
      "Ep:125, loss:0.00002, loss_test:0.07673, lr:5.42e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.434, tt:2322.712\n",
      "Ep:126, loss:0.00002, loss_test:0.07642, lr:5.36e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.414, tt:2338.556\n",
      "Ep:127, loss:0.00002, loss_test:0.07751, lr:5.31e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.393, tt:2354.351\n",
      "Ep:128, loss:0.00002, loss_test:0.07656, lr:5.26e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.374, tt:2370.183\n",
      "Ep:129, loss:0.00002, loss_test:0.07723, lr:5.20e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.354, tt:2385.991\n",
      "Ep:130, loss:0.00002, loss_test:0.07743, lr:5.15e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.335, tt:2401.832\n",
      "Ep:131, loss:0.00002, loss_test:0.07690, lr:5.10e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.316, tt:2417.722\n",
      "Ep:132, loss:0.00002, loss_test:0.07763, lr:5.05e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.298, tt:2433.592\n",
      "Ep:133, loss:0.00002, loss_test:0.07719, lr:5.00e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.280, tt:2449.489\n",
      "Ep:134, loss:0.00002, loss_test:0.07778, lr:4.95e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.262, tt:2465.376\n",
      "Ep:135, loss:0.00002, loss_test:0.07728, lr:4.90e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.245, tt:2481.318\n",
      "Ep:136, loss:0.00002, loss_test:0.07805, lr:4.85e-03, fs:0.65169 (r=0.586,p=0.734),  time:18.228, tt:2497.249\n",
      "Ep:137, loss:0.00002, loss_test:0.07763, lr:4.80e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.211, tt:2513.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00002, loss_test:0.07779, lr:4.75e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.194, tt:2528.938\n",
      "Ep:139, loss:0.00002, loss_test:0.07812, lr:4.71e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.178, tt:2544.857\n",
      "Ep:140, loss:0.00002, loss_test:0.07808, lr:4.66e-03, fs:0.65169 (r=0.586,p=0.734),  time:18.161, tt:2560.720\n",
      "Ep:141, loss:0.00002, loss_test:0.07792, lr:4.61e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.145, tt:2576.577\n",
      "Ep:142, loss:0.00002, loss_test:0.07833, lr:4.57e-03, fs:0.65537 (r=0.586,p=0.744),  time:18.129, tt:2592.444\n",
      "Ep:143, loss:0.00002, loss_test:0.07806, lr:4.52e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.113, tt:2608.305\n",
      "Ep:144, loss:0.00002, loss_test:0.07819, lr:4.48e-03, fs:0.65537 (r=0.586,p=0.744),  time:18.098, tt:2624.171\n",
      "Ep:145, loss:0.00002, loss_test:0.07843, lr:4.43e-03, fs:0.65537 (r=0.586,p=0.744),  time:18.083, tt:2640.147\n",
      "Ep:146, loss:0.00002, loss_test:0.07823, lr:4.39e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.067, tt:2655.875\n",
      "Ep:147, loss:0.00002, loss_test:0.07834, lr:4.34e-03, fs:0.65537 (r=0.586,p=0.744),  time:18.052, tt:2671.666\n",
      "Ep:148, loss:0.00002, loss_test:0.07846, lr:4.30e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.037, tt:2687.466\n",
      "Ep:149, loss:0.00002, loss_test:0.07848, lr:4.26e-03, fs:0.65169 (r=0.586,p=0.734),  time:18.022, tt:2703.294\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,\"41-41\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 40\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1039\n",
      "1049\n",
      "1042\n",
      "1062\n",
      "1036\n",
      "1040\n",
      "510\n",
      "Ep:0, loss:0.00060, loss_test:0.08700, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:30.663, tt:30.663\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.08286, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:31.614, tt:63.227\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.07853, lr:1.00e-02, fs:0.68116 (r=0.949,p=0.531),  time:31.890, tt:95.670\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00048, loss_test:0.07556, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:32.021, tt:128.083\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.07332, lr:1.00e-02, fs:0.70111 (r=0.960,p=0.552),  time:32.096, tt:160.481\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00042, loss_test:0.07176, lr:1.00e-02, fs:0.70769 (r=0.929,p=0.571),  time:32.125, tt:192.752\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.07103, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:32.160, tt:225.118\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.06997, lr:1.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:32.198, tt:257.584\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.06961, lr:1.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:32.179, tt:289.614\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.06911, lr:1.00e-02, fs:0.75294 (r=0.970,p=0.615),  time:32.177, tt:321.770\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.06886, lr:1.00e-02, fs:0.77600 (r=0.980,p=0.642),  time:32.221, tt:354.432\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.06993, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:32.244, tt:386.927\n",
      "Ep:12, loss:0.00029, loss_test:0.06953, lr:1.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:32.245, tt:419.179\n",
      "Ep:13, loss:0.00028, loss_test:0.07023, lr:1.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:32.267, tt:451.742\n",
      "Ep:14, loss:0.00026, loss_test:0.07131, lr:1.00e-02, fs:0.75536 (r=0.889,p=0.657),  time:32.259, tt:483.882\n",
      "Ep:15, loss:0.00025, loss_test:0.07185, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:32.241, tt:515.856\n",
      "Ep:16, loss:0.00024, loss_test:0.07194, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:32.251, tt:548.272\n",
      "Ep:17, loss:0.00023, loss_test:0.07163, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:32.260, tt:580.684\n",
      "Ep:18, loss:0.00021, loss_test:0.07203, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:32.263, tt:613.000\n",
      "Ep:19, loss:0.00020, loss_test:0.07399, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:32.275, tt:645.499\n",
      "Ep:20, loss:0.00019, loss_test:0.07440, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:32.272, tt:677.721\n",
      "Ep:21, loss:0.00018, loss_test:0.07483, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:32.265, tt:709.831\n",
      "Ep:22, loss:0.00018, loss_test:0.07355, lr:9.90e-03, fs:0.66986 (r=0.707,p=0.636),  time:32.272, tt:742.258\n",
      "Ep:23, loss:0.00017, loss_test:0.07448, lr:9.80e-03, fs:0.66990 (r=0.697,p=0.645),  time:32.278, tt:774.683\n",
      "Ep:24, loss:0.00016, loss_test:0.07479, lr:9.70e-03, fs:0.66341 (r=0.687,p=0.642),  time:32.287, tt:807.187\n",
      "Ep:25, loss:0.00015, loss_test:0.07518, lr:9.61e-03, fs:0.66019 (r=0.687,p=0.636),  time:32.288, tt:839.501\n",
      "Ep:26, loss:0.00015, loss_test:0.07593, lr:9.51e-03, fs:0.65686 (r=0.677,p=0.638),  time:32.289, tt:871.817\n",
      "Ep:27, loss:0.00014, loss_test:0.07620, lr:9.41e-03, fs:0.66337 (r=0.677,p=0.650),  time:32.286, tt:904.009\n",
      "Ep:28, loss:0.00013, loss_test:0.07664, lr:9.32e-03, fs:0.65672 (r=0.667,p=0.647),  time:32.290, tt:936.411\n",
      "Ep:29, loss:0.00013, loss_test:0.07665, lr:9.23e-03, fs:0.66000 (r=0.667,p=0.653),  time:32.293, tt:968.800\n",
      "Ep:30, loss:0.00012, loss_test:0.07756, lr:9.14e-03, fs:0.66000 (r=0.667,p=0.653),  time:32.303, tt:1001.397\n",
      "Ep:31, loss:0.00012, loss_test:0.07800, lr:9.04e-03, fs:0.65327 (r=0.657,p=0.650),  time:32.309, tt:1033.901\n",
      "Ep:32, loss:0.00011, loss_test:0.07864, lr:8.95e-03, fs:0.65657 (r=0.657,p=0.657),  time:32.308, tt:1066.170\n",
      "Ep:33, loss:0.00011, loss_test:0.07937, lr:8.86e-03, fs:0.65990 (r=0.657,p=0.663),  time:32.317, tt:1098.777\n",
      "Ep:34, loss:0.00010, loss_test:0.08078, lr:8.78e-03, fs:0.65979 (r=0.646,p=0.674),  time:32.325, tt:1131.358\n",
      "Ep:35, loss:0.00010, loss_test:0.08099, lr:8.69e-03, fs:0.65641 (r=0.646,p=0.667),  time:32.325, tt:1163.717\n",
      "Ep:36, loss:0.00010, loss_test:0.08207, lr:8.60e-03, fs:0.65641 (r=0.646,p=0.667),  time:32.324, tt:1195.981\n",
      "Ep:37, loss:0.00009, loss_test:0.08258, lr:8.51e-03, fs:0.65979 (r=0.646,p=0.674),  time:32.330, tt:1228.537\n",
      "Ep:38, loss:0.00009, loss_test:0.08326, lr:8.43e-03, fs:0.65979 (r=0.646,p=0.674),  time:32.326, tt:1260.696\n",
      "Ep:39, loss:0.00009, loss_test:0.08299, lr:8.35e-03, fs:0.65641 (r=0.646,p=0.667),  time:32.331, tt:1293.259\n",
      "Ep:40, loss:0.00008, loss_test:0.08262, lr:8.26e-03, fs:0.65306 (r=0.646,p=0.660),  time:32.338, tt:1325.847\n",
      "Ep:41, loss:0.00008, loss_test:0.08341, lr:8.18e-03, fs:0.65641 (r=0.646,p=0.667),  time:32.345, tt:1358.504\n",
      "Ep:42, loss:0.00008, loss_test:0.08489, lr:8.10e-03, fs:0.65979 (r=0.646,p=0.674),  time:32.347, tt:1390.940\n",
      "Ep:43, loss:0.00008, loss_test:0.08506, lr:8.02e-03, fs:0.67368 (r=0.646,p=0.703),  time:32.353, tt:1423.545\n",
      "Ep:44, loss:0.00007, loss_test:0.08525, lr:7.94e-03, fs:0.66667 (r=0.646,p=0.688),  time:32.349, tt:1455.689\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75d1c7d2006b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"41-41\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,\"41-41\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 40\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00035, loss_test:0.09127, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:18.827, tt:18.827\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00034, loss_test:0.08759, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:18.733, tt:37.465\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00032, loss_test:0.08447, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:18.671, tt:56.012\n",
      "Ep:3, loss:0.00031, loss_test:0.08201, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:18.739, tt:74.956\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00030, loss_test:0.07996, lr:1.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:18.702, tt:93.511\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00029, loss_test:0.07844, lr:1.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:18.669, tt:112.017\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00028, loss_test:0.07693, lr:1.00e-02, fs:0.68889 (r=0.939,p=0.544),  time:18.667, tt:130.668\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00027, loss_test:0.07632, lr:1.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:18.665, tt:149.318\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.07530, lr:1.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:18.669, tt:168.023\n",
      "Ep:9, loss:0.00025, loss_test:0.07457, lr:1.00e-02, fs:0.70992 (r=0.939,p=0.571),  time:18.613, tt:186.131\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.07391, lr:1.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:18.633, tt:204.966\n",
      "Ep:11, loss:0.00024, loss_test:0.07365, lr:1.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:18.628, tt:223.537\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.07249, lr:1.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:18.625, tt:242.131\n",
      "Ep:13, loss:0.00022, loss_test:0.07210, lr:1.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:18.600, tt:260.405\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.07162, lr:1.00e-02, fs:0.72031 (r=0.949,p=0.580),  time:18.586, tt:278.791\n",
      "Ep:15, loss:0.00021, loss_test:0.07141, lr:1.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:18.604, tt:297.663\n",
      "Ep:16, loss:0.00020, loss_test:0.07247, lr:1.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:18.604, tt:316.274\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.07051, lr:1.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:18.607, tt:334.924\n",
      "Ep:18, loss:0.00019, loss_test:0.07179, lr:1.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:18.605, tt:353.499\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.07165, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:18.593, tt:371.865\n",
      "Ep:20, loss:0.00018, loss_test:0.07120, lr:1.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:18.586, tt:390.314\n",
      "Ep:21, loss:0.00017, loss_test:0.07148, lr:1.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:18.602, tt:409.239\n",
      "Ep:22, loss:0.00017, loss_test:0.07109, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:18.603, tt:427.879\n",
      "Ep:23, loss:0.00016, loss_test:0.07154, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:18.610, tt:446.635\n",
      "Ep:24, loss:0.00016, loss_test:0.07222, lr:1.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:18.606, tt:465.159\n",
      "Ep:25, loss:0.00015, loss_test:0.07171, lr:1.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:18.606, tt:483.759\n",
      "Ep:26, loss:0.00015, loss_test:0.07358, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:18.603, tt:502.278\n",
      "Ep:27, loss:0.00014, loss_test:0.07274, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:18.607, tt:520.988\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.07365, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:18.602, tt:539.456\n",
      "Ep:29, loss:0.00013, loss_test:0.07307, lr:1.00e-02, fs:0.75536 (r=0.889,p=0.657),  time:18.607, tt:558.196\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.07298, lr:1.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:18.617, tt:577.125\n",
      "Ep:31, loss:0.00012, loss_test:0.07291, lr:1.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:18.619, tt:595.809\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07398, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:18.625, tt:614.632\n",
      "Ep:33, loss:0.00011, loss_test:0.07350, lr:1.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:18.633, tt:633.520\n",
      "Ep:34, loss:0.00011, loss_test:0.07344, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:18.635, tt:652.241\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07427, lr:1.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:18.638, tt:670.966\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.07334, lr:1.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:18.643, tt:689.791\n",
      "Ep:37, loss:0.00010, loss_test:0.07494, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:18.646, tt:708.532\n",
      "Ep:38, loss:0.00010, loss_test:0.07390, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:18.644, tt:727.098\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07367, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:18.642, tt:745.685\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.07578, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:18.641, tt:764.283\n",
      "Ep:41, loss:0.00009, loss_test:0.07415, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:18.640, tt:782.889\n",
      "Ep:42, loss:0.00008, loss_test:0.07391, lr:1.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:18.630, tt:801.088\n",
      "Ep:43, loss:0.00008, loss_test:0.07702, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:18.634, tt:819.904\n",
      "Ep:44, loss:0.00008, loss_test:0.07386, lr:1.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:18.634, tt:838.518\n",
      "Ep:45, loss:0.00008, loss_test:0.07678, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:18.640, tt:857.419\n",
      "Ep:46, loss:0.00007, loss_test:0.07717, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:18.638, tt:875.983\n",
      "Ep:47, loss:0.00007, loss_test:0.07574, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:18.639, tt:894.651\n",
      "Ep:48, loss:0.00007, loss_test:0.07515, lr:1.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:18.639, tt:913.306\n",
      "Ep:49, loss:0.00007, loss_test:0.07797, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:18.642, tt:932.085\n",
      "Ep:50, loss:0.00007, loss_test:0.07553, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:18.646, tt:950.926\n",
      "Ep:51, loss:0.00006, loss_test:0.07748, lr:9.90e-03, fs:0.77570 (r=0.838,p=0.722),  time:18.652, tt:969.909\n",
      "Ep:52, loss:0.00006, loss_test:0.07625, lr:9.80e-03, fs:0.78704 (r=0.859,p=0.726),  time:18.655, tt:988.696\n",
      "Ep:53, loss:0.00006, loss_test:0.07740, lr:9.70e-03, fs:0.78341 (r=0.859,p=0.720),  time:18.648, tt:1007.013\n",
      "Ep:54, loss:0.00006, loss_test:0.07647, lr:9.61e-03, fs:0.77626 (r=0.859,p=0.708),  time:18.645, tt:1025.457\n",
      "Ep:55, loss:0.00006, loss_test:0.07662, lr:9.51e-03, fs:0.78704 (r=0.859,p=0.726),  time:18.645, tt:1044.145\n",
      "Ep:56, loss:0.00006, loss_test:0.07794, lr:9.41e-03, fs:0.76056 (r=0.818,p=0.711),  time:18.645, tt:1062.765\n",
      "Ep:57, loss:0.00005, loss_test:0.07639, lr:9.32e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.645, tt:1081.409\n",
      "Ep:58, loss:0.00005, loss_test:0.07817, lr:9.23e-03, fs:0.75472 (r=0.808,p=0.708),  time:18.648, tt:1100.231\n",
      "Ep:59, loss:0.00005, loss_test:0.07615, lr:9.14e-03, fs:0.77982 (r=0.859,p=0.714),  time:18.650, tt:1118.991\n",
      "Ep:60, loss:0.00005, loss_test:0.07855, lr:9.04e-03, fs:0.73529 (r=0.758,p=0.714),  time:18.649, tt:1137.608\n",
      "Ep:61, loss:0.00005, loss_test:0.07962, lr:8.95e-03, fs:0.73430 (r=0.768,p=0.704),  time:18.653, tt:1156.489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00005, loss_test:0.07651, lr:8.86e-03, fs:0.79817 (r=0.879,p=0.731),  time:18.655, tt:1175.272\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.08087, lr:8.86e-03, fs:0.68041 (r=0.667,p=0.695),  time:18.658, tt:1194.087\n",
      "Ep:64, loss:0.00005, loss_test:0.07864, lr:8.86e-03, fs:0.75362 (r=0.788,p=0.722),  time:18.662, tt:1213.010\n",
      "Ep:65, loss:0.00004, loss_test:0.07665, lr:8.86e-03, fs:0.79630 (r=0.869,p=0.735),  time:18.664, tt:1231.806\n",
      "Ep:66, loss:0.00004, loss_test:0.08061, lr:8.86e-03, fs:0.69388 (r=0.687,p=0.701),  time:18.665, tt:1250.550\n",
      "Ep:67, loss:0.00004, loss_test:0.07862, lr:8.86e-03, fs:0.73267 (r=0.747,p=0.718),  time:18.665, tt:1269.186\n",
      "Ep:68, loss:0.00004, loss_test:0.07940, lr:8.86e-03, fs:0.73529 (r=0.758,p=0.714),  time:18.666, tt:1287.957\n",
      "Ep:69, loss:0.00004, loss_test:0.07907, lr:8.86e-03, fs:0.71642 (r=0.727,p=0.706),  time:18.665, tt:1306.565\n",
      "Ep:70, loss:0.00004, loss_test:0.07951, lr:8.86e-03, fs:0.73529 (r=0.758,p=0.714),  time:18.667, tt:1325.351\n",
      "Ep:71, loss:0.00004, loss_test:0.07886, lr:8.86e-03, fs:0.73892 (r=0.758,p=0.721),  time:18.670, tt:1344.223\n",
      "Ep:72, loss:0.00004, loss_test:0.07948, lr:8.86e-03, fs:0.72637 (r=0.737,p=0.716),  time:18.671, tt:1362.975\n",
      "Ep:73, loss:0.00004, loss_test:0.07970, lr:8.86e-03, fs:0.72637 (r=0.737,p=0.716),  time:18.670, tt:1381.606\n",
      "Ep:74, loss:0.00004, loss_test:0.07902, lr:8.78e-03, fs:0.73267 (r=0.747,p=0.718),  time:18.676, tt:1400.703\n",
      "Ep:75, loss:0.00004, loss_test:0.08020, lr:8.69e-03, fs:0.71717 (r=0.717,p=0.717),  time:18.677, tt:1419.456\n",
      "Ep:76, loss:0.00003, loss_test:0.07934, lr:8.60e-03, fs:0.74257 (r=0.758,p=0.728),  time:18.678, tt:1438.181\n",
      "Ep:77, loss:0.00003, loss_test:0.08001, lr:8.51e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.680, tt:1457.027\n",
      "Ep:78, loss:0.00003, loss_test:0.07947, lr:8.43e-03, fs:0.73000 (r=0.737,p=0.723),  time:18.678, tt:1475.523\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75d1c7d2006b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"41-41\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,\"41-41\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 40\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00054, loss_test:0.14182, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.712, tt:15.712\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13906, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:15.733, tt:31.466\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.13366, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:15.727, tt:47.182\n",
      "Ep:3, loss:0.00050, loss_test:0.12751, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:15.728, tt:62.911\n",
      "Ep:4, loss:0.00046, loss_test:0.12394, lr:1.00e-02, fs:0.64078 (r=0.667,p=0.617),  time:15.738, tt:78.690\n",
      "Ep:5, loss:0.00045, loss_test:0.12047, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:15.747, tt:94.482\n",
      "Ep:6, loss:0.00043, loss_test:0.11617, lr:1.00e-02, fs:0.66667 (r=0.717,p=0.623),  time:15.752, tt:110.262\n",
      "Ep:7, loss:0.00041, loss_test:0.11476, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:15.753, tt:126.021\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.11277, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:15.752, tt:141.772\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.11050, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:15.751, tt:157.507\n",
      "Ep:10, loss:0.00036, loss_test:0.10929, lr:1.00e-02, fs:0.68627 (r=0.707,p=0.667),  time:15.761, tt:173.375\n",
      "Ep:11, loss:0.00035, loss_test:0.10667, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:15.759, tt:189.102\n",
      "Ep:12, loss:0.00033, loss_test:0.10667, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:15.753, tt:204.793\n",
      "Ep:13, loss:0.00032, loss_test:0.10574, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:15.747, tt:220.461\n",
      "Ep:14, loss:0.00031, loss_test:0.10576, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:15.747, tt:236.201\n",
      "Ep:15, loss:0.00030, loss_test:0.10676, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:15.745, tt:251.916\n",
      "Ep:16, loss:0.00028, loss_test:0.10693, lr:1.00e-02, fs:0.69110 (r=0.667,p=0.717),  time:15.743, tt:267.628\n",
      "Ep:17, loss:0.00027, loss_test:0.10793, lr:1.00e-02, fs:0.65217 (r=0.606,p=0.706),  time:15.746, tt:283.419\n",
      "Ep:18, loss:0.00026, loss_test:0.10720, lr:1.00e-02, fs:0.66667 (r=0.616,p=0.726),  time:15.750, tt:299.251\n",
      "Ep:19, loss:0.00025, loss_test:0.10870, lr:1.00e-02, fs:0.63687 (r=0.576,p=0.713),  time:15.750, tt:314.999\n",
      "Ep:20, loss:0.00024, loss_test:0.10743, lr:9.90e-03, fs:0.63277 (r=0.566,p=0.718),  time:15.755, tt:330.851\n",
      "Ep:21, loss:0.00022, loss_test:0.10782, lr:9.80e-03, fs:0.62147 (r=0.556,p=0.705),  time:15.754, tt:346.590\n",
      "Ep:22, loss:0.00021, loss_test:0.11026, lr:9.70e-03, fs:0.56442 (r=0.465,p=0.719),  time:15.755, tt:362.354\n",
      "Ep:23, loss:0.00020, loss_test:0.10783, lr:9.61e-03, fs:0.58824 (r=0.505,p=0.704),  time:15.757, tt:378.174\n",
      "Ep:24, loss:0.00019, loss_test:0.11000, lr:9.51e-03, fs:0.55901 (r=0.455,p=0.726),  time:15.758, tt:393.942\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-52f9ee764729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"41-41\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,\"41-41\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.05863, lr:1.00e-02, fs:0.31746 (r=0.202,p=0.741),  time:36.974, tt:36.974\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.03964, lr:1.00e-02, fs:0.40506 (r=0.323,p=0.542),  time:36.496, tt:72.992\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02900, lr:1.00e-02, fs:0.51675 (r=0.545,p=0.491),  time:37.139, tt:111.418\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02488, lr:1.00e-02, fs:0.61475 (r=0.758,p=0.517),  time:36.811, tt:147.244\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02368, lr:1.00e-02, fs:0.61993 (r=0.848,p=0.488),  time:36.704, tt:183.522\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02343, lr:1.00e-02, fs:0.63415 (r=0.919,p=0.484),  time:36.773, tt:220.636\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02342, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:36.750, tt:257.250\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02343, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:36.906, tt:295.251\n",
      "Ep:8, loss:0.00004, loss_test:0.02338, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:36.783, tt:331.046\n",
      "Ep:9, loss:0.00004, loss_test:0.02330, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:36.824, tt:368.237\n",
      "Ep:10, loss:0.00004, loss_test:0.02321, lr:1.00e-02, fs:0.64360 (r=0.939,p=0.489),  time:36.780, tt:404.576\n",
      "Ep:11, loss:0.00004, loss_test:0.02314, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:36.761, tt:441.126\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02310, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:36.796, tt:478.342\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02311, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:36.666, tt:513.323\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02316, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:36.625, tt:549.371\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02327, lr:1.00e-02, fs:0.64419 (r=0.869,p=0.512),  time:36.677, tt:586.837\n",
      "Ep:16, loss:0.00004, loss_test:0.02342, lr:1.00e-02, fs:0.62791 (r=0.818,p=0.509),  time:36.664, tt:623.295\n",
      "Ep:17, loss:0.00004, loss_test:0.02360, lr:1.00e-02, fs:0.61417 (r=0.788,p=0.503),  time:36.579, tt:658.425\n",
      "Ep:18, loss:0.00004, loss_test:0.02376, lr:1.00e-02, fs:0.60558 (r=0.768,p=0.500),  time:36.620, tt:695.784\n",
      "Ep:19, loss:0.00004, loss_test:0.02388, lr:1.00e-02, fs:0.59677 (r=0.747,p=0.497),  time:36.603, tt:732.055\n",
      "Ep:20, loss:0.00004, loss_test:0.02393, lr:1.00e-02, fs:0.58197 (r=0.717,p=0.490),  time:36.643, tt:769.495\n",
      "Ep:21, loss:0.00004, loss_test:0.02392, lr:1.00e-02, fs:0.57500 (r=0.697,p=0.489),  time:36.702, tt:807.453\n",
      "Ep:22, loss:0.00004, loss_test:0.02385, lr:1.00e-02, fs:0.57983 (r=0.697,p=0.496),  time:36.674, tt:843.501\n",
      "Ep:23, loss:0.00004, loss_test:0.02373, lr:1.00e-02, fs:0.57983 (r=0.697,p=0.496),  time:36.568, tt:877.636\n",
      "Ep:24, loss:0.00004, loss_test:0.02357, lr:1.00e-02, fs:0.58824 (r=0.707,p=0.504),  time:36.531, tt:913.280\n",
      "Ep:25, loss:0.00004, loss_test:0.02341, lr:1.00e-02, fs:0.59414 (r=0.717,p=0.507),  time:36.554, tt:950.399\n",
      "Ep:26, loss:0.00004, loss_test:0.02327, lr:9.90e-03, fs:0.59751 (r=0.727,p=0.507),  time:36.539, tt:986.544\n",
      "Ep:27, loss:0.00003, loss_test:0.02317, lr:9.80e-03, fs:0.60331 (r=0.737,p=0.510),  time:36.596, tt:1024.691\n",
      "Ep:28, loss:0.00003, loss_test:0.02307, lr:9.70e-03, fs:0.60331 (r=0.737,p=0.510),  time:36.602, tt:1061.457\n",
      "Ep:29, loss:0.00003, loss_test:0.02301, lr:9.61e-03, fs:0.59167 (r=0.717,p=0.504),  time:36.560, tt:1096.788\n",
      "Ep:30, loss:0.00003, loss_test:0.02297, lr:9.51e-03, fs:0.59414 (r=0.717,p=0.507),  time:36.485, tt:1131.050\n",
      "Ep:31, loss:0.00003, loss_test:0.02294, lr:9.41e-03, fs:0.59916 (r=0.717,p=0.514),  time:36.531, tt:1169.006\n",
      "Ep:32, loss:0.00003, loss_test:0.02291, lr:9.32e-03, fs:0.59574 (r=0.707,p=0.515),  time:36.461, tt:1203.200\n",
      "Ep:33, loss:0.00003, loss_test:0.02289, lr:9.23e-03, fs:0.58009 (r=0.677,p=0.508),  time:36.383, tt:1237.035\n",
      "Ep:34, loss:0.00003, loss_test:0.02287, lr:9.14e-03, fs:0.58009 (r=0.677,p=0.508),  time:36.318, tt:1271.124\n",
      "Ep:35, loss:0.00003, loss_test:0.02285, lr:9.04e-03, fs:0.58009 (r=0.677,p=0.508),  time:36.360, tt:1308.955\n",
      "Ep:36, loss:0.00003, loss_test:0.02283, lr:8.95e-03, fs:0.58261 (r=0.677,p=0.511),  time:36.342, tt:1344.642\n",
      "Ep:37, loss:0.00003, loss_test:0.02279, lr:8.86e-03, fs:0.57642 (r=0.667,p=0.508),  time:36.400, tt:1383.209\n",
      "Ep:38, loss:0.00003, loss_test:0.02276, lr:8.78e-03, fs:0.57895 (r=0.667,p=0.512),  time:36.429, tt:1420.727\n",
      "Ep:39, loss:0.00003, loss_test:0.02273, lr:8.69e-03, fs:0.58515 (r=0.677,p=0.515),  time:36.314, tt:1452.569\n",
      "Ep:40, loss:0.00003, loss_test:0.02269, lr:8.60e-03, fs:0.58772 (r=0.677,p=0.519),  time:36.363, tt:1490.890\n",
      "Ep:41, loss:0.00003, loss_test:0.02265, lr:8.51e-03, fs:0.58772 (r=0.677,p=0.519),  time:36.364, tt:1527.269\n",
      "Ep:42, loss:0.00003, loss_test:0.02261, lr:8.43e-03, fs:0.58772 (r=0.677,p=0.519),  time:36.397, tt:1565.068\n",
      "Ep:43, loss:0.00003, loss_test:0.02258, lr:8.35e-03, fs:0.58772 (r=0.677,p=0.519),  time:36.387, tt:1601.034\n",
      "Ep:44, loss:0.00003, loss_test:0.02256, lr:8.26e-03, fs:0.58772 (r=0.677,p=0.519),  time:36.430, tt:1639.365\n",
      "Ep:45, loss:0.00003, loss_test:0.02254, lr:8.18e-03, fs:0.58407 (r=0.667,p=0.520),  time:36.455, tt:1676.920\n",
      "Ep:46, loss:0.00003, loss_test:0.02252, lr:8.10e-03, fs:0.58929 (r=0.667,p=0.528),  time:36.495, tt:1715.270\n",
      "Ep:47, loss:0.00003, loss_test:0.02249, lr:8.02e-03, fs:0.59556 (r=0.677,p=0.532),  time:36.532, tt:1753.537\n",
      "Ep:48, loss:0.00003, loss_test:0.02247, lr:7.94e-03, fs:0.59556 (r=0.677,p=0.532),  time:36.524, tt:1789.700\n",
      "Ep:49, loss:0.00003, loss_test:0.02244, lr:7.86e-03, fs:0.59556 (r=0.677,p=0.532),  time:36.569, tt:1828.439\n",
      "Ep:50, loss:0.00003, loss_test:0.02240, lr:7.78e-03, fs:0.58296 (r=0.657,p=0.524),  time:36.559, tt:1864.522\n",
      "Ep:51, loss:0.00003, loss_test:0.02237, lr:7.70e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.558, tt:1901.025\n",
      "Ep:52, loss:0.00003, loss_test:0.02233, lr:7.62e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.578, tt:1938.624\n",
      "Ep:53, loss:0.00003, loss_test:0.02230, lr:7.55e-03, fs:0.57919 (r=0.646,p=0.525),  time:36.639, tt:1978.512\n",
      "Ep:54, loss:0.00003, loss_test:0.02227, lr:7.47e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.643, tt:2015.342\n",
      "Ep:55, loss:0.00003, loss_test:0.02224, lr:7.40e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.678, tt:2053.965\n",
      "Ep:56, loss:0.00003, loss_test:0.02222, lr:7.32e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.722, tt:2093.176\n",
      "Ep:57, loss:0.00003, loss_test:0.02220, lr:7.25e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.756, tt:2131.859\n",
      "Ep:58, loss:0.00003, loss_test:0.02218, lr:7.18e-03, fs:0.58559 (r=0.657,p=0.528),  time:36.756, tt:2168.581\n",
      "Ep:59, loss:0.00003, loss_test:0.02215, lr:7.11e-03, fs:0.59193 (r=0.667,p=0.532),  time:36.779, tt:2206.764\n",
      "Ep:60, loss:0.00003, loss_test:0.02213, lr:7.03e-03, fs:0.61062 (r=0.697,p=0.543),  time:36.792, tt:2244.292\n",
      "Ep:61, loss:0.00003, loss_test:0.02210, lr:6.96e-03, fs:0.61062 (r=0.697,p=0.543),  time:36.797, tt:2281.400\n",
      "Ep:62, loss:0.00003, loss_test:0.02207, lr:6.89e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.826, tt:2320.020\n",
      "Ep:63, loss:0.00003, loss_test:0.02204, lr:6.83e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.841, tt:2357.847\n",
      "Ep:64, loss:0.00003, loss_test:0.02202, lr:6.76e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.835, tt:2394.267\n",
      "Ep:65, loss:0.00003, loss_test:0.02200, lr:6.69e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.843, tt:2431.642\n",
      "Ep:66, loss:0.00003, loss_test:0.02198, lr:6.62e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.846, tt:2468.653\n",
      "Ep:67, loss:0.00003, loss_test:0.02196, lr:6.56e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.851, tt:2505.893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00003, loss_test:0.02194, lr:6.49e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.878, tt:2544.559\n",
      "Ep:69, loss:0.00003, loss_test:0.02193, lr:6.43e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.895, tt:2582.634\n",
      "Ep:70, loss:0.00003, loss_test:0.02192, lr:6.36e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.875, tt:2618.145\n",
      "Ep:71, loss:0.00003, loss_test:0.02190, lr:6.30e-03, fs:0.60714 (r=0.687,p=0.544),  time:36.874, tt:2654.924\n",
      "Ep:72, loss:0.00003, loss_test:0.02189, lr:6.24e-03, fs:0.60090 (r=0.677,p=0.540),  time:36.904, tt:2694.019\n",
      "Ep:73, loss:0.00003, loss_test:0.02187, lr:6.17e-03, fs:0.60360 (r=0.677,p=0.545),  time:36.878, tt:2728.965\n",
      "Ep:74, loss:0.00003, loss_test:0.02186, lr:6.11e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.866, tt:2764.933\n",
      "Ep:75, loss:0.00003, loss_test:0.02185, lr:6.05e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.922, tt:2806.036\n",
      "Ep:76, loss:0.00003, loss_test:0.02183, lr:5.99e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.930, tt:2843.587\n",
      "Ep:77, loss:0.00003, loss_test:0.02182, lr:5.93e-03, fs:0.60000 (r=0.667,p=0.545),  time:36.950, tt:2882.112\n",
      "Ep:78, loss:0.00003, loss_test:0.02180, lr:5.87e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.970, tt:2920.663\n",
      "Ep:79, loss:0.00003, loss_test:0.02178, lr:5.81e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.973, tt:2957.867\n",
      "Ep:80, loss:0.00003, loss_test:0.02176, lr:5.75e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.955, tt:2993.314\n",
      "Ep:81, loss:0.00003, loss_test:0.02174, lr:5.70e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.985, tt:3032.760\n",
      "Ep:82, loss:0.00003, loss_test:0.02173, lr:5.64e-03, fs:0.60633 (r=0.677,p=0.549),  time:37.003, tt:3071.236\n",
      "Ep:83, loss:0.00003, loss_test:0.02171, lr:5.58e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.985, tt:3106.762\n",
      "Ep:84, loss:0.00003, loss_test:0.02169, lr:5.53e-03, fs:0.60633 (r=0.677,p=0.549),  time:36.991, tt:3144.205\n",
      "Ep:85, loss:0.00003, loss_test:0.02167, lr:5.47e-03, fs:0.60909 (r=0.677,p=0.554),  time:37.017, tt:3183.468\n",
      "Ep:86, loss:0.00003, loss_test:0.02166, lr:5.42e-03, fs:0.60909 (r=0.677,p=0.554),  time:36.984, tt:3217.638\n",
      "Ep:87, loss:0.00003, loss_test:0.02165, lr:5.36e-03, fs:0.60274 (r=0.667,p=0.550),  time:36.971, tt:3253.433\n",
      "Ep:88, loss:0.00003, loss_test:0.02163, lr:5.31e-03, fs:0.60550 (r=0.667,p=0.555),  time:36.993, tt:3292.376\n",
      "Ep:89, loss:0.00003, loss_test:0.02162, lr:5.26e-03, fs:0.60550 (r=0.667,p=0.555),  time:36.990, tt:3329.095\n",
      "Ep:90, loss:0.00003, loss_test:0.02160, lr:5.20e-03, fs:0.60550 (r=0.667,p=0.555),  time:36.993, tt:3366.330\n",
      "Ep:91, loss:0.00003, loss_test:0.02158, lr:5.15e-03, fs:0.60829 (r=0.667,p=0.559),  time:37.021, tt:3405.908\n",
      "Ep:92, loss:0.00003, loss_test:0.02157, lr:5.10e-03, fs:0.60829 (r=0.667,p=0.559),  time:37.005, tt:3441.502\n",
      "Ep:93, loss:0.00003, loss_test:0.02156, lr:5.05e-03, fs:0.60829 (r=0.667,p=0.559),  time:37.022, tt:3480.109\n",
      "Ep:94, loss:0.00003, loss_test:0.02155, lr:5.00e-03, fs:0.60185 (r=0.657,p=0.556),  time:37.047, tt:3519.461\n",
      "Ep:95, loss:0.00003, loss_test:0.02154, lr:4.95e-03, fs:0.60185 (r=0.657,p=0.556),  time:37.072, tt:3558.865\n",
      "Ep:96, loss:0.00003, loss_test:0.02153, lr:4.90e-03, fs:0.60185 (r=0.657,p=0.556),  time:37.078, tt:3596.543\n",
      "Ep:97, loss:0.00003, loss_test:0.02152, lr:4.85e-03, fs:0.60185 (r=0.657,p=0.556),  time:37.108, tt:3636.613\n",
      "Ep:98, loss:0.00003, loss_test:0.02150, lr:4.80e-03, fs:0.60185 (r=0.657,p=0.556),  time:37.112, tt:3674.093\n",
      "Ep:99, loss:0.00003, loss_test:0.02149, lr:4.75e-03, fs:0.60185 (r=0.657,p=0.556),  time:37.107, tt:3710.736\n",
      "Ep:100, loss:0.00003, loss_test:0.02148, lr:4.71e-03, fs:0.60465 (r=0.657,p=0.560),  time:37.120, tt:3749.144\n",
      "Ep:101, loss:0.00003, loss_test:0.02146, lr:4.66e-03, fs:0.60465 (r=0.657,p=0.560),  time:37.141, tt:3788.354\n",
      "Ep:102, loss:0.00003, loss_test:0.02145, lr:4.61e-03, fs:0.60465 (r=0.657,p=0.560),  time:37.122, tt:3823.517\n",
      "Ep:103, loss:0.00003, loss_test:0.02143, lr:4.57e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.136, tt:3862.160\n",
      "Ep:104, loss:0.00003, loss_test:0.02142, lr:4.52e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.122, tt:3897.839\n",
      "Ep:105, loss:0.00003, loss_test:0.02141, lr:4.48e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.121, tt:3934.851\n",
      "Ep:106, loss:0.00003, loss_test:0.02140, lr:4.43e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.141, tt:3974.070\n",
      "Ep:107, loss:0.00003, loss_test:0.02138, lr:4.39e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.156, tt:4012.826\n",
      "Ep:108, loss:0.00003, loss_test:0.02137, lr:4.34e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.144, tt:4048.720\n",
      "Ep:109, loss:0.00003, loss_test:0.02136, lr:4.30e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.148, tt:4086.231\n",
      "Ep:110, loss:0.00003, loss_test:0.02135, lr:4.26e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.158, tt:4124.534\n",
      "Ep:111, loss:0.00003, loss_test:0.02135, lr:4.21e-03, fs:0.60748 (r=0.657,p=0.565),  time:37.137, tt:4159.381\n",
      "Ep:112, loss:0.00003, loss_test:0.02134, lr:4.17e-03, fs:0.61033 (r=0.657,p=0.570),  time:37.145, tt:4197.396\n",
      "Ep:113, loss:0.00003, loss_test:0.02132, lr:4.13e-03, fs:0.61033 (r=0.657,p=0.570),  time:37.147, tt:4234.727\n",
      "Ep:114, loss:0.00003, loss_test:0.02131, lr:4.09e-03, fs:0.61033 (r=0.657,p=0.570),  time:37.149, tt:4272.123\n",
      "Ep:115, loss:0.00003, loss_test:0.02130, lr:4.05e-03, fs:0.61033 (r=0.657,p=0.570),  time:37.161, tt:4310.716\n",
      "Ep:116, loss:0.00003, loss_test:0.02129, lr:4.01e-03, fs:0.61321 (r=0.657,p=0.575),  time:37.175, tt:4349.500\n",
      "Ep:117, loss:0.00003, loss_test:0.02129, lr:3.97e-03, fs:0.60952 (r=0.646,p=0.577),  time:37.185, tt:4387.831\n",
      "Ep:118, loss:0.00003, loss_test:0.02128, lr:3.93e-03, fs:0.60952 (r=0.646,p=0.577),  time:37.178, tt:4424.150\n",
      "Ep:119, loss:0.00003, loss_test:0.02127, lr:3.89e-03, fs:0.60952 (r=0.646,p=0.577),  time:37.195, tt:4463.401\n",
      "Ep:120, loss:0.00003, loss_test:0.02126, lr:3.85e-03, fs:0.60952 (r=0.646,p=0.577),  time:37.202, tt:4501.472\n",
      "Ep:121, loss:0.00003, loss_test:0.02125, lr:3.81e-03, fs:0.60952 (r=0.646,p=0.577),  time:37.226, tt:4541.531\n",
      "Ep:122, loss:0.00003, loss_test:0.02124, lr:3.77e-03, fs:0.60952 (r=0.646,p=0.577),  time:37.244, tt:4580.963\n",
      "Ep:123, loss:0.00003, loss_test:0.02123, lr:3.73e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.242, tt:4618.002\n",
      "Ep:124, loss:0.00003, loss_test:0.02122, lr:3.70e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.233, tt:4654.137\n",
      "Ep:125, loss:0.00003, loss_test:0.02121, lr:3.66e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.235, tt:4691.588\n",
      "Ep:126, loss:0.00003, loss_test:0.02120, lr:3.62e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.238, tt:4729.271\n",
      "Ep:127, loss:0.00003, loss_test:0.02119, lr:3.59e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.245, tt:4767.318\n",
      "Ep:128, loss:0.00003, loss_test:0.02118, lr:3.55e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.246, tt:4804.729\n",
      "Ep:129, loss:0.00003, loss_test:0.02118, lr:3.52e-03, fs:0.61244 (r=0.646,p=0.582),  time:37.264, tt:4844.316\n",
      "Ep:130, loss:0.00003, loss_test:0.02117, lr:3.48e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.265, tt:4881.756\n",
      "Ep:131, loss:0.00003, loss_test:0.02116, lr:3.45e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.260, tt:4918.299\n",
      "Ep:132, loss:0.00003, loss_test:0.02115, lr:3.41e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.276, tt:4957.749\n",
      "Ep:133, loss:0.00003, loss_test:0.02114, lr:3.38e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.288, tt:4996.528\n",
      "Ep:134, loss:0.00003, loss_test:0.02113, lr:3.34e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.275, tt:5032.099\n",
      "Ep:135, loss:0.00003, loss_test:0.02112, lr:3.31e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.270, tt:5068.691\n",
      "Ep:136, loss:0.00003, loss_test:0.02111, lr:3.28e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.272, tt:5106.310\n",
      "Ep:137, loss:0.00003, loss_test:0.02110, lr:3.24e-03, fs:0.61538 (r=0.646,p=0.587),  time:37.263, tt:5142.301\n",
      "Ep:138, loss:0.00003, loss_test:0.02109, lr:3.21e-03, fs:0.60870 (r=0.636,p=0.583),  time:37.278, tt:5181.668\n",
      "Ep:139, loss:0.00003, loss_test:0.02109, lr:3.18e-03, fs:0.60870 (r=0.636,p=0.583),  time:37.284, tt:5219.735\n",
      "Ep:140, loss:0.00003, loss_test:0.02108, lr:3.15e-03, fs:0.60870 (r=0.636,p=0.583),  time:37.276, tt:5255.978\n",
      "Ep:141, loss:0.00003, loss_test:0.02107, lr:3.12e-03, fs:0.60870 (r=0.636,p=0.583),  time:37.287, tt:5294.821\n",
      "Ep:142, loss:0.00003, loss_test:0.02106, lr:3.09e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.296, tt:5333.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00003, loss_test:0.02105, lr:3.05e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.298, tt:5370.907\n",
      "Ep:144, loss:0.00003, loss_test:0.02104, lr:3.02e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.293, tt:5407.490\n",
      "Ep:145, loss:0.00003, loss_test:0.02104, lr:2.99e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.318, tt:5448.394\n",
      "Ep:146, loss:0.00003, loss_test:0.02103, lr:2.96e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.316, tt:5485.385\n",
      "Ep:147, loss:0.00003, loss_test:0.02102, lr:2.93e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.312, tt:5522.161\n",
      "Ep:148, loss:0.00003, loss_test:0.02102, lr:2.90e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.325, tt:5561.464\n",
      "Ep:149, loss:0.00003, loss_test:0.02101, lr:2.88e-03, fs:0.61165 (r=0.636,p=0.589),  time:37.322, tt:5598.261\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training = gcn_training.Training()\n",
    "training.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "train(training,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training state loaded for configuration: \n",
      "tmp_cv_result_60.pt\n",
      "Previous log: \n",
      "\n",
      "[{'epoch': 0, 'loss': 0.0002718152245506644, 'loss_test': 0.14717204868793488, 'acc': 0.4898989898989899, 'acc2': 0, 'true_positives': 94.0, 'false_positives': 96.0, 'true_negatives': 3.0, 'false_negatives': 5.0, 'recall': 0.9494949494949495, 'specificity': 0.030303030303030304, 'precision': 0.49473684210526314, 'fscore': 0.6505190311418685, 'time_epoch': 21.09198, 'time_total': 21.09198, 'lr': 0.01, 'batch_splits': 1024}]\n",
      "\t \t \t \t ##########Labels##########\n",
      "\t \t \t \t Similar \t Not Similar\n",
      "Prediction Similar: \t \t 94.0 \t \t 96.0\n",
      "Prediction Not Similar:  \t 5.0 \t \t 3.0\n",
      "\t \t \t \t----------------------\n",
      "\t \t \t \t99.0 \t \t 99.0\n",
      "\n",
      "Recall/Sensitivity: 0.9494949494949495\n",
      "Precision: 0.49473684210526314\n",
      "Fscore: 0.6505190311418685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'true_positives': 94.0,\n",
       " 'false_positives': 96.0,\n",
       " 'true_negatives': 3.0,\n",
       " 'false_negatives': 5.0,\n",
       " 'recall': 0.9494949494949495,\n",
       " 'specificity': 0.030303030303030304,\n",
       " 'precision': 0.49473684210526314,\n",
       " 'fscore': 0.6505190311418685,\n",
       " 'acc': 0.4898989898989899}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = gcn_training.Training()\n",
    "training.load_state(path=\"./models/openml_203ds_datasets_matching/isolation/2/cv/best/net_name:Fasttext2_364/optimizer_name:sgd/loss_name:CosineEmbeddingLoss/loss_parameters:0.7+mean|batch_splits:1024|lr:1e-02|epochs_run:00_180/tmp_cv_result_60.pt\")\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "# confusion_matrix_quick(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'])\n",
    "confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14000, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.195, tt:20.195\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13509, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:23.035, tt:46.070\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.12473, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:27.727, tt:83.181\n",
      "Ep:3, loss:0.00050, loss_test:0.10865, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:35.113, tt:140.453\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.10145, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:40.481, tt:202.407\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.09767, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:43.927, tt:263.562\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.09193, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:46.096, tt:322.672\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.08840, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:48.040, tt:384.322\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00038, loss_test:0.08474, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:49.193, tt:442.736\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.08232, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:50.496, tt:504.962\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.08125, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:51.536, tt:566.894\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.07905, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:52.303, tt:627.639\n",
      "Ep:12, loss:0.00032, loss_test:0.07694, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:52.737, tt:685.578\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.07593, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:53.270, tt:745.776\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.07440, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:53.672, tt:805.086\n",
      "Ep:15, loss:0.00028, loss_test:0.07312, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:53.911, tt:862.574\n",
      "Ep:16, loss:0.00026, loss_test:0.07126, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:54.176, tt:920.997\n",
      "Ep:17, loss:0.00025, loss_test:0.06975, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:54.461, tt:980.292\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.06946, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:54.923, tt:1043.536\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.06899, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:55.239, tt:1104.772\n",
      "Ep:20, loss:0.00022, loss_test:0.06713, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:55.501, tt:1165.526\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.06844, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:55.718, tt:1225.807\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.06969, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:55.931, tt:1286.403\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.07246, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:55.999, tt:1343.967\n",
      "Ep:24, loss:0.00018, loss_test:0.07163, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:56.154, tt:1403.862\n",
      "Ep:25, loss:0.00017, loss_test:0.06308, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:56.312, tt:1464.120\n",
      "Ep:26, loss:0.00016, loss_test:0.06159, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:56.410, tt:1523.059\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.06580, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:56.558, tt:1583.631\n",
      "Ep:28, loss:0.00014, loss_test:0.06857, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:56.695, tt:1644.163\n",
      "Ep:29, loss:0.00013, loss_test:0.06822, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:56.799, tt:1703.982\n",
      "Ep:30, loss:0.00012, loss_test:0.06526, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:56.955, tt:1765.607\n",
      "Ep:31, loss:0.00011, loss_test:0.06667, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:57.124, tt:1827.954\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.06467, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:57.224, tt:1888.379\n",
      "Ep:33, loss:0.00010, loss_test:0.06468, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:57.405, tt:1951.778\n",
      "Ep:34, loss:0.00009, loss_test:0.06234, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:57.556, tt:2014.449\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06319, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:57.688, tt:2076.781\n",
      "Ep:36, loss:0.00008, loss_test:0.06058, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:57.807, tt:2138.860\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.06591, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:57.928, tt:2201.257\n",
      "Ep:38, loss:0.00007, loss_test:0.06595, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:57.923, tt:2259.003\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.06824, lr:1.00e-02, fs:0.90426 (r=0.859,p=0.955),  time:58.075, tt:2323.002\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.06848, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:58.255, tt:2388.447\n",
      "Ep:41, loss:0.00006, loss_test:0.06299, lr:1.00e-02, fs:0.90426 (r=0.859,p=0.955),  time:58.497, tt:2456.861\n",
      "Ep:42, loss:0.00006, loss_test:0.06109, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:58.454, tt:2513.508\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.05970, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:58.452, tt:2571.868\n",
      "Ep:44, loss:0.00005, loss_test:0.06242, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:58.453, tt:2630.396\n",
      "Ep:45, loss:0.00005, loss_test:0.06338, lr:1.00e-02, fs:0.90426 (r=0.859,p=0.955),  time:58.541, tt:2692.902\n",
      "Ep:46, loss:0.00005, loss_test:0.06885, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:58.502, tt:2749.574\n",
      "Ep:47, loss:0.00004, loss_test:0.06625, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:58.482, tt:2807.129\n",
      "Ep:48, loss:0.00004, loss_test:0.06192, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:58.521, tt:2867.516\n",
      "Ep:49, loss:0.00004, loss_test:0.06258, lr:1.00e-02, fs:0.90909 (r=0.859,p=0.966),  time:58.515, tt:2925.759\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.06457, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:58.509, tt:2983.959\n",
      "Ep:51, loss:0.00004, loss_test:0.06688, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:58.526, tt:3043.370\n",
      "Ep:52, loss:0.00003, loss_test:0.06752, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:58.522, tt:3101.666\n",
      "Ep:53, loss:0.00003, loss_test:0.06837, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:58.569, tt:3162.721\n",
      "Ep:54, loss:0.00003, loss_test:0.06557, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:58.611, tt:3223.592\n",
      "Ep:55, loss:0.00003, loss_test:0.06399, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:58.615, tt:3282.463\n",
      "Ep:56, loss:0.00003, loss_test:0.06947, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:58.613, tt:3340.966\n",
      "Ep:57, loss:0.00003, loss_test:0.06653, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:58.719, tt:3405.699\n",
      "Ep:58, loss:0.00003, loss_test:0.06927, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:58.763, tt:3466.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00002, loss_test:0.06936, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:58.797, tt:3527.840\n",
      "Ep:60, loss:0.00002, loss_test:0.06414, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:58.895, tt:3592.592\n",
      "Ep:61, loss:0.00002, loss_test:0.06669, lr:9.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:58.984, tt:3657.032\n",
      "Ep:62, loss:0.00002, loss_test:0.06727, lr:9.80e-03, fs:0.86667 (r=0.788,p=0.963),  time:59.026, tt:3718.667\n",
      "Ep:63, loss:0.00002, loss_test:0.06733, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.092, tt:3781.890\n",
      "Ep:64, loss:0.00002, loss_test:0.06828, lr:9.61e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.172, tt:3846.201\n",
      "Ep:65, loss:0.00002, loss_test:0.06841, lr:9.51e-03, fs:0.82081 (r=0.717,p=0.959),  time:59.233, tt:3909.404\n",
      "Ep:66, loss:0.00002, loss_test:0.06673, lr:9.41e-03, fs:0.86813 (r=0.798,p=0.952),  time:59.251, tt:3969.839\n",
      "Ep:67, loss:0.00002, loss_test:0.06722, lr:9.32e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.237, tt:4028.137\n",
      "Ep:68, loss:0.00002, loss_test:0.06916, lr:9.23e-03, fs:0.84270 (r=0.758,p=0.949),  time:59.241, tt:4087.620\n",
      "Ep:69, loss:0.00002, loss_test:0.06603, lr:9.14e-03, fs:0.86188 (r=0.788,p=0.951),  time:59.240, tt:4146.824\n",
      "Ep:70, loss:0.00002, loss_test:0.06871, lr:9.04e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.288, tt:4209.448\n",
      "Ep:71, loss:0.00002, loss_test:0.06806, lr:8.95e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.316, tt:4270.732\n",
      "Ep:72, loss:0.00001, loss_test:0.07219, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.359, tt:4333.241\n",
      "Ep:73, loss:0.00001, loss_test:0.06919, lr:8.78e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.408, tt:4396.212\n",
      "Ep:74, loss:0.00001, loss_test:0.06896, lr:8.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.442, tt:4458.170\n",
      "Ep:75, loss:0.00001, loss_test:0.06795, lr:8.60e-03, fs:0.86667 (r=0.788,p=0.963),  time:59.473, tt:4519.915\n",
      "Ep:76, loss:0.00001, loss_test:0.07030, lr:8.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.487, tt:4580.474\n",
      "Ep:77, loss:0.00001, loss_test:0.07301, lr:8.43e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.505, tt:4641.374\n",
      "Ep:78, loss:0.00001, loss_test:0.06870, lr:8.35e-03, fs:0.86188 (r=0.788,p=0.951),  time:59.526, tt:4702.553\n",
      "Ep:79, loss:0.00001, loss_test:0.06960, lr:8.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.536, tt:4762.902\n",
      "Ep:80, loss:0.00001, loss_test:0.07039, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.552, tt:4823.729\n",
      "Ep:81, loss:0.00001, loss_test:0.06781, lr:8.10e-03, fs:0.86188 (r=0.788,p=0.951),  time:59.575, tt:4885.161\n",
      "Ep:82, loss:0.00001, loss_test:0.07204, lr:8.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:59.587, tt:4945.688\n",
      "Ep:83, loss:0.00001, loss_test:0.07159, lr:7.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.595, tt:5006.011\n",
      "Ep:84, loss:0.00001, loss_test:0.07107, lr:7.86e-03, fs:0.85083 (r=0.778,p=0.939),  time:59.615, tt:5067.306\n",
      "Ep:85, loss:0.00001, loss_test:0.07112, lr:7.78e-03, fs:0.85083 (r=0.778,p=0.939),  time:59.630, tt:5128.197\n",
      "Ep:86, loss:0.00001, loss_test:0.07392, lr:7.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.635, tt:5188.252\n",
      "Ep:87, loss:0.00001, loss_test:0.07170, lr:7.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.638, tt:5248.153\n",
      "Ep:88, loss:0.00001, loss_test:0.06990, lr:7.55e-03, fs:0.86667 (r=0.788,p=0.963),  time:59.636, tt:5307.640\n",
      "Ep:89, loss:0.00001, loss_test:0.07315, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:59.644, tt:5367.923\n",
      "Ep:90, loss:0.00001, loss_test:0.07176, lr:7.40e-03, fs:0.85083 (r=0.778,p=0.939),  time:59.640, tt:5427.231\n",
      "Ep:91, loss:0.00001, loss_test:0.07136, lr:7.32e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.651, tt:5487.911\n",
      "Ep:92, loss:0.00001, loss_test:0.07276, lr:7.25e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.689, tt:5551.090\n",
      "Ep:93, loss:0.00001, loss_test:0.06961, lr:7.18e-03, fs:0.86188 (r=0.788,p=0.951),  time:59.713, tt:5613.054\n",
      "Ep:94, loss:0.00001, loss_test:0.07217, lr:7.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:59.729, tt:5674.265\n",
      "Ep:95, loss:0.00001, loss_test:0.07332, lr:7.03e-03, fs:0.85876 (r=0.768,p=0.974),  time:59.753, tt:5736.324\n",
      "Ep:96, loss:0.00001, loss_test:0.07148, lr:6.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.758, tt:5796.523\n",
      "Ep:97, loss:0.00001, loss_test:0.07147, lr:6.89e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.770, tt:5857.506\n",
      "Ep:98, loss:0.00001, loss_test:0.07317, lr:6.83e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.783, tt:5918.557\n",
      "Ep:99, loss:0.00001, loss_test:0.07250, lr:6.76e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.782, tt:5978.180\n",
      "Ep:100, loss:0.00001, loss_test:0.07092, lr:6.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:59.806, tt:6040.360\n",
      "Ep:101, loss:0.00001, loss_test:0.07198, lr:6.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.803, tt:6099.879\n",
      "Ep:102, loss:0.00001, loss_test:0.07264, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.791, tt:6158.513\n",
      "Ep:103, loss:0.00001, loss_test:0.06990, lr:6.49e-03, fs:0.86667 (r=0.788,p=0.963),  time:59.802, tt:6219.376\n",
      "Ep:104, loss:0.00001, loss_test:0.07659, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:59.837, tt:6282.876\n",
      "Ep:105, loss:0.00001, loss_test:0.07186, lr:6.36e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.851, tt:6344.189\n",
      "Ep:106, loss:0.00001, loss_test:0.07248, lr:6.30e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.848, tt:6403.703\n",
      "Ep:107, loss:0.00001, loss_test:0.07227, lr:6.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.873, tt:6466.235\n",
      "Ep:108, loss:0.00001, loss_test:0.07082, lr:6.17e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.895, tt:6528.571\n",
      "Ep:109, loss:0.00001, loss_test:0.07300, lr:6.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:59.918, tt:6590.953\n",
      "Ep:110, loss:0.00001, loss_test:0.07264, lr:6.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.926, tt:6651.796\n",
      "Ep:111, loss:0.00001, loss_test:0.07095, lr:5.99e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.950, tt:6714.412\n",
      "Ep:112, loss:0.00001, loss_test:0.07238, lr:5.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.955, tt:6774.902\n",
      "Ep:113, loss:0.00001, loss_test:0.07274, lr:5.87e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.951, tt:6834.421\n",
      "Ep:114, loss:0.00001, loss_test:0.07111, lr:5.81e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.966, tt:6896.042\n",
      "Ep:115, loss:0.00000, loss_test:0.07201, lr:5.75e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.964, tt:6955.810\n",
      "Ep:116, loss:0.00000, loss_test:0.07231, lr:5.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.970, tt:7016.454\n",
      "Ep:117, loss:0.00000, loss_test:0.07089, lr:5.64e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.971, tt:7076.554\n",
      "Ep:118, loss:0.00000, loss_test:0.07272, lr:5.58e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.968, tt:7136.185\n",
      "Ep:119, loss:0.00000, loss_test:0.07215, lr:5.53e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.987, tt:7198.476\n",
      "Ep:120, loss:0.00000, loss_test:0.07154, lr:5.47e-03, fs:0.84916 (r=0.768,p=0.950),  time:59.998, tt:7259.746\n",
      "Ep:121, loss:0.00000, loss_test:0.07256, lr:5.42e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.990, tt:7318.814\n",
      "Ep:122, loss:0.00000, loss_test:0.07239, lr:5.36e-03, fs:0.85393 (r=0.768,p=0.962),  time:59.999, tt:7379.835\n",
      "Ep:123, loss:0.00000, loss_test:0.07156, lr:5.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.009, tt:7441.106\n",
      "Ep:124, loss:0.00000, loss_test:0.07259, lr:5.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.015, tt:7501.861\n",
      "Ep:125, loss:0.00000, loss_test:0.07158, lr:5.20e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.039, tt:7564.884\n",
      "Ep:126, loss:0.00000, loss_test:0.07178, lr:5.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:60.042, tt:7625.383\n",
      "Ep:127, loss:0.00000, loss_test:0.07197, lr:5.10e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.049, tt:7686.238\n",
      "Ep:128, loss:0.00000, loss_test:0.07192, lr:5.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.045, tt:7745.857\n",
      "Ep:129, loss:0.00000, loss_test:0.07156, lr:5.00e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.053, tt:7806.871\n",
      "Ep:130, loss:0.00000, loss_test:0.07270, lr:4.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.063, tt:7868.203\n",
      "Ep:131, loss:0.00000, loss_test:0.07142, lr:4.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.058, tt:7927.625\n",
      "Ep:132, loss:0.00000, loss_test:0.07240, lr:4.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.055, tt:7987.291\n",
      "Ep:133, loss:0.00000, loss_test:0.07171, lr:4.80e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.065, tt:8048.670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.07395, lr:4.75e-03, fs:0.85876 (r=0.768,p=0.974),  time:60.087, tt:8111.701\n",
      "Ep:135, loss:0.00000, loss_test:0.07223, lr:4.71e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.090, tt:8172.252\n",
      "Ep:136, loss:0.00000, loss_test:0.07318, lr:4.66e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.103, tt:8234.179\n",
      "Ep:137, loss:0.00000, loss_test:0.07220, lr:4.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:60.117, tt:8296.196\n",
      "Ep:138, loss:0.00000, loss_test:0.07439, lr:4.57e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.133, tt:8358.551\n",
      "Ep:139, loss:0.00000, loss_test:0.07270, lr:4.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:60.143, tt:8420.055\n",
      "Ep:140, loss:0.00000, loss_test:0.07355, lr:4.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.156, tt:8481.926\n",
      "Ep:141, loss:0.00000, loss_test:0.07269, lr:4.43e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.170, tt:8544.099\n",
      "Ep:142, loss:0.00000, loss_test:0.07287, lr:4.39e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.185, tt:8606.515\n",
      "Ep:143, loss:0.00000, loss_test:0.07322, lr:4.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.205, tt:8669.489\n",
      "Ep:144, loss:0.00000, loss_test:0.07229, lr:4.30e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.223, tt:8732.275\n",
      "Ep:145, loss:0.00000, loss_test:0.07356, lr:4.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.238, tt:8794.730\n",
      "Ep:146, loss:0.00000, loss_test:0.07257, lr:4.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.265, tt:8858.949\n",
      "Ep:147, loss:0.00000, loss_test:0.07259, lr:4.17e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.287, tt:8922.455\n",
      "Ep:148, loss:0.00000, loss_test:0.07361, lr:4.13e-03, fs:0.85393 (r=0.768,p=0.962),  time:60.306, tt:8985.546\n",
      "Ep:149, loss:0.00000, loss_test:0.07219, lr:4.09e-03, fs:0.84916 (r=0.768,p=0.950),  time:60.316, tt:9047.457\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14594, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.976, tt:52.976\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14324, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:57.455, tt:114.911\n",
      "Ep:2, loss:0.00053, loss_test:0.13625, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:55.243, tt:165.730\n",
      "Ep:3, loss:0.00048, loss_test:0.12909, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:56.701, tt:226.806\n",
      "Ep:4, loss:0.00045, loss_test:0.12448, lr:1.00e-02, fs:0.60287 (r=0.636,p=0.573),  time:58.199, tt:290.997\n",
      "Ep:5, loss:0.00043, loss_test:0.11969, lr:1.00e-02, fs:0.62385 (r=0.687,p=0.571),  time:59.364, tt:356.181\n",
      "Ep:6, loss:0.00040, loss_test:0.11666, lr:1.00e-02, fs:0.63959 (r=0.636,p=0.643),  time:60.321, tt:422.247\n",
      "Ep:7, loss:0.00038, loss_test:0.11223, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:60.924, tt:487.390\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.11029, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:61.370, tt:552.332\n",
      "Ep:9, loss:0.00035, loss_test:0.10795, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:61.848, tt:618.483\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.10603, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:62.085, tt:682.933\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.10396, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:62.089, tt:745.074\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.10423, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:62.340, tt:810.422\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.10249, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:62.378, tt:873.288\n",
      "Ep:14, loss:0.00027, loss_test:0.10161, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:62.558, tt:938.374\n",
      "Ep:15, loss:0.00026, loss_test:0.10149, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:62.900, tt:1006.398\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.10121, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:62.878, tt:1068.924\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.10093, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:62.920, tt:1132.555\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.09917, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:63.054, tt:1198.032\n",
      "Ep:19, loss:0.00021, loss_test:0.09926, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:63.132, tt:1262.648\n",
      "Ep:20, loss:0.00020, loss_test:0.10033, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:63.225, tt:1327.720\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09813, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:63.272, tt:1391.974\n",
      "Ep:22, loss:0.00018, loss_test:0.09567, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:63.395, tt:1458.090\n",
      "Ep:23, loss:0.00017, loss_test:0.09575, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:63.450, tt:1522.808\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09815, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:63.474, tt:1586.855\n",
      "Ep:25, loss:0.00015, loss_test:0.09659, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:63.489, tt:1650.702\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09309, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:63.499, tt:1714.475\n",
      "Ep:27, loss:0.00013, loss_test:0.09364, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:63.557, tt:1779.605\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09549, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:63.600, tt:1844.390\n",
      "Ep:29, loss:0.00012, loss_test:0.09552, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:63.664, tt:1909.929\n",
      "Ep:30, loss:0.00011, loss_test:0.09470, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:63.786, tt:1977.377\n",
      "Ep:31, loss:0.00011, loss_test:0.09355, lr:1.00e-02, fs:0.74419 (r=0.646,p=0.877),  time:63.864, tt:2043.652\n",
      "Ep:32, loss:0.00010, loss_test:0.09131, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:63.973, tt:2111.121\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.09079, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:64.133, tt:2180.516\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.08949, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:64.150, tt:2245.242\n",
      "Ep:35, loss:0.00009, loss_test:0.09562, lr:1.00e-02, fs:0.73494 (r=0.616,p=0.910),  time:64.189, tt:2310.794\n",
      "Ep:36, loss:0.00008, loss_test:0.09131, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:64.225, tt:2376.313\n",
      "Ep:37, loss:0.00008, loss_test:0.09549, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:64.270, tt:2442.260\n",
      "Ep:38, loss:0.00008, loss_test:0.09600, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:64.293, tt:2507.440\n",
      "Ep:39, loss:0.00007, loss_test:0.09178, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:64.337, tt:2573.490\n",
      "Ep:40, loss:0.00007, loss_test:0.09611, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:64.334, tt:2637.697\n",
      "Ep:41, loss:0.00007, loss_test:0.09669, lr:1.00e-02, fs:0.69512 (r=0.576,p=0.877),  time:64.321, tt:2701.472\n",
      "Ep:42, loss:0.00006, loss_test:0.09222, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:64.278, tt:2763.972\n",
      "Ep:43, loss:0.00006, loss_test:0.09428, lr:1.00e-02, fs:0.70370 (r=0.576,p=0.905),  time:64.252, tt:2827.083\n",
      "Ep:44, loss:0.00006, loss_test:0.09600, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:64.251, tt:2891.274\n",
      "Ep:45, loss:0.00005, loss_test:0.09842, lr:9.90e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.240, tt:2955.061\n",
      "Ep:46, loss:0.00005, loss_test:0.09277, lr:9.80e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.233, tt:3018.936\n",
      "Ep:47, loss:0.00005, loss_test:0.09340, lr:9.70e-03, fs:0.72289 (r=0.606,p=0.896),  time:64.279, tt:3085.391\n",
      "Ep:48, loss:0.00005, loss_test:0.09367, lr:9.61e-03, fs:0.72840 (r=0.596,p=0.937),  time:64.309, tt:3151.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00005, loss_test:0.09369, lr:9.51e-03, fs:0.70440 (r=0.566,p=0.933),  time:64.345, tt:3217.236\n",
      "Ep:50, loss:0.00004, loss_test:0.09287, lr:9.41e-03, fs:0.70440 (r=0.566,p=0.933),  time:64.377, tt:3283.243\n",
      "Ep:51, loss:0.00004, loss_test:0.09390, lr:9.32e-03, fs:0.70440 (r=0.566,p=0.933),  time:64.388, tt:3348.158\n",
      "Ep:52, loss:0.00004, loss_test:0.09117, lr:9.23e-03, fs:0.75152 (r=0.626,p=0.939),  time:64.454, tt:3416.069\n",
      "Ep:53, loss:0.00004, loss_test:0.09348, lr:9.14e-03, fs:0.68790 (r=0.545,p=0.931),  time:64.439, tt:3479.697\n",
      "Ep:54, loss:0.00004, loss_test:0.09610, lr:9.04e-03, fs:0.67105 (r=0.515,p=0.962),  time:64.446, tt:3544.519\n",
      "Ep:55, loss:0.00004, loss_test:0.09258, lr:8.95e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.489, tt:3611.366\n",
      "Ep:56, loss:0.00004, loss_test:0.09237, lr:8.86e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.512, tt:3677.181\n",
      "Ep:57, loss:0.00004, loss_test:0.09964, lr:8.78e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.543, tt:3743.509\n",
      "Ep:58, loss:0.00003, loss_test:0.09834, lr:8.69e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.594, tt:3811.055\n",
      "Ep:59, loss:0.00003, loss_test:0.09705, lr:8.60e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.616, tt:3876.959\n",
      "Ep:60, loss:0.00003, loss_test:0.09340, lr:8.51e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.640, tt:3943.035\n",
      "Ep:61, loss:0.00003, loss_test:0.09665, lr:8.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.592, tt:4004.730\n",
      "Ep:62, loss:0.00003, loss_test:0.09511, lr:8.35e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.621, tt:4071.101\n",
      "Ep:63, loss:0.00003, loss_test:0.09730, lr:8.26e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.649, tt:4137.516\n",
      "Ep:64, loss:0.00003, loss_test:0.09885, lr:8.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.690, tt:4204.879\n",
      "Ep:65, loss:0.00003, loss_test:0.09713, lr:8.10e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.706, tt:4270.584\n",
      "Ep:66, loss:0.00003, loss_test:0.09533, lr:8.02e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.704, tt:4335.179\n",
      "Ep:67, loss:0.00003, loss_test:0.09911, lr:7.94e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.713, tt:4400.453\n",
      "Ep:68, loss:0.00002, loss_test:0.09674, lr:7.86e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.740, tt:4467.057\n",
      "Ep:69, loss:0.00002, loss_test:0.09755, lr:7.78e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.752, tt:4532.648\n",
      "Ep:70, loss:0.00002, loss_test:0.09949, lr:7.70e-03, fs:0.70886 (r=0.566,p=0.949),  time:64.753, tt:4597.435\n",
      "Ep:71, loss:0.00002, loss_test:0.10240, lr:7.62e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.775, tt:4663.834\n",
      "Ep:72, loss:0.00002, loss_test:0.09913, lr:7.55e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.754, tt:4727.021\n",
      "Ep:73, loss:0.00002, loss_test:0.09963, lr:7.47e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.735, tt:4790.368\n",
      "Ep:74, loss:0.00002, loss_test:0.09713, lr:7.40e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.736, tt:4855.204\n",
      "Ep:75, loss:0.00002, loss_test:0.10181, lr:7.32e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.745, tt:4920.596\n",
      "Ep:76, loss:0.00002, loss_test:0.09798, lr:7.25e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.718, tt:4983.275\n",
      "Ep:77, loss:0.00002, loss_test:0.10295, lr:7.18e-03, fs:0.70886 (r=0.566,p=0.949),  time:64.705, tt:5046.959\n",
      "Ep:78, loss:0.00002, loss_test:0.10083, lr:7.11e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.691, tt:5110.574\n",
      "Ep:79, loss:0.00002, loss_test:0.09927, lr:7.03e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.688, tt:5175.006\n",
      "Ep:80, loss:0.00002, loss_test:0.09719, lr:6.96e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.643, tt:5236.109\n",
      "Ep:81, loss:0.00002, loss_test:0.10056, lr:6.89e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.620, tt:5298.861\n",
      "Ep:82, loss:0.00002, loss_test:0.10336, lr:6.83e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.606, tt:5362.292\n",
      "Ep:83, loss:0.00002, loss_test:0.10008, lr:6.76e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.595, tt:5425.992\n",
      "Ep:84, loss:0.00002, loss_test:0.09738, lr:6.69e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.570, tt:5488.467\n",
      "Ep:85, loss:0.00002, loss_test:0.10019, lr:6.62e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.586, tt:5554.422\n",
      "Ep:86, loss:0.00002, loss_test:0.09963, lr:6.56e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.572, tt:5617.745\n",
      "Ep:87, loss:0.00001, loss_test:0.10678, lr:6.49e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.559, tt:5681.164\n",
      "Ep:88, loss:0.00001, loss_test:0.10081, lr:6.43e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.554, tt:5745.345\n",
      "Ep:89, loss:0.00001, loss_test:0.09856, lr:6.36e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.567, tt:5811.012\n",
      "Ep:90, loss:0.00001, loss_test:0.10223, lr:6.30e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.559, tt:5874.828\n",
      "Ep:91, loss:0.00001, loss_test:0.10344, lr:6.24e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.554, tt:5938.952\n",
      "Ep:92, loss:0.00001, loss_test:0.10146, lr:6.17e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.541, tt:6002.335\n",
      "Ep:93, loss:0.00001, loss_test:0.10110, lr:6.11e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.524, tt:6065.267\n",
      "Ep:94, loss:0.00001, loss_test:0.09941, lr:6.05e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.515, tt:6128.931\n",
      "Ep:95, loss:0.00001, loss_test:0.10336, lr:5.99e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.505, tt:6192.458\n",
      "Ep:96, loss:0.00001, loss_test:0.10070, lr:5.93e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.495, tt:6256.021\n",
      "Ep:97, loss:0.00001, loss_test:0.10150, lr:5.87e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.495, tt:6320.484\n",
      "Ep:98, loss:0.00001, loss_test:0.10265, lr:5.81e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.492, tt:6384.740\n",
      "Ep:99, loss:0.00001, loss_test:0.10619, lr:5.75e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.468, tt:6446.811\n",
      "Ep:100, loss:0.00001, loss_test:0.09959, lr:5.70e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.441, tt:6508.496\n",
      "Ep:101, loss:0.00001, loss_test:0.10409, lr:5.64e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.457, tt:6574.590\n",
      "Ep:102, loss:0.00001, loss_test:0.10180, lr:5.58e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.431, tt:6636.369\n",
      "Ep:103, loss:0.00001, loss_test:0.10305, lr:5.53e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.430, tt:6700.720\n",
      "Ep:104, loss:0.00001, loss_test:0.10152, lr:5.47e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.436, tt:6765.799\n",
      "Ep:105, loss:0.00001, loss_test:0.10204, lr:5.42e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.413, tt:6827.730\n",
      "Ep:106, loss:0.00001, loss_test:0.10335, lr:5.36e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.397, tt:6890.449\n",
      "Ep:107, loss:0.00001, loss_test:0.10259, lr:5.31e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.392, tt:6954.289\n",
      "Ep:108, loss:0.00001, loss_test:0.10174, lr:5.26e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.363, tt:7015.536\n",
      "Ep:109, loss:0.00001, loss_test:0.10475, lr:5.20e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.347, tt:7078.179\n",
      "Ep:110, loss:0.00001, loss_test:0.10036, lr:5.15e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.323, tt:7139.851\n",
      "Ep:111, loss:0.00001, loss_test:0.10288, lr:5.10e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.331, tt:7205.022\n",
      "Ep:112, loss:0.00001, loss_test:0.10234, lr:5.05e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.308, tt:7266.825\n",
      "Ep:113, loss:0.00001, loss_test:0.10236, lr:5.00e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.296, tt:7329.701\n",
      "Ep:114, loss:0.00001, loss_test:0.10299, lr:4.95e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.274, tt:7391.487\n",
      "Ep:115, loss:0.00001, loss_test:0.10192, lr:4.90e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.242, tt:7452.111\n",
      "Ep:116, loss:0.00001, loss_test:0.10237, lr:4.85e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.223, tt:7514.113\n",
      "Ep:117, loss:0.00001, loss_test:0.10243, lr:4.80e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.196, tt:7575.083\n",
      "Ep:118, loss:0.00001, loss_test:0.10298, lr:4.75e-03, fs:0.66225 (r=0.505,p=0.962),  time:64.180, tt:7637.443\n",
      "Ep:119, loss:0.00001, loss_test:0.10233, lr:4.71e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.174, tt:7700.845\n",
      "Ep:120, loss:0.00001, loss_test:0.10226, lr:4.66e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.154, tt:7762.612\n",
      "Ep:121, loss:0.00001, loss_test:0.10311, lr:4.61e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.137, tt:7824.687\n",
      "Ep:122, loss:0.00001, loss_test:0.10206, lr:4.57e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.125, tt:7887.431\n",
      "Ep:123, loss:0.00001, loss_test:0.10315, lr:4.52e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.120, tt:7950.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00001, loss_test:0.10291, lr:4.48e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.096, tt:8011.956\n",
      "Ep:125, loss:0.00001, loss_test:0.10260, lr:4.43e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.077, tt:8073.711\n",
      "Ep:126, loss:0.00001, loss_test:0.10340, lr:4.39e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.058, tt:8135.310\n",
      "Ep:127, loss:0.00001, loss_test:0.10225, lr:4.34e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.045, tt:8197.745\n",
      "Ep:128, loss:0.00001, loss_test:0.10460, lr:4.30e-03, fs:0.66667 (r=0.505,p=0.980),  time:64.025, tt:8259.173\n",
      "Ep:129, loss:0.00001, loss_test:0.10235, lr:4.26e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.996, tt:8319.493\n",
      "Ep:130, loss:0.00001, loss_test:0.10510, lr:4.21e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.968, tt:8379.849\n",
      "Ep:131, loss:0.00001, loss_test:0.10283, lr:4.17e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.946, tt:8440.925\n",
      "Ep:132, loss:0.00001, loss_test:0.10330, lr:4.13e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.924, tt:8501.922\n",
      "Ep:133, loss:0.00001, loss_test:0.10364, lr:4.09e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.911, tt:8564.057\n",
      "Ep:134, loss:0.00001, loss_test:0.10307, lr:4.05e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.893, tt:8625.580\n",
      "Ep:135, loss:0.00001, loss_test:0.10403, lr:4.01e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.885, tt:8688.399\n",
      "Ep:136, loss:0.00001, loss_test:0.10268, lr:3.97e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.865, tt:8749.542\n",
      "Ep:137, loss:0.00001, loss_test:0.10448, lr:3.93e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.831, tt:8808.617\n",
      "Ep:138, loss:0.00001, loss_test:0.10288, lr:3.89e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.811, tt:8869.681\n",
      "Ep:139, loss:0.00001, loss_test:0.10348, lr:3.85e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.793, tt:8931.076\n",
      "Ep:140, loss:0.00001, loss_test:0.10357, lr:3.81e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.771, tt:8991.670\n",
      "Ep:141, loss:0.00001, loss_test:0.10372, lr:3.77e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.771, tt:9055.454\n",
      "Ep:142, loss:0.00001, loss_test:0.10326, lr:3.73e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.745, tt:9115.526\n",
      "Ep:143, loss:0.00001, loss_test:0.10338, lr:3.70e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.710, tt:9174.198\n",
      "Ep:144, loss:0.00001, loss_test:0.10289, lr:3.66e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.695, tt:9235.797\n",
      "Ep:145, loss:0.00001, loss_test:0.10361, lr:3.62e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.671, tt:9296.007\n",
      "Ep:146, loss:0.00001, loss_test:0.10303, lr:3.59e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.659, tt:9357.922\n",
      "Ep:147, loss:0.00001, loss_test:0.10389, lr:3.55e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.632, tt:9417.517\n",
      "Ep:148, loss:0.00001, loss_test:0.10344, lr:3.52e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.599, tt:9476.317\n",
      "Ep:149, loss:0.00001, loss_test:0.10300, lr:3.48e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.587, tt:9538.016\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14127, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:54.781, tt:54.781\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13695, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:55.042, tt:110.084\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.12801, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:54.722, tt:164.165\n",
      "Ep:3, loss:0.00048, loss_test:0.12109, lr:1.00e-02, fs:0.63000 (r=0.636,p=0.624),  time:55.579, tt:222.316\n",
      "Ep:4, loss:0.00045, loss_test:0.11506, lr:1.00e-02, fs:0.65000 (r=0.657,p=0.644),  time:57.042, tt:285.208\n",
      "Ep:5, loss:0.00043, loss_test:0.11185, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:58.260, tt:349.562\n",
      "Ep:6, loss:0.00041, loss_test:0.11216, lr:1.00e-02, fs:0.65641 (r=0.646,p=0.667),  time:58.915, tt:412.406\n",
      "Ep:7, loss:0.00039, loss_test:0.10869, lr:1.00e-02, fs:0.66667 (r=0.677,p=0.657),  time:59.538, tt:476.301\n",
      "Ep:8, loss:0.00037, loss_test:0.10952, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:60.131, tt:541.181\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.10488, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:60.427, tt:604.271\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.10398, lr:1.00e-02, fs:0.69474 (r=0.667,p=0.725),  time:60.763, tt:668.388\n",
      "Ep:11, loss:0.00032, loss_test:0.10157, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:61.278, tt:735.335\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.10238, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:61.456, tt:798.924\n",
      "Ep:13, loss:0.00030, loss_test:0.10190, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:61.843, tt:865.808\n",
      "Ep:14, loss:0.00028, loss_test:0.10201, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:62.120, tt:931.796\n",
      "Ep:15, loss:0.00027, loss_test:0.09958, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:62.358, tt:997.735\n",
      "Ep:16, loss:0.00026, loss_test:0.10039, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:62.509, tt:1062.651\n",
      "Ep:17, loss:0.00025, loss_test:0.09760, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:62.687, tt:1128.370\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.10000, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:62.750, tt:1192.251\n",
      "Ep:19, loss:0.00023, loss_test:0.09589, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:62.826, tt:1256.522\n",
      "Ep:20, loss:0.00022, loss_test:0.09894, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:62.949, tt:1321.933\n",
      "Ep:21, loss:0.00021, loss_test:0.09466, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:63.068, tt:1387.496\n",
      "Ep:22, loss:0.00020, loss_test:0.09624, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:63.110, tt:1451.527\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.09240, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:63.021, tt:1512.500\n",
      "Ep:24, loss:0.00018, loss_test:0.09148, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:63.055, tt:1576.370\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.09035, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:63.061, tt:1639.597\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.08948, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:63.023, tt:1701.613\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.08912, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:63.017, tt:1764.462\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08728, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:63.078, tt:1829.265\n",
      "Ep:29, loss:0.00014, loss_test:0.08862, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.174, tt:1895.212\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08781, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:63.157, tt:1957.862\n",
      "Ep:31, loss:0.00012, loss_test:0.08633, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:63.213, tt:2022.816\n",
      "Ep:32, loss:0.00011, loss_test:0.08375, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:63.283, tt:2088.327\n",
      "Ep:33, loss:0.00011, loss_test:0.08420, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.273, tt:2151.294\n",
      "Ep:34, loss:0.00010, loss_test:0.09082, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:63.295, tt:2215.330\n",
      "Ep:35, loss:0.00010, loss_test:0.08539, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.351, tt:2280.653\n",
      "Ep:36, loss:0.00009, loss_test:0.08570, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:63.420, tt:2346.549\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.08638, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:63.462, tt:2411.544\n",
      "Ep:38, loss:0.00008, loss_test:0.08284, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:63.458, tt:2474.868\n",
      "Ep:39, loss:0.00008, loss_test:0.08951, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:63.532, tt:2541.274\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00008, loss_test:0.08732, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.584, tt:2606.946\n",
      "Ep:41, loss:0.00007, loss_test:0.08436, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:63.594, tt:2670.957\n",
      "Ep:42, loss:0.00007, loss_test:0.08513, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:63.619, tt:2735.608\n",
      "Ep:43, loss:0.00006, loss_test:0.09031, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.675, tt:2801.707\n",
      "Ep:44, loss:0.00006, loss_test:0.08662, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:63.706, tt:2866.772\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00006, loss_test:0.08800, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:63.682, tt:2929.375\n",
      "Ep:46, loss:0.00005, loss_test:0.08750, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.715, tt:2994.601\n",
      "Ep:47, loss:0.00005, loss_test:0.08633, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:63.736, tt:3059.324\n",
      "Ep:48, loss:0.00005, loss_test:0.08462, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:63.730, tt:3122.775\n",
      "Ep:49, loss:0.00005, loss_test:0.09426, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:63.710, tt:3185.511\n",
      "Ep:50, loss:0.00005, loss_test:0.08865, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:63.696, tt:3248.508\n",
      "Ep:51, loss:0.00005, loss_test:0.08849, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.682, tt:3311.455\n",
      "Ep:52, loss:0.00004, loss_test:0.09239, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:63.739, tt:3378.179\n",
      "Ep:53, loss:0.00004, loss_test:0.08939, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:63.772, tt:3443.693\n",
      "Ep:54, loss:0.00004, loss_test:0.09026, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:63.712, tt:3504.152\n",
      "Ep:55, loss:0.00004, loss_test:0.09084, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:63.679, tt:3566.008\n",
      "Ep:56, loss:0.00004, loss_test:0.09210, lr:9.90e-03, fs:0.73939 (r=0.616,p=0.924),  time:63.677, tt:3629.607\n",
      "Ep:57, loss:0.00003, loss_test:0.09043, lr:9.80e-03, fs:0.76190 (r=0.646,p=0.928),  time:63.667, tt:3692.705\n",
      "Ep:58, loss:0.00003, loss_test:0.09248, lr:9.70e-03, fs:0.70000 (r=0.566,p=0.918),  time:63.667, tt:3756.357\n",
      "Ep:59, loss:0.00003, loss_test:0.09194, lr:9.61e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.639, tt:3818.356\n",
      "Ep:60, loss:0.00003, loss_test:0.08971, lr:9.51e-03, fs:0.75449 (r=0.636,p=0.926),  time:63.638, tt:3881.900\n",
      "Ep:61, loss:0.00003, loss_test:0.09950, lr:9.41e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.626, tt:3944.783\n",
      "Ep:62, loss:0.00003, loss_test:0.09391, lr:9.32e-03, fs:0.73939 (r=0.616,p=0.924),  time:63.597, tt:4006.592\n",
      "Ep:63, loss:0.00003, loss_test:0.09413, lr:9.23e-03, fs:0.71605 (r=0.586,p=0.921),  time:63.563, tt:4068.032\n",
      "Ep:64, loss:0.00003, loss_test:0.09696, lr:9.14e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.544, tt:4130.374\n",
      "Ep:65, loss:0.00003, loss_test:0.09252, lr:9.04e-03, fs:0.71698 (r=0.576,p=0.950),  time:63.516, tt:4192.065\n",
      "Ep:66, loss:0.00002, loss_test:0.09504, lr:8.95e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.500, tt:4254.513\n",
      "Ep:67, loss:0.00002, loss_test:0.09577, lr:8.86e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.492, tt:4317.461\n",
      "Ep:68, loss:0.00002, loss_test:0.09451, lr:8.78e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.508, tt:4382.073\n",
      "Ep:69, loss:0.00002, loss_test:0.09542, lr:8.69e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.518, tt:4446.269\n",
      "Ep:70, loss:0.00002, loss_test:0.09572, lr:8.60e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.482, tt:4507.251\n",
      "Ep:71, loss:0.00002, loss_test:0.09464, lr:8.51e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.500, tt:4572.015\n",
      "Ep:72, loss:0.00002, loss_test:0.09639, lr:8.43e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.485, tt:4634.438\n",
      "Ep:73, loss:0.00002, loss_test:0.09746, lr:8.35e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.466, tt:4696.518\n",
      "Ep:74, loss:0.00002, loss_test:0.09599, lr:8.26e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.450, tt:4758.713\n",
      "Ep:75, loss:0.00002, loss_test:0.09880, lr:8.18e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.448, tt:4822.045\n",
      "Ep:76, loss:0.00002, loss_test:0.09784, lr:8.10e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.447, tt:4885.392\n",
      "Ep:77, loss:0.00002, loss_test:0.10032, lr:8.02e-03, fs:0.71338 (r=0.566,p=0.966),  time:63.415, tt:4946.366\n",
      "Ep:78, loss:0.00002, loss_test:0.10024, lr:7.94e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.390, tt:5007.814\n",
      "Ep:79, loss:0.00002, loss_test:0.09836, lr:7.86e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.371, tt:5069.681\n",
      "Ep:80, loss:0.00002, loss_test:0.09950, lr:7.78e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.383, tt:5134.025\n",
      "Ep:81, loss:0.00001, loss_test:0.09758, lr:7.70e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.347, tt:5194.488\n",
      "Ep:82, loss:0.00001, loss_test:0.10081, lr:7.62e-03, fs:0.71338 (r=0.566,p=0.966),  time:63.367, tt:5259.472\n",
      "Ep:83, loss:0.00001, loss_test:0.09885, lr:7.55e-03, fs:0.70886 (r=0.566,p=0.949),  time:63.328, tt:5319.551\n",
      "Ep:84, loss:0.00001, loss_test:0.09951, lr:7.47e-03, fs:0.71338 (r=0.566,p=0.966),  time:63.318, tt:5382.024\n",
      "Ep:85, loss:0.00001, loss_test:0.09968, lr:7.40e-03, fs:0.71338 (r=0.566,p=0.966),  time:63.292, tt:5443.071\n",
      "Ep:86, loss:0.00001, loss_test:0.10127, lr:7.32e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.267, tt:5504.240\n",
      "Ep:87, loss:0.00001, loss_test:0.09778, lr:7.25e-03, fs:0.71338 (r=0.566,p=0.966),  time:63.237, tt:5564.820\n",
      "Ep:88, loss:0.00001, loss_test:0.10096, lr:7.18e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.236, tt:5627.963\n",
      "Ep:89, loss:0.00001, loss_test:0.09964, lr:7.11e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.236, tt:5691.239\n",
      "Ep:90, loss:0.00001, loss_test:0.10102, lr:7.03e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.240, tt:5754.881\n",
      "Ep:91, loss:0.00001, loss_test:0.10060, lr:6.96e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.228, tt:5816.980\n",
      "Ep:92, loss:0.00001, loss_test:0.10068, lr:6.89e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.224, tt:5879.822\n",
      "Ep:93, loss:0.00001, loss_test:0.10207, lr:6.83e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.205, tt:5941.256\n",
      "Ep:94, loss:0.00001, loss_test:0.10039, lr:6.76e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.184, tt:6002.492\n",
      "Ep:95, loss:0.00001, loss_test:0.10072, lr:6.69e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.164, tt:6063.752\n",
      "Ep:96, loss:0.00001, loss_test:0.10103, lr:6.62e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.166, tt:6127.122\n",
      "Ep:97, loss:0.00001, loss_test:0.10054, lr:6.56e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.151, tt:6188.813\n",
      "Ep:98, loss:0.00001, loss_test:0.10235, lr:6.49e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.152, tt:6252.092\n",
      "Ep:99, loss:0.00001, loss_test:0.10386, lr:6.43e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.114, tt:6311.422\n",
      "Ep:100, loss:0.00001, loss_test:0.10245, lr:6.36e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.112, tt:6374.349\n",
      "Ep:101, loss:0.00001, loss_test:0.10308, lr:6.30e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.101, tt:6436.264\n",
      "Ep:102, loss:0.00001, loss_test:0.10034, lr:6.24e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.095, tt:6498.771\n",
      "Ep:103, loss:0.00001, loss_test:0.10230, lr:6.17e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.091, tt:6561.417\n",
      "Ep:104, loss:0.00001, loss_test:0.10213, lr:6.11e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.097, tt:6625.149\n",
      "Ep:105, loss:0.00001, loss_test:0.10306, lr:6.05e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.094, tt:6688.016\n",
      "Ep:106, loss:0.00001, loss_test:0.10298, lr:5.99e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.104, tt:6752.171\n",
      "Ep:107, loss:0.00001, loss_test:0.10311, lr:5.93e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.078, tt:6812.384\n",
      "Ep:108, loss:0.00001, loss_test:0.10159, lr:5.87e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.082, tt:6875.986\n",
      "Ep:109, loss:0.00001, loss_test:0.10205, lr:5.81e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.079, tt:6938.702\n",
      "Ep:110, loss:0.00001, loss_test:0.10198, lr:5.75e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.085, tt:7002.462\n",
      "Ep:111, loss:0.00001, loss_test:0.10246, lr:5.70e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.088, tt:7065.889\n",
      "Ep:112, loss:0.00001, loss_test:0.10212, lr:5.64e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.085, tt:7128.557\n",
      "Ep:113, loss:0.00001, loss_test:0.10143, lr:5.58e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.079, tt:7191.029\n",
      "Ep:114, loss:0.00001, loss_test:0.10254, lr:5.53e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.064, tt:7252.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00001, loss_test:0.10380, lr:5.47e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.076, tt:7316.795\n",
      "Ep:116, loss:0.00001, loss_test:0.10288, lr:5.42e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.076, tt:7379.926\n",
      "Ep:117, loss:0.00001, loss_test:0.10265, lr:5.36e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.083, tt:7443.761\n",
      "Ep:118, loss:0.00001, loss_test:0.10294, lr:5.31e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.078, tt:7506.333\n",
      "Ep:119, loss:0.00001, loss_test:0.10187, lr:5.26e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.087, tt:7570.476\n",
      "Ep:120, loss:0.00001, loss_test:0.10351, lr:5.20e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.101, tt:7635.267\n",
      "Ep:121, loss:0.00001, loss_test:0.10311, lr:5.15e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.132, tt:7702.097\n",
      "Ep:122, loss:0.00001, loss_test:0.10321, lr:5.10e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.139, tt:7766.141\n",
      "Ep:123, loss:0.00001, loss_test:0.10243, lr:5.05e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.140, tt:7829.375\n",
      "Ep:124, loss:0.00001, loss_test:0.10182, lr:5.00e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.141, tt:7892.665\n",
      "Ep:125, loss:0.00001, loss_test:0.10335, lr:4.95e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.135, tt:7954.955\n",
      "Ep:126, loss:0.00001, loss_test:0.10284, lr:4.90e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.135, tt:8018.171\n",
      "Ep:127, loss:0.00001, loss_test:0.10336, lr:4.85e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.148, tt:8082.974\n",
      "Ep:128, loss:0.00001, loss_test:0.10260, lr:4.80e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.172, tt:8149.137\n",
      "Ep:129, loss:0.00001, loss_test:0.10242, lr:4.75e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.170, tt:8212.160\n",
      "Ep:130, loss:0.00001, loss_test:0.10271, lr:4.71e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.193, tt:8278.247\n",
      "Ep:131, loss:0.00001, loss_test:0.10335, lr:4.66e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.196, tt:8341.933\n",
      "Ep:132, loss:0.00001, loss_test:0.10445, lr:4.61e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.192, tt:8404.561\n",
      "Ep:133, loss:0.00001, loss_test:0.10240, lr:4.57e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.180, tt:8466.096\n",
      "Ep:134, loss:0.00001, loss_test:0.10369, lr:4.52e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.176, tt:8528.768\n",
      "Ep:135, loss:0.00001, loss_test:0.10304, lr:4.48e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.175, tt:8591.809\n",
      "Ep:136, loss:0.00001, loss_test:0.10263, lr:4.43e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.170, tt:8654.253\n",
      "Ep:137, loss:0.00001, loss_test:0.10247, lr:4.39e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.177, tt:8718.376\n",
      "Ep:138, loss:0.00001, loss_test:0.10289, lr:4.34e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.176, tt:8781.404\n",
      "Ep:139, loss:0.00001, loss_test:0.10295, lr:4.30e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.186, tt:8846.014\n",
      "Ep:140, loss:0.00001, loss_test:0.10286, lr:4.26e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.197, tt:8910.836\n",
      "Ep:141, loss:0.00001, loss_test:0.10226, lr:4.21e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.217, tt:8976.759\n",
      "Ep:142, loss:0.00001, loss_test:0.10321, lr:4.17e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.250, tt:9044.736\n",
      "Ep:143, loss:0.00001, loss_test:0.10267, lr:4.13e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.269, tt:9110.742\n",
      "Ep:144, loss:0.00001, loss_test:0.10309, lr:4.09e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.287, tt:9176.637\n",
      "Ep:145, loss:0.00001, loss_test:0.10267, lr:4.05e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.285, tt:9239.588\n",
      "Ep:146, loss:0.00001, loss_test:0.10303, lr:4.01e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.307, tt:9306.167\n",
      "Ep:147, loss:0.00001, loss_test:0.10281, lr:3.97e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.296, tt:9367.826\n",
      "Ep:148, loss:0.00001, loss_test:0.10351, lr:3.93e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.310, tt:9433.141\n",
      "Ep:149, loss:0.00000, loss_test:0.10262, lr:3.89e-03, fs:0.71795 (r=0.566,p=0.982),  time:63.318, tt:9497.636\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14590, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.984, tt:56.984\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.14368, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.551, tt:119.102\n",
      "Ep:2, loss:0.00051, loss_test:0.13848, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:58.069, tt:174.206\n",
      "Ep:3, loss:0.00046, loss_test:0.13595, lr:1.00e-02, fs:0.55959 (r=0.545,p=0.574),  time:59.569, tt:238.276\n",
      "Ep:4, loss:0.00044, loss_test:0.13095, lr:1.00e-02, fs:0.61883 (r=0.697,p=0.556),  time:60.737, tt:303.687\n",
      "Ep:5, loss:0.00042, loss_test:0.12742, lr:1.00e-02, fs:0.58537 (r=0.606,p=0.566),  time:61.480, tt:368.879\n",
      "Ep:6, loss:0.00040, loss_test:0.12369, lr:1.00e-02, fs:0.61836 (r=0.646,p=0.593),  time:61.859, tt:433.015\n",
      "Ep:7, loss:0.00038, loss_test:0.12076, lr:1.00e-02, fs:0.59615 (r=0.626,p=0.569),  time:62.164, tt:497.310\n",
      "Ep:8, loss:0.00036, loss_test:0.11882, lr:1.00e-02, fs:0.60302 (r=0.606,p=0.600),  time:62.292, tt:560.625\n",
      "Ep:9, loss:0.00034, loss_test:0.11589, lr:1.00e-02, fs:0.64390 (r=0.667,p=0.623),  time:62.504, tt:625.040\n",
      "Ep:10, loss:0.00033, loss_test:0.11494, lr:1.00e-02, fs:0.60104 (r=0.586,p=0.617),  time:62.786, tt:690.652\n",
      "Ep:11, loss:0.00031, loss_test:0.11144, lr:1.00e-02, fs:0.64039 (r=0.657,p=0.625),  time:62.821, tt:753.850\n",
      "Ep:12, loss:0.00030, loss_test:0.11291, lr:9.90e-03, fs:0.61376 (r=0.586,p=0.644),  time:62.716, tt:815.313\n",
      "Ep:13, loss:0.00029, loss_test:0.11062, lr:9.80e-03, fs:0.61702 (r=0.586,p=0.652),  time:62.564, tt:875.897\n",
      "Ep:14, loss:0.00028, loss_test:0.11081, lr:9.70e-03, fs:0.60733 (r=0.586,p=0.630),  time:62.441, tt:936.616\n",
      "Ep:15, loss:0.00027, loss_test:0.11421, lr:9.61e-03, fs:0.61364 (r=0.545,p=0.701),  time:62.449, tt:999.191\n",
      "Ep:16, loss:0.00025, loss_test:0.10960, lr:9.51e-03, fs:0.61538 (r=0.566,p=0.675),  time:62.315, tt:1059.362\n",
      "Ep:17, loss:0.00024, loss_test:0.11344, lr:9.41e-03, fs:0.62069 (r=0.545,p=0.720),  time:62.270, tt:1120.865\n",
      "Ep:18, loss:0.00023, loss_test:0.11527, lr:9.32e-03, fs:0.62791 (r=0.545,p=0.740),  time:62.135, tt:1180.571\n",
      "Ep:19, loss:0.00022, loss_test:0.11094, lr:9.23e-03, fs:0.63277 (r=0.566,p=0.718),  time:62.165, tt:1243.294\n",
      "Ep:20, loss:0.00021, loss_test:0.11604, lr:9.14e-03, fs:0.63529 (r=0.545,p=0.761),  time:62.287, tt:1308.025\n",
      "Ep:21, loss:0.00020, loss_test:0.11676, lr:9.04e-03, fs:0.65089 (r=0.556,p=0.786),  time:62.373, tt:1372.217\n",
      "Ep:22, loss:0.00019, loss_test:0.11397, lr:8.95e-03, fs:0.65143 (r=0.576,p=0.750),  time:62.508, tt:1437.692\n",
      "Ep:23, loss:0.00018, loss_test:0.11829, lr:8.86e-03, fs:0.65909 (r=0.586,p=0.753),  time:62.638, tt:1503.319\n",
      "Ep:24, loss:0.00017, loss_test:0.11591, lr:8.78e-03, fs:0.67059 (r=0.576,p=0.803),  time:62.642, tt:1566.044\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.12022, lr:8.78e-03, fs:0.68263 (r=0.576,p=0.838),  time:62.729, tt:1630.962\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.11838, lr:8.78e-03, fs:0.67442 (r=0.586,p=0.795),  time:62.851, tt:1696.988\n",
      "Ep:27, loss:0.00015, loss_test:0.11682, lr:8.78e-03, fs:0.66286 (r=0.586,p=0.763),  time:62.932, tt:1762.083\n",
      "Ep:28, loss:0.00014, loss_test:0.11917, lr:8.78e-03, fs:0.67857 (r=0.576,p=0.826),  time:62.950, tt:1825.547\n",
      "Ep:29, loss:0.00014, loss_test:0.12273, lr:8.78e-03, fs:0.69939 (r=0.576,p=0.891),  time:62.993, tt:1889.785\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.11842, lr:8.78e-03, fs:0.68263 (r=0.576,p=0.838),  time:63.027, tt:1953.848\n",
      "Ep:31, loss:0.00012, loss_test:0.11816, lr:8.78e-03, fs:0.68235 (r=0.586,p=0.817),  time:63.072, tt:2018.307\n",
      "Ep:32, loss:0.00012, loss_test:0.11797, lr:8.78e-03, fs:0.68639 (r=0.586,p=0.829),  time:63.106, tt:2082.503\n",
      "Ep:33, loss:0.00011, loss_test:0.12500, lr:8.78e-03, fs:0.68639 (r=0.586,p=0.829),  time:63.133, tt:2146.529\n",
      "Ep:34, loss:0.00011, loss_test:0.13036, lr:8.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:63.187, tt:2211.545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:35, loss:0.00010, loss_test:0.12241, lr:8.78e-03, fs:0.69461 (r=0.586,p=0.853),  time:63.180, tt:2274.474\n",
      "Ep:36, loss:0.00010, loss_test:0.11678, lr:8.78e-03, fs:0.68235 (r=0.586,p=0.817),  time:63.262, tt:2340.690\n",
      "Ep:37, loss:0.00009, loss_test:0.12502, lr:8.78e-03, fs:0.69461 (r=0.586,p=0.853),  time:63.322, tt:2406.225\n",
      "Ep:38, loss:0.00009, loss_test:0.12675, lr:8.78e-03, fs:0.69136 (r=0.566,p=0.889),  time:63.373, tt:2471.539\n",
      "Ep:39, loss:0.00008, loss_test:0.11953, lr:8.78e-03, fs:0.69048 (r=0.586,p=0.841),  time:63.353, tt:2534.112\n",
      "Ep:40, loss:0.00008, loss_test:0.11777, lr:8.78e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.341, tt:2596.979\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.12599, lr:8.78e-03, fs:0.69136 (r=0.566,p=0.889),  time:63.353, tt:2660.812\n",
      "Ep:42, loss:0.00007, loss_test:0.12467, lr:8.78e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.385, tt:2725.551\n",
      "Ep:43, loss:0.00007, loss_test:0.11363, lr:8.78e-03, fs:0.69461 (r=0.586,p=0.853),  time:63.396, tt:2789.442\n",
      "Ep:44, loss:0.00007, loss_test:0.11897, lr:8.78e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.405, tt:2853.228\n",
      "Ep:45, loss:0.00006, loss_test:0.12354, lr:8.78e-03, fs:0.69136 (r=0.566,p=0.889),  time:63.472, tt:2919.728\n",
      "Ep:46, loss:0.00006, loss_test:0.12220, lr:8.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:63.511, tt:2985.016\n",
      "Ep:47, loss:0.00006, loss_test:0.12459, lr:8.78e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.593, tt:3052.487\n",
      "Ep:48, loss:0.00006, loss_test:0.12322, lr:8.78e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.643, tt:3118.514\n",
      "Ep:49, loss:0.00005, loss_test:0.12302, lr:8.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:63.654, tt:3182.715\n",
      "Ep:50, loss:0.00005, loss_test:0.12935, lr:8.78e-03, fs:0.68354 (r=0.545,p=0.915),  time:63.644, tt:3245.838\n",
      "Ep:51, loss:0.00005, loss_test:0.12127, lr:8.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:63.685, tt:3311.642\n",
      "Ep:52, loss:0.00005, loss_test:0.12371, lr:8.69e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.704, tt:3376.321\n",
      "Ep:53, loss:0.00005, loss_test:0.12946, lr:8.60e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.727, tt:3441.256\n",
      "Ep:54, loss:0.00005, loss_test:0.13193, lr:8.51e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.761, tt:3506.883\n",
      "Ep:55, loss:0.00005, loss_test:0.12935, lr:8.43e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.777, tt:3571.514\n",
      "Ep:56, loss:0.00005, loss_test:0.12234, lr:8.35e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.813, tt:3637.367\n",
      "Ep:57, loss:0.00004, loss_test:0.11356, lr:8.26e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.853, tt:3703.499\n",
      "Ep:58, loss:0.00004, loss_test:0.11872, lr:8.18e-03, fs:0.71250 (r=0.576,p=0.934),  time:63.870, tt:3768.306\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00004, loss_test:0.12912, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.878, tt:3832.686\n",
      "Ep:60, loss:0.00004, loss_test:0.13342, lr:8.18e-03, fs:0.68750 (r=0.556,p=0.902),  time:63.893, tt:3897.476\n",
      "Ep:61, loss:0.00004, loss_test:0.12600, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.881, tt:3960.643\n",
      "Ep:62, loss:0.00004, loss_test:0.12139, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.878, tt:4024.295\n",
      "Ep:63, loss:0.00003, loss_test:0.12556, lr:8.18e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.878, tt:4088.215\n",
      "Ep:64, loss:0.00003, loss_test:0.12161, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.874, tt:4151.795\n",
      "Ep:65, loss:0.00003, loss_test:0.12595, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.907, tt:4217.838\n",
      "Ep:66, loss:0.00003, loss_test:0.12133, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.948, tt:4284.497\n",
      "Ep:67, loss:0.00003, loss_test:0.11803, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.963, tt:4349.472\n",
      "Ep:68, loss:0.00003, loss_test:0.12611, lr:8.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.968, tt:4413.774\n",
      "Ep:69, loss:0.00003, loss_test:0.12965, lr:8.18e-03, fs:0.63158 (r=0.485,p=0.906),  time:63.964, tt:4477.452\n",
      "Ep:70, loss:0.00003, loss_test:0.12311, lr:8.10e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.981, tt:4542.659\n",
      "Ep:71, loss:0.00003, loss_test:0.12657, lr:8.02e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.953, tt:4604.641\n",
      "Ep:72, loss:0.00003, loss_test:0.12422, lr:7.94e-03, fs:0.70807 (r=0.576,p=0.919),  time:63.928, tt:4666.772\n",
      "Ep:73, loss:0.00003, loss_test:0.12154, lr:7.86e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.958, tt:4732.887\n",
      "Ep:74, loss:0.00003, loss_test:0.12543, lr:7.78e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.996, tt:4799.702\n",
      "Ep:75, loss:0.00002, loss_test:0.12438, lr:7.70e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.013, tt:4864.972\n",
      "Ep:76, loss:0.00002, loss_test:0.12306, lr:7.62e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.013, tt:4928.973\n",
      "Ep:77, loss:0.00002, loss_test:0.12504, lr:7.55e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.014, tt:4993.107\n",
      "Ep:78, loss:0.00002, loss_test:0.12444, lr:7.47e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.047, tt:5059.686\n",
      "Ep:79, loss:0.00002, loss_test:0.12107, lr:7.40e-03, fs:0.70807 (r=0.576,p=0.919),  time:64.069, tt:5125.505\n",
      "Ep:80, loss:0.00002, loss_test:0.12119, lr:7.32e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.056, tt:5188.552\n",
      "Ep:81, loss:0.00002, loss_test:0.12405, lr:7.25e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.073, tt:5253.980\n",
      "Ep:82, loss:0.00002, loss_test:0.12790, lr:7.18e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.079, tt:5318.535\n",
      "Ep:83, loss:0.00002, loss_test:0.12554, lr:7.11e-03, fs:0.70370 (r=0.576,p=0.905),  time:64.105, tt:5384.790\n",
      "Ep:84, loss:0.00002, loss_test:0.12911, lr:7.03e-03, fs:0.61333 (r=0.465,p=0.902),  time:64.128, tt:5450.921\n",
      "Ep:85, loss:0.00002, loss_test:0.12606, lr:6.96e-03, fs:0.70807 (r=0.576,p=0.919),  time:64.155, tt:5517.309\n",
      "Ep:86, loss:0.00002, loss_test:0.12833, lr:6.89e-03, fs:0.68354 (r=0.545,p=0.915),  time:64.203, tt:5585.696\n",
      "Ep:87, loss:0.00002, loss_test:0.12702, lr:6.83e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.206, tt:5650.132\n",
      "Ep:88, loss:0.00002, loss_test:0.12327, lr:6.76e-03, fs:0.70807 (r=0.576,p=0.919),  time:64.231, tt:5716.579\n",
      "Ep:89, loss:0.00002, loss_test:0.12445, lr:6.69e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.231, tt:5780.761\n",
      "Ep:90, loss:0.00002, loss_test:0.12475, lr:6.62e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.233, tt:5845.184\n",
      "Ep:91, loss:0.00002, loss_test:0.12843, lr:6.56e-03, fs:0.70807 (r=0.576,p=0.919),  time:64.250, tt:5910.967\n",
      "Ep:92, loss:0.00002, loss_test:0.13081, lr:6.49e-03, fs:0.61745 (r=0.465,p=0.920),  time:64.279, tt:5977.970\n",
      "Ep:93, loss:0.00002, loss_test:0.12524, lr:6.43e-03, fs:0.70807 (r=0.576,p=0.919),  time:64.271, tt:6041.487\n",
      "Ep:94, loss:0.00002, loss_test:0.12631, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.274, tt:6105.987\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.12692, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.277, tt:6170.546\n",
      "Ep:96, loss:0.00002, loss_test:0.12560, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.295, tt:6236.605\n",
      "Ep:97, loss:0.00002, loss_test:0.12845, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.311, tt:6302.501\n",
      "Ep:98, loss:0.00001, loss_test:0.12899, lr:6.36e-03, fs:0.70440 (r=0.566,p=0.933),  time:64.327, tt:6368.340\n",
      "Ep:99, loss:0.00001, loss_test:0.12734, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.331, tt:6433.067\n",
      "Ep:100, loss:0.00001, loss_test:0.12560, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.333, tt:6497.646\n",
      "Ep:101, loss:0.00001, loss_test:0.12745, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.344, tt:6563.067\n",
      "Ep:102, loss:0.00001, loss_test:0.12772, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.334, tt:6626.422\n",
      "Ep:103, loss:0.00001, loss_test:0.12651, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.341, tt:6691.473\n",
      "Ep:104, loss:0.00001, loss_test:0.12758, lr:6.36e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.352, tt:6756.992\n",
      "Ep:105, loss:0.00001, loss_test:0.12696, lr:6.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.340, tt:6820.076\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.12555, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.346, tt:6885.074\n",
      "Ep:107, loss:0.00001, loss_test:0.12724, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.341, tt:6948.825\n",
      "Ep:108, loss:0.00001, loss_test:0.12979, lr:6.36e-03, fs:0.63087 (r=0.475,p=0.940),  time:64.354, tt:7014.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00001, loss_test:0.12981, lr:6.36e-03, fs:0.63087 (r=0.475,p=0.940),  time:64.368, tt:7080.443\n",
      "Ep:110, loss:0.00001, loss_test:0.12666, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.380, tt:7146.165\n",
      "Ep:111, loss:0.00001, loss_test:0.12800, lr:6.36e-03, fs:0.70064 (r=0.556,p=0.948),  time:64.403, tt:7213.137\n",
      "Ep:112, loss:0.00001, loss_test:0.12707, lr:6.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.426, tt:7280.173\n",
      "Ep:113, loss:0.00001, loss_test:0.13044, lr:6.36e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.441, tt:7346.308\n",
      "Ep:114, loss:0.00001, loss_test:0.12819, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.443, tt:7410.908\n",
      "Ep:115, loss:0.00001, loss_test:0.12800, lr:6.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.444, tt:7475.542\n",
      "Ep:116, loss:0.00001, loss_test:0.12906, lr:6.36e-03, fs:0.70886 (r=0.566,p=0.949),  time:64.453, tt:7541.026\n",
      "Ep:117, loss:0.00001, loss_test:0.12910, lr:6.30e-03, fs:0.71338 (r=0.566,p=0.966),  time:64.458, tt:7606.053\n",
      "Ep:118, loss:0.00001, loss_test:0.12766, lr:6.24e-03, fs:0.71338 (r=0.566,p=0.966),  time:64.467, tt:7671.592\n",
      "Ep:119, loss:0.00001, loss_test:0.12610, lr:6.17e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.479, tt:7737.506\n",
      "Ep:120, loss:0.00001, loss_test:0.13050, lr:6.11e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.503, tt:7804.918\n",
      "Ep:121, loss:0.00001, loss_test:0.12927, lr:6.05e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.511, tt:7870.376\n",
      "Ep:122, loss:0.00001, loss_test:0.12863, lr:5.99e-03, fs:0.70064 (r=0.556,p=0.948),  time:64.514, tt:7935.226\n",
      "Ep:123, loss:0.00001, loss_test:0.12882, lr:5.93e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.521, tt:8000.550\n",
      "Ep:124, loss:0.00001, loss_test:0.12656, lr:5.87e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.523, tt:8065.413\n",
      "Ep:125, loss:0.00001, loss_test:0.12935, lr:5.81e-03, fs:0.63514 (r=0.475,p=0.959),  time:64.523, tt:8129.889\n",
      "Ep:126, loss:0.00001, loss_test:0.12929, lr:5.75e-03, fs:0.62585 (r=0.465,p=0.958),  time:64.514, tt:8193.252\n",
      "Ep:127, loss:0.00001, loss_test:0.13092, lr:5.70e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.496, tt:8255.541\n",
      "Ep:128, loss:0.00001, loss_test:0.12636, lr:5.64e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.485, tt:8318.593\n",
      "Ep:129, loss:0.00001, loss_test:0.12679, lr:5.58e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.480, tt:8382.340\n",
      "Ep:130, loss:0.00001, loss_test:0.12916, lr:5.53e-03, fs:0.63087 (r=0.475,p=0.940),  time:64.464, tt:8444.775\n",
      "Ep:131, loss:0.00001, loss_test:0.12954, lr:5.47e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.434, tt:8505.354\n",
      "Ep:132, loss:0.00001, loss_test:0.12676, lr:5.42e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.433, tt:8569.595\n",
      "Ep:133, loss:0.00001, loss_test:0.12856, lr:5.36e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.420, tt:8632.262\n",
      "Ep:134, loss:0.00001, loss_test:0.12805, lr:5.31e-03, fs:0.65333 (r=0.495,p=0.961),  time:64.442, tt:8699.697\n",
      "Ep:137, loss:0.00001, loss_test:0.12812, lr:5.15e-03, fs:0.67974 (r=0.525,p=0.963),  time:64.437, tt:8892.325\n",
      "Ep:138, loss:0.00001, loss_test:0.12865, lr:5.10e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.440, tt:8957.136\n",
      "Ep:139, loss:0.00001, loss_test:0.12723, lr:5.05e-03, fs:0.71338 (r=0.566,p=0.966),  time:64.424, tt:9019.308\n",
      "Ep:140, loss:0.00001, loss_test:0.12823, lr:5.00e-03, fs:0.62585 (r=0.465,p=0.958),  time:64.436, tt:9085.453\n",
      "Ep:141, loss:0.00001, loss_test:0.12779, lr:4.95e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.426, tt:9148.504\n",
      "Ep:142, loss:0.00001, loss_test:0.12687, lr:4.90e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.423, tt:9212.515\n",
      "Ep:143, loss:0.00001, loss_test:0.12650, lr:4.85e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.428, tt:9277.561\n",
      "Ep:144, loss:0.00001, loss_test:0.12795, lr:4.80e-03, fs:0.62585 (r=0.465,p=0.958),  time:64.406, tt:9338.858\n",
      "Ep:145, loss:0.00001, loss_test:0.12872, lr:4.75e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.394, tt:9401.588\n",
      "Ep:146, loss:0.00001, loss_test:0.12692, lr:4.71e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.391, tt:9465.519\n",
      "Ep:149, loss:0.00001, loss_test:0.12930, lr:4.57e-03, fs:0.61644 (r=0.455,p=0.957),  time:64.340, tt:9651.010\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14023, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.143, tt:53.143\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13474, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:56.811, tt:113.622\n",
      "Ep:2, loss:0.00053, loss_test:0.12228, lr:1.00e-02, fs:0.68841 (r=0.960,p=0.537),  time:56.299, tt:168.897\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00049, loss_test:0.10913, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:57.935, tt:231.739\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00046, loss_test:0.10542, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:59.097, tt:295.485\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.10280, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:59.937, tt:359.623\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.09861, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:60.321, tt:422.244\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.09650, lr:1.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:60.538, tt:484.302\n",
      "Ep:8, loss:0.00038, loss_test:0.09362, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:60.911, tt:548.195\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.09139, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:61.240, tt:612.397\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.08834, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:61.372, tt:675.093\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.08659, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:61.562, tt:738.743\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.08381, lr:1.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:61.936, tt:805.173\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.08225, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:62.040, tt:868.566\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.08054, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:62.123, tt:931.848\n",
      "Ep:15, loss:0.00028, loss_test:0.07909, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:62.177, tt:994.833\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.07693, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:62.066, tt:1055.118\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.07696, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:62.114, tt:1118.046\n",
      "Ep:18, loss:0.00024, loss_test:0.07446, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:62.240, tt:1182.562\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.07376, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:62.296, tt:1245.916\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.07265, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:62.414, tt:1310.692\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.07149, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:62.452, tt:1373.937\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.07053, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:62.437, tt:1436.046\n",
      "Ep:23, loss:0.00019, loss_test:0.07005, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:62.450, tt:1498.806\n",
      "Ep:24, loss:0.00018, loss_test:0.06865, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:62.464, tt:1561.610\n",
      "Ep:25, loss:0.00017, loss_test:0.06922, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:62.487, tt:1624.665\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.06825, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:62.510, tt:1687.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00015, loss_test:0.07142, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:62.499, tt:1749.971\n",
      "Ep:28, loss:0.00014, loss_test:0.07006, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:62.521, tt:1813.105\n",
      "Ep:29, loss:0.00014, loss_test:0.06625, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:62.573, tt:1877.193\n",
      "Ep:30, loss:0.00013, loss_test:0.06775, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:62.612, tt:1940.960\n",
      "Ep:31, loss:0.00012, loss_test:0.06852, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:62.661, tt:2005.160\n",
      "Ep:32, loss:0.00011, loss_test:0.07022, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:62.715, tt:2069.583\n",
      "Ep:33, loss:0.00010, loss_test:0.06911, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:62.766, tt:2134.035\n",
      "Ep:34, loss:0.00010, loss_test:0.06630, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:62.746, tt:2196.094\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06695, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:62.779, tt:2260.059\n",
      "Ep:36, loss:0.00009, loss_test:0.06953, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:62.794, tt:2323.382\n",
      "Ep:37, loss:0.00008, loss_test:0.06851, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:62.815, tt:2386.973\n",
      "Ep:38, loss:0.00008, loss_test:0.06844, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:62.871, tt:2451.952\n",
      "Ep:39, loss:0.00007, loss_test:0.06725, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:62.882, tt:2515.275\n",
      "Ep:40, loss:0.00007, loss_test:0.06479, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:62.930, tt:2580.150\n",
      "Ep:41, loss:0.00007, loss_test:0.06393, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:63.034, tt:2647.425\n",
      "Ep:42, loss:0.00006, loss_test:0.06463, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:63.033, tt:2710.432\n",
      "Ep:43, loss:0.00006, loss_test:0.06690, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:63.038, tt:2773.663\n",
      "Ep:44, loss:0.00006, loss_test:0.06479, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:63.056, tt:2837.526\n",
      "Ep:45, loss:0.00005, loss_test:0.06713, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:63.092, tt:2902.221\n",
      "Ep:46, loss:0.00005, loss_test:0.07149, lr:9.90e-03, fs:0.78363 (r=0.677,p=0.931),  time:63.076, tt:2964.561\n",
      "Ep:47, loss:0.00005, loss_test:0.06655, lr:9.80e-03, fs:0.86957 (r=0.808,p=0.941),  time:63.120, tt:3029.740\n",
      "Ep:48, loss:0.00005, loss_test:0.06462, lr:9.70e-03, fs:0.87179 (r=0.859,p=0.885),  time:63.119, tt:3092.839\n",
      "Ep:49, loss:0.00005, loss_test:0.06533, lr:9.61e-03, fs:0.86772 (r=0.828,p=0.911),  time:63.128, tt:3156.418\n",
      "Ep:50, loss:0.00004, loss_test:0.06553, lr:9.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:63.096, tt:3217.901\n",
      "Ep:51, loss:0.00004, loss_test:0.06338, lr:9.41e-03, fs:0.86667 (r=0.788,p=0.963),  time:63.075, tt:3279.900\n",
      "Ep:52, loss:0.00004, loss_test:0.06298, lr:9.32e-03, fs:0.88770 (r=0.838,p=0.943),  time:63.062, tt:3342.296\n",
      "Ep:53, loss:0.00004, loss_test:0.06351, lr:9.23e-03, fs:0.87629 (r=0.859,p=0.895),  time:63.063, tt:3405.408\n",
      "Ep:54, loss:0.00004, loss_test:0.06386, lr:9.14e-03, fs:0.87432 (r=0.808,p=0.952),  time:63.041, tt:3467.256\n",
      "Ep:55, loss:0.00004, loss_test:0.06595, lr:9.04e-03, fs:0.88525 (r=0.818,p=0.964),  time:63.067, tt:3531.743\n",
      "Ep:56, loss:0.00004, loss_test:0.06734, lr:8.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:63.066, tt:3594.762\n",
      "Ep:57, loss:0.00003, loss_test:0.06705, lr:8.86e-03, fs:0.85128 (r=0.838,p=0.865),  time:63.103, tt:3659.970\n",
      "Ep:58, loss:0.00003, loss_test:0.06566, lr:8.78e-03, fs:0.86957 (r=0.808,p=0.941),  time:63.149, tt:3725.793\n",
      "Ep:59, loss:0.00003, loss_test:0.06598, lr:8.69e-03, fs:0.86339 (r=0.798,p=0.940),  time:63.154, tt:3789.236\n",
      "Ep:60, loss:0.00003, loss_test:0.06514, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:63.118, tt:3850.227\n",
      "Ep:61, loss:0.00003, loss_test:0.06230, lr:8.51e-03, fs:0.88172 (r=0.828,p=0.943),  time:63.156, tt:3915.671\n",
      "Ep:62, loss:0.00003, loss_test:0.06251, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:63.187, tt:3980.805\n",
      "Ep:63, loss:0.00003, loss_test:0.06309, lr:8.35e-03, fs:0.88043 (r=0.818,p=0.953),  time:63.217, tt:4045.864\n",
      "Ep:64, loss:0.00003, loss_test:0.06279, lr:8.26e-03, fs:0.87701 (r=0.828,p=0.932),  time:63.275, tt:4112.843\n",
      "Ep:65, loss:0.00002, loss_test:0.06362, lr:8.18e-03, fs:0.88172 (r=0.828,p=0.943),  time:63.295, tt:4177.492\n",
      "Ep:66, loss:0.00002, loss_test:0.06373, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:63.314, tt:4242.027\n",
      "Ep:67, loss:0.00002, loss_test:0.06474, lr:8.02e-03, fs:0.88043 (r=0.818,p=0.953),  time:63.324, tt:4306.041\n",
      "Ep:68, loss:0.00002, loss_test:0.06327, lr:7.94e-03, fs:0.87234 (r=0.828,p=0.921),  time:63.368, tt:4372.391\n",
      "Ep:69, loss:0.00002, loss_test:0.06332, lr:7.86e-03, fs:0.87097 (r=0.818,p=0.931),  time:63.391, tt:4437.399\n",
      "Ep:70, loss:0.00002, loss_test:0.06312, lr:7.78e-03, fs:0.88043 (r=0.818,p=0.953),  time:63.384, tt:4500.283\n",
      "Ep:71, loss:0.00002, loss_test:0.06426, lr:7.70e-03, fs:0.87701 (r=0.828,p=0.932),  time:63.398, tt:4564.623\n",
      "Ep:72, loss:0.00002, loss_test:0.06651, lr:7.62e-03, fs:0.80899 (r=0.727,p=0.911),  time:63.460, tt:4632.594\n",
      "Ep:73, loss:0.00002, loss_test:0.06408, lr:7.55e-03, fs:0.87568 (r=0.818,p=0.942),  time:63.509, tt:4699.661\n",
      "Ep:74, loss:0.00002, loss_test:0.06398, lr:7.47e-03, fs:0.87568 (r=0.818,p=0.942),  time:63.572, tt:4767.916\n",
      "Ep:75, loss:0.00002, loss_test:0.06241, lr:7.40e-03, fs:0.89005 (r=0.859,p=0.924),  time:63.656, tt:4837.823\n",
      "Ep:76, loss:0.00002, loss_test:0.06529, lr:7.32e-03, fs:0.80460 (r=0.707,p=0.933),  time:63.702, tt:4905.067\n",
      "Ep:77, loss:0.00002, loss_test:0.06424, lr:7.25e-03, fs:0.87568 (r=0.818,p=0.942),  time:63.756, tt:4972.962\n",
      "Ep:78, loss:0.00002, loss_test:0.06360, lr:7.18e-03, fs:0.89474 (r=0.859,p=0.934),  time:63.797, tt:5039.950\n",
      "Ep:79, loss:0.00002, loss_test:0.06569, lr:7.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:63.861, tt:5108.907\n",
      "Ep:80, loss:0.00002, loss_test:0.06274, lr:7.03e-03, fs:0.87568 (r=0.818,p=0.942),  time:63.914, tt:5177.065\n",
      "Ep:81, loss:0.00002, loss_test:0.06357, lr:6.96e-03, fs:0.87701 (r=0.828,p=0.932),  time:63.956, tt:5244.368\n",
      "Ep:82, loss:0.00002, loss_test:0.06453, lr:6.89e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.004, tt:5312.319\n",
      "Ep:83, loss:0.00002, loss_test:0.06768, lr:6.83e-03, fs:0.79769 (r=0.697,p=0.932),  time:64.040, tt:5379.365\n",
      "Ep:84, loss:0.00002, loss_test:0.06572, lr:6.76e-03, fs:0.81564 (r=0.737,p=0.912),  time:64.064, tt:5445.455\n",
      "Ep:85, loss:0.00002, loss_test:0.06394, lr:6.69e-03, fs:0.87568 (r=0.818,p=0.942),  time:64.117, tt:5514.067\n",
      "Ep:86, loss:0.00002, loss_test:0.06396, lr:6.62e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.149, tt:5580.934\n",
      "Ep:87, loss:0.00001, loss_test:0.06518, lr:6.56e-03, fs:0.84615 (r=0.778,p=0.928),  time:64.182, tt:5647.980\n",
      "Ep:88, loss:0.00001, loss_test:0.06482, lr:6.49e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.227, tt:5716.167\n",
      "Ep:89, loss:0.00001, loss_test:0.06432, lr:6.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.258, tt:5783.237\n",
      "Ep:90, loss:0.00001, loss_test:0.06346, lr:6.36e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.326, tt:5853.675\n",
      "Ep:91, loss:0.00001, loss_test:0.06476, lr:6.30e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.369, tt:5921.980\n",
      "Ep:92, loss:0.00001, loss_test:0.06482, lr:6.24e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.395, tt:5988.778\n",
      "Ep:93, loss:0.00001, loss_test:0.06618, lr:6.17e-03, fs:0.80000 (r=0.707,p=0.921),  time:64.423, tt:6055.750\n",
      "Ep:94, loss:0.00001, loss_test:0.06456, lr:6.11e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.444, tt:6122.180\n",
      "Ep:95, loss:0.00001, loss_test:0.06454, lr:6.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:64.482, tt:6190.292\n",
      "Ep:96, loss:0.00001, loss_test:0.06488, lr:5.99e-03, fs:0.87568 (r=0.818,p=0.942),  time:64.514, tt:6257.834\n",
      "Ep:97, loss:0.00001, loss_test:0.06491, lr:5.93e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.580, tt:6328.873\n",
      "Ep:98, loss:0.00001, loss_test:0.06553, lr:5.87e-03, fs:0.87432 (r=0.808,p=0.952),  time:64.617, tt:6397.055\n",
      "Ep:99, loss:0.00001, loss_test:0.06456, lr:5.81e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.637, tt:6463.729\n",
      "Ep:100, loss:0.00001, loss_test:0.06523, lr:5.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:64.673, tt:6531.937\n",
      "Ep:101, loss:0.00001, loss_test:0.06453, lr:5.70e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.728, tt:6602.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:102, loss:0.00001, loss_test:0.06498, lr:5.64e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.782, tt:6672.512\n",
      "Ep:103, loss:0.00001, loss_test:0.06463, lr:5.58e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.815, tt:6740.811\n",
      "Ep:104, loss:0.00001, loss_test:0.06498, lr:5.53e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.846, tt:6808.797\n",
      "Ep:105, loss:0.00001, loss_test:0.06570, lr:5.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:64.887, tt:6878.002\n",
      "Ep:106, loss:0.00001, loss_test:0.06457, lr:5.42e-03, fs:0.87568 (r=0.818,p=0.942),  time:64.892, tt:6943.402\n",
      "Ep:107, loss:0.00001, loss_test:0.06532, lr:5.36e-03, fs:0.87097 (r=0.818,p=0.931),  time:64.938, tt:7013.357\n",
      "Ep:108, loss:0.00001, loss_test:0.06556, lr:5.31e-03, fs:0.86957 (r=0.808,p=0.941),  time:64.974, tt:7082.190\n",
      "Ep:109, loss:0.00001, loss_test:0.06574, lr:5.26e-03, fs:0.86339 (r=0.798,p=0.940),  time:65.020, tt:7152.248\n",
      "Ep:110, loss:0.00001, loss_test:0.06526, lr:5.20e-03, fs:0.87568 (r=0.818,p=0.942),  time:65.041, tt:7219.576\n",
      "Ep:111, loss:0.00001, loss_test:0.06569, lr:5.15e-03, fs:0.83146 (r=0.747,p=0.937),  time:65.050, tt:7285.654\n",
      "Ep:112, loss:0.00001, loss_test:0.06571, lr:5.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:65.098, tt:7356.088\n",
      "Ep:113, loss:0.00001, loss_test:0.06526, lr:5.05e-03, fs:0.87568 (r=0.818,p=0.942),  time:65.155, tt:7427.623\n",
      "Ep:114, loss:0.00001, loss_test:0.06569, lr:5.00e-03, fs:0.85083 (r=0.778,p=0.939),  time:65.181, tt:7495.823\n",
      "Ep:115, loss:0.00001, loss_test:0.06627, lr:4.95e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.194, tt:7562.505\n",
      "Ep:116, loss:0.00001, loss_test:0.06587, lr:4.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:65.204, tt:7628.864\n",
      "Ep:117, loss:0.00001, loss_test:0.06588, lr:4.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:65.221, tt:7696.060\n",
      "Ep:118, loss:0.00001, loss_test:0.06566, lr:4.80e-03, fs:0.87568 (r=0.818,p=0.942),  time:65.227, tt:7762.046\n",
      "Ep:119, loss:0.00001, loss_test:0.06642, lr:4.75e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.264, tt:7831.697\n",
      "Ep:120, loss:0.00001, loss_test:0.06571, lr:4.71e-03, fs:0.88043 (r=0.818,p=0.953),  time:65.281, tt:7898.962\n",
      "Ep:121, loss:0.00001, loss_test:0.06645, lr:4.66e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.304, tt:7967.142\n",
      "Ep:122, loss:0.00001, loss_test:0.06614, lr:4.61e-03, fs:0.82486 (r=0.737,p=0.936),  time:65.338, tt:8036.573\n",
      "Ep:123, loss:0.00001, loss_test:0.06617, lr:4.57e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.367, tt:8105.513\n",
      "Ep:124, loss:0.00001, loss_test:0.06689, lr:4.52e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.390, tt:8173.770\n",
      "Ep:125, loss:0.00001, loss_test:0.06676, lr:4.48e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.414, tt:8242.193\n",
      "Ep:126, loss:0.00001, loss_test:0.06648, lr:4.43e-03, fs:0.83616 (r=0.747,p=0.949),  time:65.429, tt:8309.512\n",
      "Ep:127, loss:0.00001, loss_test:0.06711, lr:4.39e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.463, tt:8379.275\n",
      "Ep:128, loss:0.00001, loss_test:0.06677, lr:4.34e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.496, tt:8449.042\n",
      "Ep:129, loss:0.00001, loss_test:0.06626, lr:4.30e-03, fs:0.87432 (r=0.808,p=0.952),  time:65.542, tt:8520.413\n",
      "Ep:130, loss:0.00001, loss_test:0.06723, lr:4.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.601, tt:8593.751\n",
      "Ep:131, loss:0.00001, loss_test:0.06675, lr:4.21e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.651, tt:8665.900\n",
      "Ep:132, loss:0.00001, loss_test:0.06710, lr:4.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.681, tt:8735.571\n",
      "Ep:133, loss:0.00001, loss_test:0.06717, lr:4.13e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.705, tt:8804.422\n",
      "Ep:134, loss:0.00001, loss_test:0.06684, lr:4.09e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.738, tt:8874.598\n",
      "Ep:135, loss:0.00001, loss_test:0.06729, lr:4.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.748, tt:8941.729\n",
      "Ep:136, loss:0.00001, loss_test:0.06683, lr:4.01e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.792, tt:9013.465\n",
      "Ep:137, loss:0.00001, loss_test:0.06715, lr:3.97e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.825, tt:9083.914\n",
      "Ep:138, loss:0.00001, loss_test:0.06713, lr:3.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.862, tt:9154.872\n",
      "Ep:139, loss:0.00001, loss_test:0.06750, lr:3.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.891, tt:9224.748\n",
      "Ep:140, loss:0.00001, loss_test:0.06764, lr:3.85e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.910, tt:9293.262\n",
      "Ep:141, loss:0.00001, loss_test:0.06754, lr:3.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.943, tt:9363.913\n",
      "Ep:142, loss:0.00001, loss_test:0.06740, lr:3.77e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.966, tt:9433.117\n",
      "Ep:143, loss:0.00001, loss_test:0.06779, lr:3.73e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.990, tt:9502.515\n",
      "Ep:144, loss:0.00001, loss_test:0.06775, lr:3.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:66.005, tt:9570.721\n",
      "Ep:145, loss:0.00001, loss_test:0.06772, lr:3.66e-03, fs:0.80233 (r=0.697,p=0.945),  time:66.017, tt:9638.472\n",
      "Ep:146, loss:0.00001, loss_test:0.06746, lr:3.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:66.019, tt:9704.842\n",
      "Ep:147, loss:0.00001, loss_test:0.06774, lr:3.59e-03, fs:0.80233 (r=0.697,p=0.945),  time:66.061, tt:9776.961\n",
      "Ep:148, loss:0.00001, loss_test:0.06775, lr:3.55e-03, fs:0.80233 (r=0.697,p=0.945),  time:66.086, tt:9846.806\n",
      "Ep:149, loss:0.00001, loss_test:0.06845, lr:3.52e-03, fs:0.79769 (r=0.697,p=0.932),  time:66.082, tt:9912.332\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f39c2e7837b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid protocol version: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprotocol_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0m_sys_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14398, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:5.364, tt:5.364\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14373, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:5.359, tt:10.718\n",
      "Ep:2, loss:0.00000, loss_test:0.14334, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:5.458, tt:16.374\n",
      "Ep:3, loss:0.00000, loss_test:0.14281, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:5.775, tt:23.101\n",
      "Ep:4, loss:0.00000, loss_test:0.14210, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:6.446, tt:32.229\n",
      "Ep:5, loss:0.00000, loss_test:0.14117, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.223, tt:43.340\n",
      "Ep:6, loss:0.00000, loss_test:0.13997, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:7.948, tt:55.636\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00000, loss_test:0.13837, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:8.692, tt:69.540\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00000, loss_test:0.13633, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:9.380, tt:84.417\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00000, loss_test:0.13376, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:10.131, tt:101.307\n",
      "Ep:10, loss:0.00000, loss_test:0.13093, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:10.623, tt:116.858\n",
      "Ep:11, loss:0.00000, loss_test:0.12832, lr:1.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:11.139, tt:133.669\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00000, loss_test:0.12562, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:11.591, tt:150.683\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00000, loss_test:0.12327, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:11.926, tt:166.966\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00000, loss_test:0.12167, lr:1.00e-02, fs:0.64545 (r=0.717,p=0.587),  time:12.240, tt:183.604\n",
      "Ep:15, loss:0.00000, loss_test:0.12081, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:12.525, tt:200.403\n",
      "Ep:16, loss:0.00000, loss_test:0.11969, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:12.745, tt:216.671\n",
      "Ep:17, loss:0.00000, loss_test:0.11845, lr:1.00e-02, fs:0.66667 (r=0.727,p=0.615),  time:12.963, tt:233.343\n",
      "Ep:18, loss:0.00000, loss_test:0.11777, lr:1.00e-02, fs:0.69912 (r=0.798,p=0.622),  time:13.199, tt:250.772\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00000, loss_test:0.11754, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:13.399, tt:267.989\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00000, loss_test:0.11711, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:13.530, tt:284.140\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00000, loss_test:0.11610, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:13.690, tt:301.185\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00000, loss_test:0.11487, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:13.832, tt:318.147\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.11379, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:13.973, tt:335.345\n",
      "Ep:24, loss:0.00000, loss_test:0.11295, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:14.095, tt:352.364\n",
      "Ep:25, loss:0.00000, loss_test:0.11235, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:14.205, tt:369.327\n",
      "Ep:26, loss:0.00000, loss_test:0.11156, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:14.358, tt:387.654\n",
      "Ep:27, loss:0.00000, loss_test:0.11060, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:14.434, tt:404.166\n",
      "Ep:28, loss:0.00000, loss_test:0.10965, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:14.507, tt:420.689\n",
      "Ep:29, loss:0.00000, loss_test:0.10869, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:14.560, tt:436.792\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.10795, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:14.633, tt:453.618\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.10747, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:14.687, tt:469.984\n",
      "Ep:32, loss:0.00000, loss_test:0.10713, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:14.739, tt:486.383\n",
      "Ep:33, loss:0.00000, loss_test:0.10668, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:14.811, tt:503.558\n",
      "Ep:34, loss:0.00000, loss_test:0.10594, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:14.844, tt:519.545\n",
      "Ep:35, loss:0.00000, loss_test:0.10501, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:14.888, tt:535.952\n",
      "Ep:36, loss:0.00000, loss_test:0.10414, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:14.926, tt:552.253\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.10336, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:14.940, tt:567.715\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00000, loss_test:0.10277, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:14.995, tt:584.812\n",
      "Ep:39, loss:0.00000, loss_test:0.10243, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:15.019, tt:600.771\n",
      "Ep:40, loss:0.00000, loss_test:0.10211, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:15.067, tt:617.758\n",
      "Ep:41, loss:0.00000, loss_test:0.10144, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:15.103, tt:634.318\n",
      "Ep:42, loss:0.00000, loss_test:0.10054, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:15.137, tt:650.870\n",
      "Ep:43, loss:0.00000, loss_test:0.09985, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:15.161, tt:667.081\n",
      "Ep:44, loss:0.00000, loss_test:0.09956, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:15.196, tt:683.801\n",
      "Ep:45, loss:0.00000, loss_test:0.09971, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:15.230, tt:700.587\n",
      "Ep:46, loss:0.00000, loss_test:0.10010, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:15.263, tt:717.370\n",
      "Ep:47, loss:0.00000, loss_test:0.10017, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:15.279, tt:733.413\n",
      "Ep:48, loss:0.00000, loss_test:0.09982, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:15.290, tt:749.216\n",
      "Ep:49, loss:0.00000, loss_test:0.09922, lr:9.90e-03, fs:0.73016 (r=0.697,p=0.767),  time:15.309, tt:765.427\n",
      "Ep:50, loss:0.00000, loss_test:0.09864, lr:9.80e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.334, tt:782.025\n",
      "Ep:51, loss:0.00000, loss_test:0.09827, lr:9.70e-03, fs:0.74468 (r=0.707,p=0.787),  time:15.359, tt:798.652\n",
      "Ep:52, loss:0.00000, loss_test:0.09818, lr:9.61e-03, fs:0.73118 (r=0.687,p=0.782),  time:15.384, tt:815.355\n",
      "Ep:53, loss:0.00000, loss_test:0.09810, lr:9.51e-03, fs:0.73118 (r=0.687,p=0.782),  time:15.402, tt:831.702\n",
      "Ep:54, loss:0.00000, loss_test:0.09784, lr:9.41e-03, fs:0.72432 (r=0.677,p=0.779),  time:15.429, tt:848.602\n",
      "Ep:55, loss:0.00000, loss_test:0.09750, lr:9.32e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.455, tt:865.461\n",
      "Ep:56, loss:0.00000, loss_test:0.09722, lr:9.23e-03, fs:0.74194 (r=0.697,p=0.793),  time:15.462, tt:881.360\n",
      "Ep:57, loss:0.00000, loss_test:0.09713, lr:9.14e-03, fs:0.73514 (r=0.687,p=0.791),  time:15.488, tt:898.306\n",
      "Ep:58, loss:0.00000, loss_test:0.09722, lr:9.04e-03, fs:0.72826 (r=0.677,p=0.788),  time:15.500, tt:914.513\n",
      "Ep:59, loss:0.00000, loss_test:0.09730, lr:8.95e-03, fs:0.72131 (r=0.667,p=0.786),  time:15.499, tt:929.936\n",
      "Ep:60, loss:0.00000, loss_test:0.09724, lr:8.86e-03, fs:0.71823 (r=0.657,p=0.793),  time:15.516, tt:946.456\n",
      "Ep:61, loss:0.00000, loss_test:0.09691, lr:8.78e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.529, tt:962.807\n",
      "Ep:62, loss:0.00000, loss_test:0.09649, lr:8.69e-03, fs:0.70391 (r=0.636,p=0.787),  time:15.534, tt:978.610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00000, loss_test:0.09611, lr:8.60e-03, fs:0.71508 (r=0.646,p=0.800),  time:15.563, tt:996.008\n",
      "Ep:64, loss:0.00000, loss_test:0.09589, lr:8.51e-03, fs:0.71910 (r=0.646,p=0.810),  time:15.592, tt:1013.504\n",
      "Ep:65, loss:0.00000, loss_test:0.09578, lr:8.43e-03, fs:0.71186 (r=0.636,p=0.808),  time:15.605, tt:1029.943\n",
      "Ep:66, loss:0.00000, loss_test:0.09562, lr:8.35e-03, fs:0.71186 (r=0.636,p=0.808),  time:15.609, tt:1045.790\n",
      "Ep:67, loss:0.00000, loss_test:0.09535, lr:8.26e-03, fs:0.71910 (r=0.646,p=0.810),  time:15.612, tt:1061.590\n",
      "Ep:68, loss:0.00000, loss_test:0.09506, lr:8.18e-03, fs:0.71910 (r=0.646,p=0.810),  time:15.616, tt:1077.497\n",
      "Ep:69, loss:0.00000, loss_test:0.09490, lr:8.10e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.628, tt:1093.960\n",
      "Ep:70, loss:0.00000, loss_test:0.09487, lr:8.02e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.638, tt:1110.304\n",
      "Ep:71, loss:0.00000, loss_test:0.09489, lr:7.94e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.642, tt:1126.199\n",
      "Ep:72, loss:0.00000, loss_test:0.09485, lr:7.86e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.650, tt:1142.427\n",
      "Ep:73, loss:0.00000, loss_test:0.09472, lr:7.78e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.659, tt:1158.760\n",
      "Ep:74, loss:0.00000, loss_test:0.09452, lr:7.70e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.677, tt:1175.798\n",
      "Ep:75, loss:0.00000, loss_test:0.09436, lr:7.62e-03, fs:0.72626 (r=0.657,p=0.812),  time:15.685, tt:1192.026\n",
      "Ep:76, loss:0.00000, loss_test:0.09427, lr:7.55e-03, fs:0.73034 (r=0.657,p=0.823),  time:15.689, tt:1208.090\n",
      "Ep:77, loss:0.00000, loss_test:0.09428, lr:7.47e-03, fs:0.73446 (r=0.657,p=0.833),  time:15.696, tt:1224.305\n",
      "Ep:78, loss:0.00000, loss_test:0.09434, lr:7.40e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.712, tt:1241.268\n",
      "Ep:79, loss:0.00000, loss_test:0.09435, lr:7.32e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.730, tt:1258.431\n",
      "Ep:80, loss:0.00000, loss_test:0.09434, lr:7.25e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.740, tt:1274.908\n",
      "Ep:81, loss:0.00000, loss_test:0.09426, lr:7.18e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.750, tt:1291.492\n",
      "Ep:82, loss:0.00000, loss_test:0.09416, lr:7.11e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.769, tt:1308.868\n",
      "Ep:83, loss:0.00000, loss_test:0.09407, lr:7.03e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.785, tt:1325.899\n",
      "Ep:84, loss:0.00000, loss_test:0.09399, lr:6.96e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.807, tt:1343.633\n",
      "Ep:85, loss:0.00000, loss_test:0.09389, lr:6.89e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.821, tt:1360.597\n",
      "Ep:86, loss:0.00000, loss_test:0.09380, lr:6.83e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.832, tt:1377.420\n",
      "Ep:87, loss:0.00000, loss_test:0.09373, lr:6.76e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.848, tt:1394.600\n",
      "Ep:88, loss:0.00000, loss_test:0.09371, lr:6.69e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.858, tt:1411.352\n",
      "Ep:89, loss:0.00000, loss_test:0.09368, lr:6.62e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.862, tt:1427.583\n",
      "Ep:90, loss:0.00000, loss_test:0.09362, lr:6.56e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.867, tt:1443.868\n",
      "Ep:91, loss:0.00000, loss_test:0.09353, lr:6.49e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.876, tt:1460.591\n",
      "Ep:92, loss:0.00000, loss_test:0.09348, lr:6.43e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.886, tt:1477.409\n",
      "Ep:93, loss:0.00000, loss_test:0.09345, lr:6.36e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.905, tt:1495.084\n",
      "Ep:94, loss:0.00000, loss_test:0.09344, lr:6.30e-03, fs:0.72727 (r=0.646,p=0.831),  time:15.900, tt:1510.545\n",
      "Ep:95, loss:0.00000, loss_test:0.09341, lr:6.24e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.899, tt:1526.288\n",
      "Ep:96, loss:0.00000, loss_test:0.09333, lr:6.17e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.902, tt:1542.480\n",
      "Ep:97, loss:0.00000, loss_test:0.09318, lr:6.11e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.903, tt:1558.507\n",
      "Ep:98, loss:0.00000, loss_test:0.09308, lr:6.05e-03, fs:0.73143 (r=0.646,p=0.842),  time:15.915, tt:1575.588\n",
      "Ep:99, loss:0.00000, loss_test:0.09299, lr:5.99e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.929, tt:1592.883\n",
      "Ep:100, loss:0.00000, loss_test:0.09297, lr:5.93e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.933, tt:1609.218\n",
      "Ep:101, loss:0.00000, loss_test:0.09304, lr:5.87e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.954, tt:1627.330\n",
      "Ep:102, loss:0.00000, loss_test:0.09305, lr:5.81e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.960, tt:1643.853\n",
      "Ep:103, loss:0.00000, loss_test:0.09296, lr:5.75e-03, fs:0.73563 (r=0.646,p=0.853),  time:15.961, tt:1659.985\n",
      "Ep:104, loss:0.00000, loss_test:0.09284, lr:5.70e-03, fs:0.73988 (r=0.646,p=0.865),  time:15.973, tt:1677.209\n",
      "Ep:105, loss:0.00000, loss_test:0.09281, lr:5.64e-03, fs:0.73988 (r=0.646,p=0.865),  time:15.978, tt:1693.656\n",
      "Ep:106, loss:0.00000, loss_test:0.09288, lr:5.58e-03, fs:0.74419 (r=0.646,p=0.877),  time:15.990, tt:1710.947\n",
      "Ep:107, loss:0.00000, loss_test:0.09303, lr:5.53e-03, fs:0.74419 (r=0.646,p=0.877),  time:15.995, tt:1727.458\n",
      "Ep:108, loss:0.00000, loss_test:0.09309, lr:5.47e-03, fs:0.74419 (r=0.646,p=0.877),  time:16.009, tt:1745.009\n",
      "Ep:109, loss:0.00000, loss_test:0.09303, lr:5.42e-03, fs:0.74419 (r=0.646,p=0.877),  time:16.026, tt:1762.908\n",
      "Ep:110, loss:0.00000, loss_test:0.09289, lr:5.36e-03, fs:0.74419 (r=0.646,p=0.877),  time:16.040, tt:1780.396\n",
      "Ep:111, loss:0.00000, loss_test:0.09282, lr:5.31e-03, fs:0.74419 (r=0.646,p=0.877),  time:16.048, tt:1797.384\n",
      "Ep:112, loss:0.00000, loss_test:0.09284, lr:5.26e-03, fs:0.74419 (r=0.646,p=0.877),  time:16.061, tt:1814.939\n",
      "Ep:113, loss:0.00000, loss_test:0.09299, lr:5.20e-03, fs:0.73684 (r=0.636,p=0.875),  time:16.078, tt:1832.922\n",
      "Ep:114, loss:0.00000, loss_test:0.09314, lr:5.15e-03, fs:0.73684 (r=0.636,p=0.875),  time:16.090, tt:1850.322\n",
      "Ep:115, loss:0.00000, loss_test:0.09321, lr:5.10e-03, fs:0.73684 (r=0.636,p=0.875),  time:16.109, tt:1868.602\n",
      "Ep:116, loss:0.00000, loss_test:0.09318, lr:5.05e-03, fs:0.73684 (r=0.636,p=0.875),  time:16.120, tt:1886.021\n",
      "Ep:117, loss:0.00000, loss_test:0.09310, lr:5.00e-03, fs:0.73684 (r=0.636,p=0.875),  time:16.130, tt:1903.391\n",
      "Ep:118, loss:0.00000, loss_test:0.09306, lr:4.95e-03, fs:0.73684 (r=0.636,p=0.875),  time:16.142, tt:1920.894\n",
      "Ep:119, loss:0.00000, loss_test:0.09305, lr:4.90e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.153, tt:1938.309\n",
      "Ep:120, loss:0.00000, loss_test:0.09304, lr:4.85e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.166, tt:1956.064\n",
      "Ep:121, loss:0.00000, loss_test:0.09295, lr:4.80e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.183, tt:1974.371\n",
      "Ep:122, loss:0.00000, loss_test:0.09288, lr:4.75e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.196, tt:1992.067\n",
      "Ep:123, loss:0.00000, loss_test:0.09288, lr:4.71e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.200, tt:2008.826\n",
      "Ep:124, loss:0.00000, loss_test:0.09283, lr:4.66e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.210, tt:2026.313\n",
      "Ep:125, loss:0.00000, loss_test:0.09276, lr:4.61e-03, fs:0.72941 (r=0.626,p=0.873),  time:16.226, tt:2044.476\n",
      "Ep:126, loss:0.00000, loss_test:0.09276, lr:4.57e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.234, tt:2061.700\n",
      "Ep:127, loss:0.00000, loss_test:0.09275, lr:4.52e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.248, tt:2079.751\n",
      "Ep:128, loss:0.00000, loss_test:0.09265, lr:4.48e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.255, tt:2096.866\n",
      "Ep:129, loss:0.00000, loss_test:0.09255, lr:4.43e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.263, tt:2114.153\n",
      "Ep:130, loss:0.00000, loss_test:0.09256, lr:4.39e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.275, tt:2131.988\n",
      "Ep:131, loss:0.00000, loss_test:0.09267, lr:4.34e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.287, tt:2149.936\n",
      "Ep:132, loss:0.00000, loss_test:0.09276, lr:4.30e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.303, tt:2168.243\n",
      "Ep:133, loss:0.00000, loss_test:0.09277, lr:4.26e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.310, tt:2185.572\n",
      "Ep:134, loss:0.00000, loss_test:0.09273, lr:4.21e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.314, tt:2202.448\n",
      "Ep:135, loss:0.00000, loss_test:0.09270, lr:4.17e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.323, tt:2219.959\n",
      "Ep:136, loss:0.00000, loss_test:0.09270, lr:4.13e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.334, tt:2237.698\n",
      "Ep:137, loss:0.00000, loss_test:0.09278, lr:4.09e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.351, tt:2256.369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.09285, lr:4.05e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.359, tt:2273.851\n",
      "Ep:139, loss:0.00000, loss_test:0.09286, lr:4.01e-03, fs:0.72189 (r=0.616,p=0.871),  time:16.358, tt:2290.187\n",
      "Ep:140, loss:0.00000, loss_test:0.09281, lr:3.97e-03, fs:0.72619 (r=0.616,p=0.884),  time:16.368, tt:2307.886\n",
      "Ep:141, loss:0.00000, loss_test:0.09275, lr:3.93e-03, fs:0.72619 (r=0.616,p=0.884),  time:16.374, tt:2325.146\n",
      "Ep:142, loss:0.00000, loss_test:0.09270, lr:3.89e-03, fs:0.72619 (r=0.616,p=0.884),  time:16.380, tt:2342.305\n",
      "Ep:143, loss:0.00000, loss_test:0.09271, lr:3.85e-03, fs:0.72619 (r=0.616,p=0.884),  time:16.385, tt:2359.500\n",
      "Ep:144, loss:0.00000, loss_test:0.09273, lr:3.81e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.394, tt:2377.166\n",
      "Ep:145, loss:0.00000, loss_test:0.09277, lr:3.77e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.407, tt:2395.410\n",
      "Ep:146, loss:0.00000, loss_test:0.09282, lr:3.73e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.411, tt:2412.353\n",
      "Ep:147, loss:0.00000, loss_test:0.09281, lr:3.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.421, tt:2430.252\n",
      "Ep:148, loss:0.00000, loss_test:0.09279, lr:3.66e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.428, tt:2447.738\n",
      "Ep:149, loss:0.00000, loss_test:0.09275, lr:3.62e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.436, tt:2465.396\n",
      "Ep:150, loss:0.00000, loss_test:0.09271, lr:3.59e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.438, tt:2482.176\n",
      "Ep:151, loss:0.00000, loss_test:0.09271, lr:3.55e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.443, tt:2499.388\n",
      "Ep:152, loss:0.00000, loss_test:0.09273, lr:3.52e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.447, tt:2516.386\n",
      "Ep:153, loss:0.00000, loss_test:0.09277, lr:3.48e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.463, tt:2535.290\n",
      "Ep:154, loss:0.00000, loss_test:0.09278, lr:3.45e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.460, tt:2551.289\n",
      "Ep:155, loss:0.00000, loss_test:0.09277, lr:3.41e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.458, tt:2567.525\n",
      "Ep:156, loss:0.00000, loss_test:0.09272, lr:3.38e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.455, tt:2583.459\n",
      "Ep:157, loss:0.00000, loss_test:0.09266, lr:3.34e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.457, tt:2600.149\n",
      "Ep:158, loss:0.00000, loss_test:0.09263, lr:3.31e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.461, tt:2617.248\n",
      "Ep:159, loss:0.00000, loss_test:0.09263, lr:3.28e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.460, tt:2633.619\n",
      "Ep:160, loss:0.00000, loss_test:0.09264, lr:3.24e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.465, tt:2650.858\n",
      "Ep:161, loss:0.00000, loss_test:0.09265, lr:3.21e-03, fs:0.73054 (r=0.616,p=0.897),  time:16.470, tt:2668.134\n",
      "Ep:162, loss:0.00000, loss_test:0.09268, lr:3.18e-03, fs:0.73494 (r=0.616,p=0.910),  time:16.475, tt:2685.442\n",
      "Ep:163, loss:0.00000, loss_test:0.09269, lr:3.15e-03, fs:0.73494 (r=0.616,p=0.910),  time:16.476, tt:2702.097\n",
      "Ep:164, loss:0.00000, loss_test:0.09269, lr:3.12e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.473, tt:2718.096\n",
      "Ep:165, loss:0.00000, loss_test:0.09271, lr:3.09e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.480, tt:2735.712\n",
      "Ep:166, loss:0.00000, loss_test:0.09272, lr:3.05e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.485, tt:2752.976\n",
      "Ep:167, loss:0.00000, loss_test:0.09273, lr:3.02e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.483, tt:2769.215\n",
      "Ep:168, loss:0.00000, loss_test:0.09275, lr:2.99e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.491, tt:2786.926\n",
      "Ep:169, loss:0.00000, loss_test:0.09280, lr:2.96e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.488, tt:2803.006\n",
      "Ep:170, loss:0.00000, loss_test:0.09284, lr:2.93e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.493, tt:2820.280\n",
      "Ep:171, loss:0.00000, loss_test:0.09286, lr:2.90e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.494, tt:2836.912\n",
      "Ep:172, loss:0.00000, loss_test:0.09288, lr:2.88e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.496, tt:2853.744\n",
      "Ep:173, loss:0.00000, loss_test:0.09290, lr:2.85e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.494, tt:2870.027\n",
      "Ep:174, loss:0.00000, loss_test:0.09293, lr:2.82e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.500, tt:2887.511\n",
      "Ep:175, loss:0.00000, loss_test:0.09296, lr:2.79e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.503, tt:2904.575\n",
      "Ep:176, loss:0.00000, loss_test:0.09296, lr:2.76e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.503, tt:2921.043\n",
      "Ep:177, loss:0.00000, loss_test:0.09293, lr:2.73e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.506, tt:2938.053\n",
      "Ep:178, loss:0.00000, loss_test:0.09290, lr:2.71e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.511, tt:2955.416\n",
      "Ep:179, loss:0.00000, loss_test:0.09289, lr:2.68e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.516, tt:2972.883\n",
      "Ep:180, loss:0.00000, loss_test:0.09289, lr:2.65e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.519, tt:2989.986\n",
      "Ep:181, loss:0.00000, loss_test:0.09290, lr:2.63e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.520, tt:3006.677\n",
      "Ep:182, loss:0.00000, loss_test:0.09292, lr:2.60e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.526, tt:3024.252\n",
      "Ep:183, loss:0.00000, loss_test:0.09292, lr:2.57e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.532, tt:3041.812\n",
      "Ep:184, loss:0.00000, loss_test:0.09287, lr:2.55e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.541, tt:3059.992\n",
      "Ep:185, loss:0.00000, loss_test:0.09285, lr:2.52e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.547, tt:3077.804\n",
      "Ep:186, loss:0.00000, loss_test:0.09289, lr:2.50e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.551, tt:3095.059\n",
      "Ep:187, loss:0.00000, loss_test:0.09296, lr:2.47e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.558, tt:3112.886\n",
      "Ep:188, loss:0.00000, loss_test:0.09306, lr:2.45e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.564, tt:3130.560\n",
      "Ep:189, loss:0.00000, loss_test:0.09313, lr:2.42e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.567, tt:3147.667\n",
      "Ep:190, loss:0.00000, loss_test:0.09314, lr:2.40e-03, fs:0.72727 (r=0.606,p=0.909),  time:16.574, tt:3165.578\n",
      "Ep:191, loss:0.00000, loss_test:0.09312, lr:2.38e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.583, tt:3183.866\n",
      "Ep:192, loss:0.00000, loss_test:0.09310, lr:2.35e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.592, tt:3202.233\n",
      "Ep:193, loss:0.00000, loss_test:0.09312, lr:2.33e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.595, tt:3219.444\n",
      "Ep:194, loss:0.00000, loss_test:0.09317, lr:2.31e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.604, tt:3237.695\n",
      "Ep:195, loss:0.00000, loss_test:0.09322, lr:2.28e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.606, tt:3254.710\n",
      "Ep:196, loss:0.00000, loss_test:0.09327, lr:2.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.609, tt:3271.901\n",
      "Ep:197, loss:0.00000, loss_test:0.09333, lr:2.24e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.617, tt:3290.252\n",
      "Ep:198, loss:0.00000, loss_test:0.09340, lr:2.21e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.625, tt:3308.415\n",
      "Ep:199, loss:0.00000, loss_test:0.09342, lr:2.19e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.629, tt:3325.788\n",
      "Ep:200, loss:0.00000, loss_test:0.09344, lr:2.17e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.630, tt:3342.685\n",
      "Ep:201, loss:0.00000, loss_test:0.09347, lr:2.15e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.633, tt:3359.881\n",
      "Ep:202, loss:0.00000, loss_test:0.09353, lr:2.13e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.632, tt:3376.260\n",
      "Ep:203, loss:0.00000, loss_test:0.09359, lr:2.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.636, tt:3393.656\n",
      "Ep:204, loss:0.00000, loss_test:0.09365, lr:2.08e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.636, tt:3410.328\n",
      "Ep:205, loss:0.00000, loss_test:0.09369, lr:2.06e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.639, tt:3427.597\n",
      "Ep:206, loss:0.00000, loss_test:0.09369, lr:2.04e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.638, tt:3444.016\n",
      "Ep:207, loss:0.00000, loss_test:0.09367, lr:2.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.637, tt:3460.508\n",
      "Ep:208, loss:0.00000, loss_test:0.09365, lr:2.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.639, tt:3477.503\n",
      "Ep:209, loss:0.00000, loss_test:0.09364, lr:1.98e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.646, tt:3495.638\n",
      "Ep:210, loss:0.00000, loss_test:0.09364, lr:1.96e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.648, tt:3512.701\n",
      "Ep:211, loss:0.00000, loss_test:0.09367, lr:1.94e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.650, tt:3529.814\n",
      "Ep:212, loss:0.00000, loss_test:0.09370, lr:1.92e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.650, tt:3546.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:213, loss:0.00000, loss_test:0.09371, lr:1.90e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.655, tt:3564.144\n",
      "Ep:214, loss:0.00000, loss_test:0.09371, lr:1.89e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.657, tt:3581.147\n",
      "Ep:215, loss:0.00000, loss_test:0.09370, lr:1.87e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.659, tt:3598.442\n",
      "Ep:216, loss:0.00000, loss_test:0.09369, lr:1.85e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.659, tt:3615.078\n",
      "Ep:217, loss:0.00000, loss_test:0.09372, lr:1.83e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.660, tt:3631.804\n",
      "Ep:218, loss:0.00000, loss_test:0.09377, lr:1.81e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.663, tt:3649.093\n",
      "Ep:219, loss:0.00000, loss_test:0.09383, lr:1.79e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.661, tt:3665.384\n",
      "Ep:220, loss:0.00000, loss_test:0.09385, lr:1.78e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.664, tt:3682.702\n",
      "Ep:221, loss:0.00000, loss_test:0.09389, lr:1.76e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.664, tt:3699.441\n",
      "Ep:222, loss:0.00000, loss_test:0.09393, lr:1.74e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.670, tt:3717.337\n",
      "Ep:223, loss:0.00000, loss_test:0.09393, lr:1.72e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.669, tt:3733.797\n",
      "Ep:224, loss:0.00000, loss_test:0.09392, lr:1.71e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.671, tt:3751.052\n",
      "Ep:225, loss:0.00000, loss_test:0.09392, lr:1.69e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.676, tt:3768.743\n",
      "Ep:226, loss:0.00000, loss_test:0.09395, lr:1.67e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.676, tt:3785.402\n",
      "Ep:227, loss:0.00000, loss_test:0.09397, lr:1.65e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.680, tt:3802.929\n",
      "Ep:228, loss:0.00000, loss_test:0.09397, lr:1.64e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.682, tt:3820.072\n",
      "Ep:229, loss:0.00000, loss_test:0.09396, lr:1.62e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.684, tt:3837.228\n",
      "Ep:230, loss:0.00000, loss_test:0.09396, lr:1.61e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.687, tt:3854.659\n",
      "Ep:231, loss:0.00000, loss_test:0.09397, lr:1.59e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.690, tt:3872.014\n",
      "Ep:232, loss:0.00000, loss_test:0.09397, lr:1.57e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.692, tt:3889.228\n",
      "Ep:233, loss:0.00000, loss_test:0.09394, lr:1.56e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.692, tt:3906.039\n",
      "Ep:234, loss:0.00000, loss_test:0.09391, lr:1.54e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.693, tt:3922.777\n",
      "Ep:235, loss:0.00000, loss_test:0.09391, lr:1.53e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.696, tt:3940.192\n",
      "Ep:236, loss:0.00000, loss_test:0.09393, lr:1.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.698, tt:3957.543\n",
      "Ep:237, loss:0.00000, loss_test:0.09396, lr:1.50e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.699, tt:3974.434\n",
      "Ep:238, loss:0.00000, loss_test:0.09398, lr:1.48e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.699, tt:3990.948\n",
      "Ep:239, loss:0.00000, loss_test:0.09398, lr:1.47e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.701, tt:4008.359\n",
      "Ep:240, loss:0.00000, loss_test:0.09398, lr:1.45e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.704, tt:4025.703\n",
      "Ep:241, loss:0.00000, loss_test:0.09402, lr:1.44e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.705, tt:4042.610\n",
      "Ep:242, loss:0.00000, loss_test:0.09406, lr:1.42e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.708, tt:4060.117\n",
      "Ep:243, loss:0.00000, loss_test:0.09409, lr:1.41e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.710, tt:4077.209\n",
      "Ep:244, loss:0.00000, loss_test:0.09409, lr:1.39e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.712, tt:4094.541\n",
      "Ep:245, loss:0.00000, loss_test:0.09408, lr:1.38e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.716, tt:4112.060\n",
      "Ep:246, loss:0.00000, loss_test:0.09407, lr:1.37e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.716, tt:4128.832\n",
      "Ep:247, loss:0.00000, loss_test:0.09407, lr:1.35e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.719, tt:4146.216\n",
      "Ep:248, loss:0.00000, loss_test:0.09409, lr:1.34e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.721, tt:4163.551\n",
      "Ep:249, loss:0.00000, loss_test:0.09412, lr:1.33e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.729, tt:4182.133\n",
      "Ep:250, loss:0.00000, loss_test:0.09412, lr:1.31e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.737, tt:4200.932\n",
      "Ep:251, loss:0.00000, loss_test:0.09412, lr:1.30e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.746, tt:4219.946\n",
      "Ep:252, loss:0.00000, loss_test:0.09413, lr:1.29e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.751, tt:4237.969\n",
      "Ep:253, loss:0.00000, loss_test:0.09414, lr:1.27e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.753, tt:4255.348\n",
      "Ep:254, loss:0.00000, loss_test:0.09416, lr:1.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.757, tt:4273.118\n",
      "Ep:255, loss:0.00000, loss_test:0.09419, lr:1.25e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.762, tt:4291.118\n",
      "Ep:256, loss:0.00000, loss_test:0.09421, lr:1.24e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.771, tt:4310.121\n",
      "Ep:257, loss:0.00000, loss_test:0.09424, lr:1.22e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.775, tt:4328.068\n",
      "Ep:258, loss:0.00000, loss_test:0.09425, lr:1.21e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.781, tt:4346.321\n",
      "Ep:259, loss:0.00000, loss_test:0.09425, lr:1.20e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.782, tt:4363.368\n",
      "Ep:260, loss:0.00000, loss_test:0.09426, lr:1.19e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.790, tt:4382.237\n",
      "Ep:261, loss:0.00000, loss_test:0.09427, lr:1.18e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.799, tt:4401.339\n",
      "Ep:262, loss:0.00000, loss_test:0.09429, lr:1.16e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.804, tt:4419.323\n",
      "Ep:263, loss:0.00000, loss_test:0.09431, lr:1.15e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.808, tt:4437.303\n",
      "Ep:264, loss:0.00000, loss_test:0.09433, lr:1.14e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.815, tt:4456.053\n",
      "Ep:265, loss:0.00000, loss_test:0.09435, lr:1.13e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.822, tt:4474.519\n",
      "Ep:266, loss:0.00000, loss_test:0.09437, lr:1.12e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.824, tt:4492.054\n",
      "Ep:267, loss:0.00000, loss_test:0.09438, lr:1.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.830, tt:4510.442\n",
      "Ep:268, loss:0.00000, loss_test:0.09440, lr:1.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.837, tt:4529.177\n",
      "Ep:269, loss:0.00000, loss_test:0.09441, lr:1.08e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.845, tt:4548.283\n",
      "Ep:270, loss:0.00000, loss_test:0.09443, lr:1.07e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.852, tt:4566.994\n",
      "Ep:271, loss:0.00000, loss_test:0.09445, lr:1.06e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.861, tt:4586.194\n",
      "Ep:272, loss:0.00000, loss_test:0.09446, lr:1.05e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.863, tt:4603.733\n",
      "Ep:273, loss:0.00000, loss_test:0.09447, lr:1.04e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.869, tt:4622.226\n",
      "Ep:274, loss:0.00000, loss_test:0.09449, lr:1.03e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.875, tt:4640.543\n",
      "Ep:275, loss:0.00000, loss_test:0.09451, lr:1.02e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.880, tt:4659.014\n",
      "Ep:276, loss:0.00000, loss_test:0.09454, lr:1.01e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.887, tt:4677.574\n",
      "Ep:277, loss:0.00000, loss_test:0.09456, lr:1.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:16.893, tt:4696.255\n",
      "Ep:278, loss:0.00000, loss_test:0.09458, lr:9.91e-04, fs:0.73171 (r=0.606,p=0.923),  time:16.900, tt:4715.041\n",
      "Ep:279, loss:0.00000, loss_test:0.09461, lr:9.81e-04, fs:0.73171 (r=0.606,p=0.923),  time:16.903, tt:4732.924\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14393, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.246, tt:15.246\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14365, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.214, tt:32.428\n",
      "Ep:2, loss:0.00000, loss_test:0.14323, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.168, tt:48.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00000, loss_test:0.14266, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.288, tt:65.151\n",
      "Ep:4, loss:0.00000, loss_test:0.14192, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.402, tt:82.010\n",
      "Ep:5, loss:0.00000, loss_test:0.14097, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:16.045, tt:96.269\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00000, loss_test:0.13974, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:16.080, tt:112.558\n",
      "Ep:7, loss:0.00000, loss_test:0.13808, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:15.974, tt:127.788\n",
      "Ep:8, loss:0.00000, loss_test:0.13590, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:16.115, tt:145.039\n",
      "Ep:9, loss:0.00000, loss_test:0.13333, lr:1.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:16.384, tt:163.841\n",
      "Ep:10, loss:0.00000, loss_test:0.13091, lr:1.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:16.595, tt:182.540\n",
      "Ep:11, loss:0.00000, loss_test:0.12915, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:16.896, tt:202.755\n",
      "Ep:12, loss:0.00000, loss_test:0.12838, lr:1.00e-02, fs:0.62500 (r=0.707,p=0.560),  time:17.082, tt:222.070\n",
      "Ep:13, loss:0.00000, loss_test:0.12951, lr:1.00e-02, fs:0.64078 (r=0.667,p=0.617),  time:17.156, tt:240.185\n",
      "Ep:14, loss:0.00000, loss_test:0.13075, lr:1.00e-02, fs:0.63636 (r=0.636,p=0.636),  time:17.282, tt:259.237\n",
      "Ep:15, loss:0.00000, loss_test:0.13083, lr:1.00e-02, fs:0.61140 (r=0.596,p=0.628),  time:17.359, tt:277.749\n",
      "Ep:16, loss:0.00000, loss_test:0.12940, lr:1.00e-02, fs:0.61140 (r=0.596,p=0.628),  time:17.499, tt:297.487\n",
      "Ep:17, loss:0.00000, loss_test:0.12723, lr:9.90e-03, fs:0.62944 (r=0.626,p=0.633),  time:17.582, tt:316.479\n",
      "Ep:18, loss:0.00000, loss_test:0.12517, lr:9.80e-03, fs:0.66995 (r=0.687,p=0.654),  time:17.662, tt:335.582\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00000, loss_test:0.12331, lr:9.80e-03, fs:0.65700 (r=0.687,p=0.630),  time:17.705, tt:354.095\n",
      "Ep:20, loss:0.00000, loss_test:0.12192, lr:9.80e-03, fs:0.67925 (r=0.727,p=0.637),  time:17.769, tt:373.154\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00000, loss_test:0.12073, lr:9.80e-03, fs:0.69484 (r=0.747,p=0.649),  time:17.843, tt:392.556\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00000, loss_test:0.11972, lr:9.80e-03, fs:0.68932 (r=0.717,p=0.664),  time:17.900, tt:411.702\n",
      "Ep:23, loss:0.00000, loss_test:0.11898, lr:9.80e-03, fs:0.65657 (r=0.657,p=0.657),  time:17.949, tt:430.774\n",
      "Ep:24, loss:0.00000, loss_test:0.11828, lr:9.80e-03, fs:0.63542 (r=0.616,p=0.656),  time:18.038, tt:450.941\n",
      "Ep:25, loss:0.00000, loss_test:0.11758, lr:9.80e-03, fs:0.64894 (r=0.616,p=0.685),  time:18.076, tt:469.984\n",
      "Ep:26, loss:0.00000, loss_test:0.11657, lr:9.80e-03, fs:0.66667 (r=0.646,p=0.688),  time:18.103, tt:488.791\n",
      "Ep:27, loss:0.00000, loss_test:0.11534, lr:9.80e-03, fs:0.70352 (r=0.707,p=0.700),  time:18.117, tt:507.266\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00000, loss_test:0.11432, lr:9.80e-03, fs:0.71000 (r=0.717,p=0.703),  time:18.161, tt:526.668\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.11353, lr:9.80e-03, fs:0.70936 (r=0.727,p=0.692),  time:18.176, tt:545.291\n",
      "Ep:30, loss:0.00000, loss_test:0.11292, lr:9.80e-03, fs:0.71287 (r=0.727,p=0.699),  time:18.204, tt:564.334\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.11245, lr:9.80e-03, fs:0.71000 (r=0.717,p=0.703),  time:18.213, tt:582.811\n",
      "Ep:32, loss:0.00000, loss_test:0.11205, lr:9.80e-03, fs:0.72081 (r=0.717,p=0.724),  time:18.220, tt:601.266\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.11158, lr:9.80e-03, fs:0.72449 (r=0.717,p=0.732),  time:18.258, tt:620.756\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.11093, lr:9.80e-03, fs:0.72449 (r=0.717,p=0.732),  time:18.295, tt:640.308\n",
      "Ep:35, loss:0.00000, loss_test:0.11006, lr:9.80e-03, fs:0.72449 (r=0.717,p=0.732),  time:18.300, tt:658.804\n",
      "Ep:36, loss:0.00000, loss_test:0.10918, lr:9.80e-03, fs:0.72727 (r=0.727,p=0.727),  time:18.302, tt:677.159\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.10843, lr:9.80e-03, fs:0.73096 (r=0.727,p=0.735),  time:18.295, tt:695.192\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00000, loss_test:0.10772, lr:9.80e-03, fs:0.73469 (r=0.727,p=0.742),  time:18.290, tt:713.322\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.10702, lr:9.80e-03, fs:0.73846 (r=0.727,p=0.750),  time:18.297, tt:731.877\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.10623, lr:9.80e-03, fs:0.74227 (r=0.727,p=0.758),  time:18.292, tt:749.971\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00000, loss_test:0.10529, lr:9.80e-03, fs:0.74227 (r=0.727,p=0.758),  time:18.332, tt:769.962\n",
      "Ep:42, loss:0.00000, loss_test:0.10427, lr:9.80e-03, fs:0.74227 (r=0.727,p=0.758),  time:18.344, tt:788.786\n",
      "Ep:43, loss:0.00000, loss_test:0.10335, lr:9.80e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.352, tt:807.506\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00000, loss_test:0.10265, lr:9.80e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.361, tt:826.244\n",
      "Ep:45, loss:0.00000, loss_test:0.10215, lr:9.80e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.366, tt:844.831\n",
      "Ep:46, loss:0.00000, loss_test:0.10178, lr:9.80e-03, fs:0.74872 (r=0.737,p=0.760),  time:18.374, tt:863.576\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00000, loss_test:0.10150, lr:9.80e-03, fs:0.74611 (r=0.727,p=0.766),  time:18.382, tt:882.343\n",
      "Ep:48, loss:0.00000, loss_test:0.10122, lr:9.80e-03, fs:0.74611 (r=0.727,p=0.766),  time:18.377, tt:900.490\n",
      "Ep:49, loss:0.00000, loss_test:0.10084, lr:9.80e-03, fs:0.74611 (r=0.727,p=0.766),  time:18.374, tt:918.717\n",
      "Ep:50, loss:0.00000, loss_test:0.10030, lr:9.80e-03, fs:0.75258 (r=0.737,p=0.768),  time:18.360, tt:936.347\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00000, loss_test:0.09973, lr:9.80e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.365, tt:954.954\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00000, loss_test:0.09922, lr:9.80e-03, fs:0.76531 (r=0.758,p=0.773),  time:18.365, tt:973.346\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00000, loss_test:0.09882, lr:9.80e-03, fs:0.76531 (r=0.758,p=0.773),  time:18.357, tt:991.261\n",
      "Ep:54, loss:0.00000, loss_test:0.09852, lr:9.80e-03, fs:0.77320 (r=0.758,p=0.789),  time:18.359, tt:1009.764\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00000, loss_test:0.09817, lr:9.80e-03, fs:0.77320 (r=0.758,p=0.789),  time:18.362, tt:1028.272\n",
      "Ep:56, loss:0.00000, loss_test:0.09775, lr:9.80e-03, fs:0.77320 (r=0.758,p=0.789),  time:18.350, tt:1045.977\n",
      "Ep:57, loss:0.00000, loss_test:0.09728, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:18.354, tt:1064.542\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00000, loss_test:0.09681, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.350, tt:1082.667\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00000, loss_test:0.09635, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.351, tt:1101.055\n",
      "Ep:60, loss:0.00000, loss_test:0.09590, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.336, tt:1118.472\n",
      "Ep:61, loss:0.00000, loss_test:0.09538, lr:9.80e-03, fs:0.79381 (r=0.778,p=0.811),  time:18.319, tt:1135.758\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00000, loss_test:0.09488, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.320, tt:1154.171\n",
      "Ep:63, loss:0.00000, loss_test:0.09449, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.306, tt:1171.599\n",
      "Ep:64, loss:0.00000, loss_test:0.09415, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.294, tt:1189.087\n",
      "Ep:65, loss:0.00000, loss_test:0.09382, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.293, tt:1207.319\n",
      "Ep:66, loss:0.00000, loss_test:0.09341, lr:9.80e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.287, tt:1225.231\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00000, loss_test:0.09296, lr:9.80e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.277, tt:1242.868\n",
      "Ep:68, loss:0.00000, loss_test:0.09254, lr:9.80e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.274, tt:1260.908\n",
      "Ep:69, loss:0.00000, loss_test:0.09216, lr:9.80e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.268, tt:1278.793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00000, loss_test:0.09181, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:18.254, tt:1296.016\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00000, loss_test:0.09144, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:18.257, tt:1314.508\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00000, loss_test:0.09097, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:18.259, tt:1332.903\n",
      "Ep:73, loss:0.00000, loss_test:0.09060, lr:9.80e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.252, tt:1350.631\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00000, loss_test:0.09040, lr:9.80e-03, fs:0.81481 (r=0.778,p=0.856),  time:18.240, tt:1368.014\n",
      "Ep:75, loss:0.00000, loss_test:0.09032, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.254, tt:1387.306\n",
      "Ep:76, loss:0.00000, loss_test:0.09020, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.253, tt:1405.475\n",
      "Ep:77, loss:0.00000, loss_test:0.08998, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.238, tt:1422.598\n",
      "Ep:78, loss:0.00000, loss_test:0.08974, lr:9.80e-03, fs:0.81481 (r=0.778,p=0.856),  time:18.222, tt:1439.528\n",
      "Ep:79, loss:0.00000, loss_test:0.08958, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.213, tt:1457.064\n",
      "Ep:80, loss:0.00000, loss_test:0.08949, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.205, tt:1474.574\n",
      "Ep:81, loss:0.00000, loss_test:0.08931, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.195, tt:1492.014\n",
      "Ep:82, loss:0.00000, loss_test:0.08906, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.184, tt:1509.294\n",
      "Ep:83, loss:0.00000, loss_test:0.08892, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.172, tt:1526.469\n",
      "Ep:84, loss:0.00000, loss_test:0.08887, lr:9.80e-03, fs:0.81720 (r=0.768,p=0.874),  time:18.176, tt:1544.948\n",
      "Ep:85, loss:0.00000, loss_test:0.08868, lr:9.70e-03, fs:0.82609 (r=0.768,p=0.894),  time:18.173, tt:1562.891\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00000, loss_test:0.08841, lr:9.70e-03, fs:0.82609 (r=0.768,p=0.894),  time:18.178, tt:1581.451\n",
      "Ep:87, loss:0.00000, loss_test:0.08831, lr:9.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:18.179, tt:1599.778\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00000, loss_test:0.08839, lr:9.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:18.182, tt:1618.183\n",
      "Ep:89, loss:0.00000, loss_test:0.08836, lr:9.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:18.180, tt:1636.158\n",
      "Ep:90, loss:0.00000, loss_test:0.08818, lr:9.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:18.182, tt:1654.549\n",
      "Ep:91, loss:0.00000, loss_test:0.08791, lr:9.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:18.178, tt:1672.372\n",
      "Ep:92, loss:0.00000, loss_test:0.08787, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:18.181, tt:1690.847\n",
      "Ep:93, loss:0.00000, loss_test:0.08790, lr:9.70e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.182, tt:1709.123\n",
      "Ep:94, loss:0.00000, loss_test:0.08771, lr:9.70e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.185, tt:1727.570\n",
      "Ep:95, loss:0.00000, loss_test:0.08738, lr:9.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.188, tt:1746.081\n",
      "Ep:96, loss:0.00000, loss_test:0.08716, lr:9.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.183, tt:1763.703\n",
      "Ep:97, loss:0.00000, loss_test:0.08718, lr:9.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.176, tt:1781.232\n",
      "Ep:98, loss:0.00000, loss_test:0.08728, lr:9.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.170, tt:1798.846\n",
      "Ep:99, loss:0.00000, loss_test:0.08724, lr:9.61e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.164, tt:1816.381\n",
      "Ep:100, loss:0.00000, loss_test:0.08707, lr:9.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.183, tt:1836.532\n",
      "Ep:101, loss:0.00000, loss_test:0.08715, lr:9.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.182, tt:1854.587\n",
      "Ep:102, loss:0.00000, loss_test:0.08742, lr:9.32e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.183, tt:1872.854\n",
      "Ep:103, loss:0.00000, loss_test:0.08752, lr:9.23e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.195, tt:1892.271\n",
      "Ep:104, loss:0.00000, loss_test:0.08742, lr:9.14e-03, fs:0.78857 (r=0.697,p=0.908),  time:18.202, tt:1911.247\n",
      "Ep:105, loss:0.00000, loss_test:0.08744, lr:9.04e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.200, tt:1929.198\n",
      "Ep:106, loss:0.00000, loss_test:0.08750, lr:8.95e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.209, tt:1948.309\n",
      "Ep:107, loss:0.00000, loss_test:0.08754, lr:8.86e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.215, tt:1967.232\n",
      "Ep:108, loss:0.00000, loss_test:0.08755, lr:8.78e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.217, tt:1985.623\n",
      "Ep:109, loss:0.00000, loss_test:0.08754, lr:8.69e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.218, tt:2003.985\n",
      "Ep:110, loss:0.00000, loss_test:0.08751, lr:8.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.214, tt:2021.733\n",
      "Ep:111, loss:0.00000, loss_test:0.08763, lr:8.51e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.217, tt:2040.312\n",
      "Ep:112, loss:0.00000, loss_test:0.08780, lr:8.43e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.219, tt:2058.755\n",
      "Ep:113, loss:0.00000, loss_test:0.08778, lr:8.35e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.217, tt:2076.748\n",
      "Ep:114, loss:0.00000, loss_test:0.08761, lr:8.26e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.215, tt:2094.700\n",
      "Ep:115, loss:0.00000, loss_test:0.08740, lr:8.18e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.215, tt:2112.907\n",
      "Ep:116, loss:0.00000, loss_test:0.08736, lr:8.10e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.209, tt:2130.511\n",
      "Ep:117, loss:0.00000, loss_test:0.08756, lr:8.02e-03, fs:0.77647 (r=0.667,p=0.930),  time:18.215, tt:2149.382\n",
      "Ep:118, loss:0.00000, loss_test:0.08759, lr:7.94e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.209, tt:2166.865\n",
      "Ep:119, loss:0.00000, loss_test:0.08743, lr:7.86e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.200, tt:2184.044\n",
      "Ep:120, loss:0.00000, loss_test:0.08730, lr:7.78e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.192, tt:2201.291\n",
      "Ep:121, loss:0.00000, loss_test:0.08741, lr:7.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.192, tt:2219.438\n",
      "Ep:122, loss:0.00000, loss_test:0.08766, lr:7.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.187, tt:2237.035\n",
      "Ep:123, loss:0.00000, loss_test:0.08778, lr:7.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.188, tt:2255.274\n",
      "Ep:124, loss:0.00000, loss_test:0.08775, lr:7.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.198, tt:2274.694\n",
      "Ep:125, loss:0.00000, loss_test:0.08768, lr:7.40e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.202, tt:2293.429\n",
      "Ep:126, loss:0.00000, loss_test:0.08769, lr:7.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.205, tt:2311.977\n",
      "Ep:127, loss:0.00000, loss_test:0.08769, lr:7.25e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.211, tt:2330.976\n",
      "Ep:128, loss:0.00000, loss_test:0.08764, lr:7.18e-03, fs:0.76923 (r=0.657,p=0.929),  time:18.218, tt:2350.071\n",
      "Ep:129, loss:0.00000, loss_test:0.08765, lr:7.11e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.230, tt:2369.834\n",
      "Ep:130, loss:0.00000, loss_test:0.08779, lr:7.03e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.238, tt:2389.218\n",
      "Ep:131, loss:0.00000, loss_test:0.08796, lr:6.96e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.247, tt:2408.621\n",
      "Ep:132, loss:0.00000, loss_test:0.08805, lr:6.89e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.254, tt:2427.844\n",
      "Ep:133, loss:0.00000, loss_test:0.08801, lr:6.83e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.257, tt:2446.499\n",
      "Ep:134, loss:0.00000, loss_test:0.08808, lr:6.76e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.259, tt:2464.935\n",
      "Ep:135, loss:0.00000, loss_test:0.08817, lr:6.69e-03, fs:0.77381 (r=0.657,p=0.942),  time:18.266, tt:2484.142\n",
      "Ep:136, loss:0.00000, loss_test:0.08822, lr:6.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.264, tt:2502.198\n",
      "Ep:137, loss:0.00000, loss_test:0.08817, lr:6.56e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.267, tt:2520.861\n",
      "Ep:138, loss:0.00000, loss_test:0.08810, lr:6.49e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.277, tt:2540.453\n",
      "Ep:139, loss:0.00000, loss_test:0.08819, lr:6.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.282, tt:2559.472\n",
      "Ep:140, loss:0.00000, loss_test:0.08844, lr:6.36e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.286, tt:2578.329\n",
      "Ep:141, loss:0.00000, loss_test:0.08855, lr:6.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.295, tt:2597.836\n",
      "Ep:142, loss:0.00000, loss_test:0.08843, lr:6.24e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.297, tt:2616.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.08835, lr:6.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.303, tt:2635.663\n",
      "Ep:144, loss:0.00000, loss_test:0.08851, lr:6.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.305, tt:2654.234\n",
      "Ep:145, loss:0.00000, loss_test:0.08872, lr:6.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.313, tt:2673.637\n",
      "Ep:146, loss:0.00000, loss_test:0.08884, lr:5.99e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.323, tt:2693.453\n",
      "Ep:147, loss:0.00000, loss_test:0.08888, lr:5.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.321, tt:2711.477\n",
      "Ep:148, loss:0.00000, loss_test:0.08891, lr:5.87e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.325, tt:2730.372\n",
      "Ep:149, loss:0.00000, loss_test:0.08903, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.328, tt:2749.266\n",
      "Ep:150, loss:0.00000, loss_test:0.08925, lr:5.75e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.328, tt:2767.486\n",
      "Ep:151, loss:0.00000, loss_test:0.08946, lr:5.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.329, tt:2786.062\n",
      "Ep:152, loss:0.00000, loss_test:0.08957, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.337, tt:2805.566\n",
      "Ep:153, loss:0.00000, loss_test:0.08959, lr:5.58e-03, fs:0.76647 (r=0.646,p=0.941),  time:18.341, tt:2824.541\n",
      "Ep:154, loss:0.00000, loss_test:0.08952, lr:5.53e-03, fs:0.77108 (r=0.646,p=0.955),  time:18.347, tt:2843.853\n",
      "Ep:155, loss:0.00000, loss_test:0.08958, lr:5.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:18.349, tt:2862.438\n",
      "Ep:156, loss:0.00000, loss_test:0.08977, lr:5.42e-03, fs:0.77108 (r=0.646,p=0.955),  time:18.354, tt:2881.636\n",
      "Ep:157, loss:0.00000, loss_test:0.08994, lr:5.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.362, tt:2901.148\n",
      "Ep:158, loss:0.00000, loss_test:0.09004, lr:5.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.376, tt:2921.849\n",
      "Ep:159, loss:0.00000, loss_test:0.09006, lr:5.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.380, tt:2940.861\n",
      "Ep:160, loss:0.00000, loss_test:0.09013, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.382, tt:2959.536\n",
      "Ep:161, loss:0.00000, loss_test:0.09025, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.383, tt:2978.014\n",
      "Ep:162, loss:0.00000, loss_test:0.09037, lr:5.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.381, tt:2996.130\n",
      "Ep:163, loss:0.00000, loss_test:0.09041, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.386, tt:3015.341\n",
      "Ep:164, loss:0.00000, loss_test:0.09046, lr:5.00e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.394, tt:3035.013\n",
      "Ep:165, loss:0.00000, loss_test:0.09053, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.394, tt:3053.385\n",
      "Ep:166, loss:0.00000, loss_test:0.09067, lr:4.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.389, tt:3071.021\n",
      "Ep:167, loss:0.00000, loss_test:0.09086, lr:4.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.391, tt:3089.647\n",
      "Ep:168, loss:0.00000, loss_test:0.09097, lr:4.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.388, tt:3107.572\n",
      "Ep:169, loss:0.00000, loss_test:0.09102, lr:4.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.387, tt:3125.867\n",
      "Ep:170, loss:0.00000, loss_test:0.09100, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.389, tt:3144.470\n",
      "Ep:171, loss:0.00000, loss_test:0.09094, lr:4.66e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.394, tt:3163.837\n",
      "Ep:172, loss:0.00000, loss_test:0.09091, lr:4.61e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.400, tt:3183.232\n",
      "Ep:173, loss:0.00000, loss_test:0.09097, lr:4.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.397, tt:3201.164\n",
      "Ep:174, loss:0.00000, loss_test:0.09109, lr:4.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.402, tt:3220.303\n",
      "Ep:175, loss:0.00000, loss_test:0.09128, lr:4.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.406, tt:3239.442\n",
      "Ep:176, loss:0.00000, loss_test:0.09143, lr:4.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.412, tt:3258.865\n",
      "Ep:177, loss:0.00000, loss_test:0.09155, lr:4.39e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.420, tt:3278.724\n",
      "Ep:178, loss:0.00000, loss_test:0.09162, lr:4.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.421, tt:3297.307\n",
      "Ep:179, loss:0.00000, loss_test:0.09170, lr:4.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.422, tt:3315.914\n",
      "Ep:180, loss:0.00000, loss_test:0.09177, lr:4.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.423, tt:3334.478\n",
      "Ep:181, loss:0.00000, loss_test:0.09182, lr:4.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.424, tt:3353.177\n",
      "Ep:182, loss:0.00000, loss_test:0.09192, lr:4.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.420, tt:3370.932\n",
      "Ep:183, loss:0.00000, loss_test:0.09203, lr:4.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.418, tt:3388.980\n",
      "Ep:184, loss:0.00000, loss_test:0.09215, lr:4.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.423, tt:3408.176\n",
      "Ep:185, loss:0.00000, loss_test:0.09227, lr:4.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.428, tt:3427.531\n",
      "Ep:186, loss:0.00000, loss_test:0.09235, lr:4.01e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.433, tt:3446.888\n",
      "Ep:187, loss:0.00000, loss_test:0.09239, lr:3.97e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.435, tt:3465.770\n",
      "Ep:188, loss:0.00000, loss_test:0.09241, lr:3.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.435, tt:3484.246\n",
      "Ep:189, loss:0.00000, loss_test:0.09243, lr:3.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.440, tt:3503.593\n",
      "Ep:190, loss:0.00000, loss_test:0.09245, lr:3.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.443, tt:3522.591\n",
      "Ep:191, loss:0.00000, loss_test:0.09241, lr:3.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.447, tt:3541.770\n",
      "Ep:192, loss:0.00000, loss_test:0.09242, lr:3.77e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.454, tt:3561.558\n",
      "Ep:193, loss:0.00000, loss_test:0.09251, lr:3.73e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.457, tt:3580.676\n",
      "Ep:194, loss:0.00000, loss_test:0.09265, lr:3.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.463, tt:3600.320\n",
      "Ep:195, loss:0.00000, loss_test:0.09278, lr:3.66e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.466, tt:3619.375\n",
      "Ep:196, loss:0.00000, loss_test:0.09281, lr:3.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.471, tt:3638.851\n",
      "Ep:197, loss:0.00000, loss_test:0.09274, lr:3.59e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.473, tt:3657.747\n",
      "Ep:198, loss:0.00000, loss_test:0.09271, lr:3.55e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.479, tt:3677.318\n",
      "Ep:199, loss:0.00000, loss_test:0.09276, lr:3.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.483, tt:3696.644\n",
      "Ep:200, loss:0.00000, loss_test:0.09285, lr:3.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.484, tt:3715.239\n",
      "Ep:201, loss:0.00000, loss_test:0.09292, lr:3.45e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.486, tt:3734.218\n",
      "Ep:202, loss:0.00000, loss_test:0.09297, lr:3.41e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.483, tt:3752.117\n",
      "Ep:203, loss:0.00000, loss_test:0.09304, lr:3.38e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.485, tt:3770.856\n",
      "Ep:204, loss:0.00000, loss_test:0.09309, lr:3.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.487, tt:3789.783\n",
      "Ep:205, loss:0.00000, loss_test:0.09310, lr:3.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.487, tt:3808.254\n",
      "Ep:206, loss:0.00000, loss_test:0.09315, lr:3.28e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.491, tt:3827.533\n",
      "Ep:207, loss:0.00000, loss_test:0.09320, lr:3.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.492, tt:3846.272\n",
      "Ep:208, loss:0.00000, loss_test:0.09328, lr:3.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.487, tt:3863.743\n",
      "Ep:209, loss:0.00000, loss_test:0.09332, lr:3.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.488, tt:3882.398\n",
      "Ep:210, loss:0.00000, loss_test:0.09334, lr:3.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.492, tt:3901.761\n",
      "Ep:211, loss:0.00000, loss_test:0.09336, lr:3.12e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.495, tt:3920.876\n",
      "Ep:212, loss:0.00000, loss_test:0.09335, lr:3.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.499, tt:3940.295\n",
      "Ep:213, loss:0.00000, loss_test:0.09332, lr:3.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.506, tt:3960.263\n",
      "Ep:214, loss:0.00000, loss_test:0.09333, lr:3.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.513, tt:3980.235\n",
      "Ep:215, loss:0.00000, loss_test:0.09340, lr:2.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.512, tt:3998.691\n",
      "Ep:216, loss:0.00000, loss_test:0.09347, lr:2.96e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.514, tt:4017.478\n",
      "Ep:217, loss:0.00000, loss_test:0.09346, lr:2.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.515, tt:4036.293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:218, loss:0.00000, loss_test:0.09341, lr:2.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.517, tt:4055.293\n",
      "Ep:219, loss:0.00000, loss_test:0.09338, lr:2.88e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.525, tt:4075.424\n",
      "Ep:220, loss:0.00000, loss_test:0.09341, lr:2.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.530, tt:4095.167\n",
      "Ep:221, loss:0.00000, loss_test:0.09346, lr:2.82e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.537, tt:4115.226\n",
      "Ep:222, loss:0.00000, loss_test:0.09350, lr:2.79e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.539, tt:4134.225\n",
      "Ep:223, loss:0.00000, loss_test:0.09351, lr:2.76e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.544, tt:4153.800\n",
      "Ep:224, loss:0.00000, loss_test:0.09350, lr:2.73e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.544, tt:4172.499\n",
      "Ep:225, loss:0.00000, loss_test:0.09350, lr:2.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.547, tt:4191.677\n",
      "Ep:226, loss:0.00000, loss_test:0.09352, lr:2.68e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.548, tt:4210.357\n",
      "Ep:227, loss:0.00000, loss_test:0.09357, lr:2.65e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.551, tt:4229.524\n",
      "Ep:228, loss:0.00000, loss_test:0.09359, lr:2.63e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.553, tt:4248.529\n",
      "Ep:229, loss:0.00000, loss_test:0.09362, lr:2.60e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.555, tt:4267.537\n",
      "Ep:230, loss:0.00000, loss_test:0.09370, lr:2.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.557, tt:4286.760\n",
      "Ep:231, loss:0.00000, loss_test:0.09377, lr:2.55e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.560, tt:4306.029\n",
      "Ep:232, loss:0.00000, loss_test:0.09382, lr:2.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.561, tt:4324.605\n",
      "Ep:233, loss:0.00000, loss_test:0.09384, lr:2.50e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.568, tt:4344.833\n",
      "Ep:234, loss:0.00000, loss_test:0.09389, lr:2.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.569, tt:4363.745\n",
      "Ep:235, loss:0.00000, loss_test:0.09395, lr:2.45e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.570, tt:4382.592\n",
      "Ep:236, loss:0.00000, loss_test:0.09397, lr:2.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.572, tt:4401.615\n",
      "Ep:237, loss:0.00000, loss_test:0.09398, lr:2.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.571, tt:4419.882\n",
      "Ep:238, loss:0.00000, loss_test:0.09398, lr:2.38e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.573, tt:4438.878\n",
      "Ep:239, loss:0.00000, loss_test:0.09400, lr:2.35e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.570, tt:4456.718\n",
      "Ep:240, loss:0.00000, loss_test:0.09406, lr:2.33e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.571, tt:4475.657\n",
      "Ep:241, loss:0.00000, loss_test:0.09413, lr:2.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.574, tt:4494.972\n",
      "Ep:242, loss:0.00000, loss_test:0.09419, lr:2.28e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.570, tt:4512.523\n",
      "Ep:243, loss:0.00000, loss_test:0.09422, lr:2.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.570, tt:4531.026\n",
      "Ep:244, loss:0.00000, loss_test:0.09423, lr:2.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.570, tt:4549.609\n",
      "Ep:245, loss:0.00000, loss_test:0.09427, lr:2.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.567, tt:4567.544\n",
      "Ep:246, loss:0.00000, loss_test:0.09433, lr:2.19e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.567, tt:4585.955\n",
      "Ep:247, loss:0.00000, loss_test:0.09436, lr:2.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.564, tt:4603.944\n",
      "Ep:248, loss:0.00000, loss_test:0.09438, lr:2.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.562, tt:4622.057\n",
      "Ep:249, loss:0.00000, loss_test:0.09438, lr:2.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.564, tt:4641.070\n",
      "Ep:250, loss:0.00000, loss_test:0.09437, lr:2.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.563, tt:4659.233\n",
      "Ep:251, loss:0.00000, loss_test:0.09438, lr:2.08e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.559, tt:4676.968\n",
      "Ep:252, loss:0.00000, loss_test:0.09440, lr:2.06e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.557, tt:4694.999\n",
      "Ep:253, loss:0.00000, loss_test:0.09444, lr:2.04e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.554, tt:4712.798\n",
      "Ep:254, loss:0.00000, loss_test:0.09448, lr:2.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.552, tt:4730.718\n",
      "Ep:255, loss:0.00000, loss_test:0.09451, lr:2.00e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.553, tt:4749.621\n",
      "Ep:256, loss:0.00000, loss_test:0.09454, lr:1.98e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.550, tt:4767.418\n",
      "Ep:257, loss:0.00000, loss_test:0.09456, lr:1.96e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.551, tt:4786.186\n",
      "Ep:258, loss:0.00000, loss_test:0.09458, lr:1.94e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.548, tt:4803.917\n",
      "Ep:259, loss:0.00000, loss_test:0.09460, lr:1.92e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.553, tt:4823.784\n",
      "Ep:260, loss:0.00000, loss_test:0.09461, lr:1.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.553, tt:4842.331\n",
      "Ep:261, loss:0.00000, loss_test:0.09461, lr:1.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.556, tt:4861.609\n",
      "Ep:262, loss:0.00000, loss_test:0.09458, lr:1.87e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.555, tt:4879.992\n",
      "Ep:263, loss:0.00000, loss_test:0.09457, lr:1.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.552, tt:4897.815\n",
      "Ep:264, loss:0.00000, loss_test:0.09459, lr:1.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.551, tt:4916.082\n",
      "Ep:265, loss:0.00000, loss_test:0.09463, lr:1.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.552, tt:4934.908\n",
      "Ep:266, loss:0.00000, loss_test:0.09464, lr:1.79e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.552, tt:4953.363\n",
      "Ep:267, loss:0.00000, loss_test:0.09465, lr:1.78e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.555, tt:4972.619\n",
      "Ep:268, loss:0.00000, loss_test:0.09465, lr:1.76e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.554, tt:4991.042\n",
      "Ep:269, loss:0.00000, loss_test:0.09465, lr:1.74e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.553, tt:5009.409\n",
      "Ep:270, loss:0.00000, loss_test:0.09465, lr:1.72e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.553, tt:5027.875\n",
      "Ep:271, loss:0.00000, loss_test:0.09465, lr:1.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:18.554, tt:5046.622\n",
      "Ep:272, loss:0.00000, loss_test:0.09466, lr:1.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.553, tt:5064.921\n",
      "Ep:273, loss:0.00000, loss_test:0.09469, lr:1.67e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.555, tt:5083.957\n",
      "Ep:274, loss:0.00000, loss_test:0.09471, lr:1.65e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.560, tt:5103.951\n",
      "Ep:275, loss:0.00000, loss_test:0.09472, lr:1.64e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.562, tt:5122.996\n",
      "Ep:276, loss:0.00000, loss_test:0.09472, lr:1.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.564, tt:5142.299\n",
      "Ep:277, loss:0.00000, loss_test:0.09473, lr:1.61e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.567, tt:5161.546\n",
      "Ep:278, loss:0.00000, loss_test:0.09473, lr:1.59e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.568, tt:5180.602\n",
      "Ep:279, loss:0.00000, loss_test:0.09474, lr:1.57e-03, fs:0.78049 (r=0.646,p=0.985),  time:18.573, tt:5200.489\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"1-2\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=40000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,280,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 512: \n",
      "Ep:0, loss:0.00112, loss_test:0.14584, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:16.759, tt:16.759\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00111, loss_test:0.14491, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:17.414, tt:34.828\n",
      "Ep:2, loss:0.00109, loss_test:0.14311, lr:4.00e-03, fs:0.64384 (r=0.949,p=0.487),  time:18.559, tt:55.678\n",
      "Ep:3, loss:0.00106, loss_test:0.13985, lr:4.00e-03, fs:0.64085 (r=0.919,p=0.492),  time:19.392, tt:77.566\n",
      "Ep:4, loss:0.00101, loss_test:0.13431, lr:4.00e-03, fs:0.63396 (r=0.848,p=0.506),  time:19.866, tt:99.332\n",
      "Ep:5, loss:0.00095, loss_test:0.12944, lr:4.00e-03, fs:0.62281 (r=0.717,p=0.550),  time:20.257, tt:121.543\n",
      "Ep:6, loss:0.00092, loss_test:0.12685, lr:4.00e-03, fs:0.64455 (r=0.687,p=0.607),  time:20.515, tt:143.603\n",
      "Ep:7, loss:0.00091, loss_test:0.12399, lr:4.00e-03, fs:0.64815 (r=0.707,p=0.598),  time:20.858, tt:166.864\n",
      "Ep:8, loss:0.00089, loss_test:0.12288, lr:4.00e-03, fs:0.64889 (r=0.737,p=0.579),  time:21.056, tt:189.501\n",
      "Ep:9, loss:0.00086, loss_test:0.12088, lr:4.00e-03, fs:0.65766 (r=0.737,p=0.593),  time:21.190, tt:211.899\n",
      "Ep:10, loss:0.00084, loss_test:0.11875, lr:4.00e-03, fs:0.64762 (r=0.687,p=0.613),  time:21.241, tt:233.647\n",
      "Ep:11, loss:0.00083, loss_test:0.11630, lr:4.00e-03, fs:0.65072 (r=0.687,p=0.618),  time:21.364, tt:256.371\n",
      "Ep:12, loss:0.00081, loss_test:0.11379, lr:3.96e-03, fs:0.66667 (r=0.707,p=0.631),  time:21.457, tt:278.942\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00079, loss_test:0.11137, lr:3.96e-03, fs:0.66019 (r=0.687,p=0.636),  time:21.561, tt:301.859\n",
      "Ep:14, loss:0.00077, loss_test:0.10947, lr:3.96e-03, fs:0.66667 (r=0.677,p=0.657),  time:21.621, tt:324.322\n",
      "Ep:15, loss:0.00076, loss_test:0.10764, lr:3.96e-03, fs:0.65990 (r=0.657,p=0.663),  time:21.785, tt:348.562\n",
      "Ep:16, loss:0.00074, loss_test:0.10551, lr:3.96e-03, fs:0.71220 (r=0.737,p=0.689),  time:21.839, tt:371.265\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00072, loss_test:0.10405, lr:3.96e-03, fs:0.71287 (r=0.727,p=0.699),  time:21.883, tt:393.894\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00071, loss_test:0.10275, lr:3.96e-03, fs:0.72362 (r=0.727,p=0.720),  time:21.867, tt:415.479\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00069, loss_test:0.10071, lr:3.96e-03, fs:0.73367 (r=0.737,p=0.730),  time:21.905, tt:438.109\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00068, loss_test:0.09937, lr:3.96e-03, fs:0.72821 (r=0.717,p=0.740),  time:21.940, tt:460.750\n",
      "Ep:21, loss:0.00067, loss_test:0.09791, lr:3.96e-03, fs:0.75377 (r=0.758,p=0.750),  time:21.941, tt:482.695\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00066, loss_test:0.09630, lr:3.96e-03, fs:0.77157 (r=0.768,p=0.776),  time:21.951, tt:504.875\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00064, loss_test:0.09547, lr:3.96e-03, fs:0.77612 (r=0.788,p=0.765),  time:21.974, tt:527.380\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00064, loss_test:0.09459, lr:3.96e-03, fs:0.77949 (r=0.768,p=0.792),  time:22.014, tt:550.359\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00062, loss_test:0.09361, lr:3.96e-03, fs:0.77949 (r=0.768,p=0.792),  time:22.024, tt:572.613\n",
      "Ep:26, loss:0.00061, loss_test:0.09271, lr:3.96e-03, fs:0.78351 (r=0.768,p=0.800),  time:22.039, tt:595.059\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00060, loss_test:0.09181, lr:3.96e-03, fs:0.78125 (r=0.758,p=0.806),  time:22.052, tt:617.467\n",
      "Ep:28, loss:0.00059, loss_test:0.09067, lr:3.96e-03, fs:0.78974 (r=0.778,p=0.802),  time:22.038, tt:639.111\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00058, loss_test:0.09010, lr:3.96e-03, fs:0.79592 (r=0.788,p=0.804),  time:22.057, tt:661.698\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00057, loss_test:0.08935, lr:3.96e-03, fs:0.80412 (r=0.788,p=0.821),  time:22.069, tt:684.146\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00056, loss_test:0.08889, lr:3.96e-03, fs:0.79167 (r=0.768,p=0.817),  time:22.055, tt:705.751\n",
      "Ep:32, loss:0.00055, loss_test:0.08782, lr:3.96e-03, fs:0.81250 (r=0.788,p=0.839),  time:22.075, tt:728.488\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00054, loss_test:0.08751, lr:3.96e-03, fs:0.80214 (r=0.758,p=0.852),  time:22.121, tt:752.115\n",
      "Ep:34, loss:0.00053, loss_test:0.08697, lr:3.96e-03, fs:0.80423 (r=0.768,p=0.844),  time:22.122, tt:774.274\n",
      "Ep:35, loss:0.00052, loss_test:0.08659, lr:3.96e-03, fs:0.80423 (r=0.768,p=0.844),  time:22.141, tt:797.072\n",
      "Ep:36, loss:0.00051, loss_test:0.08659, lr:3.96e-03, fs:0.79348 (r=0.737,p=0.859),  time:22.151, tt:819.587\n",
      "Ep:37, loss:0.00050, loss_test:0.08548, lr:3.96e-03, fs:0.80423 (r=0.768,p=0.844),  time:22.142, tt:841.384\n",
      "Ep:38, loss:0.00049, loss_test:0.08566, lr:3.96e-03, fs:0.80000 (r=0.747,p=0.860),  time:22.149, tt:863.797\n",
      "Ep:39, loss:0.00048, loss_test:0.08502, lr:3.96e-03, fs:0.80000 (r=0.747,p=0.860),  time:22.168, tt:886.724\n",
      "Ep:40, loss:0.00047, loss_test:0.08488, lr:3.96e-03, fs:0.80435 (r=0.747,p=0.871),  time:22.176, tt:909.207\n",
      "Ep:41, loss:0.00047, loss_test:0.08420, lr:3.96e-03, fs:0.80000 (r=0.747,p=0.860),  time:22.186, tt:931.826\n",
      "Ep:42, loss:0.00046, loss_test:0.08437, lr:3.96e-03, fs:0.78652 (r=0.707,p=0.886),  time:22.192, tt:954.276\n",
      "Ep:43, loss:0.00045, loss_test:0.08310, lr:3.96e-03, fs:0.81283 (r=0.768,p=0.864),  time:22.206, tt:977.052\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00044, loss_test:0.08370, lr:3.96e-03, fs:0.77714 (r=0.687,p=0.895),  time:22.221, tt:999.953\n",
      "Ep:45, loss:0.00043, loss_test:0.08228, lr:3.96e-03, fs:0.81481 (r=0.778,p=0.856),  time:22.239, tt:1022.991\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00042, loss_test:0.08342, lr:3.96e-03, fs:0.76744 (r=0.667,p=0.904),  time:22.249, tt:1045.682\n",
      "Ep:47, loss:0.00041, loss_test:0.08208, lr:3.96e-03, fs:0.79348 (r=0.737,p=0.859),  time:22.255, tt:1068.229\n",
      "Ep:48, loss:0.00040, loss_test:0.08175, lr:3.96e-03, fs:0.79775 (r=0.717,p=0.899),  time:22.267, tt:1091.072\n",
      "Ep:49, loss:0.00040, loss_test:0.08099, lr:3.96e-03, fs:0.79558 (r=0.727,p=0.878),  time:22.258, tt:1112.904\n",
      "Ep:50, loss:0.00039, loss_test:0.08154, lr:3.96e-03, fs:0.79096 (r=0.707,p=0.897),  time:22.273, tt:1135.944\n",
      "Ep:51, loss:0.00038, loss_test:0.07976, lr:3.96e-03, fs:0.80220 (r=0.737,p=0.880),  time:22.272, tt:1158.156\n",
      "Ep:52, loss:0.00038, loss_test:0.08076, lr:3.96e-03, fs:0.78409 (r=0.697,p=0.896),  time:22.269, tt:1180.269\n",
      "Ep:53, loss:0.00037, loss_test:0.07956, lr:3.96e-03, fs:0.79330 (r=0.717,p=0.887),  time:22.288, tt:1203.540\n",
      "Ep:54, loss:0.00036, loss_test:0.07947, lr:3.96e-03, fs:0.79330 (r=0.717,p=0.887),  time:22.293, tt:1226.130\n",
      "Ep:55, loss:0.00036, loss_test:0.07913, lr:3.96e-03, fs:0.76571 (r=0.677,p=0.882),  time:22.306, tt:1249.162\n",
      "Ep:56, loss:0.00035, loss_test:0.07823, lr:3.96e-03, fs:0.80000 (r=0.727,p=0.889),  time:22.306, tt:1271.435\n",
      "Ep:57, loss:0.00034, loss_test:0.07800, lr:3.92e-03, fs:0.79330 (r=0.717,p=0.887),  time:22.310, tt:1293.988\n",
      "Ep:58, loss:0.00033, loss_test:0.07862, lr:3.88e-03, fs:0.75862 (r=0.667,p=0.880),  time:22.303, tt:1315.885\n",
      "Ep:59, loss:0.00033, loss_test:0.07717, lr:3.84e-03, fs:0.80000 (r=0.727,p=0.889),  time:22.312, tt:1338.724\n",
      "Ep:60, loss:0.00032, loss_test:0.07852, lr:3.80e-03, fs:0.74556 (r=0.636,p=0.900),  time:22.321, tt:1361.575\n",
      "Ep:61, loss:0.00032, loss_test:0.07622, lr:3.77e-03, fs:0.79781 (r=0.737,p=0.869),  time:22.321, tt:1383.931\n",
      "Ep:62, loss:0.00031, loss_test:0.07821, lr:3.73e-03, fs:0.74556 (r=0.636,p=0.900),  time:22.326, tt:1406.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00030, loss_test:0.07666, lr:3.69e-03, fs:0.76571 (r=0.677,p=0.882),  time:22.328, tt:1429.002\n",
      "Ep:64, loss:0.00029, loss_test:0.07648, lr:3.65e-03, fs:0.77966 (r=0.697,p=0.885),  time:22.330, tt:1451.476\n",
      "Ep:65, loss:0.00029, loss_test:0.07672, lr:3.62e-03, fs:0.76301 (r=0.667,p=0.892),  time:22.340, tt:1474.461\n",
      "Ep:66, loss:0.00028, loss_test:0.07576, lr:3.58e-03, fs:0.76836 (r=0.687,p=0.872),  time:22.346, tt:1497.214\n",
      "Ep:67, loss:0.00028, loss_test:0.07624, lr:3.55e-03, fs:0.79096 (r=0.707,p=0.897),  time:22.358, tt:1520.314\n",
      "Ep:68, loss:0.00027, loss_test:0.07609, lr:3.51e-03, fs:0.75145 (r=0.657,p=0.878),  time:22.371, tt:1543.605\n",
      "Ep:69, loss:0.00027, loss_test:0.07553, lr:3.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:22.366, tt:1565.637\n",
      "Ep:70, loss:0.00027, loss_test:0.07586, lr:3.44e-03, fs:0.76136 (r=0.677,p=0.870),  time:22.376, tt:1588.677\n",
      "Ep:71, loss:0.00026, loss_test:0.07636, lr:3.41e-03, fs:0.75294 (r=0.646,p=0.901),  time:22.379, tt:1611.293\n",
      "Ep:72, loss:0.00026, loss_test:0.07441, lr:3.37e-03, fs:0.80220 (r=0.737,p=0.880),  time:22.381, tt:1633.804\n",
      "Ep:73, loss:0.00025, loss_test:0.07628, lr:3.34e-03, fs:0.75000 (r=0.636,p=0.913),  time:22.390, tt:1656.831\n",
      "Ep:74, loss:0.00025, loss_test:0.07467, lr:3.30e-03, fs:0.79121 (r=0.727,p=0.867),  time:22.398, tt:1679.881\n",
      "Ep:75, loss:0.00024, loss_test:0.07516, lr:3.27e-03, fs:0.77011 (r=0.677,p=0.893),  time:22.413, tt:1703.421\n",
      "Ep:76, loss:0.00024, loss_test:0.07460, lr:3.24e-03, fs:0.75862 (r=0.667,p=0.880),  time:22.417, tt:1726.096\n",
      "Ep:77, loss:0.00023, loss_test:0.07441, lr:3.21e-03, fs:0.78652 (r=0.707,p=0.886),  time:22.423, tt:1748.979\n",
      "Ep:78, loss:0.00023, loss_test:0.07566, lr:3.17e-03, fs:0.75000 (r=0.636,p=0.913),  time:22.426, tt:1771.634\n",
      "Ep:79, loss:0.00023, loss_test:0.07429, lr:3.14e-03, fs:0.78889 (r=0.717,p=0.877),  time:22.431, tt:1794.520\n",
      "Ep:80, loss:0.00023, loss_test:0.07427, lr:3.11e-03, fs:0.75145 (r=0.657,p=0.878),  time:22.435, tt:1817.249\n",
      "Ep:81, loss:0.00022, loss_test:0.07437, lr:3.08e-03, fs:0.77011 (r=0.677,p=0.893),  time:22.438, tt:1839.889\n",
      "Ep:82, loss:0.00022, loss_test:0.07345, lr:3.05e-03, fs:0.77778 (r=0.707,p=0.864),  time:22.446, tt:1863.027\n",
      "Ep:83, loss:0.00021, loss_test:0.07444, lr:3.02e-03, fs:0.77273 (r=0.687,p=0.883),  time:22.444, tt:1885.280\n",
      "Ep:84, loss:0.00021, loss_test:0.07392, lr:2.99e-03, fs:0.76023 (r=0.657,p=0.903),  time:22.444, tt:1907.753\n",
      "Ep:85, loss:0.00021, loss_test:0.07280, lr:2.96e-03, fs:0.78689 (r=0.727,p=0.857),  time:22.444, tt:1930.152\n",
      "Ep:86, loss:0.00021, loss_test:0.07493, lr:2.93e-03, fs:0.74699 (r=0.626,p=0.925),  time:22.443, tt:1952.539\n",
      "Ep:87, loss:0.00021, loss_test:0.07287, lr:2.90e-03, fs:0.77348 (r=0.707,p=0.854),  time:22.446, tt:1975.274\n",
      "Ep:88, loss:0.00020, loss_test:0.07400, lr:2.87e-03, fs:0.74699 (r=0.626,p=0.925),  time:22.458, tt:1998.757\n",
      "Ep:89, loss:0.00020, loss_test:0.07298, lr:2.84e-03, fs:0.78212 (r=0.707,p=0.875),  time:22.457, tt:2021.106\n",
      "Ep:90, loss:0.00019, loss_test:0.07307, lr:2.81e-03, fs:0.75862 (r=0.667,p=0.880),  time:22.460, tt:2043.835\n",
      "Ep:91, loss:0.00019, loss_test:0.07296, lr:2.79e-03, fs:0.76301 (r=0.667,p=0.892),  time:22.466, tt:2066.871\n",
      "Ep:92, loss:0.00019, loss_test:0.07286, lr:2.76e-03, fs:0.75706 (r=0.677,p=0.859),  time:22.476, tt:2090.298\n",
      "Ep:93, loss:0.00019, loss_test:0.07283, lr:2.73e-03, fs:0.77966 (r=0.697,p=0.885),  time:22.480, tt:2113.154\n",
      "Ep:94, loss:0.00018, loss_test:0.07278, lr:2.70e-03, fs:0.75581 (r=0.657,p=0.890),  time:22.488, tt:2136.330\n",
      "Ep:95, loss:0.00018, loss_test:0.07286, lr:2.68e-03, fs:0.76744 (r=0.667,p=0.904),  time:22.499, tt:2159.937\n",
      "Ep:96, loss:0.00018, loss_test:0.07293, lr:2.65e-03, fs:0.76023 (r=0.657,p=0.903),  time:22.510, tt:2183.435\n",
      "Ep:97, loss:0.00018, loss_test:0.07273, lr:2.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:22.508, tt:2205.767\n",
      "Ep:98, loss:0.00018, loss_test:0.07372, lr:2.60e-03, fs:0.74251 (r=0.626,p=0.912),  time:22.510, tt:2228.479\n",
      "Ep:99, loss:0.00017, loss_test:0.07259, lr:2.57e-03, fs:0.74713 (r=0.657,p=0.867),  time:22.511, tt:2251.102\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=512 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14625, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:8.708, tt:8.708\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14598, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:9.531, tt:19.063\n",
      "Ep:2, loss:0.00028, loss_test:0.14554, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:9.930, tt:29.790\n",
      "Ep:3, loss:0.00028, loss_test:0.14492, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:10.172, tt:40.689\n",
      "Ep:4, loss:0.00028, loss_test:0.14402, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:10.239, tt:51.196\n",
      "Ep:5, loss:0.00027, loss_test:0.14274, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:10.364, tt:62.183\n",
      "Ep:6, loss:0.00027, loss_test:0.14087, lr:8.00e-03, fs:0.66212 (r=0.980,p=0.500),  time:10.442, tt:73.091\n",
      "Ep:7, loss:0.00026, loss_test:0.13807, lr:8.00e-03, fs:0.64336 (r=0.929,p=0.492),  time:10.486, tt:83.890\n",
      "Ep:8, loss:0.00025, loss_test:0.13403, lr:8.00e-03, fs:0.65693 (r=0.909,p=0.514),  time:10.538, tt:94.842\n",
      "Ep:9, loss:0.00024, loss_test:0.12875, lr:8.00e-03, fs:0.62698 (r=0.798,p=0.516),  time:10.579, tt:105.794\n",
      "Ep:10, loss:0.00023, loss_test:0.12443, lr:8.00e-03, fs:0.64000 (r=0.727,p=0.571),  time:10.582, tt:116.407\n",
      "Ep:11, loss:0.00023, loss_test:0.12154, lr:8.00e-03, fs:0.66667 (r=0.697,p=0.639),  time:10.610, tt:127.318\n",
      "Ep:12, loss:0.00022, loss_test:0.11975, lr:7.92e-03, fs:0.65049 (r=0.677,p=0.626),  time:10.642, tt:138.346\n",
      "Ep:13, loss:0.00022, loss_test:0.11832, lr:7.84e-03, fs:0.66667 (r=0.707,p=0.631),  time:10.721, tt:150.098\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.11738, lr:7.84e-03, fs:0.67556 (r=0.768,p=0.603),  time:10.985, tt:164.776\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.11609, lr:7.84e-03, fs:0.68996 (r=0.798,p=0.608),  time:11.221, tt:179.530\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.11409, lr:7.84e-03, fs:0.67873 (r=0.758,p=0.615),  time:11.819, tt:200.923\n",
      "Ep:17, loss:0.00020, loss_test:0.11218, lr:7.84e-03, fs:0.68837 (r=0.747,p=0.638),  time:12.320, tt:221.767\n",
      "Ep:18, loss:0.00020, loss_test:0.11041, lr:7.84e-03, fs:0.68868 (r=0.737,p=0.646),  time:12.818, tt:243.550\n",
      "Ep:19, loss:0.00019, loss_test:0.10899, lr:7.84e-03, fs:0.69524 (r=0.737,p=0.658),  time:13.222, tt:264.445\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.10777, lr:7.84e-03, fs:0.67943 (r=0.717,p=0.645),  time:13.655, tt:286.760\n",
      "Ep:21, loss:0.00019, loss_test:0.10649, lr:7.84e-03, fs:0.68868 (r=0.737,p=0.646),  time:14.087, tt:309.904\n",
      "Ep:22, loss:0.00018, loss_test:0.10516, lr:7.84e-03, fs:0.68246 (r=0.727,p=0.643),  time:14.529, tt:334.171\n",
      "Ep:23, loss:0.00018, loss_test:0.10355, lr:7.84e-03, fs:0.69231 (r=0.727,p=0.661),  time:14.918, tt:358.021\n",
      "Ep:24, loss:0.00018, loss_test:0.10198, lr:7.84e-03, fs:0.70874 (r=0.737,p=0.682),  time:15.454, tt:386.353\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.10096, lr:7.84e-03, fs:0.70874 (r=0.737,p=0.682),  time:15.895, tt:413.262\n",
      "Ep:26, loss:0.00017, loss_test:0.09995, lr:7.84e-03, fs:0.72549 (r=0.747,p=0.705),  time:16.375, tt:442.121\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.09878, lr:7.84e-03, fs:0.70707 (r=0.707,p=0.707),  time:16.834, tt:471.338\n",
      "Ep:28, loss:0.00016, loss_test:0.09781, lr:7.84e-03, fs:0.72081 (r=0.717,p=0.724),  time:17.242, tt:500.017\n",
      "Ep:29, loss:0.00016, loss_test:0.09686, lr:7.84e-03, fs:0.72821 (r=0.717,p=0.740),  time:17.625, tt:528.740\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.09588, lr:7.84e-03, fs:0.73575 (r=0.717,p=0.755),  time:17.975, tt:557.229\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.09497, lr:7.84e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.281, tt:584.997\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.09424, lr:7.84e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.616, tt:614.314\n",
      "Ep:33, loss:0.00015, loss_test:0.09362, lr:7.84e-03, fs:0.75269 (r=0.707,p=0.805),  time:18.927, tt:643.515\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.09298, lr:7.84e-03, fs:0.74595 (r=0.697,p=0.802),  time:19.191, tt:671.677\n",
      "Ep:35, loss:0.00015, loss_test:0.09216, lr:7.84e-03, fs:0.74866 (r=0.707,p=0.795),  time:19.454, tt:700.333\n",
      "Ep:36, loss:0.00014, loss_test:0.09138, lr:7.84e-03, fs:0.75410 (r=0.697,p=0.821),  time:19.668, tt:727.720\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00014, loss_test:0.09072, lr:7.84e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.910, tt:756.586\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00014, loss_test:0.09003, lr:7.84e-03, fs:0.75676 (r=0.707,p=0.814),  time:20.172, tt:786.718\n",
      "Ep:39, loss:0.00014, loss_test:0.08949, lr:7.84e-03, fs:0.75824 (r=0.697,p=0.831),  time:20.337, tt:813.470\n",
      "Ep:40, loss:0.00013, loss_test:0.08926, lr:7.84e-03, fs:0.76503 (r=0.707,p=0.833),  time:20.546, tt:842.384\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00013, loss_test:0.08881, lr:7.84e-03, fs:0.75676 (r=0.707,p=0.814),  time:20.746, tt:871.351\n",
      "Ep:42, loss:0.00013, loss_test:0.08825, lr:7.84e-03, fs:0.75824 (r=0.697,p=0.831),  time:20.944, tt:900.570\n",
      "Ep:43, loss:0.00013, loss_test:0.08754, lr:7.84e-03, fs:0.76923 (r=0.707,p=0.843),  time:21.131, tt:929.754\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00013, loss_test:0.08727, lr:7.84e-03, fs:0.77095 (r=0.697,p=0.863),  time:21.306, tt:958.754\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00012, loss_test:0.08658, lr:7.84e-03, fs:0.76836 (r=0.687,p=0.872),  time:21.453, tt:986.835\n",
      "Ep:46, loss:0.00012, loss_test:0.08576, lr:7.84e-03, fs:0.76243 (r=0.697,p=0.841),  time:21.611, tt:1015.698\n",
      "Ep:47, loss:0.00012, loss_test:0.08537, lr:7.84e-03, fs:0.76667 (r=0.697,p=0.852),  time:21.755, tt:1044.261\n",
      "Ep:48, loss:0.00012, loss_test:0.08539, lr:7.84e-03, fs:0.76836 (r=0.687,p=0.872),  time:21.884, tt:1072.312\n",
      "Ep:49, loss:0.00011, loss_test:0.08452, lr:7.84e-03, fs:0.76404 (r=0.687,p=0.861),  time:22.030, tt:1101.478\n",
      "Ep:50, loss:0.00011, loss_test:0.08349, lr:7.84e-03, fs:0.76923 (r=0.707,p=0.843),  time:22.197, tt:1132.022\n",
      "Ep:51, loss:0.00011, loss_test:0.08397, lr:7.84e-03, fs:0.76136 (r=0.677,p=0.870),  time:22.332, tt:1161.273\n",
      "Ep:52, loss:0.00011, loss_test:0.08407, lr:7.84e-03, fs:0.74419 (r=0.646,p=0.877),  time:22.422, tt:1188.388\n",
      "Ep:53, loss:0.00010, loss_test:0.08270, lr:7.84e-03, fs:0.76243 (r=0.697,p=0.841),  time:22.545, tt:1217.456\n",
      "Ep:54, loss:0.00010, loss_test:0.08299, lr:7.84e-03, fs:0.73988 (r=0.646,p=0.865),  time:22.670, tt:1246.876\n",
      "Ep:55, loss:0.00010, loss_test:0.08342, lr:7.84e-03, fs:0.73988 (r=0.646,p=0.865),  time:22.771, tt:1275.192\n",
      "Ep:56, loss:0.00010, loss_test:0.08185, lr:7.76e-03, fs:0.77596 (r=0.717,p=0.845),  time:22.873, tt:1303.756\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00010, loss_test:0.08266, lr:7.76e-03, fs:0.74419 (r=0.646,p=0.877),  time:22.962, tt:1331.797\n",
      "Ep:58, loss:0.00009, loss_test:0.08214, lr:7.76e-03, fs:0.75281 (r=0.677,p=0.848),  time:23.070, tt:1361.105\n",
      "Ep:59, loss:0.00009, loss_test:0.08120, lr:7.76e-03, fs:0.76571 (r=0.677,p=0.882),  time:23.164, tt:1389.833\n",
      "Ep:60, loss:0.00009, loss_test:0.08162, lr:7.76e-03, fs:0.73988 (r=0.646,p=0.865),  time:23.281, tt:1420.132\n",
      "Ep:61, loss:0.00009, loss_test:0.08099, lr:7.76e-03, fs:0.74286 (r=0.657,p=0.855),  time:23.372, tt:1449.064\n",
      "Ep:62, loss:0.00009, loss_test:0.07960, lr:7.76e-03, fs:0.76136 (r=0.677,p=0.870),  time:23.455, tt:1477.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00008, loss_test:0.08120, lr:7.76e-03, fs:0.74713 (r=0.657,p=0.867),  time:23.558, tt:1507.744\n",
      "Ep:64, loss:0.00008, loss_test:0.07944, lr:7.76e-03, fs:0.75862 (r=0.667,p=0.880),  time:23.650, tt:1537.219\n",
      "Ep:65, loss:0.00008, loss_test:0.07943, lr:7.76e-03, fs:0.77011 (r=0.677,p=0.893),  time:23.720, tt:1565.499\n",
      "Ep:66, loss:0.00008, loss_test:0.08008, lr:7.76e-03, fs:0.76301 (r=0.667,p=0.892),  time:23.790, tt:1593.942\n",
      "Ep:67, loss:0.00008, loss_test:0.07891, lr:7.76e-03, fs:0.76301 (r=0.667,p=0.892),  time:23.850, tt:1621.829\n",
      "Ep:68, loss:0.00008, loss_test:0.07920, lr:7.68e-03, fs:0.75581 (r=0.657,p=0.890),  time:23.927, tt:1650.953\n",
      "Ep:69, loss:0.00008, loss_test:0.07990, lr:7.61e-03, fs:0.73810 (r=0.626,p=0.899),  time:24.011, tt:1680.767\n",
      "Ep:70, loss:0.00007, loss_test:0.07794, lr:7.53e-03, fs:0.77528 (r=0.697,p=0.873),  time:24.095, tt:1710.754\n",
      "Ep:71, loss:0.00007, loss_test:0.07925, lr:7.46e-03, fs:0.74556 (r=0.636,p=0.900),  time:24.160, tt:1739.506\n",
      "Ep:72, loss:0.00007, loss_test:0.07891, lr:7.38e-03, fs:0.73810 (r=0.626,p=0.899),  time:24.217, tt:1767.847\n",
      "Ep:73, loss:0.00007, loss_test:0.07691, lr:7.31e-03, fs:0.76136 (r=0.677,p=0.870),  time:24.280, tt:1796.690\n",
      "Ep:74, loss:0.00007, loss_test:0.07967, lr:7.24e-03, fs:0.72289 (r=0.606,p=0.896),  time:24.358, tt:1826.872\n",
      "Ep:75, loss:0.00007, loss_test:0.07858, lr:7.16e-03, fs:0.73810 (r=0.626,p=0.899),  time:24.409, tt:1855.071\n",
      "Ep:76, loss:0.00007, loss_test:0.07609, lr:7.09e-03, fs:0.75429 (r=0.667,p=0.868),  time:24.482, tt:1885.143\n",
      "Ep:77, loss:0.00007, loss_test:0.07945, lr:7.02e-03, fs:0.72289 (r=0.606,p=0.896),  time:24.524, tt:1912.910\n",
      "Ep:78, loss:0.00006, loss_test:0.07748, lr:6.95e-03, fs:0.76023 (r=0.657,p=0.903),  time:24.583, tt:1942.044\n",
      "Ep:79, loss:0.00006, loss_test:0.07609, lr:6.88e-03, fs:0.75740 (r=0.646,p=0.914),  time:24.632, tt:1970.588\n",
      "Ep:80, loss:0.00006, loss_test:0.07817, lr:6.81e-03, fs:0.74419 (r=0.646,p=0.877),  time:24.688, tt:1999.715\n",
      "Ep:81, loss:0.00006, loss_test:0.07705, lr:6.74e-03, fs:0.75294 (r=0.646,p=0.901),  time:24.726, tt:2027.570\n",
      "Ep:82, loss:0.00006, loss_test:0.07648, lr:6.68e-03, fs:0.74419 (r=0.646,p=0.877),  time:24.771, tt:2055.961\n",
      "Ep:83, loss:0.00006, loss_test:0.07830, lr:6.61e-03, fs:0.72941 (r=0.626,p=0.873),  time:24.822, tt:2085.024\n",
      "Ep:84, loss:0.00006, loss_test:0.07623, lr:6.54e-03, fs:0.74556 (r=0.636,p=0.900),  time:24.885, tt:2115.186\n",
      "Ep:85, loss:0.00006, loss_test:0.07594, lr:6.48e-03, fs:0.74118 (r=0.636,p=0.887),  time:24.942, tt:2145.021\n",
      "Ep:86, loss:0.00006, loss_test:0.07793, lr:6.41e-03, fs:0.73373 (r=0.626,p=0.886),  time:24.978, tt:2173.074\n",
      "Ep:87, loss:0.00006, loss_test:0.07497, lr:6.35e-03, fs:0.74419 (r=0.646,p=0.877),  time:25.012, tt:2201.032\n",
      "Ep:88, loss:0.00006, loss_test:0.07597, lr:6.29e-03, fs:0.74556 (r=0.636,p=0.900),  time:25.053, tt:2229.687\n",
      "Ep:89, loss:0.00005, loss_test:0.07709, lr:6.22e-03, fs:0.73373 (r=0.626,p=0.886),  time:25.101, tt:2259.121\n",
      "Ep:90, loss:0.00005, loss_test:0.07511, lr:6.16e-03, fs:0.74854 (r=0.646,p=0.889),  time:25.159, tt:2289.481\n",
      "Ep:91, loss:0.00005, loss_test:0.07629, lr:6.10e-03, fs:0.75000 (r=0.636,p=0.913),  time:25.190, tt:2317.516\n",
      "Ep:92, loss:0.00005, loss_test:0.07612, lr:6.04e-03, fs:0.75294 (r=0.646,p=0.901),  time:25.224, tt:2345.811\n",
      "Ep:93, loss:0.00005, loss_test:0.07465, lr:5.98e-03, fs:0.74419 (r=0.646,p=0.877),  time:25.270, tt:2375.414\n",
      "Ep:94, loss:0.00005, loss_test:0.07628, lr:5.92e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.313, tt:2404.780\n",
      "Ep:95, loss:0.00005, loss_test:0.07581, lr:5.86e-03, fs:0.74118 (r=0.636,p=0.887),  time:25.348, tt:2433.392\n",
      "Ep:96, loss:0.00005, loss_test:0.07489, lr:5.80e-03, fs:0.74118 (r=0.636,p=0.887),  time:25.376, tt:2461.515\n",
      "Ep:97, loss:0.00005, loss_test:0.07596, lr:5.74e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.405, tt:2489.662\n",
      "Ep:98, loss:0.00005, loss_test:0.07474, lr:5.68e-03, fs:0.73684 (r=0.636,p=0.875),  time:25.442, tt:2518.758\n",
      "Ep:99, loss:0.00005, loss_test:0.07476, lr:5.63e-03, fs:0.73373 (r=0.626,p=0.886),  time:25.475, tt:2547.529\n",
      "Ep:100, loss:0.00005, loss_test:0.07488, lr:5.57e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.521, tt:2577.620\n",
      "Ep:101, loss:0.00005, loss_test:0.07408, lr:5.52e-03, fs:0.73684 (r=0.636,p=0.875),  time:25.564, tt:2607.515\n",
      "Ep:102, loss:0.00005, loss_test:0.07472, lr:5.46e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.590, tt:2635.753\n",
      "Ep:103, loss:0.00005, loss_test:0.07403, lr:5.41e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.620, tt:2664.504\n",
      "Ep:104, loss:0.00004, loss_test:0.07403, lr:5.35e-03, fs:0.73373 (r=0.626,p=0.886),  time:25.641, tt:2692.308\n",
      "Ep:105, loss:0.00004, loss_test:0.07478, lr:5.30e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.678, tt:2721.856\n",
      "Ep:106, loss:0.00004, loss_test:0.07365, lr:5.25e-03, fs:0.74556 (r=0.636,p=0.900),  time:25.714, tt:2751.370\n",
      "Ep:107, loss:0.00004, loss_test:0.07377, lr:5.19e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.742, tt:2780.109\n",
      "Ep:108, loss:0.00004, loss_test:0.07399, lr:5.14e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.770, tt:2808.912\n",
      "Ep:109, loss:0.00004, loss_test:0.07379, lr:5.09e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.821, tt:2840.358\n",
      "Ep:110, loss:0.00004, loss_test:0.07430, lr:5.04e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.864, tt:2870.920\n",
      "Ep:111, loss:0.00004, loss_test:0.07305, lr:4.99e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.904, tt:2901.263\n",
      "Ep:112, loss:0.00004, loss_test:0.07379, lr:4.94e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.939, tt:2931.097\n",
      "Ep:113, loss:0.00004, loss_test:0.07361, lr:4.89e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.958, tt:2959.218\n",
      "Ep:114, loss:0.00004, loss_test:0.07340, lr:4.84e-03, fs:0.73810 (r=0.626,p=0.899),  time:25.990, tt:2988.866\n",
      "Ep:115, loss:0.00004, loss_test:0.07314, lr:4.79e-03, fs:0.73810 (r=0.626,p=0.899),  time:26.017, tt:3018.028\n",
      "Ep:116, loss:0.00004, loss_test:0.07321, lr:4.74e-03, fs:0.73810 (r=0.626,p=0.899),  time:26.062, tt:3049.267\n",
      "Ep:117, loss:0.00004, loss_test:0.07337, lr:4.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.093, tt:3079.022\n",
      "Ep:118, loss:0.00004, loss_test:0.07301, lr:4.65e-03, fs:0.73810 (r=0.626,p=0.899),  time:26.106, tt:3106.575\n",
      "Ep:119, loss:0.00004, loss_test:0.07309, lr:4.60e-03, fs:0.73810 (r=0.626,p=0.899),  time:26.132, tt:3135.831\n",
      "Ep:120, loss:0.00004, loss_test:0.07328, lr:4.56e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.160, tt:3165.346\n",
      "Ep:121, loss:0.00004, loss_test:0.07338, lr:4.51e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.188, tt:3194.886\n",
      "Ep:122, loss:0.00004, loss_test:0.07292, lr:4.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:26.232, tt:3226.581\n",
      "Ep:123, loss:0.00004, loss_test:0.07315, lr:4.42e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.248, tt:3254.775\n",
      "Ep:124, loss:0.00004, loss_test:0.07312, lr:4.38e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.254, tt:3281.699\n",
      "Ep:125, loss:0.00004, loss_test:0.07275, lr:4.33e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.267, tt:3309.590\n",
      "Ep:126, loss:0.00004, loss_test:0.07320, lr:4.29e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.280, tt:3337.553\n",
      "Ep:127, loss:0.00004, loss_test:0.07300, lr:4.25e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.294, tt:3365.586\n",
      "Ep:128, loss:0.00004, loss_test:0.07274, lr:4.20e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.321, tt:3395.350\n",
      "Ep:129, loss:0.00004, loss_test:0.07309, lr:4.16e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.334, tt:3423.469\n",
      "Ep:130, loss:0.00004, loss_test:0.07272, lr:4.12e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.345, tt:3451.193\n",
      "Ep:131, loss:0.00004, loss_test:0.07248, lr:4.08e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.373, tt:3481.213\n",
      "Ep:132, loss:0.00004, loss_test:0.07288, lr:4.04e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.409, tt:3512.357\n",
      "Ep:133, loss:0.00003, loss_test:0.07277, lr:4.00e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.424, tt:3540.849\n",
      "Ep:134, loss:0.00003, loss_test:0.07282, lr:3.96e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.443, tt:3569.777\n",
      "Ep:135, loss:0.00003, loss_test:0.07314, lr:3.92e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.461, tt:3598.724\n",
      "Ep:136, loss:0.00003, loss_test:0.07276, lr:3.88e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.478, tt:3627.483\n",
      "Ep:137, loss:0.00003, loss_test:0.07277, lr:3.84e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.514, tt:3658.978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00003, loss_test:0.07322, lr:3.80e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.544, tt:3689.668\n",
      "Ep:139, loss:0.00003, loss_test:0.07268, lr:3.76e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.554, tt:3717.604\n",
      "Ep:140, loss:0.00003, loss_test:0.07281, lr:3.73e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.568, tt:3746.115\n",
      "Ep:141, loss:0.00003, loss_test:0.07295, lr:3.69e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.581, tt:3774.562\n",
      "Ep:142, loss:0.00003, loss_test:0.07254, lr:3.65e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.622, tt:3806.890\n",
      "Ep:143, loss:0.00003, loss_test:0.07283, lr:3.62e-03, fs:0.72289 (r=0.606,p=0.896),  time:26.634, tt:3835.237\n",
      "Ep:144, loss:0.00003, loss_test:0.07265, lr:3.58e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.648, tt:3863.925\n",
      "Ep:145, loss:0.00003, loss_test:0.07308, lr:3.54e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.662, tt:3892.629\n",
      "Ep:146, loss:0.00003, loss_test:0.07306, lr:3.51e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.680, tt:3922.017\n",
      "Ep:147, loss:0.00003, loss_test:0.07258, lr:3.47e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.707, tt:3952.680\n",
      "Ep:148, loss:0.00003, loss_test:0.07265, lr:3.44e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.732, tt:3983.055\n",
      "Ep:149, loss:0.00003, loss_test:0.07296, lr:3.40e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.741, tt:4011.174\n",
      "Ep:150, loss:0.00003, loss_test:0.07286, lr:3.37e-03, fs:0.72619 (r=0.616,p=0.884),  time:26.740, tt:4037.743\n",
      "Ep:151, loss:0.00003, loss_test:0.07271, lr:3.34e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.753, tt:4066.456\n",
      "Ep:152, loss:0.00003, loss_test:0.07307, lr:3.30e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.767, tt:4095.354\n",
      "Ep:153, loss:0.00003, loss_test:0.07300, lr:3.27e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.793, tt:4126.145\n",
      "Ep:154, loss:0.00003, loss_test:0.07295, lr:3.24e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.810, tt:4155.552\n",
      "Ep:155, loss:0.00003, loss_test:0.07303, lr:3.21e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.824, tt:4184.588\n",
      "Ep:156, loss:0.00003, loss_test:0.07340, lr:3.17e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.834, tt:4212.923\n",
      "Ep:157, loss:0.00003, loss_test:0.07324, lr:3.14e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.842, tt:4240.967\n",
      "Ep:158, loss:0.00003, loss_test:0.07282, lr:3.11e-03, fs:0.72619 (r=0.616,p=0.884),  time:26.862, tt:4271.005\n",
      "Ep:159, loss:0.00003, loss_test:0.07357, lr:3.08e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.880, tt:4300.873\n",
      "Ep:160, loss:0.00003, loss_test:0.07334, lr:3.05e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.888, tt:4328.960\n",
      "Ep:161, loss:0.00003, loss_test:0.07289, lr:3.02e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.904, tt:4358.505\n",
      "Ep:162, loss:0.00003, loss_test:0.07361, lr:2.99e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.918, tt:4387.607\n",
      "Ep:163, loss:0.00003, loss_test:0.07359, lr:2.96e-03, fs:0.72619 (r=0.616,p=0.884),  time:26.931, tt:4416.760\n",
      "Ep:164, loss:0.00003, loss_test:0.07287, lr:2.93e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.947, tt:4446.220\n",
      "Ep:165, loss:0.00003, loss_test:0.07319, lr:2.90e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.955, tt:4474.479\n",
      "Ep:166, loss:0.00003, loss_test:0.07380, lr:2.87e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.964, tt:4503.039\n",
      "Ep:167, loss:0.00003, loss_test:0.07343, lr:2.84e-03, fs:0.72941 (r=0.626,p=0.873),  time:26.978, tt:4532.249\n",
      "Ep:168, loss:0.00003, loss_test:0.07304, lr:2.81e-03, fs:0.73054 (r=0.616,p=0.897),  time:26.990, tt:4561.245\n",
      "Ep:169, loss:0.00003, loss_test:0.07317, lr:2.78e-03, fs:0.73054 (r=0.616,p=0.897),  time:27.007, tt:4591.212\n",
      "Ep:170, loss:0.00003, loss_test:0.07365, lr:2.76e-03, fs:0.72619 (r=0.616,p=0.884),  time:27.016, tt:4619.783\n",
      "Ep:171, loss:0.00003, loss_test:0.07341, lr:2.73e-03, fs:0.72941 (r=0.626,p=0.873),  time:27.028, tt:4648.761\n",
      "Ep:172, loss:0.00003, loss_test:0.07313, lr:2.70e-03, fs:0.72619 (r=0.616,p=0.884),  time:27.037, tt:4677.480\n",
      "Ep:173, loss:0.00003, loss_test:0.07373, lr:2.68e-03, fs:0.72289 (r=0.606,p=0.896),  time:27.048, tt:4706.428\n",
      "Ep:174, loss:0.00003, loss_test:0.07377, lr:2.65e-03, fs:0.73054 (r=0.616,p=0.897),  time:27.074, tt:4738.018\n",
      "Ep:175, loss:0.00003, loss_test:0.07314, lr:2.62e-03, fs:0.72941 (r=0.626,p=0.873),  time:27.071, tt:4764.457\n",
      "Ep:176, loss:0.00003, loss_test:0.07332, lr:2.60e-03, fs:0.73054 (r=0.616,p=0.897),  time:27.077, tt:4792.616\n",
      "Ep:177, loss:0.00003, loss_test:0.07390, lr:2.57e-03, fs:0.72289 (r=0.606,p=0.896),  time:27.085, tt:4821.103\n",
      "Ep:178, loss:0.00003, loss_test:0.07352, lr:2.54e-03, fs:0.72619 (r=0.616,p=0.884),  time:27.089, tt:4848.874\n",
      "Ep:179, loss:0.00003, loss_test:0.07298, lr:2.52e-03, fs:0.72189 (r=0.616,p=0.871),  time:27.085, tt:4875.333\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"5-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14297, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.725, tt:9.725\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14198, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.720, tt:21.441\n",
      "Ep:2, loss:0.00028, loss_test:0.14022, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:12.110, tt:36.329\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13741, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:14.542, tt:58.166\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13311, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:16.833, tt:84.164\n",
      "Ep:5, loss:0.00025, loss_test:0.12890, lr:1.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:19.177, tt:115.060\n",
      "Ep:6, loss:0.00024, loss_test:0.12565, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:20.779, tt:145.456\n",
      "Ep:7, loss:0.00023, loss_test:0.12370, lr:1.00e-02, fs:0.59048 (r=0.626,p=0.559),  time:22.085, tt:176.679\n",
      "Ep:8, loss:0.00023, loss_test:0.12223, lr:1.00e-02, fs:0.61692 (r=0.626,p=0.608),  time:23.012, tt:207.110\n",
      "Ep:9, loss:0.00022, loss_test:0.12050, lr:1.00e-02, fs:0.62264 (r=0.667,p=0.584),  time:23.679, tt:236.794\n",
      "Ep:10, loss:0.00021, loss_test:0.11852, lr:1.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:24.441, tt:268.850\n",
      "Ep:11, loss:0.00021, loss_test:0.11503, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:25.045, tt:300.546\n",
      "Ep:12, loss:0.00020, loss_test:0.11165, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:25.629, tt:333.182\n",
      "Ep:13, loss:0.00020, loss_test:0.10966, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:26.001, tt:364.010\n",
      "Ep:14, loss:0.00019, loss_test:0.10819, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:26.338, tt:395.073\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10765, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:26.622, tt:425.950\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10685, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:26.931, tt:457.831\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10590, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:27.137, tt:488.461\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10496, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:27.311, tt:518.917\n",
      "Ep:19, loss:0.00017, loss_test:0.10396, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:27.512, tt:550.233\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.10317, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:27.762, tt:583.011\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.10225, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:27.937, tt:614.617\n",
      "Ep:22, loss:0.00016, loss_test:0.10141, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:28.056, tt:645.280\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.10065, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:28.159, tt:675.817\n",
      "Ep:24, loss:0.00016, loss_test:0.10001, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:28.258, tt:706.441\n",
      "Ep:25, loss:0.00015, loss_test:0.09936, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:28.333, tt:736.657\n",
      "Ep:26, loss:0.00015, loss_test:0.09869, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:28.442, tt:767.928\n",
      "Ep:27, loss:0.00015, loss_test:0.09817, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:28.553, tt:799.471\n",
      "Ep:28, loss:0.00014, loss_test:0.09754, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:28.672, tt:831.498\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09691, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:28.797, tt:863.920\n",
      "Ep:30, loss:0.00014, loss_test:0.09639, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:28.895, tt:895.731\n",
      "Ep:31, loss:0.00013, loss_test:0.09573, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:28.970, tt:927.047\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.09507, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:29.006, tt:957.185\n",
      "Ep:33, loss:0.00013, loss_test:0.09471, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:29.088, tt:988.985\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.09456, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:29.175, tt:1021.118\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.09400, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:29.224, tt:1052.067\n",
      "Ep:36, loss:0.00012, loss_test:0.09376, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:29.288, tt:1083.654\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.09395, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:29.364, tt:1115.826\n",
      "Ep:38, loss:0.00011, loss_test:0.09313, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:29.437, tt:1148.046\n",
      "Ep:39, loss:0.00011, loss_test:0.09297, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:29.474, tt:1178.953\n",
      "Ep:40, loss:0.00011, loss_test:0.09321, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:29.525, tt:1210.512\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.09240, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:29.573, tt:1242.045\n",
      "Ep:42, loss:0.00010, loss_test:0.09235, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:29.605, tt:1273.028\n",
      "Ep:43, loss:0.00010, loss_test:0.09195, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:29.676, tt:1305.743\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.09184, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:29.729, tt:1337.820\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.09268, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:29.812, tt:1371.333\n",
      "Ep:46, loss:0.00009, loss_test:0.09203, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:29.866, tt:1403.684\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.09233, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:29.931, tt:1436.670\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.09229, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:29.953, tt:1467.699\n",
      "Ep:49, loss:0.00008, loss_test:0.09216, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:29.973, tt:1498.638\n",
      "Ep:50, loss:0.00008, loss_test:0.09227, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:30.031, tt:1531.565\n",
      "Ep:51, loss:0.00008, loss_test:0.09192, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.049, tt:1562.545\n",
      "Ep:52, loss:0.00008, loss_test:0.09113, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:30.089, tt:1594.704\n",
      "Ep:53, loss:0.00008, loss_test:0.09137, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.121, tt:1626.551\n",
      "Ep:54, loss:0.00007, loss_test:0.09061, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:30.158, tt:1658.675\n",
      "Ep:55, loss:0.00007, loss_test:0.09065, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.184, tt:1690.307\n",
      "Ep:56, loss:0.00007, loss_test:0.09106, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:30.237, tt:1723.515\n",
      "Ep:57, loss:0.00007, loss_test:0.09024, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:30.253, tt:1754.694\n",
      "Ep:58, loss:0.00007, loss_test:0.09058, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:30.272, tt:1786.033\n",
      "Ep:59, loss:0.00006, loss_test:0.08987, lr:9.90e-03, fs:0.75862 (r=0.778,p=0.740),  time:30.326, tt:1819.561\n",
      "Ep:60, loss:0.00006, loss_test:0.09118, lr:9.80e-03, fs:0.74227 (r=0.727,p=0.758),  time:30.349, tt:1851.265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.08977, lr:9.70e-03, fs:0.76617 (r=0.778,p=0.755),  time:30.342, tt:1881.223\n",
      "Ep:62, loss:0.00006, loss_test:0.09038, lr:9.61e-03, fs:0.72917 (r=0.707,p=0.753),  time:30.353, tt:1912.262\n",
      "Ep:63, loss:0.00006, loss_test:0.08942, lr:9.51e-03, fs:0.76617 (r=0.778,p=0.755),  time:30.376, tt:1944.081\n",
      "Ep:64, loss:0.00006, loss_test:0.09023, lr:9.41e-03, fs:0.71875 (r=0.697,p=0.742),  time:30.376, tt:1974.469\n",
      "Ep:65, loss:0.00006, loss_test:0.08885, lr:9.32e-03, fs:0.74227 (r=0.727,p=0.758),  time:30.381, tt:2005.160\n",
      "Ep:66, loss:0.00005, loss_test:0.08946, lr:9.23e-03, fs:0.74112 (r=0.737,p=0.745),  time:30.412, tt:2037.597\n",
      "Ep:67, loss:0.00005, loss_test:0.09027, lr:9.14e-03, fs:0.72340 (r=0.687,p=0.764),  time:30.440, tt:2069.901\n",
      "Ep:68, loss:0.00005, loss_test:0.08839, lr:9.04e-03, fs:0.74112 (r=0.737,p=0.745),  time:30.444, tt:2100.633\n",
      "Ep:69, loss:0.00005, loss_test:0.08957, lr:8.95e-03, fs:0.71204 (r=0.687,p=0.739),  time:30.437, tt:2130.620\n",
      "Ep:70, loss:0.00005, loss_test:0.09032, lr:8.86e-03, fs:0.71658 (r=0.677,p=0.761),  time:30.452, tt:2162.079\n",
      "Ep:71, loss:0.00005, loss_test:0.08813, lr:8.78e-03, fs:0.75127 (r=0.747,p=0.755),  time:30.458, tt:2192.947\n",
      "Ep:72, loss:0.00005, loss_test:0.08964, lr:8.69e-03, fs:0.70588 (r=0.667,p=0.750),  time:30.445, tt:2222.478\n",
      "Ep:73, loss:0.00005, loss_test:0.08919, lr:8.60e-03, fs:0.73958 (r=0.717,p=0.763),  time:30.428, tt:2251.637\n",
      "Ep:74, loss:0.00005, loss_test:0.08901, lr:8.51e-03, fs:0.69841 (r=0.667,p=0.733),  time:30.430, tt:2282.249\n",
      "Ep:75, loss:0.00004, loss_test:0.08822, lr:8.43e-03, fs:0.70899 (r=0.677,p=0.744),  time:30.451, tt:2314.261\n",
      "Ep:76, loss:0.00004, loss_test:0.08989, lr:8.35e-03, fs:0.70588 (r=0.667,p=0.750),  time:30.456, tt:2345.091\n",
      "Ep:77, loss:0.00004, loss_test:0.08837, lr:8.26e-03, fs:0.70213 (r=0.667,p=0.742),  time:30.453, tt:2375.372\n",
      "Ep:78, loss:0.00004, loss_test:0.08898, lr:8.18e-03, fs:0.69892 (r=0.657,p=0.747),  time:30.448, tt:2405.411\n",
      "Ep:79, loss:0.00004, loss_test:0.08842, lr:8.10e-03, fs:0.71277 (r=0.677,p=0.753),  time:30.457, tt:2436.538\n",
      "Ep:80, loss:0.00004, loss_test:0.08826, lr:8.02e-03, fs:0.70899 (r=0.677,p=0.744),  time:30.457, tt:2467.026\n",
      "Ep:81, loss:0.00004, loss_test:0.08793, lr:7.94e-03, fs:0.71958 (r=0.687,p=0.756),  time:30.471, tt:2498.658\n",
      "Ep:82, loss:0.00004, loss_test:0.08811, lr:7.86e-03, fs:0.71958 (r=0.687,p=0.756),  time:30.490, tt:2530.637\n",
      "Ep:83, loss:0.00004, loss_test:0.08768, lr:7.78e-03, fs:0.71658 (r=0.677,p=0.761),  time:30.501, tt:2562.096\n",
      "Ep:84, loss:0.00004, loss_test:0.08807, lr:7.70e-03, fs:0.71277 (r=0.677,p=0.753),  time:30.505, tt:2592.928\n",
      "Ep:85, loss:0.00004, loss_test:0.08793, lr:7.62e-03, fs:0.72340 (r=0.687,p=0.764),  time:30.517, tt:2624.439\n",
      "Ep:86, loss:0.00004, loss_test:0.08814, lr:7.55e-03, fs:0.71351 (r=0.667,p=0.767),  time:30.514, tt:2654.723\n",
      "Ep:87, loss:0.00004, loss_test:0.08694, lr:7.47e-03, fs:0.71958 (r=0.687,p=0.756),  time:30.503, tt:2684.294\n",
      "Ep:88, loss:0.00004, loss_test:0.08853, lr:7.40e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.508, tt:2715.219\n",
      "Ep:89, loss:0.00004, loss_test:0.08719, lr:7.32e-03, fs:0.72043 (r=0.677,p=0.770),  time:30.523, tt:2747.030\n",
      "Ep:90, loss:0.00004, loss_test:0.08724, lr:7.25e-03, fs:0.71658 (r=0.677,p=0.761),  time:30.522, tt:2777.509\n",
      "Ep:91, loss:0.00003, loss_test:0.08797, lr:7.18e-03, fs:0.72432 (r=0.677,p=0.779),  time:30.509, tt:2806.808\n",
      "Ep:92, loss:0.00003, loss_test:0.08688, lr:7.11e-03, fs:0.72727 (r=0.687,p=0.773),  time:30.512, tt:2837.623\n",
      "Ep:93, loss:0.00003, loss_test:0.08695, lr:7.03e-03, fs:0.72043 (r=0.677,p=0.770),  time:30.506, tt:2867.595\n",
      "Ep:94, loss:0.00003, loss_test:0.08768, lr:6.96e-03, fs:0.72043 (r=0.677,p=0.770),  time:30.526, tt:2899.934\n",
      "Ep:95, loss:0.00003, loss_test:0.08730, lr:6.89e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.527, tt:2930.585\n",
      "Ep:96, loss:0.00003, loss_test:0.08673, lr:6.83e-03, fs:0.72043 (r=0.677,p=0.770),  time:30.534, tt:2961.812\n",
      "Ep:97, loss:0.00003, loss_test:0.08793, lr:6.76e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.543, tt:2993.251\n",
      "Ep:98, loss:0.00003, loss_test:0.08621, lr:6.69e-03, fs:0.73404 (r=0.697,p=0.775),  time:30.564, tt:3025.791\n",
      "Ep:99, loss:0.00003, loss_test:0.08771, lr:6.62e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.582, tt:3058.230\n",
      "Ep:100, loss:0.00003, loss_test:0.08663, lr:6.56e-03, fs:0.72432 (r=0.677,p=0.779),  time:30.598, tt:3090.409\n",
      "Ep:101, loss:0.00003, loss_test:0.08700, lr:6.49e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.601, tt:3121.305\n",
      "Ep:102, loss:0.00003, loss_test:0.08658, lr:6.43e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.602, tt:3152.012\n",
      "Ep:103, loss:0.00003, loss_test:0.08749, lr:6.36e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.614, tt:3183.832\n",
      "Ep:104, loss:0.00003, loss_test:0.08640, lr:6.30e-03, fs:0.70270 (r=0.657,p=0.756),  time:30.637, tt:3216.896\n",
      "Ep:105, loss:0.00003, loss_test:0.08667, lr:6.24e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.646, tt:3248.451\n",
      "Ep:106, loss:0.00003, loss_test:0.08691, lr:6.17e-03, fs:0.70270 (r=0.657,p=0.756),  time:30.657, tt:3280.258\n",
      "Ep:107, loss:0.00003, loss_test:0.08630, lr:6.11e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.666, tt:3311.975\n",
      "Ep:108, loss:0.00003, loss_test:0.08692, lr:6.05e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.662, tt:3342.122\n",
      "Ep:109, loss:0.00003, loss_test:0.08644, lr:5.99e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.667, tt:3373.361\n",
      "Ep:110, loss:0.00003, loss_test:0.08695, lr:5.93e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.671, tt:3404.513\n",
      "Ep:111, loss:0.00003, loss_test:0.08621, lr:5.87e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.670, tt:3434.991\n",
      "Ep:112, loss:0.00003, loss_test:0.08707, lr:5.81e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.672, tt:3465.947\n",
      "Ep:113, loss:0.00003, loss_test:0.08706, lr:5.75e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.678, tt:3497.290\n",
      "Ep:114, loss:0.00003, loss_test:0.08634, lr:5.70e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.674, tt:3527.560\n",
      "Ep:115, loss:0.00003, loss_test:0.08602, lr:5.64e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.674, tt:3558.176\n",
      "Ep:116, loss:0.00003, loss_test:0.08690, lr:5.58e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.660, tt:3587.256\n",
      "Ep:117, loss:0.00003, loss_test:0.08674, lr:5.53e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.674, tt:3619.583\n",
      "Ep:118, loss:0.00003, loss_test:0.08654, lr:5.47e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.679, tt:3650.810\n",
      "Ep:119, loss:0.00003, loss_test:0.08695, lr:5.42e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.674, tt:3680.837\n",
      "Ep:120, loss:0.00003, loss_test:0.08666, lr:5.36e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.671, tt:3711.152\n",
      "Ep:121, loss:0.00003, loss_test:0.08678, lr:5.31e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.678, tt:3742.732\n",
      "Ep:122, loss:0.00002, loss_test:0.08711, lr:5.26e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.685, tt:3774.207\n",
      "Ep:123, loss:0.00002, loss_test:0.08675, lr:5.20e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.682, tt:3804.606\n",
      "Ep:124, loss:0.00002, loss_test:0.08677, lr:5.15e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.682, tt:3835.258\n",
      "Ep:125, loss:0.00002, loss_test:0.08660, lr:5.10e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.681, tt:3865.815\n",
      "Ep:126, loss:0.00002, loss_test:0.08665, lr:5.05e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.670, tt:3895.114\n",
      "Ep:127, loss:0.00002, loss_test:0.08646, lr:5.00e-03, fs:0.71038 (r=0.657,p=0.774),  time:30.666, tt:3925.279\n",
      "Ep:128, loss:0.00002, loss_test:0.08708, lr:4.95e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.671, tt:3956.546\n",
      "Ep:129, loss:0.00002, loss_test:0.08737, lr:4.90e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.662, tt:3986.070\n",
      "Ep:130, loss:0.00002, loss_test:0.08620, lr:4.85e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.651, tt:4015.247\n",
      "Ep:131, loss:0.00002, loss_test:0.08725, lr:4.80e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.654, tt:4046.358\n",
      "Ep:132, loss:0.00002, loss_test:0.08764, lr:4.75e-03, fs:0.72222 (r=0.657,p=0.802),  time:30.644, tt:4075.626\n",
      "Ep:133, loss:0.00002, loss_test:0.08655, lr:4.71e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.647, tt:4106.698\n",
      "Ep:134, loss:0.00002, loss_test:0.08708, lr:4.66e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.639, tt:4136.305\n",
      "Ep:135, loss:0.00002, loss_test:0.08758, lr:4.61e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.633, tt:4166.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00002, loss_test:0.08686, lr:4.57e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.628, tt:4196.060\n",
      "Ep:137, loss:0.00002, loss_test:0.08737, lr:4.52e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.632, tt:4227.235\n",
      "Ep:138, loss:0.00002, loss_test:0.08704, lr:4.48e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.626, tt:4257.047\n",
      "Ep:139, loss:0.00002, loss_test:0.08678, lr:4.43e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.614, tt:4285.926\n",
      "Ep:140, loss:0.00002, loss_test:0.08735, lr:4.39e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.609, tt:4315.913\n",
      "Ep:141, loss:0.00002, loss_test:0.08702, lr:4.34e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.601, tt:4345.380\n",
      "Ep:142, loss:0.00002, loss_test:0.08704, lr:4.30e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.598, tt:4375.455\n",
      "Ep:143, loss:0.00002, loss_test:0.08756, lr:4.26e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.605, tt:4407.162\n",
      "Ep:144, loss:0.00002, loss_test:0.08690, lr:4.21e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.600, tt:4437.054\n",
      "Ep:145, loss:0.00002, loss_test:0.08723, lr:4.17e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.605, tt:4468.341\n",
      "Ep:146, loss:0.00002, loss_test:0.08762, lr:4.13e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.608, tt:4499.372\n",
      "Ep:147, loss:0.00002, loss_test:0.08726, lr:4.09e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.607, tt:4529.908\n",
      "Ep:148, loss:0.00002, loss_test:0.08736, lr:4.05e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.606, tt:4560.354\n",
      "Ep:149, loss:0.00002, loss_test:0.08744, lr:4.01e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.620, tt:4592.954\n",
      "Ep:150, loss:0.00002, loss_test:0.08759, lr:3.97e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.636, tt:4626.001\n",
      "Ep:151, loss:0.00002, loss_test:0.08744, lr:3.93e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.635, tt:4656.461\n",
      "Ep:152, loss:0.00002, loss_test:0.08703, lr:3.89e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.638, tt:4687.669\n",
      "Ep:153, loss:0.00002, loss_test:0.08777, lr:3.85e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.647, tt:4719.677\n",
      "Ep:154, loss:0.00002, loss_test:0.08749, lr:3.81e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.645, tt:4750.053\n",
      "Ep:155, loss:0.00002, loss_test:0.08722, lr:3.77e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.647, tt:4780.932\n",
      "Ep:156, loss:0.00002, loss_test:0.08751, lr:3.73e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.643, tt:4810.875\n",
      "Ep:157, loss:0.00002, loss_test:0.08757, lr:3.70e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.654, tt:4843.394\n",
      "Ep:158, loss:0.00002, loss_test:0.08736, lr:3.66e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.656, tt:4874.277\n",
      "Ep:159, loss:0.00002, loss_test:0.08732, lr:3.62e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.667, tt:4906.797\n",
      "Ep:160, loss:0.00002, loss_test:0.08763, lr:3.59e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.677, tt:4938.990\n",
      "Ep:161, loss:0.00002, loss_test:0.08773, lr:3.55e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.683, tt:4970.657\n",
      "Ep:162, loss:0.00002, loss_test:0.08717, lr:3.52e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.688, tt:5002.193\n",
      "Ep:163, loss:0.00002, loss_test:0.08726, lr:3.48e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.690, tt:5033.217\n",
      "Ep:164, loss:0.00002, loss_test:0.08742, lr:3.45e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.696, tt:5064.820\n",
      "Ep:165, loss:0.00002, loss_test:0.08761, lr:3.41e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.705, tt:5096.988\n",
      "Ep:166, loss:0.00002, loss_test:0.08743, lr:3.38e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.701, tt:5126.983\n",
      "Ep:167, loss:0.00002, loss_test:0.08716, lr:3.34e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.712, tt:5159.686\n",
      "Ep:168, loss:0.00002, loss_test:0.08730, lr:3.31e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.709, tt:5189.837\n",
      "Ep:169, loss:0.00002, loss_test:0.08724, lr:3.28e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.712, tt:5221.086\n",
      "Ep:170, loss:0.00002, loss_test:0.08739, lr:3.24e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.717, tt:5252.661\n",
      "Ep:171, loss:0.00002, loss_test:0.08761, lr:3.21e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.721, tt:5284.029\n",
      "Ep:172, loss:0.00002, loss_test:0.08720, lr:3.18e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.733, tt:5316.800\n",
      "Ep:173, loss:0.00002, loss_test:0.08733, lr:3.15e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.734, tt:5347.751\n",
      "Ep:174, loss:0.00002, loss_test:0.08761, lr:3.12e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.723, tt:5376.606\n",
      "Ep:175, loss:0.00002, loss_test:0.08756, lr:3.09e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.723, tt:5407.203\n",
      "Ep:176, loss:0.00002, loss_test:0.08723, lr:3.05e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.721, tt:5437.582\n",
      "Ep:177, loss:0.00002, loss_test:0.08765, lr:3.02e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.720, tt:5468.072\n",
      "Ep:178, loss:0.00002, loss_test:0.08790, lr:2.99e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.723, tt:5499.350\n",
      "Ep:179, loss:0.00002, loss_test:0.08742, lr:2.96e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.713, tt:5528.353\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14435, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.950, tt:29.950\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14357, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.254, tt:56.508\n",
      "Ep:2, loss:0.00028, loss_test:0.14214, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.716, tt:83.148\n",
      "Ep:3, loss:0.00027, loss_test:0.13982, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.595, tt:106.379\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13619, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:26.180, tt:130.898\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.13150, lr:1.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:26.385, tt:158.309\n",
      "Ep:6, loss:0.00024, loss_test:0.12686, lr:1.00e-02, fs:0.63025 (r=0.758,p=0.540),  time:26.950, tt:188.648\n",
      "Ep:7, loss:0.00023, loss_test:0.12539, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:27.284, tt:218.271\n",
      "Ep:8, loss:0.00023, loss_test:0.12524, lr:1.00e-02, fs:0.63014 (r=0.697,p=0.575),  time:27.827, tt:250.442\n",
      "Ep:9, loss:0.00022, loss_test:0.12404, lr:1.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:28.179, tt:281.786\n",
      "Ep:10, loss:0.00022, loss_test:0.12302, lr:1.00e-02, fs:0.62162 (r=0.697,p=0.561),  time:28.242, tt:310.666\n",
      "Ep:11, loss:0.00021, loss_test:0.12231, lr:1.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:28.347, tt:340.161\n",
      "Ep:12, loss:0.00020, loss_test:0.12171, lr:1.00e-02, fs:0.65753 (r=0.727,p=0.600),  time:28.339, tt:368.408\n",
      "Ep:13, loss:0.00020, loss_test:0.12097, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:28.467, tt:398.544\n",
      "Ep:14, loss:0.00019, loss_test:0.12025, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:28.577, tt:428.655\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11935, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:28.602, tt:457.629\n",
      "Ep:16, loss:0.00019, loss_test:0.11860, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:28.721, tt:488.260\n",
      "Ep:17, loss:0.00018, loss_test:0.11787, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:28.780, tt:518.032\n",
      "Ep:18, loss:0.00018, loss_test:0.11686, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:28.867, tt:548.481\n",
      "Ep:19, loss:0.00017, loss_test:0.11594, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:28.879, tt:577.588\n",
      "Ep:20, loss:0.00017, loss_test:0.11479, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:28.921, tt:607.331\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.11353, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:28.944, tt:636.773\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.11285, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:29.044, tt:668.022\n",
      "Ep:23, loss:0.00016, loss_test:0.11259, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:29.141, tt:699.378\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00016, loss_test:0.11190, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:29.232, tt:730.811\n",
      "Ep:25, loss:0.00015, loss_test:0.11089, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:29.299, tt:761.763\n",
      "Ep:26, loss:0.00015, loss_test:0.11024, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:29.346, tt:792.351\n",
      "Ep:27, loss:0.00015, loss_test:0.10978, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:29.365, tt:822.210\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.10905, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:29.378, tt:851.976\n",
      "Ep:29, loss:0.00014, loss_test:0.10821, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:29.403, tt:882.099\n",
      "Ep:30, loss:0.00014, loss_test:0.10735, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:29.471, tt:913.598\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.10724, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:29.507, tt:944.211\n",
      "Ep:32, loss:0.00013, loss_test:0.10703, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:29.536, tt:974.702\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.10568, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:29.528, tt:1003.964\n",
      "Ep:34, loss:0.00013, loss_test:0.10521, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:29.570, tt:1034.943\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.10535, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:29.538, tt:1063.367\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.10352, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:29.549, tt:1093.315\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.10255, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:29.635, tt:1126.123\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.10293, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:29.604, tt:1154.557\n",
      "Ep:39, loss:0.00011, loss_test:0.10141, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:29.635, tt:1185.385\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.10108, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:29.669, tt:1216.417\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.10129, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:29.726, tt:1248.498\n",
      "Ep:42, loss:0.00011, loss_test:0.10051, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:29.763, tt:1279.802\n",
      "Ep:43, loss:0.00010, loss_test:0.10012, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:29.801, tt:1311.225\n",
      "Ep:44, loss:0.00010, loss_test:0.10005, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:29.836, tt:1342.626\n",
      "Ep:45, loss:0.00010, loss_test:0.10148, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.863, tt:1373.697\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.09989, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:29.895, tt:1405.076\n",
      "Ep:47, loss:0.00009, loss_test:0.10072, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.920, tt:1436.165\n",
      "Ep:48, loss:0.00009, loss_test:0.10095, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:29.962, tt:1468.147\n",
      "Ep:49, loss:0.00009, loss_test:0.09979, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:29.969, tt:1498.446\n",
      "Ep:50, loss:0.00009, loss_test:0.10045, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:30.012, tt:1530.630\n",
      "Ep:51, loss:0.00008, loss_test:0.10155, lr:1.00e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.070, tt:1563.658\n",
      "Ep:52, loss:0.00008, loss_test:0.10004, lr:1.00e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.092, tt:1594.883\n",
      "Ep:53, loss:0.00008, loss_test:0.10056, lr:1.00e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.129, tt:1626.974\n",
      "Ep:54, loss:0.00008, loss_test:0.10098, lr:1.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.124, tt:1656.825\n",
      "Ep:55, loss:0.00007, loss_test:0.09961, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.170, tt:1689.495\n",
      "Ep:56, loss:0.00007, loss_test:0.10115, lr:1.00e-02, fs:0.69461 (r=0.586,p=0.853),  time:30.219, tt:1722.487\n",
      "Ep:57, loss:0.00007, loss_test:0.10077, lr:9.90e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.218, tt:1752.618\n",
      "Ep:58, loss:0.00007, loss_test:0.10041, lr:9.80e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.209, tt:1782.305\n",
      "Ep:59, loss:0.00007, loss_test:0.10045, lr:9.70e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.251, tt:1815.088\n",
      "Ep:60, loss:0.00006, loss_test:0.10139, lr:9.61e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.238, tt:1844.536\n",
      "Ep:61, loss:0.00006, loss_test:0.10087, lr:9.51e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.237, tt:1874.711\n",
      "Ep:62, loss:0.00006, loss_test:0.10117, lr:9.41e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.256, tt:1906.158\n",
      "Ep:63, loss:0.00006, loss_test:0.09871, lr:9.32e-03, fs:0.73143 (r=0.646,p=0.842),  time:30.278, tt:1937.793\n",
      "Ep:64, loss:0.00006, loss_test:0.10116, lr:9.23e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.316, tt:1970.552\n",
      "Ep:65, loss:0.00006, loss_test:0.09880, lr:9.14e-03, fs:0.71765 (r=0.616,p=0.859),  time:30.336, tt:2002.179\n",
      "Ep:66, loss:0.00005, loss_test:0.10061, lr:9.04e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.351, tt:2033.514\n",
      "Ep:67, loss:0.00005, loss_test:0.10064, lr:8.95e-03, fs:0.71084 (r=0.596,p=0.881),  time:30.358, tt:2064.318\n",
      "Ep:68, loss:0.00005, loss_test:0.09958, lr:8.86e-03, fs:0.72619 (r=0.616,p=0.884),  time:30.394, tt:2097.205\n",
      "Ep:69, loss:0.00005, loss_test:0.09955, lr:8.78e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.397, tt:2127.793\n",
      "Ep:70, loss:0.00005, loss_test:0.10016, lr:8.69e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.415, tt:2159.448\n",
      "Ep:71, loss:0.00005, loss_test:0.10016, lr:8.60e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.439, tt:2191.583\n",
      "Ep:72, loss:0.00005, loss_test:0.10063, lr:8.51e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.455, tt:2223.228\n",
      "Ep:73, loss:0.00005, loss_test:0.10024, lr:8.43e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.471, tt:2254.846\n",
      "Ep:74, loss:0.00005, loss_test:0.10072, lr:8.35e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.503, tt:2287.705\n",
      "Ep:75, loss:0.00004, loss_test:0.09977, lr:8.26e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.524, tt:2319.813\n",
      "Ep:76, loss:0.00004, loss_test:0.09997, lr:8.18e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.548, tt:2352.193\n",
      "Ep:77, loss:0.00004, loss_test:0.10111, lr:8.10e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.570, tt:2384.456\n",
      "Ep:78, loss:0.00004, loss_test:0.09910, lr:8.02e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.578, tt:2415.643\n",
      "Ep:79, loss:0.00004, loss_test:0.10148, lr:7.94e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.587, tt:2446.955\n",
      "Ep:80, loss:0.00004, loss_test:0.10015, lr:7.86e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.608, tt:2479.210\n",
      "Ep:81, loss:0.00004, loss_test:0.09919, lr:7.78e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.630, tt:2511.674\n",
      "Ep:82, loss:0.00004, loss_test:0.10105, lr:7.70e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.646, tt:2543.600\n",
      "Ep:83, loss:0.00004, loss_test:0.09989, lr:7.62e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.633, tt:2573.191\n",
      "Ep:84, loss:0.00004, loss_test:0.09932, lr:7.55e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.616, tt:2602.367\n",
      "Ep:85, loss:0.00004, loss_test:0.10055, lr:7.47e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.615, tt:2632.854\n",
      "Ep:86, loss:0.00004, loss_test:0.10049, lr:7.40e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.627, tt:2664.558\n",
      "Ep:87, loss:0.00003, loss_test:0.09829, lr:7.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.637, tt:2696.039\n",
      "Ep:88, loss:0.00003, loss_test:0.10107, lr:7.25e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.658, tt:2728.562\n",
      "Ep:89, loss:0.00003, loss_test:0.09878, lr:7.18e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.684, tt:2761.537\n",
      "Ep:90, loss:0.00003, loss_test:0.09971, lr:7.11e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.694, tt:2793.157\n",
      "Ep:91, loss:0.00003, loss_test:0.09951, lr:7.03e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.698, tt:2824.172\n",
      "Ep:92, loss:0.00003, loss_test:0.09912, lr:6.96e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.708, tt:2855.835\n",
      "Ep:93, loss:0.00003, loss_test:0.10152, lr:6.89e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.724, tt:2888.078\n",
      "Ep:94, loss:0.00003, loss_test:0.09833, lr:6.83e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.743, tt:2920.573\n",
      "Ep:95, loss:0.00003, loss_test:0.10080, lr:6.76e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.766, tt:2953.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00003, loss_test:0.10077, lr:6.69e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.779, tt:2985.574\n",
      "Ep:97, loss:0.00003, loss_test:0.09921, lr:6.62e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.796, tt:3017.994\n",
      "Ep:98, loss:0.00003, loss_test:0.10065, lr:6.56e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.793, tt:3048.462\n",
      "Ep:99, loss:0.00003, loss_test:0.09946, lr:6.49e-03, fs:0.71084 (r=0.596,p=0.881),  time:30.798, tt:3079.811\n",
      "Ep:100, loss:0.00003, loss_test:0.09951, lr:6.43e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.802, tt:3111.003\n",
      "Ep:101, loss:0.00003, loss_test:0.09960, lr:6.36e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.809, tt:3142.525\n",
      "Ep:102, loss:0.00003, loss_test:0.09911, lr:6.30e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.833, tt:3175.792\n",
      "Ep:103, loss:0.00003, loss_test:0.09960, lr:6.24e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.832, tt:3206.494\n",
      "Ep:104, loss:0.00003, loss_test:0.10011, lr:6.17e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.848, tt:3239.026\n",
      "Ep:105, loss:0.00003, loss_test:0.09835, lr:6.11e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.871, tt:3272.371\n",
      "Ep:106, loss:0.00003, loss_test:0.10044, lr:6.05e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.877, tt:3303.794\n",
      "Ep:107, loss:0.00003, loss_test:0.09845, lr:5.99e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.870, tt:3333.953\n",
      "Ep:108, loss:0.00003, loss_test:0.09993, lr:5.93e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.883, tt:3366.253\n",
      "Ep:109, loss:0.00003, loss_test:0.10035, lr:5.87e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.883, tt:3397.138\n",
      "Ep:110, loss:0.00003, loss_test:0.09937, lr:5.81e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.893, tt:3429.088\n",
      "Ep:111, loss:0.00003, loss_test:0.09975, lr:5.75e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.907, tt:3461.628\n",
      "Ep:112, loss:0.00003, loss_test:0.09874, lr:5.70e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.901, tt:3491.805\n",
      "Ep:113, loss:0.00002, loss_test:0.09977, lr:5.64e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.892, tt:3521.641\n",
      "Ep:114, loss:0.00002, loss_test:0.09899, lr:5.58e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.891, tt:3552.417\n",
      "Ep:115, loss:0.00002, loss_test:0.09845, lr:5.53e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.911, tt:3585.637\n",
      "Ep:116, loss:0.00002, loss_test:0.09986, lr:5.47e-03, fs:0.71951 (r=0.596,p=0.908),  time:30.914, tt:3616.952\n",
      "Ep:117, loss:0.00002, loss_test:0.09817, lr:5.42e-03, fs:0.71951 (r=0.596,p=0.908),  time:30.922, tt:3648.789\n",
      "Ep:118, loss:0.00002, loss_test:0.09995, lr:5.36e-03, fs:0.71951 (r=0.596,p=0.908),  time:30.921, tt:3679.544\n",
      "Ep:119, loss:0.00002, loss_test:0.09892, lr:5.31e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.936, tt:3712.359\n",
      "Ep:120, loss:0.00002, loss_test:0.09873, lr:5.26e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.945, tt:3744.390\n",
      "Ep:121, loss:0.00002, loss_test:0.09901, lr:5.20e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.951, tt:3776.030\n",
      "Ep:122, loss:0.00002, loss_test:0.09902, lr:5.15e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.960, tt:3808.046\n",
      "Ep:123, loss:0.00002, loss_test:0.09967, lr:5.10e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.956, tt:3838.602\n",
      "Ep:124, loss:0.00002, loss_test:0.09780, lr:5.05e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.968, tt:3871.006\n",
      "Ep:125, loss:0.00002, loss_test:0.09933, lr:5.00e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.969, tt:3902.097\n",
      "Ep:126, loss:0.00002, loss_test:0.09911, lr:4.95e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.970, tt:3933.220\n",
      "Ep:127, loss:0.00002, loss_test:0.09795, lr:4.90e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.972, tt:3964.471\n",
      "Ep:128, loss:0.00002, loss_test:0.09992, lr:4.85e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.975, tt:3995.715\n",
      "Ep:129, loss:0.00002, loss_test:0.09873, lr:4.80e-03, fs:0.71951 (r=0.596,p=0.908),  time:30.979, tt:4027.286\n",
      "Ep:130, loss:0.00002, loss_test:0.09854, lr:4.75e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.975, tt:4057.681\n",
      "Ep:131, loss:0.00002, loss_test:0.09989, lr:4.71e-03, fs:0.70370 (r=0.576,p=0.905),  time:30.970, tt:4088.029\n",
      "Ep:132, loss:0.00002, loss_test:0.09845, lr:4.66e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.969, tt:4118.904\n",
      "Ep:133, loss:0.00002, loss_test:0.09844, lr:4.61e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.963, tt:4149.032\n",
      "Ep:134, loss:0.00002, loss_test:0.09942, lr:4.57e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.962, tt:4179.911\n",
      "Ep:135, loss:0.00002, loss_test:0.09802, lr:4.52e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.975, tt:4212.638\n",
      "Ep:136, loss:0.00002, loss_test:0.09947, lr:4.48e-03, fs:0.71166 (r=0.586,p=0.906),  time:30.991, tt:4245.814\n",
      "Ep:137, loss:0.00002, loss_test:0.09876, lr:4.43e-03, fs:0.71951 (r=0.596,p=0.908),  time:30.986, tt:4276.024\n",
      "Ep:138, loss:0.00002, loss_test:0.09812, lr:4.39e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.993, tt:4307.991\n",
      "Ep:139, loss:0.00002, loss_test:0.09924, lr:4.34e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.009, tt:4341.195\n",
      "Ep:140, loss:0.00002, loss_test:0.09840, lr:4.30e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.013, tt:4372.775\n",
      "Ep:141, loss:0.00002, loss_test:0.09848, lr:4.26e-03, fs:0.72289 (r=0.606,p=0.896),  time:31.006, tt:4402.917\n",
      "Ep:142, loss:0.00002, loss_test:0.09973, lr:4.21e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.016, tt:4435.304\n",
      "Ep:143, loss:0.00002, loss_test:0.09849, lr:4.17e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.027, tt:4467.909\n",
      "Ep:144, loss:0.00002, loss_test:0.09839, lr:4.13e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.033, tt:4499.852\n",
      "Ep:145, loss:0.00002, loss_test:0.09828, lr:4.09e-03, fs:0.72289 (r=0.606,p=0.896),  time:31.033, tt:4530.772\n",
      "Ep:146, loss:0.00002, loss_test:0.09879, lr:4.05e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.044, tt:4563.486\n",
      "Ep:147, loss:0.00002, loss_test:0.09866, lr:4.01e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.047, tt:4595.005\n",
      "Ep:148, loss:0.00002, loss_test:0.09831, lr:3.97e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.056, tt:4627.386\n",
      "Ep:149, loss:0.00002, loss_test:0.09886, lr:3.93e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.057, tt:4658.484\n",
      "Ep:150, loss:0.00002, loss_test:0.09866, lr:3.89e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.054, tt:4689.215\n",
      "Ep:151, loss:0.00002, loss_test:0.09813, lr:3.85e-03, fs:0.71951 (r=0.596,p=0.908),  time:31.057, tt:4720.602\n",
      "Ep:152, loss:0.00002, loss_test:0.09909, lr:3.81e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.060, tt:4752.216\n",
      "Ep:153, loss:0.00002, loss_test:0.09825, lr:3.77e-03, fs:0.73054 (r=0.616,p=0.897),  time:31.067, tt:4784.288\n",
      "Ep:154, loss:0.00002, loss_test:0.09913, lr:3.73e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.071, tt:4815.932\n",
      "Ep:155, loss:0.00002, loss_test:0.09928, lr:3.70e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.082, tt:4848.851\n",
      "Ep:156, loss:0.00002, loss_test:0.09771, lr:3.66e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.086, tt:4880.438\n",
      "Ep:157, loss:0.00002, loss_test:0.09896, lr:3.62e-03, fs:0.71515 (r=0.596,p=0.894),  time:31.095, tt:4913.058\n",
      "Ep:158, loss:0.00002, loss_test:0.09895, lr:3.59e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.100, tt:4944.885\n",
      "Ep:159, loss:0.00002, loss_test:0.09844, lr:3.55e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.100, tt:4975.938\n",
      "Ep:160, loss:0.00002, loss_test:0.09887, lr:3.52e-03, fs:0.73054 (r=0.616,p=0.897),  time:31.095, tt:5006.365\n",
      "Ep:161, loss:0.00002, loss_test:0.09863, lr:3.48e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.076, tt:5034.333\n",
      "Ep:162, loss:0.00002, loss_test:0.09889, lr:3.45e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.078, tt:5065.728\n",
      "Ep:163, loss:0.00002, loss_test:0.09923, lr:3.41e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.076, tt:5096.515\n",
      "Ep:164, loss:0.00002, loss_test:0.09867, lr:3.38e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.073, tt:5127.082\n",
      "Ep:165, loss:0.00002, loss_test:0.09913, lr:3.34e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.074, tt:5158.313\n",
      "Ep:166, loss:0.00002, loss_test:0.09875, lr:3.31e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.078, tt:5190.052\n",
      "Ep:167, loss:0.00002, loss_test:0.09840, lr:3.28e-03, fs:0.72289 (r=0.606,p=0.896),  time:31.075, tt:5220.523\n",
      "Ep:168, loss:0.00002, loss_test:0.09902, lr:3.24e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.072, tt:5251.111\n",
      "Ep:169, loss:0.00002, loss_test:0.09828, lr:3.21e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.070, tt:5281.890\n",
      "Ep:170, loss:0.00002, loss_test:0.09885, lr:3.18e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.073, tt:5313.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:171, loss:0.00002, loss_test:0.09902, lr:3.15e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.071, tt:5344.279\n",
      "Ep:172, loss:0.00002, loss_test:0.09798, lr:3.12e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.085, tt:5377.624\n",
      "Ep:173, loss:0.00002, loss_test:0.09902, lr:3.09e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.078, tt:5407.579\n",
      "Ep:174, loss:0.00002, loss_test:0.09932, lr:3.05e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.077, tt:5438.491\n",
      "Ep:175, loss:0.00002, loss_test:0.09808, lr:3.02e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.089, tt:5471.682\n",
      "Ep:176, loss:0.00002, loss_test:0.09848, lr:2.99e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.088, tt:5502.550\n",
      "Ep:177, loss:0.00002, loss_test:0.09904, lr:2.96e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.101, tt:5536.061\n",
      "Ep:178, loss:0.00002, loss_test:0.09803, lr:2.93e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.113, tt:5569.205\n",
      "Ep:179, loss:0.00002, loss_test:0.09835, lr:2.90e-03, fs:0.70732 (r=0.586,p=0.892),  time:31.109, tt:5599.555\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14089, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:61.674, tt:61.674\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.13282, lr:1.00e-02, fs:0.63004 (r=0.869,p=0.494),  time:56.891, tt:113.781\n",
      "Ep:2, loss:0.00048, loss_test:0.12046, lr:1.00e-02, fs:0.63158 (r=0.667,p=0.600),  time:56.455, tt:169.364\n",
      "Ep:3, loss:0.00045, loss_test:0.11555, lr:1.00e-02, fs:0.66038 (r=0.707,p=0.619),  time:57.005, tt:228.020\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00043, loss_test:0.11124, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:58.619, tt:293.097\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.10695, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:59.861, tt:359.167\n",
      "Ep:6, loss:0.00038, loss_test:0.10302, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:60.813, tt:425.691\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00036, loss_test:0.09850, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:61.402, tt:491.216\n",
      "Ep:8, loss:0.00035, loss_test:0.09545, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:61.624, tt:554.620\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00033, loss_test:0.09221, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:61.928, tt:619.282\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.09024, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:62.232, tt:684.553\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.08804, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:62.382, tt:748.583\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.08644, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:62.461, tt:811.997\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.08532, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:62.579, tt:876.103\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.08419, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:62.450, tt:936.753\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08387, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:62.614, tt:1001.822\n",
      "Ep:16, loss:0.00025, loss_test:0.08393, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:62.685, tt:1065.649\n",
      "Ep:17, loss:0.00024, loss_test:0.08283, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:62.878, tt:1131.797\n",
      "Ep:18, loss:0.00023, loss_test:0.08350, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:63.098, tt:1198.853\n",
      "Ep:19, loss:0.00022, loss_test:0.08447, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:63.155, tt:1263.101\n",
      "Ep:20, loss:0.00021, loss_test:0.08302, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:63.180, tt:1326.784\n",
      "Ep:21, loss:0.00020, loss_test:0.08664, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:63.208, tt:1390.575\n",
      "Ep:22, loss:0.00019, loss_test:0.08563, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:63.283, tt:1455.506\n",
      "Ep:23, loss:0.00018, loss_test:0.08514, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:63.360, tt:1520.642\n",
      "Ep:24, loss:0.00017, loss_test:0.08461, lr:1.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:63.315, tt:1582.865\n",
      "Ep:25, loss:0.00016, loss_test:0.08056, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:63.291, tt:1645.560\n",
      "Ep:26, loss:0.00016, loss_test:0.08524, lr:9.90e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.327, tt:1709.835\n",
      "Ep:27, loss:0.00015, loss_test:0.08499, lr:9.80e-03, fs:0.77457 (r=0.677,p=0.905),  time:63.404, tt:1775.322\n",
      "Ep:28, loss:0.00014, loss_test:0.08360, lr:9.70e-03, fs:0.75581 (r=0.657,p=0.890),  time:63.436, tt:1839.641\n",
      "Ep:29, loss:0.00013, loss_test:0.08366, lr:9.61e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.470, tt:1904.104\n",
      "Ep:30, loss:0.00013, loss_test:0.08864, lr:9.51e-03, fs:0.75449 (r=0.636,p=0.926),  time:63.458, tt:1967.195\n",
      "Ep:31, loss:0.00012, loss_test:0.08415, lr:9.41e-03, fs:0.75449 (r=0.636,p=0.926),  time:63.356, tt:2027.392\n",
      "Ep:32, loss:0.00011, loss_test:0.08152, lr:9.32e-03, fs:0.75740 (r=0.646,p=0.914),  time:63.314, tt:2089.355\n",
      "Ep:33, loss:0.00011, loss_test:0.08545, lr:9.23e-03, fs:0.75904 (r=0.636,p=0.940),  time:63.353, tt:2154.007\n",
      "Ep:34, loss:0.00010, loss_test:0.08232, lr:9.14e-03, fs:0.76190 (r=0.646,p=0.928),  time:63.424, tt:2219.826\n",
      "Ep:35, loss:0.00010, loss_test:0.08044, lr:9.04e-03, fs:0.76190 (r=0.646,p=0.928),  time:63.474, tt:2285.064\n",
      "Ep:36, loss:0.00009, loss_test:0.08475, lr:8.95e-03, fs:0.76364 (r=0.636,p=0.955),  time:63.452, tt:2347.731\n",
      "Ep:37, loss:0.00009, loss_test:0.08064, lr:8.86e-03, fs:0.76647 (r=0.646,p=0.941),  time:63.486, tt:2412.454\n",
      "Ep:38, loss:0.00009, loss_test:0.08060, lr:8.78e-03, fs:0.76647 (r=0.646,p=0.941),  time:63.486, tt:2475.970\n",
      "Ep:39, loss:0.00008, loss_test:0.08384, lr:8.69e-03, fs:0.77108 (r=0.646,p=0.955),  time:63.507, tt:2540.275\n",
      "Ep:40, loss:0.00008, loss_test:0.07770, lr:8.60e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.487, tt:2602.979\n",
      "Ep:41, loss:0.00008, loss_test:0.07861, lr:8.51e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.511, tt:2667.466\n",
      "Ep:42, loss:0.00007, loss_test:0.07888, lr:8.43e-03, fs:0.78571 (r=0.667,p=0.957),  time:63.494, tt:2730.254\n",
      "Ep:43, loss:0.00007, loss_test:0.07816, lr:8.35e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.534, tt:2795.512\n",
      "Ep:44, loss:0.00007, loss_test:0.08005, lr:8.26e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.534, tt:2859.031\n",
      "Ep:45, loss:0.00006, loss_test:0.07705, lr:8.18e-03, fs:0.79290 (r=0.677,p=0.957),  time:63.556, tt:2923.558\n",
      "Ep:46, loss:0.00006, loss_test:0.07904, lr:8.10e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.535, tt:2986.140\n",
      "Ep:47, loss:0.00006, loss_test:0.07936, lr:8.02e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.534, tt:3049.624\n",
      "Ep:48, loss:0.00006, loss_test:0.07841, lr:7.94e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.527, tt:3112.815\n",
      "Ep:49, loss:0.00006, loss_test:0.07845, lr:7.86e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.559, tt:3177.970\n",
      "Ep:50, loss:0.00005, loss_test:0.07764, lr:7.78e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.551, tt:3241.117\n",
      "Ep:51, loss:0.00005, loss_test:0.07891, lr:7.70e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.502, tt:3302.124\n",
      "Ep:52, loss:0.00005, loss_test:0.07834, lr:7.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.527, tt:3366.948\n",
      "Ep:53, loss:0.00005, loss_test:0.07668, lr:7.55e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.514, tt:3429.739\n",
      "Ep:54, loss:0.00005, loss_test:0.08111, lr:7.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.516, tt:3493.402\n",
      "Ep:55, loss:0.00005, loss_test:0.07910, lr:7.40e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.525, tt:3557.422\n",
      "Ep:56, loss:0.00004, loss_test:0.07762, lr:7.32e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.514, tt:3620.278\n",
      "Ep:57, loss:0.00004, loss_test:0.07838, lr:7.25e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.533, tt:3684.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00004, loss_test:0.08297, lr:7.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.557, tt:3749.868\n",
      "Ep:59, loss:0.00004, loss_test:0.07997, lr:7.11e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.572, tt:3814.315\n",
      "Ep:60, loss:0.00004, loss_test:0.07755, lr:7.03e-03, fs:0.79042 (r=0.667,p=0.971),  time:63.558, tt:3877.043\n",
      "Ep:61, loss:0.00004, loss_test:0.07858, lr:6.96e-03, fs:0.77844 (r=0.657,p=0.956),  time:63.532, tt:3938.958\n",
      "Ep:62, loss:0.00004, loss_test:0.07786, lr:6.89e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.535, tt:4002.721\n",
      "Ep:63, loss:0.00004, loss_test:0.08036, lr:6.83e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.575, tt:4068.789\n",
      "Ep:64, loss:0.00004, loss_test:0.08167, lr:6.76e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.595, tt:4133.696\n",
      "Ep:65, loss:0.00004, loss_test:0.08018, lr:6.69e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.621, tt:4199.007\n",
      "Ep:66, loss:0.00003, loss_test:0.07705, lr:6.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.615, tt:4262.207\n",
      "Ep:67, loss:0.00003, loss_test:0.08061, lr:6.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.659, tt:4328.793\n",
      "Ep:68, loss:0.00003, loss_test:0.08014, lr:6.49e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.664, tt:4392.820\n",
      "Ep:69, loss:0.00003, loss_test:0.07946, lr:6.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.680, tt:4457.576\n",
      "Ep:70, loss:0.00003, loss_test:0.07961, lr:6.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.687, tt:4521.775\n",
      "Ep:71, loss:0.00003, loss_test:0.08055, lr:6.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.686, tt:4585.398\n",
      "Ep:72, loss:0.00003, loss_test:0.07993, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.712, tt:4650.990\n",
      "Ep:73, loss:0.00003, loss_test:0.08072, lr:6.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.699, tt:4713.714\n",
      "Ep:74, loss:0.00003, loss_test:0.08106, lr:6.11e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.686, tt:4776.417\n",
      "Ep:75, loss:0.00003, loss_test:0.07890, lr:6.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.694, tt:4840.720\n",
      "Ep:76, loss:0.00003, loss_test:0.08095, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.709, tt:4905.563\n",
      "Ep:77, loss:0.00003, loss_test:0.08181, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.751, tt:4972.590\n",
      "Ep:78, loss:0.00003, loss_test:0.07963, lr:5.87e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.747, tt:5035.974\n",
      "Ep:79, loss:0.00002, loss_test:0.08095, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.788, tt:5103.066\n",
      "Ep:80, loss:0.00002, loss_test:0.08134, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.789, tt:5166.904\n",
      "Ep:81, loss:0.00002, loss_test:0.08090, lr:5.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.796, tt:5231.300\n",
      "Ep:82, loss:0.00002, loss_test:0.08210, lr:5.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.816, tt:5296.751\n",
      "Ep:83, loss:0.00002, loss_test:0.08191, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.842, tt:5362.739\n",
      "Ep:84, loss:0.00002, loss_test:0.08225, lr:5.53e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.835, tt:5425.954\n",
      "Ep:85, loss:0.00002, loss_test:0.08197, lr:5.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.825, tt:5488.973\n",
      "Ep:86, loss:0.00002, loss_test:0.08130, lr:5.42e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.849, tt:5554.891\n",
      "Ep:87, loss:0.00002, loss_test:0.08377, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.844, tt:5618.272\n",
      "Ep:88, loss:0.00002, loss_test:0.08114, lr:5.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.850, tt:5682.628\n",
      "Ep:89, loss:0.00002, loss_test:0.08157, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.841, tt:5745.673\n",
      "Ep:90, loss:0.00002, loss_test:0.08316, lr:5.20e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.844, tt:5809.797\n",
      "Ep:91, loss:0.00002, loss_test:0.08381, lr:5.15e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.837, tt:5872.994\n",
      "Ep:92, loss:0.00002, loss_test:0.08196, lr:5.10e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.822, tt:5935.410\n",
      "Ep:93, loss:0.00002, loss_test:0.08283, lr:5.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:63.821, tt:5999.206\n",
      "Ep:94, loss:0.00002, loss_test:0.08393, lr:5.00e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.834, tt:6064.214\n",
      "Ep:95, loss:0.00002, loss_test:0.08400, lr:4.95e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.846, tt:6129.223\n",
      "Ep:96, loss:0.00002, loss_test:0.08154, lr:4.90e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.825, tt:6191.005\n",
      "Ep:97, loss:0.00002, loss_test:0.08631, lr:4.85e-03, fs:0.78528 (r=0.646,p=1.000),  time:63.829, tt:6255.237\n",
      "Ep:98, loss:0.00002, loss_test:0.08356, lr:4.80e-03, fs:0.79268 (r=0.657,p=1.000),  time:63.817, tt:6317.856\n",
      "Ep:99, loss:0.00002, loss_test:0.08380, lr:4.75e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.833, tt:6383.300\n",
      "Ep:100, loss:0.00002, loss_test:0.08584, lr:4.71e-03, fs:0.76250 (r=0.616,p=1.000),  time:63.847, tt:6448.595\n",
      "Ep:101, loss:0.00002, loss_test:0.08352, lr:4.66e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.855, tt:6513.234\n",
      "Ep:102, loss:0.00002, loss_test:0.08543, lr:4.61e-03, fs:0.78528 (r=0.646,p=1.000),  time:63.858, tt:6577.353\n",
      "Ep:103, loss:0.00002, loss_test:0.08516, lr:4.57e-03, fs:0.79268 (r=0.657,p=1.000),  time:63.855, tt:6640.877\n",
      "Ep:104, loss:0.00002, loss_test:0.08468, lr:4.52e-03, fs:0.79268 (r=0.657,p=1.000),  time:63.865, tt:6705.853\n",
      "Ep:105, loss:0.00002, loss_test:0.08673, lr:4.48e-03, fs:0.75472 (r=0.606,p=1.000),  time:63.871, tt:6770.312\n",
      "Ep:106, loss:0.00002, loss_test:0.08409, lr:4.43e-03, fs:0.79268 (r=0.657,p=1.000),  time:63.868, tt:6833.887\n",
      "Ep:107, loss:0.00001, loss_test:0.08622, lr:4.39e-03, fs:0.76250 (r=0.616,p=1.000),  time:63.881, tt:6899.102\n",
      "Ep:108, loss:0.00001, loss_test:0.08570, lr:4.34e-03, fs:0.78528 (r=0.646,p=1.000),  time:63.890, tt:6964.025\n",
      "Ep:109, loss:0.00001, loss_test:0.08527, lr:4.30e-03, fs:0.79268 (r=0.657,p=1.000),  time:63.878, tt:7026.551\n",
      "Ep:110, loss:0.00001, loss_test:0.08637, lr:4.26e-03, fs:0.76250 (r=0.616,p=1.000),  time:63.889, tt:7091.687\n",
      "Ep:111, loss:0.00001, loss_test:0.08559, lr:4.21e-03, fs:0.78528 (r=0.646,p=1.000),  time:63.896, tt:7156.359\n",
      "Ep:112, loss:0.00001, loss_test:0.08559, lr:4.17e-03, fs:0.75472 (r=0.606,p=1.000),  time:63.895, tt:7220.187\n",
      "Ep:113, loss:0.00001, loss_test:0.08575, lr:4.13e-03, fs:0.78528 (r=0.646,p=1.000),  time:63.883, tt:7282.626\n",
      "Ep:114, loss:0.00001, loss_test:0.08555, lr:4.09e-03, fs:0.77019 (r=0.626,p=1.000),  time:63.898, tt:7348.313\n",
      "Ep:115, loss:0.00001, loss_test:0.08675, lr:4.05e-03, fs:0.75472 (r=0.606,p=1.000),  time:63.898, tt:7412.204\n",
      "Ep:116, loss:0.00001, loss_test:0.08469, lr:4.01e-03, fs:0.77019 (r=0.626,p=1.000),  time:63.888, tt:7474.855\n",
      "Ep:117, loss:0.00001, loss_test:0.08792, lr:3.97e-03, fs:0.74684 (r=0.596,p=1.000),  time:63.898, tt:7540.003\n",
      "Ep:118, loss:0.00001, loss_test:0.08499, lr:3.93e-03, fs:0.78528 (r=0.646,p=1.000),  time:63.893, tt:7603.310\n",
      "Ep:119, loss:0.00001, loss_test:0.08848, lr:3.89e-03, fs:0.73885 (r=0.586,p=1.000),  time:63.891, tt:7666.924\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14244, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:60.580, tt:60.580\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.13335, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:57.051, tt:114.103\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00048, loss_test:0.11741, lr:1.00e-02, fs:0.65116 (r=0.707,p=0.603),  time:57.898, tt:173.693\n",
      "Ep:3, loss:0.00045, loss_test:0.11316, lr:1.00e-02, fs:0.66359 (r=0.727,p=0.610),  time:57.213, tt:228.854\n",
      "Ep:4, loss:0.00042, loss_test:0.10937, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:57.793, tt:288.964\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.10485, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:58.922, tt:353.531\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00038, loss_test:0.10074, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:59.610, tt:417.273\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00036, loss_test:0.09861, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:60.187, tt:481.499\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00034, loss_test:0.09725, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:60.454, tt:544.089\n",
      "Ep:9, loss:0.00033, loss_test:0.09495, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:60.592, tt:605.924\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.09382, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:60.882, tt:669.700\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.09282, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:61.240, tt:734.882\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00029, loss_test:0.09171, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:61.580, tt:800.539\n",
      "Ep:13, loss:0.00028, loss_test:0.08895, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:61.724, tt:864.140\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.08905, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:61.981, tt:929.719\n",
      "Ep:15, loss:0.00026, loss_test:0.08878, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:61.940, tt:991.042\n",
      "Ep:16, loss:0.00025, loss_test:0.08784, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:62.196, tt:1057.330\n",
      "Ep:17, loss:0.00024, loss_test:0.08659, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:62.342, tt:1122.161\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.08741, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:62.471, tt:1186.955\n",
      "Ep:19, loss:0.00022, loss_test:0.08699, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:62.606, tt:1252.126\n",
      "Ep:20, loss:0.00021, loss_test:0.08475, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:62.708, tt:1316.859\n",
      "Ep:21, loss:0.00019, loss_test:0.08829, lr:1.00e-02, fs:0.73143 (r=0.646,p=0.842),  time:62.856, tt:1382.833\n",
      "Ep:22, loss:0.00018, loss_test:0.08515, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:63.027, tt:1449.621\n",
      "Ep:23, loss:0.00018, loss_test:0.08763, lr:1.00e-02, fs:0.72000 (r=0.636,p=0.829),  time:63.160, tt:1515.844\n",
      "Ep:24, loss:0.00017, loss_test:0.08629, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:63.274, tt:1581.848\n",
      "Ep:25, loss:0.00016, loss_test:0.08722, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:63.389, tt:1648.123\n",
      "Ep:26, loss:0.00015, loss_test:0.08527, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:63.461, tt:1713.450\n",
      "Ep:27, loss:0.00014, loss_test:0.08621, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:63.481, tt:1777.475\n",
      "Ep:28, loss:0.00013, loss_test:0.08208, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:63.546, tt:1842.833\n",
      "Ep:29, loss:0.00013, loss_test:0.08719, lr:9.90e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.635, tt:1909.048\n",
      "Ep:30, loss:0.00012, loss_test:0.08564, lr:9.80e-03, fs:0.72515 (r=0.626,p=0.861),  time:63.701, tt:1974.735\n",
      "Ep:31, loss:0.00011, loss_test:0.08877, lr:9.70e-03, fs:0.69512 (r=0.576,p=0.877),  time:63.770, tt:2040.647\n",
      "Ep:32, loss:0.00010, loss_test:0.08726, lr:9.61e-03, fs:0.68712 (r=0.566,p=0.875),  time:63.785, tt:2104.890\n",
      "Ep:33, loss:0.00010, loss_test:0.08641, lr:9.51e-03, fs:0.71429 (r=0.606,p=0.870),  time:63.824, tt:2170.002\n",
      "Ep:34, loss:0.00009, loss_test:0.08217, lr:9.41e-03, fs:0.71765 (r=0.616,p=0.859),  time:63.926, tt:2237.402\n",
      "Ep:35, loss:0.00009, loss_test:0.08298, lr:9.32e-03, fs:0.75145 (r=0.657,p=0.878),  time:63.958, tt:2302.505\n",
      "Ep:36, loss:0.00008, loss_test:0.08653, lr:9.23e-03, fs:0.69091 (r=0.576,p=0.864),  time:63.995, tt:2367.828\n",
      "Ep:37, loss:0.00008, loss_test:0.08759, lr:9.14e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.065, tt:2434.488\n",
      "Ep:38, loss:0.00008, loss_test:0.08569, lr:9.04e-03, fs:0.70659 (r=0.596,p=0.868),  time:64.154, tt:2502.012\n",
      "Ep:39, loss:0.00007, loss_test:0.08686, lr:8.95e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.210, tt:2568.402\n",
      "Ep:40, loss:0.00007, loss_test:0.08401, lr:8.86e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.231, tt:2633.458\n",
      "Ep:41, loss:0.00007, loss_test:0.08700, lr:8.78e-03, fs:0.68293 (r=0.566,p=0.862),  time:64.284, tt:2699.926\n",
      "Ep:42, loss:0.00007, loss_test:0.08772, lr:8.69e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.264, tt:2763.341\n",
      "Ep:43, loss:0.00006, loss_test:0.09014, lr:8.60e-03, fs:0.69136 (r=0.566,p=0.889),  time:64.261, tt:2827.476\n",
      "Ep:44, loss:0.00006, loss_test:0.08439, lr:8.51e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.294, tt:2893.224\n",
      "Ep:45, loss:0.00006, loss_test:0.09017, lr:8.43e-03, fs:0.68323 (r=0.556,p=0.887),  time:64.301, tt:2957.855\n",
      "Ep:46, loss:0.00006, loss_test:0.08761, lr:8.35e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.299, tt:3022.050\n",
      "Ep:47, loss:0.00006, loss_test:0.08803, lr:8.26e-03, fs:0.71515 (r=0.596,p=0.894),  time:64.269, tt:3084.897\n",
      "Ep:48, loss:0.00006, loss_test:0.09476, lr:8.18e-03, fs:0.68323 (r=0.556,p=0.887),  time:64.277, tt:3149.597\n",
      "Ep:49, loss:0.00005, loss_test:0.09229, lr:8.10e-03, fs:0.69136 (r=0.566,p=0.889),  time:64.246, tt:3212.288\n",
      "Ep:50, loss:0.00005, loss_test:0.08907, lr:8.02e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.250, tt:3276.752\n",
      "Ep:51, loss:0.00005, loss_test:0.09149, lr:7.94e-03, fs:0.67081 (r=0.545,p=0.871),  time:64.302, tt:3343.687\n",
      "Ep:52, loss:0.00004, loss_test:0.09200, lr:7.86e-03, fs:0.69512 (r=0.576,p=0.877),  time:64.313, tt:3408.566\n",
      "Ep:53, loss:0.00004, loss_test:0.08704, lr:7.78e-03, fs:0.69512 (r=0.576,p=0.877),  time:64.323, tt:3473.433\n",
      "Ep:54, loss:0.00004, loss_test:0.09589, lr:7.70e-03, fs:0.66667 (r=0.535,p=0.883),  time:64.324, tt:3537.830\n",
      "Ep:55, loss:0.00004, loss_test:0.09470, lr:7.62e-03, fs:0.67081 (r=0.545,p=0.871),  time:64.377, tt:3605.102\n",
      "Ep:56, loss:0.00004, loss_test:0.09227, lr:7.55e-03, fs:0.65409 (r=0.525,p=0.867),  time:64.400, tt:3670.821\n",
      "Ep:57, loss:0.00004, loss_test:0.08848, lr:7.47e-03, fs:0.69512 (r=0.576,p=0.877),  time:64.379, tt:3734.005\n",
      "Ep:58, loss:0.00004, loss_test:0.09596, lr:7.40e-03, fs:0.66667 (r=0.535,p=0.883),  time:64.381, tt:3798.502\n",
      "Ep:59, loss:0.00004, loss_test:0.09386, lr:7.32e-03, fs:0.65409 (r=0.525,p=0.867),  time:64.382, tt:3862.926\n",
      "Ep:60, loss:0.00004, loss_test:0.09251, lr:7.25e-03, fs:0.67081 (r=0.545,p=0.871),  time:64.387, tt:3927.601\n",
      "Ep:61, loss:0.00003, loss_test:0.09292, lr:7.18e-03, fs:0.67081 (r=0.545,p=0.871),  time:64.358, tt:3990.207\n",
      "Ep:62, loss:0.00003, loss_test:0.09520, lr:7.11e-03, fs:0.64968 (r=0.515,p=0.879),  time:64.363, tt:4054.866\n",
      "Ep:63, loss:0.00003, loss_test:0.09581, lr:7.03e-03, fs:0.65823 (r=0.525,p=0.881),  time:64.348, tt:4118.250\n",
      "Ep:64, loss:0.00003, loss_test:0.09204, lr:6.96e-03, fs:0.68323 (r=0.556,p=0.887),  time:64.344, tt:4182.353\n",
      "Ep:65, loss:0.00003, loss_test:0.09533, lr:6.89e-03, fs:0.67500 (r=0.545,p=0.885),  time:64.365, tt:4248.080\n",
      "Ep:66, loss:0.00003, loss_test:0.09505, lr:6.83e-03, fs:0.65823 (r=0.525,p=0.881),  time:64.333, tt:4310.335\n",
      "Ep:67, loss:0.00003, loss_test:0.09387, lr:6.76e-03, fs:0.68323 (r=0.556,p=0.887),  time:64.315, tt:4373.444\n",
      "Ep:68, loss:0.00003, loss_test:0.09415, lr:6.69e-03, fs:0.65823 (r=0.525,p=0.881),  time:64.296, tt:4436.419\n",
      "Ep:69, loss:0.00003, loss_test:0.09417, lr:6.62e-03, fs:0.64968 (r=0.515,p=0.879),  time:64.309, tt:4501.610\n",
      "Ep:70, loss:0.00003, loss_test:0.09461, lr:6.56e-03, fs:0.65823 (r=0.525,p=0.881),  time:64.308, tt:4565.897\n",
      "Ep:71, loss:0.00003, loss_test:0.09641, lr:6.49e-03, fs:0.64968 (r=0.515,p=0.879),  time:64.288, tt:4628.712\n",
      "Ep:72, loss:0.00003, loss_test:0.09570, lr:6.43e-03, fs:0.65823 (r=0.525,p=0.881),  time:64.281, tt:4692.489\n",
      "Ep:73, loss:0.00003, loss_test:0.09598, lr:6.36e-03, fs:0.68323 (r=0.556,p=0.887),  time:64.288, tt:4757.328\n",
      "Ep:74, loss:0.00003, loss_test:0.09495, lr:6.30e-03, fs:0.67500 (r=0.545,p=0.885),  time:64.307, tt:4823.059\n",
      "Ep:75, loss:0.00002, loss_test:0.09721, lr:6.24e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.300, tt:4886.803\n",
      "Ep:76, loss:0.00002, loss_test:0.09656, lr:6.17e-03, fs:0.65385 (r=0.515,p=0.895),  time:64.319, tt:4952.578\n",
      "Ep:77, loss:0.00002, loss_test:0.09604, lr:6.11e-03, fs:0.64968 (r=0.515,p=0.879),  time:64.287, tt:5014.353\n",
      "Ep:78, loss:0.00002, loss_test:0.09834, lr:6.05e-03, fs:0.64968 (r=0.515,p=0.879),  time:64.279, tt:5078.077\n",
      "Ep:79, loss:0.00002, loss_test:0.09764, lr:5.99e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.287, tt:5142.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00002, loss_test:0.09602, lr:5.93e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.297, tt:5208.070\n",
      "Ep:81, loss:0.00002, loss_test:0.09829, lr:5.87e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.282, tt:5271.117\n",
      "Ep:82, loss:0.00002, loss_test:0.09619, lr:5.81e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.274, tt:5334.752\n",
      "Ep:83, loss:0.00002, loss_test:0.09644, lr:5.75e-03, fs:0.65385 (r=0.515,p=0.895),  time:64.273, tt:5398.897\n",
      "Ep:84, loss:0.00002, loss_test:0.09631, lr:5.70e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.245, tt:5460.806\n",
      "Ep:85, loss:0.00002, loss_test:0.09675, lr:5.64e-03, fs:0.65385 (r=0.515,p=0.895),  time:64.252, tt:5525.660\n",
      "Ep:86, loss:0.00002, loss_test:0.09750, lr:5.58e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.258, tt:5590.406\n",
      "Ep:87, loss:0.00002, loss_test:0.09632, lr:5.53e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.254, tt:5654.311\n",
      "Ep:88, loss:0.00002, loss_test:0.09692, lr:5.47e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.252, tt:5718.405\n",
      "Ep:89, loss:0.00002, loss_test:0.09746, lr:5.42e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.264, tt:5783.729\n",
      "Ep:90, loss:0.00002, loss_test:0.09872, lr:5.36e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.256, tt:5847.312\n",
      "Ep:91, loss:0.00002, loss_test:0.09755, lr:5.31e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.263, tt:5912.156\n",
      "Ep:92, loss:0.00002, loss_test:0.09838, lr:5.26e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.280, tt:5978.063\n",
      "Ep:93, loss:0.00002, loss_test:0.09781, lr:5.20e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.294, tt:6043.598\n",
      "Ep:94, loss:0.00002, loss_test:0.09806, lr:5.15e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.309, tt:6109.382\n",
      "Ep:95, loss:0.00002, loss_test:0.09968, lr:5.10e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.321, tt:6174.781\n",
      "Ep:96, loss:0.00002, loss_test:0.09754, lr:5.05e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.319, tt:6238.940\n",
      "Ep:97, loss:0.00002, loss_test:0.09862, lr:5.00e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.327, tt:6304.027\n",
      "Ep:98, loss:0.00002, loss_test:0.09945, lr:4.95e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.326, tt:6368.254\n",
      "Ep:99, loss:0.00002, loss_test:0.09834, lr:4.90e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.334, tt:6433.421\n",
      "Ep:100, loss:0.00002, loss_test:0.09904, lr:4.85e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.324, tt:6496.688\n",
      "Ep:101, loss:0.00002, loss_test:0.09743, lr:4.80e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.315, tt:6560.161\n",
      "Ep:102, loss:0.00001, loss_test:0.09898, lr:4.75e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.319, tt:6624.869\n",
      "Ep:103, loss:0.00001, loss_test:0.09840, lr:4.71e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.312, tt:6688.408\n",
      "Ep:104, loss:0.00001, loss_test:0.09838, lr:4.66e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.323, tt:6753.904\n",
      "Ep:105, loss:0.00001, loss_test:0.10042, lr:4.61e-03, fs:0.64516 (r=0.505,p=0.893),  time:64.332, tt:6819.140\n",
      "Ep:106, loss:0.00001, loss_test:0.09814, lr:4.57e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.305, tt:6880.660\n",
      "Ep:107, loss:0.00001, loss_test:0.10092, lr:4.52e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.326, tt:6947.215\n",
      "Ep:108, loss:0.00001, loss_test:0.09825, lr:4.48e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.329, tt:7011.910\n",
      "Ep:109, loss:0.00001, loss_test:0.09940, lr:4.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.343, tt:7077.753\n",
      "Ep:110, loss:0.00001, loss_test:0.10098, lr:4.39e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.335, tt:7141.133\n",
      "Ep:111, loss:0.00001, loss_test:0.09904, lr:4.34e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.328, tt:7204.708\n",
      "Ep:112, loss:0.00001, loss_test:0.09968, lr:4.30e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.340, tt:7270.464\n",
      "Ep:113, loss:0.00001, loss_test:0.09952, lr:4.26e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.332, tt:7333.795\n",
      "Ep:114, loss:0.00001, loss_test:0.09866, lr:4.21e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.329, tt:7397.830\n",
      "Ep:115, loss:0.00001, loss_test:0.10092, lr:4.17e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.325, tt:7461.670\n",
      "Ep:116, loss:0.00001, loss_test:0.09883, lr:4.13e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.338, tt:7527.524\n",
      "Ep:117, loss:0.00001, loss_test:0.10097, lr:4.09e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.340, tt:7592.131\n",
      "Ep:118, loss:0.00001, loss_test:0.09865, lr:4.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.336, tt:7655.950\n",
      "Ep:119, loss:0.00001, loss_test:0.09994, lr:4.01e-03, fs:0.64935 (r=0.505,p=0.909),  time:64.343, tt:7721.132\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.14647, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:95.248, tt:95.248\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00081, loss_test:0.14231, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:90.501, tt:181.002\n",
      "Ep:2, loss:0.00073, loss_test:0.13241, lr:1.00e-02, fs:0.58182 (r=0.646,p=0.529),  time:87.059, tt:261.177\n",
      "Ep:3, loss:0.00066, loss_test:0.13081, lr:1.00e-02, fs:0.60577 (r=0.636,p=0.578),  time:87.849, tt:351.396\n",
      "Ep:4, loss:0.00061, loss_test:0.12546, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:89.724, tt:448.618\n",
      "Ep:5, loss:0.00057, loss_test:0.12246, lr:1.00e-02, fs:0.65686 (r=0.677,p=0.638),  time:91.377, tt:548.261\n",
      "Ep:6, loss:0.00053, loss_test:0.12012, lr:1.00e-02, fs:0.64000 (r=0.646,p=0.634),  time:92.705, tt:648.937\n",
      "Ep:7, loss:0.00050, loss_test:0.11797, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:93.417, tt:747.335\n",
      "Ep:8, loss:0.00047, loss_test:0.12002, lr:1.00e-02, fs:0.66667 (r=0.626,p=0.713),  time:94.035, tt:846.314\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.11777, lr:1.00e-02, fs:0.67368 (r=0.646,p=0.703),  time:94.704, tt:947.036\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.11471, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:95.302, tt:1048.322\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00039, loss_test:0.11625, lr:1.00e-02, fs:0.69474 (r=0.667,p=0.725),  time:95.498, tt:1145.972\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00037, loss_test:0.11665, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:95.940, tt:1247.218\n",
      "Ep:13, loss:0.00034, loss_test:0.11740, lr:1.00e-02, fs:0.71508 (r=0.646,p=0.800),  time:96.077, tt:1345.073\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00032, loss_test:0.11705, lr:1.00e-02, fs:0.71508 (r=0.646,p=0.800),  time:96.011, tt:1440.171\n",
      "Ep:15, loss:0.00030, loss_test:0.11900, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:96.159, tt:1538.547\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.11676, lr:1.00e-02, fs:0.71111 (r=0.646,p=0.790),  time:96.349, tt:1637.937\n",
      "Ep:17, loss:0.00026, loss_test:0.12121, lr:1.00e-02, fs:0.69822 (r=0.596,p=0.843),  time:96.525, tt:1737.453\n",
      "Ep:18, loss:0.00024, loss_test:0.11856, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:96.671, tt:1836.745\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.11846, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:96.840, tt:1936.807\n",
      "Ep:20, loss:0.00021, loss_test:0.12042, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:96.860, tt:2034.058\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.11818, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:96.934, tt:2132.549\n",
      "Ep:22, loss:0.00018, loss_test:0.11587, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:97.003, tt:2231.063\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.11574, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:97.171, tt:2332.109\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.11722, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:97.297, tt:2432.427\n",
      "Ep:25, loss:0.00014, loss_test:0.11998, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:97.284, tt:2529.386\n",
      "Ep:26, loss:0.00013, loss_test:0.11433, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:97.351, tt:2628.464\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00012, loss_test:0.11349, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:97.364, tt:2726.206\n",
      "Ep:28, loss:0.00011, loss_test:0.12011, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:97.345, tt:2823.004\n",
      "Ep:29, loss:0.00011, loss_test:0.11931, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:97.373, tt:2921.199\n",
      "Ep:30, loss:0.00010, loss_test:0.12127, lr:1.00e-02, fs:0.74556 (r=0.636,p=0.900),  time:97.416, tt:3019.899\n",
      "Ep:31, loss:0.00009, loss_test:0.12558, lr:1.00e-02, fs:0.67516 (r=0.535,p=0.914),  time:97.323, tt:3114.326\n",
      "Ep:32, loss:0.00009, loss_test:0.12770, lr:1.00e-02, fs:0.73939 (r=0.616,p=0.924),  time:97.394, tt:3214.009\n",
      "Ep:33, loss:0.00008, loss_test:0.12404, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:97.413, tt:3312.056\n",
      "Ep:34, loss:0.00008, loss_test:0.12175, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:97.453, tt:3410.848\n",
      "Ep:35, loss:0.00007, loss_test:0.12592, lr:1.00e-02, fs:0.75449 (r=0.636,p=0.926),  time:97.510, tt:3510.373\n",
      "Ep:36, loss:0.00007, loss_test:0.12517, lr:1.00e-02, fs:0.68354 (r=0.545,p=0.915),  time:97.488, tt:3607.072\n",
      "Ep:37, loss:0.00007, loss_test:0.12621, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:97.535, tt:3706.342\n",
      "Ep:38, loss:0.00006, loss_test:0.12493, lr:9.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:97.561, tt:3804.861\n",
      "Ep:39, loss:0.00006, loss_test:0.12544, lr:9.80e-03, fs:0.76190 (r=0.646,p=0.928),  time:97.541, tt:3901.641\n",
      "Ep:40, loss:0.00006, loss_test:0.12911, lr:9.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:97.511, tt:3997.960\n",
      "Ep:41, loss:0.00005, loss_test:0.12683, lr:9.61e-03, fs:0.76190 (r=0.646,p=0.928),  time:97.539, tt:4096.651\n",
      "Ep:42, loss:0.00005, loss_test:0.12393, lr:9.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:97.519, tt:4193.319\n",
      "Ep:43, loss:0.00005, loss_test:0.12247, lr:9.41e-03, fs:0.76923 (r=0.657,p=0.929),  time:97.591, tt:4294.018\n",
      "Ep:44, loss:0.00005, loss_test:0.12694, lr:9.32e-03, fs:0.75904 (r=0.636,p=0.940),  time:97.641, tt:4393.867\n",
      "Ep:45, loss:0.00005, loss_test:0.12832, lr:9.23e-03, fs:0.75152 (r=0.626,p=0.939),  time:97.644, tt:4491.634\n",
      "Ep:46, loss:0.00004, loss_test:0.13212, lr:9.14e-03, fs:0.68790 (r=0.545,p=0.931),  time:97.665, tt:4590.251\n",
      "Ep:47, loss:0.00004, loss_test:0.12847, lr:9.04e-03, fs:0.75904 (r=0.636,p=0.940),  time:97.677, tt:4688.492\n",
      "Ep:48, loss:0.00004, loss_test:0.12795, lr:8.95e-03, fs:0.67097 (r=0.525,p=0.929),  time:97.742, tt:4789.342\n",
      "Ep:49, loss:0.00004, loss_test:0.13228, lr:8.86e-03, fs:0.75449 (r=0.636,p=0.926),  time:97.743, tt:4887.141\n",
      "Ep:50, loss:0.00004, loss_test:0.13237, lr:8.78e-03, fs:0.61745 (r=0.465,p=0.920),  time:97.785, tt:4987.044\n",
      "Ep:51, loss:0.00004, loss_test:0.13120, lr:8.69e-03, fs:0.68790 (r=0.545,p=0.931),  time:97.820, tt:5086.628\n",
      "Ep:52, loss:0.00004, loss_test:0.13444, lr:8.60e-03, fs:0.63576 (r=0.485,p=0.923),  time:97.812, tt:5184.031\n",
      "Ep:53, loss:0.00003, loss_test:0.13276, lr:8.51e-03, fs:0.62667 (r=0.475,p=0.922),  time:97.858, tt:5284.306\n",
      "Ep:54, loss:0.00003, loss_test:0.13306, lr:8.43e-03, fs:0.62667 (r=0.475,p=0.922),  time:97.835, tt:5380.938\n",
      "Ep:55, loss:0.00003, loss_test:0.13034, lr:8.35e-03, fs:0.72050 (r=0.586,p=0.935),  time:97.919, tt:5483.465\n",
      "Ep:56, loss:0.00003, loss_test:0.13322, lr:8.26e-03, fs:0.61745 (r=0.465,p=0.920),  time:97.893, tt:5579.924\n",
      "Ep:57, loss:0.00003, loss_test:0.13217, lr:8.18e-03, fs:0.61745 (r=0.465,p=0.920),  time:97.924, tt:5679.589\n",
      "Ep:58, loss:0.00003, loss_test:0.13671, lr:8.10e-03, fs:0.67949 (r=0.535,p=0.930),  time:97.947, tt:5778.900\n",
      "Ep:59, loss:0.00003, loss_test:0.13606, lr:8.02e-03, fs:0.57931 (r=0.424,p=0.913),  time:97.956, tt:5877.365\n",
      "Ep:60, loss:0.00003, loss_test:0.13666, lr:7.94e-03, fs:0.61745 (r=0.465,p=0.920),  time:97.986, tt:5977.169\n",
      "Ep:61, loss:0.00003, loss_test:0.13412, lr:7.86e-03, fs:0.69620 (r=0.556,p=0.932),  time:98.008, tt:6076.472\n",
      "Ep:62, loss:0.00003, loss_test:0.13263, lr:7.78e-03, fs:0.57931 (r=0.424,p=0.913),  time:98.053, tt:6177.315\n",
      "Ep:63, loss:0.00002, loss_test:0.13136, lr:7.70e-03, fs:0.68790 (r=0.545,p=0.931),  time:98.071, tt:6276.554\n",
      "Ep:64, loss:0.00002, loss_test:0.13251, lr:7.62e-03, fs:0.72050 (r=0.586,p=0.935),  time:98.020, tt:6371.313\n",
      "Ep:65, loss:0.00002, loss_test:0.13320, lr:7.55e-03, fs:0.68790 (r=0.545,p=0.931),  time:97.997, tt:6467.781\n",
      "Ep:66, loss:0.00002, loss_test:0.13003, lr:7.47e-03, fs:0.63576 (r=0.485,p=0.923),  time:98.003, tt:6566.232\n",
      "Ep:67, loss:0.00002, loss_test:0.13340, lr:7.40e-03, fs:0.68790 (r=0.545,p=0.931),  time:98.001, tt:6664.088\n",
      "Ep:68, loss:0.00002, loss_test:0.13634, lr:7.32e-03, fs:0.67097 (r=0.525,p=0.929),  time:97.986, tt:6761.004\n",
      "Ep:69, loss:0.00002, loss_test:0.13393, lr:7.25e-03, fs:0.62162 (r=0.465,p=0.939),  time:97.948, tt:6856.356\n",
      "Ep:70, loss:0.00002, loss_test:0.13425, lr:7.18e-03, fs:0.58333 (r=0.424,p=0.933),  time:97.951, tt:6954.555\n",
      "Ep:71, loss:0.00002, loss_test:0.13578, lr:7.11e-03, fs:0.61224 (r=0.455,p=0.938),  time:97.988, tt:7055.150\n",
      "Ep:72, loss:0.00002, loss_test:0.13533, lr:7.03e-03, fs:0.66225 (r=0.505,p=0.962),  time:97.971, tt:7151.854\n",
      "Ep:73, loss:0.00002, loss_test:0.13862, lr:6.96e-03, fs:0.57746 (r=0.414,p=0.953),  time:97.964, tt:7249.345\n",
      "Ep:74, loss:0.00002, loss_test:0.13762, lr:6.89e-03, fs:0.58741 (r=0.424,p=0.955),  time:97.967, tt:7347.516\n",
      "Ep:75, loss:0.00002, loss_test:0.13624, lr:6.83e-03, fs:0.64430 (r=0.485,p=0.960),  time:97.981, tt:7446.581\n",
      "Ep:76, loss:0.00002, loss_test:0.13649, lr:6.76e-03, fs:0.57746 (r=0.414,p=0.953),  time:97.971, tt:7543.736\n",
      "Ep:77, loss:0.00002, loss_test:0.13538, lr:6.69e-03, fs:0.57746 (r=0.414,p=0.953),  time:97.980, tt:7642.436\n",
      "Ep:78, loss:0.00002, loss_test:0.13536, lr:6.62e-03, fs:0.67974 (r=0.525,p=0.963),  time:98.002, tt:7742.128\n",
      "Ep:79, loss:0.00001, loss_test:0.13569, lr:6.56e-03, fs:0.65333 (r=0.495,p=0.961),  time:97.996, tt:7839.673\n",
      "Ep:80, loss:0.00001, loss_test:0.13652, lr:6.49e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.005, tt:7938.377\n",
      "Ep:81, loss:0.00001, loss_test:0.13516, lr:6.43e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.009, tt:8036.744\n",
      "Ep:82, loss:0.00001, loss_test:0.13765, lr:6.36e-03, fs:0.69677 (r=0.545,p=0.964),  time:97.988, tt:8132.991\n",
      "Ep:83, loss:0.00001, loss_test:0.13452, lr:6.30e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.974, tt:8229.805\n",
      "Ep:84, loss:0.00001, loss_test:0.13591, lr:6.24e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.973, tt:8327.713\n",
      "Ep:85, loss:0.00001, loss_test:0.13790, lr:6.17e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.962, tt:8424.751\n",
      "Ep:86, loss:0.00001, loss_test:0.13885, lr:6.11e-03, fs:0.67974 (r=0.525,p=0.963),  time:97.971, tt:8523.476\n",
      "Ep:87, loss:0.00001, loss_test:0.13841, lr:6.05e-03, fs:0.67974 (r=0.525,p=0.963),  time:97.968, tt:8621.167\n",
      "Ep:88, loss:0.00001, loss_test:0.13636, lr:5.99e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.973, tt:8719.623\n",
      "Ep:89, loss:0.00001, loss_test:0.13843, lr:5.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.989, tt:8818.988\n",
      "Ep:90, loss:0.00001, loss_test:0.13682, lr:5.87e-03, fs:0.67974 (r=0.525,p=0.963),  time:97.978, tt:8915.990\n",
      "Ep:91, loss:0.00001, loss_test:0.13621, lr:5.81e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.017, tt:9017.561\n",
      "Ep:92, loss:0.00001, loss_test:0.13675, lr:5.75e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.020, tt:9115.840\n",
      "Ep:93, loss:0.00001, loss_test:0.13903, lr:5.70e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.013, tt:9213.203\n",
      "Ep:94, loss:0.00001, loss_test:0.13758, lr:5.64e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.997, tt:9309.710\n",
      "Ep:95, loss:0.00001, loss_test:0.13737, lr:5.58e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.987, tt:9406.764\n",
      "Ep:96, loss:0.00001, loss_test:0.13824, lr:5.53e-03, fs:0.64430 (r=0.485,p=0.960),  time:98.008, tt:9506.787\n",
      "Ep:97, loss:0.00001, loss_test:0.13818, lr:5.47e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.046, tt:9608.503\n",
      "Ep:98, loss:0.00001, loss_test:0.13945, lr:5.42e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.024, tt:9704.418\n",
      "Ep:99, loss:0.00001, loss_test:0.13757, lr:5.36e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.074, tt:9807.414\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.14498, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:96.536, tt:96.536\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00081, loss_test:0.13947, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:95.435, tt:190.869\n",
      "Ep:2, loss:0.00074, loss_test:0.12161, lr:1.00e-02, fs:0.64348 (r=0.747,p=0.565),  time:90.738, tt:272.213\n",
      "Ep:3, loss:0.00067, loss_test:0.11954, lr:1.00e-02, fs:0.63256 (r=0.687,p=0.586),  time:90.522, tt:362.089\n",
      "Ep:4, loss:0.00063, loss_test:0.11167, lr:1.00e-02, fs:0.66667 (r=0.677,p=0.657),  time:91.911, tt:459.553\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00058, loss_test:0.10774, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:93.134, tt:558.803\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00055, loss_test:0.10475, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:93.616, tt:655.309\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00052, loss_test:0.10512, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:94.038, tt:752.306\n",
      "Ep:8, loss:0.00049, loss_test:0.10156, lr:1.00e-02, fs:0.68817 (r=0.646,p=0.736),  time:94.552, tt:850.965\n",
      "Ep:9, loss:0.00046, loss_test:0.09898, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:94.441, tt:944.406\n",
      "Ep:10, loss:0.00044, loss_test:0.09857, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:94.818, tt:1042.993\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.09985, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:95.071, tt:1140.855\n",
      "Ep:12, loss:0.00039, loss_test:0.09860, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:95.292, tt:1238.792\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00037, loss_test:0.09612, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:95.481, tt:1336.729\n",
      "Ep:14, loss:0.00035, loss_test:0.09361, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:95.429, tt:1431.433\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00032, loss_test:0.09623, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:95.469, tt:1527.498\n",
      "Ep:16, loss:0.00030, loss_test:0.09465, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:95.454, tt:1622.717\n",
      "Ep:17, loss:0.00028, loss_test:0.09488, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:95.673, tt:1722.121\n",
      "Ep:18, loss:0.00026, loss_test:0.09554, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:95.795, tt:1820.109\n",
      "Ep:19, loss:0.00024, loss_test:0.09755, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:95.852, tt:1917.035\n",
      "Ep:20, loss:0.00023, loss_test:0.09571, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:95.896, tt:2013.815\n",
      "Ep:21, loss:0.00020, loss_test:0.09336, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:95.947, tt:2110.827\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.09349, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:95.933, tt:2206.448\n",
      "Ep:23, loss:0.00017, loss_test:0.09324, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:95.852, tt:2300.459\n",
      "Ep:24, loss:0.00016, loss_test:0.09585, lr:1.00e-02, fs:0.74556 (r=0.636,p=0.900),  time:95.860, tt:2396.510\n",
      "Ep:25, loss:0.00015, loss_test:0.09670, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:95.965, tt:2495.089\n",
      "Ep:26, loss:0.00014, loss_test:0.09785, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:96.059, tt:2593.602\n",
      "Ep:27, loss:0.00012, loss_test:0.10383, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:96.081, tt:2690.277\n",
      "Ep:28, loss:0.00011, loss_test:0.09980, lr:1.00e-02, fs:0.70732 (r=0.586,p=0.892),  time:96.132, tt:2787.820\n",
      "Ep:29, loss:0.00011, loss_test:0.10525, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:96.072, tt:2882.162\n",
      "Ep:30, loss:0.00010, loss_test:0.10425, lr:1.00e-02, fs:0.71166 (r=0.586,p=0.906),  time:96.167, tt:2981.166\n",
      "Ep:31, loss:0.00009, loss_test:0.09946, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:96.217, tt:3078.938\n",
      "Ep:32, loss:0.00009, loss_test:0.09532, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:96.215, tt:3175.105\n",
      "Ep:33, loss:0.00008, loss_test:0.09936, lr:9.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:96.253, tt:3272.604\n",
      "Ep:34, loss:0.00008, loss_test:0.09701, lr:9.80e-03, fs:0.73054 (r=0.616,p=0.897),  time:96.329, tt:3371.511\n",
      "Ep:35, loss:0.00007, loss_test:0.09503, lr:9.70e-03, fs:0.73494 (r=0.616,p=0.910),  time:96.349, tt:3468.550\n",
      "Ep:36, loss:0.00007, loss_test:0.09790, lr:9.61e-03, fs:0.73939 (r=0.616,p=0.924),  time:96.350, tt:3564.961\n",
      "Ep:37, loss:0.00006, loss_test:0.09849, lr:9.51e-03, fs:0.71951 (r=0.596,p=0.908),  time:96.346, tt:3661.152\n",
      "Ep:38, loss:0.00006, loss_test:0.09894, lr:9.41e-03, fs:0.72393 (r=0.596,p=0.922),  time:96.376, tt:3758.668\n",
      "Ep:39, loss:0.00006, loss_test:0.10213, lr:9.32e-03, fs:0.75449 (r=0.636,p=0.926),  time:96.396, tt:3855.850\n",
      "Ep:40, loss:0.00005, loss_test:0.10007, lr:9.23e-03, fs:0.73620 (r=0.606,p=0.938),  time:96.486, tt:3955.922\n",
      "Ep:41, loss:0.00005, loss_test:0.10541, lr:9.14e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.542, tt:4054.773\n",
      "Ep:42, loss:0.00005, loss_test:0.10110, lr:9.04e-03, fs:0.73292 (r=0.596,p=0.952),  time:96.527, tt:4150.679\n",
      "Ep:43, loss:0.00005, loss_test:0.10311, lr:8.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:96.588, tt:4249.866\n",
      "Ep:44, loss:0.00004, loss_test:0.10208, lr:8.86e-03, fs:0.74390 (r=0.616,p=0.938),  time:96.595, tt:4346.762\n",
      "Ep:45, loss:0.00004, loss_test:0.09925, lr:8.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:96.649, tt:4445.853\n",
      "Ep:46, loss:0.00004, loss_test:0.10187, lr:8.69e-03, fs:0.73939 (r=0.616,p=0.924),  time:96.694, tt:4544.624\n",
      "Ep:47, loss:0.00004, loss_test:0.10231, lr:8.60e-03, fs:0.73939 (r=0.616,p=0.924),  time:96.653, tt:4639.327\n",
      "Ep:48, loss:0.00004, loss_test:0.10258, lr:8.51e-03, fs:0.73171 (r=0.606,p=0.923),  time:96.654, tt:4736.043\n",
      "Ep:49, loss:0.00004, loss_test:0.10402, lr:8.43e-03, fs:0.73292 (r=0.596,p=0.952),  time:96.593, tt:4829.635\n",
      "Ep:50, loss:0.00003, loss_test:0.10561, lr:8.35e-03, fs:0.73292 (r=0.596,p=0.952),  time:96.576, tt:4925.351\n",
      "Ep:51, loss:0.00003, loss_test:0.10737, lr:8.26e-03, fs:0.73292 (r=0.596,p=0.952),  time:96.630, tt:5024.782\n",
      "Ep:52, loss:0.00003, loss_test:0.10580, lr:8.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:96.622, tt:5120.989\n",
      "Ep:53, loss:0.00003, loss_test:0.10048, lr:8.10e-03, fs:0.74390 (r=0.616,p=0.938),  time:96.639, tt:5218.496\n",
      "Ep:54, loss:0.00003, loss_test:0.10362, lr:8.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:96.635, tt:5314.927\n",
      "Ep:55, loss:0.00003, loss_test:0.10970, lr:7.94e-03, fs:0.74847 (r=0.616,p=0.953),  time:96.615, tt:5410.426\n",
      "Ep:56, loss:0.00003, loss_test:0.10734, lr:7.86e-03, fs:0.74074 (r=0.606,p=0.952),  time:96.648, tt:5508.941\n",
      "Ep:57, loss:0.00003, loss_test:0.10752, lr:7.78e-03, fs:0.74074 (r=0.606,p=0.952),  time:96.660, tt:5606.304\n",
      "Ep:58, loss:0.00003, loss_test:0.10633, lr:7.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:96.661, tt:5702.981\n",
      "Ep:59, loss:0.00002, loss_test:0.10646, lr:7.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:96.675, tt:5800.524\n",
      "Ep:60, loss:0.00002, loss_test:0.10847, lr:7.55e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.684, tt:5897.736\n",
      "Ep:61, loss:0.00002, loss_test:0.11000, lr:7.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.706, tt:5995.772\n",
      "Ep:62, loss:0.00002, loss_test:0.10719, lr:7.40e-03, fs:0.74074 (r=0.606,p=0.952),  time:96.723, tt:6093.520\n",
      "Ep:63, loss:0.00002, loss_test:0.10806, lr:7.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:96.726, tt:6190.443\n",
      "Ep:64, loss:0.00002, loss_test:0.10846, lr:7.25e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.764, tt:6289.631\n",
      "Ep:65, loss:0.00002, loss_test:0.10719, lr:7.18e-03, fs:0.74847 (r=0.616,p=0.953),  time:96.743, tt:6385.030\n",
      "Ep:66, loss:0.00002, loss_test:0.10755, lr:7.11e-03, fs:0.72500 (r=0.586,p=0.951),  time:96.754, tt:6482.526\n",
      "Ep:67, loss:0.00002, loss_test:0.10817, lr:7.03e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.741, tt:6578.357\n",
      "Ep:68, loss:0.00002, loss_test:0.10806, lr:6.96e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.764, tt:6676.745\n",
      "Ep:69, loss:0.00002, loss_test:0.10898, lr:6.89e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.778, tt:6774.462\n",
      "Ep:70, loss:0.00002, loss_test:0.11026, lr:6.83e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.799, tt:6872.703\n",
      "Ep:71, loss:0.00002, loss_test:0.10909, lr:6.76e-03, fs:0.72500 (r=0.586,p=0.951),  time:96.785, tt:6968.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00002, loss_test:0.11112, lr:6.69e-03, fs:0.74534 (r=0.606,p=0.968),  time:96.778, tt:7064.807\n",
      "Ep:73, loss:0.00002, loss_test:0.11203, lr:6.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.762, tt:7160.374\n",
      "Ep:74, loss:0.00002, loss_test:0.11177, lr:6.56e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.772, tt:7257.921\n",
      "Ep:75, loss:0.00002, loss_test:0.11185, lr:6.49e-03, fs:0.72956 (r=0.586,p=0.967),  time:96.768, tt:7354.361\n",
      "Ep:76, loss:0.00002, loss_test:0.11030, lr:6.43e-03, fs:0.73292 (r=0.596,p=0.952),  time:96.780, tt:7452.064\n",
      "Ep:77, loss:0.00002, loss_test:0.11066, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.803, tt:7550.612\n",
      "Ep:78, loss:0.00002, loss_test:0.11233, lr:6.30e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.810, tt:7648.003\n",
      "Ep:79, loss:0.00002, loss_test:0.11020, lr:6.24e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.846, tt:7747.690\n",
      "Ep:80, loss:0.00001, loss_test:0.11167, lr:6.17e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.854, tt:7845.209\n",
      "Ep:81, loss:0.00001, loss_test:0.11365, lr:6.11e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.879, tt:7944.044\n",
      "Ep:82, loss:0.00001, loss_test:0.11134, lr:6.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:96.874, tt:8040.562\n",
      "Ep:83, loss:0.00001, loss_test:0.11319, lr:5.99e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.877, tt:8137.706\n",
      "Ep:84, loss:0.00001, loss_test:0.11246, lr:5.93e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.853, tt:8232.525\n",
      "Ep:85, loss:0.00001, loss_test:0.11408, lr:5.87e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.843, tt:8328.465\n",
      "Ep:86, loss:0.00001, loss_test:0.11273, lr:5.81e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.853, tt:8426.172\n",
      "Ep:87, loss:0.00001, loss_test:0.11366, lr:5.75e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.877, tt:8525.146\n",
      "Ep:88, loss:0.00001, loss_test:0.11482, lr:5.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.901, tt:8624.226\n",
      "Ep:89, loss:0.00001, loss_test:0.11472, lr:5.64e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.933, tt:8723.949\n",
      "Ep:90, loss:0.00001, loss_test:0.11364, lr:5.58e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.922, tt:8819.924\n",
      "Ep:91, loss:0.00001, loss_test:0.11509, lr:5.53e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.920, tt:8916.673\n",
      "Ep:92, loss:0.00001, loss_test:0.11497, lr:5.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.919, tt:9013.488\n",
      "Ep:93, loss:0.00001, loss_test:0.11402, lr:5.42e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.929, tt:9111.323\n",
      "Ep:94, loss:0.00001, loss_test:0.11437, lr:5.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.938, tt:9209.106\n",
      "Ep:95, loss:0.00001, loss_test:0.11498, lr:5.31e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.932, tt:9305.440\n",
      "Ep:96, loss:0.00001, loss_test:0.11351, lr:5.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.939, tt:9403.128\n",
      "Ep:97, loss:0.00001, loss_test:0.11490, lr:5.20e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.958, tt:9501.872\n",
      "Ep:98, loss:0.00001, loss_test:0.11564, lr:5.15e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.933, tt:9596.355\n",
      "Ep:99, loss:0.00001, loss_test:0.11501, lr:5.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:96.975, tt:9697.533\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00097, loss_test:0.13940, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:113.576, tt:113.576\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00091, loss_test:0.12283, lr:1.00e-02, fs:0.60606 (r=0.707,p=0.530),  time:114.273, tt:228.545\n",
      "Ep:2, loss:0.00081, loss_test:0.11951, lr:1.00e-02, fs:0.63725 (r=0.657,p=0.619),  time:105.351, tt:316.053\n",
      "Ep:3, loss:0.00074, loss_test:0.11207, lr:1.00e-02, fs:0.64921 (r=0.626,p=0.674),  time:107.447, tt:429.788\n",
      "Ep:4, loss:0.00067, loss_test:0.10770, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:108.619, tt:543.095\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00062, loss_test:0.10399, lr:1.00e-02, fs:0.66304 (r=0.616,p=0.718),  time:109.662, tt:657.970\n",
      "Ep:6, loss:0.00057, loss_test:0.10309, lr:1.00e-02, fs:0.65169 (r=0.586,p=0.734),  time:110.714, tt:775.001\n",
      "Ep:7, loss:0.00052, loss_test:0.10188, lr:1.00e-02, fs:0.64804 (r=0.586,p=0.725),  time:111.503, tt:892.024\n",
      "Ep:8, loss:0.00048, loss_test:0.10253, lr:1.00e-02, fs:0.67045 (r=0.596,p=0.766),  time:111.772, tt:1005.952\n",
      "Ep:9, loss:0.00045, loss_test:0.10308, lr:1.00e-02, fs:0.69767 (r=0.606,p=0.822),  time:112.213, tt:1122.133\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00041, loss_test:0.10202, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:112.595, tt:1238.540\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00037, loss_test:0.10377, lr:1.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:112.796, tt:1353.554\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.10404, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:112.885, tt:1467.511\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.10377, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:112.958, tt:1581.417\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00028, loss_test:0.10456, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:112.997, tt:1694.951\n",
      "Ep:15, loss:0.00025, loss_test:0.10132, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:112.989, tt:1807.830\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.10301, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:113.217, tt:1924.685\n",
      "Ep:17, loss:0.00021, loss_test:0.10320, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:113.277, tt:2038.984\n",
      "Ep:18, loss:0.00019, loss_test:0.10631, lr:1.00e-02, fs:0.73494 (r=0.616,p=0.910),  time:113.308, tt:2152.860\n",
      "Ep:19, loss:0.00017, loss_test:0.10098, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:113.420, tt:2268.401\n",
      "Ep:20, loss:0.00016, loss_test:0.10015, lr:1.00e-02, fs:0.73563 (r=0.646,p=0.853),  time:113.601, tt:2385.622\n",
      "Ep:21, loss:0.00015, loss_test:0.10342, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:113.686, tt:2501.098\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.10606, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:113.647, tt:2613.880\n",
      "Ep:23, loss:0.00012, loss_test:0.10874, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:113.678, tt:2728.271\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.10918, lr:1.00e-02, fs:0.72050 (r=0.586,p=0.935),  time:113.654, tt:2841.341\n",
      "Ep:25, loss:0.00011, loss_test:0.10924, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:113.661, tt:2955.176\n",
      "Ep:26, loss:0.00010, loss_test:0.11248, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:113.586, tt:3066.826\n",
      "Ep:27, loss:0.00009, loss_test:0.11455, lr:1.00e-02, fs:0.72500 (r=0.586,p=0.951),  time:113.676, tt:3182.925\n",
      "Ep:28, loss:0.00009, loss_test:0.11682, lr:1.00e-02, fs:0.72152 (r=0.576,p=0.966),  time:113.784, tt:3299.744\n",
      "Ep:29, loss:0.00008, loss_test:0.11637, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:113.801, tt:3414.033\n",
      "Ep:30, loss:0.00007, loss_test:0.11546, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:113.851, tt:3529.389\n",
      "Ep:31, loss:0.00007, loss_test:0.11653, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:113.832, tt:3642.636\n",
      "Ep:32, loss:0.00006, loss_test:0.11579, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:113.857, tt:3757.268\n",
      "Ep:33, loss:0.00006, loss_test:0.11696, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:113.948, tt:3874.215\n",
      "Ep:34, loss:0.00006, loss_test:0.11807, lr:1.00e-02, fs:0.71698 (r=0.576,p=0.950),  time:113.985, tt:3989.467\n",
      "Ep:35, loss:0.00005, loss_test:0.11921, lr:9.90e-03, fs:0.71698 (r=0.576,p=0.950),  time:113.998, tt:4103.923\n",
      "Ep:36, loss:0.00005, loss_test:0.12064, lr:9.80e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.090, tt:4221.330\n",
      "Ep:37, loss:0.00005, loss_test:0.11829, lr:9.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.213, tt:4340.081\n",
      "Ep:38, loss:0.00004, loss_test:0.12242, lr:9.61e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.287, tt:4457.180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00004, loss_test:0.11881, lr:9.51e-03, fs:0.71250 (r=0.576,p=0.934),  time:114.300, tt:4571.987\n",
      "Ep:40, loss:0.00004, loss_test:0.12325, lr:9.41e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.277, tt:4685.367\n",
      "Ep:41, loss:0.00003, loss_test:0.12295, lr:9.32e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.253, tt:4798.630\n",
      "Ep:42, loss:0.00003, loss_test:0.12179, lr:9.23e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.168, tt:4909.234\n",
      "Ep:43, loss:0.00003, loss_test:0.12501, lr:9.14e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.125, tt:5021.513\n",
      "Ep:44, loss:0.00003, loss_test:0.12751, lr:9.04e-03, fs:0.70064 (r=0.556,p=0.948),  time:114.192, tt:5138.637\n",
      "Ep:45, loss:0.00003, loss_test:0.12591, lr:8.95e-03, fs:0.64901 (r=0.495,p=0.942),  time:114.162, tt:5251.453\n",
      "Ep:46, loss:0.00003, loss_test:0.12474, lr:8.86e-03, fs:0.70886 (r=0.566,p=0.949),  time:114.147, tt:5364.905\n",
      "Ep:47, loss:0.00002, loss_test:0.12628, lr:8.78e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.125, tt:5478.024\n",
      "Ep:48, loss:0.00002, loss_test:0.12616, lr:8.69e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.139, tt:5592.791\n",
      "Ep:49, loss:0.00002, loss_test:0.12638, lr:8.60e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.162, tt:5708.100\n",
      "Ep:50, loss:0.00002, loss_test:0.12567, lr:8.51e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.222, tt:5825.299\n",
      "Ep:51, loss:0.00002, loss_test:0.12671, lr:8.43e-03, fs:0.66667 (r=0.515,p=0.944),  time:114.251, tt:5941.066\n",
      "Ep:52, loss:0.00002, loss_test:0.12749, lr:8.35e-03, fs:0.71698 (r=0.576,p=0.950),  time:114.264, tt:6056.005\n",
      "Ep:53, loss:0.00002, loss_test:0.12927, lr:8.26e-03, fs:0.64000 (r=0.485,p=0.941),  time:114.282, tt:6171.251\n",
      "Ep:54, loss:0.00002, loss_test:0.12836, lr:8.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:114.289, tt:6285.906\n",
      "Ep:55, loss:0.00002, loss_test:0.12729, lr:8.10e-03, fs:0.70886 (r=0.566,p=0.949),  time:114.301, tt:6400.829\n",
      "Ep:56, loss:0.00002, loss_test:0.12735, lr:8.02e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.328, tt:6516.681\n",
      "Ep:57, loss:0.00002, loss_test:0.12861, lr:7.94e-03, fs:0.66667 (r=0.515,p=0.944),  time:114.357, tt:6632.681\n",
      "Ep:58, loss:0.00002, loss_test:0.12887, lr:7.86e-03, fs:0.64000 (r=0.485,p=0.941),  time:114.387, tt:6748.832\n",
      "Ep:59, loss:0.00001, loss_test:0.12686, lr:7.78e-03, fs:0.65789 (r=0.505,p=0.943),  time:114.416, tt:6864.947\n",
      "Ep:60, loss:0.00001, loss_test:0.12774, lr:7.70e-03, fs:0.68387 (r=0.535,p=0.946),  time:114.429, tt:6980.193\n",
      "Ep:61, loss:0.00001, loss_test:0.12748, lr:7.62e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.450, tt:7095.916\n",
      "Ep:62, loss:0.00001, loss_test:0.12794, lr:7.55e-03, fs:0.67532 (r=0.525,p=0.945),  time:114.403, tt:7207.376\n",
      "Ep:63, loss:0.00001, loss_test:0.12690, lr:7.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:114.413, tt:7322.451\n",
      "Ep:64, loss:0.00001, loss_test:0.12829, lr:7.40e-03, fs:0.64000 (r=0.485,p=0.941),  time:114.414, tt:7436.879\n",
      "Ep:65, loss:0.00001, loss_test:0.12818, lr:7.32e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.462, tt:7554.522\n",
      "Ep:66, loss:0.00001, loss_test:0.12939, lr:7.25e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.448, tt:7667.997\n",
      "Ep:67, loss:0.00001, loss_test:0.12878, lr:7.18e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.499, tt:7785.912\n",
      "Ep:68, loss:0.00001, loss_test:0.12981, lr:7.11e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.543, tt:7903.435\n",
      "Ep:69, loss:0.00001, loss_test:0.13173, lr:7.03e-03, fs:0.63514 (r=0.475,p=0.959),  time:114.563, tt:8019.439\n",
      "Ep:70, loss:0.00001, loss_test:0.12993, lr:6.96e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.549, tt:8133.014\n",
      "Ep:71, loss:0.00001, loss_test:0.12853, lr:6.89e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.573, tt:8249.273\n",
      "Ep:72, loss:0.00001, loss_test:0.12935, lr:6.83e-03, fs:0.63514 (r=0.475,p=0.959),  time:114.592, tt:8365.248\n",
      "Ep:73, loss:0.00001, loss_test:0.12869, lr:6.76e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.605, tt:8480.760\n",
      "Ep:74, loss:0.00001, loss_test:0.12938, lr:6.69e-03, fs:0.63514 (r=0.475,p=0.959),  time:114.618, tt:8596.315\n",
      "Ep:75, loss:0.00001, loss_test:0.12890, lr:6.62e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.610, tt:8710.346\n",
      "Ep:76, loss:0.00001, loss_test:0.12892, lr:6.56e-03, fs:0.63087 (r=0.475,p=0.940),  time:114.622, tt:8825.904\n",
      "Ep:77, loss:0.00001, loss_test:0.13103, lr:6.49e-03, fs:0.63514 (r=0.475,p=0.959),  time:114.626, tt:8940.848\n",
      "Ep:78, loss:0.00001, loss_test:0.13039, lr:6.43e-03, fs:0.63514 (r=0.475,p=0.959),  time:114.647, tt:9057.075\n",
      "Ep:79, loss:0.00001, loss_test:0.13016, lr:6.36e-03, fs:0.63514 (r=0.475,p=0.959),  time:114.649, tt:9171.915\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14326, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:113.013, tt:113.013\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00092, loss_test:0.13138, lr:1.00e-02, fs:0.63118 (r=0.838,p=0.506),  time:112.762, tt:225.523\n",
      "Ep:2, loss:0.00082, loss_test:0.12143, lr:1.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:106.501, tt:319.503\n",
      "Ep:3, loss:0.00075, loss_test:0.11350, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:108.177, tt:432.707\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00069, loss_test:0.10729, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:109.657, tt:548.286\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00063, loss_test:0.10222, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:109.895, tt:659.367\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00058, loss_test:0.09686, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:110.374, tt:772.615\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00054, loss_test:0.09307, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:110.639, tt:885.113\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00051, loss_test:0.08984, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:111.243, tt:1001.183\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00047, loss_test:0.08585, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:111.431, tt:1114.311\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00043, loss_test:0.08451, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:111.541, tt:1226.957\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.08212, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:111.707, tt:1340.483\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00036, loss_test:0.08436, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:112.094, tt:1457.221\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00033, loss_test:0.08041, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:112.217, tt:1571.043\n",
      "Ep:14, loss:0.00030, loss_test:0.08132, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:112.315, tt:1684.722\n",
      "Ep:15, loss:0.00027, loss_test:0.07788, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:112.411, tt:1798.569\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.07892, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:112.567, tt:1913.631\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.07828, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:112.674, tt:2028.133\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.07873, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:112.882, tt:2144.767\n",
      "Ep:19, loss:0.00019, loss_test:0.07357, lr:1.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:113.114, tt:2262.273\n",
      "Ep:20, loss:0.00017, loss_test:0.07584, lr:1.00e-02, fs:0.83721 (r=0.727,p=0.986),  time:113.111, tt:2375.338\n",
      "Ep:21, loss:0.00016, loss_test:0.07674, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:113.288, tt:2492.340\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07162, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:113.345, tt:2606.933\n",
      "Ep:23, loss:0.00013, loss_test:0.07187, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:113.258, tt:2718.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00012, loss_test:0.07207, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:113.287, tt:2832.182\n",
      "Ep:25, loss:0.00011, loss_test:0.06989, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:113.316, tt:2946.225\n",
      "Ep:26, loss:0.00011, loss_test:0.07203, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:113.346, tt:3060.348\n",
      "Ep:27, loss:0.00010, loss_test:0.07322, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:113.401, tt:3175.224\n",
      "Ep:28, loss:0.00009, loss_test:0.07084, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:113.382, tt:3288.072\n",
      "Ep:29, loss:0.00009, loss_test:0.07130, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:113.421, tt:3402.615\n",
      "Ep:30, loss:0.00008, loss_test:0.07521, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:113.442, tt:3516.714\n",
      "Ep:31, loss:0.00008, loss_test:0.07397, lr:1.00e-02, fs:0.79518 (r=0.667,p=0.985),  time:113.517, tt:3632.528\n",
      "Ep:32, loss:0.00007, loss_test:0.07485, lr:1.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:113.495, tt:3745.335\n",
      "Ep:33, loss:0.00007, loss_test:0.07704, lr:9.90e-03, fs:0.79518 (r=0.667,p=0.985),  time:113.526, tt:3859.901\n",
      "Ep:34, loss:0.00006, loss_test:0.07449, lr:9.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.520, tt:3973.202\n",
      "Ep:35, loss:0.00006, loss_test:0.07704, lr:9.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.539, tt:4087.401\n",
      "Ep:36, loss:0.00006, loss_test:0.07593, lr:9.61e-03, fs:0.79290 (r=0.677,p=0.957),  time:113.572, tt:4202.161\n",
      "Ep:37, loss:0.00005, loss_test:0.07621, lr:9.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.589, tt:4316.389\n",
      "Ep:38, loss:0.00005, loss_test:0.07561, lr:9.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.613, tt:4430.903\n",
      "Ep:39, loss:0.00005, loss_test:0.07754, lr:9.32e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.658, tt:4546.334\n",
      "Ep:40, loss:0.00004, loss_test:0.07880, lr:9.23e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.667, tt:4660.361\n",
      "Ep:41, loss:0.00004, loss_test:0.07935, lr:9.14e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.677, tt:4774.444\n",
      "Ep:42, loss:0.00004, loss_test:0.08088, lr:9.04e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.725, tt:4890.184\n",
      "Ep:43, loss:0.00004, loss_test:0.08096, lr:8.95e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.772, tt:5005.987\n",
      "Ep:44, loss:0.00003, loss_test:0.08250, lr:8.86e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.828, tt:5122.246\n",
      "Ep:45, loss:0.00003, loss_test:0.08342, lr:8.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.804, tt:5234.965\n",
      "Ep:46, loss:0.00003, loss_test:0.08480, lr:8.69e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.875, tt:5352.145\n",
      "Ep:47, loss:0.00003, loss_test:0.08355, lr:8.60e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.883, tt:5466.371\n",
      "Ep:48, loss:0.00003, loss_test:0.08308, lr:8.51e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.911, tt:5581.619\n",
      "Ep:49, loss:0.00003, loss_test:0.08390, lr:8.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.901, tt:5695.029\n",
      "Ep:50, loss:0.00002, loss_test:0.08485, lr:8.35e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.889, tt:5808.360\n",
      "Ep:51, loss:0.00002, loss_test:0.08488, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.913, tt:5923.452\n",
      "Ep:52, loss:0.00002, loss_test:0.08459, lr:8.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.947, tt:6039.215\n",
      "Ep:53, loss:0.00002, loss_test:0.08404, lr:8.10e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.951, tt:6153.366\n",
      "Ep:54, loss:0.00002, loss_test:0.08426, lr:8.02e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.950, tt:6267.224\n",
      "Ep:55, loss:0.00002, loss_test:0.08473, lr:7.94e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.954, tt:6381.426\n",
      "Ep:56, loss:0.00002, loss_test:0.08396, lr:7.86e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.968, tt:6496.198\n",
      "Ep:57, loss:0.00002, loss_test:0.08441, lr:7.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.921, tt:6607.417\n",
      "Ep:58, loss:0.00002, loss_test:0.08491, lr:7.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:113.931, tt:6721.940\n",
      "Ep:59, loss:0.00002, loss_test:0.08493, lr:7.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.930, tt:6835.803\n",
      "Ep:60, loss:0.00002, loss_test:0.08543, lr:7.55e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.904, tt:6948.175\n",
      "Ep:61, loss:0.00002, loss_test:0.08502, lr:7.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.919, tt:7062.998\n",
      "Ep:62, loss:0.00001, loss_test:0.08470, lr:7.40e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.917, tt:7176.766\n",
      "Ep:63, loss:0.00001, loss_test:0.08540, lr:7.32e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.926, tt:7291.270\n",
      "Ep:64, loss:0.00001, loss_test:0.08487, lr:7.25e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.935, tt:7405.806\n",
      "Ep:65, loss:0.00001, loss_test:0.08523, lr:7.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.979, tt:7522.605\n",
      "Ep:66, loss:0.00001, loss_test:0.08594, lr:7.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.013, tt:7638.887\n",
      "Ep:67, loss:0.00001, loss_test:0.08609, lr:7.03e-03, fs:0.78313 (r=0.657,p=0.970),  time:113.997, tt:7751.766\n",
      "Ep:68, loss:0.00001, loss_test:0.08478, lr:6.96e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.035, tt:7868.418\n",
      "Ep:69, loss:0.00001, loss_test:0.08571, lr:6.89e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.040, tt:7982.786\n",
      "Ep:70, loss:0.00001, loss_test:0.08405, lr:6.83e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.059, tt:8098.178\n",
      "Ep:71, loss:0.00001, loss_test:0.08595, lr:6.76e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.080, tt:8213.741\n",
      "Ep:72, loss:0.00001, loss_test:0.08543, lr:6.69e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.119, tt:8330.654\n",
      "Ep:73, loss:0.00001, loss_test:0.08560, lr:6.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.141, tt:8446.454\n",
      "Ep:74, loss:0.00001, loss_test:0.08547, lr:6.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.177, tt:8563.285\n",
      "Ep:75, loss:0.00001, loss_test:0.08516, lr:6.49e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.205, tt:8679.608\n",
      "Ep:76, loss:0.00001, loss_test:0.08596, lr:6.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.269, tt:8798.713\n",
      "Ep:77, loss:0.00001, loss_test:0.08561, lr:6.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.290, tt:8914.640\n",
      "Ep:78, loss:0.00001, loss_test:0.08698, lr:6.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.317, tt:9031.032\n",
      "Ep:79, loss:0.00001, loss_test:0.08629, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.411, tt:9152.855\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00123, loss_test:0.12784, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:147.776, tt:147.776\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00108, loss_test:0.10848, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:139.583, tt:279.167\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00095, loss_test:0.09805, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:136.520, tt:409.560\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00085, loss_test:0.09103, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:139.012, tt:556.049\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00077, loss_test:0.08629, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:140.498, tt:702.492\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00071, loss_test:0.08199, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:141.421, tt:848.525\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00065, loss_test:0.07672, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:143.140, tt:1001.979\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00059, loss_test:0.07136, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:143.847, tt:1150.777\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00054, loss_test:0.06687, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:144.532, tt:1300.787\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00048, loss_test:0.06248, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:144.967, tt:1449.669\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00043, loss_test:0.06015, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:145.742, tt:1603.167\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00038, loss_test:0.05804, lr:1.00e-02, fs:0.94000 (r=0.949,p=0.931),  time:146.223, tt:1754.677\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.05495, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:146.408, tt:1903.299\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.05169, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:146.800, tt:2055.197\n",
      "Ep:14, loss:0.00027, loss_test:0.05130, lr:1.00e-02, fs:0.95000 (r=0.960,p=0.941),  time:147.055, tt:2205.828\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.05278, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:147.170, tt:2354.720\n",
      "Ep:16, loss:0.00021, loss_test:0.04740, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:147.335, tt:2504.699\n",
      "Ep:17, loss:0.00018, loss_test:0.04564, lr:1.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:147.236, tt:2650.250\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.04459, lr:1.00e-02, fs:0.96040 (r=0.980,p=0.942),  time:147.347, tt:2799.596\n",
      "Ep:19, loss:0.00015, loss_test:0.04436, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:147.264, tt:2945.277\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.04602, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:146.986, tt:3086.713\n",
      "Ep:21, loss:0.00012, loss_test:0.04608, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:146.673, tt:3226.808\n",
      "Ep:22, loss:0.00011, loss_test:0.04463, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:146.532, tt:3370.247\n",
      "Ep:23, loss:0.00010, loss_test:0.04517, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:146.354, tt:3512.499\n",
      "Ep:24, loss:0.00008, loss_test:0.04599, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.209, tt:3655.225\n",
      "Ep:25, loss:0.00008, loss_test:0.04614, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.264, tt:3802.861\n",
      "Ep:26, loss:0.00007, loss_test:0.04790, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.261, tt:3949.052\n",
      "Ep:27, loss:0.00006, loss_test:0.04611, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.296, tt:4096.295\n",
      "Ep:28, loss:0.00006, loss_test:0.04573, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.308, tt:4242.939\n",
      "Ep:29, loss:0.00005, loss_test:0.04413, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.329, tt:4389.863\n",
      "Ep:30, loss:0.00005, loss_test:0.04617, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:146.287, tt:4534.883\n",
      "Ep:31, loss:0.00004, loss_test:0.04468, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:146.275, tt:4680.802\n",
      "Ep:32, loss:0.00004, loss_test:0.04464, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:146.305, tt:4828.065\n",
      "Ep:33, loss:0.00004, loss_test:0.04484, lr:9.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:146.378, tt:4976.864\n",
      "Ep:34, loss:0.00003, loss_test:0.04758, lr:9.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:146.469, tt:5126.427\n",
      "Ep:35, loss:0.00003, loss_test:0.04443, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:146.565, tt:5276.349\n",
      "Ep:36, loss:0.00003, loss_test:0.04442, lr:9.41e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.587, tt:5423.725\n",
      "Ep:37, loss:0.00003, loss_test:0.04433, lr:9.32e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.625, tt:5571.755\n",
      "Ep:38, loss:0.00002, loss_test:0.04441, lr:9.23e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.673, tt:5720.231\n",
      "Ep:39, loss:0.00002, loss_test:0.04581, lr:9.14e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.719, tt:5868.770\n",
      "Ep:40, loss:0.00002, loss_test:0.04465, lr:9.04e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.736, tt:6016.193\n",
      "Ep:41, loss:0.00002, loss_test:0.04544, lr:8.95e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.719, tt:6162.217\n",
      "Ep:42, loss:0.00002, loss_test:0.04549, lr:8.86e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.709, tt:6308.480\n",
      "Ep:43, loss:0.00002, loss_test:0.04532, lr:8.78e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.702, tt:6454.871\n",
      "Ep:44, loss:0.00002, loss_test:0.04633, lr:8.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.729, tt:6602.797\n",
      "Ep:45, loss:0.00002, loss_test:0.04663, lr:8.60e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.706, tt:6748.467\n",
      "Ep:46, loss:0.00001, loss_test:0.04650, lr:8.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.627, tt:6891.466\n",
      "Ep:47, loss:0.00001, loss_test:0.04612, lr:8.43e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.690, tt:7041.097\n",
      "Ep:48, loss:0.00001, loss_test:0.04566, lr:8.35e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.777, tt:7192.052\n",
      "Ep:49, loss:0.00001, loss_test:0.04664, lr:8.26e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.827, tt:7341.357\n",
      "Ep:50, loss:0.00001, loss_test:0.04631, lr:8.18e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.846, tt:7489.124\n",
      "Ep:51, loss:0.00001, loss_test:0.04696, lr:8.10e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.858, tt:7636.591\n",
      "Ep:52, loss:0.00001, loss_test:0.04759, lr:8.02e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.866, tt:7783.923\n",
      "Ep:53, loss:0.00001, loss_test:0.04764, lr:7.94e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.929, tt:7934.151\n",
      "Ep:54, loss:0.00001, loss_test:0.04734, lr:7.86e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.923, tt:8080.779\n",
      "Ep:55, loss:0.00001, loss_test:0.04873, lr:7.78e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.961, tt:8229.819\n",
      "Ep:56, loss:0.00001, loss_test:0.04685, lr:7.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.955, tt:8376.426\n",
      "Ep:57, loss:0.00001, loss_test:0.04793, lr:7.62e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.941, tt:8522.578\n",
      "Ep:58, loss:0.00001, loss_test:0.04735, lr:7.55e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.903, tt:8667.290\n",
      "Ep:59, loss:0.00001, loss_test:0.04788, lr:7.47e-03, fs:0.86857 (r=0.768,p=1.000),  time:146.919, tt:8815.149\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00122, loss_test:0.13454, lr:1.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:145.949, tt:145.949\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00104, loss_test:0.11771, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:140.448, tt:280.896\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00091, loss_test:0.10958, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:137.615, tt:412.845\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00082, loss_test:0.10336, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:140.002, tt:560.007\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00074, loss_test:0.09852, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:141.364, tt:706.822\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00068, loss_test:0.09596, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:142.199, tt:853.195\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00062, loss_test:0.09440, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:143.231, tt:1002.614\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00057, loss_test:0.09109, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:143.803, tt:1150.420\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00052, loss_test:0.09011, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:144.266, tt:1298.393\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00048, loss_test:0.08636, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:144.243, tt:1442.435\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00043, loss_test:0.09006, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:144.582, tt:1590.397\n",
      "Ep:11, loss:0.00040, loss_test:0.08502, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:145.053, tt:1740.636\n",
      "Ep:12, loss:0.00035, loss_test:0.08508, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:145.360, tt:1889.679\n",
      "Ep:13, loss:0.00032, loss_test:0.08499, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:145.952, tt:2043.325\n",
      "Ep:14, loss:0.00028, loss_test:0.08207, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:146.050, tt:2190.746\n",
      "Ep:15, loss:0.00025, loss_test:0.07939, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:146.256, tt:2340.092\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00022, loss_test:0.08009, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:146.375, tt:2488.373\n",
      "Ep:17, loss:0.00020, loss_test:0.08127, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:146.368, tt:2634.625\n",
      "Ep:18, loss:0.00018, loss_test:0.07867, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:146.391, tt:2781.424\n",
      "Ep:19, loss:0.00016, loss_test:0.07949, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:146.361, tt:2927.220\n",
      "Ep:20, loss:0.00014, loss_test:0.08140, lr:1.00e-02, fs:0.70370 (r=0.576,p=0.905),  time:146.348, tt:3073.307\n",
      "Ep:21, loss:0.00013, loss_test:0.07767, lr:1.00e-02, fs:0.71951 (r=0.596,p=0.908),  time:146.317, tt:3218.966\n",
      "Ep:22, loss:0.00012, loss_test:0.07913, lr:1.00e-02, fs:0.71951 (r=0.596,p=0.908),  time:146.306, tt:3365.034\n",
      "Ep:23, loss:0.00011, loss_test:0.07559, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:146.336, tt:3512.057\n",
      "Ep:24, loss:0.00010, loss_test:0.07921, lr:1.00e-02, fs:0.70807 (r=0.576,p=0.919),  time:146.427, tt:3660.685\n",
      "Ep:25, loss:0.00009, loss_test:0.08065, lr:1.00e-02, fs:0.70807 (r=0.576,p=0.919),  time:146.459, tt:3807.944\n",
      "Ep:26, loss:0.00008, loss_test:0.08396, lr:1.00e-02, fs:0.70807 (r=0.576,p=0.919),  time:146.451, tt:3954.184\n",
      "Ep:27, loss:0.00007, loss_test:0.08007, lr:9.90e-03, fs:0.70807 (r=0.576,p=0.919),  time:146.579, tt:4104.219\n",
      "Ep:28, loss:0.00007, loss_test:0.08588, lr:9.80e-03, fs:0.70807 (r=0.576,p=0.919),  time:146.639, tt:4252.522\n",
      "Ep:29, loss:0.00006, loss_test:0.08719, lr:9.70e-03, fs:0.70807 (r=0.576,p=0.919),  time:146.654, tt:4399.635\n",
      "Ep:30, loss:0.00006, loss_test:0.08290, lr:9.61e-03, fs:0.70807 (r=0.576,p=0.919),  time:146.730, tt:4548.622\n",
      "Ep:31, loss:0.00005, loss_test:0.08364, lr:9.51e-03, fs:0.70807 (r=0.576,p=0.919),  time:146.799, tt:4697.577\n",
      "Ep:32, loss:0.00005, loss_test:0.08462, lr:9.41e-03, fs:0.71250 (r=0.576,p=0.934),  time:146.900, tt:4847.688\n",
      "Ep:33, loss:0.00004, loss_test:0.08907, lr:9.32e-03, fs:0.71250 (r=0.576,p=0.934),  time:147.057, tt:4999.944\n",
      "Ep:34, loss:0.00004, loss_test:0.08999, lr:9.23e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.064, tt:5147.251\n",
      "Ep:35, loss:0.00004, loss_test:0.08820, lr:9.14e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.060, tt:5294.161\n",
      "Ep:36, loss:0.00003, loss_test:0.09096, lr:9.04e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.093, tt:5442.453\n",
      "Ep:37, loss:0.00003, loss_test:0.08887, lr:8.95e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.164, tt:5592.236\n",
      "Ep:38, loss:0.00003, loss_test:0.08845, lr:8.86e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.054, tt:5735.096\n",
      "Ep:39, loss:0.00003, loss_test:0.08857, lr:8.78e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.083, tt:5883.323\n",
      "Ep:40, loss:0.00003, loss_test:0.08909, lr:8.69e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.082, tt:6030.374\n",
      "Ep:41, loss:0.00002, loss_test:0.09130, lr:8.60e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.085, tt:6177.556\n",
      "Ep:42, loss:0.00002, loss_test:0.09136, lr:8.51e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.141, tt:6327.059\n",
      "Ep:43, loss:0.00002, loss_test:0.09192, lr:8.43e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.136, tt:6474.002\n",
      "Ep:44, loss:0.00002, loss_test:0.09157, lr:8.35e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.163, tt:6622.318\n",
      "Ep:45, loss:0.00002, loss_test:0.09439, lr:8.26e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.227, tt:6772.423\n",
      "Ep:46, loss:0.00002, loss_test:0.09381, lr:8.18e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.341, tt:6925.010\n",
      "Ep:47, loss:0.00002, loss_test:0.09192, lr:8.10e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.419, tt:7076.109\n",
      "Ep:48, loss:0.00002, loss_test:0.09236, lr:8.02e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.428, tt:7223.953\n",
      "Ep:49, loss:0.00002, loss_test:0.09269, lr:7.94e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.412, tt:7370.605\n",
      "Ep:50, loss:0.00002, loss_test:0.09263, lr:7.86e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.440, tt:7519.445\n",
      "Ep:51, loss:0.00001, loss_test:0.09341, lr:7.78e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.533, tt:7671.740\n",
      "Ep:52, loss:0.00001, loss_test:0.09346, lr:7.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.534, tt:7819.287\n",
      "Ep:53, loss:0.00001, loss_test:0.09446, lr:7.62e-03, fs:0.71698 (r=0.576,p=0.950),  time:147.547, tt:7967.554\n",
      "Ep:54, loss:0.00001, loss_test:0.09430, lr:7.55e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.540, tt:8114.726\n",
      "Ep:55, loss:0.00001, loss_test:0.09505, lr:7.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.584, tt:8264.701\n",
      "Ep:56, loss:0.00001, loss_test:0.09494, lr:7.40e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.585, tt:8412.356\n",
      "Ep:57, loss:0.00001, loss_test:0.09337, lr:7.32e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.650, tt:8563.680\n",
      "Ep:58, loss:0.00001, loss_test:0.09418, lr:7.25e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.655, tt:8711.643\n",
      "Ep:59, loss:0.00001, loss_test:0.09365, lr:7.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:147.671, tt:8860.234\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00397, loss_test:0.11035, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:519.860, tt:519.860\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00251, loss_test:0.10180, lr:1.00e-02, fs:0.70857 (r=0.626,p=0.816),  time:544.761, tt:1089.522\n",
      "Ep:2, loss:0.00164, loss_test:0.09890, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:550.103, tt:1650.309\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00108, loss_test:0.10107, lr:1.00e-02, fs:0.74847 (r=0.616,p=0.953),  time:553.879, tt:2215.515\n",
      "Ep:4, loss:0.00074, loss_test:0.11624, lr:1.00e-02, fs:0.63014 (r=0.465,p=0.979),  time:556.321, tt:2781.603\n",
      "Ep:5, loss:0.00052, loss_test:0.12292, lr:1.00e-02, fs:0.63014 (r=0.465,p=0.979),  time:557.532, tt:3345.194\n",
      "Ep:6, loss:0.00037, loss_test:0.12163, lr:1.00e-02, fs:0.56522 (r=0.394,p=1.000),  time:558.571, tt:3909.998\n",
      "Ep:7, loss:0.00026, loss_test:0.12403, lr:1.00e-02, fs:0.53333 (r=0.364,p=1.000),  time:558.486, tt:4467.888\n",
      "Ep:8, loss:0.00019, loss_test:0.13022, lr:1.00e-02, fs:0.53333 (r=0.364,p=1.000),  time:559.063, tt:5031.568\n",
      "Ep:9, loss:0.00015, loss_test:0.13199, lr:1.00e-02, fs:0.56522 (r=0.394,p=1.000),  time:559.825, tt:5598.247\n",
      "Ep:10, loss:0.00011, loss_test:0.13662, lr:1.00e-02, fs:0.53333 (r=0.364,p=1.000),  time:559.711, tt:6156.823\n",
      "Ep:11, loss:0.00008, loss_test:0.13717, lr:1.00e-02, fs:0.63448 (r=0.465,p=1.000),  time:560.272, tt:6723.260\n",
      "Ep:12, loss:0.00006, loss_test:0.13947, lr:1.00e-02, fs:0.65306 (r=0.485,p=1.000),  time:560.367, tt:7284.766\n",
      "Ep:13, loss:0.00005, loss_test:0.14314, lr:1.00e-02, fs:0.65306 (r=0.485,p=1.000),  time:560.351, tt:7844.917\n",
      "Ep:14, loss:0.00004, loss_test:0.14451, lr:9.90e-03, fs:0.65306 (r=0.485,p=1.000),  time:560.125, tt:8401.872\n",
      "Ep:15, loss:0.00003, loss_test:0.14347, lr:9.80e-03, fs:0.65306 (r=0.485,p=1.000),  time:560.431, tt:8966.892\n",
      "Ep:16, loss:0.00002, loss_test:0.14370, lr:9.70e-03, fs:0.65306 (r=0.485,p=1.000),  time:560.391, tt:9526.655\n",
      "Ep:17, loss:0.00002, loss_test:0.14367, lr:9.61e-03, fs:0.65306 (r=0.485,p=1.000),  time:560.105, tt:10081.894\n",
      "Ep:18, loss:0.00002, loss_test:0.14138, lr:9.51e-03, fs:0.65306 (r=0.485,p=1.000),  time:559.952, tt:10639.092\n",
      "Ep:19, loss:0.00002, loss_test:0.14452, lr:9.41e-03, fs:0.65306 (r=0.485,p=1.000),  time:559.452, tt:11189.045\n",
      "Ep:20, loss:0.00001, loss_test:0.14386, lr:9.32e-03, fs:0.65306 (r=0.485,p=1.000),  time:559.557, tt:11750.687\n",
      "Ep:21, loss:0.00001, loss_test:0.14304, lr:9.23e-03, fs:0.65306 (r=0.485,p=1.000),  time:558.940, tt:12296.687\n",
      "Ep:22, loss:0.00001, loss_test:0.14259, lr:9.14e-03, fs:0.65306 (r=0.485,p=1.000),  time:559.135, tt:12860.110\n",
      "Ep:23, loss:0.00001, loss_test:0.14376, lr:9.04e-03, fs:0.65306 (r=0.485,p=1.000),  time:559.036, tt:13416.853\n",
      "Ep:24, loss:0.00001, loss_test:0.14269, lr:8.95e-03, fs:0.65306 (r=0.485,p=1.000),  time:558.858, tt:13971.444\n",
      "Ep:25, loss:0.00001, loss_test:0.14341, lr:8.86e-03, fs:0.65306 (r=0.485,p=1.000),  time:558.520, tt:14521.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00001, loss_test:0.14375, lr:8.78e-03, fs:0.65306 (r=0.485,p=1.000),  time:557.913, tt:15063.639\n",
      "Ep:27, loss:0.00001, loss_test:0.14172, lr:8.69e-03, fs:0.65306 (r=0.485,p=1.000),  time:557.499, tt:15609.964\n",
      "Ep:28, loss:0.00001, loss_test:0.14110, lr:8.60e-03, fs:0.65306 (r=0.485,p=1.000),  time:557.388, tt:16164.256\n",
      "Ep:29, loss:0.00001, loss_test:0.14101, lr:8.51e-03, fs:0.65306 (r=0.485,p=1.000),  time:556.898, tt:16706.931\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00394, loss_test:0.11263, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:509.834, tt:509.834\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00254, loss_test:0.09556, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:532.857, tt:1065.713\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00169, loss_test:0.08908, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:545.304, tt:1635.912\n",
      "Ep:3, loss:0.00113, loss_test:0.09606, lr:1.00e-02, fs:0.68387 (r=0.535,p=0.946),  time:545.366, tt:2181.463\n",
      "Ep:4, loss:0.00073, loss_test:0.11164, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:545.748, tt:2728.738\n",
      "Ep:5, loss:0.00048, loss_test:0.11319, lr:1.00e-02, fs:0.69281 (r=0.535,p=0.981),  time:548.954, tt:3293.721\n",
      "Ep:6, loss:0.00032, loss_test:0.11600, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:551.240, tt:3858.679\n",
      "Ep:7, loss:0.00024, loss_test:0.12185, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:551.107, tt:4408.858\n",
      "Ep:8, loss:0.00016, loss_test:0.12504, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:551.438, tt:4962.941\n",
      "Ep:9, loss:0.00012, loss_test:0.13014, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:550.683, tt:5506.834\n",
      "Ep:10, loss:0.00009, loss_test:0.12923, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:550.050, tt:6050.551\n",
      "Ep:11, loss:0.00006, loss_test:0.13017, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:549.495, tt:6593.939\n",
      "Ep:12, loss:0.00005, loss_test:0.13478, lr:1.00e-02, fs:0.69737 (r=0.535,p=1.000),  time:549.075, tt:7137.972\n",
      "Ep:13, loss:0.00004, loss_test:0.13474, lr:9.90e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.961, tt:7685.455\n",
      "Ep:14, loss:0.00003, loss_test:0.13033, lr:9.80e-03, fs:0.69737 (r=0.535,p=1.000),  time:549.011, tt:8235.163\n",
      "Ep:15, loss:0.00003, loss_test:0.13401, lr:9.70e-03, fs:0.69737 (r=0.535,p=1.000),  time:549.004, tt:8784.070\n",
      "Ep:16, loss:0.00003, loss_test:0.13220, lr:9.61e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.782, tt:9329.293\n",
      "Ep:17, loss:0.00002, loss_test:0.13231, lr:9.51e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.504, tt:9873.068\n",
      "Ep:18, loss:0.00002, loss_test:0.13119, lr:9.41e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.596, tt:10423.316\n",
      "Ep:19, loss:0.00002, loss_test:0.13331, lr:9.32e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.551, tt:10971.023\n",
      "Ep:20, loss:0.00002, loss_test:0.13199, lr:9.23e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.471, tt:11517.881\n",
      "Ep:21, loss:0.00001, loss_test:0.13183, lr:9.14e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.278, tt:12062.109\n",
      "Ep:22, loss:0.00001, loss_test:0.13091, lr:9.04e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.471, tt:12614.841\n",
      "Ep:23, loss:0.00001, loss_test:0.13131, lr:8.95e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.336, tt:13160.060\n",
      "Ep:24, loss:0.00001, loss_test:0.13136, lr:8.86e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.234, tt:13705.843\n",
      "Ep:25, loss:0.00001, loss_test:0.13384, lr:8.78e-03, fs:0.69737 (r=0.535,p=1.000),  time:548.113, tt:14250.944\n",
      "Ep:26, loss:0.00001, loss_test:0.13163, lr:8.69e-03, fs:0.69737 (r=0.535,p=1.000),  time:547.750, tt:14789.264\n",
      "Ep:27, loss:0.00001, loss_test:0.13198, lr:8.60e-03, fs:0.69737 (r=0.535,p=1.000),  time:547.556, tt:15331.554\n",
      "Ep:28, loss:0.00001, loss_test:0.13201, lr:8.51e-03, fs:0.69737 (r=0.535,p=1.000),  time:547.576, tt:15879.701\n",
      "Ep:29, loss:0.00001, loss_test:0.13191, lr:8.43e-03, fs:0.69737 (r=0.535,p=1.000),  time:547.656, tt:16429.694\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,6,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,80,cv_number,8,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,10,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,0,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "ITERATION: 0\n",
      "ITERATION: 1\n",
      "ITERATION: 2\n",
      "ITERATION: 3\n",
      "ITERATION: 4\n",
      "ITERATION: 5\n",
      "ITERATION: 6\n",
      "ITERATION: 7\n",
      "ITERATION: 8\n",
      "ITERATION: 9\n",
      "ITERATION: 10\n",
      "ITERATION: 11\n",
      "ITERATION: 12\n",
      "ITERATION: 13\n",
      "ITERATION: 14\n",
      "ITERATION: 15\n",
      "ITERATION: 16\n",
      "ITERATION: 17\n",
      "ITERATION: 18\n",
      "ITERATION: 19\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14689, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.303, tt:8.303\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14625, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:8.731, tt:17.462\n",
      "Ep:2, loss:0.00027, loss_test:0.14505, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:8.970, tt:26.909\n",
      "Ep:3, loss:0.00026, loss_test:0.14312, lr:1.00e-02, fs:0.62857 (r=0.889,p=0.486),  time:9.250, tt:37.001\n",
      "Ep:4, loss:0.00025, loss_test:0.14132, lr:1.00e-02, fs:0.58268 (r=0.747,p=0.477),  time:9.623, tt:48.115\n",
      "Ep:5, loss:0.00024, loss_test:0.14150, lr:1.00e-02, fs:0.57143 (r=0.646,p=0.512),  time:10.175, tt:61.047\n",
      "Ep:6, loss:0.00022, loss_test:0.14300, lr:1.00e-02, fs:0.59574 (r=0.566,p=0.629),  time:10.656, tt:74.592\n",
      "Ep:7, loss:0.00022, loss_test:0.14174, lr:1.00e-02, fs:0.61290 (r=0.576,p=0.655),  time:11.474, tt:91.795\n",
      "Ep:8, loss:0.00021, loss_test:0.13861, lr:1.00e-02, fs:0.60825 (r=0.596,p=0.621),  time:12.517, tt:112.653\n",
      "Ep:9, loss:0.00021, loss_test:0.13631, lr:1.00e-02, fs:0.59406 (r=0.606,p=0.583),  time:13.926, tt:139.260\n",
      "Ep:10, loss:0.00020, loss_test:0.13514, lr:1.00e-02, fs:0.60825 (r=0.596,p=0.621),  time:15.167, tt:166.839\n",
      "Ep:11, loss:0.00020, loss_test:0.13518, lr:1.00e-02, fs:0.59341 (r=0.545,p=0.651),  time:16.135, tt:193.614\n",
      "Ep:12, loss:0.00019, loss_test:0.13345, lr:9.90e-03, fs:0.60571 (r=0.535,p=0.697),  time:17.095, tt:222.229\n",
      "Ep:13, loss:0.00018, loss_test:0.12959, lr:9.80e-03, fs:0.60440 (r=0.556,p=0.663),  time:17.840, tt:249.765\n",
      "Ep:14, loss:0.00018, loss_test:0.12698, lr:9.70e-03, fs:0.60215 (r=0.566,p=0.644),  time:18.540, tt:278.105\n",
      "Ep:15, loss:0.00017, loss_test:0.12573, lr:9.61e-03, fs:0.61290 (r=0.576,p=0.655),  time:19.153, tt:306.440\n",
      "Ep:16, loss:0.00017, loss_test:0.12461, lr:9.51e-03, fs:0.60109 (r=0.556,p=0.655),  time:19.666, tt:334.328\n",
      "Ep:17, loss:0.00017, loss_test:0.12369, lr:9.41e-03, fs:0.61202 (r=0.566,p=0.667),  time:20.215, tt:363.871\n",
      "Ep:18, loss:0.00016, loss_test:0.12237, lr:9.32e-03, fs:0.60440 (r=0.556,p=0.663),  time:20.626, tt:391.888\n",
      "Ep:19, loss:0.00016, loss_test:0.12074, lr:9.23e-03, fs:0.60870 (r=0.566,p=0.659),  time:21.021, tt:420.426\n",
      "Ep:20, loss:0.00015, loss_test:0.11952, lr:9.14e-03, fs:0.61202 (r=0.566,p=0.667),  time:21.345, tt:448.253\n",
      "Ep:21, loss:0.00015, loss_test:0.11809, lr:9.04e-03, fs:0.61538 (r=0.566,p=0.675),  time:21.630, tt:475.860\n",
      "Ep:22, loss:0.00015, loss_test:0.11674, lr:8.95e-03, fs:0.64865 (r=0.606,p=0.698),  time:21.860, tt:502.779\n",
      "Ep:23, loss:0.00015, loss_test:0.11591, lr:8.86e-03, fs:0.65217 (r=0.606,p=0.706),  time:22.199, tt:532.768\n",
      "Ep:24, loss:0.00014, loss_test:0.11510, lr:8.78e-03, fs:0.65217 (r=0.606,p=0.706),  time:22.448, tt:561.191\n",
      "Ep:25, loss:0.00014, loss_test:0.11407, lr:8.69e-03, fs:0.64865 (r=0.606,p=0.698),  time:22.705, tt:590.335\n",
      "Ep:26, loss:0.00014, loss_test:0.11416, lr:8.60e-03, fs:0.65193 (r=0.596,p=0.720),  time:22.915, tt:618.707\n",
      "Ep:27, loss:0.00014, loss_test:0.11349, lr:8.51e-03, fs:0.65574 (r=0.606,p=0.714),  time:23.116, tt:647.242\n",
      "Ep:28, loss:0.00013, loss_test:0.11274, lr:8.43e-03, fs:0.65574 (r=0.606,p=0.714),  time:23.237, tt:673.886\n",
      "Ep:29, loss:0.00013, loss_test:0.11200, lr:8.35e-03, fs:0.65574 (r=0.606,p=0.714),  time:23.402, tt:702.057\n",
      "Ep:30, loss:0.00013, loss_test:0.11171, lr:8.26e-03, fs:0.65934 (r=0.606,p=0.723),  time:23.521, tt:729.148\n",
      "Ep:31, loss:0.00013, loss_test:0.11158, lr:8.18e-03, fs:0.63687 (r=0.576,p=0.713),  time:23.685, tt:757.914\n",
      "Ep:32, loss:0.00012, loss_test:0.11016, lr:8.10e-03, fs:0.65574 (r=0.606,p=0.714),  time:23.806, tt:785.606\n",
      "Ep:33, loss:0.00012, loss_test:0.10953, lr:8.02e-03, fs:0.65934 (r=0.606,p=0.723),  time:23.923, tt:813.375\n",
      "Ep:34, loss:0.00012, loss_test:0.10987, lr:7.94e-03, fs:0.64444 (r=0.586,p=0.716),  time:24.011, tt:840.378\n",
      "Ep:35, loss:0.00012, loss_test:0.10922, lr:7.86e-03, fs:0.65193 (r=0.596,p=0.720),  time:24.077, tt:866.780\n",
      "Ep:36, loss:0.00012, loss_test:0.10782, lr:7.78e-03, fs:0.67027 (r=0.626,p=0.721),  time:24.163, tt:894.026\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.10811, lr:7.78e-03, fs:0.65193 (r=0.596,p=0.720),  time:24.227, tt:920.632\n",
      "Ep:38, loss:0.00011, loss_test:0.10743, lr:7.78e-03, fs:0.66298 (r=0.606,p=0.732),  time:24.296, tt:947.549\n",
      "Ep:39, loss:0.00011, loss_test:0.10692, lr:7.78e-03, fs:0.66298 (r=0.606,p=0.732),  time:24.381, tt:975.223\n",
      "Ep:40, loss:0.00011, loss_test:0.10656, lr:7.78e-03, fs:0.66298 (r=0.606,p=0.732),  time:24.416, tt:1001.042\n",
      "Ep:41, loss:0.00011, loss_test:0.10633, lr:7.78e-03, fs:0.66298 (r=0.606,p=0.732),  time:24.503, tt:1029.112\n",
      "Ep:42, loss:0.00011, loss_test:0.10493, lr:7.78e-03, fs:0.68108 (r=0.636,p=0.733),  time:24.566, tt:1056.356\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.10642, lr:7.78e-03, fs:0.66667 (r=0.606,p=0.741),  time:24.631, tt:1083.783\n",
      "Ep:44, loss:0.00010, loss_test:0.10486, lr:7.78e-03, fs:0.68108 (r=0.636,p=0.733),  time:24.666, tt:1109.979\n",
      "Ep:45, loss:0.00010, loss_test:0.10416, lr:7.78e-03, fs:0.68817 (r=0.646,p=0.736),  time:24.699, tt:1136.133\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.10491, lr:7.78e-03, fs:0.68132 (r=0.626,p=0.747),  time:24.792, tt:1165.209\n",
      "Ep:47, loss:0.00010, loss_test:0.10385, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:24.814, tt:1191.069\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00010, loss_test:0.10426, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:24.910, tt:1220.578\n",
      "Ep:49, loss:0.00010, loss_test:0.10385, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:24.986, tt:1249.277\n",
      "Ep:50, loss:0.00010, loss_test:0.10371, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:25.050, tt:1277.532\n",
      "Ep:51, loss:0.00009, loss_test:0.10427, lr:7.78e-03, fs:0.68852 (r=0.636,p=0.750),  time:25.090, tt:1304.679\n",
      "Ep:52, loss:0.00009, loss_test:0.10213, lr:7.78e-03, fs:0.70270 (r=0.657,p=0.756),  time:25.125, tt:1331.651\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.10342, lr:7.78e-03, fs:0.68852 (r=0.636,p=0.750),  time:25.172, tt:1359.279\n",
      "Ep:54, loss:0.00009, loss_test:0.10318, lr:7.78e-03, fs:0.68852 (r=0.636,p=0.750),  time:25.234, tt:1387.860\n",
      "Ep:55, loss:0.00009, loss_test:0.10318, lr:7.78e-03, fs:0.68132 (r=0.626,p=0.747),  time:25.287, tt:1416.056\n",
      "Ep:56, loss:0.00009, loss_test:0.10218, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:25.355, tt:1445.213\n",
      "Ep:57, loss:0.00009, loss_test:0.10192, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:25.414, tt:1473.997\n",
      "Ep:58, loss:0.00008, loss_test:0.10259, lr:7.78e-03, fs:0.68132 (r=0.626,p=0.747),  time:25.423, tt:1499.948\n",
      "Ep:59, loss:0.00008, loss_test:0.10104, lr:7.78e-03, fs:0.70968 (r=0.667,p=0.759),  time:25.456, tt:1527.360\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00008, loss_test:0.10229, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:25.490, tt:1554.902\n",
      "Ep:61, loss:0.00008, loss_test:0.10259, lr:7.78e-03, fs:0.68156 (r=0.616,p=0.762),  time:25.526, tt:1582.641\n",
      "Ep:62, loss:0.00008, loss_test:0.10056, lr:7.78e-03, fs:0.70270 (r=0.657,p=0.756),  time:25.578, tt:1611.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00008, loss_test:0.10187, lr:7.78e-03, fs:0.68508 (r=0.626,p=0.756),  time:25.612, tt:1639.193\n",
      "Ep:64, loss:0.00008, loss_test:0.10200, lr:7.78e-03, fs:0.68539 (r=0.616,p=0.772),  time:25.649, tt:1667.216\n",
      "Ep:65, loss:0.00008, loss_test:0.09958, lr:7.78e-03, fs:0.71038 (r=0.657,p=0.774),  time:25.691, tt:1695.639\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00007, loss_test:0.10084, lr:7.78e-03, fs:0.68539 (r=0.616,p=0.772),  time:25.730, tt:1723.903\n",
      "Ep:67, loss:0.00007, loss_test:0.09970, lr:7.78e-03, fs:0.69231 (r=0.636,p=0.759),  time:25.773, tt:1752.539\n",
      "Ep:68, loss:0.00007, loss_test:0.09918, lr:7.78e-03, fs:0.70000 (r=0.636,p=0.778),  time:25.817, tt:1781.338\n",
      "Ep:69, loss:0.00007, loss_test:0.09950, lr:7.78e-03, fs:0.70056 (r=0.626,p=0.795),  time:25.834, tt:1808.354\n",
      "Ep:70, loss:0.00007, loss_test:0.09896, lr:7.78e-03, fs:0.70000 (r=0.636,p=0.778),  time:25.879, tt:1837.401\n",
      "Ep:71, loss:0.00007, loss_test:0.10044, lr:7.78e-03, fs:0.71591 (r=0.636,p=0.818),  time:25.919, tt:1866.188\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00007, loss_test:0.09738, lr:7.78e-03, fs:0.71429 (r=0.657,p=0.783),  time:25.953, tt:1894.582\n",
      "Ep:73, loss:0.00007, loss_test:0.09858, lr:7.78e-03, fs:0.70391 (r=0.636,p=0.787),  time:25.975, tt:1922.137\n",
      "Ep:74, loss:0.00006, loss_test:0.09928, lr:7.78e-03, fs:0.72727 (r=0.646,p=0.831),  time:26.018, tt:1951.324\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00006, loss_test:0.09674, lr:7.78e-03, fs:0.71823 (r=0.657,p=0.793),  time:26.034, tt:1978.573\n",
      "Ep:76, loss:0.00006, loss_test:0.09906, lr:7.78e-03, fs:0.70175 (r=0.606,p=0.833),  time:26.057, tt:2006.377\n",
      "Ep:77, loss:0.00006, loss_test:0.09881, lr:7.78e-03, fs:0.71264 (r=0.626,p=0.827),  time:26.081, tt:2034.332\n",
      "Ep:78, loss:0.00006, loss_test:0.09603, lr:7.78e-03, fs:0.71823 (r=0.657,p=0.793),  time:26.102, tt:2062.089\n",
      "Ep:79, loss:0.00006, loss_test:0.09870, lr:7.78e-03, fs:0.71856 (r=0.606,p=0.882),  time:26.133, tt:2090.628\n",
      "Ep:80, loss:0.00006, loss_test:0.09499, lr:7.78e-03, fs:0.71508 (r=0.646,p=0.800),  time:26.161, tt:2119.064\n",
      "Ep:81, loss:0.00006, loss_test:0.09754, lr:7.78e-03, fs:0.73256 (r=0.636,p=0.863),  time:26.194, tt:2147.872\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00006, loss_test:0.09864, lr:7.78e-03, fs:0.71429 (r=0.606,p=0.870),  time:26.231, tt:2177.164\n",
      "Ep:83, loss:0.00005, loss_test:0.09520, lr:7.78e-03, fs:0.73143 (r=0.646,p=0.842),  time:26.261, tt:2205.888\n",
      "Ep:84, loss:0.00005, loss_test:0.09561, lr:7.78e-03, fs:0.73256 (r=0.636,p=0.863),  time:26.291, tt:2234.735\n",
      "Ep:85, loss:0.00005, loss_test:0.09688, lr:7.78e-03, fs:0.73373 (r=0.626,p=0.886),  time:26.304, tt:2262.134\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00005, loss_test:0.09560, lr:7.78e-03, fs:0.74419 (r=0.646,p=0.877),  time:26.330, tt:2290.675\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00005, loss_test:0.09485, lr:7.78e-03, fs:0.73988 (r=0.646,p=0.865),  time:26.361, tt:2319.804\n",
      "Ep:88, loss:0.00005, loss_test:0.09612, lr:7.78e-03, fs:0.73373 (r=0.626,p=0.886),  time:26.412, tt:2350.686\n",
      "Ep:89, loss:0.00005, loss_test:0.09403, lr:7.78e-03, fs:0.76836 (r=0.687,p=0.872),  time:26.451, tt:2380.620\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00005, loss_test:0.09571, lr:7.78e-03, fs:0.73373 (r=0.626,p=0.886),  time:26.478, tt:2409.536\n",
      "Ep:91, loss:0.00005, loss_test:0.09429, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.507, tt:2438.639\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00005, loss_test:0.09488, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.535, tt:2467.759\n",
      "Ep:93, loss:0.00004, loss_test:0.09319, lr:7.78e-03, fs:0.75581 (r=0.657,p=0.890),  time:26.567, tt:2497.298\n",
      "Ep:94, loss:0.00004, loss_test:0.09505, lr:7.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:26.590, tt:2526.065\n",
      "Ep:95, loss:0.00004, loss_test:0.09485, lr:7.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:26.608, tt:2554.336\n",
      "Ep:96, loss:0.00004, loss_test:0.09364, lr:7.78e-03, fs:0.74118 (r=0.636,p=0.887),  time:26.635, tt:2583.639\n",
      "Ep:97, loss:0.00004, loss_test:0.09185, lr:7.78e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.658, tt:2612.446\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00004, loss_test:0.09487, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.674, tt:2640.720\n",
      "Ep:99, loss:0.00004, loss_test:0.09215, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.687, tt:2668.720\n",
      "Ep:100, loss:0.00004, loss_test:0.09372, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.683, tt:2694.943\n",
      "Ep:101, loss:0.00004, loss_test:0.09347, lr:7.78e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.701, tt:2723.461\n",
      "Ep:102, loss:0.00004, loss_test:0.09290, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.706, tt:2750.697\n",
      "Ep:103, loss:0.00004, loss_test:0.09268, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.726, tt:2779.546\n",
      "Ep:104, loss:0.00004, loss_test:0.09273, lr:7.78e-03, fs:0.78857 (r=0.697,p=0.908),  time:26.741, tt:2807.754\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00004, loss_test:0.09434, lr:7.78e-03, fs:0.77011 (r=0.677,p=0.893),  time:26.767, tt:2837.252\n",
      "Ep:106, loss:0.00004, loss_test:0.09214, lr:7.78e-03, fs:0.78409 (r=0.697,p=0.896),  time:26.805, tt:2868.111\n",
      "Ep:107, loss:0.00003, loss_test:0.09627, lr:7.78e-03, fs:0.76023 (r=0.657,p=0.903),  time:26.811, tt:2895.583\n",
      "Ep:108, loss:0.00003, loss_test:0.09237, lr:7.78e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.824, tt:2923.842\n",
      "Ep:109, loss:0.00003, loss_test:0.09514, lr:7.78e-03, fs:0.78161 (r=0.687,p=0.907),  time:26.831, tt:2951.457\n",
      "Ep:110, loss:0.00003, loss_test:0.09566, lr:7.78e-03, fs:0.77457 (r=0.677,p=0.905),  time:26.846, tt:2979.856\n",
      "Ep:111, loss:0.00003, loss_test:0.09214, lr:7.78e-03, fs:0.78409 (r=0.697,p=0.896),  time:26.857, tt:3008.016\n",
      "Ep:112, loss:0.00003, loss_test:0.09631, lr:7.78e-03, fs:0.77457 (r=0.677,p=0.905),  time:26.872, tt:3036.544\n",
      "Ep:113, loss:0.00003, loss_test:0.09059, lr:7.78e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.897, tt:3066.219\n",
      "Ep:114, loss:0.00003, loss_test:0.09618, lr:7.78e-03, fs:0.77907 (r=0.677,p=0.918),  time:26.906, tt:3094.226\n",
      "Ep:115, loss:0.00003, loss_test:0.09255, lr:7.78e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.919, tt:3122.565\n",
      "Ep:116, loss:0.00003, loss_test:0.09204, lr:7.70e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.898, tt:3147.068\n",
      "Ep:117, loss:0.00003, loss_test:0.09518, lr:7.62e-03, fs:0.77907 (r=0.677,p=0.918),  time:26.923, tt:3176.919\n",
      "Ep:118, loss:0.00003, loss_test:0.09213, lr:7.55e-03, fs:0.77714 (r=0.687,p=0.895),  time:26.938, tt:3205.629\n",
      "Ep:119, loss:0.00003, loss_test:0.09467, lr:7.47e-03, fs:0.78613 (r=0.687,p=0.919),  time:26.971, tt:3236.532\n",
      "Ep:120, loss:0.00003, loss_test:0.09129, lr:7.40e-03, fs:0.77714 (r=0.687,p=0.895),  time:27.013, tt:3268.581\n",
      "Ep:121, loss:0.00003, loss_test:0.09458, lr:7.32e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.047, tt:3299.696\n",
      "Ep:122, loss:0.00003, loss_test:0.09455, lr:7.25e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.066, tt:3329.116\n",
      "Ep:123, loss:0.00003, loss_test:0.09117, lr:7.18e-03, fs:0.78161 (r=0.687,p=0.907),  time:27.113, tt:3362.012\n",
      "Ep:124, loss:0.00003, loss_test:0.09484, lr:7.11e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.139, tt:3392.427\n",
      "Ep:125, loss:0.00003, loss_test:0.09250, lr:7.03e-03, fs:0.78857 (r=0.697,p=0.908),  time:27.168, tt:3423.107\n",
      "Ep:126, loss:0.00003, loss_test:0.09311, lr:6.96e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.203, tt:3454.725\n",
      "Ep:127, loss:0.00002, loss_test:0.09288, lr:6.89e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.236, tt:3486.163\n",
      "Ep:128, loss:0.00002, loss_test:0.09402, lr:6.83e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.271, tt:3517.943\n",
      "Ep:129, loss:0.00002, loss_test:0.09272, lr:6.76e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.304, tt:3549.478\n",
      "Ep:130, loss:0.00002, loss_test:0.09535, lr:6.69e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.336, tt:3580.989\n",
      "Ep:131, loss:0.00002, loss_test:0.09408, lr:6.62e-03, fs:0.79070 (r=0.687,p=0.932),  time:27.364, tt:3612.025\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00002, loss_test:0.09366, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.404, tt:3644.683\n",
      "Ep:133, loss:0.00002, loss_test:0.09355, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.445, tt:3677.682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.09461, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.474, tt:3708.957\n",
      "Ep:135, loss:0.00002, loss_test:0.09390, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.498, tt:3739.700\n",
      "Ep:136, loss:0.00002, loss_test:0.09554, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.528, tt:3771.387\n",
      "Ep:137, loss:0.00002, loss_test:0.09244, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.555, tt:3802.627\n",
      "Ep:138, loss:0.00002, loss_test:0.09608, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.575, tt:3832.899\n",
      "Ep:139, loss:0.00002, loss_test:0.09297, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.594, tt:3863.106\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14060, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.166, tt:32.166\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13913, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:31.636, tt:63.272\n",
      "Ep:2, loss:0.00027, loss_test:0.13653, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.312, tt:87.937\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13212, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:29.944, tt:119.775\n",
      "Ep:4, loss:0.00026, loss_test:0.12535, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:30.347, tt:151.736\n",
      "Ep:5, loss:0.00025, loss_test:0.11677, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:30.135, tt:180.807\n",
      "Ep:6, loss:0.00023, loss_test:0.11229, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:29.728, tt:208.094\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11192, lr:1.00e-02, fs:0.67000 (r=0.677,p=0.663),  time:29.293, tt:234.343\n",
      "Ep:8, loss:0.00022, loss_test:0.10986, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:29.255, tt:263.294\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10834, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:29.513, tt:295.132\n",
      "Ep:10, loss:0.00021, loss_test:0.10603, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:29.656, tt:326.219\n",
      "Ep:11, loss:0.00020, loss_test:0.10400, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:29.672, tt:356.058\n",
      "Ep:12, loss:0.00019, loss_test:0.10164, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:29.807, tt:387.490\n",
      "Ep:13, loss:0.00019, loss_test:0.09966, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:30.000, tt:419.993\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09762, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:30.186, tt:452.783\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09524, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:30.389, tt:486.222\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09359, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.529, tt:518.999\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09221, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.559, tt:550.060\n",
      "Ep:18, loss:0.00016, loss_test:0.09083, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:30.604, tt:581.476\n",
      "Ep:19, loss:0.00016, loss_test:0.08918, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:30.690, tt:613.800\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08819, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.720, tt:645.129\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08681, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.804, tt:677.695\n",
      "Ep:22, loss:0.00015, loss_test:0.08559, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.843, tt:709.391\n",
      "Ep:23, loss:0.00015, loss_test:0.08487, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.882, tt:741.174\n",
      "Ep:24, loss:0.00014, loss_test:0.08448, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.870, tt:771.753\n",
      "Ep:25, loss:0.00014, loss_test:0.08284, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:30.897, tt:803.317\n",
      "Ep:26, loss:0.00014, loss_test:0.08240, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:30.934, tt:835.220\n",
      "Ep:27, loss:0.00013, loss_test:0.08254, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.981, tt:867.459\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08214, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:31.039, tt:900.131\n",
      "Ep:29, loss:0.00013, loss_test:0.08112, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:31.059, tt:931.771\n",
      "Ep:30, loss:0.00013, loss_test:0.08082, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:31.095, tt:963.942\n",
      "Ep:31, loss:0.00012, loss_test:0.08067, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:31.094, tt:994.999\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.08090, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:31.077, tt:1025.555\n",
      "Ep:33, loss:0.00012, loss_test:0.07964, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:31.095, tt:1057.226\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08029, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:31.071, tt:1087.486\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07928, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:31.100, tt:1119.583\n",
      "Ep:36, loss:0.00011, loss_test:0.07962, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.065, tt:1149.415\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07781, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:31.055, tt:1180.092\n",
      "Ep:38, loss:0.00011, loss_test:0.08095, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:31.081, tt:1212.155\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07796, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.067, tt:1242.691\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07802, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.084, tt:1274.430\n",
      "Ep:41, loss:0.00010, loss_test:0.07782, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.101, tt:1306.257\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.07848, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.090, tt:1336.865\n",
      "Ep:43, loss:0.00009, loss_test:0.07627, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.106, tt:1368.645\n",
      "Ep:44, loss:0.00009, loss_test:0.07727, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:31.137, tt:1401.171\n",
      "Ep:45, loss:0.00009, loss_test:0.07912, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.129, tt:1431.930\n",
      "Ep:46, loss:0.00009, loss_test:0.07528, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.103, tt:1461.829\n",
      "Ep:47, loss:0.00009, loss_test:0.08059, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.107, tt:1493.113\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.07641, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:31.084, tt:1523.113\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.07504, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.088, tt:1554.389\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.07885, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.105, tt:1586.341\n",
      "Ep:51, loss:0.00008, loss_test:0.07617, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.114, tt:1617.946\n",
      "Ep:52, loss:0.00008, loss_test:0.07626, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:31.090, tt:1647.753\n",
      "Ep:53, loss:0.00008, loss_test:0.07837, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:31.091, tt:1678.888\n",
      "Ep:54, loss:0.00007, loss_test:0.07498, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:31.090, tt:1709.923\n",
      "Ep:55, loss:0.00007, loss_test:0.07753, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.079, tt:1740.399\n",
      "Ep:56, loss:0.00007, loss_test:0.07775, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:31.093, tt:1772.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00007, loss_test:0.07409, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.100, tt:1803.796\n",
      "Ep:58, loss:0.00007, loss_test:0.08038, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.091, tt:1834.392\n",
      "Ep:59, loss:0.00007, loss_test:0.07335, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.107, tt:1866.410\n",
      "Ep:60, loss:0.00006, loss_test:0.07780, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.103, tt:1897.305\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.07450, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.079, tt:1926.908\n",
      "Ep:62, loss:0.00006, loss_test:0.07555, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:31.076, tt:1957.772\n",
      "Ep:63, loss:0.00006, loss_test:0.07693, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.090, tt:1989.759\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.07345, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.068, tt:2019.429\n",
      "Ep:65, loss:0.00006, loss_test:0.07786, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:31.072, tt:2050.779\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.07452, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:31.078, tt:2082.245\n",
      "Ep:67, loss:0.00006, loss_test:0.07763, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.083, tt:2113.661\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.07577, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:31.089, tt:2145.109\n",
      "Ep:69, loss:0.00005, loss_test:0.07354, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.106, tt:2177.448\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.07881, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:31.100, tt:2208.074\n",
      "Ep:71, loss:0.00005, loss_test:0.07535, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.114, tt:2240.197\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.07429, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.127, tt:2272.275\n",
      "Ep:73, loss:0.00005, loss_test:0.07760, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.135, tt:2303.981\n",
      "Ep:74, loss:0.00005, loss_test:0.07452, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:31.133, tt:2334.997\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.07630, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.135, tt:2366.223\n",
      "Ep:76, loss:0.00005, loss_test:0.07574, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.137, tt:2397.538\n",
      "Ep:77, loss:0.00004, loss_test:0.07518, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.111, tt:2426.666\n",
      "Ep:78, loss:0.00004, loss_test:0.07704, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.119, tt:2458.396\n",
      "Ep:79, loss:0.00004, loss_test:0.07518, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.109, tt:2488.701\n",
      "Ep:80, loss:0.00004, loss_test:0.07616, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.120, tt:2520.740\n",
      "Ep:81, loss:0.00004, loss_test:0.07697, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.140, tt:2553.448\n",
      "Ep:82, loss:0.00004, loss_test:0.07573, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.150, tt:2585.479\n",
      "Ep:83, loss:0.00004, loss_test:0.07712, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:31.150, tt:2616.630\n",
      "Ep:84, loss:0.00004, loss_test:0.07783, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:31.119, tt:2645.138\n",
      "Ep:85, loss:0.00004, loss_test:0.07732, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.117, tt:2676.097\n",
      "Ep:86, loss:0.00004, loss_test:0.07636, lr:9.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.125, tt:2707.849\n",
      "Ep:87, loss:0.00004, loss_test:0.07715, lr:9.80e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.129, tt:2739.340\n",
      "Ep:88, loss:0.00004, loss_test:0.07763, lr:9.70e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.129, tt:2770.460\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00004, loss_test:0.07470, lr:9.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.133, tt:2801.967\n",
      "Ep:90, loss:0.00003, loss_test:0.07842, lr:9.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.121, tt:2831.967\n",
      "Ep:91, loss:0.00003, loss_test:0.07646, lr:9.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.139, tt:2864.831\n",
      "Ep:92, loss:0.00003, loss_test:0.07622, lr:9.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.137, tt:2895.735\n",
      "Ep:93, loss:0.00003, loss_test:0.07962, lr:9.70e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.139, tt:2927.055\n",
      "Ep:94, loss:0.00003, loss_test:0.07555, lr:9.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.143, tt:2958.586\n",
      "Ep:95, loss:0.00003, loss_test:0.08215, lr:9.70e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.165, tt:2991.805\n",
      "Ep:96, loss:0.00003, loss_test:0.07454, lr:9.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.161, tt:3022.661\n",
      "Ep:97, loss:0.00003, loss_test:0.08147, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.177, tt:3055.333\n",
      "Ep:98, loss:0.00003, loss_test:0.07477, lr:9.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.188, tt:3087.593\n",
      "Ep:99, loss:0.00003, loss_test:0.08365, lr:9.70e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.204, tt:3120.360\n",
      "Ep:100, loss:0.00003, loss_test:0.07497, lr:9.61e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.211, tt:3152.299\n",
      "Ep:101, loss:0.00003, loss_test:0.08006, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.219, tt:3184.306\n",
      "Ep:102, loss:0.00003, loss_test:0.08038, lr:9.41e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.223, tt:3215.938\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00003, loss_test:0.07766, lr:9.41e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.236, tt:3248.562\n",
      "Ep:104, loss:0.00003, loss_test:0.08275, lr:9.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.222, tt:3278.263\n",
      "Ep:105, loss:0.00003, loss_test:0.07530, lr:9.41e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.235, tt:3310.962\n",
      "Ep:106, loss:0.00003, loss_test:0.08272, lr:9.41e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.235, tt:3342.132\n",
      "Ep:107, loss:0.00003, loss_test:0.07771, lr:9.41e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.245, tt:3374.500\n",
      "Ep:108, loss:0.00003, loss_test:0.08141, lr:9.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.256, tt:3406.916\n",
      "Ep:109, loss:0.00003, loss_test:0.07879, lr:9.41e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.255, tt:3438.006\n",
      "Ep:110, loss:0.00002, loss_test:0.07706, lr:9.41e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.280, tt:3472.114\n",
      "Ep:111, loss:0.00002, loss_test:0.08331, lr:9.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.292, tt:3504.708\n",
      "Ep:112, loss:0.00002, loss_test:0.07757, lr:9.41e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.292, tt:3535.964\n",
      "Ep:113, loss:0.00002, loss_test:0.08376, lr:9.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.298, tt:3567.975\n",
      "Ep:114, loss:0.00002, loss_test:0.07859, lr:9.32e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.317, tt:3601.451\n",
      "Ep:115, loss:0.00002, loss_test:0.08527, lr:9.23e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.326, tt:3633.777\n",
      "Ep:116, loss:0.00002, loss_test:0.08181, lr:9.14e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.326, tt:3665.188\n",
      "Ep:117, loss:0.00002, loss_test:0.07682, lr:9.04e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.331, tt:3697.090\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00002, loss_test:0.08813, lr:9.04e-03, fs:0.83429 (r=0.737,p=0.961),  time:31.321, tt:3727.165\n",
      "Ep:119, loss:0.00002, loss_test:0.07576, lr:9.04e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.326, tt:3759.073\n",
      "Ep:120, loss:0.00002, loss_test:0.08717, lr:9.04e-03, fs:0.84091 (r=0.747,p=0.961),  time:31.337, tt:3791.801\n",
      "Ep:121, loss:0.00002, loss_test:0.08060, lr:9.04e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.357, tt:3825.518\n",
      "Ep:122, loss:0.00002, loss_test:0.07926, lr:9.04e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.342, tt:3855.081\n",
      "Ep:123, loss:0.00002, loss_test:0.08966, lr:9.04e-03, fs:0.85714 (r=0.758,p=0.987),  time:31.345, tt:3886.780\n",
      "Ep:124, loss:0.00002, loss_test:0.07688, lr:9.04e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.347, tt:3918.319\n",
      "Ep:125, loss:0.00002, loss_test:0.08402, lr:9.04e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.352, tt:3950.347\n",
      "Ep:126, loss:0.00002, loss_test:0.08285, lr:9.04e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.348, tt:3981.225\n",
      "Ep:127, loss:0.00002, loss_test:0.07919, lr:9.04e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.347, tt:4012.440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00002, loss_test:0.08521, lr:9.04e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.353, tt:4044.528\n",
      "Ep:129, loss:0.00002, loss_test:0.07812, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.366, tt:4077.581\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00002, loss_test:0.08441, lr:8.95e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.365, tt:4108.850\n",
      "Ep:131, loss:0.00002, loss_test:0.08167, lr:8.95e-03, fs:0.87500 (r=0.778,p=1.000),  time:31.372, tt:4141.137\n",
      "Ep:132, loss:0.00002, loss_test:0.08096, lr:8.95e-03, fs:0.87500 (r=0.778,p=1.000),  time:31.382, tt:4173.805\n",
      "Ep:133, loss:0.00002, loss_test:0.08593, lr:8.95e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.383, tt:4205.341\n",
      "Ep:134, loss:0.00002, loss_test:0.07786, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.391, tt:4237.724\n",
      "Ep:135, loss:0.00002, loss_test:0.08618, lr:8.95e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.392, tt:4269.247\n",
      "Ep:136, loss:0.00002, loss_test:0.07986, lr:8.95e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.383, tt:4299.508\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00002, loss_test:0.08142, lr:8.95e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.383, tt:4330.886\n",
      "Ep:138, loss:0.00002, loss_test:0.08391, lr:8.95e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.378, tt:4361.544\n",
      "Ep:139, loss:0.00001, loss_test:0.07812, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.371, tt:4391.908\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-2\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,140,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14448, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:70.307, tt:70.307\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00095, loss_test:0.13814, lr:1.00e-02, fs:0.63571 (r=0.899,p=0.492),  time:94.393, tt:188.785\n",
      "Ep:2, loss:0.00085, loss_test:0.12775, lr:1.00e-02, fs:0.67265 (r=0.758,p=0.605),  time:101.702, tt:305.105\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00079, loss_test:0.11938, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:105.273, tt:421.092\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00072, loss_test:0.11033, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:108.180, tt:540.897\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00066, loss_test:0.10190, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:109.712, tt:658.272\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00061, loss_test:0.09466, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:111.052, tt:777.366\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00057, loss_test:0.09148, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:111.849, tt:894.789\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00053, loss_test:0.08864, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:112.575, tt:1013.174\n",
      "Ep:9, loss:0.00050, loss_test:0.08795, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:113.033, tt:1130.333\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00046, loss_test:0.08620, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:113.427, tt:1247.694\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00043, loss_test:0.08508, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:113.745, tt:1364.943\n",
      "Ep:12, loss:0.00040, loss_test:0.08417, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:113.925, tt:1481.026\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00037, loss_test:0.08048, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:114.421, tt:1601.899\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00034, loss_test:0.08049, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:114.774, tt:1721.609\n",
      "Ep:15, loss:0.00031, loss_test:0.07950, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:114.829, tt:1837.261\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.08146, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:114.989, tt:1954.805\n",
      "Ep:17, loss:0.00026, loss_test:0.08092, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:115.192, tt:2073.453\n",
      "Ep:18, loss:0.00023, loss_test:0.07818, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:115.484, tt:2194.192\n",
      "Ep:19, loss:0.00021, loss_test:0.07804, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:115.586, tt:2311.715\n",
      "Ep:20, loss:0.00019, loss_test:0.07596, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:115.769, tt:2431.154\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.07680, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:115.875, tt:2549.241\n",
      "Ep:22, loss:0.00016, loss_test:0.07466, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:115.890, tt:2665.459\n",
      "Ep:23, loss:0.00015, loss_test:0.07844, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:115.779, tt:2778.702\n",
      "Ep:24, loss:0.00014, loss_test:0.07569, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:115.848, tt:2896.202\n",
      "Ep:25, loss:0.00013, loss_test:0.07466, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:115.964, tt:3015.073\n",
      "Ep:26, loss:0.00012, loss_test:0.07538, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:115.973, tt:3131.272\n",
      "Ep:27, loss:0.00011, loss_test:0.07451, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:116.079, tt:3250.219\n",
      "Ep:28, loss:0.00010, loss_test:0.07761, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:116.107, tt:3367.098\n",
      "Ep:29, loss:0.00010, loss_test:0.07772, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:116.123, tt:3483.678\n",
      "Ep:30, loss:0.00009, loss_test:0.07627, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:116.129, tt:3599.984\n",
      "Ep:31, loss:0.00008, loss_test:0.07772, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:116.085, tt:3714.727\n",
      "Ep:32, loss:0.00008, loss_test:0.07745, lr:9.90e-03, fs:0.81609 (r=0.717,p=0.947),  time:116.096, tt:3831.158\n",
      "Ep:33, loss:0.00008, loss_test:0.07753, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:116.210, tt:3951.149\n",
      "Ep:34, loss:0.00007, loss_test:0.07718, lr:9.70e-03, fs:0.82955 (r=0.737,p=0.948),  time:116.177, tt:4066.193\n",
      "Ep:35, loss:0.00007, loss_test:0.08033, lr:9.61e-03, fs:0.80233 (r=0.697,p=0.945),  time:116.186, tt:4182.681\n",
      "Ep:36, loss:0.00006, loss_test:0.08180, lr:9.51e-03, fs:0.80925 (r=0.707,p=0.946),  time:116.194, tt:4299.160\n",
      "Ep:37, loss:0.00006, loss_test:0.07995, lr:9.41e-03, fs:0.80925 (r=0.707,p=0.946),  time:116.232, tt:4416.816\n",
      "Ep:38, loss:0.00006, loss_test:0.08253, lr:9.32e-03, fs:0.79769 (r=0.697,p=0.932),  time:116.257, tt:4534.024\n",
      "Ep:39, loss:0.00005, loss_test:0.08036, lr:9.23e-03, fs:0.80925 (r=0.707,p=0.946),  time:116.242, tt:4649.679\n",
      "Ep:40, loss:0.00005, loss_test:0.08021, lr:9.14e-03, fs:0.80233 (r=0.697,p=0.945),  time:116.204, tt:4764.382\n",
      "Ep:41, loss:0.00005, loss_test:0.08085, lr:9.04e-03, fs:0.79769 (r=0.697,p=0.932),  time:116.172, tt:4879.226\n",
      "Ep:43, loss:0.00004, loss_test:0.08140, lr:8.86e-03, fs:0.75904 (r=0.636,p=0.940),  time:116.169, tt:5111.440\n",
      "Ep:44, loss:0.00004, loss_test:0.08419, lr:8.78e-03, fs:0.72840 (r=0.596,p=0.937),  time:116.174, tt:5227.821\n",
      "Ep:45, loss:0.00004, loss_test:0.08452, lr:8.69e-03, fs:0.71250 (r=0.576,p=0.934),  time:116.164, tt:5343.559\n",
      "Ep:46, loss:0.00004, loss_test:0.08629, lr:8.60e-03, fs:0.71250 (r=0.576,p=0.934),  time:116.158, tt:5459.430\n",
      "Ep:47, loss:0.00004, loss_test:0.08550, lr:8.51e-03, fs:0.71250 (r=0.576,p=0.934),  time:116.138, tt:5574.603\n",
      "Ep:48, loss:0.00003, loss_test:0.08496, lr:8.43e-03, fs:0.71250 (r=0.576,p=0.934),  time:116.206, tt:5694.107\n",
      "Ep:49, loss:0.00003, loss_test:0.08586, lr:8.35e-03, fs:0.71250 (r=0.576,p=0.934),  time:116.231, tt:5811.542\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "ITERATION: 0\n",
      "ITERATION: 1\n",
      "ITERATION: 2\n",
      "ITERATION: 3\n",
      "ITERATION: 4\n",
      "ITERATION: 5\n",
      "ITERATION: 6\n",
      "ITERATION: 7\n",
      "ITERATION: 8\n",
      "ITERATION: 9\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 4096: \n",
      "Ep:0, loss:0.00007, loss_test:0.14354, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.419, tt:8.419\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.14263, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.284, tt:16.568\n",
      "Ep:2, loss:0.00007, loss_test:0.14106, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.269, tt:24.807\n",
      "Ep:3, loss:0.00007, loss_test:0.13859, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:8.271, tt:33.083\n",
      "Ep:4, loss:0.00007, loss_test:0.13510, lr:1.00e-02, fs:0.63636 (r=0.919,p=0.487),  time:8.259, tt:41.297\n",
      "Ep:5, loss:0.00006, loss_test:0.12999, lr:1.00e-02, fs:0.64122 (r=0.848,p=0.515),  time:8.244, tt:49.465\n",
      "Ep:6, loss:0.00006, loss_test:0.12338, lr:1.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:8.240, tt:57.677\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00006, loss_test:0.12019, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:8.236, tt:65.889\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00006, loss_test:0.11976, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:8.235, tt:74.119\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00006, loss_test:0.11731, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:8.243, tt:82.432\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00005, loss_test:0.11437, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:8.245, tt:90.696\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00005, loss_test:0.11218, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:8.247, tt:98.968\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.11094, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:8.248, tt:107.218\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00005, loss_test:0.10990, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:8.251, tt:115.515\n",
      "Ep:14, loss:0.00005, loss_test:0.10726, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:8.253, tt:123.799\n",
      "Ep:15, loss:0.00005, loss_test:0.10494, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:8.256, tt:132.097\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00005, loss_test:0.10293, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:8.291, tt:140.945\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00005, loss_test:0.10105, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:8.370, tt:150.656\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.09812, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:8.443, tt:160.421\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.09666, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:8.644, tt:172.887\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.09610, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:9.203, tt:193.260\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.09529, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:9.873, tt:217.203\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.09388, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:10.778, tt:247.885\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.09277, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:11.684, tt:280.423\n",
      "Ep:24, loss:0.00004, loss_test:0.09195, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:12.464, tt:311.610\n",
      "Ep:25, loss:0.00004, loss_test:0.09069, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:13.380, tt:347.877\n",
      "Ep:26, loss:0.00004, loss_test:0.08986, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:14.083, tt:380.245\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.08976, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:14.725, tt:412.299\n",
      "Ep:28, loss:0.00004, loss_test:0.08915, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:15.253, tt:442.337\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.08821, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:15.791, tt:473.723\n",
      "Ep:30, loss:0.00003, loss_test:0.08749, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:16.330, tt:506.226\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.08724, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:16.809, tt:537.898\n",
      "Ep:32, loss:0.00003, loss_test:0.08661, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:17.252, tt:569.325\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.08590, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:17.662, tt:600.509\n",
      "Ep:34, loss:0.00003, loss_test:0.08587, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:17.991, tt:629.688\n",
      "Ep:35, loss:0.00003, loss_test:0.08527, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:18.343, tt:660.363\n",
      "Ep:36, loss:0.00003, loss_test:0.08517, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:18.712, tt:692.352\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.08498, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:19.030, tt:723.129\n",
      "Ep:38, loss:0.00003, loss_test:0.08455, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:19.319, tt:753.438\n",
      "Ep:39, loss:0.00003, loss_test:0.08445, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:19.641, tt:785.645\n",
      "Ep:40, loss:0.00003, loss_test:0.08424, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:19.906, tt:816.153\n",
      "Ep:41, loss:0.00003, loss_test:0.08433, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:20.202, tt:848.486\n",
      "Ep:42, loss:0.00003, loss_test:0.08383, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:20.445, tt:879.121\n",
      "Ep:43, loss:0.00003, loss_test:0.08331, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:20.686, tt:910.164\n",
      "Ep:44, loss:0.00003, loss_test:0.08315, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:20.939, tt:942.243\n",
      "Ep:45, loss:0.00002, loss_test:0.08306, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:21.180, tt:974.270\n",
      "Ep:46, loss:0.00002, loss_test:0.08297, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:21.408, tt:1006.163\n",
      "Ep:47, loss:0.00002, loss_test:0.08207, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:21.624, tt:1037.938\n",
      "Ep:48, loss:0.00002, loss_test:0.08230, lr:9.90e-03, fs:0.80851 (r=0.768,p=0.854),  time:21.830, tt:1069.661\n",
      "Ep:49, loss:0.00002, loss_test:0.08155, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:22.041, tt:1102.064\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=4096 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "ITERATION: 0\n",
      "ITERATION: 1\n",
      "ITERATION: 2\n",
      "ITERATION: 3\n",
      "ITERATION: 4\n",
      "ITERATION: 5\n",
      "ITERATION: 6\n",
      "ITERATION: 7\n",
      "ITERATION: 8\n",
      "ITERATION: 9\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14736, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.572, tt:16.572\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14525, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:16.391, tt:32.781\n",
      "Ep:2, loss:0.00052, loss_test:0.13865, lr:1.00e-02, fs:0.62921 (r=0.848,p=0.500),  time:16.304, tt:48.913\n",
      "Ep:3, loss:0.00047, loss_test:0.13544, lr:1.00e-02, fs:0.60204 (r=0.596,p=0.608),  time:16.292, tt:65.168\n",
      "Ep:4, loss:0.00044, loss_test:0.12952, lr:1.00e-02, fs:0.64574 (r=0.727,p=0.581),  time:16.318, tt:81.588\n",
      "Ep:5, loss:0.00041, loss_test:0.12517, lr:1.00e-02, fs:0.65728 (r=0.707,p=0.614),  time:16.304, tt:97.824\n",
      "Ep:6, loss:0.00038, loss_test:0.12440, lr:1.00e-02, fs:0.63959 (r=0.636,p=0.643),  time:16.313, tt:114.188\n",
      "Ep:7, loss:0.00035, loss_test:0.11820, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:16.318, tt:130.544\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00033, loss_test:0.11631, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:16.318, tt:146.865\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00031, loss_test:0.11461, lr:1.00e-02, fs:0.64078 (r=0.667,p=0.617),  time:16.310, tt:163.095\n",
      "Ep:10, loss:0.00030, loss_test:0.11281, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:16.321, tt:179.531\n",
      "Ep:11, loss:0.00028, loss_test:0.11188, lr:1.00e-02, fs:0.64921 (r=0.626,p=0.674),  time:16.328, tt:195.939\n",
      "Ep:12, loss:0.00027, loss_test:0.10893, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:16.336, tt:212.366\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.10883, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:16.340, tt:228.763\n",
      "Ep:14, loss:0.00024, loss_test:0.10704, lr:1.00e-02, fs:0.67980 (r=0.697,p=0.663),  time:16.339, tt:245.087\n",
      "Ep:15, loss:0.00023, loss_test:0.10666, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:16.341, tt:261.459\n",
      "Ep:16, loss:0.00022, loss_test:0.10481, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:16.342, tt:277.811\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10361, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:16.339, tt:294.108\n",
      "Ep:18, loss:0.00020, loss_test:0.10312, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:16.339, tt:310.444\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.10172, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:16.343, tt:326.862\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.10213, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:16.340, tt:343.145\n",
      "Ep:21, loss:0.00017, loss_test:0.09942, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:16.339, tt:359.461\n",
      "Ep:22, loss:0.00016, loss_test:0.10131, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:16.338, tt:375.764\n",
      "Ep:23, loss:0.00016, loss_test:0.09873, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:16.335, tt:392.040\n",
      "Ep:24, loss:0.00015, loss_test:0.10019, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:16.335, tt:408.367\n",
      "Ep:25, loss:0.00014, loss_test:0.09992, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:16.336, tt:424.732\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09917, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:16.339, tt:441.165\n",
      "Ep:27, loss:0.00013, loss_test:0.09493, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:16.343, tt:457.613\n",
      "Ep:28, loss:0.00013, loss_test:0.09754, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:16.347, tt:474.049\n",
      "Ep:29, loss:0.00012, loss_test:0.09477, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:16.347, tt:490.405\n",
      "Ep:30, loss:0.00011, loss_test:0.09427, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:16.353, tt:506.949\n",
      "Ep:31, loss:0.00011, loss_test:0.09374, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:16.359, tt:523.477\n",
      "Ep:32, loss:0.00010, loss_test:0.09322, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:16.363, tt:539.989\n",
      "Ep:33, loss:0.00010, loss_test:0.09393, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:16.362, tt:556.309\n",
      "Ep:34, loss:0.00009, loss_test:0.09273, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:16.364, tt:572.741\n",
      "Ep:35, loss:0.00009, loss_test:0.09192, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:16.367, tt:589.229\n",
      "Ep:36, loss:0.00009, loss_test:0.09230, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:16.368, tt:605.618\n",
      "Ep:37, loss:0.00008, loss_test:0.09232, lr:9.90e-03, fs:0.71429 (r=0.758,p=0.676),  time:16.369, tt:622.004\n",
      "Ep:38, loss:0.00008, loss_test:0.09316, lr:9.80e-03, fs:0.70813 (r=0.747,p=0.673),  time:16.371, tt:638.455\n",
      "Ep:39, loss:0.00008, loss_test:0.09108, lr:9.70e-03, fs:0.71770 (r=0.758,p=0.682),  time:16.371, tt:654.827\n",
      "Ep:40, loss:0.00008, loss_test:0.09318, lr:9.61e-03, fs:0.71090 (r=0.758,p=0.670),  time:16.369, tt:671.141\n",
      "Ep:41, loss:0.00007, loss_test:0.09121, lr:9.51e-03, fs:0.72115 (r=0.758,p=0.688),  time:16.368, tt:687.446\n",
      "Ep:42, loss:0.00007, loss_test:0.08993, lr:9.41e-03, fs:0.71921 (r=0.737,p=0.702),  time:16.368, tt:703.841\n",
      "Ep:43, loss:0.00006, loss_test:0.08973, lr:9.32e-03, fs:0.71921 (r=0.737,p=0.702),  time:16.368, tt:720.187\n",
      "Ep:44, loss:0.00006, loss_test:0.08995, lr:9.23e-03, fs:0.71569 (r=0.737,p=0.695),  time:16.369, tt:736.592\n",
      "Ep:45, loss:0.00006, loss_test:0.08917, lr:9.14e-03, fs:0.72637 (r=0.737,p=0.716),  time:16.367, tt:752.876\n",
      "Ep:46, loss:0.00006, loss_test:0.08767, lr:9.04e-03, fs:0.71569 (r=0.737,p=0.695),  time:16.368, tt:769.284\n",
      "Ep:47, loss:0.00006, loss_test:0.08944, lr:8.95e-03, fs:0.70531 (r=0.737,p=0.676),  time:16.366, tt:785.592\n",
      "Ep:48, loss:0.00006, loss_test:0.08849, lr:8.86e-03, fs:0.71220 (r=0.737,p=0.689),  time:16.365, tt:801.904\n",
      "Ep:49, loss:0.00005, loss_test:0.08799, lr:8.78e-03, fs:0.71921 (r=0.737,p=0.702),  time:16.368, tt:818.388\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 6400 Test samples: 198\n",
      "Train positive samples: 3200 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00096, loss_test:0.13222, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:36.452, tt:36.452\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00086, loss_test:0.11779, lr:1.00e-02, fs:0.64390 (r=0.667,p=0.623),  time:52.515, tt:105.030\n",
      "Ep:2, loss:0.00078, loss_test:0.10920, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:72.022, tt:216.065\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00070, loss_test:0.10405, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:83.310, tt:333.239\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00064, loss_test:0.09696, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:90.032, tt:450.161\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00059, loss_test:0.09197, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:93.865, tt:563.192\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00054, loss_test:0.08928, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:96.896, tt:678.274\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00050, loss_test:0.08628, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:99.306, tt:794.452\n",
      "Ep:8, loss:0.00046, loss_test:0.08646, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:101.129, tt:910.160\n",
      "Ep:9, loss:0.00042, loss_test:0.08275, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:102.522, tt:1025.223\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00038, loss_test:0.08577, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:103.552, tt:1139.069\n",
      "Ep:11, loss:0.00035, loss_test:0.07996, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:104.405, tt:1252.860\n",
      "Ep:12, loss:0.00032, loss_test:0.08225, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:105.026, tt:1365.332\n",
      "Ep:13, loss:0.00029, loss_test:0.07943, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:105.659, tt:1479.231\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.08083, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:106.614, tt:1599.213\n",
      "Ep:15, loss:0.00023, loss_test:0.08174, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:107.368, tt:1717.896\n",
      "Ep:16, loss:0.00020, loss_test:0.08067, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:107.916, tt:1834.578\n",
      "Ep:17, loss:0.00018, loss_test:0.08159, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:108.229, tt:1948.125\n",
      "Ep:18, loss:0.00017, loss_test:0.08078, lr:1.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:108.512, tt:2061.732\n",
      "Ep:19, loss:0.00015, loss_test:0.08426, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:108.835, tt:2176.692\n",
      "Ep:20, loss:0.00014, loss_test:0.07917, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:109.056, tt:2290.175\n",
      "Ep:21, loss:0.00012, loss_test:0.07862, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:109.384, tt:2406.446\n",
      "Ep:22, loss:0.00011, loss_test:0.07713, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:109.538, tt:2519.370\n",
      "Ep:23, loss:0.00010, loss_test:0.07612, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:109.688, tt:2632.505\n",
      "Ep:24, loss:0.00009, loss_test:0.07692, lr:1.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:109.881, tt:2747.032\n",
      "Ep:25, loss:0.00009, loss_test:0.08167, lr:9.90e-03, fs:0.78571 (r=0.667,p=0.957),  time:110.062, tt:2861.607\n",
      "Ep:26, loss:0.00008, loss_test:0.08042, lr:9.80e-03, fs:0.79532 (r=0.687,p=0.944),  time:110.238, tt:2976.422\n",
      "Ep:27, loss:0.00008, loss_test:0.07920, lr:9.70e-03, fs:0.78571 (r=0.667,p=0.957),  time:110.466, tt:3093.062\n",
      "Ep:28, loss:0.00007, loss_test:0.08308, lr:9.61e-03, fs:0.79769 (r=0.697,p=0.932),  time:110.618, tt:3207.930\n",
      "Ep:29, loss:0.00007, loss_test:0.07952, lr:9.51e-03, fs:0.78571 (r=0.667,p=0.957),  time:110.838, tt:3325.142\n",
      "Ep:30, loss:0.00006, loss_test:0.07967, lr:9.41e-03, fs:0.78571 (r=0.667,p=0.957),  time:110.913, tt:3438.318\n",
      "Ep:31, loss:0.00006, loss_test:0.08113, lr:9.32e-03, fs:0.78571 (r=0.667,p=0.957),  time:111.012, tt:3552.373\n",
      "Ep:32, loss:0.00005, loss_test:0.08096, lr:9.23e-03, fs:0.78571 (r=0.667,p=0.957),  time:111.088, tt:3665.901\n",
      "Ep:33, loss:0.00005, loss_test:0.08364, lr:9.14e-03, fs:0.79042 (r=0.667,p=0.971),  time:111.182, tt:3780.180\n",
      "Ep:34, loss:0.00005, loss_test:0.08420, lr:9.04e-03, fs:0.78571 (r=0.667,p=0.957),  time:111.187, tt:3891.531\n",
      "Ep:35, loss:0.00004, loss_test:0.08369, lr:8.95e-03, fs:0.79042 (r=0.667,p=0.971),  time:111.365, tt:4009.149\n",
      "Ep:36, loss:0.00004, loss_test:0.08393, lr:8.86e-03, fs:0.78313 (r=0.657,p=0.970),  time:111.449, tt:4123.620\n",
      "Ep:37, loss:0.00004, loss_test:0.08487, lr:8.78e-03, fs:0.78571 (r=0.667,p=0.957),  time:111.552, tt:4238.992\n",
      "Ep:38, loss:0.00004, loss_test:0.08275, lr:8.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:111.671, tt:4355.167\n",
      "Ep:39, loss:0.00003, loss_test:0.08561, lr:8.60e-03, fs:0.79042 (r=0.667,p=0.971),  time:111.748, tt:4469.938\n",
      "Ep:40, loss:0.00003, loss_test:0.08729, lr:8.51e-03, fs:0.69677 (r=0.545,p=0.964),  time:111.923, tt:4588.838\n",
      "Ep:41, loss:0.00003, loss_test:0.08686, lr:8.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:111.927, tt:4700.934\n",
      "Ep:42, loss:0.00003, loss_test:0.08573, lr:8.35e-03, fs:0.69677 (r=0.545,p=0.964),  time:112.048, tt:4818.053\n",
      "Ep:43, loss:0.00003, loss_test:0.08599, lr:8.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:112.104, tt:4932.584\n",
      "Ep:44, loss:0.00003, loss_test:0.08594, lr:8.18e-03, fs:0.70513 (r=0.556,p=0.965),  time:112.118, tt:5045.328\n",
      "Ep:45, loss:0.00002, loss_test:0.08760, lr:8.10e-03, fs:0.69677 (r=0.545,p=0.964),  time:112.195, tt:5160.960\n",
      "Ep:46, loss:0.00002, loss_test:0.08718, lr:8.02e-03, fs:0.69677 (r=0.545,p=0.964),  time:112.243, tt:5275.436\n",
      "Ep:47, loss:0.00002, loss_test:0.08969, lr:7.94e-03, fs:0.69677 (r=0.545,p=0.964),  time:112.307, tt:5390.743\n",
      "Ep:48, loss:0.00002, loss_test:0.08984, lr:7.86e-03, fs:0.70130 (r=0.545,p=0.982),  time:112.391, tt:5507.138\n",
      "Ep:49, loss:0.00002, loss_test:0.08996, lr:7.78e-03, fs:0.70130 (r=0.545,p=0.982),  time:112.472, tt:5623.617\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 6400 Test samples: 198\n",
      "Train positive samples: 3200 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00028, loss_test:0.14190, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.445, tt:16.445\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13836, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.985, tt:31.970\n",
      "Ep:2, loss:0.00027, loss_test:0.12969, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:15.858, tt:47.573\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11487, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:15.799, tt:63.195\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00022, loss_test:0.11261, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:15.782, tt:78.910\n",
      "Ep:5, loss:0.00021, loss_test:0.10664, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:15.766, tt:94.597\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00020, loss_test:0.10231, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:15.774, tt:110.419\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00019, loss_test:0.09794, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:15.761, tt:126.087\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00018, loss_test:0.09437, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:15.749, tt:141.737\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00017, loss_test:0.09144, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:15.741, tt:157.412\n",
      "Ep:10, loss:0.00017, loss_test:0.08993, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:15.731, tt:173.039\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00016, loss_test:0.08706, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:15.722, tt:188.662\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00015, loss_test:0.08634, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:15.716, tt:204.308\n",
      "Ep:13, loss:0.00015, loss_test:0.08488, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:15.709, tt:219.928\n",
      "Ep:14, loss:0.00014, loss_test:0.08404, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:15.705, tt:235.576\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00014, loss_test:0.08389, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:15.699, tt:251.190\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00013, loss_test:0.08324, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:15.697, tt:266.856\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00012, loss_test:0.08401, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:15.695, tt:282.506\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00012, loss_test:0.08188, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:15.700, tt:298.295\n",
      "Ep:19, loss:0.00011, loss_test:0.08369, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:15.699, tt:313.987\n",
      "Ep:20, loss:0.00010, loss_test:0.08348, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:15.698, tt:329.655\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.08143, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:15.696, tt:345.305\n",
      "Ep:22, loss:0.00009, loss_test:0.08533, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:15.695, tt:360.977\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.08311, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:15.691, tt:376.578\n",
      "Ep:24, loss:0.00008, loss_test:0.08435, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:15.693, tt:392.327\n",
      "Ep:25, loss:0.00008, loss_test:0.08363, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:15.693, tt:408.022\n",
      "Ep:26, loss:0.00007, loss_test:0.08419, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:15.696, tt:423.782\n",
      "Ep:27, loss:0.00007, loss_test:0.08488, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:15.698, tt:439.542\n",
      "Ep:28, loss:0.00007, loss_test:0.08588, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:15.699, tt:455.274\n",
      "Ep:29, loss:0.00006, loss_test:0.08013, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:15.699, tt:470.981\n",
      "Ep:30, loss:0.00006, loss_test:0.08301, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:15.699, tt:486.684\n",
      "Ep:31, loss:0.00006, loss_test:0.08786, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:15.699, tt:502.356\n",
      "Ep:32, loss:0.00005, loss_test:0.08562, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:15.698, tt:518.024\n",
      "Ep:33, loss:0.00005, loss_test:0.08414, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:15.701, tt:533.824\n",
      "Ep:34, loss:0.00005, loss_test:0.08115, lr:9.90e-03, fs:0.82418 (r=0.758,p=0.904),  time:15.699, tt:549.456\n",
      "Ep:35, loss:0.00005, loss_test:0.08804, lr:9.80e-03, fs:0.74251 (r=0.626,p=0.912),  time:15.696, tt:565.060\n",
      "Ep:36, loss:0.00005, loss_test:0.08630, lr:9.70e-03, fs:0.75000 (r=0.636,p=0.913),  time:15.697, tt:580.800\n",
      "Ep:37, loss:0.00004, loss_test:0.08691, lr:9.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:15.696, tt:596.432\n",
      "Ep:38, loss:0.00004, loss_test:0.08567, lr:9.51e-03, fs:0.75152 (r=0.626,p=0.939),  time:15.694, tt:612.059\n",
      "Ep:39, loss:0.00004, loss_test:0.08609, lr:9.41e-03, fs:0.75152 (r=0.626,p=0.939),  time:15.692, tt:627.697\n",
      "Ep:40, loss:0.00004, loss_test:0.08891, lr:9.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:15.691, tt:643.341\n",
      "Ep:41, loss:0.00004, loss_test:0.08715, lr:9.23e-03, fs:0.74390 (r=0.616,p=0.938),  time:15.691, tt:659.024\n",
      "Ep:42, loss:0.00003, loss_test:0.08841, lr:9.14e-03, fs:0.74390 (r=0.616,p=0.938),  time:15.691, tt:674.696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3e961e20528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,43,cv_number,4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14438, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.701, tt:8.701\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14385, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.016, tt:18.032\n",
      "Ep:2, loss:0.00014, loss_test:0.14301, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.246, tt:27.738\n",
      "Ep:3, loss:0.00014, loss_test:0.14183, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.420, tt:37.680\n",
      "Ep:4, loss:0.00014, loss_test:0.14020, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.260, tt:51.299\n",
      "Ep:5, loss:0.00014, loss_test:0.13797, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:11.753, tt:70.516\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00013, loss_test:0.13465, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:13.804, tt:96.629\n",
      "Ep:7, loss:0.00013, loss_test:0.12942, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:16.067, tt:128.533\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00013, loss_test:0.12150, lr:1.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:17.835, tt:160.511\n",
      "Ep:9, loss:0.00012, loss_test:0.11581, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:19.242, tt:192.418\n",
      "Ep:10, loss:0.00011, loss_test:0.11541, lr:1.00e-02, fs:0.59091 (r=0.525,p=0.675),  time:20.445, tt:224.893\n",
      "Ep:11, loss:0.00011, loss_test:0.11425, lr:1.00e-02, fs:0.59091 (r=0.525,p=0.675),  time:21.376, tt:256.516\n",
      "Ep:12, loss:0.00011, loss_test:0.11242, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:22.321, tt:290.171\n",
      "Ep:13, loss:0.00011, loss_test:0.10986, lr:1.00e-02, fs:0.66667 (r=0.646,p=0.688),  time:23.044, tt:322.610\n",
      "Ep:14, loss:0.00010, loss_test:0.10762, lr:1.00e-02, fs:0.65591 (r=0.616,p=0.701),  time:23.777, tt:356.651\n",
      "Ep:15, loss:0.00010, loss_test:0.10695, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:24.278, tt:388.442\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00010, loss_test:0.10532, lr:1.00e-02, fs:0.68449 (r=0.646,p=0.727),  time:24.707, tt:420.020\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.10397, lr:1.00e-02, fs:0.69792 (r=0.677,p=0.720),  time:25.118, tt:452.125\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.10408, lr:1.00e-02, fs:0.69189 (r=0.646,p=0.744),  time:25.519, tt:484.853\n",
      "Ep:19, loss:0.00009, loss_test:0.10454, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:25.884, tt:517.681\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.10356, lr:1.00e-02, fs:0.69189 (r=0.646,p=0.744),  time:26.164, tt:549.450\n",
      "Ep:21, loss:0.00008, loss_test:0.10254, lr:1.00e-02, fs:0.69892 (r=0.657,p=0.747),  time:26.460, tt:582.117\n",
      "Ep:22, loss:0.00008, loss_test:0.10268, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:26.706, tt:614.233\n",
      "Ep:23, loss:0.00008, loss_test:0.10209, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:27.101, tt:650.415\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00008, loss_test:0.10135, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:27.358, tt:683.956\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.10179, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:27.528, tt:715.737\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.10241, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:27.709, tt:748.146\n",
      "Ep:27, loss:0.00007, loss_test:0.10043, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:27.935, tt:782.177\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.10014, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:28.080, tt:814.310\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00007, loss_test:0.09949, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:28.173, tt:845.188\n",
      "Ep:30, loss:0.00006, loss_test:0.09911, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:28.287, tt:876.908\n",
      "Ep:31, loss:0.00006, loss_test:0.09945, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:28.482, tt:911.436\n",
      "Ep:32, loss:0.00006, loss_test:0.09885, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:28.611, tt:944.179\n",
      "Ep:33, loss:0.00006, loss_test:0.09843, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:28.695, tt:975.618\n",
      "Ep:34, loss:0.00006, loss_test:0.09912, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:28.808, tt:1008.291\n",
      "Ep:35, loss:0.00006, loss_test:0.09847, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:28.933, tt:1041.606\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.09752, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:29.047, tt:1074.729\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.09881, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:29.126, tt:1106.794\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.09839, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:29.214, tt:1139.327\n",
      "Ep:39, loss:0.00005, loss_test:0.09743, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:29.325, tt:1173.017\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.10036, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.416, tt:1206.041\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.09859, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:29.514, tt:1239.584\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.09656, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:29.610, tt:1273.226\n",
      "Ep:43, loss:0.00005, loss_test:0.09924, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.696, tt:1306.633\n",
      "Ep:44, loss:0.00005, loss_test:0.09763, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:29.794, tt:1340.732\n",
      "Ep:45, loss:0.00004, loss_test:0.09582, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:29.877, tt:1374.351\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.09777, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:29.962, tt:1408.197\n",
      "Ep:47, loss:0.00004, loss_test:0.09766, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.053, tt:1442.540\n",
      "Ep:48, loss:0.00004, loss_test:0.09556, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.132, tt:1476.481\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.09731, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.190, tt:1509.492\n",
      "Ep:50, loss:0.00004, loss_test:0.09663, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.247, tt:1542.576\n",
      "Ep:51, loss:0.00004, loss_test:0.09691, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.300, tt:1575.620\n",
      "Ep:52, loss:0.00004, loss_test:0.09639, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.342, tt:1608.121\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.09703, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.392, tt:1641.144\n",
      "Ep:54, loss:0.00004, loss_test:0.09559, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.444, tt:1674.419\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.09739, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.498, tt:1707.912\n",
      "Ep:56, loss:0.00003, loss_test:0.09520, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.547, tt:1741.198\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.09578, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.564, tt:1772.701\n",
      "Ep:58, loss:0.00003, loss_test:0.09645, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.604, tt:1805.626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.09582, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.616, tt:1836.958\n",
      "Ep:60, loss:0.00003, loss_test:0.09705, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.671, tt:1870.909\n",
      "Ep:61, loss:0.00003, loss_test:0.09550, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.696, tt:1903.148\n",
      "Ep:62, loss:0.00003, loss_test:0.09554, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.734, tt:1936.243\n",
      "Ep:63, loss:0.00003, loss_test:0.09575, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.771, tt:1969.318\n",
      "Ep:64, loss:0.00003, loss_test:0.09598, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.824, tt:2003.529\n",
      "Ep:65, loss:0.00003, loss_test:0.09577, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.850, tt:2036.092\n",
      "Ep:66, loss:0.00003, loss_test:0.09457, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.881, tt:2069.003\n",
      "Ep:67, loss:0.00003, loss_test:0.09503, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.901, tt:2101.246\n",
      "Ep:68, loss:0.00003, loss_test:0.09533, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.945, tt:2135.221\n",
      "Ep:69, loss:0.00003, loss_test:0.09468, lr:9.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.933, tt:2165.302\n",
      "Ep:70, loss:0.00003, loss_test:0.09772, lr:9.70e-03, fs:0.80682 (r=0.717,p=0.922),  time:30.982, tt:2199.752\n",
      "Ep:71, loss:0.00002, loss_test:0.09376, lr:9.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.000, tt:2232.035\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.09622, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.032, tt:2265.357\n",
      "Ep:73, loss:0.00002, loss_test:0.09585, lr:9.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.058, tt:2298.256\n",
      "Ep:74, loss:0.00002, loss_test:0.09405, lr:9.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.098, tt:2332.315\n",
      "Ep:75, loss:0.00002, loss_test:0.09694, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.115, tt:2364.764\n",
      "Ep:76, loss:0.00002, loss_test:0.09411, lr:9.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.138, tt:2397.613\n",
      "Ep:77, loss:0.00002, loss_test:0.09667, lr:9.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:31.166, tt:2430.956\n",
      "Ep:78, loss:0.00002, loss_test:0.09614, lr:9.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.178, tt:2463.087\n",
      "Ep:79, loss:0.00002, loss_test:0.09598, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.206, tt:2496.496\n",
      "Ep:80, loss:0.00002, loss_test:0.09871, lr:9.61e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.258, tt:2531.912\n",
      "Ep:81, loss:0.00002, loss_test:0.09441, lr:9.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.275, tt:2564.571\n",
      "Ep:82, loss:0.00002, loss_test:0.10014, lr:9.61e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.300, tt:2597.879\n",
      "Ep:83, loss:0.00002, loss_test:0.09650, lr:9.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.333, tt:2631.993\n",
      "Ep:84, loss:0.00002, loss_test:0.09662, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.331, tt:2663.173\n",
      "Ep:85, loss:0.00002, loss_test:0.10046, lr:9.32e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.327, tt:2694.084\n",
      "Ep:86, loss:0.00002, loss_test:0.09721, lr:9.23e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.331, tt:2725.755\n",
      "Ep:87, loss:0.00002, loss_test:0.09944, lr:9.14e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.331, tt:2757.131\n",
      "Ep:88, loss:0.00002, loss_test:0.09999, lr:9.04e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.346, tt:2789.806\n",
      "Ep:89, loss:0.00002, loss_test:0.09881, lr:8.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.324, tt:2819.141\n",
      "Ep:90, loss:0.00002, loss_test:0.09969, lr:8.86e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.336, tt:2851.592\n",
      "Ep:91, loss:0.00002, loss_test:0.09955, lr:8.78e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.341, tt:2883.396\n",
      "Ep:92, loss:0.00002, loss_test:0.09935, lr:8.69e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.342, tt:2914.831\n",
      "Ep:93, loss:0.00002, loss_test:0.10053, lr:8.60e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.354, tt:2947.300\n",
      "Ep:94, loss:0.00002, loss_test:0.09981, lr:8.51e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.360, tt:2979.223\n",
      "Ep:95, loss:0.00002, loss_test:0.10062, lr:8.43e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.369, tt:3011.466\n",
      "Ep:96, loss:0.00002, loss_test:0.10078, lr:8.35e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.377, tt:3043.573\n",
      "Ep:97, loss:0.00002, loss_test:0.09825, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.395, tt:3076.680\n",
      "Ep:98, loss:0.00002, loss_test:0.10416, lr:8.18e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.401, tt:3108.670\n",
      "Ep:99, loss:0.00001, loss_test:0.09885, lr:8.10e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.413, tt:3141.305\n",
      "Ep:100, loss:0.00001, loss_test:0.10151, lr:8.02e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.437, tt:3175.185\n",
      "Ep:101, loss:0.00001, loss_test:0.10071, lr:7.94e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.460, tt:3208.938\n",
      "Ep:102, loss:0.00001, loss_test:0.09940, lr:7.86e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.485, tt:3242.945\n",
      "Ep:103, loss:0.00001, loss_test:0.10015, lr:7.78e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.499, tt:3275.848\n",
      "Ep:104, loss:0.00001, loss_test:0.10126, lr:7.70e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.528, tt:3310.449\n",
      "Ep:105, loss:0.00001, loss_test:0.09973, lr:7.62e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.545, tt:3343.816\n",
      "Ep:106, loss:0.00001, loss_test:0.10336, lr:7.55e-03, fs:0.75449 (r=0.636,p=0.926),  time:31.563, tt:3377.231\n",
      "Ep:107, loss:0.00001, loss_test:0.09921, lr:7.47e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.567, tt:3409.218\n",
      "Ep:108, loss:0.00001, loss_test:0.10227, lr:7.40e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.576, tt:3441.837\n",
      "Ep:109, loss:0.00001, loss_test:0.10190, lr:7.32e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.589, tt:3474.829\n",
      "Ep:110, loss:0.00001, loss_test:0.10054, lr:7.25e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.589, tt:3506.415\n",
      "Ep:111, loss:0.00001, loss_test:0.10320, lr:7.18e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.604, tt:3539.671\n",
      "Ep:112, loss:0.00001, loss_test:0.10055, lr:7.11e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.614, tt:3572.329\n",
      "Ep:113, loss:0.00001, loss_test:0.10062, lr:7.03e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.631, tt:3605.920\n",
      "Ep:114, loss:0.00001, loss_test:0.10292, lr:6.96e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.641, tt:3638.660\n",
      "Ep:115, loss:0.00001, loss_test:0.10072, lr:6.89e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.649, tt:3671.227\n",
      "Ep:116, loss:0.00001, loss_test:0.10134, lr:6.83e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.667, tt:3705.034\n",
      "Ep:117, loss:0.00001, loss_test:0.10315, lr:6.76e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.671, tt:3737.213\n",
      "Ep:118, loss:0.00001, loss_test:0.10091, lr:6.69e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.678, tt:3769.708\n",
      "Ep:119, loss:0.00001, loss_test:0.10173, lr:6.62e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.694, tt:3803.305\n",
      "Ep:120, loss:0.00001, loss_test:0.10231, lr:6.56e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.705, tt:3836.361\n",
      "Ep:121, loss:0.00001, loss_test:0.10152, lr:6.49e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.749, tt:3873.319\n",
      "Ep:122, loss:0.00001, loss_test:0.10228, lr:6.43e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.767, tt:3907.371\n",
      "Ep:123, loss:0.00001, loss_test:0.10215, lr:6.36e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.770, tt:3939.514\n",
      "Ep:124, loss:0.00001, loss_test:0.10143, lr:6.30e-03, fs:0.75000 (r=0.636,p=0.913),  time:31.778, tt:3972.193\n",
      "Ep:125, loss:0.00001, loss_test:0.10202, lr:6.24e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.790, tt:4005.530\n",
      "Ep:126, loss:0.00001, loss_test:0.10253, lr:6.17e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.788, tt:4037.114\n",
      "Ep:127, loss:0.00001, loss_test:0.10217, lr:6.11e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.791, tt:4069.305\n",
      "Ep:128, loss:0.00001, loss_test:0.10266, lr:6.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.799, tt:4102.016\n",
      "Ep:129, loss:0.00001, loss_test:0.10240, lr:5.99e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.812, tt:4135.507\n",
      "Ep:130, loss:0.00001, loss_test:0.10137, lr:5.93e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.821, tt:4168.541\n",
      "Ep:131, loss:0.00001, loss_test:0.10345, lr:5.87e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.824, tt:4200.703\n",
      "Ep:132, loss:0.00001, loss_test:0.10150, lr:5.81e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.829, tt:4233.233\n",
      "Ep:133, loss:0.00001, loss_test:0.10325, lr:5.75e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.828, tt:4264.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.10220, lr:5.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.829, tt:4296.868\n",
      "Ep:135, loss:0.00001, loss_test:0.10291, lr:5.64e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.837, tt:4329.889\n",
      "Ep:136, loss:0.00001, loss_test:0.10276, lr:5.58e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.849, tt:4363.312\n",
      "Ep:137, loss:0.00001, loss_test:0.10279, lr:5.53e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.850, tt:4395.247\n",
      "Ep:138, loss:0.00001, loss_test:0.10317, lr:5.47e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.856, tt:4427.926\n",
      "Ep:139, loss:0.00001, loss_test:0.10233, lr:5.42e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.864, tt:4460.940\n",
      "Ep:140, loss:0.00001, loss_test:0.10376, lr:5.36e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.875, tt:4494.340\n",
      "Ep:141, loss:0.00001, loss_test:0.10165, lr:5.31e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.882, tt:4527.200\n",
      "Ep:142, loss:0.00001, loss_test:0.10324, lr:5.26e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.900, tt:4561.659\n",
      "Ep:143, loss:0.00001, loss_test:0.10311, lr:5.20e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.909, tt:4594.874\n",
      "Ep:144, loss:0.00001, loss_test:0.10194, lr:5.15e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.915, tt:4627.707\n",
      "Ep:145, loss:0.00001, loss_test:0.10367, lr:5.10e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.918, tt:4660.026\n",
      "Ep:146, loss:0.00001, loss_test:0.10295, lr:5.05e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.913, tt:4691.226\n",
      "Ep:147, loss:0.00001, loss_test:0.10191, lr:5.00e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.925, tt:4724.962\n",
      "Ep:148, loss:0.00001, loss_test:0.10348, lr:4.95e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.930, tt:4757.557\n",
      "Ep:149, loss:0.00001, loss_test:0.10303, lr:4.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.940, tt:4791.009\n",
      "Ep:150, loss:0.00001, loss_test:0.10299, lr:4.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.941, tt:4823.044\n",
      "Ep:151, loss:0.00001, loss_test:0.10281, lr:4.80e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.944, tt:4855.519\n",
      "Ep:152, loss:0.00001, loss_test:0.10252, lr:4.75e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.948, tt:4888.013\n",
      "Ep:153, loss:0.00001, loss_test:0.10263, lr:4.71e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.958, tt:4921.491\n",
      "Ep:154, loss:0.00001, loss_test:0.10300, lr:4.66e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.969, tt:4955.201\n",
      "Ep:155, loss:0.00001, loss_test:0.10321, lr:4.61e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.973, tt:4987.788\n",
      "Ep:156, loss:0.00001, loss_test:0.10295, lr:4.57e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.976, tt:5020.251\n",
      "Ep:157, loss:0.00001, loss_test:0.10292, lr:4.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.972, tt:5051.590\n",
      "Ep:158, loss:0.00001, loss_test:0.10280, lr:4.48e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.988, tt:5086.088\n",
      "Ep:159, loss:0.00001, loss_test:0.10322, lr:4.43e-03, fs:0.73939 (r=0.616,p=0.924),  time:31.996, tt:5119.291\n",
      "Ep:160, loss:0.00001, loss_test:0.10151, lr:4.39e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.002, tt:5152.395\n",
      "Ep:161, loss:0.00001, loss_test:0.10359, lr:4.34e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.008, tt:5185.255\n",
      "Ep:162, loss:0.00001, loss_test:0.10396, lr:4.30e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.013, tt:5218.182\n",
      "Ep:163, loss:0.00001, loss_test:0.10198, lr:4.26e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.008, tt:5249.341\n",
      "Ep:164, loss:0.00001, loss_test:0.10368, lr:4.21e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.015, tt:5282.463\n",
      "Ep:165, loss:0.00001, loss_test:0.10440, lr:4.17e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.023, tt:5315.874\n",
      "Ep:166, loss:0.00001, loss_test:0.10248, lr:4.13e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.025, tt:5348.142\n",
      "Ep:167, loss:0.00001, loss_test:0.10291, lr:4.09e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.022, tt:5379.632\n",
      "Ep:168, loss:0.00001, loss_test:0.10280, lr:4.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.030, tt:5413.071\n",
      "Ep:169, loss:0.00001, loss_test:0.10308, lr:4.01e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.033, tt:5445.538\n",
      "Ep:170, loss:0.00001, loss_test:0.10285, lr:3.97e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.033, tt:5477.681\n",
      "Ep:171, loss:0.00001, loss_test:0.10267, lr:3.93e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.029, tt:5509.049\n",
      "Ep:172, loss:0.00001, loss_test:0.10290, lr:3.89e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.027, tt:5540.632\n",
      "Ep:173, loss:0.00001, loss_test:0.10313, lr:3.85e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.021, tt:5571.618\n",
      "Ep:174, loss:0.00001, loss_test:0.10308, lr:3.81e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.012, tt:5602.083\n",
      "Ep:175, loss:0.00001, loss_test:0.10292, lr:3.77e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.010, tt:5633.809\n",
      "Ep:176, loss:0.00001, loss_test:0.10285, lr:3.73e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.015, tt:5666.612\n",
      "Ep:177, loss:0.00001, loss_test:0.10297, lr:3.70e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.017, tt:5699.024\n",
      "Ep:178, loss:0.00001, loss_test:0.10289, lr:3.66e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.014, tt:5730.587\n",
      "Ep:179, loss:0.00001, loss_test:0.10383, lr:3.62e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.014, tt:5762.486\n",
      "Ep:180, loss:0.00001, loss_test:0.10219, lr:3.59e-03, fs:0.74251 (r=0.626,p=0.912),  time:32.004, tt:5792.729\n",
      "Ep:181, loss:0.00001, loss_test:0.10364, lr:3.55e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.007, tt:5825.280\n",
      "Ep:182, loss:0.00001, loss_test:0.10356, lr:3.52e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.994, tt:5854.958\n",
      "Ep:183, loss:0.00001, loss_test:0.10256, lr:3.48e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.989, tt:5886.005\n",
      "Ep:184, loss:0.00001, loss_test:0.10396, lr:3.45e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.978, tt:5915.916\n",
      "Ep:185, loss:0.00001, loss_test:0.10420, lr:3.41e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.962, tt:5944.996\n",
      "Ep:186, loss:0.00001, loss_test:0.10241, lr:3.38e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.954, tt:5975.388\n",
      "Ep:187, loss:0.00001, loss_test:0.10340, lr:3.34e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.950, tt:6006.535\n",
      "Ep:188, loss:0.00001, loss_test:0.10354, lr:3.31e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.946, tt:6037.865\n",
      "Ep:189, loss:0.00001, loss_test:0.10295, lr:3.28e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.946, tt:6069.725\n",
      "Ep:190, loss:0.00001, loss_test:0.10355, lr:3.24e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.944, tt:6101.248\n",
      "Ep:191, loss:0.00001, loss_test:0.10310, lr:3.21e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.943, tt:6133.047\n",
      "Ep:192, loss:0.00001, loss_test:0.10320, lr:3.18e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.933, tt:6163.058\n",
      "Ep:193, loss:0.00001, loss_test:0.10314, lr:3.15e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.914, tt:6191.330\n",
      "Ep:194, loss:0.00001, loss_test:0.10308, lr:3.12e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.910, tt:6222.450\n",
      "Ep:195, loss:0.00001, loss_test:0.10349, lr:3.09e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.902, tt:6252.834\n",
      "Ep:196, loss:0.00001, loss_test:0.10310, lr:3.05e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.901, tt:6284.399\n",
      "Ep:197, loss:0.00001, loss_test:0.10305, lr:3.02e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.896, tt:6315.438\n",
      "Ep:198, loss:0.00001, loss_test:0.10357, lr:2.99e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.894, tt:6346.922\n",
      "Ep:199, loss:0.00001, loss_test:0.10311, lr:2.96e-03, fs:0.74699 (r=0.626,p=0.925),  time:31.900, tt:6380.081\n",
      "Ep:200, loss:0.00001, loss_test:0.10360, lr:2.93e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.903, tt:6412.460\n",
      "Ep:201, loss:0.00001, loss_test:0.10311, lr:2.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.908, tt:6445.480\n",
      "Ep:202, loss:0.00001, loss_test:0.10354, lr:2.88e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.913, tt:6478.379\n",
      "Ep:203, loss:0.00001, loss_test:0.10356, lr:2.85e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.918, tt:6511.268\n",
      "Ep:204, loss:0.00001, loss_test:0.10309, lr:2.82e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.911, tt:6541.813\n",
      "Ep:205, loss:0.00001, loss_test:0.10337, lr:2.79e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.912, tt:6573.791\n",
      "Ep:206, loss:0.00001, loss_test:0.10313, lr:2.76e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.912, tt:6605.702\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14007, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.511, tt:13.511\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.13869, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.786, tt:33.573\n",
      "Ep:2, loss:0.00014, loss_test:0.13628, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.571, tt:64.712\n",
      "Ep:3, loss:0.00013, loss_test:0.13236, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:23.975, tt:95.901\n",
      "Ep:4, loss:0.00013, loss_test:0.12573, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:25.478, tt:127.388\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00012, loss_test:0.11495, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:26.585, tt:159.510\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00012, loss_test:0.10668, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:27.607, tt:193.247\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00011, loss_test:0.10498, lr:1.00e-02, fs:0.71204 (r=0.687,p=0.739),  time:28.263, tt:226.101\n",
      "Ep:8, loss:0.00011, loss_test:0.10510, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:28.488, tt:256.388\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00011, loss_test:0.10490, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:28.870, tt:288.702\n",
      "Ep:10, loss:0.00010, loss_test:0.10102, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:29.163, tt:320.797\n",
      "Ep:11, loss:0.00010, loss_test:0.09879, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:29.317, tt:351.800\n",
      "Ep:12, loss:0.00010, loss_test:0.09649, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:29.545, tt:384.084\n",
      "Ep:13, loss:0.00009, loss_test:0.09527, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:29.704, tt:415.854\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00009, loss_test:0.09174, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:29.757, tt:446.357\n",
      "Ep:15, loss:0.00009, loss_test:0.09040, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:29.932, tt:478.917\n",
      "Ep:16, loss:0.00009, loss_test:0.08994, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:30.151, tt:512.575\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00008, loss_test:0.08817, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.282, tt:545.069\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00008, loss_test:0.08637, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:30.422, tt:578.018\n",
      "Ep:19, loss:0.00008, loss_test:0.08490, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:30.471, tt:609.421\n",
      "Ep:20, loss:0.00008, loss_test:0.08428, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.568, tt:641.925\n",
      "Ep:21, loss:0.00007, loss_test:0.08337, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:30.554, tt:672.180\n",
      "Ep:22, loss:0.00007, loss_test:0.08196, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.661, tt:705.214\n",
      "Ep:23, loss:0.00007, loss_test:0.08121, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:30.717, tt:737.197\n",
      "Ep:24, loss:0.00007, loss_test:0.08086, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.792, tt:769.792\n",
      "Ep:25, loss:0.00007, loss_test:0.08007, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.896, tt:803.307\n",
      "Ep:26, loss:0.00007, loss_test:0.07911, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.968, tt:836.130\n",
      "Ep:27, loss:0.00006, loss_test:0.07843, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.988, tt:867.664\n",
      "Ep:28, loss:0.00006, loss_test:0.07756, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:31.049, tt:900.406\n",
      "Ep:29, loss:0.00006, loss_test:0.07727, lr:9.90e-03, fs:0.77083 (r=0.747,p=0.796),  time:31.062, tt:931.875\n",
      "Ep:30, loss:0.00006, loss_test:0.07648, lr:9.80e-03, fs:0.79381 (r=0.778,p=0.811),  time:31.055, tt:962.690\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.07598, lr:9.80e-03, fs:0.79581 (r=0.768,p=0.826),  time:31.084, tt:994.690\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.07513, lr:9.80e-03, fs:0.80829 (r=0.788,p=0.830),  time:31.088, tt:1025.910\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.07475, lr:9.80e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.066, tt:1056.260\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00005, loss_test:0.07474, lr:9.80e-03, fs:0.79365 (r=0.758,p=0.833),  time:31.061, tt:1087.124\n",
      "Ep:35, loss:0.00005, loss_test:0.07395, lr:9.80e-03, fs:0.81026 (r=0.798,p=0.823),  time:31.066, tt:1118.391\n",
      "Ep:36, loss:0.00005, loss_test:0.07375, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:31.094, tt:1150.471\n",
      "Ep:37, loss:0.00005, loss_test:0.07332, lr:9.80e-03, fs:0.78947 (r=0.758,p=0.824),  time:31.108, tt:1182.098\n",
      "Ep:38, loss:0.00005, loss_test:0.07219, lr:9.80e-03, fs:0.82474 (r=0.808,p=0.842),  time:31.160, tt:1215.254\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07209, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:31.181, tt:1247.256\n",
      "Ep:40, loss:0.00005, loss_test:0.07103, lr:9.80e-03, fs:0.82474 (r=0.808,p=0.842),  time:31.207, tt:1279.467\n",
      "Ep:41, loss:0.00005, loss_test:0.07138, lr:9.80e-03, fs:0.79570 (r=0.747,p=0.851),  time:31.211, tt:1310.865\n",
      "Ep:42, loss:0.00005, loss_test:0.07083, lr:9.80e-03, fs:0.79144 (r=0.747,p=0.841),  time:31.200, tt:1341.592\n",
      "Ep:43, loss:0.00004, loss_test:0.06945, lr:9.80e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.169, tt:1371.437\n",
      "Ep:44, loss:0.00004, loss_test:0.06998, lr:9.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:31.161, tt:1402.240\n",
      "Ep:45, loss:0.00004, loss_test:0.06885, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:31.156, tt:1433.175\n",
      "Ep:46, loss:0.00004, loss_test:0.06902, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:31.152, tt:1464.147\n",
      "Ep:47, loss:0.00004, loss_test:0.06765, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:31.177, tt:1496.514\n",
      "Ep:48, loss:0.00004, loss_test:0.06778, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:31.222, tt:1529.867\n",
      "Ep:49, loss:0.00004, loss_test:0.06810, lr:9.80e-03, fs:0.80000 (r=0.747,p=0.860),  time:31.196, tt:1559.794\n",
      "Ep:50, loss:0.00004, loss_test:0.06709, lr:9.70e-03, fs:0.80000 (r=0.747,p=0.860),  time:31.206, tt:1591.490\n",
      "Ep:51, loss:0.00004, loss_test:0.06688, lr:9.61e-03, fs:0.80435 (r=0.747,p=0.871),  time:31.211, tt:1622.953\n",
      "Ep:52, loss:0.00004, loss_test:0.06597, lr:9.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:31.204, tt:1653.817\n",
      "Ep:53, loss:0.00004, loss_test:0.06700, lr:9.41e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.206, tt:1685.116\n",
      "Ep:54, loss:0.00004, loss_test:0.06552, lr:9.32e-03, fs:0.80435 (r=0.747,p=0.871),  time:31.191, tt:1715.512\n",
      "Ep:55, loss:0.00003, loss_test:0.06731, lr:9.23e-03, fs:0.79775 (r=0.717,p=0.899),  time:31.208, tt:1747.647\n",
      "Ep:56, loss:0.00003, loss_test:0.06633, lr:9.14e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.171, tt:1776.739\n",
      "Ep:57, loss:0.00003, loss_test:0.06453, lr:9.04e-03, fs:0.79348 (r=0.737,p=0.859),  time:31.163, tt:1807.441\n",
      "Ep:58, loss:0.00003, loss_test:0.06765, lr:8.95e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.141, tt:1837.348\n",
      "Ep:59, loss:0.00003, loss_test:0.06369, lr:8.86e-03, fs:0.80423 (r=0.768,p=0.844),  time:31.152, tt:1869.107\n",
      "Ep:60, loss:0.00003, loss_test:0.06648, lr:8.78e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.146, tt:1899.934\n",
      "Ep:61, loss:0.00003, loss_test:0.06568, lr:8.69e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.167, tt:1932.360\n",
      "Ep:62, loss:0.00003, loss_test:0.06404, lr:8.60e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.180, tt:1964.354\n",
      "Ep:63, loss:0.00003, loss_test:0.06609, lr:8.51e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.182, tt:1995.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00003, loss_test:0.06432, lr:8.43e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.222, tt:2029.416\n",
      "Ep:65, loss:0.00003, loss_test:0.06451, lr:8.35e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.245, tt:2062.144\n",
      "Ep:66, loss:0.00003, loss_test:0.06535, lr:8.26e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.217, tt:2091.567\n",
      "Ep:67, loss:0.00003, loss_test:0.06450, lr:8.18e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.233, tt:2123.837\n",
      "Ep:68, loss:0.00003, loss_test:0.06485, lr:8.10e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.236, tt:2155.274\n",
      "Ep:69, loss:0.00003, loss_test:0.06494, lr:8.02e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.229, tt:2186.052\n",
      "Ep:70, loss:0.00003, loss_test:0.06459, lr:7.94e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.249, tt:2218.665\n",
      "Ep:71, loss:0.00003, loss_test:0.06390, lr:7.86e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.262, tt:2250.888\n",
      "Ep:72, loss:0.00003, loss_test:0.06478, lr:7.78e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.279, tt:2283.358\n",
      "Ep:73, loss:0.00002, loss_test:0.06457, lr:7.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.262, tt:2313.385\n",
      "Ep:74, loss:0.00002, loss_test:0.06430, lr:7.62e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.284, tt:2346.308\n",
      "Ep:75, loss:0.00002, loss_test:0.06485, lr:7.55e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.287, tt:2377.807\n",
      "Ep:76, loss:0.00002, loss_test:0.06483, lr:7.47e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.291, tt:2409.402\n",
      "Ep:77, loss:0.00002, loss_test:0.06430, lr:7.40e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.297, tt:2441.198\n",
      "Ep:78, loss:0.00002, loss_test:0.06472, lr:7.32e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.306, tt:2473.213\n",
      "Ep:79, loss:0.00002, loss_test:0.06459, lr:7.25e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.330, tt:2506.412\n",
      "Ep:80, loss:0.00002, loss_test:0.06512, lr:7.18e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.348, tt:2539.199\n",
      "Ep:81, loss:0.00002, loss_test:0.06485, lr:7.11e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.364, tt:2571.836\n",
      "Ep:82, loss:0.00002, loss_test:0.06412, lr:7.03e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.370, tt:2603.731\n",
      "Ep:83, loss:0.00002, loss_test:0.06554, lr:6.96e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.394, tt:2637.075\n",
      "Ep:84, loss:0.00002, loss_test:0.06518, lr:6.89e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.389, tt:2668.066\n",
      "Ep:85, loss:0.00002, loss_test:0.06430, lr:6.83e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.421, tt:2702.193\n",
      "Ep:86, loss:0.00002, loss_test:0.06562, lr:6.76e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.433, tt:2734.693\n",
      "Ep:87, loss:0.00002, loss_test:0.06523, lr:6.69e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.442, tt:2766.925\n",
      "Ep:88, loss:0.00002, loss_test:0.06469, lr:6.62e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.437, tt:2797.926\n",
      "Ep:89, loss:0.00002, loss_test:0.06583, lr:6.56e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.423, tt:2828.026\n",
      "Ep:90, loss:0.00002, loss_test:0.06499, lr:6.49e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.433, tt:2860.381\n",
      "Ep:91, loss:0.00002, loss_test:0.06521, lr:6.43e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.444, tt:2892.872\n",
      "Ep:92, loss:0.00002, loss_test:0.06588, lr:6.36e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.456, tt:2925.448\n",
      "Ep:93, loss:0.00002, loss_test:0.06526, lr:6.30e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.460, tt:2957.224\n",
      "Ep:94, loss:0.00002, loss_test:0.06517, lr:6.24e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.462, tt:2988.896\n",
      "Ep:95, loss:0.00002, loss_test:0.06639, lr:6.17e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.461, tt:3020.237\n",
      "Ep:96, loss:0.00002, loss_test:0.06599, lr:6.11e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.442, tt:3049.860\n",
      "Ep:97, loss:0.00002, loss_test:0.06510, lr:6.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.424, tt:3079.560\n",
      "Ep:98, loss:0.00002, loss_test:0.06639, lr:5.99e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.418, tt:3110.415\n",
      "Ep:99, loss:0.00002, loss_test:0.06626, lr:5.93e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.429, tt:3142.899\n",
      "Ep:100, loss:0.00002, loss_test:0.06517, lr:5.87e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.432, tt:3174.662\n",
      "Ep:101, loss:0.00002, loss_test:0.06688, lr:5.81e-03, fs:0.77647 (r=0.667,p=0.930),  time:31.437, tt:3206.606\n",
      "Ep:102, loss:0.00002, loss_test:0.06636, lr:5.75e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.452, tt:3239.557\n",
      "Ep:103, loss:0.00002, loss_test:0.06555, lr:5.70e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.468, tt:3272.664\n",
      "Ep:104, loss:0.00002, loss_test:0.06680, lr:5.64e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.468, tt:3304.096\n",
      "Ep:105, loss:0.00002, loss_test:0.06639, lr:5.58e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.474, tt:3336.296\n",
      "Ep:106, loss:0.00002, loss_test:0.06570, lr:5.53e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.525, tt:3373.171\n",
      "Ep:107, loss:0.00002, loss_test:0.06658, lr:5.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.521, tt:3404.237\n",
      "Ep:108, loss:0.00002, loss_test:0.06560, lr:5.42e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.540, tt:3437.817\n",
      "Ep:109, loss:0.00002, loss_test:0.06659, lr:5.36e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.539, tt:3469.310\n",
      "Ep:110, loss:0.00001, loss_test:0.06567, lr:5.31e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.549, tt:3501.941\n",
      "Ep:111, loss:0.00001, loss_test:0.06621, lr:5.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.548, tt:3533.349\n",
      "Ep:112, loss:0.00001, loss_test:0.06617, lr:5.20e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.556, tt:3565.844\n",
      "Ep:113, loss:0.00001, loss_test:0.06557, lr:5.15e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.573, tt:3599.300\n",
      "Ep:114, loss:0.00001, loss_test:0.06674, lr:5.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.575, tt:3631.091\n",
      "Ep:115, loss:0.00001, loss_test:0.06630, lr:5.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.576, tt:3662.810\n",
      "Ep:116, loss:0.00001, loss_test:0.06547, lr:5.00e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.572, tt:3693.973\n",
      "Ep:117, loss:0.00001, loss_test:0.06646, lr:4.95e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.571, tt:3725.423\n",
      "Ep:118, loss:0.00001, loss_test:0.06603, lr:4.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.574, tt:3757.314\n",
      "Ep:119, loss:0.00001, loss_test:0.06560, lr:4.85e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.570, tt:3788.444\n",
      "Ep:120, loss:0.00001, loss_test:0.06697, lr:4.80e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.573, tt:3820.309\n",
      "Ep:121, loss:0.00001, loss_test:0.06702, lr:4.75e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.570, tt:3851.575\n",
      "Ep:122, loss:0.00001, loss_test:0.06545, lr:4.71e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.573, tt:3883.486\n",
      "Ep:123, loss:0.00001, loss_test:0.06649, lr:4.66e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.584, tt:3916.470\n",
      "Ep:124, loss:0.00001, loss_test:0.06708, lr:4.61e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.588, tt:3948.545\n",
      "Ep:125, loss:0.00001, loss_test:0.06600, lr:4.57e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.585, tt:3979.665\n",
      "Ep:126, loss:0.00001, loss_test:0.06651, lr:4.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.580, tt:4010.696\n",
      "Ep:127, loss:0.00001, loss_test:0.06632, lr:4.48e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.573, tt:4041.363\n",
      "Ep:128, loss:0.00001, loss_test:0.06642, lr:4.43e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.558, tt:4070.938\n",
      "Ep:129, loss:0.00001, loss_test:0.06637, lr:4.39e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.557, tt:4102.423\n",
      "Ep:130, loss:0.00001, loss_test:0.06622, lr:4.34e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.546, tt:4132.482\n",
      "Ep:131, loss:0.00001, loss_test:0.06620, lr:4.30e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.534, tt:4162.542\n",
      "Ep:132, loss:0.00001, loss_test:0.06640, lr:4.26e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.538, tt:4194.505\n",
      "Ep:133, loss:0.00001, loss_test:0.06621, lr:4.21e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.529, tt:4224.864\n",
      "Ep:134, loss:0.00001, loss_test:0.06631, lr:4.17e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.536, tt:4257.311\n",
      "Ep:135, loss:0.00001, loss_test:0.06613, lr:4.13e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.540, tt:4289.430\n",
      "Ep:136, loss:0.00001, loss_test:0.06631, lr:4.09e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.545, tt:4321.726\n",
      "Ep:137, loss:0.00001, loss_test:0.06638, lr:4.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.538, tt:4352.269\n",
      "Ep:138, loss:0.00001, loss_test:0.06653, lr:4.01e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.540, tt:4384.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00001, loss_test:0.06621, lr:3.97e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.545, tt:4416.258\n",
      "Ep:140, loss:0.00001, loss_test:0.06665, lr:3.93e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.544, tt:4447.773\n",
      "Ep:141, loss:0.00001, loss_test:0.06595, lr:3.89e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.531, tt:4477.400\n",
      "Ep:142, loss:0.00001, loss_test:0.06628, lr:3.85e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.533, tt:4509.279\n",
      "Ep:143, loss:0.00001, loss_test:0.06609, lr:3.81e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.534, tt:4540.922\n",
      "Ep:144, loss:0.00001, loss_test:0.06619, lr:3.77e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.532, tt:4572.114\n",
      "Ep:145, loss:0.00001, loss_test:0.06628, lr:3.73e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.535, tt:4604.054\n",
      "Ep:146, loss:0.00001, loss_test:0.06590, lr:3.70e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.525, tt:4634.228\n",
      "Ep:147, loss:0.00001, loss_test:0.06624, lr:3.66e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.516, tt:4664.388\n",
      "Ep:148, loss:0.00001, loss_test:0.06595, lr:3.62e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.518, tt:4696.196\n",
      "Ep:149, loss:0.00001, loss_test:0.06619, lr:3.59e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.523, tt:4728.455\n",
      "Ep:150, loss:0.00001, loss_test:0.06620, lr:3.55e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.521, tt:4759.730\n",
      "Ep:151, loss:0.00001, loss_test:0.06587, lr:3.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.523, tt:4791.497\n",
      "Ep:152, loss:0.00001, loss_test:0.06675, lr:3.48e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.521, tt:4822.737\n",
      "Ep:153, loss:0.00001, loss_test:0.06593, lr:3.45e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.516, tt:4853.515\n",
      "Ep:154, loss:0.00001, loss_test:0.06581, lr:3.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.518, tt:4885.366\n",
      "Ep:155, loss:0.00001, loss_test:0.06660, lr:3.38e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.523, tt:4917.553\n",
      "Ep:156, loss:0.00001, loss_test:0.06601, lr:3.34e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.523, tt:4949.167\n",
      "Ep:157, loss:0.00001, loss_test:0.06621, lr:3.31e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.528, tt:4981.370\n",
      "Ep:158, loss:0.00001, loss_test:0.06638, lr:3.28e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.527, tt:5012.837\n",
      "Ep:159, loss:0.00001, loss_test:0.06589, lr:3.24e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.524, tt:5043.887\n",
      "Ep:160, loss:0.00001, loss_test:0.06641, lr:3.21e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.519, tt:5074.571\n",
      "Ep:161, loss:0.00001, loss_test:0.06616, lr:3.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.511, tt:5104.861\n",
      "Ep:162, loss:0.00001, loss_test:0.06615, lr:3.15e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.514, tt:5136.794\n",
      "Ep:163, loss:0.00001, loss_test:0.06658, lr:3.12e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.506, tt:5167.038\n",
      "Ep:164, loss:0.00001, loss_test:0.06586, lr:3.09e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.506, tt:5198.569\n",
      "Ep:165, loss:0.00001, loss_test:0.06640, lr:3.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.506, tt:5229.964\n",
      "Ep:166, loss:0.00001, loss_test:0.06660, lr:3.02e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.501, tt:5260.606\n",
      "Ep:167, loss:0.00001, loss_test:0.06615, lr:2.99e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.499, tt:5291.858\n",
      "Ep:168, loss:0.00001, loss_test:0.06645, lr:2.96e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.499, tt:5323.313\n",
      "Ep:169, loss:0.00001, loss_test:0.06667, lr:2.93e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.504, tt:5355.752\n",
      "Ep:170, loss:0.00001, loss_test:0.06623, lr:2.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.499, tt:5386.249\n",
      "Ep:171, loss:0.00001, loss_test:0.06623, lr:2.88e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.506, tt:5419.108\n",
      "Ep:172, loss:0.00001, loss_test:0.06686, lr:2.85e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.510, tt:5451.159\n",
      "Ep:173, loss:0.00001, loss_test:0.06669, lr:2.82e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.534, tt:5486.962\n",
      "Ep:174, loss:0.00001, loss_test:0.06621, lr:2.79e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.537, tt:5519.007\n",
      "Ep:175, loss:0.00001, loss_test:0.06667, lr:2.76e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.535, tt:5550.082\n",
      "Ep:176, loss:0.00001, loss_test:0.06664, lr:2.73e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.532, tt:5581.197\n",
      "Ep:177, loss:0.00001, loss_test:0.06640, lr:2.71e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.536, tt:5613.408\n",
      "Ep:178, loss:0.00001, loss_test:0.06674, lr:2.68e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.537, tt:5645.207\n",
      "Ep:179, loss:0.00001, loss_test:0.06660, lr:2.65e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.547, tt:5678.486\n",
      "Ep:180, loss:0.00001, loss_test:0.06645, lr:2.63e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.558, tt:5711.925\n",
      "Ep:181, loss:0.00001, loss_test:0.06644, lr:2.60e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.568, tt:5745.328\n",
      "Ep:182, loss:0.00001, loss_test:0.06649, lr:2.57e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.569, tt:5777.199\n",
      "Ep:183, loss:0.00001, loss_test:0.06656, lr:2.55e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.580, tt:5810.666\n",
      "Ep:184, loss:0.00001, loss_test:0.06671, lr:2.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.593, tt:5844.741\n",
      "Ep:185, loss:0.00001, loss_test:0.06673, lr:2.50e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.598, tt:5877.204\n",
      "Ep:186, loss:0.00001, loss_test:0.06674, lr:2.47e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.610, tt:5911.111\n",
      "Ep:187, loss:0.00001, loss_test:0.06677, lr:2.45e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.621, tt:5944.777\n",
      "Ep:188, loss:0.00001, loss_test:0.06650, lr:2.42e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.629, tt:5977.825\n",
      "Ep:189, loss:0.00001, loss_test:0.06691, lr:2.40e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.647, tt:6012.859\n",
      "Ep:190, loss:0.00001, loss_test:0.06688, lr:2.38e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.660, tt:6047.034\n",
      "Ep:191, loss:0.00001, loss_test:0.06681, lr:2.35e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.671, tt:6080.842\n",
      "Ep:192, loss:0.00001, loss_test:0.06673, lr:2.33e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.684, tt:6114.945\n",
      "Ep:193, loss:0.00001, loss_test:0.06667, lr:2.31e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.697, tt:6149.178\n",
      "Ep:194, loss:0.00001, loss_test:0.06698, lr:2.28e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.734, tt:6188.069\n",
      "Ep:195, loss:0.00001, loss_test:0.06686, lr:2.26e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.741, tt:6221.212\n",
      "Ep:196, loss:0.00001, loss_test:0.06687, lr:2.24e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.747, tt:6254.155\n",
      "Ep:197, loss:0.00001, loss_test:0.06692, lr:2.21e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.755, tt:6287.399\n",
      "Ep:198, loss:0.00001, loss_test:0.06710, lr:2.19e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.755, tt:6319.329\n",
      "Ep:199, loss:0.00001, loss_test:0.06700, lr:2.17e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.765, tt:6352.917\n",
      "Ep:200, loss:0.00001, loss_test:0.06681, lr:2.15e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.769, tt:6385.504\n",
      "Ep:201, loss:0.00001, loss_test:0.06710, lr:2.13e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.773, tt:6418.222\n",
      "Ep:202, loss:0.00001, loss_test:0.06719, lr:2.11e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.775, tt:6450.317\n",
      "Ep:203, loss:0.00001, loss_test:0.06708, lr:2.08e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.772, tt:6481.493\n",
      "Ep:204, loss:0.00001, loss_test:0.06704, lr:2.06e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.776, tt:6514.120\n",
      "Ep:205, loss:0.00001, loss_test:0.06711, lr:2.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.780, tt:6546.687\n",
      "Ep:206, loss:0.00001, loss_test:0.06697, lr:2.02e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.787, tt:6579.904\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14112, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.297, tt:35.297\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.13747, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.053, tt:98.106\n",
      "Ep:2, loss:0.00054, loss_test:0.12994, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:54.401, tt:163.202\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.11670, lr:1.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:57.127, tt:228.507\n",
      "Ep:4, loss:0.00046, loss_test:0.10812, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:58.804, tt:294.018\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.10594, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:60.235, tt:361.411\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.09856, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:60.946, tt:426.625\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.09768, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:61.630, tt:493.043\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.09423, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:61.883, tt:556.946\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.09240, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:62.101, tt:621.011\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.09003, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:62.410, tt:686.509\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.08706, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:62.851, tt:754.206\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.08627, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:63.345, tt:823.490\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.08353, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:63.725, tt:892.156\n",
      "Ep:14, loss:0.00027, loss_test:0.08147, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:63.983, tt:959.740\n",
      "Ep:15, loss:0.00026, loss_test:0.08035, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:63.945, tt:1023.115\n",
      "Ep:16, loss:0.00025, loss_test:0.07912, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:64.141, tt:1090.402\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.07840, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:64.191, tt:1155.432\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.07780, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:64.314, tt:1221.969\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.07704, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:64.367, tt:1287.342\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.07608, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:64.395, tt:1352.302\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.07486, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:64.571, tt:1420.551\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.07336, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:64.753, tt:1489.316\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.07343, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:64.845, tt:1556.273\n",
      "Ep:24, loss:0.00017, loss_test:0.07334, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:64.884, tt:1622.097\n",
      "Ep:25, loss:0.00016, loss_test:0.07231, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:64.956, tt:1688.856\n",
      "Ep:26, loss:0.00015, loss_test:0.07071, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:64.976, tt:1754.356\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.07053, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:65.080, tt:1822.251\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07202, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:65.179, tt:1890.191\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07060, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:65.251, tt:1957.519\n",
      "Ep:30, loss:0.00012, loss_test:0.06773, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:65.269, tt:2023.353\n",
      "Ep:31, loss:0.00012, loss_test:0.06952, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:65.260, tt:2088.309\n",
      "Ep:32, loss:0.00011, loss_test:0.07192, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:65.240, tt:2152.932\n",
      "Ep:33, loss:0.00011, loss_test:0.06959, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:65.258, tt:2218.788\n",
      "Ep:34, loss:0.00010, loss_test:0.06940, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:65.302, tt:2285.555\n",
      "Ep:35, loss:0.00010, loss_test:0.06948, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:65.258, tt:2349.295\n",
      "Ep:36, loss:0.00009, loss_test:0.07231, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:65.260, tt:2414.610\n",
      "Ep:37, loss:0.00009, loss_test:0.07083, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:65.259, tt:2479.853\n",
      "Ep:38, loss:0.00008, loss_test:0.06975, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:65.315, tt:2547.281\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.07154, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:65.345, tt:2613.788\n",
      "Ep:40, loss:0.00008, loss_test:0.07259, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:65.351, tt:2679.407\n",
      "Ep:41, loss:0.00007, loss_test:0.07738, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:65.373, tt:2745.662\n",
      "Ep:42, loss:0.00007, loss_test:0.06961, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:65.394, tt:2811.927\n",
      "Ep:43, loss:0.00007, loss_test:0.06853, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:65.413, tt:2878.162\n",
      "Ep:44, loss:0.00007, loss_test:0.07329, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:65.422, tt:2944.005\n",
      "Ep:45, loss:0.00006, loss_test:0.07607, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:65.422, tt:3009.404\n",
      "Ep:46, loss:0.00006, loss_test:0.07023, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:65.413, tt:3074.399\n",
      "Ep:47, loss:0.00006, loss_test:0.06901, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:65.455, tt:3141.822\n",
      "Ep:48, loss:0.00006, loss_test:0.06968, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:65.445, tt:3206.814\n",
      "Ep:49, loss:0.00005, loss_test:0.07578, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:65.450, tt:3272.510\n",
      "Ep:50, loss:0.00005, loss_test:0.07647, lr:9.90e-03, fs:0.79070 (r=0.687,p=0.932),  time:65.466, tt:3338.788\n",
      "Ep:51, loss:0.00005, loss_test:0.07118, lr:9.80e-03, fs:0.79769 (r=0.697,p=0.932),  time:65.498, tt:3405.876\n",
      "Ep:52, loss:0.00005, loss_test:0.07308, lr:9.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:65.518, tt:3472.428\n",
      "Ep:53, loss:0.00005, loss_test:0.07542, lr:9.61e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.544, tt:3539.372\n",
      "Ep:54, loss:0.00004, loss_test:0.07384, lr:9.51e-03, fs:0.82486 (r=0.737,p=0.936),  time:65.551, tt:3605.304\n",
      "Ep:55, loss:0.00004, loss_test:0.07589, lr:9.41e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.567, tt:3671.727\n",
      "Ep:56, loss:0.00004, loss_test:0.07358, lr:9.32e-03, fs:0.78363 (r=0.677,p=0.931),  time:65.545, tt:3736.077\n",
      "Ep:57, loss:0.00004, loss_test:0.07244, lr:9.23e-03, fs:0.76923 (r=0.657,p=0.929),  time:65.593, tt:3804.408\n",
      "Ep:58, loss:0.00004, loss_test:0.07405, lr:9.14e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.611, tt:3871.047\n",
      "Ep:59, loss:0.00004, loss_test:0.07490, lr:9.04e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.683, tt:3941.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00004, loss_test:0.07557, lr:8.95e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.724, tt:4009.144\n",
      "Ep:61, loss:0.00004, loss_test:0.07465, lr:8.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.757, tt:4076.947\n",
      "Ep:62, loss:0.00003, loss_test:0.07504, lr:8.78e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.730, tt:4141.003\n",
      "Ep:63, loss:0.00003, loss_test:0.07878, lr:8.69e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.719, tt:4206.038\n",
      "Ep:64, loss:0.00003, loss_test:0.07436, lr:8.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.733, tt:4272.625\n",
      "Ep:65, loss:0.00003, loss_test:0.07678, lr:8.51e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.730, tt:4338.183\n",
      "Ep:66, loss:0.00003, loss_test:0.08154, lr:8.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.745, tt:4404.890\n",
      "Ep:67, loss:0.00003, loss_test:0.07616, lr:8.35e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.740, tt:4470.341\n",
      "Ep:68, loss:0.00003, loss_test:0.07859, lr:8.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.766, tt:4537.868\n",
      "Ep:69, loss:0.00003, loss_test:0.07589, lr:8.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.806, tt:4606.417\n",
      "Ep:70, loss:0.00003, loss_test:0.07657, lr:8.10e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.811, tt:4672.571\n",
      "Ep:71, loss:0.00003, loss_test:0.08216, lr:8.02e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.810, tt:4738.330\n",
      "Ep:72, loss:0.00003, loss_test:0.07900, lr:7.94e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.825, tt:4805.190\n",
      "Ep:73, loss:0.00003, loss_test:0.07622, lr:7.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.842, tt:4872.337\n",
      "Ep:74, loss:0.00003, loss_test:0.07994, lr:7.78e-03, fs:0.76190 (r=0.646,p=0.928),  time:65.859, tt:4939.456\n",
      "Ep:75, loss:0.00002, loss_test:0.08327, lr:7.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.882, tt:5007.053\n",
      "Ep:76, loss:0.00002, loss_test:0.07982, lr:7.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.899, tt:5074.204\n",
      "Ep:77, loss:0.00002, loss_test:0.08307, lr:7.55e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.883, tt:5138.842\n",
      "Ep:78, loss:0.00002, loss_test:0.08205, lr:7.47e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.897, tt:5205.885\n",
      "Ep:79, loss:0.00002, loss_test:0.08193, lr:7.40e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.937, tt:5274.998\n",
      "Ep:80, loss:0.00002, loss_test:0.08236, lr:7.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.926, tt:5340.025\n",
      "Ep:81, loss:0.00002, loss_test:0.08337, lr:7.25e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.917, tt:5405.231\n",
      "Ep:82, loss:0.00002, loss_test:0.08124, lr:7.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.935, tt:5472.582\n",
      "Ep:83, loss:0.00002, loss_test:0.08544, lr:7.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.978, tt:5542.162\n",
      "Ep:84, loss:0.00002, loss_test:0.08398, lr:7.03e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.978, tt:5608.095\n",
      "Ep:85, loss:0.00002, loss_test:0.08258, lr:6.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.998, tt:5675.849\n",
      "Ep:86, loss:0.00002, loss_test:0.08631, lr:6.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.979, tt:5740.180\n",
      "Ep:87, loss:0.00002, loss_test:0.08302, lr:6.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.990, tt:5807.163\n",
      "Ep:88, loss:0.00002, loss_test:0.08436, lr:6.76e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.987, tt:5872.804\n",
      "Ep:89, loss:0.00002, loss_test:0.08342, lr:6.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.968, tt:5937.163\n",
      "Ep:90, loss:0.00002, loss_test:0.08390, lr:6.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:65.977, tt:6003.911\n",
      "Ep:91, loss:0.00002, loss_test:0.08631, lr:6.56e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.960, tt:6068.294\n",
      "Ep:92, loss:0.00002, loss_test:0.08274, lr:6.49e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.956, tt:6133.942\n",
      "Ep:93, loss:0.00002, loss_test:0.08521, lr:6.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.971, tt:6201.250\n",
      "Ep:94, loss:0.00002, loss_test:0.08621, lr:6.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.973, tt:6267.473\n",
      "Ep:95, loss:0.00002, loss_test:0.08420, lr:6.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.971, tt:6333.254\n",
      "Ep:96, loss:0.00002, loss_test:0.08786, lr:6.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.977, tt:6399.745\n",
      "Ep:97, loss:0.00001, loss_test:0.08544, lr:6.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.998, tt:6467.783\n",
      "Ep:98, loss:0.00001, loss_test:0.08693, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.025, tt:6536.479\n",
      "Ep:99, loss:0.00001, loss_test:0.08592, lr:6.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.009, tt:6600.930\n",
      "Ep:100, loss:0.00001, loss_test:0.08709, lr:5.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.023, tt:6668.370\n",
      "Ep:101, loss:0.00001, loss_test:0.08501, lr:5.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.020, tt:6733.998\n",
      "Ep:102, loss:0.00001, loss_test:0.08709, lr:5.87e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.000, tt:6798.044\n",
      "Ep:103, loss:0.00001, loss_test:0.08657, lr:5.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.996, tt:6863.586\n",
      "Ep:104, loss:0.00001, loss_test:0.08755, lr:5.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.012, tt:6931.233\n",
      "Ep:105, loss:0.00001, loss_test:0.08701, lr:5.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.026, tt:6998.729\n",
      "Ep:106, loss:0.00001, loss_test:0.08712, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.036, tt:7065.856\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14363, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.376, tt:4.376\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14337, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.342, tt:8.683\n",
      "Ep:2, loss:0.00014, loss_test:0.14297, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.332, tt:12.995\n",
      "Ep:3, loss:0.00014, loss_test:0.14241, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.326, tt:17.303\n",
      "Ep:4, loss:0.00014, loss_test:0.14168, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.323, tt:21.615\n",
      "Ep:5, loss:0.00014, loss_test:0.14073, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.320, tt:25.923\n",
      "Ep:6, loss:0.00014, loss_test:0.13952, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:4.315, tt:30.206\n",
      "Ep:7, loss:0.00014, loss_test:0.13804, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:4.452, tt:35.618\n",
      "Ep:8, loss:0.00013, loss_test:0.13627, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:4.442, tt:39.974\n",
      "Ep:9, loss:0.00013, loss_test:0.13412, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:4.427, tt:44.274\n",
      "Ep:10, loss:0.00013, loss_test:0.13143, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:4.415, tt:48.560\n",
      "Ep:11, loss:0.00013, loss_test:0.12806, lr:1.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:4.406, tt:52.871\n",
      "Ep:12, loss:0.00012, loss_test:0.12405, lr:9.90e-03, fs:0.66406 (r=0.859,p=0.541),  time:4.397, tt:57.159\n",
      "Ep:13, loss:0.00012, loss_test:0.12047, lr:9.80e-03, fs:0.65021 (r=0.798,p=0.549),  time:4.397, tt:61.555\n",
      "Ep:14, loss:0.00012, loss_test:0.11818, lr:9.70e-03, fs:0.63111 (r=0.717,p=0.563),  time:4.392, tt:65.879\n",
      "Ep:15, loss:0.00011, loss_test:0.11729, lr:9.61e-03, fs:0.61244 (r=0.646,p=0.582),  time:4.389, tt:70.231\n",
      "Ep:16, loss:0.00011, loss_test:0.11694, lr:9.51e-03, fs:0.62376 (r=0.636,p=0.612),  time:4.385, tt:74.551\n",
      "Ep:17, loss:0.00011, loss_test:0.11644, lr:9.41e-03, fs:0.63636 (r=0.636,p=0.636),  time:4.382, tt:78.871\n",
      "Ep:18, loss:0.00011, loss_test:0.11562, lr:9.32e-03, fs:0.63317 (r=0.636,p=0.630),  time:4.377, tt:83.167\n",
      "Ep:19, loss:0.00011, loss_test:0.11448, lr:9.23e-03, fs:0.62439 (r=0.646,p=0.604),  time:4.372, tt:87.439\n",
      "Ep:20, loss:0.00011, loss_test:0.11363, lr:9.14e-03, fs:0.63158 (r=0.667,p=0.600),  time:4.368, tt:91.734\n",
      "Ep:21, loss:0.00011, loss_test:0.11341, lr:9.04e-03, fs:0.62617 (r=0.677,p=0.583),  time:4.365, tt:96.035\n",
      "Ep:22, loss:0.00011, loss_test:0.11323, lr:8.95e-03, fs:0.63348 (r=0.707,p=0.574),  time:4.363, tt:100.339\n",
      "Ep:23, loss:0.00010, loss_test:0.11275, lr:8.86e-03, fs:0.62727 (r=0.697,p=0.570),  time:4.359, tt:104.620\n",
      "Ep:24, loss:0.00010, loss_test:0.11206, lr:8.78e-03, fs:0.63507 (r=0.677,p=0.598),  time:4.356, tt:108.904\n",
      "Ep:25, loss:0.00010, loss_test:0.11134, lr:8.69e-03, fs:0.64423 (r=0.677,p=0.615),  time:4.355, tt:113.224\n",
      "Ep:26, loss:0.00010, loss_test:0.11100, lr:8.60e-03, fs:0.65686 (r=0.677,p=0.638),  time:4.354, tt:117.552\n",
      "Ep:27, loss:0.00010, loss_test:0.11089, lr:8.51e-03, fs:0.67337 (r=0.677,p=0.670),  time:4.352, tt:121.868\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.11072, lr:8.51e-03, fs:0.67005 (r=0.667,p=0.673),  time:4.350, tt:126.164\n",
      "Ep:29, loss:0.00010, loss_test:0.11035, lr:8.51e-03, fs:0.67005 (r=0.667,p=0.673),  time:4.349, tt:130.483\n",
      "Ep:30, loss:0.00009, loss_test:0.11013, lr:8.51e-03, fs:0.68000 (r=0.687,p=0.673),  time:4.348, tt:134.791\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.10998, lr:8.51e-03, fs:0.67327 (r=0.687,p=0.660),  time:4.348, tt:139.152\n",
      "Ep:32, loss:0.00009, loss_test:0.10984, lr:8.51e-03, fs:0.67961 (r=0.707,p=0.654),  time:4.346, tt:143.432\n",
      "Ep:33, loss:0.00009, loss_test:0.10961, lr:8.51e-03, fs:0.66667 (r=0.697,p=0.639),  time:4.345, tt:147.738\n",
      "Ep:34, loss:0.00009, loss_test:0.10932, lr:8.51e-03, fs:0.66667 (r=0.687,p=0.648),  time:4.344, tt:152.052\n",
      "Ep:35, loss:0.00009, loss_test:0.10904, lr:8.51e-03, fs:0.67000 (r=0.677,p=0.663),  time:4.344, tt:156.378\n",
      "Ep:36, loss:0.00009, loss_test:0.10886, lr:8.51e-03, fs:0.68367 (r=0.677,p=0.691),  time:4.342, tt:160.649\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.10877, lr:8.51e-03, fs:0.68718 (r=0.677,p=0.698),  time:4.340, tt:164.901\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.10861, lr:8.51e-03, fs:0.69388 (r=0.687,p=0.701),  time:4.339, tt:169.211\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.10826, lr:8.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:4.339, tt:173.544\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.10785, lr:8.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:4.338, tt:177.854\n",
      "Ep:41, loss:0.00008, loss_test:0.10750, lr:8.51e-03, fs:0.69697 (r=0.697,p=0.697),  time:4.337, tt:182.154\n",
      "Ep:42, loss:0.00008, loss_test:0.10732, lr:8.51e-03, fs:0.69697 (r=0.697,p=0.697),  time:4.336, tt:186.454\n",
      "Ep:43, loss:0.00008, loss_test:0.10732, lr:8.51e-03, fs:0.69697 (r=0.697,p=0.697),  time:4.336, tt:190.782\n",
      "Ep:44, loss:0.00008, loss_test:0.10747, lr:8.51e-03, fs:0.69036 (r=0.687,p=0.694),  time:4.336, tt:195.108\n",
      "Ep:45, loss:0.00008, loss_test:0.10765, lr:8.51e-03, fs:0.69388 (r=0.687,p=0.701),  time:4.335, tt:199.410\n",
      "Ep:46, loss:0.00008, loss_test:0.10771, lr:8.51e-03, fs:0.69388 (r=0.687,p=0.701),  time:4.335, tt:203.736\n",
      "Ep:47, loss:0.00008, loss_test:0.10767, lr:8.51e-03, fs:0.68687 (r=0.687,p=0.687),  time:4.334, tt:208.008\n",
      "Ep:48, loss:0.00008, loss_test:0.10763, lr:8.51e-03, fs:0.69347 (r=0.697,p=0.690),  time:4.333, tt:212.298\n",
      "Ep:49, loss:0.00007, loss_test:0.10768, lr:8.51e-03, fs:0.69000 (r=0.697,p=0.683),  time:4.332, tt:216.595\n",
      "Ep:50, loss:0.00007, loss_test:0.10762, lr:8.51e-03, fs:0.69347 (r=0.697,p=0.690),  time:4.334, tt:221.050\n",
      "Ep:51, loss:0.00007, loss_test:0.10746, lr:8.43e-03, fs:0.69347 (r=0.697,p=0.690),  time:4.343, tt:225.837\n",
      "Ep:52, loss:0.00007, loss_test:0.10719, lr:8.35e-03, fs:0.69347 (r=0.697,p=0.690),  time:4.354, tt:230.737\n",
      "Ep:53, loss:0.00007, loss_test:0.10684, lr:8.26e-03, fs:0.69347 (r=0.697,p=0.690),  time:4.362, tt:235.568\n",
      "Ep:54, loss:0.00007, loss_test:0.10653, lr:8.18e-03, fs:0.69000 (r=0.697,p=0.683),  time:4.376, tt:240.660\n",
      "Ep:55, loss:0.00007, loss_test:0.10629, lr:8.10e-03, fs:0.69000 (r=0.697,p=0.683),  time:4.401, tt:246.475\n",
      "Ep:56, loss:0.00007, loss_test:0.10610, lr:8.02e-03, fs:0.69347 (r=0.697,p=0.690),  time:4.453, tt:253.838\n",
      "Ep:57, loss:0.00007, loss_test:0.10592, lr:7.94e-03, fs:0.69697 (r=0.697,p=0.697),  time:4.508, tt:261.478\n",
      "Ep:58, loss:0.00007, loss_test:0.10565, lr:7.86e-03, fs:0.68687 (r=0.687,p=0.687),  time:4.645, tt:274.037\n",
      "Ep:59, loss:0.00007, loss_test:0.10541, lr:7.78e-03, fs:0.68687 (r=0.687,p=0.687),  time:4.790, tt:287.420\n",
      "Ep:60, loss:0.00007, loss_test:0.10518, lr:7.70e-03, fs:0.68687 (r=0.687,p=0.687),  time:4.934, tt:300.995\n",
      "Ep:61, loss:0.00007, loss_test:0.10507, lr:7.62e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.086, tt:315.331\n",
      "Ep:62, loss:0.00007, loss_test:0.10504, lr:7.55e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.226, tt:329.242\n",
      "Ep:63, loss:0.00007, loss_test:0.10493, lr:7.47e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.369, tt:343.626\n",
      "Ep:64, loss:0.00006, loss_test:0.10469, lr:7.40e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.509, tt:358.110\n",
      "Ep:65, loss:0.00006, loss_test:0.10442, lr:7.32e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.639, tt:372.192\n",
      "Ep:66, loss:0.00006, loss_test:0.10422, lr:7.25e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.776, tt:387.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00006, loss_test:0.10410, lr:7.18e-03, fs:0.68020 (r=0.677,p=0.684),  time:5.898, tt:401.061\n",
      "Ep:68, loss:0.00006, loss_test:0.10404, lr:7.11e-03, fs:0.68020 (r=0.677,p=0.684),  time:6.020, tt:415.412\n",
      "Ep:69, loss:0.00006, loss_test:0.10391, lr:7.03e-03, fs:0.68687 (r=0.687,p=0.687),  time:6.147, tt:430.300\n",
      "Ep:70, loss:0.00006, loss_test:0.10374, lr:6.96e-03, fs:0.68342 (r=0.687,p=0.680),  time:6.276, tt:445.563\n",
      "Ep:71, loss:0.00006, loss_test:0.10353, lr:6.89e-03, fs:0.68367 (r=0.677,p=0.691),  time:6.392, tt:460.240\n",
      "Ep:72, loss:0.00006, loss_test:0.10331, lr:6.83e-03, fs:0.69697 (r=0.697,p=0.697),  time:6.512, tt:475.359\n",
      "Ep:73, loss:0.00006, loss_test:0.10317, lr:6.76e-03, fs:0.70051 (r=0.697,p=0.704),  time:6.612, tt:489.310\n",
      "Ep:74, loss:0.00006, loss_test:0.10306, lr:6.69e-03, fs:0.69036 (r=0.687,p=0.694),  time:6.726, tt:504.414\n",
      "Ep:75, loss:0.00006, loss_test:0.10293, lr:6.62e-03, fs:0.69697 (r=0.697,p=0.697),  time:6.851, tt:520.668\n",
      "Ep:76, loss:0.00006, loss_test:0.10269, lr:6.56e-03, fs:0.69697 (r=0.697,p=0.697),  time:6.960, tt:535.956\n",
      "Ep:77, loss:0.00006, loss_test:0.10246, lr:6.49e-03, fs:0.69697 (r=0.697,p=0.697),  time:7.060, tt:550.659\n",
      "Ep:78, loss:0.00006, loss_test:0.10235, lr:6.43e-03, fs:0.69697 (r=0.697,p=0.697),  time:7.167, tt:566.201\n",
      "Ep:79, loss:0.00006, loss_test:0.10224, lr:6.36e-03, fs:0.69697 (r=0.697,p=0.697),  time:7.265, tt:581.234\n",
      "Ep:80, loss:0.00006, loss_test:0.10202, lr:6.30e-03, fs:0.69697 (r=0.697,p=0.697),  time:7.365, tt:596.597\n",
      "Ep:81, loss:0.00006, loss_test:0.10180, lr:6.24e-03, fs:0.69000 (r=0.697,p=0.683),  time:7.452, tt:611.041\n",
      "Ep:82, loss:0.00006, loss_test:0.10173, lr:6.17e-03, fs:0.68657 (r=0.697,p=0.676),  time:7.539, tt:625.712\n",
      "Ep:83, loss:0.00005, loss_test:0.10173, lr:6.11e-03, fs:0.68657 (r=0.697,p=0.676),  time:7.627, tt:640.668\n",
      "Ep:84, loss:0.00005, loss_test:0.10161, lr:6.05e-03, fs:0.68657 (r=0.697,p=0.676),  time:7.715, tt:655.790\n",
      "Ep:85, loss:0.00005, loss_test:0.10147, lr:5.99e-03, fs:0.69652 (r=0.707,p=0.686),  time:7.815, tt:672.118\n",
      "Ep:86, loss:0.00005, loss_test:0.10144, lr:5.93e-03, fs:0.69652 (r=0.707,p=0.686),  time:7.891, tt:686.526\n",
      "Ep:87, loss:0.00005, loss_test:0.10151, lr:5.87e-03, fs:0.69652 (r=0.707,p=0.686),  time:7.978, tt:702.028\n",
      "Ep:88, loss:0.00005, loss_test:0.10142, lr:5.81e-03, fs:0.69652 (r=0.707,p=0.686),  time:8.056, tt:716.951\n",
      "Ep:89, loss:0.00005, loss_test:0.10123, lr:5.75e-03, fs:0.69652 (r=0.707,p=0.686),  time:8.135, tt:732.132\n",
      "Ep:90, loss:0.00005, loss_test:0.10116, lr:5.70e-03, fs:0.69652 (r=0.707,p=0.686),  time:8.222, tt:748.194\n",
      "Ep:91, loss:0.00005, loss_test:0.10112, lr:5.64e-03, fs:0.69652 (r=0.707,p=0.686),  time:8.320, tt:765.445\n",
      "Ep:92, loss:0.00005, loss_test:0.10100, lr:5.58e-03, fs:0.69652 (r=0.707,p=0.686),  time:8.398, tt:780.993\n",
      "Ep:93, loss:0.00005, loss_test:0.10087, lr:5.53e-03, fs:0.70000 (r=0.707,p=0.693),  time:8.487, tt:797.731\n",
      "Ep:94, loss:0.00005, loss_test:0.10076, lr:5.47e-03, fs:0.70000 (r=0.707,p=0.693),  time:8.569, tt:814.099\n",
      "Ep:95, loss:0.00005, loss_test:0.10076, lr:5.42e-03, fs:0.69652 (r=0.707,p=0.686),  time:8.656, tt:830.994\n",
      "Ep:96, loss:0.00005, loss_test:0.10068, lr:5.36e-03, fs:0.70000 (r=0.707,p=0.693),  time:8.731, tt:846.945\n",
      "Ep:97, loss:0.00005, loss_test:0.10045, lr:5.31e-03, fs:0.70000 (r=0.707,p=0.693),  time:8.809, tt:863.300\n",
      "Ep:98, loss:0.00005, loss_test:0.10031, lr:5.26e-03, fs:0.70352 (r=0.707,p=0.700),  time:8.882, tt:879.339\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00005, loss_test:0.10013, lr:5.26e-03, fs:0.70000 (r=0.707,p=0.693),  time:8.953, tt:895.252\n",
      "Ep:100, loss:0.00005, loss_test:0.10010, lr:5.26e-03, fs:0.70000 (r=0.707,p=0.693),  time:9.018, tt:910.780\n",
      "Ep:101, loss:0.00005, loss_test:0.09989, lr:5.26e-03, fs:0.70000 (r=0.707,p=0.693),  time:9.068, tt:924.923\n",
      "Ep:102, loss:0.00005, loss_test:0.09978, lr:5.26e-03, fs:0.70000 (r=0.707,p=0.693),  time:9.126, tt:939.954\n",
      "Ep:103, loss:0.00005, loss_test:0.09986, lr:5.26e-03, fs:0.69697 (r=0.697,p=0.697),  time:9.197, tt:956.489\n",
      "Ep:104, loss:0.00005, loss_test:0.09972, lr:5.26e-03, fs:0.69697 (r=0.697,p=0.697),  time:9.265, tt:972.784\n",
      "Ep:105, loss:0.00005, loss_test:0.09940, lr:5.26e-03, fs:0.69697 (r=0.697,p=0.697),  time:9.320, tt:987.947\n",
      "Ep:106, loss:0.00005, loss_test:0.09935, lr:5.26e-03, fs:0.69697 (r=0.697,p=0.697),  time:9.364, tt:1001.906\n",
      "Ep:107, loss:0.00005, loss_test:0.09930, lr:5.26e-03, fs:0.70352 (r=0.707,p=0.700),  time:9.413, tt:1016.634\n",
      "Ep:108, loss:0.00005, loss_test:0.09920, lr:5.26e-03, fs:0.70352 (r=0.707,p=0.700),  time:9.460, tt:1031.169\n",
      "Ep:109, loss:0.00005, loss_test:0.09905, lr:5.26e-03, fs:0.70352 (r=0.707,p=0.700),  time:9.509, tt:1045.948\n",
      "Ep:110, loss:0.00005, loss_test:0.09887, lr:5.20e-03, fs:0.70352 (r=0.707,p=0.700),  time:9.563, tt:1061.476\n",
      "Ep:111, loss:0.00005, loss_test:0.09864, lr:5.15e-03, fs:0.70352 (r=0.707,p=0.700),  time:9.613, tt:1076.647\n",
      "Ep:112, loss:0.00005, loss_test:0.09855, lr:5.10e-03, fs:0.70352 (r=0.707,p=0.700),  time:9.666, tt:1092.273\n",
      "Ep:113, loss:0.00005, loss_test:0.09852, lr:5.05e-03, fs:0.70707 (r=0.707,p=0.707),  time:9.718, tt:1107.797\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00004, loss_test:0.09834, lr:5.05e-03, fs:0.70707 (r=0.707,p=0.707),  time:9.764, tt:1122.881\n",
      "Ep:115, loss:0.00004, loss_test:0.09834, lr:5.05e-03, fs:0.71066 (r=0.707,p=0.714),  time:9.815, tt:1138.561\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00004, loss_test:0.09811, lr:5.05e-03, fs:0.71066 (r=0.707,p=0.714),  time:9.867, tt:1154.406\n",
      "Ep:117, loss:0.00004, loss_test:0.09800, lr:5.05e-03, fs:0.71066 (r=0.707,p=0.714),  time:9.913, tt:1169.785\n",
      "Ep:118, loss:0.00004, loss_test:0.09792, lr:5.05e-03, fs:0.71066 (r=0.707,p=0.714),  time:9.955, tt:1184.700\n",
      "Ep:119, loss:0.00004, loss_test:0.09771, lr:5.05e-03, fs:0.71717 (r=0.717,p=0.717),  time:9.996, tt:1199.536\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00004, loss_test:0.09777, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.035, tt:1214.276\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00004, loss_test:0.09761, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.075, tt:1229.117\n",
      "Ep:122, loss:0.00004, loss_test:0.09748, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.111, tt:1243.648\n",
      "Ep:123, loss:0.00004, loss_test:0.09743, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.152, tt:1258.899\n",
      "Ep:124, loss:0.00004, loss_test:0.09728, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.189, tt:1273.658\n",
      "Ep:125, loss:0.00004, loss_test:0.09715, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.227, tt:1288.561\n",
      "Ep:126, loss:0.00004, loss_test:0.09712, lr:5.05e-03, fs:0.72449 (r=0.717,p=0.732),  time:10.267, tt:1303.948\n",
      "Ep:127, loss:0.00004, loss_test:0.09692, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.307, tt:1319.243\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00004, loss_test:0.09684, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.357, tt:1336.047\n",
      "Ep:129, loss:0.00004, loss_test:0.09680, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.398, tt:1351.801\n",
      "Ep:130, loss:0.00004, loss_test:0.09673, lr:5.05e-03, fs:0.73196 (r=0.717,p=0.747),  time:10.437, tt:1367.218\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00004, loss_test:0.09670, lr:5.05e-03, fs:0.73196 (r=0.717,p=0.747),  time:10.473, tt:1382.488\n",
      "Ep:132, loss:0.00004, loss_test:0.09667, lr:5.05e-03, fs:0.73196 (r=0.717,p=0.747),  time:10.508, tt:1397.504\n",
      "Ep:133, loss:0.00004, loss_test:0.09659, lr:5.05e-03, fs:0.73196 (r=0.717,p=0.747),  time:10.547, tt:1413.311\n",
      "Ep:134, loss:0.00004, loss_test:0.09648, lr:5.05e-03, fs:0.73196 (r=0.717,p=0.747),  time:10.578, tt:1428.074\n",
      "Ep:135, loss:0.00004, loss_test:0.09643, lr:5.05e-03, fs:0.73196 (r=0.717,p=0.747),  time:10.617, tt:1443.873\n",
      "Ep:136, loss:0.00004, loss_test:0.09643, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.648, tt:1458.791\n",
      "Ep:137, loss:0.00004, loss_test:0.09630, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.675, tt:1473.199\n",
      "Ep:138, loss:0.00004, loss_test:0.09627, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.707, tt:1488.233\n",
      "Ep:139, loss:0.00004, loss_test:0.09609, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.739, tt:1503.428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00004, loss_test:0.09609, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.768, tt:1518.242\n",
      "Ep:141, loss:0.00004, loss_test:0.09592, lr:5.05e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.797, tt:1533.213\n",
      "Ep:142, loss:0.00004, loss_test:0.09599, lr:5.00e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.826, tt:1548.100\n",
      "Ep:143, loss:0.00004, loss_test:0.09577, lr:4.95e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.857, tt:1563.415\n",
      "Ep:144, loss:0.00004, loss_test:0.09603, lr:4.90e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.891, tt:1579.241\n",
      "Ep:145, loss:0.00004, loss_test:0.09574, lr:4.85e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.920, tt:1594.321\n",
      "Ep:146, loss:0.00004, loss_test:0.09547, lr:4.80e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.953, tt:1610.133\n",
      "Ep:147, loss:0.00004, loss_test:0.09553, lr:4.75e-03, fs:0.72821 (r=0.717,p=0.740),  time:10.984, tt:1625.652\n",
      "Ep:148, loss:0.00004, loss_test:0.09549, lr:4.71e-03, fs:0.72821 (r=0.717,p=0.740),  time:11.017, tt:1641.559\n",
      "Ep:149, loss:0.00004, loss_test:0.09515, lr:4.66e-03, fs:0.72821 (r=0.717,p=0.740),  time:11.047, tt:1657.114\n",
      "Ep:150, loss:0.00004, loss_test:0.09548, lr:4.61e-03, fs:0.72821 (r=0.717,p=0.740),  time:11.073, tt:1672.081\n",
      "Ep:151, loss:0.00004, loss_test:0.09527, lr:4.57e-03, fs:0.73196 (r=0.717,p=0.747),  time:11.104, tt:1687.788\n",
      "Ep:152, loss:0.00004, loss_test:0.09489, lr:4.52e-03, fs:0.73196 (r=0.717,p=0.747),  time:11.132, tt:1703.211\n",
      "Ep:153, loss:0.00004, loss_test:0.09509, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.170, tt:1720.191\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00004, loss_test:0.09499, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.196, tt:1735.346\n",
      "Ep:155, loss:0.00004, loss_test:0.09468, lr:4.48e-03, fs:0.73196 (r=0.717,p=0.747),  time:11.221, tt:1750.549\n",
      "Ep:156, loss:0.00003, loss_test:0.09510, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.248, tt:1765.921\n",
      "Ep:157, loss:0.00003, loss_test:0.09497, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.278, tt:1781.882\n",
      "Ep:158, loss:0.00003, loss_test:0.09444, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.298, tt:1796.421\n",
      "Ep:159, loss:0.00003, loss_test:0.09444, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.325, tt:1812.030\n",
      "Ep:160, loss:0.00003, loss_test:0.09475, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.350, tt:1827.425\n",
      "Ep:161, loss:0.00003, loss_test:0.09462, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.373, tt:1842.403\n",
      "Ep:162, loss:0.00003, loss_test:0.09444, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.403, tt:1858.771\n",
      "Ep:163, loss:0.00003, loss_test:0.09455, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.430, tt:1874.478\n",
      "Ep:164, loss:0.00003, loss_test:0.09458, lr:4.48e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.448, tt:1888.917\n",
      "Ep:165, loss:0.00003, loss_test:0.09429, lr:4.43e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.469, tt:1903.908\n",
      "Ep:166, loss:0.00003, loss_test:0.09420, lr:4.39e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.492, tt:1919.204\n",
      "Ep:167, loss:0.00003, loss_test:0.09465, lr:4.34e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.512, tt:1934.093\n",
      "Ep:168, loss:0.00003, loss_test:0.09458, lr:4.30e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.534, tt:1949.319\n",
      "Ep:169, loss:0.00003, loss_test:0.09410, lr:4.26e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.559, tt:1965.110\n",
      "Ep:170, loss:0.00003, loss_test:0.09408, lr:4.21e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.581, tt:1980.329\n",
      "Ep:171, loss:0.00003, loss_test:0.09434, lr:4.17e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.606, tt:1996.180\n",
      "Ep:172, loss:0.00003, loss_test:0.09423, lr:4.13e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.616, tt:2009.632\n",
      "Ep:173, loss:0.00003, loss_test:0.09395, lr:4.09e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.636, tt:2024.747\n",
      "Ep:174, loss:0.00003, loss_test:0.09431, lr:4.05e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.655, tt:2039.590\n",
      "Ep:175, loss:0.00003, loss_test:0.09426, lr:4.01e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.670, tt:2053.959\n",
      "Ep:176, loss:0.00003, loss_test:0.09404, lr:3.97e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.686, tt:2068.492\n",
      "Ep:177, loss:0.00003, loss_test:0.09410, lr:3.93e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.699, tt:2082.488\n",
      "Ep:178, loss:0.00003, loss_test:0.09439, lr:3.89e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.714, tt:2096.799\n",
      "Ep:179, loss:0.00003, loss_test:0.09436, lr:3.85e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.725, tt:2110.522\n",
      "Ep:180, loss:0.00003, loss_test:0.09411, lr:3.81e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.742, tt:2125.349\n",
      "Ep:181, loss:0.00003, loss_test:0.09420, lr:3.77e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.759, tt:2140.092\n",
      "Ep:182, loss:0.00003, loss_test:0.09413, lr:3.73e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.777, tt:2155.185\n",
      "Ep:183, loss:0.00003, loss_test:0.09385, lr:3.70e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.781, tt:2167.626\n",
      "Ep:184, loss:0.00003, loss_test:0.09401, lr:3.66e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.788, tt:2180.852\n",
      "Ep:185, loss:0.00003, loss_test:0.09430, lr:3.62e-03, fs:0.73958 (r=0.717,p=0.763),  time:11.803, tt:2195.404\n",
      "##########Best model found so far##########\n",
      "Ep:186, loss:0.00003, loss_test:0.09419, lr:3.62e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.812, tt:2208.829\n",
      "Ep:187, loss:0.00003, loss_test:0.09390, lr:3.62e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.827, tt:2223.524\n",
      "Ep:188, loss:0.00003, loss_test:0.09405, lr:3.62e-03, fs:0.73958 (r=0.717,p=0.763),  time:11.839, tt:2237.556\n",
      "Ep:189, loss:0.00003, loss_test:0.09395, lr:3.62e-03, fs:0.73958 (r=0.717,p=0.763),  time:11.850, tt:2251.484\n",
      "Ep:190, loss:0.00003, loss_test:0.09367, lr:3.62e-03, fs:0.73958 (r=0.717,p=0.763),  time:11.861, tt:2265.520\n",
      "Ep:191, loss:0.00003, loss_test:0.09387, lr:3.62e-03, fs:0.73958 (r=0.717,p=0.763),  time:11.877, tt:2280.436\n",
      "Ep:192, loss:0.00003, loss_test:0.09426, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:11.896, tt:2295.870\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00003, loss_test:0.09423, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:11.914, tt:2311.382\n",
      "Ep:194, loss:0.00003, loss_test:0.09383, lr:3.62e-03, fs:0.73575 (r=0.717,p=0.755),  time:11.926, tt:2325.489\n",
      "Ep:195, loss:0.00003, loss_test:0.09374, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:11.939, tt:2340.118\n",
      "Ep:196, loss:0.00003, loss_test:0.09396, lr:3.62e-03, fs:0.74737 (r=0.717,p=0.780),  time:11.960, tt:2356.053\n",
      "##########Best model found so far##########\n",
      "Ep:197, loss:0.00003, loss_test:0.09399, lr:3.62e-03, fs:0.74737 (r=0.717,p=0.780),  time:11.981, tt:2372.287\n",
      "Ep:198, loss:0.00003, loss_test:0.09381, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:11.999, tt:2387.729\n",
      "Ep:199, loss:0.00003, loss_test:0.09394, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:12.010, tt:2401.917\n",
      "Ep:200, loss:0.00003, loss_test:0.09398, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:12.028, tt:2417.715\n",
      "Ep:201, loss:0.00003, loss_test:0.09387, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:12.044, tt:2432.895\n",
      "Ep:202, loss:0.00003, loss_test:0.09369, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:12.055, tt:2447.155\n",
      "Ep:203, loss:0.00003, loss_test:0.09400, lr:3.62e-03, fs:0.74737 (r=0.717,p=0.780),  time:12.071, tt:2462.471\n",
      "Ep:204, loss:0.00003, loss_test:0.09413, lr:3.62e-03, fs:0.74737 (r=0.717,p=0.780),  time:12.087, tt:2477.773\n",
      "Ep:205, loss:0.00003, loss_test:0.09389, lr:3.62e-03, fs:0.74346 (r=0.717,p=0.772),  time:12.107, tt:2494.101\n",
      "Ep:206, loss:0.00003, loss_test:0.09392, lr:3.62e-03, fs:0.74737 (r=0.717,p=0.780),  time:12.126, tt:2510.008\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14103, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.422, tt:15.422\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13910, lr:1.00e-02, fs:0.66667 (r=0.982,p=0.505),  time:20.148, tt:40.296\n",
      "Ep:2, loss:0.00027, loss_test:0.13582, lr:1.00e-02, fs:0.66250 (r=0.964,p=0.505),  time:23.548, tt:70.643\n",
      "Ep:3, loss:0.00026, loss_test:0.13054, lr:1.00e-02, fs:0.63576 (r=0.873,p=0.500),  time:25.776, tt:103.105\n",
      "Ep:4, loss:0.00025, loss_test:0.12432, lr:1.00e-02, fs:0.63158 (r=0.764,p=0.538),  time:26.719, tt:133.596\n",
      "Ep:5, loss:0.00024, loss_test:0.12014, lr:1.00e-02, fs:0.63793 (r=0.673,p=0.607),  time:27.548, tt:165.287\n",
      "Ep:6, loss:0.00023, loss_test:0.11869, lr:1.00e-02, fs:0.64286 (r=0.655,p=0.632),  time:28.309, tt:198.161\n",
      "Ep:7, loss:0.00022, loss_test:0.11704, lr:1.00e-02, fs:0.67241 (r=0.709,p=0.639),  time:28.802, tt:230.420\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11514, lr:1.00e-02, fs:0.68376 (r=0.727,p=0.645),  time:29.121, tt:262.086\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11350, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:29.480, tt:294.804\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11228, lr:1.00e-02, fs:0.70270 (r=0.709,p=0.696),  time:29.823, tt:328.053\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10952, lr:1.00e-02, fs:0.71429 (r=0.727,p=0.702),  time:29.920, tt:359.039\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10581, lr:1.00e-02, fs:0.71930 (r=0.745,p=0.695),  time:30.286, tt:393.721\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10260, lr:1.00e-02, fs:0.74576 (r=0.800,p=0.698),  time:30.523, tt:427.325\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10033, lr:1.00e-02, fs:0.76522 (r=0.800,p=0.733),  time:30.682, tt:460.230\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09930, lr:1.00e-02, fs:0.77477 (r=0.782,p=0.768),  time:30.754, tt:492.063\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09723, lr:1.00e-02, fs:0.79646 (r=0.818,p=0.776),  time:30.767, tt:523.045\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09497, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:30.911, tt:556.392\n",
      "Ep:18, loss:0.00016, loss_test:0.09287, lr:1.00e-02, fs:0.81034 (r=0.855,p=0.770),  time:30.990, tt:588.803\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09103, lr:1.00e-02, fs:0.81416 (r=0.836,p=0.793),  time:31.105, tt:622.099\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.08892, lr:1.00e-02, fs:0.82759 (r=0.873,p=0.787),  time:31.164, tt:654.450\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08664, lr:1.00e-02, fs:0.83761 (r=0.891,p=0.790),  time:31.237, tt:687.211\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08384, lr:1.00e-02, fs:0.84211 (r=0.873,p=0.814),  time:31.277, tt:719.379\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08232, lr:1.00e-02, fs:0.84956 (r=0.873,p=0.828),  time:31.319, tt:751.651\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08157, lr:1.00e-02, fs:0.83478 (r=0.873,p=0.800),  time:31.380, tt:784.495\n",
      "Ep:25, loss:0.00013, loss_test:0.07976, lr:1.00e-02, fs:0.82456 (r=0.855,p=0.797),  time:31.421, tt:816.945\n",
      "Ep:26, loss:0.00013, loss_test:0.07824, lr:1.00e-02, fs:0.83478 (r=0.873,p=0.800),  time:31.445, tt:849.028\n",
      "Ep:27, loss:0.00013, loss_test:0.07709, lr:1.00e-02, fs:0.83478 (r=0.873,p=0.800),  time:31.434, tt:880.147\n",
      "Ep:28, loss:0.00012, loss_test:0.07585, lr:1.00e-02, fs:0.82759 (r=0.873,p=0.787),  time:31.473, tt:912.711\n",
      "Ep:29, loss:0.00012, loss_test:0.07446, lr:1.00e-02, fs:0.82759 (r=0.873,p=0.787),  time:31.474, tt:944.208\n",
      "Ep:30, loss:0.00012, loss_test:0.07344, lr:1.00e-02, fs:0.82759 (r=0.873,p=0.787),  time:31.444, tt:974.752\n",
      "Ep:31, loss:0.00012, loss_test:0.07199, lr:1.00e-02, fs:0.83478 (r=0.873,p=0.800),  time:31.455, tt:1006.548\n",
      "Ep:32, loss:0.00011, loss_test:0.07063, lr:1.00e-02, fs:0.83478 (r=0.873,p=0.800),  time:31.463, tt:1038.269\n",
      "Ep:33, loss:0.00011, loss_test:0.06981, lr:1.00e-02, fs:0.84483 (r=0.891,p=0.803),  time:31.483, tt:1070.432\n",
      "Ep:34, loss:0.00011, loss_test:0.06869, lr:1.00e-02, fs:0.85217 (r=0.891,p=0.817),  time:31.477, tt:1101.712\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.06707, lr:1.00e-02, fs:0.85965 (r=0.891,p=0.831),  time:31.490, tt:1133.644\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.06594, lr:1.00e-02, fs:0.85965 (r=0.891,p=0.831),  time:31.489, tt:1165.105\n",
      "Ep:37, loss:0.00010, loss_test:0.06514, lr:1.00e-02, fs:0.88496 (r=0.909,p=0.862),  time:31.499, tt:1196.945\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.06346, lr:1.00e-02, fs:0.87719 (r=0.909,p=0.847),  time:31.541, tt:1230.113\n",
      "Ep:39, loss:0.00010, loss_test:0.06204, lr:1.00e-02, fs:0.88496 (r=0.909,p=0.862),  time:31.547, tt:1261.889\n",
      "Ep:40, loss:0.00009, loss_test:0.06173, lr:1.00e-02, fs:0.88496 (r=0.909,p=0.862),  time:31.560, tt:1293.960\n",
      "Ep:41, loss:0.00009, loss_test:0.06048, lr:1.00e-02, fs:0.87719 (r=0.909,p=0.847),  time:31.577, tt:1326.235\n",
      "Ep:42, loss:0.00009, loss_test:0.05906, lr:1.00e-02, fs:0.90090 (r=0.909,p=0.893),  time:31.571, tt:1357.570\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.05828, lr:1.00e-02, fs:0.89474 (r=0.927,p=0.864),  time:31.580, tt:1389.538\n",
      "Ep:44, loss:0.00009, loss_test:0.05681, lr:1.00e-02, fs:0.89474 (r=0.927,p=0.864),  time:31.581, tt:1421.154\n",
      "Ep:45, loss:0.00008, loss_test:0.05594, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.612, tt:1454.149\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.05526, lr:1.00e-02, fs:0.89474 (r=0.927,p=0.864),  time:31.604, tt:1485.367\n",
      "Ep:47, loss:0.00008, loss_test:0.05367, lr:1.00e-02, fs:0.91071 (r=0.927,p=0.895),  time:31.646, tt:1519.002\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.05376, lr:1.00e-02, fs:0.89474 (r=0.927,p=0.864),  time:31.657, tt:1551.182\n",
      "Ep:49, loss:0.00008, loss_test:0.05269, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.671, tt:1583.558\n",
      "Ep:50, loss:0.00008, loss_test:0.05162, lr:1.00e-02, fs:0.89474 (r=0.927,p=0.864),  time:31.711, tt:1617.251\n",
      "Ep:51, loss:0.00007, loss_test:0.05169, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.715, tt:1649.191\n",
      "Ep:52, loss:0.00007, loss_test:0.05091, lr:1.00e-02, fs:0.91071 (r=0.927,p=0.895),  time:31.716, tt:1680.968\n",
      "Ep:53, loss:0.00007, loss_test:0.04952, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.736, tt:1713.731\n",
      "Ep:54, loss:0.00007, loss_test:0.04912, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.754, tt:1746.490\n",
      "Ep:55, loss:0.00007, loss_test:0.04822, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.772, tt:1779.225\n",
      "Ep:56, loss:0.00007, loss_test:0.04792, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.740, tt:1809.176\n",
      "Ep:57, loss:0.00006, loss_test:0.04772, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.755, tt:1841.761\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.04617, lr:1.00e-02, fs:0.89474 (r=0.927,p=0.864),  time:31.726, tt:1871.818\n",
      "Ep:59, loss:0.00006, loss_test:0.04697, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.733, tt:1903.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00006, loss_test:0.04509, lr:1.00e-02, fs:0.90265 (r=0.927,p=0.879),  time:31.730, tt:1935.517\n",
      "Ep:61, loss:0.00006, loss_test:0.04544, lr:1.00e-02, fs:0.93578 (r=0.927,p=0.944),  time:31.734, tt:1967.529\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.04422, lr:1.00e-02, fs:0.91071 (r=0.927,p=0.895),  time:31.763, tt:2001.091\n",
      "Ep:63, loss:0.00006, loss_test:0.04374, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.764, tt:2032.906\n",
      "Ep:64, loss:0.00006, loss_test:0.04319, lr:1.00e-02, fs:0.91071 (r=0.927,p=0.895),  time:31.760, tt:2064.413\n",
      "Ep:65, loss:0.00005, loss_test:0.04251, lr:1.00e-02, fs:0.93578 (r=0.927,p=0.944),  time:31.765, tt:2096.508\n",
      "Ep:66, loss:0.00005, loss_test:0.04220, lr:1.00e-02, fs:0.91892 (r=0.927,p=0.911),  time:31.789, tt:2129.867\n",
      "Ep:67, loss:0.00005, loss_test:0.04177, lr:1.00e-02, fs:0.91892 (r=0.927,p=0.911),  time:31.804, tt:2162.654\n",
      "Ep:68, loss:0.00005, loss_test:0.04146, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.802, tt:2194.309\n",
      "Ep:69, loss:0.00005, loss_test:0.04088, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.815, tt:2227.017\n",
      "Ep:70, loss:0.00005, loss_test:0.04082, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.805, tt:2258.145\n",
      "Ep:71, loss:0.00005, loss_test:0.04023, lr:1.00e-02, fs:0.93578 (r=0.927,p=0.944),  time:31.797, tt:2289.388\n",
      "Ep:72, loss:0.00005, loss_test:0.04033, lr:1.00e-02, fs:0.92727 (r=0.927,p=0.927),  time:31.788, tt:2320.491\n",
      "Ep:73, loss:0.00005, loss_test:0.03942, lr:9.90e-03, fs:0.93578 (r=0.927,p=0.944),  time:31.798, tt:2353.046\n",
      "Ep:74, loss:0.00004, loss_test:0.03917, lr:9.80e-03, fs:0.92727 (r=0.927,p=0.927),  time:31.785, tt:2383.861\n",
      "Ep:75, loss:0.00004, loss_test:0.03871, lr:9.70e-03, fs:0.93578 (r=0.927,p=0.944),  time:31.782, tt:2415.404\n",
      "Ep:76, loss:0.00004, loss_test:0.03824, lr:9.61e-03, fs:0.92727 (r=0.927,p=0.927),  time:31.849, tt:2452.352\n",
      "Ep:77, loss:0.00004, loss_test:0.03854, lr:9.51e-03, fs:0.92593 (r=0.909,p=0.943),  time:31.864, tt:2485.390\n",
      "Ep:78, loss:0.00004, loss_test:0.03771, lr:9.41e-03, fs:0.91743 (r=0.909,p=0.926),  time:31.843, tt:2515.624\n",
      "Ep:79, loss:0.00004, loss_test:0.03744, lr:9.32e-03, fs:0.91743 (r=0.909,p=0.926),  time:31.866, tt:2549.291\n",
      "Ep:80, loss:0.00004, loss_test:0.03727, lr:9.23e-03, fs:0.92593 (r=0.909,p=0.943),  time:31.887, tt:2582.810\n",
      "Ep:81, loss:0.00004, loss_test:0.03686, lr:9.14e-03, fs:0.91743 (r=0.909,p=0.926),  time:31.898, tt:2615.642\n",
      "Ep:82, loss:0.00004, loss_test:0.03638, lr:9.04e-03, fs:0.93458 (r=0.909,p=0.962),  time:31.913, tt:2648.793\n",
      "Ep:83, loss:0.00004, loss_test:0.03655, lr:8.95e-03, fs:0.91743 (r=0.909,p=0.926),  time:31.936, tt:2682.660\n",
      "Ep:84, loss:0.00004, loss_test:0.03604, lr:8.86e-03, fs:0.93458 (r=0.909,p=0.962),  time:31.964, tt:2716.919\n",
      "Ep:85, loss:0.00004, loss_test:0.03612, lr:8.78e-03, fs:0.91743 (r=0.909,p=0.926),  time:31.971, tt:2749.511\n",
      "Ep:86, loss:0.00003, loss_test:0.03529, lr:8.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:31.984, tt:2782.596\n",
      "Ep:87, loss:0.00003, loss_test:0.03550, lr:8.60e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.003, tt:2816.264\n",
      "Ep:88, loss:0.00003, loss_test:0.03507, lr:8.51e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.022, tt:2849.963\n",
      "Ep:89, loss:0.00003, loss_test:0.03532, lr:8.43e-03, fs:0.92593 (r=0.909,p=0.943),  time:32.027, tt:2882.443\n",
      "Ep:90, loss:0.00003, loss_test:0.03467, lr:8.35e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.045, tt:2916.130\n",
      "Ep:91, loss:0.00003, loss_test:0.03449, lr:8.26e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.072, tt:2950.644\n",
      "Ep:92, loss:0.00003, loss_test:0.03436, lr:8.18e-03, fs:0.92593 (r=0.909,p=0.943),  time:32.090, tt:2984.411\n",
      "Ep:93, loss:0.00003, loss_test:0.03403, lr:8.10e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.101, tt:3017.499\n",
      "Ep:94, loss:0.00003, loss_test:0.03399, lr:8.02e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.125, tt:3051.852\n",
      "Ep:95, loss:0.00003, loss_test:0.03357, lr:7.94e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.144, tt:3085.843\n",
      "Ep:96, loss:0.00003, loss_test:0.03427, lr:7.86e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.144, tt:3117.999\n",
      "Ep:97, loss:0.00003, loss_test:0.03351, lr:7.78e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.168, tt:3152.441\n",
      "Ep:98, loss:0.00003, loss_test:0.03322, lr:7.70e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.180, tt:3185.789\n",
      "Ep:99, loss:0.00003, loss_test:0.03273, lr:7.62e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.196, tt:3219.608\n",
      "Ep:100, loss:0.00003, loss_test:0.03281, lr:7.55e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.212, tt:3253.427\n",
      "Ep:101, loss:0.00003, loss_test:0.03245, lr:7.47e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.227, tt:3287.162\n",
      "Ep:102, loss:0.00003, loss_test:0.03245, lr:7.40e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.231, tt:3319.840\n",
      "Ep:103, loss:0.00003, loss_test:0.03228, lr:7.32e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.245, tt:3353.489\n",
      "Ep:104, loss:0.00003, loss_test:0.03203, lr:7.25e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.255, tt:3386.799\n",
      "Ep:105, loss:0.00002, loss_test:0.03199, lr:7.18e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.256, tt:3419.144\n",
      "Ep:106, loss:0.00002, loss_test:0.03169, lr:7.11e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.262, tt:3452.048\n",
      "Ep:107, loss:0.00002, loss_test:0.03171, lr:7.03e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.256, tt:3483.624\n",
      "Ep:108, loss:0.00002, loss_test:0.03154, lr:6.96e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.268, tt:3517.233\n",
      "Ep:109, loss:0.00002, loss_test:0.03141, lr:6.89e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.284, tt:3551.189\n",
      "Ep:110, loss:0.00002, loss_test:0.03124, lr:6.83e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.272, tt:3582.160\n",
      "Ep:111, loss:0.00002, loss_test:0.03155, lr:6.76e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.271, tt:3614.331\n",
      "Ep:112, loss:0.00002, loss_test:0.03108, lr:6.69e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.279, tt:3647.477\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00002, loss_test:0.03136, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.282, tt:3680.205\n",
      "Ep:114, loss:0.00002, loss_test:0.03062, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.292, tt:3713.632\n",
      "Ep:115, loss:0.00002, loss_test:0.03098, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.288, tt:3745.395\n",
      "Ep:116, loss:0.00002, loss_test:0.03033, lr:6.69e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.294, tt:3778.400\n",
      "Ep:117, loss:0.00002, loss_test:0.03095, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.281, tt:3809.200\n",
      "Ep:118, loss:0.00002, loss_test:0.03049, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.284, tt:3841.847\n",
      "Ep:119, loss:0.00002, loss_test:0.02990, lr:6.69e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.294, tt:3875.334\n",
      "Ep:120, loss:0.00002, loss_test:0.03106, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.289, tt:3906.957\n",
      "Ep:121, loss:0.00002, loss_test:0.02973, lr:6.69e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.294, tt:3939.827\n",
      "Ep:122, loss:0.00002, loss_test:0.03047, lr:6.69e-03, fs:0.93458 (r=0.909,p=0.962),  time:32.300, tt:3972.943\n",
      "Ep:123, loss:0.00002, loss_test:0.02999, lr:6.69e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.317, tt:4007.278\n",
      "Ep:124, loss:0.00002, loss_test:0.02992, lr:6.62e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.325, tt:4040.617\n",
      "Ep:125, loss:0.00002, loss_test:0.03008, lr:6.56e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.315, tt:4071.640\n",
      "Ep:126, loss:0.00002, loss_test:0.02977, lr:6.49e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.329, tt:4105.731\n",
      "Ep:127, loss:0.00002, loss_test:0.02976, lr:6.43e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.334, tt:4138.763\n",
      "Ep:128, loss:0.00002, loss_test:0.02948, lr:6.36e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.338, tt:4171.583\n",
      "Ep:129, loss:0.00002, loss_test:0.02952, lr:6.30e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.340, tt:4204.195\n",
      "Ep:130, loss:0.00002, loss_test:0.02943, lr:6.24e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.354, tt:4238.362\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00002, loss_test:0.02901, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.348, tt:4269.940\n",
      "Ep:132, loss:0.00002, loss_test:0.02930, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.351, tt:4302.735\n",
      "Ep:133, loss:0.00002, loss_test:0.02897, lr:6.24e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.362, tt:4336.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.02898, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.366, tt:4369.370\n",
      "Ep:135, loss:0.00002, loss_test:0.02895, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.379, tt:4403.566\n",
      "Ep:136, loss:0.00002, loss_test:0.02880, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.377, tt:4435.662\n",
      "Ep:137, loss:0.00002, loss_test:0.02880, lr:6.24e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.386, tt:4469.253\n",
      "Ep:138, loss:0.00002, loss_test:0.02875, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.400, tt:4503.556\n",
      "Ep:139, loss:0.00002, loss_test:0.02879, lr:6.24e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.411, tt:4537.495\n",
      "Ep:140, loss:0.00002, loss_test:0.02847, lr:6.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.414, tt:4570.439\n",
      "Ep:141, loss:0.00002, loss_test:0.02904, lr:6.24e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.425, tt:4604.370\n",
      "Ep:142, loss:0.00002, loss_test:0.02846, lr:6.17e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.432, tt:4637.733\n",
      "Ep:143, loss:0.00002, loss_test:0.02842, lr:6.11e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.443, tt:4671.728\n",
      "Ep:144, loss:0.00001, loss_test:0.02913, lr:6.05e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.438, tt:4703.539\n",
      "Ep:145, loss:0.00001, loss_test:0.02819, lr:5.99e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.437, tt:4735.849\n",
      "Ep:146, loss:0.00001, loss_test:0.02868, lr:5.93e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.432, tt:4767.552\n",
      "Ep:147, loss:0.00001, loss_test:0.02879, lr:5.87e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.426, tt:4799.023\n",
      "Ep:148, loss:0.00001, loss_test:0.02800, lr:5.81e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.429, tt:4831.871\n",
      "Ep:149, loss:0.00001, loss_test:0.02824, lr:5.75e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.429, tt:4864.369\n",
      "Ep:150, loss:0.00001, loss_test:0.02838, lr:5.70e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.429, tt:4896.801\n",
      "Ep:151, loss:0.00001, loss_test:0.02788, lr:5.64e-03, fs:0.94444 (r=0.927,p=0.962),  time:32.435, tt:4930.080\n",
      "Ep:152, loss:0.00001, loss_test:0.02811, lr:5.58e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.418, tt:4959.882\n",
      "Ep:153, loss:0.00001, loss_test:0.02793, lr:5.53e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.419, tt:4992.549\n",
      "Ep:154, loss:0.00001, loss_test:0.02775, lr:5.47e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.414, tt:5024.222\n",
      "Ep:155, loss:0.00001, loss_test:0.02795, lr:5.42e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.422, tt:5057.798\n",
      "Ep:156, loss:0.00001, loss_test:0.02775, lr:5.36e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.429, tt:5091.346\n",
      "Ep:157, loss:0.00001, loss_test:0.02766, lr:5.31e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.439, tt:5125.371\n",
      "Ep:158, loss:0.00001, loss_test:0.02765, lr:5.26e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.433, tt:5156.870\n",
      "Ep:159, loss:0.00001, loss_test:0.02747, lr:5.20e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.455, tt:5192.780\n",
      "Ep:160, loss:0.00001, loss_test:0.02760, lr:5.15e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.448, tt:5224.063\n",
      "Ep:161, loss:0.00001, loss_test:0.02738, lr:5.10e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.444, tt:5255.945\n",
      "Ep:162, loss:0.00001, loss_test:0.02744, lr:5.05e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.445, tt:5288.613\n",
      "Ep:163, loss:0.00001, loss_test:0.02732, lr:5.00e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.454, tt:5322.464\n",
      "Ep:164, loss:0.00001, loss_test:0.02755, lr:4.95e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.464, tt:5356.636\n",
      "Ep:165, loss:0.00001, loss_test:0.02736, lr:4.90e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.462, tt:5388.671\n",
      "Ep:166, loss:0.00001, loss_test:0.02747, lr:4.85e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.468, tt:5422.123\n",
      "Ep:167, loss:0.00001, loss_test:0.02729, lr:4.80e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.471, tt:5455.154\n",
      "Ep:168, loss:0.00001, loss_test:0.02708, lr:4.75e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.477, tt:5488.549\n",
      "Ep:169, loss:0.00001, loss_test:0.02765, lr:4.71e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.481, tt:5521.763\n",
      "Ep:170, loss:0.00001, loss_test:0.02714, lr:4.66e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.484, tt:5554.763\n",
      "Ep:171, loss:0.00001, loss_test:0.02726, lr:4.61e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.486, tt:5587.607\n",
      "Ep:172, loss:0.00001, loss_test:0.02766, lr:4.57e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.485, tt:5619.918\n",
      "Ep:173, loss:0.00001, loss_test:0.02690, lr:4.52e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.487, tt:5652.693\n",
      "Ep:174, loss:0.00001, loss_test:0.02729, lr:4.48e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.485, tt:5684.866\n",
      "Ep:175, loss:0.00001, loss_test:0.02741, lr:4.43e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.489, tt:5718.021\n",
      "Ep:176, loss:0.00001, loss_test:0.02663, lr:4.39e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.495, tt:5751.664\n",
      "Ep:177, loss:0.00001, loss_test:0.02722, lr:4.34e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.495, tt:5784.135\n",
      "Ep:178, loss:0.00001, loss_test:0.02730, lr:4.30e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.499, tt:5817.324\n",
      "Ep:179, loss:0.00001, loss_test:0.02651, lr:4.26e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.495, tt:5849.093\n",
      "Ep:180, loss:0.00001, loss_test:0.02712, lr:4.21e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.496, tt:5881.824\n",
      "Ep:181, loss:0.00001, loss_test:0.02708, lr:4.17e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.495, tt:5914.170\n",
      "Ep:182, loss:0.00001, loss_test:0.02652, lr:4.13e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.506, tt:5948.581\n",
      "Ep:183, loss:0.00001, loss_test:0.02681, lr:4.09e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.512, tt:5982.200\n",
      "Ep:184, loss:0.00001, loss_test:0.02676, lr:4.05e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.514, tt:6015.047\n",
      "Ep:185, loss:0.00001, loss_test:0.02652, lr:4.01e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.516, tt:6048.007\n",
      "Ep:186, loss:0.00001, loss_test:0.02682, lr:3.97e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.518, tt:6080.810\n",
      "Ep:187, loss:0.00001, loss_test:0.02673, lr:3.93e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.521, tt:6113.958\n",
      "Ep:188, loss:0.00001, loss_test:0.02637, lr:3.89e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.515, tt:6145.257\n",
      "Ep:189, loss:0.00001, loss_test:0.02681, lr:3.85e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.522, tt:6179.164\n",
      "Ep:190, loss:0.00001, loss_test:0.02642, lr:3.81e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.528, tt:6212.771\n",
      "Ep:191, loss:0.00001, loss_test:0.02633, lr:3.77e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.526, tt:6244.909\n",
      "Ep:192, loss:0.00001, loss_test:0.02690, lr:3.73e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.530, tt:6278.374\n",
      "Ep:193, loss:0.00001, loss_test:0.02637, lr:3.70e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.536, tt:6311.938\n",
      "Ep:194, loss:0.00001, loss_test:0.02630, lr:3.66e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.539, tt:6345.157\n",
      "Ep:195, loss:0.00001, loss_test:0.02654, lr:3.62e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.540, tt:6377.784\n",
      "Ep:196, loss:0.00001, loss_test:0.02629, lr:3.59e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.529, tt:6408.146\n",
      "Ep:197, loss:0.00001, loss_test:0.02631, lr:3.55e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.525, tt:6439.946\n",
      "Ep:198, loss:0.00001, loss_test:0.02639, lr:3.52e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.524, tt:6472.209\n",
      "Ep:199, loss:0.00001, loss_test:0.02623, lr:3.48e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.530, tt:6505.965\n",
      "Ep:200, loss:0.00001, loss_test:0.02639, lr:3.45e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.534, tt:6539.356\n",
      "Ep:201, loss:0.00001, loss_test:0.02619, lr:3.41e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.533, tt:6571.607\n",
      "Ep:202, loss:0.00001, loss_test:0.02620, lr:3.38e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.541, tt:6605.870\n",
      "Ep:203, loss:0.00001, loss_test:0.02633, lr:3.34e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.541, tt:6638.396\n",
      "Ep:204, loss:0.00001, loss_test:0.02607, lr:3.31e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.543, tt:6671.275\n",
      "Ep:205, loss:0.00001, loss_test:0.02617, lr:3.28e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.550, tt:6705.231\n",
      "Ep:206, loss:0.00001, loss_test:0.02638, lr:3.24e-03, fs:0.95327 (r=0.927,p=0.981),  time:32.562, tt:6740.262\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13932, lr:1.00e-02, fs:0.67081 (r=0.982,p=0.509),  time:12.644, tt:12.644\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13696, lr:1.00e-02, fs:0.66250 (r=0.964,p=0.505),  time:15.256, tt:30.512\n",
      "Ep:2, loss:0.00027, loss_test:0.13454, lr:1.00e-02, fs:0.64103 (r=0.909,p=0.495),  time:19.218, tt:57.655\n",
      "Ep:3, loss:0.00026, loss_test:0.13191, lr:1.00e-02, fs:0.62500 (r=0.818,p=0.506),  time:21.992, tt:87.968\n",
      "Ep:4, loss:0.00025, loss_test:0.12842, lr:1.00e-02, fs:0.62774 (r=0.782,p=0.524),  time:24.806, tt:124.032\n",
      "Ep:5, loss:0.00025, loss_test:0.12407, lr:1.00e-02, fs:0.64122 (r=0.764,p=0.553),  time:26.586, tt:159.515\n",
      "Ep:6, loss:0.00024, loss_test:0.11966, lr:1.00e-02, fs:0.66142 (r=0.764,p=0.583),  time:27.975, tt:195.822\n",
      "Ep:7, loss:0.00023, loss_test:0.11611, lr:1.00e-02, fs:0.68800 (r=0.782,p=0.614),  time:28.843, tt:230.742\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11348, lr:1.00e-02, fs:0.67717 (r=0.782,p=0.597),  time:29.659, tt:266.935\n",
      "Ep:9, loss:0.00022, loss_test:0.11192, lr:1.00e-02, fs:0.67717 (r=0.782,p=0.597),  time:30.411, tt:304.106\n",
      "Ep:10, loss:0.00021, loss_test:0.11058, lr:1.00e-02, fs:0.67213 (r=0.745,p=0.612),  time:30.935, tt:340.282\n",
      "Ep:11, loss:0.00021, loss_test:0.10916, lr:1.00e-02, fs:0.68333 (r=0.745,p=0.631),  time:31.219, tt:374.628\n",
      "Ep:12, loss:0.00020, loss_test:0.10744, lr:1.00e-02, fs:0.68908 (r=0.745,p=0.641),  time:31.487, tt:409.327\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10548, lr:1.00e-02, fs:0.68333 (r=0.745,p=0.631),  time:31.881, tt:446.328\n",
      "Ep:14, loss:0.00019, loss_test:0.10340, lr:1.00e-02, fs:0.70085 (r=0.745,p=0.661),  time:32.269, tt:484.031\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10110, lr:1.00e-02, fs:0.72269 (r=0.782,p=0.672),  time:32.535, tt:520.554\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09880, lr:1.00e-02, fs:0.72881 (r=0.782,p=0.683),  time:32.655, tt:555.143\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09705, lr:1.00e-02, fs:0.73333 (r=0.800,p=0.677),  time:32.866, tt:591.582\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09489, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:33.069, tt:628.310\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09289, lr:1.00e-02, fs:0.76033 (r=0.836,p=0.697),  time:33.339, tt:666.771\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09190, lr:1.00e-02, fs:0.77049 (r=0.855,p=0.701),  time:33.527, tt:704.070\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09020, lr:1.00e-02, fs:0.77049 (r=0.855,p=0.701),  time:33.745, tt:742.394\n",
      "Ep:22, loss:0.00015, loss_test:0.08877, lr:1.00e-02, fs:0.77686 (r=0.855,p=0.712),  time:33.857, tt:778.710\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08759, lr:1.00e-02, fs:0.77686 (r=0.855,p=0.712),  time:34.035, tt:816.844\n",
      "Ep:24, loss:0.00015, loss_test:0.08535, lr:1.00e-02, fs:0.78333 (r=0.855,p=0.723),  time:34.131, tt:853.281\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08347, lr:1.00e-02, fs:0.78333 (r=0.855,p=0.723),  time:34.227, tt:889.902\n",
      "Ep:26, loss:0.00014, loss_test:0.08211, lr:1.00e-02, fs:0.78992 (r=0.855,p=0.734),  time:34.315, tt:926.498\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08062, lr:1.00e-02, fs:0.79661 (r=0.855,p=0.746),  time:34.424, tt:963.874\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07889, lr:1.00e-02, fs:0.80672 (r=0.873,p=0.750),  time:34.527, tt:1001.271\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07681, lr:1.00e-02, fs:0.82051 (r=0.873,p=0.774),  time:34.755, tt:1042.663\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07546, lr:1.00e-02, fs:0.83051 (r=0.891,p=0.778),  time:34.820, tt:1079.410\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07448, lr:1.00e-02, fs:0.84483 (r=0.891,p=0.803),  time:34.894, tt:1116.610\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07286, lr:1.00e-02, fs:0.84298 (r=0.927,p=0.773),  time:34.954, tt:1153.471\n",
      "Ep:33, loss:0.00012, loss_test:0.07224, lr:1.00e-02, fs:0.85965 (r=0.891,p=0.831),  time:35.005, tt:1190.166\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.07044, lr:1.00e-02, fs:0.87179 (r=0.927,p=0.823),  time:35.045, tt:1226.571\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.06909, lr:1.00e-02, fs:0.88136 (r=0.945,p=0.825),  time:35.076, tt:1262.749\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.06802, lr:1.00e-02, fs:0.88889 (r=0.945,p=0.839),  time:35.135, tt:1300.008\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.06579, lr:1.00e-02, fs:0.89831 (r=0.964,p=0.841),  time:35.122, tt:1334.617\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.06519, lr:1.00e-02, fs:0.89831 (r=0.964,p=0.841),  time:35.119, tt:1369.642\n",
      "Ep:39, loss:0.00010, loss_test:0.06359, lr:1.00e-02, fs:0.88889 (r=0.945,p=0.839),  time:35.139, tt:1405.541\n",
      "Ep:40, loss:0.00009, loss_test:0.06239, lr:1.00e-02, fs:0.89831 (r=0.964,p=0.841),  time:35.172, tt:1442.072\n",
      "Ep:41, loss:0.00009, loss_test:0.06117, lr:1.00e-02, fs:0.89655 (r=0.945,p=0.852),  time:35.203, tt:1478.529\n",
      "Ep:42, loss:0.00009, loss_test:0.06011, lr:1.00e-02, fs:0.89655 (r=0.945,p=0.852),  time:35.244, tt:1515.491\n",
      "Ep:43, loss:0.00009, loss_test:0.05943, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.299, tt:1553.134\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.05785, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.312, tt:1589.019\n",
      "Ep:45, loss:0.00008, loss_test:0.05578, lr:1.00e-02, fs:0.89655 (r=0.945,p=0.852),  time:35.341, tt:1625.698\n",
      "Ep:46, loss:0.00008, loss_test:0.05589, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.360, tt:1661.934\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.05346, lr:1.00e-02, fs:0.89655 (r=0.945,p=0.852),  time:35.435, tt:1700.868\n",
      "Ep:48, loss:0.00007, loss_test:0.05372, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.503, tt:1739.631\n",
      "Ep:49, loss:0.00007, loss_test:0.05138, lr:1.00e-02, fs:0.89655 (r=0.945,p=0.852),  time:35.495, tt:1774.759\n",
      "Ep:50, loss:0.00007, loss_test:0.05115, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.475, tt:1809.247\n",
      "Ep:51, loss:0.00007, loss_test:0.05074, lr:1.00e-02, fs:0.89655 (r=0.945,p=0.852),  time:35.483, tt:1845.094\n",
      "Ep:52, loss:0.00007, loss_test:0.04971, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.489, tt:1880.901\n",
      "Ep:53, loss:0.00006, loss_test:0.04920, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.493, tt:1916.612\n",
      "Ep:54, loss:0.00006, loss_test:0.04896, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.479, tt:1951.371\n",
      "Ep:55, loss:0.00006, loss_test:0.04695, lr:1.00e-02, fs:0.92035 (r=0.945,p=0.897),  time:35.500, tt:1988.007\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.04772, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.456, tt:2020.976\n",
      "Ep:57, loss:0.00006, loss_test:0.04568, lr:1.00e-02, fs:0.90435 (r=0.945,p=0.867),  time:35.485, tt:2058.124\n",
      "Ep:58, loss:0.00006, loss_test:0.04663, lr:1.00e-02, fs:0.92857 (r=0.945,p=0.912),  time:35.494, tt:2094.175\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00005, loss_test:0.04538, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.495, tt:2129.691\n",
      "Ep:62, loss:0.00005, loss_test:0.04324, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.524, tt:2237.985\n",
      "Ep:63, loss:0.00005, loss_test:0.04382, lr:1.00e-02, fs:0.92035 (r=0.945,p=0.897),  time:35.533, tt:2274.116\n",
      "Ep:64, loss:0.00005, loss_test:0.04277, lr:1.00e-02, fs:0.92035 (r=0.945,p=0.897),  time:35.535, tt:2309.800\n",
      "Ep:65, loss:0.00004, loss_test:0.04315, lr:1.00e-02, fs:0.92035 (r=0.945,p=0.897),  time:35.553, tt:2346.502\n",
      "Ep:66, loss:0.00004, loss_test:0.04181, lr:1.00e-02, fs:0.92857 (r=0.945,p=0.912),  time:35.588, tt:2384.386\n",
      "Ep:67, loss:0.00004, loss_test:0.04246, lr:1.00e-02, fs:0.92035 (r=0.945,p=0.897),  time:35.592, tt:2420.277\n",
      "Ep:68, loss:0.00004, loss_test:0.04438, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.617, tt:2457.572\n",
      "Ep:69, loss:0.00004, loss_test:0.04094, lr:1.00e-02, fs:0.91228 (r=0.945,p=0.881),  time:35.623, tt:2493.603\n",
      "Ep:70, loss:0.00004, loss_test:0.04280, lr:9.90e-03, fs:0.92857 (r=0.945,p=0.912),  time:35.630, tt:2529.703\n",
      "Ep:71, loss:0.00004, loss_test:0.04241, lr:9.80e-03, fs:0.92035 (r=0.945,p=0.897),  time:35.644, tt:2566.370\n",
      "Ep:72, loss:0.00004, loss_test:0.04179, lr:9.70e-03, fs:0.92857 (r=0.945,p=0.912),  time:35.635, tt:2601.385\n",
      "Ep:73, loss:0.00005, loss_test:0.04316, lr:9.61e-03, fs:0.91071 (r=0.927,p=0.895),  time:35.647, tt:2637.881\n",
      "Ep:74, loss:0.00004, loss_test:0.04281, lr:9.51e-03, fs:0.92857 (r=0.945,p=0.912),  time:35.646, tt:2673.474\n",
      "Ep:75, loss:0.00004, loss_test:0.04133, lr:9.41e-03, fs:0.91071 (r=0.927,p=0.895),  time:35.630, tt:2707.866\n",
      "Ep:76, loss:0.00004, loss_test:0.04316, lr:9.32e-03, fs:0.92035 (r=0.945,p=0.897),  time:35.606, tt:2741.700\n",
      "Ep:77, loss:0.00004, loss_test:0.04070, lr:9.23e-03, fs:0.92035 (r=0.945,p=0.897),  time:35.592, tt:2776.154\n",
      "Ep:78, loss:0.00004, loss_test:0.04329, lr:9.14e-03, fs:0.92035 (r=0.945,p=0.897),  time:35.586, tt:2811.282\n",
      "Ep:79, loss:0.00004, loss_test:0.03824, lr:9.04e-03, fs:0.92857 (r=0.945,p=0.912),  time:35.589, tt:2847.097\n",
      "Ep:80, loss:0.00004, loss_test:0.04177, lr:8.95e-03, fs:0.92857 (r=0.945,p=0.912),  time:35.581, tt:2882.087\n",
      "Ep:81, loss:0.00004, loss_test:0.03784, lr:8.86e-03, fs:0.93694 (r=0.945,p=0.929),  time:35.588, tt:2918.231\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00003, loss_test:0.04129, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:35.577, tt:2952.853\n",
      "Ep:83, loss:0.00003, loss_test:0.03743, lr:8.86e-03, fs:0.93694 (r=0.945,p=0.929),  time:35.590, tt:2989.532\n",
      "Ep:84, loss:0.00003, loss_test:0.03903, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.594, tt:3025.464\n",
      "Ep:85, loss:0.00003, loss_test:0.03774, lr:8.86e-03, fs:0.94545 (r=0.945,p=0.945),  time:35.595, tt:3061.152\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00003, loss_test:0.03791, lr:8.86e-03, fs:0.92857 (r=0.945,p=0.912),  time:35.607, tt:3097.779\n",
      "Ep:87, loss:0.00003, loss_test:0.03717, lr:8.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.600, tt:3132.818\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.03677, lr:8.86e-03, fs:0.91892 (r=0.927,p=0.911),  time:35.594, tt:3167.822\n",
      "Ep:89, loss:0.00003, loss_test:0.03737, lr:8.86e-03, fs:0.94545 (r=0.945,p=0.945),  time:35.570, tt:3201.260\n",
      "Ep:90, loss:0.00003, loss_test:0.03620, lr:8.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.583, tt:3238.083\n",
      "Ep:91, loss:0.00003, loss_test:0.03813, lr:8.86e-03, fs:0.93578 (r=0.927,p=0.944),  time:35.594, tt:3274.662\n",
      "Ep:92, loss:0.00003, loss_test:0.03539, lr:8.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.595, tt:3310.333\n",
      "Ep:93, loss:0.00003, loss_test:0.03845, lr:8.86e-03, fs:0.92727 (r=0.927,p=0.927),  time:35.606, tt:3347.004\n",
      "Ep:94, loss:0.00003, loss_test:0.03508, lr:8.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.613, tt:3383.255\n",
      "Ep:95, loss:0.00003, loss_test:0.03553, lr:8.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.614, tt:3418.977\n",
      "Ep:96, loss:0.00002, loss_test:0.03708, lr:8.86e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.655, tt:3458.535\n",
      "Ep:97, loss:0.00002, loss_test:0.03439, lr:8.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.681, tt:3496.783\n",
      "Ep:98, loss:0.00002, loss_test:0.03719, lr:8.86e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.702, tt:3534.449\n",
      "Ep:99, loss:0.00002, loss_test:0.03484, lr:8.78e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.718, tt:3571.828\n",
      "Ep:100, loss:0.00002, loss_test:0.03554, lr:8.69e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.736, tt:3609.289\n",
      "Ep:101, loss:0.00002, loss_test:0.03565, lr:8.60e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.762, tt:3647.692\n",
      "Ep:102, loss:0.00002, loss_test:0.03463, lr:8.51e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.767, tt:3684.011\n",
      "Ep:103, loss:0.00002, loss_test:0.03592, lr:8.43e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.785, tt:3721.634\n",
      "Ep:104, loss:0.00002, loss_test:0.03456, lr:8.35e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.812, tt:3760.209\n",
      "Ep:105, loss:0.00002, loss_test:0.03527, lr:8.26e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.836, tt:3798.588\n",
      "Ep:106, loss:0.00002, loss_test:0.03395, lr:8.18e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.836, tt:3834.497\n",
      "Ep:107, loss:0.00002, loss_test:0.03602, lr:8.10e-03, fs:0.93578 (r=0.927,p=0.944),  time:35.842, tt:3870.907\n",
      "Ep:108, loss:0.00002, loss_test:0.03309, lr:8.02e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.838, tt:3906.326\n",
      "Ep:109, loss:0.00002, loss_test:0.03516, lr:7.94e-03, fs:0.93578 (r=0.927,p=0.944),  time:35.851, tt:3943.656\n",
      "Ep:110, loss:0.00002, loss_test:0.03379, lr:7.86e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.871, tt:3981.719\n",
      "Ep:111, loss:0.00002, loss_test:0.03306, lr:7.78e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.863, tt:4016.682\n",
      "Ep:112, loss:0.00002, loss_test:0.03463, lr:7.70e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.848, tt:4050.845\n",
      "Ep:113, loss:0.00002, loss_test:0.03300, lr:7.62e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.858, tt:4087.788\n",
      "Ep:114, loss:0.00002, loss_test:0.03471, lr:7.55e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.856, tt:4123.431\n",
      "Ep:115, loss:0.00002, loss_test:0.03311, lr:7.47e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.862, tt:4160.013\n",
      "Ep:116, loss:0.00002, loss_test:0.03495, lr:7.40e-03, fs:0.93578 (r=0.927,p=0.944),  time:35.882, tt:4198.160\n",
      "Ep:117, loss:0.00002, loss_test:0.03260, lr:7.32e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.887, tt:4234.687\n",
      "Ep:118, loss:0.00002, loss_test:0.03472, lr:7.25e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.898, tt:4271.893\n",
      "Ep:119, loss:0.00002, loss_test:0.03287, lr:7.18e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.906, tt:4308.748\n",
      "Ep:120, loss:0.00002, loss_test:0.03372, lr:7.11e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.907, tt:4344.697\n",
      "Ep:121, loss:0.00002, loss_test:0.03350, lr:7.03e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.943, tt:4385.026\n",
      "Ep:122, loss:0.00002, loss_test:0.03294, lr:6.96e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.946, tt:4421.373\n",
      "Ep:123, loss:0.00002, loss_test:0.03349, lr:6.89e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.955, tt:4458.432\n",
      "Ep:124, loss:0.00002, loss_test:0.03302, lr:6.83e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.961, tt:4495.139\n",
      "Ep:125, loss:0.00002, loss_test:0.03328, lr:6.76e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.972, tt:4532.490\n",
      "Ep:126, loss:0.00002, loss_test:0.03336, lr:6.69e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.986, tt:4570.181\n",
      "Ep:127, loss:0.00002, loss_test:0.03315, lr:6.62e-03, fs:0.95413 (r=0.945,p=0.963),  time:35.988, tt:4606.526\n",
      "Ep:128, loss:0.00002, loss_test:0.03286, lr:6.56e-03, fs:0.94444 (r=0.927,p=0.962),  time:35.996, tt:4643.422\n",
      "Ep:129, loss:0.00002, loss_test:0.03318, lr:6.49e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.010, tt:4681.297\n",
      "Ep:130, loss:0.00002, loss_test:0.03237, lr:6.43e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.017, tt:4718.208\n",
      "Ep:131, loss:0.00002, loss_test:0.03293, lr:6.36e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.023, tt:4755.007\n",
      "Ep:132, loss:0.00002, loss_test:0.03259, lr:6.30e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.036, tt:4792.737\n",
      "Ep:133, loss:0.00002, loss_test:0.03260, lr:6.24e-03, fs:0.95413 (r=0.945,p=0.963),  time:36.054, tt:4831.238\n",
      "Ep:134, loss:0.00002, loss_test:0.03308, lr:6.17e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.055, tt:4867.361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.03251, lr:6.11e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.072, tt:4905.809\n",
      "Ep:136, loss:0.00001, loss_test:0.03282, lr:6.05e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.082, tt:4943.194\n",
      "Ep:137, loss:0.00001, loss_test:0.03246, lr:5.99e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.079, tt:4978.866\n",
      "Ep:138, loss:0.00001, loss_test:0.03288, lr:5.93e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.075, tt:5014.493\n",
      "Ep:139, loss:0.00001, loss_test:0.03248, lr:5.87e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.082, tt:5051.548\n",
      "Ep:140, loss:0.00001, loss_test:0.03244, lr:5.81e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.103, tt:5090.492\n",
      "Ep:141, loss:0.00001, loss_test:0.03278, lr:5.75e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.111, tt:5127.819\n",
      "Ep:142, loss:0.00001, loss_test:0.03218, lr:5.70e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.127, tt:5166.219\n",
      "Ep:143, loss:0.00001, loss_test:0.03226, lr:5.64e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.140, tt:5204.170\n",
      "Ep:144, loss:0.00001, loss_test:0.03228, lr:5.58e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.148, tt:5241.516\n",
      "Ep:145, loss:0.00001, loss_test:0.03212, lr:5.53e-03, fs:0.95413 (r=0.945,p=0.963),  time:36.149, tt:5277.699\n",
      "Ep:146, loss:0.00001, loss_test:0.03230, lr:5.47e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.144, tt:5313.145\n",
      "Ep:147, loss:0.00001, loss_test:0.03272, lr:5.42e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.153, tt:5350.594\n",
      "Ep:148, loss:0.00001, loss_test:0.03169, lr:5.36e-03, fs:0.95413 (r=0.945,p=0.963),  time:36.157, tt:5387.377\n",
      "Ep:149, loss:0.00001, loss_test:0.03288, lr:5.31e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.149, tt:5422.409\n",
      "Ep:150, loss:0.00001, loss_test:0.03176, lr:5.26e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.138, tt:5456.815\n",
      "Ep:151, loss:0.00001, loss_test:0.03265, lr:5.20e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.145, tt:5493.986\n",
      "Ep:152, loss:0.00001, loss_test:0.03268, lr:5.15e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.157, tt:5532.054\n",
      "Ep:153, loss:0.00001, loss_test:0.03183, lr:5.10e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.178, tt:5571.427\n",
      "Ep:154, loss:0.00001, loss_test:0.03251, lr:5.05e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.180, tt:5607.870\n",
      "Ep:155, loss:0.00001, loss_test:0.03207, lr:5.00e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.185, tt:5644.838\n",
      "Ep:156, loss:0.00001, loss_test:0.03226, lr:4.95e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.192, tt:5682.182\n",
      "Ep:157, loss:0.00001, loss_test:0.03230, lr:4.90e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.201, tt:5719.817\n",
      "Ep:158, loss:0.00001, loss_test:0.03157, lr:4.85e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.234, tt:5761.217\n",
      "Ep:159, loss:0.00001, loss_test:0.03217, lr:4.80e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.244, tt:5799.098\n",
      "Ep:160, loss:0.00001, loss_test:0.03201, lr:4.75e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.245, tt:5835.397\n",
      "Ep:161, loss:0.00001, loss_test:0.03180, lr:4.71e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.260, tt:5874.151\n",
      "Ep:162, loss:0.00001, loss_test:0.03206, lr:4.66e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.266, tt:5911.294\n",
      "Ep:163, loss:0.00001, loss_test:0.03199, lr:4.61e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.266, tt:5947.566\n",
      "Ep:164, loss:0.00001, loss_test:0.03169, lr:4.57e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.274, tt:5985.249\n",
      "Ep:165, loss:0.00001, loss_test:0.03214, lr:4.52e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.280, tt:6022.496\n",
      "Ep:166, loss:0.00001, loss_test:0.03175, lr:4.48e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.277, tt:6058.331\n",
      "Ep:167, loss:0.00001, loss_test:0.03178, lr:4.43e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.275, tt:6094.235\n",
      "Ep:168, loss:0.00001, loss_test:0.03174, lr:4.39e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.272, tt:6129.981\n",
      "Ep:169, loss:0.00001, loss_test:0.03197, lr:4.34e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.272, tt:6166.269\n",
      "Ep:170, loss:0.00001, loss_test:0.03167, lr:4.30e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.269, tt:6201.969\n",
      "Ep:171, loss:0.00001, loss_test:0.03166, lr:4.26e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.262, tt:6236.981\n",
      "Ep:172, loss:0.00001, loss_test:0.03190, lr:4.21e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.265, tt:6273.763\n",
      "Ep:173, loss:0.00001, loss_test:0.03153, lr:4.17e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.272, tt:6311.366\n",
      "Ep:174, loss:0.00001, loss_test:0.03166, lr:4.13e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.278, tt:6348.637\n",
      "Ep:175, loss:0.00001, loss_test:0.03192, lr:4.09e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.275, tt:6384.458\n",
      "Ep:176, loss:0.00001, loss_test:0.03151, lr:4.05e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.270, tt:6419.749\n",
      "Ep:177, loss:0.00001, loss_test:0.03189, lr:4.01e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.279, tt:6457.635\n",
      "Ep:178, loss:0.00001, loss_test:0.03173, lr:3.97e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.283, tt:6494.581\n",
      "Ep:179, loss:0.00001, loss_test:0.03150, lr:3.93e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.295, tt:6533.048\n",
      "Ep:180, loss:0.00001, loss_test:0.03169, lr:3.89e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.295, tt:6569.360\n",
      "Ep:181, loss:0.00001, loss_test:0.03162, lr:3.85e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.300, tt:6606.612\n",
      "Ep:182, loss:0.00001, loss_test:0.03140, lr:3.81e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.300, tt:6642.834\n",
      "Ep:183, loss:0.00001, loss_test:0.03169, lr:3.77e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.309, tt:6680.817\n",
      "Ep:184, loss:0.00001, loss_test:0.03172, lr:3.73e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.313, tt:6717.989\n",
      "Ep:185, loss:0.00001, loss_test:0.03122, lr:3.70e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.321, tt:6755.736\n",
      "Ep:186, loss:0.00001, loss_test:0.03188, lr:3.66e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.351, tt:6797.584\n",
      "Ep:187, loss:0.00001, loss_test:0.03138, lr:3.62e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.359, tt:6835.568\n",
      "Ep:188, loss:0.00001, loss_test:0.03147, lr:3.59e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.371, tt:6874.079\n",
      "Ep:189, loss:0.00001, loss_test:0.03159, lr:3.55e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.374, tt:6911.118\n",
      "Ep:190, loss:0.00001, loss_test:0.03171, lr:3.52e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.382, tt:6948.881\n",
      "Ep:191, loss:0.00001, loss_test:0.03150, lr:3.48e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.383, tt:6985.616\n",
      "Ep:192, loss:0.00001, loss_test:0.03135, lr:3.45e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.395, tt:7024.270\n",
      "Ep:193, loss:0.00001, loss_test:0.03199, lr:3.41e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.402, tt:7061.934\n",
      "Ep:194, loss:0.00001, loss_test:0.03123, lr:3.38e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.413, tt:7100.526\n",
      "Ep:195, loss:0.00001, loss_test:0.03182, lr:3.34e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.417, tt:7137.745\n",
      "Ep:196, loss:0.00001, loss_test:0.03126, lr:3.31e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.430, tt:7176.752\n",
      "Ep:197, loss:0.00001, loss_test:0.03137, lr:3.28e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.433, tt:7213.772\n",
      "Ep:198, loss:0.00001, loss_test:0.03177, lr:3.24e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.446, tt:7252.767\n",
      "Ep:199, loss:0.00001, loss_test:0.03137, lr:3.21e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.446, tt:7289.286\n",
      "Ep:200, loss:0.00001, loss_test:0.03162, lr:3.18e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.450, tt:7326.466\n",
      "Ep:201, loss:0.00001, loss_test:0.03159, lr:3.15e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.462, tt:7365.389\n",
      "Ep:202, loss:0.00001, loss_test:0.03124, lr:3.12e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.465, tt:7402.383\n",
      "Ep:203, loss:0.00001, loss_test:0.03169, lr:3.09e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.475, tt:7440.819\n",
      "Ep:204, loss:0.00001, loss_test:0.03160, lr:3.05e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.496, tt:7481.690\n",
      "Ep:205, loss:0.00001, loss_test:0.03124, lr:3.02e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.502, tt:7519.381\n",
      "Ep:206, loss:0.00001, loss_test:0.03145, lr:2.99e-03, fs:0.94444 (r=0.927,p=0.962),  time:36.514, tt:7558.393\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02384, lr:6.00e-02, fs:0.63158 (r=0.764,p=0.538),  time:27.326, tt:27.326\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02569, lr:6.00e-02, fs:0.67901 (r=1.000,p=0.514),  time:30.192, tt:60.384\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02737, lr:6.00e-02, fs:0.67485 (r=1.000,p=0.509),  time:30.626, tt:91.878\n",
      "Ep:3, loss:0.00005, loss_test:0.02725, lr:6.00e-02, fs:0.67901 (r=1.000,p=0.514),  time:31.797, tt:127.190\n",
      "Ep:4, loss:0.00005, loss_test:0.02693, lr:6.00e-02, fs:0.65409 (r=0.945,p=0.500),  time:32.272, tt:161.359\n",
      "Ep:5, loss:0.00005, loss_test:0.02655, lr:6.00e-02, fs:0.62745 (r=0.873,p=0.490),  time:32.623, tt:195.735\n",
      "Ep:6, loss:0.00005, loss_test:0.02609, lr:6.00e-02, fs:0.62252 (r=0.855,p=0.490),  time:32.579, tt:228.056\n",
      "Ep:7, loss:0.00005, loss_test:0.02576, lr:6.00e-02, fs:0.62069 (r=0.818,p=0.500),  time:32.338, tt:258.708\n",
      "Ep:8, loss:0.00005, loss_test:0.02533, lr:6.00e-02, fs:0.61972 (r=0.800,p=0.506),  time:32.359, tt:291.233\n",
      "Ep:9, loss:0.00005, loss_test:0.02492, lr:6.00e-02, fs:0.62411 (r=0.800,p=0.512),  time:32.574, tt:325.736\n",
      "Ep:10, loss:0.00005, loss_test:0.02451, lr:6.00e-02, fs:0.62937 (r=0.818,p=0.511),  time:32.831, tt:361.145\n",
      "Ep:11, loss:0.00005, loss_test:0.02398, lr:6.00e-02, fs:0.62500 (r=0.818,p=0.506),  time:32.849, tt:394.186\n",
      "Ep:12, loss:0.00005, loss_test:0.02335, lr:6.00e-02, fs:0.62500 (r=0.818,p=0.506),  time:32.969, tt:428.595\n",
      "Ep:13, loss:0.00005, loss_test:0.02262, lr:5.94e-02, fs:0.63946 (r=0.855,p=0.511),  time:33.035, tt:462.497\n",
      "Ep:14, loss:0.00004, loss_test:0.02192, lr:5.88e-02, fs:0.64384 (r=0.855,p=0.516),  time:33.130, tt:496.943\n",
      "Ep:15, loss:0.00004, loss_test:0.02133, lr:5.82e-02, fs:0.64828 (r=0.855,p=0.522),  time:33.228, tt:531.655\n",
      "Ep:16, loss:0.00004, loss_test:0.02085, lr:5.76e-02, fs:0.65278 (r=0.855,p=0.528),  time:33.387, tt:567.575\n",
      "Ep:17, loss:0.00004, loss_test:0.02034, lr:5.71e-02, fs:0.67143 (r=0.855,p=0.553),  time:33.525, tt:603.456\n",
      "Ep:18, loss:0.00004, loss_test:0.01990, lr:5.65e-02, fs:0.68116 (r=0.855,p=0.566),  time:33.605, tt:638.500\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01948, lr:5.65e-02, fs:0.68116 (r=0.855,p=0.566),  time:33.621, tt:672.423\n",
      "Ep:20, loss:0.00004, loss_test:0.01919, lr:5.65e-02, fs:0.67626 (r=0.855,p=0.560),  time:33.617, tt:705.964\n",
      "Ep:21, loss:0.00004, loss_test:0.01891, lr:5.65e-02, fs:0.67626 (r=0.855,p=0.560),  time:33.590, tt:738.970\n",
      "Ep:22, loss:0.00004, loss_test:0.01862, lr:5.65e-02, fs:0.69065 (r=0.873,p=0.571),  time:33.685, tt:774.763\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01833, lr:5.65e-02, fs:0.69565 (r=0.873,p=0.578),  time:33.816, tt:811.585\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01811, lr:5.65e-02, fs:0.68613 (r=0.855,p=0.573),  time:33.850, tt:846.245\n",
      "Ep:25, loss:0.00004, loss_test:0.01793, lr:5.65e-02, fs:0.70588 (r=0.873,p=0.593),  time:33.818, tt:879.278\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01768, lr:5.65e-02, fs:0.71942 (r=0.909,p=0.595),  time:33.841, tt:913.694\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01746, lr:5.65e-02, fs:0.73759 (r=0.945,p=0.605),  time:33.902, tt:949.249\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01727, lr:5.65e-02, fs:0.73759 (r=0.945,p=0.605),  time:33.912, tt:983.444\n",
      "Ep:29, loss:0.00003, loss_test:0.01708, lr:5.65e-02, fs:0.74820 (r=0.945,p=0.619),  time:33.975, tt:1019.253\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01679, lr:5.65e-02, fs:0.73913 (r=0.927,p=0.614),  time:34.001, tt:1054.026\n",
      "Ep:31, loss:0.00003, loss_test:0.01653, lr:5.65e-02, fs:0.73381 (r=0.927,p=0.607),  time:33.987, tt:1087.572\n",
      "Ep:32, loss:0.00003, loss_test:0.01631, lr:5.65e-02, fs:0.73913 (r=0.927,p=0.614),  time:33.997, tt:1121.891\n",
      "Ep:33, loss:0.00003, loss_test:0.01599, lr:5.65e-02, fs:0.73913 (r=0.927,p=0.614),  time:34.019, tt:1156.630\n",
      "Ep:34, loss:0.00003, loss_test:0.01566, lr:5.65e-02, fs:0.74820 (r=0.945,p=0.619),  time:34.076, tt:1192.671\n",
      "Ep:35, loss:0.00003, loss_test:0.01527, lr:5.65e-02, fs:0.76259 (r=0.964,p=0.631),  time:34.108, tt:1227.882\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01505, lr:5.65e-02, fs:0.76471 (r=0.945,p=0.642),  time:34.122, tt:1262.526\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01480, lr:5.65e-02, fs:0.77037 (r=0.945,p=0.650),  time:34.112, tt:1296.241\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01431, lr:5.65e-02, fs:0.78195 (r=0.945,p=0.667),  time:34.142, tt:1331.547\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01405, lr:5.65e-02, fs:0.79389 (r=0.945,p=0.684),  time:34.148, tt:1365.913\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01372, lr:5.65e-02, fs:0.80000 (r=0.945,p=0.693),  time:34.178, tt:1401.285\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01323, lr:5.65e-02, fs:0.81890 (r=0.945,p=0.722),  time:34.191, tt:1436.042\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01304, lr:5.65e-02, fs:0.81250 (r=0.945,p=0.712),  time:34.213, tt:1471.140\n",
      "Ep:43, loss:0.00002, loss_test:0.01278, lr:5.65e-02, fs:0.82812 (r=0.964,p=0.726),  time:34.226, tt:1505.947\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01266, lr:5.65e-02, fs:0.84127 (r=0.964,p=0.746),  time:34.229, tt:1540.292\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01233, lr:5.65e-02, fs:0.85484 (r=0.964,p=0.768),  time:34.262, tt:1576.057\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01220, lr:5.65e-02, fs:0.85484 (r=0.964,p=0.768),  time:34.290, tt:1611.638\n",
      "Ep:47, loss:0.00002, loss_test:0.01202, lr:5.65e-02, fs:0.86885 (r=0.964,p=0.791),  time:34.294, tt:1646.135\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01182, lr:5.65e-02, fs:0.88333 (r=0.964,p=0.815),  time:34.304, tt:1680.880\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01182, lr:5.65e-02, fs:0.89076 (r=0.964,p=0.828),  time:34.316, tt:1715.789\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01199, lr:5.65e-02, fs:0.88333 (r=0.964,p=0.815),  time:34.324, tt:1750.503\n",
      "Ep:51, loss:0.00002, loss_test:0.01169, lr:5.65e-02, fs:0.88136 (r=0.945,p=0.825),  time:34.334, tt:1785.370\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m#naive way of testing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mth_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mthreshold_acc\u001b[0;34m(model, g, features, mask, loss, print_details, threshold_dist, threshold_cos, path)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;31m#mask = np.array([x for x in mask if x[2]==1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m#dist() | max(0, m - dist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03049, lr:6.00e-02, fs:0.58065 (r=0.636,p=0.534),  time:10.864, tt:10.864\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:11.879, tt:23.759\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02686, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:13.786, tt:41.357\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02722, lr:6.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:15.977, tt:63.908\n",
      "Ep:4, loss:0.00005, loss_test:0.02708, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:18.441, tt:92.204\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02661, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:20.398, tt:122.385\n",
      "Ep:6, loss:0.00005, loss_test:0.02606, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:21.756, tt:152.293\n",
      "Ep:7, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:22.767, tt:182.134\n",
      "Ep:8, loss:0.00005, loss_test:0.02542, lr:6.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:23.653, tt:212.874\n",
      "Ep:9, loss:0.00005, loss_test:0.02460, lr:6.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:24.436, tt:244.362\n",
      "Ep:10, loss:0.00005, loss_test:0.02360, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:24.964, tt:274.602\n",
      "Ep:11, loss:0.00005, loss_test:0.02268, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:25.563, tt:306.753\n",
      "Ep:12, loss:0.00004, loss_test:0.02173, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:26.060, tt:338.784\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02087, lr:6.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:26.457, tt:370.395\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02024, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:26.887, tt:403.312\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01974, lr:6.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:27.290, tt:436.648\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01931, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:27.557, tt:468.476\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01896, lr:6.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:27.837, tt:501.074\n",
      "Ep:18, loss:0.00004, loss_test:0.01866, lr:6.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:28.084, tt:533.597\n",
      "Ep:19, loss:0.00004, loss_test:0.01834, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:28.188, tt:563.760\n",
      "Ep:20, loss:0.00004, loss_test:0.01813, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:28.396, tt:596.312\n",
      "Ep:21, loss:0.00004, loss_test:0.01800, lr:6.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:28.484, tt:626.643\n",
      "Ep:22, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:28.584, tt:657.439\n",
      "Ep:23, loss:0.00003, loss_test:0.01800, lr:6.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:28.720, tt:689.290\n",
      "Ep:24, loss:0.00003, loss_test:0.01807, lr:6.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:28.827, tt:720.681\n",
      "Ep:25, loss:0.00003, loss_test:0.01804, lr:6.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:28.829, tt:749.560\n",
      "Ep:26, loss:0.00003, loss_test:0.01786, lr:6.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:28.958, tt:781.869\n",
      "Ep:27, loss:0.00003, loss_test:0.01771, lr:6.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:29.012, tt:812.328\n",
      "Ep:28, loss:0.00003, loss_test:0.01761, lr:5.94e-02, fs:0.70588 (r=0.848,p=0.604),  time:29.150, tt:845.353\n",
      "Ep:29, loss:0.00003, loss_test:0.01752, lr:5.88e-02, fs:0.71667 (r=0.869,p=0.610),  time:29.233, tt:876.998\n",
      "Ep:30, loss:0.00003, loss_test:0.01738, lr:5.82e-02, fs:0.70588 (r=0.848,p=0.604),  time:29.297, tt:908.195\n",
      "Ep:31, loss:0.00003, loss_test:0.01718, lr:5.76e-02, fs:0.71245 (r=0.838,p=0.619),  time:29.332, tt:938.627\n",
      "Ep:32, loss:0.00003, loss_test:0.01700, lr:5.71e-02, fs:0.71552 (r=0.838,p=0.624),  time:29.350, tt:968.544\n",
      "Ep:33, loss:0.00003, loss_test:0.01677, lr:5.65e-02, fs:0.71366 (r=0.818,p=0.633),  time:29.455, tt:1001.486\n",
      "Ep:34, loss:0.00003, loss_test:0.01652, lr:5.59e-02, fs:0.70852 (r=0.798,p=0.637),  time:29.494, tt:1032.275\n",
      "Ep:35, loss:0.00003, loss_test:0.01620, lr:5.54e-02, fs:0.72321 (r=0.818,p=0.648),  time:29.561, tt:1064.195\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01608, lr:5.54e-02, fs:0.71889 (r=0.788,p=0.661),  time:29.588, tt:1094.768\n",
      "Ep:37, loss:0.00002, loss_test:0.01594, lr:5.54e-02, fs:0.72558 (r=0.788,p=0.672),  time:29.645, tt:1126.512\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01555, lr:5.54e-02, fs:0.72558 (r=0.788,p=0.672),  time:29.679, tt:1157.488\n",
      "Ep:39, loss:0.00002, loss_test:0.01533, lr:5.54e-02, fs:0.73239 (r=0.788,p=0.684),  time:29.701, tt:1188.043\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01521, lr:5.54e-02, fs:0.74286 (r=0.788,p=0.703),  time:29.717, tt:1218.378\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01502, lr:5.54e-02, fs:0.75349 (r=0.818,p=0.698),  time:29.729, tt:1248.622\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01493, lr:5.54e-02, fs:0.75728 (r=0.788,p=0.729),  time:29.802, tt:1281.505\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01496, lr:5.54e-02, fs:0.75238 (r=0.798,p=0.712),  time:29.830, tt:1312.501\n",
      "Ep:44, loss:0.00002, loss_test:0.01492, lr:5.54e-02, fs:0.75862 (r=0.778,p=0.740),  time:29.855, tt:1343.494\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01478, lr:5.54e-02, fs:0.77670 (r=0.808,p=0.748),  time:29.880, tt:1374.498\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01438, lr:5.54e-02, fs:0.76238 (r=0.778,p=0.748),  time:29.913, tt:1405.891\n",
      "Ep:47, loss:0.00002, loss_test:0.01451, lr:5.54e-02, fs:0.77073 (r=0.798,p=0.745),  time:29.946, tt:1437.386\n",
      "Ep:48, loss:0.00002, loss_test:0.01466, lr:5.54e-02, fs:0.77778 (r=0.778,p=0.778),  time:29.939, tt:1467.032\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01412, lr:5.54e-02, fs:0.75962 (r=0.798,p=0.725),  time:29.986, tt:1499.311\n",
      "Ep:50, loss:0.00002, loss_test:0.01481, lr:5.54e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.025, tt:1531.268\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01416, lr:5.54e-02, fs:0.78218 (r=0.798,p=0.767),  time:30.064, tt:1563.320\n",
      "Ep:52, loss:0.00001, loss_test:0.01446, lr:5.54e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.097, tt:1595.116\n",
      "Ep:53, loss:0.00001, loss_test:0.01426, lr:5.54e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.143, tt:1627.746\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01364, lr:5.54e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.149, tt:1658.186\n",
      "Ep:55, loss:0.00001, loss_test:0.01405, lr:5.54e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.145, tt:1688.100\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01393, lr:5.54e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.164, tt:1719.340\n",
      "Ep:57, loss:0.00001, loss_test:0.01392, lr:5.54e-02, fs:0.81675 (r=0.788,p=0.848),  time:30.189, tt:1750.956\n",
      "Ep:58, loss:0.00001, loss_test:0.01442, lr:5.54e-02, fs:0.80829 (r=0.788,p=0.830),  time:30.223, tt:1783.157\n",
      "Ep:59, loss:0.00001, loss_test:0.01318, lr:5.54e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.240, tt:1814.425\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01473, lr:5.54e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.253, tt:1845.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01388, lr:5.54e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.271, tt:1876.772\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01349, lr:5.54e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.312, tt:1909.628\n",
      "Ep:63, loss:0.00001, loss_test:0.01414, lr:5.54e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.344, tt:1942.019\n",
      "Ep:64, loss:0.00001, loss_test:0.01484, lr:5.54e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.363, tt:1973.574\n",
      "Ep:65, loss:0.00001, loss_test:0.01348, lr:5.54e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.381, tt:2005.151\n",
      "Ep:66, loss:0.00001, loss_test:0.01405, lr:5.54e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.407, tt:2037.295\n",
      "Ep:67, loss:0.00001, loss_test:0.01438, lr:5.54e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.419, tt:2068.470\n",
      "Ep:68, loss:0.00001, loss_test:0.01364, lr:5.54e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.421, tt:2099.066\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01425, lr:5.54e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.443, tt:2130.994\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01436, lr:5.54e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.464, tt:2162.968\n",
      "Ep:71, loss:0.00001, loss_test:0.01425, lr:5.54e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.467, tt:2193.598\n",
      "Ep:72, loss:0.00001, loss_test:0.01420, lr:5.54e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.501, tt:2226.553\n",
      "Ep:73, loss:0.00001, loss_test:0.01350, lr:5.54e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.519, tt:2258.440\n",
      "Ep:74, loss:0.00001, loss_test:0.01678, lr:5.54e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.514, tt:2288.517\n",
      "Ep:75, loss:0.00001, loss_test:0.01473, lr:5.54e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.522, tt:2319.641\n",
      "Ep:76, loss:0.00001, loss_test:0.01405, lr:5.54e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.538, tt:2351.419\n",
      "Ep:77, loss:0.00001, loss_test:0.01458, lr:5.54e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.563, tt:2383.887\n",
      "Ep:78, loss:0.00001, loss_test:0.01510, lr:5.54e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.577, tt:2415.566\n",
      "Ep:79, loss:0.00001, loss_test:0.01455, lr:5.54e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.585, tt:2446.836\n",
      "Ep:80, loss:0.00001, loss_test:0.01483, lr:5.54e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.594, tt:2478.110\n",
      "Ep:81, loss:0.00001, loss_test:0.01487, lr:5.48e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.594, tt:2508.687\n",
      "Ep:82, loss:0.00001, loss_test:0.01538, lr:5.43e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.574, tt:2537.626\n",
      "Ep:83, loss:0.00001, loss_test:0.01617, lr:5.37e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.578, tt:2568.564\n",
      "Ep:84, loss:0.00001, loss_test:0.01746, lr:5.32e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.579, tt:2599.239\n",
      "Ep:85, loss:0.00001, loss_test:0.01437, lr:5.27e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.590, tt:2630.783\n",
      "Ep:86, loss:0.00001, loss_test:0.01518, lr:5.21e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.584, tt:2660.848\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01568, lr:5.21e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.608, tt:2693.519\n",
      "Ep:88, loss:0.00000, loss_test:0.01618, lr:5.21e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.610, tt:2724.295\n",
      "Ep:89, loss:0.00000, loss_test:0.01503, lr:5.21e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.634, tt:2757.027\n",
      "Ep:90, loss:0.00000, loss_test:0.01537, lr:5.21e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.639, tt:2788.146\n",
      "Ep:91, loss:0.00000, loss_test:0.01675, lr:5.21e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.655, tt:2820.247\n",
      "Ep:92, loss:0.00001, loss_test:0.01659, lr:5.21e-02, fs:0.76503 (r=0.707,p=0.833),  time:30.664, tt:2851.735\n",
      "Ep:93, loss:0.00001, loss_test:0.01488, lr:5.21e-02, fs:0.85714 (r=0.818,p=0.900),  time:30.673, tt:2883.287\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01495, lr:5.21e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.686, tt:2915.193\n",
      "Ep:95, loss:0.00000, loss_test:0.01675, lr:5.21e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.689, tt:2946.173\n",
      "Ep:96, loss:0.00000, loss_test:0.01642, lr:5.21e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.690, tt:2976.933\n",
      "Ep:97, loss:0.00000, loss_test:0.01557, lr:5.21e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.699, tt:3008.550\n",
      "Ep:98, loss:0.00000, loss_test:0.01571, lr:5.21e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.710, tt:3040.292\n",
      "Ep:99, loss:0.00000, loss_test:0.01784, lr:5.21e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.721, tt:3072.060\n",
      "Ep:100, loss:0.00000, loss_test:0.01446, lr:5.21e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.729, tt:3103.586\n",
      "Ep:101, loss:0.00000, loss_test:0.01697, lr:5.21e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.732, tt:3134.699\n",
      "Ep:102, loss:0.00000, loss_test:0.01652, lr:5.21e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.733, tt:3165.457\n",
      "Ep:103, loss:0.00000, loss_test:0.01721, lr:5.21e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.735, tt:3196.453\n",
      "Ep:104, loss:0.00000, loss_test:0.01653, lr:5.21e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.748, tt:3228.590\n",
      "Ep:105, loss:0.00000, loss_test:0.01752, lr:5.16e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.754, tt:3259.930\n",
      "Ep:106, loss:0.00000, loss_test:0.01644, lr:5.11e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.756, tt:3290.936\n",
      "Ep:107, loss:0.00000, loss_test:0.01681, lr:5.06e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.762, tt:3322.274\n",
      "Ep:108, loss:0.00000, loss_test:0.01754, lr:5.01e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.769, tt:3353.849\n",
      "Ep:109, loss:0.00000, loss_test:0.01741, lr:4.96e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.773, tt:3384.999\n",
      "Ep:110, loss:0.00000, loss_test:0.01743, lr:4.91e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.781, tt:3416.643\n",
      "Ep:111, loss:0.00000, loss_test:0.01845, lr:4.86e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.774, tt:3446.725\n",
      "Ep:112, loss:0.00000, loss_test:0.01699, lr:4.81e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.778, tt:3477.905\n",
      "Ep:113, loss:0.00000, loss_test:0.01817, lr:4.76e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.788, tt:3509.783\n",
      "Ep:114, loss:0.00000, loss_test:0.01791, lr:4.71e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.785, tt:3540.290\n",
      "Ep:115, loss:0.00000, loss_test:0.01948, lr:4.67e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.782, tt:3570.719\n",
      "Ep:116, loss:0.00000, loss_test:0.01827, lr:4.62e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.783, tt:3601.659\n",
      "Ep:117, loss:0.00000, loss_test:0.01889, lr:4.57e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.796, tt:3633.935\n",
      "Ep:118, loss:0.00000, loss_test:0.01905, lr:4.53e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.805, tt:3665.782\n",
      "Ep:119, loss:0.00000, loss_test:0.01885, lr:4.48e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.780, tt:3693.626\n",
      "Ep:120, loss:0.00000, loss_test:0.01897, lr:4.44e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.775, tt:3723.724\n",
      "Ep:121, loss:0.00000, loss_test:0.01927, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.774, tt:3754.387\n",
      "Ep:122, loss:0.00000, loss_test:0.01984, lr:4.35e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.774, tt:3785.146\n",
      "Ep:123, loss:0.00000, loss_test:0.01937, lr:4.31e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.779, tt:3816.657\n",
      "Ep:124, loss:0.00000, loss_test:0.01964, lr:4.26e-02, fs:0.79545 (r=0.707,p=0.909),  time:30.782, tt:3847.728\n",
      "Ep:125, loss:0.00000, loss_test:0.02056, lr:4.22e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.777, tt:3877.938\n",
      "Ep:126, loss:0.00000, loss_test:0.01921, lr:4.18e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.784, tt:3909.602\n",
      "Ep:127, loss:0.00000, loss_test:0.01993, lr:4.14e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.794, tt:3941.605\n",
      "Ep:128, loss:0.00000, loss_test:0.02036, lr:4.10e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.797, tt:3972.826\n",
      "Ep:129, loss:0.00000, loss_test:0.02048, lr:4.05e-02, fs:0.79545 (r=0.707,p=0.909),  time:30.796, tt:4003.499\n",
      "Ep:130, loss:0.00000, loss_test:0.01984, lr:4.01e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.801, tt:4034.958\n",
      "Ep:131, loss:0.00000, loss_test:0.02063, lr:3.97e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.806, tt:4066.408\n",
      "Ep:132, loss:0.00000, loss_test:0.02110, lr:3.93e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.819, tt:4098.912\n",
      "Ep:133, loss:0.00000, loss_test:0.02046, lr:3.89e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.823, tt:4130.334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.02068, lr:3.86e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.827, tt:4161.610\n",
      "Ep:135, loss:0.00000, loss_test:0.02123, lr:3.82e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.821, tt:4191.589\n",
      "Ep:136, loss:0.00000, loss_test:0.02122, lr:3.78e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.831, tt:4223.835\n",
      "Ep:137, loss:0.00000, loss_test:0.02067, lr:3.74e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.831, tt:4254.669\n",
      "Ep:138, loss:0.00000, loss_test:0.02129, lr:3.70e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.830, tt:4285.389\n",
      "Ep:139, loss:0.00000, loss_test:0.02161, lr:3.67e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.828, tt:4315.889\n",
      "Ep:140, loss:0.00000, loss_test:0.02093, lr:3.63e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.829, tt:4346.927\n",
      "Ep:141, loss:0.00000, loss_test:0.02143, lr:3.59e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.835, tt:4378.500\n",
      "Ep:142, loss:0.00000, loss_test:0.02182, lr:3.56e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.838, tt:4409.838\n",
      "Ep:143, loss:0.00000, loss_test:0.02082, lr:3.52e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.847, tt:4442.034\n",
      "Ep:144, loss:0.00000, loss_test:0.02206, lr:3.49e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.852, tt:4473.513\n",
      "Ep:145, loss:0.00000, loss_test:0.02119, lr:3.45e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.847, tt:4503.664\n",
      "Ep:146, loss:0.00000, loss_test:0.02191, lr:3.42e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.834, tt:4532.608\n",
      "Ep:147, loss:0.00000, loss_test:0.02159, lr:3.38e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.826, tt:4562.306\n",
      "Ep:148, loss:0.00000, loss_test:0.02169, lr:3.35e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.830, tt:4593.708\n",
      "Ep:149, loss:0.00000, loss_test:0.02218, lr:3.32e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.841, tt:4626.174\n",
      "Ep:150, loss:0.00000, loss_test:0.02168, lr:3.28e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.854, tt:4658.960\n",
      "Ep:151, loss:0.00000, loss_test:0.02231, lr:3.25e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.864, tt:4691.372\n",
      "Ep:152, loss:0.00000, loss_test:0.02190, lr:3.22e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.867, tt:4722.607\n",
      "Ep:153, loss:0.00000, loss_test:0.02230, lr:3.19e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.878, tt:4755.203\n",
      "Ep:154, loss:0.00000, loss_test:0.02175, lr:3.15e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.898, tt:4789.117\n",
      "Ep:155, loss:0.00000, loss_test:0.02272, lr:3.12e-02, fs:0.76023 (r=0.657,p=0.903),  time:30.902, tt:4820.789\n",
      "Ep:156, loss:0.00000, loss_test:0.02179, lr:3.09e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.909, tt:4852.665\n",
      "Ep:157, loss:0.00000, loss_test:0.02226, lr:3.06e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.910, tt:4883.725\n",
      "Ep:158, loss:0.00000, loss_test:0.02241, lr:3.03e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.911, tt:4914.896\n",
      "Ep:159, loss:0.00000, loss_test:0.02221, lr:3.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.911, tt:4945.711\n",
      "Ep:160, loss:0.00000, loss_test:0.02269, lr:2.97e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.917, tt:4977.591\n",
      "Ep:161, loss:0.00000, loss_test:0.02242, lr:2.94e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.917, tt:5008.523\n",
      "Ep:162, loss:0.00000, loss_test:0.02265, lr:2.91e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.911, tt:5038.432\n",
      "Ep:163, loss:0.00000, loss_test:0.02266, lr:2.88e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.913, tt:5069.810\n",
      "Ep:164, loss:0.00000, loss_test:0.02252, lr:2.85e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.915, tt:5100.964\n",
      "Ep:165, loss:0.00000, loss_test:0.02305, lr:2.82e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.922, tt:5133.104\n",
      "Ep:166, loss:0.00000, loss_test:0.02276, lr:2.80e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.929, tt:5165.062\n",
      "Ep:167, loss:0.00000, loss_test:0.02300, lr:2.77e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.934, tt:5196.837\n",
      "Ep:168, loss:0.00000, loss_test:0.02287, lr:2.74e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.942, tt:5229.118\n",
      "Ep:169, loss:0.00000, loss_test:0.02277, lr:2.71e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.941, tt:5259.986\n",
      "Ep:170, loss:0.00000, loss_test:0.02340, lr:2.69e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.931, tt:5289.175\n",
      "Ep:171, loss:0.00000, loss_test:0.02278, lr:2.66e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.928, tt:5319.585\n",
      "Ep:172, loss:0.00000, loss_test:0.02342, lr:2.63e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.941, tt:5352.809\n",
      "Ep:173, loss:0.00000, loss_test:0.02291, lr:2.61e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.943, tt:5384.159\n",
      "Ep:174, loss:0.00000, loss_test:0.02316, lr:2.58e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.954, tt:5416.974\n",
      "Ep:175, loss:0.00000, loss_test:0.02323, lr:2.55e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.956, tt:5448.175\n",
      "Ep:176, loss:0.00000, loss_test:0.02314, lr:2.53e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.945, tt:5477.261\n",
      "Ep:177, loss:0.00000, loss_test:0.02344, lr:2.50e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.930, tt:5505.484\n",
      "Ep:178, loss:0.00000, loss_test:0.02297, lr:2.48e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.921, tt:5534.852\n",
      "Ep:179, loss:0.00000, loss_test:0.02358, lr:2.45e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.916, tt:5564.881\n",
      "Ep:180, loss:0.00000, loss_test:0.02305, lr:2.43e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.909, tt:5594.580\n",
      "Ep:181, loss:0.00000, loss_test:0.02369, lr:2.40e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.907, tt:5625.069\n",
      "Ep:182, loss:0.00000, loss_test:0.02337, lr:2.38e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.892, tt:5653.174\n",
      "Ep:183, loss:0.00000, loss_test:0.02341, lr:2.36e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.882, tt:5682.205\n",
      "Ep:184, loss:0.00000, loss_test:0.02350, lr:2.33e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.878, tt:5712.489\n",
      "Ep:185, loss:0.00000, loss_test:0.02334, lr:2.31e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.867, tt:5741.303\n",
      "Ep:186, loss:0.00000, loss_test:0.02369, lr:2.29e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.865, tt:5771.743\n",
      "Ep:187, loss:0.00000, loss_test:0.02331, lr:2.26e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.862, tt:5802.091\n",
      "Ep:188, loss:0.00000, loss_test:0.02368, lr:2.24e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.866, tt:5833.717\n",
      "Ep:189, loss:0.00000, loss_test:0.02356, lr:2.22e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.864, tt:5864.217\n",
      "Ep:190, loss:0.00000, loss_test:0.02360, lr:2.20e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.867, tt:5895.629\n",
      "Ep:191, loss:0.00000, loss_test:0.02374, lr:2.17e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.871, tt:5927.143\n",
      "Ep:192, loss:0.00000, loss_test:0.02363, lr:2.15e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.872, tt:5958.251\n",
      "Ep:193, loss:0.00000, loss_test:0.02377, lr:2.13e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.878, tt:5990.275\n",
      "Ep:194, loss:0.00000, loss_test:0.02352, lr:2.11e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.878, tt:6021.291\n",
      "Ep:195, loss:0.00000, loss_test:0.02380, lr:2.09e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.881, tt:6052.728\n",
      "Ep:196, loss:0.00000, loss_test:0.02375, lr:2.07e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.882, tt:6083.734\n",
      "Ep:197, loss:0.00000, loss_test:0.02383, lr:2.05e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.880, tt:6114.253\n",
      "Ep:198, loss:0.00000, loss_test:0.02390, lr:2.03e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.889, tt:6146.926\n",
      "Ep:199, loss:0.00000, loss_test:0.02373, lr:2.01e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.899, tt:6179.735\n",
      "Ep:200, loss:0.00000, loss_test:0.02406, lr:1.99e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.911, tt:6213.199\n",
      "Ep:201, loss:0.00000, loss_test:0.02364, lr:1.97e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.915, tt:6244.804\n",
      "Ep:202, loss:0.00000, loss_test:0.02416, lr:1.95e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.914, tt:6275.632\n",
      "Ep:203, loss:0.00000, loss_test:0.02381, lr:1.93e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.919, tt:6307.424\n",
      "Ep:204, loss:0.00000, loss_test:0.02414, lr:1.91e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.921, tt:6338.736\n",
      "Ep:205, loss:0.00000, loss_test:0.02399, lr:1.89e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.922, tt:6370.013\n",
      "Ep:206, loss:0.00000, loss_test:0.02402, lr:1.87e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.925, tt:6401.453\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13836, lr:1.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:27.849, tt:27.849\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13745, lr:1.00e-02, fs:0.62879 (r=0.838,p=0.503),  time:29.207, tt:58.414\n",
      "Ep:2, loss:0.00026, loss_test:0.13679, lr:1.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:26.024, tt:78.071\n",
      "Ep:3, loss:0.00026, loss_test:0.13671, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:26.424, tt:105.694\n",
      "Ep:4, loss:0.00026, loss_test:0.13636, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:27.353, tt:136.766\n",
      "Ep:5, loss:0.00025, loss_test:0.13540, lr:1.00e-02, fs:0.63158 (r=0.788,p=0.527),  time:27.784, tt:166.703\n",
      "Ep:6, loss:0.00025, loss_test:0.13407, lr:1.00e-02, fs:0.63415 (r=0.788,p=0.531),  time:28.425, tt:198.976\n",
      "Ep:7, loss:0.00025, loss_test:0.13311, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:28.719, tt:229.756\n",
      "Ep:8, loss:0.00025, loss_test:0.13198, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:28.962, tt:260.659\n",
      "Ep:9, loss:0.00025, loss_test:0.13079, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:29.311, tt:293.109\n",
      "Ep:10, loss:0.00024, loss_test:0.12957, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:29.528, tt:324.807\n",
      "Ep:11, loss:0.00024, loss_test:0.12779, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:29.698, tt:356.376\n",
      "Ep:12, loss:0.00024, loss_test:0.12592, lr:9.90e-03, fs:0.65272 (r=0.788,p=0.557),  time:29.939, tt:389.205\n",
      "Ep:13, loss:0.00024, loss_test:0.12423, lr:9.80e-03, fs:0.65833 (r=0.798,p=0.560),  time:30.113, tt:421.583\n",
      "Ep:14, loss:0.00023, loss_test:0.12253, lr:9.70e-03, fs:0.65272 (r=0.788,p=0.557),  time:30.197, tt:452.954\n",
      "Ep:15, loss:0.00023, loss_test:0.12017, lr:9.61e-03, fs:0.64979 (r=0.778,p=0.558),  time:30.315, tt:485.038\n",
      "Ep:16, loss:0.00022, loss_test:0.11696, lr:9.51e-03, fs:0.65812 (r=0.778,p=0.570),  time:30.476, tt:518.089\n",
      "Ep:17, loss:0.00022, loss_test:0.11498, lr:9.41e-03, fs:0.67782 (r=0.818,p=0.579),  time:30.651, tt:551.723\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.11303, lr:9.41e-03, fs:0.68670 (r=0.808,p=0.597),  time:30.694, tt:583.180\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.10907, lr:9.41e-03, fs:0.69604 (r=0.798,p=0.617),  time:30.718, tt:614.358\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10653, lr:9.41e-03, fs:0.70742 (r=0.818,p=0.623),  time:30.753, tt:645.808\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.10445, lr:9.41e-03, fs:0.70485 (r=0.808,p=0.625),  time:30.819, tt:678.016\n",
      "Ep:22, loss:0.00019, loss_test:0.10175, lr:9.41e-03, fs:0.70642 (r=0.778,p=0.647),  time:30.916, tt:711.066\n",
      "Ep:23, loss:0.00019, loss_test:0.10015, lr:9.41e-03, fs:0.71560 (r=0.788,p=0.655),  time:30.969, tt:743.265\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.09797, lr:9.41e-03, fs:0.72811 (r=0.798,p=0.669),  time:30.976, tt:774.389\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.09574, lr:9.41e-03, fs:0.75000 (r=0.818,p=0.692),  time:31.000, tt:805.996\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.09485, lr:9.41e-03, fs:0.75349 (r=0.818,p=0.698),  time:30.974, tt:836.304\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.09421, lr:9.41e-03, fs:0.76777 (r=0.818,p=0.723),  time:30.985, tt:867.577\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.09395, lr:9.41e-03, fs:0.76190 (r=0.808,p=0.721),  time:31.000, tt:898.991\n",
      "Ep:29, loss:0.00015, loss_test:0.09315, lr:9.41e-03, fs:0.74286 (r=0.788,p=0.703),  time:30.988, tt:929.627\n",
      "Ep:30, loss:0.00015, loss_test:0.09277, lr:9.41e-03, fs:0.73684 (r=0.778,p=0.700),  time:30.979, tt:960.345\n",
      "Ep:31, loss:0.00014, loss_test:0.09143, lr:9.41e-03, fs:0.73632 (r=0.747,p=0.725),  time:31.017, tt:992.533\n",
      "Ep:32, loss:0.00014, loss_test:0.09211, lr:9.41e-03, fs:0.71066 (r=0.707,p=0.714),  time:30.978, tt:1022.275\n",
      "Ep:33, loss:0.00013, loss_test:0.09090, lr:9.41e-03, fs:0.72081 (r=0.717,p=0.724),  time:30.995, tt:1053.840\n",
      "Ep:34, loss:0.00012, loss_test:0.08990, lr:9.41e-03, fs:0.72165 (r=0.707,p=0.737),  time:30.984, tt:1084.456\n",
      "Ep:35, loss:0.00012, loss_test:0.08984, lr:9.41e-03, fs:0.70213 (r=0.667,p=0.742),  time:30.999, tt:1115.961\n",
      "Ep:36, loss:0.00011, loss_test:0.08878, lr:9.41e-03, fs:0.71277 (r=0.677,p=0.753),  time:31.070, tt:1149.600\n",
      "Ep:37, loss:0.00011, loss_test:0.09086, lr:9.41e-03, fs:0.69945 (r=0.646,p=0.762),  time:31.107, tt:1182.068\n",
      "Ep:38, loss:0.00010, loss_test:0.08826, lr:9.41e-03, fs:0.74396 (r=0.778,p=0.713),  time:31.128, tt:1214.004\n",
      "Ep:39, loss:0.00011, loss_test:0.08926, lr:9.32e-03, fs:0.70000 (r=0.636,p=0.778),  time:31.125, tt:1244.995\n",
      "Ep:40, loss:0.00009, loss_test:0.08796, lr:9.23e-03, fs:0.67416 (r=0.606,p=0.759),  time:31.120, tt:1275.916\n",
      "Ep:41, loss:0.00009, loss_test:0.08325, lr:9.14e-03, fs:0.72826 (r=0.677,p=0.788),  time:31.092, tt:1305.855\n",
      "Ep:42, loss:0.00010, loss_test:0.08839, lr:9.04e-03, fs:0.66286 (r=0.586,p=0.763),  time:31.051, tt:1335.206\n",
      "Ep:43, loss:0.00009, loss_test:0.08137, lr:8.95e-03, fs:0.79070 (r=0.859,p=0.733),  time:31.046, tt:1366.034\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.08924, lr:8.95e-03, fs:0.69945 (r=0.646,p=0.762),  time:31.073, tt:1398.289\n",
      "Ep:45, loss:0.00008, loss_test:0.07556, lr:8.95e-03, fs:0.80203 (r=0.798,p=0.806),  time:31.084, tt:1429.858\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.08260, lr:8.95e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.064, tt:1460.008\n",
      "Ep:47, loss:0.00007, loss_test:0.08061, lr:8.95e-03, fs:0.74860 (r=0.677,p=0.838),  time:31.079, tt:1491.781\n",
      "Ep:48, loss:0.00007, loss_test:0.08031, lr:8.95e-03, fs:0.70115 (r=0.616,p=0.813),  time:31.060, tt:1521.928\n",
      "Ep:49, loss:0.00007, loss_test:0.08437, lr:8.95e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.098, tt:1554.898\n",
      "Ep:50, loss:0.00006, loss_test:0.08292, lr:8.95e-03, fs:0.77660 (r=0.737,p=0.820),  time:31.089, tt:1585.526\n",
      "Ep:51, loss:0.00006, loss_test:0.08279, lr:8.95e-03, fs:0.74419 (r=0.646,p=0.877),  time:31.078, tt:1616.046\n",
      "Ep:52, loss:0.00005, loss_test:0.08414, lr:8.95e-03, fs:0.71264 (r=0.626,p=0.827),  time:31.106, tt:1648.621\n",
      "Ep:53, loss:0.00005, loss_test:0.07808, lr:8.95e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.131, tt:1681.078\n",
      "Ep:54, loss:0.00005, loss_test:0.08355, lr:8.95e-03, fs:0.76404 (r=0.687,p=0.861),  time:31.114, tt:1711.297\n",
      "Ep:55, loss:0.00005, loss_test:0.07883, lr:8.95e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.147, tt:1744.237\n",
      "Ep:56, loss:0.00004, loss_test:0.08028, lr:8.95e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.155, tt:1775.813\n",
      "Ep:57, loss:0.00004, loss_test:0.08357, lr:8.86e-03, fs:0.72289 (r=0.606,p=0.896),  time:31.188, tt:1808.878\n",
      "Ep:58, loss:0.00004, loss_test:0.08410, lr:8.78e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.217, tt:1841.832\n",
      "Ep:59, loss:0.00004, loss_test:0.07959, lr:8.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:31.211, tt:1872.656\n",
      "Ep:60, loss:0.00004, loss_test:0.07202, lr:8.60e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.177, tt:1901.770\n",
      "Ep:61, loss:0.00003, loss_test:0.08367, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.187, tt:1933.608\n",
      "Ep:62, loss:0.00003, loss_test:0.07632, lr:8.43e-03, fs:0.72619 (r=0.616,p=0.884),  time:31.188, tt:1964.865\n",
      "Ep:63, loss:0.00003, loss_test:0.07852, lr:8.35e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.179, tt:1995.445\n",
      "Ep:64, loss:0.00003, loss_test:0.08284, lr:8.26e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.170, tt:2026.039\n",
      "Ep:65, loss:0.00003, loss_test:0.07535, lr:8.18e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.140, tt:2055.255\n",
      "Ep:66, loss:0.00003, loss_test:0.07167, lr:8.10e-03, fs:0.75581 (r=0.657,p=0.890),  time:31.151, tt:2087.102\n",
      "Ep:67, loss:0.00003, loss_test:0.07460, lr:8.02e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.149, tt:2118.135\n",
      "Ep:68, loss:0.00003, loss_test:0.08127, lr:7.94e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.155, tt:2149.667\n",
      "Ep:69, loss:0.00002, loss_test:0.07711, lr:7.86e-03, fs:0.71166 (r=0.586,p=0.906),  time:31.144, tt:2180.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00002, loss_test:0.07505, lr:7.78e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.141, tt:2210.997\n",
      "Ep:71, loss:0.00002, loss_test:0.07772, lr:7.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:31.150, tt:2242.810\n",
      "Ep:72, loss:0.00002, loss_test:0.08039, lr:7.62e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.122, tt:2271.890\n",
      "Ep:73, loss:0.00002, loss_test:0.07012, lr:7.55e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.118, tt:2302.731\n",
      "Ep:74, loss:0.00002, loss_test:0.08471, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.116, tt:2333.676\n",
      "Ep:75, loss:0.00002, loss_test:0.07825, lr:7.40e-03, fs:0.72393 (r=0.596,p=0.922),  time:31.130, tt:2365.854\n",
      "Ep:76, loss:0.00002, loss_test:0.07318, lr:7.32e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.147, tt:2398.335\n",
      "Ep:77, loss:0.00002, loss_test:0.08222, lr:7.25e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.148, tt:2429.535\n",
      "Ep:78, loss:0.00002, loss_test:0.07251, lr:7.18e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.142, tt:2460.182\n",
      "Ep:79, loss:0.00002, loss_test:0.07621, lr:7.11e-03, fs:0.72050 (r=0.586,p=0.935),  time:31.122, tt:2489.758\n",
      "Ep:80, loss:0.00002, loss_test:0.07637, lr:7.03e-03, fs:0.75904 (r=0.636,p=0.940),  time:31.085, tt:2517.852\n",
      "Ep:81, loss:0.00002, loss_test:0.07131, lr:6.96e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.084, tt:2548.882\n",
      "Ep:82, loss:0.00002, loss_test:0.08034, lr:6.89e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.077, tt:2579.376\n",
      "Ep:83, loss:0.00002, loss_test:0.07709, lr:6.83e-03, fs:0.71605 (r=0.586,p=0.921),  time:31.073, tt:2610.146\n",
      "Ep:84, loss:0.00002, loss_test:0.07932, lr:6.76e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.061, tt:2640.151\n",
      "Ep:85, loss:0.00001, loss_test:0.07792, lr:6.69e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.066, tt:2671.639\n",
      "Ep:86, loss:0.00001, loss_test:0.07724, lr:6.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.058, tt:2702.063\n",
      "Ep:87, loss:0.00001, loss_test:0.07473, lr:6.56e-03, fs:0.75904 (r=0.636,p=0.940),  time:31.068, tt:2734.024\n",
      "Ep:88, loss:0.00001, loss_test:0.07771, lr:6.49e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.082, tt:2766.321\n",
      "Ep:89, loss:0.00001, loss_test:0.08259, lr:6.43e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.088, tt:2797.953\n",
      "Ep:90, loss:0.00001, loss_test:0.07372, lr:6.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.127, tt:2832.556\n",
      "Ep:91, loss:0.00001, loss_test:0.07958, lr:6.30e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.161, tt:2866.767\n",
      "Ep:92, loss:0.00001, loss_test:0.07984, lr:6.24e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.214, tt:2902.923\n",
      "Ep:93, loss:0.00001, loss_test:0.08028, lr:6.17e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.259, tt:2938.339\n",
      "Ep:94, loss:0.00001, loss_test:0.07868, lr:6.11e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.302, tt:2973.735\n",
      "Ep:95, loss:0.00001, loss_test:0.07948, lr:6.05e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.334, tt:3008.025\n",
      "Ep:96, loss:0.00001, loss_test:0.08038, lr:5.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.378, tt:3043.637\n",
      "Ep:97, loss:0.00001, loss_test:0.07547, lr:5.93e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.450, tt:3082.089\n",
      "Ep:98, loss:0.00001, loss_test:0.08239, lr:5.87e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.489, tt:3117.366\n",
      "Ep:99, loss:0.00001, loss_test:0.07906, lr:5.81e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.528, tt:3152.780\n",
      "Ep:100, loss:0.00001, loss_test:0.08103, lr:5.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.578, tt:3189.340\n",
      "Ep:101, loss:0.00001, loss_test:0.08184, lr:5.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:31.609, tt:3224.118\n",
      "Ep:102, loss:0.00001, loss_test:0.07918, lr:5.64e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.666, tt:3261.608\n",
      "Ep:103, loss:0.00001, loss_test:0.07687, lr:5.58e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.698, tt:3296.597\n",
      "Ep:104, loss:0.00001, loss_test:0.08387, lr:5.53e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.746, tt:3333.307\n",
      "Ep:105, loss:0.00001, loss_test:0.07920, lr:5.47e-03, fs:0.72050 (r=0.586,p=0.935),  time:31.790, tt:3369.712\n",
      "Ep:106, loss:0.00001, loss_test:0.08279, lr:5.42e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.806, tt:3403.296\n",
      "Ep:107, loss:0.00001, loss_test:0.07762, lr:5.36e-03, fs:0.72840 (r=0.596,p=0.937),  time:31.850, tt:3439.788\n",
      "Ep:108, loss:0.00001, loss_test:0.08496, lr:5.31e-03, fs:0.72050 (r=0.586,p=0.935),  time:31.890, tt:3476.040\n",
      "Ep:109, loss:0.00001, loss_test:0.07857, lr:5.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.922, tt:3511.468\n",
      "Ep:110, loss:0.00001, loss_test:0.08382, lr:5.20e-03, fs:0.72050 (r=0.586,p=0.935),  time:31.959, tt:3547.441\n",
      "Ep:111, loss:0.00001, loss_test:0.08021, lr:5.15e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.012, tt:3585.327\n",
      "Ep:112, loss:0.00001, loss_test:0.08456, lr:5.10e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.053, tt:3622.003\n",
      "Ep:113, loss:0.00001, loss_test:0.07859, lr:5.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.076, tt:3656.688\n",
      "Ep:114, loss:0.00001, loss_test:0.08497, lr:5.00e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.111, tt:3692.817\n",
      "Ep:115, loss:0.00001, loss_test:0.07979, lr:4.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.155, tt:3729.978\n",
      "Ep:116, loss:0.00001, loss_test:0.08430, lr:4.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:32.206, tt:3768.099\n",
      "Ep:117, loss:0.00001, loss_test:0.08168, lr:4.85e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.231, tt:3803.273\n",
      "Ep:118, loss:0.00001, loss_test:0.08484, lr:4.80e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.260, tt:3838.905\n",
      "Ep:119, loss:0.00001, loss_test:0.08306, lr:4.75e-03, fs:0.72050 (r=0.586,p=0.935),  time:32.295, tt:3875.365\n",
      "Ep:120, loss:0.00001, loss_test:0.08738, lr:4.71e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.322, tt:3910.994\n",
      "Ep:121, loss:0.00001, loss_test:0.07981, lr:4.66e-03, fs:0.72050 (r=0.586,p=0.935),  time:32.346, tt:3946.226\n",
      "Ep:122, loss:0.00001, loss_test:0.08807, lr:4.61e-03, fs:0.74074 (r=0.606,p=0.952),  time:32.378, tt:3982.450\n",
      "Ep:123, loss:0.00001, loss_test:0.08271, lr:4.57e-03, fs:0.72050 (r=0.586,p=0.935),  time:32.402, tt:4017.798\n",
      "Ep:124, loss:0.00001, loss_test:0.08703, lr:4.52e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.429, tt:4053.583\n",
      "Ep:125, loss:0.00001, loss_test:0.08319, lr:4.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.456, tt:4089.499\n",
      "Ep:126, loss:0.00001, loss_test:0.08433, lr:4.43e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.485, tt:4125.603\n",
      "Ep:127, loss:0.00001, loss_test:0.08466, lr:4.39e-03, fs:0.74074 (r=0.606,p=0.952),  time:32.503, tt:4160.328\n",
      "Ep:128, loss:0.00001, loss_test:0.08293, lr:4.34e-03, fs:0.72840 (r=0.596,p=0.937),  time:32.530, tt:4196.339\n",
      "Ep:129, loss:0.00001, loss_test:0.08735, lr:4.30e-03, fs:0.74074 (r=0.606,p=0.952),  time:32.557, tt:4232.356\n",
      "Ep:130, loss:0.00001, loss_test:0.08268, lr:4.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:32.582, tt:4268.202\n",
      "Ep:131, loss:0.00001, loss_test:0.08720, lr:4.21e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.602, tt:4303.398\n",
      "Ep:132, loss:0.00001, loss_test:0.08416, lr:4.17e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.615, tt:4337.750\n",
      "Ep:133, loss:0.00001, loss_test:0.08803, lr:4.13e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.637, tt:4373.423\n",
      "Ep:134, loss:0.00001, loss_test:0.08679, lr:4.09e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.655, tt:4408.397\n",
      "Ep:135, loss:0.00001, loss_test:0.08524, lr:4.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.682, tt:4444.807\n",
      "Ep:136, loss:0.00001, loss_test:0.08605, lr:4.01e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.703, tt:4480.247\n",
      "Ep:137, loss:0.00001, loss_test:0.08671, lr:3.97e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.708, tt:4513.643\n",
      "Ep:138, loss:0.00001, loss_test:0.08504, lr:3.93e-03, fs:0.72050 (r=0.586,p=0.935),  time:32.717, tt:4547.703\n",
      "Ep:139, loss:0.00001, loss_test:0.08501, lr:3.89e-03, fs:0.72840 (r=0.596,p=0.937),  time:32.732, tt:4582.532\n",
      "Ep:140, loss:0.00001, loss_test:0.08568, lr:3.85e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.750, tt:4617.720\n",
      "Ep:141, loss:0.00001, loss_test:0.08545, lr:3.81e-03, fs:0.74074 (r=0.606,p=0.952),  time:32.765, tt:4652.653\n",
      "Ep:142, loss:0.00001, loss_test:0.08536, lr:3.77e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.775, tt:4686.822\n",
      "Ep:143, loss:0.00001, loss_test:0.08860, lr:3.73e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.794, tt:4722.385\n",
      "Ep:144, loss:0.00001, loss_test:0.08730, lr:3.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.811, tt:4757.537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.08642, lr:3.66e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.819, tt:4791.566\n",
      "Ep:146, loss:0.00001, loss_test:0.08562, lr:3.62e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.826, tt:4825.394\n",
      "Ep:147, loss:0.00001, loss_test:0.08490, lr:3.59e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.835, tt:4859.566\n",
      "Ep:148, loss:0.00001, loss_test:0.08634, lr:3.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.849, tt:4894.472\n",
      "Ep:149, loss:0.00001, loss_test:0.08585, lr:3.52e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.866, tt:4929.841\n",
      "Ep:150, loss:0.00001, loss_test:0.08611, lr:3.48e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.876, tt:4964.312\n",
      "Ep:151, loss:0.00001, loss_test:0.08766, lr:3.45e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.892, tt:4999.539\n",
      "Ep:152, loss:0.00000, loss_test:0.08540, lr:3.41e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.897, tt:5033.288\n",
      "Ep:153, loss:0.00000, loss_test:0.08591, lr:3.38e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.919, tt:5069.559\n",
      "Ep:154, loss:0.00000, loss_test:0.08538, lr:3.34e-03, fs:0.73292 (r=0.596,p=0.952),  time:32.932, tt:5104.472\n",
      "Ep:155, loss:0.00000, loss_test:0.08500, lr:3.31e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.942, tt:5138.900\n",
      "Ep:156, loss:0.00000, loss_test:0.08696, lr:3.28e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.962, tt:5174.957\n",
      "Ep:157, loss:0.00000, loss_test:0.08338, lr:3.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.962, tt:5207.981\n",
      "Ep:158, loss:0.00000, loss_test:0.08763, lr:3.21e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.970, tt:5242.242\n",
      "Ep:159, loss:0.00000, loss_test:0.08515, lr:3.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.979, tt:5276.596\n",
      "Ep:160, loss:0.00000, loss_test:0.08563, lr:3.15e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.988, tt:5311.142\n",
      "Ep:161, loss:0.00000, loss_test:0.08709, lr:3.12e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.994, tt:5345.081\n",
      "Ep:162, loss:0.00000, loss_test:0.08420, lr:3.09e-03, fs:0.72500 (r=0.586,p=0.951),  time:32.999, tt:5378.862\n",
      "Ep:163, loss:0.00000, loss_test:0.08707, lr:3.05e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.004, tt:5412.586\n",
      "Ep:164, loss:0.00000, loss_test:0.08561, lr:3.02e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.008, tt:5446.322\n",
      "Ep:165, loss:0.00000, loss_test:0.08461, lr:2.99e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.008, tt:5479.297\n",
      "Ep:166, loss:0.00000, loss_test:0.08613, lr:2.96e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.015, tt:5513.520\n",
      "Ep:167, loss:0.00000, loss_test:0.08612, lr:2.93e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.020, tt:5547.356\n",
      "Ep:168, loss:0.00000, loss_test:0.08733, lr:2.90e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.037, tt:5583.176\n",
      "Ep:169, loss:0.00000, loss_test:0.08382, lr:2.88e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.041, tt:5616.939\n",
      "Ep:170, loss:0.00000, loss_test:0.08748, lr:2.85e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.047, tt:5650.985\n",
      "Ep:171, loss:0.00000, loss_test:0.08535, lr:2.82e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.052, tt:5684.942\n",
      "Ep:172, loss:0.00000, loss_test:0.08565, lr:2.79e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.058, tt:5718.962\n",
      "Ep:173, loss:0.00000, loss_test:0.08740, lr:2.76e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.071, tt:5754.384\n",
      "Ep:174, loss:0.00000, loss_test:0.08435, lr:2.73e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.086, tt:5789.991\n",
      "Ep:175, loss:0.00000, loss_test:0.08654, lr:2.71e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.090, tt:5823.816\n",
      "Ep:176, loss:0.00000, loss_test:0.08578, lr:2.68e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.099, tt:5858.532\n",
      "Ep:177, loss:0.00000, loss_test:0.08498, lr:2.65e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.109, tt:5893.373\n",
      "Ep:178, loss:0.00000, loss_test:0.08599, lr:2.63e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.135, tt:5931.204\n",
      "Ep:179, loss:0.00000, loss_test:0.08545, lr:2.60e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.141, tt:5965.352\n",
      "Ep:180, loss:0.00000, loss_test:0.08566, lr:2.57e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.140, tt:5998.352\n",
      "Ep:181, loss:0.00000, loss_test:0.08626, lr:2.55e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.137, tt:6031.005\n",
      "Ep:182, loss:0.00000, loss_test:0.08497, lr:2.52e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.141, tt:6064.786\n",
      "Ep:183, loss:0.00000, loss_test:0.08532, lr:2.50e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.152, tt:6100.002\n",
      "Ep:184, loss:0.00000, loss_test:0.08501, lr:2.47e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.162, tt:6135.030\n",
      "Ep:185, loss:0.00000, loss_test:0.08583, lr:2.45e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.159, tt:6167.598\n",
      "Ep:186, loss:0.00000, loss_test:0.08594, lr:2.42e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.166, tt:6202.052\n",
      "Ep:187, loss:0.00000, loss_test:0.08492, lr:2.40e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.176, tt:6237.060\n",
      "Ep:188, loss:0.00000, loss_test:0.08614, lr:2.38e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.182, tt:6271.456\n",
      "Ep:189, loss:0.00000, loss_test:0.08565, lr:2.35e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.190, tt:6306.187\n",
      "Ep:190, loss:0.00000, loss_test:0.08582, lr:2.33e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.200, tt:6341.126\n",
      "Ep:191, loss:0.00000, loss_test:0.08589, lr:2.31e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.210, tt:6376.400\n",
      "Ep:192, loss:0.00000, loss_test:0.08449, lr:2.28e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.217, tt:6410.943\n",
      "Ep:193, loss:0.00000, loss_test:0.08606, lr:2.26e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.223, tt:6445.183\n",
      "Ep:194, loss:0.00000, loss_test:0.08580, lr:2.24e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.227, tt:6479.302\n",
      "Ep:195, loss:0.00000, loss_test:0.08456, lr:2.21e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.229, tt:6512.806\n",
      "Ep:196, loss:0.00000, loss_test:0.08613, lr:2.19e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.236, tt:6547.494\n",
      "Ep:197, loss:0.00000, loss_test:0.08542, lr:2.17e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.257, tt:6584.824\n",
      "Ep:198, loss:0.00000, loss_test:0.08469, lr:2.15e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.262, tt:6619.062\n",
      "Ep:199, loss:0.00000, loss_test:0.08573, lr:2.13e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.273, tt:6654.546\n",
      "Ep:200, loss:0.00000, loss_test:0.08466, lr:2.11e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.272, tt:6687.643\n",
      "Ep:201, loss:0.00000, loss_test:0.08610, lr:2.08e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.270, tt:6720.579\n",
      "Ep:202, loss:0.00000, loss_test:0.08647, lr:2.06e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.269, tt:6753.610\n",
      "Ep:203, loss:0.00000, loss_test:0.08379, lr:2.04e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.268, tt:6786.604\n",
      "Ep:204, loss:0.00000, loss_test:0.08622, lr:2.02e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.273, tt:6820.969\n",
      "Ep:205, loss:0.00000, loss_test:0.08653, lr:2.00e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.278, tt:6855.309\n",
      "Ep:206, loss:0.00000, loss_test:0.08405, lr:1.98e-03, fs:0.72500 (r=0.586,p=0.951),  time:33.293, tt:6891.629\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03093, lr:6.00e-02, fs:0.60444 (r=0.687,p=0.540),  time:27.571, tt:27.571\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02557, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:26.591, tt:53.181\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02653, lr:6.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:25.797, tt:77.390\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02661, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:26.733, tt:106.932\n",
      "Ep:4, loss:0.00005, loss_test:0.02715, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:27.753, tt:138.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00005, loss_test:0.02775, lr:6.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:28.538, tt:171.227\n",
      "Ep:6, loss:0.00005, loss_test:0.02778, lr:6.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:29.603, tt:207.220\n",
      "Ep:7, loss:0.00005, loss_test:0.02733, lr:6.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:30.273, tt:242.187\n",
      "Ep:8, loss:0.00005, loss_test:0.02674, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:30.609, tt:275.484\n",
      "Ep:9, loss:0.00005, loss_test:0.02610, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:31.053, tt:310.531\n",
      "Ep:10, loss:0.00005, loss_test:0.02544, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:31.420, tt:345.617\n",
      "Ep:11, loss:0.00004, loss_test:0.02485, lr:6.00e-02, fs:0.62357 (r=0.828,p=0.500),  time:31.717, tt:380.609\n",
      "Ep:12, loss:0.00004, loss_test:0.02423, lr:6.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:31.912, tt:414.854\n",
      "Ep:13, loss:0.00004, loss_test:0.02359, lr:6.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:32.155, tt:450.166\n",
      "Ep:14, loss:0.00004, loss_test:0.02299, lr:5.94e-02, fs:0.64341 (r=0.838,p=0.522),  time:32.368, tt:485.514\n",
      "Ep:15, loss:0.00004, loss_test:0.02247, lr:5.88e-02, fs:0.63566 (r=0.828,p=0.516),  time:32.616, tt:521.850\n",
      "Ep:16, loss:0.00004, loss_test:0.02196, lr:5.82e-02, fs:0.64615 (r=0.848,p=0.522),  time:32.652, tt:555.083\n",
      "Ep:17, loss:0.00004, loss_test:0.02152, lr:5.76e-02, fs:0.64865 (r=0.848,p=0.525),  time:32.771, tt:589.884\n",
      "Ep:18, loss:0.00004, loss_test:0.02109, lr:5.71e-02, fs:0.64368 (r=0.848,p=0.519),  time:32.799, tt:623.173\n",
      "Ep:19, loss:0.00004, loss_test:0.02077, lr:5.65e-02, fs:0.64368 (r=0.848,p=0.519),  time:32.923, tt:658.463\n",
      "Ep:20, loss:0.00004, loss_test:0.02040, lr:5.59e-02, fs:0.65134 (r=0.859,p=0.525),  time:32.937, tt:691.667\n",
      "Ep:21, loss:0.00004, loss_test:0.01996, lr:5.54e-02, fs:0.66412 (r=0.879,p=0.534),  time:33.024, tt:726.525\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01963, lr:5.54e-02, fs:0.67717 (r=0.869,p=0.555),  time:33.138, tt:762.168\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01924, lr:5.54e-02, fs:0.68775 (r=0.879,p=0.565),  time:33.199, tt:796.785\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01886, lr:5.54e-02, fs:0.69323 (r=0.879,p=0.572),  time:33.254, tt:831.349\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01858, lr:5.54e-02, fs:0.69880 (r=0.879,p=0.580),  time:33.313, tt:866.126\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01830, lr:5.54e-02, fs:0.70635 (r=0.899,p=0.582),  time:33.387, tt:901.439\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01799, lr:5.54e-02, fs:0.70356 (r=0.899,p=0.578),  time:33.432, tt:936.108\n",
      "Ep:28, loss:0.00003, loss_test:0.01785, lr:5.54e-02, fs:0.71713 (r=0.909,p=0.592),  time:33.475, tt:970.764\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01754, lr:5.54e-02, fs:0.72289 (r=0.909,p=0.600),  time:33.529, tt:1005.884\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01728, lr:5.54e-02, fs:0.72874 (r=0.909,p=0.608),  time:33.569, tt:1040.650\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01707, lr:5.54e-02, fs:0.73387 (r=0.919,p=0.611),  time:33.637, tt:1076.377\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01690, lr:5.54e-02, fs:0.73251 (r=0.899,p=0.618),  time:33.719, tt:1112.723\n",
      "Ep:33, loss:0.00003, loss_test:0.01646, lr:5.54e-02, fs:0.75000 (r=0.909,p=0.638),  time:33.810, tt:1149.556\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01630, lr:5.54e-02, fs:0.75000 (r=0.909,p=0.638),  time:33.868, tt:1185.388\n",
      "Ep:35, loss:0.00003, loss_test:0.01602, lr:5.54e-02, fs:0.75630 (r=0.909,p=0.647),  time:33.921, tt:1221.157\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01570, lr:5.54e-02, fs:0.76596 (r=0.909,p=0.662),  time:33.973, tt:1256.998\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01573, lr:5.54e-02, fs:0.75983 (r=0.879,p=0.669),  time:34.018, tt:1292.677\n",
      "Ep:38, loss:0.00002, loss_test:0.01538, lr:5.54e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.074, tt:1328.905\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01509, lr:5.54e-02, fs:0.77922 (r=0.909,p=0.682),  time:34.099, tt:1363.954\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01555, lr:5.54e-02, fs:0.76316 (r=0.879,p=0.674),  time:34.108, tt:1398.443\n",
      "Ep:41, loss:0.00002, loss_test:0.01460, lr:5.54e-02, fs:0.80176 (r=0.919,p=0.711),  time:34.121, tt:1433.062\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01494, lr:5.54e-02, fs:0.78070 (r=0.899,p=0.690),  time:34.127, tt:1467.458\n",
      "Ep:43, loss:0.00002, loss_test:0.01443, lr:5.54e-02, fs:0.79646 (r=0.909,p=0.709),  time:34.145, tt:1502.401\n",
      "Ep:44, loss:0.00002, loss_test:0.01430, lr:5.54e-02, fs:0.80357 (r=0.909,p=0.720),  time:34.146, tt:1536.576\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01409, lr:5.54e-02, fs:0.81279 (r=0.899,p=0.742),  time:34.164, tt:1571.535\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01378, lr:5.54e-02, fs:0.82192 (r=0.909,p=0.750),  time:34.189, tt:1606.875\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01385, lr:5.54e-02, fs:0.80734 (r=0.889,p=0.739),  time:34.204, tt:1641.781\n",
      "Ep:48, loss:0.00002, loss_test:0.01395, lr:5.54e-02, fs:0.80734 (r=0.889,p=0.739),  time:34.221, tt:1676.808\n",
      "Ep:49, loss:0.00002, loss_test:0.01375, lr:5.54e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.220, tt:1711.001\n",
      "Ep:50, loss:0.00002, loss_test:0.01424, lr:5.54e-02, fs:0.79621 (r=0.848,p=0.750),  time:34.230, tt:1745.714\n",
      "Ep:51, loss:0.00002, loss_test:0.01363, lr:5.54e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.257, tt:1781.369\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01411, lr:5.54e-02, fs:0.78261 (r=0.818,p=0.750),  time:34.253, tt:1815.434\n",
      "Ep:53, loss:0.00002, loss_test:0.01376, lr:5.54e-02, fs:0.78469 (r=0.828,p=0.745),  time:34.253, tt:1849.675\n",
      "Ep:54, loss:0.00001, loss_test:0.01373, lr:5.54e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.276, tt:1885.174\n",
      "Ep:55, loss:0.00001, loss_test:0.01477, lr:5.54e-02, fs:0.73737 (r=0.737,p=0.737),  time:34.284, tt:1919.896\n",
      "Ep:56, loss:0.00001, loss_test:0.01350, lr:5.54e-02, fs:0.80193 (r=0.838,p=0.769),  time:34.289, tt:1954.494\n",
      "Ep:57, loss:0.00001, loss_test:0.01429, lr:5.54e-02, fs:0.75510 (r=0.747,p=0.763),  time:34.300, tt:1989.381\n",
      "Ep:58, loss:0.00001, loss_test:0.01434, lr:5.54e-02, fs:0.72821 (r=0.717,p=0.740),  time:34.363, tt:2027.415\n",
      "Ep:59, loss:0.00001, loss_test:0.01392, lr:5.54e-02, fs:0.74611 (r=0.727,p=0.766),  time:34.372, tt:2062.348\n",
      "Ep:60, loss:0.00001, loss_test:0.01465, lr:5.54e-02, fs:0.74611 (r=0.727,p=0.766),  time:34.383, tt:2097.365\n",
      "Ep:61, loss:0.00001, loss_test:0.01421, lr:5.54e-02, fs:0.76923 (r=0.758,p=0.781),  time:34.387, tt:2132.004\n",
      "Ep:62, loss:0.00001, loss_test:0.01396, lr:5.54e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.392, tt:2166.724\n",
      "Ep:63, loss:0.00001, loss_test:0.01451, lr:5.48e-02, fs:0.74866 (r=0.707,p=0.795),  time:34.397, tt:2201.417\n",
      "Ep:64, loss:0.00001, loss_test:0.01503, lr:5.43e-02, fs:0.73626 (r=0.677,p=0.807),  time:34.379, tt:2234.657\n",
      "Ep:65, loss:0.00001, loss_test:0.01556, lr:5.37e-02, fs:0.73034 (r=0.657,p=0.823),  time:34.415, tt:2271.416\n",
      "Ep:66, loss:0.00001, loss_test:0.01490, lr:5.32e-02, fs:0.74725 (r=0.687,p=0.819),  time:34.423, tt:2306.349\n",
      "Ep:67, loss:0.00001, loss_test:0.01528, lr:5.27e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.432, tt:2341.379\n",
      "Ep:68, loss:0.00001, loss_test:0.01469, lr:5.21e-02, fs:0.76087 (r=0.707,p=0.824),  time:34.442, tt:2376.475\n",
      "Ep:69, loss:0.00001, loss_test:0.01514, lr:5.16e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.444, tt:2411.079\n",
      "Ep:70, loss:0.00001, loss_test:0.01622, lr:5.11e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.466, tt:2447.067\n",
      "Ep:71, loss:0.00001, loss_test:0.01530, lr:5.06e-02, fs:0.75556 (r=0.687,p=0.840),  time:34.458, tt:2480.955\n",
      "Ep:72, loss:0.00001, loss_test:0.01590, lr:5.01e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.447, tt:2514.641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00001, loss_test:0.01676, lr:4.96e-02, fs:0.74157 (r=0.667,p=0.835),  time:34.456, tt:2549.729\n",
      "Ep:74, loss:0.00001, loss_test:0.01554, lr:4.91e-02, fs:0.76571 (r=0.677,p=0.882),  time:34.481, tt:2586.066\n",
      "Ep:75, loss:0.00001, loss_test:0.01647, lr:4.86e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.478, tt:2620.344\n",
      "Ep:76, loss:0.00001, loss_test:0.01655, lr:4.81e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.465, tt:2653.832\n",
      "Ep:77, loss:0.00001, loss_test:0.01610, lr:4.76e-02, fs:0.75978 (r=0.687,p=0.850),  time:34.469, tt:2688.592\n",
      "Ep:78, loss:0.00001, loss_test:0.01748, lr:4.71e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.484, tt:2724.236\n",
      "Ep:79, loss:0.00001, loss_test:0.01676, lr:4.67e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.493, tt:2759.436\n",
      "Ep:80, loss:0.00001, loss_test:0.01684, lr:4.62e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.495, tt:2794.058\n",
      "Ep:81, loss:0.00001, loss_test:0.01796, lr:4.57e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.499, tt:2828.940\n",
      "Ep:82, loss:0.00001, loss_test:0.01758, lr:4.53e-02, fs:0.75145 (r=0.657,p=0.878),  time:34.501, tt:2863.574\n",
      "Ep:83, loss:0.00001, loss_test:0.01835, lr:4.48e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.499, tt:2897.876\n",
      "Ep:84, loss:0.00001, loss_test:0.01806, lr:4.44e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.494, tt:2931.984\n",
      "Ep:85, loss:0.00001, loss_test:0.01729, lr:4.39e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.497, tt:2966.709\n",
      "Ep:86, loss:0.00001, loss_test:0.01879, lr:4.35e-02, fs:0.74157 (r=0.667,p=0.835),  time:34.462, tt:2998.231\n",
      "Ep:87, loss:0.00001, loss_test:0.01699, lr:4.31e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.472, tt:3033.556\n",
      "Ep:88, loss:0.00001, loss_test:0.01807, lr:4.26e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.518, tt:3072.088\n",
      "Ep:89, loss:0.00001, loss_test:0.01913, lr:4.22e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.530, tt:3107.687\n",
      "Ep:90, loss:0.00001, loss_test:0.01839, lr:4.18e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.535, tt:3142.702\n",
      "Ep:91, loss:0.00001, loss_test:0.01810, lr:4.14e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.564, tt:3179.914\n",
      "Ep:92, loss:0.00001, loss_test:0.01935, lr:4.10e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.593, tt:3217.147\n",
      "Ep:93, loss:0.00001, loss_test:0.01838, lr:4.05e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.605, tt:3252.907\n",
      "Ep:94, loss:0.00001, loss_test:0.01838, lr:4.01e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.613, tt:3288.212\n",
      "Ep:95, loss:0.00001, loss_test:0.01922, lr:3.97e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.615, tt:3323.051\n",
      "Ep:96, loss:0.00001, loss_test:0.01902, lr:3.93e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.609, tt:3357.082\n",
      "Ep:97, loss:0.00000, loss_test:0.02040, lr:3.89e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.594, tt:3390.220\n",
      "Ep:98, loss:0.00001, loss_test:0.01982, lr:3.86e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.592, tt:3424.589\n",
      "Ep:99, loss:0.00000, loss_test:0.02035, lr:3.82e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.580, tt:3458.000\n",
      "Ep:100, loss:0.00000, loss_test:0.02029, lr:3.78e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.577, tt:3492.313\n",
      "Ep:101, loss:0.00000, loss_test:0.02110, lr:3.74e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.568, tt:3525.954\n",
      "Ep:102, loss:0.00000, loss_test:0.02055, lr:3.70e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.567, tt:3560.409\n",
      "Ep:103, loss:0.00000, loss_test:0.02143, lr:3.67e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.604, tt:3598.779\n",
      "Ep:104, loss:0.00000, loss_test:0.02097, lr:3.63e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.602, tt:3633.202\n",
      "Ep:105, loss:0.00000, loss_test:0.02209, lr:3.59e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.597, tt:3667.327\n",
      "Ep:106, loss:0.00000, loss_test:0.02141, lr:3.56e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.598, tt:3701.949\n",
      "Ep:107, loss:0.00000, loss_test:0.02254, lr:3.52e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.598, tt:3736.626\n",
      "Ep:108, loss:0.00000, loss_test:0.02213, lr:3.49e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.612, tt:3772.679\n",
      "Ep:109, loss:0.00000, loss_test:0.02284, lr:3.45e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.609, tt:3806.951\n",
      "Ep:110, loss:0.00000, loss_test:0.02173, lr:3.42e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.613, tt:3842.094\n",
      "Ep:111, loss:0.00000, loss_test:0.02328, lr:3.38e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.614, tt:3876.807\n",
      "Ep:112, loss:0.00000, loss_test:0.02238, lr:3.35e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.613, tt:3911.230\n",
      "Ep:113, loss:0.00000, loss_test:0.02237, lr:3.32e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.618, tt:3946.457\n",
      "Ep:114, loss:0.00000, loss_test:0.02301, lr:3.28e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.612, tt:3980.437\n",
      "Ep:115, loss:0.00000, loss_test:0.02329, lr:3.25e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.614, tt:4015.263\n",
      "Ep:116, loss:0.00000, loss_test:0.02284, lr:3.22e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.618, tt:4050.312\n",
      "Ep:117, loss:0.00000, loss_test:0.02385, lr:3.19e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.635, tt:4086.881\n",
      "Ep:118, loss:0.00000, loss_test:0.02342, lr:3.15e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.629, tt:4120.852\n",
      "Ep:119, loss:0.00000, loss_test:0.02267, lr:3.12e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.624, tt:4154.899\n",
      "Ep:120, loss:0.00000, loss_test:0.02432, lr:3.09e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.620, tt:4188.974\n",
      "Ep:121, loss:0.00000, loss_test:0.02325, lr:3.06e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.619, tt:4223.513\n",
      "Ep:122, loss:0.00000, loss_test:0.02374, lr:3.03e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.628, tt:4259.215\n",
      "Ep:123, loss:0.00000, loss_test:0.02451, lr:3.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.631, tt:4294.238\n",
      "Ep:124, loss:0.00000, loss_test:0.02366, lr:2.97e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.622, tt:4327.772\n",
      "Ep:125, loss:0.00000, loss_test:0.02363, lr:2.94e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.620, tt:4362.085\n",
      "Ep:126, loss:0.00000, loss_test:0.02467, lr:2.91e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.606, tt:4395.008\n",
      "Ep:127, loss:0.00000, loss_test:0.02335, lr:2.88e-02, fs:0.75000 (r=0.636,p=0.913),  time:34.600, tt:4428.760\n",
      "Ep:128, loss:0.00000, loss_test:0.02490, lr:2.85e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.595, tt:4462.716\n",
      "Ep:129, loss:0.00000, loss_test:0.02380, lr:2.82e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.597, tt:4497.638\n",
      "Ep:130, loss:0.00000, loss_test:0.02470, lr:2.80e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.599, tt:4532.510\n",
      "Ep:131, loss:0.00000, loss_test:0.02428, lr:2.77e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.600, tt:4567.198\n",
      "Ep:132, loss:0.00000, loss_test:0.02480, lr:2.74e-02, fs:0.71951 (r=0.596,p=0.908),  time:34.599, tt:4601.718\n",
      "Ep:133, loss:0.00000, loss_test:0.02515, lr:2.71e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.599, tt:4636.316\n",
      "Ep:134, loss:0.00000, loss_test:0.02496, lr:2.69e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.603, tt:4671.363\n",
      "Ep:135, loss:0.00000, loss_test:0.02516, lr:2.66e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.613, tt:4707.387\n",
      "Ep:136, loss:0.00000, loss_test:0.02557, lr:2.63e-02, fs:0.72393 (r=0.596,p=0.922),  time:34.623, tt:4743.336\n",
      "Ep:137, loss:0.00000, loss_test:0.02524, lr:2.61e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.640, tt:4780.266\n",
      "Ep:138, loss:0.00000, loss_test:0.02540, lr:2.58e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.647, tt:4815.980\n",
      "Ep:139, loss:0.00000, loss_test:0.02583, lr:2.55e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.645, tt:4850.284\n",
      "Ep:140, loss:0.00000, loss_test:0.02539, lr:2.53e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.642, tt:4884.591\n",
      "Ep:141, loss:0.00000, loss_test:0.02583, lr:2.50e-02, fs:0.70807 (r=0.576,p=0.919),  time:34.640, tt:4918.943\n",
      "Ep:142, loss:0.00000, loss_test:0.02598, lr:2.48e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.640, tt:4953.485\n",
      "Ep:143, loss:0.00000, loss_test:0.02601, lr:2.45e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.642, tt:4988.420\n",
      "Ep:144, loss:0.00000, loss_test:0.02612, lr:2.43e-02, fs:0.70807 (r=0.576,p=0.919),  time:34.646, tt:5023.613\n",
      "Ep:145, loss:0.00000, loss_test:0.02612, lr:2.40e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.647, tt:5058.446\n",
      "Ep:146, loss:0.00000, loss_test:0.02610, lr:2.38e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.643, tt:5092.478\n",
      "Ep:147, loss:0.00000, loss_test:0.02648, lr:2.36e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.643, tt:5127.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00000, loss_test:0.02635, lr:2.33e-02, fs:0.70807 (r=0.576,p=0.919),  time:34.643, tt:5161.852\n",
      "Ep:149, loss:0.00000, loss_test:0.02656, lr:2.31e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.649, tt:5197.366\n",
      "Ep:150, loss:0.00000, loss_test:0.02661, lr:2.29e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.657, tt:5233.138\n",
      "Ep:151, loss:0.00000, loss_test:0.02658, lr:2.26e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.657, tt:5267.877\n",
      "Ep:152, loss:0.00000, loss_test:0.02674, lr:2.24e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.651, tt:5301.556\n",
      "Ep:153, loss:0.00000, loss_test:0.02674, lr:2.22e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.655, tt:5336.807\n",
      "Ep:154, loss:0.00000, loss_test:0.02674, lr:2.20e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.656, tt:5371.728\n",
      "Ep:155, loss:0.00000, loss_test:0.02700, lr:2.17e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.659, tt:5406.838\n",
      "Ep:156, loss:0.00000, loss_test:0.02696, lr:2.15e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.661, tt:5441.734\n",
      "Ep:157, loss:0.00000, loss_test:0.02712, lr:2.13e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.664, tt:5476.858\n",
      "Ep:158, loss:0.00000, loss_test:0.02710, lr:2.11e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.666, tt:5511.839\n",
      "Ep:159, loss:0.00000, loss_test:0.02723, lr:2.09e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.672, tt:5547.445\n",
      "Ep:160, loss:0.00000, loss_test:0.02726, lr:2.07e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.678, tt:5583.178\n",
      "Ep:161, loss:0.00000, loss_test:0.02721, lr:2.05e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.690, tt:5619.772\n",
      "Ep:162, loss:0.00000, loss_test:0.02725, lr:2.03e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.702, tt:5656.386\n",
      "Ep:163, loss:0.00000, loss_test:0.02738, lr:2.01e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.706, tt:5691.747\n",
      "Ep:164, loss:0.00000, loss_test:0.02743, lr:1.99e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.707, tt:5726.646\n",
      "Ep:165, loss:0.00000, loss_test:0.02745, lr:1.97e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.711, tt:5762.034\n",
      "Ep:166, loss:0.00000, loss_test:0.02758, lr:1.95e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.713, tt:5797.117\n",
      "Ep:167, loss:0.00000, loss_test:0.02755, lr:1.93e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.722, tt:5833.231\n",
      "Ep:168, loss:0.00000, loss_test:0.02760, lr:1.91e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.721, tt:5867.808\n",
      "Ep:169, loss:0.00000, loss_test:0.02782, lr:1.89e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.723, tt:5902.978\n",
      "Ep:170, loss:0.00000, loss_test:0.02754, lr:1.87e-02, fs:0.70807 (r=0.576,p=0.919),  time:34.726, tt:5938.074\n",
      "Ep:171, loss:0.00000, loss_test:0.02786, lr:1.85e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.720, tt:5971.888\n",
      "Ep:172, loss:0.00000, loss_test:0.02792, lr:1.83e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.728, tt:6007.965\n",
      "Ep:173, loss:0.00000, loss_test:0.02789, lr:1.81e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.729, tt:6042.888\n",
      "Ep:174, loss:0.00000, loss_test:0.02801, lr:1.80e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.736, tt:6078.750\n",
      "Ep:175, loss:0.00000, loss_test:0.02789, lr:1.78e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.737, tt:6113.673\n",
      "Ep:176, loss:0.00000, loss_test:0.02813, lr:1.76e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.734, tt:6147.942\n",
      "Ep:177, loss:0.00000, loss_test:0.02816, lr:1.74e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.734, tt:6182.639\n",
      "Ep:178, loss:0.00000, loss_test:0.02818, lr:1.73e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.735, tt:6217.507\n",
      "Ep:179, loss:0.00000, loss_test:0.02824, lr:1.71e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.731, tt:6251.561\n",
      "Ep:180, loss:0.00000, loss_test:0.02831, lr:1.69e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.735, tt:6287.082\n",
      "Ep:181, loss:0.00000, loss_test:0.02841, lr:1.67e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.740, tt:6322.607\n",
      "Ep:182, loss:0.00000, loss_test:0.02835, lr:1.66e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.738, tt:6357.017\n",
      "Ep:183, loss:0.00000, loss_test:0.02838, lr:1.64e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.733, tt:6390.922\n",
      "Ep:184, loss:0.00000, loss_test:0.02859, lr:1.62e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.738, tt:6426.450\n",
      "Ep:185, loss:0.00000, loss_test:0.02845, lr:1.61e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.736, tt:6460.847\n",
      "Ep:186, loss:0.00000, loss_test:0.02854, lr:1.59e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.740, tt:6496.427\n",
      "Ep:187, loss:0.00000, loss_test:0.02869, lr:1.58e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.742, tt:6531.471\n",
      "Ep:188, loss:0.00000, loss_test:0.02841, lr:1.56e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.740, tt:6565.911\n",
      "Ep:189, loss:0.00000, loss_test:0.02878, lr:1.54e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.747, tt:6601.860\n",
      "Ep:190, loss:0.00000, loss_test:0.02860, lr:1.53e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.743, tt:6635.923\n",
      "Ep:191, loss:0.00000, loss_test:0.02882, lr:1.51e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.734, tt:6668.915\n",
      "Ep:192, loss:0.00000, loss_test:0.02872, lr:1.50e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.729, tt:6702.730\n",
      "Ep:193, loss:0.00000, loss_test:0.02880, lr:1.48e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.727, tt:6736.965\n",
      "Ep:194, loss:0.00000, loss_test:0.02891, lr:1.47e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.725, tt:6771.440\n",
      "Ep:195, loss:0.00000, loss_test:0.02888, lr:1.45e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.717, tt:6804.588\n",
      "Ep:196, loss:0.00000, loss_test:0.02900, lr:1.44e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.717, tt:6839.293\n",
      "Ep:197, loss:0.00000, loss_test:0.02890, lr:1.43e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.711, tt:6872.823\n",
      "Ep:198, loss:0.00000, loss_test:0.02906, lr:1.41e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.716, tt:6908.473\n",
      "Ep:199, loss:0.00000, loss_test:0.02904, lr:1.40e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.713, tt:6942.607\n",
      "Ep:200, loss:0.00000, loss_test:0.02907, lr:1.38e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.717, tt:6978.053\n",
      "Ep:201, loss:0.00000, loss_test:0.02918, lr:1.37e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.726, tt:7014.632\n",
      "Ep:202, loss:0.00000, loss_test:0.02915, lr:1.36e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.728, tt:7049.806\n",
      "Ep:203, loss:0.00000, loss_test:0.02917, lr:1.34e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.720, tt:7082.887\n",
      "Ep:204, loss:0.00000, loss_test:0.02935, lr:1.33e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.724, tt:7118.458\n",
      "Ep:205, loss:0.00000, loss_test:0.02916, lr:1.32e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.724, tt:7153.120\n",
      "Ep:206, loss:0.00000, loss_test:0.02936, lr:1.30e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.725, tt:7188.035\n",
      "Ep:207, loss:0.00000, loss_test:0.02922, lr:1.29e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.725, tt:7222.712\n",
      "Ep:208, loss:0.00000, loss_test:0.02945, lr:1.28e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.731, tt:7258.717\n",
      "Ep:209, loss:0.00000, loss_test:0.02934, lr:1.26e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.724, tt:7292.008\n",
      "Ep:210, loss:0.00000, loss_test:0.02946, lr:1.25e-02, fs:0.71698 (r=0.576,p=0.950),  time:34.726, tt:7327.152\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14141, lr:1.00e-02, fs:0.62992 (r=0.808,p=0.516),  time:28.394, tt:28.394\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.14113, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:29.259, tt:58.518\n",
      "Ep:2, loss:0.00026, loss_test:0.14107, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:29.792, tt:89.377\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.14129, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:29.682, tt:118.729\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.14149, lr:1.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:31.061, tt:155.303\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.14154, lr:1.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:31.701, tt:190.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00025, loss_test:0.14146, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:32.075, tt:224.527\n",
      "Ep:7, loss:0.00025, loss_test:0.14139, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:32.364, tt:258.911\n",
      "Ep:8, loss:0.00025, loss_test:0.14118, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:32.748, tt:294.730\n",
      "Ep:9, loss:0.00025, loss_test:0.14093, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:33.530, tt:335.299\n",
      "Ep:10, loss:0.00025, loss_test:0.14068, lr:1.00e-02, fs:0.63492 (r=0.808,p=0.523),  time:33.763, tt:371.388\n",
      "Ep:11, loss:0.00025, loss_test:0.14037, lr:1.00e-02, fs:0.63492 (r=0.808,p=0.523),  time:33.892, tt:406.701\n",
      "Ep:12, loss:0.00025, loss_test:0.14018, lr:1.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:34.010, tt:442.130\n",
      "Ep:13, loss:0.00024, loss_test:0.14007, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:34.175, tt:478.451\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.13990, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:34.324, tt:514.867\n",
      "Ep:15, loss:0.00024, loss_test:0.13957, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:34.412, tt:550.595\n",
      "Ep:16, loss:0.00024, loss_test:0.13925, lr:1.00e-02, fs:0.63492 (r=0.808,p=0.523),  time:34.550, tt:587.356\n",
      "Ep:17, loss:0.00024, loss_test:0.13895, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:34.611, tt:623.001\n",
      "Ep:18, loss:0.00024, loss_test:0.13858, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:34.736, tt:659.980\n",
      "Ep:19, loss:0.00023, loss_test:0.13798, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:34.790, tt:695.806\n",
      "Ep:20, loss:0.00023, loss_test:0.13714, lr:1.00e-02, fs:0.62857 (r=0.778,p=0.527),  time:34.860, tt:732.064\n",
      "Ep:21, loss:0.00023, loss_test:0.13628, lr:1.00e-02, fs:0.62810 (r=0.768,p=0.531),  time:34.871, tt:767.152\n",
      "Ep:22, loss:0.00023, loss_test:0.13480, lr:1.00e-02, fs:0.61345 (r=0.737,p=0.525),  time:34.889, tt:802.445\n",
      "Ep:23, loss:0.00022, loss_test:0.13338, lr:1.00e-02, fs:0.61017 (r=0.727,p=0.526),  time:34.971, tt:839.299\n",
      "Ep:24, loss:0.00022, loss_test:0.13191, lr:1.00e-02, fs:0.60684 (r=0.717,p=0.526),  time:35.031, tt:875.771\n",
      "Ep:25, loss:0.00022, loss_test:0.12980, lr:9.90e-03, fs:0.61947 (r=0.707,p=0.551),  time:35.008, tt:910.218\n",
      "Ep:26, loss:0.00021, loss_test:0.12794, lr:9.80e-03, fs:0.61333 (r=0.697,p=0.548),  time:35.043, tt:946.170\n",
      "Ep:27, loss:0.00021, loss_test:0.12530, lr:9.70e-03, fs:0.61818 (r=0.687,p=0.562),  time:35.089, tt:982.495\n",
      "Ep:28, loss:0.00020, loss_test:0.12283, lr:9.61e-03, fs:0.62780 (r=0.707,p=0.565),  time:35.115, tt:1018.335\n",
      "Ep:29, loss:0.00020, loss_test:0.12033, lr:9.51e-03, fs:0.64840 (r=0.717,p=0.592),  time:35.137, tt:1054.106\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00019, loss_test:0.11743, lr:9.51e-03, fs:0.62857 (r=0.667,p=0.595),  time:35.163, tt:1090.044\n",
      "Ep:31, loss:0.00018, loss_test:0.11424, lr:9.51e-03, fs:0.66047 (r=0.717,p=0.612),  time:35.176, tt:1125.642\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00018, loss_test:0.11122, lr:9.51e-03, fs:0.68545 (r=0.737,p=0.640),  time:35.209, tt:1161.906\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00017, loss_test:0.10832, lr:9.51e-03, fs:0.69856 (r=0.737,p=0.664),  time:35.277, tt:1199.434\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.10668, lr:9.51e-03, fs:0.70142 (r=0.747,p=0.661),  time:35.336, tt:1236.775\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00016, loss_test:0.10277, lr:9.51e-03, fs:0.71028 (r=0.768,p=0.661),  time:35.368, tt:1273.247\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00016, loss_test:0.10103, lr:9.51e-03, fs:0.71698 (r=0.768,p=0.673),  time:35.413, tt:1310.287\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00015, loss_test:0.09909, lr:9.51e-03, fs:0.72464 (r=0.758,p=0.694),  time:35.457, tt:1347.349\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00015, loss_test:0.09690, lr:9.51e-03, fs:0.71000 (r=0.717,p=0.703),  time:35.495, tt:1384.296\n",
      "Ep:39, loss:0.00014, loss_test:0.09519, lr:9.51e-03, fs:0.72000 (r=0.727,p=0.713),  time:35.541, tt:1421.632\n",
      "Ep:40, loss:0.00014, loss_test:0.09387, lr:9.51e-03, fs:0.75238 (r=0.798,p=0.712),  time:35.559, tt:1457.915\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00013, loss_test:0.09293, lr:9.51e-03, fs:0.74419 (r=0.808,p=0.690),  time:35.572, tt:1494.029\n",
      "Ep:42, loss:0.00013, loss_test:0.09543, lr:9.51e-03, fs:0.75349 (r=0.818,p=0.698),  time:35.583, tt:1530.088\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00013, loss_test:0.09235, lr:9.51e-03, fs:0.75676 (r=0.848,p=0.683),  time:35.612, tt:1566.944\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00012, loss_test:0.09223, lr:9.51e-03, fs:0.70466 (r=0.687,p=0.723),  time:35.617, tt:1602.785\n",
      "Ep:45, loss:0.00012, loss_test:0.08749, lr:9.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:35.616, tt:1638.352\n",
      "Ep:46, loss:0.00011, loss_test:0.08715, lr:9.51e-03, fs:0.77143 (r=0.818,p=0.730),  time:35.666, tt:1676.319\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00011, loss_test:0.10436, lr:9.51e-03, fs:0.73276 (r=0.859,p=0.639),  time:35.638, tt:1710.645\n",
      "Ep:48, loss:0.00012, loss_test:0.09160, lr:9.51e-03, fs:0.75789 (r=0.727,p=0.791),  time:35.644, tt:1746.552\n",
      "Ep:49, loss:0.00013, loss_test:0.09970, lr:9.51e-03, fs:0.72381 (r=0.768,p=0.685),  time:35.661, tt:1783.033\n",
      "Ep:50, loss:0.00012, loss_test:0.08380, lr:9.51e-03, fs:0.77073 (r=0.798,p=0.745),  time:35.662, tt:1818.783\n",
      "Ep:51, loss:0.00011, loss_test:0.09163, lr:9.51e-03, fs:0.76098 (r=0.788,p=0.736),  time:35.669, tt:1854.806\n",
      "Ep:52, loss:0.00010, loss_test:0.08047, lr:9.51e-03, fs:0.81308 (r=0.879,p=0.757),  time:35.675, tt:1890.761\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00010, loss_test:0.08371, lr:9.51e-03, fs:0.78673 (r=0.838,p=0.741),  time:35.714, tt:1928.535\n",
      "Ep:54, loss:0.00009, loss_test:0.08906, lr:9.51e-03, fs:0.72131 (r=0.667,p=0.786),  time:35.717, tt:1964.421\n",
      "Ep:55, loss:0.00009, loss_test:0.07930, lr:9.51e-03, fs:0.80392 (r=0.828,p=0.781),  time:35.756, tt:2002.310\n",
      "Ep:56, loss:0.00008, loss_test:0.07726, lr:9.51e-03, fs:0.80788 (r=0.828,p=0.788),  time:35.792, tt:2040.132\n",
      "Ep:57, loss:0.00008, loss_test:0.08044, lr:9.51e-03, fs:0.76684 (r=0.747,p=0.787),  time:35.815, tt:2077.264\n",
      "Ep:58, loss:0.00008, loss_test:0.07766, lr:9.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:35.819, tt:2113.322\n",
      "Ep:59, loss:0.00008, loss_test:0.08752, lr:9.51e-03, fs:0.76289 (r=0.747,p=0.779),  time:35.829, tt:2149.714\n",
      "Ep:60, loss:0.00008, loss_test:0.08913, lr:9.51e-03, fs:0.71658 (r=0.677,p=0.761),  time:35.832, tt:2185.761\n",
      "Ep:61, loss:0.00008, loss_test:0.09597, lr:9.51e-03, fs:0.70718 (r=0.646,p=0.780),  time:35.845, tt:2222.370\n",
      "Ep:62, loss:0.00007, loss_test:0.08793, lr:9.51e-03, fs:0.72222 (r=0.657,p=0.802),  time:35.838, tt:2257.808\n",
      "Ep:63, loss:0.00007, loss_test:0.08052, lr:9.51e-03, fs:0.76596 (r=0.727,p=0.809),  time:35.853, tt:2294.569\n",
      "Ep:64, loss:0.00006, loss_test:0.09437, lr:9.41e-03, fs:0.71508 (r=0.646,p=0.800),  time:35.864, tt:2331.170\n",
      "Ep:65, loss:0.00006, loss_test:0.07910, lr:9.32e-03, fs:0.81000 (r=0.818,p=0.802),  time:35.867, tt:2367.219\n",
      "Ep:66, loss:0.00006, loss_test:0.09677, lr:9.23e-03, fs:0.70330 (r=0.646,p=0.771),  time:35.874, tt:2403.578\n",
      "Ep:67, loss:0.00006, loss_test:0.08549, lr:9.14e-03, fs:0.74317 (r=0.687,p=0.810),  time:35.868, tt:2439.053\n",
      "Ep:68, loss:0.00005, loss_test:0.08997, lr:9.04e-03, fs:0.78307 (r=0.747,p=0.822),  time:35.880, tt:2475.745\n",
      "Ep:69, loss:0.00005, loss_test:0.07679, lr:8.95e-03, fs:0.79381 (r=0.778,p=0.811),  time:35.867, tt:2510.678\n",
      "Ep:70, loss:0.00005, loss_test:0.10670, lr:8.86e-03, fs:0.69048 (r=0.586,p=0.841),  time:35.882, tt:2547.613\n",
      "Ep:71, loss:0.00006, loss_test:0.08524, lr:8.78e-03, fs:0.80189 (r=0.859,p=0.752),  time:35.882, tt:2583.472\n",
      "Ep:72, loss:0.00007, loss_test:0.08255, lr:8.69e-03, fs:0.80597 (r=0.818,p=0.794),  time:35.899, tt:2620.596\n",
      "Ep:73, loss:0.00006, loss_test:0.07750, lr:8.60e-03, fs:0.75648 (r=0.737,p=0.777),  time:35.911, tt:2657.404\n",
      "Ep:74, loss:0.00006, loss_test:0.08349, lr:8.51e-03, fs:0.72928 (r=0.667,p=0.805),  time:35.923, tt:2694.188\n",
      "Ep:75, loss:0.00005, loss_test:0.09374, lr:8.43e-03, fs:0.68927 (r=0.616,p=0.782),  time:35.914, tt:2729.473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00005, loss_test:0.08314, lr:8.35e-03, fs:0.79365 (r=0.758,p=0.833),  time:35.910, tt:2765.036\n",
      "Ep:77, loss:0.00005, loss_test:0.09315, lr:8.26e-03, fs:0.70391 (r=0.636,p=0.787),  time:35.912, tt:2801.171\n",
      "Ep:78, loss:0.00004, loss_test:0.08119, lr:8.18e-03, fs:0.79365 (r=0.758,p=0.833),  time:35.916, tt:2837.356\n",
      "Ep:79, loss:0.00004, loss_test:0.08361, lr:8.10e-03, fs:0.73446 (r=0.657,p=0.833),  time:35.910, tt:2872.794\n",
      "Ep:80, loss:0.00004, loss_test:0.08689, lr:8.02e-03, fs:0.78947 (r=0.758,p=0.824),  time:35.913, tt:2908.945\n",
      "Ep:81, loss:0.00004, loss_test:0.08560, lr:7.94e-03, fs:0.74118 (r=0.636,p=0.887),  time:35.917, tt:2945.218\n",
      "Ep:82, loss:0.00003, loss_test:0.09088, lr:7.86e-03, fs:0.79348 (r=0.737,p=0.859),  time:35.950, tt:2983.878\n",
      "Ep:83, loss:0.00003, loss_test:0.07980, lr:7.78e-03, fs:0.75429 (r=0.667,p=0.868),  time:35.963, tt:3020.900\n",
      "Ep:84, loss:0.00003, loss_test:0.08783, lr:7.70e-03, fs:0.73563 (r=0.646,p=0.853),  time:35.967, tt:3057.200\n",
      "Ep:85, loss:0.00003, loss_test:0.08831, lr:7.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:35.977, tt:3093.996\n",
      "Ep:86, loss:0.00003, loss_test:0.09130, lr:7.55e-03, fs:0.74854 (r=0.646,p=0.889),  time:35.985, tt:3130.698\n",
      "Ep:87, loss:0.00003, loss_test:0.08786, lr:7.47e-03, fs:0.74419 (r=0.646,p=0.877),  time:36.004, tt:3168.339\n",
      "Ep:88, loss:0.00002, loss_test:0.09177, lr:7.40e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.001, tt:3204.054\n",
      "Ep:89, loss:0.00002, loss_test:0.08936, lr:7.32e-03, fs:0.74419 (r=0.646,p=0.877),  time:35.994, tt:3239.419\n",
      "Ep:90, loss:0.00002, loss_test:0.08606, lr:7.25e-03, fs:0.75740 (r=0.646,p=0.914),  time:35.962, tt:3272.567\n",
      "Ep:91, loss:0.00002, loss_test:0.10114, lr:7.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:35.946, tt:3307.017\n",
      "Ep:92, loss:0.00002, loss_test:0.08596, lr:7.11e-03, fs:0.74854 (r=0.646,p=0.889),  time:35.953, tt:3343.655\n",
      "Ep:93, loss:0.00002, loss_test:0.09232, lr:7.03e-03, fs:0.75740 (r=0.646,p=0.914),  time:35.960, tt:3380.279\n",
      "Ep:94, loss:0.00002, loss_test:0.09006, lr:6.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:35.960, tt:3416.233\n",
      "Ep:95, loss:0.00002, loss_test:0.09004, lr:6.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:35.946, tt:3450.800\n",
      "Ep:96, loss:0.00002, loss_test:0.09959, lr:6.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.971, tt:3489.236\n",
      "Ep:97, loss:0.00002, loss_test:0.08809, lr:6.76e-03, fs:0.76647 (r=0.646,p=0.941),  time:35.981, tt:3526.131\n",
      "Ep:98, loss:0.00002, loss_test:0.08700, lr:6.69e-03, fs:0.74854 (r=0.646,p=0.889),  time:35.992, tt:3563.226\n",
      "Ep:99, loss:0.00002, loss_test:0.09978, lr:6.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.008, tt:3600.766\n",
      "Ep:100, loss:0.00002, loss_test:0.09261, lr:6.56e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.002, tt:3636.210\n",
      "Ep:101, loss:0.00002, loss_test:0.09582, lr:6.49e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.018, tt:3673.825\n",
      "Ep:102, loss:0.00001, loss_test:0.09622, lr:6.43e-03, fs:0.75904 (r=0.636,p=0.940),  time:36.013, tt:3709.323\n",
      "Ep:103, loss:0.00001, loss_test:0.09301, lr:6.36e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.016, tt:3745.690\n",
      "Ep:104, loss:0.00001, loss_test:0.09507, lr:6.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.008, tt:3780.863\n",
      "Ep:105, loss:0.00001, loss_test:0.09525, lr:6.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.011, tt:3817.139\n",
      "Ep:106, loss:0.00001, loss_test:0.09754, lr:6.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.007, tt:3852.765\n",
      "Ep:107, loss:0.00001, loss_test:0.09555, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.022, tt:3890.422\n",
      "Ep:108, loss:0.00001, loss_test:0.09698, lr:6.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:36.028, tt:3927.019\n",
      "Ep:109, loss:0.00001, loss_test:0.09434, lr:5.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.040, tt:3964.424\n",
      "Ep:110, loss:0.00001, loss_test:0.09369, lr:5.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.040, tt:4000.467\n",
      "Ep:111, loss:0.00001, loss_test:0.10940, lr:5.87e-03, fs:0.70886 (r=0.566,p=0.949),  time:36.037, tt:4036.178\n",
      "Ep:112, loss:0.00001, loss_test:0.08792, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.043, tt:4072.855\n",
      "Ep:113, loss:0.00001, loss_test:0.10334, lr:5.75e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.043, tt:4108.907\n",
      "Ep:114, loss:0.00001, loss_test:0.09525, lr:5.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:36.030, tt:4143.493\n",
      "Ep:115, loss:0.00001, loss_test:0.10029, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.032, tt:4179.725\n",
      "Ep:116, loss:0.00001, loss_test:0.10026, lr:5.58e-03, fs:0.75904 (r=0.636,p=0.940),  time:36.022, tt:4214.540\n",
      "Ep:117, loss:0.00001, loss_test:0.09779, lr:5.53e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.018, tt:4250.116\n",
      "Ep:118, loss:0.00001, loss_test:0.10089, lr:5.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.019, tt:4286.212\n",
      "Ep:119, loss:0.00001, loss_test:0.09954, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.013, tt:4321.571\n",
      "Ep:120, loss:0.00001, loss_test:0.09703, lr:5.36e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.018, tt:4358.127\n",
      "Ep:121, loss:0.00001, loss_test:0.09884, lr:5.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.017, tt:4394.075\n",
      "Ep:122, loss:0.00001, loss_test:0.10118, lr:5.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.015, tt:4429.906\n",
      "Ep:123, loss:0.00001, loss_test:0.10019, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.013, tt:4465.578\n",
      "Ep:124, loss:0.00001, loss_test:0.10038, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.017, tt:4502.127\n",
      "Ep:125, loss:0.00001, loss_test:0.10287, lr:5.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.011, tt:4537.337\n",
      "Ep:126, loss:0.00001, loss_test:0.10014, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.004, tt:4572.454\n",
      "Ep:127, loss:0.00001, loss_test:0.10440, lr:5.00e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.017, tt:4610.206\n",
      "Ep:128, loss:0.00001, loss_test:0.10137, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.019, tt:4646.469\n",
      "Ep:129, loss:0.00001, loss_test:0.09893, lr:4.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.020, tt:4682.657\n",
      "Ep:130, loss:0.00001, loss_test:0.10162, lr:4.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.026, tt:4719.371\n",
      "Ep:131, loss:0.00001, loss_test:0.10114, lr:4.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.018, tt:4754.325\n",
      "Ep:132, loss:0.00001, loss_test:0.10129, lr:4.75e-03, fs:0.76829 (r=0.636,p=0.969),  time:36.021, tt:4790.825\n",
      "Ep:133, loss:0.00001, loss_test:0.10008, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.027, tt:4827.583\n",
      "Ep:134, loss:0.00001, loss_test:0.10304, lr:4.66e-03, fs:0.76074 (r=0.626,p=0.969),  time:36.029, tt:4863.902\n",
      "Ep:135, loss:0.00001, loss_test:0.09827, lr:4.61e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.035, tt:4900.778\n",
      "Ep:136, loss:0.00001, loss_test:0.10431, lr:4.57e-03, fs:0.73750 (r=0.596,p=0.967),  time:36.038, tt:4937.255\n",
      "Ep:137, loss:0.00001, loss_test:0.10276, lr:4.52e-03, fs:0.75309 (r=0.616,p=0.968),  time:36.038, tt:4973.298\n",
      "Ep:138, loss:0.00001, loss_test:0.09946, lr:4.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.056, tt:5011.785\n",
      "Ep:139, loss:0.00001, loss_test:0.10241, lr:4.43e-03, fs:0.76074 (r=0.626,p=0.969),  time:36.061, tt:5048.501\n",
      "Ep:140, loss:0.00001, loss_test:0.10053, lr:4.39e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.063, tt:5084.931\n",
      "Ep:141, loss:0.00001, loss_test:0.10324, lr:4.34e-03, fs:0.73750 (r=0.596,p=0.967),  time:36.071, tt:5122.134\n",
      "Ep:142, loss:0.00001, loss_test:0.10350, lr:4.30e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.068, tt:5157.743\n",
      "Ep:143, loss:0.00001, loss_test:0.10060, lr:4.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.063, tt:5193.095\n",
      "Ep:144, loss:0.00001, loss_test:0.10428, lr:4.21e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.068, tt:5229.791\n",
      "Ep:145, loss:0.00001, loss_test:0.10585, lr:4.17e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.074, tt:5266.863\n",
      "Ep:146, loss:0.00001, loss_test:0.10148, lr:4.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.088, tt:5304.963\n",
      "Ep:147, loss:0.00001, loss_test:0.10513, lr:4.09e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.091, tt:5341.458\n",
      "Ep:148, loss:0.00001, loss_test:0.10276, lr:4.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.099, tt:5378.821\n",
      "Ep:149, loss:0.00000, loss_test:0.10401, lr:4.01e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.099, tt:5414.784\n",
      "Ep:150, loss:0.00000, loss_test:0.10309, lr:3.97e-03, fs:0.75309 (r=0.616,p=0.968),  time:36.105, tt:5451.841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00000, loss_test:0.10230, lr:3.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.113, tt:5489.150\n",
      "Ep:152, loss:0.00000, loss_test:0.10550, lr:3.89e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.117, tt:5525.920\n",
      "Ep:153, loss:0.00000, loss_test:0.10372, lr:3.85e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.117, tt:5561.984\n",
      "Ep:154, loss:0.00000, loss_test:0.10182, lr:3.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.114, tt:5597.681\n",
      "Ep:155, loss:0.00000, loss_test:0.10673, lr:3.77e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.119, tt:5634.497\n",
      "Ep:156, loss:0.00000, loss_test:0.10544, lr:3.73e-03, fs:0.77301 (r=0.636,p=0.984),  time:36.127, tt:5671.893\n",
      "Ep:157, loss:0.00000, loss_test:0.10529, lr:3.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.123, tt:5707.485\n",
      "Ep:158, loss:0.00000, loss_test:0.10893, lr:3.66e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.136, tt:5745.586\n",
      "Ep:159, loss:0.00000, loss_test:0.10325, lr:3.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:36.145, tt:5783.130\n",
      "Ep:160, loss:0.00000, loss_test:0.10549, lr:3.59e-03, fs:0.72956 (r=0.586,p=0.967),  time:36.144, tt:5819.168\n",
      "Ep:161, loss:0.00000, loss_test:0.10799, lr:3.55e-03, fs:0.69677 (r=0.545,p=0.964),  time:36.138, tt:5854.412\n",
      "Ep:162, loss:0.00000, loss_test:0.10568, lr:3.52e-03, fs:0.76829 (r=0.636,p=0.969),  time:36.146, tt:5891.788\n",
      "Ep:163, loss:0.00000, loss_test:0.10997, lr:3.48e-03, fs:0.69677 (r=0.545,p=0.964),  time:36.149, tt:5928.402\n",
      "Ep:164, loss:0.00000, loss_test:0.10637, lr:3.45e-03, fs:0.72152 (r=0.576,p=0.966),  time:36.148, tt:5964.496\n",
      "Ep:165, loss:0.00000, loss_test:0.10578, lr:3.41e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.146, tt:6000.274\n",
      "Ep:166, loss:0.00000, loss_test:0.10664, lr:3.38e-03, fs:0.70513 (r=0.556,p=0.965),  time:36.150, tt:6037.011\n",
      "Ep:167, loss:0.00000, loss_test:0.10726, lr:3.34e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.147, tt:6072.712\n",
      "Ep:168, loss:0.00000, loss_test:0.11177, lr:3.31e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.147, tt:6108.898\n",
      "Ep:169, loss:0.00000, loss_test:0.10970, lr:3.28e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.155, tt:6146.278\n",
      "Ep:170, loss:0.00000, loss_test:0.10684, lr:3.24e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.154, tt:6182.267\n",
      "Ep:171, loss:0.00000, loss_test:0.10819, lr:3.21e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.150, tt:6217.727\n",
      "Ep:172, loss:0.00000, loss_test:0.10730, lr:3.18e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.151, tt:6254.167\n",
      "Ep:173, loss:0.00000, loss_test:0.10939, lr:3.15e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.157, tt:6291.371\n",
      "Ep:174, loss:0.00000, loss_test:0.10771, lr:3.12e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.164, tt:6328.613\n",
      "Ep:175, loss:0.00000, loss_test:0.10684, lr:3.09e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.176, tt:6366.898\n",
      "Ep:176, loss:0.00000, loss_test:0.10959, lr:3.05e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.177, tt:6403.378\n",
      "Ep:177, loss:0.00000, loss_test:0.10812, lr:3.02e-03, fs:0.70513 (r=0.556,p=0.965),  time:36.175, tt:6439.229\n",
      "Ep:178, loss:0.00000, loss_test:0.10863, lr:2.99e-03, fs:0.69677 (r=0.545,p=0.964),  time:36.181, tt:6476.328\n",
      "Ep:179, loss:0.00000, loss_test:0.10934, lr:2.96e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.181, tt:6512.662\n",
      "Ep:180, loss:0.00000, loss_test:0.10686, lr:2.93e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.182, tt:6549.011\n",
      "Ep:181, loss:0.00000, loss_test:0.11058, lr:2.90e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.182, tt:6585.099\n",
      "Ep:182, loss:0.00000, loss_test:0.10822, lr:2.88e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.189, tt:6622.614\n",
      "Ep:183, loss:0.00000, loss_test:0.11110, lr:2.85e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.185, tt:6658.082\n",
      "Ep:184, loss:0.00000, loss_test:0.10967, lr:2.82e-03, fs:0.70513 (r=0.556,p=0.965),  time:36.192, tt:6695.576\n",
      "Ep:185, loss:0.00000, loss_test:0.10836, lr:2.79e-03, fs:0.71338 (r=0.566,p=0.966),  time:36.195, tt:6732.312\n",
      "Ep:186, loss:0.00000, loss_test:0.11077, lr:2.76e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.204, tt:6770.130\n",
      "Ep:187, loss:0.00000, loss_test:0.11020, lr:2.73e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.201, tt:6805.773\n",
      "Ep:188, loss:0.00000, loss_test:0.11248, lr:2.71e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.221, tt:6845.829\n",
      "Ep:189, loss:0.00000, loss_test:0.11134, lr:2.68e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.216, tt:6881.002\n",
      "Ep:190, loss:0.00000, loss_test:0.11026, lr:2.65e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.213, tt:6916.624\n",
      "Ep:191, loss:0.00000, loss_test:0.10904, lr:2.63e-03, fs:0.69677 (r=0.545,p=0.964),  time:36.223, tt:6954.811\n",
      "Ep:192, loss:0.00000, loss_test:0.11334, lr:2.60e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.218, tt:6990.103\n",
      "Ep:193, loss:0.00000, loss_test:0.11040, lr:2.57e-03, fs:0.69677 (r=0.545,p=0.964),  time:36.211, tt:7025.024\n",
      "Ep:194, loss:0.00000, loss_test:0.11115, lr:2.55e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.210, tt:7061.015\n",
      "Ep:195, loss:0.00000, loss_test:0.11141, lr:2.52e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.213, tt:7097.667\n",
      "Ep:196, loss:0.00000, loss_test:0.11259, lr:2.50e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.213, tt:7133.943\n",
      "Ep:197, loss:0.00000, loss_test:0.11008, lr:2.47e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.204, tt:7168.411\n",
      "Ep:198, loss:0.00000, loss_test:0.11230, lr:2.45e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.200, tt:7203.898\n",
      "Ep:199, loss:0.00000, loss_test:0.11028, lr:2.42e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.192, tt:7238.355\n",
      "Ep:200, loss:0.00000, loss_test:0.11151, lr:2.40e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.191, tt:7274.434\n",
      "Ep:201, loss:0.00000, loss_test:0.11203, lr:2.38e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.183, tt:7308.886\n",
      "Ep:202, loss:0.00000, loss_test:0.11067, lr:2.35e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.176, tt:7343.828\n",
      "Ep:203, loss:0.00000, loss_test:0.11363, lr:2.33e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.165, tt:7377.736\n",
      "Ep:204, loss:0.00000, loss_test:0.11205, lr:2.31e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.163, tt:7413.465\n",
      "Ep:205, loss:0.00000, loss_test:0.11280, lr:2.28e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.158, tt:7448.476\n",
      "Ep:206, loss:0.00000, loss_test:0.11318, lr:2.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.155, tt:7484.109\n",
      "Ep:207, loss:0.00000, loss_test:0.11279, lr:2.24e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.148, tt:7518.876\n",
      "Ep:208, loss:0.00000, loss_test:0.11328, lr:2.21e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.157, tt:7556.792\n",
      "Ep:209, loss:0.00000, loss_test:0.11348, lr:2.19e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.160, tt:7593.520\n",
      "Ep:210, loss:0.00000, loss_test:0.11131, lr:2.17e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.155, tt:7628.684\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00015, loss_test:0.03218, lr:6.00e-02, fs:0.57919 (r=0.646,p=0.525),  time:24.053, tt:24.053\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02697, lr:6.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:25.381, tt:50.762\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02807, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:26.708, tt:80.125\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02842, lr:6.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:27.266, tt:109.063\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02854, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:28.001, tt:140.005\n",
      "Ep:5, loss:0.00005, loss_test:0.02874, lr:6.00e-02, fs:0.63704 (r=0.869,p=0.503),  time:28.936, tt:173.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00005, loss_test:0.02895, lr:6.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:29.578, tt:207.044\n",
      "Ep:7, loss:0.00005, loss_test:0.02899, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:30.127, tt:241.014\n",
      "Ep:8, loss:0.00005, loss_test:0.02876, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:30.671, tt:276.040\n",
      "Ep:9, loss:0.00005, loss_test:0.02834, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:30.942, tt:309.420\n",
      "Ep:10, loss:0.00005, loss_test:0.02793, lr:6.00e-02, fs:0.63704 (r=0.869,p=0.503),  time:31.237, tt:343.602\n",
      "Ep:11, loss:0.00005, loss_test:0.02751, lr:6.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:31.517, tt:378.201\n",
      "Ep:12, loss:0.00005, loss_test:0.02709, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:31.664, tt:411.633\n",
      "Ep:13, loss:0.00005, loss_test:0.02674, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:31.948, tt:447.276\n",
      "Ep:14, loss:0.00005, loss_test:0.02642, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:32.102, tt:481.533\n",
      "Ep:15, loss:0.00005, loss_test:0.02597, lr:5.94e-02, fs:0.63846 (r=0.838,p=0.516),  time:32.293, tt:516.683\n",
      "Ep:16, loss:0.00005, loss_test:0.02531, lr:5.88e-02, fs:0.63878 (r=0.848,p=0.512),  time:32.420, tt:551.143\n",
      "Ep:17, loss:0.00004, loss_test:0.02464, lr:5.82e-02, fs:0.64122 (r=0.848,p=0.515),  time:32.519, tt:585.339\n",
      "Ep:18, loss:0.00004, loss_test:0.02406, lr:5.76e-02, fs:0.64394 (r=0.859,p=0.515),  time:32.589, tt:619.185\n",
      "Ep:19, loss:0.00004, loss_test:0.02363, lr:5.71e-02, fs:0.64885 (r=0.859,p=0.521),  time:32.672, tt:653.445\n",
      "Ep:20, loss:0.00004, loss_test:0.02337, lr:5.65e-02, fs:0.65134 (r=0.859,p=0.525),  time:32.785, tt:688.484\n",
      "Ep:21, loss:0.00004, loss_test:0.02307, lr:5.59e-02, fs:0.66667 (r=0.899,p=0.530),  time:32.860, tt:722.912\n",
      "Ep:22, loss:0.00004, loss_test:0.02275, lr:5.54e-02, fs:0.68148 (r=0.929,p=0.538),  time:32.972, tt:758.346\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.02255, lr:5.54e-02, fs:0.67897 (r=0.929,p=0.535),  time:33.065, tt:793.567\n",
      "Ep:24, loss:0.00004, loss_test:0.02246, lr:5.54e-02, fs:0.68148 (r=0.929,p=0.538),  time:33.174, tt:829.347\n",
      "Ep:25, loss:0.00004, loss_test:0.02234, lr:5.54e-02, fs:0.67416 (r=0.909,p=0.536),  time:33.338, tt:866.777\n",
      "Ep:26, loss:0.00004, loss_test:0.02212, lr:5.54e-02, fs:0.67416 (r=0.909,p=0.536),  time:33.397, tt:901.721\n",
      "Ep:27, loss:0.00004, loss_test:0.02187, lr:5.54e-02, fs:0.68657 (r=0.929,p=0.544),  time:33.476, tt:937.335\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.02176, lr:5.54e-02, fs:0.67910 (r=0.919,p=0.538),  time:33.512, tt:971.839\n",
      "Ep:29, loss:0.00004, loss_test:0.02160, lr:5.54e-02, fs:0.68165 (r=0.919,p=0.542),  time:33.559, tt:1006.781\n",
      "Ep:30, loss:0.00004, loss_test:0.02115, lr:5.54e-02, fs:0.68914 (r=0.929,p=0.548),  time:33.597, tt:1041.505\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.02076, lr:5.54e-02, fs:0.68914 (r=0.929,p=0.548),  time:33.614, tt:1075.633\n",
      "Ep:32, loss:0.00004, loss_test:0.02057, lr:5.54e-02, fs:0.69630 (r=0.949,p=0.550),  time:33.659, tt:1110.741\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.02032, lr:5.54e-02, fs:0.69630 (r=0.949,p=0.550),  time:33.684, tt:1145.270\n",
      "Ep:34, loss:0.00003, loss_test:0.01985, lr:5.54e-02, fs:0.69630 (r=0.949,p=0.550),  time:33.744, tt:1181.026\n",
      "Ep:35, loss:0.00003, loss_test:0.01954, lr:5.54e-02, fs:0.69925 (r=0.939,p=0.557),  time:33.766, tt:1215.558\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01942, lr:5.54e-02, fs:0.69925 (r=0.939,p=0.557),  time:33.772, tt:1249.563\n",
      "Ep:37, loss:0.00003, loss_test:0.01901, lr:5.54e-02, fs:0.70412 (r=0.949,p=0.560),  time:33.832, tt:1285.619\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01863, lr:5.54e-02, fs:0.71161 (r=0.960,p=0.565),  time:33.853, tt:1320.255\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01846, lr:5.54e-02, fs:0.69962 (r=0.929,p=0.561),  time:33.931, tt:1357.258\n",
      "Ep:40, loss:0.00003, loss_test:0.01807, lr:5.54e-02, fs:0.70769 (r=0.929,p=0.571),  time:34.050, tt:1396.069\n",
      "Ep:41, loss:0.00003, loss_test:0.01758, lr:5.54e-02, fs:0.71815 (r=0.939,p=0.581),  time:34.106, tt:1432.453\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01728, lr:5.54e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.123, tt:1467.285\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01701, lr:5.54e-02, fs:0.74016 (r=0.949,p=0.606),  time:34.158, tt:1502.971\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01689, lr:5.54e-02, fs:0.73600 (r=0.929,p=0.609),  time:34.203, tt:1539.150\n",
      "Ep:45, loss:0.00003, loss_test:0.01639, lr:5.54e-02, fs:0.75102 (r=0.929,p=0.630),  time:34.243, tt:1575.175\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01608, lr:5.54e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.270, tt:1610.706\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01602, lr:5.54e-02, fs:0.75304 (r=0.939,p=0.628),  time:34.269, tt:1644.889\n",
      "Ep:48, loss:0.00003, loss_test:0.01564, lr:5.54e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.284, tt:1679.925\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01563, lr:5.54e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.317, tt:1715.828\n",
      "Ep:50, loss:0.00003, loss_test:0.01530, lr:5.54e-02, fs:0.77686 (r=0.949,p=0.657),  time:34.323, tt:1750.464\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01488, lr:5.54e-02, fs:0.77686 (r=0.949,p=0.657),  time:34.346, tt:1785.976\n",
      "Ep:52, loss:0.00002, loss_test:0.01505, lr:5.54e-02, fs:0.76667 (r=0.929,p=0.652),  time:34.376, tt:1821.926\n",
      "Ep:53, loss:0.00002, loss_test:0.01437, lr:5.54e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.415, tt:1858.406\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01511, lr:5.54e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.443, tt:1894.375\n",
      "Ep:55, loss:0.00002, loss_test:0.01392, lr:5.54e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.492, tt:1931.544\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01456, lr:5.54e-02, fs:0.77637 (r=0.929,p=0.667),  time:34.497, tt:1966.334\n",
      "Ep:57, loss:0.00002, loss_test:0.01328, lr:5.54e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.507, tt:2001.418\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01369, lr:5.54e-02, fs:0.77447 (r=0.919,p=0.669),  time:34.514, tt:2036.301\n",
      "Ep:59, loss:0.00002, loss_test:0.01335, lr:5.54e-02, fs:0.78448 (r=0.919,p=0.684),  time:34.504, tt:2070.246\n",
      "Ep:60, loss:0.00002, loss_test:0.01291, lr:5.54e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.504, tt:2104.731\n",
      "Ep:61, loss:0.00002, loss_test:0.01397, lr:5.54e-02, fs:0.78414 (r=0.899,p=0.695),  time:34.522, tt:2140.359\n",
      "Ep:62, loss:0.00002, loss_test:0.01258, lr:5.54e-02, fs:0.82667 (r=0.939,p=0.738),  time:34.535, tt:2175.695\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01362, lr:5.54e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.525, tt:2209.606\n",
      "Ep:64, loss:0.00002, loss_test:0.01353, lr:5.54e-02, fs:0.77679 (r=0.879,p=0.696),  time:34.537, tt:2244.923\n",
      "Ep:65, loss:0.00002, loss_test:0.01304, lr:5.54e-02, fs:0.81448 (r=0.909,p=0.738),  time:34.522, tt:2278.472\n",
      "Ep:66, loss:0.00002, loss_test:0.01284, lr:5.54e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.489, tt:2310.792\n",
      "Ep:67, loss:0.00002, loss_test:0.01264, lr:5.54e-02, fs:0.82407 (r=0.899,p=0.761),  time:34.486, tt:2345.076\n",
      "Ep:68, loss:0.00002, loss_test:0.01258, lr:5.54e-02, fs:0.81651 (r=0.899,p=0.748),  time:34.479, tt:2379.040\n",
      "Ep:69, loss:0.00002, loss_test:0.01426, lr:5.54e-02, fs:0.79263 (r=0.869,p=0.729),  time:34.474, tt:2413.171\n",
      "Ep:70, loss:0.00002, loss_test:0.01153, lr:5.54e-02, fs:0.84018 (r=0.929,p=0.767),  time:34.490, tt:2448.757\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.01407, lr:5.54e-02, fs:0.80189 (r=0.859,p=0.752),  time:34.482, tt:2482.674\n",
      "Ep:72, loss:0.00002, loss_test:0.01251, lr:5.54e-02, fs:0.81308 (r=0.879,p=0.757),  time:34.462, tt:2515.694\n",
      "Ep:73, loss:0.00002, loss_test:0.01234, lr:5.54e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.458, tt:2549.926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00001, loss_test:0.01323, lr:5.54e-02, fs:0.82927 (r=0.859,p=0.802),  time:34.466, tt:2584.958\n",
      "Ep:75, loss:0.00001, loss_test:0.01194, lr:5.54e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.468, tt:2619.542\n",
      "Ep:76, loss:0.00001, loss_test:0.01376, lr:5.54e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.467, tt:2653.976\n",
      "Ep:77, loss:0.00001, loss_test:0.01141, lr:5.54e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.450, tt:2687.138\n",
      "Ep:78, loss:0.00001, loss_test:0.01363, lr:5.54e-02, fs:0.80402 (r=0.808,p=0.800),  time:34.443, tt:2721.005\n",
      "Ep:79, loss:0.00001, loss_test:0.01413, lr:5.54e-02, fs:0.78261 (r=0.818,p=0.750),  time:34.420, tt:2753.629\n",
      "Ep:80, loss:0.00001, loss_test:0.01397, lr:5.54e-02, fs:0.80000 (r=0.828,p=0.774),  time:34.404, tt:2786.693\n",
      "Ep:81, loss:0.00002, loss_test:0.01486, lr:5.54e-02, fs:0.75598 (r=0.798,p=0.718),  time:34.404, tt:2821.149\n",
      "Ep:82, loss:0.00001, loss_test:0.01414, lr:5.48e-02, fs:0.80788 (r=0.828,p=0.788),  time:34.403, tt:2855.436\n",
      "Ep:83, loss:0.00001, loss_test:0.01502, lr:5.43e-02, fs:0.75598 (r=0.798,p=0.718),  time:34.390, tt:2888.771\n",
      "Ep:84, loss:0.00001, loss_test:0.01332, lr:5.37e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.370, tt:2921.489\n",
      "Ep:85, loss:0.00001, loss_test:0.01402, lr:5.32e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.361, tt:2955.030\n",
      "Ep:86, loss:0.00001, loss_test:0.01315, lr:5.27e-02, fs:0.80583 (r=0.838,p=0.776),  time:34.345, tt:2988.011\n",
      "Ep:87, loss:0.00001, loss_test:0.01564, lr:5.21e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.324, tt:3020.507\n",
      "Ep:88, loss:0.00001, loss_test:0.01354, lr:5.16e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.265, tt:3049.623\n",
      "Ep:89, loss:0.00001, loss_test:0.01535, lr:5.11e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.253, tt:3082.788\n",
      "Ep:90, loss:0.00001, loss_test:0.01439, lr:5.06e-02, fs:0.83417 (r=0.838,p=0.830),  time:34.230, tt:3114.934\n",
      "Ep:91, loss:0.00001, loss_test:0.01543, lr:5.01e-02, fs:0.80808 (r=0.808,p=0.808),  time:34.213, tt:3147.599\n",
      "Ep:92, loss:0.00001, loss_test:0.01481, lr:4.96e-02, fs:0.82653 (r=0.818,p=0.835),  time:34.189, tt:3179.585\n",
      "Ep:93, loss:0.00001, loss_test:0.01609, lr:4.91e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.175, tt:3212.445\n",
      "Ep:94, loss:0.00001, loss_test:0.01623, lr:4.86e-02, fs:0.79581 (r=0.768,p=0.826),  time:34.160, tt:3245.182\n",
      "Ep:95, loss:0.00001, loss_test:0.01638, lr:4.81e-02, fs:0.76344 (r=0.717,p=0.816),  time:34.159, tt:3279.287\n",
      "Ep:96, loss:0.00001, loss_test:0.01724, lr:4.76e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.149, tt:3312.496\n",
      "Ep:97, loss:0.00001, loss_test:0.01676, lr:4.71e-02, fs:0.79144 (r=0.747,p=0.841),  time:34.132, tt:3344.927\n",
      "Ep:98, loss:0.00001, loss_test:0.01682, lr:4.67e-02, fs:0.81053 (r=0.778,p=0.846),  time:34.136, tt:3379.419\n",
      "Ep:99, loss:0.00001, loss_test:0.01727, lr:4.62e-02, fs:0.75824 (r=0.697,p=0.831),  time:34.125, tt:3412.489\n",
      "Ep:100, loss:0.00001, loss_test:0.01939, lr:4.57e-02, fs:0.75410 (r=0.697,p=0.821),  time:34.130, tt:3447.087\n",
      "Ep:101, loss:0.00001, loss_test:0.02036, lr:4.53e-02, fs:0.76503 (r=0.707,p=0.833),  time:34.114, tt:3479.628\n",
      "Ep:102, loss:0.00001, loss_test:0.01803, lr:4.48e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.096, tt:3511.891\n",
      "Ep:103, loss:0.00001, loss_test:0.01703, lr:4.44e-02, fs:0.76503 (r=0.707,p=0.833),  time:34.078, tt:3544.134\n",
      "Ep:104, loss:0.00001, loss_test:0.02008, lr:4.39e-02, fs:0.74860 (r=0.677,p=0.838),  time:34.060, tt:3576.267\n",
      "Ep:105, loss:0.00001, loss_test:0.02127, lr:4.35e-02, fs:0.74860 (r=0.677,p=0.838),  time:34.047, tt:3608.981\n",
      "Ep:106, loss:0.00001, loss_test:0.01903, lr:4.31e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.041, tt:3642.409\n",
      "Ep:107, loss:0.00001, loss_test:0.01772, lr:4.26e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.027, tt:3674.890\n",
      "Ep:108, loss:0.00001, loss_test:0.02013, lr:4.22e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.022, tt:3708.355\n",
      "Ep:109, loss:0.00001, loss_test:0.02080, lr:4.18e-02, fs:0.71676 (r=0.626,p=0.838),  time:34.026, tt:3742.806\n",
      "Ep:110, loss:0.00001, loss_test:0.01962, lr:4.14e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.026, tt:3776.835\n",
      "Ep:111, loss:0.00001, loss_test:0.01938, lr:4.10e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.021, tt:3810.389\n",
      "Ep:112, loss:0.00001, loss_test:0.02115, lr:4.05e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.029, tt:3845.318\n",
      "Ep:113, loss:0.00001, loss_test:0.02186, lr:4.01e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.046, tt:3881.222\n",
      "Ep:114, loss:0.00000, loss_test:0.02117, lr:3.97e-02, fs:0.69461 (r=0.586,p=0.853),  time:34.055, tt:3916.355\n",
      "Ep:115, loss:0.00000, loss_test:0.02286, lr:3.93e-02, fs:0.68263 (r=0.576,p=0.838),  time:34.075, tt:3952.745\n",
      "Ep:116, loss:0.00000, loss_test:0.02446, lr:3.89e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.091, tt:3988.600\n",
      "Ep:117, loss:0.00000, loss_test:0.02236, lr:3.86e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.117, tt:4025.758\n",
      "Ep:118, loss:0.00000, loss_test:0.02155, lr:3.82e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.138, tt:4062.363\n",
      "Ep:119, loss:0.00000, loss_test:0.02456, lr:3.78e-02, fs:0.68263 (r=0.576,p=0.838),  time:34.151, tt:4098.179\n",
      "Ep:120, loss:0.00000, loss_test:0.02394, lr:3.74e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.179, tt:4135.641\n",
      "Ep:121, loss:0.00000, loss_test:0.02287, lr:3.70e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.196, tt:4171.923\n",
      "Ep:122, loss:0.00000, loss_test:0.02462, lr:3.67e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.197, tt:4206.186\n",
      "Ep:123, loss:0.00000, loss_test:0.02631, lr:3.63e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.219, tt:4243.184\n",
      "Ep:124, loss:0.00000, loss_test:0.02556, lr:3.59e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.271, tt:4283.852\n",
      "Ep:125, loss:0.00000, loss_test:0.02366, lr:3.56e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.283, tt:4319.684\n",
      "Ep:126, loss:0.00000, loss_test:0.02555, lr:3.52e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.299, tt:4355.983\n",
      "Ep:127, loss:0.00000, loss_test:0.02696, lr:3.49e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.315, tt:4392.347\n",
      "Ep:128, loss:0.00000, loss_test:0.02644, lr:3.45e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.336, tt:4429.373\n",
      "Ep:129, loss:0.00000, loss_test:0.02553, lr:3.42e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.357, tt:4466.378\n",
      "Ep:130, loss:0.00000, loss_test:0.02763, lr:3.38e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.361, tt:4501.233\n",
      "Ep:131, loss:0.00000, loss_test:0.02919, lr:3.35e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.370, tt:4536.851\n",
      "Ep:132, loss:0.00000, loss_test:0.02656, lr:3.32e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.383, tt:4572.880\n",
      "Ep:133, loss:0.00000, loss_test:0.02527, lr:3.28e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.386, tt:4607.772\n",
      "Ep:134, loss:0.00000, loss_test:0.02869, lr:3.25e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.394, tt:4643.233\n",
      "Ep:135, loss:0.00000, loss_test:0.02948, lr:3.22e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.413, tt:4680.104\n",
      "Ep:136, loss:0.00000, loss_test:0.02643, lr:3.19e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.425, tt:4716.212\n",
      "Ep:137, loss:0.00000, loss_test:0.02929, lr:3.15e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.445, tt:4753.474\n",
      "Ep:138, loss:0.00000, loss_test:0.03022, lr:3.12e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.456, tt:4789.445\n",
      "Ep:139, loss:0.00000, loss_test:0.02626, lr:3.09e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.473, tt:4826.239\n",
      "Ep:140, loss:0.00000, loss_test:0.02858, lr:3.06e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.485, tt:4862.430\n",
      "Ep:141, loss:0.00000, loss_test:0.03200, lr:3.03e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.498, tt:4898.652\n",
      "Ep:142, loss:0.00000, loss_test:0.02727, lr:3.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.500, tt:4933.525\n",
      "Ep:143, loss:0.00000, loss_test:0.03008, lr:2.97e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.519, tt:4970.718\n",
      "Ep:144, loss:0.00000, loss_test:0.03040, lr:2.94e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.537, tt:5007.917\n",
      "Ep:145, loss:0.00000, loss_test:0.02836, lr:2.91e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.541, tt:5042.932\n",
      "Ep:146, loss:0.00000, loss_test:0.03238, lr:2.88e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.546, tt:5078.291\n",
      "Ep:147, loss:0.00000, loss_test:0.02919, lr:2.85e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.545, tt:5112.731\n",
      "Ep:148, loss:0.00000, loss_test:0.02987, lr:2.82e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.543, tt:5146.865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:149, loss:0.00000, loss_test:0.03248, lr:2.80e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.551, tt:5182.612\n",
      "Ep:150, loss:0.00000, loss_test:0.02901, lr:2.77e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.558, tt:5218.280\n",
      "Ep:151, loss:0.00000, loss_test:0.03336, lr:2.74e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.558, tt:5252.817\n",
      "Ep:152, loss:0.00000, loss_test:0.03075, lr:2.71e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.569, tt:5289.035\n",
      "Ep:153, loss:0.00000, loss_test:0.03136, lr:2.69e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.577, tt:5324.892\n",
      "Ep:154, loss:0.00000, loss_test:0.03392, lr:2.66e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.587, tt:5360.913\n",
      "Ep:155, loss:0.00000, loss_test:0.02988, lr:2.63e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.608, tt:5398.791\n",
      "Ep:156, loss:0.00000, loss_test:0.03402, lr:2.61e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.620, tt:5435.301\n",
      "Ep:157, loss:0.00000, loss_test:0.03085, lr:2.58e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.630, tt:5471.582\n",
      "Ep:158, loss:0.00000, loss_test:0.03384, lr:2.55e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.652, tt:5509.726\n",
      "Ep:159, loss:0.00000, loss_test:0.03230, lr:2.53e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.666, tt:5546.638\n",
      "Ep:160, loss:0.00000, loss_test:0.03365, lr:2.50e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.681, tt:5583.621\n",
      "Ep:161, loss:0.00000, loss_test:0.03406, lr:2.48e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.691, tt:5619.905\n",
      "Ep:162, loss:0.00000, loss_test:0.03245, lr:2.45e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.693, tt:5655.015\n",
      "Ep:163, loss:0.00000, loss_test:0.03477, lr:2.43e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.699, tt:5690.602\n",
      "Ep:164, loss:0.00000, loss_test:0.03393, lr:2.40e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.706, tt:5726.530\n",
      "Ep:165, loss:0.00000, loss_test:0.03360, lr:2.38e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.712, tt:5762.125\n",
      "Ep:166, loss:0.00000, loss_test:0.03569, lr:2.36e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.721, tt:5798.401\n",
      "Ep:167, loss:0.00000, loss_test:0.03362, lr:2.33e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.721, tt:5833.172\n",
      "Ep:168, loss:0.00000, loss_test:0.03609, lr:2.31e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.742, tt:5871.391\n",
      "Ep:169, loss:0.00000, loss_test:0.03413, lr:2.29e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.739, tt:5905.632\n",
      "Ep:170, loss:0.00000, loss_test:0.03557, lr:2.26e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.753, tt:5942.769\n",
      "Ep:171, loss:0.00000, loss_test:0.03547, lr:2.24e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.756, tt:5978.057\n",
      "Ep:172, loss:0.00000, loss_test:0.03456, lr:2.22e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.760, tt:6013.472\n",
      "Ep:173, loss:0.00000, loss_test:0.03745, lr:2.20e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.771, tt:6050.176\n",
      "Ep:174, loss:0.00000, loss_test:0.03453, lr:2.17e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.783, tt:6086.976\n",
      "Ep:175, loss:0.00000, loss_test:0.03635, lr:2.15e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.783, tt:6121.849\n",
      "Ep:176, loss:0.00000, loss_test:0.03610, lr:2.13e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.784, tt:6156.705\n",
      "Ep:177, loss:0.00000, loss_test:0.03516, lr:2.11e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.788, tt:6192.225\n",
      "Ep:178, loss:0.00000, loss_test:0.03797, lr:2.09e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.788, tt:6227.140\n",
      "Ep:179, loss:0.00000, loss_test:0.03482, lr:2.07e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.798, tt:6263.705\n",
      "Ep:180, loss:0.00000, loss_test:0.03756, lr:2.05e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.802, tt:6299.094\n",
      "Ep:181, loss:0.00000, loss_test:0.03587, lr:2.03e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.809, tt:6335.206\n",
      "Ep:182, loss:0.00000, loss_test:0.03754, lr:2.01e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.817, tt:6371.473\n",
      "Ep:183, loss:0.00000, loss_test:0.03671, lr:1.99e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.820, tt:6406.807\n",
      "Ep:184, loss:0.00000, loss_test:0.03700, lr:1.97e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.826, tt:6442.771\n",
      "Ep:185, loss:0.00000, loss_test:0.03754, lr:1.95e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.827, tt:6477.778\n",
      "Ep:186, loss:0.00000, loss_test:0.03673, lr:1.93e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.829, tt:6513.017\n",
      "Ep:187, loss:0.00000, loss_test:0.03891, lr:1.91e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.837, tt:6549.387\n",
      "Ep:188, loss:0.00000, loss_test:0.03601, lr:1.89e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.847, tt:6586.144\n",
      "Ep:189, loss:0.00000, loss_test:0.03879, lr:1.87e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.849, tt:6621.324\n",
      "Ep:190, loss:0.00000, loss_test:0.03730, lr:1.85e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.850, tt:6656.354\n",
      "Ep:191, loss:0.00000, loss_test:0.03848, lr:1.83e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.852, tt:6691.543\n",
      "Ep:192, loss:0.00000, loss_test:0.03763, lr:1.81e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.852, tt:6726.496\n",
      "Ep:193, loss:0.00000, loss_test:0.03880, lr:1.80e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.862, tt:6763.180\n",
      "Ep:194, loss:0.00000, loss_test:0.03838, lr:1.78e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.862, tt:6798.160\n",
      "Ep:195, loss:0.00000, loss_test:0.03901, lr:1.76e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.864, tt:6833.350\n",
      "Ep:196, loss:0.00000, loss_test:0.03835, lr:1.74e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.860, tt:6867.382\n",
      "Ep:197, loss:0.00000, loss_test:0.03946, lr:1.73e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.857, tt:6901.605\n",
      "Ep:198, loss:0.00000, loss_test:0.03870, lr:1.71e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.860, tt:6937.119\n",
      "Ep:199, loss:0.00000, loss_test:0.03968, lr:1.69e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.860, tt:6972.075\n",
      "Ep:200, loss:0.00000, loss_test:0.03915, lr:1.67e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.862, tt:7007.303\n",
      "Ep:201, loss:0.00000, loss_test:0.03962, lr:1.66e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.866, tt:7043.012\n",
      "Ep:202, loss:0.00000, loss_test:0.03917, lr:1.64e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.865, tt:7077.594\n",
      "Ep:203, loss:0.00000, loss_test:0.03968, lr:1.62e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.870, tt:7113.395\n",
      "Ep:204, loss:0.00000, loss_test:0.03978, lr:1.61e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.872, tt:7148.851\n",
      "Ep:205, loss:0.00000, loss_test:0.03949, lr:1.59e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.879, tt:7185.000\n",
      "Ep:206, loss:0.00000, loss_test:0.04046, lr:1.58e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.887, tt:7221.630\n",
      "Ep:207, loss:0.00000, loss_test:0.03961, lr:1.56e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.886, tt:7256.270\n",
      "Ep:208, loss:0.00000, loss_test:0.04048, lr:1.54e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.888, tt:7291.597\n",
      "Ep:209, loss:0.00000, loss_test:0.04010, lr:1.53e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.890, tt:7326.856\n",
      "Ep:210, loss:0.00000, loss_test:0.04093, lr:1.51e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.891, tt:7362.000\n",
      "Ep:211, loss:0.00000, loss_test:0.03943, lr:1.50e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.889, tt:7396.364\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13984, lr:1.00e-02, fs:0.62992 (r=0.808,p=0.516),  time:31.625, tt:31.625\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.14062, lr:1.00e-02, fs:0.62992 (r=0.808,p=0.516),  time:31.702, tt:63.405\n",
      "Ep:2, loss:0.00025, loss_test:0.14136, lr:1.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:31.989, tt:95.968\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.14169, lr:1.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:31.039, tt:124.156\n",
      "Ep:4, loss:0.00025, loss_test:0.14162, lr:1.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:31.835, tt:159.177\n",
      "Ep:5, loss:0.00025, loss_test:0.14147, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:32.249, tt:193.492\n",
      "Ep:6, loss:0.00025, loss_test:0.14111, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:32.879, tt:230.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00025, loss_test:0.14087, lr:1.00e-02, fs:0.62698 (r=0.798,p=0.516),  time:33.447, tt:267.574\n",
      "Ep:8, loss:0.00024, loss_test:0.14075, lr:1.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:33.958, tt:305.623\n",
      "Ep:9, loss:0.00024, loss_test:0.13996, lr:1.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:34.205, tt:342.046\n",
      "Ep:10, loss:0.00024, loss_test:0.13891, lr:1.00e-02, fs:0.62400 (r=0.788,p=0.517),  time:34.520, tt:379.719\n",
      "Ep:11, loss:0.00024, loss_test:0.13811, lr:1.00e-02, fs:0.61847 (r=0.778,p=0.513),  time:34.693, tt:416.320\n",
      "Ep:12, loss:0.00023, loss_test:0.13676, lr:1.00e-02, fs:0.62295 (r=0.768,p=0.524),  time:34.724, tt:451.418\n",
      "Ep:13, loss:0.00023, loss_test:0.13478, lr:1.00e-02, fs:0.61728 (r=0.758,p=0.521),  time:34.829, tt:487.613\n",
      "Ep:14, loss:0.00023, loss_test:0.13388, lr:9.90e-03, fs:0.60169 (r=0.717,p=0.518),  time:35.045, tt:525.672\n",
      "Ep:15, loss:0.00022, loss_test:0.13235, lr:9.80e-03, fs:0.60870 (r=0.707,p=0.534),  time:35.163, tt:562.615\n",
      "Ep:16, loss:0.00022, loss_test:0.13016, lr:9.70e-03, fs:0.59556 (r=0.677,p=0.532),  time:35.211, tt:598.595\n",
      "Ep:17, loss:0.00021, loss_test:0.12770, lr:9.61e-03, fs:0.58065 (r=0.636,p=0.534),  time:35.282, tt:635.074\n",
      "Ep:18, loss:0.00021, loss_test:0.12474, lr:9.51e-03, fs:0.57944 (r=0.626,p=0.539),  time:35.320, tt:671.083\n",
      "Ep:19, loss:0.00020, loss_test:0.12200, lr:9.41e-03, fs:0.61751 (r=0.677,p=0.568),  time:35.393, tt:707.853\n",
      "Ep:20, loss:0.00019, loss_test:0.11818, lr:9.32e-03, fs:0.62617 (r=0.677,p=0.583),  time:35.456, tt:744.574\n",
      "Ep:21, loss:0.00019, loss_test:0.11770, lr:9.23e-03, fs:0.67606 (r=0.727,p=0.632),  time:35.532, tt:781.714\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.11358, lr:9.23e-03, fs:0.68519 (r=0.747,p=0.632),  time:35.586, tt:818.472\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.11199, lr:9.23e-03, fs:0.68269 (r=0.717,p=0.651),  time:35.648, tt:855.561\n",
      "Ep:24, loss:0.00017, loss_test:0.11134, lr:9.23e-03, fs:0.69194 (r=0.737,p=0.652),  time:35.669, tt:891.737\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.10993, lr:9.23e-03, fs:0.67647 (r=0.697,p=0.657),  time:35.661, tt:927.182\n",
      "Ep:26, loss:0.00016, loss_test:0.10914, lr:9.23e-03, fs:0.70476 (r=0.747,p=0.667),  time:35.669, tt:963.071\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.10564, lr:9.23e-03, fs:0.70192 (r=0.737,p=0.670),  time:35.696, tt:999.501\n",
      "Ep:28, loss:0.00015, loss_test:0.10634, lr:9.23e-03, fs:0.68932 (r=0.717,p=0.664),  time:35.689, tt:1034.993\n",
      "Ep:29, loss:0.00014, loss_test:0.10600, lr:9.23e-03, fs:0.68000 (r=0.687,p=0.673),  time:35.877, tt:1076.318\n",
      "Ep:30, loss:0.00014, loss_test:0.10519, lr:9.23e-03, fs:0.71698 (r=0.768,p=0.673),  time:35.905, tt:1113.050\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09982, lr:9.23e-03, fs:0.70936 (r=0.727,p=0.692),  time:35.927, tt:1149.655\n",
      "Ep:32, loss:0.00013, loss_test:0.11274, lr:9.23e-03, fs:0.68783 (r=0.657,p=0.722),  time:35.919, tt:1185.312\n",
      "Ep:33, loss:0.00013, loss_test:0.10677, lr:9.23e-03, fs:0.70769 (r=0.697,p=0.719),  time:35.941, tt:1221.990\n",
      "Ep:34, loss:0.00012, loss_test:0.09713, lr:9.23e-03, fs:0.70936 (r=0.727,p=0.692),  time:35.941, tt:1257.942\n",
      "Ep:35, loss:0.00011, loss_test:0.10667, lr:9.23e-03, fs:0.71204 (r=0.687,p=0.739),  time:35.945, tt:1294.026\n",
      "Ep:36, loss:0.00010, loss_test:0.10158, lr:9.23e-03, fs:0.70408 (r=0.697,p=0.711),  time:35.988, tt:1331.553\n",
      "Ep:37, loss:0.00010, loss_test:0.09222, lr:9.23e-03, fs:0.72195 (r=0.747,p=0.698),  time:36.006, tt:1368.245\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.09108, lr:9.23e-03, fs:0.70833 (r=0.687,p=0.731),  time:36.005, tt:1404.189\n",
      "Ep:39, loss:0.00010, loss_test:0.11614, lr:9.23e-03, fs:0.71357 (r=0.717,p=0.710),  time:36.036, tt:1441.450\n",
      "Ep:40, loss:0.00010, loss_test:0.09044, lr:9.23e-03, fs:0.73171 (r=0.758,p=0.708),  time:36.040, tt:1477.659\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.10699, lr:9.23e-03, fs:0.72115 (r=0.758,p=0.688),  time:36.043, tt:1513.811\n",
      "Ep:42, loss:0.00009, loss_test:0.08796, lr:9.23e-03, fs:0.76056 (r=0.818,p=0.711),  time:36.044, tt:1549.897\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.09910, lr:9.23e-03, fs:0.72637 (r=0.737,p=0.716),  time:36.053, tt:1586.326\n",
      "Ep:44, loss:0.00008, loss_test:0.09414, lr:9.23e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.064, tt:1622.901\n",
      "Ep:45, loss:0.00008, loss_test:0.09180, lr:9.23e-03, fs:0.70330 (r=0.646,p=0.771),  time:36.097, tt:1660.476\n",
      "Ep:46, loss:0.00008, loss_test:0.10795, lr:9.23e-03, fs:0.74112 (r=0.737,p=0.745),  time:36.102, tt:1696.790\n",
      "Ep:47, loss:0.00008, loss_test:0.08528, lr:9.23e-03, fs:0.75728 (r=0.788,p=0.729),  time:36.131, tt:1734.264\n",
      "Ep:48, loss:0.00008, loss_test:0.10598, lr:9.23e-03, fs:0.75622 (r=0.768,p=0.745),  time:36.176, tt:1772.636\n",
      "Ep:49, loss:0.00008, loss_test:0.08037, lr:9.23e-03, fs:0.79426 (r=0.838,p=0.755),  time:36.211, tt:1810.543\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.09486, lr:9.23e-03, fs:0.71856 (r=0.606,p=0.882),  time:36.196, tt:1846.012\n",
      "Ep:51, loss:0.00007, loss_test:0.08748, lr:9.23e-03, fs:0.75532 (r=0.717,p=0.798),  time:36.204, tt:1882.618\n",
      "Ep:52, loss:0.00006, loss_test:0.08955, lr:9.23e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.203, tt:1918.778\n",
      "Ep:53, loss:0.00006, loss_test:0.09338, lr:9.23e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.228, tt:1956.287\n",
      "Ep:54, loss:0.00006, loss_test:0.08962, lr:9.23e-03, fs:0.74641 (r=0.788,p=0.709),  time:36.220, tt:1992.123\n",
      "Ep:55, loss:0.00008, loss_test:0.09753, lr:9.23e-03, fs:0.71591 (r=0.636,p=0.818),  time:36.234, tt:2029.116\n",
      "Ep:56, loss:0.00007, loss_test:0.09326, lr:9.23e-03, fs:0.68927 (r=0.616,p=0.782),  time:36.257, tt:2066.637\n",
      "Ep:57, loss:0.00008, loss_test:0.08910, lr:9.23e-03, fs:0.76617 (r=0.778,p=0.755),  time:36.262, tt:2103.222\n",
      "Ep:58, loss:0.00007, loss_test:0.09147, lr:9.23e-03, fs:0.73256 (r=0.636,p=0.863),  time:36.278, tt:2140.419\n",
      "Ep:59, loss:0.00006, loss_test:0.08822, lr:9.23e-03, fs:0.75728 (r=0.788,p=0.729),  time:36.271, tt:2176.246\n",
      "Ep:60, loss:0.00007, loss_test:0.08664, lr:9.23e-03, fs:0.74033 (r=0.677,p=0.817),  time:36.282, tt:2213.191\n",
      "Ep:61, loss:0.00006, loss_test:0.10391, lr:9.14e-03, fs:0.71006 (r=0.606,p=0.857),  time:36.311, tt:2251.293\n",
      "Ep:62, loss:0.00005, loss_test:0.08670, lr:9.04e-03, fs:0.75532 (r=0.717,p=0.798),  time:36.331, tt:2288.877\n",
      "Ep:63, loss:0.00005, loss_test:0.09432, lr:8.95e-03, fs:0.71186 (r=0.636,p=0.808),  time:36.369, tt:2327.614\n",
      "Ep:64, loss:0.00005, loss_test:0.09780, lr:8.86e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.377, tt:2364.478\n",
      "Ep:65, loss:0.00005, loss_test:0.08336, lr:8.78e-03, fs:0.78571 (r=0.778,p=0.794),  time:36.375, tt:2400.758\n",
      "Ep:66, loss:0.00004, loss_test:0.09488, lr:8.69e-03, fs:0.67485 (r=0.556,p=0.859),  time:36.386, tt:2437.878\n",
      "Ep:67, loss:0.00004, loss_test:0.08328, lr:8.60e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.380, tt:2473.820\n",
      "Ep:68, loss:0.00004, loss_test:0.09103, lr:8.51e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.396, tt:2511.343\n",
      "Ep:69, loss:0.00004, loss_test:0.09407, lr:8.43e-03, fs:0.67089 (r=0.535,p=0.898),  time:36.403, tt:2548.200\n",
      "Ep:70, loss:0.00003, loss_test:0.09128, lr:8.35e-03, fs:0.71006 (r=0.606,p=0.857),  time:36.424, tt:2586.095\n",
      "Ep:71, loss:0.00003, loss_test:0.10027, lr:8.26e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.434, tt:2623.228\n",
      "Ep:72, loss:0.00003, loss_test:0.08970, lr:8.18e-03, fs:0.76136 (r=0.677,p=0.870),  time:36.426, tt:2659.112\n",
      "Ep:73, loss:0.00003, loss_test:0.10079, lr:8.10e-03, fs:0.66667 (r=0.535,p=0.883),  time:36.444, tt:2696.825\n",
      "Ep:74, loss:0.00003, loss_test:0.09372, lr:8.02e-03, fs:0.69182 (r=0.556,p=0.917),  time:36.464, tt:2734.768\n",
      "Ep:75, loss:0.00003, loss_test:0.09521, lr:7.94e-03, fs:0.66667 (r=0.535,p=0.883),  time:36.465, tt:2771.302\n",
      "Ep:76, loss:0.00002, loss_test:0.09045, lr:7.86e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.464, tt:2807.730\n",
      "Ep:77, loss:0.00003, loss_test:0.09819, lr:7.78e-03, fs:0.67089 (r=0.535,p=0.898),  time:36.495, tt:2846.595\n",
      "Ep:78, loss:0.00002, loss_test:0.09400, lr:7.70e-03, fs:0.68354 (r=0.545,p=0.915),  time:36.490, tt:2882.716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00002, loss_test:0.09848, lr:7.62e-03, fs:0.70000 (r=0.566,p=0.918),  time:36.482, tt:2918.521\n",
      "Ep:80, loss:0.00002, loss_test:0.10091, lr:7.55e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.470, tt:2954.109\n",
      "Ep:81, loss:0.00002, loss_test:0.10271, lr:7.47e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.450, tt:2988.905\n",
      "Ep:82, loss:0.00002, loss_test:0.10346, lr:7.40e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.439, tt:3024.472\n",
      "Ep:83, loss:0.00002, loss_test:0.10183, lr:7.32e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.428, tt:3059.971\n",
      "Ep:84, loss:0.00002, loss_test:0.10627, lr:7.25e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.395, tt:3093.605\n",
      "Ep:85, loss:0.00002, loss_test:0.09647, lr:7.18e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.366, tt:3127.509\n",
      "Ep:86, loss:0.00002, loss_test:0.11093, lr:7.11e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.340, tt:3161.586\n",
      "Ep:87, loss:0.00001, loss_test:0.10782, lr:7.03e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.313, tt:3195.543\n",
      "Ep:88, loss:0.00002, loss_test:0.10435, lr:6.96e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.287, tt:3229.520\n",
      "Ep:89, loss:0.00001, loss_test:0.10567, lr:6.89e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.257, tt:3263.173\n",
      "Ep:90, loss:0.00001, loss_test:0.10974, lr:6.83e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.234, tt:3297.290\n",
      "Ep:91, loss:0.00001, loss_test:0.11326, lr:6.76e-03, fs:0.68387 (r=0.535,p=0.946),  time:36.180, tt:3328.573\n",
      "Ep:92, loss:0.00001, loss_test:0.11596, lr:6.69e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.136, tt:3360.621\n",
      "Ep:93, loss:0.00001, loss_test:0.10939, lr:6.62e-03, fs:0.68387 (r=0.535,p=0.946),  time:36.111, tt:3394.481\n",
      "Ep:94, loss:0.00001, loss_test:0.11477, lr:6.56e-03, fs:0.67516 (r=0.535,p=0.914),  time:36.086, tt:3428.205\n",
      "Ep:95, loss:0.00001, loss_test:0.11133, lr:6.49e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.061, tt:3461.870\n",
      "Ep:96, loss:0.00001, loss_test:0.10926, lr:6.43e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.052, tt:3497.057\n",
      "Ep:97, loss:0.00001, loss_test:0.11978, lr:6.36e-03, fs:0.68831 (r=0.535,p=0.964),  time:36.037, tt:3531.641\n",
      "Ep:98, loss:0.00001, loss_test:0.10907, lr:6.30e-03, fs:0.67949 (r=0.535,p=0.930),  time:36.005, tt:3564.487\n",
      "Ep:99, loss:0.00001, loss_test:0.11466, lr:6.24e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.982, tt:3598.190\n",
      "Ep:100, loss:0.00001, loss_test:0.11830, lr:6.17e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.968, tt:3632.743\n",
      "Ep:101, loss:0.00001, loss_test:0.11119, lr:6.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.952, tt:3667.154\n",
      "Ep:102, loss:0.00001, loss_test:0.11683, lr:6.05e-03, fs:0.67516 (r=0.535,p=0.914),  time:35.948, tt:3702.692\n",
      "Ep:103, loss:0.00001, loss_test:0.11362, lr:5.99e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.944, tt:3738.212\n",
      "Ep:104, loss:0.00001, loss_test:0.11314, lr:5.93e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.926, tt:3772.210\n",
      "Ep:105, loss:0.00001, loss_test:0.11350, lr:5.87e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.898, tt:3805.175\n",
      "Ep:106, loss:0.00001, loss_test:0.11517, lr:5.81e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.877, tt:3838.788\n",
      "Ep:107, loss:0.00001, loss_test:0.11233, lr:5.75e-03, fs:0.67516 (r=0.535,p=0.914),  time:35.872, tt:3874.202\n",
      "Ep:108, loss:0.00001, loss_test:0.11301, lr:5.70e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.873, tt:3910.111\n",
      "Ep:109, loss:0.00001, loss_test:0.11310, lr:5.64e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.854, tt:3943.947\n",
      "Ep:110, loss:0.00001, loss_test:0.11336, lr:5.58e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.837, tt:3977.883\n",
      "Ep:111, loss:0.00001, loss_test:0.11557, lr:5.53e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.822, tt:4012.059\n",
      "Ep:112, loss:0.00000, loss_test:0.10931, lr:5.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.813, tt:4046.861\n",
      "Ep:113, loss:0.00000, loss_test:0.11161, lr:5.42e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.795, tt:4080.652\n",
      "Ep:114, loss:0.00000, loss_test:0.11603, lr:5.36e-03, fs:0.68831 (r=0.535,p=0.964),  time:35.782, tt:4114.891\n",
      "Ep:115, loss:0.00000, loss_test:0.11426, lr:5.31e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.772, tt:4149.582\n",
      "Ep:116, loss:0.00000, loss_test:0.11393, lr:5.26e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.791, tt:4187.506\n",
      "Ep:117, loss:0.00000, loss_test:0.11309, lr:5.20e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.768, tt:4220.612\n",
      "Ep:118, loss:0.00000, loss_test:0.11542, lr:5.15e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.755, tt:4254.838\n",
      "Ep:119, loss:0.00000, loss_test:0.11195, lr:5.10e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.764, tt:4291.625\n",
      "Ep:120, loss:0.00000, loss_test:0.11499, lr:5.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.754, tt:4326.249\n",
      "Ep:121, loss:0.00000, loss_test:0.11552, lr:5.00e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.740, tt:4360.282\n",
      "Ep:122, loss:0.00000, loss_test:0.11462, lr:4.95e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.734, tt:4395.306\n",
      "Ep:123, loss:0.00000, loss_test:0.11679, lr:4.90e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.721, tt:4429.369\n",
      "Ep:124, loss:0.00000, loss_test:0.11459, lr:4.85e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.705, tt:4463.104\n",
      "Ep:125, loss:0.00000, loss_test:0.11285, lr:4.80e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.699, tt:4498.127\n",
      "Ep:126, loss:0.00000, loss_test:0.11225, lr:4.75e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.690, tt:4532.661\n",
      "Ep:127, loss:0.00000, loss_test:0.11600, lr:4.71e-03, fs:0.68831 (r=0.535,p=0.964),  time:35.686, tt:4567.842\n",
      "Ep:128, loss:0.00000, loss_test:0.11441, lr:4.66e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.669, tt:4601.307\n",
      "Ep:129, loss:0.00000, loss_test:0.11392, lr:4.61e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.665, tt:4636.402\n",
      "Ep:130, loss:0.00000, loss_test:0.11746, lr:4.57e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.647, tt:4669.792\n",
      "Ep:131, loss:0.00000, loss_test:0.11141, lr:4.52e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.647, tt:4705.348\n",
      "Ep:132, loss:0.00000, loss_test:0.11785, lr:4.48e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.642, tt:4740.428\n",
      "Ep:133, loss:0.00000, loss_test:0.11451, lr:4.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.627, tt:4774.030\n",
      "Ep:134, loss:0.00000, loss_test:0.11786, lr:4.39e-03, fs:0.68831 (r=0.535,p=0.964),  time:35.624, tt:4809.261\n",
      "Ep:135, loss:0.00000, loss_test:0.11418, lr:4.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.635, tt:4846.313\n",
      "Ep:136, loss:0.00000, loss_test:0.11525, lr:4.30e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.620, tt:4879.906\n",
      "Ep:137, loss:0.00000, loss_test:0.11651, lr:4.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.607, tt:4913.817\n",
      "Ep:138, loss:0.00000, loss_test:0.11775, lr:4.21e-03, fs:0.68831 (r=0.535,p=0.964),  time:35.594, tt:4947.540\n",
      "Ep:139, loss:0.00000, loss_test:0.11616, lr:4.17e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.577, tt:4980.732\n",
      "Ep:140, loss:0.00000, loss_test:0.11574, lr:4.13e-03, fs:0.68831 (r=0.535,p=0.964),  time:35.573, tt:5015.848\n",
      "Ep:141, loss:0.00000, loss_test:0.11252, lr:4.09e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.562, tt:5049.817\n",
      "Ep:142, loss:0.00000, loss_test:0.11680, lr:4.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.562, tt:5085.388\n",
      "Ep:143, loss:0.00000, loss_test:0.11450, lr:4.01e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.542, tt:5118.006\n",
      "Ep:144, loss:0.00000, loss_test:0.11678, lr:3.97e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.539, tt:5153.159\n",
      "Ep:145, loss:0.00000, loss_test:0.11543, lr:3.93e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.532, tt:5187.683\n",
      "Ep:146, loss:0.00000, loss_test:0.11458, lr:3.89e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.527, tt:5222.442\n",
      "Ep:147, loss:0.00000, loss_test:0.11482, lr:3.85e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.517, tt:5256.574\n",
      "Ep:148, loss:0.00000, loss_test:0.11341, lr:3.81e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.509, tt:5290.819\n",
      "Ep:149, loss:0.00000, loss_test:0.11399, lr:3.77e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.503, tt:5325.459\n",
      "Ep:150, loss:0.00000, loss_test:0.11323, lr:3.73e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.498, tt:5360.250\n",
      "Ep:151, loss:0.00000, loss_test:0.11223, lr:3.70e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.502, tt:5396.270\n",
      "Ep:152, loss:0.00000, loss_test:0.11391, lr:3.66e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.495, tt:5430.696\n",
      "Ep:153, loss:0.00000, loss_test:0.11308, lr:3.62e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.489, tt:5465.372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00000, loss_test:0.11525, lr:3.59e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.482, tt:5499.678\n",
      "Ep:155, loss:0.00000, loss_test:0.11507, lr:3.55e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.467, tt:5532.862\n",
      "Ep:156, loss:0.00000, loss_test:0.11299, lr:3.52e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.458, tt:5566.940\n",
      "Ep:157, loss:0.00000, loss_test:0.11459, lr:3.48e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.448, tt:5600.793\n",
      "Ep:158, loss:0.00000, loss_test:0.11432, lr:3.45e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.445, tt:5635.678\n",
      "Ep:159, loss:0.00000, loss_test:0.11458, lr:3.41e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.440, tt:5670.434\n",
      "Ep:160, loss:0.00000, loss_test:0.11351, lr:3.38e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.428, tt:5703.845\n",
      "Ep:161, loss:0.00000, loss_test:0.11282, lr:3.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.425, tt:5738.893\n",
      "Ep:162, loss:0.00000, loss_test:0.11461, lr:3.31e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.415, tt:5772.713\n",
      "Ep:163, loss:0.00000, loss_test:0.11365, lr:3.28e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.408, tt:5806.987\n",
      "Ep:164, loss:0.00000, loss_test:0.11498, lr:3.24e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.402, tt:5841.353\n",
      "Ep:165, loss:0.00000, loss_test:0.11492, lr:3.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.401, tt:5876.617\n",
      "Ep:166, loss:0.00000, loss_test:0.11334, lr:3.18e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.401, tt:5912.025\n",
      "Ep:167, loss:0.00000, loss_test:0.11484, lr:3.15e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.406, tt:5948.259\n",
      "Ep:168, loss:0.00000, loss_test:0.11220, lr:3.12e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.398, tt:5982.327\n",
      "Ep:169, loss:0.00000, loss_test:0.11565, lr:3.09e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.388, tt:6015.890\n",
      "Ep:170, loss:0.00000, loss_test:0.11377, lr:3.05e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.383, tt:6050.488\n",
      "Ep:171, loss:0.00000, loss_test:0.11423, lr:3.02e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.374, tt:6084.251\n",
      "Ep:172, loss:0.00000, loss_test:0.11498, lr:2.99e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.364, tt:6117.974\n",
      "Ep:173, loss:0.00000, loss_test:0.11296, lr:2.96e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.359, tt:6152.391\n",
      "Ep:174, loss:0.00000, loss_test:0.11323, lr:2.93e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.352, tt:6186.643\n",
      "Ep:175, loss:0.00000, loss_test:0.11374, lr:2.90e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.348, tt:6221.184\n",
      "Ep:176, loss:0.00000, loss_test:0.11379, lr:2.88e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.352, tt:6257.301\n",
      "Ep:177, loss:0.00000, loss_test:0.11379, lr:2.85e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.343, tt:6291.008\n",
      "Ep:178, loss:0.00000, loss_test:0.11429, lr:2.82e-03, fs:0.68831 (r=0.535,p=0.964),  time:35.339, tt:6325.756\n",
      "Ep:179, loss:0.00000, loss_test:0.11259, lr:2.79e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.340, tt:6361.159\n",
      "Ep:180, loss:0.00000, loss_test:0.11585, lr:2.76e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.331, tt:6394.979\n",
      "Ep:181, loss:0.00000, loss_test:0.11382, lr:2.73e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.326, tt:6429.352\n",
      "Ep:182, loss:0.00000, loss_test:0.11513, lr:2.71e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.317, tt:6463.016\n",
      "Ep:183, loss:0.00000, loss_test:0.11545, lr:2.68e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.310, tt:6496.972\n",
      "Ep:184, loss:0.00000, loss_test:0.11267, lr:2.65e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.308, tt:6531.930\n",
      "Ep:185, loss:0.00000, loss_test:0.11462, lr:2.63e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.306, tt:6566.885\n",
      "Ep:186, loss:0.00000, loss_test:0.11389, lr:2.60e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.304, tt:6601.891\n",
      "Ep:187, loss:0.00000, loss_test:0.11423, lr:2.57e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.305, tt:6637.262\n",
      "Ep:188, loss:0.00000, loss_test:0.11556, lr:2.55e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.321, tt:6675.577\n",
      "Ep:189, loss:0.00000, loss_test:0.11345, lr:2.52e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.314, tt:6709.612\n",
      "Ep:190, loss:0.00000, loss_test:0.11351, lr:2.50e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.310, tt:6744.181\n",
      "Ep:191, loss:0.00000, loss_test:0.11552, lr:2.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.313, tt:6780.061\n",
      "Ep:192, loss:0.00000, loss_test:0.11458, lr:2.45e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.308, tt:6814.428\n",
      "Ep:193, loss:0.00000, loss_test:0.11358, lr:2.42e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.303, tt:6848.803\n",
      "Ep:194, loss:0.00000, loss_test:0.11521, lr:2.40e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.296, tt:6882.717\n",
      "Ep:195, loss:0.00000, loss_test:0.11452, lr:2.38e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.292, tt:6917.305\n",
      "Ep:196, loss:0.00000, loss_test:0.11377, lr:2.35e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.286, tt:6951.354\n",
      "Ep:197, loss:0.00000, loss_test:0.11491, lr:2.33e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.285, tt:6986.471\n",
      "Ep:198, loss:0.00000, loss_test:0.11457, lr:2.31e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.280, tt:7020.807\n",
      "Ep:199, loss:0.00000, loss_test:0.11399, lr:2.28e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.271, tt:7054.262\n",
      "Ep:200, loss:0.00000, loss_test:0.11482, lr:2.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.272, tt:7089.682\n",
      "Ep:201, loss:0.00000, loss_test:0.11413, lr:2.24e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.261, tt:7122.755\n",
      "Ep:202, loss:0.00000, loss_test:0.11266, lr:2.21e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.264, tt:7158.569\n",
      "Ep:203, loss:0.00000, loss_test:0.11404, lr:2.19e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.260, tt:7192.943\n",
      "Ep:204, loss:0.00000, loss_test:0.11430, lr:2.17e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.251, tt:7226.490\n",
      "Ep:205, loss:0.00000, loss_test:0.11350, lr:2.15e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.248, tt:7261.064\n",
      "Ep:206, loss:0.00000, loss_test:0.11401, lr:2.13e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.242, tt:7295.046\n",
      "Ep:207, loss:0.00000, loss_test:0.11419, lr:2.11e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.241, tt:7330.102\n",
      "Ep:208, loss:0.00000, loss_test:0.11310, lr:2.08e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.236, tt:7364.363\n",
      "Ep:209, loss:0.00000, loss_test:0.11348, lr:2.06e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.231, tt:7398.551\n",
      "Ep:210, loss:0.00000, loss_test:0.11435, lr:2.04e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.233, tt:7434.200\n",
      "Ep:211, loss:0.00000, loss_test:0.11349, lr:2.02e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.235, tt:7469.805\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.03935, lr:6.00e-02, fs:0.62136 (r=0.646,p=0.598),  time:28.125, tt:28.125\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02548, lr:6.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:26.176, tt:52.353\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02597, lr:6.00e-02, fs:0.63121 (r=0.899,p=0.486),  time:25.497, tt:76.490\n",
      "Ep:3, loss:0.00005, loss_test:0.02629, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:25.854, tt:103.416\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02594, lr:6.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:27.145, tt:135.723\n",
      "Ep:5, loss:0.00005, loss_test:0.02591, lr:6.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:27.862, tt:167.171\n",
      "Ep:6, loss:0.00005, loss_test:0.02612, lr:6.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:28.522, tt:199.653\n",
      "Ep:7, loss:0.00005, loss_test:0.02605, lr:6.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:29.119, tt:232.949\n",
      "Ep:8, loss:0.00005, loss_test:0.02560, lr:6.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:29.694, tt:267.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:30.454, tt:304.545\n",
      "Ep:10, loss:0.00005, loss_test:0.02437, lr:6.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:30.799, tt:338.794\n",
      "Ep:11, loss:0.00005, loss_test:0.02368, lr:6.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:31.159, tt:373.910\n",
      "Ep:12, loss:0.00004, loss_test:0.02300, lr:6.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:31.420, tt:408.456\n",
      "Ep:13, loss:0.00004, loss_test:0.02244, lr:6.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:31.612, tt:442.573\n",
      "Ep:14, loss:0.00004, loss_test:0.02188, lr:6.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:31.846, tt:477.686\n",
      "Ep:15, loss:0.00004, loss_test:0.02131, lr:5.94e-02, fs:0.65323 (r=0.818,p=0.544),  time:31.958, tt:511.322\n",
      "Ep:16, loss:0.00004, loss_test:0.02075, lr:5.88e-02, fs:0.64000 (r=0.808,p=0.530),  time:32.022, tt:544.381\n",
      "Ep:17, loss:0.00004, loss_test:0.02011, lr:5.82e-02, fs:0.65060 (r=0.818,p=0.540),  time:32.101, tt:577.821\n",
      "Ep:18, loss:0.00004, loss_test:0.01952, lr:5.76e-02, fs:0.65060 (r=0.818,p=0.540),  time:32.234, tt:612.443\n",
      "Ep:19, loss:0.00004, loss_test:0.01905, lr:5.71e-02, fs:0.65323 (r=0.818,p=0.544),  time:32.378, tt:647.555\n",
      "Ep:20, loss:0.00003, loss_test:0.01883, lr:5.65e-02, fs:0.67500 (r=0.818,p=0.574),  time:32.468, tt:681.836\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01856, lr:5.65e-02, fs:0.66946 (r=0.808,p=0.571),  time:32.541, tt:715.911\n",
      "Ep:22, loss:0.00003, loss_test:0.01815, lr:5.65e-02, fs:0.66949 (r=0.798,p=0.577),  time:32.588, tt:749.534\n",
      "Ep:23, loss:0.00003, loss_test:0.01772, lr:5.65e-02, fs:0.67511 (r=0.808,p=0.580),  time:32.715, tt:785.169\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01737, lr:5.65e-02, fs:0.69565 (r=0.808,p=0.611),  time:32.809, tt:820.224\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01710, lr:5.65e-02, fs:0.71429 (r=0.808,p=0.640),  time:32.895, tt:855.279\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01679, lr:5.65e-02, fs:0.71749 (r=0.808,p=0.645),  time:32.928, tt:889.060\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01650, lr:5.65e-02, fs:0.72000 (r=0.818,p=0.643),  time:32.985, tt:923.592\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01635, lr:5.65e-02, fs:0.72973 (r=0.818,p=0.659),  time:33.071, tt:959.073\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01606, lr:5.65e-02, fs:0.74074 (r=0.808,p=0.684),  time:33.136, tt:994.072\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01557, lr:5.65e-02, fs:0.75349 (r=0.818,p=0.698),  time:33.188, tt:1028.840\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01526, lr:5.65e-02, fs:0.76498 (r=0.838,p=0.703),  time:33.267, tt:1064.559\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01503, lr:5.65e-02, fs:0.76279 (r=0.828,p=0.707),  time:33.287, tt:1098.458\n",
      "Ep:33, loss:0.00002, loss_test:0.01494, lr:5.65e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.294, tt:1132.007\n",
      "Ep:34, loss:0.00002, loss_test:0.01466, lr:5.65e-02, fs:0.76852 (r=0.838,p=0.709),  time:33.306, tt:1165.709\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01453, lr:5.65e-02, fs:0.76777 (r=0.818,p=0.723),  time:33.339, tt:1200.196\n",
      "Ep:36, loss:0.00002, loss_test:0.01449, lr:5.65e-02, fs:0.78261 (r=0.818,p=0.750),  time:33.365, tt:1234.512\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01425, lr:5.65e-02, fs:0.77885 (r=0.818,p=0.743),  time:33.380, tt:1268.443\n",
      "Ep:38, loss:0.00002, loss_test:0.01421, lr:5.65e-02, fs:0.78261 (r=0.818,p=0.750),  time:33.404, tt:1302.767\n",
      "Ep:39, loss:0.00002, loss_test:0.01428, lr:5.65e-02, fs:0.78431 (r=0.808,p=0.762),  time:33.432, tt:1337.268\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01436, lr:5.65e-02, fs:0.77833 (r=0.798,p=0.760),  time:33.460, tt:1371.863\n",
      "Ep:41, loss:0.00002, loss_test:0.01434, lr:5.65e-02, fs:0.77833 (r=0.798,p=0.760),  time:33.498, tt:1406.925\n",
      "Ep:42, loss:0.00001, loss_test:0.01443, lr:5.65e-02, fs:0.78000 (r=0.788,p=0.772),  time:33.500, tt:1440.515\n",
      "Ep:43, loss:0.00001, loss_test:0.01441, lr:5.65e-02, fs:0.78788 (r=0.788,p=0.788),  time:33.521, tt:1474.937\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01459, lr:5.65e-02, fs:0.78173 (r=0.778,p=0.786),  time:33.544, tt:1509.492\n",
      "Ep:45, loss:0.00001, loss_test:0.01472, lr:5.65e-02, fs:0.77320 (r=0.758,p=0.789),  time:33.547, tt:1543.143\n",
      "Ep:46, loss:0.00001, loss_test:0.01466, lr:5.65e-02, fs:0.76923 (r=0.758,p=0.781),  time:33.560, tt:1577.337\n",
      "Ep:47, loss:0.00001, loss_test:0.01473, lr:5.65e-02, fs:0.77320 (r=0.758,p=0.789),  time:33.578, tt:1611.723\n",
      "Ep:48, loss:0.00001, loss_test:0.01483, lr:5.65e-02, fs:0.76289 (r=0.747,p=0.779),  time:33.608, tt:1646.779\n",
      "Ep:49, loss:0.00001, loss_test:0.01494, lr:5.65e-02, fs:0.76289 (r=0.747,p=0.779),  time:33.644, tt:1682.210\n",
      "Ep:50, loss:0.00001, loss_test:0.01494, lr:5.65e-02, fs:0.76923 (r=0.758,p=0.781),  time:33.665, tt:1716.901\n",
      "Ep:51, loss:0.00001, loss_test:0.01527, lr:5.65e-02, fs:0.75132 (r=0.717,p=0.789),  time:33.677, tt:1751.213\n",
      "Ep:52, loss:0.00001, loss_test:0.01552, lr:5.65e-02, fs:0.74468 (r=0.707,p=0.787),  time:33.711, tt:1786.676\n",
      "Ep:53, loss:0.00001, loss_test:0.01577, lr:5.65e-02, fs:0.74468 (r=0.707,p=0.787),  time:33.748, tt:1822.381\n",
      "Ep:54, loss:0.00001, loss_test:0.01595, lr:5.65e-02, fs:0.74468 (r=0.707,p=0.787),  time:33.789, tt:1858.400\n",
      "Ep:55, loss:0.00001, loss_test:0.01640, lr:5.59e-02, fs:0.74866 (r=0.707,p=0.795),  time:33.819, tt:1893.854\n",
      "Ep:56, loss:0.00001, loss_test:0.01677, lr:5.54e-02, fs:0.74194 (r=0.697,p=0.793),  time:33.830, tt:1928.331\n",
      "Ep:57, loss:0.00001, loss_test:0.01677, lr:5.48e-02, fs:0.74194 (r=0.697,p=0.793),  time:33.864, tt:1964.094\n",
      "Ep:58, loss:0.00001, loss_test:0.01730, lr:5.43e-02, fs:0.73913 (r=0.687,p=0.800),  time:33.870, tt:1998.344\n",
      "Ep:59, loss:0.00001, loss_test:0.01745, lr:5.37e-02, fs:0.74033 (r=0.677,p=0.817),  time:33.905, tt:2034.284\n",
      "Ep:60, loss:0.00001, loss_test:0.01777, lr:5.32e-02, fs:0.74033 (r=0.677,p=0.817),  time:33.928, tt:2069.627\n",
      "Ep:61, loss:0.00001, loss_test:0.01798, lr:5.27e-02, fs:0.74033 (r=0.677,p=0.817),  time:33.956, tt:2105.244\n",
      "Ep:62, loss:0.00001, loss_test:0.01834, lr:5.21e-02, fs:0.74033 (r=0.677,p=0.817),  time:33.985, tt:2141.060\n",
      "Ep:63, loss:0.00001, loss_test:0.01862, lr:5.16e-02, fs:0.74444 (r=0.677,p=0.827),  time:33.986, tt:2175.075\n",
      "Ep:64, loss:0.00001, loss_test:0.01862, lr:5.11e-02, fs:0.74157 (r=0.667,p=0.835),  time:34.003, tt:2210.219\n",
      "Ep:65, loss:0.00001, loss_test:0.01916, lr:5.06e-02, fs:0.74157 (r=0.667,p=0.835),  time:34.033, tt:2246.159\n",
      "Ep:66, loss:0.00001, loss_test:0.01936, lr:5.01e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.038, tt:2280.544\n",
      "Ep:67, loss:0.00000, loss_test:0.01979, lr:4.96e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.064, tt:2316.336\n",
      "Ep:68, loss:0.00000, loss_test:0.01982, lr:4.91e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.097, tt:2352.711\n",
      "Ep:69, loss:0.00000, loss_test:0.02029, lr:4.86e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.138, tt:2389.658\n",
      "Ep:70, loss:0.00000, loss_test:0.02060, lr:4.81e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.157, tt:2425.127\n",
      "Ep:71, loss:0.00000, loss_test:0.02066, lr:4.76e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.186, tt:2461.427\n",
      "Ep:72, loss:0.00000, loss_test:0.02078, lr:4.71e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.183, tt:2495.394\n",
      "Ep:73, loss:0.00000, loss_test:0.02108, lr:4.67e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.202, tt:2530.943\n",
      "Ep:74, loss:0.00000, loss_test:0.02157, lr:4.62e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.217, tt:2566.311\n",
      "Ep:75, loss:0.00000, loss_test:0.02173, lr:4.57e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.232, tt:2601.657\n",
      "Ep:76, loss:0.00000, loss_test:0.02186, lr:4.53e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.244, tt:2636.825\n",
      "Ep:77, loss:0.00000, loss_test:0.02219, lr:4.48e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.277, tt:2673.605\n",
      "Ep:78, loss:0.00000, loss_test:0.02250, lr:4.44e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.293, tt:2709.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00000, loss_test:0.02270, lr:4.39e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.303, tt:2744.206\n",
      "Ep:80, loss:0.00000, loss_test:0.02292, lr:4.35e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.310, tt:2779.086\n",
      "Ep:81, loss:0.00000, loss_test:0.02304, lr:4.31e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.309, tt:2813.340\n",
      "Ep:82, loss:0.00000, loss_test:0.02337, lr:4.26e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.314, tt:2848.081\n",
      "Ep:83, loss:0.00000, loss_test:0.02359, lr:4.22e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.326, tt:2883.385\n",
      "Ep:84, loss:0.00000, loss_test:0.02374, lr:4.18e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.348, tt:2919.601\n",
      "Ep:85, loss:0.00000, loss_test:0.02385, lr:4.14e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.353, tt:2954.382\n",
      "Ep:86, loss:0.00000, loss_test:0.02402, lr:4.10e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.339, tt:2987.478\n",
      "Ep:87, loss:0.00000, loss_test:0.02421, lr:4.05e-02, fs:0.67081 (r=0.545,p=0.871),  time:34.346, tt:3022.486\n",
      "Ep:88, loss:0.00000, loss_test:0.02422, lr:4.01e-02, fs:0.67901 (r=0.556,p=0.873),  time:34.362, tt:3058.218\n",
      "Ep:89, loss:0.00000, loss_test:0.02458, lr:3.97e-02, fs:0.67081 (r=0.545,p=0.871),  time:34.362, tt:3092.604\n",
      "Ep:90, loss:0.00000, loss_test:0.02460, lr:3.93e-02, fs:0.66667 (r=0.535,p=0.883),  time:34.387, tt:3129.204\n",
      "Ep:91, loss:0.00000, loss_test:0.02492, lr:3.89e-02, fs:0.67500 (r=0.545,p=0.885),  time:34.399, tt:3164.737\n",
      "Ep:92, loss:0.00000, loss_test:0.02505, lr:3.86e-02, fs:0.66667 (r=0.535,p=0.883),  time:34.449, tt:3203.769\n",
      "Ep:93, loss:0.00000, loss_test:0.02518, lr:3.82e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.468, tt:3239.982\n",
      "Ep:94, loss:0.00000, loss_test:0.02529, lr:3.78e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.484, tt:3275.944\n",
      "Ep:95, loss:0.00000, loss_test:0.02546, lr:3.74e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.491, tt:3311.156\n",
      "Ep:96, loss:0.00000, loss_test:0.02570, lr:3.70e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.506, tt:3347.047\n",
      "Ep:97, loss:0.00000, loss_test:0.02573, lr:3.67e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.522, tt:3383.144\n",
      "Ep:98, loss:0.00000, loss_test:0.02585, lr:3.63e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.530, tt:3418.430\n",
      "Ep:99, loss:0.00000, loss_test:0.02597, lr:3.59e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.545, tt:3454.499\n",
      "Ep:100, loss:0.00000, loss_test:0.02623, lr:3.56e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.569, tt:3491.439\n",
      "Ep:101, loss:0.00000, loss_test:0.02619, lr:3.52e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.595, tt:3528.666\n",
      "Ep:102, loss:0.00000, loss_test:0.02625, lr:3.49e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.603, tt:3564.157\n",
      "Ep:103, loss:0.00000, loss_test:0.02640, lr:3.45e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.613, tt:3599.715\n",
      "Ep:104, loss:0.00000, loss_test:0.02658, lr:3.42e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.628, tt:3635.947\n",
      "Ep:105, loss:0.00000, loss_test:0.02657, lr:3.38e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.636, tt:3671.455\n",
      "Ep:106, loss:0.00000, loss_test:0.02672, lr:3.35e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.638, tt:3706.288\n",
      "Ep:107, loss:0.00000, loss_test:0.02677, lr:3.32e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.648, tt:3742.009\n",
      "Ep:108, loss:0.00000, loss_test:0.02692, lr:3.28e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.672, tt:3779.197\n",
      "Ep:109, loss:0.00000, loss_test:0.02693, lr:3.25e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.680, tt:3814.790\n",
      "Ep:110, loss:0.00000, loss_test:0.02705, lr:3.22e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.699, tt:3851.608\n",
      "Ep:111, loss:0.00000, loss_test:0.02722, lr:3.19e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.713, tt:3887.815\n",
      "Ep:112, loss:0.00000, loss_test:0.02709, lr:3.15e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.722, tt:3923.534\n",
      "Ep:113, loss:0.00000, loss_test:0.02726, lr:3.12e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.723, tt:3958.460\n",
      "Ep:114, loss:0.00000, loss_test:0.02743, lr:3.09e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.729, tt:3993.787\n",
      "Ep:115, loss:0.00000, loss_test:0.02739, lr:3.06e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.743, tt:4030.175\n",
      "Ep:116, loss:0.00000, loss_test:0.02749, lr:3.03e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.734, tt:4063.892\n",
      "Ep:117, loss:0.00000, loss_test:0.02750, lr:3.00e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.744, tt:4099.753\n",
      "Ep:118, loss:0.00000, loss_test:0.02764, lr:2.97e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.752, tt:4135.478\n",
      "Ep:119, loss:0.00000, loss_test:0.02768, lr:2.94e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.754, tt:4170.495\n",
      "Ep:120, loss:0.00000, loss_test:0.02764, lr:2.91e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.760, tt:4205.990\n",
      "Ep:121, loss:0.00000, loss_test:0.02776, lr:2.88e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.759, tt:4240.575\n",
      "Ep:122, loss:0.00000, loss_test:0.02778, lr:2.85e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.772, tt:4276.923\n",
      "Ep:123, loss:0.00000, loss_test:0.02791, lr:2.82e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.778, tt:4312.532\n",
      "Ep:124, loss:0.00000, loss_test:0.02797, lr:2.80e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.793, tt:4349.107\n",
      "Ep:125, loss:0.00000, loss_test:0.02799, lr:2.77e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.803, tt:4385.136\n",
      "Ep:126, loss:0.00000, loss_test:0.02805, lr:2.74e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.817, tt:4421.708\n",
      "Ep:127, loss:0.00000, loss_test:0.02812, lr:2.71e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.823, tt:4457.365\n",
      "Ep:128, loss:0.00000, loss_test:0.02821, lr:2.69e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.825, tt:4492.419\n",
      "Ep:129, loss:0.00000, loss_test:0.02822, lr:2.66e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.826, tt:4527.414\n",
      "Ep:130, loss:0.00000, loss_test:0.02829, lr:2.63e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.825, tt:4562.034\n",
      "Ep:131, loss:0.00000, loss_test:0.02832, lr:2.61e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.839, tt:4598.721\n",
      "Ep:132, loss:0.00000, loss_test:0.02833, lr:2.58e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.844, tt:4634.259\n",
      "Ep:133, loss:0.00000, loss_test:0.02843, lr:2.55e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.855, tt:4670.598\n",
      "Ep:134, loss:0.00000, loss_test:0.02844, lr:2.53e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.860, tt:4706.140\n",
      "Ep:135, loss:0.00000, loss_test:0.02852, lr:2.50e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.859, tt:4740.769\n",
      "Ep:136, loss:0.00000, loss_test:0.02861, lr:2.48e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.868, tt:4776.973\n",
      "Ep:137, loss:0.00000, loss_test:0.02854, lr:2.45e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.874, tt:4812.654\n",
      "Ep:138, loss:0.00000, loss_test:0.02853, lr:2.43e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.890, tt:4849.678\n",
      "Ep:139, loss:0.00000, loss_test:0.02869, lr:2.40e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.891, tt:4884.762\n",
      "Ep:140, loss:0.00000, loss_test:0.02870, lr:2.38e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.899, tt:4920.695\n",
      "Ep:141, loss:0.00000, loss_test:0.02871, lr:2.36e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.905, tt:4956.458\n",
      "Ep:142, loss:0.00000, loss_test:0.02878, lr:2.33e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.908, tt:4991.891\n",
      "Ep:143, loss:0.00000, loss_test:0.02876, lr:2.31e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.901, tt:5025.803\n",
      "Ep:144, loss:0.00000, loss_test:0.02885, lr:2.29e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.914, tt:5062.494\n",
      "Ep:145, loss:0.00000, loss_test:0.02889, lr:2.26e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.928, tt:5099.500\n",
      "Ep:146, loss:0.00000, loss_test:0.02885, lr:2.24e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.941, tt:5136.297\n",
      "Ep:147, loss:0.00000, loss_test:0.02891, lr:2.22e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.959, tt:5173.907\n",
      "Ep:148, loss:0.00000, loss_test:0.02899, lr:2.20e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.971, tt:5210.690\n",
      "Ep:149, loss:0.00000, loss_test:0.02902, lr:2.17e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.985, tt:5247.800\n",
      "Ep:150, loss:0.00000, loss_test:0.02905, lr:2.15e-02, fs:0.67089 (r=0.535,p=0.898),  time:34.986, tt:5282.833\n",
      "Ep:151, loss:0.00000, loss_test:0.02908, lr:2.13e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.003, tt:5320.425\n",
      "Ep:152, loss:0.00000, loss_test:0.02909, lr:2.11e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.015, tt:5357.286\n",
      "Ep:153, loss:0.00000, loss_test:0.02913, lr:2.09e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.016, tt:5392.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00000, loss_test:0.02913, lr:2.07e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.026, tt:5429.000\n",
      "Ep:155, loss:0.00000, loss_test:0.02918, lr:2.05e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.031, tt:5464.825\n",
      "Ep:156, loss:0.00000, loss_test:0.02924, lr:2.03e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.035, tt:5500.457\n",
      "Ep:157, loss:0.00000, loss_test:0.02923, lr:2.01e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.041, tt:5536.404\n",
      "Ep:158, loss:0.00000, loss_test:0.02922, lr:1.99e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.043, tt:5571.834\n",
      "Ep:159, loss:0.00000, loss_test:0.02930, lr:1.97e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.036, tt:5605.795\n",
      "Ep:160, loss:0.00000, loss_test:0.02933, lr:1.95e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.044, tt:5642.146\n",
      "Ep:161, loss:0.00000, loss_test:0.02930, lr:1.93e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.047, tt:5677.639\n",
      "Ep:162, loss:0.00000, loss_test:0.02934, lr:1.91e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.055, tt:5714.033\n",
      "Ep:163, loss:0.00000, loss_test:0.02942, lr:1.89e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.060, tt:5749.762\n",
      "Ep:164, loss:0.00000, loss_test:0.02940, lr:1.87e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.055, tt:5784.044\n",
      "Ep:165, loss:0.00000, loss_test:0.02942, lr:1.85e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.055, tt:5819.185\n",
      "Ep:166, loss:0.00000, loss_test:0.02947, lr:1.83e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.057, tt:5854.540\n",
      "Ep:167, loss:0.00000, loss_test:0.02945, lr:1.81e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.063, tt:5890.544\n",
      "Ep:168, loss:0.00000, loss_test:0.02950, lr:1.80e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.067, tt:5926.333\n",
      "Ep:169, loss:0.00000, loss_test:0.02951, lr:1.78e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.074, tt:5962.558\n",
      "Ep:170, loss:0.00000, loss_test:0.02952, lr:1.76e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.079, tt:5998.508\n",
      "Ep:171, loss:0.00000, loss_test:0.02953, lr:1.74e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.081, tt:6033.991\n",
      "Ep:172, loss:0.00000, loss_test:0.02960, lr:1.73e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.085, tt:6069.781\n",
      "Ep:173, loss:0.00000, loss_test:0.02957, lr:1.71e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.087, tt:6105.216\n",
      "Ep:174, loss:0.00000, loss_test:0.02953, lr:1.69e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.086, tt:6140.043\n",
      "Ep:175, loss:0.00000, loss_test:0.02963, lr:1.67e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.088, tt:6175.435\n",
      "Ep:176, loss:0.00000, loss_test:0.02963, lr:1.66e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.089, tt:6210.714\n",
      "Ep:177, loss:0.00000, loss_test:0.02964, lr:1.64e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.093, tt:6246.573\n",
      "Ep:178, loss:0.00000, loss_test:0.02968, lr:1.62e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.101, tt:6283.066\n",
      "Ep:179, loss:0.00000, loss_test:0.02968, lr:1.61e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.108, tt:6319.378\n",
      "Ep:180, loss:0.00000, loss_test:0.02968, lr:1.59e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.107, tt:6354.348\n",
      "Ep:181, loss:0.00000, loss_test:0.02974, lr:1.58e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.103, tt:6388.829\n",
      "Ep:182, loss:0.00000, loss_test:0.02975, lr:1.56e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.108, tt:6424.703\n",
      "Ep:183, loss:0.00000, loss_test:0.02975, lr:1.54e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.107, tt:6459.749\n",
      "Ep:184, loss:0.00000, loss_test:0.02978, lr:1.53e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.109, tt:6495.223\n",
      "Ep:185, loss:0.00000, loss_test:0.02981, lr:1.51e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.117, tt:6531.836\n",
      "Ep:186, loss:0.00000, loss_test:0.02983, lr:1.50e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.116, tt:6566.663\n",
      "Ep:187, loss:0.00000, loss_test:0.02983, lr:1.48e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.106, tt:6599.913\n",
      "Ep:188, loss:0.00000, loss_test:0.02982, lr:1.47e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.107, tt:6635.288\n",
      "Ep:189, loss:0.00000, loss_test:0.02987, lr:1.45e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.115, tt:6671.868\n",
      "Ep:190, loss:0.00000, loss_test:0.02990, lr:1.44e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.133, tt:6710.484\n",
      "Ep:191, loss:0.00000, loss_test:0.02989, lr:1.43e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.139, tt:6746.678\n",
      "Ep:192, loss:0.00000, loss_test:0.02991, lr:1.41e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.154, tt:6784.706\n",
      "Ep:193, loss:0.00000, loss_test:0.02994, lr:1.40e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.157, tt:6820.512\n",
      "Ep:194, loss:0.00000, loss_test:0.02992, lr:1.38e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.149, tt:6854.109\n",
      "Ep:195, loss:0.00000, loss_test:0.02994, lr:1.37e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.148, tt:6888.937\n",
      "Ep:196, loss:0.00000, loss_test:0.02998, lr:1.36e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.149, tt:6924.265\n",
      "Ep:197, loss:0.00000, loss_test:0.02998, lr:1.34e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.141, tt:6957.905\n",
      "Ep:198, loss:0.00000, loss_test:0.03000, lr:1.33e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.132, tt:6991.293\n",
      "Ep:199, loss:0.00000, loss_test:0.03002, lr:1.32e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.121, tt:7024.214\n",
      "Ep:200, loss:0.00000, loss_test:0.03002, lr:1.30e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.122, tt:7059.458\n",
      "Ep:201, loss:0.00000, loss_test:0.03003, lr:1.29e-02, fs:0.67089 (r=0.535,p=0.898),  time:35.106, tt:7091.490\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14189, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:33.012, tt:33.012\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14000, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:33.181, tt:66.362\n",
      "Ep:2, loss:0.00026, loss_test:0.13802, lr:1.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:31.906, tt:95.718\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13675, lr:1.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:31.609, tt:126.437\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13605, lr:1.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:32.270, tt:161.351\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.13567, lr:1.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:32.961, tt:197.764\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.13546, lr:1.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:33.216, tt:232.515\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.13527, lr:1.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:33.577, tt:268.613\n",
      "Ep:8, loss:0.00025, loss_test:0.13495, lr:1.00e-02, fs:0.64542 (r=0.818,p=0.533),  time:33.807, tt:304.262\n",
      "Ep:9, loss:0.00025, loss_test:0.13451, lr:1.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:33.861, tt:338.606\n",
      "Ep:10, loss:0.00025, loss_test:0.13401, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:33.929, tt:373.223\n",
      "Ep:11, loss:0.00025, loss_test:0.13358, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:34.009, tt:408.109\n",
      "Ep:12, loss:0.00025, loss_test:0.13323, lr:1.00e-02, fs:0.63200 (r=0.798,p=0.523),  time:34.016, tt:442.207\n",
      "Ep:13, loss:0.00025, loss_test:0.13284, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:34.015, tt:476.212\n",
      "Ep:14, loss:0.00025, loss_test:0.13235, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:34.171, tt:512.568\n",
      "Ep:15, loss:0.00024, loss_test:0.13185, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:34.189, tt:547.019\n",
      "Ep:16, loss:0.00024, loss_test:0.13141, lr:1.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:34.455, tt:585.738\n",
      "Ep:17, loss:0.00024, loss_test:0.13089, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:34.481, tt:620.656\n",
      "Ep:18, loss:0.00024, loss_test:0.13023, lr:9.90e-03, fs:0.63673 (r=0.788,p=0.534),  time:34.493, tt:655.364\n",
      "Ep:19, loss:0.00024, loss_test:0.12954, lr:9.80e-03, fs:0.63115 (r=0.778,p=0.531),  time:34.554, tt:691.075\n",
      "Ep:20, loss:0.00024, loss_test:0.12878, lr:9.70e-03, fs:0.63115 (r=0.778,p=0.531),  time:34.657, tt:727.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00024, loss_test:0.12795, lr:9.61e-03, fs:0.62810 (r=0.768,p=0.531),  time:34.677, tt:762.889\n",
      "Ep:22, loss:0.00023, loss_test:0.12697, lr:9.51e-03, fs:0.62810 (r=0.768,p=0.531),  time:34.718, tt:798.515\n",
      "Ep:23, loss:0.00023, loss_test:0.12592, lr:9.41e-03, fs:0.63071 (r=0.768,p=0.535),  time:34.787, tt:834.888\n",
      "Ep:24, loss:0.00023, loss_test:0.12471, lr:9.32e-03, fs:0.63071 (r=0.768,p=0.535),  time:34.798, tt:869.947\n",
      "Ep:25, loss:0.00023, loss_test:0.12331, lr:9.23e-03, fs:0.63291 (r=0.758,p=0.543),  time:34.834, tt:905.679\n",
      "Ep:26, loss:0.00022, loss_test:0.12174, lr:9.14e-03, fs:0.63291 (r=0.758,p=0.543),  time:34.969, tt:944.154\n",
      "Ep:27, loss:0.00022, loss_test:0.12010, lr:9.04e-03, fs:0.64135 (r=0.768,p=0.551),  time:34.983, tt:979.526\n",
      "Ep:28, loss:0.00022, loss_test:0.11830, lr:8.95e-03, fs:0.64135 (r=0.768,p=0.551),  time:34.949, tt:1013.526\n",
      "Ep:29, loss:0.00021, loss_test:0.11641, lr:8.86e-03, fs:0.64979 (r=0.778,p=0.558),  time:34.967, tt:1049.006\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00021, loss_test:0.11432, lr:8.86e-03, fs:0.65532 (r=0.778,p=0.566),  time:34.984, tt:1084.514\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00020, loss_test:0.11143, lr:8.86e-03, fs:0.66667 (r=0.778,p=0.583),  time:35.001, tt:1120.036\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00020, loss_test:0.10839, lr:8.86e-03, fs:0.68421 (r=0.788,p=0.605),  time:35.038, tt:1156.243\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00019, loss_test:0.10545, lr:8.86e-03, fs:0.69333 (r=0.788,p=0.619),  time:35.062, tt:1192.119\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00018, loss_test:0.10254, lr:8.86e-03, fs:0.70536 (r=0.798,p=0.632),  time:35.148, tt:1230.168\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00018, loss_test:0.09962, lr:8.86e-03, fs:0.71560 (r=0.788,p=0.655),  time:35.219, tt:1267.867\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00017, loss_test:0.09724, lr:8.86e-03, fs:0.73488 (r=0.798,p=0.681),  time:35.250, tt:1304.232\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00016, loss_test:0.09428, lr:8.86e-03, fs:0.72906 (r=0.747,p=0.712),  time:35.223, tt:1338.477\n",
      "Ep:38, loss:0.00015, loss_test:0.09337, lr:8.86e-03, fs:0.73096 (r=0.727,p=0.735),  time:35.250, tt:1374.759\n",
      "Ep:39, loss:0.00015, loss_test:0.09258, lr:8.86e-03, fs:0.71921 (r=0.737,p=0.702),  time:35.261, tt:1410.428\n",
      "Ep:40, loss:0.00014, loss_test:0.09001, lr:8.86e-03, fs:0.73267 (r=0.747,p=0.718),  time:35.267, tt:1445.953\n",
      "Ep:41, loss:0.00013, loss_test:0.08932, lr:8.86e-03, fs:0.74112 (r=0.737,p=0.745),  time:35.304, tt:1482.759\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00013, loss_test:0.08933, lr:8.86e-03, fs:0.75132 (r=0.717,p=0.789),  time:35.323, tt:1518.891\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00012, loss_test:0.08607, lr:8.86e-03, fs:0.75622 (r=0.768,p=0.745),  time:35.311, tt:1553.683\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00011, loss_test:0.08523, lr:8.86e-03, fs:0.77487 (r=0.747,p=0.804),  time:35.326, tt:1589.689\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.08210, lr:8.86e-03, fs:0.77157 (r=0.768,p=0.776),  time:35.353, tt:1626.259\n",
      "Ep:46, loss:0.00010, loss_test:0.07879, lr:8.86e-03, fs:0.79793 (r=0.778,p=0.819),  time:35.366, tt:1662.195\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.07871, lr:8.86e-03, fs:0.78947 (r=0.758,p=0.824),  time:35.394, tt:1698.891\n",
      "Ep:48, loss:0.00008, loss_test:0.07635, lr:8.86e-03, fs:0.79365 (r=0.758,p=0.833),  time:35.408, tt:1734.982\n",
      "Ep:49, loss:0.00008, loss_test:0.07863, lr:8.86e-03, fs:0.78261 (r=0.727,p=0.847),  time:35.429, tt:1771.470\n",
      "Ep:50, loss:0.00007, loss_test:0.07650, lr:8.86e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.453, tt:1808.121\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.07591, lr:8.86e-03, fs:0.81081 (r=0.758,p=0.872),  time:35.474, tt:1844.647\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.07529, lr:8.86e-03, fs:0.82353 (r=0.778,p=0.875),  time:35.481, tt:1880.469\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.07461, lr:8.86e-03, fs:0.78212 (r=0.707,p=0.875),  time:35.454, tt:1914.532\n",
      "Ep:54, loss:0.00006, loss_test:0.07392, lr:8.86e-03, fs:0.80000 (r=0.768,p=0.835),  time:35.453, tt:1949.897\n",
      "Ep:55, loss:0.00005, loss_test:0.07545, lr:8.86e-03, fs:0.77778 (r=0.707,p=0.864),  time:35.463, tt:1985.938\n",
      "Ep:56, loss:0.00005, loss_test:0.07076, lr:8.86e-03, fs:0.83060 (r=0.768,p=0.905),  time:35.469, tt:2021.755\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.07539, lr:8.86e-03, fs:0.76023 (r=0.657,p=0.903),  time:35.454, tt:2056.316\n",
      "Ep:58, loss:0.00004, loss_test:0.07356, lr:8.86e-03, fs:0.80628 (r=0.778,p=0.837),  time:35.460, tt:2092.148\n",
      "Ep:59, loss:0.00004, loss_test:0.07065, lr:8.86e-03, fs:0.82873 (r=0.758,p=0.915),  time:35.484, tt:2129.028\n",
      "Ep:60, loss:0.00004, loss_test:0.07157, lr:8.86e-03, fs:0.83243 (r=0.778,p=0.895),  time:35.468, tt:2163.523\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.07598, lr:8.86e-03, fs:0.71515 (r=0.596,p=0.894),  time:35.477, tt:2199.549\n",
      "Ep:62, loss:0.00003, loss_test:0.07206, lr:8.86e-03, fs:0.82418 (r=0.758,p=0.904),  time:35.496, tt:2236.277\n",
      "Ep:63, loss:0.00003, loss_test:0.07766, lr:8.86e-03, fs:0.69512 (r=0.576,p=0.877),  time:35.503, tt:2272.185\n",
      "Ep:64, loss:0.00003, loss_test:0.07188, lr:8.86e-03, fs:0.77011 (r=0.677,p=0.893),  time:35.528, tt:2309.351\n",
      "Ep:65, loss:0.00003, loss_test:0.07833, lr:8.86e-03, fs:0.70732 (r=0.586,p=0.892),  time:35.523, tt:2344.519\n",
      "Ep:66, loss:0.00003, loss_test:0.07580, lr:8.86e-03, fs:0.74556 (r=0.636,p=0.900),  time:35.508, tt:2379.020\n",
      "Ep:67, loss:0.00003, loss_test:0.07252, lr:8.86e-03, fs:0.78857 (r=0.697,p=0.908),  time:35.512, tt:2414.845\n",
      "Ep:68, loss:0.00002, loss_test:0.07529, lr:8.86e-03, fs:0.77907 (r=0.677,p=0.918),  time:35.490, tt:2448.817\n",
      "Ep:69, loss:0.00002, loss_test:0.07733, lr:8.86e-03, fs:0.75000 (r=0.636,p=0.913),  time:35.490, tt:2484.312\n",
      "Ep:70, loss:0.00002, loss_test:0.07686, lr:8.86e-03, fs:0.70000 (r=0.566,p=0.918),  time:35.491, tt:2519.873\n",
      "Ep:71, loss:0.00002, loss_test:0.07782, lr:8.86e-03, fs:0.71951 (r=0.596,p=0.908),  time:35.473, tt:2554.073\n",
      "Ep:72, loss:0.00002, loss_test:0.08151, lr:8.78e-03, fs:0.67925 (r=0.545,p=0.900),  time:35.456, tt:2588.282\n",
      "Ep:73, loss:0.00002, loss_test:0.07603, lr:8.69e-03, fs:0.72727 (r=0.606,p=0.909),  time:35.476, tt:2625.221\n",
      "Ep:74, loss:0.00002, loss_test:0.08218, lr:8.60e-03, fs:0.67516 (r=0.535,p=0.914),  time:35.456, tt:2659.189\n",
      "Ep:75, loss:0.00002, loss_test:0.07558, lr:8.51e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.446, tt:2693.933\n",
      "Ep:76, loss:0.00002, loss_test:0.08445, lr:8.43e-03, fs:0.70807 (r=0.576,p=0.919),  time:35.451, tt:2729.751\n",
      "Ep:77, loss:0.00002, loss_test:0.08113, lr:8.35e-03, fs:0.70000 (r=0.566,p=0.918),  time:35.445, tt:2764.735\n",
      "Ep:78, loss:0.00001, loss_test:0.08150, lr:8.26e-03, fs:0.71605 (r=0.586,p=0.921),  time:35.433, tt:2799.183\n",
      "Ep:79, loss:0.00001, loss_test:0.09194, lr:8.18e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.407, tt:2832.589\n",
      "Ep:80, loss:0.00001, loss_test:0.07802, lr:8.10e-03, fs:0.75000 (r=0.636,p=0.913),  time:35.381, tt:2865.852\n",
      "Ep:81, loss:0.00001, loss_test:0.08662, lr:8.02e-03, fs:0.67516 (r=0.535,p=0.914),  time:35.368, tt:2900.178\n",
      "Ep:82, loss:0.00001, loss_test:0.08091, lr:7.94e-03, fs:0.73939 (r=0.616,p=0.924),  time:35.362, tt:2935.076\n",
      "Ep:83, loss:0.00001, loss_test:0.08495, lr:7.86e-03, fs:0.69620 (r=0.556,p=0.932),  time:35.350, tt:2969.399\n",
      "Ep:84, loss:0.00001, loss_test:0.08646, lr:7.78e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.330, tt:3003.066\n",
      "Ep:85, loss:0.00001, loss_test:0.08460, lr:7.70e-03, fs:0.73939 (r=0.616,p=0.924),  time:35.339, tt:3039.156\n",
      "Ep:86, loss:0.00001, loss_test:0.09134, lr:7.62e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.349, tt:3075.320\n",
      "Ep:87, loss:0.00001, loss_test:0.08680, lr:7.55e-03, fs:0.68790 (r=0.545,p=0.931),  time:35.337, tt:3109.620\n",
      "Ep:88, loss:0.00001, loss_test:0.08386, lr:7.47e-03, fs:0.75904 (r=0.636,p=0.940),  time:35.350, tt:3146.176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00001, loss_test:0.08763, lr:7.40e-03, fs:0.67949 (r=0.535,p=0.930),  time:35.335, tt:3180.135\n",
      "Ep:90, loss:0.00001, loss_test:0.08392, lr:7.32e-03, fs:0.70000 (r=0.566,p=0.918),  time:35.316, tt:3213.796\n",
      "Ep:91, loss:0.00001, loss_test:0.08943, lr:7.25e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.319, tt:3249.358\n",
      "Ep:92, loss:0.00001, loss_test:0.08443, lr:7.18e-03, fs:0.69620 (r=0.556,p=0.932),  time:35.321, tt:3284.829\n",
      "Ep:93, loss:0.00001, loss_test:0.08941, lr:7.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.333, tt:3321.341\n",
      "Ep:94, loss:0.00001, loss_test:0.08645, lr:7.03e-03, fs:0.70440 (r=0.566,p=0.933),  time:35.366, tt:3359.785\n",
      "Ep:95, loss:0.00001, loss_test:0.08829, lr:6.96e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.396, tt:3398.056\n",
      "Ep:96, loss:0.00001, loss_test:0.08677, lr:6.89e-03, fs:0.70440 (r=0.566,p=0.933),  time:35.423, tt:3436.056\n",
      "Ep:97, loss:0.00001, loss_test:0.08693, lr:6.83e-03, fs:0.69231 (r=0.545,p=0.947),  time:35.442, tt:3473.324\n",
      "Ep:98, loss:0.00001, loss_test:0.08528, lr:6.76e-03, fs:0.70886 (r=0.566,p=0.949),  time:35.444, tt:3508.952\n",
      "Ep:99, loss:0.00001, loss_test:0.08966, lr:6.69e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.447, tt:3544.687\n",
      "Ep:100, loss:0.00001, loss_test:0.08441, lr:6.62e-03, fs:0.70886 (r=0.566,p=0.949),  time:35.467, tt:3582.130\n",
      "Ep:101, loss:0.00001, loss_test:0.09075, lr:6.56e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.503, tt:3621.298\n",
      "Ep:102, loss:0.00001, loss_test:0.08747, lr:6.49e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.555, tt:3662.182\n",
      "Ep:103, loss:0.00001, loss_test:0.08849, lr:6.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.592, tt:3701.619\n",
      "Ep:104, loss:0.00001, loss_test:0.08712, lr:6.36e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.604, tt:3738.406\n",
      "Ep:105, loss:0.00000, loss_test:0.08789, lr:6.30e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.627, tt:3776.435\n",
      "Ep:106, loss:0.00000, loss_test:0.08915, lr:6.24e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.637, tt:3813.161\n",
      "Ep:107, loss:0.00000, loss_test:0.08669, lr:6.17e-03, fs:0.70886 (r=0.566,p=0.949),  time:35.659, tt:3851.172\n",
      "Ep:108, loss:0.00000, loss_test:0.08817, lr:6.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:35.676, tt:3888.704\n",
      "Ep:109, loss:0.00000, loss_test:0.08572, lr:6.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.666, tt:3923.281\n",
      "Ep:110, loss:0.00000, loss_test:0.08874, lr:5.99e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.658, tt:3958.012\n",
      "Ep:111, loss:0.00000, loss_test:0.08700, lr:5.93e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.651, tt:3992.912\n",
      "Ep:112, loss:0.00000, loss_test:0.08838, lr:5.87e-03, fs:0.70886 (r=0.566,p=0.949),  time:35.643, tt:4027.613\n",
      "Ep:113, loss:0.00000, loss_test:0.08872, lr:5.81e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.650, tt:4064.122\n",
      "Ep:114, loss:0.00000, loss_test:0.08786, lr:5.75e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.648, tt:4099.566\n",
      "Ep:115, loss:0.00000, loss_test:0.08811, lr:5.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.656, tt:4136.048\n",
      "Ep:116, loss:0.00000, loss_test:0.08734, lr:5.64e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.652, tt:4171.330\n",
      "Ep:117, loss:0.00000, loss_test:0.08901, lr:5.58e-03, fs:0.69231 (r=0.545,p=0.947),  time:35.657, tt:4207.581\n",
      "Ep:118, loss:0.00000, loss_test:0.08693, lr:5.53e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.653, tt:4242.741\n",
      "Ep:119, loss:0.00000, loss_test:0.08876, lr:5.47e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.659, tt:4279.045\n",
      "Ep:120, loss:0.00000, loss_test:0.08755, lr:5.42e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.658, tt:4314.623\n",
      "Ep:121, loss:0.00000, loss_test:0.08737, lr:5.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.677, tt:4352.563\n",
      "Ep:122, loss:0.00000, loss_test:0.08818, lr:5.31e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.687, tt:4389.558\n",
      "Ep:123, loss:0.00000, loss_test:0.08677, lr:5.26e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.684, tt:4424.779\n",
      "Ep:124, loss:0.00000, loss_test:0.08892, lr:5.20e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.682, tt:4460.279\n",
      "Ep:125, loss:0.00000, loss_test:0.08826, lr:5.15e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.695, tt:4497.584\n",
      "Ep:126, loss:0.00000, loss_test:0.08684, lr:5.10e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.696, tt:4533.363\n",
      "Ep:127, loss:0.00000, loss_test:0.08786, lr:5.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.705, tt:4570.257\n",
      "Ep:128, loss:0.00000, loss_test:0.08846, lr:5.00e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.710, tt:4606.647\n",
      "Ep:129, loss:0.00000, loss_test:0.08695, lr:4.95e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.724, tt:4644.083\n",
      "Ep:130, loss:0.00000, loss_test:0.08463, lr:4.90e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.725, tt:4679.940\n",
      "Ep:131, loss:0.00000, loss_test:0.08891, lr:4.85e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.728, tt:4716.094\n",
      "Ep:132, loss:0.00000, loss_test:0.08813, lr:4.80e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.735, tt:4752.802\n",
      "Ep:133, loss:0.00000, loss_test:0.08633, lr:4.75e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.748, tt:4790.251\n",
      "Ep:134, loss:0.00000, loss_test:0.08794, lr:4.71e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.754, tt:4826.851\n",
      "Ep:135, loss:0.00000, loss_test:0.08546, lr:4.66e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.781, tt:4866.196\n",
      "Ep:136, loss:0.00000, loss_test:0.08793, lr:4.61e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.781, tt:4901.976\n",
      "Ep:137, loss:0.00000, loss_test:0.08816, lr:4.57e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.780, tt:4937.644\n",
      "Ep:138, loss:0.00000, loss_test:0.08518, lr:4.52e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.784, tt:4973.968\n",
      "Ep:139, loss:0.00000, loss_test:0.08570, lr:4.48e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.792, tt:5010.940\n",
      "Ep:140, loss:0.00000, loss_test:0.08737, lr:4.43e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.789, tt:5046.241\n",
      "Ep:141, loss:0.00000, loss_test:0.08718, lr:4.39e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.785, tt:5081.413\n",
      "Ep:142, loss:0.00000, loss_test:0.08635, lr:4.34e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.787, tt:5117.577\n",
      "Ep:143, loss:0.00000, loss_test:0.08642, lr:4.30e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.796, tt:5154.688\n",
      "Ep:144, loss:0.00000, loss_test:0.08634, lr:4.26e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.794, tt:5190.113\n",
      "Ep:145, loss:0.00000, loss_test:0.08535, lr:4.21e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.804, tt:5227.425\n",
      "Ep:146, loss:0.00000, loss_test:0.08561, lr:4.17e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.796, tt:5262.067\n",
      "Ep:147, loss:0.00000, loss_test:0.08592, lr:4.13e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.791, tt:5297.055\n",
      "Ep:148, loss:0.00000, loss_test:0.08464, lr:4.09e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.788, tt:5332.418\n",
      "Ep:149, loss:0.00000, loss_test:0.08550, lr:4.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.781, tt:5367.086\n",
      "Ep:150, loss:0.00000, loss_test:0.08542, lr:4.01e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.772, tt:5401.609\n",
      "Ep:151, loss:0.00000, loss_test:0.08621, lr:3.97e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.768, tt:5436.675\n",
      "Ep:152, loss:0.00000, loss_test:0.08603, lr:3.93e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.760, tt:5471.335\n",
      "Ep:155, loss:0.00000, loss_test:0.08537, lr:3.81e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.733, tt:5574.343\n",
      "Ep:156, loss:0.00000, loss_test:0.08469, lr:3.77e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.730, tt:5609.618\n",
      "Ep:157, loss:0.00000, loss_test:0.08497, lr:3.73e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.723, tt:5644.283\n",
      "Ep:158, loss:0.00000, loss_test:0.08534, lr:3.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.725, tt:5680.215\n",
      "Ep:159, loss:0.00000, loss_test:0.08501, lr:3.66e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.746, tt:5719.399\n",
      "Ep:160, loss:0.00000, loss_test:0.08442, lr:3.62e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.740, tt:5754.204\n",
      "Ep:161, loss:0.00000, loss_test:0.08485, lr:3.59e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.740, tt:5789.904\n",
      "Ep:162, loss:0.00000, loss_test:0.08548, lr:3.55e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.747, tt:5826.780\n",
      "Ep:163, loss:0.00000, loss_test:0.08580, lr:3.52e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.745, tt:5862.159\n",
      "Ep:164, loss:0.00000, loss_test:0.08494, lr:3.48e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.744, tt:5897.811\n",
      "Ep:165, loss:0.00000, loss_test:0.08601, lr:3.45e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.750, tt:5934.472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:166, loss:0.00000, loss_test:0.08620, lr:3.41e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.747, tt:5969.713\n",
      "Ep:167, loss:0.00000, loss_test:0.08447, lr:3.38e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.751, tt:6006.236\n",
      "Ep:168, loss:0.00000, loss_test:0.08579, lr:3.34e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.758, tt:6043.170\n",
      "Ep:169, loss:0.00000, loss_test:0.08593, lr:3.31e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.764, tt:6079.809\n",
      "Ep:170, loss:0.00000, loss_test:0.08462, lr:3.28e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.769, tt:6116.426\n",
      "Ep:171, loss:0.00000, loss_test:0.08512, lr:3.24e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.769, tt:6152.236\n",
      "Ep:172, loss:0.00000, loss_test:0.08607, lr:3.21e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.772, tt:6188.593\n",
      "Ep:173, loss:0.00000, loss_test:0.08526, lr:3.18e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.761, tt:6222.345\n",
      "Ep:174, loss:0.00000, loss_test:0.08464, lr:3.15e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.752, tt:6256.595\n",
      "Ep:175, loss:0.00000, loss_test:0.08490, lr:3.12e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.748, tt:6291.726\n",
      "Ep:176, loss:0.00000, loss_test:0.08494, lr:3.09e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.746, tt:6327.066\n",
      "Ep:177, loss:0.00000, loss_test:0.08521, lr:3.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.743, tt:6362.312\n",
      "Ep:178, loss:0.00000, loss_test:0.08531, lr:3.02e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.744, tt:6398.246\n",
      "Ep:179, loss:0.00000, loss_test:0.08425, lr:2.99e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.743, tt:6433.677\n",
      "Ep:180, loss:0.00000, loss_test:0.08447, lr:2.96e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.752, tt:6471.094\n",
      "Ep:181, loss:0.00000, loss_test:0.08581, lr:2.93e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.750, tt:6506.547\n",
      "Ep:182, loss:0.00000, loss_test:0.08592, lr:2.90e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.747, tt:6541.730\n",
      "Ep:183, loss:0.00000, loss_test:0.08550, lr:2.88e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.769, tt:6581.539\n",
      "Ep:184, loss:0.00000, loss_test:0.08457, lr:2.85e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.757, tt:6615.080\n",
      "Ep:185, loss:0.00000, loss_test:0.08413, lr:2.82e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.761, tt:6651.480\n",
      "Ep:186, loss:0.00000, loss_test:0.08412, lr:2.79e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.756, tt:6686.282\n",
      "Ep:187, loss:0.00000, loss_test:0.08415, lr:2.76e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.758, tt:6722.564\n",
      "Ep:188, loss:0.00000, loss_test:0.08449, lr:2.73e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.748, tt:6756.440\n",
      "Ep:189, loss:0.00000, loss_test:0.08431, lr:2.71e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.750, tt:6792.592\n",
      "Ep:190, loss:0.00000, loss_test:0.08439, lr:2.68e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.749, tt:6828.071\n",
      "Ep:191, loss:0.00000, loss_test:0.08507, lr:2.65e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.749, tt:6863.788\n",
      "Ep:192, loss:0.00000, loss_test:0.08479, lr:2.63e-03, fs:0.72152 (r=0.576,p=0.966),  time:35.750, tt:6899.759\n",
      "Ep:193, loss:0.00000, loss_test:0.08398, lr:2.60e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.751, tt:6935.667\n",
      "Ep:194, loss:0.00000, loss_test:0.08384, lr:2.57e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.746, tt:6970.554\n",
      "Ep:195, loss:0.00000, loss_test:0.08409, lr:2.55e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.737, tt:7004.404\n",
      "Ep:196, loss:0.00000, loss_test:0.08396, lr:2.52e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.727, tt:7038.230\n",
      "Ep:197, loss:0.00000, loss_test:0.08432, lr:2.50e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.721, tt:7072.846\n",
      "Ep:198, loss:0.00000, loss_test:0.08409, lr:2.47e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.724, tt:7109.164\n",
      "Ep:199, loss:0.00000, loss_test:0.08407, lr:2.45e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.723, tt:7144.649\n",
      "Ep:200, loss:0.00000, loss_test:0.08389, lr:2.42e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.722, tt:7180.084\n",
      "Ep:201, loss:0.00000, loss_test:0.08412, lr:2.40e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.699, tt:7211.187\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.03282, lr:6.00e-02, fs:0.63303 (r=0.697,p=0.580),  time:24.923, tt:24.923\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02469, lr:6.00e-02, fs:0.63235 (r=0.869,p=0.497),  time:24.047, tt:48.094\n",
      "Ep:2, loss:0.00005, loss_test:0.02680, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.285, tt:72.854\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02686, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:23.486, tt:93.945\n",
      "Ep:4, loss:0.00005, loss_test:0.02583, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:23.810, tt:119.052\n",
      "Ep:5, loss:0.00005, loss_test:0.02524, lr:6.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:24.270, tt:145.619\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02510, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:25.247, tt:176.730\n",
      "Ep:7, loss:0.00005, loss_test:0.02499, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:25.693, tt:205.545\n",
      "Ep:8, loss:0.00005, loss_test:0.02471, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:26.043, tt:234.386\n",
      "Ep:9, loss:0.00005, loss_test:0.02408, lr:6.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:26.335, tt:263.355\n",
      "Ep:10, loss:0.00005, loss_test:0.02319, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:26.685, tt:293.534\n",
      "Ep:11, loss:0.00005, loss_test:0.02228, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:27.038, tt:324.455\n",
      "Ep:12, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:27.221, tt:353.876\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02087, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:27.404, tt:383.661\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02032, lr:6.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:27.597, tt:413.951\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:27.785, tt:444.556\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01961, lr:6.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:27.906, tt:474.400\n",
      "Ep:17, loss:0.00004, loss_test:0.01944, lr:6.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:28.018, tt:504.326\n",
      "Ep:18, loss:0.00004, loss_test:0.01939, lr:6.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:28.162, tt:535.070\n",
      "Ep:19, loss:0.00004, loss_test:0.01937, lr:6.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:28.307, tt:566.138\n",
      "Ep:20, loss:0.00004, loss_test:0.01922, lr:6.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:28.403, tt:596.466\n",
      "Ep:21, loss:0.00004, loss_test:0.01900, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:28.425, tt:625.355\n",
      "Ep:22, loss:0.00004, loss_test:0.01874, lr:6.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:28.523, tt:656.020\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01850, lr:6.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:28.542, tt:685.017\n",
      "Ep:24, loss:0.00004, loss_test:0.01829, lr:6.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:28.526, tt:713.150\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01810, lr:6.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:28.649, tt:744.871\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01790, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:28.668, tt:774.039\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01769, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:28.707, tt:803.791\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:28, loss:0.00004, loss_test:0.01748, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:28.712, tt:832.640\n",
      "Ep:29, loss:0.00004, loss_test:0.01719, lr:6.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:28.803, tt:864.104\n",
      "Ep:30, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:28.873, tt:895.074\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01675, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:28.944, tt:926.217\n",
      "Ep:32, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:28.940, tt:955.035\n",
      "Ep:33, loss:0.00003, loss_test:0.01603, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:28.965, tt:984.811\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01573, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:29.006, tt:1015.219\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01548, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:29.055, tt:1045.966\n",
      "Ep:36, loss:0.00003, loss_test:0.01512, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:29.106, tt:1076.913\n",
      "Ep:37, loss:0.00003, loss_test:0.01485, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:29.104, tt:1105.947\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01470, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:29.119, tt:1135.637\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01458, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:29.140, tt:1165.592\n",
      "Ep:40, loss:0.00003, loss_test:0.01460, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:29.144, tt:1194.894\n",
      "Ep:41, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:29.158, tt:1224.625\n",
      "Ep:42, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:29.170, tt:1254.310\n",
      "Ep:43, loss:0.00002, loss_test:0.01471, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:29.176, tt:1283.726\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:29.171, tt:1312.684\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01469, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:29.182, tt:1342.356\n",
      "Ep:46, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:29.181, tt:1371.502\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:29.186, tt:1400.917\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:29.182, tt:1429.908\n",
      "Ep:49, loss:0.00002, loss_test:0.01516, lr:6.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:29.162, tt:1458.118\n",
      "Ep:50, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:29.164, tt:1487.359\n",
      "Ep:51, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:29.148, tt:1515.686\n",
      "Ep:52, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:29.145, tt:1544.690\n",
      "Ep:53, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:29.137, tt:1573.401\n",
      "Ep:54, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:29.140, tt:1602.692\n",
      "Ep:55, loss:0.00001, loss_test:0.01465, lr:6.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:29.132, tt:1631.419\n",
      "Ep:56, loss:0.00001, loss_test:0.01450, lr:6.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:29.133, tt:1660.579\n",
      "Ep:57, loss:0.00001, loss_test:0.01417, lr:6.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.150, tt:1690.726\n",
      "Ep:58, loss:0.00001, loss_test:0.01571, lr:6.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:29.166, tt:1720.800\n",
      "Ep:59, loss:0.00001, loss_test:0.01445, lr:5.94e-02, fs:0.75532 (r=0.717,p=0.798),  time:29.146, tt:1748.777\n",
      "Ep:60, loss:0.00001, loss_test:0.01514, lr:5.88e-02, fs:0.76344 (r=0.717,p=0.816),  time:29.142, tt:1777.686\n",
      "Ep:61, loss:0.00001, loss_test:0.01447, lr:5.82e-02, fs:0.77174 (r=0.717,p=0.835),  time:29.148, tt:1807.195\n",
      "Ep:62, loss:0.00001, loss_test:0.01448, lr:5.76e-02, fs:0.77419 (r=0.727,p=0.828),  time:29.149, tt:1836.370\n",
      "Ep:63, loss:0.00001, loss_test:0.01694, lr:5.71e-02, fs:0.76087 (r=0.707,p=0.824),  time:29.152, tt:1865.711\n",
      "Ep:64, loss:0.00001, loss_test:0.01409, lr:5.65e-02, fs:0.77419 (r=0.727,p=0.828),  time:29.157, tt:1895.189\n",
      "Ep:65, loss:0.00001, loss_test:0.01781, lr:5.59e-02, fs:0.75000 (r=0.697,p=0.812),  time:29.166, tt:1924.936\n",
      "Ep:66, loss:0.00001, loss_test:0.01448, lr:5.54e-02, fs:0.77174 (r=0.717,p=0.835),  time:29.187, tt:1955.517\n",
      "Ep:67, loss:0.00001, loss_test:0.01812, lr:5.48e-02, fs:0.74725 (r=0.687,p=0.819),  time:29.182, tt:1984.373\n",
      "Ep:68, loss:0.00001, loss_test:0.01475, lr:5.43e-02, fs:0.76923 (r=0.707,p=0.843),  time:29.180, tt:2013.422\n",
      "Ep:69, loss:0.00001, loss_test:0.01746, lr:5.37e-02, fs:0.74725 (r=0.687,p=0.819),  time:29.189, tt:2043.239\n",
      "Ep:70, loss:0.00001, loss_test:0.01521, lr:5.32e-02, fs:0.76923 (r=0.707,p=0.843),  time:29.208, tt:2073.792\n",
      "Ep:71, loss:0.00001, loss_test:0.01666, lr:5.27e-02, fs:0.75978 (r=0.687,p=0.850),  time:29.210, tt:2103.096\n",
      "Ep:72, loss:0.00001, loss_test:0.01628, lr:5.21e-02, fs:0.75281 (r=0.677,p=0.848),  time:29.229, tt:2133.747\n",
      "Ep:73, loss:0.00001, loss_test:0.01733, lr:5.16e-02, fs:0.75138 (r=0.687,p=0.829),  time:29.216, tt:2161.982\n",
      "Ep:74, loss:0.00001, loss_test:0.01719, lr:5.11e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.223, tt:2191.742\n",
      "Ep:75, loss:0.00001, loss_test:0.01727, lr:5.06e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.234, tt:2221.795\n",
      "Ep:76, loss:0.00001, loss_test:0.01854, lr:5.01e-02, fs:0.75706 (r=0.677,p=0.859),  time:29.251, tt:2252.304\n",
      "Ep:77, loss:0.00001, loss_test:0.01777, lr:4.96e-02, fs:0.75978 (r=0.687,p=0.850),  time:29.260, tt:2282.256\n",
      "Ep:78, loss:0.00001, loss_test:0.01865, lr:4.91e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.263, tt:2311.750\n",
      "Ep:79, loss:0.00001, loss_test:0.01784, lr:4.86e-02, fs:0.75429 (r=0.667,p=0.868),  time:29.260, tt:2340.798\n",
      "Ep:80, loss:0.00001, loss_test:0.01989, lr:4.81e-02, fs:0.75706 (r=0.677,p=0.859),  time:29.270, tt:2370.846\n",
      "Ep:81, loss:0.00001, loss_test:0.01821, lr:4.76e-02, fs:0.75706 (r=0.677,p=0.859),  time:29.284, tt:2401.323\n",
      "Ep:82, loss:0.00001, loss_test:0.01946, lr:4.71e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.313, tt:2432.965\n",
      "Ep:83, loss:0.00001, loss_test:0.01892, lr:4.67e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.332, tt:2463.908\n",
      "Ep:84, loss:0.00001, loss_test:0.01969, lr:4.62e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.335, tt:2493.466\n",
      "Ep:85, loss:0.00001, loss_test:0.02027, lr:4.57e-02, fs:0.75706 (r=0.677,p=0.859),  time:29.346, tt:2523.746\n",
      "Ep:86, loss:0.00001, loss_test:0.01895, lr:4.53e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.354, tt:2553.814\n",
      "Ep:87, loss:0.00001, loss_test:0.02120, lr:4.48e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.357, tt:2583.414\n",
      "Ep:88, loss:0.00001, loss_test:0.01915, lr:4.44e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.360, tt:2613.014\n",
      "Ep:89, loss:0.00001, loss_test:0.02084, lr:4.39e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.385, tt:2644.632\n",
      "Ep:90, loss:0.00001, loss_test:0.02024, lr:4.35e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.398, tt:2675.228\n",
      "Ep:91, loss:0.00001, loss_test:0.02059, lr:4.31e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.404, tt:2705.208\n",
      "Ep:92, loss:0.00001, loss_test:0.02126, lr:4.26e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.419, tt:2735.952\n",
      "Ep:93, loss:0.00000, loss_test:0.02102, lr:4.22e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.433, tt:2766.677\n",
      "Ep:94, loss:0.00000, loss_test:0.02173, lr:4.18e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.455, tt:2798.213\n",
      "Ep:95, loss:0.00000, loss_test:0.02180, lr:4.14e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.467, tt:2828.809\n",
      "Ep:96, loss:0.00000, loss_test:0.02206, lr:4.10e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.476, tt:2859.137\n",
      "Ep:97, loss:0.00000, loss_test:0.02240, lr:4.05e-02, fs:0.76571 (r=0.677,p=0.882),  time:29.476, tt:2888.602\n",
      "Ep:98, loss:0.00000, loss_test:0.02224, lr:4.01e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.481, tt:2918.649\n",
      "Ep:99, loss:0.00000, loss_test:0.02286, lr:3.97e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.479, tt:2947.937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00000, loss_test:0.02235, lr:3.93e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.489, tt:2978.435\n",
      "Ep:101, loss:0.00000, loss_test:0.02311, lr:3.89e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.493, tt:3008.241\n",
      "Ep:102, loss:0.00000, loss_test:0.02374, lr:3.86e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.500, tt:3038.502\n",
      "Ep:103, loss:0.00000, loss_test:0.02267, lr:3.82e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.503, tt:3068.289\n",
      "Ep:104, loss:0.00000, loss_test:0.02425, lr:3.78e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.499, tt:3097.372\n",
      "Ep:105, loss:0.00000, loss_test:0.02301, lr:3.74e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.503, tt:3127.297\n",
      "Ep:106, loss:0.00000, loss_test:0.02443, lr:3.70e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.518, tt:3158.387\n",
      "Ep:107, loss:0.00000, loss_test:0.02457, lr:3.67e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.522, tt:3188.426\n",
      "Ep:108, loss:0.00000, loss_test:0.02378, lr:3.63e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.530, tt:3218.748\n",
      "Ep:109, loss:0.00000, loss_test:0.02520, lr:3.59e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.534, tt:3248.764\n",
      "Ep:110, loss:0.00000, loss_test:0.02483, lr:3.56e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.541, tt:3279.028\n",
      "Ep:111, loss:0.00000, loss_test:0.02483, lr:3.52e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.552, tt:3309.803\n",
      "Ep:112, loss:0.00000, loss_test:0.02602, lr:3.49e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.566, tt:3340.988\n",
      "Ep:113, loss:0.00000, loss_test:0.02474, lr:3.45e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.578, tt:3371.850\n",
      "Ep:114, loss:0.00000, loss_test:0.02597, lr:3.42e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.581, tt:3401.848\n",
      "Ep:115, loss:0.00000, loss_test:0.02574, lr:3.38e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.587, tt:3432.147\n",
      "Ep:116, loss:0.00000, loss_test:0.02596, lr:3.35e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.597, tt:3462.895\n",
      "Ep:117, loss:0.00000, loss_test:0.02673, lr:3.32e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.603, tt:3493.147\n",
      "Ep:118, loss:0.00000, loss_test:0.02587, lr:3.28e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.609, tt:3523.445\n",
      "Ep:119, loss:0.00000, loss_test:0.02739, lr:3.25e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.620, tt:3554.425\n",
      "Ep:120, loss:0.00000, loss_test:0.02647, lr:3.22e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.631, tt:3585.294\n",
      "Ep:121, loss:0.00000, loss_test:0.02688, lr:3.19e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.639, tt:3616.011\n",
      "Ep:122, loss:0.00000, loss_test:0.02733, lr:3.15e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.638, tt:3645.482\n",
      "Ep:123, loss:0.00000, loss_test:0.02788, lr:3.12e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.647, tt:3676.274\n",
      "Ep:124, loss:0.00000, loss_test:0.02784, lr:3.09e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.663, tt:3707.933\n",
      "Ep:125, loss:0.00000, loss_test:0.02797, lr:3.06e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.679, tt:3739.585\n",
      "Ep:126, loss:0.00000, loss_test:0.02740, lr:3.03e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.699, tt:3771.740\n",
      "Ep:127, loss:0.00000, loss_test:0.02819, lr:3.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.704, tt:3802.116\n",
      "Ep:128, loss:0.00000, loss_test:0.02864, lr:2.97e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.712, tt:3832.823\n",
      "Ep:129, loss:0.00000, loss_test:0.02883, lr:2.94e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.720, tt:3863.586\n",
      "Ep:130, loss:0.00000, loss_test:0.02892, lr:2.91e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.730, tt:3894.654\n",
      "Ep:131, loss:0.00000, loss_test:0.02871, lr:2.88e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.737, tt:3925.251\n",
      "Ep:132, loss:0.00000, loss_test:0.02910, lr:2.85e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.741, tt:3955.530\n",
      "Ep:133, loss:0.00000, loss_test:0.02885, lr:2.82e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.739, tt:3985.090\n",
      "Ep:134, loss:0.00000, loss_test:0.02963, lr:2.80e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.741, tt:4014.999\n",
      "Ep:135, loss:0.00000, loss_test:0.02959, lr:2.77e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.747, tt:4045.643\n",
      "Ep:136, loss:0.00000, loss_test:0.02965, lr:2.74e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.754, tt:4076.262\n",
      "Ep:137, loss:0.00000, loss_test:0.02974, lr:2.71e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.752, tt:4105.821\n",
      "Ep:138, loss:0.00000, loss_test:0.02987, lr:2.69e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.746, tt:4134.647\n",
      "Ep:139, loss:0.00000, loss_test:0.03043, lr:2.66e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.742, tt:4163.914\n",
      "Ep:140, loss:0.00000, loss_test:0.02993, lr:2.63e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.750, tt:4194.728\n",
      "Ep:141, loss:0.00000, loss_test:0.03064, lr:2.61e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.749, tt:4224.402\n",
      "Ep:142, loss:0.00000, loss_test:0.03035, lr:2.58e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.745, tt:4253.555\n",
      "Ep:143, loss:0.00000, loss_test:0.03105, lr:2.55e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.747, tt:4283.503\n",
      "Ep:144, loss:0.00000, loss_test:0.03025, lr:2.53e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.755, tt:4314.452\n",
      "Ep:145, loss:0.00000, loss_test:0.03115, lr:2.50e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.759, tt:4344.779\n",
      "Ep:146, loss:0.00000, loss_test:0.03105, lr:2.48e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.768, tt:4375.860\n",
      "Ep:147, loss:0.00000, loss_test:0.03092, lr:2.45e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.781, tt:4407.551\n",
      "Ep:148, loss:0.00000, loss_test:0.03160, lr:2.43e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.791, tt:4438.919\n",
      "Ep:149, loss:0.00000, loss_test:0.03093, lr:2.40e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.788, tt:4468.164\n",
      "Ep:150, loss:0.00000, loss_test:0.03217, lr:2.38e-02, fs:0.77907 (r=0.677,p=0.918),  time:29.789, tt:4498.113\n",
      "Ep:151, loss:0.00000, loss_test:0.03116, lr:2.36e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.788, tt:4527.833\n",
      "Ep:152, loss:0.00000, loss_test:0.03149, lr:2.33e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.796, tt:4558.818\n",
      "Ep:153, loss:0.00000, loss_test:0.03219, lr:2.31e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.801, tt:4589.416\n",
      "Ep:154, loss:0.00000, loss_test:0.03131, lr:2.29e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.810, tt:4620.531\n",
      "Ep:155, loss:0.00000, loss_test:0.03250, lr:2.26e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.814, tt:4650.925\n",
      "Ep:156, loss:0.00000, loss_test:0.03161, lr:2.24e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.818, tt:4681.369\n",
      "Ep:157, loss:0.00000, loss_test:0.03232, lr:2.22e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.822, tt:4711.844\n",
      "Ep:158, loss:0.00000, loss_test:0.03228, lr:2.20e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.822, tt:4741.621\n",
      "Ep:159, loss:0.00000, loss_test:0.03267, lr:2.17e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.823, tt:4771.730\n",
      "Ep:160, loss:0.00000, loss_test:0.03186, lr:2.15e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.832, tt:4802.981\n",
      "Ep:161, loss:0.00000, loss_test:0.03280, lr:2.13e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.835, tt:4833.247\n",
      "Ep:162, loss:0.00000, loss_test:0.03208, lr:2.11e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.843, tt:4864.383\n",
      "Ep:163, loss:0.00000, loss_test:0.03305, lr:2.09e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.849, tt:4895.251\n",
      "Ep:164, loss:0.00000, loss_test:0.03259, lr:2.07e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.861, tt:4927.142\n",
      "Ep:165, loss:0.00000, loss_test:0.03283, lr:2.05e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.870, tt:4958.499\n",
      "Ep:166, loss:0.00000, loss_test:0.03281, lr:2.03e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.876, tt:4989.339\n",
      "Ep:167, loss:0.00000, loss_test:0.03293, lr:2.01e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.882, tt:5020.193\n",
      "Ep:168, loss:0.00000, loss_test:0.03303, lr:1.99e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.885, tt:5050.529\n",
      "Ep:169, loss:0.00000, loss_test:0.03330, lr:1.97e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.890, tt:5081.285\n",
      "Ep:170, loss:0.00000, loss_test:0.03292, lr:1.95e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.891, tt:5111.282\n",
      "Ep:171, loss:0.00000, loss_test:0.03331, lr:1.93e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.894, tt:5141.763\n",
      "Ep:172, loss:0.00000, loss_test:0.03316, lr:1.91e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.901, tt:5172.859\n",
      "Ep:173, loss:0.00000, loss_test:0.03346, lr:1.89e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.904, tt:5203.302\n",
      "Ep:174, loss:0.00000, loss_test:0.03329, lr:1.87e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.907, tt:5233.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:175, loss:0.00000, loss_test:0.03376, lr:1.85e-02, fs:0.78363 (r=0.677,p=0.931),  time:29.908, tt:5263.776\n",
      "Ep:176, loss:0.00000, loss_test:0.03347, lr:1.83e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.915, tt:5295.036\n",
      "Ep:177, loss:0.00000, loss_test:0.03347, lr:1.81e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.934, tt:5328.299\n",
      "Ep:178, loss:0.00000, loss_test:0.03382, lr:1.80e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.935, tt:5358.453\n",
      "Ep:179, loss:0.00000, loss_test:0.03353, lr:1.78e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.934, tt:5388.159\n",
      "Ep:180, loss:0.00000, loss_test:0.03379, lr:1.76e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.937, tt:5418.645\n",
      "Ep:181, loss:0.00000, loss_test:0.03405, lr:1.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.940, tt:5449.071\n",
      "Ep:182, loss:0.00000, loss_test:0.03359, lr:1.73e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.945, tt:5479.868\n",
      "Ep:183, loss:0.00000, loss_test:0.03405, lr:1.71e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.945, tt:5509.957\n",
      "Ep:184, loss:0.00000, loss_test:0.03417, lr:1.69e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.944, tt:5539.669\n",
      "Ep:185, loss:0.00000, loss_test:0.03398, lr:1.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.954, tt:5571.441\n",
      "Ep:186, loss:0.00000, loss_test:0.03410, lr:1.66e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.954, tt:5601.324\n",
      "Ep:187, loss:0.00000, loss_test:0.03435, lr:1.64e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.958, tt:5632.167\n",
      "Ep:188, loss:0.00000, loss_test:0.03402, lr:1.62e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.955, tt:5661.428\n",
      "Ep:189, loss:0.00000, loss_test:0.03416, lr:1.61e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.960, tt:5692.327\n",
      "Ep:190, loss:0.00000, loss_test:0.03456, lr:1.59e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.960, tt:5722.416\n",
      "Ep:191, loss:0.00000, loss_test:0.03428, lr:1.58e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.963, tt:5752.872\n",
      "Ep:192, loss:0.00000, loss_test:0.03446, lr:1.56e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.962, tt:5782.639\n",
      "Ep:193, loss:0.00000, loss_test:0.03429, lr:1.54e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.959, tt:5812.094\n",
      "Ep:194, loss:0.00000, loss_test:0.03473, lr:1.53e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.957, tt:5841.647\n",
      "Ep:195, loss:0.00000, loss_test:0.03434, lr:1.51e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.956, tt:5871.287\n",
      "Ep:196, loss:0.00000, loss_test:0.03484, lr:1.50e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.948, tt:5899.669\n",
      "Ep:197, loss:0.00000, loss_test:0.03472, lr:1.48e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.945, tt:5929.177\n",
      "Ep:198, loss:0.00000, loss_test:0.03452, lr:1.47e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.942, tt:5958.359\n",
      "Ep:199, loss:0.00000, loss_test:0.03485, lr:1.45e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.934, tt:5986.874\n",
      "Ep:200, loss:0.00000, loss_test:0.03459, lr:1.44e-02, fs:0.78824 (r=0.677,p=0.944),  time:29.924, tt:6014.682\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13742, lr:1.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:28.439, tt:28.439\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13626, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:26.576, tt:53.153\n",
      "Ep:2, loss:0.00026, loss_test:0.13518, lr:1.00e-02, fs:0.63320 (r=0.828,p=0.512),  time:26.403, tt:79.209\n",
      "Ep:3, loss:0.00026, loss_test:0.13431, lr:1.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:26.159, tt:104.637\n",
      "Ep:4, loss:0.00026, loss_test:0.13331, lr:1.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:25.906, tt:129.532\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.13215, lr:1.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:26.470, tt:158.820\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.13099, lr:1.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:27.204, tt:190.428\n",
      "Ep:7, loss:0.00025, loss_test:0.12977, lr:1.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:27.710, tt:221.683\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.12852, lr:1.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:27.966, tt:251.698\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12717, lr:1.00e-02, fs:0.66397 (r=0.828,p=0.554),  time:28.163, tt:281.627\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.12566, lr:1.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:28.568, tt:314.251\n",
      "Ep:11, loss:0.00024, loss_test:0.12387, lr:1.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:28.807, tt:345.687\n",
      "Ep:12, loss:0.00024, loss_test:0.12145, lr:1.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:28.840, tt:374.914\n",
      "Ep:13, loss:0.00024, loss_test:0.11837, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:29.098, tt:407.370\n",
      "Ep:14, loss:0.00023, loss_test:0.11580, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:29.208, tt:438.113\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.11279, lr:1.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:29.301, tt:468.818\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.11023, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:29.292, tt:497.967\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.10787, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:29.359, tt:528.468\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10621, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:29.322, tt:557.117\n",
      "Ep:19, loss:0.00022, loss_test:0.10458, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:29.442, tt:588.832\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.10156, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:29.489, tt:619.276\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10180, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:29.549, tt:650.075\n",
      "Ep:22, loss:0.00021, loss_test:0.09944, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:29.565, tt:680.000\n",
      "Ep:23, loss:0.00020, loss_test:0.09623, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:29.555, tt:709.325\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.09632, lr:1.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:29.620, tt:740.495\n",
      "Ep:25, loss:0.00020, loss_test:0.09171, lr:1.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:29.623, tt:770.199\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00019, loss_test:0.08907, lr:1.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:29.719, tt:802.404\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.08848, lr:1.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:29.765, tt:833.416\n",
      "Ep:28, loss:0.00018, loss_test:0.08275, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:29.759, tt:863.007\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00018, loss_test:0.08442, lr:1.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:29.775, tt:893.263\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.07863, lr:1.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:29.774, tt:922.980\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.07832, lr:1.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.820, tt:954.227\n",
      "Ep:32, loss:0.00016, loss_test:0.07716, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:29.857, tt:985.266\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.07862, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:29.889, tt:1016.228\n",
      "Ep:34, loss:0.00014, loss_test:0.08111, lr:1.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:29.937, tt:1047.799\n",
      "Ep:35, loss:0.00016, loss_test:0.10957, lr:1.00e-02, fs:0.71212 (r=0.949,p=0.570),  time:29.949, tt:1078.177\n",
      "Ep:36, loss:0.00017, loss_test:0.09917, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:29.981, tt:1109.292\n",
      "Ep:37, loss:0.00015, loss_test:0.09126, lr:1.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:30.003, tt:1140.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00015, loss_test:0.08190, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.010, tt:1170.401\n",
      "Ep:39, loss:0.00014, loss_test:0.07236, lr:1.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:30.052, tt:1202.084\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.07596, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.093, tt:1233.800\n",
      "Ep:41, loss:0.00013, loss_test:0.07654, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:30.128, tt:1265.392\n",
      "Ep:42, loss:0.00012, loss_test:0.07817, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.121, tt:1295.195\n",
      "Ep:43, loss:0.00011, loss_test:0.07049, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:30.144, tt:1326.348\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00011, loss_test:0.07724, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.163, tt:1357.314\n",
      "Ep:45, loss:0.00010, loss_test:0.06578, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:30.169, tt:1387.786\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.08259, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.157, tt:1417.386\n",
      "Ep:47, loss:0.00009, loss_test:0.07251, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.191, tt:1449.159\n",
      "Ep:48, loss:0.00009, loss_test:0.07562, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.196, tt:1479.612\n",
      "Ep:49, loss:0.00008, loss_test:0.06683, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:30.213, tt:1510.649\n",
      "Ep:50, loss:0.00008, loss_test:0.08844, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:30.201, tt:1540.274\n",
      "Ep:51, loss:0.00008, loss_test:0.06606, lr:1.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:30.218, tt:1571.362\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.08187, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.225, tt:1601.920\n",
      "Ep:53, loss:0.00007, loss_test:0.06865, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.236, tt:1632.761\n",
      "Ep:54, loss:0.00007, loss_test:0.07045, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:30.258, tt:1664.194\n",
      "Ep:55, loss:0.00006, loss_test:0.06317, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.277, tt:1695.537\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.07896, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:30.315, tt:1727.930\n",
      "Ep:57, loss:0.00005, loss_test:0.06660, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.341, tt:1759.794\n",
      "Ep:58, loss:0.00005, loss_test:0.06582, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.362, tt:1791.363\n",
      "Ep:59, loss:0.00004, loss_test:0.06605, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.354, tt:1821.228\n",
      "Ep:60, loss:0.00004, loss_test:0.07084, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:30.397, tt:1854.193\n",
      "Ep:61, loss:0.00004, loss_test:0.07027, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.409, tt:1885.340\n",
      "Ep:62, loss:0.00004, loss_test:0.07277, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.422, tt:1916.584\n",
      "Ep:63, loss:0.00003, loss_test:0.06673, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:30.430, tt:1947.548\n",
      "Ep:64, loss:0.00003, loss_test:0.07077, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.425, tt:1977.653\n",
      "Ep:65, loss:0.00003, loss_test:0.07395, lr:1.00e-02, fs:0.71429 (r=0.606,p=0.870),  time:30.440, tt:2009.007\n",
      "Ep:66, loss:0.00003, loss_test:0.07442, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.462, tt:2040.963\n",
      "Ep:67, loss:0.00004, loss_test:0.08846, lr:9.90e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.482, tt:2072.754\n",
      "Ep:68, loss:0.00004, loss_test:0.08091, lr:9.80e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.488, tt:2103.660\n",
      "Ep:69, loss:0.00003, loss_test:0.07524, lr:9.70e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.496, tt:2134.744\n",
      "Ep:70, loss:0.00003, loss_test:0.07426, lr:9.61e-03, fs:0.73864 (r=0.657,p=0.844),  time:30.499, tt:2165.404\n",
      "Ep:71, loss:0.00003, loss_test:0.09113, lr:9.51e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.497, tt:2195.776\n",
      "Ep:72, loss:0.00003, loss_test:0.07157, lr:9.41e-03, fs:0.71264 (r=0.626,p=0.827),  time:30.499, tt:2226.418\n",
      "Ep:73, loss:0.00002, loss_test:0.08948, lr:9.32e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.494, tt:2256.532\n",
      "Ep:74, loss:0.00002, loss_test:0.08694, lr:9.23e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.488, tt:2286.568\n",
      "Ep:75, loss:0.00002, loss_test:0.07806, lr:9.14e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.475, tt:2316.103\n",
      "Ep:76, loss:0.00002, loss_test:0.08328, lr:9.04e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.475, tt:2346.597\n",
      "Ep:77, loss:0.00002, loss_test:0.08441, lr:8.95e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.477, tt:2377.195\n",
      "Ep:78, loss:0.00002, loss_test:0.08577, lr:8.86e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.493, tt:2408.922\n",
      "Ep:79, loss:0.00002, loss_test:0.10044, lr:8.78e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.494, tt:2439.560\n",
      "Ep:80, loss:0.00002, loss_test:0.08436, lr:8.69e-03, fs:0.77011 (r=0.677,p=0.893),  time:30.494, tt:2470.014\n",
      "Ep:81, loss:0.00002, loss_test:0.09827, lr:8.60e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.482, tt:2499.498\n",
      "Ep:82, loss:0.00001, loss_test:0.09354, lr:8.51e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.488, tt:2530.478\n",
      "Ep:83, loss:0.00001, loss_test:0.10144, lr:8.43e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.485, tt:2560.714\n",
      "Ep:84, loss:0.00001, loss_test:0.08718, lr:8.35e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.488, tt:2591.484\n",
      "Ep:85, loss:0.00001, loss_test:0.10169, lr:8.26e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.492, tt:2622.275\n",
      "Ep:86, loss:0.00001, loss_test:0.08410, lr:8.18e-03, fs:0.72189 (r=0.616,p=0.871),  time:30.497, tt:2653.224\n",
      "Ep:87, loss:0.00001, loss_test:0.11061, lr:8.10e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.497, tt:2683.720\n",
      "Ep:88, loss:0.00001, loss_test:0.08787, lr:8.02e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.495, tt:2714.090\n",
      "Ep:89, loss:0.00001, loss_test:0.10014, lr:7.94e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.491, tt:2744.227\n",
      "Ep:90, loss:0.00001, loss_test:0.07946, lr:7.86e-03, fs:0.73256 (r=0.636,p=0.863),  time:30.479, tt:2773.594\n",
      "Ep:91, loss:0.00001, loss_test:0.10763, lr:7.78e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.469, tt:2803.140\n",
      "Ep:92, loss:0.00001, loss_test:0.09219, lr:7.70e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.474, tt:2834.085\n",
      "Ep:93, loss:0.00001, loss_test:0.10435, lr:7.62e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.468, tt:2864.000\n",
      "Ep:94, loss:0.00001, loss_test:0.09351, lr:7.55e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.477, tt:2895.269\n",
      "Ep:95, loss:0.00001, loss_test:0.10575, lr:7.47e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.476, tt:2925.673\n",
      "Ep:96, loss:0.00001, loss_test:0.10343, lr:7.40e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.484, tt:2956.957\n",
      "Ep:97, loss:0.00001, loss_test:0.10723, lr:7.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.482, tt:2987.209\n",
      "Ep:98, loss:0.00001, loss_test:0.09974, lr:7.25e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.484, tt:3017.913\n",
      "Ep:99, loss:0.00001, loss_test:0.10629, lr:7.18e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.506, tt:3050.649\n",
      "Ep:100, loss:0.00001, loss_test:0.10003, lr:7.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.528, tt:3083.324\n",
      "Ep:101, loss:0.00001, loss_test:0.10150, lr:7.03e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.541, tt:3115.134\n",
      "Ep:102, loss:0.00000, loss_test:0.10381, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.550, tt:3146.654\n",
      "Ep:103, loss:0.00000, loss_test:0.11015, lr:6.89e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.555, tt:3177.682\n",
      "Ep:104, loss:0.00000, loss_test:0.10367, lr:6.83e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.559, tt:3208.733\n",
      "Ep:105, loss:0.00000, loss_test:0.10532, lr:6.76e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.570, tt:3240.385\n",
      "Ep:106, loss:0.00000, loss_test:0.10590, lr:6.69e-03, fs:0.69182 (r=0.556,p=0.917),  time:30.580, tt:3272.110\n",
      "Ep:107, loss:0.00000, loss_test:0.11200, lr:6.62e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.591, tt:3303.870\n",
      "Ep:108, loss:0.00000, loss_test:0.10358, lr:6.56e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.603, tt:3335.718\n",
      "Ep:109, loss:0.00000, loss_test:0.11042, lr:6.49e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.594, tt:3365.303\n",
      "Ep:110, loss:0.00000, loss_test:0.10109, lr:6.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.606, tt:3397.298\n",
      "Ep:111, loss:0.00000, loss_test:0.10648, lr:6.36e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.597, tt:3426.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:112, loss:0.00000, loss_test:0.10065, lr:6.30e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.593, tt:3457.039\n",
      "Ep:113, loss:0.00000, loss_test:0.10781, lr:6.24e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.579, tt:3486.056\n",
      "Ep:114, loss:0.00000, loss_test:0.10733, lr:6.17e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.576, tt:3516.230\n",
      "Ep:115, loss:0.00000, loss_test:0.11023, lr:6.11e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.576, tt:3546.769\n",
      "Ep:116, loss:0.00000, loss_test:0.10688, lr:6.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.578, tt:3577.585\n",
      "Ep:117, loss:0.00000, loss_test:0.10408, lr:5.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.571, tt:3607.383\n",
      "Ep:118, loss:0.00000, loss_test:0.10475, lr:5.93e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.567, tt:3637.516\n",
      "Ep:119, loss:0.00000, loss_test:0.10507, lr:5.87e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.561, tt:3667.312\n",
      "Ep:120, loss:0.00000, loss_test:0.10535, lr:5.81e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.564, tt:3698.275\n",
      "Ep:121, loss:0.00000, loss_test:0.10398, lr:5.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.562, tt:3728.603\n",
      "Ep:122, loss:0.00000, loss_test:0.10351, lr:5.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.552, tt:3757.877\n",
      "Ep:123, loss:0.00000, loss_test:0.10150, lr:5.64e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.545, tt:3787.553\n",
      "Ep:124, loss:0.00000, loss_test:0.10483, lr:5.58e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.546, tt:3818.305\n",
      "Ep:125, loss:0.00000, loss_test:0.10290, lr:5.53e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.539, tt:3847.879\n",
      "Ep:126, loss:0.00000, loss_test:0.10729, lr:5.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.535, tt:3877.889\n",
      "Ep:127, loss:0.00000, loss_test:0.10341, lr:5.42e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.555, tt:3911.048\n",
      "Ep:128, loss:0.00000, loss_test:0.10601, lr:5.36e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.556, tt:3941.718\n",
      "Ep:129, loss:0.00000, loss_test:0.10815, lr:5.31e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.562, tt:3973.015\n",
      "Ep:130, loss:0.00000, loss_test:0.10574, lr:5.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.559, tt:4003.199\n",
      "Ep:131, loss:0.00000, loss_test:0.10782, lr:5.20e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.550, tt:4032.631\n",
      "Ep:132, loss:0.00000, loss_test:0.10255, lr:5.15e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.531, tt:4060.660\n",
      "Ep:133, loss:0.00000, loss_test:0.10766, lr:5.10e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.532, tt:4091.229\n",
      "Ep:134, loss:0.00000, loss_test:0.10441, lr:5.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.543, tt:4123.357\n",
      "Ep:135, loss:0.00000, loss_test:0.10489, lr:5.00e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.540, tt:4153.460\n",
      "Ep:136, loss:0.00000, loss_test:0.10613, lr:4.95e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.536, tt:4183.383\n",
      "Ep:137, loss:0.00000, loss_test:0.10364, lr:4.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.519, tt:4211.647\n",
      "Ep:138, loss:0.00000, loss_test:0.10232, lr:4.85e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.525, tt:4242.942\n",
      "Ep:139, loss:0.00000, loss_test:0.10302, lr:4.80e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.522, tt:4273.102\n",
      "Ep:140, loss:0.00000, loss_test:0.10243, lr:4.75e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.527, tt:4304.248\n",
      "Ep:141, loss:0.00000, loss_test:0.10221, lr:4.71e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.527, tt:4334.835\n",
      "Ep:142, loss:0.00000, loss_test:0.10485, lr:4.66e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.527, tt:4365.379\n",
      "Ep:143, loss:0.00000, loss_test:0.10584, lr:4.61e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.523, tt:4395.279\n",
      "Ep:144, loss:0.00000, loss_test:0.10188, lr:4.57e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.510, tt:4424.018\n",
      "Ep:145, loss:0.00000, loss_test:0.10324, lr:4.52e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.499, tt:4452.921\n",
      "Ep:146, loss:0.00000, loss_test:0.10197, lr:4.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.495, tt:4482.834\n",
      "Ep:147, loss:0.00000, loss_test:0.10209, lr:4.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.490, tt:4512.584\n",
      "Ep:148, loss:0.00000, loss_test:0.10304, lr:4.39e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.489, tt:4542.844\n",
      "Ep:149, loss:0.00000, loss_test:0.10059, lr:4.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.502, tt:4575.326\n",
      "Ep:150, loss:0.00000, loss_test:0.10154, lr:4.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.503, tt:4605.938\n",
      "Ep:151, loss:0.00000, loss_test:0.10243, lr:4.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.494, tt:4635.113\n",
      "Ep:152, loss:0.00000, loss_test:0.10357, lr:4.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.485, tt:4664.247\n",
      "Ep:153, loss:0.00000, loss_test:0.10423, lr:4.17e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.466, tt:4691.736\n",
      "Ep:154, loss:0.00000, loss_test:0.10046, lr:4.13e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.452, tt:4719.984\n",
      "Ep:155, loss:0.00000, loss_test:0.10160, lr:4.09e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.437, tt:4748.241\n",
      "Ep:156, loss:0.00000, loss_test:0.10293, lr:4.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.438, tt:4778.692\n",
      "Ep:157, loss:0.00000, loss_test:0.10289, lr:4.01e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.431, tt:4808.144\n",
      "Ep:158, loss:0.00000, loss_test:0.10270, lr:3.97e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.436, tt:4839.356\n",
      "Ep:159, loss:0.00000, loss_test:0.10173, lr:3.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.430, tt:4868.768\n",
      "Ep:160, loss:0.00000, loss_test:0.09997, lr:3.89e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.419, tt:4897.508\n",
      "Ep:161, loss:0.00000, loss_test:0.10211, lr:3.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.419, tt:4927.881\n",
      "Ep:162, loss:0.00000, loss_test:0.10253, lr:3.81e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.419, tt:4958.269\n",
      "Ep:163, loss:0.00000, loss_test:0.10213, lr:3.77e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.420, tt:4988.821\n",
      "Ep:164, loss:0.00000, loss_test:0.10111, lr:3.73e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.418, tt:5018.966\n",
      "Ep:165, loss:0.00000, loss_test:0.10103, lr:3.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.427, tt:5050.827\n",
      "Ep:166, loss:0.00000, loss_test:0.10133, lr:3.66e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.432, tt:5082.099\n",
      "Ep:167, loss:0.00000, loss_test:0.10132, lr:3.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.425, tt:5111.371\n",
      "Ep:168, loss:0.00000, loss_test:0.10061, lr:3.59e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.434, tt:5143.339\n",
      "Ep:169, loss:0.00000, loss_test:0.10092, lr:3.55e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.436, tt:5174.115\n",
      "Ep:170, loss:0.00000, loss_test:0.10007, lr:3.52e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.448, tt:5206.647\n",
      "Ep:171, loss:0.00000, loss_test:0.10035, lr:3.48e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.454, tt:5238.078\n",
      "Ep:172, loss:0.00000, loss_test:0.09854, lr:3.45e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.469, tt:5271.210\n",
      "Ep:173, loss:0.00000, loss_test:0.09990, lr:3.41e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.470, tt:5301.840\n",
      "Ep:174, loss:0.00000, loss_test:0.10148, lr:3.38e-03, fs:0.74074 (r=0.606,p=0.952),  time:30.462, tt:5330.924\n",
      "Ep:175, loss:0.00000, loss_test:0.10026, lr:3.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.465, tt:5361.753\n",
      "Ep:176, loss:0.00000, loss_test:0.10080, lr:3.31e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.467, tt:5392.601\n",
      "Ep:177, loss:0.00000, loss_test:0.10125, lr:3.28e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.464, tt:5422.657\n",
      "Ep:178, loss:0.00000, loss_test:0.10098, lr:3.24e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.464, tt:5453.033\n",
      "Ep:179, loss:0.00000, loss_test:0.10057, lr:3.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.476, tt:5485.719\n",
      "Ep:180, loss:0.00000, loss_test:0.10043, lr:3.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.475, tt:5515.929\n",
      "Ep:181, loss:0.00000, loss_test:0.10007, lr:3.15e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.478, tt:5547.024\n",
      "Ep:182, loss:0.00000, loss_test:0.10039, lr:3.12e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.477, tt:5577.251\n",
      "Ep:183, loss:0.00000, loss_test:0.09936, lr:3.09e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.468, tt:5606.153\n",
      "Ep:184, loss:0.00000, loss_test:0.09951, lr:3.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.460, tt:5635.068\n",
      "Ep:185, loss:0.00000, loss_test:0.10042, lr:3.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.463, tt:5666.192\n",
      "Ep:186, loss:0.00000, loss_test:0.10016, lr:2.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.454, tt:5694.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:187, loss:0.00000, loss_test:0.09990, lr:2.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.450, tt:5724.614\n",
      "Ep:188, loss:0.00000, loss_test:0.10052, lr:2.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.451, tt:5755.275\n",
      "Ep:189, loss:0.00000, loss_test:0.09986, lr:2.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.452, tt:5785.868\n",
      "Ep:190, loss:0.00000, loss_test:0.10001, lr:2.88e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.458, tt:5817.455\n",
      "Ep:191, loss:0.00000, loss_test:0.09934, lr:2.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.465, tt:5849.263\n",
      "Ep:192, loss:0.00000, loss_test:0.09965, lr:2.82e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.464, tt:5879.623\n",
      "Ep:193, loss:0.00000, loss_test:0.10019, lr:2.79e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.475, tt:5912.105\n",
      "Ep:194, loss:0.00000, loss_test:0.10108, lr:2.76e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.478, tt:5943.217\n",
      "Ep:195, loss:0.00000, loss_test:0.10104, lr:2.73e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.480, tt:5974.111\n",
      "Ep:196, loss:0.00000, loss_test:0.10091, lr:2.71e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.480, tt:6004.545\n",
      "Ep:197, loss:0.00000, loss_test:0.10023, lr:2.68e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.481, tt:6035.175\n",
      "Ep:198, loss:0.00000, loss_test:0.09920, lr:2.65e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.471, tt:6063.730\n",
      "Ep:199, loss:0.00000, loss_test:0.09972, lr:2.63e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.467, tt:6093.333\n",
      "Ep:200, loss:0.00000, loss_test:0.09912, lr:2.60e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.468, tt:6124.029\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02082, lr:6.00e-02, fs:0.64615 (r=0.848,p=0.522),  time:25.716, tt:25.716\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02361, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:23.002, tt:46.005\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02576, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.066, tt:69.198\n",
      "Ep:3, loss:0.00005, loss_test:0.02624, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.086, tt:92.345\n",
      "Ep:4, loss:0.00005, loss_test:0.02593, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.750, tt:118.748\n",
      "Ep:5, loss:0.00005, loss_test:0.02511, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.700, tt:148.199\n",
      "Ep:6, loss:0.00005, loss_test:0.02389, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:25.489, tt:178.426\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02255, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:26.132, tt:209.056\n",
      "Ep:8, loss:0.00004, loss_test:0.02139, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:26.660, tt:239.940\n",
      "Ep:9, loss:0.00004, loss_test:0.02065, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:27.028, tt:270.284\n",
      "Ep:10, loss:0.00004, loss_test:0.02026, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:27.331, tt:300.643\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:27.679, tt:332.151\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01922, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:27.955, tt:363.417\n",
      "Ep:13, loss:0.00004, loss_test:0.01857, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:28.142, tt:393.994\n",
      "Ep:14, loss:0.00004, loss_test:0.01811, lr:6.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:28.378, tt:425.669\n",
      "Ep:15, loss:0.00004, loss_test:0.01781, lr:6.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:28.616, tt:457.849\n",
      "Ep:16, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:28.832, tt:490.137\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:28.990, tt:521.818\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:29.137, tt:553.603\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01674, lr:6.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:29.242, tt:584.837\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:29.445, tt:618.335\n",
      "Ep:21, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:29.509, tt:649.207\n",
      "Ep:22, loss:0.00003, loss_test:0.01623, lr:6.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:29.580, tt:680.344\n",
      "Ep:23, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:29.641, tt:711.395\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01591, lr:6.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:29.753, tt:743.830\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:29.802, tt:774.846\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:29.855, tt:806.072\n",
      "Ep:27, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:29.953, tt:838.675\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01547, lr:6.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:30.024, tt:870.691\n",
      "Ep:29, loss:0.00003, loss_test:0.01535, lr:6.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:30.040, tt:901.194\n",
      "Ep:30, loss:0.00003, loss_test:0.01525, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:30.055, tt:931.713\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:30.136, tt:964.349\n",
      "Ep:32, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.161, tt:995.300\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01497, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:30.169, tt:1025.755\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01492, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:30.197, tt:1056.889\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:30.249, tt:1088.964\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:30.317, tt:1121.732\n",
      "Ep:37, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:30.331, tt:1152.591\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:30.350, tt:1183.667\n",
      "Ep:39, loss:0.00002, loss_test:0.01471, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:30.369, tt:1214.778\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01469, lr:6.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:30.377, tt:1245.441\n",
      "Ep:41, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:30.375, tt:1275.747\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:30.398, tt:1307.115\n",
      "Ep:43, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:30.405, tt:1337.833\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:30.448, tt:1370.178\n",
      "Ep:45, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.470, tt:1401.600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:30.494, tt:1433.204\n",
      "Ep:47, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.513, tt:1464.612\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.519, tt:1495.440\n",
      "Ep:49, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:30.539, tt:1526.967\n",
      "Ep:50, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.563, tt:1558.706\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.569, tt:1589.574\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.581, tt:1620.778\n",
      "Ep:53, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:30.600, tt:1652.395\n",
      "Ep:54, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:30.626, tt:1684.452\n",
      "Ep:55, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:30.646, tt:1716.171\n",
      "Ep:56, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:30.677, tt:1748.562\n",
      "Ep:57, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:30.684, tt:1779.685\n",
      "Ep:58, loss:0.00002, loss_test:0.01469, lr:6.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:30.731, tt:1813.108\n",
      "Ep:59, loss:0.00002, loss_test:0.01470, lr:6.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:30.747, tt:1844.827\n",
      "Ep:60, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:30.751, tt:1875.786\n",
      "Ep:61, loss:0.00002, loss_test:0.01469, lr:6.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:30.752, tt:1906.646\n",
      "Ep:62, loss:0.00002, loss_test:0.01472, lr:6.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:30.784, tt:1939.373\n",
      "Ep:63, loss:0.00002, loss_test:0.01471, lr:5.94e-02, fs:0.78218 (r=0.798,p=0.767),  time:30.821, tt:1972.532\n",
      "Ep:64, loss:0.00002, loss_test:0.01472, lr:5.88e-02, fs:0.76382 (r=0.768,p=0.760),  time:30.837, tt:2004.399\n",
      "Ep:65, loss:0.00002, loss_test:0.01471, lr:5.82e-02, fs:0.76382 (r=0.768,p=0.760),  time:30.850, tt:2036.115\n",
      "Ep:66, loss:0.00002, loss_test:0.01473, lr:5.76e-02, fs:0.76382 (r=0.768,p=0.760),  time:30.855, tt:2067.273\n",
      "Ep:67, loss:0.00002, loss_test:0.01474, lr:5.71e-02, fs:0.76382 (r=0.768,p=0.760),  time:30.852, tt:2097.909\n",
      "Ep:68, loss:0.00002, loss_test:0.01476, lr:5.65e-02, fs:0.75758 (r=0.758,p=0.758),  time:30.884, tt:2131.021\n",
      "Ep:69, loss:0.00002, loss_test:0.01478, lr:5.59e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.906, tt:2163.421\n",
      "Ep:70, loss:0.00001, loss_test:0.01484, lr:5.54e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.896, tt:2193.589\n",
      "Ep:71, loss:0.00001, loss_test:0.01484, lr:5.48e-02, fs:0.75127 (r=0.747,p=0.755),  time:30.896, tt:2224.492\n",
      "Ep:72, loss:0.00001, loss_test:0.01483, lr:5.43e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.909, tt:2256.375\n",
      "Ep:73, loss:0.00001, loss_test:0.01485, lr:5.37e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.926, tt:2288.550\n",
      "Ep:74, loss:0.00001, loss_test:0.01487, lr:5.32e-02, fs:0.75510 (r=0.747,p=0.763),  time:30.943, tt:2320.693\n",
      "Ep:75, loss:0.00001, loss_test:0.01492, lr:5.27e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.966, tt:2353.389\n",
      "Ep:76, loss:0.00001, loss_test:0.01496, lr:5.21e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.970, tt:2384.672\n",
      "Ep:77, loss:0.00001, loss_test:0.01494, lr:5.16e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.973, tt:2415.919\n",
      "Ep:78, loss:0.00001, loss_test:0.01494, lr:5.11e-02, fs:0.76289 (r=0.747,p=0.779),  time:30.990, tt:2448.178\n",
      "Ep:79, loss:0.00001, loss_test:0.01496, lr:5.06e-02, fs:0.76289 (r=0.747,p=0.779),  time:31.008, tt:2480.673\n",
      "Ep:80, loss:0.00001, loss_test:0.01496, lr:5.01e-02, fs:0.76289 (r=0.747,p=0.779),  time:31.006, tt:2511.472\n",
      "Ep:81, loss:0.00001, loss_test:0.01499, lr:4.96e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.987, tt:2540.899\n",
      "Ep:82, loss:0.00001, loss_test:0.01500, lr:4.91e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.984, tt:2571.642\n",
      "Ep:83, loss:0.00001, loss_test:0.01498, lr:4.86e-02, fs:0.75648 (r=0.737,p=0.777),  time:30.976, tt:2601.953\n",
      "Ep:84, loss:0.00001, loss_test:0.01499, lr:4.81e-02, fs:0.76042 (r=0.737,p=0.785),  time:30.961, tt:2631.656\n",
      "Ep:85, loss:0.00001, loss_test:0.01501, lr:4.76e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.959, tt:2662.440\n",
      "Ep:86, loss:0.00001, loss_test:0.01502, lr:4.71e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.963, tt:2693.819\n",
      "Ep:87, loss:0.00001, loss_test:0.01502, lr:4.67e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.959, tt:2724.382\n",
      "Ep:88, loss:0.00001, loss_test:0.01502, lr:4.62e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.963, tt:2755.744\n",
      "Ep:89, loss:0.00001, loss_test:0.01502, lr:4.57e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.971, tt:2787.432\n",
      "Ep:90, loss:0.00001, loss_test:0.01501, lr:4.53e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.969, tt:2818.166\n",
      "Ep:91, loss:0.00001, loss_test:0.01499, lr:4.48e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.949, tt:2847.322\n",
      "Ep:92, loss:0.00001, loss_test:0.01501, lr:4.44e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.947, tt:2878.092\n",
      "Ep:93, loss:0.00001, loss_test:0.01500, lr:4.39e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.952, tt:2909.503\n",
      "Ep:94, loss:0.00001, loss_test:0.01500, lr:4.35e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.956, tt:2940.802\n",
      "Ep:95, loss:0.00001, loss_test:0.01501, lr:4.31e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.953, tt:2971.490\n",
      "Ep:96, loss:0.00001, loss_test:0.01506, lr:4.26e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.976, tt:3004.629\n",
      "Ep:97, loss:0.00001, loss_test:0.01507, lr:4.22e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.970, tt:3035.066\n",
      "Ep:98, loss:0.00001, loss_test:0.01507, lr:4.18e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.972, tt:3066.180\n",
      "Ep:99, loss:0.00001, loss_test:0.01506, lr:4.14e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.989, tt:3098.901\n",
      "Ep:100, loss:0.00001, loss_test:0.01505, lr:4.10e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.986, tt:3129.603\n",
      "Ep:101, loss:0.00001, loss_test:0.01504, lr:4.05e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.997, tt:3161.711\n",
      "Ep:102, loss:0.00001, loss_test:0.01505, lr:4.01e-02, fs:0.78919 (r=0.737,p=0.849),  time:31.003, tt:3193.257\n",
      "Ep:103, loss:0.00001, loss_test:0.01506, lr:3.97e-02, fs:0.79348 (r=0.737,p=0.859),  time:31.005, tt:3224.549\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.01509, lr:3.97e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.005, tt:3255.544\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01509, lr:3.97e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.014, tt:3287.435\n",
      "Ep:106, loss:0.00001, loss_test:0.01507, lr:3.97e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.015, tt:3318.606\n",
      "Ep:107, loss:0.00001, loss_test:0.01509, lr:3.97e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.015, tt:3349.628\n",
      "Ep:108, loss:0.00001, loss_test:0.01510, lr:3.97e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.001, tt:3379.087\n",
      "Ep:109, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.994, tt:3409.310\n",
      "Ep:110, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.988, tt:3439.617\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.990, tt:3470.868\n",
      "Ep:112, loss:0.00001, loss_test:0.01509, lr:3.97e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.995, tt:3502.463\n",
      "Ep:113, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.991, tt:3532.994\n",
      "Ep:114, loss:0.00001, loss_test:0.01513, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.998, tt:3564.753\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.01513, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.998, tt:3595.731\n",
      "Ep:116, loss:0.00001, loss_test:0.01515, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.003, tt:3627.346\n",
      "Ep:117, loss:0.00001, loss_test:0.01513, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.020, tt:3660.362\n",
      "Ep:118, loss:0.00001, loss_test:0.01510, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.003, tt:3689.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00001, loss_test:0.01512, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.004, tt:3720.501\n",
      "Ep:120, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.008, tt:3752.016\n",
      "Ep:121, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.016, tt:3783.933\n",
      "Ep:122, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.008, tt:3814.040\n",
      "Ep:123, loss:0.00001, loss_test:0.01512, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.015, tt:3845.896\n",
      "Ep:124, loss:0.00001, loss_test:0.01512, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.020, tt:3877.462\n",
      "Ep:125, loss:0.00001, loss_test:0.01511, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.012, tt:3907.465\n",
      "Ep:126, loss:0.00001, loss_test:0.01513, lr:3.93e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.010, tt:3938.288\n",
      "Ep:127, loss:0.00001, loss_test:0.01512, lr:3.89e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.019, tt:3970.442\n",
      "Ep:128, loss:0.00001, loss_test:0.01514, lr:3.86e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.018, tt:4001.350\n",
      "Ep:129, loss:0.00001, loss_test:0.01513, lr:3.82e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.028, tt:4033.617\n",
      "Ep:130, loss:0.00001, loss_test:0.01514, lr:3.78e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.023, tt:4064.068\n",
      "Ep:131, loss:0.00001, loss_test:0.01514, lr:3.74e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.028, tt:4095.736\n",
      "Ep:132, loss:0.00001, loss_test:0.01514, lr:3.70e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.025, tt:4126.329\n",
      "Ep:133, loss:0.00001, loss_test:0.01511, lr:3.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.027, tt:4157.589\n",
      "Ep:134, loss:0.00001, loss_test:0.01508, lr:3.63e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.033, tt:4189.444\n",
      "Ep:135, loss:0.00001, loss_test:0.01511, lr:3.59e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.041, tt:4221.577\n",
      "Ep:136, loss:0.00001, loss_test:0.01511, lr:3.56e-02, fs:0.80874 (r=0.747,p=0.881),  time:31.037, tt:4252.064\n",
      "Ep:137, loss:0.00001, loss_test:0.01512, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.022, tt:4281.016\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00001, loss_test:0.01511, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.015, tt:4311.050\n",
      "Ep:139, loss:0.00001, loss_test:0.01509, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.056, tt:4347.795\n",
      "Ep:140, loss:0.00001, loss_test:0.01510, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.056, tt:4378.926\n",
      "Ep:141, loss:0.00001, loss_test:0.01512, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.055, tt:4409.842\n",
      "Ep:142, loss:0.00001, loss_test:0.01512, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.054, tt:4440.652\n",
      "Ep:143, loss:0.00001, loss_test:0.01511, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.053, tt:4471.611\n",
      "Ep:144, loss:0.00001, loss_test:0.01513, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.057, tt:4503.270\n",
      "Ep:145, loss:0.00001, loss_test:0.01513, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.057, tt:4534.305\n",
      "Ep:146, loss:0.00001, loss_test:0.01510, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.058, tt:4565.538\n",
      "Ep:147, loss:0.00001, loss_test:0.01510, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.063, tt:4597.333\n",
      "Ep:148, loss:0.00001, loss_test:0.01512, lr:3.52e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.065, tt:4628.641\n",
      "Ep:149, loss:0.00001, loss_test:0.01513, lr:3.49e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.065, tt:4659.745\n",
      "Ep:150, loss:0.00001, loss_test:0.01512, lr:3.45e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.072, tt:4691.881\n",
      "Ep:151, loss:0.00001, loss_test:0.01510, lr:3.42e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.075, tt:4723.328\n",
      "Ep:152, loss:0.00001, loss_test:0.01510, lr:3.38e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.080, tt:4755.262\n",
      "Ep:153, loss:0.00001, loss_test:0.01509, lr:3.35e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.093, tt:4788.298\n",
      "Ep:154, loss:0.00001, loss_test:0.01513, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.084, tt:4818.044\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.01515, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.079, tt:4848.351\n",
      "Ep:156, loss:0.00001, loss_test:0.01517, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.072, tt:4878.349\n",
      "Ep:157, loss:0.00001, loss_test:0.01515, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.066, tt:4908.384\n",
      "Ep:158, loss:0.00001, loss_test:0.01514, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.064, tt:4939.119\n",
      "Ep:159, loss:0.00001, loss_test:0.01513, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.057, tt:4969.142\n",
      "Ep:160, loss:0.00001, loss_test:0.01512, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.055, tt:4999.901\n",
      "Ep:161, loss:0.00001, loss_test:0.01513, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.053, tt:5030.571\n",
      "Ep:162, loss:0.00001, loss_test:0.01514, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.052, tt:5061.458\n",
      "Ep:163, loss:0.00001, loss_test:0.01516, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.047, tt:5091.777\n",
      "Ep:164, loss:0.00001, loss_test:0.01517, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.039, tt:5121.484\n",
      "Ep:165, loss:0.00001, loss_test:0.01517, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.040, tt:5152.589\n",
      "Ep:166, loss:0.00001, loss_test:0.01518, lr:3.28e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.036, tt:5182.946\n",
      "Ep:167, loss:0.00001, loss_test:0.01519, lr:3.25e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.032, tt:5213.441\n",
      "Ep:168, loss:0.00001, loss_test:0.01519, lr:3.22e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.041, tt:5245.950\n",
      "Ep:169, loss:0.00001, loss_test:0.01518, lr:3.19e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.041, tt:5277.008\n",
      "Ep:170, loss:0.00001, loss_test:0.01518, lr:3.15e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.046, tt:5308.795\n",
      "Ep:171, loss:0.00001, loss_test:0.01519, lr:3.12e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.048, tt:5340.216\n",
      "Ep:172, loss:0.00001, loss_test:0.01517, lr:3.09e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.052, tt:5372.079\n",
      "Ep:173, loss:0.00001, loss_test:0.01519, lr:3.06e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.055, tt:5403.541\n",
      "Ep:174, loss:0.00001, loss_test:0.01520, lr:3.03e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.046, tt:5433.058\n",
      "Ep:175, loss:0.00001, loss_test:0.01522, lr:3.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.046, tt:5464.090\n",
      "Ep:176, loss:0.00001, loss_test:0.01523, lr:2.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.058, tt:5497.249\n",
      "Ep:177, loss:0.00001, loss_test:0.01523, lr:2.94e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.074, tt:5531.255\n",
      "Ep:178, loss:0.00001, loss_test:0.01524, lr:2.91e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.079, tt:5563.110\n",
      "Ep:179, loss:0.00001, loss_test:0.01525, lr:2.88e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.075, tt:5593.578\n",
      "Ep:180, loss:0.00001, loss_test:0.01523, lr:2.85e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.072, tt:5623.997\n",
      "Ep:181, loss:0.00001, loss_test:0.01523, lr:2.82e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.064, tt:5653.736\n",
      "Ep:182, loss:0.00001, loss_test:0.01524, lr:2.80e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.070, tt:5685.820\n",
      "Ep:183, loss:0.00001, loss_test:0.01524, lr:2.77e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.069, tt:5716.764\n",
      "Ep:184, loss:0.00001, loss_test:0.01525, lr:2.74e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.062, tt:5746.511\n",
      "Ep:185, loss:0.00001, loss_test:0.01527, lr:2.71e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.063, tt:5777.693\n",
      "Ep:186, loss:0.00001, loss_test:0.01527, lr:2.69e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.064, tt:5808.897\n",
      "Ep:187, loss:0.00001, loss_test:0.01529, lr:2.66e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.063, tt:5839.816\n",
      "Ep:188, loss:0.00001, loss_test:0.01529, lr:2.63e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.066, tt:5871.390\n",
      "Ep:189, loss:0.00001, loss_test:0.01529, lr:2.61e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.069, tt:5903.100\n",
      "Ep:190, loss:0.00001, loss_test:0.01528, lr:2.58e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.071, tt:5934.483\n",
      "Ep:191, loss:0.00001, loss_test:0.01527, lr:2.55e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.073, tt:5966.110\n",
      "Ep:192, loss:0.00001, loss_test:0.01529, lr:2.53e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.072, tt:5996.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:193, loss:0.00001, loss_test:0.01530, lr:2.50e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.074, tt:6028.437\n",
      "Ep:194, loss:0.00001, loss_test:0.01533, lr:2.48e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.076, tt:6059.852\n",
      "Ep:195, loss:0.00001, loss_test:0.01532, lr:2.45e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.071, tt:6089.945\n",
      "Ep:196, loss:0.00001, loss_test:0.01533, lr:2.43e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.070, tt:6120.752\n",
      "Ep:197, loss:0.00001, loss_test:0.01534, lr:2.40e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.066, tt:6150.969\n",
      "Ep:198, loss:0.00001, loss_test:0.01534, lr:2.38e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.071, tt:6183.124\n",
      "Ep:199, loss:0.00001, loss_test:0.01534, lr:2.36e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.074, tt:6214.783\n",
      "Ep:200, loss:0.00001, loss_test:0.01536, lr:2.33e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.075, tt:6246.154\n",
      "Ep:201, loss:0.00001, loss_test:0.01536, lr:2.31e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.081, tt:6278.402\n",
      "Ep:202, loss:0.00001, loss_test:0.01537, lr:2.29e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.083, tt:6309.946\n",
      "Ep:203, loss:0.00001, loss_test:0.01536, lr:2.26e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.080, tt:6340.363\n",
      "Ep:204, loss:0.00001, loss_test:0.01539, lr:2.24e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.081, tt:6371.546\n",
      "Ep:205, loss:0.00001, loss_test:0.01538, lr:2.22e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.076, tt:6401.625\n",
      "Ep:206, loss:0.00001, loss_test:0.01538, lr:2.20e-02, fs:0.81768 (r=0.747,p=0.902),  time:31.059, tt:6429.131\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14325, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.440, tt:33.440\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14261, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.562, tt:65.124\n",
      "Ep:2, loss:0.00028, loss_test:0.14158, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.264, tt:90.791\n",
      "Ep:3, loss:0.00028, loss_test:0.13995, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:28.436, tt:113.745\n",
      "Ep:4, loss:0.00027, loss_test:0.13740, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:28.429, tt:142.143\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00027, loss_test:0.13364, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:28.552, tt:171.312\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.12900, lr:1.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:28.941, tt:202.585\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12389, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:29.292, tt:234.339\n",
      "Ep:8, loss:0.00024, loss_test:0.12122, lr:1.00e-02, fs:0.62037 (r=0.677,p=0.573),  time:29.520, tt:265.676\n",
      "Ep:9, loss:0.00023, loss_test:0.11935, lr:1.00e-02, fs:0.62626 (r=0.626,p=0.626),  time:29.843, tt:298.431\n",
      "Ep:10, loss:0.00023, loss_test:0.11601, lr:1.00e-02, fs:0.63158 (r=0.667,p=0.600),  time:29.774, tt:327.518\n",
      "Ep:11, loss:0.00022, loss_test:0.11495, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:29.969, tt:359.624\n",
      "Ep:12, loss:0.00021, loss_test:0.11334, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:30.173, tt:392.254\n",
      "Ep:13, loss:0.00021, loss_test:0.11034, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:30.336, tt:424.709\n",
      "Ep:14, loss:0.00020, loss_test:0.10692, lr:1.00e-02, fs:0.66321 (r=0.646,p=0.681),  time:30.425, tt:456.376\n",
      "Ep:15, loss:0.00020, loss_test:0.10399, lr:1.00e-02, fs:0.68657 (r=0.697,p=0.676),  time:30.446, tt:487.143\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10238, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.579, tt:519.841\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10007, lr:1.00e-02, fs:0.69474 (r=0.667,p=0.725),  time:30.657, tt:551.822\n",
      "Ep:18, loss:0.00018, loss_test:0.09835, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:30.709, tt:583.477\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09767, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:30.816, tt:616.329\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09654, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:30.884, tt:648.570\n",
      "Ep:21, loss:0.00017, loss_test:0.09553, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.919, tt:680.210\n",
      "Ep:22, loss:0.00016, loss_test:0.09506, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.951, tt:711.871\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09447, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:31.034, tt:744.804\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09369, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:31.096, tt:777.390\n",
      "Ep:25, loss:0.00015, loss_test:0.09340, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:31.193, tt:811.014\n",
      "Ep:26, loss:0.00015, loss_test:0.09287, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:31.244, tt:843.577\n",
      "Ep:27, loss:0.00014, loss_test:0.09228, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:31.367, tt:878.277\n",
      "Ep:28, loss:0.00014, loss_test:0.09136, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:31.434, tt:911.592\n",
      "Ep:29, loss:0.00014, loss_test:0.09130, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:31.480, tt:944.392\n",
      "Ep:30, loss:0.00013, loss_test:0.09071, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:31.503, tt:976.583\n",
      "Ep:31, loss:0.00013, loss_test:0.08971, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:31.462, tt:1006.783\n",
      "Ep:32, loss:0.00013, loss_test:0.08926, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:31.524, tt:1040.281\n",
      "Ep:33, loss:0.00012, loss_test:0.08801, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:31.522, tt:1071.736\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08761, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:31.547, tt:1104.156\n",
      "Ep:35, loss:0.00012, loss_test:0.08806, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:31.588, tt:1137.156\n",
      "Ep:36, loss:0.00012, loss_test:0.08701, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:31.590, tt:1168.844\n",
      "Ep:37, loss:0.00011, loss_test:0.08768, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:31.599, tt:1200.759\n",
      "Ep:38, loss:0.00011, loss_test:0.08678, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:31.615, tt:1232.999\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08628, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:31.647, tt:1265.876\n",
      "Ep:40, loss:0.00010, loss_test:0.08701, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:31.658, tt:1297.971\n",
      "Ep:41, loss:0.00010, loss_test:0.08523, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:31.683, tt:1330.678\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.08392, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:31.710, tt:1458.659\n",
      "Ep:46, loss:0.00009, loss_test:0.08564, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:31.702, tt:1490.015\n",
      "Ep:47, loss:0.00009, loss_test:0.08398, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:31.667, tt:1520.012\n",
      "Ep:48, loss:0.00009, loss_test:0.08598, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:31.666, tt:1551.644\n",
      "Ep:49, loss:0.00008, loss_test:0.08448, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:31.689, tt:1584.443\n",
      "Ep:50, loss:0.00008, loss_test:0.08435, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:31.727, tt:1618.062\n",
      "Ep:51, loss:0.00008, loss_test:0.08429, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:31.770, tt:1652.041\n",
      "Ep:52, loss:0.00008, loss_test:0.08555, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:31.801, tt:1685.465\n",
      "Ep:53, loss:0.00008, loss_test:0.08454, lr:9.90e-03, fs:0.74317 (r=0.687,p=0.810),  time:31.836, tt:1719.136\n",
      "Ep:54, loss:0.00008, loss_test:0.08546, lr:9.80e-03, fs:0.73034 (r=0.657,p=0.823),  time:31.842, tt:1751.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00007, loss_test:0.08391, lr:9.70e-03, fs:0.73913 (r=0.687,p=0.800),  time:31.833, tt:1782.638\n",
      "Ep:56, loss:0.00007, loss_test:0.08696, lr:9.61e-03, fs:0.71264 (r=0.626,p=0.827),  time:31.824, tt:1813.996\n",
      "Ep:57, loss:0.00007, loss_test:0.08442, lr:9.51e-03, fs:0.73626 (r=0.677,p=0.807),  time:31.847, tt:1847.155\n",
      "Ep:58, loss:0.00007, loss_test:0.08696, lr:9.41e-03, fs:0.71264 (r=0.626,p=0.827),  time:31.830, tt:1877.986\n",
      "Ep:59, loss:0.00007, loss_test:0.08541, lr:9.32e-03, fs:0.73446 (r=0.657,p=0.833),  time:31.819, tt:1909.120\n",
      "Ep:60, loss:0.00007, loss_test:0.08539, lr:9.23e-03, fs:0.73034 (r=0.657,p=0.823),  time:31.811, tt:1940.462\n",
      "Ep:61, loss:0.00007, loss_test:0.08716, lr:9.14e-03, fs:0.71264 (r=0.626,p=0.827),  time:31.830, tt:1973.460\n",
      "Ep:62, loss:0.00006, loss_test:0.08409, lr:9.04e-03, fs:0.73333 (r=0.667,p=0.815),  time:31.827, tt:2005.099\n",
      "Ep:63, loss:0.00006, loss_test:0.08759, lr:8.95e-03, fs:0.71676 (r=0.626,p=0.838),  time:31.815, tt:2036.139\n",
      "Ep:64, loss:0.00006, loss_test:0.08477, lr:8.86e-03, fs:0.72222 (r=0.657,p=0.802),  time:31.817, tt:2068.137\n",
      "Ep:65, loss:0.00006, loss_test:0.08664, lr:8.78e-03, fs:0.72727 (r=0.646,p=0.831),  time:31.825, tt:2100.444\n",
      "Ep:66, loss:0.00006, loss_test:0.08530, lr:8.69e-03, fs:0.73034 (r=0.657,p=0.823),  time:31.810, tt:2131.260\n",
      "Ep:67, loss:0.00006, loss_test:0.08504, lr:8.60e-03, fs:0.72222 (r=0.657,p=0.802),  time:31.822, tt:2163.907\n",
      "Ep:68, loss:0.00006, loss_test:0.08615, lr:8.51e-03, fs:0.73446 (r=0.657,p=0.833),  time:31.830, tt:2196.294\n",
      "Ep:69, loss:0.00005, loss_test:0.08519, lr:8.43e-03, fs:0.73743 (r=0.667,p=0.825),  time:31.843, tt:2228.999\n",
      "Ep:70, loss:0.00005, loss_test:0.08710, lr:8.35e-03, fs:0.73143 (r=0.646,p=0.842),  time:31.869, tt:2262.678\n",
      "Ep:71, loss:0.00005, loss_test:0.08555, lr:8.26e-03, fs:0.73743 (r=0.667,p=0.825),  time:31.861, tt:2293.964\n",
      "Ep:72, loss:0.00005, loss_test:0.08507, lr:8.18e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.869, tt:2326.462\n",
      "Ep:73, loss:0.00005, loss_test:0.08618, lr:8.10e-03, fs:0.73864 (r=0.657,p=0.844),  time:31.842, tt:2356.316\n",
      "Ep:74, loss:0.00005, loss_test:0.08620, lr:8.02e-03, fs:0.73743 (r=0.667,p=0.825),  time:31.841, tt:2388.087\n",
      "Ep:75, loss:0.00005, loss_test:0.08495, lr:7.94e-03, fs:0.74444 (r=0.677,p=0.827),  time:31.835, tt:2419.468\n",
      "Ep:76, loss:0.00005, loss_test:0.08649, lr:7.86e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.812, tt:2449.540\n",
      "Ep:77, loss:0.00005, loss_test:0.08509, lr:7.78e-03, fs:0.74860 (r=0.677,p=0.838),  time:31.807, tt:2480.922\n",
      "Ep:78, loss:0.00005, loss_test:0.08544, lr:7.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:31.827, tt:2514.328\n",
      "Ep:79, loss:0.00004, loss_test:0.08579, lr:7.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.826, tt:2546.119\n",
      "Ep:80, loss:0.00004, loss_test:0.08491, lr:7.55e-03, fs:0.74860 (r=0.677,p=0.838),  time:31.832, tt:2578.389\n",
      "Ep:81, loss:0.00004, loss_test:0.08560, lr:7.47e-03, fs:0.76571 (r=0.677,p=0.882),  time:31.828, tt:2609.893\n",
      "Ep:82, loss:0.00004, loss_test:0.08456, lr:7.40e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.824, tt:2641.393\n",
      "Ep:83, loss:0.00004, loss_test:0.08565, lr:7.32e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.825, tt:2673.265\n",
      "Ep:84, loss:0.00004, loss_test:0.08416, lr:7.25e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.831, tt:2705.621\n",
      "Ep:85, loss:0.00004, loss_test:0.08569, lr:7.18e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.830, tt:2737.396\n",
      "Ep:86, loss:0.00004, loss_test:0.08444, lr:7.11e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.827, tt:2768.939\n",
      "Ep:87, loss:0.00004, loss_test:0.08298, lr:7.03e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.822, tt:2800.303\n",
      "Ep:88, loss:0.00004, loss_test:0.08829, lr:6.96e-03, fs:0.74854 (r=0.646,p=0.889),  time:31.840, tt:2833.784\n",
      "Ep:89, loss:0.00004, loss_test:0.08162, lr:6.89e-03, fs:0.75556 (r=0.687,p=0.840),  time:31.858, tt:2867.256\n",
      "Ep:90, loss:0.00004, loss_test:0.08584, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.876, tt:2900.675\n",
      "Ep:91, loss:0.00004, loss_test:0.08471, lr:6.76e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.890, tt:2933.898\n",
      "Ep:92, loss:0.00004, loss_test:0.08160, lr:6.69e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.891, tt:2965.839\n",
      "Ep:93, loss:0.00004, loss_test:0.08611, lr:6.62e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.886, tt:2997.244\n",
      "Ep:94, loss:0.00004, loss_test:0.08154, lr:6.56e-03, fs:0.76136 (r=0.677,p=0.870),  time:31.892, tt:3029.731\n",
      "Ep:95, loss:0.00003, loss_test:0.08446, lr:6.49e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.887, tt:3061.189\n",
      "Ep:96, loss:0.00003, loss_test:0.08503, lr:6.43e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.895, tt:3093.782\n",
      "Ep:97, loss:0.00003, loss_test:0.08080, lr:6.36e-03, fs:0.76571 (r=0.677,p=0.882),  time:31.911, tt:3127.236\n",
      "Ep:98, loss:0.00003, loss_test:0.08392, lr:6.30e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.908, tt:3158.855\n",
      "Ep:99, loss:0.00003, loss_test:0.08163, lr:6.24e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.904, tt:3190.366\n",
      "Ep:100, loss:0.00003, loss_test:0.08253, lr:6.17e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.914, tt:3223.329\n",
      "Ep:101, loss:0.00003, loss_test:0.08394, lr:6.11e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.912, tt:3254.986\n",
      "Ep:102, loss:0.00003, loss_test:0.08095, lr:6.05e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.923, tt:3288.117\n",
      "Ep:103, loss:0.00003, loss_test:0.08257, lr:5.99e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.917, tt:3319.409\n",
      "Ep:104, loss:0.00003, loss_test:0.08226, lr:5.93e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.912, tt:3350.764\n",
      "Ep:105, loss:0.00003, loss_test:0.08007, lr:5.87e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.917, tt:3383.238\n",
      "Ep:106, loss:0.00003, loss_test:0.08337, lr:5.81e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.912, tt:3414.540\n",
      "Ep:107, loss:0.00003, loss_test:0.08020, lr:5.75e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.904, tt:3445.620\n",
      "Ep:108, loss:0.00003, loss_test:0.08294, lr:5.70e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.922, tt:3479.450\n",
      "Ep:109, loss:0.00003, loss_test:0.08270, lr:5.64e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.922, tt:3511.453\n",
      "Ep:110, loss:0.00003, loss_test:0.07971, lr:5.58e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.922, tt:3543.392\n",
      "Ep:111, loss:0.00003, loss_test:0.08282, lr:5.53e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.926, tt:3575.671\n",
      "Ep:112, loss:0.00003, loss_test:0.08030, lr:5.47e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.923, tt:3607.347\n",
      "Ep:113, loss:0.00003, loss_test:0.08047, lr:5.42e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.916, tt:3638.447\n",
      "Ep:114, loss:0.00003, loss_test:0.08128, lr:5.36e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.904, tt:3668.930\n",
      "Ep:115, loss:0.00003, loss_test:0.08033, lr:5.31e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.898, tt:3700.201\n",
      "Ep:116, loss:0.00003, loss_test:0.08026, lr:5.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.892, tt:3731.417\n",
      "Ep:117, loss:0.00003, loss_test:0.08085, lr:5.20e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:3763.600\n",
      "Ep:118, loss:0.00003, loss_test:0.07987, lr:5.15e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.884, tt:3794.250\n",
      "Ep:119, loss:0.00003, loss_test:0.08055, lr:5.10e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.874, tt:3824.821\n",
      "Ep:120, loss:0.00003, loss_test:0.08044, lr:5.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.856, tt:3854.572\n",
      "Ep:121, loss:0.00003, loss_test:0.08090, lr:5.00e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.860, tt:3886.959\n",
      "Ep:122, loss:0.00002, loss_test:0.07989, lr:4.95e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.859, tt:3918.709\n",
      "Ep:123, loss:0.00002, loss_test:0.08153, lr:4.90e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.854, tt:3949.927\n",
      "Ep:124, loss:0.00002, loss_test:0.07906, lr:4.85e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.857, tt:3982.179\n",
      "Ep:125, loss:0.00002, loss_test:0.08088, lr:4.80e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.862, tt:4014.671\n",
      "Ep:126, loss:0.00002, loss_test:0.07990, lr:4.75e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.863, tt:4046.611\n",
      "Ep:127, loss:0.00002, loss_test:0.08052, lr:4.71e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.879, tt:4080.450\n",
      "Ep:128, loss:0.00002, loss_test:0.08117, lr:4.66e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.874, tt:4111.785\n",
      "Ep:129, loss:0.00002, loss_test:0.07899, lr:4.61e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.869, tt:4142.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.08098, lr:4.57e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.890, tt:4177.533\n",
      "Ep:131, loss:0.00002, loss_test:0.07971, lr:4.52e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.875, tt:4207.472\n",
      "Ep:132, loss:0.00002, loss_test:0.07960, lr:4.48e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.878, tt:4239.787\n",
      "Ep:133, loss:0.00002, loss_test:0.08042, lr:4.43e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.883, tt:4272.338\n",
      "Ep:134, loss:0.00002, loss_test:0.07935, lr:4.39e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.878, tt:4303.521\n",
      "Ep:135, loss:0.00002, loss_test:0.07958, lr:4.34e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.869, tt:4334.140\n",
      "Ep:136, loss:0.00002, loss_test:0.07972, lr:4.30e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.870, tt:4366.182\n",
      "Ep:137, loss:0.00002, loss_test:0.07953, lr:4.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.873, tt:4398.513\n",
      "Ep:138, loss:0.00002, loss_test:0.07953, lr:4.21e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.872, tt:4430.273\n",
      "Ep:139, loss:0.00002, loss_test:0.07963, lr:4.17e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.880, tt:4463.205\n",
      "Ep:140, loss:0.00002, loss_test:0.07960, lr:4.13e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.869, tt:4493.563\n",
      "Ep:141, loss:0.00002, loss_test:0.07982, lr:4.09e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.870, tt:4525.531\n",
      "Ep:142, loss:0.00002, loss_test:0.07905, lr:4.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.860, tt:4556.021\n",
      "Ep:143, loss:0.00002, loss_test:0.08019, lr:4.01e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.867, tt:4588.885\n",
      "Ep:144, loss:0.00002, loss_test:0.07956, lr:3.97e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.859, tt:4619.556\n",
      "Ep:145, loss:0.00002, loss_test:0.07883, lr:3.93e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.854, tt:4650.655\n",
      "Ep:146, loss:0.00002, loss_test:0.08027, lr:3.89e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.884, tt:4686.915\n",
      "Ep:147, loss:0.00002, loss_test:0.07920, lr:3.85e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.891, tt:4719.898\n",
      "Ep:148, loss:0.00002, loss_test:0.08006, lr:3.81e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.897, tt:4752.627\n",
      "Ep:149, loss:0.00002, loss_test:0.08060, lr:3.77e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:4784.262\n",
      "Ep:150, loss:0.00002, loss_test:0.07862, lr:3.73e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.902, tt:4817.149\n",
      "Ep:151, loss:0.00002, loss_test:0.07968, lr:3.70e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.902, tt:4849.152\n",
      "Ep:152, loss:0.00002, loss_test:0.07948, lr:3.66e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.910, tt:4882.207\n",
      "Ep:153, loss:0.00002, loss_test:0.07853, lr:3.62e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.904, tt:4913.162\n",
      "Ep:154, loss:0.00002, loss_test:0.08010, lr:3.59e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.907, tt:4945.552\n",
      "Ep:155, loss:0.00002, loss_test:0.07953, lr:3.55e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.904, tt:4976.975\n",
      "Ep:156, loss:0.00002, loss_test:0.07861, lr:3.52e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.910, tt:5009.849\n",
      "Ep:157, loss:0.00002, loss_test:0.08008, lr:3.48e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.915, tt:5042.509\n",
      "Ep:158, loss:0.00002, loss_test:0.07999, lr:3.45e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.909, tt:5073.597\n",
      "Ep:159, loss:0.00002, loss_test:0.07850, lr:3.41e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:5103.180\n",
      "Ep:160, loss:0.00002, loss_test:0.07976, lr:3.38e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.882, tt:5133.067\n",
      "Ep:161, loss:0.00002, loss_test:0.07955, lr:3.34e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.886, tt:5165.513\n",
      "Ep:162, loss:0.00002, loss_test:0.07812, lr:3.31e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.886, tt:5197.360\n",
      "Ep:163, loss:0.00002, loss_test:0.08023, lr:3.28e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.890, tt:5229.888\n",
      "Ep:164, loss:0.00002, loss_test:0.07924, lr:3.24e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.871, tt:5258.730\n",
      "Ep:165, loss:0.00002, loss_test:0.07850, lr:3.21e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.862, tt:5289.169\n",
      "Ep:166, loss:0.00002, loss_test:0.07994, lr:3.18e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.852, tt:5319.237\n",
      "Ep:167, loss:0.00002, loss_test:0.07901, lr:3.15e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.848, tt:5350.544\n",
      "Ep:168, loss:0.00002, loss_test:0.07888, lr:3.12e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.861, tt:5384.575\n",
      "Ep:169, loss:0.00002, loss_test:0.07940, lr:3.09e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.857, tt:5415.693\n",
      "Ep:170, loss:0.00002, loss_test:0.07854, lr:3.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.860, tt:5448.121\n",
      "Ep:171, loss:0.00002, loss_test:0.07876, lr:3.02e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.865, tt:5480.811\n",
      "Ep:172, loss:0.00002, loss_test:0.07872, lr:2.99e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.884, tt:5515.975\n",
      "Ep:173, loss:0.00002, loss_test:0.07892, lr:2.96e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.890, tt:5548.910\n",
      "Ep:174, loss:0.00002, loss_test:0.07901, lr:2.93e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.892, tt:5581.156\n",
      "Ep:175, loss:0.00002, loss_test:0.07913, lr:2.90e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.890, tt:5612.620\n",
      "Ep:176, loss:0.00002, loss_test:0.07834, lr:2.88e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.893, tt:5644.975\n",
      "Ep:177, loss:0.00002, loss_test:0.07942, lr:2.85e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:5677.302\n",
      "Ep:178, loss:0.00002, loss_test:0.07897, lr:2.82e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.896, tt:5709.385\n",
      "Ep:179, loss:0.00002, loss_test:0.07852, lr:2.79e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:5741.016\n",
      "Ep:180, loss:0.00002, loss_test:0.07915, lr:2.76e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.901, tt:5773.996\n",
      "Ep:181, loss:0.00002, loss_test:0.07816, lr:2.73e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:5804.803\n",
      "Ep:182, loss:0.00002, loss_test:0.07889, lr:2.71e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.888, tt:5835.589\n",
      "Ep:183, loss:0.00002, loss_test:0.07871, lr:2.68e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.892, tt:5868.125\n",
      "Ep:184, loss:0.00002, loss_test:0.07879, lr:2.65e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.900, tt:5901.524\n",
      "Ep:185, loss:0.00002, loss_test:0.07855, lr:2.63e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.895, tt:5932.555\n",
      "Ep:186, loss:0.00002, loss_test:0.07836, lr:2.60e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.897, tt:5964.718\n",
      "Ep:187, loss:0.00002, loss_test:0.07912, lr:2.57e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.896, tt:5996.485\n",
      "Ep:188, loss:0.00002, loss_test:0.07858, lr:2.55e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.891, tt:6027.444\n",
      "Ep:189, loss:0.00002, loss_test:0.07856, lr:2.52e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.899, tt:6060.859\n",
      "Ep:190, loss:0.00002, loss_test:0.07888, lr:2.50e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.903, tt:6093.527\n",
      "Ep:191, loss:0.00002, loss_test:0.07824, lr:2.47e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.906, tt:6125.870\n",
      "Ep:192, loss:0.00002, loss_test:0.07872, lr:2.45e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.910, tt:6158.686\n",
      "Ep:193, loss:0.00002, loss_test:0.07865, lr:2.42e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.915, tt:6191.413\n",
      "Ep:194, loss:0.00002, loss_test:0.07807, lr:2.40e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.913, tt:6223.125\n",
      "Ep:195, loss:0.00002, loss_test:0.07878, lr:2.38e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.918, tt:6255.848\n",
      "Ep:196, loss:0.00002, loss_test:0.07824, lr:2.35e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.922, tt:6288.559\n",
      "Ep:197, loss:0.00002, loss_test:0.07840, lr:2.33e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.919, tt:6320.058\n",
      "Ep:198, loss:0.00002, loss_test:0.07855, lr:2.31e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.920, tt:6352.085\n",
      "Ep:199, loss:0.00002, loss_test:0.07843, lr:2.28e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.921, tt:6384.144\n",
      "Ep:200, loss:0.00002, loss_test:0.07845, lr:2.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.925, tt:6416.971\n",
      "Ep:201, loss:0.00002, loss_test:0.07819, lr:2.24e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.925, tt:6448.817\n",
      "Ep:202, loss:0.00002, loss_test:0.07833, lr:2.21e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.929, tt:6481.500\n",
      "Ep:203, loss:0.00002, loss_test:0.07869, lr:2.19e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.932, tt:6514.185\n",
      "Ep:204, loss:0.00002, loss_test:0.07826, lr:2.17e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.933, tt:6546.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00002, loss_test:0.07832, lr:2.15e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.916, tt:6574.641\n",
      "Ep:206, loss:0.00002, loss_test:0.07845, lr:2.13e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.898, tt:6602.804\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02173, lr:6.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:27.238, tt:27.238\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02292, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:24.884, tt:49.767\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02463, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.721, tt:68.162\n",
      "Ep:3, loss:0.00005, loss_test:0.02491, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.114, tt:92.457\n",
      "Ep:4, loss:0.00005, loss_test:0.02432, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.535, tt:117.673\n",
      "Ep:5, loss:0.00004, loss_test:0.02334, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:24.292, tt:145.752\n",
      "Ep:6, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:24.957, tt:174.696\n",
      "Ep:7, loss:0.00004, loss_test:0.02156, lr:6.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:25.811, tt:206.491\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02111, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:26.551, tt:238.960\n",
      "Ep:9, loss:0.00004, loss_test:0.02060, lr:6.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:27.098, tt:270.979\n",
      "Ep:10, loss:0.00004, loss_test:0.01978, lr:6.00e-02, fs:0.63281 (r=0.818,p=0.516),  time:27.669, tt:304.354\n",
      "Ep:11, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.67925 (r=0.909,p=0.542),  time:28.006, tt:336.077\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01850, lr:6.00e-02, fs:0.70111 (r=0.960,p=0.552),  time:28.249, tt:367.234\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01813, lr:6.00e-02, fs:0.70803 (r=0.980,p=0.554),  time:28.541, tt:399.575\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01781, lr:6.00e-02, fs:0.72388 (r=0.980,p=0.574),  time:28.734, tt:431.008\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01760, lr:6.00e-02, fs:0.71970 (r=0.960,p=0.576),  time:28.883, tt:462.134\n",
      "Ep:16, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:29.073, tt:494.239\n",
      "Ep:17, loss:0.00003, loss_test:0.01748, lr:6.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:29.275, tt:526.947\n",
      "Ep:18, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:29.379, tt:558.202\n",
      "Ep:19, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:29.500, tt:589.993\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:29.637, tt:622.370\n",
      "Ep:21, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:29.730, tt:654.070\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:29.773, tt:684.775\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:29.798, tt:715.163\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:29.877, tt:746.916\n",
      "Ep:25, loss:0.00003, loss_test:0.01597, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:29.930, tt:778.184\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01576, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:29.983, tt:809.529\n",
      "Ep:27, loss:0.00003, loss_test:0.01556, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:30.029, tt:840.804\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:30.087, tt:872.514\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01521, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:30.161, tt:904.838\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01508, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:30.195, tt:936.055\n",
      "Ep:31, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:30.215, tt:966.875\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:30.234, tt:997.720\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:30.243, tt:1028.251\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01455, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:30.284, tt:1059.947\n",
      "Ep:35, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.304, tt:1090.939\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01437, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.334, tt:1122.355\n",
      "Ep:37, loss:0.00002, loss_test:0.01425, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.370, tt:1154.042\n",
      "Ep:38, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.399, tt:1185.545\n",
      "Ep:39, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.432, tt:1217.277\n",
      "Ep:40, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:30.452, tt:1248.520\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:30.450, tt:1278.897\n",
      "Ep:42, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:30.455, tt:1309.567\n",
      "Ep:43, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:30.471, tt:1340.706\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:30.487, tt:1371.911\n",
      "Ep:45, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:30.519, tt:1403.857\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:30.522, tt:1434.544\n",
      "Ep:47, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:30.534, tt:1465.643\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:30.556, tt:1497.250\n",
      "Ep:49, loss:0.00002, loss_test:0.01341, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:30.610, tt:1530.514\n",
      "Ep:50, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:30.638, tt:1562.553\n",
      "Ep:51, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:30.660, tt:1594.336\n",
      "Ep:52, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:30.673, tt:1625.660\n",
      "Ep:53, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:30.685, tt:1657.007\n",
      "Ep:54, loss:0.00002, loss_test:0.01326, lr:6.00e-02, fs:0.81938 (r=0.939,p=0.727),  time:30.683, tt:1687.587\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01320, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:30.696, tt:1718.959\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.674, tt:1748.396\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.687, tt:1779.828\n",
      "Ep:58, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.699, tt:1811.219\n",
      "Ep:59, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:30.716, tt:1842.978\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01314, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:30.703, tt:1872.906\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:30.689, tt:1902.694\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:30.682, tt:1932.990\n",
      "Ep:63, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:30.661, tt:1962.285\n",
      "Ep:64, loss:0.00001, loss_test:0.01303, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:30.662, tt:1992.999\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01298, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:30.670, tt:2024.198\n",
      "Ep:66, loss:0.00001, loss_test:0.01300, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.642, tt:2052.990\n",
      "Ep:67, loss:0.00001, loss_test:0.01298, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:30.641, tt:2083.618\n",
      "Ep:68, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:30.629, tt:2113.404\n",
      "Ep:69, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:30.621, tt:2143.482\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01295, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.608, tt:2173.197\n",
      "Ep:71, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:30.615, tt:2204.256\n",
      "Ep:72, loss:0.00001, loss_test:0.01287, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:30.599, tt:2233.746\n",
      "Ep:73, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.589, tt:2263.561\n",
      "Ep:74, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.560, tt:2291.964\n",
      "Ep:75, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.559, tt:2322.451\n",
      "Ep:76, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:30.553, tt:2352.585\n",
      "Ep:77, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:30.557, tt:2383.416\n",
      "Ep:78, loss:0.00001, loss_test:0.01298, lr:6.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:30.562, tt:2414.387\n",
      "Ep:79, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.553, tt:2444.233\n",
      "Ep:80, loss:0.00001, loss_test:0.01295, lr:6.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:30.567, tt:2475.964\n",
      "Ep:81, loss:0.00001, loss_test:0.01295, lr:5.94e-02, fs:0.85167 (r=0.899,p=0.809),  time:30.564, tt:2506.227\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01299, lr:5.94e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.555, tt:2536.039\n",
      "Ep:83, loss:0.00001, loss_test:0.01296, lr:5.94e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.563, tt:2567.305\n",
      "Ep:84, loss:0.00001, loss_test:0.01298, lr:5.94e-02, fs:0.85990 (r=0.899,p=0.824),  time:30.553, tt:2597.047\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01300, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.565, tt:2628.591\n",
      "Ep:86, loss:0.00001, loss_test:0.01302, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.569, tt:2659.528\n",
      "Ep:87, loss:0.00001, loss_test:0.01306, lr:5.94e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.571, tt:2690.259\n",
      "Ep:88, loss:0.00001, loss_test:0.01306, lr:5.94e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.567, tt:2720.494\n",
      "Ep:89, loss:0.00001, loss_test:0.01311, lr:5.94e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.597, tt:2753.706\n",
      "Ep:90, loss:0.00001, loss_test:0.01304, lr:5.94e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.599, tt:2784.482\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01306, lr:5.94e-02, fs:0.86139 (r=0.879,p=0.845),  time:30.607, tt:2815.828\n",
      "Ep:92, loss:0.00001, loss_test:0.01319, lr:5.94e-02, fs:0.86000 (r=0.869,p=0.851),  time:30.603, tt:2846.051\n",
      "Ep:93, loss:0.00001, loss_test:0.01317, lr:5.94e-02, fs:0.86000 (r=0.869,p=0.851),  time:30.613, tt:2877.669\n",
      "Ep:94, loss:0.00001, loss_test:0.01313, lr:5.94e-02, fs:0.86000 (r=0.869,p=0.851),  time:30.613, tt:2908.278\n",
      "Ep:95, loss:0.00001, loss_test:0.01318, lr:5.94e-02, fs:0.85427 (r=0.859,p=0.850),  time:30.611, tt:2938.664\n",
      "Ep:96, loss:0.00001, loss_test:0.01318, lr:5.94e-02, fs:0.85859 (r=0.859,p=0.859),  time:30.615, tt:2969.643\n",
      "Ep:97, loss:0.00001, loss_test:0.01329, lr:5.94e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.613, tt:3000.091\n",
      "Ep:98, loss:0.00001, loss_test:0.01318, lr:5.94e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.618, tt:3031.151\n",
      "Ep:99, loss:0.00001, loss_test:0.01327, lr:5.94e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.620, tt:3062.032\n",
      "Ep:100, loss:0.00001, loss_test:0.01334, lr:5.94e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.638, tt:3094.434\n",
      "Ep:101, loss:0.00001, loss_test:0.01324, lr:5.94e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.638, tt:3125.062\n",
      "Ep:102, loss:0.00001, loss_test:0.01338, lr:5.88e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.627, tt:3154.594\n",
      "Ep:103, loss:0.00001, loss_test:0.01338, lr:5.82e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.630, tt:3185.561\n",
      "Ep:104, loss:0.00001, loss_test:0.01341, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.636, tt:3216.775\n",
      "Ep:105, loss:0.00001, loss_test:0.01347, lr:5.71e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.647, tt:3248.534\n",
      "Ep:106, loss:0.00001, loss_test:0.01349, lr:5.65e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.631, tt:3277.544\n",
      "Ep:107, loss:0.00001, loss_test:0.01361, lr:5.59e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.638, tt:3308.855\n",
      "Ep:108, loss:0.00001, loss_test:0.01354, lr:5.54e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.633, tt:3339.030\n",
      "Ep:109, loss:0.00001, loss_test:0.01353, lr:5.48e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.627, tt:3369.010\n",
      "Ep:110, loss:0.00001, loss_test:0.01361, lr:5.43e-02, fs:0.78919 (r=0.737,p=0.849),  time:30.621, tt:3398.889\n",
      "Ep:111, loss:0.00001, loss_test:0.01367, lr:5.37e-02, fs:0.77596 (r=0.717,p=0.845),  time:30.616, tt:3428.961\n",
      "Ep:112, loss:0.00001, loss_test:0.01366, lr:5.32e-02, fs:0.77596 (r=0.717,p=0.845),  time:30.605, tt:3458.397\n",
      "Ep:113, loss:0.00001, loss_test:0.01374, lr:5.27e-02, fs:0.76923 (r=0.707,p=0.843),  time:30.612, tt:3489.776\n",
      "Ep:114, loss:0.00001, loss_test:0.01375, lr:5.21e-02, fs:0.76923 (r=0.707,p=0.843),  time:30.618, tt:3521.103\n",
      "Ep:115, loss:0.00001, loss_test:0.01370, lr:5.16e-02, fs:0.77596 (r=0.717,p=0.845),  time:30.617, tt:3551.586\n",
      "Ep:116, loss:0.00001, loss_test:0.01382, lr:5.11e-02, fs:0.75556 (r=0.687,p=0.840),  time:30.624, tt:3582.989\n",
      "Ep:117, loss:0.00001, loss_test:0.01389, lr:5.06e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.619, tt:3613.044\n",
      "Ep:118, loss:0.00001, loss_test:0.01388, lr:5.01e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.612, tt:3642.807\n",
      "Ep:119, loss:0.00001, loss_test:0.01382, lr:4.96e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.615, tt:3673.842\n",
      "Ep:120, loss:0.00001, loss_test:0.01397, lr:4.91e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.614, tt:3704.328\n",
      "Ep:121, loss:0.00001, loss_test:0.01399, lr:4.86e-02, fs:0.74576 (r=0.667,p=0.846),  time:30.611, tt:3734.495\n",
      "Ep:122, loss:0.00001, loss_test:0.01405, lr:4.81e-02, fs:0.73143 (r=0.646,p=0.842),  time:30.610, tt:3765.057\n",
      "Ep:123, loss:0.00001, loss_test:0.01401, lr:4.76e-02, fs:0.73864 (r=0.657,p=0.844),  time:30.616, tt:3796.337\n",
      "Ep:124, loss:0.00001, loss_test:0.01410, lr:4.71e-02, fs:0.73563 (r=0.646,p=0.853),  time:30.606, tt:3825.691\n",
      "Ep:125, loss:0.00001, loss_test:0.01416, lr:4.67e-02, fs:0.73563 (r=0.646,p=0.853),  time:30.613, tt:3857.222\n",
      "Ep:126, loss:0.00001, loss_test:0.01413, lr:4.62e-02, fs:0.73563 (r=0.646,p=0.853),  time:30.610, tt:3887.413\n",
      "Ep:127, loss:0.00001, loss_test:0.01411, lr:4.57e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.601, tt:3916.979\n",
      "Ep:128, loss:0.00001, loss_test:0.01424, lr:4.53e-02, fs:0.73256 (r=0.636,p=0.863),  time:30.595, tt:3946.805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.01433, lr:4.48e-02, fs:0.73684 (r=0.636,p=0.875),  time:30.611, tt:3979.397\n",
      "Ep:130, loss:0.00001, loss_test:0.01427, lr:4.44e-02, fs:0.74118 (r=0.636,p=0.887),  time:30.622, tt:4011.533\n",
      "Ep:131, loss:0.00001, loss_test:0.01427, lr:4.39e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.623, tt:4042.245\n",
      "Ep:132, loss:0.00001, loss_test:0.01432, lr:4.35e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.623, tt:4072.855\n",
      "Ep:133, loss:0.00001, loss_test:0.01441, lr:4.31e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.611, tt:4101.854\n",
      "Ep:134, loss:0.00001, loss_test:0.01439, lr:4.26e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.604, tt:4131.572\n",
      "Ep:135, loss:0.00001, loss_test:0.01443, lr:4.22e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.593, tt:4160.685\n",
      "Ep:136, loss:0.00001, loss_test:0.01448, lr:4.18e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.588, tt:4190.604\n",
      "Ep:137, loss:0.00001, loss_test:0.01448, lr:4.14e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.588, tt:4221.100\n",
      "Ep:138, loss:0.00001, loss_test:0.01453, lr:4.10e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.588, tt:4251.704\n",
      "Ep:139, loss:0.00001, loss_test:0.01451, lr:4.05e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.575, tt:4280.495\n",
      "Ep:140, loss:0.00001, loss_test:0.01460, lr:4.01e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.577, tt:4311.407\n",
      "Ep:141, loss:0.00001, loss_test:0.01464, lr:3.97e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.576, tt:4341.805\n",
      "Ep:142, loss:0.00001, loss_test:0.01466, lr:3.93e-02, fs:0.73373 (r=0.626,p=0.886),  time:30.576, tt:4372.432\n",
      "Ep:143, loss:0.00001, loss_test:0.01467, lr:3.89e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.582, tt:4403.839\n",
      "Ep:144, loss:0.00001, loss_test:0.01474, lr:3.86e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.578, tt:4433.818\n",
      "Ep:145, loss:0.00001, loss_test:0.01480, lr:3.82e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.574, tt:4463.745\n",
      "Ep:146, loss:0.00001, loss_test:0.01478, lr:3.78e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.575, tt:4494.552\n",
      "Ep:147, loss:0.00001, loss_test:0.01486, lr:3.74e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.575, tt:4525.082\n",
      "Ep:148, loss:0.00001, loss_test:0.01490, lr:3.70e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.585, tt:4557.101\n",
      "Ep:149, loss:0.00001, loss_test:0.01486, lr:3.67e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.590, tt:4588.426\n",
      "Ep:150, loss:0.00001, loss_test:0.01489, lr:3.63e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.593, tt:4619.510\n",
      "Ep:151, loss:0.00001, loss_test:0.01495, lr:3.59e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.587, tt:4649.249\n",
      "Ep:152, loss:0.00001, loss_test:0.01498, lr:3.56e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.587, tt:4679.760\n",
      "Ep:153, loss:0.00001, loss_test:0.01503, lr:3.52e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.590, tt:4710.818\n",
      "Ep:154, loss:0.00001, loss_test:0.01502, lr:3.49e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.582, tt:4740.257\n",
      "Ep:155, loss:0.00001, loss_test:0.01508, lr:3.45e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.577, tt:4770.004\n",
      "Ep:156, loss:0.00001, loss_test:0.01508, lr:3.42e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.573, tt:4799.882\n",
      "Ep:157, loss:0.00001, loss_test:0.01509, lr:3.38e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.567, tt:4829.609\n",
      "Ep:158, loss:0.00001, loss_test:0.01518, lr:3.35e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.590, tt:4863.781\n",
      "Ep:159, loss:0.00001, loss_test:0.01522, lr:3.32e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.587, tt:4893.960\n",
      "Ep:160, loss:0.00001, loss_test:0.01519, lr:3.28e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.582, tt:4923.626\n",
      "Ep:161, loss:0.00001, loss_test:0.01521, lr:3.25e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.579, tt:4953.877\n",
      "Ep:162, loss:0.00001, loss_test:0.01534, lr:3.22e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.575, tt:4983.652\n",
      "Ep:163, loss:0.00001, loss_test:0.01526, lr:3.19e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.575, tt:5014.243\n",
      "Ep:164, loss:0.00001, loss_test:0.01526, lr:3.15e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.576, tt:5044.973\n",
      "Ep:165, loss:0.00001, loss_test:0.01536, lr:3.12e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.577, tt:5075.832\n",
      "Ep:166, loss:0.00001, loss_test:0.01541, lr:3.09e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.571, tt:5105.357\n",
      "Ep:167, loss:0.00001, loss_test:0.01537, lr:3.06e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.559, tt:5133.954\n",
      "Ep:168, loss:0.00001, loss_test:0.01536, lr:3.03e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.563, tt:5165.096\n",
      "Ep:169, loss:0.00000, loss_test:0.01540, lr:3.00e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.565, tt:5196.067\n",
      "Ep:170, loss:0.00000, loss_test:0.01550, lr:2.97e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.572, tt:5227.731\n",
      "Ep:171, loss:0.00000, loss_test:0.01549, lr:2.94e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.571, tt:5258.217\n",
      "Ep:172, loss:0.00000, loss_test:0.01544, lr:2.91e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.569, tt:5288.389\n",
      "Ep:173, loss:0.00000, loss_test:0.01551, lr:2.88e-02, fs:0.71084 (r=0.596,p=0.881),  time:30.573, tt:5319.668\n",
      "Ep:174, loss:0.00000, loss_test:0.01559, lr:2.85e-02, fs:0.70303 (r=0.586,p=0.879),  time:30.564, tt:5348.683\n",
      "Ep:175, loss:0.00000, loss_test:0.01556, lr:2.82e-02, fs:0.70303 (r=0.586,p=0.879),  time:30.561, tt:5378.739\n",
      "Ep:176, loss:0.00000, loss_test:0.01560, lr:2.80e-02, fs:0.70303 (r=0.586,p=0.879),  time:30.555, tt:5408.170\n",
      "Ep:177, loss:0.00000, loss_test:0.01562, lr:2.77e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.548, tt:5437.529\n",
      "Ep:178, loss:0.00000, loss_test:0.01563, lr:2.74e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.541, tt:5466.899\n",
      "Ep:179, loss:0.00000, loss_test:0.01565, lr:2.71e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.536, tt:5496.497\n",
      "Ep:180, loss:0.00000, loss_test:0.01571, lr:2.69e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.539, tt:5527.548\n",
      "Ep:181, loss:0.00000, loss_test:0.01574, lr:2.66e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.533, tt:5557.036\n",
      "Ep:182, loss:0.00000, loss_test:0.01572, lr:2.63e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.536, tt:5588.175\n",
      "Ep:183, loss:0.00000, loss_test:0.01577, lr:2.61e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.531, tt:5617.750\n",
      "Ep:184, loss:0.00000, loss_test:0.01578, lr:2.58e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.530, tt:5648.105\n",
      "Ep:185, loss:0.00000, loss_test:0.01584, lr:2.55e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.542, tt:5680.863\n",
      "Ep:186, loss:0.00000, loss_test:0.01578, lr:2.53e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.536, tt:5710.277\n",
      "Ep:187, loss:0.00000, loss_test:0.01585, lr:2.50e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.532, tt:5740.080\n",
      "Ep:188, loss:0.00000, loss_test:0.01586, lr:2.48e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.531, tt:5770.419\n",
      "Ep:189, loss:0.00000, loss_test:0.01590, lr:2.45e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.530, tt:5800.643\n",
      "Ep:190, loss:0.00000, loss_test:0.01592, lr:2.43e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.520, tt:5829.309\n",
      "Ep:191, loss:0.00000, loss_test:0.01595, lr:2.40e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.519, tt:5859.736\n",
      "Ep:192, loss:0.00000, loss_test:0.01594, lr:2.38e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.521, tt:5890.553\n",
      "Ep:193, loss:0.00000, loss_test:0.01597, lr:2.36e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.514, tt:5919.803\n",
      "Ep:194, loss:0.00000, loss_test:0.01597, lr:2.33e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.508, tt:5949.029\n",
      "Ep:195, loss:0.00000, loss_test:0.01602, lr:2.31e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.503, tt:5978.535\n",
      "Ep:196, loss:0.00000, loss_test:0.01601, lr:2.29e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.497, tt:6007.921\n",
      "Ep:197, loss:0.00000, loss_test:0.01598, lr:2.26e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.500, tt:6038.906\n",
      "Ep:198, loss:0.00000, loss_test:0.01607, lr:2.24e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.497, tt:6068.932\n",
      "Ep:199, loss:0.00000, loss_test:0.01613, lr:2.22e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.500, tt:6099.899\n",
      "Ep:200, loss:0.00000, loss_test:0.01609, lr:2.20e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.506, tt:6131.798\n",
      "Ep:201, loss:0.00000, loss_test:0.01611, lr:2.17e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.502, tt:6161.460\n",
      "Ep:202, loss:0.00000, loss_test:0.01617, lr:2.15e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.501, tt:6191.787\n",
      "Ep:203, loss:0.00000, loss_test:0.01618, lr:2.13e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.501, tt:6222.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.01620, lr:2.11e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.498, tt:6252.145\n",
      "Ep:205, loss:0.00000, loss_test:0.01620, lr:2.09e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.498, tt:6282.537\n",
      "Ep:206, loss:0.00000, loss_test:0.01625, lr:2.07e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.492, tt:6311.899\n",
      "Ep:207, loss:0.00000, loss_test:0.01623, lr:2.05e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.497, tt:6343.378\n",
      "Ep:208, loss:0.00000, loss_test:0.01627, lr:2.03e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.497, tt:6373.905\n",
      "Ep:209, loss:0.00000, loss_test:0.01632, lr:2.01e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.485, tt:6401.909\n",
      "Ep:210, loss:0.00000, loss_test:0.01630, lr:1.99e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.486, tt:6432.553\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14257, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.901, tt:30.901\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14128, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.008, tt:56.015\n",
      "Ep:2, loss:0.00027, loss_test:0.13911, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:27.565, tt:82.694\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13551, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:27.574, tt:110.296\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13138, lr:1.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:27.443, tt:137.214\n",
      "Ep:5, loss:0.00024, loss_test:0.12835, lr:1.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:28.030, tt:168.182\n",
      "Ep:6, loss:0.00023, loss_test:0.12752, lr:1.00e-02, fs:0.63393 (r=0.717,p=0.568),  time:28.630, tt:200.412\n",
      "Ep:7, loss:0.00023, loss_test:0.12575, lr:1.00e-02, fs:0.60748 (r=0.657,p=0.565),  time:28.814, tt:230.516\n",
      "Ep:8, loss:0.00022, loss_test:0.12316, lr:1.00e-02, fs:0.64889 (r=0.737,p=0.579),  time:29.382, tt:264.439\n",
      "Ep:9, loss:0.00022, loss_test:0.12314, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:29.801, tt:298.006\n",
      "Ep:10, loss:0.00022, loss_test:0.12304, lr:1.00e-02, fs:0.65198 (r=0.747,p=0.578),  time:30.180, tt:331.977\n",
      "Ep:11, loss:0.00021, loss_test:0.12175, lr:1.00e-02, fs:0.62326 (r=0.677,p=0.578),  time:30.400, tt:364.800\n",
      "Ep:12, loss:0.00020, loss_test:0.11984, lr:1.00e-02, fs:0.62201 (r=0.657,p=0.591),  time:30.483, tt:396.276\n",
      "Ep:13, loss:0.00020, loss_test:0.11674, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:30.625, tt:428.749\n",
      "Ep:14, loss:0.00019, loss_test:0.11480, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:30.800, tt:461.999\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11260, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:30.983, tt:495.721\n",
      "Ep:16, loss:0.00018, loss_test:0.11236, lr:1.00e-02, fs:0.63590 (r=0.626,p=0.646),  time:31.176, tt:529.986\n",
      "Ep:17, loss:0.00018, loss_test:0.11093, lr:1.00e-02, fs:0.68269 (r=0.717,p=0.651),  time:31.388, tt:564.990\n",
      "Ep:18, loss:0.00017, loss_test:0.10914, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:31.500, tt:598.492\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10785, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:31.632, tt:632.630\n",
      "Ep:20, loss:0.00017, loss_test:0.10580, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:31.734, tt:666.409\n",
      "Ep:21, loss:0.00016, loss_test:0.10444, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:31.829, tt:700.236\n",
      "Ep:22, loss:0.00016, loss_test:0.10372, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:31.838, tt:732.283\n",
      "Ep:23, loss:0.00015, loss_test:0.10279, lr:1.00e-02, fs:0.67368 (r=0.646,p=0.703),  time:31.873, tt:764.943\n",
      "Ep:24, loss:0.00015, loss_test:0.10081, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:31.882, tt:797.038\n",
      "Ep:25, loss:0.00015, loss_test:0.10016, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:31.942, tt:830.485\n",
      "Ep:26, loss:0.00014, loss_test:0.09989, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:32.013, tt:864.361\n",
      "Ep:27, loss:0.00014, loss_test:0.09920, lr:1.00e-02, fs:0.68449 (r=0.646,p=0.727),  time:32.067, tt:897.869\n",
      "Ep:28, loss:0.00014, loss_test:0.09763, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:32.117, tt:931.397\n",
      "Ep:29, loss:0.00013, loss_test:0.09728, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:32.190, tt:965.713\n",
      "Ep:30, loss:0.00013, loss_test:0.09613, lr:9.90e-03, fs:0.69149 (r=0.657,p=0.730),  time:32.185, tt:997.735\n",
      "Ep:31, loss:0.00013, loss_test:0.09462, lr:9.80e-03, fs:0.69519 (r=0.657,p=0.739),  time:32.231, tt:1031.406\n",
      "Ep:32, loss:0.00012, loss_test:0.09510, lr:9.70e-03, fs:0.69892 (r=0.657,p=0.747),  time:32.251, tt:1064.289\n",
      "Ep:33, loss:0.00012, loss_test:0.09313, lr:9.61e-03, fs:0.69945 (r=0.646,p=0.762),  time:32.303, tt:1098.297\n",
      "Ep:34, loss:0.00012, loss_test:0.09268, lr:9.51e-03, fs:0.70968 (r=0.667,p=0.759),  time:32.315, tt:1131.015\n",
      "Ep:35, loss:0.00012, loss_test:0.09331, lr:9.41e-03, fs:0.67039 (r=0.606,p=0.750),  time:32.360, tt:1164.954\n",
      "Ep:36, loss:0.00011, loss_test:0.09072, lr:9.32e-03, fs:0.70968 (r=0.667,p=0.759),  time:32.420, tt:1199.522\n",
      "Ep:37, loss:0.00011, loss_test:0.09226, lr:9.23e-03, fs:0.68132 (r=0.626,p=0.747),  time:32.431, tt:1232.369\n",
      "Ep:38, loss:0.00011, loss_test:0.09176, lr:9.14e-03, fs:0.68132 (r=0.626,p=0.747),  time:32.439, tt:1265.133\n",
      "Ep:39, loss:0.00011, loss_test:0.09045, lr:9.04e-03, fs:0.66667 (r=0.586,p=0.773),  time:32.467, tt:1298.693\n",
      "Ep:40, loss:0.00010, loss_test:0.09005, lr:8.95e-03, fs:0.68508 (r=0.626,p=0.756),  time:32.487, tt:1331.968\n",
      "Ep:41, loss:0.00010, loss_test:0.08970, lr:8.86e-03, fs:0.70718 (r=0.646,p=0.780),  time:32.497, tt:1364.863\n",
      "Ep:42, loss:0.00010, loss_test:0.08906, lr:8.78e-03, fs:0.68605 (r=0.596,p=0.808),  time:32.505, tt:1397.711\n",
      "Ep:43, loss:0.00010, loss_test:0.08809, lr:8.69e-03, fs:0.70330 (r=0.646,p=0.771),  time:32.509, tt:1430.398\n",
      "Ep:44, loss:0.00009, loss_test:0.08963, lr:8.60e-03, fs:0.69822 (r=0.596,p=0.843),  time:32.516, tt:1463.205\n",
      "Ep:45, loss:0.00009, loss_test:0.08772, lr:8.51e-03, fs:0.71676 (r=0.626,p=0.838),  time:32.516, tt:1495.740\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.08744, lr:8.51e-03, fs:0.72000 (r=0.636,p=0.829),  time:32.518, tt:1528.365\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.09099, lr:8.51e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.509, tt:1560.438\n",
      "Ep:48, loss:0.00009, loss_test:0.08538, lr:8.51e-03, fs:0.72527 (r=0.667,p=0.795),  time:32.550, tt:1594.930\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.08938, lr:8.51e-03, fs:0.69939 (r=0.576,p=0.891),  time:32.572, tt:1628.624\n",
      "Ep:50, loss:0.00008, loss_test:0.08628, lr:8.51e-03, fs:0.73256 (r=0.636,p=0.863),  time:32.561, tt:1660.603\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.08584, lr:8.51e-03, fs:0.73684 (r=0.636,p=0.875),  time:32.538, tt:1692.000\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.08684, lr:8.51e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.564, tt:1725.901\n",
      "Ep:53, loss:0.00008, loss_test:0.08462, lr:8.51e-03, fs:0.74576 (r=0.667,p=0.846),  time:32.586, tt:1759.649\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.08703, lr:8.51e-03, fs:0.73054 (r=0.616,p=0.897),  time:32.599, tt:1792.966\n",
      "Ep:55, loss:0.00008, loss_test:0.08349, lr:8.51e-03, fs:0.75281 (r=0.677,p=0.848),  time:32.567, tt:1823.748\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.08608, lr:8.51e-03, fs:0.72941 (r=0.626,p=0.873),  time:32.580, tt:1857.036\n",
      "Ep:57, loss:0.00007, loss_test:0.08378, lr:8.51e-03, fs:0.74419 (r=0.646,p=0.877),  time:32.573, tt:1889.259\n",
      "Ep:58, loss:0.00007, loss_test:0.08398, lr:8.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:32.567, tt:1921.462\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00007, loss_test:0.08396, lr:8.51e-03, fs:0.75145 (r=0.657,p=0.878),  time:32.567, tt:1954.031\n",
      "Ep:60, loss:0.00007, loss_test:0.08318, lr:8.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:32.569, tt:1986.716\n",
      "Ep:61, loss:0.00007, loss_test:0.08421, lr:8.51e-03, fs:0.75581 (r=0.657,p=0.890),  time:32.568, tt:2019.243\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.08309, lr:8.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:32.557, tt:2051.098\n",
      "Ep:63, loss:0.00006, loss_test:0.08152, lr:8.51e-03, fs:0.75581 (r=0.657,p=0.890),  time:32.590, tt:2085.754\n",
      "Ep:64, loss:0.00006, loss_test:0.08381, lr:8.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:32.604, tt:2119.230\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.08121, lr:8.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:32.591, tt:2150.974\n",
      "Ep:66, loss:0.00006, loss_test:0.08288, lr:8.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:32.566, tt:2181.920\n",
      "Ep:67, loss:0.00006, loss_test:0.08159, lr:8.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:32.548, tt:2213.284\n",
      "Ep:68, loss:0.00006, loss_test:0.08188, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:32.549, tt:2245.879\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00006, loss_test:0.08133, lr:8.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.533, tt:2277.302\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.08194, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:32.515, tt:2308.539\n",
      "Ep:71, loss:0.00005, loss_test:0.08189, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.495, tt:2339.675\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.07986, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.473, tt:2370.551\n",
      "Ep:73, loss:0.00005, loss_test:0.08264, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:32.453, tt:2401.545\n",
      "Ep:74, loss:0.00005, loss_test:0.08081, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.470, tt:2435.240\n",
      "Ep:75, loss:0.00005, loss_test:0.08009, lr:8.51e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.464, tt:2467.300\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00005, loss_test:0.08234, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:32.452, tt:2498.783\n",
      "Ep:77, loss:0.00005, loss_test:0.08033, lr:8.51e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.470, tt:2532.631\n",
      "Ep:78, loss:0.00005, loss_test:0.08270, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:32.452, tt:2563.727\n",
      "Ep:79, loss:0.00005, loss_test:0.08050, lr:8.51e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.461, tt:2596.874\n",
      "Ep:80, loss:0.00005, loss_test:0.08094, lr:8.51e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.466, tt:2629.748\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.08217, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:32.436, tt:2659.764\n",
      "Ep:82, loss:0.00004, loss_test:0.08120, lr:8.51e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.436, tt:2692.194\n",
      "Ep:83, loss:0.00004, loss_test:0.08175, lr:8.51e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.435, tt:2724.509\n",
      "Ep:84, loss:0.00004, loss_test:0.08097, lr:8.51e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.443, tt:2757.680\n",
      "Ep:85, loss:0.00004, loss_test:0.08118, lr:8.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:32.435, tt:2789.368\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00004, loss_test:0.08012, lr:8.51e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.430, tt:2821.451\n",
      "Ep:87, loss:0.00004, loss_test:0.08134, lr:8.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:32.421, tt:2853.017\n",
      "Ep:88, loss:0.00004, loss_test:0.08295, lr:8.51e-03, fs:0.77844 (r=0.657,p=0.956),  time:32.421, tt:2885.441\n",
      "Ep:89, loss:0.00004, loss_test:0.08102, lr:8.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:32.425, tt:2918.252\n",
      "Ep:90, loss:0.00004, loss_test:0.08387, lr:8.51e-03, fs:0.77576 (r=0.646,p=0.970),  time:32.421, tt:2950.275\n",
      "Ep:91, loss:0.00004, loss_test:0.08005, lr:8.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:32.422, tt:2982.863\n",
      "Ep:92, loss:0.00004, loss_test:0.08348, lr:8.51e-03, fs:0.77381 (r=0.657,p=0.942),  time:32.431, tt:3016.057\n",
      "Ep:93, loss:0.00004, loss_test:0.08236, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.427, tt:3048.165\n",
      "Ep:94, loss:0.00004, loss_test:0.08163, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.424, tt:3080.320\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00004, loss_test:0.08527, lr:8.51e-03, fs:0.76364 (r=0.636,p=0.955),  time:32.427, tt:3112.962\n",
      "Ep:96, loss:0.00004, loss_test:0.08029, lr:8.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.427, tt:3145.413\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00003, loss_test:0.08546, lr:8.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.437, tt:3178.795\n",
      "Ep:98, loss:0.00003, loss_test:0.08041, lr:8.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.445, tt:3212.074\n",
      "Ep:99, loss:0.00003, loss_test:0.08495, lr:8.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.432, tt:3243.181\n",
      "Ep:100, loss:0.00003, loss_test:0.08091, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.434, tt:3275.808\n",
      "Ep:101, loss:0.00003, loss_test:0.08370, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.409, tt:3305.759\n",
      "Ep:102, loss:0.00003, loss_test:0.08225, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.393, tt:3336.503\n",
      "Ep:103, loss:0.00003, loss_test:0.08186, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.389, tt:3368.438\n",
      "Ep:104, loss:0.00003, loss_test:0.08466, lr:8.51e-03, fs:0.77108 (r=0.646,p=0.955),  time:32.384, tt:3400.321\n",
      "Ep:105, loss:0.00003, loss_test:0.08189, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.382, tt:3432.492\n",
      "Ep:106, loss:0.00003, loss_test:0.08385, lr:8.51e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.384, tt:3465.039\n",
      "Ep:107, loss:0.00003, loss_test:0.08340, lr:8.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.395, tt:3498.659\n",
      "Ep:108, loss:0.00003, loss_test:0.08259, lr:8.43e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.399, tt:3531.498\n",
      "Ep:109, loss:0.00003, loss_test:0.08473, lr:8.35e-03, fs:0.78571 (r=0.667,p=0.957),  time:32.394, tt:3563.347\n",
      "Ep:110, loss:0.00003, loss_test:0.08274, lr:8.26e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.402, tt:3596.662\n",
      "Ep:111, loss:0.00003, loss_test:0.08567, lr:8.18e-03, fs:0.76364 (r=0.636,p=0.955),  time:32.396, tt:3628.372\n",
      "Ep:112, loss:0.00003, loss_test:0.08457, lr:8.10e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.385, tt:3659.475\n",
      "Ep:113, loss:0.00003, loss_test:0.08588, lr:8.02e-03, fs:0.77301 (r=0.636,p=0.984),  time:32.386, tt:3691.981\n",
      "Ep:114, loss:0.00003, loss_test:0.08457, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.380, tt:3723.716\n",
      "Ep:115, loss:0.00003, loss_test:0.08759, lr:7.86e-03, fs:0.76829 (r=0.636,p=0.969),  time:32.368, tt:3754.693\n",
      "Ep:116, loss:0.00003, loss_test:0.08692, lr:7.78e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.360, tt:3786.147\n",
      "Ep:117, loss:0.00002, loss_test:0.08402, lr:7.70e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.327, tt:3814.528\n",
      "Ep:118, loss:0.00002, loss_test:0.08622, lr:7.62e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.306, tt:3844.370\n",
      "Ep:119, loss:0.00002, loss_test:0.08501, lr:7.55e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.304, tt:3876.513\n",
      "Ep:120, loss:0.00002, loss_test:0.08699, lr:7.47e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.308, tt:3909.284\n",
      "Ep:121, loss:0.00002, loss_test:0.08643, lr:7.40e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.315, tt:3942.388\n",
      "Ep:122, loss:0.00002, loss_test:0.08585, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.302, tt:3973.166\n",
      "Ep:123, loss:0.00002, loss_test:0.08634, lr:7.25e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.299, tt:4005.126\n",
      "Ep:124, loss:0.00002, loss_test:0.08728, lr:7.18e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.303, tt:4037.837\n",
      "Ep:125, loss:0.00002, loss_test:0.08709, lr:7.11e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.305, tt:4070.416\n",
      "Ep:126, loss:0.00002, loss_test:0.08623, lr:7.03e-03, fs:0.75610 (r=0.626,p=0.954),  time:32.305, tt:4102.792\n",
      "Ep:127, loss:0.00002, loss_test:0.08710, lr:6.96e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.310, tt:4135.670\n",
      "Ep:128, loss:0.00002, loss_test:0.08738, lr:6.89e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.307, tt:4167.543\n",
      "Ep:129, loss:0.00002, loss_test:0.08863, lr:6.83e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.303, tt:4199.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.08742, lr:6.76e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.297, tt:4230.961\n",
      "Ep:131, loss:0.00002, loss_test:0.08721, lr:6.69e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.326, tt:4267.020\n",
      "Ep:132, loss:0.00002, loss_test:0.08716, lr:6.62e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.328, tt:4299.562\n",
      "Ep:133, loss:0.00002, loss_test:0.08914, lr:6.56e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.331, tt:4332.358\n",
      "Ep:134, loss:0.00002, loss_test:0.08630, lr:6.49e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.333, tt:4364.985\n",
      "Ep:135, loss:0.00002, loss_test:0.09057, lr:6.43e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.336, tt:4397.657\n",
      "Ep:136, loss:0.00002, loss_test:0.08667, lr:6.36e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.335, tt:4429.920\n",
      "Ep:137, loss:0.00002, loss_test:0.08999, lr:6.30e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.337, tt:4462.556\n",
      "Ep:138, loss:0.00002, loss_test:0.08765, lr:6.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.335, tt:4494.554\n",
      "Ep:139, loss:0.00002, loss_test:0.09020, lr:6.17e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.334, tt:4526.753\n",
      "Ep:140, loss:0.00002, loss_test:0.08913, lr:6.11e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.335, tt:4559.217\n",
      "Ep:141, loss:0.00002, loss_test:0.08724, lr:6.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.325, tt:4590.081\n",
      "Ep:142, loss:0.00002, loss_test:0.09134, lr:5.99e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.328, tt:4622.956\n",
      "Ep:143, loss:0.00002, loss_test:0.08611, lr:5.93e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.329, tt:4655.384\n",
      "Ep:144, loss:0.00002, loss_test:0.09040, lr:5.87e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.325, tt:4687.152\n",
      "Ep:145, loss:0.00002, loss_test:0.09038, lr:5.81e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.338, tt:4721.323\n",
      "Ep:146, loss:0.00002, loss_test:0.08791, lr:5.75e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.328, tt:4752.182\n",
      "Ep:147, loss:0.00002, loss_test:0.09243, lr:5.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.318, tt:4783.114\n",
      "Ep:148, loss:0.00002, loss_test:0.08780, lr:5.64e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.319, tt:4815.485\n",
      "Ep:149, loss:0.00002, loss_test:0.08991, lr:5.58e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.315, tt:4847.200\n",
      "Ep:150, loss:0.00002, loss_test:0.09111, lr:5.53e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.304, tt:4877.912\n",
      "Ep:151, loss:0.00002, loss_test:0.08741, lr:5.47e-03, fs:0.75610 (r=0.626,p=0.954),  time:32.303, tt:4910.054\n",
      "Ep:152, loss:0.00002, loss_test:0.09143, lr:5.42e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.324, tt:4945.561\n",
      "Ep:153, loss:0.00002, loss_test:0.09081, lr:5.36e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.325, tt:4978.107\n",
      "Ep:154, loss:0.00001, loss_test:0.08720, lr:5.31e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.322, tt:5009.939\n",
      "Ep:155, loss:0.00001, loss_test:0.09215, lr:5.26e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.319, tt:5041.794\n",
      "Ep:156, loss:0.00001, loss_test:0.08916, lr:5.20e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.320, tt:5074.198\n",
      "Ep:157, loss:0.00001, loss_test:0.09020, lr:5.15e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.328, tt:5107.801\n",
      "Ep:158, loss:0.00001, loss_test:0.09205, lr:5.10e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.331, tt:5140.556\n",
      "Ep:159, loss:0.00001, loss_test:0.08741, lr:5.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:32.324, tt:5171.859\n",
      "Ep:160, loss:0.00001, loss_test:0.09235, lr:5.00e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.323, tt:5203.961\n",
      "Ep:161, loss:0.00001, loss_test:0.08984, lr:4.95e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.313, tt:5234.752\n",
      "Ep:162, loss:0.00001, loss_test:0.08815, lr:4.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.315, tt:5267.355\n",
      "Ep:163, loss:0.00001, loss_test:0.09187, lr:4.85e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.304, tt:5297.858\n",
      "Ep:164, loss:0.00001, loss_test:0.08917, lr:4.80e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.288, tt:5327.569\n",
      "Ep:165, loss:0.00001, loss_test:0.08899, lr:4.75e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.290, tt:5360.172\n",
      "Ep:166, loss:0.00001, loss_test:0.09152, lr:4.71e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.288, tt:5392.129\n",
      "Ep:167, loss:0.00001, loss_test:0.08926, lr:4.66e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.288, tt:5424.440\n",
      "Ep:168, loss:0.00001, loss_test:0.08889, lr:4.61e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.291, tt:5457.182\n",
      "Ep:169, loss:0.00001, loss_test:0.09180, lr:4.57e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.289, tt:5489.150\n",
      "Ep:170, loss:0.00001, loss_test:0.08891, lr:4.52e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.288, tt:5521.225\n",
      "Ep:171, loss:0.00001, loss_test:0.09086, lr:4.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.289, tt:5553.707\n",
      "Ep:172, loss:0.00001, loss_test:0.09242, lr:4.43e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.289, tt:5585.930\n",
      "Ep:173, loss:0.00001, loss_test:0.08800, lr:4.39e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.292, tt:5618.738\n",
      "Ep:174, loss:0.00001, loss_test:0.09115, lr:4.34e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.287, tt:5650.221\n",
      "Ep:175, loss:0.00001, loss_test:0.09221, lr:4.30e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.284, tt:5681.928\n",
      "Ep:176, loss:0.00001, loss_test:0.08826, lr:4.26e-03, fs:0.75309 (r=0.616,p=0.968),  time:32.282, tt:5713.863\n",
      "Ep:177, loss:0.00001, loss_test:0.09124, lr:4.21e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.279, tt:5745.662\n",
      "Ep:178, loss:0.00001, loss_test:0.09146, lr:4.17e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.275, tt:5777.165\n",
      "Ep:179, loss:0.00001, loss_test:0.08892, lr:4.13e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.263, tt:5807.412\n",
      "Ep:180, loss:0.00001, loss_test:0.09055, lr:4.09e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.263, tt:5839.617\n",
      "Ep:181, loss:0.00001, loss_test:0.09150, lr:4.05e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.264, tt:5871.985\n",
      "Ep:182, loss:0.00001, loss_test:0.08815, lr:4.01e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.258, tt:5903.264\n",
      "Ep:183, loss:0.00001, loss_test:0.09061, lr:3.97e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.250, tt:5934.073\n",
      "Ep:184, loss:0.00001, loss_test:0.09114, lr:3.93e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.246, tt:5965.539\n",
      "Ep:185, loss:0.00001, loss_test:0.08863, lr:3.89e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.245, tt:5997.589\n",
      "Ep:186, loss:0.00001, loss_test:0.09089, lr:3.85e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.237, tt:6028.303\n",
      "Ep:187, loss:0.00001, loss_test:0.09022, lr:3.81e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.232, tt:6059.686\n",
      "Ep:188, loss:0.00001, loss_test:0.08888, lr:3.77e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.227, tt:6090.990\n",
      "Ep:189, loss:0.00001, loss_test:0.09012, lr:3.73e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.240, tt:6125.607\n",
      "Ep:190, loss:0.00001, loss_test:0.09033, lr:3.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.241, tt:6158.049\n",
      "Ep:191, loss:0.00001, loss_test:0.08866, lr:3.66e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.240, tt:6190.017\n",
      "Ep:192, loss:0.00001, loss_test:0.09052, lr:3.62e-03, fs:0.75000 (r=0.606,p=0.984),  time:32.236, tt:6221.608\n",
      "Ep:193, loss:0.00001, loss_test:0.09090, lr:3.59e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.233, tt:6253.276\n",
      "Ep:194, loss:0.00001, loss_test:0.08855, lr:3.55e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.232, tt:6285.292\n",
      "Ep:195, loss:0.00001, loss_test:0.09055, lr:3.52e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.227, tt:6316.422\n",
      "Ep:196, loss:0.00001, loss_test:0.09091, lr:3.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.230, tt:6349.250\n",
      "Ep:197, loss:0.00001, loss_test:0.08945, lr:3.45e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.224, tt:6380.293\n",
      "Ep:198, loss:0.00001, loss_test:0.08958, lr:3.41e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.208, tt:6409.394\n",
      "Ep:199, loss:0.00001, loss_test:0.09092, lr:3.38e-03, fs:0.75000 (r=0.606,p=0.984),  time:32.202, tt:6440.300\n",
      "Ep:200, loss:0.00001, loss_test:0.08959, lr:3.34e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.200, tt:6472.132\n",
      "Ep:201, loss:0.00001, loss_test:0.08950, lr:3.31e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.194, tt:6503.136\n",
      "Ep:202, loss:0.00001, loss_test:0.09079, lr:3.28e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.191, tt:6534.839\n",
      "Ep:203, loss:0.00001, loss_test:0.09000, lr:3.24e-03, fs:0.75000 (r=0.606,p=0.984),  time:32.188, tt:6566.272\n",
      "Ep:204, loss:0.00001, loss_test:0.08898, lr:3.21e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.186, tt:6598.175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00001, loss_test:0.09071, lr:3.18e-03, fs:0.75000 (r=0.606,p=0.984),  time:32.179, tt:6628.778\n",
      "Ep:206, loss:0.00001, loss_test:0.09095, lr:3.15e-03, fs:0.75000 (r=0.606,p=0.984),  time:32.175, tt:6660.173\n",
      "Ep:207, loss:0.00001, loss_test:0.08927, lr:3.12e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.161, tt:6689.536\n",
      "Ep:208, loss:0.00001, loss_test:0.09023, lr:3.09e-03, fs:0.75000 (r=0.606,p=0.984),  time:32.151, tt:6719.455\n",
      "Ep:209, loss:0.00001, loss_test:0.09071, lr:3.05e-03, fs:0.74214 (r=0.596,p=0.983),  time:32.132, tt:6747.625\n",
      "Ep:210, loss:0.00001, loss_test:0.08990, lr:3.02e-03, fs:0.75776 (r=0.616,p=0.984),  time:32.121, tt:6777.599\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02094, lr:6.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:27.435, tt:27.435\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02115, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:23.478, tt:46.956\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02246, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:21.943, tt:65.830\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02258, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:21.714, tt:86.857\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02195, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:23.034, tt:115.170\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02123, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:23.939, tt:143.633\n",
      "Ep:6, loss:0.00004, loss_test:0.02069, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:24.747, tt:173.227\n",
      "Ep:7, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:25.116, tt:200.926\n",
      "Ep:8, loss:0.00004, loss_test:0.01999, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:25.484, tt:229.356\n",
      "Ep:9, loss:0.00004, loss_test:0.01934, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:26.071, tt:260.713\n",
      "Ep:10, loss:0.00003, loss_test:0.01877, lr:6.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:26.548, tt:292.027\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01840, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:26.836, tt:322.037\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01803, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:27.188, tt:353.443\n",
      "Ep:13, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:27.510, tt:385.142\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:27.651, tt:414.769\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01712, lr:6.00e-02, fs:0.71318 (r=0.929,p=0.579),  time:27.866, tt:445.850\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:28.043, tt:476.731\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:28.137, tt:506.460\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01653, lr:6.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:28.301, tt:537.727\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:28.349, tt:566.976\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:28.397, tt:596.332\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01597, lr:6.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:28.408, tt:624.972\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:28.545, tt:656.538\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:28.564, tt:685.535\n",
      "Ep:24, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:28.592, tt:714.790\n",
      "Ep:25, loss:0.00003, loss_test:0.01517, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:28.649, tt:744.875\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01502, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:28.712, tt:775.219\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01491, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:28.774, tt:805.669\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.76793 (r=0.919,p=0.659),  time:28.838, tt:836.304\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:28.891, tt:866.721\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:29.063, tt:900.944\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:29.090, tt:930.887\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:29.121, tt:960.985\n",
      "Ep:33, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:29.159, tt:991.400\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:29.208, tt:1022.265\n",
      "Ep:35, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:29.242, tt:1052.722\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:29.282, tt:1083.424\n",
      "Ep:37, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:29.314, tt:1113.950\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:29.343, tt:1144.395\n",
      "Ep:39, loss:0.00002, loss_test:0.01391, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:29.371, tt:1174.835\n",
      "Ep:40, loss:0.00002, loss_test:0.01385, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:29.381, tt:1204.639\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:29.371, tt:1233.571\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:29.434, tt:1265.678\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:29.475, tt:1296.880\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:29.490, tt:1327.065\n",
      "Ep:45, loss:0.00002, loss_test:0.01359, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:29.531, tt:1358.448\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:29.537, tt:1388.260\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:29.539, tt:1417.873\n",
      "Ep:48, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.592, tt:1450.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:29.626, tt:1481.319\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:29.649, tt:1512.112\n",
      "Ep:51, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.681, tt:1543.426\n",
      "Ep:52, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.732, tt:1575.802\n",
      "Ep:53, loss:0.00002, loss_test:0.01321, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.738, tt:1605.833\n",
      "Ep:54, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:29.723, tt:1634.756\n",
      "Ep:55, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:29.726, tt:1664.655\n",
      "Ep:56, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.737, tt:1695.022\n",
      "Ep:57, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:29.750, tt:1725.517\n",
      "Ep:58, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:29.743, tt:1754.849\n",
      "Ep:59, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:29.749, tt:1784.955\n",
      "Ep:60, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:29.756, tt:1815.098\n",
      "Ep:61, loss:0.00001, loss_test:0.01291, lr:5.94e-02, fs:0.82353 (r=0.848,p=0.800),  time:29.752, tt:1844.602\n",
      "Ep:62, loss:0.00001, loss_test:0.01290, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:29.754, tt:1874.506\n",
      "Ep:63, loss:0.00001, loss_test:0.01291, lr:5.82e-02, fs:0.82759 (r=0.848,p=0.808),  time:29.771, tt:1905.373\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01289, lr:5.82e-02, fs:0.82759 (r=0.848,p=0.808),  time:29.778, tt:1935.582\n",
      "Ep:65, loss:0.00001, loss_test:0.01284, lr:5.82e-02, fs:0.83333 (r=0.859,p=0.810),  time:29.779, tt:1965.447\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01281, lr:5.82e-02, fs:0.82759 (r=0.848,p=0.808),  time:29.804, tt:1996.855\n",
      "Ep:67, loss:0.00001, loss_test:0.01278, lr:5.82e-02, fs:0.83168 (r=0.848,p=0.816),  time:29.822, tt:2027.882\n",
      "Ep:68, loss:0.00001, loss_test:0.01273, lr:5.82e-02, fs:0.83168 (r=0.848,p=0.816),  time:29.807, tt:2056.704\n",
      "Ep:69, loss:0.00001, loss_test:0.01283, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:29.814, tt:2086.995\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01283, lr:5.82e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.804, tt:2116.094\n",
      "Ep:71, loss:0.00001, loss_test:0.01275, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:29.803, tt:2145.812\n",
      "Ep:72, loss:0.00001, loss_test:0.01273, lr:5.82e-02, fs:0.82828 (r=0.828,p=0.828),  time:29.806, tt:2175.827\n",
      "Ep:73, loss:0.00001, loss_test:0.01267, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:29.842, tt:2208.312\n",
      "Ep:74, loss:0.00001, loss_test:0.01270, lr:5.82e-02, fs:0.83249 (r=0.828,p=0.837),  time:29.851, tt:2238.808\n",
      "Ep:75, loss:0.00001, loss_test:0.01273, lr:5.82e-02, fs:0.83673 (r=0.828,p=0.845),  time:29.859, tt:2269.251\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01274, lr:5.82e-02, fs:0.83673 (r=0.828,p=0.845),  time:29.883, tt:2301.018\n",
      "Ep:77, loss:0.00001, loss_test:0.01265, lr:5.82e-02, fs:0.83673 (r=0.828,p=0.845),  time:29.887, tt:2331.210\n",
      "Ep:78, loss:0.00001, loss_test:0.01268, lr:5.82e-02, fs:0.83938 (r=0.818,p=0.862),  time:29.894, tt:2361.661\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01268, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.899, tt:2391.911\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01265, lr:5.82e-02, fs:0.83938 (r=0.818,p=0.862),  time:29.909, tt:2422.611\n",
      "Ep:81, loss:0.00001, loss_test:0.01266, lr:5.82e-02, fs:0.83938 (r=0.818,p=0.862),  time:29.912, tt:2452.823\n",
      "Ep:82, loss:0.00001, loss_test:0.01266, lr:5.82e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.911, tt:2482.621\n",
      "Ep:83, loss:0.00001, loss_test:0.01261, lr:5.82e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.906, tt:2512.100\n",
      "Ep:84, loss:0.00001, loss_test:0.01265, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.921, tt:2543.268\n",
      "Ep:85, loss:0.00001, loss_test:0.01270, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.938, tt:2574.631\n",
      "Ep:86, loss:0.00001, loss_test:0.01258, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.941, tt:2604.862\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01258, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.942, tt:2634.892\n",
      "Ep:88, loss:0.00001, loss_test:0.01268, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.945, tt:2665.062\n",
      "Ep:89, loss:0.00001, loss_test:0.01269, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.962, tt:2696.536\n",
      "Ep:90, loss:0.00001, loss_test:0.01269, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.956, tt:2726.016\n",
      "Ep:91, loss:0.00001, loss_test:0.01271, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.955, tt:2755.855\n",
      "Ep:92, loss:0.00001, loss_test:0.01266, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.946, tt:2785.010\n",
      "Ep:93, loss:0.00001, loss_test:0.01272, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.936, tt:2814.005\n",
      "Ep:94, loss:0.00001, loss_test:0.01266, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.950, tt:2845.220\n",
      "Ep:95, loss:0.00001, loss_test:0.01265, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.946, tt:2874.783\n",
      "Ep:96, loss:0.00001, loss_test:0.01273, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.920, tt:2902.210\n",
      "Ep:97, loss:0.00001, loss_test:0.01269, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.929, tt:2932.994\n",
      "Ep:98, loss:0.00001, loss_test:0.01276, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.944, tt:2964.413\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01281, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.962, tt:2996.224\n",
      "Ep:100, loss:0.00001, loss_test:0.01274, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.964, tt:3026.334\n",
      "Ep:101, loss:0.00001, loss_test:0.01279, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.949, tt:3054.832\n",
      "Ep:102, loss:0.00001, loss_test:0.01284, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.947, tt:3084.548\n",
      "Ep:103, loss:0.00001, loss_test:0.01280, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.926, tt:3112.283\n",
      "Ep:104, loss:0.00001, loss_test:0.01282, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.925, tt:3142.090\n",
      "Ep:105, loss:0.00001, loss_test:0.01288, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.916, tt:3171.057\n",
      "Ep:106, loss:0.00001, loss_test:0.01292, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.940, tt:3203.544\n",
      "Ep:107, loss:0.00001, loss_test:0.01288, lr:5.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.945, tt:3234.028\n",
      "Ep:108, loss:0.00001, loss_test:0.01293, lr:5.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.943, tt:3263.782\n",
      "Ep:109, loss:0.00001, loss_test:0.01293, lr:5.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.956, tt:3295.201\n",
      "Ep:110, loss:0.00001, loss_test:0.01296, lr:5.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.955, tt:3324.960\n",
      "Ep:111, loss:0.00001, loss_test:0.01299, lr:5.65e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.960, tt:3355.486\n",
      "Ep:112, loss:0.00001, loss_test:0.01297, lr:5.59e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.939, tt:3383.050\n",
      "Ep:113, loss:0.00001, loss_test:0.01298, lr:5.54e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.924, tt:3411.301\n",
      "Ep:114, loss:0.00001, loss_test:0.01301, lr:5.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.932, tt:3442.148\n",
      "Ep:115, loss:0.00001, loss_test:0.01304, lr:5.43e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.948, tt:3473.983\n",
      "Ep:116, loss:0.00001, loss_test:0.01304, lr:5.37e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.954, tt:3504.638\n",
      "Ep:117, loss:0.00001, loss_test:0.01310, lr:5.32e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.964, tt:3535.724\n",
      "Ep:118, loss:0.00001, loss_test:0.01308, lr:5.27e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.969, tt:3566.310\n",
      "Ep:119, loss:0.00001, loss_test:0.01310, lr:5.21e-02, fs:0.85561 (r=0.808,p=0.909),  time:29.984, tt:3598.029\n",
      "Ep:120, loss:0.00001, loss_test:0.01319, lr:5.16e-02, fs:0.85561 (r=0.808,p=0.909),  time:29.982, tt:3627.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.01313, lr:5.11e-02, fs:0.85106 (r=0.808,p=0.899),  time:29.995, tt:3659.384\n",
      "Ep:122, loss:0.00001, loss_test:0.01317, lr:5.06e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.001, tt:3690.114\n",
      "Ep:123, loss:0.00001, loss_test:0.01323, lr:5.01e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.007, tt:3720.810\n",
      "Ep:124, loss:0.00001, loss_test:0.01323, lr:4.96e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.004, tt:3750.465\n",
      "Ep:125, loss:0.00001, loss_test:0.01321, lr:4.91e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.010, tt:3781.238\n",
      "Ep:126, loss:0.00001, loss_test:0.01326, lr:4.86e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.006, tt:3810.749\n",
      "Ep:127, loss:0.00001, loss_test:0.01333, lr:4.81e-02, fs:0.85561 (r=0.808,p=0.909),  time:29.995, tt:3839.392\n",
      "Ep:128, loss:0.00001, loss_test:0.01330, lr:4.76e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.028, tt:3873.619\n",
      "Ep:129, loss:0.00001, loss_test:0.01330, lr:4.71e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.033, tt:3904.257\n",
      "Ep:130, loss:0.00001, loss_test:0.01342, lr:4.67e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.037, tt:3934.788\n",
      "Ep:131, loss:0.00001, loss_test:0.01341, lr:4.62e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.043, tt:3965.676\n",
      "Ep:132, loss:0.00001, loss_test:0.01337, lr:4.57e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.036, tt:3994.735\n",
      "Ep:133, loss:0.00001, loss_test:0.01341, lr:4.53e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.028, tt:4023.718\n",
      "Ep:134, loss:0.00001, loss_test:0.01349, lr:4.48e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.024, tt:4053.285\n",
      "Ep:135, loss:0.00001, loss_test:0.01343, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.018, tt:4082.452\n",
      "Ep:136, loss:0.00001, loss_test:0.01348, lr:4.39e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.021, tt:4112.875\n",
      "Ep:137, loss:0.00001, loss_test:0.01352, lr:4.35e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.028, tt:4143.916\n",
      "Ep:138, loss:0.00001, loss_test:0.01349, lr:4.31e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.026, tt:4173.663\n",
      "Ep:139, loss:0.00001, loss_test:0.01353, lr:4.26e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.014, tt:4202.006\n",
      "Ep:140, loss:0.00001, loss_test:0.01355, lr:4.22e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.010, tt:4231.345\n",
      "Ep:141, loss:0.00001, loss_test:0.01359, lr:4.18e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.015, tt:4262.060\n",
      "Ep:142, loss:0.00001, loss_test:0.01358, lr:4.14e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.009, tt:4291.352\n",
      "Ep:143, loss:0.00000, loss_test:0.01364, lr:4.10e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.006, tt:4320.915\n",
      "Ep:144, loss:0.00000, loss_test:0.01366, lr:4.05e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.002, tt:4350.323\n",
      "Ep:145, loss:0.00000, loss_test:0.01367, lr:4.01e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.006, tt:4380.946\n",
      "Ep:146, loss:0.00000, loss_test:0.01369, lr:3.97e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.004, tt:4410.658\n",
      "Ep:147, loss:0.00000, loss_test:0.01371, lr:3.93e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.003, tt:4440.477\n",
      "Ep:148, loss:0.00000, loss_test:0.01371, lr:3.89e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.002, tt:4470.337\n",
      "Ep:149, loss:0.00000, loss_test:0.01376, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.005, tt:4500.788\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00000, loss_test:0.01381, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.005, tt:4530.687\n",
      "Ep:151, loss:0.00000, loss_test:0.01378, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.011, tt:4561.738\n",
      "Ep:152, loss:0.00000, loss_test:0.01381, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.006, tt:4590.933\n",
      "Ep:153, loss:0.00000, loss_test:0.01383, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.006, tt:4620.869\n",
      "Ep:154, loss:0.00000, loss_test:0.01387, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.002, tt:4650.239\n",
      "Ep:155, loss:0.00000, loss_test:0.01390, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.016, tt:4682.530\n",
      "Ep:156, loss:0.00000, loss_test:0.01389, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.018, tt:4712.790\n",
      "Ep:157, loss:0.00000, loss_test:0.01390, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.014, tt:4742.221\n",
      "Ep:158, loss:0.00000, loss_test:0.01397, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.016, tt:4772.616\n",
      "Ep:159, loss:0.00000, loss_test:0.01393, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.008, tt:4801.266\n",
      "Ep:160, loss:0.00000, loss_test:0.01399, lr:3.86e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.003, tt:4830.481\n",
      "Ep:161, loss:0.00000, loss_test:0.01402, lr:3.82e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.008, tt:4861.344\n",
      "Ep:162, loss:0.00000, loss_test:0.01400, lr:3.78e-02, fs:0.85246 (r=0.788,p=0.929),  time:30.011, tt:4891.840\n",
      "Ep:163, loss:0.00000, loss_test:0.01404, lr:3.74e-02, fs:0.85246 (r=0.788,p=0.929),  time:30.014, tt:4922.239\n",
      "Ep:164, loss:0.00000, loss_test:0.01407, lr:3.70e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.019, tt:4953.125\n",
      "Ep:165, loss:0.00000, loss_test:0.01408, lr:3.67e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.019, tt:4983.199\n",
      "Ep:166, loss:0.00000, loss_test:0.01411, lr:3.63e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.018, tt:5012.934\n",
      "Ep:167, loss:0.00000, loss_test:0.01412, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.018, tt:5043.006\n",
      "Ep:168, loss:0.00000, loss_test:0.01415, lr:3.56e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.018, tt:5073.072\n",
      "Ep:169, loss:0.00000, loss_test:0.01418, lr:3.52e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.018, tt:5103.061\n",
      "Ep:170, loss:0.00000, loss_test:0.01418, lr:3.49e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.018, tt:5133.004\n",
      "Ep:171, loss:0.00000, loss_test:0.01417, lr:3.45e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.022, tt:5163.867\n",
      "Ep:172, loss:0.00000, loss_test:0.01421, lr:3.42e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.024, tt:5194.217\n",
      "Ep:173, loss:0.00000, loss_test:0.01422, lr:3.38e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.029, tt:5225.068\n",
      "Ep:174, loss:0.00000, loss_test:0.01425, lr:3.35e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.029, tt:5255.119\n",
      "Ep:175, loss:0.00000, loss_test:0.01428, lr:3.32e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.037, tt:5286.434\n",
      "Ep:176, loss:0.00000, loss_test:0.01430, lr:3.28e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.040, tt:5317.066\n",
      "Ep:177, loss:0.00000, loss_test:0.01431, lr:3.25e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.047, tt:5348.385\n",
      "Ep:178, loss:0.00000, loss_test:0.01432, lr:3.22e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.051, tt:5379.072\n",
      "Ep:179, loss:0.00000, loss_test:0.01431, lr:3.19e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.050, tt:5409.060\n",
      "Ep:180, loss:0.00000, loss_test:0.01435, lr:3.15e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.060, tt:5440.782\n",
      "Ep:181, loss:0.00000, loss_test:0.01437, lr:3.12e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.065, tt:5471.910\n",
      "Ep:182, loss:0.00000, loss_test:0.01437, lr:3.09e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.063, tt:5501.553\n",
      "Ep:183, loss:0.00000, loss_test:0.01443, lr:3.06e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.062, tt:5531.492\n",
      "Ep:184, loss:0.00000, loss_test:0.01443, lr:3.03e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.070, tt:5563.013\n",
      "Ep:185, loss:0.00000, loss_test:0.01444, lr:3.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.080, tt:5594.928\n",
      "Ep:186, loss:0.00000, loss_test:0.01444, lr:2.97e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.083, tt:5625.534\n",
      "Ep:187, loss:0.00000, loss_test:0.01446, lr:2.94e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.081, tt:5655.226\n",
      "Ep:188, loss:0.00000, loss_test:0.01450, lr:2.91e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.090, tt:5687.017\n",
      "Ep:189, loss:0.00000, loss_test:0.01448, lr:2.88e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.099, tt:5718.891\n",
      "Ep:190, loss:0.00000, loss_test:0.01448, lr:2.85e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.094, tt:5748.029\n",
      "Ep:191, loss:0.00000, loss_test:0.01456, lr:2.82e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.098, tt:5778.744\n",
      "Ep:192, loss:0.00000, loss_test:0.01453, lr:2.80e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.106, tt:5810.387\n",
      "Ep:193, loss:0.00000, loss_test:0.01457, lr:2.77e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.124, tt:5844.014\n",
      "Ep:194, loss:0.00000, loss_test:0.01456, lr:2.74e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.131, tt:5875.504\n",
      "Ep:195, loss:0.00000, loss_test:0.01457, lr:2.71e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.144, tt:5908.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00000, loss_test:0.01457, lr:2.69e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.155, tt:5940.474\n",
      "Ep:197, loss:0.00000, loss_test:0.01459, lr:2.66e-02, fs:0.80233 (r=0.697,p=0.945),  time:30.163, tt:5972.230\n",
      "Ep:198, loss:0.00000, loss_test:0.01462, lr:2.63e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.162, tt:6002.158\n",
      "Ep:199, loss:0.00000, loss_test:0.01464, lr:2.61e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.165, tt:6033.081\n",
      "Ep:200, loss:0.00000, loss_test:0.01464, lr:2.58e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.176, tt:6065.456\n",
      "Ep:201, loss:0.00000, loss_test:0.01466, lr:2.55e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.181, tt:6096.548\n",
      "Ep:202, loss:0.00000, loss_test:0.01469, lr:2.53e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.187, tt:6127.878\n",
      "Ep:203, loss:0.00000, loss_test:0.01470, lr:2.50e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.188, tt:6158.397\n",
      "Ep:204, loss:0.00000, loss_test:0.01469, lr:2.48e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.199, tt:6190.812\n",
      "Ep:205, loss:0.00000, loss_test:0.01471, lr:2.45e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.200, tt:6221.239\n",
      "Ep:206, loss:0.00000, loss_test:0.01472, lr:2.43e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.203, tt:6252.006\n",
      "Ep:207, loss:0.00000, loss_test:0.01474, lr:2.40e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.209, tt:6283.469\n",
      "Ep:208, loss:0.00000, loss_test:0.01474, lr:2.38e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.220, tt:6316.012\n",
      "Ep:209, loss:0.00000, loss_test:0.01476, lr:2.36e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.228, tt:6347.779\n",
      "Ep:210, loss:0.00000, loss_test:0.01478, lr:2.33e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.225, tt:6377.533\n",
      "Ep:211, loss:0.00000, loss_test:0.01478, lr:2.31e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.230, tt:6408.855\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14134, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.317, tt:28.317\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13999, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.722, tt:53.443\n",
      "Ep:2, loss:0.00027, loss_test:0.13776, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:26.549, tt:79.646\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13433, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:27.801, tt:111.203\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12966, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:28.046, tt:140.229\n",
      "Ep:5, loss:0.00025, loss_test:0.12508, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:28.425, tt:170.551\n",
      "Ep:6, loss:0.00024, loss_test:0.12216, lr:1.00e-02, fs:0.65560 (r=0.798,p=0.556),  time:28.805, tt:201.638\n",
      "Ep:7, loss:0.00023, loss_test:0.12129, lr:1.00e-02, fs:0.65471 (r=0.737,p=0.589),  time:28.872, tt:230.973\n",
      "Ep:8, loss:0.00023, loss_test:0.12045, lr:1.00e-02, fs:0.65455 (r=0.727,p=0.595),  time:28.879, tt:259.913\n",
      "Ep:11, loss:0.00021, loss_test:0.11601, lr:1.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:29.550, tt:354.597\n",
      "Ep:12, loss:0.00021, loss_test:0.11412, lr:1.00e-02, fs:0.66667 (r=0.717,p=0.623),  time:29.745, tt:386.684\n",
      "Ep:13, loss:0.00020, loss_test:0.11213, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:29.775, tt:416.848\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.11002, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:29.844, tt:447.664\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10756, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:30.036, tt:480.581\n",
      "Ep:16, loss:0.00019, loss_test:0.10584, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:30.106, tt:511.805\n",
      "Ep:17, loss:0.00018, loss_test:0.10345, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:30.085, tt:541.534\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10146, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:30.205, tt:573.892\n",
      "Ep:19, loss:0.00017, loss_test:0.09988, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:30.220, tt:604.396\n",
      "Ep:20, loss:0.00017, loss_test:0.09847, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:30.365, tt:637.655\n",
      "Ep:21, loss:0.00016, loss_test:0.09637, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.467, tt:670.268\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09504, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.432, tt:699.934\n",
      "Ep:23, loss:0.00016, loss_test:0.09367, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:30.486, tt:731.672\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09178, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:30.472, tt:761.793\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08952, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:30.476, tt:792.371\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08990, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.538, tt:824.516\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08943, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:30.570, tt:855.953\n",
      "Ep:28, loss:0.00014, loss_test:0.08623, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.590, tt:887.100\n",
      "Ep:29, loss:0.00013, loss_test:0.08763, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:30.620, tt:918.614\n",
      "Ep:30, loss:0.00013, loss_test:0.08683, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:30.599, tt:948.578\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08377, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.645, tt:980.647\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08499, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.680, tt:1012.454\n",
      "Ep:33, loss:0.00012, loss_test:0.08385, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:30.765, tt:1045.997\n",
      "Ep:34, loss:0.00012, loss_test:0.08337, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:30.720, tt:1075.208\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08385, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:30.741, tt:1106.663\n",
      "Ep:36, loss:0.00011, loss_test:0.08174, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.760, tt:1138.119\n",
      "Ep:37, loss:0.00011, loss_test:0.08287, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.774, tt:1169.399\n",
      "Ep:38, loss:0.00011, loss_test:0.08149, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:30.783, tt:1200.550\n",
      "Ep:39, loss:0.00011, loss_test:0.08211, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.826, tt:1233.034\n",
      "Ep:40, loss:0.00010, loss_test:0.08081, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.819, tt:1263.580\n",
      "Ep:41, loss:0.00010, loss_test:0.07969, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.842, tt:1295.368\n",
      "Ep:42, loss:0.00010, loss_test:0.08160, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.839, tt:1326.058\n",
      "Ep:43, loss:0.00009, loss_test:0.07911, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.847, tt:1357.262\n",
      "Ep:44, loss:0.00009, loss_test:0.08097, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:30.876, tt:1389.430\n",
      "Ep:45, loss:0.00009, loss_test:0.07942, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:30.862, tt:1419.644\n",
      "Ep:46, loss:0.00009, loss_test:0.07948, lr:9.90e-03, fs:0.78495 (r=0.737,p=0.839),  time:30.888, tt:1451.756\n",
      "Ep:47, loss:0.00009, loss_test:0.07956, lr:9.80e-03, fs:0.77778 (r=0.707,p=0.864),  time:30.886, tt:1482.522\n",
      "Ep:48, loss:0.00008, loss_test:0.07968, lr:9.70e-03, fs:0.79570 (r=0.747,p=0.851),  time:30.892, tt:1513.716\n",
      "Ep:49, loss:0.00008, loss_test:0.07765, lr:9.61e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.923, tt:1546.139\n",
      "Ep:50, loss:0.00008, loss_test:0.07973, lr:9.51e-03, fs:0.78689 (r=0.727,p=0.857),  time:30.963, tt:1579.107\n",
      "Ep:51, loss:0.00008, loss_test:0.07684, lr:9.41e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.920, tt:1607.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00008, loss_test:0.07903, lr:9.32e-03, fs:0.77596 (r=0.717,p=0.845),  time:30.936, tt:1639.602\n",
      "Ep:53, loss:0.00008, loss_test:0.07684, lr:9.23e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.961, tt:1671.918\n",
      "Ep:54, loss:0.00007, loss_test:0.07593, lr:9.14e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.991, tt:1704.514\n",
      "Ep:55, loss:0.00007, loss_test:0.07846, lr:9.04e-03, fs:0.78919 (r=0.737,p=0.849),  time:31.049, tt:1738.746\n",
      "Ep:56, loss:0.00007, loss_test:0.07475, lr:8.95e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.079, tt:1771.518\n",
      "Ep:57, loss:0.00007, loss_test:0.07903, lr:8.86e-03, fs:0.78261 (r=0.727,p=0.847),  time:31.108, tt:1804.253\n",
      "Ep:58, loss:0.00007, loss_test:0.07410, lr:8.78e-03, fs:0.79781 (r=0.737,p=0.869),  time:31.133, tt:1836.840\n",
      "Ep:59, loss:0.00006, loss_test:0.07791, lr:8.69e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.170, tt:1870.212\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.07469, lr:8.69e-03, fs:0.79121 (r=0.727,p=0.867),  time:31.181, tt:1902.014\n",
      "Ep:61, loss:0.00006, loss_test:0.07731, lr:8.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.191, tt:1933.842\n",
      "Ep:62, loss:0.00006, loss_test:0.07457, lr:8.69e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.208, tt:1966.101\n",
      "Ep:63, loss:0.00006, loss_test:0.07491, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.214, tt:1997.699\n",
      "Ep:64, loss:0.00006, loss_test:0.07550, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.207, tt:2028.483\n",
      "Ep:65, loss:0.00006, loss_test:0.07520, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.219, tt:2060.478\n",
      "Ep:66, loss:0.00006, loss_test:0.07504, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.251, tt:2093.789\n",
      "Ep:67, loss:0.00005, loss_test:0.07342, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.260, tt:2125.695\n",
      "Ep:68, loss:0.00005, loss_test:0.07416, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.264, tt:2157.199\n",
      "Ep:69, loss:0.00005, loss_test:0.07498, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.260, tt:2188.187\n",
      "Ep:70, loss:0.00005, loss_test:0.07294, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.275, tt:2220.512\n",
      "Ep:71, loss:0.00005, loss_test:0.07365, lr:8.60e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.269, tt:2251.363\n",
      "Ep:72, loss:0.00005, loss_test:0.07436, lr:8.51e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.289, tt:2284.131\n",
      "Ep:73, loss:0.00005, loss_test:0.07358, lr:8.43e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.281, tt:2314.778\n",
      "Ep:74, loss:0.00005, loss_test:0.07355, lr:8.35e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.300, tt:2347.538\n",
      "Ep:75, loss:0.00005, loss_test:0.07745, lr:8.26e-03, fs:0.78453 (r=0.717,p=0.866),  time:31.315, tt:2379.941\n",
      "Ep:76, loss:0.00005, loss_test:0.07185, lr:8.18e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.327, tt:2412.156\n",
      "Ep:77, loss:0.00005, loss_test:0.07591, lr:8.10e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.349, tt:2445.232\n",
      "Ep:78, loss:0.00004, loss_test:0.07145, lr:8.02e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.349, tt:2476.532\n",
      "Ep:79, loss:0.00004, loss_test:0.07660, lr:7.94e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.345, tt:2507.611\n",
      "Ep:80, loss:0.00004, loss_test:0.07415, lr:7.86e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.355, tt:2539.765\n",
      "Ep:81, loss:0.00004, loss_test:0.07386, lr:7.78e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.384, tt:2573.484\n",
      "Ep:82, loss:0.00004, loss_test:0.07325, lr:7.70e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.374, tt:2604.007\n",
      "Ep:83, loss:0.00004, loss_test:0.07346, lr:7.62e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.379, tt:2635.826\n",
      "Ep:84, loss:0.00004, loss_test:0.07520, lr:7.55e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.379, tt:2667.210\n",
      "Ep:85, loss:0.00004, loss_test:0.07196, lr:7.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.397, tt:2700.109\n",
      "Ep:86, loss:0.00004, loss_test:0.07378, lr:7.40e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.416, tt:2733.176\n",
      "Ep:87, loss:0.00004, loss_test:0.07207, lr:7.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.421, tt:2765.071\n",
      "Ep:88, loss:0.00004, loss_test:0.07432, lr:7.25e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.427, tt:2797.014\n",
      "Ep:89, loss:0.00004, loss_test:0.07232, lr:7.18e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.437, tt:2829.305\n",
      "Ep:90, loss:0.00004, loss_test:0.07390, lr:7.11e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.441, tt:2861.172\n",
      "Ep:91, loss:0.00004, loss_test:0.07274, lr:7.03e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.447, tt:2893.083\n",
      "Ep:92, loss:0.00004, loss_test:0.07243, lr:6.96e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.457, tt:2925.482\n",
      "Ep:93, loss:0.00003, loss_test:0.07260, lr:6.89e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.460, tt:2957.245\n",
      "Ep:94, loss:0.00003, loss_test:0.07310, lr:6.83e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.463, tt:2989.028\n",
      "Ep:95, loss:0.00003, loss_test:0.07356, lr:6.76e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.477, tt:3021.783\n",
      "Ep:96, loss:0.00003, loss_test:0.07205, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.493, tt:3054.808\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00003, loss_test:0.07480, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.501, tt:3087.060\n",
      "Ep:98, loss:0.00003, loss_test:0.07250, lr:6.69e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.511, tt:3119.576\n",
      "Ep:99, loss:0.00003, loss_test:0.07529, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.507, tt:3150.679\n",
      "Ep:100, loss:0.00003, loss_test:0.07258, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.520, tt:3183.521\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00003, loss_test:0.07666, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.549, tt:3217.994\n",
      "Ep:102, loss:0.00003, loss_test:0.07503, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.552, tt:3249.837\n",
      "Ep:103, loss:0.00003, loss_test:0.07387, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.567, tt:3282.924\n",
      "Ep:104, loss:0.00003, loss_test:0.07520, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.562, tt:3313.995\n",
      "Ep:105, loss:0.00003, loss_test:0.07255, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.567, tt:3346.141\n",
      "Ep:106, loss:0.00003, loss_test:0.07606, lr:6.69e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.577, tt:3378.759\n",
      "Ep:107, loss:0.00003, loss_test:0.07209, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.584, tt:3411.103\n",
      "Ep:108, loss:0.00003, loss_test:0.07547, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.600, tt:3444.429\n",
      "Ep:109, loss:0.00003, loss_test:0.07138, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.592, tt:3475.156\n",
      "Ep:110, loss:0.00003, loss_test:0.07676, lr:6.69e-03, fs:0.81609 (r=0.717,p=0.947),  time:31.606, tt:3508.231\n",
      "Ep:111, loss:0.00003, loss_test:0.07319, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.618, tt:3541.246\n",
      "Ep:112, loss:0.00003, loss_test:0.07509, lr:6.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.625, tt:3573.681\n",
      "Ep:113, loss:0.00003, loss_test:0.07497, lr:6.56e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.626, tt:3605.419\n",
      "Ep:114, loss:0.00003, loss_test:0.07429, lr:6.49e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.608, tt:3634.878\n",
      "Ep:115, loss:0.00003, loss_test:0.07522, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.595, tt:3665.041\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00003, loss_test:0.07323, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.603, tt:3697.519\n",
      "Ep:117, loss:0.00003, loss_test:0.07540, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.599, tt:3728.629\n",
      "Ep:118, loss:0.00003, loss_test:0.07431, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.587, tt:3758.904\n",
      "Ep:119, loss:0.00002, loss_test:0.07498, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.589, tt:3790.734\n",
      "Ep:120, loss:0.00002, loss_test:0.07502, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.578, tt:3820.971\n",
      "Ep:121, loss:0.00002, loss_test:0.07506, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.574, tt:3851.970\n",
      "Ep:122, loss:0.00002, loss_test:0.07407, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.583, tt:3884.693\n",
      "Ep:123, loss:0.00002, loss_test:0.07574, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.576, tt:3915.459\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.07491, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.583, tt:3947.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00002, loss_test:0.07562, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.581, tt:3979.246\n",
      "Ep:126, loss:0.00002, loss_test:0.07433, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.588, tt:4011.677\n",
      "Ep:127, loss:0.00002, loss_test:0.07612, lr:6.43e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.605, tt:4045.491\n",
      "Ep:128, loss:0.00002, loss_test:0.07546, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.609, tt:4077.614\n",
      "Ep:129, loss:0.00002, loss_test:0.07406, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.615, tt:4109.926\n",
      "Ep:130, loss:0.00002, loss_test:0.07552, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.620, tt:4142.241\n",
      "Ep:131, loss:0.00002, loss_test:0.07442, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.628, tt:4174.852\n",
      "Ep:132, loss:0.00002, loss_test:0.07574, lr:6.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:31.645, tt:4208.794\n",
      "Ep:133, loss:0.00002, loss_test:0.07442, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.649, tt:4241.011\n",
      "Ep:134, loss:0.00002, loss_test:0.07549, lr:6.43e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.652, tt:4273.054\n",
      "Ep:135, loss:0.00002, loss_test:0.07353, lr:6.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.648, tt:4304.065\n",
      "Ep:136, loss:0.00002, loss_test:0.07608, lr:6.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.645, tt:4335.373\n",
      "Ep:137, loss:0.00002, loss_test:0.07455, lr:6.24e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.644, tt:4366.873\n",
      "Ep:138, loss:0.00002, loss_test:0.07597, lr:6.17e-03, fs:0.78571 (r=0.667,p=0.957),  time:31.646, tt:4398.764\n",
      "Ep:139, loss:0.00002, loss_test:0.07441, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.645, tt:4430.335\n",
      "Ep:140, loss:0.00002, loss_test:0.07425, lr:6.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.656, tt:4463.506\n",
      "Ep:141, loss:0.00002, loss_test:0.07533, lr:5.99e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.648, tt:4493.989\n",
      "Ep:142, loss:0.00002, loss_test:0.07420, lr:5.93e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.648, tt:4525.603\n",
      "Ep:143, loss:0.00002, loss_test:0.07487, lr:5.87e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.643, tt:4556.614\n",
      "Ep:144, loss:0.00002, loss_test:0.07476, lr:5.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.646, tt:4588.708\n",
      "Ep:145, loss:0.00002, loss_test:0.07597, lr:5.75e-03, fs:0.82081 (r=0.717,p=0.959),  time:31.645, tt:4620.123\n",
      "Ep:146, loss:0.00002, loss_test:0.07365, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.643, tt:4651.477\n",
      "Ep:147, loss:0.00002, loss_test:0.07679, lr:5.64e-03, fs:0.79290 (r=0.677,p=0.957),  time:31.633, tt:4681.668\n",
      "Ep:148, loss:0.00002, loss_test:0.07485, lr:5.58e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.632, tt:4713.103\n",
      "Ep:149, loss:0.00002, loss_test:0.07602, lr:5.53e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.633, tt:4744.878\n",
      "Ep:150, loss:0.00002, loss_test:0.07578, lr:5.47e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.638, tt:4777.270\n",
      "Ep:151, loss:0.00002, loss_test:0.07566, lr:5.42e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.636, tt:4808.721\n",
      "Ep:152, loss:0.00002, loss_test:0.07546, lr:5.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.641, tt:4841.036\n",
      "Ep:153, loss:0.00002, loss_test:0.07510, lr:5.31e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.638, tt:4872.197\n",
      "Ep:154, loss:0.00002, loss_test:0.07623, lr:5.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.639, tt:4904.001\n",
      "Ep:155, loss:0.00002, loss_test:0.07436, lr:5.20e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.639, tt:4935.748\n",
      "Ep:156, loss:0.00002, loss_test:0.07808, lr:5.15e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.637, tt:4966.955\n",
      "Ep:157, loss:0.00002, loss_test:0.07523, lr:5.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.635, tt:4998.326\n",
      "Ep:158, loss:0.00002, loss_test:0.07693, lr:5.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.634, tt:5029.882\n",
      "Ep:159, loss:0.00002, loss_test:0.07509, lr:5.00e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.636, tt:5061.765\n",
      "Ep:160, loss:0.00002, loss_test:0.07835, lr:4.95e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.637, tt:5093.608\n",
      "Ep:161, loss:0.00002, loss_test:0.07622, lr:4.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.633, tt:5124.582\n",
      "Ep:162, loss:0.00002, loss_test:0.07645, lr:4.85e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.637, tt:5156.863\n",
      "Ep:163, loss:0.00001, loss_test:0.07792, lr:4.80e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.640, tt:5189.030\n",
      "Ep:164, loss:0.00001, loss_test:0.07531, lr:4.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.653, tt:5222.742\n",
      "Ep:165, loss:0.00001, loss_test:0.07758, lr:4.71e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.650, tt:5253.976\n",
      "Ep:166, loss:0.00001, loss_test:0.07550, lr:4.66e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.643, tt:5284.327\n",
      "Ep:167, loss:0.00001, loss_test:0.07581, lr:4.61e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.644, tt:5316.167\n",
      "Ep:168, loss:0.00001, loss_test:0.07802, lr:4.57e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.648, tt:5348.556\n",
      "Ep:169, loss:0.00001, loss_test:0.07462, lr:4.52e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.658, tt:5381.865\n",
      "Ep:170, loss:0.00001, loss_test:0.07804, lr:4.48e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.667, tt:5415.121\n",
      "Ep:171, loss:0.00001, loss_test:0.07681, lr:4.43e-03, fs:0.77844 (r=0.657,p=0.956),  time:31.677, tt:5448.505\n",
      "Ep:172, loss:0.00001, loss_test:0.07628, lr:4.39e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.679, tt:5480.475\n",
      "Ep:173, loss:0.00001, loss_test:0.07828, lr:4.34e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.683, tt:5512.766\n",
      "Ep:174, loss:0.00001, loss_test:0.07682, lr:4.30e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.683, tt:5544.521\n",
      "Ep:175, loss:0.00001, loss_test:0.07755, lr:4.26e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.689, tt:5577.287\n",
      "Ep:176, loss:0.00001, loss_test:0.07801, lr:4.21e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.690, tt:5609.066\n",
      "Ep:177, loss:0.00001, loss_test:0.07628, lr:4.17e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.690, tt:5640.829\n",
      "Ep:178, loss:0.00001, loss_test:0.07677, lr:4.13e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.686, tt:5671.863\n",
      "Ep:179, loss:0.00001, loss_test:0.07728, lr:4.09e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.688, tt:5703.922\n",
      "Ep:180, loss:0.00001, loss_test:0.07584, lr:4.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.696, tt:5736.912\n",
      "Ep:181, loss:0.00001, loss_test:0.07767, lr:4.01e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.705, tt:5770.339\n",
      "Ep:182, loss:0.00001, loss_test:0.07686, lr:3.97e-03, fs:0.74847 (r=0.616,p=0.953),  time:31.708, tt:5802.613\n",
      "Ep:183, loss:0.00001, loss_test:0.07650, lr:3.93e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.712, tt:5834.948\n",
      "Ep:184, loss:0.00001, loss_test:0.07720, lr:3.89e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.714, tt:5867.055\n",
      "Ep:185, loss:0.00001, loss_test:0.07711, lr:3.85e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.713, tt:5898.690\n",
      "Ep:186, loss:0.00001, loss_test:0.07690, lr:3.81e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.717, tt:5931.138\n",
      "Ep:187, loss:0.00001, loss_test:0.07679, lr:3.77e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.718, tt:5962.965\n",
      "Ep:188, loss:0.00001, loss_test:0.07701, lr:3.73e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.729, tt:5996.716\n",
      "Ep:189, loss:0.00001, loss_test:0.07689, lr:3.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.760, tt:6034.412\n",
      "Ep:190, loss:0.00001, loss_test:0.07659, lr:3.66e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.762, tt:6066.503\n",
      "Ep:191, loss:0.00001, loss_test:0.07648, lr:3.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.769, tt:6099.593\n",
      "Ep:192, loss:0.00001, loss_test:0.07720, lr:3.59e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.773, tt:6132.213\n",
      "Ep:193, loss:0.00001, loss_test:0.07666, lr:3.55e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.774, tt:6164.143\n",
      "Ep:194, loss:0.00001, loss_test:0.07701, lr:3.52e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.772, tt:6195.530\n",
      "Ep:195, loss:0.00001, loss_test:0.07737, lr:3.48e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.779, tt:6228.655\n",
      "Ep:196, loss:0.00001, loss_test:0.07670, lr:3.45e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.783, tt:6261.239\n",
      "Ep:197, loss:0.00001, loss_test:0.07733, lr:3.41e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.776, tt:6291.662\n",
      "Ep:198, loss:0.00001, loss_test:0.07760, lr:3.38e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.770, tt:6322.298\n",
      "Ep:199, loss:0.00001, loss_test:0.07723, lr:3.34e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.768, tt:6353.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00001, loss_test:0.07691, lr:3.31e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.773, tt:6386.333\n",
      "Ep:201, loss:0.00001, loss_test:0.07888, lr:3.28e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.777, tt:6418.997\n",
      "Ep:202, loss:0.00001, loss_test:0.07784, lr:3.24e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.778, tt:6450.946\n",
      "Ep:203, loss:0.00001, loss_test:0.07669, lr:3.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.780, tt:6483.141\n",
      "Ep:204, loss:0.00001, loss_test:0.07851, lr:3.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.784, tt:6515.656\n",
      "Ep:205, loss:0.00001, loss_test:0.07793, lr:3.15e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.790, tt:6548.690\n",
      "Ep:206, loss:0.00001, loss_test:0.07726, lr:3.12e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.788, tt:6580.204\n",
      "Ep:207, loss:0.00001, loss_test:0.07766, lr:3.09e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.788, tt:6611.860\n",
      "Ep:208, loss:0.00001, loss_test:0.07753, lr:3.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.792, tt:6644.457\n",
      "Ep:209, loss:0.00001, loss_test:0.07770, lr:3.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.786, tt:6674.963\n",
      "Ep:210, loss:0.00001, loss_test:0.07741, lr:2.99e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.796, tt:6708.872\n",
      "Ep:211, loss:0.00001, loss_test:0.07711, lr:2.96e-03, fs:0.74074 (r=0.606,p=0.952),  time:31.803, tt:6742.254\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02126, lr:6.00e-02, fs:0.61674 (r=0.707,p=0.547),  time:22.205, tt:22.205\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02163, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.630, tt:45.260\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02422, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.698, tt:74.094\n",
      "Ep:3, loss:0.00005, loss_test:0.02543, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.446, tt:101.784\n",
      "Ep:4, loss:0.00005, loss_test:0.02562, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.899, tt:129.495\n",
      "Ep:5, loss:0.00005, loss_test:0.02516, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.693, tt:160.158\n",
      "Ep:6, loss:0.00005, loss_test:0.02423, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.770, tt:187.391\n",
      "Ep:7, loss:0.00005, loss_test:0.02294, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.921, tt:215.365\n",
      "Ep:8, loss:0.00004, loss_test:0.02145, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.241, tt:245.173\n",
      "Ep:9, loss:0.00004, loss_test:0.02004, lr:6.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:27.585, tt:275.848\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:27.766, tt:305.426\n",
      "Ep:11, loss:0.00004, loss_test:0.01896, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:28.114, tt:337.372\n",
      "Ep:12, loss:0.00004, loss_test:0.01920, lr:6.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:28.354, tt:368.607\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.67265 (r=0.758,p=0.605),  time:28.515, tt:399.214\n",
      "Ep:14, loss:0.00003, loss_test:0.01860, lr:6.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:28.632, tt:429.473\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:28.753, tt:460.041\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:28.904, tt:491.362\n",
      "Ep:17, loss:0.00003, loss_test:0.01711, lr:6.00e-02, fs:0.71970 (r=0.960,p=0.576),  time:28.944, tt:520.985\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.72727 (r=0.970,p=0.582),  time:28.933, tt:549.728\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.74330 (r=0.980,p=0.599),  time:29.079, tt:581.585\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:29.203, tt:613.266\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01627, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:29.243, tt:643.344\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.75949 (r=0.909,p=0.652),  time:29.296, tt:673.817\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:29.368, tt:704.822\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:29.410, tt:735.247\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01591, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:29.396, tt:764.300\n",
      "Ep:26, loss:0.00003, loss_test:0.01571, lr:6.00e-02, fs:0.78261 (r=0.909,p=0.687),  time:29.440, tt:794.874\n",
      "Ep:27, loss:0.00003, loss_test:0.01553, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:29.438, tt:824.277\n",
      "Ep:28, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.447, tt:853.952\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:29.438, tt:883.149\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:29.472, tt:913.630\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:29.479, tt:943.331\n",
      "Ep:32, loss:0.00002, loss_test:0.01508, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:29.522, tt:974.219\n",
      "Ep:33, loss:0.00002, loss_test:0.01504, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:29.515, tt:1003.494\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01498, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:29.504, tt:1032.656\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:29.499, tt:1061.971\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.488, tt:1091.059\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.467, tt:1119.755\n",
      "Ep:38, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:29.441, tt:1148.206\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01450, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:29.445, tt:1177.819\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:29.428, tt:1206.544\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01439, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:29.467, tt:1237.634\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01435, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:29.454, tt:1266.535\n",
      "Ep:43, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:29.490, tt:1297.579\n",
      "Ep:44, loss:0.00002, loss_test:0.01423, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:29.500, tt:1327.486\n",
      "Ep:45, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:29.487, tt:1356.405\n",
      "Ep:46, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:29.519, tt:1387.396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:29.541, tt:1417.961\n",
      "Ep:48, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:29.551, tt:1447.976\n",
      "Ep:49, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:29.573, tt:1478.648\n",
      "Ep:50, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:29.572, tt:1508.168\n",
      "Ep:51, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.577, tt:1538.018\n",
      "Ep:52, loss:0.00002, loss_test:0.01393, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.568, tt:1567.125\n",
      "Ep:53, loss:0.00002, loss_test:0.01388, lr:5.94e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.592, tt:1597.949\n",
      "Ep:54, loss:0.00001, loss_test:0.01384, lr:5.88e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.605, tt:1628.287\n",
      "Ep:55, loss:0.00001, loss_test:0.01383, lr:5.82e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.609, tt:1658.114\n",
      "Ep:56, loss:0.00001, loss_test:0.01381, lr:5.76e-02, fs:0.82075 (r=0.879,p=0.770),  time:29.615, tt:1688.077\n",
      "Ep:57, loss:0.00001, loss_test:0.01379, lr:5.71e-02, fs:0.81517 (r=0.869,p=0.768),  time:29.623, tt:1718.121\n",
      "Ep:58, loss:0.00001, loss_test:0.01379, lr:5.65e-02, fs:0.82692 (r=0.869,p=0.789),  time:29.639, tt:1748.715\n",
      "Ep:59, loss:0.00001, loss_test:0.01377, lr:5.59e-02, fs:0.81731 (r=0.859,p=0.780),  time:29.661, tt:1779.637\n",
      "Ep:60, loss:0.00001, loss_test:0.01375, lr:5.54e-02, fs:0.82126 (r=0.859,p=0.787),  time:29.688, tt:1810.964\n",
      "Ep:61, loss:0.00001, loss_test:0.01374, lr:5.48e-02, fs:0.81951 (r=0.848,p=0.792),  time:29.708, tt:1841.900\n",
      "Ep:62, loss:0.00001, loss_test:0.01372, lr:5.43e-02, fs:0.81951 (r=0.848,p=0.792),  time:29.698, tt:1870.986\n",
      "Ep:63, loss:0.00001, loss_test:0.01371, lr:5.37e-02, fs:0.82353 (r=0.848,p=0.800),  time:29.691, tt:1900.245\n",
      "Ep:64, loss:0.00001, loss_test:0.01369, lr:5.32e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.700, tt:1930.528\n",
      "Ep:65, loss:0.00001, loss_test:0.01369, lr:5.27e-02, fs:0.81592 (r=0.828,p=0.804),  time:29.697, tt:1960.012\n",
      "Ep:66, loss:0.00001, loss_test:0.01368, lr:5.21e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.726, tt:1991.643\n",
      "Ep:67, loss:0.00001, loss_test:0.01368, lr:5.16e-02, fs:0.79798 (r=0.798,p=0.798),  time:29.738, tt:2022.195\n",
      "Ep:68, loss:0.00001, loss_test:0.01367, lr:5.11e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.778, tt:2054.679\n",
      "Ep:69, loss:0.00001, loss_test:0.01366, lr:5.06e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.782, tt:2084.717\n",
      "Ep:70, loss:0.00001, loss_test:0.01368, lr:5.01e-02, fs:0.78571 (r=0.778,p=0.794),  time:29.787, tt:2114.848\n",
      "Ep:71, loss:0.00001, loss_test:0.01370, lr:4.96e-02, fs:0.77949 (r=0.768,p=0.792),  time:29.801, tt:2145.642\n",
      "Ep:72, loss:0.00001, loss_test:0.01372, lr:4.91e-02, fs:0.76684 (r=0.747,p=0.787),  time:29.798, tt:2175.261\n",
      "Ep:73, loss:0.00001, loss_test:0.01372, lr:4.86e-02, fs:0.77720 (r=0.758,p=0.798),  time:29.809, tt:2205.829\n",
      "Ep:74, loss:0.00001, loss_test:0.01373, lr:4.81e-02, fs:0.77487 (r=0.747,p=0.804),  time:29.799, tt:2234.945\n",
      "Ep:75, loss:0.00001, loss_test:0.01371, lr:4.76e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.798, tt:2264.636\n",
      "Ep:76, loss:0.00001, loss_test:0.01371, lr:4.71e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.795, tt:2294.203\n",
      "Ep:77, loss:0.00001, loss_test:0.01371, lr:4.67e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.798, tt:2324.226\n",
      "Ep:78, loss:0.00001, loss_test:0.01372, lr:4.62e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.817, tt:2355.542\n",
      "Ep:79, loss:0.00001, loss_test:0.01372, lr:4.57e-02, fs:0.79787 (r=0.758,p=0.843),  time:29.825, tt:2386.022\n",
      "Ep:80, loss:0.00001, loss_test:0.01374, lr:4.53e-02, fs:0.80645 (r=0.758,p=0.862),  time:29.838, tt:2416.884\n",
      "Ep:81, loss:0.00001, loss_test:0.01374, lr:4.48e-02, fs:0.81081 (r=0.758,p=0.872),  time:29.852, tt:2447.875\n",
      "Ep:82, loss:0.00001, loss_test:0.01376, lr:4.44e-02, fs:0.80435 (r=0.747,p=0.871),  time:29.847, tt:2477.278\n",
      "Ep:83, loss:0.00001, loss_test:0.01376, lr:4.39e-02, fs:0.80435 (r=0.747,p=0.871),  time:29.852, tt:2507.530\n",
      "Ep:84, loss:0.00001, loss_test:0.01377, lr:4.35e-02, fs:0.80435 (r=0.747,p=0.871),  time:29.860, tt:2538.110\n",
      "Ep:85, loss:0.00001, loss_test:0.01378, lr:4.31e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.879, tt:2569.621\n",
      "Ep:86, loss:0.00001, loss_test:0.01379, lr:4.26e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.895, tt:2600.861\n",
      "Ep:87, loss:0.00001, loss_test:0.01380, lr:4.22e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.899, tt:2631.136\n",
      "Ep:88, loss:0.00001, loss_test:0.01381, lr:4.18e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.904, tt:2661.458\n",
      "Ep:89, loss:0.00001, loss_test:0.01381, lr:4.14e-02, fs:0.79558 (r=0.727,p=0.878),  time:29.894, tt:2690.457\n",
      "Ep:90, loss:0.00001, loss_test:0.01382, lr:4.10e-02, fs:0.79558 (r=0.727,p=0.878),  time:29.899, tt:2720.804\n",
      "Ep:91, loss:0.00001, loss_test:0.01383, lr:4.05e-02, fs:0.79558 (r=0.727,p=0.878),  time:29.910, tt:2751.676\n",
      "Ep:92, loss:0.00001, loss_test:0.01384, lr:4.01e-02, fs:0.79558 (r=0.727,p=0.878),  time:29.929, tt:2783.393\n",
      "Ep:93, loss:0.00001, loss_test:0.01385, lr:3.97e-02, fs:0.79558 (r=0.727,p=0.878),  time:29.949, tt:2815.167\n",
      "Ep:94, loss:0.00001, loss_test:0.01387, lr:3.93e-02, fs:0.80447 (r=0.727,p=0.900),  time:29.952, tt:2845.482\n",
      "Ep:95, loss:0.00001, loss_test:0.01389, lr:3.89e-02, fs:0.79775 (r=0.717,p=0.899),  time:29.966, tt:2876.774\n",
      "Ep:96, loss:0.00001, loss_test:0.01389, lr:3.86e-02, fs:0.79775 (r=0.717,p=0.899),  time:29.968, tt:2906.904\n",
      "Ep:97, loss:0.00001, loss_test:0.01390, lr:3.82e-02, fs:0.79775 (r=0.717,p=0.899),  time:29.971, tt:2937.135\n",
      "Ep:98, loss:0.00001, loss_test:0.01392, lr:3.78e-02, fs:0.79775 (r=0.717,p=0.899),  time:29.979, tt:2967.966\n",
      "Ep:99, loss:0.00001, loss_test:0.01393, lr:3.74e-02, fs:0.79096 (r=0.707,p=0.897),  time:29.989, tt:2998.925\n",
      "Ep:100, loss:0.00001, loss_test:0.01395, lr:3.70e-02, fs:0.79096 (r=0.707,p=0.897),  time:29.989, tt:3028.927\n",
      "Ep:101, loss:0.00001, loss_test:0.01397, lr:3.67e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.002, tt:3060.254\n",
      "Ep:102, loss:0.00001, loss_test:0.01398, lr:3.63e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.008, tt:3090.849\n",
      "Ep:103, loss:0.00001, loss_test:0.01399, lr:3.59e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.001, tt:3120.088\n",
      "Ep:104, loss:0.00001, loss_test:0.01401, lr:3.56e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.008, tt:3150.818\n",
      "Ep:105, loss:0.00001, loss_test:0.01401, lr:3.52e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.016, tt:3181.729\n",
      "Ep:106, loss:0.00001, loss_test:0.01402, lr:3.49e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.033, tt:3213.576\n",
      "Ep:107, loss:0.00001, loss_test:0.01404, lr:3.45e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.021, tt:3242.248\n",
      "Ep:108, loss:0.00001, loss_test:0.01405, lr:3.42e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.027, tt:3272.928\n",
      "Ep:109, loss:0.00001, loss_test:0.01406, lr:3.38e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.015, tt:3301.698\n",
      "Ep:110, loss:0.00001, loss_test:0.01408, lr:3.35e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.022, tt:3332.473\n",
      "Ep:111, loss:0.00001, loss_test:0.01409, lr:3.32e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.036, tt:3364.085\n",
      "Ep:112, loss:0.00001, loss_test:0.01411, lr:3.28e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.028, tt:3393.141\n",
      "Ep:113, loss:0.00001, loss_test:0.01412, lr:3.25e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.029, tt:3423.335\n",
      "Ep:114, loss:0.00001, loss_test:0.01414, lr:3.22e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.035, tt:3454.050\n",
      "Ep:115, loss:0.00001, loss_test:0.01416, lr:3.19e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.037, tt:3484.312\n",
      "Ep:116, loss:0.00001, loss_test:0.01417, lr:3.15e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.025, tt:3512.923\n",
      "Ep:117, loss:0.00001, loss_test:0.01418, lr:3.12e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.023, tt:3542.743\n",
      "Ep:118, loss:0.00001, loss_test:0.01418, lr:3.09e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.032, tt:3573.863\n",
      "Ep:119, loss:0.00001, loss_test:0.01420, lr:3.06e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.031, tt:3603.666\n",
      "Ep:120, loss:0.00001, loss_test:0.01422, lr:3.03e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.033, tt:3633.976\n",
      "Ep:121, loss:0.00001, loss_test:0.01423, lr:3.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:30.037, tt:3664.483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00001, loss_test:0.01424, lr:2.97e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.055, tt:3696.766\n",
      "Ep:123, loss:0.00001, loss_test:0.01425, lr:2.94e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.052, tt:3726.415\n",
      "Ep:124, loss:0.00001, loss_test:0.01427, lr:2.91e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.056, tt:3757.021\n",
      "Ep:125, loss:0.00001, loss_test:0.01429, lr:2.88e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.053, tt:3786.720\n",
      "Ep:126, loss:0.00001, loss_test:0.01430, lr:2.85e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.051, tt:3816.420\n",
      "Ep:127, loss:0.00001, loss_test:0.01431, lr:2.82e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.044, tt:3845.622\n",
      "Ep:128, loss:0.00001, loss_test:0.01432, lr:2.80e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.050, tt:3876.473\n",
      "Ep:129, loss:0.00001, loss_test:0.01433, lr:2.77e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.057, tt:3907.384\n",
      "Ep:130, loss:0.00001, loss_test:0.01434, lr:2.74e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.057, tt:3937.403\n",
      "Ep:131, loss:0.00001, loss_test:0.01437, lr:2.71e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.056, tt:3967.407\n",
      "Ep:132, loss:0.00001, loss_test:0.01438, lr:2.69e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.054, tt:3997.237\n",
      "Ep:133, loss:0.00001, loss_test:0.01439, lr:2.66e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.049, tt:4026.572\n",
      "Ep:134, loss:0.00001, loss_test:0.01440, lr:2.63e-02, fs:0.75294 (r=0.646,p=0.901),  time:30.052, tt:4056.963\n",
      "Ep:135, loss:0.00001, loss_test:0.01441, lr:2.61e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.048, tt:4086.483\n",
      "Ep:136, loss:0.00001, loss_test:0.01443, lr:2.58e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.041, tt:4115.673\n",
      "Ep:137, loss:0.00001, loss_test:0.01444, lr:2.55e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.046, tt:4146.396\n",
      "Ep:138, loss:0.00001, loss_test:0.01446, lr:2.53e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.050, tt:4176.927\n",
      "Ep:139, loss:0.00001, loss_test:0.01447, lr:2.50e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.041, tt:4205.720\n",
      "Ep:140, loss:0.00001, loss_test:0.01449, lr:2.48e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.042, tt:4235.982\n",
      "Ep:141, loss:0.00001, loss_test:0.01450, lr:2.45e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.032, tt:4264.508\n",
      "Ep:142, loss:0.00001, loss_test:0.01451, lr:2.43e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.038, tt:4295.455\n",
      "Ep:143, loss:0.00001, loss_test:0.01452, lr:2.40e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.048, tt:4326.899\n",
      "Ep:144, loss:0.00001, loss_test:0.01453, lr:2.38e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.067, tt:4359.723\n",
      "Ep:145, loss:0.00001, loss_test:0.01454, lr:2.36e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.072, tt:4390.581\n",
      "Ep:146, loss:0.00001, loss_test:0.01455, lr:2.33e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.069, tt:4420.148\n",
      "Ep:147, loss:0.00001, loss_test:0.01457, lr:2.31e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.079, tt:4451.676\n",
      "Ep:148, loss:0.00001, loss_test:0.01458, lr:2.29e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.082, tt:4482.209\n",
      "Ep:149, loss:0.00001, loss_test:0.01459, lr:2.26e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.083, tt:4512.512\n",
      "Ep:150, loss:0.00001, loss_test:0.01459, lr:2.24e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.101, tt:4545.199\n",
      "Ep:151, loss:0.00001, loss_test:0.01461, lr:2.22e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.101, tt:4575.417\n",
      "Ep:152, loss:0.00001, loss_test:0.01462, lr:2.20e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.105, tt:4606.120\n",
      "Ep:153, loss:0.00001, loss_test:0.01463, lr:2.17e-02, fs:0.74556 (r=0.636,p=0.900),  time:30.108, tt:4636.560\n",
      "Ep:154, loss:0.00001, loss_test:0.01464, lr:2.15e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.100, tt:4665.535\n",
      "Ep:155, loss:0.00001, loss_test:0.01466, lr:2.13e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.099, tt:4695.409\n",
      "Ep:156, loss:0.00001, loss_test:0.01467, lr:2.11e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.106, tt:4726.684\n",
      "Ep:157, loss:0.00001, loss_test:0.01468, lr:2.09e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.100, tt:4755.770\n",
      "Ep:158, loss:0.00001, loss_test:0.01469, lr:2.07e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.101, tt:4786.081\n",
      "Ep:159, loss:0.00001, loss_test:0.01470, lr:2.05e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.110, tt:4817.652\n",
      "Ep:160, loss:0.00001, loss_test:0.01472, lr:2.03e-02, fs:0.75000 (r=0.636,p=0.913),  time:30.106, tt:4847.142\n",
      "Ep:161, loss:0.00001, loss_test:0.01474, lr:2.01e-02, fs:0.74251 (r=0.626,p=0.912),  time:30.100, tt:4876.129\n",
      "Ep:162, loss:0.00001, loss_test:0.01475, lr:1.99e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.109, tt:4907.728\n",
      "Ep:163, loss:0.00001, loss_test:0.01476, lr:1.97e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.110, tt:4938.079\n",
      "Ep:164, loss:0.00001, loss_test:0.01476, lr:1.95e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.112, tt:4968.486\n",
      "Ep:165, loss:0.00001, loss_test:0.01478, lr:1.93e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.121, tt:5000.093\n",
      "Ep:166, loss:0.00001, loss_test:0.01478, lr:1.91e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.135, tt:5032.520\n",
      "Ep:167, loss:0.00001, loss_test:0.01479, lr:1.89e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.137, tt:5063.067\n",
      "Ep:168, loss:0.00001, loss_test:0.01480, lr:1.87e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.148, tt:5094.927\n",
      "Ep:169, loss:0.00001, loss_test:0.01480, lr:1.85e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.148, tt:5125.204\n",
      "Ep:170, loss:0.00001, loss_test:0.01481, lr:1.83e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.146, tt:5155.000\n",
      "Ep:171, loss:0.00001, loss_test:0.01482, lr:1.81e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.143, tt:5184.571\n",
      "Ep:172, loss:0.00001, loss_test:0.01483, lr:1.80e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.148, tt:5215.558\n",
      "Ep:173, loss:0.00001, loss_test:0.01485, lr:1.78e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.142, tt:5244.660\n",
      "Ep:174, loss:0.00001, loss_test:0.01486, lr:1.76e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.140, tt:5274.451\n",
      "Ep:175, loss:0.00001, loss_test:0.01486, lr:1.74e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.134, tt:5303.665\n",
      "Ep:176, loss:0.00001, loss_test:0.01487, lr:1.73e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.135, tt:5333.848\n",
      "Ep:177, loss:0.00000, loss_test:0.01488, lr:1.71e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.135, tt:5363.948\n",
      "Ep:178, loss:0.00000, loss_test:0.01489, lr:1.69e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.131, tt:5393.516\n",
      "Ep:179, loss:0.00000, loss_test:0.01490, lr:1.67e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.123, tt:5422.187\n",
      "Ep:180, loss:0.00000, loss_test:0.01491, lr:1.66e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.122, tt:5451.998\n",
      "Ep:181, loss:0.00000, loss_test:0.01491, lr:1.64e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.109, tt:5479.917\n",
      "Ep:182, loss:0.00000, loss_test:0.01492, lr:1.62e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.129, tt:5513.572\n",
      "Ep:183, loss:0.00000, loss_test:0.01492, lr:1.61e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.129, tt:5543.670\n",
      "Ep:184, loss:0.00000, loss_test:0.01494, lr:1.59e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.127, tt:5573.447\n",
      "Ep:185, loss:0.00000, loss_test:0.01495, lr:1.58e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.124, tt:5603.094\n",
      "Ep:186, loss:0.00000, loss_test:0.01495, lr:1.56e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.121, tt:5632.642\n",
      "Ep:187, loss:0.00000, loss_test:0.01496, lr:1.54e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.120, tt:5662.563\n",
      "Ep:188, loss:0.00000, loss_test:0.01497, lr:1.53e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.119, tt:5692.504\n",
      "Ep:189, loss:0.00000, loss_test:0.01498, lr:1.51e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.116, tt:5722.123\n",
      "Ep:190, loss:0.00000, loss_test:0.01498, lr:1.50e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.121, tt:5753.046\n",
      "Ep:191, loss:0.00000, loss_test:0.01499, lr:1.48e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.120, tt:5783.076\n",
      "Ep:192, loss:0.00000, loss_test:0.01500, lr:1.47e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.116, tt:5812.351\n",
      "Ep:193, loss:0.00000, loss_test:0.01500, lr:1.45e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.120, tt:5843.235\n",
      "Ep:194, loss:0.00000, loss_test:0.01501, lr:1.44e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.125, tt:5874.432\n",
      "Ep:195, loss:0.00000, loss_test:0.01502, lr:1.43e-02, fs:0.72393 (r=0.596,p=0.922),  time:30.128, tt:5905.145\n",
      "Ep:196, loss:0.00000, loss_test:0.01502, lr:1.41e-02, fs:0.72393 (r=0.596,p=0.922),  time:30.128, tt:5935.177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.01503, lr:1.40e-02, fs:0.72840 (r=0.596,p=0.937),  time:30.124, tt:5964.495\n",
      "Ep:198, loss:0.00000, loss_test:0.01504, lr:1.38e-02, fs:0.72840 (r=0.596,p=0.937),  time:30.127, tt:5995.323\n",
      "Ep:199, loss:0.00000, loss_test:0.01505, lr:1.37e-02, fs:0.72840 (r=0.596,p=0.937),  time:30.123, tt:6024.543\n",
      "Ep:200, loss:0.00000, loss_test:0.01506, lr:1.36e-02, fs:0.72840 (r=0.596,p=0.937),  time:30.126, tt:6055.261\n",
      "Ep:201, loss:0.00000, loss_test:0.01507, lr:1.34e-02, fs:0.72840 (r=0.596,p=0.937),  time:30.130, tt:6086.229\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13718, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.637, tt:23.637\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13511, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:25.975, tt:51.949\n",
      "Ep:2, loss:0.00027, loss_test:0.13168, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:27.680, tt:83.041\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12688, lr:1.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:28.917, tt:115.666\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12145, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:29.074, tt:145.368\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11752, lr:1.00e-02, fs:0.65728 (r=0.707,p=0.614),  time:29.417, tt:176.502\n",
      "Ep:6, loss:0.00024, loss_test:0.11621, lr:1.00e-02, fs:0.62295 (r=0.576,p=0.679),  time:29.936, tt:209.554\n",
      "Ep:7, loss:0.00023, loss_test:0.11519, lr:1.00e-02, fs:0.61878 (r=0.566,p=0.683),  time:30.248, tt:241.988\n",
      "Ep:8, loss:0.00022, loss_test:0.11326, lr:1.00e-02, fs:0.65686 (r=0.677,p=0.638),  time:30.009, tt:270.079\n",
      "Ep:9, loss:0.00022, loss_test:0.11151, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:30.123, tt:301.233\n",
      "Ep:10, loss:0.00021, loss_test:0.10953, lr:1.00e-02, fs:0.64615 (r=0.636,p=0.656),  time:30.280, tt:333.081\n",
      "Ep:11, loss:0.00020, loss_test:0.10880, lr:1.00e-02, fs:0.65591 (r=0.616,p=0.701),  time:30.412, tt:364.948\n",
      "Ep:12, loss:0.00020, loss_test:0.10664, lr:1.00e-02, fs:0.67021 (r=0.636,p=0.708),  time:30.426, tt:395.543\n",
      "Ep:13, loss:0.00019, loss_test:0.10476, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:30.553, tt:427.742\n",
      "Ep:14, loss:0.00019, loss_test:0.10302, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:30.600, tt:459.001\n",
      "Ep:15, loss:0.00018, loss_test:0.10142, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:30.706, tt:491.293\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09956, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:30.799, tt:523.580\n",
      "Ep:17, loss:0.00017, loss_test:0.09784, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.934, tt:556.815\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09632, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:30.873, tt:586.592\n",
      "Ep:19, loss:0.00016, loss_test:0.09480, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:30.929, tt:618.587\n",
      "Ep:20, loss:0.00015, loss_test:0.09320, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:30.904, tt:648.990\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09185, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:30.964, tt:681.207\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.09054, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:31.011, tt:713.248\n",
      "Ep:23, loss:0.00014, loss_test:0.08888, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:31.063, tt:745.519\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08733, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:31.036, tt:775.903\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08619, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:31.025, tt:806.650\n",
      "Ep:26, loss:0.00012, loss_test:0.08520, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:31.048, tt:838.306\n",
      "Ep:27, loss:0.00012, loss_test:0.08424, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.110, tt:871.074\n",
      "Ep:28, loss:0.00012, loss_test:0.08348, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:31.135, tt:902.925\n",
      "Ep:29, loss:0.00011, loss_test:0.08288, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:31.219, tt:936.579\n",
      "Ep:30, loss:0.00011, loss_test:0.08185, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:31.209, tt:967.471\n",
      "Ep:31, loss:0.00011, loss_test:0.08129, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:31.272, tt:1000.706\n",
      "Ep:32, loss:0.00010, loss_test:0.08086, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:31.266, tt:1031.779\n",
      "Ep:33, loss:0.00010, loss_test:0.07977, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:31.264, tt:1062.978\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07891, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:31.278, tt:1094.740\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.07877, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:31.306, tt:1127.001\n",
      "Ep:36, loss:0.00009, loss_test:0.07762, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:31.318, tt:1158.768\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07705, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.328, tt:1190.449\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07648, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.371, tt:1223.458\n",
      "Ep:39, loss:0.00008, loss_test:0.07586, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:31.369, tt:1254.763\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.07553, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:31.394, tt:1287.168\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.07505, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:31.422, tt:1319.732\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07469, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:31.431, tt:1351.552\n",
      "Ep:43, loss:0.00007, loss_test:0.07440, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:31.446, tt:1383.631\n",
      "Ep:44, loss:0.00007, loss_test:0.07358, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.419, tt:1413.841\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07365, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.447, tt:1446.548\n",
      "Ep:46, loss:0.00007, loss_test:0.07365, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.447, tt:1478.015\n",
      "Ep:47, loss:0.00007, loss_test:0.07350, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.426, tt:1508.450\n",
      "Ep:48, loss:0.00007, loss_test:0.07338, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.452, tt:1541.137\n",
      "Ep:49, loss:0.00006, loss_test:0.07317, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.445, tt:1572.264\n",
      "Ep:50, loss:0.00006, loss_test:0.07335, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:31.439, tt:1603.376\n",
      "Ep:51, loss:0.00006, loss_test:0.07322, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:31.459, tt:1635.879\n",
      "Ep:52, loss:0.00006, loss_test:0.07273, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:31.484, tt:1668.659\n",
      "Ep:53, loss:0.00006, loss_test:0.07319, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:31.482, tt:1700.021\n",
      "Ep:54, loss:0.00006, loss_test:0.07313, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:31.487, tt:1731.766\n",
      "Ep:55, loss:0.00005, loss_test:0.07267, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:31.500, tt:1763.977\n",
      "Ep:56, loss:0.00005, loss_test:0.07286, lr:9.90e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.466, tt:1793.582\n",
      "Ep:57, loss:0.00005, loss_test:0.07328, lr:9.80e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.484, tt:1826.098\n",
      "Ep:58, loss:0.00005, loss_test:0.07246, lr:9.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.501, tt:1858.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00005, loss_test:0.07242, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.502, tt:1890.092\n",
      "Ep:60, loss:0.00005, loss_test:0.07339, lr:9.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.495, tt:1921.219\n",
      "Ep:61, loss:0.00005, loss_test:0.07314, lr:9.41e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.532, tt:1954.971\n",
      "Ep:62, loss:0.00005, loss_test:0.07198, lr:9.32e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.524, tt:1986.005\n",
      "Ep:63, loss:0.00005, loss_test:0.07299, lr:9.23e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.537, tt:2018.388\n",
      "Ep:64, loss:0.00004, loss_test:0.07396, lr:9.14e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.549, tt:2050.670\n",
      "Ep:65, loss:0.00004, loss_test:0.07270, lr:9.04e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.552, tt:2082.429\n",
      "Ep:66, loss:0.00004, loss_test:0.07221, lr:8.95e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.537, tt:2113.005\n",
      "Ep:67, loss:0.00004, loss_test:0.07348, lr:8.86e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.542, tt:2144.852\n",
      "Ep:68, loss:0.00004, loss_test:0.07341, lr:8.78e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.565, tt:2177.956\n",
      "Ep:69, loss:0.00004, loss_test:0.07183, lr:8.69e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.560, tt:2209.176\n",
      "Ep:70, loss:0.00004, loss_test:0.07239, lr:8.60e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.563, tt:2240.947\n",
      "Ep:71, loss:0.00004, loss_test:0.07333, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.558, tt:2272.194\n",
      "Ep:72, loss:0.00004, loss_test:0.07285, lr:8.43e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.548, tt:2303.009\n",
      "Ep:73, loss:0.00004, loss_test:0.07200, lr:8.35e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.565, tt:2335.821\n",
      "Ep:74, loss:0.00004, loss_test:0.07221, lr:8.26e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.563, tt:2367.233\n",
      "Ep:75, loss:0.00004, loss_test:0.07285, lr:8.18e-03, fs:0.79290 (r=0.677,p=0.957),  time:31.559, tt:2398.492\n",
      "Ep:76, loss:0.00004, loss_test:0.07254, lr:8.10e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.580, tt:2431.634\n",
      "Ep:77, loss:0.00003, loss_test:0.07216, lr:8.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.575, tt:2462.819\n",
      "Ep:78, loss:0.00003, loss_test:0.07239, lr:7.94e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.579, tt:2494.734\n",
      "Ep:79, loss:0.00003, loss_test:0.07224, lr:7.86e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.583, tt:2526.657\n",
      "Ep:80, loss:0.00003, loss_test:0.07204, lr:7.78e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.597, tt:2559.396\n",
      "Ep:81, loss:0.00003, loss_test:0.07211, lr:7.70e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.610, tt:2591.987\n",
      "Ep:82, loss:0.00003, loss_test:0.07234, lr:7.62e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.600, tt:2622.813\n",
      "Ep:83, loss:0.00003, loss_test:0.07212, lr:7.55e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.609, tt:2655.189\n",
      "Ep:84, loss:0.00003, loss_test:0.07186, lr:7.47e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.572, tt:2683.648\n",
      "Ep:85, loss:0.00003, loss_test:0.07208, lr:7.40e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.575, tt:2715.488\n",
      "Ep:86, loss:0.00003, loss_test:0.07243, lr:7.32e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.585, tt:2747.911\n",
      "Ep:87, loss:0.00003, loss_test:0.07197, lr:7.25e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.596, tt:2780.489\n",
      "Ep:88, loss:0.00003, loss_test:0.07161, lr:7.18e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.601, tt:2812.452\n",
      "Ep:89, loss:0.00003, loss_test:0.07221, lr:7.11e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.610, tt:2844.904\n",
      "Ep:90, loss:0.00003, loss_test:0.07222, lr:7.03e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.606, tt:2876.116\n",
      "Ep:91, loss:0.00003, loss_test:0.07151, lr:6.96e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.606, tt:2907.774\n",
      "Ep:92, loss:0.00003, loss_test:0.07186, lr:6.89e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.614, tt:2940.113\n",
      "Ep:93, loss:0.00003, loss_test:0.07239, lr:6.83e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.625, tt:2972.708\n",
      "Ep:94, loss:0.00003, loss_test:0.07188, lr:6.76e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.621, tt:3004.019\n",
      "Ep:95, loss:0.00003, loss_test:0.07150, lr:6.69e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.616, tt:3035.162\n",
      "Ep:96, loss:0.00003, loss_test:0.07232, lr:6.62e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.619, tt:3067.025\n",
      "Ep:97, loss:0.00003, loss_test:0.07224, lr:6.56e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.617, tt:3098.512\n",
      "Ep:98, loss:0.00003, loss_test:0.07150, lr:6.49e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.606, tt:3128.955\n",
      "Ep:99, loss:0.00003, loss_test:0.07214, lr:6.43e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.615, tt:3161.532\n",
      "Ep:100, loss:0.00003, loss_test:0.07242, lr:6.36e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.626, tt:3194.176\n",
      "Ep:101, loss:0.00003, loss_test:0.07206, lr:6.30e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.627, tt:3225.956\n",
      "Ep:102, loss:0.00002, loss_test:0.07154, lr:6.24e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.634, tt:3258.331\n",
      "Ep:103, loss:0.00002, loss_test:0.07194, lr:6.17e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.632, tt:3289.754\n",
      "Ep:104, loss:0.00002, loss_test:0.07198, lr:6.11e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.639, tt:3322.107\n",
      "Ep:105, loss:0.00002, loss_test:0.07198, lr:6.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.642, tt:3354.071\n",
      "Ep:106, loss:0.00002, loss_test:0.07206, lr:5.99e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.644, tt:3385.922\n",
      "Ep:107, loss:0.00002, loss_test:0.07202, lr:5.93e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.640, tt:3417.173\n",
      "Ep:108, loss:0.00002, loss_test:0.07207, lr:5.87e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.638, tt:3448.528\n",
      "Ep:109, loss:0.00002, loss_test:0.07200, lr:5.81e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.643, tt:3480.756\n",
      "Ep:110, loss:0.00002, loss_test:0.07229, lr:5.75e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.647, tt:3512.766\n",
      "Ep:111, loss:0.00002, loss_test:0.07216, lr:5.70e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.644, tt:3544.169\n",
      "Ep:112, loss:0.00002, loss_test:0.07214, lr:5.64e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.643, tt:3575.656\n",
      "Ep:113, loss:0.00002, loss_test:0.07244, lr:5.58e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.647, tt:3607.716\n",
      "Ep:114, loss:0.00002, loss_test:0.07211, lr:5.53e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.649, tt:3639.687\n",
      "Ep:115, loss:0.00002, loss_test:0.07227, lr:5.47e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.653, tt:3671.754\n",
      "Ep:116, loss:0.00002, loss_test:0.07257, lr:5.42e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.663, tt:3704.610\n",
      "Ep:117, loss:0.00002, loss_test:0.07244, lr:5.36e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.666, tt:3736.550\n",
      "Ep:118, loss:0.00002, loss_test:0.07215, lr:5.31e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.663, tt:3767.851\n",
      "Ep:119, loss:0.00002, loss_test:0.07263, lr:5.26e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.665, tt:3799.855\n",
      "Ep:120, loss:0.00002, loss_test:0.07285, lr:5.20e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.670, tt:3832.021\n",
      "Ep:121, loss:0.00002, loss_test:0.07268, lr:5.15e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.669, tt:3863.620\n",
      "Ep:122, loss:0.00002, loss_test:0.07244, lr:5.10e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.649, tt:3892.831\n",
      "Ep:123, loss:0.00002, loss_test:0.07241, lr:5.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.647, tt:3924.249\n",
      "Ep:124, loss:0.00002, loss_test:0.07265, lr:5.00e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.644, tt:3955.500\n",
      "Ep:125, loss:0.00002, loss_test:0.07289, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.644, tt:3987.175\n",
      "Ep:126, loss:0.00002, loss_test:0.07273, lr:4.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.654, tt:4019.994\n",
      "Ep:127, loss:0.00002, loss_test:0.07249, lr:4.85e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.651, tt:4051.377\n",
      "Ep:128, loss:0.00002, loss_test:0.07267, lr:4.80e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.651, tt:4082.992\n",
      "Ep:129, loss:0.00002, loss_test:0.07301, lr:4.75e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.648, tt:4114.187\n",
      "Ep:130, loss:0.00002, loss_test:0.07288, lr:4.71e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.650, tt:4146.199\n",
      "Ep:131, loss:0.00002, loss_test:0.07294, lr:4.66e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.650, tt:4177.771\n",
      "Ep:132, loss:0.00002, loss_test:0.07314, lr:4.61e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.668, tt:4211.818\n",
      "Ep:133, loss:0.00002, loss_test:0.07294, lr:4.57e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.661, tt:4242.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.07285, lr:4.52e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.664, tt:4274.580\n",
      "Ep:135, loss:0.00002, loss_test:0.07317, lr:4.48e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.667, tt:4306.651\n",
      "Ep:136, loss:0.00002, loss_test:0.07304, lr:4.43e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.666, tt:4338.198\n",
      "Ep:137, loss:0.00002, loss_test:0.07307, lr:4.39e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.663, tt:4369.494\n",
      "Ep:138, loss:0.00002, loss_test:0.07333, lr:4.34e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.663, tt:4401.097\n",
      "Ep:139, loss:0.00002, loss_test:0.07339, lr:4.30e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.651, tt:4431.160\n",
      "Ep:140, loss:0.00002, loss_test:0.07331, lr:4.26e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.647, tt:4462.183\n",
      "Ep:141, loss:0.00002, loss_test:0.07323, lr:4.21e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.645, tt:4493.649\n",
      "Ep:142, loss:0.00002, loss_test:0.07333, lr:4.17e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.649, tt:4525.792\n",
      "Ep:143, loss:0.00002, loss_test:0.07337, lr:4.13e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.633, tt:4555.219\n",
      "Ep:144, loss:0.00002, loss_test:0.07338, lr:4.09e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.631, tt:4586.559\n",
      "Ep:145, loss:0.00002, loss_test:0.07342, lr:4.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.627, tt:4617.474\n",
      "Ep:146, loss:0.00002, loss_test:0.07338, lr:4.01e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.616, tt:4647.539\n",
      "Ep:147, loss:0.00002, loss_test:0.07360, lr:3.97e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.618, tt:4679.506\n",
      "Ep:148, loss:0.00002, loss_test:0.07363, lr:3.93e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.614, tt:4710.458\n",
      "Ep:149, loss:0.00002, loss_test:0.07351, lr:3.89e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.607, tt:4741.089\n",
      "Ep:150, loss:0.00002, loss_test:0.07372, lr:3.85e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.601, tt:4771.768\n",
      "Ep:151, loss:0.00002, loss_test:0.07381, lr:3.81e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.588, tt:4801.387\n",
      "Ep:152, loss:0.00002, loss_test:0.07374, lr:3.77e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.591, tt:4833.410\n",
      "Ep:153, loss:0.00002, loss_test:0.07384, lr:3.73e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.613, tt:4868.341\n",
      "Ep:154, loss:0.00002, loss_test:0.07400, lr:3.70e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.617, tt:4900.580\n",
      "Ep:155, loss:0.00002, loss_test:0.07391, lr:3.66e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.624, tt:4933.291\n",
      "Ep:156, loss:0.00002, loss_test:0.07382, lr:3.62e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.620, tt:4964.377\n",
      "Ep:157, loss:0.00002, loss_test:0.07404, lr:3.59e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.622, tt:4996.257\n",
      "Ep:158, loss:0.00002, loss_test:0.07412, lr:3.55e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.624, tt:5028.265\n",
      "Ep:159, loss:0.00002, loss_test:0.07435, lr:3.52e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.623, tt:5059.669\n",
      "Ep:160, loss:0.00002, loss_test:0.07426, lr:3.48e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.631, tt:5092.561\n",
      "Ep:161, loss:0.00002, loss_test:0.07403, lr:3.45e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.625, tt:5123.323\n",
      "Ep:162, loss:0.00002, loss_test:0.07426, lr:3.41e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.628, tt:5155.362\n",
      "Ep:163, loss:0.00002, loss_test:0.07459, lr:3.38e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.625, tt:5186.545\n",
      "Ep:164, loss:0.00002, loss_test:0.07449, lr:3.34e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.622, tt:5217.664\n",
      "Ep:165, loss:0.00002, loss_test:0.07419, lr:3.31e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.625, tt:5249.782\n",
      "Ep:166, loss:0.00002, loss_test:0.07415, lr:3.28e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.621, tt:5280.789\n",
      "Ep:167, loss:0.00002, loss_test:0.07457, lr:3.24e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.626, tt:5313.155\n",
      "Ep:168, loss:0.00002, loss_test:0.07481, lr:3.21e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.630, tt:5345.480\n",
      "Ep:169, loss:0.00002, loss_test:0.07459, lr:3.18e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.628, tt:5376.756\n",
      "Ep:170, loss:0.00002, loss_test:0.07429, lr:3.15e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.621, tt:5407.156\n",
      "Ep:171, loss:0.00002, loss_test:0.07453, lr:3.12e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.622, tt:5438.972\n",
      "Ep:172, loss:0.00001, loss_test:0.07467, lr:3.09e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.630, tt:5471.927\n",
      "Ep:173, loss:0.00001, loss_test:0.07465, lr:3.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.633, tt:5504.087\n",
      "Ep:174, loss:0.00001, loss_test:0.07459, lr:3.02e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.626, tt:5534.636\n",
      "Ep:175, loss:0.00001, loss_test:0.07448, lr:2.99e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.637, tt:5568.051\n",
      "Ep:176, loss:0.00001, loss_test:0.07466, lr:2.96e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.640, tt:5600.217\n",
      "Ep:177, loss:0.00001, loss_test:0.07493, lr:2.93e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.635, tt:5631.081\n",
      "Ep:178, loss:0.00001, loss_test:0.07493, lr:2.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.641, tt:5663.776\n",
      "Ep:179, loss:0.00001, loss_test:0.07470, lr:2.88e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.652, tt:5697.420\n",
      "Ep:180, loss:0.00001, loss_test:0.07479, lr:2.85e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.654, tt:5729.346\n",
      "Ep:181, loss:0.00001, loss_test:0.07483, lr:2.82e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.649, tt:5760.185\n",
      "Ep:182, loss:0.00001, loss_test:0.07497, lr:2.79e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.658, tt:5793.369\n",
      "Ep:183, loss:0.00001, loss_test:0.07510, lr:2.76e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.657, tt:5824.872\n",
      "Ep:184, loss:0.00001, loss_test:0.07482, lr:2.73e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.658, tt:5856.643\n",
      "Ep:185, loss:0.00001, loss_test:0.07502, lr:2.71e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.659, tt:5888.482\n",
      "Ep:186, loss:0.00001, loss_test:0.07516, lr:2.68e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.660, tt:5920.453\n",
      "Ep:187, loss:0.00001, loss_test:0.07521, lr:2.65e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.666, tt:5953.247\n",
      "Ep:188, loss:0.00001, loss_test:0.07500, lr:2.63e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.666, tt:5984.866\n",
      "Ep:189, loss:0.00001, loss_test:0.07516, lr:2.60e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.664, tt:6016.209\n",
      "Ep:190, loss:0.00001, loss_test:0.07532, lr:2.57e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.653, tt:6045.672\n",
      "Ep:191, loss:0.00001, loss_test:0.07523, lr:2.55e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.652, tt:6077.119\n",
      "Ep:192, loss:0.00001, loss_test:0.07526, lr:2.52e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.643, tt:6107.166\n",
      "Ep:193, loss:0.00001, loss_test:0.07535, lr:2.50e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.645, tt:6139.040\n",
      "Ep:194, loss:0.00001, loss_test:0.07532, lr:2.47e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.647, tt:6171.078\n",
      "Ep:195, loss:0.00001, loss_test:0.07544, lr:2.45e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.655, tt:6204.457\n",
      "Ep:196, loss:0.00001, loss_test:0.07538, lr:2.42e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.661, tt:6237.124\n",
      "Ep:197, loss:0.00001, loss_test:0.07552, lr:2.40e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.665, tt:6269.640\n",
      "Ep:198, loss:0.00001, loss_test:0.07561, lr:2.38e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.663, tt:6301.032\n",
      "Ep:199, loss:0.00001, loss_test:0.07548, lr:2.35e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.666, tt:6333.194\n",
      "Ep:200, loss:0.00001, loss_test:0.07551, lr:2.33e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.656, tt:6362.889\n",
      "Ep:201, loss:0.00001, loss_test:0.07561, lr:2.31e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.650, tt:6393.359\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.01991, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:20.466, tt:20.466\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02401, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.831, tt:41.663\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02662, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.892, tt:62.675\n",
      "Ep:3, loss:0.00005, loss_test:0.02743, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.181, tt:84.726\n",
      "Ep:4, loss:0.00005, loss_test:0.02748, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.979, tt:104.893\n",
      "Ep:5, loss:0.00005, loss_test:0.02686, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.375, tt:128.252\n",
      "Ep:6, loss:0.00005, loss_test:0.02578, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.660, tt:151.620\n",
      "Ep:7, loss:0.00005, loss_test:0.02443, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.187, tt:177.494\n",
      "Ep:8, loss:0.00005, loss_test:0.02297, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:22.653, tt:203.874\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02172, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:22.845, tt:228.452\n",
      "Ep:10, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:22.888, tt:251.763\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:22.965, tt:275.581\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02026, lr:6.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:23.029, tt:299.375\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01950, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:23.179, tt:324.508\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01886, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:23.304, tt:349.554\n",
      "Ep:15, loss:0.00004, loss_test:0.01846, lr:6.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:23.477, tt:375.629\n",
      "Ep:16, loss:0.00004, loss_test:0.01816, lr:6.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:23.639, tt:401.856\n",
      "Ep:17, loss:0.00004, loss_test:0.01789, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:23.772, tt:427.898\n",
      "Ep:18, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:23.805, tt:452.293\n",
      "Ep:19, loss:0.00004, loss_test:0.01745, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:23.875, tt:477.505\n",
      "Ep:20, loss:0.00004, loss_test:0.01725, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:24.014, tt:504.292\n",
      "Ep:21, loss:0.00003, loss_test:0.01707, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:24.058, tt:529.272\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01690, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:24.091, tt:554.103\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01675, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:24.158, tt:579.796\n",
      "Ep:24, loss:0.00003, loss_test:0.01660, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:24.218, tt:605.450\n",
      "Ep:25, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:24.240, tt:630.250\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:24.264, tt:655.132\n",
      "Ep:27, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:24.332, tt:681.304\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:24.417, tt:708.081\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01573, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:24.490, tt:734.711\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01551, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:24.515, tt:759.952\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01529, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:24.519, tt:784.618\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01509, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:24.554, tt:810.269\n",
      "Ep:33, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:24.583, tt:835.832\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01482, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:24.628, tt:861.988\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01472, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:24.673, tt:888.217\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:24.673, tt:912.885\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:24.714, tt:939.150\n",
      "Ep:38, loss:0.00002, loss_test:0.01451, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:24.758, tt:965.566\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:24.761, tt:990.427\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01432, lr:6.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:24.802, tt:1016.903\n",
      "Ep:41, loss:0.00002, loss_test:0.01420, lr:6.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:24.812, tt:1042.084\n",
      "Ep:42, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:24.824, tt:1067.435\n",
      "Ep:43, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:24.851, tt:1093.434\n",
      "Ep:44, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:24.889, tt:1119.994\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:24.928, tt:1146.708\n",
      "Ep:46, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:24.958, tt:1173.021\n",
      "Ep:47, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:24.986, tt:1199.352\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01359, lr:6.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:25.019, tt:1225.909\n",
      "Ep:49, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:25.021, tt:1251.038\n",
      "Ep:50, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:25.015, tt:1275.769\n",
      "Ep:51, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:25.031, tt:1301.601\n",
      "Ep:52, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.049, tt:1327.573\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:25.078, tt:1354.238\n",
      "Ep:54, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:25.096, tt:1380.272\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:25.151, tt:1408.439\n",
      "Ep:56, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.145, tt:1433.285\n",
      "Ep:57, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:25.157, tt:1459.115\n",
      "Ep:58, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:25.170, tt:1485.014\n",
      "Ep:59, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:25.201, tt:1512.040\n",
      "Ep:60, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:25.220, tt:1538.399\n",
      "Ep:61, loss:0.00002, loss_test:0.01314, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:25.232, tt:1564.377\n",
      "Ep:62, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:25.244, tt:1590.400\n",
      "Ep:63, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:25.220, tt:1614.060\n",
      "Ep:64, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:25.226, tt:1639.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:25.220, tt:1664.488\n",
      "Ep:66, loss:0.00001, loss_test:0.01313, lr:5.94e-02, fs:0.83092 (r=0.869,p=0.796),  time:25.221, tt:1689.800\n",
      "Ep:67, loss:0.00001, loss_test:0.01311, lr:5.88e-02, fs:0.82524 (r=0.859,p=0.794),  time:25.215, tt:1714.648\n",
      "Ep:68, loss:0.00001, loss_test:0.01310, lr:5.82e-02, fs:0.83092 (r=0.869,p=0.796),  time:25.225, tt:1740.523\n",
      "Ep:69, loss:0.00001, loss_test:0.01310, lr:5.76e-02, fs:0.82524 (r=0.859,p=0.794),  time:25.232, tt:1766.224\n",
      "Ep:70, loss:0.00001, loss_test:0.01310, lr:5.71e-02, fs:0.82524 (r=0.859,p=0.794),  time:25.224, tt:1790.896\n",
      "Ep:71, loss:0.00001, loss_test:0.01309, lr:5.65e-02, fs:0.83092 (r=0.869,p=0.796),  time:25.230, tt:1816.580\n",
      "Ep:72, loss:0.00001, loss_test:0.01313, lr:5.59e-02, fs:0.81951 (r=0.848,p=0.792),  time:25.237, tt:1842.297\n",
      "Ep:73, loss:0.00001, loss_test:0.01312, lr:5.54e-02, fs:0.81951 (r=0.848,p=0.792),  time:25.231, tt:1867.120\n",
      "Ep:74, loss:0.00001, loss_test:0.01313, lr:5.48e-02, fs:0.81951 (r=0.848,p=0.792),  time:25.227, tt:1892.051\n",
      "Ep:75, loss:0.00001, loss_test:0.01313, lr:5.43e-02, fs:0.82353 (r=0.848,p=0.800),  time:25.230, tt:1917.490\n",
      "Ep:76, loss:0.00001, loss_test:0.01314, lr:5.37e-02, fs:0.82353 (r=0.848,p=0.800),  time:25.232, tt:1942.833\n",
      "Ep:77, loss:0.00001, loss_test:0.01318, lr:5.32e-02, fs:0.82353 (r=0.848,p=0.800),  time:25.236, tt:1968.422\n",
      "Ep:78, loss:0.00001, loss_test:0.01323, lr:5.27e-02, fs:0.81773 (r=0.838,p=0.798),  time:25.249, tt:1994.675\n",
      "Ep:79, loss:0.00001, loss_test:0.01322, lr:5.21e-02, fs:0.82353 (r=0.848,p=0.800),  time:25.242, tt:2019.353\n",
      "Ep:80, loss:0.00001, loss_test:0.01321, lr:5.16e-02, fs:0.82353 (r=0.848,p=0.800),  time:25.245, tt:2044.872\n",
      "Ep:81, loss:0.00001, loss_test:0.01319, lr:5.11e-02, fs:0.82353 (r=0.848,p=0.800),  time:25.271, tt:2072.216\n",
      "Ep:82, loss:0.00001, loss_test:0.01322, lr:5.06e-02, fs:0.81951 (r=0.848,p=0.792),  time:25.267, tt:2097.172\n",
      "Ep:83, loss:0.00001, loss_test:0.01326, lr:5.01e-02, fs:0.81373 (r=0.838,p=0.790),  time:25.279, tt:2123.398\n",
      "Ep:84, loss:0.00001, loss_test:0.01328, lr:4.96e-02, fs:0.82000 (r=0.828,p=0.812),  time:25.279, tt:2148.758\n",
      "Ep:85, loss:0.00001, loss_test:0.01332, lr:4.91e-02, fs:0.82000 (r=0.828,p=0.812),  time:25.277, tt:2173.829\n",
      "Ep:86, loss:0.00001, loss_test:0.01333, lr:4.86e-02, fs:0.82178 (r=0.838,p=0.806),  time:25.293, tt:2200.478\n",
      "Ep:87, loss:0.00001, loss_test:0.01336, lr:4.81e-02, fs:0.82178 (r=0.838,p=0.806),  time:25.300, tt:2226.380\n",
      "Ep:88, loss:0.00001, loss_test:0.01336, lr:4.76e-02, fs:0.82178 (r=0.838,p=0.806),  time:25.301, tt:2251.771\n",
      "Ep:89, loss:0.00001, loss_test:0.01336, lr:4.71e-02, fs:0.82178 (r=0.838,p=0.806),  time:25.288, tt:2275.906\n",
      "Ep:90, loss:0.00001, loss_test:0.01340, lr:4.67e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.288, tt:2301.229\n",
      "Ep:91, loss:0.00001, loss_test:0.01344, lr:4.62e-02, fs:0.82178 (r=0.838,p=0.806),  time:25.283, tt:2326.001\n",
      "Ep:92, loss:0.00001, loss_test:0.01346, lr:4.57e-02, fs:0.82178 (r=0.838,p=0.806),  time:25.287, tt:2351.723\n",
      "Ep:93, loss:0.00001, loss_test:0.01347, lr:4.53e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.290, tt:2377.231\n",
      "Ep:94, loss:0.00001, loss_test:0.01350, lr:4.48e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.289, tt:2402.426\n",
      "Ep:95, loss:0.00001, loss_test:0.01354, lr:4.44e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.297, tt:2428.533\n",
      "Ep:96, loss:0.00001, loss_test:0.01354, lr:4.39e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.301, tt:2454.167\n",
      "Ep:97, loss:0.00001, loss_test:0.01357, lr:4.35e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.305, tt:2479.854\n",
      "Ep:98, loss:0.00001, loss_test:0.01361, lr:4.31e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.311, tt:2505.754\n",
      "Ep:99, loss:0.00001, loss_test:0.01365, lr:4.26e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.316, tt:2531.633\n",
      "Ep:100, loss:0.00001, loss_test:0.01365, lr:4.22e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.320, tt:2557.296\n",
      "Ep:101, loss:0.00001, loss_test:0.01367, lr:4.18e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.335, tt:2584.127\n",
      "Ep:102, loss:0.00001, loss_test:0.01370, lr:4.14e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.342, tt:2610.266\n",
      "Ep:103, loss:0.00001, loss_test:0.01373, lr:4.10e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.346, tt:2635.982\n",
      "Ep:104, loss:0.00001, loss_test:0.01376, lr:4.05e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.351, tt:2661.837\n",
      "Ep:105, loss:0.00001, loss_test:0.01376, lr:4.01e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.348, tt:2686.872\n",
      "Ep:106, loss:0.00001, loss_test:0.01376, lr:3.97e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.356, tt:2713.044\n",
      "Ep:107, loss:0.00001, loss_test:0.01380, lr:3.93e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.384, tt:2741.436\n",
      "Ep:108, loss:0.00001, loss_test:0.01385, lr:3.89e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.395, tt:2768.078\n",
      "Ep:109, loss:0.00001, loss_test:0.01389, lr:3.86e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.404, tt:2794.397\n",
      "Ep:110, loss:0.00001, loss_test:0.01391, lr:3.82e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.414, tt:2820.976\n",
      "Ep:111, loss:0.00001, loss_test:0.01393, lr:3.78e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.414, tt:2846.411\n",
      "Ep:112, loss:0.00001, loss_test:0.01395, lr:3.74e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.417, tt:2872.170\n",
      "Ep:113, loss:0.00001, loss_test:0.01399, lr:3.70e-02, fs:0.81592 (r=0.828,p=0.804),  time:25.425, tt:2898.408\n",
      "Ep:114, loss:0.00001, loss_test:0.01401, lr:3.67e-02, fs:0.82000 (r=0.828,p=0.812),  time:25.433, tt:2924.763\n",
      "Ep:115, loss:0.00001, loss_test:0.01401, lr:3.63e-02, fs:0.82412 (r=0.828,p=0.820),  time:25.436, tt:2950.558\n",
      "Ep:116, loss:0.00001, loss_test:0.01403, lr:3.59e-02, fs:0.82412 (r=0.828,p=0.820),  time:25.434, tt:2975.809\n",
      "Ep:117, loss:0.00001, loss_test:0.01407, lr:3.56e-02, fs:0.82234 (r=0.818,p=0.827),  time:25.440, tt:3001.902\n",
      "Ep:118, loss:0.00001, loss_test:0.01411, lr:3.52e-02, fs:0.81633 (r=0.808,p=0.825),  time:25.446, tt:3028.101\n",
      "Ep:119, loss:0.00001, loss_test:0.01413, lr:3.49e-02, fs:0.82653 (r=0.818,p=0.835),  time:25.435, tt:3052.164\n",
      "Ep:120, loss:0.00001, loss_test:0.01413, lr:3.45e-02, fs:0.82234 (r=0.818,p=0.827),  time:25.442, tt:3078.478\n",
      "Ep:121, loss:0.00001, loss_test:0.01417, lr:3.42e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.445, tt:3104.350\n",
      "Ep:122, loss:0.00001, loss_test:0.01419, lr:3.38e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.443, tt:3129.490\n",
      "Ep:123, loss:0.00001, loss_test:0.01420, lr:3.35e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.446, tt:3155.324\n",
      "Ep:124, loss:0.00001, loss_test:0.01422, lr:3.32e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.449, tt:3181.069\n",
      "Ep:125, loss:0.00001, loss_test:0.01425, lr:3.28e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.457, tt:3207.531\n",
      "Ep:126, loss:0.00001, loss_test:0.01429, lr:3.25e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.451, tt:3232.334\n",
      "Ep:127, loss:0.00001, loss_test:0.01433, lr:3.22e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.452, tt:3257.912\n",
      "Ep:128, loss:0.00001, loss_test:0.01434, lr:3.19e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.456, tt:3283.851\n",
      "Ep:129, loss:0.00001, loss_test:0.01436, lr:3.15e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.447, tt:3308.109\n",
      "Ep:130, loss:0.00001, loss_test:0.01439, lr:3.12e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.445, tt:3333.293\n",
      "Ep:131, loss:0.00001, loss_test:0.01440, lr:3.09e-02, fs:0.81443 (r=0.798,p=0.832),  time:25.440, tt:3358.076\n",
      "Ep:132, loss:0.00001, loss_test:0.01443, lr:3.06e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.440, tt:3383.471\n",
      "Ep:133, loss:0.00001, loss_test:0.01445, lr:3.03e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.439, tt:3408.819\n",
      "Ep:134, loss:0.00001, loss_test:0.01446, lr:3.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.430, tt:3433.110\n",
      "Ep:135, loss:0.00001, loss_test:0.01449, lr:2.97e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.434, tt:3458.984\n",
      "Ep:136, loss:0.00001, loss_test:0.01454, lr:2.94e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.436, tt:3484.778\n",
      "Ep:137, loss:0.00001, loss_test:0.01455, lr:2.91e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.436, tt:3510.237\n",
      "Ep:138, loss:0.00001, loss_test:0.01455, lr:2.88e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.433, tt:3535.168\n",
      "Ep:139, loss:0.00001, loss_test:0.01458, lr:2.85e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.432, tt:3560.459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.01461, lr:2.82e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.437, tt:3586.586\n",
      "Ep:141, loss:0.00001, loss_test:0.01464, lr:2.80e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.423, tt:3610.001\n",
      "Ep:142, loss:0.00001, loss_test:0.01466, lr:2.77e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.410, tt:3633.624\n",
      "Ep:143, loss:0.00001, loss_test:0.01468, lr:2.74e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.407, tt:3658.563\n",
      "Ep:144, loss:0.00001, loss_test:0.01470, lr:2.71e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.403, tt:3683.391\n",
      "Ep:145, loss:0.00001, loss_test:0.01471, lr:2.69e-02, fs:0.80208 (r=0.778,p=0.828),  time:25.405, tt:3709.070\n",
      "Ep:146, loss:0.00001, loss_test:0.01473, lr:2.66e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.406, tt:3734.652\n",
      "Ep:147, loss:0.00001, loss_test:0.01475, lr:2.63e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.405, tt:3759.915\n",
      "Ep:148, loss:0.00001, loss_test:0.01476, lr:2.61e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.401, tt:3784.790\n",
      "Ep:149, loss:0.00001, loss_test:0.01480, lr:2.58e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.405, tt:3810.814\n",
      "Ep:150, loss:0.00001, loss_test:0.01483, lr:2.55e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.406, tt:3836.348\n",
      "Ep:151, loss:0.00001, loss_test:0.01487, lr:2.53e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.407, tt:3861.819\n",
      "Ep:152, loss:0.00001, loss_test:0.01489, lr:2.50e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.408, tt:3887.366\n",
      "Ep:153, loss:0.00001, loss_test:0.01491, lr:2.48e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.410, tt:3913.130\n",
      "Ep:154, loss:0.00001, loss_test:0.01493, lr:2.45e-02, fs:0.78947 (r=0.758,p=0.824),  time:25.411, tt:3938.772\n",
      "Ep:155, loss:0.00001, loss_test:0.01494, lr:2.43e-02, fs:0.79365 (r=0.758,p=0.833),  time:25.420, tt:3965.559\n",
      "Ep:156, loss:0.00001, loss_test:0.01497, lr:2.40e-02, fs:0.79365 (r=0.758,p=0.833),  time:25.429, tt:3992.416\n",
      "Ep:157, loss:0.00001, loss_test:0.01499, lr:2.38e-02, fs:0.79365 (r=0.758,p=0.833),  time:25.439, tt:4019.301\n",
      "Ep:158, loss:0.00001, loss_test:0.01499, lr:2.36e-02, fs:0.79365 (r=0.758,p=0.833),  time:25.439, tt:4044.729\n",
      "Ep:159, loss:0.00001, loss_test:0.01502, lr:2.33e-02, fs:0.79365 (r=0.758,p=0.833),  time:25.439, tt:4070.174\n",
      "Ep:160, loss:0.00001, loss_test:0.01503, lr:2.31e-02, fs:0.79365 (r=0.758,p=0.833),  time:25.441, tt:4096.066\n",
      "Ep:161, loss:0.00001, loss_test:0.01505, lr:2.29e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.440, tt:4121.336\n",
      "Ep:162, loss:0.00001, loss_test:0.01506, lr:2.26e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.446, tt:4147.628\n",
      "Ep:163, loss:0.00001, loss_test:0.01509, lr:2.24e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.447, tt:4173.333\n",
      "Ep:164, loss:0.00001, loss_test:0.01512, lr:2.22e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.448, tt:4198.852\n",
      "Ep:165, loss:0.00001, loss_test:0.01513, lr:2.20e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.455, tt:4225.468\n",
      "Ep:166, loss:0.00001, loss_test:0.01514, lr:2.17e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.454, tt:4250.774\n",
      "Ep:167, loss:0.00001, loss_test:0.01517, lr:2.15e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.458, tt:4276.955\n",
      "Ep:168, loss:0.00001, loss_test:0.01519, lr:2.13e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.456, tt:4302.130\n",
      "Ep:169, loss:0.00001, loss_test:0.01520, lr:2.11e-02, fs:0.79787 (r=0.758,p=0.843),  time:25.460, tt:4328.181\n",
      "Ep:170, loss:0.00001, loss_test:0.01520, lr:2.09e-02, fs:0.79144 (r=0.747,p=0.841),  time:25.461, tt:4353.912\n",
      "Ep:171, loss:0.00001, loss_test:0.01523, lr:2.07e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.461, tt:4379.312\n",
      "Ep:172, loss:0.00001, loss_test:0.01524, lr:2.05e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.461, tt:4404.779\n",
      "Ep:173, loss:0.00001, loss_test:0.01526, lr:2.03e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.463, tt:4430.573\n",
      "Ep:174, loss:0.00001, loss_test:0.01528, lr:2.01e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.468, tt:4456.935\n",
      "Ep:175, loss:0.00001, loss_test:0.01530, lr:1.99e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.469, tt:4482.598\n",
      "Ep:176, loss:0.00001, loss_test:0.01531, lr:1.97e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.468, tt:4507.867\n",
      "Ep:177, loss:0.00001, loss_test:0.01534, lr:1.95e-02, fs:0.79570 (r=0.747,p=0.851),  time:25.467, tt:4533.062\n",
      "Ep:178, loss:0.00001, loss_test:0.01535, lr:1.93e-02, fs:0.78919 (r=0.737,p=0.849),  time:25.474, tt:4559.813\n",
      "Ep:179, loss:0.00001, loss_test:0.01537, lr:1.91e-02, fs:0.78919 (r=0.737,p=0.849),  time:25.476, tt:4585.671\n",
      "Ep:180, loss:0.00001, loss_test:0.01539, lr:1.89e-02, fs:0.78261 (r=0.727,p=0.847),  time:25.480, tt:4611.958\n",
      "Ep:181, loss:0.00001, loss_test:0.01540, lr:1.87e-02, fs:0.78919 (r=0.737,p=0.849),  time:25.482, tt:4637.657\n",
      "Ep:182, loss:0.00001, loss_test:0.01541, lr:1.85e-02, fs:0.77596 (r=0.717,p=0.845),  time:25.483, tt:4663.405\n",
      "Ep:183, loss:0.00001, loss_test:0.01542, lr:1.83e-02, fs:0.76923 (r=0.707,p=0.843),  time:25.478, tt:4687.915\n",
      "Ep:184, loss:0.00001, loss_test:0.01545, lr:1.81e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.487, tt:4715.182\n",
      "Ep:185, loss:0.00001, loss_test:0.01546, lr:1.80e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.495, tt:4742.117\n",
      "Ep:186, loss:0.00001, loss_test:0.01548, lr:1.78e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.498, tt:4768.148\n",
      "Ep:187, loss:0.00001, loss_test:0.01548, lr:1.76e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.494, tt:4792.835\n",
      "Ep:188, loss:0.00001, loss_test:0.01550, lr:1.74e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.499, tt:4819.247\n",
      "Ep:189, loss:0.00001, loss_test:0.01552, lr:1.73e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.498, tt:4844.534\n",
      "Ep:190, loss:0.00001, loss_test:0.01553, lr:1.71e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.493, tt:4869.237\n",
      "Ep:191, loss:0.00001, loss_test:0.01554, lr:1.69e-02, fs:0.76243 (r=0.697,p=0.841),  time:25.491, tt:4894.345\n",
      "Ep:192, loss:0.00001, loss_test:0.01556, lr:1.67e-02, fs:0.75556 (r=0.687,p=0.840),  time:25.492, tt:4920.035\n",
      "Ep:193, loss:0.00001, loss_test:0.01557, lr:1.66e-02, fs:0.75556 (r=0.687,p=0.840),  time:25.496, tt:4946.290\n",
      "Ep:194, loss:0.00001, loss_test:0.01559, lr:1.64e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.495, tt:4971.622\n",
      "Ep:195, loss:0.00001, loss_test:0.01561, lr:1.62e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.492, tt:4996.456\n",
      "Ep:196, loss:0.00001, loss_test:0.01563, lr:1.61e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.487, tt:5020.903\n",
      "Ep:197, loss:0.00001, loss_test:0.01563, lr:1.59e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.483, tt:5045.683\n",
      "Ep:198, loss:0.00001, loss_test:0.01564, lr:1.58e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.484, tt:5071.357\n",
      "Ep:199, loss:0.00001, loss_test:0.01566, lr:1.56e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.477, tt:5095.408\n",
      "Ep:200, loss:0.00001, loss_test:0.01568, lr:1.54e-02, fs:0.74860 (r=0.677,p=0.838),  time:25.476, tt:5120.682\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13799, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.112, tt:24.112\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13589, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:25.411, tt:50.822\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13216, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:24.147, tt:72.441\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12649, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:23.637, tt:94.546\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11973, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:23.809, tt:119.043\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11632, lr:1.00e-02, fs:0.64115 (r=0.677,p=0.609),  time:23.850, tt:143.103\n",
      "Ep:6, loss:0.00023, loss_test:0.11566, lr:1.00e-02, fs:0.63317 (r=0.636,p=0.630),  time:24.197, tt:169.378\n",
      "Ep:7, loss:0.00023, loss_test:0.11383, lr:1.00e-02, fs:0.64115 (r=0.677,p=0.609),  time:24.380, tt:195.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00023, loss_test:0.11261, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:24.549, tt:220.937\n",
      "Ep:9, loss:0.00022, loss_test:0.11104, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:24.872, tt:248.716\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10827, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:25.152, tt:276.677\n",
      "Ep:11, loss:0.00021, loss_test:0.10703, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:25.120, tt:301.437\n",
      "Ep:12, loss:0.00021, loss_test:0.10602, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:25.211, tt:327.748\n",
      "Ep:13, loss:0.00020, loss_test:0.10490, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:25.370, tt:355.187\n",
      "Ep:14, loss:0.00020, loss_test:0.10351, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:25.485, tt:382.270\n",
      "Ep:15, loss:0.00020, loss_test:0.10134, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:25.508, tt:408.125\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09944, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:25.599, tt:435.187\n",
      "Ep:17, loss:0.00019, loss_test:0.09799, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:25.634, tt:461.413\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09756, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:25.729, tt:488.848\n",
      "Ep:19, loss:0.00018, loss_test:0.09734, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:25.766, tt:515.324\n",
      "Ep:20, loss:0.00017, loss_test:0.09681, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:25.832, tt:542.462\n",
      "Ep:21, loss:0.00017, loss_test:0.09584, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:25.830, tt:568.265\n",
      "Ep:22, loss:0.00016, loss_test:0.09410, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:25.914, tt:596.016\n",
      "Ep:23, loss:0.00016, loss_test:0.09270, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:25.980, tt:623.531\n",
      "Ep:24, loss:0.00016, loss_test:0.09167, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:26.009, tt:650.219\n",
      "Ep:25, loss:0.00015, loss_test:0.09074, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:25.962, tt:675.024\n",
      "Ep:26, loss:0.00015, loss_test:0.08980, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:25.979, tt:701.422\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08850, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:26.081, tt:730.278\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08729, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:26.050, tt:755.451\n",
      "Ep:29, loss:0.00014, loss_test:0.08671, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:26.085, tt:782.538\n",
      "Ep:30, loss:0.00013, loss_test:0.08558, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:26.121, tt:809.761\n",
      "Ep:31, loss:0.00013, loss_test:0.08460, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:26.171, tt:837.476\n",
      "Ep:32, loss:0.00013, loss_test:0.08375, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:26.166, tt:863.477\n",
      "Ep:33, loss:0.00012, loss_test:0.08295, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:26.170, tt:889.770\n",
      "Ep:34, loss:0.00012, loss_test:0.08193, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:26.245, tt:918.591\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.08096, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:26.272, tt:945.799\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08060, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:26.276, tt:972.200\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07941, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:26.318, tt:1000.084\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.07839, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:26.344, tt:1027.415\n",
      "Ep:39, loss:0.00010, loss_test:0.07806, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:26.360, tt:1054.398\n",
      "Ep:40, loss:0.00010, loss_test:0.07664, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:26.404, tt:1082.554\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.07650, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:26.421, tt:1109.699\n",
      "Ep:42, loss:0.00009, loss_test:0.07561, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:26.453, tt:1137.478\n",
      "Ep:43, loss:0.00009, loss_test:0.07412, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:26.493, tt:1165.693\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.07468, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:26.491, tt:1192.096\n",
      "Ep:45, loss:0.00008, loss_test:0.07271, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:26.504, tt:1219.200\n",
      "Ep:46, loss:0.00008, loss_test:0.07245, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:26.476, tt:1244.379\n",
      "Ep:47, loss:0.00008, loss_test:0.07160, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:26.475, tt:1270.819\n",
      "Ep:48, loss:0.00008, loss_test:0.07101, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:26.497, tt:1298.344\n",
      "Ep:49, loss:0.00007, loss_test:0.07050, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:26.523, tt:1326.139\n",
      "Ep:50, loss:0.00007, loss_test:0.07008, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:26.534, tt:1353.239\n",
      "Ep:51, loss:0.00007, loss_test:0.06953, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:26.535, tt:1379.838\n",
      "Ep:52, loss:0.00007, loss_test:0.06957, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:26.524, tt:1405.750\n",
      "Ep:53, loss:0.00007, loss_test:0.06891, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:26.520, tt:1432.105\n",
      "Ep:54, loss:0.00006, loss_test:0.06854, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:26.522, tt:1458.732\n",
      "Ep:55, loss:0.00006, loss_test:0.06761, lr:9.90e-03, fs:0.81675 (r=0.788,p=0.848),  time:26.530, tt:1485.703\n",
      "Ep:56, loss:0.00006, loss_test:0.06742, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:26.524, tt:1511.858\n",
      "Ep:57, loss:0.00006, loss_test:0.06729, lr:9.70e-03, fs:0.81675 (r=0.788,p=0.848),  time:26.514, tt:1537.786\n",
      "Ep:58, loss:0.00006, loss_test:0.06685, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:26.510, tt:1564.078\n",
      "Ep:59, loss:0.00006, loss_test:0.06690, lr:9.51e-03, fs:0.81675 (r=0.788,p=0.848),  time:26.552, tt:1593.144\n",
      "Ep:60, loss:0.00006, loss_test:0.06668, lr:9.41e-03, fs:0.82540 (r=0.788,p=0.867),  time:26.562, tt:1620.309\n",
      "Ep:61, loss:0.00005, loss_test:0.06658, lr:9.32e-03, fs:0.82105 (r=0.788,p=0.857),  time:26.560, tt:1646.697\n",
      "Ep:62, loss:0.00005, loss_test:0.06605, lr:9.23e-03, fs:0.82540 (r=0.788,p=0.867),  time:26.574, tt:1674.160\n",
      "Ep:63, loss:0.00005, loss_test:0.06655, lr:9.14e-03, fs:0.82979 (r=0.788,p=0.876),  time:26.589, tt:1701.673\n",
      "Ep:64, loss:0.00005, loss_test:0.06608, lr:9.04e-03, fs:0.82979 (r=0.788,p=0.876),  time:26.585, tt:1728.032\n",
      "Ep:65, loss:0.00005, loss_test:0.06588, lr:8.95e-03, fs:0.82540 (r=0.788,p=0.867),  time:26.585, tt:1754.615\n",
      "Ep:66, loss:0.00005, loss_test:0.06579, lr:8.86e-03, fs:0.81915 (r=0.778,p=0.865),  time:26.581, tt:1780.949\n",
      "Ep:67, loss:0.00005, loss_test:0.06601, lr:8.78e-03, fs:0.82979 (r=0.788,p=0.876),  time:26.581, tt:1807.484\n",
      "Ep:68, loss:0.00005, loss_test:0.06559, lr:8.69e-03, fs:0.83598 (r=0.798,p=0.878),  time:26.588, tt:1834.551\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.06552, lr:8.69e-03, fs:0.82353 (r=0.778,p=0.875),  time:26.588, tt:1861.127\n",
      "Ep:70, loss:0.00005, loss_test:0.06555, lr:8.69e-03, fs:0.82979 (r=0.788,p=0.876),  time:26.582, tt:1887.302\n",
      "Ep:71, loss:0.00004, loss_test:0.06626, lr:8.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.589, tt:1914.373\n",
      "Ep:72, loss:0.00004, loss_test:0.06550, lr:8.69e-03, fs:0.81720 (r=0.768,p=0.874),  time:26.575, tt:1939.940\n",
      "Ep:73, loss:0.00004, loss_test:0.06530, lr:8.69e-03, fs:0.82353 (r=0.778,p=0.875),  time:26.577, tt:1966.699\n",
      "Ep:74, loss:0.00004, loss_test:0.06554, lr:8.69e-03, fs:0.83871 (r=0.788,p=0.897),  time:26.575, tt:1993.117\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.06502, lr:8.69e-03, fs:0.82162 (r=0.768,p=0.884),  time:26.576, tt:2019.748\n",
      "Ep:76, loss:0.00004, loss_test:0.06531, lr:8.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.578, tt:2046.467\n",
      "Ep:77, loss:0.00004, loss_test:0.06473, lr:8.69e-03, fs:0.82979 (r=0.788,p=0.876),  time:26.566, tt:2072.110\n",
      "Ep:78, loss:0.00004, loss_test:0.06529, lr:8.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.547, tt:2097.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00004, loss_test:0.06572, lr:8.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.541, tt:2123.310\n",
      "Ep:80, loss:0.00004, loss_test:0.06456, lr:8.69e-03, fs:0.82796 (r=0.778,p=0.885),  time:26.554, tt:2150.881\n",
      "Ep:81, loss:0.00004, loss_test:0.06617, lr:8.69e-03, fs:0.83060 (r=0.768,p=0.905),  time:26.570, tt:2178.722\n",
      "Ep:82, loss:0.00004, loss_test:0.06433, lr:8.69e-03, fs:0.83871 (r=0.788,p=0.897),  time:26.578, tt:2205.953\n",
      "Ep:83, loss:0.00004, loss_test:0.06484, lr:8.69e-03, fs:0.83696 (r=0.778,p=0.906),  time:26.608, tt:2235.104\n",
      "Ep:84, loss:0.00004, loss_test:0.06548, lr:8.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.608, tt:2261.700\n",
      "Ep:85, loss:0.00003, loss_test:0.06492, lr:8.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.621, tt:2289.431\n",
      "Ep:86, loss:0.00003, loss_test:0.06545, lr:8.60e-03, fs:0.83696 (r=0.778,p=0.906),  time:26.623, tt:2316.174\n",
      "Ep:87, loss:0.00003, loss_test:0.06459, lr:8.51e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.636, tt:2343.934\n",
      "Ep:88, loss:0.00003, loss_test:0.06530, lr:8.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.638, tt:2370.813\n",
      "Ep:89, loss:0.00003, loss_test:0.06478, lr:8.35e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.643, tt:2397.854\n",
      "Ep:90, loss:0.00003, loss_test:0.06517, lr:8.26e-03, fs:0.83696 (r=0.778,p=0.906),  time:26.642, tt:2424.465\n",
      "Ep:91, loss:0.00003, loss_test:0.06467, lr:8.18e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.635, tt:2450.441\n",
      "Ep:92, loss:0.00003, loss_test:0.06515, lr:8.10e-03, fs:0.83696 (r=0.778,p=0.906),  time:26.638, tt:2477.373\n",
      "Ep:93, loss:0.00003, loss_test:0.06512, lr:8.02e-03, fs:0.83696 (r=0.778,p=0.906),  time:26.655, tt:2505.560\n",
      "Ep:94, loss:0.00003, loss_test:0.06443, lr:7.94e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.655, tt:2532.259\n",
      "Ep:95, loss:0.00003, loss_test:0.06490, lr:7.86e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.666, tt:2559.895\n",
      "Ep:96, loss:0.00003, loss_test:0.06544, lr:7.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:26.664, tt:2586.373\n",
      "Ep:97, loss:0.00003, loss_test:0.06499, lr:7.70e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.682, tt:2614.825\n",
      "Ep:98, loss:0.00003, loss_test:0.06556, lr:7.62e-03, fs:0.83516 (r=0.768,p=0.916),  time:26.686, tt:2641.888\n",
      "Ep:99, loss:0.00003, loss_test:0.06646, lr:7.55e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.693, tt:2669.299\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00003, loss_test:0.06500, lr:7.55e-03, fs:0.83243 (r=0.778,p=0.895),  time:26.720, tt:2698.766\n",
      "Ep:101, loss:0.00003, loss_test:0.06539, lr:7.55e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.709, tt:2724.362\n",
      "Ep:102, loss:0.00003, loss_test:0.06536, lr:7.55e-03, fs:0.83516 (r=0.768,p=0.916),  time:26.716, tt:2751.697\n",
      "Ep:103, loss:0.00003, loss_test:0.06609, lr:7.55e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.725, tt:2779.352\n",
      "Ep:104, loss:0.00003, loss_test:0.06596, lr:7.55e-03, fs:0.83060 (r=0.768,p=0.905),  time:26.730, tt:2806.660\n",
      "Ep:105, loss:0.00002, loss_test:0.06562, lr:7.55e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.733, tt:2833.724\n",
      "Ep:106, loss:0.00002, loss_test:0.06644, lr:7.55e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.735, tt:2860.616\n",
      "Ep:107, loss:0.00002, loss_test:0.06568, lr:7.55e-03, fs:0.83060 (r=0.768,p=0.905),  time:26.738, tt:2887.707\n",
      "Ep:108, loss:0.00002, loss_test:0.06657, lr:7.55e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.785, tt:2919.599\n",
      "Ep:109, loss:0.00002, loss_test:0.06600, lr:7.55e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.800, tt:2948.055\n",
      "Ep:110, loss:0.00002, loss_test:0.06573, lr:7.55e-03, fs:0.83060 (r=0.768,p=0.905),  time:26.802, tt:2975.033\n",
      "Ep:111, loss:0.00002, loss_test:0.06762, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.802, tt:3001.812\n",
      "Ep:112, loss:0.00002, loss_test:0.06604, lr:7.40e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.821, tt:3030.765\n",
      "Ep:113, loss:0.00002, loss_test:0.06641, lr:7.32e-03, fs:0.82609 (r=0.768,p=0.894),  time:26.828, tt:3058.445\n",
      "Ep:114, loss:0.00002, loss_test:0.06674, lr:7.25e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.833, tt:3085.805\n",
      "Ep:115, loss:0.00002, loss_test:0.06652, lr:7.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.844, tt:3113.960\n",
      "Ep:116, loss:0.00002, loss_test:0.06643, lr:7.11e-03, fs:0.83516 (r=0.768,p=0.916),  time:26.847, tt:3141.107\n",
      "Ep:117, loss:0.00002, loss_test:0.06624, lr:7.03e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.837, tt:3166.781\n",
      "Ep:118, loss:0.00002, loss_test:0.06761, lr:6.96e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.841, tt:3194.073\n",
      "Ep:119, loss:0.00002, loss_test:0.06637, lr:6.89e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.859, tt:3223.128\n",
      "Ep:120, loss:0.00002, loss_test:0.06714, lr:6.83e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.869, tt:3251.167\n",
      "Ep:121, loss:0.00002, loss_test:0.06754, lr:6.76e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.881, tt:3279.540\n",
      "Ep:122, loss:0.00002, loss_test:0.06656, lr:6.69e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.889, tt:3307.350\n",
      "Ep:123, loss:0.00002, loss_test:0.06713, lr:6.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.888, tt:3334.091\n",
      "Ep:124, loss:0.00002, loss_test:0.06731, lr:6.56e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.888, tt:3360.972\n",
      "Ep:125, loss:0.00002, loss_test:0.06724, lr:6.49e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.893, tt:3388.547\n",
      "Ep:126, loss:0.00002, loss_test:0.06758, lr:6.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.904, tt:3416.754\n",
      "Ep:127, loss:0.00002, loss_test:0.06663, lr:6.36e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.910, tt:3444.485\n",
      "Ep:128, loss:0.00002, loss_test:0.06758, lr:6.30e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.916, tt:3472.153\n",
      "Ep:129, loss:0.00002, loss_test:0.06672, lr:6.24e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.938, tt:3501.893\n",
      "Ep:130, loss:0.00002, loss_test:0.06770, lr:6.17e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.954, tt:3530.968\n",
      "Ep:131, loss:0.00002, loss_test:0.06773, lr:6.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.964, tt:3559.274\n",
      "Ep:132, loss:0.00002, loss_test:0.06646, lr:6.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:26.984, tt:3588.822\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00002, loss_test:0.06838, lr:6.05e-03, fs:0.82682 (r=0.747,p=0.925),  time:26.986, tt:3616.185\n",
      "Ep:134, loss:0.00002, loss_test:0.06801, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.996, tt:3644.436\n",
      "Ep:135, loss:0.00002, loss_test:0.06665, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:27.005, tt:3672.661\n",
      "Ep:136, loss:0.00002, loss_test:0.06781, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.999, tt:3698.881\n",
      "Ep:137, loss:0.00002, loss_test:0.06787, lr:6.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:26.991, tt:3724.804\n",
      "Ep:138, loss:0.00002, loss_test:0.06734, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.995, tt:3752.363\n",
      "Ep:139, loss:0.00002, loss_test:0.06725, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:26.996, tt:3779.498\n",
      "Ep:140, loss:0.00002, loss_test:0.06794, lr:6.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.005, tt:3807.738\n",
      "Ep:141, loss:0.00002, loss_test:0.06789, lr:6.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.010, tt:3835.405\n",
      "Ep:142, loss:0.00002, loss_test:0.06733, lr:6.05e-03, fs:0.83978 (r=0.768,p=0.927),  time:27.014, tt:3863.037\n",
      "Ep:143, loss:0.00002, loss_test:0.06770, lr:6.05e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.011, tt:3889.640\n",
      "Ep:144, loss:0.00002, loss_test:0.06769, lr:5.99e-03, fs:0.83146 (r=0.747,p=0.937),  time:27.013, tt:3916.911\n",
      "Ep:145, loss:0.00002, loss_test:0.06746, lr:5.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.030, tt:3946.448\n",
      "Ep:146, loss:0.00002, loss_test:0.06786, lr:5.87e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.058, tt:3977.571\n",
      "Ep:147, loss:0.00002, loss_test:0.06814, lr:5.81e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.066, tt:4005.725\n",
      "Ep:148, loss:0.00001, loss_test:0.06735, lr:5.75e-03, fs:0.84916 (r=0.768,p=0.950),  time:27.067, tt:4033.034\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00001, loss_test:0.06825, lr:5.75e-03, fs:0.82682 (r=0.747,p=0.925),  time:27.072, tt:4060.781\n",
      "Ep:150, loss:0.00001, loss_test:0.06803, lr:5.75e-03, fs:0.84916 (r=0.768,p=0.950),  time:27.066, tt:4086.923\n",
      "Ep:151, loss:0.00001, loss_test:0.06823, lr:5.75e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.065, tt:4113.927\n",
      "Ep:152, loss:0.00001, loss_test:0.06822, lr:5.75e-03, fs:0.82682 (r=0.747,p=0.925),  time:27.070, tt:4141.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00001, loss_test:0.06773, lr:5.75e-03, fs:0.84916 (r=0.768,p=0.950),  time:27.082, tt:4170.552\n",
      "Ep:154, loss:0.00001, loss_test:0.06821, lr:5.75e-03, fs:0.84270 (r=0.758,p=0.949),  time:27.085, tt:4198.119\n",
      "Ep:155, loss:0.00001, loss_test:0.06779, lr:5.75e-03, fs:0.84270 (r=0.758,p=0.949),  time:27.082, tt:4224.818\n",
      "Ep:156, loss:0.00001, loss_test:0.06850, lr:5.75e-03, fs:0.80925 (r=0.707,p=0.946),  time:27.088, tt:4252.753\n",
      "Ep:157, loss:0.00001, loss_test:0.06846, lr:5.75e-03, fs:0.81609 (r=0.717,p=0.947),  time:27.100, tt:4281.740\n",
      "Ep:158, loss:0.00001, loss_test:0.06751, lr:5.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.090, tt:4307.371\n",
      "Ep:159, loss:0.00001, loss_test:0.06891, lr:5.75e-03, fs:0.78824 (r=0.677,p=0.944),  time:27.098, tt:4335.682\n",
      "Ep:160, loss:0.00001, loss_test:0.06856, lr:5.70e-03, fs:0.80925 (r=0.707,p=0.946),  time:27.105, tt:4363.888\n",
      "Ep:161, loss:0.00001, loss_test:0.06847, lr:5.64e-03, fs:0.80925 (r=0.707,p=0.946),  time:27.107, tt:4391.287\n",
      "Ep:162, loss:0.00001, loss_test:0.06889, lr:5.58e-03, fs:0.80925 (r=0.707,p=0.946),  time:27.111, tt:4419.021\n",
      "Ep:163, loss:0.00001, loss_test:0.06851, lr:5.53e-03, fs:0.81609 (r=0.717,p=0.947),  time:27.110, tt:4446.045\n",
      "Ep:164, loss:0.00001, loss_test:0.06891, lr:5.47e-03, fs:0.80925 (r=0.707,p=0.946),  time:27.117, tt:4474.300\n",
      "Ep:165, loss:0.00001, loss_test:0.06831, lr:5.42e-03, fs:0.82955 (r=0.737,p=0.948),  time:27.131, tt:4503.691\n",
      "Ep:166, loss:0.00001, loss_test:0.06919, lr:5.36e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.134, tt:4531.338\n",
      "Ep:167, loss:0.00001, loss_test:0.06892, lr:5.31e-03, fs:0.78824 (r=0.677,p=0.944),  time:27.142, tt:4559.784\n",
      "Ep:168, loss:0.00001, loss_test:0.06843, lr:5.26e-03, fs:0.81609 (r=0.717,p=0.947),  time:27.146, tt:4587.621\n",
      "Ep:169, loss:0.00001, loss_test:0.06917, lr:5.20e-03, fs:0.80233 (r=0.697,p=0.945),  time:27.145, tt:4614.688\n",
      "Ep:170, loss:0.00001, loss_test:0.06864, lr:5.15e-03, fs:0.79532 (r=0.687,p=0.944),  time:27.148, tt:4642.284\n",
      "Ep:171, loss:0.00001, loss_test:0.06885, lr:5.10e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.154, tt:4670.504\n",
      "Ep:172, loss:0.00001, loss_test:0.06906, lr:5.05e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.160, tt:4698.687\n",
      "Ep:173, loss:0.00001, loss_test:0.06910, lr:5.00e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.158, tt:4725.434\n",
      "Ep:174, loss:0.00001, loss_test:0.06862, lr:4.95e-03, fs:0.77381 (r=0.657,p=0.942),  time:27.163, tt:4753.564\n",
      "Ep:175, loss:0.00001, loss_test:0.06928, lr:4.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:27.164, tt:4780.860\n",
      "Ep:176, loss:0.00001, loss_test:0.06924, lr:4.85e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.169, tt:4808.983\n",
      "Ep:177, loss:0.00001, loss_test:0.06884, lr:4.80e-03, fs:0.78824 (r=0.677,p=0.944),  time:27.173, tt:4836.854\n",
      "Ep:178, loss:0.00001, loss_test:0.06902, lr:4.75e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.182, tt:4865.573\n",
      "Ep:179, loss:0.00001, loss_test:0.06891, lr:4.71e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.184, tt:4893.040\n",
      "Ep:180, loss:0.00001, loss_test:0.06926, lr:4.66e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.193, tt:4921.931\n",
      "Ep:181, loss:0.00001, loss_test:0.06896, lr:4.61e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.198, tt:4949.999\n",
      "Ep:182, loss:0.00001, loss_test:0.06913, lr:4.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.188, tt:4975.351\n",
      "Ep:183, loss:0.00001, loss_test:0.06955, lr:4.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.179, tt:5000.954\n",
      "Ep:184, loss:0.00001, loss_test:0.06864, lr:4.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:27.170, tt:5026.500\n",
      "Ep:185, loss:0.00001, loss_test:0.06946, lr:4.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.167, tt:5053.003\n",
      "Ep:186, loss:0.00001, loss_test:0.06983, lr:4.39e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.163, tt:5079.514\n",
      "Ep:187, loss:0.00001, loss_test:0.06888, lr:4.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.166, tt:5107.204\n",
      "Ep:188, loss:0.00001, loss_test:0.06917, lr:4.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.161, tt:5133.396\n",
      "Ep:189, loss:0.00001, loss_test:0.06965, lr:4.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:27.160, tt:5160.484\n",
      "Ep:190, loss:0.00001, loss_test:0.06910, lr:4.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.159, tt:5187.341\n",
      "Ep:191, loss:0.00001, loss_test:0.06934, lr:4.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.165, tt:5215.731\n",
      "Ep:192, loss:0.00001, loss_test:0.06942, lr:4.13e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.172, tt:5244.258\n",
      "Ep:193, loss:0.00001, loss_test:0.06898, lr:4.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.172, tt:5271.397\n",
      "Ep:194, loss:0.00001, loss_test:0.06970, lr:4.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.180, tt:5300.140\n",
      "Ep:195, loss:0.00001, loss_test:0.06919, lr:4.01e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.177, tt:5326.773\n",
      "Ep:196, loss:0.00001, loss_test:0.06923, lr:3.97e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.175, tt:5353.420\n",
      "Ep:197, loss:0.00001, loss_test:0.06929, lr:3.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.174, tt:5380.471\n",
      "Ep:198, loss:0.00001, loss_test:0.06930, lr:3.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.159, tt:5404.734\n",
      "Ep:199, loss:0.00001, loss_test:0.06967, lr:3.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.144, tt:5428.860\n",
      "Ep:200, loss:0.00001, loss_test:0.06967, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:27.135, tt:5454.091\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02341, lr:6.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:29.520, tt:29.520\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02589, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:29.070, tt:58.139\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02778, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.251, tt:81.753\n",
      "Ep:3, loss:0.00005, loss_test:0.02798, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.195, tt:112.780\n",
      "Ep:4, loss:0.00005, loss_test:0.02703, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.864, tt:144.319\n",
      "Ep:5, loss:0.00005, loss_test:0.02534, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:29.462, tt:176.771\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02359, lr:6.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:30.162, tt:211.135\n",
      "Ep:7, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:30.326, tt:242.610\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02165, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:30.668, tt:276.012\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02095, lr:6.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:31.220, tt:312.197\n",
      "Ep:10, loss:0.00004, loss_test:0.02005, lr:6.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:31.644, tt:348.088\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:32.033, tt:384.391\n",
      "Ep:12, loss:0.00004, loss_test:0.01906, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:32.266, tt:419.459\n",
      "Ep:13, loss:0.00004, loss_test:0.01860, lr:6.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:32.493, tt:454.897\n",
      "Ep:14, loss:0.00004, loss_test:0.01822, lr:6.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:32.660, tt:489.893\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01795, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:32.847, tt:525.549\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01763, lr:6.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:32.986, tt:560.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:33.109, tt:595.965\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.71373 (r=0.919,p=0.583),  time:33.224, tt:631.249\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01675, lr:6.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:33.297, tt:665.936\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:33.330, tt:699.935\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:33.391, tt:734.595\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:33.427, tt:768.821\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01602, lr:6.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:33.441, tt:802.573\n",
      "Ep:24, loss:0.00003, loss_test:0.01591, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:33.480, tt:836.988\n",
      "Ep:25, loss:0.00003, loss_test:0.01579, lr:6.00e-02, fs:0.75105 (r=0.899,p=0.645),  time:33.497, tt:870.934\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.75105 (r=0.899,p=0.645),  time:33.561, tt:906.139\n",
      "Ep:27, loss:0.00003, loss_test:0.01563, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:33.606, tt:940.966\n",
      "Ep:28, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:33.616, tt:974.861\n",
      "Ep:29, loss:0.00002, loss_test:0.01546, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:33.622, tt:1008.668\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01542, lr:6.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:33.652, tt:1043.226\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01536, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:33.658, tt:1077.056\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:33.720, tt:1112.748\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:33.698, tt:1145.727\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:33.694, tt:1179.304\n",
      "Ep:35, loss:0.00002, loss_test:0.01506, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:33.728, tt:1214.212\n",
      "Ep:36, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:33.751, tt:1248.793\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:33.771, tt:1283.301\n",
      "Ep:38, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:33.761, tt:1316.661\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:33.826, tt:1353.043\n",
      "Ep:40, loss:0.00002, loss_test:0.01476, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:33.877, tt:1388.971\n",
      "Ep:41, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:33.917, tt:1424.495\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01482, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:33.904, tt:1457.888\n",
      "Ep:43, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:33.931, tt:1492.956\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:33.961, tt:1528.247\n",
      "Ep:45, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:33.978, tt:1562.982\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01479, lr:6.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:34.020, tt:1598.930\n",
      "Ep:47, loss:0.00001, loss_test:0.01484, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.043, tt:1634.069\n",
      "Ep:48, loss:0.00001, loss_test:0.01483, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.066, tt:1669.234\n",
      "Ep:49, loss:0.00001, loss_test:0.01487, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.087, tt:1704.373\n",
      "Ep:50, loss:0.00001, loss_test:0.01492, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.106, tt:1739.397\n",
      "Ep:51, loss:0.00001, loss_test:0.01496, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:34.162, tt:1776.438\n",
      "Ep:52, loss:0.00001, loss_test:0.01498, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:34.188, tt:1811.981\n",
      "Ep:53, loss:0.00001, loss_test:0.01498, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.211, tt:1847.408\n",
      "Ep:54, loss:0.00001, loss_test:0.01504, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.210, tt:1881.550\n",
      "Ep:55, loss:0.00001, loss_test:0.01505, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.216, tt:1916.121\n",
      "Ep:56, loss:0.00001, loss_test:0.01506, lr:6.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.216, tt:1950.294\n",
      "Ep:57, loss:0.00001, loss_test:0.01511, lr:5.94e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.230, tt:1985.353\n",
      "Ep:58, loss:0.00001, loss_test:0.01510, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.255, tt:2021.059\n",
      "Ep:59, loss:0.00001, loss_test:0.01518, lr:5.82e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.273, tt:2056.398\n",
      "Ep:60, loss:0.00001, loss_test:0.01526, lr:5.76e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.276, tt:2090.865\n",
      "Ep:61, loss:0.00001, loss_test:0.01525, lr:5.71e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.298, tt:2126.496\n",
      "Ep:62, loss:0.00001, loss_test:0.01537, lr:5.65e-02, fs:0.75393 (r=0.727,p=0.783),  time:34.314, tt:2161.778\n",
      "Ep:63, loss:0.00001, loss_test:0.01538, lr:5.59e-02, fs:0.75393 (r=0.727,p=0.783),  time:34.355, tt:2198.700\n",
      "Ep:64, loss:0.00001, loss_test:0.01540, lr:5.54e-02, fs:0.75132 (r=0.717,p=0.789),  time:34.379, tt:2234.623\n",
      "Ep:65, loss:0.00001, loss_test:0.01542, lr:5.48e-02, fs:0.74866 (r=0.707,p=0.795),  time:34.386, tt:2269.485\n",
      "Ep:66, loss:0.00001, loss_test:0.01548, lr:5.43e-02, fs:0.73797 (r=0.697,p=0.784),  time:34.419, tt:2306.083\n",
      "Ep:67, loss:0.00001, loss_test:0.01546, lr:5.37e-02, fs:0.73797 (r=0.697,p=0.784),  time:34.418, tt:2340.434\n",
      "Ep:68, loss:0.00001, loss_test:0.01560, lr:5.32e-02, fs:0.72826 (r=0.677,p=0.788),  time:34.426, tt:2375.369\n",
      "Ep:69, loss:0.00001, loss_test:0.01556, lr:5.27e-02, fs:0.71038 (r=0.657,p=0.774),  time:34.440, tt:2410.768\n",
      "Ep:70, loss:0.00001, loss_test:0.01567, lr:5.21e-02, fs:0.71429 (r=0.657,p=0.783),  time:34.448, tt:2445.811\n",
      "Ep:71, loss:0.00001, loss_test:0.01571, lr:5.16e-02, fs:0.70718 (r=0.646,p=0.780),  time:34.485, tt:2482.949\n",
      "Ep:72, loss:0.00001, loss_test:0.01572, lr:5.11e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.504, tt:2518.826\n",
      "Ep:73, loss:0.00001, loss_test:0.01570, lr:5.06e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.562, tt:2557.581\n",
      "Ep:74, loss:0.00001, loss_test:0.01579, lr:5.01e-02, fs:0.71111 (r=0.646,p=0.790),  time:34.560, tt:2591.984\n",
      "Ep:75, loss:0.00001, loss_test:0.01573, lr:4.96e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.577, tt:2627.871\n",
      "Ep:76, loss:0.00001, loss_test:0.01582, lr:4.91e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.592, tt:2663.586\n",
      "Ep:77, loss:0.00001, loss_test:0.01589, lr:4.86e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.608, tt:2699.389\n",
      "Ep:78, loss:0.00001, loss_test:0.01599, lr:4.81e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.635, tt:2736.132\n",
      "Ep:79, loss:0.00001, loss_test:0.01606, lr:4.76e-02, fs:0.70391 (r=0.636,p=0.787),  time:34.649, tt:2771.912\n",
      "Ep:80, loss:0.00001, loss_test:0.01586, lr:4.71e-02, fs:0.69663 (r=0.626,p=0.785),  time:34.671, tt:2808.323\n",
      "Ep:81, loss:0.00001, loss_test:0.01618, lr:4.67e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.675, tt:2843.312\n",
      "Ep:82, loss:0.00001, loss_test:0.01595, lr:4.62e-02, fs:0.69663 (r=0.626,p=0.785),  time:34.700, tt:2880.079\n",
      "Ep:83, loss:0.00001, loss_test:0.01624, lr:4.57e-02, fs:0.71186 (r=0.636,p=0.808),  time:34.720, tt:2916.461\n",
      "Ep:84, loss:0.00001, loss_test:0.01610, lr:4.53e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.742, tt:2953.037\n",
      "Ep:85, loss:0.00001, loss_test:0.01631, lr:4.48e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.753, tt:2988.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00001, loss_test:0.01623, lr:4.44e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.748, tt:3023.062\n",
      "Ep:87, loss:0.00001, loss_test:0.01641, lr:4.39e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.733, tt:3056.489\n",
      "Ep:88, loss:0.00001, loss_test:0.01653, lr:4.35e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.733, tt:3091.196\n",
      "Ep:89, loss:0.00001, loss_test:0.01650, lr:4.31e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.730, tt:3125.668\n",
      "Ep:90, loss:0.00001, loss_test:0.01660, lr:4.26e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.748, tt:3162.081\n",
      "Ep:91, loss:0.00001, loss_test:0.01664, lr:4.22e-02, fs:0.70056 (r=0.626,p=0.795),  time:34.758, tt:3197.780\n",
      "Ep:92, loss:0.00001, loss_test:0.01678, lr:4.18e-02, fs:0.70455 (r=0.626,p=0.805),  time:34.771, tt:3233.708\n",
      "Ep:93, loss:0.00001, loss_test:0.01670, lr:4.14e-02, fs:0.70455 (r=0.626,p=0.805),  time:34.788, tt:3270.111\n",
      "Ep:94, loss:0.00001, loss_test:0.01697, lr:4.10e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.797, tt:3305.674\n",
      "Ep:95, loss:0.00001, loss_test:0.01692, lr:4.05e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.809, tt:3341.701\n",
      "Ep:96, loss:0.00001, loss_test:0.01709, lr:4.01e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.829, tt:3378.455\n",
      "Ep:97, loss:0.00001, loss_test:0.01700, lr:3.97e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.834, tt:3413.746\n",
      "Ep:98, loss:0.00001, loss_test:0.01711, lr:3.93e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.849, tt:3450.054\n",
      "Ep:99, loss:0.00001, loss_test:0.01718, lr:3.89e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.866, tt:3486.619\n",
      "Ep:100, loss:0.00001, loss_test:0.01723, lr:3.86e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.878, tt:3522.646\n",
      "Ep:101, loss:0.00001, loss_test:0.01727, lr:3.82e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.891, tt:3558.838\n",
      "Ep:102, loss:0.00001, loss_test:0.01742, lr:3.78e-02, fs:0.69364 (r=0.606,p=0.811),  time:34.912, tt:3595.921\n",
      "Ep:103, loss:0.00000, loss_test:0.01741, lr:3.74e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.931, tt:3632.843\n",
      "Ep:104, loss:0.00000, loss_test:0.01747, lr:3.70e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.951, tt:3669.829\n",
      "Ep:105, loss:0.00000, loss_test:0.01753, lr:3.67e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.966, tt:3706.369\n",
      "Ep:106, loss:0.00000, loss_test:0.01759, lr:3.63e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.982, tt:3743.105\n",
      "Ep:107, loss:0.00000, loss_test:0.01767, lr:3.59e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.000, tt:3780.012\n",
      "Ep:108, loss:0.00000, loss_test:0.01765, lr:3.56e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.012, tt:3816.321\n",
      "Ep:109, loss:0.00000, loss_test:0.01782, lr:3.52e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.040, tt:3854.400\n",
      "Ep:110, loss:0.00000, loss_test:0.01779, lr:3.49e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.053, tt:3890.867\n",
      "Ep:111, loss:0.00000, loss_test:0.01790, lr:3.45e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.053, tt:3925.908\n",
      "Ep:112, loss:0.00000, loss_test:0.01790, lr:3.42e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.074, tt:3963.326\n",
      "Ep:113, loss:0.00000, loss_test:0.01800, lr:3.38e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.081, tt:3999.249\n",
      "Ep:114, loss:0.00000, loss_test:0.01797, lr:3.35e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.101, tt:4036.615\n",
      "Ep:115, loss:0.00000, loss_test:0.01801, lr:3.32e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.107, tt:4072.358\n",
      "Ep:116, loss:0.00000, loss_test:0.01822, lr:3.28e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.111, tt:4108.032\n",
      "Ep:117, loss:0.00000, loss_test:0.01800, lr:3.25e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.116, tt:4143.746\n",
      "Ep:118, loss:0.00000, loss_test:0.01832, lr:3.22e-02, fs:0.67456 (r=0.576,p=0.814),  time:35.105, tt:4177.469\n",
      "Ep:119, loss:0.00000, loss_test:0.01819, lr:3.19e-02, fs:0.68235 (r=0.586,p=0.817),  time:35.112, tt:4213.385\n",
      "Ep:120, loss:0.00000, loss_test:0.01837, lr:3.15e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.104, tt:4247.536\n",
      "Ep:121, loss:0.00000, loss_test:0.01833, lr:3.12e-02, fs:0.68639 (r=0.586,p=0.829),  time:35.110, tt:4283.452\n",
      "Ep:122, loss:0.00000, loss_test:0.01846, lr:3.09e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.109, tt:4318.463\n",
      "Ep:123, loss:0.00000, loss_test:0.01857, lr:3.06e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.108, tt:4353.406\n",
      "Ep:124, loss:0.00000, loss_test:0.01854, lr:3.03e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.118, tt:4389.733\n",
      "Ep:125, loss:0.00000, loss_test:0.01868, lr:3.00e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.131, tt:4426.449\n",
      "Ep:126, loss:0.00000, loss_test:0.01850, lr:2.97e-02, fs:0.69461 (r=0.586,p=0.853),  time:35.143, tt:4463.158\n",
      "Ep:127, loss:0.00000, loss_test:0.01882, lr:2.94e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.146, tt:4498.657\n",
      "Ep:128, loss:0.00000, loss_test:0.01868, lr:2.91e-02, fs:0.69048 (r=0.586,p=0.841),  time:35.138, tt:4532.827\n",
      "Ep:129, loss:0.00000, loss_test:0.01885, lr:2.88e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.143, tt:4568.627\n",
      "Ep:130, loss:0.00000, loss_test:0.01886, lr:2.85e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.145, tt:4603.971\n",
      "Ep:131, loss:0.00000, loss_test:0.01885, lr:2.82e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.139, tt:4638.373\n",
      "Ep:132, loss:0.00000, loss_test:0.01897, lr:2.80e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.138, tt:4673.291\n",
      "Ep:133, loss:0.00000, loss_test:0.01888, lr:2.77e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.169, tt:4712.621\n",
      "Ep:134, loss:0.00000, loss_test:0.01909, lr:2.74e-02, fs:0.67857 (r=0.576,p=0.826),  time:35.177, tt:4748.896\n",
      "Ep:135, loss:0.00000, loss_test:0.01900, lr:2.71e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.171, tt:4783.263\n",
      "Ep:136, loss:0.00000, loss_test:0.01913, lr:2.69e-02, fs:0.68263 (r=0.576,p=0.838),  time:35.181, tt:4819.794\n",
      "Ep:137, loss:0.00000, loss_test:0.01914, lr:2.66e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.189, tt:4856.137\n",
      "Ep:138, loss:0.00000, loss_test:0.01917, lr:2.63e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.202, tt:4893.068\n",
      "Ep:139, loss:0.00000, loss_test:0.01928, lr:2.61e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.190, tt:4926.630\n",
      "Ep:140, loss:0.00000, loss_test:0.01926, lr:2.58e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.203, tt:4963.596\n",
      "Ep:141, loss:0.00000, loss_test:0.01937, lr:2.55e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.201, tt:4998.522\n",
      "Ep:142, loss:0.00000, loss_test:0.01938, lr:2.53e-02, fs:0.68675 (r=0.576,p=0.851),  time:35.203, tt:5034.057\n",
      "Ep:143, loss:0.00000, loss_test:0.01946, lr:2.50e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.204, tt:5069.356\n",
      "Ep:144, loss:0.00000, loss_test:0.01950, lr:2.48e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.205, tt:5104.660\n",
      "Ep:145, loss:0.00000, loss_test:0.01953, lr:2.45e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.208, tt:5140.346\n",
      "Ep:146, loss:0.00000, loss_test:0.01960, lr:2.43e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.212, tt:5176.204\n",
      "Ep:147, loss:0.00000, loss_test:0.01962, lr:2.40e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.217, tt:5212.187\n",
      "Ep:148, loss:0.00000, loss_test:0.01958, lr:2.38e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.233, tt:5249.773\n",
      "Ep:149, loss:0.00000, loss_test:0.01967, lr:2.36e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.232, tt:5284.797\n",
      "Ep:150, loss:0.00000, loss_test:0.01972, lr:2.33e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.230, tt:5319.802\n",
      "Ep:151, loss:0.00000, loss_test:0.01970, lr:2.31e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.232, tt:5355.334\n",
      "Ep:152, loss:0.00000, loss_test:0.01976, lr:2.29e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.252, tt:5393.605\n",
      "Ep:153, loss:0.00000, loss_test:0.01980, lr:2.26e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.259, tt:5429.816\n",
      "Ep:154, loss:0.00000, loss_test:0.01990, lr:2.24e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.268, tt:5466.517\n",
      "Ep:155, loss:0.00000, loss_test:0.01981, lr:2.22e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.273, tt:5502.635\n",
      "Ep:156, loss:0.00000, loss_test:0.01991, lr:2.20e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.278, tt:5538.682\n",
      "Ep:157, loss:0.00000, loss_test:0.01995, lr:2.17e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.279, tt:5574.070\n",
      "Ep:158, loss:0.00000, loss_test:0.01995, lr:2.15e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.286, tt:5610.432\n",
      "Ep:159, loss:0.00000, loss_test:0.02003, lr:2.13e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.289, tt:5646.274\n",
      "Ep:160, loss:0.00000, loss_test:0.02001, lr:2.11e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.290, tt:5681.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:161, loss:0.00000, loss_test:0.02009, lr:2.09e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.300, tt:5718.653\n",
      "Ep:162, loss:0.00000, loss_test:0.02011, lr:2.07e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.315, tt:5756.304\n",
      "Ep:163, loss:0.00000, loss_test:0.02018, lr:2.05e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.322, tt:5792.769\n",
      "Ep:164, loss:0.00000, loss_test:0.02017, lr:2.03e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.315, tt:5826.935\n",
      "Ep:165, loss:0.00000, loss_test:0.02022, lr:2.01e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.323, tt:5863.619\n",
      "Ep:166, loss:0.00000, loss_test:0.02018, lr:1.99e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.322, tt:5898.792\n",
      "Ep:167, loss:0.00000, loss_test:0.02029, lr:1.97e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.322, tt:5934.093\n",
      "Ep:168, loss:0.00000, loss_test:0.02031, lr:1.95e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.323, tt:5969.620\n",
      "Ep:169, loss:0.00000, loss_test:0.02032, lr:1.93e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.333, tt:6006.631\n",
      "Ep:170, loss:0.00000, loss_test:0.02038, lr:1.91e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.328, tt:6041.146\n",
      "Ep:171, loss:0.00000, loss_test:0.02039, lr:1.89e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.328, tt:6076.389\n",
      "Ep:172, loss:0.00000, loss_test:0.02040, lr:1.87e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.319, tt:6110.252\n",
      "Ep:173, loss:0.00000, loss_test:0.02047, lr:1.85e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.321, tt:6145.816\n",
      "Ep:174, loss:0.00000, loss_test:0.02042, lr:1.83e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.318, tt:6180.675\n",
      "Ep:175, loss:0.00000, loss_test:0.02052, lr:1.81e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.317, tt:6215.862\n",
      "Ep:176, loss:0.00000, loss_test:0.02048, lr:1.80e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.314, tt:6250.589\n",
      "Ep:177, loss:0.00000, loss_test:0.02053, lr:1.78e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.323, tt:6287.467\n",
      "Ep:178, loss:0.00000, loss_test:0.02059, lr:1.76e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.325, tt:6323.115\n",
      "Ep:179, loss:0.00000, loss_test:0.02057, lr:1.74e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.323, tt:6358.079\n",
      "Ep:180, loss:0.00000, loss_test:0.02062, lr:1.73e-02, fs:0.69091 (r=0.576,p=0.864),  time:35.322, tt:6393.294\n",
      "Ep:181, loss:0.00000, loss_test:0.02064, lr:1.71e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.313, tt:6426.957\n",
      "Ep:182, loss:0.00000, loss_test:0.02066, lr:1.69e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.311, tt:6461.933\n",
      "Ep:183, loss:0.00000, loss_test:0.02069, lr:1.67e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.307, tt:6496.461\n",
      "Ep:184, loss:0.00000, loss_test:0.02073, lr:1.66e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.296, tt:6529.849\n",
      "Ep:185, loss:0.00000, loss_test:0.02074, lr:1.64e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.293, tt:6564.512\n",
      "Ep:186, loss:0.00000, loss_test:0.02079, lr:1.62e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.312, tt:6603.250\n",
      "Ep:187, loss:0.00000, loss_test:0.02076, lr:1.61e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.303, tt:6636.957\n",
      "Ep:188, loss:0.00000, loss_test:0.02079, lr:1.59e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.294, tt:6670.571\n",
      "Ep:189, loss:0.00000, loss_test:0.02086, lr:1.58e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.285, tt:6704.074\n",
      "Ep:190, loss:0.00000, loss_test:0.02080, lr:1.56e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.288, tt:6739.953\n",
      "Ep:191, loss:0.00000, loss_test:0.02088, lr:1.54e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.285, tt:6774.812\n",
      "Ep:192, loss:0.00000, loss_test:0.02091, lr:1.53e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.283, tt:6809.646\n",
      "Ep:193, loss:0.00000, loss_test:0.02085, lr:1.51e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.288, tt:6845.801\n",
      "Ep:194, loss:0.00000, loss_test:0.02095, lr:1.50e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.287, tt:6880.964\n",
      "Ep:195, loss:0.00000, loss_test:0.02094, lr:1.48e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.287, tt:6916.346\n",
      "Ep:196, loss:0.00000, loss_test:0.02096, lr:1.47e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.293, tt:6952.665\n",
      "Ep:197, loss:0.00000, loss_test:0.02104, lr:1.45e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.295, tt:6988.375\n",
      "Ep:198, loss:0.00000, loss_test:0.02101, lr:1.44e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.295, tt:7023.702\n",
      "Ep:199, loss:0.00000, loss_test:0.02102, lr:1.43e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.291, tt:7058.122\n",
      "Ep:200, loss:0.00000, loss_test:0.02109, lr:1.41e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.293, tt:7093.933\n",
      "Ep:201, loss:0.00000, loss_test:0.02106, lr:1.40e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.305, tt:7131.529\n",
      "Ep:202, loss:0.00000, loss_test:0.02109, lr:1.38e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.314, tt:7168.704\n",
      "Ep:203, loss:0.00000, loss_test:0.02111, lr:1.37e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.325, tt:7206.379\n",
      "Ep:204, loss:0.00000, loss_test:0.02114, lr:1.36e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.322, tt:7240.982\n",
      "Ep:205, loss:0.00000, loss_test:0.02116, lr:1.34e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.312, tt:7274.373\n",
      "Ep:206, loss:0.00000, loss_test:0.02117, lr:1.33e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.303, tt:7307.809\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14016, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:37.722, tt:37.722\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13751, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:35.920, tt:71.840\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13338, lr:1.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:35.481, tt:106.442\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12986, lr:1.00e-02, fs:0.63200 (r=0.798,p=0.523),  time:35.301, tt:141.205\n",
      "Ep:4, loss:0.00025, loss_test:0.12697, lr:1.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:34.732, tt:173.658\n",
      "Ep:5, loss:0.00024, loss_test:0.12484, lr:1.00e-02, fs:0.63677 (r=0.717,p=0.573),  time:35.152, tt:210.913\n",
      "Ep:6, loss:0.00024, loss_test:0.12266, lr:1.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:35.190, tt:246.328\n",
      "Ep:7, loss:0.00023, loss_test:0.12079, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:35.113, tt:280.900\n",
      "Ep:8, loss:0.00023, loss_test:0.11897, lr:1.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:35.491, tt:319.415\n",
      "Ep:9, loss:0.00022, loss_test:0.11647, lr:1.00e-02, fs:0.66071 (r=0.747,p=0.592),  time:35.467, tt:354.670\n",
      "Ep:10, loss:0.00022, loss_test:0.11519, lr:1.00e-02, fs:0.64815 (r=0.707,p=0.598),  time:35.505, tt:390.558\n",
      "Ep:11, loss:0.00021, loss_test:0.11358, lr:1.00e-02, fs:0.65138 (r=0.717,p=0.597),  time:35.745, tt:428.941\n",
      "Ep:12, loss:0.00021, loss_test:0.11167, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:35.914, tt:466.881\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.11027, lr:1.00e-02, fs:0.68868 (r=0.737,p=0.646),  time:36.017, tt:504.239\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10877, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:35.985, tt:539.773\n",
      "Ep:15, loss:0.00019, loss_test:0.10718, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:36.061, tt:576.980\n",
      "Ep:16, loss:0.00019, loss_test:0.10475, lr:1.00e-02, fs:0.68293 (r=0.707,p=0.660),  time:36.188, tt:615.203\n",
      "Ep:17, loss:0.00018, loss_test:0.10302, lr:1.00e-02, fs:0.67662 (r=0.687,p=0.667),  time:36.183, tt:651.299\n",
      "Ep:18, loss:0.00018, loss_test:0.10199, lr:1.00e-02, fs:0.67005 (r=0.667,p=0.673),  time:36.235, tt:688.462\n",
      "Ep:19, loss:0.00017, loss_test:0.10049, lr:1.00e-02, fs:0.67010 (r=0.657,p=0.684),  time:36.232, tt:724.638\n",
      "Ep:20, loss:0.00017, loss_test:0.10015, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:36.258, tt:761.426\n",
      "Ep:21, loss:0.00016, loss_test:0.09960, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:36.239, tt:797.253\n",
      "Ep:22, loss:0.00016, loss_test:0.10027, lr:1.00e-02, fs:0.66667 (r=0.616,p=0.726),  time:36.237, tt:833.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00015, loss_test:0.09869, lr:1.00e-02, fs:0.69474 (r=0.667,p=0.725),  time:36.243, tt:869.832\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09891, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:36.306, tt:907.643\n",
      "Ep:25, loss:0.00014, loss_test:0.09835, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:36.364, tt:945.466\n",
      "Ep:26, loss:0.00014, loss_test:0.09708, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:36.381, tt:982.298\n",
      "Ep:27, loss:0.00013, loss_test:0.09775, lr:1.00e-02, fs:0.67391 (r=0.626,p=0.729),  time:36.401, tt:1019.237\n",
      "Ep:28, loss:0.00013, loss_test:0.09764, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:36.413, tt:1055.985\n",
      "Ep:29, loss:0.00012, loss_test:0.09669, lr:1.00e-02, fs:0.66667 (r=0.606,p=0.741),  time:36.390, tt:1091.708\n",
      "Ep:30, loss:0.00012, loss_test:0.09796, lr:1.00e-02, fs:0.67039 (r=0.606,p=0.750),  time:36.397, tt:1128.299\n",
      "Ep:31, loss:0.00011, loss_test:0.09738, lr:1.00e-02, fs:0.65909 (r=0.586,p=0.753),  time:36.407, tt:1165.026\n",
      "Ep:32, loss:0.00011, loss_test:0.09648, lr:1.00e-02, fs:0.64773 (r=0.576,p=0.740),  time:36.402, tt:1201.261\n",
      "Ep:33, loss:0.00011, loss_test:0.09786, lr:1.00e-02, fs:0.67442 (r=0.586,p=0.795),  time:36.463, tt:1239.733\n",
      "Ep:34, loss:0.00010, loss_test:0.09607, lr:1.00e-02, fs:0.66286 (r=0.586,p=0.763),  time:36.509, tt:1277.813\n",
      "Ep:35, loss:0.00010, loss_test:0.09635, lr:9.90e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.543, tt:1315.535\n",
      "Ep:36, loss:0.00009, loss_test:0.09698, lr:9.80e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.536, tt:1351.837\n",
      "Ep:37, loss:0.00009, loss_test:0.09495, lr:9.70e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.563, tt:1389.395\n",
      "Ep:38, loss:0.00009, loss_test:0.09631, lr:9.61e-03, fs:0.67059 (r=0.576,p=0.803),  time:36.569, tt:1426.183\n",
      "Ep:39, loss:0.00008, loss_test:0.09453, lr:9.51e-03, fs:0.67456 (r=0.576,p=0.814),  time:36.565, tt:1462.611\n",
      "Ep:40, loss:0.00008, loss_test:0.09542, lr:9.41e-03, fs:0.66667 (r=0.576,p=0.792),  time:36.557, tt:1498.837\n",
      "Ep:41, loss:0.00008, loss_test:0.09620, lr:9.32e-03, fs:0.68293 (r=0.566,p=0.862),  time:36.571, tt:1535.975\n",
      "Ep:42, loss:0.00008, loss_test:0.09286, lr:9.23e-03, fs:0.66667 (r=0.586,p=0.773),  time:36.581, tt:1572.979\n",
      "Ep:43, loss:0.00008, loss_test:0.09934, lr:9.14e-03, fs:0.68712 (r=0.566,p=0.875),  time:36.588, tt:1609.882\n",
      "Ep:44, loss:0.00007, loss_test:0.09226, lr:9.04e-03, fs:0.66667 (r=0.576,p=0.792),  time:36.586, tt:1646.354\n",
      "Ep:45, loss:0.00007, loss_test:0.09684, lr:8.95e-03, fs:0.67470 (r=0.566,p=0.836),  time:36.562, tt:1681.863\n",
      "Ep:46, loss:0.00007, loss_test:0.09127, lr:8.86e-03, fs:0.69006 (r=0.596,p=0.819),  time:36.590, tt:1719.741\n",
      "Ep:47, loss:0.00007, loss_test:0.09741, lr:8.78e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.593, tt:1756.476\n",
      "Ep:48, loss:0.00007, loss_test:0.09088, lr:8.69e-03, fs:0.69006 (r=0.596,p=0.819),  time:36.607, tt:1793.759\n",
      "Ep:49, loss:0.00006, loss_test:0.09565, lr:8.60e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.598, tt:1829.914\n",
      "Ep:50, loss:0.00006, loss_test:0.09134, lr:8.51e-03, fs:0.69412 (r=0.596,p=0.831),  time:36.589, tt:1866.058\n",
      "Ep:51, loss:0.00006, loss_test:0.09363, lr:8.43e-03, fs:0.66667 (r=0.566,p=0.812),  time:36.573, tt:1901.811\n",
      "Ep:52, loss:0.00006, loss_test:0.09275, lr:8.35e-03, fs:0.68263 (r=0.576,p=0.838),  time:36.557, tt:1937.530\n",
      "Ep:53, loss:0.00006, loss_test:0.09429, lr:8.26e-03, fs:0.67879 (r=0.566,p=0.848),  time:36.560, tt:1974.245\n",
      "Ep:54, loss:0.00005, loss_test:0.08973, lr:8.18e-03, fs:0.66279 (r=0.576,p=0.781),  time:36.567, tt:2011.196\n",
      "Ep:55, loss:0.00005, loss_test:0.09425, lr:8.10e-03, fs:0.68293 (r=0.566,p=0.862),  time:36.541, tt:2046.307\n",
      "Ep:56, loss:0.00005, loss_test:0.08949, lr:8.02e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.517, tt:2081.481\n",
      "Ep:57, loss:0.00005, loss_test:0.09222, lr:7.94e-03, fs:0.68263 (r=0.576,p=0.838),  time:36.506, tt:2117.322\n",
      "Ep:58, loss:0.00005, loss_test:0.09172, lr:7.86e-03, fs:0.68263 (r=0.576,p=0.838),  time:36.511, tt:2154.162\n",
      "Ep:59, loss:0.00005, loss_test:0.09121, lr:7.78e-03, fs:0.68675 (r=0.576,p=0.851),  time:36.520, tt:2191.186\n",
      "Ep:60, loss:0.00005, loss_test:0.09261, lr:7.70e-03, fs:0.67470 (r=0.566,p=0.836),  time:36.538, tt:2228.842\n",
      "Ep:61, loss:0.00005, loss_test:0.08996, lr:7.62e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.550, tt:2266.130\n",
      "Ep:62, loss:0.00005, loss_test:0.09355, lr:7.55e-03, fs:0.67879 (r=0.566,p=0.848),  time:36.538, tt:2301.925\n",
      "Ep:63, loss:0.00004, loss_test:0.08959, lr:7.47e-03, fs:0.69822 (r=0.596,p=0.843),  time:36.523, tt:2337.452\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.09343, lr:7.47e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.518, tt:2373.695\n",
      "Ep:65, loss:0.00004, loss_test:0.09242, lr:7.47e-03, fs:0.68675 (r=0.576,p=0.851),  time:36.522, tt:2410.449\n",
      "Ep:66, loss:0.00004, loss_test:0.08940, lr:7.47e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.516, tt:2446.577\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.09565, lr:7.47e-03, fs:0.69512 (r=0.576,p=0.877),  time:36.492, tt:2481.467\n",
      "Ep:68, loss:0.00004, loss_test:0.08923, lr:7.47e-03, fs:0.71345 (r=0.616,p=0.847),  time:36.506, tt:2518.942\n",
      "Ep:69, loss:0.00004, loss_test:0.09229, lr:7.47e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.479, tt:2553.526\n",
      "Ep:70, loss:0.00004, loss_test:0.09206, lr:7.47e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.461, tt:2588.705\n",
      "Ep:71, loss:0.00004, loss_test:0.09064, lr:7.47e-03, fs:0.71006 (r=0.606,p=0.857),  time:36.472, tt:2626.000\n",
      "Ep:72, loss:0.00004, loss_test:0.09309, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.464, tt:2661.841\n",
      "Ep:73, loss:0.00004, loss_test:0.08968, lr:7.47e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.441, tt:2696.628\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.09360, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.430, tt:2732.260\n",
      "Ep:75, loss:0.00004, loss_test:0.09116, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.418, tt:2767.800\n",
      "Ep:76, loss:0.00003, loss_test:0.09279, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.408, tt:2803.435\n",
      "Ep:77, loss:0.00003, loss_test:0.09269, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.426, tt:2841.242\n",
      "Ep:78, loss:0.00003, loss_test:0.09173, lr:7.47e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.415, tt:2876.770\n",
      "Ep:79, loss:0.00003, loss_test:0.09335, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.416, tt:2913.318\n",
      "Ep:80, loss:0.00003, loss_test:0.09233, lr:7.47e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.436, tt:2951.308\n",
      "Ep:81, loss:0.00003, loss_test:0.09348, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.422, tt:2986.615\n",
      "Ep:82, loss:0.00003, loss_test:0.09174, lr:7.47e-03, fs:0.72619 (r=0.616,p=0.884),  time:36.428, tt:3023.565\n",
      "Ep:83, loss:0.00003, loss_test:0.09239, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:36.423, tt:3059.536\n",
      "Ep:84, loss:0.00003, loss_test:0.09297, lr:7.47e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.420, tt:3095.686\n",
      "Ep:85, loss:0.00003, loss_test:0.09240, lr:7.40e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.426, tt:3132.613\n",
      "Ep:86, loss:0.00003, loss_test:0.09273, lr:7.32e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.403, tt:3167.048\n",
      "Ep:87, loss:0.00003, loss_test:0.09250, lr:7.25e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.390, tt:3202.344\n",
      "Ep:88, loss:0.00003, loss_test:0.09307, lr:7.18e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.356, tt:3235.702\n",
      "Ep:89, loss:0.00003, loss_test:0.09361, lr:7.11e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.339, tt:3270.490\n",
      "Ep:90, loss:0.00003, loss_test:0.09272, lr:7.03e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.326, tt:3305.673\n",
      "Ep:91, loss:0.00003, loss_test:0.09529, lr:6.96e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.314, tt:3340.903\n",
      "Ep:92, loss:0.00003, loss_test:0.09206, lr:6.89e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.295, tt:3375.398\n",
      "Ep:93, loss:0.00003, loss_test:0.09495, lr:6.83e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.293, tt:3411.504\n",
      "Ep:94, loss:0.00003, loss_test:0.09486, lr:6.76e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.305, tt:3448.937\n",
      "Ep:95, loss:0.00003, loss_test:0.09436, lr:6.69e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.307, tt:3485.520\n",
      "Ep:96, loss:0.00002, loss_test:0.09537, lr:6.62e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.296, tt:3520.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00002, loss_test:0.09289, lr:6.56e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.313, tt:3558.640\n",
      "Ep:98, loss:0.00002, loss_test:0.09547, lr:6.49e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.324, tt:3596.054\n",
      "Ep:99, loss:0.00002, loss_test:0.09409, lr:6.43e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.324, tt:3632.398\n",
      "Ep:100, loss:0.00002, loss_test:0.09416, lr:6.36e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.332, tt:3669.553\n",
      "Ep:101, loss:0.00002, loss_test:0.09524, lr:6.30e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.335, tt:3706.197\n",
      "Ep:102, loss:0.00002, loss_test:0.09284, lr:6.24e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.330, tt:3742.009\n",
      "Ep:103, loss:0.00002, loss_test:0.09557, lr:6.17e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.311, tt:3776.356\n",
      "Ep:104, loss:0.00002, loss_test:0.09355, lr:6.11e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.314, tt:3812.931\n",
      "Ep:105, loss:0.00002, loss_test:0.09617, lr:6.05e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.310, tt:3848.854\n",
      "Ep:106, loss:0.00002, loss_test:0.09454, lr:5.99e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.304, tt:3884.509\n",
      "Ep:107, loss:0.00002, loss_test:0.09662, lr:5.93e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.291, tt:3919.480\n",
      "Ep:108, loss:0.00002, loss_test:0.09558, lr:5.87e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.287, tt:3955.287\n",
      "Ep:109, loss:0.00002, loss_test:0.09494, lr:5.81e-03, fs:0.71006 (r=0.606,p=0.857),  time:36.279, tt:3990.647\n",
      "Ep:110, loss:0.00002, loss_test:0.09682, lr:5.75e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.278, tt:4026.862\n",
      "Ep:111, loss:0.00002, loss_test:0.09470, lr:5.70e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.275, tt:4062.745\n",
      "Ep:112, loss:0.00002, loss_test:0.09644, lr:5.64e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.268, tt:4098.283\n",
      "Ep:113, loss:0.00002, loss_test:0.09572, lr:5.58e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.268, tt:4134.510\n",
      "Ep:114, loss:0.00002, loss_test:0.09535, lr:5.53e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.266, tt:4170.641\n",
      "Ep:115, loss:0.00002, loss_test:0.09636, lr:5.47e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.264, tt:4206.580\n",
      "Ep:116, loss:0.00002, loss_test:0.09599, lr:5.42e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.275, tt:4244.186\n",
      "Ep:117, loss:0.00002, loss_test:0.09557, lr:5.36e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.277, tt:4280.718\n",
      "Ep:118, loss:0.00002, loss_test:0.09625, lr:5.31e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.273, tt:4316.536\n",
      "Ep:119, loss:0.00002, loss_test:0.09694, lr:5.26e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.267, tt:4352.039\n",
      "Ep:120, loss:0.00002, loss_test:0.09532, lr:5.20e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.267, tt:4388.358\n",
      "Ep:121, loss:0.00002, loss_test:0.09755, lr:5.15e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.264, tt:4424.156\n",
      "Ep:122, loss:0.00002, loss_test:0.09579, lr:5.10e-03, fs:0.71006 (r=0.606,p=0.857),  time:36.270, tt:4461.199\n",
      "Ep:123, loss:0.00002, loss_test:0.09686, lr:5.05e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.272, tt:4497.774\n",
      "Ep:124, loss:0.00002, loss_test:0.09661, lr:5.00e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.270, tt:4533.788\n",
      "Ep:125, loss:0.00002, loss_test:0.09647, lr:4.95e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.275, tt:4570.643\n",
      "Ep:126, loss:0.00002, loss_test:0.09748, lr:4.90e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.283, tt:4607.934\n",
      "Ep:127, loss:0.00002, loss_test:0.09668, lr:4.85e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.277, tt:4643.472\n",
      "Ep:128, loss:0.00002, loss_test:0.09770, lr:4.80e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.280, tt:4680.175\n",
      "Ep:129, loss:0.00002, loss_test:0.09709, lr:4.75e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.296, tt:4718.434\n",
      "Ep:130, loss:0.00002, loss_test:0.09633, lr:4.71e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.304, tt:4755.811\n",
      "Ep:131, loss:0.00002, loss_test:0.09784, lr:4.66e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.302, tt:4791.921\n",
      "Ep:132, loss:0.00002, loss_test:0.09716, lr:4.61e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.314, tt:4829.747\n",
      "Ep:133, loss:0.00002, loss_test:0.09830, lr:4.57e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.313, tt:4865.999\n",
      "Ep:134, loss:0.00002, loss_test:0.09780, lr:4.52e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.299, tt:4900.423\n",
      "Ep:135, loss:0.00002, loss_test:0.09654, lr:4.48e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.311, tt:4938.247\n",
      "Ep:136, loss:0.00002, loss_test:0.09838, lr:4.43e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.296, tt:4972.501\n",
      "Ep:137, loss:0.00002, loss_test:0.09929, lr:4.39e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.299, tt:5009.259\n",
      "Ep:138, loss:0.00002, loss_test:0.09761, lr:4.34e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.288, tt:5044.026\n",
      "Ep:139, loss:0.00002, loss_test:0.09807, lr:4.30e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.280, tt:5079.257\n",
      "Ep:140, loss:0.00002, loss_test:0.09892, lr:4.26e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.283, tt:5115.915\n",
      "Ep:141, loss:0.00002, loss_test:0.09804, lr:4.21e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.280, tt:5151.742\n",
      "Ep:142, loss:0.00002, loss_test:0.09921, lr:4.17e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.273, tt:5187.100\n",
      "Ep:143, loss:0.00002, loss_test:0.09904, lr:4.13e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.277, tt:5223.927\n",
      "Ep:144, loss:0.00002, loss_test:0.09712, lr:4.09e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.274, tt:5259.733\n",
      "Ep:145, loss:0.00002, loss_test:0.09951, lr:4.05e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.270, tt:5295.421\n",
      "Ep:146, loss:0.00001, loss_test:0.09902, lr:4.01e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.272, tt:5332.005\n",
      "Ep:147, loss:0.00001, loss_test:0.09783, lr:3.97e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.255, tt:5365.812\n",
      "Ep:148, loss:0.00001, loss_test:0.09961, lr:3.93e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.251, tt:5401.451\n",
      "Ep:149, loss:0.00001, loss_test:0.09866, lr:3.89e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.247, tt:5437.111\n",
      "Ep:150, loss:0.00001, loss_test:0.09798, lr:3.85e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.244, tt:5472.809\n",
      "Ep:151, loss:0.00001, loss_test:0.09913, lr:3.81e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.238, tt:5508.200\n",
      "Ep:152, loss:0.00001, loss_test:0.09898, lr:3.77e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.236, tt:5544.079\n",
      "Ep:153, loss:0.00001, loss_test:0.09834, lr:3.73e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.233, tt:5579.942\n",
      "Ep:154, loss:0.00001, loss_test:0.09972, lr:3.70e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.241, tt:5617.351\n",
      "Ep:155, loss:0.00001, loss_test:0.09850, lr:3.66e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.235, tt:5652.677\n",
      "Ep:156, loss:0.00001, loss_test:0.09835, lr:3.62e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.228, tt:5687.832\n",
      "Ep:157, loss:0.00001, loss_test:0.09993, lr:3.59e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.236, tt:5725.281\n",
      "Ep:158, loss:0.00001, loss_test:0.09915, lr:3.55e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.236, tt:5761.557\n",
      "Ep:159, loss:0.00001, loss_test:0.09876, lr:3.52e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.243, tt:5798.889\n",
      "Ep:160, loss:0.00001, loss_test:0.09927, lr:3.48e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.238, tt:5834.353\n",
      "Ep:161, loss:0.00001, loss_test:0.10037, lr:3.45e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.244, tt:5871.577\n",
      "Ep:162, loss:0.00001, loss_test:0.09897, lr:3.41e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.257, tt:5909.908\n",
      "Ep:163, loss:0.00001, loss_test:0.09967, lr:3.38e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.265, tt:5947.496\n",
      "Ep:164, loss:0.00001, loss_test:0.10027, lr:3.34e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.272, tt:5984.859\n",
      "Ep:165, loss:0.00001, loss_test:0.09918, lr:3.31e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.274, tt:6021.462\n",
      "Ep:166, loss:0.00001, loss_test:0.09938, lr:3.28e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.279, tt:6058.622\n",
      "Ep:167, loss:0.00001, loss_test:0.09981, lr:3.24e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.282, tt:6095.321\n",
      "Ep:168, loss:0.00001, loss_test:0.09922, lr:3.21e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.283, tt:6131.832\n",
      "Ep:169, loss:0.00001, loss_test:0.09947, lr:3.18e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.287, tt:6168.787\n",
      "Ep:170, loss:0.00001, loss_test:0.09955, lr:3.15e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.285, tt:6204.649\n",
      "Ep:171, loss:0.00001, loss_test:0.09991, lr:3.12e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.283, tt:6240.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:172, loss:0.00001, loss_test:0.09930, lr:3.09e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.285, tt:6277.302\n",
      "Ep:173, loss:0.00001, loss_test:0.09976, lr:3.05e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.293, tt:6314.968\n",
      "Ep:174, loss:0.00001, loss_test:0.09941, lr:3.02e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.293, tt:6351.351\n",
      "Ep:175, loss:0.00001, loss_test:0.09935, lr:2.99e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.296, tt:6388.089\n",
      "Ep:176, loss:0.00001, loss_test:0.10015, lr:2.96e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.288, tt:6422.888\n",
      "Ep:177, loss:0.00001, loss_test:0.09985, lr:2.93e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.290, tt:6459.703\n",
      "Ep:178, loss:0.00001, loss_test:0.09939, lr:2.90e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.299, tt:6497.534\n",
      "Ep:179, loss:0.00001, loss_test:0.10011, lr:2.88e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.303, tt:6534.594\n",
      "Ep:180, loss:0.00001, loss_test:0.10003, lr:2.85e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.310, tt:6572.046\n",
      "Ep:181, loss:0.00001, loss_test:0.09923, lr:2.82e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.308, tt:6607.993\n",
      "Ep:182, loss:0.00001, loss_test:0.09995, lr:2.79e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.303, tt:6643.514\n",
      "Ep:183, loss:0.00001, loss_test:0.10058, lr:2.76e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.311, tt:6681.153\n",
      "Ep:184, loss:0.00001, loss_test:0.09965, lr:2.73e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.312, tt:6717.732\n",
      "Ep:185, loss:0.00001, loss_test:0.09970, lr:2.71e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.317, tt:6754.915\n",
      "Ep:186, loss:0.00001, loss_test:0.10030, lr:2.68e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.313, tt:6790.606\n",
      "Ep:187, loss:0.00001, loss_test:0.09973, lr:2.65e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.318, tt:6827.769\n",
      "Ep:188, loss:0.00001, loss_test:0.09940, lr:2.63e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.323, tt:6865.027\n",
      "Ep:189, loss:0.00001, loss_test:0.10049, lr:2.60e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.320, tt:6900.886\n",
      "Ep:190, loss:0.00001, loss_test:0.09994, lr:2.57e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.318, tt:6936.790\n",
      "Ep:191, loss:0.00001, loss_test:0.09951, lr:2.55e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.319, tt:6973.290\n",
      "Ep:192, loss:0.00001, loss_test:0.10036, lr:2.52e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.322, tt:7010.097\n",
      "Ep:193, loss:0.00001, loss_test:0.10020, lr:2.50e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.320, tt:7046.089\n",
      "Ep:194, loss:0.00001, loss_test:0.09968, lr:2.47e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.311, tt:7080.739\n",
      "Ep:195, loss:0.00001, loss_test:0.10061, lr:2.45e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.309, tt:7116.630\n",
      "Ep:196, loss:0.00001, loss_test:0.10058, lr:2.42e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.300, tt:7151.029\n",
      "Ep:197, loss:0.00001, loss_test:0.09999, lr:2.40e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.299, tt:7187.156\n",
      "Ep:198, loss:0.00001, loss_test:0.10017, lr:2.38e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.300, tt:7223.775\n",
      "Ep:199, loss:0.00001, loss_test:0.09998, lr:2.35e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.306, tt:7261.106\n",
      "Ep:200, loss:0.00001, loss_test:0.10006, lr:2.33e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.305, tt:7297.284\n",
      "Ep:201, loss:0.00001, loss_test:0.09995, lr:2.31e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.308, tt:7334.291\n",
      "Ep:202, loss:0.00001, loss_test:0.10029, lr:2.28e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.307, tt:7370.396\n",
      "Ep:203, loss:0.00001, loss_test:0.09995, lr:2.26e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.305, tt:7406.162\n",
      "Ep:204, loss:0.00001, loss_test:0.10017, lr:2.24e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.308, tt:7443.109\n",
      "Ep:205, loss:0.00001, loss_test:0.09991, lr:2.21e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.298, tt:7477.489\n",
      "Ep:206, loss:0.00001, loss_test:0.10020, lr:2.19e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.286, tt:7511.265\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02462, lr:6.00e-02, fs:0.62069 (r=0.818,p=0.500),  time:29.445, tt:29.445\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02630, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:29.339, tt:58.679\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02781, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.893, tt:86.680\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02805, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.715, tt:118.860\n",
      "Ep:4, loss:0.00005, loss_test:0.02723, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:30.244, tt:151.219\n",
      "Ep:5, loss:0.00005, loss_test:0.02608, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:30.299, tt:181.795\n",
      "Ep:6, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:30.986, tt:216.902\n",
      "Ep:7, loss:0.00004, loss_test:0.02455, lr:6.00e-02, fs:0.63359 (r=0.838,p=0.509),  time:31.300, tt:250.400\n",
      "Ep:8, loss:0.00004, loss_test:0.02410, lr:6.00e-02, fs:0.62257 (r=0.808,p=0.506),  time:31.555, tt:283.999\n",
      "Ep:9, loss:0.00004, loss_test:0.02313, lr:6.00e-02, fs:0.64093 (r=0.838,p=0.519),  time:31.836, tt:318.359\n",
      "Ep:10, loss:0.00004, loss_test:0.02226, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:32.157, tt:353.730\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02171, lr:6.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:32.412, tt:388.938\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02129, lr:6.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:32.571, tt:423.419\n",
      "Ep:13, loss:0.00004, loss_test:0.02092, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:32.848, tt:459.877\n",
      "Ep:14, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:33.083, tt:496.240\n",
      "Ep:15, loss:0.00004, loss_test:0.02022, lr:6.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:33.206, tt:531.304\n",
      "Ep:16, loss:0.00003, loss_test:0.01953, lr:6.00e-02, fs:0.66667 (r=0.879,p=0.537),  time:33.374, tt:567.352\n",
      "Ep:17, loss:0.00003, loss_test:0.01890, lr:6.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:33.522, tt:603.395\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01834, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:33.674, tt:639.808\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01790, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:33.721, tt:674.417\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01756, lr:6.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:33.758, tt:708.908\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01728, lr:6.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:33.808, tt:743.781\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:33.831, tt:778.118\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01652, lr:6.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:33.988, tt:815.714\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01616, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.051, tt:851.279\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:34.156, tt:888.061\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:34.239, tt:924.464\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.256, tt:959.180\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01518, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.326, tt:995.440\n",
      "Ep:29, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:34.371, tt:1031.127\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01497, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:34.452, tt:1067.998\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.472, tt:1103.091\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.556, tt:1140.343\n",
      "Ep:33, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:34.591, tt:1176.086\n",
      "Ep:34, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:34.612, tt:1211.414\n",
      "Ep:35, loss:0.00002, loss_test:0.01435, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:34.691, tt:1248.884\n",
      "Ep:36, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:34.698, tt:1283.827\n",
      "Ep:37, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:34.733, tt:1319.867\n",
      "Ep:38, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:34.746, tt:1355.107\n",
      "Ep:39, loss:0.00002, loss_test:0.01410, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:34.754, tt:1390.149\n",
      "Ep:40, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:34.782, tt:1426.077\n",
      "Ep:41, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.778, tt:1460.681\n",
      "Ep:42, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.786, tt:1495.781\n",
      "Ep:43, loss:0.00002, loss_test:0.01402, lr:5.94e-02, fs:0.79245 (r=0.848,p=0.743),  time:34.801, tt:1531.232\n",
      "Ep:44, loss:0.00002, loss_test:0.01392, lr:5.88e-02, fs:0.79048 (r=0.838,p=0.748),  time:34.804, tt:1566.187\n",
      "Ep:45, loss:0.00002, loss_test:0.01389, lr:5.82e-02, fs:0.79048 (r=0.838,p=0.748),  time:34.827, tt:1602.054\n",
      "Ep:46, loss:0.00002, loss_test:0.01394, lr:5.76e-02, fs:0.77073 (r=0.798,p=0.745),  time:34.838, tt:1637.386\n",
      "Ep:47, loss:0.00002, loss_test:0.01396, lr:5.71e-02, fs:0.77073 (r=0.798,p=0.745),  time:34.876, tt:1674.051\n",
      "Ep:48, loss:0.00001, loss_test:0.01404, lr:5.65e-02, fs:0.78218 (r=0.798,p=0.767),  time:34.898, tt:1709.986\n",
      "Ep:49, loss:0.00001, loss_test:0.01392, lr:5.59e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.917, tt:1745.865\n",
      "Ep:50, loss:0.00001, loss_test:0.01409, lr:5.54e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.910, tt:1780.421\n",
      "Ep:51, loss:0.00001, loss_test:0.01402, lr:5.48e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.921, tt:1815.872\n",
      "Ep:52, loss:0.00001, loss_test:0.01410, lr:5.43e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.922, tt:1850.868\n",
      "Ep:53, loss:0.00001, loss_test:0.01414, lr:5.37e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.926, tt:1886.004\n",
      "Ep:54, loss:0.00001, loss_test:0.01427, lr:5.32e-02, fs:0.75789 (r=0.727,p=0.791),  time:34.946, tt:1922.025\n",
      "Ep:55, loss:0.00001, loss_test:0.01429, lr:5.27e-02, fs:0.75789 (r=0.727,p=0.791),  time:34.947, tt:1957.036\n",
      "Ep:56, loss:0.00001, loss_test:0.01434, lr:5.21e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.962, tt:1992.833\n",
      "Ep:57, loss:0.00001, loss_test:0.01446, lr:5.16e-02, fs:0.75789 (r=0.727,p=0.791),  time:34.992, tt:2029.532\n",
      "Ep:58, loss:0.00001, loss_test:0.01436, lr:5.11e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.986, tt:2064.202\n",
      "Ep:59, loss:0.00001, loss_test:0.01454, lr:5.06e-02, fs:0.76190 (r=0.727,p=0.800),  time:35.034, tt:2102.037\n",
      "Ep:60, loss:0.00001, loss_test:0.01460, lr:5.01e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.054, tt:2138.316\n",
      "Ep:61, loss:0.00001, loss_test:0.01454, lr:4.96e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.056, tt:2173.495\n",
      "Ep:62, loss:0.00001, loss_test:0.01466, lr:4.91e-02, fs:0.75936 (r=0.717,p=0.807),  time:35.057, tt:2208.600\n",
      "Ep:63, loss:0.00001, loss_test:0.01484, lr:4.86e-02, fs:0.73913 (r=0.687,p=0.800),  time:35.092, tt:2245.882\n",
      "Ep:64, loss:0.00001, loss_test:0.01465, lr:4.81e-02, fs:0.75269 (r=0.707,p=0.805),  time:35.113, tt:2282.348\n",
      "Ep:65, loss:0.00001, loss_test:0.01475, lr:4.76e-02, fs:0.75269 (r=0.707,p=0.805),  time:35.130, tt:2318.561\n",
      "Ep:66, loss:0.00001, loss_test:0.01502, lr:4.71e-02, fs:0.72527 (r=0.667,p=0.795),  time:35.130, tt:2353.719\n",
      "Ep:67, loss:0.00001, loss_test:0.01496, lr:4.67e-02, fs:0.73224 (r=0.677,p=0.798),  time:35.132, tt:2388.942\n",
      "Ep:68, loss:0.00001, loss_test:0.01499, lr:4.62e-02, fs:0.73224 (r=0.677,p=0.798),  time:35.095, tt:2421.545\n",
      "Ep:69, loss:0.00001, loss_test:0.01532, lr:4.57e-02, fs:0.72222 (r=0.657,p=0.802),  time:35.087, tt:2456.059\n",
      "Ep:70, loss:0.00001, loss_test:0.01520, lr:4.53e-02, fs:0.71823 (r=0.657,p=0.793),  time:35.083, tt:2490.922\n",
      "Ep:71, loss:0.00001, loss_test:0.01549, lr:4.48e-02, fs:0.71823 (r=0.657,p=0.793),  time:35.051, tt:2523.677\n",
      "Ep:72, loss:0.00001, loss_test:0.01535, lr:4.44e-02, fs:0.72928 (r=0.667,p=0.805),  time:35.046, tt:2558.348\n",
      "Ep:73, loss:0.00001, loss_test:0.01548, lr:4.39e-02, fs:0.72222 (r=0.657,p=0.802),  time:35.021, tt:2591.547\n",
      "Ep:74, loss:0.00001, loss_test:0.01566, lr:4.35e-02, fs:0.72222 (r=0.657,p=0.802),  time:34.999, tt:2624.922\n",
      "Ep:75, loss:0.00001, loss_test:0.01585, lr:4.31e-02, fs:0.72626 (r=0.657,p=0.812),  time:34.977, tt:2658.224\n",
      "Ep:76, loss:0.00001, loss_test:0.01574, lr:4.26e-02, fs:0.72222 (r=0.657,p=0.802),  time:34.957, tt:2691.651\n",
      "Ep:77, loss:0.00001, loss_test:0.01574, lr:4.22e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.960, tt:2726.847\n",
      "Ep:78, loss:0.00001, loss_test:0.01610, lr:4.18e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.976, tt:2763.083\n",
      "Ep:79, loss:0.00001, loss_test:0.01600, lr:4.14e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.954, tt:2796.336\n",
      "Ep:80, loss:0.00001, loss_test:0.01614, lr:4.10e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.962, tt:2831.943\n",
      "Ep:81, loss:0.00001, loss_test:0.01613, lr:4.05e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.940, tt:2865.074\n",
      "Ep:82, loss:0.00001, loss_test:0.01636, lr:4.01e-02, fs:0.72832 (r=0.636,p=0.851),  time:34.933, tt:2899.474\n",
      "Ep:83, loss:0.00001, loss_test:0.01632, lr:3.97e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.921, tt:2933.389\n",
      "Ep:84, loss:0.00001, loss_test:0.01641, lr:3.93e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.902, tt:2966.699\n",
      "Ep:85, loss:0.00001, loss_test:0.01640, lr:3.89e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.903, tt:3001.677\n",
      "Ep:86, loss:0.00001, loss_test:0.01679, lr:3.86e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.868, tt:3033.492\n",
      "Ep:87, loss:0.00001, loss_test:0.01656, lr:3.82e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.859, tt:3067.603\n",
      "Ep:88, loss:0.00001, loss_test:0.01677, lr:3.78e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.864, tt:3102.922\n",
      "Ep:89, loss:0.00001, loss_test:0.01700, lr:3.74e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.844, tt:3135.987\n",
      "Ep:90, loss:0.00001, loss_test:0.01684, lr:3.70e-02, fs:0.72515 (r=0.626,p=0.861),  time:34.837, tt:3170.205\n",
      "Ep:91, loss:0.00001, loss_test:0.01710, lr:3.67e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.814, tt:3202.869\n",
      "Ep:92, loss:0.00001, loss_test:0.01708, lr:3.63e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.816, tt:3237.861\n",
      "Ep:93, loss:0.00001, loss_test:0.01744, lr:3.59e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.813, tt:3272.423\n",
      "Ep:94, loss:0.00001, loss_test:0.01732, lr:3.56e-02, fs:0.72515 (r=0.626,p=0.861),  time:34.795, tt:3305.486\n",
      "Ep:95, loss:0.00001, loss_test:0.01734, lr:3.52e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.780, tt:3338.862\n",
      "Ep:96, loss:0.00001, loss_test:0.01742, lr:3.49e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.759, tt:3371.577\n",
      "Ep:97, loss:0.00001, loss_test:0.01757, lr:3.45e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.768, tt:3407.251\n",
      "Ep:98, loss:0.00001, loss_test:0.01764, lr:3.42e-02, fs:0.72515 (r=0.626,p=0.861),  time:34.782, tt:3443.455\n",
      "Ep:99, loss:0.00001, loss_test:0.01777, lr:3.38e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.777, tt:3477.682\n",
      "Ep:100, loss:0.00001, loss_test:0.01782, lr:3.35e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.779, tt:3512.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00001, loss_test:0.01795, lr:3.32e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.766, tt:3546.181\n",
      "Ep:102, loss:0.00001, loss_test:0.01802, lr:3.28e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.770, tt:3581.321\n",
      "Ep:103, loss:0.00001, loss_test:0.01803, lr:3.25e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.784, tt:3617.501\n",
      "Ep:104, loss:0.00001, loss_test:0.01824, lr:3.22e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.784, tt:3652.332\n",
      "Ep:105, loss:0.00001, loss_test:0.01815, lr:3.19e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.782, tt:3686.856\n",
      "Ep:106, loss:0.00001, loss_test:0.01849, lr:3.15e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.771, tt:3720.458\n",
      "Ep:107, loss:0.00001, loss_test:0.01841, lr:3.12e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.770, tt:3755.129\n",
      "Ep:108, loss:0.00001, loss_test:0.01849, lr:3.09e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.770, tt:3789.888\n",
      "Ep:109, loss:0.00001, loss_test:0.01866, lr:3.06e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.768, tt:3824.483\n",
      "Ep:110, loss:0.00001, loss_test:0.01878, lr:3.03e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.768, tt:3859.293\n",
      "Ep:111, loss:0.00001, loss_test:0.01867, lr:3.00e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.772, tt:3894.495\n",
      "Ep:112, loss:0.00001, loss_test:0.01902, lr:2.97e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.788, tt:3930.990\n",
      "Ep:113, loss:0.00001, loss_test:0.01892, lr:2.94e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.776, tt:3964.506\n",
      "Ep:114, loss:0.00001, loss_test:0.01906, lr:2.91e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.765, tt:3997.973\n",
      "Ep:115, loss:0.00001, loss_test:0.01916, lr:2.88e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.751, tt:4031.123\n",
      "Ep:116, loss:0.00001, loss_test:0.01922, lr:2.85e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.743, tt:4064.931\n",
      "Ep:117, loss:0.00001, loss_test:0.01920, lr:2.82e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.737, tt:4099.010\n",
      "Ep:118, loss:0.00000, loss_test:0.01945, lr:2.80e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.747, tt:4134.898\n",
      "Ep:119, loss:0.00000, loss_test:0.01948, lr:2.77e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.749, tt:4169.912\n",
      "Ep:120, loss:0.00000, loss_test:0.01939, lr:2.74e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.749, tt:4204.640\n",
      "Ep:121, loss:0.00000, loss_test:0.01964, lr:2.71e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.745, tt:4238.863\n",
      "Ep:122, loss:0.00000, loss_test:0.01952, lr:2.69e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.746, tt:4273.729\n",
      "Ep:123, loss:0.00000, loss_test:0.01968, lr:2.66e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.761, tt:4310.324\n",
      "Ep:124, loss:0.00000, loss_test:0.01979, lr:2.63e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.778, tt:4347.263\n",
      "Ep:125, loss:0.00000, loss_test:0.02000, lr:2.61e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.788, tt:4383.283\n",
      "Ep:126, loss:0.00000, loss_test:0.01986, lr:2.58e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.789, tt:4418.183\n",
      "Ep:127, loss:0.00000, loss_test:0.02000, lr:2.55e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.790, tt:4453.086\n",
      "Ep:128, loss:0.00000, loss_test:0.02003, lr:2.53e-02, fs:0.70238 (r=0.596,p=0.855),  time:34.794, tt:4488.435\n",
      "Ep:129, loss:0.00000, loss_test:0.02019, lr:2.50e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.795, tt:4523.317\n",
      "Ep:130, loss:0.00000, loss_test:0.02023, lr:2.48e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.800, tt:4558.808\n",
      "Ep:131, loss:0.00000, loss_test:0.02038, lr:2.45e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.805, tt:4594.215\n",
      "Ep:132, loss:0.00000, loss_test:0.02040, lr:2.43e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.801, tt:4628.491\n",
      "Ep:133, loss:0.00000, loss_test:0.02042, lr:2.40e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.802, tt:4663.414\n",
      "Ep:134, loss:0.00000, loss_test:0.02051, lr:2.38e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.810, tt:4699.284\n",
      "Ep:135, loss:0.00000, loss_test:0.02056, lr:2.36e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.819, tt:4735.358\n",
      "Ep:136, loss:0.00000, loss_test:0.02073, lr:2.33e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.812, tt:4769.289\n",
      "Ep:137, loss:0.00000, loss_test:0.02074, lr:2.31e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.828, tt:4806.312\n",
      "Ep:138, loss:0.00000, loss_test:0.02078, lr:2.29e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.832, tt:4841.584\n",
      "Ep:139, loss:0.00000, loss_test:0.02080, lr:2.26e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.836, tt:4877.006\n",
      "Ep:140, loss:0.00000, loss_test:0.02081, lr:2.24e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.846, tt:4913.249\n",
      "Ep:141, loss:0.00000, loss_test:0.02095, lr:2.22e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.847, tt:4948.233\n",
      "Ep:142, loss:0.00000, loss_test:0.02105, lr:2.20e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.853, tt:4984.016\n",
      "Ep:143, loss:0.00000, loss_test:0.02104, lr:2.17e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.863, tt:5020.328\n",
      "Ep:144, loss:0.00000, loss_test:0.02113, lr:2.15e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.865, tt:5055.458\n",
      "Ep:145, loss:0.00000, loss_test:0.02117, lr:2.13e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.878, tt:5092.141\n",
      "Ep:146, loss:0.00000, loss_test:0.02122, lr:2.11e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.875, tt:5126.554\n",
      "Ep:147, loss:0.00000, loss_test:0.02123, lr:2.09e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.886, tt:5163.189\n",
      "Ep:148, loss:0.00000, loss_test:0.02139, lr:2.07e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.891, tt:5198.736\n",
      "Ep:149, loss:0.00000, loss_test:0.02138, lr:2.05e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.891, tt:5233.723\n",
      "Ep:150, loss:0.00000, loss_test:0.02152, lr:2.03e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.896, tt:5269.327\n",
      "Ep:151, loss:0.00000, loss_test:0.02155, lr:2.01e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.909, tt:5306.174\n",
      "Ep:152, loss:0.00000, loss_test:0.02148, lr:1.99e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.908, tt:5340.934\n",
      "Ep:153, loss:0.00000, loss_test:0.02161, lr:1.97e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.915, tt:5376.875\n",
      "Ep:154, loss:0.00000, loss_test:0.02160, lr:1.95e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.919, tt:5412.379\n",
      "Ep:155, loss:0.00000, loss_test:0.02173, lr:1.93e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.926, tt:5448.422\n",
      "Ep:156, loss:0.00000, loss_test:0.02178, lr:1.91e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.920, tt:5482.367\n",
      "Ep:157, loss:0.00000, loss_test:0.02180, lr:1.89e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.920, tt:5517.379\n",
      "Ep:158, loss:0.00000, loss_test:0.02187, lr:1.87e-02, fs:0.69880 (r=0.586,p=0.866),  time:34.923, tt:5552.788\n",
      "Ep:159, loss:0.00000, loss_test:0.02193, lr:1.85e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.921, tt:5587.405\n",
      "Ep:160, loss:0.00000, loss_test:0.02195, lr:1.83e-02, fs:0.69091 (r=0.576,p=0.864),  time:34.925, tt:5622.923\n",
      "Ep:161, loss:0.00000, loss_test:0.02200, lr:1.81e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.925, tt:5657.842\n",
      "Ep:162, loss:0.00000, loss_test:0.02203, lr:1.80e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.923, tt:5692.428\n",
      "Ep:163, loss:0.00000, loss_test:0.02210, lr:1.78e-02, fs:0.68712 (r=0.566,p=0.875),  time:34.931, tt:5728.680\n",
      "Ep:164, loss:0.00000, loss_test:0.02214, lr:1.76e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.938, tt:5764.802\n",
      "Ep:165, loss:0.00000, loss_test:0.02221, lr:1.74e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.938, tt:5799.769\n",
      "Ep:166, loss:0.00000, loss_test:0.02224, lr:1.73e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.945, tt:5835.736\n",
      "Ep:167, loss:0.00000, loss_test:0.02231, lr:1.71e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.948, tt:5871.231\n",
      "Ep:168, loss:0.00000, loss_test:0.02234, lr:1.69e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.952, tt:5906.908\n",
      "Ep:169, loss:0.00000, loss_test:0.02233, lr:1.67e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.952, tt:5941.831\n",
      "Ep:170, loss:0.00000, loss_test:0.02236, lr:1.66e-02, fs:0.68712 (r=0.566,p=0.875),  time:34.965, tt:5979.014\n",
      "Ep:171, loss:0.00000, loss_test:0.02245, lr:1.64e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.976, tt:6015.841\n",
      "Ep:172, loss:0.00000, loss_test:0.02253, lr:1.62e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.981, tt:6051.748\n",
      "Ep:173, loss:0.00000, loss_test:0.02256, lr:1.61e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.985, tt:6087.403\n",
      "Ep:174, loss:0.00000, loss_test:0.02263, lr:1.59e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.989, tt:6123.104\n",
      "Ep:175, loss:0.00000, loss_test:0.02258, lr:1.58e-02, fs:0.68712 (r=0.566,p=0.875),  time:34.994, tt:6158.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:176, loss:0.00000, loss_test:0.02262, lr:1.56e-02, fs:0.68712 (r=0.566,p=0.875),  time:34.996, tt:6194.283\n",
      "Ep:177, loss:0.00000, loss_test:0.02274, lr:1.54e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.991, tt:6228.332\n",
      "Ep:178, loss:0.00000, loss_test:0.02280, lr:1.53e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.988, tt:6262.842\n",
      "Ep:179, loss:0.00000, loss_test:0.02275, lr:1.51e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.984, tt:6297.145\n",
      "Ep:180, loss:0.00000, loss_test:0.02277, lr:1.50e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.011, tt:6337.053\n",
      "Ep:181, loss:0.00000, loss_test:0.02296, lr:1.48e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.012, tt:6372.170\n",
      "Ep:182, loss:0.00000, loss_test:0.02288, lr:1.47e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.019, tt:6408.406\n",
      "Ep:183, loss:0.00000, loss_test:0.02288, lr:1.45e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.019, tt:6443.538\n",
      "Ep:184, loss:0.00000, loss_test:0.02297, lr:1.44e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.026, tt:6479.831\n",
      "Ep:185, loss:0.00000, loss_test:0.02300, lr:1.43e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.032, tt:6515.896\n",
      "Ep:186, loss:0.00000, loss_test:0.02305, lr:1.41e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.040, tt:6552.413\n",
      "Ep:187, loss:0.00000, loss_test:0.02309, lr:1.40e-02, fs:0.69512 (r=0.576,p=0.877),  time:35.055, tt:6590.394\n",
      "Ep:188, loss:0.00000, loss_test:0.02312, lr:1.38e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.067, tt:6627.720\n",
      "Ep:189, loss:0.00000, loss_test:0.02317, lr:1.37e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.068, tt:6663.012\n",
      "Ep:190, loss:0.00000, loss_test:0.02317, lr:1.36e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.075, tt:6699.240\n",
      "Ep:191, loss:0.00000, loss_test:0.02328, lr:1.34e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.087, tt:6736.768\n",
      "Ep:192, loss:0.00000, loss_test:0.02333, lr:1.33e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.084, tt:6771.115\n",
      "Ep:193, loss:0.00000, loss_test:0.02332, lr:1.32e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.087, tt:6806.974\n",
      "Ep:194, loss:0.00000, loss_test:0.02333, lr:1.30e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.098, tt:6844.045\n",
      "Ep:195, loss:0.00000, loss_test:0.02341, lr:1.29e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.100, tt:6879.672\n",
      "Ep:196, loss:0.00000, loss_test:0.02344, lr:1.28e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.110, tt:6916.747\n",
      "Ep:197, loss:0.00000, loss_test:0.02344, lr:1.26e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.118, tt:6953.302\n",
      "Ep:198, loss:0.00000, loss_test:0.02350, lr:1.25e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.121, tt:6989.056\n",
      "Ep:199, loss:0.00000, loss_test:0.02351, lr:1.24e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.127, tt:7025.423\n",
      "Ep:200, loss:0.00000, loss_test:0.02357, lr:1.23e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.123, tt:7059.670\n",
      "Ep:201, loss:0.00000, loss_test:0.02360, lr:1.21e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.128, tt:7095.769\n",
      "Ep:202, loss:0.00000, loss_test:0.02361, lr:1.20e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.122, tt:7129.692\n",
      "Ep:203, loss:0.00000, loss_test:0.02367, lr:1.19e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.121, tt:7164.591\n",
      "Ep:204, loss:0.00000, loss_test:0.02371, lr:1.18e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.124, tt:7200.523\n",
      "Ep:205, loss:0.00000, loss_test:0.02375, lr:1.17e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.133, tt:7237.362\n",
      "Ep:206, loss:0.00000, loss_test:0.02375, lr:1.15e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.136, tt:7273.222\n",
      "Ep:207, loss:0.00000, loss_test:0.02379, lr:1.14e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.147, tt:7310.628\n",
      "Ep:208, loss:0.00000, loss_test:0.02383, lr:1.13e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.136, tt:7343.419\n",
      "Ep:209, loss:0.00000, loss_test:0.02383, lr:1.12e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.141, tt:7379.567\n",
      "Ep:210, loss:0.00000, loss_test:0.02384, lr:1.11e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.146, tt:7415.821\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14307, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:32.544, tt:32.544\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14170, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:33.190, tt:66.379\n",
      "Ep:2, loss:0.00026, loss_test:0.14048, lr:1.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:33.449, tt:100.346\n",
      "Ep:3, loss:0.00025, loss_test:0.13997, lr:1.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:33.281, tt:133.125\n",
      "Ep:4, loss:0.00025, loss_test:0.13890, lr:1.00e-02, fs:0.62602 (r=0.778,p=0.524),  time:33.079, tt:165.396\n",
      "Ep:5, loss:0.00024, loss_test:0.13809, lr:1.00e-02, fs:0.60833 (r=0.737,p=0.518),  time:33.619, tt:201.716\n",
      "Ep:6, loss:0.00024, loss_test:0.13597, lr:1.00e-02, fs:0.61411 (r=0.747,p=0.521),  time:34.279, tt:239.954\n",
      "Ep:7, loss:0.00023, loss_test:0.13312, lr:1.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:34.240, tt:273.918\n",
      "Ep:8, loss:0.00023, loss_test:0.13074, lr:1.00e-02, fs:0.62500 (r=0.758,p=0.532),  time:34.482, tt:310.340\n",
      "Ep:9, loss:0.00022, loss_test:0.12865, lr:1.00e-02, fs:0.61739 (r=0.717,p=0.542),  time:34.458, tt:344.576\n",
      "Ep:10, loss:0.00021, loss_test:0.12588, lr:1.00e-02, fs:0.61818 (r=0.687,p=0.562),  time:34.570, tt:380.266\n",
      "Ep:11, loss:0.00021, loss_test:0.12287, lr:1.00e-02, fs:0.61538 (r=0.687,p=0.557),  time:34.784, tt:417.405\n",
      "Ep:12, loss:0.00020, loss_test:0.11952, lr:9.90e-03, fs:0.63964 (r=0.717,p=0.577),  time:34.993, tt:454.909\n",
      "Ep:13, loss:0.00020, loss_test:0.11578, lr:9.80e-03, fs:0.64545 (r=0.717,p=0.587),  time:35.135, tt:491.884\n",
      "Ep:14, loss:0.00019, loss_test:0.11267, lr:9.70e-03, fs:0.68182 (r=0.758,p=0.620),  time:35.324, tt:529.865\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.11122, lr:9.70e-03, fs:0.69683 (r=0.778,p=0.631),  time:35.479, tt:567.659\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10900, lr:9.70e-03, fs:0.70588 (r=0.788,p=0.639),  time:35.643, tt:605.931\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10721, lr:9.70e-03, fs:0.70370 (r=0.768,p=0.650),  time:35.746, tt:643.427\n",
      "Ep:18, loss:0.00017, loss_test:0.10571, lr:9.70e-03, fs:0.70423 (r=0.758,p=0.658),  time:35.757, tt:679.387\n",
      "Ep:19, loss:0.00016, loss_test:0.10399, lr:9.70e-03, fs:0.73148 (r=0.798,p=0.675),  time:35.838, tt:716.765\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10262, lr:9.70e-03, fs:0.72558 (r=0.788,p=0.672),  time:35.789, tt:751.572\n",
      "Ep:21, loss:0.00016, loss_test:0.10103, lr:9.70e-03, fs:0.71845 (r=0.747,p=0.692),  time:35.822, tt:788.077\n",
      "Ep:22, loss:0.00015, loss_test:0.09984, lr:9.70e-03, fs:0.72115 (r=0.758,p=0.688),  time:35.905, tt:825.821\n",
      "Ep:23, loss:0.00015, loss_test:0.09851, lr:9.70e-03, fs:0.72464 (r=0.758,p=0.694),  time:35.891, tt:861.396\n",
      "Ep:24, loss:0.00014, loss_test:0.09648, lr:9.70e-03, fs:0.74146 (r=0.768,p=0.717),  time:35.968, tt:899.207\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09579, lr:9.70e-03, fs:0.74757 (r=0.778,p=0.720),  time:36.023, tt:936.599\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09516, lr:9.70e-03, fs:0.74257 (r=0.758,p=0.728),  time:36.055, tt:973.476\n",
      "Ep:27, loss:0.00013, loss_test:0.09448, lr:9.70e-03, fs:0.74877 (r=0.768,p=0.731),  time:36.046, tt:1009.291\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.09361, lr:9.70e-03, fs:0.75248 (r=0.768,p=0.738),  time:36.042, tt:1045.230\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.09292, lr:9.70e-03, fs:0.74877 (r=0.768,p=0.731),  time:36.017, tt:1080.521\n",
      "Ep:30, loss:0.00012, loss_test:0.09197, lr:9.70e-03, fs:0.74627 (r=0.758,p=0.735),  time:36.119, tt:1119.696\n",
      "Ep:31, loss:0.00011, loss_test:0.09037, lr:9.70e-03, fs:0.74877 (r=0.768,p=0.731),  time:36.128, tt:1156.110\n",
      "Ep:32, loss:0.00011, loss_test:0.08965, lr:9.70e-03, fs:0.75758 (r=0.758,p=0.758),  time:36.159, tt:1193.257\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00010, loss_test:0.08871, lr:9.70e-03, fs:0.74372 (r=0.747,p=0.740),  time:36.206, tt:1231.014\n",
      "Ep:34, loss:0.00010, loss_test:0.08852, lr:9.70e-03, fs:0.75758 (r=0.758,p=0.758),  time:36.329, tt:1271.512\n",
      "Ep:35, loss:0.00010, loss_test:0.08593, lr:9.70e-03, fs:0.75758 (r=0.758,p=0.758),  time:36.357, tt:1308.841\n",
      "Ep:36, loss:0.00010, loss_test:0.08576, lr:9.70e-03, fs:0.75510 (r=0.747,p=0.763),  time:36.391, tt:1346.467\n",
      "Ep:37, loss:0.00009, loss_test:0.08495, lr:9.70e-03, fs:0.77000 (r=0.778,p=0.762),  time:36.417, tt:1383.863\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08298, lr:9.70e-03, fs:0.74227 (r=0.727,p=0.758),  time:36.453, tt:1421.657\n",
      "Ep:39, loss:0.00009, loss_test:0.08558, lr:9.70e-03, fs:0.76923 (r=0.758,p=0.781),  time:36.476, tt:1459.041\n",
      "Ep:40, loss:0.00008, loss_test:0.08191, lr:9.70e-03, fs:0.76684 (r=0.747,p=0.787),  time:36.505, tt:1496.725\n",
      "Ep:41, loss:0.00008, loss_test:0.08556, lr:9.70e-03, fs:0.74194 (r=0.697,p=0.793),  time:36.555, tt:1535.309\n",
      "Ep:42, loss:0.00008, loss_test:0.08268, lr:9.70e-03, fs:0.78607 (r=0.798,p=0.775),  time:36.566, tt:1572.354\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.08283, lr:9.70e-03, fs:0.74033 (r=0.677,p=0.817),  time:36.588, tt:1609.860\n",
      "Ep:44, loss:0.00008, loss_test:0.08339, lr:9.70e-03, fs:0.78392 (r=0.788,p=0.780),  time:36.576, tt:1645.909\n",
      "Ep:45, loss:0.00007, loss_test:0.07985, lr:9.70e-03, fs:0.74866 (r=0.707,p=0.795),  time:36.614, tt:1684.264\n",
      "Ep:46, loss:0.00007, loss_test:0.08110, lr:9.70e-03, fs:0.73446 (r=0.657,p=0.833),  time:36.636, tt:1721.878\n",
      "Ep:47, loss:0.00007, loss_test:0.08097, lr:9.70e-03, fs:0.77778 (r=0.778,p=0.778),  time:36.633, tt:1758.393\n",
      "Ep:48, loss:0.00007, loss_test:0.07824, lr:9.70e-03, fs:0.74157 (r=0.667,p=0.835),  time:36.714, tt:1798.961\n",
      "Ep:49, loss:0.00006, loss_test:0.08149, lr:9.70e-03, fs:0.79167 (r=0.768,p=0.817),  time:36.721, tt:1836.046\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07922, lr:9.70e-03, fs:0.73333 (r=0.667,p=0.815),  time:36.784, tt:1875.984\n",
      "Ep:51, loss:0.00006, loss_test:0.08059, lr:9.70e-03, fs:0.76190 (r=0.727,p=0.800),  time:36.819, tt:1914.576\n",
      "Ep:52, loss:0.00006, loss_test:0.08132, lr:9.70e-03, fs:0.79144 (r=0.747,p=0.841),  time:36.840, tt:1952.495\n",
      "Ep:53, loss:0.00006, loss_test:0.07998, lr:9.70e-03, fs:0.74317 (r=0.687,p=0.810),  time:36.864, tt:1990.650\n",
      "Ep:54, loss:0.00006, loss_test:0.07738, lr:9.70e-03, fs:0.73143 (r=0.646,p=0.842),  time:36.872, tt:2027.941\n",
      "Ep:55, loss:0.00006, loss_test:0.08292, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:36.881, tt:2065.340\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.07571, lr:9.70e-03, fs:0.74286 (r=0.657,p=0.855),  time:36.887, tt:2102.559\n",
      "Ep:57, loss:0.00006, loss_test:0.07861, lr:9.70e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.893, tt:2139.794\n",
      "Ep:58, loss:0.00005, loss_test:0.08081, lr:9.70e-03, fs:0.78075 (r=0.737,p=0.830),  time:36.893, tt:2176.662\n",
      "Ep:59, loss:0.00005, loss_test:0.07556, lr:9.70e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.917, tt:2215.026\n",
      "Ep:60, loss:0.00005, loss_test:0.07993, lr:9.70e-03, fs:0.78075 (r=0.737,p=0.830),  time:36.887, tt:2250.118\n",
      "Ep:61, loss:0.00005, loss_test:0.07588, lr:9.70e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.879, tt:2286.477\n",
      "Ep:62, loss:0.00005, loss_test:0.07569, lr:9.70e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.874, tt:2323.087\n",
      "Ep:63, loss:0.00005, loss_test:0.07692, lr:9.70e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.885, tt:2360.669\n",
      "Ep:64, loss:0.00005, loss_test:0.07413, lr:9.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.869, tt:2396.464\n",
      "Ep:65, loss:0.00004, loss_test:0.07764, lr:9.70e-03, fs:0.78453 (r=0.717,p=0.866),  time:36.888, tt:2434.588\n",
      "Ep:66, loss:0.00004, loss_test:0.07720, lr:9.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.878, tt:2470.815\n",
      "Ep:67, loss:0.00004, loss_test:0.07925, lr:9.61e-03, fs:0.80000 (r=0.747,p=0.860),  time:36.913, tt:2510.051\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.07641, lr:9.61e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.911, tt:2546.847\n",
      "Ep:69, loss:0.00004, loss_test:0.07998, lr:9.61e-03, fs:0.78689 (r=0.727,p=0.857),  time:36.902, tt:2583.142\n",
      "Ep:70, loss:0.00004, loss_test:0.07886, lr:9.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.883, tt:2618.709\n",
      "Ep:71, loss:0.00004, loss_test:0.07539, lr:9.61e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.893, tt:2656.272\n",
      "Ep:72, loss:0.00004, loss_test:0.07821, lr:9.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.892, tt:2693.143\n",
      "Ep:73, loss:0.00004, loss_test:0.07315, lr:9.61e-03, fs:0.75281 (r=0.677,p=0.848),  time:36.884, tt:2729.443\n",
      "Ep:74, loss:0.00004, loss_test:0.07853, lr:9.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.876, tt:2765.690\n",
      "Ep:75, loss:0.00003, loss_test:0.07477, lr:9.61e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.880, tt:2802.884\n",
      "Ep:76, loss:0.00003, loss_test:0.07990, lr:9.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.872, tt:2839.107\n",
      "Ep:77, loss:0.00003, loss_test:0.07684, lr:9.61e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.879, tt:2876.583\n",
      "Ep:78, loss:0.00003, loss_test:0.07823, lr:9.61e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.881, tt:2913.607\n",
      "Ep:79, loss:0.00003, loss_test:0.07746, lr:9.51e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.890, tt:2951.178\n",
      "Ep:80, loss:0.00003, loss_test:0.07934, lr:9.41e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.867, tt:2986.222\n",
      "Ep:81, loss:0.00003, loss_test:0.08102, lr:9.32e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.865, tt:3022.894\n",
      "Ep:82, loss:0.00003, loss_test:0.07610, lr:9.23e-03, fs:0.77273 (r=0.687,p=0.883),  time:36.846, tt:3058.189\n",
      "Ep:83, loss:0.00003, loss_test:0.08302, lr:9.14e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.827, tt:3093.471\n",
      "Ep:84, loss:0.00003, loss_test:0.07849, lr:9.04e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.811, tt:3128.938\n",
      "Ep:85, loss:0.00004, loss_test:0.07947, lr:8.95e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.813, tt:3165.947\n",
      "Ep:86, loss:0.00003, loss_test:0.08071, lr:8.86e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.807, tt:3202.243\n",
      "Ep:87, loss:0.00003, loss_test:0.07988, lr:8.78e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.797, tt:3238.154\n",
      "Ep:88, loss:0.00003, loss_test:0.07821, lr:8.69e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.778, tt:3273.284\n",
      "Ep:89, loss:0.00003, loss_test:0.08018, lr:8.60e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.755, tt:3307.995\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00003, loss_test:0.08081, lr:8.60e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.726, tt:3342.067\n",
      "Ep:91, loss:0.00002, loss_test:0.07868, lr:8.60e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.724, tt:3378.618\n",
      "Ep:92, loss:0.00002, loss_test:0.08045, lr:8.60e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.699, tt:3413.005\n",
      "Ep:93, loss:0.00002, loss_test:0.07777, lr:8.60e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.662, tt:3446.247\n",
      "Ep:94, loss:0.00002, loss_test:0.08208, lr:8.60e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.651, tt:3481.804\n",
      "Ep:95, loss:0.00002, loss_test:0.07965, lr:8.60e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.665, tt:3519.835\n",
      "Ep:96, loss:0.00002, loss_test:0.08125, lr:8.60e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.673, tt:3557.325\n",
      "Ep:97, loss:0.00002, loss_test:0.07896, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.674, tt:3594.088\n",
      "Ep:98, loss:0.00002, loss_test:0.08162, lr:8.60e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.672, tt:3630.563\n",
      "Ep:99, loss:0.00002, loss_test:0.07908, lr:8.60e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.673, tt:3667.314\n",
      "Ep:100, loss:0.00002, loss_test:0.08231, lr:8.60e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.656, tt:3702.234\n",
      "Ep:101, loss:0.00002, loss_test:0.08045, lr:8.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.646, tt:3737.850\n",
      "Ep:102, loss:0.00002, loss_test:0.08047, lr:8.43e-03, fs:0.74419 (r=0.646,p=0.877),  time:36.650, tt:3774.981\n",
      "Ep:103, loss:0.00002, loss_test:0.07979, lr:8.35e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.654, tt:3811.973\n",
      "Ep:104, loss:0.00002, loss_test:0.08236, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.645, tt:3847.740\n",
      "Ep:105, loss:0.00002, loss_test:0.08131, lr:8.18e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.643, tt:3884.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00002, loss_test:0.08050, lr:8.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.626, tt:3918.942\n",
      "Ep:107, loss:0.00002, loss_test:0.08239, lr:8.02e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.616, tt:3954.553\n",
      "Ep:108, loss:0.00002, loss_test:0.08224, lr:7.94e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.613, tt:3990.864\n",
      "Ep:109, loss:0.00002, loss_test:0.07932, lr:7.86e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.599, tt:4025.855\n",
      "Ep:110, loss:0.00002, loss_test:0.08285, lr:7.78e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.596, tt:4062.191\n",
      "Ep:111, loss:0.00002, loss_test:0.07993, lr:7.70e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.593, tt:4098.443\n",
      "Ep:112, loss:0.00002, loss_test:0.08385, lr:7.62e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.594, tt:4135.146\n",
      "Ep:113, loss:0.00002, loss_test:0.08228, lr:7.55e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.593, tt:4171.606\n",
      "Ep:114, loss:0.00002, loss_test:0.08291, lr:7.47e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.591, tt:4207.977\n",
      "Ep:115, loss:0.00002, loss_test:0.08098, lr:7.40e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.594, tt:4244.880\n",
      "Ep:116, loss:0.00002, loss_test:0.08444, lr:7.32e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.596, tt:4281.760\n",
      "Ep:117, loss:0.00002, loss_test:0.07948, lr:7.25e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.586, tt:4317.184\n",
      "Ep:118, loss:0.00002, loss_test:0.08500, lr:7.18e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.602, tt:4355.646\n",
      "Ep:119, loss:0.00001, loss_test:0.08193, lr:7.11e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.606, tt:4392.757\n",
      "Ep:120, loss:0.00001, loss_test:0.08285, lr:7.03e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.601, tt:4428.691\n",
      "Ep:121, loss:0.00001, loss_test:0.08208, lr:6.96e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.603, tt:4465.600\n",
      "Ep:122, loss:0.00001, loss_test:0.08325, lr:6.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.601, tt:4501.980\n",
      "Ep:123, loss:0.00001, loss_test:0.08135, lr:6.83e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.601, tt:4538.531\n",
      "Ep:124, loss:0.00001, loss_test:0.08299, lr:6.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.603, tt:4575.415\n",
      "Ep:125, loss:0.00001, loss_test:0.08257, lr:6.69e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.608, tt:4612.553\n",
      "Ep:126, loss:0.00001, loss_test:0.08128, lr:6.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.599, tt:4648.052\n",
      "Ep:127, loss:0.00001, loss_test:0.08331, lr:6.56e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.603, tt:4685.206\n",
      "Ep:128, loss:0.00001, loss_test:0.08046, lr:6.49e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.610, tt:4722.660\n",
      "Ep:129, loss:0.00001, loss_test:0.08315, lr:6.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.600, tt:4757.991\n",
      "Ep:130, loss:0.00001, loss_test:0.08091, lr:6.36e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.600, tt:4794.580\n",
      "Ep:131, loss:0.00001, loss_test:0.08289, lr:6.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.590, tt:4829.835\n",
      "Ep:132, loss:0.00001, loss_test:0.08050, lr:6.24e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.588, tt:4866.253\n",
      "Ep:133, loss:0.00001, loss_test:0.08294, lr:6.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.582, tt:4902.038\n",
      "Ep:134, loss:0.00001, loss_test:0.08181, lr:6.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.577, tt:4937.858\n",
      "Ep:135, loss:0.00001, loss_test:0.08079, lr:6.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.571, tt:4973.720\n",
      "Ep:136, loss:0.00001, loss_test:0.08174, lr:5.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.571, tt:5010.271\n",
      "Ep:137, loss:0.00001, loss_test:0.08075, lr:5.93e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.568, tt:5046.342\n",
      "Ep:138, loss:0.00001, loss_test:0.08310, lr:5.87e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.575, tt:5083.908\n",
      "Ep:139, loss:0.00001, loss_test:0.08180, lr:5.81e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.577, tt:5120.735\n",
      "Ep:140, loss:0.00001, loss_test:0.08146, lr:5.75e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.576, tt:5157.231\n",
      "Ep:141, loss:0.00001, loss_test:0.08186, lr:5.70e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.572, tt:5193.234\n",
      "Ep:142, loss:0.00001, loss_test:0.08067, lr:5.64e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.557, tt:5227.593\n",
      "Ep:143, loss:0.00001, loss_test:0.08315, lr:5.58e-03, fs:0.74699 (r=0.626,p=0.925),  time:36.547, tt:5262.816\n",
      "Ep:144, loss:0.00001, loss_test:0.08057, lr:5.53e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.542, tt:5298.608\n",
      "Ep:145, loss:0.00001, loss_test:0.08325, lr:5.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.538, tt:5334.480\n",
      "Ep:146, loss:0.00001, loss_test:0.08123, lr:5.42e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.531, tt:5370.074\n",
      "Ep:147, loss:0.00001, loss_test:0.08210, lr:5.36e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.545, tt:5408.625\n",
      "Ep:148, loss:0.00001, loss_test:0.08240, lr:5.31e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.540, tt:5444.465\n",
      "Ep:149, loss:0.00001, loss_test:0.08061, lr:5.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.535, tt:5480.296\n",
      "Ep:150, loss:0.00001, loss_test:0.08296, lr:5.20e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.537, tt:5517.043\n",
      "Ep:151, loss:0.00001, loss_test:0.08123, lr:5.15e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.531, tt:5552.737\n",
      "Ep:152, loss:0.00001, loss_test:0.08304, lr:5.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.530, tt:5589.092\n",
      "Ep:153, loss:0.00001, loss_test:0.08235, lr:5.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.523, tt:5624.568\n",
      "Ep:154, loss:0.00001, loss_test:0.08103, lr:5.00e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.518, tt:5660.356\n",
      "Ep:155, loss:0.00001, loss_test:0.08334, lr:4.95e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.540, tt:5700.272\n",
      "Ep:156, loss:0.00001, loss_test:0.08104, lr:4.90e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.543, tt:5737.296\n",
      "Ep:157, loss:0.00001, loss_test:0.08219, lr:4.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.539, tt:5773.194\n",
      "Ep:158, loss:0.00001, loss_test:0.08209, lr:4.80e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.533, tt:5808.765\n",
      "Ep:159, loss:0.00001, loss_test:0.08199, lr:4.75e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.530, tt:5844.852\n",
      "Ep:160, loss:0.00001, loss_test:0.08248, lr:4.71e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.531, tt:5881.552\n",
      "Ep:161, loss:0.00001, loss_test:0.08170, lr:4.66e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.530, tt:5917.840\n",
      "Ep:162, loss:0.00001, loss_test:0.08279, lr:4.61e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.536, tt:5955.331\n",
      "Ep:163, loss:0.00001, loss_test:0.08173, lr:4.57e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.538, tt:5992.238\n",
      "Ep:164, loss:0.00001, loss_test:0.08238, lr:4.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.538, tt:6028.716\n",
      "Ep:165, loss:0.00001, loss_test:0.08255, lr:4.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.547, tt:6066.743\n",
      "Ep:166, loss:0.00001, loss_test:0.08202, lr:4.43e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.542, tt:6102.438\n",
      "Ep:167, loss:0.00001, loss_test:0.08259, lr:4.39e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.546, tt:6139.656\n",
      "Ep:168, loss:0.00001, loss_test:0.08187, lr:4.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.539, tt:6175.047\n",
      "Ep:169, loss:0.00001, loss_test:0.08279, lr:4.30e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.545, tt:6212.591\n",
      "Ep:170, loss:0.00001, loss_test:0.08214, lr:4.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.552, tt:6250.472\n",
      "Ep:171, loss:0.00001, loss_test:0.08370, lr:4.21e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.551, tt:6286.731\n",
      "Ep:172, loss:0.00001, loss_test:0.08344, lr:4.17e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.557, tt:6324.426\n",
      "Ep:173, loss:0.00001, loss_test:0.08288, lr:4.13e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.572, tt:6363.577\n",
      "Ep:174, loss:0.00001, loss_test:0.08371, lr:4.09e-03, fs:0.73494 (r=0.616,p=0.910),  time:36.563, tt:6398.534\n",
      "Ep:175, loss:0.00001, loss_test:0.08277, lr:4.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.565, tt:6435.446\n",
      "Ep:176, loss:0.00001, loss_test:0.08396, lr:4.01e-03, fs:0.74556 (r=0.636,p=0.900),  time:36.565, tt:6471.997\n",
      "Ep:177, loss:0.00001, loss_test:0.08323, lr:3.97e-03, fs:0.72727 (r=0.606,p=0.909),  time:36.564, tt:6508.472\n",
      "Ep:178, loss:0.00001, loss_test:0.08202, lr:3.93e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.575, tt:6546.935\n",
      "Ep:179, loss:0.00001, loss_test:0.08363, lr:3.89e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.573, tt:6583.055\n",
      "Ep:180, loss:0.00001, loss_test:0.08370, lr:3.85e-03, fs:0.74251 (r=0.626,p=0.912),  time:36.582, tt:6621.363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:181, loss:0.00001, loss_test:0.08366, lr:3.81e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.583, tt:6658.116\n",
      "Ep:182, loss:0.00001, loss_test:0.08373, lr:3.77e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.583, tt:6694.647\n",
      "Ep:183, loss:0.00001, loss_test:0.08278, lr:3.73e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.586, tt:6731.758\n",
      "Ep:184, loss:0.00001, loss_test:0.08355, lr:3.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.585, tt:6768.185\n",
      "Ep:185, loss:0.00001, loss_test:0.08345, lr:3.66e-03, fs:0.73054 (r=0.616,p=0.897),  time:36.585, tt:6804.888\n",
      "Ep:186, loss:0.00001, loss_test:0.08330, lr:3.62e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.579, tt:6840.343\n",
      "Ep:187, loss:0.00001, loss_test:0.08355, lr:3.59e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.570, tt:6875.225\n",
      "Ep:188, loss:0.00001, loss_test:0.08312, lr:3.55e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.563, tt:6910.480\n",
      "Ep:189, loss:0.00001, loss_test:0.08394, lr:3.52e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.561, tt:6946.644\n",
      "Ep:190, loss:0.00001, loss_test:0.08367, lr:3.48e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.564, tt:6983.706\n",
      "Ep:191, loss:0.00001, loss_test:0.08340, lr:3.45e-03, fs:0.73810 (r=0.626,p=0.899),  time:36.569, tt:7021.288\n",
      "Ep:192, loss:0.00001, loss_test:0.08417, lr:3.41e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.587, tt:7061.215\n",
      "Ep:193, loss:0.00001, loss_test:0.08375, lr:3.38e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.592, tt:7098.764\n",
      "Ep:194, loss:0.00001, loss_test:0.08347, lr:3.34e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.597, tt:7136.403\n",
      "Ep:195, loss:0.00001, loss_test:0.08391, lr:3.31e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.596, tt:7172.727\n",
      "Ep:196, loss:0.00001, loss_test:0.08415, lr:3.28e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.587, tt:7207.615\n",
      "Ep:197, loss:0.00001, loss_test:0.08388, lr:3.24e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.590, tt:7244.898\n",
      "Ep:198, loss:0.00001, loss_test:0.08321, lr:3.21e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.591, tt:7281.637\n",
      "Ep:199, loss:0.00001, loss_test:0.08453, lr:3.18e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.595, tt:7318.948\n",
      "Ep:200, loss:0.00001, loss_test:0.08493, lr:3.15e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.590, tt:7354.587\n",
      "Ep:201, loss:0.00001, loss_test:0.08387, lr:3.12e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.590, tt:7391.278\n",
      "Ep:202, loss:0.00001, loss_test:0.08407, lr:3.09e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.592, tt:7428.116\n",
      "Ep:203, loss:0.00001, loss_test:0.08498, lr:3.05e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.591, tt:7464.608\n",
      "Ep:204, loss:0.00001, loss_test:0.08443, lr:3.02e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.591, tt:7501.237\n",
      "Ep:205, loss:0.00001, loss_test:0.08449, lr:2.99e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.579, tt:7535.363\n",
      "Ep:206, loss:0.00001, loss_test:0.08396, lr:2.96e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.574, tt:7570.851\n",
      "Ep:207, loss:0.00001, loss_test:0.08450, lr:2.93e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.566, tt:7605.731\n",
      "Ep:208, loss:0.00001, loss_test:0.08547, lr:2.90e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.561, tt:7641.299\n",
      "Ep:209, loss:0.00001, loss_test:0.08488, lr:2.88e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.548, tt:7675.102\n",
      "Ep:210, loss:0.00001, loss_test:0.08485, lr:2.85e-03, fs:0.72289 (r=0.606,p=0.896),  time:36.538, tt:7709.521\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02439, lr:6.00e-02, fs:0.61905 (r=0.788,p=0.510),  time:29.087, tt:29.087\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02551, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:30.886, tt:61.773\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02727, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.641, tt:91.922\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02748, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.673, tt:118.692\n",
      "Ep:4, loss:0.00005, loss_test:0.02702, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:29.141, tt:145.704\n",
      "Ep:5, loss:0.00005, loss_test:0.02613, lr:6.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:29.553, tt:177.315\n",
      "Ep:6, loss:0.00005, loss_test:0.02542, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:30.375, tt:212.622\n",
      "Ep:7, loss:0.00004, loss_test:0.02487, lr:6.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:30.595, tt:244.758\n",
      "Ep:8, loss:0.00004, loss_test:0.02395, lr:6.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:30.616, tt:275.541\n",
      "Ep:9, loss:0.00004, loss_test:0.02282, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:30.869, tt:308.687\n",
      "Ep:10, loss:0.00004, loss_test:0.02198, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:30.853, tt:339.382\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02136, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:31.119, tt:373.432\n",
      "Ep:12, loss:0.00004, loss_test:0.02095, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:31.490, tt:409.366\n",
      "Ep:13, loss:0.00004, loss_test:0.02064, lr:6.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:31.867, tt:446.141\n",
      "Ep:14, loss:0.00004, loss_test:0.02026, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:32.062, tt:480.936\n",
      "Ep:15, loss:0.00004, loss_test:0.01986, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:32.262, tt:516.187\n",
      "Ep:16, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:32.497, tt:552.450\n",
      "Ep:17, loss:0.00003, loss_test:0.01915, lr:6.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:32.656, tt:587.817\n",
      "Ep:18, loss:0.00003, loss_test:0.01880, lr:6.00e-02, fs:0.67925 (r=0.909,p=0.542),  time:32.831, tt:623.780\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01852, lr:6.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:32.915, tt:658.291\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01821, lr:6.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:32.968, tt:692.327\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01785, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:33.090, tt:727.986\n",
      "Ep:22, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:33.150, tt:762.448\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01742, lr:6.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:33.277, tt:798.639\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:33.327, tt:833.184\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:33.384, tt:867.985\n",
      "Ep:26, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:33.467, tt:903.612\n",
      "Ep:27, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:33.489, tt:937.680\n",
      "Ep:28, loss:0.00003, loss_test:0.01676, lr:6.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:33.538, tt:972.596\n",
      "Ep:29, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:33.619, tt:1008.556\n",
      "Ep:30, loss:0.00003, loss_test:0.01652, lr:6.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:33.672, tt:1043.845\n",
      "Ep:31, loss:0.00003, loss_test:0.01628, lr:6.00e-02, fs:0.75000 (r=0.909,p=0.638),  time:33.712, tt:1078.800\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:33.814, tt:1115.860\n",
      "Ep:33, loss:0.00002, loss_test:0.01601, lr:6.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:33.857, tt:1151.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00002, loss_test:0.01586, lr:6.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:33.875, tt:1185.619\n",
      "Ep:35, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.75862 (r=0.889,p=0.662),  time:33.898, tt:1220.324\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:33.932, tt:1255.488\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01548, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:33.942, tt:1289.801\n",
      "Ep:38, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:33.977, tt:1325.121\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01539, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:33.992, tt:1359.687\n",
      "Ep:40, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:34.012, tt:1394.479\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:34.038, tt:1429.593\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:34.080, tt:1465.437\n",
      "Ep:43, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:34.087, tt:1499.828\n",
      "Ep:44, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:34.122, tt:1535.475\n",
      "Ep:45, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:34.111, tt:1569.098\n",
      "Ep:46, loss:0.00002, loss_test:0.01489, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:34.106, tt:1602.965\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:34.141, tt:1638.760\n",
      "Ep:48, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:34.133, tt:1672.519\n",
      "Ep:49, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:34.146, tt:1707.286\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01471, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:34.176, tt:1742.989\n",
      "Ep:51, loss:0.00002, loss_test:0.01469, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:34.206, tt:1778.730\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01492, lr:6.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:34.251, tt:1815.284\n",
      "Ep:53, loss:0.00001, loss_test:0.01487, lr:6.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:34.257, tt:1849.863\n",
      "Ep:54, loss:0.00001, loss_test:0.01481, lr:6.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:34.256, tt:1884.089\n",
      "Ep:55, loss:0.00001, loss_test:0.01494, lr:6.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:34.269, tt:1919.051\n",
      "Ep:56, loss:0.00001, loss_test:0.01466, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:34.275, tt:1953.684\n",
      "Ep:57, loss:0.00001, loss_test:0.01493, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:34.244, tt:1986.144\n",
      "Ep:58, loss:0.00001, loss_test:0.01502, lr:6.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:34.261, tt:2021.396\n",
      "Ep:59, loss:0.00001, loss_test:0.01503, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:34.256, tt:2055.358\n",
      "Ep:60, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:34.240, tt:2088.621\n",
      "Ep:61, loss:0.00001, loss_test:0.01510, lr:6.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:34.244, tt:2123.113\n",
      "Ep:62, loss:0.00001, loss_test:0.01508, lr:6.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:34.257, tt:2158.192\n",
      "Ep:63, loss:0.00001, loss_test:0.01527, lr:5.94e-02, fs:0.77320 (r=0.758,p=0.789),  time:34.232, tt:2190.824\n",
      "Ep:64, loss:0.00001, loss_test:0.01536, lr:5.88e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.246, tt:2225.984\n",
      "Ep:65, loss:0.00001, loss_test:0.01513, lr:5.82e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.277, tt:2262.278\n",
      "Ep:66, loss:0.00001, loss_test:0.01525, lr:5.76e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.291, tt:2297.513\n",
      "Ep:67, loss:0.00001, loss_test:0.01542, lr:5.71e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.288, tt:2331.612\n",
      "Ep:68, loss:0.00001, loss_test:0.01501, lr:5.65e-02, fs:0.79167 (r=0.768,p=0.817),  time:34.258, tt:2363.780\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01565, lr:5.65e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.256, tt:2397.894\n",
      "Ep:70, loss:0.00001, loss_test:0.01504, lr:5.65e-02, fs:0.79581 (r=0.768,p=0.826),  time:34.234, tt:2430.631\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01557, lr:5.65e-02, fs:0.77419 (r=0.727,p=0.828),  time:34.232, tt:2464.729\n",
      "Ep:72, loss:0.00001, loss_test:0.01538, lr:5.65e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.240, tt:2499.544\n",
      "Ep:73, loss:0.00001, loss_test:0.01546, lr:5.65e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.226, tt:2532.724\n",
      "Ep:74, loss:0.00001, loss_test:0.01580, lr:5.65e-02, fs:0.74595 (r=0.697,p=0.802),  time:34.237, tt:2567.806\n",
      "Ep:75, loss:0.00001, loss_test:0.01538, lr:5.65e-02, fs:0.79365 (r=0.758,p=0.833),  time:34.236, tt:2601.950\n",
      "Ep:76, loss:0.00001, loss_test:0.01586, lr:5.65e-02, fs:0.76923 (r=0.707,p=0.843),  time:34.245, tt:2636.896\n",
      "Ep:77, loss:0.00001, loss_test:0.01570, lr:5.65e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.262, tt:2672.444\n",
      "Ep:78, loss:0.00001, loss_test:0.01593, lr:5.65e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.271, tt:2707.391\n",
      "Ep:79, loss:0.00001, loss_test:0.01622, lr:5.65e-02, fs:0.75824 (r=0.697,p=0.831),  time:34.289, tt:2743.119\n",
      "Ep:80, loss:0.00001, loss_test:0.01583, lr:5.65e-02, fs:0.77348 (r=0.707,p=0.854),  time:34.304, tt:2778.587\n",
      "Ep:81, loss:0.00001, loss_test:0.01648, lr:5.65e-02, fs:0.73743 (r=0.667,p=0.825),  time:34.326, tt:2814.729\n",
      "Ep:82, loss:0.00001, loss_test:0.01590, lr:5.59e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.344, tt:2850.552\n",
      "Ep:83, loss:0.00001, loss_test:0.01661, lr:5.54e-02, fs:0.73446 (r=0.657,p=0.833),  time:34.360, tt:2886.229\n",
      "Ep:84, loss:0.00001, loss_test:0.01586, lr:5.48e-02, fs:0.75281 (r=0.677,p=0.848),  time:34.369, tt:2921.341\n",
      "Ep:85, loss:0.00001, loss_test:0.01648, lr:5.43e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.389, tt:2957.413\n",
      "Ep:86, loss:0.00001, loss_test:0.01642, lr:5.37e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.398, tt:2992.635\n",
      "Ep:87, loss:0.00001, loss_test:0.01629, lr:5.32e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.368, tt:3024.364\n",
      "Ep:88, loss:0.00001, loss_test:0.01667, lr:5.27e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.346, tt:3056.763\n",
      "Ep:89, loss:0.00001, loss_test:0.01667, lr:5.21e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.366, tt:3092.954\n",
      "Ep:90, loss:0.00001, loss_test:0.01670, lr:5.16e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.393, tt:3129.794\n",
      "Ep:91, loss:0.00001, loss_test:0.01691, lr:5.11e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.419, tt:3166.549\n",
      "Ep:92, loss:0.00001, loss_test:0.01700, lr:5.06e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.445, tt:3203.360\n",
      "Ep:93, loss:0.00001, loss_test:0.01739, lr:5.01e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.464, tt:3239.575\n",
      "Ep:94, loss:0.00001, loss_test:0.01689, lr:4.96e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.489, tt:3276.498\n",
      "Ep:95, loss:0.00001, loss_test:0.01755, lr:4.91e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.498, tt:3311.783\n",
      "Ep:96, loss:0.00001, loss_test:0.01721, lr:4.86e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.514, tt:3347.903\n",
      "Ep:97, loss:0.00001, loss_test:0.01746, lr:4.81e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.521, tt:3383.018\n",
      "Ep:98, loss:0.00001, loss_test:0.01752, lr:4.76e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.547, tt:3420.113\n",
      "Ep:99, loss:0.00001, loss_test:0.01743, lr:4.71e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.561, tt:3456.105\n",
      "Ep:100, loss:0.00001, loss_test:0.01786, lr:4.67e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.558, tt:3490.312\n",
      "Ep:101, loss:0.00001, loss_test:0.01742, lr:4.62e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.558, tt:3524.915\n",
      "Ep:102, loss:0.00000, loss_test:0.01825, lr:4.57e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.572, tt:3560.905\n",
      "Ep:103, loss:0.00000, loss_test:0.01781, lr:4.53e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.581, tt:3596.372\n",
      "Ep:104, loss:0.00000, loss_test:0.01839, lr:4.48e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.598, tt:3632.799\n",
      "Ep:105, loss:0.00000, loss_test:0.01799, lr:4.44e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.613, tt:3668.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00000, loss_test:0.01849, lr:4.39e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.632, tt:3705.646\n",
      "Ep:107, loss:0.00000, loss_test:0.01836, lr:4.35e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.652, tt:3742.405\n",
      "Ep:108, loss:0.00000, loss_test:0.01851, lr:4.31e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.666, tt:3778.618\n",
      "Ep:109, loss:0.00000, loss_test:0.01849, lr:4.26e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.682, tt:3814.992\n",
      "Ep:110, loss:0.00000, loss_test:0.01860, lr:4.22e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.696, tt:3851.219\n",
      "Ep:111, loss:0.00000, loss_test:0.01878, lr:4.18e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.700, tt:3886.455\n",
      "Ep:112, loss:0.00000, loss_test:0.01855, lr:4.14e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.721, tt:3923.485\n",
      "Ep:113, loss:0.00000, loss_test:0.01874, lr:4.10e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.751, tt:3961.632\n",
      "Ep:114, loss:0.00000, loss_test:0.01887, lr:4.05e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.756, tt:3996.918\n",
      "Ep:115, loss:0.00000, loss_test:0.01871, lr:4.01e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.765, tt:4032.721\n",
      "Ep:116, loss:0.00000, loss_test:0.01903, lr:3.97e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.775, tt:4068.715\n",
      "Ep:117, loss:0.00000, loss_test:0.01881, lr:3.93e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.779, tt:4103.886\n",
      "Ep:118, loss:0.00000, loss_test:0.01917, lr:3.89e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.779, tt:4138.749\n",
      "Ep:119, loss:0.00000, loss_test:0.01898, lr:3.86e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.770, tt:4172.460\n",
      "Ep:120, loss:0.00000, loss_test:0.01899, lr:3.82e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.776, tt:4207.904\n",
      "Ep:121, loss:0.00000, loss_test:0.01935, lr:3.78e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.782, tt:4243.391\n",
      "Ep:122, loss:0.00000, loss_test:0.01903, lr:3.74e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.793, tt:4279.594\n",
      "Ep:123, loss:0.00000, loss_test:0.01940, lr:3.70e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.796, tt:4314.676\n",
      "Ep:124, loss:0.00000, loss_test:0.01926, lr:3.67e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.784, tt:4348.031\n",
      "Ep:125, loss:0.00000, loss_test:0.01939, lr:3.63e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.797, tt:4384.433\n",
      "Ep:126, loss:0.00000, loss_test:0.01954, lr:3.59e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.795, tt:4418.913\n",
      "Ep:127, loss:0.00000, loss_test:0.01953, lr:3.56e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.795, tt:4453.707\n",
      "Ep:128, loss:0.00000, loss_test:0.01965, lr:3.52e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.802, tt:4489.454\n",
      "Ep:129, loss:0.00000, loss_test:0.01964, lr:3.49e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.795, tt:4523.397\n",
      "Ep:130, loss:0.00000, loss_test:0.01973, lr:3.45e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.805, tt:4559.420\n",
      "Ep:131, loss:0.00000, loss_test:0.01977, lr:3.42e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.812, tt:4595.229\n",
      "Ep:132, loss:0.00000, loss_test:0.01976, lr:3.38e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.811, tt:4629.855\n",
      "Ep:133, loss:0.00000, loss_test:0.01990, lr:3.35e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.809, tt:4664.383\n",
      "Ep:134, loss:0.00000, loss_test:0.01970, lr:3.32e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.816, tt:4700.138\n",
      "Ep:135, loss:0.00000, loss_test:0.02006, lr:3.28e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.820, tt:4735.457\n",
      "Ep:136, loss:0.00000, loss_test:0.01981, lr:3.25e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.827, tt:4771.254\n",
      "Ep:137, loss:0.00000, loss_test:0.02001, lr:3.22e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.827, tt:4806.113\n",
      "Ep:138, loss:0.00000, loss_test:0.01993, lr:3.19e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.817, tt:4839.585\n",
      "Ep:139, loss:0.00000, loss_test:0.02011, lr:3.15e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.817, tt:4874.337\n",
      "Ep:140, loss:0.00000, loss_test:0.02004, lr:3.12e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.821, tt:4909.801\n",
      "Ep:141, loss:0.00000, loss_test:0.02025, lr:3.09e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.813, tt:4943.441\n",
      "Ep:142, loss:0.00000, loss_test:0.02005, lr:3.06e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.816, tt:4978.660\n",
      "Ep:143, loss:0.00000, loss_test:0.02037, lr:3.03e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.814, tt:5013.228\n",
      "Ep:144, loss:0.00000, loss_test:0.02009, lr:3.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.817, tt:5048.499\n",
      "Ep:145, loss:0.00000, loss_test:0.02040, lr:2.97e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.825, tt:5084.479\n",
      "Ep:146, loss:0.00000, loss_test:0.02028, lr:2.94e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.829, tt:5119.836\n",
      "Ep:147, loss:0.00000, loss_test:0.02042, lr:2.91e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.842, tt:5156.616\n",
      "Ep:148, loss:0.00000, loss_test:0.02045, lr:2.88e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.845, tt:5191.869\n",
      "Ep:149, loss:0.00000, loss_test:0.02031, lr:2.85e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.838, tt:5225.680\n",
      "Ep:150, loss:0.00000, loss_test:0.02052, lr:2.82e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.832, tt:5259.650\n",
      "Ep:151, loss:0.00000, loss_test:0.02039, lr:2.80e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.830, tt:5294.193\n",
      "Ep:152, loss:0.00000, loss_test:0.02057, lr:2.77e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.826, tt:5328.304\n",
      "Ep:153, loss:0.00000, loss_test:0.02059, lr:2.74e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.814, tt:5361.320\n",
      "Ep:154, loss:0.00000, loss_test:0.02055, lr:2.71e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.815, tt:5396.394\n",
      "Ep:155, loss:0.00000, loss_test:0.02074, lr:2.69e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.811, tt:5430.466\n",
      "Ep:156, loss:0.00000, loss_test:0.02051, lr:2.66e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.817, tt:5466.294\n",
      "Ep:157, loss:0.00000, loss_test:0.02074, lr:2.63e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.819, tt:5501.338\n",
      "Ep:158, loss:0.00000, loss_test:0.02085, lr:2.61e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.816, tt:5535.709\n",
      "Ep:159, loss:0.00000, loss_test:0.02061, lr:2.58e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.818, tt:5570.905\n",
      "Ep:160, loss:0.00000, loss_test:0.02099, lr:2.55e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.818, tt:5605.659\n",
      "Ep:161, loss:0.00000, loss_test:0.02072, lr:2.53e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.822, tt:5641.117\n",
      "Ep:162, loss:0.00000, loss_test:0.02086, lr:2.50e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.821, tt:5675.844\n",
      "Ep:163, loss:0.00000, loss_test:0.02104, lr:2.48e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.820, tt:5710.417\n",
      "Ep:164, loss:0.00000, loss_test:0.02077, lr:2.45e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.814, tt:5744.237\n",
      "Ep:165, loss:0.00000, loss_test:0.02095, lr:2.43e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.811, tt:5778.668\n",
      "Ep:166, loss:0.00000, loss_test:0.02105, lr:2.40e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.823, tt:5815.391\n",
      "Ep:167, loss:0.00000, loss_test:0.02087, lr:2.38e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.822, tt:5850.059\n",
      "Ep:168, loss:0.00000, loss_test:0.02116, lr:2.36e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.810, tt:5882.937\n",
      "Ep:169, loss:0.00000, loss_test:0.02096, lr:2.33e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.810, tt:5917.720\n",
      "Ep:170, loss:0.00000, loss_test:0.02101, lr:2.31e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.803, tt:5951.274\n",
      "Ep:171, loss:0.00000, loss_test:0.02121, lr:2.29e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.800, tt:5985.625\n",
      "Ep:172, loss:0.00000, loss_test:0.02104, lr:2.26e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.808, tt:6021.829\n",
      "Ep:173, loss:0.00000, loss_test:0.02115, lr:2.24e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.811, tt:6057.039\n",
      "Ep:174, loss:0.00000, loss_test:0.02121, lr:2.22e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.816, tt:6092.856\n",
      "Ep:175, loss:0.00000, loss_test:0.02115, lr:2.20e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.819, tt:6128.119\n",
      "Ep:176, loss:0.00000, loss_test:0.02128, lr:2.17e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.820, tt:6163.074\n",
      "Ep:177, loss:0.00000, loss_test:0.02124, lr:2.15e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.825, tt:6198.762\n",
      "Ep:178, loss:0.00000, loss_test:0.02126, lr:2.13e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.826, tt:6233.886\n",
      "Ep:179, loss:0.00000, loss_test:0.02137, lr:2.11e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.823, tt:6268.057\n",
      "Ep:180, loss:0.00000, loss_test:0.02126, lr:2.09e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.821, tt:6302.620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:181, loss:0.00000, loss_test:0.02134, lr:2.07e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.822, tt:6337.632\n",
      "Ep:182, loss:0.00000, loss_test:0.02137, lr:2.05e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.825, tt:6372.931\n",
      "Ep:183, loss:0.00000, loss_test:0.02137, lr:2.03e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.818, tt:6406.515\n",
      "Ep:184, loss:0.00000, loss_test:0.02132, lr:2.01e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.827, tt:6442.942\n",
      "Ep:185, loss:0.00000, loss_test:0.02145, lr:1.99e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.829, tt:6478.157\n",
      "Ep:186, loss:0.00000, loss_test:0.02151, lr:1.97e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.832, tt:6513.497\n",
      "Ep:187, loss:0.00000, loss_test:0.02138, lr:1.95e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.832, tt:6548.400\n",
      "Ep:188, loss:0.00000, loss_test:0.02150, lr:1.93e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.833, tt:6583.453\n",
      "Ep:189, loss:0.00000, loss_test:0.02149, lr:1.91e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.833, tt:6618.250\n",
      "Ep:190, loss:0.00000, loss_test:0.02151, lr:1.89e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.844, tt:6655.198\n",
      "Ep:191, loss:0.00000, loss_test:0.02155, lr:1.87e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.842, tt:6689.737\n",
      "Ep:192, loss:0.00000, loss_test:0.02155, lr:1.85e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.836, tt:6723.392\n",
      "Ep:193, loss:0.00000, loss_test:0.02159, lr:1.83e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.833, tt:6757.617\n",
      "Ep:194, loss:0.00000, loss_test:0.02159, lr:1.81e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.836, tt:6793.032\n",
      "Ep:195, loss:0.00000, loss_test:0.02165, lr:1.80e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.839, tt:6828.374\n",
      "Ep:196, loss:0.00000, loss_test:0.02166, lr:1.78e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.846, tt:6864.629\n",
      "Ep:197, loss:0.00000, loss_test:0.02168, lr:1.76e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.857, tt:6901.757\n",
      "Ep:198, loss:0.00000, loss_test:0.02162, lr:1.74e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.859, tt:6936.881\n",
      "Ep:199, loss:0.00000, loss_test:0.02174, lr:1.73e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.856, tt:6971.271\n",
      "Ep:200, loss:0.00000, loss_test:0.02169, lr:1.71e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.861, tt:7007.109\n",
      "Ep:201, loss:0.00000, loss_test:0.02171, lr:1.69e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.862, tt:7042.208\n",
      "Ep:202, loss:0.00000, loss_test:0.02179, lr:1.67e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.858, tt:7076.091\n",
      "Ep:203, loss:0.00000, loss_test:0.02173, lr:1.66e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.855, tt:7110.399\n",
      "Ep:204, loss:0.00000, loss_test:0.02180, lr:1.64e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.857, tt:7145.653\n",
      "Ep:205, loss:0.00000, loss_test:0.02183, lr:1.62e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.864, tt:7182.008\n",
      "Ep:206, loss:0.00000, loss_test:0.02181, lr:1.61e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.860, tt:7216.023\n",
      "Ep:207, loss:0.00000, loss_test:0.02185, lr:1.59e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.857, tt:7250.259\n",
      "Ep:208, loss:0.00000, loss_test:0.02184, lr:1.58e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.849, tt:7283.526\n",
      "Ep:209, loss:0.00000, loss_test:0.02191, lr:1.56e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.844, tt:7317.319\n",
      "Ep:210, loss:0.00000, loss_test:0.02190, lr:1.54e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.835, tt:7350.248\n",
      "Ep:211, loss:0.00000, loss_test:0.02191, lr:1.53e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.829, tt:7383.750\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14462, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.372, tt:34.372\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14331, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:34.659, tt:69.318\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.14074, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:33.658, tt:100.973\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13866, lr:1.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:32.891, tt:131.563\n",
      "Ep:4, loss:0.00025, loss_test:0.13868, lr:1.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:32.932, tt:164.661\n",
      "Ep:5, loss:0.00025, loss_test:0.13839, lr:1.00e-02, fs:0.62295 (r=0.768,p=0.524),  time:33.691, tt:202.144\n",
      "Ep:6, loss:0.00025, loss_test:0.13741, lr:1.00e-02, fs:0.61667 (r=0.747,p=0.525),  time:34.024, tt:238.168\n",
      "Ep:7, loss:0.00024, loss_test:0.13636, lr:1.00e-02, fs:0.61157 (r=0.747,p=0.517),  time:34.204, tt:273.635\n",
      "Ep:8, loss:0.00024, loss_test:0.13562, lr:1.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:34.041, tt:306.374\n",
      "Ep:9, loss:0.00024, loss_test:0.13502, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:33.862, tt:338.624\n",
      "Ep:10, loss:0.00023, loss_test:0.13427, lr:1.00e-02, fs:0.63158 (r=0.788,p=0.527),  time:34.068, tt:374.748\n",
      "Ep:11, loss:0.00023, loss_test:0.13318, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:34.246, tt:410.947\n",
      "Ep:12, loss:0.00023, loss_test:0.13190, lr:1.00e-02, fs:0.63598 (r=0.768,p=0.543),  time:34.345, tt:446.482\n",
      "Ep:13, loss:0.00022, loss_test:0.13020, lr:1.00e-02, fs:0.64407 (r=0.768,p=0.555),  time:34.496, tt:482.941\n",
      "Ep:14, loss:0.00022, loss_test:0.12786, lr:9.90e-03, fs:0.64103 (r=0.758,p=0.556),  time:34.594, tt:518.905\n",
      "Ep:15, loss:0.00021, loss_test:0.12673, lr:9.80e-03, fs:0.63519 (r=0.747,p=0.552),  time:34.617, tt:553.871\n",
      "Ep:16, loss:0.00021, loss_test:0.12393, lr:9.70e-03, fs:0.64069 (r=0.747,p=0.561),  time:34.711, tt:590.081\n",
      "Ep:17, loss:0.00020, loss_test:0.12180, lr:9.61e-03, fs:0.65236 (r=0.768,p=0.567),  time:34.703, tt:624.646\n",
      "Ep:18, loss:0.00020, loss_test:0.11922, lr:9.51e-03, fs:0.64348 (r=0.747,p=0.565),  time:34.703, tt:659.364\n",
      "Ep:19, loss:0.00019, loss_test:0.11646, lr:9.41e-03, fs:0.66667 (r=0.747,p=0.602),  time:34.790, tt:695.791\n",
      "Ep:20, loss:0.00019, loss_test:0.11303, lr:9.32e-03, fs:0.68182 (r=0.758,p=0.620),  time:34.761, tt:729.989\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.10986, lr:9.32e-03, fs:0.69369 (r=0.778,p=0.626),  time:34.861, tt:766.945\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.10781, lr:9.32e-03, fs:0.71749 (r=0.808,p=0.645),  time:34.885, tt:802.345\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.10440, lr:9.32e-03, fs:0.70698 (r=0.768,p=0.655),  time:34.873, tt:836.947\n",
      "Ep:24, loss:0.00017, loss_test:0.10307, lr:9.32e-03, fs:0.73973 (r=0.818,p=0.675),  time:34.888, tt:872.198\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.10061, lr:9.32e-03, fs:0.73239 (r=0.788,p=0.684),  time:34.921, tt:907.941\n",
      "Ep:26, loss:0.00016, loss_test:0.09898, lr:9.32e-03, fs:0.74074 (r=0.808,p=0.684),  time:34.926, tt:943.001\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09696, lr:9.32e-03, fs:0.73934 (r=0.788,p=0.696),  time:34.999, tt:979.984\n",
      "Ep:28, loss:0.00015, loss_test:0.09569, lr:9.32e-03, fs:0.75576 (r=0.828,p=0.695),  time:35.079, tt:1017.305\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09385, lr:9.32e-03, fs:0.75000 (r=0.788,p=0.716),  time:35.073, tt:1052.190\n",
      "Ep:30, loss:0.00014, loss_test:0.09289, lr:9.32e-03, fs:0.76636 (r=0.828,p=0.713),  time:35.079, tt:1087.441\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09142, lr:9.32e-03, fs:0.76415 (r=0.818,p=0.717),  time:35.184, tt:1125.900\n",
      "Ep:32, loss:0.00013, loss_test:0.09040, lr:9.32e-03, fs:0.75238 (r=0.798,p=0.712),  time:35.241, tt:1162.963\n",
      "Ep:33, loss:0.00013, loss_test:0.08894, lr:9.32e-03, fs:0.77358 (r=0.828,p=0.726),  time:35.287, tt:1199.762\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08965, lr:9.32e-03, fs:0.75362 (r=0.788,p=0.722),  time:35.314, tt:1235.988\n",
      "Ep:35, loss:0.00012, loss_test:0.08849, lr:9.32e-03, fs:0.77143 (r=0.818,p=0.730),  time:35.341, tt:1272.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00012, loss_test:0.08671, lr:9.32e-03, fs:0.74872 (r=0.737,p=0.760),  time:35.363, tt:1308.441\n",
      "Ep:37, loss:0.00011, loss_test:0.08742, lr:9.32e-03, fs:0.76923 (r=0.808,p=0.734),  time:35.346, tt:1343.163\n",
      "Ep:38, loss:0.00011, loss_test:0.08608, lr:9.32e-03, fs:0.73469 (r=0.727,p=0.742),  time:35.399, tt:1380.554\n",
      "Ep:39, loss:0.00011, loss_test:0.08627, lr:9.32e-03, fs:0.75000 (r=0.758,p=0.743),  time:35.427, tt:1417.075\n",
      "Ep:40, loss:0.00010, loss_test:0.08539, lr:9.32e-03, fs:0.74000 (r=0.747,p=0.733),  time:35.483, tt:1454.786\n",
      "Ep:41, loss:0.00010, loss_test:0.08498, lr:9.32e-03, fs:0.73298 (r=0.707,p=0.761),  time:35.493, tt:1490.710\n",
      "Ep:42, loss:0.00010, loss_test:0.08522, lr:9.32e-03, fs:0.76617 (r=0.778,p=0.755),  time:35.487, tt:1525.936\n",
      "Ep:43, loss:0.00009, loss_test:0.08258, lr:9.32e-03, fs:0.75532 (r=0.717,p=0.798),  time:35.492, tt:1561.631\n",
      "Ep:44, loss:0.00009, loss_test:0.08607, lr:9.32e-03, fs:0.76142 (r=0.758,p=0.765),  time:35.496, tt:1597.337\n",
      "Ep:45, loss:0.00009, loss_test:0.08262, lr:9.23e-03, fs:0.74866 (r=0.707,p=0.795),  time:35.514, tt:1633.637\n",
      "Ep:46, loss:0.00009, loss_test:0.08122, lr:9.14e-03, fs:0.74227 (r=0.727,p=0.758),  time:35.527, tt:1669.764\n",
      "Ep:47, loss:0.00008, loss_test:0.08592, lr:9.04e-03, fs:0.70652 (r=0.657,p=0.765),  time:35.541, tt:1705.955\n",
      "Ep:48, loss:0.00008, loss_test:0.08179, lr:8.95e-03, fs:0.75258 (r=0.737,p=0.768),  time:35.501, tt:1739.528\n",
      "Ep:49, loss:0.00008, loss_test:0.08257, lr:8.86e-03, fs:0.71910 (r=0.646,p=0.810),  time:35.489, tt:1774.474\n",
      "Ep:50, loss:0.00008, loss_test:0.08154, lr:8.78e-03, fs:0.75258 (r=0.737,p=0.768),  time:35.483, tt:1809.621\n",
      "Ep:51, loss:0.00008, loss_test:0.08397, lr:8.69e-03, fs:0.72928 (r=0.667,p=0.805),  time:35.494, tt:1845.685\n",
      "Ep:52, loss:0.00007, loss_test:0.08002, lr:8.60e-03, fs:0.75132 (r=0.717,p=0.789),  time:35.493, tt:1881.127\n",
      "Ep:53, loss:0.00007, loss_test:0.08087, lr:8.51e-03, fs:0.75000 (r=0.697,p=0.812),  time:35.496, tt:1916.787\n",
      "Ep:54, loss:0.00007, loss_test:0.08108, lr:8.43e-03, fs:0.73797 (r=0.697,p=0.784),  time:35.513, tt:1953.190\n",
      "Ep:55, loss:0.00007, loss_test:0.07966, lr:8.35e-03, fs:0.75824 (r=0.697,p=0.831),  time:35.529, tt:1989.608\n",
      "Ep:56, loss:0.00007, loss_test:0.07938, lr:8.26e-03, fs:0.74317 (r=0.687,p=0.810),  time:35.542, tt:2025.887\n",
      "Ep:57, loss:0.00006, loss_test:0.08417, lr:8.18e-03, fs:0.71910 (r=0.646,p=0.810),  time:35.544, tt:2061.570\n",
      "Ep:58, loss:0.00006, loss_test:0.07750, lr:8.10e-03, fs:0.76503 (r=0.707,p=0.833),  time:35.513, tt:2095.245\n",
      "Ep:59, loss:0.00006, loss_test:0.08105, lr:8.02e-03, fs:0.76667 (r=0.697,p=0.852),  time:35.483, tt:2128.999\n",
      "Ep:60, loss:0.00006, loss_test:0.08189, lr:7.94e-03, fs:0.74595 (r=0.697,p=0.802),  time:35.493, tt:2165.083\n",
      "Ep:61, loss:0.00006, loss_test:0.08267, lr:7.86e-03, fs:0.74576 (r=0.667,p=0.846),  time:35.497, tt:2200.823\n",
      "Ep:62, loss:0.00006, loss_test:0.07795, lr:7.78e-03, fs:0.78261 (r=0.727,p=0.847),  time:35.494, tt:2236.095\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.08080, lr:7.78e-03, fs:0.75824 (r=0.697,p=0.831),  time:35.480, tt:2270.689\n",
      "Ep:64, loss:0.00006, loss_test:0.07946, lr:7.78e-03, fs:0.75000 (r=0.667,p=0.857),  time:35.438, tt:2303.474\n",
      "Ep:65, loss:0.00005, loss_test:0.07799, lr:7.78e-03, fs:0.75824 (r=0.697,p=0.831),  time:35.455, tt:2340.048\n",
      "Ep:66, loss:0.00005, loss_test:0.08266, lr:7.78e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.463, tt:2376.040\n",
      "Ep:67, loss:0.00005, loss_test:0.07726, lr:7.78e-03, fs:0.76503 (r=0.707,p=0.833),  time:35.491, tt:2413.355\n",
      "Ep:68, loss:0.00005, loss_test:0.08105, lr:7.78e-03, fs:0.75294 (r=0.646,p=0.901),  time:35.509, tt:2450.134\n",
      "Ep:69, loss:0.00005, loss_test:0.07961, lr:7.78e-03, fs:0.77778 (r=0.707,p=0.864),  time:35.515, tt:2486.069\n",
      "Ep:70, loss:0.00005, loss_test:0.08046, lr:7.78e-03, fs:0.76301 (r=0.667,p=0.892),  time:35.519, tt:2521.837\n",
      "Ep:71, loss:0.00005, loss_test:0.07833, lr:7.78e-03, fs:0.77778 (r=0.707,p=0.864),  time:35.533, tt:2558.397\n",
      "Ep:72, loss:0.00005, loss_test:0.08218, lr:7.78e-03, fs:0.76136 (r=0.677,p=0.870),  time:35.540, tt:2594.456\n",
      "Ep:73, loss:0.00005, loss_test:0.07833, lr:7.78e-03, fs:0.75706 (r=0.677,p=0.859),  time:35.554, tt:2631.011\n",
      "Ep:74, loss:0.00005, loss_test:0.07975, lr:7.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.557, tt:2666.738\n",
      "Ep:75, loss:0.00004, loss_test:0.08001, lr:7.62e-03, fs:0.76404 (r=0.687,p=0.861),  time:35.560, tt:2702.593\n",
      "Ep:76, loss:0.00004, loss_test:0.08202, lr:7.55e-03, fs:0.76744 (r=0.667,p=0.904),  time:35.547, tt:2737.108\n",
      "Ep:77, loss:0.00004, loss_test:0.07832, lr:7.47e-03, fs:0.76404 (r=0.687,p=0.861),  time:35.556, tt:2773.335\n",
      "Ep:78, loss:0.00004, loss_test:0.08186, lr:7.40e-03, fs:0.77457 (r=0.677,p=0.905),  time:35.538, tt:2807.539\n",
      "Ep:79, loss:0.00004, loss_test:0.07915, lr:7.32e-03, fs:0.77348 (r=0.707,p=0.854),  time:35.547, tt:2843.749\n",
      "Ep:80, loss:0.00004, loss_test:0.08491, lr:7.25e-03, fs:0.75740 (r=0.646,p=0.914),  time:35.550, tt:2879.563\n",
      "Ep:81, loss:0.00004, loss_test:0.07939, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.535, tt:2913.879\n",
      "Ep:82, loss:0.00004, loss_test:0.08182, lr:7.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:35.563, tt:2951.690\n",
      "Ep:83, loss:0.00004, loss_test:0.08243, lr:7.03e-03, fs:0.76301 (r=0.667,p=0.892),  time:35.567, tt:2987.637\n",
      "Ep:84, loss:0.00004, loss_test:0.08010, lr:6.96e-03, fs:0.76836 (r=0.687,p=0.872),  time:35.567, tt:3023.207\n",
      "Ep:85, loss:0.00004, loss_test:0.08607, lr:6.89e-03, fs:0.75740 (r=0.646,p=0.914),  time:35.577, tt:3059.646\n",
      "Ep:86, loss:0.00004, loss_test:0.08249, lr:6.83e-03, fs:0.76836 (r=0.687,p=0.872),  time:35.589, tt:3096.282\n",
      "Ep:87, loss:0.00004, loss_test:0.08408, lr:6.76e-03, fs:0.76471 (r=0.657,p=0.915),  time:35.548, tt:3128.192\n",
      "Ep:88, loss:0.00004, loss_test:0.07976, lr:6.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:35.555, tt:3164.377\n",
      "Ep:89, loss:0.00003, loss_test:0.08493, lr:6.62e-03, fs:0.73054 (r=0.616,p=0.897),  time:35.567, tt:3201.036\n",
      "Ep:90, loss:0.00003, loss_test:0.08016, lr:6.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:35.542, tt:3234.333\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00003, loss_test:0.08463, lr:6.56e-03, fs:0.74251 (r=0.626,p=0.912),  time:35.507, tt:3266.650\n",
      "Ep:92, loss:0.00003, loss_test:0.08261, lr:6.56e-03, fs:0.77714 (r=0.687,p=0.895),  time:35.504, tt:3301.852\n",
      "Ep:93, loss:0.00003, loss_test:0.08320, lr:6.56e-03, fs:0.77193 (r=0.667,p=0.917),  time:35.494, tt:3336.411\n",
      "Ep:94, loss:0.00003, loss_test:0.08161, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:35.488, tt:3371.404\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00003, loss_test:0.08345, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:35.496, tt:3407.623\n",
      "Ep:96, loss:0.00003, loss_test:0.08621, lr:6.56e-03, fs:0.76471 (r=0.657,p=0.915),  time:35.486, tt:3442.097\n",
      "Ep:97, loss:0.00003, loss_test:0.08159, lr:6.56e-03, fs:0.78857 (r=0.697,p=0.908),  time:35.480, tt:3476.996\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00003, loss_test:0.08271, lr:6.56e-03, fs:0.78161 (r=0.687,p=0.907),  time:35.478, tt:3512.298\n",
      "Ep:99, loss:0.00003, loss_test:0.08599, lr:6.56e-03, fs:0.75740 (r=0.646,p=0.914),  time:35.472, tt:3547.211\n",
      "Ep:100, loss:0.00003, loss_test:0.08345, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.485, tt:3583.939\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00003, loss_test:0.08381, lr:6.56e-03, fs:0.77457 (r=0.677,p=0.905),  time:35.494, tt:3620.419\n",
      "Ep:102, loss:0.00003, loss_test:0.08725, lr:6.56e-03, fs:0.71951 (r=0.596,p=0.908),  time:35.509, tt:3657.445\n",
      "Ep:103, loss:0.00003, loss_test:0.08039, lr:6.56e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.513, tt:3693.325\n",
      "Ep:104, loss:0.00003, loss_test:0.08810, lr:6.56e-03, fs:0.71166 (r=0.586,p=0.906),  time:35.502, tt:3727.703\n",
      "Ep:105, loss:0.00003, loss_test:0.07903, lr:6.56e-03, fs:0.79545 (r=0.707,p=0.909),  time:35.508, tt:3763.850\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00003, loss_test:0.08889, lr:6.56e-03, fs:0.70370 (r=0.576,p=0.905),  time:35.510, tt:3799.533\n",
      "Ep:107, loss:0.00003, loss_test:0.08532, lr:6.56e-03, fs:0.75294 (r=0.646,p=0.901),  time:35.518, tt:3835.972\n",
      "Ep:108, loss:0.00003, loss_test:0.08506, lr:6.56e-03, fs:0.77193 (r=0.667,p=0.917),  time:35.515, tt:3871.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00003, loss_test:0.08674, lr:6.56e-03, fs:0.76647 (r=0.646,p=0.941),  time:35.522, tt:3907.441\n",
      "Ep:110, loss:0.00003, loss_test:0.08386, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:35.525, tt:3943.320\n",
      "Ep:111, loss:0.00002, loss_test:0.08669, lr:6.56e-03, fs:0.71951 (r=0.596,p=0.908),  time:35.531, tt:3979.459\n",
      "Ep:112, loss:0.00002, loss_test:0.08268, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:35.534, tt:4015.351\n",
      "Ep:113, loss:0.00002, loss_test:0.08570, lr:6.56e-03, fs:0.77193 (r=0.667,p=0.917),  time:35.538, tt:4051.357\n",
      "Ep:114, loss:0.00002, loss_test:0.08632, lr:6.56e-03, fs:0.72727 (r=0.606,p=0.909),  time:35.532, tt:4086.232\n",
      "Ep:115, loss:0.00002, loss_test:0.08240, lr:6.56e-03, fs:0.79769 (r=0.697,p=0.932),  time:35.542, tt:4122.899\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.08834, lr:6.56e-03, fs:0.74251 (r=0.626,p=0.912),  time:35.537, tt:4157.847\n",
      "Ep:117, loss:0.00002, loss_test:0.08218, lr:6.56e-03, fs:0.77907 (r=0.677,p=0.918),  time:35.532, tt:4192.799\n",
      "Ep:118, loss:0.00002, loss_test:0.08511, lr:6.56e-03, fs:0.80000 (r=0.687,p=0.958),  time:35.528, tt:4227.859\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.08475, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.520, tt:4262.416\n",
      "Ep:120, loss:0.00002, loss_test:0.08879, lr:6.56e-03, fs:0.71166 (r=0.586,p=0.906),  time:35.511, tt:4296.886\n",
      "Ep:121, loss:0.00002, loss_test:0.08478, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.504, tt:4331.449\n",
      "Ep:122, loss:0.00002, loss_test:0.08561, lr:6.56e-03, fs:0.76471 (r=0.657,p=0.915),  time:35.516, tt:4368.448\n",
      "Ep:123, loss:0.00002, loss_test:0.09371, lr:6.56e-03, fs:0.69939 (r=0.576,p=0.891),  time:35.513, tt:4403.655\n",
      "Ep:124, loss:0.00002, loss_test:0.08459, lr:6.56e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.510, tt:4438.805\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00002, loss_test:0.08891, lr:6.56e-03, fs:0.69136 (r=0.566,p=0.889),  time:35.506, tt:4473.756\n",
      "Ep:126, loss:0.00002, loss_test:0.08540, lr:6.56e-03, fs:0.79290 (r=0.677,p=0.957),  time:35.513, tt:4510.095\n",
      "Ep:127, loss:0.00002, loss_test:0.08621, lr:6.56e-03, fs:0.79769 (r=0.697,p=0.932),  time:35.511, tt:4545.445\n",
      "Ep:128, loss:0.00002, loss_test:0.08808, lr:6.56e-03, fs:0.79290 (r=0.677,p=0.957),  time:35.511, tt:4580.975\n",
      "Ep:129, loss:0.00002, loss_test:0.08511, lr:6.56e-03, fs:0.79769 (r=0.697,p=0.932),  time:35.513, tt:4616.743\n",
      "Ep:130, loss:0.00002, loss_test:0.08823, lr:6.56e-03, fs:0.78363 (r=0.677,p=0.931),  time:35.500, tt:4650.503\n",
      "Ep:131, loss:0.00002, loss_test:0.08602, lr:6.56e-03, fs:0.79290 (r=0.677,p=0.957),  time:35.505, tt:4686.644\n",
      "Ep:132, loss:0.00002, loss_test:0.08710, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.511, tt:4723.011\n",
      "Ep:133, loss:0.00002, loss_test:0.09000, lr:6.56e-03, fs:0.72956 (r=0.586,p=0.967),  time:35.514, tt:4758.910\n",
      "Ep:134, loss:0.00002, loss_test:0.08494, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.515, tt:4794.490\n",
      "Ep:135, loss:0.00002, loss_test:0.09132, lr:6.56e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.514, tt:4829.881\n",
      "Ep:136, loss:0.00002, loss_test:0.08505, lr:6.49e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.517, tt:4865.800\n",
      "Ep:137, loss:0.00002, loss_test:0.09156, lr:6.43e-03, fs:0.71166 (r=0.586,p=0.906),  time:35.514, tt:4900.863\n",
      "Ep:138, loss:0.00002, loss_test:0.08880, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:35.502, tt:4934.769\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00002, loss_test:0.08818, lr:6.36e-03, fs:0.73494 (r=0.616,p=0.910),  time:35.514, tt:4972.025\n",
      "Ep:140, loss:0.00002, loss_test:0.09173, lr:6.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.520, tt:5008.380\n",
      "Ep:141, loss:0.00002, loss_test:0.09004, lr:6.36e-03, fs:0.74390 (r=0.616,p=0.938),  time:35.510, tt:5042.463\n",
      "Ep:142, loss:0.00001, loss_test:0.09031, lr:6.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:35.512, tt:5078.214\n",
      "Ep:143, loss:0.00001, loss_test:0.08850, lr:6.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.511, tt:5113.609\n",
      "Ep:144, loss:0.00001, loss_test:0.08835, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:35.510, tt:5148.951\n",
      "Ep:145, loss:0.00001, loss_test:0.09138, lr:6.36e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.503, tt:5183.482\n",
      "Ep:146, loss:0.00001, loss_test:0.08827, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:35.495, tt:5217.809\n",
      "Ep:147, loss:0.00001, loss_test:0.08897, lr:6.36e-03, fs:0.79042 (r=0.667,p=0.971),  time:35.491, tt:5252.728\n",
      "Ep:148, loss:0.00001, loss_test:0.09262, lr:6.36e-03, fs:0.70370 (r=0.576,p=0.905),  time:35.497, tt:5288.984\n",
      "Ep:149, loss:0.00001, loss_test:0.08819, lr:6.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:35.500, tt:5324.939\n",
      "Ep:150, loss:0.00001, loss_test:0.09370, lr:6.30e-03, fs:0.70370 (r=0.576,p=0.905),  time:35.491, tt:5359.175\n",
      "Ep:151, loss:0.00001, loss_test:0.09381, lr:6.24e-03, fs:0.74534 (r=0.606,p=0.968),  time:35.492, tt:5394.778\n",
      "Ep:152, loss:0.00001, loss_test:0.09234, lr:6.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.492, tt:5430.264\n",
      "Ep:153, loss:0.00001, loss_test:0.09121, lr:6.11e-03, fs:0.74390 (r=0.616,p=0.938),  time:35.484, tt:5464.604\n",
      "Ep:154, loss:0.00001, loss_test:0.09061, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.476, tt:5498.767\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.09385, lr:6.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:35.477, tt:5534.436\n",
      "Ep:156, loss:0.00001, loss_test:0.09421, lr:6.05e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.470, tt:5568.823\n",
      "Ep:157, loss:0.00001, loss_test:0.08988, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.474, tt:5604.953\n",
      "Ep:158, loss:0.00001, loss_test:0.09302, lr:6.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:35.470, tt:5639.757\n",
      "Ep:159, loss:0.00001, loss_test:0.09118, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.474, tt:5675.787\n",
      "Ep:160, loss:0.00001, loss_test:0.09249, lr:6.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:35.470, tt:5710.658\n",
      "Ep:161, loss:0.00001, loss_test:0.09140, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.472, tt:5746.402\n",
      "Ep:162, loss:0.00001, loss_test:0.09294, lr:6.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:35.473, tt:5782.162\n",
      "Ep:163, loss:0.00001, loss_test:0.09530, lr:6.05e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.476, tt:5818.050\n",
      "Ep:164, loss:0.00001, loss_test:0.09199, lr:6.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.484, tt:5854.829\n",
      "Ep:165, loss:0.00001, loss_test:0.09274, lr:6.05e-03, fs:0.70807 (r=0.576,p=0.919),  time:35.492, tt:5891.710\n",
      "Ep:166, loss:0.00001, loss_test:0.09368, lr:5.99e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.501, tt:5928.654\n",
      "Ep:167, loss:0.00001, loss_test:0.09315, lr:5.93e-03, fs:0.72393 (r=0.596,p=0.922),  time:35.503, tt:5964.477\n",
      "Ep:168, loss:0.00001, loss_test:0.09271, lr:5.87e-03, fs:0.81176 (r=0.697,p=0.972),  time:35.522, tt:6003.240\n",
      "Ep:169, loss:0.00001, loss_test:0.09874, lr:5.81e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.530, tt:6040.048\n",
      "Ep:170, loss:0.00001, loss_test:0.09024, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:35.524, tt:6074.567\n",
      "Ep:171, loss:0.00001, loss_test:0.09530, lr:5.70e-03, fs:0.72956 (r=0.586,p=0.967),  time:35.522, tt:6109.762\n",
      "Ep:172, loss:0.00001, loss_test:0.09244, lr:5.64e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.526, tt:6146.022\n",
      "Ep:173, loss:0.00001, loss_test:0.09374, lr:5.58e-03, fs:0.74534 (r=0.606,p=0.968),  time:35.536, tt:6183.197\n",
      "Ep:174, loss:0.00001, loss_test:0.09522, lr:5.53e-03, fs:0.70513 (r=0.556,p=0.965),  time:35.544, tt:6220.162\n",
      "Ep:175, loss:0.00001, loss_test:0.09373, lr:5.47e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.551, tt:6256.935\n",
      "Ep:176, loss:0.00001, loss_test:0.09446, lr:5.42e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.552, tt:6292.679\n",
      "Ep:177, loss:0.00001, loss_test:0.09389, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:35.546, tt:6327.175\n",
      "Ep:178, loss:0.00001, loss_test:0.09262, lr:5.31e-03, fs:0.74847 (r=0.616,p=0.953),  time:35.544, tt:6362.398\n",
      "Ep:179, loss:0.00001, loss_test:0.09259, lr:5.26e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.533, tt:6395.977\n",
      "Ep:180, loss:0.00001, loss_test:0.09619, lr:5.20e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.527, tt:6430.408\n",
      "Ep:181, loss:0.00001, loss_test:0.08969, lr:5.15e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.531, tt:6466.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:182, loss:0.00001, loss_test:0.09627, lr:5.10e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.534, tt:6502.787\n",
      "Ep:183, loss:0.00001, loss_test:0.09427, lr:5.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:35.542, tt:6539.748\n",
      "Ep:184, loss:0.00001, loss_test:0.09251, lr:5.00e-03, fs:0.74074 (r=0.606,p=0.952),  time:35.561, tt:6578.739\n",
      "Ep:185, loss:0.00001, loss_test:0.09497, lr:4.95e-03, fs:0.73750 (r=0.596,p=0.967),  time:35.558, tt:6613.839\n",
      "Ep:186, loss:0.00001, loss_test:0.09611, lr:4.90e-03, fs:0.72152 (r=0.576,p=0.966),  time:35.559, tt:6649.614\n",
      "Ep:187, loss:0.00001, loss_test:0.09073, lr:4.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.564, tt:6686.066\n",
      "Ep:188, loss:0.00001, loss_test:0.09325, lr:4.80e-03, fs:0.72956 (r=0.586,p=0.967),  time:35.570, tt:6722.761\n",
      "Ep:189, loss:0.00001, loss_test:0.09478, lr:4.75e-03, fs:0.73750 (r=0.596,p=0.967),  time:35.567, tt:6757.644\n",
      "Ep:190, loss:0.00001, loss_test:0.09187, lr:4.71e-03, fs:0.76829 (r=0.636,p=0.969),  time:35.570, tt:6793.919\n",
      "Ep:191, loss:0.00001, loss_test:0.09188, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.573, tt:6829.970\n",
      "Ep:192, loss:0.00001, loss_test:0.09530, lr:4.61e-03, fs:0.70513 (r=0.556,p=0.965),  time:35.565, tt:6863.970\n",
      "Ep:193, loss:0.00001, loss_test:0.09269, lr:4.57e-03, fs:0.78313 (r=0.657,p=0.970),  time:35.565, tt:6899.582\n",
      "Ep:194, loss:0.00001, loss_test:0.09234, lr:4.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.564, tt:6934.896\n",
      "Ep:195, loss:0.00001, loss_test:0.09608, lr:4.48e-03, fs:0.72152 (r=0.576,p=0.966),  time:35.565, tt:6970.707\n",
      "Ep:196, loss:0.00001, loss_test:0.09220, lr:4.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.583, tt:7009.795\n",
      "Ep:197, loss:0.00001, loss_test:0.09209, lr:4.39e-03, fs:0.73292 (r=0.596,p=0.952),  time:35.575, tt:7043.919\n",
      "Ep:198, loss:0.00001, loss_test:0.09356, lr:4.34e-03, fs:0.73750 (r=0.596,p=0.967),  time:35.567, tt:7077.822\n",
      "Ep:199, loss:0.00001, loss_test:0.09340, lr:4.30e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.561, tt:7112.236\n",
      "Ep:200, loss:0.00001, loss_test:0.09383, lr:4.26e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.571, tt:7149.774\n",
      "Ep:201, loss:0.00001, loss_test:0.09320, lr:4.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.576, tt:7186.322\n",
      "Ep:202, loss:0.00001, loss_test:0.09435, lr:4.17e-03, fs:0.71698 (r=0.576,p=0.950),  time:35.586, tt:7223.957\n",
      "Ep:203, loss:0.00001, loss_test:0.09296, lr:4.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.588, tt:7259.901\n",
      "Ep:204, loss:0.00001, loss_test:0.09469, lr:4.09e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.586, tt:7295.124\n",
      "Ep:205, loss:0.00001, loss_test:0.09276, lr:4.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:35.584, tt:7330.316\n",
      "Ep:206, loss:0.00001, loss_test:0.09567, lr:4.01e-03, fs:0.70064 (r=0.556,p=0.948),  time:35.594, tt:7368.015\n",
      "Ep:207, loss:0.00001, loss_test:0.09315, lr:3.97e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.606, tt:7406.135\n",
      "Ep:208, loss:0.00001, loss_test:0.09416, lr:3.93e-03, fs:0.70886 (r=0.566,p=0.949),  time:35.613, tt:7443.105\n",
      "Ep:209, loss:0.00001, loss_test:0.09489, lr:3.89e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.624, tt:7481.097\n",
      "Ep:210, loss:0.00001, loss_test:0.09585, lr:3.85e-03, fs:0.72500 (r=0.586,p=0.951),  time:35.632, tt:7518.359\n",
      "Ep:211, loss:0.00001, loss_test:0.09425, lr:3.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.630, tt:7553.499\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02952, lr:6.00e-02, fs:0.56731 (r=0.596,p=0.541),  time:31.360, tt:31.360\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02329, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:32.026, tt:64.051\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02620, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.430, tt:91.289\n",
      "Ep:3, loss:0.00005, loss_test:0.02780, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.789, tt:119.155\n",
      "Ep:4, loss:0.00005, loss_test:0.02817, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.142, tt:150.711\n",
      "Ep:5, loss:0.00005, loss_test:0.02789, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.988, tt:185.926\n",
      "Ep:6, loss:0.00005, loss_test:0.02704, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.504, tt:220.530\n",
      "Ep:7, loss:0.00005, loss_test:0.02591, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:31.984, tt:255.870\n",
      "Ep:8, loss:0.00005, loss_test:0.02466, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:32.114, tt:289.022\n",
      "Ep:9, loss:0.00005, loss_test:0.02382, lr:6.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:32.031, tt:320.309\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02352, lr:6.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:32.010, tt:352.105\n",
      "Ep:11, loss:0.00004, loss_test:0.02339, lr:6.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:32.133, tt:385.595\n",
      "Ep:12, loss:0.00004, loss_test:0.02279, lr:6.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:32.525, tt:422.826\n",
      "Ep:13, loss:0.00004, loss_test:0.02174, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:32.610, tt:456.537\n",
      "Ep:14, loss:0.00004, loss_test:0.02069, lr:6.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:32.782, tt:491.728\n",
      "Ep:15, loss:0.00004, loss_test:0.01989, lr:6.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:32.851, tt:525.616\n",
      "Ep:16, loss:0.00004, loss_test:0.01924, lr:6.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:32.930, tt:559.811\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:33.122, tt:596.203\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:33.321, tt:633.098\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:33.512, tt:670.242\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01760, lr:6.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:33.671, tt:707.082\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01731, lr:6.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:33.945, tt:746.791\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:34.033, tt:782.756\n",
      "Ep:23, loss:0.00003, loss_test:0.01664, lr:6.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:34.134, tt:819.217\n",
      "Ep:24, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:34.278, tt:856.944\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:34.334, tt:892.677\n",
      "Ep:26, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:34.394, tt:928.639\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:34.460, tt:964.882\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.497, tt:1000.413\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01530, lr:6.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:34.555, tt:1036.635\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01516, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:34.611, tt:1072.957\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:34.652, tt:1108.849\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:34.707, tt:1145.318\n",
      "Ep:33, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:34.767, tt:1182.069\n",
      "Ep:34, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:34.806, tt:1218.205\n",
      "Ep:35, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:34.794, tt:1252.580\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01386, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:34.785, tt:1287.048\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01366, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.849, tt:1324.271\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.864, tt:1359.695\n",
      "Ep:39, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.883, tt:1395.308\n",
      "Ep:40, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:34.926, tt:1431.968\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:34.941, tt:1467.520\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:34.971, tt:1503.748\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:35.003, tt:1540.127\n",
      "Ep:44, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.007, tt:1575.319\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:34.997, tt:1609.873\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01247, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:34.975, tt:1643.814\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01237, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:34.981, tt:1679.110\n",
      "Ep:48, loss:0.00001, loss_test:0.01231, lr:6.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:35.029, tt:1716.401\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01222, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:35.040, tt:1751.998\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:35.036, tt:1786.826\n",
      "Ep:51, loss:0.00001, loss_test:0.01210, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:35.075, tt:1823.897\n",
      "Ep:52, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:35.080, tt:1859.224\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01202, lr:6.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.109, tt:1895.902\n",
      "Ep:54, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:35.121, tt:1931.681\n",
      "Ep:55, loss:0.00001, loss_test:0.01202, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:35.132, tt:1967.408\n",
      "Ep:56, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:35.139, tt:2002.934\n",
      "Ep:57, loss:0.00001, loss_test:0.01201, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:35.127, tt:2037.355\n",
      "Ep:58, loss:0.00001, loss_test:0.01203, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:35.116, tt:2071.826\n",
      "Ep:59, loss:0.00001, loss_test:0.01202, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:35.149, tt:2108.969\n",
      "Ep:60, loss:0.00001, loss_test:0.01207, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:35.172, tt:2145.498\n",
      "Ep:61, loss:0.00001, loss_test:0.01208, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.180, tt:2181.136\n",
      "Ep:62, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.176, tt:2216.080\n",
      "Ep:63, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:35.161, tt:2250.311\n",
      "Ep:64, loss:0.00001, loss_test:0.01220, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:35.176, tt:2286.411\n",
      "Ep:65, loss:0.00001, loss_test:0.01227, lr:5.88e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.177, tt:2321.673\n",
      "Ep:66, loss:0.00001, loss_test:0.01232, lr:5.82e-02, fs:0.81818 (r=0.818,p=0.818),  time:35.185, tt:2357.412\n",
      "Ep:67, loss:0.00001, loss_test:0.01237, lr:5.76e-02, fs:0.81218 (r=0.808,p=0.816),  time:35.193, tt:2393.097\n",
      "Ep:68, loss:0.00001, loss_test:0.01241, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:35.205, tt:2429.168\n",
      "Ep:69, loss:0.00001, loss_test:0.01247, lr:5.65e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.224, tt:2465.697\n",
      "Ep:70, loss:0.00001, loss_test:0.01251, lr:5.59e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.233, tt:2501.558\n",
      "Ep:71, loss:0.00001, loss_test:0.01261, lr:5.54e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.259, tt:2538.636\n",
      "Ep:72, loss:0.00001, loss_test:0.01268, lr:5.48e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.271, tt:2574.814\n",
      "Ep:73, loss:0.00001, loss_test:0.01269, lr:5.43e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.281, tt:2610.829\n",
      "Ep:74, loss:0.00001, loss_test:0.01277, lr:5.37e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.283, tt:2646.213\n",
      "Ep:75, loss:0.00001, loss_test:0.01289, lr:5.32e-02, fs:0.81026 (r=0.798,p=0.823),  time:35.275, tt:2680.908\n",
      "Ep:76, loss:0.00001, loss_test:0.01297, lr:5.27e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.274, tt:2716.096\n",
      "Ep:77, loss:0.00001, loss_test:0.01299, lr:5.21e-02, fs:0.81026 (r=0.798,p=0.823),  time:35.277, tt:2751.584\n",
      "Ep:78, loss:0.00001, loss_test:0.01308, lr:5.16e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.265, tt:2785.963\n",
      "Ep:79, loss:0.00001, loss_test:0.01313, lr:5.11e-02, fs:0.80829 (r=0.788,p=0.830),  time:35.276, tt:2822.117\n",
      "Ep:80, loss:0.00001, loss_test:0.01316, lr:5.06e-02, fs:0.80208 (r=0.778,p=0.828),  time:35.282, tt:2857.818\n",
      "Ep:81, loss:0.00001, loss_test:0.01326, lr:5.01e-02, fs:0.80208 (r=0.778,p=0.828),  time:35.285, tt:2893.341\n",
      "Ep:82, loss:0.00001, loss_test:0.01331, lr:4.96e-02, fs:0.80628 (r=0.778,p=0.837),  time:35.298, tt:2929.712\n",
      "Ep:83, loss:0.00001, loss_test:0.01337, lr:4.91e-02, fs:0.80628 (r=0.778,p=0.837),  time:35.308, tt:2965.897\n",
      "Ep:84, loss:0.00001, loss_test:0.01349, lr:4.86e-02, fs:0.80628 (r=0.778,p=0.837),  time:35.312, tt:3001.520\n",
      "Ep:85, loss:0.00001, loss_test:0.01353, lr:4.81e-02, fs:0.80628 (r=0.778,p=0.837),  time:35.304, tt:3036.144\n",
      "Ep:86, loss:0.00001, loss_test:0.01358, lr:4.76e-02, fs:0.80628 (r=0.778,p=0.837),  time:35.294, tt:3070.538\n",
      "Ep:87, loss:0.00001, loss_test:0.01365, lr:4.71e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.295, tt:3105.937\n",
      "Ep:88, loss:0.00001, loss_test:0.01369, lr:4.67e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.287, tt:3140.508\n",
      "Ep:89, loss:0.00000, loss_test:0.01378, lr:4.62e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.275, tt:3174.718\n",
      "Ep:90, loss:0.00000, loss_test:0.01389, lr:4.57e-02, fs:0.79787 (r=0.758,p=0.843),  time:35.275, tt:3210.004\n",
      "Ep:91, loss:0.00000, loss_test:0.01395, lr:4.53e-02, fs:0.80214 (r=0.758,p=0.852),  time:35.287, tt:3246.437\n",
      "Ep:92, loss:0.00000, loss_test:0.01402, lr:4.48e-02, fs:0.80214 (r=0.758,p=0.852),  time:35.284, tt:3281.444\n",
      "Ep:93, loss:0.00000, loss_test:0.01408, lr:4.44e-02, fs:0.79570 (r=0.747,p=0.851),  time:35.283, tt:3316.647\n",
      "Ep:94, loss:0.00000, loss_test:0.01412, lr:4.39e-02, fs:0.79570 (r=0.747,p=0.851),  time:35.281, tt:3351.706\n",
      "Ep:95, loss:0.00000, loss_test:0.01420, lr:4.35e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.270, tt:3385.945\n",
      "Ep:96, loss:0.00000, loss_test:0.01427, lr:4.31e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.273, tt:3421.470\n",
      "Ep:97, loss:0.00000, loss_test:0.01435, lr:4.26e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.280, tt:3457.485\n",
      "Ep:98, loss:0.00000, loss_test:0.01439, lr:4.22e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.280, tt:3492.688\n",
      "Ep:99, loss:0.00000, loss_test:0.01442, lr:4.18e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.291, tt:3529.126\n",
      "Ep:100, loss:0.00000, loss_test:0.01448, lr:4.14e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.280, tt:3563.258\n",
      "Ep:101, loss:0.00000, loss_test:0.01455, lr:4.10e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.276, tt:3598.129\n",
      "Ep:102, loss:0.00000, loss_test:0.01459, lr:4.05e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.283, tt:3634.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:103, loss:0.00000, loss_test:0.01465, lr:4.01e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.290, tt:3670.119\n",
      "Ep:104, loss:0.00000, loss_test:0.01471, lr:3.97e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.295, tt:3705.947\n",
      "Ep:105, loss:0.00000, loss_test:0.01477, lr:3.93e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.310, tt:3742.910\n",
      "Ep:106, loss:0.00000, loss_test:0.01484, lr:3.89e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.297, tt:3776.744\n",
      "Ep:107, loss:0.00000, loss_test:0.01491, lr:3.86e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.305, tt:3812.891\n",
      "Ep:108, loss:0.00000, loss_test:0.01494, lr:3.82e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.310, tt:3848.785\n",
      "Ep:109, loss:0.00000, loss_test:0.01498, lr:3.78e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.311, tt:3884.189\n",
      "Ep:110, loss:0.00000, loss_test:0.01506, lr:3.74e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.308, tt:3919.220\n",
      "Ep:111, loss:0.00000, loss_test:0.01509, lr:3.70e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.315, tt:3955.304\n",
      "Ep:112, loss:0.00000, loss_test:0.01510, lr:3.67e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.323, tt:3991.479\n",
      "Ep:113, loss:0.00000, loss_test:0.01516, lr:3.63e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.329, tt:4027.514\n",
      "Ep:114, loss:0.00000, loss_test:0.01524, lr:3.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.335, tt:4063.549\n",
      "Ep:115, loss:0.00000, loss_test:0.01528, lr:3.56e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.320, tt:4097.172\n",
      "Ep:116, loss:0.00000, loss_test:0.01531, lr:3.52e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.329, tt:4133.456\n",
      "Ep:117, loss:0.00000, loss_test:0.01535, lr:3.49e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.342, tt:4170.335\n",
      "Ep:118, loss:0.00000, loss_test:0.01540, lr:3.45e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.341, tt:4205.578\n",
      "Ep:119, loss:0.00000, loss_test:0.01544, lr:3.42e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.351, tt:4242.137\n",
      "Ep:120, loss:0.00000, loss_test:0.01550, lr:3.38e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.357, tt:4278.240\n",
      "Ep:121, loss:0.00000, loss_test:0.01556, lr:3.35e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.369, tt:4314.986\n",
      "Ep:122, loss:0.00000, loss_test:0.01560, lr:3.32e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.380, tt:4351.710\n",
      "Ep:123, loss:0.00000, loss_test:0.01564, lr:3.28e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.390, tt:4388.362\n",
      "Ep:124, loss:0.00000, loss_test:0.01566, lr:3.25e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.380, tt:4422.468\n",
      "Ep:125, loss:0.00000, loss_test:0.01572, lr:3.22e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.392, tt:4459.443\n",
      "Ep:126, loss:0.00000, loss_test:0.01577, lr:3.19e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.395, tt:4495.153\n",
      "Ep:127, loss:0.00000, loss_test:0.01580, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.409, tt:4532.313\n",
      "Ep:128, loss:0.00000, loss_test:0.01584, lr:3.12e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.416, tt:4568.645\n",
      "Ep:129, loss:0.00000, loss_test:0.01586, lr:3.09e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.417, tt:4604.237\n",
      "Ep:130, loss:0.00000, loss_test:0.01590, lr:3.06e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.426, tt:4640.788\n",
      "Ep:131, loss:0.00000, loss_test:0.01595, lr:3.03e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.433, tt:4677.216\n",
      "Ep:132, loss:0.00000, loss_test:0.01601, lr:3.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.439, tt:4713.428\n",
      "Ep:133, loss:0.00000, loss_test:0.01603, lr:2.97e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.447, tt:4749.899\n",
      "Ep:134, loss:0.00000, loss_test:0.01606, lr:2.94e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.458, tt:4786.830\n",
      "Ep:135, loss:0.00000, loss_test:0.01610, lr:2.91e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.458, tt:4822.230\n",
      "Ep:136, loss:0.00000, loss_test:0.01614, lr:2.88e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.457, tt:4857.605\n",
      "Ep:137, loss:0.00000, loss_test:0.01621, lr:2.85e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.487, tt:4897.143\n",
      "Ep:138, loss:0.00000, loss_test:0.01622, lr:2.82e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.495, tt:4933.830\n",
      "Ep:139, loss:0.00000, loss_test:0.01622, lr:2.80e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.513, tt:4971.777\n",
      "Ep:140, loss:0.00000, loss_test:0.01629, lr:2.77e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.518, tt:5007.979\n",
      "Ep:141, loss:0.00000, loss_test:0.01634, lr:2.74e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.527, tt:5044.874\n",
      "Ep:142, loss:0.00000, loss_test:0.01635, lr:2.71e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.527, tt:5080.393\n",
      "Ep:143, loss:0.00000, loss_test:0.01639, lr:2.69e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.534, tt:5116.936\n",
      "Ep:144, loss:0.00000, loss_test:0.01645, lr:2.66e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.541, tt:5153.503\n",
      "Ep:145, loss:0.00000, loss_test:0.01646, lr:2.63e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.542, tt:5189.129\n",
      "Ep:146, loss:0.00000, loss_test:0.01649, lr:2.61e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.548, tt:5225.515\n",
      "Ep:147, loss:0.00000, loss_test:0.01655, lr:2.58e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.554, tt:5261.938\n",
      "Ep:148, loss:0.00000, loss_test:0.01659, lr:2.55e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.555, tt:5297.636\n",
      "Ep:149, loss:0.00000, loss_test:0.01660, lr:2.53e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.557, tt:5333.583\n",
      "Ep:150, loss:0.00000, loss_test:0.01659, lr:2.50e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.569, tt:5370.858\n",
      "Ep:151, loss:0.00000, loss_test:0.01664, lr:2.48e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.562, tt:5405.349\n",
      "Ep:152, loss:0.00000, loss_test:0.01669, lr:2.45e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.562, tt:5441.023\n",
      "Ep:153, loss:0.00000, loss_test:0.01670, lr:2.43e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.562, tt:5476.501\n",
      "Ep:154, loss:0.00000, loss_test:0.01673, lr:2.40e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.566, tt:5512.704\n",
      "Ep:155, loss:0.00000, loss_test:0.01678, lr:2.38e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.563, tt:5547.768\n",
      "Ep:156, loss:0.00000, loss_test:0.01680, lr:2.36e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.558, tt:5582.662\n",
      "Ep:157, loss:0.00000, loss_test:0.01682, lr:2.33e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.554, tt:5617.502\n",
      "Ep:158, loss:0.00000, loss_test:0.01685, lr:2.31e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.554, tt:5653.009\n",
      "Ep:159, loss:0.00000, loss_test:0.01688, lr:2.29e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.555, tt:5688.872\n",
      "Ep:160, loss:0.00000, loss_test:0.01690, lr:2.26e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.537, tt:5721.529\n",
      "Ep:161, loss:0.00000, loss_test:0.01693, lr:2.24e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.534, tt:5756.509\n",
      "Ep:162, loss:0.00000, loss_test:0.01695, lr:2.22e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.521, tt:5789.993\n",
      "Ep:163, loss:0.00000, loss_test:0.01698, lr:2.20e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.517, tt:5824.751\n",
      "Ep:164, loss:0.00000, loss_test:0.01700, lr:2.17e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.524, tt:5861.442\n",
      "Ep:165, loss:0.00000, loss_test:0.01705, lr:2.15e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.518, tt:5896.044\n",
      "Ep:166, loss:0.00000, loss_test:0.01707, lr:2.13e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.509, tt:5930.072\n",
      "Ep:167, loss:0.00000, loss_test:0.01709, lr:2.11e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.497, tt:5963.455\n",
      "Ep:168, loss:0.00000, loss_test:0.01711, lr:2.09e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.482, tt:5996.497\n",
      "Ep:169, loss:0.00000, loss_test:0.01715, lr:2.07e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.482, tt:6031.923\n",
      "Ep:170, loss:0.00000, loss_test:0.01716, lr:2.05e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.474, tt:6065.991\n",
      "Ep:171, loss:0.00000, loss_test:0.01719, lr:2.03e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.462, tt:6099.528\n",
      "Ep:172, loss:0.00000, loss_test:0.01722, lr:2.01e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.455, tt:6133.714\n",
      "Ep:173, loss:0.00000, loss_test:0.01723, lr:1.99e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.449, tt:6168.096\n",
      "Ep:174, loss:0.00000, loss_test:0.01725, lr:1.97e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.443, tt:6202.442\n",
      "Ep:175, loss:0.00000, loss_test:0.01728, lr:1.95e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.435, tt:6236.499\n",
      "Ep:176, loss:0.00000, loss_test:0.01730, lr:1.93e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.431, tt:6271.270\n",
      "Ep:177, loss:0.00000, loss_test:0.01731, lr:1.91e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.426, tt:6305.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:178, loss:0.00000, loss_test:0.01734, lr:1.89e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.418, tt:6339.872\n",
      "Ep:179, loss:0.00000, loss_test:0.01736, lr:1.87e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.413, tt:6374.400\n",
      "Ep:180, loss:0.00000, loss_test:0.01739, lr:1.85e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.410, tt:6409.207\n",
      "Ep:181, loss:0.00000, loss_test:0.01740, lr:1.83e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.399, tt:6442.693\n",
      "Ep:182, loss:0.00000, loss_test:0.01742, lr:1.81e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.386, tt:6475.586\n",
      "Ep:183, loss:0.00000, loss_test:0.01745, lr:1.80e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.382, tt:6510.321\n",
      "Ep:184, loss:0.00000, loss_test:0.01747, lr:1.78e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.373, tt:6543.984\n",
      "Ep:185, loss:0.00000, loss_test:0.01748, lr:1.76e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.361, tt:6577.145\n",
      "Ep:186, loss:0.00000, loss_test:0.01752, lr:1.74e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.351, tt:6610.678\n",
      "Ep:187, loss:0.00000, loss_test:0.01752, lr:1.73e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.351, tt:6646.056\n",
      "Ep:188, loss:0.00000, loss_test:0.01753, lr:1.71e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.360, tt:6683.052\n",
      "Ep:189, loss:0.00000, loss_test:0.01756, lr:1.69e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.361, tt:6718.623\n",
      "Ep:190, loss:0.00000, loss_test:0.01759, lr:1.67e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.350, tt:6751.765\n",
      "Ep:191, loss:0.00000, loss_test:0.01760, lr:1.66e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.344, tt:6786.049\n",
      "Ep:192, loss:0.00000, loss_test:0.01763, lr:1.64e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.337, tt:6820.016\n",
      "Ep:193, loss:0.00000, loss_test:0.01765, lr:1.62e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.330, tt:6854.043\n",
      "Ep:194, loss:0.00000, loss_test:0.01766, lr:1.61e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.325, tt:6888.370\n",
      "Ep:195, loss:0.00000, loss_test:0.01768, lr:1.59e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.324, tt:6923.449\n",
      "Ep:196, loss:0.00000, loss_test:0.01770, lr:1.58e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.322, tt:6958.489\n",
      "Ep:197, loss:0.00000, loss_test:0.01773, lr:1.56e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.319, tt:6993.242\n",
      "Ep:198, loss:0.00000, loss_test:0.01774, lr:1.54e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.305, tt:7025.785\n",
      "Ep:199, loss:0.00000, loss_test:0.01776, lr:1.53e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.302, tt:7060.383\n",
      "Ep:200, loss:0.00000, loss_test:0.01777, lr:1.51e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.290, tt:7093.370\n",
      "Ep:201, loss:0.00000, loss_test:0.01780, lr:1.50e-02, fs:0.77381 (r=0.657,p=0.942),  time:35.276, tt:7125.698\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13385, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:34.524, tt:34.524\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13288, lr:1.00e-02, fs:0.62992 (r=0.808,p=0.516),  time:34.689, tt:69.377\n",
      "Ep:2, loss:0.00026, loss_test:0.13216, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:33.910, tt:101.729\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13172, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:34.068, tt:136.270\n",
      "Ep:4, loss:0.00025, loss_test:0.13090, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:34.598, tt:172.989\n",
      "Ep:5, loss:0.00025, loss_test:0.12983, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:34.923, tt:209.536\n",
      "Ep:6, loss:0.00025, loss_test:0.12863, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:35.239, tt:246.676\n",
      "Ep:7, loss:0.00025, loss_test:0.12738, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:35.404, tt:283.234\n",
      "Ep:8, loss:0.00024, loss_test:0.12605, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:35.341, tt:318.069\n",
      "Ep:9, loss:0.00024, loss_test:0.12454, lr:1.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:35.104, tt:351.040\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.12278, lr:1.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:35.310, tt:388.406\n",
      "Ep:11, loss:0.00023, loss_test:0.12084, lr:1.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:35.424, tt:425.094\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.11855, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.501, tt:461.515\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.11616, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:35.696, tt:499.743\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.11388, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:35.770, tt:536.549\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.11181, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:35.910, tt:574.568\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.10989, lr:1.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:36.024, tt:612.415\n",
      "Ep:17, loss:0.00020, loss_test:0.10802, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:36.157, tt:650.819\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00020, loss_test:0.10619, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:36.163, tt:687.091\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.10428, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:36.218, tt:724.355\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.10244, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:36.229, tt:760.814\n",
      "Ep:21, loss:0.00018, loss_test:0.10039, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:36.268, tt:797.901\n",
      "Ep:22, loss:0.00017, loss_test:0.09862, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:36.387, tt:836.912\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09741, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:36.526, tt:876.621\n",
      "Ep:24, loss:0.00016, loss_test:0.09591, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:36.659, tt:916.469\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09482, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:36.762, tt:955.823\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09261, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:36.814, tt:993.971\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09033, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:36.859, tt:1032.057\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08955, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:36.947, tt:1071.453\n",
      "Ep:29, loss:0.00012, loss_test:0.08740, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:37.013, tt:1110.396\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08454, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:37.052, tt:1148.607\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08561, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:37.089, tt:1186.842\n",
      "Ep:32, loss:0.00010, loss_test:0.08171, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:37.124, tt:1225.099\n",
      "Ep:33, loss:0.00010, loss_test:0.08069, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:37.196, tt:1264.674\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.08116, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:37.251, tt:1303.796\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.07868, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:37.277, tt:1341.981\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.07754, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:37.339, tt:1381.536\n",
      "Ep:37, loss:0.00008, loss_test:0.07835, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:37.339, tt:1418.899\n",
      "Ep:38, loss:0.00008, loss_test:0.07541, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:37.356, tt:1456.903\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00007, loss_test:0.07456, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:37.354, tt:1494.175\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.07445, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:37.344, tt:1531.113\n",
      "Ep:41, loss:0.00006, loss_test:0.07208, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:37.321, tt:1567.499\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.07342, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:37.329, tt:1605.142\n",
      "Ep:43, loss:0.00006, loss_test:0.07261, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:37.345, tt:1643.169\n",
      "Ep:44, loss:0.00006, loss_test:0.07030, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:37.326, tt:1679.689\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.07201, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:37.360, tt:1718.575\n",
      "Ep:46, loss:0.00005, loss_test:0.06935, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:37.385, tt:1757.081\n",
      "Ep:47, loss:0.00005, loss_test:0.07076, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:37.418, tt:1796.042\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.06945, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:37.420, tt:1833.604\n",
      "Ep:49, loss:0.00005, loss_test:0.06892, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:37.434, tt:1871.696\n",
      "Ep:50, loss:0.00004, loss_test:0.07015, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:37.437, tt:1909.295\n",
      "Ep:51, loss:0.00004, loss_test:0.06670, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:37.435, tt:1946.622\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.06978, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:37.460, tt:1985.400\n",
      "Ep:53, loss:0.00004, loss_test:0.06543, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:37.483, tt:2024.075\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00004, loss_test:0.06677, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:37.528, tt:2064.037\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.06646, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:37.512, tt:2100.665\n",
      "Ep:56, loss:0.00004, loss_test:0.06661, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:37.494, tt:2137.140\n",
      "Ep:57, loss:0.00004, loss_test:0.06509, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:37.490, tt:2174.395\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.06729, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:37.476, tt:2211.070\n",
      "Ep:59, loss:0.00003, loss_test:0.06398, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:37.487, tt:2249.217\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.06717, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.496, tt:2287.257\n",
      "Ep:61, loss:0.00003, loss_test:0.06430, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:37.503, tt:2325.168\n",
      "Ep:62, loss:0.00003, loss_test:0.06357, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:37.499, tt:2362.432\n",
      "Ep:63, loss:0.00003, loss_test:0.06503, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.500, tt:2399.999\n",
      "Ep:64, loss:0.00003, loss_test:0.06288, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:37.497, tt:2437.326\n",
      "Ep:65, loss:0.00003, loss_test:0.06509, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:37.505, tt:2475.345\n",
      "Ep:66, loss:0.00003, loss_test:0.06151, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:37.508, tt:2513.052\n",
      "Ep:67, loss:0.00003, loss_test:0.06488, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:37.510, tt:2550.663\n",
      "Ep:68, loss:0.00003, loss_test:0.06304, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:37.519, tt:2588.786\n",
      "Ep:69, loss:0.00003, loss_test:0.06397, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:37.510, tt:2625.718\n",
      "Ep:70, loss:0.00003, loss_test:0.06261, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:37.510, tt:2663.186\n",
      "Ep:71, loss:0.00002, loss_test:0.06378, lr:9.90e-03, fs:0.87755 (r=0.869,p=0.887),  time:37.510, tt:2700.709\n",
      "Ep:72, loss:0.00002, loss_test:0.06311, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:37.495, tt:2737.144\n",
      "Ep:73, loss:0.00002, loss_test:0.06296, lr:9.70e-03, fs:0.88442 (r=0.889,p=0.880),  time:37.489, tt:2774.202\n",
      "Ep:74, loss:0.00002, loss_test:0.06414, lr:9.61e-03, fs:0.81081 (r=0.758,p=0.872),  time:37.464, tt:2809.828\n",
      "Ep:75, loss:0.00002, loss_test:0.06216, lr:9.51e-03, fs:0.89000 (r=0.899,p=0.881),  time:37.445, tt:2845.826\n",
      "Ep:76, loss:0.00002, loss_test:0.06362, lr:9.41e-03, fs:0.80435 (r=0.747,p=0.871),  time:37.450, tt:2883.641\n",
      "Ep:77, loss:0.00002, loss_test:0.06261, lr:9.32e-03, fs:0.88889 (r=0.889,p=0.889),  time:37.462, tt:2922.037\n",
      "Ep:78, loss:0.00002, loss_test:0.06258, lr:9.23e-03, fs:0.87179 (r=0.859,p=0.885),  time:37.446, tt:2958.222\n",
      "Ep:79, loss:0.00002, loss_test:0.06327, lr:9.14e-03, fs:0.82609 (r=0.768,p=0.894),  time:37.437, tt:2994.964\n",
      "Ep:80, loss:0.00002, loss_test:0.06354, lr:9.04e-03, fs:0.88325 (r=0.879,p=0.888),  time:37.432, tt:3031.986\n",
      "Ep:81, loss:0.00002, loss_test:0.06173, lr:8.95e-03, fs:0.86010 (r=0.838,p=0.883),  time:37.446, tt:3070.602\n",
      "Ep:82, loss:0.00002, loss_test:0.06413, lr:8.86e-03, fs:0.85106 (r=0.808,p=0.899),  time:37.468, tt:3109.834\n",
      "Ep:83, loss:0.00002, loss_test:0.06197, lr:8.78e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.456, tt:3146.289\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.06333, lr:8.78e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.439, tt:3182.280\n",
      "Ep:85, loss:0.00002, loss_test:0.06265, lr:8.78e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.413, tt:3217.528\n",
      "Ep:86, loss:0.00002, loss_test:0.06365, lr:8.78e-03, fs:0.87500 (r=0.848,p=0.903),  time:37.409, tt:3254.563\n",
      "Ep:87, loss:0.00002, loss_test:0.06184, lr:8.78e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.385, tt:3289.862\n",
      "Ep:88, loss:0.00002, loss_test:0.06426, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:37.378, tt:3326.631\n",
      "Ep:89, loss:0.00002, loss_test:0.06299, lr:8.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:37.384, tt:3364.526\n",
      "Ep:90, loss:0.00002, loss_test:0.06310, lr:8.78e-03, fs:0.90355 (r=0.899,p=0.908),  time:37.390, tt:3402.505\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.06339, lr:8.78e-03, fs:0.88660 (r=0.869,p=0.905),  time:37.388, tt:3439.685\n",
      "Ep:92, loss:0.00002, loss_test:0.06247, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:37.380, tt:3476.321\n",
      "Ep:93, loss:0.00002, loss_test:0.06393, lr:8.78e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.385, tt:3514.171\n",
      "Ep:94, loss:0.00002, loss_test:0.06302, lr:8.78e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.386, tt:3551.685\n",
      "Ep:95, loss:0.00002, loss_test:0.06351, lr:8.78e-03, fs:0.89796 (r=0.889,p=0.907),  time:37.366, tt:3587.093\n",
      "Ep:96, loss:0.00002, loss_test:0.06416, lr:8.78e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.362, tt:3624.124\n",
      "Ep:97, loss:0.00002, loss_test:0.06300, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:37.351, tt:3660.444\n",
      "Ep:98, loss:0.00002, loss_test:0.06500, lr:8.78e-03, fs:0.88660 (r=0.869,p=0.905),  time:37.310, tt:3693.711\n",
      "Ep:99, loss:0.00002, loss_test:0.06459, lr:8.78e-03, fs:0.86170 (r=0.818,p=0.910),  time:37.289, tt:3728.949\n",
      "Ep:100, loss:0.00001, loss_test:0.06401, lr:8.78e-03, fs:0.89796 (r=0.889,p=0.907),  time:37.297, tt:3766.980\n",
      "Ep:101, loss:0.00001, loss_test:0.06350, lr:8.78e-03, fs:0.88660 (r=0.869,p=0.905),  time:37.310, tt:3805.635\n",
      "Ep:102, loss:0.00001, loss_test:0.06446, lr:8.69e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.300, tt:3841.862\n",
      "Ep:103, loss:0.00001, loss_test:0.06376, lr:8.60e-03, fs:0.89231 (r=0.879,p=0.906),  time:37.291, tt:3878.285\n",
      "Ep:104, loss:0.00001, loss_test:0.06376, lr:8.51e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.297, tt:3916.192\n",
      "Ep:105, loss:0.00001, loss_test:0.06309, lr:8.43e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.321, tt:3955.976\n",
      "Ep:106, loss:0.00001, loss_test:0.06424, lr:8.35e-03, fs:0.88660 (r=0.869,p=0.905),  time:37.329, tt:3994.151\n",
      "Ep:107, loss:0.00001, loss_test:0.06314, lr:8.26e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.335, tt:4032.162\n",
      "Ep:108, loss:0.00001, loss_test:0.06490, lr:8.18e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.323, tt:4068.236\n",
      "Ep:109, loss:0.00001, loss_test:0.06401, lr:8.10e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.320, tt:4105.170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:110, loss:0.00001, loss_test:0.06407, lr:8.02e-03, fs:0.87368 (r=0.838,p=0.912),  time:37.316, tt:4142.102\n",
      "Ep:111, loss:0.00001, loss_test:0.06338, lr:7.94e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.302, tt:4177.860\n",
      "Ep:112, loss:0.00001, loss_test:0.06475, lr:7.86e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.296, tt:4214.423\n",
      "Ep:113, loss:0.00001, loss_test:0.06412, lr:7.78e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.292, tt:4251.290\n",
      "Ep:114, loss:0.00001, loss_test:0.06470, lr:7.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.288, tt:4288.113\n",
      "Ep:115, loss:0.00001, loss_test:0.06307, lr:7.62e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.281, tt:4324.616\n",
      "Ep:116, loss:0.00001, loss_test:0.06522, lr:7.55e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.278, tt:4361.548\n",
      "Ep:117, loss:0.00001, loss_test:0.06413, lr:7.47e-03, fs:0.88542 (r=0.859,p=0.914),  time:37.276, tt:4398.539\n",
      "Ep:118, loss:0.00001, loss_test:0.06448, lr:7.40e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.279, tt:4436.235\n",
      "Ep:119, loss:0.00001, loss_test:0.06475, lr:7.32e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.276, tt:4473.110\n",
      "Ep:120, loss:0.00001, loss_test:0.06297, lr:7.25e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.273, tt:4510.037\n",
      "Ep:121, loss:0.00001, loss_test:0.06505, lr:7.18e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.271, tt:4547.056\n",
      "Ep:122, loss:0.00001, loss_test:0.06377, lr:7.11e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.291, tt:4586.767\n",
      "Ep:123, loss:0.00001, loss_test:0.06372, lr:7.03e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.292, tt:4624.227\n",
      "Ep:124, loss:0.00001, loss_test:0.06504, lr:6.96e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.291, tt:4661.322\n",
      "Ep:125, loss:0.00001, loss_test:0.06382, lr:6.89e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.292, tt:4698.845\n",
      "Ep:126, loss:0.00001, loss_test:0.06473, lr:6.83e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.281, tt:4734.705\n",
      "Ep:127, loss:0.00001, loss_test:0.06430, lr:6.76e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.278, tt:4771.564\n",
      "Ep:128, loss:0.00001, loss_test:0.06401, lr:6.69e-03, fs:0.88542 (r=0.859,p=0.914),  time:37.285, tt:4809.773\n",
      "Ep:129, loss:0.00001, loss_test:0.06551, lr:6.62e-03, fs:0.87234 (r=0.828,p=0.921),  time:37.282, tt:4846.611\n",
      "Ep:130, loss:0.00001, loss_test:0.06290, lr:6.56e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.281, tt:4883.826\n",
      "Ep:131, loss:0.00001, loss_test:0.06441, lr:6.49e-03, fs:0.90155 (r=0.879,p=0.926),  time:37.282, tt:4921.282\n",
      "Ep:132, loss:0.00001, loss_test:0.06567, lr:6.43e-03, fs:0.87831 (r=0.838,p=0.922),  time:37.281, tt:4958.354\n",
      "Ep:133, loss:0.00001, loss_test:0.06314, lr:6.36e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.283, tt:4995.957\n",
      "Ep:134, loss:0.00001, loss_test:0.06501, lr:6.30e-03, fs:0.89691 (r=0.879,p=0.916),  time:37.275, tt:5032.099\n",
      "Ep:135, loss:0.00001, loss_test:0.06489, lr:6.24e-03, fs:0.90155 (r=0.879,p=0.926),  time:37.272, tt:5068.944\n",
      "Ep:136, loss:0.00001, loss_test:0.06411, lr:6.17e-03, fs:0.88298 (r=0.838,p=0.933),  time:37.271, tt:5106.104\n",
      "Ep:137, loss:0.00001, loss_test:0.06429, lr:6.11e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.265, tt:5142.630\n",
      "Ep:138, loss:0.00001, loss_test:0.06444, lr:6.05e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.261, tt:5179.212\n",
      "Ep:139, loss:0.00001, loss_test:0.06426, lr:5.99e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.253, tt:5215.373\n",
      "Ep:140, loss:0.00001, loss_test:0.06443, lr:5.93e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.253, tt:5252.708\n",
      "Ep:141, loss:0.00001, loss_test:0.06430, lr:5.87e-03, fs:0.90155 (r=0.879,p=0.926),  time:37.240, tt:5288.019\n",
      "Ep:142, loss:0.00001, loss_test:0.06450, lr:5.81e-03, fs:0.89005 (r=0.859,p=0.924),  time:37.230, tt:5323.854\n",
      "Ep:143, loss:0.00001, loss_test:0.06361, lr:5.75e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.219, tt:5359.578\n",
      "Ep:144, loss:0.00001, loss_test:0.06460, lr:5.70e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.210, tt:5395.397\n",
      "Ep:145, loss:0.00001, loss_test:0.06441, lr:5.64e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.208, tt:5432.373\n",
      "Ep:146, loss:0.00001, loss_test:0.06357, lr:5.58e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.207, tt:5469.371\n",
      "Ep:147, loss:0.00001, loss_test:0.06446, lr:5.53e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.205, tt:5506.290\n",
      "Ep:148, loss:0.00001, loss_test:0.06378, lr:5.47e-03, fs:0.90155 (r=0.879,p=0.926),  time:37.190, tt:5541.301\n",
      "Ep:149, loss:0.00001, loss_test:0.06470, lr:5.42e-03, fs:0.88889 (r=0.848,p=0.933),  time:37.194, tt:5579.167\n",
      "Ep:150, loss:0.00001, loss_test:0.06379, lr:5.36e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.188, tt:5615.416\n",
      "Ep:151, loss:0.00001, loss_test:0.06450, lr:5.31e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.189, tt:5652.699\n",
      "Ep:152, loss:0.00001, loss_test:0.06458, lr:5.26e-03, fs:0.88889 (r=0.848,p=0.933),  time:37.176, tt:5687.958\n",
      "Ep:153, loss:0.00001, loss_test:0.06377, lr:5.20e-03, fs:0.89947 (r=0.859,p=0.944),  time:37.180, tt:5725.694\n",
      "Ep:154, loss:0.00001, loss_test:0.06520, lr:5.15e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.174, tt:5761.975\n",
      "Ep:155, loss:0.00001, loss_test:0.06428, lr:5.10e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.169, tt:5798.357\n",
      "Ep:156, loss:0.00001, loss_test:0.06370, lr:5.05e-03, fs:0.89947 (r=0.859,p=0.944),  time:37.165, tt:5834.936\n",
      "Ep:157, loss:0.00001, loss_test:0.06474, lr:5.00e-03, fs:0.89474 (r=0.859,p=0.934),  time:37.160, tt:5871.303\n",
      "Ep:158, loss:0.00001, loss_test:0.06417, lr:4.95e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.146, tt:5906.234\n",
      "Ep:159, loss:0.00001, loss_test:0.06442, lr:4.90e-03, fs:0.89840 (r=0.848,p=0.955),  time:37.145, tt:5943.214\n",
      "Ep:160, loss:0.00001, loss_test:0.06368, lr:4.85e-03, fs:0.89474 (r=0.859,p=0.934),  time:37.136, tt:5978.888\n",
      "Ep:161, loss:0.00001, loss_test:0.06358, lr:4.80e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.119, tt:6013.330\n",
      "Ep:162, loss:0.00001, loss_test:0.06423, lr:4.75e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.116, tt:6049.929\n",
      "Ep:163, loss:0.00001, loss_test:0.06420, lr:4.71e-03, fs:0.90526 (r=0.869,p=0.945),  time:37.107, tt:6085.473\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00001, loss_test:0.06347, lr:4.71e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.098, tt:6121.195\n",
      "Ep:165, loss:0.00001, loss_test:0.06408, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.102, tt:6158.854\n",
      "Ep:166, loss:0.00001, loss_test:0.06433, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.099, tt:6195.561\n",
      "Ep:167, loss:0.00001, loss_test:0.06375, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.093, tt:6231.683\n",
      "Ep:168, loss:0.00001, loss_test:0.06385, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.096, tt:6269.255\n",
      "Ep:169, loss:0.00001, loss_test:0.06373, lr:4.71e-03, fs:0.89583 (r=0.869,p=0.925),  time:37.087, tt:6304.810\n",
      "Ep:170, loss:0.00001, loss_test:0.06425, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.087, tt:6341.889\n",
      "Ep:171, loss:0.00001, loss_test:0.06481, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.077, tt:6377.173\n",
      "Ep:172, loss:0.00001, loss_test:0.06547, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.078, tt:6414.477\n",
      "Ep:173, loss:0.00001, loss_test:0.06317, lr:4.71e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.070, tt:6450.159\n",
      "##########Best model found so far##########\n",
      "Ep:174, loss:0.00001, loss_test:0.06436, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.087, tt:6490.208\n",
      "Ep:175, loss:0.00001, loss_test:0.06504, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.087, tt:6527.277\n",
      "Ep:176, loss:0.00001, loss_test:0.06349, lr:4.71e-03, fs:0.91489 (r=0.869,p=0.966),  time:37.080, tt:6563.243\n",
      "##########Best model found so far##########\n",
      "Ep:177, loss:0.00001, loss_test:0.06455, lr:4.71e-03, fs:0.90426 (r=0.859,p=0.955),  time:37.077, tt:6599.766\n",
      "Ep:178, loss:0.00001, loss_test:0.06378, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.071, tt:6635.747\n",
      "Ep:179, loss:0.00001, loss_test:0.06287, lr:4.71e-03, fs:0.90625 (r=0.879,p=0.935),  time:37.070, tt:6672.644\n",
      "Ep:180, loss:0.00001, loss_test:0.06393, lr:4.71e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.071, tt:6709.783\n",
      "Ep:181, loss:0.00001, loss_test:0.06411, lr:4.71e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.068, tt:6746.462\n",
      "Ep:182, loss:0.00001, loss_test:0.06348, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.065, tt:6782.903\n",
      "Ep:183, loss:0.00001, loss_test:0.06326, lr:4.71e-03, fs:0.90526 (r=0.869,p=0.945),  time:37.057, tt:6818.452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:184, loss:0.00001, loss_test:0.06344, lr:4.71e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.054, tt:6855.026\n",
      "Ep:185, loss:0.00001, loss_test:0.06349, lr:4.71e-03, fs:0.90526 (r=0.869,p=0.945),  time:37.054, tt:6891.998\n",
      "Ep:186, loss:0.00001, loss_test:0.06347, lr:4.71e-03, fs:0.90052 (r=0.869,p=0.935),  time:37.046, tt:6927.642\n",
      "Ep:187, loss:0.00001, loss_test:0.06393, lr:4.71e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.042, tt:6963.937\n",
      "Ep:188, loss:0.00001, loss_test:0.06283, lr:4.66e-03, fs:0.91489 (r=0.869,p=0.966),  time:37.044, tt:7001.312\n",
      "Ep:189, loss:0.00001, loss_test:0.06436, lr:4.61e-03, fs:0.90526 (r=0.869,p=0.945),  time:37.041, tt:7037.711\n",
      "Ep:190, loss:0.00001, loss_test:0.06424, lr:4.57e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.034, tt:7073.566\n",
      "Ep:191, loss:0.00001, loss_test:0.06269, lr:4.52e-03, fs:0.91489 (r=0.869,p=0.966),  time:37.031, tt:7109.856\n",
      "Ep:192, loss:0.00001, loss_test:0.06362, lr:4.48e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.054, tt:7151.376\n",
      "Ep:193, loss:0.00001, loss_test:0.06372, lr:4.43e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.052, tt:7188.091\n",
      "Ep:194, loss:0.00001, loss_test:0.06290, lr:4.39e-03, fs:0.90526 (r=0.869,p=0.945),  time:37.049, tt:7224.598\n",
      "Ep:195, loss:0.00001, loss_test:0.06364, lr:4.34e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.047, tt:7261.266\n",
      "Ep:196, loss:0.00001, loss_test:0.06303, lr:4.30e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.057, tt:7300.286\n",
      "Ep:197, loss:0.00001, loss_test:0.06337, lr:4.26e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.047, tt:7335.313\n",
      "Ep:198, loss:0.00001, loss_test:0.06346, lr:4.21e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.049, tt:7372.745\n",
      "Ep:199, loss:0.00001, loss_test:0.06263, lr:4.17e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.047, tt:7409.492\n",
      "Ep:200, loss:0.00001, loss_test:0.06356, lr:4.13e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.034, tt:7443.883\n",
      "Ep:201, loss:0.00001, loss_test:0.06339, lr:4.09e-03, fs:0.91005 (r=0.869,p=0.956),  time:37.016, tt:7477.210\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02344, lr:6.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:24.906, tt:24.906\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02691, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.675, tt:45.349\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02975, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.222, tt:66.667\n",
      "Ep:3, loss:0.00006, loss_test:0.03068, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.289, tt:93.155\n",
      "Ep:4, loss:0.00006, loss_test:0.03044, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.428, tt:122.142\n",
      "Ep:5, loss:0.00006, loss_test:0.02946, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.444, tt:152.662\n",
      "Ep:6, loss:0.00006, loss_test:0.02803, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:25.953, tt:181.669\n",
      "Ep:7, loss:0.00005, loss_test:0.02642, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:26.355, tt:210.841\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:26.744, tt:240.700\n",
      "Ep:9, loss:0.00005, loss_test:0.02430, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:26.674, tt:266.743\n",
      "Ep:10, loss:0.00005, loss_test:0.02393, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:26.621, tt:292.836\n",
      "Ep:11, loss:0.00005, loss_test:0.02322, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:26.747, tt:320.959\n",
      "Ep:12, loss:0.00005, loss_test:0.02217, lr:6.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:26.915, tt:349.894\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02142, lr:6.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:27.007, tt:378.100\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02087, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:27.192, tt:407.875\n",
      "Ep:15, loss:0.00004, loss_test:0.02035, lr:6.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:27.283, tt:436.534\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:27.396, tt:465.733\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01949, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:27.526, tt:495.471\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01931, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:27.641, tt:525.184\n",
      "Ep:19, loss:0.00004, loss_test:0.01922, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:27.774, tt:555.488\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01913, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:27.833, tt:584.493\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01903, lr:6.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:27.915, tt:614.129\n",
      "Ep:22, loss:0.00004, loss_test:0.01885, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:28.030, tt:644.696\n",
      "Ep:23, loss:0.00004, loss_test:0.01858, lr:6.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:28.101, tt:674.431\n",
      "Ep:24, loss:0.00004, loss_test:0.01827, lr:6.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:28.186, tt:704.643\n",
      "Ep:25, loss:0.00004, loss_test:0.01801, lr:6.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:28.253, tt:734.574\n",
      "Ep:26, loss:0.00003, loss_test:0.01779, lr:6.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:28.310, tt:764.381\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01762, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:28.417, tt:795.680\n",
      "Ep:28, loss:0.00003, loss_test:0.01752, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:28.452, tt:825.100\n",
      "Ep:29, loss:0.00003, loss_test:0.01734, lr:6.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:28.519, tt:855.556\n",
      "Ep:30, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:28.603, tt:886.708\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:28.675, tt:917.588\n",
      "Ep:32, loss:0.00003, loss_test:0.01668, lr:6.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:28.692, tt:946.839\n",
      "Ep:33, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:28.746, tt:977.366\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:28.804, tt:1008.146\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01595, lr:6.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:28.838, tt:1038.156\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:28.867, tt:1068.077\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01551, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:28.952, tt:1100.184\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:28.976, tt:1130.061\n",
      "Ep:39, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:28.992, tt:1159.688\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01493, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:29.088, tt:1192.592\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:29.157, tt:1224.612\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:29.172, tt:1254.417\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:29.207, tt:1285.098\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01391, lr:6.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:29.251, tt:1316.296\n",
      "Ep:45, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:29.267, tt:1346.268\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:29.301, tt:1377.152\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:29.303, tt:1406.558\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.325, tt:1436.902\n",
      "Ep:49, loss:0.00002, loss_test:0.01288, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:29.389, tt:1469.441\n",
      "Ep:50, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:29.402, tt:1499.520\n",
      "Ep:51, loss:0.00002, loss_test:0.01251, lr:6.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:29.421, tt:1529.898\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:29.455, tt:1561.098\n",
      "Ep:53, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:29.481, tt:1591.993\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:29.501, tt:1622.549\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01197, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:29.548, tt:1654.698\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:29.582, tt:1686.167\n",
      "Ep:57, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:29.608, tt:1717.247\n",
      "Ep:58, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:29.625, tt:1747.901\n",
      "Ep:59, loss:0.00001, loss_test:0.01172, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:29.653, tt:1779.168\n",
      "Ep:60, loss:0.00001, loss_test:0.01163, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:29.674, tt:1810.139\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01150, lr:6.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:29.701, tt:1841.432\n",
      "Ep:62, loss:0.00001, loss_test:0.01155, lr:6.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:29.714, tt:1872.010\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01146, lr:6.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:29.717, tt:1901.863\n",
      "Ep:64, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:29.730, tt:1932.430\n",
      "Ep:65, loss:0.00001, loss_test:0.01151, lr:6.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:29.729, tt:1962.102\n",
      "Ep:66, loss:0.00001, loss_test:0.01146, lr:6.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:29.736, tt:1992.306\n",
      "Ep:67, loss:0.00001, loss_test:0.01161, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:29.757, tt:2023.465\n",
      "Ep:68, loss:0.00001, loss_test:0.01143, lr:6.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:29.762, tt:2053.569\n",
      "Ep:69, loss:0.00001, loss_test:0.01160, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.748, tt:2082.356\n",
      "Ep:70, loss:0.00001, loss_test:0.01158, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.755, tt:2112.586\n",
      "Ep:71, loss:0.00001, loss_test:0.01147, lr:6.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:29.756, tt:2142.397\n",
      "Ep:72, loss:0.00001, loss_test:0.01176, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.800, tt:2175.395\n",
      "Ep:73, loss:0.00001, loss_test:0.01169, lr:6.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:29.819, tt:2206.594\n",
      "Ep:74, loss:0.00001, loss_test:0.01178, lr:5.94e-02, fs:0.83673 (r=0.828,p=0.845),  time:29.828, tt:2237.137\n",
      "Ep:75, loss:0.00001, loss_test:0.01176, lr:5.88e-02, fs:0.84103 (r=0.828,p=0.854),  time:29.849, tt:2268.560\n",
      "Ep:76, loss:0.00001, loss_test:0.01180, lr:5.82e-02, fs:0.84694 (r=0.838,p=0.856),  time:29.867, tt:2299.783\n",
      "Ep:77, loss:0.00001, loss_test:0.01192, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:29.878, tt:2330.510\n",
      "Ep:78, loss:0.00001, loss_test:0.01185, lr:5.71e-02, fs:0.84103 (r=0.828,p=0.854),  time:29.879, tt:2360.413\n",
      "Ep:79, loss:0.00001, loss_test:0.01194, lr:5.65e-02, fs:0.84103 (r=0.828,p=0.854),  time:29.871, tt:2389.678\n",
      "Ep:80, loss:0.00001, loss_test:0.01198, lr:5.59e-02, fs:0.82902 (r=0.808,p=0.851),  time:29.879, tt:2420.210\n",
      "Ep:81, loss:0.00001, loss_test:0.01197, lr:5.54e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.876, tt:2449.813\n",
      "Ep:82, loss:0.00001, loss_test:0.01218, lr:5.48e-02, fs:0.81283 (r=0.768,p=0.864),  time:29.878, tt:2479.852\n",
      "Ep:83, loss:0.00001, loss_test:0.01211, lr:5.43e-02, fs:0.80645 (r=0.758,p=0.862),  time:29.871, tt:2509.122\n",
      "Ep:84, loss:0.00001, loss_test:0.01218, lr:5.37e-02, fs:0.78453 (r=0.717,p=0.866),  time:29.878, tt:2539.672\n",
      "Ep:85, loss:0.00001, loss_test:0.01227, lr:5.32e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.880, tt:2569.704\n",
      "Ep:86, loss:0.00001, loss_test:0.01226, lr:5.27e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.891, tt:2600.499\n",
      "Ep:87, loss:0.00001, loss_test:0.01251, lr:5.21e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.897, tt:2630.954\n",
      "Ep:88, loss:0.00001, loss_test:0.01245, lr:5.16e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.907, tt:2661.726\n",
      "Ep:89, loss:0.00001, loss_test:0.01252, lr:5.11e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.910, tt:2691.912\n",
      "Ep:90, loss:0.00001, loss_test:0.01268, lr:5.06e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.919, tt:2722.631\n",
      "Ep:91, loss:0.00001, loss_test:0.01260, lr:5.01e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.914, tt:2752.118\n",
      "Ep:92, loss:0.00001, loss_test:0.01270, lr:4.96e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.936, tt:2784.005\n",
      "Ep:93, loss:0.00001, loss_test:0.01267, lr:4.91e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.945, tt:2814.788\n",
      "Ep:94, loss:0.00001, loss_test:0.01286, lr:4.86e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.941, tt:2844.388\n",
      "Ep:95, loss:0.00001, loss_test:0.01299, lr:4.81e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.934, tt:2873.711\n",
      "Ep:96, loss:0.00001, loss_test:0.01299, lr:4.76e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.937, tt:2903.877\n",
      "Ep:97, loss:0.00000, loss_test:0.01303, lr:4.71e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.923, tt:2932.425\n",
      "Ep:98, loss:0.00000, loss_test:0.01308, lr:4.67e-02, fs:0.78212 (r=0.707,p=0.875),  time:29.921, tt:2962.181\n",
      "Ep:99, loss:0.00000, loss_test:0.01319, lr:4.62e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.922, tt:2992.228\n",
      "Ep:100, loss:0.00000, loss_test:0.01323, lr:4.57e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.913, tt:3021.240\n",
      "Ep:101, loss:0.00000, loss_test:0.01322, lr:4.53e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.912, tt:3051.055\n",
      "Ep:102, loss:0.00000, loss_test:0.01333, lr:4.48e-02, fs:0.78212 (r=0.707,p=0.875),  time:29.906, tt:3080.288\n",
      "Ep:103, loss:0.00000, loss_test:0.01343, lr:4.44e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.903, tt:3109.912\n",
      "Ep:104, loss:0.00000, loss_test:0.01350, lr:4.39e-02, fs:0.78212 (r=0.707,p=0.875),  time:29.902, tt:3139.758\n",
      "Ep:105, loss:0.00000, loss_test:0.01354, lr:4.35e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.887, tt:3168.073\n",
      "Ep:106, loss:0.00000, loss_test:0.01359, lr:4.31e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.871, tt:3196.249\n",
      "Ep:107, loss:0.00000, loss_test:0.01369, lr:4.26e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.882, tt:3227.272\n",
      "Ep:108, loss:0.00000, loss_test:0.01373, lr:4.22e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.856, tt:3254.299\n",
      "Ep:109, loss:0.00000, loss_test:0.01381, lr:4.18e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.855, tt:3284.009\n",
      "Ep:110, loss:0.00000, loss_test:0.01385, lr:4.14e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.854, tt:3313.759\n",
      "Ep:111, loss:0.00000, loss_test:0.01390, lr:4.10e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.840, tt:3342.048\n",
      "Ep:112, loss:0.00000, loss_test:0.01399, lr:4.05e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.821, tt:3369.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00000, loss_test:0.01401, lr:4.01e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.830, tt:3400.665\n",
      "Ep:114, loss:0.00000, loss_test:0.01400, lr:3.97e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.837, tt:3431.207\n",
      "Ep:115, loss:0.00000, loss_test:0.01417, lr:3.93e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.837, tt:3461.130\n",
      "Ep:116, loss:0.00000, loss_test:0.01421, lr:3.89e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.844, tt:3491.758\n",
      "Ep:117, loss:0.00000, loss_test:0.01421, lr:3.86e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.840, tt:3521.178\n",
      "Ep:118, loss:0.00000, loss_test:0.01428, lr:3.82e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.848, tt:3551.942\n",
      "Ep:119, loss:0.00000, loss_test:0.01429, lr:3.78e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.841, tt:3580.927\n",
      "Ep:120, loss:0.00000, loss_test:0.01435, lr:3.74e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.837, tt:3610.230\n",
      "Ep:121, loss:0.00000, loss_test:0.01443, lr:3.70e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.830, tt:3639.205\n",
      "Ep:122, loss:0.00000, loss_test:0.01440, lr:3.67e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.829, tt:3668.965\n",
      "Ep:123, loss:0.00000, loss_test:0.01451, lr:3.63e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.828, tt:3698.693\n",
      "Ep:124, loss:0.00000, loss_test:0.01454, lr:3.59e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.821, tt:3727.674\n",
      "Ep:125, loss:0.00000, loss_test:0.01454, lr:3.56e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.818, tt:3757.112\n",
      "Ep:126, loss:0.00000, loss_test:0.01459, lr:3.52e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.827, tt:3787.999\n",
      "Ep:127, loss:0.00000, loss_test:0.01460, lr:3.49e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.821, tt:3817.054\n",
      "Ep:128, loss:0.00000, loss_test:0.01464, lr:3.45e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.822, tt:3847.009\n",
      "Ep:129, loss:0.00000, loss_test:0.01473, lr:3.42e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.825, tt:3877.259\n",
      "Ep:130, loss:0.00000, loss_test:0.01476, lr:3.38e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.832, tt:3907.950\n",
      "Ep:131, loss:0.00000, loss_test:0.01475, lr:3.35e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.829, tt:3937.460\n",
      "Ep:132, loss:0.00000, loss_test:0.01480, lr:3.32e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.810, tt:3964.751\n",
      "Ep:133, loss:0.00000, loss_test:0.01486, lr:3.28e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.807, tt:3994.073\n",
      "Ep:134, loss:0.00000, loss_test:0.01487, lr:3.25e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.816, tt:4025.100\n",
      "Ep:135, loss:0.00000, loss_test:0.01489, lr:3.22e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.814, tt:4054.727\n",
      "Ep:136, loss:0.00000, loss_test:0.01496, lr:3.19e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.825, tt:4085.986\n",
      "Ep:137, loss:0.00000, loss_test:0.01494, lr:3.15e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.837, tt:4117.454\n",
      "Ep:138, loss:0.00000, loss_test:0.01499, lr:3.12e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.835, tt:4147.124\n",
      "Ep:139, loss:0.00000, loss_test:0.01501, lr:3.09e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.833, tt:4176.567\n",
      "Ep:140, loss:0.00000, loss_test:0.01505, lr:3.06e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.830, tt:4206.047\n",
      "Ep:141, loss:0.00000, loss_test:0.01507, lr:3.03e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.838, tt:4237.014\n",
      "Ep:142, loss:0.00000, loss_test:0.01512, lr:3.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.833, tt:4266.049\n",
      "Ep:143, loss:0.00000, loss_test:0.01516, lr:2.97e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.833, tt:4295.893\n",
      "Ep:144, loss:0.00000, loss_test:0.01516, lr:2.94e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.834, tt:4325.945\n",
      "Ep:145, loss:0.00000, loss_test:0.01519, lr:2.91e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.839, tt:4356.443\n",
      "Ep:146, loss:0.00000, loss_test:0.01519, lr:2.88e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.830, tt:4384.943\n",
      "Ep:147, loss:0.00000, loss_test:0.01523, lr:2.85e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.835, tt:4415.582\n",
      "Ep:148, loss:0.00000, loss_test:0.01528, lr:2.82e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.836, tt:4445.601\n",
      "Ep:149, loss:0.00000, loss_test:0.01529, lr:2.80e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.833, tt:4474.917\n",
      "Ep:150, loss:0.00000, loss_test:0.01533, lr:2.77e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.826, tt:4503.779\n",
      "Ep:151, loss:0.00000, loss_test:0.01536, lr:2.74e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.833, tt:4534.542\n",
      "Ep:152, loss:0.00000, loss_test:0.01536, lr:2.71e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.836, tt:4564.918\n",
      "Ep:153, loss:0.00000, loss_test:0.01538, lr:2.69e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.834, tt:4594.426\n",
      "Ep:154, loss:0.00000, loss_test:0.01541, lr:2.66e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.832, tt:4623.942\n",
      "Ep:155, loss:0.00000, loss_test:0.01543, lr:2.63e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.834, tt:4654.113\n",
      "Ep:156, loss:0.00000, loss_test:0.01545, lr:2.61e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.835, tt:4684.140\n",
      "Ep:157, loss:0.00000, loss_test:0.01551, lr:2.58e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.830, tt:4713.144\n",
      "Ep:158, loss:0.00000, loss_test:0.01549, lr:2.55e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.829, tt:4742.799\n",
      "Ep:159, loss:0.00000, loss_test:0.01550, lr:2.53e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.825, tt:4771.974\n",
      "Ep:160, loss:0.00000, loss_test:0.01553, lr:2.50e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.826, tt:4801.925\n",
      "Ep:161, loss:0.00000, loss_test:0.01552, lr:2.48e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.827, tt:4832.034\n",
      "Ep:162, loss:0.00000, loss_test:0.01555, lr:2.45e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.827, tt:4861.875\n",
      "Ep:163, loss:0.00000, loss_test:0.01561, lr:2.43e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.829, tt:4891.966\n",
      "Ep:164, loss:0.00000, loss_test:0.01559, lr:2.40e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.829, tt:4921.804\n",
      "Ep:165, loss:0.00000, loss_test:0.01558, lr:2.38e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.832, tt:4952.077\n",
      "Ep:166, loss:0.00000, loss_test:0.01560, lr:2.36e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.834, tt:4982.271\n",
      "Ep:167, loss:0.00000, loss_test:0.01565, lr:2.33e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.828, tt:5011.141\n",
      "Ep:168, loss:0.00000, loss_test:0.01568, lr:2.31e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.844, tt:5043.611\n",
      "Ep:169, loss:0.00000, loss_test:0.01567, lr:2.29e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.847, tt:5074.027\n",
      "Ep:170, loss:0.00000, loss_test:0.01565, lr:2.26e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.840, tt:5102.656\n",
      "Ep:171, loss:0.00000, loss_test:0.01568, lr:2.24e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.835, tt:5131.664\n",
      "Ep:172, loss:0.00000, loss_test:0.01576, lr:2.22e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.832, tt:5160.900\n",
      "Ep:173, loss:0.00000, loss_test:0.01580, lr:2.20e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.831, tt:5190.605\n",
      "Ep:174, loss:0.00000, loss_test:0.01578, lr:2.17e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.823, tt:5219.010\n",
      "Ep:175, loss:0.00000, loss_test:0.01576, lr:2.15e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.822, tt:5248.757\n",
      "Ep:176, loss:0.00000, loss_test:0.01576, lr:2.13e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.826, tt:5279.189\n",
      "Ep:177, loss:0.00000, loss_test:0.01580, lr:2.11e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.818, tt:5307.638\n",
      "Ep:178, loss:0.00000, loss_test:0.01582, lr:2.09e-02, fs:0.76301 (r=0.667,p=0.892),  time:29.814, tt:5336.677\n",
      "Ep:179, loss:0.00000, loss_test:0.01584, lr:2.07e-02, fs:0.76301 (r=0.667,p=0.892),  time:29.814, tt:5366.464\n",
      "Ep:180, loss:0.00000, loss_test:0.01585, lr:2.05e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.818, tt:5397.039\n",
      "Ep:181, loss:0.00000, loss_test:0.01585, lr:2.03e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.817, tt:5426.651\n",
      "Ep:182, loss:0.00000, loss_test:0.01583, lr:2.01e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.820, tt:5457.085\n",
      "Ep:183, loss:0.00000, loss_test:0.01587, lr:1.99e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.819, tt:5486.729\n",
      "Ep:184, loss:0.00000, loss_test:0.01587, lr:1.97e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.820, tt:5516.625\n",
      "Ep:185, loss:0.00000, loss_test:0.01588, lr:1.95e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.819, tt:5546.420\n",
      "Ep:186, loss:0.00000, loss_test:0.01590, lr:1.93e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.823, tt:5576.849\n",
      "Ep:187, loss:0.00000, loss_test:0.01592, lr:1.91e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.820, tt:5606.221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:188, loss:0.00000, loss_test:0.01591, lr:1.89e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.827, tt:5637.235\n",
      "Ep:189, loss:0.00000, loss_test:0.01591, lr:1.87e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.832, tt:5668.110\n",
      "Ep:190, loss:0.00000, loss_test:0.01594, lr:1.85e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.837, tt:5698.805\n",
      "Ep:191, loss:0.00000, loss_test:0.01598, lr:1.83e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.862, tt:5733.471\n",
      "Ep:192, loss:0.00000, loss_test:0.01598, lr:1.81e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.868, tt:5764.436\n",
      "Ep:193, loss:0.00000, loss_test:0.01600, lr:1.80e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.873, tt:5795.307\n",
      "Ep:194, loss:0.00000, loss_test:0.01602, lr:1.78e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.878, tt:5826.222\n",
      "Ep:195, loss:0.00000, loss_test:0.01601, lr:1.76e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.878, tt:5856.106\n",
      "Ep:196, loss:0.00000, loss_test:0.01602, lr:1.74e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.878, tt:5885.969\n",
      "Ep:197, loss:0.00000, loss_test:0.01604, lr:1.73e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.869, tt:5914.056\n",
      "Ep:198, loss:0.00000, loss_test:0.01607, lr:1.71e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.860, tt:5942.151\n",
      "Ep:199, loss:0.00000, loss_test:0.01607, lr:1.69e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.863, tt:5972.567\n",
      "Ep:200, loss:0.00000, loss_test:0.01606, lr:1.67e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.848, tt:5999.447\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14144, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:30.063, tt:30.063\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13966, lr:1.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:28.464, tt:56.929\n",
      "Ep:2, loss:0.00027, loss_test:0.13666, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:27.994, tt:83.981\n",
      "Ep:3, loss:0.00026, loss_test:0.13263, lr:1.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:28.180, tt:112.722\n",
      "Ep:4, loss:0.00025, loss_test:0.13007, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:28.630, tt:143.150\n",
      "Ep:5, loss:0.00025, loss_test:0.12685, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:28.907, tt:173.443\n",
      "Ep:6, loss:0.00025, loss_test:0.12235, lr:1.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:29.314, tt:205.199\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11931, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:29.380, tt:235.041\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.11657, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:29.309, tt:263.783\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11393, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:29.248, tt:292.485\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.11193, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:29.327, tt:322.594\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.11136, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:29.435, tt:353.216\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11055, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:29.560, tt:384.280\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10951, lr:1.00e-02, fs:0.75105 (r=0.899,p=0.645),  time:29.578, tt:414.091\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10880, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:29.716, tt:445.745\n",
      "Ep:15, loss:0.00021, loss_test:0.10826, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:29.850, tt:477.601\n",
      "Ep:16, loss:0.00020, loss_test:0.10797, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:29.947, tt:509.092\n",
      "Ep:17, loss:0.00020, loss_test:0.10653, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:29.971, tt:539.475\n",
      "Ep:18, loss:0.00020, loss_test:0.10525, lr:1.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:30.050, tt:570.955\n",
      "Ep:19, loss:0.00019, loss_test:0.10435, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:30.030, tt:600.590\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.10362, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:30.062, tt:631.312\n",
      "Ep:21, loss:0.00018, loss_test:0.10172, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:30.120, tt:662.642\n",
      "Ep:22, loss:0.00018, loss_test:0.09942, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:30.206, tt:694.735\n",
      "Ep:23, loss:0.00017, loss_test:0.09762, lr:1.00e-02, fs:0.76190 (r=0.889,p=0.667),  time:30.283, tt:726.790\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09700, lr:1.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:30.384, tt:759.596\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.09417, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:30.463, tt:792.028\n",
      "Ep:26, loss:0.00016, loss_test:0.09294, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:30.507, tt:823.695\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.09022, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:30.535, tt:854.991\n",
      "Ep:28, loss:0.00015, loss_test:0.08899, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:30.589, tt:887.079\n",
      "Ep:29, loss:0.00014, loss_test:0.08672, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.645, tt:919.363\n",
      "Ep:30, loss:0.00014, loss_test:0.08468, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:30.688, tt:951.328\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08415, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:30.694, tt:982.209\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08221, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.733, tt:1014.183\n",
      "Ep:33, loss:0.00012, loss_test:0.08117, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.764, tt:1045.978\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.07922, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:30.765, tt:1076.765\n",
      "Ep:35, loss:0.00011, loss_test:0.07971, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.784, tt:1108.239\n",
      "Ep:36, loss:0.00011, loss_test:0.07696, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.783, tt:1138.978\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07645, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.799, tt:1170.359\n",
      "Ep:38, loss:0.00010, loss_test:0.07740, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.812, tt:1201.651\n",
      "Ep:39, loss:0.00010, loss_test:0.07372, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.794, tt:1231.770\n",
      "Ep:40, loss:0.00009, loss_test:0.07370, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:30.809, tt:1263.166\n",
      "Ep:41, loss:0.00009, loss_test:0.07378, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.827, tt:1294.730\n",
      "Ep:42, loss:0.00009, loss_test:0.07150, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.862, tt:1327.054\n",
      "Ep:43, loss:0.00008, loss_test:0.07133, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.909, tt:1359.986\n",
      "Ep:44, loss:0.00008, loss_test:0.07134, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.984, tt:1394.264\n",
      "Ep:45, loss:0.00008, loss_test:0.07223, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:31.039, tt:1427.787\n",
      "Ep:46, loss:0.00007, loss_test:0.07117, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:31.077, tt:1460.637\n",
      "Ep:47, loss:0.00007, loss_test:0.07069, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.105, tt:1493.020\n",
      "Ep:48, loss:0.00007, loss_test:0.07265, lr:9.90e-03, fs:0.79781 (r=0.737,p=0.869),  time:31.138, tt:1525.748\n",
      "Ep:49, loss:0.00007, loss_test:0.07152, lr:9.80e-03, fs:0.79570 (r=0.747,p=0.851),  time:31.171, tt:1558.540\n",
      "Ep:50, loss:0.00006, loss_test:0.07254, lr:9.70e-03, fs:0.80412 (r=0.788,p=0.821),  time:31.192, tt:1590.780\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00006, loss_test:0.07462, lr:9.70e-03, fs:0.80000 (r=0.747,p=0.860),  time:31.220, tt:1623.428\n",
      "Ep:52, loss:0.00006, loss_test:0.06923, lr:9.70e-03, fs:0.82474 (r=0.808,p=0.842),  time:31.225, tt:1654.947\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.07623, lr:9.70e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.234, tt:1686.655\n",
      "Ep:54, loss:0.00005, loss_test:0.07243, lr:9.70e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.232, tt:1717.770\n",
      "Ep:55, loss:0.00005, loss_test:0.07517, lr:9.70e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.246, tt:1749.762\n",
      "Ep:56, loss:0.00005, loss_test:0.07339, lr:9.70e-03, fs:0.81283 (r=0.768,p=0.864),  time:31.266, tt:1782.165\n",
      "Ep:57, loss:0.00005, loss_test:0.07261, lr:9.70e-03, fs:0.80000 (r=0.747,p=0.860),  time:31.277, tt:1814.093\n",
      "Ep:58, loss:0.00005, loss_test:0.07663, lr:9.70e-03, fs:0.80435 (r=0.747,p=0.871),  time:31.302, tt:1846.844\n",
      "Ep:59, loss:0.00004, loss_test:0.07253, lr:9.70e-03, fs:0.79570 (r=0.747,p=0.851),  time:31.290, tt:1877.404\n",
      "Ep:60, loss:0.00004, loss_test:0.07243, lr:9.70e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.314, tt:1910.156\n",
      "Ep:61, loss:0.00004, loss_test:0.07556, lr:9.70e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.313, tt:1941.426\n",
      "Ep:62, loss:0.00004, loss_test:0.07367, lr:9.70e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.316, tt:1972.893\n",
      "Ep:63, loss:0.00004, loss_test:0.07312, lr:9.70e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.307, tt:2003.637\n",
      "Ep:64, loss:0.00004, loss_test:0.07466, lr:9.61e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.327, tt:2036.237\n",
      "Ep:65, loss:0.00004, loss_test:0.07203, lr:9.51e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.307, tt:2066.292\n",
      "Ep:66, loss:0.00004, loss_test:0.07593, lr:9.41e-03, fs:0.77778 (r=0.707,p=0.864),  time:31.294, tt:2096.731\n",
      "Ep:67, loss:0.00004, loss_test:0.07219, lr:9.32e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.288, tt:2127.602\n",
      "Ep:68, loss:0.00003, loss_test:0.07294, lr:9.23e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.278, tt:2158.163\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00003, loss_test:0.07425, lr:9.23e-03, fs:0.79330 (r=0.717,p=0.887),  time:31.274, tt:2189.187\n",
      "Ep:70, loss:0.00003, loss_test:0.07257, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:31.268, tt:2220.036\n",
      "Ep:71, loss:0.00003, loss_test:0.07557, lr:9.23e-03, fs:0.77273 (r=0.687,p=0.883),  time:31.282, tt:2252.311\n",
      "Ep:72, loss:0.00003, loss_test:0.07331, lr:9.23e-03, fs:0.82682 (r=0.747,p=0.925),  time:31.272, tt:2282.820\n",
      "Ep:73, loss:0.00003, loss_test:0.07528, lr:9.23e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.276, tt:2314.431\n",
      "Ep:74, loss:0.00003, loss_test:0.07321, lr:9.23e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.284, tt:2346.279\n",
      "Ep:75, loss:0.00003, loss_test:0.07565, lr:9.23e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.277, tt:2377.087\n",
      "Ep:76, loss:0.00003, loss_test:0.07500, lr:9.23e-03, fs:0.81143 (r=0.717,p=0.934),  time:31.308, tt:2410.746\n",
      "Ep:77, loss:0.00003, loss_test:0.07361, lr:9.23e-03, fs:0.85263 (r=0.818,p=0.890),  time:31.305, tt:2441.821\n",
      "Ep:78, loss:0.00003, loss_test:0.07662, lr:9.23e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.302, tt:2472.859\n",
      "Ep:79, loss:0.00003, loss_test:0.07331, lr:9.23e-03, fs:0.82682 (r=0.747,p=0.925),  time:31.303, tt:2504.244\n",
      "Ep:80, loss:0.00003, loss_test:0.07428, lr:9.14e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.294, tt:2534.845\n",
      "Ep:81, loss:0.00002, loss_test:0.07668, lr:9.04e-03, fs:0.82486 (r=0.737,p=0.936),  time:31.280, tt:2564.976\n",
      "Ep:82, loss:0.00002, loss_test:0.07404, lr:8.95e-03, fs:0.82979 (r=0.788,p=0.876),  time:31.265, tt:2595.010\n",
      "Ep:83, loss:0.00002, loss_test:0.07666, lr:8.86e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.269, tt:2626.573\n",
      "Ep:84, loss:0.00002, loss_test:0.07767, lr:8.78e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.261, tt:2657.154\n",
      "Ep:85, loss:0.00002, loss_test:0.07262, lr:8.69e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.254, tt:2687.841\n",
      "Ep:86, loss:0.00002, loss_test:0.07530, lr:8.60e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.241, tt:2717.963\n",
      "Ep:87, loss:0.00002, loss_test:0.07485, lr:8.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:31.241, tt:2749.230\n",
      "Ep:88, loss:0.00002, loss_test:0.07234, lr:8.43e-03, fs:0.81564 (r=0.737,p=0.912),  time:31.248, tt:2781.038\n",
      "Ep:89, loss:0.00002, loss_test:0.07722, lr:8.35e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.233, tt:2810.981\n",
      "Ep:90, loss:0.00002, loss_test:0.07337, lr:8.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.242, tt:2843.044\n",
      "Ep:91, loss:0.00002, loss_test:0.07586, lr:8.18e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.246, tt:2874.634\n",
      "Ep:92, loss:0.00002, loss_test:0.07527, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.233, tt:2904.673\n",
      "Ep:93, loss:0.00002, loss_test:0.07685, lr:8.02e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.204, tt:2933.207\n",
      "Ep:94, loss:0.00002, loss_test:0.07380, lr:7.94e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.183, tt:2962.408\n",
      "Ep:95, loss:0.00002, loss_test:0.07605, lr:7.86e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.188, tt:2994.011\n",
      "Ep:96, loss:0.00002, loss_test:0.07432, lr:7.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.168, tt:3023.333\n",
      "Ep:97, loss:0.00002, loss_test:0.07979, lr:7.70e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.173, tt:3054.999\n",
      "Ep:98, loss:0.00002, loss_test:0.07581, lr:7.62e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.190, tt:3087.812\n",
      "Ep:99, loss:0.00002, loss_test:0.07727, lr:7.55e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.193, tt:3119.338\n",
      "Ep:100, loss:0.00002, loss_test:0.07810, lr:7.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.195, tt:3150.685\n",
      "Ep:101, loss:0.00002, loss_test:0.07818, lr:7.40e-03, fs:0.76023 (r=0.657,p=0.903),  time:31.203, tt:3182.718\n",
      "Ep:102, loss:0.00002, loss_test:0.07549, lr:7.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.204, tt:3213.969\n",
      "Ep:103, loss:0.00002, loss_test:0.07900, lr:7.25e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.194, tt:3244.136\n",
      "Ep:104, loss:0.00002, loss_test:0.07805, lr:7.18e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.191, tt:3275.075\n",
      "Ep:105, loss:0.00001, loss_test:0.07627, lr:7.11e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.190, tt:3306.135\n",
      "Ep:106, loss:0.00001, loss_test:0.08084, lr:7.03e-03, fs:0.73810 (r=0.626,p=0.899),  time:31.175, tt:3335.746\n",
      "Ep:107, loss:0.00001, loss_test:0.07796, lr:6.96e-03, fs:0.80925 (r=0.707,p=0.946),  time:31.167, tt:3366.061\n",
      "Ep:108, loss:0.00001, loss_test:0.07842, lr:6.89e-03, fs:0.75294 (r=0.646,p=0.901),  time:31.154, tt:3395.799\n",
      "Ep:109, loss:0.00001, loss_test:0.08062, lr:6.83e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.155, tt:3426.999\n",
      "Ep:110, loss:0.00001, loss_test:0.07749, lr:6.76e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.158, tt:3458.581\n",
      "Ep:111, loss:0.00001, loss_test:0.07941, lr:6.69e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.158, tt:3489.698\n",
      "Ep:112, loss:0.00001, loss_test:0.07961, lr:6.62e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.150, tt:3519.901\n",
      "Ep:113, loss:0.00001, loss_test:0.07832, lr:6.56e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.135, tt:3549.400\n",
      "Ep:114, loss:0.00001, loss_test:0.07823, lr:6.49e-03, fs:0.80925 (r=0.707,p=0.946),  time:31.125, tt:3579.380\n",
      "Ep:115, loss:0.00001, loss_test:0.07969, lr:6.43e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.123, tt:3610.303\n",
      "Ep:116, loss:0.00001, loss_test:0.07931, lr:6.36e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.122, tt:3641.289\n",
      "Ep:117, loss:0.00001, loss_test:0.07904, lr:6.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.120, tt:3672.164\n",
      "Ep:118, loss:0.00001, loss_test:0.07922, lr:6.24e-03, fs:0.74556 (r=0.636,p=0.900),  time:31.127, tt:3704.114\n",
      "Ep:119, loss:0.00001, loss_test:0.07845, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.155, tt:3738.541\n",
      "Ep:120, loss:0.00001, loss_test:0.07994, lr:6.11e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.159, tt:3770.217\n",
      "Ep:121, loss:0.00001, loss_test:0.08144, lr:6.05e-03, fs:0.73054 (r=0.616,p=0.897),  time:31.163, tt:3801.933\n",
      "Ep:122, loss:0.00001, loss_test:0.07856, lr:5.99e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.160, tt:3832.686\n",
      "Ep:123, loss:0.00001, loss_test:0.08219, lr:5.93e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.163, tt:3864.183\n",
      "Ep:124, loss:0.00001, loss_test:0.08043, lr:5.87e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.163, tt:3895.323\n",
      "Ep:125, loss:0.00001, loss_test:0.08091, lr:5.81e-03, fs:0.73494 (r=0.616,p=0.910),  time:31.158, tt:3925.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00001, loss_test:0.08017, lr:5.75e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.156, tt:3956.842\n",
      "Ep:127, loss:0.00001, loss_test:0.08018, lr:5.70e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.155, tt:3987.880\n",
      "Ep:128, loss:0.00001, loss_test:0.08022, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.159, tt:4019.459\n",
      "Ep:129, loss:0.00001, loss_test:0.08073, lr:5.58e-03, fs:0.75904 (r=0.636,p=0.940),  time:31.175, tt:4052.728\n",
      "Ep:130, loss:0.00001, loss_test:0.07948, lr:5.53e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.166, tt:4082.763\n",
      "Ep:131, loss:0.00001, loss_test:0.08004, lr:5.47e-03, fs:0.75904 (r=0.636,p=0.940),  time:31.163, tt:4113.451\n",
      "Ep:132, loss:0.00001, loss_test:0.08042, lr:5.42e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.152, tt:4143.253\n",
      "Ep:133, loss:0.00001, loss_test:0.08174, lr:5.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.160, tt:4175.451\n",
      "Ep:134, loss:0.00001, loss_test:0.07901, lr:5.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.159, tt:4206.470\n",
      "Ep:135, loss:0.00001, loss_test:0.08184, lr:5.26e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.164, tt:4238.321\n",
      "Ep:136, loss:0.00001, loss_test:0.08097, lr:5.20e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.167, tt:4269.880\n",
      "Ep:137, loss:0.00001, loss_test:0.08120, lr:5.15e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.168, tt:4301.251\n",
      "Ep:138, loss:0.00001, loss_test:0.08021, lr:5.10e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.178, tt:4333.806\n",
      "Ep:139, loss:0.00001, loss_test:0.08208, lr:5.05e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.186, tt:4366.008\n",
      "Ep:140, loss:0.00001, loss_test:0.08142, lr:5.00e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.193, tt:4398.157\n",
      "Ep:141, loss:0.00001, loss_test:0.08133, lr:4.95e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.207, tt:4431.359\n",
      "Ep:142, loss:0.00001, loss_test:0.08093, lr:4.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.214, tt:4463.574\n",
      "Ep:143, loss:0.00001, loss_test:0.08188, lr:4.85e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.220, tt:4495.709\n",
      "Ep:144, loss:0.00001, loss_test:0.08080, lr:4.80e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.227, tt:4527.985\n",
      "Ep:145, loss:0.00001, loss_test:0.08154, lr:4.75e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.237, tt:4560.623\n",
      "Ep:146, loss:0.00001, loss_test:0.08141, lr:4.71e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.246, tt:4593.231\n",
      "Ep:147, loss:0.00001, loss_test:0.08017, lr:4.66e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.248, tt:4624.662\n",
      "Ep:148, loss:0.00001, loss_test:0.08176, lr:4.61e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.248, tt:4656.019\n",
      "Ep:149, loss:0.00001, loss_test:0.08219, lr:4.57e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.245, tt:4686.770\n",
      "Ep:150, loss:0.00001, loss_test:0.08036, lr:4.52e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.254, tt:4719.359\n",
      "Ep:151, loss:0.00001, loss_test:0.08019, lr:4.48e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.264, tt:4752.195\n",
      "Ep:152, loss:0.00001, loss_test:0.08288, lr:4.43e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.259, tt:4782.690\n",
      "Ep:153, loss:0.00001, loss_test:0.08038, lr:4.39e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.245, tt:4811.654\n",
      "Ep:154, loss:0.00001, loss_test:0.08135, lr:4.34e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.235, tt:4841.394\n",
      "Ep:155, loss:0.00001, loss_test:0.08046, lr:4.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.237, tt:4872.924\n",
      "Ep:156, loss:0.00001, loss_test:0.08321, lr:4.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.245, tt:4905.432\n",
      "Ep:157, loss:0.00001, loss_test:0.08202, lr:4.21e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.250, tt:4937.564\n",
      "Ep:158, loss:0.00001, loss_test:0.08234, lr:4.17e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.261, tt:4970.567\n",
      "Ep:159, loss:0.00001, loss_test:0.08199, lr:4.13e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.269, tt:5003.102\n",
      "Ep:160, loss:0.00001, loss_test:0.08107, lr:4.09e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.280, tt:5036.070\n",
      "Ep:161, loss:0.00001, loss_test:0.08374, lr:4.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.274, tt:5066.353\n",
      "Ep:162, loss:0.00001, loss_test:0.08067, lr:4.01e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.281, tt:5098.724\n",
      "Ep:163, loss:0.00001, loss_test:0.08212, lr:3.97e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.305, tt:5133.944\n",
      "Ep:164, loss:0.00001, loss_test:0.08127, lr:3.93e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.307, tt:5165.651\n",
      "Ep:165, loss:0.00001, loss_test:0.08152, lr:3.89e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.303, tt:5196.344\n",
      "Ep:166, loss:0.00001, loss_test:0.08310, lr:3.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:31.307, tt:5228.299\n",
      "Ep:167, loss:0.00001, loss_test:0.08125, lr:3.81e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.315, tt:5260.950\n",
      "Ep:168, loss:0.00001, loss_test:0.08205, lr:3.77e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.316, tt:5292.449\n",
      "Ep:169, loss:0.00001, loss_test:0.08112, lr:3.73e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.327, tt:5325.517\n",
      "Ep:170, loss:0.00001, loss_test:0.08168, lr:3.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.327, tt:5356.976\n",
      "Ep:171, loss:0.00001, loss_test:0.08264, lr:3.66e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.334, tt:5389.462\n",
      "Ep:172, loss:0.00001, loss_test:0.08084, lr:3.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.341, tt:5422.030\n",
      "Ep:173, loss:0.00001, loss_test:0.08160, lr:3.59e-03, fs:0.75904 (r=0.636,p=0.940),  time:31.348, tt:5454.609\n",
      "Ep:174, loss:0.00001, loss_test:0.08069, lr:3.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.359, tt:5487.805\n",
      "Ep:175, loss:0.00001, loss_test:0.08345, lr:3.52e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.356, tt:5518.675\n",
      "Ep:176, loss:0.00001, loss_test:0.08275, lr:3.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.364, tt:5551.511\n",
      "Ep:177, loss:0.00001, loss_test:0.08142, lr:3.45e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.363, tt:5582.535\n",
      "Ep:178, loss:0.00001, loss_test:0.08349, lr:3.41e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.356, tt:5612.742\n",
      "Ep:179, loss:0.00001, loss_test:0.08165, lr:3.38e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.353, tt:5643.554\n",
      "Ep:180, loss:0.00001, loss_test:0.08202, lr:3.34e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.351, tt:5674.573\n",
      "Ep:181, loss:0.00001, loss_test:0.08290, lr:3.31e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.358, tt:5707.210\n",
      "Ep:182, loss:0.00001, loss_test:0.08148, lr:3.28e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.355, tt:5738.012\n",
      "Ep:183, loss:0.00001, loss_test:0.08270, lr:3.24e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.354, tt:5769.114\n",
      "Ep:184, loss:0.00001, loss_test:0.08278, lr:3.21e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.358, tt:5801.309\n",
      "Ep:185, loss:0.00001, loss_test:0.08055, lr:3.18e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.351, tt:5831.289\n",
      "Ep:186, loss:0.00001, loss_test:0.08273, lr:3.15e-03, fs:0.74390 (r=0.616,p=0.938),  time:31.353, tt:5863.091\n",
      "Ep:187, loss:0.00001, loss_test:0.08212, lr:3.12e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.352, tt:5894.087\n",
      "Ep:188, loss:0.00001, loss_test:0.08161, lr:3.09e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.353, tt:5925.726\n",
      "Ep:189, loss:0.00001, loss_test:0.08335, lr:3.05e-03, fs:0.73171 (r=0.606,p=0.923),  time:31.344, tt:5955.270\n",
      "Ep:190, loss:0.00001, loss_test:0.08203, lr:3.02e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.340, tt:5986.026\n",
      "Ep:191, loss:0.00001, loss_test:0.08227, lr:2.99e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.342, tt:6017.632\n",
      "Ep:192, loss:0.00001, loss_test:0.08235, lr:2.96e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.344, tt:6049.448\n",
      "Ep:193, loss:0.00001, loss_test:0.08170, lr:2.93e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.343, tt:6080.472\n",
      "Ep:194, loss:0.00001, loss_test:0.08192, lr:2.90e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.344, tt:6112.152\n",
      "Ep:195, loss:0.00001, loss_test:0.08313, lr:2.88e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.350, tt:6144.687\n",
      "Ep:196, loss:0.00001, loss_test:0.08265, lr:2.85e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.347, tt:6175.286\n",
      "Ep:197, loss:0.00001, loss_test:0.08200, lr:2.82e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.336, tt:6204.473\n",
      "Ep:198, loss:0.00001, loss_test:0.08324, lr:2.79e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.322, tt:6233.057\n",
      "Ep:199, loss:0.00001, loss_test:0.08182, lr:2.76e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.299, tt:6259.864\n",
      "Ep:200, loss:0.00001, loss_test:0.08237, lr:2.73e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.287, tt:6288.652\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02109, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:12.204, tt:12.204\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02514, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.716, tt:23.432\n",
      "Ep:2, loss:0.00005, loss_test:0.02767, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.557, tt:34.671\n",
      "Ep:3, loss:0.00005, loss_test:0.02865, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.449, tt:45.797\n",
      "Ep:4, loss:0.00006, loss_test:0.02874, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.388, tt:56.938\n",
      "Ep:5, loss:0.00005, loss_test:0.02807, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.328, tt:67.969\n",
      "Ep:6, loss:0.00005, loss_test:0.02682, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.271, tt:78.898\n",
      "Ep:7, loss:0.00005, loss_test:0.02522, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.231, tt:89.847\n",
      "Ep:8, loss:0.00005, loss_test:0.02347, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:11.191, tt:100.715\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02215, lr:6.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:11.159, tt:111.586\n",
      "Ep:10, loss:0.00004, loss_test:0.02181, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:11.145, tt:122.597\n",
      "Ep:11, loss:0.00004, loss_test:0.02202, lr:6.00e-02, fs:0.62551 (r=0.768,p=0.528),  time:11.164, tt:133.964\n",
      "Ep:12, loss:0.00004, loss_test:0.02153, lr:6.00e-02, fs:0.62447 (r=0.747,p=0.536),  time:11.161, tt:145.094\n",
      "Ep:13, loss:0.00004, loss_test:0.02031, lr:6.00e-02, fs:0.65560 (r=0.798,p=0.556),  time:11.337, tt:158.722\n",
      "Ep:14, loss:0.00004, loss_test:0.01922, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:11.330, tt:169.954\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01860, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:11.320, tt:181.124\n",
      "Ep:16, loss:0.00003, loss_test:0.01814, lr:6.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:11.313, tt:192.322\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01767, lr:6.00e-02, fs:0.71483 (r=0.949,p=0.573),  time:11.311, tt:203.603\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01727, lr:6.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:11.310, tt:214.890\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:11.309, tt:226.188\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:11.289, tt:237.074\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:11.271, tt:247.961\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:11.270, tt:259.219\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:11.268, tt:270.421\n",
      "Ep:24, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:11.265, tt:281.625\n",
      "Ep:25, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:11.263, tt:292.836\n",
      "Ep:26, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:11.257, tt:303.934\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:11.256, tt:315.163\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01520, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:11.253, tt:326.345\n",
      "Ep:29, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:11.260, tt:337.799\n",
      "Ep:30, loss:0.00002, loss_test:0.01476, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:11.262, tt:349.116\n",
      "Ep:31, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:11.262, tt:360.372\n",
      "Ep:32, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:11.261, tt:371.604\n",
      "Ep:33, loss:0.00002, loss_test:0.01432, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:11.255, tt:382.676\n",
      "Ep:34, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:11.251, tt:393.783\n",
      "Ep:35, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:11.246, tt:404.857\n",
      "Ep:36, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:11.245, tt:416.047\n",
      "Ep:37, loss:0.00002, loss_test:0.01387, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:11.243, tt:427.218\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:11.239, tt:438.320\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:11.237, tt:449.494\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:11.241, tt:460.876\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01341, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:11.237, tt:471.962\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:11.230, tt:482.906\n",
      "Ep:43, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:11.224, tt:493.870\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01315, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:11.220, tt:504.890\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01307, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:11.217, tt:515.993\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01297, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:11.211, tt:526.935\n",
      "Ep:47, loss:0.00001, loss_test:0.01292, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.205, tt:537.841\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.207, tt:549.141\n",
      "Ep:49, loss:0.00001, loss_test:0.01283, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.205, tt:560.225\n",
      "Ep:50, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.201, tt:571.269\n",
      "Ep:51, loss:0.00001, loss_test:0.01276, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.198, tt:582.301\n",
      "Ep:52, loss:0.00001, loss_test:0.01274, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.195, tt:593.328\n",
      "Ep:53, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:11.198, tt:604.683\n",
      "Ep:54, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:11.198, tt:615.894\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01266, lr:6.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:11.241, tt:629.510\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01267, lr:6.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:11.240, tt:640.695\n",
      "Ep:57, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:11.250, tt:652.528\n",
      "Ep:58, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:11.255, tt:664.029\n",
      "Ep:59, loss:0.00001, loss_test:0.01258, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:11.255, tt:675.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01262, lr:6.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:11.258, tt:686.745\n",
      "Ep:61, loss:0.00001, loss_test:0.01264, lr:6.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:11.260, tt:698.140\n",
      "Ep:62, loss:0.00001, loss_test:0.01264, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:11.262, tt:709.507\n",
      "Ep:63, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:11.264, tt:720.905\n",
      "Ep:64, loss:0.00001, loss_test:0.01269, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:11.266, tt:732.273\n",
      "Ep:65, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:11.268, tt:743.667\n",
      "Ep:66, loss:0.00001, loss_test:0.01275, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:11.276, tt:755.460\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:11.283, tt:767.262\n",
      "Ep:68, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:11.284, tt:778.591\n",
      "Ep:69, loss:0.00001, loss_test:0.01284, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:11.316, tt:792.089\n",
      "Ep:70, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:11.344, tt:805.450\n",
      "Ep:71, loss:0.00001, loss_test:0.01292, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:11.376, tt:819.076\n",
      "Ep:72, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:11.449, tt:835.745\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01301, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:11.582, tt:857.081\n",
      "Ep:74, loss:0.00001, loss_test:0.01305, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:11.829, tt:887.201\n",
      "Ep:75, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:12.128, tt:921.736\n",
      "Ep:76, loss:0.00001, loss_test:0.01314, lr:6.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:12.468, tt:960.008\n",
      "Ep:77, loss:0.00001, loss_test:0.01321, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:12.831, tt:1000.838\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01325, lr:6.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:13.160, tt:1039.673\n",
      "Ep:79, loss:0.00001, loss_test:0.01330, lr:6.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:13.489, tt:1079.100\n",
      "Ep:80, loss:0.00001, loss_test:0.01336, lr:6.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:13.833, tt:1120.495\n",
      "Ep:81, loss:0.00001, loss_test:0.01341, lr:6.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:14.136, tt:1159.126\n",
      "Ep:82, loss:0.00001, loss_test:0.01348, lr:6.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:14.450, tt:1199.374\n",
      "Ep:83, loss:0.00001, loss_test:0.01357, lr:6.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:14.763, tt:1240.130\n",
      "Ep:84, loss:0.00001, loss_test:0.01360, lr:6.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:15.075, tt:1281.349\n",
      "Ep:85, loss:0.00001, loss_test:0.01364, lr:6.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:15.364, tt:1321.320\n",
      "Ep:86, loss:0.00001, loss_test:0.01372, lr:6.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:15.625, tt:1359.403\n",
      "Ep:87, loss:0.00001, loss_test:0.01380, lr:6.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:15.906, tt:1399.758\n",
      "Ep:88, loss:0.00001, loss_test:0.01384, lr:6.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:16.178, tt:1439.821\n",
      "Ep:89, loss:0.00001, loss_test:0.01389, lr:5.94e-02, fs:0.85263 (r=0.818,p=0.890),  time:16.439, tt:1479.533\n",
      "Ep:90, loss:0.00000, loss_test:0.01393, lr:5.88e-02, fs:0.85263 (r=0.818,p=0.890),  time:16.702, tt:1519.868\n",
      "Ep:91, loss:0.00000, loss_test:0.01400, lr:5.82e-02, fs:0.85263 (r=0.818,p=0.890),  time:16.950, tt:1559.440\n",
      "Ep:92, loss:0.00000, loss_test:0.01409, lr:5.76e-02, fs:0.85263 (r=0.818,p=0.890),  time:17.189, tt:1598.531\n",
      "Ep:93, loss:0.00000, loss_test:0.01415, lr:5.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:17.433, tt:1638.722\n",
      "Ep:94, loss:0.00000, loss_test:0.01419, lr:5.65e-02, fs:0.86170 (r=0.818,p=0.910),  time:17.656, tt:1677.274\n",
      "Ep:95, loss:0.00000, loss_test:0.01424, lr:5.59e-02, fs:0.86170 (r=0.818,p=0.910),  time:17.872, tt:1715.717\n",
      "Ep:96, loss:0.00000, loss_test:0.01430, lr:5.54e-02, fs:0.85561 (r=0.808,p=0.909),  time:18.086, tt:1754.389\n",
      "Ep:97, loss:0.00000, loss_test:0.01435, lr:5.48e-02, fs:0.85561 (r=0.808,p=0.909),  time:18.294, tt:1792.799\n",
      "Ep:98, loss:0.00000, loss_test:0.01442, lr:5.43e-02, fs:0.85561 (r=0.808,p=0.909),  time:18.510, tt:1832.507\n",
      "Ep:99, loss:0.00000, loss_test:0.01447, lr:5.37e-02, fs:0.85561 (r=0.808,p=0.909),  time:18.720, tt:1872.043\n",
      "Ep:100, loss:0.00000, loss_test:0.01450, lr:5.32e-02, fs:0.85561 (r=0.808,p=0.909),  time:18.912, tt:1910.134\n",
      "Ep:101, loss:0.00000, loss_test:0.01459, lr:5.27e-02, fs:0.85561 (r=0.808,p=0.909),  time:19.102, tt:1948.394\n",
      "Ep:102, loss:0.00000, loss_test:0.01466, lr:5.21e-02, fs:0.85405 (r=0.798,p=0.919),  time:19.314, tt:1989.385\n",
      "Ep:103, loss:0.00000, loss_test:0.01473, lr:5.16e-02, fs:0.85405 (r=0.798,p=0.919),  time:19.539, tt:2032.091\n",
      "Ep:104, loss:0.00000, loss_test:0.01477, lr:5.11e-02, fs:0.84783 (r=0.788,p=0.918),  time:19.754, tt:2074.199\n",
      "Ep:105, loss:0.00000, loss_test:0.01485, lr:5.06e-02, fs:0.84783 (r=0.788,p=0.918),  time:19.940, tt:2113.630\n",
      "Ep:106, loss:0.00000, loss_test:0.01491, lr:5.01e-02, fs:0.84153 (r=0.778,p=0.917),  time:20.120, tt:2152.820\n",
      "Ep:107, loss:0.00000, loss_test:0.01497, lr:4.96e-02, fs:0.84615 (r=0.778,p=0.928),  time:20.319, tt:2194.500\n",
      "Ep:108, loss:0.00000, loss_test:0.01505, lr:4.91e-02, fs:0.83978 (r=0.768,p=0.927),  time:20.514, tt:2236.055\n",
      "Ep:109, loss:0.00000, loss_test:0.01512, lr:4.86e-02, fs:0.83333 (r=0.758,p=0.926),  time:20.706, tt:2277.626\n",
      "Ep:110, loss:0.00000, loss_test:0.01516, lr:4.81e-02, fs:0.82682 (r=0.747,p=0.925),  time:20.893, tt:2319.097\n",
      "Ep:111, loss:0.00000, loss_test:0.01521, lr:4.76e-02, fs:0.81356 (r=0.727,p=0.923),  time:21.077, tt:2360.588\n",
      "Ep:112, loss:0.00000, loss_test:0.01528, lr:4.71e-02, fs:0.81356 (r=0.727,p=0.923),  time:21.255, tt:2401.806\n",
      "Ep:113, loss:0.00000, loss_test:0.01535, lr:4.67e-02, fs:0.80682 (r=0.717,p=0.922),  time:21.406, tt:2440.256\n",
      "Ep:114, loss:0.00000, loss_test:0.01539, lr:4.62e-02, fs:0.80000 (r=0.707,p=0.921),  time:21.582, tt:2481.910\n",
      "Ep:115, loss:0.00000, loss_test:0.01544, lr:4.57e-02, fs:0.78613 (r=0.687,p=0.919),  time:21.757, tt:2523.769\n",
      "Ep:116, loss:0.00000, loss_test:0.01549, lr:4.53e-02, fs:0.77193 (r=0.667,p=0.917),  time:21.920, tt:2564.632\n",
      "Ep:117, loss:0.00000, loss_test:0.01553, lr:4.48e-02, fs:0.76471 (r=0.657,p=0.915),  time:22.082, tt:2605.735\n",
      "Ep:118, loss:0.00000, loss_test:0.01560, lr:4.44e-02, fs:0.76471 (r=0.657,p=0.915),  time:22.233, tt:2645.745\n",
      "Ep:119, loss:0.00000, loss_test:0.01564, lr:4.39e-02, fs:0.75740 (r=0.646,p=0.914),  time:22.376, tt:2685.124\n",
      "Ep:120, loss:0.00000, loss_test:0.01567, lr:4.35e-02, fs:0.75740 (r=0.646,p=0.914),  time:22.513, tt:2724.039\n",
      "Ep:121, loss:0.00000, loss_test:0.01573, lr:4.31e-02, fs:0.75740 (r=0.646,p=0.914),  time:22.656, tt:2764.015\n",
      "Ep:122, loss:0.00000, loss_test:0.01580, lr:4.26e-02, fs:0.74251 (r=0.626,p=0.912),  time:22.812, tt:2805.884\n",
      "Ep:123, loss:0.00000, loss_test:0.01585, lr:4.22e-02, fs:0.74251 (r=0.626,p=0.912),  time:22.968, tt:2848.023\n",
      "Ep:124, loss:0.00000, loss_test:0.01587, lr:4.18e-02, fs:0.74251 (r=0.626,p=0.912),  time:23.117, tt:2889.678\n",
      "Ep:125, loss:0.00000, loss_test:0.01594, lr:4.14e-02, fs:0.74251 (r=0.626,p=0.912),  time:23.267, tt:2931.608\n",
      "Ep:126, loss:0.00000, loss_test:0.01599, lr:4.10e-02, fs:0.74251 (r=0.626,p=0.912),  time:23.397, tt:2971.435\n",
      "Ep:127, loss:0.00000, loss_test:0.01604, lr:4.05e-02, fs:0.74251 (r=0.626,p=0.912),  time:23.525, tt:3011.245\n",
      "Ep:128, loss:0.00000, loss_test:0.01608, lr:4.01e-02, fs:0.74251 (r=0.626,p=0.912),  time:23.657, tt:3051.709\n",
      "Ep:129, loss:0.00000, loss_test:0.01610, lr:3.97e-02, fs:0.73494 (r=0.616,p=0.910),  time:23.793, tt:3093.040\n",
      "Ep:130, loss:0.00000, loss_test:0.01616, lr:3.93e-02, fs:0.72727 (r=0.606,p=0.909),  time:23.929, tt:3134.659\n",
      "Ep:131, loss:0.00000, loss_test:0.01622, lr:3.89e-02, fs:0.71166 (r=0.586,p=0.906),  time:24.052, tt:3174.856\n",
      "Ep:132, loss:0.00000, loss_test:0.01625, lr:3.86e-02, fs:0.71166 (r=0.586,p=0.906),  time:24.193, tt:3217.717\n",
      "Ep:133, loss:0.00000, loss_test:0.01629, lr:3.82e-02, fs:0.71166 (r=0.586,p=0.906),  time:24.294, tt:3255.440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01633, lr:3.78e-02, fs:0.71166 (r=0.586,p=0.906),  time:24.425, tt:3297.402\n",
      "Ep:135, loss:0.00000, loss_test:0.01639, lr:3.74e-02, fs:0.71166 (r=0.586,p=0.906),  time:24.533, tt:3336.478\n",
      "Ep:136, loss:0.00000, loss_test:0.01644, lr:3.70e-02, fs:0.71166 (r=0.586,p=0.906),  time:24.643, tt:3376.066\n",
      "Ep:137, loss:0.00000, loss_test:0.01648, lr:3.67e-02, fs:0.70370 (r=0.576,p=0.905),  time:24.764, tt:3417.464\n",
      "Ep:138, loss:0.00000, loss_test:0.01651, lr:3.63e-02, fs:0.70370 (r=0.576,p=0.905),  time:24.877, tt:3457.864\n",
      "Ep:139, loss:0.00000, loss_test:0.01656, lr:3.59e-02, fs:0.70370 (r=0.576,p=0.905),  time:24.986, tt:3498.099\n",
      "Ep:140, loss:0.00000, loss_test:0.01660, lr:3.56e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.096, tt:3538.470\n",
      "Ep:141, loss:0.00000, loss_test:0.01664, lr:3.52e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.197, tt:3577.993\n",
      "Ep:142, loss:0.00000, loss_test:0.01667, lr:3.49e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.305, tt:3618.549\n",
      "Ep:143, loss:0.00000, loss_test:0.01671, lr:3.45e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.445, tt:3664.149\n",
      "Ep:144, loss:0.00000, loss_test:0.01676, lr:3.42e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.554, tt:3705.281\n",
      "Ep:145, loss:0.00000, loss_test:0.01680, lr:3.38e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.650, tt:3744.914\n",
      "Ep:146, loss:0.00000, loss_test:0.01684, lr:3.35e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.761, tt:3786.795\n",
      "Ep:147, loss:0.00000, loss_test:0.01688, lr:3.32e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.857, tt:3826.899\n",
      "Ep:148, loss:0.00000, loss_test:0.01692, lr:3.28e-02, fs:0.70370 (r=0.576,p=0.905),  time:25.965, tt:3868.832\n",
      "Ep:149, loss:0.00000, loss_test:0.01696, lr:3.25e-02, fs:0.68750 (r=0.556,p=0.902),  time:26.061, tt:3909.211\n",
      "Ep:150, loss:0.00000, loss_test:0.01700, lr:3.22e-02, fs:0.68750 (r=0.556,p=0.902),  time:26.160, tt:3950.178\n",
      "Ep:151, loss:0.00000, loss_test:0.01704, lr:3.19e-02, fs:0.68750 (r=0.556,p=0.902),  time:26.257, tt:3991.042\n",
      "Ep:152, loss:0.00000, loss_test:0.01708, lr:3.15e-02, fs:0.68750 (r=0.556,p=0.902),  time:26.352, tt:4031.912\n",
      "Ep:153, loss:0.00000, loss_test:0.01710, lr:3.12e-02, fs:0.68750 (r=0.556,p=0.902),  time:26.441, tt:4071.931\n",
      "Ep:154, loss:0.00000, loss_test:0.01714, lr:3.09e-02, fs:0.67925 (r=0.545,p=0.900),  time:26.534, tt:4112.725\n",
      "Ep:155, loss:0.00000, loss_test:0.01718, lr:3.06e-02, fs:0.67925 (r=0.545,p=0.900),  time:26.618, tt:4152.474\n",
      "Ep:156, loss:0.00000, loss_test:0.01721, lr:3.03e-02, fs:0.67925 (r=0.545,p=0.900),  time:26.700, tt:4191.856\n",
      "Ep:157, loss:0.00000, loss_test:0.01723, lr:3.00e-02, fs:0.67925 (r=0.545,p=0.900),  time:26.773, tt:4230.145\n",
      "Ep:158, loss:0.00000, loss_test:0.01727, lr:2.97e-02, fs:0.67925 (r=0.545,p=0.900),  time:26.859, tt:4270.613\n",
      "Ep:159, loss:0.00000, loss_test:0.01730, lr:2.94e-02, fs:0.67925 (r=0.545,p=0.900),  time:26.955, tt:4312.852\n",
      "Ep:160, loss:0.00000, loss_test:0.01733, lr:2.91e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.035, tt:4352.663\n",
      "Ep:161, loss:0.00000, loss_test:0.01736, lr:2.88e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.121, tt:4393.650\n",
      "Ep:162, loss:0.00000, loss_test:0.01740, lr:2.85e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.206, tt:4434.657\n",
      "Ep:163, loss:0.00000, loss_test:0.01743, lr:2.82e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.293, tt:4476.015\n",
      "Ep:164, loss:0.00000, loss_test:0.01745, lr:2.80e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.381, tt:4517.909\n",
      "Ep:165, loss:0.00000, loss_test:0.01749, lr:2.77e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.456, tt:4557.756\n",
      "Ep:166, loss:0.00000, loss_test:0.01752, lr:2.74e-02, fs:0.67925 (r=0.545,p=0.900),  time:27.535, tt:4598.320\n",
      "Ep:167, loss:0.00000, loss_test:0.01755, lr:2.71e-02, fs:0.67089 (r=0.535,p=0.898),  time:27.607, tt:4638.003\n",
      "Ep:168, loss:0.00000, loss_test:0.01759, lr:2.69e-02, fs:0.67089 (r=0.535,p=0.898),  time:27.700, tt:4681.379\n",
      "Ep:169, loss:0.00000, loss_test:0.01763, lr:2.66e-02, fs:0.67089 (r=0.535,p=0.898),  time:27.766, tt:4720.182\n",
      "Ep:170, loss:0.00000, loss_test:0.01766, lr:2.63e-02, fs:0.67089 (r=0.535,p=0.898),  time:27.833, tt:4759.366\n",
      "Ep:171, loss:0.00000, loss_test:0.01768, lr:2.61e-02, fs:0.67516 (r=0.535,p=0.914),  time:27.895, tt:4797.883\n",
      "Ep:172, loss:0.00000, loss_test:0.01770, lr:2.58e-02, fs:0.67516 (r=0.535,p=0.914),  time:27.958, tt:4836.778\n",
      "Ep:173, loss:0.00000, loss_test:0.01774, lr:2.55e-02, fs:0.67516 (r=0.535,p=0.914),  time:28.024, tt:4876.162\n",
      "Ep:174, loss:0.00000, loss_test:0.01776, lr:2.53e-02, fs:0.67516 (r=0.535,p=0.914),  time:28.095, tt:4916.549\n",
      "Ep:175, loss:0.00000, loss_test:0.01779, lr:2.50e-02, fs:0.67516 (r=0.535,p=0.914),  time:28.150, tt:4954.436\n",
      "Ep:176, loss:0.00000, loss_test:0.01782, lr:2.48e-02, fs:0.67516 (r=0.535,p=0.914),  time:28.210, tt:4993.219\n",
      "Ep:177, loss:0.00000, loss_test:0.01785, lr:2.45e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.281, tt:5034.099\n",
      "Ep:178, loss:0.00000, loss_test:0.01788, lr:2.43e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.353, tt:5075.274\n",
      "Ep:179, loss:0.00000, loss_test:0.01790, lr:2.40e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.414, tt:5114.609\n",
      "Ep:180, loss:0.00000, loss_test:0.01792, lr:2.38e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.478, tt:5154.463\n",
      "Ep:181, loss:0.00000, loss_test:0.01794, lr:2.36e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.544, tt:5194.947\n",
      "Ep:182, loss:0.00000, loss_test:0.01798, lr:2.33e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.613, tt:5236.249\n",
      "Ep:183, loss:0.00000, loss_test:0.01801, lr:2.31e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.666, tt:5274.509\n",
      "Ep:184, loss:0.00000, loss_test:0.01803, lr:2.29e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.719, tt:5313.055\n",
      "Ep:185, loss:0.00000, loss_test:0.01805, lr:2.26e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.798, tt:5356.511\n",
      "Ep:186, loss:0.00000, loss_test:0.01807, lr:2.24e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.849, tt:5394.843\n",
      "Ep:187, loss:0.00000, loss_test:0.01809, lr:2.22e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.905, tt:5434.199\n",
      "Ep:188, loss:0.00000, loss_test:0.01811, lr:2.20e-02, fs:0.67949 (r=0.535,p=0.930),  time:28.967, tt:5474.789\n",
      "Ep:189, loss:0.00000, loss_test:0.01814, lr:2.17e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.033, tt:5516.253\n",
      "Ep:190, loss:0.00000, loss_test:0.01817, lr:2.15e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.091, tt:5556.428\n",
      "Ep:191, loss:0.00000, loss_test:0.01819, lr:2.13e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.158, tt:5598.297\n",
      "Ep:192, loss:0.00000, loss_test:0.01821, lr:2.11e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.234, tt:5642.201\n",
      "Ep:193, loss:0.00000, loss_test:0.01823, lr:2.09e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.307, tt:5685.629\n",
      "Ep:194, loss:0.00000, loss_test:0.01826, lr:2.07e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.372, tt:5727.537\n",
      "Ep:195, loss:0.00000, loss_test:0.01827, lr:2.05e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.434, tt:5769.074\n",
      "Ep:196, loss:0.00000, loss_test:0.01830, lr:2.03e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.504, tt:5812.357\n",
      "Ep:197, loss:0.00000, loss_test:0.01831, lr:2.01e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.566, tt:5854.026\n",
      "Ep:198, loss:0.00000, loss_test:0.01834, lr:1.99e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.616, tt:5893.589\n",
      "Ep:199, loss:0.00000, loss_test:0.01836, lr:1.97e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.675, tt:5935.052\n",
      "Ep:200, loss:0.00000, loss_test:0.01837, lr:1.95e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.737, tt:5977.222\n",
      "Ep:201, loss:0.00000, loss_test:0.01839, lr:1.93e-02, fs:0.67949 (r=0.535,p=0.930),  time:29.791, tt:6017.689\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13821, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.275, tt:42.275\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13617, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.158, tt:82.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00027, loss_test:0.13270, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:40.571, tt:121.712\n",
      "Ep:3, loss:0.00026, loss_test:0.12721, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:40.394, tt:161.577\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11986, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:40.460, tt:202.299\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11460, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:40.773, tt:244.635\n",
      "Ep:6, loss:0.00023, loss_test:0.11255, lr:1.00e-02, fs:0.63636 (r=0.636,p=0.636),  time:40.962, tt:286.734\n",
      "Ep:7, loss:0.00022, loss_test:0.10968, lr:1.00e-02, fs:0.64000 (r=0.646,p=0.634),  time:41.128, tt:329.026\n",
      "Ep:8, loss:0.00022, loss_test:0.10693, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:41.110, tt:369.986\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10341, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:41.200, tt:412.004\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10058, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:41.161, tt:452.769\n",
      "Ep:11, loss:0.00019, loss_test:0.09804, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:41.260, tt:495.120\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09619, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:41.229, tt:535.981\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09424, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:41.317, tt:578.440\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.09203, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:41.305, tt:619.571\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08981, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:41.360, tt:661.767\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08791, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:41.401, tt:703.819\n",
      "Ep:17, loss:0.00014, loss_test:0.08545, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:41.365, tt:744.566\n",
      "Ep:18, loss:0.00014, loss_test:0.08350, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:41.343, tt:785.511\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.08181, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:41.336, tt:826.720\n",
      "Ep:20, loss:0.00012, loss_test:0.08062, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:41.309, tt:867.480\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07887, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:41.392, tt:910.623\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00011, loss_test:0.07694, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:41.449, tt:953.331\n",
      "Ep:23, loss:0.00010, loss_test:0.07603, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:41.396, tt:993.514\n",
      "Ep:24, loss:0.00010, loss_test:0.07466, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.441, tt:1036.037\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.07397, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:41.486, tt:1078.649\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.07348, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:41.488, tt:1120.177\n",
      "Ep:27, loss:0.00008, loss_test:0.07229, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:41.631, tt:1165.677\n",
      "Ep:28, loss:0.00008, loss_test:0.07075, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.615, tt:1206.828\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.07056, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:41.619, tt:1248.579\n",
      "Ep:30, loss:0.00007, loss_test:0.07091, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:41.652, tt:1291.203\n",
      "Ep:31, loss:0.00007, loss_test:0.06897, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:41.644, tt:1332.614\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.06917, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:41.624, tt:1373.605\n",
      "Ep:33, loss:0.00006, loss_test:0.06904, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.639, tt:1415.740\n",
      "Ep:34, loss:0.00006, loss_test:0.06720, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.612, tt:1456.431\n",
      "Ep:35, loss:0.00006, loss_test:0.06865, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:41.583, tt:1496.982\n",
      "Ep:36, loss:0.00005, loss_test:0.06795, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:41.528, tt:1536.554\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.06634, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.525, tt:1577.936\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.06965, lr:1.00e-02, fs:0.78363 (r=0.677,p=0.931),  time:41.512, tt:1618.967\n",
      "Ep:39, loss:0.00005, loss_test:0.06626, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.479, tt:1659.145\n",
      "Ep:40, loss:0.00004, loss_test:0.06655, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:41.458, tt:1699.760\n",
      "Ep:41, loss:0.00004, loss_test:0.06735, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:41.418, tt:1739.544\n",
      "Ep:42, loss:0.00004, loss_test:0.06502, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:41.389, tt:1779.739\n",
      "Ep:43, loss:0.00004, loss_test:0.06713, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:41.396, tt:1821.425\n",
      "Ep:44, loss:0.00004, loss_test:0.06590, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:41.403, tt:1863.140\n",
      "Ep:45, loss:0.00003, loss_test:0.06443, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:41.430, tt:1905.771\n",
      "Ep:46, loss:0.00003, loss_test:0.06661, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:41.423, tt:1946.872\n",
      "Ep:47, loss:0.00003, loss_test:0.06543, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:41.527, tt:1993.288\n",
      "Ep:48, loss:0.00003, loss_test:0.06517, lr:1.00e-02, fs:0.78363 (r=0.677,p=0.931),  time:41.545, tt:2035.684\n",
      "Ep:49, loss:0.00003, loss_test:0.06662, lr:9.90e-03, fs:0.80000 (r=0.707,p=0.921),  time:41.538, tt:2076.911\n",
      "Ep:50, loss:0.00003, loss_test:0.06688, lr:9.80e-03, fs:0.77381 (r=0.657,p=0.942),  time:41.516, tt:2117.298\n",
      "Ep:51, loss:0.00003, loss_test:0.06512, lr:9.70e-03, fs:0.79769 (r=0.697,p=0.932),  time:41.540, tt:2160.078\n",
      "Ep:52, loss:0.00003, loss_test:0.06605, lr:9.61e-03, fs:0.77647 (r=0.667,p=0.930),  time:41.563, tt:2202.849\n",
      "Ep:53, loss:0.00002, loss_test:0.06603, lr:9.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.558, tt:2244.117\n",
      "Ep:54, loss:0.00002, loss_test:0.06436, lr:9.41e-03, fs:0.79070 (r=0.687,p=0.932),  time:41.568, tt:2286.216\n",
      "Ep:55, loss:0.00002, loss_test:0.06607, lr:9.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.561, tt:2327.423\n",
      "Ep:56, loss:0.00002, loss_test:0.06724, lr:9.23e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.557, tt:2368.763\n",
      "Ep:57, loss:0.00002, loss_test:0.06473, lr:9.14e-03, fs:0.77647 (r=0.667,p=0.930),  time:41.553, tt:2410.070\n",
      "Ep:58, loss:0.00002, loss_test:0.06605, lr:9.04e-03, fs:0.77647 (r=0.667,p=0.930),  time:41.572, tt:2452.768\n",
      "Ep:59, loss:0.00002, loss_test:0.06839, lr:8.95e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.571, tt:2494.275\n",
      "Ep:60, loss:0.00002, loss_test:0.06625, lr:8.86e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.531, tt:2533.390\n",
      "Ep:61, loss:0.00002, loss_test:0.06539, lr:8.78e-03, fs:0.77647 (r=0.667,p=0.930),  time:41.533, tt:2575.033\n",
      "Ep:62, loss:0.00002, loss_test:0.06854, lr:8.69e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.528, tt:2616.251\n",
      "Ep:63, loss:0.00002, loss_test:0.06913, lr:8.60e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.506, tt:2656.359\n",
      "Ep:64, loss:0.00002, loss_test:0.06711, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.515, tt:2698.482\n",
      "Ep:65, loss:0.00002, loss_test:0.06686, lr:8.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.480, tt:2737.672\n",
      "Ep:66, loss:0.00002, loss_test:0.06908, lr:8.35e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.485, tt:2779.479\n",
      "Ep:67, loss:0.00001, loss_test:0.06985, lr:8.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.492, tt:2821.466\n",
      "Ep:68, loss:0.00001, loss_test:0.06747, lr:8.18e-03, fs:0.76923 (r=0.657,p=0.929),  time:41.490, tt:2862.788\n",
      "Ep:69, loss:0.00001, loss_test:0.06834, lr:8.10e-03, fs:0.75449 (r=0.636,p=0.926),  time:41.452, tt:2901.614\n",
      "Ep:70, loss:0.00001, loss_test:0.07028, lr:8.02e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.360, tt:2936.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.07012, lr:7.94e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.229, tt:2968.458\n",
      "Ep:72, loss:0.00001, loss_test:0.06868, lr:7.86e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.124, tt:3002.033\n",
      "Ep:73, loss:0.00001, loss_test:0.06937, lr:7.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.089, tt:3040.614\n",
      "Ep:74, loss:0.00001, loss_test:0.07085, lr:7.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.091, tt:3081.846\n",
      "Ep:75, loss:0.00001, loss_test:0.07053, lr:7.62e-03, fs:0.73171 (r=0.606,p=0.923),  time:41.099, tt:3123.533\n",
      "Ep:76, loss:0.00001, loss_test:0.06972, lr:7.55e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.098, tt:3164.520\n",
      "Ep:77, loss:0.00001, loss_test:0.07045, lr:7.47e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.100, tt:3205.823\n",
      "Ep:78, loss:0.00001, loss_test:0.07094, lr:7.40e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.067, tt:3244.278\n",
      "Ep:79, loss:0.00001, loss_test:0.07058, lr:7.32e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.067, tt:3285.355\n",
      "Ep:80, loss:0.00001, loss_test:0.07060, lr:7.25e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.049, tt:3324.993\n",
      "Ep:81, loss:0.00001, loss_test:0.07103, lr:7.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.037, tt:3365.068\n",
      "Ep:82, loss:0.00001, loss_test:0.07136, lr:7.11e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.036, tt:3405.982\n",
      "Ep:83, loss:0.00001, loss_test:0.07055, lr:7.03e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.044, tt:3447.717\n",
      "Ep:84, loss:0.00001, loss_test:0.07034, lr:6.96e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.053, tt:3489.545\n",
      "Ep:85, loss:0.00001, loss_test:0.07135, lr:6.89e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.075, tt:3532.452\n",
      "Ep:86, loss:0.00001, loss_test:0.07108, lr:6.83e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.069, tt:3573.039\n",
      "Ep:87, loss:0.00001, loss_test:0.07112, lr:6.76e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.081, tt:3615.116\n",
      "Ep:88, loss:0.00001, loss_test:0.07139, lr:6.69e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.154, tt:3662.687\n",
      "Ep:89, loss:0.00001, loss_test:0.07205, lr:6.62e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.153, tt:3703.732\n",
      "Ep:90, loss:0.00001, loss_test:0.07114, lr:6.56e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.144, tt:3744.078\n",
      "Ep:91, loss:0.00001, loss_test:0.07114, lr:6.49e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.143, tt:3785.201\n",
      "Ep:92, loss:0.00001, loss_test:0.07181, lr:6.43e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.161, tt:3828.012\n",
      "Ep:93, loss:0.00001, loss_test:0.07169, lr:6.36e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.168, tt:3869.800\n",
      "Ep:94, loss:0.00001, loss_test:0.07096, lr:6.30e-03, fs:0.72500 (r=0.586,p=0.951),  time:41.184, tt:3912.473\n",
      "Ep:95, loss:0.00001, loss_test:0.07223, lr:6.24e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.184, tt:3953.708\n",
      "Ep:96, loss:0.00001, loss_test:0.07295, lr:6.17e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.195, tt:3995.874\n",
      "Ep:97, loss:0.00001, loss_test:0.07216, lr:6.11e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.203, tt:4037.845\n",
      "Ep:98, loss:0.00001, loss_test:0.07140, lr:6.05e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.223, tt:4081.109\n",
      "Ep:99, loss:0.00001, loss_test:0.07198, lr:5.99e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.204, tt:4120.405\n",
      "Ep:100, loss:0.00001, loss_test:0.07241, lr:5.93e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.221, tt:4163.353\n",
      "Ep:101, loss:0.00001, loss_test:0.07168, lr:5.87e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.235, tt:4205.927\n",
      "Ep:102, loss:0.00001, loss_test:0.07210, lr:5.81e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.235, tt:4247.234\n",
      "Ep:103, loss:0.00001, loss_test:0.07265, lr:5.75e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.235, tt:4288.477\n",
      "Ep:104, loss:0.00001, loss_test:0.07290, lr:5.70e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.225, tt:4328.634\n",
      "Ep:105, loss:0.00001, loss_test:0.07224, lr:5.64e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.259, tt:4373.487\n",
      "Ep:106, loss:0.00001, loss_test:0.07198, lr:5.58e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.285, tt:4417.526\n",
      "Ep:107, loss:0.00001, loss_test:0.07285, lr:5.53e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.295, tt:4459.851\n",
      "Ep:108, loss:0.00001, loss_test:0.07316, lr:5.47e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.304, tt:4502.150\n",
      "Ep:109, loss:0.00001, loss_test:0.07249, lr:5.42e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.321, tt:4545.310\n",
      "Ep:110, loss:0.00001, loss_test:0.07234, lr:5.36e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.319, tt:4586.449\n",
      "Ep:111, loss:0.00001, loss_test:0.07310, lr:5.31e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.323, tt:4628.159\n",
      "Ep:112, loss:0.00001, loss_test:0.07323, lr:5.26e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.320, tt:4669.131\n",
      "Ep:113, loss:0.00001, loss_test:0.07249, lr:5.20e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.318, tt:4710.259\n",
      "Ep:114, loss:0.00001, loss_test:0.07308, lr:5.15e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.320, tt:4751.785\n",
      "Ep:115, loss:0.00001, loss_test:0.07374, lr:5.10e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.332, tt:4794.560\n",
      "Ep:116, loss:0.00001, loss_test:0.07309, lr:5.05e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.330, tt:4835.596\n",
      "Ep:117, loss:0.00001, loss_test:0.07231, lr:5.00e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.332, tt:4877.118\n",
      "Ep:118, loss:0.00001, loss_test:0.07296, lr:4.95e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.312, tt:4916.156\n",
      "Ep:119, loss:0.00000, loss_test:0.07309, lr:4.90e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.293, tt:4955.107\n",
      "Ep:120, loss:0.00000, loss_test:0.07275, lr:4.85e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.302, tt:4997.518\n",
      "Ep:121, loss:0.00000, loss_test:0.07224, lr:4.80e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.320, tt:5041.016\n",
      "Ep:122, loss:0.00000, loss_test:0.07304, lr:4.75e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.332, tt:5083.819\n",
      "Ep:123, loss:0.00000, loss_test:0.07339, lr:4.71e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.337, tt:5125.731\n",
      "Ep:124, loss:0.00000, loss_test:0.07343, lr:4.66e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.345, tt:5168.173\n",
      "Ep:125, loss:0.00000, loss_test:0.07270, lr:4.61e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.334, tt:5208.044\n",
      "Ep:126, loss:0.00000, loss_test:0.07263, lr:4.57e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.347, tt:5251.035\n",
      "Ep:127, loss:0.00000, loss_test:0.07294, lr:4.52e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.352, tt:5293.064\n",
      "Ep:128, loss:0.00000, loss_test:0.07342, lr:4.48e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.347, tt:5333.778\n",
      "Ep:129, loss:0.00000, loss_test:0.07280, lr:4.43e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.355, tt:5376.190\n",
      "Ep:130, loss:0.00000, loss_test:0.07307, lr:4.39e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.359, tt:5418.023\n",
      "Ep:131, loss:0.00000, loss_test:0.07349, lr:4.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.370, tt:5460.862\n",
      "Ep:132, loss:0.00000, loss_test:0.07326, lr:4.30e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.369, tt:5502.014\n",
      "Ep:133, loss:0.00000, loss_test:0.07293, lr:4.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.380, tt:5544.861\n",
      "Ep:134, loss:0.00000, loss_test:0.07305, lr:4.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.367, tt:5584.580\n",
      "Ep:135, loss:0.00000, loss_test:0.07389, lr:4.17e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.375, tt:5626.975\n",
      "Ep:136, loss:0.00000, loss_test:0.07399, lr:4.13e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.374, tt:5668.248\n",
      "Ep:137, loss:0.00000, loss_test:0.07327, lr:4.09e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.408, tt:5714.287\n",
      "Ep:138, loss:0.00000, loss_test:0.07354, lr:4.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.414, tt:5756.519\n",
      "Ep:139, loss:0.00000, loss_test:0.07385, lr:4.01e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.411, tt:5797.486\n",
      "Ep:140, loss:0.00000, loss_test:0.07350, lr:3.97e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.416, tt:5839.613\n",
      "Ep:141, loss:0.00000, loss_test:0.07337, lr:3.93e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.419, tt:5881.525\n",
      "Ep:142, loss:0.00000, loss_test:0.07395, lr:3.89e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.413, tt:5921.987\n",
      "Ep:143, loss:0.00000, loss_test:0.07413, lr:3.85e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.425, tt:5965.199\n",
      "Ep:144, loss:0.00000, loss_test:0.07377, lr:3.81e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.435, tt:6008.062\n",
      "Ep:145, loss:0.00000, loss_test:0.07345, lr:3.77e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.436, tt:6049.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.07387, lr:3.73e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.433, tt:6090.659\n",
      "Ep:147, loss:0.00000, loss_test:0.07389, lr:3.70e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.436, tt:6132.559\n",
      "Ep:148, loss:0.00000, loss_test:0.07397, lr:3.66e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.447, tt:6175.578\n",
      "Ep:149, loss:0.00000, loss_test:0.07387, lr:3.62e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.453, tt:6217.889\n",
      "Ep:150, loss:0.00000, loss_test:0.07380, lr:3.59e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.454, tt:6259.536\n",
      "Ep:151, loss:0.00000, loss_test:0.07398, lr:3.55e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.464, tt:6302.511\n",
      "Ep:152, loss:0.00000, loss_test:0.07420, lr:3.52e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.471, tt:6345.018\n",
      "Ep:153, loss:0.00000, loss_test:0.07411, lr:3.48e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.476, tt:6387.254\n",
      "Ep:154, loss:0.00000, loss_test:0.07366, lr:3.45e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.473, tt:6428.257\n",
      "Ep:155, loss:0.00000, loss_test:0.07386, lr:3.41e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.485, tt:6471.700\n",
      "Ep:156, loss:0.00000, loss_test:0.07399, lr:3.38e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.492, tt:6514.267\n",
      "Ep:157, loss:0.00000, loss_test:0.07389, lr:3.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.540, tt:6563.273\n",
      "Ep:158, loss:0.00000, loss_test:0.07380, lr:3.31e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.564, tt:6608.627\n",
      "Ep:159, loss:0.00000, loss_test:0.07426, lr:3.28e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.575, tt:6652.060\n",
      "Ep:160, loss:0.00000, loss_test:0.07452, lr:3.24e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.597, tt:6697.106\n",
      "Ep:161, loss:0.00000, loss_test:0.07425, lr:3.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.615, tt:6741.604\n",
      "Ep:162, loss:0.00000, loss_test:0.07384, lr:3.18e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.628, tt:6785.397\n",
      "Ep:163, loss:0.00000, loss_test:0.07398, lr:3.15e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.649, tt:6830.401\n",
      "Ep:164, loss:0.00000, loss_test:0.07438, lr:3.12e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.655, tt:6873.016\n",
      "Ep:165, loss:0.00000, loss_test:0.07452, lr:3.09e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.662, tt:6915.935\n",
      "Ep:166, loss:0.00000, loss_test:0.07448, lr:3.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.684, tt:6961.273\n",
      "Ep:167, loss:0.00000, loss_test:0.07410, lr:3.02e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.699, tt:7005.436\n",
      "Ep:168, loss:0.00000, loss_test:0.07392, lr:2.99e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.706, tt:7048.335\n",
      "Ep:169, loss:0.00000, loss_test:0.07414, lr:2.96e-03, fs:0.68387 (r=0.535,p=0.946),  time:41.706, tt:7090.046\n",
      "Ep:170, loss:0.00000, loss_test:0.07430, lr:2.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.711, tt:7132.664\n",
      "Ep:171, loss:0.00000, loss_test:0.07415, lr:2.90e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.707, tt:7173.687\n",
      "Ep:172, loss:0.00000, loss_test:0.07390, lr:2.88e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.701, tt:7214.339\n",
      "Ep:173, loss:0.00000, loss_test:0.07436, lr:2.85e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.703, tt:7256.349\n",
      "Ep:174, loss:0.00000, loss_test:0.07443, lr:2.82e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.693, tt:7296.272\n",
      "Ep:175, loss:0.00000, loss_test:0.07432, lr:2.79e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.700, tt:7339.202\n",
      "Ep:176, loss:0.00000, loss_test:0.07430, lr:2.76e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.708, tt:7382.368\n",
      "Ep:177, loss:0.00000, loss_test:0.07409, lr:2.73e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.725, tt:7427.128\n",
      "Ep:178, loss:0.00000, loss_test:0.07425, lr:2.71e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.732, tt:7470.030\n",
      "Ep:179, loss:0.00000, loss_test:0.07448, lr:2.68e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.745, tt:7514.177\n",
      "Ep:180, loss:0.00000, loss_test:0.07452, lr:2.65e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.756, tt:7557.757\n",
      "Ep:181, loss:0.00000, loss_test:0.07413, lr:2.63e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.763, tt:7600.866\n",
      "Ep:182, loss:0.00000, loss_test:0.07395, lr:2.60e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.777, tt:7645.130\n",
      "Ep:183, loss:0.00000, loss_test:0.07404, lr:2.57e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.790, tt:7689.346\n",
      "Ep:184, loss:0.00000, loss_test:0.07437, lr:2.55e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.800, tt:7732.927\n",
      "Ep:185, loss:0.00000, loss_test:0.07449, lr:2.52e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.810, tt:7776.664\n",
      "Ep:186, loss:0.00000, loss_test:0.07426, lr:2.50e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.801, tt:7816.826\n",
      "Ep:187, loss:0.00000, loss_test:0.07405, lr:2.47e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.805, tt:7859.257\n",
      "Ep:188, loss:0.00000, loss_test:0.07420, lr:2.45e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.809, tt:7901.957\n",
      "Ep:189, loss:0.00000, loss_test:0.07436, lr:2.42e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.822, tt:7946.261\n",
      "Ep:190, loss:0.00000, loss_test:0.07434, lr:2.40e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.834, tt:7990.331\n",
      "Ep:191, loss:0.00000, loss_test:0.07416, lr:2.38e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.856, tt:8036.317\n",
      "Ep:192, loss:0.00000, loss_test:0.07426, lr:2.35e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.859, tt:8078.749\n",
      "Ep:193, loss:0.00000, loss_test:0.07433, lr:2.33e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.866, tt:8121.916\n",
      "Ep:194, loss:0.00000, loss_test:0.07435, lr:2.31e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.884, tt:8167.472\n",
      "Ep:195, loss:0.00000, loss_test:0.07420, lr:2.28e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.884, tt:8209.216\n",
      "Ep:196, loss:0.00000, loss_test:0.07429, lr:2.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.919, tt:8258.091\n",
      "Ep:197, loss:0.00000, loss_test:0.07440, lr:2.24e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.925, tt:8301.141\n",
      "Ep:198, loss:0.00000, loss_test:0.07424, lr:2.21e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.929, tt:8343.943\n",
      "Ep:199, loss:0.00000, loss_test:0.07408, lr:2.19e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.945, tt:8389.059\n",
      "Ep:200, loss:0.00000, loss_test:0.07415, lr:2.17e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.949, tt:8431.835\n",
      "Ep:201, loss:0.00000, loss_test:0.07445, lr:2.15e-03, fs:0.68831 (r=0.535,p=0.964),  time:41.954, tt:8474.613\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02062, lr:6.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:34.295, tt:34.295\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02465, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.640, tt:69.281\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02639, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.628, tt:103.884\n",
      "Ep:3, loss:0.00005, loss_test:0.02617, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.293, tt:137.172\n",
      "Ep:4, loss:0.00005, loss_test:0.02500, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.186, tt:170.931\n",
      "Ep:5, loss:0.00005, loss_test:0.02332, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.150, tt:204.898\n",
      "Ep:6, loss:0.00004, loss_test:0.02134, lr:6.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:34.112, tt:238.783\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:33.976, tt:271.808\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01940, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:33.920, tt:305.278\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01937, lr:6.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:34.045, tt:340.454\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00004, loss_test:0.01891, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:34.131, tt:375.438\n",
      "Ep:11, loss:0.00004, loss_test:0.01835, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:34.299, tt:411.586\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01813, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:34.183, tt:444.376\n",
      "Ep:13, loss:0.00004, loss_test:0.01801, lr:6.00e-02, fs:0.71852 (r=0.980,p=0.567),  time:34.242, tt:479.387\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01771, lr:6.00e-02, fs:0.72119 (r=0.980,p=0.571),  time:34.174, tt:512.611\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01738, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:34.232, tt:547.708\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01721, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:34.178, tt:581.018\n",
      "Ep:17, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:34.213, tt:615.841\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:34.160, tt:649.049\n",
      "Ep:19, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:34.101, tt:682.024\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:34.082, tt:715.728\n",
      "Ep:21, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:34.085, tt:749.864\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:34.067, tt:783.539\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:34.134, tt:819.213\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.76793 (r=0.919,p=0.659),  time:34.140, tt:853.509\n",
      "Ep:25, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:34.191, tt:888.964\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01523, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:34.152, tt:922.112\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01501, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.204, tt:957.713\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.252, tt:993.297\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01470, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:34.285, tt:1028.541\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:34.242, tt:1061.494\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:34.207, tt:1094.627\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.243, tt:1130.011\n",
      "Ep:33, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:34.226, tt:1163.670\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.303, tt:1200.616\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.297, tt:1234.696\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01393, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:34.331, tt:1270.235\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:34.299, tt:1303.358\n",
      "Ep:38, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:34.324, tt:1338.649\n",
      "Ep:39, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:34.352, tt:1374.068\n",
      "Ep:40, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.333, tt:1407.639\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.306, tt:1440.867\n",
      "Ep:42, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.290, tt:1474.482\n",
      "Ep:43, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:34.304, tt:1509.393\n",
      "Ep:44, loss:0.00002, loss_test:0.01343, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.302, tt:1543.576\n",
      "Ep:45, loss:0.00002, loss_test:0.01335, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.298, tt:1577.688\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.267, tt:1610.546\n",
      "Ep:47, loss:0.00002, loss_test:0.01331, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.278, tt:1645.345\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01333, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.275, tt:1679.481\n",
      "Ep:49, loss:0.00001, loss_test:0.01331, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.280, tt:1713.988\n",
      "Ep:50, loss:0.00001, loss_test:0.01335, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.254, tt:1746.930\n",
      "Ep:51, loss:0.00001, loss_test:0.01336, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.251, tt:1781.077\n",
      "Ep:52, loss:0.00001, loss_test:0.01333, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.230, tt:1814.200\n",
      "Ep:53, loss:0.00001, loss_test:0.01335, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.236, tt:1848.729\n",
      "Ep:54, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.229, tt:1882.573\n",
      "Ep:55, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.222, tt:1916.448\n",
      "Ep:56, loss:0.00001, loss_test:0.01340, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.216, tt:1950.306\n",
      "Ep:57, loss:0.00001, loss_test:0.01342, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.211, tt:1984.218\n",
      "Ep:58, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.172, tt:2016.125\n",
      "Ep:59, loss:0.00001, loss_test:0.01351, lr:5.94e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.239, tt:2054.325\n",
      "Ep:60, loss:0.00001, loss_test:0.01358, lr:5.88e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.263, tt:2090.058\n",
      "Ep:61, loss:0.00001, loss_test:0.01356, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.276, tt:2125.121\n",
      "Ep:62, loss:0.00001, loss_test:0.01355, lr:5.76e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.288, tt:2160.127\n",
      "Ep:63, loss:0.00001, loss_test:0.01362, lr:5.71e-02, fs:0.80597 (r=0.818,p=0.794),  time:34.304, tt:2195.483\n",
      "Ep:64, loss:0.00001, loss_test:0.01373, lr:5.65e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.310, tt:2230.183\n",
      "Ep:65, loss:0.00001, loss_test:0.01375, lr:5.59e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.332, tt:2265.898\n",
      "Ep:66, loss:0.00001, loss_test:0.01378, lr:5.54e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.357, tt:2301.897\n",
      "Ep:67, loss:0.00001, loss_test:0.01388, lr:5.48e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.363, tt:2336.681\n",
      "Ep:68, loss:0.00001, loss_test:0.01394, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.369, tt:2371.451\n",
      "Ep:69, loss:0.00001, loss_test:0.01402, lr:5.37e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.366, tt:2405.621\n",
      "Ep:70, loss:0.00001, loss_test:0.01400, lr:5.32e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.378, tt:2440.816\n",
      "Ep:71, loss:0.00001, loss_test:0.01409, lr:5.27e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.400, tt:2476.766\n",
      "Ep:72, loss:0.00001, loss_test:0.01417, lr:5.21e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.403, tt:2511.413\n",
      "Ep:73, loss:0.00001, loss_test:0.01425, lr:5.16e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.418, tt:2546.930\n",
      "Ep:74, loss:0.00001, loss_test:0.01429, lr:5.11e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.428, tt:2582.132\n",
      "Ep:75, loss:0.00001, loss_test:0.01435, lr:5.06e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.455, tt:2618.551\n",
      "Ep:76, loss:0.00001, loss_test:0.01444, lr:5.01e-02, fs:0.75132 (r=0.717,p=0.789),  time:34.477, tt:2654.762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00001, loss_test:0.01450, lr:4.96e-02, fs:0.74866 (r=0.707,p=0.795),  time:34.479, tt:2689.354\n",
      "Ep:78, loss:0.00001, loss_test:0.01454, lr:4.91e-02, fs:0.74595 (r=0.697,p=0.802),  time:34.470, tt:2723.149\n",
      "Ep:79, loss:0.00001, loss_test:0.01462, lr:4.86e-02, fs:0.73913 (r=0.687,p=0.800),  time:34.492, tt:2759.365\n",
      "Ep:80, loss:0.00001, loss_test:0.01470, lr:4.81e-02, fs:0.72527 (r=0.667,p=0.795),  time:34.482, tt:2793.067\n",
      "Ep:81, loss:0.00001, loss_test:0.01475, lr:4.76e-02, fs:0.72527 (r=0.667,p=0.795),  time:34.479, tt:2827.308\n",
      "Ep:82, loss:0.00001, loss_test:0.01489, lr:4.71e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.485, tt:2862.259\n",
      "Ep:83, loss:0.00001, loss_test:0.01490, lr:4.67e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.492, tt:2897.370\n",
      "Ep:84, loss:0.00001, loss_test:0.01495, lr:4.62e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.453, tt:2928.465\n",
      "Ep:85, loss:0.00001, loss_test:0.01507, lr:4.57e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.388, tt:2957.339\n",
      "Ep:86, loss:0.00001, loss_test:0.01513, lr:4.53e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.273, tt:2981.770\n",
      "Ep:87, loss:0.00001, loss_test:0.01522, lr:4.48e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.138, tt:3004.157\n",
      "Ep:88, loss:0.00001, loss_test:0.01527, lr:4.44e-02, fs:0.72727 (r=0.646,p=0.831),  time:33.987, tt:3024.864\n",
      "Ep:89, loss:0.00001, loss_test:0.01538, lr:4.39e-02, fs:0.72727 (r=0.646,p=0.831),  time:33.874, tt:3048.631\n",
      "Ep:90, loss:0.00001, loss_test:0.01545, lr:4.35e-02, fs:0.72727 (r=0.646,p=0.831),  time:33.843, tt:3079.670\n",
      "Ep:91, loss:0.00001, loss_test:0.01549, lr:4.31e-02, fs:0.72727 (r=0.646,p=0.831),  time:33.800, tt:3109.609\n",
      "Ep:92, loss:0.00001, loss_test:0.01559, lr:4.26e-02, fs:0.71264 (r=0.626,p=0.827),  time:33.822, tt:3145.411\n",
      "Ep:93, loss:0.00001, loss_test:0.01566, lr:4.22e-02, fs:0.71264 (r=0.626,p=0.827),  time:33.838, tt:3180.778\n",
      "Ep:94, loss:0.00001, loss_test:0.01573, lr:4.18e-02, fs:0.71264 (r=0.626,p=0.827),  time:33.842, tt:3214.990\n",
      "Ep:95, loss:0.00001, loss_test:0.01582, lr:4.14e-02, fs:0.71264 (r=0.626,p=0.827),  time:33.845, tt:3249.099\n",
      "Ep:96, loss:0.00001, loss_test:0.01588, lr:4.10e-02, fs:0.71264 (r=0.626,p=0.827),  time:33.860, tt:3284.408\n",
      "Ep:97, loss:0.00001, loss_test:0.01592, lr:4.05e-02, fs:0.71264 (r=0.626,p=0.827),  time:33.855, tt:3317.823\n",
      "Ep:98, loss:0.00001, loss_test:0.01605, lr:4.01e-02, fs:0.71676 (r=0.626,p=0.838),  time:33.852, tt:3351.299\n",
      "Ep:99, loss:0.00001, loss_test:0.01614, lr:3.97e-02, fs:0.71676 (r=0.626,p=0.838),  time:33.859, tt:3385.902\n",
      "Ep:100, loss:0.00001, loss_test:0.01619, lr:3.93e-02, fs:0.71676 (r=0.626,p=0.838),  time:33.864, tt:3420.299\n",
      "Ep:101, loss:0.00001, loss_test:0.01628, lr:3.89e-02, fs:0.72093 (r=0.626,p=0.849),  time:33.873, tt:3455.042\n",
      "Ep:102, loss:0.00001, loss_test:0.01633, lr:3.86e-02, fs:0.72093 (r=0.626,p=0.849),  time:33.888, tt:3490.501\n",
      "Ep:103, loss:0.00001, loss_test:0.01639, lr:3.82e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.900, tt:3525.615\n",
      "Ep:104, loss:0.00001, loss_test:0.01649, lr:3.78e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.889, tt:3558.298\n",
      "Ep:105, loss:0.00001, loss_test:0.01656, lr:3.74e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.890, tt:3592.324\n",
      "Ep:106, loss:0.00001, loss_test:0.01662, lr:3.70e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.861, tt:3623.167\n",
      "Ep:107, loss:0.00001, loss_test:0.01664, lr:3.67e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.858, tt:3656.636\n",
      "Ep:108, loss:0.00001, loss_test:0.01670, lr:3.63e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.862, tt:3690.931\n",
      "Ep:109, loss:0.00001, loss_test:0.01677, lr:3.59e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.850, tt:3723.524\n",
      "Ep:110, loss:0.00001, loss_test:0.01688, lr:3.56e-02, fs:0.72515 (r=0.626,p=0.861),  time:33.877, tt:3760.399\n",
      "Ep:111, loss:0.00001, loss_test:0.01694, lr:3.52e-02, fs:0.72941 (r=0.626,p=0.873),  time:33.872, tt:3793.709\n",
      "Ep:112, loss:0.00001, loss_test:0.01697, lr:3.49e-02, fs:0.72941 (r=0.626,p=0.873),  time:33.888, tt:3829.311\n",
      "Ep:113, loss:0.00001, loss_test:0.01702, lr:3.45e-02, fs:0.72941 (r=0.626,p=0.873),  time:33.881, tt:3862.443\n",
      "Ep:114, loss:0.00001, loss_test:0.01714, lr:3.42e-02, fs:0.72941 (r=0.626,p=0.873),  time:33.904, tt:3898.935\n",
      "Ep:115, loss:0.00001, loss_test:0.01718, lr:3.38e-02, fs:0.72941 (r=0.626,p=0.873),  time:33.913, tt:3933.900\n",
      "Ep:116, loss:0.00001, loss_test:0.01718, lr:3.35e-02, fs:0.72941 (r=0.626,p=0.873),  time:33.922, tt:3968.872\n",
      "Ep:117, loss:0.00001, loss_test:0.01731, lr:3.32e-02, fs:0.72619 (r=0.616,p=0.884),  time:33.929, tt:4003.579\n",
      "Ep:118, loss:0.00001, loss_test:0.01741, lr:3.28e-02, fs:0.72619 (r=0.616,p=0.884),  time:33.938, tt:4038.579\n",
      "Ep:119, loss:0.00001, loss_test:0.01742, lr:3.25e-02, fs:0.72619 (r=0.616,p=0.884),  time:33.941, tt:4072.927\n",
      "Ep:120, loss:0.00001, loss_test:0.01749, lr:3.22e-02, fs:0.72619 (r=0.616,p=0.884),  time:33.954, tt:4108.393\n",
      "Ep:121, loss:0.00000, loss_test:0.01757, lr:3.19e-02, fs:0.73054 (r=0.616,p=0.897),  time:33.962, tt:4143.384\n",
      "Ep:122, loss:0.00000, loss_test:0.01762, lr:3.15e-02, fs:0.72619 (r=0.616,p=0.884),  time:33.972, tt:4178.603\n",
      "Ep:123, loss:0.00000, loss_test:0.01765, lr:3.12e-02, fs:0.72619 (r=0.616,p=0.884),  time:33.985, tt:4214.106\n",
      "Ep:124, loss:0.00000, loss_test:0.01770, lr:3.09e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.008, tt:4251.049\n",
      "Ep:125, loss:0.00000, loss_test:0.01779, lr:3.06e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.020, tt:4286.578\n",
      "Ep:126, loss:0.00000, loss_test:0.01781, lr:3.03e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.018, tt:4320.245\n",
      "Ep:127, loss:0.00000, loss_test:0.01786, lr:3.00e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.027, tt:4355.511\n",
      "Ep:128, loss:0.00000, loss_test:0.01795, lr:2.97e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.039, tt:4390.982\n",
      "Ep:129, loss:0.00000, loss_test:0.01802, lr:2.94e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.060, tt:4427.737\n",
      "Ep:130, loss:0.00000, loss_test:0.01802, lr:2.91e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.063, tt:4462.268\n",
      "Ep:131, loss:0.00000, loss_test:0.01811, lr:2.88e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.073, tt:4497.644\n",
      "Ep:132, loss:0.00000, loss_test:0.01819, lr:2.85e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.067, tt:4530.927\n",
      "Ep:133, loss:0.00000, loss_test:0.01821, lr:2.82e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.071, tt:4565.500\n",
      "Ep:134, loss:0.00000, loss_test:0.01824, lr:2.80e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.079, tt:4600.608\n",
      "Ep:135, loss:0.00000, loss_test:0.01830, lr:2.77e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.091, tt:4636.405\n",
      "Ep:136, loss:0.00000, loss_test:0.01836, lr:2.74e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.094, tt:4670.940\n",
      "Ep:137, loss:0.00000, loss_test:0.01838, lr:2.71e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.105, tt:4706.475\n",
      "Ep:138, loss:0.00000, loss_test:0.01845, lr:2.69e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.111, tt:4741.390\n",
      "Ep:139, loss:0.00000, loss_test:0.01851, lr:2.66e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.117, tt:4776.363\n",
      "Ep:140, loss:0.00000, loss_test:0.01854, lr:2.63e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.113, tt:4810.002\n",
      "Ep:141, loss:0.00000, loss_test:0.01860, lr:2.61e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.117, tt:4844.626\n",
      "Ep:142, loss:0.00000, loss_test:0.01867, lr:2.58e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.130, tt:4880.630\n",
      "Ep:143, loss:0.00000, loss_test:0.01870, lr:2.55e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.125, tt:4914.052\n",
      "Ep:144, loss:0.00000, loss_test:0.01875, lr:2.53e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.132, tt:4949.103\n",
      "Ep:145, loss:0.00000, loss_test:0.01883, lr:2.50e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.125, tt:4982.258\n",
      "Ep:146, loss:0.00000, loss_test:0.01886, lr:2.48e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.119, tt:5015.456\n",
      "Ep:147, loss:0.00000, loss_test:0.01888, lr:2.45e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.111, tt:5048.499\n",
      "Ep:148, loss:0.00000, loss_test:0.01895, lr:2.43e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.108, tt:5082.153\n",
      "Ep:149, loss:0.00000, loss_test:0.01898, lr:2.40e-02, fs:0.70732 (r=0.586,p=0.892),  time:34.108, tt:5116.225\n",
      "Ep:150, loss:0.00000, loss_test:0.01901, lr:2.38e-02, fs:0.70732 (r=0.586,p=0.892),  time:34.113, tt:5151.060\n",
      "Ep:151, loss:0.00000, loss_test:0.01906, lr:2.36e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.108, tt:5184.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.01908, lr:2.33e-02, fs:0.70732 (r=0.586,p=0.892),  time:34.103, tt:5217.813\n",
      "Ep:153, loss:0.00000, loss_test:0.01915, lr:2.31e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.109, tt:5252.732\n",
      "Ep:154, loss:0.00000, loss_test:0.01920, lr:2.29e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.130, tt:5290.171\n",
      "Ep:155, loss:0.00000, loss_test:0.01924, lr:2.26e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.137, tt:5325.363\n",
      "Ep:156, loss:0.00000, loss_test:0.01927, lr:2.24e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.139, tt:5359.877\n",
      "Ep:157, loss:0.00000, loss_test:0.01932, lr:2.22e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.137, tt:5393.676\n",
      "Ep:158, loss:0.00000, loss_test:0.01936, lr:2.20e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.132, tt:5426.979\n",
      "Ep:159, loss:0.00000, loss_test:0.01938, lr:2.17e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.138, tt:5462.077\n",
      "Ep:160, loss:0.00000, loss_test:0.01942, lr:2.15e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.132, tt:5495.187\n",
      "Ep:161, loss:0.00000, loss_test:0.01948, lr:2.13e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.129, tt:5528.956\n",
      "Ep:162, loss:0.00000, loss_test:0.01951, lr:2.11e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.127, tt:5562.695\n",
      "Ep:163, loss:0.00000, loss_test:0.01952, lr:2.09e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.131, tt:5597.554\n",
      "Ep:164, loss:0.00000, loss_test:0.01956, lr:2.07e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.127, tt:5630.900\n",
      "Ep:165, loss:0.00000, loss_test:0.01961, lr:2.05e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.127, tt:5665.066\n",
      "Ep:166, loss:0.00000, loss_test:0.01966, lr:2.03e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.132, tt:5700.018\n",
      "Ep:167, loss:0.00000, loss_test:0.01968, lr:2.01e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.133, tt:5734.266\n",
      "Ep:168, loss:0.00000, loss_test:0.01969, lr:1.99e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.133, tt:5768.529\n",
      "Ep:169, loss:0.00000, loss_test:0.01973, lr:1.97e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.122, tt:5800.796\n",
      "Ep:170, loss:0.00000, loss_test:0.01978, lr:1.95e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.125, tt:5835.356\n",
      "Ep:171, loss:0.00000, loss_test:0.01981, lr:1.93e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.131, tt:5870.564\n",
      "Ep:172, loss:0.00000, loss_test:0.01984, lr:1.91e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.136, tt:5905.559\n",
      "Ep:173, loss:0.00000, loss_test:0.01987, lr:1.89e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.144, tt:5941.075\n",
      "Ep:174, loss:0.00000, loss_test:0.01990, lr:1.87e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.156, tt:5977.353\n",
      "Ep:175, loss:0.00000, loss_test:0.01993, lr:1.85e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.149, tt:6010.246\n",
      "Ep:176, loss:0.00000, loss_test:0.01994, lr:1.83e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.145, tt:6043.705\n",
      "Ep:177, loss:0.00000, loss_test:0.01999, lr:1.81e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.151, tt:6078.952\n",
      "Ep:178, loss:0.00000, loss_test:0.02003, lr:1.80e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.160, tt:6114.699\n",
      "Ep:179, loss:0.00000, loss_test:0.02006, lr:1.78e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.162, tt:6149.125\n",
      "Ep:180, loss:0.00000, loss_test:0.02009, lr:1.76e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.169, tt:6184.509\n",
      "Ep:181, loss:0.00000, loss_test:0.02013, lr:1.74e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.171, tt:6219.169\n",
      "Ep:182, loss:0.00000, loss_test:0.02016, lr:1.73e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.177, tt:6254.460\n",
      "Ep:183, loss:0.00000, loss_test:0.02017, lr:1.71e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.172, tt:6287.560\n",
      "Ep:184, loss:0.00000, loss_test:0.02021, lr:1.69e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.173, tt:6322.046\n",
      "Ep:185, loss:0.00000, loss_test:0.02024, lr:1.67e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.165, tt:6354.713\n",
      "Ep:186, loss:0.00000, loss_test:0.02026, lr:1.66e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.170, tt:6389.820\n",
      "Ep:187, loss:0.00000, loss_test:0.02027, lr:1.64e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.175, tt:6424.912\n",
      "Ep:188, loss:0.00000, loss_test:0.02031, lr:1.62e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.173, tt:6458.631\n",
      "Ep:189, loss:0.00000, loss_test:0.02035, lr:1.61e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.170, tt:6492.221\n",
      "Ep:190, loss:0.00000, loss_test:0.02036, lr:1.59e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.172, tt:6526.813\n",
      "Ep:191, loss:0.00000, loss_test:0.02038, lr:1.58e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.169, tt:6560.359\n",
      "Ep:192, loss:0.00000, loss_test:0.02041, lr:1.56e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.168, tt:6594.366\n",
      "Ep:193, loss:0.00000, loss_test:0.02043, lr:1.54e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.170, tt:6628.977\n",
      "Ep:194, loss:0.00000, loss_test:0.02046, lr:1.53e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.167, tt:6662.483\n",
      "Ep:195, loss:0.00000, loss_test:0.02048, lr:1.51e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.168, tt:6696.904\n",
      "Ep:196, loss:0.00000, loss_test:0.02049, lr:1.50e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.162, tt:6729.860\n",
      "Ep:197, loss:0.00000, loss_test:0.02051, lr:1.48e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.160, tt:6763.692\n",
      "Ep:198, loss:0.00000, loss_test:0.02054, lr:1.47e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.156, tt:6797.079\n",
      "Ep:199, loss:0.00000, loss_test:0.02056, lr:1.45e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.154, tt:6830.849\n",
      "Ep:200, loss:0.00000, loss_test:0.02060, lr:1.44e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.151, tt:6864.448\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14065, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.796, tt:36.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13834, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.912, tt:73.825\n",
      "Ep:2, loss:0.00027, loss_test:0.13392, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:37.137, tt:111.411\n",
      "Ep:3, loss:0.00026, loss_test:0.12645, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:36.965, tt:147.860\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11976, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:36.795, tt:183.973\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11930, lr:1.00e-02, fs:0.62264 (r=0.667,p=0.584),  time:36.645, tt:219.869\n",
      "Ep:6, loss:0.00023, loss_test:0.11826, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:36.435, tt:255.047\n",
      "Ep:7, loss:0.00022, loss_test:0.11719, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:36.258, tt:290.066\n",
      "Ep:8, loss:0.00022, loss_test:0.11404, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:36.299, tt:326.689\n",
      "Ep:9, loss:0.00021, loss_test:0.10898, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:36.250, tt:362.497\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10679, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:36.091, tt:396.998\n",
      "Ep:11, loss:0.00020, loss_test:0.10603, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:35.964, tt:431.566\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10525, lr:1.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:35.896, tt:466.645\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10067, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:35.923, tt:502.922\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09799, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:35.881, tt:538.215\n",
      "Ep:15, loss:0.00017, loss_test:0.09606, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:35.811, tt:572.969\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09329, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:35.717, tt:607.181\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09129, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:35.742, tt:643.361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00015, loss_test:0.08875, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:35.839, tt:680.931\n",
      "Ep:19, loss:0.00014, loss_test:0.08702, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:35.923, tt:718.455\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08704, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:36.130, tt:758.727\n",
      "Ep:21, loss:0.00013, loss_test:0.08498, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:36.113, tt:794.477\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08440, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:36.073, tt:829.689\n",
      "Ep:23, loss:0.00012, loss_test:0.08209, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:36.137, tt:867.287\n",
      "Ep:24, loss:0.00011, loss_test:0.08232, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:36.191, tt:904.778\n",
      "Ep:25, loss:0.00010, loss_test:0.08000, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:36.146, tt:939.794\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07821, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:36.133, tt:975.581\n",
      "Ep:27, loss:0.00009, loss_test:0.07753, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:36.105, tt:1010.952\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.07540, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.046, tt:1045.325\n",
      "Ep:29, loss:0.00008, loss_test:0.07466, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:36.032, tt:1080.949\n",
      "Ep:30, loss:0.00008, loss_test:0.07322, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:36.026, tt:1116.816\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.07273, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:36.037, tt:1153.199\n",
      "Ep:32, loss:0.00007, loss_test:0.07273, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:36.032, tt:1189.049\n",
      "Ep:33, loss:0.00007, loss_test:0.07090, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:36.035, tt:1225.184\n",
      "Ep:34, loss:0.00007, loss_test:0.07165, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:36.000, tt:1260.015\n",
      "Ep:35, loss:0.00006, loss_test:0.06982, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:36.035, tt:1297.245\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.06818, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:36.037, tt:1333.351\n",
      "Ep:37, loss:0.00006, loss_test:0.06913, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:36.014, tt:1368.522\n",
      "Ep:38, loss:0.00005, loss_test:0.06595, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.992, tt:1403.693\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.06795, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.944, tt:1437.759\n",
      "Ep:40, loss:0.00005, loss_test:0.06631, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.917, tt:1472.607\n",
      "Ep:41, loss:0.00005, loss_test:0.06623, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.932, tt:1509.145\n",
      "Ep:42, loss:0.00005, loss_test:0.06649, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:35.972, tt:1546.808\n",
      "Ep:43, loss:0.00004, loss_test:0.06417, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.973, tt:1582.819\n",
      "Ep:44, loss:0.00004, loss_test:0.06792, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:36.006, tt:1620.264\n",
      "Ep:45, loss:0.00004, loss_test:0.06395, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:36.024, tt:1657.103\n",
      "Ep:46, loss:0.00004, loss_test:0.06541, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:36.011, tt:1692.502\n",
      "Ep:47, loss:0.00003, loss_test:0.06555, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:36.015, tt:1728.729\n",
      "Ep:48, loss:0.00003, loss_test:0.06392, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.010, tt:1764.477\n",
      "Ep:49, loss:0.00003, loss_test:0.06585, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:35.976, tt:1798.778\n",
      "Ep:50, loss:0.00003, loss_test:0.06471, lr:9.90e-03, fs:0.82486 (r=0.737,p=0.936),  time:35.978, tt:1834.889\n",
      "Ep:51, loss:0.00003, loss_test:0.06478, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.977, tt:1870.787\n",
      "Ep:52, loss:0.00003, loss_test:0.06529, lr:9.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:35.985, tt:1907.186\n",
      "Ep:53, loss:0.00003, loss_test:0.06388, lr:9.61e-03, fs:0.82486 (r=0.737,p=0.936),  time:35.993, tt:1943.598\n",
      "Ep:54, loss:0.00003, loss_test:0.06627, lr:9.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.019, tt:1981.030\n",
      "Ep:55, loss:0.00003, loss_test:0.06309, lr:9.41e-03, fs:0.83429 (r=0.737,p=0.961),  time:36.017, tt:2016.949\n",
      "Ep:56, loss:0.00003, loss_test:0.06828, lr:9.32e-03, fs:0.82486 (r=0.737,p=0.936),  time:35.991, tt:2051.490\n",
      "Ep:57, loss:0.00002, loss_test:0.06690, lr:9.23e-03, fs:0.83429 (r=0.737,p=0.961),  time:36.003, tt:2088.170\n",
      "Ep:58, loss:0.00002, loss_test:0.06491, lr:9.14e-03, fs:0.84091 (r=0.747,p=0.961),  time:36.005, tt:2124.273\n",
      "Ep:59, loss:0.00002, loss_test:0.06817, lr:9.04e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.011, tt:2160.668\n",
      "Ep:60, loss:0.00002, loss_test:0.06491, lr:8.95e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.008, tt:2196.508\n",
      "Ep:61, loss:0.00002, loss_test:0.06592, lr:8.86e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.020, tt:2233.271\n",
      "Ep:62, loss:0.00002, loss_test:0.06653, lr:8.78e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.034, tt:2270.168\n",
      "Ep:63, loss:0.00002, loss_test:0.06643, lr:8.69e-03, fs:0.83908 (r=0.737,p=0.973),  time:36.031, tt:2305.998\n",
      "Ep:64, loss:0.00002, loss_test:0.06707, lr:8.60e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.044, tt:2342.891\n",
      "Ep:65, loss:0.00002, loss_test:0.06831, lr:8.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.066, tt:2380.353\n",
      "Ep:66, loss:0.00002, loss_test:0.06691, lr:8.43e-03, fs:0.83429 (r=0.737,p=0.961),  time:36.074, tt:2416.937\n",
      "Ep:67, loss:0.00002, loss_test:0.06837, lr:8.35e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.069, tt:2452.669\n",
      "Ep:68, loss:0.00001, loss_test:0.06997, lr:8.26e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.077, tt:2489.300\n",
      "Ep:69, loss:0.00001, loss_test:0.06698, lr:8.18e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.061, tt:2524.240\n",
      "Ep:70, loss:0.00001, loss_test:0.07031, lr:8.10e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.046, tt:2559.267\n",
      "Ep:71, loss:0.00001, loss_test:0.06845, lr:8.02e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.022, tt:2593.594\n",
      "Ep:72, loss:0.00001, loss_test:0.06828, lr:7.94e-03, fs:0.85057 (r=0.747,p=0.987),  time:36.013, tt:2628.927\n",
      "Ep:73, loss:0.00001, loss_test:0.06997, lr:7.86e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.025, tt:2665.827\n",
      "Ep:74, loss:0.00001, loss_test:0.06739, lr:7.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:35.998, tt:2699.876\n",
      "Ep:75, loss:0.00001, loss_test:0.07078, lr:7.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.012, tt:2736.892\n",
      "Ep:76, loss:0.00001, loss_test:0.07080, lr:7.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.013, tt:2772.995\n",
      "Ep:77, loss:0.00001, loss_test:0.06817, lr:7.55e-03, fs:0.85057 (r=0.747,p=0.987),  time:36.014, tt:2809.122\n",
      "Ep:78, loss:0.00001, loss_test:0.07016, lr:7.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.004, tt:2844.329\n",
      "Ep:79, loss:0.00001, loss_test:0.06996, lr:7.40e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.980, tt:2878.373\n",
      "Ep:80, loss:0.00001, loss_test:0.06851, lr:7.32e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.972, tt:2913.706\n",
      "Ep:81, loss:0.00001, loss_test:0.06997, lr:7.25e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.953, tt:2948.125\n",
      "Ep:82, loss:0.00001, loss_test:0.07152, lr:7.18e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.919, tt:2981.275\n",
      "Ep:83, loss:0.00001, loss_test:0.06859, lr:7.11e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.890, tt:3014.740\n",
      "Ep:84, loss:0.00001, loss_test:0.06971, lr:7.03e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.838, tt:3046.207\n",
      "Ep:85, loss:0.00001, loss_test:0.07178, lr:6.96e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.764, tt:3075.739\n",
      "Ep:86, loss:0.00001, loss_test:0.06890, lr:6.89e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.699, tt:3105.785\n",
      "Ep:87, loss:0.00001, loss_test:0.06942, lr:6.83e-03, fs:0.85057 (r=0.747,p=0.987),  time:35.657, tt:3137.851\n",
      "Ep:88, loss:0.00001, loss_test:0.07087, lr:6.76e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.663, tt:3174.042\n",
      "Ep:89, loss:0.00001, loss_test:0.06928, lr:6.69e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.665, tt:3209.853\n",
      "Ep:90, loss:0.00001, loss_test:0.06965, lr:6.62e-03, fs:0.84393 (r=0.737,p=0.986),  time:35.657, tt:3244.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:91, loss:0.00001, loss_test:0.06908, lr:6.56e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.664, tt:3281.071\n",
      "Ep:92, loss:0.00001, loss_test:0.06960, lr:6.49e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.671, tt:3317.394\n",
      "Ep:93, loss:0.00001, loss_test:0.06998, lr:6.43e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.669, tt:3352.841\n",
      "Ep:94, loss:0.00001, loss_test:0.06905, lr:6.36e-03, fs:0.84393 (r=0.737,p=0.986),  time:35.673, tt:3388.960\n",
      "Ep:95, loss:0.00001, loss_test:0.07166, lr:6.30e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.681, tt:3425.403\n",
      "Ep:96, loss:0.00001, loss_test:0.07030, lr:6.24e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.679, tt:3460.862\n",
      "Ep:97, loss:0.00001, loss_test:0.07030, lr:6.17e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.682, tt:3496.789\n",
      "Ep:98, loss:0.00001, loss_test:0.07034, lr:6.11e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.697, tt:3534.001\n",
      "Ep:99, loss:0.00001, loss_test:0.07015, lr:6.05e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.712, tt:3571.212\n",
      "Ep:100, loss:0.00001, loss_test:0.07001, lr:5.99e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.701, tt:3605.798\n",
      "Ep:101, loss:0.00001, loss_test:0.06971, lr:5.93e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.702, tt:3641.625\n",
      "Ep:102, loss:0.00001, loss_test:0.07010, lr:5.87e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.706, tt:3677.712\n",
      "Ep:103, loss:0.00001, loss_test:0.07031, lr:5.81e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.711, tt:3713.895\n",
      "Ep:104, loss:0.00001, loss_test:0.06973, lr:5.75e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.729, tt:3751.525\n",
      "Ep:105, loss:0.00001, loss_test:0.07114, lr:5.70e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.728, tt:3787.169\n",
      "Ep:106, loss:0.00001, loss_test:0.06977, lr:5.64e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.750, tt:3825.231\n",
      "Ep:107, loss:0.00001, loss_test:0.07076, lr:5.58e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.756, tt:3861.698\n",
      "Ep:108, loss:0.00001, loss_test:0.07069, lr:5.53e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.759, tt:3897.732\n",
      "Ep:109, loss:0.00001, loss_test:0.07008, lr:5.47e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.772, tt:3934.919\n",
      "Ep:110, loss:0.00001, loss_test:0.07018, lr:5.42e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.772, tt:3970.645\n",
      "Ep:111, loss:0.00001, loss_test:0.07082, lr:5.36e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.752, tt:4004.193\n",
      "Ep:112, loss:0.00001, loss_test:0.07111, lr:5.31e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.734, tt:4037.911\n",
      "Ep:113, loss:0.00000, loss_test:0.07011, lr:5.26e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.742, tt:4074.607\n",
      "Ep:114, loss:0.00000, loss_test:0.06994, lr:5.20e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.734, tt:4109.448\n",
      "Ep:115, loss:0.00000, loss_test:0.07047, lr:5.15e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.750, tt:4146.967\n",
      "Ep:116, loss:0.00000, loss_test:0.07013, lr:5.10e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.755, tt:4183.366\n",
      "Ep:117, loss:0.00000, loss_test:0.06967, lr:5.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.761, tt:4219.805\n",
      "Ep:118, loss:0.00000, loss_test:0.07112, lr:5.00e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.769, tt:4256.524\n",
      "Ep:119, loss:0.00000, loss_test:0.07042, lr:4.95e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.768, tt:4292.179\n",
      "Ep:120, loss:0.00000, loss_test:0.07030, lr:4.90e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.775, tt:4328.786\n",
      "Ep:121, loss:0.00000, loss_test:0.07109, lr:4.85e-03, fs:0.82353 (r=0.707,p=0.986),  time:35.777, tt:4364.817\n",
      "Ep:122, loss:0.00000, loss_test:0.07003, lr:4.80e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.784, tt:4401.400\n",
      "Ep:123, loss:0.00000, loss_test:0.07042, lr:4.75e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.779, tt:4436.613\n",
      "Ep:124, loss:0.00000, loss_test:0.07043, lr:4.71e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.775, tt:4471.829\n",
      "Ep:125, loss:0.00000, loss_test:0.07014, lr:4.66e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.780, tt:4508.290\n",
      "Ep:126, loss:0.00000, loss_test:0.07069, lr:4.61e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.786, tt:4544.770\n",
      "Ep:127, loss:0.00000, loss_test:0.07023, lr:4.57e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.799, tt:4582.237\n",
      "Ep:128, loss:0.00000, loss_test:0.07000, lr:4.52e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.813, tt:4619.813\n",
      "Ep:129, loss:0.00000, loss_test:0.07051, lr:4.48e-03, fs:0.82353 (r=0.707,p=0.986),  time:35.835, tt:4658.508\n",
      "Ep:130, loss:0.00000, loss_test:0.07054, lr:4.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:35.839, tt:4694.913\n",
      "Ep:131, loss:0.00000, loss_test:0.07036, lr:4.39e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.848, tt:4731.928\n",
      "Ep:132, loss:0.00000, loss_test:0.07055, lr:4.34e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.863, tt:4769.806\n",
      "Ep:133, loss:0.00000, loss_test:0.07020, lr:4.30e-03, fs:0.82353 (r=0.707,p=0.986),  time:35.920, tt:4813.254\n",
      "Ep:134, loss:0.00000, loss_test:0.07015, lr:4.26e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.977, tt:4856.925\n",
      "Ep:135, loss:0.00000, loss_test:0.07011, lr:4.21e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.986, tt:4894.073\n",
      "Ep:136, loss:0.00000, loss_test:0.07025, lr:4.17e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.988, tt:4930.332\n",
      "Ep:137, loss:0.00000, loss_test:0.07108, lr:4.13e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.003, tt:4968.443\n",
      "Ep:138, loss:0.00000, loss_test:0.07062, lr:4.09e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.000, tt:5003.975\n",
      "Ep:139, loss:0.00000, loss_test:0.06952, lr:4.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.036, tt:5045.079\n",
      "Ep:140, loss:0.00000, loss_test:0.07037, lr:4.01e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.032, tt:5080.447\n",
      "Ep:141, loss:0.00000, loss_test:0.07061, lr:3.97e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.031, tt:5116.390\n",
      "Ep:142, loss:0.00000, loss_test:0.07003, lr:3.93e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.034, tt:5152.845\n",
      "Ep:143, loss:0.00000, loss_test:0.07055, lr:3.89e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.035, tt:5189.064\n",
      "Ep:144, loss:0.00000, loss_test:0.07085, lr:3.85e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.038, tt:5225.554\n",
      "Ep:145, loss:0.00000, loss_test:0.07035, lr:3.81e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.036, tt:5261.288\n",
      "Ep:146, loss:0.00000, loss_test:0.07038, lr:3.77e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.037, tt:5297.403\n",
      "Ep:147, loss:0.00000, loss_test:0.07029, lr:3.73e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.023, tt:5331.370\n",
      "Ep:148, loss:0.00000, loss_test:0.07011, lr:3.70e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.033, tt:5368.986\n",
      "Ep:149, loss:0.00000, loss_test:0.06992, lr:3.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.025, tt:5403.798\n",
      "Ep:150, loss:0.00000, loss_test:0.07025, lr:3.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.027, tt:5440.037\n",
      "Ep:151, loss:0.00000, loss_test:0.07065, lr:3.59e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.030, tt:5476.628\n",
      "Ep:152, loss:0.00000, loss_test:0.07030, lr:3.55e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.034, tt:5513.132\n",
      "Ep:153, loss:0.00000, loss_test:0.06994, lr:3.52e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.039, tt:5549.963\n",
      "Ep:154, loss:0.00000, loss_test:0.07067, lr:3.48e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.034, tt:5585.290\n",
      "Ep:155, loss:0.00000, loss_test:0.07059, lr:3.45e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.025, tt:5619.970\n",
      "Ep:156, loss:0.00000, loss_test:0.07037, lr:3.41e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.021, tt:5655.333\n",
      "Ep:157, loss:0.00000, loss_test:0.07057, lr:3.38e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.022, tt:5691.477\n",
      "Ep:158, loss:0.00000, loss_test:0.07048, lr:3.34e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.019, tt:5726.989\n",
      "Ep:159, loss:0.00000, loss_test:0.07008, lr:3.31e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.014, tt:5762.276\n",
      "Ep:160, loss:0.00000, loss_test:0.07032, lr:3.28e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.014, tt:5798.326\n",
      "Ep:161, loss:0.00000, loss_test:0.07047, lr:3.24e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.025, tt:5836.087\n",
      "Ep:162, loss:0.00000, loss_test:0.07029, lr:3.21e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.020, tt:5871.338\n",
      "Ep:163, loss:0.00000, loss_test:0.07017, lr:3.18e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.027, tt:5908.469\n",
      "Ep:164, loss:0.00000, loss_test:0.07003, lr:3.15e-03, fs:0.80952 (r=0.687,p=0.986),  time:36.020, tt:5943.344\n",
      "Ep:165, loss:0.00000, loss_test:0.07029, lr:3.12e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.010, tt:5977.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:166, loss:0.00000, loss_test:0.07053, lr:3.09e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.005, tt:6012.859\n",
      "Ep:167, loss:0.00000, loss_test:0.07015, lr:3.05e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.995, tt:6047.169\n",
      "Ep:168, loss:0.00000, loss_test:0.06998, lr:3.02e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.989, tt:6082.093\n",
      "Ep:169, loss:0.00000, loss_test:0.07049, lr:2.99e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.978, tt:6116.296\n",
      "Ep:170, loss:0.00000, loss_test:0.07064, lr:2.96e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.976, tt:6151.874\n",
      "Ep:171, loss:0.00000, loss_test:0.07022, lr:2.93e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.965, tt:6186.043\n",
      "Ep:172, loss:0.00000, loss_test:0.07002, lr:2.90e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.952, tt:6219.674\n",
      "Ep:173, loss:0.00000, loss_test:0.07019, lr:2.88e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.942, tt:6253.925\n",
      "Ep:174, loss:0.00000, loss_test:0.07012, lr:2.85e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.935, tt:6288.708\n",
      "Ep:175, loss:0.00000, loss_test:0.07024, lr:2.82e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.916, tt:6321.280\n",
      "Ep:176, loss:0.00000, loss_test:0.07035, lr:2.79e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.916, tt:6357.074\n",
      "Ep:177, loss:0.00000, loss_test:0.07030, lr:2.76e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.910, tt:6392.018\n",
      "Ep:178, loss:0.00000, loss_test:0.07038, lr:2.73e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.908, tt:6427.585\n",
      "Ep:179, loss:0.00000, loss_test:0.07047, lr:2.71e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.896, tt:6461.193\n",
      "Ep:180, loss:0.00000, loss_test:0.07016, lr:2.68e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.891, tt:6496.260\n",
      "Ep:181, loss:0.00000, loss_test:0.06999, lr:2.65e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.878, tt:6529.746\n",
      "Ep:182, loss:0.00000, loss_test:0.07038, lr:2.63e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.869, tt:6564.009\n",
      "Ep:183, loss:0.00000, loss_test:0.07068, lr:2.60e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.852, tt:6596.749\n",
      "Ep:184, loss:0.00000, loss_test:0.07059, lr:2.57e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.848, tt:6631.919\n",
      "Ep:185, loss:0.00000, loss_test:0.07033, lr:2.55e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.836, tt:6665.578\n",
      "Ep:186, loss:0.00000, loss_test:0.07017, lr:2.52e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.826, tt:6699.380\n",
      "Ep:187, loss:0.00000, loss_test:0.07019, lr:2.50e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.835, tt:6736.927\n",
      "Ep:188, loss:0.00000, loss_test:0.07032, lr:2.47e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.821, tt:6770.194\n",
      "Ep:189, loss:0.00000, loss_test:0.07035, lr:2.45e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.809, tt:6803.793\n",
      "Ep:190, loss:0.00000, loss_test:0.07020, lr:2.42e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.802, tt:6838.113\n",
      "Ep:191, loss:0.00000, loss_test:0.07008, lr:2.40e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.799, tt:6873.424\n",
      "Ep:192, loss:0.00000, loss_test:0.07018, lr:2.38e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.790, tt:6907.504\n",
      "Ep:193, loss:0.00000, loss_test:0.07036, lr:2.35e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.793, tt:6943.847\n",
      "Ep:194, loss:0.00000, loss_test:0.07036, lr:2.33e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.782, tt:6977.530\n",
      "Ep:195, loss:0.00000, loss_test:0.07036, lr:2.31e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.778, tt:7012.573\n",
      "Ep:196, loss:0.00000, loss_test:0.07035, lr:2.28e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.776, tt:7047.848\n",
      "Ep:197, loss:0.00000, loss_test:0.07028, lr:2.26e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.775, tt:7083.394\n",
      "Ep:198, loss:0.00000, loss_test:0.07029, lr:2.24e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.767, tt:7117.642\n",
      "Ep:199, loss:0.00000, loss_test:0.07020, lr:2.21e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.755, tt:7150.909\n",
      "Ep:200, loss:0.00000, loss_test:0.07024, lr:2.19e-03, fs:0.79518 (r=0.667,p=0.985),  time:35.749, tt:7185.483\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02200, lr:6.00e-02, fs:0.62009 (r=0.816,p=0.500),  time:13.254, tt:13.254\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02399, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.175, tt:26.350\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.231, tt:39.692\n",
      "Ep:3, loss:0.00005, loss_test:0.02467, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.190, tt:56.761\n",
      "Ep:4, loss:0.00005, loss_test:0.02357, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.955, tt:79.773\n",
      "Ep:5, loss:0.00004, loss_test:0.02228, lr:6.00e-02, fs:0.63158 (r=0.897,p=0.487),  time:18.503, tt:111.016\n",
      "Ep:6, loss:0.00004, loss_test:0.02152, lr:6.00e-02, fs:0.62338 (r=0.828,p=0.500),  time:21.568, tt:150.979\n",
      "Ep:7, loss:0.00004, loss_test:0.02168, lr:6.00e-02, fs:0.60952 (r=0.736,p=0.520),  time:23.830, tt:190.642\n",
      "Ep:8, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.61140 (r=0.678,p=0.557),  time:25.725, tt:231.523\n",
      "Ep:9, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.60825 (r=0.678,p=0.551),  time:27.093, tt:270.926\n",
      "Ep:10, loss:0.00003, loss_test:0.01982, lr:6.00e-02, fs:0.62439 (r=0.736,p=0.542),  time:28.314, tt:311.459\n",
      "Ep:11, loss:0.00003, loss_test:0.01914, lr:6.00e-02, fs:0.65753 (r=0.828,p=0.545),  time:29.280, tt:351.362\n",
      "Ep:12, loss:0.00003, loss_test:0.01862, lr:6.00e-02, fs:0.65753 (r=0.828,p=0.545),  time:30.379, tt:394.931\n",
      "Ep:13, loss:0.00003, loss_test:0.01809, lr:5.94e-02, fs:0.67290 (r=0.828,p=0.567),  time:31.037, tt:434.523\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01774, lr:5.94e-02, fs:0.69231 (r=0.828,p=0.595),  time:31.663, tt:474.947\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01752, lr:5.94e-02, fs:0.69903 (r=0.828,p=0.605),  time:32.277, tt:516.429\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01717, lr:5.94e-02, fs:0.70244 (r=0.828,p=0.610),  time:32.872, tt:558.829\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01672, lr:5.94e-02, fs:0.69903 (r=0.828,p=0.605),  time:33.320, tt:599.756\n",
      "Ep:18, loss:0.00003, loss_test:0.01631, lr:5.94e-02, fs:0.70531 (r=0.839,p=0.608),  time:33.641, tt:639.172\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01598, lr:5.94e-02, fs:0.70192 (r=0.839,p=0.603),  time:33.986, tt:679.711\n",
      "Ep:20, loss:0.00003, loss_test:0.01574, lr:5.94e-02, fs:0.70874 (r=0.839,p=0.613),  time:34.327, tt:720.874\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01555, lr:5.94e-02, fs:0.71921 (r=0.839,p=0.629),  time:34.590, tt:760.983\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01535, lr:5.94e-02, fs:0.74112 (r=0.839,p=0.664),  time:34.817, tt:800.801\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01510, lr:5.94e-02, fs:0.75127 (r=0.851,p=0.673),  time:35.048, tt:841.147\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01488, lr:5.94e-02, fs:0.75127 (r=0.851,p=0.673),  time:35.247, tt:881.170\n",
      "Ep:25, loss:0.00002, loss_test:0.01464, lr:5.94e-02, fs:0.76531 (r=0.862,p=0.688),  time:35.519, tt:923.492\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01444, lr:5.94e-02, fs:0.76142 (r=0.862,p=0.682),  time:35.721, tt:964.479\n",
      "Ep:27, loss:0.00002, loss_test:0.01428, lr:5.94e-02, fs:0.76531 (r=0.862,p=0.688),  time:35.886, tt:1004.805\n",
      "Ep:28, loss:0.00002, loss_test:0.01413, lr:5.94e-02, fs:0.76923 (r=0.862,p=0.694),  time:36.221, tt:1050.412\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01402, lr:5.94e-02, fs:0.78125 (r=0.862,p=0.714),  time:36.384, tt:1091.523\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01389, lr:5.94e-02, fs:0.77895 (r=0.851,p=0.718),  time:36.630, tt:1135.529\n",
      "Ep:31, loss:0.00002, loss_test:0.01378, lr:5.94e-02, fs:0.77895 (r=0.851,p=0.718),  time:36.823, tt:1178.341\n",
      "Ep:32, loss:0.00002, loss_test:0.01370, lr:5.94e-02, fs:0.78307 (r=0.851,p=0.725),  time:37.002, tt:1221.063\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01365, lr:5.94e-02, fs:0.78307 (r=0.851,p=0.725),  time:37.131, tt:1262.466\n",
      "Ep:34, loss:0.00002, loss_test:0.01358, lr:5.94e-02, fs:0.79581 (r=0.874,p=0.731),  time:37.249, tt:1303.698\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01353, lr:5.94e-02, fs:0.80000 (r=0.874,p=0.738),  time:37.336, tt:1344.084\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01348, lr:5.94e-02, fs:0.80000 (r=0.874,p=0.738),  time:37.490, tt:1387.116\n",
      "Ep:37, loss:0.00002, loss_test:0.01342, lr:5.94e-02, fs:0.80423 (r=0.874,p=0.745),  time:37.643, tt:1430.420\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01339, lr:5.94e-02, fs:0.80423 (r=0.874,p=0.745),  time:37.703, tt:1470.433\n",
      "Ep:39, loss:0.00002, loss_test:0.01336, lr:5.94e-02, fs:0.80423 (r=0.874,p=0.745),  time:37.792, tt:1511.688\n",
      "Ep:40, loss:0.00002, loss_test:0.01332, lr:5.94e-02, fs:0.81283 (r=0.874,p=0.760),  time:37.951, tt:1556.011\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01330, lr:5.94e-02, fs:0.81283 (r=0.874,p=0.760),  time:38.077, tt:1599.251\n",
      "Ep:42, loss:0.00002, loss_test:0.01326, lr:5.94e-02, fs:0.81720 (r=0.874,p=0.768),  time:38.171, tt:1641.334\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01323, lr:5.94e-02, fs:0.81720 (r=0.874,p=0.768),  time:38.232, tt:1682.186\n",
      "Ep:44, loss:0.00002, loss_test:0.01322, lr:5.94e-02, fs:0.81720 (r=0.874,p=0.768),  time:38.305, tt:1723.733\n",
      "Ep:45, loss:0.00001, loss_test:0.01321, lr:5.94e-02, fs:0.81720 (r=0.874,p=0.768),  time:38.341, tt:1763.696\n",
      "Ep:46, loss:0.00001, loss_test:0.01321, lr:5.94e-02, fs:0.82162 (r=0.874,p=0.776),  time:38.398, tt:1804.719\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01317, lr:5.94e-02, fs:0.82162 (r=0.874,p=0.776),  time:38.482, tt:1847.144\n",
      "Ep:48, loss:0.00001, loss_test:0.01314, lr:5.94e-02, fs:0.82609 (r=0.874,p=0.784),  time:38.527, tt:1887.807\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01313, lr:5.94e-02, fs:0.82609 (r=0.874,p=0.784),  time:38.579, tt:1928.972\n",
      "Ep:50, loss:0.00001, loss_test:0.01313, lr:5.94e-02, fs:0.82609 (r=0.874,p=0.784),  time:38.595, tt:1968.363\n",
      "Ep:51, loss:0.00001, loss_test:0.01314, lr:5.94e-02, fs:0.81768 (r=0.851,p=0.787),  time:38.662, tt:2010.442\n",
      "Ep:52, loss:0.00001, loss_test:0.01311, lr:5.94e-02, fs:0.81768 (r=0.851,p=0.787),  time:38.717, tt:2052.016\n",
      "Ep:53, loss:0.00001, loss_test:0.01308, lr:5.94e-02, fs:0.81768 (r=0.851,p=0.787),  time:38.748, tt:2092.401\n",
      "Ep:54, loss:0.00001, loss_test:0.01306, lr:5.94e-02, fs:0.81768 (r=0.851,p=0.787),  time:38.774, tt:2132.560\n",
      "Ep:55, loss:0.00001, loss_test:0.01301, lr:5.94e-02, fs:0.81768 (r=0.851,p=0.787),  time:38.852, tt:2175.691\n",
      "Ep:56, loss:0.00001, loss_test:0.01304, lr:5.94e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.879, tt:2216.126\n",
      "Ep:57, loss:0.00001, loss_test:0.01305, lr:5.94e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.902, tt:2256.325\n",
      "Ep:58, loss:0.00001, loss_test:0.01303, lr:5.94e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.932, tt:2296.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01308, lr:5.94e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.947, tt:2336.843\n",
      "Ep:60, loss:0.00001, loss_test:0.01308, lr:5.88e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.985, tt:2378.081\n",
      "Ep:61, loss:0.00001, loss_test:0.01307, lr:5.82e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.995, tt:2417.708\n",
      "Ep:62, loss:0.00001, loss_test:0.01311, lr:5.76e-02, fs:0.82682 (r=0.851,p=0.804),  time:39.024, tt:2458.499\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01311, lr:5.76e-02, fs:0.82682 (r=0.851,p=0.804),  time:39.014, tt:2496.892\n",
      "Ep:64, loss:0.00001, loss_test:0.01311, lr:5.76e-02, fs:0.82682 (r=0.851,p=0.804),  time:39.046, tt:2538.004\n",
      "Ep:65, loss:0.00001, loss_test:0.01313, lr:5.76e-02, fs:0.83146 (r=0.851,p=0.813),  time:39.108, tt:2581.154\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01315, lr:5.76e-02, fs:0.83146 (r=0.851,p=0.813),  time:39.129, tt:2621.628\n",
      "Ep:67, loss:0.00001, loss_test:0.01319, lr:5.76e-02, fs:0.84091 (r=0.851,p=0.831),  time:39.171, tt:2663.600\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01320, lr:5.76e-02, fs:0.84091 (r=0.851,p=0.831),  time:39.182, tt:2703.541\n",
      "Ep:69, loss:0.00001, loss_test:0.01320, lr:5.76e-02, fs:0.82759 (r=0.828,p=0.828),  time:39.209, tt:2744.595\n",
      "Ep:70, loss:0.00001, loss_test:0.01323, lr:5.76e-02, fs:0.82759 (r=0.828,p=0.828),  time:39.221, tt:2784.725\n",
      "Ep:71, loss:0.00001, loss_test:0.01323, lr:5.76e-02, fs:0.82759 (r=0.828,p=0.828),  time:39.251, tt:2826.092\n",
      "Ep:72, loss:0.00001, loss_test:0.01327, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.309, tt:2869.570\n",
      "Ep:73, loss:0.00001, loss_test:0.01330, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.345, tt:2911.553\n",
      "Ep:74, loss:0.00001, loss_test:0.01336, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.376, tt:2953.173\n",
      "Ep:75, loss:0.00001, loss_test:0.01336, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.360, tt:2991.345\n",
      "Ep:76, loss:0.00001, loss_test:0.01340, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.371, tt:3031.539\n",
      "Ep:77, loss:0.00001, loss_test:0.01341, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.410, tt:3073.956\n",
      "Ep:78, loss:0.00001, loss_test:0.01344, lr:5.76e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.408, tt:3113.258\n",
      "Ep:79, loss:0.00001, loss_test:0.01345, lr:5.71e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.442, tt:3155.341\n",
      "Ep:80, loss:0.00001, loss_test:0.01351, lr:5.65e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.416, tt:3192.730\n",
      "Ep:81, loss:0.00001, loss_test:0.01352, lr:5.59e-02, fs:0.82081 (r=0.816,p=0.826),  time:39.410, tt:3231.597\n",
      "Ep:82, loss:0.00001, loss_test:0.01354, lr:5.54e-02, fs:0.82558 (r=0.816,p=0.835),  time:39.417, tt:3271.639\n",
      "Ep:83, loss:0.00001, loss_test:0.01358, lr:5.48e-02, fs:0.82558 (r=0.816,p=0.835),  time:39.404, tt:3309.900\n",
      "Ep:84, loss:0.00001, loss_test:0.01365, lr:5.43e-02, fs:0.83041 (r=0.816,p=0.845),  time:39.406, tt:3349.549\n",
      "Ep:85, loss:0.00001, loss_test:0.01365, lr:5.37e-02, fs:0.82558 (r=0.816,p=0.835),  time:39.417, tt:3389.903\n",
      "Ep:86, loss:0.00001, loss_test:0.01369, lr:5.32e-02, fs:0.83041 (r=0.816,p=0.845),  time:39.416, tt:3429.163\n",
      "Ep:87, loss:0.00001, loss_test:0.01372, lr:5.27e-02, fs:0.83529 (r=0.816,p=0.855),  time:39.433, tt:3470.079\n",
      "Ep:88, loss:0.00001, loss_test:0.01374, lr:5.21e-02, fs:0.83529 (r=0.816,p=0.855),  time:39.426, tt:3508.950\n",
      "Ep:89, loss:0.00001, loss_test:0.01377, lr:5.16e-02, fs:0.83529 (r=0.816,p=0.855),  time:39.432, tt:3548.922\n",
      "Ep:90, loss:0.00001, loss_test:0.01382, lr:5.11e-02, fs:0.84024 (r=0.816,p=0.866),  time:39.541, tt:3598.189\n",
      "Ep:91, loss:0.00001, loss_test:0.01385, lr:5.06e-02, fs:0.84524 (r=0.816,p=0.877),  time:39.548, tt:3638.384\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01387, lr:5.06e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.546, tt:3677.742\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01393, lr:5.06e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.573, tt:3719.905\n",
      "Ep:94, loss:0.00001, loss_test:0.01398, lr:5.06e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.584, tt:3760.478\n",
      "Ep:95, loss:0.00001, loss_test:0.01405, lr:5.06e-02, fs:0.85542 (r=0.816,p=0.899),  time:39.589, tt:3800.532\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01407, lr:5.06e-02, fs:0.85542 (r=0.816,p=0.899),  time:39.608, tt:3841.928\n",
      "Ep:97, loss:0.00001, loss_test:0.01402, lr:5.06e-02, fs:0.85542 (r=0.816,p=0.899),  time:39.631, tt:3883.882\n",
      "Ep:98, loss:0.00001, loss_test:0.01413, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.635, tt:3923.861\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01421, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.636, tt:3963.613\n",
      "Ep:100, loss:0.00001, loss_test:0.01418, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.636, tt:4003.209\n",
      "Ep:101, loss:0.00001, loss_test:0.01421, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.644, tt:4043.694\n",
      "Ep:102, loss:0.00001, loss_test:0.01428, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.650, tt:4083.977\n",
      "Ep:103, loss:0.00001, loss_test:0.01433, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.689, tt:4127.626\n",
      "Ep:104, loss:0.00001, loss_test:0.01434, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.693, tt:4167.774\n",
      "Ep:105, loss:0.00001, loss_test:0.01434, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.698, tt:4208.008\n",
      "Ep:106, loss:0.00000, loss_test:0.01435, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.705, tt:4248.451\n",
      "Ep:107, loss:0.00000, loss_test:0.01441, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.708, tt:4288.446\n",
      "Ep:108, loss:0.00000, loss_test:0.01447, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.712, tt:4328.565\n",
      "Ep:109, loss:0.00000, loss_test:0.01449, lr:5.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.720, tt:4369.241\n",
      "Ep:110, loss:0.00000, loss_test:0.01451, lr:5.01e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.725, tt:4409.492\n",
      "Ep:111, loss:0.00000, loss_test:0.01460, lr:4.96e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.732, tt:4449.987\n",
      "Ep:112, loss:0.00000, loss_test:0.01460, lr:4.91e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.752, tt:4491.965\n",
      "Ep:113, loss:0.00000, loss_test:0.01459, lr:4.86e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.763, tt:4533.001\n",
      "Ep:114, loss:0.00000, loss_test:0.01463, lr:4.81e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.779, tt:4574.596\n",
      "Ep:115, loss:0.00000, loss_test:0.01471, lr:4.76e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.802, tt:4616.982\n",
      "Ep:116, loss:0.00000, loss_test:0.01475, lr:4.71e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.792, tt:4655.690\n",
      "Ep:117, loss:0.00000, loss_test:0.01474, lr:4.67e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.802, tt:4696.661\n",
      "Ep:118, loss:0.00000, loss_test:0.01477, lr:4.62e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.824, tt:4739.001\n",
      "Ep:119, loss:0.00000, loss_test:0.01482, lr:4.57e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.850, tt:4781.977\n",
      "Ep:120, loss:0.00000, loss_test:0.01480, lr:4.53e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.873, tt:4824.609\n",
      "Ep:121, loss:0.00000, loss_test:0.01489, lr:4.48e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.907, tt:4868.667\n",
      "Ep:122, loss:0.00000, loss_test:0.01496, lr:4.44e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.934, tt:4911.859\n",
      "Ep:123, loss:0.00000, loss_test:0.01495, lr:4.39e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.954, tt:4954.322\n",
      "Ep:124, loss:0.00000, loss_test:0.01499, lr:4.35e-02, fs:0.86061 (r=0.816,p=0.910),  time:39.980, tt:4997.446\n",
      "Ep:125, loss:0.00000, loss_test:0.01498, lr:4.31e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.010, tt:5041.297\n",
      "Ep:126, loss:0.00000, loss_test:0.01504, lr:4.26e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.025, tt:5083.235\n",
      "Ep:127, loss:0.00000, loss_test:0.01507, lr:4.22e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.041, tt:5125.186\n",
      "Ep:128, loss:0.00000, loss_test:0.01509, lr:4.18e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.079, tt:5170.153\n",
      "Ep:129, loss:0.00000, loss_test:0.01511, lr:4.14e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.097, tt:5212.608\n",
      "Ep:130, loss:0.00000, loss_test:0.01520, lr:4.10e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.114, tt:5254.889\n",
      "Ep:131, loss:0.00000, loss_test:0.01521, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.178, tt:5303.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01524, lr:4.01e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.192, tt:5345.514\n",
      "Ep:133, loss:0.00000, loss_test:0.01526, lr:3.97e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.206, tt:5387.630\n",
      "Ep:134, loss:0.00000, loss_test:0.01529, lr:3.93e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.219, tt:5429.501\n",
      "Ep:135, loss:0.00000, loss_test:0.01532, lr:3.89e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.208, tt:5468.347\n",
      "Ep:136, loss:0.00000, loss_test:0.01537, lr:3.86e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.221, tt:5510.265\n",
      "Ep:137, loss:0.00000, loss_test:0.01539, lr:3.82e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.239, tt:5553.040\n",
      "Ep:138, loss:0.00000, loss_test:0.01541, lr:3.78e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.243, tt:5593.722\n",
      "Ep:139, loss:0.00000, loss_test:0.01542, lr:3.74e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.249, tt:5634.857\n",
      "Ep:140, loss:0.00000, loss_test:0.01541, lr:3.70e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.270, tt:5678.016\n",
      "Ep:141, loss:0.00000, loss_test:0.01547, lr:3.67e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.275, tt:5719.042\n",
      "Ep:142, loss:0.00000, loss_test:0.01551, lr:3.63e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.276, tt:5759.466\n",
      "Ep:143, loss:0.00000, loss_test:0.01549, lr:3.59e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.271, tt:5798.957\n",
      "Ep:144, loss:0.00000, loss_test:0.01554, lr:3.56e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.273, tt:5839.592\n",
      "Ep:145, loss:0.00000, loss_test:0.01556, lr:3.52e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.263, tt:5878.343\n",
      "Ep:146, loss:0.00000, loss_test:0.01560, lr:3.49e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.263, tt:5918.733\n",
      "Ep:147, loss:0.00000, loss_test:0.01562, lr:3.45e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.264, tt:5959.034\n",
      "Ep:148, loss:0.00000, loss_test:0.01565, lr:3.42e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.258, tt:5998.422\n",
      "Ep:149, loss:0.00000, loss_test:0.01565, lr:3.38e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.261, tt:6039.077\n",
      "Ep:150, loss:0.00000, loss_test:0.01564, lr:3.35e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.267, tt:6080.359\n",
      "Ep:151, loss:0.00000, loss_test:0.01570, lr:3.32e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.276, tt:6121.968\n",
      "Ep:152, loss:0.00000, loss_test:0.01571, lr:3.28e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.303, tt:6166.361\n",
      "Ep:153, loss:0.00000, loss_test:0.01574, lr:3.25e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.312, tt:6208.079\n",
      "Ep:154, loss:0.00000, loss_test:0.01575, lr:3.22e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.300, tt:6246.470\n",
      "Ep:155, loss:0.00000, loss_test:0.01576, lr:3.19e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.300, tt:6286.766\n",
      "Ep:156, loss:0.00000, loss_test:0.01582, lr:3.15e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.298, tt:6326.840\n",
      "Ep:157, loss:0.00000, loss_test:0.01583, lr:3.12e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.286, tt:6365.211\n",
      "Ep:158, loss:0.00000, loss_test:0.01583, lr:3.09e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.284, tt:6405.125\n",
      "Ep:159, loss:0.00000, loss_test:0.01585, lr:3.06e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.284, tt:6445.367\n",
      "Ep:160, loss:0.00000, loss_test:0.01591, lr:3.03e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.281, tt:6485.170\n",
      "Ep:161, loss:0.00000, loss_test:0.01591, lr:3.00e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.284, tt:6526.008\n",
      "Ep:162, loss:0.00000, loss_test:0.01592, lr:2.97e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.283, tt:6566.162\n",
      "Ep:163, loss:0.00000, loss_test:0.01593, lr:2.94e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.281, tt:6606.102\n",
      "Ep:164, loss:0.00000, loss_test:0.01597, lr:2.91e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.283, tt:6646.709\n",
      "Ep:165, loss:0.00000, loss_test:0.01599, lr:2.88e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.279, tt:6686.295\n",
      "Ep:166, loss:0.00000, loss_test:0.01601, lr:2.85e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.274, tt:6725.747\n",
      "Ep:167, loss:0.00000, loss_test:0.01602, lr:2.82e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.279, tt:6766.873\n",
      "Ep:168, loss:0.00000, loss_test:0.01604, lr:2.80e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.275, tt:6806.468\n",
      "Ep:169, loss:0.00000, loss_test:0.01605, lr:2.77e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.280, tt:6847.647\n",
      "Ep:170, loss:0.00000, loss_test:0.01607, lr:2.74e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.278, tt:6887.570\n",
      "Ep:171, loss:0.00000, loss_test:0.01608, lr:2.71e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.277, tt:6927.562\n",
      "Ep:172, loss:0.00000, loss_test:0.01609, lr:2.69e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.289, tt:6970.033\n",
      "Ep:173, loss:0.00000, loss_test:0.01610, lr:2.66e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.278, tt:7008.456\n",
      "Ep:174, loss:0.00000, loss_test:0.01614, lr:2.63e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.281, tt:7049.151\n",
      "Ep:175, loss:0.00000, loss_test:0.01615, lr:2.61e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.272, tt:7087.942\n",
      "Ep:176, loss:0.00000, loss_test:0.01618, lr:2.58e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.280, tt:7129.512\n",
      "Ep:177, loss:0.00000, loss_test:0.01620, lr:2.55e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.284, tt:7170.512\n",
      "Ep:178, loss:0.00000, loss_test:0.01621, lr:2.53e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.288, tt:7211.495\n",
      "Ep:179, loss:0.00000, loss_test:0.01624, lr:2.50e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.298, tt:7253.638\n",
      "Ep:180, loss:0.00000, loss_test:0.01625, lr:2.48e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.307, tt:7295.636\n",
      "Ep:181, loss:0.00000, loss_test:0.01625, lr:2.45e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.306, tt:7335.744\n",
      "Ep:182, loss:0.00000, loss_test:0.01626, lr:2.43e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.297, tt:7374.392\n",
      "Ep:183, loss:0.00000, loss_test:0.01628, lr:2.40e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.303, tt:7415.675\n",
      "Ep:184, loss:0.00000, loss_test:0.01629, lr:2.38e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.310, tt:7457.395\n",
      "Ep:185, loss:0.00000, loss_test:0.01629, lr:2.36e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.314, tt:7498.426\n",
      "Ep:186, loss:0.00000, loss_test:0.01633, lr:2.33e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.314, tt:7538.677\n",
      "Ep:187, loss:0.00000, loss_test:0.01636, lr:2.31e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.328, tt:7581.708\n",
      "Ep:188, loss:0.00000, loss_test:0.01636, lr:2.29e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.330, tt:7622.423\n",
      "Ep:189, loss:0.00000, loss_test:0.01638, lr:2.26e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.338, tt:7664.251\n",
      "Ep:190, loss:0.00000, loss_test:0.01639, lr:2.24e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.344, tt:7705.687\n",
      "Ep:191, loss:0.00000, loss_test:0.01641, lr:2.22e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.348, tt:7746.890\n",
      "Ep:192, loss:0.00000, loss_test:0.01642, lr:2.20e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.349, tt:7787.366\n",
      "Ep:193, loss:0.00000, loss_test:0.01643, lr:2.17e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.387, tt:7835.030\n",
      "Ep:194, loss:0.00000, loss_test:0.01646, lr:2.15e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.387, tt:7875.488\n",
      "Ep:195, loss:0.00000, loss_test:0.01647, lr:2.13e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.386, tt:7915.647\n",
      "Ep:196, loss:0.00000, loss_test:0.01646, lr:2.11e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.387, tt:7956.173\n",
      "Ep:197, loss:0.00000, loss_test:0.01648, lr:2.09e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.382, tt:7995.673\n",
      "Ep:198, loss:0.00000, loss_test:0.01652, lr:2.07e-02, fs:0.86061 (r=0.816,p=0.910),  time:40.384, tt:8036.423\n",
      "Ep:199, loss:0.00000, loss_test:0.01653, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.378, tt:8075.669\n",
      "##########Best model found so far##########\n",
      "Ep:200, loss:0.00000, loss_test:0.01652, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.382, tt:8116.813\n",
      "Ep:201, loss:0.00000, loss_test:0.01654, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.381, tt:8157.016\n",
      "Ep:202, loss:0.00000, loss_test:0.01655, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.378, tt:8196.791\n",
      "Ep:203, loss:0.00000, loss_test:0.01657, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.368, tt:8235.119\n",
      "Ep:204, loss:0.00000, loss_test:0.01655, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.367, tt:8275.142\n",
      "Ep:205, loss:0.00000, loss_test:0.01657, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.360, tt:8314.097\n",
      "Ep:206, loss:0.00000, loss_test:0.01660, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.359, tt:8354.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.01663, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.368, tt:8396.512\n",
      "Ep:208, loss:0.00000, loss_test:0.01662, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.360, tt:8435.275\n",
      "Ep:209, loss:0.00000, loss_test:0.01665, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.366, tt:8476.909\n",
      "Ep:210, loss:0.00000, loss_test:0.01664, lr:2.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.368, tt:8517.595\n",
      "Ep:211, loss:0.00000, loss_test:0.01665, lr:2.03e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.365, tt:8557.373\n",
      "Ep:212, loss:0.00000, loss_test:0.01667, lr:2.01e-02, fs:0.86585 (r=0.816,p=0.922),  time:40.374, tt:8599.672\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14671, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.449, tt:37.449\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14590, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.371, tt:74.742\n",
      "Ep:2, loss:0.00027, loss_test:0.14435, lr:1.00e-02, fs:0.63241 (r=0.920,p=0.482),  time:36.017, tt:108.050\n",
      "Ep:3, loss:0.00026, loss_test:0.14136, lr:1.00e-02, fs:0.62551 (r=0.874,p=0.487),  time:35.411, tt:141.645\n",
      "Ep:4, loss:0.00025, loss_test:0.13827, lr:1.00e-02, fs:0.58986 (r=0.736,p=0.492),  time:33.766, tt:168.832\n",
      "Ep:5, loss:0.00023, loss_test:0.13600, lr:1.00e-02, fs:0.57955 (r=0.586,p=0.573),  time:35.055, tt:210.331\n",
      "Ep:6, loss:0.00023, loss_test:0.13420, lr:1.00e-02, fs:0.58750 (r=0.540,p=0.644),  time:35.551, tt:248.858\n",
      "Ep:7, loss:0.00022, loss_test:0.12872, lr:1.00e-02, fs:0.59091 (r=0.598,p=0.584),  time:36.348, tt:290.785\n",
      "Ep:8, loss:0.00021, loss_test:0.12550, lr:1.00e-02, fs:0.57754 (r=0.621,p=0.540),  time:36.899, tt:332.089\n",
      "Ep:9, loss:0.00021, loss_test:0.12177, lr:1.00e-02, fs:0.63095 (r=0.609,p=0.654),  time:37.589, tt:375.892\n",
      "Ep:10, loss:0.00020, loss_test:0.11942, lr:1.00e-02, fs:0.64052 (r=0.563,p=0.742),  time:37.834, tt:416.179\n",
      "Ep:11, loss:0.00019, loss_test:0.11441, lr:1.00e-02, fs:0.65432 (r=0.609,p=0.707),  time:38.044, tt:456.526\n",
      "Ep:12, loss:0.00018, loss_test:0.10974, lr:9.90e-03, fs:0.65089 (r=0.632,p=0.671),  time:38.081, tt:495.047\n",
      "Ep:13, loss:0.00018, loss_test:0.10504, lr:9.80e-03, fs:0.66250 (r=0.609,p=0.726),  time:38.341, tt:536.779\n",
      "Ep:14, loss:0.00017, loss_test:0.10055, lr:9.70e-03, fs:0.67081 (r=0.621,p=0.730),  time:38.603, tt:579.042\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09707, lr:9.70e-03, fs:0.69461 (r=0.667,p=0.725),  time:38.702, tt:619.238\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09402, lr:9.70e-03, fs:0.69565 (r=0.644,p=0.757),  time:39.130, tt:665.218\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09195, lr:9.70e-03, fs:0.75000 (r=0.724,p=0.778),  time:39.360, tt:708.479\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08982, lr:9.70e-03, fs:0.75145 (r=0.747,p=0.756),  time:39.537, tt:751.208\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08782, lr:9.70e-03, fs:0.76471 (r=0.747,p=0.783),  time:39.600, tt:792.010\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08593, lr:9.70e-03, fs:0.80000 (r=0.805,p=0.795),  time:39.680, tt:833.275\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08469, lr:9.70e-03, fs:0.78613 (r=0.782,p=0.791),  time:39.849, tt:876.683\n",
      "Ep:22, loss:0.00013, loss_test:0.08389, lr:9.70e-03, fs:0.77381 (r=0.747,p=0.802),  time:39.859, tt:916.747\n",
      "Ep:23, loss:0.00013, loss_test:0.08207, lr:9.70e-03, fs:0.82486 (r=0.839,p=0.811),  time:39.965, tt:959.155\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.08145, lr:9.70e-03, fs:0.77108 (r=0.736,p=0.810),  time:40.065, tt:1001.628\n",
      "Ep:25, loss:0.00012, loss_test:0.08026, lr:9.70e-03, fs:0.81176 (r=0.793,p=0.831),  time:40.104, tt:1042.700\n",
      "Ep:26, loss:0.00011, loss_test:0.07861, lr:9.70e-03, fs:0.81395 (r=0.805,p=0.824),  time:40.108, tt:1082.928\n",
      "Ep:27, loss:0.00011, loss_test:0.07749, lr:9.70e-03, fs:0.81871 (r=0.805,p=0.833),  time:40.118, tt:1123.307\n",
      "Ep:28, loss:0.00010, loss_test:0.07879, lr:9.70e-03, fs:0.81212 (r=0.770,p=0.859),  time:40.151, tt:1164.378\n",
      "Ep:29, loss:0.00010, loss_test:0.07694, lr:9.70e-03, fs:0.81657 (r=0.793,p=0.841),  time:40.198, tt:1205.932\n",
      "Ep:30, loss:0.00010, loss_test:0.07644, lr:9.70e-03, fs:0.82209 (r=0.770,p=0.882),  time:40.225, tt:1246.985\n",
      "Ep:31, loss:0.00009, loss_test:0.07766, lr:9.70e-03, fs:0.84663 (r=0.793,p=0.908),  time:40.214, tt:1286.840\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.07664, lr:9.70e-03, fs:0.84524 (r=0.816,p=0.877),  time:40.232, tt:1327.662\n",
      "Ep:33, loss:0.00009, loss_test:0.07559, lr:9.70e-03, fs:0.85030 (r=0.816,p=0.887),  time:40.213, tt:1367.245\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.07650, lr:9.70e-03, fs:0.85366 (r=0.805,p=0.909),  time:40.181, tt:1406.333\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.07517, lr:9.70e-03, fs:0.84337 (r=0.805,p=0.886),  time:40.185, tt:1446.656\n",
      "Ep:36, loss:0.00008, loss_test:0.07603, lr:9.70e-03, fs:0.86061 (r=0.816,p=0.910),  time:40.270, tt:1489.975\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.07399, lr:9.70e-03, fs:0.88372 (r=0.874,p=0.894),  time:40.326, tt:1532.398\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.07662, lr:9.70e-03, fs:0.87117 (r=0.816,p=0.934),  time:40.396, tt:1575.448\n",
      "Ep:39, loss:0.00007, loss_test:0.07425, lr:9.70e-03, fs:0.88235 (r=0.862,p=0.904),  time:40.356, tt:1614.239\n",
      "Ep:40, loss:0.00006, loss_test:0.07472, lr:9.70e-03, fs:0.88623 (r=0.851,p=0.925),  time:40.359, tt:1654.715\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.07915, lr:9.70e-03, fs:0.82353 (r=0.724,p=0.955),  time:40.380, tt:1695.945\n",
      "Ep:42, loss:0.00006, loss_test:0.07363, lr:9.70e-03, fs:0.89412 (r=0.874,p=0.916),  time:40.428, tt:1738.416\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.07734, lr:9.70e-03, fs:0.84416 (r=0.747,p=0.970),  time:40.429, tt:1778.868\n",
      "Ep:44, loss:0.00005, loss_test:0.07411, lr:9.70e-03, fs:0.88095 (r=0.851,p=0.914),  time:40.473, tt:1821.295\n",
      "Ep:45, loss:0.00005, loss_test:0.07608, lr:9.70e-03, fs:0.83660 (r=0.736,p=0.970),  time:40.505, tt:1863.218\n",
      "Ep:46, loss:0.00005, loss_test:0.07469, lr:9.70e-03, fs:0.89024 (r=0.839,p=0.948),  time:40.513, tt:1904.105\n",
      "Ep:47, loss:0.00005, loss_test:0.07512, lr:9.70e-03, fs:0.87654 (r=0.816,p=0.947),  time:40.503, tt:1944.159\n",
      "Ep:48, loss:0.00005, loss_test:0.07616, lr:9.70e-03, fs:0.86957 (r=0.805,p=0.946),  time:40.506, tt:1984.794\n",
      "Ep:49, loss:0.00004, loss_test:0.07443, lr:9.70e-03, fs:0.91566 (r=0.874,p=0.962),  time:40.530, tt:2026.507\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.07911, lr:9.70e-03, fs:0.83660 (r=0.736,p=0.970),  time:40.539, tt:2067.475\n",
      "Ep:51, loss:0.00004, loss_test:0.07353, lr:9.70e-03, fs:0.89820 (r=0.862,p=0.938),  time:40.549, tt:2108.530\n",
      "Ep:52, loss:0.00004, loss_test:0.07938, lr:9.70e-03, fs:0.76389 (r=0.632,p=0.965),  time:40.648, tt:2154.362\n",
      "Ep:53, loss:0.00004, loss_test:0.07296, lr:9.70e-03, fs:0.89941 (r=0.874,p=0.927),  time:40.641, tt:2194.598\n",
      "Ep:54, loss:0.00003, loss_test:0.08000, lr:9.70e-03, fs:0.74648 (r=0.609,p=0.964),  time:40.662, tt:2236.390\n",
      "Ep:55, loss:0.00003, loss_test:0.07566, lr:9.70e-03, fs:0.89157 (r=0.851,p=0.937),  time:40.665, tt:2277.224\n",
      "Ep:56, loss:0.00003, loss_test:0.07482, lr:9.70e-03, fs:0.90244 (r=0.851,p=0.961),  time:40.663, tt:2317.787\n",
      "Ep:57, loss:0.00003, loss_test:0.07802, lr:9.70e-03, fs:0.88199 (r=0.816,p=0.959),  time:40.690, tt:2359.999\n",
      "Ep:58, loss:0.00003, loss_test:0.07465, lr:9.70e-03, fs:0.86250 (r=0.793,p=0.945),  time:40.705, tt:2401.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.07884, lr:9.70e-03, fs:0.86792 (r=0.793,p=0.958),  time:40.704, tt:2442.227\n",
      "Ep:60, loss:0.00003, loss_test:0.07729, lr:9.70e-03, fs:0.83117 (r=0.736,p=0.955),  time:40.723, tt:2484.076\n",
      "Ep:61, loss:0.00003, loss_test:0.08190, lr:9.61e-03, fs:0.78912 (r=0.667,p=0.967),  time:40.721, tt:2524.719\n",
      "Ep:62, loss:0.00003, loss_test:0.08658, lr:9.51e-03, fs:0.88199 (r=0.816,p=0.959),  time:40.747, tt:2567.082\n",
      "Ep:63, loss:0.00003, loss_test:0.08412, lr:9.41e-03, fs:0.73759 (r=0.598,p=0.963),  time:40.772, tt:2609.433\n",
      "Ep:64, loss:0.00003, loss_test:0.07814, lr:9.32e-03, fs:0.88050 (r=0.805,p=0.972),  time:40.794, tt:2651.582\n",
      "Ep:65, loss:0.00002, loss_test:0.08031, lr:9.23e-03, fs:0.82895 (r=0.724,p=0.969),  time:40.793, tt:2692.316\n",
      "Ep:66, loss:0.00002, loss_test:0.08286, lr:9.14e-03, fs:0.74648 (r=0.609,p=0.964),  time:40.801, tt:2733.668\n",
      "Ep:67, loss:0.00002, loss_test:0.07877, lr:9.04e-03, fs:0.87500 (r=0.805,p=0.959),  time:40.818, tt:2775.657\n",
      "Ep:68, loss:0.00002, loss_test:0.09220, lr:8.95e-03, fs:0.71014 (r=0.563,p=0.961),  time:40.827, tt:2817.060\n",
      "Ep:69, loss:0.00002, loss_test:0.07958, lr:8.86e-03, fs:0.91463 (r=0.862,p=0.974),  time:40.829, tt:2858.006\n",
      "Ep:70, loss:0.00002, loss_test:0.08185, lr:8.78e-03, fs:0.78912 (r=0.667,p=0.967),  time:40.828, tt:2898.823\n",
      "Ep:71, loss:0.00002, loss_test:0.08709, lr:8.69e-03, fs:0.75524 (r=0.621,p=0.964),  time:40.845, tt:2940.861\n",
      "Ep:72, loss:0.00002, loss_test:0.08267, lr:8.60e-03, fs:0.78082 (r=0.655,p=0.966),  time:40.850, tt:2982.058\n",
      "Ep:73, loss:0.00002, loss_test:0.08533, lr:8.51e-03, fs:0.74648 (r=0.609,p=0.964),  time:40.844, tt:3022.424\n",
      "Ep:74, loss:0.00001, loss_test:0.08485, lr:8.43e-03, fs:0.76389 (r=0.632,p=0.965),  time:40.848, tt:3063.567\n",
      "Ep:75, loss:0.00001, loss_test:0.08641, lr:8.35e-03, fs:0.74648 (r=0.609,p=0.964),  time:40.876, tt:3106.602\n",
      "Ep:76, loss:0.00001, loss_test:0.08407, lr:8.26e-03, fs:0.78082 (r=0.655,p=0.966),  time:40.897, tt:3149.033\n",
      "Ep:77, loss:0.00001, loss_test:0.08837, lr:8.18e-03, fs:0.74648 (r=0.609,p=0.964),  time:40.931, tt:3192.620\n",
      "Ep:78, loss:0.00001, loss_test:0.08569, lr:8.10e-03, fs:0.74648 (r=0.609,p=0.964),  time:40.966, tt:3236.281\n",
      "Ep:79, loss:0.00001, loss_test:0.08658, lr:8.02e-03, fs:0.78082 (r=0.655,p=0.966),  time:40.992, tt:3279.376\n",
      "Ep:80, loss:0.00001, loss_test:0.08767, lr:7.94e-03, fs:0.80537 (r=0.690,p=0.968),  time:41.072, tt:3326.858\n",
      "Ep:81, loss:0.00001, loss_test:0.08566, lr:7.86e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.092, tt:3369.582\n",
      "Ep:82, loss:0.00001, loss_test:0.08652, lr:7.78e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.082, tt:3409.818\n",
      "Ep:83, loss:0.00001, loss_test:0.08666, lr:7.70e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.098, tt:3452.228\n",
      "Ep:84, loss:0.00001, loss_test:0.08716, lr:7.62e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.102, tt:3493.662\n",
      "Ep:85, loss:0.00001, loss_test:0.08544, lr:7.55e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.135, tt:3537.614\n",
      "Ep:86, loss:0.00001, loss_test:0.09123, lr:7.47e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.167, tt:3581.542\n",
      "Ep:87, loss:0.00001, loss_test:0.08511, lr:7.40e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.186, tt:3624.332\n",
      "Ep:88, loss:0.00001, loss_test:0.09051, lr:7.32e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.232, tt:3669.632\n",
      "Ep:89, loss:0.00001, loss_test:0.08671, lr:7.25e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.231, tt:3710.763\n",
      "Ep:90, loss:0.00001, loss_test:0.08730, lr:7.18e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.260, tt:3754.641\n",
      "Ep:91, loss:0.00001, loss_test:0.08878, lr:7.11e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.273, tt:3797.135\n",
      "Ep:92, loss:0.00001, loss_test:0.08620, lr:7.03e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.298, tt:3840.685\n",
      "Ep:93, loss:0.00001, loss_test:0.08795, lr:6.96e-03, fs:0.76389 (r=0.632,p=0.965),  time:41.336, tt:3885.587\n",
      "Ep:94, loss:0.00001, loss_test:0.08853, lr:6.89e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.380, tt:3931.078\n",
      "Ep:95, loss:0.00001, loss_test:0.08857, lr:6.83e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.378, tt:3972.323\n",
      "Ep:96, loss:0.00001, loss_test:0.08672, lr:6.76e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.407, tt:4016.475\n",
      "Ep:97, loss:0.00001, loss_test:0.08712, lr:6.69e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.418, tt:4058.958\n",
      "Ep:98, loss:0.00001, loss_test:0.08930, lr:6.62e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.444, tt:4102.980\n",
      "Ep:99, loss:0.00001, loss_test:0.09046, lr:6.56e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.454, tt:4145.370\n",
      "Ep:100, loss:0.00001, loss_test:0.08668, lr:6.49e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.482, tt:4189.685\n",
      "Ep:101, loss:0.00001, loss_test:0.09140, lr:6.43e-03, fs:0.75177 (r=0.609,p=0.981),  time:41.459, tt:4228.861\n",
      "Ep:102, loss:0.00001, loss_test:0.09041, lr:6.36e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.482, tt:4272.616\n",
      "Ep:103, loss:0.00001, loss_test:0.08891, lr:6.30e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.468, tt:4312.675\n",
      "Ep:104, loss:0.00001, loss_test:0.08978, lr:6.24e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.458, tt:4353.122\n",
      "Ep:105, loss:0.00001, loss_test:0.08714, lr:6.17e-03, fs:0.75177 (r=0.609,p=0.981),  time:41.450, tt:4393.673\n",
      "Ep:106, loss:0.00001, loss_test:0.08992, lr:6.11e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.452, tt:4435.416\n",
      "Ep:107, loss:0.00001, loss_test:0.08985, lr:6.05e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.445, tt:4476.051\n",
      "Ep:108, loss:0.00001, loss_test:0.08654, lr:5.99e-03, fs:0.75177 (r=0.609,p=0.981),  time:41.464, tt:4519.579\n",
      "Ep:109, loss:0.00001, loss_test:0.09185, lr:5.93e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.443, tt:4558.696\n",
      "Ep:110, loss:0.00001, loss_test:0.09077, lr:5.87e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.443, tt:4600.143\n",
      "Ep:111, loss:0.00000, loss_test:0.09090, lr:5.81e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.437, tt:4640.929\n",
      "Ep:112, loss:0.00000, loss_test:0.09251, lr:5.75e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.437, tt:4682.383\n",
      "Ep:113, loss:0.00000, loss_test:0.08895, lr:5.70e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.429, tt:4722.879\n",
      "Ep:114, loss:0.00000, loss_test:0.09122, lr:5.64e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.421, tt:4763.369\n",
      "Ep:115, loss:0.00000, loss_test:0.09059, lr:5.58e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.410, tt:4803.578\n",
      "Ep:116, loss:0.00000, loss_test:0.08948, lr:5.53e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.393, tt:4843.007\n",
      "Ep:117, loss:0.00000, loss_test:0.08995, lr:5.47e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.387, tt:4883.666\n",
      "Ep:118, loss:0.00000, loss_test:0.09049, lr:5.42e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.376, tt:4923.703\n",
      "Ep:119, loss:0.00000, loss_test:0.09012, lr:5.36e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.373, tt:4964.794\n",
      "Ep:120, loss:0.00000, loss_test:0.09050, lr:5.31e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.359, tt:5004.484\n",
      "Ep:121, loss:0.00000, loss_test:0.09169, lr:5.26e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.349, tt:5044.523\n",
      "Ep:122, loss:0.00000, loss_test:0.09080, lr:5.20e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.338, tt:5084.518\n",
      "Ep:123, loss:0.00000, loss_test:0.09124, lr:5.15e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.322, tt:5123.932\n",
      "Ep:124, loss:0.00000, loss_test:0.09052, lr:5.10e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.317, tt:5164.631\n",
      "Ep:125, loss:0.00000, loss_test:0.09066, lr:5.05e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.324, tt:5206.800\n",
      "Ep:126, loss:0.00000, loss_test:0.09393, lr:5.00e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.321, tt:5247.780\n",
      "Ep:127, loss:0.00000, loss_test:0.09309, lr:4.95e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.315, tt:5288.367\n",
      "Ep:128, loss:0.00000, loss_test:0.09142, lr:4.90e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.320, tt:5330.302\n",
      "Ep:129, loss:0.00000, loss_test:0.09330, lr:4.85e-03, fs:0.70588 (r=0.552,p=0.980),  time:41.306, tt:5369.755\n",
      "Ep:130, loss:0.00000, loss_test:0.09214, lr:4.80e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.307, tt:5411.182\n",
      "Ep:131, loss:0.00000, loss_test:0.09194, lr:4.75e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.308, tt:5452.610\n",
      "Ep:132, loss:0.00000, loss_test:0.09356, lr:4.71e-03, fs:0.69630 (r=0.540,p=0.979),  time:41.291, tt:5491.753\n",
      "Ep:133, loss:0.00000, loss_test:0.09290, lr:4.66e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.296, tt:5533.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.09220, lr:4.61e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.290, tt:5574.102\n",
      "Ep:135, loss:0.00000, loss_test:0.09261, lr:4.57e-03, fs:0.72464 (r=0.575,p=0.980),  time:41.281, tt:5614.186\n",
      "Ep:136, loss:0.00000, loss_test:0.09288, lr:4.52e-03, fs:0.72464 (r=0.575,p=0.980),  time:41.269, tt:5653.823\n",
      "Ep:137, loss:0.00000, loss_test:0.09290, lr:4.48e-03, fs:0.71533 (r=0.563,p=0.980),  time:41.255, tt:5693.199\n",
      "Ep:138, loss:0.00000, loss_test:0.09323, lr:4.43e-03, fs:0.71533 (r=0.563,p=0.980),  time:41.260, tt:5735.085\n",
      "Ep:139, loss:0.00000, loss_test:0.09399, lr:4.39e-03, fs:0.69630 (r=0.540,p=0.979),  time:41.272, tt:5778.054\n",
      "Ep:140, loss:0.00000, loss_test:0.09235, lr:4.34e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.262, tt:5817.901\n",
      "Ep:141, loss:0.00000, loss_test:0.09339, lr:4.30e-03, fs:0.72464 (r=0.575,p=0.980),  time:41.271, tt:5860.443\n",
      "Ep:142, loss:0.00000, loss_test:0.09364, lr:4.26e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.284, tt:5903.682\n",
      "Ep:143, loss:0.00000, loss_test:0.09389, lr:4.21e-03, fs:0.69630 (r=0.540,p=0.979),  time:41.295, tt:5946.512\n",
      "Ep:144, loss:0.00000, loss_test:0.09319, lr:4.17e-03, fs:0.72464 (r=0.575,p=0.980),  time:41.299, tt:5988.323\n",
      "Ep:145, loss:0.00000, loss_test:0.09383, lr:4.13e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.306, tt:6030.745\n",
      "Ep:146, loss:0.00000, loss_test:0.09410, lr:4.09e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.322, tt:6074.263\n",
      "Ep:147, loss:0.00000, loss_test:0.09482, lr:4.05e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.330, tt:6116.817\n",
      "Ep:148, loss:0.00000, loss_test:0.09448, lr:4.01e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.342, tt:6160.016\n",
      "Ep:149, loss:0.00000, loss_test:0.09453, lr:3.97e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.350, tt:6202.547\n",
      "Ep:150, loss:0.00000, loss_test:0.09439, lr:3.93e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.352, tt:6244.085\n",
      "Ep:151, loss:0.00000, loss_test:0.09461, lr:3.89e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.370, tt:6288.230\n",
      "Ep:152, loss:0.00000, loss_test:0.09459, lr:3.85e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.369, tt:6329.470\n",
      "Ep:153, loss:0.00000, loss_test:0.09409, lr:3.81e-03, fs:0.69630 (r=0.540,p=0.979),  time:41.363, tt:6369.911\n",
      "Ep:154, loss:0.00000, loss_test:0.09470, lr:3.77e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.364, tt:6411.442\n",
      "Ep:155, loss:0.00000, loss_test:0.09480, lr:3.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.357, tt:6451.638\n",
      "Ep:156, loss:0.00000, loss_test:0.09350, lr:3.70e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.355, tt:6492.751\n",
      "Ep:157, loss:0.00000, loss_test:0.09465, lr:3.66e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.358, tt:6534.610\n",
      "Ep:158, loss:0.00000, loss_test:0.09531, lr:3.62e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.362, tt:6576.512\n",
      "Ep:159, loss:0.00000, loss_test:0.09330, lr:3.59e-03, fs:0.70588 (r=0.552,p=0.980),  time:41.368, tt:6618.956\n",
      "Ep:160, loss:0.00000, loss_test:0.09513, lr:3.55e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.372, tt:6660.906\n",
      "Ep:161, loss:0.00000, loss_test:0.09517, lr:3.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.378, tt:6703.164\n",
      "Ep:162, loss:0.00000, loss_test:0.09417, lr:3.48e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.383, tt:6745.489\n",
      "Ep:163, loss:0.00000, loss_test:0.09442, lr:3.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.380, tt:6786.343\n",
      "Ep:164, loss:0.00000, loss_test:0.09457, lr:3.41e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.391, tt:6829.501\n",
      "Ep:165, loss:0.00000, loss_test:0.09398, lr:3.38e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.400, tt:6872.453\n",
      "Ep:166, loss:0.00000, loss_test:0.09499, lr:3.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.400, tt:6913.812\n",
      "Ep:167, loss:0.00000, loss_test:0.09481, lr:3.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.398, tt:6954.860\n",
      "Ep:168, loss:0.00000, loss_test:0.09368, lr:3.28e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.390, tt:6994.948\n",
      "Ep:169, loss:0.00000, loss_test:0.09612, lr:3.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.374, tt:7033.616\n",
      "Ep:170, loss:0.00000, loss_test:0.09658, lr:3.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.368, tt:7073.913\n",
      "Ep:171, loss:0.00000, loss_test:0.09455, lr:3.18e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.369, tt:7115.388\n",
      "Ep:172, loss:0.00000, loss_test:0.09451, lr:3.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.373, tt:7157.475\n",
      "Ep:173, loss:0.00000, loss_test:0.09497, lr:3.12e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.368, tt:7198.102\n",
      "Ep:174, loss:0.00000, loss_test:0.09521, lr:3.09e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.364, tt:7238.765\n",
      "Ep:175, loss:0.00000, loss_test:0.09483, lr:3.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.360, tt:7279.323\n",
      "Ep:176, loss:0.00000, loss_test:0.09405, lr:3.02e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.338, tt:7316.856\n",
      "Ep:177, loss:0.00000, loss_test:0.09465, lr:2.99e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.342, tt:7358.864\n",
      "Ep:178, loss:0.00000, loss_test:0.09457, lr:2.96e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.337, tt:7399.335\n",
      "Ep:179, loss:0.00000, loss_test:0.09427, lr:2.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.320, tt:7437.663\n",
      "Ep:180, loss:0.00000, loss_test:0.09480, lr:2.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.322, tt:7479.266\n",
      "Ep:181, loss:0.00000, loss_test:0.09491, lr:2.88e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.313, tt:7519.021\n",
      "Ep:182, loss:0.00000, loss_test:0.09387, lr:2.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.324, tt:7562.291\n",
      "Ep:183, loss:0.00000, loss_test:0.09451, lr:2.82e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.325, tt:7603.879\n",
      "Ep:184, loss:0.00000, loss_test:0.09521, lr:2.79e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.333, tt:7646.622\n",
      "Ep:185, loss:0.00000, loss_test:0.09422, lr:2.76e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.325, tt:7686.380\n",
      "Ep:186, loss:0.00000, loss_test:0.09425, lr:2.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.320, tt:7726.760\n",
      "Ep:187, loss:0.00000, loss_test:0.09422, lr:2.71e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.315, tt:7767.266\n",
      "Ep:188, loss:0.00000, loss_test:0.09392, lr:2.68e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.315, tt:7808.545\n",
      "Ep:189, loss:0.00000, loss_test:0.09444, lr:2.65e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.323, tt:7851.372\n",
      "Ep:190, loss:0.00000, loss_test:0.09483, lr:2.63e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.325, tt:7893.073\n",
      "Ep:191, loss:0.00000, loss_test:0.09441, lr:2.60e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.327, tt:7934.775\n",
      "Ep:192, loss:0.00000, loss_test:0.09450, lr:2.57e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.327, tt:7976.114\n",
      "Ep:193, loss:0.00000, loss_test:0.09472, lr:2.55e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.337, tt:8019.465\n",
      "Ep:194, loss:0.00000, loss_test:0.09458, lr:2.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.337, tt:8060.723\n",
      "Ep:195, loss:0.00000, loss_test:0.09462, lr:2.50e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.333, tt:8101.299\n",
      "Ep:196, loss:0.00000, loss_test:0.09473, lr:2.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.321, tt:8140.144\n",
      "Ep:197, loss:0.00000, loss_test:0.09494, lr:2.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.317, tt:8180.842\n",
      "Ep:198, loss:0.00000, loss_test:0.09488, lr:2.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.308, tt:8220.208\n",
      "Ep:199, loss:0.00000, loss_test:0.09451, lr:2.40e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.313, tt:8262.602\n",
      "Ep:200, loss:0.00000, loss_test:0.09405, lr:2.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.307, tt:8302.650\n",
      "Ep:201, loss:0.00000, loss_test:0.09485, lr:2.35e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.303, tt:8343.258\n",
      "Ep:202, loss:0.00000, loss_test:0.09502, lr:2.33e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.298, tt:8383.554\n",
      "Ep:203, loss:0.00000, loss_test:0.09476, lr:2.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.300, tt:8425.264\n",
      "Ep:204, loss:0.00000, loss_test:0.09420, lr:2.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.286, tt:8463.650\n",
      "Ep:205, loss:0.00000, loss_test:0.09436, lr:2.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.292, tt:8506.130\n",
      "Ep:206, loss:0.00000, loss_test:0.09440, lr:2.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.287, tt:8546.392\n",
      "Ep:207, loss:0.00000, loss_test:0.09434, lr:2.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.293, tt:8588.871\n",
      "Ep:208, loss:0.00000, loss_test:0.09447, lr:2.19e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.293, tt:8630.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.09466, lr:2.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.288, tt:8670.551\n",
      "Ep:210, loss:0.00000, loss_test:0.09410, lr:2.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.293, tt:8712.773\n",
      "Ep:211, loss:0.00000, loss_test:0.09425, lr:2.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.293, tt:8754.014\n",
      "Ep:212, loss:0.00000, loss_test:0.09442, lr:2.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.286, tt:8793.856\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02235, lr:6.00e-02, fs:0.60944 (r=0.816,p=0.486),  time:33.265, tt:33.265\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02363, lr:6.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:30.774, tt:61.547\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02426, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.005, tt:90.016\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02359, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:29.003, tt:116.011\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02279, lr:6.00e-02, fs:0.65306 (r=0.920,p=0.506),  time:29.478, tt:147.392\n",
      "Ep:5, loss:0.00004, loss_test:0.02263, lr:6.00e-02, fs:0.63793 (r=0.851,p=0.510),  time:31.202, tt:187.214\n",
      "Ep:6, loss:0.00004, loss_test:0.02246, lr:6.00e-02, fs:0.59535 (r=0.736,p=0.500),  time:32.637, tt:228.460\n",
      "Ep:7, loss:0.00004, loss_test:0.02149, lr:6.00e-02, fs:0.60748 (r=0.747,p=0.512),  time:33.810, tt:270.479\n",
      "Ep:8, loss:0.00003, loss_test:0.02049, lr:6.00e-02, fs:0.64602 (r=0.839,p=0.525),  time:34.627, tt:311.644\n",
      "Ep:9, loss:0.00003, loss_test:0.01986, lr:6.00e-02, fs:0.67249 (r=0.885,p=0.542),  time:35.164, tt:351.644\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01928, lr:6.00e-02, fs:0.68142 (r=0.885,p=0.554),  time:35.820, tt:394.024\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01890, lr:6.00e-02, fs:0.68493 (r=0.862,p=0.568),  time:36.271, tt:435.253\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01866, lr:6.00e-02, fs:0.69767 (r=0.862,p=0.586),  time:36.622, tt:476.083\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01829, lr:6.00e-02, fs:0.69484 (r=0.851,p=0.587),  time:36.970, tt:517.579\n",
      "Ep:14, loss:0.00003, loss_test:0.01779, lr:6.00e-02, fs:0.71628 (r=0.885,p=0.602),  time:37.208, tt:558.117\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01730, lr:6.00e-02, fs:0.73832 (r=0.908,p=0.622),  time:37.406, tt:598.489\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.74419 (r=0.920,p=0.625),  time:37.621, tt:639.557\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.72897 (r=0.897,p=0.614),  time:37.767, tt:679.801\n",
      "Ep:18, loss:0.00003, loss_test:0.01630, lr:6.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:37.927, tt:720.614\n",
      "Ep:19, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:38.005, tt:760.101\n",
      "Ep:20, loss:0.00003, loss_test:0.01559, lr:6.00e-02, fs:0.76279 (r=0.943,p=0.641),  time:38.057, tt:799.188\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.76279 (r=0.943,p=0.641),  time:38.123, tt:838.695\n",
      "Ep:22, loss:0.00002, loss_test:0.01497, lr:6.00e-02, fs:0.76279 (r=0.943,p=0.641),  time:38.177, tt:878.065\n",
      "Ep:23, loss:0.00002, loss_test:0.01476, lr:6.00e-02, fs:0.77358 (r=0.943,p=0.656),  time:38.244, tt:917.848\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.78095 (r=0.943,p=0.667),  time:38.351, tt:958.787\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.78469 (r=0.943,p=0.672),  time:38.375, tt:997.758\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01413, lr:6.00e-02, fs:0.78846 (r=0.943,p=0.678),  time:38.453, tt:1038.221\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01391, lr:6.00e-02, fs:0.80193 (r=0.954,p=0.692),  time:38.626, tt:1081.529\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.80583 (r=0.954,p=0.697),  time:38.630, tt:1120.257\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.82857 (r=1.000,p=0.707),  time:38.665, tt:1159.945\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.83254 (r=1.000,p=0.713),  time:38.650, tt:1198.150\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.81731 (r=0.977,p=0.702),  time:38.691, tt:1238.112\n",
      "Ep:32, loss:0.00002, loss_test:0.01320, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:38.695, tt:1276.944\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:38.791, tt:1318.909\n",
      "Ep:34, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.82927 (r=0.977,p=0.720),  time:38.867, tt:1360.335\n",
      "Ep:35, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:38.883, tt:1399.773\n",
      "Ep:36, loss:0.00002, loss_test:0.01288, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:38.891, tt:1438.984\n",
      "Ep:37, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:38.917, tt:1478.845\n",
      "Ep:38, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:38.908, tt:1517.397\n",
      "Ep:39, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.84577 (r=0.977,p=0.746),  time:38.952, tt:1558.068\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.84577 (r=0.977,p=0.746),  time:39.036, tt:1600.475\n",
      "Ep:41, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.83417 (r=0.954,p=0.741),  time:39.066, tt:1640.786\n",
      "Ep:42, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.83838 (r=0.954,p=0.748),  time:39.056, tt:1679.426\n",
      "Ep:43, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.83249 (r=0.943,p=0.745),  time:39.100, tt:1720.397\n",
      "Ep:44, loss:0.00001, loss_test:0.01276, lr:6.00e-02, fs:0.83673 (r=0.943,p=0.752),  time:39.098, tt:1759.407\n",
      "Ep:45, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.84103 (r=0.943,p=0.759),  time:39.113, tt:1799.202\n",
      "Ep:46, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.83505 (r=0.931,p=0.757),  time:39.121, tt:1838.698\n",
      "Ep:47, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.82292 (r=0.908,p=0.752),  time:39.144, tt:1878.889\n",
      "Ep:48, loss:0.00001, loss_test:0.01281, lr:6.00e-02, fs:0.81675 (r=0.897,p=0.750),  time:39.177, tt:1919.651\n",
      "Ep:49, loss:0.00001, loss_test:0.01284, lr:6.00e-02, fs:0.81675 (r=0.897,p=0.750),  time:39.219, tt:1960.952\n",
      "Ep:50, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.81481 (r=0.885,p=0.755),  time:39.234, tt:2000.914\n",
      "Ep:51, loss:0.00001, loss_test:0.01289, lr:5.94e-02, fs:0.80214 (r=0.862,p=0.750),  time:39.241, tt:2040.514\n",
      "Ep:52, loss:0.00001, loss_test:0.01296, lr:5.88e-02, fs:0.80645 (r=0.862,p=0.758),  time:39.258, tt:2080.693\n",
      "Ep:53, loss:0.00001, loss_test:0.01300, lr:5.82e-02, fs:0.80645 (r=0.862,p=0.758),  time:39.325, tt:2123.544\n",
      "Ep:54, loss:0.00001, loss_test:0.01298, lr:5.76e-02, fs:0.80645 (r=0.862,p=0.758),  time:39.321, tt:2162.631\n",
      "Ep:55, loss:0.00001, loss_test:0.01309, lr:5.71e-02, fs:0.81081 (r=0.862,p=0.765),  time:39.352, tt:2203.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00001, loss_test:0.01311, lr:5.65e-02, fs:0.80435 (r=0.851,p=0.763),  time:39.391, tt:2245.295\n",
      "Ep:57, loss:0.00001, loss_test:0.01311, lr:5.59e-02, fs:0.79121 (r=0.828,p=0.758),  time:39.409, tt:2285.743\n",
      "Ep:58, loss:0.00001, loss_test:0.01322, lr:5.54e-02, fs:0.79121 (r=0.828,p=0.758),  time:39.419, tt:2325.703\n",
      "Ep:59, loss:0.00001, loss_test:0.01331, lr:5.48e-02, fs:0.79121 (r=0.828,p=0.758),  time:39.446, tt:2366.758\n",
      "Ep:60, loss:0.00001, loss_test:0.01334, lr:5.43e-02, fs:0.79121 (r=0.828,p=0.758),  time:39.470, tt:2407.665\n",
      "Ep:61, loss:0.00001, loss_test:0.01340, lr:5.37e-02, fs:0.79121 (r=0.828,p=0.758),  time:39.470, tt:2447.116\n",
      "Ep:62, loss:0.00001, loss_test:0.01345, lr:5.32e-02, fs:0.79121 (r=0.828,p=0.758),  time:39.504, tt:2488.754\n",
      "Ep:63, loss:0.00001, loss_test:0.01353, lr:5.27e-02, fs:0.77778 (r=0.805,p=0.753),  time:39.525, tt:2529.570\n",
      "Ep:64, loss:0.00001, loss_test:0.01367, lr:5.21e-02, fs:0.78212 (r=0.805,p=0.761),  time:39.546, tt:2570.492\n",
      "Ep:65, loss:0.00001, loss_test:0.01369, lr:5.16e-02, fs:0.78212 (r=0.805,p=0.761),  time:39.578, tt:2612.115\n",
      "Ep:66, loss:0.00001, loss_test:0.01375, lr:5.11e-02, fs:0.78212 (r=0.805,p=0.761),  time:39.612, tt:2654.016\n",
      "Ep:67, loss:0.00001, loss_test:0.01384, lr:5.06e-02, fs:0.78212 (r=0.805,p=0.761),  time:39.620, tt:2694.131\n",
      "Ep:68, loss:0.00001, loss_test:0.01388, lr:5.01e-02, fs:0.78652 (r=0.805,p=0.769),  time:39.639, tt:2735.111\n",
      "Ep:69, loss:0.00001, loss_test:0.01396, lr:4.96e-02, fs:0.78652 (r=0.805,p=0.769),  time:39.665, tt:2776.525\n",
      "Ep:70, loss:0.00001, loss_test:0.01406, lr:4.91e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.675, tt:2816.929\n",
      "Ep:71, loss:0.00001, loss_test:0.01415, lr:4.86e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.663, tt:2855.706\n",
      "Ep:72, loss:0.00001, loss_test:0.01419, lr:4.81e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.648, tt:2894.298\n",
      "Ep:73, loss:0.00001, loss_test:0.01430, lr:4.76e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.664, tt:2935.144\n",
      "Ep:74, loss:0.00001, loss_test:0.01434, lr:4.71e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.680, tt:2976.035\n",
      "Ep:75, loss:0.00001, loss_test:0.01447, lr:4.67e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.676, tt:3015.371\n",
      "Ep:76, loss:0.00001, loss_test:0.01460, lr:4.62e-02, fs:0.79096 (r=0.805,p=0.778),  time:39.691, tt:3056.230\n",
      "Ep:77, loss:0.00001, loss_test:0.01467, lr:4.57e-02, fs:0.79545 (r=0.805,p=0.787),  time:39.692, tt:3095.989\n",
      "Ep:78, loss:0.00001, loss_test:0.01472, lr:4.53e-02, fs:0.79545 (r=0.805,p=0.787),  time:39.692, tt:3135.648\n",
      "Ep:79, loss:0.00001, loss_test:0.01476, lr:4.48e-02, fs:0.80000 (r=0.805,p=0.795),  time:39.688, tt:3175.003\n",
      "Ep:80, loss:0.00001, loss_test:0.01488, lr:4.44e-02, fs:0.80000 (r=0.805,p=0.795),  time:39.709, tt:3216.446\n",
      "Ep:81, loss:0.00001, loss_test:0.01494, lr:4.39e-02, fs:0.80000 (r=0.805,p=0.795),  time:39.692, tt:3254.740\n",
      "Ep:82, loss:0.00001, loss_test:0.01513, lr:4.35e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.724, tt:3297.082\n",
      "Ep:83, loss:0.00001, loss_test:0.01517, lr:4.31e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.723, tt:3336.725\n",
      "Ep:84, loss:0.00001, loss_test:0.01525, lr:4.26e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.723, tt:3376.441\n",
      "Ep:85, loss:0.00001, loss_test:0.01533, lr:4.22e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.733, tt:3417.040\n",
      "Ep:86, loss:0.00001, loss_test:0.01540, lr:4.18e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.736, tt:3457.030\n",
      "Ep:87, loss:0.00001, loss_test:0.01547, lr:4.14e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.755, tt:3498.419\n",
      "Ep:88, loss:0.00001, loss_test:0.01562, lr:4.10e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.763, tt:3538.903\n",
      "Ep:89, loss:0.00001, loss_test:0.01566, lr:4.05e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.761, tt:3578.505\n",
      "Ep:90, loss:0.00001, loss_test:0.01579, lr:4.01e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.768, tt:3618.885\n",
      "Ep:91, loss:0.00001, loss_test:0.01591, lr:3.97e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.773, tt:3659.075\n",
      "Ep:92, loss:0.00001, loss_test:0.01590, lr:3.93e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.783, tt:3699.830\n",
      "Ep:93, loss:0.00001, loss_test:0.01604, lr:3.89e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.797, tt:3740.873\n",
      "Ep:94, loss:0.00001, loss_test:0.01611, lr:3.86e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.820, tt:3782.888\n",
      "Ep:95, loss:0.00001, loss_test:0.01610, lr:3.82e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.825, tt:3823.192\n",
      "Ep:96, loss:0.00001, loss_test:0.01624, lr:3.78e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.843, tt:3864.759\n",
      "Ep:97, loss:0.00001, loss_test:0.01637, lr:3.74e-02, fs:0.80460 (r=0.805,p=0.805),  time:39.841, tt:3904.406\n",
      "Ep:98, loss:0.00001, loss_test:0.01642, lr:3.70e-02, fs:0.80925 (r=0.805,p=0.814),  time:39.841, tt:3944.284\n",
      "Ep:99, loss:0.00001, loss_test:0.01654, lr:3.67e-02, fs:0.79769 (r=0.793,p=0.802),  time:39.849, tt:3984.927\n",
      "Ep:100, loss:0.00001, loss_test:0.01659, lr:3.63e-02, fs:0.80925 (r=0.805,p=0.814),  time:39.857, tt:4025.569\n",
      "Ep:101, loss:0.00001, loss_test:0.01663, lr:3.59e-02, fs:0.80925 (r=0.805,p=0.814),  time:39.874, tt:4067.195\n",
      "Ep:102, loss:0.00001, loss_test:0.01677, lr:3.56e-02, fs:0.80925 (r=0.805,p=0.814),  time:39.871, tt:4106.690\n",
      "Ep:103, loss:0.00001, loss_test:0.01679, lr:3.52e-02, fs:0.81395 (r=0.805,p=0.824),  time:39.872, tt:4146.637\n",
      "Ep:104, loss:0.00001, loss_test:0.01687, lr:3.49e-02, fs:0.80702 (r=0.793,p=0.821),  time:39.891, tt:4188.524\n",
      "Ep:105, loss:0.00001, loss_test:0.01689, lr:3.45e-02, fs:0.81871 (r=0.805,p=0.833),  time:39.903, tt:4229.672\n",
      "Ep:106, loss:0.00001, loss_test:0.01697, lr:3.42e-02, fs:0.81871 (r=0.805,p=0.833),  time:39.914, tt:4270.779\n",
      "Ep:107, loss:0.00001, loss_test:0.01713, lr:3.38e-02, fs:0.81176 (r=0.793,p=0.831),  time:39.916, tt:4310.969\n",
      "Ep:108, loss:0.00001, loss_test:0.01717, lr:3.35e-02, fs:0.81871 (r=0.805,p=0.833),  time:39.925, tt:4351.835\n",
      "Ep:109, loss:0.00001, loss_test:0.01724, lr:3.32e-02, fs:0.81176 (r=0.793,p=0.831),  time:39.937, tt:4393.085\n",
      "Ep:110, loss:0.00001, loss_test:0.01728, lr:3.28e-02, fs:0.81176 (r=0.793,p=0.831),  time:39.943, tt:4433.712\n",
      "Ep:111, loss:0.00001, loss_test:0.01731, lr:3.25e-02, fs:0.81176 (r=0.793,p=0.831),  time:39.951, tt:4474.475\n",
      "Ep:112, loss:0.00001, loss_test:0.01741, lr:3.22e-02, fs:0.81176 (r=0.793,p=0.831),  time:39.955, tt:4514.971\n",
      "Ep:113, loss:0.00001, loss_test:0.01751, lr:3.19e-02, fs:0.81657 (r=0.793,p=0.841),  time:39.961, tt:4555.525\n",
      "Ep:114, loss:0.00001, loss_test:0.01752, lr:3.15e-02, fs:0.81657 (r=0.793,p=0.841),  time:39.964, tt:4595.836\n",
      "Ep:115, loss:0.00000, loss_test:0.01760, lr:3.12e-02, fs:0.81657 (r=0.793,p=0.841),  time:39.999, tt:4639.862\n",
      "Ep:116, loss:0.00000, loss_test:0.01767, lr:3.09e-02, fs:0.81657 (r=0.793,p=0.841),  time:40.005, tt:4680.618\n",
      "Ep:117, loss:0.00000, loss_test:0.01774, lr:3.06e-02, fs:0.82143 (r=0.793,p=0.852),  time:40.013, tt:4721.571\n",
      "Ep:118, loss:0.00000, loss_test:0.01783, lr:3.03e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.016, tt:4761.943\n",
      "Ep:119, loss:0.00000, loss_test:0.01786, lr:3.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:40.039, tt:4804.656\n",
      "Ep:120, loss:0.00000, loss_test:0.01792, lr:2.97e-02, fs:0.82143 (r=0.793,p=0.852),  time:40.056, tt:4846.785\n",
      "Ep:121, loss:0.00000, loss_test:0.01799, lr:2.94e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.076, tt:4889.233\n",
      "Ep:122, loss:0.00000, loss_test:0.01806, lr:2.91e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.084, tt:4930.363\n",
      "Ep:123, loss:0.00000, loss_test:0.01812, lr:2.88e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.107, tt:4973.231\n",
      "Ep:124, loss:0.00000, loss_test:0.01811, lr:2.85e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.110, tt:5013.810\n",
      "Ep:125, loss:0.00000, loss_test:0.01818, lr:2.82e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.113, tt:5054.192\n",
      "Ep:126, loss:0.00000, loss_test:0.01825, lr:2.80e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.123, tt:5095.673\n",
      "Ep:127, loss:0.00000, loss_test:0.01826, lr:2.77e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.120, tt:5135.385\n",
      "Ep:128, loss:0.00000, loss_test:0.01835, lr:2.74e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.111, tt:5174.311\n",
      "Ep:129, loss:0.00000, loss_test:0.01842, lr:2.71e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.120, tt:5215.546\n",
      "Ep:130, loss:0.00000, loss_test:0.01846, lr:2.69e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.121, tt:5255.805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.01854, lr:2.66e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.131, tt:5297.340\n",
      "Ep:132, loss:0.00000, loss_test:0.01852, lr:2.63e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.178, tt:5343.724\n",
      "Ep:133, loss:0.00000, loss_test:0.01858, lr:2.61e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.173, tt:5383.155\n",
      "Ep:134, loss:0.00000, loss_test:0.01866, lr:2.58e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.177, tt:5423.918\n",
      "Ep:135, loss:0.00000, loss_test:0.01868, lr:2.55e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.179, tt:5464.399\n",
      "Ep:136, loss:0.00000, loss_test:0.01869, lr:2.53e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.195, tt:5506.673\n",
      "Ep:137, loss:0.00000, loss_test:0.01873, lr:2.50e-02, fs:0.81928 (r=0.782,p=0.861),  time:40.206, tt:5548.363\n",
      "Ep:138, loss:0.00000, loss_test:0.01876, lr:2.48e-02, fs:0.81928 (r=0.782,p=0.861),  time:40.200, tt:5587.845\n",
      "Ep:139, loss:0.00000, loss_test:0.01880, lr:2.45e-02, fs:0.81928 (r=0.782,p=0.861),  time:40.208, tt:5629.087\n",
      "Ep:140, loss:0.00000, loss_test:0.01885, lr:2.43e-02, fs:0.82424 (r=0.782,p=0.872),  time:40.222, tt:5671.359\n",
      "Ep:141, loss:0.00000, loss_test:0.01895, lr:2.40e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.230, tt:5712.682\n",
      "Ep:142, loss:0.00000, loss_test:0.01897, lr:2.38e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.234, tt:5753.493\n",
      "Ep:143, loss:0.00000, loss_test:0.01904, lr:2.36e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.238, tt:5794.276\n",
      "Ep:144, loss:0.00000, loss_test:0.01910, lr:2.33e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.243, tt:5835.263\n",
      "Ep:145, loss:0.00000, loss_test:0.01906, lr:2.31e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.246, tt:5875.942\n",
      "Ep:146, loss:0.00000, loss_test:0.01909, lr:2.29e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.249, tt:5916.554\n",
      "Ep:147, loss:0.00000, loss_test:0.01918, lr:2.26e-02, fs:0.80247 (r=0.747,p=0.867),  time:40.252, tt:5957.297\n",
      "Ep:148, loss:0.00000, loss_test:0.01919, lr:2.24e-02, fs:0.81707 (r=0.770,p=0.870),  time:40.240, tt:5995.692\n",
      "Ep:149, loss:0.00000, loss_test:0.01928, lr:2.22e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.257, tt:6038.563\n",
      "Ep:150, loss:0.00000, loss_test:0.01930, lr:2.20e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.259, tt:6079.073\n",
      "Ep:151, loss:0.00000, loss_test:0.01925, lr:2.17e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.268, tt:6120.720\n",
      "Ep:152, loss:0.00000, loss_test:0.01935, lr:2.15e-02, fs:0.79503 (r=0.736,p=0.865),  time:40.263, tt:6160.170\n",
      "Ep:153, loss:0.00000, loss_test:0.01940, lr:2.13e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.268, tt:6201.226\n",
      "Ep:154, loss:0.00000, loss_test:0.01941, lr:2.11e-02, fs:0.80247 (r=0.747,p=0.867),  time:40.278, tt:6243.121\n",
      "Ep:155, loss:0.00000, loss_test:0.01940, lr:2.09e-02, fs:0.80247 (r=0.747,p=0.867),  time:40.275, tt:6282.958\n",
      "Ep:156, loss:0.00000, loss_test:0.01951, lr:2.07e-02, fs:0.75641 (r=0.678,p=0.855),  time:40.283, tt:6324.472\n",
      "Ep:157, loss:0.00000, loss_test:0.01951, lr:2.05e-02, fs:0.78750 (r=0.724,p=0.863),  time:40.279, tt:6364.059\n",
      "Ep:158, loss:0.00000, loss_test:0.01950, lr:2.03e-02, fs:0.80745 (r=0.747,p=0.878),  time:40.273, tt:6403.452\n",
      "Ep:159, loss:0.00000, loss_test:0.01959, lr:2.01e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.279, tt:6444.666\n",
      "Ep:160, loss:0.00000, loss_test:0.01963, lr:1.99e-02, fs:0.76129 (r=0.678,p=0.868),  time:40.287, tt:6486.194\n",
      "Ep:161, loss:0.00000, loss_test:0.01959, lr:1.97e-02, fs:0.81250 (r=0.747,p=0.890),  time:40.285, tt:6526.175\n",
      "Ep:162, loss:0.00000, loss_test:0.01965, lr:1.95e-02, fs:0.80503 (r=0.736,p=0.889),  time:40.281, tt:6565.765\n",
      "Ep:163, loss:0.00000, loss_test:0.01975, lr:1.93e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.286, tt:6606.969\n",
      "Ep:164, loss:0.00000, loss_test:0.01977, lr:1.91e-02, fs:0.75817 (r=0.667,p=0.879),  time:40.280, tt:6646.126\n",
      "Ep:165, loss:0.00000, loss_test:0.01975, lr:1.89e-02, fs:0.80503 (r=0.736,p=0.889),  time:40.282, tt:6686.730\n",
      "Ep:166, loss:0.00000, loss_test:0.01980, lr:1.87e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.288, tt:6728.053\n",
      "Ep:167, loss:0.00000, loss_test:0.01984, lr:1.85e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.295, tt:6769.502\n",
      "Ep:168, loss:0.00000, loss_test:0.01984, lr:1.83e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.309, tt:6812.257\n",
      "Ep:169, loss:0.00000, loss_test:0.01986, lr:1.81e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.295, tt:6850.196\n",
      "Ep:170, loss:0.00000, loss_test:0.01993, lr:1.80e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.299, tt:6891.176\n",
      "Ep:171, loss:0.00000, loss_test:0.01996, lr:1.78e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.320, tt:6934.956\n",
      "Ep:172, loss:0.00000, loss_test:0.01993, lr:1.76e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.321, tt:6975.478\n",
      "Ep:173, loss:0.00000, loss_test:0.01996, lr:1.74e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.317, tt:7015.225\n",
      "Ep:174, loss:0.00000, loss_test:0.02005, lr:1.73e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.325, tt:7056.848\n",
      "Ep:175, loss:0.00000, loss_test:0.02004, lr:1.71e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.317, tt:7095.860\n",
      "Ep:176, loss:0.00000, loss_test:0.02004, lr:1.69e-02, fs:0.76623 (r=0.678,p=0.881),  time:40.329, tt:7138.258\n",
      "Ep:177, loss:0.00000, loss_test:0.02008, lr:1.67e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.339, tt:7180.299\n",
      "Ep:178, loss:0.00000, loss_test:0.02009, lr:1.66e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.346, tt:7221.973\n",
      "Ep:179, loss:0.00000, loss_test:0.02011, lr:1.64e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.344, tt:7261.949\n",
      "Ep:180, loss:0.00000, loss_test:0.02013, lr:1.62e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.351, tt:7303.528\n",
      "Ep:181, loss:0.00000, loss_test:0.02020, lr:1.61e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.355, tt:7344.552\n",
      "Ep:182, loss:0.00000, loss_test:0.02022, lr:1.59e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.391, tt:7391.636\n",
      "Ep:183, loss:0.00000, loss_test:0.02019, lr:1.58e-02, fs:0.75000 (r=0.655,p=0.877),  time:40.397, tt:7433.047\n",
      "Ep:184, loss:0.00000, loss_test:0.02022, lr:1.56e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.404, tt:7474.802\n",
      "Ep:185, loss:0.00000, loss_test:0.02029, lr:1.54e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.400, tt:7514.480\n",
      "Ep:186, loss:0.00000, loss_test:0.02031, lr:1.53e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.397, tt:7554.330\n",
      "Ep:187, loss:0.00000, loss_test:0.02031, lr:1.51e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.389, tt:7593.215\n",
      "Ep:188, loss:0.00000, loss_test:0.02035, lr:1.50e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.387, tt:7633.141\n",
      "Ep:189, loss:0.00000, loss_test:0.02038, lr:1.48e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.384, tt:7672.939\n",
      "Ep:190, loss:0.00000, loss_test:0.02036, lr:1.47e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.389, tt:7714.299\n",
      "Ep:191, loss:0.00000, loss_test:0.02038, lr:1.45e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.394, tt:7755.708\n",
      "Ep:192, loss:0.00000, loss_test:0.02042, lr:1.44e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.400, tt:7797.128\n",
      "Ep:193, loss:0.00000, loss_test:0.02044, lr:1.43e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.399, tt:7837.358\n",
      "Ep:194, loss:0.00000, loss_test:0.02045, lr:1.41e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.399, tt:7877.860\n",
      "Ep:195, loss:0.00000, loss_test:0.02048, lr:1.40e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.405, tt:7919.291\n",
      "Ep:196, loss:0.00000, loss_test:0.02050, lr:1.38e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.405, tt:7959.706\n",
      "Ep:197, loss:0.00000, loss_test:0.02049, lr:1.37e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.406, tt:8000.369\n",
      "Ep:198, loss:0.00000, loss_test:0.02052, lr:1.36e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.403, tt:8040.237\n",
      "Ep:199, loss:0.00000, loss_test:0.02051, lr:1.34e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.411, tt:8082.293\n",
      "Ep:200, loss:0.00000, loss_test:0.02055, lr:1.33e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.420, tt:8124.463\n",
      "Ep:201, loss:0.00000, loss_test:0.02057, lr:1.32e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.424, tt:8165.674\n",
      "Ep:202, loss:0.00000, loss_test:0.02059, lr:1.30e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.429, tt:8207.096\n",
      "Ep:203, loss:0.00000, loss_test:0.02064, lr:1.29e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.433, tt:8248.243\n",
      "Ep:204, loss:0.00000, loss_test:0.02064, lr:1.28e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.436, tt:8289.481\n",
      "Ep:205, loss:0.00000, loss_test:0.02065, lr:1.26e-02, fs:0.73333 (r=0.632,p=0.873),  time:40.435, tt:8329.701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.02068, lr:1.25e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.433, tt:8369.537\n",
      "Ep:207, loss:0.00000, loss_test:0.02068, lr:1.24e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.438, tt:8411.160\n",
      "Ep:208, loss:0.00000, loss_test:0.02066, lr:1.23e-02, fs:0.73333 (r=0.632,p=0.873),  time:40.435, tt:8450.943\n",
      "Ep:209, loss:0.00000, loss_test:0.02070, lr:1.21e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.436, tt:8491.491\n",
      "Ep:210, loss:0.00000, loss_test:0.02074, lr:1.20e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.438, tt:8532.461\n",
      "Ep:211, loss:0.00000, loss_test:0.02073, lr:1.19e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.465, tt:8578.483\n",
      "Ep:212, loss:0.00000, loss_test:0.02074, lr:1.18e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.469, tt:8619.823\n",
      "Ep:213, loss:0.00000, loss_test:0.02078, lr:1.17e-02, fs:0.72483 (r=0.621,p=0.871),  time:40.471, tt:8660.755\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14661, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.796, tt:38.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14557, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.047, tt:74.093\n",
      "Ep:2, loss:0.00027, loss_test:0.14351, lr:1.00e-02, fs:0.66148 (r=0.977,p=0.500),  time:36.403, tt:109.209\n",
      "Ep:3, loss:0.00026, loss_test:0.13935, lr:1.00e-02, fs:0.62447 (r=0.851,p=0.493),  time:36.623, tt:146.492\n",
      "Ep:4, loss:0.00024, loss_test:0.13737, lr:1.00e-02, fs:0.59716 (r=0.724,p=0.508),  time:36.390, tt:181.951\n",
      "Ep:5, loss:0.00023, loss_test:0.13656, lr:1.00e-02, fs:0.60317 (r=0.655,p=0.559),  time:37.115, tt:222.690\n",
      "Ep:6, loss:0.00023, loss_test:0.13317, lr:1.00e-02, fs:0.62295 (r=0.655,p=0.594),  time:37.576, tt:263.033\n",
      "Ep:7, loss:0.00022, loss_test:0.12928, lr:1.00e-02, fs:0.60204 (r=0.678,p=0.541),  time:38.177, tt:305.412\n",
      "Ep:8, loss:0.00021, loss_test:0.12570, lr:1.00e-02, fs:0.63366 (r=0.736,p=0.557),  time:38.535, tt:346.811\n",
      "Ep:9, loss:0.00021, loss_test:0.12153, lr:1.00e-02, fs:0.61538 (r=0.644,p=0.589),  time:38.932, tt:389.325\n",
      "Ep:10, loss:0.00020, loss_test:0.11854, lr:1.00e-02, fs:0.61714 (r=0.621,p=0.614),  time:39.169, tt:430.864\n",
      "Ep:11, loss:0.00020, loss_test:0.11492, lr:1.00e-02, fs:0.63736 (r=0.667,p=0.611),  time:39.387, tt:472.647\n",
      "Ep:12, loss:0.00019, loss_test:0.11151, lr:9.90e-03, fs:0.65241 (r=0.701,p=0.610),  time:39.591, tt:514.686\n",
      "Ep:13, loss:0.00018, loss_test:0.10756, lr:9.80e-03, fs:0.68508 (r=0.713,p=0.660),  time:39.703, tt:555.841\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10439, lr:9.80e-03, fs:0.67045 (r=0.678,p=0.663),  time:40.013, tt:600.189\n",
      "Ep:15, loss:0.00017, loss_test:0.10114, lr:9.80e-03, fs:0.70787 (r=0.724,p=0.692),  time:40.240, tt:643.842\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09877, lr:9.80e-03, fs:0.74595 (r=0.793,p=0.704),  time:40.330, tt:685.609\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09701, lr:9.80e-03, fs:0.77596 (r=0.816,p=0.740),  time:40.705, tt:732.681\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09392, lr:9.80e-03, fs:0.75281 (r=0.770,p=0.736),  time:40.680, tt:772.922\n",
      "Ep:19, loss:0.00015, loss_test:0.09220, lr:9.80e-03, fs:0.80214 (r=0.862,p=0.750),  time:40.687, tt:813.734\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09104, lr:9.80e-03, fs:0.81319 (r=0.851,p=0.779),  time:40.715, tt:855.006\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08895, lr:9.80e-03, fs:0.81522 (r=0.862,p=0.773),  time:40.742, tt:896.318\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08746, lr:9.80e-03, fs:0.80645 (r=0.862,p=0.758),  time:40.755, tt:937.365\n",
      "Ep:23, loss:0.00013, loss_test:0.08511, lr:9.80e-03, fs:0.82222 (r=0.851,p=0.796),  time:40.786, tt:978.861\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08375, lr:9.80e-03, fs:0.83871 (r=0.897,p=0.788),  time:40.858, tt:1021.455\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08252, lr:9.80e-03, fs:0.83060 (r=0.874,p=0.792),  time:40.867, tt:1062.555\n",
      "Ep:26, loss:0.00012, loss_test:0.08017, lr:9.80e-03, fs:0.82873 (r=0.862,p=0.798),  time:40.840, tt:1102.667\n",
      "Ep:27, loss:0.00012, loss_test:0.07859, lr:9.80e-03, fs:0.86022 (r=0.920,p=0.808),  time:40.864, tt:1144.192\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.07787, lr:9.80e-03, fs:0.84746 (r=0.862,p=0.833),  time:40.917, tt:1186.604\n",
      "Ep:29, loss:0.00011, loss_test:0.07651, lr:9.80e-03, fs:0.85561 (r=0.920,p=0.800),  time:40.935, tt:1228.044\n",
      "Ep:30, loss:0.00011, loss_test:0.07558, lr:9.80e-03, fs:0.87640 (r=0.897,p=0.857),  time:40.992, tt:1270.747\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.07490, lr:9.80e-03, fs:0.84916 (r=0.874,p=0.826),  time:41.027, tt:1312.854\n",
      "Ep:32, loss:0.00010, loss_test:0.07357, lr:9.80e-03, fs:0.87006 (r=0.885,p=0.856),  time:41.022, tt:1353.728\n",
      "Ep:33, loss:0.00009, loss_test:0.07298, lr:9.80e-03, fs:0.88043 (r=0.931,p=0.835),  time:41.039, tt:1395.335\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.07308, lr:9.80e-03, fs:0.87006 (r=0.885,p=0.856),  time:41.039, tt:1436.364\n",
      "Ep:35, loss:0.00009, loss_test:0.07190, lr:9.80e-03, fs:0.89130 (r=0.943,p=0.845),  time:41.059, tt:1478.128\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07287, lr:9.80e-03, fs:0.86517 (r=0.885,p=0.846),  time:41.059, tt:1519.166\n",
      "Ep:37, loss:0.00008, loss_test:0.07182, lr:9.80e-03, fs:0.89385 (r=0.920,p=0.870),  time:41.078, tt:1560.958\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07223, lr:9.80e-03, fs:0.85057 (r=0.851,p=0.851),  time:41.066, tt:1601.555\n",
      "Ep:39, loss:0.00008, loss_test:0.07298, lr:9.80e-03, fs:0.84337 (r=0.805,p=0.886),  time:40.977, tt:1639.063\n",
      "Ep:40, loss:0.00008, loss_test:0.07306, lr:9.80e-03, fs:0.85380 (r=0.839,p=0.869),  time:40.981, tt:1680.239\n",
      "Ep:41, loss:0.00007, loss_test:0.07235, lr:9.80e-03, fs:0.87293 (r=0.908,p=0.840),  time:40.965, tt:1720.514\n",
      "Ep:42, loss:0.00007, loss_test:0.07560, lr:9.80e-03, fs:0.79487 (r=0.713,p=0.899),  time:40.957, tt:1761.133\n",
      "Ep:43, loss:0.00007, loss_test:0.07293, lr:9.80e-03, fs:0.87293 (r=0.908,p=0.840),  time:40.950, tt:1801.800\n",
      "Ep:44, loss:0.00007, loss_test:0.07527, lr:9.80e-03, fs:0.79487 (r=0.713,p=0.899),  time:40.921, tt:1841.424\n",
      "Ep:45, loss:0.00007, loss_test:0.07319, lr:9.80e-03, fs:0.85057 (r=0.851,p=0.851),  time:40.926, tt:1882.599\n",
      "Ep:46, loss:0.00006, loss_test:0.07489, lr:9.80e-03, fs:0.81988 (r=0.759,p=0.892),  time:40.884, tt:1921.562\n",
      "Ep:47, loss:0.00006, loss_test:0.07287, lr:9.80e-03, fs:0.85556 (r=0.885,p=0.828),  time:40.940, tt:1965.099\n",
      "Ep:48, loss:0.00006, loss_test:0.07890, lr:9.80e-03, fs:0.71724 (r=0.598,p=0.897),  time:40.975, tt:2007.781\n",
      "Ep:49, loss:0.00006, loss_test:0.07137, lr:9.70e-03, fs:0.87568 (r=0.931,p=0.827),  time:40.970, tt:2048.476\n",
      "Ep:50, loss:0.00006, loss_test:0.07850, lr:9.61e-03, fs:0.74324 (r=0.632,p=0.902),  time:40.961, tt:2089.029\n",
      "Ep:51, loss:0.00005, loss_test:0.07193, lr:9.51e-03, fs:0.86667 (r=0.897,p=0.839),  time:40.987, tt:2131.319\n",
      "Ep:52, loss:0.00005, loss_test:0.07857, lr:9.41e-03, fs:0.70833 (r=0.586,p=0.895),  time:40.946, tt:2170.138\n",
      "Ep:53, loss:0.00005, loss_test:0.07187, lr:9.32e-03, fs:0.87356 (r=0.874,p=0.874),  time:41.025, tt:2215.330\n",
      "Ep:54, loss:0.00005, loss_test:0.07912, lr:9.23e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.011, tt:2255.621\n",
      "Ep:55, loss:0.00005, loss_test:0.07361, lr:9.14e-03, fs:0.78750 (r=0.724,p=0.863),  time:41.031, tt:2297.749\n",
      "Ep:56, loss:0.00005, loss_test:0.07638, lr:9.04e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.026, tt:2338.471\n",
      "Ep:57, loss:0.00004, loss_test:0.07610, lr:8.95e-03, fs:0.73826 (r=0.632,p=0.887),  time:41.009, tt:2378.541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00004, loss_test:0.07410, lr:8.86e-03, fs:0.75000 (r=0.655,p=0.877),  time:41.022, tt:2420.284\n",
      "Ep:59, loss:0.00004, loss_test:0.08042, lr:8.78e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.016, tt:2460.939\n",
      "Ep:60, loss:0.00004, loss_test:0.07464, lr:8.69e-03, fs:0.77707 (r=0.701,p=0.871),  time:41.009, tt:2501.550\n",
      "Ep:61, loss:0.00004, loss_test:0.08206, lr:8.60e-03, fs:0.70000 (r=0.563,p=0.925),  time:41.007, tt:2542.405\n",
      "Ep:62, loss:0.00004, loss_test:0.07485, lr:8.51e-03, fs:0.77124 (r=0.678,p=0.894),  time:41.009, tt:2583.588\n",
      "Ep:63, loss:0.00004, loss_test:0.08362, lr:8.43e-03, fs:0.70000 (r=0.563,p=0.925),  time:41.002, tt:2624.119\n",
      "Ep:64, loss:0.00004, loss_test:0.07680, lr:8.35e-03, fs:0.75168 (r=0.644,p=0.903),  time:40.997, tt:2664.787\n",
      "Ep:65, loss:0.00004, loss_test:0.08358, lr:8.26e-03, fs:0.72727 (r=0.598,p=0.929),  time:40.986, tt:2705.098\n",
      "Ep:66, loss:0.00004, loss_test:0.07619, lr:8.18e-03, fs:0.69014 (r=0.563,p=0.891),  time:40.985, tt:2745.982\n",
      "Ep:67, loss:0.00003, loss_test:0.08335, lr:8.10e-03, fs:0.67153 (r=0.529,p=0.920),  time:40.993, tt:2787.519\n",
      "Ep:68, loss:0.00003, loss_test:0.07664, lr:8.02e-03, fs:0.74324 (r=0.632,p=0.902),  time:40.997, tt:2828.790\n",
      "Ep:69, loss:0.00003, loss_test:0.08280, lr:7.94e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.027, tt:2871.898\n",
      "Ep:70, loss:0.00003, loss_test:0.07740, lr:7.86e-03, fs:0.71724 (r=0.598,p=0.897),  time:41.025, tt:2912.797\n",
      "Ep:71, loss:0.00003, loss_test:0.08107, lr:7.78e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.035, tt:2954.496\n",
      "Ep:72, loss:0.00003, loss_test:0.08280, lr:7.70e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.011, tt:2993.827\n",
      "Ep:73, loss:0.00003, loss_test:0.07986, lr:7.62e-03, fs:0.73611 (r=0.609,p=0.930),  time:41.009, tt:3034.700\n",
      "Ep:74, loss:0.00003, loss_test:0.08402, lr:7.55e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.027, tt:3076.999\n",
      "Ep:75, loss:0.00003, loss_test:0.08155, lr:7.47e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.004, tt:3116.319\n",
      "Ep:76, loss:0.00003, loss_test:0.08125, lr:7.40e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.001, tt:3157.109\n",
      "Ep:77, loss:0.00003, loss_test:0.08354, lr:7.32e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.021, tt:3199.615\n",
      "Ep:78, loss:0.00003, loss_test:0.08181, lr:7.25e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.010, tt:3239.811\n",
      "Ep:79, loss:0.00002, loss_test:0.08149, lr:7.18e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.020, tt:3281.585\n",
      "Ep:80, loss:0.00002, loss_test:0.08315, lr:7.11e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.041, tt:3324.320\n",
      "Ep:81, loss:0.00002, loss_test:0.08212, lr:7.03e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.057, tt:3366.711\n",
      "Ep:82, loss:0.00002, loss_test:0.08346, lr:6.96e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.057, tt:3407.767\n",
      "Ep:83, loss:0.00002, loss_test:0.08176, lr:6.89e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.037, tt:3447.110\n",
      "Ep:84, loss:0.00002, loss_test:0.08177, lr:6.83e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.038, tt:3488.198\n",
      "Ep:85, loss:0.00002, loss_test:0.08601, lr:6.76e-03, fs:0.72857 (r=0.586,p=0.962),  time:41.045, tt:3529.901\n",
      "Ep:86, loss:0.00002, loss_test:0.07939, lr:6.69e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.042, tt:3570.626\n",
      "Ep:87, loss:0.00002, loss_test:0.09012, lr:6.62e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.032, tt:3610.854\n",
      "Ep:88, loss:0.00002, loss_test:0.08130, lr:6.56e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.007, tt:3649.659\n",
      "Ep:89, loss:0.00002, loss_test:0.08579, lr:6.49e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.000, tt:3689.987\n",
      "Ep:90, loss:0.00002, loss_test:0.08854, lr:6.43e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.002, tt:3731.204\n",
      "Ep:91, loss:0.00002, loss_test:0.08240, lr:6.36e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.010, tt:3772.932\n",
      "Ep:92, loss:0.00002, loss_test:0.08813, lr:6.30e-03, fs:0.67164 (r=0.517,p=0.957),  time:40.994, tt:3812.475\n",
      "Ep:93, loss:0.00002, loss_test:0.08633, lr:6.24e-03, fs:0.68148 (r=0.529,p=0.958),  time:40.997, tt:3853.717\n",
      "Ep:94, loss:0.00002, loss_test:0.08441, lr:6.17e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.023, tt:3897.194\n",
      "Ep:95, loss:0.00002, loss_test:0.08827, lr:6.11e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.047, tt:3940.510\n",
      "Ep:96, loss:0.00002, loss_test:0.08509, lr:6.05e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.070, tt:3983.745\n",
      "Ep:97, loss:0.00002, loss_test:0.08972, lr:5.99e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.064, tt:4024.247\n",
      "Ep:98, loss:0.00002, loss_test:0.08984, lr:5.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.051, tt:4064.007\n",
      "Ep:99, loss:0.00002, loss_test:0.08955, lr:5.87e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.070, tt:4107.041\n",
      "Ep:100, loss:0.00002, loss_test:0.08845, lr:5.81e-03, fs:0.71014 (r=0.563,p=0.961),  time:41.072, tt:4148.264\n",
      "Ep:101, loss:0.00002, loss_test:0.08971, lr:5.75e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.055, tt:4187.634\n",
      "Ep:102, loss:0.00002, loss_test:0.09106, lr:5.70e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.050, tt:4228.201\n",
      "Ep:103, loss:0.00002, loss_test:0.09006, lr:5.64e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.061, tt:4270.364\n",
      "Ep:104, loss:0.00001, loss_test:0.09009, lr:5.58e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.058, tt:4311.091\n",
      "Ep:105, loss:0.00001, loss_test:0.09135, lr:5.53e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.067, tt:4353.097\n",
      "Ep:106, loss:0.00001, loss_test:0.09253, lr:5.47e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.077, tt:4395.208\n",
      "Ep:107, loss:0.00001, loss_test:0.09135, lr:5.42e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.062, tt:4434.695\n",
      "Ep:108, loss:0.00001, loss_test:0.09296, lr:5.36e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.075, tt:4477.161\n",
      "Ep:109, loss:0.00001, loss_test:0.09465, lr:5.31e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.073, tt:4517.981\n",
      "Ep:110, loss:0.00001, loss_test:0.09304, lr:5.26e-03, fs:0.70073 (r=0.552,p=0.960),  time:41.081, tt:4559.987\n",
      "Ep:111, loss:0.00001, loss_test:0.09370, lr:5.20e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.085, tt:4601.518\n",
      "Ep:112, loss:0.00001, loss_test:0.09527, lr:5.15e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.079, tt:4641.892\n",
      "Ep:113, loss:0.00001, loss_test:0.09473, lr:5.10e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.086, tt:4683.824\n",
      "Ep:114, loss:0.00001, loss_test:0.09583, lr:5.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.097, tt:4726.144\n",
      "Ep:115, loss:0.00001, loss_test:0.09409, lr:5.00e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.079, tt:4765.169\n",
      "Ep:116, loss:0.00001, loss_test:0.09729, lr:4.95e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.054, tt:4803.358\n",
      "Ep:117, loss:0.00001, loss_test:0.09411, lr:4.90e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.053, tt:4844.198\n",
      "Ep:118, loss:0.00001, loss_test:0.09722, lr:4.85e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.048, tt:4884.654\n",
      "Ep:119, loss:0.00001, loss_test:0.09387, lr:4.80e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.046, tt:4925.543\n",
      "Ep:120, loss:0.00001, loss_test:0.09754, lr:4.75e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.052, tt:4967.294\n",
      "Ep:121, loss:0.00001, loss_test:0.09730, lr:4.71e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.046, tt:5007.562\n",
      "Ep:122, loss:0.00001, loss_test:0.09759, lr:4.66e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.064, tt:5050.897\n",
      "Ep:123, loss:0.00001, loss_test:0.09569, lr:4.61e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.071, tt:5092.847\n",
      "Ep:124, loss:0.00001, loss_test:0.09625, lr:4.57e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.050, tt:5131.272\n",
      "Ep:125, loss:0.00001, loss_test:0.09646, lr:4.52e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.038, tt:5170.741\n",
      "Ep:126, loss:0.00001, loss_test:0.09464, lr:4.48e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.041, tt:5212.203\n",
      "Ep:127, loss:0.00001, loss_test:0.09883, lr:4.43e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.041, tt:5253.238\n",
      "Ep:128, loss:0.00001, loss_test:0.09476, lr:4.39e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.051, tt:5295.612\n",
      "Ep:129, loss:0.00001, loss_test:0.09825, lr:4.34e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.056, tt:5337.343\n",
      "Ep:130, loss:0.00001, loss_test:0.09761, lr:4.30e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.063, tt:5379.208\n",
      "Ep:131, loss:0.00001, loss_test:0.09629, lr:4.26e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.066, tt:5420.690\n",
      "Ep:132, loss:0.00001, loss_test:0.09770, lr:4.21e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.069, tt:5462.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.09763, lr:4.17e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.076, tt:5504.138\n",
      "Ep:134, loss:0.00001, loss_test:0.09622, lr:4.13e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.076, tt:5545.197\n",
      "Ep:135, loss:0.00001, loss_test:0.09803, lr:4.09e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.084, tt:5587.392\n",
      "Ep:136, loss:0.00001, loss_test:0.09718, lr:4.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.090, tt:5629.395\n",
      "Ep:137, loss:0.00001, loss_test:0.09781, lr:4.01e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.096, tt:5671.251\n",
      "Ep:138, loss:0.00001, loss_test:0.09783, lr:3.97e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.119, tt:5715.587\n",
      "Ep:139, loss:0.00001, loss_test:0.09711, lr:3.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.128, tt:5757.986\n",
      "Ep:140, loss:0.00001, loss_test:0.09872, lr:3.89e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.129, tt:5799.150\n",
      "Ep:141, loss:0.00001, loss_test:0.09689, lr:3.85e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.140, tt:5841.830\n",
      "Ep:142, loss:0.00001, loss_test:0.09844, lr:3.81e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.142, tt:5883.312\n",
      "Ep:143, loss:0.00001, loss_test:0.09750, lr:3.77e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.125, tt:5921.942\n",
      "Ep:144, loss:0.00001, loss_test:0.09863, lr:3.73e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.134, tt:5964.434\n",
      "Ep:145, loss:0.00001, loss_test:0.09816, lr:3.70e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.139, tt:6006.325\n",
      "Ep:146, loss:0.00001, loss_test:0.09924, lr:3.66e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.139, tt:6047.377\n",
      "Ep:147, loss:0.00001, loss_test:0.09803, lr:3.62e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.146, tt:6089.632\n",
      "Ep:148, loss:0.00001, loss_test:0.09839, lr:3.59e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.142, tt:6130.090\n",
      "Ep:149, loss:0.00001, loss_test:0.09925, lr:3.55e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.145, tt:6171.794\n",
      "Ep:150, loss:0.00001, loss_test:0.09779, lr:3.52e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.196, tt:6220.572\n",
      "Ep:151, loss:0.00001, loss_test:0.10027, lr:3.48e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.203, tt:6262.931\n",
      "Ep:152, loss:0.00001, loss_test:0.09848, lr:3.45e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.210, tt:6305.160\n",
      "Ep:153, loss:0.00001, loss_test:0.09904, lr:3.41e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.213, tt:6346.731\n",
      "Ep:154, loss:0.00001, loss_test:0.10038, lr:3.38e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.204, tt:6386.621\n",
      "Ep:155, loss:0.00001, loss_test:0.09760, lr:3.34e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.199, tt:6427.053\n",
      "Ep:156, loss:0.00001, loss_test:0.09873, lr:3.31e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.197, tt:6467.980\n",
      "Ep:157, loss:0.00001, loss_test:0.09888, lr:3.28e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.183, tt:6506.968\n",
      "Ep:158, loss:0.00001, loss_test:0.09849, lr:3.24e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.182, tt:6547.940\n",
      "Ep:159, loss:0.00001, loss_test:0.09850, lr:3.21e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.188, tt:6590.010\n",
      "Ep:160, loss:0.00001, loss_test:0.10021, lr:3.18e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.194, tt:6632.254\n",
      "Ep:161, loss:0.00001, loss_test:0.09934, lr:3.15e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.191, tt:6672.891\n",
      "Ep:162, loss:0.00001, loss_test:0.09809, lr:3.12e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.185, tt:6713.075\n",
      "Ep:163, loss:0.00001, loss_test:0.10065, lr:3.09e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.197, tt:6756.326\n",
      "Ep:164, loss:0.00001, loss_test:0.09900, lr:3.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.203, tt:6798.556\n",
      "Ep:165, loss:0.00001, loss_test:0.09933, lr:3.02e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.214, tt:6841.447\n",
      "Ep:166, loss:0.00001, loss_test:0.10103, lr:2.99e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.209, tt:6881.857\n",
      "Ep:167, loss:0.00001, loss_test:0.10012, lr:2.96e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.211, tt:6923.375\n",
      "Ep:168, loss:0.00001, loss_test:0.09835, lr:2.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.216, tt:6965.517\n",
      "Ep:169, loss:0.00001, loss_test:0.10035, lr:2.90e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.229, tt:7008.996\n",
      "Ep:170, loss:0.00001, loss_test:0.10058, lr:2.88e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.263, tt:7055.948\n",
      "Ep:171, loss:0.00001, loss_test:0.09892, lr:2.85e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.270, tt:7098.499\n",
      "Ep:172, loss:0.00001, loss_test:0.10082, lr:2.82e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.270, tt:7139.749\n",
      "Ep:173, loss:0.00001, loss_test:0.09977, lr:2.79e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.277, tt:7182.258\n",
      "Ep:174, loss:0.00001, loss_test:0.09948, lr:2.76e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.287, tt:7225.204\n",
      "Ep:175, loss:0.00001, loss_test:0.10016, lr:2.73e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.289, tt:7266.778\n",
      "Ep:176, loss:0.00001, loss_test:0.10059, lr:2.71e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.291, tt:7308.524\n",
      "Ep:177, loss:0.00001, loss_test:0.09913, lr:2.68e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.293, tt:7350.149\n",
      "Ep:178, loss:0.00001, loss_test:0.09927, lr:2.65e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.297, tt:7392.244\n",
      "Ep:179, loss:0.00001, loss_test:0.10040, lr:2.63e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.304, tt:7434.711\n",
      "Ep:180, loss:0.00001, loss_test:0.09990, lr:2.60e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.314, tt:7477.790\n",
      "Ep:181, loss:0.00001, loss_test:0.09971, lr:2.57e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.322, tt:7520.544\n",
      "Ep:182, loss:0.00001, loss_test:0.10094, lr:2.55e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.328, tt:7562.992\n",
      "Ep:183, loss:0.00001, loss_test:0.10156, lr:2.52e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.334, tt:7605.504\n",
      "Ep:184, loss:0.00001, loss_test:0.09986, lr:2.50e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.337, tt:7647.270\n",
      "Ep:185, loss:0.00001, loss_test:0.10167, lr:2.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.343, tt:7689.804\n",
      "Ep:186, loss:0.00001, loss_test:0.10160, lr:2.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.344, tt:7731.299\n",
      "Ep:187, loss:0.00001, loss_test:0.10020, lr:2.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.347, tt:7773.236\n",
      "Ep:188, loss:0.00000, loss_test:0.10041, lr:2.40e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.342, tt:7813.642\n",
      "Ep:189, loss:0.00000, loss_test:0.10067, lr:2.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.350, tt:7856.502\n",
      "Ep:190, loss:0.00000, loss_test:0.10035, lr:2.35e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.371, tt:7901.940\n",
      "Ep:191, loss:0.00000, loss_test:0.10066, lr:2.33e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.386, tt:7946.135\n",
      "Ep:192, loss:0.00000, loss_test:0.09997, lr:2.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.394, tt:7989.028\n",
      "Ep:193, loss:0.00000, loss_test:0.10061, lr:2.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.399, tt:8031.486\n",
      "Ep:194, loss:0.00000, loss_test:0.10099, lr:2.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.404, tt:8073.810\n",
      "Ep:195, loss:0.00000, loss_test:0.10040, lr:2.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.412, tt:8116.738\n",
      "Ep:196, loss:0.00000, loss_test:0.10118, lr:2.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.413, tt:8158.345\n",
      "Ep:197, loss:0.00000, loss_test:0.10093, lr:2.19e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.424, tt:8201.912\n",
      "Ep:198, loss:0.00000, loss_test:0.10068, lr:2.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.422, tt:8242.987\n",
      "Ep:199, loss:0.00000, loss_test:0.10128, lr:2.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.427, tt:8285.413\n",
      "Ep:200, loss:0.00000, loss_test:0.10072, lr:2.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.425, tt:8326.455\n",
      "Ep:201, loss:0.00000, loss_test:0.10059, lr:2.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.428, tt:8368.437\n",
      "Ep:202, loss:0.00000, loss_test:0.10008, lr:2.08e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.432, tt:8410.657\n",
      "Ep:203, loss:0.00000, loss_test:0.10057, lr:2.06e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.443, tt:8454.269\n",
      "Ep:204, loss:0.00000, loss_test:0.10132, lr:2.04e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.438, tt:8494.700\n",
      "Ep:205, loss:0.00000, loss_test:0.09985, lr:2.02e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.435, tt:8535.588\n",
      "Ep:206, loss:0.00000, loss_test:0.10119, lr:2.00e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.428, tt:8575.494\n",
      "Ep:207, loss:0.00000, loss_test:0.10200, lr:1.98e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.428, tt:8617.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.10058, lr:1.96e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.423, tt:8657.478\n",
      "Ep:209, loss:0.00000, loss_test:0.10097, lr:1.94e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.429, tt:8700.149\n",
      "Ep:210, loss:0.00000, loss_test:0.10129, lr:1.92e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.459, tt:8747.870\n",
      "Ep:211, loss:0.00000, loss_test:0.10069, lr:1.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.457, tt:8788.894\n",
      "Ep:212, loss:0.00000, loss_test:0.10072, lr:1.89e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.457, tt:8830.259\n",
      "Ep:213, loss:0.00000, loss_test:0.10148, lr:1.87e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.455, tt:8871.341\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02232, lr:6.00e-02, fs:0.63333 (r=0.874,p=0.497),  time:28.408, tt:28.408\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02478, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.890, tt:59.780\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02566, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.084, tt:93.252\n",
      "Ep:3, loss:0.00005, loss_test:0.02479, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.803, tt:127.210\n",
      "Ep:4, loss:0.00004, loss_test:0.02317, lr:6.00e-02, fs:0.66148 (r=0.977,p=0.500),  time:32.735, tt:163.674\n",
      "Ep:5, loss:0.00004, loss_test:0.02190, lr:6.00e-02, fs:0.65574 (r=0.920,p=0.510),  time:34.036, tt:204.217\n",
      "Ep:6, loss:0.00004, loss_test:0.02181, lr:6.00e-02, fs:0.64574 (r=0.828,p=0.529),  time:34.923, tt:244.461\n",
      "Ep:7, loss:0.00004, loss_test:0.02198, lr:6.00e-02, fs:0.60664 (r=0.736,p=0.516),  time:35.774, tt:286.196\n",
      "Ep:8, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.60870 (r=0.724,p=0.525),  time:36.433, tt:327.896\n",
      "Ep:9, loss:0.00004, loss_test:0.02022, lr:6.00e-02, fs:0.65789 (r=0.862,p=0.532),  time:36.944, tt:369.440\n",
      "Ep:10, loss:0.00003, loss_test:0.01970, lr:6.00e-02, fs:0.67227 (r=0.920,p=0.530),  time:37.457, tt:412.023\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01928, lr:6.00e-02, fs:0.68333 (r=0.943,p=0.536),  time:37.651, tt:451.811\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01870, lr:6.00e-02, fs:0.69528 (r=0.931,p=0.555),  time:37.906, tt:492.783\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01825, lr:6.00e-02, fs:0.71028 (r=0.874,p=0.598),  time:38.256, tt:535.587\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01800, lr:6.00e-02, fs:0.71845 (r=0.851,p=0.622),  time:38.539, tt:578.091\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.71845 (r=0.851,p=0.622),  time:38.841, tt:621.459\n",
      "Ep:16, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.74178 (r=0.908,p=0.627),  time:39.447, tt:670.602\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.75799 (r=0.954,p=0.629),  time:39.583, tt:712.501\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.76364 (r=0.966,p=0.632),  time:39.736, tt:754.981\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01579, lr:6.00e-02, fs:0.76712 (r=0.966,p=0.636),  time:39.961, tt:799.217\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01555, lr:6.00e-02, fs:0.75926 (r=0.943,p=0.636),  time:40.103, tt:842.161\n",
      "Ep:21, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.76636 (r=0.943,p=0.646),  time:40.204, tt:884.499\n",
      "Ep:22, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.76995 (r=0.943,p=0.651),  time:40.199, tt:924.577\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.76636 (r=0.943,p=0.646),  time:40.430, tt:970.309\n",
      "Ep:24, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.77570 (r=0.954,p=0.654),  time:40.459, tt:1011.466\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01420, lr:6.00e-02, fs:0.79808 (r=0.954,p=0.686),  time:40.561, tt:1054.578\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.80976 (r=0.954,p=0.703),  time:40.637, tt:1097.212\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.80583 (r=0.954,p=0.697),  time:40.644, tt:1138.019\n",
      "Ep:28, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.81159 (r=0.966,p=0.700),  time:40.769, tt:1182.311\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.81340 (r=0.977,p=0.697),  time:40.801, tt:1224.026\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.81731 (r=0.977,p=0.702),  time:40.913, tt:1268.313\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.81731 (r=0.977,p=0.702),  time:40.974, tt:1311.163\n",
      "Ep:32, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:40.992, tt:1352.732\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:41.043, tt:1395.473\n",
      "Ep:34, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:41.093, tt:1438.244\n",
      "Ep:35, loss:0.00002, loss_test:0.01264, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:41.216, tt:1483.771\n",
      "Ep:36, loss:0.00002, loss_test:0.01252, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:41.245, tt:1526.083\n",
      "Ep:37, loss:0.00002, loss_test:0.01246, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:41.238, tt:1567.053\n",
      "Ep:38, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:41.302, tt:1610.768\n",
      "Ep:39, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.82927 (r=0.977,p=0.720),  time:41.328, tt:1653.114\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01229, lr:6.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:41.451, tt:1699.477\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.82587 (r=0.954,p=0.728),  time:41.449, tt:1740.849\n",
      "Ep:42, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.82587 (r=0.954,p=0.728),  time:41.476, tt:1783.489\n",
      "Ep:43, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.82587 (r=0.954,p=0.728),  time:41.533, tt:1827.456\n",
      "Ep:44, loss:0.00002, loss_test:0.01213, lr:6.00e-02, fs:0.82587 (r=0.954,p=0.728),  time:41.571, tt:1870.683\n",
      "Ep:45, loss:0.00001, loss_test:0.01212, lr:6.00e-02, fs:0.81818 (r=0.931,p=0.730),  time:41.569, tt:1912.177\n",
      "Ep:46, loss:0.00001, loss_test:0.01214, lr:6.00e-02, fs:0.81026 (r=0.908,p=0.731),  time:41.575, tt:1954.008\n",
      "Ep:47, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.81026 (r=0.908,p=0.731),  time:41.576, tt:1995.640\n",
      "Ep:48, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:41.562, tt:2036.534\n",
      "Ep:49, loss:0.00001, loss_test:0.01214, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:41.550, tt:2077.490\n",
      "Ep:50, loss:0.00001, loss_test:0.01216, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:41.512, tt:2117.122\n",
      "Ep:51, loss:0.00001, loss_test:0.01219, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:41.512, tt:2158.605\n",
      "Ep:52, loss:0.00001, loss_test:0.01224, lr:5.94e-02, fs:0.80208 (r=0.885,p=0.733),  time:41.580, tt:2203.734\n",
      "Ep:53, loss:0.00001, loss_test:0.01221, lr:5.88e-02, fs:0.80628 (r=0.885,p=0.740),  time:41.596, tt:2246.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00001, loss_test:0.01232, lr:5.82e-02, fs:0.80000 (r=0.874,p=0.738),  time:41.625, tt:2289.356\n",
      "Ep:55, loss:0.00001, loss_test:0.01238, lr:5.76e-02, fs:0.79144 (r=0.851,p=0.740),  time:41.635, tt:2331.537\n",
      "Ep:56, loss:0.00001, loss_test:0.01236, lr:5.71e-02, fs:0.79144 (r=0.851,p=0.740),  time:41.607, tt:2371.615\n",
      "Ep:57, loss:0.00001, loss_test:0.01241, lr:5.65e-02, fs:0.79570 (r=0.851,p=0.747),  time:41.617, tt:2413.771\n",
      "Ep:58, loss:0.00001, loss_test:0.01253, lr:5.59e-02, fs:0.77838 (r=0.828,p=0.735),  time:41.603, tt:2454.564\n",
      "Ep:59, loss:0.00001, loss_test:0.01255, lr:5.54e-02, fs:0.78689 (r=0.828,p=0.750),  time:41.590, tt:2495.423\n",
      "Ep:60, loss:0.00001, loss_test:0.01253, lr:5.48e-02, fs:0.78689 (r=0.828,p=0.750),  time:41.590, tt:2537.010\n",
      "Ep:61, loss:0.00001, loss_test:0.01267, lr:5.43e-02, fs:0.79121 (r=0.828,p=0.758),  time:41.586, tt:2578.336\n",
      "Ep:62, loss:0.00001, loss_test:0.01273, lr:5.37e-02, fs:0.80000 (r=0.828,p=0.774),  time:41.588, tt:2620.035\n",
      "Ep:63, loss:0.00001, loss_test:0.01279, lr:5.32e-02, fs:0.80447 (r=0.828,p=0.783),  time:41.587, tt:2661.538\n",
      "Ep:64, loss:0.00001, loss_test:0.01285, lr:5.27e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.612, tt:2704.800\n",
      "Ep:65, loss:0.00001, loss_test:0.01292, lr:5.21e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.601, tt:2745.643\n",
      "Ep:66, loss:0.00001, loss_test:0.01297, lr:5.16e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.613, tt:2788.050\n",
      "Ep:67, loss:0.00001, loss_test:0.01306, lr:5.11e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.613, tt:2829.660\n",
      "Ep:68, loss:0.00001, loss_test:0.01318, lr:5.06e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.638, tt:2872.998\n",
      "Ep:69, loss:0.00001, loss_test:0.01321, lr:5.01e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.634, tt:2914.356\n",
      "Ep:70, loss:0.00001, loss_test:0.01328, lr:4.96e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.638, tt:2956.286\n",
      "Ep:71, loss:0.00001, loss_test:0.01353, lr:4.91e-02, fs:0.80899 (r=0.828,p=0.791),  time:41.634, tt:2997.632\n",
      "Ep:72, loss:0.00001, loss_test:0.01355, lr:4.86e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.641, tt:3039.805\n",
      "Ep:73, loss:0.00001, loss_test:0.01359, lr:4.81e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.644, tt:3081.636\n",
      "Ep:74, loss:0.00001, loss_test:0.01364, lr:4.76e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.640, tt:3122.986\n",
      "Ep:75, loss:0.00001, loss_test:0.01380, lr:4.71e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.627, tt:3163.641\n",
      "Ep:76, loss:0.00001, loss_test:0.01393, lr:4.67e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.684, tt:3209.656\n",
      "Ep:77, loss:0.00001, loss_test:0.01412, lr:4.62e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.679, tt:3250.926\n",
      "Ep:78, loss:0.00001, loss_test:0.01413, lr:4.57e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.675, tt:3292.365\n",
      "Ep:79, loss:0.00001, loss_test:0.01430, lr:4.53e-02, fs:0.80682 (r=0.816,p=0.798),  time:41.678, tt:3334.207\n",
      "Ep:80, loss:0.00001, loss_test:0.01439, lr:4.48e-02, fs:0.81143 (r=0.816,p=0.807),  time:41.680, tt:3376.066\n",
      "Ep:81, loss:0.00001, loss_test:0.01436, lr:4.44e-02, fs:0.81609 (r=0.816,p=0.816),  time:41.667, tt:3416.721\n",
      "Ep:82, loss:0.00001, loss_test:0.01457, lr:4.39e-02, fs:0.81609 (r=0.816,p=0.816),  time:41.648, tt:3456.799\n",
      "Ep:83, loss:0.00001, loss_test:0.01469, lr:4.35e-02, fs:0.82558 (r=0.816,p=0.835),  time:41.667, tt:3500.061\n",
      "Ep:84, loss:0.00001, loss_test:0.01476, lr:4.31e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.679, tt:3542.701\n",
      "Ep:85, loss:0.00001, loss_test:0.01486, lr:4.26e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.694, tt:3585.644\n",
      "Ep:86, loss:0.00001, loss_test:0.01499, lr:4.22e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.684, tt:3626.534\n",
      "Ep:87, loss:0.00001, loss_test:0.01508, lr:4.18e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.693, tt:3668.960\n",
      "Ep:88, loss:0.00001, loss_test:0.01510, lr:4.14e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.676, tt:3709.179\n",
      "Ep:89, loss:0.00001, loss_test:0.01535, lr:4.10e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.691, tt:3752.202\n",
      "Ep:90, loss:0.00001, loss_test:0.01543, lr:4.05e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.710, tt:3795.613\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01542, lr:4.05e-02, fs:0.83041 (r=0.816,p=0.845),  time:41.699, tt:3836.331\n",
      "Ep:92, loss:0.00001, loss_test:0.01563, lr:4.05e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.708, tt:3878.889\n",
      "Ep:93, loss:0.00001, loss_test:0.01579, lr:4.05e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.714, tt:3921.159\n",
      "Ep:94, loss:0.00001, loss_test:0.01583, lr:4.05e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.726, tt:3963.955\n",
      "Ep:95, loss:0.00001, loss_test:0.01597, lr:4.05e-02, fs:0.84024 (r=0.816,p=0.866),  time:41.740, tt:4007.006\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01607, lr:4.05e-02, fs:0.84024 (r=0.816,p=0.866),  time:41.744, tt:4049.157\n",
      "Ep:97, loss:0.00001, loss_test:0.01622, lr:4.05e-02, fs:0.84024 (r=0.816,p=0.866),  time:41.751, tt:4091.597\n",
      "Ep:98, loss:0.00001, loss_test:0.01635, lr:4.05e-02, fs:0.84024 (r=0.816,p=0.866),  time:41.757, tt:4133.916\n",
      "Ep:99, loss:0.00001, loss_test:0.01644, lr:4.05e-02, fs:0.84524 (r=0.816,p=0.877),  time:41.753, tt:4175.347\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01643, lr:4.05e-02, fs:0.84024 (r=0.816,p=0.866),  time:41.745, tt:4216.290\n",
      "Ep:101, loss:0.00001, loss_test:0.01669, lr:4.05e-02, fs:0.84524 (r=0.816,p=0.877),  time:41.764, tt:4259.917\n",
      "Ep:102, loss:0.00001, loss_test:0.01676, lr:4.05e-02, fs:0.84524 (r=0.816,p=0.877),  time:41.764, tt:4301.715\n",
      "Ep:103, loss:0.00001, loss_test:0.01683, lr:4.05e-02, fs:0.84524 (r=0.816,p=0.877),  time:41.772, tt:4344.242\n",
      "Ep:104, loss:0.00001, loss_test:0.01696, lr:4.05e-02, fs:0.85030 (r=0.816,p=0.887),  time:41.792, tt:4388.206\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01705, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.815, tt:4432.412\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.01729, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.824, tt:4475.150\n",
      "Ep:107, loss:0.00001, loss_test:0.01729, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.816, tt:4516.150\n",
      "Ep:108, loss:0.00001, loss_test:0.01741, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.837, tt:4560.182\n",
      "Ep:109, loss:0.00001, loss_test:0.01757, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.857, tt:4604.232\n",
      "Ep:110, loss:0.00001, loss_test:0.01772, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.849, tt:4645.215\n",
      "Ep:111, loss:0.00001, loss_test:0.01768, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.830, tt:4684.976\n",
      "Ep:112, loss:0.00001, loss_test:0.01797, lr:4.05e-02, fs:0.85542 (r=0.816,p=0.899),  time:41.822, tt:4725.835\n",
      "Ep:113, loss:0.00001, loss_test:0.01807, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.830, tt:4768.590\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00000, loss_test:0.01806, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.830, tt:4810.461\n",
      "Ep:115, loss:0.00000, loss_test:0.01833, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.815, tt:4850.498\n",
      "Ep:116, loss:0.00000, loss_test:0.01841, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.816, tt:4892.421\n",
      "Ep:117, loss:0.00000, loss_test:0.01847, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.810, tt:4933.613\n",
      "Ep:118, loss:0.00000, loss_test:0.01854, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.805, tt:4974.787\n",
      "Ep:119, loss:0.00000, loss_test:0.01874, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.794, tt:5015.279\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00000, loss_test:0.01897, lr:4.05e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.763, tt:5053.324\n",
      "Ep:121, loss:0.00000, loss_test:0.01891, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.761, tt:5094.819\n",
      "Ep:122, loss:0.00000, loss_test:0.01904, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.759, tt:5136.297\n",
      "Ep:123, loss:0.00000, loss_test:0.01915, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.752, tt:5177.224\n",
      "Ep:124, loss:0.00000, loss_test:0.01930, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.765, tt:5220.659\n",
      "Ep:125, loss:0.00000, loss_test:0.01938, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.764, tt:5262.246\n",
      "Ep:126, loss:0.00000, loss_test:0.01948, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.776, tt:5305.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00000, loss_test:0.01960, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.778, tt:5347.562\n",
      "Ep:128, loss:0.00000, loss_test:0.01980, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.781, tt:5389.776\n",
      "Ep:129, loss:0.00000, loss_test:0.01982, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.768, tt:5429.900\n",
      "Ep:130, loss:0.00000, loss_test:0.02018, lr:4.05e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.751, tt:5469.412\n",
      "Ep:131, loss:0.00000, loss_test:0.02016, lr:4.01e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.760, tt:5512.367\n",
      "Ep:132, loss:0.00000, loss_test:0.02022, lr:3.97e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.752, tt:5553.059\n",
      "Ep:133, loss:0.00000, loss_test:0.02043, lr:3.93e-02, fs:0.86585 (r=0.816,p=0.922),  time:41.768, tt:5596.846\n",
      "Ep:134, loss:0.00000, loss_test:0.02037, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.771, tt:5639.050\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00000, loss_test:0.02059, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.773, tt:5681.063\n",
      "Ep:136, loss:0.00000, loss_test:0.02072, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.773, tt:5722.912\n",
      "Ep:137, loss:0.00000, loss_test:0.02083, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.765, tt:5763.563\n",
      "Ep:138, loss:0.00000, loss_test:0.02097, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.773, tt:5806.406\n",
      "Ep:139, loss:0.00000, loss_test:0.02095, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.767, tt:5847.442\n",
      "Ep:140, loss:0.00000, loss_test:0.02127, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.777, tt:5890.621\n",
      "Ep:141, loss:0.00000, loss_test:0.02123, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.787, tt:5933.709\n",
      "Ep:142, loss:0.00000, loss_test:0.02132, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.783, tt:5974.963\n",
      "Ep:143, loss:0.00000, loss_test:0.02141, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.781, tt:6016.418\n",
      "Ep:144, loss:0.00000, loss_test:0.02156, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.792, tt:6059.816\n",
      "Ep:145, loss:0.00000, loss_test:0.02165, lr:3.89e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.819, tt:6105.611\n",
      "Ep:146, loss:0.00000, loss_test:0.02158, lr:3.86e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.840, tt:6150.518\n",
      "Ep:147, loss:0.00000, loss_test:0.02198, lr:3.82e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.850, tt:6193.738\n",
      "Ep:148, loss:0.00000, loss_test:0.02189, lr:3.78e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.853, tt:6236.069\n",
      "Ep:149, loss:0.00000, loss_test:0.02205, lr:3.74e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.858, tt:6278.648\n",
      "Ep:150, loss:0.00000, loss_test:0.02203, lr:3.70e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.866, tt:6321.739\n",
      "Ep:151, loss:0.00000, loss_test:0.02217, lr:3.67e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.861, tt:6362.919\n",
      "Ep:152, loss:0.00000, loss_test:0.02224, lr:3.63e-02, fs:0.87117 (r=0.816,p=0.934),  time:41.882, tt:6407.955\n",
      "Ep:153, loss:0.00000, loss_test:0.02228, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.887, tt:6450.646\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00000, loss_test:0.02269, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.895, tt:6493.743\n",
      "Ep:155, loss:0.00000, loss_test:0.02254, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.893, tt:6535.351\n",
      "Ep:156, loss:0.00000, loss_test:0.02272, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.899, tt:6578.134\n",
      "Ep:157, loss:0.00000, loss_test:0.02269, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.924, tt:6624.029\n",
      "Ep:158, loss:0.00000, loss_test:0.02273, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.931, tt:6667.085\n",
      "Ep:159, loss:0.00000, loss_test:0.02298, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.943, tt:6710.851\n",
      "Ep:160, loss:0.00000, loss_test:0.02281, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.957, tt:6755.052\n",
      "Ep:161, loss:0.00000, loss_test:0.02318, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.968, tt:6798.884\n",
      "Ep:162, loss:0.00000, loss_test:0.02310, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.979, tt:6842.587\n",
      "Ep:163, loss:0.00000, loss_test:0.02321, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:41.996, tt:6887.394\n",
      "Ep:164, loss:0.00000, loss_test:0.02330, lr:3.59e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.014, tt:6932.241\n",
      "Ep:165, loss:0.00000, loss_test:0.02327, lr:3.56e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.040, tt:6978.665\n",
      "Ep:166, loss:0.00000, loss_test:0.02353, lr:3.52e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.054, tt:7023.044\n",
      "Ep:167, loss:0.00000, loss_test:0.02338, lr:3.49e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.075, tt:7068.599\n",
      "Ep:168, loss:0.00000, loss_test:0.02366, lr:3.45e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.084, tt:7112.149\n",
      "Ep:169, loss:0.00000, loss_test:0.02365, lr:3.42e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.089, tt:7155.196\n",
      "Ep:170, loss:0.00000, loss_test:0.02353, lr:3.38e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.103, tt:7199.560\n",
      "Ep:171, loss:0.00000, loss_test:0.02383, lr:3.35e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.111, tt:7243.111\n",
      "Ep:172, loss:0.00000, loss_test:0.02390, lr:3.32e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.125, tt:7287.609\n",
      "Ep:173, loss:0.00000, loss_test:0.02392, lr:3.28e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.133, tt:7331.092\n",
      "Ep:174, loss:0.00000, loss_test:0.02406, lr:3.25e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.142, tt:7374.765\n",
      "Ep:175, loss:0.00000, loss_test:0.02388, lr:3.22e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.154, tt:7419.128\n",
      "Ep:176, loss:0.00000, loss_test:0.02410, lr:3.19e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.164, tt:7463.036\n",
      "Ep:177, loss:0.00000, loss_test:0.02408, lr:3.15e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.169, tt:7506.095\n",
      "Ep:178, loss:0.00000, loss_test:0.02423, lr:3.12e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.166, tt:7547.635\n",
      "Ep:179, loss:0.00000, loss_test:0.02449, lr:3.09e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.161, tt:7589.043\n",
      "Ep:180, loss:0.00000, loss_test:0.02427, lr:3.06e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.164, tt:7631.635\n",
      "Ep:181, loss:0.00000, loss_test:0.02438, lr:3.03e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.171, tt:7675.184\n",
      "Ep:182, loss:0.00000, loss_test:0.02439, lr:3.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.162, tt:7715.659\n",
      "Ep:183, loss:0.00000, loss_test:0.02438, lr:2.97e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.156, tt:7756.721\n",
      "Ep:184, loss:0.00000, loss_test:0.02470, lr:2.94e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.167, tt:7800.940\n",
      "Ep:185, loss:0.00000, loss_test:0.02460, lr:2.91e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.178, tt:7845.192\n",
      "Ep:186, loss:0.00000, loss_test:0.02465, lr:2.88e-02, fs:0.87654 (r=0.816,p=0.947),  time:42.184, tt:7888.467\n",
      "Ep:187, loss:0.00000, loss_test:0.02481, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.187, tt:7931.237\n",
      "##########Best model found so far##########\n",
      "Ep:188, loss:0.00000, loss_test:0.02472, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.183, tt:7972.498\n",
      "Ep:189, loss:0.00000, loss_test:0.02485, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.189, tt:8015.910\n",
      "Ep:190, loss:0.00000, loss_test:0.02483, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.192, tt:8058.656\n",
      "Ep:191, loss:0.00000, loss_test:0.02502, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.196, tt:8101.696\n",
      "Ep:192, loss:0.00000, loss_test:0.02483, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.203, tt:8145.087\n",
      "Ep:193, loss:0.00000, loss_test:0.02502, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.215, tt:8189.656\n",
      "Ep:194, loss:0.00000, loss_test:0.02512, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.219, tt:8232.648\n",
      "Ep:195, loss:0.00000, loss_test:0.02506, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.226, tt:8276.251\n",
      "Ep:196, loss:0.00000, loss_test:0.02524, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.228, tt:8318.882\n",
      "Ep:197, loss:0.00000, loss_test:0.02518, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.223, tt:8360.133\n",
      "Ep:198, loss:0.00000, loss_test:0.02523, lr:2.85e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.225, tt:8402.701\n",
      "Ep:199, loss:0.00000, loss_test:0.02531, lr:2.82e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.235, tt:8447.085\n",
      "Ep:200, loss:0.00000, loss_test:0.02521, lr:2.80e-02, fs:0.85350 (r=0.770,p=0.957),  time:42.230, tt:8488.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:201, loss:0.00000, loss_test:0.02545, lr:2.77e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.232, tt:8530.939\n",
      "Ep:202, loss:0.00000, loss_test:0.02546, lr:2.74e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.236, tt:8573.965\n",
      "Ep:203, loss:0.00000, loss_test:0.02529, lr:2.71e-02, fs:0.85350 (r=0.770,p=0.957),  time:42.229, tt:8614.703\n",
      "Ep:204, loss:0.00000, loss_test:0.02563, lr:2.69e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.234, tt:8657.962\n",
      "Ep:205, loss:0.00000, loss_test:0.02561, lr:2.66e-02, fs:0.88199 (r=0.816,p=0.959),  time:42.241, tt:8701.689\n",
      "Ep:206, loss:0.00000, loss_test:0.02546, lr:2.63e-02, fs:0.85350 (r=0.770,p=0.957),  time:42.242, tt:8744.109\n",
      "Ep:207, loss:0.00000, loss_test:0.02565, lr:2.61e-02, fs:0.88750 (r=0.816,p=0.973),  time:42.253, tt:8788.576\n",
      "##########Best model found so far##########\n",
      "Ep:208, loss:0.00000, loss_test:0.02562, lr:2.61e-02, fs:0.88050 (r=0.805,p=0.972),  time:42.257, tt:8831.747\n",
      "Ep:209, loss:0.00000, loss_test:0.02564, lr:2.61e-02, fs:0.85161 (r=0.759,p=0.971),  time:42.277, tt:8878.183\n",
      "Ep:210, loss:0.00000, loss_test:0.02589, lr:2.61e-02, fs:0.89308 (r=0.816,p=0.986),  time:42.279, tt:8920.920\n",
      "##########Best model found so far##########\n",
      "Ep:211, loss:0.00000, loss_test:0.02568, lr:2.61e-02, fs:0.82119 (r=0.713,p=0.969),  time:42.276, tt:8962.475\n",
      "Ep:212, loss:0.00000, loss_test:0.02589, lr:2.61e-02, fs:0.88608 (r=0.805,p=0.986),  time:42.268, tt:9003.131\n",
      "Ep:213, loss:0.00000, loss_test:0.02595, lr:2.61e-02, fs:0.88608 (r=0.805,p=0.986),  time:42.276, tt:9047.165\n",
      "Ep:214, loss:0.00000, loss_test:0.02574, lr:2.61e-02, fs:0.82119 (r=0.713,p=0.969),  time:42.267, tt:9087.505\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14677, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.541, tt:34.541\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14579, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:34.741, tt:69.482\n",
      "Ep:2, loss:0.00027, loss_test:0.14408, lr:1.00e-02, fs:0.64542 (r=0.931,p=0.494),  time:35.922, tt:107.766\n",
      "Ep:3, loss:0.00026, loss_test:0.14127, lr:1.00e-02, fs:0.62762 (r=0.862,p=0.493),  time:36.486, tt:145.942\n",
      "Ep:4, loss:0.00025, loss_test:0.13943, lr:1.00e-02, fs:0.59729 (r=0.759,p=0.493),  time:37.754, tt:188.769\n",
      "Ep:5, loss:0.00024, loss_test:0.13629, lr:1.00e-02, fs:0.60000 (r=0.690,p=0.531),  time:38.205, tt:229.228\n",
      "Ep:6, loss:0.00023, loss_test:0.13240, lr:1.00e-02, fs:0.58763 (r=0.655,p=0.533),  time:38.768, tt:271.378\n",
      "Ep:7, loss:0.00023, loss_test:0.12990, lr:1.00e-02, fs:0.60302 (r=0.690,p=0.536),  time:39.379, tt:315.031\n",
      "Ep:8, loss:0.00022, loss_test:0.12825, lr:1.00e-02, fs:0.62000 (r=0.713,p=0.549),  time:39.762, tt:357.858\n",
      "Ep:9, loss:0.00021, loss_test:0.12526, lr:1.00e-02, fs:0.62434 (r=0.678,p=0.578),  time:40.214, tt:402.143\n",
      "Ep:10, loss:0.00021, loss_test:0.12130, lr:1.00e-02, fs:0.61272 (r=0.609,p=0.616),  time:40.425, tt:444.673\n",
      "Ep:11, loss:0.00020, loss_test:0.11735, lr:1.00e-02, fs:0.63584 (r=0.632,p=0.640),  time:40.684, tt:488.205\n",
      "Ep:12, loss:0.00020, loss_test:0.11433, lr:9.90e-03, fs:0.62983 (r=0.655,p=0.606),  time:40.975, tt:532.672\n",
      "Ep:13, loss:0.00019, loss_test:0.11033, lr:9.80e-03, fs:0.64088 (r=0.667,p=0.617),  time:41.195, tt:576.728\n",
      "Ep:14, loss:0.00018, loss_test:0.10737, lr:9.70e-03, fs:0.66279 (r=0.655,p=0.671),  time:41.669, tt:625.037\n",
      "Ep:15, loss:0.00018, loss_test:0.10384, lr:9.61e-03, fs:0.67778 (r=0.701,p=0.656),  time:41.718, tt:667.484\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.10109, lr:9.61e-03, fs:0.72727 (r=0.782,p=0.680),  time:41.822, tt:710.979\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09860, lr:9.61e-03, fs:0.74444 (r=0.770,p=0.720),  time:41.842, tt:753.153\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09547, lr:9.61e-03, fs:0.76087 (r=0.805,p=0.722),  time:41.902, tt:796.145\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09263, lr:9.61e-03, fs:0.77838 (r=0.828,p=0.735),  time:41.978, tt:839.569\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.08994, lr:9.61e-03, fs:0.79121 (r=0.828,p=0.758),  time:42.084, tt:883.756\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08805, lr:9.61e-03, fs:0.80645 (r=0.862,p=0.758),  time:42.108, tt:926.368\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08590, lr:9.61e-03, fs:0.81283 (r=0.874,p=0.760),  time:42.209, tt:970.796\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08386, lr:9.61e-03, fs:0.81768 (r=0.851,p=0.787),  time:42.276, tt:1014.615\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08242, lr:9.61e-03, fs:0.82609 (r=0.874,p=0.784),  time:42.362, tt:1059.048\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08022, lr:9.61e-03, fs:0.84153 (r=0.885,p=0.802),  time:42.372, tt:1101.667\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07879, lr:9.61e-03, fs:0.84615 (r=0.885,p=0.811),  time:42.454, tt:1146.256\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07896, lr:9.61e-03, fs:0.83422 (r=0.897,p=0.780),  time:42.471, tt:1189.189\n",
      "Ep:28, loss:0.00012, loss_test:0.07697, lr:9.61e-03, fs:0.84746 (r=0.862,p=0.833),  time:42.540, tt:1233.660\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07595, lr:9.61e-03, fs:0.85263 (r=0.931,p=0.786),  time:42.626, tt:1278.768\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.07493, lr:9.61e-03, fs:0.86364 (r=0.874,p=0.854),  time:42.668, tt:1322.707\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07482, lr:9.61e-03, fs:0.84817 (r=0.931,p=0.779),  time:42.695, tt:1366.235\n",
      "Ep:32, loss:0.00010, loss_test:0.07388, lr:9.61e-03, fs:0.89017 (r=0.885,p=0.895),  time:42.704, tt:1409.233\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07309, lr:9.61e-03, fs:0.85864 (r=0.943,p=0.788),  time:42.796, tt:1455.056\n",
      "Ep:34, loss:0.00010, loss_test:0.07333, lr:9.61e-03, fs:0.88889 (r=0.874,p=0.905),  time:42.854, tt:1499.890\n",
      "Ep:35, loss:0.00009, loss_test:0.07124, lr:9.61e-03, fs:0.87234 (r=0.943,p=0.812),  time:42.885, tt:1543.856\n",
      "Ep:36, loss:0.00009, loss_test:0.07237, lr:9.61e-03, fs:0.88506 (r=0.885,p=0.885),  time:42.927, tt:1588.294\n",
      "Ep:37, loss:0.00009, loss_test:0.07038, lr:9.61e-03, fs:0.89888 (r=0.920,p=0.879),  time:42.923, tt:1631.073\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07106, lr:9.61e-03, fs:0.89773 (r=0.908,p=0.888),  time:42.894, tt:1672.851\n",
      "Ep:39, loss:0.00008, loss_test:0.07007, lr:9.61e-03, fs:0.90503 (r=0.931,p=0.880),  time:42.900, tt:1716.004\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.07117, lr:9.61e-03, fs:0.89017 (r=0.885,p=0.895),  time:42.877, tt:1757.938\n",
      "Ep:41, loss:0.00008, loss_test:0.06991, lr:9.61e-03, fs:0.90395 (r=0.920,p=0.889),  time:42.847, tt:1799.554\n",
      "Ep:42, loss:0.00007, loss_test:0.07080, lr:9.61e-03, fs:0.86705 (r=0.862,p=0.872),  time:42.838, tt:1842.049\n",
      "Ep:43, loss:0.00007, loss_test:0.07024, lr:9.61e-03, fs:0.88095 (r=0.851,p=0.914),  time:42.793, tt:1882.896\n",
      "Ep:44, loss:0.00007, loss_test:0.07209, lr:9.61e-03, fs:0.79755 (r=0.747,p=0.855),  time:42.772, tt:1924.720\n",
      "Ep:45, loss:0.00007, loss_test:0.06884, lr:9.61e-03, fs:0.87209 (r=0.862,p=0.882),  time:42.786, tt:1968.149\n",
      "Ep:46, loss:0.00007, loss_test:0.07170, lr:9.61e-03, fs:0.83529 (r=0.816,p=0.855),  time:42.727, tt:2008.189\n",
      "Ep:47, loss:0.00006, loss_test:0.07087, lr:9.61e-03, fs:0.86061 (r=0.816,p=0.910),  time:42.711, tt:2050.143\n",
      "Ep:48, loss:0.00006, loss_test:0.06955, lr:9.61e-03, fs:0.86391 (r=0.839,p=0.890),  time:42.707, tt:2092.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00006, loss_test:0.07139, lr:9.61e-03, fs:0.83019 (r=0.759,p=0.917),  time:42.626, tt:2131.301\n",
      "Ep:50, loss:0.00006, loss_test:0.07048, lr:9.61e-03, fs:0.86061 (r=0.816,p=0.910),  time:42.604, tt:2172.793\n",
      "Ep:51, loss:0.00005, loss_test:0.07009, lr:9.51e-03, fs:0.83230 (r=0.770,p=0.905),  time:42.590, tt:2214.660\n",
      "Ep:52, loss:0.00005, loss_test:0.06861, lr:9.41e-03, fs:0.86905 (r=0.839,p=0.901),  time:42.598, tt:2257.683\n",
      "Ep:53, loss:0.00005, loss_test:0.07164, lr:9.32e-03, fs:0.80255 (r=0.724,p=0.900),  time:42.586, tt:2299.638\n",
      "Ep:54, loss:0.00005, loss_test:0.06951, lr:9.23e-03, fs:0.86061 (r=0.816,p=0.910),  time:42.568, tt:2341.250\n",
      "Ep:55, loss:0.00005, loss_test:0.07097, lr:9.14e-03, fs:0.81013 (r=0.736,p=0.901),  time:42.561, tt:2383.389\n",
      "Ep:56, loss:0.00004, loss_test:0.07114, lr:9.04e-03, fs:0.77632 (r=0.678,p=0.908),  time:42.528, tt:2424.091\n",
      "Ep:57, loss:0.00004, loss_test:0.06998, lr:8.95e-03, fs:0.83230 (r=0.770,p=0.905),  time:42.478, tt:2463.735\n",
      "Ep:58, loss:0.00004, loss_test:0.07680, lr:8.86e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.480, tt:2506.334\n",
      "Ep:59, loss:0.00004, loss_test:0.06985, lr:8.78e-03, fs:0.87500 (r=0.885,p=0.865),  time:42.456, tt:2547.354\n",
      "Ep:60, loss:0.00004, loss_test:0.07413, lr:8.69e-03, fs:0.77027 (r=0.655,p=0.934),  time:42.403, tt:2586.589\n",
      "Ep:61, loss:0.00004, loss_test:0.07089, lr:8.60e-03, fs:0.83636 (r=0.793,p=0.885),  time:42.427, tt:2630.468\n",
      "Ep:62, loss:0.00004, loss_test:0.07325, lr:8.51e-03, fs:0.73826 (r=0.632,p=0.887),  time:42.442, tt:2673.863\n",
      "Ep:63, loss:0.00004, loss_test:0.07248, lr:8.43e-03, fs:0.85185 (r=0.793,p=0.920),  time:42.421, tt:2714.922\n",
      "Ep:64, loss:0.00004, loss_test:0.07545, lr:8.35e-03, fs:0.72340 (r=0.586,p=0.944),  time:42.370, tt:2754.032\n",
      "Ep:65, loss:0.00003, loss_test:0.06983, lr:8.26e-03, fs:0.83436 (r=0.782,p=0.895),  time:42.378, tt:2796.950\n",
      "Ep:66, loss:0.00003, loss_test:0.07537, lr:8.18e-03, fs:0.71942 (r=0.575,p=0.962),  time:42.397, tt:2840.614\n",
      "Ep:67, loss:0.00003, loss_test:0.07254, lr:8.10e-03, fs:0.85000 (r=0.782,p=0.932),  time:42.382, tt:2881.944\n",
      "Ep:68, loss:0.00003, loss_test:0.07582, lr:8.02e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.377, tt:2924.019\n",
      "Ep:69, loss:0.00003, loss_test:0.07340, lr:7.94e-03, fs:0.75342 (r=0.632,p=0.932),  time:42.369, tt:2965.796\n",
      "Ep:70, loss:0.00003, loss_test:0.07600, lr:7.86e-03, fs:0.75342 (r=0.632,p=0.932),  time:42.376, tt:3008.662\n",
      "Ep:71, loss:0.00003, loss_test:0.07626, lr:7.78e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.370, tt:3050.654\n",
      "Ep:72, loss:0.00003, loss_test:0.07295, lr:7.70e-03, fs:0.81290 (r=0.724,p=0.926),  time:42.366, tt:3092.721\n",
      "Ep:73, loss:0.00003, loss_test:0.07647, lr:7.62e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.368, tt:3135.264\n",
      "Ep:74, loss:0.00003, loss_test:0.07323, lr:7.55e-03, fs:0.76510 (r=0.655,p=0.919),  time:42.376, tt:3178.201\n",
      "Ep:75, loss:0.00003, loss_test:0.08275, lr:7.47e-03, fs:0.70073 (r=0.552,p=0.960),  time:42.356, tt:3219.072\n",
      "Ep:76, loss:0.00003, loss_test:0.07363, lr:7.40e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.368, tt:3262.372\n",
      "Ep:77, loss:0.00003, loss_test:0.07483, lr:7.32e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.378, tt:3305.458\n",
      "Ep:78, loss:0.00002, loss_test:0.07730, lr:7.25e-03, fs:0.70073 (r=0.552,p=0.960),  time:42.379, tt:3347.937\n",
      "Ep:79, loss:0.00002, loss_test:0.07753, lr:7.18e-03, fs:0.86420 (r=0.805,p=0.933),  time:42.365, tt:3389.214\n",
      "Ep:80, loss:0.00002, loss_test:0.07470, lr:7.11e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.330, tt:3428.744\n",
      "Ep:81, loss:0.00002, loss_test:0.08039, lr:7.03e-03, fs:0.75000 (r=0.621,p=0.947),  time:42.319, tt:3470.159\n",
      "Ep:82, loss:0.00002, loss_test:0.07463, lr:6.96e-03, fs:0.76510 (r=0.655,p=0.919),  time:42.345, tt:3514.613\n",
      "Ep:83, loss:0.00002, loss_test:0.07843, lr:6.89e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.314, tt:3554.358\n",
      "Ep:84, loss:0.00002, loss_test:0.07651, lr:6.83e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.320, tt:3597.213\n",
      "Ep:85, loss:0.00002, loss_test:0.07568, lr:6.76e-03, fs:0.75000 (r=0.621,p=0.947),  time:42.325, tt:3639.965\n",
      "Ep:86, loss:0.00002, loss_test:0.07851, lr:6.69e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.315, tt:3681.368\n",
      "Ep:87, loss:0.00002, loss_test:0.07609, lr:6.62e-03, fs:0.73239 (r=0.598,p=0.945),  time:42.291, tt:3721.633\n",
      "Ep:88, loss:0.00002, loss_test:0.07898, lr:6.56e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.277, tt:3762.667\n",
      "Ep:89, loss:0.00002, loss_test:0.07753, lr:6.49e-03, fs:0.71942 (r=0.575,p=0.962),  time:42.271, tt:3804.394\n",
      "Ep:90, loss:0.00002, loss_test:0.07697, lr:6.43e-03, fs:0.71942 (r=0.575,p=0.962),  time:42.241, tt:3843.934\n",
      "Ep:91, loss:0.00002, loss_test:0.07712, lr:6.36e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.221, tt:3884.353\n",
      "Ep:92, loss:0.00002, loss_test:0.07659, lr:6.30e-03, fs:0.71942 (r=0.575,p=0.962),  time:42.184, tt:3923.157\n",
      "Ep:93, loss:0.00002, loss_test:0.07925, lr:6.24e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.175, tt:3964.407\n",
      "Ep:94, loss:0.00002, loss_test:0.07899, lr:6.17e-03, fs:0.70073 (r=0.552,p=0.960),  time:42.183, tt:4007.344\n",
      "Ep:95, loss:0.00001, loss_test:0.07681, lr:6.11e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.172, tt:4048.555\n",
      "Ep:96, loss:0.00001, loss_test:0.08107, lr:6.05e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.160, tt:4089.536\n",
      "Ep:97, loss:0.00001, loss_test:0.07909, lr:5.99e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.145, tt:4130.168\n",
      "Ep:98, loss:0.00001, loss_test:0.07629, lr:5.93e-03, fs:0.74483 (r=0.621,p=0.931),  time:42.150, tt:4172.872\n",
      "Ep:99, loss:0.00001, loss_test:0.07992, lr:5.87e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.125, tt:4212.487\n",
      "Ep:100, loss:0.00001, loss_test:0.07919, lr:5.81e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.116, tt:4253.683\n",
      "Ep:101, loss:0.00001, loss_test:0.07807, lr:5.75e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.087, tt:4292.838\n",
      "Ep:102, loss:0.00001, loss_test:0.08077, lr:5.70e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.074, tt:4333.580\n",
      "Ep:103, loss:0.00001, loss_test:0.07828, lr:5.64e-03, fs:0.72857 (r=0.586,p=0.962),  time:42.051, tt:4373.260\n",
      "Ep:104, loss:0.00001, loss_test:0.07952, lr:5.58e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.049, tt:4415.183\n",
      "Ep:105, loss:0.00001, loss_test:0.07885, lr:5.53e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.035, tt:4455.694\n",
      "Ep:106, loss:0.00001, loss_test:0.08023, lr:5.47e-03, fs:0.71014 (r=0.563,p=0.961),  time:42.026, tt:4496.761\n",
      "Ep:107, loss:0.00001, loss_test:0.07906, lr:5.42e-03, fs:0.70504 (r=0.563,p=0.942),  time:42.012, tt:4537.315\n",
      "Ep:108, loss:0.00001, loss_test:0.08028, lr:5.36e-03, fs:0.68148 (r=0.529,p=0.958),  time:42.020, tt:4580.178\n",
      "Ep:109, loss:0.00001, loss_test:0.07846, lr:5.31e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.020, tt:4622.253\n",
      "Ep:110, loss:0.00001, loss_test:0.08056, lr:5.26e-03, fs:0.69118 (r=0.540,p=0.959),  time:42.021, tt:4664.308\n",
      "Ep:111, loss:0.00001, loss_test:0.08009, lr:5.20e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.003, tt:4704.302\n",
      "Ep:112, loss:0.00001, loss_test:0.08027, lr:5.15e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.972, tt:4742.809\n",
      "Ep:113, loss:0.00001, loss_test:0.08069, lr:5.10e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.956, tt:4783.005\n",
      "Ep:114, loss:0.00001, loss_test:0.08155, lr:5.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.921, tt:4820.928\n",
      "Ep:115, loss:0.00001, loss_test:0.07955, lr:5.00e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.899, tt:4860.271\n",
      "Ep:116, loss:0.00001, loss_test:0.08042, lr:4.95e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.870, tt:4898.769\n",
      "Ep:117, loss:0.00001, loss_test:0.08123, lr:4.90e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.870, tt:4940.671\n",
      "Ep:118, loss:0.00001, loss_test:0.08181, lr:4.85e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.857, tt:4981.038\n",
      "Ep:119, loss:0.00001, loss_test:0.08086, lr:4.80e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.858, tt:5022.932\n",
      "Ep:120, loss:0.00001, loss_test:0.08087, lr:4.75e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.846, tt:5063.407\n",
      "Ep:121, loss:0.00001, loss_test:0.08205, lr:4.71e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.843, tt:5104.835\n",
      "Ep:122, loss:0.00001, loss_test:0.08162, lr:4.66e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.834, tt:5145.629\n",
      "Ep:123, loss:0.00001, loss_test:0.08075, lr:4.61e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.843, tt:5188.471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00001, loss_test:0.08226, lr:4.57e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.843, tt:5230.354\n",
      "Ep:125, loss:0.00001, loss_test:0.08192, lr:4.52e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.840, tt:5271.844\n",
      "Ep:126, loss:0.00001, loss_test:0.08241, lr:4.48e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.845, tt:5314.310\n",
      "Ep:127, loss:0.00001, loss_test:0.08164, lr:4.43e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.832, tt:5354.450\n",
      "Ep:128, loss:0.00001, loss_test:0.08348, lr:4.39e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.830, tt:5396.065\n",
      "Ep:129, loss:0.00001, loss_test:0.08368, lr:4.34e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.846, tt:5439.936\n",
      "Ep:130, loss:0.00001, loss_test:0.08331, lr:4.30e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.860, tt:5483.678\n",
      "Ep:131, loss:0.00001, loss_test:0.08285, lr:4.26e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.875, tt:5527.483\n",
      "Ep:132, loss:0.00001, loss_test:0.08283, lr:4.21e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.873, tt:5569.051\n",
      "Ep:133, loss:0.00001, loss_test:0.08490, lr:4.17e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.878, tt:5611.599\n",
      "Ep:134, loss:0.00001, loss_test:0.08149, lr:4.13e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.876, tt:5653.205\n",
      "Ep:135, loss:0.00001, loss_test:0.08381, lr:4.09e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.871, tt:5694.451\n",
      "Ep:136, loss:0.00001, loss_test:0.08379, lr:4.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.858, tt:5734.517\n",
      "Ep:137, loss:0.00001, loss_test:0.08222, lr:4.01e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.857, tt:5776.305\n",
      "Ep:138, loss:0.00001, loss_test:0.08385, lr:3.97e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.846, tt:5816.529\n",
      "Ep:139, loss:0.00001, loss_test:0.08363, lr:3.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.830, tt:5856.225\n",
      "Ep:140, loss:0.00001, loss_test:0.08268, lr:3.89e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.827, tt:5897.608\n",
      "Ep:141, loss:0.00001, loss_test:0.08244, lr:3.85e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.821, tt:5938.511\n",
      "Ep:142, loss:0.00001, loss_test:0.08250, lr:3.81e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.812, tt:5979.148\n",
      "Ep:143, loss:0.00001, loss_test:0.08439, lr:3.77e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.808, tt:6020.285\n",
      "Ep:144, loss:0.00001, loss_test:0.08290, lr:3.73e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.799, tt:6060.924\n",
      "Ep:145, loss:0.00001, loss_test:0.08189, lr:3.70e-03, fs:0.68613 (r=0.540,p=0.940),  time:41.792, tt:6101.682\n",
      "Ep:146, loss:0.00001, loss_test:0.08419, lr:3.66e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.785, tt:6142.441\n",
      "Ep:147, loss:0.00001, loss_test:0.08428, lr:3.62e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.770, tt:6181.915\n",
      "Ep:148, loss:0.00001, loss_test:0.08132, lr:3.59e-03, fs:0.68613 (r=0.540,p=0.940),  time:41.754, tt:6221.357\n",
      "Ep:149, loss:0.00001, loss_test:0.08322, lr:3.55e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.746, tt:6261.837\n",
      "Ep:150, loss:0.00001, loss_test:0.08443, lr:3.52e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.737, tt:6302.325\n",
      "Ep:151, loss:0.00001, loss_test:0.08253, lr:3.48e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.724, tt:6342.064\n",
      "Ep:152, loss:0.00001, loss_test:0.08290, lr:3.45e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.728, tt:6384.444\n",
      "Ep:153, loss:0.00001, loss_test:0.08357, lr:3.41e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.717, tt:6424.428\n",
      "Ep:154, loss:0.00001, loss_test:0.08228, lr:3.38e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.724, tt:6467.256\n",
      "Ep:155, loss:0.00001, loss_test:0.08382, lr:3.34e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.750, tt:6513.038\n",
      "Ep:156, loss:0.00001, loss_test:0.08306, lr:3.31e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.746, tt:6554.113\n",
      "Ep:157, loss:0.00001, loss_test:0.08304, lr:3.28e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.734, tt:6594.032\n",
      "Ep:158, loss:0.00001, loss_test:0.08505, lr:3.24e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.723, tt:6633.926\n",
      "Ep:159, loss:0.00001, loss_test:0.08346, lr:3.21e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.717, tt:6674.713\n",
      "Ep:160, loss:0.00001, loss_test:0.08316, lr:3.18e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.711, tt:6715.448\n",
      "Ep:161, loss:0.00001, loss_test:0.08273, lr:3.15e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.703, tt:6755.831\n",
      "Ep:162, loss:0.00001, loss_test:0.08286, lr:3.12e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.699, tt:6796.859\n",
      "Ep:163, loss:0.00001, loss_test:0.08400, lr:3.09e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.699, tt:6838.610\n",
      "Ep:164, loss:0.00001, loss_test:0.08306, lr:3.05e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.701, tt:6880.707\n",
      "Ep:165, loss:0.00001, loss_test:0.08293, lr:3.02e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.695, tt:6921.366\n",
      "Ep:166, loss:0.00001, loss_test:0.08253, lr:2.99e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.683, tt:6961.073\n",
      "Ep:167, loss:0.00001, loss_test:0.08346, lr:2.96e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.671, tt:7000.741\n",
      "Ep:168, loss:0.00001, loss_test:0.08472, lr:2.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:41.660, tt:7040.581\n",
      "Ep:169, loss:0.00001, loss_test:0.08266, lr:2.90e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.662, tt:7082.544\n",
      "Ep:170, loss:0.00001, loss_test:0.08238, lr:2.88e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.659, tt:7123.710\n",
      "Ep:171, loss:0.00001, loss_test:0.08374, lr:2.85e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.663, tt:7166.057\n",
      "Ep:172, loss:0.00001, loss_test:0.08322, lr:2.82e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.654, tt:7206.138\n",
      "Ep:173, loss:0.00001, loss_test:0.08276, lr:2.79e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.647, tt:7246.637\n",
      "Ep:174, loss:0.00001, loss_test:0.08337, lr:2.76e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.658, tt:7290.160\n",
      "Ep:175, loss:0.00001, loss_test:0.08327, lr:2.73e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.642, tt:7328.976\n",
      "Ep:176, loss:0.00001, loss_test:0.08308, lr:2.71e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.642, tt:7370.638\n",
      "Ep:177, loss:0.00001, loss_test:0.08267, lr:2.68e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.648, tt:7413.293\n",
      "Ep:178, loss:0.00001, loss_test:0.08298, lr:2.65e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.635, tt:7452.609\n",
      "Ep:179, loss:0.00001, loss_test:0.08305, lr:2.63e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.638, tt:7494.770\n",
      "Ep:180, loss:0.00001, loss_test:0.08301, lr:2.60e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.630, tt:7535.041\n",
      "Ep:181, loss:0.00001, loss_test:0.08299, lr:2.57e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.633, tt:7577.269\n",
      "Ep:182, loss:0.00000, loss_test:0.08249, lr:2.55e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.630, tt:7618.289\n",
      "Ep:183, loss:0.00000, loss_test:0.08309, lr:2.52e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.617, tt:7657.457\n",
      "Ep:184, loss:0.00000, loss_test:0.08315, lr:2.50e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.603, tt:7696.504\n",
      "Ep:185, loss:0.00000, loss_test:0.08264, lr:2.47e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.602, tt:7737.987\n",
      "Ep:186, loss:0.00000, loss_test:0.08355, lr:2.45e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.600, tt:7779.282\n",
      "Ep:187, loss:0.00000, loss_test:0.08277, lr:2.42e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.603, tt:7821.366\n",
      "Ep:188, loss:0.00000, loss_test:0.08242, lr:2.40e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.594, tt:7861.233\n",
      "Ep:189, loss:0.00000, loss_test:0.08350, lr:2.38e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.594, tt:7902.842\n",
      "Ep:190, loss:0.00000, loss_test:0.08388, lr:2.35e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.586, tt:7943.018\n",
      "Ep:191, loss:0.00000, loss_test:0.08290, lr:2.33e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.588, tt:7984.849\n",
      "Ep:192, loss:0.00000, loss_test:0.08287, lr:2.31e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.594, tt:8027.712\n",
      "Ep:193, loss:0.00000, loss_test:0.08301, lr:2.28e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.597, tt:8069.842\n",
      "Ep:194, loss:0.00000, loss_test:0.08229, lr:2.26e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.601, tt:8112.290\n",
      "Ep:195, loss:0.00000, loss_test:0.08268, lr:2.24e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.595, tt:8152.679\n",
      "Ep:196, loss:0.00000, loss_test:0.08367, lr:2.21e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.586, tt:8192.397\n",
      "Ep:197, loss:0.00000, loss_test:0.08288, lr:2.19e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.578, tt:8232.456\n",
      "Ep:198, loss:0.00000, loss_test:0.08273, lr:2.17e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.583, tt:8275.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:199, loss:0.00000, loss_test:0.08333, lr:2.15e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.576, tt:8315.275\n",
      "Ep:200, loss:0.00000, loss_test:0.08242, lr:2.13e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.578, tt:8357.278\n",
      "Ep:201, loss:0.00000, loss_test:0.08301, lr:2.11e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.569, tt:8396.936\n",
      "Ep:202, loss:0.00000, loss_test:0.08306, lr:2.08e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.568, tt:8438.388\n",
      "Ep:203, loss:0.00000, loss_test:0.08257, lr:2.06e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.569, tt:8480.008\n",
      "Ep:204, loss:0.00000, loss_test:0.08251, lr:2.04e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.591, tt:8526.113\n",
      "Ep:205, loss:0.00000, loss_test:0.08257, lr:2.02e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.590, tt:8567.632\n",
      "Ep:206, loss:0.00000, loss_test:0.08270, lr:2.00e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.586, tt:8608.279\n",
      "Ep:207, loss:0.00000, loss_test:0.08304, lr:1.98e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.583, tt:8649.238\n",
      "Ep:208, loss:0.00000, loss_test:0.08222, lr:1.96e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.587, tt:8691.617\n",
      "Ep:209, loss:0.00000, loss_test:0.08291, lr:1.94e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.592, tt:8734.396\n",
      "Ep:210, loss:0.00000, loss_test:0.08345, lr:1.92e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.584, tt:8774.319\n",
      "Ep:211, loss:0.00000, loss_test:0.08251, lr:1.90e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.579, tt:8814.745\n",
      "Ep:212, loss:0.00000, loss_test:0.08288, lr:1.89e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.578, tt:8856.020\n",
      "Ep:213, loss:0.00000, loss_test:0.08326, lr:1.87e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.583, tt:8898.783\n",
      "Ep:214, loss:0.00000, loss_test:0.08243, lr:1.85e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.580, tt:8939.792\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02081, lr:6.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:20.112, tt:20.112\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02283, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.827, tt:47.653\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02342, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.806, tt:80.417\n",
      "Ep:3, loss:0.00004, loss_test:0.02267, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:29.810, tt:119.239\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02169, lr:6.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:31.570, tt:157.851\n",
      "Ep:5, loss:0.00004, loss_test:0.02124, lr:6.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:32.599, tt:195.593\n",
      "Ep:6, loss:0.00004, loss_test:0.02074, lr:6.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:33.260, tt:232.817\n",
      "Ep:7, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:34.046, tt:272.368\n",
      "Ep:8, loss:0.00003, loss_test:0.01899, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:34.600, tt:311.399\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01844, lr:6.00e-02, fs:0.68889 (r=0.939,p=0.544),  time:35.033, tt:350.331\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01802, lr:6.00e-02, fs:0.69373 (r=0.949,p=0.547),  time:35.671, tt:392.380\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:36.086, tt:433.028\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01726, lr:6.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:36.472, tt:474.130\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01691, lr:6.00e-02, fs:0.73518 (r=0.939,p=0.604),  time:36.789, tt:515.050\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:36.972, tt:554.586\n",
      "Ep:15, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:37.094, tt:593.498\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:37.257, tt:633.362\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:37.319, tt:671.745\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:37.449, tt:711.526\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01547, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:37.581, tt:751.626\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:37.710, tt:791.917\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:37.881, tt:833.377\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:38.008, tt:874.177\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01472, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:38.088, tt:914.113\n",
      "Ep:24, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:38.160, tt:953.995\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:38.219, tt:993.695\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:38.304, tt:1034.197\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:38.390, tt:1074.917\n",
      "Ep:28, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:38.458, tt:1115.270\n",
      "Ep:29, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:38.589, tt:1157.657\n",
      "Ep:30, loss:0.00002, loss_test:0.01377, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:38.628, tt:1197.457\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:38.629, tt:1236.118\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:38.694, tt:1276.895\n",
      "Ep:33, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:38.761, tt:1317.874\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:38.763, tt:1356.721\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01343, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:38.751, tt:1395.027\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:38.822, tt:1436.406\n",
      "Ep:37, loss:0.00002, loss_test:0.01331, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:38.825, tt:1475.349\n",
      "Ep:38, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:38.876, tt:1516.181\n",
      "Ep:39, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:39.000, tt:1559.988\n",
      "Ep:40, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:39.050, tt:1601.048\n",
      "Ep:41, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:39.104, tt:1642.367\n",
      "Ep:42, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:39.124, tt:1682.335\n",
      "Ep:43, loss:0.00001, loss_test:0.01311, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:39.182, tt:1723.994\n",
      "Ep:44, loss:0.00001, loss_test:0.01300, lr:6.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:39.233, tt:1765.507\n",
      "Ep:45, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:39.281, tt:1806.914\n",
      "Ep:46, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:39.324, tt:1848.217\n",
      "Ep:47, loss:0.00001, loss_test:0.01286, lr:5.94e-02, fs:0.79602 (r=0.808,p=0.784),  time:39.357, tt:1889.135\n",
      "Ep:48, loss:0.00001, loss_test:0.01283, lr:5.88e-02, fs:0.79602 (r=0.808,p=0.784),  time:39.417, tt:1931.425\n",
      "Ep:49, loss:0.00001, loss_test:0.01287, lr:5.82e-02, fs:0.79602 (r=0.808,p=0.784),  time:39.496, tt:1974.816\n",
      "Ep:50, loss:0.00001, loss_test:0.01278, lr:5.76e-02, fs:0.80000 (r=0.808,p=0.792),  time:39.556, tt:2017.356\n",
      "Ep:51, loss:0.00001, loss_test:0.01277, lr:5.71e-02, fs:0.79397 (r=0.798,p=0.790),  time:39.592, tt:2058.779\n",
      "Ep:52, loss:0.00001, loss_test:0.01275, lr:5.65e-02, fs:0.79397 (r=0.798,p=0.790),  time:39.619, tt:2099.833\n",
      "Ep:53, loss:0.00001, loss_test:0.01278, lr:5.59e-02, fs:0.79798 (r=0.798,p=0.798),  time:39.614, tt:2139.168\n",
      "Ep:54, loss:0.00001, loss_test:0.01273, lr:5.54e-02, fs:0.79798 (r=0.798,p=0.798),  time:39.661, tt:2181.336\n",
      "Ep:55, loss:0.00001, loss_test:0.01269, lr:5.48e-02, fs:0.79798 (r=0.798,p=0.798),  time:39.704, tt:2223.414\n",
      "Ep:56, loss:0.00001, loss_test:0.01268, lr:5.43e-02, fs:0.79798 (r=0.798,p=0.798),  time:39.733, tt:2264.761\n",
      "Ep:57, loss:0.00001, loss_test:0.01269, lr:5.37e-02, fs:0.80203 (r=0.798,p=0.806),  time:39.739, tt:2304.875\n",
      "Ep:58, loss:0.00001, loss_test:0.01273, lr:5.32e-02, fs:0.80203 (r=0.798,p=0.806),  time:39.769, tt:2346.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01273, lr:5.27e-02, fs:0.81026 (r=0.798,p=0.823),  time:39.788, tt:2387.277\n",
      "Ep:60, loss:0.00001, loss_test:0.01271, lr:5.21e-02, fs:0.81026 (r=0.798,p=0.823),  time:39.809, tt:2428.337\n",
      "Ep:61, loss:0.00001, loss_test:0.01279, lr:5.16e-02, fs:0.81443 (r=0.798,p=0.832),  time:39.829, tt:2469.413\n",
      "Ep:62, loss:0.00001, loss_test:0.01272, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.870, tt:2511.791\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01270, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.897, tt:2553.396\n",
      "Ep:64, loss:0.00001, loss_test:0.01277, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.932, tt:2595.610\n",
      "Ep:65, loss:0.00001, loss_test:0.01273, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.952, tt:2636.825\n",
      "Ep:66, loss:0.00001, loss_test:0.01277, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.979, tt:2678.611\n",
      "Ep:67, loss:0.00001, loss_test:0.01286, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.993, tt:2719.518\n",
      "Ep:68, loss:0.00001, loss_test:0.01270, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:40.019, tt:2761.289\n",
      "Ep:69, loss:0.00001, loss_test:0.01280, lr:5.11e-02, fs:0.81865 (r=0.798,p=0.840),  time:40.039, tt:2802.707\n",
      "Ep:70, loss:0.00001, loss_test:0.01285, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.074, tt:2845.223\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01279, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.069, tt:2884.985\n",
      "Ep:72, loss:0.00001, loss_test:0.01284, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.072, tt:2925.271\n",
      "Ep:73, loss:0.00001, loss_test:0.01296, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.069, tt:2965.137\n",
      "Ep:74, loss:0.00001, loss_test:0.01278, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.075, tt:3005.648\n",
      "Ep:75, loss:0.00001, loss_test:0.01305, lr:5.11e-02, fs:0.82105 (r=0.788,p=0.857),  time:40.119, tt:3049.023\n",
      "Ep:76, loss:0.00001, loss_test:0.01293, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.125, tt:3089.591\n",
      "Ep:77, loss:0.00001, loss_test:0.01294, lr:5.11e-02, fs:0.83158 (r=0.798,p=0.868),  time:40.126, tt:3129.796\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01306, lr:5.11e-02, fs:0.82540 (r=0.788,p=0.867),  time:40.144, tt:3171.409\n",
      "Ep:79, loss:0.00001, loss_test:0.01305, lr:5.11e-02, fs:0.82540 (r=0.788,p=0.867),  time:40.169, tt:3213.536\n",
      "Ep:80, loss:0.00001, loss_test:0.01303, lr:5.11e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.180, tt:3254.559\n",
      "Ep:81, loss:0.00001, loss_test:0.01311, lr:5.11e-02, fs:0.83422 (r=0.788,p=0.886),  time:40.191, tt:3295.681\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01316, lr:5.11e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.208, tt:3337.273\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01310, lr:5.11e-02, fs:0.83422 (r=0.788,p=0.886),  time:40.237, tt:3379.908\n",
      "Ep:84, loss:0.00001, loss_test:0.01330, lr:5.11e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.258, tt:3421.897\n",
      "Ep:85, loss:0.00001, loss_test:0.01321, lr:5.11e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.265, tt:3462.760\n",
      "Ep:86, loss:0.00001, loss_test:0.01329, lr:5.11e-02, fs:0.83871 (r=0.788,p=0.897),  time:40.275, tt:3503.966\n",
      "Ep:87, loss:0.00001, loss_test:0.01330, lr:5.11e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.276, tt:3544.302\n",
      "Ep:88, loss:0.00001, loss_test:0.01335, lr:5.11e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.380, tt:3593.793\n",
      "Ep:89, loss:0.00001, loss_test:0.01348, lr:5.11e-02, fs:0.82609 (r=0.768,p=0.894),  time:40.371, tt:3633.425\n",
      "Ep:90, loss:0.00001, loss_test:0.01340, lr:5.11e-02, fs:0.83696 (r=0.778,p=0.906),  time:40.394, tt:3675.859\n",
      "Ep:91, loss:0.00001, loss_test:0.01349, lr:5.11e-02, fs:0.83696 (r=0.778,p=0.906),  time:40.411, tt:3717.832\n",
      "Ep:92, loss:0.00001, loss_test:0.01348, lr:5.11e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.416, tt:3758.731\n",
      "Ep:93, loss:0.00001, loss_test:0.01361, lr:5.11e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.430, tt:3800.461\n",
      "Ep:94, loss:0.00001, loss_test:0.01354, lr:5.06e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.426, tt:3840.457\n",
      "Ep:95, loss:0.00001, loss_test:0.01372, lr:5.01e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.426, tt:3880.896\n",
      "Ep:96, loss:0.00001, loss_test:0.01372, lr:4.96e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.428, tt:3921.470\n",
      "Ep:97, loss:0.00001, loss_test:0.01369, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.438, tt:3962.899\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01381, lr:4.91e-02, fs:0.83516 (r=0.768,p=0.916),  time:40.433, tt:4002.857\n",
      "Ep:99, loss:0.00001, loss_test:0.01380, lr:4.91e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.435, tt:4043.507\n",
      "Ep:100, loss:0.00000, loss_test:0.01378, lr:4.91e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.430, tt:4083.470\n",
      "Ep:101, loss:0.00000, loss_test:0.01398, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.405, tt:4121.271\n",
      "Ep:102, loss:0.00000, loss_test:0.01390, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.381, tt:4159.285\n",
      "Ep:103, loss:0.00000, loss_test:0.01398, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.364, tt:4197.813\n",
      "Ep:104, loss:0.00000, loss_test:0.01412, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.370, tt:4238.884\n",
      "Ep:105, loss:0.00000, loss_test:0.01400, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.353, tt:4277.387\n",
      "Ep:106, loss:0.00000, loss_test:0.01420, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.354, tt:4317.867\n",
      "Ep:107, loss:0.00000, loss_test:0.01413, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.354, tt:4358.270\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.01413, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.362, tt:4399.419\n",
      "Ep:109, loss:0.00000, loss_test:0.01430, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.439, tt:4448.282\n",
      "Ep:110, loss:0.00000, loss_test:0.01423, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.417, tt:4486.284\n",
      "Ep:111, loss:0.00000, loss_test:0.01433, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.414, tt:4526.340\n",
      "Ep:112, loss:0.00000, loss_test:0.01435, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.429, tt:4568.502\n",
      "Ep:113, loss:0.00000, loss_test:0.01441, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.411, tt:4606.866\n",
      "Ep:114, loss:0.00000, loss_test:0.01448, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.420, tt:4648.297\n",
      "Ep:115, loss:0.00000, loss_test:0.01450, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.419, tt:4688.599\n",
      "Ep:116, loss:0.00000, loss_test:0.01458, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.397, tt:4726.475\n",
      "Ep:117, loss:0.00000, loss_test:0.01465, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.376, tt:4764.426\n",
      "Ep:118, loss:0.00000, loss_test:0.01458, lr:4.91e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.382, tt:4805.424\n",
      "Ep:119, loss:0.00000, loss_test:0.01475, lr:4.86e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.381, tt:4845.712\n",
      "Ep:120, loss:0.00000, loss_test:0.01484, lr:4.81e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.380, tt:4885.975\n",
      "Ep:121, loss:0.00000, loss_test:0.01476, lr:4.76e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.351, tt:4922.870\n",
      "Ep:122, loss:0.00000, loss_test:0.01493, lr:4.71e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.344, tt:4962.284\n",
      "Ep:123, loss:0.00000, loss_test:0.01490, lr:4.67e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.342, tt:5002.453\n",
      "Ep:124, loss:0.00000, loss_test:0.01499, lr:4.62e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.334, tt:5041.700\n",
      "Ep:125, loss:0.00000, loss_test:0.01505, lr:4.57e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.309, tt:5078.951\n",
      "Ep:126, loss:0.00000, loss_test:0.01503, lr:4.53e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.315, tt:5120.036\n",
      "Ep:127, loss:0.00000, loss_test:0.01507, lr:4.48e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.310, tt:5159.664\n",
      "Ep:128, loss:0.00000, loss_test:0.01515, lr:4.44e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.311, tt:5200.182\n",
      "Ep:129, loss:0.00000, loss_test:0.01515, lr:4.39e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.283, tt:5236.793\n",
      "Ep:130, loss:0.00000, loss_test:0.01517, lr:4.35e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.306, tt:5280.068\n",
      "Ep:131, loss:0.00000, loss_test:0.01540, lr:4.31e-02, fs:0.81609 (r=0.717,p=0.947),  time:40.290, tt:5318.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01520, lr:4.26e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.282, tt:5357.469\n",
      "Ep:133, loss:0.00000, loss_test:0.01537, lr:4.22e-02, fs:0.82286 (r=0.727,p=0.947),  time:40.272, tt:5396.428\n",
      "Ep:134, loss:0.00000, loss_test:0.01545, lr:4.18e-02, fs:0.80925 (r=0.707,p=0.946),  time:40.261, tt:5435.251\n",
      "Ep:135, loss:0.00000, loss_test:0.01539, lr:4.14e-02, fs:0.82286 (r=0.727,p=0.947),  time:40.251, tt:5474.087\n",
      "Ep:136, loss:0.00000, loss_test:0.01555, lr:4.10e-02, fs:0.80925 (r=0.707,p=0.946),  time:40.243, tt:5513.348\n",
      "Ep:137, loss:0.00000, loss_test:0.01556, lr:4.05e-02, fs:0.81609 (r=0.717,p=0.947),  time:40.232, tt:5552.039\n",
      "Ep:138, loss:0.00000, loss_test:0.01557, lr:4.01e-02, fs:0.81395 (r=0.707,p=0.959),  time:40.219, tt:5590.389\n",
      "Ep:139, loss:0.00000, loss_test:0.01565, lr:3.97e-02, fs:0.79290 (r=0.677,p=0.957),  time:40.210, tt:5629.456\n",
      "Ep:140, loss:0.00000, loss_test:0.01580, lr:3.93e-02, fs:0.78571 (r=0.667,p=0.957),  time:40.205, tt:5668.852\n",
      "Ep:141, loss:0.00000, loss_test:0.01564, lr:3.89e-02, fs:0.81395 (r=0.707,p=0.959),  time:40.197, tt:5708.022\n",
      "Ep:142, loss:0.00000, loss_test:0.01586, lr:3.86e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.183, tt:5746.133\n",
      "Ep:143, loss:0.00000, loss_test:0.01582, lr:3.82e-02, fs:0.79762 (r=0.677,p=0.971),  time:40.169, tt:5784.273\n",
      "Ep:144, loss:0.00000, loss_test:0.01584, lr:3.78e-02, fs:0.79762 (r=0.677,p=0.971),  time:40.153, tt:5822.218\n",
      "Ep:145, loss:0.00000, loss_test:0.01595, lr:3.74e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.136, tt:5859.865\n",
      "Ep:146, loss:0.00000, loss_test:0.01595, lr:3.70e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.133, tt:5899.556\n",
      "Ep:147, loss:0.00000, loss_test:0.01597, lr:3.67e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.141, tt:5940.843\n",
      "Ep:148, loss:0.00000, loss_test:0.01602, lr:3.63e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.137, tt:5980.451\n",
      "Ep:149, loss:0.00000, loss_test:0.01609, lr:3.59e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.146, tt:6021.899\n",
      "Ep:150, loss:0.00000, loss_test:0.01610, lr:3.56e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.152, tt:6063.009\n",
      "Ep:151, loss:0.00000, loss_test:0.01615, lr:3.52e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.152, tt:6103.055\n",
      "Ep:152, loss:0.00000, loss_test:0.01624, lr:3.49e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.155, tt:6143.653\n",
      "Ep:153, loss:0.00000, loss_test:0.01620, lr:3.45e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.157, tt:6184.188\n",
      "Ep:154, loss:0.00000, loss_test:0.01627, lr:3.42e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.150, tt:6223.247\n",
      "Ep:155, loss:0.00000, loss_test:0.01632, lr:3.38e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.150, tt:6263.322\n",
      "Ep:156, loss:0.00000, loss_test:0.01635, lr:3.35e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.147, tt:6303.092\n",
      "Ep:157, loss:0.00000, loss_test:0.01639, lr:3.32e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.144, tt:6342.804\n",
      "Ep:158, loss:0.00000, loss_test:0.01645, lr:3.28e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.148, tt:6383.463\n",
      "Ep:159, loss:0.00000, loss_test:0.01645, lr:3.25e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.146, tt:6423.399\n",
      "Ep:160, loss:0.00000, loss_test:0.01649, lr:3.22e-02, fs:0.77576 (r=0.646,p=0.970),  time:40.146, tt:6463.509\n",
      "Ep:161, loss:0.00000, loss_test:0.01657, lr:3.19e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.147, tt:6503.860\n",
      "Ep:162, loss:0.00000, loss_test:0.01653, lr:3.15e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.149, tt:6544.327\n",
      "Ep:163, loss:0.00000, loss_test:0.01663, lr:3.12e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.149, tt:6584.370\n",
      "Ep:164, loss:0.00000, loss_test:0.01665, lr:3.09e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.163, tt:6626.937\n",
      "Ep:165, loss:0.00000, loss_test:0.01665, lr:3.06e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.162, tt:6666.960\n",
      "Ep:166, loss:0.00000, loss_test:0.01671, lr:3.03e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.157, tt:6706.287\n",
      "Ep:167, loss:0.00000, loss_test:0.01673, lr:3.00e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.168, tt:6748.215\n",
      "Ep:168, loss:0.00000, loss_test:0.01677, lr:2.97e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.172, tt:6789.108\n",
      "Ep:169, loss:0.00000, loss_test:0.01677, lr:2.94e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.169, tt:6828.767\n",
      "Ep:170, loss:0.00000, loss_test:0.01684, lr:2.91e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.161, tt:6867.503\n",
      "Ep:171, loss:0.00000, loss_test:0.01686, lr:2.88e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.152, tt:6906.077\n",
      "Ep:172, loss:0.00000, loss_test:0.01691, lr:2.85e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.143, tt:6944.721\n",
      "Ep:173, loss:0.00000, loss_test:0.01691, lr:2.82e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.136, tt:6983.689\n",
      "Ep:174, loss:0.00000, loss_test:0.01695, lr:2.80e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.135, tt:7023.641\n",
      "Ep:175, loss:0.00000, loss_test:0.01699, lr:2.77e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.129, tt:7062.746\n",
      "Ep:176, loss:0.00000, loss_test:0.01699, lr:2.74e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.131, tt:7103.218\n",
      "Ep:177, loss:0.00000, loss_test:0.01703, lr:2.71e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.125, tt:7142.277\n",
      "Ep:178, loss:0.00000, loss_test:0.01710, lr:2.69e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.121, tt:7181.571\n",
      "Ep:179, loss:0.00000, loss_test:0.01706, lr:2.66e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.108, tt:7219.390\n",
      "Ep:180, loss:0.00000, loss_test:0.01712, lr:2.63e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.107, tt:7259.455\n",
      "Ep:181, loss:0.00000, loss_test:0.01711, lr:2.61e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.129, tt:7303.480\n",
      "Ep:182, loss:0.00000, loss_test:0.01716, lr:2.58e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.131, tt:7343.951\n",
      "Ep:183, loss:0.00000, loss_test:0.01721, lr:2.55e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.129, tt:7383.819\n",
      "Ep:184, loss:0.00000, loss_test:0.01720, lr:2.53e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.138, tt:7425.601\n",
      "Ep:185, loss:0.00000, loss_test:0.01724, lr:2.50e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.140, tt:7466.007\n",
      "Ep:186, loss:0.00000, loss_test:0.01725, lr:2.48e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.143, tt:7506.667\n",
      "Ep:187, loss:0.00000, loss_test:0.01729, lr:2.45e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.135, tt:7545.347\n",
      "Ep:188, loss:0.00000, loss_test:0.01730, lr:2.43e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.128, tt:7584.154\n",
      "Ep:189, loss:0.00000, loss_test:0.01737, lr:2.40e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.135, tt:7625.706\n",
      "Ep:190, loss:0.00000, loss_test:0.01738, lr:2.38e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.133, tt:7665.340\n",
      "Ep:191, loss:0.00000, loss_test:0.01738, lr:2.36e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.138, tt:7706.580\n",
      "Ep:192, loss:0.00000, loss_test:0.01737, lr:2.33e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.152, tt:7749.336\n",
      "Ep:193, loss:0.00000, loss_test:0.01743, lr:2.31e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.159, tt:7790.782\n",
      "Ep:194, loss:0.00000, loss_test:0.01745, lr:2.29e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.167, tt:7832.621\n",
      "Ep:195, loss:0.00000, loss_test:0.01745, lr:2.26e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.172, tt:7873.648\n",
      "Ep:196, loss:0.00000, loss_test:0.01750, lr:2.24e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.178, tt:7915.056\n",
      "Ep:197, loss:0.00000, loss_test:0.01748, lr:2.22e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.184, tt:7956.488\n",
      "Ep:198, loss:0.00000, loss_test:0.01754, lr:2.20e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.182, tt:7996.239\n",
      "Ep:199, loss:0.00000, loss_test:0.01757, lr:2.17e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.177, tt:8035.327\n",
      "Ep:200, loss:0.00000, loss_test:0.01756, lr:2.15e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.176, tt:8075.438\n",
      "Ep:201, loss:0.00000, loss_test:0.01758, lr:2.13e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.170, tt:8114.413\n",
      "Ep:202, loss:0.00000, loss_test:0.01764, lr:2.11e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.169, tt:8154.394\n",
      "Ep:203, loss:0.00000, loss_test:0.01763, lr:2.09e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.174, tt:8195.453\n",
      "Ep:204, loss:0.00000, loss_test:0.01763, lr:2.07e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.162, tt:8233.133\n",
      "Ep:205, loss:0.00000, loss_test:0.01769, lr:2.05e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.161, tt:8273.074\n",
      "Ep:206, loss:0.00000, loss_test:0.01772, lr:2.03e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.167, tt:8314.660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.01768, lr:2.01e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.175, tt:8356.427\n",
      "Ep:208, loss:0.00000, loss_test:0.01773, lr:1.99e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.177, tt:8397.001\n",
      "Ep:209, loss:0.00000, loss_test:0.01779, lr:1.97e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.178, tt:8437.296\n",
      "Ep:210, loss:0.00000, loss_test:0.01778, lr:1.95e-02, fs:0.78049 (r=0.646,p=0.985),  time:40.202, tt:8482.705\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14516, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.785, tt:34.785\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14433, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.037, tt:62.074\n",
      "Ep:2, loss:0.00028, loss_test:0.14289, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.809, tt:98.426\n",
      "Ep:3, loss:0.00027, loss_test:0.14063, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:32.656, tt:130.625\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13680, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:34.565, tt:172.825\n",
      "Ep:5, loss:0.00025, loss_test:0.13329, lr:1.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:35.778, tt:214.669\n",
      "Ep:6, loss:0.00024, loss_test:0.12996, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:36.580, tt:256.060\n",
      "Ep:7, loss:0.00023, loss_test:0.12594, lr:1.00e-02, fs:0.64629 (r=0.747,p=0.569),  time:37.341, tt:298.731\n",
      "Ep:8, loss:0.00022, loss_test:0.12179, lr:1.00e-02, fs:0.64979 (r=0.778,p=0.558),  time:38.031, tt:342.275\n",
      "Ep:9, loss:0.00022, loss_test:0.12172, lr:1.00e-02, fs:0.65854 (r=0.818,p=0.551),  time:38.517, tt:385.171\n",
      "Ep:10, loss:0.00021, loss_test:0.11965, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:38.869, tt:427.554\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11532, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:39.095, tt:469.142\n",
      "Ep:12, loss:0.00020, loss_test:0.10995, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:39.351, tt:511.569\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10626, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:39.674, tt:555.442\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10267, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:39.770, tt:596.548\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09953, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:39.752, tt:636.024\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09735, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:39.835, tt:677.191\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09464, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:39.967, tt:719.410\n",
      "Ep:18, loss:0.00016, loss_test:0.09310, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:40.179, tt:763.397\n",
      "Ep:19, loss:0.00016, loss_test:0.09187, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:40.368, tt:807.361\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09070, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.354, tt:847.434\n",
      "Ep:21, loss:0.00015, loss_test:0.08858, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:40.455, tt:890.002\n",
      "Ep:22, loss:0.00014, loss_test:0.08728, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:40.417, tt:929.591\n",
      "Ep:23, loss:0.00014, loss_test:0.08628, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:40.366, tt:968.795\n",
      "Ep:24, loss:0.00013, loss_test:0.08514, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:40.334, tt:1008.353\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08377, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:40.352, tt:1049.147\n",
      "Ep:26, loss:0.00012, loss_test:0.08382, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:40.384, tt:1090.370\n",
      "Ep:27, loss:0.00012, loss_test:0.08276, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:40.441, tt:1132.341\n",
      "Ep:28, loss:0.00012, loss_test:0.08194, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:40.496, tt:1174.374\n",
      "Ep:29, loss:0.00011, loss_test:0.08065, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:40.457, tt:1213.718\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08008, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:40.528, tt:1256.373\n",
      "Ep:31, loss:0.00010, loss_test:0.07896, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:40.596, tt:1299.061\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.07785, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:40.647, tt:1341.343\n",
      "Ep:33, loss:0.00010, loss_test:0.07837, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:40.671, tt:1382.806\n",
      "Ep:34, loss:0.00009, loss_test:0.07735, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:40.685, tt:1423.974\n",
      "Ep:35, loss:0.00009, loss_test:0.07746, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:40.717, tt:1465.819\n",
      "Ep:36, loss:0.00009, loss_test:0.07696, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:40.731, tt:1507.035\n",
      "Ep:37, loss:0.00008, loss_test:0.07629, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:40.772, tt:1549.336\n",
      "Ep:38, loss:0.00008, loss_test:0.07495, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:40.751, tt:1589.272\n",
      "Ep:39, loss:0.00008, loss_test:0.07424, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:40.663, tt:1626.508\n",
      "Ep:40, loss:0.00007, loss_test:0.07808, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:40.644, tt:1666.424\n",
      "Ep:41, loss:0.00007, loss_test:0.07435, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:40.654, tt:1707.457\n",
      "Ep:42, loss:0.00007, loss_test:0.07560, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:40.697, tt:1749.992\n",
      "Ep:43, loss:0.00007, loss_test:0.07461, lr:9.90e-03, fs:0.76667 (r=0.697,p=0.852),  time:40.657, tt:1788.900\n",
      "Ep:44, loss:0.00007, loss_test:0.07707, lr:9.80e-03, fs:0.79545 (r=0.707,p=0.909),  time:40.631, tt:1828.412\n",
      "Ep:45, loss:0.00006, loss_test:0.07241, lr:9.70e-03, fs:0.83495 (r=0.869,p=0.804),  time:40.617, tt:1868.371\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.07923, lr:9.70e-03, fs:0.77647 (r=0.667,p=0.930),  time:40.601, tt:1908.268\n",
      "Ep:47, loss:0.00006, loss_test:0.07306, lr:9.70e-03, fs:0.84211 (r=0.889,p=0.800),  time:40.614, tt:1949.487\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.08480, lr:9.70e-03, fs:0.73418 (r=0.586,p=0.983),  time:40.617, tt:1990.222\n",
      "Ep:49, loss:0.00006, loss_test:0.07264, lr:9.70e-03, fs:0.81773 (r=0.838,p=0.798),  time:40.653, tt:2032.630\n",
      "Ep:50, loss:0.00006, loss_test:0.08394, lr:9.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:40.649, tt:2073.093\n",
      "Ep:51, loss:0.00005, loss_test:0.07166, lr:9.70e-03, fs:0.81951 (r=0.848,p=0.792),  time:40.630, tt:2112.785\n",
      "Ep:52, loss:0.00005, loss_test:0.08763, lr:9.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:40.686, tt:2156.345\n",
      "Ep:53, loss:0.00005, loss_test:0.07153, lr:9.70e-03, fs:0.78723 (r=0.747,p=0.831),  time:40.731, tt:2199.478\n",
      "Ep:54, loss:0.00005, loss_test:0.08006, lr:9.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:40.732, tt:2240.282\n",
      "Ep:55, loss:0.00005, loss_test:0.08082, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:40.749, tt:2281.920\n",
      "Ep:56, loss:0.00005, loss_test:0.07383, lr:9.70e-03, fs:0.80000 (r=0.707,p=0.921),  time:40.779, tt:2324.407\n",
      "Ep:57, loss:0.00005, loss_test:0.07912, lr:9.70e-03, fs:0.76023 (r=0.657,p=0.903),  time:40.788, tt:2365.686\n",
      "Ep:58, loss:0.00004, loss_test:0.07458, lr:9.70e-03, fs:0.78363 (r=0.677,p=0.931),  time:40.798, tt:2407.062\n",
      "Ep:59, loss:0.00004, loss_test:0.07717, lr:9.61e-03, fs:0.77576 (r=0.646,p=0.970),  time:40.819, tt:2449.141\n",
      "Ep:60, loss:0.00004, loss_test:0.07875, lr:9.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:40.842, tt:2491.345\n",
      "Ep:61, loss:0.00004, loss_test:0.07699, lr:9.41e-03, fs:0.77907 (r=0.677,p=0.918),  time:40.849, tt:2532.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00004, loss_test:0.07916, lr:9.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:40.849, tt:2573.472\n",
      "Ep:63, loss:0.00004, loss_test:0.07802, lr:9.23e-03, fs:0.76301 (r=0.667,p=0.892),  time:40.871, tt:2615.732\n",
      "Ep:64, loss:0.00004, loss_test:0.08080, lr:9.14e-03, fs:0.75294 (r=0.646,p=0.901),  time:40.932, tt:2660.571\n",
      "Ep:65, loss:0.00003, loss_test:0.07673, lr:9.04e-03, fs:0.78824 (r=0.677,p=0.944),  time:40.916, tt:2700.463\n",
      "Ep:66, loss:0.00003, loss_test:0.08112, lr:8.95e-03, fs:0.75610 (r=0.626,p=0.954),  time:40.870, tt:2738.306\n",
      "Ep:67, loss:0.00003, loss_test:0.08318, lr:8.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:40.877, tt:2779.664\n",
      "Ep:68, loss:0.00003, loss_test:0.07989, lr:8.78e-03, fs:0.77576 (r=0.646,p=0.970),  time:40.875, tt:2820.343\n",
      "Ep:69, loss:0.00003, loss_test:0.08390, lr:8.69e-03, fs:0.75152 (r=0.626,p=0.939),  time:40.833, tt:2858.278\n",
      "Ep:70, loss:0.00003, loss_test:0.08390, lr:8.60e-03, fs:0.75152 (r=0.626,p=0.939),  time:40.843, tt:2899.869\n",
      "Ep:71, loss:0.00003, loss_test:0.08231, lr:8.51e-03, fs:0.77381 (r=0.657,p=0.942),  time:40.849, tt:2941.116\n",
      "Ep:72, loss:0.00003, loss_test:0.08527, lr:8.43e-03, fs:0.74074 (r=0.606,p=0.952),  time:40.829, tt:2980.514\n",
      "Ep:73, loss:0.00003, loss_test:0.08326, lr:8.35e-03, fs:0.75152 (r=0.626,p=0.939),  time:40.844, tt:3022.461\n",
      "Ep:74, loss:0.00002, loss_test:0.08693, lr:8.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:40.852, tt:3063.910\n",
      "Ep:75, loss:0.00002, loss_test:0.08338, lr:8.18e-03, fs:0.75152 (r=0.626,p=0.939),  time:40.842, tt:3103.986\n",
      "Ep:76, loss:0.00002, loss_test:0.08907, lr:8.10e-03, fs:0.73750 (r=0.596,p=0.967),  time:40.848, tt:3145.286\n",
      "Ep:77, loss:0.00002, loss_test:0.08642, lr:8.02e-03, fs:0.73292 (r=0.596,p=0.952),  time:40.859, tt:3186.965\n",
      "Ep:78, loss:0.00002, loss_test:0.08353, lr:7.94e-03, fs:0.73620 (r=0.606,p=0.938),  time:40.851, tt:3227.193\n",
      "Ep:79, loss:0.00002, loss_test:0.08923, lr:7.86e-03, fs:0.76543 (r=0.626,p=0.984),  time:40.881, tt:3270.443\n",
      "Ep:80, loss:0.00002, loss_test:0.08428, lr:7.78e-03, fs:0.72152 (r=0.576,p=0.966),  time:40.916, tt:3314.198\n",
      "Ep:81, loss:0.00002, loss_test:0.08923, lr:7.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:40.926, tt:3355.961\n",
      "Ep:82, loss:0.00002, loss_test:0.08874, lr:7.62e-03, fs:0.71698 (r=0.576,p=0.950),  time:40.909, tt:3395.477\n",
      "Ep:83, loss:0.00002, loss_test:0.08856, lr:7.55e-03, fs:0.72152 (r=0.576,p=0.966),  time:40.923, tt:3437.522\n",
      "Ep:84, loss:0.00002, loss_test:0.09104, lr:7.47e-03, fs:0.72611 (r=0.576,p=0.983),  time:40.908, tt:3477.212\n",
      "Ep:85, loss:0.00002, loss_test:0.08615, lr:7.40e-03, fs:0.72152 (r=0.576,p=0.966),  time:40.897, tt:3517.177\n",
      "Ep:86, loss:0.00002, loss_test:0.09278, lr:7.32e-03, fs:0.72611 (r=0.576,p=0.983),  time:40.879, tt:3556.440\n",
      "Ep:87, loss:0.00002, loss_test:0.09021, lr:7.25e-03, fs:0.72611 (r=0.576,p=0.983),  time:40.881, tt:3597.532\n",
      "Ep:88, loss:0.00002, loss_test:0.08974, lr:7.18e-03, fs:0.72611 (r=0.576,p=0.983),  time:40.898, tt:3639.950\n",
      "Ep:89, loss:0.00001, loss_test:0.09036, lr:7.11e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.888, tt:3679.950\n",
      "Ep:90, loss:0.00001, loss_test:0.08911, lr:7.03e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.899, tt:3721.777\n",
      "Ep:91, loss:0.00001, loss_test:0.08973, lr:6.96e-03, fs:0.72611 (r=0.576,p=0.983),  time:40.899, tt:3762.738\n",
      "Ep:92, loss:0.00001, loss_test:0.09222, lr:6.89e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.906, tt:3804.243\n",
      "Ep:93, loss:0.00001, loss_test:0.08791, lr:6.83e-03, fs:0.71698 (r=0.576,p=0.950),  time:40.918, tt:3846.258\n",
      "Ep:94, loss:0.00001, loss_test:0.09077, lr:6.76e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.928, tt:3888.197\n",
      "Ep:95, loss:0.00001, loss_test:0.09231, lr:6.69e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.922, tt:3928.468\n",
      "Ep:96, loss:0.00001, loss_test:0.09292, lr:6.62e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.967, tt:3973.794\n",
      "Ep:97, loss:0.00001, loss_test:0.08954, lr:6.56e-03, fs:0.73077 (r=0.576,p=1.000),  time:40.973, tt:4015.321\n",
      "Ep:98, loss:0.00001, loss_test:0.09197, lr:6.49e-03, fs:0.72611 (r=0.576,p=0.983),  time:40.982, tt:4057.215\n",
      "Ep:99, loss:0.00001, loss_test:0.09036, lr:6.43e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.013, tt:4101.259\n",
      "Ep:100, loss:0.00001, loss_test:0.08990, lr:6.36e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.038, tt:4144.838\n",
      "Ep:101, loss:0.00001, loss_test:0.09213, lr:6.30e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.060, tt:4188.070\n",
      "Ep:102, loss:0.00001, loss_test:0.09066, lr:6.24e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.050, tt:4228.106\n",
      "Ep:103, loss:0.00001, loss_test:0.09024, lr:6.17e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.063, tt:4270.584\n",
      "Ep:104, loss:0.00001, loss_test:0.09149, lr:6.11e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.070, tt:4312.343\n",
      "Ep:105, loss:0.00001, loss_test:0.09489, lr:6.05e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.071, tt:4353.553\n",
      "Ep:106, loss:0.00001, loss_test:0.09052, lr:5.99e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.075, tt:4395.040\n",
      "Ep:107, loss:0.00001, loss_test:0.09118, lr:5.93e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.075, tt:4436.075\n",
      "Ep:108, loss:0.00001, loss_test:0.09170, lr:5.87e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.087, tt:4478.438\n",
      "Ep:109, loss:0.00001, loss_test:0.09105, lr:5.81e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.080, tt:4518.762\n",
      "Ep:110, loss:0.00001, loss_test:0.09135, lr:5.75e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.100, tt:4562.124\n",
      "Ep:111, loss:0.00001, loss_test:0.09136, lr:5.70e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.105, tt:4603.708\n",
      "Ep:112, loss:0.00001, loss_test:0.09117, lr:5.64e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.121, tt:4646.640\n",
      "Ep:113, loss:0.00001, loss_test:0.09282, lr:5.58e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.119, tt:4687.587\n",
      "Ep:114, loss:0.00001, loss_test:0.09267, lr:5.53e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.125, tt:4729.430\n",
      "Ep:115, loss:0.00001, loss_test:0.09365, lr:5.47e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.117, tt:4769.584\n",
      "Ep:116, loss:0.00001, loss_test:0.09065, lr:5.42e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.126, tt:4811.790\n",
      "Ep:117, loss:0.00001, loss_test:0.09140, lr:5.36e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.137, tt:4854.150\n",
      "Ep:118, loss:0.00001, loss_test:0.09184, lr:5.31e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.153, tt:4897.193\n",
      "Ep:119, loss:0.00001, loss_test:0.09070, lr:5.26e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.165, tt:4939.769\n",
      "Ep:120, loss:0.00001, loss_test:0.09356, lr:5.20e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.179, tt:4982.667\n",
      "Ep:121, loss:0.00001, loss_test:0.09050, lr:5.15e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.170, tt:5022.682\n",
      "Ep:122, loss:0.00001, loss_test:0.09364, lr:5.10e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.170, tt:5063.910\n",
      "Ep:123, loss:0.00001, loss_test:0.09153, lr:5.05e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.176, tt:5105.773\n",
      "Ep:124, loss:0.00001, loss_test:0.09252, lr:5.00e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.187, tt:5148.357\n",
      "Ep:125, loss:0.00001, loss_test:0.09213, lr:4.95e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.188, tt:5189.726\n",
      "Ep:126, loss:0.00001, loss_test:0.09132, lr:4.90e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.198, tt:5232.089\n",
      "Ep:127, loss:0.00001, loss_test:0.09085, lr:4.85e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.189, tt:5272.143\n",
      "Ep:128, loss:0.00001, loss_test:0.09336, lr:4.80e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.195, tt:5314.180\n",
      "Ep:129, loss:0.00001, loss_test:0.09148, lr:4.75e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.199, tt:5355.875\n",
      "Ep:130, loss:0.00001, loss_test:0.09295, lr:4.71e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.208, tt:5398.281\n",
      "Ep:131, loss:0.00001, loss_test:0.09184, lr:4.66e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.216, tt:5440.450\n",
      "Ep:132, loss:0.00001, loss_test:0.09195, lr:4.61e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.225, tt:5482.903\n",
      "Ep:133, loss:0.00001, loss_test:0.09276, lr:4.57e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.242, tt:5526.419\n",
      "Ep:134, loss:0.00001, loss_test:0.09238, lr:4.52e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.244, tt:5567.910\n",
      "Ep:135, loss:0.00001, loss_test:0.09201, lr:4.48e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.248, tt:5609.792\n",
      "Ep:136, loss:0.00001, loss_test:0.09157, lr:4.43e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.264, tt:5653.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.09229, lr:4.39e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.247, tt:5692.106\n",
      "Ep:138, loss:0.00001, loss_test:0.09107, lr:4.34e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.243, tt:5732.817\n",
      "Ep:139, loss:0.00001, loss_test:0.09310, lr:4.30e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.251, tt:5775.112\n",
      "Ep:140, loss:0.00001, loss_test:0.09231, lr:4.26e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.240, tt:5814.859\n",
      "Ep:141, loss:0.00001, loss_test:0.09246, lr:4.21e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.236, tt:5855.455\n",
      "Ep:142, loss:0.00001, loss_test:0.09323, lr:4.17e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.240, tt:5897.349\n",
      "Ep:143, loss:0.00001, loss_test:0.09249, lr:4.13e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.257, tt:5940.952\n",
      "Ep:144, loss:0.00001, loss_test:0.09236, lr:4.09e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.264, tt:5983.222\n",
      "Ep:145, loss:0.00001, loss_test:0.09341, lr:4.05e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.252, tt:6022.753\n",
      "Ep:146, loss:0.00000, loss_test:0.09336, lr:4.01e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.238, tt:6062.008\n",
      "Ep:147, loss:0.00000, loss_test:0.09176, lr:3.97e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.245, tt:6104.196\n",
      "Ep:148, loss:0.00000, loss_test:0.09278, lr:3.93e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.266, tt:6148.602\n",
      "Ep:149, loss:0.00000, loss_test:0.09315, lr:3.89e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.282, tt:6192.362\n",
      "Ep:150, loss:0.00000, loss_test:0.09278, lr:3.85e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.293, tt:6235.176\n",
      "Ep:151, loss:0.00000, loss_test:0.09088, lr:3.81e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.305, tt:6278.383\n",
      "Ep:152, loss:0.00000, loss_test:0.09342, lr:3.77e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.295, tt:6318.130\n",
      "Ep:153, loss:0.00000, loss_test:0.09181, lr:3.73e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.296, tt:6359.534\n",
      "Ep:154, loss:0.00000, loss_test:0.09340, lr:3.70e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.314, tt:6403.689\n",
      "Ep:155, loss:0.00000, loss_test:0.09376, lr:3.66e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.324, tt:6446.518\n",
      "Ep:156, loss:0.00000, loss_test:0.09212, lr:3.62e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.340, tt:6490.382\n",
      "Ep:157, loss:0.00000, loss_test:0.09335, lr:3.59e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.357, tt:6534.425\n",
      "Ep:158, loss:0.00000, loss_test:0.09271, lr:3.55e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.372, tt:6578.223\n",
      "Ep:159, loss:0.00000, loss_test:0.09386, lr:3.52e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.393, tt:6622.902\n",
      "Ep:160, loss:0.00000, loss_test:0.09303, lr:3.48e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.417, tt:6668.065\n",
      "Ep:161, loss:0.00000, loss_test:0.09261, lr:3.45e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.413, tt:6708.858\n",
      "Ep:162, loss:0.00000, loss_test:0.09313, lr:3.41e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.425, tt:6752.247\n",
      "Ep:163, loss:0.00000, loss_test:0.09231, lr:3.38e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.442, tt:6796.450\n",
      "Ep:164, loss:0.00000, loss_test:0.09295, lr:3.34e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.457, tt:6840.389\n",
      "Ep:165, loss:0.00000, loss_test:0.09339, lr:3.31e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.453, tt:6881.192\n",
      "Ep:166, loss:0.00000, loss_test:0.09255, lr:3.28e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.464, tt:6924.438\n",
      "Ep:167, loss:0.00000, loss_test:0.09367, lr:3.24e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.515, tt:6974.585\n",
      "Ep:168, loss:0.00000, loss_test:0.09277, lr:3.21e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.532, tt:7018.961\n",
      "Ep:169, loss:0.00000, loss_test:0.09320, lr:3.18e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.528, tt:7059.729\n",
      "Ep:170, loss:0.00000, loss_test:0.09266, lr:3.15e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.547, tt:7104.604\n",
      "Ep:171, loss:0.00000, loss_test:0.09295, lr:3.12e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.565, tt:7149.196\n",
      "Ep:172, loss:0.00000, loss_test:0.09309, lr:3.09e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.577, tt:7192.839\n",
      "Ep:173, loss:0.00000, loss_test:0.09263, lr:3.05e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.591, tt:7236.755\n",
      "Ep:174, loss:0.00000, loss_test:0.09394, lr:3.02e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.605, tt:7280.955\n",
      "Ep:175, loss:0.00000, loss_test:0.09345, lr:2.99e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.611, tt:7323.482\n",
      "Ep:176, loss:0.00000, loss_test:0.09340, lr:2.96e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.608, tt:7364.701\n",
      "Ep:177, loss:0.00000, loss_test:0.09309, lr:2.93e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.610, tt:7406.568\n",
      "Ep:178, loss:0.00000, loss_test:0.09261, lr:2.90e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.606, tt:7447.412\n",
      "Ep:179, loss:0.00000, loss_test:0.09351, lr:2.88e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.607, tt:7489.275\n",
      "Ep:180, loss:0.00000, loss_test:0.09370, lr:2.85e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.613, tt:7531.871\n",
      "Ep:181, loss:0.00000, loss_test:0.09309, lr:2.82e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.620, tt:7574.830\n",
      "Ep:182, loss:0.00000, loss_test:0.09324, lr:2.79e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.633, tt:7618.757\n",
      "Ep:183, loss:0.00000, loss_test:0.09277, lr:2.76e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.641, tt:7661.924\n",
      "Ep:184, loss:0.00000, loss_test:0.09330, lr:2.73e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.645, tt:7704.311\n",
      "Ep:185, loss:0.00000, loss_test:0.09309, lr:2.71e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.658, tt:7748.302\n",
      "Ep:186, loss:0.00000, loss_test:0.09338, lr:2.68e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.668, tt:7791.985\n",
      "Ep:187, loss:0.00000, loss_test:0.09319, lr:2.65e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.695, tt:7838.744\n",
      "Ep:188, loss:0.00000, loss_test:0.09307, lr:2.63e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.704, tt:7882.022\n",
      "Ep:189, loss:0.00000, loss_test:0.09329, lr:2.60e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.714, tt:7925.607\n",
      "Ep:190, loss:0.00000, loss_test:0.09305, lr:2.57e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.737, tt:7971.809\n",
      "Ep:191, loss:0.00000, loss_test:0.09400, lr:2.55e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.743, tt:8014.589\n",
      "Ep:192, loss:0.00000, loss_test:0.09327, lr:2.52e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.761, tt:8059.827\n",
      "Ep:193, loss:0.00000, loss_test:0.09338, lr:2.50e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.766, tt:8102.556\n",
      "Ep:194, loss:0.00000, loss_test:0.09386, lr:2.47e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.776, tt:8146.347\n",
      "Ep:195, loss:0.00000, loss_test:0.09364, lr:2.45e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.790, tt:8190.822\n",
      "Ep:196, loss:0.00000, loss_test:0.09330, lr:2.42e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.803, tt:8235.105\n",
      "Ep:197, loss:0.00000, loss_test:0.09321, lr:2.40e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.816, tt:8279.532\n",
      "Ep:198, loss:0.00000, loss_test:0.09390, lr:2.38e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.825, tt:8323.138\n",
      "Ep:199, loss:0.00000, loss_test:0.09409, lr:2.35e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.862, tt:8372.419\n",
      "Ep:200, loss:0.00000, loss_test:0.09341, lr:2.33e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.879, tt:8417.710\n",
      "Ep:201, loss:0.00000, loss_test:0.09368, lr:2.31e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.891, tt:8461.912\n",
      "Ep:202, loss:0.00000, loss_test:0.09346, lr:2.28e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.896, tt:8504.796\n",
      "Ep:203, loss:0.00000, loss_test:0.09324, lr:2.26e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.906, tt:8548.830\n",
      "Ep:204, loss:0.00000, loss_test:0.09431, lr:2.24e-03, fs:0.73077 (r=0.576,p=1.000),  time:41.910, tt:8591.469\n",
      "Ep:205, loss:0.00000, loss_test:0.09415, lr:2.21e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.920, tt:8635.524\n",
      "Ep:206, loss:0.00000, loss_test:0.09348, lr:2.19e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.939, tt:8681.278\n",
      "Ep:207, loss:0.00000, loss_test:0.09383, lr:2.17e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.947, tt:8725.010\n",
      "Ep:208, loss:0.00000, loss_test:0.09388, lr:2.15e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.955, tt:8768.685\n",
      "Ep:209, loss:0.00000, loss_test:0.09331, lr:2.13e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.964, tt:8812.367\n",
      "Ep:210, loss:0.00000, loss_test:0.09410, lr:2.11e-03, fs:0.72611 (r=0.576,p=0.983),  time:41.970, tt:8855.638\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02084, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:35.836, tt:35.836\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02322, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.990, tt:67.980\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02405, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.594, tt:91.781\n",
      "Ep:3, loss:0.00004, loss_test:0.02318, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.224, tt:124.897\n",
      "Ep:4, loss:0.00004, loss_test:0.02198, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:32.789, tt:163.947\n",
      "Ep:5, loss:0.00004, loss_test:0.02097, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:34.640, tt:207.841\n",
      "Ep:6, loss:0.00004, loss_test:0.02046, lr:6.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:36.162, tt:253.132\n",
      "Ep:7, loss:0.00004, loss_test:0.01980, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:37.140, tt:297.116\n",
      "Ep:8, loss:0.00004, loss_test:0.01890, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:38.023, tt:342.204\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01832, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:38.635, tt:386.354\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:39.031, tt:429.346\n",
      "Ep:11, loss:0.00003, loss_test:0.01747, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:39.391, tt:472.688\n",
      "Ep:12, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:39.808, tt:517.508\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01674, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:40.201, tt:562.811\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:40.307, tt:604.612\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:40.777, tt:652.428\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01589, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:40.884, tt:695.030\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:40.991, tt:737.829\n",
      "Ep:18, loss:0.00003, loss_test:0.01535, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:41.068, tt:780.290\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01520, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:41.130, tt:822.593\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:41.245, tt:866.135\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:41.336, tt:909.401\n",
      "Ep:22, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:41.381, tt:951.755\n",
      "Ep:23, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:41.478, tt:995.474\n",
      "Ep:24, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:41.541, tt:1038.522\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:41.589, tt:1081.324\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01425, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:41.638, tt:1124.227\n",
      "Ep:27, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:41.670, tt:1166.753\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:41.680, tt:1208.718\n",
      "Ep:29, loss:0.00002, loss_test:0.01394, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:41.750, tt:1252.494\n",
      "Ep:30, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:41.749, tt:1294.221\n",
      "Ep:31, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:41.812, tt:1338.000\n",
      "Ep:32, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:41.810, tt:1379.744\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:41.848, tt:1422.821\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:41.866, tt:1465.308\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:41.936, tt:1509.679\n",
      "Ep:36, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:41.958, tt:1552.449\n",
      "Ep:37, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:41.953, tt:1594.220\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:41.983, tt:1637.355\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:42.019, tt:1680.762\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:42.009, tt:1722.380\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:42.011, tt:1764.474\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01315, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:42.066, tt:1808.859\n",
      "Ep:43, loss:0.00001, loss_test:0.01311, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:42.048, tt:1850.102\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:42.027, tt:1891.196\n",
      "Ep:45, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:42.003, tt:1932.143\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:41.990, tt:1973.527\n",
      "Ep:47, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:42.018, tt:2016.885\n",
      "Ep:48, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:42.006, tt:2058.315\n",
      "Ep:49, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:41.986, tt:2099.298\n",
      "Ep:50, loss:0.00001, loss_test:0.01304, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:41.992, tt:2141.599\n",
      "Ep:51, loss:0.00001, loss_test:0.01304, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:41.969, tt:2182.370\n",
      "Ep:52, loss:0.00001, loss_test:0.01315, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:41.978, tt:2224.825\n",
      "Ep:53, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:41.970, tt:2266.367\n",
      "Ep:54, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.944, tt:2306.944\n",
      "Ep:55, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.922, tt:2347.623\n",
      "Ep:56, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.906, tt:2388.619\n",
      "Ep:57, loss:0.00001, loss_test:0.01312, lr:5.94e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.873, tt:2428.614\n",
      "Ep:58, loss:0.00001, loss_test:0.01316, lr:5.88e-02, fs:0.83000 (r=0.838,p=0.822),  time:41.872, tt:2470.466\n",
      "Ep:59, loss:0.00001, loss_test:0.01316, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.842, tt:2510.544\n",
      "Ep:60, loss:0.00001, loss_test:0.01318, lr:5.76e-02, fs:0.83000 (r=0.838,p=0.822),  time:41.843, tt:2552.416\n",
      "Ep:61, loss:0.00001, loss_test:0.01319, lr:5.71e-02, fs:0.83417 (r=0.838,p=0.830),  time:41.848, tt:2594.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01327, lr:5.65e-02, fs:0.81633 (r=0.808,p=0.825),  time:41.852, tt:2636.686\n",
      "Ep:63, loss:0.00001, loss_test:0.01332, lr:5.59e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.861, tt:2679.105\n",
      "Ep:64, loss:0.00001, loss_test:0.01329, lr:5.54e-02, fs:0.81633 (r=0.808,p=0.825),  time:41.876, tt:2721.912\n",
      "Ep:65, loss:0.00001, loss_test:0.01334, lr:5.48e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.900, tt:2765.395\n",
      "Ep:66, loss:0.00001, loss_test:0.01336, lr:5.43e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.886, tt:2806.359\n",
      "Ep:67, loss:0.00001, loss_test:0.01340, lr:5.37e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.890, tt:2848.510\n",
      "Ep:68, loss:0.00001, loss_test:0.01348, lr:5.32e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.884, tt:2889.998\n",
      "Ep:69, loss:0.00001, loss_test:0.01355, lr:5.27e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.893, tt:2932.490\n",
      "Ep:70, loss:0.00001, loss_test:0.01356, lr:5.21e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.901, tt:2974.935\n",
      "Ep:71, loss:0.00001, loss_test:0.01355, lr:5.16e-02, fs:0.82474 (r=0.808,p=0.842),  time:41.897, tt:3016.550\n",
      "Ep:72, loss:0.00001, loss_test:0.01360, lr:5.11e-02, fs:0.82902 (r=0.808,p=0.851),  time:41.929, tt:3060.824\n",
      "Ep:73, loss:0.00001, loss_test:0.01371, lr:5.06e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.895, tt:3100.249\n",
      "Ep:74, loss:0.00001, loss_test:0.01373, lr:5.01e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.898, tt:3142.360\n",
      "Ep:75, loss:0.00001, loss_test:0.01377, lr:4.96e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.903, tt:3184.658\n",
      "Ep:76, loss:0.00001, loss_test:0.01380, lr:4.91e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.917, tt:3227.621\n",
      "Ep:77, loss:0.00001, loss_test:0.01388, lr:4.86e-02, fs:0.84211 (r=0.808,p=0.879),  time:41.898, tt:3268.073\n",
      "Ep:78, loss:0.00001, loss_test:0.01390, lr:4.81e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.912, tt:3311.020\n",
      "Ep:79, loss:0.00001, loss_test:0.01396, lr:4.76e-02, fs:0.83770 (r=0.808,p=0.870),  time:41.911, tt:3352.860\n",
      "Ep:80, loss:0.00001, loss_test:0.01401, lr:4.71e-02, fs:0.84656 (r=0.808,p=0.889),  time:41.919, tt:3395.442\n",
      "Ep:81, loss:0.00001, loss_test:0.01406, lr:4.67e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.943, tt:3439.353\n",
      "Ep:82, loss:0.00001, loss_test:0.01411, lr:4.62e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.939, tt:3480.964\n",
      "Ep:83, loss:0.00001, loss_test:0.01415, lr:4.57e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.931, tt:3522.207\n",
      "Ep:84, loss:0.00001, loss_test:0.01419, lr:4.53e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.956, tt:3566.274\n",
      "Ep:85, loss:0.00001, loss_test:0.01430, lr:4.48e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.941, tt:3606.964\n",
      "Ep:86, loss:0.00001, loss_test:0.01430, lr:4.44e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.947, tt:3649.368\n",
      "Ep:87, loss:0.00001, loss_test:0.01431, lr:4.39e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.962, tt:3692.630\n",
      "Ep:88, loss:0.00001, loss_test:0.01436, lr:4.35e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.967, tt:3735.036\n",
      "Ep:89, loss:0.00001, loss_test:0.01441, lr:4.31e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.979, tt:3778.090\n",
      "Ep:90, loss:0.00001, loss_test:0.01447, lr:4.26e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.978, tt:3819.959\n",
      "Ep:91, loss:0.00001, loss_test:0.01457, lr:4.22e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.988, tt:3862.919\n",
      "Ep:92, loss:0.00001, loss_test:0.01455, lr:4.18e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.013, tt:3907.228\n",
      "Ep:93, loss:0.00001, loss_test:0.01461, lr:4.14e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.024, tt:3950.243\n",
      "Ep:94, loss:0.00001, loss_test:0.01464, lr:4.10e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.022, tt:3992.114\n",
      "Ep:95, loss:0.00001, loss_test:0.01471, lr:4.05e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.028, tt:4034.684\n",
      "Ep:96, loss:0.00001, loss_test:0.01472, lr:4.01e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.046, tt:4078.487\n",
      "Ep:97, loss:0.00001, loss_test:0.01479, lr:3.97e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.036, tt:4119.514\n",
      "Ep:98, loss:0.00001, loss_test:0.01480, lr:3.93e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.029, tt:4160.905\n",
      "Ep:99, loss:0.00001, loss_test:0.01487, lr:3.89e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.013, tt:4201.268\n",
      "Ep:100, loss:0.00001, loss_test:0.01487, lr:3.86e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.024, tt:4244.443\n",
      "Ep:101, loss:0.00001, loss_test:0.01491, lr:3.82e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.026, tt:4286.653\n",
      "Ep:102, loss:0.00001, loss_test:0.01498, lr:3.78e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.051, tt:4331.220\n",
      "Ep:103, loss:0.00001, loss_test:0.01500, lr:3.74e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.056, tt:4373.863\n",
      "Ep:104, loss:0.00001, loss_test:0.01504, lr:3.70e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.058, tt:4416.117\n",
      "Ep:105, loss:0.00001, loss_test:0.01509, lr:3.67e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.061, tt:4458.445\n",
      "Ep:106, loss:0.00001, loss_test:0.01510, lr:3.63e-02, fs:0.84492 (r=0.798,p=0.898),  time:42.077, tt:4502.231\n",
      "Ep:107, loss:0.00001, loss_test:0.01514, lr:3.59e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.068, tt:4543.349\n",
      "Ep:108, loss:0.00001, loss_test:0.01519, lr:3.56e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.067, tt:4585.312\n",
      "Ep:109, loss:0.00001, loss_test:0.01521, lr:3.52e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.054, tt:4625.911\n",
      "Ep:110, loss:0.00001, loss_test:0.01526, lr:3.49e-02, fs:0.84324 (r=0.788,p=0.907),  time:42.057, tt:4668.300\n",
      "Ep:111, loss:0.00001, loss_test:0.01533, lr:3.45e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.014, tt:4705.591\n",
      "Ep:112, loss:0.00001, loss_test:0.01531, lr:3.42e-02, fs:0.84324 (r=0.788,p=0.907),  time:42.017, tt:4747.958\n",
      "Ep:113, loss:0.00001, loss_test:0.01535, lr:3.38e-02, fs:0.84324 (r=0.788,p=0.907),  time:41.997, tt:4787.656\n",
      "Ep:114, loss:0.00000, loss_test:0.01542, lr:3.35e-02, fs:0.84324 (r=0.788,p=0.907),  time:41.977, tt:4827.378\n",
      "Ep:115, loss:0.00000, loss_test:0.01541, lr:3.32e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.953, tt:4866.522\n",
      "Ep:116, loss:0.00000, loss_test:0.01550, lr:3.28e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.946, tt:4907.717\n",
      "Ep:117, loss:0.00000, loss_test:0.01551, lr:3.25e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.934, tt:4948.239\n",
      "Ep:118, loss:0.00000, loss_test:0.01554, lr:3.22e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.936, tt:4990.408\n",
      "Ep:119, loss:0.00000, loss_test:0.01557, lr:3.19e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.929, tt:5031.467\n",
      "Ep:120, loss:0.00000, loss_test:0.01560, lr:3.15e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.917, tt:5071.997\n",
      "Ep:121, loss:0.00000, loss_test:0.01565, lr:3.12e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.913, tt:5113.383\n",
      "Ep:122, loss:0.00000, loss_test:0.01570, lr:3.09e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.901, tt:5153.799\n",
      "Ep:123, loss:0.00000, loss_test:0.01569, lr:3.06e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.898, tt:5195.309\n",
      "Ep:124, loss:0.00000, loss_test:0.01578, lr:3.03e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.888, tt:5236.041\n",
      "Ep:125, loss:0.00000, loss_test:0.01581, lr:3.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.872, tt:5275.904\n",
      "Ep:126, loss:0.00000, loss_test:0.01583, lr:2.97e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.849, tt:5314.775\n",
      "Ep:127, loss:0.00000, loss_test:0.01585, lr:2.94e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.848, tt:5356.489\n",
      "Ep:128, loss:0.00000, loss_test:0.01590, lr:2.91e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.835, tt:5396.708\n",
      "Ep:129, loss:0.00000, loss_test:0.01591, lr:2.88e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.831, tt:5438.063\n",
      "Ep:130, loss:0.00000, loss_test:0.01598, lr:2.85e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.814, tt:5477.680\n",
      "Ep:131, loss:0.00000, loss_test:0.01602, lr:2.82e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.797, tt:5517.220\n",
      "Ep:132, loss:0.00000, loss_test:0.01603, lr:2.80e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.803, tt:5559.752\n",
      "Ep:133, loss:0.00000, loss_test:0.01605, lr:2.77e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.797, tt:5600.843\n",
      "Ep:134, loss:0.00000, loss_test:0.01609, lr:2.74e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.797, tt:5642.636\n",
      "Ep:135, loss:0.00000, loss_test:0.01613, lr:2.71e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.791, tt:5683.592\n",
      "Ep:136, loss:0.00000, loss_test:0.01613, lr:2.69e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.775, tt:5723.228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.01614, lr:2.66e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.768, tt:5763.958\n",
      "Ep:138, loss:0.00000, loss_test:0.01622, lr:2.63e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.757, tt:5804.180\n",
      "Ep:139, loss:0.00000, loss_test:0.01627, lr:2.61e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.749, tt:5844.823\n",
      "Ep:140, loss:0.00000, loss_test:0.01628, lr:2.58e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.733, tt:5884.307\n",
      "Ep:141, loss:0.00000, loss_test:0.01629, lr:2.55e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.733, tt:5926.130\n",
      "Ep:142, loss:0.00000, loss_test:0.01632, lr:2.53e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.704, tt:5963.628\n",
      "Ep:143, loss:0.00000, loss_test:0.01639, lr:2.50e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.690, tt:6003.411\n",
      "Ep:144, loss:0.00000, loss_test:0.01641, lr:2.48e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.686, tt:6044.445\n",
      "Ep:145, loss:0.00000, loss_test:0.01643, lr:2.45e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.675, tt:6084.489\n",
      "Ep:146, loss:0.00000, loss_test:0.01646, lr:2.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.665, tt:6124.692\n",
      "Ep:147, loss:0.00000, loss_test:0.01650, lr:2.40e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.660, tt:6165.747\n",
      "Ep:148, loss:0.00000, loss_test:0.01652, lr:2.38e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.655, tt:6206.660\n",
      "Ep:149, loss:0.00000, loss_test:0.01655, lr:2.36e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.642, tt:6246.339\n",
      "Ep:150, loss:0.00000, loss_test:0.01661, lr:2.33e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.641, tt:6287.821\n",
      "Ep:151, loss:0.00000, loss_test:0.01660, lr:2.31e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.638, tt:6328.971\n",
      "Ep:152, loss:0.00000, loss_test:0.01662, lr:2.29e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.632, tt:6369.642\n",
      "Ep:153, loss:0.00000, loss_test:0.01667, lr:2.26e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.636, tt:6412.013\n",
      "Ep:154, loss:0.00000, loss_test:0.01669, lr:2.24e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.628, tt:6452.411\n",
      "Ep:155, loss:0.00000, loss_test:0.01669, lr:2.22e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.628, tt:6493.938\n",
      "Ep:156, loss:0.00000, loss_test:0.01672, lr:2.20e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.620, tt:6534.360\n",
      "Ep:157, loss:0.00000, loss_test:0.01676, lr:2.17e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.622, tt:6576.252\n",
      "Ep:158, loss:0.00000, loss_test:0.01678, lr:2.15e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.641, tt:6620.863\n",
      "Ep:159, loss:0.00000, loss_test:0.01681, lr:2.13e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.624, tt:6659.919\n",
      "Ep:160, loss:0.00000, loss_test:0.01684, lr:2.11e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.606, tt:6698.609\n",
      "Ep:161, loss:0.00000, loss_test:0.01689, lr:2.09e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.587, tt:6737.149\n",
      "Ep:162, loss:0.00000, loss_test:0.01691, lr:2.07e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.567, tt:6775.467\n",
      "Ep:163, loss:0.00000, loss_test:0.01695, lr:2.05e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.560, tt:6815.834\n",
      "Ep:164, loss:0.00000, loss_test:0.01698, lr:2.03e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.537, tt:6853.542\n",
      "Ep:165, loss:0.00000, loss_test:0.01701, lr:2.01e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.528, tt:6893.674\n",
      "Ep:166, loss:0.00000, loss_test:0.01703, lr:1.99e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.519, tt:6933.646\n",
      "Ep:167, loss:0.00000, loss_test:0.01705, lr:1.97e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.501, tt:6972.158\n",
      "Ep:168, loss:0.00000, loss_test:0.01706, lr:1.95e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.487, tt:7011.295\n",
      "Ep:169, loss:0.00000, loss_test:0.01710, lr:1.93e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.477, tt:7051.030\n",
      "Ep:170, loss:0.00000, loss_test:0.01712, lr:1.91e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.453, tt:7088.437\n",
      "Ep:171, loss:0.00000, loss_test:0.01714, lr:1.89e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.437, tt:7127.108\n",
      "Ep:172, loss:0.00000, loss_test:0.01719, lr:1.87e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.429, tt:7167.290\n",
      "Ep:173, loss:0.00000, loss_test:0.01721, lr:1.85e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.421, tt:7207.296\n",
      "Ep:174, loss:0.00000, loss_test:0.01720, lr:1.83e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.401, tt:7245.139\n",
      "Ep:175, loss:0.00000, loss_test:0.01724, lr:1.81e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.383, tt:7283.395\n",
      "Ep:176, loss:0.00000, loss_test:0.01727, lr:1.80e-02, fs:0.84153 (r=0.778,p=0.917),  time:41.377, tt:7323.797\n",
      "Ep:177, loss:0.00000, loss_test:0.01732, lr:1.78e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.368, tt:7363.436\n",
      "Ep:178, loss:0.00000, loss_test:0.01731, lr:1.76e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.363, tt:7403.994\n",
      "Ep:179, loss:0.00000, loss_test:0.01735, lr:1.74e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.360, tt:7444.770\n",
      "Ep:180, loss:0.00000, loss_test:0.01738, lr:1.73e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.349, tt:7484.157\n",
      "Ep:181, loss:0.00000, loss_test:0.01740, lr:1.71e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.345, tt:7524.775\n",
      "Ep:182, loss:0.00000, loss_test:0.01742, lr:1.69e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.343, tt:7565.766\n",
      "Ep:183, loss:0.00000, loss_test:0.01743, lr:1.67e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.330, tt:7604.761\n",
      "Ep:184, loss:0.00000, loss_test:0.01746, lr:1.66e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.321, tt:7644.397\n",
      "Ep:185, loss:0.00000, loss_test:0.01749, lr:1.64e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.305, tt:7682.819\n",
      "Ep:186, loss:0.00000, loss_test:0.01752, lr:1.62e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.297, tt:7722.535\n",
      "Ep:187, loss:0.00000, loss_test:0.01752, lr:1.61e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.288, tt:7762.194\n",
      "Ep:188, loss:0.00000, loss_test:0.01755, lr:1.59e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.279, tt:7801.813\n",
      "Ep:189, loss:0.00000, loss_test:0.01757, lr:1.58e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.282, tt:7843.559\n",
      "Ep:190, loss:0.00000, loss_test:0.01760, lr:1.56e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.278, tt:7884.077\n",
      "Ep:191, loss:0.00000, loss_test:0.01762, lr:1.54e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.269, tt:7923.708\n",
      "Ep:192, loss:0.00000, loss_test:0.01764, lr:1.53e-02, fs:0.82873 (r=0.758,p=0.915),  time:41.262, tt:7963.472\n",
      "Ep:193, loss:0.00000, loss_test:0.01766, lr:1.51e-02, fs:0.82873 (r=0.758,p=0.915),  time:41.246, tt:8001.782\n",
      "Ep:194, loss:0.00000, loss_test:0.01769, lr:1.50e-02, fs:0.82873 (r=0.758,p=0.915),  time:41.243, tt:8042.434\n",
      "Ep:195, loss:0.00000, loss_test:0.01771, lr:1.48e-02, fs:0.82873 (r=0.758,p=0.915),  time:41.249, tt:8084.744\n",
      "Ep:196, loss:0.00000, loss_test:0.01770, lr:1.47e-02, fs:0.82873 (r=0.758,p=0.915),  time:41.247, tt:8125.621\n",
      "Ep:197, loss:0.00000, loss_test:0.01773, lr:1.45e-02, fs:0.82873 (r=0.758,p=0.915),  time:41.239, tt:8165.255\n",
      "Ep:198, loss:0.00000, loss_test:0.01776, lr:1.44e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.223, tt:8203.342\n",
      "Ep:199, loss:0.00000, loss_test:0.01778, lr:1.43e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.215, tt:8243.009\n",
      "Ep:200, loss:0.00000, loss_test:0.01779, lr:1.41e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.247, tt:8290.672\n",
      "Ep:201, loss:0.00000, loss_test:0.01782, lr:1.40e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.253, tt:8333.047\n",
      "Ep:202, loss:0.00000, loss_test:0.01784, lr:1.38e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.247, tt:8373.188\n",
      "Ep:203, loss:0.00000, loss_test:0.01784, lr:1.37e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.233, tt:8411.550\n",
      "Ep:204, loss:0.00000, loss_test:0.01787, lr:1.36e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.220, tt:8450.011\n",
      "Ep:205, loss:0.00000, loss_test:0.01788, lr:1.34e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.221, tt:8491.451\n",
      "Ep:206, loss:0.00000, loss_test:0.01790, lr:1.33e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.217, tt:8531.887\n",
      "Ep:207, loss:0.00000, loss_test:0.01791, lr:1.32e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.223, tt:8574.433\n",
      "Ep:208, loss:0.00000, loss_test:0.01793, lr:1.30e-02, fs:0.82222 (r=0.747,p=0.914),  time:41.226, tt:8616.190\n",
      "Ep:209, loss:0.00000, loss_test:0.01796, lr:1.29e-02, fs:0.81564 (r=0.737,p=0.912),  time:41.237, tt:8659.793\n",
      "Ep:210, loss:0.00000, loss_test:0.01797, lr:1.28e-02, fs:0.81564 (r=0.737,p=0.912),  time:41.230, tt:8699.463\n",
      "Ep:211, loss:0.00000, loss_test:0.01798, lr:1.26e-02, fs:0.81564 (r=0.737,p=0.912),  time:41.232, tt:8741.150\n",
      "Model and results saved\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14425, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.398, tt:39.398\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14328, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.434, tt:74.867\n",
      "Ep:2, loss:0.00028, loss_test:0.14156, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:35.978, tt:107.934\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13866, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:34.844, tt:139.376\n",
      "Ep:4, loss:0.00026, loss_test:0.13484, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:35.489, tt:177.443\n",
      "Ep:5, loss:0.00025, loss_test:0.13146, lr:1.00e-02, fs:0.61905 (r=0.788,p=0.510),  time:36.405, tt:218.431\n",
      "Ep:6, loss:0.00024, loss_test:0.12757, lr:1.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:37.094, tt:259.658\n",
      "Ep:7, loss:0.00023, loss_test:0.12194, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:37.608, tt:300.862\n",
      "Ep:8, loss:0.00022, loss_test:0.11853, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:38.314, tt:344.826\n",
      "Ep:9, loss:0.00021, loss_test:0.11647, lr:1.00e-02, fs:0.63717 (r=0.727,p=0.567),  time:38.757, tt:387.569\n",
      "Ep:10, loss:0.00020, loss_test:0.11326, lr:1.00e-02, fs:0.66359 (r=0.727,p=0.610),  time:38.869, tt:427.563\n",
      "Ep:11, loss:0.00020, loss_test:0.10871, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:39.162, tt:469.943\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10470, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:39.488, tt:513.345\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10269, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:39.658, tt:555.211\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10114, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:39.897, tt:598.455\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09961, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:40.196, tt:643.135\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09803, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:40.259, tt:684.407\n",
      "Ep:17, loss:0.00016, loss_test:0.09614, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:40.344, tt:726.198\n",
      "Ep:18, loss:0.00015, loss_test:0.09403, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.378, tt:767.175\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09301, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:40.438, tt:808.753\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09173, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:40.456, tt:849.578\n",
      "Ep:21, loss:0.00013, loss_test:0.09042, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:40.532, tt:891.714\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08905, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:40.535, tt:932.304\n",
      "Ep:23, loss:0.00012, loss_test:0.08903, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:40.628, tt:975.083\n",
      "Ep:24, loss:0.00012, loss_test:0.08819, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:40.691, tt:1017.272\n",
      "Ep:25, loss:0.00011, loss_test:0.08667, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:40.744, tt:1059.338\n",
      "Ep:26, loss:0.00011, loss_test:0.08652, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:40.828, tt:1102.360\n",
      "Ep:27, loss:0.00010, loss_test:0.08744, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:40.886, tt:1144.795\n",
      "Ep:28, loss:0.00010, loss_test:0.08355, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:41.020, tt:1189.587\n",
      "Ep:29, loss:0.00010, loss_test:0.08370, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:41.019, tt:1230.555\n",
      "Ep:30, loss:0.00009, loss_test:0.08530, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:41.058, tt:1272.798\n",
      "Ep:31, loss:0.00009, loss_test:0.08177, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:41.085, tt:1314.713\n",
      "Ep:32, loss:0.00008, loss_test:0.08697, lr:1.00e-02, fs:0.69939 (r=0.576,p=0.891),  time:41.131, tt:1357.307\n",
      "Ep:33, loss:0.00008, loss_test:0.08064, lr:9.90e-03, fs:0.80412 (r=0.788,p=0.821),  time:41.134, tt:1398.562\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.08822, lr:9.90e-03, fs:0.71605 (r=0.586,p=0.921),  time:41.175, tt:1441.127\n",
      "Ep:35, loss:0.00007, loss_test:0.07954, lr:9.90e-03, fs:0.80435 (r=0.747,p=0.871),  time:41.148, tt:1481.318\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.08192, lr:9.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.122, tt:1521.510\n",
      "Ep:37, loss:0.00007, loss_test:0.08371, lr:9.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.134, tt:1563.105\n",
      "Ep:38, loss:0.00006, loss_test:0.08030, lr:9.90e-03, fs:0.75862 (r=0.667,p=0.880),  time:41.189, tt:1606.376\n",
      "Ep:39, loss:0.00006, loss_test:0.08445, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:41.201, tt:1648.043\n",
      "Ep:40, loss:0.00006, loss_test:0.07680, lr:9.90e-03, fs:0.82653 (r=0.818,p=0.835),  time:41.286, tt:1692.711\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.08677, lr:9.90e-03, fs:0.70732 (r=0.586,p=0.892),  time:41.298, tt:1734.505\n",
      "Ep:42, loss:0.00005, loss_test:0.07889, lr:9.90e-03, fs:0.80226 (r=0.717,p=0.910),  time:41.314, tt:1776.496\n",
      "Ep:43, loss:0.00005, loss_test:0.08562, lr:9.90e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.300, tt:1817.220\n",
      "Ep:44, loss:0.00005, loss_test:0.07738, lr:9.90e-03, fs:0.79545 (r=0.707,p=0.909),  time:41.334, tt:1860.035\n",
      "Ep:45, loss:0.00005, loss_test:0.08399, lr:9.90e-03, fs:0.73810 (r=0.626,p=0.899),  time:41.360, tt:1902.577\n",
      "Ep:46, loss:0.00005, loss_test:0.07890, lr:9.90e-03, fs:0.77457 (r=0.677,p=0.905),  time:41.388, tt:1945.249\n",
      "Ep:47, loss:0.00005, loss_test:0.08315, lr:9.90e-03, fs:0.71605 (r=0.586,p=0.921),  time:41.370, tt:1985.748\n",
      "Ep:48, loss:0.00004, loss_test:0.07467, lr:9.90e-03, fs:0.83696 (r=0.778,p=0.906),  time:41.381, tt:2027.650\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.08090, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.398, tt:2069.925\n",
      "Ep:50, loss:0.00004, loss_test:0.07782, lr:9.90e-03, fs:0.75294 (r=0.646,p=0.901),  time:41.406, tt:2111.701\n",
      "Ep:51, loss:0.00004, loss_test:0.07615, lr:9.90e-03, fs:0.78161 (r=0.687,p=0.907),  time:41.412, tt:2153.446\n",
      "Ep:52, loss:0.00004, loss_test:0.08173, lr:9.90e-03, fs:0.72289 (r=0.606,p=0.896),  time:41.453, tt:2197.020\n",
      "Ep:53, loss:0.00004, loss_test:0.07701, lr:9.90e-03, fs:0.77457 (r=0.677,p=0.905),  time:41.451, tt:2238.364\n",
      "Ep:54, loss:0.00003, loss_test:0.07796, lr:9.90e-03, fs:0.73810 (r=0.626,p=0.899),  time:41.429, tt:2278.580\n",
      "Ep:55, loss:0.00003, loss_test:0.07481, lr:9.90e-03, fs:0.77457 (r=0.677,p=0.905),  time:41.405, tt:2318.696\n",
      "Ep:56, loss:0.00003, loss_test:0.07724, lr:9.90e-03, fs:0.73054 (r=0.616,p=0.897),  time:41.421, tt:2360.976\n",
      "Ep:57, loss:0.00003, loss_test:0.08373, lr:9.90e-03, fs:0.71166 (r=0.586,p=0.906),  time:41.401, tt:2401.283\n",
      "Ep:58, loss:0.00003, loss_test:0.07855, lr:9.90e-03, fs:0.78824 (r=0.677,p=0.944),  time:41.447, tt:2445.387\n",
      "Ep:59, loss:0.00003, loss_test:0.08567, lr:9.90e-03, fs:0.71166 (r=0.586,p=0.906),  time:41.466, tt:2487.969\n",
      "Ep:60, loss:0.00003, loss_test:0.08221, lr:9.80e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.503, tt:2531.708\n",
      "Ep:61, loss:0.00003, loss_test:0.08093, lr:9.70e-03, fs:0.72727 (r=0.606,p=0.909),  time:41.478, tt:2571.628\n",
      "Ep:62, loss:0.00003, loss_test:0.08558, lr:9.61e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.526, tt:2616.138\n",
      "Ep:63, loss:0.00003, loss_test:0.08160, lr:9.51e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.557, tt:2659.656\n",
      "Ep:64, loss:0.00003, loss_test:0.08985, lr:9.41e-03, fs:0.70000 (r=0.566,p=0.918),  time:41.645, tt:2706.895\n",
      "Ep:65, loss:0.00002, loss_test:0.07817, lr:9.32e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.674, tt:2750.473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.08602, lr:9.23e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.696, tt:2793.644\n",
      "Ep:67, loss:0.00002, loss_test:0.08053, lr:9.14e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.726, tt:2837.370\n",
      "Ep:68, loss:0.00002, loss_test:0.08440, lr:9.04e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.741, tt:2880.114\n",
      "Ep:69, loss:0.00002, loss_test:0.07981, lr:8.95e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.773, tt:2924.098\n",
      "Ep:70, loss:0.00002, loss_test:0.09003, lr:8.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.787, tt:2966.859\n",
      "Ep:71, loss:0.00002, loss_test:0.08741, lr:8.78e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.821, tt:3011.089\n",
      "Ep:72, loss:0.00002, loss_test:0.08475, lr:8.69e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.839, tt:3054.220\n",
      "Ep:73, loss:0.00002, loss_test:0.09201, lr:8.60e-03, fs:0.70064 (r=0.556,p=0.948),  time:41.795, tt:3092.802\n",
      "Ep:74, loss:0.00002, loss_test:0.08221, lr:8.51e-03, fs:0.72050 (r=0.586,p=0.935),  time:41.771, tt:3132.789\n",
      "Ep:75, loss:0.00002, loss_test:0.08818, lr:8.43e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.779, tt:3175.168\n",
      "Ep:76, loss:0.00002, loss_test:0.08576, lr:8.35e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.809, tt:3219.316\n",
      "Ep:77, loss:0.00001, loss_test:0.08757, lr:8.26e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.822, tt:3262.080\n",
      "Ep:78, loss:0.00001, loss_test:0.08380, lr:8.18e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.799, tt:3302.159\n",
      "Ep:79, loss:0.00001, loss_test:0.08566, lr:8.10e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.817, tt:3345.383\n",
      "Ep:80, loss:0.00001, loss_test:0.08774, lr:8.02e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.813, tt:3386.832\n",
      "Ep:81, loss:0.00001, loss_test:0.08795, lr:7.94e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.823, tt:3429.495\n",
      "Ep:82, loss:0.00001, loss_test:0.08803, lr:7.86e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.825, tt:3471.437\n",
      "Ep:83, loss:0.00001, loss_test:0.08762, lr:7.78e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.837, tt:3514.285\n",
      "Ep:84, loss:0.00001, loss_test:0.09083, lr:7.70e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.837, tt:3556.112\n",
      "Ep:85, loss:0.00001, loss_test:0.08551, lr:7.62e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.858, tt:3599.795\n",
      "Ep:86, loss:0.00001, loss_test:0.09164, lr:7.55e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.842, tt:3640.214\n",
      "Ep:87, loss:0.00001, loss_test:0.08712, lr:7.47e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.817, tt:3679.882\n",
      "Ep:88, loss:0.00001, loss_test:0.09101, lr:7.40e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.817, tt:3721.733\n",
      "Ep:89, loss:0.00001, loss_test:0.08762, lr:7.32e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.787, tt:3760.795\n",
      "Ep:90, loss:0.00001, loss_test:0.08833, lr:7.25e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.788, tt:3802.698\n",
      "Ep:91, loss:0.00001, loss_test:0.09115, lr:7.18e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.761, tt:3842.018\n",
      "Ep:92, loss:0.00001, loss_test:0.08608, lr:7.11e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.740, tt:3881.856\n",
      "Ep:93, loss:0.00001, loss_test:0.09112, lr:7.03e-03, fs:0.70440 (r=0.566,p=0.933),  time:41.747, tt:3924.218\n",
      "Ep:94, loss:0.00001, loss_test:0.08650, lr:6.96e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.729, tt:3964.247\n",
      "Ep:95, loss:0.00001, loss_test:0.09259, lr:6.89e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.712, tt:4004.350\n",
      "Ep:96, loss:0.00001, loss_test:0.08637, lr:6.83e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.698, tt:4044.717\n",
      "Ep:97, loss:0.00001, loss_test:0.09315, lr:6.76e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.684, tt:4085.018\n",
      "Ep:98, loss:0.00001, loss_test:0.09187, lr:6.69e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.676, tt:4125.925\n",
      "Ep:99, loss:0.00001, loss_test:0.08788, lr:6.62e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.656, tt:4165.627\n",
      "Ep:100, loss:0.00001, loss_test:0.09685, lr:6.56e-03, fs:0.69231 (r=0.545,p=0.947),  time:41.615, tt:4203.155\n",
      "Ep:101, loss:0.00001, loss_test:0.09065, lr:6.49e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.589, tt:4242.108\n",
      "Ep:102, loss:0.00001, loss_test:0.08933, lr:6.43e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.587, tt:4283.485\n",
      "Ep:103, loss:0.00001, loss_test:0.09164, lr:6.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.575, tt:4323.825\n",
      "Ep:104, loss:0.00001, loss_test:0.09507, lr:6.30e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.583, tt:4366.246\n",
      "Ep:105, loss:0.00001, loss_test:0.08856, lr:6.24e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.574, tt:4406.809\n",
      "Ep:106, loss:0.00001, loss_test:0.09661, lr:6.17e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.578, tt:4448.856\n",
      "Ep:107, loss:0.00001, loss_test:0.09058, lr:6.11e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.550, tt:4487.423\n",
      "Ep:108, loss:0.00001, loss_test:0.09039, lr:6.05e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.542, tt:4528.071\n",
      "Ep:109, loss:0.00001, loss_test:0.09381, lr:5.99e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.531, tt:4568.447\n",
      "Ep:110, loss:0.00001, loss_test:0.09364, lr:5.93e-03, fs:0.70886 (r=0.566,p=0.949),  time:41.511, tt:4607.717\n",
      "Ep:111, loss:0.00001, loss_test:0.09048, lr:5.87e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.503, tt:4648.356\n",
      "Ep:112, loss:0.00001, loss_test:0.09685, lr:5.81e-03, fs:0.70513 (r=0.556,p=0.965),  time:41.496, tt:4689.027\n",
      "Ep:113, loss:0.00001, loss_test:0.09484, lr:5.75e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.494, tt:4730.354\n",
      "Ep:114, loss:0.00001, loss_test:0.09103, lr:5.70e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.482, tt:4770.422\n",
      "Ep:115, loss:0.00001, loss_test:0.09459, lr:5.64e-03, fs:0.70513 (r=0.556,p=0.965),  time:41.466, tt:4810.005\n",
      "Ep:116, loss:0.00001, loss_test:0.09234, lr:5.58e-03, fs:0.71250 (r=0.576,p=0.934),  time:41.470, tt:4852.033\n",
      "Ep:117, loss:0.00000, loss_test:0.09201, lr:5.53e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.476, tt:4894.145\n",
      "Ep:118, loss:0.00000, loss_test:0.09384, lr:5.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.457, tt:4933.414\n",
      "Ep:119, loss:0.00000, loss_test:0.09245, lr:5.42e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.432, tt:4971.784\n",
      "Ep:120, loss:0.00000, loss_test:0.09223, lr:5.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:41.423, tt:5012.219\n",
      "Ep:121, loss:0.00000, loss_test:0.09317, lr:5.31e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.426, tt:5053.989\n",
      "Ep:122, loss:0.00000, loss_test:0.09219, lr:5.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.430, tt:5095.948\n",
      "Ep:123, loss:0.00000, loss_test:0.09115, lr:5.20e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.432, tt:5137.579\n",
      "Ep:124, loss:0.00000, loss_test:0.09435, lr:5.15e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.430, tt:5178.787\n",
      "Ep:125, loss:0.00000, loss_test:0.09260, lr:5.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.425, tt:5219.576\n",
      "Ep:126, loss:0.00000, loss_test:0.09252, lr:5.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.442, tt:5263.189\n",
      "Ep:127, loss:0.00000, loss_test:0.09261, lr:5.00e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.437, tt:5303.899\n",
      "Ep:128, loss:0.00000, loss_test:0.09275, lr:4.95e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.437, tt:5345.332\n",
      "Ep:129, loss:0.00000, loss_test:0.09201, lr:4.90e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.483, tt:5392.827\n",
      "Ep:130, loss:0.00000, loss_test:0.09543, lr:4.85e-03, fs:0.71338 (r=0.566,p=0.966),  time:41.487, tt:5434.785\n",
      "Ep:131, loss:0.00000, loss_test:0.09353, lr:4.80e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.494, tt:5477.151\n",
      "Ep:132, loss:0.00000, loss_test:0.09179, lr:4.75e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.496, tt:5519.016\n",
      "Ep:133, loss:0.00000, loss_test:0.09398, lr:4.71e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.495, tt:5560.376\n",
      "Ep:134, loss:0.00000, loss_test:0.09281, lr:4.66e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.481, tt:5599.997\n",
      "Ep:135, loss:0.00000, loss_test:0.09180, lr:4.61e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:5641.128\n",
      "Ep:136, loss:0.00000, loss_test:0.09240, lr:4.57e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.463, tt:5680.419\n",
      "Ep:137, loss:0.00000, loss_test:0.09380, lr:4.52e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.468, tt:5722.538\n",
      "Ep:138, loss:0.00000, loss_test:0.09208, lr:4.48e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.466, tt:5763.785\n",
      "Ep:139, loss:0.00000, loss_test:0.09218, lr:4.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.463, tt:5804.877\n",
      "Ep:140, loss:0.00000, loss_test:0.09384, lr:4.39e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.472, tt:5847.572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.09354, lr:4.34e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:5889.984\n",
      "Ep:142, loss:0.00000, loss_test:0.09168, lr:4.30e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.466, tt:5929.620\n",
      "Ep:143, loss:0.00000, loss_test:0.09285, lr:4.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.468, tt:5971.353\n",
      "Ep:144, loss:0.00000, loss_test:0.09428, lr:4.21e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.469, tt:6013.004\n",
      "Ep:145, loss:0.00000, loss_test:0.09170, lr:4.17e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.481, tt:6056.258\n",
      "Ep:146, loss:0.00000, loss_test:0.09540, lr:4.13e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.478, tt:6097.297\n",
      "Ep:147, loss:0.00000, loss_test:0.09449, lr:4.09e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.473, tt:6137.968\n",
      "Ep:148, loss:0.00000, loss_test:0.09295, lr:4.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.460, tt:6177.604\n",
      "Ep:149, loss:0.00000, loss_test:0.09337, lr:4.01e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.452, tt:6217.773\n",
      "Ep:150, loss:0.00000, loss_test:0.09306, lr:3.97e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.466, tt:6261.339\n",
      "Ep:151, loss:0.00000, loss_test:0.09472, lr:3.93e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.454, tt:6301.082\n",
      "Ep:152, loss:0.00000, loss_test:0.09152, lr:3.89e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.473, tt:6345.400\n",
      "Ep:153, loss:0.00000, loss_test:0.09355, lr:3.85e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.483, tt:6388.430\n",
      "Ep:154, loss:0.00000, loss_test:0.09431, lr:3.81e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.474, tt:6428.454\n",
      "Ep:155, loss:0.00000, loss_test:0.09144, lr:3.77e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.480, tt:6470.946\n",
      "Ep:156, loss:0.00000, loss_test:0.09305, lr:3.73e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:6512.163\n",
      "Ep:157, loss:0.00000, loss_test:0.09528, lr:3.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.486, tt:6554.720\n",
      "Ep:158, loss:0.00000, loss_test:0.09362, lr:3.66e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.489, tt:6596.827\n",
      "Ep:159, loss:0.00000, loss_test:0.09168, lr:3.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.487, tt:6637.937\n",
      "Ep:160, loss:0.00000, loss_test:0.09335, lr:3.59e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.477, tt:6677.787\n",
      "Ep:161, loss:0.00000, loss_test:0.09353, lr:3.55e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.467, tt:6717.574\n",
      "Ep:162, loss:0.00000, loss_test:0.09168, lr:3.52e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.466, tt:6758.932\n",
      "Ep:163, loss:0.00000, loss_test:0.09404, lr:3.48e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:6802.623\n",
      "Ep:164, loss:0.00000, loss_test:0.09491, lr:3.45e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.483, tt:6844.747\n",
      "Ep:165, loss:0.00000, loss_test:0.09242, lr:3.41e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:6885.526\n",
      "Ep:166, loss:0.00000, loss_test:0.09294, lr:3.38e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.475, tt:6926.409\n",
      "Ep:167, loss:0.00000, loss_test:0.09357, lr:3.34e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.478, tt:6968.335\n",
      "Ep:168, loss:0.00000, loss_test:0.09324, lr:3.31e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:7010.011\n",
      "Ep:169, loss:0.00000, loss_test:0.09224, lr:3.28e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.474, tt:7050.521\n",
      "Ep:170, loss:0.00000, loss_test:0.09349, lr:3.24e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.493, tt:7095.233\n",
      "Ep:171, loss:0.00000, loss_test:0.09427, lr:3.21e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.500, tt:7138.028\n",
      "Ep:172, loss:0.00000, loss_test:0.09336, lr:3.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.498, tt:7179.223\n",
      "Ep:173, loss:0.00000, loss_test:0.09264, lr:3.15e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.504, tt:7221.709\n",
      "Ep:174, loss:0.00000, loss_test:0.09348, lr:3.12e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.485, tt:7259.850\n",
      "Ep:175, loss:0.00000, loss_test:0.09347, lr:3.09e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.488, tt:7301.864\n",
      "Ep:176, loss:0.00000, loss_test:0.09273, lr:3.05e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.492, tt:7344.060\n",
      "Ep:177, loss:0.00000, loss_test:0.09342, lr:3.02e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.492, tt:7385.587\n",
      "Ep:178, loss:0.00000, loss_test:0.09366, lr:2.99e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.497, tt:7427.883\n",
      "Ep:179, loss:0.00000, loss_test:0.09255, lr:2.96e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.490, tt:7468.258\n",
      "Ep:180, loss:0.00000, loss_test:0.09230, lr:2.93e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.493, tt:7510.276\n",
      "Ep:181, loss:0.00000, loss_test:0.09323, lr:2.90e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.508, tt:7554.439\n",
      "Ep:182, loss:0.00000, loss_test:0.09312, lr:2.88e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.515, tt:7597.298\n",
      "Ep:183, loss:0.00000, loss_test:0.09249, lr:2.85e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.511, tt:7638.049\n",
      "Ep:184, loss:0.00000, loss_test:0.09337, lr:2.82e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.509, tt:7679.095\n",
      "Ep:185, loss:0.00000, loss_test:0.09351, lr:2.79e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.510, tt:7720.925\n",
      "Ep:186, loss:0.00000, loss_test:0.09331, lr:2.76e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.518, tt:7763.780\n",
      "Ep:187, loss:0.00000, loss_test:0.09287, lr:2.73e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.515, tt:7804.903\n",
      "Ep:188, loss:0.00000, loss_test:0.09344, lr:2.71e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.516, tt:7846.559\n",
      "Ep:189, loss:0.00000, loss_test:0.09370, lr:2.68e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.516, tt:7888.054\n",
      "Ep:190, loss:0.00000, loss_test:0.09231, lr:2.65e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.507, tt:7927.752\n",
      "Ep:191, loss:0.00000, loss_test:0.09313, lr:2.63e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.509, tt:7969.695\n",
      "Ep:192, loss:0.00000, loss_test:0.09454, lr:2.60e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.505, tt:8010.497\n",
      "Ep:193, loss:0.00000, loss_test:0.09390, lr:2.57e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.504, tt:8051.853\n",
      "Ep:194, loss:0.00000, loss_test:0.09343, lr:2.55e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.493, tt:8091.092\n",
      "Ep:195, loss:0.00000, loss_test:0.09353, lr:2.52e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.489, tt:8131.874\n",
      "Ep:196, loss:0.00000, loss_test:0.09341, lr:2.50e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.488, tt:8173.109\n",
      "Ep:197, loss:0.00000, loss_test:0.09301, lr:2.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.485, tt:8213.933\n",
      "Ep:198, loss:0.00000, loss_test:0.09268, lr:2.45e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.504, tt:8259.289\n",
      "Ep:199, loss:0.00000, loss_test:0.09262, lr:2.42e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.498, tt:8299.652\n",
      "Ep:200, loss:0.00000, loss_test:0.09337, lr:2.40e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.497, tt:8340.955\n",
      "Ep:201, loss:0.00000, loss_test:0.09324, lr:2.38e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.484, tt:8379.722\n",
      "Ep:202, loss:0.00000, loss_test:0.09284, lr:2.35e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.482, tt:8420.861\n",
      "Ep:203, loss:0.00000, loss_test:0.09347, lr:2.33e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.484, tt:8462.727\n",
      "Ep:204, loss:0.00000, loss_test:0.09335, lr:2.31e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.488, tt:8504.962\n",
      "Ep:205, loss:0.00000, loss_test:0.09274, lr:2.28e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.480, tt:8544.908\n",
      "Ep:206, loss:0.00000, loss_test:0.09268, lr:2.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:8586.244\n",
      "Ep:207, loss:0.00000, loss_test:0.09267, lr:2.24e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.475, tt:8626.826\n",
      "Ep:208, loss:0.00000, loss_test:0.09274, lr:2.21e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.482, tt:8669.757\n",
      "Ep:209, loss:0.00000, loss_test:0.09299, lr:2.19e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.479, tt:8710.659\n",
      "Ep:210, loss:0.00000, loss_test:0.09308, lr:2.17e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.486, tt:8753.629\n",
      "Ep:211, loss:0.00000, loss_test:0.09308, lr:2.15e-03, fs:0.72152 (r=0.576,p=0.966),  time:41.486, tt:8794.943\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02016, lr:6.00e-02, fs:0.63393 (r=0.816,p=0.518),  time:12.921, tt:12.921\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02210, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:12.819, tt:25.638\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02270, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.049, tt:39.148\n",
      "Ep:3, loss:0.00004, loss_test:0.02169, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:13.345, tt:53.382\n",
      "Ep:4, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.66932 (r=0.966,p=0.512),  time:14.511, tt:72.554\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01904, lr:6.00e-02, fs:0.68670 (r=0.920,p=0.548),  time:16.902, tt:101.415\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01876, lr:6.00e-02, fs:0.68293 (r=0.805,p=0.593),  time:19.797, tt:138.576\n",
      "Ep:7, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.67337 (r=0.770,p=0.598),  time:22.210, tt:177.677\n",
      "Ep:8, loss:0.00003, loss_test:0.01829, lr:6.00e-02, fs:0.67662 (r=0.782,p=0.596),  time:24.013, tt:216.116\n",
      "Ep:9, loss:0.00003, loss_test:0.01820, lr:6.00e-02, fs:0.67619 (r=0.816,p=0.577),  time:25.523, tt:255.231\n",
      "Ep:10, loss:0.00003, loss_test:0.01820, lr:6.00e-02, fs:0.67317 (r=0.793,p=0.585),  time:26.737, tt:294.104\n",
      "Ep:11, loss:0.00003, loss_test:0.01833, lr:6.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:27.752, tt:333.019\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.71038 (r=0.747,p=0.677),  time:28.695, tt:373.041\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01844, lr:6.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:29.398, tt:411.578\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01806, lr:6.00e-02, fs:0.72527 (r=0.759,p=0.695),  time:30.135, tt:452.023\n",
      "Ep:15, loss:0.00003, loss_test:0.01786, lr:6.00e-02, fs:0.73626 (r=0.770,p=0.705),  time:30.698, tt:491.166\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00002, loss_test:0.01802, lr:6.00e-02, fs:0.74444 (r=0.770,p=0.720),  time:31.242, tt:531.116\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01834, lr:6.00e-02, fs:0.75706 (r=0.770,p=0.744),  time:31.692, tt:570.452\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01861, lr:6.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:32.097, tt:609.851\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01848, lr:6.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:32.505, tt:650.093\n",
      "Ep:20, loss:0.00002, loss_test:0.01830, lr:6.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:32.788, tt:688.551\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01816, lr:6.00e-02, fs:0.77457 (r=0.770,p=0.779),  time:33.122, tt:728.686\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01821, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:33.420, tt:768.669\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01843, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:33.681, tt:808.350\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01835, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:33.889, tt:847.233\n",
      "Ep:25, loss:0.00002, loss_test:0.01827, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:34.026, tt:884.663\n",
      "Ep:26, loss:0.00002, loss_test:0.01833, lr:6.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:34.219, tt:923.916\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01844, lr:6.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:34.396, tt:963.094\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01845, lr:6.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:34.545, tt:1001.804\n",
      "Ep:29, loss:0.00002, loss_test:0.01838, lr:6.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:34.618, tt:1038.555\n",
      "Ep:30, loss:0.00002, loss_test:0.01847, lr:6.00e-02, fs:0.80000 (r=0.759,p=0.846),  time:34.737, tt:1076.850\n",
      "Ep:31, loss:0.00001, loss_test:0.01861, lr:6.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:34.863, tt:1115.617\n",
      "Ep:32, loss:0.00001, loss_test:0.01849, lr:6.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:34.958, tt:1153.600\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00001, loss_test:0.01850, lr:6.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:35.034, tt:1191.171\n",
      "Ep:34, loss:0.00001, loss_test:0.01860, lr:6.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:35.132, tt:1229.606\n",
      "Ep:35, loss:0.00001, loss_test:0.01878, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:35.288, tt:1270.372\n",
      "Ep:36, loss:0.00001, loss_test:0.01881, lr:6.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:35.404, tt:1309.943\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00001, loss_test:0.01876, lr:6.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:35.514, tt:1349.534\n",
      "Ep:38, loss:0.00001, loss_test:0.01899, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.577, tt:1387.501\n",
      "Ep:39, loss:0.00001, loss_test:0.01932, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.609, tt:1424.370\n",
      "Ep:40, loss:0.00001, loss_test:0.01924, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.707, tt:1463.986\n",
      "Ep:41, loss:0.00001, loss_test:0.01927, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.801, tt:1503.623\n",
      "Ep:42, loss:0.00001, loss_test:0.01950, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.880, tt:1542.834\n",
      "Ep:43, loss:0.00001, loss_test:0.01947, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.966, tt:1582.517\n",
      "Ep:44, loss:0.00001, loss_test:0.01948, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:36.026, tt:1621.151\n",
      "Ep:45, loss:0.00001, loss_test:0.01968, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:36.063, tt:1658.915\n",
      "Ep:46, loss:0.00001, loss_test:0.01988, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:36.106, tt:1697.005\n",
      "Ep:47, loss:0.00001, loss_test:0.01993, lr:6.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:36.179, tt:1736.578\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01990, lr:6.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:36.251, tt:1776.308\n",
      "Ep:49, loss:0.00001, loss_test:0.02029, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.336, tt:1816.802\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.02032, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.380, tt:1855.358\n",
      "Ep:51, loss:0.00001, loss_test:0.02053, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.396, tt:1892.593\n",
      "Ep:52, loss:0.00001, loss_test:0.02070, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.446, tt:1931.618\n",
      "Ep:53, loss:0.00001, loss_test:0.02089, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.545, tt:1973.436\n",
      "Ep:54, loss:0.00001, loss_test:0.02111, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.615, tt:2013.811\n",
      "Ep:55, loss:0.00001, loss_test:0.02125, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.661, tt:2053.018\n",
      "Ep:56, loss:0.00001, loss_test:0.02137, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.708, tt:2092.377\n",
      "Ep:57, loss:0.00001, loss_test:0.02152, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.793, tt:2133.999\n",
      "Ep:58, loss:0.00001, loss_test:0.02157, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.843, tt:2173.718\n",
      "Ep:59, loss:0.00001, loss_test:0.02187, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.875, tt:2212.513\n",
      "Ep:60, loss:0.00001, loss_test:0.02190, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.903, tt:2251.060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.02198, lr:5.94e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.954, tt:2291.120\n",
      "Ep:62, loss:0.00001, loss_test:0.02215, lr:5.88e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.993, tt:2330.583\n",
      "Ep:63, loss:0.00001, loss_test:0.02236, lr:5.82e-02, fs:0.83436 (r=0.782,p=0.895),  time:36.994, tt:2367.617\n",
      "Ep:64, loss:0.00001, loss_test:0.02257, lr:5.76e-02, fs:0.83436 (r=0.782,p=0.895),  time:37.018, tt:2406.178\n",
      "Ep:65, loss:0.00001, loss_test:0.02269, lr:5.71e-02, fs:0.83436 (r=0.782,p=0.895),  time:37.057, tt:2445.761\n",
      "Ep:66, loss:0.00001, loss_test:0.02277, lr:5.65e-02, fs:0.83436 (r=0.782,p=0.895),  time:37.097, tt:2485.529\n",
      "Ep:67, loss:0.00001, loss_test:0.02290, lr:5.59e-02, fs:0.83951 (r=0.782,p=0.907),  time:37.139, tt:2525.469\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00000, loss_test:0.02308, lr:5.59e-02, fs:0.84472 (r=0.782,p=0.919),  time:37.175, tt:2565.088\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00000, loss_test:0.02320, lr:5.59e-02, fs:0.84472 (r=0.782,p=0.919),  time:37.186, tt:2603.038\n",
      "Ep:70, loss:0.00000, loss_test:0.02327, lr:5.59e-02, fs:0.83544 (r=0.759,p=0.930),  time:37.194, tt:2640.750\n",
      "Ep:71, loss:0.00000, loss_test:0.02335, lr:5.59e-02, fs:0.83544 (r=0.759,p=0.930),  time:37.194, tt:2677.957\n",
      "Ep:72, loss:0.00000, loss_test:0.02350, lr:5.59e-02, fs:0.80263 (r=0.701,p=0.938),  time:37.200, tt:2715.604\n",
      "Ep:73, loss:0.00000, loss_test:0.02374, lr:5.59e-02, fs:0.80795 (r=0.701,p=0.953),  time:37.225, tt:2754.658\n",
      "Ep:74, loss:0.00000, loss_test:0.02377, lr:5.59e-02, fs:0.80263 (r=0.701,p=0.938),  time:37.352, tt:2801.429\n",
      "Ep:75, loss:0.00000, loss_test:0.02394, lr:5.59e-02, fs:0.80537 (r=0.690,p=0.968),  time:37.374, tt:2840.420\n",
      "Ep:76, loss:0.00000, loss_test:0.02421, lr:5.59e-02, fs:0.80537 (r=0.690,p=0.968),  time:37.378, tt:2878.139\n",
      "Ep:77, loss:0.00000, loss_test:0.02418, lr:5.59e-02, fs:0.80537 (r=0.690,p=0.968),  time:37.407, tt:2917.766\n",
      "Ep:78, loss:0.00000, loss_test:0.02457, lr:5.59e-02, fs:0.80537 (r=0.690,p=0.968),  time:37.449, tt:2958.498\n",
      "Ep:79, loss:0.00000, loss_test:0.02455, lr:5.59e-02, fs:0.80272 (r=0.678,p=0.983),  time:37.474, tt:2997.957\n",
      "Ep:80, loss:0.00000, loss_test:0.02474, lr:5.54e-02, fs:0.79452 (r=0.667,p=0.983),  time:37.489, tt:3036.578\n",
      "Ep:81, loss:0.00000, loss_test:0.02497, lr:5.48e-02, fs:0.79452 (r=0.667,p=0.983),  time:37.492, tt:3074.334\n",
      "Ep:82, loss:0.00000, loss_test:0.02480, lr:5.43e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.528, tt:3114.809\n",
      "Ep:83, loss:0.00000, loss_test:0.02534, lr:5.37e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.578, tt:3156.527\n",
      "Ep:84, loss:0.00000, loss_test:0.02512, lr:5.32e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.598, tt:3195.837\n",
      "Ep:85, loss:0.00000, loss_test:0.02525, lr:5.27e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.609, tt:3234.359\n",
      "Ep:86, loss:0.00000, loss_test:0.02562, lr:5.21e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.632, tt:3274.005\n",
      "Ep:87, loss:0.00000, loss_test:0.02558, lr:5.16e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.656, tt:3313.704\n",
      "Ep:88, loss:0.00000, loss_test:0.02576, lr:5.11e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.679, tt:3353.466\n",
      "Ep:89, loss:0.00000, loss_test:0.02573, lr:5.06e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.654, tt:3388.900\n",
      "Ep:90, loss:0.00000, loss_test:0.02588, lr:5.01e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.644, tt:3425.594\n",
      "Ep:91, loss:0.00000, loss_test:0.02609, lr:4.96e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.659, tt:3464.629\n",
      "Ep:92, loss:0.00000, loss_test:0.02597, lr:4.91e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.688, tt:3505.019\n",
      "Ep:93, loss:0.00000, loss_test:0.02634, lr:4.86e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.696, tt:3543.414\n",
      "Ep:94, loss:0.00000, loss_test:0.02620, lr:4.81e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.701, tt:3581.601\n",
      "Ep:95, loss:0.00000, loss_test:0.02637, lr:4.76e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.714, tt:3620.572\n",
      "Ep:96, loss:0.00000, loss_test:0.02647, lr:4.71e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.778, tt:3664.442\n",
      "Ep:97, loss:0.00000, loss_test:0.02650, lr:4.67e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.790, tt:3703.397\n",
      "Ep:98, loss:0.00000, loss_test:0.02676, lr:4.62e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.813, tt:3743.449\n",
      "Ep:99, loss:0.00000, loss_test:0.02673, lr:4.57e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.822, tt:3782.168\n",
      "Ep:100, loss:0.00000, loss_test:0.02683, lr:4.53e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.841, tt:3821.963\n",
      "Ep:101, loss:0.00000, loss_test:0.02695, lr:4.48e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.848, tt:3860.498\n",
      "Ep:102, loss:0.00000, loss_test:0.02704, lr:4.44e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.857, tt:3899.304\n",
      "Ep:103, loss:0.00000, loss_test:0.02707, lr:4.39e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.852, tt:3936.659\n",
      "Ep:104, loss:0.00000, loss_test:0.02718, lr:4.35e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.852, tt:3974.435\n",
      "Ep:105, loss:0.00000, loss_test:0.02724, lr:4.31e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.870, tt:4014.262\n",
      "Ep:106, loss:0.00000, loss_test:0.02730, lr:4.26e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.870, tt:4052.089\n",
      "Ep:107, loss:0.00000, loss_test:0.02744, lr:4.22e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.885, tt:4091.527\n",
      "Ep:108, loss:0.00000, loss_test:0.02753, lr:4.18e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.890, tt:4130.055\n",
      "Ep:109, loss:0.00000, loss_test:0.02750, lr:4.14e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.875, tt:4166.234\n",
      "Ep:110, loss:0.00000, loss_test:0.02762, lr:4.10e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.883, tt:4205.041\n",
      "Ep:111, loss:0.00000, loss_test:0.02769, lr:4.05e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.880, tt:4242.601\n",
      "Ep:112, loss:0.00000, loss_test:0.02773, lr:4.01e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.880, tt:4280.445\n",
      "Ep:113, loss:0.00000, loss_test:0.02774, lr:3.97e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.861, tt:4316.124\n",
      "Ep:114, loss:0.00000, loss_test:0.02795, lr:3.93e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.868, tt:4354.848\n",
      "Ep:115, loss:0.00000, loss_test:0.02781, lr:3.89e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.883, tt:4394.405\n",
      "Ep:116, loss:0.00000, loss_test:0.02803, lr:3.86e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.901, tt:4434.409\n",
      "Ep:117, loss:0.00000, loss_test:0.02811, lr:3.82e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.935, tt:4476.307\n",
      "Ep:118, loss:0.00000, loss_test:0.02812, lr:3.78e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.923, tt:4512.849\n",
      "Ep:119, loss:0.00000, loss_test:0.02816, lr:3.74e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.910, tt:4549.256\n",
      "Ep:120, loss:0.00000, loss_test:0.02822, lr:3.70e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.920, tt:4588.315\n",
      "Ep:121, loss:0.00000, loss_test:0.02836, lr:3.67e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.930, tt:4627.419\n",
      "Ep:122, loss:0.00000, loss_test:0.02831, lr:3.63e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.940, tt:4666.649\n",
      "Ep:123, loss:0.00000, loss_test:0.02836, lr:3.59e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.951, tt:4705.985\n",
      "Ep:124, loss:0.00000, loss_test:0.02851, lr:3.56e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.976, tt:4747.012\n",
      "Ep:125, loss:0.00000, loss_test:0.02849, lr:3.52e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.998, tt:4787.715\n",
      "Ep:126, loss:0.00000, loss_test:0.02847, lr:3.49e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.992, tt:4824.995\n",
      "Ep:127, loss:0.00000, loss_test:0.02871, lr:3.45e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.990, tt:4862.754\n",
      "Ep:128, loss:0.00000, loss_test:0.02862, lr:3.42e-02, fs:0.78621 (r=0.655,p=0.983),  time:37.991, tt:4900.813\n",
      "Ep:129, loss:0.00000, loss_test:0.02875, lr:3.38e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.004, tt:4940.456\n",
      "Ep:130, loss:0.00000, loss_test:0.02878, lr:3.35e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.014, tt:4979.875\n",
      "Ep:131, loss:0.00000, loss_test:0.02880, lr:3.32e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.033, tt:5020.297\n",
      "Ep:132, loss:0.00000, loss_test:0.02895, lr:3.28e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.037, tt:5058.936\n",
      "Ep:133, loss:0.00000, loss_test:0.02891, lr:3.25e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.043, tt:5097.755\n",
      "Ep:134, loss:0.00000, loss_test:0.02898, lr:3.22e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.045, tt:5136.038\n",
      "Ep:135, loss:0.00000, loss_test:0.02906, lr:3.19e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.049, tt:5174.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02904, lr:3.15e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.063, tt:5214.608\n",
      "Ep:137, loss:0.00000, loss_test:0.02914, lr:3.12e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.062, tt:5252.516\n",
      "Ep:138, loss:0.00000, loss_test:0.02916, lr:3.09e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.064, tt:5290.871\n",
      "Ep:139, loss:0.00000, loss_test:0.02919, lr:3.06e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.079, tt:5331.004\n",
      "Ep:140, loss:0.00000, loss_test:0.02923, lr:3.03e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.074, tt:5368.451\n",
      "Ep:141, loss:0.00000, loss_test:0.02935, lr:3.00e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.094, tt:5409.295\n",
      "Ep:142, loss:0.00000, loss_test:0.02936, lr:2.97e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.104, tt:5448.833\n",
      "Ep:143, loss:0.00000, loss_test:0.02934, lr:2.94e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.111, tt:5487.956\n",
      "Ep:144, loss:0.00000, loss_test:0.02937, lr:2.91e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.110, tt:5525.990\n",
      "Ep:145, loss:0.00000, loss_test:0.02948, lr:2.88e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.115, tt:5564.852\n",
      "Ep:146, loss:0.00000, loss_test:0.02947, lr:2.85e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.107, tt:5601.765\n",
      "Ep:147, loss:0.00000, loss_test:0.02952, lr:2.82e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.118, tt:5641.468\n",
      "Ep:148, loss:0.00000, loss_test:0.02957, lr:2.80e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.118, tt:5679.563\n",
      "Ep:149, loss:0.00000, loss_test:0.02963, lr:2.77e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.127, tt:5719.101\n",
      "Ep:150, loss:0.00000, loss_test:0.02970, lr:2.74e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.126, tt:5757.075\n",
      "Ep:151, loss:0.00000, loss_test:0.02960, lr:2.71e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.136, tt:5796.645\n",
      "Ep:152, loss:0.00000, loss_test:0.02968, lr:2.69e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.141, tt:5835.567\n",
      "Ep:153, loss:0.00000, loss_test:0.02983, lr:2.66e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.156, tt:5876.068\n",
      "Ep:154, loss:0.00000, loss_test:0.02979, lr:2.63e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.189, tt:5919.230\n",
      "Ep:155, loss:0.00000, loss_test:0.02978, lr:2.61e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.203, tt:5959.612\n",
      "Ep:156, loss:0.00000, loss_test:0.02984, lr:2.58e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.226, tt:6001.451\n",
      "Ep:157, loss:0.00000, loss_test:0.02988, lr:2.55e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.253, tt:6043.933\n",
      "Ep:158, loss:0.00000, loss_test:0.02993, lr:2.53e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.271, tt:6085.112\n",
      "Ep:159, loss:0.00000, loss_test:0.02993, lr:2.50e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.297, tt:6127.469\n",
      "Ep:160, loss:0.00000, loss_test:0.02998, lr:2.48e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.322, tt:6169.891\n",
      "Ep:161, loss:0.00000, loss_test:0.03002, lr:2.45e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.346, tt:6212.129\n",
      "Ep:162, loss:0.00000, loss_test:0.03003, lr:2.43e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.367, tt:6253.792\n",
      "Ep:163, loss:0.00000, loss_test:0.03009, lr:2.40e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.377, tt:6293.886\n",
      "Ep:164, loss:0.00000, loss_test:0.03008, lr:2.38e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.372, tt:6331.386\n",
      "Ep:165, loss:0.00000, loss_test:0.03011, lr:2.36e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.389, tt:6372.620\n",
      "Ep:166, loss:0.00000, loss_test:0.03014, lr:2.33e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.407, tt:6413.948\n",
      "Ep:167, loss:0.00000, loss_test:0.03017, lr:2.31e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.404, tt:6451.935\n",
      "Ep:168, loss:0.00000, loss_test:0.03021, lr:2.29e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.403, tt:6490.174\n",
      "Ep:169, loss:0.00000, loss_test:0.03023, lr:2.26e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.391, tt:6526.421\n",
      "Ep:170, loss:0.00000, loss_test:0.03024, lr:2.24e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.384, tt:6563.672\n",
      "Ep:171, loss:0.00000, loss_test:0.03029, lr:2.22e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.393, tt:6603.659\n",
      "Ep:172, loss:0.00000, loss_test:0.03030, lr:2.20e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.424, tt:6647.339\n",
      "Ep:173, loss:0.00000, loss_test:0.03033, lr:2.17e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.423, tt:6685.532\n",
      "Ep:174, loss:0.00000, loss_test:0.03036, lr:2.15e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.416, tt:6722.827\n",
      "Ep:175, loss:0.00000, loss_test:0.03039, lr:2.13e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.411, tt:6760.377\n",
      "Ep:176, loss:0.00000, loss_test:0.03040, lr:2.11e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.407, tt:6798.107\n",
      "Ep:177, loss:0.00000, loss_test:0.03046, lr:2.09e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.405, tt:6836.158\n",
      "Ep:178, loss:0.00000, loss_test:0.03043, lr:2.07e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.404, tt:6874.337\n",
      "Ep:179, loss:0.00000, loss_test:0.03040, lr:2.05e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.403, tt:6912.576\n",
      "Ep:180, loss:0.00000, loss_test:0.03049, lr:2.03e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.400, tt:6950.471\n",
      "Ep:181, loss:0.00000, loss_test:0.03055, lr:2.01e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.399, tt:6988.554\n",
      "Ep:182, loss:0.00000, loss_test:0.03053, lr:1.99e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.392, tt:7025.824\n",
      "Ep:183, loss:0.00000, loss_test:0.03049, lr:1.97e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.407, tt:7066.903\n",
      "Ep:184, loss:0.00000, loss_test:0.03058, lr:1.95e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.399, tt:7103.901\n",
      "Ep:185, loss:0.00000, loss_test:0.03063, lr:1.93e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.400, tt:7142.411\n",
      "Ep:186, loss:0.00000, loss_test:0.03057, lr:1.91e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.412, tt:7182.973\n",
      "Ep:187, loss:0.00000, loss_test:0.03060, lr:1.89e-02, fs:0.78621 (r=0.655,p=0.983),  time:38.420, tt:7223.005\n",
      "Ep:188, loss:0.00000, loss_test:0.03069, lr:1.87e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.416, tt:7260.552\n",
      "Ep:189, loss:0.00000, loss_test:0.03069, lr:1.85e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.431, tt:7301.898\n",
      "Ep:190, loss:0.00000, loss_test:0.03067, lr:1.83e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.437, tt:7341.513\n",
      "Ep:191, loss:0.00000, loss_test:0.03070, lr:1.81e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.454, tt:7383.120\n",
      "Ep:192, loss:0.00000, loss_test:0.03078, lr:1.80e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.453, tt:7421.410\n",
      "Ep:193, loss:0.00000, loss_test:0.03079, lr:1.78e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.469, tt:7463.069\n",
      "Ep:194, loss:0.00000, loss_test:0.03080, lr:1.76e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.481, tt:7503.725\n",
      "Ep:195, loss:0.00000, loss_test:0.03077, lr:1.74e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.491, tt:7544.311\n",
      "Ep:196, loss:0.00000, loss_test:0.03082, lr:1.73e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.496, tt:7583.714\n",
      "Ep:197, loss:0.00000, loss_test:0.03081, lr:1.71e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.500, tt:7623.053\n",
      "Ep:198, loss:0.00000, loss_test:0.03083, lr:1.69e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.508, tt:7663.139\n",
      "Ep:199, loss:0.00000, loss_test:0.03087, lr:1.67e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.504, tt:7700.745\n",
      "Ep:200, loss:0.00000, loss_test:0.03091, lr:1.66e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.505, tt:7739.568\n",
      "Ep:201, loss:0.00000, loss_test:0.03086, lr:1.64e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.511, tt:7779.208\n",
      "Ep:202, loss:0.00000, loss_test:0.03090, lr:1.62e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.520, tt:7819.539\n",
      "Ep:203, loss:0.00000, loss_test:0.03095, lr:1.61e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.531, tt:7860.262\n",
      "Ep:204, loss:0.00000, loss_test:0.03095, lr:1.59e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.546, tt:7901.881\n",
      "Ep:205, loss:0.00000, loss_test:0.03094, lr:1.58e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.551, tt:7941.545\n",
      "Ep:206, loss:0.00000, loss_test:0.03097, lr:1.56e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.557, tt:7981.322\n",
      "Ep:207, loss:0.00000, loss_test:0.03097, lr:1.54e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.561, tt:8020.617\n",
      "Ep:208, loss:0.00000, loss_test:0.03099, lr:1.53e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.554, tt:8057.816\n",
      "Ep:209, loss:0.00000, loss_test:0.03100, lr:1.51e-02, fs:0.78082 (r=0.655,p=0.966),  time:38.555, tt:8096.639\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14388, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.910, tt:41.910\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14269, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.079, tt:82.158\n",
      "Ep:2, loss:0.00028, loss_test:0.14053, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.527, tt:121.581\n",
      "Ep:3, loss:0.00027, loss_test:0.13666, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:39.094, tt:156.375\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12958, lr:1.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:37.215, tt:186.075\n",
      "Ep:5, loss:0.00025, loss_test:0.11849, lr:1.00e-02, fs:0.68807 (r=0.862,p=0.573),  time:36.098, tt:216.586\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11218, lr:1.00e-02, fs:0.67742 (r=0.724,p=0.636),  time:36.143, tt:253.003\n",
      "Ep:7, loss:0.00022, loss_test:0.10855, lr:1.00e-02, fs:0.67442 (r=0.667,p=0.682),  time:36.810, tt:294.483\n",
      "Ep:8, loss:0.00021, loss_test:0.10467, lr:1.00e-02, fs:0.70588 (r=0.759,p=0.660),  time:37.477, tt:337.290\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10420, lr:1.00e-02, fs:0.68182 (r=0.690,p=0.674),  time:37.992, tt:379.920\n",
      "Ep:10, loss:0.00019, loss_test:0.10379, lr:1.00e-02, fs:0.69091 (r=0.655,p=0.731),  time:38.415, tt:422.564\n",
      "Ep:11, loss:0.00018, loss_test:0.09992, lr:1.00e-02, fs:0.72832 (r=0.724,p=0.733),  time:38.624, tt:463.488\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09803, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:39.014, tt:507.182\n",
      "Ep:13, loss:0.00017, loss_test:0.09957, lr:1.00e-02, fs:0.73494 (r=0.701,p=0.772),  time:39.307, tt:550.292\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.09699, lr:1.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:39.531, tt:592.961\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.09557, lr:1.00e-02, fs:0.75294 (r=0.736,p=0.771),  time:39.722, tt:635.546\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09423, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:39.789, tt:676.413\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09253, lr:1.00e-02, fs:0.77381 (r=0.747,p=0.802),  time:40.028, tt:720.500\n",
      "Ep:18, loss:0.00013, loss_test:0.09022, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:40.183, tt:763.483\n",
      "Ep:19, loss:0.00013, loss_test:0.09442, lr:1.00e-02, fs:0.78313 (r=0.747,p=0.823),  time:40.300, tt:806.003\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.09147, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:40.462, tt:849.707\n",
      "Ep:21, loss:0.00011, loss_test:0.09040, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:40.661, tt:894.539\n",
      "Ep:22, loss:0.00011, loss_test:0.09336, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:40.802, tt:938.443\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.08990, lr:1.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:40.873, tt:980.959\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.09212, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.977, tt:1024.430\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.08838, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:41.082, tt:1068.129\n",
      "Ep:26, loss:0.00009, loss_test:0.09034, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:41.114, tt:1110.085\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00008, loss_test:0.08757, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:41.213, tt:1153.963\n",
      "Ep:28, loss:0.00008, loss_test:0.09111, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:41.229, tt:1195.638\n",
      "Ep:29, loss:0.00007, loss_test:0.08291, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:41.252, tt:1237.549\n",
      "Ep:30, loss:0.00007, loss_test:0.09496, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.273, tt:1279.459\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.08526, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:41.375, tt:1324.004\n",
      "Ep:32, loss:0.00006, loss_test:0.09507, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.378, tt:1365.458\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.08929, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.407, tt:1407.834\n",
      "Ep:34, loss:0.00005, loss_test:0.09604, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.456, tt:1450.965\n",
      "Ep:35, loss:0.00005, loss_test:0.08437, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.425, tt:1491.289\n",
      "Ep:36, loss:0.00005, loss_test:0.08549, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.389, tt:1531.411\n",
      "Ep:37, loss:0.00004, loss_test:0.09792, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.370, tt:1572.042\n",
      "Ep:38, loss:0.00005, loss_test:0.08910, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.404, tt:1614.770\n",
      "Ep:39, loss:0.00004, loss_test:0.09656, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.434, tt:1657.369\n",
      "Ep:40, loss:0.00004, loss_test:0.08586, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.454, tt:1699.601\n",
      "Ep:41, loss:0.00004, loss_test:0.09034, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:41.402, tt:1738.875\n",
      "Ep:42, loss:0.00003, loss_test:0.08836, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.432, tt:1781.572\n",
      "Ep:43, loss:0.00003, loss_test:0.09290, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.488, tt:1825.479\n",
      "Ep:44, loss:0.00003, loss_test:0.09221, lr:9.90e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.551, tt:1869.790\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.08871, lr:9.90e-03, fs:0.85000 (r=0.782,p=0.932),  time:41.583, tt:1912.814\n",
      "Ep:46, loss:0.00003, loss_test:0.09382, lr:9.90e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.583, tt:1954.388\n",
      "Ep:47, loss:0.00002, loss_test:0.09770, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:41.557, tt:1994.752\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.08583, lr:9.90e-03, fs:0.85535 (r=0.782,p=0.944),  time:41.582, tt:2037.517\n",
      "Ep:49, loss:0.00002, loss_test:0.09433, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:41.582, tt:2079.101\n",
      "Ep:50, loss:0.00002, loss_test:0.09254, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:41.624, tt:2122.840\n",
      "Ep:51, loss:0.00002, loss_test:0.09184, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:41.617, tt:2164.096\n",
      "Ep:52, loss:0.00002, loss_test:0.09158, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:41.663, tt:2208.120\n",
      "Ep:53, loss:0.00001, loss_test:0.09375, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.672, tt:2250.290\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.09602, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:41.647, tt:2290.603\n",
      "Ep:55, loss:0.00001, loss_test:0.09475, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.666, tt:2333.292\n",
      "Ep:56, loss:0.00001, loss_test:0.09534, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.677, tt:2375.591\n",
      "Ep:57, loss:0.00001, loss_test:0.09678, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.658, tt:2416.143\n",
      "Ep:58, loss:0.00001, loss_test:0.09846, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.658, tt:2457.806\n",
      "Ep:59, loss:0.00001, loss_test:0.10073, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.664, tt:2499.821\n",
      "Ep:60, loss:0.00001, loss_test:0.09718, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.649, tt:2540.575\n",
      "Ep:61, loss:0.00001, loss_test:0.10159, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.660, tt:2582.942\n",
      "Ep:62, loss:0.00001, loss_test:0.09659, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.639, tt:2623.240\n",
      "Ep:63, loss:0.00001, loss_test:0.10090, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.637, tt:2664.760\n",
      "Ep:64, loss:0.00001, loss_test:0.09447, lr:9.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.623, tt:2705.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.09974, lr:9.80e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.609, tt:2746.167\n",
      "Ep:66, loss:0.00001, loss_test:0.10195, lr:9.70e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.585, tt:2786.166\n",
      "Ep:67, loss:0.00000, loss_test:0.09868, lr:9.61e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.555, tt:2825.759\n",
      "Ep:68, loss:0.00000, loss_test:0.09990, lr:9.51e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.537, tt:2866.056\n",
      "Ep:69, loss:0.00000, loss_test:0.09976, lr:9.41e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.554, tt:2908.812\n",
      "Ep:70, loss:0.00000, loss_test:0.10182, lr:9.32e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.562, tt:2950.902\n",
      "Ep:71, loss:0.00000, loss_test:0.10027, lr:9.23e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.539, tt:2990.801\n",
      "Ep:72, loss:0.00000, loss_test:0.10103, lr:9.14e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.516, tt:3030.685\n",
      "Ep:73, loss:0.00000, loss_test:0.10025, lr:9.04e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.505, tt:3071.341\n",
      "Ep:74, loss:0.00000, loss_test:0.09887, lr:8.95e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.501, tt:3112.569\n",
      "Ep:75, loss:0.00000, loss_test:0.09889, lr:8.86e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.500, tt:3154.011\n",
      "Ep:76, loss:0.00000, loss_test:0.10079, lr:8.78e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.509, tt:3196.196\n",
      "Ep:77, loss:0.00000, loss_test:0.09959, lr:8.69e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.521, tt:3238.628\n",
      "Ep:78, loss:0.00000, loss_test:0.09973, lr:8.60e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.510, tt:3279.292\n",
      "Ep:79, loss:0.00000, loss_test:0.10009, lr:8.51e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.529, tt:3322.319\n",
      "Ep:80, loss:0.00000, loss_test:0.09824, lr:8.43e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.512, tt:3362.482\n",
      "Ep:81, loss:0.00000, loss_test:0.09957, lr:8.35e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.508, tt:3403.678\n",
      "Ep:82, loss:0.00000, loss_test:0.10145, lr:8.26e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.525, tt:3446.593\n",
      "Ep:83, loss:0.00000, loss_test:0.09892, lr:8.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.524, tt:3488.049\n",
      "Ep:84, loss:0.00000, loss_test:0.09998, lr:8.10e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.527, tt:3529.768\n",
      "Ep:85, loss:0.00000, loss_test:0.09977, lr:8.02e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.522, tt:3570.883\n",
      "Ep:86, loss:0.00000, loss_test:0.09842, lr:7.94e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.536, tt:3613.611\n",
      "Ep:87, loss:0.00000, loss_test:0.09909, lr:7.86e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.544, tt:3655.873\n",
      "Ep:88, loss:0.00000, loss_test:0.10075, lr:7.78e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.505, tt:3693.920\n",
      "Ep:89, loss:0.00000, loss_test:0.09903, lr:7.70e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.491, tt:3734.203\n",
      "Ep:90, loss:0.00000, loss_test:0.09906, lr:7.62e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.499, tt:3776.402\n",
      "Ep:91, loss:0.00000, loss_test:0.09908, lr:7.55e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.494, tt:3817.450\n",
      "Ep:92, loss:0.00000, loss_test:0.09910, lr:7.47e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.506, tt:3860.093\n",
      "Ep:93, loss:0.00000, loss_test:0.09891, lr:7.40e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.500, tt:3900.959\n",
      "Ep:94, loss:0.00000, loss_test:0.09915, lr:7.32e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.509, tt:3943.326\n",
      "Ep:95, loss:0.00000, loss_test:0.09893, lr:7.25e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.513, tt:3985.237\n",
      "Ep:96, loss:0.00000, loss_test:0.09896, lr:7.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.514, tt:4026.864\n",
      "Ep:97, loss:0.00000, loss_test:0.09889, lr:7.11e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.523, tt:4069.215\n",
      "Ep:98, loss:0.00000, loss_test:0.09909, lr:7.03e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.534, tt:4111.882\n",
      "Ep:99, loss:0.00000, loss_test:0.09909, lr:6.96e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.557, tt:4155.675\n",
      "Ep:100, loss:0.00000, loss_test:0.09842, lr:6.89e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.543, tt:4195.840\n",
      "Ep:101, loss:0.00000, loss_test:0.09892, lr:6.83e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.524, tt:4235.406\n",
      "Ep:102, loss:0.00000, loss_test:0.09828, lr:6.76e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.525, tt:4277.081\n",
      "Ep:103, loss:0.00000, loss_test:0.09882, lr:6.69e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.534, tt:4319.524\n",
      "Ep:104, loss:0.00000, loss_test:0.09859, lr:6.62e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.532, tt:4360.868\n",
      "Ep:105, loss:0.00000, loss_test:0.09846, lr:6.56e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.530, tt:4402.168\n",
      "Ep:106, loss:0.00000, loss_test:0.09853, lr:6.49e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.532, tt:4443.903\n",
      "Ep:107, loss:0.00000, loss_test:0.09822, lr:6.43e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.546, tt:4486.966\n",
      "Ep:108, loss:0.00000, loss_test:0.09865, lr:6.36e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.563, tt:4530.419\n",
      "Ep:109, loss:0.00000, loss_test:0.09826, lr:6.30e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.571, tt:4572.847\n",
      "Ep:110, loss:0.00000, loss_test:0.09861, lr:6.24e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.566, tt:4613.857\n",
      "Ep:111, loss:0.00000, loss_test:0.09881, lr:6.17e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.551, tt:4653.669\n",
      "Ep:112, loss:0.00000, loss_test:0.09833, lr:6.11e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.552, tt:4695.407\n",
      "Ep:113, loss:0.00000, loss_test:0.09879, lr:6.05e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.552, tt:4736.887\n",
      "Ep:114, loss:0.00000, loss_test:0.09870, lr:5.99e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.547, tt:4777.903\n",
      "Ep:115, loss:0.00000, loss_test:0.09859, lr:5.93e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.543, tt:4818.981\n",
      "Ep:116, loss:0.00000, loss_test:0.09865, lr:5.87e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.505, tt:4856.085\n",
      "Ep:117, loss:0.00000, loss_test:0.09829, lr:5.81e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.552, tt:4903.191\n",
      "Ep:118, loss:0.00000, loss_test:0.09831, lr:5.75e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.549, tt:4944.301\n",
      "Ep:119, loss:0.00000, loss_test:0.09844, lr:5.70e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.552, tt:4986.280\n",
      "Ep:120, loss:0.00000, loss_test:0.09861, lr:5.64e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.552, tt:5027.847\n",
      "Ep:121, loss:0.00000, loss_test:0.09833, lr:5.58e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.544, tt:5068.313\n",
      "Ep:122, loss:0.00000, loss_test:0.09841, lr:5.53e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.526, tt:5107.658\n",
      "Ep:123, loss:0.00000, loss_test:0.09859, lr:5.47e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.520, tt:5148.481\n",
      "Ep:124, loss:0.00000, loss_test:0.09821, lr:5.42e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.495, tt:5186.836\n",
      "Ep:125, loss:0.00000, loss_test:0.09808, lr:5.36e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.484, tt:5226.995\n",
      "Ep:126, loss:0.00000, loss_test:0.09844, lr:5.31e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.471, tt:5266.830\n",
      "Ep:127, loss:0.00000, loss_test:0.09876, lr:5.26e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.475, tt:5308.758\n",
      "Ep:128, loss:0.00000, loss_test:0.09850, lr:5.20e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.480, tt:5350.923\n",
      "Ep:129, loss:0.00000, loss_test:0.09834, lr:5.15e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.473, tt:5391.515\n",
      "Ep:130, loss:0.00000, loss_test:0.09842, lr:5.10e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.474, tt:5433.065\n",
      "Ep:131, loss:0.00000, loss_test:0.09825, lr:5.05e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.465, tt:5473.314\n",
      "Ep:132, loss:0.00000, loss_test:0.09818, lr:5.00e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.458, tt:5513.852\n",
      "Ep:133, loss:0.00000, loss_test:0.09800, lr:4.95e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.442, tt:5553.220\n",
      "Ep:134, loss:0.00000, loss_test:0.09805, lr:4.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.434, tt:5593.546\n",
      "Ep:135, loss:0.00000, loss_test:0.09883, lr:4.85e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.417, tt:5632.752\n",
      "Ep:136, loss:0.00000, loss_test:0.09847, lr:4.80e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.400, tt:5671.863\n",
      "Ep:137, loss:0.00000, loss_test:0.09890, lr:4.75e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.376, tt:5709.859\n",
      "Ep:138, loss:0.00000, loss_test:0.09872, lr:4.71e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.376, tt:5751.261\n",
      "Ep:139, loss:0.00000, loss_test:0.09842, lr:4.66e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.377, tt:5792.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.09845, lr:4.61e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.369, tt:5833.038\n",
      "Ep:141, loss:0.00000, loss_test:0.09839, lr:4.57e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.363, tt:5873.580\n",
      "Ep:142, loss:0.00000, loss_test:0.09795, lr:4.52e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.354, tt:5913.673\n",
      "Ep:143, loss:0.00000, loss_test:0.09846, lr:4.48e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.359, tt:5955.626\n",
      "Ep:144, loss:0.00000, loss_test:0.09843, lr:4.43e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.356, tt:5996.657\n",
      "Ep:145, loss:0.00000, loss_test:0.09813, lr:4.39e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.353, tt:6037.470\n",
      "Ep:146, loss:0.00000, loss_test:0.09853, lr:4.34e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.352, tt:6078.778\n",
      "Ep:147, loss:0.00000, loss_test:0.09902, lr:4.30e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.341, tt:6118.537\n",
      "Ep:148, loss:0.00000, loss_test:0.09897, lr:4.26e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.348, tt:6160.890\n",
      "Ep:149, loss:0.00000, loss_test:0.09889, lr:4.21e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.343, tt:6201.383\n",
      "Ep:150, loss:0.00000, loss_test:0.09839, lr:4.17e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.345, tt:6243.169\n",
      "Ep:151, loss:0.00000, loss_test:0.09792, lr:4.13e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.356, tt:6286.072\n",
      "Ep:152, loss:0.00000, loss_test:0.09828, lr:4.09e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.345, tt:6325.726\n",
      "Ep:153, loss:0.00000, loss_test:0.09845, lr:4.05e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.348, tt:6367.553\n",
      "Ep:154, loss:0.00000, loss_test:0.09810, lr:4.01e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.350, tt:6409.216\n",
      "Ep:155, loss:0.00000, loss_test:0.09782, lr:3.97e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.362, tt:6452.404\n",
      "Ep:156, loss:0.00000, loss_test:0.09809, lr:3.93e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.376, tt:6496.034\n",
      "Ep:157, loss:0.00000, loss_test:0.09827, lr:3.89e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.369, tt:6536.252\n",
      "Ep:158, loss:0.00000, loss_test:0.09807, lr:3.85e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.402, tt:6582.983\n",
      "Ep:159, loss:0.00000, loss_test:0.09788, lr:3.81e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.414, tt:6626.226\n",
      "Ep:160, loss:0.00000, loss_test:0.09800, lr:3.77e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.414, tt:6667.718\n",
      "Ep:161, loss:0.00000, loss_test:0.09804, lr:3.73e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.411, tt:6708.598\n",
      "Ep:162, loss:0.00000, loss_test:0.09816, lr:3.70e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.399, tt:6747.969\n",
      "Ep:163, loss:0.00000, loss_test:0.09794, lr:3.66e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.408, tt:6790.912\n",
      "Ep:164, loss:0.00000, loss_test:0.09801, lr:3.62e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.413, tt:6833.101\n",
      "Ep:165, loss:0.00000, loss_test:0.09807, lr:3.59e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.420, tt:6875.662\n",
      "Ep:166, loss:0.00000, loss_test:0.09793, lr:3.55e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.423, tt:6917.600\n",
      "Ep:167, loss:0.00000, loss_test:0.09768, lr:3.52e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.435, tt:6961.038\n",
      "Ep:168, loss:0.00000, loss_test:0.09842, lr:3.48e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.441, tt:7003.490\n",
      "Ep:169, loss:0.00000, loss_test:0.09863, lr:3.45e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.457, tt:7047.646\n",
      "Ep:170, loss:0.00000, loss_test:0.09826, lr:3.41e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.463, tt:7090.169\n",
      "Ep:171, loss:0.00000, loss_test:0.09786, lr:3.38e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.472, tt:7133.233\n",
      "Ep:172, loss:0.00000, loss_test:0.09801, lr:3.34e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.460, tt:7172.601\n",
      "Ep:173, loss:0.00000, loss_test:0.09812, lr:3.31e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.468, tt:7215.462\n",
      "Ep:174, loss:0.00000, loss_test:0.09814, lr:3.28e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.474, tt:7257.998\n",
      "Ep:175, loss:0.00000, loss_test:0.09822, lr:3.24e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.482, tt:7300.857\n",
      "Ep:176, loss:0.00000, loss_test:0.09808, lr:3.21e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.488, tt:7343.356\n",
      "Ep:177, loss:0.00000, loss_test:0.09778, lr:3.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.492, tt:7385.547\n",
      "Ep:178, loss:0.00000, loss_test:0.09795, lr:3.15e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.497, tt:7428.003\n",
      "Ep:179, loss:0.00000, loss_test:0.09796, lr:3.12e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.522, tt:7474.048\n",
      "Ep:180, loss:0.00000, loss_test:0.09793, lr:3.09e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.520, tt:7515.183\n",
      "Ep:181, loss:0.00000, loss_test:0.09801, lr:3.05e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.524, tt:7557.300\n",
      "Ep:182, loss:0.00000, loss_test:0.09799, lr:3.02e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.523, tt:7598.703\n",
      "Ep:183, loss:0.00000, loss_test:0.09783, lr:2.99e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.527, tt:7640.958\n",
      "Ep:184, loss:0.00000, loss_test:0.09782, lr:2.96e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.537, tt:7684.413\n",
      "Ep:185, loss:0.00000, loss_test:0.09791, lr:2.93e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.546, tt:7727.584\n",
      "Ep:186, loss:0.00000, loss_test:0.09784, lr:2.90e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.544, tt:7768.780\n",
      "Ep:187, loss:0.00000, loss_test:0.09769, lr:2.88e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.549, tt:7811.258\n",
      "Ep:188, loss:0.00000, loss_test:0.09777, lr:2.85e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.551, tt:7853.209\n",
      "Ep:189, loss:0.00000, loss_test:0.09802, lr:2.82e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.556, tt:7895.659\n",
      "Ep:190, loss:0.00000, loss_test:0.09800, lr:2.79e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.558, tt:7937.587\n",
      "Ep:191, loss:0.00000, loss_test:0.09784, lr:2.76e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.561, tt:7979.658\n",
      "Ep:192, loss:0.00000, loss_test:0.09771, lr:2.73e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.564, tt:8021.793\n",
      "Ep:193, loss:0.00000, loss_test:0.09769, lr:2.71e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.564, tt:8063.352\n",
      "Ep:194, loss:0.00000, loss_test:0.09799, lr:2.68e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.563, tt:8104.719\n",
      "Ep:195, loss:0.00000, loss_test:0.09817, lr:2.65e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.557, tt:8145.085\n",
      "Ep:196, loss:0.00000, loss_test:0.09802, lr:2.63e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.566, tt:8188.596\n",
      "Ep:197, loss:0.00000, loss_test:0.09777, lr:2.60e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.575, tt:8231.754\n",
      "Ep:198, loss:0.00000, loss_test:0.09778, lr:2.57e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.573, tt:8273.026\n",
      "Ep:199, loss:0.00000, loss_test:0.09779, lr:2.55e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.591, tt:8318.129\n",
      "Ep:200, loss:0.00000, loss_test:0.09782, lr:2.52e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.592, tt:8360.071\n",
      "Ep:201, loss:0.00000, loss_test:0.09787, lr:2.50e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.590, tt:8401.230\n",
      "Ep:202, loss:0.00000, loss_test:0.09782, lr:2.47e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.587, tt:8442.126\n",
      "Ep:203, loss:0.00000, loss_test:0.09786, lr:2.45e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.593, tt:8485.057\n",
      "Ep:204, loss:0.00000, loss_test:0.09785, lr:2.42e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.606, tt:8529.325\n",
      "Ep:205, loss:0.00000, loss_test:0.09773, lr:2.40e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.617, tt:8573.187\n",
      "Ep:206, loss:0.00000, loss_test:0.09753, lr:2.38e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.616, tt:8614.483\n",
      "Ep:207, loss:0.00000, loss_test:0.09757, lr:2.35e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.616, tt:8656.072\n",
      "Ep:208, loss:0.00000, loss_test:0.09797, lr:2.33e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.625, tt:8699.660\n",
      "Ep:209, loss:0.00000, loss_test:0.09815, lr:2.31e-03, fs:0.87742 (r=0.782,p=1.000),  time:41.621, tt:8740.511\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02028, lr:6.00e-02, fs:0.64378 (r=0.862,p=0.514),  time:33.637, tt:33.637\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.793, tt:69.586\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02326, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.658, tt:103.974\n",
      "Ep:3, loss:0.00005, loss_test:0.02236, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.631, tt:138.526\n",
      "Ep:4, loss:0.00004, loss_test:0.02072, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:34.547, tt:172.737\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01911, lr:6.00e-02, fs:0.67213 (r=0.943,p=0.522),  time:34.383, tt:206.296\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01831, lr:6.00e-02, fs:0.69406 (r=0.874,p=0.576),  time:34.346, tt:240.425\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01801, lr:6.00e-02, fs:0.67980 (r=0.793,p=0.595),  time:34.385, tt:275.080\n",
      "Ep:8, loss:0.00004, loss_test:0.01759, lr:6.00e-02, fs:0.68966 (r=0.805,p=0.603),  time:34.385, tt:309.466\n",
      "Ep:9, loss:0.00003, loss_test:0.01731, lr:6.00e-02, fs:0.68571 (r=0.828,p=0.585),  time:34.436, tt:344.365\n",
      "Ep:10, loss:0.00003, loss_test:0.01716, lr:6.00e-02, fs:0.66667 (r=0.805,p=0.569),  time:34.366, tt:378.023\n",
      "Ep:11, loss:0.00003, loss_test:0.01707, lr:6.00e-02, fs:0.68293 (r=0.805,p=0.593),  time:34.280, tt:411.366\n",
      "Ep:12, loss:0.00003, loss_test:0.01715, lr:6.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:34.257, tt:445.337\n",
      "Ep:13, loss:0.00003, loss_test:0.01734, lr:6.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:34.303, tt:480.236\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.73333 (r=0.759,p=0.710),  time:34.224, tt:513.363\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:34.273, tt:548.367\n",
      "Ep:16, loss:0.00003, loss_test:0.01718, lr:6.00e-02, fs:0.75138 (r=0.782,p=0.723),  time:34.273, tt:582.648\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01722, lr:6.00e-02, fs:0.76923 (r=0.805,p=0.737),  time:34.248, tt:616.468\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:34.272, tt:651.176\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01774, lr:6.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:34.362, tt:687.235\n",
      "Ep:20, loss:0.00002, loss_test:0.01796, lr:6.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:34.360, tt:721.551\n",
      "Ep:21, loss:0.00002, loss_test:0.01799, lr:6.00e-02, fs:0.76923 (r=0.747,p=0.793),  time:34.372, tt:756.180\n",
      "Ep:22, loss:0.00002, loss_test:0.01793, lr:6.00e-02, fs:0.78107 (r=0.759,p=0.805),  time:34.490, tt:793.271\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01792, lr:6.00e-02, fs:0.78107 (r=0.759,p=0.805),  time:34.513, tt:828.304\n",
      "Ep:24, loss:0.00002, loss_test:0.01796, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:34.516, tt:862.904\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01806, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:34.885, tt:907.010\n",
      "Ep:26, loss:0.00002, loss_test:0.01817, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:34.894, tt:942.142\n",
      "Ep:27, loss:0.00002, loss_test:0.01812, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:34.902, tt:977.269\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01811, lr:6.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:34.912, tt:1012.435\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01816, lr:6.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:35.100, tt:1053.014\n",
      "Ep:30, loss:0.00002, loss_test:0.01828, lr:6.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:35.103, tt:1088.194\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01826, lr:6.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:35.119, tt:1123.793\n",
      "Ep:32, loss:0.00002, loss_test:0.01818, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.130, tt:1159.280\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01816, lr:6.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:35.120, tt:1194.079\n",
      "Ep:34, loss:0.00001, loss_test:0.01835, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:35.145, tt:1230.071\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00001, loss_test:0.01845, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:35.140, tt:1265.027\n",
      "Ep:36, loss:0.00001, loss_test:0.01834, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:35.116, tt:1299.287\n",
      "Ep:37, loss:0.00001, loss_test:0.01840, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:35.141, tt:1335.346\n",
      "Ep:38, loss:0.00001, loss_test:0.01841, lr:6.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:35.123, tt:1369.782\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01852, lr:6.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:35.069, tt:1402.744\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01862, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:35.031, tt:1436.258\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01871, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:35.022, tt:1470.921\n",
      "Ep:42, loss:0.00001, loss_test:0.01885, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:35.028, tt:1506.216\n",
      "Ep:43, loss:0.00001, loss_test:0.01899, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:35.024, tt:1541.057\n",
      "Ep:44, loss:0.00001, loss_test:0.01902, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:35.013, tt:1575.571\n",
      "Ep:45, loss:0.00001, loss_test:0.01928, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.924, tt:1606.526\n",
      "Ep:46, loss:0.00001, loss_test:0.01943, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.943, tt:1642.338\n",
      "Ep:47, loss:0.00001, loss_test:0.01945, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.968, tt:1678.459\n",
      "Ep:48, loss:0.00001, loss_test:0.01962, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.966, tt:1713.315\n",
      "Ep:49, loss:0.00001, loss_test:0.01978, lr:6.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:34.967, tt:1748.346\n",
      "Ep:50, loss:0.00001, loss_test:0.01985, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:34.963, tt:1783.109\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.02007, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:34.926, tt:1816.127\n",
      "Ep:52, loss:0.00001, loss_test:0.02024, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:34.895, tt:1849.458\n",
      "Ep:53, loss:0.00001, loss_test:0.02034, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:34.899, tt:1884.563\n",
      "Ep:54, loss:0.00001, loss_test:0.02047, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:34.888, tt:1918.861\n",
      "Ep:55, loss:0.00001, loss_test:0.02057, lr:6.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:34.876, tt:1953.052\n",
      "Ep:56, loss:0.00001, loss_test:0.02089, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:34.882, tt:1988.296\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.02105, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:34.890, tt:2023.600\n",
      "Ep:58, loss:0.00001, loss_test:0.02121, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:34.956, tt:2062.395\n",
      "Ep:59, loss:0.00001, loss_test:0.02144, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:34.941, tt:2096.479\n",
      "Ep:60, loss:0.00001, loss_test:0.02162, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:34.972, tt:2133.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.02165, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.006, tt:2170.358\n",
      "Ep:62, loss:0.00001, loss_test:0.02188, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:35.009, tt:2205.581\n",
      "Ep:63, loss:0.00001, loss_test:0.02211, lr:6.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.020, tt:2241.259\n",
      "Ep:64, loss:0.00001, loss_test:0.02229, lr:6.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.046, tt:2278.018\n",
      "Ep:65, loss:0.00001, loss_test:0.02236, lr:6.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:35.076, tt:2315.021\n",
      "Ep:66, loss:0.00001, loss_test:0.02284, lr:6.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:35.089, tt:2350.976\n",
      "Ep:67, loss:0.00001, loss_test:0.02282, lr:6.00e-02, fs:0.84416 (r=0.747,p=0.970),  time:35.111, tt:2387.563\n",
      "Ep:68, loss:0.00000, loss_test:0.02299, lr:5.94e-02, fs:0.84416 (r=0.747,p=0.970),  time:35.117, tt:2423.054\n",
      "Ep:69, loss:0.00000, loss_test:0.02327, lr:5.88e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.129, tt:2459.013\n",
      "Ep:70, loss:0.00000, loss_test:0.02324, lr:5.82e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.133, tt:2494.420\n",
      "Ep:71, loss:0.00000, loss_test:0.02370, lr:5.76e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.113, tt:2528.123\n",
      "Ep:72, loss:0.00000, loss_test:0.02393, lr:5.71e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.109, tt:2562.923\n",
      "Ep:73, loss:0.00000, loss_test:0.02384, lr:5.65e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.098, tt:2597.251\n",
      "Ep:74, loss:0.00000, loss_test:0.02406, lr:5.59e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.123, tt:2634.254\n",
      "Ep:75, loss:0.00000, loss_test:0.02435, lr:5.54e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.115, tt:2668.764\n",
      "Ep:76, loss:0.00000, loss_test:0.02436, lr:5.48e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.117, tt:2704.035\n",
      "Ep:77, loss:0.00000, loss_test:0.02446, lr:5.43e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.164, tt:2742.807\n",
      "Ep:78, loss:0.00000, loss_test:0.02468, lr:5.37e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.154, tt:2777.142\n",
      "Ep:79, loss:0.00000, loss_test:0.02467, lr:5.32e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.154, tt:2812.282\n",
      "Ep:80, loss:0.00000, loss_test:0.02480, lr:5.27e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.161, tt:2848.013\n",
      "Ep:81, loss:0.00000, loss_test:0.02498, lr:5.21e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.149, tt:2882.228\n",
      "Ep:82, loss:0.00000, loss_test:0.02512, lr:5.16e-02, fs:0.83660 (r=0.736,p=0.970),  time:35.172, tt:2919.267\n",
      "Ep:83, loss:0.00000, loss_test:0.02525, lr:5.11e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.184, tt:2955.463\n",
      "Ep:84, loss:0.00000, loss_test:0.02542, lr:5.06e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.171, tt:2989.574\n",
      "Ep:85, loss:0.00000, loss_test:0.02556, lr:5.01e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.162, tt:3023.917\n",
      "Ep:86, loss:0.00000, loss_test:0.02568, lr:4.96e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.169, tt:3059.693\n",
      "Ep:87, loss:0.00000, loss_test:0.02586, lr:4.91e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.177, tt:3095.580\n",
      "Ep:88, loss:0.00000, loss_test:0.02585, lr:4.86e-02, fs:0.82895 (r=0.724,p=0.969),  time:35.165, tt:3129.669\n",
      "Ep:89, loss:0.00000, loss_test:0.02606, lr:4.81e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.166, tt:3164.900\n",
      "Ep:90, loss:0.00000, loss_test:0.02622, lr:4.76e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.146, tt:3198.323\n",
      "Ep:91, loss:0.00000, loss_test:0.02625, lr:4.71e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.137, tt:3232.620\n",
      "Ep:92, loss:0.00000, loss_test:0.02643, lr:4.67e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.130, tt:3267.120\n",
      "Ep:93, loss:0.00000, loss_test:0.02646, lr:4.62e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.145, tt:3303.665\n",
      "Ep:94, loss:0.00000, loss_test:0.02659, lr:4.57e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.123, tt:3336.662\n",
      "Ep:95, loss:0.00000, loss_test:0.02673, lr:4.53e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.109, tt:3370.466\n",
      "Ep:96, loss:0.00000, loss_test:0.02677, lr:4.48e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.113, tt:3406.008\n",
      "Ep:97, loss:0.00000, loss_test:0.02696, lr:4.44e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.088, tt:3438.611\n",
      "Ep:98, loss:0.00000, loss_test:0.02704, lr:4.39e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.026, tt:3467.530\n",
      "Ep:99, loss:0.00000, loss_test:0.02707, lr:4.35e-02, fs:0.83444 (r=0.724,p=0.984),  time:35.026, tt:3502.632\n",
      "Ep:100, loss:0.00000, loss_test:0.02722, lr:4.31e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.982, tt:3533.203\n",
      "Ep:101, loss:0.00000, loss_test:0.02733, lr:4.26e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.962, tt:3566.145\n",
      "Ep:102, loss:0.00000, loss_test:0.02739, lr:4.22e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.948, tt:3599.683\n",
      "Ep:103, loss:0.00000, loss_test:0.02747, lr:4.18e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.916, tt:3631.294\n",
      "Ep:104, loss:0.00000, loss_test:0.02763, lr:4.14e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.889, tt:3663.353\n",
      "Ep:105, loss:0.00000, loss_test:0.02766, lr:4.10e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.866, tt:3695.840\n",
      "Ep:106, loss:0.00000, loss_test:0.02781, lr:4.05e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.853, tt:3729.300\n",
      "Ep:107, loss:0.00000, loss_test:0.02781, lr:4.01e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.827, tt:3761.319\n",
      "Ep:108, loss:0.00000, loss_test:0.02798, lr:3.97e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.832, tt:3796.652\n",
      "Ep:109, loss:0.00000, loss_test:0.02814, lr:3.93e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.818, tt:3830.032\n",
      "Ep:110, loss:0.00000, loss_test:0.02807, lr:3.89e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.809, tt:3863.747\n",
      "Ep:111, loss:0.00000, loss_test:0.02823, lr:3.86e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.788, tt:3896.219\n",
      "Ep:112, loss:0.00000, loss_test:0.02835, lr:3.82e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.799, tt:3932.315\n",
      "Ep:113, loss:0.00000, loss_test:0.02833, lr:3.78e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.801, tt:3967.340\n",
      "Ep:114, loss:0.00000, loss_test:0.02846, lr:3.74e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.796, tt:4001.518\n",
      "Ep:115, loss:0.00000, loss_test:0.02854, lr:3.70e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.804, tt:4037.241\n",
      "Ep:116, loss:0.00000, loss_test:0.02848, lr:3.67e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.794, tt:4070.921\n",
      "Ep:117, loss:0.00000, loss_test:0.02858, lr:3.63e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.795, tt:4105.788\n",
      "Ep:118, loss:0.00000, loss_test:0.02866, lr:3.59e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.786, tt:4139.555\n",
      "Ep:119, loss:0.00000, loss_test:0.02870, lr:3.56e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.770, tt:4172.398\n",
      "Ep:120, loss:0.00000, loss_test:0.02877, lr:3.52e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.748, tt:4204.530\n",
      "Ep:121, loss:0.00000, loss_test:0.02881, lr:3.49e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.736, tt:4237.805\n",
      "Ep:122, loss:0.00000, loss_test:0.02883, lr:3.45e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.728, tt:4271.556\n",
      "Ep:123, loss:0.00000, loss_test:0.02888, lr:3.42e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.707, tt:4303.683\n",
      "Ep:124, loss:0.00000, loss_test:0.02895, lr:3.38e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.702, tt:4337.740\n",
      "Ep:125, loss:0.00000, loss_test:0.02898, lr:3.35e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.689, tt:4370.771\n",
      "Ep:126, loss:0.00000, loss_test:0.02906, lr:3.32e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.679, tt:4404.206\n",
      "Ep:127, loss:0.00000, loss_test:0.02915, lr:3.28e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.690, tt:4440.320\n",
      "Ep:128, loss:0.00000, loss_test:0.02915, lr:3.25e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.694, tt:4475.464\n",
      "Ep:129, loss:0.00000, loss_test:0.02922, lr:3.22e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.692, tt:4509.991\n",
      "Ep:130, loss:0.00000, loss_test:0.02928, lr:3.19e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.695, tt:4545.057\n",
      "Ep:131, loss:0.00000, loss_test:0.02933, lr:3.15e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.697, tt:4579.940\n",
      "Ep:132, loss:0.00000, loss_test:0.02942, lr:3.12e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.683, tt:4612.811\n",
      "Ep:133, loss:0.00000, loss_test:0.02951, lr:3.09e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.683, tt:4647.530\n",
      "Ep:134, loss:0.00000, loss_test:0.02952, lr:3.06e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.683, tt:4682.226\n",
      "Ep:135, loss:0.00000, loss_test:0.02960, lr:3.03e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.699, tt:4719.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02962, lr:3.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.694, tt:4753.071\n",
      "Ep:137, loss:0.00000, loss_test:0.02971, lr:2.97e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.681, tt:4786.017\n",
      "Ep:138, loss:0.00000, loss_test:0.02978, lr:2.94e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.668, tt:4818.817\n",
      "Ep:139, loss:0.00000, loss_test:0.02977, lr:2.91e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.655, tt:4851.747\n",
      "Ep:140, loss:0.00000, loss_test:0.02983, lr:2.88e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.632, tt:4883.119\n",
      "Ep:141, loss:0.00000, loss_test:0.02995, lr:2.85e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.617, tt:4915.557\n",
      "Ep:142, loss:0.00000, loss_test:0.02992, lr:2.82e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.611, tt:4949.379\n",
      "Ep:143, loss:0.00000, loss_test:0.02995, lr:2.80e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.599, tt:4982.254\n",
      "Ep:144, loss:0.00000, loss_test:0.02999, lr:2.77e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.593, tt:5015.985\n",
      "Ep:145, loss:0.00000, loss_test:0.03006, lr:2.74e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.572, tt:5047.489\n",
      "Ep:146, loss:0.00000, loss_test:0.03008, lr:2.71e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.569, tt:5081.616\n",
      "Ep:147, loss:0.00000, loss_test:0.03012, lr:2.69e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.574, tt:5117.002\n",
      "Ep:148, loss:0.00000, loss_test:0.03018, lr:2.66e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.574, tt:5151.526\n",
      "Ep:149, loss:0.00000, loss_test:0.03025, lr:2.63e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.579, tt:5186.905\n",
      "Ep:150, loss:0.00000, loss_test:0.03022, lr:2.61e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.574, tt:5220.685\n",
      "Ep:151, loss:0.00000, loss_test:0.03026, lr:2.58e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.551, tt:5251.792\n",
      "Ep:152, loss:0.00000, loss_test:0.03031, lr:2.55e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.539, tt:5284.527\n",
      "Ep:153, loss:0.00000, loss_test:0.03037, lr:2.53e-02, fs:0.83444 (r=0.724,p=0.984),  time:34.515, tt:5315.325\n",
      "Ep:154, loss:0.00000, loss_test:0.03039, lr:2.50e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.488, tt:5345.688\n",
      "Ep:155, loss:0.00000, loss_test:0.03041, lr:2.48e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.488, tt:5380.111\n",
      "Ep:156, loss:0.00000, loss_test:0.03048, lr:2.45e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.485, tt:5414.195\n",
      "Ep:157, loss:0.00000, loss_test:0.03047, lr:2.43e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.484, tt:5448.429\n",
      "Ep:158, loss:0.00000, loss_test:0.03050, lr:2.40e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.469, tt:5480.583\n",
      "Ep:159, loss:0.00000, loss_test:0.03058, lr:2.38e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.457, tt:5513.182\n",
      "Ep:160, loss:0.00000, loss_test:0.03060, lr:2.36e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.447, tt:5546.047\n",
      "Ep:161, loss:0.00000, loss_test:0.03059, lr:2.33e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.453, tt:5581.398\n",
      "Ep:162, loss:0.00000, loss_test:0.03060, lr:2.31e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.457, tt:5616.473\n",
      "Ep:163, loss:0.00000, loss_test:0.03065, lr:2.29e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.459, tt:5651.297\n",
      "Ep:164, loss:0.00000, loss_test:0.03069, lr:2.26e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.463, tt:5686.392\n",
      "Ep:165, loss:0.00000, loss_test:0.03073, lr:2.24e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.451, tt:5718.946\n",
      "Ep:166, loss:0.00000, loss_test:0.03079, lr:2.22e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.454, tt:5753.778\n",
      "Ep:167, loss:0.00000, loss_test:0.03079, lr:2.20e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.440, tt:5785.913\n",
      "Ep:168, loss:0.00000, loss_test:0.03085, lr:2.17e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.435, tt:5819.516\n",
      "Ep:169, loss:0.00000, loss_test:0.03088, lr:2.15e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.416, tt:5850.643\n",
      "Ep:170, loss:0.00000, loss_test:0.03090, lr:2.13e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.402, tt:5882.691\n",
      "Ep:171, loss:0.00000, loss_test:0.03090, lr:2.11e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.396, tt:5916.142\n",
      "Ep:172, loss:0.00000, loss_test:0.03092, lr:2.09e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.393, tt:5949.953\n",
      "Ep:173, loss:0.00000, loss_test:0.03095, lr:2.07e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.387, tt:5983.412\n",
      "Ep:174, loss:0.00000, loss_test:0.03100, lr:2.05e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.387, tt:6017.702\n",
      "Ep:175, loss:0.00000, loss_test:0.03104, lr:2.03e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.386, tt:6051.946\n",
      "Ep:176, loss:0.00000, loss_test:0.03105, lr:2.01e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.386, tt:6086.314\n",
      "Ep:177, loss:0.00000, loss_test:0.03109, lr:1.99e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.381, tt:6119.773\n",
      "Ep:178, loss:0.00000, loss_test:0.03111, lr:1.97e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.380, tt:6154.049\n",
      "Ep:179, loss:0.00000, loss_test:0.03112, lr:1.95e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.365, tt:6185.705\n",
      "Ep:180, loss:0.00000, loss_test:0.03114, lr:1.93e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.355, tt:6218.181\n",
      "Ep:181, loss:0.00000, loss_test:0.03118, lr:1.91e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.352, tt:6251.980\n",
      "Ep:182, loss:0.00000, loss_test:0.03118, lr:1.89e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.353, tt:6286.604\n",
      "Ep:183, loss:0.00000, loss_test:0.03119, lr:1.87e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.352, tt:6320.735\n",
      "Ep:184, loss:0.00000, loss_test:0.03123, lr:1.85e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.344, tt:6353.608\n",
      "Ep:185, loss:0.00000, loss_test:0.03128, lr:1.83e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.345, tt:6388.115\n",
      "Ep:186, loss:0.00000, loss_test:0.03127, lr:1.81e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.323, tt:6418.382\n",
      "Ep:187, loss:0.00000, loss_test:0.03129, lr:1.80e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.316, tt:6451.488\n",
      "Ep:188, loss:0.00000, loss_test:0.03132, lr:1.78e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.306, tt:6483.767\n",
      "Ep:189, loss:0.00000, loss_test:0.03136, lr:1.76e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.309, tt:6518.770\n",
      "Ep:190, loss:0.00000, loss_test:0.03134, lr:1.74e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.299, tt:6551.029\n",
      "Ep:191, loss:0.00000, loss_test:0.03137, lr:1.73e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.306, tt:6586.791\n",
      "Ep:192, loss:0.00000, loss_test:0.03140, lr:1.71e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.307, tt:6621.284\n",
      "Ep:193, loss:0.00000, loss_test:0.03142, lr:1.69e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.311, tt:6656.334\n",
      "Ep:194, loss:0.00000, loss_test:0.03143, lr:1.67e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.309, tt:6690.204\n",
      "Ep:195, loss:0.00000, loss_test:0.03142, lr:1.66e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.320, tt:6726.635\n",
      "Ep:196, loss:0.00000, loss_test:0.03144, lr:1.64e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.332, tt:6763.482\n",
      "Ep:197, loss:0.00000, loss_test:0.03146, lr:1.62e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.323, tt:6795.918\n",
      "Ep:198, loss:0.00000, loss_test:0.03149, lr:1.61e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.320, tt:6829.681\n",
      "Ep:199, loss:0.00000, loss_test:0.03152, lr:1.59e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.313, tt:6862.628\n",
      "Ep:200, loss:0.00000, loss_test:0.03152, lr:1.58e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.306, tt:6895.480\n",
      "Ep:201, loss:0.00000, loss_test:0.03152, lr:1.56e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.300, tt:6928.664\n",
      "Ep:202, loss:0.00000, loss_test:0.03155, lr:1.54e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.281, tt:6959.135\n",
      "Ep:203, loss:0.00000, loss_test:0.03159, lr:1.53e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.275, tt:6992.065\n",
      "Ep:204, loss:0.00000, loss_test:0.03157, lr:1.51e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.270, tt:7025.381\n",
      "Ep:205, loss:0.00000, loss_test:0.03160, lr:1.50e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.267, tt:7058.977\n",
      "Ep:206, loss:0.00000, loss_test:0.03161, lr:1.48e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.267, tt:7093.311\n",
      "Ep:207, loss:0.00000, loss_test:0.03162, lr:1.47e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.261, tt:7126.387\n",
      "Ep:208, loss:0.00000, loss_test:0.03162, lr:1.45e-02, fs:0.84000 (r=0.724,p=1.000),  time:34.272, tt:7162.770\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "#             loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14327, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.255, tt:14.255\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14216, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.245, tt:26.491\n",
      "Ep:2, loss:0.00028, loss_test:0.14014, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.849, tt:38.547\n",
      "Ep:3, loss:0.00027, loss_test:0.13673, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:13.052, tt:52.209\n",
      "Ep:4, loss:0.00026, loss_test:0.13111, lr:1.00e-02, fs:0.65882 (r=0.966,p=0.500),  time:12.859, tt:64.293\n",
      "Ep:5, loss:0.00025, loss_test:0.12190, lr:1.00e-02, fs:0.64220 (r=0.805,p=0.534),  time:12.753, tt:76.518\n",
      "Ep:6, loss:0.00023, loss_test:0.11291, lr:1.00e-02, fs:0.63030 (r=0.598,p=0.667),  time:12.682, tt:88.775\n",
      "Ep:7, loss:0.00022, loss_test:0.11141, lr:1.00e-02, fs:0.62893 (r=0.575,p=0.694),  time:12.614, tt:100.913\n",
      "Ep:8, loss:0.00021, loss_test:0.11008, lr:1.00e-02, fs:0.64706 (r=0.632,p=0.663),  time:12.564, tt:113.077\n",
      "Ep:9, loss:0.00020, loss_test:0.10722, lr:1.00e-02, fs:0.70455 (r=0.713,p=0.697),  time:12.507, tt:125.070\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10543, lr:1.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:12.480, tt:137.284\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.10662, lr:1.00e-02, fs:0.73939 (r=0.701,p=0.782),  time:12.463, tt:149.550\n",
      "Ep:12, loss:0.00017, loss_test:0.10250, lr:1.00e-02, fs:0.75294 (r=0.736,p=0.771),  time:12.434, tt:161.646\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.10056, lr:1.00e-02, fs:0.75145 (r=0.747,p=0.756),  time:12.401, tt:173.619\n",
      "Ep:14, loss:0.00015, loss_test:0.10207, lr:1.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:12.392, tt:185.881\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00014, loss_test:0.10013, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:12.392, tt:198.270\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.09791, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:12.388, tt:210.595\n",
      "Ep:17, loss:0.00013, loss_test:0.09901, lr:1.00e-02, fs:0.77381 (r=0.747,p=0.802),  time:12.317, tt:221.707\n",
      "Ep:18, loss:0.00012, loss_test:0.09816, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:12.253, tt:232.816\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.09788, lr:1.00e-02, fs:0.78313 (r=0.747,p=0.823),  time:12.196, tt:243.925\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.09690, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:12.144, tt:255.028\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.09620, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:12.099, tt:266.187\n",
      "Ep:22, loss:0.00010, loss_test:0.09856, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:12.055, tt:277.268\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.09721, lr:1.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:12.015, tt:288.361\n",
      "Ep:24, loss:0.00009, loss_test:0.09776, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:11.980, tt:299.510\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00008, loss_test:0.09733, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:11.946, tt:310.598\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00008, loss_test:0.09831, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:11.913, tt:321.643\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.09531, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:11.884, tt:332.751\n",
      "Ep:28, loss:0.00007, loss_test:0.09500, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:11.857, tt:343.867\n",
      "Ep:29, loss:0.00006, loss_test:0.09409, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:11.832, tt:354.975\n",
      "Ep:30, loss:0.00006, loss_test:0.09521, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:11.808, tt:366.049\n",
      "Ep:31, loss:0.00005, loss_test:0.09676, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:11.789, tt:377.256\n",
      "Ep:32, loss:0.00005, loss_test:0.09496, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:11.768, tt:388.356\n",
      "Ep:33, loss:0.00005, loss_test:0.09798, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:11.749, tt:399.480\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00004, loss_test:0.09469, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:11.733, tt:410.665\n",
      "Ep:35, loss:0.00004, loss_test:0.09782, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:11.716, tt:421.783\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00004, loss_test:0.09381, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:11.701, tt:432.954\n",
      "Ep:37, loss:0.00003, loss_test:0.09831, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:11.686, tt:444.073\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.09380, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:11.671, tt:455.165\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.09920, lr:1.00e-02, fs:0.86452 (r=0.770,p=0.985),  time:11.656, tt:466.252\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.09284, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:11.643, tt:477.369\n",
      "Ep:41, loss:0.00003, loss_test:0.10141, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:11.631, tt:488.505\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.09158, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:11.619, tt:499.614\n",
      "Ep:43, loss:0.00002, loss_test:0.10044, lr:1.00e-02, fs:0.86452 (r=0.770,p=0.985),  time:11.608, tt:510.770\n",
      "Ep:44, loss:0.00002, loss_test:0.09406, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:11.660, tt:524.716\n",
      "Ep:45, loss:0.00002, loss_test:0.09771, lr:1.00e-02, fs:0.87013 (r=0.770,p=1.000),  time:11.649, tt:535.859\n",
      "Ep:46, loss:0.00002, loss_test:0.09510, lr:1.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:11.638, tt:547.000\n",
      "Ep:47, loss:0.00002, loss_test:0.09885, lr:1.00e-02, fs:0.80822 (r=0.678,p=1.000),  time:11.627, tt:558.116\n",
      "Ep:48, loss:0.00002, loss_test:0.09307, lr:1.00e-02, fs:0.84211 (r=0.736,p=0.985),  time:11.617, tt:569.250\n",
      "Ep:49, loss:0.00001, loss_test:0.09732, lr:1.00e-02, fs:0.86275 (r=0.759,p=1.000),  time:11.607, tt:580.326\n",
      "Ep:50, loss:0.00001, loss_test:0.09497, lr:1.00e-02, fs:0.87013 (r=0.770,p=1.000),  time:11.598, tt:591.474\n",
      "Ep:51, loss:0.00001, loss_test:0.09846, lr:1.00e-02, fs:0.80000 (r=0.667,p=1.000),  time:11.590, tt:602.670\n",
      "Ep:52, loss:0.00001, loss_test:0.09639, lr:1.00e-02, fs:0.80000 (r=0.667,p=1.000),  time:11.582, tt:613.863\n",
      "Ep:53, loss:0.00001, loss_test:0.09453, lr:9.90e-03, fs:0.84000 (r=0.724,p=1.000),  time:11.574, tt:624.985\n",
      "Ep:54, loss:0.00001, loss_test:0.09939, lr:9.80e-03, fs:0.80000 (r=0.667,p=1.000),  time:11.567, tt:636.177\n",
      "Ep:55, loss:0.00001, loss_test:0.09445, lr:9.70e-03, fs:0.80822 (r=0.678,p=1.000),  time:11.560, tt:647.363\n",
      "Ep:56, loss:0.00001, loss_test:0.10012, lr:9.61e-03, fs:0.80000 (r=0.667,p=1.000),  time:11.553, tt:658.505\n",
      "Ep:57, loss:0.00001, loss_test:0.09599, lr:9.51e-03, fs:0.80822 (r=0.678,p=1.000),  time:11.546, tt:669.670\n",
      "Ep:58, loss:0.00001, loss_test:0.09591, lr:9.41e-03, fs:0.80000 (r=0.667,p=1.000),  time:11.539, tt:680.800\n",
      "Ep:59, loss:0.00001, loss_test:0.09645, lr:9.32e-03, fs:0.80000 (r=0.667,p=1.000),  time:11.552, tt:693.140\n",
      "Ep:60, loss:0.00001, loss_test:0.09670, lr:9.23e-03, fs:0.80000 (r=0.667,p=1.000),  time:11.552, tt:704.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.09617, lr:9.14e-03, fs:0.79167 (r=0.655,p=1.000),  time:11.568, tt:717.233\n",
      "Ep:62, loss:0.00001, loss_test:0.09467, lr:9.04e-03, fs:0.80822 (r=0.678,p=1.000),  time:11.593, tt:730.389\n",
      "Ep:63, loss:0.00001, loss_test:0.09838, lr:8.95e-03, fs:0.78322 (r=0.644,p=1.000),  time:11.607, tt:742.830\n",
      "Ep:64, loss:0.00001, loss_test:0.09590, lr:8.86e-03, fs:0.82432 (r=0.701,p=1.000),  time:11.620, tt:755.326\n",
      "Ep:65, loss:0.00001, loss_test:0.09588, lr:8.78e-03, fs:0.78322 (r=0.644,p=1.000),  time:11.635, tt:767.932\n",
      "Ep:66, loss:0.00001, loss_test:0.09734, lr:8.69e-03, fs:0.79167 (r=0.655,p=1.000),  time:11.647, tt:780.326\n",
      "Ep:67, loss:0.00001, loss_test:0.09648, lr:8.60e-03, fs:0.78322 (r=0.644,p=1.000),  time:11.659, tt:792.806\n",
      "Ep:68, loss:0.00001, loss_test:0.09961, lr:8.51e-03, fs:0.79167 (r=0.655,p=1.000),  time:11.670, tt:805.244\n",
      "Ep:69, loss:0.00001, loss_test:0.09682, lr:8.43e-03, fs:0.77465 (r=0.632,p=1.000),  time:11.686, tt:817.998\n",
      "Ep:70, loss:0.00000, loss_test:0.10012, lr:8.35e-03, fs:0.78322 (r=0.644,p=1.000),  time:11.697, tt:830.515\n",
      "Ep:71, loss:0.00000, loss_test:0.09858, lr:8.26e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.714, tt:843.377\n",
      "Ep:72, loss:0.00000, loss_test:0.09806, lr:8.18e-03, fs:0.78322 (r=0.644,p=1.000),  time:11.729, tt:856.237\n",
      "Ep:73, loss:0.00000, loss_test:0.09769, lr:8.10e-03, fs:0.77465 (r=0.632,p=1.000),  time:11.742, tt:868.916\n",
      "Ep:74, loss:0.00000, loss_test:0.09775, lr:8.02e-03, fs:0.77465 (r=0.632,p=1.000),  time:11.756, tt:881.677\n",
      "Ep:75, loss:0.00000, loss_test:0.09769, lr:7.94e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.768, tt:894.351\n",
      "Ep:76, loss:0.00000, loss_test:0.09783, lr:7.86e-03, fs:0.77465 (r=0.632,p=1.000),  time:11.785, tt:907.448\n",
      "Ep:77, loss:0.00000, loss_test:0.09898, lr:7.78e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.798, tt:920.266\n",
      "Ep:78, loss:0.00000, loss_test:0.09797, lr:7.70e-03, fs:0.77465 (r=0.632,p=1.000),  time:11.812, tt:933.167\n",
      "Ep:79, loss:0.00000, loss_test:0.09847, lr:7.62e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.824, tt:945.946\n",
      "Ep:80, loss:0.00000, loss_test:0.09956, lr:7.55e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.836, tt:958.714\n",
      "Ep:81, loss:0.00000, loss_test:0.09752, lr:7.47e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.849, tt:971.614\n",
      "Ep:82, loss:0.00000, loss_test:0.09935, lr:7.40e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.859, tt:984.261\n",
      "Ep:83, loss:0.00000, loss_test:0.09939, lr:7.32e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.870, tt:997.085\n",
      "Ep:84, loss:0.00000, loss_test:0.09810, lr:7.25e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.878, tt:1009.619\n",
      "Ep:85, loss:0.00000, loss_test:0.09787, lr:7.18e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.889, tt:1022.470\n",
      "Ep:86, loss:0.00000, loss_test:0.09909, lr:7.11e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.897, tt:1035.069\n",
      "Ep:87, loss:0.00000, loss_test:0.10020, lr:7.03e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.904, tt:1047.549\n",
      "Ep:88, loss:0.00000, loss_test:0.09838, lr:6.96e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.913, tt:1060.262\n",
      "Ep:89, loss:0.00000, loss_test:0.09910, lr:6.89e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.920, tt:1072.807\n",
      "Ep:90, loss:0.00000, loss_test:0.10014, lr:6.83e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.928, tt:1085.438\n",
      "Ep:91, loss:0.00000, loss_test:0.09950, lr:6.76e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.940, tt:1098.452\n",
      "Ep:92, loss:0.00000, loss_test:0.09917, lr:6.69e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.950, tt:1111.367\n",
      "Ep:93, loss:0.00000, loss_test:0.10012, lr:6.62e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.955, tt:1123.808\n",
      "Ep:94, loss:0.00000, loss_test:0.10038, lr:6.56e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.960, tt:1136.165\n",
      "Ep:95, loss:0.00000, loss_test:0.10059, lr:6.49e-03, fs:0.75714 (r=0.609,p=1.000),  time:11.968, tt:1148.936\n",
      "Ep:96, loss:0.00000, loss_test:0.10059, lr:6.43e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.031, tt:1167.005\n",
      "Ep:97, loss:0.00000, loss_test:0.09990, lr:6.36e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.040, tt:1179.937\n",
      "Ep:98, loss:0.00000, loss_test:0.10120, lr:6.30e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.047, tt:1192.635\n",
      "Ep:99, loss:0.00000, loss_test:0.10015, lr:6.24e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.053, tt:1205.345\n",
      "Ep:100, loss:0.00000, loss_test:0.10050, lr:6.17e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.061, tt:1218.122\n",
      "Ep:101, loss:0.00000, loss_test:0.10134, lr:6.11e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.068, tt:1230.962\n",
      "Ep:102, loss:0.00000, loss_test:0.10008, lr:6.05e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.072, tt:1243.447\n",
      "Ep:103, loss:0.00000, loss_test:0.09974, lr:5.99e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.076, tt:1255.876\n",
      "Ep:104, loss:0.00000, loss_test:0.10038, lr:5.93e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.080, tt:1268.432\n",
      "Ep:105, loss:0.00000, loss_test:0.09947, lr:5.87e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.084, tt:1280.952\n",
      "Ep:106, loss:0.00000, loss_test:0.09961, lr:5.81e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.103, tt:1294.970\n",
      "Ep:107, loss:0.00000, loss_test:0.09987, lr:5.75e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.107, tt:1307.595\n",
      "Ep:108, loss:0.00000, loss_test:0.09922, lr:5.70e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.114, tt:1320.390\n",
      "Ep:109, loss:0.00000, loss_test:0.09982, lr:5.64e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.123, tt:1333.556\n",
      "Ep:110, loss:0.00000, loss_test:0.10017, lr:5.58e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.126, tt:1346.010\n",
      "Ep:111, loss:0.00000, loss_test:0.09917, lr:5.53e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.132, tt:1358.774\n",
      "Ep:112, loss:0.00000, loss_test:0.10002, lr:5.47e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.136, tt:1371.374\n",
      "Ep:113, loss:0.00000, loss_test:0.09987, lr:5.42e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.140, tt:1383.911\n",
      "Ep:114, loss:0.00000, loss_test:0.09975, lr:5.36e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.142, tt:1396.384\n",
      "Ep:115, loss:0.00000, loss_test:0.09941, lr:5.31e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.148, tt:1409.216\n",
      "Ep:116, loss:0.00000, loss_test:0.09935, lr:5.26e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.153, tt:1421.888\n",
      "Ep:117, loss:0.00000, loss_test:0.10008, lr:5.20e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.159, tt:1434.741\n",
      "Ep:118, loss:0.00000, loss_test:0.09949, lr:5.15e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.163, tt:1447.392\n",
      "Ep:119, loss:0.00000, loss_test:0.10011, lr:5.10e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.168, tt:1460.170\n",
      "Ep:120, loss:0.00000, loss_test:0.09960, lr:5.05e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.173, tt:1472.875\n",
      "Ep:121, loss:0.00000, loss_test:0.09900, lr:5.00e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.175, tt:1485.397\n",
      "Ep:122, loss:0.00000, loss_test:0.09925, lr:4.95e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.179, tt:1498.055\n",
      "Ep:123, loss:0.00000, loss_test:0.09929, lr:4.90e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.182, tt:1510.560\n",
      "Ep:124, loss:0.00000, loss_test:0.09967, lr:4.85e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.184, tt:1523.045\n",
      "Ep:125, loss:0.00000, loss_test:0.10010, lr:4.80e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.187, tt:1535.552\n",
      "Ep:126, loss:0.00000, loss_test:0.09991, lr:4.75e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.190, tt:1548.168\n",
      "Ep:127, loss:0.00000, loss_test:0.09913, lr:4.71e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.194, tt:1560.873\n",
      "Ep:128, loss:0.00000, loss_test:0.09904, lr:4.66e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.198, tt:1573.554\n",
      "Ep:129, loss:0.00000, loss_test:0.09944, lr:4.61e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.204, tt:1586.473\n",
      "Ep:130, loss:0.00000, loss_test:0.09955, lr:4.57e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.206, tt:1598.999\n",
      "Ep:131, loss:0.00000, loss_test:0.09902, lr:4.52e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.210, tt:1611.727\n",
      "Ep:132, loss:0.00000, loss_test:0.09937, lr:4.48e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.213, tt:1624.333\n",
      "Ep:133, loss:0.00000, loss_test:0.10034, lr:4.43e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.218, tt:1637.213\n",
      "Ep:134, loss:0.00000, loss_test:0.09997, lr:4.39e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.222, tt:1649.945\n",
      "Ep:135, loss:0.00000, loss_test:0.09965, lr:4.34e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.225, tt:1662.607\n",
      "Ep:136, loss:0.00000, loss_test:0.09912, lr:4.30e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.229, tt:1675.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.09882, lr:4.26e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.232, tt:1687.960\n",
      "Ep:138, loss:0.00000, loss_test:0.09890, lr:4.21e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.235, tt:1700.611\n",
      "Ep:139, loss:0.00000, loss_test:0.09872, lr:4.17e-03, fs:0.80000 (r=0.667,p=1.000),  time:12.236, tt:1713.048\n",
      "Ep:140, loss:0.00000, loss_test:0.09905, lr:4.13e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.241, tt:1725.940\n",
      "Ep:141, loss:0.00000, loss_test:0.09918, lr:4.09e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.244, tt:1738.634\n",
      "Ep:142, loss:0.00000, loss_test:0.09893, lr:4.05e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.247, tt:1751.335\n",
      "Ep:143, loss:0.00000, loss_test:0.09895, lr:4.01e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.251, tt:1764.153\n",
      "Ep:144, loss:0.00000, loss_test:0.09913, lr:3.97e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.253, tt:1776.638\n",
      "Ep:145, loss:0.00000, loss_test:0.09933, lr:3.93e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.256, tt:1789.308\n",
      "Ep:146, loss:0.00000, loss_test:0.09928, lr:3.89e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.283, tt:1805.671\n",
      "Ep:147, loss:0.00000, loss_test:0.09892, lr:3.85e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.286, tt:1818.311\n",
      "Ep:148, loss:0.00000, loss_test:0.09904, lr:3.81e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.290, tt:1831.157\n",
      "Ep:149, loss:0.00000, loss_test:0.09898, lr:3.77e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.291, tt:1843.703\n",
      "Ep:150, loss:0.00000, loss_test:0.09865, lr:3.73e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.294, tt:1856.354\n",
      "Ep:151, loss:0.00000, loss_test:0.09881, lr:3.70e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.296, tt:1869.048\n",
      "Ep:152, loss:0.00000, loss_test:0.09887, lr:3.66e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.298, tt:1881.659\n",
      "Ep:153, loss:0.00000, loss_test:0.09882, lr:3.62e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.300, tt:1894.263\n",
      "Ep:154, loss:0.00000, loss_test:0.09890, lr:3.59e-03, fs:0.80000 (r=0.667,p=1.000),  time:12.302, tt:1906.826\n",
      "Ep:155, loss:0.00000, loss_test:0.09888, lr:3.55e-03, fs:0.79167 (r=0.655,p=1.000),  time:12.305, tt:1919.645\n",
      "Ep:156, loss:0.00000, loss_test:0.09888, lr:3.52e-03, fs:0.79167 (r=0.655,p=1.000),  time:12.308, tt:1932.382\n",
      "Ep:157, loss:0.00000, loss_test:0.09888, lr:3.48e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.311, tt:1945.064\n",
      "Ep:158, loss:0.00000, loss_test:0.09928, lr:3.45e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.313, tt:1957.714\n",
      "Ep:159, loss:0.00000, loss_test:0.09919, lr:3.41e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.315, tt:1970.470\n",
      "Ep:160, loss:0.00000, loss_test:0.09896, lr:3.38e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.319, tt:1983.352\n",
      "Ep:161, loss:0.00000, loss_test:0.09879, lr:3.34e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.323, tt:1996.396\n",
      "Ep:162, loss:0.00000, loss_test:0.09900, lr:3.31e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.325, tt:2009.051\n",
      "Ep:163, loss:0.00000, loss_test:0.09891, lr:3.28e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.327, tt:2021.600\n",
      "Ep:164, loss:0.00000, loss_test:0.09896, lr:3.24e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.330, tt:2034.423\n",
      "Ep:165, loss:0.00000, loss_test:0.09891, lr:3.21e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.333, tt:2047.232\n",
      "Ep:166, loss:0.00000, loss_test:0.09902, lr:3.18e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.335, tt:2059.908\n",
      "Ep:167, loss:0.00000, loss_test:0.09877, lr:3.15e-03, fs:0.79167 (r=0.655,p=1.000),  time:12.338, tt:2072.832\n",
      "Ep:168, loss:0.00000, loss_test:0.09958, lr:3.12e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.340, tt:2085.390\n",
      "Ep:169, loss:0.00000, loss_test:0.10041, lr:3.09e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.340, tt:2097.788\n",
      "Ep:170, loss:0.00000, loss_test:0.09967, lr:3.05e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.343, tt:2110.609\n",
      "Ep:171, loss:0.00000, loss_test:0.09903, lr:3.02e-03, fs:0.78322 (r=0.644,p=1.000),  time:12.345, tt:2123.254\n",
      "Ep:172, loss:0.00000, loss_test:0.09947, lr:2.99e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.345, tt:2135.731\n",
      "Ep:173, loss:0.00000, loss_test:0.09994, lr:2.96e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.347, tt:2148.384\n",
      "Ep:174, loss:0.00000, loss_test:0.09956, lr:2.93e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.348, tt:2160.976\n",
      "Ep:175, loss:0.00000, loss_test:0.09909, lr:2.90e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.351, tt:2173.837\n",
      "Ep:176, loss:0.00000, loss_test:0.09877, lr:2.88e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.353, tt:2186.557\n",
      "Ep:177, loss:0.00000, loss_test:0.09868, lr:2.85e-03, fs:0.80000 (r=0.667,p=1.000),  time:12.355, tt:2199.154\n",
      "Ep:178, loss:0.00000, loss_test:0.09907, lr:2.82e-03, fs:0.80000 (r=0.667,p=1.000),  time:12.359, tt:2212.314\n",
      "Ep:179, loss:0.00000, loss_test:0.09945, lr:2.79e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.362, tt:2225.170\n",
      "Ep:180, loss:0.00000, loss_test:0.09944, lr:2.76e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.362, tt:2237.474\n",
      "Ep:181, loss:0.00000, loss_test:0.09923, lr:2.73e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.364, tt:2250.290\n",
      "Ep:182, loss:0.00000, loss_test:0.09911, lr:2.71e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.367, tt:2263.078\n",
      "Ep:183, loss:0.00000, loss_test:0.09892, lr:2.68e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.369, tt:2275.919\n",
      "Ep:184, loss:0.00000, loss_test:0.09876, lr:2.65e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.370, tt:2288.468\n",
      "Ep:185, loss:0.00000, loss_test:0.09855, lr:2.63e-03, fs:0.79167 (r=0.655,p=1.000),  time:12.371, tt:2301.028\n",
      "Ep:186, loss:0.00000, loss_test:0.09910, lr:2.60e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.371, tt:2313.392\n",
      "Ep:187, loss:0.00000, loss_test:0.09977, lr:2.57e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.372, tt:2325.845\n",
      "Ep:188, loss:0.00000, loss_test:0.09985, lr:2.55e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.372, tt:2338.312\n",
      "Ep:189, loss:0.00000, loss_test:0.09940, lr:2.52e-03, fs:0.76596 (r=0.621,p=1.000),  time:12.373, tt:2350.867\n",
      "Ep:190, loss:0.00000, loss_test:0.09900, lr:2.50e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.374, tt:2363.353\n",
      "Ep:191, loss:0.00000, loss_test:0.09863, lr:2.47e-03, fs:0.75714 (r=0.609,p=1.000),  time:12.374, tt:2375.790\n",
      "Ep:192, loss:0.00000, loss_test:0.09878, lr:2.45e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.375, tt:2388.330\n",
      "Ep:193, loss:0.00000, loss_test:0.09882, lr:2.42e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.376, tt:2400.977\n",
      "Ep:194, loss:0.00000, loss_test:0.09883, lr:2.40e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.377, tt:2413.447\n",
      "Ep:195, loss:0.00000, loss_test:0.09879, lr:2.38e-03, fs:0.77465 (r=0.632,p=1.000),  time:12.378, tt:2426.002\n",
      "Ep:196, loss:0.00000, loss_test:0.09863, lr:2.35e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.384, tt:2439.694\n",
      "Ep:197, loss:0.00000, loss_test:0.09846, lr:2.33e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.386, tt:2452.434\n",
      "Ep:198, loss:0.00000, loss_test:0.09850, lr:2.31e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.387, tt:2464.970\n",
      "Ep:199, loss:0.00000, loss_test:0.09840, lr:2.28e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.388, tt:2477.655\n",
      "Ep:200, loss:0.00000, loss_test:0.09853, lr:2.26e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.391, tt:2490.528\n",
      "Ep:201, loss:0.00000, loss_test:0.09882, lr:2.24e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.392, tt:2503.275\n",
      "Ep:202, loss:0.00000, loss_test:0.09879, lr:2.21e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.395, tt:2516.098\n",
      "Ep:203, loss:0.00000, loss_test:0.09858, lr:2.19e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.398, tt:2529.182\n",
      "Ep:204, loss:0.00000, loss_test:0.09860, lr:2.17e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.399, tt:2541.735\n",
      "Ep:205, loss:0.00000, loss_test:0.09869, lr:2.15e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.400, tt:2554.409\n",
      "Ep:206, loss:0.00000, loss_test:0.09854, lr:2.13e-03, fs:0.80822 (r=0.678,p=1.000),  time:12.402, tt:2567.165\n",
      "Ep:207, loss:0.00000, loss_test:0.09836, lr:2.11e-03, fs:0.81633 (r=0.690,p=1.000),  time:12.403, tt:2579.845\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00007, loss_test:0.01989, lr:6.00e-02, fs:0.66129 (r=0.943,p=0.509),  time:12.785, tt:12.785\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02365, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.632, tt:25.264\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02535, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.567, tt:37.700\n",
      "Ep:3, loss:0.00005, loss_test:0.02527, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.486, tt:49.942\n",
      "Ep:4, loss:0.00005, loss_test:0.02437, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.474, tt:62.368\n",
      "Ep:5, loss:0.00005, loss_test:0.02269, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.462, tt:74.769\n",
      "Ep:6, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:12.441, tt:87.084\n",
      "Ep:7, loss:0.00004, loss_test:0.01947, lr:6.00e-02, fs:0.66116 (r=0.920,p=0.516),  time:12.407, tt:99.259\n",
      "Ep:8, loss:0.00004, loss_test:0.01882, lr:6.00e-02, fs:0.67873 (r=0.862,p=0.560),  time:12.417, tt:111.749\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.66986 (r=0.805,p=0.574),  time:12.432, tt:124.325\n",
      "Ep:10, loss:0.00004, loss_test:0.01838, lr:6.00e-02, fs:0.64734 (r=0.770,p=0.558),  time:12.427, tt:136.701\n",
      "Ep:11, loss:0.00003, loss_test:0.01830, lr:6.00e-02, fs:0.64186 (r=0.793,p=0.539),  time:12.422, tt:149.061\n",
      "Ep:12, loss:0.00003, loss_test:0.01830, lr:6.00e-02, fs:0.66038 (r=0.805,p=0.560),  time:12.426, tt:161.544\n",
      "Ep:13, loss:0.00003, loss_test:0.01827, lr:6.00e-02, fs:0.67308 (r=0.805,p=0.579),  time:12.425, tt:173.944\n",
      "Ep:14, loss:0.00003, loss_test:0.01840, lr:6.00e-02, fs:0.70000 (r=0.805,p=0.619),  time:12.439, tt:186.587\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01867, lr:6.00e-02, fs:0.71134 (r=0.793,p=0.645),  time:12.431, tt:198.901\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01884, lr:6.00e-02, fs:0.69474 (r=0.759,p=0.641),  time:12.431, tt:211.333\n",
      "Ep:17, loss:0.00003, loss_test:0.01887, lr:6.00e-02, fs:0.68783 (r=0.747,p=0.637),  time:12.429, tt:223.715\n",
      "Ep:18, loss:0.00003, loss_test:0.01876, lr:6.00e-02, fs:0.68783 (r=0.747,p=0.637),  time:12.423, tt:236.036\n",
      "Ep:19, loss:0.00003, loss_test:0.01876, lr:6.00e-02, fs:0.69149 (r=0.747,p=0.644),  time:12.435, tt:248.709\n",
      "Ep:20, loss:0.00003, loss_test:0.01891, lr:6.00e-02, fs:0.69519 (r=0.747,p=0.650),  time:12.441, tt:261.250\n",
      "Ep:21, loss:0.00002, loss_test:0.01925, lr:6.00e-02, fs:0.70652 (r=0.747,p=0.670),  time:12.444, tt:273.757\n",
      "Ep:22, loss:0.00002, loss_test:0.01952, lr:6.00e-02, fs:0.70652 (r=0.747,p=0.670),  time:12.444, tt:286.215\n",
      "Ep:23, loss:0.00002, loss_test:0.01962, lr:6.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:12.431, tt:298.339\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01959, lr:6.00e-02, fs:0.72527 (r=0.759,p=0.695),  time:12.438, tt:310.938\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01942, lr:6.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:12.446, tt:323.588\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01932, lr:6.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:12.447, tt:336.073\n",
      "Ep:27, loss:0.00002, loss_test:0.01929, lr:6.00e-02, fs:0.73743 (r=0.759,p=0.717),  time:12.444, tt:348.428\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01933, lr:6.00e-02, fs:0.75281 (r=0.770,p=0.736),  time:12.440, tt:360.751\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01941, lr:6.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:12.449, tt:373.456\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01947, lr:6.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:12.447, tt:385.854\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01948, lr:6.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:12.441, tt:398.106\n",
      "Ep:32, loss:0.00002, loss_test:0.01940, lr:6.00e-02, fs:0.77457 (r=0.770,p=0.779),  time:12.433, tt:410.294\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01931, lr:6.00e-02, fs:0.77907 (r=0.770,p=0.788),  time:12.439, tt:422.912\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01950, lr:6.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:12.436, tt:435.252\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00001, loss_test:0.01966, lr:6.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:12.438, tt:447.783\n",
      "Ep:36, loss:0.00001, loss_test:0.01976, lr:6.00e-02, fs:0.79070 (r=0.782,p=0.800),  time:12.444, tt:460.418\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00001, loss_test:0.02000, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:12.443, tt:472.836\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00001, loss_test:0.02019, lr:6.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:12.442, tt:485.248\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.02022, lr:6.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:12.443, tt:497.733\n",
      "Ep:40, loss:0.00001, loss_test:0.02031, lr:6.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:12.450, tt:510.430\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.02054, lr:6.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:12.446, tt:522.751\n",
      "Ep:42, loss:0.00001, loss_test:0.02079, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:12.437, tt:534.801\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.02098, lr:6.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:12.435, tt:547.154\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.02124, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:12.439, tt:559.777\n",
      "Ep:45, loss:0.00001, loss_test:0.02156, lr:6.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:12.444, tt:572.408\n",
      "Ep:46, loss:0.00001, loss_test:0.02168, lr:6.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:12.450, tt:585.171\n",
      "Ep:47, loss:0.00001, loss_test:0.02200, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:12.456, tt:597.905\n",
      "Ep:48, loss:0.00001, loss_test:0.02226, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:12.462, tt:610.633\n",
      "Ep:49, loss:0.00001, loss_test:0.02258, lr:6.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:12.468, tt:623.376\n",
      "Ep:50, loss:0.00001, loss_test:0.02280, lr:6.00e-02, fs:0.81290 (r=0.724,p=0.926),  time:12.472, tt:636.059\n",
      "Ep:51, loss:0.00001, loss_test:0.02305, lr:6.00e-02, fs:0.80519 (r=0.713,p=0.925),  time:12.522, tt:651.148\n",
      "Ep:52, loss:0.00001, loss_test:0.02344, lr:6.00e-02, fs:0.79739 (r=0.701,p=0.924),  time:12.525, tt:663.838\n",
      "Ep:53, loss:0.00001, loss_test:0.02373, lr:6.00e-02, fs:0.78667 (r=0.678,p=0.937),  time:12.527, tt:676.450\n",
      "Ep:54, loss:0.00001, loss_test:0.02418, lr:6.00e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.530, tt:689.149\n",
      "Ep:55, loss:0.00001, loss_test:0.02445, lr:5.94e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.533, tt:701.821\n",
      "Ep:56, loss:0.00001, loss_test:0.02460, lr:5.88e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.534, tt:714.437\n",
      "Ep:57, loss:0.00001, loss_test:0.02494, lr:5.82e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.536, tt:727.109\n",
      "Ep:58, loss:0.00001, loss_test:0.02510, lr:5.76e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.539, tt:739.804\n",
      "Ep:59, loss:0.00001, loss_test:0.02535, lr:5.71e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.539, tt:752.362\n",
      "Ep:60, loss:0.00001, loss_test:0.02568, lr:5.65e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.511, tt:763.178\n",
      "Ep:61, loss:0.00001, loss_test:0.02592, lr:5.59e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.483, tt:773.965\n",
      "Ep:62, loss:0.00001, loss_test:0.02622, lr:5.54e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.457, tt:784.768\n",
      "Ep:63, loss:0.00001, loss_test:0.02635, lr:5.48e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.431, tt:795.589\n",
      "Ep:64, loss:0.00001, loss_test:0.02687, lr:5.43e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.405, tt:806.350\n",
      "Ep:65, loss:0.00001, loss_test:0.02704, lr:5.37e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.381, tt:817.119\n",
      "Ep:66, loss:0.00001, loss_test:0.02715, lr:5.32e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.357, tt:827.927\n",
      "Ep:67, loss:0.00001, loss_test:0.02763, lr:5.27e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.334, tt:838.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.02763, lr:5.21e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.311, tt:849.430\n",
      "Ep:69, loss:0.00001, loss_test:0.02824, lr:5.16e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.289, tt:860.225\n",
      "Ep:70, loss:0.00000, loss_test:0.02832, lr:5.11e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.267, tt:870.990\n",
      "Ep:71, loss:0.00000, loss_test:0.02858, lr:5.06e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.247, tt:881.767\n",
      "Ep:72, loss:0.00000, loss_test:0.02882, lr:5.01e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.227, tt:892.557\n",
      "Ep:73, loss:0.00000, loss_test:0.02915, lr:4.96e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.207, tt:903.318\n",
      "Ep:74, loss:0.00000, loss_test:0.02948, lr:4.91e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.188, tt:914.066\n",
      "Ep:75, loss:0.00000, loss_test:0.02953, lr:4.86e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.169, tt:924.816\n",
      "Ep:76, loss:0.00000, loss_test:0.02999, lr:4.81e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.151, tt:935.617\n",
      "Ep:77, loss:0.00000, loss_test:0.03008, lr:4.76e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.133, tt:946.396\n",
      "Ep:78, loss:0.00000, loss_test:0.03046, lr:4.71e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.116, tt:957.174\n",
      "Ep:79, loss:0.00000, loss_test:0.03066, lr:4.67e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.099, tt:967.936\n",
      "Ep:80, loss:0.00000, loss_test:0.03065, lr:4.62e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.083, tt:978.716\n",
      "Ep:81, loss:0.00000, loss_test:0.03108, lr:4.57e-02, fs:0.77852 (r=0.667,p=0.935),  time:12.067, tt:989.468\n",
      "Ep:82, loss:0.00000, loss_test:0.03118, lr:4.53e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.051, tt:1000.243\n",
      "Ep:83, loss:0.00000, loss_test:0.03133, lr:4.48e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.036, tt:1011.008\n",
      "Ep:84, loss:0.00000, loss_test:0.03172, lr:4.44e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.021, tt:1021.819\n",
      "Ep:85, loss:0.00000, loss_test:0.03166, lr:4.39e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.007, tt:1032.609\n",
      "Ep:86, loss:0.00000, loss_test:0.03198, lr:4.35e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.998, tt:1043.795\n",
      "Ep:87, loss:0.00000, loss_test:0.03217, lr:4.31e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.984, tt:1054.598\n",
      "Ep:88, loss:0.00000, loss_test:0.03237, lr:4.26e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.976, tt:1065.858\n",
      "Ep:89, loss:0.00000, loss_test:0.03254, lr:4.22e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.977, tt:1077.929\n",
      "Ep:90, loss:0.00000, loss_test:0.03261, lr:4.18e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.979, tt:1090.058\n",
      "Ep:91, loss:0.00000, loss_test:0.03294, lr:4.14e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.979, tt:1102.057\n",
      "Ep:92, loss:0.00000, loss_test:0.03295, lr:4.10e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.990, tt:1115.082\n",
      "Ep:93, loss:0.00000, loss_test:0.03339, lr:4.05e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.991, tt:1127.121\n",
      "Ep:94, loss:0.00000, loss_test:0.03328, lr:4.01e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.991, tt:1139.123\n",
      "Ep:95, loss:0.00000, loss_test:0.03358, lr:3.97e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.991, tt:1151.130\n",
      "Ep:96, loss:0.00000, loss_test:0.03381, lr:3.93e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.990, tt:1163.050\n",
      "Ep:97, loss:0.00000, loss_test:0.03399, lr:3.89e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.992, tt:1175.230\n",
      "Ep:98, loss:0.00000, loss_test:0.03423, lr:3.86e-02, fs:0.78378 (r=0.667,p=0.951),  time:11.993, tt:1187.350\n",
      "Ep:99, loss:0.00000, loss_test:0.03427, lr:3.82e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.006, tt:1200.611\n",
      "Ep:100, loss:0.00000, loss_test:0.03440, lr:3.78e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.021, tt:1214.125\n",
      "Ep:101, loss:0.00000, loss_test:0.03455, lr:3.74e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.061, tt:1230.215\n",
      "Ep:102, loss:0.00000, loss_test:0.03477, lr:3.70e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.184, tt:1254.971\n",
      "Ep:103, loss:0.00000, loss_test:0.03490, lr:3.67e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.319, tt:1281.143\n",
      "Ep:104, loss:0.00000, loss_test:0.03496, lr:3.63e-02, fs:0.78378 (r=0.667,p=0.951),  time:12.538, tt:1316.491\n",
      "Ep:105, loss:0.00000, loss_test:0.03509, lr:3.59e-02, fs:0.78912 (r=0.667,p=0.967),  time:12.760, tt:1352.518\n",
      "Ep:106, loss:0.00000, loss_test:0.03520, lr:3.56e-02, fs:0.78912 (r=0.667,p=0.967),  time:12.977, tt:1388.549\n",
      "Ep:107, loss:0.00000, loss_test:0.03541, lr:3.52e-02, fs:0.78912 (r=0.667,p=0.967),  time:13.193, tt:1424.797\n",
      "Ep:108, loss:0.00000, loss_test:0.03549, lr:3.49e-02, fs:0.78912 (r=0.667,p=0.967),  time:13.406, tt:1461.267\n",
      "Ep:109, loss:0.00000, loss_test:0.03548, lr:3.45e-02, fs:0.78912 (r=0.667,p=0.967),  time:13.602, tt:1496.178\n",
      "Ep:110, loss:0.00000, loss_test:0.03591, lr:3.42e-02, fs:0.78912 (r=0.667,p=0.967),  time:13.824, tt:1534.500\n",
      "Ep:111, loss:0.00000, loss_test:0.03568, lr:3.38e-02, fs:0.78912 (r=0.667,p=0.967),  time:14.040, tt:1572.488\n",
      "Ep:112, loss:0.00000, loss_test:0.03602, lr:3.35e-02, fs:0.78912 (r=0.667,p=0.967),  time:14.244, tt:1609.519\n",
      "Ep:113, loss:0.00000, loss_test:0.03621, lr:3.32e-02, fs:0.78912 (r=0.667,p=0.967),  time:14.450, tt:1647.348\n",
      "Ep:114, loss:0.00000, loss_test:0.03619, lr:3.28e-02, fs:0.78912 (r=0.667,p=0.967),  time:14.634, tt:1682.940\n",
      "Ep:115, loss:0.00000, loss_test:0.03645, lr:3.25e-02, fs:0.78912 (r=0.667,p=0.967),  time:14.830, tt:1720.288\n",
      "Ep:116, loss:0.00000, loss_test:0.03642, lr:3.22e-02, fs:0.78912 (r=0.667,p=0.967),  time:15.014, tt:1756.655\n",
      "Ep:117, loss:0.00000, loss_test:0.03659, lr:3.19e-02, fs:0.78912 (r=0.667,p=0.967),  time:15.202, tt:1793.853\n",
      "Ep:118, loss:0.00000, loss_test:0.03675, lr:3.15e-02, fs:0.78912 (r=0.667,p=0.967),  time:15.395, tt:1832.051\n",
      "Ep:119, loss:0.00000, loss_test:0.03676, lr:3.12e-02, fs:0.78912 (r=0.667,p=0.967),  time:15.550, tt:1866.057\n",
      "Ep:120, loss:0.00000, loss_test:0.03702, lr:3.09e-02, fs:0.78912 (r=0.667,p=0.967),  time:15.721, tt:1902.292\n",
      "Ep:121, loss:0.00000, loss_test:0.03707, lr:3.06e-02, fs:0.78912 (r=0.667,p=0.967),  time:15.889, tt:1938.443\n",
      "Ep:122, loss:0.00000, loss_test:0.03711, lr:3.03e-02, fs:0.78912 (r=0.667,p=0.967),  time:16.089, tt:1978.971\n",
      "Ep:123, loss:0.00000, loss_test:0.03732, lr:3.00e-02, fs:0.79452 (r=0.667,p=0.983),  time:16.246, tt:2014.527\n",
      "Ep:124, loss:0.00000, loss_test:0.03735, lr:2.97e-02, fs:0.79452 (r=0.667,p=0.983),  time:16.411, tt:2051.414\n",
      "Ep:125, loss:0.00000, loss_test:0.03745, lr:2.94e-02, fs:0.79452 (r=0.667,p=0.983),  time:16.564, tt:2087.117\n",
      "Ep:126, loss:0.00000, loss_test:0.03765, lr:2.91e-02, fs:0.79452 (r=0.667,p=0.983),  time:16.721, tt:2123.606\n",
      "Ep:127, loss:0.00000, loss_test:0.03767, lr:2.88e-02, fs:0.79452 (r=0.667,p=0.983),  time:16.883, tt:2161.080\n",
      "Ep:128, loss:0.00000, loss_test:0.03782, lr:2.85e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.033, tt:2197.203\n",
      "Ep:129, loss:0.00000, loss_test:0.03800, lr:2.82e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.174, tt:2232.666\n",
      "Ep:130, loss:0.00000, loss_test:0.03791, lr:2.80e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.333, tt:2270.568\n",
      "Ep:131, loss:0.00000, loss_test:0.03813, lr:2.77e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.480, tt:2307.400\n",
      "Ep:132, loss:0.00000, loss_test:0.03822, lr:2.74e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.623, tt:2343.910\n",
      "Ep:133, loss:0.00000, loss_test:0.03822, lr:2.71e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.768, tt:2380.952\n",
      "Ep:134, loss:0.00000, loss_test:0.03841, lr:2.69e-02, fs:0.79452 (r=0.667,p=0.983),  time:17.915, tt:2418.532\n",
      "Ep:135, loss:0.00000, loss_test:0.03843, lr:2.66e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.061, tt:2456.299\n",
      "Ep:136, loss:0.00000, loss_test:0.03857, lr:2.63e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.200, tt:2493.387\n",
      "Ep:137, loss:0.00000, loss_test:0.03862, lr:2.61e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.326, tt:2529.054\n",
      "Ep:138, loss:0.00000, loss_test:0.03867, lr:2.58e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.453, tt:2564.996\n",
      "Ep:139, loss:0.00000, loss_test:0.03881, lr:2.55e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.594, tt:2603.095\n",
      "Ep:140, loss:0.00000, loss_test:0.03881, lr:2.53e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.709, tt:2638.002\n",
      "Ep:141, loss:0.00000, loss_test:0.03892, lr:2.50e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.835, tt:2674.614\n",
      "Ep:142, loss:0.00000, loss_test:0.03915, lr:2.48e-02, fs:0.79452 (r=0.667,p=0.983),  time:18.959, tt:2711.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.03905, lr:2.45e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.086, tt:2748.418\n",
      "Ep:144, loss:0.00000, loss_test:0.03911, lr:2.43e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.215, tt:2786.218\n",
      "Ep:145, loss:0.00000, loss_test:0.03934, lr:2.40e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.369, tt:2827.853\n",
      "Ep:146, loss:0.00000, loss_test:0.03920, lr:2.38e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.486, tt:2864.508\n",
      "Ep:147, loss:0.00000, loss_test:0.03935, lr:2.36e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.609, tt:2902.127\n",
      "Ep:148, loss:0.00000, loss_test:0.03952, lr:2.33e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.716, tt:2937.681\n",
      "Ep:149, loss:0.00000, loss_test:0.03949, lr:2.31e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.840, tt:2975.956\n",
      "Ep:150, loss:0.00000, loss_test:0.03957, lr:2.29e-02, fs:0.79452 (r=0.667,p=0.983),  time:19.955, tt:3013.272\n",
      "Ep:151, loss:0.00000, loss_test:0.03974, lr:2.26e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.075, tt:3051.438\n",
      "Ep:152, loss:0.00000, loss_test:0.03973, lr:2.24e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.179, tt:3087.381\n",
      "Ep:153, loss:0.00000, loss_test:0.03980, lr:2.22e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.286, tt:3124.040\n",
      "Ep:154, loss:0.00000, loss_test:0.03992, lr:2.20e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.401, tt:3162.227\n",
      "Ep:155, loss:0.00000, loss_test:0.03993, lr:2.17e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.512, tt:3199.800\n",
      "Ep:156, loss:0.00000, loss_test:0.04000, lr:2.15e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.612, tt:3236.138\n",
      "Ep:157, loss:0.00000, loss_test:0.04011, lr:2.13e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.719, tt:3273.625\n",
      "Ep:158, loss:0.00000, loss_test:0.04015, lr:2.11e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.809, tt:3308.687\n",
      "Ep:159, loss:0.00000, loss_test:0.04018, lr:2.09e-02, fs:0.79452 (r=0.667,p=0.983),  time:20.899, tt:3343.911\n",
      "Ep:160, loss:0.00000, loss_test:0.04028, lr:2.07e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.000, tt:3380.954\n",
      "Ep:161, loss:0.00000, loss_test:0.04032, lr:2.05e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.083, tt:3415.369\n",
      "Ep:162, loss:0.00000, loss_test:0.04033, lr:2.03e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.172, tt:3451.077\n",
      "Ep:163, loss:0.00000, loss_test:0.04044, lr:2.01e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.249, tt:3484.792\n",
      "Ep:164, loss:0.00000, loss_test:0.04052, lr:1.99e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.380, tt:3527.703\n",
      "Ep:165, loss:0.00000, loss_test:0.04050, lr:1.97e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.465, tt:3563.111\n",
      "Ep:166, loss:0.00000, loss_test:0.04058, lr:1.95e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.559, tt:3600.398\n",
      "Ep:167, loss:0.00000, loss_test:0.04062, lr:1.93e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.645, tt:3636.427\n",
      "Ep:168, loss:0.00000, loss_test:0.04069, lr:1.91e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.735, tt:3673.182\n",
      "Ep:169, loss:0.00000, loss_test:0.04076, lr:1.89e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.819, tt:3709.230\n",
      "Ep:170, loss:0.00000, loss_test:0.04082, lr:1.87e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.908, tt:3746.287\n",
      "Ep:171, loss:0.00000, loss_test:0.04083, lr:1.85e-02, fs:0.79452 (r=0.667,p=0.983),  time:21.993, tt:3782.748\n",
      "Ep:172, loss:0.00000, loss_test:0.04088, lr:1.83e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.084, tt:3820.510\n",
      "Ep:173, loss:0.00000, loss_test:0.04095, lr:1.81e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.172, tt:3857.846\n",
      "Ep:174, loss:0.00000, loss_test:0.04099, lr:1.80e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.245, tt:3892.916\n",
      "Ep:175, loss:0.00000, loss_test:0.04100, lr:1.78e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.323, tt:3928.829\n",
      "Ep:176, loss:0.00000, loss_test:0.04107, lr:1.76e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.406, tt:3965.851\n",
      "Ep:177, loss:0.00000, loss_test:0.04113, lr:1.74e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.479, tt:4001.218\n",
      "Ep:178, loss:0.00000, loss_test:0.04116, lr:1.73e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.559, tt:4038.110\n",
      "Ep:179, loss:0.00000, loss_test:0.04117, lr:1.71e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.644, tt:4075.937\n",
      "Ep:180, loss:0.00000, loss_test:0.04124, lr:1.69e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.724, tt:4113.074\n",
      "Ep:181, loss:0.00000, loss_test:0.04131, lr:1.67e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.803, tt:4150.156\n",
      "Ep:182, loss:0.00000, loss_test:0.04132, lr:1.66e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.882, tt:4187.359\n",
      "Ep:183, loss:0.00000, loss_test:0.04136, lr:1.64e-02, fs:0.79452 (r=0.667,p=0.983),  time:22.948, tt:4222.483\n",
      "Ep:184, loss:0.00000, loss_test:0.04145, lr:1.62e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.028, tt:4260.246\n",
      "Ep:185, loss:0.00000, loss_test:0.04144, lr:1.61e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.099, tt:4296.500\n",
      "Ep:186, loss:0.00000, loss_test:0.04147, lr:1.59e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.167, tt:4332.192\n",
      "Ep:187, loss:0.00000, loss_test:0.04156, lr:1.58e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.237, tt:4368.586\n",
      "Ep:188, loss:0.00000, loss_test:0.04159, lr:1.56e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.307, tt:4404.961\n",
      "Ep:189, loss:0.00000, loss_test:0.04157, lr:1.54e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.380, tt:4442.120\n",
      "Ep:190, loss:0.00000, loss_test:0.04162, lr:1.53e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.445, tt:4477.976\n",
      "Ep:191, loss:0.00000, loss_test:0.04169, lr:1.51e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.504, tt:4512.757\n",
      "Ep:192, loss:0.00000, loss_test:0.04175, lr:1.50e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.565, tt:4548.063\n",
      "Ep:193, loss:0.00000, loss_test:0.04178, lr:1.48e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.631, tt:4584.418\n",
      "Ep:194, loss:0.00000, loss_test:0.04179, lr:1.47e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.696, tt:4620.708\n",
      "Ep:195, loss:0.00000, loss_test:0.04182, lr:1.45e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.758, tt:4656.563\n",
      "Ep:196, loss:0.00000, loss_test:0.04190, lr:1.44e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.818, tt:4692.055\n",
      "Ep:197, loss:0.00000, loss_test:0.04193, lr:1.43e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.881, tt:4728.378\n",
      "Ep:198, loss:0.00000, loss_test:0.04194, lr:1.41e-02, fs:0.79452 (r=0.667,p=0.983),  time:23.938, tt:4763.651\n",
      "Ep:199, loss:0.00000, loss_test:0.04198, lr:1.40e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.005, tt:4800.997\n",
      "Ep:200, loss:0.00000, loss_test:0.04202, lr:1.38e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.066, tt:4837.321\n",
      "Ep:201, loss:0.00000, loss_test:0.04204, lr:1.37e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.121, tt:4872.505\n",
      "Ep:202, loss:0.00000, loss_test:0.04208, lr:1.36e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.172, tt:4907.008\n",
      "Ep:203, loss:0.00000, loss_test:0.04209, lr:1.34e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.232, tt:4943.247\n",
      "Ep:204, loss:0.00000, loss_test:0.04217, lr:1.33e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.296, tt:4980.718\n",
      "Ep:205, loss:0.00000, loss_test:0.04219, lr:1.32e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.354, tt:5016.922\n",
      "Ep:206, loss:0.00000, loss_test:0.04218, lr:1.30e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.415, tt:5053.949\n",
      "Ep:207, loss:0.00000, loss_test:0.04226, lr:1.29e-02, fs:0.79452 (r=0.667,p=0.983),  time:24.472, tt:5090.227\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02142, lr:6.00e-02, fs:0.63538 (r=0.889,p=0.494),  time:18.111, tt:18.111\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02469, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.854, tt:49.708\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02590, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.349, tt:85.048\n",
      "Ep:3, loss:0.00005, loss_test:0.02564, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.299, tt:121.195\n",
      "Ep:4, loss:0.00005, loss_test:0.02446, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:32.017, tt:160.086\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02297, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:33.064, tt:198.382\n",
      "Ep:6, loss:0.00004, loss_test:0.02179, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:33.543, tt:234.801\n",
      "Ep:7, loss:0.00004, loss_test:0.02113, lr:6.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:34.500, tt:275.996\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02050, lr:6.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:34.900, tt:314.099\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01959, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:35.198, tt:351.979\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01877, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.232, tt:387.547\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01825, lr:6.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:35.370, tt:424.435\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01778, lr:6.00e-02, fs:0.71483 (r=0.949,p=0.573),  time:35.581, tt:462.547\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:35.857, tt:502.002\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:35.858, tt:537.869\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:35.684, tt:570.942\n",
      "Ep:16, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:35.636, tt:605.817\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01657, lr:6.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:35.536, tt:639.639\n",
      "Ep:18, loss:0.00003, loss_test:0.01650, lr:6.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:35.536, tt:675.183\n",
      "Ep:19, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:35.411, tt:708.224\n",
      "Ep:20, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:35.388, tt:743.151\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:35.335, tt:777.365\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:35.281, tt:811.453\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:35.253, tt:846.067\n",
      "Ep:24, loss:0.00002, loss_test:0.01587, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:35.210, tt:880.251\n",
      "Ep:25, loss:0.00002, loss_test:0.01585, lr:6.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:35.161, tt:914.178\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01582, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:35.203, tt:950.489\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01578, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:35.074, tt:982.077\n",
      "Ep:28, loss:0.00002, loss_test:0.01572, lr:6.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:35.096, tt:1017.794\n",
      "Ep:29, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:35.069, tt:1052.073\n",
      "Ep:30, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:35.091, tt:1087.808\n",
      "Ep:31, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:35.056, tt:1121.779\n",
      "Ep:32, loss:0.00002, loss_test:0.01562, lr:6.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:35.044, tt:1156.445\n",
      "Ep:33, loss:0.00002, loss_test:0.01563, lr:6.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:35.041, tt:1191.404\n",
      "Ep:34, loss:0.00002, loss_test:0.01563, lr:6.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:34.996, tt:1224.847\n",
      "Ep:35, loss:0.00002, loss_test:0.01563, lr:6.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:34.948, tt:1258.142\n",
      "Ep:36, loss:0.00002, loss_test:0.01562, lr:6.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:34.934, tt:1292.545\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:34.923, tt:1327.090\n",
      "Ep:38, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:34.889, tt:1360.665\n",
      "Ep:39, loss:0.00002, loss_test:0.01569, lr:6.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:34.879, tt:1395.172\n",
      "Ep:40, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:34.932, tt:1432.195\n",
      "Ep:41, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.944, tt:1467.630\n",
      "Ep:42, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.941, tt:1502.480\n",
      "Ep:43, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.891, tt:1535.216\n",
      "Ep:44, loss:0.00001, loss_test:0.01574, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.858, tt:1568.611\n",
      "Ep:45, loss:0.00001, loss_test:0.01582, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.837, tt:1602.498\n",
      "Ep:46, loss:0.00001, loss_test:0.01582, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.862, tt:1638.516\n",
      "Ep:47, loss:0.00001, loss_test:0.01582, lr:6.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.880, tt:1674.240\n",
      "Ep:48, loss:0.00001, loss_test:0.01586, lr:5.94e-02, fs:0.75510 (r=0.747,p=0.763),  time:34.816, tt:1705.962\n",
      "Ep:49, loss:0.00001, loss_test:0.01585, lr:5.88e-02, fs:0.75897 (r=0.747,p=0.771),  time:34.778, tt:1738.899\n",
      "Ep:50, loss:0.00001, loss_test:0.01594, lr:5.82e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.765, tt:1773.006\n",
      "Ep:51, loss:0.00001, loss_test:0.01590, lr:5.76e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.752, tt:1807.125\n",
      "Ep:52, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.739, tt:1841.168\n",
      "Ep:53, loss:0.00001, loss_test:0.01600, lr:5.65e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.702, tt:1873.911\n",
      "Ep:54, loss:0.00001, loss_test:0.01604, lr:5.59e-02, fs:0.75648 (r=0.737,p=0.777),  time:34.660, tt:1906.306\n",
      "Ep:55, loss:0.00001, loss_test:0.01605, lr:5.54e-02, fs:0.76042 (r=0.737,p=0.785),  time:34.684, tt:1942.277\n",
      "Ep:56, loss:0.00001, loss_test:0.01607, lr:5.48e-02, fs:0.76042 (r=0.737,p=0.785),  time:34.680, tt:1976.748\n",
      "Ep:57, loss:0.00001, loss_test:0.01613, lr:5.43e-02, fs:0.76042 (r=0.737,p=0.785),  time:34.656, tt:2010.033\n",
      "Ep:58, loss:0.00001, loss_test:0.01611, lr:5.37e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.625, tt:2042.885\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01613, lr:5.37e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.598, tt:2075.876\n",
      "Ep:60, loss:0.00001, loss_test:0.01621, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.589, tt:2109.940\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01628, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.587, tt:2144.389\n",
      "Ep:62, loss:0.00001, loss_test:0.01631, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.583, tt:2178.702\n",
      "Ep:63, loss:0.00001, loss_test:0.01632, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.576, tt:2212.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01634, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.544, tt:2245.380\n",
      "Ep:65, loss:0.00001, loss_test:0.01637, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.544, tt:2279.918\n",
      "Ep:66, loss:0.00001, loss_test:0.01643, lr:5.37e-02, fs:0.77249 (r=0.737,p=0.811),  time:34.571, tt:2316.235\n",
      "Ep:67, loss:0.00001, loss_test:0.01652, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.595, tt:2352.429\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01647, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.590, tt:2386.677\n",
      "Ep:69, loss:0.00001, loss_test:0.01644, lr:5.37e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.632, tt:2424.207\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01648, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.670, tt:2461.536\n",
      "Ep:71, loss:0.00001, loss_test:0.01662, lr:5.37e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.664, tt:2495.834\n",
      "Ep:72, loss:0.00001, loss_test:0.01668, lr:5.37e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.658, tt:2530.042\n",
      "Ep:73, loss:0.00001, loss_test:0.01669, lr:5.37e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.666, tt:2565.309\n",
      "Ep:74, loss:0.00001, loss_test:0.01664, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.665, tt:2599.857\n",
      "Ep:75, loss:0.00001, loss_test:0.01663, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.672, tt:2635.053\n",
      "Ep:76, loss:0.00001, loss_test:0.01670, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.675, tt:2669.963\n",
      "Ep:77, loss:0.00001, loss_test:0.01678, lr:5.37e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.692, tt:2705.974\n",
      "Ep:78, loss:0.00001, loss_test:0.01686, lr:5.37e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.678, tt:2739.547\n",
      "Ep:79, loss:0.00001, loss_test:0.01692, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.671, tt:2773.695\n",
      "Ep:80, loss:0.00001, loss_test:0.01683, lr:5.37e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.678, tt:2808.918\n",
      "Ep:81, loss:0.00001, loss_test:0.01691, lr:5.32e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.701, tt:2845.458\n",
      "Ep:82, loss:0.00001, loss_test:0.01698, lr:5.27e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.709, tt:2880.840\n",
      "Ep:83, loss:0.00001, loss_test:0.01705, lr:5.21e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.692, tt:2914.152\n",
      "Ep:84, loss:0.00001, loss_test:0.01708, lr:5.16e-02, fs:0.77174 (r=0.717,p=0.835),  time:34.698, tt:2949.311\n",
      "Ep:85, loss:0.00001, loss_test:0.01712, lr:5.11e-02, fs:0.77596 (r=0.717,p=0.845),  time:34.702, tt:2984.369\n",
      "Ep:86, loss:0.00001, loss_test:0.01720, lr:5.06e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.698, tt:3018.717\n",
      "Ep:87, loss:0.00001, loss_test:0.01720, lr:5.01e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.741, tt:3057.212\n",
      "Ep:88, loss:0.00001, loss_test:0.01727, lr:4.96e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.735, tt:3091.459\n",
      "Ep:89, loss:0.00001, loss_test:0.01736, lr:4.91e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.820, tt:3133.764\n",
      "Ep:90, loss:0.00001, loss_test:0.01735, lr:4.86e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.826, tt:3169.206\n",
      "Ep:91, loss:0.00001, loss_test:0.01741, lr:4.81e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.855, tt:3206.667\n",
      "Ep:92, loss:0.00001, loss_test:0.01747, lr:4.76e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.869, tt:3242.787\n",
      "Ep:93, loss:0.00001, loss_test:0.01746, lr:4.71e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.869, tt:3277.693\n",
      "Ep:94, loss:0.00001, loss_test:0.01747, lr:4.67e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.866, tt:3312.260\n",
      "Ep:95, loss:0.00001, loss_test:0.01752, lr:4.62e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.878, tt:3348.335\n",
      "Ep:96, loss:0.00001, loss_test:0.01767, lr:4.57e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.894, tt:3384.684\n",
      "Ep:97, loss:0.00001, loss_test:0.01775, lr:4.53e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.886, tt:3418.820\n",
      "Ep:98, loss:0.00001, loss_test:0.01776, lr:4.48e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.895, tt:3454.559\n",
      "Ep:99, loss:0.00001, loss_test:0.01777, lr:4.44e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.914, tt:3491.409\n",
      "Ep:100, loss:0.00001, loss_test:0.01778, lr:4.39e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.918, tt:3526.736\n",
      "Ep:101, loss:0.00001, loss_test:0.01789, lr:4.35e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.929, tt:3562.786\n",
      "Ep:102, loss:0.00001, loss_test:0.01794, lr:4.31e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.928, tt:3597.613\n",
      "Ep:103, loss:0.00001, loss_test:0.01789, lr:4.26e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.931, tt:3632.856\n",
      "Ep:104, loss:0.00001, loss_test:0.01793, lr:4.22e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.936, tt:3668.303\n",
      "Ep:105, loss:0.00001, loss_test:0.01803, lr:4.18e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.941, tt:3703.743\n",
      "Ep:106, loss:0.00001, loss_test:0.01809, lr:4.14e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.946, tt:3739.254\n",
      "Ep:107, loss:0.00001, loss_test:0.01810, lr:4.10e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.952, tt:3774.772\n",
      "Ep:108, loss:0.00001, loss_test:0.01814, lr:4.05e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.952, tt:3809.763\n",
      "Ep:109, loss:0.00000, loss_test:0.01822, lr:4.01e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.976, tt:3847.406\n",
      "Ep:110, loss:0.00000, loss_test:0.01823, lr:3.97e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.982, tt:3882.961\n",
      "Ep:111, loss:0.00000, loss_test:0.01831, lr:3.93e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.984, tt:3918.237\n",
      "Ep:112, loss:0.00000, loss_test:0.01836, lr:3.89e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.986, tt:3953.381\n",
      "Ep:113, loss:0.00000, loss_test:0.01839, lr:3.86e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.971, tt:3986.665\n",
      "Ep:114, loss:0.00000, loss_test:0.01846, lr:3.82e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.995, tt:4024.408\n",
      "Ep:115, loss:0.00000, loss_test:0.01850, lr:3.78e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.981, tt:4057.747\n",
      "Ep:116, loss:0.00000, loss_test:0.01851, lr:3.74e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.970, tt:4091.466\n",
      "Ep:117, loss:0.00000, loss_test:0.01858, lr:3.70e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.960, tt:4125.304\n",
      "Ep:118, loss:0.00000, loss_test:0.01860, lr:3.67e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.993, tt:4164.191\n",
      "Ep:119, loss:0.00000, loss_test:0.01867, lr:3.63e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.981, tt:4197.726\n",
      "Ep:120, loss:0.00000, loss_test:0.01870, lr:3.59e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.980, tt:4232.588\n",
      "Ep:121, loss:0.00000, loss_test:0.01876, lr:3.56e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.972, tt:4266.532\n",
      "Ep:122, loss:0.00000, loss_test:0.01885, lr:3.52e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.953, tt:4299.172\n",
      "Ep:123, loss:0.00000, loss_test:0.01885, lr:3.49e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.960, tt:4335.087\n",
      "Ep:124, loss:0.00000, loss_test:0.01890, lr:3.45e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.954, tt:4369.297\n",
      "Ep:125, loss:0.00000, loss_test:0.01893, lr:3.42e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.958, tt:4404.736\n",
      "Ep:126, loss:0.00000, loss_test:0.01897, lr:3.38e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.967, tt:4440.840\n",
      "Ep:127, loss:0.00000, loss_test:0.01900, lr:3.35e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.975, tt:4476.786\n",
      "Ep:128, loss:0.00000, loss_test:0.01905, lr:3.32e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.975, tt:4511.720\n",
      "Ep:129, loss:0.00000, loss_test:0.01907, lr:3.28e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.971, tt:4546.191\n",
      "Ep:130, loss:0.00000, loss_test:0.01910, lr:3.25e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.964, tt:4580.295\n",
      "Ep:131, loss:0.00000, loss_test:0.01913, lr:3.22e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.963, tt:4615.147\n",
      "Ep:132, loss:0.00000, loss_test:0.01912, lr:3.19e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.957, tt:4649.311\n",
      "Ep:133, loss:0.00000, loss_test:0.01921, lr:3.15e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.964, tt:4685.173\n",
      "Ep:134, loss:0.00000, loss_test:0.01931, lr:3.12e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.976, tt:4721.696\n",
      "Ep:135, loss:0.00000, loss_test:0.01929, lr:3.09e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.978, tt:4756.988\n",
      "Ep:136, loss:0.00000, loss_test:0.01934, lr:3.06e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.974, tt:4791.434\n",
      "Ep:137, loss:0.00000, loss_test:0.01938, lr:3.03e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.965, tt:4825.115\n",
      "Ep:138, loss:0.00000, loss_test:0.01938, lr:3.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.964, tt:4860.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.01942, lr:2.97e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.944, tt:4892.221\n",
      "Ep:140, loss:0.00000, loss_test:0.01945, lr:2.94e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.931, tt:4925.284\n",
      "Ep:141, loss:0.00000, loss_test:0.01951, lr:2.91e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.936, tt:4960.863\n",
      "Ep:142, loss:0.00000, loss_test:0.01955, lr:2.88e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.985, tt:5002.791\n",
      "Ep:143, loss:0.00000, loss_test:0.01959, lr:2.85e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.986, tt:5037.959\n",
      "Ep:144, loss:0.00000, loss_test:0.01959, lr:2.82e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.976, tt:5071.525\n",
      "Ep:145, loss:0.00000, loss_test:0.01966, lr:2.80e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.965, tt:5104.851\n",
      "Ep:146, loss:0.00000, loss_test:0.01969, lr:2.77e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.963, tt:5139.539\n",
      "Ep:147, loss:0.00000, loss_test:0.01973, lr:2.74e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.959, tt:5173.914\n",
      "Ep:148, loss:0.00000, loss_test:0.01976, lr:2.71e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.938, tt:5205.704\n",
      "Ep:149, loss:0.00000, loss_test:0.01978, lr:2.69e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.935, tt:5240.325\n",
      "Ep:150, loss:0.00000, loss_test:0.01980, lr:2.66e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.919, tt:5272.828\n",
      "Ep:151, loss:0.00000, loss_test:0.01984, lr:2.63e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.910, tt:5306.287\n",
      "Ep:152, loss:0.00000, loss_test:0.01988, lr:2.61e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.896, tt:5339.056\n",
      "Ep:153, loss:0.00000, loss_test:0.01995, lr:2.58e-02, fs:0.70659 (r=0.596,p=0.868),  time:34.883, tt:5371.972\n",
      "Ep:154, loss:0.00000, loss_test:0.01997, lr:2.55e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.886, tt:5407.252\n",
      "Ep:155, loss:0.00000, loss_test:0.01999, lr:2.53e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.870, tt:5439.796\n",
      "Ep:156, loss:0.00000, loss_test:0.02000, lr:2.50e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.858, tt:5472.738\n",
      "Ep:157, loss:0.00000, loss_test:0.02001, lr:2.48e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.858, tt:5507.630\n",
      "Ep:158, loss:0.00000, loss_test:0.02008, lr:2.45e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.848, tt:5540.786\n",
      "Ep:159, loss:0.00000, loss_test:0.02012, lr:2.43e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.845, tt:5575.126\n",
      "Ep:160, loss:0.00000, loss_test:0.02014, lr:2.40e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.834, tt:5608.214\n",
      "Ep:161, loss:0.00000, loss_test:0.02019, lr:2.38e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.822, tt:5641.232\n",
      "Ep:162, loss:0.00000, loss_test:0.02021, lr:2.36e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.819, tt:5675.459\n",
      "Ep:163, loss:0.00000, loss_test:0.02019, lr:2.33e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.809, tt:5708.659\n",
      "Ep:164, loss:0.00000, loss_test:0.02024, lr:2.31e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.806, tt:5743.069\n",
      "Ep:165, loss:0.00000, loss_test:0.02027, lr:2.29e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.805, tt:5777.709\n",
      "Ep:166, loss:0.00000, loss_test:0.02026, lr:2.26e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.805, tt:5812.508\n",
      "Ep:167, loss:0.00000, loss_test:0.02031, lr:2.24e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.820, tt:5849.725\n",
      "Ep:168, loss:0.00000, loss_test:0.02036, lr:2.22e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.820, tt:5884.660\n",
      "Ep:169, loss:0.00000, loss_test:0.02038, lr:2.20e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.811, tt:5917.795\n",
      "Ep:170, loss:0.00000, loss_test:0.02040, lr:2.17e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.807, tt:5952.037\n",
      "Ep:171, loss:0.00000, loss_test:0.02044, lr:2.15e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.793, tt:5984.461\n",
      "Ep:172, loss:0.00000, loss_test:0.02047, lr:2.13e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.792, tt:6019.023\n",
      "Ep:173, loss:0.00000, loss_test:0.02047, lr:2.11e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.776, tt:6051.045\n",
      "Ep:174, loss:0.00000, loss_test:0.02053, lr:2.09e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.774, tt:6085.404\n",
      "Ep:175, loss:0.00000, loss_test:0.02057, lr:2.07e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.764, tt:6118.548\n",
      "Ep:176, loss:0.00000, loss_test:0.02061, lr:2.05e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.765, tt:6153.442\n",
      "Ep:177, loss:0.00000, loss_test:0.02062, lr:2.03e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.765, tt:6188.199\n",
      "Ep:178, loss:0.00000, loss_test:0.02065, lr:2.01e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.757, tt:6221.505\n",
      "Ep:179, loss:0.00000, loss_test:0.02068, lr:1.99e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.761, tt:6256.926\n",
      "Ep:180, loss:0.00000, loss_test:0.02070, lr:1.97e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.769, tt:6293.193\n",
      "Ep:181, loss:0.00000, loss_test:0.02070, lr:1.95e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.766, tt:6327.478\n",
      "Ep:182, loss:0.00000, loss_test:0.02073, lr:1.93e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.772, tt:6363.221\n",
      "Ep:183, loss:0.00000, loss_test:0.02077, lr:1.91e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.770, tt:6397.612\n",
      "Ep:184, loss:0.00000, loss_test:0.02079, lr:1.89e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.764, tt:6431.271\n",
      "Ep:185, loss:0.00000, loss_test:0.02082, lr:1.87e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.759, tt:6465.161\n",
      "Ep:186, loss:0.00000, loss_test:0.02083, lr:1.85e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.759, tt:6499.949\n",
      "Ep:187, loss:0.00000, loss_test:0.02085, lr:1.83e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.766, tt:6536.015\n",
      "Ep:188, loss:0.00000, loss_test:0.02088, lr:1.81e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.748, tt:6567.427\n",
      "Ep:189, loss:0.00000, loss_test:0.02091, lr:1.80e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.738, tt:6600.298\n",
      "Ep:190, loss:0.00000, loss_test:0.02092, lr:1.78e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.746, tt:6636.548\n",
      "Ep:191, loss:0.00000, loss_test:0.02093, lr:1.76e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.763, tt:6674.582\n",
      "Ep:192, loss:0.00000, loss_test:0.02094, lr:1.74e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.761, tt:6708.777\n",
      "Ep:193, loss:0.00000, loss_test:0.02095, lr:1.73e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.760, tt:6743.446\n",
      "Ep:194, loss:0.00000, loss_test:0.02099, lr:1.71e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.741, tt:6774.425\n",
      "Ep:195, loss:0.00000, loss_test:0.02100, lr:1.69e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.727, tt:6806.516\n",
      "Ep:196, loss:0.00000, loss_test:0.02104, lr:1.67e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.732, tt:6842.122\n",
      "Ep:197, loss:0.00000, loss_test:0.02104, lr:1.66e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.732, tt:6876.890\n",
      "Ep:198, loss:0.00000, loss_test:0.02106, lr:1.64e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.733, tt:6911.808\n",
      "Ep:199, loss:0.00000, loss_test:0.02109, lr:1.62e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.737, tt:6947.463\n",
      "Ep:200, loss:0.00000, loss_test:0.02110, lr:1.61e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.734, tt:6981.485\n",
      "Ep:201, loss:0.00000, loss_test:0.02112, lr:1.59e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.740, tt:7017.578\n",
      "Ep:202, loss:0.00000, loss_test:0.02115, lr:1.58e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.740, tt:7052.260\n",
      "Ep:203, loss:0.00000, loss_test:0.02116, lr:1.56e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.746, tt:7088.159\n",
      "Ep:204, loss:0.00000, loss_test:0.02119, lr:1.54e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.754, tt:7124.618\n",
      "Ep:205, loss:0.00000, loss_test:0.02120, lr:1.53e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.756, tt:7159.661\n",
      "Ep:206, loss:0.00000, loss_test:0.02123, lr:1.51e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.752, tt:7193.760\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.03415, lr:1.00e-02, fs:0.49143 (r=0.434,p=0.566),  time:25.423, tt:25.423\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02549, lr:1.00e-02, fs:0.58515 (r=0.677,p=0.515),  time:24.822, tt:49.643\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02283, lr:1.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:24.131, tt:72.393\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02273, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:23.921, tt:95.683\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02319, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:25.120, tt:125.600\n",
      "Ep:5, loss:0.00004, loss_test:0.02352, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:27.063, tt:162.379\n",
      "Ep:6, loss:0.00004, loss_test:0.02356, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:28.357, tt:198.496\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02333, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.052, tt:232.417\n",
      "Ep:8, loss:0.00004, loss_test:0.02291, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.617, tt:266.553\n",
      "Ep:9, loss:0.00004, loss_test:0.02239, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:30.264, tt:302.642\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02190, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:30.770, tt:338.467\n",
      "Ep:11, loss:0.00004, loss_test:0.02144, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:31.138, tt:373.650\n",
      "Ep:12, loss:0.00004, loss_test:0.02107, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:31.408, tt:408.305\n",
      "Ep:13, loss:0.00004, loss_test:0.02078, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:31.588, tt:442.226\n",
      "Ep:14, loss:0.00004, loss_test:0.02054, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:31.789, tt:476.837\n",
      "Ep:15, loss:0.00004, loss_test:0.02034, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:31.943, tt:511.094\n",
      "Ep:16, loss:0.00004, loss_test:0.02011, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:32.140, tt:546.377\n",
      "Ep:17, loss:0.00004, loss_test:0.01988, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:32.360, tt:582.475\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01963, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:32.519, tt:617.868\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01939, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:32.662, tt:653.234\n",
      "Ep:20, loss:0.00004, loss_test:0.01921, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:32.816, tt:689.131\n",
      "Ep:21, loss:0.00004, loss_test:0.01908, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:32.952, tt:724.947\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01897, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:33.025, tt:759.568\n",
      "Ep:23, loss:0.00004, loss_test:0.01886, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:33.137, tt:795.291\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01876, lr:1.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:33.274, tt:831.844\n",
      "Ep:25, loss:0.00003, loss_test:0.01867, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:33.408, tt:868.600\n",
      "Ep:26, loss:0.00003, loss_test:0.01857, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:33.498, tt:904.446\n",
      "Ep:27, loss:0.00003, loss_test:0.01847, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:33.613, tt:941.161\n",
      "Ep:28, loss:0.00003, loss_test:0.01836, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:33.681, tt:976.757\n",
      "Ep:29, loss:0.00003, loss_test:0.01824, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:33.705, tt:1011.164\n",
      "Ep:30, loss:0.00003, loss_test:0.01813, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:33.709, tt:1044.983\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01801, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:33.716, tt:1078.902\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01791, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:33.739, tt:1113.384\n",
      "Ep:33, loss:0.00003, loss_test:0.01782, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:33.767, tt:1148.074\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01774, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:33.806, tt:1183.193\n",
      "Ep:35, loss:0.00003, loss_test:0.01768, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:33.806, tt:1217.032\n",
      "Ep:36, loss:0.00003, loss_test:0.01762, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:33.826, tt:1251.558\n",
      "Ep:37, loss:0.00003, loss_test:0.01756, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:33.820, tt:1285.148\n",
      "Ep:38, loss:0.00003, loss_test:0.01748, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:33.868, tt:1320.844\n",
      "Ep:39, loss:0.00003, loss_test:0.01741, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:33.882, tt:1355.269\n",
      "Ep:40, loss:0.00003, loss_test:0.01733, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:33.912, tt:1390.396\n",
      "Ep:41, loss:0.00003, loss_test:0.01725, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:33.919, tt:1424.612\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01717, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:33.958, tt:1460.173\n",
      "Ep:43, loss:0.00003, loss_test:0.01711, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:33.999, tt:1495.941\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01707, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:34.012, tt:1530.558\n",
      "Ep:45, loss:0.00003, loss_test:0.01702, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:34.008, tt:1564.368\n",
      "Ep:46, loss:0.00003, loss_test:0.01699, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:33.999, tt:1597.951\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01695, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:34.022, tt:1633.066\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01690, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:34.051, tt:1668.481\n",
      "Ep:49, loss:0.00003, loss_test:0.01685, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:34.071, tt:1703.533\n",
      "Ep:50, loss:0.00003, loss_test:0.01680, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:34.069, tt:1737.517\n",
      "Ep:51, loss:0.00003, loss_test:0.01676, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:34.087, tt:1772.540\n",
      "Ep:52, loss:0.00003, loss_test:0.01671, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:34.105, tt:1807.588\n",
      "Ep:53, loss:0.00003, loss_test:0.01667, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:34.137, tt:1843.387\n",
      "Ep:54, loss:0.00003, loss_test:0.01663, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:34.129, tt:1877.082\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.01659, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:34.141, tt:1911.922\n",
      "Ep:56, loss:0.00003, loss_test:0.01654, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:34.150, tt:1946.577\n",
      "Ep:57, loss:0.00003, loss_test:0.01650, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:34.153, tt:1980.860\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01645, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:34.141, tt:2014.314\n",
      "Ep:59, loss:0.00003, loss_test:0.01641, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:34.136, tt:2048.180\n",
      "Ep:60, loss:0.00003, loss_test:0.01637, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.146, tt:2082.912\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.01635, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.120, tt:2115.445\n",
      "Ep:62, loss:0.00003, loss_test:0.01633, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.122, tt:2149.701\n",
      "Ep:63, loss:0.00003, loss_test:0.01629, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:34.104, tt:2182.657\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.01625, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:34.095, tt:2216.160\n",
      "Ep:65, loss:0.00002, loss_test:0.01621, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:34.093, tt:2250.121\n",
      "Ep:66, loss:0.00002, loss_test:0.01618, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:34.108, tt:2285.240\n",
      "Ep:67, loss:0.00002, loss_test:0.01617, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:34.116, tt:2319.868\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01615, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:34.117, tt:2354.064\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.01612, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:34.122, tt:2388.524\n",
      "Ep:70, loss:0.00002, loss_test:0.01609, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:34.136, tt:2423.633\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.01608, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:34.160, tt:2459.497\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.01606, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:34.191, tt:2495.924\n",
      "Ep:73, loss:0.00002, loss_test:0.01604, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:34.215, tt:2531.922\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01601, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:34.214, tt:2566.078\n",
      "Ep:75, loss:0.00002, loss_test:0.01601, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:34.227, tt:2601.217\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.01599, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:34.245, tt:2636.895\n",
      "Ep:77, loss:0.00002, loss_test:0.01597, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:34.248, tt:2671.333\n",
      "Ep:78, loss:0.00002, loss_test:0.01595, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:34.279, tt:2708.080\n",
      "Ep:79, loss:0.00002, loss_test:0.01593, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:34.290, tt:2743.226\n",
      "Ep:80, loss:0.00002, loss_test:0.01591, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:34.314, tt:2779.433\n",
      "Ep:81, loss:0.00002, loss_test:0.01589, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:34.328, tt:2814.933\n",
      "Ep:82, loss:0.00002, loss_test:0.01589, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:34.338, tt:2850.064\n",
      "Ep:83, loss:0.00002, loss_test:0.01589, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:34.352, tt:2885.579\n",
      "Ep:84, loss:0.00002, loss_test:0.01589, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:34.373, tt:2921.689\n",
      "Ep:85, loss:0.00002, loss_test:0.01586, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:34.395, tt:2957.931\n",
      "Ep:86, loss:0.00002, loss_test:0.01585, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:34.396, tt:2992.467\n",
      "Ep:87, loss:0.00002, loss_test:0.01585, lr:9.90e-03, fs:0.74286 (r=0.788,p=0.703),  time:34.412, tt:3028.269\n",
      "Ep:88, loss:0.00002, loss_test:0.01584, lr:9.80e-03, fs:0.74641 (r=0.788,p=0.709),  time:34.416, tt:3063.023\n",
      "Ep:89, loss:0.00002, loss_test:0.01583, lr:9.70e-03, fs:0.74641 (r=0.788,p=0.709),  time:34.440, tt:3099.570\n",
      "Ep:90, loss:0.00002, loss_test:0.01582, lr:9.61e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.472, tt:3136.929\n",
      "Ep:91, loss:0.00002, loss_test:0.01580, lr:9.51e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.487, tt:3172.767\n",
      "Ep:92, loss:0.00002, loss_test:0.01579, lr:9.41e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.508, tt:3209.278\n",
      "Ep:93, loss:0.00002, loss_test:0.01579, lr:9.32e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.510, tt:3243.900\n",
      "Ep:94, loss:0.00002, loss_test:0.01576, lr:9.23e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.529, tt:3280.239\n",
      "Ep:95, loss:0.00002, loss_test:0.01574, lr:9.14e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.542, tt:3315.990\n",
      "Ep:96, loss:0.00002, loss_test:0.01573, lr:9.04e-03, fs:0.75000 (r=0.788,p=0.716),  time:34.542, tt:3350.545\n",
      "Ep:97, loss:0.00002, loss_test:0.01573, lr:8.95e-03, fs:0.74396 (r=0.778,p=0.713),  time:34.548, tt:3385.702\n",
      "Ep:98, loss:0.00002, loss_test:0.01573, lr:8.86e-03, fs:0.74396 (r=0.778,p=0.713),  time:34.564, tt:3421.874\n",
      "Ep:99, loss:0.00002, loss_test:0.01572, lr:8.78e-03, fs:0.74757 (r=0.778,p=0.720),  time:34.573, tt:3457.251\n",
      "Ep:100, loss:0.00002, loss_test:0.01572, lr:8.69e-03, fs:0.74757 (r=0.778,p=0.720),  time:34.582, tt:3492.743\n",
      "Ep:101, loss:0.00002, loss_test:0.01572, lr:8.60e-03, fs:0.74757 (r=0.778,p=0.720),  time:34.595, tt:3528.662\n",
      "Ep:102, loss:0.00002, loss_test:0.01572, lr:8.51e-03, fs:0.75362 (r=0.788,p=0.722),  time:34.595, tt:3563.258\n",
      "Ep:103, loss:0.00002, loss_test:0.01572, lr:8.43e-03, fs:0.74146 (r=0.768,p=0.717),  time:34.599, tt:3598.270\n",
      "Ep:104, loss:0.00002, loss_test:0.01572, lr:8.35e-03, fs:0.74877 (r=0.768,p=0.731),  time:34.609, tt:3633.916\n",
      "Ep:105, loss:0.00002, loss_test:0.01572, lr:8.26e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.608, tt:3668.483\n",
      "Ep:106, loss:0.00002, loss_test:0.01571, lr:8.18e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.613, tt:3703.593\n",
      "Ep:107, loss:0.00002, loss_test:0.01570, lr:8.10e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.619, tt:3738.868\n",
      "Ep:108, loss:0.00002, loss_test:0.01570, lr:8.02e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.630, tt:3774.703\n",
      "Ep:109, loss:0.00002, loss_test:0.01569, lr:7.94e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.629, tt:3809.236\n",
      "Ep:110, loss:0.00002, loss_test:0.01569, lr:7.86e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.629, tt:3843.772\n",
      "Ep:111, loss:0.00002, loss_test:0.01568, lr:7.78e-03, fs:0.75490 (r=0.778,p=0.733),  time:34.625, tt:3877.971\n",
      "Ep:112, loss:0.00002, loss_test:0.01568, lr:7.70e-03, fs:0.75862 (r=0.778,p=0.740),  time:34.624, tt:3912.538\n",
      "Ep:113, loss:0.00002, loss_test:0.01568, lr:7.62e-03, fs:0.75862 (r=0.778,p=0.740),  time:34.628, tt:3947.638\n",
      "Ep:114, loss:0.00002, loss_test:0.01568, lr:7.55e-03, fs:0.76238 (r=0.778,p=0.748),  time:34.643, tt:3983.891\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00002, loss_test:0.01569, lr:7.55e-03, fs:0.76238 (r=0.778,p=0.748),  time:34.667, tt:4021.344\n",
      "Ep:116, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76847 (r=0.788,p=0.750),  time:34.683, tt:4057.931\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76847 (r=0.788,p=0.750),  time:34.686, tt:4092.908\n",
      "Ep:118, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76847 (r=0.788,p=0.750),  time:34.691, tt:4128.220\n",
      "Ep:119, loss:0.00002, loss_test:0.01568, lr:7.55e-03, fs:0.76238 (r=0.778,p=0.748),  time:34.703, tt:4164.388\n",
      "Ep:120, loss:0.00002, loss_test:0.01568, lr:7.55e-03, fs:0.76238 (r=0.778,p=0.748),  time:34.706, tt:4199.433\n",
      "Ep:121, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76238 (r=0.778,p=0.748),  time:34.717, tt:4235.433\n",
      "Ep:122, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76238 (r=0.778,p=0.748),  time:34.715, tt:4269.913\n",
      "Ep:123, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76617 (r=0.778,p=0.755),  time:34.718, tt:4304.980\n",
      "Ep:124, loss:0.00002, loss_test:0.01566, lr:7.55e-03, fs:0.76617 (r=0.778,p=0.755),  time:34.732, tt:4341.443\n",
      "Ep:125, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.76617 (r=0.778,p=0.755),  time:34.733, tt:4376.302\n",
      "Ep:126, loss:0.00002, loss_test:0.01567, lr:7.55e-03, fs:0.77000 (r=0.778,p=0.762),  time:34.736, tt:4411.517\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.01568, lr:7.55e-03, fs:0.77000 (r=0.778,p=0.762),  time:34.729, tt:4445.316\n",
      "Ep:128, loss:0.00002, loss_test:0.01569, lr:7.55e-03, fs:0.77000 (r=0.778,p=0.762),  time:34.726, tt:4479.641\n",
      "Ep:129, loss:0.00002, loss_test:0.01569, lr:7.55e-03, fs:0.77000 (r=0.778,p=0.762),  time:34.729, tt:4514.832\n",
      "Ep:130, loss:0.00002, loss_test:0.01570, lr:7.55e-03, fs:0.77000 (r=0.778,p=0.762),  time:34.732, tt:4549.909\n",
      "Ep:131, loss:0.00002, loss_test:0.01572, lr:7.55e-03, fs:0.77387 (r=0.778,p=0.770),  time:34.742, tt:4585.929\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00002, loss_test:0.01573, lr:7.55e-03, fs:0.77387 (r=0.778,p=0.770),  time:34.738, tt:4620.139\n",
      "Ep:133, loss:0.00002, loss_test:0.01573, lr:7.55e-03, fs:0.77387 (r=0.778,p=0.770),  time:34.744, tt:4655.714\n",
      "Ep:134, loss:0.00002, loss_test:0.01574, lr:7.55e-03, fs:0.77387 (r=0.778,p=0.770),  time:34.743, tt:4690.307\n",
      "Ep:135, loss:0.00002, loss_test:0.01575, lr:7.55e-03, fs:0.76768 (r=0.768,p=0.768),  time:34.743, tt:4725.001\n",
      "Ep:136, loss:0.00002, loss_test:0.01575, lr:7.55e-03, fs:0.76768 (r=0.768,p=0.768),  time:34.734, tt:4758.603\n",
      "Ep:137, loss:0.00002, loss_test:0.01577, lr:7.55e-03, fs:0.76142 (r=0.758,p=0.765),  time:34.742, tt:4794.430\n",
      "Ep:138, loss:0.00002, loss_test:0.01577, lr:7.55e-03, fs:0.76142 (r=0.758,p=0.765),  time:34.749, tt:4830.065\n",
      "Ep:139, loss:0.00002, loss_test:0.01576, lr:7.55e-03, fs:0.77157 (r=0.768,p=0.776),  time:34.751, tt:4865.076\n",
      "Ep:140, loss:0.00002, loss_test:0.01576, lr:7.55e-03, fs:0.77157 (r=0.768,p=0.776),  time:34.760, tt:4901.227\n",
      "Ep:141, loss:0.00002, loss_test:0.01576, lr:7.55e-03, fs:0.77157 (r=0.768,p=0.776),  time:34.751, tt:4934.571\n",
      "Ep:142, loss:0.00002, loss_test:0.01577, lr:7.55e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.755, tt:4969.918\n",
      "Ep:143, loss:0.00002, loss_test:0.01578, lr:7.47e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.751, tt:5004.129\n",
      "Ep:144, loss:0.00002, loss_test:0.01579, lr:7.40e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.753, tt:5039.168\n",
      "Ep:145, loss:0.00002, loss_test:0.01580, lr:7.32e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.759, tt:5074.840\n",
      "Ep:146, loss:0.00001, loss_test:0.01579, lr:7.25e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.759, tt:5109.620\n",
      "Ep:147, loss:0.00001, loss_test:0.01580, lr:7.18e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.762, tt:5144.795\n",
      "Ep:148, loss:0.00001, loss_test:0.01582, lr:7.11e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.772, tt:5181.024\n",
      "Ep:149, loss:0.00001, loss_test:0.01583, lr:7.03e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.767, tt:5215.003\n",
      "Ep:150, loss:0.00001, loss_test:0.01583, lr:6.96e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.766, tt:5249.622\n",
      "Ep:151, loss:0.00001, loss_test:0.01583, lr:6.89e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.763, tt:5283.917\n",
      "Ep:152, loss:0.00001, loss_test:0.01583, lr:6.83e-03, fs:0.76531 (r=0.758,p=0.773),  time:34.769, tt:5319.601\n",
      "Ep:153, loss:0.00001, loss_test:0.01584, lr:6.76e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.764, tt:5353.701\n",
      "Ep:154, loss:0.00001, loss_test:0.01583, lr:6.69e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.763, tt:5388.266\n",
      "Ep:155, loss:0.00001, loss_test:0.01583, lr:6.62e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.762, tt:5422.865\n",
      "Ep:156, loss:0.00001, loss_test:0.01584, lr:6.56e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.767, tt:5458.373\n",
      "Ep:157, loss:0.00001, loss_test:0.01586, lr:6.49e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.771, tt:5493.794\n",
      "Ep:158, loss:0.00001, loss_test:0.01587, lr:6.43e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.773, tt:5528.845\n",
      "Ep:159, loss:0.00001, loss_test:0.01587, lr:6.36e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.777, tt:5564.324\n",
      "Ep:160, loss:0.00001, loss_test:0.01586, lr:6.30e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.781, tt:5599.732\n",
      "Ep:161, loss:0.00001, loss_test:0.01586, lr:6.24e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.794, tt:5636.650\n",
      "Ep:162, loss:0.00001, loss_test:0.01587, lr:6.17e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.803, tt:5672.860\n",
      "Ep:163, loss:0.00001, loss_test:0.01587, lr:6.11e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.823, tt:5711.023\n",
      "Ep:164, loss:0.00001, loss_test:0.01587, lr:6.05e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.822, tt:5745.706\n",
      "Ep:165, loss:0.00001, loss_test:0.01587, lr:5.99e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.824, tt:5780.853\n",
      "Ep:166, loss:0.00001, loss_test:0.01586, lr:5.93e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.824, tt:5815.663\n",
      "Ep:167, loss:0.00001, loss_test:0.01587, lr:5.87e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.828, tt:5851.061\n",
      "Ep:168, loss:0.00001, loss_test:0.01588, lr:5.81e-03, fs:0.77320 (r=0.758,p=0.789),  time:34.830, tt:5886.231\n",
      "Ep:169, loss:0.00001, loss_test:0.01588, lr:5.75e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.827, tt:5920.515\n",
      "Ep:170, loss:0.00001, loss_test:0.01589, lr:5.70e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.830, tt:5955.883\n",
      "Ep:171, loss:0.00001, loss_test:0.01590, lr:5.64e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.833, tt:5991.330\n",
      "Ep:172, loss:0.00001, loss_test:0.01591, lr:5.58e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.831, tt:6025.786\n",
      "Ep:173, loss:0.00001, loss_test:0.01591, lr:5.53e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.826, tt:6059.767\n",
      "Ep:174, loss:0.00001, loss_test:0.01591, lr:5.47e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.827, tt:6094.733\n",
      "Ep:175, loss:0.00001, loss_test:0.01592, lr:5.42e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.831, tt:6130.277\n",
      "Ep:176, loss:0.00001, loss_test:0.01592, lr:5.36e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.828, tt:6164.524\n",
      "Ep:177, loss:0.00001, loss_test:0.01593, lr:5.31e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.833, tt:6200.340\n",
      "Ep:178, loss:0.00001, loss_test:0.01592, lr:5.26e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.840, tt:6236.351\n",
      "Ep:179, loss:0.00001, loss_test:0.01593, lr:5.20e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.841, tt:6271.387\n",
      "Ep:180, loss:0.00001, loss_test:0.01593, lr:5.15e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.839, tt:6305.853\n",
      "Ep:181, loss:0.00001, loss_test:0.01593, lr:5.10e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.845, tt:6341.880\n",
      "Ep:182, loss:0.00001, loss_test:0.01594, lr:5.05e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.859, tt:6379.163\n",
      "Ep:183, loss:0.00001, loss_test:0.01595, lr:5.00e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.859, tt:6413.969\n",
      "Ep:184, loss:0.00001, loss_test:0.01594, lr:4.95e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.868, tt:6450.548\n",
      "Ep:185, loss:0.00001, loss_test:0.01595, lr:4.90e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.867, tt:6485.171\n",
      "Ep:186, loss:0.00001, loss_test:0.01596, lr:4.85e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.862, tt:6519.231\n",
      "Ep:187, loss:0.00001, loss_test:0.01597, lr:4.80e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.874, tt:6556.394\n",
      "Ep:188, loss:0.00001, loss_test:0.01597, lr:4.75e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.880, tt:6592.361\n",
      "Ep:189, loss:0.00001, loss_test:0.01597, lr:4.71e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.880, tt:6627.109\n",
      "Ep:190, loss:0.00001, loss_test:0.01597, lr:4.66e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.883, tt:6662.579\n",
      "Ep:191, loss:0.00001, loss_test:0.01597, lr:4.61e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.881, tt:6697.146\n",
      "Ep:192, loss:0.00001, loss_test:0.01598, lr:4.57e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.888, tt:6733.443\n",
      "Ep:193, loss:0.00001, loss_test:0.01599, lr:4.52e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.896, tt:6769.829\n",
      "Ep:194, loss:0.00001, loss_test:0.01599, lr:4.48e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.895, tt:6804.620\n",
      "Ep:195, loss:0.00001, loss_test:0.01600, lr:4.43e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.898, tt:6840.095\n",
      "Ep:196, loss:0.00001, loss_test:0.01600, lr:4.39e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.898, tt:6874.926\n",
      "Ep:197, loss:0.00001, loss_test:0.01600, lr:4.34e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.902, tt:6910.516\n",
      "Ep:198, loss:0.00001, loss_test:0.01600, lr:4.30e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.898, tt:6944.701\n",
      "Ep:199, loss:0.00001, loss_test:0.01600, lr:4.26e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.899, tt:6979.752\n",
      "Ep:200, loss:0.00001, loss_test:0.01600, lr:4.21e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.907, tt:7016.401\n",
      "Ep:201, loss:0.00001, loss_test:0.01601, lr:4.17e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.913, tt:7052.365\n",
      "Ep:202, loss:0.00001, loss_test:0.01602, lr:4.13e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.919, tt:7088.602\n",
      "Ep:203, loss:0.00001, loss_test:0.01603, lr:4.09e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.923, tt:7124.321\n",
      "Ep:204, loss:0.00001, loss_test:0.01603, lr:4.05e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.929, tt:7160.409\n",
      "Ep:205, loss:0.00001, loss_test:0.01604, lr:4.01e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.932, tt:7195.977\n",
      "Ep:206, loss:0.00001, loss_test:0.01604, lr:3.97e-03, fs:0.76923 (r=0.758,p=0.781),  time:34.932, tt:7230.972\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02723, lr:1.00e-02, fs:0.51977 (r=0.465,p=0.590),  time:30.880, tt:30.880\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02291, lr:1.00e-02, fs:0.60550 (r=0.667,p=0.555),  time:31.589, tt:63.178\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02116, lr:1.00e-02, fs:0.62500 (r=0.808,p=0.510),  time:30.917, tt:92.752\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02101, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:31.664, tt:126.656\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02131, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:33.214, tt:166.071\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02154, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:34.004, tt:204.026\n",
      "Ep:6, loss:0.00004, loss_test:0.02156, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:34.622, tt:242.354\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02137, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.635, tt:285.078\n",
      "Ep:8, loss:0.00004, loss_test:0.02104, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:36.006, tt:324.057\n",
      "Ep:9, loss:0.00004, loss_test:0.02064, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:36.288, tt:362.875\n",
      "Ep:10, loss:0.00004, loss_test:0.02022, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:36.418, tt:400.599\n",
      "Ep:11, loss:0.00004, loss_test:0.01983, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:36.535, tt:438.423\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01951, lr:1.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:36.785, tt:478.207\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01926, lr:1.00e-02, fs:0.68148 (r=0.929,p=0.538),  time:36.957, tt:517.397\n",
      "Ep:14, loss:0.00004, loss_test:0.01907, lr:1.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:37.162, tt:557.436\n",
      "Ep:15, loss:0.00004, loss_test:0.01893, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:37.344, tt:597.507\n",
      "Ep:16, loss:0.00003, loss_test:0.01882, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:37.334, tt:634.675\n",
      "Ep:17, loss:0.00003, loss_test:0.01869, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:37.520, tt:675.366\n",
      "Ep:18, loss:0.00003, loss_test:0.01856, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:37.610, tt:714.596\n",
      "Ep:19, loss:0.00003, loss_test:0.01843, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:37.703, tt:754.059\n",
      "Ep:20, loss:0.00003, loss_test:0.01830, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:37.838, tt:794.598\n",
      "Ep:21, loss:0.00003, loss_test:0.01820, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:37.860, tt:832.914\n",
      "Ep:22, loss:0.00003, loss_test:0.01812, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:37.851, tt:870.580\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01804, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:37.925, tt:910.195\n",
      "Ep:24, loss:0.00003, loss_test:0.01796, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:37.904, tt:947.594\n",
      "Ep:25, loss:0.00003, loss_test:0.01789, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:37.935, tt:986.313\n",
      "Ep:26, loss:0.00003, loss_test:0.01781, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:37.977, tt:1025.380\n",
      "Ep:27, loss:0.00003, loss_test:0.01774, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:38.031, tt:1064.872\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01767, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:38.084, tt:1104.430\n",
      "Ep:29, loss:0.00003, loss_test:0.01761, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:38.107, tt:1143.197\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01755, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:38.161, tt:1182.985\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01750, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:38.126, tt:1220.034\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01744, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.146, tt:1258.816\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01738, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.120, tt:1296.076\n",
      "Ep:34, loss:0.00003, loss_test:0.01733, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.105, tt:1333.688\n",
      "Ep:35, loss:0.00003, loss_test:0.01727, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.181, tt:1374.524\n",
      "Ep:36, loss:0.00003, loss_test:0.01721, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.142, tt:1411.256\n",
      "Ep:37, loss:0.00003, loss_test:0.01716, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:38.127, tt:1448.837\n",
      "Ep:38, loss:0.00003, loss_test:0.01711, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:38.129, tt:1487.016\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01705, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:38.151, tt:1526.022\n",
      "Ep:40, loss:0.00003, loss_test:0.01700, lr:1.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:38.198, tt:1566.110\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01695, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:38.213, tt:1604.934\n",
      "Ep:42, loss:0.00003, loss_test:0.01690, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:38.243, tt:1644.444\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01686, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:38.167, tt:1679.359\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01681, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:38.151, tt:1716.775\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01677, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:38.130, tt:1753.980\n",
      "Ep:46, loss:0.00003, loss_test:0.01673, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:38.143, tt:1792.727\n",
      "Ep:47, loss:0.00003, loss_test:0.01669, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:38.133, tt:1830.390\n",
      "Ep:48, loss:0.00003, loss_test:0.01665, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:38.112, tt:1867.477\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01660, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:38.133, tt:1906.640\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01656, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:38.131, tt:1944.677\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00003, loss_test:0.01653, lr:1.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:38.092, tt:1980.771\n",
      "Ep:52, loss:0.00003, loss_test:0.01650, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:38.067, tt:2017.553\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01647, lr:1.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:38.024, tt:2053.308\n",
      "Ep:54, loss:0.00003, loss_test:0.01643, lr:1.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:38.065, tt:2093.568\n",
      "Ep:55, loss:0.00003, loss_test:0.01640, lr:1.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:38.042, tt:2130.356\n",
      "Ep:56, loss:0.00003, loss_test:0.01637, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:38.053, tt:2169.019\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01634, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:38.057, tt:2207.287\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01631, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:38.068, tt:2245.994\n",
      "Ep:59, loss:0.00003, loss_test:0.01628, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:38.096, tt:2285.753\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.01626, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:38.138, tt:2326.428\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.01623, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:38.142, tt:2364.782\n",
      "Ep:62, loss:0.00002, loss_test:0.01621, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:38.150, tt:2403.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00002, loss_test:0.01618, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:38.143, tt:2441.161\n",
      "Ep:64, loss:0.00002, loss_test:0.01616, lr:1.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:38.176, tt:2481.472\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01614, lr:1.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:38.186, tt:2520.262\n",
      "Ep:66, loss:0.00002, loss_test:0.01612, lr:1.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:38.176, tt:2557.821\n",
      "Ep:67, loss:0.00002, loss_test:0.01609, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:38.263, tt:2601.860\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01607, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:38.277, tt:2641.134\n",
      "Ep:69, loss:0.00002, loss_test:0.01604, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:38.280, tt:2679.577\n",
      "Ep:70, loss:0.00002, loss_test:0.01602, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:38.310, tt:2720.015\n",
      "Ep:71, loss:0.00002, loss_test:0.01599, lr:1.00e-02, fs:0.75000 (r=0.848,p=0.672),  time:38.331, tt:2759.823\n",
      "Ep:72, loss:0.00002, loss_test:0.01597, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:38.350, tt:2799.573\n",
      "Ep:73, loss:0.00002, loss_test:0.01594, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:38.369, tt:2839.340\n",
      "Ep:74, loss:0.00002, loss_test:0.01592, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:38.381, tt:2878.593\n",
      "Ep:75, loss:0.00002, loss_test:0.01590, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:38.389, tt:2917.560\n",
      "Ep:76, loss:0.00002, loss_test:0.01588, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:38.388, tt:2955.903\n",
      "Ep:77, loss:0.00002, loss_test:0.01585, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:38.388, tt:2994.258\n",
      "Ep:78, loss:0.00002, loss_test:0.01583, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:38.422, tt:3035.369\n",
      "Ep:79, loss:0.00002, loss_test:0.01581, lr:9.90e-03, fs:0.75455 (r=0.838,p=0.686),  time:38.438, tt:3075.063\n",
      "Ep:80, loss:0.00002, loss_test:0.01579, lr:9.80e-03, fs:0.75455 (r=0.838,p=0.686),  time:38.443, tt:3113.906\n",
      "Ep:81, loss:0.00002, loss_test:0.01577, lr:9.70e-03, fs:0.75455 (r=0.838,p=0.686),  time:38.463, tt:3153.980\n",
      "Ep:82, loss:0.00002, loss_test:0.01575, lr:9.61e-03, fs:0.75229 (r=0.828,p=0.689),  time:38.498, tt:3195.376\n",
      "Ep:83, loss:0.00002, loss_test:0.01574, lr:9.51e-03, fs:0.74654 (r=0.818,p=0.686),  time:38.501, tt:3234.090\n",
      "Ep:84, loss:0.00002, loss_test:0.01573, lr:9.41e-03, fs:0.74654 (r=0.818,p=0.686),  time:38.530, tt:3275.033\n",
      "Ep:85, loss:0.00002, loss_test:0.01571, lr:9.32e-03, fs:0.74654 (r=0.818,p=0.686),  time:38.543, tt:3314.700\n",
      "Ep:86, loss:0.00002, loss_test:0.01570, lr:9.23e-03, fs:0.74654 (r=0.818,p=0.686),  time:38.560, tt:3354.715\n",
      "Ep:87, loss:0.00002, loss_test:0.01569, lr:9.14e-03, fs:0.75349 (r=0.818,p=0.698),  time:38.566, tt:3393.766\n",
      "Ep:88, loss:0.00002, loss_test:0.01568, lr:9.04e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.568, tt:3432.585\n",
      "Ep:89, loss:0.00002, loss_test:0.01567, lr:8.95e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.592, tt:3473.284\n",
      "Ep:90, loss:0.00002, loss_test:0.01566, lr:8.86e-03, fs:0.75349 (r=0.818,p=0.698),  time:38.611, tt:3513.615\n",
      "Ep:91, loss:0.00002, loss_test:0.01565, lr:8.78e-03, fs:0.75349 (r=0.818,p=0.698),  time:38.622, tt:3553.212\n",
      "Ep:92, loss:0.00002, loss_test:0.01564, lr:8.69e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.620, tt:3591.660\n",
      "Ep:93, loss:0.00002, loss_test:0.01562, lr:8.60e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.624, tt:3630.699\n",
      "Ep:94, loss:0.00002, loss_test:0.01561, lr:8.51e-03, fs:0.75349 (r=0.818,p=0.698),  time:38.637, tt:3670.470\n",
      "Ep:95, loss:0.00002, loss_test:0.01561, lr:8.43e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.641, tt:3709.499\n",
      "Ep:96, loss:0.00002, loss_test:0.01559, lr:8.35e-03, fs:0.75701 (r=0.818,p=0.704),  time:38.640, tt:3748.074\n",
      "Ep:97, loss:0.00002, loss_test:0.01559, lr:8.26e-03, fs:0.75117 (r=0.808,p=0.702),  time:38.687, tt:3791.307\n",
      "Ep:98, loss:0.00002, loss_test:0.01558, lr:8.18e-03, fs:0.75829 (r=0.808,p=0.714),  time:38.687, tt:3830.026\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00002, loss_test:0.01557, lr:8.18e-03, fs:0.75829 (r=0.808,p=0.714),  time:38.691, tt:3869.050\n",
      "Ep:100, loss:0.00002, loss_test:0.01556, lr:8.18e-03, fs:0.75238 (r=0.798,p=0.712),  time:38.699, tt:3908.557\n",
      "Ep:101, loss:0.00002, loss_test:0.01555, lr:8.18e-03, fs:0.75238 (r=0.798,p=0.712),  time:38.690, tt:3946.376\n",
      "Ep:102, loss:0.00002, loss_test:0.01555, lr:8.18e-03, fs:0.75598 (r=0.798,p=0.718),  time:38.706, tt:3986.680\n",
      "Ep:103, loss:0.00002, loss_test:0.01554, lr:8.18e-03, fs:0.75598 (r=0.798,p=0.718),  time:38.690, tt:4023.801\n",
      "Ep:104, loss:0.00002, loss_test:0.01553, lr:8.18e-03, fs:0.75598 (r=0.798,p=0.718),  time:38.678, tt:4061.147\n",
      "Ep:105, loss:0.00002, loss_test:0.01553, lr:8.18e-03, fs:0.75598 (r=0.798,p=0.718),  time:38.690, tt:4101.098\n",
      "Ep:106, loss:0.00002, loss_test:0.01552, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.697, tt:4140.548\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01552, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.694, tt:4178.940\n",
      "Ep:108, loss:0.00002, loss_test:0.01551, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.696, tt:4217.810\n",
      "Ep:109, loss:0.00002, loss_test:0.01551, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.699, tt:4256.901\n",
      "Ep:110, loss:0.00002, loss_test:0.01550, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.708, tt:4296.540\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00002, loss_test:0.01550, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.719, tt:4336.511\n",
      "Ep:112, loss:0.00002, loss_test:0.01549, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.714, tt:4374.663\n",
      "Ep:113, loss:0.00002, loss_test:0.01548, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.724, tt:4414.518\n",
      "Ep:114, loss:0.00002, loss_test:0.01547, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.730, tt:4453.924\n",
      "Ep:115, loss:0.00002, loss_test:0.01547, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.717, tt:4491.218\n",
      "Ep:116, loss:0.00002, loss_test:0.01546, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.719, tt:4530.153\n",
      "Ep:117, loss:0.00002, loss_test:0.01545, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.722, tt:4569.251\n",
      "Ep:118, loss:0.00002, loss_test:0.01545, lr:8.18e-03, fs:0.75962 (r=0.798,p=0.725),  time:38.720, tt:4607.647\n",
      "Ep:119, loss:0.00002, loss_test:0.01544, lr:8.18e-03, fs:0.76329 (r=0.798,p=0.731),  time:38.724, tt:4646.842\n",
      "Ep:120, loss:0.00002, loss_test:0.01543, lr:8.18e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.720, tt:4685.153\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00002, loss_test:0.01542, lr:8.18e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.720, tt:4723.853\n",
      "Ep:122, loss:0.00002, loss_test:0.01542, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.702, tt:4760.332\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00002, loss_test:0.01542, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.715, tt:4800.680\n",
      "Ep:124, loss:0.00002, loss_test:0.01542, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.725, tt:4840.662\n",
      "Ep:125, loss:0.00002, loss_test:0.01542, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.733, tt:4880.397\n",
      "Ep:126, loss:0.00002, loss_test:0.01541, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.742, tt:4920.272\n",
      "Ep:127, loss:0.00002, loss_test:0.01541, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.741, tt:4958.835\n",
      "Ep:128, loss:0.00002, loss_test:0.01540, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.745, tt:4998.158\n",
      "Ep:129, loss:0.00002, loss_test:0.01539, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.750, tt:5037.442\n",
      "Ep:130, loss:0.00002, loss_test:0.01539, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.747, tt:5075.845\n",
      "Ep:131, loss:0.00002, loss_test:0.01538, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.748, tt:5114.691\n",
      "Ep:132, loss:0.00002, loss_test:0.01538, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.747, tt:5153.414\n",
      "Ep:133, loss:0.00002, loss_test:0.01538, lr:8.18e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.753, tt:5192.884\n",
      "Ep:134, loss:0.00002, loss_test:0.01537, lr:8.10e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.758, tt:5232.330\n",
      "Ep:135, loss:0.00002, loss_test:0.01536, lr:8.02e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.782, tt:5274.321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00002, loss_test:0.01536, lr:7.94e-03, fs:0.77073 (r=0.798,p=0.745),  time:38.788, tt:5313.904\n",
      "Ep:137, loss:0.00002, loss_test:0.01536, lr:7.86e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.797, tt:5353.932\n",
      "Ep:138, loss:0.00002, loss_test:0.01535, lr:7.78e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.792, tt:5392.112\n",
      "Ep:139, loss:0.00002, loss_test:0.01535, lr:7.70e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.801, tt:5432.091\n",
      "Ep:140, loss:0.00002, loss_test:0.01535, lr:7.62e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.806, tt:5471.578\n",
      "Ep:141, loss:0.00002, loss_test:0.01534, lr:7.55e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.808, tt:5510.739\n",
      "Ep:142, loss:0.00002, loss_test:0.01534, lr:7.47e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.807, tt:5549.455\n",
      "Ep:143, loss:0.00002, loss_test:0.01533, lr:7.40e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.821, tt:5590.170\n",
      "Ep:144, loss:0.00002, loss_test:0.01533, lr:7.32e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.843, tt:5632.250\n",
      "Ep:145, loss:0.00002, loss_test:0.01533, lr:7.25e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.837, tt:5670.210\n",
      "Ep:146, loss:0.00002, loss_test:0.01533, lr:7.18e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.832, tt:5708.285\n",
      "Ep:147, loss:0.00002, loss_test:0.01532, lr:7.11e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.825, tt:5746.034\n",
      "Ep:148, loss:0.00002, loss_test:0.01531, lr:7.03e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.829, tt:5785.500\n",
      "Ep:149, loss:0.00002, loss_test:0.01531, lr:6.96e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.824, tt:5823.560\n",
      "Ep:150, loss:0.00002, loss_test:0.01531, lr:6.89e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.831, tt:5863.452\n",
      "Ep:151, loss:0.00002, loss_test:0.01531, lr:6.83e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.839, tt:5903.574\n",
      "Ep:152, loss:0.00002, loss_test:0.01531, lr:6.76e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.839, tt:5942.422\n",
      "Ep:153, loss:0.00002, loss_test:0.01531, lr:6.69e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.843, tt:5981.789\n",
      "Ep:154, loss:0.00002, loss_test:0.01531, lr:6.62e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.839, tt:6019.980\n",
      "Ep:155, loss:0.00002, loss_test:0.01530, lr:6.56e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.841, tt:6059.164\n",
      "Ep:156, loss:0.00002, loss_test:0.01529, lr:6.49e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.848, tt:6099.158\n",
      "Ep:157, loss:0.00002, loss_test:0.01529, lr:6.43e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.847, tt:6137.856\n",
      "Ep:158, loss:0.00002, loss_test:0.01529, lr:6.36e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.846, tt:6176.443\n",
      "Ep:159, loss:0.00002, loss_test:0.01529, lr:6.30e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.843, tt:6214.956\n",
      "Ep:160, loss:0.00002, loss_test:0.01528, lr:6.24e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.849, tt:6254.660\n",
      "Ep:161, loss:0.00002, loss_test:0.01528, lr:6.17e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.866, tt:6296.251\n",
      "Ep:162, loss:0.00002, loss_test:0.01528, lr:6.11e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.873, tt:6336.286\n",
      "Ep:163, loss:0.00002, loss_test:0.01527, lr:6.05e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.869, tt:6374.501\n",
      "Ep:164, loss:0.00002, loss_test:0.01527, lr:5.99e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.864, tt:6412.520\n",
      "Ep:165, loss:0.00002, loss_test:0.01527, lr:5.93e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.864, tt:6451.428\n",
      "Ep:166, loss:0.00002, loss_test:0.01526, lr:5.87e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.866, tt:6490.655\n",
      "Ep:167, loss:0.00002, loss_test:0.01527, lr:5.81e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.863, tt:6528.976\n",
      "Ep:168, loss:0.00002, loss_test:0.01527, lr:5.75e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.860, tt:6567.376\n",
      "Ep:169, loss:0.00002, loss_test:0.01526, lr:5.70e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.854, tt:6605.178\n",
      "Ep:170, loss:0.00002, loss_test:0.01526, lr:5.64e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.849, tt:6643.197\n",
      "Ep:171, loss:0.00002, loss_test:0.01526, lr:5.58e-03, fs:0.76699 (r=0.798,p=0.738),  time:38.847, tt:6681.644\n",
      "Ep:172, loss:0.00002, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.842, tt:6719.679\n",
      "##########Best model found so far##########\n",
      "Ep:173, loss:0.00002, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.842, tt:6758.530\n",
      "Ep:174, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.851, tt:6798.985\n",
      "Ep:175, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.862, tt:6839.662\n",
      "Ep:176, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.863, tt:6878.777\n",
      "Ep:177, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.858, tt:6916.642\n",
      "Ep:178, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.864, tt:6956.745\n",
      "Ep:179, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.856, tt:6994.031\n",
      "Ep:180, loss:0.00001, loss_test:0.01526, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.857, tt:7033.199\n",
      "Ep:181, loss:0.00001, loss_test:0.01525, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.852, tt:7071.097\n",
      "Ep:182, loss:0.00001, loss_test:0.01525, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.851, tt:7109.745\n",
      "Ep:183, loss:0.00001, loss_test:0.01525, lr:5.53e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.843, tt:7147.147\n",
      "Ep:184, loss:0.00001, loss_test:0.01525, lr:5.47e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.840, tt:7185.429\n",
      "Ep:185, loss:0.00001, loss_test:0.01525, lr:5.42e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.838, tt:7223.954\n",
      "Ep:186, loss:0.00001, loss_test:0.01525, lr:5.36e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.827, tt:7260.630\n",
      "Ep:187, loss:0.00001, loss_test:0.01525, lr:5.31e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.832, tt:7300.465\n",
      "Ep:188, loss:0.00001, loss_test:0.01525, lr:5.26e-03, fs:0.77295 (r=0.808,p=0.741),  time:38.816, tt:7336.316\n",
      "Ep:189, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.823, tt:7376.399\n",
      "##########Best model found so far##########\n",
      "Ep:190, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.821, tt:7414.825\n",
      "Ep:191, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.822, tt:7453.863\n",
      "Ep:192, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.822, tt:7492.606\n",
      "Ep:193, loss:0.00001, loss_test:0.01524, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.815, tt:7530.094\n",
      "Ep:194, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.811, tt:7568.078\n",
      "Ep:195, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.833, tt:7611.213\n",
      "Ep:196, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.832, tt:7649.935\n",
      "Ep:197, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.833, tt:7688.970\n",
      "Ep:198, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.817, tt:7724.544\n",
      "##########Best model found so far##########\n",
      "Ep:199, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.819, tt:7763.853\n",
      "Ep:200, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.821, tt:7802.984\n",
      "Ep:201, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.822, tt:7841.975\n",
      "Ep:202, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.821, tt:7880.713\n",
      "Ep:203, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.829, tt:7921.032\n",
      "Ep:204, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.822, tt:7958.483\n",
      "Ep:205, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.820, tt:7996.921\n",
      "Ep:206, loss:0.00001, loss_test:0.01525, lr:5.20e-03, fs:0.78049 (r=0.808,p=0.755),  time:38.806, tt:8032.936\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13943, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:25.741, tt:25.741\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13771, lr:1.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:28.748, tt:57.495\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13585, lr:1.00e-02, fs:0.65660 (r=0.879,p=0.524),  time:29.926, tt:89.777\n",
      "Ep:3, loss:0.00025, loss_test:0.13443, lr:1.00e-02, fs:0.62903 (r=0.788,p=0.523),  time:30.373, tt:121.492\n",
      "Ep:4, loss:0.00025, loss_test:0.13298, lr:1.00e-02, fs:0.62128 (r=0.737,p=0.537),  time:31.630, tt:158.151\n",
      "Ep:5, loss:0.00025, loss_test:0.13110, lr:1.00e-02, fs:0.61803 (r=0.727,p=0.537),  time:32.162, tt:192.969\n",
      "Ep:6, loss:0.00024, loss_test:0.12868, lr:1.00e-02, fs:0.62338 (r=0.727,p=0.545),  time:32.936, tt:230.549\n",
      "Ep:7, loss:0.00024, loss_test:0.12622, lr:1.00e-02, fs:0.62931 (r=0.737,p=0.549),  time:33.238, tt:265.901\n",
      "Ep:8, loss:0.00023, loss_test:0.12396, lr:1.00e-02, fs:0.63203 (r=0.737,p=0.553),  time:33.449, tt:301.043\n",
      "Ep:9, loss:0.00023, loss_test:0.12138, lr:1.00e-02, fs:0.64286 (r=0.727,p=0.576),  time:33.598, tt:335.984\n",
      "Ep:10, loss:0.00022, loss_test:0.11862, lr:1.00e-02, fs:0.65455 (r=0.727,p=0.595),  time:34.067, tt:374.738\n",
      "Ep:11, loss:0.00022, loss_test:0.11586, lr:1.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:34.362, tt:412.345\n",
      "Ep:12, loss:0.00021, loss_test:0.11269, lr:1.00e-02, fs:0.68545 (r=0.737,p=0.640),  time:34.582, tt:449.561\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.11051, lr:1.00e-02, fs:0.68545 (r=0.737,p=0.640),  time:34.807, tt:487.302\n",
      "Ep:14, loss:0.00020, loss_test:0.10802, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:34.879, tt:523.178\n",
      "Ep:15, loss:0.00019, loss_test:0.10637, lr:1.00e-02, fs:0.66667 (r=0.677,p=0.657),  time:35.054, tt:560.861\n",
      "Ep:16, loss:0.00019, loss_test:0.10459, lr:1.00e-02, fs:0.67317 (r=0.697,p=0.651),  time:35.254, tt:599.320\n",
      "Ep:17, loss:0.00018, loss_test:0.10309, lr:1.00e-02, fs:0.67000 (r=0.677,p=0.663),  time:35.428, tt:637.708\n",
      "Ep:18, loss:0.00018, loss_test:0.10244, lr:1.00e-02, fs:0.65641 (r=0.646,p=0.667),  time:35.550, tt:675.442\n",
      "Ep:19, loss:0.00017, loss_test:0.10196, lr:1.00e-02, fs:0.66321 (r=0.646,p=0.681),  time:35.578, tt:711.565\n",
      "Ep:20, loss:0.00017, loss_test:0.10119, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:35.606, tt:747.717\n",
      "Ep:21, loss:0.00016, loss_test:0.09997, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:35.594, tt:783.062\n",
      "Ep:22, loss:0.00016, loss_test:0.09980, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:35.608, tt:818.989\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09862, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:35.633, tt:855.204\n",
      "Ep:24, loss:0.00015, loss_test:0.09853, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:35.677, tt:891.935\n",
      "Ep:25, loss:0.00014, loss_test:0.09793, lr:1.00e-02, fs:0.66316 (r=0.636,p=0.692),  time:35.750, tt:929.511\n",
      "Ep:26, loss:0.00014, loss_test:0.09803, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:35.812, tt:966.930\n",
      "Ep:27, loss:0.00013, loss_test:0.09729, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:35.832, tt:1003.306\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09712, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:35.792, tt:1037.977\n",
      "Ep:29, loss:0.00012, loss_test:0.09729, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:35.773, tt:1073.181\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.09745, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:35.810, tt:1110.097\n",
      "Ep:31, loss:0.00012, loss_test:0.09610, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:35.789, tt:1145.260\n",
      "Ep:32, loss:0.00011, loss_test:0.09635, lr:1.00e-02, fs:0.66667 (r=0.606,p=0.741),  time:35.857, tt:1183.289\n",
      "Ep:33, loss:0.00011, loss_test:0.09752, lr:1.00e-02, fs:0.67778 (r=0.616,p=0.753),  time:35.888, tt:1220.202\n",
      "Ep:34, loss:0.00010, loss_test:0.09570, lr:1.00e-02, fs:0.65556 (r=0.596,p=0.728),  time:35.823, tt:1253.801\n",
      "Ep:35, loss:0.00010, loss_test:0.09712, lr:1.00e-02, fs:0.67416 (r=0.606,p=0.759),  time:35.891, tt:1292.072\n",
      "Ep:36, loss:0.00010, loss_test:0.09634, lr:1.00e-02, fs:0.65537 (r=0.586,p=0.744),  time:35.890, tt:1327.939\n",
      "Ep:37, loss:0.00009, loss_test:0.09696, lr:1.00e-02, fs:0.67778 (r=0.616,p=0.753),  time:35.941, tt:1365.755\n",
      "Ep:38, loss:0.00009, loss_test:0.09764, lr:1.00e-02, fs:0.65517 (r=0.576,p=0.760),  time:35.963, tt:1402.542\n",
      "Ep:39, loss:0.00009, loss_test:0.09749, lr:1.00e-02, fs:0.67045 (r=0.596,p=0.766),  time:36.011, tt:1440.450\n",
      "Ep:40, loss:0.00009, loss_test:0.09740, lr:1.00e-02, fs:0.65517 (r=0.576,p=0.760),  time:36.027, tt:1477.109\n",
      "Ep:41, loss:0.00008, loss_test:0.09775, lr:9.90e-03, fs:0.65517 (r=0.576,p=0.760),  time:36.062, tt:1514.584\n",
      "Ep:42, loss:0.00008, loss_test:0.09674, lr:9.80e-03, fs:0.67045 (r=0.596,p=0.766),  time:36.071, tt:1551.035\n",
      "Ep:43, loss:0.00008, loss_test:0.09600, lr:9.70e-03, fs:0.65143 (r=0.576,p=0.750),  time:36.123, tt:1589.418\n",
      "Ep:44, loss:0.00007, loss_test:0.09499, lr:9.61e-03, fs:0.68927 (r=0.616,p=0.782),  time:36.169, tt:1627.589\n",
      "Ep:45, loss:0.00007, loss_test:0.09706, lr:9.51e-03, fs:0.65896 (r=0.576,p=0.770),  time:36.189, tt:1664.686\n",
      "Ep:46, loss:0.00007, loss_test:0.09405, lr:9.41e-03, fs:0.68539 (r=0.616,p=0.772),  time:36.207, tt:1701.710\n",
      "Ep:47, loss:0.00007, loss_test:0.09651, lr:9.32e-03, fs:0.65497 (r=0.566,p=0.778),  time:36.226, tt:1738.862\n",
      "Ep:48, loss:0.00007, loss_test:0.09405, lr:9.23e-03, fs:0.67816 (r=0.596,p=0.787),  time:36.272, tt:1777.305\n",
      "Ep:49, loss:0.00007, loss_test:0.09370, lr:9.14e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.283, tt:1814.171\n",
      "Ep:50, loss:0.00006, loss_test:0.09622, lr:9.04e-03, fs:0.66279 (r=0.576,p=0.781),  time:36.299, tt:1851.226\n",
      "Ep:51, loss:0.00006, loss_test:0.09317, lr:8.95e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.347, tt:1890.035\n",
      "Ep:52, loss:0.00006, loss_test:0.09512, lr:8.86e-03, fs:0.66279 (r=0.576,p=0.781),  time:36.363, tt:1927.257\n",
      "Ep:53, loss:0.00006, loss_test:0.09394, lr:8.78e-03, fs:0.66272 (r=0.566,p=0.800),  time:36.356, tt:1963.244\n",
      "Ep:54, loss:0.00005, loss_test:0.09388, lr:8.69e-03, fs:0.65896 (r=0.576,p=0.770),  time:36.363, tt:1999.944\n",
      "Ep:55, loss:0.00005, loss_test:0.09462, lr:8.60e-03, fs:0.67059 (r=0.576,p=0.803),  time:36.372, tt:2036.842\n",
      "Ep:56, loss:0.00005, loss_test:0.09203, lr:8.51e-03, fs:0.66667 (r=0.586,p=0.773),  time:36.414, tt:2075.622\n",
      "Ep:57, loss:0.00005, loss_test:0.09401, lr:8.43e-03, fs:0.67456 (r=0.576,p=0.814),  time:36.419, tt:2112.321\n",
      "Ep:58, loss:0.00005, loss_test:0.09279, lr:8.35e-03, fs:0.66667 (r=0.586,p=0.773),  time:36.417, tt:2148.612\n",
      "Ep:59, loss:0.00005, loss_test:0.09586, lr:8.26e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.435, tt:2186.103\n",
      "Ep:60, loss:0.00005, loss_test:0.09234, lr:8.18e-03, fs:0.67052 (r=0.586,p=0.784),  time:36.485, tt:2225.586\n",
      "Ep:61, loss:0.00005, loss_test:0.09492, lr:8.10e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.490, tt:2262.407\n",
      "Ep:62, loss:0.00005, loss_test:0.09421, lr:8.02e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.502, tt:2299.655\n",
      "Ep:63, loss:0.00004, loss_test:0.09332, lr:7.94e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.492, tt:2335.483\n",
      "Ep:64, loss:0.00004, loss_test:0.09231, lr:7.86e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.507, tt:2372.975\n",
      "Ep:65, loss:0.00004, loss_test:0.08999, lr:7.78e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.521, tt:2410.376\n",
      "Ep:66, loss:0.00004, loss_test:0.09274, lr:7.70e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.554, tt:2449.119\n",
      "Ep:67, loss:0.00004, loss_test:0.09091, lr:7.62e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.581, tt:2487.485\n",
      "Ep:68, loss:0.00004, loss_test:0.09341, lr:7.55e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.598, tt:2525.228\n",
      "Ep:69, loss:0.00004, loss_test:0.09203, lr:7.47e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.600, tt:2562.032\n",
      "Ep:70, loss:0.00004, loss_test:0.09065, lr:7.40e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.621, tt:2600.100\n",
      "Ep:71, loss:0.00004, loss_test:0.09223, lr:7.32e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.641, tt:2638.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00004, loss_test:0.09114, lr:7.25e-03, fs:0.67442 (r=0.586,p=0.795),  time:36.629, tt:2673.928\n",
      "Ep:73, loss:0.00004, loss_test:0.09071, lr:7.18e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.637, tt:2711.136\n",
      "Ep:74, loss:0.00004, loss_test:0.09357, lr:7.11e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.635, tt:2747.655\n",
      "Ep:75, loss:0.00003, loss_test:0.08974, lr:7.03e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.640, tt:2784.633\n",
      "Ep:76, loss:0.00003, loss_test:0.09287, lr:6.96e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.647, tt:2821.841\n",
      "Ep:77, loss:0.00003, loss_test:0.08961, lr:6.89e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.678, tt:2860.885\n",
      "Ep:78, loss:0.00003, loss_test:0.09469, lr:6.83e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.686, tt:2898.171\n",
      "Ep:79, loss:0.00003, loss_test:0.09035, lr:6.76e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.695, tt:2935.590\n",
      "Ep:80, loss:0.00003, loss_test:0.09220, lr:6.69e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.704, tt:2973.033\n",
      "Ep:81, loss:0.00003, loss_test:0.09423, lr:6.62e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.707, tt:3009.978\n",
      "Ep:82, loss:0.00003, loss_test:0.08898, lr:6.56e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.748, tt:3050.065\n",
      "Ep:83, loss:0.00003, loss_test:0.09415, lr:6.49e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.771, tt:3088.767\n",
      "Ep:84, loss:0.00003, loss_test:0.09212, lr:6.43e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.795, tt:3127.614\n",
      "Ep:85, loss:0.00003, loss_test:0.09073, lr:6.36e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.819, tt:3166.410\n",
      "Ep:86, loss:0.00003, loss_test:0.09435, lr:6.30e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.821, tt:3203.468\n",
      "Ep:87, loss:0.00003, loss_test:0.08878, lr:6.24e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.837, tt:3241.682\n",
      "Ep:88, loss:0.00003, loss_test:0.09446, lr:6.17e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.860, tt:3280.513\n",
      "Ep:89, loss:0.00003, loss_test:0.08903, lr:6.11e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.875, tt:3318.765\n",
      "Ep:90, loss:0.00003, loss_test:0.09282, lr:6.05e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.863, tt:3354.571\n",
      "Ep:91, loss:0.00003, loss_test:0.09459, lr:5.99e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.888, tt:3393.715\n",
      "Ep:92, loss:0.00003, loss_test:0.08758, lr:5.93e-03, fs:0.67836 (r=0.586,p=0.806),  time:36.904, tt:3432.094\n",
      "Ep:93, loss:0.00003, loss_test:0.09479, lr:5.87e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.931, tt:3471.506\n",
      "Ep:94, loss:0.00003, loss_test:0.09131, lr:5.81e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.953, tt:3510.537\n",
      "Ep:95, loss:0.00003, loss_test:0.08959, lr:5.75e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.967, tt:3548.821\n",
      "Ep:96, loss:0.00002, loss_test:0.09378, lr:5.70e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.968, tt:3585.929\n",
      "Ep:97, loss:0.00002, loss_test:0.08971, lr:5.64e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.988, tt:3624.861\n",
      "Ep:98, loss:0.00002, loss_test:0.09246, lr:5.58e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.970, tt:3660.044\n",
      "Ep:99, loss:0.00002, loss_test:0.09174, lr:5.53e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.966, tt:3696.622\n",
      "Ep:100, loss:0.00002, loss_test:0.09050, lr:5.47e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.955, tt:3732.424\n",
      "Ep:101, loss:0.00002, loss_test:0.09335, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.941, tt:3768.024\n",
      "Ep:102, loss:0.00002, loss_test:0.09024, lr:5.36e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.938, tt:3804.608\n",
      "Ep:103, loss:0.00002, loss_test:0.09285, lr:5.31e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.935, tt:3841.270\n",
      "Ep:104, loss:0.00002, loss_test:0.09152, lr:5.26e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.932, tt:3877.883\n",
      "Ep:105, loss:0.00002, loss_test:0.09224, lr:5.20e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.920, tt:3913.503\n",
      "Ep:106, loss:0.00002, loss_test:0.09367, lr:5.15e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.926, tt:3951.118\n",
      "Ep:107, loss:0.00002, loss_test:0.09226, lr:5.10e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.927, tt:3988.078\n",
      "Ep:108, loss:0.00002, loss_test:0.09269, lr:5.05e-03, fs:0.68639 (r=0.586,p=0.829),  time:36.922, tt:4024.474\n",
      "Ep:109, loss:0.00002, loss_test:0.09278, lr:5.00e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.917, tt:4060.849\n",
      "Ep:110, loss:0.00002, loss_test:0.09157, lr:4.95e-03, fs:0.68235 (r=0.586,p=0.817),  time:36.908, tt:4096.756\n",
      "Ep:111, loss:0.00002, loss_test:0.09154, lr:4.90e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.905, tt:4133.396\n",
      "Ep:112, loss:0.00002, loss_test:0.09287, lr:4.85e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.898, tt:4169.469\n",
      "Ep:113, loss:0.00002, loss_test:0.09294, lr:4.80e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.894, tt:4205.876\n",
      "Ep:114, loss:0.00002, loss_test:0.09224, lr:4.75e-03, fs:0.69880 (r=0.586,p=0.866),  time:36.891, tt:4242.447\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00002, loss_test:0.09121, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.918, tt:4282.530\n",
      "Ep:116, loss:0.00002, loss_test:0.09029, lr:4.75e-03, fs:0.69880 (r=0.586,p=0.866),  time:36.930, tt:4320.778\n",
      "Ep:117, loss:0.00002, loss_test:0.09166, lr:4.75e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.922, tt:4356.786\n",
      "Ep:118, loss:0.00002, loss_test:0.09072, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.929, tt:4394.569\n",
      "Ep:119, loss:0.00002, loss_test:0.08998, lr:4.75e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.920, tt:4430.421\n",
      "Ep:120, loss:0.00002, loss_test:0.09024, lr:4.75e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.921, tt:4467.443\n",
      "Ep:121, loss:0.00002, loss_test:0.09100, lr:4.75e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.908, tt:4502.746\n",
      "Ep:122, loss:0.00002, loss_test:0.09096, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.901, tt:4538.816\n",
      "Ep:123, loss:0.00002, loss_test:0.09031, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.891, tt:4574.448\n",
      "Ep:124, loss:0.00002, loss_test:0.09011, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.885, tt:4610.637\n",
      "Ep:125, loss:0.00002, loss_test:0.09114, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.881, tt:4647.032\n",
      "Ep:126, loss:0.00002, loss_test:0.08963, lr:4.71e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.886, tt:4684.459\n",
      "Ep:127, loss:0.00002, loss_test:0.09079, lr:4.66e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.892, tt:4722.158\n",
      "Ep:128, loss:0.00002, loss_test:0.09081, lr:4.61e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.898, tt:4759.838\n",
      "Ep:129, loss:0.00002, loss_test:0.09037, lr:4.57e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.886, tt:4795.230\n",
      "Ep:130, loss:0.00002, loss_test:0.09047, lr:4.52e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.886, tt:4832.045\n",
      "Ep:131, loss:0.00002, loss_test:0.08961, lr:4.48e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.864, tt:4865.997\n",
      "Ep:132, loss:0.00002, loss_test:0.09075, lr:4.43e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.875, tt:4904.441\n",
      "Ep:133, loss:0.00002, loss_test:0.09028, lr:4.39e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.906, tt:4945.380\n",
      "Ep:134, loss:0.00002, loss_test:0.08910, lr:4.34e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.913, tt:4983.247\n",
      "Ep:135, loss:0.00002, loss_test:0.09073, lr:4.30e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.917, tt:5020.709\n",
      "Ep:136, loss:0.00002, loss_test:0.08974, lr:4.26e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.909, tt:5056.517\n",
      "Ep:137, loss:0.00002, loss_test:0.08904, lr:4.21e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.903, tt:5092.636\n",
      "Ep:138, loss:0.00002, loss_test:0.09091, lr:4.17e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.915, tt:5131.231\n",
      "Ep:139, loss:0.00002, loss_test:0.09016, lr:4.13e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.918, tt:5168.551\n",
      "Ep:140, loss:0.00002, loss_test:0.09037, lr:4.09e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.928, tt:5206.887\n",
      "Ep:141, loss:0.00002, loss_test:0.09020, lr:4.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.911, tt:5241.420\n",
      "Ep:142, loss:0.00002, loss_test:0.08959, lr:4.01e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.896, tt:5276.076\n",
      "Ep:143, loss:0.00002, loss_test:0.08965, lr:3.97e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.881, tt:5310.932\n",
      "Ep:144, loss:0.00002, loss_test:0.09027, lr:3.93e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.880, tt:5347.591\n",
      "Ep:145, loss:0.00002, loss_test:0.09061, lr:3.89e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.870, tt:5383.030\n",
      "Ep:146, loss:0.00002, loss_test:0.08944, lr:3.85e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.858, tt:5418.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00002, loss_test:0.09038, lr:3.81e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.849, tt:5453.710\n",
      "Ep:148, loss:0.00002, loss_test:0.09051, lr:3.77e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.834, tt:5488.253\n",
      "Ep:149, loss:0.00002, loss_test:0.08923, lr:3.73e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.826, tt:5523.887\n",
      "Ep:150, loss:0.00002, loss_test:0.09066, lr:3.70e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.821, tt:5559.982\n",
      "Ep:151, loss:0.00002, loss_test:0.09087, lr:3.66e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.820, tt:5596.619\n",
      "Ep:152, loss:0.00002, loss_test:0.08999, lr:3.62e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.814, tt:5632.582\n",
      "Ep:153, loss:0.00002, loss_test:0.08969, lr:3.59e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.822, tt:5670.517\n",
      "Ep:154, loss:0.00002, loss_test:0.09102, lr:3.55e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.814, tt:5706.185\n",
      "Ep:155, loss:0.00002, loss_test:0.08984, lr:3.52e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.809, tt:5742.196\n",
      "Ep:156, loss:0.00001, loss_test:0.09018, lr:3.48e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.857, tt:5786.495\n",
      "Ep:157, loss:0.00001, loss_test:0.09164, lr:3.45e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.853, tt:5822.847\n",
      "Ep:158, loss:0.00001, loss_test:0.09006, lr:3.41e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.843, tt:5858.006\n",
      "Ep:159, loss:0.00001, loss_test:0.08936, lr:3.38e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.828, tt:5892.450\n",
      "Ep:160, loss:0.00001, loss_test:0.09072, lr:3.34e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.821, tt:5928.149\n",
      "Ep:161, loss:0.00001, loss_test:0.09081, lr:3.31e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.827, tt:5965.933\n",
      "Ep:162, loss:0.00001, loss_test:0.09015, lr:3.28e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.818, tt:6001.329\n",
      "Ep:163, loss:0.00001, loss_test:0.08996, lr:3.24e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.809, tt:6036.704\n",
      "Ep:164, loss:0.00001, loss_test:0.09062, lr:3.21e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.801, tt:6072.107\n",
      "Ep:165, loss:0.00001, loss_test:0.09018, lr:3.18e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.792, tt:6107.406\n",
      "Ep:166, loss:0.00001, loss_test:0.09019, lr:3.15e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.799, tt:6145.354\n",
      "Ep:167, loss:0.00001, loss_test:0.09012, lr:3.12e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.799, tt:6182.285\n",
      "Ep:168, loss:0.00001, loss_test:0.09061, lr:3.09e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.785, tt:6216.623\n",
      "Ep:169, loss:0.00001, loss_test:0.09018, lr:3.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.792, tt:6254.686\n",
      "Ep:170, loss:0.00001, loss_test:0.09170, lr:3.02e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.782, tt:6289.694\n",
      "Ep:171, loss:0.00001, loss_test:0.09033, lr:2.99e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.771, tt:6324.565\n",
      "Ep:172, loss:0.00001, loss_test:0.09081, lr:2.96e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.758, tt:6359.123\n",
      "Ep:173, loss:0.00001, loss_test:0.09084, lr:2.93e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.753, tt:6394.985\n",
      "Ep:174, loss:0.00001, loss_test:0.09098, lr:2.90e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.750, tt:6431.238\n",
      "Ep:175, loss:0.00001, loss_test:0.09039, lr:2.88e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.741, tt:6466.401\n",
      "Ep:176, loss:0.00001, loss_test:0.09049, lr:2.85e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.729, tt:6501.088\n",
      "Ep:177, loss:0.00001, loss_test:0.09122, lr:2.82e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.721, tt:6536.320\n",
      "Ep:178, loss:0.00001, loss_test:0.09091, lr:2.79e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.719, tt:6572.707\n",
      "Ep:179, loss:0.00001, loss_test:0.09102, lr:2.76e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.724, tt:6610.285\n",
      "Ep:180, loss:0.00001, loss_test:0.09086, lr:2.73e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.722, tt:6646.759\n",
      "Ep:181, loss:0.00001, loss_test:0.09067, lr:2.71e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.723, tt:6683.566\n",
      "Ep:182, loss:0.00001, loss_test:0.09077, lr:2.68e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.717, tt:6719.289\n",
      "Ep:183, loss:0.00001, loss_test:0.09113, lr:2.65e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.714, tt:6755.303\n",
      "Ep:184, loss:0.00001, loss_test:0.09066, lr:2.63e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.710, tt:6791.433\n",
      "Ep:185, loss:0.00001, loss_test:0.09064, lr:2.60e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.703, tt:6826.681\n",
      "Ep:186, loss:0.00001, loss_test:0.09124, lr:2.57e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.700, tt:6862.848\n",
      "Ep:187, loss:0.00001, loss_test:0.09088, lr:2.55e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.694, tt:6898.522\n",
      "Ep:188, loss:0.00001, loss_test:0.09150, lr:2.52e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.690, tt:6934.321\n",
      "Ep:189, loss:0.00001, loss_test:0.09118, lr:2.50e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.686, tt:6970.372\n",
      "Ep:190, loss:0.00001, loss_test:0.09125, lr:2.47e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.680, tt:7005.848\n",
      "Ep:191, loss:0.00001, loss_test:0.09128, lr:2.45e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.677, tt:7042.035\n",
      "Ep:192, loss:0.00001, loss_test:0.09142, lr:2.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.670, tt:7077.347\n",
      "Ep:193, loss:0.00001, loss_test:0.09159, lr:2.40e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.674, tt:7114.717\n",
      "Ep:194, loss:0.00001, loss_test:0.09157, lr:2.38e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.671, tt:7150.800\n",
      "Ep:195, loss:0.00001, loss_test:0.09080, lr:2.35e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.666, tt:7186.475\n",
      "Ep:196, loss:0.00001, loss_test:0.09148, lr:2.33e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.673, tt:7224.610\n",
      "Ep:197, loss:0.00001, loss_test:0.09160, lr:2.31e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.664, tt:7259.457\n",
      "Ep:198, loss:0.00001, loss_test:0.09117, lr:2.28e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.670, tt:7297.343\n",
      "Ep:199, loss:0.00001, loss_test:0.09100, lr:2.26e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.661, tt:7332.146\n",
      "Ep:200, loss:0.00001, loss_test:0.09148, lr:2.24e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.663, tt:7369.273\n",
      "Ep:201, loss:0.00001, loss_test:0.09132, lr:2.21e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.659, tt:7405.051\n",
      "Ep:202, loss:0.00001, loss_test:0.09134, lr:2.19e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.675, tt:7444.926\n",
      "Ep:203, loss:0.00001, loss_test:0.09125, lr:2.17e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.679, tt:7482.594\n",
      "Ep:204, loss:0.00001, loss_test:0.09177, lr:2.15e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.680, tt:7519.492\n",
      "Ep:205, loss:0.00001, loss_test:0.09188, lr:2.13e-03, fs:0.69048 (r=0.586,p=0.841),  time:36.674, tt:7554.821\n",
      "Ep:206, loss:0.00001, loss_test:0.09122, lr:2.11e-03, fs:0.69461 (r=0.586,p=0.853),  time:36.670, tt:7590.667\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14013, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.375, tt:35.375\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13728, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:35.058, tt:70.116\n",
      "Ep:2, loss:0.00027, loss_test:0.13185, lr:1.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:33.801, tt:101.403\n",
      "Ep:3, loss:0.00025, loss_test:0.12430, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:34.739, tt:138.955\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11938, lr:1.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:35.479, tt:177.397\n",
      "Ep:5, loss:0.00023, loss_test:0.11771, lr:1.00e-02, fs:0.62687 (r=0.636,p=0.618),  time:35.919, tt:215.512\n",
      "Ep:6, loss:0.00022, loss_test:0.11480, lr:1.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:35.963, tt:251.744\n",
      "Ep:7, loss:0.00022, loss_test:0.11136, lr:1.00e-02, fs:0.66667 (r=0.727,p=0.615),  time:36.077, tt:288.619\n",
      "Ep:8, loss:0.00021, loss_test:0.10838, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:36.264, tt:326.379\n",
      "Ep:9, loss:0.00020, loss_test:0.10655, lr:1.00e-02, fs:0.68293 (r=0.707,p=0.660),  time:36.452, tt:364.518\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00019, loss_test:0.10343, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:36.598, tt:402.574\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.10019, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:36.776, tt:441.307\n",
      "Ep:12, loss:0.00017, loss_test:0.09792, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:36.818, tt:478.638\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09618, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:36.776, tt:514.862\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.09447, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:36.812, tt:552.180\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.09215, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:36.858, tt:589.731\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09083, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:36.864, tt:626.684\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09220, lr:1.00e-02, fs:0.72527 (r=0.667,p=0.795),  time:37.043, tt:666.776\n",
      "Ep:18, loss:0.00014, loss_test:0.09116, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:37.152, tt:705.891\n",
      "Ep:19, loss:0.00013, loss_test:0.09079, lr:1.00e-02, fs:0.71910 (r=0.646,p=0.810),  time:37.092, tt:741.847\n",
      "Ep:20, loss:0.00013, loss_test:0.08854, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:37.114, tt:779.402\n",
      "Ep:21, loss:0.00012, loss_test:0.08841, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:37.178, tt:817.912\n",
      "Ep:22, loss:0.00012, loss_test:0.08758, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:37.284, tt:857.534\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08636, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:37.313, tt:895.518\n",
      "Ep:24, loss:0.00011, loss_test:0.08621, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:37.370, tt:934.249\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.08621, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:37.375, tt:971.744\n",
      "Ep:26, loss:0.00010, loss_test:0.08380, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:37.402, tt:1009.843\n",
      "Ep:27, loss:0.00009, loss_test:0.08270, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:37.433, tt:1048.115\n",
      "Ep:28, loss:0.00009, loss_test:0.08398, lr:1.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:37.426, tt:1085.367\n",
      "Ep:29, loss:0.00009, loss_test:0.08107, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:37.414, tt:1122.406\n",
      "Ep:30, loss:0.00008, loss_test:0.08249, lr:1.00e-02, fs:0.71591 (r=0.636,p=0.818),  time:37.365, tt:1158.321\n",
      "Ep:31, loss:0.00008, loss_test:0.07930, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:37.297, tt:1193.490\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08190, lr:1.00e-02, fs:0.71345 (r=0.616,p=0.847),  time:37.321, tt:1231.578\n",
      "Ep:33, loss:0.00007, loss_test:0.08063, lr:1.00e-02, fs:0.72832 (r=0.636,p=0.851),  time:37.372, tt:1270.658\n",
      "Ep:34, loss:0.00007, loss_test:0.07720, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:37.620, tt:1316.692\n",
      "Ep:35, loss:0.00007, loss_test:0.08091, lr:1.00e-02, fs:0.72316 (r=0.646,p=0.821),  time:37.568, tt:1352.446\n",
      "Ep:36, loss:0.00006, loss_test:0.07674, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:37.548, tt:1389.287\n",
      "Ep:37, loss:0.00006, loss_test:0.08216, lr:1.00e-02, fs:0.71429 (r=0.606,p=0.870),  time:37.567, tt:1427.538\n",
      "Ep:38, loss:0.00006, loss_test:0.07658, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:37.471, tt:1461.382\n",
      "Ep:39, loss:0.00006, loss_test:0.07998, lr:1.00e-02, fs:0.73810 (r=0.626,p=0.899),  time:37.428, tt:1497.122\n",
      "Ep:40, loss:0.00006, loss_test:0.07569, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:37.382, tt:1532.649\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.07711, lr:1.00e-02, fs:0.73373 (r=0.626,p=0.886),  time:37.336, tt:1568.098\n",
      "Ep:42, loss:0.00005, loss_test:0.07819, lr:1.00e-02, fs:0.72619 (r=0.616,p=0.884),  time:37.322, tt:1604.829\n",
      "Ep:43, loss:0.00005, loss_test:0.07356, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:37.264, tt:1639.612\n",
      "Ep:44, loss:0.00005, loss_test:0.07910, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:37.330, tt:1679.839\n",
      "Ep:45, loss:0.00005, loss_test:0.07595, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:37.314, tt:1716.459\n",
      "Ep:46, loss:0.00005, loss_test:0.07508, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:37.317, tt:1753.910\n",
      "Ep:47, loss:0.00004, loss_test:0.07599, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:37.288, tt:1789.809\n",
      "Ep:48, loss:0.00004, loss_test:0.07249, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:37.292, tt:1827.329\n",
      "Ep:49, loss:0.00004, loss_test:0.07489, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:37.259, tt:1862.941\n",
      "Ep:50, loss:0.00004, loss_test:0.07384, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:37.250, tt:1899.761\n",
      "Ep:51, loss:0.00004, loss_test:0.07165, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:37.275, tt:1938.284\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.07419, lr:1.00e-02, fs:0.77108 (r=0.646,p=0.955),  time:37.254, tt:1974.469\n",
      "Ep:53, loss:0.00004, loss_test:0.07189, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:37.251, tt:2011.581\n",
      "Ep:54, loss:0.00004, loss_test:0.07300, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:37.259, tt:2049.235\n",
      "Ep:55, loss:0.00003, loss_test:0.06941, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:37.249, tt:2085.917\n",
      "Ep:56, loss:0.00003, loss_test:0.06924, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:37.245, tt:2122.988\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.07378, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:37.259, tt:2161.010\n",
      "Ep:58, loss:0.00003, loss_test:0.06791, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:37.257, tt:2198.155\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.07905, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:37.241, tt:2234.444\n",
      "Ep:60, loss:0.00003, loss_test:0.06706, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:37.242, tt:2271.767\n",
      "Ep:61, loss:0.00003, loss_test:0.07403, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:37.218, tt:2307.535\n",
      "Ep:62, loss:0.00003, loss_test:0.06827, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:37.230, tt:2345.470\n",
      "Ep:63, loss:0.00003, loss_test:0.06838, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:37.225, tt:2382.411\n",
      "Ep:64, loss:0.00003, loss_test:0.06695, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:37.217, tt:2419.123\n",
      "Ep:65, loss:0.00002, loss_test:0.06733, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:37.203, tt:2455.409\n",
      "Ep:66, loss:0.00002, loss_test:0.06910, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:37.208, tt:2492.962\n",
      "Ep:67, loss:0.00002, loss_test:0.06578, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:37.192, tt:2529.030\n",
      "Ep:68, loss:0.00002, loss_test:0.06851, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:37.223, tt:2568.394\n",
      "Ep:69, loss:0.00002, loss_test:0.06668, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:37.230, tt:2606.125\n",
      "Ep:70, loss:0.00002, loss_test:0.06394, lr:9.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:37.265, tt:2645.832\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.07022, lr:9.90e-03, fs:0.75904 (r=0.636,p=0.940),  time:37.243, tt:2681.508\n",
      "Ep:72, loss:0.00002, loss_test:0.06457, lr:9.90e-03, fs:0.84270 (r=0.758,p=0.949),  time:37.240, tt:2718.491\n",
      "Ep:73, loss:0.00002, loss_test:0.06750, lr:9.90e-03, fs:0.79070 (r=0.687,p=0.932),  time:37.263, tt:2757.486\n",
      "Ep:74, loss:0.00002, loss_test:0.06469, lr:9.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:37.291, tt:2796.860\n",
      "Ep:75, loss:0.00002, loss_test:0.06779, lr:9.90e-03, fs:0.76364 (r=0.636,p=0.955),  time:37.314, tt:2835.897\n",
      "Ep:76, loss:0.00002, loss_test:0.06750, lr:9.90e-03, fs:0.77647 (r=0.667,p=0.930),  time:37.294, tt:2871.637\n",
      "Ep:77, loss:0.00002, loss_test:0.06421, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.301, tt:2909.498\n",
      "Ep:78, loss:0.00002, loss_test:0.06745, lr:9.90e-03, fs:0.79769 (r=0.697,p=0.932),  time:37.293, tt:2946.162\n",
      "Ep:79, loss:0.00002, loss_test:0.06609, lr:9.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:37.297, tt:2983.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00002, loss_test:0.06516, lr:9.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.294, tt:3020.813\n",
      "Ep:81, loss:0.00001, loss_test:0.06795, lr:9.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:37.316, tt:3059.928\n",
      "Ep:82, loss:0.00001, loss_test:0.06521, lr:9.80e-03, fs:0.78107 (r=0.667,p=0.943),  time:37.322, tt:3097.731\n",
      "Ep:83, loss:0.00001, loss_test:0.06558, lr:9.70e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.327, tt:3135.430\n",
      "Ep:84, loss:0.00001, loss_test:0.06815, lr:9.61e-03, fs:0.75610 (r=0.626,p=0.954),  time:37.343, tt:3174.154\n",
      "Ep:85, loss:0.00001, loss_test:0.06536, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.351, tt:3212.188\n",
      "Ep:86, loss:0.00001, loss_test:0.06517, lr:9.41e-03, fs:0.84746 (r=0.758,p=0.962),  time:37.337, tt:3248.282\n",
      "Ep:87, loss:0.00001, loss_test:0.06937, lr:9.32e-03, fs:0.75904 (r=0.636,p=0.940),  time:37.337, tt:3285.673\n",
      "Ep:88, loss:0.00001, loss_test:0.06419, lr:9.23e-03, fs:0.86188 (r=0.788,p=0.951),  time:37.346, tt:3323.796\n",
      "Ep:89, loss:0.00001, loss_test:0.06873, lr:9.14e-03, fs:0.75904 (r=0.636,p=0.940),  time:37.331, tt:3359.758\n",
      "Ep:90, loss:0.00001, loss_test:0.06614, lr:9.04e-03, fs:0.78824 (r=0.677,p=0.944),  time:37.303, tt:3394.609\n",
      "Ep:91, loss:0.00001, loss_test:0.06549, lr:8.95e-03, fs:0.84746 (r=0.758,p=0.962),  time:37.299, tt:3431.543\n",
      "Ep:92, loss:0.00001, loss_test:0.06724, lr:8.86e-03, fs:0.76647 (r=0.646,p=0.941),  time:37.310, tt:3469.800\n",
      "Ep:93, loss:0.00001, loss_test:0.06577, lr:8.78e-03, fs:0.80233 (r=0.697,p=0.945),  time:37.305, tt:3506.663\n",
      "Ep:94, loss:0.00001, loss_test:0.06786, lr:8.69e-03, fs:0.76364 (r=0.636,p=0.955),  time:37.288, tt:3542.395\n",
      "Ep:95, loss:0.00001, loss_test:0.06648, lr:8.60e-03, fs:0.79532 (r=0.687,p=0.944),  time:37.277, tt:3578.625\n",
      "Ep:96, loss:0.00001, loss_test:0.06565, lr:8.51e-03, fs:0.84270 (r=0.758,p=0.949),  time:37.257, tt:3613.949\n",
      "Ep:97, loss:0.00001, loss_test:0.06738, lr:8.43e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.234, tt:3648.912\n",
      "Ep:98, loss:0.00001, loss_test:0.06818, lr:8.35e-03, fs:0.78824 (r=0.677,p=0.944),  time:37.217, tt:3684.470\n",
      "Ep:99, loss:0.00001, loss_test:0.06477, lr:8.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.210, tt:3721.006\n",
      "Ep:100, loss:0.00001, loss_test:0.06771, lr:8.18e-03, fs:0.78571 (r=0.667,p=0.957),  time:37.209, tt:3758.121\n",
      "Ep:101, loss:0.00001, loss_test:0.06731, lr:8.10e-03, fs:0.75152 (r=0.626,p=0.939),  time:37.214, tt:3795.832\n",
      "Ep:102, loss:0.00001, loss_test:0.06602, lr:8.02e-03, fs:0.86957 (r=0.808,p=0.941),  time:37.208, tt:3832.431\n",
      "Ep:103, loss:0.00001, loss_test:0.06928, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:37.195, tt:3868.322\n",
      "Ep:104, loss:0.00001, loss_test:0.06698, lr:7.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.171, tt:3902.995\n",
      "Ep:105, loss:0.00001, loss_test:0.06651, lr:7.78e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.155, tt:3938.427\n",
      "Ep:106, loss:0.00001, loss_test:0.06854, lr:7.70e-03, fs:0.74390 (r=0.616,p=0.938),  time:37.157, tt:3975.786\n",
      "Ep:107, loss:0.00001, loss_test:0.06794, lr:7.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:37.157, tt:4012.955\n",
      "Ep:108, loss:0.00001, loss_test:0.06715, lr:7.55e-03, fs:0.78107 (r=0.667,p=0.943),  time:37.169, tt:4051.437\n",
      "Ep:109, loss:0.00001, loss_test:0.06894, lr:7.47e-03, fs:0.74390 (r=0.616,p=0.938),  time:37.157, tt:4087.324\n",
      "Ep:110, loss:0.00001, loss_test:0.06858, lr:7.40e-03, fs:0.77381 (r=0.657,p=0.942),  time:37.154, tt:4124.148\n",
      "Ep:111, loss:0.00001, loss_test:0.06793, lr:7.32e-03, fs:0.75904 (r=0.636,p=0.940),  time:37.156, tt:4161.448\n",
      "Ep:112, loss:0.00001, loss_test:0.06981, lr:7.25e-03, fs:0.74390 (r=0.616,p=0.938),  time:37.166, tt:4199.763\n",
      "Ep:113, loss:0.00001, loss_test:0.06785, lr:7.18e-03, fs:0.77381 (r=0.657,p=0.942),  time:37.148, tt:4234.830\n",
      "Ep:114, loss:0.00001, loss_test:0.06963, lr:7.11e-03, fs:0.74074 (r=0.606,p=0.952),  time:37.156, tt:4272.955\n",
      "Ep:115, loss:0.00001, loss_test:0.06940, lr:7.03e-03, fs:0.76647 (r=0.646,p=0.941),  time:37.141, tt:4308.315\n",
      "Ep:116, loss:0.00001, loss_test:0.06818, lr:6.96e-03, fs:0.78824 (r=0.677,p=0.944),  time:37.143, tt:4345.698\n",
      "Ep:117, loss:0.00001, loss_test:0.07133, lr:6.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:37.126, tt:4380.835\n",
      "Ep:118, loss:0.00001, loss_test:0.06919, lr:6.83e-03, fs:0.77381 (r=0.657,p=0.942),  time:37.130, tt:4418.506\n",
      "Ep:119, loss:0.00001, loss_test:0.06880, lr:6.76e-03, fs:0.83429 (r=0.737,p=0.961),  time:37.165, tt:4459.856\n",
      "Ep:120, loss:0.00001, loss_test:0.06934, lr:6.69e-03, fs:0.77381 (r=0.657,p=0.942),  time:37.172, tt:4497.823\n",
      "Ep:121, loss:0.00001, loss_test:0.06995, lr:6.62e-03, fs:0.74390 (r=0.616,p=0.938),  time:37.164, tt:4534.066\n",
      "Ep:122, loss:0.00001, loss_test:0.06914, lr:6.56e-03, fs:0.74390 (r=0.616,p=0.938),  time:37.148, tt:4569.252\n",
      "Ep:123, loss:0.00001, loss_test:0.06980, lr:6.49e-03, fs:0.73620 (r=0.606,p=0.938),  time:37.132, tt:4604.379\n",
      "Ep:124, loss:0.00001, loss_test:0.07098, lr:6.43e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.131, tt:4641.370\n",
      "Ep:125, loss:0.00001, loss_test:0.06892, lr:6.36e-03, fs:0.76647 (r=0.646,p=0.941),  time:37.126, tt:4677.921\n",
      "Ep:126, loss:0.00001, loss_test:0.06971, lr:6.30e-03, fs:0.75904 (r=0.636,p=0.940),  time:37.121, tt:4714.332\n",
      "Ep:127, loss:0.00000, loss_test:0.07169, lr:6.24e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.128, tt:4752.367\n",
      "Ep:128, loss:0.00000, loss_test:0.06988, lr:6.17e-03, fs:0.72050 (r=0.586,p=0.935),  time:37.123, tt:4788.826\n",
      "Ep:129, loss:0.00000, loss_test:0.07001, lr:6.11e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.105, tt:4823.593\n",
      "Ep:130, loss:0.00000, loss_test:0.07081, lr:6.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.101, tt:4860.267\n",
      "Ep:131, loss:0.00000, loss_test:0.06981, lr:5.99e-03, fs:0.72050 (r=0.586,p=0.935),  time:37.090, tt:4895.932\n",
      "Ep:132, loss:0.00000, loss_test:0.07041, lr:5.93e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.084, tt:4932.224\n",
      "Ep:133, loss:0.00000, loss_test:0.07107, lr:5.87e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.083, tt:4969.076\n",
      "Ep:134, loss:0.00000, loss_test:0.07098, lr:5.81e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.073, tt:5004.836\n",
      "Ep:135, loss:0.00000, loss_test:0.07047, lr:5.75e-03, fs:0.72050 (r=0.586,p=0.935),  time:37.065, tt:5040.816\n",
      "Ep:136, loss:0.00000, loss_test:0.07124, lr:5.70e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.058, tt:5076.895\n",
      "Ep:137, loss:0.00000, loss_test:0.07189, lr:5.64e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.050, tt:5112.882\n",
      "Ep:138, loss:0.00000, loss_test:0.06969, lr:5.58e-03, fs:0.72840 (r=0.596,p=0.937),  time:37.044, tt:5149.114\n",
      "Ep:139, loss:0.00000, loss_test:0.07221, lr:5.53e-03, fs:0.72152 (r=0.576,p=0.966),  time:37.042, tt:5185.833\n",
      "Ep:140, loss:0.00000, loss_test:0.07148, lr:5.47e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.019, tt:5219.728\n",
      "Ep:141, loss:0.00000, loss_test:0.07053, lr:5.42e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.005, tt:5254.722\n",
      "Ep:142, loss:0.00000, loss_test:0.07258, lr:5.36e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.000, tt:5291.053\n",
      "Ep:143, loss:0.00000, loss_test:0.07127, lr:5.31e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.009, tt:5329.297\n",
      "Ep:144, loss:0.00000, loss_test:0.07169, lr:5.26e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.006, tt:5365.825\n",
      "Ep:145, loss:0.00000, loss_test:0.07256, lr:5.20e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.004, tt:5402.628\n",
      "Ep:146, loss:0.00000, loss_test:0.07195, lr:5.15e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.008, tt:5440.183\n",
      "Ep:147, loss:0.00000, loss_test:0.07110, lr:5.10e-03, fs:0.74074 (r=0.606,p=0.952),  time:37.010, tt:5477.434\n",
      "Ep:148, loss:0.00000, loss_test:0.07270, lr:5.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.015, tt:5515.293\n",
      "Ep:149, loss:0.00000, loss_test:0.07246, lr:5.00e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.021, tt:5553.192\n",
      "Ep:150, loss:0.00000, loss_test:0.07206, lr:4.95e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.016, tt:5589.438\n",
      "Ep:151, loss:0.00000, loss_test:0.07273, lr:4.90e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.027, tt:5628.081\n",
      "Ep:152, loss:0.00000, loss_test:0.07226, lr:4.85e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.037, tt:5666.609\n",
      "Ep:153, loss:0.00000, loss_test:0.07346, lr:4.80e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.036, tt:5703.569\n",
      "Ep:154, loss:0.00000, loss_test:0.07300, lr:4.75e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.032, tt:5740.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.07155, lr:4.71e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.040, tt:5778.240\n",
      "Ep:156, loss:0.00000, loss_test:0.07309, lr:4.66e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.053, tt:5817.267\n",
      "Ep:157, loss:0.00000, loss_test:0.07343, lr:4.61e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.044, tt:5852.905\n",
      "Ep:158, loss:0.00000, loss_test:0.07254, lr:4.57e-03, fs:0.71250 (r=0.576,p=0.934),  time:37.054, tt:5891.615\n",
      "Ep:159, loss:0.00000, loss_test:0.07374, lr:4.52e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.052, tt:5928.250\n",
      "Ep:160, loss:0.00000, loss_test:0.07293, lr:4.48e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.048, tt:5964.748\n",
      "Ep:161, loss:0.00000, loss_test:0.07295, lr:4.43e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.044, tt:6001.056\n",
      "Ep:162, loss:0.00000, loss_test:0.07292, lr:4.39e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.033, tt:6036.455\n",
      "Ep:163, loss:0.00000, loss_test:0.07368, lr:4.34e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.038, tt:6074.174\n",
      "Ep:164, loss:0.00000, loss_test:0.07337, lr:4.30e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.034, tt:6110.611\n",
      "Ep:165, loss:0.00000, loss_test:0.07224, lr:4.26e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.048, tt:6149.945\n",
      "Ep:166, loss:0.00000, loss_test:0.07423, lr:4.21e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.055, tt:6188.102\n",
      "Ep:167, loss:0.00000, loss_test:0.07434, lr:4.17e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.069, tt:6227.590\n",
      "Ep:168, loss:0.00000, loss_test:0.07287, lr:4.13e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.075, tt:6265.709\n",
      "Ep:169, loss:0.00000, loss_test:0.07429, lr:4.09e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.079, tt:6303.420\n",
      "Ep:170, loss:0.00000, loss_test:0.07447, lr:4.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.082, tt:6341.066\n",
      "Ep:171, loss:0.00000, loss_test:0.07328, lr:4.01e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.079, tt:6377.641\n",
      "Ep:172, loss:0.00000, loss_test:0.07431, lr:3.97e-03, fs:0.72152 (r=0.576,p=0.966),  time:37.088, tt:6416.177\n",
      "Ep:173, loss:0.00000, loss_test:0.07429, lr:3.93e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.093, tt:6454.217\n",
      "Ep:174, loss:0.00000, loss_test:0.07355, lr:3.89e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.092, tt:6491.043\n",
      "Ep:175, loss:0.00000, loss_test:0.07401, lr:3.85e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.093, tt:6528.306\n",
      "Ep:176, loss:0.00000, loss_test:0.07446, lr:3.81e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.095, tt:6565.802\n",
      "Ep:177, loss:0.00000, loss_test:0.07404, lr:3.77e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.109, tt:6605.470\n",
      "Ep:178, loss:0.00000, loss_test:0.07384, lr:3.73e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.121, tt:6644.731\n",
      "Ep:179, loss:0.00000, loss_test:0.07458, lr:3.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.118, tt:6681.316\n",
      "Ep:180, loss:0.00000, loss_test:0.07402, lr:3.66e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.112, tt:6717.191\n",
      "Ep:181, loss:0.00000, loss_test:0.07425, lr:3.62e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.121, tt:6755.990\n",
      "Ep:182, loss:0.00000, loss_test:0.07410, lr:3.59e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.125, tt:6793.821\n",
      "Ep:183, loss:0.00000, loss_test:0.07437, lr:3.55e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.125, tt:6830.972\n",
      "Ep:184, loss:0.00000, loss_test:0.07458, lr:3.52e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.128, tt:6868.718\n",
      "Ep:185, loss:0.00000, loss_test:0.07423, lr:3.48e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.126, tt:6905.474\n",
      "Ep:186, loss:0.00000, loss_test:0.07444, lr:3.45e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.135, tt:6944.184\n",
      "Ep:187, loss:0.00000, loss_test:0.07441, lr:3.41e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.141, tt:6982.489\n",
      "Ep:188, loss:0.00000, loss_test:0.07427, lr:3.38e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.141, tt:7019.571\n",
      "Ep:189, loss:0.00000, loss_test:0.07466, lr:3.34e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.150, tt:7058.510\n",
      "Ep:190, loss:0.00000, loss_test:0.07484, lr:3.31e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.140, tt:7093.756\n",
      "Ep:191, loss:0.00000, loss_test:0.07489, lr:3.28e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.149, tt:7132.518\n",
      "Ep:192, loss:0.00000, loss_test:0.07431, lr:3.24e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.147, tt:7169.411\n",
      "Ep:193, loss:0.00000, loss_test:0.07506, lr:3.21e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.150, tt:7207.063\n",
      "Ep:194, loss:0.00000, loss_test:0.07532, lr:3.18e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.157, tt:7245.530\n",
      "Ep:195, loss:0.00000, loss_test:0.07459, lr:3.15e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.160, tt:7283.393\n",
      "Ep:196, loss:0.00000, loss_test:0.07488, lr:3.12e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.170, tt:7322.416\n",
      "Ep:197, loss:0.00000, loss_test:0.07501, lr:3.09e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.175, tt:7360.576\n",
      "Ep:198, loss:0.00000, loss_test:0.07503, lr:3.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.179, tt:7398.711\n",
      "Ep:199, loss:0.00000, loss_test:0.07527, lr:3.02e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.168, tt:7433.635\n",
      "Ep:200, loss:0.00000, loss_test:0.07515, lr:2.99e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.167, tt:7470.484\n",
      "Ep:201, loss:0.00000, loss_test:0.07489, lr:2.96e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.164, tt:7507.111\n",
      "Ep:202, loss:0.00000, loss_test:0.07463, lr:2.93e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.172, tt:7545.885\n",
      "Ep:203, loss:0.00000, loss_test:0.07536, lr:2.90e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.179, tt:7584.513\n",
      "Ep:204, loss:0.00000, loss_test:0.07548, lr:2.88e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.190, tt:7623.877\n",
      "Ep:205, loss:0.00000, loss_test:0.07554, lr:2.85e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.195, tt:7662.213\n",
      "Ep:206, loss:0.00000, loss_test:0.07514, lr:2.82e-03, fs:0.71698 (r=0.576,p=0.950),  time:37.199, tt:7700.164\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00083, loss_test:0.01991, lr:1.00e-02, fs:0.68644 (r=0.931,p=0.544),  time:556.453, tt:556.453\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01823, lr:1.00e-02, fs:0.72146 (r=0.908,p=0.598),  time:608.078, tt:1216.156\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01760, lr:1.00e-02, fs:0.71154 (r=0.851,p=0.612),  time:624.440, tt:1873.320\n",
      "Ep:3, loss:0.00051, loss_test:0.01726, lr:1.00e-02, fs:0.74396 (r=0.885,p=0.642),  time:633.427, tt:2533.710\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00046, loss_test:0.01694, lr:1.00e-02, fs:0.75122 (r=0.885,p=0.653),  time:639.987, tt:3199.933\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00041, loss_test:0.01673, lr:1.00e-02, fs:0.77320 (r=0.862,p=0.701),  time:641.803, tt:3850.817\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00037, loss_test:0.01645, lr:1.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:643.030, tt:4501.210\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00034, loss_test:0.01622, lr:1.00e-02, fs:0.81081 (r=0.862,p=0.765),  time:645.810, tt:5166.480\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00031, loss_test:0.01600, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:646.848, tt:5821.631\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.01584, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:648.074, tt:6480.738\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00026, loss_test:0.01578, lr:1.00e-02, fs:0.80000 (r=0.805,p=0.795),  time:647.997, tt:7127.964\n",
      "Ep:11, loss:0.00024, loss_test:0.01559, lr:1.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:648.308, tt:7779.694\n",
      "Ep:12, loss:0.00022, loss_test:0.01546, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:648.308, tt:8428.009\n",
      "Ep:13, loss:0.00020, loss_test:0.01568, lr:1.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:648.051, tt:9072.709\n",
      "Ep:14, loss:0.00018, loss_test:0.01581, lr:1.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:648.298, tt:9724.467\n",
      "Ep:15, loss:0.00017, loss_test:0.01614, lr:1.00e-02, fs:0.78788 (r=0.747,p=0.833),  time:648.625, tt:10378.003\n",
      "Ep:16, loss:0.00016, loss_test:0.01628, lr:1.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:648.664, tt:11027.293\n",
      "Ep:17, loss:0.00015, loss_test:0.01651, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:648.728, tt:11677.104\n",
      "Ep:18, loss:0.00014, loss_test:0.01681, lr:1.00e-02, fs:0.79245 (r=0.724,p=0.875),  time:648.730, tt:12325.871\n",
      "Ep:19, loss:0.00013, loss_test:0.01722, lr:1.00e-02, fs:0.77707 (r=0.701,p=0.871),  time:648.806, tt:12976.115\n",
      "Ep:20, loss:0.00012, loss_test:0.01755, lr:1.00e-02, fs:0.76923 (r=0.690,p=0.870),  time:648.778, tt:13624.347\n",
      "Ep:21, loss:0.00011, loss_test:0.01794, lr:9.90e-03, fs:0.76923 (r=0.690,p=0.870),  time:648.868, tt:14275.093\n",
      "Ep:22, loss:0.00010, loss_test:0.01802, lr:9.80e-03, fs:0.76923 (r=0.690,p=0.870),  time:649.067, tt:14928.549\n",
      "Ep:23, loss:0.00010, loss_test:0.01855, lr:9.70e-03, fs:0.76923 (r=0.690,p=0.870),  time:649.318, tt:15583.636\n",
      "Ep:24, loss:0.00009, loss_test:0.01878, lr:9.61e-03, fs:0.77419 (r=0.690,p=0.882),  time:649.566, tt:16239.159\n",
      "Ep:25, loss:0.00009, loss_test:0.01903, lr:9.51e-03, fs:0.77419 (r=0.690,p=0.882),  time:649.825, tt:16895.462\n",
      "Ep:26, loss:0.00008, loss_test:0.01933, lr:9.41e-03, fs:0.77419 (r=0.690,p=0.882),  time:650.466, tt:17562.585\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00093, loss_test:0.02100, lr:1.00e-02, fs:0.67500 (r=0.931,p=0.529),  time:644.331, tt:644.331\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00066, loss_test:0.01859, lr:1.00e-02, fs:0.69869 (r=0.920,p=0.563),  time:656.766, tt:1313.533\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00058, loss_test:0.01770, lr:1.00e-02, fs:0.69484 (r=0.851,p=0.587),  time:661.647, tt:1984.940\n",
      "Ep:3, loss:0.00051, loss_test:0.01732, lr:1.00e-02, fs:0.72986 (r=0.885,p=0.621),  time:664.738, tt:2658.953\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.01718, lr:1.00e-02, fs:0.75248 (r=0.874,p=0.661),  time:667.452, tt:3337.260\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.01705, lr:1.00e-02, fs:0.76617 (r=0.885,p=0.675),  time:668.411, tt:4010.468\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00036, loss_test:0.01688, lr:1.00e-02, fs:0.78788 (r=0.897,p=0.703),  time:669.689, tt:4687.820\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.01670, lr:1.00e-02, fs:0.77720 (r=0.862,p=0.708),  time:671.385, tt:5371.079\n",
      "Ep:8, loss:0.00029, loss_test:0.01684, lr:1.00e-02, fs:0.78495 (r=0.839,p=0.737),  time:671.578, tt:6044.199\n",
      "Ep:9, loss:0.00026, loss_test:0.01689, lr:1.00e-02, fs:0.78261 (r=0.828,p=0.742),  time:671.203, tt:6712.034\n",
      "Ep:10, loss:0.00024, loss_test:0.01694, lr:1.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:671.093, tt:7382.028\n",
      "Ep:11, loss:0.00022, loss_test:0.01714, lr:1.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:670.735, tt:8048.814\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.01733, lr:1.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:671.681, tt:8731.847\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.01746, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:671.334, tt:9398.682\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.01780, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:671.002, tt:10065.033\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.01809, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:670.652, tt:10730.436\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.01833, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:670.445, tt:11397.563\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00013, loss_test:0.01862, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:670.373, tt:12066.713\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00012, loss_test:0.01887, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:670.328, tt:12736.240\n",
      "Ep:19, loss:0.00011, loss_test:0.01910, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:670.302, tt:13406.039\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00010, loss_test:0.01939, lr:1.00e-02, fs:0.85542 (r=0.816,p=0.899),  time:670.668, tt:14084.022\n",
      "Ep:21, loss:0.00010, loss_test:0.01961, lr:1.00e-02, fs:0.85542 (r=0.816,p=0.899),  time:671.201, tt:14766.425\n",
      "Ep:22, loss:0.00009, loss_test:0.02011, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:671.334, tt:15440.682\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.02042, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:671.053, tt:16105.264\n",
      "Ep:24, loss:0.00008, loss_test:0.02073, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:670.838, tt:16770.939\n",
      "Ep:25, loss:0.00008, loss_test:0.02106, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:670.603, tt:17435.689\n",
      "Ep:26, loss:0.00007, loss_test:0.02130, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:669.203, tt:18068.468\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00074, loss_test:0.01915, lr:1.00e-02, fs:0.66667 (r=0.931,p=0.519),  time:693.583, tt:693.583\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.01774, lr:1.00e-02, fs:0.71861 (r=0.954,p=0.576),  time:696.470, tt:1392.940\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.01690, lr:1.00e-02, fs:0.74775 (r=0.954,p=0.615),  time:696.631, tt:2089.894\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01625, lr:1.00e-02, fs:0.77209 (r=0.954,p=0.648),  time:697.674, tt:2790.697\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.01577, lr:1.00e-02, fs:0.75490 (r=0.885,p=0.658),  time:696.337, tt:3481.685\n",
      "Ep:5, loss:0.00044, loss_test:0.01543, lr:1.00e-02, fs:0.77157 (r=0.874,p=0.691),  time:696.569, tt:4179.415\n",
      "Ep:6, loss:0.00041, loss_test:0.01515, lr:1.00e-02, fs:0.79592 (r=0.897,p=0.716),  time:696.484, tt:4875.386\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.01491, lr:1.00e-02, fs:0.81026 (r=0.908,p=0.731),  time:697.174, tt:5577.395\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.01468, lr:1.00e-02, fs:0.82902 (r=0.920,p=0.755),  time:697.259, tt:6275.333\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.01451, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:697.306, tt:6973.062\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01432, lr:1.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:697.338, tt:7670.719\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.01417, lr:1.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:696.648, tt:8359.778\n",
      "Ep:12, loss:0.00030, loss_test:0.01407, lr:1.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:696.961, tt:9060.487\n",
      "Ep:13, loss:0.00028, loss_test:0.01404, lr:1.00e-02, fs:0.84324 (r=0.897,p=0.796),  time:697.400, tt:9763.598\n",
      "Ep:14, loss:0.00027, loss_test:0.01391, lr:1.00e-02, fs:0.83516 (r=0.874,p=0.800),  time:697.522, tt:10462.834\n",
      "Ep:15, loss:0.00025, loss_test:0.01387, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:697.477, tt:11159.632\n",
      "Ep:16, loss:0.00024, loss_test:0.01391, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:697.124, tt:11851.102\n",
      "Ep:17, loss:0.00023, loss_test:0.01382, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:697.340, tt:12552.112\n",
      "Ep:18, loss:0.00022, loss_test:0.01397, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:697.624, tt:13254.854\n",
      "Ep:19, loss:0.00021, loss_test:0.01389, lr:1.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:697.882, tt:13957.636\n",
      "Ep:20, loss:0.00020, loss_test:0.01392, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:697.936, tt:14656.650\n",
      "Ep:21, loss:0.00019, loss_test:0.01403, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:698.421, tt:15365.257\n",
      "Ep:22, loss:0.00018, loss_test:0.01407, lr:9.90e-03, fs:0.84706 (r=0.828,p=0.867),  time:698.312, tt:16061.175\n",
      "Ep:23, loss:0.00017, loss_test:0.01415, lr:9.80e-03, fs:0.84706 (r=0.828,p=0.867),  time:698.310, tt:16759.446\n",
      "Ep:24, loss:0.00017, loss_test:0.01409, lr:9.70e-03, fs:0.84706 (r=0.828,p=0.867),  time:698.281, tt:17457.036\n",
      "Ep:25, loss:0.00016, loss_test:0.01425, lr:9.61e-03, fs:0.86228 (r=0.828,p=0.900),  time:697.843, tt:18143.926\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.01433, lr:9.61e-03, fs:0.86747 (r=0.828,p=0.911),  time:697.804, tt:18840.707\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00076, loss_test:0.01969, lr:1.00e-02, fs:0.67188 (r=0.989,p=0.509),  time:680.757, tt:680.757\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01835, lr:1.00e-02, fs:0.71489 (r=0.966,p=0.568),  time:685.670, tt:1371.340\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00058, loss_test:0.01762, lr:1.00e-02, fs:0.73820 (r=0.989,p=0.589),  time:690.116, tt:2070.348\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00055, loss_test:0.01709, lr:1.00e-02, fs:0.76652 (r=1.000,p=0.621),  time:691.128, tt:2764.512\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00052, loss_test:0.01671, lr:1.00e-02, fs:0.79817 (r=1.000,p=0.664),  time:691.741, tt:3458.707\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00050, loss_test:0.01645, lr:1.00e-02, fs:0.80930 (r=1.000,p=0.680),  time:694.622, tt:4167.734\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00048, loss_test:0.01625, lr:1.00e-02, fs:0.78095 (r=0.943,p=0.667),  time:701.721, tt:4912.046\n",
      "Ep:7, loss:0.00046, loss_test:0.01609, lr:1.00e-02, fs:0.78049 (r=0.920,p=0.678),  time:701.655, tt:5613.241\n",
      "Ep:8, loss:0.00044, loss_test:0.01595, lr:1.00e-02, fs:0.78431 (r=0.920,p=0.684),  time:700.898, tt:6308.082\n",
      "Ep:9, loss:0.00042, loss_test:0.01583, lr:1.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:701.391, tt:7013.910\n",
      "Ep:10, loss:0.00041, loss_test:0.01571, lr:1.00e-02, fs:0.79602 (r=0.920,p=0.702),  time:701.312, tt:7714.434\n",
      "Ep:11, loss:0.00039, loss_test:0.01561, lr:1.00e-02, fs:0.79602 (r=0.920,p=0.702),  time:701.752, tt:8421.026\n",
      "Ep:12, loss:0.00038, loss_test:0.01554, lr:1.00e-02, fs:0.80808 (r=0.920,p=0.721),  time:701.925, tt:9125.019\n",
      "Ep:13, loss:0.00036, loss_test:0.01546, lr:1.00e-02, fs:0.81218 (r=0.920,p=0.727),  time:701.344, tt:9818.811\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00035, loss_test:0.01541, lr:1.00e-02, fs:0.82051 (r=0.920,p=0.741),  time:701.474, tt:10522.114\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00034, loss_test:0.01533, lr:1.00e-02, fs:0.82051 (r=0.920,p=0.741),  time:701.470, tt:11223.514\n",
      "Ep:16, loss:0.00033, loss_test:0.01528, lr:1.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:701.293, tt:11921.981\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00032, loss_test:0.01519, lr:1.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:701.184, tt:12621.310\n",
      "Ep:18, loss:0.00031, loss_test:0.01518, lr:1.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:700.981, tt:13318.637\n",
      "Ep:19, loss:0.00030, loss_test:0.01514, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:701.022, tt:14020.437\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00029, loss_test:0.01510, lr:1.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:701.156, tt:14724.285\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00028, loss_test:0.01508, lr:1.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:701.565, tt:15434.420\n",
      "Ep:22, loss:0.00027, loss_test:0.01508, lr:1.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:701.668, tt:16138.367\n",
      "Ep:23, loss:0.00026, loss_test:0.01508, lr:1.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:701.530, tt:16836.723\n",
      "Ep:24, loss:0.00025, loss_test:0.01510, lr:1.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:701.266, tt:17531.646\n",
      "Ep:25, loss:0.00025, loss_test:0.01510, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:701.210, tt:18231.462\n",
      "Ep:26, loss:0.00024, loss_test:0.01516, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:701.681, tt:18945.378\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00078, loss_test:0.01968, lr:1.00e-02, fs:0.67470 (r=0.966,p=0.519),  time:584.567, tt:584.567\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01854, lr:1.00e-02, fs:0.69565 (r=0.920,p=0.559),  time:600.538, tt:1201.077\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00057, loss_test:0.01794, lr:1.00e-02, fs:0.72889 (r=0.943,p=0.594),  time:599.054, tt:1797.162\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.01756, lr:1.00e-02, fs:0.74654 (r=0.931,p=0.623),  time:597.526, tt:2390.103\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01736, lr:1.00e-02, fs:0.72464 (r=0.862,p=0.625),  time:595.302, tt:2976.511\n",
      "Ep:5, loss:0.00046, loss_test:0.01715, lr:1.00e-02, fs:0.75000 (r=0.862,p=0.664),  time:595.321, tt:3571.926\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.01697, lr:1.00e-02, fs:0.75758 (r=0.862,p=0.676),  time:595.405, tt:4167.838\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.01687, lr:1.00e-02, fs:0.76923 (r=0.862,p=0.694),  time:596.391, tt:4771.127\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.01679, lr:1.00e-02, fs:0.78351 (r=0.874,p=0.710),  time:597.369, tt:5376.324\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.01666, lr:1.00e-02, fs:0.78351 (r=0.874,p=0.710),  time:597.013, tt:5970.131\n",
      "Ep:10, loss:0.00035, loss_test:0.01659, lr:1.00e-02, fs:0.80628 (r=0.885,p=0.740),  time:597.424, tt:6571.666\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.01651, lr:1.00e-02, fs:0.79787 (r=0.862,p=0.743),  time:597.300, tt:7167.600\n",
      "Ep:12, loss:0.00032, loss_test:0.01646, lr:1.00e-02, fs:0.78919 (r=0.839,p=0.745),  time:598.140, tt:7775.815\n",
      "Ep:13, loss:0.00030, loss_test:0.01644, lr:1.00e-02, fs:0.79570 (r=0.851,p=0.747),  time:597.860, tt:8370.045\n",
      "Ep:14, loss:0.00029, loss_test:0.01644, lr:1.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:597.854, tt:8967.806\n",
      "Ep:15, loss:0.00027, loss_test:0.01639, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:598.030, tt:9568.479\n",
      "Ep:16, loss:0.00026, loss_test:0.01643, lr:1.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:598.037, tt:10166.630\n",
      "Ep:17, loss:0.00025, loss_test:0.01650, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:598.226, tt:10768.075\n",
      "Ep:18, loss:0.00024, loss_test:0.01651, lr:1.00e-02, fs:0.77966 (r=0.793,p=0.767),  time:598.533, tt:11372.133\n",
      "Ep:19, loss:0.00022, loss_test:0.01662, lr:1.00e-02, fs:0.78161 (r=0.782,p=0.782),  time:598.600, tt:11971.997\n",
      "Ep:20, loss:0.00021, loss_test:0.01675, lr:1.00e-02, fs:0.77193 (r=0.759,p=0.786),  time:598.217, tt:12562.554\n",
      "Ep:21, loss:0.00020, loss_test:0.01677, lr:1.00e-02, fs:0.78107 (r=0.759,p=0.805),  time:597.542, tt:13145.917\n",
      "Ep:22, loss:0.00019, loss_test:0.01691, lr:9.90e-03, fs:0.78571 (r=0.759,p=0.815),  time:597.550, tt:13743.646\n",
      "Ep:23, loss:0.00019, loss_test:0.01717, lr:9.80e-03, fs:0.76829 (r=0.724,p=0.818),  time:596.342, tt:14312.213\n",
      "Ep:24, loss:0.00018, loss_test:0.01721, lr:9.70e-03, fs:0.76829 (r=0.724,p=0.818),  time:593.381, tt:14834.529\n",
      "Ep:25, loss:0.00017, loss_test:0.01725, lr:9.61e-03, fs:0.77301 (r=0.724,p=0.829),  time:591.131, tt:15369.410\n",
      "Ep:26, loss:0.00016, loss_test:0.01735, lr:9.51e-03, fs:0.77301 (r=0.724,p=0.829),  time:589.160, tt:15907.332\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00101, loss_test:0.02093, lr:1.00e-02, fs:0.65753 (r=0.828,p=0.545),  time:590.045, tt:590.045\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00069, loss_test:0.01705, lr:1.00e-02, fs:0.73874 (r=0.943,p=0.607),  time:600.647, tt:1201.295\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00056, loss_test:0.01553, lr:1.00e-02, fs:0.78140 (r=0.966,p=0.656),  time:599.309, tt:1797.928\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.01478, lr:1.00e-02, fs:0.75728 (r=0.897,p=0.655),  time:598.591, tt:2394.365\n",
      "Ep:4, loss:0.00038, loss_test:0.01434, lr:1.00e-02, fs:0.78788 (r=0.897,p=0.703),  time:599.098, tt:2995.491\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00031, loss_test:0.01464, lr:1.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:597.831, tt:3586.989\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.01527, lr:1.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:598.124, tt:4186.865\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00021, loss_test:0.01641, lr:1.00e-02, fs:0.84916 (r=0.874,p=0.826),  time:598.537, tt:4788.292\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00018, loss_test:0.01717, lr:1.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:598.474, tt:5386.262\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00015, loss_test:0.01818, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:598.602, tt:5986.021\n",
      "Ep:10, loss:0.00013, loss_test:0.01991, lr:1.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:599.068, tt:6589.745\n",
      "Ep:11, loss:0.00011, loss_test:0.02123, lr:1.00e-02, fs:0.86550 (r=0.851,p=0.881),  time:598.844, tt:7186.131\n",
      "Ep:12, loss:0.00010, loss_test:0.02231, lr:1.00e-02, fs:0.87574 (r=0.851,p=0.902),  time:599.068, tt:7787.879\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00009, loss_test:0.02352, lr:1.00e-02, fs:0.88095 (r=0.851,p=0.914),  time:599.276, tt:8389.864\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00008, loss_test:0.02519, lr:1.00e-02, fs:0.89157 (r=0.851,p=0.937),  time:599.520, tt:8992.800\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00007, loss_test:0.02574, lr:1.00e-02, fs:0.89697 (r=0.851,p=0.949),  time:599.046, tt:9584.742\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00006, loss_test:0.02711, lr:1.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:599.107, tt:10184.816\n",
      "Ep:17, loss:0.00006, loss_test:0.02810, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:599.000, tt:10781.998\n",
      "Ep:18, loss:0.00005, loss_test:0.02983, lr:1.00e-02, fs:0.82119 (r=0.713,p=0.969),  time:599.081, tt:11382.541\n",
      "Ep:19, loss:0.00005, loss_test:0.03050, lr:1.00e-02, fs:0.82119 (r=0.713,p=0.969),  time:597.436, tt:11948.723\n",
      "Ep:20, loss:0.00004, loss_test:0.03087, lr:1.00e-02, fs:0.82119 (r=0.713,p=0.969),  time:593.140, tt:12455.935\n",
      "Ep:21, loss:0.00004, loss_test:0.03261, lr:1.00e-02, fs:0.82119 (r=0.713,p=0.969),  time:586.447, tt:12901.836\n",
      "Ep:22, loss:0.00004, loss_test:0.03350, lr:1.00e-02, fs:0.79730 (r=0.678,p=0.967),  time:580.193, tt:13344.429\n",
      "Ep:23, loss:0.00003, loss_test:0.03491, lr:1.00e-02, fs:0.77241 (r=0.644,p=0.966),  time:570.526, tt:13692.625\n",
      "Ep:24, loss:0.00003, loss_test:0.03524, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:558.637, tt:13965.934\n",
      "Ep:25, loss:0.00003, loss_test:0.03618, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:546.141, tt:14199.664\n",
      "Ep:26, loss:0.00003, loss_test:0.03725, lr:1.00e-02, fs:0.76389 (r=0.632,p=0.965),  time:533.921, tt:14415.867\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00071, loss_test:0.01812, lr:1.00e-02, fs:0.68778 (r=0.874,p=0.567),  time:668.668, tt:668.668\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00057, loss_test:0.01677, lr:1.00e-02, fs:0.74886 (r=0.943,p=0.621),  time:660.542, tt:1321.085\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.01602, lr:1.00e-02, fs:0.79439 (r=0.977,p=0.669),  time:658.032, tt:1974.097\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.01566, lr:1.00e-02, fs:0.76847 (r=0.897,p=0.672),  time:656.027, tt:2624.109\n",
      "Ep:4, loss:0.00041, loss_test:0.01543, lr:1.00e-02, fs:0.78788 (r=0.897,p=0.703),  time:658.013, tt:3290.064\n",
      "Ep:5, loss:0.00038, loss_test:0.01532, lr:1.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:657.627, tt:3945.761\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.01529, lr:1.00e-02, fs:0.82979 (r=0.897,p=0.772),  time:657.427, tt:4601.988\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.01530, lr:1.00e-02, fs:0.82796 (r=0.885,p=0.778),  time:657.523, tt:5260.188\n",
      "Ep:8, loss:0.00029, loss_test:0.01538, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:657.875, tt:5920.878\n",
      "Ep:9, loss:0.00027, loss_test:0.01550, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:659.938, tt:6599.384\n",
      "Ep:10, loss:0.00025, loss_test:0.01560, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:666.939, tt:7336.327\n",
      "Ep:11, loss:0.00023, loss_test:0.01585, lr:1.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:673.627, tt:8083.520\n",
      "Ep:12, loss:0.00021, loss_test:0.01611, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:678.740, tt:8823.626\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.01634, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:683.701, tt:9571.807\n",
      "Ep:14, loss:0.00018, loss_test:0.01667, lr:1.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:687.579, tt:10313.683\n",
      "Ep:15, loss:0.00017, loss_test:0.01690, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:691.758, tt:11068.131\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.01732, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:694.304, tt:11803.161\n",
      "Ep:17, loss:0.00015, loss_test:0.01750, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:697.304, tt:12551.464\n",
      "Ep:18, loss:0.00014, loss_test:0.01778, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:699.679, tt:13293.898\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.01816, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:702.023, tt:14040.452\n",
      "Ep:20, loss:0.00012, loss_test:0.01840, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:704.135, tt:14786.838\n",
      "Ep:21, loss:0.00011, loss_test:0.01884, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:706.118, tt:15534.597\n",
      "Ep:22, loss:0.00011, loss_test:0.01902, lr:1.00e-02, fs:0.81290 (r=0.724,p=0.926),  time:707.837, tt:16280.242\n",
      "Ep:23, loss:0.00010, loss_test:0.01946, lr:1.00e-02, fs:0.80519 (r=0.713,p=0.925),  time:709.357, tt:17024.567\n",
      "Ep:24, loss:0.00009, loss_test:0.01979, lr:1.00e-02, fs:0.74830 (r=0.632,p=0.917),  time:710.622, tt:17765.562\n",
      "Ep:25, loss:0.00009, loss_test:0.02019, lr:1.00e-02, fs:0.73103 (r=0.609,p=0.914),  time:711.631, tt:18502.401\n",
      "Ep:26, loss:0.00008, loss_test:0.02045, lr:1.00e-02, fs:0.72222 (r=0.598,p=0.912),  time:712.658, tt:19241.757\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14169, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:44.746, tt:44.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.13905, lr:1.00e-02, fs:0.65891 (r=0.977,p=0.497),  time:46.325, tt:92.651\n",
      "Ep:2, loss:0.00001, loss_test:0.13374, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:45.927, tt:137.782\n",
      "Ep:3, loss:0.00001, loss_test:0.12479, lr:1.00e-02, fs:0.68376 (r=0.920,p=0.544),  time:43.413, tt:173.650\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.11751, lr:1.00e-02, fs:0.71795 (r=0.805,p=0.648),  time:43.527, tt:217.636\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.11698, lr:1.00e-02, fs:0.69231 (r=0.724,p=0.663),  time:44.012, tt:264.072\n",
      "Ep:6, loss:0.00001, loss_test:0.11271, lr:1.00e-02, fs:0.73469 (r=0.828,p=0.661),  time:44.495, tt:311.467\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.11108, lr:1.00e-02, fs:0.74510 (r=0.874,p=0.650),  time:45.133, tt:361.067\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.10795, lr:1.00e-02, fs:0.75132 (r=0.816,p=0.696),  time:45.494, tt:409.449\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.10800, lr:1.00e-02, fs:0.72826 (r=0.770,p=0.691),  time:46.079, tt:460.789\n",
      "Ep:10, loss:0.00001, loss_test:0.10720, lr:1.00e-02, fs:0.75258 (r=0.839,p=0.682),  time:46.374, tt:510.112\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00001, loss_test:0.10633, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:46.610, tt:559.324\n",
      "Ep:12, loss:0.00001, loss_test:0.10538, lr:1.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:46.909, tt:609.818\n",
      "Ep:13, loss:0.00001, loss_test:0.10416, lr:1.00e-02, fs:0.74866 (r=0.805,p=0.700),  time:47.111, tt:659.550\n",
      "Ep:14, loss:0.00001, loss_test:0.10179, lr:1.00e-02, fs:0.75556 (r=0.782,p=0.731),  time:47.218, tt:708.264\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00001, loss_test:0.10011, lr:1.00e-02, fs:0.77348 (r=0.805,p=0.745),  time:47.385, tt:758.164\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09798, lr:1.00e-02, fs:0.76923 (r=0.805,p=0.737),  time:47.490, tt:807.334\n",
      "Ep:17, loss:0.00001, loss_test:0.09587, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:47.403, tt:853.249\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.09329, lr:1.00e-02, fs:0.78212 (r=0.805,p=0.761),  time:47.869, tt:909.511\n",
      "Ep:19, loss:0.00001, loss_test:0.09115, lr:1.00e-02, fs:0.79096 (r=0.805,p=0.778),  time:47.858, tt:957.168\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.08940, lr:1.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:47.865, tt:1005.162\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.08833, lr:1.00e-02, fs:0.79096 (r=0.805,p=0.778),  time:47.968, tt:1055.287\n",
      "Ep:22, loss:0.00001, loss_test:0.08711, lr:1.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:47.971, tt:1103.332\n",
      "Ep:23, loss:0.00001, loss_test:0.08582, lr:1.00e-02, fs:0.79096 (r=0.805,p=0.778),  time:47.997, tt:1151.932\n",
      "Ep:24, loss:0.00001, loss_test:0.08549, lr:1.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:48.028, tt:1200.691\n",
      "Ep:25, loss:0.00001, loss_test:0.08479, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:48.040, tt:1249.051\n",
      "Ep:26, loss:0.00001, loss_test:0.08459, lr:1.00e-02, fs:0.80460 (r=0.805,p=0.805),  time:48.026, tt:1296.700\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00000, loss_test:0.08500, lr:1.00e-02, fs:0.80925 (r=0.805,p=0.814),  time:47.978, tt:1343.375\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00000, loss_test:0.08388, lr:1.00e-02, fs:0.81657 (r=0.793,p=0.841),  time:47.984, tt:1391.533\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.08404, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:48.032, tt:1440.968\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.08282, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:48.091, tt:1490.807\n",
      "Ep:31, loss:0.00000, loss_test:0.08184, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:48.017, tt:1536.541\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.08291, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:48.046, tt:1585.508\n",
      "Ep:33, loss:0.00000, loss_test:0.08052, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:48.090, tt:1635.048\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.08055, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:48.113, tt:1683.966\n",
      "Ep:35, loss:0.00000, loss_test:0.08073, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:48.065, tt:1730.329\n",
      "Ep:36, loss:0.00000, loss_test:0.08105, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:48.204, tt:1783.551\n",
      "Ep:37, loss:0.00000, loss_test:0.07997, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:48.215, tt:1832.182\n",
      "Ep:38, loss:0.00000, loss_test:0.08139, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:48.222, tt:1880.657\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.08351, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:48.218, tt:1928.705\n",
      "Ep:40, loss:0.00000, loss_test:0.07995, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:48.222, tt:1977.116\n",
      "Ep:41, loss:0.00000, loss_test:0.08334, lr:1.00e-02, fs:0.83019 (r=0.759,p=0.917),  time:48.247, tt:2026.395\n",
      "Ep:42, loss:0.00000, loss_test:0.08332, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:48.219, tt:2073.410\n",
      "Ep:43, loss:0.00000, loss_test:0.08395, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:48.197, tt:2120.686\n",
      "Ep:44, loss:0.00000, loss_test:0.08212, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:48.207, tt:2169.317\n",
      "Ep:45, loss:0.00000, loss_test:0.08546, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:48.192, tt:2216.830\n",
      "Ep:46, loss:0.00000, loss_test:0.08530, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:48.180, tt:2264.482\n",
      "Ep:47, loss:0.00000, loss_test:0.08436, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:48.130, tt:2310.220\n",
      "Ep:48, loss:0.00000, loss_test:0.08629, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:48.150, tt:2359.368\n",
      "Ep:49, loss:0.00000, loss_test:0.08365, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:48.166, tt:2408.276\n",
      "Ep:50, loss:0.00000, loss_test:0.08589, lr:9.90e-03, fs:0.80769 (r=0.724,p=0.913),  time:48.159, tt:2456.103\n",
      "Ep:51, loss:0.00000, loss_test:0.08759, lr:9.80e-03, fs:0.81818 (r=0.724,p=0.940),  time:48.175, tt:2505.103\n",
      "Ep:52, loss:0.00000, loss_test:0.08517, lr:9.70e-03, fs:0.82051 (r=0.736,p=0.928),  time:48.189, tt:2554.038\n",
      "Ep:53, loss:0.00000, loss_test:0.08688, lr:9.61e-03, fs:0.75676 (r=0.644,p=0.918),  time:48.185, tt:2601.978\n",
      "Ep:54, loss:0.00000, loss_test:0.08613, lr:9.51e-03, fs:0.77027 (r=0.655,p=0.934),  time:48.245, tt:2653.456\n",
      "Ep:55, loss:0.00000, loss_test:0.08320, lr:9.41e-03, fs:0.75342 (r=0.632,p=0.932),  time:48.269, tt:2703.066\n",
      "Ep:56, loss:0.00000, loss_test:0.08473, lr:9.32e-03, fs:0.72727 (r=0.598,p=0.929),  time:48.312, tt:2753.790\n",
      "Ep:57, loss:0.00000, loss_test:0.08713, lr:9.23e-03, fs:0.71831 (r=0.586,p=0.927),  time:48.327, tt:2802.993\n",
      "Ep:58, loss:0.00000, loss_test:0.08609, lr:9.14e-03, fs:0.71831 (r=0.586,p=0.927),  time:48.311, tt:2850.347\n",
      "Ep:59, loss:0.00000, loss_test:0.08426, lr:9.04e-03, fs:0.70000 (r=0.563,p=0.925),  time:48.315, tt:2898.891\n",
      "Ep:60, loss:0.00000, loss_test:0.08602, lr:8.95e-03, fs:0.71429 (r=0.575,p=0.943),  time:48.336, tt:2948.498\n",
      "Ep:61, loss:0.00000, loss_test:0.08592, lr:8.86e-03, fs:0.70000 (r=0.563,p=0.925),  time:48.384, tt:2999.788\n",
      "Ep:62, loss:0.00000, loss_test:0.08335, lr:8.78e-03, fs:0.70000 (r=0.563,p=0.925),  time:48.383, tt:3048.123\n",
      "Ep:63, loss:0.00000, loss_test:0.08481, lr:8.69e-03, fs:0.70000 (r=0.563,p=0.925),  time:48.376, tt:3096.077\n",
      "Ep:64, loss:0.00000, loss_test:0.08663, lr:8.60e-03, fs:0.70000 (r=0.563,p=0.925),  time:48.380, tt:3144.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00000, loss_test:0.08261, lr:8.51e-03, fs:0.70504 (r=0.563,p=0.942),  time:48.434, tt:3196.669\n",
      "Ep:66, loss:0.00000, loss_test:0.08689, lr:8.43e-03, fs:0.70000 (r=0.563,p=0.925),  time:48.456, tt:3246.520\n",
      "Ep:67, loss:0.00000, loss_test:0.08451, lr:8.35e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.448, tt:3294.468\n",
      "Ep:68, loss:0.00000, loss_test:0.08634, lr:8.26e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.495, tt:3346.181\n",
      "Ep:69, loss:0.00000, loss_test:0.08466, lr:8.18e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.474, tt:3393.210\n",
      "Ep:70, loss:0.00000, loss_test:0.08689, lr:8.10e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.496, tt:3443.234\n",
      "Ep:71, loss:0.00000, loss_test:0.08658, lr:8.02e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.497, tt:3491.757\n",
      "Ep:72, loss:0.00000, loss_test:0.08771, lr:7.94e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.486, tt:3539.477\n",
      "Ep:73, loss:0.00000, loss_test:0.08731, lr:7.86e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.488, tt:3588.144\n",
      "Ep:74, loss:0.00000, loss_test:0.08718, lr:7.78e-03, fs:0.69565 (r=0.552,p=0.941),  time:48.484, tt:3636.331\n",
      "Ep:75, loss:0.00000, loss_test:0.08843, lr:7.70e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.480, tt:3684.486\n",
      "Ep:76, loss:0.00000, loss_test:0.08734, lr:7.62e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.480, tt:3732.961\n",
      "Ep:77, loss:0.00000, loss_test:0.08840, lr:7.55e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.493, tt:3782.459\n",
      "Ep:78, loss:0.00000, loss_test:0.08735, lr:7.47e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.480, tt:3829.903\n",
      "Ep:79, loss:0.00000, loss_test:0.08898, lr:7.40e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.468, tt:3877.422\n",
      "Ep:80, loss:0.00000, loss_test:0.08773, lr:7.32e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.473, tt:3926.280\n",
      "Ep:81, loss:0.00000, loss_test:0.08876, lr:7.25e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.464, tt:3974.070\n",
      "Ep:82, loss:0.00000, loss_test:0.08860, lr:7.18e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.496, tt:4025.137\n",
      "Ep:83, loss:0.00000, loss_test:0.08890, lr:7.11e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.497, tt:4073.723\n",
      "Ep:84, loss:0.00000, loss_test:0.08871, lr:7.03e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.497, tt:4122.246\n",
      "Ep:85, loss:0.00000, loss_test:0.08903, lr:6.96e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.505, tt:4171.465\n",
      "Ep:86, loss:0.00000, loss_test:0.08950, lr:6.89e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.482, tt:4217.925\n",
      "Ep:87, loss:0.00000, loss_test:0.08944, lr:6.83e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.537, tt:4271.246\n",
      "Ep:88, loss:0.00000, loss_test:0.08982, lr:6.76e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.491, tt:4315.735\n",
      "Ep:89, loss:0.00000, loss_test:0.09027, lr:6.69e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.476, tt:4362.874\n",
      "Ep:90, loss:0.00000, loss_test:0.08977, lr:6.62e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.483, tt:4411.964\n",
      "Ep:91, loss:0.00000, loss_test:0.09039, lr:6.56e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.493, tt:4461.339\n",
      "Ep:92, loss:0.00000, loss_test:0.09067, lr:6.49e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.488, tt:4509.418\n",
      "Ep:93, loss:0.00000, loss_test:0.08993, lr:6.43e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.511, tt:4559.989\n",
      "Ep:94, loss:0.00000, loss_test:0.09100, lr:6.36e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.470, tt:4604.642\n",
      "Ep:95, loss:0.00000, loss_test:0.09017, lr:6.30e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.422, tt:4648.550\n",
      "Ep:96, loss:0.00000, loss_test:0.09165, lr:6.24e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.369, tt:4691.799\n",
      "Ep:97, loss:0.00000, loss_test:0.09046, lr:6.17e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.318, tt:4735.122\n",
      "Ep:98, loss:0.00000, loss_test:0.09205, lr:6.11e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.270, tt:4778.686\n",
      "Ep:99, loss:0.00000, loss_test:0.09077, lr:6.05e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.212, tt:4821.176\n",
      "Ep:100, loss:0.00000, loss_test:0.09220, lr:5.99e-03, fs:0.70588 (r=0.552,p=0.980),  time:48.171, tt:4865.223\n",
      "Ep:101, loss:0.00000, loss_test:0.09103, lr:5.93e-03, fs:0.70073 (r=0.552,p=0.960),  time:48.127, tt:4908.983\n",
      "Ep:102, loss:0.00000, loss_test:0.09216, lr:5.87e-03, fs:0.70588 (r=0.552,p=0.980),  time:48.078, tt:4952.067\n",
      "Ep:103, loss:0.00000, loss_test:0.09161, lr:5.81e-03, fs:0.70588 (r=0.552,p=0.980),  time:48.027, tt:4994.802\n",
      "Ep:104, loss:0.00000, loss_test:0.09193, lr:5.75e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.994, tt:5039.421\n",
      "Ep:105, loss:0.00000, loss_test:0.09168, lr:5.70e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.950, tt:5082.725\n",
      "Ep:106, loss:0.00000, loss_test:0.09190, lr:5.64e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.937, tt:5129.216\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14529, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.026, tt:14.026\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14437, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.287, tt:26.573\n",
      "Ep:2, loss:0.00001, loss_test:0.14272, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:13.158, tt:39.473\n",
      "Ep:3, loss:0.00001, loss_test:0.13995, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:13.513, tt:54.051\n",
      "Ep:4, loss:0.00001, loss_test:0.13538, lr:1.00e-02, fs:0.66406 (r=0.977,p=0.503),  time:14.786, tt:73.932\n",
      "Ep:5, loss:0.00001, loss_test:0.12734, lr:1.00e-02, fs:0.68333 (r=0.943,p=0.536),  time:17.839, tt:107.035\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.11825, lr:1.00e-02, fs:0.68966 (r=0.805,p=0.603),  time:22.147, tt:155.032\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.11740, lr:1.00e-02, fs:0.68132 (r=0.713,p=0.653),  time:25.395, tt:203.156\n",
      "Ep:8, loss:0.00001, loss_test:0.11508, lr:1.00e-02, fs:0.69189 (r=0.736,p=0.653),  time:27.957, tt:251.613\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.11160, lr:1.00e-02, fs:0.70408 (r=0.793,p=0.633),  time:29.939, tt:299.394\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.11026, lr:1.00e-02, fs:0.72362 (r=0.828,p=0.643),  time:31.562, tt:347.183\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00001, loss_test:0.10870, lr:1.00e-02, fs:0.70899 (r=0.770,p=0.657),  time:33.038, tt:396.451\n",
      "Ep:12, loss:0.00001, loss_test:0.10957, lr:1.00e-02, fs:0.67797 (r=0.690,p=0.667),  time:34.977, tt:454.701\n",
      "Ep:13, loss:0.00001, loss_test:0.10686, lr:1.00e-02, fs:0.68889 (r=0.713,p=0.667),  time:35.896, tt:502.540\n",
      "Ep:14, loss:0.00001, loss_test:0.10392, lr:1.00e-02, fs:0.69231 (r=0.724,p=0.663),  time:36.687, tt:550.308\n",
      "Ep:15, loss:0.00001, loss_test:0.10180, lr:1.00e-02, fs:0.72414 (r=0.724,p=0.724),  time:37.370, tt:597.927\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.10132, lr:1.00e-02, fs:0.72832 (r=0.724,p=0.733),  time:37.928, tt:644.780\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09910, lr:1.00e-02, fs:0.74576 (r=0.759,p=0.733),  time:38.404, tt:691.270\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.09776, lr:1.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:38.842, tt:738.006\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.09664, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:39.164, tt:783.270\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.09539, lr:1.00e-02, fs:0.75862 (r=0.759,p=0.759),  time:39.555, tt:830.661\n",
      "Ep:21, loss:0.00001, loss_test:0.09397, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:39.885, tt:877.468\n",
      "Ep:22, loss:0.00001, loss_test:0.09276, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.120, tt:922.765\n",
      "Ep:23, loss:0.00001, loss_test:0.09144, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.386, tt:969.260\n",
      "Ep:24, loss:0.00001, loss_test:0.09070, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.614, tt:1015.347\n",
      "Ep:25, loss:0.00001, loss_test:0.08951, lr:1.00e-02, fs:0.77011 (r=0.770,p=0.770),  time:40.823, tt:1061.390\n",
      "Ep:26, loss:0.00001, loss_test:0.08753, lr:1.00e-02, fs:0.77714 (r=0.782,p=0.773),  time:41.069, tt:1108.865\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.08625, lr:1.00e-02, fs:0.78161 (r=0.782,p=0.782),  time:41.284, tt:1155.952\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.08554, lr:1.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:41.446, tt:1201.946\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00001, loss_test:0.08479, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:41.652, tt:1249.554\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.08448, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:41.909, tt:1299.190\n",
      "Ep:31, loss:0.00001, loss_test:0.08380, lr:1.00e-02, fs:0.80925 (r=0.805,p=0.814),  time:42.045, tt:1345.429\n",
      "Ep:32, loss:0.00001, loss_test:0.08255, lr:1.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:42.214, tt:1393.068\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.08308, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:42.401, tt:1441.639\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.08240, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:42.543, tt:1488.996\n",
      "Ep:35, loss:0.00000, loss_test:0.08221, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:42.664, tt:1535.920\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00000, loss_test:0.08216, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:42.810, tt:1583.967\n",
      "Ep:37, loss:0.00000, loss_test:0.08169, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:42.897, tt:1630.082\n",
      "Ep:38, loss:0.00000, loss_test:0.08191, lr:1.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:42.998, tt:1676.933\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.08082, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:43.109, tt:1724.346\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.08157, lr:1.00e-02, fs:0.84524 (r=0.816,p=0.877),  time:43.215, tt:1771.804\n",
      "Ep:41, loss:0.00000, loss_test:0.08001, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:43.345, tt:1820.479\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00000, loss_test:0.08179, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:43.482, tt:1869.727\n",
      "Ep:43, loss:0.00000, loss_test:0.07926, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:43.599, tt:1918.356\n",
      "Ep:44, loss:0.00000, loss_test:0.08081, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:43.707, tt:1966.807\n",
      "Ep:45, loss:0.00000, loss_test:0.07883, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:43.826, tt:2015.982\n",
      "Ep:46, loss:0.00000, loss_test:0.07910, lr:1.00e-02, fs:0.85366 (r=0.805,p=0.909),  time:43.980, tt:2067.070\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00000, loss_test:0.07857, lr:1.00e-02, fs:0.85366 (r=0.805,p=0.909),  time:44.045, tt:2114.177\n",
      "Ep:48, loss:0.00000, loss_test:0.07747, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:44.000, tt:2155.978\n",
      "Ep:49, loss:0.00000, loss_test:0.07829, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:43.967, tt:2198.337\n",
      "Ep:50, loss:0.00000, loss_test:0.07648, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:43.947, tt:2241.280\n",
      "Ep:51, loss:0.00000, loss_test:0.07665, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:43.946, tt:2285.174\n",
      "Ep:52, loss:0.00000, loss_test:0.07575, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:43.942, tt:2328.913\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00000, loss_test:0.07506, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:44.001, tt:2376.059\n",
      "Ep:54, loss:0.00000, loss_test:0.07491, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:44.085, tt:2424.650\n",
      "Ep:55, loss:0.00000, loss_test:0.07556, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:44.140, tt:2471.842\n",
      "Ep:56, loss:0.00000, loss_test:0.07553, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:44.172, tt:2517.781\n",
      "Ep:57, loss:0.00000, loss_test:0.07502, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:44.224, tt:2565.013\n",
      "Ep:58, loss:0.00000, loss_test:0.07460, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:44.280, tt:2612.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00000, loss_test:0.07388, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:44.350, tt:2661.029\n",
      "Ep:60, loss:0.00000, loss_test:0.07534, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:44.419, tt:2709.588\n",
      "Ep:61, loss:0.00000, loss_test:0.07536, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:44.489, tt:2758.296\n",
      "Ep:62, loss:0.00000, loss_test:0.07486, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:44.556, tt:2807.027\n",
      "Ep:63, loss:0.00000, loss_test:0.07525, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:44.598, tt:2854.299\n",
      "Ep:64, loss:0.00000, loss_test:0.07444, lr:9.90e-03, fs:0.82803 (r=0.747,p=0.929),  time:44.665, tt:2903.206\n",
      "Ep:65, loss:0.00000, loss_test:0.07598, lr:9.80e-03, fs:0.84416 (r=0.747,p=0.970),  time:44.705, tt:2950.561\n",
      "Ep:66, loss:0.00000, loss_test:0.07379, lr:9.70e-03, fs:0.82803 (r=0.747,p=0.929),  time:44.760, tt:2998.904\n",
      "Ep:67, loss:0.00000, loss_test:0.07630, lr:9.61e-03, fs:0.82803 (r=0.747,p=0.929),  time:44.828, tt:3048.271\n",
      "Ep:68, loss:0.00000, loss_test:0.07593, lr:9.51e-03, fs:0.83871 (r=0.747,p=0.956),  time:44.871, tt:3096.090\n",
      "Ep:69, loss:0.00000, loss_test:0.07471, lr:9.41e-03, fs:0.82803 (r=0.747,p=0.929),  time:44.910, tt:3143.669\n",
      "Ep:70, loss:0.00000, loss_test:0.07630, lr:9.32e-03, fs:0.82803 (r=0.747,p=0.929),  time:44.931, tt:3190.114\n",
      "Ep:71, loss:0.00000, loss_test:0.07437, lr:9.23e-03, fs:0.83333 (r=0.747,p=0.942),  time:45.003, tt:3240.206\n",
      "Ep:72, loss:0.00000, loss_test:0.07589, lr:9.14e-03, fs:0.82803 (r=0.747,p=0.929),  time:45.025, tt:3286.842\n",
      "Ep:73, loss:0.00000, loss_test:0.07462, lr:9.04e-03, fs:0.83871 (r=0.747,p=0.956),  time:45.071, tt:3335.242\n",
      "Ep:74, loss:0.00000, loss_test:0.07719, lr:8.95e-03, fs:0.82803 (r=0.747,p=0.929),  time:45.101, tt:3382.605\n",
      "Ep:75, loss:0.00000, loss_test:0.07492, lr:8.86e-03, fs:0.83333 (r=0.747,p=0.942),  time:45.150, tt:3431.384\n",
      "Ep:76, loss:0.00000, loss_test:0.07830, lr:8.78e-03, fs:0.83871 (r=0.747,p=0.956),  time:45.181, tt:3478.968\n",
      "Ep:77, loss:0.00000, loss_test:0.07566, lr:8.69e-03, fs:0.82051 (r=0.736,p=0.928),  time:45.204, tt:3525.902\n",
      "Ep:78, loss:0.00000, loss_test:0.07785, lr:8.60e-03, fs:0.82051 (r=0.736,p=0.928),  time:45.221, tt:3572.420\n",
      "Ep:79, loss:0.00000, loss_test:0.07633, lr:8.51e-03, fs:0.83871 (r=0.747,p=0.956),  time:45.241, tt:3619.261\n",
      "Ep:80, loss:0.00000, loss_test:0.07789, lr:8.43e-03, fs:0.81290 (r=0.724,p=0.926),  time:45.272, tt:3667.025\n",
      "Ep:81, loss:0.00000, loss_test:0.07696, lr:8.35e-03, fs:0.83117 (r=0.736,p=0.955),  time:45.303, tt:3714.863\n",
      "Ep:82, loss:0.00000, loss_test:0.07859, lr:8.26e-03, fs:0.81818 (r=0.724,p=0.940),  time:45.334, tt:3762.746\n",
      "Ep:83, loss:0.00000, loss_test:0.07730, lr:8.18e-03, fs:0.80519 (r=0.713,p=0.925),  time:45.366, tt:3810.778\n",
      "Ep:84, loss:0.00000, loss_test:0.07874, lr:8.10e-03, fs:0.81579 (r=0.713,p=0.954),  time:45.380, tt:3857.292\n",
      "Ep:85, loss:0.00000, loss_test:0.07793, lr:8.02e-03, fs:0.80263 (r=0.701,p=0.938),  time:45.402, tt:3904.576\n",
      "Ep:86, loss:0.00000, loss_test:0.07939, lr:7.94e-03, fs:0.80263 (r=0.701,p=0.938),  time:45.452, tt:3954.307\n",
      "Ep:87, loss:0.00000, loss_test:0.07845, lr:7.86e-03, fs:0.80263 (r=0.701,p=0.938),  time:45.493, tt:4003.341\n",
      "Ep:88, loss:0.00000, loss_test:0.07914, lr:7.78e-03, fs:0.79470 (r=0.690,p=0.938),  time:45.548, tt:4053.732\n",
      "Ep:89, loss:0.00000, loss_test:0.07883, lr:7.70e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.583, tt:4102.439\n",
      "Ep:90, loss:0.00000, loss_test:0.07933, lr:7.62e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.605, tt:4150.036\n",
      "Ep:91, loss:0.00000, loss_test:0.07908, lr:7.55e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.643, tt:4199.144\n",
      "Ep:92, loss:0.00000, loss_test:0.07935, lr:7.47e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.677, tt:4247.999\n",
      "Ep:93, loss:0.00000, loss_test:0.07942, lr:7.40e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.702, tt:4295.980\n",
      "Ep:94, loss:0.00000, loss_test:0.07945, lr:7.32e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.738, tt:4345.131\n",
      "Ep:95, loss:0.00000, loss_test:0.07987, lr:7.25e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.775, tt:4394.355\n",
      "Ep:96, loss:0.00000, loss_test:0.07972, lr:7.18e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.850, tt:4447.454\n",
      "Ep:97, loss:0.00000, loss_test:0.07987, lr:7.11e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.892, tt:4497.408\n",
      "Ep:98, loss:0.00000, loss_test:0.07990, lr:7.03e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.930, tt:4547.080\n",
      "Ep:99, loss:0.00000, loss_test:0.08011, lr:6.96e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.967, tt:4596.730\n",
      "Ep:100, loss:0.00000, loss_test:0.08006, lr:6.89e-03, fs:0.80537 (r=0.690,p=0.968),  time:46.010, tt:4646.974\n",
      "Ep:101, loss:0.00000, loss_test:0.08053, lr:6.83e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.985, tt:4690.509\n",
      "Ep:102, loss:0.00000, loss_test:0.08051, lr:6.76e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.965, tt:4734.440\n",
      "Ep:103, loss:0.00000, loss_test:0.08097, lr:6.69e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.947, tt:4778.447\n",
      "Ep:104, loss:0.00000, loss_test:0.08103, lr:6.62e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.936, tt:4823.305\n",
      "Ep:105, loss:0.00000, loss_test:0.08158, lr:6.56e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.918, tt:4867.286\n",
      "Ep:106, loss:0.00000, loss_test:0.08160, lr:6.49e-03, fs:0.80537 (r=0.690,p=0.968),  time:45.892, tt:4910.425\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00340, loss_test:0.15516, lr:4.00e-03, fs:0.46995 (r=0.434,p=0.512),  time:570.839, tt:570.839\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00248, loss_test:0.13112, lr:4.00e-03, fs:0.54023 (r=0.475,p=0.627),  time:561.623, tt:1123.245\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00188, loss_test:0.12585, lr:4.00e-03, fs:0.56977 (r=0.495,p=0.671),  time:560.790, tt:1682.369\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00141, loss_test:0.12841, lr:4.00e-03, fs:0.56410 (r=0.444,p=0.772),  time:562.657, tt:2250.629\n",
      "Ep:4, loss:0.00099, loss_test:0.13847, lr:4.00e-03, fs:0.51799 (r=0.364,p=0.900),  time:563.439, tt:2817.195\n",
      "Ep:5, loss:0.00063, loss_test:0.14509, lr:4.00e-03, fs:0.49275 (r=0.343,p=0.872),  time:562.962, tt:3377.773\n",
      "Ep:6, loss:0.00039, loss_test:0.15975, lr:4.00e-03, fs:0.50370 (r=0.343,p=0.944),  time:554.178, tt:3879.244\n",
      "Ep:7, loss:0.00024, loss_test:0.16762, lr:4.00e-03, fs:0.50746 (r=0.343,p=0.971),  time:557.133, tt:4457.063\n",
      "Ep:8, loss:0.00016, loss_test:0.17227, lr:4.00e-03, fs:0.50746 (r=0.343,p=0.971),  time:560.275, tt:5042.472\n",
      "Ep:9, loss:0.00011, loss_test:0.17575, lr:4.00e-03, fs:0.50746 (r=0.343,p=0.971),  time:561.862, tt:5618.623\n",
      "Ep:10, loss:0.00008, loss_test:0.17976, lr:4.00e-03, fs:0.52941 (r=0.364,p=0.973),  time:564.101, tt:6205.115\n",
      "Ep:11, loss:0.00007, loss_test:0.17696, lr:4.00e-03, fs:0.55474 (r=0.384,p=1.000),  time:564.984, tt:6779.810\n",
      "Ep:12, loss:0.00005, loss_test:0.17736, lr:4.00e-03, fs:0.55474 (r=0.384,p=1.000),  time:566.960, tt:7370.480\n",
      "Ep:13, loss:0.00004, loss_test:0.18037, lr:4.00e-03, fs:0.50000 (r=0.333,p=1.000),  time:568.492, tt:7958.892\n",
      "Ep:14, loss:0.00003, loss_test:0.17985, lr:3.96e-03, fs:0.49624 (r=0.333,p=0.971),  time:569.931, tt:8548.958\n",
      "Ep:15, loss:0.00003, loss_test:0.18132, lr:3.92e-03, fs:0.50000 (r=0.333,p=1.000),  time:571.120, tt:9137.913\n",
      "Ep:16, loss:0.00003, loss_test:0.17921, lr:3.88e-03, fs:0.50000 (r=0.333,p=1.000),  time:571.921, tt:9722.656\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.13872, lr:4.00e-03, fs:0.66667 (r=0.990,p=0.503),  time:24.646, tt:24.646\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13524, lr:4.00e-03, fs:0.67354 (r=0.990,p=0.510),  time:24.606, tt:49.212\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.12925, lr:4.00e-03, fs:0.66197 (r=0.949,p=0.508),  time:24.719, tt:74.158\n",
      "Ep:3, loss:0.00051, loss_test:0.12059, lr:4.00e-03, fs:0.66165 (r=0.889,p=0.527),  time:24.642, tt:98.568\n",
      "Ep:4, loss:0.00049, loss_test:0.10872, lr:4.00e-03, fs:0.67841 (r=0.778,p=0.602),  time:24.624, tt:123.119\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.10136, lr:4.00e-03, fs:0.70142 (r=0.747,p=0.661),  time:24.598, tt:147.588\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.09815, lr:4.00e-03, fs:0.73059 (r=0.808,p=0.667),  time:24.631, tt:172.418\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.09204, lr:4.00e-03, fs:0.75000 (r=0.788,p=0.716),  time:24.654, tt:197.228\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00041, loss_test:0.08870, lr:4.00e-03, fs:0.77228 (r=0.788,p=0.757),  time:24.705, tt:222.349\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00039, loss_test:0.08545, lr:4.00e-03, fs:0.77295 (r=0.808,p=0.741),  time:24.702, tt:247.021\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00037, loss_test:0.08226, lr:4.00e-03, fs:0.78173 (r=0.778,p=0.786),  time:24.735, tt:272.083\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00036, loss_test:0.07955, lr:4.00e-03, fs:0.79188 (r=0.788,p=0.796),  time:24.753, tt:297.030\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.07770, lr:4.00e-03, fs:0.79592 (r=0.788,p=0.804),  time:24.773, tt:322.053\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00033, loss_test:0.07596, lr:4.00e-03, fs:0.79381 (r=0.778,p=0.811),  time:24.805, tt:347.275\n",
      "Ep:14, loss:0.00031, loss_test:0.07335, lr:4.00e-03, fs:0.80203 (r=0.798,p=0.806),  time:24.824, tt:372.357\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.07277, lr:4.00e-03, fs:0.81250 (r=0.788,p=0.839),  time:24.829, tt:397.265\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00029, loss_test:0.07050, lr:4.00e-03, fs:0.81443 (r=0.798,p=0.832),  time:24.829, tt:422.098\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00028, loss_test:0.06941, lr:4.00e-03, fs:0.85279 (r=0.848,p=0.857),  time:24.849, tt:447.287\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00027, loss_test:0.06896, lr:4.00e-03, fs:0.83770 (r=0.808,p=0.870),  time:24.850, tt:472.157\n",
      "Ep:19, loss:0.00026, loss_test:0.06611, lr:4.00e-03, fs:0.87129 (r=0.889,p=0.854),  time:24.858, tt:497.153\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00025, loss_test:0.06639, lr:4.00e-03, fs:0.84974 (r=0.828,p=0.872),  time:24.873, tt:522.333\n",
      "Ep:21, loss:0.00024, loss_test:0.06513, lr:4.00e-03, fs:0.87310 (r=0.869,p=0.878),  time:24.880, tt:547.368\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00023, loss_test:0.06419, lr:4.00e-03, fs:0.87879 (r=0.879,p=0.879),  time:24.881, tt:572.268\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00022, loss_test:0.06338, lr:4.00e-03, fs:0.85567 (r=0.838,p=0.874),  time:24.855, tt:596.516\n",
      "Ep:24, loss:0.00021, loss_test:0.06208, lr:4.00e-03, fs:0.84375 (r=0.818,p=0.871),  time:24.715, tt:617.878\n",
      "Ep:25, loss:0.00020, loss_test:0.06179, lr:4.00e-03, fs:0.84656 (r=0.808,p=0.889),  time:24.587, tt:639.253\n",
      "Ep:26, loss:0.00020, loss_test:0.06284, lr:4.00e-03, fs:0.85561 (r=0.808,p=0.909),  time:24.468, tt:660.644\n",
      "Ep:27, loss:0.00019, loss_test:0.05927, lr:4.00e-03, fs:0.84375 (r=0.818,p=0.871),  time:24.356, tt:681.972\n",
      "Ep:28, loss:0.00018, loss_test:0.05927, lr:4.00e-03, fs:0.86170 (r=0.818,p=0.910),  time:24.253, tt:703.347\n",
      "Ep:29, loss:0.00017, loss_test:0.05930, lr:4.00e-03, fs:0.86022 (r=0.808,p=0.920),  time:24.186, tt:725.586\n",
      "Ep:30, loss:0.00016, loss_test:0.05768, lr:4.00e-03, fs:0.87097 (r=0.818,p=0.931),  time:24.096, tt:746.985\n",
      "Ep:31, loss:0.00016, loss_test:0.05563, lr:4.00e-03, fs:0.86631 (r=0.818,p=0.920),  time:24.009, tt:768.301\n",
      "Ep:32, loss:0.00015, loss_test:0.05789, lr:4.00e-03, fs:0.86339 (r=0.798,p=0.940),  time:23.927, tt:789.595\n",
      "Ep:33, loss:0.00014, loss_test:0.05834, lr:4.00e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.885, tt:812.099\n",
      "Ep:34, loss:0.00014, loss_test:0.05214, lr:3.96e-03, fs:0.88298 (r=0.838,p=0.933),  time:23.943, tt:838.004\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.05596, lr:3.96e-03, fs:0.86813 (r=0.798,p=0.952),  time:24.001, tt:864.035\n",
      "Ep:36, loss:0.00013, loss_test:0.05885, lr:3.96e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.081, tt:890.991\n",
      "Ep:37, loss:0.00012, loss_test:0.05097, lr:3.96e-03, fs:0.88298 (r=0.838,p=0.933),  time:24.285, tt:922.842\n",
      "Ep:38, loss:0.00011, loss_test:0.05479, lr:3.96e-03, fs:0.87912 (r=0.808,p=0.964),  time:24.948, tt:972.957\n",
      "Ep:39, loss:0.00011, loss_test:0.05505, lr:3.96e-03, fs:0.87912 (r=0.808,p=0.964),  time:26.174, tt:1046.961\n",
      "Ep:40, loss:0.00010, loss_test:0.05081, lr:3.96e-03, fs:0.89130 (r=0.828,p=0.965),  time:27.551, tt:1129.604\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.05378, lr:3.96e-03, fs:0.87293 (r=0.798,p=0.963),  time:28.863, tt:1212.265\n",
      "Ep:42, loss:0.00009, loss_test:0.05374, lr:3.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:30.152, tt:1296.545\n",
      "Ep:43, loss:0.00009, loss_test:0.05122, lr:3.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:31.371, tt:1380.330\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.05092, lr:3.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:32.518, tt:1463.326\n",
      "Ep:45, loss:0.00008, loss_test:0.05110, lr:3.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:33.659, tt:1548.300\n",
      "Ep:46, loss:0.00007, loss_test:0.05239, lr:3.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:34.696, tt:1630.692\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.04994, lr:3.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.750, tt:1716.000\n",
      "Ep:48, loss:0.00007, loss_test:0.04907, lr:3.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.701, tt:1798.367\n",
      "Ep:49, loss:0.00006, loss_test:0.05169, lr:3.96e-03, fs:0.90710 (r=0.838,p=0.988),  time:37.646, tt:1882.315\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.05184, lr:3.96e-03, fs:0.90710 (r=0.838,p=0.988),  time:38.596, tt:1968.371\n",
      "Ep:51, loss:0.00006, loss_test:0.04720, lr:3.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:39.478, tt:2052.831\n",
      "Ep:52, loss:0.00005, loss_test:0.05031, lr:3.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:40.308, tt:2136.322\n",
      "Ep:53, loss:0.00005, loss_test:0.05115, lr:3.96e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.129, tt:2220.989\n",
      "Ep:54, loss:0.00005, loss_test:0.04846, lr:3.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:41.889, tt:2303.875\n",
      "Ep:55, loss:0.00005, loss_test:0.04639, lr:3.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:42.646, tt:2388.180\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00435, loss_test:0.11076, lr:4.00e-03, fs:0.69903 (r=0.727,p=0.673),  time:661.821, tt:661.821\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00300, loss_test:0.09350, lr:4.00e-03, fs:0.73797 (r=0.697,p=0.784),  time:710.272, tt:1420.545\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00215, loss_test:0.08754, lr:4.00e-03, fs:0.75138 (r=0.687,p=0.829),  time:726.943, tt:2180.828\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00157, loss_test:0.08461, lr:4.00e-03, fs:0.75862 (r=0.667,p=0.880),  time:734.014, tt:2936.055\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00114, loss_test:0.08417, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:736.989, tt:3684.943\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00081, loss_test:0.08497, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:738.237, tt:4429.421\n",
      "Ep:6, loss:0.00059, loss_test:0.08690, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:737.369, tt:5161.582\n",
      "Ep:7, loss:0.00043, loss_test:0.09203, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:735.960, tt:5887.679\n",
      "Ep:8, loss:0.00032, loss_test:0.09248, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:736.139, tt:6625.247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-94dc3bc778db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00383, loss_test:0.09625, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:406.247, tt:406.247\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00193, loss_test:0.08454, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:575.184, tt:1150.368\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00094, loss_test:0.09648, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:633.807, tt:1901.422\n",
      "Ep:3, loss:0.00050, loss_test:0.10010, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:662.034, tt:2648.137\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.09802, lr:1.00e-02, fs:0.78788 (r=0.657,p=0.985),  time:680.376, tt:3401.879\n",
      "Ep:5, loss:0.00014, loss_test:0.10587, lr:1.00e-02, fs:0.75000 (r=0.606,p=0.984),  time:689.750, tt:4138.499\n",
      "Ep:6, loss:0.00008, loss_test:0.10411, lr:1.00e-02, fs:0.75000 (r=0.606,p=0.984),  time:698.875, tt:4892.127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0472c9fc7a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00385, loss_test:0.09520, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:702.964, tt:702.964\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00211, loss_test:0.08167, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:725.737, tt:1451.474\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00108, loss_test:0.09439, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:734.901, tt:2204.704\n",
      "Ep:3, loss:0.00053, loss_test:0.10687, lr:1.00e-02, fs:0.72050 (r=0.586,p=0.935),  time:739.372, tt:2957.486\n",
      "Ep:4, loss:0.00029, loss_test:0.11932, lr:1.00e-02, fs:0.68831 (r=0.535,p=0.964),  time:743.779, tt:3718.896\n",
      "Ep:5, loss:0.00015, loss_test:0.13018, lr:1.00e-02, fs:0.69281 (r=0.535,p=0.981),  time:743.945, tt:4463.670\n",
      "Ep:6, loss:0.00007, loss_test:0.12798, lr:1.00e-02, fs:0.69281 (r=0.535,p=0.981),  time:744.554, tt:5211.879\n",
      "Ep:7, loss:0.00005, loss_test:0.12834, lr:1.00e-02, fs:0.69281 (r=0.535,p=0.981),  time:743.561, tt:5948.486\n",
      "Ep:8, loss:0.00003, loss_test:0.12549, lr:1.00e-02, fs:0.69281 (r=0.535,p=0.981),  time:742.327, tt:6680.945\n",
      "Ep:9, loss:0.00002, loss_test:0.13075, lr:1.00e-02, fs:0.64865 (r=0.485,p=0.980),  time:743.198, tt:7431.977\n",
      "Ep:10, loss:0.00002, loss_test:0.12747, lr:1.00e-02, fs:0.64865 (r=0.485,p=0.980),  time:743.269, tt:8175.956\n",
      "Ep:11, loss:0.00001, loss_test:0.12888, lr:1.00e-02, fs:0.64865 (r=0.485,p=0.980),  time:744.164, tt:8929.971\n",
      "Ep:12, loss:0.00001, loss_test:0.12738, lr:1.00e-02, fs:0.64865 (r=0.485,p=0.980),  time:745.384, tt:9689.997\n",
      "Ep:13, loss:0.00001, loss_test:0.12757, lr:9.90e-03, fs:0.64865 (r=0.485,p=0.980),  time:746.430, tt:10450.020\n",
      "Ep:14, loss:0.00001, loss_test:0.12479, lr:9.80e-03, fs:0.64865 (r=0.485,p=0.980),  time:747.873, tt:11218.095\n",
      "Ep:15, loss:0.00001, loss_test:0.12342, lr:9.70e-03, fs:0.70130 (r=0.545,p=0.982),  time:748.267, tt:11972.278\n",
      "Ep:16, loss:0.00001, loss_test:0.12571, lr:9.61e-03, fs:0.64865 (r=0.485,p=0.980),  time:748.985, tt:12732.737\n",
      "Ep:17, loss:0.00001, loss_test:0.12427, lr:9.51e-03, fs:0.70968 (r=0.556,p=0.982),  time:750.008, tt:13500.151\n",
      "Ep:18, loss:0.00001, loss_test:0.12405, lr:9.41e-03, fs:0.64865 (r=0.485,p=0.980),  time:750.418, tt:14257.934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14113, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.401, tt:10.401\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14074, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.125, tt:24.250\n",
      "Ep:2, loss:0.00004, loss_test:0.14016, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.522, tt:43.567\n",
      "Ep:3, loss:0.00004, loss_test:0.13938, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.631, tt:62.522\n",
      "Ep:4, loss:0.00004, loss_test:0.13838, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.503, tt:82.514\n",
      "Ep:5, loss:0.00004, loss_test:0.13712, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:16.929, tt:101.572\n",
      "Ep:6, loss:0.00004, loss_test:0.13554, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:17.097, tt:119.678\n",
      "Ep:7, loss:0.00004, loss_test:0.13359, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:17.348, tt:138.781\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.13116, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:17.480, tt:157.321\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.12823, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:17.708, tt:177.079\n",
      "Ep:10, loss:0.00004, loss_test:0.12503, lr:1.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:17.759, tt:195.348\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.12184, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:17.909, tt:214.907\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.11893, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:18.174, tt:236.255\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.11814, lr:1.00e-02, fs:0.68936 (r=0.818,p=0.596),  time:18.272, tt:255.811\n",
      "Ep:14, loss:0.00003, loss_test:0.11939, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:18.380, tt:275.706\n",
      "Ep:15, loss:0.00003, loss_test:0.12041, lr:1.00e-02, fs:0.61616 (r=0.616,p=0.616),  time:18.455, tt:295.285\n",
      "Ep:16, loss:0.00003, loss_test:0.12036, lr:1.00e-02, fs:0.60825 (r=0.596,p=0.621),  time:18.513, tt:314.715\n",
      "Ep:17, loss:0.00003, loss_test:0.11930, lr:1.00e-02, fs:0.60825 (r=0.596,p=0.621),  time:18.508, tt:333.140\n",
      "Ep:18, loss:0.00003, loss_test:0.11750, lr:1.00e-02, fs:0.63636 (r=0.636,p=0.636),  time:18.625, tt:353.878\n",
      "Ep:19, loss:0.00003, loss_test:0.11557, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:18.676, tt:373.525\n",
      "Ep:20, loss:0.00003, loss_test:0.11433, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:18.716, tt:393.038\n",
      "Ep:21, loss:0.00003, loss_test:0.11378, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:18.734, tt:412.145\n",
      "Ep:22, loss:0.00003, loss_test:0.11451, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:18.787, tt:432.094\n",
      "Ep:23, loss:0.00003, loss_test:0.11502, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:18.854, tt:452.485\n",
      "Ep:24, loss:0.00003, loss_test:0.11402, lr:9.90e-03, fs:0.66667 (r=0.646,p=0.688),  time:18.884, tt:472.092\n",
      "Ep:25, loss:0.00003, loss_test:0.11262, lr:9.80e-03, fs:0.66667 (r=0.667,p=0.667),  time:18.886, tt:491.038\n",
      "Ep:26, loss:0.00003, loss_test:0.11174, lr:9.70e-03, fs:0.67327 (r=0.687,p=0.660),  time:18.906, tt:510.469\n",
      "Ep:27, loss:0.00002, loss_test:0.11129, lr:9.61e-03, fs:0.68657 (r=0.697,p=0.676),  time:18.917, tt:529.680\n",
      "Ep:28, loss:0.00002, loss_test:0.11141, lr:9.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:18.964, tt:549.954\n",
      "Ep:29, loss:0.00002, loss_test:0.11149, lr:9.41e-03, fs:0.72251 (r=0.697,p=0.750),  time:18.977, tt:569.305\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.11077, lr:9.41e-03, fs:0.71503 (r=0.697,p=0.734),  time:19.013, tt:589.399\n",
      "Ep:31, loss:0.00002, loss_test:0.10999, lr:9.41e-03, fs:0.71429 (r=0.707,p=0.722),  time:19.027, tt:608.866\n",
      "Ep:32, loss:0.00002, loss_test:0.10939, lr:9.41e-03, fs:0.70707 (r=0.707,p=0.707),  time:19.051, tt:628.679\n",
      "Ep:33, loss:0.00002, loss_test:0.10889, lr:9.41e-03, fs:0.72165 (r=0.707,p=0.737),  time:19.070, tt:648.393\n",
      "Ep:34, loss:0.00002, loss_test:0.10815, lr:9.41e-03, fs:0.72917 (r=0.707,p=0.753),  time:19.108, tt:668.764\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.10690, lr:9.41e-03, fs:0.72821 (r=0.717,p=0.740),  time:19.132, tt:688.760\n",
      "Ep:36, loss:0.00002, loss_test:0.10606, lr:9.41e-03, fs:0.72727 (r=0.727,p=0.727),  time:19.098, tt:706.644\n",
      "Ep:37, loss:0.00002, loss_test:0.10555, lr:9.41e-03, fs:0.73469 (r=0.727,p=0.742),  time:19.074, tt:724.828\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.10517, lr:9.41e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.070, tt:743.723\n",
      "Ep:39, loss:0.00002, loss_test:0.10454, lr:9.41e-03, fs:0.72917 (r=0.707,p=0.753),  time:19.083, tt:763.313\n",
      "Ep:40, loss:0.00002, loss_test:0.10348, lr:9.41e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.111, tt:783.548\n",
      "Ep:41, loss:0.00002, loss_test:0.10268, lr:9.41e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.127, tt:803.351\n",
      "Ep:42, loss:0.00002, loss_test:0.10205, lr:9.41e-03, fs:0.72251 (r=0.697,p=0.750),  time:19.125, tt:822.354\n",
      "Ep:43, loss:0.00002, loss_test:0.10140, lr:9.41e-03, fs:0.72251 (r=0.697,p=0.750),  time:19.133, tt:841.840\n",
      "Ep:44, loss:0.00002, loss_test:0.10062, lr:9.41e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.106, tt:859.783\n",
      "Ep:45, loss:0.00002, loss_test:0.09993, lr:9.41e-03, fs:0.71503 (r=0.697,p=0.734),  time:19.115, tt:879.268\n",
      "Ep:46, loss:0.00002, loss_test:0.09937, lr:9.41e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.131, tt:899.160\n",
      "Ep:47, loss:0.00002, loss_test:0.09877, lr:9.41e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.170, tt:920.167\n",
      "Ep:48, loss:0.00002, loss_test:0.09793, lr:9.41e-03, fs:0.71503 (r=0.697,p=0.734),  time:19.167, tt:939.182\n",
      "Ep:49, loss:0.00002, loss_test:0.09729, lr:9.32e-03, fs:0.70833 (r=0.687,p=0.731),  time:19.158, tt:957.905\n",
      "Ep:50, loss:0.00002, loss_test:0.09670, lr:9.23e-03, fs:0.71204 (r=0.687,p=0.739),  time:19.185, tt:978.429\n",
      "Ep:51, loss:0.00001, loss_test:0.09570, lr:9.14e-03, fs:0.70833 (r=0.687,p=0.731),  time:19.167, tt:996.692\n",
      "Ep:52, loss:0.00001, loss_test:0.09489, lr:9.04e-03, fs:0.71134 (r=0.697,p=0.726),  time:19.172, tt:1016.090\n",
      "Ep:53, loss:0.00001, loss_test:0.09440, lr:8.95e-03, fs:0.70466 (r=0.687,p=0.723),  time:19.174, tt:1035.386\n",
      "Ep:54, loss:0.00001, loss_test:0.09376, lr:8.86e-03, fs:0.71134 (r=0.697,p=0.726),  time:19.198, tt:1055.866\n",
      "Ep:55, loss:0.00001, loss_test:0.09342, lr:8.78e-03, fs:0.71134 (r=0.697,p=0.726),  time:19.188, tt:1074.534\n",
      "Ep:56, loss:0.00001, loss_test:0.09334, lr:8.69e-03, fs:0.70466 (r=0.687,p=0.723),  time:19.166, tt:1092.485\n",
      "Ep:57, loss:0.00001, loss_test:0.09259, lr:8.60e-03, fs:0.70408 (r=0.697,p=0.711),  time:19.183, tt:1112.640\n",
      "Ep:58, loss:0.00001, loss_test:0.09211, lr:8.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:19.228, tt:1134.445\n",
      "Ep:59, loss:0.00001, loss_test:0.09224, lr:8.43e-03, fs:0.73404 (r=0.697,p=0.775),  time:19.245, tt:1154.693\n",
      "Ep:60, loss:0.00001, loss_test:0.09187, lr:8.35e-03, fs:0.73016 (r=0.697,p=0.767),  time:19.251, tt:1174.281\n",
      "Ep:61, loss:0.00001, loss_test:0.09116, lr:8.26e-03, fs:0.72251 (r=0.697,p=0.750),  time:19.253, tt:1193.685\n",
      "Ep:62, loss:0.00001, loss_test:0.09118, lr:8.18e-03, fs:0.73224 (r=0.677,p=0.798),  time:19.269, tt:1213.975\n",
      "Ep:63, loss:0.00001, loss_test:0.09056, lr:8.10e-03, fs:0.72432 (r=0.677,p=0.779),  time:19.290, tt:1234.530\n",
      "Ep:64, loss:0.00001, loss_test:0.08996, lr:8.02e-03, fs:0.71204 (r=0.687,p=0.739),  time:19.313, tt:1255.353\n",
      "Ep:65, loss:0.00001, loss_test:0.09044, lr:7.94e-03, fs:0.74033 (r=0.677,p=0.817),  time:19.324, tt:1275.368\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.09024, lr:7.94e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.335, tt:1295.472\n",
      "Ep:67, loss:0.00001, loss_test:0.08922, lr:7.94e-03, fs:0.73118 (r=0.687,p=0.782),  time:19.329, tt:1314.362\n",
      "Ep:68, loss:0.00001, loss_test:0.08911, lr:7.94e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.299, tt:1331.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.08896, lr:7.94e-03, fs:0.72928 (r=0.667,p=0.805),  time:19.316, tt:1352.153\n",
      "Ep:70, loss:0.00001, loss_test:0.08842, lr:7.94e-03, fs:0.73626 (r=0.677,p=0.807),  time:19.321, tt:1371.780\n",
      "Ep:71, loss:0.00001, loss_test:0.08804, lr:7.94e-03, fs:0.73514 (r=0.687,p=0.791),  time:19.316, tt:1390.778\n",
      "Ep:72, loss:0.00001, loss_test:0.08868, lr:7.94e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.341, tt:1411.865\n",
      "Ep:73, loss:0.00001, loss_test:0.08840, lr:7.94e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.357, tt:1432.455\n",
      "Ep:74, loss:0.00001, loss_test:0.08738, lr:7.94e-03, fs:0.73224 (r=0.677,p=0.798),  time:19.368, tt:1452.602\n",
      "Ep:75, loss:0.00001, loss_test:0.08752, lr:7.94e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.376, tt:1472.543\n",
      "Ep:76, loss:0.00001, loss_test:0.08737, lr:7.94e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.396, tt:1493.471\n",
      "Ep:77, loss:0.00001, loss_test:0.08655, lr:7.86e-03, fs:0.73626 (r=0.677,p=0.807),  time:19.407, tt:1513.775\n",
      "Ep:78, loss:0.00001, loss_test:0.08661, lr:7.78e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.415, tt:1533.754\n",
      "Ep:79, loss:0.00001, loss_test:0.08660, lr:7.70e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.418, tt:1553.441\n",
      "Ep:80, loss:0.00001, loss_test:0.08637, lr:7.62e-03, fs:0.74444 (r=0.677,p=0.827),  time:19.417, tt:1572.744\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.08639, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.446, tt:1594.593\n",
      "Ep:82, loss:0.00001, loss_test:0.08603, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.449, tt:1614.276\n",
      "Ep:83, loss:0.00001, loss_test:0.08679, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.453, tt:1634.091\n",
      "Ep:84, loss:0.00001, loss_test:0.08681, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.457, tt:1653.851\n",
      "Ep:85, loss:0.00001, loss_test:0.08603, lr:7.62e-03, fs:0.74033 (r=0.677,p=0.817),  time:19.466, tt:1674.105\n",
      "Ep:86, loss:0.00001, loss_test:0.08610, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.476, tt:1694.408\n",
      "Ep:87, loss:0.00001, loss_test:0.08581, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.472, tt:1713.527\n",
      "Ep:88, loss:0.00001, loss_test:0.08583, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.480, tt:1733.699\n",
      "Ep:89, loss:0.00001, loss_test:0.08595, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.476, tt:1752.870\n",
      "Ep:90, loss:0.00001, loss_test:0.08585, lr:7.62e-03, fs:0.74444 (r=0.677,p=0.827),  time:19.475, tt:1772.190\n",
      "Ep:91, loss:0.00001, loss_test:0.08610, lr:7.62e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.498, tt:1793.782\n",
      "Ep:92, loss:0.00001, loss_test:0.08579, lr:7.55e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.483, tt:1811.945\n",
      "Ep:93, loss:0.00001, loss_test:0.08571, lr:7.47e-03, fs:0.72928 (r=0.667,p=0.805),  time:19.477, tt:1830.810\n",
      "Ep:94, loss:0.00001, loss_test:0.08664, lr:7.40e-03, fs:0.74576 (r=0.667,p=0.846),  time:19.477, tt:1850.348\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.08672, lr:7.40e-03, fs:0.74576 (r=0.667,p=0.846),  time:19.464, tt:1868.512\n",
      "Ep:96, loss:0.00001, loss_test:0.08592, lr:7.40e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.461, tt:1887.723\n",
      "Ep:97, loss:0.00001, loss_test:0.08542, lr:7.40e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.466, tt:1907.694\n",
      "Ep:98, loss:0.00001, loss_test:0.08583, lr:7.40e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.480, tt:1928.562\n",
      "Ep:99, loss:0.00001, loss_test:0.08628, lr:7.40e-03, fs:0.74576 (r=0.667,p=0.846),  time:19.471, tt:1947.076\n",
      "Ep:100, loss:0.00001, loss_test:0.08578, lr:7.40e-03, fs:0.73743 (r=0.667,p=0.825),  time:19.478, tt:1967.324\n",
      "Ep:101, loss:0.00001, loss_test:0.08547, lr:7.40e-03, fs:0.74576 (r=0.667,p=0.846),  time:19.472, tt:1986.187\n",
      "Ep:102, loss:0.00001, loss_test:0.08545, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.474, tt:2005.850\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.08590, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.476, tt:2025.543\n",
      "Ep:104, loss:0.00001, loss_test:0.08590, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.478, tt:2045.193\n",
      "Ep:105, loss:0.00001, loss_test:0.08518, lr:7.40e-03, fs:0.74576 (r=0.667,p=0.846),  time:19.479, tt:2064.825\n",
      "Ep:106, loss:0.00001, loss_test:0.08569, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.489, tt:2085.307\n",
      "Ep:107, loss:0.00001, loss_test:0.08619, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.521, tt:2108.270\n",
      "Ep:108, loss:0.00001, loss_test:0.08567, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.528, tt:2128.526\n",
      "Ep:109, loss:0.00001, loss_test:0.08582, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.523, tt:2147.553\n",
      "Ep:110, loss:0.00001, loss_test:0.08681, lr:7.40e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.525, tt:2167.231\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.08676, lr:7.40e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.524, tt:2186.741\n",
      "Ep:112, loss:0.00001, loss_test:0.08545, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.529, tt:2206.781\n",
      "Ep:113, loss:0.00001, loss_test:0.08464, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.536, tt:2227.064\n",
      "Ep:114, loss:0.00001, loss_test:0.08569, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.531, tt:2246.111\n",
      "Ep:115, loss:0.00001, loss_test:0.08593, lr:7.40e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.528, tt:2265.218\n",
      "Ep:116, loss:0.00001, loss_test:0.08486, lr:7.40e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.519, tt:2283.685\n",
      "Ep:117, loss:0.00001, loss_test:0.08478, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.557, tt:2307.692\n",
      "Ep:118, loss:0.00001, loss_test:0.08592, lr:7.40e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.551, tt:2326.555\n",
      "Ep:119, loss:0.00000, loss_test:0.08625, lr:7.40e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.555, tt:2346.628\n",
      "Ep:120, loss:0.00000, loss_test:0.08540, lr:7.40e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.549, tt:2365.382\n",
      "Ep:121, loss:0.00000, loss_test:0.08496, lr:7.40e-03, fs:0.74576 (r=0.667,p=0.846),  time:19.555, tt:2385.677\n",
      "Ep:122, loss:0.00000, loss_test:0.08671, lr:7.32e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.555, tt:2405.318\n",
      "Ep:123, loss:0.00000, loss_test:0.08659, lr:7.25e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.557, tt:2425.064\n",
      "Ep:124, loss:0.00000, loss_test:0.08553, lr:7.18e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.548, tt:2443.481\n",
      "Ep:125, loss:0.00000, loss_test:0.08449, lr:7.11e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.540, tt:2462.071\n",
      "Ep:126, loss:0.00000, loss_test:0.08617, lr:7.03e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.534, tt:2480.825\n",
      "Ep:127, loss:0.00000, loss_test:0.08710, lr:6.96e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.538, tt:2500.882\n",
      "Ep:128, loss:0.00000, loss_test:0.08590, lr:6.89e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.530, tt:2519.412\n",
      "Ep:129, loss:0.00000, loss_test:0.08394, lr:6.83e-03, fs:0.75000 (r=0.667,p=0.857),  time:19.523, tt:2537.991\n",
      "Ep:130, loss:0.00000, loss_test:0.08422, lr:6.76e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.518, tt:2556.843\n",
      "Ep:131, loss:0.00000, loss_test:0.08644, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.521, tt:2576.758\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00000, loss_test:0.08744, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.511, tt:2594.904\n",
      "Ep:133, loss:0.00000, loss_test:0.08676, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.517, tt:2615.319\n",
      "Ep:134, loss:0.00000, loss_test:0.08482, lr:6.69e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.522, tt:2635.405\n",
      "Ep:135, loss:0.00000, loss_test:0.08446, lr:6.69e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.529, tt:2655.877\n",
      "Ep:136, loss:0.00000, loss_test:0.08559, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.530, tt:2675.631\n",
      "Ep:137, loss:0.00000, loss_test:0.08614, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.537, tt:2696.173\n",
      "Ep:138, loss:0.00000, loss_test:0.08529, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.543, tt:2716.469\n",
      "Ep:139, loss:0.00000, loss_test:0.08404, lr:6.69e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.542, tt:2735.825\n",
      "Ep:140, loss:0.00000, loss_test:0.08389, lr:6.69e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.538, tt:2754.828\n",
      "Ep:141, loss:0.00000, loss_test:0.08479, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.545, tt:2775.459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.08513, lr:6.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.548, tt:2795.325\n",
      "Ep:143, loss:0.00000, loss_test:0.08471, lr:6.62e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.555, tt:2815.863\n",
      "Ep:144, loss:0.00000, loss_test:0.08372, lr:6.56e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.554, tt:2835.397\n",
      "Ep:145, loss:0.00000, loss_test:0.08414, lr:6.49e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.562, tt:2855.991\n",
      "Ep:146, loss:0.00000, loss_test:0.08477, lr:6.43e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.556, tt:2874.803\n",
      "Ep:147, loss:0.00000, loss_test:0.08461, lr:6.36e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.560, tt:2894.862\n",
      "Ep:148, loss:0.00000, loss_test:0.08379, lr:6.30e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.562, tt:2914.798\n",
      "Ep:149, loss:0.00000, loss_test:0.08356, lr:6.24e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.559, tt:2933.825\n",
      "Ep:150, loss:0.00000, loss_test:0.08444, lr:6.17e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.613, tt:2961.508\n",
      "Ep:151, loss:0.00000, loss_test:0.08427, lr:6.11e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.608, tt:2980.454\n",
      "Ep:152, loss:0.00000, loss_test:0.08424, lr:6.05e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.612, tt:3000.703\n",
      "Ep:153, loss:0.00000, loss_test:0.08351, lr:5.99e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.623, tt:3021.914\n",
      "Ep:154, loss:0.00000, loss_test:0.08324, lr:5.93e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.626, tt:3042.048\n",
      "Ep:155, loss:0.00000, loss_test:0.08428, lr:5.87e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.635, tt:3063.047\n",
      "Ep:156, loss:0.00000, loss_test:0.08442, lr:5.81e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.636, tt:3082.889\n",
      "Ep:157, loss:0.00000, loss_test:0.08360, lr:5.75e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.636, tt:3102.449\n",
      "Ep:158, loss:0.00000, loss_test:0.08309, lr:5.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.637, tt:3122.219\n",
      "Ep:159, loss:0.00000, loss_test:0.08335, lr:5.64e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.639, tt:3142.195\n",
      "Ep:160, loss:0.00000, loss_test:0.08354, lr:5.58e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.649, tt:3163.485\n",
      "Ep:161, loss:0.00000, loss_test:0.08389, lr:5.53e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.654, tt:3183.873\n",
      "Ep:162, loss:0.00000, loss_test:0.08354, lr:5.47e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.645, tt:3202.214\n",
      "Ep:163, loss:0.00000, loss_test:0.08310, lr:5.42e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.645, tt:3221.769\n",
      "Ep:164, loss:0.00000, loss_test:0.08316, lr:5.36e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.642, tt:3240.977\n",
      "Ep:165, loss:0.00000, loss_test:0.08323, lr:5.31e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.640, tt:3260.279\n",
      "Ep:166, loss:0.00000, loss_test:0.08341, lr:5.26e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.643, tt:3280.334\n",
      "Ep:167, loss:0.00000, loss_test:0.08316, lr:5.20e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.644, tt:3300.182\n",
      "Ep:168, loss:0.00000, loss_test:0.08284, lr:5.15e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.638, tt:3318.804\n",
      "Ep:169, loss:0.00000, loss_test:0.08375, lr:5.10e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.632, tt:3337.374\n",
      "Ep:170, loss:0.00000, loss_test:0.08411, lr:5.05e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.633, tt:3357.222\n",
      "Ep:171, loss:0.00000, loss_test:0.08364, lr:5.00e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.639, tt:3377.919\n",
      "Ep:172, loss:0.00000, loss_test:0.08383, lr:4.95e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.642, tt:3397.998\n",
      "Ep:173, loss:0.00000, loss_test:0.08367, lr:4.90e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.653, tt:3419.665\n",
      "Ep:174, loss:0.00000, loss_test:0.08349, lr:4.85e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.654, tt:3439.398\n",
      "Ep:175, loss:0.00000, loss_test:0.08352, lr:4.80e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.651, tt:3458.611\n",
      "Ep:176, loss:0.00000, loss_test:0.08439, lr:4.75e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.657, tt:3479.342\n",
      "Ep:177, loss:0.00000, loss_test:0.08456, lr:4.71e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.662, tt:3499.918\n",
      "Ep:178, loss:0.00000, loss_test:0.08392, lr:4.66e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.664, tt:3519.849\n",
      "Ep:179, loss:0.00000, loss_test:0.08371, lr:4.61e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.674, tt:3541.264\n",
      "Ep:180, loss:0.00000, loss_test:0.08423, lr:4.57e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.673, tt:3560.894\n",
      "Ep:181, loss:0.00000, loss_test:0.08413, lr:4.52e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.680, tt:3581.793\n",
      "Ep:182, loss:0.00000, loss_test:0.08365, lr:4.48e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.683, tt:3601.924\n",
      "Ep:183, loss:0.00000, loss_test:0.08384, lr:4.43e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.686, tt:3622.148\n",
      "Ep:184, loss:0.00000, loss_test:0.08371, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.687, tt:3642.102\n",
      "##########Best model found so far##########\n",
      "Ep:185, loss:0.00000, loss_test:0.08324, lr:4.39e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.685, tt:3661.370\n",
      "Ep:186, loss:0.00000, loss_test:0.08362, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.687, tt:3681.530\n",
      "Ep:187, loss:0.00000, loss_test:0.08360, lr:4.39e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.690, tt:3701.657\n",
      "Ep:188, loss:0.00000, loss_test:0.08336, lr:4.39e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.692, tt:3721.852\n",
      "Ep:189, loss:0.00000, loss_test:0.08313, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.703, tt:3743.534\n",
      "Ep:190, loss:0.00000, loss_test:0.08338, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.704, tt:3763.377\n",
      "Ep:191, loss:0.00000, loss_test:0.08306, lr:4.39e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.715, tt:3785.249\n",
      "Ep:192, loss:0.00000, loss_test:0.08381, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.722, tt:3806.379\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00000, loss_test:0.08393, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.727, tt:3827.051\n",
      "Ep:194, loss:0.00000, loss_test:0.08328, lr:4.39e-03, fs:0.75862 (r=0.667,p=0.880),  time:19.726, tt:3846.542\n",
      "Ep:195, loss:0.00000, loss_test:0.08350, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.731, tt:3867.320\n",
      "Ep:196, loss:0.00000, loss_test:0.08333, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.730, tt:3886.904\n",
      "Ep:197, loss:0.00000, loss_test:0.08341, lr:4.39e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.733, tt:3907.070\n",
      "Ep:198, loss:0.00000, loss_test:0.08365, lr:4.39e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.729, tt:3926.070\n",
      "Ep:199, loss:0.00000, loss_test:0.08405, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.735, tt:3946.921\n",
      "Ep:200, loss:0.00000, loss_test:0.08381, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.733, tt:3966.365\n",
      "Ep:201, loss:0.00000, loss_test:0.08318, lr:4.39e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.733, tt:3986.128\n",
      "Ep:202, loss:0.00000, loss_test:0.08418, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.730, tt:4005.207\n",
      "Ep:203, loss:0.00000, loss_test:0.08453, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.730, tt:4024.946\n",
      "Ep:204, loss:0.00000, loss_test:0.08408, lr:4.34e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.734, tt:4045.451\n",
      "Ep:205, loss:0.00000, loss_test:0.08339, lr:4.30e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.740, tt:4066.380\n",
      "Ep:206, loss:0.00000, loss_test:0.08399, lr:4.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.737, tt:4085.485\n",
      "Ep:207, loss:0.00000, loss_test:0.08423, lr:4.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.733, tt:4104.359\n",
      "Ep:208, loss:0.00000, loss_test:0.08410, lr:4.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.734, tt:4124.349\n",
      "Ep:209, loss:0.00000, loss_test:0.08376, lr:4.13e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.735, tt:4144.316\n",
      "Ep:210, loss:0.00000, loss_test:0.08418, lr:4.09e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.736, tt:4164.365\n",
      "Ep:211, loss:0.00000, loss_test:0.08423, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.735, tt:4183.856\n",
      "Ep:212, loss:0.00000, loss_test:0.08402, lr:4.01e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.725, tt:4201.422\n",
      "Ep:213, loss:0.00000, loss_test:0.08349, lr:3.97e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.729, tt:4221.978\n",
      "Ep:214, loss:0.00000, loss_test:0.08460, lr:3.93e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.731, tt:4242.254\n",
      "Ep:215, loss:0.00000, loss_test:0.08515, lr:3.89e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.730, tt:4261.768\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:216, loss:0.00000, loss_test:0.08499, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.736, tt:4282.684\n",
      "Ep:217, loss:0.00000, loss_test:0.08433, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.728, tt:4300.786\n",
      "Ep:218, loss:0.00000, loss_test:0.08376, lr:3.89e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.722, tt:4319.068\n",
      "Ep:219, loss:0.00000, loss_test:0.08437, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.718, tt:4337.897\n",
      "Ep:220, loss:0.00000, loss_test:0.08471, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.717, tt:4357.506\n",
      "Ep:221, loss:0.00000, loss_test:0.08467, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.711, tt:4375.809\n",
      "Ep:222, loss:0.00000, loss_test:0.08402, lr:3.89e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.715, tt:4396.440\n",
      "Ep:223, loss:0.00000, loss_test:0.08388, lr:3.89e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.712, tt:4415.447\n",
      "Ep:224, loss:0.00000, loss_test:0.08447, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.712, tt:4435.203\n",
      "Ep:225, loss:0.00000, loss_test:0.08457, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.710, tt:4454.453\n",
      "Ep:226, loss:0.00000, loss_test:0.08420, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.713, tt:4474.764\n",
      "Ep:227, loss:0.00000, loss_test:0.08371, lr:3.85e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.712, tt:4494.430\n",
      "Ep:228, loss:0.00000, loss_test:0.08461, lr:3.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.709, tt:4513.286\n",
      "Ep:229, loss:0.00000, loss_test:0.08478, lr:3.77e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.708, tt:4532.826\n",
      "Ep:230, loss:0.00000, loss_test:0.08434, lr:3.73e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.709, tt:4552.805\n",
      "Ep:231, loss:0.00000, loss_test:0.08374, lr:3.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.710, tt:4572.755\n",
      "Ep:232, loss:0.00000, loss_test:0.08375, lr:3.66e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.712, tt:4592.794\n",
      "Ep:233, loss:0.00000, loss_test:0.08420, lr:3.62e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.716, tt:4613.508\n",
      "Ep:234, loss:0.00000, loss_test:0.08407, lr:3.59e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.713, tt:4632.511\n",
      "Ep:235, loss:0.00000, loss_test:0.08379, lr:3.55e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.714, tt:4652.425\n",
      "Ep:236, loss:0.00000, loss_test:0.08361, lr:3.52e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.716, tt:4672.604\n",
      "Ep:237, loss:0.00000, loss_test:0.08437, lr:3.48e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.716, tt:4692.483\n",
      "Ep:238, loss:0.00000, loss_test:0.08436, lr:3.45e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.717, tt:4712.359\n",
      "Ep:239, loss:0.00000, loss_test:0.08403, lr:3.41e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.723, tt:4733.409\n",
      "Ep:240, loss:0.00000, loss_test:0.08373, lr:3.38e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.728, tt:4754.332\n",
      "Ep:241, loss:0.00000, loss_test:0.08391, lr:3.34e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.728, tt:4774.086\n",
      "Ep:242, loss:0.00000, loss_test:0.08430, lr:3.31e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.728, tt:4793.972\n",
      "Ep:243, loss:0.00000, loss_test:0.08419, lr:3.28e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.726, tt:4813.211\n",
      "Ep:244, loss:0.00000, loss_test:0.08387, lr:3.24e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.727, tt:4833.209\n",
      "Ep:245, loss:0.00000, loss_test:0.08357, lr:3.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.728, tt:4853.000\n",
      "Ep:246, loss:0.00000, loss_test:0.08421, lr:3.18e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.729, tt:4872.954\n",
      "Ep:247, loss:0.00000, loss_test:0.08433, lr:3.15e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.737, tt:4894.774\n",
      "Ep:248, loss:0.00000, loss_test:0.08421, lr:3.12e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.743, tt:4916.074\n",
      "Ep:249, loss:0.00000, loss_test:0.08391, lr:3.09e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.750, tt:4937.409\n",
      "Ep:250, loss:0.00000, loss_test:0.08394, lr:3.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.754, tt:4958.147\n",
      "Ep:251, loss:0.00000, loss_test:0.08399, lr:3.02e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.757, tt:4978.641\n",
      "Ep:252, loss:0.00000, loss_test:0.08398, lr:2.99e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.760, tt:4999.203\n",
      "Ep:253, loss:0.00000, loss_test:0.08356, lr:2.96e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.758, tt:5018.535\n",
      "Ep:254, loss:0.00000, loss_test:0.08369, lr:2.93e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.762, tt:5039.242\n",
      "Ep:255, loss:0.00000, loss_test:0.08401, lr:2.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.774, tt:5062.066\n",
      "Ep:256, loss:0.00000, loss_test:0.08385, lr:2.88e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.775, tt:5082.180\n",
      "Ep:257, loss:0.00000, loss_test:0.08367, lr:2.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.781, tt:5103.442\n",
      "Ep:258, loss:0.00000, loss_test:0.08380, lr:2.82e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.778, tt:5122.598\n",
      "Ep:259, loss:0.00000, loss_test:0.08404, lr:2.79e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.780, tt:5142.857\n",
      "Ep:260, loss:0.00000, loss_test:0.08384, lr:2.76e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.780, tt:5162.694\n",
      "Ep:261, loss:0.00000, loss_test:0.08350, lr:2.73e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.782, tt:5182.865\n",
      "Ep:262, loss:0.00000, loss_test:0.08385, lr:2.71e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.785, tt:5203.565\n",
      "Ep:263, loss:0.00000, loss_test:0.08397, lr:2.68e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.784, tt:5222.905\n",
      "Ep:264, loss:0.00000, loss_test:0.08376, lr:2.65e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.783, tt:5242.589\n",
      "Ep:265, loss:0.00000, loss_test:0.08379, lr:2.63e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.788, tt:5263.503\n",
      "Ep:266, loss:0.00000, loss_test:0.08385, lr:2.60e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.783, tt:5281.971\n",
      "Ep:267, loss:0.00000, loss_test:0.08383, lr:2.57e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.782, tt:5301.515\n",
      "Ep:268, loss:0.00000, loss_test:0.08375, lr:2.55e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.787, tt:5322.589\n",
      "Ep:269, loss:0.00000, loss_test:0.08387, lr:2.52e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.784, tt:5341.696\n",
      "Ep:270, loss:0.00000, loss_test:0.08372, lr:2.50e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.782, tt:5360.968\n",
      "Ep:271, loss:0.00000, loss_test:0.08356, lr:2.47e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.776, tt:5379.051\n",
      "Ep:272, loss:0.00000, loss_test:0.08409, lr:2.45e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.779, tt:5399.612\n",
      "Ep:273, loss:0.00000, loss_test:0.08409, lr:2.42e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.781, tt:5419.935\n",
      "Ep:274, loss:0.00000, loss_test:0.08382, lr:2.40e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.781, tt:5439.895\n",
      "Ep:275, loss:0.00000, loss_test:0.08370, lr:2.38e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.783, tt:5460.118\n",
      "Ep:276, loss:0.00000, loss_test:0.08373, lr:2.35e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.784, tt:5480.160\n",
      "Ep:277, loss:0.00000, loss_test:0.08362, lr:2.33e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.785, tt:5500.315\n",
      "Ep:278, loss:0.00000, loss_test:0.08367, lr:2.31e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.786, tt:5520.271\n",
      "Ep:279, loss:0.00000, loss_test:0.08364, lr:2.28e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.788, tt:5540.600\n",
      "Ep:280, loss:0.00000, loss_test:0.08383, lr:2.26e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.789, tt:5560.702\n",
      "Ep:281, loss:0.00000, loss_test:0.08373, lr:2.24e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.785, tt:5579.407\n",
      "Ep:282, loss:0.00000, loss_test:0.08376, lr:2.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.786, tt:5599.382\n",
      "Ep:283, loss:0.00000, loss_test:0.08352, lr:2.19e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.786, tt:5619.319\n",
      "Ep:284, loss:0.00000, loss_test:0.08346, lr:2.17e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.786, tt:5638.936\n",
      "Ep:285, loss:0.00000, loss_test:0.08355, lr:2.15e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.785, tt:5658.506\n",
      "Ep:286, loss:0.00000, loss_test:0.08386, lr:2.13e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.785, tt:5678.215\n",
      "Ep:287, loss:0.00000, loss_test:0.08388, lr:2.11e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.785, tt:5698.151\n",
      "Ep:288, loss:0.00000, loss_test:0.08369, lr:2.08e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.787, tt:5718.362\n",
      "Ep:289, loss:0.00000, loss_test:0.08374, lr:2.06e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.787, tt:5738.310\n",
      "Ep:290, loss:0.00000, loss_test:0.08358, lr:2.04e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.787, tt:5757.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:291, loss:0.00000, loss_test:0.08347, lr:2.02e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.791, tt:5779.029\n",
      "Ep:292, loss:0.00000, loss_test:0.08341, lr:2.00e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.787, tt:5797.585\n",
      "Ep:293, loss:0.00000, loss_test:0.08361, lr:1.98e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.782, tt:5816.010\n",
      "Ep:294, loss:0.00000, loss_test:0.08394, lr:1.96e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.787, tt:5837.233\n",
      "Ep:295, loss:0.00000, loss_test:0.08403, lr:1.94e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.784, tt:5856.159\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13576, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:8.155, tt:8.155\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13497, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:8.845, tt:17.690\n",
      "Ep:2, loss:0.00004, loss_test:0.13374, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:11.232, tt:33.697\n",
      "Ep:3, loss:0.00004, loss_test:0.13205, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:13.156, tt:52.623\n",
      "Ep:4, loss:0.00004, loss_test:0.12991, lr:1.00e-02, fs:0.67857 (r=0.960,p=0.525),  time:14.217, tt:71.086\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.12753, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:14.655, tt:87.927\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.12501, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:15.165, tt:106.155\n",
      "Ep:7, loss:0.00004, loss_test:0.12282, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:15.573, tt:124.584\n",
      "Ep:8, loss:0.00004, loss_test:0.12120, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:15.950, tt:143.551\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.12018, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:16.196, tt:161.965\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.12012, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:16.350, tt:179.849\n",
      "Ep:11, loss:0.00004, loss_test:0.11991, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:16.517, tt:198.201\n",
      "Ep:12, loss:0.00004, loss_test:0.11958, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:16.647, tt:216.416\n",
      "Ep:13, loss:0.00003, loss_test:0.11898, lr:1.00e-02, fs:0.69264 (r=0.808,p=0.606),  time:16.737, tt:234.313\n",
      "Ep:14, loss:0.00003, loss_test:0.11821, lr:1.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:16.823, tt:252.350\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.11741, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:16.878, tt:270.042\n",
      "Ep:16, loss:0.00003, loss_test:0.11670, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:16.931, tt:287.825\n",
      "Ep:17, loss:0.00003, loss_test:0.11624, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:17.009, tt:306.170\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.11624, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:17.080, tt:324.514\n",
      "Ep:19, loss:0.00003, loss_test:0.11659, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:17.169, tt:343.376\n",
      "Ep:20, loss:0.00003, loss_test:0.11679, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:17.159, tt:360.332\n",
      "Ep:21, loss:0.00003, loss_test:0.11637, lr:1.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:17.213, tt:378.696\n",
      "Ep:22, loss:0.00003, loss_test:0.11558, lr:1.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:17.234, tt:396.376\n",
      "Ep:23, loss:0.00003, loss_test:0.11481, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:17.273, tt:414.559\n",
      "Ep:24, loss:0.00003, loss_test:0.11430, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:17.366, tt:434.146\n",
      "Ep:25, loss:0.00003, loss_test:0.11405, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:17.415, tt:452.784\n",
      "Ep:26, loss:0.00003, loss_test:0.11361, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:17.417, tt:470.251\n",
      "Ep:27, loss:0.00003, loss_test:0.11289, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:17.506, tt:490.167\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.11193, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:17.547, tt:508.868\n",
      "Ep:29, loss:0.00003, loss_test:0.11072, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:17.543, tt:526.295\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.10944, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:17.576, tt:544.848\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.10819, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:17.629, tt:564.143\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.10712, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:17.657, tt:582.673\n",
      "Ep:33, loss:0.00002, loss_test:0.10645, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.669, tt:600.755\n",
      "Ep:34, loss:0.00002, loss_test:0.10556, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:17.710, tt:619.855\n",
      "Ep:35, loss:0.00002, loss_test:0.10489, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:17.730, tt:638.262\n",
      "Ep:36, loss:0.00002, loss_test:0.10428, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:17.731, tt:656.041\n",
      "Ep:37, loss:0.00002, loss_test:0.10378, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:17.751, tt:674.524\n",
      "Ep:38, loss:0.00002, loss_test:0.10330, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:17.794, tt:693.958\n",
      "Ep:39, loss:0.00002, loss_test:0.10288, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:17.828, tt:713.134\n",
      "Ep:40, loss:0.00002, loss_test:0.10283, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:17.852, tt:731.918\n",
      "Ep:41, loss:0.00002, loss_test:0.10315, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:17.847, tt:749.593\n",
      "Ep:42, loss:0.00002, loss_test:0.10321, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:17.901, tt:769.756\n",
      "Ep:43, loss:0.00002, loss_test:0.10291, lr:9.90e-03, fs:0.71429 (r=0.707,p=0.722),  time:17.898, tt:787.504\n",
      "Ep:44, loss:0.00002, loss_test:0.10288, lr:9.80e-03, fs:0.72165 (r=0.707,p=0.737),  time:17.954, tt:807.944\n",
      "Ep:45, loss:0.00002, loss_test:0.10347, lr:9.70e-03, fs:0.72165 (r=0.707,p=0.737),  time:17.957, tt:826.014\n",
      "Ep:46, loss:0.00002, loss_test:0.10306, lr:9.61e-03, fs:0.72165 (r=0.707,p=0.737),  time:17.949, tt:843.606\n",
      "Ep:47, loss:0.00002, loss_test:0.10240, lr:9.51e-03, fs:0.71503 (r=0.697,p=0.734),  time:17.951, tt:861.655\n",
      "Ep:48, loss:0.00002, loss_test:0.10334, lr:9.41e-03, fs:0.71503 (r=0.697,p=0.734),  time:17.975, tt:880.794\n",
      "Ep:49, loss:0.00002, loss_test:0.10306, lr:9.32e-03, fs:0.71134 (r=0.697,p=0.726),  time:17.996, tt:899.777\n",
      "Ep:50, loss:0.00002, loss_test:0.10247, lr:9.23e-03, fs:0.70769 (r=0.697,p=0.719),  time:18.015, tt:918.742\n",
      "Ep:51, loss:0.00002, loss_test:0.10319, lr:9.14e-03, fs:0.70769 (r=0.697,p=0.719),  time:18.021, tt:937.089\n",
      "Ep:52, loss:0.00002, loss_test:0.10378, lr:9.04e-03, fs:0.70769 (r=0.697,p=0.719),  time:18.024, tt:955.262\n",
      "Ep:53, loss:0.00002, loss_test:0.10253, lr:8.95e-03, fs:0.70051 (r=0.697,p=0.704),  time:18.040, tt:974.166\n",
      "Ep:54, loss:0.00002, loss_test:0.10258, lr:8.86e-03, fs:0.70051 (r=0.697,p=0.704),  time:18.065, tt:993.569\n",
      "Ep:55, loss:0.00002, loss_test:0.10331, lr:8.78e-03, fs:0.70051 (r=0.697,p=0.704),  time:18.084, tt:1012.680\n",
      "Ep:56, loss:0.00002, loss_test:0.10243, lr:8.69e-03, fs:0.70051 (r=0.697,p=0.704),  time:18.105, tt:1031.992\n",
      "Ep:57, loss:0.00002, loss_test:0.10197, lr:8.60e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.111, tt:1050.427\n",
      "Ep:58, loss:0.00002, loss_test:0.10233, lr:8.51e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.122, tt:1069.215\n",
      "Ep:59, loss:0.00002, loss_test:0.10144, lr:8.43e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.135, tt:1088.098\n",
      "Ep:60, loss:0.00002, loss_test:0.10087, lr:8.35e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.149, tt:1107.089\n",
      "Ep:61, loss:0.00001, loss_test:0.10070, lr:8.26e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.156, tt:1125.643\n",
      "Ep:62, loss:0.00001, loss_test:0.10058, lr:8.18e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.160, tt:1144.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.09998, lr:8.10e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.195, tt:1164.489\n",
      "Ep:64, loss:0.00001, loss_test:0.09956, lr:8.02e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.197, tt:1182.813\n",
      "Ep:65, loss:0.00001, loss_test:0.09957, lr:7.94e-03, fs:0.71429 (r=0.707,p=0.722),  time:18.211, tt:1201.912\n",
      "Ep:66, loss:0.00001, loss_test:0.09916, lr:7.86e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.233, tt:1221.623\n",
      "Ep:67, loss:0.00001, loss_test:0.09866, lr:7.78e-03, fs:0.70352 (r=0.707,p=0.700),  time:18.248, tt:1240.870\n",
      "Ep:68, loss:0.00001, loss_test:0.09951, lr:7.70e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.267, tt:1260.414\n",
      "Ep:69, loss:0.00001, loss_test:0.09887, lr:7.62e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.274, tt:1279.209\n",
      "Ep:70, loss:0.00001, loss_test:0.09768, lr:7.55e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.279, tt:1297.817\n",
      "Ep:71, loss:0.00001, loss_test:0.09894, lr:7.47e-03, fs:0.71429 (r=0.707,p=0.722),  time:18.286, tt:1316.569\n",
      "Ep:72, loss:0.00001, loss_test:0.09851, lr:7.40e-03, fs:0.71429 (r=0.707,p=0.722),  time:18.292, tt:1335.335\n",
      "Ep:73, loss:0.00001, loss_test:0.09686, lr:7.32e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.311, tt:1355.038\n",
      "Ep:74, loss:0.00001, loss_test:0.09839, lr:7.25e-03, fs:0.71795 (r=0.707,p=0.729),  time:18.312, tt:1373.437\n",
      "Ep:75, loss:0.00001, loss_test:0.09790, lr:7.18e-03, fs:0.71795 (r=0.707,p=0.729),  time:18.312, tt:1391.696\n",
      "Ep:76, loss:0.00001, loss_test:0.09646, lr:7.11e-03, fs:0.71429 (r=0.707,p=0.722),  time:18.299, tt:1408.999\n",
      "Ep:77, loss:0.00001, loss_test:0.09697, lr:7.03e-03, fs:0.71429 (r=0.707,p=0.722),  time:18.283, tt:1426.082\n",
      "Ep:78, loss:0.00001, loss_test:0.09701, lr:6.96e-03, fs:0.73096 (r=0.727,p=0.735),  time:18.305, tt:1446.109\n",
      "Ep:79, loss:0.00001, loss_test:0.09587, lr:6.89e-03, fs:0.72727 (r=0.727,p=0.727),  time:18.292, tt:1463.350\n",
      "Ep:80, loss:0.00001, loss_test:0.09539, lr:6.83e-03, fs:0.72727 (r=0.727,p=0.727),  time:18.275, tt:1480.280\n",
      "Ep:81, loss:0.00001, loss_test:0.09598, lr:6.76e-03, fs:0.73096 (r=0.727,p=0.735),  time:18.266, tt:1497.772\n",
      "Ep:82, loss:0.00001, loss_test:0.09515, lr:6.69e-03, fs:0.73096 (r=0.727,p=0.735),  time:18.257, tt:1515.303\n",
      "Ep:83, loss:0.00001, loss_test:0.09450, lr:6.62e-03, fs:0.72727 (r=0.727,p=0.727),  time:18.245, tt:1532.602\n",
      "Ep:84, loss:0.00001, loss_test:0.09528, lr:6.56e-03, fs:0.74112 (r=0.737,p=0.745),  time:18.232, tt:1549.681\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.09446, lr:6.56e-03, fs:0.74112 (r=0.737,p=0.745),  time:18.223, tt:1567.219\n",
      "Ep:86, loss:0.00001, loss_test:0.09398, lr:6.56e-03, fs:0.73737 (r=0.737,p=0.737),  time:18.217, tt:1584.857\n",
      "Ep:87, loss:0.00001, loss_test:0.09570, lr:6.56e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.213, tt:1602.748\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.09486, lr:6.56e-03, fs:0.74747 (r=0.747,p=0.747),  time:18.201, tt:1619.871\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.09357, lr:6.56e-03, fs:0.73737 (r=0.737,p=0.737),  time:18.197, tt:1637.728\n",
      "Ep:90, loss:0.00001, loss_test:0.09578, lr:6.56e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.190, tt:1655.305\n",
      "Ep:91, loss:0.00001, loss_test:0.09515, lr:6.56e-03, fs:0.75127 (r=0.747,p=0.755),  time:18.183, tt:1672.805\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.09302, lr:6.56e-03, fs:0.73367 (r=0.737,p=0.730),  time:18.164, tt:1689.260\n",
      "Ep:93, loss:0.00001, loss_test:0.09463, lr:6.56e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.146, tt:1705.692\n",
      "Ep:94, loss:0.00001, loss_test:0.09446, lr:6.56e-03, fs:0.75127 (r=0.747,p=0.755),  time:18.129, tt:1722.300\n",
      "Ep:95, loss:0.00001, loss_test:0.09260, lr:6.56e-03, fs:0.74000 (r=0.747,p=0.733),  time:18.117, tt:1739.227\n",
      "Ep:96, loss:0.00001, loss_test:0.09351, lr:6.56e-03, fs:0.75127 (r=0.747,p=0.755),  time:18.106, tt:1756.263\n",
      "Ep:97, loss:0.00001, loss_test:0.09456, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.086, tt:1772.425\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.09304, lr:6.56e-03, fs:0.74747 (r=0.747,p=0.747),  time:18.073, tt:1789.267\n",
      "Ep:99, loss:0.00001, loss_test:0.09291, lr:6.56e-03, fs:0.75127 (r=0.747,p=0.755),  time:18.060, tt:1806.043\n",
      "Ep:100, loss:0.00001, loss_test:0.09396, lr:6.56e-03, fs:0.76289 (r=0.747,p=0.779),  time:18.072, tt:1825.229\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.09347, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.066, tt:1842.751\n",
      "Ep:102, loss:0.00001, loss_test:0.09194, lr:6.56e-03, fs:0.74747 (r=0.747,p=0.747),  time:18.042, tt:1858.318\n",
      "Ep:103, loss:0.00001, loss_test:0.09306, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.031, tt:1875.234\n",
      "Ep:104, loss:0.00001, loss_test:0.09303, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.020, tt:1892.066\n",
      "Ep:105, loss:0.00001, loss_test:0.09171, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.017, tt:1909.749\n",
      "Ep:106, loss:0.00001, loss_test:0.09176, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.009, tt:1926.968\n",
      "Ep:107, loss:0.00001, loss_test:0.09223, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:18.003, tt:1944.308\n",
      "Ep:108, loss:0.00001, loss_test:0.09143, lr:6.56e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.987, tt:1960.600\n",
      "Ep:109, loss:0.00001, loss_test:0.09079, lr:6.56e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.974, tt:1977.152\n",
      "Ep:110, loss:0.00001, loss_test:0.09153, lr:6.56e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.970, tt:1994.635\n",
      "Ep:111, loss:0.00001, loss_test:0.09091, lr:6.56e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.966, tt:2012.146\n",
      "Ep:112, loss:0.00001, loss_test:0.08938, lr:6.49e-03, fs:0.75510 (r=0.747,p=0.763),  time:17.956, tt:2029.077\n",
      "Ep:113, loss:0.00001, loss_test:0.09178, lr:6.43e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.944, tt:2045.571\n",
      "Ep:114, loss:0.00001, loss_test:0.09182, lr:6.36e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.936, tt:2062.634\n",
      "Ep:115, loss:0.00001, loss_test:0.08928, lr:6.30e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.934, tt:2080.300\n",
      "Ep:116, loss:0.00001, loss_test:0.08904, lr:6.24e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.937, tt:2098.636\n",
      "Ep:117, loss:0.00001, loss_test:0.09103, lr:6.17e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.937, tt:2116.599\n",
      "Ep:118, loss:0.00001, loss_test:0.09101, lr:6.11e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.929, tt:2133.547\n",
      "Ep:119, loss:0.00001, loss_test:0.08846, lr:6.05e-03, fs:0.76289 (r=0.747,p=0.779),  time:17.918, tt:2150.130\n",
      "Ep:120, loss:0.00001, loss_test:0.08813, lr:5.99e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.906, tt:2166.673\n",
      "Ep:121, loss:0.00001, loss_test:0.09030, lr:5.93e-03, fs:0.75648 (r=0.737,p=0.777),  time:17.907, tt:2184.661\n",
      "Ep:122, loss:0.00001, loss_test:0.08967, lr:5.87e-03, fs:0.76440 (r=0.737,p=0.793),  time:17.904, tt:2202.130\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.08743, lr:5.87e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.905, tt:2220.282\n",
      "Ep:124, loss:0.00001, loss_test:0.08776, lr:5.87e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.903, tt:2237.834\n",
      "Ep:125, loss:0.00001, loss_test:0.08906, lr:5.87e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.898, tt:2255.146\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00001, loss_test:0.08826, lr:5.87e-03, fs:0.76440 (r=0.737,p=0.793),  time:17.894, tt:2272.540\n",
      "Ep:127, loss:0.00001, loss_test:0.08652, lr:5.87e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.886, tt:2289.459\n",
      "Ep:128, loss:0.00001, loss_test:0.08713, lr:5.87e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.874, tt:2305.690\n",
      "Ep:129, loss:0.00001, loss_test:0.08752, lr:5.87e-03, fs:0.76440 (r=0.737,p=0.793),  time:17.872, tt:2323.338\n",
      "Ep:130, loss:0.00001, loss_test:0.08677, lr:5.87e-03, fs:0.75258 (r=0.737,p=0.768),  time:17.869, tt:2340.893\n",
      "Ep:131, loss:0.00001, loss_test:0.08571, lr:5.87e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.861, tt:2357.636\n",
      "Ep:132, loss:0.00001, loss_test:0.08639, lr:5.87e-03, fs:0.76440 (r=0.737,p=0.793),  time:17.858, tt:2375.171\n",
      "Ep:133, loss:0.00001, loss_test:0.08690, lr:5.87e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.854, tt:2392.487\n",
      "Ep:134, loss:0.00001, loss_test:0.08562, lr:5.87e-03, fs:0.75510 (r=0.747,p=0.763),  time:17.852, tt:2410.062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.08461, lr:5.87e-03, fs:0.75510 (r=0.747,p=0.763),  time:17.849, tt:2427.514\n",
      "Ep:136, loss:0.00001, loss_test:0.08746, lr:5.87e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.856, tt:2446.297\n",
      "Ep:137, loss:0.00001, loss_test:0.08714, lr:5.81e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.862, tt:2464.972\n",
      "Ep:138, loss:0.00001, loss_test:0.08477, lr:5.75e-03, fs:0.75897 (r=0.747,p=0.771),  time:17.863, tt:2482.967\n",
      "Ep:139, loss:0.00001, loss_test:0.08482, lr:5.70e-03, fs:0.75510 (r=0.747,p=0.763),  time:17.875, tt:2502.446\n",
      "Ep:140, loss:0.00001, loss_test:0.08630, lr:5.64e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.862, tt:2518.565\n",
      "Ep:141, loss:0.00001, loss_test:0.08632, lr:5.58e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.861, tt:2536.265\n",
      "Ep:142, loss:0.00001, loss_test:0.08449, lr:5.53e-03, fs:0.75648 (r=0.737,p=0.777),  time:17.865, tt:2554.690\n",
      "Ep:143, loss:0.00001, loss_test:0.08413, lr:5.47e-03, fs:0.74490 (r=0.737,p=0.753),  time:17.867, tt:2572.886\n",
      "Ep:144, loss:0.00001, loss_test:0.08519, lr:5.42e-03, fs:0.76440 (r=0.737,p=0.793),  time:17.869, tt:2591.044\n",
      "Ep:145, loss:0.00001, loss_test:0.08582, lr:5.36e-03, fs:0.77249 (r=0.737,p=0.811),  time:17.873, tt:2609.475\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00001, loss_test:0.08468, lr:5.36e-03, fs:0.75648 (r=0.737,p=0.777),  time:17.886, tt:2629.213\n",
      "Ep:147, loss:0.00001, loss_test:0.08405, lr:5.36e-03, fs:0.74872 (r=0.737,p=0.760),  time:17.897, tt:2648.800\n",
      "Ep:148, loss:0.00001, loss_test:0.08456, lr:5.36e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.904, tt:2667.727\n",
      "Ep:149, loss:0.00001, loss_test:0.08496, lr:5.36e-03, fs:0.76440 (r=0.737,p=0.793),  time:17.909, tt:2686.366\n",
      "Ep:150, loss:0.00001, loss_test:0.08403, lr:5.36e-03, fs:0.75258 (r=0.737,p=0.768),  time:17.925, tt:2706.611\n",
      "Ep:151, loss:0.00001, loss_test:0.08300, lr:5.36e-03, fs:0.75258 (r=0.737,p=0.768),  time:17.930, tt:2725.394\n",
      "Ep:152, loss:0.00001, loss_test:0.08464, lr:5.36e-03, fs:0.76042 (r=0.737,p=0.785),  time:17.945, tt:2745.627\n",
      "Ep:153, loss:0.00001, loss_test:0.08459, lr:5.36e-03, fs:0.77249 (r=0.737,p=0.811),  time:17.955, tt:2765.006\n",
      "Ep:154, loss:0.00001, loss_test:0.08336, lr:5.36e-03, fs:0.75648 (r=0.737,p=0.777),  time:17.962, tt:2784.109\n",
      "Ep:155, loss:0.00001, loss_test:0.08282, lr:5.36e-03, fs:0.74490 (r=0.737,p=0.753),  time:17.969, tt:2803.106\n",
      "Ep:156, loss:0.00001, loss_test:0.08321, lr:5.36e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.985, tt:2823.568\n",
      "Ep:157, loss:0.00001, loss_test:0.08483, lr:5.31e-03, fs:0.76842 (r=0.737,p=0.802),  time:17.994, tt:2842.991\n",
      "Ep:158, loss:0.00000, loss_test:0.08426, lr:5.26e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.019, tt:2865.014\n",
      "Ep:159, loss:0.00000, loss_test:0.08230, lr:5.20e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.024, tt:2883.789\n",
      "Ep:160, loss:0.00000, loss_test:0.08280, lr:5.15e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.037, tt:2903.923\n",
      "Ep:161, loss:0.00000, loss_test:0.08425, lr:5.10e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.046, tt:2923.387\n",
      "Ep:162, loss:0.00000, loss_test:0.08385, lr:5.05e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.052, tt:2942.422\n",
      "Ep:163, loss:0.00000, loss_test:0.08272, lr:5.00e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.059, tt:2961.657\n",
      "Ep:164, loss:0.00000, loss_test:0.08292, lr:4.95e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.061, tt:2980.079\n",
      "Ep:165, loss:0.00000, loss_test:0.08320, lr:4.90e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.067, tt:2999.141\n",
      "Ep:166, loss:0.00000, loss_test:0.08297, lr:4.85e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.068, tt:3017.306\n",
      "Ep:167, loss:0.00000, loss_test:0.08257, lr:4.80e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.079, tt:3037.285\n",
      "Ep:168, loss:0.00000, loss_test:0.08299, lr:4.75e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.084, tt:3056.124\n",
      "Ep:169, loss:0.00000, loss_test:0.08288, lr:4.71e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.094, tt:3075.983\n",
      "Ep:170, loss:0.00000, loss_test:0.08251, lr:4.66e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.102, tt:3095.456\n",
      "Ep:171, loss:0.00000, loss_test:0.08278, lr:4.61e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.113, tt:3115.418\n",
      "Ep:172, loss:0.00000, loss_test:0.08273, lr:4.57e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.117, tt:3134.213\n",
      "Ep:173, loss:0.00000, loss_test:0.08230, lr:4.52e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.122, tt:3153.234\n",
      "Ep:174, loss:0.00000, loss_test:0.08269, lr:4.48e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.132, tt:3173.081\n",
      "Ep:175, loss:0.00000, loss_test:0.08268, lr:4.43e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.129, tt:3190.719\n",
      "Ep:176, loss:0.00000, loss_test:0.08213, lr:4.39e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.137, tt:3210.215\n",
      "Ep:177, loss:0.00000, loss_test:0.08198, lr:4.34e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.141, tt:3229.106\n",
      "Ep:178, loss:0.00000, loss_test:0.08257, lr:4.30e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.148, tt:3248.531\n",
      "Ep:179, loss:0.00000, loss_test:0.08286, lr:4.26e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.157, tt:3268.305\n",
      "Ep:180, loss:0.00000, loss_test:0.08245, lr:4.21e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.163, tt:3287.448\n",
      "Ep:181, loss:0.00000, loss_test:0.08168, lr:4.17e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.169, tt:3306.690\n",
      "Ep:182, loss:0.00000, loss_test:0.08155, lr:4.13e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.177, tt:3326.444\n",
      "Ep:183, loss:0.00000, loss_test:0.08228, lr:4.09e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.181, tt:3345.395\n",
      "Ep:184, loss:0.00000, loss_test:0.08243, lr:4.05e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.186, tt:3364.383\n",
      "Ep:185, loss:0.00000, loss_test:0.08189, lr:4.01e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.195, tt:3384.254\n",
      "Ep:186, loss:0.00000, loss_test:0.08162, lr:3.97e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.198, tt:3403.070\n",
      "Ep:187, loss:0.00000, loss_test:0.08191, lr:3.93e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.199, tt:3421.449\n",
      "Ep:188, loss:0.00000, loss_test:0.08210, lr:3.89e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.207, tt:3441.153\n",
      "Ep:189, loss:0.00000, loss_test:0.08224, lr:3.85e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.213, tt:3460.440\n",
      "##########Best model found so far##########\n",
      "Ep:190, loss:0.00000, loss_test:0.08175, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.219, tt:3479.748\n",
      "Ep:191, loss:0.00000, loss_test:0.08166, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.222, tt:3498.705\n",
      "Ep:192, loss:0.00000, loss_test:0.08167, lr:3.85e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.226, tt:3517.580\n",
      "Ep:193, loss:0.00000, loss_test:0.08194, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.230, tt:3536.566\n",
      "Ep:194, loss:0.00000, loss_test:0.08185, lr:3.85e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.232, tt:3555.237\n",
      "##########Best model found so far##########\n",
      "Ep:195, loss:0.00000, loss_test:0.08180, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.241, tt:3575.265\n",
      "Ep:196, loss:0.00000, loss_test:0.08172, lr:3.85e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.247, tt:3594.646\n",
      "Ep:197, loss:0.00000, loss_test:0.08156, lr:3.85e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.254, tt:3614.257\n",
      "Ep:198, loss:0.00000, loss_test:0.08139, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.258, tt:3633.432\n",
      "Ep:199, loss:0.00000, loss_test:0.08142, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.262, tt:3652.495\n",
      "Ep:200, loss:0.00000, loss_test:0.08134, lr:3.85e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.263, tt:3670.858\n",
      "Ep:201, loss:0.00000, loss_test:0.08100, lr:3.85e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.267, tt:3689.886\n",
      "Ep:202, loss:0.00000, loss_test:0.08089, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.273, tt:3709.458\n",
      "Ep:203, loss:0.00000, loss_test:0.08123, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.276, tt:3728.314\n",
      "Ep:204, loss:0.00000, loss_test:0.08163, lr:3.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.284, tt:3748.165\n",
      "Ep:205, loss:0.00000, loss_test:0.08140, lr:3.85e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.293, tt:3768.424\n",
      "Ep:206, loss:0.00000, loss_test:0.08107, lr:3.81e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.300, tt:3788.158\n",
      "Ep:207, loss:0.00000, loss_test:0.08085, lr:3.77e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.300, tt:3806.501\n",
      "Ep:208, loss:0.00000, loss_test:0.08103, lr:3.73e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.304, tt:3825.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.08120, lr:3.70e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.305, tt:3844.019\n",
      "Ep:210, loss:0.00000, loss_test:0.08114, lr:3.66e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.312, tt:3863.766\n",
      "Ep:211, loss:0.00000, loss_test:0.08096, lr:3.62e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.315, tt:3882.694\n",
      "Ep:212, loss:0.00000, loss_test:0.08052, lr:3.59e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.313, tt:3900.618\n",
      "Ep:213, loss:0.00000, loss_test:0.08049, lr:3.55e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.316, tt:3919.520\n",
      "Ep:214, loss:0.00000, loss_test:0.08072, lr:3.52e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.317, tt:3938.143\n",
      "Ep:215, loss:0.00000, loss_test:0.08102, lr:3.48e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.321, tt:3957.310\n",
      "Ep:216, loss:0.00000, loss_test:0.08082, lr:3.45e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.321, tt:3975.621\n",
      "Ep:217, loss:0.00000, loss_test:0.08032, lr:3.41e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.322, tt:3994.189\n",
      "Ep:218, loss:0.00000, loss_test:0.08020, lr:3.38e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.323, tt:4012.815\n",
      "Ep:219, loss:0.00000, loss_test:0.08082, lr:3.34e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.327, tt:4031.962\n",
      "Ep:220, loss:0.00000, loss_test:0.08134, lr:3.31e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.327, tt:4050.293\n",
      "Ep:221, loss:0.00000, loss_test:0.08104, lr:3.28e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.333, tt:4069.951\n",
      "Ep:222, loss:0.00000, loss_test:0.08047, lr:3.24e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.341, tt:4089.946\n",
      "Ep:223, loss:0.00000, loss_test:0.08024, lr:3.21e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.342, tt:4108.660\n",
      "Ep:224, loss:0.00000, loss_test:0.08041, lr:3.18e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.342, tt:4126.981\n",
      "Ep:225, loss:0.00000, loss_test:0.08077, lr:3.15e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.348, tt:4146.620\n",
      "Ep:226, loss:0.00000, loss_test:0.08059, lr:3.12e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.347, tt:4164.775\n",
      "Ep:227, loss:0.00000, loss_test:0.08015, lr:3.09e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.347, tt:4183.181\n",
      "Ep:228, loss:0.00000, loss_test:0.07995, lr:3.05e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.348, tt:4201.805\n",
      "Ep:229, loss:0.00000, loss_test:0.08003, lr:3.02e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.354, tt:4221.379\n",
      "Ep:230, loss:0.00000, loss_test:0.08026, lr:2.99e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.354, tt:4239.873\n",
      "Ep:231, loss:0.00000, loss_test:0.08025, lr:2.96e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.359, tt:4259.276\n",
      "Ep:232, loss:0.00000, loss_test:0.08011, lr:2.93e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.357, tt:4277.227\n",
      "Ep:233, loss:0.00000, loss_test:0.07992, lr:2.90e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.363, tt:4296.846\n",
      "Ep:234, loss:0.00000, loss_test:0.08010, lr:2.88e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.367, tt:4316.173\n",
      "Ep:235, loss:0.00000, loss_test:0.08032, lr:2.85e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.364, tt:4333.879\n",
      "Ep:236, loss:0.00000, loss_test:0.08013, lr:2.82e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.368, tt:4353.238\n",
      "Ep:237, loss:0.00000, loss_test:0.07983, lr:2.79e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.372, tt:4372.421\n",
      "Ep:238, loss:0.00000, loss_test:0.07982, lr:2.76e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.373, tt:4391.260\n",
      "Ep:239, loss:0.00000, loss_test:0.08014, lr:2.73e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.377, tt:4410.363\n",
      "Ep:240, loss:0.00000, loss_test:0.08012, lr:2.71e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.379, tt:4429.446\n",
      "Ep:241, loss:0.00000, loss_test:0.07978, lr:2.68e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.385, tt:4449.120\n",
      "Ep:242, loss:0.00000, loss_test:0.07965, lr:2.65e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.389, tt:4468.515\n",
      "Ep:243, loss:0.00000, loss_test:0.07989, lr:2.63e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.388, tt:4486.762\n",
      "Ep:244, loss:0.00000, loss_test:0.08007, lr:2.60e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.387, tt:4504.796\n",
      "Ep:245, loss:0.00000, loss_test:0.07991, lr:2.57e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.391, tt:4524.231\n",
      "Ep:246, loss:0.00000, loss_test:0.07961, lr:2.55e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.390, tt:4542.414\n",
      "Ep:247, loss:0.00000, loss_test:0.07951, lr:2.52e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.394, tt:4561.610\n",
      "Ep:248, loss:0.00000, loss_test:0.07974, lr:2.50e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.392, tt:4579.593\n",
      "Ep:249, loss:0.00000, loss_test:0.08001, lr:2.47e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.397, tt:4599.342\n",
      "Ep:250, loss:0.00000, loss_test:0.07986, lr:2.45e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.396, tt:4617.403\n",
      "Ep:251, loss:0.00000, loss_test:0.07949, lr:2.42e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.396, tt:4635.743\n",
      "Ep:252, loss:0.00000, loss_test:0.07950, lr:2.40e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.398, tt:4654.639\n",
      "Ep:253, loss:0.00000, loss_test:0.07973, lr:2.38e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.398, tt:4673.078\n",
      "Ep:254, loss:0.00000, loss_test:0.07976, lr:2.35e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.404, tt:4692.976\n",
      "Ep:255, loss:0.00000, loss_test:0.07973, lr:2.33e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.405, tt:4711.624\n",
      "Ep:256, loss:0.00000, loss_test:0.07956, lr:2.31e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.408, tt:4730.734\n",
      "Ep:257, loss:0.00000, loss_test:0.07955, lr:2.28e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.408, tt:4749.377\n",
      "Ep:258, loss:0.00000, loss_test:0.07973, lr:2.26e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.408, tt:4767.651\n",
      "Ep:259, loss:0.00000, loss_test:0.07965, lr:2.24e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.409, tt:4786.314\n",
      "Ep:260, loss:0.00000, loss_test:0.07949, lr:2.21e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.408, tt:4804.502\n",
      "Ep:261, loss:0.00000, loss_test:0.07936, lr:2.19e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.412, tt:4823.830\n",
      "Ep:262, loss:0.00000, loss_test:0.07950, lr:2.17e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.413, tt:4842.605\n",
      "Ep:263, loss:0.00000, loss_test:0.07964, lr:2.15e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.415, tt:4861.664\n",
      "Ep:264, loss:0.00000, loss_test:0.07952, lr:2.13e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.416, tt:4880.151\n",
      "Ep:265, loss:0.00000, loss_test:0.07928, lr:2.11e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.412, tt:4897.694\n",
      "Ep:266, loss:0.00000, loss_test:0.07939, lr:2.08e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.415, tt:4916.937\n",
      "Ep:267, loss:0.00000, loss_test:0.07956, lr:2.06e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.419, tt:4936.400\n",
      "Ep:268, loss:0.00000, loss_test:0.07960, lr:2.04e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.423, tt:4955.825\n",
      "Ep:269, loss:0.00000, loss_test:0.07957, lr:2.02e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.423, tt:4974.181\n",
      "Ep:270, loss:0.00000, loss_test:0.07945, lr:2.00e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.426, tt:4993.401\n",
      "Ep:271, loss:0.00000, loss_test:0.07950, lr:1.98e-03, fs:0.76440 (r=0.737,p=0.793),  time:18.427, tt:5012.251\n",
      "Ep:272, loss:0.00000, loss_test:0.07961, lr:1.96e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.428, tt:5030.736\n",
      "Ep:273, loss:0.00000, loss_test:0.07960, lr:1.94e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.426, tt:5048.642\n",
      "Ep:274, loss:0.00000, loss_test:0.07942, lr:1.92e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.424, tt:5066.597\n",
      "Ep:275, loss:0.00000, loss_test:0.07926, lr:1.90e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.426, tt:5085.496\n",
      "Ep:276, loss:0.00000, loss_test:0.07931, lr:1.89e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.435, tt:5106.417\n",
      "Ep:277, loss:0.00000, loss_test:0.07950, lr:1.87e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.433, tt:5124.488\n",
      "Ep:278, loss:0.00000, loss_test:0.07954, lr:1.85e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.433, tt:5142.871\n",
      "Ep:279, loss:0.00000, loss_test:0.07938, lr:1.83e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.432, tt:5160.897\n",
      "Ep:280, loss:0.00000, loss_test:0.07934, lr:1.81e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.434, tt:5180.059\n",
      "Ep:281, loss:0.00000, loss_test:0.07946, lr:1.79e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.437, tt:5199.354\n",
      "Ep:282, loss:0.00000, loss_test:0.07952, lr:1.78e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.439, tt:5218.320\n",
      "Ep:283, loss:0.00000, loss_test:0.07939, lr:1.76e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.439, tt:5236.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:284, loss:0.00000, loss_test:0.07919, lr:1.74e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.440, tt:5255.438\n",
      "Ep:285, loss:0.00000, loss_test:0.07931, lr:1.72e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.442, tt:5274.461\n",
      "Ep:286, loss:0.00000, loss_test:0.07937, lr:1.71e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.444, tt:5293.365\n",
      "Ep:287, loss:0.00000, loss_test:0.07927, lr:1.69e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.449, tt:5313.321\n",
      "Ep:288, loss:0.00000, loss_test:0.07936, lr:1.67e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.453, tt:5333.048\n",
      "Ep:289, loss:0.00000, loss_test:0.07942, lr:1.65e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.453, tt:5351.466\n",
      "Ep:290, loss:0.00000, loss_test:0.07942, lr:1.64e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.456, tt:5370.569\n",
      "Ep:291, loss:0.00000, loss_test:0.07941, lr:1.62e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.458, tt:5389.713\n",
      "Ep:292, loss:0.00000, loss_test:0.07937, lr:1.61e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.458, tt:5408.253\n",
      "Ep:293, loss:0.00000, loss_test:0.07926, lr:1.59e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.462, tt:5427.723\n",
      "Ep:294, loss:0.00000, loss_test:0.07922, lr:1.57e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.465, tt:5447.141\n",
      "Ep:295, loss:0.00000, loss_test:0.07931, lr:1.56e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.465, tt:5465.764\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Creating cross validation splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13991, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:6.120, tt:6.120\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13962, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:7.789, tt:15.579\n",
      "Ep:2, loss:0.00004, loss_test:0.13939, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:10.228, tt:30.683\n",
      "Ep:3, loss:0.00004, loss_test:0.13923, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:12.139, tt:48.558\n",
      "Ep:4, loss:0.00004, loss_test:0.13901, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:13.316, tt:66.579\n",
      "Ep:5, loss:0.00004, loss_test:0.13873, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:14.199, tt:85.192\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13846, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:14.689, tt:102.825\n",
      "Ep:7, loss:0.00004, loss_test:0.13823, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:15.100, tt:120.804\n",
      "Ep:8, loss:0.00004, loss_test:0.13804, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:15.395, tt:138.552\n",
      "Ep:9, loss:0.00004, loss_test:0.13780, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:15.601, tt:156.006\n",
      "Ep:10, loss:0.00003, loss_test:0.13745, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:15.865, tt:174.513\n",
      "Ep:11, loss:0.00003, loss_test:0.13711, lr:1.00e-02, fs:0.65000 (r=0.788,p=0.553),  time:16.132, tt:193.587\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.13660, lr:1.00e-02, fs:0.63866 (r=0.768,p=0.547),  time:16.314, tt:212.083\n",
      "Ep:13, loss:0.00003, loss_test:0.13580, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:16.469, tt:230.572\n",
      "Ep:14, loss:0.00003, loss_test:0.13492, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:16.563, tt:248.448\n",
      "Ep:15, loss:0.00003, loss_test:0.13399, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:16.688, tt:267.002\n",
      "Ep:16, loss:0.00003, loss_test:0.13307, lr:1.00e-02, fs:0.64706 (r=0.778,p=0.554),  time:16.745, tt:284.660\n",
      "Ep:17, loss:0.00003, loss_test:0.13213, lr:1.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:16.804, tt:302.465\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.13119, lr:1.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:16.903, tt:321.157\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.13024, lr:1.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:16.972, tt:339.442\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.12930, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:17.069, tt:358.445\n",
      "Ep:21, loss:0.00003, loss_test:0.12828, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:17.098, tt:376.159\n",
      "Ep:22, loss:0.00003, loss_test:0.12720, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:17.159, tt:394.666\n",
      "Ep:23, loss:0.00003, loss_test:0.12581, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:17.186, tt:412.470\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.12403, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:17.253, tt:431.337\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.12198, lr:1.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:17.302, tt:449.853\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.11976, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:17.340, tt:468.174\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.11770, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:17.340, tt:485.532\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.11559, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:17.394, tt:504.414\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.11340, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:17.419, tt:522.570\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.11138, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:17.479, tt:541.860\n",
      "Ep:31, loss:0.00003, loss_test:0.10980, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:17.499, tt:559.958\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.10852, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:17.524, tt:578.289\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.10728, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:17.560, tt:597.033\n",
      "Ep:34, loss:0.00003, loss_test:0.10579, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:17.587, tt:615.533\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.10446, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:17.610, tt:633.963\n",
      "Ep:36, loss:0.00003, loss_test:0.10336, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:17.610, tt:651.587\n",
      "Ep:37, loss:0.00002, loss_test:0.10244, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:17.629, tt:669.910\n",
      "Ep:38, loss:0.00002, loss_test:0.10184, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:17.649, tt:688.298\n",
      "Ep:39, loss:0.00002, loss_test:0.10113, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:17.657, tt:706.300\n",
      "Ep:40, loss:0.00002, loss_test:0.10052, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:17.656, tt:723.899\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.10002, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:17.690, tt:742.998\n",
      "Ep:42, loss:0.00002, loss_test:0.09959, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:17.705, tt:761.310\n",
      "Ep:43, loss:0.00002, loss_test:0.09936, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:17.728, tt:780.050\n",
      "Ep:44, loss:0.00002, loss_test:0.09917, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:17.767, tt:799.505\n",
      "Ep:45, loss:0.00002, loss_test:0.09894, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:17.799, tt:818.733\n",
      "Ep:46, loss:0.00002, loss_test:0.09867, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:17.837, tt:838.316\n",
      "Ep:47, loss:0.00002, loss_test:0.09886, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:17.879, tt:858.180\n",
      "Ep:48, loss:0.00002, loss_test:0.09890, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.905, tt:877.348\n",
      "Ep:49, loss:0.00002, loss_test:0.09887, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:17.942, tt:897.106\n",
      "Ep:50, loss:0.00002, loss_test:0.09904, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:17.984, tt:917.207\n",
      "Ep:51, loss:0.00002, loss_test:0.09990, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:18.002, tt:936.125\n",
      "Ep:52, loss:0.00002, loss_test:0.10007, lr:9.90e-03, fs:0.69744 (r=0.687,p=0.708),  time:18.025, tt:955.317\n",
      "Ep:53, loss:0.00002, loss_test:0.10031, lr:9.80e-03, fs:0.70103 (r=0.687,p=0.716),  time:18.006, tt:972.311\n",
      "Ep:54, loss:0.00002, loss_test:0.10166, lr:9.70e-03, fs:0.70833 (r=0.687,p=0.731),  time:18.044, tt:992.414\n",
      "Ep:55, loss:0.00002, loss_test:0.10210, lr:9.61e-03, fs:0.71503 (r=0.697,p=0.734),  time:18.086, tt:1012.795\n",
      "Ep:56, loss:0.00002, loss_test:0.10176, lr:9.51e-03, fs:0.70769 (r=0.697,p=0.719),  time:18.122, tt:1032.938\n",
      "Ep:57, loss:0.00002, loss_test:0.10189, lr:9.41e-03, fs:0.71503 (r=0.697,p=0.734),  time:18.182, tt:1054.565\n",
      "Ep:58, loss:0.00002, loss_test:0.10328, lr:9.32e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.204, tt:1074.063\n",
      "Ep:59, loss:0.00001, loss_test:0.10308, lr:9.23e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.233, tt:1094.005\n",
      "Ep:60, loss:0.00001, loss_test:0.10290, lr:9.14e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.257, tt:1113.679\n",
      "Ep:61, loss:0.00001, loss_test:0.10254, lr:9.04e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.270, tt:1132.763\n",
      "Ep:62, loss:0.00001, loss_test:0.10191, lr:8.95e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.293, tt:1152.457\n",
      "Ep:63, loss:0.00001, loss_test:0.10187, lr:8.86e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.301, tt:1171.235\n",
      "Ep:64, loss:0.00001, loss_test:0.10151, lr:8.78e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.319, tt:1190.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.10206, lr:8.69e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.339, tt:1210.367\n",
      "Ep:66, loss:0.00001, loss_test:0.10105, lr:8.60e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.355, tt:1229.770\n",
      "Ep:67, loss:0.00001, loss_test:0.10138, lr:8.51e-03, fs:0.75000 (r=0.727,p=0.774),  time:18.363, tt:1248.667\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.10175, lr:8.51e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.377, tt:1268.012\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.10061, lr:8.51e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.369, tt:1285.836\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.10120, lr:8.51e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.384, tt:1305.285\n",
      "Ep:71, loss:0.00001, loss_test:0.09893, lr:8.51e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.390, tt:1324.101\n",
      "Ep:72, loss:0.00001, loss_test:0.10102, lr:8.51e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.401, tt:1343.247\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.09700, lr:8.51e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.404, tt:1361.920\n",
      "Ep:74, loss:0.00001, loss_test:0.09987, lr:8.51e-03, fs:0.77249 (r=0.737,p=0.811),  time:18.399, tt:1379.923\n",
      "Ep:75, loss:0.00001, loss_test:0.09563, lr:8.51e-03, fs:0.76842 (r=0.737,p=0.802),  time:18.402, tt:1398.579\n",
      "Ep:76, loss:0.00001, loss_test:0.10375, lr:8.51e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.410, tt:1417.566\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.09539, lr:8.51e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.425, tt:1437.181\n",
      "Ep:78, loss:0.00001, loss_test:0.10367, lr:8.51e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.429, tt:1455.862\n",
      "Ep:79, loss:0.00001, loss_test:0.09614, lr:8.51e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.443, tt:1475.422\n",
      "Ep:80, loss:0.00001, loss_test:0.09947, lr:8.51e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.458, tt:1495.072\n",
      "Ep:81, loss:0.00001, loss_test:0.09851, lr:8.51e-03, fs:0.80000 (r=0.727,p=0.889),  time:18.465, tt:1514.155\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.09472, lr:8.51e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.480, tt:1533.838\n",
      "Ep:83, loss:0.00001, loss_test:0.10301, lr:8.51e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.482, tt:1552.455\n",
      "Ep:84, loss:0.00001, loss_test:0.09646, lr:8.51e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.502, tt:1572.643\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.10423, lr:8.51e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.562, tt:1596.328\n",
      "Ep:86, loss:0.00001, loss_test:0.09441, lr:8.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.559, tt:1614.672\n",
      "Ep:87, loss:0.00001, loss_test:0.09585, lr:8.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.560, tt:1633.247\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.09953, lr:8.51e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.557, tt:1651.590\n",
      "Ep:89, loss:0.00001, loss_test:0.09330, lr:8.51e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.555, tt:1669.919\n",
      "Ep:90, loss:0.00001, loss_test:0.09417, lr:8.51e-03, fs:0.81768 (r=0.747,p=0.902),  time:18.553, tt:1688.323\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.09687, lr:8.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:18.562, tt:1707.696\n",
      "Ep:92, loss:0.00001, loss_test:0.09376, lr:8.51e-03, fs:0.82682 (r=0.747,p=0.925),  time:18.555, tt:1725.644\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.09395, lr:8.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:18.564, tt:1744.985\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.09113, lr:8.51e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.550, tt:1762.292\n",
      "Ep:95, loss:0.00001, loss_test:0.09086, lr:8.51e-03, fs:0.83616 (r=0.747,p=0.949),  time:18.552, tt:1781.000\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.09468, lr:8.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:18.545, tt:1798.827\n",
      "Ep:97, loss:0.00001, loss_test:0.09039, lr:8.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.542, tt:1817.131\n",
      "Ep:98, loss:0.00001, loss_test:0.09569, lr:8.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:18.551, tt:1836.529\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.08888, lr:8.51e-03, fs:0.79787 (r=0.758,p=0.843),  time:18.561, tt:1856.068\n",
      "Ep:100, loss:0.00001, loss_test:0.09587, lr:8.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:18.547, tt:1873.263\n",
      "Ep:101, loss:0.00001, loss_test:0.09052, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.557, tt:1892.815\n",
      "Ep:102, loss:0.00001, loss_test:0.08901, lr:8.51e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.559, tt:1911.624\n",
      "Ep:103, loss:0.00001, loss_test:0.09427, lr:8.51e-03, fs:0.84091 (r=0.747,p=0.961),  time:18.557, tt:1929.938\n",
      "Ep:104, loss:0.00001, loss_test:0.09076, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.550, tt:1947.754\n",
      "Ep:105, loss:0.00001, loss_test:0.09168, lr:8.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:18.544, tt:1965.702\n",
      "Ep:106, loss:0.00001, loss_test:0.08968, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.543, tt:1984.129\n",
      "Ep:107, loss:0.00001, loss_test:0.10153, lr:8.51e-03, fs:0.73143 (r=0.646,p=0.842),  time:18.529, tt:2001.104\n",
      "Ep:108, loss:0.00001, loss_test:0.09421, lr:8.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:18.527, tt:2019.447\n",
      "Ep:109, loss:0.00001, loss_test:0.08836, lr:8.51e-03, fs:0.82222 (r=0.747,p=0.914),  time:18.532, tt:2038.542\n",
      "Ep:110, loss:0.00001, loss_test:0.09422, lr:8.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:18.538, tt:2057.682\n",
      "Ep:111, loss:0.00001, loss_test:0.09679, lr:8.35e-03, fs:0.81319 (r=0.747,p=0.892),  time:18.548, tt:2077.376\n",
      "Ep:112, loss:0.00001, loss_test:0.09292, lr:8.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.535, tt:2094.427\n",
      "Ep:113, loss:0.00001, loss_test:0.09225, lr:8.18e-03, fs:0.83516 (r=0.768,p=0.916),  time:18.540, tt:2113.516\n",
      "Ep:114, loss:0.00001, loss_test:0.08426, lr:8.10e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.546, tt:2132.761\n",
      "Ep:115, loss:0.00001, loss_test:0.09148, lr:8.02e-03, fs:0.82873 (r=0.758,p=0.915),  time:18.550, tt:2151.813\n",
      "Ep:116, loss:0.00001, loss_test:0.09709, lr:7.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.547, tt:2169.948\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00000, loss_test:0.08146, lr:7.94e-03, fs:0.82222 (r=0.747,p=0.914),  time:18.552, tt:2189.102\n",
      "Ep:118, loss:0.00000, loss_test:0.08047, lr:7.94e-03, fs:0.81967 (r=0.758,p=0.893),  time:18.550, tt:2207.496\n",
      "Ep:119, loss:0.00000, loss_test:0.09049, lr:7.94e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.553, tt:2226.353\n",
      "Ep:120, loss:0.00000, loss_test:0.09719, lr:7.94e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.560, tt:2245.762\n",
      "Ep:121, loss:0.00000, loss_test:0.08227, lr:7.94e-03, fs:0.83616 (r=0.747,p=0.949),  time:18.557, tt:2263.943\n",
      "Ep:122, loss:0.00000, loss_test:0.07931, lr:7.94e-03, fs:0.81967 (r=0.758,p=0.893),  time:18.552, tt:2281.849\n",
      "Ep:123, loss:0.00000, loss_test:0.08668, lr:7.94e-03, fs:0.85227 (r=0.758,p=0.974),  time:18.561, tt:2301.611\n",
      "Ep:124, loss:0.00000, loss_test:0.09335, lr:7.94e-03, fs:0.83237 (r=0.727,p=0.973),  time:18.565, tt:2320.578\n",
      "Ep:125, loss:0.00000, loss_test:0.08478, lr:7.94e-03, fs:0.83429 (r=0.737,p=0.961),  time:18.570, tt:2339.852\n",
      "Ep:126, loss:0.00000, loss_test:0.08096, lr:7.94e-03, fs:0.83146 (r=0.747,p=0.937),  time:18.576, tt:2359.189\n",
      "Ep:127, loss:0.00000, loss_test:0.08217, lr:7.94e-03, fs:0.85057 (r=0.747,p=0.987),  time:18.583, tt:2378.582\n",
      "Ep:128, loss:0.00000, loss_test:0.08783, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:18.584, tt:2397.335\n",
      "Ep:129, loss:0.00000, loss_test:0.08632, lr:7.78e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.590, tt:2416.724\n",
      "Ep:130, loss:0.00000, loss_test:0.08282, lr:7.70e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.597, tt:2436.163\n",
      "Ep:131, loss:0.00000, loss_test:0.08032, lr:7.62e-03, fs:0.84746 (r=0.758,p=0.962),  time:18.596, tt:2454.695\n",
      "Ep:132, loss:0.00000, loss_test:0.08246, lr:7.55e-03, fs:0.83237 (r=0.727,p=0.973),  time:18.594, tt:2473.062\n",
      "Ep:133, loss:0.00000, loss_test:0.08858, lr:7.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.596, tt:2491.885\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.08324, lr:7.47e-03, fs:0.83908 (r=0.737,p=0.973),  time:18.596, tt:2510.474\n",
      "Ep:135, loss:0.00000, loss_test:0.08042, lr:7.47e-03, fs:0.84270 (r=0.758,p=0.949),  time:18.599, tt:2529.479\n",
      "Ep:136, loss:0.00000, loss_test:0.08206, lr:7.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:18.597, tt:2547.821\n",
      "Ep:137, loss:0.00000, loss_test:0.08386, lr:7.47e-03, fs:0.85057 (r=0.747,p=0.987),  time:18.599, tt:2566.659\n",
      "Ep:138, loss:0.00000, loss_test:0.08168, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.603, tt:2585.756\n",
      "Ep:139, loss:0.00000, loss_test:0.08045, lr:7.47e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.604, tt:2604.592\n",
      "Ep:140, loss:0.00000, loss_test:0.08202, lr:7.47e-03, fs:0.84571 (r=0.747,p=0.974),  time:18.599, tt:2622.414\n",
      "Ep:141, loss:0.00000, loss_test:0.08508, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.600, tt:2641.212\n",
      "Ep:142, loss:0.00000, loss_test:0.08305, lr:7.47e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.601, tt:2659.932\n",
      "Ep:143, loss:0.00000, loss_test:0.08313, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.607, tt:2679.398\n",
      "Ep:144, loss:0.00000, loss_test:0.08349, lr:7.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:18.610, tt:2698.456\n",
      "Ep:145, loss:0.00000, loss_test:0.09145, lr:7.40e-03, fs:0.85393 (r=0.768,p=0.962),  time:18.613, tt:2717.473\n",
      "Ep:146, loss:0.00000, loss_test:0.08670, lr:7.32e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.620, tt:2737.126\n",
      "Ep:147, loss:0.00000, loss_test:0.08447, lr:7.25e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.617, tt:2755.335\n",
      "Ep:148, loss:0.00000, loss_test:0.08387, lr:7.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:18.621, tt:2774.548\n",
      "Ep:149, loss:0.00000, loss_test:0.08606, lr:7.11e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.628, tt:2794.193\n",
      "Ep:150, loss:0.00000, loss_test:0.08844, lr:7.03e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.630, tt:2813.109\n",
      "Ep:151, loss:0.00000, loss_test:0.08571, lr:6.96e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.632, tt:2832.021\n",
      "Ep:152, loss:0.00000, loss_test:0.08505, lr:6.89e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.635, tt:2851.124\n",
      "Ep:153, loss:0.00000, loss_test:0.08552, lr:6.83e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.641, tt:2870.672\n",
      "Ep:154, loss:0.00000, loss_test:0.08416, lr:6.76e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.648, tt:2890.366\n",
      "Ep:155, loss:0.00000, loss_test:0.08503, lr:6.69e-03, fs:0.85714 (r=0.758,p=0.987),  time:18.649, tt:2909.225\n",
      "Ep:156, loss:0.00000, loss_test:0.08498, lr:6.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:18.648, tt:2927.772\n",
      "Ep:157, loss:0.00000, loss_test:0.08580, lr:6.56e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.653, tt:2947.188\n",
      "Ep:158, loss:0.00000, loss_test:0.08630, lr:6.49e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.660, tt:2966.880\n",
      "Ep:159, loss:0.00000, loss_test:0.08444, lr:6.43e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.667, tt:2986.754\n",
      "Ep:160, loss:0.00000, loss_test:0.08570, lr:6.36e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.697, tt:3010.222\n",
      "Ep:161, loss:0.00000, loss_test:0.08868, lr:6.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.703, tt:3029.886\n",
      "Ep:162, loss:0.00000, loss_test:0.08566, lr:6.24e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.710, tt:3049.746\n",
      "Ep:163, loss:0.00000, loss_test:0.08387, lr:6.17e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.716, tt:3069.491\n",
      "Ep:164, loss:0.00000, loss_test:0.08653, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.721, tt:3088.983\n",
      "Ep:165, loss:0.00000, loss_test:0.08749, lr:6.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.722, tt:3107.904\n",
      "Ep:166, loss:0.00000, loss_test:0.08555, lr:5.99e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.728, tt:3127.616\n",
      "Ep:167, loss:0.00000, loss_test:0.08537, lr:5.93e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.735, tt:3147.516\n",
      "Ep:168, loss:0.00000, loss_test:0.08457, lr:5.87e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.739, tt:3166.966\n",
      "Ep:169, loss:0.00000, loss_test:0.08581, lr:5.81e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.739, tt:3185.668\n",
      "Ep:170, loss:0.00000, loss_test:0.08684, lr:5.75e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.746, tt:3205.590\n",
      "Ep:171, loss:0.00000, loss_test:0.08479, lr:5.70e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.752, tt:3225.393\n",
      "Ep:172, loss:0.00000, loss_test:0.08408, lr:5.64e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.754, tt:3244.423\n",
      "Ep:173, loss:0.00000, loss_test:0.08597, lr:5.58e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.753, tt:3262.988\n",
      "Ep:174, loss:0.00000, loss_test:0.08598, lr:5.53e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.754, tt:3281.948\n",
      "Ep:175, loss:0.00000, loss_test:0.08388, lr:5.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.759, tt:3301.620\n",
      "Ep:176, loss:0.00000, loss_test:0.08428, lr:5.42e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.765, tt:3321.466\n",
      "Ep:177, loss:0.00000, loss_test:0.08594, lr:5.36e-03, fs:0.85057 (r=0.747,p=0.987),  time:18.769, tt:3340.952\n",
      "Ep:178, loss:0.00000, loss_test:0.08496, lr:5.31e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.769, tt:3359.584\n",
      "Ep:179, loss:0.00000, loss_test:0.08399, lr:5.26e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.776, tt:3379.669\n",
      "Ep:180, loss:0.00000, loss_test:0.08538, lr:5.20e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.778, tt:3398.898\n",
      "Ep:181, loss:0.00000, loss_test:0.08590, lr:5.15e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.779, tt:3417.732\n",
      "Ep:182, loss:0.00000, loss_test:0.08510, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.784, tt:3437.447\n",
      "Ep:183, loss:0.00000, loss_test:0.08526, lr:5.05e-03, fs:0.85057 (r=0.747,p=0.987),  time:18.780, tt:3455.432\n",
      "Ep:184, loss:0.00000, loss_test:0.08542, lr:5.00e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.784, tt:3474.993\n",
      "Ep:185, loss:0.00000, loss_test:0.08537, lr:4.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.782, tt:3493.536\n",
      "Ep:186, loss:0.00000, loss_test:0.08533, lr:4.90e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.780, tt:3511.917\n",
      "Ep:187, loss:0.00000, loss_test:0.08560, lr:4.85e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.784, tt:3531.304\n",
      "Ep:188, loss:0.00000, loss_test:0.08504, lr:4.80e-03, fs:0.85714 (r=0.758,p=0.987),  time:18.775, tt:3548.529\n",
      "Ep:189, loss:0.00000, loss_test:0.08499, lr:4.75e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.775, tt:3567.321\n",
      "Ep:190, loss:0.00000, loss_test:0.08634, lr:4.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.773, tt:3585.548\n",
      "Ep:191, loss:0.00000, loss_test:0.08660, lr:4.66e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.775, tt:3604.844\n",
      "Ep:192, loss:0.00000, loss_test:0.08668, lr:4.61e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.772, tt:3622.956\n",
      "Ep:193, loss:0.00000, loss_test:0.08565, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.771, tt:3641.608\n",
      "Ep:194, loss:0.00000, loss_test:0.08583, lr:4.52e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.772, tt:3660.589\n",
      "Ep:195, loss:0.00000, loss_test:0.08778, lr:4.48e-03, fs:0.85714 (r=0.758,p=0.987),  time:18.768, tt:3678.597\n",
      "Ep:196, loss:0.00000, loss_test:0.08649, lr:4.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.771, tt:3697.878\n",
      "Ep:197, loss:0.00000, loss_test:0.08594, lr:4.39e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.790, tt:3720.463\n",
      "Ep:198, loss:0.00000, loss_test:0.08728, lr:4.34e-03, fs:0.85057 (r=0.747,p=0.987),  time:18.792, tt:3739.676\n",
      "Ep:199, loss:0.00000, loss_test:0.08699, lr:4.30e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.791, tt:3758.278\n",
      "Ep:200, loss:0.00000, loss_test:0.08600, lr:4.26e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.797, tt:3778.218\n",
      "Ep:201, loss:0.00000, loss_test:0.08683, lr:4.21e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.805, tt:3798.626\n",
      "Ep:202, loss:0.00000, loss_test:0.08711, lr:4.17e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.811, tt:3818.615\n",
      "Ep:203, loss:0.00000, loss_test:0.08663, lr:4.13e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.812, tt:3837.554\n",
      "Ep:204, loss:0.00000, loss_test:0.08669, lr:4.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:18.818, tt:3857.690\n",
      "Ep:205, loss:0.00000, loss_test:0.08691, lr:4.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:18.820, tt:3877.014\n",
      "Ep:206, loss:0.00000, loss_test:0.08681, lr:4.01e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.821, tt:3895.979\n",
      "Ep:207, loss:0.00000, loss_test:0.08729, lr:3.97e-03, fs:0.85714 (r=0.758,p=0.987),  time:18.817, tt:3914.035\n",
      "Ep:208, loss:0.00000, loss_test:0.08705, lr:3.93e-03, fs:0.84393 (r=0.737,p=0.986),  time:18.820, tt:3933.351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.08752, lr:3.89e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.820, tt:3952.265\n",
      "Ep:210, loss:0.00000, loss_test:0.08714, lr:3.85e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.825, tt:3972.096\n",
      "Ep:211, loss:0.00000, loss_test:0.08624, lr:3.81e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.829, tt:3991.797\n",
      "Ep:212, loss:0.00000, loss_test:0.08701, lr:3.77e-03, fs:0.84884 (r=0.737,p=1.000),  time:18.830, tt:4010.828\n",
      "Ep:213, loss:0.00000, loss_test:0.08756, lr:3.73e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.829, tt:4029.370\n",
      "Ep:214, loss:0.00000, loss_test:0.08700, lr:3.70e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.835, tt:4049.492\n",
      "Ep:215, loss:0.00000, loss_test:0.08689, lr:3.66e-03, fs:0.84884 (r=0.737,p=1.000),  time:18.840, tt:4069.540\n",
      "Ep:216, loss:0.00000, loss_test:0.08714, lr:3.62e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.843, tt:4089.017\n",
      "Ep:217, loss:0.00000, loss_test:0.08769, lr:3.59e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.846, tt:4108.494\n",
      "Ep:218, loss:0.00000, loss_test:0.08735, lr:3.55e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.850, tt:4128.220\n",
      "Ep:219, loss:0.00000, loss_test:0.08672, lr:3.52e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.852, tt:4147.352\n",
      "Ep:220, loss:0.00000, loss_test:0.08725, lr:3.48e-03, fs:0.84884 (r=0.737,p=1.000),  time:18.855, tt:4167.023\n",
      "Ep:221, loss:0.00000, loss_test:0.08758, lr:3.45e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.851, tt:4184.859\n",
      "Ep:222, loss:0.00000, loss_test:0.08722, lr:3.41e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.850, tt:4203.642\n",
      "Ep:223, loss:0.00000, loss_test:0.08715, lr:3.38e-03, fs:0.84884 (r=0.737,p=1.000),  time:18.853, tt:4223.104\n",
      "Ep:224, loss:0.00000, loss_test:0.08710, lr:3.34e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.853, tt:4241.871\n",
      "Ep:225, loss:0.00000, loss_test:0.08743, lr:3.31e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.854, tt:4260.943\n",
      "Ep:226, loss:0.00000, loss_test:0.08755, lr:3.28e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.858, tt:4280.721\n",
      "Ep:227, loss:0.00000, loss_test:0.08711, lr:3.24e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.857, tt:4299.329\n",
      "Ep:228, loss:0.00000, loss_test:0.08711, lr:3.21e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.847, tt:4316.027\n",
      "Ep:229, loss:0.00000, loss_test:0.08766, lr:3.18e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.839, tt:4332.950\n",
      "Ep:230, loss:0.00000, loss_test:0.08766, lr:3.15e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.829, tt:4349.542\n",
      "Ep:231, loss:0.00000, loss_test:0.08740, lr:3.12e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.819, tt:4366.118\n",
      "Ep:232, loss:0.00000, loss_test:0.08770, lr:3.09e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.811, tt:4382.943\n",
      "Ep:233, loss:0.00000, loss_test:0.08766, lr:3.05e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.804, tt:4400.200\n",
      "Ep:234, loss:0.00000, loss_test:0.08739, lr:3.02e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.808, tt:4419.922\n",
      "Ep:235, loss:0.00000, loss_test:0.08761, lr:2.99e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.796, tt:4435.847\n",
      "Ep:236, loss:0.00000, loss_test:0.08765, lr:2.96e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.789, tt:4453.031\n",
      "Ep:237, loss:0.00000, loss_test:0.08757, lr:2.93e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.782, tt:4470.042\n",
      "Ep:238, loss:0.00000, loss_test:0.08777, lr:2.90e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.768, tt:4485.438\n",
      "Ep:239, loss:0.00000, loss_test:0.08781, lr:2.88e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.761, tt:4502.728\n",
      "Ep:240, loss:0.00000, loss_test:0.08781, lr:2.85e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.753, tt:4519.561\n",
      "Ep:241, loss:0.00000, loss_test:0.08818, lr:2.82e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.750, tt:4537.404\n",
      "Ep:242, loss:0.00000, loss_test:0.08813, lr:2.79e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.747, tt:4555.517\n",
      "Ep:243, loss:0.00000, loss_test:0.08777, lr:2.76e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.741, tt:4572.877\n",
      "Ep:244, loss:0.00000, loss_test:0.08781, lr:2.73e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.730, tt:4588.759\n",
      "Ep:245, loss:0.00000, loss_test:0.08810, lr:2.71e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.729, tt:4607.277\n",
      "Ep:246, loss:0.00000, loss_test:0.08833, lr:2.68e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.718, tt:4623.318\n",
      "Ep:247, loss:0.00000, loss_test:0.08858, lr:2.65e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.713, tt:4640.851\n",
      "Ep:248, loss:0.00000, loss_test:0.08828, lr:2.63e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.705, tt:4657.600\n",
      "Ep:249, loss:0.00000, loss_test:0.08803, lr:2.60e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.701, tt:4675.323\n",
      "Ep:250, loss:0.00000, loss_test:0.08819, lr:2.57e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.698, tt:4693.093\n",
      "Ep:251, loss:0.00000, loss_test:0.08835, lr:2.55e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.688, tt:4709.277\n",
      "Ep:252, loss:0.00000, loss_test:0.08831, lr:2.52e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.681, tt:4726.208\n",
      "Ep:253, loss:0.00000, loss_test:0.08821, lr:2.50e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.673, tt:4742.935\n",
      "Ep:254, loss:0.00000, loss_test:0.08877, lr:2.47e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.665, tt:4759.556\n",
      "Ep:255, loss:0.00000, loss_test:0.08885, lr:2.45e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.656, tt:4775.840\n",
      "Ep:256, loss:0.00000, loss_test:0.08851, lr:2.42e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.644, tt:4791.595\n",
      "Ep:257, loss:0.00000, loss_test:0.08825, lr:2.40e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.635, tt:4807.954\n",
      "Ep:258, loss:0.00000, loss_test:0.08863, lr:2.38e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.628, tt:4824.762\n",
      "Ep:259, loss:0.00000, loss_test:0.08901, lr:2.35e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.621, tt:4841.560\n",
      "Ep:260, loss:0.00000, loss_test:0.08889, lr:2.33e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.614, tt:4858.272\n",
      "Ep:261, loss:0.00000, loss_test:0.08863, lr:2.31e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.609, tt:4875.430\n",
      "Ep:262, loss:0.00000, loss_test:0.08852, lr:2.28e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.604, tt:4892.786\n",
      "Ep:263, loss:0.00000, loss_test:0.08862, lr:2.26e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.601, tt:4910.581\n",
      "Ep:264, loss:0.00000, loss_test:0.08881, lr:2.24e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.593, tt:4927.243\n",
      "Ep:265, loss:0.00000, loss_test:0.08892, lr:2.21e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.591, tt:4945.187\n",
      "Ep:266, loss:0.00000, loss_test:0.08879, lr:2.19e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.591, tt:4963.835\n",
      "Ep:267, loss:0.00000, loss_test:0.08863, lr:2.17e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.587, tt:4981.449\n",
      "Ep:268, loss:0.00000, loss_test:0.08869, lr:2.15e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.582, tt:4998.686\n",
      "Ep:269, loss:0.00000, loss_test:0.08881, lr:2.13e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.572, tt:5014.393\n",
      "Ep:270, loss:0.00000, loss_test:0.08869, lr:2.11e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.569, tt:5032.249\n",
      "Ep:271, loss:0.00000, loss_test:0.08865, lr:2.08e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.566, tt:5049.836\n",
      "Ep:272, loss:0.00000, loss_test:0.08876, lr:2.06e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.564, tt:5068.076\n",
      "Ep:273, loss:0.00000, loss_test:0.08888, lr:2.04e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.560, tt:5085.387\n",
      "Ep:274, loss:0.00000, loss_test:0.08876, lr:2.02e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.552, tt:5101.697\n",
      "Ep:275, loss:0.00000, loss_test:0.08855, lr:2.00e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.550, tt:5119.718\n",
      "Ep:276, loss:0.00000, loss_test:0.08854, lr:1.98e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.544, tt:5136.643\n",
      "Ep:277, loss:0.00000, loss_test:0.08884, lr:1.96e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.538, tt:5153.431\n",
      "Ep:278, loss:0.00000, loss_test:0.08899, lr:1.94e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.529, tt:5169.634\n",
      "Ep:279, loss:0.00000, loss_test:0.08892, lr:1.92e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.519, tt:5185.431\n",
      "Ep:280, loss:0.00000, loss_test:0.08904, lr:1.90e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.513, tt:5202.068\n",
      "Ep:281, loss:0.00000, loss_test:0.08906, lr:1.89e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.507, tt:5219.026\n",
      "Ep:282, loss:0.00000, loss_test:0.08886, lr:1.87e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.505, tt:5236.996\n",
      "Ep:283, loss:0.00000, loss_test:0.08876, lr:1.85e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.500, tt:5253.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:284, loss:0.00000, loss_test:0.08905, lr:1.83e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.493, tt:5270.385\n",
      "Ep:285, loss:0.00000, loss_test:0.08914, lr:1.81e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.482, tt:5285.935\n",
      "Ep:286, loss:0.00000, loss_test:0.08903, lr:1.79e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.476, tt:5302.624\n",
      "Ep:287, loss:0.00000, loss_test:0.08895, lr:1.78e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.474, tt:5320.606\n",
      "Ep:288, loss:0.00000, loss_test:0.08913, lr:1.76e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.464, tt:5336.222\n",
      "Ep:289, loss:0.00000, loss_test:0.08914, lr:1.74e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.454, tt:5351.656\n",
      "Ep:290, loss:0.00000, loss_test:0.08900, lr:1.72e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.449, tt:5368.607\n",
      "Ep:291, loss:0.00000, loss_test:0.08909, lr:1.71e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.444, tt:5385.562\n",
      "Ep:292, loss:0.00000, loss_test:0.08913, lr:1.69e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.439, tt:5402.642\n",
      "Ep:293, loss:0.00000, loss_test:0.08912, lr:1.67e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.433, tt:5419.204\n",
      "Ep:294, loss:0.00000, loss_test:0.08903, lr:1.65e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.424, tt:5435.220\n",
      "Ep:295, loss:0.00000, loss_test:0.08910, lr:1.64e-03, fs:0.84211 (r=0.727,p=1.000),  time:18.419, tt:5452.171\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14344, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.446, tt:8.446\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14325, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.825, tt:17.650\n",
      "Ep:2, loss:0.00004, loss_test:0.14298, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.446, tt:31.338\n",
      "Ep:3, loss:0.00004, loss_test:0.14260, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.579, tt:46.318\n",
      "Ep:4, loss:0.00004, loss_test:0.14212, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.286, tt:61.428\n",
      "Ep:5, loss:0.00004, loss_test:0.14150, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.791, tt:76.748\n",
      "Ep:6, loss:0.00004, loss_test:0.14077, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.153, tt:92.068\n",
      "Ep:7, loss:0.00004, loss_test:0.13987, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.395, tt:107.158\n",
      "Ep:8, loss:0.00004, loss_test:0.13878, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.623, tt:122.609\n",
      "Ep:9, loss:0.00004, loss_test:0.13749, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.811, tt:138.113\n",
      "Ep:10, loss:0.00004, loss_test:0.13591, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:13.974, tt:153.712\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.13394, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:14.023, tt:168.281\n",
      "Ep:12, loss:0.00004, loss_test:0.13147, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:14.109, tt:183.413\n",
      "Ep:13, loss:0.00004, loss_test:0.12843, lr:1.00e-02, fs:0.68100 (r=0.960,p=0.528),  time:14.179, tt:198.507\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.12510, lr:1.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:14.413, tt:216.195\n",
      "Ep:15, loss:0.00004, loss_test:0.12149, lr:1.00e-02, fs:0.66667 (r=0.818,p=0.562),  time:14.492, tt:231.871\n",
      "Ep:16, loss:0.00003, loss_test:0.11844, lr:1.00e-02, fs:0.66364 (r=0.737,p=0.603),  time:14.586, tt:247.963\n",
      "Ep:17, loss:0.00003, loss_test:0.11665, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:14.532, tt:261.570\n",
      "Ep:18, loss:0.00003, loss_test:0.11649, lr:1.00e-02, fs:0.61458 (r=0.596,p=0.634),  time:14.542, tt:276.297\n",
      "Ep:19, loss:0.00003, loss_test:0.11655, lr:1.00e-02, fs:0.63102 (r=0.596,p=0.670),  time:14.570, tt:291.401\n",
      "Ep:20, loss:0.00003, loss_test:0.11555, lr:1.00e-02, fs:0.62703 (r=0.586,p=0.674),  time:14.672, tt:308.120\n",
      "Ep:21, loss:0.00003, loss_test:0.11406, lr:1.00e-02, fs:0.66316 (r=0.636,p=0.692),  time:14.694, tt:323.271\n",
      "Ep:22, loss:0.00003, loss_test:0.11345, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:14.729, tt:338.776\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.11333, lr:1.00e-02, fs:0.67980 (r=0.697,p=0.663),  time:14.749, tt:353.970\n",
      "Ep:24, loss:0.00003, loss_test:0.11301, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:14.827, tt:370.673\n",
      "Ep:25, loss:0.00003, loss_test:0.11225, lr:1.00e-02, fs:0.67662 (r=0.687,p=0.667),  time:14.855, tt:386.224\n",
      "Ep:26, loss:0.00003, loss_test:0.11208, lr:1.00e-02, fs:0.67010 (r=0.657,p=0.684),  time:14.907, tt:402.501\n",
      "Ep:27, loss:0.00003, loss_test:0.11256, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:14.938, tt:418.256\n",
      "Ep:28, loss:0.00003, loss_test:0.11276, lr:1.00e-02, fs:0.67391 (r=0.626,p=0.729),  time:14.971, tt:434.152\n",
      "Ep:29, loss:0.00003, loss_test:0.11204, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:14.986, tt:449.583\n",
      "Ep:30, loss:0.00003, loss_test:0.11079, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:14.969, tt:464.053\n",
      "Ep:31, loss:0.00003, loss_test:0.11009, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:14.981, tt:479.389\n",
      "Ep:32, loss:0.00003, loss_test:0.10954, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:14.985, tt:494.504\n",
      "Ep:33, loss:0.00003, loss_test:0.10902, lr:1.00e-02, fs:0.66667 (r=0.646,p=0.688),  time:14.974, tt:509.116\n",
      "Ep:34, loss:0.00003, loss_test:0.10887, lr:9.90e-03, fs:0.66667 (r=0.626,p=0.713),  time:14.994, tt:524.786\n",
      "Ep:35, loss:0.00003, loss_test:0.10915, lr:9.80e-03, fs:0.67391 (r=0.626,p=0.729),  time:15.041, tt:541.469\n",
      "Ep:36, loss:0.00003, loss_test:0.10930, lr:9.70e-03, fs:0.67760 (r=0.626,p=0.738),  time:15.033, tt:556.221\n",
      "Ep:37, loss:0.00002, loss_test:0.10911, lr:9.61e-03, fs:0.67760 (r=0.626,p=0.738),  time:15.068, tt:572.580\n",
      "Ep:38, loss:0.00002, loss_test:0.10874, lr:9.51e-03, fs:0.68108 (r=0.636,p=0.733),  time:15.067, tt:587.603\n",
      "Ep:39, loss:0.00002, loss_test:0.10841, lr:9.41e-03, fs:0.68449 (r=0.646,p=0.727),  time:15.078, tt:603.107\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10828, lr:9.41e-03, fs:0.68421 (r=0.657,p=0.714),  time:15.095, tt:618.913\n",
      "Ep:41, loss:0.00002, loss_test:0.10821, lr:9.41e-03, fs:0.68783 (r=0.657,p=0.722),  time:15.113, tt:634.748\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10816, lr:9.41e-03, fs:0.68449 (r=0.646,p=0.727),  time:15.138, tt:650.945\n",
      "Ep:43, loss:0.00002, loss_test:0.10813, lr:9.41e-03, fs:0.68108 (r=0.636,p=0.733),  time:15.154, tt:666.776\n",
      "Ep:44, loss:0.00002, loss_test:0.10799, lr:9.41e-03, fs:0.69189 (r=0.646,p=0.744),  time:15.172, tt:682.740\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.10761, lr:9.41e-03, fs:0.67725 (r=0.646,p=0.711),  time:15.183, tt:698.429\n",
      "Ep:46, loss:0.00002, loss_test:0.10712, lr:9.41e-03, fs:0.68421 (r=0.657,p=0.714),  time:15.182, tt:713.532\n",
      "Ep:47, loss:0.00002, loss_test:0.10665, lr:9.41e-03, fs:0.68750 (r=0.667,p=0.710),  time:15.179, tt:728.599\n",
      "Ep:48, loss:0.00002, loss_test:0.10632, lr:9.41e-03, fs:0.68421 (r=0.657,p=0.714),  time:15.166, tt:743.113\n",
      "Ep:49, loss:0.00002, loss_test:0.10611, lr:9.41e-03, fs:0.68421 (r=0.657,p=0.714),  time:15.201, tt:760.071\n",
      "Ep:50, loss:0.00002, loss_test:0.10576, lr:9.41e-03, fs:0.68783 (r=0.657,p=0.722),  time:15.225, tt:776.479\n",
      "Ep:51, loss:0.00002, loss_test:0.10536, lr:9.41e-03, fs:0.68783 (r=0.657,p=0.722),  time:15.245, tt:792.718\n",
      "Ep:52, loss:0.00002, loss_test:0.10496, lr:9.41e-03, fs:0.69474 (r=0.667,p=0.725),  time:15.238, tt:807.618\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.10463, lr:9.41e-03, fs:0.70157 (r=0.677,p=0.728),  time:15.242, tt:823.090\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.10443, lr:9.41e-03, fs:0.70157 (r=0.677,p=0.728),  time:15.241, tt:838.238\n",
      "Ep:55, loss:0.00002, loss_test:0.10432, lr:9.41e-03, fs:0.69841 (r=0.667,p=0.733),  time:15.240, tt:853.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00002, loss_test:0.10407, lr:9.41e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.244, tt:868.936\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.10367, lr:9.41e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.230, tt:883.318\n",
      "Ep:58, loss:0.00002, loss_test:0.10327, lr:9.41e-03, fs:0.71875 (r=0.697,p=0.742),  time:15.220, tt:897.962\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.10307, lr:9.41e-03, fs:0.72251 (r=0.697,p=0.750),  time:15.224, tt:913.431\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.10308, lr:9.41e-03, fs:0.72251 (r=0.697,p=0.750),  time:15.229, tt:928.985\n",
      "Ep:61, loss:0.00002, loss_test:0.10305, lr:9.41e-03, fs:0.73298 (r=0.707,p=0.761),  time:15.219, tt:943.558\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.10294, lr:9.41e-03, fs:0.73298 (r=0.707,p=0.761),  time:15.225, tt:959.177\n",
      "Ep:63, loss:0.00002, loss_test:0.10279, lr:9.41e-03, fs:0.73298 (r=0.707,p=0.761),  time:15.235, tt:975.053\n",
      "Ep:64, loss:0.00002, loss_test:0.10267, lr:9.41e-03, fs:0.73298 (r=0.707,p=0.761),  time:15.226, tt:989.697\n",
      "Ep:65, loss:0.00002, loss_test:0.10257, lr:9.41e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.214, tt:1004.139\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.10247, lr:9.41e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.192, tt:1017.861\n",
      "Ep:67, loss:0.00002, loss_test:0.10236, lr:9.41e-03, fs:0.74737 (r=0.717,p=0.780),  time:15.187, tt:1032.720\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.10223, lr:9.41e-03, fs:0.74737 (r=0.717,p=0.780),  time:15.189, tt:1048.007\n",
      "Ep:69, loss:0.00002, loss_test:0.10210, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.179, tt:1062.543\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.10202, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.183, tt:1078.014\n",
      "Ep:71, loss:0.00002, loss_test:0.10199, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.191, tt:1093.774\n",
      "Ep:72, loss:0.00002, loss_test:0.10191, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.181, tt:1108.176\n",
      "Ep:73, loss:0.00002, loss_test:0.10182, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.186, tt:1123.755\n",
      "Ep:74, loss:0.00002, loss_test:0.10186, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.171, tt:1137.801\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.10198, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.185, tt:1154.049\n",
      "Ep:76, loss:0.00002, loss_test:0.10207, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.186, tt:1169.324\n",
      "Ep:77, loss:0.00002, loss_test:0.10215, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.200, tt:1185.607\n",
      "Ep:78, loss:0.00002, loss_test:0.10205, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.215, tt:1201.958\n",
      "Ep:79, loss:0.00002, loss_test:0.10195, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.201, tt:1216.113\n",
      "Ep:80, loss:0.00002, loss_test:0.10196, lr:9.41e-03, fs:0.76042 (r=0.737,p=0.785),  time:15.202, tt:1231.328\n",
      "Ep:81, loss:0.00002, loss_test:0.10206, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.201, tt:1246.503\n",
      "Ep:82, loss:0.00001, loss_test:0.10204, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.210, tt:1262.402\n",
      "Ep:83, loss:0.00001, loss_test:0.10191, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.224, tt:1278.801\n",
      "Ep:84, loss:0.00001, loss_test:0.10176, lr:9.41e-03, fs:0.76440 (r=0.737,p=0.793),  time:15.239, tt:1295.306\n",
      "Ep:85, loss:0.00001, loss_test:0.10164, lr:9.41e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.248, tt:1311.363\n",
      "Ep:86, loss:0.00001, loss_test:0.10165, lr:9.32e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.259, tt:1327.538\n",
      "Ep:87, loss:0.00001, loss_test:0.10159, lr:9.23e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.257, tt:1342.636\n",
      "Ep:88, loss:0.00001, loss_test:0.10144, lr:9.14e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.262, tt:1358.352\n",
      "Ep:89, loss:0.00001, loss_test:0.10138, lr:9.04e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.270, tt:1374.287\n",
      "Ep:90, loss:0.00001, loss_test:0.10146, lr:8.95e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.286, tt:1391.070\n",
      "Ep:91, loss:0.00001, loss_test:0.10144, lr:8.86e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.299, tt:1407.534\n",
      "Ep:92, loss:0.00001, loss_test:0.10126, lr:8.78e-03, fs:0.75789 (r=0.727,p=0.791),  time:15.308, tt:1423.673\n",
      "Ep:93, loss:0.00001, loss_test:0.10109, lr:8.69e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.315, tt:1439.572\n",
      "Ep:94, loss:0.00001, loss_test:0.10095, lr:8.60e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.312, tt:1454.634\n",
      "Ep:95, loss:0.00001, loss_test:0.10075, lr:8.51e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.315, tt:1470.193\n",
      "Ep:96, loss:0.00001, loss_test:0.10063, lr:8.43e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.324, tt:1486.392\n",
      "Ep:97, loss:0.00001, loss_test:0.10059, lr:8.35e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.331, tt:1502.440\n",
      "Ep:98, loss:0.00001, loss_test:0.10041, lr:8.26e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.326, tt:1517.229\n",
      "Ep:99, loss:0.00001, loss_test:0.10017, lr:8.18e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.320, tt:1531.976\n",
      "Ep:100, loss:0.00001, loss_test:0.10004, lr:8.10e-03, fs:0.76190 (r=0.727,p=0.800),  time:15.318, tt:1547.106\n",
      "Ep:101, loss:0.00001, loss_test:0.10008, lr:8.02e-03, fs:0.76596 (r=0.727,p=0.809),  time:15.306, tt:1561.233\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.10013, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.302, tt:1576.064\n",
      "Ep:103, loss:0.00001, loss_test:0.10001, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.293, tt:1590.504\n",
      "Ep:104, loss:0.00001, loss_test:0.09987, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.289, tt:1605.335\n",
      "Ep:105, loss:0.00001, loss_test:0.09984, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.283, tt:1620.014\n",
      "Ep:106, loss:0.00001, loss_test:0.09985, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.284, tt:1635.417\n",
      "Ep:107, loss:0.00001, loss_test:0.09974, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.273, tt:1649.505\n",
      "Ep:108, loss:0.00001, loss_test:0.09953, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.264, tt:1663.825\n",
      "Ep:109, loss:0.00001, loss_test:0.09934, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.260, tt:1678.564\n",
      "Ep:110, loss:0.00001, loss_test:0.09919, lr:8.02e-03, fs:0.75936 (r=0.717,p=0.807),  time:15.252, tt:1692.919\n",
      "Ep:111, loss:0.00001, loss_test:0.09909, lr:8.02e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.235, tt:1706.360\n",
      "Ep:112, loss:0.00001, loss_test:0.09902, lr:8.02e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.233, tt:1721.355\n",
      "Ep:113, loss:0.00001, loss_test:0.09887, lr:7.94e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.227, tt:1735.882\n",
      "Ep:114, loss:0.00001, loss_test:0.09867, lr:7.86e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.223, tt:1750.625\n",
      "Ep:115, loss:0.00001, loss_test:0.09857, lr:7.78e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.213, tt:1764.672\n",
      "Ep:116, loss:0.00001, loss_test:0.09852, lr:7.70e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.211, tt:1779.731\n",
      "Ep:117, loss:0.00001, loss_test:0.09838, lr:7.62e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.207, tt:1794.454\n",
      "Ep:118, loss:0.00001, loss_test:0.09819, lr:7.55e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.199, tt:1808.737\n",
      "Ep:119, loss:0.00001, loss_test:0.09816, lr:7.47e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.204, tt:1824.432\n",
      "Ep:120, loss:0.00001, loss_test:0.09807, lr:7.40e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.206, tt:1839.867\n",
      "Ep:121, loss:0.00001, loss_test:0.09795, lr:7.32e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.209, tt:1855.527\n",
      "Ep:122, loss:0.00001, loss_test:0.09777, lr:7.25e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.214, tt:1871.339\n",
      "Ep:123, loss:0.00001, loss_test:0.09761, lr:7.18e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.209, tt:1885.975\n",
      "Ep:124, loss:0.00001, loss_test:0.09752, lr:7.11e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.209, tt:1901.122\n",
      "Ep:125, loss:0.00001, loss_test:0.09739, lr:7.03e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.203, tt:1915.549\n",
      "Ep:126, loss:0.00001, loss_test:0.09725, lr:6.96e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.196, tt:1929.856\n",
      "Ep:127, loss:0.00001, loss_test:0.09708, lr:6.89e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.197, tt:1945.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00001, loss_test:0.09692, lr:6.83e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.194, tt:1960.078\n",
      "Ep:129, loss:0.00001, loss_test:0.09678, lr:6.76e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.202, tt:1976.226\n",
      "Ep:130, loss:0.00001, loss_test:0.09664, lr:6.69e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.212, tt:1992.786\n",
      "Ep:131, loss:0.00001, loss_test:0.09658, lr:6.62e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.217, tt:2008.690\n",
      "Ep:132, loss:0.00001, loss_test:0.09658, lr:6.56e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.222, tt:2024.537\n",
      "Ep:133, loss:0.00001, loss_test:0.09658, lr:6.49e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.225, tt:2040.152\n",
      "Ep:134, loss:0.00001, loss_test:0.09649, lr:6.43e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.233, tt:2056.507\n",
      "Ep:135, loss:0.00001, loss_test:0.09641, lr:6.36e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.237, tt:2072.282\n",
      "Ep:136, loss:0.00001, loss_test:0.09629, lr:6.30e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.232, tt:2086.741\n",
      "Ep:137, loss:0.00001, loss_test:0.09619, lr:6.24e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.238, tt:2102.797\n",
      "Ep:138, loss:0.00001, loss_test:0.09615, lr:6.17e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.243, tt:2118.720\n",
      "Ep:139, loss:0.00001, loss_test:0.09610, lr:6.11e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.244, tt:2134.166\n",
      "Ep:140, loss:0.00001, loss_test:0.09601, lr:6.05e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.246, tt:2149.685\n",
      "Ep:141, loss:0.00001, loss_test:0.09595, lr:5.99e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.253, tt:2165.907\n",
      "Ep:142, loss:0.00001, loss_test:0.09591, lr:5.93e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.254, tt:2181.334\n",
      "Ep:143, loss:0.00001, loss_test:0.09586, lr:5.87e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.261, tt:2197.529\n",
      "Ep:144, loss:0.00001, loss_test:0.09580, lr:5.81e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.266, tt:2213.524\n",
      "Ep:145, loss:0.00001, loss_test:0.09579, lr:5.75e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.271, tt:2229.571\n",
      "Ep:146, loss:0.00001, loss_test:0.09580, lr:5.70e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.274, tt:2245.250\n",
      "Ep:147, loss:0.00001, loss_test:0.09582, lr:5.64e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.273, tt:2260.362\n",
      "Ep:148, loss:0.00001, loss_test:0.09578, lr:5.58e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.274, tt:2275.881\n",
      "Ep:149, loss:0.00001, loss_test:0.09579, lr:5.53e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.269, tt:2290.337\n",
      "Ep:150, loss:0.00001, loss_test:0.09572, lr:5.47e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.266, tt:2305.163\n",
      "Ep:151, loss:0.00001, loss_test:0.09567, lr:5.42e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.275, tt:2321.730\n",
      "Ep:152, loss:0.00001, loss_test:0.09563, lr:5.36e-03, fs:0.76344 (r=0.717,p=0.816),  time:15.278, tt:2337.592\n",
      "Ep:153, loss:0.00001, loss_test:0.09556, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.282, tt:2353.435\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00001, loss_test:0.09556, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.287, tt:2369.424\n",
      "Ep:155, loss:0.00001, loss_test:0.09567, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.287, tt:2384.744\n",
      "Ep:156, loss:0.00001, loss_test:0.09560, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.292, tt:2400.807\n",
      "Ep:157, loss:0.00001, loss_test:0.09548, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.298, tt:2417.091\n",
      "Ep:158, loss:0.00001, loss_test:0.09542, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.304, tt:2433.340\n",
      "Ep:159, loss:0.00001, loss_test:0.09538, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.314, tt:2450.163\n",
      "Ep:160, loss:0.00001, loss_test:0.09536, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.326, tt:2467.561\n",
      "Ep:161, loss:0.00001, loss_test:0.09536, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.324, tt:2482.557\n",
      "Ep:162, loss:0.00001, loss_test:0.09531, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.333, tt:2499.242\n",
      "Ep:163, loss:0.00001, loss_test:0.09523, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.330, tt:2514.171\n",
      "Ep:164, loss:0.00001, loss_test:0.09516, lr:5.31e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.330, tt:2529.410\n",
      "Ep:165, loss:0.00001, loss_test:0.09518, lr:5.26e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.326, tt:2544.145\n",
      "Ep:166, loss:0.00001, loss_test:0.09515, lr:5.20e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.326, tt:2559.496\n",
      "Ep:167, loss:0.00001, loss_test:0.09509, lr:5.15e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.321, tt:2573.931\n",
      "Ep:168, loss:0.00001, loss_test:0.09509, lr:5.10e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.322, tt:2589.457\n",
      "Ep:169, loss:0.00001, loss_test:0.09508, lr:5.05e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.323, tt:2604.879\n",
      "Ep:170, loss:0.00001, loss_test:0.09505, lr:5.00e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.326, tt:2620.726\n",
      "Ep:171, loss:0.00001, loss_test:0.09504, lr:4.95e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.322, tt:2635.319\n",
      "Ep:172, loss:0.00001, loss_test:0.09506, lr:4.90e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.322, tt:2650.758\n",
      "Ep:173, loss:0.00001, loss_test:0.09505, lr:4.85e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.323, tt:2666.138\n",
      "Ep:174, loss:0.00001, loss_test:0.09501, lr:4.80e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.322, tt:2681.285\n",
      "Ep:175, loss:0.00001, loss_test:0.09493, lr:4.75e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.314, tt:2695.269\n",
      "Ep:176, loss:0.00001, loss_test:0.09492, lr:4.71e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.320, tt:2711.667\n",
      "Ep:177, loss:0.00001, loss_test:0.09492, lr:4.66e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.318, tt:2726.571\n",
      "Ep:178, loss:0.00001, loss_test:0.09490, lr:4.61e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.317, tt:2741.694\n",
      "Ep:179, loss:0.00001, loss_test:0.09482, lr:4.57e-03, fs:0.77005 (r=0.727,p=0.818),  time:15.318, tt:2757.298\n",
      "Ep:180, loss:0.00001, loss_test:0.09478, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.316, tt:2772.111\n",
      "##########Best model found so far##########\n",
      "Ep:181, loss:0.00001, loss_test:0.09479, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.309, tt:2786.317\n",
      "Ep:182, loss:0.00001, loss_test:0.09477, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.311, tt:2801.928\n",
      "Ep:183, loss:0.00001, loss_test:0.09472, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.310, tt:2817.080\n",
      "Ep:184, loss:0.00001, loss_test:0.09465, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.311, tt:2832.619\n",
      "Ep:185, loss:0.00001, loss_test:0.09460, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.315, tt:2848.579\n",
      "Ep:186, loss:0.00001, loss_test:0.09457, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.315, tt:2863.825\n",
      "Ep:187, loss:0.00001, loss_test:0.09454, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.314, tt:2879.085\n",
      "Ep:188, loss:0.00001, loss_test:0.09453, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.321, tt:2895.760\n",
      "Ep:189, loss:0.00001, loss_test:0.09447, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.322, tt:2911.167\n",
      "Ep:190, loss:0.00001, loss_test:0.09441, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.324, tt:2926.958\n",
      "Ep:191, loss:0.00001, loss_test:0.09441, lr:4.52e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.325, tt:2942.437\n",
      "Ep:192, loss:0.00001, loss_test:0.09440, lr:4.48e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.323, tt:2957.356\n",
      "Ep:193, loss:0.00001, loss_test:0.09442, lr:4.43e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.327, tt:2973.443\n",
      "Ep:194, loss:0.00001, loss_test:0.09441, lr:4.39e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.326, tt:2988.518\n",
      "Ep:195, loss:0.00001, loss_test:0.09438, lr:4.34e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.324, tt:3003.553\n",
      "Ep:196, loss:0.00001, loss_test:0.09433, lr:4.30e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.324, tt:3018.881\n",
      "Ep:197, loss:0.00001, loss_test:0.09433, lr:4.26e-03, fs:0.77419 (r=0.727,p=0.828),  time:15.319, tt:3033.177\n",
      "Ep:198, loss:0.00001, loss_test:0.09433, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.318, tt:3048.228\n",
      "##########Best model found so far##########\n",
      "Ep:199, loss:0.00001, loss_test:0.09435, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.335, tt:3067.034\n",
      "Ep:200, loss:0.00001, loss_test:0.09434, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.337, tt:3082.773\n",
      "Ep:201, loss:0.00001, loss_test:0.09432, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.338, tt:3098.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00001, loss_test:0.09429, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.334, tt:3112.764\n",
      "Ep:203, loss:0.00001, loss_test:0.09431, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.339, tt:3129.123\n",
      "Ep:204, loss:0.00001, loss_test:0.09430, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.334, tt:3143.520\n",
      "Ep:205, loss:0.00001, loss_test:0.09427, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.338, tt:3159.595\n",
      "Ep:206, loss:0.00001, loss_test:0.09423, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.340, tt:3175.351\n",
      "Ep:207, loss:0.00001, loss_test:0.09418, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.343, tt:3191.272\n",
      "Ep:208, loss:0.00001, loss_test:0.09416, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.336, tt:3205.224\n",
      "Ep:209, loss:0.00001, loss_test:0.09412, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.337, tt:3220.731\n",
      "##########Best model found so far##########\n",
      "Ep:210, loss:0.00001, loss_test:0.09411, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.335, tt:3235.770\n",
      "Ep:211, loss:0.00001, loss_test:0.09410, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.338, tt:3251.550\n",
      "Ep:212, loss:0.00001, loss_test:0.09408, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.339, tt:3267.121\n",
      "Ep:213, loss:0.00001, loss_test:0.09405, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.345, tt:3283.780\n",
      "Ep:214, loss:0.00001, loss_test:0.09401, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.348, tt:3299.848\n",
      "Ep:215, loss:0.00001, loss_test:0.09397, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.348, tt:3315.179\n",
      "Ep:216, loss:0.00001, loss_test:0.09398, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.347, tt:3330.298\n",
      "Ep:217, loss:0.00001, loss_test:0.09396, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.346, tt:3345.478\n",
      "Ep:218, loss:0.00001, loss_test:0.09393, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.344, tt:3360.313\n",
      "Ep:219, loss:0.00001, loss_test:0.09394, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.344, tt:3375.625\n",
      "Ep:220, loss:0.00001, loss_test:0.09394, lr:4.21e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.341, tt:3390.356\n",
      "Ep:221, loss:0.00001, loss_test:0.09390, lr:4.17e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.343, tt:3406.067\n",
      "Ep:222, loss:0.00001, loss_test:0.09386, lr:4.13e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.346, tt:3422.102\n",
      "Ep:223, loss:0.00001, loss_test:0.09387, lr:4.09e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.344, tt:3437.118\n",
      "Ep:224, loss:0.00001, loss_test:0.09387, lr:4.05e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.343, tt:3452.168\n",
      "Ep:225, loss:0.00001, loss_test:0.09385, lr:4.01e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.338, tt:3466.308\n",
      "Ep:226, loss:0.00001, loss_test:0.09381, lr:3.97e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.335, tt:3480.983\n",
      "Ep:227, loss:0.00001, loss_test:0.09382, lr:3.93e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.333, tt:3495.975\n",
      "Ep:228, loss:0.00001, loss_test:0.09383, lr:3.89e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.332, tt:3511.074\n",
      "Ep:229, loss:0.00001, loss_test:0.09377, lr:3.85e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.336, tt:3527.373\n",
      "Ep:230, loss:0.00001, loss_test:0.09372, lr:3.81e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.338, tt:3543.000\n",
      "Ep:231, loss:0.00001, loss_test:0.09367, lr:3.77e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.336, tt:3558.043\n",
      "Ep:232, loss:0.00001, loss_test:0.09366, lr:3.73e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.336, tt:3573.270\n",
      "Ep:233, loss:0.00001, loss_test:0.09362, lr:3.70e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.335, tt:3588.372\n",
      "Ep:234, loss:0.00001, loss_test:0.09362, lr:3.66e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.330, tt:3602.536\n",
      "Ep:235, loss:0.00001, loss_test:0.09356, lr:3.62e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.330, tt:3617.984\n",
      "Ep:236, loss:0.00001, loss_test:0.09353, lr:3.59e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.331, tt:3633.454\n",
      "Ep:237, loss:0.00001, loss_test:0.09351, lr:3.55e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.334, tt:3649.409\n",
      "Ep:238, loss:0.00001, loss_test:0.09352, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.333, tt:3664.660\n",
      "##########Best model found so far##########\n",
      "Ep:239, loss:0.00001, loss_test:0.09349, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.335, tt:3680.346\n",
      "Ep:240, loss:0.00001, loss_test:0.09345, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.336, tt:3695.929\n",
      "Ep:241, loss:0.00001, loss_test:0.09341, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.334, tt:3710.919\n",
      "Ep:242, loss:0.00001, loss_test:0.09337, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.335, tt:3726.294\n",
      "Ep:243, loss:0.00001, loss_test:0.09332, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.339, tt:3742.617\n",
      "Ep:244, loss:0.00001, loss_test:0.09325, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.339, tt:3758.128\n",
      "Ep:245, loss:0.00001, loss_test:0.09325, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.345, tt:3774.818\n",
      "Ep:246, loss:0.00001, loss_test:0.09323, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.346, tt:3790.429\n",
      "Ep:247, loss:0.00001, loss_test:0.09318, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.348, tt:3806.380\n",
      "Ep:248, loss:0.00001, loss_test:0.09314, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.346, tt:3821.044\n",
      "Ep:249, loss:0.00001, loss_test:0.09313, lr:3.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.351, tt:3837.768\n",
      "Ep:250, loss:0.00001, loss_test:0.09309, lr:3.48e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.350, tt:3852.876\n",
      "Ep:251, loss:0.00001, loss_test:0.09303, lr:3.45e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.351, tt:3868.542\n",
      "Ep:252, loss:0.00001, loss_test:0.09297, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.353, tt:3884.285\n",
      "##########Best model found so far##########\n",
      "Ep:253, loss:0.00001, loss_test:0.09297, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.354, tt:3900.005\n",
      "Ep:254, loss:0.00001, loss_test:0.09295, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.354, tt:3915.392\n",
      "Ep:255, loss:0.00001, loss_test:0.09292, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.355, tt:3931.000\n",
      "Ep:256, loss:0.00001, loss_test:0.09288, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.361, tt:3947.708\n",
      "Ep:257, loss:0.00001, loss_test:0.09285, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.361, tt:3963.259\n",
      "Ep:258, loss:0.00001, loss_test:0.09279, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.359, tt:3978.071\n",
      "Ep:259, loss:0.00001, loss_test:0.09272, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.365, tt:3994.929\n",
      "Ep:260, loss:0.00001, loss_test:0.09263, lr:3.41e-03, fs:0.79348 (r=0.737,p=0.859),  time:15.365, tt:4010.139\n",
      "Ep:261, loss:0.00001, loss_test:0.09257, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.364, tt:4025.408\n",
      "##########Best model found so far##########\n",
      "Ep:262, loss:0.00001, loss_test:0.09257, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.364, tt:4040.757\n",
      "Ep:263, loss:0.00001, loss_test:0.09252, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.363, tt:4055.831\n",
      "Ep:264, loss:0.00001, loss_test:0.09244, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.361, tt:4070.738\n",
      "Ep:265, loss:0.00001, loss_test:0.09238, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.361, tt:4086.033\n",
      "Ep:266, loss:0.00001, loss_test:0.09235, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.362, tt:4101.632\n",
      "Ep:267, loss:0.00001, loss_test:0.09232, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.364, tt:4117.475\n",
      "Ep:268, loss:0.00001, loss_test:0.09227, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.368, tt:4133.889\n",
      "Ep:269, loss:0.00001, loss_test:0.09221, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.371, tt:4150.060\n",
      "Ep:270, loss:0.00001, loss_test:0.09216, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.372, tt:4165.791\n",
      "Ep:271, loss:0.00001, loss_test:0.09213, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.370, tt:4180.746\n",
      "Ep:272, loss:0.00001, loss_test:0.09210, lr:3.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.370, tt:4195.935\n",
      "Ep:273, loss:0.00001, loss_test:0.09205, lr:3.38e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.370, tt:4211.447\n",
      "Ep:274, loss:0.00001, loss_test:0.09198, lr:3.34e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.368, tt:4226.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:275, loss:0.00001, loss_test:0.09194, lr:3.31e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.366, tt:4240.964\n",
      "Ep:276, loss:0.00001, loss_test:0.09188, lr:3.28e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.364, tt:4255.914\n",
      "Ep:277, loss:0.00001, loss_test:0.09183, lr:3.24e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.367, tt:4272.037\n",
      "Ep:278, loss:0.00001, loss_test:0.09178, lr:3.21e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.368, tt:4287.668\n",
      "Ep:279, loss:0.00001, loss_test:0.09173, lr:3.18e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.365, tt:4302.150\n",
      "Ep:280, loss:0.00001, loss_test:0.09169, lr:3.15e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.374, tt:4320.085\n",
      "Ep:281, loss:0.00001, loss_test:0.09170, lr:3.12e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.375, tt:4335.887\n",
      "Ep:282, loss:0.00001, loss_test:0.09169, lr:3.09e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.374, tt:4350.744\n",
      "Ep:283, loss:0.00001, loss_test:0.09168, lr:3.05e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.374, tt:4366.358\n",
      "Ep:284, loss:0.00001, loss_test:0.09165, lr:3.02e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.373, tt:4381.278\n",
      "Ep:285, loss:0.00001, loss_test:0.09164, lr:2.99e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.374, tt:4396.936\n",
      "Ep:286, loss:0.00001, loss_test:0.09163, lr:2.96e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.376, tt:4412.882\n",
      "Ep:287, loss:0.00001, loss_test:0.09162, lr:2.93e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.377, tt:4428.466\n",
      "Ep:288, loss:0.00001, loss_test:0.09160, lr:2.90e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.379, tt:4444.609\n",
      "Ep:289, loss:0.00001, loss_test:0.09158, lr:2.88e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.381, tt:4460.491\n",
      "Ep:290, loss:0.00001, loss_test:0.09157, lr:2.85e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.379, tt:4475.378\n",
      "##########Best model found so far##########\n",
      "Ep:291, loss:0.00001, loss_test:0.09156, lr:2.85e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.381, tt:4491.267\n",
      "Ep:292, loss:0.00001, loss_test:0.09155, lr:2.85e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.380, tt:4506.254\n",
      "Ep:293, loss:0.00001, loss_test:0.09156, lr:2.85e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.382, tt:4522.273\n",
      "Ep:294, loss:0.00001, loss_test:0.09153, lr:2.85e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.384, tt:4538.170\n",
      "Ep:295, loss:0.00001, loss_test:0.09146, lr:2.85e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.382, tt:4553.028\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14304, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.759, tt:18.759\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14253, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.854, tt:29.708\n",
      "Ep:2, loss:0.00004, loss_test:0.14176, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:14.164, tt:42.491\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.14068, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:15.027, tt:60.106\n",
      "Ep:4, loss:0.00004, loss_test:0.13922, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:16.187, tt:80.934\n",
      "Ep:5, loss:0.00004, loss_test:0.13730, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:16.797, tt:100.783\n",
      "Ep:6, loss:0.00004, loss_test:0.13479, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:17.321, tt:121.250\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.13156, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:17.701, tt:141.609\n",
      "Ep:8, loss:0.00004, loss_test:0.12727, lr:1.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:17.868, tt:160.811\n",
      "Ep:9, loss:0.00003, loss_test:0.12311, lr:1.00e-02, fs:0.61803 (r=0.727,p=0.537),  time:17.990, tt:179.903\n",
      "Ep:10, loss:0.00003, loss_test:0.11990, lr:1.00e-02, fs:0.63000 (r=0.636,p=0.624),  time:18.282, tt:201.102\n",
      "Ep:11, loss:0.00003, loss_test:0.11896, lr:1.00e-02, fs:0.61290 (r=0.576,p=0.655),  time:18.483, tt:221.798\n",
      "Ep:12, loss:0.00003, loss_test:0.11844, lr:1.00e-02, fs:0.61878 (r=0.566,p=0.683),  time:18.548, tt:241.121\n",
      "Ep:13, loss:0.00003, loss_test:0.11711, lr:1.00e-02, fs:0.63333 (r=0.576,p=0.704),  time:18.603, tt:260.437\n",
      "Ep:14, loss:0.00003, loss_test:0.11499, lr:1.00e-02, fs:0.63102 (r=0.596,p=0.670),  time:18.720, tt:280.795\n",
      "Ep:15, loss:0.00003, loss_test:0.11335, lr:1.00e-02, fs:0.64039 (r=0.657,p=0.625),  time:18.742, tt:299.868\n",
      "Ep:16, loss:0.00003, loss_test:0.11231, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:18.746, tt:318.679\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.11106, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:18.802, tt:338.431\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.10973, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:18.885, tt:358.824\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.10912, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:18.783, tt:375.652\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.10901, lr:1.00e-02, fs:0.68852 (r=0.636,p=0.750),  time:18.812, tt:395.061\n",
      "Ep:21, loss:0.00003, loss_test:0.10808, lr:1.00e-02, fs:0.69189 (r=0.646,p=0.744),  time:18.863, tt:414.996\n",
      "Ep:22, loss:0.00003, loss_test:0.10711, lr:1.00e-02, fs:0.69110 (r=0.667,p=0.717),  time:18.899, tt:434.674\n",
      "Ep:23, loss:0.00003, loss_test:0.10661, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:18.865, tt:452.758\n",
      "Ep:24, loss:0.00003, loss_test:0.10614, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:18.824, tt:470.593\n",
      "Ep:25, loss:0.00002, loss_test:0.10565, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:18.816, tt:489.212\n",
      "Ep:26, loss:0.00002, loss_test:0.10558, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:18.875, tt:509.631\n",
      "Ep:27, loss:0.00002, loss_test:0.10529, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:18.907, tt:529.402\n",
      "Ep:28, loss:0.00002, loss_test:0.10419, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:18.951, tt:549.594\n",
      "Ep:29, loss:0.00002, loss_test:0.10276, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:18.975, tt:569.253\n",
      "Ep:30, loss:0.00002, loss_test:0.10168, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:18.992, tt:588.760\n",
      "Ep:31, loss:0.00002, loss_test:0.10091, lr:9.90e-03, fs:0.69792 (r=0.677,p=0.720),  time:19.040, tt:609.291\n",
      "Ep:32, loss:0.00002, loss_test:0.10061, lr:9.80e-03, fs:0.69189 (r=0.646,p=0.744),  time:19.054, tt:628.795\n",
      "Ep:33, loss:0.00002, loss_test:0.10012, lr:9.70e-03, fs:0.68508 (r=0.626,p=0.756),  time:19.086, tt:648.914\n",
      "Ep:34, loss:0.00002, loss_test:0.09902, lr:9.61e-03, fs:0.70270 (r=0.657,p=0.756),  time:19.102, tt:668.567\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.09789, lr:9.61e-03, fs:0.70899 (r=0.677,p=0.744),  time:19.091, tt:687.279\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.09725, lr:9.61e-03, fs:0.72251 (r=0.697,p=0.750),  time:19.073, tt:705.707\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.09704, lr:9.61e-03, fs:0.70588 (r=0.667,p=0.750),  time:19.087, tt:725.321\n",
      "Ep:38, loss:0.00002, loss_test:0.09721, lr:9.61e-03, fs:0.68852 (r=0.636,p=0.750),  time:19.103, tt:745.020\n",
      "Ep:39, loss:0.00002, loss_test:0.09650, lr:9.61e-03, fs:0.71958 (r=0.687,p=0.756),  time:19.112, tt:764.470\n",
      "Ep:40, loss:0.00002, loss_test:0.09562, lr:9.61e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.091, tt:782.732\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.09528, lr:9.61e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.090, tt:801.760\n",
      "Ep:42, loss:0.00002, loss_test:0.09544, lr:9.61e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.072, tt:820.101\n",
      "Ep:43, loss:0.00002, loss_test:0.09545, lr:9.61e-03, fs:0.73404 (r=0.697,p=0.775),  time:19.090, tt:839.967\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.09474, lr:9.61e-03, fs:0.74074 (r=0.707,p=0.778),  time:19.096, tt:859.317\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:45, loss:0.00002, loss_test:0.09398, lr:9.61e-03, fs:0.73684 (r=0.707,p=0.769),  time:19.124, tt:879.713\n",
      "Ep:46, loss:0.00002, loss_test:0.09356, lr:9.61e-03, fs:0.73684 (r=0.707,p=0.769),  time:19.149, tt:900.023\n",
      "Ep:47, loss:0.00002, loss_test:0.09354, lr:9.61e-03, fs:0.73797 (r=0.697,p=0.784),  time:19.143, tt:918.862\n",
      "Ep:48, loss:0.00002, loss_test:0.09339, lr:9.61e-03, fs:0.72826 (r=0.677,p=0.788),  time:19.127, tt:937.242\n",
      "Ep:49, loss:0.00002, loss_test:0.09278, lr:9.61e-03, fs:0.74468 (r=0.707,p=0.787),  time:19.112, tt:955.622\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.09217, lr:9.61e-03, fs:0.74074 (r=0.707,p=0.778),  time:19.098, tt:973.984\n",
      "Ep:51, loss:0.00002, loss_test:0.09199, lr:9.61e-03, fs:0.74866 (r=0.707,p=0.795),  time:19.096, tt:992.971\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.09185, lr:9.61e-03, fs:0.74595 (r=0.697,p=0.802),  time:19.105, tt:1012.589\n",
      "Ep:53, loss:0.00001, loss_test:0.09129, lr:9.61e-03, fs:0.75269 (r=0.707,p=0.805),  time:19.120, tt:1032.476\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.09052, lr:9.61e-03, fs:0.75269 (r=0.707,p=0.805),  time:19.131, tt:1052.191\n",
      "Ep:55, loss:0.00001, loss_test:0.09003, lr:9.61e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.135, tt:1071.562\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.08984, lr:9.61e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.155, tt:1091.812\n",
      "Ep:57, loss:0.00001, loss_test:0.08968, lr:9.61e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.161, tt:1111.334\n",
      "Ep:58, loss:0.00001, loss_test:0.08923, lr:9.61e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.162, tt:1130.561\n",
      "Ep:59, loss:0.00001, loss_test:0.08873, lr:9.61e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.185, tt:1151.078\n",
      "Ep:60, loss:0.00001, loss_test:0.08846, lr:9.61e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.200, tt:1171.229\n",
      "Ep:61, loss:0.00001, loss_test:0.08839, lr:9.61e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.222, tt:1191.768\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.08819, lr:9.61e-03, fs:0.76503 (r=0.707,p=0.833),  time:19.247, tt:1212.539\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.08784, lr:9.61e-03, fs:0.76503 (r=0.707,p=0.833),  time:19.265, tt:1232.938\n",
      "Ep:64, loss:0.00001, loss_test:0.08770, lr:9.61e-03, fs:0.75978 (r=0.687,p=0.850),  time:19.281, tt:1253.248\n",
      "Ep:65, loss:0.00001, loss_test:0.08737, lr:9.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.282, tt:1272.611\n",
      "Ep:66, loss:0.00001, loss_test:0.08705, lr:9.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.293, tt:1292.614\n",
      "Ep:67, loss:0.00001, loss_test:0.08686, lr:9.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.307, tt:1312.846\n",
      "Ep:68, loss:0.00001, loss_test:0.08666, lr:9.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.327, tt:1333.530\n",
      "Ep:69, loss:0.00001, loss_test:0.08667, lr:9.61e-03, fs:0.73563 (r=0.646,p=0.853),  time:19.329, tt:1353.060\n",
      "Ep:70, loss:0.00001, loss_test:0.08666, lr:9.61e-03, fs:0.73563 (r=0.646,p=0.853),  time:19.347, tt:1373.616\n",
      "Ep:71, loss:0.00001, loss_test:0.08633, lr:9.61e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.362, tt:1394.095\n",
      "Ep:72, loss:0.00001, loss_test:0.08632, lr:9.61e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.354, tt:1412.828\n",
      "Ep:73, loss:0.00001, loss_test:0.08687, lr:9.61e-03, fs:0.73256 (r=0.636,p=0.863),  time:19.348, tt:1431.759\n",
      "Ep:74, loss:0.00001, loss_test:0.08687, lr:9.51e-03, fs:0.73256 (r=0.636,p=0.863),  time:19.372, tt:1452.862\n",
      "Ep:75, loss:0.00001, loss_test:0.08625, lr:9.41e-03, fs:0.73256 (r=0.636,p=0.863),  time:19.366, tt:1471.851\n",
      "Ep:76, loss:0.00001, loss_test:0.08609, lr:9.32e-03, fs:0.73256 (r=0.636,p=0.863),  time:19.356, tt:1490.413\n",
      "Ep:77, loss:0.00001, loss_test:0.08608, lr:9.23e-03, fs:0.72941 (r=0.626,p=0.873),  time:19.374, tt:1511.156\n",
      "Ep:78, loss:0.00001, loss_test:0.08557, lr:9.14e-03, fs:0.72941 (r=0.626,p=0.873),  time:19.370, tt:1530.246\n",
      "Ep:79, loss:0.00001, loss_test:0.08471, lr:9.04e-03, fs:0.73684 (r=0.636,p=0.875),  time:19.376, tt:1550.050\n",
      "Ep:80, loss:0.00001, loss_test:0.08584, lr:8.95e-03, fs:0.72941 (r=0.626,p=0.873),  time:19.385, tt:1570.166\n",
      "Ep:81, loss:0.00001, loss_test:0.08509, lr:8.86e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.391, tt:1590.085\n",
      "Ep:82, loss:0.00001, loss_test:0.08456, lr:8.78e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.386, tt:1609.076\n",
      "Ep:83, loss:0.00001, loss_test:0.08505, lr:8.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.393, tt:1629.035\n",
      "Ep:84, loss:0.00001, loss_test:0.08506, lr:8.60e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.397, tt:1648.717\n",
      "Ep:85, loss:0.00001, loss_test:0.08413, lr:8.51e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.398, tt:1668.231\n",
      "Ep:86, loss:0.00001, loss_test:0.08415, lr:8.43e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.413, tt:1688.914\n",
      "Ep:87, loss:0.00001, loss_test:0.08456, lr:8.35e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.422, tt:1709.162\n",
      "Ep:88, loss:0.00001, loss_test:0.08382, lr:8.26e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.430, tt:1729.274\n",
      "Ep:89, loss:0.00001, loss_test:0.08424, lr:8.18e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.450, tt:1750.491\n",
      "Ep:90, loss:0.00001, loss_test:0.08419, lr:8.10e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.463, tt:1771.107\n",
      "Ep:91, loss:0.00001, loss_test:0.08376, lr:8.02e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.477, tt:1791.878\n",
      "Ep:92, loss:0.00001, loss_test:0.08403, lr:7.94e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.493, tt:1812.841\n",
      "Ep:93, loss:0.00001, loss_test:0.08435, lr:7.86e-03, fs:0.75294 (r=0.646,p=0.901),  time:19.503, tt:1833.282\n",
      "Ep:94, loss:0.00001, loss_test:0.08350, lr:7.78e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.512, tt:1853.680\n",
      "Ep:95, loss:0.00001, loss_test:0.08309, lr:7.70e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.526, tt:1874.499\n",
      "Ep:96, loss:0.00001, loss_test:0.08368, lr:7.62e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.542, tt:1895.554\n",
      "Ep:97, loss:0.00001, loss_test:0.08344, lr:7.55e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.538, tt:1914.770\n",
      "Ep:98, loss:0.00001, loss_test:0.08272, lr:7.47e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.546, tt:1935.044\n",
      "Ep:99, loss:0.00001, loss_test:0.08291, lr:7.40e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.552, tt:1955.180\n",
      "Ep:100, loss:0.00001, loss_test:0.08356, lr:7.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.557, tt:1975.296\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.08311, lr:7.32e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.565, tt:1995.652\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.08251, lr:7.32e-03, fs:0.77844 (r=0.657,p=0.956),  time:19.582, tt:2016.965\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.08267, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.591, tt:2037.454\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.08305, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.601, tt:2058.133\n",
      "Ep:105, loss:0.00001, loss_test:0.08271, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.614, tt:2079.128\n",
      "Ep:106, loss:0.00001, loss_test:0.08238, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.618, tt:2099.167\n",
      "Ep:107, loss:0.00001, loss_test:0.08251, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.619, tt:2118.847\n",
      "Ep:108, loss:0.00001, loss_test:0.08233, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.629, tt:2139.575\n",
      "Ep:109, loss:0.00001, loss_test:0.08200, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.634, tt:2159.729\n",
      "Ep:110, loss:0.00001, loss_test:0.08224, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.649, tt:2180.985\n",
      "Ep:111, loss:0.00001, loss_test:0.08163, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.656, tt:2201.481\n",
      "Ep:112, loss:0.00001, loss_test:0.08191, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.669, tt:2222.564\n",
      "Ep:113, loss:0.00001, loss_test:0.08127, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.674, tt:2242.819\n",
      "Ep:114, loss:0.00001, loss_test:0.08224, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.683, tt:2263.586\n",
      "Ep:115, loss:0.00001, loss_test:0.08099, lr:7.25e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.698, tt:2285.010\n",
      "Ep:116, loss:0.00001, loss_test:0.08152, lr:7.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.687, tt:2303.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:117, loss:0.00001, loss_test:0.08184, lr:7.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.691, tt:2323.579\n",
      "Ep:118, loss:0.00000, loss_test:0.08068, lr:7.03e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.705, tt:2344.862\n",
      "Ep:119, loss:0.00000, loss_test:0.08142, lr:6.96e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.722, tt:2366.654\n",
      "Ep:120, loss:0.00000, loss_test:0.08136, lr:6.89e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.717, tt:2385.770\n",
      "Ep:121, loss:0.00000, loss_test:0.08045, lr:6.83e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.720, tt:2405.793\n",
      "Ep:122, loss:0.00000, loss_test:0.08167, lr:6.76e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.716, tt:2425.096\n",
      "Ep:123, loss:0.00000, loss_test:0.08123, lr:6.69e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.724, tt:2445.803\n",
      "Ep:124, loss:0.00000, loss_test:0.08013, lr:6.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.723, tt:2465.420\n",
      "Ep:125, loss:0.00000, loss_test:0.08101, lr:6.56e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.723, tt:2485.121\n",
      "Ep:126, loss:0.00000, loss_test:0.08071, lr:6.49e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.724, tt:2505.002\n",
      "Ep:127, loss:0.00000, loss_test:0.08031, lr:6.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.723, tt:2524.517\n",
      "Ep:128, loss:0.00000, loss_test:0.08009, lr:6.36e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.723, tt:2544.236\n",
      "Ep:129, loss:0.00000, loss_test:0.08049, lr:6.30e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.733, tt:2565.234\n",
      "Ep:130, loss:0.00000, loss_test:0.08016, lr:6.24e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.731, tt:2584.743\n",
      "Ep:131, loss:0.00000, loss_test:0.07977, lr:6.17e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.734, tt:2604.902\n",
      "Ep:132, loss:0.00000, loss_test:0.08034, lr:6.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.731, tt:2624.187\n",
      "Ep:133, loss:0.00000, loss_test:0.08005, lr:6.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.733, tt:2644.193\n",
      "Ep:134, loss:0.00000, loss_test:0.07965, lr:5.99e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.737, tt:2664.440\n",
      "Ep:135, loss:0.00000, loss_test:0.08009, lr:5.93e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.748, tt:2685.689\n",
      "Ep:136, loss:0.00000, loss_test:0.08033, lr:5.87e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.747, tt:2705.288\n",
      "Ep:137, loss:0.00000, loss_test:0.08009, lr:5.81e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.742, tt:2724.367\n",
      "Ep:138, loss:0.00000, loss_test:0.07982, lr:5.75e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.745, tt:2744.607\n",
      "Ep:139, loss:0.00000, loss_test:0.08024, lr:5.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.748, tt:2764.746\n",
      "Ep:140, loss:0.00000, loss_test:0.08028, lr:5.64e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.746, tt:2784.180\n",
      "Ep:141, loss:0.00000, loss_test:0.07995, lr:5.58e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.742, tt:2803.411\n",
      "Ep:142, loss:0.00000, loss_test:0.08018, lr:5.53e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.743, tt:2823.199\n",
      "Ep:143, loss:0.00000, loss_test:0.08030, lr:5.47e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.732, tt:2841.471\n",
      "Ep:144, loss:0.00000, loss_test:0.08056, lr:5.42e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.729, tt:2860.647\n",
      "Ep:145, loss:0.00000, loss_test:0.08013, lr:5.36e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.722, tt:2879.458\n",
      "Ep:146, loss:0.00000, loss_test:0.08071, lr:5.31e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.728, tt:2899.961\n",
      "Ep:147, loss:0.00000, loss_test:0.08015, lr:5.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.724, tt:2919.193\n",
      "Ep:148, loss:0.00000, loss_test:0.08005, lr:5.20e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.725, tt:2939.012\n",
      "Ep:149, loss:0.00000, loss_test:0.08101, lr:5.15e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.727, tt:2959.051\n",
      "Ep:150, loss:0.00000, loss_test:0.08055, lr:5.10e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.720, tt:2977.655\n",
      "Ep:151, loss:0.00000, loss_test:0.07969, lr:5.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.714, tt:2996.507\n",
      "Ep:152, loss:0.00000, loss_test:0.08113, lr:5.00e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.705, tt:3014.899\n",
      "Ep:153, loss:0.00000, loss_test:0.08105, lr:4.95e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.697, tt:3033.270\n",
      "Ep:154, loss:0.00000, loss_test:0.07998, lr:4.90e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.685, tt:3051.132\n",
      "Ep:155, loss:0.00000, loss_test:0.08053, lr:4.85e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.674, tt:3069.218\n",
      "Ep:156, loss:0.00000, loss_test:0.08077, lr:4.80e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.667, tt:3087.689\n",
      "Ep:157, loss:0.00000, loss_test:0.08025, lr:4.75e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.666, tt:3107.152\n",
      "Ep:158, loss:0.00000, loss_test:0.08062, lr:4.71e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.666, tt:3126.930\n",
      "Ep:159, loss:0.00000, loss_test:0.08080, lr:4.66e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.654, tt:3144.700\n",
      "Ep:160, loss:0.00000, loss_test:0.08046, lr:4.61e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.659, tt:3165.084\n",
      "Ep:161, loss:0.00000, loss_test:0.08063, lr:4.57e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.656, tt:3184.236\n",
      "Ep:162, loss:0.00000, loss_test:0.08091, lr:4.52e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.656, tt:3203.982\n",
      "Ep:163, loss:0.00000, loss_test:0.08071, lr:4.48e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.657, tt:3223.717\n",
      "Ep:164, loss:0.00000, loss_test:0.08071, lr:4.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.662, tt:3244.184\n",
      "Ep:165, loss:0.00000, loss_test:0.08070, lr:4.39e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.658, tt:3263.263\n",
      "Ep:166, loss:0.00000, loss_test:0.08079, lr:4.34e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.652, tt:3281.946\n",
      "Ep:167, loss:0.00000, loss_test:0.08117, lr:4.30e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.653, tt:3301.712\n",
      "Ep:168, loss:0.00000, loss_test:0.08096, lr:4.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.651, tt:3320.987\n",
      "Ep:169, loss:0.00000, loss_test:0.08098, lr:4.21e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.639, tt:3338.698\n",
      "Ep:170, loss:0.00000, loss_test:0.08130, lr:4.17e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.639, tt:3358.249\n",
      "Ep:171, loss:0.00000, loss_test:0.08124, lr:4.13e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.635, tt:3377.143\n",
      "Ep:172, loss:0.00000, loss_test:0.08108, lr:4.09e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.641, tt:3397.935\n",
      "Ep:173, loss:0.00000, loss_test:0.08180, lr:4.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.634, tt:3416.235\n",
      "Ep:174, loss:0.00000, loss_test:0.08157, lr:4.01e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.635, tt:3436.081\n",
      "Ep:175, loss:0.00000, loss_test:0.08119, lr:3.97e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.622, tt:3453.529\n",
      "Ep:176, loss:0.00000, loss_test:0.08170, lr:3.93e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.621, tt:3472.872\n",
      "Ep:177, loss:0.00000, loss_test:0.08173, lr:3.89e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.616, tt:3491.719\n",
      "Ep:178, loss:0.00000, loss_test:0.08126, lr:3.85e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.611, tt:3510.450\n",
      "Ep:179, loss:0.00000, loss_test:0.08173, lr:3.81e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.609, tt:3529.621\n",
      "Ep:180, loss:0.00000, loss_test:0.08200, lr:3.77e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.605, tt:3548.492\n",
      "Ep:181, loss:0.00000, loss_test:0.08158, lr:3.73e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.604, tt:3567.839\n",
      "Ep:182, loss:0.00000, loss_test:0.08177, lr:3.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.601, tt:3586.973\n",
      "Ep:183, loss:0.00000, loss_test:0.08211, lr:3.66e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.599, tt:3606.248\n",
      "Ep:184, loss:0.00000, loss_test:0.08205, lr:3.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.598, tt:3625.563\n",
      "Ep:185, loss:0.00000, loss_test:0.08168, lr:3.59e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.594, tt:3644.410\n",
      "Ep:186, loss:0.00000, loss_test:0.08237, lr:3.55e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.606, tt:3666.258\n",
      "Ep:187, loss:0.00000, loss_test:0.08253, lr:3.52e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.605, tt:3685.655\n",
      "Ep:188, loss:0.00000, loss_test:0.08221, lr:3.48e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.604, tt:3705.220\n",
      "Ep:189, loss:0.00000, loss_test:0.08224, lr:3.45e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.607, tt:3725.283\n",
      "Ep:190, loss:0.00000, loss_test:0.08275, lr:3.41e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.610, tt:3745.528\n",
      "Ep:191, loss:0.00000, loss_test:0.08270, lr:3.38e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.612, tt:3765.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:192, loss:0.00000, loss_test:0.08260, lr:3.34e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.608, tt:3784.301\n",
      "Ep:193, loss:0.00000, loss_test:0.08299, lr:3.31e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.607, tt:3803.808\n",
      "Ep:194, loss:0.00000, loss_test:0.08306, lr:3.28e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.609, tt:3823.695\n",
      "Ep:195, loss:0.00000, loss_test:0.08284, lr:3.24e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.610, tt:3843.513\n",
      "Ep:196, loss:0.00000, loss_test:0.08332, lr:3.21e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.615, tt:3864.220\n",
      "Ep:197, loss:0.00000, loss_test:0.08346, lr:3.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.619, tt:3884.542\n",
      "Ep:198, loss:0.00000, loss_test:0.08321, lr:3.15e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.624, tt:3905.144\n",
      "Ep:199, loss:0.00000, loss_test:0.08339, lr:3.12e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.621, tt:3924.262\n",
      "Ep:200, loss:0.00000, loss_test:0.08367, lr:3.09e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.626, tt:3944.912\n",
      "Ep:201, loss:0.00000, loss_test:0.08360, lr:3.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.626, tt:3964.511\n",
      "Ep:202, loss:0.00000, loss_test:0.08332, lr:3.02e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.634, tt:3985.676\n",
      "Ep:203, loss:0.00000, loss_test:0.08387, lr:2.99e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.632, tt:4004.894\n",
      "Ep:204, loss:0.00000, loss_test:0.08403, lr:2.96e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.633, tt:4024.669\n",
      "Ep:205, loss:0.00000, loss_test:0.08379, lr:2.93e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.631, tt:4044.044\n",
      "Ep:206, loss:0.00000, loss_test:0.08369, lr:2.90e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.624, tt:4062.100\n",
      "Ep:207, loss:0.00000, loss_test:0.08385, lr:2.88e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.618, tt:4080.556\n",
      "Ep:208, loss:0.00000, loss_test:0.08405, lr:2.85e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.624, tt:4101.403\n",
      "Ep:209, loss:0.00000, loss_test:0.08407, lr:2.82e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.625, tt:4121.170\n",
      "Ep:210, loss:0.00000, loss_test:0.08410, lr:2.79e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.630, tt:4142.004\n",
      "Ep:211, loss:0.00000, loss_test:0.08410, lr:2.76e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.631, tt:4161.819\n",
      "Ep:212, loss:0.00000, loss_test:0.08429, lr:2.73e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.634, tt:4182.050\n",
      "Ep:213, loss:0.00000, loss_test:0.08434, lr:2.71e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.637, tt:4202.221\n",
      "Ep:214, loss:0.00000, loss_test:0.08435, lr:2.68e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.635, tt:4221.487\n",
      "Ep:215, loss:0.00000, loss_test:0.08441, lr:2.65e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.634, tt:4240.847\n",
      "Ep:216, loss:0.00000, loss_test:0.08453, lr:2.63e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.638, tt:4261.409\n",
      "Ep:217, loss:0.00000, loss_test:0.08446, lr:2.60e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.644, tt:4282.345\n",
      "Ep:218, loss:0.00000, loss_test:0.08473, lr:2.57e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.661, tt:4305.779\n",
      "Ep:219, loss:0.00000, loss_test:0.08484, lr:2.55e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.663, tt:4325.839\n",
      "Ep:220, loss:0.00000, loss_test:0.08464, lr:2.52e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.672, tt:4347.475\n",
      "Ep:221, loss:0.00000, loss_test:0.08476, lr:2.50e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.676, tt:4368.006\n",
      "Ep:222, loss:0.00000, loss_test:0.08493, lr:2.47e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.678, tt:4388.132\n",
      "Ep:223, loss:0.00000, loss_test:0.08499, lr:2.45e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.684, tt:4409.195\n",
      "Ep:224, loss:0.00000, loss_test:0.08500, lr:2.42e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.693, tt:4430.898\n",
      "Ep:225, loss:0.00000, loss_test:0.08504, lr:2.40e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.696, tt:4451.214\n",
      "Ep:226, loss:0.00000, loss_test:0.08525, lr:2.38e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.696, tt:4470.994\n",
      "Ep:227, loss:0.00000, loss_test:0.08537, lr:2.35e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.688, tt:4488.954\n",
      "Ep:228, loss:0.00000, loss_test:0.08526, lr:2.33e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.692, tt:4509.581\n",
      "Ep:229, loss:0.00000, loss_test:0.08563, lr:2.31e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.701, tt:4531.116\n",
      "Ep:230, loss:0.00000, loss_test:0.08562, lr:2.28e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.703, tt:4551.476\n",
      "Ep:231, loss:0.00000, loss_test:0.08545, lr:2.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.702, tt:4570.939\n",
      "Ep:232, loss:0.00000, loss_test:0.08553, lr:2.24e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.703, tt:4590.847\n",
      "Ep:233, loss:0.00000, loss_test:0.08562, lr:2.21e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.710, tt:4612.049\n",
      "Ep:234, loss:0.00000, loss_test:0.08562, lr:2.19e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.708, tt:4631.308\n",
      "Ep:235, loss:0.00000, loss_test:0.08579, lr:2.17e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.706, tt:4650.722\n",
      "Ep:236, loss:0.00000, loss_test:0.08587, lr:2.15e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.700, tt:4668.814\n",
      "Ep:237, loss:0.00000, loss_test:0.08583, lr:2.13e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.700, tt:4688.697\n",
      "Ep:238, loss:0.00000, loss_test:0.08597, lr:2.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.695, tt:4707.219\n",
      "Ep:239, loss:0.00000, loss_test:0.08595, lr:2.08e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.693, tt:4726.350\n",
      "Ep:240, loss:0.00000, loss_test:0.08603, lr:2.06e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.694, tt:4746.257\n",
      "Ep:241, loss:0.00000, loss_test:0.08616, lr:2.04e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.696, tt:4766.460\n",
      "Ep:242, loss:0.00000, loss_test:0.08603, lr:2.02e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.696, tt:4786.147\n",
      "Ep:243, loss:0.00000, loss_test:0.08621, lr:2.00e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.693, tt:4805.166\n",
      "Ep:244, loss:0.00000, loss_test:0.08621, lr:1.98e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.692, tt:4824.461\n",
      "Ep:245, loss:0.00000, loss_test:0.08628, lr:1.96e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.690, tt:4843.828\n",
      "Ep:246, loss:0.00000, loss_test:0.08628, lr:1.94e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.692, tt:4863.967\n",
      "Ep:247, loss:0.00000, loss_test:0.08662, lr:1.92e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.691, tt:4883.479\n",
      "Ep:248, loss:0.00000, loss_test:0.08663, lr:1.90e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.689, tt:4902.632\n",
      "Ep:249, loss:0.00000, loss_test:0.08646, lr:1.89e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.688, tt:4922.003\n",
      "Ep:250, loss:0.00000, loss_test:0.08678, lr:1.87e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.698, tt:4944.240\n",
      "Ep:251, loss:0.00000, loss_test:0.08687, lr:1.85e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.693, tt:4962.575\n",
      "Ep:252, loss:0.00000, loss_test:0.08674, lr:1.83e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.690, tt:4981.610\n",
      "Ep:253, loss:0.00000, loss_test:0.08673, lr:1.81e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.686, tt:5000.189\n",
      "Ep:254, loss:0.00000, loss_test:0.08703, lr:1.79e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.690, tt:5021.062\n",
      "Ep:255, loss:0.00000, loss_test:0.08714, lr:1.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.689, tt:5040.281\n",
      "Ep:256, loss:0.00000, loss_test:0.08700, lr:1.76e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.686, tt:5059.293\n",
      "Ep:257, loss:0.00000, loss_test:0.08690, lr:1.74e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.687, tt:5079.263\n",
      "Ep:258, loss:0.00000, loss_test:0.08733, lr:1.72e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.690, tt:5099.795\n",
      "Ep:259, loss:0.00000, loss_test:0.08758, lr:1.71e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.694, tt:5120.399\n",
      "Ep:260, loss:0.00000, loss_test:0.08752, lr:1.69e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.700, tt:5141.729\n",
      "Ep:261, loss:0.00000, loss_test:0.08730, lr:1.67e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.702, tt:5161.949\n",
      "Ep:262, loss:0.00000, loss_test:0.08743, lr:1.65e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.705, tt:5182.408\n",
      "Ep:263, loss:0.00000, loss_test:0.08771, lr:1.64e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.701, tt:5201.139\n",
      "Ep:264, loss:0.00000, loss_test:0.08777, lr:1.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.704, tt:5221.580\n",
      "Ep:265, loss:0.00000, loss_test:0.08767, lr:1.61e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.704, tt:5241.350\n",
      "Ep:266, loss:0.00000, loss_test:0.08764, lr:1.59e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.702, tt:5260.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:267, loss:0.00000, loss_test:0.08801, lr:1.57e-03, fs:0.78788 (r=0.657,p=0.985),  time:19.709, tt:5281.898\n",
      "Ep:268, loss:0.00000, loss_test:0.08815, lr:1.56e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.709, tt:5301.777\n",
      "Ep:269, loss:0.00000, loss_test:0.08806, lr:1.54e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.710, tt:5321.580\n",
      "Ep:270, loss:0.00000, loss_test:0.08795, lr:1.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.705, tt:5340.154\n",
      "Ep:271, loss:0.00000, loss_test:0.08831, lr:1.51e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.708, tt:5360.618\n",
      "Ep:272, loss:0.00000, loss_test:0.08850, lr:1.50e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.709, tt:5380.629\n",
      "Ep:273, loss:0.00000, loss_test:0.08842, lr:1.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.707, tt:5399.723\n",
      "Ep:274, loss:0.00000, loss_test:0.08829, lr:1.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.712, tt:5420.866\n",
      "Ep:275, loss:0.00000, loss_test:0.08828, lr:1.45e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.714, tt:5440.996\n",
      "Ep:276, loss:0.00000, loss_test:0.08863, lr:1.44e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.714, tt:5460.829\n",
      "Ep:277, loss:0.00000, loss_test:0.08885, lr:1.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.714, tt:5480.494\n",
      "Ep:278, loss:0.00000, loss_test:0.08881, lr:1.41e-03, fs:0.78049 (r=0.646,p=0.985),  time:19.716, tt:5500.750\n",
      "Ep:279, loss:0.00000, loss_test:0.08865, lr:1.39e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.717, tt:5520.891\n",
      "Ep:280, loss:0.00000, loss_test:0.08858, lr:1.38e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.719, tt:5541.130\n",
      "Ep:281, loss:0.00000, loss_test:0.08890, lr:1.37e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.719, tt:5560.864\n",
      "Ep:282, loss:0.00000, loss_test:0.08912, lr:1.35e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.731, tt:5583.910\n",
      "Ep:283, loss:0.00000, loss_test:0.08909, lr:1.34e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.727, tt:5602.494\n",
      "Ep:284, loss:0.00000, loss_test:0.08889, lr:1.33e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.727, tt:5622.330\n",
      "Ep:285, loss:0.00000, loss_test:0.08891, lr:1.31e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.726, tt:5641.589\n",
      "Ep:286, loss:0.00000, loss_test:0.08914, lr:1.30e-03, fs:0.77301 (r=0.636,p=0.984),  time:19.729, tt:5662.320\n",
      "Ep:287, loss:0.00000, loss_test:0.08926, lr:1.29e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.730, tt:5682.382\n",
      "Ep:288, loss:0.00000, loss_test:0.08922, lr:1.27e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.729, tt:5701.752\n",
      "Ep:289, loss:0.00000, loss_test:0.08909, lr:1.26e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.726, tt:5720.489\n",
      "Ep:290, loss:0.00000, loss_test:0.08917, lr:1.25e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.724, tt:5739.824\n",
      "Ep:291, loss:0.00000, loss_test:0.08939, lr:1.24e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.728, tt:5760.459\n",
      "Ep:292, loss:0.00000, loss_test:0.08943, lr:1.22e-03, fs:0.75776 (r=0.616,p=0.984),  time:19.735, tt:5782.421\n",
      "Ep:293, loss:0.00000, loss_test:0.08929, lr:1.21e-03, fs:0.75776 (r=0.616,p=0.984),  time:19.737, tt:5802.801\n",
      "Ep:294, loss:0.00000, loss_test:0.08931, lr:1.20e-03, fs:0.75776 (r=0.616,p=0.984),  time:19.736, tt:5822.240\n",
      "Ep:295, loss:0.00000, loss_test:0.08951, lr:1.19e-03, fs:0.75000 (r=0.606,p=0.984),  time:19.737, tt:5842.247\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14348, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:9.118, tt:9.118\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14295, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:9.259, tt:18.518\n",
      "Ep:2, loss:0.00004, loss_test:0.14203, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:11.168, tt:33.505\n",
      "Ep:3, loss:0.00004, loss_test:0.14058, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:12.835, tt:51.340\n",
      "Ep:4, loss:0.00004, loss_test:0.13859, lr:1.00e-02, fs:0.64516 (r=0.909,p=0.500),  time:13.590, tt:67.952\n",
      "Ep:5, loss:0.00004, loss_test:0.13622, lr:1.00e-02, fs:0.62687 (r=0.848,p=0.497),  time:14.294, tt:85.765\n",
      "Ep:6, loss:0.00004, loss_test:0.13458, lr:1.00e-02, fs:0.62698 (r=0.798,p=0.516),  time:14.455, tt:101.184\n",
      "Ep:7, loss:0.00004, loss_test:0.13354, lr:1.00e-02, fs:0.63415 (r=0.788,p=0.531),  time:14.854, tt:118.832\n",
      "Ep:8, loss:0.00003, loss_test:0.13281, lr:1.00e-02, fs:0.64706 (r=0.778,p=0.554),  time:15.078, tt:135.705\n",
      "Ep:9, loss:0.00003, loss_test:0.13284, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:15.354, tt:153.540\n",
      "Ep:10, loss:0.00003, loss_test:0.13300, lr:1.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:15.433, tt:169.761\n",
      "Ep:11, loss:0.00003, loss_test:0.13232, lr:1.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:15.625, tt:187.500\n",
      "Ep:12, loss:0.00003, loss_test:0.13075, lr:9.90e-03, fs:0.64912 (r=0.747,p=0.574),  time:15.735, tt:204.555\n",
      "Ep:13, loss:0.00003, loss_test:0.12865, lr:9.80e-03, fs:0.64912 (r=0.747,p=0.574),  time:15.776, tt:220.866\n",
      "Ep:14, loss:0.00003, loss_test:0.12661, lr:9.70e-03, fs:0.64629 (r=0.747,p=0.569),  time:15.906, tt:238.597\n",
      "Ep:15, loss:0.00003, loss_test:0.12480, lr:9.61e-03, fs:0.65801 (r=0.768,p=0.576),  time:15.995, tt:255.923\n",
      "Ep:16, loss:0.00003, loss_test:0.12315, lr:9.51e-03, fs:0.66087 (r=0.768,p=0.580),  time:16.095, tt:273.618\n",
      "Ep:17, loss:0.00003, loss_test:0.12163, lr:9.41e-03, fs:0.66667 (r=0.768,p=0.589),  time:16.172, tt:291.090\n",
      "Ep:18, loss:0.00003, loss_test:0.12061, lr:9.32e-03, fs:0.67273 (r=0.747,p=0.612),  time:16.150, tt:306.857\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11933, lr:9.32e-03, fs:0.69159 (r=0.747,p=0.643),  time:16.219, tt:324.381\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.11776, lr:9.32e-03, fs:0.69856 (r=0.737,p=0.664),  time:16.408, tt:344.573\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.11606, lr:9.32e-03, fs:0.70531 (r=0.737,p=0.676),  time:16.480, tt:362.552\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.11474, lr:9.32e-03, fs:0.70531 (r=0.737,p=0.676),  time:16.564, tt:380.977\n",
      "Ep:23, loss:0.00003, loss_test:0.11362, lr:9.32e-03, fs:0.70531 (r=0.737,p=0.676),  time:16.609, tt:398.607\n",
      "Ep:24, loss:0.00003, loss_test:0.11270, lr:9.32e-03, fs:0.73077 (r=0.768,p=0.697),  time:16.657, tt:416.430\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.11198, lr:9.32e-03, fs:0.73077 (r=0.768,p=0.697),  time:16.722, tt:434.781\n",
      "Ep:26, loss:0.00003, loss_test:0.11131, lr:9.32e-03, fs:0.73077 (r=0.768,p=0.697),  time:16.779, tt:453.036\n",
      "Ep:27, loss:0.00003, loss_test:0.11041, lr:9.32e-03, fs:0.72115 (r=0.758,p=0.688),  time:16.851, tt:471.815\n",
      "Ep:28, loss:0.00003, loss_test:0.10930, lr:9.32e-03, fs:0.72038 (r=0.768,p=0.679),  time:16.916, tt:490.570\n",
      "Ep:29, loss:0.00003, loss_test:0.10860, lr:9.32e-03, fs:0.72038 (r=0.768,p=0.679),  time:17.003, tt:510.094\n",
      "Ep:30, loss:0.00003, loss_test:0.10830, lr:9.32e-03, fs:0.71429 (r=0.758,p=0.676),  time:17.085, tt:529.641\n",
      "Ep:31, loss:0.00003, loss_test:0.10838, lr:9.32e-03, fs:0.70874 (r=0.737,p=0.682),  time:17.168, tt:549.368\n",
      "Ep:32, loss:0.00003, loss_test:0.10875, lr:9.32e-03, fs:0.70244 (r=0.727,p=0.679),  time:17.216, tt:568.115\n",
      "Ep:33, loss:0.00003, loss_test:0.10889, lr:9.32e-03, fs:0.69951 (r=0.717,p=0.683),  time:17.278, tt:587.443\n",
      "Ep:34, loss:0.00003, loss_test:0.10879, lr:9.32e-03, fs:0.69951 (r=0.717,p=0.683),  time:17.345, tt:607.075\n",
      "Ep:35, loss:0.00002, loss_test:0.10860, lr:9.32e-03, fs:0.69951 (r=0.717,p=0.683),  time:17.404, tt:626.558\n",
      "Ep:36, loss:0.00002, loss_test:0.10855, lr:9.23e-03, fs:0.69951 (r=0.717,p=0.683),  time:17.441, tt:645.330\n",
      "Ep:37, loss:0.00002, loss_test:0.10886, lr:9.14e-03, fs:0.69000 (r=0.697,p=0.683),  time:17.490, tt:664.627\n",
      "Ep:38, loss:0.00002, loss_test:0.10936, lr:9.04e-03, fs:0.69000 (r=0.697,p=0.683),  time:17.554, tt:684.618\n",
      "Ep:39, loss:0.00002, loss_test:0.10965, lr:8.95e-03, fs:0.70051 (r=0.697,p=0.704),  time:17.601, tt:704.029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00002, loss_test:0.10943, lr:8.86e-03, fs:0.70051 (r=0.697,p=0.704),  time:17.634, tt:723.008\n",
      "Ep:41, loss:0.00002, loss_test:0.10900, lr:8.78e-03, fs:0.69697 (r=0.697,p=0.697),  time:17.649, tt:741.276\n",
      "Ep:42, loss:0.00002, loss_test:0.10860, lr:8.69e-03, fs:0.69000 (r=0.697,p=0.683),  time:17.684, tt:760.416\n",
      "Ep:43, loss:0.00002, loss_test:0.10836, lr:8.60e-03, fs:0.69000 (r=0.697,p=0.683),  time:17.699, tt:778.760\n",
      "Ep:44, loss:0.00002, loss_test:0.10818, lr:8.51e-03, fs:0.68687 (r=0.687,p=0.687),  time:17.740, tt:798.279\n",
      "Ep:45, loss:0.00002, loss_test:0.10773, lr:8.43e-03, fs:0.68367 (r=0.677,p=0.691),  time:17.799, tt:818.775\n",
      "Ep:46, loss:0.00002, loss_test:0.10723, lr:8.35e-03, fs:0.68020 (r=0.677,p=0.684),  time:17.835, tt:838.266\n",
      "Ep:47, loss:0.00002, loss_test:0.10687, lr:8.26e-03, fs:0.68687 (r=0.687,p=0.687),  time:17.862, tt:857.362\n",
      "Ep:48, loss:0.00002, loss_test:0.10665, lr:8.18e-03, fs:0.69388 (r=0.687,p=0.701),  time:17.897, tt:876.929\n",
      "Ep:49, loss:0.00002, loss_test:0.10649, lr:8.10e-03, fs:0.69388 (r=0.687,p=0.701),  time:17.942, tt:897.101\n",
      "Ep:50, loss:0.00002, loss_test:0.10628, lr:8.02e-03, fs:0.69388 (r=0.687,p=0.701),  time:17.966, tt:916.256\n",
      "Ep:51, loss:0.00002, loss_test:0.10609, lr:7.94e-03, fs:0.69388 (r=0.687,p=0.701),  time:17.956, tt:933.696\n",
      "Ep:52, loss:0.00002, loss_test:0.10602, lr:7.86e-03, fs:0.69744 (r=0.687,p=0.708),  time:17.970, tt:952.407\n",
      "Ep:53, loss:0.00002, loss_test:0.10607, lr:7.78e-03, fs:0.69744 (r=0.687,p=0.708),  time:17.986, tt:971.220\n",
      "Ep:54, loss:0.00002, loss_test:0.10604, lr:7.70e-03, fs:0.69744 (r=0.687,p=0.708),  time:18.018, tt:990.995\n",
      "Ep:55, loss:0.00002, loss_test:0.10579, lr:7.62e-03, fs:0.69744 (r=0.687,p=0.708),  time:18.046, tt:1010.602\n",
      "Ep:56, loss:0.00002, loss_test:0.10553, lr:7.55e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.076, tt:1030.338\n",
      "Ep:57, loss:0.00002, loss_test:0.10532, lr:7.47e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.097, tt:1049.645\n",
      "Ep:58, loss:0.00002, loss_test:0.10517, lr:7.40e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.121, tt:1069.156\n",
      "Ep:59, loss:0.00002, loss_test:0.10495, lr:7.32e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.131, tt:1087.859\n",
      "Ep:60, loss:0.00002, loss_test:0.10481, lr:7.25e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.133, tt:1106.130\n",
      "Ep:61, loss:0.00002, loss_test:0.10484, lr:7.18e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.163, tt:1126.098\n",
      "Ep:62, loss:0.00002, loss_test:0.10482, lr:7.11e-03, fs:0.69430 (r=0.677,p=0.713),  time:18.186, tt:1145.720\n",
      "Ep:63, loss:0.00002, loss_test:0.10464, lr:7.03e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.207, tt:1165.275\n",
      "Ep:64, loss:0.00002, loss_test:0.10452, lr:6.96e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.222, tt:1184.403\n",
      "Ep:65, loss:0.00002, loss_test:0.10453, lr:6.89e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.239, tt:1203.807\n",
      "Ep:66, loss:0.00002, loss_test:0.10459, lr:6.83e-03, fs:0.69792 (r=0.677,p=0.720),  time:18.256, tt:1223.147\n",
      "Ep:67, loss:0.00002, loss_test:0.10470, lr:6.76e-03, fs:0.70157 (r=0.677,p=0.728),  time:18.271, tt:1242.414\n",
      "Ep:68, loss:0.00002, loss_test:0.10465, lr:6.69e-03, fs:0.70157 (r=0.677,p=0.728),  time:18.294, tt:1262.255\n",
      "Ep:69, loss:0.00002, loss_test:0.10445, lr:6.62e-03, fs:0.70157 (r=0.677,p=0.728),  time:18.307, tt:1281.511\n",
      "Ep:70, loss:0.00002, loss_test:0.10424, lr:6.56e-03, fs:0.70833 (r=0.687,p=0.731),  time:18.323, tt:1300.918\n",
      "Ep:71, loss:0.00002, loss_test:0.10427, lr:6.49e-03, fs:0.71204 (r=0.687,p=0.739),  time:18.353, tt:1321.449\n",
      "Ep:72, loss:0.00002, loss_test:0.10442, lr:6.43e-03, fs:0.71204 (r=0.687,p=0.739),  time:18.387, tt:1342.253\n",
      "Ep:73, loss:0.00002, loss_test:0.10444, lr:6.36e-03, fs:0.71204 (r=0.687,p=0.739),  time:18.394, tt:1361.152\n",
      "Ep:74, loss:0.00002, loss_test:0.10429, lr:6.30e-03, fs:0.71579 (r=0.687,p=0.747),  time:18.412, tt:1380.879\n",
      "Ep:75, loss:0.00002, loss_test:0.10418, lr:6.24e-03, fs:0.71579 (r=0.687,p=0.747),  time:18.426, tt:1400.339\n",
      "Ep:76, loss:0.00002, loss_test:0.10426, lr:6.17e-03, fs:0.71579 (r=0.687,p=0.747),  time:18.427, tt:1418.895\n",
      "Ep:77, loss:0.00002, loss_test:0.10423, lr:6.11e-03, fs:0.72632 (r=0.697,p=0.758),  time:18.434, tt:1437.858\n",
      "Ep:78, loss:0.00002, loss_test:0.10415, lr:6.05e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.449, tt:1457.455\n",
      "Ep:79, loss:0.00002, loss_test:0.10401, lr:5.99e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.468, tt:1477.402\n",
      "Ep:80, loss:0.00002, loss_test:0.10391, lr:5.93e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.484, tt:1497.192\n",
      "Ep:81, loss:0.00002, loss_test:0.10384, lr:5.87e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.484, tt:1515.663\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.10383, lr:5.87e-03, fs:0.73298 (r=0.707,p=0.761),  time:18.499, tt:1535.383\n",
      "Ep:83, loss:0.00001, loss_test:0.10382, lr:5.87e-03, fs:0.73298 (r=0.707,p=0.761),  time:18.504, tt:1554.324\n",
      "Ep:84, loss:0.00001, loss_test:0.10376, lr:5.87e-03, fs:0.73298 (r=0.707,p=0.761),  time:18.503, tt:1572.716\n",
      "Ep:85, loss:0.00001, loss_test:0.10369, lr:5.87e-03, fs:0.73298 (r=0.707,p=0.761),  time:18.515, tt:1592.261\n",
      "Ep:86, loss:0.00001, loss_test:0.10359, lr:5.87e-03, fs:0.72917 (r=0.707,p=0.753),  time:18.521, tt:1611.361\n",
      "Ep:87, loss:0.00001, loss_test:0.10357, lr:5.87e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.533, tt:1630.935\n",
      "Ep:88, loss:0.00001, loss_test:0.10366, lr:5.87e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.541, tt:1650.126\n",
      "Ep:89, loss:0.00001, loss_test:0.10372, lr:5.87e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.547, tt:1669.201\n",
      "Ep:90, loss:0.00001, loss_test:0.10360, lr:5.87e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.563, tt:1689.260\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.10342, lr:5.87e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.568, tt:1708.274\n",
      "Ep:92, loss:0.00001, loss_test:0.10335, lr:5.87e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.582, tt:1728.124\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.10325, lr:5.87e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.594, tt:1747.800\n",
      "Ep:94, loss:0.00001, loss_test:0.10312, lr:5.87e-03, fs:0.75132 (r=0.717,p=0.789),  time:18.597, tt:1766.719\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.10290, lr:5.87e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.604, tt:1785.937\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.10288, lr:5.87e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.612, tt:1805.321\n",
      "Ep:97, loss:0.00001, loss_test:0.10276, lr:5.87e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.615, tt:1824.317\n",
      "Ep:98, loss:0.00001, loss_test:0.10264, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.621, tt:1843.526\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.10269, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.634, tt:1863.401\n",
      "Ep:100, loss:0.00001, loss_test:0.10259, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.630, tt:1881.595\n",
      "Ep:101, loss:0.00001, loss_test:0.10251, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.628, tt:1900.094\n",
      "Ep:102, loss:0.00001, loss_test:0.10254, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.633, tt:1919.238\n",
      "Ep:103, loss:0.00001, loss_test:0.10257, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.650, tt:1939.644\n",
      "Ep:104, loss:0.00001, loss_test:0.10246, lr:5.87e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.663, tt:1959.604\n",
      "Ep:105, loss:0.00001, loss_test:0.10246, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.669, tt:1978.955\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.10265, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.674, tt:1998.134\n",
      "Ep:107, loss:0.00001, loss_test:0.10274, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.689, tt:2018.404\n",
      "Ep:108, loss:0.00001, loss_test:0.10277, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.703, tt:2038.591\n",
      "Ep:109, loss:0.00001, loss_test:0.10279, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.709, tt:2057.936\n",
      "Ep:110, loss:0.00001, loss_test:0.10273, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.717, tt:2077.579\n",
      "Ep:111, loss:0.00001, loss_test:0.10255, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.728, tt:2097.528\n",
      "Ep:112, loss:0.00001, loss_test:0.10244, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.732, tt:2116.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00001, loss_test:0.10242, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.741, tt:2136.445\n",
      "Ep:114, loss:0.00001, loss_test:0.10239, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.741, tt:2155.229\n",
      "Ep:115, loss:0.00001, loss_test:0.10233, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.738, tt:2173.604\n",
      "Ep:116, loss:0.00001, loss_test:0.10226, lr:5.87e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.744, tt:2192.996\n",
      "Ep:117, loss:0.00001, loss_test:0.10217, lr:5.81e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.743, tt:2211.632\n",
      "Ep:118, loss:0.00001, loss_test:0.10223, lr:5.75e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.749, tt:2231.077\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.10220, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.737, tt:2248.496\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.10221, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.746, tt:2268.245\n",
      "Ep:121, loss:0.00001, loss_test:0.10220, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.744, tt:2286.793\n",
      "Ep:122, loss:0.00001, loss_test:0.10213, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.750, tt:2306.192\n",
      "Ep:123, loss:0.00001, loss_test:0.10211, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.764, tt:2326.675\n",
      "Ep:124, loss:0.00001, loss_test:0.10221, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.762, tt:2345.239\n",
      "Ep:125, loss:0.00001, loss_test:0.10205, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.772, tt:2365.247\n",
      "Ep:126, loss:0.00001, loss_test:0.10200, lr:5.75e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.780, tt:2385.088\n",
      "Ep:127, loss:0.00001, loss_test:0.10197, lr:5.75e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.803, tt:2406.796\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.10185, lr:5.75e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.802, tt:2425.502\n",
      "Ep:129, loss:0.00001, loss_test:0.10188, lr:5.75e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.803, tt:2444.449\n",
      "Ep:130, loss:0.00001, loss_test:0.10175, lr:5.75e-03, fs:0.77174 (r=0.717,p=0.835),  time:18.804, tt:2463.370\n",
      "Ep:131, loss:0.00001, loss_test:0.10168, lr:5.75e-03, fs:0.76503 (r=0.707,p=0.833),  time:18.805, tt:2482.293\n",
      "Ep:132, loss:0.00001, loss_test:0.10176, lr:5.75e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.812, tt:2501.971\n",
      "Ep:133, loss:0.00001, loss_test:0.10172, lr:5.75e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.818, tt:2521.665\n",
      "Ep:134, loss:0.00001, loss_test:0.10165, lr:5.75e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.825, tt:2541.424\n",
      "Ep:135, loss:0.00001, loss_test:0.10163, lr:5.75e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.823, tt:2559.969\n",
      "Ep:136, loss:0.00001, loss_test:0.10158, lr:5.75e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.829, tt:2579.542\n",
      "Ep:137, loss:0.00001, loss_test:0.10166, lr:5.75e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.831, tt:2598.667\n",
      "Ep:138, loss:0.00001, loss_test:0.10169, lr:5.75e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.821, tt:2616.082\n",
      "Ep:139, loss:0.00001, loss_test:0.10155, lr:5.70e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.830, tt:2636.235\n",
      "Ep:140, loss:0.00001, loss_test:0.10158, lr:5.64e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.834, tt:2655.643\n",
      "Ep:141, loss:0.00001, loss_test:0.10171, lr:5.58e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.835, tt:2674.513\n",
      "Ep:142, loss:0.00001, loss_test:0.10150, lr:5.53e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.833, tt:2693.170\n",
      "Ep:143, loss:0.00001, loss_test:0.10154, lr:5.47e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.829, tt:2711.381\n",
      "Ep:144, loss:0.00001, loss_test:0.10166, lr:5.42e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.820, tt:2728.912\n",
      "Ep:145, loss:0.00001, loss_test:0.10152, lr:5.36e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.817, tt:2747.276\n",
      "Ep:146, loss:0.00001, loss_test:0.10156, lr:5.31e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.808, tt:2764.783\n",
      "Ep:147, loss:0.00001, loss_test:0.10143, lr:5.26e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.803, tt:2782.875\n",
      "Ep:148, loss:0.00001, loss_test:0.10148, lr:5.20e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.799, tt:2801.083\n",
      "Ep:149, loss:0.00001, loss_test:0.10164, lr:5.15e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.797, tt:2819.586\n",
      "Ep:150, loss:0.00001, loss_test:0.10164, lr:5.10e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.777, tt:2835.339\n",
      "Ep:151, loss:0.00001, loss_test:0.10164, lr:5.05e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.768, tt:2852.731\n",
      "Ep:152, loss:0.00001, loss_test:0.10168, lr:5.00e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.752, tt:2869.113\n",
      "Ep:153, loss:0.00001, loss_test:0.10145, lr:4.95e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.741, tt:2886.184\n",
      "Ep:154, loss:0.00001, loss_test:0.10150, lr:4.90e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.730, tt:2903.147\n",
      "Ep:155, loss:0.00001, loss_test:0.10156, lr:4.85e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.725, tt:2921.103\n",
      "Ep:156, loss:0.00001, loss_test:0.10153, lr:4.80e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.712, tt:2937.774\n",
      "Ep:157, loss:0.00001, loss_test:0.10157, lr:4.75e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.705, tt:2955.369\n",
      "Ep:158, loss:0.00001, loss_test:0.10155, lr:4.71e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.696, tt:2972.650\n",
      "Ep:159, loss:0.00001, loss_test:0.10149, lr:4.66e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.682, tt:2989.066\n",
      "Ep:160, loss:0.00001, loss_test:0.10150, lr:4.61e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.676, tt:3006.866\n",
      "Ep:161, loss:0.00001, loss_test:0.10145, lr:4.57e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.672, tt:3024.852\n",
      "Ep:162, loss:0.00001, loss_test:0.10146, lr:4.52e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.661, tt:3041.715\n",
      "Ep:163, loss:0.00001, loss_test:0.10139, lr:4.48e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.653, tt:3059.083\n",
      "Ep:164, loss:0.00001, loss_test:0.10119, lr:4.43e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.649, tt:3077.055\n",
      "Ep:165, loss:0.00001, loss_test:0.10126, lr:4.39e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.646, tt:3095.279\n",
      "Ep:166, loss:0.00001, loss_test:0.10123, lr:4.34e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.633, tt:3111.789\n",
      "Ep:167, loss:0.00001, loss_test:0.10105, lr:4.30e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.626, tt:3129.160\n",
      "Ep:168, loss:0.00001, loss_test:0.10098, lr:4.26e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.617, tt:3146.353\n",
      "Ep:169, loss:0.00001, loss_test:0.10086, lr:4.21e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.608, tt:3163.309\n",
      "Ep:170, loss:0.00001, loss_test:0.10077, lr:4.17e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.602, tt:3180.932\n",
      "Ep:171, loss:0.00001, loss_test:0.10059, lr:4.13e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.588, tt:3197.168\n",
      "Ep:172, loss:0.00001, loss_test:0.10053, lr:4.09e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.579, tt:3214.175\n",
      "Ep:173, loss:0.00001, loss_test:0.10056, lr:4.05e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.570, tt:3231.163\n",
      "Ep:174, loss:0.00001, loss_test:0.10045, lr:4.01e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.566, tt:3248.967\n",
      "Ep:175, loss:0.00001, loss_test:0.10040, lr:3.97e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.560, tt:3266.543\n",
      "Ep:176, loss:0.00001, loss_test:0.10032, lr:3.93e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.555, tt:3284.227\n",
      "Ep:177, loss:0.00001, loss_test:0.10042, lr:3.89e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.553, tt:3302.390\n",
      "Ep:178, loss:0.00001, loss_test:0.10038, lr:3.85e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.541, tt:3318.881\n",
      "Ep:179, loss:0.00001, loss_test:0.10023, lr:3.81e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.532, tt:3335.777\n",
      "Ep:180, loss:0.00001, loss_test:0.10018, lr:3.77e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.523, tt:3352.724\n",
      "Ep:181, loss:0.00001, loss_test:0.10016, lr:3.73e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.512, tt:3369.180\n",
      "Ep:182, loss:0.00001, loss_test:0.10010, lr:3.70e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.506, tt:3386.540\n",
      "Ep:183, loss:0.00001, loss_test:0.10008, lr:3.66e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.498, tt:3403.670\n",
      "Ep:184, loss:0.00001, loss_test:0.09996, lr:3.62e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.490, tt:3420.610\n",
      "Ep:185, loss:0.00001, loss_test:0.09987, lr:3.59e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.474, tt:3436.199\n",
      "Ep:186, loss:0.00001, loss_test:0.09989, lr:3.55e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.458, tt:3451.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:187, loss:0.00001, loss_test:0.09995, lr:3.52e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.444, tt:3467.522\n",
      "Ep:188, loss:0.00001, loss_test:0.09992, lr:3.48e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.434, tt:3484.089\n",
      "Ep:189, loss:0.00001, loss_test:0.09985, lr:3.45e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.417, tt:3499.309\n",
      "Ep:190, loss:0.00001, loss_test:0.09978, lr:3.41e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.398, tt:3513.931\n",
      "Ep:191, loss:0.00001, loss_test:0.09972, lr:3.38e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.386, tt:3530.057\n",
      "Ep:192, loss:0.00001, loss_test:0.09972, lr:3.34e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.374, tt:3546.101\n",
      "Ep:193, loss:0.00001, loss_test:0.09964, lr:3.31e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.367, tt:3563.189\n",
      "Ep:194, loss:0.00001, loss_test:0.09963, lr:3.28e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.357, tt:3579.651\n",
      "Ep:195, loss:0.00001, loss_test:0.09961, lr:3.24e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.347, tt:3595.995\n",
      "Ep:196, loss:0.00001, loss_test:0.09953, lr:3.21e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.334, tt:3611.840\n",
      "Ep:197, loss:0.00001, loss_test:0.09953, lr:3.18e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.312, tt:3625.853\n",
      "Ep:198, loss:0.00001, loss_test:0.09948, lr:3.15e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.297, tt:3641.071\n",
      "Ep:199, loss:0.00001, loss_test:0.09944, lr:3.12e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.284, tt:3656.895\n",
      "Ep:200, loss:0.00001, loss_test:0.09940, lr:3.09e-03, fs:0.75429 (r=0.667,p=0.868),  time:18.273, tt:3672.874\n",
      "Ep:201, loss:0.00001, loss_test:0.09932, lr:3.05e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.258, tt:3688.049\n",
      "Ep:202, loss:0.00001, loss_test:0.09926, lr:3.02e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.251, tt:3704.883\n",
      "Ep:203, loss:0.00001, loss_test:0.09929, lr:2.99e-03, fs:0.75862 (r=0.667,p=0.880),  time:18.243, tt:3721.545\n",
      "Ep:204, loss:0.00001, loss_test:0.09924, lr:2.96e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.232, tt:3737.544\n",
      "Ep:205, loss:0.00001, loss_test:0.09914, lr:2.93e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.217, tt:3752.800\n",
      "Ep:206, loss:0.00001, loss_test:0.09905, lr:2.90e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.204, tt:3768.240\n",
      "Ep:207, loss:0.00001, loss_test:0.09904, lr:2.88e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.195, tt:3784.584\n",
      "Ep:208, loss:0.00001, loss_test:0.09907, lr:2.85e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.183, tt:3800.332\n",
      "Ep:209, loss:0.00001, loss_test:0.09906, lr:2.82e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.173, tt:3816.380\n",
      "Ep:210, loss:0.00001, loss_test:0.09901, lr:2.79e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.159, tt:3831.464\n",
      "Ep:211, loss:0.00001, loss_test:0.09897, lr:2.76e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.147, tt:3847.244\n",
      "Ep:212, loss:0.00001, loss_test:0.09893, lr:2.73e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.140, tt:3863.847\n",
      "Ep:213, loss:0.00001, loss_test:0.09885, lr:2.71e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.132, tt:3880.255\n",
      "Ep:214, loss:0.00001, loss_test:0.09881, lr:2.68e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.122, tt:3896.321\n",
      "Ep:215, loss:0.00001, loss_test:0.09883, lr:2.65e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.116, tt:3913.148\n",
      "Ep:216, loss:0.00001, loss_test:0.09880, lr:2.63e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.110, tt:3929.793\n",
      "Ep:217, loss:0.00001, loss_test:0.09876, lr:2.60e-03, fs:0.78161 (r=0.687,p=0.907),  time:18.100, tt:3945.764\n",
      "##########Best model found so far##########\n",
      "Ep:218, loss:0.00001, loss_test:0.09871, lr:2.60e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.095, tt:3962.769\n",
      "Ep:219, loss:0.00001, loss_test:0.09869, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.089, tt:3979.472\n",
      "##########Best model found so far##########\n",
      "Ep:220, loss:0.00001, loss_test:0.09869, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.076, tt:3994.835\n",
      "Ep:221, loss:0.00001, loss_test:0.09867, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.067, tt:4010.948\n",
      "Ep:222, loss:0.00001, loss_test:0.09864, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.058, tt:4026.850\n",
      "Ep:223, loss:0.00001, loss_test:0.09866, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.052, tt:4043.748\n",
      "Ep:224, loss:0.00001, loss_test:0.09864, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.046, tt:4060.303\n",
      "Ep:225, loss:0.00001, loss_test:0.09859, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.043, tt:4077.728\n",
      "Ep:226, loss:0.00001, loss_test:0.09856, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.042, tt:4095.520\n",
      "Ep:227, loss:0.00001, loss_test:0.09851, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.039, tt:4112.839\n",
      "Ep:228, loss:0.00001, loss_test:0.09845, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.030, tt:4128.878\n",
      "Ep:229, loss:0.00001, loss_test:0.09841, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.025, tt:4145.697\n",
      "Ep:230, loss:0.00001, loss_test:0.09836, lr:2.60e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.017, tt:4161.823\n",
      "Ep:231, loss:0.00001, loss_test:0.09834, lr:2.57e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.009, tt:4178.177\n",
      "Ep:232, loss:0.00001, loss_test:0.09830, lr:2.55e-03, fs:0.78613 (r=0.687,p=0.919),  time:17.999, tt:4193.701\n",
      "Ep:233, loss:0.00001, loss_test:0.09827, lr:2.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:17.995, tt:4210.916\n",
      "Ep:234, loss:0.00001, loss_test:0.09825, lr:2.50e-03, fs:0.78613 (r=0.687,p=0.919),  time:17.990, tt:4227.690\n",
      "Ep:235, loss:0.00001, loss_test:0.09829, lr:2.47e-03, fs:0.78613 (r=0.687,p=0.919),  time:17.990, tt:4245.694\n",
      "Ep:236, loss:0.00001, loss_test:0.09827, lr:2.45e-03, fs:0.78613 (r=0.687,p=0.919),  time:17.989, tt:4263.384\n",
      "Ep:237, loss:0.00001, loss_test:0.09819, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:17.990, tt:4281.627\n",
      "##########Best model found so far##########\n",
      "Ep:238, loss:0.00001, loss_test:0.09821, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:17.986, tt:4298.609\n",
      "Ep:239, loss:0.00001, loss_test:0.09825, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:17.988, tt:4317.100\n",
      "Ep:240, loss:0.00001, loss_test:0.09822, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:17.989, tt:4335.267\n",
      "Ep:241, loss:0.00001, loss_test:0.09816, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:17.995, tt:4354.848\n",
      "Ep:242, loss:0.00001, loss_test:0.09815, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.010, tt:4376.347\n",
      "Ep:243, loss:0.00001, loss_test:0.09817, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.020, tt:4396.940\n",
      "Ep:244, loss:0.00001, loss_test:0.09813, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.027, tt:4416.587\n",
      "Ep:245, loss:0.00001, loss_test:0.09805, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.033, tt:4436.076\n",
      "Ep:246, loss:0.00001, loss_test:0.09811, lr:2.42e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.037, tt:4455.020\n",
      "Ep:247, loss:0.00001, loss_test:0.09817, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.040, tt:4473.854\n",
      "Ep:248, loss:0.00001, loss_test:0.09811, lr:2.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.040, tt:4491.941\n",
      "Ep:249, loss:0.00001, loss_test:0.09806, lr:2.40e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.043, tt:4510.645\n",
      "Ep:250, loss:0.00001, loss_test:0.09809, lr:2.38e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.045, tt:4529.344\n",
      "Ep:251, loss:0.00001, loss_test:0.09810, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.051, tt:4548.863\n",
      "##########Best model found so far##########\n",
      "Ep:252, loss:0.00001, loss_test:0.09806, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.057, tt:4568.309\n",
      "Ep:253, loss:0.00001, loss_test:0.09805, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.063, tt:4588.097\n",
      "Ep:254, loss:0.00001, loss_test:0.09799, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.069, tt:4607.539\n",
      "Ep:255, loss:0.00001, loss_test:0.09795, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.073, tt:4626.790\n",
      "Ep:256, loss:0.00001, loss_test:0.09800, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.076, tt:4645.527\n",
      "Ep:257, loss:0.00001, loss_test:0.09796, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.087, tt:4666.317\n",
      "Ep:258, loss:0.00001, loss_test:0.09795, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.089, tt:4685.149\n",
      "Ep:259, loss:0.00001, loss_test:0.09784, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.096, tt:4704.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:260, loss:0.00001, loss_test:0.09785, lr:2.35e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.103, tt:4724.814\n",
      "Ep:261, loss:0.00001, loss_test:0.09794, lr:2.35e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.108, tt:4744.232\n",
      "Ep:262, loss:0.00001, loss_test:0.09788, lr:2.35e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.110, tt:4762.987\n",
      "Ep:263, loss:0.00001, loss_test:0.09782, lr:2.33e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.114, tt:4781.968\n",
      "Ep:264, loss:0.00001, loss_test:0.09785, lr:2.31e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.117, tt:4801.041\n",
      "Ep:265, loss:0.00001, loss_test:0.09787, lr:2.28e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.119, tt:4819.691\n",
      "Ep:266, loss:0.00001, loss_test:0.09784, lr:2.26e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.122, tt:4838.461\n",
      "Ep:267, loss:0.00001, loss_test:0.09783, lr:2.24e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.126, tt:4857.764\n",
      "Ep:268, loss:0.00001, loss_test:0.09777, lr:2.21e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.131, tt:4877.300\n",
      "Ep:269, loss:0.00001, loss_test:0.09779, lr:2.19e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.137, tt:4897.092\n",
      "Ep:270, loss:0.00001, loss_test:0.09778, lr:2.17e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.143, tt:4916.771\n",
      "Ep:271, loss:0.00000, loss_test:0.09772, lr:2.15e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.149, tt:4936.617\n",
      "Ep:272, loss:0.00000, loss_test:0.09769, lr:2.13e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.156, tt:4956.532\n",
      "Ep:273, loss:0.00000, loss_test:0.09770, lr:2.11e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.156, tt:4974.807\n",
      "Ep:274, loss:0.00000, loss_test:0.09766, lr:2.08e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.159, tt:4993.822\n",
      "Ep:275, loss:0.00000, loss_test:0.09769, lr:2.06e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.164, tt:5013.269\n",
      "Ep:276, loss:0.00000, loss_test:0.09772, lr:2.04e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.166, tt:5031.933\n",
      "Ep:277, loss:0.00000, loss_test:0.09768, lr:2.02e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.170, tt:5051.147\n",
      "Ep:278, loss:0.00000, loss_test:0.09769, lr:2.00e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.173, tt:5070.193\n",
      "Ep:279, loss:0.00000, loss_test:0.09771, lr:1.98e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.177, tt:5089.487\n",
      "Ep:280, loss:0.00000, loss_test:0.09768, lr:1.96e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.177, tt:5107.676\n",
      "Ep:281, loss:0.00000, loss_test:0.09776, lr:1.94e-03, fs:0.80000 (r=0.707,p=0.921),  time:18.180, tt:5126.715\n",
      "Ep:282, loss:0.00000, loss_test:0.09776, lr:1.92e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.182, tt:5145.567\n",
      "Ep:283, loss:0.00000, loss_test:0.09769, lr:1.90e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.183, tt:5163.882\n",
      "Ep:284, loss:0.00000, loss_test:0.09770, lr:1.89e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.187, tt:5183.265\n",
      "Ep:285, loss:0.00000, loss_test:0.09764, lr:1.87e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.196, tt:5203.936\n",
      "Ep:286, loss:0.00000, loss_test:0.09763, lr:1.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.199, tt:5223.105\n",
      "Ep:287, loss:0.00000, loss_test:0.09773, lr:1.83e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.204, tt:5242.883\n",
      "Ep:288, loss:0.00000, loss_test:0.09772, lr:1.81e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.201, tt:5260.055\n",
      "Ep:289, loss:0.00000, loss_test:0.09768, lr:1.79e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.201, tt:5278.189\n",
      "Ep:290, loss:0.00000, loss_test:0.09771, lr:1.78e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.203, tt:5297.120\n",
      "Ep:291, loss:0.00000, loss_test:0.09768, lr:1.76e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.202, tt:5315.098\n",
      "Ep:292, loss:0.00000, loss_test:0.09765, lr:1.74e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.206, tt:5334.429\n",
      "Ep:293, loss:0.00000, loss_test:0.09771, lr:1.72e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.208, tt:5353.093\n",
      "Ep:294, loss:0.00000, loss_test:0.09768, lr:1.71e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.212, tt:5372.409\n",
      "Ep:295, loss:0.00000, loss_test:0.09758, lr:1.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.214, tt:5391.223\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14399, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.776, tt:19.776\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14013, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:20.664, tt:41.328\n",
      "Ep:2, loss:0.00052, loss_test:0.13025, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:22.239, tt:66.716\n",
      "Ep:3, loss:0.00047, loss_test:0.12410, lr:1.00e-02, fs:0.59893 (r=0.566,p=0.636),  time:25.243, tt:100.971\n",
      "Ep:4, loss:0.00043, loss_test:0.12017, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:29.776, tt:148.878\n",
      "Ep:5, loss:0.00041, loss_test:0.11876, lr:1.00e-02, fs:0.65263 (r=0.626,p=0.681),  time:35.040, tt:210.241\n",
      "Ep:6, loss:0.00038, loss_test:0.11754, lr:1.00e-02, fs:0.65285 (r=0.636,p=0.670),  time:39.752, tt:278.264\n",
      "Ep:7, loss:0.00036, loss_test:0.12010, lr:1.00e-02, fs:0.55621 (r=0.475,p=0.671),  time:43.072, tt:344.572\n",
      "Ep:8, loss:0.00034, loss_test:0.11527, lr:1.00e-02, fs:0.62222 (r=0.566,p=0.691),  time:45.252, tt:407.272\n",
      "Ep:9, loss:0.00032, loss_test:0.11875, lr:1.00e-02, fs:0.58683 (r=0.495,p=0.721),  time:47.523, tt:475.230\n",
      "Ep:10, loss:0.00030, loss_test:0.11368, lr:1.00e-02, fs:0.62147 (r=0.556,p=0.705),  time:49.163, tt:540.791\n",
      "Ep:11, loss:0.00028, loss_test:0.11355, lr:1.00e-02, fs:0.61905 (r=0.525,p=0.754),  time:50.751, tt:609.010\n",
      "Ep:12, loss:0.00027, loss_test:0.11487, lr:9.90e-03, fs:0.62722 (r=0.535,p=0.757),  time:51.843, tt:673.961\n",
      "Ep:13, loss:0.00025, loss_test:0.11215, lr:9.80e-03, fs:0.63529 (r=0.545,p=0.761),  time:53.004, tt:742.061\n",
      "Ep:14, loss:0.00024, loss_test:0.11453, lr:9.70e-03, fs:0.63804 (r=0.525,p=0.812),  time:54.127, tt:811.900\n",
      "Ep:15, loss:0.00023, loss_test:0.11038, lr:9.61e-03, fs:0.65882 (r=0.566,p=0.789),  time:54.814, tt:877.027\n",
      "Ep:16, loss:0.00022, loss_test:0.11332, lr:9.51e-03, fs:0.66279 (r=0.576,p=0.781),  time:55.529, tt:943.986\n",
      "Ep:17, loss:0.00021, loss_test:0.11490, lr:9.41e-03, fs:0.61350 (r=0.505,p=0.781),  time:56.242, tt:1012.354\n",
      "Ep:18, loss:0.00020, loss_test:0.11242, lr:9.32e-03, fs:0.69318 (r=0.616,p=0.792),  time:56.719, tt:1077.669\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.11385, lr:9.32e-03, fs:0.65882 (r=0.566,p=0.789),  time:57.171, tt:1143.427\n",
      "Ep:20, loss:0.00018, loss_test:0.11677, lr:9.32e-03, fs:0.60123 (r=0.495,p=0.766),  time:57.638, tt:1210.406\n",
      "Ep:21, loss:0.00017, loss_test:0.11648, lr:9.32e-03, fs:0.64634 (r=0.535,p=0.815),  time:58.077, tt:1277.701\n",
      "Ep:22, loss:0.00016, loss_test:0.11622, lr:9.32e-03, fs:0.66667 (r=0.566,p=0.812),  time:58.368, tt:1342.473\n",
      "Ep:23, loss:0.00015, loss_test:0.11759, lr:9.32e-03, fs:0.62963 (r=0.515,p=0.810),  time:58.757, tt:1410.180\n",
      "Ep:24, loss:0.00015, loss_test:0.11743, lr:9.32e-03, fs:0.65854 (r=0.545,p=0.831),  time:58.992, tt:1474.790\n",
      "Ep:25, loss:0.00014, loss_test:0.12152, lr:9.32e-03, fs:0.64596 (r=0.525,p=0.839),  time:59.195, tt:1539.061\n",
      "Ep:26, loss:0.00013, loss_test:0.11417, lr:9.32e-03, fs:0.68235 (r=0.586,p=0.817),  time:59.491, tt:1606.268\n",
      "Ep:27, loss:0.00013, loss_test:0.11752, lr:9.32e-03, fs:0.67066 (r=0.566,p=0.824),  time:59.738, tt:1672.652\n",
      "Ep:28, loss:0.00012, loss_test:0.11902, lr:9.32e-03, fs:0.67073 (r=0.556,p=0.846),  time:59.937, tt:1738.180\n",
      "Ep:29, loss:0.00012, loss_test:0.11593, lr:9.32e-03, fs:0.70238 (r=0.596,p=0.855),  time:60.153, tt:1804.593\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.12500, lr:9.32e-03, fs:0.61438 (r=0.475,p=0.870),  time:60.382, tt:1871.842\n",
      "Ep:31, loss:0.00011, loss_test:0.12635, lr:9.32e-03, fs:0.65823 (r=0.525,p=0.881),  time:60.556, tt:1937.778\n",
      "Ep:32, loss:0.00010, loss_test:0.12222, lr:9.32e-03, fs:0.67081 (r=0.545,p=0.871),  time:60.760, tt:2005.066\n",
      "Ep:33, loss:0.00010, loss_test:0.11644, lr:9.32e-03, fs:0.67879 (r=0.566,p=0.848),  time:60.899, tt:2070.549\n",
      "Ep:34, loss:0.00009, loss_test:0.12310, lr:9.32e-03, fs:0.67081 (r=0.545,p=0.871),  time:61.075, tt:2137.632\n",
      "Ep:35, loss:0.00009, loss_test:0.12486, lr:9.32e-03, fs:0.66250 (r=0.535,p=0.869),  time:61.217, tt:2203.824\n",
      "Ep:36, loss:0.00009, loss_test:0.12665, lr:9.32e-03, fs:0.66250 (r=0.535,p=0.869),  time:61.367, tt:2270.571\n",
      "Ep:37, loss:0.00008, loss_test:0.11886, lr:9.32e-03, fs:0.67081 (r=0.545,p=0.871),  time:61.562, tt:2339.358\n",
      "Ep:38, loss:0.00008, loss_test:0.12484, lr:9.32e-03, fs:0.66250 (r=0.535,p=0.869),  time:61.680, tt:2405.533\n",
      "Ep:39, loss:0.00007, loss_test:0.13055, lr:9.32e-03, fs:0.65823 (r=0.525,p=0.881),  time:61.771, tt:2470.852\n",
      "Ep:40, loss:0.00007, loss_test:0.12648, lr:9.32e-03, fs:0.64935 (r=0.505,p=0.909),  time:61.898, tt:2537.816\n",
      "Ep:41, loss:0.00007, loss_test:0.11793, lr:9.23e-03, fs:0.67089 (r=0.535,p=0.898),  time:62.056, tt:2606.341\n",
      "Ep:42, loss:0.00007, loss_test:0.12712, lr:9.14e-03, fs:0.67500 (r=0.545,p=0.885),  time:62.121, tt:2671.224\n",
      "Ep:43, loss:0.00006, loss_test:0.12839, lr:9.04e-03, fs:0.67081 (r=0.545,p=0.871),  time:62.228, tt:2738.011\n",
      "Ep:44, loss:0.00006, loss_test:0.12153, lr:8.95e-03, fs:0.67081 (r=0.545,p=0.871),  time:62.275, tt:2802.375\n",
      "Ep:45, loss:0.00006, loss_test:0.12727, lr:8.86e-03, fs:0.67500 (r=0.545,p=0.885),  time:62.302, tt:2865.877\n",
      "Ep:46, loss:0.00006, loss_test:0.13031, lr:8.78e-03, fs:0.67925 (r=0.545,p=0.900),  time:62.347, tt:2930.321\n",
      "Ep:47, loss:0.00006, loss_test:0.13272, lr:8.69e-03, fs:0.67925 (r=0.545,p=0.900),  time:62.437, tt:2996.975\n",
      "Ep:48, loss:0.00005, loss_test:0.12221, lr:8.60e-03, fs:0.68354 (r=0.545,p=0.915),  time:62.533, tt:3064.124\n",
      "Ep:49, loss:0.00005, loss_test:0.12363, lr:8.51e-03, fs:0.67925 (r=0.545,p=0.900),  time:62.613, tt:3130.660\n",
      "Ep:50, loss:0.00005, loss_test:0.12751, lr:8.43e-03, fs:0.67925 (r=0.545,p=0.900),  time:62.679, tt:3196.651\n",
      "Ep:51, loss:0.00005, loss_test:0.12766, lr:8.35e-03, fs:0.67925 (r=0.545,p=0.900),  time:62.741, tt:3262.554\n",
      "Ep:52, loss:0.00004, loss_test:0.12729, lr:8.26e-03, fs:0.67925 (r=0.545,p=0.900),  time:62.793, tt:3328.046\n",
      "Ep:53, loss:0.00004, loss_test:0.12691, lr:8.18e-03, fs:0.68354 (r=0.545,p=0.915),  time:62.830, tt:3392.815\n",
      "Ep:54, loss:0.00004, loss_test:0.12622, lr:8.10e-03, fs:0.68790 (r=0.545,p=0.931),  time:62.887, tt:3458.770\n",
      "Ep:55, loss:0.00004, loss_test:0.13107, lr:8.02e-03, fs:0.68790 (r=0.545,p=0.931),  time:62.924, tt:3523.750\n",
      "Ep:56, loss:0.00004, loss_test:0.12615, lr:7.94e-03, fs:0.68354 (r=0.545,p=0.915),  time:62.983, tt:3590.057\n",
      "Ep:57, loss:0.00004, loss_test:0.12777, lr:7.86e-03, fs:0.68354 (r=0.545,p=0.915),  time:63.052, tt:3656.988\n",
      "Ep:58, loss:0.00004, loss_test:0.13112, lr:7.78e-03, fs:0.67500 (r=0.545,p=0.885),  time:63.077, tt:3721.564\n",
      "Ep:59, loss:0.00004, loss_test:0.12955, lr:7.70e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.175, tt:3790.511\n",
      "Ep:60, loss:0.00004, loss_test:0.12585, lr:7.62e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.197, tt:3854.998\n",
      "Ep:61, loss:0.00003, loss_test:0.13259, lr:7.55e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.241, tt:3920.945\n",
      "Ep:62, loss:0.00003, loss_test:0.12670, lr:7.47e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.281, tt:3986.725\n",
      "Ep:63, loss:0.00003, loss_test:0.13363, lr:7.40e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.324, tt:4052.765\n",
      "Ep:64, loss:0.00003, loss_test:0.13397, lr:7.32e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.354, tt:4118.023\n",
      "Ep:65, loss:0.00003, loss_test:0.12602, lr:7.25e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.394, tt:4184.033\n",
      "Ep:66, loss:0.00003, loss_test:0.13565, lr:7.18e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.431, tt:4249.885\n",
      "Ep:67, loss:0.00003, loss_test:0.13553, lr:7.11e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.492, tt:4317.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00003, loss_test:0.12996, lr:7.03e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.527, tt:4383.374\n",
      "Ep:69, loss:0.00003, loss_test:0.12944, lr:6.96e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.531, tt:4447.161\n",
      "Ep:70, loss:0.00003, loss_test:0.13555, lr:6.89e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.558, tt:4512.620\n",
      "Ep:71, loss:0.00003, loss_test:0.12823, lr:6.83e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.609, tt:4579.830\n",
      "Ep:72, loss:0.00003, loss_test:0.13139, lr:6.76e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.644, tt:4646.016\n",
      "Ep:73, loss:0.00003, loss_test:0.13484, lr:6.69e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.661, tt:4710.879\n",
      "Ep:74, loss:0.00002, loss_test:0.13018, lr:6.62e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.698, tt:4777.350\n",
      "Ep:75, loss:0.00002, loss_test:0.13292, lr:6.56e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.726, tt:4843.144\n",
      "Ep:76, loss:0.00002, loss_test:0.13279, lr:6.49e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.759, tt:4909.471\n",
      "Ep:77, loss:0.00002, loss_test:0.13155, lr:6.43e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.786, tt:4975.274\n",
      "Ep:78, loss:0.00002, loss_test:0.13164, lr:6.36e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.799, tt:5040.097\n",
      "Ep:79, loss:0.00002, loss_test:0.13274, lr:6.30e-03, fs:0.66667 (r=0.515,p=0.944),  time:63.825, tt:5105.992\n",
      "Ep:80, loss:0.00002, loss_test:0.13170, lr:6.24e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.868, tt:5173.320\n",
      "Ep:81, loss:0.00002, loss_test:0.13678, lr:6.17e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.869, tt:5237.224\n",
      "Ep:82, loss:0.00002, loss_test:0.13366, lr:6.11e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.898, tt:5303.511\n",
      "Ep:83, loss:0.00002, loss_test:0.13367, lr:6.05e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.931, tt:5370.183\n",
      "Ep:84, loss:0.00002, loss_test:0.13567, lr:5.99e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.953, tt:5436.015\n",
      "Ep:85, loss:0.00002, loss_test:0.13598, lr:5.93e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.994, tt:5503.495\n",
      "Ep:86, loss:0.00002, loss_test:0.13031, lr:5.87e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.002, tt:5568.218\n",
      "Ep:87, loss:0.00002, loss_test:0.14029, lr:5.81e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.019, tt:5633.673\n",
      "Ep:88, loss:0.00002, loss_test:0.13436, lr:5.75e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.047, tt:5700.209\n",
      "Ep:89, loss:0.00002, loss_test:0.13498, lr:5.70e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.078, tt:5766.981\n",
      "Ep:90, loss:0.00002, loss_test:0.13763, lr:5.64e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.114, tt:5834.380\n",
      "Ep:91, loss:0.00002, loss_test:0.13333, lr:5.58e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.148, tt:5901.625\n",
      "Ep:92, loss:0.00002, loss_test:0.13692, lr:5.53e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.161, tt:5966.932\n",
      "Ep:93, loss:0.00002, loss_test:0.13600, lr:5.47e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.178, tt:6032.753\n",
      "Ep:94, loss:0.00002, loss_test:0.13425, lr:5.42e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.217, tt:6100.571\n",
      "Ep:95, loss:0.00002, loss_test:0.13845, lr:5.36e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.245, tt:6167.530\n",
      "Ep:96, loss:0.00002, loss_test:0.13627, lr:5.31e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.229, tt:6230.225\n",
      "Ep:97, loss:0.00002, loss_test:0.13600, lr:5.26e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.246, tt:6296.094\n",
      "Ep:98, loss:0.00002, loss_test:0.13798, lr:5.20e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.246, tt:6360.306\n",
      "Ep:99, loss:0.00002, loss_test:0.13581, lr:5.15e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.267, tt:6426.685\n",
      "Ep:100, loss:0.00002, loss_test:0.13838, lr:5.10e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.295, tt:6493.808\n",
      "Ep:101, loss:0.00001, loss_test:0.13563, lr:5.05e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.299, tt:6558.539\n",
      "Ep:102, loss:0.00001, loss_test:0.13867, lr:5.00e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.292, tt:6622.102\n",
      "Ep:103, loss:0.00001, loss_test:0.13463, lr:4.95e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.290, tt:6686.109\n",
      "Ep:104, loss:0.00001, loss_test:0.14084, lr:4.90e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.293, tt:6750.796\n",
      "Ep:105, loss:0.00001, loss_test:0.13673, lr:4.85e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.304, tt:6816.200\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14385, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:83.279, tt:83.279\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13737, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:79.200, tt:158.401\n",
      "Ep:2, loss:0.00048, loss_test:0.13135, lr:1.00e-02, fs:0.58333 (r=0.566,p=0.602),  time:76.675, tt:230.026\n",
      "Ep:3, loss:0.00043, loss_test:0.12503, lr:1.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:76.821, tt:307.284\n",
      "Ep:4, loss:0.00040, loss_test:0.12508, lr:1.00e-02, fs:0.53933 (r=0.485,p=0.608),  time:76.247, tt:381.235\n",
      "Ep:5, loss:0.00036, loss_test:0.12201, lr:1.00e-02, fs:0.60773 (r=0.556,p=0.671),  time:77.788, tt:466.726\n",
      "Ep:6, loss:0.00033, loss_test:0.12189, lr:1.00e-02, fs:0.58621 (r=0.515,p=0.680),  time:78.500, tt:549.501\n",
      "Ep:7, loss:0.00030, loss_test:0.11765, lr:1.00e-02, fs:0.61078 (r=0.515,p=0.750),  time:78.906, tt:631.245\n",
      "Ep:8, loss:0.00028, loss_test:0.11444, lr:1.00e-02, fs:0.67039 (r=0.606,p=0.750),  time:79.152, tt:712.366\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.10774, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:79.244, tt:792.443\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.10763, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:79.428, tt:873.706\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10950, lr:1.00e-02, fs:0.68927 (r=0.616,p=0.782),  time:79.691, tt:956.290\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.11664, lr:1.00e-02, fs:0.66265 (r=0.556,p=0.821),  time:79.918, tt:1038.940\n",
      "Ep:13, loss:0.00019, loss_test:0.11610, lr:1.00e-02, fs:0.65455 (r=0.545,p=0.818),  time:80.281, tt:1123.928\n",
      "Ep:14, loss:0.00017, loss_test:0.12203, lr:1.00e-02, fs:0.61635 (r=0.495,p=0.817),  time:80.334, tt:1205.003\n",
      "Ep:15, loss:0.00016, loss_test:0.11354, lr:1.00e-02, fs:0.67470 (r=0.566,p=0.836),  time:80.616, tt:1289.858\n",
      "Ep:16, loss:0.00015, loss_test:0.11237, lr:1.00e-02, fs:0.67066 (r=0.566,p=0.824),  time:80.857, tt:1374.561\n",
      "Ep:17, loss:0.00014, loss_test:0.11472, lr:1.00e-02, fs:0.64198 (r=0.525,p=0.825),  time:80.972, tt:1457.492\n",
      "Ep:18, loss:0.00013, loss_test:0.12055, lr:1.00e-02, fs:0.63291 (r=0.505,p=0.847),  time:80.958, tt:1538.207\n",
      "Ep:19, loss:0.00012, loss_test:0.12472, lr:1.00e-02, fs:0.57718 (r=0.434,p=0.860),  time:81.141, tt:1622.815\n",
      "Ep:20, loss:0.00011, loss_test:0.12246, lr:1.00e-02, fs:0.57895 (r=0.444,p=0.830),  time:80.950, tt:1699.957\n",
      "Ep:21, loss:0.00010, loss_test:0.13150, lr:1.00e-02, fs:0.57143 (r=0.424,p=0.875),  time:81.070, tt:1783.544\n",
      "Ep:22, loss:0.00009, loss_test:0.13278, lr:1.00e-02, fs:0.58904 (r=0.434,p=0.915),  time:81.137, tt:1866.155\n",
      "Ep:23, loss:0.00009, loss_test:0.13116, lr:9.90e-03, fs:0.56376 (r=0.424,p=0.840),  time:81.267, tt:1950.414\n",
      "Ep:24, loss:0.00008, loss_test:0.12233, lr:9.80e-03, fs:0.58667 (r=0.444,p=0.863),  time:81.352, tt:2033.798\n",
      "Ep:25, loss:0.00007, loss_test:0.11622, lr:9.70e-03, fs:0.64151 (r=0.515,p=0.850),  time:81.432, tt:2117.240\n",
      "Ep:26, loss:0.00007, loss_test:0.11861, lr:9.61e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.461, tt:2199.434\n",
      "Ep:27, loss:0.00006, loss_test:0.12350, lr:9.51e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.518, tt:2282.510\n",
      "Ep:28, loss:0.00006, loss_test:0.11715, lr:9.41e-03, fs:0.63694 (r=0.505,p=0.862),  time:81.574, tt:2365.644\n",
      "Ep:29, loss:0.00005, loss_test:0.12300, lr:9.32e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.520, tt:2445.607\n",
      "Ep:30, loss:0.00005, loss_test:0.12658, lr:9.23e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.619, tt:2530.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00004, loss_test:0.11944, lr:9.14e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.683, tt:2613.853\n",
      "Ep:32, loss:0.00004, loss_test:0.12933, lr:9.04e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.711, tt:2696.471\n",
      "Ep:33, loss:0.00004, loss_test:0.12821, lr:8.95e-03, fs:0.58108 (r=0.434,p=0.878),  time:81.764, tt:2779.971\n",
      "Ep:34, loss:0.00004, loss_test:0.13217, lr:8.86e-03, fs:0.58904 (r=0.434,p=0.915),  time:81.787, tt:2862.550\n",
      "Ep:35, loss:0.00003, loss_test:0.13155, lr:8.78e-03, fs:0.58904 (r=0.434,p=0.915),  time:81.830, tt:2945.890\n",
      "Ep:36, loss:0.00003, loss_test:0.13007, lr:8.69e-03, fs:0.58904 (r=0.434,p=0.915),  time:81.997, tt:3033.873\n",
      "Ep:37, loss:0.00003, loss_test:0.12932, lr:8.60e-03, fs:0.58904 (r=0.434,p=0.915),  time:82.008, tt:3116.300\n",
      "Ep:38, loss:0.00003, loss_test:0.13411, lr:8.51e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.077, tt:3200.990\n",
      "Ep:39, loss:0.00002, loss_test:0.13058, lr:8.43e-03, fs:0.59310 (r=0.434,p=0.935),  time:82.027, tt:3281.074\n",
      "Ep:40, loss:0.00002, loss_test:0.13207, lr:8.35e-03, fs:0.59310 (r=0.434,p=0.935),  time:81.991, tt:3361.625\n",
      "Ep:41, loss:0.00002, loss_test:0.12824, lr:8.26e-03, fs:0.58904 (r=0.434,p=0.915),  time:81.989, tt:3443.536\n",
      "Ep:42, loss:0.00002, loss_test:0.13155, lr:8.18e-03, fs:0.59310 (r=0.434,p=0.935),  time:81.941, tt:3523.451\n",
      "Ep:43, loss:0.00002, loss_test:0.13640, lr:8.10e-03, fs:0.59722 (r=0.434,p=0.956),  time:81.957, tt:3606.086\n",
      "Ep:44, loss:0.00002, loss_test:0.13050, lr:8.02e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.028, tt:3691.243\n",
      "Ep:45, loss:0.00002, loss_test:0.13028, lr:7.94e-03, fs:0.59310 (r=0.434,p=0.935),  time:82.058, tt:3774.669\n",
      "Ep:46, loss:0.00002, loss_test:0.14169, lr:7.86e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.076, tt:3857.581\n",
      "Ep:47, loss:0.00002, loss_test:0.13391, lr:7.78e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.136, tt:3942.520\n",
      "Ep:48, loss:0.00002, loss_test:0.13270, lr:7.70e-03, fs:0.59310 (r=0.434,p=0.935),  time:82.103, tt:4023.063\n",
      "Ep:49, loss:0.00001, loss_test:0.13595, lr:7.62e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.030, tt:4101.479\n",
      "Ep:50, loss:0.00001, loss_test:0.13527, lr:7.55e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.032, tt:4183.648\n",
      "Ep:51, loss:0.00001, loss_test:0.13411, lr:7.47e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.037, tt:4265.904\n",
      "Ep:52, loss:0.00001, loss_test:0.13761, lr:7.40e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.065, tt:4349.446\n",
      "Ep:53, loss:0.00001, loss_test:0.13143, lr:7.32e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.110, tt:4433.960\n",
      "Ep:54, loss:0.00001, loss_test:0.13610, lr:7.25e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.105, tt:4515.770\n",
      "Ep:55, loss:0.00001, loss_test:0.13596, lr:7.18e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.096, tt:4597.349\n",
      "Ep:56, loss:0.00001, loss_test:0.13779, lr:7.11e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.078, tt:4678.433\n",
      "Ep:57, loss:0.00001, loss_test:0.13792, lr:7.03e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.068, tt:4759.921\n",
      "Ep:58, loss:0.00001, loss_test:0.13981, lr:6.96e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.066, tt:4841.904\n",
      "Ep:59, loss:0.00001, loss_test:0.13623, lr:6.89e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.048, tt:4922.865\n",
      "Ep:60, loss:0.00001, loss_test:0.13932, lr:6.83e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.034, tt:5004.069\n",
      "Ep:61, loss:0.00001, loss_test:0.14319, lr:6.76e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.021, tt:5085.305\n",
      "Ep:62, loss:0.00001, loss_test:0.13715, lr:6.69e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.086, tt:5171.414\n",
      "Ep:63, loss:0.00001, loss_test:0.14053, lr:6.62e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.090, tt:5253.761\n",
      "Ep:64, loss:0.00001, loss_test:0.13887, lr:6.56e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.104, tt:5336.745\n",
      "Ep:65, loss:0.00001, loss_test:0.14327, lr:6.49e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.112, tt:5419.368\n",
      "Ep:66, loss:0.00001, loss_test:0.13842, lr:6.43e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.101, tt:5500.769\n",
      "Ep:67, loss:0.00001, loss_test:0.14103, lr:6.36e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.166, tt:5587.281\n",
      "Ep:68, loss:0.00001, loss_test:0.14316, lr:6.30e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.215, tt:5672.804\n",
      "Ep:69, loss:0.00001, loss_test:0.13998, lr:6.24e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.166, tt:5751.617\n",
      "Ep:70, loss:0.00001, loss_test:0.14323, lr:6.17e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.171, tt:5834.156\n",
      "Ep:71, loss:0.00001, loss_test:0.14125, lr:6.11e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.145, tt:5914.446\n",
      "Ep:72, loss:0.00001, loss_test:0.14396, lr:6.05e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.213, tt:6001.517\n",
      "Ep:73, loss:0.00000, loss_test:0.14612, lr:5.99e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.139, tt:6078.305\n",
      "Ep:74, loss:0.00000, loss_test:0.14049, lr:5.93e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.170, tt:6162.732\n",
      "Ep:75, loss:0.00000, loss_test:0.14394, lr:5.87e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.175, tt:6245.308\n",
      "Ep:76, loss:0.00000, loss_test:0.14284, lr:5.81e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.180, tt:6327.827\n",
      "Ep:77, loss:0.00000, loss_test:0.14212, lr:5.75e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.252, tt:6415.666\n",
      "Ep:78, loss:0.00000, loss_test:0.14722, lr:5.70e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.244, tt:6497.294\n",
      "Ep:79, loss:0.00000, loss_test:0.14272, lr:5.64e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.268, tt:6581.401\n",
      "Ep:80, loss:0.00000, loss_test:0.14644, lr:5.58e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.295, tt:6665.864\n",
      "Ep:81, loss:0.00000, loss_test:0.14210, lr:5.53e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.369, tt:6754.289\n",
      "Ep:82, loss:0.00000, loss_test:0.14522, lr:5.47e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.394, tt:6838.700\n",
      "Ep:83, loss:0.00000, loss_test:0.14318, lr:5.42e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.385, tt:6920.359\n",
      "Ep:84, loss:0.00000, loss_test:0.14230, lr:5.36e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.409, tt:7004.774\n",
      "Ep:85, loss:0.00000, loss_test:0.14414, lr:5.31e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.382, tt:7084.861\n",
      "Ep:86, loss:0.00000, loss_test:0.14464, lr:5.26e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.423, tt:7170.819\n",
      "Ep:87, loss:0.00000, loss_test:0.14133, lr:5.20e-03, fs:0.57746 (r=0.414,p=0.953),  time:82.428, tt:7253.642\n",
      "Ep:88, loss:0.00000, loss_test:0.14426, lr:5.15e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.428, tt:7336.073\n",
      "Ep:89, loss:0.00000, loss_test:0.14316, lr:5.10e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.434, tt:7419.034\n",
      "Ep:90, loss:0.00000, loss_test:0.14569, lr:5.05e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.435, tt:7501.546\n",
      "Ep:91, loss:0.00000, loss_test:0.14315, lr:5.00e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.424, tt:7583.050\n",
      "Ep:92, loss:0.00000, loss_test:0.14441, lr:4.95e-03, fs:0.57746 (r=0.414,p=0.953),  time:82.416, tt:7664.666\n",
      "Ep:93, loss:0.00000, loss_test:0.14521, lr:4.90e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.396, tt:7745.248\n",
      "Ep:94, loss:0.00000, loss_test:0.14408, lr:4.85e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.420, tt:7829.879\n",
      "Ep:95, loss:0.00000, loss_test:0.14548, lr:4.80e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.414, tt:7911.750\n",
      "Ep:96, loss:0.00000, loss_test:0.14283, lr:4.75e-03, fs:0.56738 (r=0.404,p=0.952),  time:82.437, tt:7996.433\n",
      "Ep:97, loss:0.00000, loss_test:0.14595, lr:4.71e-03, fs:0.56115 (r=0.394,p=0.975),  time:82.474, tt:8082.457\n",
      "Ep:98, loss:0.00000, loss_test:0.14251, lr:4.66e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.504, tt:8167.920\n",
      "Ep:99, loss:0.00000, loss_test:0.14586, lr:4.61e-03, fs:0.58156 (r=0.414,p=0.976),  time:82.495, tt:8249.498\n",
      "Ep:100, loss:0.00000, loss_test:0.14276, lr:4.57e-03, fs:0.54676 (r=0.384,p=0.950),  time:82.494, tt:8331.935\n",
      "Ep:101, loss:0.00000, loss_test:0.14467, lr:4.52e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.518, tt:8416.802\n",
      "Ep:102, loss:0.00000, loss_test:0.14360, lr:4.48e-03, fs:0.56738 (r=0.404,p=0.952),  time:82.526, tt:8500.130\n",
      "Ep:103, loss:0.00000, loss_test:0.14571, lr:4.43e-03, fs:0.56115 (r=0.394,p=0.975),  time:82.573, tt:8587.577\n",
      "Ep:104, loss:0.00000, loss_test:0.14313, lr:4.39e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.582, tt:8671.152\n",
      "Ep:105, loss:0.00000, loss_test:0.14488, lr:4.34e-03, fs:0.56115 (r=0.394,p=0.975),  time:82.549, tt:8750.155\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00054, loss_test:0.13931, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:71.415, tt:71.415\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00052, loss_test:0.12861, lr:1.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:70.228, tt:140.456\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00048, loss_test:0.12016, lr:1.00e-02, fs:0.65438 (r=0.717,p=0.602),  time:67.483, tt:202.449\n",
      "Ep:3, loss:0.00045, loss_test:0.12078, lr:1.00e-02, fs:0.64762 (r=0.687,p=0.613),  time:67.917, tt:271.668\n",
      "Ep:4, loss:0.00043, loss_test:0.11892, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:67.829, tt:339.145\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.11736, lr:1.00e-02, fs:0.65657 (r=0.657,p=0.657),  time:67.714, tt:406.281\n",
      "Ep:6, loss:0.00038, loss_test:0.11504, lr:1.00e-02, fs:0.64286 (r=0.636,p=0.649),  time:68.607, tt:480.252\n",
      "Ep:7, loss:0.00035, loss_test:0.11518, lr:1.00e-02, fs:0.65306 (r=0.646,p=0.660),  time:69.484, tt:555.875\n",
      "Ep:8, loss:0.00033, loss_test:0.11034, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:70.413, tt:633.713\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00031, loss_test:0.11373, lr:1.00e-02, fs:0.65591 (r=0.616,p=0.701),  time:70.687, tt:706.869\n",
      "Ep:10, loss:0.00029, loss_test:0.10893, lr:1.00e-02, fs:0.64865 (r=0.606,p=0.698),  time:70.948, tt:780.424\n",
      "Ep:11, loss:0.00028, loss_test:0.11397, lr:1.00e-02, fs:0.59551 (r=0.535,p=0.671),  time:71.183, tt:854.195\n",
      "Ep:12, loss:0.00026, loss_test:0.11264, lr:1.00e-02, fs:0.62791 (r=0.545,p=0.740),  time:71.426, tt:928.535\n",
      "Ep:13, loss:0.00025, loss_test:0.11170, lr:1.00e-02, fs:0.62722 (r=0.535,p=0.757),  time:71.555, tt:1001.766\n",
      "Ep:14, loss:0.00023, loss_test:0.11275, lr:1.00e-02, fs:0.62791 (r=0.545,p=0.740),  time:71.624, tt:1074.357\n",
      "Ep:15, loss:0.00022, loss_test:0.11681, lr:1.00e-02, fs:0.63584 (r=0.556,p=0.743),  time:71.797, tt:1148.748\n",
      "Ep:16, loss:0.00021, loss_test:0.11683, lr:1.00e-02, fs:0.63529 (r=0.545,p=0.761),  time:71.949, tt:1223.126\n",
      "Ep:17, loss:0.00019, loss_test:0.11765, lr:1.00e-02, fs:0.63218 (r=0.556,p=0.733),  time:72.092, tt:1297.661\n",
      "Ep:18, loss:0.00018, loss_test:0.12546, lr:1.00e-02, fs:0.63804 (r=0.525,p=0.812),  time:72.387, tt:1375.349\n",
      "Ep:19, loss:0.00017, loss_test:0.11612, lr:1.00e-02, fs:0.65143 (r=0.576,p=0.750),  time:72.483, tt:1449.656\n",
      "Ep:20, loss:0.00017, loss_test:0.11880, lr:9.90e-03, fs:0.67429 (r=0.596,p=0.776),  time:72.612, tt:1524.851\n",
      "Ep:21, loss:0.00016, loss_test:0.13537, lr:9.80e-03, fs:0.62577 (r=0.515,p=0.797),  time:72.712, tt:1599.670\n",
      "Ep:22, loss:0.00015, loss_test:0.13242, lr:9.70e-03, fs:0.63750 (r=0.515,p=0.836),  time:72.871, tt:1676.036\n",
      "Ep:23, loss:0.00014, loss_test:0.12261, lr:9.61e-03, fs:0.71351 (r=0.667,p=0.767),  time:72.964, tt:1751.136\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.13164, lr:9.61e-03, fs:0.60759 (r=0.485,p=0.814),  time:73.051, tt:1826.287\n",
      "Ep:25, loss:0.00013, loss_test:0.13891, lr:9.61e-03, fs:0.56579 (r=0.434,p=0.811),  time:73.130, tt:1901.384\n",
      "Ep:26, loss:0.00012, loss_test:0.12661, lr:9.61e-03, fs:0.71823 (r=0.657,p=0.793),  time:73.304, tt:1979.214\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.13434, lr:9.61e-03, fs:0.67836 (r=0.586,p=0.806),  time:73.416, tt:2055.649\n",
      "Ep:28, loss:0.00012, loss_test:0.15159, lr:9.61e-03, fs:0.53595 (r=0.414,p=0.759),  time:73.573, tt:2133.621\n",
      "Ep:29, loss:0.00012, loss_test:0.14645, lr:9.61e-03, fs:0.58974 (r=0.465,p=0.807),  time:73.599, tt:2207.983\n",
      "Ep:30, loss:0.00011, loss_test:0.12996, lr:9.61e-03, fs:0.67052 (r=0.586,p=0.784),  time:73.612, tt:2281.982\n",
      "Ep:31, loss:0.00011, loss_test:0.12246, lr:9.61e-03, fs:0.73118 (r=0.687,p=0.782),  time:73.720, tt:2359.045\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.12780, lr:9.61e-03, fs:0.70718 (r=0.646,p=0.780),  time:73.766, tt:2434.282\n",
      "Ep:33, loss:0.00009, loss_test:0.13152, lr:9.61e-03, fs:0.67059 (r=0.576,p=0.803),  time:73.802, tt:2509.264\n",
      "Ep:34, loss:0.00009, loss_test:0.13420, lr:9.61e-03, fs:0.68293 (r=0.566,p=0.862),  time:73.787, tt:2582.536\n",
      "Ep:35, loss:0.00008, loss_test:0.14018, lr:9.61e-03, fs:0.60759 (r=0.485,p=0.814),  time:73.744, tt:2654.780\n",
      "Ep:36, loss:0.00008, loss_test:0.13588, lr:9.61e-03, fs:0.67879 (r=0.566,p=0.848),  time:73.763, tt:2729.224\n",
      "Ep:37, loss:0.00008, loss_test:0.13386, lr:9.61e-03, fs:0.67470 (r=0.566,p=0.836),  time:73.802, tt:2804.473\n",
      "Ep:38, loss:0.00007, loss_test:0.13329, lr:9.61e-03, fs:0.65089 (r=0.556,p=0.786),  time:73.779, tt:2877.383\n",
      "Ep:39, loss:0.00007, loss_test:0.13497, lr:9.61e-03, fs:0.65868 (r=0.556,p=0.809),  time:73.842, tt:2953.683\n",
      "Ep:40, loss:0.00007, loss_test:0.13544, lr:9.61e-03, fs:0.66258 (r=0.545,p=0.844),  time:73.843, tt:3027.563\n",
      "Ep:41, loss:0.00006, loss_test:0.13909, lr:9.61e-03, fs:0.56579 (r=0.434,p=0.811),  time:73.911, tt:3104.246\n",
      "Ep:42, loss:0.00006, loss_test:0.14840, lr:9.61e-03, fs:0.57718 (r=0.434,p=0.860),  time:73.910, tt:3178.143\n",
      "Ep:43, loss:0.00006, loss_test:0.14074, lr:9.51e-03, fs:0.67081 (r=0.545,p=0.871),  time:73.937, tt:3253.226\n",
      "Ep:44, loss:0.00006, loss_test:0.13168, lr:9.41e-03, fs:0.64286 (r=0.545,p=0.783),  time:73.944, tt:3327.467\n",
      "Ep:45, loss:0.00006, loss_test:0.14087, lr:9.32e-03, fs:0.65854 (r=0.545,p=0.831),  time:73.939, tt:3401.213\n",
      "Ep:46, loss:0.00006, loss_test:0.14035, lr:9.23e-03, fs:0.67500 (r=0.545,p=0.885),  time:73.919, tt:3474.177\n",
      "Ep:47, loss:0.00005, loss_test:0.14065, lr:9.14e-03, fs:0.67081 (r=0.545,p=0.871),  time:73.916, tt:3547.959\n",
      "Ep:48, loss:0.00005, loss_test:0.14090, lr:9.04e-03, fs:0.64968 (r=0.515,p=0.879),  time:73.908, tt:3621.481\n",
      "Ep:49, loss:0.00005, loss_test:0.13432, lr:8.95e-03, fs:0.65854 (r=0.545,p=0.831),  time:73.967, tt:3698.356\n",
      "Ep:50, loss:0.00005, loss_test:0.12968, lr:8.86e-03, fs:0.65868 (r=0.556,p=0.809),  time:73.939, tt:3770.876\n",
      "Ep:51, loss:0.00005, loss_test:0.13013, lr:8.78e-03, fs:0.64634 (r=0.535,p=0.815),  time:73.923, tt:3844.003\n",
      "Ep:52, loss:0.00005, loss_test:0.13181, lr:8.69e-03, fs:0.67081 (r=0.545,p=0.871),  time:73.931, tt:3918.362\n",
      "Ep:53, loss:0.00005, loss_test:0.13896, lr:8.60e-03, fs:0.59211 (r=0.455,p=0.849),  time:73.891, tt:3990.089\n",
      "Ep:54, loss:0.00005, loss_test:0.13167, lr:8.51e-03, fs:0.66258 (r=0.545,p=0.844),  time:73.922, tt:4065.692\n",
      "Ep:55, loss:0.00004, loss_test:0.13860, lr:8.43e-03, fs:0.67500 (r=0.545,p=0.885),  time:73.982, tt:4142.990\n",
      "Ep:56, loss:0.00004, loss_test:0.14077, lr:8.35e-03, fs:0.68354 (r=0.545,p=0.915),  time:73.991, tt:4217.485\n",
      "Ep:57, loss:0.00004, loss_test:0.13932, lr:8.26e-03, fs:0.68790 (r=0.545,p=0.931),  time:74.052, tt:4295.040\n",
      "Ep:58, loss:0.00004, loss_test:0.13874, lr:8.18e-03, fs:0.67500 (r=0.545,p=0.885),  time:74.119, tt:4373.014\n",
      "Ep:59, loss:0.00004, loss_test:0.13717, lr:8.10e-03, fs:0.67500 (r=0.545,p=0.885),  time:74.171, tt:4450.233\n",
      "Ep:60, loss:0.00004, loss_test:0.13414, lr:8.02e-03, fs:0.66667 (r=0.545,p=0.857),  time:74.234, tt:4528.253\n",
      "Ep:61, loss:0.00003, loss_test:0.13587, lr:7.94e-03, fs:0.67925 (r=0.545,p=0.900),  time:74.230, tt:4602.268\n",
      "Ep:62, loss:0.00003, loss_test:0.14045, lr:7.86e-03, fs:0.64516 (r=0.505,p=0.893),  time:74.216, tt:4675.606\n",
      "Ep:63, loss:0.00003, loss_test:0.13819, lr:7.78e-03, fs:0.67089 (r=0.535,p=0.898),  time:74.194, tt:4748.400\n",
      "Ep:64, loss:0.00003, loss_test:0.14279, lr:7.70e-03, fs:0.59459 (r=0.444,p=0.898),  time:74.185, tt:4822.041\n",
      "Ep:65, loss:0.00003, loss_test:0.14327, lr:7.62e-03, fs:0.59310 (r=0.434,p=0.935),  time:74.208, tt:4897.696\n",
      "Ep:66, loss:0.00003, loss_test:0.14256, lr:7.55e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.215, tt:4972.403\n",
      "Ep:67, loss:0.00003, loss_test:0.13978, lr:7.47e-03, fs:0.68790 (r=0.545,p=0.931),  time:74.227, tt:5047.410\n",
      "Ep:68, loss:0.00003, loss_test:0.13477, lr:7.40e-03, fs:0.67081 (r=0.545,p=0.871),  time:74.238, tt:5122.431\n",
      "Ep:69, loss:0.00003, loss_test:0.13798, lr:7.32e-03, fs:0.68354 (r=0.545,p=0.915),  time:74.286, tt:5199.990\n",
      "Ep:70, loss:0.00003, loss_test:0.14248, lr:7.25e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.326, tt:5277.157\n",
      "Ep:71, loss:0.00003, loss_test:0.14161, lr:7.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.366, tt:5354.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00003, loss_test:0.14489, lr:7.11e-03, fs:0.59722 (r=0.434,p=0.956),  time:74.367, tt:5428.769\n",
      "Ep:73, loss:0.00003, loss_test:0.14025, lr:7.03e-03, fs:0.68354 (r=0.545,p=0.915),  time:74.392, tt:5504.991\n",
      "Ep:74, loss:0.00003, loss_test:0.14159, lr:6.96e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.407, tt:5580.518\n",
      "Ep:75, loss:0.00003, loss_test:0.14130, lr:6.89e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.422, tt:5656.061\n",
      "Ep:76, loss:0.00003, loss_test:0.14131, lr:6.83e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.415, tt:5729.976\n",
      "Ep:77, loss:0.00002, loss_test:0.13896, lr:6.76e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.422, tt:5804.904\n",
      "Ep:78, loss:0.00002, loss_test:0.14108, lr:6.69e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.458, tt:5882.163\n",
      "Ep:79, loss:0.00002, loss_test:0.13794, lr:6.62e-03, fs:0.67949 (r=0.535,p=0.930),  time:74.464, tt:5957.086\n",
      "Ep:80, loss:0.00002, loss_test:0.14028, lr:6.56e-03, fs:0.68354 (r=0.545,p=0.915),  time:74.440, tt:6029.657\n",
      "Ep:81, loss:0.00002, loss_test:0.13834, lr:6.49e-03, fs:0.68790 (r=0.545,p=0.931),  time:74.513, tt:6110.089\n",
      "Ep:82, loss:0.00002, loss_test:0.13864, lr:6.43e-03, fs:0.68354 (r=0.545,p=0.915),  time:74.487, tt:6182.452\n",
      "Ep:83, loss:0.00002, loss_test:0.14561, lr:6.36e-03, fs:0.61644 (r=0.455,p=0.957),  time:74.517, tt:6259.411\n",
      "Ep:84, loss:0.00002, loss_test:0.14181, lr:6.30e-03, fs:0.68831 (r=0.535,p=0.964),  time:74.534, tt:6335.410\n",
      "Ep:85, loss:0.00002, loss_test:0.14471, lr:6.24e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.540, tt:6410.406\n",
      "Ep:86, loss:0.00002, loss_test:0.14207, lr:6.17e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.517, tt:6482.989\n",
      "Ep:87, loss:0.00002, loss_test:0.14289, lr:6.11e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.530, tt:6558.625\n",
      "Ep:88, loss:0.00002, loss_test:0.14254, lr:6.05e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.539, tt:6633.988\n",
      "Ep:89, loss:0.00002, loss_test:0.14051, lr:5.99e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.523, tt:6707.063\n",
      "Ep:90, loss:0.00002, loss_test:0.14111, lr:5.93e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.538, tt:6782.923\n",
      "Ep:91, loss:0.00002, loss_test:0.13981, lr:5.87e-03, fs:0.68790 (r=0.545,p=0.931),  time:74.543, tt:6857.915\n",
      "Ep:92, loss:0.00002, loss_test:0.14229, lr:5.81e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.588, tt:6936.662\n",
      "Ep:93, loss:0.00002, loss_test:0.14185, lr:5.75e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.618, tt:7014.084\n",
      "Ep:94, loss:0.00002, loss_test:0.14340, lr:5.70e-03, fs:0.67974 (r=0.525,p=0.963),  time:74.594, tt:7086.443\n",
      "Ep:95, loss:0.00002, loss_test:0.14757, lr:5.64e-03, fs:0.59722 (r=0.434,p=0.956),  time:74.585, tt:7160.194\n",
      "Ep:96, loss:0.00002, loss_test:0.14316, lr:5.58e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.575, tt:7233.732\n",
      "Ep:97, loss:0.00002, loss_test:0.14039, lr:5.53e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.582, tt:7308.996\n",
      "Ep:98, loss:0.00002, loss_test:0.14100, lr:5.47e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.589, tt:7384.312\n",
      "Ep:99, loss:0.00002, loss_test:0.14466, lr:5.42e-03, fs:0.68831 (r=0.535,p=0.964),  time:74.572, tt:7457.227\n",
      "Ep:100, loss:0.00002, loss_test:0.14451, lr:5.36e-03, fs:0.61644 (r=0.455,p=0.957),  time:74.563, tt:7530.823\n",
      "Ep:101, loss:0.00002, loss_test:0.13989, lr:5.31e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.535, tt:7602.588\n",
      "Ep:102, loss:0.00002, loss_test:0.14021, lr:5.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.553, tt:7678.995\n",
      "Ep:103, loss:0.00002, loss_test:0.14475, lr:5.20e-03, fs:0.65772 (r=0.495,p=0.980),  time:74.551, tt:7753.330\n",
      "Ep:104, loss:0.00002, loss_test:0.14248, lr:5.15e-03, fs:0.69677 (r=0.545,p=0.964),  time:74.549, tt:7827.638\n",
      "Ep:105, loss:0.00002, loss_test:0.13969, lr:5.10e-03, fs:0.68831 (r=0.535,p=0.964),  time:74.544, tt:7901.682\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02804, lr:6.00e-02, fs:0.59459 (r=0.667,p=0.537),  time:10.702, tt:10.702\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02469, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:11.328, tt:22.657\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02675, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:12.921, tt:38.764\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02710, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:15.509, tt:62.035\n",
      "Ep:4, loss:0.00005, loss_test:0.02683, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:17.885, tt:89.424\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02611, lr:6.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:20.155, tt:120.933\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02545, lr:6.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:22.214, tt:155.501\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02496, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:23.664, tt:189.314\n",
      "Ep:8, loss:0.00005, loss_test:0.02424, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:24.700, tt:222.296\n",
      "Ep:9, loss:0.00005, loss_test:0.02330, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:25.751, tt:257.512\n",
      "Ep:10, loss:0.00005, loss_test:0.02234, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:26.519, tt:291.706\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02138, lr:6.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:27.201, tt:326.409\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02060, lr:6.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:27.827, tt:361.752\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02002, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:28.275, tt:395.848\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01948, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:28.664, tt:429.964\n",
      "Ep:15, loss:0.00004, loss_test:0.01904, lr:6.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:28.996, tt:463.942\n",
      "Ep:16, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:29.226, tt:496.846\n",
      "Ep:17, loss:0.00004, loss_test:0.01842, lr:6.00e-02, fs:0.71318 (r=0.929,p=0.579),  time:29.445, tt:530.001\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01824, lr:6.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:29.701, tt:564.325\n",
      "Ep:19, loss:0.00004, loss_test:0.01804, lr:6.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:29.889, tt:597.782\n",
      "Ep:20, loss:0.00004, loss_test:0.01778, lr:6.00e-02, fs:0.70769 (r=0.929,p=0.571),  time:30.057, tt:631.205\n",
      "Ep:21, loss:0.00004, loss_test:0.01755, lr:6.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:30.218, tt:664.793\n",
      "Ep:22, loss:0.00004, loss_test:0.01729, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:30.388, tt:698.917\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:30.550, tt:733.193\n",
      "Ep:24, loss:0.00003, loss_test:0.01687, lr:6.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:30.654, tt:766.339\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:30.767, tt:799.943\n",
      "Ep:26, loss:0.00003, loss_test:0.01666, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:30.855, tt:833.086\n",
      "Ep:27, loss:0.00003, loss_test:0.01657, lr:6.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:30.994, tt:867.826\n",
      "Ep:28, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:31.134, tt:902.886\n",
      "Ep:29, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:31.224, tt:936.734\n",
      "Ep:30, loss:0.00003, loss_test:0.01583, lr:6.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:31.279, tt:969.646\n",
      "Ep:31, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:31.451, tt:1006.418\n",
      "Ep:32, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:31.504, tt:1039.647\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01530, lr:6.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:31.572, tt:1073.445\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:31.664, tt:1108.229\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:31.708, tt:1141.472\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:31.763, tt:1175.246\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:31.850, tt:1210.290\n",
      "Ep:38, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:31.867, tt:1242.822\n",
      "Ep:39, loss:0.00002, loss_test:0.01493, lr:6.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:31.897, tt:1275.880\n",
      "Ep:40, loss:0.00002, loss_test:0.01476, lr:6.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:31.989, tt:1311.561\n",
      "Ep:41, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:32.023, tt:1344.966\n",
      "Ep:42, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:32.035, tt:1377.526\n",
      "Ep:43, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:32.098, tt:1412.292\n",
      "Ep:44, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:32.149, tt:1446.695\n",
      "Ep:45, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:32.208, tt:1481.569\n",
      "Ep:46, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:32.259, tt:1516.151\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01460, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:32.299, tt:1550.365\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01536, lr:6.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:32.364, tt:1585.812\n",
      "Ep:49, loss:0.00001, loss_test:0.01466, lr:6.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:32.430, tt:1621.509\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:32.484, tt:1656.678\n",
      "Ep:51, loss:0.00001, loss_test:0.01545, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:32.523, tt:1691.205\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01486, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:32.532, tt:1724.180\n",
      "Ep:53, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:32.542, tt:1757.246\n",
      "Ep:54, loss:0.00001, loss_test:0.01598, lr:6.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:32.557, tt:1790.628\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01475, lr:6.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:32.588, tt:1824.915\n",
      "Ep:56, loss:0.00001, loss_test:0.01423, lr:6.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:32.626, tt:1859.655\n",
      "Ep:57, loss:0.00001, loss_test:0.01498, lr:6.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:32.646, tt:1893.475\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01436, lr:6.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:32.646, tt:1926.088\n",
      "Ep:59, loss:0.00001, loss_test:0.01521, lr:6.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:32.660, tt:1959.593\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01485, lr:6.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:32.705, tt:1994.979\n",
      "Ep:61, loss:0.00001, loss_test:0.01684, lr:6.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:32.723, tt:2028.815\n",
      "Ep:62, loss:0.00001, loss_test:0.01412, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:32.749, tt:2063.175\n",
      "Ep:63, loss:0.00001, loss_test:0.01487, lr:6.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:32.768, tt:2097.167\n",
      "Ep:64, loss:0.00001, loss_test:0.01355, lr:6.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:32.783, tt:2130.912\n",
      "Ep:65, loss:0.00001, loss_test:0.01394, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:32.797, tt:2164.608\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01586, lr:6.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:32.824, tt:2199.199\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01360, lr:6.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:32.830, tt:2232.429\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:32.851, tt:2266.692\n",
      "Ep:69, loss:0.00001, loss_test:0.01439, lr:6.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:32.872, tt:2301.063\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01444, lr:6.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:32.903, tt:2336.116\n",
      "Ep:71, loss:0.00001, loss_test:0.01535, lr:6.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:32.929, tt:2370.894\n",
      "Ep:72, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:32.954, tt:2405.674\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01511, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:32.978, tt:2440.400\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01501, lr:6.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:33.002, tt:2475.177\n",
      "Ep:75, loss:0.00001, loss_test:0.01527, lr:6.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:33.039, tt:2510.943\n",
      "Ep:76, loss:0.00001, loss_test:0.01573, lr:6.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:33.055, tt:2545.269\n",
      "Ep:77, loss:0.00001, loss_test:0.01592, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:33.068, tt:2579.305\n",
      "Ep:78, loss:0.00001, loss_test:0.01472, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:33.095, tt:2614.533\n",
      "Ep:79, loss:0.00001, loss_test:0.01521, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:33.101, tt:2648.116\n",
      "Ep:80, loss:0.00001, loss_test:0.01563, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:33.112, tt:2682.085\n",
      "Ep:81, loss:0.00001, loss_test:0.01517, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:33.128, tt:2716.494\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01398, lr:6.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:33.135, tt:2750.168\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01621, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:33.148, tt:2784.398\n",
      "Ep:84, loss:0.00001, loss_test:0.01523, lr:6.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:33.152, tt:2817.948\n",
      "Ep:85, loss:0.00000, loss_test:0.01566, lr:6.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:33.162, tt:2851.973\n",
      "Ep:86, loss:0.00001, loss_test:0.01550, lr:6.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:33.175, tt:2886.213\n",
      "Ep:87, loss:0.00000, loss_test:0.01637, lr:6.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:33.193, tt:2921.005\n",
      "Ep:88, loss:0.00000, loss_test:0.01598, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:33.209, tt:2955.645\n",
      "Ep:89, loss:0.00000, loss_test:0.01635, lr:6.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:33.238, tt:2991.429\n",
      "Ep:90, loss:0.00000, loss_test:0.01423, lr:6.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:33.259, tt:3026.541\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00000, loss_test:0.01611, lr:6.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:33.275, tt:3061.334\n",
      "Ep:92, loss:0.00000, loss_test:0.01566, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:33.269, tt:3094.062\n",
      "Ep:93, loss:0.00000, loss_test:0.01709, lr:6.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:33.287, tt:3129.010\n",
      "Ep:94, loss:0.00001, loss_test:0.01534, lr:6.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:33.305, tt:3163.950\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00000, loss_test:0.01413, lr:6.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:33.317, tt:3198.413\n",
      "Ep:96, loss:0.00000, loss_test:0.01511, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:33.335, tt:3233.501\n",
      "Ep:97, loss:0.00000, loss_test:0.01549, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:33.348, tt:3268.081\n",
      "Ep:98, loss:0.00000, loss_test:0.01358, lr:6.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:33.363, tt:3302.965\n",
      "Ep:99, loss:0.00000, loss_test:0.01782, lr:6.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:33.374, tt:3337.450\n",
      "Ep:100, loss:0.00001, loss_test:0.01162, lr:6.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:33.391, tt:3372.440\n",
      "Ep:101, loss:0.00001, loss_test:0.01435, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:33.395, tt:3406.318\n",
      "Ep:102, loss:0.00001, loss_test:0.01337, lr:6.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:33.391, tt:3439.235\n",
      "Ep:103, loss:0.00001, loss_test:0.01250, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:33.390, tt:3472.523\n",
      "Ep:104, loss:0.00000, loss_test:0.01662, lr:6.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:33.390, tt:3505.976\n",
      "Ep:105, loss:0.00000, loss_test:0.01407, lr:6.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:33.387, tt:3539.030\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00000, loss_test:0.01345, lr:6.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:33.397, tt:3573.502\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00000, loss_test:0.01557, lr:6.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:33.403, tt:3607.552\n",
      "Ep:108, loss:0.00000, loss_test:0.01410, lr:6.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:33.410, tt:3641.641\n",
      "Ep:109, loss:0.00000, loss_test:0.01671, lr:6.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:33.408, tt:3674.884\n",
      "Ep:110, loss:0.00000, loss_test:0.01478, lr:6.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:33.400, tt:3707.454\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.01574, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.413, tt:3742.244\n",
      "Ep:112, loss:0.00000, loss_test:0.01688, lr:6.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.421, tt:3776.571\n",
      "Ep:113, loss:0.00000, loss_test:0.01492, lr:6.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:33.428, tt:3810.823\n",
      "Ep:114, loss:0.00000, loss_test:0.01720, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.444, tt:3846.020\n",
      "Ep:115, loss:0.00000, loss_test:0.01539, lr:6.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:33.453, tt:3880.604\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00000, loss_test:0.01706, lr:6.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:33.462, tt:3915.030\n",
      "Ep:117, loss:0.00000, loss_test:0.01583, lr:6.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:33.464, tt:3948.740\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00000, loss_test:0.01663, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.469, tt:3982.850\n",
      "Ep:119, loss:0.00000, loss_test:0.01767, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.475, tt:4017.043\n",
      "Ep:120, loss:0.00000, loss_test:0.01624, lr:6.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:33.473, tt:4050.180\n",
      "Ep:121, loss:0.00000, loss_test:0.01759, lr:6.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.466, tt:4082.912\n",
      "Ep:122, loss:0.00000, loss_test:0.01681, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.468, tt:4116.626\n",
      "Ep:123, loss:0.00000, loss_test:0.01705, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.479, tt:4151.338\n",
      "Ep:124, loss:0.00000, loss_test:0.01758, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.486, tt:4185.746\n",
      "Ep:125, loss:0.00000, loss_test:0.01805, lr:6.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.494, tt:4220.292\n",
      "Ep:126, loss:0.00000, loss_test:0.01650, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.490, tt:4253.205\n",
      "Ep:127, loss:0.00000, loss_test:0.01812, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.496, tt:4287.516\n",
      "Ep:128, loss:0.00000, loss_test:0.01686, lr:6.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.501, tt:4321.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00000, loss_test:0.01764, lr:5.94e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.512, tt:4356.612\n",
      "Ep:130, loss:0.00000, loss_test:0.01871, lr:5.88e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.517, tt:4390.768\n",
      "Ep:131, loss:0.00000, loss_test:0.01758, lr:5.82e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.540, tt:4427.306\n",
      "Ep:132, loss:0.00000, loss_test:0.01770, lr:5.76e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.543, tt:4461.217\n",
      "Ep:133, loss:0.00000, loss_test:0.01807, lr:5.71e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.537, tt:4493.912\n",
      "Ep:134, loss:0.00000, loss_test:0.01823, lr:5.65e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.566, tt:4531.353\n",
      "Ep:135, loss:0.00000, loss_test:0.01826, lr:5.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.582, tt:4567.127\n",
      "Ep:136, loss:0.00000, loss_test:0.01820, lr:5.54e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.596, tt:4602.604\n",
      "Ep:137, loss:0.00000, loss_test:0.01805, lr:5.48e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.594, tt:4635.947\n",
      "Ep:138, loss:0.00000, loss_test:0.01888, lr:5.43e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.594, tt:4669.571\n",
      "Ep:139, loss:0.00000, loss_test:0.01845, lr:5.37e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.594, tt:4703.098\n",
      "Ep:140, loss:0.00000, loss_test:0.01794, lr:5.32e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.601, tt:4737.762\n",
      "Ep:141, loss:0.00000, loss_test:0.01886, lr:5.27e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.608, tt:4772.286\n",
      "Ep:142, loss:0.00000, loss_test:0.01840, lr:5.21e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.614, tt:4806.778\n",
      "Ep:143, loss:0.00000, loss_test:0.01857, lr:5.16e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.628, tt:4842.498\n",
      "Ep:144, loss:0.00000, loss_test:0.01878, lr:5.11e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.632, tt:4876.630\n",
      "Ep:145, loss:0.00000, loss_test:0.01861, lr:5.06e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.631, tt:4910.139\n",
      "Ep:146, loss:0.00000, loss_test:0.01879, lr:5.01e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.633, tt:4944.029\n",
      "Ep:147, loss:0.00000, loss_test:0.01873, lr:4.96e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.634, tt:4977.797\n",
      "Ep:148, loss:0.00000, loss_test:0.01900, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.629, tt:5010.704\n",
      "Ep:149, loss:0.00000, loss_test:0.01921, lr:4.86e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.625, tt:5043.719\n",
      "Ep:150, loss:0.00000, loss_test:0.01873, lr:4.81e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.628, tt:5077.827\n",
      "Ep:151, loss:0.00000, loss_test:0.01940, lr:4.76e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.622, tt:5110.534\n",
      "Ep:152, loss:0.00000, loss_test:0.01912, lr:4.71e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.614, tt:5142.960\n",
      "Ep:153, loss:0.00000, loss_test:0.01924, lr:4.67e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.605, tt:5175.240\n",
      "Ep:154, loss:0.00000, loss_test:0.01942, lr:4.62e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.606, tt:5208.870\n",
      "Ep:155, loss:0.00000, loss_test:0.01908, lr:4.57e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.606, tt:5242.575\n",
      "Ep:156, loss:0.00000, loss_test:0.01958, lr:4.53e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.608, tt:5276.511\n",
      "Ep:157, loss:0.00000, loss_test:0.01946, lr:4.48e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.609, tt:5310.165\n",
      "Ep:158, loss:0.00000, loss_test:0.01949, lr:4.44e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.608, tt:5343.620\n",
      "Ep:159, loss:0.00000, loss_test:0.01981, lr:4.39e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.607, tt:5377.066\n",
      "Ep:160, loss:0.00000, loss_test:0.01946, lr:4.35e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.606, tt:5410.522\n",
      "Ep:161, loss:0.00000, loss_test:0.01961, lr:4.31e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.604, tt:5443.792\n",
      "Ep:162, loss:0.00000, loss_test:0.01975, lr:4.26e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.607, tt:5477.989\n",
      "Ep:163, loss:0.00000, loss_test:0.01987, lr:4.22e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.612, tt:5512.308\n",
      "Ep:164, loss:0.00000, loss_test:0.01964, lr:4.18e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.616, tt:5546.582\n",
      "Ep:165, loss:0.00000, loss_test:0.01991, lr:4.14e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.616, tt:5580.295\n",
      "Ep:166, loss:0.00000, loss_test:0.01994, lr:4.10e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.618, tt:5614.204\n",
      "Ep:167, loss:0.00000, loss_test:0.01953, lr:4.05e-02, fs:0.86957 (r=0.808,p=0.941),  time:33.619, tt:5647.973\n",
      "Ep:168, loss:0.00000, loss_test:0.02009, lr:4.01e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.623, tt:5682.237\n",
      "Ep:169, loss:0.00000, loss_test:0.01973, lr:3.97e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.622, tt:5715.690\n",
      "Ep:170, loss:0.00000, loss_test:0.02001, lr:3.93e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.627, tt:5750.252\n",
      "Ep:171, loss:0.00000, loss_test:0.01999, lr:3.89e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.637, tt:5785.610\n",
      "Ep:172, loss:0.00000, loss_test:0.01978, lr:3.86e-02, fs:0.86957 (r=0.808,p=0.941),  time:33.642, tt:5820.089\n",
      "Ep:173, loss:0.00000, loss_test:0.02025, lr:3.82e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.635, tt:5852.533\n",
      "Ep:174, loss:0.00000, loss_test:0.01997, lr:3.78e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.642, tt:5887.345\n",
      "Ep:175, loss:0.00000, loss_test:0.02020, lr:3.74e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.641, tt:5920.840\n",
      "Ep:176, loss:0.00000, loss_test:0.02016, lr:3.70e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.640, tt:5954.244\n",
      "Ep:177, loss:0.00000, loss_test:0.02022, lr:3.67e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.642, tt:5988.239\n",
      "Ep:178, loss:0.00000, loss_test:0.02025, lr:3.63e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.635, tt:6020.604\n",
      "Ep:179, loss:0.00000, loss_test:0.02025, lr:3.59e-02, fs:0.86957 (r=0.808,p=0.941),  time:33.631, tt:6053.500\n",
      "Ep:180, loss:0.00000, loss_test:0.02027, lr:3.56e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.638, tt:6088.532\n",
      "Ep:181, loss:0.00000, loss_test:0.02029, lr:3.52e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.642, tt:6122.812\n",
      "Ep:182, loss:0.00000, loss_test:0.02037, lr:3.49e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.645, tt:6157.108\n",
      "Ep:183, loss:0.00000, loss_test:0.02032, lr:3.45e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.640, tt:6189.795\n",
      "Ep:184, loss:0.00000, loss_test:0.02040, lr:3.42e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.637, tt:6222.775\n",
      "Ep:185, loss:0.00000, loss_test:0.02057, lr:3.38e-02, fs:0.85083 (r=0.778,p=0.939),  time:33.645, tt:6258.046\n",
      "Ep:186, loss:0.00000, loss_test:0.02028, lr:3.35e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.642, tt:6291.134\n",
      "Ep:187, loss:0.00000, loss_test:0.02078, lr:3.32e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.636, tt:6323.604\n",
      "Ep:188, loss:0.00000, loss_test:0.02026, lr:3.28e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.633, tt:6356.566\n",
      "Ep:189, loss:0.00000, loss_test:0.02073, lr:3.25e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.638, tt:6391.195\n",
      "Ep:190, loss:0.00000, loss_test:0.02034, lr:3.22e-02, fs:0.86339 (r=0.798,p=0.940),  time:33.643, tt:6425.847\n",
      "Ep:191, loss:0.00000, loss_test:0.02087, lr:3.19e-02, fs:0.84916 (r=0.768,p=0.950),  time:33.648, tt:6460.434\n",
      "Ep:192, loss:0.00000, loss_test:0.02042, lr:3.15e-02, fs:0.86813 (r=0.798,p=0.952),  time:33.646, tt:6493.769\n",
      "Ep:193, loss:0.00000, loss_test:0.02071, lr:3.12e-02, fs:0.85556 (r=0.778,p=0.951),  time:33.653, tt:6528.768\n",
      "Ep:194, loss:0.00000, loss_test:0.02070, lr:3.09e-02, fs:0.85714 (r=0.788,p=0.940),  time:33.658, tt:6563.354\n",
      "Ep:195, loss:0.00000, loss_test:0.02070, lr:3.06e-02, fs:0.86188 (r=0.788,p=0.951),  time:33.655, tt:6596.337\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02107, lr:6.00e-02, fs:0.62979 (r=0.747,p=0.544),  time:28.104, tt:28.104\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02171, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:26.093, tt:52.186\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02367, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.390, tt:76.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00005, loss_test:0.02397, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.331, tt:105.323\n",
      "Ep:4, loss:0.00005, loss_test:0.02331, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.122, tt:130.611\n",
      "Ep:5, loss:0.00004, loss_test:0.02202, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.906, tt:161.433\n",
      "Ep:6, loss:0.00004, loss_test:0.02055, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:27.205, tt:190.432\n",
      "Ep:7, loss:0.00004, loss_test:0.01934, lr:6.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:27.767, tt:222.135\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01861, lr:6.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:28.216, tt:253.945\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01838, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:28.425, tt:284.250\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01831, lr:6.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:28.651, tt:315.159\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01793, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:28.911, tt:346.928\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:29.079, tt:378.024\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01696, lr:6.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:29.226, tt:409.162\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01674, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:29.300, tt:439.494\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:29.374, tt:469.982\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01640, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:29.546, tt:502.275\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:29.532, tt:531.570\n",
      "Ep:18, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:29.647, tt:563.286\n",
      "Ep:19, loss:0.00003, loss_test:0.01604, lr:6.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:29.722, tt:594.432\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01597, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:29.829, tt:626.410\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:29.971, tt:659.367\n",
      "Ep:22, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:30.085, tt:691.954\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01573, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:30.148, tt:723.552\n",
      "Ep:24, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:30.252, tt:756.303\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:30.303, tt:787.867\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:30.359, tt:819.691\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.362, tt:850.123\n",
      "Ep:28, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:30.380, tt:881.017\n",
      "Ep:29, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:30.421, tt:912.624\n",
      "Ep:30, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:30.443, tt:943.731\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01551, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:30.462, tt:974.776\n",
      "Ep:32, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:30.465, tt:1005.358\n",
      "Ep:33, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:30.427, tt:1034.513\n",
      "Ep:34, loss:0.00002, loss_test:0.01545, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:30.456, tt:1065.973\n",
      "Ep:35, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:30.434, tt:1095.619\n",
      "Ep:36, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:30.478, tt:1127.694\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:30.486, tt:1158.477\n",
      "Ep:38, loss:0.00002, loss_test:0.01530, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:30.492, tt:1189.185\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.440, tt:1217.588\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01525, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.509, tt:1250.884\n",
      "Ep:41, loss:0.00002, loss_test:0.01521, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.512, tt:1281.513\n",
      "Ep:42, loss:0.00002, loss_test:0.01520, lr:6.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:30.504, tt:1311.692\n",
      "Ep:43, loss:0.00002, loss_test:0.01520, lr:6.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:30.517, tt:1342.752\n",
      "Ep:44, loss:0.00002, loss_test:0.01524, lr:6.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:30.513, tt:1373.079\n",
      "Ep:45, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:30.500, tt:1403.003\n",
      "Ep:46, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:30.494, tt:1433.234\n",
      "Ep:47, loss:0.00002, loss_test:0.01518, lr:6.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:30.515, tt:1464.708\n",
      "Ep:48, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.501, tt:1494.526\n",
      "Ep:49, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:30.496, tt:1524.806\n",
      "Ep:50, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.489, tt:1554.956\n",
      "Ep:51, loss:0.00002, loss_test:0.01514, lr:5.94e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.492, tt:1585.559\n",
      "Ep:52, loss:0.00002, loss_test:0.01517, lr:5.88e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.509, tt:1616.970\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01514, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.502, tt:1647.127\n",
      "Ep:54, loss:0.00002, loss_test:0.01509, lr:5.88e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.501, tt:1677.550\n",
      "Ep:55, loss:0.00002, loss_test:0.01508, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.506, tt:1708.309\n",
      "Ep:56, loss:0.00002, loss_test:0.01509, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.515, tt:1739.365\n",
      "Ep:57, loss:0.00002, loss_test:0.01508, lr:5.88e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.503, tt:1769.146\n",
      "Ep:58, loss:0.00002, loss_test:0.01504, lr:5.88e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.490, tt:1798.894\n",
      "Ep:59, loss:0.00002, loss_test:0.01503, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.478, tt:1828.692\n",
      "Ep:60, loss:0.00002, loss_test:0.01502, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.473, tt:1858.864\n",
      "Ep:61, loss:0.00001, loss_test:0.01500, lr:5.88e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.469, tt:1889.094\n",
      "Ep:62, loss:0.00001, loss_test:0.01502, lr:5.88e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.508, tt:1921.992\n",
      "Ep:63, loss:0.00001, loss_test:0.01502, lr:5.88e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.494, tt:1951.597\n",
      "Ep:64, loss:0.00001, loss_test:0.01506, lr:5.82e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.489, tt:1981.781\n",
      "Ep:65, loss:0.00001, loss_test:0.01507, lr:5.76e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.493, tt:2012.524\n",
      "Ep:66, loss:0.00001, loss_test:0.01503, lr:5.71e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.507, tt:2043.939\n",
      "Ep:67, loss:0.00001, loss_test:0.01498, lr:5.65e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.510, tt:2074.682\n",
      "Ep:68, loss:0.00001, loss_test:0.01496, lr:5.59e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.502, tt:2104.605\n",
      "Ep:69, loss:0.00001, loss_test:0.01495, lr:5.54e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.485, tt:2133.976\n",
      "Ep:70, loss:0.00001, loss_test:0.01494, lr:5.48e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.493, tt:2165.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.01496, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.510, tt:2196.708\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01496, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.509, tt:2227.163\n",
      "Ep:73, loss:0.00001, loss_test:0.01493, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.504, tt:2257.309\n",
      "Ep:74, loss:0.00001, loss_test:0.01495, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.497, tt:2287.282\n",
      "Ep:75, loss:0.00001, loss_test:0.01496, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.495, tt:2317.630\n",
      "Ep:76, loss:0.00001, loss_test:0.01498, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.509, tt:2349.209\n",
      "Ep:77, loss:0.00001, loss_test:0.01493, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.517, tt:2380.292\n",
      "Ep:78, loss:0.00001, loss_test:0.01493, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.496, tt:2409.219\n",
      "Ep:79, loss:0.00001, loss_test:0.01493, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.496, tt:2439.656\n",
      "Ep:80, loss:0.00001, loss_test:0.01490, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.506, tt:2471.026\n",
      "Ep:81, loss:0.00001, loss_test:0.01489, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.522, tt:2502.808\n",
      "Ep:82, loss:0.00001, loss_test:0.01487, lr:5.43e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.515, tt:2532.711\n",
      "Ep:83, loss:0.00001, loss_test:0.01487, lr:5.37e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.518, tt:2563.523\n",
      "Ep:84, loss:0.00001, loss_test:0.01485, lr:5.32e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.526, tt:2594.670\n",
      "Ep:85, loss:0.00001, loss_test:0.01484, lr:5.27e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.528, tt:2625.378\n",
      "Ep:86, loss:0.00001, loss_test:0.01482, lr:5.21e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.538, tt:2656.840\n",
      "Ep:87, loss:0.00001, loss_test:0.01484, lr:5.16e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.527, tt:2686.357\n",
      "Ep:88, loss:0.00001, loss_test:0.01484, lr:5.11e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.520, tt:2716.283\n",
      "Ep:89, loss:0.00001, loss_test:0.01483, lr:5.06e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.515, tt:2746.314\n",
      "Ep:90, loss:0.00001, loss_test:0.01482, lr:5.01e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.529, tt:2778.130\n",
      "Ep:91, loss:0.00001, loss_test:0.01482, lr:4.96e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.519, tt:2807.712\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01482, lr:4.96e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.501, tt:2836.562\n",
      "Ep:93, loss:0.00001, loss_test:0.01478, lr:4.96e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.522, tt:2869.111\n",
      "Ep:94, loss:0.00001, loss_test:0.01481, lr:4.96e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.523, tt:2899.709\n",
      "Ep:95, loss:0.00001, loss_test:0.01482, lr:4.96e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.527, tt:2930.548\n",
      "Ep:96, loss:0.00001, loss_test:0.01481, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.517, tt:2960.151\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01481, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.522, tt:2991.133\n",
      "Ep:98, loss:0.00001, loss_test:0.01483, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.514, tt:3020.904\n",
      "Ep:99, loss:0.00001, loss_test:0.01487, lr:4.96e-02, fs:0.80423 (r=0.768,p=0.844),  time:30.513, tt:3051.323\n",
      "Ep:100, loss:0.00001, loss_test:0.01482, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.530, tt:3083.555\n",
      "Ep:101, loss:0.00001, loss_test:0.01482, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.543, tt:3115.369\n",
      "Ep:102, loss:0.00001, loss_test:0.01484, lr:4.96e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.542, tt:3145.811\n",
      "Ep:103, loss:0.00001, loss_test:0.01479, lr:4.96e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.545, tt:3176.697\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.01481, lr:4.96e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.546, tt:3207.307\n",
      "Ep:105, loss:0.00001, loss_test:0.01484, lr:4.96e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.540, tt:3237.267\n",
      "Ep:106, loss:0.00001, loss_test:0.01483, lr:4.96e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.526, tt:3266.326\n",
      "Ep:107, loss:0.00001, loss_test:0.01485, lr:4.96e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.532, tt:3297.404\n",
      "Ep:108, loss:0.00001, loss_test:0.01487, lr:4.96e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.536, tt:3328.471\n",
      "Ep:109, loss:0.00001, loss_test:0.01488, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.535, tt:3358.896\n",
      "Ep:110, loss:0.00001, loss_test:0.01486, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.539, tt:3389.825\n",
      "Ep:111, loss:0.00001, loss_test:0.01487, lr:4.96e-02, fs:0.80423 (r=0.768,p=0.844),  time:30.558, tt:3422.494\n",
      "Ep:112, loss:0.00001, loss_test:0.01489, lr:4.96e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.554, tt:3452.567\n",
      "Ep:113, loss:0.00001, loss_test:0.01486, lr:4.96e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.544, tt:3482.050\n",
      "Ep:114, loss:0.00001, loss_test:0.01490, lr:4.96e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.540, tt:3512.059\n",
      "Ep:115, loss:0.00001, loss_test:0.01492, lr:4.91e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.542, tt:3542.925\n",
      "Ep:116, loss:0.00001, loss_test:0.01489, lr:4.86e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.544, tt:3573.618\n",
      "Ep:117, loss:0.00001, loss_test:0.01489, lr:4.81e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.542, tt:3603.911\n",
      "Ep:118, loss:0.00001, loss_test:0.01492, lr:4.76e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.537, tt:3633.882\n",
      "Ep:119, loss:0.00001, loss_test:0.01492, lr:4.71e-02, fs:0.81283 (r=0.768,p=0.864),  time:30.541, tt:3664.942\n",
      "Ep:120, loss:0.00001, loss_test:0.01491, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.533, tt:3694.516\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.01493, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.522, tt:3723.679\n",
      "Ep:122, loss:0.00001, loss_test:0.01496, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.515, tt:3753.366\n",
      "Ep:123, loss:0.00001, loss_test:0.01497, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.508, tt:3783.029\n",
      "Ep:124, loss:0.00001, loss_test:0.01498, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.507, tt:3813.388\n",
      "Ep:125, loss:0.00001, loss_test:0.01499, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.507, tt:3843.898\n",
      "Ep:126, loss:0.00001, loss_test:0.01500, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.501, tt:3873.688\n",
      "Ep:127, loss:0.00001, loss_test:0.01497, lr:4.67e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.502, tt:3904.220\n",
      "Ep:128, loss:0.00001, loss_test:0.01499, lr:4.67e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.492, tt:3933.530\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.01502, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.489, tt:3963.603\n",
      "Ep:130, loss:0.00001, loss_test:0.01503, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.473, tt:3991.980\n",
      "Ep:131, loss:0.00001, loss_test:0.01504, lr:4.67e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.466, tt:4021.476\n",
      "Ep:132, loss:0.00001, loss_test:0.01506, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.464, tt:4051.686\n",
      "Ep:133, loss:0.00001, loss_test:0.01509, lr:4.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.461, tt:4081.789\n",
      "Ep:134, loss:0.00001, loss_test:0.01510, lr:4.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.457, tt:4111.713\n",
      "Ep:135, loss:0.00001, loss_test:0.01511, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.450, tt:4141.241\n",
      "Ep:136, loss:0.00001, loss_test:0.01510, lr:4.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.445, tt:4170.936\n",
      "Ep:137, loss:0.00001, loss_test:0.01511, lr:4.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.440, tt:4200.699\n",
      "Ep:138, loss:0.00001, loss_test:0.01511, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.437, tt:4230.721\n",
      "Ep:139, loss:0.00001, loss_test:0.01510, lr:4.67e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.432, tt:4260.412\n",
      "Ep:140, loss:0.00001, loss_test:0.01513, lr:4.62e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.418, tt:4288.976\n",
      "Ep:141, loss:0.00001, loss_test:0.01514, lr:4.57e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.409, tt:4318.139\n",
      "Ep:142, loss:0.00001, loss_test:0.01516, lr:4.53e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.407, tt:4348.203\n",
      "Ep:143, loss:0.00001, loss_test:0.01519, lr:4.48e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.409, tt:4378.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.01522, lr:4.44e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.405, tt:4408.794\n",
      "Ep:145, loss:0.00001, loss_test:0.01522, lr:4.39e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.391, tt:4437.144\n",
      "Ep:146, loss:0.00001, loss_test:0.01523, lr:4.35e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.387, tt:4466.895\n",
      "Ep:147, loss:0.00001, loss_test:0.01521, lr:4.31e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.390, tt:4497.742\n",
      "Ep:148, loss:0.00001, loss_test:0.01525, lr:4.26e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.391, tt:4528.260\n",
      "Ep:149, loss:0.00001, loss_test:0.01527, lr:4.22e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.384, tt:4557.531\n",
      "Ep:150, loss:0.00001, loss_test:0.01528, lr:4.18e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.380, tt:4587.330\n",
      "Ep:151, loss:0.00001, loss_test:0.01530, lr:4.14e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.376, tt:4617.129\n",
      "Ep:152, loss:0.00001, loss_test:0.01534, lr:4.10e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.362, tt:4645.368\n",
      "Ep:153, loss:0.00001, loss_test:0.01536, lr:4.05e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.356, tt:4674.765\n",
      "Ep:154, loss:0.00001, loss_test:0.01536, lr:4.01e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.351, tt:4704.352\n",
      "Ep:155, loss:0.00001, loss_test:0.01537, lr:3.97e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.340, tt:4733.103\n",
      "Ep:156, loss:0.00001, loss_test:0.01536, lr:3.93e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.332, tt:4762.086\n",
      "Ep:157, loss:0.00001, loss_test:0.01537, lr:3.89e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.320, tt:4790.593\n",
      "Ep:158, loss:0.00001, loss_test:0.01537, lr:3.86e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.318, tt:4820.488\n",
      "Ep:159, loss:0.00001, loss_test:0.01541, lr:3.82e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.310, tt:4849.632\n",
      "Ep:160, loss:0.00001, loss_test:0.01542, lr:3.78e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.307, tt:4879.380\n",
      "Ep:161, loss:0.00001, loss_test:0.01544, lr:3.74e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.309, tt:4909.991\n",
      "Ep:162, loss:0.00001, loss_test:0.01546, lr:3.70e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.314, tt:4941.206\n",
      "Ep:163, loss:0.00001, loss_test:0.01546, lr:3.67e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.310, tt:4970.833\n",
      "Ep:164, loss:0.00001, loss_test:0.01546, lr:3.63e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.303, tt:4999.921\n",
      "Ep:165, loss:0.00001, loss_test:0.01549, lr:3.59e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.300, tt:5029.863\n",
      "Ep:166, loss:0.00001, loss_test:0.01552, lr:3.56e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.306, tt:5061.149\n",
      "Ep:167, loss:0.00001, loss_test:0.01553, lr:3.52e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.298, tt:5090.124\n",
      "Ep:168, loss:0.00001, loss_test:0.01555, lr:3.49e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.293, tt:5119.541\n",
      "Ep:169, loss:0.00001, loss_test:0.01555, lr:3.45e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.284, tt:5148.231\n",
      "Ep:170, loss:0.00001, loss_test:0.01555, lr:3.42e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.277, tt:5177.317\n",
      "Ep:171, loss:0.00001, loss_test:0.01557, lr:3.38e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.271, tt:5206.535\n",
      "Ep:172, loss:0.00001, loss_test:0.01558, lr:3.35e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.271, tt:5236.839\n",
      "Ep:173, loss:0.00001, loss_test:0.01560, lr:3.32e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.270, tt:5266.934\n",
      "Ep:174, loss:0.00001, loss_test:0.01563, lr:3.28e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.271, tt:5297.488\n",
      "Ep:175, loss:0.00001, loss_test:0.01565, lr:3.25e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.271, tt:5327.712\n",
      "Ep:176, loss:0.00001, loss_test:0.01564, lr:3.22e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.264, tt:5356.668\n",
      "Ep:177, loss:0.00001, loss_test:0.01567, lr:3.19e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.255, tt:5385.419\n",
      "Ep:178, loss:0.00000, loss_test:0.01569, lr:3.15e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.255, tt:5415.587\n",
      "Ep:179, loss:0.00000, loss_test:0.01570, lr:3.12e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.247, tt:5444.437\n",
      "Ep:180, loss:0.00000, loss_test:0.01570, lr:3.09e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.244, tt:5474.158\n",
      "Ep:181, loss:0.00000, loss_test:0.01570, lr:3.06e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.235, tt:5502.701\n",
      "Ep:182, loss:0.00000, loss_test:0.01572, lr:3.03e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.249, tt:5535.562\n",
      "Ep:183, loss:0.00000, loss_test:0.01572, lr:3.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.252, tt:5566.277\n",
      "Ep:184, loss:0.00000, loss_test:0.01574, lr:2.97e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.241, tt:5594.639\n",
      "Ep:185, loss:0.00000, loss_test:0.01575, lr:2.94e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.236, tt:5623.830\n",
      "Ep:186, loss:0.00000, loss_test:0.01577, lr:2.91e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.236, tt:5654.144\n",
      "Ep:187, loss:0.00000, loss_test:0.01580, lr:2.88e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.232, tt:5683.669\n",
      "Ep:188, loss:0.00000, loss_test:0.01582, lr:2.85e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.234, tt:5714.169\n",
      "Ep:189, loss:0.00000, loss_test:0.01583, lr:2.82e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.239, tt:5745.385\n",
      "Ep:190, loss:0.00000, loss_test:0.01586, lr:2.80e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.236, tt:5775.165\n",
      "Ep:191, loss:0.00000, loss_test:0.01586, lr:2.77e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.230, tt:5804.066\n",
      "Ep:192, loss:0.00000, loss_test:0.01587, lr:2.74e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.223, tt:5833.090\n",
      "Ep:193, loss:0.00000, loss_test:0.01589, lr:2.71e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.217, tt:5862.170\n",
      "Ep:194, loss:0.00000, loss_test:0.01592, lr:2.69e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.213, tt:5891.565\n",
      "Ep:195, loss:0.00000, loss_test:0.01593, lr:2.66e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.214, tt:5921.999\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02097, lr:6.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:36.965, tt:36.965\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02367, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.103, tt:62.206\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02469, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.376, tt:94.129\n",
      "Ep:3, loss:0.00005, loss_test:0.02403, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.035, tt:132.140\n",
      "Ep:4, loss:0.00004, loss_test:0.02258, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:33.731, tt:168.656\n",
      "Ep:5, loss:0.00004, loss_test:0.02107, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:34.438, tt:206.627\n",
      "Ep:6, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:35.055, tt:245.383\n",
      "Ep:7, loss:0.00004, loss_test:0.01971, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:35.589, tt:284.711\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:35.893, tt:323.033\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:36.007, tt:360.073\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:36.340, tt:399.740\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:36.467, tt:437.601\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01702, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:36.625, tt:476.122\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01677, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:36.849, tt:515.891\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:36.930, tt:553.951\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:37.242, tt:595.872\n",
      "Ep:16, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:37.243, tt:633.124\n",
      "Ep:17, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:37.385, tt:672.926\n",
      "Ep:18, loss:0.00003, loss_test:0.01605, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:37.480, tt:712.121\n",
      "Ep:19, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:37.594, tt:751.885\n",
      "Ep:20, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:37.718, tt:792.083\n",
      "Ep:21, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:37.803, tt:831.662\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01574, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:37.791, tt:869.198\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:37.854, tt:908.507\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:37.903, tt:947.575\n",
      "Ep:25, loss:0.00002, loss_test:0.01549, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:37.962, tt:987.005\n",
      "Ep:26, loss:0.00002, loss_test:0.01545, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:37.981, tt:1025.485\n",
      "Ep:27, loss:0.00002, loss_test:0.01545, lr:6.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:38.053, tt:1065.471\n",
      "Ep:28, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:38.089, tt:1104.583\n",
      "Ep:29, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:38.186, tt:1145.593\n",
      "Ep:30, loss:0.00002, loss_test:0.01536, lr:6.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:38.194, tt:1184.016\n",
      "Ep:31, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:38.211, tt:1222.767\n",
      "Ep:32, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:38.238, tt:1261.843\n",
      "Ep:33, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:38.237, tt:1300.064\n",
      "Ep:34, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:38.329, tt:1341.515\n",
      "Ep:35, loss:0.00002, loss_test:0.01538, lr:5.94e-02, fs:0.74747 (r=0.747,p=0.747),  time:38.352, tt:1380.670\n",
      "Ep:36, loss:0.00002, loss_test:0.01538, lr:5.88e-02, fs:0.75127 (r=0.747,p=0.755),  time:38.360, tt:1419.312\n",
      "Ep:37, loss:0.00002, loss_test:0.01532, lr:5.82e-02, fs:0.75127 (r=0.747,p=0.755),  time:38.366, tt:1457.903\n",
      "Ep:38, loss:0.00002, loss_test:0.01534, lr:5.76e-02, fs:0.75127 (r=0.747,p=0.755),  time:38.388, tt:1497.142\n",
      "Ep:39, loss:0.00002, loss_test:0.01544, lr:5.71e-02, fs:0.75127 (r=0.747,p=0.755),  time:38.439, tt:1537.569\n",
      "Ep:40, loss:0.00002, loss_test:0.01551, lr:5.65e-02, fs:0.75510 (r=0.747,p=0.763),  time:38.431, tt:1575.672\n",
      "Ep:41, loss:0.00001, loss_test:0.01545, lr:5.59e-02, fs:0.75510 (r=0.747,p=0.763),  time:38.479, tt:1616.138\n",
      "Ep:42, loss:0.00001, loss_test:0.01551, lr:5.54e-02, fs:0.75897 (r=0.747,p=0.771),  time:38.515, tt:1656.136\n",
      "Ep:43, loss:0.00001, loss_test:0.01553, lr:5.48e-02, fs:0.75258 (r=0.737,p=0.768),  time:38.540, tt:1695.745\n",
      "Ep:44, loss:0.00001, loss_test:0.01556, lr:5.43e-02, fs:0.74611 (r=0.727,p=0.766),  time:38.531, tt:1733.906\n",
      "Ep:45, loss:0.00001, loss_test:0.01558, lr:5.37e-02, fs:0.74611 (r=0.727,p=0.766),  time:38.596, tt:1775.400\n",
      "Ep:46, loss:0.00001, loss_test:0.01565, lr:5.32e-02, fs:0.75000 (r=0.727,p=0.774),  time:38.638, tt:1815.995\n",
      "Ep:47, loss:0.00001, loss_test:0.01572, lr:5.27e-02, fs:0.75393 (r=0.727,p=0.783),  time:38.653, tt:1855.363\n",
      "Ep:48, loss:0.00001, loss_test:0.01574, lr:5.21e-02, fs:0.74737 (r=0.717,p=0.780),  time:38.646, tt:1893.645\n",
      "Ep:49, loss:0.00001, loss_test:0.01576, lr:5.16e-02, fs:0.75132 (r=0.717,p=0.789),  time:38.644, tt:1932.195\n",
      "Ep:50, loss:0.00001, loss_test:0.01578, lr:5.11e-02, fs:0.75132 (r=0.717,p=0.789),  time:38.648, tt:1971.065\n",
      "Ep:51, loss:0.00001, loss_test:0.01585, lr:5.06e-02, fs:0.75132 (r=0.717,p=0.789),  time:38.635, tt:2009.016\n",
      "Ep:52, loss:0.00001, loss_test:0.01585, lr:5.01e-02, fs:0.75132 (r=0.717,p=0.789),  time:38.634, tt:2047.617\n",
      "Ep:53, loss:0.00001, loss_test:0.01595, lr:4.96e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.622, tt:2085.575\n",
      "Ep:54, loss:0.00001, loss_test:0.01597, lr:4.91e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.637, tt:2125.054\n",
      "Ep:55, loss:0.00001, loss_test:0.01593, lr:4.86e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.647, tt:2164.225\n",
      "Ep:56, loss:0.00001, loss_test:0.01602, lr:4.81e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.639, tt:2202.415\n",
      "Ep:57, loss:0.00001, loss_test:0.01605, lr:4.76e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.621, tt:2240.021\n",
      "Ep:58, loss:0.00001, loss_test:0.01604, lr:4.71e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.676, tt:2281.897\n",
      "Ep:59, loss:0.00001, loss_test:0.01614, lr:4.67e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.642, tt:2318.545\n",
      "Ep:60, loss:0.00001, loss_test:0.01619, lr:4.62e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.645, tt:2357.357\n",
      "Ep:61, loss:0.00001, loss_test:0.01610, lr:4.57e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.644, tt:2395.948\n",
      "Ep:62, loss:0.00001, loss_test:0.01613, lr:4.53e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.652, tt:2435.095\n",
      "Ep:63, loss:0.00001, loss_test:0.01622, lr:4.48e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.645, tt:2473.301\n",
      "Ep:64, loss:0.00001, loss_test:0.01622, lr:4.44e-02, fs:0.76344 (r=0.717,p=0.816),  time:38.677, tt:2514.028\n",
      "Ep:65, loss:0.00001, loss_test:0.01624, lr:4.39e-02, fs:0.76344 (r=0.717,p=0.816),  time:38.700, tt:2554.215\n",
      "Ep:66, loss:0.00001, loss_test:0.01625, lr:4.35e-02, fs:0.76596 (r=0.727,p=0.809),  time:38.678, tt:2591.400\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01636, lr:4.35e-02, fs:0.75936 (r=0.717,p=0.807),  time:38.678, tt:2630.119\n",
      "Ep:68, loss:0.00001, loss_test:0.01632, lr:4.35e-02, fs:0.76596 (r=0.727,p=0.809),  time:38.664, tt:2667.812\n",
      "Ep:69, loss:0.00001, loss_test:0.01629, lr:4.35e-02, fs:0.77005 (r=0.727,p=0.818),  time:38.652, tt:2705.673\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01641, lr:4.35e-02, fs:0.77419 (r=0.727,p=0.828),  time:38.651, tt:2744.252\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01643, lr:4.35e-02, fs:0.77419 (r=0.727,p=0.828),  time:38.650, tt:2782.766\n",
      "Ep:72, loss:0.00001, loss_test:0.01639, lr:4.35e-02, fs:0.77419 (r=0.727,p=0.828),  time:38.642, tt:2820.862\n",
      "Ep:73, loss:0.00001, loss_test:0.01652, lr:4.35e-02, fs:0.77419 (r=0.727,p=0.828),  time:38.638, tt:2859.246\n",
      "Ep:74, loss:0.00001, loss_test:0.01648, lr:4.35e-02, fs:0.77419 (r=0.727,p=0.828),  time:38.641, tt:2898.093\n",
      "Ep:75, loss:0.00001, loss_test:0.01654, lr:4.35e-02, fs:0.77838 (r=0.727,p=0.837),  time:38.645, tt:2937.012\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01657, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.645, tt:2975.664\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01657, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.628, tt:3012.957\n",
      "Ep:78, loss:0.00001, loss_test:0.01659, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.625, tt:3051.355\n",
      "Ep:79, loss:0.00001, loss_test:0.01668, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.627, tt:3090.177\n",
      "Ep:80, loss:0.00001, loss_test:0.01669, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.645, tt:3130.279\n",
      "Ep:81, loss:0.00001, loss_test:0.01669, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.643, tt:3168.706\n",
      "Ep:82, loss:0.00001, loss_test:0.01669, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.657, tt:3208.516\n",
      "Ep:83, loss:0.00001, loss_test:0.01677, lr:4.35e-02, fs:0.77596 (r=0.717,p=0.845),  time:38.647, tt:3246.340\n",
      "Ep:84, loss:0.00001, loss_test:0.01675, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.649, tt:3285.146\n",
      "Ep:85, loss:0.00001, loss_test:0.01674, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.651, tt:3324.001\n",
      "Ep:86, loss:0.00001, loss_test:0.01677, lr:4.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:38.645, tt:3362.111\n",
      "Ep:87, loss:0.00001, loss_test:0.01680, lr:4.35e-02, fs:0.76243 (r=0.697,p=0.841),  time:38.662, tt:3402.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:88, loss:0.00001, loss_test:0.01683, lr:4.31e-02, fs:0.74860 (r=0.677,p=0.838),  time:38.667, tt:3441.329\n",
      "Ep:89, loss:0.00001, loss_test:0.01690, lr:4.26e-02, fs:0.74860 (r=0.677,p=0.838),  time:38.672, tt:3480.511\n",
      "Ep:90, loss:0.00001, loss_test:0.01693, lr:4.22e-02, fs:0.74157 (r=0.667,p=0.835),  time:38.681, tt:3519.946\n",
      "Ep:91, loss:0.00001, loss_test:0.01691, lr:4.18e-02, fs:0.74157 (r=0.667,p=0.835),  time:38.709, tt:3561.224\n",
      "Ep:92, loss:0.00001, loss_test:0.01700, lr:4.14e-02, fs:0.73446 (r=0.657,p=0.833),  time:38.701, tt:3599.178\n",
      "Ep:93, loss:0.00001, loss_test:0.01700, lr:4.10e-02, fs:0.73446 (r=0.657,p=0.833),  time:38.695, tt:3637.352\n",
      "Ep:94, loss:0.00001, loss_test:0.01702, lr:4.05e-02, fs:0.72727 (r=0.646,p=0.831),  time:38.693, tt:3675.844\n",
      "Ep:95, loss:0.00001, loss_test:0.01705, lr:4.01e-02, fs:0.72727 (r=0.646,p=0.831),  time:38.692, tt:3714.394\n",
      "Ep:96, loss:0.00001, loss_test:0.01713, lr:3.97e-02, fs:0.71264 (r=0.626,p=0.827),  time:38.686, tt:3752.549\n",
      "Ep:97, loss:0.00001, loss_test:0.01713, lr:3.93e-02, fs:0.72000 (r=0.636,p=0.829),  time:38.692, tt:3791.847\n",
      "Ep:98, loss:0.00001, loss_test:0.01718, lr:3.89e-02, fs:0.72000 (r=0.636,p=0.829),  time:38.685, tt:3829.821\n",
      "Ep:99, loss:0.00001, loss_test:0.01724, lr:3.86e-02, fs:0.71264 (r=0.626,p=0.827),  time:38.685, tt:3868.489\n",
      "Ep:100, loss:0.00001, loss_test:0.01725, lr:3.82e-02, fs:0.71264 (r=0.626,p=0.827),  time:38.699, tt:3908.559\n",
      "Ep:101, loss:0.00001, loss_test:0.01725, lr:3.78e-02, fs:0.71264 (r=0.626,p=0.827),  time:38.676, tt:3944.980\n",
      "Ep:102, loss:0.00001, loss_test:0.01728, lr:3.74e-02, fs:0.70520 (r=0.616,p=0.824),  time:38.667, tt:3982.701\n",
      "Ep:103, loss:0.00001, loss_test:0.01730, lr:3.70e-02, fs:0.70520 (r=0.616,p=0.824),  time:38.653, tt:4019.943\n",
      "Ep:104, loss:0.00001, loss_test:0.01735, lr:3.67e-02, fs:0.70520 (r=0.616,p=0.824),  time:38.659, tt:4059.243\n",
      "Ep:105, loss:0.00001, loss_test:0.01738, lr:3.63e-02, fs:0.69767 (r=0.606,p=0.822),  time:38.661, tt:4098.033\n",
      "Ep:106, loss:0.00001, loss_test:0.01744, lr:3.59e-02, fs:0.69767 (r=0.606,p=0.822),  time:38.674, tt:4138.144\n",
      "Ep:107, loss:0.00001, loss_test:0.01746, lr:3.56e-02, fs:0.69767 (r=0.606,p=0.822),  time:38.681, tt:4177.594\n",
      "Ep:108, loss:0.00001, loss_test:0.01752, lr:3.52e-02, fs:0.69767 (r=0.606,p=0.822),  time:38.691, tt:4217.271\n",
      "Ep:109, loss:0.00001, loss_test:0.01759, lr:3.49e-02, fs:0.69767 (r=0.606,p=0.822),  time:38.694, tt:4256.287\n",
      "Ep:110, loss:0.00001, loss_test:0.01758, lr:3.45e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.686, tt:4294.155\n",
      "Ep:111, loss:0.00001, loss_test:0.01762, lr:3.42e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.678, tt:4331.905\n",
      "Ep:112, loss:0.00001, loss_test:0.01768, lr:3.38e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.702, tt:4373.371\n",
      "Ep:113, loss:0.00001, loss_test:0.01767, lr:3.35e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.707, tt:4412.617\n",
      "Ep:114, loss:0.00001, loss_test:0.01771, lr:3.32e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.704, tt:4450.989\n",
      "Ep:115, loss:0.00001, loss_test:0.01777, lr:3.28e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.707, tt:4490.065\n",
      "Ep:116, loss:0.00001, loss_test:0.01781, lr:3.25e-02, fs:0.70175 (r=0.606,p=0.833),  time:38.718, tt:4529.977\n",
      "Ep:117, loss:0.00001, loss_test:0.01779, lr:3.22e-02, fs:0.69412 (r=0.596,p=0.831),  time:38.717, tt:4568.568\n",
      "Ep:118, loss:0.00001, loss_test:0.01783, lr:3.19e-02, fs:0.69412 (r=0.596,p=0.831),  time:38.709, tt:4606.367\n",
      "Ep:119, loss:0.00001, loss_test:0.01789, lr:3.15e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.693, tt:4643.203\n",
      "Ep:120, loss:0.00000, loss_test:0.01789, lr:3.12e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.698, tt:4682.462\n",
      "Ep:121, loss:0.00000, loss_test:0.01795, lr:3.09e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.701, tt:4721.524\n",
      "Ep:122, loss:0.00000, loss_test:0.01799, lr:3.06e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.690, tt:4758.868\n",
      "Ep:123, loss:0.00000, loss_test:0.01804, lr:3.03e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.690, tt:4797.538\n",
      "Ep:124, loss:0.00000, loss_test:0.01801, lr:3.00e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.677, tt:4834.589\n",
      "Ep:125, loss:0.00000, loss_test:0.01804, lr:2.97e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.683, tt:4874.087\n",
      "Ep:126, loss:0.00000, loss_test:0.01811, lr:2.94e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.678, tt:4912.165\n",
      "Ep:127, loss:0.00000, loss_test:0.01812, lr:2.91e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.684, tt:4951.563\n",
      "Ep:128, loss:0.00000, loss_test:0.01815, lr:2.88e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.698, tt:4992.030\n",
      "Ep:129, loss:0.00000, loss_test:0.01820, lr:2.85e-02, fs:0.68639 (r=0.586,p=0.829),  time:38.695, tt:5030.377\n",
      "Ep:130, loss:0.00000, loss_test:0.01821, lr:2.82e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.693, tt:5068.795\n",
      "Ep:131, loss:0.00000, loss_test:0.01828, lr:2.80e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.690, tt:5107.037\n",
      "Ep:132, loss:0.00000, loss_test:0.01830, lr:2.77e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.689, tt:5145.699\n",
      "Ep:133, loss:0.00000, loss_test:0.01832, lr:2.74e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.686, tt:5183.929\n",
      "Ep:134, loss:0.00000, loss_test:0.01836, lr:2.71e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.695, tt:5223.875\n",
      "Ep:135, loss:0.00000, loss_test:0.01840, lr:2.69e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.695, tt:5262.574\n",
      "Ep:136, loss:0.00000, loss_test:0.01840, lr:2.66e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.689, tt:5300.418\n",
      "Ep:137, loss:0.00000, loss_test:0.01842, lr:2.63e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.684, tt:5338.400\n",
      "Ep:138, loss:0.00000, loss_test:0.01846, lr:2.61e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.660, tt:5373.728\n",
      "Ep:139, loss:0.00000, loss_test:0.01849, lr:2.58e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.662, tt:5412.645\n",
      "Ep:140, loss:0.00000, loss_test:0.01851, lr:2.55e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.656, tt:5450.500\n",
      "Ep:141, loss:0.00000, loss_test:0.01855, lr:2.53e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.655, tt:5488.986\n",
      "Ep:142, loss:0.00000, loss_test:0.01856, lr:2.50e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.647, tt:5526.588\n",
      "Ep:143, loss:0.00000, loss_test:0.01858, lr:2.48e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.640, tt:5564.095\n",
      "Ep:144, loss:0.00000, loss_test:0.01860, lr:2.45e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.627, tt:5600.856\n",
      "Ep:145, loss:0.00000, loss_test:0.01861, lr:2.43e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.615, tt:5637.818\n",
      "Ep:146, loss:0.00000, loss_test:0.01867, lr:2.40e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.609, tt:5675.560\n",
      "Ep:147, loss:0.00000, loss_test:0.01871, lr:2.38e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.613, tt:5714.791\n",
      "Ep:148, loss:0.00000, loss_test:0.01868, lr:2.36e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.599, tt:5751.319\n",
      "Ep:149, loss:0.00000, loss_test:0.01874, lr:2.33e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.615, tt:5792.185\n",
      "Ep:150, loss:0.00000, loss_test:0.01878, lr:2.31e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.607, tt:5829.606\n",
      "Ep:151, loss:0.00000, loss_test:0.01879, lr:2.29e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.598, tt:5866.942\n",
      "Ep:152, loss:0.00000, loss_test:0.01882, lr:2.26e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.593, tt:5904.782\n",
      "Ep:153, loss:0.00000, loss_test:0.01885, lr:2.24e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.564, tt:5938.826\n",
      "Ep:154, loss:0.00000, loss_test:0.01887, lr:2.22e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.561, tt:5976.939\n",
      "Ep:155, loss:0.00000, loss_test:0.01888, lr:2.20e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.563, tt:6015.786\n",
      "Ep:156, loss:0.00000, loss_test:0.01893, lr:2.17e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.566, tt:6054.808\n",
      "Ep:157, loss:0.00000, loss_test:0.01896, lr:2.15e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.563, tt:6092.923\n",
      "Ep:158, loss:0.00000, loss_test:0.01897, lr:2.13e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.559, tt:6130.865\n",
      "Ep:159, loss:0.00000, loss_test:0.01899, lr:2.11e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.542, tt:6166.731\n",
      "Ep:160, loss:0.00000, loss_test:0.01900, lr:2.09e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.540, tt:6204.951\n",
      "Ep:161, loss:0.00000, loss_test:0.01903, lr:2.07e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.529, tt:6241.699\n",
      "Ep:162, loss:0.00000, loss_test:0.01907, lr:2.05e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.534, tt:6281.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00000, loss_test:0.01911, lr:2.03e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.527, tt:6318.424\n",
      "Ep:164, loss:0.00000, loss_test:0.01913, lr:2.01e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.518, tt:6355.551\n",
      "Ep:165, loss:0.00000, loss_test:0.01914, lr:1.99e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.515, tt:6393.441\n",
      "Ep:166, loss:0.00000, loss_test:0.01916, lr:1.97e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.510, tt:6431.228\n",
      "Ep:167, loss:0.00000, loss_test:0.01920, lr:1.95e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.516, tt:6470.754\n",
      "Ep:168, loss:0.00000, loss_test:0.01922, lr:1.93e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.508, tt:6507.830\n",
      "Ep:169, loss:0.00000, loss_test:0.01923, lr:1.91e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.506, tt:6546.060\n",
      "Ep:170, loss:0.00000, loss_test:0.01925, lr:1.89e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.510, tt:6585.234\n",
      "Ep:171, loss:0.00000, loss_test:0.01930, lr:1.87e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.519, tt:6625.196\n",
      "Ep:172, loss:0.00000, loss_test:0.01932, lr:1.85e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.519, tt:6663.715\n",
      "Ep:173, loss:0.00000, loss_test:0.01928, lr:1.83e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.518, tt:6702.101\n",
      "Ep:174, loss:0.00000, loss_test:0.01929, lr:1.81e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.520, tt:6740.999\n",
      "Ep:175, loss:0.00000, loss_test:0.01934, lr:1.80e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.520, tt:6779.554\n",
      "Ep:176, loss:0.00000, loss_test:0.01936, lr:1.78e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.518, tt:6817.665\n",
      "Ep:177, loss:0.00000, loss_test:0.01940, lr:1.76e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.523, tt:6857.143\n",
      "Ep:178, loss:0.00000, loss_test:0.01940, lr:1.74e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.524, tt:6895.861\n",
      "Ep:179, loss:0.00000, loss_test:0.01942, lr:1.73e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.530, tt:6935.416\n",
      "Ep:180, loss:0.00000, loss_test:0.01945, lr:1.71e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.536, tt:6974.943\n",
      "Ep:181, loss:0.00000, loss_test:0.01944, lr:1.69e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.537, tt:7013.821\n",
      "Ep:182, loss:0.00000, loss_test:0.01948, lr:1.67e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.541, tt:7052.945\n",
      "Ep:183, loss:0.00000, loss_test:0.01948, lr:1.66e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.531, tt:7089.771\n",
      "Ep:184, loss:0.00000, loss_test:0.01949, lr:1.64e-02, fs:0.69048 (r=0.586,p=0.841),  time:38.545, tt:7130.901\n",
      "Ep:185, loss:0.00000, loss_test:0.01951, lr:1.62e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.557, tt:7171.592\n",
      "Ep:186, loss:0.00000, loss_test:0.01955, lr:1.61e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.553, tt:7209.486\n",
      "Ep:187, loss:0.00000, loss_test:0.01957, lr:1.59e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.549, tt:7247.189\n",
      "Ep:188, loss:0.00000, loss_test:0.01957, lr:1.58e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.551, tt:7286.088\n",
      "Ep:189, loss:0.00000, loss_test:0.01960, lr:1.56e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.559, tt:7326.171\n",
      "Ep:190, loss:0.00000, loss_test:0.01961, lr:1.54e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.563, tt:7365.569\n",
      "Ep:191, loss:0.00000, loss_test:0.01962, lr:1.53e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.568, tt:7405.137\n",
      "Ep:192, loss:0.00000, loss_test:0.01963, lr:1.51e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.573, tt:7444.544\n",
      "Ep:193, loss:0.00000, loss_test:0.01970, lr:1.50e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.569, tt:7482.441\n",
      "Ep:194, loss:0.00000, loss_test:0.01970, lr:1.48e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.572, tt:7521.515\n",
      "Ep:195, loss:0.00000, loss_test:0.01970, lr:1.47e-02, fs:0.69461 (r=0.586,p=0.853),  time:38.573, tt:7560.343\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02308, lr:6.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:31.831, tt:31.831\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02424, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:25.632, tt:51.263\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02561, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:25.651, tt:76.953\n",
      "Ep:3, loss:0.00005, loss_test:0.02521, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:27.968, tt:111.871\n",
      "Ep:4, loss:0.00005, loss_test:0.02385, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:28.958, tt:144.791\n",
      "Ep:5, loss:0.00005, loss_test:0.02209, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:29.943, tt:179.659\n",
      "Ep:6, loss:0.00004, loss_test:0.02062, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:30.556, tt:213.893\n",
      "Ep:7, loss:0.00004, loss_test:0.02000, lr:6.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:31.153, tt:249.225\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:31.817, tt:286.354\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01873, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:32.110, tt:321.105\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01823, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:32.470, tt:357.166\n",
      "Ep:11, loss:0.00004, loss_test:0.01806, lr:6.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:32.773, tt:393.271\n",
      "Ep:12, loss:0.00004, loss_test:0.01784, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:33.058, tt:429.751\n",
      "Ep:13, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.71595 (r=0.929,p=0.582),  time:33.308, tt:466.318\n",
      "Ep:14, loss:0.00003, loss_test:0.01727, lr:6.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:33.439, tt:501.592\n",
      "Ep:15, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:33.580, tt:537.276\n",
      "Ep:16, loss:0.00003, loss_test:0.01673, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:33.666, tt:572.321\n",
      "Ep:17, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:33.781, tt:608.061\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:33.897, tt:644.034\n",
      "Ep:19, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:34.039, tt:680.789\n",
      "Ep:20, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:34.116, tt:716.443\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:34.187, tt:752.106\n",
      "Ep:22, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:34.263, tt:788.045\n",
      "Ep:23, loss:0.00003, loss_test:0.01584, lr:6.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:34.289, tt:822.948\n",
      "Ep:24, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:34.312, tt:857.810\n",
      "Ep:25, loss:0.00002, loss_test:0.01572, lr:6.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:34.382, tt:893.933\n",
      "Ep:26, loss:0.00002, loss_test:0.01572, lr:6.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:34.411, tt:929.084\n",
      "Ep:27, loss:0.00002, loss_test:0.01573, lr:6.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:34.386, tt:962.801\n",
      "Ep:28, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:34.441, tt:998.785\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:34.480, tt:1034.401\n",
      "Ep:30, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:34.519, tt:1070.100\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:34.540, tt:1105.284\n",
      "Ep:32, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:34.544, tt:1139.947\n",
      "Ep:33, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:34.570, tt:1175.387\n",
      "Ep:34, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:34.611, tt:1211.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:35, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:34.606, tt:1245.802\n",
      "Ep:36, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:34.622, tt:1281.010\n",
      "Ep:37, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:34.624, tt:1315.724\n",
      "Ep:38, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:34.625, tt:1350.363\n",
      "Ep:39, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:34.635, tt:1385.390\n",
      "Ep:40, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:34.633, tt:1419.969\n",
      "Ep:41, loss:0.00001, loss_test:0.01553, lr:6.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:34.627, tt:1454.335\n",
      "Ep:42, loss:0.00001, loss_test:0.01557, lr:5.94e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.644, tt:1489.678\n",
      "Ep:43, loss:0.00001, loss_test:0.01562, lr:5.88e-02, fs:0.74747 (r=0.747,p=0.747),  time:34.646, tt:1524.425\n",
      "Ep:44, loss:0.00001, loss_test:0.01544, lr:5.82e-02, fs:0.74747 (r=0.747,p=0.747),  time:34.632, tt:1558.420\n",
      "Ep:45, loss:0.00001, loss_test:0.01551, lr:5.76e-02, fs:0.75127 (r=0.747,p=0.755),  time:34.593, tt:1591.300\n",
      "Ep:46, loss:0.00001, loss_test:0.01562, lr:5.71e-02, fs:0.75510 (r=0.747,p=0.763),  time:34.596, tt:1626.026\n",
      "Ep:47, loss:0.00001, loss_test:0.01566, lr:5.65e-02, fs:0.75897 (r=0.747,p=0.771),  time:34.576, tt:1659.654\n",
      "Ep:48, loss:0.00001, loss_test:0.01563, lr:5.59e-02, fs:0.75897 (r=0.747,p=0.771),  time:34.584, tt:1694.616\n",
      "Ep:49, loss:0.00001, loss_test:0.01555, lr:5.54e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.575, tt:1728.745\n",
      "Ep:50, loss:0.00001, loss_test:0.01566, lr:5.48e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.544, tt:1761.744\n",
      "Ep:51, loss:0.00001, loss_test:0.01567, lr:5.43e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.537, tt:1795.928\n",
      "Ep:52, loss:0.00001, loss_test:0.01554, lr:5.37e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.561, tt:1831.755\n",
      "Ep:53, loss:0.00001, loss_test:0.01564, lr:5.32e-02, fs:0.76289 (r=0.747,p=0.779),  time:34.553, tt:1865.837\n",
      "Ep:54, loss:0.00001, loss_test:0.01574, lr:5.27e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.563, tt:1900.949\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01568, lr:5.27e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.536, tt:1934.015\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01583, lr:5.27e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.550, tt:1969.366\n",
      "Ep:57, loss:0.00001, loss_test:0.01586, lr:5.27e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.544, tt:2003.529\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01589, lr:5.27e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.550, tt:2038.447\n",
      "Ep:59, loss:0.00001, loss_test:0.01592, lr:5.27e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.543, tt:2072.583\n",
      "Ep:60, loss:0.00001, loss_test:0.01591, lr:5.27e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.546, tt:2107.296\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01599, lr:5.27e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.538, tt:2141.371\n",
      "Ep:62, loss:0.00001, loss_test:0.01600, lr:5.27e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.538, tt:2175.914\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01604, lr:5.27e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.538, tt:2210.434\n",
      "Ep:64, loss:0.00001, loss_test:0.01611, lr:5.27e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.528, tt:2244.317\n",
      "Ep:65, loss:0.00001, loss_test:0.01611, lr:5.27e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.521, tt:2278.362\n",
      "Ep:66, loss:0.00001, loss_test:0.01616, lr:5.27e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.517, tt:2312.670\n",
      "Ep:67, loss:0.00001, loss_test:0.01620, lr:5.27e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.524, tt:2347.618\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01621, lr:5.27e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.520, tt:2381.881\n",
      "Ep:69, loss:0.00001, loss_test:0.01627, lr:5.27e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.515, tt:2416.061\n",
      "Ep:70, loss:0.00001, loss_test:0.01623, lr:5.27e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.473, tt:2447.593\n",
      "Ep:71, loss:0.00001, loss_test:0.01633, lr:5.27e-02, fs:0.79144 (r=0.747,p=0.841),  time:34.467, tt:2481.648\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01627, lr:5.27e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.465, tt:2515.944\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01635, lr:5.27e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.440, tt:2548.595\n",
      "Ep:74, loss:0.00001, loss_test:0.01636, lr:5.27e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.440, tt:2582.978\n",
      "Ep:75, loss:0.00001, loss_test:0.01635, lr:5.27e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.442, tt:2617.613\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01649, lr:5.27e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.451, tt:2652.695\n",
      "Ep:77, loss:0.00001, loss_test:0.01653, lr:5.27e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.458, tt:2687.714\n",
      "Ep:78, loss:0.00001, loss_test:0.01651, lr:5.27e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.472, tt:2723.293\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01653, lr:5.27e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.481, tt:2758.455\n",
      "Ep:80, loss:0.00001, loss_test:0.01666, lr:5.27e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.488, tt:2793.490\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01675, lr:5.27e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.529, tt:2831.407\n",
      "Ep:82, loss:0.00001, loss_test:0.01664, lr:5.27e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.550, tt:2867.670\n",
      "Ep:83, loss:0.00001, loss_test:0.01669, lr:5.27e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.576, tt:2904.391\n",
      "Ep:84, loss:0.00001, loss_test:0.01679, lr:5.27e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.596, tt:2940.622\n",
      "Ep:85, loss:0.00001, loss_test:0.01692, lr:5.27e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.608, tt:2976.320\n",
      "Ep:86, loss:0.00001, loss_test:0.01692, lr:5.27e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.614, tt:3011.435\n",
      "Ep:87, loss:0.00001, loss_test:0.01698, lr:5.27e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.628, tt:3047.266\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01694, lr:5.27e-02, fs:0.81768 (r=0.747,p=0.902),  time:34.655, tt:3084.283\n",
      "Ep:89, loss:0.00001, loss_test:0.01703, lr:5.27e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.660, tt:3119.383\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01711, lr:5.27e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.675, tt:3155.405\n",
      "Ep:91, loss:0.00001, loss_test:0.01707, lr:5.27e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.686, tt:3191.099\n",
      "Ep:92, loss:0.00001, loss_test:0.01719, lr:5.27e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.702, tt:3227.277\n",
      "Ep:93, loss:0.00000, loss_test:0.01736, lr:5.27e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.701, tt:3261.932\n",
      "Ep:94, loss:0.00000, loss_test:0.01736, lr:5.27e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.702, tt:3296.700\n",
      "Ep:95, loss:0.00000, loss_test:0.01737, lr:5.27e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.714, tt:3332.498\n",
      "Ep:96, loss:0.00000, loss_test:0.01731, lr:5.27e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.715, tt:3367.337\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00000, loss_test:0.01758, lr:5.27e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.721, tt:3402.668\n",
      "Ep:98, loss:0.00000, loss_test:0.01759, lr:5.27e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.721, tt:3437.356\n",
      "Ep:99, loss:0.00000, loss_test:0.01759, lr:5.27e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.731, tt:3473.119\n",
      "Ep:100, loss:0.00000, loss_test:0.01766, lr:5.27e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.752, tt:3509.949\n",
      "Ep:101, loss:0.00000, loss_test:0.01784, lr:5.27e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.764, tt:3545.936\n",
      "Ep:102, loss:0.00000, loss_test:0.01790, lr:5.27e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.775, tt:3581.818\n",
      "Ep:103, loss:0.00000, loss_test:0.01784, lr:5.27e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.792, tt:3618.339\n",
      "Ep:104, loss:0.00000, loss_test:0.01805, lr:5.27e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.801, tt:3654.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00000, loss_test:0.01809, lr:5.27e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.809, tt:3689.709\n",
      "Ep:106, loss:0.00000, loss_test:0.01814, lr:5.27e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.830, tt:3726.817\n",
      "Ep:107, loss:0.00000, loss_test:0.01821, lr:5.27e-02, fs:0.79070 (r=0.687,p=0.932),  time:34.844, tt:3763.152\n",
      "Ep:108, loss:0.00000, loss_test:0.01828, lr:5.21e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.852, tt:3798.876\n",
      "Ep:109, loss:0.00000, loss_test:0.01831, lr:5.16e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.871, tt:3835.839\n",
      "Ep:110, loss:0.00000, loss_test:0.01854, lr:5.11e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.885, tt:3872.287\n",
      "Ep:111, loss:0.00000, loss_test:0.01857, lr:5.06e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.906, tt:3909.506\n",
      "Ep:112, loss:0.00000, loss_test:0.01851, lr:5.01e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.909, tt:3944.730\n",
      "Ep:113, loss:0.00000, loss_test:0.01859, lr:4.96e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.926, tt:3981.519\n",
      "Ep:114, loss:0.00000, loss_test:0.01872, lr:4.91e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.938, tt:4017.856\n",
      "Ep:115, loss:0.00000, loss_test:0.01884, lr:4.86e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.940, tt:4052.990\n",
      "Ep:116, loss:0.00000, loss_test:0.01876, lr:4.81e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.946, tt:4088.733\n",
      "Ep:117, loss:0.00000, loss_test:0.01883, lr:4.76e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.958, tt:4125.043\n",
      "Ep:118, loss:0.00000, loss_test:0.01899, lr:4.71e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.971, tt:4161.605\n",
      "Ep:119, loss:0.00000, loss_test:0.01916, lr:4.67e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.970, tt:4196.449\n",
      "Ep:120, loss:0.00000, loss_test:0.01900, lr:4.62e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.970, tt:4231.316\n",
      "Ep:121, loss:0.00000, loss_test:0.01918, lr:4.57e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.977, tt:4267.151\n",
      "Ep:122, loss:0.00000, loss_test:0.01927, lr:4.53e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.975, tt:4301.939\n",
      "Ep:123, loss:0.00000, loss_test:0.01926, lr:4.48e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.974, tt:4336.742\n",
      "Ep:124, loss:0.00000, loss_test:0.01935, lr:4.44e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.971, tt:4371.365\n",
      "Ep:125, loss:0.00000, loss_test:0.01937, lr:4.39e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.974, tt:4406.670\n",
      "Ep:126, loss:0.00000, loss_test:0.01947, lr:4.35e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.974, tt:4441.634\n",
      "Ep:127, loss:0.00000, loss_test:0.01953, lr:4.31e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.975, tt:4476.746\n",
      "Ep:128, loss:0.00000, loss_test:0.01964, lr:4.26e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.973, tt:4511.505\n",
      "Ep:129, loss:0.00000, loss_test:0.01959, lr:4.22e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.969, tt:4545.989\n",
      "Ep:130, loss:0.00000, loss_test:0.01977, lr:4.18e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.978, tt:4582.079\n",
      "Ep:131, loss:0.00000, loss_test:0.01980, lr:4.14e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.976, tt:4616.894\n",
      "Ep:132, loss:0.00000, loss_test:0.01983, lr:4.10e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.979, tt:4652.193\n",
      "Ep:133, loss:0.00000, loss_test:0.01986, lr:4.05e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.969, tt:4685.789\n",
      "Ep:134, loss:0.00000, loss_test:0.01992, lr:4.01e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.967, tt:4720.592\n",
      "Ep:135, loss:0.00000, loss_test:0.02007, lr:3.97e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.961, tt:4754.628\n",
      "Ep:136, loss:0.00000, loss_test:0.02002, lr:3.93e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.950, tt:4788.111\n",
      "Ep:137, loss:0.00000, loss_test:0.02007, lr:3.89e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.948, tt:4822.855\n",
      "Ep:138, loss:0.00000, loss_test:0.02008, lr:3.86e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.936, tt:4856.061\n",
      "Ep:139, loss:0.00000, loss_test:0.02020, lr:3.82e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.932, tt:4890.474\n",
      "Ep:140, loss:0.00000, loss_test:0.02025, lr:3.78e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.932, tt:4925.461\n",
      "Ep:141, loss:0.00000, loss_test:0.02019, lr:3.74e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.939, tt:4961.369\n",
      "Ep:142, loss:0.00000, loss_test:0.02036, lr:3.70e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.949, tt:4997.679\n",
      "Ep:143, loss:0.00000, loss_test:0.02033, lr:3.67e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.941, tt:5031.482\n",
      "Ep:144, loss:0.00000, loss_test:0.02043, lr:3.63e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.937, tt:5065.882\n",
      "Ep:145, loss:0.00000, loss_test:0.02046, lr:3.59e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.939, tt:5101.116\n",
      "Ep:146, loss:0.00000, loss_test:0.02051, lr:3.56e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.946, tt:5137.030\n",
      "Ep:147, loss:0.00000, loss_test:0.02056, lr:3.52e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.954, tt:5173.190\n",
      "Ep:148, loss:0.00000, loss_test:0.02055, lr:3.49e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.953, tt:5208.044\n",
      "Ep:149, loss:0.00000, loss_test:0.02064, lr:3.45e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.964, tt:5244.551\n",
      "Ep:150, loss:0.00000, loss_test:0.02065, lr:3.42e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.961, tt:5279.134\n",
      "Ep:151, loss:0.00000, loss_test:0.02070, lr:3.38e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.961, tt:5314.041\n",
      "Ep:152, loss:0.00000, loss_test:0.02079, lr:3.35e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.966, tt:5349.827\n",
      "Ep:153, loss:0.00000, loss_test:0.02078, lr:3.32e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.958, tt:5383.515\n",
      "Ep:154, loss:0.00000, loss_test:0.02079, lr:3.28e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.962, tt:5419.083\n",
      "Ep:155, loss:0.00000, loss_test:0.02085, lr:3.25e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.967, tt:5454.892\n",
      "Ep:156, loss:0.00000, loss_test:0.02089, lr:3.22e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.966, tt:5489.630\n",
      "Ep:157, loss:0.00000, loss_test:0.02082, lr:3.19e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.972, tt:5525.620\n",
      "Ep:158, loss:0.00000, loss_test:0.02091, lr:3.15e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.977, tt:5561.407\n",
      "Ep:159, loss:0.00000, loss_test:0.02099, lr:3.12e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.981, tt:5596.977\n",
      "Ep:160, loss:0.00000, loss_test:0.02100, lr:3.09e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.984, tt:5632.373\n",
      "Ep:161, loss:0.00000, loss_test:0.02104, lr:3.06e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.987, tt:5667.907\n",
      "Ep:162, loss:0.00000, loss_test:0.02109, lr:3.03e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.988, tt:5703.063\n",
      "Ep:163, loss:0.00000, loss_test:0.02113, lr:3.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.989, tt:5738.187\n",
      "Ep:164, loss:0.00000, loss_test:0.02118, lr:2.97e-02, fs:0.74699 (r=0.626,p=0.925),  time:34.992, tt:5773.726\n",
      "Ep:165, loss:0.00000, loss_test:0.02120, lr:2.94e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.000, tt:5810.080\n",
      "Ep:166, loss:0.00000, loss_test:0.02125, lr:2.91e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.012, tt:5847.042\n",
      "Ep:167, loss:0.00000, loss_test:0.02125, lr:2.88e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.020, tt:5883.380\n",
      "Ep:168, loss:0.00000, loss_test:0.02131, lr:2.85e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.022, tt:5918.752\n",
      "Ep:169, loss:0.00000, loss_test:0.02132, lr:2.82e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.033, tt:5955.655\n",
      "Ep:170, loss:0.00000, loss_test:0.02137, lr:2.80e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.035, tt:5991.052\n",
      "Ep:171, loss:0.00000, loss_test:0.02142, lr:2.77e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.039, tt:6026.711\n",
      "Ep:172, loss:0.00000, loss_test:0.02141, lr:2.74e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.052, tt:6063.918\n",
      "Ep:173, loss:0.00000, loss_test:0.02146, lr:2.71e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.054, tt:6099.436\n",
      "Ep:174, loss:0.00000, loss_test:0.02148, lr:2.69e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.055, tt:6134.595\n",
      "Ep:175, loss:0.00000, loss_test:0.02150, lr:2.66e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.055, tt:6169.661\n",
      "Ep:176, loss:0.00000, loss_test:0.02154, lr:2.63e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.060, tt:6205.568\n",
      "Ep:177, loss:0.00000, loss_test:0.02159, lr:2.61e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.073, tt:6242.914\n",
      "Ep:178, loss:0.00000, loss_test:0.02160, lr:2.58e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.075, tt:6278.363\n",
      "Ep:179, loss:0.00000, loss_test:0.02162, lr:2.55e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.082, tt:6314.794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00000, loss_test:0.02162, lr:2.53e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.088, tt:6351.014\n",
      "Ep:181, loss:0.00000, loss_test:0.02167, lr:2.50e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.089, tt:6386.228\n",
      "Ep:182, loss:0.00000, loss_test:0.02172, lr:2.48e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.100, tt:6423.267\n",
      "Ep:183, loss:0.00000, loss_test:0.02172, lr:2.45e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.101, tt:6458.547\n",
      "Ep:184, loss:0.00000, loss_test:0.02177, lr:2.43e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.105, tt:6494.502\n",
      "Ep:185, loss:0.00000, loss_test:0.02179, lr:2.40e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.116, tt:6531.528\n",
      "Ep:186, loss:0.00000, loss_test:0.02180, lr:2.38e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.115, tt:6566.564\n",
      "Ep:187, loss:0.00000, loss_test:0.02180, lr:2.36e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.116, tt:6601.890\n",
      "Ep:188, loss:0.00000, loss_test:0.02186, lr:2.33e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.133, tt:6640.189\n",
      "Ep:189, loss:0.00000, loss_test:0.02191, lr:2.31e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.129, tt:6674.422\n",
      "Ep:190, loss:0.00000, loss_test:0.02194, lr:2.29e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.138, tt:6711.376\n",
      "Ep:191, loss:0.00000, loss_test:0.02195, lr:2.26e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.147, tt:6748.251\n",
      "Ep:192, loss:0.00000, loss_test:0.02197, lr:2.24e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.151, tt:6784.191\n",
      "Ep:193, loss:0.00000, loss_test:0.02203, lr:2.22e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.153, tt:6819.675\n",
      "Ep:194, loss:0.00000, loss_test:0.02200, lr:2.20e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.158, tt:6855.778\n",
      "Ep:195, loss:0.00000, loss_test:0.02202, lr:2.17e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.163, tt:6891.916\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00025, loss_test:0.12962, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:28.358, tt:28.358\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00025, loss_test:0.12421, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:30.721, tt:61.442\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00024, loss_test:0.11763, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:31.542, tt:94.627\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00023, loss_test:0.11155, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:34.129, tt:136.516\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.10966, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:35.558, tt:177.788\n",
      "Ep:5, loss:0.00022, loss_test:0.10871, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:36.560, tt:219.360\n",
      "Ep:6, loss:0.00021, loss_test:0.10816, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:37.735, tt:264.148\n",
      "Ep:7, loss:0.00021, loss_test:0.10798, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:38.020, tt:304.164\n",
      "Ep:8, loss:0.00020, loss_test:0.10732, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:38.287, tt:344.585\n",
      "Ep:9, loss:0.00019, loss_test:0.10876, lr:1.00e-02, fs:0.67857 (r=0.768,p=0.608),  time:38.576, tt:385.761\n",
      "Ep:10, loss:0.00019, loss_test:0.10774, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:38.799, tt:426.788\n",
      "Ep:11, loss:0.00019, loss_test:0.10967, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:38.911, tt:466.928\n",
      "Ep:12, loss:0.00018, loss_test:0.10962, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:39.168, tt:509.178\n",
      "Ep:13, loss:0.00018, loss_test:0.11044, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:39.350, tt:550.896\n",
      "Ep:14, loss:0.00018, loss_test:0.11055, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:39.550, tt:593.245\n",
      "Ep:15, loss:0.00017, loss_test:0.11072, lr:9.90e-03, fs:0.67290 (r=0.727,p=0.626),  time:39.670, tt:634.728\n",
      "Ep:16, loss:0.00017, loss_test:0.11066, lr:9.80e-03, fs:0.68837 (r=0.747,p=0.638),  time:39.769, tt:676.074\n",
      "Ep:17, loss:0.00017, loss_test:0.11125, lr:9.70e-03, fs:0.66038 (r=0.707,p=0.619),  time:39.879, tt:717.822\n",
      "Ep:18, loss:0.00016, loss_test:0.11215, lr:9.61e-03, fs:0.67619 (r=0.717,p=0.640),  time:39.951, tt:759.078\n",
      "Ep:19, loss:0.00016, loss_test:0.11343, lr:9.51e-03, fs:0.66667 (r=0.707,p=0.631),  time:40.111, tt:802.210\n",
      "Ep:20, loss:0.00016, loss_test:0.11202, lr:9.41e-03, fs:0.68545 (r=0.737,p=0.640),  time:40.204, tt:844.276\n",
      "Ep:21, loss:0.00016, loss_test:0.11398, lr:9.32e-03, fs:0.69524 (r=0.737,p=0.658),  time:40.206, tt:884.531\n",
      "Ep:22, loss:0.00015, loss_test:0.11254, lr:9.23e-03, fs:0.68868 (r=0.737,p=0.646),  time:40.368, tt:928.459\n",
      "Ep:23, loss:0.00015, loss_test:0.11603, lr:9.14e-03, fs:0.67000 (r=0.677,p=0.663),  time:40.393, tt:969.440\n",
      "Ep:24, loss:0.00015, loss_test:0.11460, lr:9.04e-03, fs:0.66986 (r=0.707,p=0.636),  time:40.455, tt:1011.365\n",
      "Ep:25, loss:0.00015, loss_test:0.11879, lr:8.95e-03, fs:0.65657 (r=0.657,p=0.657),  time:40.571, tt:1054.857\n",
      "Ep:26, loss:0.00014, loss_test:0.11582, lr:8.86e-03, fs:0.67647 (r=0.697,p=0.657),  time:40.608, tt:1096.421\n",
      "Ep:27, loss:0.00014, loss_test:0.12155, lr:8.78e-03, fs:0.66667 (r=0.667,p=0.667),  time:40.598, tt:1136.748\n",
      "Ep:28, loss:0.00014, loss_test:0.11901, lr:8.69e-03, fs:0.69000 (r=0.697,p=0.683),  time:40.641, tt:1178.583\n",
      "Ep:29, loss:0.00013, loss_test:0.12110, lr:8.60e-03, fs:0.67677 (r=0.677,p=0.677),  time:40.692, tt:1220.748\n",
      "Ep:30, loss:0.00013, loss_test:0.11794, lr:8.51e-03, fs:0.68657 (r=0.697,p=0.676),  time:40.753, tt:1263.342\n",
      "Ep:31, loss:0.00013, loss_test:0.11809, lr:8.43e-03, fs:0.67337 (r=0.677,p=0.670),  time:40.748, tt:1303.948\n",
      "Ep:32, loss:0.00013, loss_test:0.12595, lr:8.35e-03, fs:0.64211 (r=0.616,p=0.670),  time:40.823, tt:1347.156\n",
      "Ep:33, loss:0.00013, loss_test:0.12305, lr:8.26e-03, fs:0.68041 (r=0.667,p=0.695),  time:40.842, tt:1388.644\n",
      "Ep:34, loss:0.00012, loss_test:0.12467, lr:8.18e-03, fs:0.64921 (r=0.626,p=0.674),  time:40.844, tt:1429.542\n",
      "Ep:35, loss:0.00012, loss_test:0.12225, lr:8.10e-03, fs:0.66321 (r=0.646,p=0.681),  time:40.812, tt:1469.244\n",
      "Ep:36, loss:0.00012, loss_test:0.12704, lr:8.02e-03, fs:0.63830 (r=0.606,p=0.674),  time:40.860, tt:1511.831\n",
      "Ep:37, loss:0.00012, loss_test:0.12545, lr:7.94e-03, fs:0.63830 (r=0.606,p=0.674),  time:40.876, tt:1553.281\n",
      "Ep:38, loss:0.00011, loss_test:0.11663, lr:7.86e-03, fs:0.67327 (r=0.687,p=0.660),  time:40.933, tt:1596.391\n",
      "Ep:39, loss:0.00011, loss_test:0.13303, lr:7.78e-03, fs:0.63830 (r=0.606,p=0.674),  time:40.980, tt:1639.214\n",
      "Ep:40, loss:0.00012, loss_test:0.12637, lr:7.70e-03, fs:0.65241 (r=0.616,p=0.693),  time:40.971, tt:1679.814\n",
      "Ep:41, loss:0.00012, loss_test:0.11928, lr:7.62e-03, fs:0.67347 (r=0.667,p=0.680),  time:40.994, tt:1721.733\n",
      "Ep:42, loss:0.00011, loss_test:0.13290, lr:7.55e-03, fs:0.64171 (r=0.606,p=0.682),  time:41.033, tt:1764.403\n",
      "Ep:43, loss:0.00011, loss_test:0.11637, lr:7.47e-03, fs:0.67662 (r=0.687,p=0.667),  time:41.031, tt:1805.367\n",
      "Ep:44, loss:0.00011, loss_test:0.13387, lr:7.40e-03, fs:0.63388 (r=0.586,p=0.690),  time:41.026, tt:1846.162\n",
      "Ep:45, loss:0.00010, loss_test:0.11830, lr:7.32e-03, fs:0.66667 (r=0.667,p=0.667),  time:41.021, tt:1886.945\n",
      "Ep:46, loss:0.00010, loss_test:0.13742, lr:7.25e-03, fs:0.62222 (r=0.566,p=0.691),  time:41.039, tt:1928.832\n",
      "Ep:47, loss:0.00010, loss_test:0.11751, lr:7.18e-03, fs:0.66321 (r=0.646,p=0.681),  time:41.059, tt:1970.811\n",
      "Ep:48, loss:0.00010, loss_test:0.13527, lr:7.11e-03, fs:0.62295 (r=0.576,p=0.679),  time:41.100, tt:2013.921\n",
      "Ep:49, loss:0.00010, loss_test:0.12491, lr:7.03e-03, fs:0.63333 (r=0.576,p=0.704),  time:41.114, tt:2055.681\n",
      "Ep:50, loss:0.00010, loss_test:0.12749, lr:6.96e-03, fs:0.64773 (r=0.576,p=0.740),  time:41.180, tt:2100.164\n",
      "Ep:51, loss:0.00009, loss_test:0.12978, lr:6.89e-03, fs:0.65217 (r=0.606,p=0.706),  time:41.194, tt:2142.087\n",
      "Ep:52, loss:0.00009, loss_test:0.12273, lr:6.83e-03, fs:0.63736 (r=0.586,p=0.699),  time:41.206, tt:2183.920\n",
      "Ep:53, loss:0.00009, loss_test:0.13365, lr:6.76e-03, fs:0.65909 (r=0.586,p=0.753),  time:41.241, tt:2226.996\n",
      "Ep:54, loss:0.00008, loss_test:0.12305, lr:6.69e-03, fs:0.64088 (r=0.586,p=0.707),  time:41.204, tt:2266.216\n",
      "Ep:55, loss:0.00008, loss_test:0.13841, lr:6.62e-03, fs:0.65556 (r=0.596,p=0.728),  time:41.227, tt:2308.713\n",
      "Ep:56, loss:0.00008, loss_test:0.12299, lr:6.56e-03, fs:0.65556 (r=0.596,p=0.728),  time:41.228, tt:2349.994\n",
      "Ep:57, loss:0.00008, loss_test:0.13629, lr:6.49e-03, fs:0.65909 (r=0.586,p=0.753),  time:41.240, tt:2391.941\n",
      "Ep:58, loss:0.00008, loss_test:0.12661, lr:6.43e-03, fs:0.65922 (r=0.596,p=0.738),  time:41.225, tt:2432.300\n",
      "Ep:59, loss:0.00007, loss_test:0.12894, lr:6.36e-03, fs:0.65909 (r=0.586,p=0.753),  time:41.234, tt:2474.016\n",
      "Ep:60, loss:0.00007, loss_test:0.13611, lr:6.30e-03, fs:0.67816 (r=0.596,p=0.787),  time:41.226, tt:2514.759\n",
      "Ep:61, loss:0.00007, loss_test:0.12255, lr:6.24e-03, fs:0.67416 (r=0.606,p=0.759),  time:41.203, tt:2554.582\n",
      "Ep:62, loss:0.00006, loss_test:0.13795, lr:6.17e-03, fs:0.68927 (r=0.616,p=0.782),  time:41.220, tt:2596.860\n",
      "Ep:63, loss:0.00006, loss_test:0.13083, lr:6.11e-03, fs:0.68208 (r=0.596,p=0.797),  time:41.235, tt:2639.072\n",
      "Ep:64, loss:0.00006, loss_test:0.12822, lr:6.05e-03, fs:0.69274 (r=0.626,p=0.775),  time:41.261, tt:2681.987\n",
      "Ep:65, loss:0.00006, loss_test:0.13589, lr:5.99e-03, fs:0.68571 (r=0.606,p=0.789),  time:41.291, tt:2725.212\n",
      "Ep:66, loss:0.00006, loss_test:0.13074, lr:5.93e-03, fs:0.69006 (r=0.596,p=0.819),  time:41.296, tt:2766.828\n",
      "Ep:67, loss:0.00005, loss_test:0.13672, lr:5.87e-03, fs:0.67816 (r=0.596,p=0.787),  time:41.326, tt:2810.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00005, loss_test:0.13455, lr:5.81e-03, fs:0.68605 (r=0.596,p=0.808),  time:41.339, tt:2852.384\n",
      "Ep:69, loss:0.00005, loss_test:0.12891, lr:5.75e-03, fs:0.69714 (r=0.616,p=0.803),  time:41.355, tt:2894.819\n",
      "Ep:70, loss:0.00005, loss_test:0.13678, lr:5.70e-03, fs:0.70455 (r=0.626,p=0.805),  time:41.374, tt:2937.542\n",
      "Ep:71, loss:0.00005, loss_test:0.12772, lr:5.64e-03, fs:0.71186 (r=0.636,p=0.808),  time:41.419, tt:2982.196\n",
      "Ep:72, loss:0.00005, loss_test:0.13337, lr:5.58e-03, fs:0.68966 (r=0.606,p=0.800),  time:41.418, tt:3023.518\n",
      "Ep:73, loss:0.00004, loss_test:0.13656, lr:5.53e-03, fs:0.68966 (r=0.606,p=0.800),  time:41.411, tt:3064.436\n",
      "Ep:74, loss:0.00004, loss_test:0.13224, lr:5.47e-03, fs:0.70520 (r=0.616,p=0.824),  time:41.413, tt:3105.937\n",
      "Ep:75, loss:0.00004, loss_test:0.13174, lr:5.42e-03, fs:0.72316 (r=0.646,p=0.821),  time:41.422, tt:3148.067\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.13681, lr:5.42e-03, fs:0.69006 (r=0.596,p=0.819),  time:41.427, tt:3189.872\n",
      "Ep:77, loss:0.00004, loss_test:0.14048, lr:5.42e-03, fs:0.68235 (r=0.586,p=0.817),  time:41.428, tt:3231.396\n",
      "Ep:78, loss:0.00004, loss_test:0.13162, lr:5.42e-03, fs:0.73143 (r=0.646,p=0.842),  time:41.450, tt:3274.564\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.13014, lr:5.42e-03, fs:0.73143 (r=0.646,p=0.842),  time:41.466, tt:3317.294\n",
      "Ep:80, loss:0.00004, loss_test:0.14155, lr:5.42e-03, fs:0.67836 (r=0.586,p=0.806),  time:41.477, tt:3359.629\n",
      "Ep:81, loss:0.00004, loss_test:0.13523, lr:5.42e-03, fs:0.70175 (r=0.606,p=0.833),  time:41.493, tt:3402.443\n",
      "Ep:82, loss:0.00003, loss_test:0.12932, lr:5.42e-03, fs:0.72727 (r=0.646,p=0.831),  time:41.501, tt:3444.581\n",
      "Ep:83, loss:0.00004, loss_test:0.14472, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.492, tt:3485.327\n",
      "Ep:84, loss:0.00004, loss_test:0.13551, lr:5.42e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.506, tt:3528.038\n",
      "Ep:85, loss:0.00003, loss_test:0.13228, lr:5.42e-03, fs:0.69006 (r=0.596,p=0.819),  time:41.521, tt:3570.807\n",
      "Ep:86, loss:0.00003, loss_test:0.14130, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.536, tt:3613.597\n",
      "Ep:87, loss:0.00003, loss_test:0.12927, lr:5.42e-03, fs:0.69364 (r=0.606,p=0.811),  time:41.535, tt:3655.118\n",
      "Ep:88, loss:0.00003, loss_test:0.14032, lr:5.42e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.554, tt:3698.271\n",
      "Ep:89, loss:0.00003, loss_test:0.14041, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.572, tt:3741.515\n",
      "Ep:90, loss:0.00003, loss_test:0.13124, lr:5.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:41.584, tt:3784.161\n",
      "Ep:91, loss:0.00003, loss_test:0.13369, lr:5.31e-03, fs:0.68235 (r=0.586,p=0.817),  time:41.567, tt:3824.183\n",
      "Ep:92, loss:0.00003, loss_test:0.13903, lr:5.26e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.547, tt:3863.840\n",
      "Ep:93, loss:0.00003, loss_test:0.12893, lr:5.20e-03, fs:0.73446 (r=0.657,p=0.833),  time:41.573, tt:3907.886\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00003, loss_test:0.14512, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.559, tt:3948.063\n",
      "Ep:95, loss:0.00003, loss_test:0.13030, lr:5.20e-03, fs:0.68639 (r=0.586,p=0.829),  time:41.560, tt:3989.803\n",
      "Ep:96, loss:0.00003, loss_test:0.13616, lr:5.20e-03, fs:0.69822 (r=0.596,p=0.843),  time:41.545, tt:4029.832\n",
      "Ep:97, loss:0.00003, loss_test:0.13508, lr:5.20e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.550, tt:4071.936\n",
      "Ep:98, loss:0.00002, loss_test:0.13490, lr:5.20e-03, fs:0.70588 (r=0.606,p=0.845),  time:41.567, tt:4115.102\n",
      "Ep:99, loss:0.00002, loss_test:0.13593, lr:5.20e-03, fs:0.68639 (r=0.586,p=0.829),  time:41.575, tt:4157.486\n",
      "Ep:100, loss:0.00002, loss_test:0.13446, lr:5.20e-03, fs:0.71006 (r=0.606,p=0.857),  time:41.560, tt:4197.596\n",
      "Ep:101, loss:0.00002, loss_test:0.13478, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.572, tt:4240.300\n",
      "Ep:102, loss:0.00002, loss_test:0.13459, lr:5.20e-03, fs:0.69822 (r=0.596,p=0.843),  time:41.586, tt:4283.307\n",
      "Ep:103, loss:0.00002, loss_test:0.13463, lr:5.20e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.587, tt:4325.047\n",
      "Ep:104, loss:0.00002, loss_test:0.13997, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.591, tt:4367.019\n",
      "Ep:105, loss:0.00002, loss_test:0.13258, lr:5.15e-03, fs:0.70588 (r=0.606,p=0.845),  time:41.591, tt:4408.643\n",
      "Ep:106, loss:0.00002, loss_test:0.13796, lr:5.10e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.597, tt:4450.844\n",
      "Ep:107, loss:0.00002, loss_test:0.13528, lr:5.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.615, tt:4494.456\n",
      "Ep:108, loss:0.00002, loss_test:0.13644, lr:5.00e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.622, tt:4536.770\n",
      "Ep:109, loss:0.00002, loss_test:0.14001, lr:4.95e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.646, tt:4581.043\n",
      "Ep:110, loss:0.00002, loss_test:0.13498, lr:4.90e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.640, tt:4622.034\n",
      "Ep:111, loss:0.00002, loss_test:0.13358, lr:4.85e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.636, tt:4663.235\n",
      "Ep:112, loss:0.00002, loss_test:0.14017, lr:4.80e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.625, tt:4703.597\n",
      "Ep:113, loss:0.00002, loss_test:0.13439, lr:4.75e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.619, tt:4744.597\n",
      "Ep:114, loss:0.00002, loss_test:0.13974, lr:4.71e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.630, tt:4787.496\n",
      "Ep:115, loss:0.00002, loss_test:0.13432, lr:4.66e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.645, tt:4830.796\n",
      "Ep:116, loss:0.00002, loss_test:0.13958, lr:4.61e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.657, tt:4873.825\n",
      "Ep:117, loss:0.00002, loss_test:0.13599, lr:4.57e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.650, tt:4914.691\n",
      "Ep:118, loss:0.00002, loss_test:0.13316, lr:4.52e-03, fs:0.74713 (r=0.657,p=0.867),  time:41.672, tt:4958.918\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.14010, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.672, tt:5000.641\n",
      "Ep:120, loss:0.00002, loss_test:0.13585, lr:4.52e-03, fs:0.71006 (r=0.606,p=0.857),  time:41.688, tt:5044.202\n",
      "Ep:121, loss:0.00001, loss_test:0.13657, lr:4.52e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.682, tt:5085.185\n",
      "Ep:122, loss:0.00001, loss_test:0.13776, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.678, tt:5126.437\n",
      "Ep:123, loss:0.00001, loss_test:0.13588, lr:4.52e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.666, tt:5166.550\n",
      "Ep:124, loss:0.00001, loss_test:0.13930, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.685, tt:5210.623\n",
      "Ep:125, loss:0.00001, loss_test:0.13623, lr:4.52e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.681, tt:5251.860\n",
      "Ep:126, loss:0.00001, loss_test:0.14005, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.661, tt:5290.912\n",
      "Ep:127, loss:0.00001, loss_test:0.13851, lr:4.52e-03, fs:0.68675 (r=0.576,p=0.851),  time:41.650, tt:5331.244\n",
      "Ep:128, loss:0.00001, loss_test:0.14255, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.685, tt:5377.301\n",
      "Ep:129, loss:0.00001, loss_test:0.13986, lr:4.52e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.709, tt:5422.192\n",
      "Ep:130, loss:0.00001, loss_test:0.14129, lr:4.48e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.722, tt:5465.572\n",
      "Ep:131, loss:0.00001, loss_test:0.14114, lr:4.43e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.732, tt:5508.619\n",
      "Ep:132, loss:0.00001, loss_test:0.14075, lr:4.39e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.721, tt:5548.854\n",
      "Ep:133, loss:0.00001, loss_test:0.14222, lr:4.34e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.721, tt:5590.551\n",
      "Ep:134, loss:0.00001, loss_test:0.14032, lr:4.30e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.728, tt:5633.287\n",
      "Ep:135, loss:0.00001, loss_test:0.13986, lr:4.26e-03, fs:0.68263 (r=0.576,p=0.838),  time:41.747, tt:5677.616\n",
      "Ep:136, loss:0.00001, loss_test:0.14539, lr:4.21e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.735, tt:5717.631\n",
      "Ep:137, loss:0.00001, loss_test:0.13837, lr:4.17e-03, fs:0.68263 (r=0.576,p=0.838),  time:41.723, tt:5757.821\n",
      "Ep:138, loss:0.00001, loss_test:0.14418, lr:4.13e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.707, tt:5797.318\n",
      "Ep:139, loss:0.00001, loss_test:0.13910, lr:4.09e-03, fs:0.68263 (r=0.576,p=0.838),  time:41.722, tt:5841.086\n",
      "Ep:140, loss:0.00001, loss_test:0.14090, lr:4.05e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.721, tt:5882.641\n",
      "Ep:141, loss:0.00001, loss_test:0.14094, lr:4.01e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.721, tt:5924.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.14081, lr:3.97e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.719, tt:5965.882\n",
      "Ep:143, loss:0.00001, loss_test:0.14010, lr:3.93e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.722, tt:6008.011\n",
      "Ep:144, loss:0.00001, loss_test:0.14182, lr:3.89e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.723, tt:6049.823\n",
      "Ep:145, loss:0.00001, loss_test:0.14147, lr:3.85e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.723, tt:6091.547\n",
      "Ep:146, loss:0.00001, loss_test:0.14050, lr:3.81e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.748, tt:6136.970\n",
      "Ep:147, loss:0.00001, loss_test:0.14090, lr:3.77e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.746, tt:6178.406\n",
      "Ep:148, loss:0.00001, loss_test:0.13978, lr:3.73e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.747, tt:6220.273\n",
      "Ep:149, loss:0.00001, loss_test:0.14139, lr:3.70e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.752, tt:6262.730\n",
      "Ep:150, loss:0.00001, loss_test:0.14210, lr:3.66e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.746, tt:6303.690\n",
      "Ep:151, loss:0.00001, loss_test:0.14215, lr:3.62e-03, fs:0.69512 (r=0.576,p=0.877),  time:41.756, tt:6346.859\n",
      "Ep:152, loss:0.00001, loss_test:0.14152, lr:3.59e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.765, tt:6389.995\n",
      "Ep:153, loss:0.00001, loss_test:0.14256, lr:3.55e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.774, tt:6433.209\n",
      "Ep:154, loss:0.00001, loss_test:0.14061, lr:3.52e-03, fs:0.68675 (r=0.576,p=0.851),  time:41.778, tt:6475.552\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13447, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:17.449, tt:17.449\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13421, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:16.542, tt:33.084\n",
      "Ep:2, loss:0.00026, loss_test:0.13363, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:17.049, tt:51.148\n",
      "Ep:3, loss:0.00025, loss_test:0.13284, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:17.300, tt:69.199\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13161, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:17.161, tt:85.806\n",
      "Ep:5, loss:0.00025, loss_test:0.13025, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:16.921, tt:101.523\n",
      "Ep:6, loss:0.00025, loss_test:0.12883, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:17.294, tt:121.059\n",
      "Ep:7, loss:0.00024, loss_test:0.12734, lr:1.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:17.242, tt:137.936\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12564, lr:1.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:17.536, tt:157.828\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.12353, lr:1.00e-02, fs:0.64979 (r=0.778,p=0.558),  time:17.815, tt:178.149\n",
      "Ep:10, loss:0.00024, loss_test:0.12074, lr:1.00e-02, fs:0.65254 (r=0.778,p=0.562),  time:17.954, tt:197.492\n",
      "Ep:11, loss:0.00023, loss_test:0.11808, lr:1.00e-02, fs:0.65254 (r=0.778,p=0.562),  time:17.882, tt:214.582\n",
      "Ep:12, loss:0.00023, loss_test:0.11501, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:17.915, tt:232.899\n",
      "Ep:13, loss:0.00022, loss_test:0.11147, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:17.903, tt:250.641\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.10913, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:17.875, tt:268.125\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.10627, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:18.169, tt:290.710\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.10360, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:18.237, tt:310.021\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.10323, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:18.183, tt:327.299\n",
      "Ep:18, loss:0.00020, loss_test:0.10047, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:18.159, tt:345.016\n",
      "Ep:19, loss:0.00019, loss_test:0.10090, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:18.118, tt:362.363\n",
      "Ep:20, loss:0.00019, loss_test:0.09879, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:18.056, tt:379.174\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09772, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:18.035, tt:396.779\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.09610, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:18.101, tt:416.325\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.09570, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:18.067, tt:433.613\n",
      "Ep:24, loss:0.00017, loss_test:0.09570, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:18.031, tt:450.777\n",
      "Ep:25, loss:0.00016, loss_test:0.09395, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:17.996, tt:467.894\n",
      "Ep:26, loss:0.00016, loss_test:0.09257, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:17.893, tt:483.098\n",
      "Ep:27, loss:0.00015, loss_test:0.09262, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:17.895, tt:501.073\n",
      "Ep:28, loss:0.00015, loss_test:0.09218, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:17.964, tt:520.951\n",
      "Ep:29, loss:0.00014, loss_test:0.09206, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:17.959, tt:538.777\n",
      "Ep:30, loss:0.00014, loss_test:0.09340, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:17.902, tt:554.959\n",
      "Ep:31, loss:0.00013, loss_test:0.09277, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:17.928, tt:573.698\n",
      "Ep:32, loss:0.00013, loss_test:0.09203, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:17.963, tt:592.782\n",
      "Ep:33, loss:0.00012, loss_test:0.09530, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:17.990, tt:611.646\n",
      "Ep:34, loss:0.00012, loss_test:0.09415, lr:9.90e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.046, tt:631.614\n",
      "Ep:35, loss:0.00011, loss_test:0.09205, lr:9.80e-03, fs:0.74510 (r=0.768,p=0.724),  time:18.012, tt:648.425\n",
      "Ep:36, loss:0.00011, loss_test:0.09783, lr:9.70e-03, fs:0.71658 (r=0.677,p=0.761),  time:17.967, tt:664.769\n",
      "Ep:37, loss:0.00010, loss_test:0.09443, lr:9.61e-03, fs:0.70051 (r=0.697,p=0.704),  time:17.952, tt:682.182\n",
      "Ep:38, loss:0.00010, loss_test:0.09259, lr:9.51e-03, fs:0.71154 (r=0.747,p=0.679),  time:17.919, tt:698.858\n",
      "Ep:39, loss:0.00010, loss_test:0.09411, lr:9.41e-03, fs:0.72727 (r=0.687,p=0.773),  time:17.947, tt:717.890\n",
      "Ep:40, loss:0.00010, loss_test:0.08984, lr:9.32e-03, fs:0.73298 (r=0.707,p=0.761),  time:17.949, tt:735.909\n",
      "Ep:41, loss:0.00009, loss_test:0.09292, lr:9.23e-03, fs:0.67429 (r=0.596,p=0.776),  time:17.896, tt:751.643\n",
      "Ep:42, loss:0.00008, loss_test:0.09277, lr:9.14e-03, fs:0.65574 (r=0.606,p=0.714),  time:17.889, tt:769.242\n",
      "Ep:43, loss:0.00008, loss_test:0.09406, lr:9.04e-03, fs:0.68108 (r=0.636,p=0.733),  time:17.927, tt:788.804\n",
      "Ep:44, loss:0.00008, loss_test:0.09606, lr:8.95e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.962, tt:808.279\n",
      "Ep:45, loss:0.00007, loss_test:0.09401, lr:8.86e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.974, tt:826.802\n",
      "Ep:46, loss:0.00007, loss_test:0.09440, lr:8.78e-03, fs:0.67816 (r=0.596,p=0.787),  time:17.995, tt:845.787\n",
      "Ep:47, loss:0.00006, loss_test:0.09509, lr:8.69e-03, fs:0.67052 (r=0.586,p=0.784),  time:17.958, tt:861.995\n",
      "Ep:48, loss:0.00006, loss_test:0.09261, lr:8.60e-03, fs:0.68966 (r=0.606,p=0.800),  time:17.978, tt:880.899\n",
      "Ep:49, loss:0.00006, loss_test:0.09846, lr:8.51e-03, fs:0.67816 (r=0.596,p=0.787),  time:17.958, tt:897.892\n",
      "Ep:50, loss:0.00005, loss_test:0.09578, lr:8.43e-03, fs:0.68605 (r=0.596,p=0.808),  time:17.934, tt:914.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00005, loss_test:0.09342, lr:8.35e-03, fs:0.69613 (r=0.636,p=0.768),  time:17.885, tt:930.043\n",
      "Ep:52, loss:0.00005, loss_test:0.08908, lr:8.26e-03, fs:0.71795 (r=0.707,p=0.729),  time:17.912, tt:949.347\n",
      "Ep:53, loss:0.00006, loss_test:0.10340, lr:8.18e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.914, tt:967.369\n",
      "Ep:54, loss:0.00005, loss_test:0.09846, lr:8.10e-03, fs:0.69006 (r=0.596,p=0.819),  time:17.916, tt:985.390\n",
      "Ep:55, loss:0.00005, loss_test:0.09885, lr:8.02e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.913, tt:1003.113\n",
      "Ep:56, loss:0.00004, loss_test:0.09812, lr:7.94e-03, fs:0.67052 (r=0.586,p=0.784),  time:17.967, tt:1024.139\n",
      "Ep:57, loss:0.00004, loss_test:0.10194, lr:7.86e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.988, tt:1043.313\n",
      "Ep:58, loss:0.00004, loss_test:0.10052, lr:7.78e-03, fs:0.68235 (r=0.586,p=0.817),  time:18.023, tt:1063.375\n",
      "Ep:59, loss:0.00004, loss_test:0.10354, lr:7.70e-03, fs:0.66286 (r=0.586,p=0.763),  time:18.053, tt:1083.158\n",
      "Ep:60, loss:0.00004, loss_test:0.10101, lr:7.62e-03, fs:0.67442 (r=0.586,p=0.795),  time:18.043, tt:1100.638\n",
      "Ep:61, loss:0.00003, loss_test:0.10611, lr:7.55e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.045, tt:1118.815\n",
      "Ep:62, loss:0.00003, loss_test:0.09948, lr:7.47e-03, fs:0.66667 (r=0.586,p=0.773),  time:18.035, tt:1136.205\n",
      "Ep:63, loss:0.00003, loss_test:0.10529, lr:7.40e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.033, tt:1154.080\n",
      "Ep:64, loss:0.00003, loss_test:0.10308, lr:7.32e-03, fs:0.71765 (r=0.616,p=0.859),  time:18.017, tt:1171.119\n",
      "Ep:65, loss:0.00003, loss_test:0.09699, lr:7.25e-03, fs:0.66667 (r=0.586,p=0.773),  time:18.010, tt:1188.656\n",
      "Ep:66, loss:0.00003, loss_test:0.11141, lr:7.18e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.996, tt:1205.755\n",
      "Ep:67, loss:0.00003, loss_test:0.10220, lr:7.11e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.969, tt:1221.886\n",
      "Ep:68, loss:0.00003, loss_test:0.10200, lr:7.03e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.962, tt:1239.405\n",
      "Ep:69, loss:0.00003, loss_test:0.10561, lr:6.96e-03, fs:0.70659 (r=0.596,p=0.868),  time:17.935, tt:1255.441\n",
      "Ep:70, loss:0.00003, loss_test:0.10309, lr:6.89e-03, fs:0.67442 (r=0.586,p=0.795),  time:17.908, tt:1271.483\n",
      "Ep:71, loss:0.00003, loss_test:0.10307, lr:6.83e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.917, tt:1290.038\n",
      "Ep:72, loss:0.00003, loss_test:0.10598, lr:6.76e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.909, tt:1307.379\n",
      "Ep:73, loss:0.00003, loss_test:0.10640, lr:6.69e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.903, tt:1324.858\n",
      "Ep:74, loss:0.00002, loss_test:0.10132, lr:6.62e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.887, tt:1341.562\n",
      "Ep:75, loss:0.00003, loss_test:0.10314, lr:6.56e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.869, tt:1358.062\n",
      "Ep:76, loss:0.00002, loss_test:0.10612, lr:6.49e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.853, tt:1374.695\n",
      "Ep:77, loss:0.00002, loss_test:0.10529, lr:6.43e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.852, tt:1392.489\n",
      "Ep:78, loss:0.00002, loss_test:0.10608, lr:6.36e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.848, tt:1409.955\n",
      "Ep:79, loss:0.00002, loss_test:0.10632, lr:6.30e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.820, tt:1425.579\n",
      "Ep:80, loss:0.00002, loss_test:0.10672, lr:6.24e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.822, tt:1443.566\n",
      "Ep:81, loss:0.00002, loss_test:0.10495, lr:6.17e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.820, tt:1461.273\n",
      "Ep:82, loss:0.00002, loss_test:0.10314, lr:6.11e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.811, tt:1478.346\n",
      "Ep:83, loss:0.00002, loss_test:0.10506, lr:6.05e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.801, tt:1495.277\n",
      "Ep:84, loss:0.00002, loss_test:0.10526, lr:5.99e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.792, tt:1512.305\n",
      "Ep:85, loss:0.00002, loss_test:0.10228, lr:5.93e-03, fs:0.67836 (r=0.586,p=0.806),  time:17.774, tt:1528.555\n",
      "Ep:86, loss:0.00002, loss_test:0.10482, lr:5.87e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.765, tt:1545.534\n",
      "Ep:87, loss:0.00002, loss_test:0.10632, lr:5.81e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.763, tt:1563.177\n",
      "Ep:88, loss:0.00002, loss_test:0.10291, lr:5.75e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.760, tt:1580.658\n",
      "Ep:89, loss:0.00002, loss_test:0.10727, lr:5.70e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.717, tt:1594.574\n",
      "Ep:90, loss:0.00001, loss_test:0.10468, lr:5.64e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.672, tt:1608.188\n",
      "Ep:91, loss:0.00001, loss_test:0.10441, lr:5.58e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.617, tt:1620.775\n",
      "Ep:92, loss:0.00001, loss_test:0.10626, lr:5.53e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.585, tt:1635.446\n",
      "Ep:93, loss:0.00001, loss_test:0.10571, lr:5.47e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.572, tt:1651.744\n",
      "Ep:94, loss:0.00001, loss_test:0.10592, lr:5.42e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.561, tt:1668.252\n",
      "Ep:95, loss:0.00001, loss_test:0.10498, lr:5.36e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.535, tt:1683.343\n",
      "Ep:96, loss:0.00001, loss_test:0.10479, lr:5.31e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.498, tt:1697.310\n",
      "Ep:97, loss:0.00001, loss_test:0.10541, lr:5.26e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.451, tt:1710.155\n",
      "Ep:98, loss:0.00001, loss_test:0.10505, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.429, tt:1725.468\n",
      "Ep:99, loss:0.00001, loss_test:0.10489, lr:5.15e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.427, tt:1742.692\n",
      "Ep:100, loss:0.00001, loss_test:0.10430, lr:5.10e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.422, tt:1759.650\n",
      "Ep:101, loss:0.00001, loss_test:0.10676, lr:5.05e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.411, tt:1775.961\n",
      "Ep:102, loss:0.00001, loss_test:0.10325, lr:5.00e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.405, tt:1792.729\n",
      "Ep:103, loss:0.00001, loss_test:0.10501, lr:4.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.412, tt:1810.835\n",
      "Ep:104, loss:0.00001, loss_test:0.10375, lr:4.90e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.401, tt:1827.116\n",
      "Ep:105, loss:0.00001, loss_test:0.10741, lr:4.85e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.400, tt:1844.385\n",
      "Ep:106, loss:0.00001, loss_test:0.10538, lr:4.80e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.404, tt:1862.187\n",
      "Ep:107, loss:0.00001, loss_test:0.10312, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.390, tt:1878.102\n",
      "Ep:108, loss:0.00001, loss_test:0.10890, lr:4.71e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.391, tt:1895.569\n",
      "Ep:109, loss:0.00001, loss_test:0.10553, lr:4.66e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.399, tt:1913.921\n",
      "Ep:110, loss:0.00001, loss_test:0.10717, lr:4.61e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.400, tt:1931.402\n",
      "Ep:111, loss:0.00001, loss_test:0.10481, lr:4.57e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.393, tt:1948.038\n",
      "Ep:112, loss:0.00001, loss_test:0.10548, lr:4.52e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.399, tt:1966.103\n",
      "Ep:113, loss:0.00001, loss_test:0.10508, lr:4.48e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.387, tt:1982.090\n",
      "Ep:114, loss:0.00001, loss_test:0.10487, lr:4.43e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.388, tt:1999.622\n",
      "Ep:115, loss:0.00001, loss_test:0.10605, lr:4.39e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.388, tt:2016.958\n",
      "Ep:116, loss:0.00001, loss_test:0.10347, lr:4.34e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.371, tt:2032.430\n",
      "Ep:117, loss:0.00001, loss_test:0.10633, lr:4.30e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.375, tt:2050.200\n",
      "Ep:118, loss:0.00001, loss_test:0.10524, lr:4.26e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.389, tt:2069.308\n",
      "Ep:119, loss:0.00001, loss_test:0.10588, lr:4.21e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.364, tt:2083.697\n",
      "Ep:120, loss:0.00001, loss_test:0.10698, lr:4.17e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.369, tt:2101.628\n",
      "Ep:121, loss:0.00001, loss_test:0.10472, lr:4.13e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.371, tt:2119.265\n",
      "Ep:122, loss:0.00001, loss_test:0.10557, lr:4.09e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.369, tt:2136.371\n",
      "Ep:123, loss:0.00001, loss_test:0.10485, lr:4.05e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.358, tt:2152.333\n",
      "Ep:124, loss:0.00001, loss_test:0.10528, lr:4.01e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.344, tt:2167.948\n",
      "Ep:125, loss:0.00001, loss_test:0.10503, lr:3.97e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.346, tt:2185.546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00001, loss_test:0.10466, lr:3.93e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.329, tt:2200.770\n",
      "Ep:127, loss:0.00001, loss_test:0.10651, lr:3.89e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.318, tt:2216.689\n",
      "Ep:128, loss:0.00001, loss_test:0.10478, lr:3.85e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.323, tt:2234.656\n",
      "Ep:129, loss:0.00001, loss_test:0.10554, lr:3.81e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.304, tt:2249.560\n",
      "Ep:130, loss:0.00001, loss_test:0.10491, lr:3.77e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.306, tt:2267.022\n",
      "Ep:131, loss:0.00001, loss_test:0.10559, lr:3.73e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.323, tt:2286.646\n",
      "Ep:132, loss:0.00001, loss_test:0.10719, lr:3.70e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.310, tt:2302.218\n",
      "Ep:133, loss:0.00001, loss_test:0.10415, lr:3.66e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.318, tt:2320.579\n",
      "Ep:134, loss:0.00001, loss_test:0.10672, lr:3.62e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.335, tt:2340.176\n",
      "Ep:135, loss:0.00001, loss_test:0.10552, lr:3.59e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.319, tt:2355.400\n",
      "Ep:136, loss:0.00001, loss_test:0.10500, lr:3.55e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.314, tt:2372.010\n",
      "Ep:137, loss:0.00001, loss_test:0.10639, lr:3.52e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.331, tt:2391.637\n",
      "Ep:138, loss:0.00001, loss_test:0.10586, lr:3.48e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.318, tt:2407.137\n",
      "Ep:139, loss:0.00001, loss_test:0.10656, lr:3.45e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.312, tt:2423.635\n",
      "Ep:140, loss:0.00001, loss_test:0.10630, lr:3.41e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.328, tt:2443.216\n",
      "Ep:141, loss:0.00001, loss_test:0.10525, lr:3.38e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.330, tt:2460.812\n",
      "Ep:142, loss:0.00001, loss_test:0.10635, lr:3.34e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.320, tt:2476.821\n",
      "Ep:143, loss:0.00001, loss_test:0.10584, lr:3.31e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.330, tt:2495.476\n",
      "Ep:144, loss:0.00001, loss_test:0.10558, lr:3.28e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.332, tt:2513.094\n",
      "Ep:145, loss:0.00001, loss_test:0.10620, lr:3.24e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.329, tt:2530.104\n",
      "Ep:146, loss:0.00001, loss_test:0.10583, lr:3.21e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.328, tt:2547.281\n",
      "Ep:147, loss:0.00001, loss_test:0.10644, lr:3.18e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.329, tt:2564.689\n",
      "Ep:148, loss:0.00001, loss_test:0.10584, lr:3.15e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.344, tt:2584.216\n",
      "Ep:149, loss:0.00001, loss_test:0.10559, lr:3.12e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.353, tt:2602.994\n",
      "Ep:150, loss:0.00001, loss_test:0.10592, lr:3.09e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.361, tt:2621.469\n",
      "Ep:151, loss:0.00001, loss_test:0.10489, lr:3.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.360, tt:2638.652\n",
      "Ep:152, loss:0.00001, loss_test:0.10616, lr:3.02e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.371, tt:2657.721\n",
      "Ep:153, loss:0.00001, loss_test:0.10684, lr:2.99e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.384, tt:2677.152\n",
      "Ep:154, loss:0.00001, loss_test:0.10568, lr:2.96e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.373, tt:2692.774\n",
      "Ep:155, loss:0.00001, loss_test:0.10788, lr:2.93e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.382, tt:2711.543\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13944, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:21.372, tt:21.372\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13901, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:20.724, tt:41.449\n",
      "Ep:2, loss:0.00026, loss_test:0.13821, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:21.297, tt:63.891\n",
      "Ep:3, loss:0.00025, loss_test:0.13681, lr:1.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:20.302, tt:81.209\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13510, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:19.633, tt:98.167\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.13382, lr:1.00e-02, fs:0.62857 (r=0.778,p=0.527),  time:19.825, tt:118.948\n",
      "Ep:6, loss:0.00024, loss_test:0.13228, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:19.821, tt:138.747\n",
      "Ep:7, loss:0.00023, loss_test:0.13024, lr:1.00e-02, fs:0.62500 (r=0.758,p=0.532),  time:20.091, tt:160.728\n",
      "Ep:8, loss:0.00023, loss_test:0.12799, lr:1.00e-02, fs:0.62393 (r=0.737,p=0.541),  time:20.228, tt:182.050\n",
      "Ep:9, loss:0.00022, loss_test:0.12187, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:20.078, tt:200.779\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.11818, lr:1.00e-02, fs:0.63850 (r=0.687,p=0.596),  time:20.052, tt:220.577\n",
      "Ep:11, loss:0.00019, loss_test:0.11642, lr:1.00e-02, fs:0.61836 (r=0.646,p=0.593),  time:19.977, tt:239.719\n",
      "Ep:12, loss:0.00018, loss_test:0.11196, lr:1.00e-02, fs:0.62827 (r=0.606,p=0.652),  time:19.952, tt:259.370\n",
      "Ep:13, loss:0.00017, loss_test:0.10814, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:19.935, tt:279.084\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.10702, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:19.948, tt:299.223\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.10237, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:20.042, tt:320.666\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.09886, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:20.099, tt:341.682\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09919, lr:1.00e-02, fs:0.66667 (r=0.606,p=0.741),  time:20.004, tt:360.072\n",
      "Ep:18, loss:0.00013, loss_test:0.09562, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:20.082, tt:381.549\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.09753, lr:1.00e-02, fs:0.68927 (r=0.616,p=0.782),  time:20.055, tt:401.090\n",
      "Ep:20, loss:0.00011, loss_test:0.09104, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:19.977, tt:419.518\n",
      "Ep:21, loss:0.00011, loss_test:0.10101, lr:1.00e-02, fs:0.65868 (r=0.556,p=0.809),  time:19.952, tt:438.942\n",
      "Ep:22, loss:0.00010, loss_test:0.08880, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:19.882, tt:457.295\n",
      "Ep:23, loss:0.00009, loss_test:0.09191, lr:1.00e-02, fs:0.70732 (r=0.586,p=0.892),  time:19.914, tt:477.938\n",
      "Ep:24, loss:0.00009, loss_test:0.09062, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:19.974, tt:499.360\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00008, loss_test:0.08895, lr:1.00e-02, fs:0.71084 (r=0.596,p=0.881),  time:19.959, tt:518.945\n",
      "Ep:26, loss:0.00008, loss_test:0.09065, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:19.957, tt:538.837\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00008, loss_test:0.09426, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:19.885, tt:556.786\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.08455, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:19.909, tt:577.375\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00007, loss_test:0.09112, lr:1.00e-02, fs:0.71856 (r=0.606,p=0.882),  time:19.965, tt:598.960\n",
      "Ep:30, loss:0.00006, loss_test:0.08944, lr:1.00e-02, fs:0.68639 (r=0.586,p=0.829),  time:19.965, tt:618.910\n",
      "Ep:31, loss:0.00006, loss_test:0.08512, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:20.044, tt:641.422\n",
      "Ep:32, loss:0.00005, loss_test:0.07989, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:20.058, tt:661.911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00005, loss_test:0.08798, lr:1.00e-02, fs:0.72414 (r=0.636,p=0.840),  time:20.000, tt:680.016\n",
      "Ep:34, loss:0.00006, loss_test:0.08354, lr:1.00e-02, fs:0.76023 (r=0.657,p=0.903),  time:19.979, tt:699.274\n",
      "Ep:35, loss:0.00005, loss_test:0.08600, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:19.970, tt:718.936\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.09600, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:19.990, tt:739.646\n",
      "Ep:37, loss:0.00005, loss_test:0.08291, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:20.013, tt:760.492\n",
      "Ep:38, loss:0.00005, loss_test:0.08750, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:20.024, tt:780.919\n",
      "Ep:39, loss:0.00004, loss_test:0.08636, lr:1.00e-02, fs:0.70175 (r=0.606,p=0.833),  time:20.042, tt:801.688\n",
      "Ep:40, loss:0.00004, loss_test:0.08258, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:20.084, tt:823.424\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00004, loss_test:0.08317, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:20.082, tt:843.423\n",
      "Ep:42, loss:0.00004, loss_test:0.07651, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:20.095, tt:864.086\n",
      "Ep:43, loss:0.00003, loss_test:0.08996, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:20.107, tt:884.688\n",
      "Ep:44, loss:0.00003, loss_test:0.07544, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:20.140, tt:906.293\n",
      "Ep:45, loss:0.00003, loss_test:0.08669, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:20.191, tt:928.765\n",
      "Ep:46, loss:0.00003, loss_test:0.07959, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:20.175, tt:948.241\n",
      "Ep:47, loss:0.00003, loss_test:0.07813, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:20.201, tt:969.630\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.08390, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:20.198, tt:989.708\n",
      "Ep:49, loss:0.00003, loss_test:0.07569, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:20.258, tt:1012.925\n",
      "Ep:50, loss:0.00002, loss_test:0.08473, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:20.251, tt:1032.789\n",
      "Ep:51, loss:0.00002, loss_test:0.07748, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:20.265, tt:1053.774\n",
      "Ep:52, loss:0.00002, loss_test:0.08153, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:20.301, tt:1075.934\n",
      "Ep:53, loss:0.00002, loss_test:0.08097, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:20.319, tt:1097.203\n",
      "Ep:54, loss:0.00002, loss_test:0.07518, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:20.347, tt:1119.087\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.08516, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:20.410, tt:1142.952\n",
      "Ep:56, loss:0.00003, loss_test:0.08089, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.426, tt:1164.254\n",
      "Ep:57, loss:0.00003, loss_test:0.08277, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:20.439, tt:1185.442\n",
      "Ep:58, loss:0.00003, loss_test:0.08786, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:20.465, tt:1207.455\n",
      "Ep:59, loss:0.00003, loss_test:0.07028, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:20.476, tt:1228.546\n",
      "Ep:60, loss:0.00003, loss_test:0.08859, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:20.468, tt:1248.559\n",
      "Ep:61, loss:0.00002, loss_test:0.07612, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.443, tt:1267.486\n",
      "Ep:62, loss:0.00002, loss_test:0.07387, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:20.431, tt:1287.167\n",
      "Ep:63, loss:0.00002, loss_test:0.09174, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:20.432, tt:1307.637\n",
      "Ep:64, loss:0.00002, loss_test:0.07187, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:20.403, tt:1326.165\n",
      "Ep:65, loss:0.00002, loss_test:0.08452, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:20.408, tt:1346.952\n",
      "Ep:66, loss:0.00001, loss_test:0.07728, lr:9.90e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.421, tt:1368.199\n",
      "Ep:67, loss:0.00001, loss_test:0.07599, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.415, tt:1388.187\n",
      "Ep:68, loss:0.00001, loss_test:0.07837, lr:9.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:20.431, tt:1409.733\n",
      "Ep:69, loss:0.00001, loss_test:0.07541, lr:9.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:20.411, tt:1428.784\n",
      "Ep:70, loss:0.00001, loss_test:0.07871, lr:9.51e-03, fs:0.77844 (r=0.657,p=0.956),  time:20.417, tt:1449.641\n",
      "Ep:71, loss:0.00001, loss_test:0.07439, lr:9.41e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.422, tt:1470.350\n",
      "Ep:72, loss:0.00001, loss_test:0.07950, lr:9.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.413, tt:1490.115\n",
      "Ep:73, loss:0.00001, loss_test:0.07948, lr:9.23e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.438, tt:1512.375\n",
      "Ep:74, loss:0.00001, loss_test:0.07459, lr:9.14e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.454, tt:1534.038\n",
      "Ep:75, loss:0.00001, loss_test:0.08094, lr:9.04e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.472, tt:1555.891\n",
      "Ep:76, loss:0.00001, loss_test:0.07513, lr:8.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.470, tt:1576.175\n",
      "Ep:77, loss:0.00001, loss_test:0.07920, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.459, tt:1595.813\n",
      "Ep:78, loss:0.00001, loss_test:0.07993, lr:8.78e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.500, tt:1619.481\n",
      "Ep:79, loss:0.00001, loss_test:0.07637, lr:8.69e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.490, tt:1639.233\n",
      "Ep:80, loss:0.00001, loss_test:0.08050, lr:8.60e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.473, tt:1658.314\n",
      "Ep:81, loss:0.00001, loss_test:0.07782, lr:8.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.472, tt:1678.734\n",
      "Ep:82, loss:0.00001, loss_test:0.08189, lr:8.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.483, tt:1700.054\n",
      "Ep:83, loss:0.00001, loss_test:0.07668, lr:8.35e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.498, tt:1721.860\n",
      "Ep:84, loss:0.00001, loss_test:0.07970, lr:8.26e-03, fs:0.75152 (r=0.626,p=0.939),  time:20.514, tt:1743.682\n",
      "Ep:85, loss:0.00001, loss_test:0.08219, lr:8.18e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.507, tt:1763.608\n",
      "Ep:86, loss:0.00001, loss_test:0.08198, lr:8.10e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.507, tt:1784.108\n",
      "Ep:87, loss:0.00000, loss_test:0.08231, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.494, tt:1803.507\n",
      "Ep:88, loss:0.00000, loss_test:0.08251, lr:7.94e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.517, tt:1825.968\n",
      "Ep:89, loss:0.00000, loss_test:0.08138, lr:7.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.508, tt:1845.706\n",
      "Ep:90, loss:0.00000, loss_test:0.08356, lr:7.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.498, tt:1865.349\n",
      "Ep:91, loss:0.00000, loss_test:0.08238, lr:7.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.495, tt:1885.537\n",
      "Ep:92, loss:0.00000, loss_test:0.08241, lr:7.62e-03, fs:0.75449 (r=0.636,p=0.926),  time:20.478, tt:1904.486\n",
      "Ep:93, loss:0.00000, loss_test:0.08294, lr:7.55e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.479, tt:1925.065\n",
      "Ep:94, loss:0.00000, loss_test:0.08587, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.482, tt:1945.756\n",
      "Ep:95, loss:0.00000, loss_test:0.08373, lr:7.40e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.462, tt:1964.312\n",
      "Ep:96, loss:0.00000, loss_test:0.08213, lr:7.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:20.449, tt:1983.584\n",
      "Ep:97, loss:0.00000, loss_test:0.08627, lr:7.25e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.442, tt:2003.361\n",
      "Ep:98, loss:0.00000, loss_test:0.08244, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.427, tt:2022.242\n",
      "Ep:99, loss:0.00000, loss_test:0.08606, lr:7.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.442, tt:2044.164\n",
      "Ep:100, loss:0.00000, loss_test:0.08381, lr:7.03e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.429, tt:2063.323\n",
      "Ep:101, loss:0.00000, loss_test:0.08614, lr:6.96e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.431, tt:2083.926\n",
      "Ep:102, loss:0.00000, loss_test:0.08293, lr:6.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.420, tt:2103.279\n",
      "Ep:103, loss:0.00000, loss_test:0.08636, lr:6.83e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.396, tt:2121.144\n",
      "Ep:104, loss:0.00000, loss_test:0.08391, lr:6.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.410, tt:2143.100\n",
      "Ep:105, loss:0.00000, loss_test:0.08569, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.415, tt:2163.995\n",
      "Ep:106, loss:0.00000, loss_test:0.08389, lr:6.62e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.414, tt:2184.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:107, loss:0.00000, loss_test:0.08545, lr:6.56e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.422, tt:2205.549\n",
      "Ep:108, loss:0.00000, loss_test:0.08382, lr:6.49e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.420, tt:2225.833\n",
      "Ep:109, loss:0.00000, loss_test:0.08571, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.433, tt:2247.634\n",
      "Ep:110, loss:0.00000, loss_test:0.08349, lr:6.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.436, tt:2268.424\n",
      "Ep:111, loss:0.00000, loss_test:0.08521, lr:6.30e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.438, tt:2289.009\n",
      "Ep:112, loss:0.00000, loss_test:0.08548, lr:6.24e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.454, tt:2311.306\n",
      "Ep:113, loss:0.00000, loss_test:0.08412, lr:6.17e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.441, tt:2330.281\n",
      "Ep:114, loss:0.00000, loss_test:0.08440, lr:6.11e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.445, tt:2351.127\n",
      "Ep:115, loss:0.00000, loss_test:0.08446, lr:6.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.448, tt:2371.947\n",
      "Ep:116, loss:0.00000, loss_test:0.08458, lr:5.99e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.437, tt:2391.165\n",
      "Ep:117, loss:0.00000, loss_test:0.08457, lr:5.93e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.451, tt:2413.195\n",
      "Ep:118, loss:0.00000, loss_test:0.08505, lr:5.87e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.440, tt:2432.378\n",
      "Ep:119, loss:0.00000, loss_test:0.08463, lr:5.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.426, tt:2451.068\n",
      "Ep:120, loss:0.00000, loss_test:0.08415, lr:5.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.439, tt:2473.150\n",
      "Ep:121, loss:0.00000, loss_test:0.08413, lr:5.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.435, tt:2493.066\n",
      "Ep:122, loss:0.00000, loss_test:0.08552, lr:5.64e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.474, tt:2518.328\n",
      "Ep:123, loss:0.00000, loss_test:0.08439, lr:5.58e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.469, tt:2538.102\n",
      "Ep:124, loss:0.00000, loss_test:0.08567, lr:5.53e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.454, tt:2556.761\n",
      "Ep:125, loss:0.00000, loss_test:0.08482, lr:5.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.470, tt:2579.268\n",
      "Ep:126, loss:0.00000, loss_test:0.08498, lr:5.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.472, tt:2599.897\n",
      "Ep:127, loss:0.00000, loss_test:0.08485, lr:5.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.464, tt:2619.450\n",
      "Ep:128, loss:0.00000, loss_test:0.08624, lr:5.31e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.466, tt:2640.121\n",
      "Ep:129, loss:0.00000, loss_test:0.08447, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.470, tt:2661.050\n",
      "Ep:130, loss:0.00000, loss_test:0.08556, lr:5.20e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.490, tt:2684.196\n",
      "Ep:131, loss:0.00000, loss_test:0.08631, lr:5.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.491, tt:2704.788\n",
      "Ep:132, loss:0.00000, loss_test:0.08464, lr:5.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.501, tt:2726.616\n",
      "Ep:133, loss:0.00000, loss_test:0.08501, lr:5.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.492, tt:2745.863\n",
      "Ep:134, loss:0.00000, loss_test:0.08523, lr:5.00e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.482, tt:2765.058\n",
      "Ep:135, loss:0.00000, loss_test:0.08505, lr:4.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.494, tt:2787.160\n",
      "Ep:136, loss:0.00000, loss_test:0.08455, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.495, tt:2807.873\n",
      "Ep:137, loss:0.00000, loss_test:0.08618, lr:4.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.489, tt:2827.471\n",
      "Ep:138, loss:0.00000, loss_test:0.08569, lr:4.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.510, tt:2850.850\n",
      "Ep:139, loss:0.00000, loss_test:0.08621, lr:4.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.520, tt:2872.862\n",
      "Ep:140, loss:0.00000, loss_test:0.08499, lr:4.71e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.547, tt:2897.161\n",
      "Ep:141, loss:0.00000, loss_test:0.08638, lr:4.66e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.548, tt:2917.774\n",
      "Ep:142, loss:0.00000, loss_test:0.08536, lr:4.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.547, tt:2938.185\n",
      "Ep:143, loss:0.00000, loss_test:0.08601, lr:4.57e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.550, tt:2959.175\n",
      "Ep:144, loss:0.00000, loss_test:0.08599, lr:4.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.553, tt:2980.128\n",
      "Ep:145, loss:0.00000, loss_test:0.08531, lr:4.48e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.546, tt:2999.688\n",
      "Ep:146, loss:0.00000, loss_test:0.08583, lr:4.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.543, tt:3019.890\n",
      "Ep:147, loss:0.00000, loss_test:0.08570, lr:4.39e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.542, tt:3040.262\n",
      "Ep:148, loss:0.00000, loss_test:0.08508, lr:4.34e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.559, tt:3063.280\n",
      "Ep:149, loss:0.00000, loss_test:0.08537, lr:4.30e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.552, tt:3082.775\n",
      "Ep:150, loss:0.00000, loss_test:0.08687, lr:4.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.553, tt:3103.505\n",
      "Ep:151, loss:0.00000, loss_test:0.08528, lr:4.21e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.545, tt:3122.846\n",
      "Ep:152, loss:0.00000, loss_test:0.08569, lr:4.17e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.531, tt:3141.280\n",
      "Ep:153, loss:0.00000, loss_test:0.08655, lr:4.13e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.542, tt:3163.414\n",
      "Ep:154, loss:0.00000, loss_test:0.08583, lr:4.09e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.530, tt:3182.092\n",
      "Ep:155, loss:0.00000, loss_test:0.08559, lr:4.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.522, tt:3201.364\n",
      "Ep:156, loss:0.00000, loss_test:0.08508, lr:4.01e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.537, tt:3224.287\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14521, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.779, tt:37.779\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14429, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.068, tt:76.135\n",
      "Ep:2, loss:0.00028, loss_test:0.14265, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.150, tt:114.449\n",
      "Ep:3, loss:0.00027, loss_test:0.13997, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.113, tt:156.452\n",
      "Ep:4, loss:0.00027, loss_test:0.13553, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:39.662, tt:198.311\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12811, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:40.228, tt:241.366\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11745, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:40.290, tt:282.030\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11194, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:40.193, tt:321.541\n",
      "Ep:8, loss:0.00022, loss_test:0.11217, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:40.510, tt:364.592\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11136, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:40.716, tt:407.157\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10979, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:40.857, tt:449.430\n",
      "Ep:11, loss:0.00020, loss_test:0.10844, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:40.821, tt:489.852\n",
      "Ep:12, loss:0.00020, loss_test:0.10897, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:40.793, tt:530.309\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10907, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:40.799, tt:571.180\n",
      "Ep:14, loss:0.00019, loss_test:0.10801, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:40.843, tt:612.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00018, loss_test:0.10773, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:40.897, tt:654.358\n",
      "Ep:16, loss:0.00018, loss_test:0.10867, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:40.893, tt:695.173\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10897, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:40.925, tt:736.648\n",
      "Ep:18, loss:0.00017, loss_test:0.10892, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:40.909, tt:777.271\n",
      "Ep:19, loss:0.00017, loss_test:0.10913, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:41.048, tt:820.967\n",
      "Ep:20, loss:0.00016, loss_test:0.10923, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:40.989, tt:860.780\n",
      "Ep:21, loss:0.00016, loss_test:0.10961, lr:1.00e-02, fs:0.65946 (r=0.616,p=0.709),  time:40.967, tt:901.267\n",
      "Ep:22, loss:0.00015, loss_test:0.10914, lr:1.00e-02, fs:0.65946 (r=0.616,p=0.709),  time:40.983, tt:942.603\n",
      "Ep:23, loss:0.00015, loss_test:0.10917, lr:1.00e-02, fs:0.67033 (r=0.616,p=0.735),  time:40.928, tt:982.278\n",
      "Ep:24, loss:0.00015, loss_test:0.10958, lr:1.00e-02, fs:0.67033 (r=0.616,p=0.735),  time:41.033, tt:1025.818\n",
      "Ep:25, loss:0.00014, loss_test:0.10995, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:41.066, tt:1067.723\n",
      "Ep:26, loss:0.00014, loss_test:0.11055, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:41.069, tt:1108.868\n",
      "Ep:27, loss:0.00014, loss_test:0.11049, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:41.080, tt:1150.244\n",
      "Ep:28, loss:0.00014, loss_test:0.11190, lr:9.90e-03, fs:0.67778 (r=0.616,p=0.753),  time:41.013, tt:1189.387\n",
      "Ep:29, loss:0.00013, loss_test:0.11174, lr:9.80e-03, fs:0.67403 (r=0.616,p=0.744),  time:40.991, tt:1229.735\n",
      "Ep:30, loss:0.00013, loss_test:0.11167, lr:9.70e-03, fs:0.67033 (r=0.616,p=0.735),  time:40.970, tt:1270.055\n",
      "Ep:31, loss:0.00013, loss_test:0.11388, lr:9.61e-03, fs:0.68182 (r=0.606,p=0.779),  time:40.971, tt:1311.070\n",
      "Ep:32, loss:0.00012, loss_test:0.11340, lr:9.51e-03, fs:0.66667 (r=0.606,p=0.741),  time:40.975, tt:1352.161\n",
      "Ep:33, loss:0.00012, loss_test:0.11413, lr:9.41e-03, fs:0.67416 (r=0.606,p=0.759),  time:40.948, tt:1392.218\n",
      "Ep:34, loss:0.00012, loss_test:0.11501, lr:9.32e-03, fs:0.68182 (r=0.606,p=0.779),  time:41.006, tt:1435.222\n",
      "Ep:35, loss:0.00012, loss_test:0.11361, lr:9.23e-03, fs:0.67416 (r=0.606,p=0.759),  time:40.991, tt:1475.664\n",
      "Ep:36, loss:0.00011, loss_test:0.11723, lr:9.14e-03, fs:0.67442 (r=0.586,p=0.795),  time:40.982, tt:1516.326\n",
      "Ep:37, loss:0.00011, loss_test:0.11328, lr:9.04e-03, fs:0.66667 (r=0.596,p=0.756),  time:40.975, tt:1557.049\n",
      "Ep:38, loss:0.00011, loss_test:0.11650, lr:8.95e-03, fs:0.67052 (r=0.586,p=0.784),  time:40.975, tt:1598.023\n",
      "Ep:39, loss:0.00011, loss_test:0.11751, lr:8.86e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.999, tt:1639.942\n",
      "Ep:40, loss:0.00011, loss_test:0.11396, lr:8.78e-03, fs:0.67045 (r=0.596,p=0.766),  time:40.977, tt:1680.050\n",
      "Ep:41, loss:0.00010, loss_test:0.11892, lr:8.69e-03, fs:0.66272 (r=0.566,p=0.800),  time:40.964, tt:1720.501\n",
      "Ep:42, loss:0.00010, loss_test:0.11540, lr:8.60e-03, fs:0.65909 (r=0.586,p=0.753),  time:40.941, tt:1760.484\n",
      "Ep:43, loss:0.00010, loss_test:0.11822, lr:8.51e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.882, tt:1798.823\n",
      "Ep:44, loss:0.00010, loss_test:0.11636, lr:8.43e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.890, tt:1840.034\n",
      "Ep:45, loss:0.00010, loss_test:0.11828, lr:8.35e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.912, tt:1881.929\n",
      "Ep:46, loss:0.00009, loss_test:0.11902, lr:8.26e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.877, tt:1921.208\n",
      "Ep:47, loss:0.00009, loss_test:0.11556, lr:8.18e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.874, tt:1961.963\n",
      "Ep:48, loss:0.00009, loss_test:0.11974, lr:8.10e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.913, tt:2004.731\n",
      "Ep:49, loss:0.00009, loss_test:0.11831, lr:8.02e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.943, tt:2047.170\n",
      "Ep:50, loss:0.00009, loss_test:0.11719, lr:7.94e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.961, tt:2089.033\n",
      "Ep:51, loss:0.00009, loss_test:0.11892, lr:7.86e-03, fs:0.66272 (r=0.566,p=0.800),  time:40.959, tt:2129.890\n",
      "Ep:52, loss:0.00008, loss_test:0.11747, lr:7.78e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.945, tt:2170.074\n",
      "Ep:53, loss:0.00008, loss_test:0.12008, lr:7.70e-03, fs:0.66272 (r=0.566,p=0.800),  time:40.984, tt:2213.122\n",
      "Ep:54, loss:0.00008, loss_test:0.11936, lr:7.62e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.978, tt:2253.765\n",
      "Ep:55, loss:0.00008, loss_test:0.11835, lr:7.55e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.948, tt:2293.068\n",
      "Ep:56, loss:0.00008, loss_test:0.12096, lr:7.47e-03, fs:0.67470 (r=0.566,p=0.836),  time:40.952, tt:2334.253\n",
      "Ep:57, loss:0.00008, loss_test:0.11783, lr:7.40e-03, fs:0.66279 (r=0.576,p=0.781),  time:40.949, tt:2375.021\n",
      "Ep:58, loss:0.00008, loss_test:0.12076, lr:7.32e-03, fs:0.67470 (r=0.566,p=0.836),  time:40.930, tt:2414.893\n",
      "Ep:59, loss:0.00008, loss_test:0.11970, lr:7.25e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.957, tt:2457.425\n",
      "Ep:60, loss:0.00008, loss_test:0.11911, lr:7.18e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.940, tt:2497.313\n",
      "Ep:61, loss:0.00007, loss_test:0.12603, lr:7.11e-03, fs:0.67470 (r=0.566,p=0.836),  time:40.943, tt:2538.458\n",
      "Ep:62, loss:0.00007, loss_test:0.11869, lr:7.03e-03, fs:0.67059 (r=0.576,p=0.803),  time:40.953, tt:2580.042\n",
      "Ep:63, loss:0.00007, loss_test:0.12222, lr:6.96e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.969, tt:2622.037\n",
      "Ep:64, loss:0.00007, loss_test:0.12379, lr:6.89e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.967, tt:2662.825\n",
      "Ep:65, loss:0.00007, loss_test:0.11772, lr:6.83e-03, fs:0.67059 (r=0.576,p=0.803),  time:40.957, tt:2703.152\n",
      "Ep:66, loss:0.00007, loss_test:0.12275, lr:6.76e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.923, tt:2741.846\n",
      "Ep:67, loss:0.00007, loss_test:0.12268, lr:6.69e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.937, tt:2783.685\n",
      "Ep:68, loss:0.00007, loss_test:0.11893, lr:6.62e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.921, tt:2823.577\n",
      "Ep:69, loss:0.00007, loss_test:0.12322, lr:6.56e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.921, tt:2864.485\n",
      "Ep:70, loss:0.00006, loss_test:0.12382, lr:6.49e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.969, tt:2908.776\n",
      "Ep:71, loss:0.00006, loss_test:0.11784, lr:6.43e-03, fs:0.67059 (r=0.576,p=0.803),  time:40.968, tt:2949.710\n",
      "Ep:72, loss:0.00006, loss_test:0.12770, lr:6.36e-03, fs:0.66258 (r=0.545,p=0.844),  time:40.972, tt:2990.927\n",
      "Ep:73, loss:0.00006, loss_test:0.11934, lr:6.30e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.965, tt:3031.421\n",
      "Ep:74, loss:0.00006, loss_test:0.12365, lr:6.24e-03, fs:0.67066 (r=0.566,p=0.824),  time:40.946, tt:3070.953\n",
      "Ep:75, loss:0.00006, loss_test:0.12593, lr:6.17e-03, fs:0.67066 (r=0.566,p=0.824),  time:40.951, tt:3112.269\n",
      "Ep:76, loss:0.00006, loss_test:0.12033, lr:6.11e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.939, tt:3152.323\n",
      "Ep:77, loss:0.00006, loss_test:0.12723, lr:6.05e-03, fs:0.65455 (r=0.545,p=0.818),  time:40.943, tt:3193.586\n",
      "Ep:78, loss:0.00006, loss_test:0.12461, lr:5.99e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.968, tt:3236.489\n",
      "Ep:79, loss:0.00006, loss_test:0.12254, lr:5.93e-03, fs:0.66667 (r=0.566,p=0.812),  time:41.019, tt:3281.508\n",
      "Ep:80, loss:0.00006, loss_test:0.12686, lr:5.87e-03, fs:0.67066 (r=0.566,p=0.824),  time:41.015, tt:3322.211\n",
      "Ep:81, loss:0.00006, loss_test:0.12642, lr:5.81e-03, fs:0.67857 (r=0.576,p=0.826),  time:41.037, tt:3365.015\n",
      "Ep:82, loss:0.00005, loss_test:0.12411, lr:5.75e-03, fs:0.66667 (r=0.566,p=0.812),  time:41.042, tt:3406.475\n",
      "Ep:83, loss:0.00005, loss_test:0.12596, lr:5.70e-03, fs:0.66667 (r=0.566,p=0.812),  time:41.052, tt:3448.404\n",
      "Ep:84, loss:0.00005, loss_test:0.12663, lr:5.64e-03, fs:0.66265 (r=0.556,p=0.821),  time:41.058, tt:3489.916\n",
      "Ep:85, loss:0.00005, loss_test:0.12298, lr:5.58e-03, fs:0.67456 (r=0.576,p=0.814),  time:41.060, tt:3531.136\n",
      "Ep:86, loss:0.00005, loss_test:0.12945, lr:5.53e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.054, tt:3571.695\n",
      "Ep:87, loss:0.00005, loss_test:0.12387, lr:5.47e-03, fs:0.67456 (r=0.576,p=0.814),  time:41.059, tt:3613.155\n",
      "Ep:88, loss:0.00005, loss_test:0.12712, lr:5.42e-03, fs:0.65868 (r=0.556,p=0.809),  time:41.084, tt:3656.518\n",
      "Ep:89, loss:0.00005, loss_test:0.12810, lr:5.36e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.002, tt:3690.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00005, loss_test:0.12453, lr:5.31e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.989, tt:3730.045\n",
      "Ep:91, loss:0.00005, loss_test:0.12859, lr:5.26e-03, fs:0.65455 (r=0.545,p=0.818),  time:40.949, tt:3767.314\n",
      "Ep:92, loss:0.00005, loss_test:0.12825, lr:5.20e-03, fs:0.65455 (r=0.545,p=0.818),  time:40.966, tt:3809.810\n",
      "Ep:93, loss:0.00005, loss_test:0.12484, lr:5.15e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.996, tt:3853.595\n",
      "Ep:94, loss:0.00005, loss_test:0.12984, lr:5.10e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.017, tt:3896.577\n",
      "Ep:95, loss:0.00005, loss_test:0.12618, lr:5.05e-03, fs:0.67066 (r=0.566,p=0.824),  time:41.022, tt:3938.112\n",
      "Ep:96, loss:0.00005, loss_test:0.12863, lr:5.00e-03, fs:0.64634 (r=0.535,p=0.815),  time:41.053, tt:3982.121\n",
      "Ep:97, loss:0.00005, loss_test:0.12947, lr:4.95e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.045, tt:4022.372\n",
      "Ep:98, loss:0.00005, loss_test:0.12821, lr:4.90e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.053, tt:4064.241\n",
      "Ep:99, loss:0.00005, loss_test:0.12808, lr:4.85e-03, fs:0.65854 (r=0.545,p=0.831),  time:41.083, tt:4108.264\n",
      "Ep:100, loss:0.00004, loss_test:0.13073, lr:4.80e-03, fs:0.65854 (r=0.545,p=0.831),  time:41.096, tt:4150.744\n",
      "Ep:101, loss:0.00004, loss_test:0.12778, lr:4.75e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.104, tt:4192.581\n",
      "Ep:102, loss:0.00004, loss_test:0.12673, lr:4.71e-03, fs:0.66265 (r=0.556,p=0.821),  time:41.117, tt:4235.056\n",
      "Ep:103, loss:0.00004, loss_test:0.13174, lr:4.66e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.129, tt:4277.435\n",
      "Ep:104, loss:0.00004, loss_test:0.12805, lr:4.61e-03, fs:0.67066 (r=0.566,p=0.824),  time:41.143, tt:4319.966\n",
      "Ep:105, loss:0.00004, loss_test:0.12915, lr:4.57e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.172, tt:4364.229\n",
      "Ep:106, loss:0.00004, loss_test:0.13116, lr:4.52e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.174, tt:4405.618\n",
      "Ep:107, loss:0.00004, loss_test:0.12888, lr:4.48e-03, fs:0.66258 (r=0.545,p=0.844),  time:41.188, tt:4448.269\n",
      "Ep:108, loss:0.00004, loss_test:0.12974, lr:4.43e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.196, tt:4490.317\n",
      "Ep:109, loss:0.00004, loss_test:0.13064, lr:4.39e-03, fs:0.65432 (r=0.535,p=0.841),  time:41.195, tt:4531.462\n",
      "Ep:110, loss:0.00004, loss_test:0.13123, lr:4.34e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.214, tt:4574.710\n",
      "Ep:111, loss:0.00004, loss_test:0.12811, lr:4.30e-03, fs:0.66667 (r=0.556,p=0.833),  time:41.239, tt:4618.758\n",
      "Ep:112, loss:0.00004, loss_test:0.13031, lr:4.26e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.247, tt:4660.899\n",
      "Ep:113, loss:0.00004, loss_test:0.13131, lr:4.21e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.305, tt:4708.795\n",
      "Ep:114, loss:0.00004, loss_test:0.12991, lr:4.17e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.317, tt:4751.497\n",
      "Ep:115, loss:0.00004, loss_test:0.12987, lr:4.13e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.350, tt:4796.655\n",
      "Ep:116, loss:0.00004, loss_test:0.13185, lr:4.09e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.360, tt:4839.090\n",
      "Ep:117, loss:0.00004, loss_test:0.12963, lr:4.05e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.369, tt:4881.597\n",
      "Ep:118, loss:0.00004, loss_test:0.12916, lr:4.01e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.377, tt:4923.872\n",
      "Ep:119, loss:0.00004, loss_test:0.13127, lr:3.97e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.396, tt:4967.566\n",
      "Ep:120, loss:0.00004, loss_test:0.12967, lr:3.93e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.413, tt:5010.953\n",
      "Ep:121, loss:0.00004, loss_test:0.13057, lr:3.89e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.420, tt:5053.201\n",
      "Ep:122, loss:0.00004, loss_test:0.13195, lr:3.85e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.435, tt:5096.521\n",
      "Ep:123, loss:0.00004, loss_test:0.13113, lr:3.81e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.455, tt:5140.361\n",
      "Ep:124, loss:0.00004, loss_test:0.13082, lr:3.77e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.467, tt:5183.353\n",
      "Ep:125, loss:0.00004, loss_test:0.13201, lr:3.73e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.470, tt:5225.187\n",
      "Ep:126, loss:0.00004, loss_test:0.13172, lr:3.70e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.475, tt:5267.314\n",
      "Ep:127, loss:0.00003, loss_test:0.13032, lr:3.66e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.485, tt:5310.069\n",
      "Ep:128, loss:0.00003, loss_test:0.13163, lr:3.62e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.488, tt:5351.944\n",
      "Ep:129, loss:0.00003, loss_test:0.13254, lr:3.59e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.504, tt:5395.482\n",
      "Ep:130, loss:0.00003, loss_test:0.13183, lr:3.55e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.507, tt:5437.357\n",
      "Ep:131, loss:0.00003, loss_test:0.13147, lr:3.52e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.509, tt:5479.168\n",
      "Ep:132, loss:0.00003, loss_test:0.13267, lr:3.48e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.517, tt:5521.740\n",
      "Ep:133, loss:0.00003, loss_test:0.13174, lr:3.45e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.528, tt:5564.727\n",
      "Ep:134, loss:0.00003, loss_test:0.13149, lr:3.41e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.526, tt:5605.964\n",
      "Ep:135, loss:0.00003, loss_test:0.13523, lr:3.38e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.537, tt:5649.034\n",
      "Ep:136, loss:0.00003, loss_test:0.13167, lr:3.34e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.548, tt:5692.100\n",
      "Ep:137, loss:0.00003, loss_test:0.13138, lr:3.31e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.571, tt:5736.860\n",
      "Ep:138, loss:0.00003, loss_test:0.13424, lr:3.28e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.578, tt:5779.411\n",
      "Ep:139, loss:0.00003, loss_test:0.13364, lr:3.24e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.592, tt:5822.939\n",
      "Ep:140, loss:0.00003, loss_test:0.13129, lr:3.21e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.603, tt:5865.995\n",
      "Ep:141, loss:0.00003, loss_test:0.13323, lr:3.18e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.616, tt:5909.534\n",
      "Ep:142, loss:0.00003, loss_test:0.13534, lr:3.15e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.619, tt:5951.519\n",
      "Ep:143, loss:0.00003, loss_test:0.13273, lr:3.12e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.621, tt:5993.471\n",
      "Ep:144, loss:0.00003, loss_test:0.13354, lr:3.09e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.631, tt:6036.485\n",
      "Ep:145, loss:0.00003, loss_test:0.13507, lr:3.05e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.645, tt:6080.197\n",
      "Ep:146, loss:0.00003, loss_test:0.13286, lr:3.02e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.648, tt:6122.312\n",
      "Ep:147, loss:0.00003, loss_test:0.13375, lr:2.99e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.653, tt:6164.654\n",
      "Ep:148, loss:0.00003, loss_test:0.13519, lr:2.96e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.660, tt:6207.338\n",
      "Ep:149, loss:0.00003, loss_test:0.13379, lr:2.93e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.672, tt:6250.862\n",
      "Ep:150, loss:0.00003, loss_test:0.13373, lr:2.90e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.693, tt:6295.593\n",
      "Ep:151, loss:0.00003, loss_test:0.13553, lr:2.88e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.693, tt:6337.408\n",
      "Ep:152, loss:0.00003, loss_test:0.13462, lr:2.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.694, tt:6379.151\n",
      "Ep:153, loss:0.00003, loss_test:0.13335, lr:2.82e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.686, tt:6419.591\n",
      "Ep:154, loss:0.00003, loss_test:0.13517, lr:2.79e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.687, tt:6461.496\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14426, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.590, tt:16.590\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14377, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.850, tt:33.699\n",
      "Ep:2, loss:0.00028, loss_test:0.14296, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.001, tt:51.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00028, loss_test:0.14172, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.622, tt:66.490\n",
      "Ep:4, loss:0.00028, loss_test:0.13978, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:16.348, tt:81.742\n",
      "Ep:5, loss:0.00027, loss_test:0.13684, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:16.154, tt:96.926\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.13230, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:16.233, tt:113.630\n",
      "Ep:7, loss:0.00025, loss_test:0.12594, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:16.277, tt:130.214\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12074, lr:1.00e-02, fs:0.64865 (r=0.727,p=0.585),  time:16.361, tt:147.247\n",
      "Ep:9, loss:0.00023, loss_test:0.11900, lr:1.00e-02, fs:0.62376 (r=0.636,p=0.612),  time:16.506, tt:165.065\n",
      "Ep:10, loss:0.00022, loss_test:0.11633, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:16.716, tt:183.873\n",
      "Ep:11, loss:0.00022, loss_test:0.11581, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:16.760, tt:201.123\n",
      "Ep:12, loss:0.00022, loss_test:0.11233, lr:1.00e-02, fs:0.63158 (r=0.667,p=0.600),  time:16.831, tt:218.805\n",
      "Ep:13, loss:0.00021, loss_test:0.11028, lr:1.00e-02, fs:0.63212 (r=0.616,p=0.649),  time:16.773, tt:234.821\n",
      "Ep:14, loss:0.00020, loss_test:0.10809, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:16.764, tt:251.455\n",
      "Ep:15, loss:0.00019, loss_test:0.10600, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:16.789, tt:268.626\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10275, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:16.866, tt:286.723\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10001, lr:1.00e-02, fs:0.67760 (r=0.626,p=0.738),  time:16.986, tt:305.741\n",
      "Ep:18, loss:0.00018, loss_test:0.09911, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:16.956, tt:322.157\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09756, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:16.920, tt:338.403\n",
      "Ep:20, loss:0.00017, loss_test:0.09632, lr:1.00e-02, fs:0.71823 (r=0.657,p=0.793),  time:16.926, tt:355.453\n",
      "Ep:21, loss:0.00016, loss_test:0.09537, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:16.919, tt:372.216\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09400, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:16.958, tt:390.030\n",
      "Ep:23, loss:0.00015, loss_test:0.09234, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:16.837, tt:404.080\n",
      "Ep:24, loss:0.00015, loss_test:0.09215, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:16.753, tt:418.820\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09143, lr:1.00e-02, fs:0.71591 (r=0.636,p=0.818),  time:16.774, tt:436.120\n",
      "Ep:26, loss:0.00014, loss_test:0.09014, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:16.798, tt:453.554\n",
      "Ep:27, loss:0.00014, loss_test:0.08952, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.688, tt:467.278\n",
      "Ep:28, loss:0.00013, loss_test:0.08890, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:16.638, tt:482.489\n",
      "Ep:29, loss:0.00013, loss_test:0.08850, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:16.595, tt:497.837\n",
      "Ep:30, loss:0.00013, loss_test:0.08765, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.616, tt:515.082\n",
      "Ep:31, loss:0.00012, loss_test:0.08754, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.671, tt:533.463\n",
      "Ep:32, loss:0.00012, loss_test:0.08699, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.735, tt:552.261\n",
      "Ep:33, loss:0.00012, loss_test:0.08624, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:16.782, tt:570.580\n",
      "Ep:34, loss:0.00011, loss_test:0.08602, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:16.838, tt:589.333\n",
      "Ep:35, loss:0.00011, loss_test:0.08496, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:16.844, tt:606.384\n",
      "Ep:36, loss:0.00011, loss_test:0.08558, lr:9.90e-03, fs:0.73626 (r=0.677,p=0.807),  time:16.874, tt:624.326\n",
      "Ep:37, loss:0.00010, loss_test:0.08495, lr:9.80e-03, fs:0.75000 (r=0.697,p=0.812),  time:16.880, tt:641.441\n",
      "Ep:38, loss:0.00010, loss_test:0.08447, lr:9.70e-03, fs:0.75138 (r=0.687,p=0.829),  time:16.884, tt:658.492\n",
      "Ep:39, loss:0.00010, loss_test:0.08455, lr:9.61e-03, fs:0.75281 (r=0.677,p=0.848),  time:16.895, tt:675.791\n",
      "Ep:40, loss:0.00010, loss_test:0.08444, lr:9.51e-03, fs:0.72414 (r=0.636,p=0.840),  time:16.903, tt:693.012\n",
      "Ep:41, loss:0.00010, loss_test:0.08408, lr:9.41e-03, fs:0.73864 (r=0.657,p=0.844),  time:16.890, tt:709.379\n",
      "Ep:42, loss:0.00009, loss_test:0.08455, lr:9.32e-03, fs:0.71006 (r=0.606,p=0.857),  time:16.920, tt:727.558\n",
      "Ep:43, loss:0.00009, loss_test:0.08384, lr:9.23e-03, fs:0.72093 (r=0.626,p=0.849),  time:16.938, tt:745.269\n",
      "Ep:44, loss:0.00009, loss_test:0.08465, lr:9.14e-03, fs:0.71951 (r=0.596,p=0.908),  time:16.959, tt:763.159\n",
      "Ep:45, loss:0.00009, loss_test:0.08327, lr:9.04e-03, fs:0.72414 (r=0.636,p=0.840),  time:16.948, tt:779.620\n",
      "Ep:46, loss:0.00008, loss_test:0.08373, lr:8.95e-03, fs:0.71084 (r=0.596,p=0.881),  time:16.957, tt:796.960\n",
      "Ep:47, loss:0.00008, loss_test:0.08310, lr:8.86e-03, fs:0.71429 (r=0.606,p=0.870),  time:16.972, tt:814.641\n",
      "Ep:48, loss:0.00008, loss_test:0.08310, lr:8.78e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.007, tt:833.320\n",
      "Ep:49, loss:0.00008, loss_test:0.08309, lr:8.69e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.018, tt:850.914\n",
      "Ep:50, loss:0.00008, loss_test:0.08242, lr:8.60e-03, fs:0.70238 (r=0.596,p=0.855),  time:17.010, tt:867.521\n",
      "Ep:51, loss:0.00008, loss_test:0.08310, lr:8.51e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.007, tt:884.384\n",
      "Ep:52, loss:0.00007, loss_test:0.08294, lr:8.43e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.015, tt:901.812\n",
      "Ep:53, loss:0.00007, loss_test:0.08347, lr:8.35e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.033, tt:919.763\n",
      "Ep:54, loss:0.00007, loss_test:0.08282, lr:8.26e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.054, tt:937.976\n",
      "Ep:55, loss:0.00007, loss_test:0.08263, lr:8.18e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.054, tt:954.999\n",
      "Ep:56, loss:0.00007, loss_test:0.08305, lr:8.10e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.027, tt:970.567\n",
      "Ep:57, loss:0.00007, loss_test:0.08239, lr:8.02e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.026, tt:987.486\n",
      "Ep:58, loss:0.00007, loss_test:0.08306, lr:7.94e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.028, tt:1004.641\n",
      "Ep:59, loss:0.00006, loss_test:0.08250, lr:7.86e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.074, tt:1024.448\n",
      "Ep:60, loss:0.00006, loss_test:0.08392, lr:7.78e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.084, tt:1042.097\n",
      "Ep:61, loss:0.00006, loss_test:0.08215, lr:7.70e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.064, tt:1057.987\n",
      "Ep:62, loss:0.00006, loss_test:0.08317, lr:7.62e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.059, tt:1074.745\n",
      "Ep:63, loss:0.00006, loss_test:0.08316, lr:7.55e-03, fs:0.68712 (r=0.566,p=0.875),  time:17.037, tt:1090.366\n",
      "Ep:64, loss:0.00006, loss_test:0.08262, lr:7.47e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.050, tt:1108.262\n",
      "Ep:65, loss:0.00006, loss_test:0.08388, lr:7.40e-03, fs:0.70000 (r=0.566,p=0.918),  time:17.074, tt:1126.898\n",
      "Ep:66, loss:0.00006, loss_test:0.08225, lr:7.32e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.065, tt:1143.329\n",
      "Ep:67, loss:0.00006, loss_test:0.08263, lr:7.25e-03, fs:0.70370 (r=0.576,p=0.905),  time:17.071, tt:1160.812\n",
      "Ep:68, loss:0.00005, loss_test:0.08204, lr:7.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.066, tt:1177.523\n",
      "Ep:69, loss:0.00005, loss_test:0.08308, lr:7.11e-03, fs:0.70000 (r=0.566,p=0.918),  time:17.075, tt:1195.273\n",
      "Ep:70, loss:0.00005, loss_test:0.08203, lr:7.03e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.107, tt:1214.628\n",
      "Ep:71, loss:0.00005, loss_test:0.08171, lr:6.96e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.114, tt:1232.243\n",
      "Ep:72, loss:0.00005, loss_test:0.08318, lr:6.89e-03, fs:0.69136 (r=0.566,p=0.889),  time:17.117, tt:1249.536\n",
      "Ep:73, loss:0.00005, loss_test:0.08153, lr:6.83e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.107, tt:1265.887\n",
      "Ep:74, loss:0.00005, loss_test:0.08209, lr:6.76e-03, fs:0.69136 (r=0.566,p=0.889),  time:17.097, tt:1282.311\n",
      "Ep:75, loss:0.00005, loss_test:0.08271, lr:6.69e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.099, tt:1299.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00005, loss_test:0.08175, lr:6.62e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.103, tt:1316.925\n",
      "Ep:77, loss:0.00005, loss_test:0.08236, lr:6.56e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.109, tt:1334.539\n",
      "Ep:78, loss:0.00005, loss_test:0.08308, lr:6.49e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.122, tt:1352.629\n",
      "Ep:79, loss:0.00004, loss_test:0.08123, lr:6.43e-03, fs:0.71515 (r=0.596,p=0.894),  time:17.117, tt:1369.336\n",
      "Ep:80, loss:0.00004, loss_test:0.08419, lr:6.36e-03, fs:0.70000 (r=0.566,p=0.918),  time:17.116, tt:1386.399\n",
      "Ep:81, loss:0.00004, loss_test:0.08192, lr:6.30e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.116, tt:1403.550\n",
      "Ep:82, loss:0.00004, loss_test:0.08272, lr:6.24e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.116, tt:1420.614\n",
      "Ep:83, loss:0.00004, loss_test:0.08217, lr:6.17e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.113, tt:1437.453\n",
      "Ep:84, loss:0.00004, loss_test:0.08243, lr:6.11e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.112, tt:1454.542\n",
      "Ep:85, loss:0.00004, loss_test:0.08296, lr:6.05e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.123, tt:1472.587\n",
      "Ep:86, loss:0.00004, loss_test:0.08136, lr:5.99e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.127, tt:1490.008\n",
      "Ep:87, loss:0.00004, loss_test:0.08368, lr:5.93e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.126, tt:1507.126\n",
      "Ep:88, loss:0.00004, loss_test:0.08233, lr:5.87e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.115, tt:1523.205\n",
      "Ep:89, loss:0.00004, loss_test:0.08251, lr:5.81e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.107, tt:1539.661\n",
      "Ep:90, loss:0.00004, loss_test:0.08305, lr:5.75e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.097, tt:1555.804\n",
      "Ep:91, loss:0.00004, loss_test:0.08257, lr:5.70e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.093, tt:1572.549\n",
      "Ep:92, loss:0.00004, loss_test:0.08266, lr:5.64e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.097, tt:1590.028\n",
      "Ep:93, loss:0.00004, loss_test:0.08266, lr:5.58e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.092, tt:1606.669\n",
      "Ep:94, loss:0.00004, loss_test:0.08205, lr:5.53e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.085, tt:1623.088\n",
      "Ep:95, loss:0.00004, loss_test:0.08304, lr:5.47e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.087, tt:1640.318\n",
      "Ep:96, loss:0.00003, loss_test:0.08367, lr:5.42e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.093, tt:1658.069\n",
      "Ep:97, loss:0.00003, loss_test:0.08144, lr:5.36e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.103, tt:1676.124\n",
      "Ep:98, loss:0.00003, loss_test:0.08377, lr:5.31e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.100, tt:1692.908\n",
      "Ep:99, loss:0.00003, loss_test:0.08194, lr:5.26e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.103, tt:1710.256\n",
      "Ep:100, loss:0.00003, loss_test:0.08241, lr:5.20e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.098, tt:1726.940\n",
      "Ep:101, loss:0.00003, loss_test:0.08290, lr:5.15e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.103, tt:1744.471\n",
      "Ep:102, loss:0.00003, loss_test:0.08193, lr:5.10e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.106, tt:1761.958\n",
      "Ep:103, loss:0.00003, loss_test:0.08309, lr:5.05e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.100, tt:1778.374\n",
      "Ep:104, loss:0.00003, loss_test:0.08290, lr:5.00e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.094, tt:1794.841\n",
      "Ep:105, loss:0.00003, loss_test:0.08171, lr:4.95e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.082, tt:1810.713\n",
      "Ep:106, loss:0.00003, loss_test:0.08332, lr:4.90e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.073, tt:1826.857\n",
      "Ep:107, loss:0.00003, loss_test:0.08146, lr:4.85e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.085, tt:1845.146\n",
      "Ep:108, loss:0.00003, loss_test:0.08288, lr:4.80e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.083, tt:1862.100\n",
      "Ep:109, loss:0.00003, loss_test:0.08338, lr:4.75e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.096, tt:1880.561\n",
      "Ep:110, loss:0.00003, loss_test:0.08061, lr:4.71e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.105, tt:1898.625\n",
      "Ep:111, loss:0.00003, loss_test:0.08446, lr:4.66e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.097, tt:1914.896\n",
      "Ep:112, loss:0.00003, loss_test:0.08310, lr:4.61e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.094, tt:1931.598\n",
      "Ep:113, loss:0.00003, loss_test:0.08089, lr:4.57e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.094, tt:1948.759\n",
      "Ep:114, loss:0.00003, loss_test:0.08395, lr:4.52e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.102, tt:1966.746\n",
      "Ep:115, loss:0.00003, loss_test:0.08181, lr:4.48e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.101, tt:1983.668\n",
      "Ep:116, loss:0.00003, loss_test:0.08173, lr:4.43e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.093, tt:1999.923\n",
      "Ep:117, loss:0.00003, loss_test:0.08294, lr:4.39e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.094, tt:2017.133\n",
      "Ep:118, loss:0.00003, loss_test:0.08250, lr:4.34e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.094, tt:2034.181\n",
      "Ep:119, loss:0.00003, loss_test:0.08165, lr:4.30e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.095, tt:2051.383\n",
      "Ep:120, loss:0.00003, loss_test:0.08302, lr:4.26e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.093, tt:2068.309\n",
      "Ep:121, loss:0.00003, loss_test:0.08162, lr:4.21e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.087, tt:2084.647\n",
      "Ep:122, loss:0.00003, loss_test:0.08239, lr:4.17e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.079, tt:2100.742\n",
      "Ep:123, loss:0.00003, loss_test:0.08176, lr:4.13e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.081, tt:2118.014\n",
      "Ep:124, loss:0.00003, loss_test:0.08248, lr:4.09e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.082, tt:2135.289\n",
      "Ep:125, loss:0.00003, loss_test:0.08198, lr:4.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.087, tt:2152.899\n",
      "Ep:126, loss:0.00003, loss_test:0.08216, lr:4.01e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.079, tt:2168.991\n",
      "Ep:127, loss:0.00002, loss_test:0.08195, lr:3.97e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.075, tt:2185.654\n",
      "Ep:128, loss:0.00002, loss_test:0.08213, lr:3.93e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.086, tt:2204.153\n",
      "Ep:129, loss:0.00002, loss_test:0.08179, lr:3.89e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.087, tt:2221.368\n",
      "Ep:130, loss:0.00002, loss_test:0.08201, lr:3.85e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.085, tt:2238.099\n",
      "Ep:131, loss:0.00002, loss_test:0.08159, lr:3.81e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.079, tt:2254.427\n",
      "Ep:132, loss:0.00002, loss_test:0.08253, lr:3.77e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.069, tt:2270.174\n",
      "Ep:133, loss:0.00002, loss_test:0.08174, lr:3.73e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.077, tt:2288.293\n",
      "Ep:134, loss:0.00002, loss_test:0.08201, lr:3.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.078, tt:2305.542\n",
      "Ep:135, loss:0.00002, loss_test:0.08191, lr:3.66e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.082, tt:2323.102\n",
      "Ep:136, loss:0.00002, loss_test:0.08189, lr:3.62e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.079, tt:2339.798\n",
      "Ep:137, loss:0.00002, loss_test:0.08237, lr:3.59e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.072, tt:2355.960\n",
      "Ep:138, loss:0.00002, loss_test:0.08148, lr:3.55e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.073, tt:2373.148\n",
      "Ep:139, loss:0.00002, loss_test:0.08253, lr:3.52e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.073, tt:2390.182\n",
      "Ep:140, loss:0.00002, loss_test:0.08159, lr:3.48e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.081, tt:2408.460\n",
      "Ep:141, loss:0.00002, loss_test:0.08227, lr:3.45e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.078, tt:2425.135\n",
      "Ep:142, loss:0.00002, loss_test:0.08293, lr:3.41e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.073, tt:2441.478\n",
      "Ep:143, loss:0.00002, loss_test:0.08128, lr:3.38e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.075, tt:2458.728\n",
      "Ep:144, loss:0.00002, loss_test:0.08259, lr:3.34e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.074, tt:2475.660\n",
      "Ep:145, loss:0.00002, loss_test:0.08173, lr:3.31e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.076, tt:2493.163\n",
      "Ep:146, loss:0.00002, loss_test:0.08181, lr:3.28e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.081, tt:2510.902\n",
      "Ep:147, loss:0.00002, loss_test:0.08211, lr:3.24e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.094, tt:2529.944\n",
      "Ep:148, loss:0.00002, loss_test:0.08180, lr:3.21e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.091, tt:2546.579\n",
      "Ep:149, loss:0.00002, loss_test:0.08221, lr:3.18e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.097, tt:2564.490\n",
      "Ep:150, loss:0.00002, loss_test:0.08140, lr:3.15e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.093, tt:2581.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00002, loss_test:0.08236, lr:3.12e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.090, tt:2597.684\n",
      "Ep:152, loss:0.00002, loss_test:0.08154, lr:3.09e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.083, tt:2613.659\n",
      "Ep:153, loss:0.00002, loss_test:0.08199, lr:3.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.092, tt:2632.210\n",
      "Ep:154, loss:0.00002, loss_test:0.08204, lr:3.02e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.100, tt:2650.458\n",
      "Ep:155, loss:0.00002, loss_test:0.08143, lr:2.99e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.101, tt:2667.777\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14116, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:19.454, tt:19.454\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13989, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:19.982, tt:39.963\n",
      "Ep:2, loss:0.00027, loss_test:0.13810, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:19.504, tt:58.513\n",
      "Ep:3, loss:0.00026, loss_test:0.13644, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:18.975, tt:75.901\n",
      "Ep:4, loss:0.00026, loss_test:0.13544, lr:1.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:18.486, tt:92.429\n",
      "Ep:5, loss:0.00025, loss_test:0.13430, lr:1.00e-02, fs:0.62651 (r=0.788,p=0.520),  time:18.528, tt:111.168\n",
      "Ep:6, loss:0.00025, loss_test:0.13278, lr:1.00e-02, fs:0.61475 (r=0.758,p=0.517),  time:18.826, tt:131.783\n",
      "Ep:7, loss:0.00024, loss_test:0.13107, lr:1.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:19.093, tt:152.748\n",
      "Ep:8, loss:0.00024, loss_test:0.12941, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:19.242, tt:173.177\n",
      "Ep:9, loss:0.00024, loss_test:0.12769, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:19.221, tt:192.213\n",
      "Ep:10, loss:0.00023, loss_test:0.12579, lr:1.00e-02, fs:0.62338 (r=0.727,p=0.545),  time:19.361, tt:212.966\n",
      "Ep:11, loss:0.00023, loss_test:0.12354, lr:1.00e-02, fs:0.61751 (r=0.677,p=0.568),  time:19.498, tt:233.972\n",
      "Ep:12, loss:0.00022, loss_test:0.12096, lr:9.90e-03, fs:0.62264 (r=0.667,p=0.584),  time:19.548, tt:254.128\n",
      "Ep:13, loss:0.00022, loss_test:0.11788, lr:9.80e-03, fs:0.64220 (r=0.707,p=0.588),  time:19.683, tt:275.559\n",
      "Ep:14, loss:0.00021, loss_test:0.11562, lr:9.70e-03, fs:0.65438 (r=0.717,p=0.602),  time:19.798, tt:296.963\n",
      "Ep:15, loss:0.00021, loss_test:0.11324, lr:9.61e-03, fs:0.66351 (r=0.707,p=0.625),  time:19.859, tt:317.748\n",
      "Ep:16, loss:0.00020, loss_test:0.11142, lr:9.51e-03, fs:0.68900 (r=0.727,p=0.655),  time:19.934, tt:338.876\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10964, lr:9.51e-03, fs:0.69565 (r=0.727,p=0.667),  time:19.980, tt:359.641\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.10748, lr:9.51e-03, fs:0.72195 (r=0.747,p=0.698),  time:20.061, tt:381.152\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.10530, lr:9.51e-03, fs:0.71357 (r=0.717,p=0.710),  time:20.095, tt:401.896\n",
      "Ep:20, loss:0.00018, loss_test:0.10374, lr:9.51e-03, fs:0.68449 (r=0.646,p=0.727),  time:20.052, tt:421.091\n",
      "Ep:21, loss:0.00017, loss_test:0.10279, lr:9.51e-03, fs:0.70526 (r=0.677,p=0.736),  time:20.025, tt:440.554\n",
      "Ep:22, loss:0.00017, loss_test:0.10190, lr:9.51e-03, fs:0.70833 (r=0.687,p=0.731),  time:20.081, tt:461.866\n",
      "Ep:23, loss:0.00016, loss_test:0.10123, lr:9.51e-03, fs:0.71204 (r=0.687,p=0.739),  time:20.068, tt:481.625\n",
      "Ep:24, loss:0.00016, loss_test:0.10028, lr:9.51e-03, fs:0.72632 (r=0.697,p=0.758),  time:20.093, tt:502.315\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.09912, lr:9.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:20.078, tt:522.024\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.09873, lr:9.51e-03, fs:0.73913 (r=0.687,p=0.800),  time:20.052, tt:541.393\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09848, lr:9.51e-03, fs:0.74611 (r=0.727,p=0.766),  time:20.023, tt:560.642\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09714, lr:9.51e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.997, tt:579.915\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09605, lr:9.51e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.974, tt:599.211\n",
      "Ep:30, loss:0.00014, loss_test:0.09485, lr:9.51e-03, fs:0.75393 (r=0.727,p=0.783),  time:19.950, tt:618.455\n",
      "Ep:31, loss:0.00014, loss_test:0.09525, lr:9.51e-03, fs:0.73514 (r=0.687,p=0.791),  time:19.936, tt:637.950\n",
      "Ep:32, loss:0.00013, loss_test:0.09460, lr:9.51e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.957, tt:658.565\n",
      "Ep:33, loss:0.00013, loss_test:0.09364, lr:9.51e-03, fs:0.76087 (r=0.707,p=0.824),  time:20.010, tt:680.328\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.09215, lr:9.51e-03, fs:0.76596 (r=0.727,p=0.809),  time:20.010, tt:700.341\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.09272, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.975, tt:719.116\n",
      "Ep:36, loss:0.00012, loss_test:0.09320, lr:9.51e-03, fs:0.75978 (r=0.687,p=0.850),  time:19.971, tt:738.926\n",
      "Ep:37, loss:0.00012, loss_test:0.09070, lr:9.51e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.992, tt:759.684\n",
      "Ep:38, loss:0.00012, loss_test:0.08972, lr:9.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.996, tt:779.858\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08930, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.992, tt:799.686\n",
      "Ep:40, loss:0.00011, loss_test:0.08912, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:20.031, tt:821.289\n",
      "Ep:41, loss:0.00011, loss_test:0.08867, lr:9.51e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.032, tt:841.357\n",
      "Ep:42, loss:0.00011, loss_test:0.08786, lr:9.51e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.087, tt:863.730\n",
      "Ep:43, loss:0.00010, loss_test:0.08683, lr:9.51e-03, fs:0.78652 (r=0.707,p=0.886),  time:20.065, tt:882.856\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.08674, lr:9.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:20.057, tt:902.579\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.08621, lr:9.51e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.075, tt:923.434\n",
      "Ep:46, loss:0.00010, loss_test:0.08607, lr:9.51e-03, fs:0.77011 (r=0.677,p=0.893),  time:20.089, tt:944.197\n",
      "Ep:47, loss:0.00009, loss_test:0.08593, lr:9.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:20.111, tt:965.317\n",
      "Ep:48, loss:0.00009, loss_test:0.08535, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.023, tt:981.119\n",
      "Ep:49, loss:0.00009, loss_test:0.08590, lr:9.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.951, tt:997.533\n",
      "Ep:50, loss:0.00009, loss_test:0.08486, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.935, tt:1016.671\n",
      "Ep:51, loss:0.00009, loss_test:0.08497, lr:9.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.863, tt:1032.887\n",
      "Ep:52, loss:0.00008, loss_test:0.08406, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.790, tt:1048.878\n",
      "Ep:53, loss:0.00008, loss_test:0.08404, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.725, tt:1065.144\n",
      "Ep:54, loss:0.00008, loss_test:0.08359, lr:9.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.728, tt:1085.036\n",
      "Ep:55, loss:0.00008, loss_test:0.08355, lr:9.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.747, tt:1105.831\n",
      "Ep:56, loss:0.00008, loss_test:0.08449, lr:9.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.744, tt:1125.382\n",
      "Ep:57, loss:0.00008, loss_test:0.08364, lr:9.32e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.721, tt:1143.806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00007, loss_test:0.08218, lr:9.23e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.723, tt:1163.666\n",
      "Ep:59, loss:0.00007, loss_test:0.08473, lr:9.14e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.727, tt:1183.644\n",
      "Ep:60, loss:0.00007, loss_test:0.08291, lr:9.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.739, tt:1204.065\n",
      "Ep:61, loss:0.00007, loss_test:0.08176, lr:8.95e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.722, tt:1222.752\n",
      "Ep:62, loss:0.00007, loss_test:0.08535, lr:8.86e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.710, tt:1241.706\n",
      "Ep:63, loss:0.00007, loss_test:0.08189, lr:8.78e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.701, tt:1260.890\n",
      "Ep:64, loss:0.00007, loss_test:0.08229, lr:8.69e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.733, tt:1282.625\n",
      "Ep:65, loss:0.00006, loss_test:0.08615, lr:8.60e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.735, tt:1302.539\n",
      "Ep:66, loss:0.00006, loss_test:0.08056, lr:8.51e-03, fs:0.77714 (r=0.687,p=0.895),  time:19.733, tt:1322.087\n",
      "Ep:67, loss:0.00006, loss_test:0.08312, lr:8.43e-03, fs:0.75449 (r=0.636,p=0.926),  time:19.739, tt:1342.221\n",
      "Ep:68, loss:0.00006, loss_test:0.08535, lr:8.35e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.752, tt:1362.916\n",
      "Ep:69, loss:0.00006, loss_test:0.08070, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.761, tt:1383.271\n",
      "Ep:70, loss:0.00006, loss_test:0.08217, lr:8.18e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.785, tt:1404.756\n",
      "Ep:71, loss:0.00006, loss_test:0.08445, lr:8.10e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.801, tt:1425.682\n",
      "Ep:72, loss:0.00006, loss_test:0.08063, lr:8.02e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.805, tt:1445.777\n",
      "Ep:73, loss:0.00006, loss_test:0.08145, lr:7.94e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.813, tt:1466.164\n",
      "Ep:74, loss:0.00005, loss_test:0.08509, lr:7.86e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.793, tt:1484.469\n",
      "Ep:75, loss:0.00005, loss_test:0.08080, lr:7.78e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.799, tt:1504.708\n",
      "Ep:76, loss:0.00005, loss_test:0.08086, lr:7.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.803, tt:1524.839\n",
      "Ep:77, loss:0.00005, loss_test:0.08475, lr:7.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.798, tt:1544.270\n",
      "Ep:78, loss:0.00005, loss_test:0.08052, lr:7.55e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.793, tt:1563.653\n",
      "Ep:79, loss:0.00005, loss_test:0.08054, lr:7.47e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.793, tt:1583.431\n",
      "Ep:80, loss:0.00005, loss_test:0.08349, lr:7.40e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.792, tt:1603.163\n",
      "Ep:81, loss:0.00005, loss_test:0.08092, lr:7.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.811, tt:1624.463\n",
      "Ep:82, loss:0.00005, loss_test:0.08066, lr:7.25e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.809, tt:1644.114\n",
      "Ep:83, loss:0.00005, loss_test:0.08244, lr:7.18e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.825, tt:1665.337\n",
      "Ep:84, loss:0.00005, loss_test:0.08044, lr:7.11e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.831, tt:1685.606\n",
      "Ep:85, loss:0.00004, loss_test:0.08089, lr:7.03e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.846, tt:1706.789\n",
      "Ep:86, loss:0.00004, loss_test:0.08145, lr:6.96e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.863, tt:1728.083\n",
      "Ep:87, loss:0.00004, loss_test:0.08109, lr:6.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.879, tt:1749.395\n",
      "Ep:88, loss:0.00004, loss_test:0.08125, lr:6.83e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.885, tt:1769.784\n",
      "Ep:89, loss:0.00004, loss_test:0.08123, lr:6.76e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.884, tt:1789.550\n",
      "Ep:90, loss:0.00004, loss_test:0.08023, lr:6.69e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.859, tt:1807.152\n",
      "Ep:91, loss:0.00004, loss_test:0.08139, lr:6.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.865, tt:1827.619\n",
      "Ep:92, loss:0.00004, loss_test:0.08073, lr:6.56e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.877, tt:1848.598\n",
      "Ep:93, loss:0.00004, loss_test:0.08101, lr:6.49e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.884, tt:1869.132\n",
      "Ep:94, loss:0.00004, loss_test:0.08077, lr:6.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.889, tt:1889.486\n",
      "Ep:95, loss:0.00004, loss_test:0.08066, lr:6.36e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.876, tt:1908.095\n",
      "Ep:96, loss:0.00004, loss_test:0.08033, lr:6.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.871, tt:1927.442\n",
      "Ep:97, loss:0.00004, loss_test:0.08068, lr:6.24e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.882, tt:1948.393\n",
      "Ep:98, loss:0.00004, loss_test:0.08164, lr:6.17e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.892, tt:1969.345\n",
      "Ep:99, loss:0.00004, loss_test:0.07970, lr:6.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.891, tt:1989.140\n",
      "Ep:100, loss:0.00004, loss_test:0.08102, lr:6.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.886, tt:2008.459\n",
      "Ep:101, loss:0.00004, loss_test:0.08092, lr:5.99e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.875, tt:2027.270\n",
      "Ep:102, loss:0.00004, loss_test:0.08082, lr:5.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.875, tt:2047.166\n",
      "Ep:103, loss:0.00003, loss_test:0.08031, lr:5.87e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.877, tt:2067.200\n",
      "Ep:104, loss:0.00003, loss_test:0.08029, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.875, tt:2086.871\n",
      "Ep:105, loss:0.00003, loss_test:0.08091, lr:5.75e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.855, tt:2104.641\n",
      "Ep:106, loss:0.00003, loss_test:0.08087, lr:5.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.850, tt:2123.912\n",
      "Ep:107, loss:0.00003, loss_test:0.08061, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.849, tt:2143.678\n",
      "Ep:108, loss:0.00003, loss_test:0.08085, lr:5.58e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.869, tt:2165.674\n",
      "Ep:109, loss:0.00003, loss_test:0.08044, lr:5.53e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.863, tt:2184.925\n",
      "Ep:110, loss:0.00003, loss_test:0.08007, lr:5.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.871, tt:2205.668\n",
      "Ep:111, loss:0.00003, loss_test:0.08174, lr:5.42e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.864, tt:2224.774\n",
      "Ep:112, loss:0.00003, loss_test:0.08030, lr:5.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.862, tt:2244.430\n",
      "Ep:113, loss:0.00003, loss_test:0.07995, lr:5.31e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.859, tt:2263.964\n",
      "Ep:114, loss:0.00003, loss_test:0.08115, lr:5.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.867, tt:2284.735\n",
      "Ep:115, loss:0.00003, loss_test:0.08086, lr:5.20e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.868, tt:2304.723\n",
      "Ep:116, loss:0.00003, loss_test:0.08077, lr:5.15e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.855, tt:2322.982\n",
      "Ep:117, loss:0.00003, loss_test:0.08024, lr:5.10e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.843, tt:2341.489\n",
      "Ep:118, loss:0.00003, loss_test:0.08101, lr:5.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.844, tt:2361.436\n",
      "Ep:119, loss:0.00003, loss_test:0.08064, lr:5.00e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.853, tt:2382.382\n",
      "Ep:120, loss:0.00003, loss_test:0.08099, lr:4.95e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.851, tt:2402.013\n",
      "Ep:121, loss:0.00003, loss_test:0.08050, lr:4.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.849, tt:2421.548\n",
      "Ep:122, loss:0.00003, loss_test:0.08071, lr:4.85e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.846, tt:2441.075\n",
      "Ep:123, loss:0.00003, loss_test:0.08088, lr:4.80e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.861, tt:2462.802\n",
      "Ep:124, loss:0.00003, loss_test:0.08055, lr:4.75e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.868, tt:2483.533\n",
      "Ep:125, loss:0.00003, loss_test:0.08080, lr:4.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.864, tt:2502.850\n",
      "Ep:126, loss:0.00003, loss_test:0.08098, lr:4.66e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.855, tt:2521.602\n",
      "Ep:127, loss:0.00003, loss_test:0.08080, lr:4.61e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.848, tt:2540.597\n",
      "Ep:128, loss:0.00003, loss_test:0.08078, lr:4.57e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.854, tt:2561.159\n",
      "Ep:129, loss:0.00003, loss_test:0.08098, lr:4.52e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.856, tt:2581.274\n",
      "Ep:130, loss:0.00003, loss_test:0.08065, lr:4.48e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.853, tt:2600.714\n",
      "Ep:131, loss:0.00003, loss_test:0.08111, lr:4.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.855, tt:2620.845\n",
      "Ep:132, loss:0.00003, loss_test:0.08103, lr:4.39e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.849, tt:2639.860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00003, loss_test:0.08111, lr:4.34e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.865, tt:2661.883\n",
      "Ep:134, loss:0.00003, loss_test:0.08109, lr:4.30e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.862, tt:2681.366\n",
      "Ep:135, loss:0.00002, loss_test:0.08077, lr:4.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.871, tt:2702.501\n",
      "Ep:136, loss:0.00002, loss_test:0.08130, lr:4.21e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.878, tt:2723.319\n",
      "Ep:137, loss:0.00002, loss_test:0.08130, lr:4.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.872, tt:2742.306\n",
      "Ep:138, loss:0.00002, loss_test:0.08133, lr:4.13e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.867, tt:2761.527\n",
      "Ep:139, loss:0.00002, loss_test:0.08187, lr:4.09e-03, fs:0.77844 (r=0.657,p=0.956),  time:19.870, tt:2781.740\n",
      "Ep:140, loss:0.00002, loss_test:0.08088, lr:4.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2801.628\n",
      "Ep:141, loss:0.00002, loss_test:0.08120, lr:4.01e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.872, tt:2821.836\n",
      "Ep:142, loss:0.00002, loss_test:0.08230, lr:3.97e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2841.434\n",
      "Ep:143, loss:0.00002, loss_test:0.08094, lr:3.93e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.873, tt:2861.750\n",
      "Ep:144, loss:0.00002, loss_test:0.08119, lr:3.89e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2881.156\n",
      "Ep:145, loss:0.00002, loss_test:0.08182, lr:3.85e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2901.066\n",
      "Ep:146, loss:0.00002, loss_test:0.08191, lr:3.81e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.865, tt:2920.188\n",
      "Ep:147, loss:0.00002, loss_test:0.08205, lr:3.77e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.863, tt:2939.715\n",
      "Ep:148, loss:0.00002, loss_test:0.08156, lr:3.73e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.863, tt:2959.593\n",
      "Ep:149, loss:0.00002, loss_test:0.08187, lr:3.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.853, tt:2978.017\n",
      "Ep:150, loss:0.00002, loss_test:0.08187, lr:3.66e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.857, tt:2998.344\n",
      "Ep:151, loss:0.00002, loss_test:0.08100, lr:3.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.862, tt:3019.004\n",
      "Ep:152, loss:0.00002, loss_test:0.08223, lr:3.59e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.859, tt:3038.373\n",
      "Ep:153, loss:0.00002, loss_test:0.08151, lr:3.55e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.857, tt:3058.045\n",
      "Ep:154, loss:0.00002, loss_test:0.08159, lr:3.52e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.855, tt:3077.477\n",
      "Ep:155, loss:0.00002, loss_test:0.08179, lr:3.48e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.852, tt:3096.956\n",
      "Ep:156, loss:0.00002, loss_test:0.08166, lr:3.45e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.859, tt:3117.923\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14450, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.033, tt:49.033\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14312, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.821, tt:97.641\n",
      "Ep:2, loss:0.00027, loss_test:0.14038, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.768, tt:152.304\n",
      "Ep:3, loss:0.00027, loss_test:0.13512, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:51.368, tt:205.472\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12535, lr:1.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:51.787, tt:258.933\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11365, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:52.223, tt:313.340\n",
      "Ep:6, loss:0.00022, loss_test:0.11197, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:52.563, tt:367.944\n",
      "Ep:7, loss:0.00021, loss_test:0.11221, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:52.654, tt:421.231\n",
      "Ep:8, loss:0.00021, loss_test:0.11162, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:52.934, tt:476.405\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10940, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:52.877, tt:528.770\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10718, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:52.764, tt:580.406\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10630, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:52.719, tt:632.623\n",
      "Ep:12, loss:0.00018, loss_test:0.10519, lr:1.00e-02, fs:0.69231 (r=0.727,p=0.661),  time:52.919, tt:687.952\n",
      "Ep:13, loss:0.00017, loss_test:0.10481, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:52.948, tt:741.275\n",
      "Ep:14, loss:0.00017, loss_test:0.10349, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:52.841, tt:792.621\n",
      "Ep:15, loss:0.00016, loss_test:0.10251, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:52.937, tt:846.985\n",
      "Ep:16, loss:0.00016, loss_test:0.10214, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:52.986, tt:900.766\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10256, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:53.019, tt:954.342\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10317, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:52.949, tt:1006.033\n",
      "Ep:19, loss:0.00015, loss_test:0.10283, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:52.956, tt:1059.126\n",
      "Ep:20, loss:0.00014, loss_test:0.10186, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:53.010, tt:1113.213\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.10305, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:53.099, tt:1168.183\n",
      "Ep:22, loss:0.00013, loss_test:0.10477, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:53.066, tt:1220.512\n",
      "Ep:23, loss:0.00013, loss_test:0.10614, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:53.196, tt:1276.704\n",
      "Ep:24, loss:0.00013, loss_test:0.10466, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:53.244, tt:1331.106\n",
      "Ep:25, loss:0.00012, loss_test:0.10705, lr:1.00e-02, fs:0.72527 (r=0.667,p=0.795),  time:53.248, tt:1384.442\n",
      "Ep:26, loss:0.00012, loss_test:0.10434, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:53.217, tt:1436.848\n",
      "Ep:27, loss:0.00012, loss_test:0.11067, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:53.168, tt:1488.698\n",
      "Ep:28, loss:0.00012, loss_test:0.10625, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:53.191, tt:1542.536\n",
      "Ep:29, loss:0.00011, loss_test:0.11010, lr:1.00e-02, fs:0.71264 (r=0.626,p=0.827),  time:53.214, tt:1596.420\n",
      "Ep:30, loss:0.00011, loss_test:0.10585, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:52.992, tt:1642.755\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.10792, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:52.844, tt:1691.001\n",
      "Ep:32, loss:0.00010, loss_test:0.10762, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:52.895, tt:1745.545\n",
      "Ep:33, loss:0.00010, loss_test:0.10776, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:52.957, tt:1800.542\n",
      "Ep:34, loss:0.00010, loss_test:0.11174, lr:1.00e-02, fs:0.72316 (r=0.646,p=0.821),  time:52.941, tt:1852.926\n",
      "Ep:35, loss:0.00009, loss_test:0.10429, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:52.995, tt:1907.809\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.11496, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:53.000, tt:1961.013\n",
      "Ep:37, loss:0.00009, loss_test:0.10778, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:53.013, tt:2014.501\n",
      "Ep:38, loss:0.00009, loss_test:0.10782, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:53.127, tt:2071.961\n",
      "Ep:39, loss:0.00008, loss_test:0.11051, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:53.168, tt:2126.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00008, loss_test:0.10830, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:53.157, tt:2179.455\n",
      "Ep:41, loss:0.00008, loss_test:0.11061, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:53.147, tt:2232.167\n",
      "Ep:42, loss:0.00007, loss_test:0.10697, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:53.136, tt:2284.868\n",
      "Ep:43, loss:0.00007, loss_test:0.11241, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:53.176, tt:2339.736\n",
      "Ep:44, loss:0.00007, loss_test:0.10834, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:53.165, tt:2392.420\n",
      "Ep:45, loss:0.00007, loss_test:0.10762, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:53.135, tt:2444.204\n",
      "Ep:46, loss:0.00007, loss_test:0.10962, lr:1.00e-02, fs:0.73446 (r=0.657,p=0.833),  time:53.113, tt:2496.288\n",
      "Ep:47, loss:0.00007, loss_test:0.11202, lr:9.90e-03, fs:0.73988 (r=0.646,p=0.865),  time:53.168, tt:2552.067\n",
      "Ep:48, loss:0.00006, loss_test:0.10667, lr:9.80e-03, fs:0.74317 (r=0.687,p=0.810),  time:53.204, tt:2606.995\n",
      "Ep:49, loss:0.00006, loss_test:0.11521, lr:9.70e-03, fs:0.72619 (r=0.616,p=0.884),  time:53.219, tt:2660.943\n",
      "Ep:50, loss:0.00006, loss_test:0.10487, lr:9.61e-03, fs:0.72928 (r=0.667,p=0.805),  time:53.206, tt:2713.519\n",
      "Ep:51, loss:0.00006, loss_test:0.11969, lr:9.51e-03, fs:0.71951 (r=0.596,p=0.908),  time:53.181, tt:2765.410\n",
      "Ep:52, loss:0.00006, loss_test:0.10370, lr:9.41e-03, fs:0.73034 (r=0.657,p=0.823),  time:53.164, tt:2817.701\n",
      "Ep:53, loss:0.00006, loss_test:0.11595, lr:9.32e-03, fs:0.73810 (r=0.626,p=0.899),  time:53.177, tt:2871.534\n",
      "Ep:54, loss:0.00005, loss_test:0.10730, lr:9.23e-03, fs:0.74713 (r=0.657,p=0.867),  time:53.143, tt:2922.866\n",
      "Ep:55, loss:0.00005, loss_test:0.11291, lr:9.14e-03, fs:0.72941 (r=0.626,p=0.873),  time:53.163, tt:2977.110\n",
      "Ep:56, loss:0.00005, loss_test:0.11099, lr:9.04e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.192, tt:3031.963\n",
      "Ep:57, loss:0.00005, loss_test:0.11038, lr:8.95e-03, fs:0.74854 (r=0.646,p=0.889),  time:53.191, tt:3085.074\n",
      "Ep:58, loss:0.00005, loss_test:0.11187, lr:8.86e-03, fs:0.73373 (r=0.626,p=0.886),  time:53.202, tt:3138.909\n",
      "Ep:59, loss:0.00004, loss_test:0.10947, lr:8.78e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.202, tt:3192.105\n",
      "Ep:60, loss:0.00004, loss_test:0.11654, lr:8.69e-03, fs:0.73054 (r=0.616,p=0.897),  time:53.218, tt:3246.329\n",
      "Ep:61, loss:0.00004, loss_test:0.10842, lr:8.60e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.208, tt:3298.912\n",
      "Ep:62, loss:0.00004, loss_test:0.11907, lr:8.51e-03, fs:0.70732 (r=0.586,p=0.892),  time:53.237, tt:3353.914\n",
      "Ep:63, loss:0.00004, loss_test:0.10761, lr:8.43e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.212, tt:3405.565\n",
      "Ep:64, loss:0.00004, loss_test:0.11828, lr:8.35e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.227, tt:3459.738\n",
      "Ep:65, loss:0.00004, loss_test:0.10668, lr:8.26e-03, fs:0.74713 (r=0.657,p=0.867),  time:53.226, tt:3512.899\n",
      "Ep:66, loss:0.00003, loss_test:0.12314, lr:8.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:53.224, tt:3565.991\n",
      "Ep:67, loss:0.00004, loss_test:0.10905, lr:8.10e-03, fs:0.73256 (r=0.636,p=0.863),  time:53.206, tt:3617.974\n",
      "Ep:68, loss:0.00003, loss_test:0.11614, lr:8.02e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.193, tt:3670.340\n",
      "Ep:69, loss:0.00003, loss_test:0.11046, lr:7.94e-03, fs:0.72189 (r=0.616,p=0.871),  time:53.193, tt:3723.542\n",
      "Ep:70, loss:0.00003, loss_test:0.11689, lr:7.86e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.202, tt:3777.354\n",
      "Ep:71, loss:0.00003, loss_test:0.11246, lr:7.78e-03, fs:0.71515 (r=0.596,p=0.894),  time:53.198, tt:3830.291\n",
      "Ep:72, loss:0.00003, loss_test:0.11531, lr:7.70e-03, fs:0.66250 (r=0.535,p=0.869),  time:53.171, tt:3881.483\n",
      "Ep:73, loss:0.00003, loss_test:0.11166, lr:7.62e-03, fs:0.71515 (r=0.596,p=0.894),  time:53.157, tt:3933.649\n",
      "Ep:74, loss:0.00003, loss_test:0.11383, lr:7.55e-03, fs:0.70303 (r=0.586,p=0.879),  time:53.172, tt:3987.897\n",
      "Ep:75, loss:0.00003, loss_test:0.11104, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:53.152, tt:4039.559\n",
      "Ep:76, loss:0.00003, loss_test:0.11190, lr:7.40e-03, fs:0.70732 (r=0.586,p=0.892),  time:53.155, tt:4092.920\n",
      "Ep:77, loss:0.00003, loss_test:0.11483, lr:7.32e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.166, tt:4146.951\n",
      "Ep:78, loss:0.00002, loss_test:0.11450, lr:7.25e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.179, tt:4201.113\n",
      "Ep:79, loss:0.00002, loss_test:0.10884, lr:7.18e-03, fs:0.71084 (r=0.596,p=0.881),  time:53.153, tt:4252.235\n",
      "Ep:80, loss:0.00002, loss_test:0.11583, lr:7.11e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.151, tt:4305.240\n",
      "Ep:81, loss:0.00002, loss_test:0.11307, lr:7.03e-03, fs:0.69136 (r=0.566,p=0.889),  time:53.135, tt:4357.094\n",
      "Ep:82, loss:0.00002, loss_test:0.11417, lr:6.96e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.130, tt:4409.802\n",
      "Ep:83, loss:0.00002, loss_test:0.11385, lr:6.89e-03, fs:0.66250 (r=0.535,p=0.869),  time:53.149, tt:4464.494\n",
      "Ep:84, loss:0.00002, loss_test:0.10858, lr:6.83e-03, fs:0.69512 (r=0.576,p=0.877),  time:53.170, tt:4519.461\n",
      "Ep:85, loss:0.00002, loss_test:0.11793, lr:6.76e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.199, tt:4575.148\n",
      "Ep:86, loss:0.00002, loss_test:0.11026, lr:6.69e-03, fs:0.69512 (r=0.576,p=0.877),  time:53.182, tt:4626.803\n",
      "Ep:87, loss:0.00002, loss_test:0.11284, lr:6.62e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.206, tt:4682.123\n",
      "Ep:88, loss:0.00002, loss_test:0.11035, lr:6.56e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.212, tt:4735.823\n",
      "Ep:89, loss:0.00002, loss_test:0.11509, lr:6.49e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.194, tt:4787.454\n",
      "Ep:90, loss:0.00002, loss_test:0.11310, lr:6.43e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.184, tt:4839.758\n",
      "Ep:91, loss:0.00002, loss_test:0.11239, lr:6.36e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.177, tt:4892.258\n",
      "Ep:92, loss:0.00002, loss_test:0.11153, lr:6.30e-03, fs:0.64968 (r=0.515,p=0.879),  time:53.167, tt:4944.550\n",
      "Ep:93, loss:0.00002, loss_test:0.11226, lr:6.24e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.167, tt:4997.665\n",
      "Ep:94, loss:0.00002, loss_test:0.11302, lr:6.17e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.185, tt:5052.586\n",
      "Ep:95, loss:0.00002, loss_test:0.11204, lr:6.11e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.190, tt:5106.277\n",
      "Ep:96, loss:0.00002, loss_test:0.11193, lr:6.05e-03, fs:0.65823 (r=0.525,p=0.881),  time:53.206, tt:5161.003\n",
      "Ep:97, loss:0.00002, loss_test:0.11419, lr:5.99e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.206, tt:5214.226\n",
      "Ep:98, loss:0.00002, loss_test:0.11165, lr:5.93e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.213, tt:5268.125\n",
      "Ep:99, loss:0.00002, loss_test:0.11413, lr:5.87e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.213, tt:5321.282\n",
      "Ep:100, loss:0.00002, loss_test:0.11393, lr:5.81e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.212, tt:5374.458\n",
      "Ep:101, loss:0.00002, loss_test:0.11202, lr:5.75e-03, fs:0.65823 (r=0.525,p=0.881),  time:53.201, tt:5426.538\n",
      "Ep:102, loss:0.00002, loss_test:0.11468, lr:5.70e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.166, tt:5476.131\n",
      "Ep:103, loss:0.00001, loss_test:0.11207, lr:5.64e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.072, tt:5519.523\n",
      "Ep:104, loss:0.00001, loss_test:0.11404, lr:5.58e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.937, tt:5558.356\n",
      "Ep:105, loss:0.00001, loss_test:0.11007, lr:5.53e-03, fs:0.69136 (r=0.566,p=0.889),  time:52.849, tt:5602.024\n",
      "Ep:106, loss:0.00001, loss_test:0.11751, lr:5.47e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.858, tt:5655.855\n",
      "Ep:107, loss:0.00001, loss_test:0.11334, lr:5.42e-03, fs:0.67500 (r=0.545,p=0.885),  time:52.858, tt:5708.654\n",
      "Ep:108, loss:0.00001, loss_test:0.11115, lr:5.36e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.834, tt:5758.894\n",
      "Ep:109, loss:0.00001, loss_test:0.11329, lr:5.31e-03, fs:0.65385 (r=0.515,p=0.895),  time:52.818, tt:5810.034\n",
      "Ep:110, loss:0.00001, loss_test:0.11279, lr:5.26e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.810, tt:5861.966\n",
      "Ep:111, loss:0.00001, loss_test:0.11218, lr:5.20e-03, fs:0.67925 (r=0.545,p=0.900),  time:52.816, tt:5915.337\n",
      "Ep:112, loss:0.00001, loss_test:0.11275, lr:5.15e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.817, tt:5968.275\n",
      "Ep:113, loss:0.00001, loss_test:0.11297, lr:5.10e-03, fs:0.65385 (r=0.515,p=0.895),  time:52.796, tt:6018.781\n",
      "Ep:114, loss:0.00001, loss_test:0.11308, lr:5.05e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.773, tt:6068.905\n",
      "Ep:115, loss:0.00001, loss_test:0.11448, lr:5.00e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.797, tt:6124.452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00001, loss_test:0.11208, lr:4.95e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.799, tt:6177.515\n",
      "Ep:117, loss:0.00001, loss_test:0.11329, lr:4.90e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.797, tt:6230.046\n",
      "Ep:118, loss:0.00001, loss_test:0.11362, lr:4.85e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.808, tt:6284.193\n",
      "Ep:119, loss:0.00001, loss_test:0.11246, lr:4.80e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.799, tt:6335.933\n",
      "Ep:120, loss:0.00001, loss_test:0.11333, lr:4.75e-03, fs:0.66667 (r=0.525,p=0.912),  time:52.786, tt:6387.071\n",
      "Ep:121, loss:0.00001, loss_test:0.11442, lr:4.71e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.768, tt:6437.664\n",
      "Ep:122, loss:0.00001, loss_test:0.11252, lr:4.66e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.777, tt:6491.560\n",
      "Ep:123, loss:0.00001, loss_test:0.11525, lr:4.61e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.774, tt:6544.005\n",
      "Ep:124, loss:0.00001, loss_test:0.11359, lr:4.57e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.773, tt:6596.626\n",
      "Ep:125, loss:0.00001, loss_test:0.11161, lr:4.52e-03, fs:0.65806 (r=0.515,p=0.911),  time:52.779, tt:6650.171\n",
      "Ep:126, loss:0.00001, loss_test:0.11518, lr:4.48e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.786, tt:6703.862\n",
      "Ep:127, loss:0.00001, loss_test:0.11257, lr:4.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.794, tt:6757.650\n",
      "Ep:128, loss:0.00001, loss_test:0.11335, lr:4.39e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.774, tt:6807.854\n",
      "Ep:129, loss:0.00001, loss_test:0.11451, lr:4.34e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.765, tt:6859.393\n",
      "Ep:130, loss:0.00001, loss_test:0.11209, lr:4.30e-03, fs:0.66667 (r=0.525,p=0.912),  time:52.762, tt:6911.767\n",
      "Ep:131, loss:0.00001, loss_test:0.11480, lr:4.26e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.745, tt:6962.331\n",
      "Ep:132, loss:0.00001, loss_test:0.11322, lr:4.21e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.731, tt:7013.286\n",
      "Ep:133, loss:0.00001, loss_test:0.11388, lr:4.17e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.736, tt:7066.624\n",
      "Ep:134, loss:0.00001, loss_test:0.11542, lr:4.13e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.737, tt:7119.552\n",
      "Ep:135, loss:0.00001, loss_test:0.11131, lr:4.09e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.725, tt:7170.611\n",
      "Ep:136, loss:0.00001, loss_test:0.11618, lr:4.05e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.729, tt:7223.910\n",
      "Ep:137, loss:0.00001, loss_test:0.11478, lr:4.01e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.743, tt:7278.589\n",
      "Ep:138, loss:0.00001, loss_test:0.11261, lr:3.97e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.738, tt:7330.616\n",
      "Ep:139, loss:0.00001, loss_test:0.11448, lr:3.93e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.729, tt:7382.011\n",
      "Ep:140, loss:0.00001, loss_test:0.11445, lr:3.89e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.738, tt:7436.035\n",
      "Ep:141, loss:0.00001, loss_test:0.11313, lr:3.85e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.728, tt:7487.342\n",
      "Ep:142, loss:0.00001, loss_test:0.11297, lr:3.81e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.732, tt:7540.731\n",
      "Ep:143, loss:0.00001, loss_test:0.11366, lr:3.77e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.723, tt:7592.043\n",
      "Ep:144, loss:0.00001, loss_test:0.11193, lr:3.73e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.692, tt:7640.339\n",
      "Ep:145, loss:0.00001, loss_test:0.11538, lr:3.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.701, tt:7694.342\n",
      "Ep:146, loss:0.00001, loss_test:0.11526, lr:3.66e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.699, tt:7746.733\n",
      "Ep:147, loss:0.00001, loss_test:0.11250, lr:3.62e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.698, tt:7799.327\n",
      "Ep:148, loss:0.00001, loss_test:0.11489, lr:3.59e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.683, tt:7849.788\n",
      "Ep:149, loss:0.00001, loss_test:0.11432, lr:3.55e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.676, tt:7901.471\n",
      "Ep:150, loss:0.00001, loss_test:0.11492, lr:3.52e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.677, tt:7954.171\n",
      "Ep:151, loss:0.00001, loss_test:0.11513, lr:3.48e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.673, tt:8006.327\n",
      "Ep:152, loss:0.00001, loss_test:0.11260, lr:3.45e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.669, tt:8058.303\n",
      "Ep:153, loss:0.00001, loss_test:0.11493, lr:3.41e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.657, tt:8109.165\n",
      "Ep:154, loss:0.00001, loss_test:0.11504, lr:3.38e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.644, tt:8159.796\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14395, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.111, tt:19.111\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14305, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.968, tt:39.936\n",
      "Ep:2, loss:0.00028, loss_test:0.14143, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.555, tt:58.665\n",
      "Ep:3, loss:0.00028, loss_test:0.13857, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:19.090, tt:76.361\n",
      "Ep:4, loss:0.00027, loss_test:0.13402, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:19.485, tt:97.424\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12745, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:19.641, tt:117.844\n",
      "Ep:6, loss:0.00024, loss_test:0.11849, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:19.800, tt:138.597\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11629, lr:1.00e-02, fs:0.58511 (r=0.556,p=0.618),  time:19.731, tt:157.849\n",
      "Ep:8, loss:0.00022, loss_test:0.11467, lr:1.00e-02, fs:0.59140 (r=0.556,p=0.632),  time:19.869, tt:178.822\n",
      "Ep:9, loss:0.00022, loss_test:0.11233, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:19.862, tt:198.618\n",
      "Ep:10, loss:0.00021, loss_test:0.10961, lr:1.00e-02, fs:0.64921 (r=0.626,p=0.674),  time:20.078, tt:220.862\n",
      "Ep:11, loss:0.00020, loss_test:0.10812, lr:1.00e-02, fs:0.65217 (r=0.606,p=0.706),  time:19.831, tt:237.974\n",
      "Ep:12, loss:0.00019, loss_test:0.10518, lr:1.00e-02, fs:0.65672 (r=0.667,p=0.647),  time:19.896, tt:258.649\n",
      "Ep:13, loss:0.00018, loss_test:0.10323, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:19.760, tt:276.641\n",
      "Ep:14, loss:0.00017, loss_test:0.10224, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:19.904, tt:298.557\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09897, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:19.907, tt:318.515\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09906, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:19.989, tt:339.818\n",
      "Ep:17, loss:0.00015, loss_test:0.09689, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:20.045, tt:360.814\n",
      "Ep:18, loss:0.00015, loss_test:0.09626, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:20.021, tt:380.402\n",
      "Ep:19, loss:0.00014, loss_test:0.09547, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:20.086, tt:401.717\n",
      "Ep:20, loss:0.00014, loss_test:0.09402, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:20.107, tt:422.252\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09462, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:20.141, tt:443.094\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.09155, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:20.111, tt:462.546\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.09562, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:20.142, tt:483.414\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09057, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:20.079, tt:501.985\n",
      "Ep:25, loss:0.00011, loss_test:0.09419, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:20.144, tt:523.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00010, loss_test:0.08946, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:20.102, tt:542.759\n",
      "Ep:27, loss:0.00010, loss_test:0.09214, lr:1.00e-02, fs:0.70520 (r=0.616,p=0.824),  time:20.068, tt:561.909\n",
      "Ep:28, loss:0.00009, loss_test:0.08751, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:19.996, tt:579.890\n",
      "Ep:29, loss:0.00009, loss_test:0.08938, lr:1.00e-02, fs:0.71591 (r=0.636,p=0.818),  time:20.115, tt:603.458\n",
      "Ep:30, loss:0.00008, loss_test:0.08929, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:20.091, tt:622.835\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.08668, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:20.140, tt:644.487\n",
      "Ep:32, loss:0.00008, loss_test:0.09111, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:20.157, tt:665.187\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.08617, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:20.136, tt:684.630\n",
      "Ep:34, loss:0.00007, loss_test:0.09375, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:20.141, tt:704.946\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.08588, lr:1.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:20.094, tt:723.368\n",
      "Ep:36, loss:0.00006, loss_test:0.09608, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:20.114, tt:744.232\n",
      "Ep:37, loss:0.00006, loss_test:0.08676, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:20.053, tt:762.017\n",
      "Ep:38, loss:0.00006, loss_test:0.09462, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:20.108, tt:784.209\n",
      "Ep:39, loss:0.00006, loss_test:0.08884, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:20.093, tt:803.700\n",
      "Ep:40, loss:0.00005, loss_test:0.09351, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:20.144, tt:825.896\n",
      "Ep:41, loss:0.00005, loss_test:0.09154, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:20.139, tt:845.837\n",
      "Ep:42, loss:0.00005, loss_test:0.09155, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:20.152, tt:866.524\n",
      "Ep:43, loss:0.00005, loss_test:0.09396, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:20.152, tt:886.675\n",
      "Ep:44, loss:0.00004, loss_test:0.09304, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:20.164, tt:907.393\n",
      "Ep:45, loss:0.00004, loss_test:0.08961, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:20.172, tt:927.922\n",
      "Ep:46, loss:0.00004, loss_test:0.09814, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.168, tt:947.901\n",
      "Ep:47, loss:0.00004, loss_test:0.09021, lr:9.80e-03, fs:0.76023 (r=0.657,p=0.903),  time:20.156, tt:967.503\n",
      "Ep:48, loss:0.00003, loss_test:0.10145, lr:9.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:20.144, tt:987.055\n",
      "Ep:49, loss:0.00003, loss_test:0.08880, lr:9.61e-03, fs:0.74854 (r=0.646,p=0.889),  time:20.143, tt:1007.146\n",
      "Ep:50, loss:0.00003, loss_test:0.10051, lr:9.51e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.144, tt:1027.341\n",
      "Ep:51, loss:0.00003, loss_test:0.09025, lr:9.41e-03, fs:0.73373 (r=0.626,p=0.886),  time:20.173, tt:1048.976\n",
      "Ep:52, loss:0.00003, loss_test:0.10184, lr:9.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.166, tt:1068.792\n",
      "Ep:53, loss:0.00003, loss_test:0.09302, lr:9.23e-03, fs:0.75000 (r=0.636,p=0.913),  time:20.188, tt:1090.170\n",
      "Ep:54, loss:0.00003, loss_test:0.09626, lr:9.14e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.180, tt:1109.909\n",
      "Ep:55, loss:0.00003, loss_test:0.09362, lr:9.04e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.176, tt:1129.829\n",
      "Ep:56, loss:0.00002, loss_test:0.09151, lr:8.95e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.174, tt:1149.917\n",
      "Ep:57, loss:0.00002, loss_test:0.09417, lr:8.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.183, tt:1170.588\n",
      "Ep:58, loss:0.00002, loss_test:0.09137, lr:8.78e-03, fs:0.72727 (r=0.606,p=0.909),  time:20.166, tt:1189.792\n",
      "Ep:59, loss:0.00002, loss_test:0.09347, lr:8.69e-03, fs:0.75449 (r=0.636,p=0.926),  time:20.168, tt:1210.108\n",
      "Ep:60, loss:0.00002, loss_test:0.09300, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.184, tt:1231.205\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.09114, lr:8.60e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.159, tt:1249.861\n",
      "Ep:62, loss:0.00002, loss_test:0.09246, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.183, tt:1271.549\n",
      "Ep:63, loss:0.00002, loss_test:0.09231, lr:8.60e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.153, tt:1289.804\n",
      "Ep:64, loss:0.00002, loss_test:0.09062, lr:8.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.165, tt:1310.721\n",
      "Ep:65, loss:0.00002, loss_test:0.09581, lr:8.60e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.172, tt:1331.333\n",
      "Ep:66, loss:0.00002, loss_test:0.09206, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.185, tt:1352.372\n",
      "Ep:67, loss:0.00002, loss_test:0.09842, lr:8.60e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.169, tt:1371.493\n",
      "Ep:68, loss:0.00002, loss_test:0.09425, lr:8.60e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.172, tt:1391.860\n",
      "Ep:69, loss:0.00002, loss_test:0.09763, lr:8.60e-03, fs:0.71605 (r=0.586,p=0.921),  time:20.156, tt:1410.942\n",
      "Ep:70, loss:0.00002, loss_test:0.10136, lr:8.60e-03, fs:0.73292 (r=0.596,p=0.952),  time:20.143, tt:1430.161\n",
      "Ep:71, loss:0.00001, loss_test:0.09076, lr:8.60e-03, fs:0.72393 (r=0.596,p=0.922),  time:20.147, tt:1450.618\n",
      "Ep:72, loss:0.00001, loss_test:0.10098, lr:8.51e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.130, tt:1469.483\n",
      "Ep:73, loss:0.00001, loss_test:0.09360, lr:8.43e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.143, tt:1490.600\n",
      "Ep:74, loss:0.00001, loss_test:0.09568, lr:8.35e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.145, tt:1510.860\n",
      "Ep:75, loss:0.00001, loss_test:0.09542, lr:8.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.176, tt:1533.391\n",
      "Ep:76, loss:0.00001, loss_test:0.09245, lr:8.18e-03, fs:0.72393 (r=0.596,p=0.922),  time:20.196, tt:1555.075\n",
      "Ep:77, loss:0.00001, loss_test:0.09854, lr:8.10e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.207, tt:1576.178\n",
      "Ep:78, loss:0.00001, loss_test:0.09544, lr:8.02e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.259, tt:1600.445\n",
      "Ep:79, loss:0.00001, loss_test:0.09751, lr:7.94e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.275, tt:1622.010\n",
      "Ep:80, loss:0.00001, loss_test:0.09994, lr:7.86e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.277, tt:1642.402\n",
      "Ep:81, loss:0.00001, loss_test:0.09259, lr:7.78e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.297, tt:1664.393\n",
      "Ep:82, loss:0.00001, loss_test:0.09488, lr:7.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.294, tt:1684.391\n",
      "Ep:83, loss:0.00001, loss_test:0.09534, lr:7.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.294, tt:1704.726\n",
      "Ep:84, loss:0.00001, loss_test:0.09656, lr:7.55e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.290, tt:1724.631\n",
      "Ep:85, loss:0.00001, loss_test:0.09605, lr:7.47e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.296, tt:1745.487\n",
      "Ep:86, loss:0.00001, loss_test:0.09694, lr:7.40e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.310, tt:1766.991\n",
      "Ep:87, loss:0.00001, loss_test:0.09902, lr:7.32e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.304, tt:1786.726\n",
      "Ep:88, loss:0.00001, loss_test:0.09541, lr:7.25e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.304, tt:1807.071\n",
      "Ep:89, loss:0.00001, loss_test:0.09760, lr:7.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.297, tt:1826.731\n",
      "Ep:90, loss:0.00001, loss_test:0.09619, lr:7.11e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.291, tt:1846.504\n",
      "Ep:91, loss:0.00001, loss_test:0.09898, lr:7.03e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.311, tt:1868.568\n",
      "Ep:92, loss:0.00001, loss_test:0.10019, lr:6.96e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.316, tt:1889.344\n",
      "Ep:93, loss:0.00001, loss_test:0.09356, lr:6.89e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.326, tt:1910.688\n",
      "Ep:94, loss:0.00001, loss_test:0.10064, lr:6.83e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.331, tt:1931.471\n",
      "Ep:95, loss:0.00001, loss_test:0.09735, lr:6.76e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.329, tt:1951.624\n",
      "Ep:96, loss:0.00001, loss_test:0.09519, lr:6.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.334, tt:1972.434\n",
      "Ep:97, loss:0.00001, loss_test:0.09952, lr:6.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.331, tt:1992.405\n",
      "Ep:98, loss:0.00001, loss_test:0.09616, lr:6.56e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.320, tt:2011.727\n",
      "Ep:99, loss:0.00001, loss_test:0.09627, lr:6.49e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.319, tt:2031.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00001, loss_test:0.09899, lr:6.43e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.309, tt:2051.164\n",
      "Ep:101, loss:0.00001, loss_test:0.09567, lr:6.36e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.300, tt:2070.554\n",
      "Ep:102, loss:0.00001, loss_test:0.09864, lr:6.30e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.331, tt:2094.045\n",
      "Ep:103, loss:0.00001, loss_test:0.10006, lr:6.24e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.327, tt:2114.021\n",
      "Ep:104, loss:0.00001, loss_test:0.09566, lr:6.17e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.343, tt:2136.028\n",
      "Ep:105, loss:0.00001, loss_test:0.09954, lr:6.11e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.337, tt:2155.761\n",
      "Ep:106, loss:0.00001, loss_test:0.09696, lr:6.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.360, tt:2178.492\n",
      "Ep:107, loss:0.00001, loss_test:0.09763, lr:5.99e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.371, tt:2200.085\n",
      "Ep:108, loss:0.00001, loss_test:0.09886, lr:5.93e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.371, tt:2220.397\n",
      "Ep:109, loss:0.00001, loss_test:0.09759, lr:5.87e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.379, tt:2241.656\n",
      "Ep:110, loss:0.00000, loss_test:0.09636, lr:5.81e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.373, tt:2261.425\n",
      "Ep:111, loss:0.00000, loss_test:0.09820, lr:5.75e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.375, tt:2281.955\n",
      "Ep:112, loss:0.00000, loss_test:0.09939, lr:5.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.352, tt:2299.828\n",
      "Ep:113, loss:0.00000, loss_test:0.09778, lr:5.64e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.345, tt:2319.352\n",
      "Ep:114, loss:0.00000, loss_test:0.09942, lr:5.58e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.339, tt:2339.033\n",
      "Ep:115, loss:0.00000, loss_test:0.09957, lr:5.53e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.335, tt:2358.864\n",
      "Ep:116, loss:0.00000, loss_test:0.09688, lr:5.47e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.318, tt:2377.209\n",
      "Ep:117, loss:0.00000, loss_test:0.09937, lr:5.42e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.329, tt:2398.780\n",
      "Ep:118, loss:0.00000, loss_test:0.09923, lr:5.36e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.327, tt:2418.924\n",
      "Ep:119, loss:0.00000, loss_test:0.09702, lr:5.31e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.345, tt:2441.432\n",
      "Ep:120, loss:0.00000, loss_test:0.10109, lr:5.26e-03, fs:0.70440 (r=0.566,p=0.933),  time:20.346, tt:2461.887\n",
      "Ep:121, loss:0.00000, loss_test:0.10394, lr:5.20e-03, fs:0.70440 (r=0.566,p=0.933),  time:20.362, tt:2484.197\n",
      "Ep:122, loss:0.00000, loss_test:0.09799, lr:5.15e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.363, tt:2504.706\n",
      "Ep:123, loss:0.00000, loss_test:0.10054, lr:5.10e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.377, tt:2526.784\n",
      "Ep:124, loss:0.00000, loss_test:0.10287, lr:5.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.376, tt:2547.059\n",
      "Ep:125, loss:0.00000, loss_test:0.10005, lr:5.00e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.370, tt:2566.664\n",
      "Ep:126, loss:0.00000, loss_test:0.10028, lr:4.95e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.370, tt:2586.935\n",
      "Ep:127, loss:0.00000, loss_test:0.10222, lr:4.90e-03, fs:0.70064 (r=0.556,p=0.948),  time:20.363, tt:2606.448\n",
      "Ep:128, loss:0.00000, loss_test:0.10091, lr:4.85e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.361, tt:2626.527\n",
      "Ep:129, loss:0.00000, loss_test:0.09880, lr:4.80e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.349, tt:2645.423\n",
      "Ep:130, loss:0.00000, loss_test:0.10036, lr:4.75e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.340, tt:2664.563\n",
      "Ep:131, loss:0.00000, loss_test:0.10062, lr:4.71e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.337, tt:2684.522\n",
      "Ep:132, loss:0.00000, loss_test:0.10057, lr:4.66e-03, fs:0.70064 (r=0.556,p=0.948),  time:20.357, tt:2707.463\n",
      "Ep:133, loss:0.00000, loss_test:0.09965, lr:4.61e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.357, tt:2727.887\n",
      "Ep:134, loss:0.00000, loss_test:0.09991, lr:4.57e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.380, tt:2751.278\n",
      "Ep:135, loss:0.00000, loss_test:0.09966, lr:4.52e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.381, tt:2771.816\n",
      "Ep:136, loss:0.00000, loss_test:0.10026, lr:4.48e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.391, tt:2793.590\n",
      "Ep:137, loss:0.00000, loss_test:0.10108, lr:4.43e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.389, tt:2813.626\n",
      "Ep:138, loss:0.00000, loss_test:0.10081, lr:4.39e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.395, tt:2834.930\n",
      "Ep:139, loss:0.00000, loss_test:0.10008, lr:4.34e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.401, tt:2856.141\n",
      "Ep:140, loss:0.00000, loss_test:0.10058, lr:4.30e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.411, tt:2877.892\n",
      "Ep:141, loss:0.00000, loss_test:0.10018, lr:4.26e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.410, tt:2898.283\n",
      "Ep:142, loss:0.00000, loss_test:0.09960, lr:4.21e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.420, tt:2920.032\n",
      "Ep:143, loss:0.00000, loss_test:0.10162, lr:4.17e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.433, tt:2942.383\n",
      "Ep:144, loss:0.00000, loss_test:0.10286, lr:4.13e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.435, tt:2963.094\n",
      "Ep:145, loss:0.00000, loss_test:0.10122, lr:4.09e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.431, tt:2982.959\n",
      "Ep:146, loss:0.00000, loss_test:0.10004, lr:4.05e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.420, tt:3001.769\n",
      "Ep:147, loss:0.00000, loss_test:0.10122, lr:4.01e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.419, tt:3022.000\n",
      "Ep:148, loss:0.00000, loss_test:0.10160, lr:3.97e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.416, tt:3042.023\n",
      "Ep:149, loss:0.00000, loss_test:0.10115, lr:3.93e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.420, tt:3063.010\n",
      "Ep:150, loss:0.00000, loss_test:0.10106, lr:3.89e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.423, tt:3083.923\n",
      "Ep:151, loss:0.00000, loss_test:0.10158, lr:3.85e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.423, tt:3104.290\n",
      "Ep:152, loss:0.00000, loss_test:0.10123, lr:3.81e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.424, tt:3124.910\n",
      "Ep:153, loss:0.00000, loss_test:0.10123, lr:3.77e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.428, tt:3145.847\n",
      "Ep:154, loss:0.00000, loss_test:0.10162, lr:3.73e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.434, tt:3167.293\n",
      "Ep:155, loss:0.00000, loss_test:0.10222, lr:3.70e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.443, tt:3189.131\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14024, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:26.035, tt:26.035\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13716, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:23.427, tt:46.854\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13425, lr:1.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:23.145, tt:69.435\n",
      "Ep:3, loss:0.00025, loss_test:0.13271, lr:1.00e-02, fs:0.60177 (r=0.687,p=0.535),  time:23.007, tt:92.027\n",
      "Ep:4, loss:0.00024, loss_test:0.12929, lr:1.00e-02, fs:0.59259 (r=0.646,p=0.547),  time:23.231, tt:116.154\n",
      "Ep:5, loss:0.00023, loss_test:0.12536, lr:1.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:23.022, tt:138.133\n",
      "Ep:6, loss:0.00023, loss_test:0.12311, lr:1.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:24.111, tt:168.776\n",
      "Ep:7, loss:0.00022, loss_test:0.12075, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:23.955, tt:191.637\n",
      "Ep:8, loss:0.00021, loss_test:0.11782, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:23.901, tt:215.110\n",
      "Ep:9, loss:0.00020, loss_test:0.11576, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:23.781, tt:237.813\n",
      "Ep:10, loss:0.00019, loss_test:0.11159, lr:1.00e-02, fs:0.64516 (r=0.606,p=0.690),  time:23.744, tt:261.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00018, loss_test:0.10814, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:23.703, tt:284.437\n",
      "Ep:12, loss:0.00017, loss_test:0.10569, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:23.780, tt:309.142\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.10361, lr:1.00e-02, fs:0.67027 (r=0.626,p=0.721),  time:23.845, tt:333.831\n",
      "Ep:14, loss:0.00016, loss_test:0.10212, lr:1.00e-02, fs:0.69149 (r=0.657,p=0.730),  time:23.745, tt:356.178\n",
      "Ep:15, loss:0.00015, loss_test:0.10038, lr:1.00e-02, fs:0.69892 (r=0.657,p=0.747),  time:23.889, tt:382.221\n",
      "Ep:16, loss:0.00014, loss_test:0.10004, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:23.882, tt:406.001\n",
      "Ep:17, loss:0.00014, loss_test:0.09925, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:24.046, tt:432.827\n",
      "Ep:18, loss:0.00013, loss_test:0.09886, lr:1.00e-02, fs:0.69613 (r=0.636,p=0.768),  time:24.002, tt:456.034\n",
      "Ep:19, loss:0.00013, loss_test:0.09811, lr:1.00e-02, fs:0.71111 (r=0.646,p=0.790),  time:24.185, tt:483.698\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.09750, lr:1.00e-02, fs:0.70000 (r=0.636,p=0.778),  time:24.256, tt:509.378\n",
      "Ep:21, loss:0.00011, loss_test:0.09851, lr:1.00e-02, fs:0.66279 (r=0.576,p=0.781),  time:24.222, tt:532.894\n",
      "Ep:22, loss:0.00011, loss_test:0.09666, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:24.200, tt:556.594\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.09970, lr:1.00e-02, fs:0.66667 (r=0.556,p=0.833),  time:24.139, tt:579.326\n",
      "Ep:24, loss:0.00010, loss_test:0.09482, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:24.143, tt:603.569\n",
      "Ep:25, loss:0.00010, loss_test:0.09875, lr:1.00e-02, fs:0.67073 (r=0.556,p=0.846),  time:24.160, tt:628.172\n",
      "Ep:26, loss:0.00009, loss_test:0.09395, lr:1.00e-02, fs:0.67442 (r=0.586,p=0.795),  time:24.179, tt:652.820\n",
      "Ep:27, loss:0.00009, loss_test:0.09503, lr:1.00e-02, fs:0.67470 (r=0.566,p=0.836),  time:24.198, tt:677.552\n",
      "Ep:28, loss:0.00008, loss_test:0.09551, lr:1.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:24.168, tt:700.861\n",
      "Ep:29, loss:0.00008, loss_test:0.09189, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:24.186, tt:725.580\n",
      "Ep:30, loss:0.00008, loss_test:0.09561, lr:1.00e-02, fs:0.69565 (r=0.566,p=0.903),  time:24.150, tt:748.656\n",
      "Ep:31, loss:0.00007, loss_test:0.09108, lr:1.00e-02, fs:0.70455 (r=0.626,p=0.805),  time:24.129, tt:772.144\n",
      "Ep:32, loss:0.00007, loss_test:0.09551, lr:1.00e-02, fs:0.69565 (r=0.566,p=0.903),  time:24.140, tt:796.609\n",
      "Ep:33, loss:0.00007, loss_test:0.09097, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:24.058, tt:817.965\n",
      "Ep:34, loss:0.00006, loss_test:0.09231, lr:9.90e-03, fs:0.73054 (r=0.616,p=0.897),  time:23.961, tt:838.646\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.08758, lr:9.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:23.847, tt:858.484\n",
      "Ep:36, loss:0.00006, loss_test:0.09460, lr:9.90e-03, fs:0.71951 (r=0.596,p=0.908),  time:23.726, tt:877.864\n",
      "Ep:37, loss:0.00006, loss_test:0.08867, lr:9.90e-03, fs:0.73684 (r=0.636,p=0.875),  time:23.590, tt:896.424\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.09217, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:23.564, tt:919.013\n",
      "Ep:39, loss:0.00005, loss_test:0.08932, lr:9.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:23.597, tt:943.872\n",
      "Ep:40, loss:0.00005, loss_test:0.08930, lr:9.90e-03, fs:0.72289 (r=0.606,p=0.896),  time:23.570, tt:966.364\n",
      "Ep:41, loss:0.00005, loss_test:0.08958, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:23.641, tt:992.940\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.08805, lr:9.90e-03, fs:0.73373 (r=0.626,p=0.886),  time:23.646, tt:1016.774\n",
      "Ep:43, loss:0.00004, loss_test:0.08640, lr:9.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:23.646, tt:1040.435\n",
      "Ep:44, loss:0.00004, loss_test:0.08873, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:23.654, tt:1064.419\n",
      "Ep:45, loss:0.00004, loss_test:0.08586, lr:9.90e-03, fs:0.74854 (r=0.646,p=0.889),  time:23.662, tt:1088.463\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.08969, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:23.641, tt:1111.107\n",
      "Ep:47, loss:0.00004, loss_test:0.08685, lr:9.90e-03, fs:0.74118 (r=0.636,p=0.887),  time:23.629, tt:1134.203\n",
      "Ep:48, loss:0.00003, loss_test:0.08778, lr:9.90e-03, fs:0.73810 (r=0.626,p=0.899),  time:23.658, tt:1159.260\n",
      "Ep:49, loss:0.00003, loss_test:0.08749, lr:9.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:23.659, tt:1182.975\n",
      "Ep:50, loss:0.00003, loss_test:0.08503, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:23.667, tt:1207.039\n",
      "Ep:51, loss:0.00003, loss_test:0.08788, lr:9.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:23.625, tt:1228.518\n",
      "Ep:52, loss:0.00003, loss_test:0.08447, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:23.629, tt:1252.341\n",
      "Ep:53, loss:0.00003, loss_test:0.08648, lr:9.90e-03, fs:0.75904 (r=0.636,p=0.940),  time:23.642, tt:1276.692\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.08678, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:23.673, tt:1302.012\n",
      "Ep:55, loss:0.00003, loss_test:0.08422, lr:9.90e-03, fs:0.73171 (r=0.606,p=0.923),  time:23.695, tt:1326.924\n",
      "Ep:56, loss:0.00003, loss_test:0.08649, lr:9.90e-03, fs:0.75610 (r=0.626,p=0.954),  time:23.723, tt:1352.183\n",
      "Ep:57, loss:0.00002, loss_test:0.08455, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:23.753, tt:1377.670\n",
      "Ep:58, loss:0.00002, loss_test:0.08504, lr:9.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:23.747, tt:1401.045\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.08643, lr:9.90e-03, fs:0.69620 (r=0.556,p=0.932),  time:23.771, tt:1426.265\n",
      "Ep:60, loss:0.00002, loss_test:0.08165, lr:9.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:23.741, tt:1448.213\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.08513, lr:9.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:23.765, tt:1473.437\n",
      "Ep:62, loss:0.00002, loss_test:0.08370, lr:9.90e-03, fs:0.74074 (r=0.606,p=0.952),  time:23.806, tt:1499.748\n",
      "Ep:63, loss:0.00002, loss_test:0.08251, lr:9.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:23.789, tt:1522.498\n",
      "Ep:64, loss:0.00002, loss_test:0.08435, lr:9.90e-03, fs:0.73292 (r=0.596,p=0.952),  time:23.792, tt:1546.482\n",
      "Ep:65, loss:0.00002, loss_test:0.08131, lr:9.90e-03, fs:0.78107 (r=0.667,p=0.943),  time:23.765, tt:1568.502\n",
      "Ep:66, loss:0.00002, loss_test:0.08446, lr:9.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:23.767, tt:1592.379\n",
      "Ep:67, loss:0.00002, loss_test:0.08281, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:23.750, tt:1615.020\n",
      "Ep:68, loss:0.00002, loss_test:0.08428, lr:9.90e-03, fs:0.73292 (r=0.596,p=0.952),  time:23.770, tt:1640.118\n",
      "Ep:69, loss:0.00002, loss_test:0.08301, lr:9.90e-03, fs:0.74847 (r=0.616,p=0.953),  time:23.749, tt:1662.407\n",
      "Ep:70, loss:0.00001, loss_test:0.08448, lr:9.90e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.767, tt:1687.478\n",
      "Ep:71, loss:0.00001, loss_test:0.08331, lr:9.90e-03, fs:0.70440 (r=0.566,p=0.933),  time:23.794, tt:1713.174\n",
      "Ep:72, loss:0.00001, loss_test:0.08164, lr:9.80e-03, fs:0.73292 (r=0.596,p=0.952),  time:23.769, tt:1735.141\n",
      "Ep:73, loss:0.00001, loss_test:0.08504, lr:9.70e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.807, tt:1761.741\n",
      "Ep:74, loss:0.00001, loss_test:0.08376, lr:9.61e-03, fs:0.72500 (r=0.586,p=0.951),  time:23.810, tt:1785.741\n",
      "Ep:75, loss:0.00001, loss_test:0.08165, lr:9.51e-03, fs:0.70440 (r=0.566,p=0.933),  time:23.814, tt:1809.856\n",
      "Ep:76, loss:0.00001, loss_test:0.08539, lr:9.41e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.807, tt:1833.165\n",
      "Ep:77, loss:0.00001, loss_test:0.08290, lr:9.32e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.821, tt:1858.038\n",
      "Ep:78, loss:0.00001, loss_test:0.08407, lr:9.23e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.838, tt:1883.240\n",
      "Ep:79, loss:0.00001, loss_test:0.08349, lr:9.14e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.829, tt:1906.355\n",
      "Ep:80, loss:0.00001, loss_test:0.08454, lr:9.04e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.831, tt:1930.324\n",
      "Ep:81, loss:0.00001, loss_test:0.08354, lr:8.95e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.857, tt:1956.307\n",
      "Ep:82, loss:0.00001, loss_test:0.08255, lr:8.86e-03, fs:0.71698 (r=0.576,p=0.950),  time:23.876, tt:1981.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.08430, lr:8.78e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.857, tt:2003.981\n",
      "Ep:84, loss:0.00001, loss_test:0.08245, lr:8.69e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.857, tt:2027.877\n",
      "Ep:85, loss:0.00001, loss_test:0.08488, lr:8.60e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.846, tt:2050.736\n",
      "Ep:86, loss:0.00001, loss_test:0.08289, lr:8.51e-03, fs:0.71698 (r=0.576,p=0.950),  time:23.862, tt:2075.963\n",
      "Ep:87, loss:0.00001, loss_test:0.08561, lr:8.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.885, tt:2101.855\n",
      "Ep:88, loss:0.00001, loss_test:0.08656, lr:8.35e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.886, tt:2125.815\n",
      "Ep:89, loss:0.00001, loss_test:0.08420, lr:8.26e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.897, tt:2150.716\n",
      "Ep:90, loss:0.00001, loss_test:0.08596, lr:8.18e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.877, tt:2172.794\n",
      "Ep:91, loss:0.00001, loss_test:0.08448, lr:8.10e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.893, tt:2198.195\n",
      "Ep:92, loss:0.00001, loss_test:0.08542, lr:8.02e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.876, tt:2220.423\n",
      "Ep:93, loss:0.00001, loss_test:0.08501, lr:7.94e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.889, tt:2245.531\n",
      "Ep:94, loss:0.00001, loss_test:0.08496, lr:7.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.879, tt:2268.530\n",
      "Ep:95, loss:0.00001, loss_test:0.08534, lr:7.78e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.882, tt:2292.655\n",
      "Ep:96, loss:0.00001, loss_test:0.08546, lr:7.70e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.888, tt:2317.095\n",
      "Ep:97, loss:0.00001, loss_test:0.08639, lr:7.62e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.875, tt:2339.747\n",
      "Ep:98, loss:0.00001, loss_test:0.08522, lr:7.55e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.875, tt:2363.598\n",
      "Ep:99, loss:0.00001, loss_test:0.08629, lr:7.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.870, tt:2386.990\n",
      "Ep:100, loss:0.00001, loss_test:0.08808, lr:7.40e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.884, tt:2412.284\n",
      "Ep:101, loss:0.00001, loss_test:0.08758, lr:7.32e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.870, tt:2434.756\n",
      "Ep:102, loss:0.00001, loss_test:0.08597, lr:7.25e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.875, tt:2459.129\n",
      "Ep:103, loss:0.00001, loss_test:0.08739, lr:7.18e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.865, tt:2481.913\n",
      "Ep:104, loss:0.00001, loss_test:0.08973, lr:7.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.880, tt:2507.440\n",
      "Ep:105, loss:0.00001, loss_test:0.08711, lr:7.03e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.892, tt:2532.510\n",
      "Ep:106, loss:0.00001, loss_test:0.08705, lr:6.96e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.879, tt:2555.015\n",
      "Ep:107, loss:0.00001, loss_test:0.08760, lr:6.89e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.882, tt:2579.237\n",
      "Ep:108, loss:0.00001, loss_test:0.08583, lr:6.83e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.878, tt:2602.750\n",
      "Ep:109, loss:0.00001, loss_test:0.08781, lr:6.76e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.893, tt:2628.185\n",
      "Ep:110, loss:0.00000, loss_test:0.08775, lr:6.69e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.887, tt:2651.487\n",
      "Ep:111, loss:0.00000, loss_test:0.08672, lr:6.62e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.894, tt:2676.176\n",
      "Ep:112, loss:0.00000, loss_test:0.08589, lr:6.56e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.885, tt:2698.986\n",
      "Ep:113, loss:0.00000, loss_test:0.08693, lr:6.49e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.886, tt:2723.060\n",
      "Ep:114, loss:0.00000, loss_test:0.08777, lr:6.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.893, tt:2747.638\n",
      "Ep:115, loss:0.00000, loss_test:0.08639, lr:6.36e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.895, tt:2771.790\n",
      "Ep:116, loss:0.00000, loss_test:0.08792, lr:6.30e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.898, tt:2796.015\n",
      "Ep:117, loss:0.00000, loss_test:0.08884, lr:6.24e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.891, tt:2819.179\n",
      "Ep:118, loss:0.00000, loss_test:0.08660, lr:6.17e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.908, tt:2845.110\n",
      "Ep:119, loss:0.00000, loss_test:0.08705, lr:6.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.898, tt:2867.703\n",
      "Ep:120, loss:0.00000, loss_test:0.08818, lr:6.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.922, tt:2894.587\n",
      "Ep:121, loss:0.00000, loss_test:0.08671, lr:5.99e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.911, tt:2917.106\n",
      "Ep:122, loss:0.00000, loss_test:0.08722, lr:5.93e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.928, tt:2943.146\n",
      "Ep:123, loss:0.00000, loss_test:0.08713, lr:5.87e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.930, tt:2967.374\n",
      "Ep:124, loss:0.00000, loss_test:0.08764, lr:5.81e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.925, tt:2990.634\n",
      "Ep:125, loss:0.00000, loss_test:0.08660, lr:5.75e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.935, tt:3015.833\n",
      "Ep:126, loss:0.00000, loss_test:0.08615, lr:5.70e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.927, tt:3038.782\n",
      "Ep:127, loss:0.00000, loss_test:0.08785, lr:5.64e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.943, tt:3064.749\n",
      "Ep:128, loss:0.00000, loss_test:0.08687, lr:5.58e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.949, tt:3089.465\n",
      "Ep:129, loss:0.00000, loss_test:0.08815, lr:5.53e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.971, tt:3116.168\n",
      "Ep:130, loss:0.00000, loss_test:0.08799, lr:5.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.968, tt:3139.812\n",
      "Ep:131, loss:0.00000, loss_test:0.08688, lr:5.42e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.957, tt:3162.261\n",
      "Ep:132, loss:0.00000, loss_test:0.08790, lr:5.36e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.959, tt:3186.520\n",
      "Ep:133, loss:0.00000, loss_test:0.08729, lr:5.31e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.945, tt:3208.578\n",
      "Ep:134, loss:0.00000, loss_test:0.08638, lr:5.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.958, tt:3234.305\n",
      "Ep:135, loss:0.00000, loss_test:0.08855, lr:5.20e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.945, tt:3256.514\n",
      "Ep:136, loss:0.00000, loss_test:0.08833, lr:5.15e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.955, tt:3281.857\n",
      "Ep:137, loss:0.00000, loss_test:0.08773, lr:5.10e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.961, tt:3306.552\n",
      "Ep:138, loss:0.00000, loss_test:0.08787, lr:5.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.967, tt:3331.393\n",
      "Ep:139, loss:0.00000, loss_test:0.08741, lr:5.00e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.956, tt:3353.799\n",
      "Ep:140, loss:0.00000, loss_test:0.08759, lr:4.95e-03, fs:0.68831 (r=0.535,p=0.964),  time:23.960, tt:3378.335\n",
      "Ep:141, loss:0.00000, loss_test:0.08862, lr:4.90e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.965, tt:3403.054\n",
      "Ep:142, loss:0.00000, loss_test:0.08872, lr:4.85e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.967, tt:3427.325\n",
      "Ep:143, loss:0.00000, loss_test:0.08819, lr:4.80e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.967, tt:3451.260\n",
      "Ep:144, loss:0.00000, loss_test:0.08791, lr:4.75e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.952, tt:3473.012\n",
      "Ep:145, loss:0.00000, loss_test:0.08802, lr:4.71e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.962, tt:3498.401\n",
      "Ep:146, loss:0.00000, loss_test:0.08841, lr:4.66e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.962, tt:3522.419\n",
      "Ep:147, loss:0.00000, loss_test:0.08859, lr:4.61e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.971, tt:3547.754\n",
      "Ep:148, loss:0.00000, loss_test:0.08863, lr:4.57e-03, fs:0.68831 (r=0.535,p=0.964),  time:23.973, tt:3571.952\n",
      "Ep:149, loss:0.00000, loss_test:0.08731, lr:4.52e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.972, tt:3595.732\n",
      "Ep:150, loss:0.00000, loss_test:0.08843, lr:4.48e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.984, tt:3621.632\n",
      "Ep:151, loss:0.00000, loss_test:0.08864, lr:4.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.968, tt:3643.108\n",
      "Ep:152, loss:0.00000, loss_test:0.08755, lr:4.39e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.977, tt:3668.528\n",
      "Ep:153, loss:0.00000, loss_test:0.08824, lr:4.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.973, tt:3691.851\n",
      "Ep:154, loss:0.00000, loss_test:0.08804, lr:4.30e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.989, tt:3718.369\n",
      "Ep:155, loss:0.00000, loss_test:0.08803, lr:4.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.980, tt:3740.854\n",
      "Ep:156, loss:0.00000, loss_test:0.08852, lr:4.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.990, tt:3766.356\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14504, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:40.494, tt:40.494\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14392, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:41.806, tt:83.612\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.14182, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:42.290, tt:126.870\n",
      "Ep:3, loss:0.00027, loss_test:0.13835, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:42.056, tt:168.225\n",
      "Ep:4, loss:0.00027, loss_test:0.13303, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:42.040, tt:210.201\n",
      "Ep:5, loss:0.00026, loss_test:0.12483, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:42.479, tt:254.876\n",
      "Ep:6, loss:0.00024, loss_test:0.11488, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:42.441, tt:297.086\n",
      "Ep:7, loss:0.00022, loss_test:0.11165, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:42.688, tt:341.508\n",
      "Ep:8, loss:0.00021, loss_test:0.11296, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:42.847, tt:385.626\n",
      "Ep:9, loss:0.00021, loss_test:0.11226, lr:1.00e-02, fs:0.65700 (r=0.687,p=0.630),  time:43.014, tt:430.140\n",
      "Ep:10, loss:0.00020, loss_test:0.11004, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:43.012, tt:473.128\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10817, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:43.118, tt:517.412\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10562, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:43.061, tt:559.797\n",
      "Ep:13, loss:0.00018, loss_test:0.10467, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:43.020, tt:602.284\n",
      "Ep:14, loss:0.00018, loss_test:0.10419, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:43.047, tt:645.702\n",
      "Ep:15, loss:0.00017, loss_test:0.10353, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:43.094, tt:689.509\n",
      "Ep:16, loss:0.00017, loss_test:0.10305, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:43.067, tt:732.144\n",
      "Ep:17, loss:0.00017, loss_test:0.10294, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:43.025, tt:774.448\n",
      "Ep:18, loss:0.00016, loss_test:0.10324, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:42.880, tt:814.727\n",
      "Ep:19, loss:0.00016, loss_test:0.10261, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:42.858, tt:857.153\n",
      "Ep:20, loss:0.00015, loss_test:0.10266, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:42.884, tt:900.564\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.10207, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:42.886, tt:943.502\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.10158, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:42.911, tt:986.948\n",
      "Ep:23, loss:0.00014, loss_test:0.10327, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:42.790, tt:1026.949\n",
      "Ep:24, loss:0.00014, loss_test:0.10307, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:42.696, tt:1067.393\n",
      "Ep:25, loss:0.00014, loss_test:0.10218, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:42.694, tt:1110.040\n",
      "Ep:26, loss:0.00013, loss_test:0.10307, lr:1.00e-02, fs:0.65608 (r=0.626,p=0.689),  time:42.639, tt:1151.243\n",
      "Ep:27, loss:0.00013, loss_test:0.10082, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:42.692, tt:1195.368\n",
      "Ep:28, loss:0.00013, loss_test:0.10239, lr:1.00e-02, fs:0.66667 (r=0.606,p=0.741),  time:42.669, tt:1237.392\n",
      "Ep:29, loss:0.00012, loss_test:0.10095, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:42.652, tt:1279.572\n",
      "Ep:30, loss:0.00012, loss_test:0.10152, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:42.626, tt:1321.400\n",
      "Ep:31, loss:0.00012, loss_test:0.10209, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:42.591, tt:1362.915\n",
      "Ep:32, loss:0.00011, loss_test:0.10353, lr:1.00e-02, fs:0.67816 (r=0.596,p=0.787),  time:42.601, tt:1405.847\n",
      "Ep:33, loss:0.00011, loss_test:0.10140, lr:9.90e-03, fs:0.68852 (r=0.636,p=0.750),  time:42.516, tt:1445.538\n",
      "Ep:34, loss:0.00011, loss_test:0.10484, lr:9.80e-03, fs:0.68571 (r=0.606,p=0.789),  time:42.500, tt:1487.502\n",
      "Ep:35, loss:0.00011, loss_test:0.10522, lr:9.70e-03, fs:0.67778 (r=0.616,p=0.753),  time:42.475, tt:1529.098\n",
      "Ep:36, loss:0.00011, loss_test:0.10190, lr:9.61e-03, fs:0.71111 (r=0.646,p=0.790),  time:42.494, tt:1572.272\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.10848, lr:9.61e-03, fs:0.68571 (r=0.606,p=0.789),  time:42.438, tt:1612.643\n",
      "Ep:38, loss:0.00010, loss_test:0.10221, lr:9.61e-03, fs:0.71038 (r=0.657,p=0.774),  time:42.364, tt:1652.196\n",
      "Ep:39, loss:0.00010, loss_test:0.10831, lr:9.61e-03, fs:0.69412 (r=0.596,p=0.831),  time:42.345, tt:1693.819\n",
      "Ep:40, loss:0.00010, loss_test:0.10504, lr:9.61e-03, fs:0.69663 (r=0.626,p=0.785),  time:42.407, tt:1738.683\n",
      "Ep:41, loss:0.00009, loss_test:0.10736, lr:9.61e-03, fs:0.70588 (r=0.606,p=0.845),  time:42.421, tt:1781.682\n",
      "Ep:42, loss:0.00009, loss_test:0.10621, lr:9.61e-03, fs:0.70857 (r=0.626,p=0.816),  time:42.438, tt:1824.816\n",
      "Ep:43, loss:0.00009, loss_test:0.10494, lr:9.61e-03, fs:0.69767 (r=0.606,p=0.822),  time:42.386, tt:1864.986\n",
      "Ep:44, loss:0.00009, loss_test:0.10738, lr:9.61e-03, fs:0.69412 (r=0.596,p=0.831),  time:42.311, tt:1904.009\n",
      "Ep:45, loss:0.00009, loss_test:0.10475, lr:9.61e-03, fs:0.70455 (r=0.626,p=0.805),  time:42.356, tt:1948.392\n",
      "Ep:46, loss:0.00008, loss_test:0.10837, lr:9.61e-03, fs:0.68571 (r=0.606,p=0.789),  time:42.374, tt:1991.571\n",
      "Ep:47, loss:0.00009, loss_test:0.10668, lr:9.61e-03, fs:0.69822 (r=0.596,p=0.843),  time:42.386, tt:2034.515\n",
      "Ep:48, loss:0.00008, loss_test:0.10456, lr:9.51e-03, fs:0.70455 (r=0.626,p=0.805),  time:42.361, tt:2075.670\n",
      "Ep:49, loss:0.00008, loss_test:0.10773, lr:9.41e-03, fs:0.70659 (r=0.596,p=0.868),  time:42.314, tt:2115.699\n",
      "Ep:50, loss:0.00008, loss_test:0.10518, lr:9.32e-03, fs:0.68927 (r=0.616,p=0.782),  time:42.292, tt:2156.912\n",
      "Ep:51, loss:0.00007, loss_test:0.10882, lr:9.23e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.270, tt:2198.054\n",
      "Ep:52, loss:0.00008, loss_test:0.10618, lr:9.14e-03, fs:0.70857 (r=0.626,p=0.816),  time:42.287, tt:2241.197\n",
      "Ep:53, loss:0.00007, loss_test:0.11248, lr:9.04e-03, fs:0.66265 (r=0.556,p=0.821),  time:42.248, tt:2281.393\n",
      "Ep:54, loss:0.00007, loss_test:0.10388, lr:8.95e-03, fs:0.69318 (r=0.616,p=0.792),  time:42.197, tt:2320.813\n",
      "Ep:55, loss:0.00007, loss_test:0.10902, lr:8.86e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.136, tt:2359.628\n",
      "Ep:56, loss:0.00007, loss_test:0.10877, lr:8.78e-03, fs:0.69364 (r=0.606,p=0.811),  time:42.106, tt:2400.036\n",
      "Ep:57, loss:0.00007, loss_test:0.10760, lr:8.69e-03, fs:0.69880 (r=0.586,p=0.866),  time:42.096, tt:2441.595\n",
      "Ep:58, loss:0.00007, loss_test:0.10896, lr:8.60e-03, fs:0.66667 (r=0.566,p=0.812),  time:42.071, tt:2482.178\n",
      "Ep:59, loss:0.00007, loss_test:0.10758, lr:8.51e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.059, tt:2523.568\n",
      "Ep:60, loss:0.00006, loss_test:0.10938, lr:8.43e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.041, tt:2564.507\n",
      "Ep:61, loss:0.00006, loss_test:0.11047, lr:8.35e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.012, tt:2604.763\n",
      "Ep:62, loss:0.00006, loss_test:0.10567, lr:8.26e-03, fs:0.70520 (r=0.616,p=0.824),  time:41.994, tt:2645.606\n",
      "Ep:63, loss:0.00006, loss_test:0.11275, lr:8.18e-03, fs:0.65854 (r=0.545,p=0.831),  time:42.017, tt:2689.057\n",
      "Ep:64, loss:0.00006, loss_test:0.10811, lr:8.10e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.044, tt:2732.872\n",
      "Ep:65, loss:0.00006, loss_test:0.11131, lr:8.02e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.064, tt:2776.233\n",
      "Ep:66, loss:0.00006, loss_test:0.11067, lr:7.94e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.049, tt:2817.279\n",
      "Ep:67, loss:0.00005, loss_test:0.10915, lr:7.86e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.046, tt:2859.102\n",
      "Ep:68, loss:0.00005, loss_test:0.10985, lr:7.78e-03, fs:0.67066 (r=0.566,p=0.824),  time:42.054, tt:2901.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00005, loss_test:0.10963, lr:7.70e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.091, tt:2946.398\n",
      "Ep:70, loss:0.00006, loss_test:0.11033, lr:7.62e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.101, tt:2989.200\n",
      "Ep:71, loss:0.00005, loss_test:0.11094, lr:7.55e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.102, tt:3031.343\n",
      "Ep:72, loss:0.00005, loss_test:0.11368, lr:7.47e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.109, tt:3073.938\n",
      "Ep:73, loss:0.00005, loss_test:0.10983, lr:7.40e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.133, tt:3117.823\n",
      "Ep:74, loss:0.00005, loss_test:0.11364, lr:7.32e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.166, tt:3162.441\n",
      "Ep:75, loss:0.00005, loss_test:0.11469, lr:7.25e-03, fs:0.65031 (r=0.535,p=0.828),  time:42.161, tt:3204.240\n",
      "Ep:76, loss:0.00005, loss_test:0.11035, lr:7.18e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.159, tt:3246.236\n",
      "Ep:77, loss:0.00005, loss_test:0.11709, lr:7.11e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.183, tt:3290.243\n",
      "Ep:78, loss:0.00004, loss_test:0.11285, lr:7.03e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.199, tt:3333.747\n",
      "Ep:79, loss:0.00004, loss_test:0.11207, lr:6.96e-03, fs:0.67073 (r=0.556,p=0.846),  time:42.249, tt:3379.954\n",
      "Ep:80, loss:0.00004, loss_test:0.11555, lr:6.89e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.287, tt:3425.286\n",
      "Ep:81, loss:0.00004, loss_test:0.11368, lr:6.83e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.302, tt:3468.799\n",
      "Ep:82, loss:0.00004, loss_test:0.11291, lr:6.76e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.301, tt:3510.984\n",
      "Ep:83, loss:0.00004, loss_test:0.11431, lr:6.69e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.336, tt:3556.189\n",
      "Ep:84, loss:0.00004, loss_test:0.11412, lr:6.62e-03, fs:0.65432 (r=0.535,p=0.841),  time:42.368, tt:3601.263\n",
      "Ep:85, loss:0.00004, loss_test:0.11200, lr:6.56e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.330, tt:3640.373\n",
      "Ep:86, loss:0.00004, loss_test:0.11663, lr:6.49e-03, fs:0.64198 (r=0.525,p=0.825),  time:42.311, tt:3681.029\n",
      "Ep:87, loss:0.00004, loss_test:0.11305, lr:6.43e-03, fs:0.67901 (r=0.556,p=0.873),  time:42.238, tt:3716.936\n",
      "Ep:88, loss:0.00004, loss_test:0.11340, lr:6.36e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.283, tt:3763.196\n",
      "Ep:89, loss:0.00004, loss_test:0.11248, lr:6.30e-03, fs:0.67073 (r=0.556,p=0.846),  time:42.329, tt:3809.630\n",
      "Ep:90, loss:0.00004, loss_test:0.11352, lr:6.24e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.348, tt:3853.650\n",
      "Ep:91, loss:0.00004, loss_test:0.11239, lr:6.17e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.387, tt:3899.636\n",
      "Ep:92, loss:0.00004, loss_test:0.11655, lr:6.11e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.415, tt:3944.612\n",
      "Ep:93, loss:0.00004, loss_test:0.11319, lr:6.05e-03, fs:0.67485 (r=0.556,p=0.859),  time:42.420, tt:3987.464\n",
      "Ep:94, loss:0.00004, loss_test:0.11450, lr:5.99e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.434, tt:4031.272\n",
      "Ep:95, loss:0.00004, loss_test:0.11483, lr:5.93e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.468, tt:4076.920\n",
      "Ep:96, loss:0.00003, loss_test:0.11456, lr:5.87e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.486, tt:4121.185\n",
      "Ep:97, loss:0.00003, loss_test:0.11624, lr:5.81e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.513, tt:4166.289\n",
      "Ep:98, loss:0.00003, loss_test:0.11464, lr:5.75e-03, fs:0.65432 (r=0.535,p=0.841),  time:42.539, tt:4211.408\n",
      "Ep:99, loss:0.00003, loss_test:0.11666, lr:5.70e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.563, tt:4256.327\n",
      "Ep:100, loss:0.00003, loss_test:0.11584, lr:5.64e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.600, tt:4302.638\n",
      "Ep:101, loss:0.00003, loss_test:0.11577, lr:5.58e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.627, tt:4347.938\n",
      "Ep:102, loss:0.00003, loss_test:0.11749, lr:5.53e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.661, tt:4394.097\n",
      "Ep:103, loss:0.00003, loss_test:0.11494, lr:5.47e-03, fs:0.65432 (r=0.535,p=0.841),  time:42.689, tt:4439.660\n",
      "Ep:104, loss:0.00003, loss_test:0.11507, lr:5.42e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.701, tt:4483.640\n",
      "Ep:105, loss:0.00003, loss_test:0.11629, lr:5.36e-03, fs:0.65000 (r=0.525,p=0.852),  time:42.733, tt:4529.700\n",
      "Ep:106, loss:0.00003, loss_test:0.11445, lr:5.31e-03, fs:0.67081 (r=0.545,p=0.871),  time:42.743, tt:4573.463\n",
      "Ep:107, loss:0.00003, loss_test:0.11552, lr:5.26e-03, fs:0.65000 (r=0.525,p=0.852),  time:42.769, tt:4619.026\n",
      "Ep:108, loss:0.00003, loss_test:0.11539, lr:5.20e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.785, tt:4663.517\n",
      "Ep:109, loss:0.00003, loss_test:0.11541, lr:5.15e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.811, tt:4709.228\n",
      "Ep:110, loss:0.00003, loss_test:0.11573, lr:5.10e-03, fs:0.65000 (r=0.525,p=0.852),  time:42.845, tt:4755.847\n",
      "Ep:111, loss:0.00003, loss_test:0.11478, lr:5.05e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.868, tt:4801.195\n",
      "Ep:112, loss:0.00003, loss_test:0.11634, lr:5.00e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.884, tt:4845.930\n",
      "Ep:113, loss:0.00003, loss_test:0.11494, lr:4.95e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.892, tt:4889.705\n",
      "Ep:114, loss:0.00003, loss_test:0.11530, lr:4.90e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.904, tt:4933.988\n",
      "Ep:115, loss:0.00003, loss_test:0.11658, lr:4.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.923, tt:4979.051\n",
      "Ep:116, loss:0.00003, loss_test:0.11576, lr:4.80e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.941, tt:5024.058\n",
      "Ep:117, loss:0.00003, loss_test:0.11450, lr:4.75e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.973, tt:5070.818\n",
      "Ep:118, loss:0.00003, loss_test:0.11716, lr:4.71e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.999, tt:5116.910\n",
      "Ep:119, loss:0.00003, loss_test:0.11651, lr:4.66e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.025, tt:5163.023\n",
      "Ep:120, loss:0.00003, loss_test:0.11537, lr:4.61e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.032, tt:5206.837\n",
      "Ep:121, loss:0.00003, loss_test:0.11683, lr:4.57e-03, fs:0.63694 (r=0.505,p=0.862),  time:43.058, tt:5253.132\n",
      "Ep:122, loss:0.00003, loss_test:0.11514, lr:4.52e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.071, tt:5297.677\n",
      "Ep:123, loss:0.00003, loss_test:0.11646, lr:4.48e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.078, tt:5341.659\n",
      "Ep:124, loss:0.00003, loss_test:0.11666, lr:4.43e-03, fs:0.64968 (r=0.515,p=0.879),  time:43.092, tt:5386.528\n",
      "Ep:125, loss:0.00003, loss_test:0.11476, lr:4.39e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.112, tt:5432.154\n",
      "Ep:126, loss:0.00002, loss_test:0.11631, lr:4.34e-03, fs:0.64968 (r=0.515,p=0.879),  time:43.132, tt:5477.742\n",
      "Ep:127, loss:0.00002, loss_test:0.11672, lr:4.30e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.158, tt:5524.257\n",
      "Ep:128, loss:0.00002, loss_test:0.11607, lr:4.26e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.172, tt:5569.239\n",
      "Ep:129, loss:0.00002, loss_test:0.11632, lr:4.21e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.183, tt:5613.807\n",
      "Ep:130, loss:0.00002, loss_test:0.11611, lr:4.17e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.225, tt:5662.468\n",
      "Ep:131, loss:0.00002, loss_test:0.11607, lr:4.13e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.236, tt:5707.216\n",
      "Ep:132, loss:0.00002, loss_test:0.11723, lr:4.09e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.233, tt:5749.995\n",
      "Ep:133, loss:0.00002, loss_test:0.11687, lr:4.05e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.240, tt:5794.132\n",
      "Ep:134, loss:0.00002, loss_test:0.11693, lr:4.01e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.255, tt:5839.484\n",
      "Ep:135, loss:0.00002, loss_test:0.11779, lr:3.97e-03, fs:0.63694 (r=0.505,p=0.862),  time:43.278, tt:5885.823\n",
      "Ep:136, loss:0.00002, loss_test:0.11780, lr:3.93e-03, fs:0.64557 (r=0.515,p=0.864),  time:43.306, tt:5932.959\n",
      "Ep:137, loss:0.00002, loss_test:0.11605, lr:3.89e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.304, tt:5975.972\n",
      "Ep:138, loss:0.00002, loss_test:0.11725, lr:3.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:43.325, tt:6022.160\n",
      "Ep:139, loss:0.00002, loss_test:0.11764, lr:3.81e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.337, tt:6067.227\n",
      "Ep:140, loss:0.00002, loss_test:0.11653, lr:3.77e-03, fs:0.65839 (r=0.535,p=0.855),  time:43.362, tt:6114.102\n",
      "Ep:141, loss:0.00002, loss_test:0.11812, lr:3.73e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.371, tt:6158.690\n",
      "Ep:142, loss:0.00002, loss_test:0.11642, lr:3.70e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.378, tt:6203.022\n",
      "Ep:143, loss:0.00002, loss_test:0.11702, lr:3.66e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.383, tt:6247.190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00002, loss_test:0.11695, lr:3.62e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.381, tt:6290.261\n",
      "Ep:145, loss:0.00002, loss_test:0.11722, lr:3.59e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.404, tt:6336.937\n",
      "Ep:146, loss:0.00002, loss_test:0.11645, lr:3.55e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.410, tt:6381.268\n",
      "Ep:147, loss:0.00002, loss_test:0.11709, lr:3.52e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.428, tt:6427.383\n",
      "Ep:148, loss:0.00002, loss_test:0.11751, lr:3.48e-03, fs:0.64968 (r=0.515,p=0.879),  time:43.419, tt:6469.449\n",
      "Ep:149, loss:0.00002, loss_test:0.11706, lr:3.45e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.422, tt:6513.319\n",
      "Ep:150, loss:0.00002, loss_test:0.11638, lr:3.41e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.414, tt:6555.442\n",
      "Ep:151, loss:0.00002, loss_test:0.11781, lr:3.38e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.420, tt:6599.798\n",
      "Ep:152, loss:0.00002, loss_test:0.11742, lr:3.34e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.412, tt:6641.986\n",
      "Ep:153, loss:0.00002, loss_test:0.11624, lr:3.31e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.421, tt:6686.813\n",
      "Ep:154, loss:0.00002, loss_test:0.11657, lr:3.28e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.438, tt:6732.851\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13769, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:14.894, tt:14.894\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13468, lr:1.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:15.473, tt:30.945\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13105, lr:1.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:16.484, tt:49.451\n",
      "Ep:3, loss:0.00025, loss_test:0.12813, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:17.784, tt:71.135\n",
      "Ep:4, loss:0.00025, loss_test:0.12516, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:17.897, tt:89.483\n",
      "Ep:5, loss:0.00024, loss_test:0.12281, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:17.837, tt:107.021\n",
      "Ep:6, loss:0.00024, loss_test:0.11954, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:17.982, tt:125.872\n",
      "Ep:7, loss:0.00023, loss_test:0.11559, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:17.919, tt:143.352\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11232, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:17.841, tt:160.567\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10963, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:17.788, tt:177.882\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10734, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:17.766, tt:195.426\n",
      "Ep:11, loss:0.00020, loss_test:0.10434, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:18.101, tt:217.213\n",
      "Ep:12, loss:0.00020, loss_test:0.10215, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:18.011, tt:234.149\n",
      "Ep:13, loss:0.00019, loss_test:0.09978, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:18.225, tt:255.152\n",
      "Ep:14, loss:0.00019, loss_test:0.09807, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:18.232, tt:273.479\n",
      "Ep:15, loss:0.00018, loss_test:0.09682, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:18.155, tt:290.475\n",
      "Ep:16, loss:0.00018, loss_test:0.09604, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:18.148, tt:308.523\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09400, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:18.234, tt:328.203\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09290, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:18.178, tt:345.379\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09262, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:18.226, tt:364.528\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09243, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:18.160, tt:381.354\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09198, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:18.251, tt:401.523\n",
      "Ep:22, loss:0.00015, loss_test:0.09142, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:18.358, tt:422.243\n",
      "Ep:23, loss:0.00015, loss_test:0.09053, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:18.290, tt:438.967\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09053, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:18.244, tt:456.091\n",
      "Ep:25, loss:0.00014, loss_test:0.08964, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:18.191, tt:472.962\n",
      "Ep:26, loss:0.00013, loss_test:0.08829, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:18.211, tt:491.685\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08779, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:18.215, tt:510.034\n",
      "Ep:28, loss:0.00012, loss_test:0.08794, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:18.279, tt:530.089\n",
      "Ep:29, loss:0.00012, loss_test:0.08652, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:18.227, tt:546.802\n",
      "Ep:30, loss:0.00012, loss_test:0.08523, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:18.280, tt:566.678\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08477, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:18.320, tt:586.235\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08421, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:18.396, tt:607.078\n",
      "Ep:33, loss:0.00010, loss_test:0.08425, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:18.480, tt:628.333\n",
      "Ep:34, loss:0.00010, loss_test:0.08259, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:18.537, tt:648.785\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08243, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:18.532, tt:667.141\n",
      "Ep:36, loss:0.00010, loss_test:0.08276, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:18.521, tt:685.288\n",
      "Ep:37, loss:0.00009, loss_test:0.08191, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:18.567, tt:705.535\n",
      "Ep:38, loss:0.00009, loss_test:0.08327, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:18.627, tt:726.443\n",
      "Ep:39, loss:0.00009, loss_test:0.08045, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:18.683, tt:747.311\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.08410, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:18.729, tt:767.871\n",
      "Ep:41, loss:0.00008, loss_test:0.07910, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:18.775, tt:788.531\n",
      "Ep:42, loss:0.00008, loss_test:0.08137, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:18.824, tt:809.438\n",
      "Ep:43, loss:0.00008, loss_test:0.07909, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:18.905, tt:831.812\n",
      "Ep:44, loss:0.00007, loss_test:0.08100, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:18.883, tt:849.752\n",
      "Ep:45, loss:0.00007, loss_test:0.08013, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:18.923, tt:870.452\n",
      "Ep:46, loss:0.00007, loss_test:0.07925, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:18.956, tt:890.931\n",
      "Ep:47, loss:0.00007, loss_test:0.07835, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:18.917, tt:907.993\n",
      "Ep:48, loss:0.00006, loss_test:0.07875, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:18.908, tt:926.488\n",
      "Ep:49, loss:0.00006, loss_test:0.07905, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:18.906, tt:945.320\n",
      "Ep:50, loss:0.00006, loss_test:0.07843, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:18.875, tt:962.641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00006, loss_test:0.07977, lr:9.90e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.883, tt:981.940\n",
      "Ep:52, loss:0.00006, loss_test:0.07806, lr:9.80e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.870, tt:1000.087\n",
      "Ep:53, loss:0.00005, loss_test:0.07797, lr:9.70e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.861, tt:1018.493\n",
      "Ep:54, loss:0.00005, loss_test:0.07845, lr:9.61e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.815, tt:1034.845\n",
      "Ep:55, loss:0.00005, loss_test:0.07866, lr:9.51e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.809, tt:1053.288\n",
      "Ep:56, loss:0.00005, loss_test:0.07875, lr:9.41e-03, fs:0.73684 (r=0.636,p=0.875),  time:18.784, tt:1070.680\n",
      "Ep:57, loss:0.00005, loss_test:0.07842, lr:9.32e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.803, tt:1090.550\n",
      "Ep:58, loss:0.00005, loss_test:0.07827, lr:9.23e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.787, tt:1108.424\n",
      "Ep:59, loss:0.00005, loss_test:0.07754, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:18.770, tt:1126.199\n",
      "Ep:60, loss:0.00004, loss_test:0.07776, lr:9.04e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.764, tt:1144.575\n",
      "Ep:61, loss:0.00004, loss_test:0.07787, lr:8.95e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.756, tt:1162.878\n",
      "Ep:62, loss:0.00004, loss_test:0.07715, lr:8.86e-03, fs:0.73684 (r=0.636,p=0.875),  time:18.764, tt:1182.111\n",
      "Ep:63, loss:0.00004, loss_test:0.07759, lr:8.78e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.773, tt:1201.446\n",
      "Ep:64, loss:0.00004, loss_test:0.07758, lr:8.69e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.790, tt:1221.349\n",
      "Ep:65, loss:0.00004, loss_test:0.07830, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.832, tt:1242.912\n",
      "Ep:66, loss:0.00004, loss_test:0.07800, lr:8.51e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.881, tt:1264.996\n",
      "Ep:67, loss:0.00004, loss_test:0.07883, lr:8.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.869, tt:1283.092\n",
      "Ep:68, loss:0.00004, loss_test:0.07714, lr:8.35e-03, fs:0.73373 (r=0.626,p=0.886),  time:18.851, tt:1300.690\n",
      "Ep:69, loss:0.00004, loss_test:0.07689, lr:8.26e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.859, tt:1320.141\n",
      "Ep:70, loss:0.00003, loss_test:0.07775, lr:8.18e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.889, tt:1341.109\n",
      "Ep:71, loss:0.00003, loss_test:0.07858, lr:8.10e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.898, tt:1360.620\n",
      "Ep:72, loss:0.00003, loss_test:0.07667, lr:8.02e-03, fs:0.73810 (r=0.626,p=0.899),  time:18.896, tt:1379.439\n",
      "Ep:73, loss:0.00003, loss_test:0.07584, lr:7.94e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.891, tt:1397.955\n",
      "Ep:74, loss:0.00003, loss_test:0.07798, lr:7.86e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.894, tt:1417.082\n",
      "Ep:75, loss:0.00003, loss_test:0.07592, lr:7.78e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.913, tt:1437.373\n",
      "Ep:76, loss:0.00003, loss_test:0.07690, lr:7.70e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.932, tt:1457.757\n",
      "Ep:77, loss:0.00003, loss_test:0.07697, lr:7.62e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.976, tt:1480.137\n",
      "Ep:78, loss:0.00003, loss_test:0.07647, lr:7.55e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.990, tt:1500.196\n",
      "Ep:79, loss:0.00003, loss_test:0.07764, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:18.973, tt:1517.804\n",
      "Ep:80, loss:0.00003, loss_test:0.07648, lr:7.40e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.959, tt:1535.706\n",
      "Ep:81, loss:0.00003, loss_test:0.07775, lr:7.32e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.960, tt:1554.703\n",
      "Ep:82, loss:0.00003, loss_test:0.07766, lr:7.25e-03, fs:0.75294 (r=0.646,p=0.901),  time:18.961, tt:1573.790\n",
      "Ep:83, loss:0.00003, loss_test:0.07698, lr:7.18e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.936, tt:1590.642\n",
      "Ep:84, loss:0.00003, loss_test:0.07814, lr:7.11e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.952, tt:1610.913\n",
      "Ep:85, loss:0.00003, loss_test:0.07673, lr:7.03e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.998, tt:1633.829\n",
      "Ep:86, loss:0.00003, loss_test:0.07689, lr:6.96e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.007, tt:1653.649\n",
      "Ep:87, loss:0.00003, loss_test:0.07783, lr:6.89e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.999, tt:1671.927\n",
      "Ep:88, loss:0.00002, loss_test:0.07654, lr:6.83e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.993, tt:1690.404\n",
      "Ep:89, loss:0.00002, loss_test:0.07744, lr:6.76e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.994, tt:1709.447\n",
      "Ep:90, loss:0.00002, loss_test:0.07847, lr:6.69e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.006, tt:1729.559\n",
      "Ep:91, loss:0.00002, loss_test:0.07561, lr:6.62e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.979, tt:1746.032\n",
      "Ep:92, loss:0.00002, loss_test:0.07835, lr:6.56e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.965, tt:1763.706\n",
      "Ep:93, loss:0.00002, loss_test:0.07624, lr:6.49e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.960, tt:1782.245\n",
      "Ep:94, loss:0.00002, loss_test:0.07822, lr:6.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.940, tt:1799.293\n",
      "Ep:95, loss:0.00002, loss_test:0.07800, lr:6.36e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.933, tt:1817.569\n",
      "Ep:96, loss:0.00002, loss_test:0.07707, lr:6.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.929, tt:1836.108\n",
      "Ep:97, loss:0.00002, loss_test:0.07751, lr:6.24e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.911, tt:1853.250\n",
      "Ep:98, loss:0.00002, loss_test:0.07696, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.894, tt:1870.542\n",
      "Ep:99, loss:0.00002, loss_test:0.07744, lr:6.11e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.865, tt:1886.521\n",
      "Ep:100, loss:0.00002, loss_test:0.07758, lr:6.05e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.852, tt:1904.041\n",
      "Ep:101, loss:0.00002, loss_test:0.08041, lr:5.99e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.845, tt:1922.153\n",
      "Ep:102, loss:0.00002, loss_test:0.07732, lr:5.93e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.818, tt:1938.204\n",
      "Ep:103, loss:0.00002, loss_test:0.07840, lr:5.87e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.824, tt:1957.724\n",
      "Ep:104, loss:0.00002, loss_test:0.07802, lr:5.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.828, tt:1976.935\n",
      "Ep:105, loss:0.00002, loss_test:0.07735, lr:5.75e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.813, tt:1994.209\n",
      "Ep:106, loss:0.00002, loss_test:0.07902, lr:5.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.825, tt:2014.292\n",
      "Ep:107, loss:0.00002, loss_test:0.07704, lr:5.64e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.815, tt:2032.031\n",
      "Ep:108, loss:0.00002, loss_test:0.07825, lr:5.58e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.834, tt:2052.906\n",
      "Ep:109, loss:0.00002, loss_test:0.07925, lr:5.53e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.826, tt:2070.894\n",
      "Ep:110, loss:0.00002, loss_test:0.07893, lr:5.47e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.812, tt:2088.085\n",
      "Ep:111, loss:0.00002, loss_test:0.07816, lr:5.42e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.803, tt:2105.977\n",
      "Ep:112, loss:0.00002, loss_test:0.07920, lr:5.36e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.837, tt:2128.573\n",
      "Ep:113, loss:0.00002, loss_test:0.07747, lr:5.31e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.863, tt:2150.416\n",
      "Ep:114, loss:0.00002, loss_test:0.07872, lr:5.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.883, tt:2171.512\n",
      "Ep:115, loss:0.00002, loss_test:0.07891, lr:5.20e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.881, tt:2190.251\n",
      "Ep:116, loss:0.00002, loss_test:0.07808, lr:5.15e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.890, tt:2210.072\n",
      "Ep:117, loss:0.00002, loss_test:0.07901, lr:5.10e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.901, tt:2230.367\n",
      "Ep:118, loss:0.00002, loss_test:0.07838, lr:5.05e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.914, tt:2250.820\n",
      "Ep:119, loss:0.00002, loss_test:0.07857, lr:5.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.928, tt:2271.304\n",
      "Ep:120, loss:0.00002, loss_test:0.07899, lr:4.95e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.913, tt:2288.474\n",
      "Ep:121, loss:0.00002, loss_test:0.07867, lr:4.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.902, tt:2306.059\n",
      "Ep:122, loss:0.00002, loss_test:0.07709, lr:4.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.888, tt:2323.201\n",
      "Ep:123, loss:0.00002, loss_test:0.07895, lr:4.80e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.905, tt:2344.280\n",
      "Ep:124, loss:0.00002, loss_test:0.07820, lr:4.75e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.895, tt:2361.844\n",
      "Ep:125, loss:0.00002, loss_test:0.07811, lr:4.71e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.886, tt:2379.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00002, loss_test:0.07819, lr:4.66e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.876, tt:2397.234\n",
      "Ep:127, loss:0.00002, loss_test:0.07816, lr:4.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.876, tt:2416.126\n",
      "Ep:128, loss:0.00001, loss_test:0.07810, lr:4.57e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.887, tt:2436.439\n",
      "Ep:129, loss:0.00001, loss_test:0.07736, lr:4.52e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.889, tt:2455.567\n",
      "Ep:130, loss:0.00001, loss_test:0.07943, lr:4.48e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.891, tt:2474.778\n",
      "Ep:131, loss:0.00001, loss_test:0.07764, lr:4.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.900, tt:2494.859\n",
      "Ep:132, loss:0.00001, loss_test:0.07810, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.891, tt:2512.538\n",
      "Ep:133, loss:0.00001, loss_test:0.07812, lr:4.34e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.899, tt:2532.442\n",
      "Ep:134, loss:0.00001, loss_test:0.07786, lr:4.30e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.888, tt:2549.942\n",
      "Ep:135, loss:0.00001, loss_test:0.07788, lr:4.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.902, tt:2570.732\n",
      "Ep:136, loss:0.00001, loss_test:0.07872, lr:4.21e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.912, tt:2590.986\n",
      "Ep:137, loss:0.00001, loss_test:0.07846, lr:4.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.897, tt:2607.830\n",
      "Ep:138, loss:0.00001, loss_test:0.07831, lr:4.13e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.858, tt:2621.225\n",
      "Ep:139, loss:0.00001, loss_test:0.07824, lr:4.09e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.819, tt:2634.693\n",
      "Ep:140, loss:0.00001, loss_test:0.07846, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.815, tt:2652.966\n",
      "Ep:141, loss:0.00001, loss_test:0.07876, lr:4.01e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.810, tt:2671.008\n",
      "Ep:142, loss:0.00001, loss_test:0.07713, lr:3.97e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.775, tt:2684.893\n",
      "Ep:143, loss:0.00001, loss_test:0.07888, lr:3.93e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.732, tt:2697.421\n",
      "Ep:144, loss:0.00001, loss_test:0.07791, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.700, tt:2711.430\n",
      "Ep:145, loss:0.00001, loss_test:0.07723, lr:3.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.687, tt:2728.355\n",
      "Ep:146, loss:0.00001, loss_test:0.07740, lr:3.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.677, tt:2745.550\n",
      "Ep:147, loss:0.00001, loss_test:0.07789, lr:3.77e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.681, tt:2764.771\n",
      "Ep:148, loss:0.00001, loss_test:0.07787, lr:3.73e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.680, tt:2783.265\n",
      "Ep:149, loss:0.00001, loss_test:0.07730, lr:3.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.680, tt:2802.008\n",
      "Ep:150, loss:0.00001, loss_test:0.07831, lr:3.66e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.662, tt:2818.024\n",
      "Ep:151, loss:0.00001, loss_test:0.07756, lr:3.62e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.647, tt:2834.387\n",
      "Ep:152, loss:0.00001, loss_test:0.07784, lr:3.59e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.640, tt:2851.894\n",
      "Ep:153, loss:0.00001, loss_test:0.07842, lr:3.55e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.636, tt:2869.985\n",
      "Ep:154, loss:0.00001, loss_test:0.07741, lr:3.52e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.632, tt:2887.908\n",
      "Ep:155, loss:0.00001, loss_test:0.07804, lr:3.48e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.617, tt:2904.247\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14193, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:18.757, tt:18.757\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14029, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:19.251, tt:38.501\n",
      "Ep:2, loss:0.00027, loss_test:0.13766, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:20.772, tt:62.317\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13675, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:21.229, tt:84.918\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13663, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:21.104, tt:105.519\n",
      "Ep:5, loss:0.00025, loss_test:0.13452, lr:1.00e-02, fs:0.62551 (r=0.768,p=0.528),  time:21.484, tt:128.902\n",
      "Ep:6, loss:0.00024, loss_test:0.13083, lr:1.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:21.291, tt:149.038\n",
      "Ep:7, loss:0.00024, loss_test:0.12835, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:21.131, tt:169.046\n",
      "Ep:8, loss:0.00023, loss_test:0.12648, lr:1.00e-02, fs:0.60684 (r=0.717,p=0.526),  time:21.060, tt:189.540\n",
      "Ep:9, loss:0.00022, loss_test:0.12565, lr:1.00e-02, fs:0.60360 (r=0.677,p=0.545),  time:21.053, tt:210.533\n",
      "Ep:10, loss:0.00022, loss_test:0.12082, lr:1.00e-02, fs:0.63348 (r=0.707,p=0.574),  time:21.072, tt:231.797\n",
      "Ep:11, loss:0.00021, loss_test:0.11668, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:21.004, tt:252.047\n",
      "Ep:12, loss:0.00020, loss_test:0.11445, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:20.878, tt:271.420\n",
      "Ep:13, loss:0.00019, loss_test:0.11341, lr:1.00e-02, fs:0.65366 (r=0.677,p=0.632),  time:20.892, tt:292.484\n",
      "Ep:14, loss:0.00019, loss_test:0.11075, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:20.905, tt:313.580\n",
      "Ep:15, loss:0.00018, loss_test:0.10827, lr:9.90e-03, fs:0.68000 (r=0.687,p=0.673),  time:20.888, tt:334.211\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10707, lr:9.90e-03, fs:0.66667 (r=0.667,p=0.667),  time:21.004, tt:357.073\n",
      "Ep:17, loss:0.00017, loss_test:0.10639, lr:9.90e-03, fs:0.66327 (r=0.657,p=0.670),  time:21.047, tt:378.855\n",
      "Ep:18, loss:0.00016, loss_test:0.10465, lr:9.90e-03, fs:0.68367 (r=0.677,p=0.691),  time:21.046, tt:399.877\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.10416, lr:9.90e-03, fs:0.65263 (r=0.626,p=0.681),  time:20.930, tt:418.596\n",
      "Ep:20, loss:0.00015, loss_test:0.10366, lr:9.90e-03, fs:0.66316 (r=0.636,p=0.692),  time:20.864, tt:438.145\n",
      "Ep:21, loss:0.00014, loss_test:0.10288, lr:9.90e-03, fs:0.67016 (r=0.646,p=0.696),  time:20.979, tt:461.528\n",
      "Ep:22, loss:0.00014, loss_test:0.10232, lr:9.90e-03, fs:0.68449 (r=0.646,p=0.727),  time:20.963, tt:482.154\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.10115, lr:9.90e-03, fs:0.68817 (r=0.646,p=0.736),  time:20.940, tt:502.563\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.10068, lr:9.90e-03, fs:0.69189 (r=0.646,p=0.744),  time:20.917, tt:522.918\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.10012, lr:9.90e-03, fs:0.69565 (r=0.646,p=0.753),  time:21.001, tt:546.039\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.10012, lr:9.90e-03, fs:0.71823 (r=0.657,p=0.793),  time:21.063, tt:568.708\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.09925, lr:9.90e-03, fs:0.74860 (r=0.677,p=0.838),  time:21.075, tt:590.098\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.09960, lr:9.90e-03, fs:0.72000 (r=0.636,p=0.829),  time:21.166, tt:613.812\n",
      "Ep:29, loss:0.00011, loss_test:0.09944, lr:9.90e-03, fs:0.76667 (r=0.697,p=0.852),  time:21.188, tt:635.639\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.09770, lr:9.90e-03, fs:0.74860 (r=0.677,p=0.838),  time:21.173, tt:656.362\n",
      "Ep:31, loss:0.00010, loss_test:0.09873, lr:9.90e-03, fs:0.75978 (r=0.687,p=0.850),  time:21.216, tt:678.917\n",
      "Ep:32, loss:0.00009, loss_test:0.09724, lr:9.90e-03, fs:0.74157 (r=0.667,p=0.835),  time:21.289, tt:702.541\n",
      "Ep:33, loss:0.00009, loss_test:0.09735, lr:9.90e-03, fs:0.75978 (r=0.687,p=0.850),  time:21.389, tt:727.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00009, loss_test:0.09607, lr:9.90e-03, fs:0.75706 (r=0.677,p=0.859),  time:21.462, tt:751.179\n",
      "Ep:35, loss:0.00008, loss_test:0.09513, lr:9.90e-03, fs:0.78022 (r=0.717,p=0.855),  time:21.445, tt:772.011\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.09822, lr:9.90e-03, fs:0.73684 (r=0.636,p=0.875),  time:21.460, tt:794.013\n",
      "Ep:37, loss:0.00008, loss_test:0.09327, lr:9.90e-03, fs:0.78022 (r=0.717,p=0.855),  time:21.492, tt:816.680\n",
      "Ep:38, loss:0.00007, loss_test:0.09919, lr:9.90e-03, fs:0.71429 (r=0.606,p=0.870),  time:21.532, tt:839.764\n",
      "Ep:39, loss:0.00007, loss_test:0.09131, lr:9.90e-03, fs:0.78919 (r=0.737,p=0.849),  time:21.552, tt:862.071\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.09741, lr:9.90e-03, fs:0.72941 (r=0.626,p=0.873),  time:21.550, tt:883.531\n",
      "Ep:41, loss:0.00007, loss_test:0.09477, lr:9.90e-03, fs:0.75429 (r=0.667,p=0.868),  time:21.535, tt:904.487\n",
      "Ep:42, loss:0.00007, loss_test:0.09299, lr:9.90e-03, fs:0.75429 (r=0.667,p=0.868),  time:21.528, tt:925.704\n",
      "Ep:43, loss:0.00006, loss_test:0.09630, lr:9.90e-03, fs:0.74419 (r=0.646,p=0.877),  time:21.496, tt:945.827\n",
      "Ep:44, loss:0.00006, loss_test:0.09200, lr:9.90e-03, fs:0.77778 (r=0.707,p=0.864),  time:21.498, tt:967.403\n",
      "Ep:45, loss:0.00006, loss_test:0.09548, lr:9.90e-03, fs:0.73684 (r=0.636,p=0.875),  time:21.507, tt:989.338\n",
      "Ep:46, loss:0.00006, loss_test:0.09250, lr:9.90e-03, fs:0.76571 (r=0.677,p=0.882),  time:21.543, tt:1012.539\n",
      "Ep:47, loss:0.00005, loss_test:0.09505, lr:9.90e-03, fs:0.73256 (r=0.636,p=0.863),  time:21.532, tt:1033.543\n",
      "Ep:48, loss:0.00005, loss_test:0.09347, lr:9.90e-03, fs:0.75862 (r=0.667,p=0.880),  time:21.551, tt:1055.982\n",
      "Ep:49, loss:0.00005, loss_test:0.09291, lr:9.90e-03, fs:0.75145 (r=0.657,p=0.878),  time:21.624, tt:1081.190\n",
      "Ep:50, loss:0.00005, loss_test:0.09520, lr:9.90e-03, fs:0.72414 (r=0.636,p=0.840),  time:21.627, tt:1102.990\n",
      "Ep:51, loss:0.00005, loss_test:0.09295, lr:9.80e-03, fs:0.77966 (r=0.697,p=0.885),  time:21.645, tt:1125.527\n",
      "Ep:52, loss:0.00005, loss_test:0.09447, lr:9.70e-03, fs:0.71264 (r=0.626,p=0.827),  time:21.650, tt:1147.458\n",
      "Ep:53, loss:0.00005, loss_test:0.09602, lr:9.61e-03, fs:0.75145 (r=0.657,p=0.878),  time:21.710, tt:1172.333\n",
      "Ep:54, loss:0.00005, loss_test:0.09517, lr:9.51e-03, fs:0.72093 (r=0.626,p=0.849),  time:21.722, tt:1194.728\n",
      "Ep:55, loss:0.00005, loss_test:0.09215, lr:9.41e-03, fs:0.76136 (r=0.677,p=0.870),  time:21.718, tt:1216.187\n",
      "Ep:56, loss:0.00004, loss_test:0.09510, lr:9.32e-03, fs:0.73256 (r=0.636,p=0.863),  time:21.746, tt:1239.496\n",
      "Ep:57, loss:0.00004, loss_test:0.08996, lr:9.23e-03, fs:0.83060 (r=0.768,p=0.905),  time:21.784, tt:1263.456\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00004, loss_test:0.09780, lr:9.23e-03, fs:0.72619 (r=0.616,p=0.884),  time:21.779, tt:1284.978\n",
      "Ep:59, loss:0.00004, loss_test:0.08945, lr:9.23e-03, fs:0.80874 (r=0.747,p=0.881),  time:21.797, tt:1307.818\n",
      "Ep:60, loss:0.00004, loss_test:0.09892, lr:9.23e-03, fs:0.71765 (r=0.616,p=0.859),  time:21.793, tt:1329.385\n",
      "Ep:61, loss:0.00004, loss_test:0.09033, lr:9.23e-03, fs:0.81111 (r=0.737,p=0.901),  time:21.816, tt:1352.609\n",
      "Ep:62, loss:0.00004, loss_test:0.09569, lr:9.23e-03, fs:0.72515 (r=0.626,p=0.861),  time:21.827, tt:1375.093\n",
      "Ep:63, loss:0.00004, loss_test:0.09117, lr:9.23e-03, fs:0.78652 (r=0.707,p=0.886),  time:21.838, tt:1397.649\n",
      "Ep:64, loss:0.00004, loss_test:0.09498, lr:9.23e-03, fs:0.73988 (r=0.646,p=0.865),  time:21.830, tt:1418.940\n",
      "Ep:65, loss:0.00004, loss_test:0.09327, lr:9.23e-03, fs:0.76023 (r=0.657,p=0.903),  time:21.794, tt:1438.411\n",
      "Ep:66, loss:0.00003, loss_test:0.09401, lr:9.23e-03, fs:0.75581 (r=0.657,p=0.890),  time:21.762, tt:1458.062\n",
      "Ep:67, loss:0.00004, loss_test:0.09252, lr:9.23e-03, fs:0.76023 (r=0.657,p=0.903),  time:21.748, tt:1478.865\n",
      "Ep:68, loss:0.00003, loss_test:0.09258, lr:9.23e-03, fs:0.75581 (r=0.657,p=0.890),  time:21.758, tt:1501.327\n",
      "Ep:69, loss:0.00003, loss_test:0.09220, lr:9.14e-03, fs:0.76023 (r=0.657,p=0.903),  time:21.751, tt:1522.555\n",
      "Ep:70, loss:0.00003, loss_test:0.09332, lr:9.04e-03, fs:0.75581 (r=0.657,p=0.890),  time:21.737, tt:1543.319\n",
      "Ep:71, loss:0.00003, loss_test:0.09290, lr:8.95e-03, fs:0.76471 (r=0.657,p=0.915),  time:21.744, tt:1565.555\n",
      "Ep:72, loss:0.00003, loss_test:0.09444, lr:8.86e-03, fs:0.76023 (r=0.657,p=0.903),  time:21.744, tt:1587.333\n",
      "Ep:73, loss:0.00003, loss_test:0.09064, lr:8.78e-03, fs:0.76023 (r=0.657,p=0.903),  time:21.768, tt:1610.844\n",
      "Ep:74, loss:0.00003, loss_test:0.09540, lr:8.69e-03, fs:0.75294 (r=0.646,p=0.901),  time:21.764, tt:1632.327\n",
      "Ep:75, loss:0.00003, loss_test:0.09049, lr:8.60e-03, fs:0.76023 (r=0.657,p=0.903),  time:21.739, tt:1652.178\n",
      "Ep:76, loss:0.00003, loss_test:0.09518, lr:8.51e-03, fs:0.76190 (r=0.646,p=0.928),  time:21.728, tt:1673.050\n",
      "Ep:77, loss:0.00003, loss_test:0.09300, lr:8.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.726, tt:1694.590\n",
      "Ep:78, loss:0.00003, loss_test:0.09423, lr:8.35e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.705, tt:1714.701\n",
      "Ep:79, loss:0.00003, loss_test:0.09439, lr:8.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.700, tt:1736.009\n",
      "Ep:80, loss:0.00003, loss_test:0.09451, lr:8.18e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.687, tt:1756.632\n",
      "Ep:81, loss:0.00002, loss_test:0.09440, lr:8.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.704, tt:1779.736\n",
      "Ep:82, loss:0.00002, loss_test:0.09465, lr:8.02e-03, fs:0.76471 (r=0.657,p=0.915),  time:21.689, tt:1800.207\n",
      "Ep:83, loss:0.00002, loss_test:0.09454, lr:7.94e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.655, tt:1819.045\n",
      "Ep:84, loss:0.00002, loss_test:0.09378, lr:7.86e-03, fs:0.76471 (r=0.657,p=0.915),  time:21.647, tt:1839.999\n",
      "Ep:85, loss:0.00002, loss_test:0.09424, lr:7.78e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.639, tt:1860.993\n",
      "Ep:86, loss:0.00002, loss_test:0.09351, lr:7.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.635, tt:1882.264\n",
      "Ep:87, loss:0.00002, loss_test:0.09490, lr:7.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.632, tt:1903.584\n",
      "Ep:88, loss:0.00002, loss_test:0.09436, lr:7.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:21.654, tt:1927.177\n",
      "Ep:89, loss:0.00002, loss_test:0.09404, lr:7.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.633, tt:1946.932\n",
      "Ep:90, loss:0.00002, loss_test:0.09488, lr:7.40e-03, fs:0.76190 (r=0.646,p=0.928),  time:21.623, tt:1967.660\n",
      "Ep:91, loss:0.00002, loss_test:0.09296, lr:7.32e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.605, tt:1987.672\n",
      "Ep:92, loss:0.00002, loss_test:0.09594, lr:7.25e-03, fs:0.74699 (r=0.626,p=0.925),  time:21.592, tt:2008.027\n",
      "Ep:93, loss:0.00002, loss_test:0.09419, lr:7.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:21.589, tt:2029.380\n",
      "Ep:94, loss:0.00002, loss_test:0.09451, lr:7.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:21.585, tt:2050.616\n",
      "Ep:95, loss:0.00002, loss_test:0.09602, lr:7.03e-03, fs:0.75152 (r=0.626,p=0.939),  time:21.596, tt:2073.263\n",
      "Ep:96, loss:0.00002, loss_test:0.09286, lr:6.96e-03, fs:0.76923 (r=0.657,p=0.929),  time:21.587, tt:2093.957\n",
      "Ep:97, loss:0.00002, loss_test:0.09601, lr:6.89e-03, fs:0.73939 (r=0.616,p=0.924),  time:21.590, tt:2115.866\n",
      "Ep:98, loss:0.00002, loss_test:0.09631, lr:6.83e-03, fs:0.75152 (r=0.626,p=0.939),  time:21.569, tt:2135.342\n",
      "Ep:99, loss:0.00002, loss_test:0.09432, lr:6.76e-03, fs:0.75740 (r=0.646,p=0.914),  time:21.563, tt:2156.277\n",
      "Ep:100, loss:0.00002, loss_test:0.09629, lr:6.69e-03, fs:0.75152 (r=0.626,p=0.939),  time:21.560, tt:2177.564\n",
      "Ep:101, loss:0.00002, loss_test:0.09569, lr:6.62e-03, fs:0.75152 (r=0.626,p=0.939),  time:21.547, tt:2197.831\n",
      "Ep:102, loss:0.00002, loss_test:0.09418, lr:6.56e-03, fs:0.75740 (r=0.646,p=0.914),  time:21.525, tt:2217.027\n",
      "Ep:103, loss:0.00002, loss_test:0.09829, lr:6.49e-03, fs:0.72840 (r=0.596,p=0.937),  time:21.548, tt:2241.038\n",
      "Ep:104, loss:0.00002, loss_test:0.09557, lr:6.43e-03, fs:0.75152 (r=0.626,p=0.939),  time:21.528, tt:2260.413\n",
      "Ep:105, loss:0.00002, loss_test:0.09498, lr:6.36e-03, fs:0.75152 (r=0.626,p=0.939),  time:21.539, tt:2283.136\n",
      "Ep:106, loss:0.00002, loss_test:0.09835, lr:6.30e-03, fs:0.72840 (r=0.596,p=0.937),  time:21.550, tt:2305.815\n",
      "Ep:107, loss:0.00002, loss_test:0.09465, lr:6.24e-03, fs:0.75740 (r=0.646,p=0.914),  time:21.546, tt:2326.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00002, loss_test:0.09696, lr:6.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:21.547, tt:2348.600\n",
      "Ep:109, loss:0.00002, loss_test:0.09815, lr:6.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:21.552, tt:2370.687\n",
      "Ep:110, loss:0.00002, loss_test:0.09683, lr:6.05e-03, fs:0.74390 (r=0.616,p=0.938),  time:21.560, tt:2393.107\n",
      "Ep:111, loss:0.00002, loss_test:0.09660, lr:5.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:21.546, tt:2413.139\n",
      "Ep:112, loss:0.00002, loss_test:0.09732, lr:5.93e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.559, tt:2436.168\n",
      "Ep:113, loss:0.00002, loss_test:0.09644, lr:5.87e-03, fs:0.73939 (r=0.616,p=0.924),  time:21.542, tt:2455.764\n",
      "Ep:114, loss:0.00002, loss_test:0.09696, lr:5.81e-03, fs:0.72840 (r=0.596,p=0.937),  time:21.551, tt:2478.339\n",
      "Ep:115, loss:0.00001, loss_test:0.09820, lr:5.75e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.551, tt:2499.870\n",
      "Ep:116, loss:0.00001, loss_test:0.09711, lr:5.70e-03, fs:0.74390 (r=0.616,p=0.938),  time:21.552, tt:2521.571\n",
      "Ep:117, loss:0.00001, loss_test:0.09722, lr:5.64e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.553, tt:2543.280\n",
      "Ep:118, loss:0.00001, loss_test:0.09842, lr:5.58e-03, fs:0.72050 (r=0.586,p=0.935),  time:21.542, tt:2563.554\n",
      "Ep:119, loss:0.00001, loss_test:0.09748, lr:5.53e-03, fs:0.73171 (r=0.606,p=0.923),  time:21.538, tt:2584.553\n",
      "Ep:120, loss:0.00001, loss_test:0.09768, lr:5.47e-03, fs:0.72840 (r=0.596,p=0.937),  time:21.523, tt:2604.245\n",
      "Ep:121, loss:0.00001, loss_test:0.09785, lr:5.42e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.521, tt:2625.574\n",
      "Ep:122, loss:0.00001, loss_test:0.09770, lr:5.36e-03, fs:0.72050 (r=0.586,p=0.935),  time:21.510, tt:2645.731\n",
      "Ep:123, loss:0.00001, loss_test:0.09820, lr:5.31e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.499, tt:2665.852\n",
      "Ep:124, loss:0.00001, loss_test:0.09881, lr:5.26e-03, fs:0.72050 (r=0.586,p=0.935),  time:21.487, tt:2685.851\n",
      "Ep:125, loss:0.00001, loss_test:0.09719, lr:5.20e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.491, tt:2707.879\n",
      "Ep:126, loss:0.00001, loss_test:0.09868, lr:5.15e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.487, tt:2728.852\n",
      "Ep:127, loss:0.00001, loss_test:0.09874, lr:5.10e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.476, tt:2748.967\n",
      "Ep:128, loss:0.00001, loss_test:0.09772, lr:5.05e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.476, tt:2770.434\n",
      "Ep:129, loss:0.00001, loss_test:0.09911, lr:5.00e-03, fs:0.72050 (r=0.586,p=0.935),  time:21.487, tt:2793.368\n",
      "Ep:130, loss:0.00001, loss_test:0.09890, lr:4.95e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.493, tt:2815.630\n",
      "Ep:131, loss:0.00001, loss_test:0.09753, lr:4.90e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.489, tt:2836.610\n",
      "Ep:132, loss:0.00001, loss_test:0.10086, lr:4.85e-03, fs:0.71166 (r=0.586,p=0.906),  time:21.489, tt:2858.047\n",
      "Ep:133, loss:0.00001, loss_test:0.09804, lr:4.80e-03, fs:0.72840 (r=0.596,p=0.937),  time:21.494, tt:2880.134\n",
      "Ep:134, loss:0.00001, loss_test:0.09821, lr:4.75e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.485, tt:2900.413\n",
      "Ep:135, loss:0.00001, loss_test:0.10004, lr:4.71e-03, fs:0.72050 (r=0.586,p=0.935),  time:21.483, tt:2921.632\n",
      "Ep:136, loss:0.00001, loss_test:0.09765, lr:4.66e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.485, tt:2943.428\n",
      "Ep:137, loss:0.00001, loss_test:0.10005, lr:4.61e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.492, tt:2965.884\n",
      "Ep:138, loss:0.00001, loss_test:0.09804, lr:4.57e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.503, tt:2988.862\n",
      "Ep:139, loss:0.00001, loss_test:0.09914, lr:4.52e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.503, tt:3010.403\n",
      "Ep:140, loss:0.00001, loss_test:0.09843, lr:4.48e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.475, tt:3028.025\n",
      "Ep:141, loss:0.00001, loss_test:0.09792, lr:4.43e-03, fs:0.71166 (r=0.586,p=0.906),  time:21.455, tt:3046.617\n",
      "Ep:142, loss:0.00001, loss_test:0.09878, lr:4.39e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.464, tt:3069.283\n",
      "Ep:143, loss:0.00001, loss_test:0.09925, lr:4.34e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.484, tt:3093.650\n",
      "Ep:144, loss:0.00001, loss_test:0.09768, lr:4.30e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.465, tt:3112.469\n",
      "Ep:145, loss:0.00001, loss_test:0.09865, lr:4.26e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.440, tt:3130.195\n",
      "Ep:146, loss:0.00001, loss_test:0.09910, lr:4.21e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.448, tt:3152.843\n",
      "Ep:147, loss:0.00001, loss_test:0.09738, lr:4.17e-03, fs:0.73171 (r=0.606,p=0.923),  time:21.438, tt:3172.781\n",
      "Ep:148, loss:0.00001, loss_test:0.09926, lr:4.13e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.448, tt:3195.729\n",
      "Ep:149, loss:0.00001, loss_test:0.09849, lr:4.09e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.456, tt:3218.443\n",
      "Ep:150, loss:0.00001, loss_test:0.09799, lr:4.05e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.456, tt:3239.862\n",
      "Ep:151, loss:0.00001, loss_test:0.09911, lr:4.01e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.472, tt:3263.677\n",
      "Ep:152, loss:0.00001, loss_test:0.09808, lr:3.97e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.469, tt:3284.759\n",
      "Ep:153, loss:0.00001, loss_test:0.09836, lr:3.93e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.461, tt:3304.959\n",
      "Ep:154, loss:0.00001, loss_test:0.09915, lr:3.89e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.458, tt:3326.058\n",
      "Ep:155, loss:0.00001, loss_test:0.09802, lr:3.85e-03, fs:0.72393 (r=0.596,p=0.922),  time:21.459, tt:3347.673\n",
      "Ep:156, loss:0.00001, loss_test:0.09951, lr:3.81e-03, fs:0.71605 (r=0.586,p=0.921),  time:21.467, tt:3370.322\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
