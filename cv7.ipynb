{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number=\"7-7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bert2_400',\n",
       " 1: 'Bert2_832',\n",
       " 2: 'Bert2_832_400_200_100',\n",
       " 3: 'Bert2_832_600_400_200',\n",
       " 4: 'Bert_300',\n",
       " 5: 'Bert_300_300_200',\n",
       " 6: 'Bert_768',\n",
       " 7: 'Fasttext2',\n",
       " 8: 'Fasttext2_150',\n",
       " 9: 'Fasttext2_200_200',\n",
       " 10: 'Fasttext2_200_200_100',\n",
       " 11: 'Fasttext2_200_200_200',\n",
       " 12: 'Fasttext2_200_200_200_100',\n",
       " 13: 'Fasttext2_200_200_200_100_relu',\n",
       " 14: 'Fasttext2_300_250_200_150',\n",
       " 15: 'Fasttext2_364',\n",
       " 16: 'Fasttext2_364_200_100',\n",
       " 17: 'Fasttext2_364_200_100_relu',\n",
       " 18: 'Fasttext2_364_300_200_100',\n",
       " 19: 'Fasttext2_364_300_200_100_relu',\n",
       " 20: 'Fasttext2_364_300_250_200',\n",
       " 21: 'Fasttext2_364_364_364',\n",
       " 22: 'Fasttext2_364_nn',\n",
       " 23: 'Fasttext2_3GCN_300_250_200_150',\n",
       " 24: 'Fasttext2_728',\n",
       " 25: 'Fasttext2_728364',\n",
       " 26: 'Fasttext2_728_364',\n",
       " 27: 'Fasttext2d_300_250_200_150',\n",
       " 28: 'Fasttext2d_364',\n",
       " 29: 'Fasttext3GCN_300',\n",
       " 30: 'FasttextSum_150',\n",
       " 31: 'FasttextSum_300_250_200_150',\n",
       " 32: 'FasttextSum_364',\n",
       " 33: 'FasttextSum_364_200_100',\n",
       " 34: 'FasttextSum_364_300_200_100',\n",
       " 35: 'FasttextSumd_150',\n",
       " 36: 'FasttextSumd_300_250_200_150',\n",
       " 37: 'Fasttext_150',\n",
       " 38: 'Fasttext_150_150_100',\n",
       " 39: 'Fasttext_200_200_200_100',\n",
       " 40: 'Fasttext_300',\n",
       " 41: 'Fasttext_300_200_100',\n",
       " 42: 'Fasttext_300_250_200_150',\n",
       " 43: 'Fasttext_3GCN',\n",
       " 44: 'Fasttext_simple_300_300'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14527, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:25.727, tt:25.727\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14433, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:28.842, tt:57.685\n",
      "Ep:2, loss:0.00014, loss_test:0.14261, lr:1.00e-02, fs:0.65292 (r=0.960,p=0.495),  time:30.039, tt:90.116\n",
      "Ep:3, loss:0.00013, loss_test:0.14008, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:30.237, tt:120.947\n",
      "Ep:4, loss:0.00013, loss_test:0.13630, lr:1.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:30.690, tt:153.450\n",
      "Ep:5, loss:0.00012, loss_test:0.13155, lr:1.00e-02, fs:0.62500 (r=0.808,p=0.510),  time:30.785, tt:184.710\n",
      "Ep:6, loss:0.00012, loss_test:0.12753, lr:1.00e-02, fs:0.59633 (r=0.657,p=0.546),  time:30.919, tt:216.430\n",
      "Ep:7, loss:0.00012, loss_test:0.12411, lr:1.00e-02, fs:0.58654 (r=0.616,p=0.560),  time:31.223, tt:249.781\n",
      "Ep:8, loss:0.00011, loss_test:0.12087, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:31.415, tt:282.738\n",
      "Ep:9, loss:0.00011, loss_test:0.11802, lr:1.00e-02, fs:0.65198 (r=0.747,p=0.578),  time:31.487, tt:314.868\n",
      "Ep:10, loss:0.00011, loss_test:0.11448, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:31.474, tt:346.215\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00010, loss_test:0.11186, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:31.569, tt:378.833\n",
      "Ep:12, loss:0.00010, loss_test:0.10956, lr:1.00e-02, fs:0.66990 (r=0.697,p=0.645),  time:31.603, tt:410.836\n",
      "Ep:13, loss:0.00010, loss_test:0.10738, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:31.613, tt:442.582\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00009, loss_test:0.10426, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:31.706, tt:475.595\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00009, loss_test:0.10178, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:31.923, tt:510.765\n",
      "Ep:16, loss:0.00009, loss_test:0.10009, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:32.004, tt:544.070\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.09795, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:32.137, tt:578.468\n",
      "Ep:18, loss:0.00008, loss_test:0.09543, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:32.213, tt:612.039\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.09375, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:32.266, tt:645.320\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.09262, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:32.291, tt:678.121\n",
      "Ep:21, loss:0.00008, loss_test:0.09088, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:32.357, tt:711.844\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.08992, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:32.390, tt:744.962\n",
      "Ep:23, loss:0.00007, loss_test:0.08898, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:32.448, tt:778.742\n",
      "Ep:24, loss:0.00007, loss_test:0.08748, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:32.433, tt:810.825\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.08632, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:32.457, tt:843.882\n",
      "Ep:26, loss:0.00007, loss_test:0.08550, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:32.489, tt:877.209\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.08482, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:32.512, tt:910.342\n",
      "Ep:28, loss:0.00007, loss_test:0.08400, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:32.563, tt:944.330\n",
      "Ep:29, loss:0.00006, loss_test:0.08283, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:32.531, tt:975.919\n",
      "Ep:30, loss:0.00006, loss_test:0.08209, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:32.543, tt:1008.821\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.08164, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:32.518, tt:1040.589\n",
      "Ep:32, loss:0.00006, loss_test:0.08077, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:32.539, tt:1073.796\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.07977, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:32.536, tt:1106.232\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.07921, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:32.513, tt:1137.970\n",
      "Ep:35, loss:0.00006, loss_test:0.07853, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:32.526, tt:1170.933\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.07821, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:32.565, tt:1204.906\n",
      "Ep:37, loss:0.00005, loss_test:0.07772, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.555, tt:1237.085\n",
      "Ep:38, loss:0.00005, loss_test:0.07699, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:32.589, tt:1270.980\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07643, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:32.608, tt:1304.317\n",
      "Ep:40, loss:0.00005, loss_test:0.07610, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.593, tt:1336.294\n",
      "Ep:41, loss:0.00005, loss_test:0.07539, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:32.536, tt:1366.517\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.07495, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:32.542, tt:1399.309\n",
      "Ep:43, loss:0.00005, loss_test:0.07417, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:32.566, tt:1432.908\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.07389, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:32.578, tt:1466.016\n",
      "Ep:45, loss:0.00004, loss_test:0.07344, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:32.573, tt:1498.355\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.07322, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:32.606, tt:1532.468\n",
      "Ep:47, loss:0.00004, loss_test:0.07316, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:32.617, tt:1565.632\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00004, loss_test:0.07238, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:32.633, tt:1599.028\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.07183, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:32.617, tt:1630.825\n",
      "Ep:50, loss:0.00004, loss_test:0.07244, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:32.631, tt:1664.180\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.07166, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:32.655, tt:1698.056\n",
      "Ep:52, loss:0.00004, loss_test:0.07179, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:32.667, tt:1731.331\n",
      "Ep:53, loss:0.00004, loss_test:0.07115, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:32.668, tt:1764.055\n",
      "Ep:54, loss:0.00004, loss_test:0.07099, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:32.678, tt:1797.307\n",
      "Ep:55, loss:0.00004, loss_test:0.07152, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.713, tt:1831.946\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.06988, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:32.722, tt:1865.147\n",
      "Ep:57, loss:0.00003, loss_test:0.07104, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.729, tt:1898.258\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.06920, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:32.767, tt:1933.245\n",
      "Ep:59, loss:0.00003, loss_test:0.07071, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.745, tt:1964.704\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.06925, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:32.746, tt:1997.498\n",
      "Ep:61, loss:0.00003, loss_test:0.06970, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.751, tt:2030.591\n",
      "Ep:62, loss:0.00003, loss_test:0.06928, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.761, tt:2063.942\n",
      "Ep:63, loss:0.00003, loss_test:0.06919, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.742, tt:2095.493\n",
      "Ep:64, loss:0.00003, loss_test:0.06933, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.757, tt:2129.208\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00003, loss_test:0.06835, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.774, tt:2163.069\n",
      "Ep:66, loss:0.00003, loss_test:0.06838, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.772, tt:2195.757\n",
      "Ep:67, loss:0.00003, loss_test:0.06872, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:32.789, tt:2229.665\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.06765, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.811, tt:2263.992\n",
      "Ep:69, loss:0.00003, loss_test:0.06867, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:32.804, tt:2296.268\n",
      "Ep:70, loss:0.00003, loss_test:0.06750, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:32.807, tt:2329.267\n",
      "Ep:71, loss:0.00003, loss_test:0.06821, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.824, tt:2363.305\n",
      "Ep:72, loss:0.00002, loss_test:0.06799, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.845, tt:2397.720\n",
      "Ep:73, loss:0.00002, loss_test:0.06781, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.851, tt:2430.963\n",
      "Ep:74, loss:0.00002, loss_test:0.06783, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.885, tt:2466.386\n",
      "Ep:75, loss:0.00002, loss_test:0.06836, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:32.889, tt:2499.577\n",
      "Ep:76, loss:0.00002, loss_test:0.06663, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.927, tt:2535.396\n",
      "Ep:77, loss:0.00002, loss_test:0.06760, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:32.950, tt:2570.103\n",
      "Ep:78, loss:0.00002, loss_test:0.06746, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:32.963, tt:2604.082\n",
      "Ep:79, loss:0.00002, loss_test:0.06608, lr:9.90e-03, fs:0.84946 (r=0.798,p=0.908),  time:32.981, tt:2638.466\n",
      "Ep:80, loss:0.00002, loss_test:0.06723, lr:9.80e-03, fs:0.84946 (r=0.798,p=0.908),  time:32.978, tt:2671.237\n",
      "Ep:81, loss:0.00002, loss_test:0.06673, lr:9.70e-03, fs:0.85405 (r=0.798,p=0.919),  time:32.969, tt:2703.457\n",
      "Ep:82, loss:0.00002, loss_test:0.06607, lr:9.61e-03, fs:0.84946 (r=0.798,p=0.908),  time:32.976, tt:2737.032\n",
      "Ep:83, loss:0.00002, loss_test:0.06730, lr:9.51e-03, fs:0.85405 (r=0.798,p=0.919),  time:32.982, tt:2770.511\n",
      "Ep:84, loss:0.00002, loss_test:0.06567, lr:9.41e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.988, tt:2803.946\n",
      "Ep:85, loss:0.00002, loss_test:0.06778, lr:9.32e-03, fs:0.85246 (r=0.788,p=0.929),  time:32.996, tt:2837.662\n",
      "Ep:86, loss:0.00002, loss_test:0.06569, lr:9.23e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.999, tt:2870.886\n",
      "Ep:87, loss:0.00002, loss_test:0.06690, lr:9.14e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.996, tt:2903.649\n",
      "Ep:88, loss:0.00002, loss_test:0.06633, lr:9.04e-03, fs:0.85405 (r=0.798,p=0.919),  time:32.997, tt:2936.716\n",
      "Ep:89, loss:0.00002, loss_test:0.06669, lr:8.95e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.978, tt:2968.044\n",
      "Ep:90, loss:0.00002, loss_test:0.06611, lr:8.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:32.977, tt:3000.862\n",
      "Ep:91, loss:0.00002, loss_test:0.06638, lr:8.78e-03, fs:0.85405 (r=0.798,p=0.919),  time:32.960, tt:3032.357\n",
      "Ep:92, loss:0.00002, loss_test:0.06715, lr:8.69e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.956, tt:3064.883\n",
      "Ep:93, loss:0.00002, loss_test:0.06557, lr:8.60e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.953, tt:3097.594\n",
      "Ep:94, loss:0.00002, loss_test:0.06608, lr:8.51e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.946, tt:3129.825\n",
      "Ep:95, loss:0.00002, loss_test:0.06618, lr:8.43e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.941, tt:3162.297\n",
      "Ep:96, loss:0.00002, loss_test:0.06624, lr:8.35e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.944, tt:3195.556\n",
      "Ep:97, loss:0.00002, loss_test:0.06490, lr:8.26e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.945, tt:3228.564\n",
      "Ep:98, loss:0.00002, loss_test:0.06701, lr:8.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.937, tt:3260.800\n",
      "Ep:99, loss:0.00002, loss_test:0.06543, lr:8.10e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.927, tt:3292.695\n",
      "Ep:100, loss:0.00001, loss_test:0.06572, lr:8.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.941, tt:3327.063\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.06550, lr:8.02e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.943, tt:3360.201\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.06677, lr:8.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.939, tt:3392.745\n",
      "Ep:103, loss:0.00001, loss_test:0.06493, lr:8.02e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.944, tt:3426.220\n",
      "Ep:104, loss:0.00001, loss_test:0.06642, lr:8.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.931, tt:3457.716\n",
      "Ep:105, loss:0.00001, loss_test:0.06649, lr:8.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.919, tt:3489.432\n",
      "Ep:106, loss:0.00001, loss_test:0.06484, lr:8.02e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.910, tt:3521.419\n",
      "Ep:107, loss:0.00001, loss_test:0.06756, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.900, tt:3553.170\n",
      "Ep:108, loss:0.00001, loss_test:0.06575, lr:8.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.893, tt:3585.292\n",
      "Ep:109, loss:0.00001, loss_test:0.06618, lr:8.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.891, tt:3618.019\n",
      "Ep:110, loss:0.00001, loss_test:0.06700, lr:8.02e-03, fs:0.83616 (r=0.747,p=0.949),  time:32.893, tt:3651.142\n",
      "Ep:111, loss:0.00001, loss_test:0.06531, lr:8.02e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.896, tt:3684.329\n",
      "Ep:112, loss:0.00001, loss_test:0.06706, lr:8.02e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.901, tt:3717.808\n",
      "Ep:113, loss:0.00001, loss_test:0.06685, lr:7.94e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.917, tt:3752.536\n",
      "Ep:114, loss:0.00001, loss_test:0.06542, lr:7.86e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.912, tt:3784.858\n",
      "Ep:115, loss:0.00001, loss_test:0.06762, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.942, tt:3821.327\n",
      "Ep:116, loss:0.00001, loss_test:0.06675, lr:7.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.950, tt:3855.127\n",
      "Ep:117, loss:0.00001, loss_test:0.06555, lr:7.62e-03, fs:0.86813 (r=0.798,p=0.952),  time:32.964, tt:3889.775\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.06714, lr:7.62e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.967, tt:3923.124\n",
      "Ep:119, loss:0.00001, loss_test:0.06542, lr:7.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.965, tt:3955.771\n",
      "Ep:120, loss:0.00001, loss_test:0.06680, lr:7.62e-03, fs:0.83616 (r=0.747,p=0.949),  time:32.962, tt:3988.366\n",
      "Ep:121, loss:0.00001, loss_test:0.06782, lr:7.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.977, tt:4023.163\n",
      "Ep:122, loss:0.00001, loss_test:0.06549, lr:7.62e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.981, tt:4056.605\n",
      "Ep:123, loss:0.00001, loss_test:0.06635, lr:7.62e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.977, tt:4089.088\n",
      "Ep:124, loss:0.00001, loss_test:0.06644, lr:7.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.983, tt:4122.859\n",
      "Ep:125, loss:0.00001, loss_test:0.06739, lr:7.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.979, tt:4155.394\n",
      "Ep:126, loss:0.00001, loss_test:0.06593, lr:7.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.973, tt:4187.549\n",
      "Ep:127, loss:0.00001, loss_test:0.06717, lr:7.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.971, tt:4220.276\n",
      "Ep:128, loss:0.00001, loss_test:0.06709, lr:7.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.978, tt:4254.154\n",
      "Ep:129, loss:0.00001, loss_test:0.06642, lr:7.55e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.970, tt:4286.082\n",
      "Ep:130, loss:0.00001, loss_test:0.06621, lr:7.47e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.958, tt:4317.529\n",
      "Ep:131, loss:0.00001, loss_test:0.06853, lr:7.40e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.945, tt:4348.701\n",
      "Ep:132, loss:0.00001, loss_test:0.06425, lr:7.32e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.935, tt:4380.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.06810, lr:7.25e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.937, tt:4413.537\n",
      "Ep:134, loss:0.00001, loss_test:0.06783, lr:7.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.920, tt:4444.253\n",
      "Ep:135, loss:0.00001, loss_test:0.06639, lr:7.11e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.908, tt:4475.432\n",
      "Ep:136, loss:0.00001, loss_test:0.06648, lr:7.03e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.902, tt:4507.607\n",
      "Ep:137, loss:0.00001, loss_test:0.06763, lr:6.96e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.903, tt:4540.638\n",
      "Ep:138, loss:0.00001, loss_test:0.06686, lr:6.89e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.889, tt:4571.611\n",
      "Ep:139, loss:0.00001, loss_test:0.06812, lr:6.83e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.881, tt:4603.294\n",
      "Ep:140, loss:0.00001, loss_test:0.06709, lr:6.76e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.879, tt:4635.961\n",
      "Ep:141, loss:0.00001, loss_test:0.06760, lr:6.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:32.865, tt:4666.872\n",
      "Ep:142, loss:0.00001, loss_test:0.06735, lr:6.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.862, tt:4699.236\n",
      "Ep:143, loss:0.00001, loss_test:0.06690, lr:6.56e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.867, tt:4732.889\n",
      "Ep:144, loss:0.00001, loss_test:0.06734, lr:6.49e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.868, tt:4765.793\n",
      "Ep:145, loss:0.00001, loss_test:0.06913, lr:6.43e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.871, tt:4799.187\n",
      "Ep:146, loss:0.00001, loss_test:0.06626, lr:6.36e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.887, tt:4834.396\n",
      "Ep:147, loss:0.00001, loss_test:0.06853, lr:6.30e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.896, tt:4868.595\n",
      "Ep:148, loss:0.00001, loss_test:0.06861, lr:6.24e-03, fs:0.80702 (r=0.697,p=0.958),  time:32.907, tt:4903.098\n",
      "Ep:149, loss:0.00001, loss_test:0.06687, lr:6.17e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.915, tt:4937.273\n",
      "Ep:150, loss:0.00001, loss_test:0.06831, lr:6.11e-03, fs:0.80702 (r=0.697,p=0.958),  time:32.921, tt:4971.060\n",
      "Ep:151, loss:0.00001, loss_test:0.06926, lr:6.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:32.926, tt:5004.739\n",
      "Ep:152, loss:0.00001, loss_test:0.06757, lr:5.99e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.928, tt:5037.910\n",
      "Ep:153, loss:0.00001, loss_test:0.06824, lr:5.93e-03, fs:0.81395 (r=0.707,p=0.959),  time:32.927, tt:5070.792\n",
      "Ep:154, loss:0.00001, loss_test:0.06811, lr:5.87e-03, fs:0.82081 (r=0.717,p=0.959),  time:32.931, tt:5104.268\n",
      "Ep:155, loss:0.00001, loss_test:0.06857, lr:5.81e-03, fs:0.80702 (r=0.697,p=0.958),  time:32.939, tt:5138.423\n",
      "Ep:156, loss:0.00001, loss_test:0.06747, lr:5.75e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.937, tt:5171.086\n",
      "Ep:157, loss:0.00001, loss_test:0.06801, lr:5.70e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.936, tt:5203.869\n",
      "Ep:158, loss:0.00001, loss_test:0.06977, lr:5.64e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.942, tt:5237.832\n",
      "Ep:159, loss:0.00001, loss_test:0.06748, lr:5.58e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.937, tt:5269.905\n",
      "Ep:160, loss:0.00001, loss_test:0.06708, lr:5.53e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.939, tt:5303.185\n",
      "Ep:161, loss:0.00001, loss_test:0.07004, lr:5.47e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.942, tt:5336.572\n",
      "Ep:162, loss:0.00001, loss_test:0.06821, lr:5.42e-03, fs:0.82081 (r=0.717,p=0.959),  time:32.939, tt:5368.999\n",
      "Ep:163, loss:0.00001, loss_test:0.06797, lr:5.36e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.946, tt:5403.150\n",
      "Ep:164, loss:0.00001, loss_test:0.06980, lr:5.31e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.941, tt:5435.217\n",
      "Ep:165, loss:0.00001, loss_test:0.06832, lr:5.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:32.946, tt:5468.969\n",
      "Ep:166, loss:0.00001, loss_test:0.06854, lr:5.20e-03, fs:0.82081 (r=0.717,p=0.959),  time:32.946, tt:5502.015\n",
      "Ep:167, loss:0.00001, loss_test:0.06866, lr:5.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.958, tt:5536.958\n",
      "Ep:168, loss:0.00001, loss_test:0.07043, lr:5.10e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.957, tt:5569.815\n",
      "Ep:169, loss:0.00001, loss_test:0.06778, lr:5.05e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.952, tt:5601.916\n",
      "Ep:170, loss:0.00001, loss_test:0.06844, lr:5.00e-03, fs:0.80000 (r=0.687,p=0.958),  time:32.945, tt:5633.680\n",
      "Ep:171, loss:0.00001, loss_test:0.06973, lr:4.95e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.945, tt:5666.486\n",
      "Ep:172, loss:0.00001, loss_test:0.06750, lr:4.90e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.962, tt:5702.352\n",
      "Ep:173, loss:0.00001, loss_test:0.06914, lr:4.85e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.961, tt:5735.288\n",
      "Ep:174, loss:0.00001, loss_test:0.06903, lr:4.80e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.958, tt:5767.682\n",
      "Ep:175, loss:0.00001, loss_test:0.06783, lr:4.75e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.958, tt:5800.526\n",
      "Ep:176, loss:0.00001, loss_test:0.06944, lr:4.71e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.958, tt:5833.498\n",
      "Ep:177, loss:0.00001, loss_test:0.06897, lr:4.66e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.951, tt:5865.333\n",
      "Ep:178, loss:0.00001, loss_test:0.06849, lr:4.61e-03, fs:0.81395 (r=0.707,p=0.959),  time:32.943, tt:5896.885\n",
      "Ep:179, loss:0.00001, loss_test:0.06926, lr:4.57e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.938, tt:5928.859\n",
      "Ep:180, loss:0.00001, loss_test:0.06967, lr:4.52e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.928, tt:5959.951\n",
      "Ep:181, loss:0.00001, loss_test:0.06834, lr:4.48e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.935, tt:5994.191\n",
      "Ep:182, loss:0.00001, loss_test:0.06952, lr:4.43e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.934, tt:6026.882\n",
      "Ep:183, loss:0.00001, loss_test:0.06958, lr:4.39e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.925, tt:6058.209\n",
      "Ep:184, loss:0.00001, loss_test:0.06907, lr:4.34e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.931, tt:6092.157\n",
      "Ep:185, loss:0.00001, loss_test:0.06924, lr:4.30e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.936, tt:6126.005\n",
      "Ep:186, loss:0.00001, loss_test:0.06853, lr:4.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:32.937, tt:6159.186\n",
      "Ep:187, loss:0.00001, loss_test:0.06957, lr:4.21e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.938, tt:6192.414\n",
      "Ep:188, loss:0.00001, loss_test:0.06874, lr:4.17e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.934, tt:6224.541\n",
      "Ep:189, loss:0.00001, loss_test:0.06928, lr:4.13e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.926, tt:6255.928\n",
      "Ep:190, loss:0.00001, loss_test:0.06973, lr:4.09e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.926, tt:6288.901\n",
      "Ep:191, loss:0.00001, loss_test:0.06924, lr:4.05e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.927, tt:6321.984\n",
      "Ep:192, loss:0.00001, loss_test:0.06913, lr:4.01e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.929, tt:6355.255\n",
      "Ep:193, loss:0.00001, loss_test:0.06928, lr:3.97e-03, fs:0.79762 (r=0.677,p=0.971),  time:32.949, tt:6392.175\n",
      "Ep:194, loss:0.00001, loss_test:0.07037, lr:3.93e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.948, tt:6424.823\n",
      "Ep:195, loss:0.00001, loss_test:0.06902, lr:3.89e-03, fs:0.79762 (r=0.677,p=0.971),  time:32.943, tt:6456.880\n",
      "Ep:196, loss:0.00001, loss_test:0.06905, lr:3.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:32.941, tt:6489.340\n",
      "Ep:197, loss:0.00001, loss_test:0.06985, lr:3.81e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.937, tt:6521.607\n",
      "Ep:198, loss:0.00001, loss_test:0.06978, lr:3.77e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.932, tt:6553.452\n",
      "Ep:199, loss:0.00001, loss_test:0.06886, lr:3.73e-03, fs:0.79762 (r=0.677,p=0.971),  time:32.929, tt:6585.756\n",
      "Ep:200, loss:0.00001, loss_test:0.06935, lr:3.70e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.928, tt:6618.443\n",
      "Ep:201, loss:0.00001, loss_test:0.06979, lr:3.66e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.905, tt:6646.901\n",
      "Ep:202, loss:0.00001, loss_test:0.07000, lr:3.62e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.883, tt:6675.153\n",
      "Ep:203, loss:0.00001, loss_test:0.06914, lr:3.59e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.865, tt:6704.520\n",
      "Ep:204, loss:0.00001, loss_test:0.06931, lr:3.55e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.847, tt:6733.712\n",
      "Ep:205, loss:0.00001, loss_test:0.07007, lr:3.52e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.791, tt:6754.911\n",
      "Ep:206, loss:0.00001, loss_test:0.06992, lr:3.48e-03, fs:0.80240 (r=0.677,p=0.985),  time:32.702, tt:6769.342\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14398, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.204, tt:26.204\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14340, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.993, tt:57.986\n",
      "Ep:2, loss:0.00014, loss_test:0.14245, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.983, tt:89.949\n",
      "Ep:3, loss:0.00014, loss_test:0.14106, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.524, tt:122.098\n",
      "Ep:4, loss:0.00014, loss_test:0.13907, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.183, tt:150.913\n",
      "Ep:5, loss:0.00013, loss_test:0.13616, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:30.660, tt:183.961\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00013, loss_test:0.13195, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:31.044, tt:217.307\n",
      "Ep:7, loss:0.00013, loss_test:0.12610, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:31.524, tt:252.191\n",
      "Ep:8, loss:0.00012, loss_test:0.12024, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:31.573, tt:284.155\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00012, loss_test:0.11556, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:31.778, tt:317.785\n",
      "Ep:10, loss:0.00011, loss_test:0.11348, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:31.730, tt:349.027\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00011, loss_test:0.11179, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:31.670, tt:380.041\n",
      "Ep:12, loss:0.00011, loss_test:0.11127, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:31.906, tt:414.777\n",
      "Ep:13, loss:0.00011, loss_test:0.10977, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:31.967, tt:447.540\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00010, loss_test:0.10786, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:32.044, tt:480.665\n",
      "Ep:15, loss:0.00010, loss_test:0.10664, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:32.048, tt:512.768\n",
      "Ep:16, loss:0.00010, loss_test:0.10539, lr:1.00e-02, fs:0.68545 (r=0.737,p=0.640),  time:32.073, tt:545.236\n",
      "Ep:17, loss:0.00010, loss_test:0.10476, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:32.093, tt:577.666\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.10342, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:32.163, tt:611.088\n",
      "Ep:19, loss:0.00009, loss_test:0.10208, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:32.152, tt:643.032\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00009, loss_test:0.10059, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:32.180, tt:675.789\n",
      "Ep:21, loss:0.00009, loss_test:0.09953, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:32.142, tt:707.125\n",
      "Ep:22, loss:0.00009, loss_test:0.09832, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:32.259, tt:741.964\n",
      "Ep:23, loss:0.00008, loss_test:0.09699, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:32.305, tt:775.331\n",
      "Ep:24, loss:0.00008, loss_test:0.09575, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:32.332, tt:808.298\n",
      "Ep:25, loss:0.00008, loss_test:0.09478, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:32.355, tt:841.229\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00008, loss_test:0.09411, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:32.342, tt:873.226\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00008, loss_test:0.09328, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:32.318, tt:904.893\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.09245, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:32.317, tt:937.179\n",
      "Ep:29, loss:0.00007, loss_test:0.09155, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:32.366, tt:970.967\n",
      "Ep:30, loss:0.00007, loss_test:0.09029, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:32.304, tt:1001.414\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.08939, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:32.293, tt:1033.367\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.08892, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:32.278, tt:1065.169\n",
      "Ep:33, loss:0.00007, loss_test:0.08825, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:32.267, tt:1097.079\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.08763, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:32.219, tt:1127.665\n",
      "Ep:35, loss:0.00007, loss_test:0.08714, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:32.249, tt:1160.971\n",
      "Ep:36, loss:0.00006, loss_test:0.08659, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:32.255, tt:1193.423\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.08623, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:32.261, tt:1225.930\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00006, loss_test:0.08610, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:32.270, tt:1258.517\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.08549, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:32.255, tt:1290.198\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.08491, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:32.247, tt:1322.126\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.08452, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.253, tt:1354.630\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.08372, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.253, tt:1386.899\n",
      "Ep:43, loss:0.00005, loss_test:0.08256, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.257, tt:1419.307\n",
      "Ep:44, loss:0.00005, loss_test:0.08261, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.259, tt:1451.635\n",
      "Ep:45, loss:0.00005, loss_test:0.08218, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:32.249, tt:1483.458\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00005, loss_test:0.08165, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:32.251, tt:1515.810\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00005, loss_test:0.08161, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:32.244, tt:1547.715\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.08167, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:32.207, tt:1578.158\n",
      "Ep:49, loss:0.00005, loss_test:0.08022, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:32.200, tt:1609.982\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00005, loss_test:0.08094, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:32.191, tt:1641.739\n",
      "Ep:51, loss:0.00005, loss_test:0.08080, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:32.186, tt:1673.679\n",
      "Ep:52, loss:0.00004, loss_test:0.07983, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:32.185, tt:1705.787\n",
      "Ep:53, loss:0.00004, loss_test:0.07989, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:32.203, tt:1738.950\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00004, loss_test:0.07928, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:32.210, tt:1771.573\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.07878, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.218, tt:1804.207\n",
      "Ep:56, loss:0.00004, loss_test:0.07937, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:32.168, tt:1833.602\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.07785, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:32.184, tt:1866.673\n",
      "Ep:58, loss:0.00004, loss_test:0.07937, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:32.188, tt:1899.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00004, loss_test:0.07717, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:32.169, tt:1930.153\n",
      "Ep:60, loss:0.00004, loss_test:0.07833, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:32.167, tt:1962.162\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.07832, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:32.180, tt:1995.131\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00003, loss_test:0.07662, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:32.174, tt:2026.951\n",
      "Ep:63, loss:0.00003, loss_test:0.07865, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:32.146, tt:2057.328\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.07593, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:32.157, tt:2090.219\n",
      "Ep:65, loss:0.00003, loss_test:0.07952, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:32.115, tt:2119.593\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00003, loss_test:0.07519, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:32.115, tt:2151.713\n",
      "Ep:67, loss:0.00003, loss_test:0.07938, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:32.098, tt:2182.689\n",
      "Ep:68, loss:0.00003, loss_test:0.07472, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:32.125, tt:2216.651\n",
      "Ep:69, loss:0.00003, loss_test:0.07877, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:32.123, tt:2248.599\n",
      "Ep:70, loss:0.00003, loss_test:0.07425, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.117, tt:2280.289\n",
      "Ep:71, loss:0.00003, loss_test:0.07829, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:32.114, tt:2312.240\n",
      "Ep:72, loss:0.00003, loss_test:0.07450, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:32.121, tt:2344.815\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.07905, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:32.118, tt:2376.698\n",
      "Ep:74, loss:0.00003, loss_test:0.07345, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:32.108, tt:2408.085\n",
      "Ep:75, loss:0.00003, loss_test:0.07956, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:32.112, tt:2440.540\n",
      "Ep:76, loss:0.00002, loss_test:0.07311, lr:1.00e-02, fs:0.88889 (r=0.808,p=0.988),  time:32.116, tt:2472.915\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.07959, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:32.118, tt:2505.190\n",
      "Ep:78, loss:0.00002, loss_test:0.07345, lr:1.00e-02, fs:0.88889 (r=0.808,p=0.988),  time:32.117, tt:2537.229\n",
      "Ep:79, loss:0.00002, loss_test:0.07712, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:32.104, tt:2568.348\n",
      "Ep:80, loss:0.00002, loss_test:0.07362, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:32.108, tt:2600.730\n",
      "Ep:81, loss:0.00002, loss_test:0.07596, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:32.119, tt:2633.741\n",
      "Ep:82, loss:0.00002, loss_test:0.07470, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:32.141, tt:2667.680\n",
      "Ep:83, loss:0.00002, loss_test:0.07437, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:32.130, tt:2698.907\n",
      "Ep:84, loss:0.00002, loss_test:0.07537, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.118, tt:2730.044\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.07468, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:32.096, tt:2760.279\n",
      "Ep:86, loss:0.00002, loss_test:0.07435, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.104, tt:2793.066\n",
      "Ep:87, loss:0.00002, loss_test:0.07681, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:32.129, tt:2827.385\n",
      "Ep:88, loss:0.00002, loss_test:0.07273, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.130, tt:2859.573\n",
      "Ep:89, loss:0.00002, loss_test:0.07559, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.120, tt:2890.788\n",
      "Ep:90, loss:0.00002, loss_test:0.07236, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.109, tt:2921.960\n",
      "Ep:91, loss:0.00002, loss_test:0.07536, lr:1.00e-02, fs:0.88889 (r=0.808,p=0.988),  time:32.101, tt:2953.285\n",
      "Ep:92, loss:0.00002, loss_test:0.07300, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.093, tt:2984.624\n",
      "Ep:93, loss:0.00002, loss_test:0.07392, lr:1.00e-02, fs:0.88889 (r=0.808,p=0.988),  time:32.086, tt:3016.112\n",
      "Ep:94, loss:0.00002, loss_test:0.07452, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.089, tt:3048.495\n",
      "Ep:95, loss:0.00002, loss_test:0.07279, lr:1.00e-02, fs:0.89385 (r=0.808,p=1.000),  time:32.091, tt:3080.758\n",
      "Ep:96, loss:0.00002, loss_test:0.07615, lr:9.90e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.103, tt:3113.953\n",
      "Ep:97, loss:0.00002, loss_test:0.07119, lr:9.80e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.103, tt:3146.084\n",
      "Ep:98, loss:0.00002, loss_test:0.07497, lr:9.70e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.104, tt:3178.327\n",
      "Ep:99, loss:0.00002, loss_test:0.07381, lr:9.61e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.087, tt:3208.666\n",
      "Ep:100, loss:0.00001, loss_test:0.07189, lr:9.51e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.080, tt:3240.055\n",
      "Ep:101, loss:0.00001, loss_test:0.07847, lr:9.41e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.101, tt:3274.311\n",
      "Ep:102, loss:0.00001, loss_test:0.07030, lr:9.32e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.092, tt:3305.473\n",
      "Ep:103, loss:0.00001, loss_test:0.07779, lr:9.23e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.094, tt:3337.743\n",
      "Ep:104, loss:0.00001, loss_test:0.07247, lr:9.14e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.124, tt:3373.066\n",
      "Ep:105, loss:0.00001, loss_test:0.07298, lr:9.04e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.126, tt:3405.333\n",
      "Ep:106, loss:0.00001, loss_test:0.07668, lr:8.95e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.122, tt:3437.097\n",
      "Ep:107, loss:0.00001, loss_test:0.07013, lr:8.86e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.115, tt:3468.402\n",
      "Ep:108, loss:0.00001, loss_test:0.07839, lr:8.78e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.110, tt:3499.981\n",
      "Ep:109, loss:0.00001, loss_test:0.07322, lr:8.69e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.102, tt:3531.256\n",
      "Ep:110, loss:0.00001, loss_test:0.07227, lr:8.60e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.114, tt:3564.673\n",
      "Ep:111, loss:0.00001, loss_test:0.07694, lr:8.51e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.121, tt:3597.528\n",
      "Ep:112, loss:0.00001, loss_test:0.07124, lr:8.43e-03, fs:0.89385 (r=0.808,p=1.000),  time:32.115, tt:3629.027\n",
      "Ep:113, loss:0.00001, loss_test:0.07467, lr:8.35e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.124, tt:3662.097\n",
      "Ep:114, loss:0.00001, loss_test:0.07433, lr:8.26e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.119, tt:3693.684\n",
      "Ep:115, loss:0.00001, loss_test:0.07305, lr:8.18e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.117, tt:3725.532\n",
      "Ep:116, loss:0.00001, loss_test:0.07671, lr:8.10e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.117, tt:3757.699\n",
      "Ep:117, loss:0.00001, loss_test:0.07261, lr:8.02e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.107, tt:3788.614\n",
      "Ep:118, loss:0.00001, loss_test:0.07391, lr:7.94e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.086, tt:3818.245\n",
      "Ep:119, loss:0.00001, loss_test:0.07611, lr:7.86e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.075, tt:3849.021\n",
      "Ep:120, loss:0.00001, loss_test:0.07218, lr:7.78e-03, fs:0.88764 (r=0.798,p=1.000),  time:32.077, tt:3881.295\n",
      "Ep:121, loss:0.00001, loss_test:0.07641, lr:7.70e-03, fs:0.87500 (r=0.778,p=1.000),  time:32.080, tt:3913.731\n",
      "Ep:122, loss:0.00001, loss_test:0.07476, lr:7.62e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.087, tt:3946.657\n",
      "Ep:123, loss:0.00001, loss_test:0.07273, lr:7.55e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.102, tt:3980.612\n",
      "Ep:124, loss:0.00001, loss_test:0.07646, lr:7.47e-03, fs:0.87500 (r=0.778,p=1.000),  time:32.117, tt:4014.607\n",
      "Ep:125, loss:0.00001, loss_test:0.07386, lr:7.40e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.123, tt:4047.514\n",
      "Ep:126, loss:0.00001, loss_test:0.07449, lr:7.32e-03, fs:0.87500 (r=0.778,p=1.000),  time:32.133, tt:4080.866\n",
      "Ep:127, loss:0.00001, loss_test:0.07574, lr:7.25e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.141, tt:4114.033\n",
      "Ep:128, loss:0.00001, loss_test:0.07391, lr:7.18e-03, fs:0.88136 (r=0.788,p=1.000),  time:32.126, tt:4144.264\n",
      "Ep:129, loss:0.00001, loss_test:0.07542, lr:7.11e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.119, tt:4175.435\n",
      "Ep:130, loss:0.00001, loss_test:0.07512, lr:7.03e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.116, tt:4207.181\n",
      "Ep:131, loss:0.00001, loss_test:0.07399, lr:6.96e-03, fs:0.87500 (r=0.778,p=1.000),  time:32.128, tt:4240.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.07602, lr:6.89e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.138, tt:4274.291\n",
      "Ep:133, loss:0.00001, loss_test:0.07385, lr:6.83e-03, fs:0.86207 (r=0.758,p=1.000),  time:32.140, tt:4306.790\n",
      "Ep:134, loss:0.00001, loss_test:0.07514, lr:6.76e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.148, tt:4339.934\n",
      "Ep:135, loss:0.00001, loss_test:0.07610, lr:6.69e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.159, tt:4373.646\n",
      "Ep:136, loss:0.00001, loss_test:0.07357, lr:6.62e-03, fs:0.85549 (r=0.747,p=1.000),  time:32.173, tt:4407.698\n",
      "Ep:137, loss:0.00001, loss_test:0.07744, lr:6.56e-03, fs:0.85549 (r=0.747,p=1.000),  time:32.182, tt:4441.164\n",
      "Ep:138, loss:0.00001, loss_test:0.07420, lr:6.49e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.193, tt:4474.860\n",
      "Ep:139, loss:0.00001, loss_test:0.07534, lr:6.43e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.195, tt:4507.279\n",
      "Ep:140, loss:0.00001, loss_test:0.07712, lr:6.36e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.201, tt:4540.361\n",
      "Ep:141, loss:0.00001, loss_test:0.07307, lr:6.30e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.215, tt:4574.532\n",
      "Ep:142, loss:0.00001, loss_test:0.07627, lr:6.24e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.225, tt:4608.220\n",
      "Ep:143, loss:0.00001, loss_test:0.07590, lr:6.17e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.237, tt:4642.091\n",
      "Ep:144, loss:0.00001, loss_test:0.07392, lr:6.11e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.238, tt:4674.454\n",
      "Ep:145, loss:0.00001, loss_test:0.07611, lr:6.05e-03, fs:0.86207 (r=0.758,p=1.000),  time:32.235, tt:4706.353\n",
      "Ep:146, loss:0.00001, loss_test:0.07514, lr:5.99e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.241, tt:4739.476\n",
      "Ep:147, loss:0.00001, loss_test:0.07472, lr:5.93e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.255, tt:4773.800\n",
      "Ep:148, loss:0.00001, loss_test:0.07627, lr:5.87e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.267, tt:4807.767\n",
      "Ep:149, loss:0.00001, loss_test:0.07503, lr:5.81e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.275, tt:4841.254\n",
      "Ep:150, loss:0.00001, loss_test:0.07578, lr:5.75e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.309, tt:4878.729\n",
      "Ep:151, loss:0.00001, loss_test:0.07618, lr:5.70e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.324, tt:4913.296\n",
      "Ep:152, loss:0.00001, loss_test:0.07487, lr:5.64e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.326, tt:4945.832\n",
      "Ep:153, loss:0.00001, loss_test:0.07632, lr:5.58e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.332, tt:4979.184\n",
      "Ep:154, loss:0.00001, loss_test:0.07508, lr:5.53e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.334, tt:5011.775\n",
      "Ep:155, loss:0.00001, loss_test:0.07537, lr:5.47e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.342, tt:5045.382\n",
      "Ep:156, loss:0.00001, loss_test:0.07600, lr:5.42e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.346, tt:5078.342\n",
      "Ep:157, loss:0.00001, loss_test:0.07472, lr:5.36e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.348, tt:5110.976\n",
      "Ep:158, loss:0.00001, loss_test:0.07610, lr:5.31e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.352, tt:5144.009\n",
      "Ep:159, loss:0.00001, loss_test:0.07458, lr:5.26e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.362, tt:5177.944\n",
      "Ep:160, loss:0.00001, loss_test:0.07587, lr:5.20e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.364, tt:5210.576\n",
      "Ep:161, loss:0.00001, loss_test:0.07586, lr:5.15e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.371, tt:5244.035\n",
      "Ep:162, loss:0.00001, loss_test:0.07457, lr:5.10e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.379, tt:5277.787\n",
      "Ep:163, loss:0.00001, loss_test:0.07696, lr:5.05e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.375, tt:5309.462\n",
      "Ep:164, loss:0.00001, loss_test:0.07626, lr:5.00e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.379, tt:5342.525\n",
      "Ep:165, loss:0.00001, loss_test:0.07459, lr:4.95e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.383, tt:5375.612\n",
      "Ep:166, loss:0.00001, loss_test:0.07666, lr:4.90e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.386, tt:5408.483\n",
      "Ep:167, loss:0.00001, loss_test:0.07553, lr:4.85e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.386, tt:5440.930\n",
      "Ep:168, loss:0.00001, loss_test:0.07542, lr:4.80e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.383, tt:5472.792\n",
      "Ep:169, loss:0.00001, loss_test:0.07682, lr:4.75e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.373, tt:5503.439\n",
      "Ep:170, loss:0.00001, loss_test:0.07527, lr:4.71e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.374, tt:5535.890\n",
      "Ep:171, loss:0.00001, loss_test:0.07604, lr:4.66e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.370, tt:5567.713\n",
      "Ep:172, loss:0.00001, loss_test:0.07678, lr:4.61e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.372, tt:5600.283\n",
      "Ep:173, loss:0.00001, loss_test:0.07554, lr:4.57e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.370, tt:5632.462\n",
      "Ep:174, loss:0.00001, loss_test:0.07673, lr:4.52e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.375, tt:5665.565\n",
      "Ep:175, loss:0.00001, loss_test:0.07557, lr:4.48e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.383, tt:5699.340\n",
      "Ep:176, loss:0.00001, loss_test:0.07645, lr:4.43e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.383, tt:5731.810\n",
      "Ep:177, loss:0.00001, loss_test:0.07654, lr:4.39e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.390, tt:5765.397\n",
      "Ep:178, loss:0.00001, loss_test:0.07589, lr:4.34e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.396, tt:5798.950\n",
      "Ep:179, loss:0.00001, loss_test:0.07664, lr:4.30e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.396, tt:5831.309\n",
      "Ep:180, loss:0.00001, loss_test:0.07607, lr:4.26e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.407, tt:5865.640\n",
      "Ep:181, loss:0.00001, loss_test:0.07601, lr:4.21e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.411, tt:5898.767\n",
      "Ep:182, loss:0.00001, loss_test:0.07656, lr:4.17e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.419, tt:5932.745\n",
      "Ep:183, loss:0.00001, loss_test:0.07667, lr:4.13e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.428, tt:5966.690\n",
      "Ep:184, loss:0.00000, loss_test:0.07620, lr:4.09e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.432, tt:5999.848\n",
      "Ep:185, loss:0.00000, loss_test:0.07665, lr:4.05e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.437, tt:6033.203\n",
      "Ep:186, loss:0.00000, loss_test:0.07687, lr:4.01e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.449, tt:6068.018\n",
      "Ep:187, loss:0.00000, loss_test:0.07628, lr:3.97e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.455, tt:6101.570\n",
      "Ep:188, loss:0.00000, loss_test:0.07683, lr:3.93e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.462, tt:6135.368\n",
      "Ep:189, loss:0.00000, loss_test:0.07640, lr:3.89e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.466, tt:6168.576\n",
      "Ep:190, loss:0.00000, loss_test:0.07666, lr:3.85e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.473, tt:6202.372\n",
      "Ep:191, loss:0.00000, loss_test:0.07659, lr:3.81e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.515, tt:6242.845\n",
      "Ep:192, loss:0.00000, loss_test:0.07629, lr:3.77e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.524, tt:6277.223\n",
      "Ep:193, loss:0.00000, loss_test:0.07705, lr:3.73e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.525, tt:6309.911\n",
      "Ep:194, loss:0.00000, loss_test:0.07671, lr:3.70e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.529, tt:6343.137\n",
      "Ep:195, loss:0.00000, loss_test:0.07661, lr:3.66e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.531, tt:6376.044\n",
      "Ep:196, loss:0.00000, loss_test:0.07689, lr:3.62e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.536, tt:6409.552\n",
      "Ep:197, loss:0.00000, loss_test:0.07657, lr:3.59e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.544, tt:6443.690\n",
      "Ep:198, loss:0.00000, loss_test:0.07646, lr:3.55e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.547, tt:6476.846\n",
      "Ep:199, loss:0.00000, loss_test:0.07672, lr:3.52e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.556, tt:6511.274\n",
      "Ep:200, loss:0.00000, loss_test:0.07659, lr:3.48e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.552, tt:6542.901\n",
      "Ep:201, loss:0.00000, loss_test:0.07651, lr:3.45e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.557, tt:6576.484\n",
      "Ep:202, loss:0.00000, loss_test:0.07690, lr:3.41e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.559, tt:6609.411\n",
      "Ep:203, loss:0.00000, loss_test:0.07722, lr:3.38e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.562, tt:6642.614\n",
      "Ep:204, loss:0.00000, loss_test:0.07663, lr:3.34e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.544, tt:6671.586\n",
      "Ep:205, loss:0.00000, loss_test:0.07690, lr:3.31e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.478, tt:6690.382\n",
      "Ep:206, loss:0.00000, loss_test:0.07703, lr:3.28e-03, fs:0.84884 (r=0.737,p=1.000),  time:32.373, tt:6701.118\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14342, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.288, tt:58.288\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13928, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.477, tt:124.954\n",
      "Ep:2, loss:0.00052, loss_test:0.12998, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:64.422, tt:193.265\n",
      "Ep:3, loss:0.00048, loss_test:0.11668, lr:1.00e-02, fs:0.64762 (r=0.687,p=0.613),  time:65.441, tt:261.763\n",
      "Ep:4, loss:0.00045, loss_test:0.11424, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:65.554, tt:327.770\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.11162, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:65.995, tt:395.967\n",
      "Ep:6, loss:0.00041, loss_test:0.10836, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:66.065, tt:462.453\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.10565, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:66.450, tt:531.598\n",
      "Ep:8, loss:0.00038, loss_test:0.10338, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:66.453, tt:598.078\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.10149, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:66.476, tt:664.756\n",
      "Ep:10, loss:0.00034, loss_test:0.09912, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:66.566, tt:732.227\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.09661, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:66.679, tt:800.150\n",
      "Ep:12, loss:0.00031, loss_test:0.09411, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:66.702, tt:867.129\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.09216, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:66.749, tt:934.493\n",
      "Ep:14, loss:0.00029, loss_test:0.09056, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:66.729, tt:1000.936\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.08895, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:66.812, tt:1068.999\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.08737, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:66.744, tt:1134.653\n",
      "Ep:17, loss:0.00025, loss_test:0.08556, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:66.658, tt:1199.852\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.08361, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:66.699, tt:1267.277\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.08561, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:66.799, tt:1335.974\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.08044, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:66.873, tt:1404.328\n",
      "Ep:21, loss:0.00021, loss_test:0.08040, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:66.866, tt:1471.048\n",
      "Ep:22, loss:0.00020, loss_test:0.08041, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:66.846, tt:1537.455\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.07866, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:66.863, tt:1604.711\n",
      "Ep:24, loss:0.00019, loss_test:0.08128, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:66.926, tt:1673.138\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.07655, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:66.872, tt:1738.684\n",
      "Ep:26, loss:0.00017, loss_test:0.07471, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:66.837, tt:1804.602\n",
      "Ep:27, loss:0.00016, loss_test:0.07540, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:66.893, tt:1872.994\n",
      "Ep:28, loss:0.00016, loss_test:0.07661, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:66.909, tt:1940.373\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.07814, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:66.973, tt:2009.182\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.07773, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:67.044, tt:2078.374\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.07531, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:67.048, tt:2145.524\n",
      "Ep:32, loss:0.00013, loss_test:0.07422, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:67.042, tt:2212.399\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07257, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:67.027, tt:2278.918\n",
      "Ep:34, loss:0.00012, loss_test:0.07818, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:66.957, tt:2343.484\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.07485, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:66.940, tt:2409.833\n",
      "Ep:36, loss:0.00011, loss_test:0.07578, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:66.876, tt:2474.400\n",
      "Ep:37, loss:0.00011, loss_test:0.07205, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:66.853, tt:2540.429\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.07203, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:66.875, tt:2608.108\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07403, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:66.823, tt:2672.920\n",
      "Ep:40, loss:0.00009, loss_test:0.07763, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:66.811, tt:2739.239\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07631, lr:1.00e-02, fs:0.87912 (r=0.808,p=0.964),  time:66.802, tt:2805.697\n",
      "Ep:42, loss:0.00009, loss_test:0.07443, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:66.825, tt:2873.453\n",
      "Ep:43, loss:0.00008, loss_test:0.07175, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:66.803, tt:2939.313\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.07332, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:66.773, tt:3004.769\n",
      "Ep:45, loss:0.00008, loss_test:0.07464, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:66.779, tt:3071.813\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.07246, lr:1.00e-02, fs:0.90110 (r=0.828,p=0.988),  time:66.750, tt:3137.256\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.07202, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:66.758, tt:3204.384\n",
      "Ep:48, loss:0.00007, loss_test:0.07116, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:66.797, tt:3273.065\n",
      "Ep:49, loss:0.00006, loss_test:0.07882, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:66.834, tt:3341.704\n",
      "Ep:50, loss:0.00006, loss_test:0.07906, lr:1.00e-02, fs:0.86364 (r=0.768,p=0.987),  time:66.834, tt:3408.519\n",
      "Ep:51, loss:0.00006, loss_test:0.07563, lr:1.00e-02, fs:0.89503 (r=0.818,p=0.988),  time:66.843, tt:3475.814\n",
      "Ep:52, loss:0.00006, loss_test:0.07712, lr:1.00e-02, fs:0.88889 (r=0.808,p=0.988),  time:66.793, tt:3540.005\n",
      "Ep:53, loss:0.00005, loss_test:0.08144, lr:1.00e-02, fs:0.86364 (r=0.768,p=0.987),  time:66.746, tt:3604.264\n",
      "Ep:54, loss:0.00005, loss_test:0.07714, lr:1.00e-02, fs:0.88889 (r=0.808,p=0.988),  time:66.730, tt:3670.159\n",
      "Ep:55, loss:0.00005, loss_test:0.07017, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:66.721, tt:3736.399\n",
      "Ep:56, loss:0.00005, loss_test:0.07478, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:66.709, tt:3802.421\n",
      "Ep:57, loss:0.00005, loss_test:0.07731, lr:1.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:66.731, tt:3870.413\n",
      "Ep:58, loss:0.00005, loss_test:0.07515, lr:9.90e-03, fs:0.89617 (r=0.828,p=0.976),  time:66.741, tt:3937.710\n",
      "Ep:59, loss:0.00004, loss_test:0.07561, lr:9.80e-03, fs:0.87151 (r=0.788,p=0.975),  time:66.792, tt:4007.529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00004, loss_test:0.07950, lr:9.70e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.778, tt:4073.468\n",
      "Ep:61, loss:0.00004, loss_test:0.07817, lr:9.61e-03, fs:0.84571 (r=0.747,p=0.974),  time:66.792, tt:4141.104\n",
      "Ep:62, loss:0.00004, loss_test:0.07765, lr:9.51e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.794, tt:4207.991\n",
      "Ep:63, loss:0.00004, loss_test:0.07821, lr:9.41e-03, fs:0.85876 (r=0.768,p=0.974),  time:66.798, tt:4275.103\n",
      "Ep:64, loss:0.00004, loss_test:0.07901, lr:9.32e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.769, tt:4340.015\n",
      "Ep:65, loss:0.00004, loss_test:0.07690, lr:9.23e-03, fs:0.85876 (r=0.768,p=0.974),  time:66.773, tt:4407.042\n",
      "Ep:66, loss:0.00004, loss_test:0.07931, lr:9.14e-03, fs:0.86364 (r=0.768,p=0.987),  time:66.795, tt:4475.293\n",
      "Ep:67, loss:0.00003, loss_test:0.07993, lr:9.04e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.773, tt:4540.585\n",
      "Ep:68, loss:0.00003, loss_test:0.08696, lr:8.95e-03, fs:0.84393 (r=0.737,p=0.986),  time:66.752, tt:4605.868\n",
      "Ep:69, loss:0.00003, loss_test:0.08394, lr:8.86e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.736, tt:4671.499\n",
      "Ep:70, loss:0.00003, loss_test:0.07759, lr:8.78e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.672, tt:4733.698\n",
      "Ep:71, loss:0.00003, loss_test:0.08559, lr:8.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:66.671, tt:4800.314\n",
      "Ep:72, loss:0.00003, loss_test:0.08029, lr:8.60e-03, fs:0.87006 (r=0.778,p=0.987),  time:66.674, tt:4867.169\n",
      "Ep:73, loss:0.00003, loss_test:0.08508, lr:8.51e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.680, tt:4934.327\n",
      "Ep:74, loss:0.00003, loss_test:0.08042, lr:8.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.676, tt:5000.715\n",
      "Ep:75, loss:0.00003, loss_test:0.08178, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:66.658, tt:5065.979\n",
      "Ep:76, loss:0.00002, loss_test:0.08511, lr:8.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.664, tt:5133.145\n",
      "Ep:77, loss:0.00002, loss_test:0.08546, lr:8.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:66.645, tt:5198.288\n",
      "Ep:78, loss:0.00002, loss_test:0.08043, lr:8.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.657, tt:5265.915\n",
      "Ep:79, loss:0.00002, loss_test:0.08530, lr:8.02e-03, fs:0.85714 (r=0.758,p=0.987),  time:66.641, tt:5331.271\n",
      "Ep:80, loss:0.00002, loss_test:0.08773, lr:7.94e-03, fs:0.85714 (r=0.758,p=0.987),  time:66.671, tt:5400.329\n",
      "Ep:81, loss:0.00002, loss_test:0.08408, lr:7.86e-03, fs:0.83908 (r=0.737,p=0.973),  time:66.682, tt:5467.924\n",
      "Ep:82, loss:0.00002, loss_test:0.08565, lr:7.78e-03, fs:0.79762 (r=0.677,p=0.971),  time:66.678, tt:5534.283\n",
      "Ep:83, loss:0.00002, loss_test:0.08306, lr:7.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.675, tt:5600.665\n",
      "Ep:84, loss:0.00002, loss_test:0.08675, lr:7.62e-03, fs:0.80952 (r=0.687,p=0.986),  time:66.673, tt:5667.215\n",
      "Ep:85, loss:0.00002, loss_test:0.08651, lr:7.55e-03, fs:0.85714 (r=0.758,p=0.987),  time:66.679, tt:5734.393\n",
      "Ep:86, loss:0.00002, loss_test:0.08549, lr:7.47e-03, fs:0.84571 (r=0.747,p=0.974),  time:66.688, tt:5801.862\n",
      "Ep:87, loss:0.00002, loss_test:0.08708, lr:7.40e-03, fs:0.83237 (r=0.727,p=0.973),  time:66.683, tt:5868.098\n",
      "Ep:88, loss:0.00002, loss_test:0.08619, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:66.677, tt:5934.294\n",
      "Ep:89, loss:0.00002, loss_test:0.08505, lr:7.25e-03, fs:0.85876 (r=0.768,p=0.974),  time:66.667, tt:6000.061\n",
      "Ep:90, loss:0.00002, loss_test:0.08850, lr:7.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:66.647, tt:6064.831\n",
      "Ep:91, loss:0.00002, loss_test:0.08526, lr:7.11e-03, fs:0.86517 (r=0.778,p=0.975),  time:66.643, tt:6131.198\n",
      "Ep:92, loss:0.00002, loss_test:0.08743, lr:7.03e-03, fs:0.77576 (r=0.646,p=0.970),  time:66.630, tt:6196.570\n",
      "Ep:93, loss:0.00002, loss_test:0.08733, lr:6.96e-03, fs:0.78313 (r=0.657,p=0.970),  time:66.636, tt:6263.829\n",
      "Ep:94, loss:0.00001, loss_test:0.08688, lr:6.89e-03, fs:0.81871 (r=0.707,p=0.972),  time:66.626, tt:6329.453\n",
      "Ep:95, loss:0.00001, loss_test:0.08661, lr:6.83e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.616, tt:6395.155\n",
      "Ep:96, loss:0.00001, loss_test:0.08642, lr:6.76e-03, fs:0.78049 (r=0.646,p=0.985),  time:66.599, tt:6460.134\n",
      "Ep:97, loss:0.00001, loss_test:0.08548, lr:6.69e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.635, tt:6530.253\n",
      "Ep:98, loss:0.00001, loss_test:0.08777, lr:6.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:66.654, tt:6598.756\n",
      "Ep:99, loss:0.00001, loss_test:0.08724, lr:6.56e-03, fs:0.83908 (r=0.737,p=0.973),  time:66.652, tt:6665.243\n",
      "Ep:100, loss:0.00001, loss_test:0.08913, lr:6.49e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.640, tt:6730.649\n",
      "Ep:101, loss:0.00001, loss_test:0.08706, lr:6.43e-03, fs:0.81657 (r=0.697,p=0.986),  time:66.638, tt:6797.025\n",
      "Ep:102, loss:0.00001, loss_test:0.08691, lr:6.36e-03, fs:0.83041 (r=0.717,p=0.986),  time:66.642, tt:6864.145\n",
      "Ep:103, loss:0.00001, loss_test:0.08702, lr:6.30e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.633, tt:6929.868\n",
      "Ep:104, loss:0.00001, loss_test:0.08684, lr:6.24e-03, fs:0.81657 (r=0.697,p=0.986),  time:66.626, tt:6995.739\n",
      "Ep:105, loss:0.00001, loss_test:0.08782, lr:6.17e-03, fs:0.85057 (r=0.747,p=0.987),  time:66.627, tt:7062.420\n",
      "Ep:106, loss:0.00001, loss_test:0.08749, lr:6.11e-03, fs:0.84393 (r=0.737,p=0.986),  time:66.531, tt:7118.783\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14700, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.693, tt:12.693\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14688, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.038, tt:26.076\n",
      "Ep:2, loss:0.00014, loss_test:0.14670, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.784, tt:41.351\n",
      "Ep:3, loss:0.00014, loss_test:0.14646, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.290, tt:57.162\n",
      "Ep:4, loss:0.00014, loss_test:0.14617, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.381, tt:71.905\n",
      "Ep:5, loss:0.00014, loss_test:0.14582, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.660, tt:87.963\n",
      "Ep:6, loss:0.00014, loss_test:0.14539, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.739, tt:103.170\n",
      "Ep:7, loss:0.00014, loss_test:0.14485, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.700, tt:117.601\n",
      "Ep:8, loss:0.00014, loss_test:0.14422, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.662, tt:131.955\n",
      "Ep:9, loss:0.00014, loss_test:0.14345, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.530, tt:145.302\n",
      "Ep:10, loss:0.00014, loss_test:0.14250, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.548, tt:160.033\n",
      "Ep:11, loss:0.00013, loss_test:0.14139, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:14.653, tt:175.832\n",
      "Ep:12, loss:0.00013, loss_test:0.14002, lr:9.90e-03, fs:0.65035 (r=0.939,p=0.497),  time:14.636, tt:190.271\n",
      "Ep:13, loss:0.00013, loss_test:0.13836, lr:9.80e-03, fs:0.64286 (r=0.909,p=0.497),  time:14.626, tt:204.758\n",
      "Ep:14, loss:0.00013, loss_test:0.13648, lr:9.70e-03, fs:0.63704 (r=0.869,p=0.503),  time:14.654, tt:219.805\n",
      "Ep:15, loss:0.00012, loss_test:0.13443, lr:9.61e-03, fs:0.64865 (r=0.848,p=0.525),  time:14.668, tt:234.685\n",
      "Ep:16, loss:0.00012, loss_test:0.13219, lr:9.51e-03, fs:0.62857 (r=0.778,p=0.527),  time:14.672, tt:249.422\n",
      "Ep:17, loss:0.00012, loss_test:0.13058, lr:9.41e-03, fs:0.61404 (r=0.707,p=0.543),  time:14.690, tt:264.413\n",
      "Ep:18, loss:0.00011, loss_test:0.12999, lr:9.32e-03, fs:0.62100 (r=0.687,p=0.567),  time:14.727, tt:279.820\n",
      "Ep:19, loss:0.00011, loss_test:0.12990, lr:9.23e-03, fs:0.62500 (r=0.657,p=0.596),  time:14.784, tt:295.676\n",
      "Ep:20, loss:0.00011, loss_test:0.12931, lr:9.14e-03, fs:0.63768 (r=0.667,p=0.611),  time:14.834, tt:311.508\n",
      "Ep:21, loss:0.00011, loss_test:0.12825, lr:9.04e-03, fs:0.62617 (r=0.677,p=0.583),  time:14.821, tt:326.065\n",
      "Ep:22, loss:0.00011, loss_test:0.12748, lr:8.95e-03, fs:0.61751 (r=0.677,p=0.568),  time:14.844, tt:341.408\n",
      "Ep:23, loss:0.00011, loss_test:0.12699, lr:8.86e-03, fs:0.61538 (r=0.687,p=0.557),  time:14.879, tt:357.107\n",
      "Ep:24, loss:0.00011, loss_test:0.12622, lr:8.78e-03, fs:0.61883 (r=0.697,p=0.556),  time:14.921, tt:373.034\n",
      "Ep:25, loss:0.00010, loss_test:0.12477, lr:8.69e-03, fs:0.61818 (r=0.687,p=0.562),  time:14.949, tt:388.672\n",
      "Ep:26, loss:0.00010, loss_test:0.12345, lr:8.60e-03, fs:0.62963 (r=0.687,p=0.581),  time:14.996, tt:404.896\n",
      "Ep:27, loss:0.00010, loss_test:0.12244, lr:8.51e-03, fs:0.63507 (r=0.677,p=0.598),  time:15.005, tt:420.127\n",
      "Ep:28, loss:0.00010, loss_test:0.12148, lr:8.43e-03, fs:0.63107 (r=0.657,p=0.607),  time:15.008, tt:435.245\n",
      "Ep:29, loss:0.00010, loss_test:0.12047, lr:8.35e-03, fs:0.64706 (r=0.667,p=0.629),  time:15.037, tt:451.103\n",
      "Ep:30, loss:0.00010, loss_test:0.11948, lr:8.26e-03, fs:0.63507 (r=0.677,p=0.598),  time:15.041, tt:466.286\n",
      "Ep:31, loss:0.00009, loss_test:0.11862, lr:8.18e-03, fs:0.64486 (r=0.697,p=0.600),  time:15.098, tt:483.141\n",
      "Ep:32, loss:0.00009, loss_test:0.11776, lr:8.10e-03, fs:0.64815 (r=0.707,p=0.598),  time:15.133, tt:499.405\n",
      "Ep:33, loss:0.00009, loss_test:0.11673, lr:8.02e-03, fs:0.64815 (r=0.707,p=0.598),  time:15.179, tt:516.072\n",
      "Ep:34, loss:0.00009, loss_test:0.11549, lr:7.94e-03, fs:0.65421 (r=0.707,p=0.609),  time:15.200, tt:532.002\n",
      "Ep:35, loss:0.00009, loss_test:0.11445, lr:7.86e-03, fs:0.66038 (r=0.707,p=0.619),  time:15.234, tt:548.417\n",
      "Ep:36, loss:0.00009, loss_test:0.11355, lr:7.78e-03, fs:0.66667 (r=0.707,p=0.631),  time:15.276, tt:565.215\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.11274, lr:7.78e-03, fs:0.67308 (r=0.707,p=0.642),  time:15.286, tt:580.876\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.11202, lr:7.78e-03, fs:0.68599 (r=0.717,p=0.657),  time:15.308, tt:597.005\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.11139, lr:7.78e-03, fs:0.68269 (r=0.717,p=0.651),  time:15.309, tt:612.365\n",
      "Ep:40, loss:0.00009, loss_test:0.11089, lr:7.78e-03, fs:0.67943 (r=0.717,p=0.645),  time:15.315, tt:627.928\n",
      "Ep:41, loss:0.00008, loss_test:0.11029, lr:7.78e-03, fs:0.68868 (r=0.737,p=0.646),  time:15.319, tt:643.402\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.10945, lr:7.78e-03, fs:0.70968 (r=0.778,p=0.653),  time:15.280, tt:657.036\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.10836, lr:7.78e-03, fs:0.71296 (r=0.778,p=0.658),  time:15.281, tt:672.347\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.10728, lr:7.78e-03, fs:0.71628 (r=0.778,p=0.664),  time:15.318, tt:689.292\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.10649, lr:7.78e-03, fs:0.71963 (r=0.778,p=0.670),  time:15.354, tt:706.280\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.10586, lr:7.78e-03, fs:0.72300 (r=0.778,p=0.675),  time:15.346, tt:721.266\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.10541, lr:7.78e-03, fs:0.72558 (r=0.788,p=0.672),  time:15.341, tt:736.361\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.10503, lr:7.78e-03, fs:0.72642 (r=0.778,p=0.681),  time:15.331, tt:751.203\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.10440, lr:7.78e-03, fs:0.72300 (r=0.778,p=0.675),  time:15.317, tt:765.864\n",
      "Ep:50, loss:0.00008, loss_test:0.10360, lr:7.78e-03, fs:0.73239 (r=0.788,p=0.684),  time:15.304, tt:780.479\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.10278, lr:7.78e-03, fs:0.72986 (r=0.778,p=0.688),  time:15.314, tt:796.342\n",
      "Ep:52, loss:0.00008, loss_test:0.10216, lr:7.78e-03, fs:0.74528 (r=0.798,p=0.699),  time:15.307, tt:811.249\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.10177, lr:7.78e-03, fs:0.74178 (r=0.798,p=0.693),  time:15.295, tt:825.906\n",
      "Ep:54, loss:0.00007, loss_test:0.10139, lr:7.78e-03, fs:0.74528 (r=0.798,p=0.699),  time:15.291, tt:840.998\n",
      "Ep:55, loss:0.00007, loss_test:0.10096, lr:7.78e-03, fs:0.74882 (r=0.798,p=0.705),  time:15.304, tt:857.001\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.10044, lr:7.78e-03, fs:0.75238 (r=0.798,p=0.712),  time:15.301, tt:872.168\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.09986, lr:7.78e-03, fs:0.75238 (r=0.798,p=0.712),  time:15.299, tt:887.325\n",
      "Ep:58, loss:0.00007, loss_test:0.09931, lr:7.78e-03, fs:0.75598 (r=0.798,p=0.718),  time:15.299, tt:902.627\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00007, loss_test:0.09879, lr:7.78e-03, fs:0.75598 (r=0.798,p=0.718),  time:15.302, tt:918.136\n",
      "Ep:60, loss:0.00007, loss_test:0.09833, lr:7.78e-03, fs:0.75598 (r=0.798,p=0.718),  time:15.307, tt:933.719\n",
      "Ep:61, loss:0.00007, loss_test:0.09793, lr:7.78e-03, fs:0.75238 (r=0.798,p=0.712),  time:15.302, tt:948.723\n",
      "Ep:62, loss:0.00007, loss_test:0.09749, lr:7.78e-03, fs:0.75962 (r=0.798,p=0.725),  time:15.312, tt:964.634\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00007, loss_test:0.09703, lr:7.78e-03, fs:0.75962 (r=0.798,p=0.725),  time:15.325, tt:980.798\n",
      "Ep:64, loss:0.00007, loss_test:0.09666, lr:7.78e-03, fs:0.75962 (r=0.798,p=0.725),  time:15.336, tt:996.830\n",
      "Ep:65, loss:0.00007, loss_test:0.09624, lr:7.78e-03, fs:0.76555 (r=0.808,p=0.727),  time:15.337, tt:1012.262\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00007, loss_test:0.09575, lr:7.78e-03, fs:0.76555 (r=0.808,p=0.727),  time:15.336, tt:1027.502\n",
      "Ep:67, loss:0.00007, loss_test:0.09527, lr:7.78e-03, fs:0.76923 (r=0.808,p=0.734),  time:15.328, tt:1042.273\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.09491, lr:7.78e-03, fs:0.76923 (r=0.808,p=0.734),  time:15.345, tt:1058.823\n",
      "Ep:69, loss:0.00006, loss_test:0.09454, lr:7.78e-03, fs:0.77143 (r=0.818,p=0.730),  time:15.339, tt:1073.707\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.09415, lr:7.78e-03, fs:0.77143 (r=0.818,p=0.730),  time:15.334, tt:1088.742\n",
      "Ep:71, loss:0.00006, loss_test:0.09375, lr:7.78e-03, fs:0.77512 (r=0.818,p=0.736),  time:15.349, tt:1105.141\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00006, loss_test:0.09342, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.356, tt:1120.976\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00006, loss_test:0.09315, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.354, tt:1136.184\n",
      "Ep:74, loss:0.00006, loss_test:0.09295, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.354, tt:1151.573\n",
      "Ep:75, loss:0.00006, loss_test:0.09259, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.348, tt:1166.430\n",
      "Ep:76, loss:0.00006, loss_test:0.09235, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.347, tt:1181.745\n",
      "Ep:77, loss:0.00006, loss_test:0.09219, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.341, tt:1196.624\n",
      "Ep:78, loss:0.00006, loss_test:0.09178, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.335, tt:1211.448\n",
      "Ep:79, loss:0.00006, loss_test:0.09157, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.321, tt:1225.691\n",
      "Ep:80, loss:0.00006, loss_test:0.09142, lr:7.78e-03, fs:0.77885 (r=0.818,p=0.743),  time:15.310, tt:1240.138\n",
      "Ep:81, loss:0.00006, loss_test:0.09115, lr:7.78e-03, fs:0.78261 (r=0.818,p=0.750),  time:15.301, tt:1254.657\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00006, loss_test:0.09087, lr:7.78e-03, fs:0.78049 (r=0.808,p=0.755),  time:15.294, tt:1269.394\n",
      "Ep:83, loss:0.00006, loss_test:0.09064, lr:7.78e-03, fs:0.78049 (r=0.808,p=0.755),  time:15.284, tt:1283.872\n",
      "Ep:84, loss:0.00006, loss_test:0.09037, lr:7.78e-03, fs:0.79227 (r=0.828,p=0.759),  time:15.287, tt:1299.431\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00006, loss_test:0.09018, lr:7.78e-03, fs:0.79808 (r=0.838,p=0.761),  time:15.271, tt:1313.286\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00005, loss_test:0.08979, lr:7.78e-03, fs:0.80193 (r=0.838,p=0.769),  time:15.275, tt:1328.957\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00005, loss_test:0.08950, lr:7.78e-03, fs:0.80583 (r=0.838,p=0.776),  time:15.270, tt:1343.733\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00005, loss_test:0.08924, lr:7.78e-03, fs:0.80769 (r=0.848,p=0.771),  time:15.272, tt:1359.216\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00005, loss_test:0.08887, lr:7.78e-03, fs:0.80583 (r=0.838,p=0.776),  time:15.266, tt:1373.971\n",
      "Ep:90, loss:0.00005, loss_test:0.08868, lr:7.78e-03, fs:0.81159 (r=0.848,p=0.778),  time:15.273, tt:1389.858\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00005, loss_test:0.08852, lr:7.78e-03, fs:0.81340 (r=0.859,p=0.773),  time:15.281, tt:1405.818\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00005, loss_test:0.08816, lr:7.78e-03, fs:0.80392 (r=0.828,p=0.781),  time:15.292, tt:1422.157\n",
      "Ep:93, loss:0.00005, loss_test:0.08794, lr:7.78e-03, fs:0.80976 (r=0.838,p=0.783),  time:15.295, tt:1437.733\n",
      "Ep:94, loss:0.00005, loss_test:0.08779, lr:7.78e-03, fs:0.82126 (r=0.859,p=0.787),  time:15.291, tt:1452.600\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00005, loss_test:0.08741, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.284, tt:1467.280\n",
      "Ep:96, loss:0.00005, loss_test:0.08702, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.276, tt:1481.728\n",
      "Ep:97, loss:0.00005, loss_test:0.08680, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.272, tt:1496.697\n",
      "Ep:98, loss:0.00005, loss_test:0.08663, lr:7.78e-03, fs:0.81731 (r=0.859,p=0.780),  time:15.258, tt:1510.588\n",
      "Ep:99, loss:0.00005, loss_test:0.08624, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.262, tt:1526.187\n",
      "Ep:100, loss:0.00005, loss_test:0.08591, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.240, tt:1539.269\n",
      "Ep:101, loss:0.00005, loss_test:0.08573, lr:7.78e-03, fs:0.81553 (r=0.848,p=0.785),  time:15.236, tt:1554.029\n",
      "Ep:102, loss:0.00005, loss_test:0.08554, lr:7.78e-03, fs:0.81159 (r=0.848,p=0.778),  time:15.232, tt:1568.868\n",
      "Ep:103, loss:0.00005, loss_test:0.08540, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.232, tt:1584.127\n",
      "Ep:104, loss:0.00005, loss_test:0.08537, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.229, tt:1599.078\n",
      "Ep:105, loss:0.00005, loss_test:0.08523, lr:7.78e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.224, tt:1613.733\n",
      "Ep:106, loss:0.00004, loss_test:0.08499, lr:7.70e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.226, tt:1629.140\n",
      "Ep:107, loss:0.00004, loss_test:0.08489, lr:7.62e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.231, tt:1644.999\n",
      "Ep:108, loss:0.00004, loss_test:0.08479, lr:7.55e-03, fs:0.81553 (r=0.848,p=0.785),  time:15.227, tt:1659.757\n",
      "Ep:109, loss:0.00004, loss_test:0.08452, lr:7.47e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.231, tt:1675.400\n",
      "Ep:110, loss:0.00004, loss_test:0.08441, lr:7.40e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.232, tt:1690.771\n",
      "Ep:111, loss:0.00004, loss_test:0.08437, lr:7.32e-03, fs:0.81951 (r=0.848,p=0.792),  time:15.231, tt:1705.862\n",
      "Ep:112, loss:0.00004, loss_test:0.08423, lr:7.25e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.235, tt:1721.504\n",
      "Ep:113, loss:0.00004, loss_test:0.08395, lr:7.18e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.238, tt:1737.179\n",
      "Ep:114, loss:0.00004, loss_test:0.08368, lr:7.11e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.235, tt:1752.078\n",
      "Ep:115, loss:0.00004, loss_test:0.08365, lr:7.03e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.233, tt:1767.061\n",
      "Ep:116, loss:0.00004, loss_test:0.08354, lr:6.96e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.240, tt:1783.055\n",
      "Ep:117, loss:0.00004, loss_test:0.08343, lr:6.89e-03, fs:0.81773 (r=0.838,p=0.798),  time:15.241, tt:1798.395\n",
      "Ep:118, loss:0.00004, loss_test:0.08330, lr:6.83e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.242, tt:1813.762\n",
      "Ep:119, loss:0.00004, loss_test:0.08314, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:15.245, tt:1829.380\n",
      "Ep:120, loss:0.00004, loss_test:0.08289, lr:6.69e-03, fs:0.82178 (r=0.838,p=0.806),  time:15.238, tt:1843.831\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00004, loss_test:0.08277, lr:6.69e-03, fs:0.82178 (r=0.838,p=0.806),  time:15.232, tt:1858.272\n",
      "Ep:122, loss:0.00004, loss_test:0.08275, lr:6.69e-03, fs:0.81553 (r=0.848,p=0.785),  time:15.226, tt:1872.809\n",
      "Ep:123, loss:0.00004, loss_test:0.08250, lr:6.69e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.214, tt:1886.596\n",
      "Ep:124, loss:0.00004, loss_test:0.08224, lr:6.69e-03, fs:0.82000 (r=0.828,p=0.812),  time:15.216, tt:1901.954\n",
      "Ep:125, loss:0.00004, loss_test:0.08222, lr:6.69e-03, fs:0.82587 (r=0.838,p=0.814),  time:15.215, tt:1917.105\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00004, loss_test:0.08224, lr:6.69e-03, fs:0.82178 (r=0.838,p=0.806),  time:15.209, tt:1931.526\n",
      "Ep:127, loss:0.00004, loss_test:0.08203, lr:6.69e-03, fs:0.82000 (r=0.828,p=0.812),  time:15.203, tt:1945.969\n",
      "Ep:128, loss:0.00004, loss_test:0.08185, lr:6.69e-03, fs:0.82000 (r=0.828,p=0.812),  time:15.191, tt:1959.687\n",
      "Ep:129, loss:0.00004, loss_test:0.08170, lr:6.69e-03, fs:0.83168 (r=0.848,p=0.816),  time:15.186, tt:1974.207\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00004, loss_test:0.08146, lr:6.69e-03, fs:0.82587 (r=0.838,p=0.814),  time:15.183, tt:1989.028\n",
      "Ep:131, loss:0.00004, loss_test:0.08124, lr:6.69e-03, fs:0.82000 (r=0.828,p=0.812),  time:15.172, tt:2002.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00004, loss_test:0.08121, lr:6.69e-03, fs:0.82587 (r=0.838,p=0.814),  time:15.160, tt:2016.218\n",
      "Ep:133, loss:0.00004, loss_test:0.08111, lr:6.69e-03, fs:0.83744 (r=0.859,p=0.817),  time:15.153, tt:2030.489\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00004, loss_test:0.08084, lr:6.69e-03, fs:0.82000 (r=0.828,p=0.812),  time:15.144, tt:2044.399\n",
      "Ep:135, loss:0.00003, loss_test:0.08075, lr:6.69e-03, fs:0.82587 (r=0.838,p=0.814),  time:15.137, tt:2058.634\n",
      "Ep:136, loss:0.00003, loss_test:0.08087, lr:6.69e-03, fs:0.83744 (r=0.859,p=0.817),  time:15.131, tt:2072.928\n",
      "Ep:137, loss:0.00003, loss_test:0.08053, lr:6.69e-03, fs:0.83582 (r=0.848,p=0.824),  time:15.127, tt:2087.561\n",
      "Ep:138, loss:0.00003, loss_test:0.08040, lr:6.69e-03, fs:0.84000 (r=0.848,p=0.832),  time:15.129, tt:2102.905\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00003, loss_test:0.08046, lr:6.69e-03, fs:0.83333 (r=0.859,p=0.810),  time:15.122, tt:2117.110\n",
      "Ep:140, loss:0.00003, loss_test:0.08017, lr:6.69e-03, fs:0.83582 (r=0.848,p=0.824),  time:15.118, tt:2131.661\n",
      "Ep:141, loss:0.00003, loss_test:0.07989, lr:6.69e-03, fs:0.83582 (r=0.848,p=0.824),  time:15.120, tt:2147.059\n",
      "Ep:142, loss:0.00003, loss_test:0.07977, lr:6.69e-03, fs:0.84158 (r=0.859,p=0.825),  time:15.121, tt:2162.370\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00003, loss_test:0.07957, lr:6.69e-03, fs:0.84422 (r=0.848,p=0.840),  time:15.126, tt:2178.126\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00003, loss_test:0.07959, lr:6.69e-03, fs:0.84422 (r=0.848,p=0.840),  time:15.120, tt:2192.443\n",
      "Ep:145, loss:0.00003, loss_test:0.07955, lr:6.69e-03, fs:0.82759 (r=0.848,p=0.808),  time:15.108, tt:2205.747\n",
      "Ep:146, loss:0.00003, loss_test:0.07921, lr:6.69e-03, fs:0.84422 (r=0.848,p=0.840),  time:15.101, tt:2219.876\n",
      "Ep:147, loss:0.00003, loss_test:0.07917, lr:6.69e-03, fs:0.84422 (r=0.848,p=0.840),  time:15.106, tt:2235.691\n",
      "Ep:148, loss:0.00003, loss_test:0.07935, lr:6.69e-03, fs:0.83168 (r=0.848,p=0.816),  time:15.091, tt:2248.573\n",
      "Ep:149, loss:0.00003, loss_test:0.07898, lr:6.69e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.086, tt:2262.876\n",
      "Ep:150, loss:0.00003, loss_test:0.07888, lr:6.69e-03, fs:0.83249 (r=0.828,p=0.837),  time:15.074, tt:2276.100\n",
      "Ep:151, loss:0.00003, loss_test:0.07900, lr:6.69e-03, fs:0.83744 (r=0.859,p=0.817),  time:15.059, tt:2288.937\n",
      "Ep:152, loss:0.00003, loss_test:0.07876, lr:6.69e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.053, tt:2303.059\n",
      "Ep:153, loss:0.00003, loss_test:0.07875, lr:6.69e-03, fs:0.82234 (r=0.818,p=0.827),  time:15.039, tt:2316.056\n",
      "Ep:154, loss:0.00003, loss_test:0.07878, lr:6.69e-03, fs:0.83582 (r=0.848,p=0.824),  time:15.031, tt:2329.779\n",
      "Ep:155, loss:0.00003, loss_test:0.07843, lr:6.62e-03, fs:0.82653 (r=0.818,p=0.835),  time:15.017, tt:2342.677\n",
      "Ep:156, loss:0.00003, loss_test:0.07842, lr:6.56e-03, fs:0.82902 (r=0.808,p=0.851),  time:15.003, tt:2355.449\n",
      "Ep:157, loss:0.00003, loss_test:0.07851, lr:6.49e-03, fs:0.83249 (r=0.828,p=0.837),  time:14.997, tt:2369.488\n",
      "Ep:158, loss:0.00003, loss_test:0.07841, lr:6.43e-03, fs:0.82653 (r=0.818,p=0.835),  time:14.988, tt:2383.156\n",
      "Ep:159, loss:0.00003, loss_test:0.07825, lr:6.36e-03, fs:0.82902 (r=0.808,p=0.851),  time:14.977, tt:2396.347\n",
      "Ep:160, loss:0.00003, loss_test:0.07808, lr:6.30e-03, fs:0.82051 (r=0.808,p=0.833),  time:14.962, tt:2408.826\n",
      "Ep:161, loss:0.00003, loss_test:0.07807, lr:6.24e-03, fs:0.82828 (r=0.828,p=0.828),  time:14.938, tt:2419.948\n",
      "Ep:162, loss:0.00003, loss_test:0.07809, lr:6.17e-03, fs:0.82902 (r=0.808,p=0.851),  time:14.924, tt:2432.658\n",
      "Ep:163, loss:0.00003, loss_test:0.07803, lr:6.11e-03, fs:0.82902 (r=0.808,p=0.851),  time:14.903, tt:2444.077\n",
      "Ep:164, loss:0.00003, loss_test:0.07793, lr:6.05e-03, fs:0.83838 (r=0.838,p=0.838),  time:14.884, tt:2455.901\n",
      "Ep:165, loss:0.00003, loss_test:0.07763, lr:5.99e-03, fs:0.82653 (r=0.818,p=0.835),  time:14.879, tt:2469.855\n",
      "Ep:166, loss:0.00003, loss_test:0.07760, lr:5.93e-03, fs:0.82902 (r=0.808,p=0.851),  time:14.869, tt:2483.134\n",
      "Ep:167, loss:0.00003, loss_test:0.07749, lr:5.87e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.857, tt:2496.048\n",
      "Ep:168, loss:0.00003, loss_test:0.07750, lr:5.81e-03, fs:0.83838 (r=0.838,p=0.838),  time:14.842, tt:2508.359\n",
      "Ep:169, loss:0.00003, loss_test:0.07739, lr:5.75e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.828, tt:2520.701\n",
      "Ep:170, loss:0.00003, loss_test:0.07726, lr:5.70e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.821, tt:2534.451\n",
      "Ep:171, loss:0.00003, loss_test:0.07708, lr:5.64e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.802, tt:2545.987\n",
      "Ep:172, loss:0.00003, loss_test:0.07705, lr:5.58e-03, fs:0.82653 (r=0.818,p=0.835),  time:14.792, tt:2558.998\n",
      "Ep:173, loss:0.00003, loss_test:0.07705, lr:5.53e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.788, tt:2573.063\n",
      "Ep:174, loss:0.00003, loss_test:0.07694, lr:5.47e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.776, tt:2585.730\n",
      "Ep:175, loss:0.00003, loss_test:0.07673, lr:5.42e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.762, tt:2598.121\n",
      "Ep:176, loss:0.00002, loss_test:0.07647, lr:5.36e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.752, tt:2611.184\n",
      "Ep:177, loss:0.00002, loss_test:0.07635, lr:5.31e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.747, tt:2624.993\n",
      "Ep:178, loss:0.00002, loss_test:0.07630, lr:5.26e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.748, tt:2639.952\n",
      "Ep:179, loss:0.00002, loss_test:0.07633, lr:5.20e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.734, tt:2652.120\n",
      "Ep:180, loss:0.00002, loss_test:0.07633, lr:5.15e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.723, tt:2664.935\n",
      "Ep:181, loss:0.00002, loss_test:0.07623, lr:5.10e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.714, tt:2678.003\n",
      "Ep:182, loss:0.00002, loss_test:0.07613, lr:5.05e-03, fs:0.83077 (r=0.818,p=0.844),  time:14.712, tt:2692.333\n",
      "Ep:183, loss:0.00002, loss_test:0.07597, lr:5.00e-03, fs:0.83077 (r=0.818,p=0.844),  time:14.702, tt:2705.137\n",
      "Ep:184, loss:0.00002, loss_test:0.07598, lr:4.95e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.696, tt:2718.829\n",
      "Ep:185, loss:0.00002, loss_test:0.07602, lr:4.90e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.691, tt:2732.600\n",
      "Ep:186, loss:0.00002, loss_test:0.07602, lr:4.85e-03, fs:0.83249 (r=0.828,p=0.837),  time:14.686, tt:2746.291\n",
      "Ep:187, loss:0.00002, loss_test:0.07576, lr:4.80e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.679, tt:2759.562\n",
      "Ep:188, loss:0.00002, loss_test:0.07565, lr:4.75e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.669, tt:2772.420\n",
      "Ep:189, loss:0.00002, loss_test:0.07562, lr:4.71e-03, fs:0.82051 (r=0.808,p=0.833),  time:14.664, tt:2786.203\n",
      "Ep:190, loss:0.00002, loss_test:0.07569, lr:4.66e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.652, tt:2798.614\n",
      "Ep:191, loss:0.00002, loss_test:0.07562, lr:4.61e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.647, tt:2812.258\n",
      "Ep:192, loss:0.00002, loss_test:0.07547, lr:4.57e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.641, tt:2825.790\n",
      "Ep:193, loss:0.00002, loss_test:0.07542, lr:4.52e-03, fs:0.82051 (r=0.808,p=0.833),  time:14.638, tt:2839.852\n",
      "Ep:194, loss:0.00002, loss_test:0.07547, lr:4.48e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.637, tt:2854.311\n",
      "Ep:195, loss:0.00002, loss_test:0.07545, lr:4.43e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.636, tt:2868.729\n",
      "Ep:196, loss:0.00002, loss_test:0.07537, lr:4.39e-03, fs:0.82051 (r=0.808,p=0.833),  time:14.632, tt:2882.553\n",
      "Ep:197, loss:0.00002, loss_test:0.07532, lr:4.34e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.621, tt:2895.007\n",
      "Ep:198, loss:0.00002, loss_test:0.07523, lr:4.30e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.618, tt:2909.079\n",
      "Ep:199, loss:0.00002, loss_test:0.07516, lr:4.26e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.621, tt:2924.130\n",
      "Ep:200, loss:0.00002, loss_test:0.07521, lr:4.21e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.627, tt:2940.028\n",
      "Ep:201, loss:0.00002, loss_test:0.07521, lr:4.17e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.626, tt:2954.407\n",
      "Ep:202, loss:0.00002, loss_test:0.07513, lr:4.13e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.622, tt:2968.238\n",
      "Ep:203, loss:0.00002, loss_test:0.07505, lr:4.09e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.611, tt:2980.543\n",
      "Ep:204, loss:0.00002, loss_test:0.07498, lr:4.05e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.596, tt:2992.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00002, loss_test:0.07499, lr:4.01e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.575, tt:3002.442\n",
      "Ep:206, loss:0.00002, loss_test:0.07497, lr:3.97e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.543, tt:3010.429\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14230, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.551, tt:24.551\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14139, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.976, tt:55.952\n",
      "Ep:2, loss:0.00028, loss_test:0.13986, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.347, tt:88.040\n",
      "Ep:3, loss:0.00028, loss_test:0.13749, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.456, tt:121.823\n",
      "Ep:4, loss:0.00027, loss_test:0.13394, lr:1.00e-02, fs:0.66250 (r=0.981,p=0.500),  time:30.449, tt:152.247\n",
      "Ep:5, loss:0.00027, loss_test:0.12902, lr:1.00e-02, fs:0.69281 (r=0.981,p=0.535),  time:30.821, tt:184.926\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.12239, lr:1.00e-02, fs:0.66667 (r=0.870,p=0.540),  time:31.124, tt:217.868\n",
      "Ep:7, loss:0.00024, loss_test:0.11685, lr:1.00e-02, fs:0.65116 (r=0.778,p=0.560),  time:31.537, tt:252.299\n",
      "Ep:8, loss:0.00023, loss_test:0.11440, lr:1.00e-02, fs:0.63717 (r=0.667,p=0.610),  time:31.572, tt:284.150\n",
      "Ep:9, loss:0.00023, loss_test:0.11237, lr:1.00e-02, fs:0.66055 (r=0.667,p=0.655),  time:31.743, tt:317.430\n",
      "Ep:10, loss:0.00022, loss_test:0.10926, lr:1.00e-02, fs:0.68376 (r=0.741,p=0.635),  time:31.801, tt:349.809\n",
      "Ep:11, loss:0.00021, loss_test:0.10642, lr:1.00e-02, fs:0.66667 (r=0.741,p=0.606),  time:31.845, tt:382.136\n",
      "Ep:12, loss:0.00021, loss_test:0.10181, lr:1.00e-02, fs:0.70175 (r=0.741,p=0.667),  time:31.981, tt:415.756\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09948, lr:1.00e-02, fs:0.72727 (r=0.741,p=0.714),  time:32.113, tt:449.586\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09523, lr:1.00e-02, fs:0.72072 (r=0.741,p=0.702),  time:32.112, tt:481.681\n",
      "Ep:15, loss:0.00019, loss_test:0.09248, lr:1.00e-02, fs:0.74783 (r=0.796,p=0.705),  time:32.169, tt:514.701\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09085, lr:1.00e-02, fs:0.78261 (r=0.833,p=0.738),  time:32.198, tt:547.370\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.08846, lr:1.00e-02, fs:0.78261 (r=0.833,p=0.738),  time:32.045, tt:576.812\n",
      "Ep:18, loss:0.00017, loss_test:0.08596, lr:1.00e-02, fs:0.79661 (r=0.870,p=0.734),  time:32.053, tt:609.003\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08422, lr:1.00e-02, fs:0.79661 (r=0.870,p=0.734),  time:32.057, tt:641.144\n",
      "Ep:20, loss:0.00016, loss_test:0.08343, lr:1.00e-02, fs:0.80000 (r=0.852,p=0.754),  time:32.110, tt:674.312\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08118, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:32.095, tt:706.097\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07983, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:32.046, tt:737.047\n",
      "Ep:23, loss:0.00015, loss_test:0.07918, lr:1.00e-02, fs:0.81034 (r=0.870,p=0.758),  time:32.079, tt:769.905\n",
      "Ep:24, loss:0.00015, loss_test:0.07696, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:32.098, tt:802.456\n",
      "Ep:25, loss:0.00014, loss_test:0.07549, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:32.096, tt:834.503\n",
      "Ep:26, loss:0.00014, loss_test:0.07447, lr:1.00e-02, fs:0.81034 (r=0.870,p=0.758),  time:32.087, tt:866.336\n",
      "Ep:27, loss:0.00014, loss_test:0.07324, lr:1.00e-02, fs:0.82051 (r=0.889,p=0.762),  time:32.061, tt:897.719\n",
      "Ep:28, loss:0.00013, loss_test:0.07189, lr:1.00e-02, fs:0.82759 (r=0.889,p=0.774),  time:32.061, tt:929.783\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07081, lr:1.00e-02, fs:0.83478 (r=0.889,p=0.787),  time:32.073, tt:962.184\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.06929, lr:1.00e-02, fs:0.83761 (r=0.907,p=0.778),  time:32.082, tt:994.537\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.06867, lr:1.00e-02, fs:0.83478 (r=0.889,p=0.787),  time:32.081, tt:1026.591\n",
      "Ep:32, loss:0.00012, loss_test:0.06723, lr:1.00e-02, fs:0.83761 (r=0.907,p=0.778),  time:32.133, tt:1060.377\n",
      "Ep:33, loss:0.00012, loss_test:0.06603, lr:1.00e-02, fs:0.83761 (r=0.907,p=0.778),  time:32.106, tt:1091.605\n",
      "Ep:34, loss:0.00012, loss_test:0.06543, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:32.108, tt:1123.784\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.06384, lr:1.00e-02, fs:0.86667 (r=0.963,p=0.788),  time:32.093, tt:1155.332\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.06289, lr:1.00e-02, fs:0.87179 (r=0.944,p=0.810),  time:32.110, tt:1188.053\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.06167, lr:1.00e-02, fs:0.88889 (r=0.963,p=0.825),  time:32.126, tt:1220.791\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.06075, lr:1.00e-02, fs:0.88136 (r=0.963,p=0.812),  time:32.146, tt:1253.696\n",
      "Ep:39, loss:0.00010, loss_test:0.05970, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.181, tt:1287.220\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.05831, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.179, tt:1319.332\n",
      "Ep:41, loss:0.00010, loss_test:0.05741, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.156, tt:1350.572\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.05632, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.172, tt:1383.408\n",
      "Ep:43, loss:0.00009, loss_test:0.05566, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.162, tt:1415.147\n",
      "Ep:44, loss:0.00009, loss_test:0.05442, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.179, tt:1448.036\n",
      "Ep:45, loss:0.00009, loss_test:0.05338, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.167, tt:1479.685\n",
      "Ep:46, loss:0.00009, loss_test:0.05267, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.190, tt:1512.953\n",
      "Ep:47, loss:0.00009, loss_test:0.05229, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.195, tt:1545.352\n",
      "Ep:48, loss:0.00008, loss_test:0.05158, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.197, tt:1577.654\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.05048, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.215, tt:1610.761\n",
      "Ep:50, loss:0.00008, loss_test:0.04997, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.220, tt:1643.227\n",
      "Ep:51, loss:0.00008, loss_test:0.04909, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.215, tt:1675.155\n",
      "Ep:52, loss:0.00008, loss_test:0.04811, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.209, tt:1707.081\n",
      "Ep:53, loss:0.00008, loss_test:0.04771, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.199, tt:1738.741\n",
      "Ep:54, loss:0.00007, loss_test:0.04728, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.200, tt:1770.995\n",
      "Ep:55, loss:0.00007, loss_test:0.04567, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.190, tt:1802.629\n",
      "Ep:56, loss:0.00007, loss_test:0.04617, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.206, tt:1835.759\n",
      "Ep:57, loss:0.00007, loss_test:0.04509, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.182, tt:1866.568\n",
      "Ep:58, loss:0.00007, loss_test:0.04406, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.182, tt:1898.750\n",
      "Ep:59, loss:0.00007, loss_test:0.04452, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.206, tt:1932.334\n",
      "Ep:60, loss:0.00007, loss_test:0.04300, lr:9.90e-03, fs:0.90435 (r=0.963,p=0.852),  time:32.217, tt:1965.213\n",
      "Ep:61, loss:0.00006, loss_test:0.04265, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:32.219, tt:1997.568\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00006, loss_test:0.04191, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:32.231, tt:2030.547\n",
      "Ep:63, loss:0.00006, loss_test:0.04130, lr:9.80e-03, fs:0.91228 (r=0.963,p=0.867),  time:32.199, tt:2060.706\n",
      "Ep:64, loss:0.00006, loss_test:0.04207, lr:9.80e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.210, tt:2093.645\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.04041, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:32.205, tt:2125.539\n",
      "Ep:66, loss:0.00006, loss_test:0.04059, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:32.206, tt:2157.834\n",
      "Ep:67, loss:0.00006, loss_test:0.03946, lr:9.80e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.212, tt:2190.386\n",
      "Ep:68, loss:0.00006, loss_test:0.03966, lr:9.80e-03, fs:0.91228 (r=0.963,p=0.867),  time:32.212, tt:2222.613\n",
      "Ep:69, loss:0.00006, loss_test:0.03845, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.198, tt:2253.876\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.03879, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:32.186, tt:2285.192\n",
      "Ep:71, loss:0.00005, loss_test:0.03737, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.179, tt:2316.855\n",
      "Ep:72, loss:0.00005, loss_test:0.03812, lr:9.80e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.174, tt:2348.678\n",
      "Ep:73, loss:0.00005, loss_test:0.03699, lr:9.80e-03, fs:0.92035 (r=0.963,p=0.881),  time:32.179, tt:2381.219\n",
      "Ep:74, loss:0.00005, loss_test:0.03608, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.178, tt:2413.380\n",
      "Ep:75, loss:0.00005, loss_test:0.03621, lr:9.80e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.183, tt:2445.918\n",
      "Ep:76, loss:0.00005, loss_test:0.03547, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.184, tt:2478.205\n",
      "Ep:77, loss:0.00005, loss_test:0.03510, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.182, tt:2510.213\n",
      "Ep:78, loss:0.00005, loss_test:0.03448, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.183, tt:2542.452\n",
      "Ep:79, loss:0.00005, loss_test:0.03489, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.192, tt:2575.391\n",
      "Ep:80, loss:0.00005, loss_test:0.03357, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.203, tt:2608.406\n",
      "Ep:81, loss:0.00004, loss_test:0.03409, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.207, tt:2640.941\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00004, loss_test:0.03282, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.223, tt:2674.513\n",
      "Ep:83, loss:0.00004, loss_test:0.03339, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.236, tt:2707.809\n",
      "Ep:84, loss:0.00004, loss_test:0.03209, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.227, tt:2739.289\n",
      "Ep:85, loss:0.00004, loss_test:0.03193, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.230, tt:2771.790\n",
      "Ep:86, loss:0.00004, loss_test:0.03162, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.257, tt:2806.325\n",
      "Ep:87, loss:0.00004, loss_test:0.03140, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.278, tt:2840.496\n",
      "Ep:88, loss:0.00004, loss_test:0.03088, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.290, tt:2873.794\n",
      "Ep:89, loss:0.00004, loss_test:0.03060, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.285, tt:2905.665\n",
      "Ep:90, loss:0.00004, loss_test:0.03008, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.281, tt:2937.572\n",
      "Ep:91, loss:0.00004, loss_test:0.02980, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.296, tt:2971.192\n",
      "Ep:92, loss:0.00004, loss_test:0.03013, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.314, tt:3005.203\n",
      "Ep:93, loss:0.00004, loss_test:0.02888, lr:9.61e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.323, tt:3038.389\n",
      "Ep:94, loss:0.00004, loss_test:0.02955, lr:9.51e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.339, tt:3072.248\n",
      "Ep:95, loss:0.00003, loss_test:0.02851, lr:9.41e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.351, tt:3105.698\n",
      "Ep:96, loss:0.00003, loss_test:0.02841, lr:9.32e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.404, tt:3143.154\n",
      "Ep:97, loss:0.00003, loss_test:0.02801, lr:9.23e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.417, tt:3176.862\n",
      "Ep:98, loss:0.00003, loss_test:0.02794, lr:9.14e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.433, tt:3210.849\n",
      "Ep:99, loss:0.00003, loss_test:0.02734, lr:9.04e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.452, tt:3245.208\n",
      "Ep:100, loss:0.00003, loss_test:0.02715, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.465, tt:3278.966\n",
      "Ep:101, loss:0.00003, loss_test:0.02693, lr:8.86e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.479, tt:3312.898\n",
      "Ep:102, loss:0.00003, loss_test:0.02672, lr:8.78e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.502, tt:3347.746\n",
      "Ep:103, loss:0.00003, loss_test:0.02638, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.513, tt:3381.305\n",
      "Ep:104, loss:0.00003, loss_test:0.02641, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.510, tt:3413.499\n",
      "Ep:105, loss:0.00003, loss_test:0.02618, lr:8.51e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.509, tt:3445.914\n",
      "Ep:106, loss:0.00003, loss_test:0.02600, lr:8.43e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.516, tt:3479.185\n",
      "Ep:107, loss:0.00003, loss_test:0.02614, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.526, tt:3512.784\n",
      "Ep:108, loss:0.00003, loss_test:0.02533, lr:8.26e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.509, tt:3543.447\n",
      "Ep:109, loss:0.00003, loss_test:0.02544, lr:8.18e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.510, tt:3576.062\n",
      "Ep:110, loss:0.00003, loss_test:0.02507, lr:8.10e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.492, tt:3606.594\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00003, loss_test:0.02501, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.495, tt:3639.465\n",
      "Ep:112, loss:0.00003, loss_test:0.02446, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.492, tt:3671.644\n",
      "Ep:113, loss:0.00003, loss_test:0.02445, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.490, tt:3703.852\n",
      "Ep:114, loss:0.00003, loss_test:0.02425, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.494, tt:3736.862\n",
      "Ep:115, loss:0.00002, loss_test:0.02398, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.489, tt:3768.667\n",
      "Ep:116, loss:0.00002, loss_test:0.02396, lr:8.10e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.495, tt:3801.887\n",
      "Ep:117, loss:0.00002, loss_test:0.02374, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.487, tt:3833.489\n",
      "Ep:118, loss:0.00002, loss_test:0.02330, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.486, tt:3865.787\n",
      "Ep:119, loss:0.00002, loss_test:0.02325, lr:8.10e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.487, tt:3898.414\n",
      "Ep:120, loss:0.00002, loss_test:0.02314, lr:8.10e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.475, tt:3929.486\n",
      "Ep:121, loss:0.00002, loss_test:0.02300, lr:8.10e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.464, tt:3960.582\n",
      "Ep:122, loss:0.00002, loss_test:0.02325, lr:8.02e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.463, tt:3993.010\n",
      "Ep:123, loss:0.00002, loss_test:0.02266, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.449, tt:4023.656\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.02228, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.443, tt:4055.378\n",
      "Ep:125, loss:0.00002, loss_test:0.02263, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.457, tt:4089.633\n",
      "Ep:126, loss:0.00002, loss_test:0.02187, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.454, tt:4121.613\n",
      "Ep:127, loss:0.00002, loss_test:0.02207, lr:7.94e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.450, tt:4153.607\n",
      "Ep:128, loss:0.00002, loss_test:0.02199, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.436, tt:4184.294\n",
      "Ep:129, loss:0.00002, loss_test:0.02158, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.436, tt:4216.708\n",
      "Ep:130, loss:0.00002, loss_test:0.02161, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.437, tt:4249.279\n",
      "Ep:131, loss:0.00002, loss_test:0.02181, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.431, tt:4280.908\n",
      "Ep:132, loss:0.00002, loss_test:0.02124, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.429, tt:4313.042\n",
      "Ep:133, loss:0.00002, loss_test:0.02139, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.415, tt:4343.566\n",
      "Ep:134, loss:0.00002, loss_test:0.02082, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.401, tt:4374.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00002, loss_test:0.02072, lr:7.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.399, tt:4406.295\n",
      "Ep:136, loss:0.00002, loss_test:0.02061, lr:7.78e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.403, tt:4439.242\n",
      "Ep:137, loss:0.00002, loss_test:0.02018, lr:7.70e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.408, tt:4472.269\n",
      "Ep:138, loss:0.00002, loss_test:0.02022, lr:7.62e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.414, tt:4505.580\n",
      "Ep:139, loss:0.00002, loss_test:0.02030, lr:7.55e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.417, tt:4538.386\n",
      "Ep:140, loss:0.00002, loss_test:0.01995, lr:7.47e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.412, tt:4570.029\n",
      "Ep:141, loss:0.00002, loss_test:0.01999, lr:7.40e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.409, tt:4602.116\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00002, loss_test:0.02004, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.413, tt:4635.058\n",
      "Ep:143, loss:0.00002, loss_test:0.01990, lr:7.40e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.422, tt:4668.798\n",
      "Ep:144, loss:0.00002, loss_test:0.01955, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.408, tt:4699.165\n",
      "Ep:145, loss:0.00002, loss_test:0.01949, lr:7.40e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.400, tt:4730.452\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00002, loss_test:0.01923, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.403, tt:4763.199\n",
      "Ep:147, loss:0.00002, loss_test:0.01920, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.402, tt:4795.433\n",
      "Ep:148, loss:0.00002, loss_test:0.01939, lr:7.40e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.402, tt:4827.849\n",
      "Ep:149, loss:0.00001, loss_test:0.01874, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.398, tt:4859.664\n",
      "Ep:150, loss:0.00001, loss_test:0.01914, lr:7.40e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.394, tt:4891.459\n",
      "Ep:151, loss:0.00001, loss_test:0.01865, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.388, tt:4922.971\n",
      "Ep:152, loss:0.00001, loss_test:0.01856, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.389, tt:4955.466\n",
      "Ep:153, loss:0.00001, loss_test:0.01860, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.396, tt:4988.909\n",
      "Ep:154, loss:0.00001, loss_test:0.01832, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.404, tt:5022.616\n",
      "Ep:155, loss:0.00001, loss_test:0.01850, lr:7.40e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.401, tt:5054.543\n",
      "Ep:156, loss:0.00001, loss_test:0.01811, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.403, tt:5087.194\n",
      "Ep:157, loss:0.00001, loss_test:0.01809, lr:7.32e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.396, tt:5118.517\n",
      "Ep:158, loss:0.00001, loss_test:0.01787, lr:7.25e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.424, tt:5155.385\n",
      "Ep:159, loss:0.00001, loss_test:0.01757, lr:7.18e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.424, tt:5187.906\n",
      "Ep:160, loss:0.00001, loss_test:0.01798, lr:7.11e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.420, tt:5219.576\n",
      "Ep:161, loss:0.00001, loss_test:0.01751, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.419, tt:5251.844\n",
      "Ep:162, loss:0.00001, loss_test:0.01751, lr:6.96e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.422, tt:5284.774\n",
      "Ep:163, loss:0.00001, loss_test:0.01709, lr:6.89e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.416, tt:5316.142\n",
      "Ep:164, loss:0.00001, loss_test:0.01776, lr:6.83e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.418, tt:5348.945\n",
      "Ep:165, loss:0.00001, loss_test:0.01699, lr:6.76e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.425, tt:5382.597\n",
      "Ep:166, loss:0.00001, loss_test:0.01680, lr:6.69e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.429, tt:5415.636\n",
      "Ep:167, loss:0.00001, loss_test:0.01764, lr:6.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.422, tt:5446.827\n",
      "Ep:168, loss:0.00001, loss_test:0.01659, lr:6.56e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.425, tt:5479.814\n",
      "Ep:169, loss:0.00001, loss_test:0.01718, lr:6.49e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.422, tt:5511.785\n",
      "Ep:170, loss:0.00001, loss_test:0.01690, lr:6.43e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.430, tt:5545.450\n",
      "Ep:171, loss:0.00001, loss_test:0.01683, lr:6.36e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.434, tt:5578.646\n",
      "Ep:172, loss:0.00001, loss_test:0.01627, lr:6.30e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.437, tt:5611.613\n",
      "Ep:173, loss:0.00001, loss_test:0.01719, lr:6.24e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.448, tt:5646.036\n",
      "Ep:174, loss:0.00001, loss_test:0.01606, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.454, tt:5679.369\n",
      "Ep:175, loss:0.00001, loss_test:0.01608, lr:6.11e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.451, tt:5711.393\n",
      "Ep:176, loss:0.00001, loss_test:0.01666, lr:6.05e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.458, tt:5744.996\n",
      "Ep:177, loss:0.00001, loss_test:0.01593, lr:5.99e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.467, tt:5779.179\n",
      "Ep:178, loss:0.00001, loss_test:0.01647, lr:5.93e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.472, tt:5812.404\n",
      "Ep:179, loss:0.00001, loss_test:0.01594, lr:5.87e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.473, tt:5845.175\n",
      "Ep:180, loss:0.00001, loss_test:0.01623, lr:5.81e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.472, tt:5877.350\n",
      "Ep:181, loss:0.00001, loss_test:0.01566, lr:5.75e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.481, tt:5911.550\n",
      "Ep:182, loss:0.00001, loss_test:0.01581, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.487, tt:5945.051\n",
      "Ep:183, loss:0.00001, loss_test:0.01608, lr:5.64e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.487, tt:5977.529\n",
      "Ep:184, loss:0.00001, loss_test:0.01532, lr:5.58e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.488, tt:6010.347\n",
      "##########Best model found so far##########\n",
      "Ep:185, loss:0.00001, loss_test:0.01600, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.482, tt:6041.663\n",
      "Ep:186, loss:0.00001, loss_test:0.01547, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.471, tt:6072.000\n",
      "Ep:187, loss:0.00001, loss_test:0.01554, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.475, tt:6105.387\n",
      "Ep:188, loss:0.00001, loss_test:0.01582, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.475, tt:6137.841\n",
      "Ep:189, loss:0.00001, loss_test:0.01532, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.477, tt:6170.625\n",
      "Ep:190, loss:0.00001, loss_test:0.01553, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.477, tt:6203.194\n",
      "Ep:191, loss:0.00001, loss_test:0.01532, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.479, tt:6235.881\n",
      "Ep:192, loss:0.00001, loss_test:0.01518, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.487, tt:6269.924\n",
      "Ep:193, loss:0.00001, loss_test:0.01522, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.498, tt:6304.547\n",
      "Ep:194, loss:0.00001, loss_test:0.01513, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.495, tt:6336.522\n",
      "Ep:195, loss:0.00001, loss_test:0.01507, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.492, tt:6368.441\n",
      "Ep:196, loss:0.00001, loss_test:0.01523, lr:5.53e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.496, tt:6401.664\n",
      "Ep:197, loss:0.00001, loss_test:0.01493, lr:5.47e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.496, tt:6434.283\n",
      "Ep:198, loss:0.00001, loss_test:0.01497, lr:5.42e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.497, tt:6466.846\n",
      "Ep:199, loss:0.00001, loss_test:0.01472, lr:5.36e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.500, tt:6500.061\n",
      "Ep:200, loss:0.00001, loss_test:0.01475, lr:5.31e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.505, tt:6533.479\n",
      "Ep:201, loss:0.00001, loss_test:0.01472, lr:5.26e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.506, tt:6566.158\n",
      "Ep:202, loss:0.00001, loss_test:0.01491, lr:5.20e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.509, tt:6599.327\n",
      "Ep:203, loss:0.00001, loss_test:0.01471, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.509, tt:6631.735\n",
      "Ep:204, loss:0.00001, loss_test:0.01469, lr:5.10e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.511, tt:6664.822\n",
      "Ep:205, loss:0.00001, loss_test:0.01461, lr:5.05e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.522, tt:6699.513\n",
      "Ep:206, loss:0.00001, loss_test:0.01440, lr:5.00e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.495, tt:6726.548\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14153, lr:1.00e-02, fs:0.67081 (r=1.000,p=0.505),  time:32.011, tt:32.011\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13986, lr:1.00e-02, fs:0.67089 (r=0.981,p=0.510),  time:34.119, tt:68.238\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13698, lr:1.00e-02, fs:0.68387 (r=0.981,p=0.525),  time:34.716, tt:104.147\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13356, lr:1.00e-02, fs:0.67532 (r=0.963,p=0.520),  time:35.091, tt:140.362\n",
      "Ep:4, loss:0.00026, loss_test:0.13092, lr:1.00e-02, fs:0.66216 (r=0.907,p=0.521),  time:35.027, tt:175.133\n",
      "Ep:5, loss:0.00026, loss_test:0.12836, lr:1.00e-02, fs:0.66197 (r=0.870,p=0.534),  time:35.343, tt:212.060\n",
      "Ep:6, loss:0.00025, loss_test:0.12648, lr:1.00e-02, fs:0.66667 (r=0.870,p=0.540),  time:35.291, tt:247.039\n",
      "Ep:7, loss:0.00025, loss_test:0.12426, lr:1.00e-02, fs:0.64234 (r=0.815,p=0.530),  time:35.520, tt:284.163\n",
      "Ep:8, loss:0.00024, loss_test:0.12141, lr:1.00e-02, fs:0.66176 (r=0.833,p=0.549),  time:35.496, tt:319.462\n",
      "Ep:9, loss:0.00023, loss_test:0.11832, lr:1.00e-02, fs:0.65672 (r=0.815,p=0.550),  time:35.561, tt:355.613\n",
      "Ep:10, loss:0.00023, loss_test:0.11576, lr:1.00e-02, fs:0.64567 (r=0.759,p=0.562),  time:35.661, tt:392.276\n",
      "Ep:11, loss:0.00022, loss_test:0.11389, lr:1.00e-02, fs:0.68254 (r=0.796,p=0.597),  time:35.709, tt:428.508\n",
      "Ep:12, loss:0.00022, loss_test:0.11167, lr:1.00e-02, fs:0.69841 (r=0.815,p=0.611),  time:35.724, tt:464.415\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10899, lr:1.00e-02, fs:0.70492 (r=0.796,p=0.632),  time:35.729, tt:500.211\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10608, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:35.847, tt:537.702\n",
      "Ep:15, loss:0.00020, loss_test:0.10265, lr:1.00e-02, fs:0.69492 (r=0.759,p=0.641),  time:35.768, tt:572.285\n",
      "Ep:16, loss:0.00019, loss_test:0.09950, lr:1.00e-02, fs:0.70085 (r=0.759,p=0.651),  time:35.780, tt:608.261\n",
      "Ep:17, loss:0.00019, loss_test:0.09566, lr:1.00e-02, fs:0.71304 (r=0.759,p=0.672),  time:35.822, tt:644.792\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09260, lr:1.00e-02, fs:0.73504 (r=0.796,p=0.683),  time:35.805, tt:680.299\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.08966, lr:1.00e-02, fs:0.75214 (r=0.815,p=0.698),  time:35.838, tt:716.751\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08760, lr:1.00e-02, fs:0.75630 (r=0.833,p=0.692),  time:35.895, tt:753.801\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.08598, lr:1.00e-02, fs:0.77311 (r=0.852,p=0.708),  time:35.921, tt:790.256\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.08434, lr:1.00e-02, fs:0.78333 (r=0.870,p=0.712),  time:35.968, tt:827.268\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08283, lr:1.00e-02, fs:0.77311 (r=0.852,p=0.708),  time:35.972, tt:863.328\n",
      "Ep:24, loss:0.00015, loss_test:0.08171, lr:1.00e-02, fs:0.78632 (r=0.852,p=0.730),  time:36.040, tt:901.000\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08050, lr:1.00e-02, fs:0.80672 (r=0.889,p=0.738),  time:36.057, tt:937.487\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.07853, lr:1.00e-02, fs:0.79661 (r=0.870,p=0.734),  time:36.136, tt:975.678\n",
      "Ep:27, loss:0.00014, loss_test:0.07681, lr:1.00e-02, fs:0.78632 (r=0.852,p=0.730),  time:36.140, tt:1011.913\n",
      "Ep:28, loss:0.00013, loss_test:0.07520, lr:1.00e-02, fs:0.79661 (r=0.870,p=0.734),  time:36.203, tt:1049.896\n",
      "Ep:29, loss:0.00013, loss_test:0.07286, lr:1.00e-02, fs:0.81356 (r=0.889,p=0.750),  time:36.261, tt:1087.842\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.07111, lr:1.00e-02, fs:0.81356 (r=0.889,p=0.750),  time:36.250, tt:1123.750\n",
      "Ep:31, loss:0.00012, loss_test:0.07020, lr:1.00e-02, fs:0.81667 (r=0.907,p=0.742),  time:36.257, tt:1160.221\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.06788, lr:1.00e-02, fs:0.82353 (r=0.907,p=0.754),  time:36.322, tt:1198.630\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06660, lr:1.00e-02, fs:0.83333 (r=0.926,p=0.758),  time:36.321, tt:1234.922\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.06526, lr:1.00e-02, fs:0.83333 (r=0.926,p=0.758),  time:36.328, tt:1271.487\n",
      "Ep:35, loss:0.00011, loss_test:0.06340, lr:1.00e-02, fs:0.83333 (r=0.926,p=0.758),  time:36.279, tt:1306.050\n",
      "Ep:36, loss:0.00011, loss_test:0.06301, lr:1.00e-02, fs:0.83333 (r=0.926,p=0.758),  time:36.307, tt:1343.369\n",
      "Ep:37, loss:0.00010, loss_test:0.06099, lr:1.00e-02, fs:0.84034 (r=0.926,p=0.769),  time:36.312, tt:1379.844\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.06032, lr:1.00e-02, fs:0.85000 (r=0.944,p=0.773),  time:36.318, tt:1416.411\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.05929, lr:1.00e-02, fs:0.85000 (r=0.944,p=0.773),  time:36.316, tt:1452.624\n",
      "Ep:40, loss:0.00009, loss_test:0.05732, lr:1.00e-02, fs:0.85714 (r=0.944,p=0.785),  time:36.345, tt:1490.148\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.05709, lr:1.00e-02, fs:0.85000 (r=0.944,p=0.773),  time:36.363, tt:1527.260\n",
      "Ep:42, loss:0.00009, loss_test:0.05680, lr:1.00e-02, fs:0.85950 (r=0.963,p=0.776),  time:36.393, tt:1564.899\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.05443, lr:1.00e-02, fs:0.86667 (r=0.963,p=0.788),  time:36.409, tt:1601.975\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.05409, lr:1.00e-02, fs:0.87395 (r=0.963,p=0.800),  time:36.460, tt:1640.701\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.05220, lr:1.00e-02, fs:0.88136 (r=0.963,p=0.812),  time:36.419, tt:1675.261\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.05170, lr:1.00e-02, fs:0.87179 (r=0.944,p=0.810),  time:36.376, tt:1709.662\n",
      "Ep:47, loss:0.00007, loss_test:0.05082, lr:1.00e-02, fs:0.87179 (r=0.944,p=0.810),  time:36.397, tt:1747.045\n",
      "Ep:48, loss:0.00007, loss_test:0.04973, lr:1.00e-02, fs:0.87395 (r=0.963,p=0.800),  time:36.402, tt:1783.707\n",
      "Ep:49, loss:0.00007, loss_test:0.04993, lr:1.00e-02, fs:0.87395 (r=0.963,p=0.800),  time:36.389, tt:1819.471\n",
      "Ep:50, loss:0.00007, loss_test:0.04861, lr:1.00e-02, fs:0.87179 (r=0.944,p=0.810),  time:36.365, tt:1854.630\n",
      "Ep:51, loss:0.00007, loss_test:0.04753, lr:1.00e-02, fs:0.88136 (r=0.963,p=0.812),  time:36.378, tt:1891.662\n",
      "Ep:52, loss:0.00006, loss_test:0.04580, lr:1.00e-02, fs:0.88889 (r=0.963,p=0.825),  time:36.378, tt:1928.026\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.04598, lr:1.00e-02, fs:0.88136 (r=0.963,p=0.812),  time:36.402, tt:1965.693\n",
      "Ep:54, loss:0.00006, loss_test:0.05044, lr:1.00e-02, fs:0.87179 (r=0.944,p=0.810),  time:36.408, tt:2002.427\n",
      "Ep:55, loss:0.00008, loss_test:0.04510, lr:1.00e-02, fs:0.88889 (r=0.963,p=0.825),  time:36.430, tt:2040.084\n",
      "Ep:56, loss:0.00007, loss_test:0.04850, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:36.417, tt:2075.764\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.04765, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:36.495, tt:2189.713\n",
      "Ep:60, loss:0.00006, loss_test:0.04756, lr:1.00e-02, fs:0.88889 (r=0.963,p=0.825),  time:36.521, tt:2227.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.04500, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:36.537, tt:2265.267\n",
      "Ep:62, loss:0.00006, loss_test:0.04292, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:36.569, tt:2303.871\n",
      "Ep:63, loss:0.00005, loss_test:0.04093, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:36.585, tt:2341.467\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.04021, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.586, tt:2378.065\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.04142, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:36.595, tt:2415.278\n",
      "Ep:66, loss:0.00005, loss_test:0.03954, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:36.563, tt:2449.745\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.03862, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:36.546, tt:2485.116\n",
      "Ep:68, loss:0.00004, loss_test:0.03834, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.536, tt:2521.011\n",
      "Ep:69, loss:0.00004, loss_test:0.03504, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:36.542, tt:2557.961\n",
      "Ep:70, loss:0.00004, loss_test:0.03704, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:36.519, tt:2592.873\n",
      "Ep:71, loss:0.00004, loss_test:0.03434, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.514, tt:2629.005\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00004, loss_test:0.03473, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:36.484, tt:2663.344\n",
      "Ep:73, loss:0.00004, loss_test:0.03462, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.487, tt:2700.046\n",
      "Ep:74, loss:0.00004, loss_test:0.03476, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.486, tt:2736.469\n",
      "Ep:75, loss:0.00004, loss_test:0.03608, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:36.474, tt:2772.015\n",
      "Ep:76, loss:0.00004, loss_test:0.03251, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.476, tt:2808.675\n",
      "Ep:77, loss:0.00003, loss_test:0.03504, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:36.472, tt:2844.780\n",
      "Ep:78, loss:0.00003, loss_test:0.02967, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.477, tt:2881.690\n",
      "Ep:79, loss:0.00003, loss_test:0.03156, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.481, tt:2918.451\n",
      "Ep:80, loss:0.00003, loss_test:0.03034, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.485, tt:2955.258\n",
      "Ep:81, loss:0.00003, loss_test:0.03031, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.508, tt:2993.694\n",
      "Ep:82, loss:0.00003, loss_test:0.02923, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.513, tt:3030.580\n",
      "Ep:83, loss:0.00003, loss_test:0.03015, lr:9.90e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.490, tt:3065.147\n",
      "Ep:84, loss:0.00003, loss_test:0.02960, lr:9.80e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.495, tt:3102.079\n",
      "Ep:85, loss:0.00003, loss_test:0.02772, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.526, tt:3141.246\n",
      "Ep:86, loss:0.00003, loss_test:0.03053, lr:9.61e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.533, tt:3178.366\n",
      "Ep:87, loss:0.00003, loss_test:0.02810, lr:9.51e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.550, tt:3216.381\n",
      "Ep:88, loss:0.00003, loss_test:0.02742, lr:9.41e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.561, tt:3253.969\n",
      "Ep:89, loss:0.00003, loss_test:0.03031, lr:9.32e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.582, tt:3292.364\n",
      "Ep:90, loss:0.00003, loss_test:0.02618, lr:9.23e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.581, tt:3328.871\n",
      "Ep:91, loss:0.00002, loss_test:0.02944, lr:9.14e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.590, tt:3366.251\n",
      "Ep:92, loss:0.00003, loss_test:0.02600, lr:9.04e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.594, tt:3403.275\n",
      "Ep:93, loss:0.00002, loss_test:0.02934, lr:8.95e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.608, tt:3441.195\n",
      "Ep:94, loss:0.00003, loss_test:0.02562, lr:8.86e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.616, tt:3478.511\n",
      "Ep:95, loss:0.00002, loss_test:0.02636, lr:8.78e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.638, tt:3517.258\n",
      "Ep:96, loss:0.00002, loss_test:0.02607, lr:8.69e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.639, tt:3553.944\n",
      "Ep:97, loss:0.00002, loss_test:0.02523, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.662, tt:3592.833\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00002, loss_test:0.02630, lr:8.60e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.676, tt:3630.954\n",
      "Ep:99, loss:0.00002, loss_test:0.02523, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.678, tt:3667.821\n",
      "Ep:100, loss:0.00002, loss_test:0.02527, lr:8.60e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.677, tt:3704.401\n",
      "Ep:101, loss:0.00002, loss_test:0.02526, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.659, tt:3739.188\n",
      "Ep:102, loss:0.00002, loss_test:0.02439, lr:8.60e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.667, tt:3776.746\n",
      "Ep:103, loss:0.00002, loss_test:0.02445, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.659, tt:3812.565\n",
      "Ep:104, loss:0.00002, loss_test:0.02404, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.669, tt:3850.230\n",
      "Ep:105, loss:0.00002, loss_test:0.02350, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.679, tt:3887.965\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.02394, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.676, tt:3924.283\n",
      "Ep:107, loss:0.00002, loss_test:0.02299, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.683, tt:3961.758\n",
      "Ep:108, loss:0.00002, loss_test:0.02352, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.656, tt:3995.529\n",
      "Ep:109, loss:0.00002, loss_test:0.02323, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.639, tt:4030.297\n",
      "Ep:110, loss:0.00002, loss_test:0.02366, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.644, tt:4067.504\n",
      "Ep:111, loss:0.00002, loss_test:0.02253, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.651, tt:4104.952\n",
      "Ep:112, loss:0.00002, loss_test:0.02245, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.647, tt:4141.155\n",
      "Ep:113, loss:0.00002, loss_test:0.02248, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.647, tt:4177.767\n",
      "Ep:114, loss:0.00002, loss_test:0.02211, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.646, tt:4214.246\n",
      "Ep:115, loss:0.00002, loss_test:0.02214, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.632, tt:4249.275\n",
      "Ep:116, loss:0.00002, loss_test:0.02326, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.626, tt:4285.210\n",
      "Ep:117, loss:0.00002, loss_test:0.02216, lr:8.51e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.629, tt:4322.261\n",
      "Ep:118, loss:0.00002, loss_test:0.02358, lr:8.43e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.683, tt:4365.236\n",
      "Ep:119, loss:0.00002, loss_test:0.02196, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.678, tt:4401.336\n",
      "Ep:120, loss:0.00002, loss_test:0.02298, lr:8.26e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.668, tt:4436.794\n",
      "Ep:121, loss:0.00002, loss_test:0.02100, lr:8.18e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.662, tt:4472.726\n",
      "Ep:122, loss:0.00002, loss_test:0.02191, lr:8.10e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.657, tt:4508.865\n",
      "Ep:123, loss:0.00002, loss_test:0.02083, lr:8.02e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.654, tt:4545.060\n",
      "Ep:124, loss:0.00002, loss_test:0.02096, lr:7.94e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.658, tt:4582.247\n",
      "Ep:125, loss:0.00002, loss_test:0.02136, lr:7.86e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.658, tt:4618.862\n",
      "Ep:126, loss:0.00002, loss_test:0.02059, lr:7.78e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.647, tt:4654.215\n",
      "Ep:127, loss:0.00002, loss_test:0.02160, lr:7.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.643, tt:4690.306\n",
      "Ep:128, loss:0.00002, loss_test:0.02074, lr:7.62e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.652, tt:4728.066\n",
      "Ep:129, loss:0.00002, loss_test:0.02130, lr:7.55e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.650, tt:4764.485\n",
      "Ep:130, loss:0.00001, loss_test:0.02037, lr:7.47e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.644, tt:4800.409\n",
      "Ep:131, loss:0.00001, loss_test:0.02153, lr:7.40e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.637, tt:4836.065\n",
      "Ep:132, loss:0.00001, loss_test:0.01979, lr:7.32e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.650, tt:4874.468\n",
      "Ep:133, loss:0.00001, loss_test:0.02136, lr:7.25e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.662, tt:4912.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.01983, lr:7.18e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.656, tt:4948.495\n",
      "Ep:135, loss:0.00001, loss_test:0.02072, lr:7.11e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.662, tt:4986.083\n",
      "Ep:136, loss:0.00001, loss_test:0.01979, lr:7.03e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.670, tt:5023.738\n",
      "Ep:137, loss:0.00001, loss_test:0.02062, lr:6.96e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.672, tt:5060.718\n",
      "Ep:138, loss:0.00001, loss_test:0.01997, lr:6.89e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.671, tt:5097.290\n",
      "Ep:139, loss:0.00001, loss_test:0.01990, lr:6.83e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.669, tt:5133.701\n",
      "Ep:140, loss:0.00001, loss_test:0.01959, lr:6.76e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.658, tt:5168.789\n",
      "Ep:141, loss:0.00001, loss_test:0.01964, lr:6.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.653, tt:5204.753\n",
      "Ep:142, loss:0.00001, loss_test:0.02039, lr:6.62e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.656, tt:5241.820\n",
      "Ep:143, loss:0.00001, loss_test:0.01936, lr:6.56e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.650, tt:5277.617\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00001, loss_test:0.02012, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.639, tt:5312.688\n",
      "Ep:145, loss:0.00001, loss_test:0.01938, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.637, tt:5349.050\n",
      "Ep:146, loss:0.00001, loss_test:0.01952, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.621, tt:5383.358\n",
      "Ep:147, loss:0.00001, loss_test:0.01964, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.609, tt:5418.113\n",
      "Ep:148, loss:0.00001, loss_test:0.01933, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.613, tt:5455.317\n",
      "Ep:149, loss:0.00001, loss_test:0.01939, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.611, tt:5491.712\n",
      "Ep:150, loss:0.00001, loss_test:0.01928, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.612, tt:5528.443\n",
      "Ep:151, loss:0.00001, loss_test:0.01921, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.600, tt:5563.254\n",
      "Ep:152, loss:0.00001, loss_test:0.01901, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.607, tt:5600.797\n",
      "Ep:153, loss:0.00001, loss_test:0.01895, lr:6.56e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.604, tt:5637.063\n",
      "Ep:154, loss:0.00001, loss_test:0.01877, lr:6.56e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.601, tt:5673.142\n",
      "Ep:155, loss:0.00001, loss_test:0.01896, lr:6.49e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.632, tt:5714.517\n",
      "Ep:156, loss:0.00001, loss_test:0.01840, lr:6.43e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.622, tt:5749.631\n",
      "Ep:157, loss:0.00001, loss_test:0.01879, lr:6.36e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.621, tt:5786.046\n",
      "Ep:158, loss:0.00001, loss_test:0.01832, lr:6.30e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.625, tt:5823.318\n",
      "Ep:159, loss:0.00001, loss_test:0.01863, lr:6.24e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.630, tt:5860.758\n",
      "Ep:160, loss:0.00001, loss_test:0.01829, lr:6.17e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.618, tt:5895.545\n",
      "Ep:161, loss:0.00001, loss_test:0.01866, lr:6.11e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.620, tt:5932.396\n",
      "Ep:162, loss:0.00001, loss_test:0.01789, lr:6.05e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.617, tt:5968.652\n",
      "Ep:163, loss:0.00001, loss_test:0.01856, lr:5.99e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.621, tt:6005.779\n",
      "Ep:164, loss:0.00001, loss_test:0.01776, lr:5.93e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.625, tt:6043.114\n",
      "Ep:165, loss:0.00001, loss_test:0.01826, lr:5.87e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.631, tt:6080.790\n",
      "Ep:166, loss:0.00001, loss_test:0.01770, lr:5.81e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.629, tt:6117.021\n",
      "Ep:167, loss:0.00001, loss_test:0.01776, lr:5.75e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.639, tt:6155.408\n",
      "Ep:168, loss:0.00001, loss_test:0.01786, lr:5.70e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.639, tt:6191.994\n",
      "Ep:169, loss:0.00001, loss_test:0.01733, lr:5.64e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.644, tt:6229.533\n",
      "Ep:170, loss:0.00001, loss_test:0.01798, lr:5.58e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.644, tt:6266.112\n",
      "Ep:171, loss:0.00001, loss_test:0.01720, lr:5.53e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.638, tt:6301.763\n",
      "Ep:172, loss:0.00001, loss_test:0.01772, lr:5.47e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.646, tt:6339.793\n",
      "Ep:173, loss:0.00001, loss_test:0.01692, lr:5.42e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.647, tt:6376.632\n",
      "Ep:174, loss:0.00001, loss_test:0.01760, lr:5.36e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.649, tt:6413.615\n",
      "Ep:175, loss:0.00001, loss_test:0.01682, lr:5.31e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.657, tt:6451.646\n",
      "Ep:176, loss:0.00001, loss_test:0.01673, lr:5.26e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.649, tt:6486.930\n",
      "Ep:177, loss:0.00001, loss_test:0.01717, lr:5.20e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.651, tt:6523.788\n",
      "Ep:178, loss:0.00001, loss_test:0.01653, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.652, tt:6560.648\n",
      "##########Best model found so far##########\n",
      "Ep:179, loss:0.00001, loss_test:0.01692, lr:5.15e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.669, tt:6600.505\n",
      "Ep:180, loss:0.00001, loss_test:0.01661, lr:5.15e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.672, tt:6637.580\n",
      "Ep:181, loss:0.00001, loss_test:0.01672, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.684, tt:6676.504\n",
      "Ep:182, loss:0.00001, loss_test:0.01647, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.692, tt:6714.546\n",
      "Ep:183, loss:0.00001, loss_test:0.01627, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.709, tt:6754.434\n",
      "Ep:184, loss:0.00001, loss_test:0.01662, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.710, tt:6791.388\n",
      "Ep:185, loss:0.00001, loss_test:0.01596, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.708, tt:6827.764\n",
      "##########Best model found so far##########\n",
      "Ep:186, loss:0.00001, loss_test:0.01707, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.714, tt:6865.516\n",
      "Ep:187, loss:0.00001, loss_test:0.01595, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.710, tt:6901.552\n",
      "Ep:188, loss:0.00001, loss_test:0.01662, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.711, tt:6938.319\n",
      "Ep:189, loss:0.00001, loss_test:0.01590, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.708, tt:6974.465\n",
      "Ep:190, loss:0.00001, loss_test:0.01631, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.707, tt:7010.980\n",
      "Ep:191, loss:0.00001, loss_test:0.01580, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.706, tt:7047.483\n",
      "Ep:192, loss:0.00001, loss_test:0.01603, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.701, tt:7083.240\n",
      "Ep:193, loss:0.00001, loss_test:0.01589, lr:5.15e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.702, tt:7120.278\n",
      "Ep:194, loss:0.00001, loss_test:0.01572, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.699, tt:7156.230\n",
      "Ep:195, loss:0.00001, loss_test:0.01599, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.703, tt:7193.837\n",
      "Ep:196, loss:0.00001, loss_test:0.01550, lr:5.15e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.695, tt:7228.944\n",
      "Ep:197, loss:0.00001, loss_test:0.01597, lr:5.10e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.695, tt:7265.571\n",
      "Ep:198, loss:0.00001, loss_test:0.01549, lr:5.05e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.695, tt:7302.209\n",
      "Ep:199, loss:0.00001, loss_test:0.01595, lr:5.00e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.700, tt:7339.998\n",
      "Ep:200, loss:0.00001, loss_test:0.01552, lr:4.95e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.699, tt:7376.597\n",
      "Ep:201, loss:0.00001, loss_test:0.01584, lr:4.90e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.706, tt:7414.590\n",
      "Ep:202, loss:0.00001, loss_test:0.01541, lr:4.85e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.706, tt:7451.222\n",
      "Ep:203, loss:0.00001, loss_test:0.01567, lr:4.80e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.704, tt:7487.630\n",
      "Ep:204, loss:0.00001, loss_test:0.01560, lr:4.75e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.655, tt:7514.301\n",
      "Ep:205, loss:0.00001, loss_test:0.01564, lr:4.71e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.567, tt:7532.777\n",
      "Ep:206, loss:0.00001, loss_test:0.01543, lr:4.66e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.472, tt:7549.660\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02671, lr:6.00e-02, fs:0.64179 (r=0.796,p=0.537),  time:33.040, tt:33.040\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02624, lr:6.00e-02, fs:0.67097 (r=0.963,p=0.515),  time:33.482, tt:66.964\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02816, lr:6.00e-02, fs:0.67081 (r=1.000,p=0.505),  time:35.151, tt:105.454\n",
      "Ep:3, loss:0.00005, loss_test:0.02834, lr:6.00e-02, fs:0.67089 (r=0.981,p=0.510),  time:34.900, tt:139.602\n",
      "Ep:4, loss:0.00006, loss_test:0.02800, lr:6.00e-02, fs:0.67516 (r=0.981,p=0.515),  time:34.276, tt:171.382\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02735, lr:6.00e-02, fs:0.66667 (r=0.944,p=0.515),  time:33.874, tt:203.243\n",
      "Ep:6, loss:0.00005, loss_test:0.02681, lr:6.00e-02, fs:0.65333 (r=0.907,p=0.510),  time:33.564, tt:234.945\n",
      "Ep:7, loss:0.00005, loss_test:0.02633, lr:6.00e-02, fs:0.63014 (r=0.852,p=0.500),  time:33.271, tt:266.164\n",
      "Ep:8, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.63889 (r=0.852,p=0.511),  time:33.379, tt:300.415\n",
      "Ep:9, loss:0.00005, loss_test:0.02549, lr:6.00e-02, fs:0.64384 (r=0.870,p=0.511),  time:33.664, tt:336.637\n",
      "Ep:10, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.67114 (r=0.926,p=0.526),  time:33.786, tt:371.641\n",
      "Ep:11, loss:0.00005, loss_test:0.02457, lr:6.00e-02, fs:0.67568 (r=0.926,p=0.532),  time:33.995, tt:407.945\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.02377, lr:6.00e-02, fs:0.67123 (r=0.907,p=0.533),  time:34.016, tt:442.213\n",
      "Ep:13, loss:0.00005, loss_test:0.02310, lr:6.00e-02, fs:0.65278 (r=0.870,p=0.522),  time:34.045, tt:476.632\n",
      "Ep:14, loss:0.00004, loss_test:0.02260, lr:6.00e-02, fs:0.66207 (r=0.889,p=0.527),  time:34.131, tt:511.960\n",
      "Ep:15, loss:0.00004, loss_test:0.02205, lr:6.00e-02, fs:0.67123 (r=0.907,p=0.533),  time:34.154, tt:546.458\n",
      "Ep:16, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.68027 (r=0.926,p=0.538),  time:34.155, tt:580.631\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02012, lr:6.00e-02, fs:0.68571 (r=0.889,p=0.558),  time:34.222, tt:616.004\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01941, lr:6.00e-02, fs:0.68571 (r=0.889,p=0.558),  time:34.272, tt:651.162\n",
      "Ep:19, loss:0.00004, loss_test:0.01890, lr:6.00e-02, fs:0.68116 (r=0.870,p=0.560),  time:34.282, tt:685.630\n",
      "Ep:20, loss:0.00004, loss_test:0.01833, lr:6.00e-02, fs:0.69118 (r=0.870,p=0.573),  time:34.355, tt:721.462\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01776, lr:6.00e-02, fs:0.71642 (r=0.889,p=0.600),  time:34.372, tt:756.190\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01699, lr:6.00e-02, fs:0.72180 (r=0.889,p=0.608),  time:34.372, tt:790.551\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01640, lr:6.00e-02, fs:0.73529 (r=0.926,p=0.610),  time:34.327, tt:823.842\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.75556 (r=0.944,p=0.630),  time:34.315, tt:857.877\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.76336 (r=0.926,p=0.649),  time:34.357, tt:893.287\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01513, lr:6.00e-02, fs:0.73846 (r=0.889,p=0.632),  time:34.391, tt:928.566\n",
      "Ep:27, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.73846 (r=0.889,p=0.632),  time:34.385, tt:962.780\n",
      "Ep:28, loss:0.00003, loss_test:0.01456, lr:6.00e-02, fs:0.74627 (r=0.926,p=0.625),  time:34.402, tt:997.646\n",
      "Ep:29, loss:0.00003, loss_test:0.01440, lr:6.00e-02, fs:0.75758 (r=0.926,p=0.641),  time:34.428, tt:1032.839\n",
      "Ep:30, loss:0.00003, loss_test:0.01437, lr:6.00e-02, fs:0.76923 (r=0.926,p=0.658),  time:34.439, tt:1067.621\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01397, lr:6.00e-02, fs:0.77612 (r=0.963,p=0.650),  time:34.466, tt:1102.926\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01363, lr:6.00e-02, fs:0.78195 (r=0.963,p=0.658),  time:34.455, tt:1137.002\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.77863 (r=0.944,p=0.662),  time:34.463, tt:1171.742\n",
      "Ep:34, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.76923 (r=0.926,p=0.658),  time:34.493, tt:1207.251\n",
      "Ep:35, loss:0.00002, loss_test:0.01276, lr:6.00e-02, fs:0.76336 (r=0.926,p=0.649),  time:34.480, tt:1241.286\n",
      "Ep:36, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.78462 (r=0.944,p=0.671),  time:34.491, tt:1276.177\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.79365 (r=0.926,p=0.694),  time:34.506, tt:1311.242\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01196, lr:6.00e-02, fs:0.77165 (r=0.907,p=0.671),  time:34.489, tt:1345.083\n",
      "Ep:39, loss:0.00002, loss_test:0.01167, lr:6.00e-02, fs:0.78740 (r=0.926,p=0.685),  time:34.521, tt:1380.821\n",
      "Ep:40, loss:0.00002, loss_test:0.01142, lr:6.00e-02, fs:0.78740 (r=0.926,p=0.685),  time:34.548, tt:1416.454\n",
      "Ep:41, loss:0.00002, loss_test:0.01114, lr:6.00e-02, fs:0.80620 (r=0.963,p=0.693),  time:34.559, tt:1451.470\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01089, lr:6.00e-02, fs:0.81250 (r=0.963,p=0.703),  time:34.557, tt:1485.949\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01071, lr:6.00e-02, fs:0.80952 (r=0.944,p=0.708),  time:34.562, tt:1520.745\n",
      "Ep:44, loss:0.00002, loss_test:0.01026, lr:6.00e-02, fs:0.84127 (r=0.981,p=0.736),  time:34.560, tt:1555.201\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01035, lr:6.00e-02, fs:0.83200 (r=0.963,p=0.732),  time:34.579, tt:1590.621\n",
      "Ep:46, loss:0.00002, loss_test:0.00987, lr:6.00e-02, fs:0.84127 (r=0.981,p=0.736),  time:34.606, tt:1626.476\n",
      "Ep:47, loss:0.00002, loss_test:0.00976, lr:6.00e-02, fs:0.84127 (r=0.981,p=0.736),  time:34.636, tt:1662.551\n",
      "Ep:48, loss:0.00002, loss_test:0.00973, lr:6.00e-02, fs:0.84553 (r=0.963,p=0.754),  time:34.637, tt:1697.235\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.00909, lr:6.00e-02, fs:0.84553 (r=0.963,p=0.754),  time:34.652, tt:1732.606\n",
      "Ep:50, loss:0.00001, loss_test:0.00888, lr:6.00e-02, fs:0.85484 (r=0.981,p=0.757),  time:34.673, tt:1768.331\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02336, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:26.022, tt:26.022\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02657, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:27.970, tt:55.940\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02806, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.913, tt:86.738\n",
      "Ep:3, loss:0.00005, loss_test:0.02741, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.475, tt:117.901\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02691, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:30.033, tt:150.164\n",
      "Ep:5, loss:0.00005, loss_test:0.02612, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:30.325, tt:181.951\n",
      "Ep:6, loss:0.00005, loss_test:0.02526, lr:6.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:30.629, tt:214.400\n",
      "Ep:7, loss:0.00005, loss_test:0.02455, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:30.618, tt:244.944\n",
      "Ep:8, loss:0.00005, loss_test:0.02414, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:30.532, tt:274.789\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00005, loss_test:0.02403, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:30.695, tt:306.954\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00005, loss_test:0.02387, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:30.670, tt:337.365\n",
      "Ep:11, loss:0.00005, loss_test:0.02347, lr:6.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:30.577, tt:366.921\n",
      "Ep:12, loss:0.00005, loss_test:0.02302, lr:6.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:30.609, tt:397.912\n",
      "Ep:13, loss:0.00005, loss_test:0.02258, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:30.602, tt:428.425\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00005, loss_test:0.02225, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:30.706, tt:460.590\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02204, lr:6.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:30.625, tt:490.006\n",
      "Ep:16, loss:0.00004, loss_test:0.02199, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:30.580, tt:519.858\n",
      "Ep:17, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:30.547, tt:549.839\n",
      "Ep:18, loss:0.00004, loss_test:0.02159, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:30.532, tt:580.111\n",
      "Ep:19, loss:0.00004, loss_test:0.02097, lr:6.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:30.527, tt:610.536\n",
      "Ep:20, loss:0.00004, loss_test:0.02040, lr:6.00e-02, fs:0.65354 (r=0.838,p=0.535),  time:30.602, tt:642.646\n",
      "Ep:21, loss:0.00004, loss_test:0.01979, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:30.698, tt:675.350\n",
      "Ep:22, loss:0.00004, loss_test:0.01916, lr:6.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:30.754, tt:707.334\n",
      "Ep:23, loss:0.00004, loss_test:0.01863, lr:6.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:30.768, tt:738.423\n",
      "Ep:24, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:30.822, tt:770.552\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:30.826, tt:801.485\n",
      "Ep:26, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:30.819, tt:832.120\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:30.824, tt:863.068\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:30.833, tt:894.163\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01579, lr:6.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:30.844, tt:925.314\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:30.878, tt:957.206\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:30.844, tt:987.001\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:30.859, tt:1018.333\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.861, tt:1049.291\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:30.869, tt:1080.424\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01470, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:30.866, tt:1111.176\n",
      "Ep:36, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.894, tt:1143.085\n",
      "Ep:37, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.874, tt:1173.195\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01450, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:30.869, tt:1203.879\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.846, tt:1233.834\n",
      "Ep:40, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:30.828, tt:1263.942\n",
      "Ep:41, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:30.828, tt:1294.790\n",
      "Ep:42, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:30.830, tt:1325.691\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01401, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:30.850, tt:1357.414\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.797, tt:1385.854\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.761, tt:1414.984\n",
      "Ep:46, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.784, tt:1446.835\n",
      "Ep:47, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.749, tt:1475.959\n",
      "Ep:48, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.725, tt:1505.502\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:30.685, tt:1534.250\n",
      "Ep:50, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.680, tt:1564.660\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01378, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:30.681, tt:1595.431\n",
      "Ep:52, loss:0.00001, loss_test:0.01398, lr:6.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:30.681, tt:1626.106\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01381, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:30.678, tt:1656.625\n",
      "Ep:54, loss:0.00001, loss_test:0.01388, lr:6.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.686, tt:1687.722\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01443, lr:6.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:30.701, tt:1719.234\n",
      "Ep:56, loss:0.00001, loss_test:0.01437, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.706, tt:1750.234\n",
      "Ep:57, loss:0.00001, loss_test:0.01544, lr:6.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.700, tt:1780.581\n",
      "Ep:58, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:30.694, tt:1810.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01552, lr:6.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:30.688, tt:1841.302\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01458, lr:6.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.670, tt:1870.867\n",
      "Ep:61, loss:0.00001, loss_test:0.01600, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.657, tt:1900.736\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01455, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.671, tt:1932.271\n",
      "Ep:63, loss:0.00001, loss_test:0.01532, lr:6.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:30.699, tt:1964.755\n",
      "Ep:64, loss:0.00001, loss_test:0.01473, lr:6.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.723, tt:1997.017\n",
      "Ep:65, loss:0.00001, loss_test:0.01729, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.721, tt:2027.561\n",
      "Ep:66, loss:0.00001, loss_test:0.01633, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.708, tt:2057.437\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01538, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.728, tt:2089.514\n",
      "Ep:68, loss:0.00001, loss_test:0.01716, lr:6.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:30.746, tt:2121.504\n",
      "Ep:69, loss:0.00001, loss_test:0.01780, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.773, tt:2154.111\n",
      "Ep:70, loss:0.00001, loss_test:0.01732, lr:6.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.784, tt:2185.644\n",
      "Ep:71, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.786, tt:2216.602\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01869, lr:6.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.805, tt:2248.772\n",
      "Ep:73, loss:0.00001, loss_test:0.01836, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.816, tt:2280.406\n",
      "Ep:74, loss:0.00001, loss_test:0.01634, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.822, tt:2311.649\n",
      "Ep:75, loss:0.00001, loss_test:0.01691, lr:6.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.841, tt:2343.884\n",
      "Ep:76, loss:0.00001, loss_test:0.01799, lr:6.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.864, tt:2376.492\n",
      "Ep:77, loss:0.00001, loss_test:0.02011, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.890, tt:2409.396\n",
      "Ep:78, loss:0.00001, loss_test:0.01692, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:30.894, tt:2440.631\n",
      "Ep:79, loss:0.00001, loss_test:0.01848, lr:6.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.870, tt:2469.571\n",
      "Ep:80, loss:0.00001, loss_test:0.01692, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.879, tt:2501.183\n",
      "Ep:81, loss:0.00001, loss_test:0.02209, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.900, tt:2533.777\n",
      "Ep:82, loss:0.00001, loss_test:0.02156, lr:6.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.901, tt:2564.760\n",
      "Ep:83, loss:0.00001, loss_test:0.01713, lr:5.94e-02, fs:0.81283 (r=0.768,p=0.864),  time:30.893, tt:2595.005\n",
      "Ep:84, loss:0.00001, loss_test:0.02026, lr:5.88e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.900, tt:2626.532\n",
      "Ep:85, loss:0.00001, loss_test:0.01899, lr:5.82e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.927, tt:2659.718\n",
      "Ep:86, loss:0.00001, loss_test:0.01929, lr:5.76e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.915, tt:2689.625\n",
      "Ep:87, loss:0.00001, loss_test:0.02232, lr:5.71e-02, fs:0.82979 (r=0.788,p=0.876),  time:30.928, tt:2721.642\n",
      "Ep:88, loss:0.00001, loss_test:0.01804, lr:5.65e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.940, tt:2753.682\n",
      "Ep:89, loss:0.00001, loss_test:0.02091, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.945, tt:2785.087\n",
      "Ep:90, loss:0.00001, loss_test:0.02047, lr:5.54e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.948, tt:2816.245\n",
      "Ep:91, loss:0.00001, loss_test:0.01978, lr:5.48e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.966, tt:2848.848\n",
      "Ep:92, loss:0.00001, loss_test:0.02297, lr:5.43e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.975, tt:2880.695\n",
      "Ep:93, loss:0.00000, loss_test:0.01926, lr:5.37e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.978, tt:2911.967\n",
      "Ep:94, loss:0.00000, loss_test:0.02267, lr:5.32e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.987, tt:2943.804\n",
      "Ep:95, loss:0.00000, loss_test:0.02216, lr:5.27e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.979, tt:2973.966\n",
      "Ep:96, loss:0.00000, loss_test:0.02316, lr:5.21e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.988, tt:3005.829\n",
      "Ep:97, loss:0.00000, loss_test:0.02259, lr:5.16e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.998, tt:3037.831\n",
      "Ep:98, loss:0.00000, loss_test:0.02366, lr:5.11e-02, fs:0.78613 (r=0.687,p=0.919),  time:31.016, tt:3070.593\n",
      "Ep:99, loss:0.00000, loss_test:0.02343, lr:5.06e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.017, tt:3101.739\n",
      "Ep:100, loss:0.00000, loss_test:0.02338, lr:5.01e-02, fs:0.79310 (r=0.697,p=0.920),  time:31.017, tt:3132.715\n",
      "Ep:101, loss:0.00000, loss_test:0.02522, lr:4.96e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.025, tt:3164.522\n",
      "Ep:102, loss:0.00000, loss_test:0.02376, lr:4.91e-02, fs:0.77457 (r=0.677,p=0.905),  time:31.029, tt:3196.001\n",
      "Ep:103, loss:0.00000, loss_test:0.02437, lr:4.86e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.025, tt:3226.567\n",
      "Ep:104, loss:0.00000, loss_test:0.02556, lr:4.81e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.020, tt:3257.067\n",
      "Ep:105, loss:0.00000, loss_test:0.02449, lr:4.76e-02, fs:0.77457 (r=0.677,p=0.905),  time:31.016, tt:3287.678\n",
      "Ep:106, loss:0.00000, loss_test:0.02457, lr:4.71e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.021, tt:3319.220\n",
      "Ep:107, loss:0.00000, loss_test:0.02501, lr:4.67e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.028, tt:3351.060\n",
      "Ep:108, loss:0.00000, loss_test:0.02695, lr:4.62e-02, fs:0.77647 (r=0.667,p=0.930),  time:31.028, tt:3382.032\n",
      "Ep:109, loss:0.00000, loss_test:0.02600, lr:4.57e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.032, tt:3413.516\n",
      "Ep:110, loss:0.00000, loss_test:0.02466, lr:4.53e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.032, tt:3444.580\n",
      "Ep:111, loss:0.00000, loss_test:0.02659, lr:4.48e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.033, tt:3475.672\n",
      "Ep:112, loss:0.00000, loss_test:0.02650, lr:4.44e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.031, tt:3506.525\n",
      "Ep:113, loss:0.00000, loss_test:0.02698, lr:4.39e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.032, tt:3537.648\n",
      "Ep:114, loss:0.00000, loss_test:0.02711, lr:4.35e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.031, tt:3568.536\n",
      "Ep:115, loss:0.00000, loss_test:0.02675, lr:4.31e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.021, tt:3598.427\n",
      "Ep:116, loss:0.00000, loss_test:0.02709, lr:4.26e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.020, tt:3629.298\n",
      "Ep:117, loss:0.00000, loss_test:0.02670, lr:4.22e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.011, tt:3659.338\n",
      "Ep:118, loss:0.00000, loss_test:0.02775, lr:4.18e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.011, tt:3690.361\n",
      "Ep:119, loss:0.00000, loss_test:0.02791, lr:4.14e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.013, tt:3721.593\n",
      "Ep:120, loss:0.00000, loss_test:0.02811, lr:4.10e-02, fs:0.77647 (r=0.667,p=0.930),  time:31.020, tt:3753.421\n",
      "Ep:121, loss:0.00000, loss_test:0.02788, lr:4.05e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.016, tt:3783.977\n",
      "Ep:122, loss:0.00000, loss_test:0.02685, lr:4.01e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.006, tt:3813.798\n",
      "Ep:123, loss:0.00000, loss_test:0.02924, lr:3.97e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.012, tt:3845.462\n",
      "Ep:124, loss:0.00000, loss_test:0.02830, lr:3.93e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.017, tt:3877.078\n",
      "Ep:125, loss:0.00000, loss_test:0.02739, lr:3.89e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.026, tt:3909.298\n",
      "Ep:126, loss:0.00000, loss_test:0.02787, lr:3.86e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.020, tt:3939.496\n",
      "Ep:127, loss:0.00000, loss_test:0.02842, lr:3.82e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.008, tt:3969.012\n",
      "Ep:128, loss:0.00000, loss_test:0.02944, lr:3.78e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.002, tt:3999.198\n",
      "Ep:129, loss:0.00000, loss_test:0.02831, lr:3.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.024, tt:4033.089\n",
      "Ep:130, loss:0.00000, loss_test:0.03020, lr:3.70e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.030, tt:4064.941\n",
      "Ep:131, loss:0.00000, loss_test:0.02857, lr:3.67e-02, fs:0.78363 (r=0.677,p=0.931),  time:31.034, tt:4096.527\n",
      "Ep:132, loss:0.00000, loss_test:0.02854, lr:3.63e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.032, tt:4127.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.03033, lr:3.59e-02, fs:0.74847 (r=0.616,p=0.953),  time:31.027, tt:4157.593\n",
      "Ep:134, loss:0.00000, loss_test:0.02949, lr:3.56e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.020, tt:4187.661\n",
      "Ep:135, loss:0.00000, loss_test:0.02920, lr:3.52e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.016, tt:4218.229\n",
      "Ep:136, loss:0.00000, loss_test:0.03085, lr:3.49e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.013, tt:4248.763\n",
      "Ep:137, loss:0.00000, loss_test:0.02920, lr:3.45e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.014, tt:4279.915\n",
      "Ep:138, loss:0.00000, loss_test:0.03015, lr:3.42e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.020, tt:4311.777\n",
      "Ep:139, loss:0.00000, loss_test:0.03010, lr:3.38e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.019, tt:4342.628\n",
      "Ep:140, loss:0.00000, loss_test:0.03050, lr:3.35e-02, fs:0.78824 (r=0.677,p=0.944),  time:31.015, tt:4373.059\n",
      "Ep:141, loss:0.00000, loss_test:0.03050, lr:3.32e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.009, tt:4403.289\n",
      "Ep:142, loss:0.00000, loss_test:0.03106, lr:3.28e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.013, tt:4434.885\n",
      "Ep:143, loss:0.00000, loss_test:0.03174, lr:3.25e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.021, tt:4466.989\n",
      "Ep:144, loss:0.00000, loss_test:0.02974, lr:3.22e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.023, tt:4498.275\n",
      "Ep:145, loss:0.00000, loss_test:0.03054, lr:3.19e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.031, tt:4530.482\n",
      "Ep:146, loss:0.00000, loss_test:0.03150, lr:3.15e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.044, tt:4563.488\n",
      "Ep:147, loss:0.00000, loss_test:0.03021, lr:3.12e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.059, tt:4596.660\n",
      "Ep:148, loss:0.00000, loss_test:0.03167, lr:3.09e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.067, tt:4629.026\n",
      "Ep:149, loss:0.00000, loss_test:0.03207, lr:3.06e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.065, tt:4659.691\n",
      "Ep:150, loss:0.00000, loss_test:0.03060, lr:3.03e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.064, tt:4690.669\n",
      "Ep:151, loss:0.00000, loss_test:0.03269, lr:3.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.058, tt:4720.858\n",
      "Ep:152, loss:0.00000, loss_test:0.03135, lr:2.97e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.052, tt:4750.927\n",
      "Ep:153, loss:0.00000, loss_test:0.03168, lr:2.94e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.051, tt:4781.877\n",
      "Ep:154, loss:0.00000, loss_test:0.03241, lr:2.91e-02, fs:0.77844 (r=0.657,p=0.956),  time:31.044, tt:4811.794\n",
      "Ep:155, loss:0.00000, loss_test:0.03181, lr:2.88e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.047, tt:4843.319\n",
      "Ep:156, loss:0.00000, loss_test:0.03174, lr:2.85e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.045, tt:4874.132\n",
      "Ep:157, loss:0.00000, loss_test:0.03222, lr:2.82e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.044, tt:4904.888\n",
      "Ep:158, loss:0.00000, loss_test:0.03216, lr:2.80e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.034, tt:4934.476\n",
      "Ep:159, loss:0.00000, loss_test:0.03271, lr:2.77e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.032, tt:4965.139\n",
      "Ep:160, loss:0.00000, loss_test:0.03217, lr:2.74e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.031, tt:4995.999\n",
      "Ep:161, loss:0.00000, loss_test:0.03220, lr:2.71e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.022, tt:5025.626\n",
      "Ep:162, loss:0.00000, loss_test:0.03325, lr:2.69e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.021, tt:5056.489\n",
      "Ep:163, loss:0.00000, loss_test:0.03164, lr:2.66e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.026, tt:5088.281\n",
      "Ep:164, loss:0.00000, loss_test:0.03345, lr:2.63e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.027, tt:5119.518\n",
      "Ep:165, loss:0.00000, loss_test:0.03281, lr:2.61e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.026, tt:5150.379\n",
      "Ep:166, loss:0.00000, loss_test:0.03241, lr:2.58e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.025, tt:5181.145\n",
      "Ep:167, loss:0.00000, loss_test:0.03416, lr:2.55e-02, fs:0.79042 (r=0.667,p=0.971),  time:31.027, tt:5212.510\n",
      "Ep:168, loss:0.00000, loss_test:0.03242, lr:2.53e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.023, tt:5242.838\n",
      "Ep:169, loss:0.00000, loss_test:0.03349, lr:2.50e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.021, tt:5273.572\n",
      "Ep:170, loss:0.00000, loss_test:0.03336, lr:2.48e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.015, tt:5303.628\n",
      "Ep:171, loss:0.00000, loss_test:0.03318, lr:2.45e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.005, tt:5332.845\n",
      "Ep:172, loss:0.00000, loss_test:0.03376, lr:2.43e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.007, tt:5364.273\n",
      "Ep:173, loss:0.00000, loss_test:0.03315, lr:2.40e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.015, tt:5396.646\n",
      "Ep:174, loss:0.00000, loss_test:0.03369, lr:2.38e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.016, tt:5427.779\n",
      "Ep:175, loss:0.00000, loss_test:0.03346, lr:2.36e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.016, tt:5458.842\n",
      "Ep:176, loss:0.00000, loss_test:0.03408, lr:2.33e-02, fs:0.78313 (r=0.657,p=0.970),  time:31.014, tt:5489.482\n",
      "Ep:177, loss:0.00000, loss_test:0.03337, lr:2.31e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.005, tt:5518.926\n",
      "Ep:178, loss:0.00000, loss_test:0.03445, lr:2.29e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.006, tt:5549.984\n",
      "Ep:179, loss:0.00000, loss_test:0.03414, lr:2.26e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.000, tt:5580.027\n",
      "Ep:180, loss:0.00000, loss_test:0.03338, lr:2.24e-02, fs:0.79290 (r=0.677,p=0.957),  time:30.993, tt:5609.760\n",
      "Ep:181, loss:0.00000, loss_test:0.03488, lr:2.22e-02, fs:0.79762 (r=0.677,p=0.971),  time:30.993, tt:5640.730\n",
      "Ep:182, loss:0.00000, loss_test:0.03336, lr:2.20e-02, fs:0.79290 (r=0.677,p=0.957),  time:30.994, tt:5671.855\n",
      "Ep:183, loss:0.00000, loss_test:0.03501, lr:2.17e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.004, tt:5704.683\n",
      "Ep:184, loss:0.00000, loss_test:0.03359, lr:2.15e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.003, tt:5735.462\n",
      "Ep:185, loss:0.00000, loss_test:0.03471, lr:2.13e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.006, tt:5767.181\n",
      "Ep:186, loss:0.00000, loss_test:0.03429, lr:2.11e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.011, tt:5799.062\n",
      "Ep:187, loss:0.00000, loss_test:0.03439, lr:2.09e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.014, tt:5830.615\n",
      "Ep:188, loss:0.00000, loss_test:0.03474, lr:2.07e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.019, tt:5862.522\n",
      "Ep:189, loss:0.00000, loss_test:0.03455, lr:2.05e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.029, tt:5895.526\n",
      "Ep:190, loss:0.00000, loss_test:0.03506, lr:2.03e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.036, tt:5927.794\n",
      "Ep:191, loss:0.00000, loss_test:0.03425, lr:2.01e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.034, tt:5958.510\n",
      "Ep:192, loss:0.00000, loss_test:0.03526, lr:1.99e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.027, tt:5988.174\n",
      "Ep:193, loss:0.00000, loss_test:0.03449, lr:1.97e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.032, tt:6020.267\n",
      "Ep:194, loss:0.00000, loss_test:0.03560, lr:1.95e-02, fs:0.79762 (r=0.677,p=0.971),  time:31.034, tt:6051.578\n",
      "Ep:195, loss:0.00000, loss_test:0.03468, lr:1.93e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.032, tt:6082.364\n",
      "Ep:196, loss:0.00000, loss_test:0.03529, lr:1.91e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.034, tt:6113.732\n",
      "Ep:197, loss:0.00000, loss_test:0.03469, lr:1.89e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.037, tt:6145.287\n",
      "Ep:198, loss:0.00000, loss_test:0.03536, lr:1.87e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.023, tt:6173.656\n",
      "Ep:199, loss:0.00000, loss_test:0.03517, lr:1.85e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.018, tt:6203.555\n",
      "Ep:200, loss:0.00000, loss_test:0.03516, lr:1.83e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.016, tt:6234.237\n",
      "Ep:201, loss:0.00000, loss_test:0.03553, lr:1.81e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.020, tt:6266.090\n",
      "Ep:202, loss:0.00000, loss_test:0.03516, lr:1.80e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.018, tt:6296.599\n",
      "Ep:203, loss:0.00000, loss_test:0.03574, lr:1.78e-02, fs:0.79290 (r=0.677,p=0.957),  time:31.015, tt:6327.138\n",
      "Ep:204, loss:0.00000, loss_test:0.03516, lr:1.76e-02, fs:0.79290 (r=0.677,p=0.957),  time:30.985, tt:6351.872\n",
      "Ep:205, loss:0.00000, loss_test:0.03548, lr:1.74e-02, fs:0.79290 (r=0.677,p=0.957),  time:30.969, tt:6379.713\n",
      "Ep:206, loss:0.00000, loss_test:0.03534, lr:1.73e-02, fs:0.79290 (r=0.677,p=0.957),  time:30.962, tt:6409.039\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12756, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:26.963, tt:26.963\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12646, lr:1.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:29.332, tt:58.665\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12518, lr:1.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:28.693, tt:86.078\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12436, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:29.374, tt:117.495\n",
      "Ep:4, loss:0.00026, loss_test:0.12391, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.794, tt:148.971\n",
      "Ep:5, loss:0.00026, loss_test:0.12335, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:30.199, tt:181.191\n",
      "Ep:6, loss:0.00026, loss_test:0.12251, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:30.543, tt:213.801\n",
      "Ep:7, loss:0.00025, loss_test:0.12186, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:30.664, tt:245.312\n",
      "Ep:8, loss:0.00025, loss_test:0.12119, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:30.919, tt:278.271\n",
      "Ep:9, loss:0.00025, loss_test:0.12062, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:31.031, tt:310.307\n",
      "Ep:10, loss:0.00025, loss_test:0.11985, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:31.025, tt:341.274\n",
      "Ep:11, loss:0.00024, loss_test:0.11891, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:31.073, tt:372.870\n",
      "Ep:12, loss:0.00024, loss_test:0.11816, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:31.245, tt:406.186\n",
      "Ep:13, loss:0.00024, loss_test:0.11758, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:31.286, tt:437.999\n",
      "Ep:14, loss:0.00024, loss_test:0.11696, lr:9.90e-03, fs:0.69136 (r=0.848,p=0.583),  time:31.546, tt:473.193\n",
      "Ep:15, loss:0.00023, loss_test:0.11660, lr:9.80e-03, fs:0.69421 (r=0.848,p=0.587),  time:31.587, tt:505.389\n",
      "Ep:16, loss:0.00023, loss_test:0.11583, lr:9.70e-03, fs:0.69421 (r=0.848,p=0.587),  time:31.624, tt:537.601\n",
      "Ep:17, loss:0.00023, loss_test:0.11516, lr:9.61e-03, fs:0.68908 (r=0.828,p=0.590),  time:31.596, tt:568.729\n",
      "Ep:18, loss:0.00022, loss_test:0.11491, lr:9.51e-03, fs:0.68354 (r=0.818,p=0.587),  time:31.624, tt:600.860\n",
      "Ep:19, loss:0.00022, loss_test:0.11411, lr:9.41e-03, fs:0.67532 (r=0.788,p=0.591),  time:31.688, tt:633.758\n",
      "Ep:20, loss:0.00022, loss_test:0.11326, lr:9.32e-03, fs:0.66960 (r=0.768,p=0.594),  time:31.757, tt:666.905\n",
      "Ep:21, loss:0.00021, loss_test:0.11298, lr:9.23e-03, fs:0.66964 (r=0.758,p=0.600),  time:31.876, tt:701.268\n",
      "Ep:22, loss:0.00021, loss_test:0.11211, lr:9.14e-03, fs:0.65158 (r=0.727,p=0.590),  time:31.828, tt:732.055\n",
      "Ep:23, loss:0.00021, loss_test:0.11132, lr:9.04e-03, fs:0.66055 (r=0.727,p=0.605),  time:31.856, tt:764.539\n",
      "Ep:24, loss:0.00020, loss_test:0.11100, lr:8.95e-03, fs:0.66977 (r=0.727,p=0.621),  time:31.789, tt:794.726\n",
      "Ep:25, loss:0.00020, loss_test:0.10956, lr:8.86e-03, fs:0.67606 (r=0.727,p=0.632),  time:31.804, tt:826.900\n",
      "Ep:26, loss:0.00019, loss_test:0.10980, lr:8.78e-03, fs:0.69194 (r=0.737,p=0.652),  time:31.763, tt:857.593\n",
      "Ep:27, loss:0.00019, loss_test:0.10872, lr:8.69e-03, fs:0.69856 (r=0.737,p=0.664),  time:31.739, tt:888.688\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.10704, lr:8.69e-03, fs:0.69565 (r=0.727,p=0.667),  time:31.700, tt:919.302\n",
      "Ep:29, loss:0.00018, loss_test:0.10895, lr:8.69e-03, fs:0.70297 (r=0.717,p=0.689),  time:31.744, tt:952.309\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00018, loss_test:0.10605, lr:8.69e-03, fs:0.71921 (r=0.737,p=0.702),  time:31.757, tt:984.457\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.10567, lr:8.69e-03, fs:0.69388 (r=0.687,p=0.701),  time:31.695, tt:1014.235\n",
      "Ep:32, loss:0.00017, loss_test:0.10186, lr:8.69e-03, fs:0.67692 (r=0.667,p=0.688),  time:31.698, tt:1046.018\n",
      "Ep:33, loss:0.00016, loss_test:0.10209, lr:8.69e-03, fs:0.69072 (r=0.677,p=0.705),  time:31.675, tt:1076.934\n",
      "Ep:34, loss:0.00016, loss_test:0.10191, lr:8.69e-03, fs:0.69430 (r=0.677,p=0.713),  time:31.628, tt:1106.963\n",
      "Ep:35, loss:0.00015, loss_test:0.10021, lr:8.69e-03, fs:0.70833 (r=0.687,p=0.731),  time:31.640, tt:1139.025\n",
      "Ep:36, loss:0.00015, loss_test:0.09927, lr:8.69e-03, fs:0.72165 (r=0.707,p=0.737),  time:31.663, tt:1171.545\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00014, loss_test:0.10030, lr:8.69e-03, fs:0.70968 (r=0.667,p=0.759),  time:31.672, tt:1203.517\n",
      "Ep:38, loss:0.00014, loss_test:0.09761, lr:8.69e-03, fs:0.74074 (r=0.707,p=0.778),  time:31.653, tt:1234.485\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.09768, lr:8.69e-03, fs:0.73514 (r=0.687,p=0.791),  time:31.666, tt:1266.653\n",
      "Ep:40, loss:0.00012, loss_test:0.09680, lr:8.69e-03, fs:0.73514 (r=0.687,p=0.791),  time:31.683, tt:1298.991\n",
      "Ep:41, loss:0.00012, loss_test:0.09430, lr:8.69e-03, fs:0.77720 (r=0.758,p=0.798),  time:31.757, tt:1333.779\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.10187, lr:8.69e-03, fs:0.72527 (r=0.667,p=0.795),  time:31.767, tt:1365.965\n",
      "Ep:43, loss:0.00011, loss_test:0.10590, lr:8.69e-03, fs:0.69945 (r=0.646,p=0.762),  time:31.756, tt:1397.275\n",
      "Ep:44, loss:0.00011, loss_test:0.09233, lr:8.69e-03, fs:0.76684 (r=0.747,p=0.787),  time:31.722, tt:1427.497\n",
      "Ep:45, loss:0.00011, loss_test:0.09485, lr:8.69e-03, fs:0.80808 (r=0.808,p=0.808),  time:31.746, tt:1460.297\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.09607, lr:8.69e-03, fs:0.78261 (r=0.727,p=0.847),  time:31.761, tt:1492.763\n",
      "Ep:47, loss:0.00009, loss_test:0.10147, lr:8.69e-03, fs:0.78919 (r=0.737,p=0.849),  time:31.786, tt:1525.746\n",
      "Ep:48, loss:0.00009, loss_test:0.09575, lr:8.69e-03, fs:0.81951 (r=0.848,p=0.792),  time:31.810, tt:1558.698\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00011, loss_test:0.09066, lr:8.69e-03, fs:0.78534 (r=0.758,p=0.815),  time:31.807, tt:1590.368\n",
      "Ep:50, loss:0.00009, loss_test:0.10896, lr:8.69e-03, fs:0.71508 (r=0.646,p=0.800),  time:31.815, tt:1622.544\n",
      "Ep:51, loss:0.00009, loss_test:0.08769, lr:8.69e-03, fs:0.86700 (r=0.889,p=0.846),  time:31.833, tt:1655.304\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00009, loss_test:0.10108, lr:8.69e-03, fs:0.71351 (r=0.667,p=0.767),  time:31.851, tt:1688.111\n",
      "Ep:53, loss:0.00009, loss_test:0.10059, lr:8.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:31.832, tt:1718.907\n",
      "Ep:54, loss:0.00008, loss_test:0.09452, lr:8.69e-03, fs:0.76344 (r=0.717,p=0.816),  time:31.824, tt:1750.341\n",
      "Ep:55, loss:0.00009, loss_test:0.10148, lr:8.69e-03, fs:0.74286 (r=0.657,p=0.855),  time:31.848, tt:1783.506\n",
      "Ep:56, loss:0.00008, loss_test:0.09228, lr:8.69e-03, fs:0.74468 (r=0.707,p=0.787),  time:31.858, tt:1815.925\n",
      "Ep:57, loss:0.00008, loss_test:0.09931, lr:8.69e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.851, tt:1847.369\n",
      "Ep:58, loss:0.00007, loss_test:0.09169, lr:8.69e-03, fs:0.80851 (r=0.768,p=0.854),  time:31.862, tt:1879.840\n",
      "Ep:59, loss:0.00007, loss_test:0.09351, lr:8.69e-03, fs:0.82418 (r=0.758,p=0.904),  time:31.858, tt:1911.491\n",
      "Ep:60, loss:0.00006, loss_test:0.09026, lr:8.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.872, tt:1944.202\n",
      "Ep:61, loss:0.00006, loss_test:0.09552, lr:8.69e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.854, tt:1974.940\n",
      "Ep:62, loss:0.00005, loss_test:0.08467, lr:8.69e-03, fs:0.81720 (r=0.768,p=0.874),  time:31.872, tt:2007.958\n",
      "Ep:63, loss:0.00005, loss_test:0.10000, lr:8.60e-03, fs:0.75281 (r=0.677,p=0.848),  time:31.858, tt:2038.902\n",
      "Ep:64, loss:0.00005, loss_test:0.09251, lr:8.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:31.866, tt:2071.277\n",
      "Ep:65, loss:0.00005, loss_test:0.09539, lr:8.43e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.870, tt:2103.406\n",
      "Ep:66, loss:0.00005, loss_test:0.09304, lr:8.35e-03, fs:0.78534 (r=0.758,p=0.815),  time:31.868, tt:2135.163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00006, loss_test:0.08285, lr:8.26e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.871, tt:2167.223\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.10473, lr:8.26e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.876, tt:2199.435\n",
      "Ep:69, loss:0.00005, loss_test:0.07858, lr:8.26e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.863, tt:2230.399\n",
      "Ep:70, loss:0.00005, loss_test:0.11083, lr:8.26e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.866, tt:2262.491\n",
      "Ep:71, loss:0.00004, loss_test:0.07640, lr:8.26e-03, fs:0.82540 (r=0.788,p=0.867),  time:31.861, tt:2293.974\n",
      "Ep:72, loss:0.00004, loss_test:0.10198, lr:8.26e-03, fs:0.75706 (r=0.677,p=0.859),  time:31.862, tt:2325.900\n",
      "Ep:73, loss:0.00004, loss_test:0.08782, lr:8.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.861, tt:2357.720\n",
      "Ep:74, loss:0.00004, loss_test:0.08568, lr:8.26e-03, fs:0.76087 (r=0.707,p=0.824),  time:31.871, tt:2390.339\n",
      "Ep:75, loss:0.00004, loss_test:0.09213, lr:8.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.866, tt:2421.792\n",
      "Ep:76, loss:0.00004, loss_test:0.08485, lr:8.26e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.867, tt:2453.760\n",
      "Ep:77, loss:0.00004, loss_test:0.08303, lr:8.26e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.881, tt:2486.700\n",
      "Ep:78, loss:0.00003, loss_test:0.09233, lr:8.26e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.889, tt:2519.210\n",
      "Ep:79, loss:0.00003, loss_test:0.07934, lr:8.18e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.890, tt:2551.199\n",
      "Ep:80, loss:0.00003, loss_test:0.08999, lr:8.10e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.899, tt:2583.846\n",
      "Ep:81, loss:0.00003, loss_test:0.08808, lr:8.02e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.919, tt:2617.321\n",
      "Ep:82, loss:0.00003, loss_test:0.08383, lr:7.94e-03, fs:0.82682 (r=0.747,p=0.925),  time:31.932, tt:2650.389\n",
      "Ep:83, loss:0.00003, loss_test:0.09218, lr:7.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.933, tt:2682.354\n",
      "Ep:84, loss:0.00003, loss_test:0.08049, lr:7.78e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.926, tt:2713.681\n",
      "Ep:85, loss:0.00003, loss_test:0.09566, lr:7.70e-03, fs:0.77457 (r=0.677,p=0.905),  time:31.918, tt:2744.914\n",
      "Ep:86, loss:0.00002, loss_test:0.08469, lr:7.62e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.919, tt:2776.942\n",
      "Ep:87, loss:0.00002, loss_test:0.08948, lr:7.55e-03, fs:0.77011 (r=0.677,p=0.893),  time:31.922, tt:2809.152\n",
      "Ep:88, loss:0.00002, loss_test:0.09097, lr:7.47e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.921, tt:2840.949\n",
      "Ep:89, loss:0.00002, loss_test:0.08708, lr:7.40e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.962, tt:2876.603\n",
      "Ep:90, loss:0.00002, loss_test:0.09148, lr:7.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.996, tt:2911.594\n",
      "Ep:91, loss:0.00002, loss_test:0.09062, lr:7.25e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.023, tt:2946.153\n",
      "Ep:92, loss:0.00002, loss_test:0.08715, lr:7.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.061, tt:2981.630\n",
      "Ep:93, loss:0.00002, loss_test:0.09142, lr:7.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.082, tt:3015.747\n",
      "Ep:94, loss:0.00002, loss_test:0.08878, lr:7.03e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.107, tt:3050.200\n",
      "Ep:95, loss:0.00002, loss_test:0.08523, lr:6.96e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.136, tt:3085.093\n",
      "Ep:96, loss:0.00002, loss_test:0.09148, lr:6.89e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.176, tt:3121.063\n",
      "Ep:97, loss:0.00002, loss_test:0.09114, lr:6.83e-03, fs:0.79070 (r=0.687,p=0.932),  time:32.216, tt:3157.126\n",
      "Ep:98, loss:0.00002, loss_test:0.08601, lr:6.76e-03, fs:0.80682 (r=0.717,p=0.922),  time:32.235, tt:3191.298\n",
      "Ep:99, loss:0.00002, loss_test:0.09233, lr:6.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.278, tt:3227.753\n",
      "Ep:100, loss:0.00002, loss_test:0.09243, lr:6.62e-03, fs:0.80460 (r=0.707,p=0.933),  time:32.308, tt:3263.076\n",
      "Ep:101, loss:0.00002, loss_test:0.08574, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.351, tt:3299.763\n",
      "Ep:102, loss:0.00002, loss_test:0.09598, lr:6.49e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.380, tt:3335.188\n",
      "Ep:103, loss:0.00002, loss_test:0.08820, lr:6.43e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.413, tt:3370.988\n",
      "Ep:104, loss:0.00002, loss_test:0.08856, lr:6.36e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.446, tt:3406.875\n",
      "Ep:105, loss:0.00001, loss_test:0.09375, lr:6.30e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.479, tt:3442.747\n",
      "Ep:106, loss:0.00001, loss_test:0.08711, lr:6.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.503, tt:3477.812\n",
      "Ep:107, loss:0.00001, loss_test:0.09221, lr:6.17e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.527, tt:3512.969\n",
      "Ep:108, loss:0.00001, loss_test:0.09342, lr:6.11e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.553, tt:3548.239\n",
      "Ep:109, loss:0.00001, loss_test:0.08771, lr:6.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:32.585, tt:3584.364\n",
      "Ep:110, loss:0.00001, loss_test:0.09326, lr:5.99e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.605, tt:3619.184\n",
      "Ep:111, loss:0.00001, loss_test:0.09184, lr:5.93e-03, fs:0.79070 (r=0.687,p=0.932),  time:32.627, tt:3654.217\n",
      "Ep:112, loss:0.00001, loss_test:0.08940, lr:5.87e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.638, tt:3688.094\n",
      "Ep:113, loss:0.00001, loss_test:0.09615, lr:5.81e-03, fs:0.78363 (r=0.677,p=0.931),  time:32.682, tt:3725.770\n",
      "Ep:114, loss:0.00001, loss_test:0.09214, lr:5.75e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.696, tt:3760.048\n",
      "Ep:115, loss:0.00001, loss_test:0.09265, lr:5.70e-03, fs:0.79769 (r=0.697,p=0.932),  time:32.727, tt:3796.352\n",
      "Ep:116, loss:0.00001, loss_test:0.09357, lr:5.64e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.749, tt:3831.668\n",
      "Ep:117, loss:0.00001, loss_test:0.09266, lr:5.58e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.779, tt:3867.936\n",
      "Ep:118, loss:0.00001, loss_test:0.09522, lr:5.53e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.796, tt:3902.671\n",
      "Ep:119, loss:0.00001, loss_test:0.09262, lr:5.47e-03, fs:0.83616 (r=0.747,p=0.949),  time:32.825, tt:3938.970\n",
      "Ep:120, loss:0.00001, loss_test:0.09451, lr:5.42e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.854, tt:3975.320\n",
      "Ep:121, loss:0.00001, loss_test:0.09478, lr:5.36e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.874, tt:4010.627\n",
      "Ep:122, loss:0.00001, loss_test:0.09902, lr:5.31e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.900, tt:4046.759\n",
      "Ep:123, loss:0.00001, loss_test:0.09442, lr:5.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.916, tt:4081.575\n",
      "Ep:124, loss:0.00001, loss_test:0.09791, lr:5.20e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.939, tt:4117.355\n",
      "Ep:125, loss:0.00001, loss_test:0.09379, lr:5.15e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.964, tt:4153.514\n",
      "Ep:126, loss:0.00001, loss_test:0.09894, lr:5.10e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.987, tt:4189.352\n",
      "Ep:127, loss:0.00001, loss_test:0.09394, lr:5.05e-03, fs:0.82486 (r=0.737,p=0.936),  time:33.011, tt:4225.368\n",
      "Ep:128, loss:0.00001, loss_test:0.09793, lr:5.00e-03, fs:0.79532 (r=0.687,p=0.944),  time:33.026, tt:4260.340\n",
      "Ep:129, loss:0.00001, loss_test:0.09419, lr:4.95e-03, fs:0.82081 (r=0.717,p=0.959),  time:33.050, tt:4296.536\n",
      "Ep:130, loss:0.00001, loss_test:0.09780, lr:4.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:33.085, tt:4334.162\n",
      "Ep:131, loss:0.00001, loss_test:0.09761, lr:4.85e-03, fs:0.80000 (r=0.687,p=0.958),  time:33.109, tt:4370.403\n",
      "Ep:132, loss:0.00001, loss_test:0.10075, lr:4.80e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.127, tt:4405.883\n",
      "Ep:133, loss:0.00001, loss_test:0.09495, lr:4.75e-03, fs:0.80233 (r=0.697,p=0.945),  time:33.152, tt:4442.409\n",
      "Ep:134, loss:0.00001, loss_test:0.10403, lr:4.71e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.181, tt:4479.438\n",
      "Ep:135, loss:0.00001, loss_test:0.09372, lr:4.66e-03, fs:0.82955 (r=0.737,p=0.948),  time:33.214, tt:4517.074\n",
      "Ep:136, loss:0.00001, loss_test:0.10412, lr:4.61e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.243, tt:4554.342\n",
      "Ep:137, loss:0.00001, loss_test:0.09624, lr:4.57e-03, fs:0.82955 (r=0.737,p=0.948),  time:33.261, tt:4590.030\n",
      "Ep:138, loss:0.00001, loss_test:0.10380, lr:4.52e-03, fs:0.80240 (r=0.677,p=0.985),  time:33.285, tt:4626.561\n",
      "Ep:139, loss:0.00001, loss_test:0.09682, lr:4.48e-03, fs:0.77381 (r=0.657,p=0.942),  time:33.304, tt:4662.594\n",
      "Ep:140, loss:0.00001, loss_test:0.10300, lr:4.43e-03, fs:0.80240 (r=0.677,p=0.985),  time:33.319, tt:4697.997\n",
      "Ep:141, loss:0.00001, loss_test:0.10139, lr:4.39e-03, fs:0.79762 (r=0.677,p=0.971),  time:33.337, tt:4733.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.09976, lr:4.34e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.348, tt:4768.748\n",
      "Ep:143, loss:0.00001, loss_test:0.10279, lr:4.30e-03, fs:0.80240 (r=0.677,p=0.985),  time:33.361, tt:4804.001\n",
      "Ep:144, loss:0.00001, loss_test:0.10216, lr:4.26e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.371, tt:4838.790\n",
      "Ep:145, loss:0.00001, loss_test:0.10228, lr:4.21e-03, fs:0.79762 (r=0.677,p=0.971),  time:33.380, tt:4873.500\n",
      "Ep:146, loss:0.00001, loss_test:0.10476, lr:4.17e-03, fs:0.80240 (r=0.677,p=0.985),  time:33.396, tt:4909.159\n",
      "Ep:147, loss:0.00001, loss_test:0.10181, lr:4.13e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.412, tt:4945.039\n",
      "Ep:148, loss:0.00001, loss_test:0.10512, lr:4.09e-03, fs:0.80240 (r=0.677,p=0.985),  time:33.426, tt:4980.432\n",
      "Ep:149, loss:0.00001, loss_test:0.10283, lr:4.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:33.447, tt:5017.108\n",
      "Ep:150, loss:0.00001, loss_test:0.10719, lr:4.01e-03, fs:0.80240 (r=0.677,p=0.985),  time:33.456, tt:5051.863\n",
      "Ep:151, loss:0.00001, loss_test:0.10445, lr:3.97e-03, fs:0.80952 (r=0.687,p=0.986),  time:33.479, tt:5088.755\n",
      "Ep:152, loss:0.00001, loss_test:0.10558, lr:3.93e-03, fs:0.79042 (r=0.667,p=0.971),  time:33.499, tt:5125.350\n",
      "Ep:153, loss:0.00001, loss_test:0.10960, lr:3.89e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.514, tt:5161.146\n",
      "Ep:154, loss:0.00001, loss_test:0.10154, lr:3.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:33.533, tt:5197.671\n",
      "Ep:155, loss:0.00001, loss_test:0.10799, lr:3.81e-03, fs:0.79290 (r=0.677,p=0.957),  time:33.543, tt:5232.672\n",
      "Ep:156, loss:0.00001, loss_test:0.10737, lr:3.77e-03, fs:0.80000 (r=0.667,p=1.000),  time:33.560, tt:5268.891\n",
      "Ep:157, loss:0.00001, loss_test:0.10794, lr:3.73e-03, fs:0.79762 (r=0.677,p=0.971),  time:33.588, tt:5306.892\n",
      "Ep:158, loss:0.00001, loss_test:0.10406, lr:3.70e-03, fs:0.79762 (r=0.677,p=0.971),  time:33.610, tt:5343.945\n",
      "Ep:159, loss:0.00001, loss_test:0.10889, lr:3.66e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.636, tt:5381.805\n",
      "Ep:160, loss:0.00001, loss_test:0.11006, lr:3.62e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.656, tt:5418.575\n",
      "Ep:161, loss:0.00001, loss_test:0.10786, lr:3.59e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.680, tt:5456.194\n",
      "Ep:162, loss:0.00001, loss_test:0.10938, lr:3.55e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.701, tt:5493.254\n",
      "Ep:163, loss:0.00001, loss_test:0.10981, lr:3.52e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.716, tt:5529.453\n",
      "Ep:164, loss:0.00001, loss_test:0.11010, lr:3.48e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.737, tt:5566.583\n",
      "Ep:165, loss:0.00001, loss_test:0.10903, lr:3.45e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.744, tt:5601.556\n",
      "Ep:166, loss:0.00001, loss_test:0.11120, lr:3.41e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.760, tt:5637.894\n",
      "Ep:167, loss:0.00001, loss_test:0.10914, lr:3.38e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.763, tt:5672.119\n",
      "Ep:168, loss:0.00001, loss_test:0.11088, lr:3.34e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.771, tt:5707.275\n",
      "Ep:169, loss:0.00001, loss_test:0.10984, lr:3.31e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.784, tt:5743.313\n",
      "Ep:170, loss:0.00001, loss_test:0.11089, lr:3.28e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.795, tt:5779.022\n",
      "Ep:171, loss:0.00001, loss_test:0.10931, lr:3.24e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.813, tt:5815.811\n",
      "Ep:172, loss:0.00001, loss_test:0.11128, lr:3.21e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.830, tt:5852.516\n",
      "Ep:173, loss:0.00001, loss_test:0.11133, lr:3.18e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.841, tt:5888.356\n",
      "Ep:174, loss:0.00001, loss_test:0.10871, lr:3.15e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.852, tt:5924.160\n",
      "Ep:175, loss:0.00001, loss_test:0.11095, lr:3.12e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.886, tt:5963.880\n",
      "Ep:176, loss:0.00000, loss_test:0.11209, lr:3.09e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.901, tt:6000.538\n",
      "Ep:177, loss:0.00000, loss_test:0.10861, lr:3.05e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.910, tt:6036.042\n",
      "Ep:178, loss:0.00000, loss_test:0.11061, lr:3.02e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.923, tt:6072.208\n",
      "Ep:179, loss:0.00000, loss_test:0.11213, lr:2.99e-03, fs:0.80000 (r=0.667,p=1.000),  time:33.938, tt:6108.819\n",
      "Ep:180, loss:0.00000, loss_test:0.10965, lr:2.96e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.947, tt:6144.368\n",
      "Ep:181, loss:0.00000, loss_test:0.10898, lr:2.93e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.962, tt:6181.039\n",
      "Ep:182, loss:0.00000, loss_test:0.11030, lr:2.90e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.975, tt:6217.512\n",
      "Ep:183, loss:0.00000, loss_test:0.11273, lr:2.88e-03, fs:0.80723 (r=0.677,p=1.000),  time:33.991, tt:6254.429\n",
      "Ep:184, loss:0.00000, loss_test:0.10932, lr:2.85e-03, fs:0.80000 (r=0.667,p=1.000),  time:34.010, tt:6291.809\n",
      "Ep:185, loss:0.00000, loss_test:0.11166, lr:2.82e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.022, tt:6328.116\n",
      "Ep:186, loss:0.00000, loss_test:0.11149, lr:2.79e-03, fs:0.80000 (r=0.667,p=1.000),  time:34.030, tt:6363.681\n",
      "Ep:187, loss:0.00000, loss_test:0.11117, lr:2.76e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.043, tt:6400.004\n",
      "Ep:188, loss:0.00000, loss_test:0.10911, lr:2.73e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.053, tt:6436.080\n",
      "Ep:189, loss:0.00000, loss_test:0.11048, lr:2.71e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.069, tt:6473.162\n",
      "Ep:190, loss:0.00000, loss_test:0.11051, lr:2.68e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.086, tt:6510.481\n",
      "Ep:191, loss:0.00000, loss_test:0.10970, lr:2.65e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.097, tt:6546.596\n",
      "Ep:192, loss:0.00000, loss_test:0.11100, lr:2.63e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.105, tt:6582.219\n",
      "Ep:193, loss:0.00000, loss_test:0.11177, lr:2.60e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.115, tt:6618.235\n",
      "Ep:194, loss:0.00000, loss_test:0.11150, lr:2.57e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.124, tt:6654.209\n",
      "Ep:195, loss:0.00000, loss_test:0.11039, lr:2.55e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.151, tt:6693.585\n",
      "Ep:196, loss:0.00000, loss_test:0.11010, lr:2.52e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.163, tt:6730.102\n",
      "Ep:197, loss:0.00000, loss_test:0.11035, lr:2.50e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.172, tt:6766.030\n",
      "Ep:198, loss:0.00000, loss_test:0.11068, lr:2.47e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.186, tt:6802.916\n",
      "Ep:199, loss:0.00000, loss_test:0.11034, lr:2.45e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.202, tt:6840.460\n",
      "Ep:200, loss:0.00000, loss_test:0.11131, lr:2.42e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.221, tt:6878.456\n",
      "Ep:201, loss:0.00000, loss_test:0.10980, lr:2.40e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.235, tt:6915.408\n",
      "Ep:202, loss:0.00000, loss_test:0.11059, lr:2.38e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.246, tt:6951.970\n",
      "Ep:203, loss:0.00000, loss_test:0.11046, lr:2.35e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.256, tt:6988.247\n",
      "Ep:204, loss:0.00000, loss_test:0.11058, lr:2.33e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.245, tt:7020.173\n",
      "Ep:205, loss:0.00000, loss_test:0.11067, lr:2.31e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.205, tt:7046.318\n",
      "Ep:206, loss:0.00000, loss_test:0.11135, lr:2.28e-03, fs:0.80723 (r=0.677,p=1.000),  time:34.176, tt:7074.502\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02419, lr:6.00e-02, fs:0.65487 (r=0.747,p=0.583),  time:28.269, tt:28.269\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02352, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:30.892, tt:61.784\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00005, loss_test:0.02453, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:32.319, tt:96.958\n",
      "Ep:3, loss:0.00005, loss_test:0.02448, lr:6.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:33.147, tt:132.588\n",
      "Ep:4, loss:0.00005, loss_test:0.02436, lr:6.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:33.907, tt:169.535\n",
      "Ep:5, loss:0.00005, loss_test:0.02405, lr:6.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:34.068, tt:204.408\n",
      "Ep:6, loss:0.00005, loss_test:0.02365, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:34.363, tt:240.542\n",
      "Ep:7, loss:0.00005, loss_test:0.02322, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:34.494, tt:275.950\n",
      "Ep:8, loss:0.00005, loss_test:0.02278, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:34.641, tt:311.771\n",
      "Ep:9, loss:0.00005, loss_test:0.02239, lr:6.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:34.851, tt:348.508\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00005, loss_test:0.02214, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:35.009, tt:385.102\n",
      "Ep:11, loss:0.00005, loss_test:0.02190, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:35.106, tt:421.272\n",
      "Ep:12, loss:0.00004, loss_test:0.02201, lr:6.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:35.030, tt:455.396\n",
      "Ep:13, loss:0.00004, loss_test:0.02255, lr:6.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:35.080, tt:491.120\n",
      "Ep:14, loss:0.00004, loss_test:0.02308, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:35.045, tt:525.669\n",
      "Ep:15, loss:0.00004, loss_test:0.02327, lr:6.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:35.036, tt:560.582\n",
      "Ep:16, loss:0.00004, loss_test:0.02318, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:35.214, tt:598.634\n",
      "Ep:17, loss:0.00004, loss_test:0.02307, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:35.172, tt:633.095\n",
      "Ep:18, loss:0.00004, loss_test:0.02291, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:35.224, tt:669.261\n",
      "Ep:19, loss:0.00004, loss_test:0.02251, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:35.236, tt:704.720\n",
      "Ep:20, loss:0.00004, loss_test:0.02199, lr:6.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:35.203, tt:739.273\n",
      "Ep:21, loss:0.00004, loss_test:0.02157, lr:5.94e-02, fs:0.65587 (r=0.818,p=0.547),  time:35.211, tt:774.649\n",
      "Ep:22, loss:0.00004, loss_test:0.02131, lr:5.88e-02, fs:0.66116 (r=0.808,p=0.559),  time:35.173, tt:808.985\n",
      "Ep:23, loss:0.00003, loss_test:0.02092, lr:5.82e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.182, tt:844.366\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.02043, lr:5.82e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.211, tt:880.273\n",
      "Ep:25, loss:0.00003, loss_test:0.02028, lr:5.82e-02, fs:0.67521 (r=0.798,p=0.585),  time:35.219, tt:915.703\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01977, lr:5.82e-02, fs:0.68398 (r=0.798,p=0.598),  time:35.235, tt:951.355\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01935, lr:5.82e-02, fs:0.68722 (r=0.788,p=0.609),  time:35.279, tt:987.818\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01918, lr:5.82e-02, fs:0.69955 (r=0.788,p=0.629),  time:35.190, tt:1020.510\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01890, lr:5.82e-02, fs:0.69333 (r=0.788,p=0.619),  time:35.221, tt:1056.641\n",
      "Ep:30, loss:0.00003, loss_test:0.01831, lr:5.82e-02, fs:0.68778 (r=0.768,p=0.623),  time:35.223, tt:1091.916\n",
      "Ep:31, loss:0.00003, loss_test:0.01840, lr:5.82e-02, fs:0.70320 (r=0.778,p=0.642),  time:35.225, tt:1127.188\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01820, lr:5.82e-02, fs:0.69683 (r=0.778,p=0.631),  time:35.190, tt:1161.272\n",
      "Ep:33, loss:0.00003, loss_test:0.01772, lr:5.82e-02, fs:0.70000 (r=0.778,p=0.636),  time:35.224, tt:1197.603\n",
      "Ep:34, loss:0.00003, loss_test:0.01790, lr:5.82e-02, fs:0.70000 (r=0.778,p=0.636),  time:35.229, tt:1233.011\n",
      "Ep:35, loss:0.00002, loss_test:0.01755, lr:5.82e-02, fs:0.70320 (r=0.778,p=0.642),  time:35.223, tt:1268.029\n",
      "Ep:36, loss:0.00002, loss_test:0.01754, lr:5.82e-02, fs:0.71628 (r=0.778,p=0.664),  time:35.304, tt:1306.251\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01702, lr:5.82e-02, fs:0.71090 (r=0.758,p=0.670),  time:35.317, tt:1342.049\n",
      "Ep:38, loss:0.00002, loss_test:0.01675, lr:5.82e-02, fs:0.73488 (r=0.798,p=0.681),  time:35.291, tt:1376.352\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01635, lr:5.82e-02, fs:0.72464 (r=0.758,p=0.694),  time:35.296, tt:1411.855\n",
      "Ep:40, loss:0.00002, loss_test:0.01626, lr:5.82e-02, fs:0.73934 (r=0.788,p=0.696),  time:35.278, tt:1446.378\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01665, lr:5.82e-02, fs:0.73267 (r=0.747,p=0.718),  time:35.327, tt:1483.750\n",
      "Ep:42, loss:0.00002, loss_test:0.01685, lr:5.82e-02, fs:0.73632 (r=0.747,p=0.725),  time:35.295, tt:1517.702\n",
      "Ep:43, loss:0.00002, loss_test:0.01615, lr:5.82e-02, fs:0.71845 (r=0.747,p=0.692),  time:35.293, tt:1552.884\n",
      "Ep:44, loss:0.00002, loss_test:0.01677, lr:5.82e-02, fs:0.71287 (r=0.727,p=0.699),  time:35.291, tt:1588.084\n",
      "Ep:45, loss:0.00002, loss_test:0.01669, lr:5.82e-02, fs:0.72362 (r=0.727,p=0.720),  time:35.308, tt:1624.188\n",
      "Ep:46, loss:0.00002, loss_test:0.01632, lr:5.82e-02, fs:0.73430 (r=0.768,p=0.704),  time:35.309, tt:1659.529\n",
      "Ep:47, loss:0.00002, loss_test:0.01663, lr:5.82e-02, fs:0.73096 (r=0.727,p=0.735),  time:35.332, tt:1695.943\n",
      "Ep:48, loss:0.00002, loss_test:0.01739, lr:5.82e-02, fs:0.74611 (r=0.727,p=0.766),  time:35.306, tt:1730.001\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01699, lr:5.82e-02, fs:0.74396 (r=0.778,p=0.713),  time:35.291, tt:1764.552\n",
      "Ep:50, loss:0.00002, loss_test:0.01627, lr:5.82e-02, fs:0.73096 (r=0.727,p=0.735),  time:35.300, tt:1800.295\n",
      "Ep:51, loss:0.00002, loss_test:0.01708, lr:5.82e-02, fs:0.76042 (r=0.737,p=0.785),  time:35.305, tt:1835.877\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01756, lr:5.82e-02, fs:0.73632 (r=0.747,p=0.725),  time:35.294, tt:1870.577\n",
      "Ep:53, loss:0.00002, loss_test:0.01665, lr:5.82e-02, fs:0.76440 (r=0.737,p=0.793),  time:35.299, tt:1906.127\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01683, lr:5.82e-02, fs:0.74872 (r=0.737,p=0.760),  time:35.313, tt:1942.235\n",
      "Ep:55, loss:0.00001, loss_test:0.01738, lr:5.82e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.341, tt:1979.105\n",
      "Ep:56, loss:0.00001, loss_test:0.01804, lr:5.82e-02, fs:0.75532 (r=0.717,p=0.798),  time:35.336, tt:2014.152\n",
      "Ep:57, loss:0.00001, loss_test:0.01773, lr:5.82e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.301, tt:2047.429\n",
      "Ep:58, loss:0.00001, loss_test:0.01723, lr:5.82e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.306, tt:2083.051\n",
      "Ep:59, loss:0.00001, loss_test:0.01809, lr:5.82e-02, fs:0.76190 (r=0.727,p=0.800),  time:35.315, tt:2118.887\n",
      "Ep:60, loss:0.00001, loss_test:0.01857, lr:5.82e-02, fs:0.77487 (r=0.747,p=0.804),  time:35.326, tt:2154.863\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01705, lr:5.82e-02, fs:0.76142 (r=0.758,p=0.765),  time:35.337, tt:2190.880\n",
      "Ep:62, loss:0.00001, loss_test:0.01680, lr:5.82e-02, fs:0.76684 (r=0.747,p=0.787),  time:35.348, tt:2226.945\n",
      "Ep:63, loss:0.00001, loss_test:0.01768, lr:5.82e-02, fs:0.78125 (r=0.758,p=0.806),  time:35.349, tt:2262.368\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01792, lr:5.82e-02, fs:0.73958 (r=0.717,p=0.763),  time:35.328, tt:2296.338\n",
      "Ep:65, loss:0.00001, loss_test:0.01765, lr:5.82e-02, fs:0.77249 (r=0.737,p=0.811),  time:35.310, tt:2330.432\n",
      "Ep:66, loss:0.00001, loss_test:0.01756, lr:5.82e-02, fs:0.76842 (r=0.737,p=0.802),  time:35.303, tt:2365.330\n",
      "Ep:67, loss:0.00001, loss_test:0.01885, lr:5.82e-02, fs:0.76190 (r=0.727,p=0.800),  time:35.308, tt:2400.940\n",
      "Ep:68, loss:0.00001, loss_test:0.01874, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.317, tt:2436.897\n",
      "Ep:69, loss:0.00001, loss_test:0.01822, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.314, tt:2471.952\n",
      "Ep:70, loss:0.00001, loss_test:0.01932, lr:5.82e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.295, tt:2505.951\n",
      "Ep:71, loss:0.00001, loss_test:0.01914, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.297, tt:2541.410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.01932, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.297, tt:2576.701\n",
      "Ep:73, loss:0.00001, loss_test:0.01933, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.289, tt:2611.367\n",
      "Ep:74, loss:0.00001, loss_test:0.01979, lr:5.82e-02, fs:0.78723 (r=0.747,p=0.831),  time:35.283, tt:2646.224\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01971, lr:5.82e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.288, tt:2681.866\n",
      "Ep:76, loss:0.00001, loss_test:0.01957, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.275, tt:2716.206\n",
      "Ep:77, loss:0.00001, loss_test:0.01946, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.257, tt:2750.077\n",
      "Ep:78, loss:0.00001, loss_test:0.02033, lr:5.82e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.268, tt:2786.171\n",
      "Ep:79, loss:0.00001, loss_test:0.01967, lr:5.82e-02, fs:0.72131 (r=0.667,p=0.786),  time:35.263, tt:2821.026\n",
      "Ep:80, loss:0.00001, loss_test:0.01864, lr:5.82e-02, fs:0.78075 (r=0.737,p=0.830),  time:35.270, tt:2856.880\n",
      "Ep:81, loss:0.00001, loss_test:0.01854, lr:5.82e-02, fs:0.76842 (r=0.737,p=0.802),  time:35.255, tt:2890.940\n",
      "Ep:82, loss:0.00001, loss_test:0.01833, lr:5.82e-02, fs:0.76190 (r=0.727,p=0.800),  time:35.253, tt:2926.013\n",
      "Ep:83, loss:0.00001, loss_test:0.01956, lr:5.82e-02, fs:0.77249 (r=0.737,p=0.811),  time:35.213, tt:2957.864\n",
      "Ep:84, loss:0.00001, loss_test:0.01941, lr:5.82e-02, fs:0.75936 (r=0.717,p=0.807),  time:35.202, tt:2992.209\n",
      "Ep:85, loss:0.00001, loss_test:0.02012, lr:5.82e-02, fs:0.75410 (r=0.697,p=0.821),  time:35.239, tt:3030.557\n",
      "Ep:86, loss:0.00001, loss_test:0.02159, lr:5.76e-02, fs:0.72928 (r=0.667,p=0.805),  time:35.227, tt:3064.732\n",
      "Ep:87, loss:0.00001, loss_test:0.02046, lr:5.71e-02, fs:0.76087 (r=0.707,p=0.824),  time:35.239, tt:3101.076\n",
      "Ep:88, loss:0.00001, loss_test:0.02047, lr:5.65e-02, fs:0.70718 (r=0.646,p=0.780),  time:35.246, tt:3136.917\n",
      "Ep:89, loss:0.00001, loss_test:0.02036, lr:5.59e-02, fs:0.76503 (r=0.707,p=0.833),  time:35.275, tt:3174.753\n",
      "Ep:90, loss:0.00001, loss_test:0.02005, lr:5.54e-02, fs:0.72928 (r=0.667,p=0.805),  time:35.276, tt:3210.143\n",
      "Ep:91, loss:0.00001, loss_test:0.02044, lr:5.48e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.256, tt:3243.525\n",
      "Ep:92, loss:0.00001, loss_test:0.02159, lr:5.43e-02, fs:0.73333 (r=0.667,p=0.815),  time:35.251, tt:3278.375\n",
      "Ep:93, loss:0.00001, loss_test:0.02103, lr:5.37e-02, fs:0.74860 (r=0.677,p=0.838),  time:35.247, tt:3313.243\n",
      "Ep:94, loss:0.00001, loss_test:0.02050, lr:5.32e-02, fs:0.71111 (r=0.646,p=0.790),  time:35.232, tt:3347.029\n",
      "Ep:95, loss:0.00001, loss_test:0.02205, lr:5.27e-02, fs:0.73143 (r=0.646,p=0.842),  time:35.216, tt:3380.761\n",
      "Ep:96, loss:0.00001, loss_test:0.02225, lr:5.21e-02, fs:0.72626 (r=0.657,p=0.812),  time:35.219, tt:3416.227\n",
      "Ep:97, loss:0.00001, loss_test:0.02143, lr:5.16e-02, fs:0.70520 (r=0.616,p=0.824),  time:35.222, tt:3451.715\n",
      "Ep:98, loss:0.00000, loss_test:0.02158, lr:5.11e-02, fs:0.72000 (r=0.636,p=0.829),  time:35.214, tt:3486.232\n",
      "Ep:99, loss:0.00000, loss_test:0.02201, lr:5.06e-02, fs:0.68571 (r=0.606,p=0.789),  time:35.216, tt:3521.587\n",
      "Ep:100, loss:0.00000, loss_test:0.02335, lr:5.01e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.244, tt:3559.687\n",
      "Ep:101, loss:0.00000, loss_test:0.02375, lr:4.96e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.234, tt:3593.898\n",
      "Ep:102, loss:0.00000, loss_test:0.02302, lr:4.91e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.227, tt:3628.346\n",
      "Ep:103, loss:0.00000, loss_test:0.02314, lr:4.86e-02, fs:0.69364 (r=0.606,p=0.811),  time:35.222, tt:3663.038\n",
      "Ep:104, loss:0.00000, loss_test:0.02423, lr:4.81e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.219, tt:3697.960\n",
      "Ep:105, loss:0.00000, loss_test:0.02442, lr:4.76e-02, fs:0.69364 (r=0.606,p=0.811),  time:35.222, tt:3733.517\n",
      "Ep:106, loss:0.00000, loss_test:0.02321, lr:4.71e-02, fs:0.69364 (r=0.606,p=0.811),  time:35.221, tt:3768.695\n",
      "Ep:107, loss:0.00000, loss_test:0.02390, lr:4.67e-02, fs:0.69767 (r=0.606,p=0.822),  time:35.221, tt:3803.919\n",
      "Ep:108, loss:0.00000, loss_test:0.02503, lr:4.62e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.228, tt:3839.806\n",
      "Ep:109, loss:0.00000, loss_test:0.02497, lr:4.57e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.240, tt:3876.437\n",
      "Ep:110, loss:0.00000, loss_test:0.02495, lr:4.53e-02, fs:0.70588 (r=0.606,p=0.845),  time:35.225, tt:3909.967\n",
      "Ep:111, loss:0.00000, loss_test:0.02500, lr:4.48e-02, fs:0.69364 (r=0.606,p=0.811),  time:35.229, tt:3945.604\n",
      "Ep:112, loss:0.00000, loss_test:0.02528, lr:4.44e-02, fs:0.69364 (r=0.606,p=0.811),  time:35.239, tt:3982.020\n",
      "Ep:113, loss:0.00000, loss_test:0.02621, lr:4.39e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.234, tt:4016.689\n",
      "Ep:114, loss:0.00000, loss_test:0.02570, lr:4.35e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.229, tt:4051.385\n",
      "Ep:115, loss:0.00000, loss_test:0.02559, lr:4.31e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.224, tt:4085.975\n",
      "Ep:116, loss:0.00000, loss_test:0.02626, lr:4.26e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.216, tt:4120.292\n",
      "Ep:117, loss:0.00000, loss_test:0.02604, lr:4.22e-02, fs:0.69364 (r=0.606,p=0.811),  time:35.201, tt:4153.762\n",
      "Ep:118, loss:0.00000, loss_test:0.02660, lr:4.18e-02, fs:0.70588 (r=0.606,p=0.845),  time:35.178, tt:4186.192\n",
      "Ep:119, loss:0.00000, loss_test:0.02670, lr:4.14e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.196, tt:4223.536\n",
      "Ep:120, loss:0.00000, loss_test:0.02646, lr:4.10e-02, fs:0.70175 (r=0.606,p=0.833),  time:35.185, tt:4257.416\n",
      "Ep:121, loss:0.00000, loss_test:0.02691, lr:4.05e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.178, tt:4291.753\n",
      "Ep:122, loss:0.00000, loss_test:0.02700, lr:4.01e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.173, tt:4326.255\n",
      "Ep:123, loss:0.00000, loss_test:0.02721, lr:3.97e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.167, tt:4360.714\n",
      "Ep:124, loss:0.00000, loss_test:0.02738, lr:3.93e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.165, tt:4395.611\n",
      "Ep:125, loss:0.00000, loss_test:0.02729, lr:3.89e-02, fs:0.70588 (r=0.606,p=0.845),  time:35.162, tt:4430.385\n",
      "Ep:126, loss:0.00000, loss_test:0.02735, lr:3.86e-02, fs:0.71006 (r=0.606,p=0.857),  time:35.152, tt:4464.345\n",
      "Ep:127, loss:0.00000, loss_test:0.02766, lr:3.82e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.152, tt:4499.490\n",
      "Ep:128, loss:0.00000, loss_test:0.02749, lr:3.78e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.151, tt:4534.534\n",
      "Ep:129, loss:0.00000, loss_test:0.02780, lr:3.74e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.157, tt:4570.374\n",
      "Ep:130, loss:0.00000, loss_test:0.02802, lr:3.70e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.145, tt:4604.050\n",
      "Ep:131, loss:0.00000, loss_test:0.02805, lr:3.67e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.145, tt:4639.162\n",
      "Ep:132, loss:0.00000, loss_test:0.02802, lr:3.63e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.137, tt:4673.170\n",
      "Ep:133, loss:0.00000, loss_test:0.02850, lr:3.59e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.127, tt:4707.080\n",
      "Ep:134, loss:0.00000, loss_test:0.02881, lr:3.56e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.135, tt:4743.289\n",
      "Ep:135, loss:0.00000, loss_test:0.02864, lr:3.52e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.122, tt:4776.525\n",
      "Ep:136, loss:0.00000, loss_test:0.02889, lr:3.49e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.126, tt:4812.239\n",
      "Ep:137, loss:0.00000, loss_test:0.02824, lr:3.45e-02, fs:0.71856 (r=0.606,p=0.882),  time:35.134, tt:4848.526\n",
      "Ep:138, loss:0.00000, loss_test:0.02899, lr:3.42e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.134, tt:4883.640\n",
      "Ep:139, loss:0.00000, loss_test:0.02906, lr:3.38e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.136, tt:4919.107\n",
      "Ep:140, loss:0.00000, loss_test:0.02916, lr:3.35e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.126, tt:4952.743\n",
      "Ep:141, loss:0.00000, loss_test:0.02949, lr:3.32e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.130, tt:4988.415\n",
      "Ep:142, loss:0.00000, loss_test:0.02918, lr:3.28e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.134, tt:5024.227\n",
      "Ep:143, loss:0.00000, loss_test:0.02939, lr:3.25e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.132, tt:5059.035\n",
      "Ep:144, loss:0.00000, loss_test:0.02968, lr:3.22e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.132, tt:5094.091\n",
      "Ep:145, loss:0.00000, loss_test:0.02943, lr:3.19e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.120, tt:5127.563\n",
      "Ep:146, loss:0.00000, loss_test:0.02972, lr:3.15e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.122, tt:5162.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.02977, lr:3.12e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.127, tt:5198.769\n",
      "Ep:148, loss:0.00000, loss_test:0.03022, lr:3.09e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.123, tt:5233.341\n",
      "Ep:149, loss:0.00000, loss_test:0.03013, lr:3.06e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.114, tt:5267.154\n",
      "Ep:150, loss:0.00000, loss_test:0.02981, lr:3.03e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.109, tt:5301.499\n",
      "Ep:151, loss:0.00000, loss_test:0.03055, lr:3.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.106, tt:5336.135\n",
      "Ep:152, loss:0.00000, loss_test:0.03038, lr:2.97e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.106, tt:5371.269\n",
      "Ep:153, loss:0.00000, loss_test:0.03033, lr:2.94e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.107, tt:5406.406\n",
      "Ep:154, loss:0.00000, loss_test:0.03058, lr:2.91e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.114, tt:5442.631\n",
      "Ep:155, loss:0.00000, loss_test:0.03057, lr:2.88e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.115, tt:5478.000\n",
      "Ep:156, loss:0.00000, loss_test:0.03115, lr:2.85e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.114, tt:5512.820\n",
      "Ep:157, loss:0.00000, loss_test:0.03049, lr:2.82e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.120, tt:5548.937\n",
      "Ep:158, loss:0.00000, loss_test:0.03040, lr:2.80e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.118, tt:5583.724\n",
      "Ep:159, loss:0.00000, loss_test:0.03116, lr:2.77e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.119, tt:5618.992\n",
      "Ep:160, loss:0.00000, loss_test:0.03051, lr:2.74e-02, fs:0.67500 (r=0.545,p=0.885),  time:35.119, tt:5654.200\n",
      "Ep:161, loss:0.00000, loss_test:0.03106, lr:2.71e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.123, tt:5689.880\n",
      "Ep:162, loss:0.00000, loss_test:0.03075, lr:2.69e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.130, tt:5726.268\n",
      "Ep:163, loss:0.00000, loss_test:0.03087, lr:2.66e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.133, tt:5761.736\n",
      "Ep:164, loss:0.00000, loss_test:0.03141, lr:2.63e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.137, tt:5797.644\n",
      "Ep:165, loss:0.00000, loss_test:0.03099, lr:2.61e-02, fs:0.71166 (r=0.586,p=0.906),  time:35.137, tt:5832.740\n",
      "Ep:166, loss:0.00000, loss_test:0.03129, lr:2.58e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.137, tt:5867.938\n",
      "Ep:167, loss:0.00000, loss_test:0.03111, lr:2.55e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.143, tt:5904.011\n",
      "Ep:168, loss:0.00000, loss_test:0.03154, lr:2.53e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.146, tt:5939.686\n",
      "Ep:169, loss:0.00000, loss_test:0.03147, lr:2.50e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.155, tt:5976.428\n",
      "Ep:170, loss:0.00000, loss_test:0.03162, lr:2.48e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.157, tt:6011.926\n",
      "Ep:171, loss:0.00000, loss_test:0.03146, lr:2.45e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.157, tt:6046.978\n",
      "Ep:172, loss:0.00000, loss_test:0.03213, lr:2.43e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.158, tt:6082.326\n",
      "Ep:173, loss:0.00000, loss_test:0.03162, lr:2.40e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.162, tt:6118.151\n",
      "Ep:174, loss:0.00000, loss_test:0.03192, lr:2.38e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.165, tt:6153.800\n",
      "Ep:175, loss:0.00000, loss_test:0.03180, lr:2.36e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.166, tt:6189.256\n",
      "Ep:176, loss:0.00000, loss_test:0.03210, lr:2.33e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.168, tt:6224.815\n",
      "Ep:177, loss:0.00000, loss_test:0.03184, lr:2.31e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.172, tt:6260.664\n",
      "Ep:178, loss:0.00000, loss_test:0.03196, lr:2.29e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.169, tt:6295.197\n",
      "Ep:179, loss:0.00000, loss_test:0.03229, lr:2.26e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.172, tt:6330.912\n",
      "Ep:180, loss:0.00000, loss_test:0.03210, lr:2.24e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.172, tt:6366.138\n",
      "Ep:181, loss:0.00000, loss_test:0.03240, lr:2.22e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.168, tt:6400.504\n",
      "Ep:182, loss:0.00000, loss_test:0.03225, lr:2.20e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.173, tt:6436.694\n",
      "Ep:183, loss:0.00000, loss_test:0.03238, lr:2.17e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.178, tt:6472.814\n",
      "Ep:184, loss:0.00000, loss_test:0.03220, lr:2.15e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.180, tt:6508.307\n",
      "Ep:185, loss:0.00000, loss_test:0.03265, lr:2.13e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.182, tt:6543.891\n",
      "Ep:186, loss:0.00000, loss_test:0.03250, lr:2.11e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.178, tt:6578.359\n",
      "Ep:187, loss:0.00000, loss_test:0.03282, lr:2.09e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.179, tt:6613.723\n",
      "Ep:188, loss:0.00000, loss_test:0.03234, lr:2.07e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.175, tt:6648.053\n",
      "Ep:189, loss:0.00000, loss_test:0.03274, lr:2.05e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.179, tt:6683.940\n",
      "Ep:190, loss:0.00000, loss_test:0.03256, lr:2.03e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.172, tt:6717.885\n",
      "Ep:191, loss:0.00000, loss_test:0.03280, lr:2.01e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.173, tt:6753.287\n",
      "Ep:192, loss:0.00000, loss_test:0.03273, lr:1.99e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.173, tt:6788.340\n",
      "Ep:193, loss:0.00000, loss_test:0.03297, lr:1.97e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.171, tt:6823.153\n",
      "Ep:194, loss:0.00000, loss_test:0.03301, lr:1.95e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.166, tt:6857.426\n",
      "Ep:195, loss:0.00000, loss_test:0.03288, lr:1.93e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.169, tt:6893.028\n",
      "Ep:196, loss:0.00000, loss_test:0.03311, lr:1.91e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.166, tt:6927.739\n",
      "Ep:197, loss:0.00000, loss_test:0.03311, lr:1.89e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.164, tt:6962.517\n",
      "Ep:198, loss:0.00000, loss_test:0.03326, lr:1.87e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.170, tt:6998.873\n",
      "Ep:199, loss:0.00000, loss_test:0.03313, lr:1.85e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.166, tt:7033.105\n",
      "Ep:200, loss:0.00000, loss_test:0.03323, lr:1.83e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.159, tt:7067.040\n",
      "Ep:201, loss:0.00000, loss_test:0.03324, lr:1.81e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.162, tt:7102.660\n",
      "Ep:202, loss:0.00000, loss_test:0.03340, lr:1.80e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.164, tt:7138.379\n",
      "Ep:203, loss:0.00000, loss_test:0.03319, lr:1.78e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.165, tt:7173.705\n",
      "Ep:204, loss:0.00000, loss_test:0.03330, lr:1.76e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.167, tt:7209.324\n",
      "Ep:205, loss:0.00000, loss_test:0.03350, lr:1.74e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.166, tt:7244.133\n",
      "Ep:206, loss:0.00000, loss_test:0.03364, lr:1.73e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.168, tt:7279.843\n",
      "Ep:207, loss:0.00000, loss_test:0.03341, lr:1.71e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.171, tt:7315.494\n",
      "Ep:208, loss:0.00000, loss_test:0.03355, lr:1.69e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.151, tt:7346.630\n",
      "Ep:209, loss:0.00000, loss_test:0.03356, lr:1.67e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.110, tt:7373.113\n",
      "Ep:210, loss:0.00000, loss_test:0.03368, lr:1.66e-02, fs:0.71951 (r=0.596,p=0.908),  time:35.074, tt:7400.704\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12688, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:30.954, tt:30.954\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12567, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:33.643, tt:67.285\n",
      "Ep:2, loss:0.00026, loss_test:0.12410, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:34.473, tt:103.420\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12270, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:34.810, tt:139.242\n",
      "Ep:4, loss:0.00026, loss_test:0.12155, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.296, tt:176.480\n",
      "Ep:5, loss:0.00026, loss_test:0.12088, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.636, tt:213.815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00025, loss_test:0.12030, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:36.103, tt:252.718\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11995, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:36.294, tt:290.356\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.11967, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:36.375, tt:327.372\n",
      "Ep:9, loss:0.00024, loss_test:0.11916, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:36.329, tt:363.293\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.11814, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:36.321, tt:399.533\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11721, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:36.204, tt:434.442\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.11626, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:36.280, tt:471.638\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.11557, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:36.236, tt:507.304\n",
      "Ep:14, loss:0.00023, loss_test:0.11483, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:36.204, tt:543.064\n",
      "Ep:15, loss:0.00022, loss_test:0.11509, lr:1.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:36.263, tt:580.203\n",
      "Ep:16, loss:0.00022, loss_test:0.11457, lr:1.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:36.253, tt:616.293\n",
      "Ep:17, loss:0.00022, loss_test:0.11611, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:36.278, tt:653.010\n",
      "Ep:18, loss:0.00021, loss_test:0.11603, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:36.240, tt:688.566\n",
      "Ep:19, loss:0.00021, loss_test:0.11727, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:36.199, tt:723.976\n",
      "Ep:20, loss:0.00020, loss_test:0.11736, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:36.159, tt:759.347\n",
      "Ep:21, loss:0.00020, loss_test:0.11685, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:36.117, tt:794.570\n",
      "Ep:22, loss:0.00019, loss_test:0.11772, lr:1.00e-02, fs:0.68519 (r=0.747,p=0.632),  time:36.105, tt:830.424\n",
      "Ep:23, loss:0.00019, loss_test:0.11362, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:36.142, tt:867.415\n",
      "Ep:24, loss:0.00018, loss_test:0.11810, lr:9.90e-03, fs:0.72277 (r=0.737,p=0.709),  time:36.105, tt:902.631\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.11080, lr:9.90e-03, fs:0.70476 (r=0.747,p=0.667),  time:36.073, tt:937.908\n",
      "Ep:26, loss:0.00017, loss_test:0.10762, lr:9.90e-03, fs:0.71845 (r=0.747,p=0.692),  time:36.085, tt:974.293\n",
      "Ep:27, loss:0.00017, loss_test:0.10585, lr:9.90e-03, fs:0.73000 (r=0.737,p=0.723),  time:36.145, tt:1012.072\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.09654, lr:9.90e-03, fs:0.74146 (r=0.768,p=0.717),  time:36.117, tt:1047.404\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.09551, lr:9.90e-03, fs:0.75983 (r=0.879,p=0.669),  time:36.088, tt:1082.633\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.09088, lr:9.90e-03, fs:0.79630 (r=0.869,p=0.735),  time:36.050, tt:1117.544\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09380, lr:9.90e-03, fs:0.74611 (r=0.727,p=0.766),  time:36.018, tt:1152.574\n",
      "Ep:32, loss:0.00014, loss_test:0.10157, lr:9.90e-03, fs:0.70103 (r=0.687,p=0.716),  time:36.026, tt:1188.842\n",
      "Ep:33, loss:0.00015, loss_test:0.09007, lr:9.90e-03, fs:0.78704 (r=0.859,p=0.726),  time:36.040, tt:1225.347\n",
      "Ep:34, loss:0.00015, loss_test:0.09116, lr:9.90e-03, fs:0.75676 (r=0.848,p=0.683),  time:36.016, tt:1260.567\n",
      "Ep:35, loss:0.00013, loss_test:0.08668, lr:9.90e-03, fs:0.80189 (r=0.859,p=0.752),  time:36.048, tt:1297.741\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.08703, lr:9.90e-03, fs:0.80189 (r=0.859,p=0.752),  time:36.010, tt:1332.388\n",
      "Ep:37, loss:0.00012, loss_test:0.08661, lr:9.90e-03, fs:0.74372 (r=0.747,p=0.740),  time:35.988, tt:1367.562\n",
      "Ep:38, loss:0.00011, loss_test:0.08720, lr:9.90e-03, fs:0.83000 (r=0.838,p=0.822),  time:35.951, tt:1402.083\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08542, lr:9.90e-03, fs:0.78704 (r=0.859,p=0.726),  time:35.946, tt:1437.838\n",
      "Ep:40, loss:0.00010, loss_test:0.08762, lr:9.90e-03, fs:0.77895 (r=0.747,p=0.813),  time:35.973, tt:1474.878\n",
      "Ep:41, loss:0.00011, loss_test:0.08537, lr:9.90e-03, fs:0.79412 (r=0.818,p=0.771),  time:35.944, tt:1509.663\n",
      "Ep:42, loss:0.00010, loss_test:0.08477, lr:9.90e-03, fs:0.81773 (r=0.838,p=0.798),  time:35.931, tt:1545.048\n",
      "Ep:43, loss:0.00009, loss_test:0.09818, lr:9.90e-03, fs:0.75936 (r=0.717,p=0.807),  time:35.911, tt:1580.081\n",
      "Ep:44, loss:0.00009, loss_test:0.08381, lr:9.90e-03, fs:0.75510 (r=0.747,p=0.763),  time:35.920, tt:1616.420\n",
      "Ep:45, loss:0.00008, loss_test:0.07668, lr:9.90e-03, fs:0.85854 (r=0.889,p=0.830),  time:35.934, tt:1652.971\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.08107, lr:9.90e-03, fs:0.80976 (r=0.838,p=0.783),  time:35.955, tt:1689.886\n",
      "Ep:47, loss:0.00008, loss_test:0.09066, lr:9.90e-03, fs:0.80645 (r=0.758,p=0.862),  time:35.941, tt:1725.181\n",
      "Ep:48, loss:0.00011, loss_test:0.08413, lr:9.90e-03, fs:0.79621 (r=0.848,p=0.750),  time:35.919, tt:1760.037\n",
      "Ep:49, loss:0.00010, loss_test:0.09024, lr:9.90e-03, fs:0.77083 (r=0.747,p=0.796),  time:35.927, tt:1796.326\n",
      "Ep:50, loss:0.00010, loss_test:0.08040, lr:9.90e-03, fs:0.77828 (r=0.869,p=0.705),  time:35.932, tt:1832.547\n",
      "Ep:51, loss:0.00009, loss_test:0.09133, lr:9.90e-03, fs:0.79570 (r=0.747,p=0.851),  time:35.941, tt:1868.941\n",
      "Ep:52, loss:0.00011, loss_test:0.08259, lr:9.90e-03, fs:0.77725 (r=0.828,p=0.732),  time:35.940, tt:1904.833\n",
      "Ep:53, loss:0.00010, loss_test:0.07896, lr:9.90e-03, fs:0.82587 (r=0.838,p=0.814),  time:35.936, tt:1940.560\n",
      "Ep:54, loss:0.00008, loss_test:0.08684, lr:9.90e-03, fs:0.78919 (r=0.737,p=0.849),  time:35.920, tt:1975.612\n",
      "Ep:55, loss:0.00007, loss_test:0.08405, lr:9.90e-03, fs:0.83838 (r=0.838,p=0.838),  time:35.929, tt:2012.032\n",
      "Ep:56, loss:0.00007, loss_test:0.07457, lr:9.90e-03, fs:0.82075 (r=0.879,p=0.770),  time:35.945, tt:2048.863\n",
      "Ep:57, loss:0.00007, loss_test:0.08550, lr:9.80e-03, fs:0.83938 (r=0.818,p=0.862),  time:35.921, tt:2083.427\n",
      "Ep:58, loss:0.00007, loss_test:0.07759, lr:9.70e-03, fs:0.80374 (r=0.869,p=0.748),  time:35.911, tt:2118.750\n",
      "Ep:59, loss:0.00006, loss_test:0.09200, lr:9.61e-03, fs:0.78495 (r=0.737,p=0.839),  time:35.921, tt:2155.249\n",
      "Ep:60, loss:0.00006, loss_test:0.07860, lr:9.51e-03, fs:0.84729 (r=0.869,p=0.827),  time:35.908, tt:2190.396\n",
      "Ep:61, loss:0.00006, loss_test:0.07708, lr:9.41e-03, fs:0.80769 (r=0.848,p=0.771),  time:35.881, tt:2224.647\n",
      "Ep:62, loss:0.00005, loss_test:0.08405, lr:9.32e-03, fs:0.81633 (r=0.808,p=0.825),  time:35.890, tt:2261.097\n",
      "Ep:63, loss:0.00005, loss_test:0.08111, lr:9.23e-03, fs:0.81407 (r=0.818,p=0.810),  time:35.885, tt:2296.665\n",
      "Ep:64, loss:0.00005, loss_test:0.08016, lr:9.14e-03, fs:0.76142 (r=0.758,p=0.765),  time:35.890, tt:2332.871\n",
      "Ep:65, loss:0.00005, loss_test:0.08584, lr:9.04e-03, fs:0.79365 (r=0.758,p=0.833),  time:35.909, tt:2370.019\n",
      "Ep:66, loss:0.00004, loss_test:0.08122, lr:8.95e-03, fs:0.82412 (r=0.828,p=0.820),  time:35.921, tt:2406.689\n",
      "Ep:67, loss:0.00004, loss_test:0.08259, lr:8.86e-03, fs:0.79167 (r=0.768,p=0.817),  time:35.925, tt:2442.924\n",
      "Ep:68, loss:0.00004, loss_test:0.08256, lr:8.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:35.931, tt:2479.256\n",
      "Ep:69, loss:0.00004, loss_test:0.08312, lr:8.69e-03, fs:0.78756 (r=0.768,p=0.809),  time:35.942, tt:2515.906\n",
      "Ep:70, loss:0.00004, loss_test:0.08054, lr:8.60e-03, fs:0.84577 (r=0.859,p=0.833),  time:35.969, tt:2553.815\n",
      "Ep:71, loss:0.00004, loss_test:0.09031, lr:8.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:35.970, tt:2589.858\n",
      "Ep:72, loss:0.00004, loss_test:0.08769, lr:8.43e-03, fs:0.78919 (r=0.737,p=0.849),  time:35.965, tt:2625.426\n",
      "Ep:73, loss:0.00003, loss_test:0.07830, lr:8.35e-03, fs:0.82234 (r=0.818,p=0.827),  time:35.955, tt:2660.678\n",
      "Ep:74, loss:0.00003, loss_test:0.08415, lr:8.26e-03, fs:0.83598 (r=0.798,p=0.878),  time:35.951, tt:2696.334\n",
      "Ep:75, loss:0.00003, loss_test:0.08819, lr:8.18e-03, fs:0.80628 (r=0.778,p=0.837),  time:35.959, tt:2732.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00003, loss_test:0.08592, lr:8.10e-03, fs:0.80851 (r=0.768,p=0.854),  time:35.956, tt:2768.609\n",
      "Ep:77, loss:0.00003, loss_test:0.08462, lr:8.02e-03, fs:0.83158 (r=0.798,p=0.868),  time:35.952, tt:2804.274\n",
      "Ep:78, loss:0.00003, loss_test:0.08592, lr:7.94e-03, fs:0.79570 (r=0.747,p=0.851),  time:35.949, tt:2839.977\n",
      "Ep:79, loss:0.00003, loss_test:0.08727, lr:7.86e-03, fs:0.81053 (r=0.778,p=0.846),  time:35.980, tt:2878.379\n",
      "Ep:80, loss:0.00003, loss_test:0.09414, lr:7.78e-03, fs:0.79558 (r=0.727,p=0.878),  time:35.975, tt:2914.001\n",
      "Ep:81, loss:0.00003, loss_test:0.08017, lr:7.70e-03, fs:0.83158 (r=0.798,p=0.868),  time:36.007, tt:2952.548\n",
      "Ep:82, loss:0.00002, loss_test:0.08349, lr:7.62e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.009, tt:2988.762\n",
      "Ep:83, loss:0.00002, loss_test:0.08849, lr:7.55e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.990, tt:3023.146\n",
      "Ep:84, loss:0.00002, loss_test:0.09111, lr:7.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.989, tt:3059.093\n",
      "Ep:85, loss:0.00002, loss_test:0.08557, lr:7.40e-03, fs:0.82979 (r=0.788,p=0.876),  time:36.004, tt:3096.358\n",
      "Ep:86, loss:0.00002, loss_test:0.09305, lr:7.32e-03, fs:0.77966 (r=0.697,p=0.885),  time:35.998, tt:3131.797\n",
      "Ep:87, loss:0.00002, loss_test:0.09288, lr:7.25e-03, fs:0.77095 (r=0.697,p=0.863),  time:35.964, tt:3164.805\n",
      "Ep:88, loss:0.00002, loss_test:0.08759, lr:7.18e-03, fs:0.81283 (r=0.768,p=0.864),  time:35.958, tt:3200.251\n",
      "Ep:89, loss:0.00002, loss_test:0.08795, lr:7.11e-03, fs:0.80663 (r=0.737,p=0.890),  time:35.957, tt:3236.151\n",
      "Ep:90, loss:0.00002, loss_test:0.08452, lr:7.03e-03, fs:0.82796 (r=0.778,p=0.885),  time:35.962, tt:3272.527\n",
      "Ep:91, loss:0.00002, loss_test:0.09088, lr:6.96e-03, fs:0.79558 (r=0.727,p=0.878),  time:35.961, tt:3308.439\n",
      "Ep:92, loss:0.00002, loss_test:0.08996, lr:6.89e-03, fs:0.83871 (r=0.788,p=0.897),  time:35.972, tt:3345.372\n",
      "Ep:93, loss:0.00002, loss_test:0.08921, lr:6.83e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.002, tt:3384.200\n",
      "Ep:94, loss:0.00002, loss_test:0.08579, lr:6.76e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.019, tt:3421.796\n",
      "Ep:95, loss:0.00001, loss_test:0.09176, lr:6.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.027, tt:3458.588\n",
      "Ep:96, loss:0.00001, loss_test:0.08979, lr:6.62e-03, fs:0.81720 (r=0.768,p=0.874),  time:36.040, tt:3495.884\n",
      "Ep:97, loss:0.00001, loss_test:0.08784, lr:6.56e-03, fs:0.86316 (r=0.828,p=0.901),  time:36.041, tt:3531.969\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.09376, lr:6.56e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.056, tt:3569.529\n",
      "Ep:99, loss:0.00001, loss_test:0.08783, lr:6.56e-03, fs:0.85106 (r=0.808,p=0.899),  time:36.068, tt:3606.801\n",
      "Ep:100, loss:0.00001, loss_test:0.08666, lr:6.56e-03, fs:0.85561 (r=0.808,p=0.909),  time:36.070, tt:3643.064\n",
      "Ep:101, loss:0.00001, loss_test:0.09116, lr:6.56e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.063, tt:3678.459\n",
      "Ep:102, loss:0.00001, loss_test:0.08474, lr:6.56e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.059, tt:3714.065\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.09346, lr:6.56e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.057, tt:3749.909\n",
      "Ep:104, loss:0.00001, loss_test:0.08567, lr:6.56e-03, fs:0.87234 (r=0.828,p=0.921),  time:36.060, tt:3786.349\n",
      "Ep:105, loss:0.00001, loss_test:0.08866, lr:6.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.051, tt:3821.405\n",
      "Ep:106, loss:0.00001, loss_test:0.09481, lr:6.56e-03, fs:0.80435 (r=0.747,p=0.871),  time:36.059, tt:3858.333\n",
      "Ep:107, loss:0.00001, loss_test:0.08484, lr:6.56e-03, fs:0.86772 (r=0.828,p=0.911),  time:36.051, tt:3893.521\n",
      "Ep:108, loss:0.00001, loss_test:0.09400, lr:6.56e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.040, tt:3928.324\n",
      "Ep:109, loss:0.00001, loss_test:0.08688, lr:6.56e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.044, tt:3964.836\n",
      "Ep:110, loss:0.00001, loss_test:0.09289, lr:6.56e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.057, tt:4002.377\n",
      "Ep:111, loss:0.00001, loss_test:0.08418, lr:6.56e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.057, tt:4038.439\n",
      "Ep:112, loss:0.00001, loss_test:0.09016, lr:6.56e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.041, tt:4072.594\n",
      "Ep:113, loss:0.00001, loss_test:0.08760, lr:6.56e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.034, tt:4107.821\n",
      "Ep:114, loss:0.00001, loss_test:0.09465, lr:6.49e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.027, tt:4143.094\n",
      "Ep:115, loss:0.00001, loss_test:0.08661, lr:6.43e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.040, tt:4180.623\n",
      "Ep:116, loss:0.00001, loss_test:0.09289, lr:6.36e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.032, tt:4215.791\n",
      "Ep:117, loss:0.00001, loss_test:0.08926, lr:6.30e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.033, tt:4251.883\n",
      "Ep:118, loss:0.00001, loss_test:0.08895, lr:6.24e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.035, tt:4288.197\n",
      "Ep:119, loss:0.00001, loss_test:0.08815, lr:6.17e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.026, tt:4323.120\n",
      "Ep:120, loss:0.00001, loss_test:0.09073, lr:6.11e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.030, tt:4359.668\n",
      "Ep:121, loss:0.00001, loss_test:0.08883, lr:6.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.031, tt:4395.779\n",
      "Ep:122, loss:0.00001, loss_test:0.09246, lr:5.99e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.015, tt:4429.786\n",
      "Ep:123, loss:0.00001, loss_test:0.09132, lr:5.93e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.022, tt:4466.702\n",
      "Ep:124, loss:0.00001, loss_test:0.09092, lr:5.87e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.028, tt:4503.455\n",
      "Ep:125, loss:0.00001, loss_test:0.09094, lr:5.81e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.030, tt:4539.824\n",
      "Ep:126, loss:0.00001, loss_test:0.08970, lr:5.75e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.028, tt:4575.537\n",
      "Ep:127, loss:0.00001, loss_test:0.09262, lr:5.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.029, tt:4611.700\n",
      "Ep:128, loss:0.00001, loss_test:0.09047, lr:5.64e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.027, tt:4647.470\n",
      "Ep:129, loss:0.00001, loss_test:0.09241, lr:5.58e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.022, tt:4682.892\n",
      "Ep:130, loss:0.00001, loss_test:0.08933, lr:5.53e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.022, tt:4718.866\n",
      "Ep:131, loss:0.00001, loss_test:0.09535, lr:5.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.026, tt:4755.380\n",
      "Ep:132, loss:0.00001, loss_test:0.08976, lr:5.42e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.028, tt:4791.710\n",
      "Ep:133, loss:0.00001, loss_test:0.09705, lr:5.36e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.037, tt:4828.987\n",
      "Ep:134, loss:0.00001, loss_test:0.09282, lr:5.31e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.042, tt:4865.734\n",
      "Ep:135, loss:0.00001, loss_test:0.09298, lr:5.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.041, tt:4901.599\n",
      "Ep:136, loss:0.00001, loss_test:0.09197, lr:5.20e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.059, tt:4940.120\n",
      "Ep:137, loss:0.00001, loss_test:0.09748, lr:5.15e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.063, tt:4976.636\n",
      "Ep:138, loss:0.00001, loss_test:0.08996, lr:5.10e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.067, tt:5013.299\n",
      "Ep:139, loss:0.00001, loss_test:0.09944, lr:5.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.065, tt:5049.051\n",
      "Ep:140, loss:0.00001, loss_test:0.09214, lr:5.00e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.066, tt:5085.358\n",
      "Ep:141, loss:0.00001, loss_test:0.09884, lr:4.95e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.065, tt:5121.271\n",
      "Ep:142, loss:0.00001, loss_test:0.09127, lr:4.90e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.062, tt:5156.884\n",
      "Ep:143, loss:0.00001, loss_test:0.09530, lr:4.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.065, tt:5193.334\n",
      "Ep:144, loss:0.00001, loss_test:0.10504, lr:4.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.070, tt:5230.100\n",
      "Ep:145, loss:0.00001, loss_test:0.09496, lr:4.75e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.072, tt:5266.550\n",
      "Ep:146, loss:0.00001, loss_test:0.10803, lr:4.71e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.071, tt:5302.393\n",
      "Ep:147, loss:0.00001, loss_test:0.09221, lr:4.66e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.076, tt:5339.258\n",
      "Ep:148, loss:0.00001, loss_test:0.10186, lr:4.61e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.077, tt:5375.477\n",
      "Ep:149, loss:0.00001, loss_test:0.09984, lr:4.57e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.073, tt:5410.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00001, loss_test:0.08794, lr:4.52e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.067, tt:5446.166\n",
      "Ep:151, loss:0.00001, loss_test:0.10173, lr:4.48e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.066, tt:5482.089\n",
      "Ep:152, loss:0.00001, loss_test:0.09963, lr:4.43e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.054, tt:5516.323\n",
      "Ep:153, loss:0.00001, loss_test:0.09224, lr:4.39e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.054, tt:5552.261\n",
      "Ep:154, loss:0.00001, loss_test:0.09838, lr:4.34e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.050, tt:5587.744\n",
      "Ep:155, loss:0.00001, loss_test:0.09750, lr:4.30e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.054, tt:5624.435\n",
      "Ep:156, loss:0.00001, loss_test:0.09774, lr:4.26e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.051, tt:5660.003\n",
      "Ep:157, loss:0.00001, loss_test:0.09799, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.051, tt:5696.064\n",
      "Ep:158, loss:0.00000, loss_test:0.09713, lr:4.17e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.049, tt:5731.768\n",
      "Ep:159, loss:0.00000, loss_test:0.09860, lr:4.13e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.051, tt:5768.201\n",
      "Ep:160, loss:0.00000, loss_test:0.09753, lr:4.09e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.051, tt:5804.176\n",
      "Ep:161, loss:0.00000, loss_test:0.10169, lr:4.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.054, tt:5840.816\n",
      "Ep:162, loss:0.00000, loss_test:0.09888, lr:4.01e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.047, tt:5875.730\n",
      "Ep:163, loss:0.00001, loss_test:0.09886, lr:3.97e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.055, tt:5912.956\n",
      "Ep:164, loss:0.00000, loss_test:0.10062, lr:3.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.058, tt:5949.626\n",
      "Ep:165, loss:0.00000, loss_test:0.10182, lr:3.89e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.058, tt:5985.553\n",
      "Ep:166, loss:0.00000, loss_test:0.10061, lr:3.85e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.057, tt:6021.454\n",
      "Ep:167, loss:0.00000, loss_test:0.10133, lr:3.81e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.060, tt:6058.078\n",
      "Ep:168, loss:0.00000, loss_test:0.09796, lr:3.77e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.070, tt:6095.756\n",
      "Ep:169, loss:0.00000, loss_test:0.10111, lr:3.73e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.079, tt:6133.458\n",
      "Ep:170, loss:0.00000, loss_test:0.09975, lr:3.70e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.077, tt:6169.217\n",
      "Ep:171, loss:0.00000, loss_test:0.10196, lr:3.66e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.074, tt:6204.762\n",
      "Ep:172, loss:0.00000, loss_test:0.10355, lr:3.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.077, tt:6241.393\n",
      "Ep:173, loss:0.00000, loss_test:0.10340, lr:3.59e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.092, tt:6279.947\n",
      "Ep:174, loss:0.00000, loss_test:0.10128, lr:3.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.096, tt:6316.787\n",
      "Ep:175, loss:0.00000, loss_test:0.10143, lr:3.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.096, tt:6352.847\n",
      "Ep:176, loss:0.00000, loss_test:0.10236, lr:3.48e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.099, tt:6389.450\n",
      "Ep:177, loss:0.00000, loss_test:0.10333, lr:3.45e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.091, tt:6424.238\n",
      "Ep:178, loss:0.00000, loss_test:0.10175, lr:3.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.085, tt:6459.160\n",
      "Ep:179, loss:0.00000, loss_test:0.10251, lr:3.38e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.090, tt:6496.174\n",
      "Ep:180, loss:0.00000, loss_test:0.10196, lr:3.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.091, tt:6532.486\n",
      "Ep:181, loss:0.00000, loss_test:0.10200, lr:3.31e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.088, tt:6568.000\n",
      "Ep:182, loss:0.00000, loss_test:0.10363, lr:3.28e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.089, tt:6604.322\n",
      "Ep:183, loss:0.00000, loss_test:0.10330, lr:3.24e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.097, tt:6641.772\n",
      "Ep:184, loss:0.00000, loss_test:0.10371, lr:3.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.099, tt:6678.404\n",
      "Ep:185, loss:0.00000, loss_test:0.10316, lr:3.18e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.119, tt:6718.133\n",
      "Ep:186, loss:0.00000, loss_test:0.10181, lr:3.15e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.119, tt:6754.225\n",
      "Ep:187, loss:0.00000, loss_test:0.10396, lr:3.12e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.129, tt:6792.159\n",
      "Ep:188, loss:0.00000, loss_test:0.10599, lr:3.09e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.129, tt:6828.394\n",
      "Ep:189, loss:0.00000, loss_test:0.10544, lr:3.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.134, tt:6865.505\n",
      "Ep:190, loss:0.00000, loss_test:0.10186, lr:3.02e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.133, tt:6901.457\n",
      "Ep:191, loss:0.00000, loss_test:0.10274, lr:2.99e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.128, tt:6936.641\n",
      "Ep:192, loss:0.00000, loss_test:0.10679, lr:2.96e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.126, tt:6972.305\n",
      "Ep:193, loss:0.00000, loss_test:0.10590, lr:2.93e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.122, tt:7007.588\n",
      "Ep:194, loss:0.00000, loss_test:0.10782, lr:2.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.123, tt:7043.922\n",
      "Ep:195, loss:0.00000, loss_test:0.10389, lr:2.88e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.122, tt:7079.898\n",
      "Ep:196, loss:0.00000, loss_test:0.10176, lr:2.85e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.115, tt:7114.675\n",
      "Ep:197, loss:0.00000, loss_test:0.10367, lr:2.82e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.114, tt:7150.658\n",
      "Ep:198, loss:0.00000, loss_test:0.10260, lr:2.79e-03, fs:0.79070 (r=0.687,p=0.932),  time:36.114, tt:7186.590\n",
      "Ep:199, loss:0.00000, loss_test:0.10725, lr:2.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.115, tt:7222.908\n",
      "Ep:200, loss:0.00000, loss_test:0.10382, lr:2.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.114, tt:7258.967\n",
      "Ep:201, loss:0.00000, loss_test:0.10337, lr:2.71e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.107, tt:7293.711\n",
      "Ep:202, loss:0.00000, loss_test:0.10396, lr:2.68e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.107, tt:7329.622\n",
      "Ep:203, loss:0.00000, loss_test:0.10118, lr:2.65e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.107, tt:7365.731\n",
      "Ep:204, loss:0.00000, loss_test:0.10407, lr:2.63e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.106, tt:7401.675\n",
      "Ep:205, loss:0.00000, loss_test:0.10515, lr:2.60e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.105, tt:7437.624\n",
      "Ep:206, loss:0.00000, loss_test:0.10352, lr:2.57e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.095, tt:7471.568\n",
      "Ep:207, loss:0.00000, loss_test:0.10470, lr:2.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.090, tt:7506.683\n",
      "Ep:208, loss:0.00000, loss_test:0.10250, lr:2.52e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.066, tt:7537.806\n",
      "Ep:209, loss:0.00000, loss_test:0.10305, lr:2.50e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.017, tt:7563.471\n",
      "Ep:210, loss:0.00000, loss_test:0.10436, lr:2.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.954, tt:7586.332\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02417, lr:6.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:30.043, tt:30.043\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02476, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:30.980, tt:61.961\n",
      "Ep:2, loss:0.00005, loss_test:0.02663, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.124, tt:96.373\n",
      "Ep:3, loss:0.00005, loss_test:0.02655, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:32.618, tt:130.474\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02603, lr:6.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:32.822, tt:164.108\n",
      "Ep:5, loss:0.00005, loss_test:0.02565, lr:6.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:33.140, tt:198.839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00005, loss_test:0.02518, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:33.294, tt:233.055\n",
      "Ep:7, loss:0.00005, loss_test:0.02477, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:33.598, tt:268.783\n",
      "Ep:8, loss:0.00005, loss_test:0.02443, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:33.727, tt:303.547\n",
      "Ep:9, loss:0.00005, loss_test:0.02414, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:33.902, tt:339.016\n",
      "Ep:10, loss:0.00005, loss_test:0.02390, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:34.074, tt:374.812\n",
      "Ep:11, loss:0.00005, loss_test:0.02368, lr:6.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:34.115, tt:409.385\n",
      "Ep:12, loss:0.00005, loss_test:0.02324, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:34.219, tt:444.852\n",
      "Ep:13, loss:0.00005, loss_test:0.02265, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:34.209, tt:478.920\n",
      "Ep:14, loss:0.00005, loss_test:0.02221, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:34.231, tt:513.459\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00005, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:34.294, tt:548.711\n",
      "Ep:16, loss:0.00004, loss_test:0.02191, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:34.334, tt:583.683\n",
      "Ep:17, loss:0.00004, loss_test:0.02204, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:34.370, tt:618.653\n",
      "Ep:18, loss:0.00004, loss_test:0.02212, lr:6.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:34.346, tt:652.569\n",
      "Ep:19, loss:0.00004, loss_test:0.02215, lr:6.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:34.358, tt:687.150\n",
      "Ep:20, loss:0.00004, loss_test:0.02216, lr:6.00e-02, fs:0.63200 (r=0.798,p=0.523),  time:34.393, tt:722.262\n",
      "Ep:21, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:34.397, tt:756.737\n",
      "Ep:22, loss:0.00004, loss_test:0.02239, lr:6.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:34.471, tt:792.832\n",
      "Ep:23, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:34.475, tt:827.389\n",
      "Ep:24, loss:0.00004, loss_test:0.02228, lr:6.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:34.419, tt:860.469\n",
      "Ep:25, loss:0.00004, loss_test:0.02218, lr:6.00e-02, fs:0.64754 (r=0.798,p=0.545),  time:34.452, tt:895.749\n",
      "Ep:26, loss:0.00004, loss_test:0.02198, lr:5.94e-02, fs:0.63934 (r=0.788,p=0.538),  time:34.474, tt:930.788\n",
      "Ep:27, loss:0.00004, loss_test:0.02200, lr:5.88e-02, fs:0.63934 (r=0.788,p=0.538),  time:34.475, tt:965.296\n",
      "Ep:28, loss:0.00004, loss_test:0.02186, lr:5.82e-02, fs:0.62551 (r=0.768,p=0.528),  time:34.482, tt:999.980\n",
      "Ep:29, loss:0.00004, loss_test:0.02174, lr:5.76e-02, fs:0.62810 (r=0.768,p=0.531),  time:34.495, tt:1034.843\n",
      "Ep:30, loss:0.00004, loss_test:0.02137, lr:5.71e-02, fs:0.63071 (r=0.768,p=0.535),  time:34.491, tt:1069.213\n",
      "Ep:31, loss:0.00004, loss_test:0.02129, lr:5.65e-02, fs:0.63598 (r=0.768,p=0.543),  time:34.464, tt:1102.855\n",
      "Ep:32, loss:0.00004, loss_test:0.02097, lr:5.59e-02, fs:0.63866 (r=0.768,p=0.547),  time:34.483, tt:1137.933\n",
      "Ep:33, loss:0.00004, loss_test:0.02059, lr:5.54e-02, fs:0.64167 (r=0.778,p=0.546),  time:34.470, tt:1171.964\n",
      "Ep:34, loss:0.00004, loss_test:0.02055, lr:5.48e-02, fs:0.64167 (r=0.778,p=0.546),  time:34.434, tt:1205.196\n",
      "Ep:35, loss:0.00004, loss_test:0.02031, lr:5.43e-02, fs:0.64979 (r=0.778,p=0.558),  time:34.437, tt:1239.735\n",
      "Ep:36, loss:0.00003, loss_test:0.01996, lr:5.37e-02, fs:0.65812 (r=0.778,p=0.570),  time:34.415, tt:1273.369\n",
      "Ep:37, loss:0.00003, loss_test:0.01977, lr:5.32e-02, fs:0.64407 (r=0.768,p=0.555),  time:34.455, tt:1309.284\n",
      "Ep:38, loss:0.00003, loss_test:0.01934, lr:5.27e-02, fs:0.65812 (r=0.778,p=0.570),  time:34.425, tt:1342.556\n",
      "Ep:39, loss:0.00003, loss_test:0.01903, lr:5.21e-02, fs:0.67811 (r=0.798,p=0.590),  time:34.417, tt:1376.679\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01910, lr:5.21e-02, fs:0.67544 (r=0.778,p=0.597),  time:34.396, tt:1410.256\n",
      "Ep:41, loss:0.00003, loss_test:0.01877, lr:5.21e-02, fs:0.68996 (r=0.798,p=0.608),  time:34.387, tt:1444.272\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01844, lr:5.21e-02, fs:0.68696 (r=0.798,p=0.603),  time:34.402, tt:1479.291\n",
      "Ep:43, loss:0.00003, loss_test:0.01887, lr:5.21e-02, fs:0.67826 (r=0.788,p=0.595),  time:34.390, tt:1513.173\n",
      "Ep:44, loss:0.00003, loss_test:0.01810, lr:5.21e-02, fs:0.69298 (r=0.798,p=0.612),  time:34.429, tt:1549.287\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01808, lr:5.21e-02, fs:0.70852 (r=0.798,p=0.637),  time:34.456, tt:1584.962\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01848, lr:5.21e-02, fs:0.70588 (r=0.788,p=0.639),  time:34.478, tt:1620.452\n",
      "Ep:47, loss:0.00003, loss_test:0.01759, lr:5.21e-02, fs:0.71111 (r=0.808,p=0.635),  time:34.532, tt:1657.557\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01796, lr:5.21e-02, fs:0.70320 (r=0.778,p=0.642),  time:34.558, tt:1693.319\n",
      "Ep:49, loss:0.00003, loss_test:0.01790, lr:5.21e-02, fs:0.70046 (r=0.768,p=0.644),  time:34.585, tt:1729.261\n",
      "Ep:50, loss:0.00003, loss_test:0.01712, lr:5.21e-02, fs:0.70370 (r=0.768,p=0.650),  time:34.615, tt:1765.346\n",
      "Ep:51, loss:0.00003, loss_test:0.01816, lr:5.21e-02, fs:0.70909 (r=0.788,p=0.645),  time:34.630, tt:1800.747\n",
      "Ep:52, loss:0.00003, loss_test:0.01686, lr:5.21e-02, fs:0.71963 (r=0.778,p=0.670),  time:34.673, tt:1837.645\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01751, lr:5.21e-02, fs:0.71362 (r=0.768,p=0.667),  time:34.668, tt:1872.088\n",
      "Ep:54, loss:0.00002, loss_test:0.01697, lr:5.21e-02, fs:0.72038 (r=0.768,p=0.679),  time:34.675, tt:1907.108\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01702, lr:5.21e-02, fs:0.72381 (r=0.768,p=0.685),  time:34.707, tt:1943.611\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01693, lr:5.21e-02, fs:0.72727 (r=0.768,p=0.691),  time:34.721, tt:1979.082\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01690, lr:5.21e-02, fs:0.73333 (r=0.778,p=0.694),  time:34.715, tt:2013.448\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01767, lr:5.21e-02, fs:0.73430 (r=0.768,p=0.704),  time:34.722, tt:2048.616\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01684, lr:5.21e-02, fs:0.73585 (r=0.788,p=0.690),  time:34.731, tt:2083.831\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01891, lr:5.21e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.706, tt:2117.061\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01693, lr:5.21e-02, fs:0.76636 (r=0.828,p=0.713),  time:34.709, tt:2151.933\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01679, lr:5.21e-02, fs:0.81132 (r=0.869,p=0.761),  time:34.715, tt:2187.019\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01891, lr:5.21e-02, fs:0.74627 (r=0.758,p=0.735),  time:34.734, tt:2222.978\n",
      "Ep:64, loss:0.00002, loss_test:0.01740, lr:5.21e-02, fs:0.80769 (r=0.848,p=0.771),  time:34.741, tt:2258.157\n",
      "Ep:65, loss:0.00002, loss_test:0.01852, lr:5.21e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.723, tt:2291.744\n",
      "Ep:66, loss:0.00002, loss_test:0.01998, lr:5.21e-02, fs:0.77157 (r=0.768,p=0.776),  time:34.731, tt:2326.993\n",
      "Ep:67, loss:0.00002, loss_test:0.01925, lr:5.21e-02, fs:0.76768 (r=0.768,p=0.768),  time:34.719, tt:2360.877\n",
      "Ep:68, loss:0.00002, loss_test:0.01906, lr:5.21e-02, fs:0.77157 (r=0.768,p=0.776),  time:34.702, tt:2394.468\n",
      "Ep:69, loss:0.00002, loss_test:0.01919, lr:5.21e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.722, tt:2430.565\n",
      "Ep:70, loss:0.00001, loss_test:0.01817, lr:5.21e-02, fs:0.80952 (r=0.859,p=0.766),  time:34.698, tt:2463.577\n",
      "Ep:71, loss:0.00002, loss_test:0.01807, lr:5.21e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.718, tt:2499.728\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.02183, lr:5.21e-02, fs:0.78351 (r=0.768,p=0.800),  time:34.721, tt:2534.641\n",
      "Ep:73, loss:0.00002, loss_test:0.01806, lr:5.21e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.694, tt:2567.325\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01669, lr:5.21e-02, fs:0.83654 (r=0.879,p=0.798),  time:34.695, tt:2602.124\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00002, loss_test:0.01822, lr:5.21e-02, fs:0.76238 (r=0.778,p=0.748),  time:34.707, tt:2637.713\n",
      "Ep:76, loss:0.00001, loss_test:0.02057, lr:5.21e-02, fs:0.76923 (r=0.758,p=0.781),  time:34.707, tt:2672.410\n",
      "Ep:77, loss:0.00001, loss_test:0.02133, lr:5.21e-02, fs:0.78351 (r=0.768,p=0.800),  time:34.684, tt:2705.325\n",
      "Ep:78, loss:0.00001, loss_test:0.01856, lr:5.21e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.697, tt:2741.033\n",
      "Ep:79, loss:0.00001, loss_test:0.02093, lr:5.21e-02, fs:0.76923 (r=0.758,p=0.781),  time:34.697, tt:2775.747\n",
      "Ep:80, loss:0.00001, loss_test:0.02000, lr:5.21e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.689, tt:2809.795\n",
      "Ep:81, loss:0.00001, loss_test:0.02167, lr:5.21e-02, fs:0.76842 (r=0.737,p=0.802),  time:34.696, tt:2845.075\n",
      "Ep:82, loss:0.00001, loss_test:0.02431, lr:5.21e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.689, tt:2879.148\n",
      "Ep:83, loss:0.00001, loss_test:0.02092, lr:5.21e-02, fs:0.77720 (r=0.758,p=0.798),  time:34.679, tt:2913.067\n",
      "Ep:84, loss:0.00001, loss_test:0.02171, lr:5.21e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.681, tt:2947.863\n",
      "Ep:85, loss:0.00001, loss_test:0.02510, lr:5.21e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.657, tt:2980.530\n",
      "Ep:86, loss:0.00001, loss_test:0.02212, lr:5.16e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.649, tt:3014.482\n",
      "Ep:87, loss:0.00001, loss_test:0.02346, lr:5.11e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.648, tt:3048.985\n",
      "Ep:88, loss:0.00001, loss_test:0.02522, lr:5.06e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.649, tt:3083.769\n",
      "Ep:89, loss:0.00001, loss_test:0.02491, lr:5.01e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.653, tt:3118.743\n",
      "Ep:90, loss:0.00001, loss_test:0.02400, lr:4.96e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.660, tt:3154.070\n",
      "Ep:91, loss:0.00001, loss_test:0.02521, lr:4.91e-02, fs:0.75132 (r=0.717,p=0.789),  time:34.669, tt:3189.522\n",
      "Ep:92, loss:0.00001, loss_test:0.02517, lr:4.86e-02, fs:0.77249 (r=0.737,p=0.811),  time:34.676, tt:3224.826\n",
      "Ep:93, loss:0.00001, loss_test:0.02641, lr:4.81e-02, fs:0.75000 (r=0.697,p=0.812),  time:34.703, tt:3262.051\n",
      "Ep:94, loss:0.00001, loss_test:0.02500, lr:4.76e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.702, tt:3296.666\n",
      "Ep:95, loss:0.00001, loss_test:0.02541, lr:4.71e-02, fs:0.75000 (r=0.697,p=0.812),  time:34.710, tt:3332.166\n",
      "Ep:96, loss:0.00001, loss_test:0.02444, lr:4.67e-02, fs:0.73913 (r=0.687,p=0.800),  time:34.730, tt:3368.848\n",
      "Ep:97, loss:0.00001, loss_test:0.02585, lr:4.62e-02, fs:0.75269 (r=0.707,p=0.805),  time:34.743, tt:3404.787\n",
      "Ep:98, loss:0.00001, loss_test:0.02614, lr:4.57e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.746, tt:3439.877\n",
      "Ep:99, loss:0.00001, loss_test:0.02726, lr:4.53e-02, fs:0.74033 (r=0.677,p=0.817),  time:34.761, tt:3476.090\n",
      "Ep:100, loss:0.00001, loss_test:0.02735, lr:4.48e-02, fs:0.72527 (r=0.667,p=0.795),  time:34.765, tt:3511.308\n",
      "Ep:101, loss:0.00001, loss_test:0.02692, lr:4.44e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.774, tt:3546.960\n",
      "Ep:102, loss:0.00001, loss_test:0.02950, lr:4.39e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.790, tt:3583.398\n",
      "Ep:103, loss:0.00001, loss_test:0.02831, lr:4.35e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.799, tt:3619.058\n",
      "Ep:104, loss:0.00001, loss_test:0.03061, lr:4.31e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.815, tt:3655.614\n",
      "Ep:105, loss:0.00001, loss_test:0.02964, lr:4.26e-02, fs:0.69006 (r=0.596,p=0.819),  time:34.820, tt:3690.966\n",
      "Ep:106, loss:0.00001, loss_test:0.03009, lr:4.22e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.850, tt:3728.994\n",
      "Ep:107, loss:0.00001, loss_test:0.03061, lr:4.18e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.862, tt:3765.074\n",
      "Ep:108, loss:0.00001, loss_test:0.03145, lr:4.14e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.875, tt:3801.329\n",
      "Ep:109, loss:0.00001, loss_test:0.03049, lr:4.10e-02, fs:0.65882 (r=0.566,p=0.789),  time:34.895, tt:3838.417\n",
      "Ep:110, loss:0.00001, loss_test:0.03236, lr:4.05e-02, fs:0.65854 (r=0.545,p=0.831),  time:34.907, tt:3874.717\n",
      "Ep:111, loss:0.00001, loss_test:0.03206, lr:4.01e-02, fs:0.65854 (r=0.545,p=0.831),  time:34.916, tt:3910.617\n",
      "Ep:112, loss:0.00001, loss_test:0.03273, lr:3.97e-02, fs:0.65432 (r=0.535,p=0.841),  time:34.926, tt:3946.635\n",
      "Ep:113, loss:0.00001, loss_test:0.03303, lr:3.93e-02, fs:0.64634 (r=0.535,p=0.815),  time:34.934, tt:3982.507\n",
      "Ep:114, loss:0.00000, loss_test:0.03412, lr:3.89e-02, fs:0.63855 (r=0.535,p=0.791),  time:34.943, tt:4018.458\n",
      "Ep:115, loss:0.00001, loss_test:0.03345, lr:3.86e-02, fs:0.63855 (r=0.535,p=0.791),  time:34.965, tt:4055.896\n",
      "Ep:116, loss:0.00000, loss_test:0.03444, lr:3.82e-02, fs:0.65432 (r=0.535,p=0.841),  time:34.992, tt:4094.034\n",
      "Ep:117, loss:0.00001, loss_test:0.03409, lr:3.78e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.007, tt:4130.846\n",
      "Ep:118, loss:0.00000, loss_test:0.03491, lr:3.74e-02, fs:0.64634 (r=0.535,p=0.815),  time:35.011, tt:4166.258\n",
      "Ep:119, loss:0.00000, loss_test:0.03487, lr:3.70e-02, fs:0.63415 (r=0.525,p=0.800),  time:35.024, tt:4202.826\n",
      "Ep:120, loss:0.00000, loss_test:0.03534, lr:3.67e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.047, tt:4240.675\n",
      "Ep:121, loss:0.00000, loss_test:0.03563, lr:3.63e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.088, tt:4280.769\n",
      "Ep:122, loss:0.00000, loss_test:0.03591, lr:3.59e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.092, tt:4316.288\n",
      "Ep:123, loss:0.00000, loss_test:0.03737, lr:3.56e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.119, tt:4354.712\n",
      "Ep:124, loss:0.00000, loss_test:0.03822, lr:3.52e-02, fs:0.65432 (r=0.535,p=0.841),  time:35.126, tt:4390.708\n",
      "Ep:125, loss:0.00000, loss_test:0.03748, lr:3.49e-02, fs:0.65839 (r=0.535,p=0.855),  time:35.142, tt:4427.896\n",
      "Ep:126, loss:0.00000, loss_test:0.03779, lr:3.45e-02, fs:0.65839 (r=0.535,p=0.855),  time:35.149, tt:4463.924\n",
      "Ep:127, loss:0.00000, loss_test:0.03958, lr:3.42e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.156, tt:4499.928\n",
      "Ep:128, loss:0.00000, loss_test:0.03796, lr:3.38e-02, fs:0.65031 (r=0.535,p=0.828),  time:35.157, tt:4535.243\n",
      "Ep:129, loss:0.00000, loss_test:0.03853, lr:3.35e-02, fs:0.65432 (r=0.535,p=0.841),  time:35.159, tt:4570.661\n",
      "Ep:130, loss:0.00000, loss_test:0.03940, lr:3.32e-02, fs:0.65432 (r=0.535,p=0.841),  time:35.163, tt:4606.343\n",
      "Ep:131, loss:0.00000, loss_test:0.03933, lr:3.28e-02, fs:0.65839 (r=0.535,p=0.855),  time:35.170, tt:4642.485\n",
      "Ep:132, loss:0.00000, loss_test:0.03945, lr:3.25e-02, fs:0.65432 (r=0.535,p=0.841),  time:35.184, tt:4679.419\n",
      "Ep:133, loss:0.00000, loss_test:0.04043, lr:3.22e-02, fs:0.61250 (r=0.495,p=0.803),  time:35.191, tt:4715.536\n",
      "Ep:134, loss:0.00000, loss_test:0.03806, lr:3.19e-02, fs:0.57325 (r=0.455,p=0.776),  time:35.185, tt:4750.019\n",
      "Ep:135, loss:0.00000, loss_test:0.03946, lr:3.15e-02, fs:0.65839 (r=0.535,p=0.855),  time:35.196, tt:4786.588\n",
      "Ep:136, loss:0.00000, loss_test:0.03936, lr:3.12e-02, fs:0.62893 (r=0.505,p=0.833),  time:35.196, tt:4821.877\n",
      "Ep:137, loss:0.00000, loss_test:0.03896, lr:3.09e-02, fs:0.62893 (r=0.505,p=0.833),  time:35.206, tt:4858.489\n",
      "Ep:138, loss:0.00000, loss_test:0.03775, lr:3.06e-02, fs:0.61635 (r=0.495,p=0.817),  time:35.221, tt:4895.651\n",
      "Ep:139, loss:0.00000, loss_test:0.03988, lr:3.03e-02, fs:0.66250 (r=0.535,p=0.869),  time:35.236, tt:4933.000\n",
      "Ep:140, loss:0.00000, loss_test:0.03813, lr:3.00e-02, fs:0.61538 (r=0.485,p=0.842),  time:35.245, tt:4969.478\n",
      "Ep:141, loss:0.00000, loss_test:0.03981, lr:2.97e-02, fs:0.63750 (r=0.515,p=0.836),  time:35.260, tt:5006.891\n",
      "Ep:142, loss:0.00000, loss_test:0.04094, lr:2.94e-02, fs:0.62420 (r=0.495,p=0.845),  time:35.266, tt:5043.107\n",
      "Ep:143, loss:0.00000, loss_test:0.03955, lr:2.91e-02, fs:0.62025 (r=0.495,p=0.831),  time:35.275, tt:5079.543\n",
      "Ep:144, loss:0.00000, loss_test:0.03938, lr:2.88e-02, fs:0.62025 (r=0.495,p=0.831),  time:35.280, tt:5115.619\n",
      "Ep:145, loss:0.00000, loss_test:0.04159, lr:2.85e-02, fs:0.66250 (r=0.535,p=0.869),  time:35.296, tt:5153.273\n",
      "Ep:146, loss:0.00000, loss_test:0.04047, lr:2.82e-02, fs:0.62420 (r=0.495,p=0.845),  time:35.310, tt:5190.504\n",
      "Ep:147, loss:0.00000, loss_test:0.04079, lr:2.80e-02, fs:0.62420 (r=0.495,p=0.845),  time:35.319, tt:5227.177\n",
      "Ep:148, loss:0.00000, loss_test:0.04184, lr:2.77e-02, fs:0.62821 (r=0.495,p=0.860),  time:35.320, tt:5262.621\n",
      "Ep:149, loss:0.00000, loss_test:0.04148, lr:2.74e-02, fs:0.61538 (r=0.485,p=0.842),  time:35.316, tt:5297.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00000, loss_test:0.04098, lr:2.71e-02, fs:0.58278 (r=0.444,p=0.846),  time:35.315, tt:5332.545\n",
      "Ep:151, loss:0.00000, loss_test:0.04336, lr:2.69e-02, fs:0.64968 (r=0.515,p=0.879),  time:35.314, tt:5367.781\n",
      "Ep:152, loss:0.00000, loss_test:0.04257, lr:2.66e-02, fs:0.61935 (r=0.485,p=0.857),  time:35.309, tt:5402.325\n",
      "Ep:153, loss:0.00000, loss_test:0.04239, lr:2.63e-02, fs:0.62338 (r=0.485,p=0.873),  time:35.306, tt:5437.190\n",
      "Ep:154, loss:0.00000, loss_test:0.04286, lr:2.61e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.313, tt:5473.482\n",
      "Ep:155, loss:0.00000, loss_test:0.04350, lr:2.58e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.327, tt:5511.041\n",
      "Ep:156, loss:0.00000, loss_test:0.04325, lr:2.55e-02, fs:0.61039 (r=0.475,p=0.855),  time:35.331, tt:5546.917\n",
      "Ep:157, loss:0.00000, loss_test:0.04354, lr:2.53e-02, fs:0.60131 (r=0.465,p=0.852),  time:35.325, tt:5581.309\n",
      "Ep:158, loss:0.00000, loss_test:0.04428, lr:2.50e-02, fs:0.60526 (r=0.465,p=0.868),  time:35.324, tt:5616.554\n",
      "Ep:159, loss:0.00000, loss_test:0.04398, lr:2.48e-02, fs:0.58278 (r=0.444,p=0.846),  time:35.315, tt:5650.419\n",
      "Ep:160, loss:0.00000, loss_test:0.04254, lr:2.45e-02, fs:0.57333 (r=0.434,p=0.843),  time:35.319, tt:5686.324\n",
      "Ep:161, loss:0.00000, loss_test:0.04332, lr:2.43e-02, fs:0.57333 (r=0.434,p=0.843),  time:35.317, tt:5721.394\n",
      "Ep:162, loss:0.00000, loss_test:0.04554, lr:2.40e-02, fs:0.60927 (r=0.465,p=0.885),  time:35.317, tt:5756.667\n",
      "Ep:163, loss:0.00000, loss_test:0.04416, lr:2.38e-02, fs:0.58667 (r=0.444,p=0.863),  time:35.309, tt:5790.736\n",
      "Ep:164, loss:0.00000, loss_test:0.04327, lr:2.36e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.309, tt:5826.004\n",
      "Ep:165, loss:0.00000, loss_test:0.04536, lr:2.33e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.309, tt:5861.234\n",
      "Ep:166, loss:0.00000, loss_test:0.04516, lr:2.31e-02, fs:0.58667 (r=0.444,p=0.863),  time:35.310, tt:5896.719\n",
      "Ep:167, loss:0.00000, loss_test:0.04434, lr:2.29e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.307, tt:5931.605\n",
      "Ep:168, loss:0.00000, loss_test:0.04564, lr:2.26e-02, fs:0.59603 (r=0.455,p=0.865),  time:35.310, tt:5967.457\n",
      "Ep:169, loss:0.00000, loss_test:0.04516, lr:2.24e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.318, tt:6004.117\n",
      "Ep:170, loss:0.00000, loss_test:0.04527, lr:2.22e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.316, tt:6039.093\n",
      "Ep:171, loss:0.00000, loss_test:0.04546, lr:2.20e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.314, tt:6074.037\n",
      "Ep:172, loss:0.00000, loss_test:0.04466, lr:2.17e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.315, tt:6109.495\n",
      "Ep:173, loss:0.00000, loss_test:0.04517, lr:2.15e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.316, tt:6144.897\n",
      "Ep:174, loss:0.00000, loss_test:0.04666, lr:2.13e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.315, tt:6180.169\n",
      "Ep:175, loss:0.00000, loss_test:0.04525, lr:2.11e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.321, tt:6216.469\n",
      "Ep:176, loss:0.00000, loss_test:0.04484, lr:2.09e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.322, tt:6251.974\n",
      "Ep:177, loss:0.00000, loss_test:0.04606, lr:2.07e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.327, tt:6288.144\n",
      "Ep:178, loss:0.00000, loss_test:0.04551, lr:2.05e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.328, tt:6323.626\n",
      "Ep:179, loss:0.00000, loss_test:0.04597, lr:2.03e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.327, tt:6358.903\n",
      "Ep:180, loss:0.00000, loss_test:0.04629, lr:2.01e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.331, tt:6394.946\n",
      "Ep:181, loss:0.00000, loss_test:0.04638, lr:1.99e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.325, tt:6429.160\n",
      "Ep:182, loss:0.00000, loss_test:0.04605, lr:1.97e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.322, tt:6464.015\n",
      "Ep:183, loss:0.00000, loss_test:0.04713, lr:1.95e-02, fs:0.58667 (r=0.444,p=0.863),  time:35.329, tt:6500.507\n",
      "Ep:184, loss:0.00000, loss_test:0.04662, lr:1.93e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.335, tt:6537.032\n",
      "Ep:185, loss:0.00000, loss_test:0.04696, lr:1.91e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.337, tt:6572.642\n",
      "Ep:186, loss:0.00000, loss_test:0.04672, lr:1.89e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.326, tt:6605.893\n",
      "Ep:187, loss:0.00000, loss_test:0.04721, lr:1.87e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.319, tt:6640.045\n",
      "Ep:188, loss:0.00000, loss_test:0.04714, lr:1.85e-02, fs:0.57718 (r=0.434,p=0.860),  time:35.317, tt:6674.854\n",
      "Ep:189, loss:0.00000, loss_test:0.04709, lr:1.83e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.315, tt:6709.768\n",
      "Ep:190, loss:0.00000, loss_test:0.04782, lr:1.81e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.320, tt:6746.072\n",
      "Ep:191, loss:0.00000, loss_test:0.04735, lr:1.80e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.318, tt:6780.974\n",
      "Ep:192, loss:0.00000, loss_test:0.04711, lr:1.78e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.320, tt:6816.743\n",
      "Ep:193, loss:0.00000, loss_test:0.04742, lr:1.76e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.321, tt:6852.333\n",
      "Ep:194, loss:0.00000, loss_test:0.04771, lr:1.74e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.320, tt:6887.348\n",
      "Ep:195, loss:0.00000, loss_test:0.04771, lr:1.73e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.320, tt:6922.712\n",
      "Ep:196, loss:0.00000, loss_test:0.04799, lr:1.71e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.323, tt:6958.562\n",
      "Ep:197, loss:0.00000, loss_test:0.04780, lr:1.69e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.322, tt:6993.856\n",
      "Ep:198, loss:0.00000, loss_test:0.04795, lr:1.67e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.322, tt:7029.102\n",
      "Ep:199, loss:0.00000, loss_test:0.04832, lr:1.66e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.324, tt:7064.874\n",
      "Ep:200, loss:0.00000, loss_test:0.04785, lr:1.64e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.325, tt:7100.288\n",
      "Ep:201, loss:0.00000, loss_test:0.04812, lr:1.62e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.319, tt:7134.492\n",
      "Ep:202, loss:0.00000, loss_test:0.04859, lr:1.61e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.324, tt:7170.835\n",
      "Ep:203, loss:0.00000, loss_test:0.04869, lr:1.59e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.320, tt:7205.372\n",
      "Ep:204, loss:0.00000, loss_test:0.04811, lr:1.58e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.319, tt:7240.464\n",
      "Ep:205, loss:0.00000, loss_test:0.04834, lr:1.56e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.321, tt:7276.164\n",
      "Ep:206, loss:0.00000, loss_test:0.04864, lr:1.54e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.322, tt:7311.677\n",
      "Ep:207, loss:0.00000, loss_test:0.04889, lr:1.53e-02, fs:0.58503 (r=0.434,p=0.896),  time:35.323, tt:7347.137\n",
      "Ep:208, loss:0.00000, loss_test:0.04907, lr:1.51e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.326, tt:7383.049\n",
      "Ep:209, loss:0.00000, loss_test:0.04817, lr:1.50e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.305, tt:7413.979\n",
      "Ep:210, loss:0.00000, loss_test:0.04899, lr:1.48e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.287, tt:7445.628\n",
      "Ep:211, loss:0.00000, loss_test:0.04921, lr:1.47e-02, fs:0.58108 (r=0.434,p=0.878),  time:35.260, tt:7475.143\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12320, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:28.608, tt:28.608\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12286, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:31.877, tt:63.753\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12259, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:32.543, tt:97.630\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12234, lr:1.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:33.381, tt:133.523\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12187, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:33.998, tt:169.991\n",
      "Ep:5, loss:0.00026, loss_test:0.12134, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:34.300, tt:205.802\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.12067, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:34.805, tt:243.632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00025, loss_test:0.11990, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:35.422, tt:283.376\n",
      "Ep:8, loss:0.00025, loss_test:0.11943, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:35.582, tt:320.234\n",
      "Ep:9, loss:0.00025, loss_test:0.11875, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:35.650, tt:356.503\n",
      "Ep:10, loss:0.00025, loss_test:0.11818, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.839, tt:394.229\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11757, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.843, tt:430.122\n",
      "Ep:12, loss:0.00024, loss_test:0.11704, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:35.905, tt:466.769\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.11625, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:35.976, tt:503.665\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.11527, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:36.108, tt:541.625\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.11441, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:36.087, tt:577.397\n",
      "Ep:16, loss:0.00023, loss_test:0.11344, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:36.077, tt:613.316\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.11226, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:36.148, tt:650.672\n",
      "Ep:18, loss:0.00022, loss_test:0.11106, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:36.179, tt:687.401\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.11009, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:36.256, tt:725.116\n",
      "Ep:20, loss:0.00021, loss_test:0.10900, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:36.276, tt:761.806\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10778, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:36.271, tt:797.972\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.10657, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:36.305, tt:835.016\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.10444, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:36.291, tt:870.995\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.10230, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:36.239, tt:905.966\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.10074, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:36.307, tt:943.971\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.09858, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:36.429, tt:983.591\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.09707, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:36.473, tt:1021.249\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.09461, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:36.460, tt:1057.327\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.09309, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:36.438, tt:1093.147\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.09725, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:36.473, tt:1130.667\n",
      "Ep:31, loss:0.00016, loss_test:0.09070, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:36.464, tt:1166.852\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.08921, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:36.457, tt:1203.087\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.09088, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:36.456, tt:1239.511\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.08812, lr:1.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:36.477, tt:1276.706\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.08760, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:36.510, tt:1314.354\n",
      "Ep:36, loss:0.00013, loss_test:0.08704, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:36.492, tt:1350.193\n",
      "Ep:37, loss:0.00013, loss_test:0.09088, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:36.485, tt:1386.427\n",
      "Ep:38, loss:0.00012, loss_test:0.08939, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:36.484, tt:1422.862\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08790, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:36.483, tt:1459.303\n",
      "Ep:40, loss:0.00012, loss_test:0.08612, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:36.498, tt:1496.428\n",
      "Ep:41, loss:0.00011, loss_test:0.08544, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:36.525, tt:1534.052\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.09080, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:36.537, tt:1571.076\n",
      "Ep:43, loss:0.00010, loss_test:0.08230, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:36.507, tt:1606.328\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00011, loss_test:0.08399, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:36.516, tt:1643.207\n",
      "Ep:45, loss:0.00010, loss_test:0.08757, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:36.541, tt:1680.883\n",
      "Ep:46, loss:0.00009, loss_test:0.08550, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:36.527, tt:1716.779\n",
      "Ep:47, loss:0.00009, loss_test:0.07552, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:36.510, tt:1752.485\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.08321, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:36.540, tt:1790.440\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.07524, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:36.537, tt:1826.873\n",
      "Ep:50, loss:0.00008, loss_test:0.09392, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:36.539, tt:1863.487\n",
      "Ep:51, loss:0.00008, loss_test:0.07656, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:36.561, tt:1901.174\n",
      "Ep:52, loss:0.00008, loss_test:0.07806, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:36.546, tt:1936.951\n",
      "Ep:53, loss:0.00008, loss_test:0.09625, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:36.544, tt:1973.377\n",
      "Ep:54, loss:0.00009, loss_test:0.08014, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:36.561, tt:2010.852\n",
      "Ep:55, loss:0.00009, loss_test:0.08436, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:36.568, tt:2047.800\n",
      "Ep:56, loss:0.00008, loss_test:0.08894, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:36.568, tt:2084.378\n",
      "Ep:57, loss:0.00008, loss_test:0.07104, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:36.561, tt:2120.551\n",
      "Ep:58, loss:0.00007, loss_test:0.08412, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:36.579, tt:2158.171\n",
      "Ep:59, loss:0.00007, loss_test:0.08634, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:36.575, tt:2194.516\n",
      "Ep:60, loss:0.00007, loss_test:0.08599, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:36.617, tt:2233.623\n",
      "Ep:61, loss:0.00007, loss_test:0.07940, lr:9.80e-03, fs:0.84058 (r=0.879,p=0.806),  time:36.625, tt:2270.758\n",
      "Ep:62, loss:0.00007, loss_test:0.07537, lr:9.70e-03, fs:0.86432 (r=0.869,p=0.860),  time:36.654, tt:2309.178\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.07215, lr:9.70e-03, fs:0.85024 (r=0.889,p=0.815),  time:36.655, tt:2345.894\n",
      "Ep:64, loss:0.00007, loss_test:0.07961, lr:9.70e-03, fs:0.86275 (r=0.889,p=0.838),  time:36.647, tt:2382.046\n",
      "Ep:65, loss:0.00006, loss_test:0.08882, lr:9.70e-03, fs:0.78723 (r=0.747,p=0.831),  time:36.637, tt:2418.016\n",
      "Ep:66, loss:0.00005, loss_test:0.06549, lr:9.70e-03, fs:0.85854 (r=0.889,p=0.830),  time:36.631, tt:2454.310\n",
      "Ep:67, loss:0.00005, loss_test:0.09759, lr:9.70e-03, fs:0.75936 (r=0.717,p=0.807),  time:36.637, tt:2491.304\n",
      "Ep:68, loss:0.00005, loss_test:0.06726, lr:9.70e-03, fs:0.85854 (r=0.889,p=0.830),  time:36.615, tt:2526.468\n",
      "Ep:69, loss:0.00005, loss_test:0.08903, lr:9.70e-03, fs:0.86010 (r=0.838,p=0.883),  time:36.622, tt:2563.518\n",
      "Ep:70, loss:0.00005, loss_test:0.07175, lr:9.70e-03, fs:0.88000 (r=0.889,p=0.871),  time:36.613, tt:2599.527\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.07338, lr:9.70e-03, fs:0.88889 (r=0.889,p=0.889),  time:36.622, tt:2636.784\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00004, loss_test:0.08733, lr:9.70e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.625, tt:2673.633\n",
      "Ep:73, loss:0.00004, loss_test:0.07712, lr:9.70e-03, fs:0.89340 (r=0.889,p=0.898),  time:36.634, tt:2710.893\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.08535, lr:9.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.643, tt:2748.196\n",
      "Ep:75, loss:0.00004, loss_test:0.07579, lr:9.70e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.633, tt:2784.122\n",
      "Ep:76, loss:0.00004, loss_test:0.08278, lr:9.70e-03, fs:0.85567 (r=0.838,p=0.874),  time:36.633, tt:2820.725\n",
      "Ep:77, loss:0.00003, loss_test:0.08344, lr:9.70e-03, fs:0.89583 (r=0.869,p=0.925),  time:36.623, tt:2856.601\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.08540, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.616, tt:2892.632\n",
      "Ep:79, loss:0.00004, loss_test:0.08650, lr:9.70e-03, fs:0.82979 (r=0.788,p=0.876),  time:36.621, tt:2929.659\n",
      "Ep:80, loss:0.00003, loss_test:0.07614, lr:9.70e-03, fs:0.89340 (r=0.889,p=0.898),  time:36.616, tt:2965.864\n",
      "Ep:81, loss:0.00003, loss_test:0.08939, lr:9.70e-03, fs:0.82222 (r=0.747,p=0.914),  time:36.607, tt:3001.767\n",
      "Ep:82, loss:0.00003, loss_test:0.08319, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.626, tt:3039.947\n",
      "Ep:83, loss:0.00003, loss_test:0.08234, lr:9.70e-03, fs:0.89583 (r=0.869,p=0.925),  time:36.623, tt:3076.354\n",
      "Ep:84, loss:0.00003, loss_test:0.07733, lr:9.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:36.638, tt:3114.224\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00003, loss_test:0.10359, lr:9.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:36.638, tt:3150.867\n",
      "Ep:86, loss:0.00003, loss_test:0.08415, lr:9.70e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.626, tt:3186.473\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00002, loss_test:0.09026, lr:9.70e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.646, tt:3224.842\n",
      "Ep:88, loss:0.00002, loss_test:0.08767, lr:9.70e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.622, tt:3259.314\n",
      "Ep:89, loss:0.00002, loss_test:0.08387, lr:9.70e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.608, tt:3294.726\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.09349, lr:9.70e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.610, tt:3331.506\n",
      "Ep:91, loss:0.00002, loss_test:0.08734, lr:9.70e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.609, tt:3367.998\n",
      "Ep:92, loss:0.00002, loss_test:0.09507, lr:9.70e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.601, tt:3403.872\n",
      "Ep:93, loss:0.00002, loss_test:0.08528, lr:9.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:36.606, tt:3440.953\n",
      "Ep:94, loss:0.00002, loss_test:0.09429, lr:9.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.595, tt:3476.490\n",
      "Ep:95, loss:0.00002, loss_test:0.08458, lr:9.70e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.603, tt:3513.842\n",
      "Ep:96, loss:0.00002, loss_test:0.09584, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.615, tt:3551.698\n",
      "Ep:97, loss:0.00002, loss_test:0.07988, lr:9.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:36.620, tt:3588.796\n",
      "Ep:98, loss:0.00002, loss_test:0.09700, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.628, tt:3626.124\n",
      "Ep:99, loss:0.00002, loss_test:0.08011, lr:9.70e-03, fs:0.88889 (r=0.848,p=0.933),  time:36.635, tt:3663.462\n",
      "Ep:100, loss:0.00002, loss_test:0.09128, lr:9.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:36.646, tt:3701.202\n",
      "Ep:101, loss:0.00002, loss_test:0.09401, lr:9.61e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.657, tt:3739.017\n",
      "Ep:102, loss:0.00002, loss_test:0.08755, lr:9.51e-03, fs:0.85405 (r=0.798,p=0.919),  time:36.664, tt:3776.355\n",
      "Ep:103, loss:0.00002, loss_test:0.08470, lr:9.41e-03, fs:0.90625 (r=0.879,p=0.935),  time:36.645, tt:3811.096\n",
      "Ep:104, loss:0.00002, loss_test:0.08787, lr:9.32e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.647, tt:3847.888\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.08339, lr:9.32e-03, fs:0.91005 (r=0.869,p=0.956),  time:36.639, tt:3883.719\n",
      "Ep:106, loss:0.00002, loss_test:0.08711, lr:9.32e-03, fs:0.89247 (r=0.838,p=0.954),  time:36.648, tt:3921.335\n",
      "Ep:107, loss:0.00001, loss_test:0.09723, lr:9.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.650, tt:3958.185\n",
      "Ep:108, loss:0.00002, loss_test:0.08596, lr:9.32e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.648, tt:3994.609\n",
      "Ep:109, loss:0.00001, loss_test:0.08777, lr:9.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:36.633, tt:4029.637\n",
      "Ep:110, loss:0.00001, loss_test:0.08427, lr:9.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.627, tt:4065.555\n",
      "Ep:111, loss:0.00002, loss_test:0.11390, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.599, tt:4099.143\n",
      "Ep:112, loss:0.00003, loss_test:0.08163, lr:9.32e-03, fs:0.90625 (r=0.879,p=0.935),  time:36.592, tt:4134.932\n",
      "Ep:113, loss:0.00002, loss_test:0.09251, lr:9.32e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.625, tt:4175.303\n",
      "Ep:114, loss:0.00002, loss_test:0.07445, lr:9.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.608, tt:4209.873\n",
      "Ep:115, loss:0.00002, loss_test:0.08612, lr:9.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.599, tt:4245.530\n",
      "Ep:116, loss:0.00002, loss_test:0.08583, lr:9.23e-03, fs:0.91099 (r=0.879,p=0.946),  time:36.600, tt:4282.219\n",
      "Ep:117, loss:0.00001, loss_test:0.09728, lr:9.14e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.593, tt:4318.029\n",
      "Ep:118, loss:0.00001, loss_test:0.08920, lr:9.04e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.594, tt:4354.722\n",
      "Ep:119, loss:0.00001, loss_test:0.08201, lr:8.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.590, tt:4390.805\n",
      "Ep:120, loss:0.00001, loss_test:0.08647, lr:8.86e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.578, tt:4425.905\n",
      "Ep:121, loss:0.00001, loss_test:0.08741, lr:8.78e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.567, tt:4461.167\n",
      "Ep:122, loss:0.00001, loss_test:0.08839, lr:8.69e-03, fs:0.86813 (r=0.798,p=0.952),  time:36.550, tt:4495.615\n",
      "Ep:123, loss:0.00001, loss_test:0.08544, lr:8.60e-03, fs:0.88649 (r=0.828,p=0.953),  time:36.537, tt:4530.564\n",
      "Ep:124, loss:0.00001, loss_test:0.08685, lr:8.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:36.517, tt:4564.603\n",
      "Ep:125, loss:0.00001, loss_test:0.08505, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.511, tt:4600.348\n",
      "Ep:126, loss:0.00001, loss_test:0.08586, lr:8.35e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.498, tt:4635.217\n",
      "Ep:127, loss:0.00001, loss_test:0.08943, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.486, tt:4670.229\n",
      "Ep:128, loss:0.00001, loss_test:0.08683, lr:8.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.466, tt:4704.076\n",
      "Ep:129, loss:0.00001, loss_test:0.08845, lr:8.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.446, tt:4737.959\n",
      "Ep:130, loss:0.00001, loss_test:0.08960, lr:8.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.445, tt:4774.235\n",
      "Ep:131, loss:0.00001, loss_test:0.08586, lr:7.94e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.427, tt:4808.331\n",
      "Ep:132, loss:0.00001, loss_test:0.08952, lr:7.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.412, tt:4842.785\n",
      "Ep:133, loss:0.00001, loss_test:0.08833, lr:7.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.389, tt:4876.133\n",
      "Ep:134, loss:0.00001, loss_test:0.08870, lr:7.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.378, tt:4911.056\n",
      "Ep:135, loss:0.00001, loss_test:0.09057, lr:7.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:36.357, tt:4944.501\n",
      "Ep:136, loss:0.00001, loss_test:0.09320, lr:7.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.346, tt:4979.359\n",
      "Ep:137, loss:0.00000, loss_test:0.09070, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.337, tt:5014.550\n",
      "Ep:138, loss:0.00000, loss_test:0.09156, lr:7.40e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.313, tt:5047.573\n",
      "Ep:139, loss:0.00000, loss_test:0.09289, lr:7.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.300, tt:5082.031\n",
      "Ep:140, loss:0.00000, loss_test:0.09468, lr:7.25e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.278, tt:5115.226\n",
      "Ep:141, loss:0.00000, loss_test:0.09410, lr:7.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.265, tt:5149.631\n",
      "Ep:142, loss:0.00000, loss_test:0.09563, lr:7.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.255, tt:5184.527\n",
      "Ep:143, loss:0.00000, loss_test:0.09212, lr:7.03e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.246, tt:5219.484\n",
      "Ep:144, loss:0.00000, loss_test:0.09498, lr:6.96e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.234, tt:5253.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.09645, lr:6.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.223, tt:5288.612\n",
      "Ep:146, loss:0.00000, loss_test:0.09753, lr:6.83e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.200, tt:5321.413\n",
      "Ep:147, loss:0.00000, loss_test:0.09628, lr:6.76e-03, fs:0.83616 (r=0.747,p=0.949),  time:36.187, tt:5355.694\n",
      "Ep:148, loss:0.00000, loss_test:0.09884, lr:6.69e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.189, tt:5392.214\n",
      "Ep:149, loss:0.00000, loss_test:0.09469, lr:6.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.174, tt:5426.057\n",
      "Ep:150, loss:0.00000, loss_test:0.09971, lr:6.56e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.169, tt:5461.585\n",
      "Ep:151, loss:0.00000, loss_test:0.09649, lr:6.49e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.164, tt:5496.948\n",
      "Ep:152, loss:0.00000, loss_test:0.09992, lr:6.43e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.157, tt:5532.005\n",
      "Ep:153, loss:0.00000, loss_test:0.09776, lr:6.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.151, tt:5567.265\n",
      "Ep:154, loss:0.00000, loss_test:0.09704, lr:6.30e-03, fs:0.82955 (r=0.737,p=0.948),  time:36.134, tt:5600.706\n",
      "Ep:155, loss:0.00000, loss_test:0.09762, lr:6.24e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.129, tt:5636.066\n",
      "Ep:156, loss:0.00000, loss_test:0.09664, lr:6.17e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.122, tt:5671.163\n",
      "Ep:157, loss:0.00000, loss_test:0.09858, lr:6.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.111, tt:5705.481\n",
      "Ep:158, loss:0.00000, loss_test:0.09711, lr:6.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.107, tt:5740.986\n",
      "Ep:159, loss:0.00000, loss_test:0.10046, lr:5.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.103, tt:5776.460\n",
      "Ep:160, loss:0.00000, loss_test:0.09939, lr:5.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.101, tt:5812.284\n",
      "Ep:161, loss:0.00000, loss_test:0.09839, lr:5.87e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.087, tt:5846.065\n",
      "Ep:162, loss:0.00000, loss_test:0.10188, lr:5.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.075, tt:5880.202\n",
      "Ep:163, loss:0.00000, loss_test:0.09981, lr:5.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.072, tt:5915.727\n",
      "Ep:164, loss:0.00000, loss_test:0.10063, lr:5.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.057, tt:5949.375\n",
      "Ep:165, loss:0.00000, loss_test:0.09670, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.046, tt:5983.705\n",
      "Ep:166, loss:0.00000, loss_test:0.10126, lr:5.58e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.034, tt:6017.656\n",
      "Ep:167, loss:0.00000, loss_test:0.09744, lr:5.53e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.021, tt:6051.524\n",
      "Ep:168, loss:0.00000, loss_test:0.09790, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.016, tt:6086.740\n",
      "Ep:169, loss:0.00000, loss_test:0.09693, lr:5.42e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.008, tt:6121.366\n",
      "Ep:170, loss:0.00000, loss_test:0.09695, lr:5.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.004, tt:6156.747\n",
      "Ep:171, loss:0.00000, loss_test:0.09716, lr:5.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.998, tt:6191.590\n",
      "Ep:172, loss:0.00000, loss_test:0.09763, lr:5.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.987, tt:6225.808\n",
      "Ep:173, loss:0.00000, loss_test:0.09977, lr:5.20e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.983, tt:6261.051\n",
      "Ep:174, loss:0.00000, loss_test:0.09639, lr:5.15e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.977, tt:6295.995\n",
      "Ep:175, loss:0.00000, loss_test:0.09867, lr:5.10e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.964, tt:6329.685\n",
      "Ep:176, loss:0.00000, loss_test:0.09711, lr:5.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.960, tt:6364.926\n",
      "Ep:177, loss:0.00000, loss_test:0.09663, lr:5.00e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.958, tt:6400.536\n",
      "Ep:178, loss:0.00000, loss_test:0.09804, lr:4.95e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.948, tt:6434.631\n",
      "Ep:179, loss:0.00000, loss_test:0.09838, lr:4.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.940, tt:6469.248\n",
      "Ep:180, loss:0.00000, loss_test:0.09830, lr:4.85e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.928, tt:6502.936\n",
      "Ep:181, loss:0.00000, loss_test:0.09742, lr:4.80e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.920, tt:6537.417\n",
      "Ep:182, loss:0.00000, loss_test:0.09759, lr:4.75e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.911, tt:6571.670\n",
      "Ep:183, loss:0.00000, loss_test:0.09789, lr:4.71e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.901, tt:6605.757\n",
      "Ep:184, loss:0.00000, loss_test:0.09677, lr:4.66e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.890, tt:6639.647\n",
      "Ep:185, loss:0.00000, loss_test:0.09810, lr:4.61e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.900, tt:6677.469\n",
      "Ep:186, loss:0.00000, loss_test:0.09642, lr:4.57e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.895, tt:6712.290\n",
      "Ep:187, loss:0.00000, loss_test:0.09687, lr:4.52e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.893, tt:6747.792\n",
      "Ep:188, loss:0.00000, loss_test:0.09820, lr:4.48e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.897, tt:6784.476\n",
      "Ep:189, loss:0.00000, loss_test:0.09893, lr:4.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.885, tt:6818.240\n",
      "Ep:190, loss:0.00000, loss_test:0.09959, lr:4.39e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.876, tt:6852.372\n",
      "Ep:191, loss:0.00000, loss_test:0.09819, lr:4.34e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.871, tt:6887.169\n",
      "Ep:192, loss:0.00000, loss_test:0.09874, lr:4.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.866, tt:6922.176\n",
      "Ep:193, loss:0.00000, loss_test:0.09834, lr:4.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.860, tt:6956.760\n",
      "Ep:194, loss:0.00000, loss_test:0.09665, lr:4.21e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.849, tt:6990.623\n",
      "Ep:195, loss:0.00000, loss_test:0.09823, lr:4.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.845, tt:7025.675\n",
      "Ep:196, loss:0.00000, loss_test:0.09759, lr:4.13e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.841, tt:7060.594\n",
      "Ep:197, loss:0.00000, loss_test:0.09846, lr:4.09e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.832, tt:7094.703\n",
      "Ep:198, loss:0.00000, loss_test:0.09968, lr:4.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.820, tt:7128.240\n",
      "Ep:199, loss:0.00000, loss_test:0.09846, lr:4.01e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.818, tt:7163.524\n",
      "Ep:200, loss:0.00000, loss_test:0.09815, lr:3.97e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.804, tt:7196.696\n",
      "Ep:201, loss:0.00000, loss_test:0.09845, lr:3.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.805, tt:7232.683\n",
      "Ep:202, loss:0.00000, loss_test:0.09702, lr:3.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.801, tt:7267.619\n",
      "Ep:203, loss:0.00000, loss_test:0.09811, lr:3.85e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.784, tt:7299.880\n",
      "Ep:204, loss:0.00000, loss_test:0.09881, lr:3.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.785, tt:7335.891\n",
      "Ep:205, loss:0.00000, loss_test:0.09785, lr:3.77e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.777, tt:7370.087\n",
      "Ep:206, loss:0.00000, loss_test:0.09774, lr:3.73e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.776, tt:7405.596\n",
      "Ep:207, loss:0.00000, loss_test:0.09844, lr:3.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.775, tt:7441.228\n",
      "Ep:208, loss:0.00000, loss_test:0.09761, lr:3.66e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.765, tt:7474.976\n",
      "Ep:209, loss:0.00000, loss_test:0.09794, lr:3.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.735, tt:7504.255\n",
      "Ep:210, loss:0.00000, loss_test:0.09925, lr:3.59e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.690, tt:7530.630\n",
      "Ep:211, loss:0.00000, loss_test:0.09912, lr:3.55e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.655, tt:7558.910\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02958, lr:6.00e-02, fs:0.63203 (r=0.737,p=0.553),  time:27.436, tt:27.436\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00006, loss_test:0.02376, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:29.929, tt:59.857\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02385, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:30.199, tt:90.598\n",
      "Ep:3, loss:0.00005, loss_test:0.02399, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:31.145, tt:124.578\n",
      "Ep:4, loss:0.00005, loss_test:0.02287, lr:6.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:31.532, tt:157.660\n",
      "Ep:5, loss:0.00005, loss_test:0.02196, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:31.983, tt:191.896\n",
      "Ep:6, loss:0.00005, loss_test:0.02142, lr:6.00e-02, fs:0.67925 (r=0.909,p=0.542),  time:32.725, tt:229.072\n",
      "Ep:7, loss:0.00004, loss_test:0.02104, lr:6.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:32.909, tt:263.271\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02097, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:33.203, tt:298.831\n",
      "Ep:9, loss:0.00004, loss_test:0.02096, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:33.185, tt:331.852\n",
      "Ep:10, loss:0.00004, loss_test:0.02087, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:33.291, tt:366.200\n",
      "Ep:11, loss:0.00004, loss_test:0.02063, lr:6.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:33.448, tt:401.374\n",
      "Ep:12, loss:0.00004, loss_test:0.02022, lr:6.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:33.544, tt:436.066\n",
      "Ep:13, loss:0.00003, loss_test:0.01959, lr:6.00e-02, fs:0.65000 (r=0.788,p=0.553),  time:33.625, tt:470.745\n",
      "Ep:14, loss:0.00003, loss_test:0.01916, lr:6.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:33.549, tt:503.238\n",
      "Ep:15, loss:0.00003, loss_test:0.01884, lr:6.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:33.561, tt:536.971\n",
      "Ep:16, loss:0.00003, loss_test:0.01843, lr:6.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:33.522, tt:569.866\n",
      "Ep:17, loss:0.00003, loss_test:0.01801, lr:6.00e-02, fs:0.66957 (r=0.778,p=0.588),  time:33.580, tt:604.434\n",
      "Ep:18, loss:0.00003, loss_test:0.01781, lr:6.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:33.598, tt:638.370\n",
      "Ep:19, loss:0.00003, loss_test:0.01790, lr:5.94e-02, fs:0.66079 (r=0.758,p=0.586),  time:33.676, tt:673.527\n",
      "Ep:20, loss:0.00002, loss_test:0.01788, lr:5.88e-02, fs:0.66071 (r=0.747,p=0.592),  time:33.687, tt:707.431\n",
      "Ep:21, loss:0.00002, loss_test:0.01759, lr:5.82e-02, fs:0.68807 (r=0.758,p=0.630),  time:33.765, tt:742.829\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01735, lr:5.82e-02, fs:0.70046 (r=0.768,p=0.644),  time:33.832, tt:778.131\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01734, lr:5.82e-02, fs:0.69767 (r=0.758,p=0.647),  time:33.857, tt:812.575\n",
      "Ep:24, loss:0.00002, loss_test:0.01718, lr:5.82e-02, fs:0.70698 (r=0.768,p=0.655),  time:33.880, tt:846.995\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01724, lr:5.82e-02, fs:0.71698 (r=0.768,p=0.673),  time:33.912, tt:881.711\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01739, lr:5.82e-02, fs:0.70755 (r=0.758,p=0.664),  time:33.935, tt:916.246\n",
      "Ep:27, loss:0.00002, loss_test:0.01726, lr:5.82e-02, fs:0.72038 (r=0.768,p=0.679),  time:34.028, tt:952.797\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01722, lr:5.82e-02, fs:0.71429 (r=0.758,p=0.676),  time:34.054, tt:987.564\n",
      "Ep:29, loss:0.00002, loss_test:0.01761, lr:5.82e-02, fs:0.70813 (r=0.747,p=0.673),  time:34.042, tt:1021.253\n",
      "Ep:30, loss:0.00002, loss_test:0.01753, lr:5.82e-02, fs:0.70813 (r=0.747,p=0.673),  time:34.008, tt:1054.235\n",
      "Ep:31, loss:0.00001, loss_test:0.01800, lr:5.82e-02, fs:0.70874 (r=0.737,p=0.682),  time:34.013, tt:1088.403\n",
      "Ep:32, loss:0.00001, loss_test:0.01816, lr:5.82e-02, fs:0.69608 (r=0.717,p=0.676),  time:34.007, tt:1122.238\n",
      "Ep:33, loss:0.00001, loss_test:0.01827, lr:5.82e-02, fs:0.68966 (r=0.707,p=0.673),  time:33.993, tt:1155.762\n",
      "Ep:34, loss:0.00001, loss_test:0.01853, lr:5.82e-02, fs:0.69000 (r=0.697,p=0.683),  time:34.010, tt:1190.337\n",
      "Ep:35, loss:0.00001, loss_test:0.01833, lr:5.82e-02, fs:0.71845 (r=0.747,p=0.692),  time:34.000, tt:1224.012\n",
      "Ep:36, loss:0.00001, loss_test:0.01882, lr:5.82e-02, fs:0.71287 (r=0.727,p=0.699),  time:33.999, tt:1257.972\n",
      "Ep:37, loss:0.00001, loss_test:0.01905, lr:5.82e-02, fs:0.71287 (r=0.727,p=0.699),  time:33.981, tt:1291.284\n",
      "Ep:38, loss:0.00001, loss_test:0.01908, lr:5.82e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.007, tt:1326.269\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01977, lr:5.82e-02, fs:0.72000 (r=0.727,p=0.713),  time:34.007, tt:1360.277\n",
      "Ep:40, loss:0.00001, loss_test:0.01941, lr:5.82e-02, fs:0.75362 (r=0.788,p=0.722),  time:34.035, tt:1395.415\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.02037, lr:5.82e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.034, tt:1429.439\n",
      "Ep:42, loss:0.00001, loss_test:0.02022, lr:5.82e-02, fs:0.76847 (r=0.788,p=0.750),  time:34.021, tt:1462.900\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.02062, lr:5.82e-02, fs:0.77228 (r=0.788,p=0.757),  time:34.029, tt:1497.263\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.02098, lr:5.82e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.052, tt:1532.319\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.02172, lr:5.82e-02, fs:0.78218 (r=0.798,p=0.767),  time:34.072, tt:1567.319\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.02181, lr:5.82e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.068, tt:1601.202\n",
      "Ep:47, loss:0.00001, loss_test:0.02192, lr:5.82e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.047, tt:1634.274\n",
      "Ep:48, loss:0.00001, loss_test:0.02273, lr:5.82e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.033, tt:1667.641\n",
      "Ep:49, loss:0.00001, loss_test:0.02243, lr:5.82e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.014, tt:1700.713\n",
      "Ep:50, loss:0.00001, loss_test:0.02330, lr:5.82e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.029, tt:1735.488\n",
      "Ep:51, loss:0.00001, loss_test:0.02339, lr:5.82e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.027, tt:1769.390\n",
      "Ep:52, loss:0.00001, loss_test:0.02396, lr:5.82e-02, fs:0.78075 (r=0.737,p=0.830),  time:33.999, tt:1801.966\n",
      "Ep:53, loss:0.00001, loss_test:0.02415, lr:5.82e-02, fs:0.77419 (r=0.727,p=0.828),  time:34.015, tt:1836.832\n",
      "Ep:54, loss:0.00001, loss_test:0.02467, lr:5.82e-02, fs:0.77005 (r=0.727,p=0.818),  time:34.043, tt:1872.354\n",
      "Ep:55, loss:0.00001, loss_test:0.02483, lr:5.82e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.057, tt:1907.213\n",
      "Ep:56, loss:0.00000, loss_test:0.02524, lr:5.82e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.069, tt:1941.934\n",
      "Ep:57, loss:0.00000, loss_test:0.02569, lr:5.76e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.079, tt:1976.580\n",
      "Ep:58, loss:0.00000, loss_test:0.02588, lr:5.71e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.061, tt:2009.580\n",
      "Ep:59, loss:0.00000, loss_test:0.02644, lr:5.65e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.056, tt:2043.339\n",
      "Ep:60, loss:0.00000, loss_test:0.02679, lr:5.59e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.071, tt:2078.354\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00000, loss_test:0.02708, lr:5.59e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.048, tt:2111.007\n",
      "Ep:62, loss:0.00000, loss_test:0.02731, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.043, tt:2144.702\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00000, loss_test:0.02815, lr:5.59e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.018, tt:2177.177\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00000, loss_test:0.02819, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.998, tt:2209.868\n",
      "Ep:65, loss:0.00000, loss_test:0.02870, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.986, tt:2243.096\n",
      "Ep:66, loss:0.00000, loss_test:0.02936, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.984, tt:2276.899\n",
      "Ep:67, loss:0.00000, loss_test:0.02982, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.995, tt:2311.653\n",
      "Ep:68, loss:0.00000, loss_test:0.02983, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.008, tt:2346.545\n",
      "Ep:69, loss:0.00000, loss_test:0.03058, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.999, tt:2379.947\n",
      "Ep:70, loss:0.00000, loss_test:0.03073, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.988, tt:2413.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00000, loss_test:0.03146, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.984, tt:2446.871\n",
      "Ep:72, loss:0.00000, loss_test:0.03135, lr:5.59e-02, fs:0.80000 (r=0.727,p=0.889),  time:33.995, tt:2481.615\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00000, loss_test:0.03243, lr:5.59e-02, fs:0.80000 (r=0.727,p=0.889),  time:33.991, tt:2515.313\n",
      "Ep:74, loss:0.00000, loss_test:0.03191, lr:5.59e-02, fs:0.80000 (r=0.727,p=0.889),  time:33.981, tt:2548.598\n",
      "Ep:75, loss:0.00000, loss_test:0.03303, lr:5.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:33.974, tt:2582.014\n",
      "Ep:76, loss:0.00000, loss_test:0.03300, lr:5.59e-02, fs:0.80000 (r=0.727,p=0.889),  time:33.962, tt:2615.070\n",
      "Ep:77, loss:0.00000, loss_test:0.03355, lr:5.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.962, tt:2649.050\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00000, loss_test:0.03378, lr:5.59e-02, fs:0.80447 (r=0.727,p=0.900),  time:33.976, tt:2684.101\n",
      "Ep:79, loss:0.00000, loss_test:0.03460, lr:5.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.997, tt:2719.764\n",
      "Ep:80, loss:0.00000, loss_test:0.03413, lr:5.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.012, tt:2754.963\n",
      "Ep:81, loss:0.00000, loss_test:0.03537, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.008, tt:2788.644\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00000, loss_test:0.03488, lr:5.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.992, tt:2821.323\n",
      "Ep:83, loss:0.00000, loss_test:0.03545, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.970, tt:2853.514\n",
      "Ep:84, loss:0.00000, loss_test:0.03558, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.964, tt:2886.978\n",
      "Ep:85, loss:0.00000, loss_test:0.03612, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.961, tt:2920.673\n",
      "Ep:86, loss:0.00000, loss_test:0.03615, lr:5.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.964, tt:2954.839\n",
      "Ep:87, loss:0.00000, loss_test:0.03681, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.969, tt:2989.289\n",
      "Ep:88, loss:0.00000, loss_test:0.03664, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.953, tt:3021.793\n",
      "Ep:89, loss:0.00000, loss_test:0.03703, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.984, tt:3058.558\n",
      "Ep:90, loss:0.00000, loss_test:0.03731, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.983, tt:3092.421\n",
      "Ep:91, loss:0.00000, loss_test:0.03758, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.987, tt:3126.787\n",
      "Ep:92, loss:0.00000, loss_test:0.03767, lr:5.59e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.973, tt:3159.446\n",
      "Ep:93, loss:0.00000, loss_test:0.03782, lr:5.54e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.959, tt:3192.192\n",
      "Ep:94, loss:0.00000, loss_test:0.03872, lr:5.48e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.948, tt:3225.084\n",
      "Ep:95, loss:0.00000, loss_test:0.03835, lr:5.43e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.953, tt:3259.521\n",
      "Ep:96, loss:0.00000, loss_test:0.03883, lr:5.37e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.953, tt:3293.456\n",
      "Ep:97, loss:0.00000, loss_test:0.03886, lr:5.32e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.930, tt:3325.180\n",
      "Ep:98, loss:0.00000, loss_test:0.03940, lr:5.27e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.932, tt:3359.314\n",
      "Ep:99, loss:0.00000, loss_test:0.03935, lr:5.21e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.929, tt:3392.873\n",
      "Ep:100, loss:0.00000, loss_test:0.03966, lr:5.16e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.934, tt:3427.382\n",
      "Ep:101, loss:0.00000, loss_test:0.03975, lr:5.11e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.926, tt:3460.501\n",
      "Ep:102, loss:0.00000, loss_test:0.03988, lr:5.06e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.912, tt:3492.981\n",
      "Ep:103, loss:0.00000, loss_test:0.04010, lr:5.01e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.923, tt:3527.944\n",
      "Ep:104, loss:0.00000, loss_test:0.04037, lr:4.96e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.945, tt:3564.255\n",
      "Ep:105, loss:0.00000, loss_test:0.04054, lr:4.91e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.951, tt:3598.772\n",
      "Ep:106, loss:0.00000, loss_test:0.04040, lr:4.86e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.959, tt:3633.588\n",
      "Ep:107, loss:0.00000, loss_test:0.04087, lr:4.81e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.974, tt:3669.239\n",
      "Ep:108, loss:0.00000, loss_test:0.04112, lr:4.76e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.988, tt:3704.649\n",
      "Ep:109, loss:0.00000, loss_test:0.04068, lr:4.71e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.025, tt:3742.699\n",
      "Ep:110, loss:0.00000, loss_test:0.04125, lr:4.67e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.037, tt:3778.098\n",
      "Ep:111, loss:0.00000, loss_test:0.04138, lr:4.62e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.043, tt:3812.846\n",
      "Ep:112, loss:0.00000, loss_test:0.04123, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.053, tt:3847.962\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.04163, lr:4.57e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.066, tt:3883.566\n",
      "Ep:114, loss:0.00000, loss_test:0.04152, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.080, tt:3919.241\n",
      "Ep:115, loss:0.00000, loss_test:0.04169, lr:4.57e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.091, tt:3954.595\n",
      "Ep:116, loss:0.00000, loss_test:0.04211, lr:4.57e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.095, tt:3989.081\n",
      "Ep:117, loss:0.00000, loss_test:0.04181, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.110, tt:4025.017\n",
      "Ep:118, loss:0.00000, loss_test:0.04216, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.125, tt:4060.874\n",
      "Ep:119, loss:0.00000, loss_test:0.04225, lr:4.57e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.143, tt:4097.203\n",
      "Ep:120, loss:0.00000, loss_test:0.04226, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.160, tt:4133.332\n",
      "Ep:121, loss:0.00000, loss_test:0.04256, lr:4.57e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.178, tt:4169.747\n",
      "Ep:122, loss:0.00000, loss_test:0.04256, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.194, tt:4205.886\n",
      "Ep:123, loss:0.00000, loss_test:0.04286, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.213, tt:4242.413\n",
      "Ep:124, loss:0.00000, loss_test:0.04263, lr:4.53e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.230, tt:4278.745\n",
      "Ep:125, loss:0.00000, loss_test:0.04304, lr:4.48e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.238, tt:4313.958\n",
      "Ep:126, loss:0.00000, loss_test:0.04302, lr:4.44e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.240, tt:4348.488\n",
      "Ep:127, loss:0.00000, loss_test:0.04319, lr:4.39e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.248, tt:4383.766\n",
      "Ep:128, loss:0.00000, loss_test:0.04292, lr:4.35e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.251, tt:4418.330\n",
      "Ep:129, loss:0.00000, loss_test:0.04349, lr:4.31e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.254, tt:4452.973\n",
      "Ep:130, loss:0.00000, loss_test:0.04338, lr:4.26e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.258, tt:4487.813\n",
      "Ep:131, loss:0.00000, loss_test:0.04352, lr:4.22e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.266, tt:4523.128\n",
      "Ep:132, loss:0.00000, loss_test:0.04345, lr:4.18e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.278, tt:4558.948\n",
      "Ep:133, loss:0.00000, loss_test:0.04363, lr:4.14e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.293, tt:4595.272\n",
      "Ep:134, loss:0.00000, loss_test:0.04369, lr:4.10e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.296, tt:4630.025\n",
      "Ep:135, loss:0.00000, loss_test:0.04393, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.298, tt:4664.540\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.04373, lr:4.05e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.305, tt:4699.805\n",
      "Ep:137, loss:0.00000, loss_test:0.04413, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.318, tt:4735.862\n",
      "Ep:138, loss:0.00000, loss_test:0.04393, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.326, tt:4771.324\n",
      "Ep:139, loss:0.00000, loss_test:0.04422, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.343, tt:4808.049\n",
      "Ep:140, loss:0.00000, loss_test:0.04416, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.349, tt:4843.194\n",
      "Ep:141, loss:0.00000, loss_test:0.04422, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.360, tt:4879.131\n",
      "Ep:142, loss:0.00000, loss_test:0.04432, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.377, tt:4915.895\n",
      "Ep:143, loss:0.00000, loss_test:0.04424, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.389, tt:4951.990\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.04448, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.401, tt:4988.140\n",
      "Ep:145, loss:0.00000, loss_test:0.04462, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.409, tt:5023.661\n",
      "Ep:146, loss:0.00000, loss_test:0.04445, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.418, tt:5059.441\n",
      "Ep:147, loss:0.00000, loss_test:0.04501, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.428, tt:5095.291\n",
      "Ep:148, loss:0.00000, loss_test:0.04457, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.443, tt:5131.936\n",
      "Ep:149, loss:0.00000, loss_test:0.04484, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.447, tt:5167.082\n",
      "Ep:150, loss:0.00000, loss_test:0.04477, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.455, tt:5202.669\n",
      "Ep:151, loss:0.00000, loss_test:0.04499, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.469, tt:5239.345\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00000, loss_test:0.04503, lr:4.05e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.475, tt:5274.733\n",
      "Ep:153, loss:0.00000, loss_test:0.04481, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.483, tt:5310.370\n",
      "Ep:154, loss:0.00000, loss_test:0.04531, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.490, tt:5346.008\n",
      "Ep:155, loss:0.00000, loss_test:0.04522, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.496, tt:5381.373\n",
      "Ep:156, loss:0.00000, loss_test:0.04522, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.504, tt:5417.201\n",
      "Ep:157, loss:0.00000, loss_test:0.04550, lr:4.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.512, tt:5452.949\n",
      "Ep:158, loss:0.00000, loss_test:0.04522, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.525, tt:5489.455\n",
      "Ep:159, loss:0.00000, loss_test:0.04559, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.541, tt:5526.485\n",
      "Ep:160, loss:0.00000, loss_test:0.04535, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.549, tt:5562.382\n",
      "Ep:161, loss:0.00000, loss_test:0.04572, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.555, tt:5597.871\n",
      "Ep:162, loss:0.00000, loss_test:0.04547, lr:4.05e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.566, tt:5634.288\n",
      "Ep:163, loss:0.00000, loss_test:0.04571, lr:4.01e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.566, tt:5668.806\n",
      "Ep:164, loss:0.00000, loss_test:0.04573, lr:3.97e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.568, tt:5703.789\n",
      "Ep:165, loss:0.00000, loss_test:0.04582, lr:3.93e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.573, tt:5739.141\n",
      "Ep:166, loss:0.00000, loss_test:0.04581, lr:3.89e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.576, tt:5774.199\n",
      "Ep:167, loss:0.00000, loss_test:0.04598, lr:3.86e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.582, tt:5809.777\n",
      "Ep:168, loss:0.00000, loss_test:0.04591, lr:3.82e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.584, tt:5844.677\n",
      "Ep:169, loss:0.00000, loss_test:0.04609, lr:3.78e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.583, tt:5879.194\n",
      "Ep:170, loss:0.00000, loss_test:0.04588, lr:3.74e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.590, tt:5914.865\n",
      "Ep:171, loss:0.00000, loss_test:0.04607, lr:3.70e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.586, tt:5948.874\n",
      "Ep:172, loss:0.00000, loss_test:0.04604, lr:3.67e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.585, tt:5983.253\n",
      "Ep:173, loss:0.00000, loss_test:0.04615, lr:3.63e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.590, tt:6018.605\n",
      "Ep:174, loss:0.00000, loss_test:0.04617, lr:3.59e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.590, tt:6053.249\n",
      "Ep:175, loss:0.00000, loss_test:0.04629, lr:3.56e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.599, tt:6089.457\n",
      "Ep:176, loss:0.00000, loss_test:0.04626, lr:3.52e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.593, tt:6122.909\n",
      "Ep:177, loss:0.00000, loss_test:0.04632, lr:3.49e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.598, tt:6158.461\n",
      "Ep:178, loss:0.00000, loss_test:0.04636, lr:3.45e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.596, tt:6192.729\n",
      "Ep:179, loss:0.00000, loss_test:0.04635, lr:3.42e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.588, tt:6225.882\n",
      "Ep:180, loss:0.00000, loss_test:0.04642, lr:3.38e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.590, tt:6260.733\n",
      "Ep:181, loss:0.00000, loss_test:0.04646, lr:3.35e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.590, tt:6295.383\n",
      "Ep:182, loss:0.00000, loss_test:0.04649, lr:3.32e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.592, tt:6330.330\n",
      "Ep:183, loss:0.00000, loss_test:0.04647, lr:3.28e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.598, tt:6366.046\n",
      "Ep:184, loss:0.00000, loss_test:0.04661, lr:3.25e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.593, tt:6399.630\n",
      "Ep:185, loss:0.00000, loss_test:0.04658, lr:3.22e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.591, tt:6433.956\n",
      "Ep:186, loss:0.00000, loss_test:0.04662, lr:3.19e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.604, tt:6470.861\n",
      "Ep:187, loss:0.00000, loss_test:0.04663, lr:3.15e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.617, tt:6507.998\n",
      "Ep:188, loss:0.00000, loss_test:0.04670, lr:3.12e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.630, tt:6545.152\n",
      "Ep:189, loss:0.00000, loss_test:0.04673, lr:3.09e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.652, tt:6583.798\n",
      "Ep:190, loss:0.00000, loss_test:0.04675, lr:3.06e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.664, tt:6620.865\n",
      "Ep:191, loss:0.00000, loss_test:0.04675, lr:3.03e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.678, tt:6658.187\n",
      "Ep:192, loss:0.00000, loss_test:0.04676, lr:3.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.684, tt:6694.019\n",
      "Ep:193, loss:0.00000, loss_test:0.04685, lr:2.97e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.683, tt:6728.427\n",
      "Ep:194, loss:0.00000, loss_test:0.04682, lr:2.94e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.687, tt:6763.960\n",
      "Ep:195, loss:0.00000, loss_test:0.04690, lr:2.91e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.689, tt:6799.008\n",
      "Ep:196, loss:0.00000, loss_test:0.04690, lr:2.88e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.697, tt:6835.389\n",
      "Ep:197, loss:0.00000, loss_test:0.04690, lr:2.85e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.703, tt:6871.193\n",
      "Ep:198, loss:0.00000, loss_test:0.04688, lr:2.82e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.698, tt:6904.846\n",
      "Ep:199, loss:0.00000, loss_test:0.04703, lr:2.80e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.676, tt:6935.194\n",
      "Ep:200, loss:0.00000, loss_test:0.04694, lr:2.77e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.655, tt:6965.713\n",
      "Ep:201, loss:0.00000, loss_test:0.04705, lr:2.74e-02, fs:0.82759 (r=0.727,p=0.960),  time:34.648, tt:6998.963\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13524, lr:1.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:30.578, tt:30.578\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13329, lr:1.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:32.528, tt:65.055\n",
      "Ep:2, loss:0.00027, loss_test:0.13111, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:33.409, tt:100.227\n",
      "Ep:3, loss:0.00027, loss_test:0.12927, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:33.897, tt:135.587\n",
      "Ep:4, loss:0.00027, loss_test:0.12793, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:34.432, tt:172.163\n",
      "Ep:5, loss:0.00027, loss_test:0.12698, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:34.729, tt:208.372\n",
      "Ep:6, loss:0.00026, loss_test:0.12625, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:35.089, tt:245.622\n",
      "Ep:7, loss:0.00026, loss_test:0.12554, lr:1.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:34.993, tt:279.945\n",
      "Ep:8, loss:0.00026, loss_test:0.12460, lr:1.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:35.225, tt:317.028\n",
      "Ep:9, loss:0.00026, loss_test:0.12370, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:35.391, tt:353.910\n",
      "Ep:10, loss:0.00026, loss_test:0.12286, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:35.487, tt:390.360\n",
      "Ep:11, loss:0.00025, loss_test:0.12200, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:35.653, tt:427.833\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00025, loss_test:0.12114, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:35.688, tt:463.938\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.12037, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.931, tt:503.031\n",
      "Ep:14, loss:0.00025, loss_test:0.11959, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:36.007, tt:540.111\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.11879, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:36.056, tt:576.895\n",
      "Ep:16, loss:0.00024, loss_test:0.11779, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:36.104, tt:613.768\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.11699, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:36.046, tt:648.823\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.11629, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:36.034, tt:684.640\n",
      "Ep:19, loss:0.00023, loss_test:0.11554, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:36.040, tt:720.807\n",
      "Ep:20, loss:0.00023, loss_test:0.11483, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:36.042, tt:756.882\n",
      "Ep:21, loss:0.00022, loss_test:0.11413, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:36.030, tt:792.670\n",
      "Ep:22, loss:0.00022, loss_test:0.11359, lr:1.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:36.065, tt:829.490\n",
      "Ep:23, loss:0.00022, loss_test:0.11311, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:36.124, tt:866.970\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.11280, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:36.160, tt:903.998\n",
      "Ep:25, loss:0.00021, loss_test:0.11243, lr:1.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:36.194, tt:941.054\n",
      "Ep:26, loss:0.00021, loss_test:0.11199, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:36.165, tt:976.467\n",
      "Ep:27, loss:0.00020, loss_test:0.11183, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:36.140, tt:1011.927\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00020, loss_test:0.11177, lr:1.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:36.193, tt:1049.606\n",
      "Ep:29, loss:0.00020, loss_test:0.11164, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:36.177, tt:1085.302\n",
      "Ep:30, loss:0.00019, loss_test:0.11175, lr:1.00e-02, fs:0.69333 (r=0.788,p=0.619),  time:36.160, tt:1120.964\n",
      "Ep:31, loss:0.00019, loss_test:0.11157, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:36.141, tt:1156.508\n",
      "Ep:32, loss:0.00018, loss_test:0.11096, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:36.203, tt:1194.708\n",
      "Ep:33, loss:0.00018, loss_test:0.11031, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:36.221, tt:1231.498\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.10953, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:36.183, tt:1266.417\n",
      "Ep:35, loss:0.00017, loss_test:0.10832, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:36.161, tt:1301.812\n",
      "Ep:36, loss:0.00016, loss_test:0.10794, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:36.136, tt:1337.022\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00016, loss_test:0.10717, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:36.132, tt:1373.002\n",
      "Ep:38, loss:0.00015, loss_test:0.10986, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:36.145, tt:1409.665\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00014, loss_test:0.10776, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:36.143, tt:1445.733\n",
      "Ep:40, loss:0.00014, loss_test:0.10993, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:36.152, tt:1482.217\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00013, loss_test:0.11127, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:36.158, tt:1518.645\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.11165, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:36.160, tt:1554.890\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00012, loss_test:0.11355, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:36.193, tt:1592.485\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00011, loss_test:0.10908, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:36.155, tt:1626.997\n",
      "Ep:45, loss:0.00011, loss_test:0.11112, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:36.184, tt:1664.456\n",
      "Ep:46, loss:0.00010, loss_test:0.10975, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:36.185, tt:1700.674\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.10561, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:36.151, tt:1735.255\n",
      "Ep:48, loss:0.00009, loss_test:0.10987, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:36.164, tt:1772.043\n",
      "Ep:49, loss:0.00008, loss_test:0.10531, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:36.142, tt:1807.124\n",
      "Ep:50, loss:0.00008, loss_test:0.10700, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:36.130, tt:1842.649\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.10132, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:36.117, tt:1878.089\n",
      "Ep:52, loss:0.00008, loss_test:0.10815, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.127, tt:1914.710\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.10973, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.121, tt:1950.508\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.10260, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:36.142, tt:1987.798\n",
      "Ep:55, loss:0.00006, loss_test:0.10906, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:36.126, tt:2023.062\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.09887, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:36.086, tt:2056.904\n",
      "Ep:57, loss:0.00005, loss_test:0.10640, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:36.071, tt:2092.103\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.10530, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:36.059, tt:2127.464\n",
      "Ep:59, loss:0.00005, loss_test:0.10244, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:36.058, tt:2163.476\n",
      "Ep:60, loss:0.00004, loss_test:0.10556, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:36.069, tt:2200.214\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.09495, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:36.077, tt:2236.796\n",
      "Ep:62, loss:0.00004, loss_test:0.10296, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:36.086, tt:2273.398\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.09707, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:36.057, tt:2307.648\n",
      "Ep:64, loss:0.00003, loss_test:0.10240, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:36.024, tt:2341.579\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00003, loss_test:0.09575, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:35.991, tt:2375.375\n",
      "Ep:66, loss:0.00003, loss_test:0.10204, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.979, tt:2410.621\n",
      "Ep:67, loss:0.00003, loss_test:0.10182, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:35.970, tt:2445.990\n",
      "Ep:68, loss:0.00003, loss_test:0.10029, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.946, tt:2480.241\n",
      "Ep:69, loss:0.00003, loss_test:0.09807, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.920, tt:2514.417\n",
      "Ep:70, loss:0.00003, loss_test:0.09387, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.887, tt:2547.997\n",
      "Ep:71, loss:0.00002, loss_test:0.09786, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.869, tt:2582.599\n",
      "Ep:72, loss:0.00002, loss_test:0.09336, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.847, tt:2616.817\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.09788, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.848, tt:2652.747\n",
      "Ep:74, loss:0.00002, loss_test:0.09461, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.844, tt:2688.323\n",
      "Ep:75, loss:0.00003, loss_test:0.09613, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.838, tt:2723.697\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.08971, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.833, tt:2759.148\n",
      "Ep:77, loss:0.00002, loss_test:0.10161, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.817, tt:2793.711\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00002, loss_test:0.09473, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.798, tt:2828.078\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.09414, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.775, tt:2862.025\n",
      "Ep:80, loss:0.00002, loss_test:0.10063, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.745, tt:2895.307\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.09477, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:35.727, tt:2929.624\n",
      "Ep:82, loss:0.00001, loss_test:0.09482, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.720, tt:2964.744\n",
      "Ep:83, loss:0.00001, loss_test:0.09325, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:35.740, tt:3002.126\n",
      "Ep:84, loss:0.00001, loss_test:0.09477, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.730, tt:3037.011\n",
      "Ep:85, loss:0.00001, loss_test:0.09787, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:35.741, tt:3073.687\n",
      "Ep:86, loss:0.00001, loss_test:0.09182, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.727, tt:3108.285\n",
      "Ep:87, loss:0.00001, loss_test:0.09421, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.727, tt:3143.972\n",
      "Ep:88, loss:0.00001, loss_test:0.09422, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.718, tt:3178.945\n",
      "Ep:89, loss:0.00001, loss_test:0.09360, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.700, tt:3213.025\n",
      "Ep:90, loss:0.00001, loss_test:0.09119, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.708, tt:3249.417\n",
      "Ep:91, loss:0.00001, loss_test:0.09381, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.733, tt:3287.441\n",
      "Ep:92, loss:0.00001, loss_test:0.09391, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.751, tt:3324.817\n",
      "Ep:93, loss:0.00001, loss_test:0.09244, lr:9.80e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.764, tt:3361.805\n",
      "Ep:94, loss:0.00001, loss_test:0.09319, lr:9.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:35.774, tt:3398.521\n",
      "Ep:95, loss:0.00001, loss_test:0.09535, lr:9.61e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.751, tt:3432.138\n",
      "Ep:96, loss:0.00001, loss_test:0.09321, lr:9.51e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.748, tt:3467.553\n",
      "Ep:97, loss:0.00001, loss_test:0.09331, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.752, tt:3503.670\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.09205, lr:9.41e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.766, tt:3540.881\n",
      "Ep:99, loss:0.00001, loss_test:0.08845, lr:9.41e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.799, tt:3579.942\n",
      "Ep:100, loss:0.00001, loss_test:0.09438, lr:9.41e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.824, tt:3618.203\n",
      "Ep:101, loss:0.00001, loss_test:0.09424, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.848, tt:3656.453\n",
      "Ep:102, loss:0.00001, loss_test:0.08893, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.872, tt:3694.847\n",
      "Ep:103, loss:0.00001, loss_test:0.09368, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.884, tt:3731.952\n",
      "Ep:104, loss:0.00001, loss_test:0.09348, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.907, tt:3770.203\n",
      "Ep:105, loss:0.00001, loss_test:0.09165, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.919, tt:3807.430\n",
      "Ep:106, loss:0.00001, loss_test:0.08902, lr:9.41e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.909, tt:3842.247\n",
      "Ep:107, loss:0.00001, loss_test:0.09129, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.901, tt:3877.306\n",
      "Ep:108, loss:0.00000, loss_test:0.09087, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.896, tt:3912.647\n",
      "Ep:109, loss:0.00000, loss_test:0.08957, lr:9.32e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.896, tt:3948.544\n",
      "Ep:110, loss:0.00000, loss_test:0.09156, lr:9.23e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.905, tt:3985.412\n",
      "Ep:111, loss:0.00000, loss_test:0.08990, lr:9.14e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.904, tt:4021.278\n",
      "Ep:112, loss:0.00000, loss_test:0.09041, lr:9.04e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.904, tt:4057.194\n",
      "Ep:113, loss:0.00000, loss_test:0.08995, lr:8.95e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.908, tt:4093.535\n",
      "Ep:114, loss:0.00000, loss_test:0.08849, lr:8.86e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.914, tt:4130.124\n",
      "Ep:115, loss:0.00000, loss_test:0.09389, lr:8.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.920, tt:4166.763\n",
      "Ep:116, loss:0.00000, loss_test:0.09721, lr:8.69e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.915, tt:4202.001\n",
      "Ep:117, loss:0.00000, loss_test:0.08962, lr:8.60e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.911, tt:4237.446\n",
      "Ep:118, loss:0.00000, loss_test:0.08942, lr:8.51e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.904, tt:4272.546\n",
      "Ep:119, loss:0.00000, loss_test:0.09057, lr:8.43e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.911, tt:4309.292\n",
      "Ep:120, loss:0.00000, loss_test:0.09052, lr:8.35e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.911, tt:4345.265\n",
      "Ep:121, loss:0.00000, loss_test:0.09102, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.907, tt:4380.645\n",
      "Ep:122, loss:0.00000, loss_test:0.09087, lr:8.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.909, tt:4416.774\n",
      "Ep:123, loss:0.00000, loss_test:0.09133, lr:8.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.904, tt:4452.151\n",
      "Ep:124, loss:0.00000, loss_test:0.09158, lr:8.02e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.901, tt:4487.635\n",
      "Ep:125, loss:0.00000, loss_test:0.09022, lr:7.94e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.901, tt:4523.583\n",
      "Ep:126, loss:0.00000, loss_test:0.09149, lr:7.86e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.893, tt:4558.419\n",
      "Ep:127, loss:0.00000, loss_test:0.08905, lr:7.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.911, tt:4596.634\n",
      "Ep:128, loss:0.00000, loss_test:0.08843, lr:7.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.908, tt:4632.122\n",
      "Ep:129, loss:0.00000, loss_test:0.09136, lr:7.62e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.898, tt:4666.774\n",
      "Ep:130, loss:0.00000, loss_test:0.09146, lr:7.55e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.888, tt:4701.385\n",
      "Ep:131, loss:0.00000, loss_test:0.08914, lr:7.47e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.894, tt:4737.981\n",
      "Ep:132, loss:0.00000, loss_test:0.08928, lr:7.40e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.913, tt:4776.462\n",
      "Ep:133, loss:0.00000, loss_test:0.08910, lr:7.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.907, tt:4811.498\n",
      "Ep:134, loss:0.00000, loss_test:0.09027, lr:7.25e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.899, tt:4846.338\n",
      "Ep:135, loss:0.00000, loss_test:0.09164, lr:7.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.887, tt:4880.670\n",
      "Ep:136, loss:0.00000, loss_test:0.08920, lr:7.11e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.887, tt:4916.466\n",
      "Ep:137, loss:0.00000, loss_test:0.09365, lr:7.03e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.879, tt:4951.317\n",
      "Ep:138, loss:0.00000, loss_test:0.09620, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.879, tt:4987.241\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00000, loss_test:0.09089, lr:6.96e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.870, tt:5021.855\n",
      "Ep:140, loss:0.00000, loss_test:0.08892, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.861, tt:5056.469\n",
      "Ep:141, loss:0.00000, loss_test:0.09023, lr:6.96e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.853, tt:5091.187\n",
      "Ep:142, loss:0.00000, loss_test:0.09014, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.847, tt:5126.067\n",
      "Ep:143, loss:0.00000, loss_test:0.09210, lr:6.96e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.844, tt:5161.511\n",
      "Ep:144, loss:0.00000, loss_test:0.09032, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.844, tt:5197.333\n",
      "Ep:145, loss:0.00000, loss_test:0.08896, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.828, tt:5230.937\n",
      "Ep:146, loss:0.00000, loss_test:0.09111, lr:6.96e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.818, tt:5265.180\n",
      "Ep:147, loss:0.00000, loss_test:0.09048, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.812, tt:5300.231\n",
      "Ep:148, loss:0.00000, loss_test:0.09045, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.807, tt:5335.251\n",
      "Ep:152, loss:0.00000, loss_test:0.08976, lr:6.76e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.799, tt:5477.265\n",
      "Ep:153, loss:0.00000, loss_test:0.08907, lr:6.69e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.804, tt:5513.750\n",
      "Ep:154, loss:0.00000, loss_test:0.09272, lr:6.62e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.799, tt:5548.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.09225, lr:6.56e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.802, tt:5585.054\n",
      "Ep:156, loss:0.00000, loss_test:0.08871, lr:6.49e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.820, tt:5623.683\n",
      "Ep:157, loss:0.00000, loss_test:0.09122, lr:6.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.812, tt:5658.307\n",
      "Ep:158, loss:0.00000, loss_test:0.09334, lr:6.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.807, tt:5693.271\n",
      "Ep:159, loss:0.00000, loss_test:0.09108, lr:6.30e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.792, tt:5726.772\n",
      "Ep:160, loss:0.00000, loss_test:0.08952, lr:6.24e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.792, tt:5762.449\n",
      "Ep:161, loss:0.00000, loss_test:0.08978, lr:6.17e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.792, tt:5798.230\n",
      "Ep:162, loss:0.00000, loss_test:0.08989, lr:6.11e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.781, tt:5832.303\n",
      "Ep:163, loss:0.00000, loss_test:0.09069, lr:6.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.775, tt:5867.041\n",
      "Ep:164, loss:0.00000, loss_test:0.09085, lr:5.99e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.774, tt:5902.783\n",
      "Ep:165, loss:0.00000, loss_test:0.08934, lr:5.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.767, tt:5937.311\n",
      "Ep:166, loss:0.00000, loss_test:0.08855, lr:5.87e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.763, tt:5972.432\n",
      "Ep:167, loss:0.00000, loss_test:0.09068, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.762, tt:6008.039\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00000, loss_test:0.09002, lr:5.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.762, tt:6043.757\n",
      "Ep:169, loss:0.00000, loss_test:0.09008, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.757, tt:6078.693\n",
      "Ep:170, loss:0.00000, loss_test:0.09073, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.756, tt:6114.249\n",
      "Ep:171, loss:0.00000, loss_test:0.09117, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.747, tt:6148.424\n",
      "Ep:172, loss:0.00000, loss_test:0.08884, lr:5.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.739, tt:6182.857\n",
      "Ep:173, loss:0.00000, loss_test:0.08824, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.739, tt:6218.666\n",
      "Ep:174, loss:0.00000, loss_test:0.08954, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.729, tt:6252.558\n",
      "Ep:175, loss:0.00000, loss_test:0.09018, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.718, tt:6286.354\n",
      "Ep:176, loss:0.00000, loss_test:0.08890, lr:5.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.704, tt:6319.606\n",
      "Ep:177, loss:0.00000, loss_test:0.08955, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.696, tt:6353.883\n",
      "Ep:178, loss:0.00000, loss_test:0.08935, lr:5.81e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.691, tt:6388.613\n",
      "Ep:179, loss:0.00000, loss_test:0.08984, lr:5.75e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.694, tt:6424.848\n",
      "Ep:180, loss:0.00000, loss_test:0.08943, lr:5.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.720, tt:6465.328\n",
      "Ep:181, loss:0.00000, loss_test:0.08929, lr:5.64e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.713, tt:6499.727\n",
      "Ep:182, loss:0.00000, loss_test:0.08962, lr:5.58e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.701, tt:6533.231\n",
      "Ep:183, loss:0.00000, loss_test:0.08908, lr:5.53e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.697, tt:6568.258\n",
      "Ep:184, loss:0.00000, loss_test:0.08963, lr:5.47e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.691, tt:6602.870\n",
      "Ep:185, loss:0.00000, loss_test:0.08998, lr:5.42e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.677, tt:6636.003\n",
      "Ep:186, loss:0.00000, loss_test:0.08986, lr:5.36e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.663, tt:6668.997\n",
      "Ep:187, loss:0.00000, loss_test:0.08982, lr:5.31e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.654, tt:6702.970\n",
      "Ep:188, loss:0.00000, loss_test:0.08942, lr:5.26e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.646, tt:6737.120\n",
      "Ep:189, loss:0.00000, loss_test:0.08868, lr:5.20e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.634, tt:6770.517\n",
      "Ep:190, loss:0.00000, loss_test:0.08979, lr:5.15e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.624, tt:6804.136\n",
      "Ep:191, loss:0.00000, loss_test:0.08971, lr:5.10e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.619, tt:6838.860\n",
      "Ep:192, loss:0.00000, loss_test:0.08902, lr:5.05e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.613, tt:6873.243\n",
      "Ep:193, loss:0.00000, loss_test:0.08907, lr:5.00e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.608, tt:6908.042\n",
      "Ep:194, loss:0.00000, loss_test:0.08932, lr:4.95e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.607, tt:6943.289\n",
      "Ep:195, loss:0.00000, loss_test:0.09037, lr:4.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.604, tt:6978.387\n",
      "Ep:196, loss:0.00000, loss_test:0.09059, lr:4.85e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.599, tt:7012.925\n",
      "Ep:197, loss:0.00000, loss_test:0.08937, lr:4.80e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.595, tt:7047.745\n",
      "Ep:198, loss:0.00000, loss_test:0.08898, lr:4.75e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.574, tt:7079.281\n",
      "Ep:199, loss:0.00000, loss_test:0.08995, lr:4.71e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.535, tt:7107.031\n",
      "Ep:200, loss:0.00000, loss_test:0.09020, lr:4.66e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.506, tt:7136.608\n",
      "Ep:201, loss:0.00000, loss_test:0.08978, lr:4.61e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.477, tt:7166.266\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02744, lr:6.00e-02, fs:0.62162 (r=0.697,p=0.561),  time:25.572, tt:25.572\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02420, lr:6.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:25.647, tt:51.294\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02669, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:27.128, tt:81.383\n",
      "Ep:3, loss:0.00005, loss_test:0.02650, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:27.755, tt:111.020\n",
      "Ep:4, loss:0.00005, loss_test:0.02568, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:28.060, tt:140.300\n",
      "Ep:5, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:28.381, tt:170.288\n",
      "Ep:6, loss:0.00005, loss_test:0.02465, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:28.603, tt:200.220\n",
      "Ep:7, loss:0.00005, loss_test:0.02438, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:28.725, tt:229.800\n",
      "Ep:8, loss:0.00005, loss_test:0.02411, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:28.922, tt:260.300\n",
      "Ep:9, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:28.994, tt:289.944\n",
      "Ep:10, loss:0.00005, loss_test:0.02358, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:29.139, tt:320.531\n",
      "Ep:11, loss:0.00005, loss_test:0.02332, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:29.298, tt:351.580\n",
      "Ep:12, loss:0.00005, loss_test:0.02303, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:29.353, tt:381.592\n",
      "Ep:13, loss:0.00005, loss_test:0.02281, lr:5.94e-02, fs:0.66920 (r=0.889,p=0.537),  time:29.464, tt:412.493\n",
      "Ep:14, loss:0.00004, loss_test:0.02276, lr:5.88e-02, fs:0.65873 (r=0.838,p=0.542),  time:29.452, tt:441.785\n",
      "Ep:15, loss:0.00004, loss_test:0.02295, lr:5.82e-02, fs:0.64490 (r=0.798,p=0.541),  time:29.488, tt:471.803\n",
      "Ep:16, loss:0.00004, loss_test:0.02324, lr:5.76e-02, fs:0.64754 (r=0.798,p=0.545),  time:29.458, tt:500.778\n",
      "Ep:17, loss:0.00004, loss_test:0.02338, lr:5.71e-02, fs:0.65021 (r=0.798,p=0.549),  time:29.497, tt:530.946\n",
      "Ep:18, loss:0.00004, loss_test:0.02324, lr:5.65e-02, fs:0.64490 (r=0.798,p=0.541),  time:29.552, tt:561.494\n",
      "Ep:19, loss:0.00004, loss_test:0.02289, lr:5.59e-02, fs:0.64257 (r=0.808,p=0.533),  time:29.515, tt:590.310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00004, loss_test:0.02249, lr:5.54e-02, fs:0.63492 (r=0.808,p=0.523),  time:29.575, tt:621.074\n",
      "Ep:21, loss:0.00004, loss_test:0.02218, lr:5.48e-02, fs:0.64314 (r=0.828,p=0.526),  time:29.578, tt:650.711\n",
      "Ep:22, loss:0.00004, loss_test:0.02198, lr:5.43e-02, fs:0.63492 (r=0.808,p=0.523),  time:29.672, tt:682.459\n",
      "Ep:23, loss:0.00004, loss_test:0.02175, lr:5.37e-02, fs:0.65306 (r=0.808,p=0.548),  time:29.716, tt:713.182\n",
      "Ep:24, loss:0.00004, loss_test:0.02141, lr:5.32e-02, fs:0.65574 (r=0.808,p=0.552),  time:29.754, tt:743.849\n",
      "Ep:25, loss:0.00004, loss_test:0.02108, lr:5.27e-02, fs:0.65021 (r=0.798,p=0.549),  time:29.810, tt:775.056\n",
      "Ep:26, loss:0.00004, loss_test:0.02069, lr:5.21e-02, fs:0.65574 (r=0.808,p=0.552),  time:29.824, tt:805.238\n",
      "Ep:27, loss:0.00004, loss_test:0.02036, lr:5.16e-02, fs:0.66129 (r=0.828,p=0.550),  time:29.839, tt:835.498\n",
      "Ep:28, loss:0.00004, loss_test:0.02007, lr:5.11e-02, fs:0.66397 (r=0.828,p=0.554),  time:29.851, tt:865.685\n",
      "Ep:29, loss:0.00004, loss_test:0.01984, lr:5.06e-02, fs:0.66393 (r=0.818,p=0.559),  time:29.830, tt:894.905\n",
      "Ep:30, loss:0.00004, loss_test:0.01961, lr:5.01e-02, fs:0.66946 (r=0.808,p=0.571),  time:29.879, tt:926.253\n",
      "Ep:31, loss:0.00004, loss_test:0.01932, lr:4.96e-02, fs:0.67227 (r=0.808,p=0.576),  time:29.887, tt:956.393\n",
      "Ep:32, loss:0.00003, loss_test:0.01900, lr:4.91e-02, fs:0.67500 (r=0.818,p=0.574),  time:29.883, tt:986.137\n",
      "Ep:33, loss:0.00003, loss_test:0.01865, lr:4.86e-02, fs:0.67500 (r=0.818,p=0.574),  time:29.867, tt:1015.488\n",
      "Ep:34, loss:0.00003, loss_test:0.01837, lr:4.81e-02, fs:0.68067 (r=0.818,p=0.583),  time:29.883, tt:1045.911\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01823, lr:4.81e-02, fs:0.69198 (r=0.828,p=0.594),  time:29.877, tt:1075.573\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01797, lr:4.81e-02, fs:0.69198 (r=0.828,p=0.594),  time:29.844, tt:1104.238\n",
      "Ep:37, loss:0.00003, loss_test:0.01759, lr:4.81e-02, fs:0.70588 (r=0.848,p=0.604),  time:29.831, tt:1133.562\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01720, lr:4.81e-02, fs:0.72199 (r=0.879,p=0.613),  time:29.828, tt:1163.291\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01698, lr:4.81e-02, fs:0.71730 (r=0.859,p=0.616),  time:29.825, tt:1192.991\n",
      "Ep:40, loss:0.00003, loss_test:0.01700, lr:4.81e-02, fs:0.69604 (r=0.798,p=0.617),  time:29.812, tt:1222.294\n",
      "Ep:41, loss:0.00003, loss_test:0.01680, lr:4.81e-02, fs:0.71930 (r=0.828,p=0.636),  time:29.821, tt:1252.496\n",
      "Ep:42, loss:0.00003, loss_test:0.01652, lr:4.81e-02, fs:0.73684 (r=0.848,p=0.651),  time:29.793, tt:1281.083\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01633, lr:4.81e-02, fs:0.74667 (r=0.848,p=0.667),  time:29.774, tt:1310.048\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01640, lr:4.81e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.744, tt:1338.475\n",
      "Ep:45, loss:0.00002, loss_test:0.01640, lr:4.81e-02, fs:0.75576 (r=0.828,p=0.695),  time:29.735, tt:1367.787\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01631, lr:4.81e-02, fs:0.76498 (r=0.838,p=0.703),  time:29.737, tt:1397.650\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01649, lr:4.81e-02, fs:0.76056 (r=0.818,p=0.711),  time:29.740, tt:1427.521\n",
      "Ep:48, loss:0.00002, loss_test:0.01647, lr:4.81e-02, fs:0.77143 (r=0.818,p=0.730),  time:29.712, tt:1455.897\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01645, lr:4.81e-02, fs:0.78095 (r=0.828,p=0.739),  time:29.713, tt:1485.665\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01641, lr:4.81e-02, fs:0.78095 (r=0.828,p=0.739),  time:29.701, tt:1514.728\n",
      "Ep:51, loss:0.00002, loss_test:0.01647, lr:4.81e-02, fs:0.78095 (r=0.828,p=0.739),  time:29.706, tt:1544.716\n",
      "Ep:52, loss:0.00002, loss_test:0.01650, lr:4.81e-02, fs:0.77885 (r=0.818,p=0.743),  time:29.689, tt:1573.535\n",
      "Ep:53, loss:0.00002, loss_test:0.01640, lr:4.81e-02, fs:0.77885 (r=0.818,p=0.743),  time:29.715, tt:1604.616\n",
      "Ep:54, loss:0.00002, loss_test:0.01624, lr:4.81e-02, fs:0.78261 (r=0.818,p=0.750),  time:29.755, tt:1636.545\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01622, lr:4.81e-02, fs:0.78641 (r=0.818,p=0.757),  time:29.733, tt:1665.045\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01635, lr:4.81e-02, fs:0.78049 (r=0.808,p=0.755),  time:29.745, tt:1695.458\n",
      "Ep:57, loss:0.00002, loss_test:0.01616, lr:4.81e-02, fs:0.78049 (r=0.808,p=0.755),  time:29.753, tt:1725.670\n",
      "Ep:58, loss:0.00001, loss_test:0.01589, lr:4.81e-02, fs:0.79227 (r=0.828,p=0.759),  time:29.749, tt:1755.206\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01599, lr:4.81e-02, fs:0.80193 (r=0.838,p=0.769),  time:29.778, tt:1786.655\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01644, lr:4.81e-02, fs:0.78431 (r=0.808,p=0.762),  time:29.775, tt:1816.268\n",
      "Ep:61, loss:0.00001, loss_test:0.01620, lr:4.81e-02, fs:0.79024 (r=0.818,p=0.764),  time:29.779, tt:1846.275\n",
      "Ep:62, loss:0.00001, loss_test:0.01614, lr:4.81e-02, fs:0.79612 (r=0.828,p=0.766),  time:29.770, tt:1875.498\n",
      "Ep:63, loss:0.00001, loss_test:0.01619, lr:4.81e-02, fs:0.79426 (r=0.838,p=0.755),  time:29.777, tt:1905.720\n",
      "Ep:64, loss:0.00001, loss_test:0.01692, lr:4.81e-02, fs:0.79208 (r=0.808,p=0.777),  time:29.811, tt:1937.718\n",
      "Ep:65, loss:0.00001, loss_test:0.01634, lr:4.81e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.831, tt:1968.850\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01626, lr:4.81e-02, fs:0.80383 (r=0.848,p=0.764),  time:29.824, tt:1998.236\n",
      "Ep:67, loss:0.00001, loss_test:0.01663, lr:4.81e-02, fs:0.78049 (r=0.808,p=0.755),  time:29.833, tt:2028.622\n",
      "Ep:68, loss:0.00001, loss_test:0.01674, lr:4.81e-02, fs:0.81517 (r=0.869,p=0.768),  time:29.841, tt:2059.013\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01670, lr:4.81e-02, fs:0.80000 (r=0.848,p=0.757),  time:29.861, tt:2090.278\n",
      "Ep:70, loss:0.00001, loss_test:0.01717, lr:4.81e-02, fs:0.78607 (r=0.798,p=0.775),  time:29.884, tt:2121.739\n",
      "Ep:71, loss:0.00001, loss_test:0.01716, lr:4.81e-02, fs:0.80769 (r=0.848,p=0.771),  time:29.876, tt:2151.078\n",
      "Ep:72, loss:0.00001, loss_test:0.01686, lr:4.81e-02, fs:0.80383 (r=0.848,p=0.764),  time:29.879, tt:2181.189\n",
      "Ep:73, loss:0.00001, loss_test:0.01809, lr:4.81e-02, fs:0.78000 (r=0.788,p=0.772),  time:29.883, tt:2211.365\n",
      "Ep:74, loss:0.00001, loss_test:0.01741, lr:4.81e-02, fs:0.78000 (r=0.788,p=0.772),  time:29.891, tt:2241.802\n",
      "Ep:75, loss:0.00001, loss_test:0.01753, lr:4.81e-02, fs:0.80769 (r=0.848,p=0.771),  time:29.893, tt:2271.869\n",
      "Ep:76, loss:0.00001, loss_test:0.01799, lr:4.81e-02, fs:0.77949 (r=0.768,p=0.792),  time:29.901, tt:2302.346\n",
      "Ep:77, loss:0.00001, loss_test:0.01810, lr:4.81e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.900, tt:2332.225\n",
      "Ep:78, loss:0.00001, loss_test:0.01813, lr:4.81e-02, fs:0.81188 (r=0.828,p=0.796),  time:29.893, tt:2361.523\n",
      "Ep:79, loss:0.00001, loss_test:0.01877, lr:4.81e-02, fs:0.78125 (r=0.758,p=0.806),  time:29.901, tt:2392.041\n",
      "Ep:80, loss:0.00001, loss_test:0.01869, lr:4.76e-02, fs:0.79365 (r=0.758,p=0.833),  time:29.926, tt:2424.028\n",
      "Ep:81, loss:0.00001, loss_test:0.01912, lr:4.71e-02, fs:0.77487 (r=0.747,p=0.804),  time:29.948, tt:2455.770\n",
      "Ep:82, loss:0.00001, loss_test:0.01959, lr:4.67e-02, fs:0.75824 (r=0.697,p=0.831),  time:29.958, tt:2486.554\n",
      "Ep:83, loss:0.00001, loss_test:0.01979, lr:4.62e-02, fs:0.75410 (r=0.697,p=0.821),  time:29.955, tt:2516.209\n",
      "Ep:84, loss:0.00001, loss_test:0.01984, lr:4.57e-02, fs:0.75138 (r=0.687,p=0.829),  time:29.960, tt:2546.576\n",
      "Ep:85, loss:0.00001, loss_test:0.02095, lr:4.53e-02, fs:0.72626 (r=0.657,p=0.812),  time:29.969, tt:2577.370\n",
      "Ep:86, loss:0.00001, loss_test:0.02041, lr:4.48e-02, fs:0.74157 (r=0.667,p=0.835),  time:29.972, tt:2607.567\n",
      "Ep:87, loss:0.00001, loss_test:0.02126, lr:4.44e-02, fs:0.72316 (r=0.646,p=0.821),  time:29.982, tt:2638.429\n",
      "Ep:88, loss:0.00001, loss_test:0.02133, lr:4.39e-02, fs:0.72000 (r=0.636,p=0.829),  time:29.994, tt:2669.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00001, loss_test:0.02149, lr:4.35e-02, fs:0.70930 (r=0.616,p=0.836),  time:29.990, tt:2699.079\n",
      "Ep:90, loss:0.00001, loss_test:0.02199, lr:4.31e-02, fs:0.72093 (r=0.626,p=0.849),  time:29.987, tt:2728.797\n",
      "Ep:91, loss:0.00000, loss_test:0.02223, lr:4.26e-02, fs:0.70930 (r=0.616,p=0.836),  time:29.994, tt:2759.421\n",
      "Ep:92, loss:0.00000, loss_test:0.02227, lr:4.22e-02, fs:0.70520 (r=0.616,p=0.824),  time:30.007, tt:2790.672\n",
      "Ep:93, loss:0.00000, loss_test:0.02309, lr:4.18e-02, fs:0.70588 (r=0.606,p=0.845),  time:30.012, tt:2821.172\n",
      "Ep:94, loss:0.00000, loss_test:0.02291, lr:4.14e-02, fs:0.74118 (r=0.636,p=0.887),  time:30.021, tt:2851.992\n",
      "Ep:95, loss:0.00001, loss_test:0.02317, lr:4.10e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.025, tt:2882.389\n",
      "Ep:96, loss:0.00000, loss_test:0.02365, lr:4.05e-02, fs:0.70520 (r=0.616,p=0.824),  time:30.032, tt:2913.066\n",
      "Ep:97, loss:0.00000, loss_test:0.02322, lr:4.01e-02, fs:0.70588 (r=0.606,p=0.845),  time:30.037, tt:2943.595\n",
      "Ep:98, loss:0.00000, loss_test:0.02392, lr:3.97e-02, fs:0.74118 (r=0.636,p=0.887),  time:30.033, tt:2973.249\n",
      "Ep:99, loss:0.00000, loss_test:0.02458, lr:3.93e-02, fs:0.70175 (r=0.606,p=0.833),  time:30.030, tt:3003.003\n",
      "Ep:100, loss:0.00000, loss_test:0.02340, lr:3.89e-02, fs:0.72000 (r=0.636,p=0.829),  time:30.037, tt:3033.765\n",
      "Ep:101, loss:0.00000, loss_test:0.02446, lr:3.86e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.039, tt:3064.001\n",
      "Ep:102, loss:0.00000, loss_test:0.02569, lr:3.82e-02, fs:0.72619 (r=0.616,p=0.884),  time:30.055, tt:3095.707\n",
      "Ep:103, loss:0.00000, loss_test:0.02381, lr:3.78e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.063, tt:3126.532\n",
      "Ep:104, loss:0.00000, loss_test:0.02562, lr:3.74e-02, fs:0.71429 (r=0.606,p=0.870),  time:30.071, tt:3157.467\n",
      "Ep:105, loss:0.00000, loss_test:0.02667, lr:3.70e-02, fs:0.73494 (r=0.616,p=0.910),  time:30.066, tt:3186.989\n",
      "Ep:106, loss:0.00000, loss_test:0.02522, lr:3.67e-02, fs:0.71429 (r=0.606,p=0.870),  time:30.066, tt:3217.014\n",
      "Ep:107, loss:0.00000, loss_test:0.02665, lr:3.63e-02, fs:0.71429 (r=0.606,p=0.870),  time:30.079, tt:3248.545\n",
      "Ep:108, loss:0.00000, loss_test:0.02736, lr:3.59e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.070, tt:3277.650\n",
      "Ep:109, loss:0.00000, loss_test:0.02647, lr:3.56e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.064, tt:3306.994\n",
      "Ep:110, loss:0.00000, loss_test:0.02820, lr:3.52e-02, fs:0.70588 (r=0.606,p=0.845),  time:30.038, tt:3334.239\n",
      "Ep:111, loss:0.00000, loss_test:0.02746, lr:3.49e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.039, tt:3364.394\n",
      "Ep:112, loss:0.00000, loss_test:0.02767, lr:3.45e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.042, tt:3394.720\n",
      "Ep:113, loss:0.00000, loss_test:0.02883, lr:3.42e-02, fs:0.72727 (r=0.606,p=0.909),  time:30.043, tt:3424.942\n",
      "Ep:114, loss:0.00000, loss_test:0.02840, lr:3.38e-02, fs:0.71429 (r=0.606,p=0.870),  time:30.052, tt:3456.008\n",
      "Ep:115, loss:0.00000, loss_test:0.02803, lr:3.35e-02, fs:0.72289 (r=0.606,p=0.896),  time:30.061, tt:3487.108\n",
      "Ep:116, loss:0.00000, loss_test:0.02984, lr:3.32e-02, fs:0.72289 (r=0.606,p=0.896),  time:30.063, tt:3517.420\n",
      "Ep:117, loss:0.00000, loss_test:0.02811, lr:3.28e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.077, tt:3549.054\n",
      "Ep:118, loss:0.00000, loss_test:0.02870, lr:3.25e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.067, tt:3577.966\n",
      "Ep:119, loss:0.00000, loss_test:0.03003, lr:3.22e-02, fs:0.71951 (r=0.596,p=0.908),  time:30.053, tt:3606.358\n",
      "Ep:120, loss:0.00000, loss_test:0.02938, lr:3.19e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.051, tt:3636.174\n",
      "Ep:121, loss:0.00000, loss_test:0.02983, lr:3.15e-02, fs:0.71951 (r=0.596,p=0.908),  time:30.074, tt:3668.993\n",
      "Ep:122, loss:0.00000, loss_test:0.03138, lr:3.12e-02, fs:0.70732 (r=0.586,p=0.892),  time:30.074, tt:3699.060\n",
      "Ep:123, loss:0.00000, loss_test:0.02986, lr:3.09e-02, fs:0.71166 (r=0.586,p=0.906),  time:30.071, tt:3728.851\n",
      "Ep:124, loss:0.00000, loss_test:0.03105, lr:3.06e-02, fs:0.71856 (r=0.606,p=0.882),  time:30.076, tt:3759.514\n",
      "Ep:125, loss:0.00000, loss_test:0.03147, lr:3.03e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.071, tt:3788.903\n",
      "Ep:126, loss:0.00000, loss_test:0.03117, lr:3.00e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.068, tt:3818.581\n",
      "Ep:127, loss:0.00000, loss_test:0.03115, lr:2.97e-02, fs:0.71166 (r=0.586,p=0.906),  time:30.075, tt:3849.612\n",
      "Ep:128, loss:0.00000, loss_test:0.03236, lr:2.94e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.074, tt:3879.497\n",
      "Ep:129, loss:0.00000, loss_test:0.03149, lr:2.91e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.079, tt:3910.219\n",
      "Ep:130, loss:0.00000, loss_test:0.03242, lr:2.88e-02, fs:0.71951 (r=0.596,p=0.908),  time:30.087, tt:3941.355\n",
      "Ep:131, loss:0.00000, loss_test:0.03260, lr:2.85e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.078, tt:3970.299\n",
      "Ep:132, loss:0.00000, loss_test:0.03258, lr:2.82e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.073, tt:3999.740\n",
      "Ep:133, loss:0.00000, loss_test:0.03273, lr:2.80e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.081, tt:4030.852\n",
      "Ep:134, loss:0.00000, loss_test:0.03369, lr:2.77e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.089, tt:4062.063\n",
      "Ep:135, loss:0.00000, loss_test:0.03277, lr:2.74e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.088, tt:4091.960\n",
      "Ep:136, loss:0.00000, loss_test:0.03383, lr:2.71e-02, fs:0.70000 (r=0.566,p=0.918),  time:30.094, tt:4122.923\n",
      "Ep:137, loss:0.00000, loss_test:0.03402, lr:2.69e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.100, tt:4153.789\n",
      "Ep:138, loss:0.00000, loss_test:0.03346, lr:2.66e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.104, tt:4184.433\n",
      "Ep:139, loss:0.00000, loss_test:0.03443, lr:2.63e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.107, tt:4214.931\n",
      "Ep:140, loss:0.00000, loss_test:0.03490, lr:2.61e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.117, tt:4246.468\n",
      "Ep:141, loss:0.00000, loss_test:0.03419, lr:2.58e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.128, tt:4278.150\n",
      "Ep:142, loss:0.00000, loss_test:0.03526, lr:2.55e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.129, tt:4308.440\n",
      "Ep:143, loss:0.00000, loss_test:0.03516, lr:2.53e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.136, tt:4339.511\n",
      "Ep:144, loss:0.00000, loss_test:0.03504, lr:2.50e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.157, tt:4372.757\n",
      "Ep:145, loss:0.00000, loss_test:0.03575, lr:2.48e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.159, tt:4403.186\n",
      "Ep:146, loss:0.00000, loss_test:0.03551, lr:2.45e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.173, tt:4435.408\n",
      "Ep:147, loss:0.00000, loss_test:0.03556, lr:2.43e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.198, tt:4469.243\n",
      "Ep:148, loss:0.00000, loss_test:0.03624, lr:2.40e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.202, tt:4500.045\n",
      "Ep:149, loss:0.00000, loss_test:0.03598, lr:2.38e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.197, tt:4529.479\n",
      "Ep:150, loss:0.00000, loss_test:0.03613, lr:2.36e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.197, tt:4559.697\n",
      "Ep:151, loss:0.00000, loss_test:0.03639, lr:2.33e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.193, tt:4589.308\n",
      "Ep:152, loss:0.00000, loss_test:0.03674, lr:2.31e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.187, tt:4618.550\n",
      "Ep:153, loss:0.00000, loss_test:0.03641, lr:2.29e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.191, tt:4649.349\n",
      "Ep:154, loss:0.00000, loss_test:0.03673, lr:2.26e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.193, tt:4679.917\n",
      "Ep:155, loss:0.00000, loss_test:0.03702, lr:2.24e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.190, tt:4709.647\n",
      "Ep:156, loss:0.00000, loss_test:0.03710, lr:2.22e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.201, tt:4741.567\n",
      "Ep:157, loss:0.00000, loss_test:0.03708, lr:2.20e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.199, tt:4771.414\n",
      "Ep:158, loss:0.00000, loss_test:0.03782, lr:2.17e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.204, tt:4802.358\n",
      "Ep:159, loss:0.00000, loss_test:0.03753, lr:2.15e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.202, tt:4832.357\n",
      "Ep:160, loss:0.00000, loss_test:0.03751, lr:2.13e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.204, tt:4862.765\n",
      "Ep:161, loss:0.00000, loss_test:0.03811, lr:2.11e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.203, tt:4892.844\n",
      "Ep:162, loss:0.00000, loss_test:0.03797, lr:2.09e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.205, tt:4923.371\n",
      "Ep:163, loss:0.00000, loss_test:0.03776, lr:2.07e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.212, tt:4954.689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:164, loss:0.00000, loss_test:0.03821, lr:2.05e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.214, tt:4985.269\n",
      "Ep:165, loss:0.00000, loss_test:0.03832, lr:2.03e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.215, tt:5015.769\n",
      "Ep:166, loss:0.00000, loss_test:0.03815, lr:2.01e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.213, tt:5045.493\n",
      "Ep:167, loss:0.00000, loss_test:0.03853, lr:1.99e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.210, tt:5075.344\n",
      "Ep:168, loss:0.00000, loss_test:0.03834, lr:1.97e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.213, tt:5105.953\n",
      "Ep:169, loss:0.00000, loss_test:0.03854, lr:1.95e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.214, tt:5136.339\n",
      "Ep:170, loss:0.00000, loss_test:0.03876, lr:1.93e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.219, tt:5167.458\n",
      "Ep:171, loss:0.00000, loss_test:0.03862, lr:1.91e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.225, tt:5198.758\n",
      "Ep:172, loss:0.00000, loss_test:0.03857, lr:1.89e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.229, tt:5229.702\n",
      "Ep:173, loss:0.00000, loss_test:0.03916, lr:1.87e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.249, tt:5263.282\n",
      "Ep:174, loss:0.00000, loss_test:0.03902, lr:1.85e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.254, tt:5294.507\n",
      "Ep:175, loss:0.00000, loss_test:0.03887, lr:1.83e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.256, tt:5324.991\n",
      "Ep:176, loss:0.00000, loss_test:0.03943, lr:1.81e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.252, tt:5354.565\n",
      "Ep:177, loss:0.00000, loss_test:0.03933, lr:1.80e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.250, tt:5384.421\n",
      "Ep:178, loss:0.00000, loss_test:0.03922, lr:1.78e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.250, tt:5414.690\n",
      "Ep:179, loss:0.00000, loss_test:0.03931, lr:1.76e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.248, tt:5444.669\n",
      "Ep:180, loss:0.00000, loss_test:0.03962, lr:1.74e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.249, tt:5475.067\n",
      "Ep:181, loss:0.00000, loss_test:0.03947, lr:1.73e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.247, tt:5505.030\n",
      "Ep:182, loss:0.00000, loss_test:0.03948, lr:1.71e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.245, tt:5534.906\n",
      "Ep:183, loss:0.00000, loss_test:0.03972, lr:1.69e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.244, tt:5564.852\n",
      "Ep:184, loss:0.00000, loss_test:0.03964, lr:1.67e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.244, tt:5595.191\n",
      "Ep:185, loss:0.00000, loss_test:0.03974, lr:1.66e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.251, tt:5626.728\n",
      "Ep:186, loss:0.00000, loss_test:0.03998, lr:1.64e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.251, tt:5656.925\n",
      "Ep:187, loss:0.00000, loss_test:0.04002, lr:1.62e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.245, tt:5686.047\n",
      "Ep:188, loss:0.00000, loss_test:0.03980, lr:1.61e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.245, tt:5716.340\n",
      "Ep:189, loss:0.00000, loss_test:0.03990, lr:1.59e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.241, tt:5745.745\n",
      "Ep:190, loss:0.00000, loss_test:0.04023, lr:1.58e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.239, tt:5775.740\n",
      "Ep:191, loss:0.00000, loss_test:0.04017, lr:1.56e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.239, tt:5805.840\n",
      "Ep:192, loss:0.00000, loss_test:0.04031, lr:1.54e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.233, tt:5835.052\n",
      "Ep:193, loss:0.00000, loss_test:0.04029, lr:1.53e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.234, tt:5865.324\n",
      "Ep:194, loss:0.00000, loss_test:0.04035, lr:1.51e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.228, tt:5894.478\n",
      "Ep:195, loss:0.00000, loss_test:0.04031, lr:1.50e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.222, tt:5923.439\n",
      "Ep:196, loss:0.00000, loss_test:0.04049, lr:1.48e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.206, tt:5950.554\n",
      "Ep:197, loss:0.00000, loss_test:0.04067, lr:1.47e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.191, tt:5977.802\n",
      "Ep:198, loss:0.00000, loss_test:0.04052, lr:1.45e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.176, tt:6005.017\n",
      "Ep:199, loss:0.00000, loss_test:0.04074, lr:1.44e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.154, tt:6030.809\n",
      "Ep:200, loss:0.00000, loss_test:0.04072, lr:1.43e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.132, tt:6056.456\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12774, lr:1.00e-02, fs:0.68657 (r=0.929,p=0.544),  time:26.334, tt:26.334\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12639, lr:1.00e-02, fs:0.68657 (r=0.929,p=0.544),  time:27.684, tt:55.367\n",
      "Ep:2, loss:0.00027, loss_test:0.12520, lr:1.00e-02, fs:0.68657 (r=0.929,p=0.544),  time:28.871, tt:86.614\n",
      "Ep:3, loss:0.00026, loss_test:0.12448, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:29.339, tt:117.357\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12349, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:29.263, tt:146.314\n",
      "Ep:5, loss:0.00026, loss_test:0.12235, lr:1.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:29.357, tt:176.143\n",
      "Ep:6, loss:0.00025, loss_test:0.12109, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.661, tt:207.628\n",
      "Ep:7, loss:0.00025, loss_test:0.12003, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:29.663, tt:237.304\n",
      "Ep:8, loss:0.00025, loss_test:0.11890, lr:1.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:29.929, tt:269.361\n",
      "Ep:9, loss:0.00024, loss_test:0.11785, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:30.162, tt:301.615\n",
      "Ep:10, loss:0.00024, loss_test:0.11732, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:30.266, tt:332.927\n",
      "Ep:11, loss:0.00023, loss_test:0.11696, lr:1.00e-02, fs:0.66376 (r=0.768,p=0.585),  time:30.490, tt:365.881\n",
      "Ep:12, loss:0.00023, loss_test:0.11724, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:30.463, tt:396.025\n",
      "Ep:13, loss:0.00023, loss_test:0.11771, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:30.437, tt:426.123\n",
      "Ep:14, loss:0.00022, loss_test:0.11751, lr:1.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:30.503, tt:457.539\n",
      "Ep:15, loss:0.00022, loss_test:0.11687, lr:9.90e-03, fs:0.66368 (r=0.747,p=0.597),  time:30.563, tt:489.013\n",
      "Ep:16, loss:0.00022, loss_test:0.11574, lr:9.80e-03, fs:0.66667 (r=0.747,p=0.602),  time:30.539, tt:519.161\n",
      "Ep:17, loss:0.00021, loss_test:0.11497, lr:9.70e-03, fs:0.66968 (r=0.747,p=0.607),  time:30.535, tt:549.635\n",
      "Ep:18, loss:0.00021, loss_test:0.11392, lr:9.61e-03, fs:0.67257 (r=0.768,p=0.598),  time:30.518, tt:579.840\n",
      "Ep:19, loss:0.00021, loss_test:0.11228, lr:9.51e-03, fs:0.69604 (r=0.798,p=0.617),  time:30.616, tt:612.319\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.11112, lr:9.51e-03, fs:0.69912 (r=0.798,p=0.622),  time:30.603, tt:642.655\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.11017, lr:9.51e-03, fs:0.69604 (r=0.798,p=0.617),  time:30.642, tt:674.124\n",
      "Ep:22, loss:0.00020, loss_test:0.10892, lr:9.51e-03, fs:0.70742 (r=0.818,p=0.623),  time:30.677, tt:705.569\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.10784, lr:9.51e-03, fs:0.70435 (r=0.818,p=0.618),  time:30.651, tt:735.615\n",
      "Ep:24, loss:0.00019, loss_test:0.10688, lr:9.51e-03, fs:0.70996 (r=0.828,p=0.621),  time:30.625, tt:765.637\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.10600, lr:9.51e-03, fs:0.70638 (r=0.838,p=0.610),  time:30.601, tt:795.623\n",
      "Ep:26, loss:0.00018, loss_test:0.10517, lr:9.51e-03, fs:0.71861 (r=0.838,p=0.629),  time:30.587, tt:825.854\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.10437, lr:9.51e-03, fs:0.72727 (r=0.848,p=0.636),  time:30.571, tt:855.987\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.10298, lr:9.51e-03, fs:0.73684 (r=0.848,p=0.651),  time:30.599, tt:887.372\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.10172, lr:9.51e-03, fs:0.74009 (r=0.848,p=0.656),  time:30.603, tt:918.089\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00016, loss_test:0.10057, lr:9.51e-03, fs:0.73778 (r=0.838,p=0.659),  time:30.604, tt:948.732\n",
      "Ep:31, loss:0.00015, loss_test:0.10175, lr:9.51e-03, fs:0.75113 (r=0.838,p=0.680),  time:30.609, tt:979.474\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.09998, lr:9.51e-03, fs:0.75676 (r=0.848,p=0.683),  time:30.602, tt:1009.856\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.10196, lr:9.51e-03, fs:0.76498 (r=0.838,p=0.703),  time:30.558, tt:1038.983\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.09750, lr:9.51e-03, fs:0.76364 (r=0.848,p=0.694),  time:30.547, tt:1069.161\n",
      "Ep:35, loss:0.00013, loss_test:0.09845, lr:9.51e-03, fs:0.77570 (r=0.838,p=0.722),  time:30.563, tt:1100.282\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.10446, lr:9.51e-03, fs:0.79621 (r=0.848,p=0.750),  time:30.553, tt:1130.462\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00013, loss_test:0.09798, lr:9.51e-03, fs:0.76777 (r=0.818,p=0.723),  time:30.532, tt:1160.211\n",
      "Ep:38, loss:0.00012, loss_test:0.09555, lr:9.51e-03, fs:0.80976 (r=0.838,p=0.783),  time:30.508, tt:1189.810\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.09228, lr:9.51e-03, fs:0.81773 (r=0.838,p=0.798),  time:30.499, tt:1219.949\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.09357, lr:9.51e-03, fs:0.79602 (r=0.808,p=0.784),  time:30.495, tt:1250.275\n",
      "Ep:41, loss:0.00009, loss_test:0.09502, lr:9.51e-03, fs:0.81818 (r=0.818,p=0.818),  time:30.497, tt:1280.869\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.08981, lr:9.51e-03, fs:0.83168 (r=0.848,p=0.816),  time:30.516, tt:1312.182\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.09386, lr:9.51e-03, fs:0.80628 (r=0.778,p=0.837),  time:30.518, tt:1342.785\n",
      "Ep:44, loss:0.00008, loss_test:0.08949, lr:9.51e-03, fs:0.80392 (r=0.828,p=0.781),  time:30.500, tt:1372.480\n",
      "Ep:45, loss:0.00008, loss_test:0.09236, lr:9.51e-03, fs:0.85864 (r=0.828,p=0.891),  time:30.459, tt:1401.132\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.08469, lr:9.51e-03, fs:0.84694 (r=0.838,p=0.856),  time:30.451, tt:1431.208\n",
      "Ep:47, loss:0.00007, loss_test:0.08844, lr:9.51e-03, fs:0.79381 (r=0.778,p=0.811),  time:30.450, tt:1461.608\n",
      "Ep:48, loss:0.00006, loss_test:0.08429, lr:9.51e-03, fs:0.83000 (r=0.838,p=0.822),  time:30.432, tt:1491.184\n",
      "Ep:49, loss:0.00006, loss_test:0.08611, lr:9.51e-03, fs:0.87234 (r=0.828,p=0.921),  time:30.424, tt:1521.218\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.08367, lr:9.51e-03, fs:0.84422 (r=0.848,p=0.840),  time:30.418, tt:1551.317\n",
      "Ep:51, loss:0.00006, loss_test:0.08562, lr:9.51e-03, fs:0.80412 (r=0.788,p=0.821),  time:30.407, tt:1581.169\n",
      "Ep:52, loss:0.00006, loss_test:0.09146, lr:9.51e-03, fs:0.82609 (r=0.768,p=0.894),  time:30.428, tt:1612.691\n",
      "Ep:53, loss:0.00005, loss_test:0.08340, lr:9.51e-03, fs:0.79793 (r=0.778,p=0.819),  time:30.433, tt:1643.374\n",
      "Ep:54, loss:0.00005, loss_test:0.08703, lr:9.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:30.460, tt:1675.304\n",
      "Ep:55, loss:0.00004, loss_test:0.08720, lr:9.51e-03, fs:0.84375 (r=0.818,p=0.871),  time:30.459, tt:1705.724\n",
      "Ep:56, loss:0.00004, loss_test:0.08132, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:30.498, tt:1738.383\n",
      "Ep:57, loss:0.00004, loss_test:0.08369, lr:9.51e-03, fs:0.81481 (r=0.778,p=0.856),  time:30.505, tt:1769.300\n",
      "Ep:58, loss:0.00004, loss_test:0.08344, lr:9.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:30.530, tt:1801.263\n",
      "Ep:59, loss:0.00003, loss_test:0.08234, lr:9.51e-03, fs:0.86458 (r=0.838,p=0.892),  time:30.534, tt:1832.012\n",
      "Ep:60, loss:0.00003, loss_test:0.08451, lr:9.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:30.555, tt:1863.851\n",
      "Ep:61, loss:0.00003, loss_test:0.07990, lr:9.41e-03, fs:0.85864 (r=0.828,p=0.891),  time:30.566, tt:1895.065\n",
      "Ep:62, loss:0.00003, loss_test:0.08024, lr:9.32e-03, fs:0.85263 (r=0.818,p=0.890),  time:30.573, tt:1926.096\n",
      "Ep:63, loss:0.00003, loss_test:0.08689, lr:9.23e-03, fs:0.83598 (r=0.798,p=0.878),  time:30.582, tt:1957.272\n",
      "Ep:64, loss:0.00003, loss_test:0.08732, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.565, tt:1986.715\n",
      "Ep:65, loss:0.00002, loss_test:0.07806, lr:9.04e-03, fs:0.83598 (r=0.798,p=0.878),  time:30.572, tt:2017.751\n",
      "Ep:66, loss:0.00002, loss_test:0.09191, lr:8.95e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.607, tt:2050.685\n",
      "Ep:67, loss:0.00002, loss_test:0.07555, lr:8.86e-03, fs:0.87500 (r=0.848,p=0.903),  time:30.620, tt:2082.174\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.08843, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.620, tt:2112.757\n",
      "Ep:69, loss:0.00002, loss_test:0.08094, lr:8.86e-03, fs:0.83158 (r=0.798,p=0.868),  time:30.616, tt:2143.123\n",
      "Ep:70, loss:0.00002, loss_test:0.08554, lr:8.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.602, tt:2172.741\n",
      "Ep:71, loss:0.00002, loss_test:0.08436, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.600, tt:2203.193\n",
      "Ep:72, loss:0.00002, loss_test:0.08488, lr:8.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.613, tt:2234.734\n",
      "Ep:73, loss:0.00002, loss_test:0.08348, lr:8.86e-03, fs:0.85714 (r=0.788,p=0.940),  time:30.641, tt:2267.421\n",
      "Ep:74, loss:0.00002, loss_test:0.08049, lr:8.86e-03, fs:0.82609 (r=0.768,p=0.894),  time:30.664, tt:2299.780\n",
      "Ep:75, loss:0.00001, loss_test:0.09162, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.663, tt:2330.363\n",
      "Ep:76, loss:0.00001, loss_test:0.08184, lr:8.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.661, tt:2360.888\n",
      "Ep:77, loss:0.00002, loss_test:0.09836, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.657, tt:2391.248\n",
      "Ep:78, loss:0.00002, loss_test:0.08171, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.659, tt:2422.089\n",
      "Ep:79, loss:0.00001, loss_test:0.09270, lr:8.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.648, tt:2451.831\n",
      "Ep:80, loss:0.00001, loss_test:0.08288, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.656, tt:2483.115\n",
      "Ep:81, loss:0.00001, loss_test:0.08750, lr:8.60e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.647, tt:2513.047\n",
      "Ep:82, loss:0.00001, loss_test:0.09195, lr:8.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.644, tt:2543.427\n",
      "Ep:83, loss:0.00001, loss_test:0.08359, lr:8.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.639, tt:2573.668\n",
      "Ep:84, loss:0.00001, loss_test:0.08991, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.639, tt:2604.335\n",
      "Ep:85, loss:0.00001, loss_test:0.08402, lr:8.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.657, tt:2636.492\n",
      "Ep:86, loss:0.00001, loss_test:0.08900, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.652, tt:2666.713\n",
      "Ep:87, loss:0.00001, loss_test:0.08734, lr:8.10e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.664, tt:2698.467\n",
      "Ep:88, loss:0.00001, loss_test:0.09425, lr:8.02e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.680, tt:2730.563\n",
      "Ep:89, loss:0.00001, loss_test:0.08512, lr:7.94e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.672, tt:2760.471\n",
      "Ep:90, loss:0.00001, loss_test:0.09126, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.666, tt:2790.608\n",
      "Ep:91, loss:0.00001, loss_test:0.08469, lr:7.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.665, tt:2821.216\n",
      "Ep:92, loss:0.00001, loss_test:0.09132, lr:7.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.684, tt:2853.579\n",
      "Ep:93, loss:0.00001, loss_test:0.08821, lr:7.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.696, tt:2885.441\n",
      "Ep:94, loss:0.00001, loss_test:0.09121, lr:7.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.707, tt:2917.209\n",
      "Ep:95, loss:0.00001, loss_test:0.08666, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.731, tt:2950.222\n",
      "Ep:96, loss:0.00001, loss_test:0.09242, lr:7.40e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.739, tt:2981.653\n",
      "Ep:97, loss:0.00001, loss_test:0.09021, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.735, tt:3012.074\n",
      "Ep:98, loss:0.00001, loss_test:0.08677, lr:7.25e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.752, tt:3044.486\n",
      "Ep:99, loss:0.00000, loss_test:0.09115, lr:7.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.751, tt:3075.061\n",
      "Ep:100, loss:0.00000, loss_test:0.08719, lr:7.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.763, tt:3107.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00000, loss_test:0.09055, lr:7.03e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.789, tt:3140.490\n",
      "Ep:102, loss:0.00000, loss_test:0.09153, lr:6.96e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.786, tt:3170.976\n",
      "Ep:103, loss:0.00000, loss_test:0.09093, lr:6.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.792, tt:3202.401\n",
      "Ep:104, loss:0.00000, loss_test:0.09098, lr:6.83e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.790, tt:3232.948\n",
      "Ep:105, loss:0.00000, loss_test:0.09310, lr:6.76e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.796, tt:3264.348\n",
      "Ep:106, loss:0.00000, loss_test:0.08852, lr:6.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.810, tt:3296.638\n",
      "Ep:107, loss:0.00000, loss_test:0.09378, lr:6.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.796, tt:3325.926\n",
      "Ep:108, loss:0.00000, loss_test:0.09329, lr:6.56e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.794, tt:3356.555\n",
      "Ep:109, loss:0.00000, loss_test:0.08906, lr:6.49e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.799, tt:3387.862\n",
      "Ep:110, loss:0.00000, loss_test:0.09295, lr:6.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.803, tt:3419.163\n",
      "Ep:111, loss:0.00000, loss_test:0.08954, lr:6.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.813, tt:3451.025\n",
      "Ep:112, loss:0.00000, loss_test:0.09186, lr:6.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.820, tt:3482.630\n",
      "Ep:113, loss:0.00000, loss_test:0.09226, lr:6.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.819, tt:3513.350\n",
      "Ep:114, loss:0.00000, loss_test:0.09229, lr:6.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.826, tt:3544.938\n",
      "Ep:115, loss:0.00000, loss_test:0.09031, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.822, tt:3575.394\n",
      "Ep:116, loss:0.00000, loss_test:0.09185, lr:6.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.819, tt:3605.840\n",
      "Ep:117, loss:0.00000, loss_test:0.09229, lr:5.99e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.831, tt:3638.055\n",
      "Ep:118, loss:0.00000, loss_test:0.09117, lr:5.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.841, tt:3670.048\n",
      "Ep:119, loss:0.00000, loss_test:0.09259, lr:5.87e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.852, tt:3702.285\n",
      "Ep:120, loss:0.00000, loss_test:0.09177, lr:5.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.865, tt:3734.658\n",
      "Ep:121, loss:0.00000, loss_test:0.09152, lr:5.75e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.864, tt:3765.454\n",
      "Ep:122, loss:0.00000, loss_test:0.09288, lr:5.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.867, tt:3796.660\n",
      "Ep:123, loss:0.00000, loss_test:0.09172, lr:5.64e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.861, tt:3826.759\n",
      "Ep:124, loss:0.00000, loss_test:0.09133, lr:5.58e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.877, tt:3859.592\n",
      "Ep:125, loss:0.00000, loss_test:0.09212, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.887, tt:3891.732\n",
      "Ep:126, loss:0.00000, loss_test:0.09249, lr:5.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.890, tt:3923.049\n",
      "Ep:127, loss:0.00000, loss_test:0.09113, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.898, tt:3954.947\n",
      "Ep:128, loss:0.00000, loss_test:0.09273, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.920, tt:3988.726\n",
      "Ep:129, loss:0.00000, loss_test:0.09269, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.918, tt:4019.287\n",
      "Ep:130, loss:0.00000, loss_test:0.09075, lr:5.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.914, tt:4049.723\n",
      "Ep:131, loss:0.00000, loss_test:0.09508, lr:5.20e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.919, tt:4081.367\n",
      "Ep:132, loss:0.00000, loss_test:0.09173, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.925, tt:4113.086\n",
      "Ep:133, loss:0.00000, loss_test:0.09359, lr:5.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.937, tt:4145.573\n",
      "Ep:134, loss:0.00000, loss_test:0.09243, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.946, tt:4177.666\n",
      "Ep:135, loss:0.00000, loss_test:0.09120, lr:5.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.965, tt:4211.212\n",
      "Ep:136, loss:0.00000, loss_test:0.09473, lr:4.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.965, tt:4242.255\n",
      "Ep:137, loss:0.00000, loss_test:0.09367, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.968, tt:4273.623\n",
      "Ep:138, loss:0.00000, loss_test:0.09239, lr:4.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.972, tt:4305.163\n",
      "Ep:139, loss:0.00000, loss_test:0.09340, lr:4.80e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.980, tt:4337.131\n",
      "Ep:140, loss:0.00000, loss_test:0.09307, lr:4.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.973, tt:4367.146\n",
      "Ep:141, loss:0.00000, loss_test:0.09274, lr:4.71e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.984, tt:4399.711\n",
      "Ep:142, loss:0.00000, loss_test:0.09237, lr:4.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.994, tt:4432.115\n",
      "Ep:143, loss:0.00000, loss_test:0.09411, lr:4.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.995, tt:4463.268\n",
      "Ep:144, loss:0.00000, loss_test:0.09282, lr:4.57e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.003, tt:4495.498\n",
      "Ep:145, loss:0.00000, loss_test:0.09276, lr:4.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.003, tt:4526.407\n",
      "Ep:146, loss:0.00000, loss_test:0.09303, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.020, tt:4559.966\n",
      "Ep:147, loss:0.00000, loss_test:0.09306, lr:4.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.025, tt:4591.655\n",
      "Ep:148, loss:0.00000, loss_test:0.09275, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.031, tt:4623.615\n",
      "Ep:149, loss:0.00000, loss_test:0.09246, lr:4.34e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.020, tt:4652.940\n",
      "Ep:150, loss:0.00000, loss_test:0.09356, lr:4.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.016, tt:4683.399\n",
      "Ep:151, loss:0.00000, loss_test:0.09365, lr:4.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.003, tt:4712.513\n",
      "Ep:152, loss:0.00000, loss_test:0.09327, lr:4.21e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.006, tt:4743.906\n",
      "Ep:153, loss:0.00000, loss_test:0.09296, lr:4.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.006, tt:4774.907\n",
      "Ep:154, loss:0.00000, loss_test:0.09311, lr:4.13e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.012, tt:4806.899\n",
      "Ep:155, loss:0.00000, loss_test:0.09291, lr:4.09e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.017, tt:4838.719\n",
      "Ep:156, loss:0.00000, loss_test:0.09228, lr:4.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.018, tt:4869.778\n",
      "Ep:157, loss:0.00000, loss_test:0.09380, lr:4.01e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.024, tt:4901.721\n",
      "Ep:158, loss:0.00000, loss_test:0.09306, lr:3.97e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.021, tt:4932.263\n",
      "Ep:159, loss:0.00000, loss_test:0.09335, lr:3.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.031, tt:4965.019\n",
      "Ep:160, loss:0.00000, loss_test:0.09473, lr:3.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.033, tt:4996.239\n",
      "Ep:161, loss:0.00000, loss_test:0.09314, lr:3.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.030, tt:5026.796\n",
      "Ep:162, loss:0.00000, loss_test:0.09349, lr:3.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.040, tt:5059.466\n",
      "Ep:163, loss:0.00000, loss_test:0.09405, lr:3.77e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.052, tt:5092.511\n",
      "Ep:164, loss:0.00000, loss_test:0.09282, lr:3.73e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.063, tt:5125.329\n",
      "Ep:165, loss:0.00000, loss_test:0.09512, lr:3.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.069, tt:5157.449\n",
      "Ep:166, loss:0.00000, loss_test:0.09343, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.070, tt:5188.734\n",
      "Ep:167, loss:0.00000, loss_test:0.09241, lr:3.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.069, tt:5219.609\n",
      "Ep:168, loss:0.00000, loss_test:0.09422, lr:3.59e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.084, tt:5253.122\n",
      "Ep:169, loss:0.00000, loss_test:0.09314, lr:3.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.090, tt:5285.259\n",
      "Ep:170, loss:0.00000, loss_test:0.09307, lr:3.52e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.093, tt:5316.856\n",
      "Ep:171, loss:0.00000, loss_test:0.09399, lr:3.48e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.085, tt:5346.560\n",
      "Ep:172, loss:0.00000, loss_test:0.09248, lr:3.45e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.083, tt:5377.324\n",
      "Ep:173, loss:0.00000, loss_test:0.09416, lr:3.41e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.085, tt:5408.745\n",
      "Ep:174, loss:0.00000, loss_test:0.09406, lr:3.38e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.086, tt:5440.125\n",
      "Ep:175, loss:0.00000, loss_test:0.09315, lr:3.34e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.091, tt:5472.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:176, loss:0.00000, loss_test:0.09397, lr:3.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.094, tt:5503.707\n",
      "Ep:177, loss:0.00000, loss_test:0.09412, lr:3.28e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.104, tt:5536.441\n",
      "Ep:178, loss:0.00000, loss_test:0.09300, lr:3.24e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.110, tt:5568.696\n",
      "Ep:179, loss:0.00000, loss_test:0.09337, lr:3.21e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.113, tt:5600.277\n",
      "Ep:180, loss:0.00000, loss_test:0.09414, lr:3.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.111, tt:5631.101\n",
      "Ep:181, loss:0.00000, loss_test:0.09329, lr:3.15e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.113, tt:5662.633\n",
      "Ep:182, loss:0.00000, loss_test:0.09273, lr:3.12e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.109, tt:5692.885\n",
      "Ep:183, loss:0.00000, loss_test:0.09411, lr:3.09e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.111, tt:5724.499\n",
      "Ep:184, loss:0.00000, loss_test:0.09295, lr:3.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.110, tt:5755.419\n",
      "Ep:185, loss:0.00000, loss_test:0.09302, lr:3.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.113, tt:5787.060\n",
      "Ep:186, loss:0.00000, loss_test:0.09377, lr:2.99e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.113, tt:5818.121\n",
      "Ep:187, loss:0.00000, loss_test:0.09289, lr:2.96e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.111, tt:5848.928\n",
      "Ep:188, loss:0.00000, loss_test:0.09314, lr:2.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.114, tt:5880.578\n",
      "Ep:189, loss:0.00000, loss_test:0.09373, lr:2.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.115, tt:5911.778\n",
      "Ep:190, loss:0.00000, loss_test:0.09243, lr:2.88e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.116, tt:5943.121\n",
      "Ep:191, loss:0.00000, loss_test:0.09342, lr:2.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.119, tt:5974.802\n",
      "Ep:192, loss:0.00000, loss_test:0.09422, lr:2.82e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.116, tt:6005.313\n",
      "Ep:193, loss:0.00000, loss_test:0.09337, lr:2.79e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.114, tt:6036.139\n",
      "Ep:194, loss:0.00000, loss_test:0.09371, lr:2.76e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.113, tt:6067.123\n",
      "Ep:195, loss:0.00000, loss_test:0.09424, lr:2.73e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.103, tt:6096.212\n",
      "Ep:196, loss:0.00000, loss_test:0.09325, lr:2.71e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.109, tt:6128.565\n",
      "Ep:197, loss:0.00000, loss_test:0.09307, lr:2.68e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.080, tt:6153.770\n",
      "Ep:198, loss:0.00000, loss_test:0.09360, lr:2.65e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.062, tt:6181.362\n",
      "Ep:199, loss:0.00000, loss_test:0.09398, lr:2.63e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.022, tt:6204.361\n",
      "Ep:200, loss:0.00000, loss_test:0.09346, lr:2.60e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.985, tt:6228.071\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02108, lr:6.00e-02, fs:0.60833 (r=0.737,p=0.518),  time:27.375, tt:27.375\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02191, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:29.006, tt:58.012\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02400, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.657, tt:88.970\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02460, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.161, tt:120.644\n",
      "Ep:4, loss:0.00005, loss_test:0.02429, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.522, tt:152.609\n",
      "Ep:5, loss:0.00005, loss_test:0.02350, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.477, tt:182.860\n",
      "Ep:6, loss:0.00005, loss_test:0.02239, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.569, tt:213.979\n",
      "Ep:7, loss:0.00004, loss_test:0.02113, lr:6.00e-02, fs:0.65068 (r=0.960,p=0.492),  time:30.617, tt:244.939\n",
      "Ep:8, loss:0.00004, loss_test:0.02001, lr:6.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:30.612, tt:275.509\n",
      "Ep:9, loss:0.00004, loss_test:0.01934, lr:6.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:30.513, tt:305.128\n",
      "Ep:10, loss:0.00004, loss_test:0.01920, lr:6.00e-02, fs:0.65613 (r=0.838,p=0.539),  time:30.536, tt:335.895\n",
      "Ep:11, loss:0.00004, loss_test:0.01933, lr:6.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:30.618, tt:367.422\n",
      "Ep:12, loss:0.00004, loss_test:0.01932, lr:6.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:30.774, tt:400.058\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01910, lr:6.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:30.713, tt:429.986\n",
      "Ep:14, loss:0.00003, loss_test:0.01883, lr:6.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:30.674, tt:460.113\n",
      "Ep:15, loss:0.00003, loss_test:0.01858, lr:6.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:30.778, tt:492.454\n",
      "Ep:16, loss:0.00003, loss_test:0.01829, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:30.812, tt:523.808\n",
      "Ep:17, loss:0.00003, loss_test:0.01800, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:30.842, tt:555.150\n",
      "Ep:18, loss:0.00003, loss_test:0.01775, lr:6.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:30.838, tt:585.913\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01754, lr:6.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:30.928, tt:618.564\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01735, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:30.956, tt:650.081\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01717, lr:6.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:31.010, tt:682.215\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:31.068, tt:714.568\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01684, lr:6.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:31.091, tt:746.193\n",
      "Ep:24, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:31.125, tt:778.126\n",
      "Ep:25, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:31.137, tt:809.557\n",
      "Ep:26, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.153, tt:841.129\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:31.186, tt:873.211\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01629, lr:6.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:31.250, tt:906.256\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:31.262, tt:937.849\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:31.225, tt:967.981\n",
      "Ep:31, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:31.226, tt:999.220\n",
      "Ep:32, loss:0.00002, loss_test:0.01612, lr:6.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:31.208, tt:1029.879\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:31.199, tt:1060.761\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01601, lr:6.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:31.187, tt:1091.558\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:31.231, tt:1124.311\n",
      "Ep:36, loss:0.00002, loss_test:0.01592, lr:6.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:31.219, tt:1155.102\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:37, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:31.214, tt:1186.124\n",
      "Ep:38, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:31.205, tt:1217.004\n",
      "Ep:39, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.198, tt:1247.936\n",
      "Ep:40, loss:0.00002, loss_test:0.01587, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.160, tt:1277.570\n",
      "Ep:41, loss:0.00002, loss_test:0.01581, lr:6.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:31.118, tt:1306.936\n",
      "Ep:42, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:31.104, tt:1337.467\n",
      "Ep:43, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:31.119, tt:1369.242\n",
      "Ep:44, loss:0.00002, loss_test:0.01563, lr:6.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:31.110, tt:1399.937\n",
      "Ep:45, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:31.095, tt:1430.373\n",
      "Ep:46, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:31.047, tt:1459.228\n",
      "Ep:47, loss:0.00002, loss_test:0.01554, lr:6.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:31.013, tt:1488.639\n",
      "Ep:48, loss:0.00002, loss_test:0.01552, lr:5.94e-02, fs:0.74627 (r=0.758,p=0.735),  time:30.984, tt:1518.212\n",
      "Ep:49, loss:0.00002, loss_test:0.01551, lr:5.88e-02, fs:0.75000 (r=0.758,p=0.743),  time:30.975, tt:1548.728\n",
      "Ep:50, loss:0.00002, loss_test:0.01551, lr:5.82e-02, fs:0.75000 (r=0.758,p=0.743),  time:30.949, tt:1578.411\n",
      "Ep:51, loss:0.00002, loss_test:0.01548, lr:5.76e-02, fs:0.75000 (r=0.758,p=0.743),  time:30.962, tt:1610.030\n",
      "Ep:52, loss:0.00002, loss_test:0.01548, lr:5.71e-02, fs:0.75377 (r=0.758,p=0.750),  time:30.935, tt:1639.552\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01544, lr:5.71e-02, fs:0.75377 (r=0.758,p=0.750),  time:30.898, tt:1668.515\n",
      "Ep:54, loss:0.00002, loss_test:0.01535, lr:5.71e-02, fs:0.75377 (r=0.758,p=0.750),  time:30.870, tt:1697.877\n",
      "Ep:55, loss:0.00002, loss_test:0.01531, lr:5.71e-02, fs:0.75377 (r=0.758,p=0.750),  time:30.845, tt:1727.293\n",
      "Ep:56, loss:0.00002, loss_test:0.01531, lr:5.71e-02, fs:0.75758 (r=0.758,p=0.758),  time:30.861, tt:1759.053\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01532, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.850, tt:1789.323\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01534, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.851, tt:1820.201\n",
      "Ep:59, loss:0.00002, loss_test:0.01527, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.871, tt:1852.267\n",
      "Ep:60, loss:0.00002, loss_test:0.01523, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.899, tt:1884.823\n",
      "Ep:61, loss:0.00001, loss_test:0.01524, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.904, tt:1916.048\n",
      "Ep:62, loss:0.00001, loss_test:0.01522, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.883, tt:1945.610\n",
      "Ep:63, loss:0.00001, loss_test:0.01520, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.882, tt:1976.431\n",
      "Ep:64, loss:0.00001, loss_test:0.01521, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.870, tt:2006.523\n",
      "Ep:65, loss:0.00001, loss_test:0.01520, lr:5.71e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.869, tt:2037.330\n",
      "Ep:66, loss:0.00001, loss_test:0.01519, lr:5.71e-02, fs:0.77320 (r=0.758,p=0.789),  time:30.875, tt:2068.645\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01516, lr:5.71e-02, fs:0.77320 (r=0.758,p=0.789),  time:30.876, tt:2099.599\n",
      "Ep:68, loss:0.00001, loss_test:0.01516, lr:5.71e-02, fs:0.77320 (r=0.758,p=0.789),  time:30.867, tt:2129.802\n",
      "Ep:69, loss:0.00001, loss_test:0.01518, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.876, tt:2161.287\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01521, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.856, tt:2190.807\n",
      "Ep:71, loss:0.00001, loss_test:0.01519, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.834, tt:2220.046\n",
      "Ep:72, loss:0.00001, loss_test:0.01523, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.813, tt:2249.361\n",
      "Ep:73, loss:0.00001, loss_test:0.01524, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.802, tt:2279.383\n",
      "Ep:74, loss:0.00001, loss_test:0.01517, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.784, tt:2308.775\n",
      "Ep:75, loss:0.00001, loss_test:0.01518, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.802, tt:2340.935\n",
      "Ep:76, loss:0.00001, loss_test:0.01515, lr:5.71e-02, fs:0.77720 (r=0.758,p=0.798),  time:30.792, tt:2371.009\n",
      "Ep:77, loss:0.00001, loss_test:0.01516, lr:5.71e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.782, tt:2401.003\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01522, lr:5.71e-02, fs:0.78534 (r=0.758,p=0.815),  time:30.770, tt:2430.816\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01524, lr:5.71e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.768, tt:2461.425\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01519, lr:5.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.766, tt:2492.084\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01517, lr:5.71e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.752, tt:2521.683\n",
      "Ep:82, loss:0.00001, loss_test:0.01524, lr:5.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.748, tt:2552.118\n",
      "Ep:83, loss:0.00001, loss_test:0.01525, lr:5.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.743, tt:2582.390\n",
      "Ep:84, loss:0.00001, loss_test:0.01521, lr:5.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.739, tt:2612.817\n",
      "Ep:85, loss:0.00001, loss_test:0.01527, lr:5.71e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.726, tt:2642.473\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01534, lr:5.71e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.728, tt:2673.336\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01533, lr:5.71e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.719, tt:2703.263\n",
      "Ep:88, loss:0.00001, loss_test:0.01526, lr:5.71e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.734, tt:2735.337\n",
      "Ep:89, loss:0.00001, loss_test:0.01528, lr:5.71e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.728, tt:2765.512\n",
      "Ep:90, loss:0.00001, loss_test:0.01528, lr:5.71e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.720, tt:2795.543\n",
      "Ep:91, loss:0.00001, loss_test:0.01537, lr:5.71e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.717, tt:2825.963\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01537, lr:5.71e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.710, tt:2856.062\n",
      "Ep:93, loss:0.00001, loss_test:0.01543, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.713, tt:2887.009\n",
      "Ep:94, loss:0.00001, loss_test:0.01539, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.710, tt:2917.408\n",
      "Ep:95, loss:0.00001, loss_test:0.01546, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.715, tt:2948.616\n",
      "Ep:96, loss:0.00001, loss_test:0.01548, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.717, tt:2979.540\n",
      "Ep:97, loss:0.00001, loss_test:0.01549, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.730, tt:3011.582\n",
      "Ep:98, loss:0.00001, loss_test:0.01548, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.741, tt:3043.313\n",
      "Ep:99, loss:0.00001, loss_test:0.01549, lr:5.71e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.732, tt:3073.192\n",
      "Ep:100, loss:0.00001, loss_test:0.01548, lr:5.71e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.712, tt:3101.923\n",
      "Ep:101, loss:0.00001, loss_test:0.01557, lr:5.71e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.715, tt:3132.935\n",
      "Ep:102, loss:0.00001, loss_test:0.01558, lr:5.71e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.726, tt:3164.801\n",
      "Ep:103, loss:0.00001, loss_test:0.01553, lr:5.65e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.724, tt:3195.321\n",
      "Ep:104, loss:0.00001, loss_test:0.01560, lr:5.59e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.739, tt:3227.598\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01561, lr:5.59e-02, fs:0.81522 (r=0.758,p=0.882),  time:30.742, tt:3258.619\n",
      "Ep:106, loss:0.00001, loss_test:0.01564, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.752, tt:3290.486\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:107, loss:0.00001, loss_test:0.01569, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.752, tt:3321.263\n",
      "Ep:108, loss:0.00001, loss_test:0.01577, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.740, tt:3350.670\n",
      "Ep:109, loss:0.00001, loss_test:0.01576, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.733, tt:3380.603\n",
      "Ep:110, loss:0.00001, loss_test:0.01575, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.726, tt:3410.550\n",
      "Ep:111, loss:0.00001, loss_test:0.01576, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.726, tt:3441.317\n",
      "Ep:112, loss:0.00001, loss_test:0.01570, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.715, tt:3470.756\n",
      "Ep:113, loss:0.00001, loss_test:0.01580, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.737, tt:3504.031\n",
      "Ep:114, loss:0.00001, loss_test:0.01585, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.735, tt:3534.490\n",
      "Ep:115, loss:0.00001, loss_test:0.01591, lr:5.59e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.731, tt:3564.806\n",
      "Ep:116, loss:0.00001, loss_test:0.01599, lr:5.59e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.735, tt:3596.045\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01598, lr:5.59e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.735, tt:3626.703\n",
      "Ep:118, loss:0.00001, loss_test:0.01595, lr:5.59e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.733, tt:3657.214\n",
      "Ep:119, loss:0.00001, loss_test:0.01599, lr:5.59e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.742, tt:3689.077\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.01600, lr:5.59e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.742, tt:3719.743\n",
      "Ep:121, loss:0.00001, loss_test:0.01602, lr:5.59e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.736, tt:3749.758\n",
      "Ep:122, loss:0.00001, loss_test:0.01607, lr:5.59e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.733, tt:3780.194\n",
      "Ep:123, loss:0.00001, loss_test:0.01614, lr:5.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.734, tt:3811.012\n",
      "Ep:124, loss:0.00001, loss_test:0.01610, lr:5.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.721, tt:3840.164\n",
      "Ep:125, loss:0.00001, loss_test:0.01615, lr:5.59e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.696, tt:3867.636\n",
      "Ep:126, loss:0.00001, loss_test:0.01621, lr:5.59e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.687, tt:3897.216\n",
      "Ep:127, loss:0.00001, loss_test:0.01622, lr:5.59e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.684, tt:3927.587\n",
      "Ep:128, loss:0.00001, loss_test:0.01631, lr:5.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.682, tt:3957.938\n",
      "Ep:129, loss:0.00001, loss_test:0.01630, lr:5.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.670, tt:3987.106\n",
      "Ep:130, loss:0.00001, loss_test:0.01632, lr:5.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.665, tt:4017.162\n",
      "Ep:131, loss:0.00001, loss_test:0.01638, lr:5.54e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.659, tt:4046.960\n",
      "Ep:132, loss:0.00001, loss_test:0.01637, lr:5.48e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.639, tt:4074.959\n",
      "Ep:133, loss:0.00001, loss_test:0.01644, lr:5.43e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.615, tt:4102.459\n",
      "Ep:134, loss:0.00001, loss_test:0.01641, lr:5.37e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.609, tt:4132.154\n",
      "Ep:135, loss:0.00001, loss_test:0.01644, lr:5.32e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.611, tt:4163.137\n",
      "Ep:136, loss:0.00001, loss_test:0.01652, lr:5.27e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.610, tt:4193.511\n",
      "Ep:137, loss:0.00001, loss_test:0.01659, lr:5.21e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.609, tt:4224.051\n",
      "Ep:138, loss:0.00001, loss_test:0.01653, lr:5.16e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.605, tt:4254.113\n",
      "Ep:139, loss:0.00001, loss_test:0.01658, lr:5.11e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.594, tt:4283.127\n",
      "Ep:140, loss:0.00001, loss_test:0.01668, lr:5.06e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.584, tt:4312.382\n",
      "Ep:141, loss:0.00001, loss_test:0.01666, lr:5.01e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.580, tt:4342.293\n",
      "Ep:142, loss:0.00001, loss_test:0.01665, lr:4.96e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.583, tt:4373.364\n",
      "Ep:143, loss:0.00001, loss_test:0.01671, lr:4.91e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.579, tt:4403.310\n",
      "Ep:144, loss:0.00001, loss_test:0.01675, lr:4.86e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.571, tt:4432.842\n",
      "Ep:145, loss:0.00001, loss_test:0.01676, lr:4.81e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.576, tt:4464.031\n",
      "Ep:146, loss:0.00001, loss_test:0.01682, lr:4.76e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.567, tt:4493.314\n",
      "Ep:147, loss:0.00001, loss_test:0.01688, lr:4.71e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.572, tt:4524.693\n",
      "Ep:148, loss:0.00001, loss_test:0.01685, lr:4.67e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.563, tt:4553.955\n",
      "Ep:149, loss:0.00001, loss_test:0.01692, lr:4.62e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.555, tt:4583.213\n",
      "Ep:150, loss:0.00001, loss_test:0.01694, lr:4.57e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.547, tt:4612.535\n",
      "Ep:151, loss:0.00001, loss_test:0.01696, lr:4.53e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.552, tt:4643.906\n",
      "Ep:152, loss:0.00001, loss_test:0.01697, lr:4.48e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.554, tt:4674.743\n",
      "Ep:153, loss:0.00001, loss_test:0.01704, lr:4.44e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.547, tt:4704.166\n",
      "Ep:154, loss:0.00001, loss_test:0.01707, lr:4.39e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.547, tt:4734.829\n",
      "Ep:155, loss:0.00001, loss_test:0.01706, lr:4.35e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.543, tt:4764.636\n",
      "Ep:156, loss:0.00001, loss_test:0.01710, lr:4.31e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.539, tt:4794.683\n",
      "Ep:157, loss:0.00001, loss_test:0.01712, lr:4.26e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.541, tt:4825.463\n",
      "Ep:158, loss:0.00001, loss_test:0.01715, lr:4.22e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.531, tt:4854.502\n",
      "Ep:159, loss:0.00001, loss_test:0.01717, lr:4.18e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.527, tt:4884.389\n",
      "Ep:160, loss:0.00001, loss_test:0.01723, lr:4.14e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.521, tt:4913.948\n",
      "Ep:161, loss:0.00001, loss_test:0.01727, lr:4.10e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.518, tt:4943.862\n",
      "Ep:162, loss:0.00001, loss_test:0.01729, lr:4.05e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.516, tt:4974.157\n",
      "Ep:163, loss:0.00000, loss_test:0.01733, lr:4.01e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.505, tt:5002.819\n",
      "Ep:164, loss:0.00000, loss_test:0.01734, lr:3.97e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.495, tt:5031.618\n",
      "Ep:165, loss:0.00000, loss_test:0.01735, lr:3.93e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.491, tt:5061.580\n",
      "Ep:166, loss:0.00000, loss_test:0.01737, lr:3.89e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.482, tt:5090.552\n",
      "Ep:167, loss:0.00000, loss_test:0.01735, lr:3.86e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.485, tt:5121.435\n",
      "Ep:168, loss:0.00000, loss_test:0.01738, lr:3.82e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.483, tt:5151.559\n",
      "Ep:169, loss:0.00000, loss_test:0.01742, lr:3.78e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.482, tt:5181.998\n",
      "Ep:170, loss:0.00000, loss_test:0.01747, lr:3.74e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.475, tt:5211.153\n",
      "Ep:171, loss:0.00000, loss_test:0.01752, lr:3.70e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.466, tt:5240.113\n",
      "Ep:172, loss:0.00000, loss_test:0.01755, lr:3.67e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.486, tt:5274.163\n",
      "Ep:173, loss:0.00000, loss_test:0.01761, lr:3.63e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.482, tt:5303.838\n",
      "Ep:174, loss:0.00000, loss_test:0.01761, lr:3.59e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.483, tt:5334.485\n",
      "Ep:175, loss:0.00000, loss_test:0.01761, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.479, tt:5364.229\n",
      "Ep:176, loss:0.00000, loss_test:0.01766, lr:3.52e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.473, tt:5393.716\n",
      "Ep:177, loss:0.00000, loss_test:0.01768, lr:3.49e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.466, tt:5423.003\n",
      "Ep:178, loss:0.00000, loss_test:0.01768, lr:3.45e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.466, tt:5453.350\n",
      "Ep:179, loss:0.00000, loss_test:0.01770, lr:3.42e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.461, tt:5483.065\n",
      "Ep:180, loss:0.00000, loss_test:0.01773, lr:3.38e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.458, tt:5512.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:181, loss:0.00000, loss_test:0.01773, lr:3.35e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.460, tt:5543.769\n",
      "Ep:182, loss:0.00000, loss_test:0.01776, lr:3.32e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.465, tt:5575.095\n",
      "Ep:183, loss:0.00000, loss_test:0.01779, lr:3.28e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.465, tt:5605.571\n",
      "Ep:184, loss:0.00000, loss_test:0.01781, lr:3.25e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.463, tt:5635.627\n",
      "Ep:185, loss:0.00000, loss_test:0.01785, lr:3.22e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.458, tt:5665.114\n",
      "Ep:186, loss:0.00000, loss_test:0.01784, lr:3.19e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.462, tt:5696.373\n",
      "Ep:187, loss:0.00000, loss_test:0.01786, lr:3.15e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.461, tt:5726.704\n",
      "Ep:188, loss:0.00000, loss_test:0.01789, lr:3.12e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.462, tt:5757.334\n",
      "Ep:189, loss:0.00000, loss_test:0.01792, lr:3.09e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.465, tt:5788.413\n",
      "Ep:190, loss:0.00000, loss_test:0.01797, lr:3.06e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.469, tt:5819.580\n",
      "Ep:191, loss:0.00000, loss_test:0.01796, lr:3.03e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.468, tt:5849.802\n",
      "Ep:192, loss:0.00000, loss_test:0.01800, lr:3.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.468, tt:5880.253\n",
      "Ep:193, loss:0.00000, loss_test:0.01805, lr:2.97e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.467, tt:5910.555\n",
      "Ep:194, loss:0.00000, loss_test:0.01803, lr:2.94e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.476, tt:5942.846\n",
      "Ep:195, loss:0.00000, loss_test:0.01807, lr:2.91e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.481, tt:5974.353\n",
      "Ep:196, loss:0.00000, loss_test:0.01809, lr:2.88e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.484, tt:6005.300\n",
      "Ep:197, loss:0.00000, loss_test:0.01812, lr:2.85e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.473, tt:6033.568\n",
      "Ep:198, loss:0.00000, loss_test:0.01814, lr:2.82e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.473, tt:6064.071\n",
      "Ep:199, loss:0.00000, loss_test:0.01815, lr:2.80e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.476, tt:6095.114\n",
      "Ep:200, loss:0.00000, loss_test:0.01816, lr:2.77e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.476, tt:6125.594\n",
      "Ep:201, loss:0.00000, loss_test:0.01820, lr:2.74e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.477, tt:6156.406\n",
      "Ep:202, loss:0.00000, loss_test:0.01822, lr:2.71e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.467, tt:6184.785\n",
      "Ep:203, loss:0.00000, loss_test:0.01822, lr:2.69e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.459, tt:6213.576\n",
      "Ep:204, loss:0.00000, loss_test:0.01822, lr:2.66e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.469, tt:6246.179\n",
      "Ep:205, loss:0.00000, loss_test:0.01825, lr:2.63e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.462, tt:6275.247\n",
      "Ep:206, loss:0.00000, loss_test:0.01825, lr:2.61e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.426, tt:6298.237\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14474, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.960, tt:30.960\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14424, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.143, tt:62.286\n",
      "Ep:2, loss:0.00028, loss_test:0.14345, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.098, tt:96.294\n",
      "Ep:3, loss:0.00028, loss_test:0.14232, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.282, tt:129.129\n",
      "Ep:4, loss:0.00028, loss_test:0.14073, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.140, tt:160.700\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00028, loss_test:0.13835, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.361, tt:194.166\n",
      "Ep:6, loss:0.00027, loss_test:0.13461, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:32.284, tt:225.989\n",
      "Ep:7, loss:0.00026, loss_test:0.12900, lr:1.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:32.129, tt:257.036\n",
      "Ep:8, loss:0.00025, loss_test:0.12102, lr:1.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:32.167, tt:289.507\n",
      "Ep:9, loss:0.00024, loss_test:0.11581, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:32.274, tt:322.739\n",
      "Ep:10, loss:0.00023, loss_test:0.11361, lr:1.00e-02, fs:0.65217 (r=0.606,p=0.706),  time:32.251, tt:354.765\n",
      "Ep:11, loss:0.00022, loss_test:0.11073, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:32.240, tt:386.885\n",
      "Ep:12, loss:0.00022, loss_test:0.11026, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:32.264, tt:419.434\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10784, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:32.265, tt:451.711\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10374, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:32.195, tt:482.924\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10182, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:32.200, tt:515.208\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09941, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:32.226, tt:547.840\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09813, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:32.218, tt:579.922\n",
      "Ep:18, loss:0.00018, loss_test:0.09677, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:32.098, tt:609.857\n",
      "Ep:19, loss:0.00018, loss_test:0.09599, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:32.082, tt:641.643\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09444, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:32.033, tt:672.697\n",
      "Ep:21, loss:0.00017, loss_test:0.09276, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:32.037, tt:704.810\n",
      "Ep:22, loss:0.00016, loss_test:0.09159, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:32.104, tt:738.401\n",
      "Ep:23, loss:0.00016, loss_test:0.09150, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:32.144, tt:771.460\n",
      "Ep:24, loss:0.00016, loss_test:0.09058, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.174, tt:804.359\n",
      "Ep:25, loss:0.00015, loss_test:0.08952, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:32.165, tt:836.278\n",
      "Ep:26, loss:0.00015, loss_test:0.08930, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.230, tt:870.214\n",
      "Ep:27, loss:0.00014, loss_test:0.08959, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:32.211, tt:901.921\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08890, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:32.199, tt:933.762\n",
      "Ep:29, loss:0.00014, loss_test:0.08834, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:32.187, tt:965.605\n",
      "Ep:30, loss:0.00013, loss_test:0.08855, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:32.185, tt:997.728\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08766, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:32.169, tt:1029.412\n",
      "Ep:32, loss:0.00013, loss_test:0.08658, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:32.151, tt:1060.971\n",
      "Ep:33, loss:0.00012, loss_test:0.08711, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:32.167, tt:1093.666\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08634, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:32.132, tt:1124.623\n",
      "Ep:35, loss:0.00012, loss_test:0.08466, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.141, tt:1157.063\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.08606, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:32.096, tt:1187.564\n",
      "Ep:40, loss:0.00011, loss_test:0.08335, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:32.054, tt:1314.207\n",
      "Ep:41, loss:0.00010, loss_test:0.08176, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:32.054, tt:1346.250\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.08525, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.998, tt:1375.931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:43, loss:0.00010, loss_test:0.08140, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:32.023, tt:1409.022\n",
      "Ep:44, loss:0.00010, loss_test:0.08127, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.001, tt:1440.045\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.08367, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.998, tt:1471.909\n",
      "Ep:46, loss:0.00009, loss_test:0.07974, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:31.999, tt:1503.933\n",
      "Ep:47, loss:0.00009, loss_test:0.08172, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.010, tt:1536.496\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.08140, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.997, tt:1567.855\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.07961, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:32.012, tt:1600.588\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.08084, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:31.992, tt:1631.611\n",
      "Ep:51, loss:0.00008, loss_test:0.08039, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:32.060, tt:1667.102\n",
      "Ep:52, loss:0.00008, loss_test:0.07877, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:32.080, tt:1700.261\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.08084, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:32.065, tt:1731.517\n",
      "Ep:54, loss:0.00008, loss_test:0.07927, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:32.060, tt:1763.292\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.07801, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:32.092, tt:1797.147\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.07899, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:32.075, tt:1828.248\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.07742, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:32.066, tt:1859.831\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.07965, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:32.056, tt:1891.323\n",
      "Ep:59, loss:0.00007, loss_test:0.07603, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:32.075, tt:1924.470\n",
      "Ep:60, loss:0.00007, loss_test:0.07754, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:32.086, tt:1957.269\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00007, loss_test:0.07727, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:32.088, tt:1989.459\n",
      "Ep:62, loss:0.00007, loss_test:0.07600, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:32.069, tt:2020.379\n",
      "Ep:63, loss:0.00006, loss_test:0.07833, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:32.058, tt:2051.713\n",
      "Ep:64, loss:0.00006, loss_test:0.07662, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:32.027, tt:2081.748\n",
      "Ep:65, loss:0.00006, loss_test:0.07594, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:32.009, tt:2112.578\n",
      "Ep:66, loss:0.00006, loss_test:0.07880, lr:1.00e-02, fs:0.86188 (r=0.788,p=0.951),  time:32.005, tt:2144.354\n",
      "Ep:67, loss:0.00006, loss_test:0.07575, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:32.010, tt:2176.673\n",
      "Ep:68, loss:0.00006, loss_test:0.07593, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:31.998, tt:2207.876\n",
      "Ep:69, loss:0.00006, loss_test:0.07731, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:32.007, tt:2240.479\n",
      "Ep:70, loss:0.00006, loss_test:0.07571, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.994, tt:2271.609\n",
      "Ep:71, loss:0.00005, loss_test:0.07613, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:32.019, tt:2305.337\n",
      "Ep:72, loss:0.00005, loss_test:0.07631, lr:9.90e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.029, tt:2338.099\n",
      "Ep:73, loss:0.00005, loss_test:0.07536, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:32.010, tt:2368.755\n",
      "Ep:74, loss:0.00005, loss_test:0.07681, lr:9.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.041, tt:2403.051\n",
      "Ep:75, loss:0.00005, loss_test:0.07549, lr:9.61e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.029, tt:2434.233\n",
      "Ep:76, loss:0.00005, loss_test:0.07560, lr:9.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.015, tt:2465.188\n",
      "Ep:77, loss:0.00005, loss_test:0.07527, lr:9.41e-03, fs:0.88421 (r=0.848,p=0.923),  time:32.013, tt:2497.011\n",
      "Ep:78, loss:0.00005, loss_test:0.07541, lr:9.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.014, tt:2529.091\n",
      "Ep:79, loss:0.00005, loss_test:0.07614, lr:9.23e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.027, tt:2562.165\n",
      "Ep:80, loss:0.00004, loss_test:0.07476, lr:9.14e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.035, tt:2594.808\n",
      "Ep:81, loss:0.00004, loss_test:0.07590, lr:9.04e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.044, tt:2627.570\n",
      "Ep:82, loss:0.00004, loss_test:0.07603, lr:8.95e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.044, tt:2659.661\n",
      "Ep:83, loss:0.00004, loss_test:0.07470, lr:8.86e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.058, tt:2692.880\n",
      "Ep:84, loss:0.00004, loss_test:0.07662, lr:8.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.077, tt:2726.552\n",
      "Ep:85, loss:0.00004, loss_test:0.07582, lr:8.69e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.058, tt:2756.979\n",
      "Ep:86, loss:0.00004, loss_test:0.07455, lr:8.60e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.052, tt:2788.535\n",
      "Ep:87, loss:0.00004, loss_test:0.07585, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.065, tt:2821.729\n",
      "Ep:88, loss:0.00004, loss_test:0.07632, lr:8.43e-03, fs:0.86813 (r=0.798,p=0.952),  time:32.074, tt:2854.600\n",
      "Ep:89, loss:0.00004, loss_test:0.07372, lr:8.35e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.080, tt:2887.184\n",
      "Ep:90, loss:0.00004, loss_test:0.07556, lr:8.26e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.093, tt:2920.483\n",
      "Ep:91, loss:0.00004, loss_test:0.07599, lr:8.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.089, tt:2952.166\n",
      "Ep:92, loss:0.00004, loss_test:0.07396, lr:8.10e-03, fs:0.90052 (r=0.869,p=0.935),  time:32.098, tt:2985.145\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00004, loss_test:0.07584, lr:8.10e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.091, tt:3016.535\n",
      "Ep:94, loss:0.00004, loss_test:0.07447, lr:8.10e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.081, tt:3047.687\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00003, loss_test:0.07439, lr:8.10e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.080, tt:3079.717\n",
      "Ep:96, loss:0.00003, loss_test:0.07520, lr:8.10e-03, fs:0.89130 (r=0.828,p=0.965),  time:32.079, tt:3111.636\n",
      "Ep:97, loss:0.00003, loss_test:0.07378, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.091, tt:3144.902\n",
      "Ep:98, loss:0.00003, loss_test:0.07505, lr:8.10e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.093, tt:3177.178\n",
      "Ep:99, loss:0.00003, loss_test:0.07535, lr:8.10e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.091, tt:3209.129\n",
      "Ep:100, loss:0.00003, loss_test:0.07383, lr:8.10e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.107, tt:3242.760\n",
      "Ep:101, loss:0.00003, loss_test:0.07539, lr:8.10e-03, fs:0.89130 (r=0.828,p=0.965),  time:32.109, tt:3275.135\n",
      "Ep:102, loss:0.00003, loss_test:0.07461, lr:8.10e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.099, tt:3306.247\n",
      "Ep:103, loss:0.00003, loss_test:0.07437, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.100, tt:3338.390\n",
      "Ep:104, loss:0.00003, loss_test:0.07463, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.102, tt:3370.729\n",
      "Ep:105, loss:0.00003, loss_test:0.07456, lr:8.10e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.128, tt:3405.612\n",
      "Ep:106, loss:0.00003, loss_test:0.07439, lr:8.02e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.126, tt:3437.463\n",
      "Ep:107, loss:0.00003, loss_test:0.07431, lr:7.94e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.126, tt:3469.633\n",
      "Ep:108, loss:0.00003, loss_test:0.07469, lr:7.86e-03, fs:0.89130 (r=0.828,p=0.965),  time:32.131, tt:3502.293\n",
      "Ep:109, loss:0.00003, loss_test:0.07440, lr:7.78e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.097, tt:3530.692\n",
      "Ep:110, loss:0.00003, loss_test:0.07444, lr:7.70e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.081, tt:3561.003\n",
      "Ep:111, loss:0.00003, loss_test:0.07438, lr:7.62e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.085, tt:3593.493\n",
      "Ep:112, loss:0.00003, loss_test:0.07400, lr:7.55e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.082, tt:3625.289\n",
      "Ep:113, loss:0.00003, loss_test:0.07546, lr:7.47e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.085, tt:3657.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00003, loss_test:0.07476, lr:7.40e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.088, tt:3690.088\n",
      "Ep:115, loss:0.00002, loss_test:0.07312, lr:7.32e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.091, tt:3722.588\n",
      "Ep:116, loss:0.00002, loss_test:0.07653, lr:7.25e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.101, tt:3755.861\n",
      "Ep:117, loss:0.00002, loss_test:0.07390, lr:7.18e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.105, tt:3788.436\n",
      "Ep:118, loss:0.00002, loss_test:0.07411, lr:7.11e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.099, tt:3819.743\n",
      "Ep:119, loss:0.00002, loss_test:0.07492, lr:7.03e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.098, tt:3851.781\n",
      "Ep:120, loss:0.00002, loss_test:0.07417, lr:6.96e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.090, tt:3882.889\n",
      "Ep:121, loss:0.00002, loss_test:0.07488, lr:6.89e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.090, tt:3915.039\n",
      "Ep:122, loss:0.00002, loss_test:0.07572, lr:6.83e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.090, tt:3947.038\n",
      "Ep:123, loss:0.00002, loss_test:0.07380, lr:6.76e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.084, tt:3978.460\n",
      "Ep:124, loss:0.00002, loss_test:0.07469, lr:6.69e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.074, tt:4009.300\n",
      "Ep:125, loss:0.00002, loss_test:0.07498, lr:6.62e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.064, tt:4040.039\n",
      "Ep:126, loss:0.00002, loss_test:0.07400, lr:6.56e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.071, tt:4072.982\n",
      "Ep:127, loss:0.00002, loss_test:0.07486, lr:6.49e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.073, tt:4105.323\n",
      "Ep:128, loss:0.00002, loss_test:0.07494, lr:6.43e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.069, tt:4136.874\n",
      "Ep:129, loss:0.00002, loss_test:0.07455, lr:6.36e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.067, tt:4168.733\n",
      "Ep:130, loss:0.00002, loss_test:0.07559, lr:6.30e-03, fs:0.87293 (r=0.798,p=0.963),  time:32.064, tt:4200.430\n",
      "Ep:131, loss:0.00002, loss_test:0.07445, lr:6.24e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.063, tt:4232.362\n",
      "Ep:132, loss:0.00002, loss_test:0.07493, lr:6.17e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.063, tt:4264.369\n",
      "Ep:133, loss:0.00002, loss_test:0.07611, lr:6.11e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.065, tt:4296.648\n",
      "Ep:134, loss:0.00002, loss_test:0.07396, lr:6.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.064, tt:4328.609\n",
      "Ep:135, loss:0.00002, loss_test:0.07613, lr:5.99e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.072, tt:4361.735\n",
      "Ep:136, loss:0.00002, loss_test:0.07640, lr:5.93e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.068, tt:4393.322\n",
      "Ep:137, loss:0.00002, loss_test:0.07423, lr:5.87e-03, fs:0.86813 (r=0.798,p=0.952),  time:32.064, tt:4424.769\n",
      "Ep:138, loss:0.00002, loss_test:0.07595, lr:5.81e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.074, tt:4458.227\n",
      "Ep:139, loss:0.00002, loss_test:0.07596, lr:5.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.073, tt:4490.223\n",
      "Ep:140, loss:0.00002, loss_test:0.07497, lr:5.70e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.072, tt:4522.195\n",
      "Ep:141, loss:0.00002, loss_test:0.07587, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.094, tt:4557.351\n",
      "Ep:142, loss:0.00002, loss_test:0.07481, lr:5.58e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.103, tt:4590.722\n",
      "Ep:143, loss:0.00002, loss_test:0.07585, lr:5.53e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.109, tt:4623.685\n",
      "Ep:144, loss:0.00002, loss_test:0.07544, lr:5.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.113, tt:4656.339\n",
      "Ep:145, loss:0.00002, loss_test:0.07531, lr:5.42e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.109, tt:4687.977\n",
      "Ep:146, loss:0.00002, loss_test:0.07565, lr:5.36e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.114, tt:4720.769\n",
      "Ep:147, loss:0.00002, loss_test:0.07522, lr:5.31e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.112, tt:4752.536\n",
      "Ep:148, loss:0.00002, loss_test:0.07577, lr:5.26e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.110, tt:4784.427\n",
      "Ep:149, loss:0.00002, loss_test:0.07544, lr:5.20e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.113, tt:4816.897\n",
      "Ep:150, loss:0.00002, loss_test:0.07556, lr:5.15e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.128, tt:4851.256\n",
      "Ep:151, loss:0.00002, loss_test:0.07549, lr:5.10e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.123, tt:4882.667\n",
      "Ep:152, loss:0.00002, loss_test:0.07510, lr:5.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.128, tt:4915.588\n",
      "Ep:153, loss:0.00002, loss_test:0.07598, lr:5.00e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.125, tt:4947.179\n",
      "Ep:154, loss:0.00002, loss_test:0.07546, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.128, tt:4979.862\n",
      "Ep:155, loss:0.00002, loss_test:0.07554, lr:4.90e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.130, tt:5012.241\n",
      "Ep:156, loss:0.00002, loss_test:0.07597, lr:4.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.134, tt:5045.046\n",
      "Ep:157, loss:0.00002, loss_test:0.07532, lr:4.80e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.143, tt:5078.665\n",
      "Ep:158, loss:0.00002, loss_test:0.07593, lr:4.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.142, tt:5110.605\n",
      "Ep:159, loss:0.00002, loss_test:0.07531, lr:4.71e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.144, tt:5142.981\n",
      "Ep:160, loss:0.00002, loss_test:0.07563, lr:4.66e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.143, tt:5175.080\n",
      "Ep:161, loss:0.00002, loss_test:0.07554, lr:4.61e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.140, tt:5206.747\n",
      "Ep:162, loss:0.00002, loss_test:0.07535, lr:4.57e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.141, tt:5238.970\n",
      "Ep:163, loss:0.00002, loss_test:0.07622, lr:4.52e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.149, tt:5272.465\n",
      "Ep:164, loss:0.00002, loss_test:0.07536, lr:4.48e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.142, tt:5303.409\n",
      "Ep:165, loss:0.00001, loss_test:0.07584, lr:4.43e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.143, tt:5335.679\n",
      "Ep:166, loss:0.00001, loss_test:0.07626, lr:4.39e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.141, tt:5367.503\n",
      "Ep:167, loss:0.00001, loss_test:0.07507, lr:4.34e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.158, tt:5402.496\n",
      "Ep:168, loss:0.00001, loss_test:0.07557, lr:4.30e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.157, tt:5434.576\n",
      "Ep:169, loss:0.00001, loss_test:0.07629, lr:4.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.157, tt:5466.675\n",
      "Ep:170, loss:0.00001, loss_test:0.07536, lr:4.21e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.164, tt:5499.972\n",
      "Ep:171, loss:0.00001, loss_test:0.07576, lr:4.17e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.166, tt:5532.488\n",
      "Ep:172, loss:0.00001, loss_test:0.07581, lr:4.13e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.159, tt:5563.547\n",
      "Ep:173, loss:0.00001, loss_test:0.07540, lr:4.09e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.161, tt:5596.030\n",
      "Ep:174, loss:0.00001, loss_test:0.07577, lr:4.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.157, tt:5627.554\n",
      "Ep:175, loss:0.00001, loss_test:0.07554, lr:4.01e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.158, tt:5659.865\n",
      "Ep:176, loss:0.00001, loss_test:0.07525, lr:3.97e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.150, tt:5690.488\n",
      "Ep:177, loss:0.00001, loss_test:0.07562, lr:3.93e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.156, tt:5723.767\n",
      "Ep:178, loss:0.00001, loss_test:0.07622, lr:3.89e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.157, tt:5756.170\n",
      "Ep:179, loss:0.00001, loss_test:0.07566, lr:3.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.155, tt:5787.880\n",
      "Ep:180, loss:0.00001, loss_test:0.07575, lr:3.81e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.159, tt:5820.755\n",
      "Ep:181, loss:0.00001, loss_test:0.07578, lr:3.77e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.159, tt:5853.015\n",
      "Ep:182, loss:0.00001, loss_test:0.07585, lr:3.73e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.154, tt:5884.177\n",
      "Ep:183, loss:0.00001, loss_test:0.07583, lr:3.70e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.142, tt:5914.136\n",
      "Ep:184, loss:0.00001, loss_test:0.07583, lr:3.66e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.147, tt:5947.139\n",
      "Ep:185, loss:0.00001, loss_test:0.07587, lr:3.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.144, tt:5978.799\n",
      "Ep:186, loss:0.00001, loss_test:0.07598, lr:3.59e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.141, tt:6010.457\n",
      "Ep:187, loss:0.00001, loss_test:0.07588, lr:3.55e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.144, tt:6043.160\n",
      "Ep:188, loss:0.00001, loss_test:0.07610, lr:3.52e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.144, tt:6075.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:189, loss:0.00001, loss_test:0.07575, lr:3.48e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.146, tt:6107.748\n",
      "Ep:190, loss:0.00001, loss_test:0.07557, lr:3.45e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.148, tt:6140.299\n",
      "Ep:191, loss:0.00001, loss_test:0.07649, lr:3.41e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.146, tt:6172.069\n",
      "Ep:192, loss:0.00001, loss_test:0.07606, lr:3.38e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.135, tt:6202.098\n",
      "Ep:193, loss:0.00001, loss_test:0.07598, lr:3.34e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.128, tt:6232.769\n",
      "Ep:194, loss:0.00001, loss_test:0.07646, lr:3.31e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.125, tt:6264.370\n",
      "Ep:195, loss:0.00001, loss_test:0.07589, lr:3.28e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.125, tt:6296.597\n",
      "Ep:196, loss:0.00001, loss_test:0.07583, lr:3.24e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.109, tt:6325.480\n",
      "Ep:197, loss:0.00001, loss_test:0.07592, lr:3.21e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.099, tt:6355.690\n",
      "Ep:198, loss:0.00001, loss_test:0.07590, lr:3.18e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.092, tt:6386.354\n",
      "Ep:199, loss:0.00001, loss_test:0.07585, lr:3.15e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.089, tt:6417.773\n",
      "Ep:200, loss:0.00001, loss_test:0.07564, lr:3.12e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.076, tt:6447.313\n",
      "Ep:201, loss:0.00001, loss_test:0.07567, lr:3.09e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.066, tt:6477.420\n",
      "Ep:202, loss:0.00001, loss_test:0.07567, lr:3.05e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.047, tt:6505.519\n",
      "Ep:203, loss:0.00001, loss_test:0.07569, lr:3.02e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.035, tt:6535.167\n",
      "Ep:204, loss:0.00001, loss_test:0.07555, lr:2.99e-03, fs:0.87006 (r=0.778,p=0.987),  time:32.020, tt:6564.039\n",
      "Ep:205, loss:0.00001, loss_test:0.07588, lr:2.96e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.986, tt:6589.201\n",
      "Ep:206, loss:0.00001, loss_test:0.07561, lr:2.93e-03, fs:0.87006 (r=0.778,p=0.987),  time:31.946, tt:6612.876\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01990, lr:6.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:28.143, tt:28.143\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02141, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:28.598, tt:57.197\n",
      "Ep:2, loss:0.00004, loss_test:0.02288, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.357, tt:88.071\n",
      "Ep:3, loss:0.00005, loss_test:0.02289, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.963, tt:119.851\n",
      "Ep:4, loss:0.00004, loss_test:0.02220, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.065, tt:150.326\n",
      "Ep:5, loss:0.00004, loss_test:0.02116, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:30.266, tt:181.597\n",
      "Ep:6, loss:0.00004, loss_test:0.02011, lr:6.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:30.536, tt:213.751\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:30.385, tt:243.081\n",
      "Ep:8, loss:0.00004, loss_test:0.01964, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:30.451, tt:274.063\n",
      "Ep:9, loss:0.00004, loss_test:0.01993, lr:6.00e-02, fs:0.66376 (r=0.768,p=0.585),  time:30.527, tt:305.270\n",
      "Ep:10, loss:0.00004, loss_test:0.01982, lr:6.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:30.569, tt:336.261\n",
      "Ep:11, loss:0.00004, loss_test:0.01948, lr:6.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:30.654, tt:367.844\n",
      "Ep:12, loss:0.00003, loss_test:0.01921, lr:6.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:30.678, tt:398.818\n",
      "Ep:13, loss:0.00003, loss_test:0.01902, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:30.759, tt:430.625\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01880, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:30.852, tt:462.778\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01859, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:30.893, tt:494.292\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01843, lr:6.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:30.867, tt:524.742\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01824, lr:6.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:30.875, tt:555.754\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01799, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:30.924, tt:587.564\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:30.908, tt:618.169\n",
      "Ep:20, loss:0.00003, loss_test:0.01742, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:30.940, tt:649.749\n",
      "Ep:21, loss:0.00003, loss_test:0.01716, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:31.046, tt:683.020\n",
      "Ep:22, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:31.082, tt:714.877\n",
      "Ep:23, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:31.103, tt:746.468\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:31.082, tt:777.044\n",
      "Ep:25, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.103, tt:808.676\n",
      "Ep:26, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:31.048, tt:838.292\n",
      "Ep:27, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:31.077, tt:870.159\n",
      "Ep:28, loss:0.00003, loss_test:0.01638, lr:6.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:31.086, tt:901.490\n",
      "Ep:29, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:31.071, tt:932.129\n",
      "Ep:30, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:31.078, tt:963.408\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:31.053, tt:993.680\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:31.042, tt:1024.376\n",
      "Ep:33, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:31.084, tt:1056.855\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01571, lr:6.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:31.075, tt:1087.632\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:31.076, tt:1118.744\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01550, lr:6.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:31.091, tt:1150.367\n",
      "Ep:37, loss:0.00002, loss_test:0.01542, lr:6.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:31.086, tt:1181.282\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:31.119, tt:1213.638\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:31.098, tt:1243.930\n",
      "Ep:40, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:31.121, tt:1275.957\n",
      "Ep:41, loss:0.00002, loss_test:0.01524, lr:6.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:31.134, tt:1307.631\n",
      "Ep:42, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:31.136, tt:1338.834\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:31.136, tt:1369.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00002, loss_test:0.01518, lr:6.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:31.169, tt:1402.603\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:31.185, tt:1434.507\n",
      "Ep:46, loss:0.00002, loss_test:0.01506, lr:6.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:31.165, tt:1464.778\n",
      "Ep:47, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:31.128, tt:1494.148\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:31.112, tt:1524.468\n",
      "Ep:49, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:31.106, tt:1555.323\n",
      "Ep:50, loss:0.00002, loss_test:0.01504, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:31.097, tt:1585.970\n",
      "Ep:51, loss:0.00002, loss_test:0.01498, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:31.087, tt:1616.545\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:31.074, tt:1646.940\n",
      "Ep:53, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:31.084, tt:1678.548\n",
      "Ep:54, loss:0.00002, loss_test:0.01492, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:31.057, tt:1708.154\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:31.057, tt:1739.201\n",
      "Ep:56, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:31.052, tt:1769.992\n",
      "Ep:57, loss:0.00002, loss_test:0.01493, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:31.041, tt:1800.362\n",
      "Ep:58, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:31.023, tt:1830.374\n",
      "Ep:59, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:30.992, tt:1859.534\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01507, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.979, tt:1889.747\n",
      "Ep:61, loss:0.00002, loss_test:0.01501, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.973, tt:1920.349\n",
      "Ep:62, loss:0.00001, loss_test:0.01501, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.975, tt:1951.425\n",
      "Ep:63, loss:0.00001, loss_test:0.01504, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.932, tt:1979.663\n",
      "Ep:64, loss:0.00001, loss_test:0.01507, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.924, tt:2010.037\n",
      "Ep:65, loss:0.00001, loss_test:0.01503, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.912, tt:2040.190\n",
      "Ep:66, loss:0.00001, loss_test:0.01511, lr:6.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.896, tt:2070.048\n",
      "Ep:67, loss:0.00001, loss_test:0.01512, lr:6.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.878, tt:2099.732\n",
      "Ep:68, loss:0.00001, loss_test:0.01519, lr:6.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.866, tt:2129.728\n",
      "Ep:69, loss:0.00001, loss_test:0.01519, lr:6.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.834, tt:2158.359\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01520, lr:6.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.844, tt:2189.910\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01522, lr:6.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:30.851, tt:2221.261\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01525, lr:6.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:30.858, tt:2252.629\n",
      "Ep:73, loss:0.00001, loss_test:0.01526, lr:6.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:30.848, tt:2282.732\n",
      "Ep:74, loss:0.00001, loss_test:0.01530, lr:6.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:30.822, tt:2311.612\n",
      "Ep:75, loss:0.00001, loss_test:0.01540, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.813, tt:2341.815\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01531, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.813, tt:2372.574\n",
      "Ep:77, loss:0.00001, loss_test:0.01537, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.831, tt:2404.789\n",
      "Ep:78, loss:0.00001, loss_test:0.01545, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.830, tt:2435.576\n",
      "Ep:79, loss:0.00001, loss_test:0.01548, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.805, tt:2464.364\n",
      "Ep:80, loss:0.00001, loss_test:0.01552, lr:6.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:30.790, tt:2493.978\n",
      "Ep:81, loss:0.00001, loss_test:0.01557, lr:6.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:30.774, tt:2523.453\n",
      "Ep:82, loss:0.00001, loss_test:0.01562, lr:6.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.775, tt:2554.284\n",
      "Ep:83, loss:0.00001, loss_test:0.01559, lr:6.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:30.767, tt:2584.439\n",
      "Ep:84, loss:0.00001, loss_test:0.01565, lr:6.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.770, tt:2615.422\n",
      "Ep:85, loss:0.00001, loss_test:0.01568, lr:6.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.761, tt:2645.453\n",
      "Ep:86, loss:0.00001, loss_test:0.01571, lr:6.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.762, tt:2676.304\n",
      "Ep:87, loss:0.00001, loss_test:0.01574, lr:5.94e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.767, tt:2707.531\n",
      "Ep:88, loss:0.00001, loss_test:0.01575, lr:5.88e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.757, tt:2737.371\n",
      "Ep:89, loss:0.00001, loss_test:0.01575, lr:5.82e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.758, tt:2768.195\n",
      "Ep:90, loss:0.00001, loss_test:0.01588, lr:5.76e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.755, tt:2798.706\n",
      "Ep:91, loss:0.00001, loss_test:0.01587, lr:5.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.751, tt:2829.101\n",
      "Ep:92, loss:0.00001, loss_test:0.01593, lr:5.65e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.749, tt:2859.657\n",
      "Ep:93, loss:0.00001, loss_test:0.01585, lr:5.59e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.745, tt:2890.076\n",
      "Ep:94, loss:0.00001, loss_test:0.01590, lr:5.54e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.759, tt:2922.139\n",
      "Ep:95, loss:0.00001, loss_test:0.01603, lr:5.48e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.759, tt:2952.878\n",
      "Ep:96, loss:0.00001, loss_test:0.01601, lr:5.43e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.762, tt:2983.924\n",
      "Ep:97, loss:0.00001, loss_test:0.01597, lr:5.37e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.774, tt:3015.824\n",
      "Ep:98, loss:0.00001, loss_test:0.01610, lr:5.32e-02, fs:0.79787 (r=0.758,p=0.843),  time:30.767, tt:3045.895\n",
      "Ep:99, loss:0.00001, loss_test:0.01620, lr:5.27e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.781, tt:3078.058\n",
      "Ep:100, loss:0.00001, loss_test:0.01617, lr:5.21e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.764, tt:3107.209\n",
      "Ep:101, loss:0.00001, loss_test:0.01610, lr:5.16e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.759, tt:3137.383\n",
      "Ep:102, loss:0.00001, loss_test:0.01614, lr:5.11e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.751, tt:3167.323\n",
      "Ep:103, loss:0.00001, loss_test:0.01617, lr:5.06e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.750, tt:3197.982\n",
      "Ep:104, loss:0.00001, loss_test:0.01629, lr:5.01e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.752, tt:3228.913\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01636, lr:5.01e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.744, tt:3258.835\n",
      "Ep:106, loss:0.00001, loss_test:0.01630, lr:5.01e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.737, tt:3288.875\n",
      "Ep:107, loss:0.00001, loss_test:0.01627, lr:5.01e-02, fs:0.80214 (r=0.758,p=0.852),  time:30.704, tt:3316.055\n",
      "Ep:108, loss:0.00001, loss_test:0.01635, lr:5.01e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.711, tt:3347.490\n",
      "Ep:109, loss:0.00001, loss_test:0.01644, lr:5.01e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.728, tt:3380.060\n",
      "Ep:110, loss:0.00001, loss_test:0.01642, lr:5.01e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.726, tt:3410.564\n",
      "Ep:111, loss:0.00001, loss_test:0.01641, lr:5.01e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.721, tt:3440.710\n",
      "Ep:112, loss:0.00001, loss_test:0.01652, lr:5.01e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.711, tt:3470.330\n",
      "Ep:113, loss:0.00001, loss_test:0.01653, lr:5.01e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.711, tt:3501.061\n",
      "Ep:114, loss:0.00001, loss_test:0.01652, lr:5.01e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.706, tt:3531.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00001, loss_test:0.01652, lr:5.01e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.706, tt:3561.883\n",
      "Ep:116, loss:0.00001, loss_test:0.01667, lr:4.96e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.707, tt:3592.711\n",
      "Ep:117, loss:0.00001, loss_test:0.01673, lr:4.91e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.715, tt:3624.338\n",
      "Ep:118, loss:0.00001, loss_test:0.01672, lr:4.86e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.718, tt:3655.440\n",
      "Ep:119, loss:0.00001, loss_test:0.01667, lr:4.81e-02, fs:0.79781 (r=0.737,p=0.869),  time:30.716, tt:3685.907\n",
      "Ep:120, loss:0.00001, loss_test:0.01678, lr:4.76e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.702, tt:3714.914\n",
      "Ep:121, loss:0.00001, loss_test:0.01678, lr:4.71e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.679, tt:3742.837\n",
      "Ep:122, loss:0.00001, loss_test:0.01680, lr:4.67e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.677, tt:3773.266\n",
      "Ep:123, loss:0.00001, loss_test:0.01677, lr:4.62e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.684, tt:3804.869\n",
      "Ep:124, loss:0.00001, loss_test:0.01688, lr:4.57e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.688, tt:3835.948\n",
      "Ep:125, loss:0.00001, loss_test:0.01690, lr:4.53e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.701, tt:3868.369\n",
      "Ep:126, loss:0.00001, loss_test:0.01686, lr:4.48e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.711, tt:3900.348\n",
      "Ep:127, loss:0.00001, loss_test:0.01695, lr:4.44e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.711, tt:3931.047\n",
      "Ep:128, loss:0.00001, loss_test:0.01709, lr:4.39e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.707, tt:3961.210\n",
      "Ep:129, loss:0.00001, loss_test:0.01707, lr:4.35e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.714, tt:3992.841\n",
      "Ep:130, loss:0.00001, loss_test:0.01705, lr:4.31e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.707, tt:4022.564\n",
      "Ep:131, loss:0.00001, loss_test:0.01713, lr:4.26e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.708, tt:4053.423\n",
      "Ep:132, loss:0.00001, loss_test:0.01705, lr:4.22e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.714, tt:4084.983\n",
      "Ep:133, loss:0.00001, loss_test:0.01712, lr:4.18e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.714, tt:4115.718\n",
      "Ep:134, loss:0.00001, loss_test:0.01716, lr:4.14e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.717, tt:4146.805\n",
      "Ep:135, loss:0.00001, loss_test:0.01714, lr:4.10e-02, fs:0.80874 (r=0.747,p=0.881),  time:30.713, tt:4176.904\n",
      "Ep:136, loss:0.00001, loss_test:0.01721, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.715, tt:4207.975\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00001, loss_test:0.01725, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.733, tt:4241.130\n",
      "Ep:138, loss:0.00001, loss_test:0.01727, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.732, tt:4271.733\n",
      "Ep:139, loss:0.00001, loss_test:0.01729, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.738, tt:4303.340\n",
      "Ep:140, loss:0.00001, loss_test:0.01735, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.744, tt:4334.889\n",
      "Ep:141, loss:0.00001, loss_test:0.01732, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.741, tt:4365.156\n",
      "Ep:142, loss:0.00001, loss_test:0.01738, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.749, tt:4397.154\n",
      "Ep:143, loss:0.00001, loss_test:0.01744, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.760, tt:4429.421\n",
      "Ep:144, loss:0.00001, loss_test:0.01747, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.770, tt:4461.652\n",
      "Ep:145, loss:0.00001, loss_test:0.01750, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.768, tt:4492.123\n",
      "Ep:146, loss:0.00001, loss_test:0.01747, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.759, tt:4521.630\n",
      "Ep:147, loss:0.00001, loss_test:0.01748, lr:4.05e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.763, tt:4552.878\n",
      "Ep:148, loss:0.00001, loss_test:0.01753, lr:4.01e-02, fs:0.81319 (r=0.747,p=0.892),  time:30.766, tt:4584.077\n",
      "Ep:149, loss:0.00001, loss_test:0.01756, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.756, tt:4613.471\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00001, loss_test:0.01761, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.754, tt:4643.874\n",
      "Ep:151, loss:0.00001, loss_test:0.01759, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.761, tt:4675.742\n",
      "Ep:152, loss:0.00001, loss_test:0.01762, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.750, tt:4704.820\n",
      "Ep:153, loss:0.00001, loss_test:0.01768, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.769, tt:4738.403\n",
      "Ep:154, loss:0.00001, loss_test:0.01773, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.766, tt:4768.678\n",
      "Ep:155, loss:0.00001, loss_test:0.01775, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.763, tt:4798.970\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00001, loss_test:0.01778, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.762, tt:4829.709\n",
      "Ep:157, loss:0.00001, loss_test:0.01775, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.765, tt:4860.845\n",
      "Ep:158, loss:0.00001, loss_test:0.01779, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.751, tt:4889.369\n",
      "Ep:159, loss:0.00001, loss_test:0.01780, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.749, tt:4919.884\n",
      "Ep:160, loss:0.00001, loss_test:0.01789, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.740, tt:4949.171\n",
      "Ep:161, loss:0.00001, loss_test:0.01792, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.735, tt:4979.038\n",
      "Ep:162, loss:0.00001, loss_test:0.01794, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.734, tt:5009.577\n",
      "Ep:163, loss:0.00001, loss_test:0.01794, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.727, tt:5039.205\n",
      "Ep:164, loss:0.00001, loss_test:0.01806, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.714, tt:5067.873\n",
      "Ep:165, loss:0.00001, loss_test:0.01805, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.709, tt:5097.716\n",
      "Ep:166, loss:0.00001, loss_test:0.01805, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.698, tt:5126.591\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00001, loss_test:0.01813, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.685, tt:5155.048\n",
      "Ep:168, loss:0.00000, loss_test:0.01809, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.666, tt:5182.501\n",
      "Ep:169, loss:0.00000, loss_test:0.01809, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.667, tt:5213.360\n",
      "Ep:170, loss:0.00000, loss_test:0.01816, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.667, tt:5243.983\n",
      "Ep:171, loss:0.00000, loss_test:0.01818, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.662, tt:5273.908\n",
      "Ep:172, loss:0.00000, loss_test:0.01821, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.661, tt:5304.296\n",
      "Ep:173, loss:0.00000, loss_test:0.01829, lr:3.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.665, tt:5335.666\n",
      "Ep:174, loss:0.00000, loss_test:0.01832, lr:3.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.657, tt:5364.894\n",
      "Ep:175, loss:0.00000, loss_test:0.01837, lr:3.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.650, tt:5394.448\n",
      "Ep:176, loss:0.00000, loss_test:0.01831, lr:3.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.650, tt:5425.041\n",
      "Ep:177, loss:0.00000, loss_test:0.01838, lr:3.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.648, tt:5455.368\n",
      "Ep:178, loss:0.00000, loss_test:0.01840, lr:3.93e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.650, tt:5486.322\n",
      "Ep:179, loss:0.00000, loss_test:0.01844, lr:3.89e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.648, tt:5516.730\n",
      "Ep:180, loss:0.00000, loss_test:0.01845, lr:3.86e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.663, tt:5550.016\n",
      "Ep:181, loss:0.00000, loss_test:0.01848, lr:3.82e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.663, tt:5580.716\n",
      "Ep:182, loss:0.00000, loss_test:0.01852, lr:3.78e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.659, tt:5610.584\n",
      "Ep:183, loss:0.00000, loss_test:0.01857, lr:3.74e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.655, tt:5640.447\n",
      "Ep:184, loss:0.00000, loss_test:0.01856, lr:3.70e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.645, tt:5669.336\n",
      "Ep:185, loss:0.00000, loss_test:0.01852, lr:3.67e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.645, tt:5699.980\n",
      "Ep:186, loss:0.00000, loss_test:0.01856, lr:3.63e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.645, tt:5730.641\n",
      "##########Best model found so far##########\n",
      "Ep:187, loss:0.00000, loss_test:0.01866, lr:3.63e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.635, tt:5759.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:188, loss:0.00000, loss_test:0.01865, lr:3.63e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.629, tt:5788.968\n",
      "Ep:189, loss:0.00000, loss_test:0.01873, lr:3.63e-02, fs:0.82955 (r=0.737,p=0.948),  time:30.628, tt:5819.335\n",
      "Ep:190, loss:0.00000, loss_test:0.01870, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.628, tt:5850.025\n",
      "Ep:191, loss:0.00000, loss_test:0.01873, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.625, tt:5879.986\n",
      "Ep:192, loss:0.00000, loss_test:0.01870, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.623, tt:5910.246\n",
      "Ep:193, loss:0.00000, loss_test:0.01878, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.628, tt:5941.750\n",
      "Ep:194, loss:0.00000, loss_test:0.01886, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.628, tt:5972.364\n",
      "Ep:195, loss:0.00000, loss_test:0.01891, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.629, tt:6003.371\n",
      "Ep:196, loss:0.00000, loss_test:0.01889, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.631, tt:6034.381\n",
      "Ep:197, loss:0.00000, loss_test:0.01891, lr:3.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.637, tt:6066.200\n",
      "Ep:198, loss:0.00000, loss_test:0.01892, lr:3.59e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.637, tt:6096.822\n",
      "Ep:199, loss:0.00000, loss_test:0.01894, lr:3.56e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.635, tt:6126.953\n",
      "Ep:200, loss:0.00000, loss_test:0.01899, lr:3.52e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.635, tt:6157.592\n",
      "Ep:201, loss:0.00000, loss_test:0.01904, lr:3.49e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.630, tt:6187.186\n",
      "Ep:202, loss:0.00000, loss_test:0.01899, lr:3.45e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.644, tt:6220.821\n",
      "Ep:203, loss:0.00000, loss_test:0.01902, lr:3.42e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.636, tt:6249.712\n",
      "Ep:204, loss:0.00000, loss_test:0.01904, lr:3.38e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.625, tt:6278.072\n",
      "Ep:205, loss:0.00000, loss_test:0.01904, lr:3.35e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.626, tt:6308.912\n",
      "Ep:206, loss:0.00000, loss_test:0.01906, lr:3.32e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.614, tt:6337.007\n",
      "Ep:207, loss:0.00000, loss_test:0.01913, lr:3.28e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.611, tt:6367.006\n",
      "Ep:208, loss:0.00000, loss_test:0.01917, lr:3.25e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.590, tt:6393.241\n",
      "Ep:209, loss:0.00000, loss_test:0.01921, lr:3.22e-02, fs:0.82081 (r=0.717,p=0.959),  time:30.571, tt:6419.996\n",
      "Ep:210, loss:0.00000, loss_test:0.01923, lr:3.19e-02, fs:0.82081 (r=0.717,p=0.959),  time:30.566, tt:6449.431\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14362, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.491, tt:31.491\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14263, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.038, tt:60.076\n",
      "Ep:2, loss:0.00028, loss_test:0.14104, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.739, tt:89.216\n",
      "Ep:3, loss:0.00028, loss_test:0.13861, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.437, tt:121.747\n",
      "Ep:4, loss:0.00027, loss_test:0.13497, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:30.716, tt:153.581\n",
      "Ep:5, loss:0.00026, loss_test:0.12946, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:30.949, tt:185.691\n",
      "Ep:6, loss:0.00025, loss_test:0.12174, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:31.172, tt:218.202\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11503, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:31.395, tt:251.157\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11579, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:31.590, tt:284.311\n",
      "Ep:9, loss:0.00022, loss_test:0.11493, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:31.702, tt:317.023\n",
      "Ep:10, loss:0.00022, loss_test:0.11251, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:31.906, tt:350.965\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11115, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:32.072, tt:384.862\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10913, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:32.235, tt:419.049\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10818, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:32.206, tt:450.878\n",
      "Ep:14, loss:0.00019, loss_test:0.10573, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:32.291, tt:484.365\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10441, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:32.358, tt:517.725\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10413, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:32.345, tt:549.865\n",
      "Ep:17, loss:0.00018, loss_test:0.10180, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:32.420, tt:583.569\n",
      "Ep:18, loss:0.00017, loss_test:0.10141, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:32.475, tt:617.025\n",
      "Ep:19, loss:0.00017, loss_test:0.10095, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:32.473, tt:649.461\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09903, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:32.476, tt:682.001\n",
      "Ep:21, loss:0.00016, loss_test:0.09822, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:32.491, tt:714.813\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09840, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.502, tt:747.543\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09654, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:32.470, tt:779.276\n",
      "Ep:24, loss:0.00015, loss_test:0.09723, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:32.484, tt:812.099\n",
      "Ep:25, loss:0.00014, loss_test:0.09675, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:32.447, tt:843.632\n",
      "Ep:26, loss:0.00014, loss_test:0.09646, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:32.461, tt:876.449\n",
      "Ep:27, loss:0.00013, loss_test:0.09567, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:32.448, tt:908.549\n",
      "Ep:28, loss:0.00013, loss_test:0.09356, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:32.442, tt:940.826\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09533, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:32.376, tt:971.291\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.09152, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:32.325, tt:1002.077\n",
      "Ep:31, loss:0.00012, loss_test:0.09165, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:32.276, tt:1032.824\n",
      "Ep:32, loss:0.00012, loss_test:0.09196, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:32.228, tt:1063.538\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08802, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:32.169, tt:1093.754\n",
      "Ep:34, loss:0.00011, loss_test:0.09427, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:32.135, tt:1124.721\n",
      "Ep:35, loss:0.00011, loss_test:0.08844, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:32.085, tt:1155.077\n",
      "Ep:36, loss:0.00010, loss_test:0.09092, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:31.980, tt:1183.264\n",
      "Ep:37, loss:0.00010, loss_test:0.08767, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.977, tt:1215.119\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.08947, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:31.923, tt:1245.014\n",
      "Ep:39, loss:0.00010, loss_test:0.08721, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:31.877, tt:1275.093\n",
      "Ep:40, loss:0.00009, loss_test:0.09065, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:31.839, tt:1305.392\n",
      "Ep:41, loss:0.00009, loss_test:0.08498, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.778, tt:1334.695\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00009, loss_test:0.09015, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:31.752, tt:1365.319\n",
      "Ep:43, loss:0.00009, loss_test:0.08595, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:31.772, tt:1397.970\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.09001, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:31.759, tt:1429.166\n",
      "Ep:45, loss:0.00008, loss_test:0.08649, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.745, tt:1460.289\n",
      "Ep:46, loss:0.00008, loss_test:0.08821, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:31.757, tt:1492.576\n",
      "Ep:47, loss:0.00008, loss_test:0.08657, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.747, tt:1523.863\n",
      "Ep:48, loss:0.00007, loss_test:0.08667, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:31.716, tt:1554.066\n",
      "Ep:49, loss:0.00007, loss_test:0.08591, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.680, tt:1584.018\n",
      "Ep:50, loss:0.00007, loss_test:0.08332, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:31.669, tt:1615.145\n",
      "Ep:51, loss:0.00007, loss_test:0.08462, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.677, tt:1647.187\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.08383, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.635, tt:1676.670\n",
      "Ep:53, loss:0.00006, loss_test:0.08259, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.609, tt:1706.889\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.08428, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.630, tt:1739.637\n",
      "Ep:55, loss:0.00006, loss_test:0.08243, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.627, tt:1771.116\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.08400, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.592, tt:1800.768\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.08320, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.594, tt:1832.456\n",
      "Ep:58, loss:0.00005, loss_test:0.08310, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.564, tt:1862.251\n",
      "Ep:59, loss:0.00005, loss_test:0.08189, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.579, tt:1894.726\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.08344, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:31.559, tt:1925.100\n",
      "Ep:61, loss:0.00005, loss_test:0.08137, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.555, tt:1956.435\n",
      "Ep:62, loss:0.00005, loss_test:0.08669, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:31.521, tt:1985.805\n",
      "Ep:63, loss:0.00005, loss_test:0.07939, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.511, tt:2016.697\n",
      "Ep:64, loss:0.00005, loss_test:0.08890, lr:1.00e-02, fs:0.86667 (r=0.788,p=0.963),  time:31.511, tt:2048.228\n",
      "Ep:65, loss:0.00005, loss_test:0.08031, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:31.511, tt:2079.699\n",
      "Ep:66, loss:0.00005, loss_test:0.08841, lr:1.00e-02, fs:0.86188 (r=0.788,p=0.951),  time:31.498, tt:2110.377\n",
      "Ep:67, loss:0.00005, loss_test:0.08106, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.490, tt:2141.304\n",
      "Ep:68, loss:0.00004, loss_test:0.08864, lr:1.00e-02, fs:0.86517 (r=0.778,p=0.975),  time:31.485, tt:2172.446\n",
      "Ep:69, loss:0.00004, loss_test:0.08071, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:31.453, tt:2201.742\n",
      "Ep:70, loss:0.00004, loss_test:0.08306, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:31.451, tt:2233.012\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.08317, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:31.435, tt:2263.307\n",
      "Ep:72, loss:0.00004, loss_test:0.08085, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.425, tt:2294.042\n",
      "Ep:73, loss:0.00004, loss_test:0.08374, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:31.429, tt:2325.733\n",
      "Ep:74, loss:0.00004, loss_test:0.08038, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.438, tt:2357.848\n",
      "Ep:75, loss:0.00004, loss_test:0.08481, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:31.445, tt:2389.843\n",
      "Ep:76, loss:0.00004, loss_test:0.08245, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:31.453, tt:2421.907\n",
      "Ep:77, loss:0.00004, loss_test:0.08448, lr:1.00e-02, fs:0.86667 (r=0.788,p=0.963),  time:31.455, tt:2453.518\n",
      "Ep:78, loss:0.00004, loss_test:0.08137, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:31.448, tt:2484.430\n",
      "Ep:79, loss:0.00003, loss_test:0.08393, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:31.458, tt:2516.653\n",
      "Ep:80, loss:0.00003, loss_test:0.08237, lr:1.00e-02, fs:0.90909 (r=0.859,p=0.966),  time:31.467, tt:2548.835\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00003, loss_test:0.08101, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:31.472, tt:2580.723\n",
      "Ep:82, loss:0.00003, loss_test:0.08188, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:31.465, tt:2611.614\n",
      "Ep:83, loss:0.00003, loss_test:0.08094, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:31.474, tt:2643.822\n",
      "Ep:84, loss:0.00003, loss_test:0.08122, lr:1.00e-02, fs:0.89617 (r=0.828,p=0.976),  time:31.486, tt:2676.303\n",
      "Ep:85, loss:0.00003, loss_test:0.08051, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:31.507, tt:2709.586\n",
      "Ep:86, loss:0.00003, loss_test:0.08141, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:31.540, tt:2744.022\n",
      "Ep:87, loss:0.00003, loss_test:0.08709, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:31.554, tt:2776.718\n",
      "Ep:88, loss:0.00003, loss_test:0.07937, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:31.563, tt:2809.149\n",
      "Ep:89, loss:0.00003, loss_test:0.08655, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:31.593, tt:2843.411\n",
      "Ep:90, loss:0.00003, loss_test:0.08058, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:31.600, tt:2875.643\n",
      "Ep:91, loss:0.00003, loss_test:0.08566, lr:1.00e-02, fs:0.86517 (r=0.778,p=0.975),  time:31.614, tt:2908.455\n",
      "Ep:92, loss:0.00002, loss_test:0.07929, lr:9.90e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.608, tt:2939.534\n",
      "Ep:93, loss:0.00002, loss_test:0.08752, lr:9.80e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.616, tt:2971.871\n",
      "Ep:94, loss:0.00003, loss_test:0.08094, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.616, tt:3003.557\n",
      "Ep:95, loss:0.00002, loss_test:0.08661, lr:9.61e-03, fs:0.88398 (r=0.808,p=0.976),  time:31.619, tt:3035.440\n",
      "Ep:96, loss:0.00002, loss_test:0.08140, lr:9.51e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.615, tt:3066.700\n",
      "Ep:97, loss:0.00002, loss_test:0.08370, lr:9.41e-03, fs:0.87912 (r=0.808,p=0.964),  time:31.627, tt:3099.475\n",
      "Ep:98, loss:0.00002, loss_test:0.08260, lr:9.32e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.632, tt:3131.574\n",
      "Ep:99, loss:0.00002, loss_test:0.08738, lr:9.23e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.632, tt:3163.229\n",
      "Ep:100, loss:0.00002, loss_test:0.08338, lr:9.14e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.648, tt:3196.400\n",
      "Ep:101, loss:0.00002, loss_test:0.08602, lr:9.04e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.651, tt:3228.403\n",
      "Ep:102, loss:0.00002, loss_test:0.08524, lr:8.95e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.652, tt:3260.182\n",
      "Ep:103, loss:0.00002, loss_test:0.08283, lr:8.86e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.651, tt:3291.753\n",
      "Ep:104, loss:0.00002, loss_test:0.08401, lr:8.78e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.661, tt:3324.401\n",
      "Ep:105, loss:0.00002, loss_test:0.08222, lr:8.69e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.654, tt:3355.352\n",
      "Ep:106, loss:0.00002, loss_test:0.08295, lr:8.60e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.655, tt:3387.084\n",
      "Ep:107, loss:0.00002, loss_test:0.08535, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.666, tt:3419.970\n",
      "Ep:108, loss:0.00002, loss_test:0.08309, lr:8.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.657, tt:3450.609\n",
      "Ep:109, loss:0.00002, loss_test:0.08535, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.652, tt:3481.696\n",
      "Ep:110, loss:0.00002, loss_test:0.08381, lr:8.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.638, tt:3511.802\n",
      "Ep:111, loss:0.00002, loss_test:0.08570, lr:8.18e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.636, tt:3543.253\n",
      "Ep:112, loss:0.00002, loss_test:0.08485, lr:8.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.617, tt:3572.757\n",
      "Ep:113, loss:0.00002, loss_test:0.08361, lr:8.02e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.600, tt:3602.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00002, loss_test:0.08759, lr:7.94e-03, fs:0.78313 (r=0.657,p=0.970),  time:31.604, tt:3634.427\n",
      "Ep:115, loss:0.00001, loss_test:0.08511, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.599, tt:3665.509\n",
      "Ep:116, loss:0.00001, loss_test:0.08436, lr:7.78e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.601, tt:3697.313\n",
      "Ep:117, loss:0.00001, loss_test:0.08463, lr:7.70e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.603, tt:3729.176\n",
      "Ep:118, loss:0.00001, loss_test:0.08669, lr:7.62e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.587, tt:3758.844\n",
      "Ep:119, loss:0.00001, loss_test:0.08427, lr:7.55e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.575, tt:3789.013\n",
      "Ep:120, loss:0.00001, loss_test:0.08636, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.570, tt:3819.940\n",
      "Ep:121, loss:0.00001, loss_test:0.08700, lr:7.40e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.571, tt:3851.635\n",
      "Ep:122, loss:0.00001, loss_test:0.08584, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.563, tt:3882.234\n",
      "Ep:123, loss:0.00001, loss_test:0.08606, lr:7.25e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.535, tt:3910.326\n",
      "Ep:124, loss:0.00001, loss_test:0.08735, lr:7.18e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.518, tt:3939.753\n",
      "Ep:125, loss:0.00001, loss_test:0.08734, lr:7.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.515, tt:3970.933\n",
      "Ep:126, loss:0.00001, loss_test:0.08532, lr:7.03e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.510, tt:4001.756\n",
      "Ep:127, loss:0.00001, loss_test:0.08751, lr:6.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.507, tt:4032.923\n",
      "Ep:128, loss:0.00001, loss_test:0.08532, lr:6.89e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.511, tt:4064.884\n",
      "Ep:129, loss:0.00001, loss_test:0.08758, lr:6.83e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.518, tt:4097.391\n",
      "Ep:130, loss:0.00001, loss_test:0.08608, lr:6.76e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.520, tt:4129.118\n",
      "Ep:131, loss:0.00001, loss_test:0.08902, lr:6.69e-03, fs:0.78313 (r=0.657,p=0.970),  time:31.504, tt:4158.497\n",
      "Ep:132, loss:0.00001, loss_test:0.08719, lr:6.62e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.499, tt:4189.392\n",
      "Ep:133, loss:0.00001, loss_test:0.08622, lr:6.56e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.499, tt:4220.815\n",
      "Ep:134, loss:0.00001, loss_test:0.08893, lr:6.49e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.505, tt:4253.219\n",
      "Ep:135, loss:0.00001, loss_test:0.08626, lr:6.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.511, tt:4285.446\n",
      "Ep:136, loss:0.00001, loss_test:0.08726, lr:6.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.507, tt:4316.454\n",
      "Ep:137, loss:0.00001, loss_test:0.08672, lr:6.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.500, tt:4346.973\n",
      "Ep:138, loss:0.00001, loss_test:0.08658, lr:6.24e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.496, tt:4378.000\n",
      "Ep:139, loss:0.00001, loss_test:0.08887, lr:6.17e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.496, tt:4409.475\n",
      "Ep:140, loss:0.00001, loss_test:0.08597, lr:6.11e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.494, tt:4440.627\n",
      "Ep:141, loss:0.00001, loss_test:0.08740, lr:6.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.497, tt:4472.530\n",
      "Ep:142, loss:0.00001, loss_test:0.08820, lr:5.99e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.495, tt:4503.789\n",
      "Ep:143, loss:0.00001, loss_test:0.08509, lr:5.93e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.492, tt:4534.816\n",
      "Ep:144, loss:0.00001, loss_test:0.08880, lr:5.87e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.495, tt:4566.827\n",
      "Ep:145, loss:0.00001, loss_test:0.08604, lr:5.81e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.482, tt:4596.438\n",
      "Ep:146, loss:0.00001, loss_test:0.08845, lr:5.75e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.493, tt:4629.516\n",
      "Ep:147, loss:0.00001, loss_test:0.08878, lr:5.70e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.492, tt:4660.772\n",
      "Ep:148, loss:0.00001, loss_test:0.08684, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.485, tt:4691.307\n",
      "Ep:149, loss:0.00001, loss_test:0.08791, lr:5.58e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.495, tt:4724.195\n",
      "Ep:150, loss:0.00001, loss_test:0.08644, lr:5.53e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.488, tt:4754.682\n",
      "Ep:151, loss:0.00001, loss_test:0.08907, lr:5.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.477, tt:4784.442\n",
      "Ep:152, loss:0.00001, loss_test:0.08962, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.473, tt:4815.369\n",
      "Ep:153, loss:0.00001, loss_test:0.08676, lr:5.36e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.469, tt:4846.195\n",
      "Ep:154, loss:0.00001, loss_test:0.08920, lr:5.31e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.471, tt:4878.035\n",
      "Ep:155, loss:0.00001, loss_test:0.08914, lr:5.26e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.472, tt:4909.690\n",
      "Ep:156, loss:0.00001, loss_test:0.08732, lr:5.20e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.474, tt:4941.368\n",
      "Ep:157, loss:0.00001, loss_test:0.08936, lr:5.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.475, tt:4972.984\n",
      "Ep:158, loss:0.00001, loss_test:0.08939, lr:5.10e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.481, tt:5005.403\n",
      "Ep:159, loss:0.00001, loss_test:0.08847, lr:5.05e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.485, tt:5037.534\n",
      "Ep:160, loss:0.00001, loss_test:0.08810, lr:5.00e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.486, tt:5069.293\n",
      "Ep:161, loss:0.00001, loss_test:0.08924, lr:4.95e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.489, tt:5101.196\n",
      "Ep:162, loss:0.00001, loss_test:0.08863, lr:4.90e-03, fs:0.79042 (r=0.667,p=0.971),  time:31.489, tt:5132.754\n",
      "Ep:163, loss:0.00001, loss_test:0.08778, lr:4.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.486, tt:5163.750\n",
      "Ep:164, loss:0.00001, loss_test:0.08819, lr:4.80e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.488, tt:5195.493\n",
      "Ep:165, loss:0.00001, loss_test:0.08903, lr:4.75e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.488, tt:5226.968\n",
      "Ep:166, loss:0.00001, loss_test:0.08695, lr:4.71e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.490, tt:5258.844\n",
      "Ep:167, loss:0.00001, loss_test:0.08892, lr:4.66e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.485, tt:5289.498\n",
      "Ep:168, loss:0.00001, loss_test:0.08827, lr:4.61e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.488, tt:5321.436\n",
      "Ep:169, loss:0.00001, loss_test:0.08824, lr:4.57e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.479, tt:5351.420\n",
      "Ep:170, loss:0.00001, loss_test:0.08791, lr:4.52e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.483, tt:5383.677\n",
      "Ep:171, loss:0.00001, loss_test:0.08979, lr:4.48e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.485, tt:5415.381\n",
      "Ep:172, loss:0.00001, loss_test:0.08897, lr:4.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.476, tt:5445.427\n",
      "Ep:173, loss:0.00001, loss_test:0.08758, lr:4.39e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.470, tt:5475.727\n",
      "Ep:174, loss:0.00001, loss_test:0.08904, lr:4.34e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.466, tt:5506.494\n",
      "Ep:175, loss:0.00001, loss_test:0.08990, lr:4.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.459, tt:5536.854\n",
      "Ep:176, loss:0.00001, loss_test:0.08918, lr:4.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:31.461, tt:5568.668\n",
      "Ep:177, loss:0.00001, loss_test:0.08849, lr:4.21e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.457, tt:5599.360\n",
      "Ep:178, loss:0.00001, loss_test:0.08974, lr:4.17e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.455, tt:5630.439\n",
      "Ep:179, loss:0.00001, loss_test:0.08944, lr:4.13e-03, fs:0.79042 (r=0.667,p=0.971),  time:31.449, tt:5660.824\n",
      "Ep:180, loss:0.00001, loss_test:0.08846, lr:4.09e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.448, tt:5692.063\n",
      "Ep:181, loss:0.00001, loss_test:0.08903, lr:4.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.448, tt:5723.575\n",
      "Ep:182, loss:0.00001, loss_test:0.09008, lr:4.01e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.449, tt:5755.214\n",
      "Ep:183, loss:0.00001, loss_test:0.08836, lr:3.97e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.448, tt:5786.350\n",
      "Ep:184, loss:0.00001, loss_test:0.08895, lr:3.93e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.451, tt:5818.429\n",
      "Ep:185, loss:0.00001, loss_test:0.08870, lr:3.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.471, tt:5853.656\n",
      "Ep:186, loss:0.00001, loss_test:0.08945, lr:3.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.476, tt:5885.961\n",
      "Ep:187, loss:0.00001, loss_test:0.08969, lr:3.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.476, tt:5917.560\n",
      "Ep:188, loss:0.00001, loss_test:0.08903, lr:3.77e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.482, tt:5950.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:189, loss:0.00001, loss_test:0.08954, lr:3.73e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.486, tt:5982.410\n",
      "Ep:190, loss:0.00001, loss_test:0.08982, lr:3.70e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.483, tt:6013.208\n",
      "Ep:191, loss:0.00001, loss_test:0.08923, lr:3.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.488, tt:6045.616\n",
      "Ep:192, loss:0.00001, loss_test:0.08959, lr:3.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.496, tt:6078.641\n",
      "Ep:193, loss:0.00001, loss_test:0.08933, lr:3.59e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.505, tt:6111.949\n",
      "Ep:194, loss:0.00001, loss_test:0.08924, lr:3.55e-03, fs:0.79762 (r=0.677,p=0.971),  time:31.508, tt:6144.112\n",
      "Ep:195, loss:0.00001, loss_test:0.09039, lr:3.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.516, tt:6177.091\n",
      "Ep:196, loss:0.00001, loss_test:0.09003, lr:3.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.517, tt:6208.878\n",
      "Ep:197, loss:0.00001, loss_test:0.08918, lr:3.45e-03, fs:0.79762 (r=0.677,p=0.971),  time:31.517, tt:6240.329\n",
      "Ep:198, loss:0.00001, loss_test:0.08938, lr:3.41e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.519, tt:6272.268\n",
      "Ep:199, loss:0.00001, loss_test:0.09000, lr:3.38e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.521, tt:6304.191\n",
      "Ep:200, loss:0.00001, loss_test:0.09001, lr:3.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.530, tt:6337.606\n",
      "Ep:201, loss:0.00001, loss_test:0.08905, lr:3.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:31.533, tt:6369.689\n",
      "Ep:202, loss:0.00001, loss_test:0.08990, lr:3.28e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.533, tt:6401.112\n",
      "Ep:203, loss:0.00001, loss_test:0.09099, lr:3.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.527, tt:6431.475\n",
      "Ep:204, loss:0.00001, loss_test:0.08998, lr:3.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.525, tt:6462.598\n",
      "Ep:205, loss:0.00001, loss_test:0.08950, lr:3.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:31.518, tt:6492.633\n",
      "Ep:206, loss:0.00001, loss_test:0.09044, lr:3.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.521, tt:6524.941\n",
      "Ep:207, loss:0.00001, loss_test:0.09003, lr:3.12e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.510, tt:6554.129\n",
      "Ep:208, loss:0.00001, loss_test:0.09019, lr:3.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.499, tt:6583.287\n",
      "Ep:209, loss:0.00001, loss_test:0.09007, lr:3.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:31.483, tt:6611.455\n",
      "Ep:210, loss:0.00001, loss_test:0.08924, lr:3.02e-03, fs:0.79042 (r=0.667,p=0.971),  time:31.458, tt:6637.682\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02089, lr:6.00e-02, fs:0.64122 (r=0.848,p=0.515),  time:28.028, tt:28.028\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02310, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:29.187, tt:58.374\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02466, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.128, tt:87.383\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02461, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.158, tt:116.633\n",
      "Ep:4, loss:0.00005, loss_test:0.02383, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.030, tt:145.152\n",
      "Ep:5, loss:0.00005, loss_test:0.02275, lr:6.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:28.869, tt:173.212\n",
      "Ep:6, loss:0.00004, loss_test:0.02165, lr:6.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:29.204, tt:204.427\n",
      "Ep:7, loss:0.00004, loss_test:0.02080, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:29.353, tt:234.822\n",
      "Ep:8, loss:0.00004, loss_test:0.02057, lr:6.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:29.355, tt:264.197\n",
      "Ep:9, loss:0.00004, loss_test:0.02082, lr:6.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:29.533, tt:295.327\n",
      "Ep:10, loss:0.00004, loss_test:0.02111, lr:6.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:29.530, tt:324.827\n",
      "Ep:11, loss:0.00004, loss_test:0.02118, lr:6.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:29.435, tt:353.214\n",
      "Ep:12, loss:0.00004, loss_test:0.02111, lr:6.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:29.522, tt:383.785\n",
      "Ep:13, loss:0.00003, loss_test:0.02094, lr:6.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:29.674, tt:415.440\n",
      "Ep:14, loss:0.00003, loss_test:0.02064, lr:5.94e-02, fs:0.68526 (r=0.869,p=0.566),  time:29.695, tt:445.419\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.02033, lr:5.94e-02, fs:0.67742 (r=0.848,p=0.564),  time:29.725, tt:475.593\n",
      "Ep:16, loss:0.00003, loss_test:0.02002, lr:5.94e-02, fs:0.67742 (r=0.848,p=0.564),  time:29.769, tt:506.075\n",
      "Ep:17, loss:0.00003, loss_test:0.01963, lr:5.94e-02, fs:0.68852 (r=0.848,p=0.579),  time:29.797, tt:536.338\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01916, lr:5.94e-02, fs:0.70539 (r=0.859,p=0.599),  time:29.820, tt:566.586\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01875, lr:5.94e-02, fs:0.70539 (r=0.859,p=0.599),  time:29.893, tt:597.859\n",
      "Ep:20, loss:0.00003, loss_test:0.01838, lr:5.94e-02, fs:0.71130 (r=0.859,p=0.607),  time:29.853, tt:626.918\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01803, lr:5.94e-02, fs:0.71130 (r=0.859,p=0.607),  time:29.864, tt:657.018\n",
      "Ep:22, loss:0.00003, loss_test:0.01778, lr:5.94e-02, fs:0.71130 (r=0.859,p=0.607),  time:29.897, tt:687.634\n",
      "Ep:23, loss:0.00003, loss_test:0.01760, lr:5.94e-02, fs:0.72034 (r=0.859,p=0.620),  time:29.886, tt:717.273\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01739, lr:5.94e-02, fs:0.72414 (r=0.848,p=0.632),  time:29.947, tt:748.682\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01719, lr:5.94e-02, fs:0.72727 (r=0.848,p=0.636),  time:29.868, tt:776.568\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01699, lr:5.94e-02, fs:0.71366 (r=0.818,p=0.633),  time:29.914, tt:807.684\n",
      "Ep:27, loss:0.00003, loss_test:0.01678, lr:5.94e-02, fs:0.71681 (r=0.818,p=0.638),  time:30.016, tt:840.461\n",
      "Ep:28, loss:0.00003, loss_test:0.01667, lr:5.94e-02, fs:0.72889 (r=0.828,p=0.651),  time:29.987, tt:869.632\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01659, lr:5.94e-02, fs:0.72889 (r=0.828,p=0.651),  time:30.013, tt:900.404\n",
      "Ep:30, loss:0.00003, loss_test:0.01652, lr:5.94e-02, fs:0.72889 (r=0.828,p=0.651),  time:30.022, tt:930.694\n",
      "Ep:31, loss:0.00002, loss_test:0.01641, lr:5.94e-02, fs:0.72889 (r=0.828,p=0.651),  time:30.045, tt:961.445\n",
      "Ep:32, loss:0.00002, loss_test:0.01631, lr:5.94e-02, fs:0.72646 (r=0.818,p=0.653),  time:30.004, tt:990.132\n",
      "Ep:33, loss:0.00002, loss_test:0.01617, lr:5.94e-02, fs:0.72646 (r=0.818,p=0.653),  time:29.982, tt:1019.400\n",
      "Ep:34, loss:0.00002, loss_test:0.01603, lr:5.94e-02, fs:0.72973 (r=0.818,p=0.659),  time:29.952, tt:1048.325\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01591, lr:5.94e-02, fs:0.74312 (r=0.818,p=0.681),  time:29.959, tt:1078.506\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01581, lr:5.94e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.959, tt:1108.484\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01577, lr:5.94e-02, fs:0.74419 (r=0.808,p=0.690),  time:29.963, tt:1138.604\n",
      "Ep:38, loss:0.00002, loss_test:0.01564, lr:5.94e-02, fs:0.74766 (r=0.808,p=0.696),  time:29.914, tt:1166.642\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01553, lr:5.94e-02, fs:0.75117 (r=0.808,p=0.702),  time:29.904, tt:1196.149\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00002, loss_test:0.01548, lr:5.94e-02, fs:0.75117 (r=0.808,p=0.702),  time:29.953, tt:1228.075\n",
      "Ep:41, loss:0.00002, loss_test:0.01543, lr:5.94e-02, fs:0.73934 (r=0.788,p=0.696),  time:29.980, tt:1259.151\n",
      "Ep:42, loss:0.00002, loss_test:0.01549, lr:5.94e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.001, tt:1290.063\n",
      "Ep:43, loss:0.00002, loss_test:0.01541, lr:5.94e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.026, tt:1321.122\n",
      "Ep:44, loss:0.00002, loss_test:0.01528, lr:5.94e-02, fs:0.73934 (r=0.788,p=0.696),  time:30.017, tt:1350.764\n",
      "Ep:45, loss:0.00002, loss_test:0.01527, lr:5.94e-02, fs:0.74286 (r=0.788,p=0.703),  time:30.034, tt:1381.579\n",
      "Ep:46, loss:0.00002, loss_test:0.01528, lr:5.94e-02, fs:0.73684 (r=0.778,p=0.700),  time:30.026, tt:1411.229\n",
      "Ep:47, loss:0.00002, loss_test:0.01525, lr:5.94e-02, fs:0.74038 (r=0.778,p=0.706),  time:30.010, tt:1440.480\n",
      "Ep:48, loss:0.00002, loss_test:0.01525, lr:5.94e-02, fs:0.74038 (r=0.778,p=0.706),  time:30.014, tt:1470.694\n",
      "Ep:49, loss:0.00002, loss_test:0.01533, lr:5.94e-02, fs:0.74038 (r=0.778,p=0.706),  time:30.021, tt:1501.067\n",
      "Ep:50, loss:0.00002, loss_test:0.01527, lr:5.94e-02, fs:0.74396 (r=0.778,p=0.713),  time:30.018, tt:1530.925\n",
      "Ep:51, loss:0.00002, loss_test:0.01523, lr:5.88e-02, fs:0.74396 (r=0.778,p=0.713),  time:30.011, tt:1560.557\n",
      "Ep:52, loss:0.00002, loss_test:0.01531, lr:5.82e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.023, tt:1591.221\n",
      "Ep:53, loss:0.00002, loss_test:0.01526, lr:5.76e-02, fs:0.74396 (r=0.778,p=0.713),  time:30.015, tt:1620.807\n",
      "Ep:54, loss:0.00002, loss_test:0.01521, lr:5.71e-02, fs:0.75000 (r=0.788,p=0.716),  time:29.999, tt:1649.937\n",
      "Ep:55, loss:0.00002, loss_test:0.01516, lr:5.65e-02, fs:0.75598 (r=0.798,p=0.718),  time:30.021, tt:1681.204\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01528, lr:5.65e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.021, tt:1711.185\n",
      "Ep:57, loss:0.00002, loss_test:0.01529, lr:5.65e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.005, tt:1740.281\n",
      "Ep:58, loss:0.00002, loss_test:0.01525, lr:5.65e-02, fs:0.75962 (r=0.798,p=0.725),  time:30.009, tt:1770.528\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01530, lr:5.65e-02, fs:0.76329 (r=0.798,p=0.731),  time:30.039, tt:1802.359\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01527, lr:5.65e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.052, tt:1833.199\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01526, lr:5.65e-02, fs:0.76699 (r=0.798,p=0.738),  time:30.051, tt:1863.139\n",
      "Ep:62, loss:0.00001, loss_test:0.01538, lr:5.65e-02, fs:0.77073 (r=0.798,p=0.745),  time:30.047, tt:1892.939\n",
      "Ep:63, loss:0.00001, loss_test:0.01540, lr:5.65e-02, fs:0.77451 (r=0.798,p=0.752),  time:30.034, tt:1922.186\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01536, lr:5.65e-02, fs:0.77451 (r=0.798,p=0.752),  time:30.032, tt:1952.074\n",
      "Ep:65, loss:0.00001, loss_test:0.01538, lr:5.65e-02, fs:0.77451 (r=0.798,p=0.752),  time:30.030, tt:1981.981\n",
      "Ep:66, loss:0.00001, loss_test:0.01540, lr:5.65e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.025, tt:2011.679\n",
      "Ep:67, loss:0.00001, loss_test:0.01546, lr:5.65e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.024, tt:2041.610\n",
      "Ep:68, loss:0.00001, loss_test:0.01541, lr:5.65e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.016, tt:2071.074\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01538, lr:5.65e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.032, tt:2102.270\n",
      "Ep:70, loss:0.00001, loss_test:0.01554, lr:5.65e-02, fs:0.77000 (r=0.778,p=0.762),  time:30.036, tt:2132.588\n",
      "Ep:71, loss:0.00001, loss_test:0.01547, lr:5.65e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.053, tt:2163.792\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01555, lr:5.65e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.053, tt:2193.838\n",
      "Ep:73, loss:0.00001, loss_test:0.01569, lr:5.65e-02, fs:0.78173 (r=0.778,p=0.786),  time:30.063, tt:2224.642\n",
      "Ep:74, loss:0.00001, loss_test:0.01558, lr:5.65e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.066, tt:2254.960\n",
      "Ep:75, loss:0.00001, loss_test:0.01572, lr:5.65e-02, fs:0.78571 (r=0.778,p=0.794),  time:30.067, tt:2285.123\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01581, lr:5.65e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.078, tt:2315.985\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01577, lr:5.65e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.068, tt:2345.335\n",
      "Ep:78, loss:0.00001, loss_test:0.01575, lr:5.65e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.060, tt:2374.713\n",
      "Ep:79, loss:0.00001, loss_test:0.01586, lr:5.65e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.069, tt:2405.540\n",
      "Ep:80, loss:0.00001, loss_test:0.01588, lr:5.65e-02, fs:0.79381 (r=0.778,p=0.811),  time:30.066, tt:2435.343\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01596, lr:5.65e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.085, tt:2466.987\n",
      "Ep:82, loss:0.00001, loss_test:0.01596, lr:5.65e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.098, tt:2498.170\n",
      "Ep:83, loss:0.00001, loss_test:0.01596, lr:5.65e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.097, tt:2528.170\n",
      "Ep:84, loss:0.00001, loss_test:0.01611, lr:5.65e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.106, tt:2558.988\n",
      "Ep:85, loss:0.00001, loss_test:0.01614, lr:5.65e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.101, tt:2588.675\n",
      "Ep:86, loss:0.00001, loss_test:0.01612, lr:5.65e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.093, tt:2618.105\n",
      "Ep:87, loss:0.00001, loss_test:0.01613, lr:5.65e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.105, tt:2649.220\n",
      "Ep:88, loss:0.00001, loss_test:0.01632, lr:5.65e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.107, tt:2679.499\n",
      "Ep:89, loss:0.00001, loss_test:0.01640, lr:5.65e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.124, tt:2711.178\n",
      "Ep:90, loss:0.00001, loss_test:0.01633, lr:5.65e-02, fs:0.78534 (r=0.758,p=0.815),  time:30.129, tt:2741.769\n",
      "Ep:91, loss:0.00001, loss_test:0.01637, lr:5.65e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.131, tt:2772.097\n",
      "Ep:92, loss:0.00001, loss_test:0.01636, lr:5.59e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.128, tt:2801.912\n",
      "Ep:93, loss:0.00001, loss_test:0.01645, lr:5.54e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.120, tt:2831.295\n",
      "Ep:94, loss:0.00001, loss_test:0.01652, lr:5.48e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.112, tt:2860.660\n",
      "Ep:95, loss:0.00001, loss_test:0.01654, lr:5.43e-02, fs:0.77249 (r=0.737,p=0.811),  time:30.121, tt:2891.587\n",
      "Ep:96, loss:0.00001, loss_test:0.01657, lr:5.37e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.130, tt:2922.564\n",
      "Ep:97, loss:0.00001, loss_test:0.01671, lr:5.32e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.132, tt:2952.963\n",
      "Ep:98, loss:0.00001, loss_test:0.01671, lr:5.27e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.133, tt:2983.158\n",
      "Ep:99, loss:0.00001, loss_test:0.01677, lr:5.21e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.118, tt:3011.821\n",
      "Ep:100, loss:0.00001, loss_test:0.01680, lr:5.16e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.115, tt:3041.600\n",
      "Ep:101, loss:0.00001, loss_test:0.01675, lr:5.11e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.104, tt:3070.574\n",
      "Ep:102, loss:0.00001, loss_test:0.01688, lr:5.06e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.106, tt:3100.941\n",
      "Ep:103, loss:0.00001, loss_test:0.01687, lr:5.01e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.117, tt:3132.164\n",
      "Ep:104, loss:0.00001, loss_test:0.01683, lr:4.96e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.136, tt:3164.237\n",
      "Ep:105, loss:0.00001, loss_test:0.01699, lr:4.91e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.117, tt:3192.361\n",
      "Ep:106, loss:0.00001, loss_test:0.01701, lr:4.86e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.108, tt:3221.603\n",
      "Ep:107, loss:0.00001, loss_test:0.01700, lr:4.81e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.113, tt:3252.227\n",
      "Ep:108, loss:0.00001, loss_test:0.01697, lr:4.76e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.107, tt:3281.655\n",
      "Ep:109, loss:0.00001, loss_test:0.01708, lr:4.71e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.085, tt:3309.393\n",
      "Ep:110, loss:0.00001, loss_test:0.01713, lr:4.67e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.057, tt:3336.354\n",
      "Ep:111, loss:0.00001, loss_test:0.01724, lr:4.62e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.055, tt:3366.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:112, loss:0.00001, loss_test:0.01718, lr:4.57e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.062, tt:3396.993\n",
      "Ep:113, loss:0.00001, loss_test:0.01730, lr:4.53e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.063, tt:3427.204\n",
      "Ep:114, loss:0.00001, loss_test:0.01727, lr:4.48e-02, fs:0.77838 (r=0.727,p=0.837),  time:30.064, tt:3457.343\n",
      "Ep:115, loss:0.00001, loss_test:0.01727, lr:4.44e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.078, tt:3489.038\n",
      "Ep:116, loss:0.00001, loss_test:0.01724, lr:4.39e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.083, tt:3519.725\n",
      "Ep:117, loss:0.00001, loss_test:0.01734, lr:4.35e-02, fs:0.78689 (r=0.727,p=0.857),  time:30.077, tt:3549.144\n",
      "Ep:118, loss:0.00001, loss_test:0.01735, lr:4.31e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.081, tt:3579.675\n",
      "Ep:119, loss:0.00001, loss_test:0.01746, lr:4.26e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.084, tt:3610.077\n",
      "Ep:120, loss:0.00001, loss_test:0.01745, lr:4.22e-02, fs:0.78689 (r=0.727,p=0.857),  time:30.092, tt:3641.160\n",
      "Ep:121, loss:0.00001, loss_test:0.01753, lr:4.18e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.096, tt:3671.707\n",
      "Ep:122, loss:0.00001, loss_test:0.01756, lr:4.14e-02, fs:0.78689 (r=0.727,p=0.857),  time:30.100, tt:3702.250\n",
      "Ep:123, loss:0.00001, loss_test:0.01758, lr:4.10e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.099, tt:3732.269\n",
      "Ep:124, loss:0.00001, loss_test:0.01762, lr:4.05e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.106, tt:3763.259\n",
      "Ep:125, loss:0.00001, loss_test:0.01762, lr:4.01e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.122, tt:3795.377\n",
      "Ep:126, loss:0.00001, loss_test:0.01770, lr:3.97e-02, fs:0.78022 (r=0.717,p=0.855),  time:30.151, tt:3829.237\n",
      "Ep:127, loss:0.00001, loss_test:0.01771, lr:3.93e-02, fs:0.78453 (r=0.717,p=0.866),  time:30.139, tt:3857.808\n",
      "Ep:128, loss:0.00001, loss_test:0.01769, lr:3.89e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.146, tt:3888.899\n",
      "Ep:129, loss:0.00001, loss_test:0.01775, lr:3.86e-02, fs:0.78453 (r=0.717,p=0.866),  time:30.148, tt:3919.289\n",
      "Ep:130, loss:0.00001, loss_test:0.01787, lr:3.82e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.149, tt:3949.483\n",
      "Ep:131, loss:0.00001, loss_test:0.01783, lr:3.78e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.155, tt:3980.516\n",
      "Ep:132, loss:0.00001, loss_test:0.01777, lr:3.74e-02, fs:0.78453 (r=0.717,p=0.866),  time:30.168, tt:4012.363\n",
      "Ep:133, loss:0.00001, loss_test:0.01783, lr:3.70e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.178, tt:4043.839\n",
      "Ep:134, loss:0.00001, loss_test:0.01792, lr:3.67e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.190, tt:4075.611\n",
      "Ep:135, loss:0.00001, loss_test:0.01795, lr:3.63e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.198, tt:4106.979\n",
      "Ep:136, loss:0.00001, loss_test:0.01792, lr:3.59e-02, fs:0.78889 (r=0.717,p=0.877),  time:30.200, tt:4137.361\n",
      "Ep:137, loss:0.00001, loss_test:0.01799, lr:3.56e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.198, tt:4167.304\n",
      "Ep:138, loss:0.00001, loss_test:0.01803, lr:3.52e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.195, tt:4197.144\n",
      "Ep:139, loss:0.00001, loss_test:0.01810, lr:3.49e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.194, tt:4227.152\n",
      "Ep:140, loss:0.00001, loss_test:0.01806, lr:3.45e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.191, tt:4256.865\n",
      "Ep:141, loss:0.00001, loss_test:0.01810, lr:3.42e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.188, tt:4286.764\n",
      "Ep:142, loss:0.00001, loss_test:0.01817, lr:3.38e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.183, tt:4316.143\n",
      "Ep:143, loss:0.00001, loss_test:0.01818, lr:3.35e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.196, tt:4348.218\n",
      "Ep:144, loss:0.00001, loss_test:0.01823, lr:3.32e-02, fs:0.79330 (r=0.717,p=0.887),  time:30.198, tt:4378.638\n",
      "Ep:145, loss:0.00001, loss_test:0.01825, lr:3.28e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.205, tt:4409.969\n",
      "Ep:146, loss:0.00001, loss_test:0.01818, lr:3.25e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.199, tt:4439.229\n",
      "Ep:147, loss:0.00001, loss_test:0.01822, lr:3.22e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.202, tt:4469.916\n",
      "Ep:148, loss:0.00001, loss_test:0.01829, lr:3.19e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.193, tt:4498.799\n",
      "Ep:149, loss:0.00001, loss_test:0.01827, lr:3.15e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.191, tt:4528.583\n",
      "Ep:150, loss:0.00001, loss_test:0.01834, lr:3.12e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.191, tt:4558.892\n",
      "Ep:151, loss:0.00001, loss_test:0.01836, lr:3.09e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.187, tt:4588.475\n",
      "Ep:152, loss:0.00001, loss_test:0.01836, lr:3.06e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.182, tt:4617.830\n",
      "Ep:153, loss:0.00001, loss_test:0.01843, lr:3.03e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.183, tt:4648.164\n",
      "Ep:154, loss:0.00001, loss_test:0.01845, lr:3.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.198, tt:4680.740\n",
      "Ep:155, loss:0.00001, loss_test:0.01842, lr:2.97e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.207, tt:4712.232\n",
      "Ep:156, loss:0.00001, loss_test:0.01841, lr:2.94e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.204, tt:4742.031\n",
      "Ep:157, loss:0.00001, loss_test:0.01848, lr:2.91e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.208, tt:4772.846\n",
      "Ep:158, loss:0.00001, loss_test:0.01853, lr:2.88e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.206, tt:4802.746\n",
      "Ep:159, loss:0.00001, loss_test:0.01855, lr:2.85e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.207, tt:4833.093\n",
      "Ep:160, loss:0.00001, loss_test:0.01861, lr:2.82e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.204, tt:4862.777\n",
      "Ep:161, loss:0.00001, loss_test:0.01866, lr:2.80e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.202, tt:4892.724\n",
      "Ep:162, loss:0.00001, loss_test:0.01864, lr:2.77e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.194, tt:4921.674\n",
      "Ep:163, loss:0.00001, loss_test:0.01870, lr:2.74e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.191, tt:4951.282\n",
      "Ep:164, loss:0.00001, loss_test:0.01872, lr:2.71e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.196, tt:4982.352\n",
      "Ep:165, loss:0.00001, loss_test:0.01872, lr:2.69e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.201, tt:5013.351\n",
      "Ep:166, loss:0.00001, loss_test:0.01869, lr:2.66e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.202, tt:5043.779\n",
      "Ep:167, loss:0.00001, loss_test:0.01878, lr:2.63e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.196, tt:5072.898\n",
      "Ep:168, loss:0.00001, loss_test:0.01876, lr:2.61e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.201, tt:5103.934\n",
      "Ep:169, loss:0.00001, loss_test:0.01878, lr:2.58e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.203, tt:5134.541\n",
      "Ep:170, loss:0.00001, loss_test:0.01879, lr:2.55e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.227, tt:5168.856\n",
      "Ep:171, loss:0.00001, loss_test:0.01881, lr:2.53e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.226, tt:5198.938\n",
      "Ep:172, loss:0.00001, loss_test:0.01884, lr:2.50e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.229, tt:5229.598\n",
      "Ep:173, loss:0.00001, loss_test:0.01888, lr:2.48e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.224, tt:5258.987\n",
      "Ep:174, loss:0.00000, loss_test:0.01893, lr:2.45e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.222, tt:5288.874\n",
      "Ep:175, loss:0.00000, loss_test:0.01894, lr:2.43e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.222, tt:5319.062\n",
      "Ep:176, loss:0.00000, loss_test:0.01896, lr:2.40e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.225, tt:5349.756\n",
      "Ep:177, loss:0.00000, loss_test:0.01898, lr:2.38e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.226, tt:5380.234\n",
      "Ep:178, loss:0.00000, loss_test:0.01902, lr:2.36e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.229, tt:5410.922\n",
      "Ep:179, loss:0.00000, loss_test:0.01904, lr:2.33e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.221, tt:5439.744\n",
      "Ep:180, loss:0.00000, loss_test:0.01904, lr:2.31e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.219, tt:5469.666\n",
      "Ep:181, loss:0.00000, loss_test:0.01904, lr:2.29e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.224, tt:5500.859\n",
      "Ep:182, loss:0.00000, loss_test:0.01907, lr:2.26e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.226, tt:5531.298\n",
      "Ep:183, loss:0.00000, loss_test:0.01909, lr:2.24e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.225, tt:5561.357\n",
      "Ep:184, loss:0.00000, loss_test:0.01912, lr:2.22e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.229, tt:5592.440\n",
      "Ep:185, loss:0.00000, loss_test:0.01917, lr:2.20e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.221, tt:5621.163\n",
      "Ep:186, loss:0.00000, loss_test:0.01917, lr:2.17e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.215, tt:5650.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:187, loss:0.00000, loss_test:0.01917, lr:2.15e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.219, tt:5681.212\n",
      "Ep:188, loss:0.00000, loss_test:0.01921, lr:2.13e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.228, tt:5713.071\n",
      "Ep:189, loss:0.00000, loss_test:0.01925, lr:2.11e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.225, tt:5742.751\n",
      "Ep:190, loss:0.00000, loss_test:0.01925, lr:2.09e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.221, tt:5772.302\n",
      "Ep:191, loss:0.00000, loss_test:0.01927, lr:2.07e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.230, tt:5804.129\n",
      "Ep:192, loss:0.00000, loss_test:0.01931, lr:2.05e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.244, tt:5837.115\n",
      "Ep:193, loss:0.00000, loss_test:0.01930, lr:2.03e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.243, tt:5867.197\n",
      "Ep:194, loss:0.00000, loss_test:0.01931, lr:2.01e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.243, tt:5897.351\n",
      "Ep:195, loss:0.00000, loss_test:0.01933, lr:1.99e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.244, tt:5927.788\n",
      "Ep:196, loss:0.00000, loss_test:0.01934, lr:1.97e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.248, tt:5958.806\n",
      "Ep:197, loss:0.00000, loss_test:0.01937, lr:1.95e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.251, tt:5989.761\n",
      "Ep:198, loss:0.00000, loss_test:0.01938, lr:1.93e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.250, tt:6019.775\n",
      "Ep:199, loss:0.00000, loss_test:0.01941, lr:1.91e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.246, tt:6049.225\n",
      "Ep:200, loss:0.00000, loss_test:0.01941, lr:1.89e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.243, tt:6078.903\n",
      "Ep:201, loss:0.00000, loss_test:0.01941, lr:1.87e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.241, tt:6108.770\n",
      "Ep:202, loss:0.00000, loss_test:0.01944, lr:1.85e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.240, tt:6138.660\n",
      "Ep:203, loss:0.00000, loss_test:0.01945, lr:1.83e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.241, tt:6169.251\n",
      "Ep:204, loss:0.00000, loss_test:0.01946, lr:1.81e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.241, tt:6199.321\n",
      "Ep:205, loss:0.00000, loss_test:0.01945, lr:1.80e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.237, tt:6228.856\n",
      "Ep:206, loss:0.00000, loss_test:0.01951, lr:1.78e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.238, tt:6259.223\n",
      "Ep:207, loss:0.00000, loss_test:0.01951, lr:1.76e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.243, tt:6290.494\n",
      "Ep:208, loss:0.00000, loss_test:0.01956, lr:1.74e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.246, tt:6321.365\n",
      "Ep:209, loss:0.00000, loss_test:0.01957, lr:1.73e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.249, tt:6352.209\n",
      "Ep:210, loss:0.00000, loss_test:0.01958, lr:1.71e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.242, tt:6381.168\n",
      "Ep:211, loss:0.00000, loss_test:0.01959, lr:1.69e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.234, tt:6409.712\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14400, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.096, tt:29.096\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14326, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.681, tt:55.363\n",
      "Ep:2, loss:0.00028, loss_test:0.14206, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.037, tt:87.111\n",
      "Ep:3, loss:0.00028, loss_test:0.14034, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.956, tt:115.826\n",
      "Ep:4, loss:0.00027, loss_test:0.13776, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.354, tt:146.772\n",
      "Ep:5, loss:0.00027, loss_test:0.13358, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:29.937, tt:179.621\n",
      "Ep:6, loss:0.00026, loss_test:0.12729, lr:1.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:30.241, tt:211.684\n",
      "Ep:7, loss:0.00025, loss_test:0.12068, lr:1.00e-02, fs:0.64957 (r=0.768,p=0.563),  time:30.051, tt:240.411\n",
      "Ep:11, loss:0.00022, loss_test:0.11692, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:30.370, tt:364.439\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.11620, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:30.515, tt:396.689\n",
      "Ep:13, loss:0.00021, loss_test:0.11581, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:30.568, tt:427.948\n",
      "Ep:14, loss:0.00020, loss_test:0.11379, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:30.707, tt:460.612\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.11193, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:30.796, tt:492.737\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.11011, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:30.838, tt:524.247\n",
      "Ep:17, loss:0.00019, loss_test:0.10853, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:30.882, tt:555.870\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10722, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:30.861, tt:586.364\n",
      "Ep:19, loss:0.00018, loss_test:0.10598, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:30.906, tt:618.123\n",
      "Ep:20, loss:0.00017, loss_test:0.10430, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:30.870, tt:648.274\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.10231, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.955, tt:681.002\n",
      "Ep:22, loss:0.00017, loss_test:0.10146, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:30.962, tt:712.130\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.10121, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:30.991, tt:743.779\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09969, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:31.027, tt:775.676\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09888, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:30.987, tt:805.673\n",
      "Ep:26, loss:0.00015, loss_test:0.09788, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.056, tt:838.504\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09669, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.071, tt:869.994\n",
      "Ep:28, loss:0.00014, loss_test:0.09643, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:31.119, tt:902.440\n",
      "Ep:29, loss:0.00014, loss_test:0.09562, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:31.138, tt:934.141\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09481, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:31.104, tt:964.232\n",
      "Ep:31, loss:0.00013, loss_test:0.09422, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:31.130, tt:996.163\n",
      "Ep:32, loss:0.00013, loss_test:0.09342, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:31.124, tt:1027.098\n",
      "Ep:33, loss:0.00013, loss_test:0.09331, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:31.159, tt:1059.407\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.09264, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:31.154, tt:1090.394\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.09206, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:31.169, tt:1122.080\n",
      "Ep:36, loss:0.00012, loss_test:0.09168, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.153, tt:1152.675\n",
      "Ep:37, loss:0.00012, loss_test:0.09098, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.136, tt:1183.182\n",
      "Ep:38, loss:0.00011, loss_test:0.08993, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:31.151, tt:1214.900\n",
      "Ep:39, loss:0.00011, loss_test:0.09128, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:31.134, tt:1245.376\n",
      "Ep:40, loss:0.00011, loss_test:0.09011, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.151, tt:1277.191\n",
      "Ep:41, loss:0.00010, loss_test:0.08813, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:31.162, tt:1308.795\n",
      "Ep:42, loss:0.00010, loss_test:0.08867, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:31.167, tt:1340.194\n",
      "Ep:43, loss:0.00010, loss_test:0.08800, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.161, tt:1371.105\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00010, loss_test:0.08788, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:31.167, tt:1402.522\n",
      "Ep:45, loss:0.00010, loss_test:0.08711, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:31.162, tt:1433.461\n",
      "Ep:46, loss:0.00009, loss_test:0.08769, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:31.193, tt:1466.086\n",
      "Ep:47, loss:0.00009, loss_test:0.08491, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.177, tt:1496.517\n",
      "Ep:48, loss:0.00009, loss_test:0.08475, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.172, tt:1527.416\n",
      "Ep:49, loss:0.00009, loss_test:0.08553, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:31.158, tt:1557.899\n",
      "Ep:50, loss:0.00008, loss_test:0.08361, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:31.158, tt:1589.079\n",
      "Ep:51, loss:0.00008, loss_test:0.08414, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.164, tt:1620.547\n",
      "Ep:52, loss:0.00008, loss_test:0.08551, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:31.168, tt:1651.926\n",
      "Ep:53, loss:0.00008, loss_test:0.08235, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:31.175, tt:1683.429\n",
      "Ep:54, loss:0.00008, loss_test:0.08377, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.222, tt:1717.216\n",
      "Ep:55, loss:0.00007, loss_test:0.08360, lr:9.90e-03, fs:0.79775 (r=0.717,p=0.899),  time:31.241, tt:1749.523\n",
      "Ep:56, loss:0.00007, loss_test:0.08204, lr:9.80e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.267, tt:1782.217\n",
      "Ep:57, loss:0.00007, loss_test:0.08096, lr:9.70e-03, fs:0.78889 (r=0.717,p=0.877),  time:31.280, tt:1814.264\n",
      "Ep:58, loss:0.00007, loss_test:0.08231, lr:9.61e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.275, tt:1845.251\n",
      "Ep:59, loss:0.00007, loss_test:0.08063, lr:9.51e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.287, tt:1877.190\n",
      "Ep:60, loss:0.00007, loss_test:0.08164, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.310, tt:1909.885\n",
      "Ep:61, loss:0.00006, loss_test:0.08142, lr:9.32e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.318, tt:1941.692\n",
      "Ep:62, loss:0.00006, loss_test:0.08002, lr:9.23e-03, fs:0.81111 (r=0.737,p=0.901),  time:31.337, tt:1974.263\n",
      "Ep:63, loss:0.00006, loss_test:0.07956, lr:9.14e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.329, tt:2005.058\n",
      "Ep:64, loss:0.00006, loss_test:0.08024, lr:9.04e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.350, tt:2037.733\n",
      "Ep:65, loss:0.00006, loss_test:0.07634, lr:8.95e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.336, tt:2068.155\n",
      "Ep:66, loss:0.00006, loss_test:0.08263, lr:8.86e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.337, tt:2099.574\n",
      "Ep:67, loss:0.00006, loss_test:0.07563, lr:8.78e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.340, tt:2131.091\n",
      "Ep:68, loss:0.00005, loss_test:0.08134, lr:8.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.362, tt:2163.978\n",
      "Ep:69, loss:0.00005, loss_test:0.07617, lr:8.60e-03, fs:0.81111 (r=0.737,p=0.901),  time:31.387, tt:2197.108\n",
      "Ep:70, loss:0.00005, loss_test:0.07900, lr:8.51e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.376, tt:2227.675\n",
      "Ep:71, loss:0.00005, loss_test:0.07671, lr:8.43e-03, fs:0.79775 (r=0.717,p=0.899),  time:31.386, tt:2259.790\n",
      "Ep:72, loss:0.00005, loss_test:0.07784, lr:8.35e-03, fs:0.78161 (r=0.687,p=0.907),  time:31.396, tt:2291.896\n",
      "Ep:73, loss:0.00005, loss_test:0.07746, lr:8.26e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.401, tt:2323.671\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.07713, lr:8.26e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.409, tt:2355.711\n",
      "Ep:75, loss:0.00005, loss_test:0.07605, lr:8.26e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.417, tt:2387.684\n",
      "Ep:76, loss:0.00005, loss_test:0.07735, lr:8.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.425, tt:2419.756\n",
      "Ep:77, loss:0.00005, loss_test:0.07648, lr:8.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.446, tt:2452.794\n",
      "Ep:78, loss:0.00004, loss_test:0.07620, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.432, tt:2483.154\n",
      "Ep:79, loss:0.00004, loss_test:0.07639, lr:8.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.446, tt:2515.646\n",
      "Ep:80, loss:0.00004, loss_test:0.07579, lr:8.26e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.477, tt:2549.626\n",
      "Ep:81, loss:0.00004, loss_test:0.07484, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:31.495, tt:2582.628\n",
      "Ep:82, loss:0.00004, loss_test:0.07659, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:31.493, tt:2613.947\n",
      "Ep:83, loss:0.00004, loss_test:0.07519, lr:8.26e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.511, tt:2646.912\n",
      "Ep:84, loss:0.00004, loss_test:0.07704, lr:8.26e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.524, tt:2679.523\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.07472, lr:8.26e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.554, tt:2713.682\n",
      "Ep:86, loss:0.00004, loss_test:0.07645, lr:8.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.542, tt:2744.157\n",
      "Ep:87, loss:0.00004, loss_test:0.07502, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.546, tt:2776.092\n",
      "Ep:88, loss:0.00004, loss_test:0.07520, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.558, tt:2808.674\n",
      "Ep:89, loss:0.00004, loss_test:0.07626, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.584, tt:2842.589\n",
      "Ep:90, loss:0.00004, loss_test:0.07373, lr:8.26e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.581, tt:2873.840\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00004, loss_test:0.07691, lr:8.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.582, tt:2905.574\n",
      "Ep:92, loss:0.00003, loss_test:0.07265, lr:8.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.587, tt:2937.622\n",
      "Ep:93, loss:0.00003, loss_test:0.07692, lr:8.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.582, tt:2968.744\n",
      "Ep:94, loss:0.00003, loss_test:0.07422, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.575, tt:2999.655\n",
      "Ep:95, loss:0.00003, loss_test:0.07586, lr:8.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.590, tt:3032.618\n",
      "Ep:96, loss:0.00003, loss_test:0.07627, lr:8.26e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.589, tt:3064.142\n",
      "Ep:97, loss:0.00003, loss_test:0.07272, lr:8.26e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.606, tt:3097.377\n",
      "Ep:98, loss:0.00003, loss_test:0.07610, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.600, tt:3128.405\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00003, loss_test:0.07389, lr:8.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.612, tt:3161.224\n",
      "Ep:100, loss:0.00003, loss_test:0.07520, lr:8.26e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.616, tt:3193.224\n",
      "Ep:101, loss:0.00003, loss_test:0.07550, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.638, tt:3227.091\n",
      "Ep:102, loss:0.00003, loss_test:0.07203, lr:8.26e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.633, tt:3258.162\n",
      "Ep:103, loss:0.00003, loss_test:0.07514, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.633, tt:3289.786\n",
      "Ep:104, loss:0.00003, loss_test:0.07363, lr:8.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.651, tt:3323.350\n",
      "Ep:105, loss:0.00003, loss_test:0.07502, lr:8.26e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.660, tt:3355.983\n",
      "Ep:106, loss:0.00003, loss_test:0.07378, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.677, tt:3389.410\n",
      "Ep:107, loss:0.00003, loss_test:0.07422, lr:8.26e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.686, tt:3422.079\n",
      "Ep:108, loss:0.00003, loss_test:0.07389, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.686, tt:3453.794\n",
      "Ep:109, loss:0.00003, loss_test:0.07405, lr:8.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.697, tt:3486.670\n",
      "Ep:110, loss:0.00003, loss_test:0.07313, lr:8.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.712, tt:3520.029\n",
      "Ep:111, loss:0.00003, loss_test:0.07468, lr:8.10e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.730, tt:3553.776\n",
      "Ep:112, loss:0.00003, loss_test:0.07370, lr:8.02e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.729, tt:3585.396\n",
      "Ep:113, loss:0.00003, loss_test:0.07644, lr:7.94e-03, fs:0.80925 (r=0.707,p=0.946),  time:31.718, tt:3615.840\n",
      "Ep:114, loss:0.00003, loss_test:0.07682, lr:7.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.714, tt:3647.093\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00002, loss_test:0.07234, lr:7.86e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.701, tt:3677.318\n",
      "Ep:116, loss:0.00003, loss_test:0.07784, lr:7.86e-03, fs:0.88268 (r=0.798,p=0.988),  time:31.713, tt:3710.470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:117, loss:0.00002, loss_test:0.07353, lr:7.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.704, tt:3741.015\n",
      "Ep:118, loss:0.00002, loss_test:0.07422, lr:7.86e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.700, tt:3772.334\n",
      "Ep:119, loss:0.00002, loss_test:0.07582, lr:7.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.716, tt:3805.930\n",
      "Ep:120, loss:0.00002, loss_test:0.07278, lr:7.86e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.722, tt:3838.319\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00002, loss_test:0.07646, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.722, tt:3870.096\n",
      "Ep:122, loss:0.00002, loss_test:0.07296, lr:7.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.730, tt:3902.771\n",
      "Ep:123, loss:0.00002, loss_test:0.07381, lr:7.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.722, tt:3933.502\n",
      "Ep:124, loss:0.00002, loss_test:0.07528, lr:7.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.720, tt:3965.055\n",
      "Ep:125, loss:0.00002, loss_test:0.07314, lr:7.86e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.726, tt:3997.531\n",
      "Ep:126, loss:0.00002, loss_test:0.07527, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.731, tt:4029.865\n",
      "Ep:127, loss:0.00002, loss_test:0.07292, lr:7.86e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.742, tt:4062.985\n",
      "Ep:128, loss:0.00002, loss_test:0.07453, lr:7.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.741, tt:4094.529\n",
      "Ep:129, loss:0.00002, loss_test:0.07404, lr:7.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.732, tt:4125.103\n",
      "Ep:130, loss:0.00002, loss_test:0.07427, lr:7.86e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.738, tt:4157.682\n",
      "Ep:131, loss:0.00002, loss_test:0.07555, lr:7.86e-03, fs:0.84091 (r=0.747,p=0.961),  time:31.749, tt:4190.881\n",
      "Ep:132, loss:0.00002, loss_test:0.07262, lr:7.78e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.770, tt:4225.432\n",
      "Ep:133, loss:0.00002, loss_test:0.07828, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.778, tt:4258.263\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00002, loss_test:0.07589, lr:7.70e-03, fs:0.88398 (r=0.808,p=0.976),  time:31.790, tt:4291.710\n",
      "Ep:135, loss:0.00002, loss_test:0.07572, lr:7.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.791, tt:4323.596\n",
      "Ep:136, loss:0.00002, loss_test:0.08057, lr:7.70e-03, fs:0.82353 (r=0.707,p=0.986),  time:31.802, tt:4356.884\n",
      "Ep:137, loss:0.00002, loss_test:0.07320, lr:7.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.809, tt:4389.665\n",
      "Ep:138, loss:0.00002, loss_test:0.07644, lr:7.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:31.798, tt:4419.922\n",
      "Ep:139, loss:0.00002, loss_test:0.07667, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.798, tt:4451.729\n",
      "Ep:140, loss:0.00002, loss_test:0.07431, lr:7.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.798, tt:4483.516\n",
      "Ep:141, loss:0.00002, loss_test:0.07618, lr:7.70e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.800, tt:4515.543\n",
      "Ep:142, loss:0.00002, loss_test:0.07598, lr:7.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.806, tt:4548.244\n",
      "Ep:143, loss:0.00002, loss_test:0.07369, lr:7.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.799, tt:4579.087\n",
      "Ep:144, loss:0.00002, loss_test:0.07840, lr:7.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:31.811, tt:4612.658\n",
      "Ep:145, loss:0.00002, loss_test:0.07887, lr:7.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:31.816, tt:4645.148\n",
      "Ep:146, loss:0.00002, loss_test:0.07389, lr:7.55e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.828, tt:4678.659\n",
      "Ep:147, loss:0.00002, loss_test:0.07715, lr:7.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.828, tt:4710.480\n",
      "Ep:148, loss:0.00002, loss_test:0.07588, lr:7.40e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.834, tt:4743.239\n",
      "Ep:149, loss:0.00002, loss_test:0.07618, lr:7.32e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.831, tt:4774.686\n",
      "Ep:150, loss:0.00002, loss_test:0.07690, lr:7.25e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.832, tt:4806.698\n",
      "Ep:151, loss:0.00002, loss_test:0.07568, lr:7.18e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.831, tt:4838.294\n",
      "Ep:152, loss:0.00002, loss_test:0.07875, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.833, tt:4870.390\n",
      "Ep:153, loss:0.00002, loss_test:0.07675, lr:7.03e-03, fs:0.83721 (r=0.727,p=0.986),  time:31.846, tt:4904.317\n",
      "Ep:154, loss:0.00002, loss_test:0.07507, lr:6.96e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.854, tt:4937.309\n",
      "Ep:155, loss:0.00001, loss_test:0.07726, lr:6.89e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.862, tt:4970.526\n",
      "Ep:156, loss:0.00001, loss_test:0.07635, lr:6.83e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.864, tt:5002.686\n",
      "Ep:157, loss:0.00001, loss_test:0.07636, lr:6.76e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.861, tt:5034.069\n",
      "Ep:158, loss:0.00001, loss_test:0.07712, lr:6.69e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.858, tt:5065.461\n",
      "Ep:159, loss:0.00001, loss_test:0.07593, lr:6.62e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.874, tt:5099.853\n",
      "Ep:160, loss:0.00001, loss_test:0.07544, lr:6.56e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.874, tt:5131.705\n",
      "Ep:161, loss:0.00001, loss_test:0.07639, lr:6.49e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.865, tt:5162.069\n",
      "Ep:162, loss:0.00001, loss_test:0.07482, lr:6.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.867, tt:5194.316\n",
      "Ep:163, loss:0.00001, loss_test:0.07810, lr:6.36e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.866, tt:5226.038\n",
      "Ep:164, loss:0.00001, loss_test:0.07623, lr:6.30e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.862, tt:5257.269\n",
      "Ep:165, loss:0.00001, loss_test:0.07528, lr:6.24e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.860, tt:5288.692\n",
      "Ep:166, loss:0.00001, loss_test:0.07695, lr:6.17e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.859, tt:5320.447\n",
      "Ep:167, loss:0.00001, loss_test:0.07612, lr:6.11e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.855, tt:5351.684\n",
      "Ep:168, loss:0.00001, loss_test:0.07579, lr:6.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.852, tt:5383.034\n",
      "Ep:169, loss:0.00001, loss_test:0.07647, lr:5.99e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.840, tt:5412.829\n",
      "Ep:170, loss:0.00001, loss_test:0.07582, lr:5.93e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.842, tt:5445.064\n",
      "Ep:171, loss:0.00001, loss_test:0.07675, lr:5.87e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.848, tt:5477.906\n",
      "Ep:172, loss:0.00001, loss_test:0.07710, lr:5.81e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.856, tt:5511.134\n",
      "Ep:173, loss:0.00001, loss_test:0.07612, lr:5.75e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.866, tt:5544.601\n",
      "Ep:174, loss:0.00001, loss_test:0.07672, lr:5.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.861, tt:5575.643\n",
      "Ep:175, loss:0.00001, loss_test:0.07790, lr:5.64e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.861, tt:5607.506\n",
      "Ep:176, loss:0.00001, loss_test:0.07568, lr:5.58e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.861, tt:5639.470\n",
      "Ep:177, loss:0.00001, loss_test:0.07586, lr:5.53e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.858, tt:5670.729\n",
      "Ep:178, loss:0.00001, loss_test:0.07683, lr:5.47e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.857, tt:5702.445\n",
      "Ep:179, loss:0.00001, loss_test:0.07694, lr:5.42e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.855, tt:5733.940\n",
      "Ep:180, loss:0.00001, loss_test:0.07608, lr:5.36e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.851, tt:5764.966\n",
      "Ep:181, loss:0.00001, loss_test:0.07698, lr:5.31e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.845, tt:5795.861\n",
      "Ep:182, loss:0.00001, loss_test:0.07641, lr:5.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.846, tt:5827.832\n",
      "Ep:183, loss:0.00001, loss_test:0.07675, lr:5.20e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.837, tt:5858.038\n",
      "Ep:184, loss:0.00001, loss_test:0.07671, lr:5.15e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.830, tt:5888.505\n",
      "Ep:185, loss:0.00001, loss_test:0.07665, lr:5.10e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.834, tt:5921.068\n",
      "Ep:186, loss:0.00001, loss_test:0.07694, lr:5.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.828, tt:5951.896\n",
      "Ep:187, loss:0.00001, loss_test:0.07753, lr:5.00e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.835, tt:5984.920\n",
      "Ep:188, loss:0.00001, loss_test:0.07737, lr:4.95e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.835, tt:6016.765\n",
      "Ep:189, loss:0.00001, loss_test:0.07693, lr:4.90e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.858, tt:6052.993\n",
      "Ep:190, loss:0.00001, loss_test:0.07677, lr:4.85e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.859, tt:6085.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00001, loss_test:0.07745, lr:4.80e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.858, tt:6116.810\n",
      "Ep:192, loss:0.00001, loss_test:0.07700, lr:4.75e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.861, tt:6149.214\n",
      "Ep:193, loss:0.00001, loss_test:0.07701, lr:4.71e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.862, tt:6181.161\n",
      "Ep:194, loss:0.00001, loss_test:0.07705, lr:4.66e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.873, tt:6215.191\n",
      "Ep:195, loss:0.00001, loss_test:0.07653, lr:4.61e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.874, tt:6247.366\n",
      "Ep:196, loss:0.00001, loss_test:0.07786, lr:4.57e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.878, tt:6279.877\n",
      "Ep:197, loss:0.00001, loss_test:0.07724, lr:4.52e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.881, tt:6312.512\n",
      "Ep:198, loss:0.00001, loss_test:0.07658, lr:4.48e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.879, tt:6343.924\n",
      "Ep:199, loss:0.00001, loss_test:0.07834, lr:4.43e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.876, tt:6375.188\n",
      "Ep:200, loss:0.00001, loss_test:0.07734, lr:4.39e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.880, tt:6407.899\n",
      "Ep:201, loss:0.00001, loss_test:0.07783, lr:4.34e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.882, tt:6440.262\n",
      "Ep:202, loss:0.00001, loss_test:0.07765, lr:4.30e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.893, tt:6474.310\n",
      "Ep:203, loss:0.00001, loss_test:0.07751, lr:4.26e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.895, tt:6506.606\n",
      "Ep:204, loss:0.00001, loss_test:0.07865, lr:4.21e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.893, tt:6537.965\n",
      "Ep:205, loss:0.00001, loss_test:0.07782, lr:4.17e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.898, tt:6571.076\n",
      "Ep:206, loss:0.00001, loss_test:0.07793, lr:4.13e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.901, tt:6603.495\n",
      "Ep:207, loss:0.00001, loss_test:0.07821, lr:4.09e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.901, tt:6635.330\n",
      "Ep:208, loss:0.00001, loss_test:0.07835, lr:4.05e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.898, tt:6666.582\n",
      "Ep:209, loss:0.00001, loss_test:0.07811, lr:4.01e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.888, tt:6696.482\n",
      "Ep:210, loss:0.00001, loss_test:0.07818, lr:3.97e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.891, tt:6728.928\n",
      "Ep:211, loss:0.00001, loss_test:0.07899, lr:3.93e-03, fs:0.88889 (r=0.808,p=0.988),  time:31.891, tt:6760.853\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02025, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:21.303, tt:21.303\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02176, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.460, tt:44.920\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02457, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.165, tt:72.494\n",
      "Ep:3, loss:0.00005, loss_test:0.02603, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.763, tt:99.052\n",
      "Ep:4, loss:0.00005, loss_test:0.02644, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.151, tt:125.755\n",
      "Ep:5, loss:0.00005, loss_test:0.02622, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.016, tt:156.095\n",
      "Ep:6, loss:0.00005, loss_test:0.02552, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.265, tt:183.856\n",
      "Ep:7, loss:0.00005, loss_test:0.02446, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.548, tt:212.382\n",
      "Ep:8, loss:0.00005, loss_test:0.02312, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.750, tt:240.753\n",
      "Ep:9, loss:0.00004, loss_test:0.02167, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.968, tt:269.681\n",
      "Ep:10, loss:0.00004, loss_test:0.02026, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:27.154, tt:298.696\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01919, lr:6.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:27.331, tt:327.970\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01877, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:27.528, tt:357.867\n",
      "Ep:13, loss:0.00004, loss_test:0.01895, lr:6.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:27.646, tt:387.042\n",
      "Ep:14, loss:0.00004, loss_test:0.01925, lr:6.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:27.837, tt:417.557\n",
      "Ep:15, loss:0.00003, loss_test:0.01920, lr:6.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:27.895, tt:446.315\n",
      "Ep:16, loss:0.00003, loss_test:0.01890, lr:6.00e-02, fs:0.66667 (r=0.768,p=0.589),  time:27.890, tt:474.122\n",
      "Ep:17, loss:0.00003, loss_test:0.01858, lr:6.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:28.008, tt:504.146\n",
      "Ep:18, loss:0.00003, loss_test:0.01834, lr:6.00e-02, fs:0.68595 (r=0.838,p=0.580),  time:28.102, tt:533.941\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01813, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:28.389, tt:567.782\n",
      "Ep:20, loss:0.00003, loss_test:0.01793, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:28.550, tt:599.545\n",
      "Ep:21, loss:0.00003, loss_test:0.01780, lr:6.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:28.626, tt:629.780\n",
      "Ep:22, loss:0.00003, loss_test:0.01773, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:28.661, tt:659.193\n",
      "Ep:23, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:28.758, tt:690.192\n",
      "Ep:24, loss:0.00003, loss_test:0.01763, lr:6.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:28.788, tt:719.700\n",
      "Ep:25, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:28.833, tt:749.655\n",
      "Ep:26, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.66960 (r=0.768,p=0.594),  time:28.871, tt:779.525\n",
      "Ep:27, loss:0.00002, loss_test:0.01730, lr:6.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:28.897, tt:809.130\n",
      "Ep:28, loss:0.00002, loss_test:0.01719, lr:6.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:28.942, tt:839.319\n",
      "Ep:29, loss:0.00002, loss_test:0.01709, lr:6.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:28.965, tt:868.965\n",
      "Ep:30, loss:0.00002, loss_test:0.01698, lr:5.94e-02, fs:0.68161 (r=0.768,p=0.613),  time:28.988, tt:898.639\n",
      "Ep:31, loss:0.00002, loss_test:0.01687, lr:5.88e-02, fs:0.68161 (r=0.768,p=0.613),  time:28.980, tt:927.355\n",
      "Ep:32, loss:0.00002, loss_test:0.01678, lr:5.82e-02, fs:0.68161 (r=0.768,p=0.613),  time:29.005, tt:957.165\n",
      "Ep:33, loss:0.00002, loss_test:0.01669, lr:5.76e-02, fs:0.68161 (r=0.768,p=0.613),  time:29.051, tt:987.745\n",
      "Ep:34, loss:0.00002, loss_test:0.01664, lr:5.71e-02, fs:0.69058 (r=0.778,p=0.621),  time:29.080, tt:1017.797\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01660, lr:5.71e-02, fs:0.69683 (r=0.778,p=0.631),  time:29.070, tt:1046.515\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01659, lr:5.71e-02, fs:0.70642 (r=0.778,p=0.647),  time:29.095, tt:1076.509\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01655, lr:5.71e-02, fs:0.70642 (r=0.778,p=0.647),  time:29.116, tt:1106.406\n",
      "Ep:38, loss:0.00002, loss_test:0.01649, lr:5.71e-02, fs:0.71296 (r=0.778,p=0.658),  time:29.131, tt:1136.097\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01643, lr:5.71e-02, fs:0.70698 (r=0.768,p=0.655),  time:29.134, tt:1165.374\n",
      "Ep:40, loss:0.00002, loss_test:0.01637, lr:5.71e-02, fs:0.71296 (r=0.778,p=0.658),  time:29.110, tt:1193.502\n",
      "Ep:41, loss:0.00002, loss_test:0.01634, lr:5.71e-02, fs:0.71628 (r=0.778,p=0.664),  time:29.149, tt:1224.253\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01630, lr:5.71e-02, fs:0.71963 (r=0.778,p=0.670),  time:29.180, tt:1254.746\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:43, loss:0.00002, loss_test:0.01625, lr:5.71e-02, fs:0.72300 (r=0.778,p=0.675),  time:29.225, tt:1285.885\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01618, lr:5.71e-02, fs:0.72897 (r=0.788,p=0.678),  time:29.255, tt:1316.496\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01614, lr:5.71e-02, fs:0.73239 (r=0.788,p=0.684),  time:29.271, tt:1346.476\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01613, lr:5.71e-02, fs:0.73239 (r=0.788,p=0.684),  time:29.298, tt:1377.028\n",
      "Ep:47, loss:0.00002, loss_test:0.01613, lr:5.71e-02, fs:0.73832 (r=0.798,p=0.687),  time:29.358, tt:1409.196\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01610, lr:5.71e-02, fs:0.73832 (r=0.798,p=0.687),  time:29.384, tt:1439.799\n",
      "Ep:49, loss:0.00002, loss_test:0.01609, lr:5.71e-02, fs:0.73832 (r=0.798,p=0.687),  time:29.406, tt:1470.310\n",
      "Ep:50, loss:0.00002, loss_test:0.01605, lr:5.71e-02, fs:0.74178 (r=0.798,p=0.693),  time:29.444, tt:1501.644\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01601, lr:5.71e-02, fs:0.74766 (r=0.808,p=0.696),  time:29.464, tt:1532.115\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01596, lr:5.71e-02, fs:0.75349 (r=0.818,p=0.698),  time:29.468, tt:1561.821\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01593, lr:5.71e-02, fs:0.75701 (r=0.818,p=0.704),  time:29.485, tt:1592.167\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.76056 (r=0.818,p=0.711),  time:29.499, tt:1622.457\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.76415 (r=0.818,p=0.717),  time:29.506, tt:1652.309\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01593, lr:5.71e-02, fs:0.76190 (r=0.808,p=0.721),  time:29.500, tt:1681.486\n",
      "Ep:57, loss:0.00001, loss_test:0.01592, lr:5.71e-02, fs:0.76190 (r=0.808,p=0.721),  time:29.518, tt:1712.018\n",
      "Ep:58, loss:0.00001, loss_test:0.01590, lr:5.71e-02, fs:0.76190 (r=0.808,p=0.721),  time:29.548, tt:1743.326\n",
      "Ep:59, loss:0.00001, loss_test:0.01591, lr:5.71e-02, fs:0.75598 (r=0.798,p=0.718),  time:29.555, tt:1773.324\n",
      "Ep:60, loss:0.00001, loss_test:0.01591, lr:5.71e-02, fs:0.76329 (r=0.798,p=0.731),  time:29.572, tt:1803.872\n",
      "Ep:61, loss:0.00001, loss_test:0.01591, lr:5.71e-02, fs:0.77073 (r=0.798,p=0.745),  time:29.611, tt:1835.891\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01592, lr:5.71e-02, fs:0.77073 (r=0.798,p=0.745),  time:29.632, tt:1866.842\n",
      "Ep:63, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.77073 (r=0.798,p=0.745),  time:29.655, tt:1897.913\n",
      "Ep:64, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.77451 (r=0.798,p=0.752),  time:29.659, tt:1927.856\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.77451 (r=0.798,p=0.752),  time:29.653, tt:1957.101\n",
      "Ep:66, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.77451 (r=0.798,p=0.752),  time:29.667, tt:1987.680\n",
      "Ep:67, loss:0.00001, loss_test:0.01595, lr:5.71e-02, fs:0.77833 (r=0.798,p=0.760),  time:29.688, tt:2018.806\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01595, lr:5.71e-02, fs:0.77833 (r=0.798,p=0.760),  time:29.698, tt:2049.138\n",
      "Ep:69, loss:0.00001, loss_test:0.01598, lr:5.71e-02, fs:0.77833 (r=0.798,p=0.760),  time:29.690, tt:2078.273\n",
      "Ep:70, loss:0.00001, loss_test:0.01598, lr:5.71e-02, fs:0.77833 (r=0.798,p=0.760),  time:29.686, tt:2107.724\n",
      "Ep:71, loss:0.00001, loss_test:0.01598, lr:5.71e-02, fs:0.77833 (r=0.798,p=0.760),  time:29.682, tt:2137.111\n",
      "Ep:72, loss:0.00001, loss_test:0.01599, lr:5.71e-02, fs:0.79000 (r=0.798,p=0.782),  time:29.680, tt:2166.635\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01599, lr:5.71e-02, fs:0.79000 (r=0.798,p=0.782),  time:29.702, tt:2197.942\n",
      "Ep:74, loss:0.00001, loss_test:0.01600, lr:5.71e-02, fs:0.79000 (r=0.798,p=0.782),  time:29.704, tt:2227.837\n",
      "Ep:75, loss:0.00001, loss_test:0.01603, lr:5.71e-02, fs:0.79000 (r=0.798,p=0.782),  time:29.700, tt:2257.214\n",
      "Ep:76, loss:0.00001, loss_test:0.01603, lr:5.71e-02, fs:0.78392 (r=0.788,p=0.780),  time:29.709, tt:2287.578\n",
      "Ep:77, loss:0.00001, loss_test:0.01606, lr:5.71e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.714, tt:2317.729\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01607, lr:5.71e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.716, tt:2347.577\n",
      "Ep:79, loss:0.00001, loss_test:0.01609, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.707, tt:2376.536\n",
      "Ep:80, loss:0.00001, loss_test:0.01610, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.703, tt:2405.971\n",
      "Ep:81, loss:0.00001, loss_test:0.01610, lr:5.71e-02, fs:0.79592 (r=0.788,p=0.804),  time:29.703, tt:2435.660\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01611, lr:5.71e-02, fs:0.79592 (r=0.788,p=0.804),  time:29.712, tt:2466.079\n",
      "Ep:83, loss:0.00001, loss_test:0.01614, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.724, tt:2496.828\n",
      "Ep:84, loss:0.00001, loss_test:0.01616, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.745, tt:2528.318\n",
      "Ep:85, loss:0.00001, loss_test:0.01617, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.748, tt:2558.357\n",
      "Ep:86, loss:0.00001, loss_test:0.01619, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.756, tt:2588.804\n",
      "Ep:87, loss:0.00001, loss_test:0.01623, lr:5.71e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.754, tt:2618.375\n",
      "Ep:88, loss:0.00001, loss_test:0.01626, lr:5.71e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.765, tt:2649.042\n",
      "Ep:89, loss:0.00001, loss_test:0.01628, lr:5.71e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.776, tt:2679.817\n",
      "Ep:90, loss:0.00001, loss_test:0.01629, lr:5.71e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.779, tt:2709.877\n",
      "Ep:91, loss:0.00001, loss_test:0.01631, lr:5.71e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.777, tt:2739.503\n",
      "Ep:92, loss:0.00001, loss_test:0.01632, lr:5.71e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.778, tt:2769.330\n",
      "Ep:93, loss:0.00001, loss_test:0.01633, lr:5.65e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.773, tt:2798.674\n",
      "Ep:94, loss:0.00001, loss_test:0.01633, lr:5.59e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.783, tt:2829.340\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01634, lr:5.59e-02, fs:0.82051 (r=0.808,p=0.833),  time:29.791, tt:2859.970\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01638, lr:5.59e-02, fs:0.82474 (r=0.808,p=0.842),  time:29.798, tt:2890.420\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01642, lr:5.59e-02, fs:0.82292 (r=0.798,p=0.849),  time:29.793, tt:2919.722\n",
      "Ep:98, loss:0.00001, loss_test:0.01645, lr:5.59e-02, fs:0.82292 (r=0.798,p=0.849),  time:29.800, tt:2950.158\n",
      "Ep:99, loss:0.00001, loss_test:0.01649, lr:5.59e-02, fs:0.82723 (r=0.798,p=0.859),  time:29.806, tt:2980.565\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01651, lr:5.59e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.803, tt:3010.070\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01656, lr:5.59e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.802, tt:3039.762\n",
      "Ep:102, loss:0.00001, loss_test:0.01660, lr:5.59e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.812, tt:3070.685\n",
      "Ep:103, loss:0.00001, loss_test:0.01664, lr:5.59e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.825, tt:3101.815\n",
      "Ep:104, loss:0.00001, loss_test:0.01667, lr:5.59e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.834, tt:3132.522\n",
      "Ep:105, loss:0.00001, loss_test:0.01670, lr:5.59e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.835, tt:3162.497\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.01672, lr:5.59e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.844, tt:3193.264\n",
      "Ep:107, loss:0.00001, loss_test:0.01674, lr:5.59e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.857, tt:3224.574\n",
      "Ep:108, loss:0.00001, loss_test:0.01678, lr:5.59e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.863, tt:3255.089\n",
      "Ep:109, loss:0.00001, loss_test:0.01680, lr:5.59e-02, fs:0.83770 (r=0.808,p=0.870),  time:29.852, tt:3283.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:110, loss:0.00001, loss_test:0.01683, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.869, tt:3315.481\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01688, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.868, tt:3345.210\n",
      "Ep:112, loss:0.00001, loss_test:0.01694, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.867, tt:3374.985\n",
      "Ep:113, loss:0.00001, loss_test:0.01697, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.866, tt:3404.769\n",
      "Ep:114, loss:0.00001, loss_test:0.01700, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.875, tt:3435.649\n",
      "Ep:115, loss:0.00001, loss_test:0.01704, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.886, tt:3466.740\n",
      "Ep:116, loss:0.00001, loss_test:0.01705, lr:5.59e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.886, tt:3496.635\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01709, lr:5.59e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.879, tt:3525.687\n",
      "Ep:118, loss:0.00001, loss_test:0.01715, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.876, tt:3555.258\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.01721, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.892, tt:3586.982\n",
      "Ep:120, loss:0.00001, loss_test:0.01725, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.916, tt:3619.878\n",
      "Ep:121, loss:0.00001, loss_test:0.01727, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.922, tt:3650.510\n",
      "Ep:122, loss:0.00001, loss_test:0.01732, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.930, tt:3681.403\n",
      "Ep:123, loss:0.00001, loss_test:0.01737, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.965, tt:3715.664\n",
      "Ep:124, loss:0.00001, loss_test:0.01741, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.962, tt:3745.313\n",
      "Ep:125, loss:0.00001, loss_test:0.01745, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.961, tt:3775.133\n",
      "Ep:126, loss:0.00001, loss_test:0.01748, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:29.966, tt:3805.622\n",
      "Ep:127, loss:0.00001, loss_test:0.01754, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.967, tt:3835.809\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.01758, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.972, tt:3866.360\n",
      "Ep:129, loss:0.00001, loss_test:0.01764, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.975, tt:3896.751\n",
      "Ep:130, loss:0.00001, loss_test:0.01766, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.979, tt:3927.186\n",
      "Ep:131, loss:0.00001, loss_test:0.01771, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.986, tt:3958.105\n",
      "Ep:132, loss:0.00001, loss_test:0.01778, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.979, tt:3987.257\n",
      "Ep:133, loss:0.00001, loss_test:0.01784, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.987, tt:4018.220\n",
      "Ep:134, loss:0.00001, loss_test:0.01786, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.991, tt:4048.734\n",
      "Ep:135, loss:0.00001, loss_test:0.01792, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.986, tt:4078.121\n",
      "Ep:136, loss:0.00001, loss_test:0.01794, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.994, tt:4109.183\n",
      "Ep:137, loss:0.00000, loss_test:0.01800, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.991, tt:4138.771\n",
      "Ep:138, loss:0.00000, loss_test:0.01804, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.986, tt:4168.042\n",
      "Ep:139, loss:0.00000, loss_test:0.01809, lr:5.54e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.987, tt:4198.173\n",
      "Ep:140, loss:0.00000, loss_test:0.01813, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.988, tt:4228.240\n",
      "Ep:141, loss:0.00000, loss_test:0.01816, lr:5.43e-02, fs:0.85714 (r=0.818,p=0.900),  time:29.981, tt:4257.247\n",
      "Ep:142, loss:0.00000, loss_test:0.01822, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.971, tt:4285.873\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00000, loss_test:0.01825, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.968, tt:4315.372\n",
      "Ep:144, loss:0.00000, loss_test:0.01831, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.970, tt:4345.583\n",
      "Ep:145, loss:0.00000, loss_test:0.01834, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.967, tt:4375.199\n",
      "Ep:146, loss:0.00000, loss_test:0.01837, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.972, tt:4405.936\n",
      "Ep:147, loss:0.00000, loss_test:0.01841, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.971, tt:4435.776\n",
      "Ep:148, loss:0.00000, loss_test:0.01845, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.966, tt:4464.977\n",
      "Ep:149, loss:0.00000, loss_test:0.01850, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.970, tt:4495.456\n",
      "Ep:150, loss:0.00000, loss_test:0.01856, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.976, tt:4526.331\n",
      "Ep:151, loss:0.00000, loss_test:0.01863, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.985, tt:4557.754\n",
      "Ep:152, loss:0.00000, loss_test:0.01869, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.984, tt:4587.618\n",
      "Ep:153, loss:0.00000, loss_test:0.01874, lr:5.37e-02, fs:0.86170 (r=0.818,p=0.910),  time:29.997, tt:4619.542\n",
      "Ep:154, loss:0.00000, loss_test:0.01878, lr:5.32e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.000, tt:4649.993\n",
      "Ep:155, loss:0.00000, loss_test:0.01882, lr:5.27e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.009, tt:4681.461\n",
      "Ep:156, loss:0.00000, loss_test:0.01888, lr:5.21e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.020, tt:4713.065\n",
      "Ep:157, loss:0.00000, loss_test:0.01892, lr:5.16e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.018, tt:4742.832\n",
      "Ep:158, loss:0.00000, loss_test:0.01895, lr:5.11e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.023, tt:4773.662\n",
      "Ep:159, loss:0.00000, loss_test:0.01900, lr:5.06e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.027, tt:4804.373\n",
      "Ep:160, loss:0.00000, loss_test:0.01903, lr:5.01e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.020, tt:4833.260\n",
      "Ep:161, loss:0.00000, loss_test:0.01909, lr:4.96e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.026, tt:4864.134\n",
      "Ep:162, loss:0.00000, loss_test:0.01914, lr:4.91e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.028, tt:4894.565\n",
      "Ep:163, loss:0.00000, loss_test:0.01918, lr:4.86e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.018, tt:4922.900\n",
      "Ep:164, loss:0.00000, loss_test:0.01921, lr:4.81e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.017, tt:4952.883\n",
      "Ep:165, loss:0.00000, loss_test:0.01924, lr:4.76e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.022, tt:4983.702\n",
      "Ep:166, loss:0.00000, loss_test:0.01929, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.035, tt:5015.909\n",
      "Ep:167, loss:0.00000, loss_test:0.01935, lr:4.67e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.043, tt:5047.258\n",
      "Ep:168, loss:0.00000, loss_test:0.01938, lr:4.62e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.039, tt:5076.649\n",
      "Ep:169, loss:0.00000, loss_test:0.01942, lr:4.57e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.040, tt:5106.864\n",
      "Ep:170, loss:0.00000, loss_test:0.01946, lr:4.53e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.039, tt:5136.691\n",
      "Ep:171, loss:0.00000, loss_test:0.01950, lr:4.48e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.038, tt:5166.554\n",
      "Ep:172, loss:0.00000, loss_test:0.01954, lr:4.44e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.038, tt:5196.495\n",
      "Ep:173, loss:0.00000, loss_test:0.01958, lr:4.39e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.045, tt:5227.786\n",
      "Ep:174, loss:0.00000, loss_test:0.01961, lr:4.35e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.047, tt:5258.265\n",
      "Ep:175, loss:0.00000, loss_test:0.01965, lr:4.31e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.048, tt:5288.384\n",
      "Ep:176, loss:0.00000, loss_test:0.01968, lr:4.26e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.050, tt:5318.782\n",
      "Ep:177, loss:0.00000, loss_test:0.01972, lr:4.22e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.052, tt:5349.173\n",
      "Ep:178, loss:0.00000, loss_test:0.01974, lr:4.18e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.057, tt:5380.255\n",
      "Ep:179, loss:0.00000, loss_test:0.01976, lr:4.14e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.070, tt:5412.538\n",
      "Ep:180, loss:0.00000, loss_test:0.01979, lr:4.10e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.073, tt:5443.285\n",
      "Ep:181, loss:0.00000, loss_test:0.01983, lr:4.05e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.074, tt:5473.432\n",
      "Ep:182, loss:0.00000, loss_test:0.01986, lr:4.01e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.072, tt:5503.200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:183, loss:0.00000, loss_test:0.01990, lr:3.97e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.094, tt:5537.358\n",
      "Ep:184, loss:0.00000, loss_test:0.01994, lr:3.93e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.099, tt:5568.273\n",
      "Ep:185, loss:0.00000, loss_test:0.01997, lr:3.89e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.104, tt:5599.253\n",
      "Ep:186, loss:0.00000, loss_test:0.02001, lr:3.86e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.110, tt:5630.488\n",
      "Ep:187, loss:0.00000, loss_test:0.02005, lr:3.82e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.112, tt:5660.981\n",
      "Ep:188, loss:0.00000, loss_test:0.02007, lr:3.78e-02, fs:0.86170 (r=0.818,p=0.910),  time:30.113, tt:5691.288\n",
      "Ep:189, loss:0.00000, loss_test:0.02011, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.115, tt:5721.904\n",
      "##########Best model found so far##########\n",
      "Ep:190, loss:0.00000, loss_test:0.02015, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.128, tt:5754.507\n",
      "Ep:191, loss:0.00000, loss_test:0.02017, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.133, tt:5785.482\n",
      "Ep:192, loss:0.00000, loss_test:0.02021, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.134, tt:5815.925\n",
      "Ep:193, loss:0.00000, loss_test:0.02025, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.141, tt:5847.435\n",
      "Ep:194, loss:0.00000, loss_test:0.02027, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.143, tt:5877.910\n",
      "Ep:195, loss:0.00000, loss_test:0.02030, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.150, tt:5909.341\n",
      "Ep:196, loss:0.00000, loss_test:0.02033, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.156, tt:5940.723\n",
      "Ep:197, loss:0.00000, loss_test:0.02037, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.156, tt:5970.914\n",
      "Ep:198, loss:0.00000, loss_test:0.02040, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.157, tt:6001.233\n",
      "Ep:199, loss:0.00000, loss_test:0.02043, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.149, tt:6029.728\n",
      "Ep:200, loss:0.00000, loss_test:0.02045, lr:3.74e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.148, tt:6059.674\n",
      "Ep:201, loss:0.00000, loss_test:0.02049, lr:3.70e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.147, tt:6089.773\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13465, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:25.552, tt:25.552\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13247, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:24.410, tt:48.819\n",
      "Ep:2, loss:0.00027, loss_test:0.12851, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:25.090, tt:75.270\n",
      "Ep:3, loss:0.00026, loss_test:0.12280, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:26.132, tt:104.529\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11660, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:26.817, tt:134.087\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11382, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:27.161, tt:162.965\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.11218, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:27.716, tt:194.014\n",
      "Ep:7, loss:0.00021, loss_test:0.10977, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:28.342, tt:226.736\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10778, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:28.688, tt:258.191\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10521, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:28.700, tt:287.001\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10375, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:29.022, tt:319.243\n",
      "Ep:11, loss:0.00019, loss_test:0.10096, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:29.232, tt:350.790\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09987, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:29.347, tt:381.510\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09850, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:29.500, tt:413.000\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09829, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:29.589, tt:443.835\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09667, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:29.596, tt:473.537\n",
      "Ep:16, loss:0.00015, loss_test:0.09539, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:29.737, tt:505.533\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09431, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:29.908, tt:538.344\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09303, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:29.935, tt:568.765\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09141, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:30.001, tt:600.019\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08992, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:30.101, tt:632.112\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08890, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.183, tt:664.032\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08799, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.228, tt:695.242\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08647, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.243, tt:725.837\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.08557, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.275, tt:756.886\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08518, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.327, tt:788.504\n",
      "Ep:26, loss:0.00011, loss_test:0.08363, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.376, tt:820.151\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.08275, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.421, tt:851.784\n",
      "Ep:28, loss:0.00010, loss_test:0.08193, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:30.462, tt:883.390\n",
      "Ep:29, loss:0.00010, loss_test:0.08088, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:30.489, tt:914.662\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.08072, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.501, tt:945.538\n",
      "Ep:31, loss:0.00009, loss_test:0.07942, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.470, tt:975.046\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.07937, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.520, tt:1007.145\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.07902, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.497, tt:1036.892\n",
      "Ep:34, loss:0.00009, loss_test:0.07811, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.520, tt:1068.206\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.07813, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.548, tt:1099.731\n",
      "Ep:36, loss:0.00008, loss_test:0.07774, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.546, tt:1130.186\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.07731, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.588, tt:1162.351\n",
      "Ep:38, loss:0.00008, loss_test:0.07659, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.615, tt:1193.967\n",
      "Ep:39, loss:0.00007, loss_test:0.07636, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.640, tt:1225.604\n",
      "Ep:40, loss:0.00007, loss_test:0.07571, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.638, tt:1256.159\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00007, loss_test:0.07518, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.660, tt:1287.715\n",
      "Ep:42, loss:0.00007, loss_test:0.07472, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.680, tt:1319.234\n",
      "Ep:43, loss:0.00007, loss_test:0.07474, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.680, tt:1349.901\n",
      "Ep:44, loss:0.00007, loss_test:0.07395, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.663, tt:1379.850\n",
      "Ep:45, loss:0.00006, loss_test:0.07415, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.679, tt:1411.213\n",
      "Ep:46, loss:0.00006, loss_test:0.07424, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.684, tt:1442.142\n",
      "Ep:47, loss:0.00006, loss_test:0.07337, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.727, tt:1474.917\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.07403, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.788, tt:1508.599\n",
      "Ep:49, loss:0.00006, loss_test:0.07280, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:30.818, tt:1540.914\n",
      "Ep:50, loss:0.00006, loss_test:0.07326, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:30.831, tt:1572.378\n",
      "Ep:51, loss:0.00006, loss_test:0.07276, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:30.868, tt:1605.117\n",
      "Ep:52, loss:0.00005, loss_test:0.07260, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:30.886, tt:1636.980\n",
      "Ep:53, loss:0.00005, loss_test:0.07297, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.909, tt:1669.096\n",
      "Ep:54, loss:0.00005, loss_test:0.07225, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:30.954, tt:1702.467\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.07282, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.948, tt:1733.068\n",
      "Ep:56, loss:0.00005, loss_test:0.07185, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:30.948, tt:1764.058\n",
      "Ep:57, loss:0.00005, loss_test:0.07240, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.949, tt:1795.070\n",
      "Ep:58, loss:0.00005, loss_test:0.07268, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.960, tt:1826.633\n",
      "Ep:59, loss:0.00005, loss_test:0.07180, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.988, tt:1859.268\n",
      "Ep:60, loss:0.00005, loss_test:0.07192, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:31.001, tt:1891.066\n",
      "Ep:61, loss:0.00004, loss_test:0.07209, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:30.980, tt:1920.769\n",
      "Ep:62, loss:0.00004, loss_test:0.07214, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.003, tt:1953.220\n",
      "Ep:63, loss:0.00004, loss_test:0.07204, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:31.014, tt:1984.908\n",
      "Ep:64, loss:0.00004, loss_test:0.07182, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:31.040, tt:2017.582\n",
      "Ep:65, loss:0.00004, loss_test:0.07197, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.047, tt:2049.092\n",
      "Ep:66, loss:0.00004, loss_test:0.07173, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.051, tt:2080.424\n",
      "Ep:67, loss:0.00004, loss_test:0.07134, lr:9.80e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.046, tt:2111.119\n",
      "Ep:68, loss:0.00004, loss_test:0.07231, lr:9.70e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.043, tt:2141.969\n",
      "Ep:69, loss:0.00004, loss_test:0.07232, lr:9.61e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.050, tt:2173.472\n",
      "Ep:70, loss:0.00004, loss_test:0.07103, lr:9.51e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.088, tt:2207.213\n",
      "Ep:71, loss:0.00004, loss_test:0.07160, lr:9.41e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.092, tt:2238.636\n",
      "Ep:72, loss:0.00003, loss_test:0.07217, lr:9.32e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.124, tt:2272.034\n",
      "Ep:73, loss:0.00003, loss_test:0.07104, lr:9.23e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.117, tt:2302.673\n",
      "Ep:74, loss:0.00003, loss_test:0.07105, lr:9.14e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.119, tt:2333.920\n",
      "Ep:75, loss:0.00003, loss_test:0.07142, lr:9.04e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.132, tt:2366.062\n",
      "Ep:76, loss:0.00003, loss_test:0.07078, lr:8.95e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.141, tt:2397.821\n",
      "Ep:77, loss:0.00003, loss_test:0.07094, lr:8.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.153, tt:2429.904\n",
      "Ep:78, loss:0.00003, loss_test:0.07085, lr:8.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.142, tt:2460.215\n",
      "Ep:79, loss:0.00003, loss_test:0.07097, lr:8.69e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.153, tt:2492.227\n",
      "Ep:80, loss:0.00003, loss_test:0.07064, lr:8.60e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.155, tt:2523.562\n",
      "Ep:81, loss:0.00003, loss_test:0.07085, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.153, tt:2554.549\n",
      "Ep:82, loss:0.00003, loss_test:0.07113, lr:8.43e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.145, tt:2585.021\n",
      "Ep:83, loss:0.00003, loss_test:0.07045, lr:8.35e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.159, tt:2617.344\n",
      "Ep:84, loss:0.00003, loss_test:0.07093, lr:8.26e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.171, tt:2649.549\n",
      "Ep:85, loss:0.00003, loss_test:0.07103, lr:8.18e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.191, tt:2682.396\n",
      "Ep:86, loss:0.00003, loss_test:0.07027, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.194, tt:2713.880\n",
      "Ep:87, loss:0.00003, loss_test:0.07080, lr:8.02e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.206, tt:2746.094\n",
      "Ep:88, loss:0.00003, loss_test:0.07168, lr:7.94e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.222, tt:2778.733\n",
      "Ep:89, loss:0.00003, loss_test:0.07075, lr:7.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.218, tt:2809.636\n",
      "Ep:90, loss:0.00002, loss_test:0.07056, lr:7.78e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.227, tt:2841.676\n",
      "Ep:91, loss:0.00002, loss_test:0.07133, lr:7.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.232, tt:2873.318\n",
      "Ep:92, loss:0.00002, loss_test:0.07071, lr:7.62e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.230, tt:2904.430\n",
      "Ep:93, loss:0.00002, loss_test:0.07088, lr:7.55e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.232, tt:2935.793\n",
      "Ep:94, loss:0.00002, loss_test:0.07065, lr:7.47e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.241, tt:2967.857\n",
      "Ep:95, loss:0.00002, loss_test:0.07091, lr:7.40e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.251, tt:3000.061\n",
      "Ep:96, loss:0.00002, loss_test:0.07074, lr:7.32e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.250, tt:3031.203\n",
      "Ep:97, loss:0.00002, loss_test:0.07065, lr:7.25e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.249, tt:3062.439\n",
      "Ep:98, loss:0.00002, loss_test:0.07130, lr:7.18e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.251, tt:3093.830\n",
      "Ep:99, loss:0.00002, loss_test:0.07082, lr:7.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.260, tt:3125.989\n",
      "Ep:100, loss:0.00002, loss_test:0.07064, lr:7.03e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.254, tt:3156.697\n",
      "Ep:101, loss:0.00002, loss_test:0.07101, lr:6.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.248, tt:3187.247\n",
      "Ep:102, loss:0.00002, loss_test:0.07126, lr:6.89e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.251, tt:3218.811\n",
      "Ep:103, loss:0.00002, loss_test:0.07120, lr:6.83e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.253, tt:3250.321\n",
      "Ep:104, loss:0.00002, loss_test:0.07108, lr:6.76e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.256, tt:3281.928\n",
      "Ep:105, loss:0.00002, loss_test:0.07137, lr:6.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.245, tt:3311.952\n",
      "Ep:106, loss:0.00002, loss_test:0.07134, lr:6.62e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.260, tt:3344.811\n",
      "Ep:107, loss:0.00002, loss_test:0.07082, lr:6.56e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.270, tt:3377.109\n",
      "Ep:108, loss:0.00002, loss_test:0.07125, lr:6.49e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.259, tt:3407.260\n",
      "Ep:109, loss:0.00002, loss_test:0.07138, lr:6.43e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.255, tt:3438.046\n",
      "Ep:110, loss:0.00002, loss_test:0.07072, lr:6.36e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.255, tt:3469.345\n",
      "Ep:111, loss:0.00002, loss_test:0.07145, lr:6.30e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.249, tt:3499.892\n",
      "Ep:112, loss:0.00002, loss_test:0.07135, lr:6.24e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.237, tt:3529.761\n",
      "Ep:113, loss:0.00002, loss_test:0.07103, lr:6.17e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.232, tt:3560.424\n",
      "Ep:114, loss:0.00002, loss_test:0.07110, lr:6.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.217, tt:3589.979\n",
      "Ep:115, loss:0.00002, loss_test:0.07155, lr:6.05e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.219, tt:3621.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00002, loss_test:0.07112, lr:5.99e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.224, tt:3653.216\n",
      "Ep:117, loss:0.00002, loss_test:0.07145, lr:5.93e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.225, tt:3684.588\n",
      "Ep:118, loss:0.00002, loss_test:0.07116, lr:5.87e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.228, tt:3716.096\n",
      "Ep:119, loss:0.00002, loss_test:0.07118, lr:5.81e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.232, tt:3747.896\n",
      "Ep:120, loss:0.00002, loss_test:0.07113, lr:5.75e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.239, tt:3779.964\n",
      "Ep:121, loss:0.00002, loss_test:0.07145, lr:5.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.242, tt:3811.564\n",
      "Ep:122, loss:0.00002, loss_test:0.07139, lr:5.64e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.238, tt:3842.216\n",
      "Ep:123, loss:0.00002, loss_test:0.07122, lr:5.58e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.221, tt:3871.389\n",
      "Ep:124, loss:0.00002, loss_test:0.07121, lr:5.53e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.217, tt:3902.144\n",
      "Ep:125, loss:0.00002, loss_test:0.07113, lr:5.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.215, tt:3933.047\n",
      "Ep:126, loss:0.00002, loss_test:0.07131, lr:5.42e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.221, tt:3965.003\n",
      "Ep:127, loss:0.00002, loss_test:0.07126, lr:5.36e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.216, tt:3995.626\n",
      "Ep:128, loss:0.00002, loss_test:0.07130, lr:5.31e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.215, tt:4026.794\n",
      "Ep:129, loss:0.00002, loss_test:0.07123, lr:5.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.216, tt:4058.105\n",
      "Ep:130, loss:0.00002, loss_test:0.07136, lr:5.20e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.224, tt:4090.321\n",
      "Ep:131, loss:0.00002, loss_test:0.07137, lr:5.15e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.230, tt:4122.405\n",
      "Ep:132, loss:0.00002, loss_test:0.07162, lr:5.10e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.230, tt:4153.542\n",
      "Ep:133, loss:0.00001, loss_test:0.07160, lr:5.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.237, tt:4185.784\n",
      "Ep:134, loss:0.00001, loss_test:0.07173, lr:5.00e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.233, tt:4216.431\n",
      "Ep:135, loss:0.00001, loss_test:0.07179, lr:4.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.228, tt:4247.026\n",
      "Ep:136, loss:0.00001, loss_test:0.07131, lr:4.90e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.236, tt:4279.305\n",
      "Ep:137, loss:0.00001, loss_test:0.07150, lr:4.85e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.247, tt:4312.143\n",
      "Ep:138, loss:0.00001, loss_test:0.07190, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.264, tt:4345.634\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00001, loss_test:0.07176, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.276, tt:4378.691\n",
      "Ep:140, loss:0.00001, loss_test:0.07162, lr:4.80e-03, fs:0.89503 (r=0.818,p=0.988),  time:31.288, tt:4411.594\n",
      "Ep:141, loss:0.00001, loss_test:0.07187, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.290, tt:4443.134\n",
      "Ep:142, loss:0.00001, loss_test:0.07180, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.300, tt:4475.865\n",
      "Ep:143, loss:0.00001, loss_test:0.07152, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.301, tt:4507.305\n",
      "Ep:144, loss:0.00001, loss_test:0.07182, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.293, tt:4537.436\n",
      "Ep:145, loss:0.00001, loss_test:0.07179, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.287, tt:4567.899\n",
      "Ep:146, loss:0.00001, loss_test:0.07180, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.287, tt:4599.185\n",
      "Ep:147, loss:0.00001, loss_test:0.07184, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.282, tt:4629.751\n",
      "Ep:148, loss:0.00001, loss_test:0.07166, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.287, tt:4661.760\n",
      "Ep:149, loss:0.00001, loss_test:0.07210, lr:4.80e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.288, tt:4693.215\n",
      "Ep:150, loss:0.00001, loss_test:0.07189, lr:4.75e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.288, tt:4724.474\n",
      "Ep:151, loss:0.00001, loss_test:0.07185, lr:4.71e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.290, tt:4756.123\n",
      "Ep:152, loss:0.00001, loss_test:0.07246, lr:4.66e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.286, tt:4786.741\n",
      "Ep:153, loss:0.00001, loss_test:0.07239, lr:4.61e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.301, tt:4820.296\n",
      "Ep:154, loss:0.00001, loss_test:0.07192, lr:4.57e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.303, tt:4851.991\n",
      "Ep:155, loss:0.00001, loss_test:0.07180, lr:4.52e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.306, tt:4883.761\n",
      "Ep:156, loss:0.00001, loss_test:0.07211, lr:4.48e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.316, tt:4916.621\n",
      "Ep:157, loss:0.00001, loss_test:0.07227, lr:4.43e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.324, tt:4949.260\n",
      "Ep:158, loss:0.00001, loss_test:0.07215, lr:4.39e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.322, tt:4980.139\n",
      "Ep:159, loss:0.00001, loss_test:0.07203, lr:4.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.326, tt:5012.198\n",
      "Ep:160, loss:0.00001, loss_test:0.07224, lr:4.30e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.332, tt:5044.389\n",
      "Ep:161, loss:0.00001, loss_test:0.07241, lr:4.26e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.335, tt:5076.268\n",
      "Ep:162, loss:0.00001, loss_test:0.07216, lr:4.21e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.337, tt:5107.870\n",
      "Ep:163, loss:0.00001, loss_test:0.07213, lr:4.17e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.340, tt:5139.793\n",
      "Ep:164, loss:0.00001, loss_test:0.07234, lr:4.13e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.350, tt:5172.703\n",
      "Ep:165, loss:0.00001, loss_test:0.07264, lr:4.09e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.354, tt:5204.782\n",
      "Ep:166, loss:0.00001, loss_test:0.07254, lr:4.05e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.360, tt:5237.101\n",
      "Ep:167, loss:0.00001, loss_test:0.07229, lr:4.01e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.360, tt:5268.496\n",
      "Ep:168, loss:0.00001, loss_test:0.07266, lr:3.97e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.353, tt:5298.646\n",
      "Ep:169, loss:0.00001, loss_test:0.07290, lr:3.93e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.350, tt:5329.429\n",
      "Ep:170, loss:0.00001, loss_test:0.07260, lr:3.89e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.343, tt:5359.705\n",
      "Ep:171, loss:0.00001, loss_test:0.07244, lr:3.85e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.345, tt:5391.304\n",
      "Ep:172, loss:0.00001, loss_test:0.07241, lr:3.81e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.343, tt:5422.407\n",
      "Ep:173, loss:0.00001, loss_test:0.07278, lr:3.77e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.342, tt:5453.444\n",
      "Ep:174, loss:0.00001, loss_test:0.07264, lr:3.73e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.343, tt:5485.055\n",
      "Ep:175, loss:0.00001, loss_test:0.07258, lr:3.70e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.345, tt:5516.681\n",
      "Ep:176, loss:0.00001, loss_test:0.07253, lr:3.66e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.342, tt:5547.596\n",
      "Ep:177, loss:0.00001, loss_test:0.07245, lr:3.62e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.346, tt:5579.676\n",
      "Ep:178, loss:0.00001, loss_test:0.07253, lr:3.59e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.344, tt:5610.560\n",
      "Ep:179, loss:0.00001, loss_test:0.07278, lr:3.55e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.336, tt:5640.428\n",
      "Ep:180, loss:0.00001, loss_test:0.07273, lr:3.52e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.335, tt:5671.604\n",
      "Ep:181, loss:0.00001, loss_test:0.07250, lr:3.48e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.327, tt:5701.519\n",
      "Ep:182, loss:0.00001, loss_test:0.07271, lr:3.45e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.329, tt:5733.146\n",
      "Ep:183, loss:0.00001, loss_test:0.07258, lr:3.41e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.324, tt:5763.565\n",
      "Ep:184, loss:0.00001, loss_test:0.07256, lr:3.38e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.328, tt:5795.718\n",
      "Ep:185, loss:0.00001, loss_test:0.07263, lr:3.34e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.337, tt:5828.743\n",
      "Ep:186, loss:0.00001, loss_test:0.07254, lr:3.31e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.337, tt:5859.938\n",
      "Ep:187, loss:0.00001, loss_test:0.07271, lr:3.28e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.343, tt:5892.441\n",
      "Ep:188, loss:0.00001, loss_test:0.07280, lr:3.24e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.347, tt:5924.584\n",
      "Ep:189, loss:0.00001, loss_test:0.07260, lr:3.21e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.346, tt:5955.658\n",
      "Ep:190, loss:0.00001, loss_test:0.07265, lr:3.18e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.353, tt:5988.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00001, loss_test:0.07274, lr:3.15e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.355, tt:6020.250\n",
      "Ep:192, loss:0.00001, loss_test:0.07243, lr:3.12e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.349, tt:6050.365\n",
      "Ep:193, loss:0.00001, loss_test:0.07265, lr:3.09e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.346, tt:6081.108\n",
      "Ep:194, loss:0.00001, loss_test:0.07273, lr:3.05e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.347, tt:6112.687\n",
      "Ep:195, loss:0.00001, loss_test:0.07256, lr:3.02e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.342, tt:6143.081\n",
      "Ep:196, loss:0.00001, loss_test:0.07266, lr:2.99e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.340, tt:6173.920\n",
      "Ep:197, loss:0.00001, loss_test:0.07264, lr:2.96e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.345, tt:6206.397\n",
      "Ep:198, loss:0.00001, loss_test:0.07263, lr:2.93e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.346, tt:6237.848\n",
      "Ep:199, loss:0.00001, loss_test:0.07267, lr:2.90e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.342, tt:6268.435\n",
      "Ep:200, loss:0.00001, loss_test:0.07266, lr:2.88e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.342, tt:6299.731\n",
      "Ep:201, loss:0.00001, loss_test:0.07287, lr:2.85e-03, fs:0.90000 (r=0.818,p=1.000),  time:31.333, tt:6329.222\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02049, lr:6.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:21.556, tt:21.556\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02260, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.641, tt:43.282\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02470, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.559, tt:61.676\n",
      "Ep:3, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.778, tt:83.111\n",
      "Ep:4, loss:0.00005, loss_test:0.02481, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.506, tt:102.533\n",
      "Ep:5, loss:0.00005, loss_test:0.02396, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.701, tt:124.207\n",
      "Ep:6, loss:0.00005, loss_test:0.02286, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:20.955, tt:146.682\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02183, lr:6.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:21.456, tt:171.647\n",
      "Ep:8, loss:0.00004, loss_test:0.02118, lr:6.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:21.843, tt:196.586\n",
      "Ep:9, loss:0.00004, loss_test:0.02113, lr:6.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:22.112, tt:221.117\n",
      "Ep:10, loss:0.00004, loss_test:0.02141, lr:6.00e-02, fs:0.63636 (r=0.778,p=0.538),  time:22.283, tt:245.109\n",
      "Ep:11, loss:0.00004, loss_test:0.02144, lr:6.00e-02, fs:0.63071 (r=0.768,p=0.535),  time:22.451, tt:269.416\n",
      "Ep:12, loss:0.00004, loss_test:0.02109, lr:6.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:22.544, tt:293.067\n",
      "Ep:13, loss:0.00004, loss_test:0.02060, lr:6.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:22.721, tt:318.099\n",
      "Ep:14, loss:0.00004, loss_test:0.02028, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:22.855, tt:342.831\n",
      "Ep:15, loss:0.00004, loss_test:0.02004, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:23.021, tt:368.339\n",
      "Ep:16, loss:0.00004, loss_test:0.01978, lr:6.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:23.098, tt:392.661\n",
      "Ep:17, loss:0.00003, loss_test:0.01950, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:23.263, tt:418.738\n",
      "Ep:18, loss:0.00003, loss_test:0.01925, lr:5.94e-02, fs:0.66932 (r=0.848,p=0.553),  time:23.413, tt:444.837\n",
      "Ep:19, loss:0.00003, loss_test:0.01903, lr:5.88e-02, fs:0.67200 (r=0.848,p=0.556),  time:23.530, tt:470.596\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01884, lr:5.88e-02, fs:0.67755 (r=0.838,p=0.568),  time:23.696, tt:497.616\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01859, lr:5.88e-02, fs:0.68595 (r=0.838,p=0.580),  time:23.776, tt:523.062\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01824, lr:5.88e-02, fs:0.68595 (r=0.838,p=0.580),  time:23.828, tt:548.049\n",
      "Ep:23, loss:0.00003, loss_test:0.01790, lr:5.88e-02, fs:0.68880 (r=0.838,p=0.585),  time:23.875, tt:572.990\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01759, lr:5.88e-02, fs:0.69167 (r=0.838,p=0.589),  time:23.908, tt:597.692\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01737, lr:5.88e-02, fs:0.69959 (r=0.859,p=0.590),  time:23.931, tt:622.197\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01720, lr:5.88e-02, fs:0.69167 (r=0.838,p=0.589),  time:23.984, tt:647.569\n",
      "Ep:27, loss:0.00003, loss_test:0.01708, lr:5.88e-02, fs:0.69167 (r=0.838,p=0.589),  time:24.054, tt:673.505\n",
      "Ep:28, loss:0.00003, loss_test:0.01698, lr:5.88e-02, fs:0.69492 (r=0.828,p=0.599),  time:24.084, tt:698.432\n",
      "Ep:29, loss:0.00003, loss_test:0.01690, lr:5.88e-02, fs:0.70042 (r=0.838,p=0.601),  time:24.097, tt:722.912\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01676, lr:5.88e-02, fs:0.71730 (r=0.859,p=0.616),  time:24.107, tt:747.331\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01663, lr:5.88e-02, fs:0.72034 (r=0.859,p=0.620),  time:24.150, tt:772.811\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01654, lr:5.88e-02, fs:0.71489 (r=0.848,p=0.618),  time:24.196, tt:798.482\n",
      "Ep:33, loss:0.00002, loss_test:0.01645, lr:5.88e-02, fs:0.71245 (r=0.838,p=0.619),  time:24.255, tt:824.672\n",
      "Ep:34, loss:0.00002, loss_test:0.01634, lr:5.88e-02, fs:0.71552 (r=0.838,p=0.624),  time:24.291, tt:850.193\n",
      "Ep:35, loss:0.00002, loss_test:0.01624, lr:5.88e-02, fs:0.71552 (r=0.838,p=0.624),  time:24.295, tt:874.629\n",
      "Ep:36, loss:0.00002, loss_test:0.01610, lr:5.88e-02, fs:0.72174 (r=0.838,p=0.634),  time:24.348, tt:900.869\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01601, lr:5.88e-02, fs:0.72727 (r=0.848,p=0.636),  time:24.399, tt:927.151\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01596, lr:5.88e-02, fs:0.73043 (r=0.848,p=0.641),  time:24.432, tt:952.860\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01589, lr:5.88e-02, fs:0.74667 (r=0.848,p=0.667),  time:24.470, tt:978.810\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01582, lr:5.88e-02, fs:0.74667 (r=0.848,p=0.667),  time:24.528, tt:1005.651\n",
      "Ep:41, loss:0.00002, loss_test:0.01572, lr:5.88e-02, fs:0.75771 (r=0.869,p=0.672),  time:24.587, tt:1032.675\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01566, lr:5.88e-02, fs:0.75771 (r=0.869,p=0.672),  time:24.608, tt:1058.132\n",
      "Ep:43, loss:0.00002, loss_test:0.01560, lr:5.88e-02, fs:0.76316 (r=0.879,p=0.674),  time:24.620, tt:1083.297\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01557, lr:5.88e-02, fs:0.77533 (r=0.889,p=0.688),  time:24.657, tt:1109.577\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01555, lr:5.88e-02, fs:0.78222 (r=0.889,p=0.698),  time:24.690, tt:1135.731\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01552, lr:5.88e-02, fs:0.78571 (r=0.889,p=0.704),  time:24.720, tt:1161.843\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01544, lr:5.88e-02, fs:0.78027 (r=0.879,p=0.702),  time:24.773, tt:1189.107\n",
      "Ep:48, loss:0.00002, loss_test:0.01539, lr:5.88e-02, fs:0.78571 (r=0.889,p=0.704),  time:24.786, tt:1214.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00002, loss_test:0.01536, lr:5.88e-02, fs:0.78924 (r=0.889,p=0.710),  time:24.784, tt:1239.178\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01533, lr:5.88e-02, fs:0.79279 (r=0.889,p=0.715),  time:24.781, tt:1263.855\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01531, lr:5.88e-02, fs:0.79821 (r=0.899,p=0.718),  time:24.806, tt:1289.906\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01528, lr:5.88e-02, fs:0.80543 (r=0.899,p=0.730),  time:24.861, tt:1317.652\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01526, lr:5.88e-02, fs:0.80543 (r=0.899,p=0.730),  time:24.901, tt:1344.640\n",
      "Ep:54, loss:0.00002, loss_test:0.01527, lr:5.88e-02, fs:0.80909 (r=0.899,p=0.736),  time:24.932, tt:1371.256\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01526, lr:5.88e-02, fs:0.80909 (r=0.899,p=0.736),  time:25.006, tt:1400.324\n",
      "Ep:56, loss:0.00002, loss_test:0.01524, lr:5.88e-02, fs:0.80909 (r=0.899,p=0.736),  time:25.022, tt:1426.274\n",
      "Ep:57, loss:0.00002, loss_test:0.01523, lr:5.88e-02, fs:0.81651 (r=0.899,p=0.748),  time:25.045, tt:1452.605\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01525, lr:5.88e-02, fs:0.81651 (r=0.899,p=0.748),  time:25.070, tt:1479.152\n",
      "Ep:59, loss:0.00002, loss_test:0.01527, lr:5.88e-02, fs:0.81651 (r=0.899,p=0.748),  time:25.076, tt:1504.575\n",
      "Ep:60, loss:0.00002, loss_test:0.01531, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:25.085, tt:1530.213\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01531, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:25.118, tt:1557.333\n",
      "Ep:62, loss:0.00001, loss_test:0.01529, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:25.135, tt:1583.510\n",
      "Ep:63, loss:0.00001, loss_test:0.01531, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:25.136, tt:1608.688\n",
      "Ep:64, loss:0.00001, loss_test:0.01534, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:25.145, tt:1634.424\n",
      "Ep:65, loss:0.00001, loss_test:0.01533, lr:5.88e-02, fs:0.81860 (r=0.889,p=0.759),  time:25.135, tt:1658.894\n",
      "Ep:66, loss:0.00001, loss_test:0.01534, lr:5.88e-02, fs:0.81860 (r=0.889,p=0.759),  time:25.130, tt:1683.719\n",
      "Ep:67, loss:0.00001, loss_test:0.01536, lr:5.88e-02, fs:0.81860 (r=0.889,p=0.759),  time:25.132, tt:1708.994\n",
      "Ep:68, loss:0.00001, loss_test:0.01541, lr:5.88e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.149, tt:1735.302\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01544, lr:5.88e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.140, tt:1759.771\n",
      "Ep:70, loss:0.00001, loss_test:0.01548, lr:5.88e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.131, tt:1784.322\n",
      "Ep:71, loss:0.00001, loss_test:0.01554, lr:5.88e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.130, tt:1809.390\n",
      "Ep:72, loss:0.00001, loss_test:0.01554, lr:5.88e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.141, tt:1835.272\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01556, lr:5.88e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.147, tt:1860.903\n",
      "Ep:74, loss:0.00001, loss_test:0.01559, lr:5.88e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.170, tt:1887.746\n",
      "Ep:75, loss:0.00001, loss_test:0.01568, lr:5.88e-02, fs:0.83412 (r=0.889,p=0.786),  time:25.176, tt:1913.389\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01574, lr:5.88e-02, fs:0.84615 (r=0.889,p=0.807),  time:25.168, tt:1937.966\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01577, lr:5.88e-02, fs:0.84615 (r=0.889,p=0.807),  time:25.183, tt:1964.304\n",
      "Ep:78, loss:0.00001, loss_test:0.01584, lr:5.88e-02, fs:0.83495 (r=0.869,p=0.804),  time:25.193, tt:1990.210\n",
      "Ep:79, loss:0.00001, loss_test:0.01589, lr:5.88e-02, fs:0.83495 (r=0.869,p=0.804),  time:25.205, tt:2016.437\n",
      "Ep:80, loss:0.00001, loss_test:0.01594, lr:5.88e-02, fs:0.83902 (r=0.869,p=0.811),  time:25.219, tt:2042.765\n",
      "Ep:81, loss:0.00001, loss_test:0.01593, lr:5.88e-02, fs:0.84314 (r=0.869,p=0.819),  time:25.240, tt:2069.692\n",
      "Ep:82, loss:0.00001, loss_test:0.01597, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:25.229, tt:2094.016\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01600, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:25.237, tt:2119.942\n",
      "Ep:84, loss:0.00001, loss_test:0.01606, lr:5.88e-02, fs:0.85149 (r=0.869,p=0.835),  time:25.238, tt:2145.244\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01607, lr:5.88e-02, fs:0.85714 (r=0.879,p=0.837),  time:25.250, tt:2171.539\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01612, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:25.253, tt:2197.017\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01619, lr:5.88e-02, fs:0.85572 (r=0.869,p=0.843),  time:25.254, tt:2222.342\n",
      "Ep:88, loss:0.00001, loss_test:0.01626, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:25.261, tt:2248.246\n",
      "Ep:89, loss:0.00001, loss_test:0.01631, lr:5.88e-02, fs:0.85427 (r=0.859,p=0.850),  time:25.264, tt:2273.753\n",
      "Ep:90, loss:0.00001, loss_test:0.01635, lr:5.88e-02, fs:0.85279 (r=0.848,p=0.857),  time:25.263, tt:2298.932\n",
      "Ep:91, loss:0.00001, loss_test:0.01636, lr:5.88e-02, fs:0.85128 (r=0.838,p=0.865),  time:25.262, tt:2324.071\n",
      "Ep:92, loss:0.00001, loss_test:0.01639, lr:5.88e-02, fs:0.85128 (r=0.838,p=0.865),  time:25.256, tt:2348.839\n",
      "Ep:93, loss:0.00001, loss_test:0.01644, lr:5.88e-02, fs:0.85567 (r=0.838,p=0.874),  time:25.256, tt:2374.106\n",
      "Ep:94, loss:0.00001, loss_test:0.01651, lr:5.88e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.245, tt:2398.240\n",
      "Ep:95, loss:0.00001, loss_test:0.01657, lr:5.88e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.255, tt:2424.495\n",
      "Ep:96, loss:0.00001, loss_test:0.01664, lr:5.88e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.249, tt:2449.178\n",
      "Ep:97, loss:0.00001, loss_test:0.01666, lr:5.88e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.258, tt:2475.285\n",
      "Ep:98, loss:0.00001, loss_test:0.01672, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:25.265, tt:2501.272\n",
      "Ep:99, loss:0.00001, loss_test:0.01681, lr:5.76e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.274, tt:2527.392\n",
      "Ep:100, loss:0.00001, loss_test:0.01688, lr:5.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.277, tt:2552.936\n",
      "Ep:101, loss:0.00001, loss_test:0.01693, lr:5.65e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.270, tt:2577.575\n",
      "Ep:102, loss:0.00001, loss_test:0.01694, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.269, tt:2602.718\n",
      "Ep:103, loss:0.00001, loss_test:0.01694, lr:5.54e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.274, tt:2628.501\n",
      "Ep:104, loss:0.00001, loss_test:0.01704, lr:5.48e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.284, tt:2654.770\n",
      "Ep:105, loss:0.00001, loss_test:0.01713, lr:5.43e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.283, tt:2679.949\n",
      "Ep:106, loss:0.00001, loss_test:0.01721, lr:5.37e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.281, tt:2705.038\n",
      "Ep:107, loss:0.00001, loss_test:0.01724, lr:5.32e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.313, tt:2733.806\n",
      "Ep:108, loss:0.00001, loss_test:0.01725, lr:5.27e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.323, tt:2760.236\n",
      "Ep:109, loss:0.00001, loss_test:0.01729, lr:5.21e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.332, tt:2786.484\n",
      "Ep:110, loss:0.00001, loss_test:0.01736, lr:5.16e-02, fs:0.85263 (r=0.818,p=0.890),  time:25.336, tt:2812.350\n",
      "Ep:111, loss:0.00001, loss_test:0.01743, lr:5.11e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.345, tt:2838.605\n",
      "Ep:112, loss:0.00001, loss_test:0.01753, lr:5.06e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.356, tt:2865.223\n",
      "Ep:113, loss:0.00001, loss_test:0.01755, lr:5.01e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.360, tt:2891.050\n",
      "Ep:114, loss:0.00001, loss_test:0.01758, lr:4.96e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.365, tt:2917.012\n",
      "Ep:115, loss:0.00001, loss_test:0.01761, lr:4.91e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.375, tt:2943.442\n",
      "Ep:116, loss:0.00001, loss_test:0.01765, lr:4.86e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.381, tt:2969.610\n",
      "Ep:117, loss:0.00001, loss_test:0.01770, lr:4.81e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.383, tt:2995.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:118, loss:0.00001, loss_test:0.01776, lr:4.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.394, tt:3021.896\n",
      "Ep:119, loss:0.00001, loss_test:0.01780, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.396, tt:3047.563\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.01788, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.404, tt:3073.892\n",
      "Ep:121, loss:0.00001, loss_test:0.01791, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.404, tt:3099.332\n",
      "Ep:122, loss:0.00001, loss_test:0.01801, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.409, tt:3125.282\n",
      "Ep:123, loss:0.00001, loss_test:0.01800, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.410, tt:3150.852\n",
      "Ep:124, loss:0.00001, loss_test:0.01804, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.424, tt:3178.046\n",
      "Ep:125, loss:0.00001, loss_test:0.01809, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.427, tt:3203.744\n",
      "Ep:126, loss:0.00001, loss_test:0.01814, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.434, tt:3230.122\n",
      "Ep:127, loss:0.00001, loss_test:0.01820, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.438, tt:3256.085\n",
      "Ep:128, loss:0.00001, loss_test:0.01824, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.442, tt:3281.981\n",
      "Ep:129, loss:0.00001, loss_test:0.01832, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.446, tt:3308.017\n",
      "Ep:130, loss:0.00001, loss_test:0.01838, lr:4.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.451, tt:3334.052\n",
      "Ep:131, loss:0.00001, loss_test:0.01840, lr:4.67e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.456, tt:3360.214\n",
      "Ep:132, loss:0.00001, loss_test:0.01847, lr:4.62e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.453, tt:3385.284\n",
      "Ep:133, loss:0.00001, loss_test:0.01854, lr:4.57e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.469, tt:3412.895\n",
      "Ep:134, loss:0.00001, loss_test:0.01856, lr:4.53e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.476, tt:3439.205\n",
      "Ep:135, loss:0.00001, loss_test:0.01859, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.485, tt:3465.956\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.01863, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.486, tt:3491.629\n",
      "Ep:137, loss:0.00001, loss_test:0.01871, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.489, tt:3517.488\n",
      "Ep:138, loss:0.00001, loss_test:0.01878, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.497, tt:3544.039\n",
      "Ep:139, loss:0.00001, loss_test:0.01879, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.499, tt:3569.811\n",
      "Ep:140, loss:0.00001, loss_test:0.01885, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.501, tt:3595.698\n",
      "Ep:141, loss:0.00001, loss_test:0.01889, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.491, tt:3619.657\n",
      "Ep:142, loss:0.00001, loss_test:0.01894, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.488, tt:3644.735\n",
      "Ep:143, loss:0.00001, loss_test:0.01898, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.487, tt:3670.110\n",
      "Ep:144, loss:0.00001, loss_test:0.01901, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.489, tt:3695.881\n",
      "Ep:145, loss:0.00001, loss_test:0.01907, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.488, tt:3721.259\n",
      "Ep:146, loss:0.00001, loss_test:0.01910, lr:4.48e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.492, tt:3747.353\n",
      "Ep:147, loss:0.00001, loss_test:0.01918, lr:4.44e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.492, tt:3772.881\n",
      "Ep:148, loss:0.00001, loss_test:0.01927, lr:4.39e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.496, tt:3798.877\n",
      "Ep:149, loss:0.00001, loss_test:0.01933, lr:4.35e-02, fs:0.86022 (r=0.808,p=0.920),  time:25.492, tt:3823.728\n",
      "Ep:150, loss:0.00001, loss_test:0.01932, lr:4.31e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.500, tt:3850.530\n",
      "Ep:151, loss:0.00000, loss_test:0.01932, lr:4.26e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.503, tt:3876.463\n",
      "Ep:152, loss:0.00000, loss_test:0.01936, lr:4.22e-02, fs:0.86170 (r=0.818,p=0.910),  time:25.506, tt:3902.481\n",
      "Ep:153, loss:0.00000, loss_test:0.01946, lr:4.18e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.507, tt:3928.024\n",
      "Ep:154, loss:0.00000, loss_test:0.01955, lr:4.14e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.512, tt:3954.382\n",
      "Ep:155, loss:0.00000, loss_test:0.01957, lr:4.10e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.523, tt:3981.624\n",
      "Ep:156, loss:0.00000, loss_test:0.01960, lr:4.05e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.532, tt:4008.536\n",
      "Ep:157, loss:0.00000, loss_test:0.01960, lr:4.01e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.541, tt:4035.435\n",
      "Ep:158, loss:0.00000, loss_test:0.01964, lr:3.97e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.550, tt:4062.377\n",
      "Ep:159, loss:0.00000, loss_test:0.01969, lr:3.93e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.548, tt:4087.704\n",
      "Ep:160, loss:0.00000, loss_test:0.01976, lr:3.89e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.548, tt:4113.256\n",
      "Ep:161, loss:0.00000, loss_test:0.01983, lr:3.86e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.547, tt:4138.567\n",
      "Ep:162, loss:0.00000, loss_test:0.01986, lr:3.82e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.547, tt:4164.147\n",
      "Ep:163, loss:0.00000, loss_test:0.01986, lr:3.78e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.548, tt:4189.855\n",
      "Ep:164, loss:0.00000, loss_test:0.01990, lr:3.74e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.541, tt:4214.233\n",
      "Ep:165, loss:0.00000, loss_test:0.01994, lr:3.70e-02, fs:0.84946 (r=0.798,p=0.908),  time:25.539, tt:4239.515\n",
      "Ep:166, loss:0.00000, loss_test:0.01998, lr:3.67e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.542, tt:4265.469\n",
      "Ep:167, loss:0.00000, loss_test:0.02002, lr:3.63e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.543, tt:4291.260\n",
      "Ep:168, loss:0.00000, loss_test:0.02005, lr:3.59e-02, fs:0.84324 (r=0.788,p=0.907),  time:25.543, tt:4316.790\n",
      "Ep:169, loss:0.00000, loss_test:0.02012, lr:3.56e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.542, tt:4342.214\n",
      "Ep:170, loss:0.00000, loss_test:0.02016, lr:3.52e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.545, tt:4368.177\n",
      "Ep:171, loss:0.00000, loss_test:0.02020, lr:3.49e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.549, tt:4394.388\n",
      "Ep:172, loss:0.00000, loss_test:0.02023, lr:3.45e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.549, tt:4419.926\n",
      "Ep:173, loss:0.00000, loss_test:0.02026, lr:3.42e-02, fs:0.83696 (r=0.778,p=0.906),  time:25.552, tt:4445.995\n",
      "Ep:174, loss:0.00000, loss_test:0.02030, lr:3.38e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.553, tt:4471.778\n",
      "Ep:175, loss:0.00000, loss_test:0.02031, lr:3.35e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.561, tt:4498.724\n",
      "Ep:176, loss:0.00000, loss_test:0.02033, lr:3.32e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.564, tt:4524.785\n",
      "Ep:177, loss:0.00000, loss_test:0.02036, lr:3.28e-02, fs:0.84153 (r=0.778,p=0.917),  time:25.561, tt:4549.881\n",
      "Ep:178, loss:0.00000, loss_test:0.02040, lr:3.25e-02, fs:0.84615 (r=0.778,p=0.928),  time:25.563, tt:4575.807\n",
      "Ep:179, loss:0.00000, loss_test:0.02047, lr:3.22e-02, fs:0.83978 (r=0.768,p=0.927),  time:25.566, tt:4601.897\n",
      "Ep:180, loss:0.00000, loss_test:0.02050, lr:3.19e-02, fs:0.83978 (r=0.768,p=0.927),  time:25.561, tt:4626.476\n",
      "Ep:181, loss:0.00000, loss_test:0.02052, lr:3.15e-02, fs:0.83978 (r=0.768,p=0.927),  time:25.562, tt:4652.345\n",
      "Ep:182, loss:0.00000, loss_test:0.02055, lr:3.12e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.564, tt:4678.160\n",
      "Ep:183, loss:0.00000, loss_test:0.02059, lr:3.09e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.560, tt:4703.038\n",
      "Ep:184, loss:0.00000, loss_test:0.02060, lr:3.06e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.563, tt:4729.197\n",
      "Ep:185, loss:0.00000, loss_test:0.02063, lr:3.03e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.561, tt:4754.391\n",
      "Ep:186, loss:0.00000, loss_test:0.02068, lr:3.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.560, tt:4779.670\n",
      "Ep:187, loss:0.00000, loss_test:0.02072, lr:2.97e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.556, tt:4804.593\n",
      "Ep:188, loss:0.00000, loss_test:0.02075, lr:2.94e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.554, tt:4829.675\n",
      "Ep:189, loss:0.00000, loss_test:0.02078, lr:2.91e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.554, tt:4855.322\n",
      "Ep:190, loss:0.00000, loss_test:0.02080, lr:2.88e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.562, tt:4882.260\n",
      "Ep:191, loss:0.00000, loss_test:0.02082, lr:2.85e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.560, tt:4907.460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:192, loss:0.00000, loss_test:0.02084, lr:2.82e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.562, tt:4933.473\n",
      "Ep:193, loss:0.00000, loss_test:0.02087, lr:2.80e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.558, tt:4958.184\n",
      "Ep:194, loss:0.00000, loss_test:0.02089, lr:2.77e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.555, tt:4983.215\n",
      "Ep:195, loss:0.00000, loss_test:0.02091, lr:2.74e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.557, tt:5009.082\n",
      "Ep:196, loss:0.00000, loss_test:0.02094, lr:2.71e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.565, tt:5036.383\n",
      "Ep:197, loss:0.00000, loss_test:0.02098, lr:2.69e-02, fs:0.83333 (r=0.758,p=0.926),  time:25.564, tt:5061.693\n",
      "Ep:198, loss:0.00000, loss_test:0.02102, lr:2.66e-02, fs:0.82682 (r=0.747,p=0.925),  time:25.563, tt:5087.072\n",
      "Ep:199, loss:0.00000, loss_test:0.02102, lr:2.63e-02, fs:0.82682 (r=0.747,p=0.925),  time:25.563, tt:5112.588\n",
      "Ep:200, loss:0.00000, loss_test:0.02105, lr:2.61e-02, fs:0.82022 (r=0.737,p=0.924),  time:25.556, tt:5136.700\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14104, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.085, tt:27.085\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13977, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.561, tt:51.122\n",
      "Ep:2, loss:0.00028, loss_test:0.13712, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:24.189, tt:72.566\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13225, lr:1.00e-02, fs:0.68085 (r=0.970,p=0.525),  time:23.798, tt:95.192\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12615, lr:1.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:24.250, tt:121.251\n",
      "Ep:5, loss:0.00025, loss_test:0.12446, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:24.876, tt:149.258\n",
      "Ep:6, loss:0.00024, loss_test:0.12472, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:24.911, tt:174.374\n",
      "Ep:7, loss:0.00024, loss_test:0.12225, lr:1.00e-02, fs:0.65138 (r=0.717,p=0.597),  time:25.267, tt:202.137\n",
      "Ep:8, loss:0.00023, loss_test:0.12019, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:25.769, tt:231.917\n",
      "Ep:9, loss:0.00023, loss_test:0.11824, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:25.954, tt:259.536\n",
      "Ep:10, loss:0.00022, loss_test:0.11561, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:25.898, tt:284.875\n",
      "Ep:11, loss:0.00021, loss_test:0.11502, lr:1.00e-02, fs:0.67662 (r=0.687,p=0.667),  time:25.891, tt:310.698\n",
      "Ep:12, loss:0.00021, loss_test:0.11378, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:25.989, tt:337.862\n",
      "Ep:13, loss:0.00020, loss_test:0.11279, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:26.211, tt:366.961\n",
      "Ep:14, loss:0.00020, loss_test:0.11150, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:26.321, tt:394.816\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11011, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:26.391, tt:422.261\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10846, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:26.537, tt:451.123\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10713, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:26.616, tt:479.080\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10582, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:26.678, tt:506.882\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10379, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:26.711, tt:534.218\n",
      "Ep:20, loss:0.00017, loss_test:0.10223, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:26.717, tt:561.052\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.10113, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:26.716, tt:587.746\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09974, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:26.648, tt:612.915\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09866, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:26.659, tt:639.821\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09708, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:26.654, tt:666.348\n",
      "Ep:25, loss:0.00015, loss_test:0.09531, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:26.701, tt:694.232\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09520, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:26.733, tt:721.784\n",
      "Ep:27, loss:0.00014, loss_test:0.09350, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:26.731, tt:748.464\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09169, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:26.732, tt:775.222\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09094, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:26.758, tt:802.729\n",
      "Ep:30, loss:0.00013, loss_test:0.09014, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:26.785, tt:830.345\n",
      "Ep:31, loss:0.00012, loss_test:0.08967, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:26.814, tt:858.052\n",
      "Ep:32, loss:0.00012, loss_test:0.08818, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:26.801, tt:884.447\n",
      "Ep:33, loss:0.00011, loss_test:0.08761, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:26.870, tt:913.569\n",
      "Ep:34, loss:0.00011, loss_test:0.08697, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:26.873, tt:940.552\n",
      "Ep:35, loss:0.00011, loss_test:0.08580, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:26.886, tt:967.900\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08625, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:26.961, tt:997.550\n",
      "Ep:37, loss:0.00010, loss_test:0.08508, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:26.955, tt:1024.287\n",
      "Ep:38, loss:0.00010, loss_test:0.08482, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:26.944, tt:1050.834\n",
      "Ep:39, loss:0.00009, loss_test:0.08364, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:26.939, tt:1077.541\n",
      "Ep:40, loss:0.00009, loss_test:0.08362, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:26.905, tt:1103.108\n",
      "Ep:41, loss:0.00009, loss_test:0.08242, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:26.919, tt:1130.610\n",
      "Ep:42, loss:0.00009, loss_test:0.08209, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:26.954, tt:1159.025\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.08140, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:26.975, tt:1186.904\n",
      "Ep:44, loss:0.00008, loss_test:0.08106, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:26.979, tt:1214.058\n",
      "Ep:45, loss:0.00008, loss_test:0.08107, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:27.006, tt:1242.257\n",
      "Ep:46, loss:0.00008, loss_test:0.07983, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:26.996, tt:1268.828\n",
      "Ep:47, loss:0.00007, loss_test:0.07900, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:26.985, tt:1295.264\n",
      "Ep:48, loss:0.00007, loss_test:0.07974, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:27.003, tt:1323.138\n",
      "Ep:49, loss:0.00007, loss_test:0.07780, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:27.017, tt:1350.837\n",
      "Ep:50, loss:0.00007, loss_test:0.07880, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:27.028, tt:1378.449\n",
      "Ep:51, loss:0.00007, loss_test:0.07770, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.054, tt:1406.788\n",
      "Ep:52, loss:0.00006, loss_test:0.07710, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:27.058, tt:1434.098\n",
      "Ep:53, loss:0.00006, loss_test:0.07753, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:27.018, tt:1458.990\n",
      "Ep:54, loss:0.00006, loss_test:0.07557, lr:9.90e-03, fs:0.85714 (r=0.818,p=0.900),  time:27.028, tt:1486.513\n",
      "Ep:55, loss:0.00006, loss_test:0.07665, lr:9.80e-03, fs:0.85405 (r=0.798,p=0.919),  time:27.031, tt:1513.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00006, loss_test:0.07650, lr:9.70e-03, fs:0.86339 (r=0.798,p=0.940),  time:27.029, tt:1540.633\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.07726, lr:9.70e-03, fs:0.85263 (r=0.818,p=0.890),  time:27.071, tt:1570.118\n",
      "Ep:58, loss:0.00006, loss_test:0.07487, lr:9.70e-03, fs:0.86339 (r=0.798,p=0.940),  time:27.062, tt:1596.676\n",
      "Ep:59, loss:0.00005, loss_test:0.07599, lr:9.70e-03, fs:0.85263 (r=0.818,p=0.890),  time:27.061, tt:1623.635\n",
      "Ep:60, loss:0.00005, loss_test:0.07693, lr:9.70e-03, fs:0.86813 (r=0.798,p=0.952),  time:27.071, tt:1651.313\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.07461, lr:9.70e-03, fs:0.85870 (r=0.798,p=0.929),  time:27.093, tt:1679.749\n",
      "Ep:62, loss:0.00005, loss_test:0.07617, lr:9.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:27.100, tt:1707.294\n",
      "Ep:63, loss:0.00005, loss_test:0.07360, lr:9.70e-03, fs:0.86022 (r=0.808,p=0.920),  time:27.112, tt:1735.170\n",
      "Ep:64, loss:0.00005, loss_test:0.07643, lr:9.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:27.124, tt:1763.061\n",
      "Ep:65, loss:0.00005, loss_test:0.07482, lr:9.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.125, tt:1790.252\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.07455, lr:9.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.120, tt:1817.012\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.07354, lr:9.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:27.116, tt:1843.894\n",
      "Ep:68, loss:0.00004, loss_test:0.07593, lr:9.70e-03, fs:0.87432 (r=0.808,p=0.952),  time:27.116, tt:1871.028\n",
      "Ep:69, loss:0.00004, loss_test:0.07410, lr:9.70e-03, fs:0.86170 (r=0.818,p=0.910),  time:27.139, tt:1899.727\n",
      "Ep:70, loss:0.00004, loss_test:0.07436, lr:9.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.141, tt:1927.026\n",
      "Ep:71, loss:0.00004, loss_test:0.07448, lr:9.70e-03, fs:0.87097 (r=0.818,p=0.931),  time:27.120, tt:1952.651\n",
      "Ep:72, loss:0.00004, loss_test:0.07422, lr:9.70e-03, fs:0.86631 (r=0.818,p=0.920),  time:27.101, tt:1978.398\n",
      "Ep:73, loss:0.00004, loss_test:0.07499, lr:9.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.101, tt:2005.509\n",
      "Ep:74, loss:0.00004, loss_test:0.07369, lr:9.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.105, tt:2032.841\n",
      "Ep:75, loss:0.00004, loss_test:0.07504, lr:9.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.106, tt:2060.092\n",
      "Ep:76, loss:0.00004, loss_test:0.07351, lr:9.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.093, tt:2086.176\n",
      "Ep:77, loss:0.00004, loss_test:0.07430, lr:9.70e-03, fs:0.86170 (r=0.818,p=0.910),  time:27.096, tt:2113.517\n",
      "Ep:78, loss:0.00003, loss_test:0.07389, lr:9.61e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.090, tt:2140.132\n",
      "Ep:79, loss:0.00003, loss_test:0.07443, lr:9.51e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.092, tt:2167.362\n",
      "Ep:80, loss:0.00003, loss_test:0.07431, lr:9.41e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.097, tt:2194.865\n",
      "Ep:81, loss:0.00003, loss_test:0.07482, lr:9.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.099, tt:2222.092\n",
      "Ep:82, loss:0.00003, loss_test:0.07504, lr:9.23e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.110, tt:2250.088\n",
      "Ep:83, loss:0.00003, loss_test:0.07405, lr:9.14e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.112, tt:2277.391\n",
      "Ep:84, loss:0.00003, loss_test:0.07425, lr:9.04e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.109, tt:2304.274\n",
      "Ep:85, loss:0.00003, loss_test:0.07424, lr:8.95e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.112, tt:2331.629\n",
      "Ep:86, loss:0.00003, loss_test:0.07439, lr:8.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.122, tt:2359.591\n",
      "Ep:87, loss:0.00003, loss_test:0.07482, lr:8.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.140, tt:2388.350\n",
      "Ep:88, loss:0.00003, loss_test:0.07310, lr:8.69e-03, fs:0.87097 (r=0.818,p=0.931),  time:27.136, tt:2415.125\n",
      "Ep:89, loss:0.00003, loss_test:0.07552, lr:8.60e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.141, tt:2442.700\n",
      "Ep:90, loss:0.00003, loss_test:0.07513, lr:8.51e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.144, tt:2470.100\n",
      "Ep:91, loss:0.00003, loss_test:0.07268, lr:8.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:27.143, tt:2497.171\n",
      "Ep:92, loss:0.00003, loss_test:0.07573, lr:8.35e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.148, tt:2524.806\n",
      "Ep:93, loss:0.00003, loss_test:0.07462, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.161, tt:2553.124\n",
      "Ep:94, loss:0.00003, loss_test:0.07310, lr:8.18e-03, fs:0.87097 (r=0.818,p=0.931),  time:27.169, tt:2581.033\n",
      "Ep:95, loss:0.00003, loss_test:0.07499, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.181, tt:2609.406\n",
      "Ep:96, loss:0.00002, loss_test:0.07619, lr:8.02e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.188, tt:2637.253\n",
      "Ep:97, loss:0.00002, loss_test:0.07341, lr:7.94e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.193, tt:2664.912\n",
      "Ep:98, loss:0.00002, loss_test:0.07430, lr:7.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.196, tt:2692.448\n",
      "Ep:99, loss:0.00002, loss_test:0.07726, lr:7.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.200, tt:2719.957\n",
      "Ep:100, loss:0.00002, loss_test:0.07423, lr:7.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.201, tt:2747.326\n",
      "Ep:101, loss:0.00002, loss_test:0.07337, lr:7.62e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.181, tt:2772.484\n",
      "Ep:102, loss:0.00002, loss_test:0.07526, lr:7.55e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.198, tt:2801.431\n",
      "Ep:103, loss:0.00002, loss_test:0.07483, lr:7.47e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.203, tt:2829.095\n",
      "Ep:104, loss:0.00002, loss_test:0.07365, lr:7.40e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.203, tt:2856.321\n",
      "Ep:105, loss:0.00002, loss_test:0.07557, lr:7.32e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.202, tt:2883.404\n",
      "Ep:106, loss:0.00002, loss_test:0.07533, lr:7.25e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.211, tt:2911.611\n",
      "Ep:107, loss:0.00002, loss_test:0.07348, lr:7.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.227, tt:2940.462\n",
      "Ep:108, loss:0.00002, loss_test:0.07492, lr:7.11e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.243, tt:2969.457\n",
      "Ep:109, loss:0.00002, loss_test:0.07489, lr:7.03e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.245, tt:2996.972\n",
      "Ep:110, loss:0.00002, loss_test:0.07371, lr:6.96e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.240, tt:3023.611\n",
      "Ep:111, loss:0.00002, loss_test:0.07500, lr:6.89e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.236, tt:3050.394\n",
      "Ep:112, loss:0.00002, loss_test:0.07469, lr:6.83e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.234, tt:3077.425\n",
      "Ep:113, loss:0.00002, loss_test:0.07448, lr:6.76e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.238, tt:3105.076\n",
      "Ep:114, loss:0.00002, loss_test:0.07534, lr:6.69e-03, fs:0.87568 (r=0.818,p=0.942),  time:27.241, tt:3132.764\n",
      "Ep:115, loss:0.00002, loss_test:0.07473, lr:6.62e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.251, tt:3161.156\n",
      "Ep:116, loss:0.00002, loss_test:0.07363, lr:6.56e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.247, tt:3187.930\n",
      "Ep:117, loss:0.00002, loss_test:0.07467, lr:6.49e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.253, tt:3215.817\n",
      "Ep:118, loss:0.00002, loss_test:0.07396, lr:6.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.265, tt:3244.488\n",
      "Ep:119, loss:0.00002, loss_test:0.07426, lr:6.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.269, tt:3272.247\n",
      "Ep:120, loss:0.00002, loss_test:0.07565, lr:6.30e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.273, tt:3300.071\n",
      "Ep:121, loss:0.00002, loss_test:0.07386, lr:6.24e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.282, tt:3328.374\n",
      "Ep:122, loss:0.00002, loss_test:0.07502, lr:6.17e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.281, tt:3355.605\n",
      "Ep:123, loss:0.00002, loss_test:0.07551, lr:6.11e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.279, tt:3382.628\n",
      "Ep:124, loss:0.00002, loss_test:0.07407, lr:6.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.277, tt:3409.644\n",
      "Ep:125, loss:0.00002, loss_test:0.07509, lr:5.99e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.282, tt:3437.483\n",
      "Ep:126, loss:0.00002, loss_test:0.07513, lr:5.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.281, tt:3464.702\n",
      "Ep:127, loss:0.00002, loss_test:0.07418, lr:5.87e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.286, tt:3492.658\n",
      "Ep:128, loss:0.00002, loss_test:0.07495, lr:5.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.297, tt:3521.265\n",
      "Ep:129, loss:0.00002, loss_test:0.07505, lr:5.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.308, tt:3550.060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.07479, lr:5.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.298, tt:3576.088\n",
      "Ep:131, loss:0.00002, loss_test:0.07529, lr:5.64e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.330, tt:3607.538\n",
      "Ep:132, loss:0.00002, loss_test:0.07496, lr:5.58e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.331, tt:3634.993\n",
      "Ep:133, loss:0.00002, loss_test:0.07456, lr:5.53e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.339, tt:3663.444\n",
      "Ep:134, loss:0.00002, loss_test:0.07515, lr:5.47e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.340, tt:3690.882\n",
      "Ep:135, loss:0.00001, loss_test:0.07470, lr:5.42e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.351, tt:3719.800\n",
      "Ep:136, loss:0.00001, loss_test:0.07434, lr:5.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.355, tt:3747.608\n",
      "Ep:137, loss:0.00001, loss_test:0.07649, lr:5.31e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.354, tt:3774.895\n",
      "Ep:138, loss:0.00001, loss_test:0.07542, lr:5.26e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.358, tt:3802.729\n",
      "Ep:139, loss:0.00001, loss_test:0.07398, lr:5.20e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.368, tt:3831.503\n",
      "Ep:140, loss:0.00001, loss_test:0.07553, lr:5.15e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.374, tt:3859.758\n",
      "Ep:141, loss:0.00001, loss_test:0.07511, lr:5.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.386, tt:3888.797\n",
      "Ep:142, loss:0.00001, loss_test:0.07461, lr:5.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.387, tt:3916.304\n",
      "Ep:143, loss:0.00001, loss_test:0.07563, lr:5.00e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.386, tt:3943.623\n",
      "Ep:144, loss:0.00001, loss_test:0.07534, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.406, tt:3973.847\n",
      "Ep:145, loss:0.00001, loss_test:0.07461, lr:4.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4003.604\n",
      "Ep:146, loss:0.00001, loss_test:0.07580, lr:4.85e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.417, tt:4030.354\n",
      "Ep:147, loss:0.00001, loss_test:0.07513, lr:4.80e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.417, tt:4057.669\n",
      "Ep:148, loss:0.00001, loss_test:0.07504, lr:4.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.415, tt:4084.793\n",
      "Ep:149, loss:0.00001, loss_test:0.07536, lr:4.71e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.402, tt:4110.313\n",
      "Ep:150, loss:0.00001, loss_test:0.07532, lr:4.66e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.405, tt:4138.116\n",
      "Ep:151, loss:0.00001, loss_test:0.07488, lr:4.61e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.408, tt:4166.008\n",
      "Ep:152, loss:0.00001, loss_test:0.07475, lr:4.57e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.414, tt:4194.343\n",
      "Ep:153, loss:0.00001, loss_test:0.07585, lr:4.52e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.424, tt:4223.346\n",
      "Ep:154, loss:0.00001, loss_test:0.07474, lr:4.48e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4250.462\n",
      "Ep:155, loss:0.00001, loss_test:0.07504, lr:4.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.418, tt:4277.241\n",
      "Ep:156, loss:0.00001, loss_test:0.07593, lr:4.39e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4305.322\n",
      "Ep:157, loss:0.00001, loss_test:0.07494, lr:4.34e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.424, tt:4332.957\n",
      "Ep:158, loss:0.00001, loss_test:0.07504, lr:4.30e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4360.148\n",
      "Ep:159, loss:0.00001, loss_test:0.07516, lr:4.26e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.426, tt:4388.139\n",
      "Ep:160, loss:0.00001, loss_test:0.07524, lr:4.21e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4415.015\n",
      "Ep:161, loss:0.00001, loss_test:0.07512, lr:4.17e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.416, tt:4441.451\n",
      "Ep:162, loss:0.00001, loss_test:0.07558, lr:4.13e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.416, tt:4468.818\n",
      "Ep:163, loss:0.00001, loss_test:0.07562, lr:4.09e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.423, tt:4497.354\n",
      "Ep:164, loss:0.00001, loss_test:0.07527, lr:4.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.428, tt:4525.569\n",
      "Ep:165, loss:0.00001, loss_test:0.07534, lr:4.01e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.433, tt:4553.820\n",
      "Ep:166, loss:0.00001, loss_test:0.07531, lr:3.97e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.435, tt:4581.704\n",
      "Ep:167, loss:0.00001, loss_test:0.07556, lr:3.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.429, tt:4608.071\n",
      "Ep:168, loss:0.00001, loss_test:0.07522, lr:3.89e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.415, tt:4633.090\n",
      "Ep:169, loss:0.00001, loss_test:0.07527, lr:3.85e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.416, tt:4660.677\n",
      "Ep:170, loss:0.00001, loss_test:0.07580, lr:3.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.420, tt:4688.816\n",
      "Ep:171, loss:0.00001, loss_test:0.07549, lr:3.77e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.419, tt:4716.047\n",
      "Ep:172, loss:0.00001, loss_test:0.07537, lr:3.73e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4743.947\n",
      "Ep:173, loss:0.00001, loss_test:0.07609, lr:3.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.425, tt:4771.993\n",
      "Ep:174, loss:0.00001, loss_test:0.07532, lr:3.66e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.428, tt:4799.840\n",
      "Ep:175, loss:0.00001, loss_test:0.07523, lr:3.62e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.427, tt:4827.067\n",
      "Ep:176, loss:0.00001, loss_test:0.07563, lr:3.59e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.429, tt:4855.004\n",
      "Ep:177, loss:0.00001, loss_test:0.07581, lr:3.55e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.434, tt:4883.296\n",
      "Ep:178, loss:0.00001, loss_test:0.07479, lr:3.52e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.433, tt:4910.584\n",
      "Ep:179, loss:0.00001, loss_test:0.07553, lr:3.48e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.430, tt:4937.309\n",
      "Ep:180, loss:0.00001, loss_test:0.07599, lr:3.45e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.422, tt:4963.361\n",
      "Ep:181, loss:0.00001, loss_test:0.07499, lr:3.41e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.405, tt:4987.638\n",
      "Ep:182, loss:0.00001, loss_test:0.07550, lr:3.38e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.401, tt:5014.463\n",
      "Ep:183, loss:0.00001, loss_test:0.07597, lr:3.34e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.389, tt:5039.566\n",
      "Ep:184, loss:0.00001, loss_test:0.07528, lr:3.31e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.381, tt:5065.417\n",
      "Ep:185, loss:0.00001, loss_test:0.07554, lr:3.28e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.373, tt:5091.470\n",
      "Ep:186, loss:0.00001, loss_test:0.07550, lr:3.24e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.363, tt:5116.900\n",
      "Ep:187, loss:0.00001, loss_test:0.07517, lr:3.21e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.371, tt:5145.774\n",
      "Ep:188, loss:0.00001, loss_test:0.07535, lr:3.18e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.366, tt:5172.269\n",
      "Ep:189, loss:0.00001, loss_test:0.07538, lr:3.15e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.366, tt:5199.568\n",
      "Ep:190, loss:0.00001, loss_test:0.07539, lr:3.12e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.367, tt:5227.044\n",
      "Ep:191, loss:0.00001, loss_test:0.07578, lr:3.09e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.357, tt:5252.571\n",
      "Ep:192, loss:0.00001, loss_test:0.07588, lr:3.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.355, tt:5279.531\n",
      "Ep:193, loss:0.00001, loss_test:0.07550, lr:3.02e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.355, tt:5306.906\n",
      "Ep:194, loss:0.00001, loss_test:0.07546, lr:2.99e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.347, tt:5332.740\n",
      "Ep:195, loss:0.00001, loss_test:0.07564, lr:2.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.355, tt:5361.520\n",
      "Ep:196, loss:0.00001, loss_test:0.07582, lr:2.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.358, tt:5389.583\n",
      "Ep:197, loss:0.00001, loss_test:0.07540, lr:2.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.358, tt:5416.838\n",
      "Ep:198, loss:0.00001, loss_test:0.07527, lr:2.88e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.351, tt:5442.762\n",
      "Ep:199, loss:0.00001, loss_test:0.07573, lr:2.85e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.346, tt:5469.138\n",
      "Ep:200, loss:0.00001, loss_test:0.07571, lr:2.82e-03, fs:0.88043 (r=0.818,p=0.953),  time:27.334, tt:5494.037\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02158, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:28.352, tt:28.352\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02649, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.009, tt:54.018\n",
      "Ep:2, loss:0.00005, loss_test:0.02876, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.343, tt:82.029\n",
      "Ep:3, loss:0.00006, loss_test:0.02930, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.808, tt:111.233\n",
      "Ep:4, loss:0.00006, loss_test:0.02896, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.470, tt:142.352\n",
      "Ep:5, loss:0.00006, loss_test:0.02794, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.087, tt:174.522\n",
      "Ep:6, loss:0.00005, loss_test:0.02627, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.751, tt:208.259\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02429, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:29.961, tt:239.692\n",
      "Ep:8, loss:0.00005, loss_test:0.02257, lr:6.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:30.375, tt:273.375\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00005, loss_test:0.02148, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:30.669, tt:306.695\n",
      "Ep:10, loss:0.00004, loss_test:0.02118, lr:6.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:31.027, tt:341.294\n",
      "Ep:11, loss:0.00004, loss_test:0.02142, lr:6.00e-02, fs:0.63846 (r=0.838,p=0.516),  time:31.391, tt:376.689\n",
      "Ep:12, loss:0.00004, loss_test:0.02147, lr:6.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:31.973, tt:415.649\n",
      "Ep:13, loss:0.00004, loss_test:0.02137, lr:6.00e-02, fs:0.62835 (r=0.828,p=0.506),  time:32.194, tt:450.717\n",
      "Ep:14, loss:0.00004, loss_test:0.02098, lr:6.00e-02, fs:0.63846 (r=0.838,p=0.516),  time:32.323, tt:484.841\n",
      "Ep:15, loss:0.00004, loss_test:0.02045, lr:6.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:32.499, tt:519.982\n",
      "Ep:16, loss:0.00004, loss_test:0.01988, lr:6.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:32.585, tt:553.941\n",
      "Ep:17, loss:0.00004, loss_test:0.01928, lr:6.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:32.668, tt:588.016\n",
      "Ep:18, loss:0.00004, loss_test:0.01883, lr:6.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:32.754, tt:622.330\n",
      "Ep:19, loss:0.00003, loss_test:0.01845, lr:6.00e-02, fs:0.66939 (r=0.828,p=0.562),  time:32.809, tt:656.176\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01815, lr:6.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:32.873, tt:690.324\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01786, lr:6.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:33.003, tt:726.060\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01759, lr:6.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:33.000, tt:758.997\n",
      "Ep:23, loss:0.00003, loss_test:0.01738, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:32.969, tt:791.268\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01722, lr:6.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:32.990, tt:824.749\n",
      "Ep:25, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:33.030, tt:858.768\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01695, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:33.076, tt:893.039\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:33.101, tt:926.830\n",
      "Ep:28, loss:0.00003, loss_test:0.01657, lr:6.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:33.167, tt:961.829\n",
      "Ep:29, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:33.149, tt:994.477\n",
      "Ep:30, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:33.202, tt:1029.261\n",
      "Ep:31, loss:0.00003, loss_test:0.01653, lr:6.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:33.221, tt:1063.056\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:33.288, tt:1098.500\n",
      "Ep:33, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:33.273, tt:1131.292\n",
      "Ep:34, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:33.346, tt:1167.111\n",
      "Ep:35, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:33.371, tt:1201.372\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01577, lr:6.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:33.424, tt:1236.679\n",
      "Ep:37, loss:0.00002, loss_test:0.01574, lr:6.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:33.479, tt:1272.214\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:33.510, tt:1306.906\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:33.536, tt:1341.432\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:33.596, tt:1377.418\n",
      "Ep:41, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:33.601, tt:1411.254\n",
      "Ep:42, loss:0.00002, loss_test:0.01544, lr:6.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:33.630, tt:1446.069\n",
      "Ep:43, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:33.620, tt:1479.286\n",
      "Ep:44, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:33.629, tt:1513.293\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:33.624, tt:1546.705\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:33.615, tt:1579.892\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:33.647, tt:1615.035\n",
      "Ep:48, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:33.667, tt:1649.707\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01515, lr:6.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.620, tt:1681.003\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01508, lr:6.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:33.607, tt:1713.942\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:33.674, tt:1751.051\n",
      "Ep:52, loss:0.00001, loss_test:0.01505, lr:6.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:33.657, tt:1783.838\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01535, lr:6.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:33.680, tt:1818.697\n",
      "Ep:54, loss:0.00001, loss_test:0.01513, lr:6.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:33.691, tt:1852.992\n",
      "Ep:55, loss:0.00001, loss_test:0.01522, lr:6.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:33.690, tt:1886.639\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01536, lr:6.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:33.719, tt:1922.002\n",
      "Ep:57, loss:0.00001, loss_test:0.01543, lr:6.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:33.741, tt:1956.954\n",
      "Ep:58, loss:0.00001, loss_test:0.01559, lr:6.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:33.758, tt:1991.693\n",
      "Ep:59, loss:0.00001, loss_test:0.01544, lr:6.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:33.759, tt:2025.556\n",
      "Ep:60, loss:0.00001, loss_test:0.01574, lr:6.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:33.760, tt:2059.357\n",
      "Ep:61, loss:0.00001, loss_test:0.01570, lr:6.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.764, tt:2093.392\n",
      "Ep:62, loss:0.00001, loss_test:0.01592, lr:6.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:33.753, tt:2126.434\n",
      "Ep:63, loss:0.00001, loss_test:0.01585, lr:6.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:33.748, tt:2159.849\n",
      "Ep:64, loss:0.00001, loss_test:0.01619, lr:6.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:33.751, tt:2193.784\n",
      "Ep:65, loss:0.00001, loss_test:0.01611, lr:6.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:33.752, tt:2227.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00001, loss_test:0.01613, lr:6.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:33.747, tt:2261.067\n",
      "Ep:67, loss:0.00001, loss_test:0.01638, lr:5.94e-02, fs:0.77907 (r=0.677,p=0.918),  time:33.774, tt:2296.605\n",
      "Ep:68, loss:0.00001, loss_test:0.01665, lr:5.88e-02, fs:0.76744 (r=0.667,p=0.904),  time:33.789, tt:2331.408\n",
      "Ep:69, loss:0.00001, loss_test:0.01646, lr:5.82e-02, fs:0.77193 (r=0.667,p=0.917),  time:33.792, tt:2365.411\n",
      "Ep:70, loss:0.00001, loss_test:0.01658, lr:5.76e-02, fs:0.77457 (r=0.677,p=0.905),  time:33.835, tt:2402.298\n",
      "Ep:71, loss:0.00001, loss_test:0.01670, lr:5.71e-02, fs:0.77907 (r=0.677,p=0.918),  time:33.830, tt:2435.753\n",
      "Ep:72, loss:0.00001, loss_test:0.01701, lr:5.65e-02, fs:0.77647 (r=0.667,p=0.930),  time:33.823, tt:2469.070\n",
      "Ep:73, loss:0.00001, loss_test:0.01688, lr:5.59e-02, fs:0.77907 (r=0.677,p=0.918),  time:33.808, tt:2501.764\n",
      "Ep:74, loss:0.00001, loss_test:0.01728, lr:5.54e-02, fs:0.77193 (r=0.667,p=0.917),  time:33.799, tt:2534.939\n",
      "Ep:75, loss:0.00001, loss_test:0.01692, lr:5.48e-02, fs:0.77907 (r=0.677,p=0.918),  time:33.812, tt:2569.678\n",
      "Ep:76, loss:0.00001, loss_test:0.01721, lr:5.43e-02, fs:0.78363 (r=0.677,p=0.931),  time:33.824, tt:2604.450\n",
      "Ep:77, loss:0.00001, loss_test:0.01713, lr:5.37e-02, fs:0.78363 (r=0.677,p=0.931),  time:33.836, tt:2639.202\n",
      "Ep:78, loss:0.00001, loss_test:0.01767, lr:5.32e-02, fs:0.78107 (r=0.667,p=0.943),  time:33.844, tt:2673.686\n",
      "Ep:79, loss:0.00001, loss_test:0.01748, lr:5.27e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.862, tt:2708.961\n",
      "Ep:80, loss:0.00001, loss_test:0.01759, lr:5.21e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.883, tt:2744.532\n",
      "Ep:81, loss:0.00001, loss_test:0.01762, lr:5.16e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.908, tt:2780.483\n",
      "Ep:82, loss:0.00001, loss_test:0.01795, lr:5.11e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.903, tt:2813.922\n",
      "Ep:83, loss:0.00001, loss_test:0.01767, lr:5.06e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.919, tt:2849.221\n",
      "Ep:84, loss:0.00001, loss_test:0.01820, lr:5.01e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.950, tt:2885.757\n",
      "Ep:85, loss:0.00001, loss_test:0.01819, lr:4.96e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.958, tt:2920.372\n",
      "Ep:86, loss:0.00001, loss_test:0.01826, lr:4.91e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.971, tt:2955.455\n",
      "Ep:87, loss:0.00001, loss_test:0.01839, lr:4.86e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.981, tt:2990.342\n",
      "Ep:88, loss:0.00001, loss_test:0.01844, lr:4.81e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.989, tt:3025.021\n",
      "Ep:89, loss:0.00001, loss_test:0.01849, lr:4.76e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.009, tt:3060.785\n",
      "Ep:90, loss:0.00001, loss_test:0.01848, lr:4.71e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.007, tt:3094.638\n",
      "Ep:91, loss:0.00001, loss_test:0.01854, lr:4.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:33.999, tt:3127.863\n",
      "Ep:92, loss:0.00001, loss_test:0.01874, lr:4.62e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.011, tt:3162.986\n",
      "Ep:93, loss:0.00001, loss_test:0.01895, lr:4.57e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.010, tt:3196.902\n",
      "Ep:94, loss:0.00001, loss_test:0.01884, lr:4.53e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.017, tt:3231.613\n",
      "Ep:95, loss:0.00001, loss_test:0.01890, lr:4.48e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.021, tt:3266.039\n",
      "Ep:96, loss:0.00001, loss_test:0.01891, lr:4.44e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.051, tt:3302.990\n",
      "Ep:97, loss:0.00001, loss_test:0.01922, lr:4.39e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.062, tt:3338.086\n",
      "Ep:98, loss:0.00001, loss_test:0.01908, lr:4.35e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.054, tt:3371.361\n",
      "Ep:99, loss:0.00001, loss_test:0.01909, lr:4.31e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.053, tt:3405.292\n",
      "Ep:100, loss:0.00001, loss_test:0.01964, lr:4.26e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.067, tt:3440.727\n",
      "Ep:101, loss:0.00001, loss_test:0.01929, lr:4.22e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.052, tt:3473.302\n",
      "Ep:102, loss:0.00001, loss_test:0.01984, lr:4.18e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.055, tt:3507.640\n",
      "Ep:103, loss:0.00000, loss_test:0.01927, lr:4.14e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.058, tt:3541.994\n",
      "Ep:104, loss:0.00000, loss_test:0.01991, lr:4.10e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.061, tt:3576.354\n",
      "Ep:105, loss:0.00000, loss_test:0.01971, lr:4.05e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.070, tt:3611.389\n",
      "Ep:106, loss:0.00000, loss_test:0.01979, lr:4.01e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.064, tt:3644.840\n",
      "Ep:107, loss:0.00000, loss_test:0.02015, lr:3.97e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.043, tt:3676.662\n",
      "Ep:108, loss:0.00000, loss_test:0.01964, lr:3.93e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.056, tt:3712.138\n",
      "Ep:109, loss:0.00000, loss_test:0.02015, lr:3.89e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.043, tt:3744.681\n",
      "Ep:110, loss:0.00000, loss_test:0.02006, lr:3.86e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.034, tt:3777.785\n",
      "Ep:111, loss:0.00000, loss_test:0.02015, lr:3.82e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.036, tt:3811.996\n",
      "Ep:112, loss:0.00000, loss_test:0.02026, lr:3.78e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.036, tt:3846.013\n",
      "Ep:113, loss:0.00000, loss_test:0.02033, lr:3.74e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.052, tt:3881.951\n",
      "Ep:114, loss:0.00000, loss_test:0.02069, lr:3.70e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.054, tt:3916.238\n",
      "Ep:115, loss:0.00000, loss_test:0.02009, lr:3.67e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.053, tt:3950.094\n",
      "Ep:116, loss:0.00000, loss_test:0.02074, lr:3.63e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.043, tt:3983.073\n",
      "Ep:117, loss:0.00000, loss_test:0.02066, lr:3.59e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.040, tt:4016.685\n",
      "Ep:118, loss:0.00000, loss_test:0.02060, lr:3.56e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.043, tt:4051.141\n",
      "Ep:119, loss:0.00000, loss_test:0.02089, lr:3.52e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.040, tt:4084.787\n",
      "Ep:120, loss:0.00000, loss_test:0.02064, lr:3.49e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.049, tt:4119.894\n",
      "Ep:121, loss:0.00000, loss_test:0.02105, lr:3.45e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.040, tt:4152.849\n",
      "Ep:122, loss:0.00000, loss_test:0.02091, lr:3.42e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.029, tt:4185.572\n",
      "Ep:123, loss:0.00000, loss_test:0.02105, lr:3.38e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.017, tt:4218.131\n",
      "Ep:124, loss:0.00000, loss_test:0.02106, lr:3.35e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.020, tt:4252.547\n",
      "Ep:125, loss:0.00000, loss_test:0.02109, lr:3.32e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.020, tt:4286.466\n",
      "Ep:126, loss:0.00000, loss_test:0.02109, lr:3.28e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.034, tt:4322.300\n",
      "Ep:127, loss:0.00000, loss_test:0.02138, lr:3.25e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.034, tt:4356.298\n",
      "Ep:128, loss:0.00000, loss_test:0.02112, lr:3.22e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.042, tt:4391.417\n",
      "Ep:129, loss:0.00000, loss_test:0.02143, lr:3.19e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.040, tt:4425.223\n",
      "Ep:130, loss:0.00000, loss_test:0.02133, lr:3.15e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.041, tt:4459.378\n",
      "Ep:131, loss:0.00000, loss_test:0.02140, lr:3.12e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.038, tt:4492.997\n",
      "Ep:132, loss:0.00000, loss_test:0.02151, lr:3.09e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.048, tt:4528.408\n",
      "Ep:133, loss:0.00000, loss_test:0.02144, lr:3.06e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.052, tt:4562.959\n",
      "Ep:134, loss:0.00000, loss_test:0.02163, lr:3.03e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.048, tt:4596.536\n",
      "Ep:135, loss:0.00000, loss_test:0.02161, lr:3.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.060, tt:4632.095\n",
      "Ep:136, loss:0.00000, loss_test:0.02179, lr:2.97e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.051, tt:4665.051\n",
      "Ep:137, loss:0.00000, loss_test:0.02159, lr:2.94e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.045, tt:4698.226\n",
      "Ep:138, loss:0.00000, loss_test:0.02191, lr:2.91e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.025, tt:4729.497\n",
      "Ep:139, loss:0.00000, loss_test:0.02178, lr:2.88e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.004, tt:4760.581\n",
      "Ep:140, loss:0.00000, loss_test:0.02194, lr:2.85e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.002, tt:4794.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.02189, lr:2.82e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.006, tt:4828.899\n",
      "Ep:142, loss:0.00000, loss_test:0.02200, lr:2.80e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.019, tt:4864.686\n",
      "Ep:143, loss:0.00000, loss_test:0.02203, lr:2.77e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.008, tt:4897.138\n",
      "Ep:144, loss:0.00000, loss_test:0.02191, lr:2.74e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.002, tt:4930.218\n",
      "Ep:145, loss:0.00000, loss_test:0.02221, lr:2.71e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.004, tt:4964.561\n",
      "Ep:146, loss:0.00000, loss_test:0.02221, lr:2.69e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.008, tt:4999.161\n",
      "Ep:147, loss:0.00000, loss_test:0.02229, lr:2.66e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.000, tt:5032.005\n",
      "Ep:148, loss:0.00000, loss_test:0.02223, lr:2.63e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.001, tt:5066.125\n",
      "Ep:149, loss:0.00000, loss_test:0.02246, lr:2.61e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.007, tt:5101.013\n",
      "Ep:150, loss:0.00000, loss_test:0.02235, lr:2.58e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.007, tt:5135.129\n",
      "Ep:151, loss:0.00000, loss_test:0.02243, lr:2.55e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.007, tt:5169.069\n",
      "Ep:152, loss:0.00000, loss_test:0.02229, lr:2.53e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.013, tt:5204.027\n",
      "Ep:153, loss:0.00000, loss_test:0.02255, lr:2.50e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.013, tt:5238.041\n",
      "Ep:154, loss:0.00000, loss_test:0.02258, lr:2.48e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.018, tt:5272.752\n",
      "Ep:155, loss:0.00000, loss_test:0.02258, lr:2.45e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.014, tt:5306.173\n",
      "Ep:156, loss:0.00000, loss_test:0.02261, lr:2.43e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.027, tt:5342.187\n",
      "Ep:157, loss:0.00000, loss_test:0.02252, lr:2.40e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.031, tt:5376.943\n",
      "Ep:158, loss:0.00000, loss_test:0.02281, lr:2.38e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.030, tt:5410.838\n",
      "Ep:159, loss:0.00000, loss_test:0.02275, lr:2.36e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.030, tt:5444.845\n",
      "Ep:160, loss:0.00000, loss_test:0.02273, lr:2.33e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.042, tt:5480.706\n",
      "Ep:161, loss:0.00000, loss_test:0.02287, lr:2.31e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.049, tt:5515.984\n",
      "Ep:162, loss:0.00000, loss_test:0.02285, lr:2.29e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.071, tt:5553.497\n",
      "Ep:163, loss:0.00000, loss_test:0.02294, lr:2.26e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.075, tt:5588.260\n",
      "Ep:164, loss:0.00000, loss_test:0.02294, lr:2.24e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.078, tt:5622.861\n",
      "Ep:165, loss:0.00000, loss_test:0.02288, lr:2.22e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.089, tt:5658.712\n",
      "Ep:166, loss:0.00000, loss_test:0.02314, lr:2.20e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.092, tt:5693.407\n",
      "Ep:167, loss:0.00000, loss_test:0.02307, lr:2.17e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.095, tt:5727.982\n",
      "Ep:168, loss:0.00000, loss_test:0.02300, lr:2.15e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.104, tt:5763.515\n",
      "Ep:169, loss:0.00000, loss_test:0.02326, lr:2.13e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.107, tt:5798.267\n",
      "Ep:170, loss:0.00000, loss_test:0.02315, lr:2.11e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.116, tt:5833.807\n",
      "Ep:171, loss:0.00000, loss_test:0.02314, lr:2.09e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.119, tt:5868.468\n",
      "Ep:172, loss:0.00000, loss_test:0.02333, lr:2.07e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.128, tt:5904.227\n",
      "Ep:173, loss:0.00000, loss_test:0.02335, lr:2.05e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.140, tt:5940.426\n",
      "Ep:174, loss:0.00000, loss_test:0.02320, lr:2.03e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.145, tt:5975.425\n",
      "Ep:175, loss:0.00000, loss_test:0.02337, lr:2.01e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.150, tt:6010.323\n",
      "Ep:176, loss:0.00000, loss_test:0.02346, lr:1.99e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.151, tt:6044.678\n",
      "Ep:177, loss:0.00000, loss_test:0.02340, lr:1.97e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.161, tt:6080.601\n",
      "Ep:178, loss:0.00000, loss_test:0.02355, lr:1.95e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.156, tt:6113.839\n",
      "Ep:179, loss:0.00000, loss_test:0.02352, lr:1.93e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.173, tt:6151.215\n",
      "Ep:180, loss:0.00000, loss_test:0.02349, lr:1.91e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.187, tt:6187.762\n",
      "Ep:181, loss:0.00000, loss_test:0.02362, lr:1.89e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.190, tt:6222.653\n",
      "Ep:182, loss:0.00000, loss_test:0.02361, lr:1.87e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.195, tt:6257.640\n",
      "Ep:183, loss:0.00000, loss_test:0.02365, lr:1.85e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.203, tt:6293.358\n",
      "Ep:184, loss:0.00000, loss_test:0.02372, lr:1.83e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.207, tt:6328.269\n",
      "Ep:185, loss:0.00000, loss_test:0.02368, lr:1.81e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.217, tt:6364.408\n",
      "Ep:186, loss:0.00000, loss_test:0.02381, lr:1.80e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.215, tt:6398.199\n",
      "Ep:187, loss:0.00000, loss_test:0.02379, lr:1.78e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.231, tt:6435.442\n",
      "Ep:188, loss:0.00000, loss_test:0.02382, lr:1.76e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.241, tt:6471.613\n",
      "Ep:189, loss:0.00000, loss_test:0.02379, lr:1.74e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.253, tt:6508.019\n",
      "Ep:190, loss:0.00000, loss_test:0.02383, lr:1.73e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.259, tt:6543.423\n",
      "Ep:191, loss:0.00000, loss_test:0.02393, lr:1.71e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.256, tt:6577.081\n",
      "Ep:192, loss:0.00000, loss_test:0.02391, lr:1.69e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.259, tt:6611.965\n",
      "Ep:193, loss:0.00000, loss_test:0.02399, lr:1.67e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.264, tt:6647.256\n",
      "Ep:194, loss:0.00000, loss_test:0.02396, lr:1.66e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.267, tt:6681.991\n",
      "Ep:195, loss:0.00000, loss_test:0.02399, lr:1.64e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.260, tt:6714.952\n",
      "Ep:196, loss:0.00000, loss_test:0.02407, lr:1.62e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.264, tt:6749.989\n",
      "Ep:197, loss:0.00000, loss_test:0.02409, lr:1.61e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.262, tt:6783.832\n",
      "Ep:198, loss:0.00000, loss_test:0.02416, lr:1.59e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.257, tt:6817.099\n",
      "Ep:199, loss:0.00000, loss_test:0.02413, lr:1.58e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.251, tt:6850.110\n",
      "Ep:200, loss:0.00000, loss_test:0.02412, lr:1.56e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.248, tt:6883.810\n",
      "Ep:201, loss:0.00000, loss_test:0.02419, lr:1.54e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.254, tt:6919.288\n",
      "Ep:202, loss:0.00000, loss_test:0.02417, lr:1.53e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.249, tt:6952.450\n",
      "Ep:203, loss:0.00000, loss_test:0.02423, lr:1.51e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.248, tt:6986.604\n",
      "Ep:204, loss:0.00000, loss_test:0.02430, lr:1.50e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.239, tt:7018.920\n",
      "Ep:205, loss:0.00000, loss_test:0.02421, lr:1.48e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.223, tt:7050.015\n",
      "Ep:206, loss:0.00000, loss_test:0.02433, lr:1.47e-02, fs:0.79762 (r=0.677,p=0.971),  time:34.225, tt:7084.505\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13740, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:36.196, tt:36.196\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13517, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:35.428, tt:70.857\n",
      "Ep:2, loss:0.00027, loss_test:0.13143, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:36.047, tt:108.141\n",
      "Ep:3, loss:0.00026, loss_test:0.12694, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:35.626, tt:142.505\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00026, loss_test:0.12224, lr:1.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:35.382, tt:176.910\n",
      "Ep:5, loss:0.00025, loss_test:0.11915, lr:1.00e-02, fs:0.66667 (r=0.798,p=0.572),  time:35.613, tt:213.677\n",
      "Ep:6, loss:0.00024, loss_test:0.11727, lr:1.00e-02, fs:0.64935 (r=0.758,p=0.568),  time:35.525, tt:248.676\n",
      "Ep:7, loss:0.00024, loss_test:0.11555, lr:1.00e-02, fs:0.64602 (r=0.737,p=0.575),  time:35.447, tt:283.579\n",
      "Ep:8, loss:0.00023, loss_test:0.11390, lr:1.00e-02, fs:0.64865 (r=0.727,p=0.585),  time:35.475, tt:319.274\n",
      "Ep:9, loss:0.00023, loss_test:0.11140, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:35.660, tt:356.599\n",
      "Ep:10, loss:0.00022, loss_test:0.10948, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:35.822, tt:394.041\n",
      "Ep:11, loss:0.00022, loss_test:0.10791, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:36.075, tt:432.900\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10669, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:36.331, tt:472.303\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10582, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:36.550, tt:511.700\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10498, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:36.600, tt:549.004\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10340, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:36.677, tt:586.828\n",
      "Ep:16, loss:0.00019, loss_test:0.10210, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:36.712, tt:624.107\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10056, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:36.649, tt:659.683\n",
      "Ep:18, loss:0.00018, loss_test:0.09915, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:36.646, tt:696.279\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09822, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:36.647, tt:732.940\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09720, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:36.717, tt:771.052\n",
      "Ep:21, loss:0.00017, loss_test:0.09669, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:36.721, tt:807.859\n",
      "Ep:22, loss:0.00016, loss_test:0.09641, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:36.720, tt:844.570\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09555, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:36.748, tt:881.959\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09452, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:36.731, tt:918.267\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09463, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:36.758, tt:955.700\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09323, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:36.743, tt:992.053\n",
      "Ep:27, loss:0.00014, loss_test:0.09317, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:36.755, tt:1029.127\n",
      "Ep:28, loss:0.00014, loss_test:0.09232, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:36.740, tt:1065.462\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09098, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:36.700, tt:1100.986\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.09113, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:36.786, tt:1140.377\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08975, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:36.810, tt:1177.911\n",
      "Ep:32, loss:0.00012, loss_test:0.08823, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:36.805, tt:1214.567\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08834, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:36.771, tt:1250.213\n",
      "Ep:34, loss:0.00011, loss_test:0.08713, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:36.800, tt:1287.988\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.08728, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:36.821, tt:1325.555\n",
      "Ep:36, loss:0.00011, loss_test:0.08681, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:36.848, tt:1363.373\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08522, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:36.854, tt:1400.463\n",
      "Ep:38, loss:0.00010, loss_test:0.08753, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.838, tt:1436.674\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.08370, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:36.851, tt:1474.030\n",
      "Ep:40, loss:0.00010, loss_test:0.08800, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:36.844, tt:1510.622\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.08313, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:36.799, tt:1545.578\n",
      "Ep:42, loss:0.00009, loss_test:0.08471, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.813, tt:1582.950\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.08207, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:36.819, tt:1620.056\n",
      "Ep:44, loss:0.00008, loss_test:0.08525, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:36.816, tt:1656.708\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.08134, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:36.831, tt:1694.232\n",
      "Ep:46, loss:0.00008, loss_test:0.08232, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:36.833, tt:1731.151\n",
      "Ep:47, loss:0.00008, loss_test:0.08325, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:36.833, tt:1767.966\n",
      "Ep:48, loss:0.00007, loss_test:0.08126, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:36.842, tt:1805.241\n",
      "Ep:49, loss:0.00007, loss_test:0.08570, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:36.863, tt:1843.164\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.07823, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.861, tt:1879.915\n",
      "Ep:51, loss:0.00007, loss_test:0.08310, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.833, tt:1915.315\n",
      "Ep:52, loss:0.00007, loss_test:0.08225, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:36.861, tt:1953.649\n",
      "Ep:53, loss:0.00006, loss_test:0.07776, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.869, tt:1990.940\n",
      "Ep:54, loss:0.00006, loss_test:0.08350, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.846, tt:2026.556\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.07706, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:36.838, tt:2062.951\n",
      "Ep:56, loss:0.00006, loss_test:0.08403, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:36.833, tt:2099.461\n",
      "Ep:57, loss:0.00006, loss_test:0.07854, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.844, tt:2136.945\n",
      "Ep:58, loss:0.00006, loss_test:0.07923, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:36.827, tt:2172.814\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00005, loss_test:0.08376, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.823, tt:2209.360\n",
      "Ep:60, loss:0.00005, loss_test:0.07783, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:36.846, tt:2247.585\n",
      "Ep:61, loss:0.00005, loss_test:0.08200, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:36.871, tt:2286.021\n",
      "Ep:62, loss:0.00005, loss_test:0.07959, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:36.899, tt:2324.644\n",
      "Ep:63, loss:0.00005, loss_test:0.07728, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.905, tt:2361.947\n",
      "Ep:64, loss:0.00005, loss_test:0.08075, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.895, tt:2398.205\n",
      "Ep:65, loss:0.00004, loss_test:0.07529, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.891, tt:2434.776\n",
      "Ep:66, loss:0.00004, loss_test:0.07872, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.919, tt:2473.572\n",
      "Ep:67, loss:0.00004, loss_test:0.07768, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.907, tt:2509.694\n",
      "Ep:68, loss:0.00004, loss_test:0.07823, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:36.904, tt:2546.353\n",
      "Ep:69, loss:0.00004, loss_test:0.07617, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:36.914, tt:2583.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00004, loss_test:0.07753, lr:9.90e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.910, tt:2620.607\n",
      "Ep:71, loss:0.00004, loss_test:0.07813, lr:9.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.901, tt:2656.864\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00004, loss_test:0.07509, lr:9.80e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.889, tt:2692.914\n",
      "Ep:73, loss:0.00004, loss_test:0.07688, lr:9.80e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.876, tt:2728.805\n",
      "Ep:74, loss:0.00004, loss_test:0.08442, lr:9.80e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.855, tt:2764.109\n",
      "Ep:75, loss:0.00004, loss_test:0.07562, lr:9.80e-03, fs:0.83333 (r=0.808,p=0.860),  time:36.855, tt:2800.967\n",
      "Ep:76, loss:0.00005, loss_test:0.07969, lr:9.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.854, tt:2837.764\n",
      "Ep:77, loss:0.00004, loss_test:0.07743, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.848, tt:2874.130\n",
      "Ep:78, loss:0.00004, loss_test:0.07701, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.831, tt:2909.609\n",
      "Ep:79, loss:0.00004, loss_test:0.08229, lr:9.80e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.829, tt:2946.357\n",
      "Ep:80, loss:0.00004, loss_test:0.07673, lr:9.80e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.795, tt:2980.385\n",
      "Ep:81, loss:0.00004, loss_test:0.07876, lr:9.80e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.787, tt:3016.573\n",
      "Ep:82, loss:0.00003, loss_test:0.07567, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.779, tt:3052.677\n",
      "Ep:83, loss:0.00003, loss_test:0.07847, lr:9.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.789, tt:3090.267\n",
      "Ep:84, loss:0.00003, loss_test:0.07400, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.779, tt:3126.206\n",
      "Ep:85, loss:0.00003, loss_test:0.08056, lr:9.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.765, tt:3161.753\n",
      "Ep:86, loss:0.00003, loss_test:0.07337, lr:9.41e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.755, tt:3197.708\n",
      "Ep:87, loss:0.00003, loss_test:0.07682, lr:9.32e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.749, tt:3233.907\n",
      "Ep:88, loss:0.00003, loss_test:0.07529, lr:9.23e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.724, tt:3268.457\n",
      "Ep:89, loss:0.00003, loss_test:0.07484, lr:9.14e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.693, tt:3302.400\n",
      "Ep:90, loss:0.00003, loss_test:0.07503, lr:9.04e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.684, tt:3338.279\n",
      "Ep:91, loss:0.00003, loss_test:0.07389, lr:8.95e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.681, tt:3374.654\n",
      "Ep:92, loss:0.00002, loss_test:0.07508, lr:8.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.693, tt:3412.414\n",
      "Ep:93, loss:0.00002, loss_test:0.07463, lr:8.78e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.701, tt:3449.910\n",
      "Ep:94, loss:0.00002, loss_test:0.07326, lr:8.69e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.725, tt:3488.919\n",
      "Ep:95, loss:0.00002, loss_test:0.07518, lr:8.60e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.728, tt:3525.919\n",
      "Ep:96, loss:0.00002, loss_test:0.07334, lr:8.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.735, tt:3563.342\n",
      "Ep:97, loss:0.00002, loss_test:0.07521, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.755, tt:3601.953\n",
      "Ep:98, loss:0.00002, loss_test:0.07555, lr:8.35e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.746, tt:3637.887\n",
      "Ep:99, loss:0.00002, loss_test:0.07297, lr:8.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.748, tt:3674.755\n",
      "Ep:100, loss:0.00002, loss_test:0.07743, lr:8.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.740, tt:3710.742\n",
      "Ep:101, loss:0.00002, loss_test:0.07339, lr:8.10e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.741, tt:3747.596\n",
      "Ep:102, loss:0.00002, loss_test:0.07819, lr:8.02e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.742, tt:3784.439\n",
      "Ep:103, loss:0.00002, loss_test:0.07164, lr:7.94e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.759, tt:3822.982\n",
      "Ep:104, loss:0.00002, loss_test:0.07665, lr:7.86e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.765, tt:3860.283\n",
      "Ep:105, loss:0.00002, loss_test:0.07332, lr:7.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.757, tt:3896.238\n",
      "Ep:106, loss:0.00002, loss_test:0.07712, lr:7.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.770, tt:3934.372\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.07315, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.774, tt:3971.539\n",
      "Ep:108, loss:0.00002, loss_test:0.07781, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.775, tt:4008.526\n",
      "Ep:109, loss:0.00002, loss_test:0.07269, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.779, tt:4045.639\n",
      "Ep:110, loss:0.00002, loss_test:0.07573, lr:7.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.779, tt:4082.494\n",
      "Ep:111, loss:0.00002, loss_test:0.07367, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.786, tt:4120.002\n",
      "Ep:112, loss:0.00002, loss_test:0.07496, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.772, tt:4155.271\n",
      "Ep:113, loss:0.00002, loss_test:0.07254, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.763, tt:4190.947\n",
      "Ep:114, loss:0.00002, loss_test:0.07703, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.771, tt:4228.695\n",
      "Ep:115, loss:0.00002, loss_test:0.07264, lr:7.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.779, tt:4266.358\n",
      "Ep:116, loss:0.00002, loss_test:0.07429, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.776, tt:4302.816\n",
      "Ep:117, loss:0.00002, loss_test:0.07424, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.774, tt:4339.352\n",
      "Ep:118, loss:0.00002, loss_test:0.07410, lr:7.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.775, tt:4376.247\n",
      "Ep:119, loss:0.00002, loss_test:0.07316, lr:7.55e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.771, tt:4412.576\n",
      "Ep:120, loss:0.00002, loss_test:0.07569, lr:7.47e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.772, tt:4449.419\n",
      "Ep:121, loss:0.00002, loss_test:0.07198, lr:7.40e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.764, tt:4485.230\n",
      "Ep:122, loss:0.00002, loss_test:0.07674, lr:7.32e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.760, tt:4521.465\n",
      "Ep:123, loss:0.00002, loss_test:0.07236, lr:7.25e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.746, tt:4556.539\n",
      "Ep:124, loss:0.00002, loss_test:0.07581, lr:7.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.743, tt:4592.814\n",
      "Ep:125, loss:0.00002, loss_test:0.07359, lr:7.11e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.738, tt:4629.037\n",
      "Ep:126, loss:0.00002, loss_test:0.07642, lr:7.03e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.750, tt:4667.212\n",
      "Ep:127, loss:0.00002, loss_test:0.07238, lr:6.96e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.755, tt:4704.614\n",
      "Ep:128, loss:0.00002, loss_test:0.07636, lr:6.89e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.744, tt:4739.948\n",
      "Ep:129, loss:0.00001, loss_test:0.07206, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.724, tt:4774.172\n",
      "Ep:130, loss:0.00001, loss_test:0.07442, lr:6.76e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.721, tt:4810.462\n",
      "Ep:131, loss:0.00001, loss_test:0.07392, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.725, tt:4847.762\n",
      "Ep:132, loss:0.00001, loss_test:0.07208, lr:6.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.734, tt:4885.569\n",
      "Ep:133, loss:0.00001, loss_test:0.07536, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.739, tt:4923.077\n",
      "Ep:134, loss:0.00001, loss_test:0.07401, lr:6.49e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.749, tt:4961.056\n",
      "Ep:135, loss:0.00001, loss_test:0.07268, lr:6.43e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.751, tt:4998.167\n",
      "Ep:136, loss:0.00001, loss_test:0.07498, lr:6.36e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.751, tt:5034.895\n",
      "Ep:137, loss:0.00001, loss_test:0.07467, lr:6.30e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.751, tt:5071.640\n",
      "Ep:138, loss:0.00001, loss_test:0.07272, lr:6.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.760, tt:5109.663\n",
      "Ep:139, loss:0.00001, loss_test:0.07551, lr:6.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.750, tt:5144.938\n",
      "Ep:140, loss:0.00001, loss_test:0.07343, lr:6.11e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.742, tt:5180.585\n",
      "Ep:141, loss:0.00001, loss_test:0.07263, lr:6.05e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.742, tt:5217.433\n",
      "Ep:142, loss:0.00001, loss_test:0.07460, lr:5.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.740, tt:5253.892\n",
      "Ep:143, loss:0.00001, loss_test:0.07406, lr:5.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.743, tt:5290.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.07407, lr:5.87e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.739, tt:5327.118\n",
      "Ep:145, loss:0.00001, loss_test:0.07475, lr:5.81e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.737, tt:5363.563\n",
      "Ep:146, loss:0.00001, loss_test:0.07305, lr:5.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.733, tt:5399.743\n",
      "Ep:147, loss:0.00001, loss_test:0.07498, lr:5.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.732, tt:5436.406\n",
      "Ep:148, loss:0.00001, loss_test:0.07450, lr:5.64e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.733, tt:5473.276\n",
      "Ep:149, loss:0.00001, loss_test:0.07386, lr:5.58e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.733, tt:5510.015\n",
      "Ep:150, loss:0.00001, loss_test:0.07391, lr:5.53e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.717, tt:5544.295\n",
      "Ep:151, loss:0.00001, loss_test:0.07481, lr:5.47e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.724, tt:5582.003\n",
      "Ep:152, loss:0.00001, loss_test:0.07302, lr:5.42e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.725, tt:5618.946\n",
      "Ep:153, loss:0.00001, loss_test:0.07576, lr:5.36e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.738, tt:5657.687\n",
      "Ep:154, loss:0.00001, loss_test:0.07426, lr:5.31e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.730, tt:5693.114\n",
      "Ep:155, loss:0.00001, loss_test:0.07323, lr:5.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.732, tt:5730.146\n",
      "Ep:156, loss:0.00001, loss_test:0.07494, lr:5.20e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.735, tt:5767.393\n",
      "Ep:157, loss:0.00001, loss_test:0.07436, lr:5.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.746, tt:5805.888\n",
      "Ep:158, loss:0.00001, loss_test:0.07422, lr:5.10e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.752, tt:5843.563\n",
      "Ep:159, loss:0.00001, loss_test:0.07516, lr:5.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.759, tt:5881.463\n",
      "Ep:160, loss:0.00001, loss_test:0.07453, lr:5.00e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.771, tt:5920.080\n",
      "Ep:161, loss:0.00001, loss_test:0.07396, lr:4.95e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.773, tt:5957.185\n",
      "Ep:162, loss:0.00001, loss_test:0.07505, lr:4.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.774, tt:5994.084\n",
      "Ep:163, loss:0.00001, loss_test:0.07451, lr:4.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.778, tt:6031.635\n",
      "Ep:164, loss:0.00001, loss_test:0.07483, lr:4.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.779, tt:6068.573\n",
      "Ep:165, loss:0.00001, loss_test:0.07502, lr:4.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.786, tt:6106.412\n",
      "Ep:166, loss:0.00001, loss_test:0.07434, lr:4.71e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.789, tt:6143.728\n",
      "Ep:167, loss:0.00001, loss_test:0.07398, lr:4.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.811, tt:6184.225\n",
      "Ep:168, loss:0.00001, loss_test:0.07515, lr:4.61e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.806, tt:6220.163\n",
      "Ep:169, loss:0.00001, loss_test:0.07567, lr:4.57e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.819, tt:6259.206\n",
      "Ep:170, loss:0.00001, loss_test:0.07332, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.831, tt:6298.028\n",
      "Ep:171, loss:0.00001, loss_test:0.07579, lr:4.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.835, tt:6335.579\n",
      "Ep:172, loss:0.00001, loss_test:0.07538, lr:4.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.836, tt:6372.702\n",
      "Ep:173, loss:0.00001, loss_test:0.07355, lr:4.39e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.836, tt:6409.429\n",
      "Ep:174, loss:0.00001, loss_test:0.07506, lr:4.34e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.845, tt:6447.909\n",
      "Ep:175, loss:0.00001, loss_test:0.07592, lr:4.30e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.851, tt:6485.693\n",
      "Ep:176, loss:0.00001, loss_test:0.07462, lr:4.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.850, tt:6522.537\n",
      "Ep:177, loss:0.00001, loss_test:0.07491, lr:4.21e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.852, tt:6559.739\n",
      "Ep:178, loss:0.00001, loss_test:0.07474, lr:4.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.856, tt:6597.171\n",
      "Ep:179, loss:0.00001, loss_test:0.07516, lr:4.13e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.859, tt:6634.602\n",
      "Ep:180, loss:0.00001, loss_test:0.07459, lr:4.09e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.863, tt:6672.261\n",
      "Ep:181, loss:0.00001, loss_test:0.07523, lr:4.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.870, tt:6710.329\n",
      "Ep:182, loss:0.00001, loss_test:0.07489, lr:4.01e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.875, tt:6748.068\n",
      "Ep:183, loss:0.00001, loss_test:0.07499, lr:3.97e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.874, tt:6784.863\n",
      "Ep:184, loss:0.00001, loss_test:0.07538, lr:3.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.878, tt:6822.430\n",
      "Ep:185, loss:0.00001, loss_test:0.07510, lr:3.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.872, tt:6858.205\n",
      "Ep:186, loss:0.00001, loss_test:0.07492, lr:3.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.867, tt:6894.153\n",
      "Ep:187, loss:0.00001, loss_test:0.07500, lr:3.81e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.861, tt:6929.843\n",
      "Ep:188, loss:0.00001, loss_test:0.07548, lr:3.77e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.852, tt:6965.105\n",
      "Ep:189, loss:0.00001, loss_test:0.07518, lr:3.73e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.857, tt:7002.920\n",
      "Ep:190, loss:0.00001, loss_test:0.07551, lr:3.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.865, tt:7041.175\n",
      "Ep:191, loss:0.00001, loss_test:0.07505, lr:3.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.867, tt:7078.382\n",
      "Ep:192, loss:0.00001, loss_test:0.07569, lr:3.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.862, tt:7114.374\n",
      "Ep:193, loss:0.00001, loss_test:0.07515, lr:3.59e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.858, tt:7150.530\n",
      "Ep:194, loss:0.00001, loss_test:0.07599, lr:3.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.865, tt:7188.719\n",
      "Ep:195, loss:0.00001, loss_test:0.07517, lr:3.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.862, tt:7224.935\n",
      "Ep:196, loss:0.00001, loss_test:0.07472, lr:3.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.862, tt:7261.745\n",
      "Ep:197, loss:0.00001, loss_test:0.07662, lr:3.45e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.856, tt:7297.569\n",
      "Ep:198, loss:0.00001, loss_test:0.07625, lr:3.41e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.855, tt:7334.136\n",
      "Ep:199, loss:0.00001, loss_test:0.07451, lr:3.38e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.855, tt:7370.922\n",
      "Ep:200, loss:0.00001, loss_test:0.07644, lr:3.34e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.859, tt:7408.756\n",
      "Ep:201, loss:0.00001, loss_test:0.07679, lr:3.31e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.853, tt:7444.371\n",
      "Ep:202, loss:0.00001, loss_test:0.07557, lr:3.28e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.851, tt:7480.833\n",
      "Ep:203, loss:0.00001, loss_test:0.07529, lr:3.24e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.853, tt:7517.911\n",
      "Ep:204, loss:0.00001, loss_test:0.07613, lr:3.21e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.842, tt:7552.666\n",
      "Ep:205, loss:0.00001, loss_test:0.07667, lr:3.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.826, tt:7586.102\n",
      "Ep:206, loss:0.00001, loss_test:0.07562, lr:3.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.817, tt:7621.120\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02164, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:27.219, tt:27.219\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02492, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.559, tt:55.118\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02657, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.982, tt:86.947\n",
      "Ep:3, loss:0.00005, loss_test:0.02610, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.087, tt:120.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00005, loss_test:0.02458, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.083, tt:150.416\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02261, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:31.264, tt:187.585\n",
      "Ep:6, loss:0.00005, loss_test:0.02107, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:31.634, tt:221.439\n",
      "Ep:7, loss:0.00004, loss_test:0.02043, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:31.707, tt:253.655\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02015, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:32.156, tt:289.402\n",
      "Ep:9, loss:0.00004, loss_test:0.01999, lr:6.00e-02, fs:0.64754 (r=0.798,p=0.545),  time:32.554, tt:325.540\n",
      "Ep:10, loss:0.00004, loss_test:0.02037, lr:6.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:32.827, tt:361.095\n",
      "Ep:11, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:33.140, tt:397.686\n",
      "Ep:12, loss:0.00004, loss_test:0.02109, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:33.452, tt:434.876\n",
      "Ep:13, loss:0.00004, loss_test:0.02124, lr:6.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:33.725, tt:472.143\n",
      "Ep:14, loss:0.00004, loss_test:0.02130, lr:6.00e-02, fs:0.63636 (r=0.778,p=0.538),  time:33.883, tt:508.246\n",
      "Ep:15, loss:0.00004, loss_test:0.02104, lr:6.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:34.034, tt:544.549\n",
      "Ep:16, loss:0.00004, loss_test:0.02053, lr:6.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:34.119, tt:580.023\n",
      "Ep:17, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:34.190, tt:615.423\n",
      "Ep:18, loss:0.00003, loss_test:0.01986, lr:6.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:34.314, tt:651.972\n",
      "Ep:19, loss:0.00003, loss_test:0.01971, lr:5.94e-02, fs:0.64463 (r=0.788,p=0.545),  time:34.366, tt:687.321\n",
      "Ep:20, loss:0.00003, loss_test:0.01947, lr:5.88e-02, fs:0.64979 (r=0.778,p=0.558),  time:34.494, tt:724.378\n",
      "Ep:21, loss:0.00003, loss_test:0.01898, lr:5.82e-02, fs:0.66383 (r=0.788,p=0.574),  time:34.585, tt:760.878\n",
      "Ep:22, loss:0.00003, loss_test:0.01849, lr:5.76e-02, fs:0.67811 (r=0.798,p=0.590),  time:34.605, tt:795.909\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01819, lr:5.76e-02, fs:0.69027 (r=0.788,p=0.614),  time:34.728, tt:833.476\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01814, lr:5.76e-02, fs:0.69683 (r=0.778,p=0.631),  time:34.749, tt:868.736\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01803, lr:5.76e-02, fs:0.69725 (r=0.768,p=0.639),  time:34.792, tt:904.589\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01783, lr:5.76e-02, fs:0.69725 (r=0.768,p=0.639),  time:34.815, tt:940.017\n",
      "Ep:27, loss:0.00003, loss_test:0.01748, lr:5.76e-02, fs:0.69955 (r=0.788,p=0.629),  time:34.845, tt:975.667\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01744, lr:5.76e-02, fs:0.70000 (r=0.778,p=0.636),  time:34.859, tt:1010.924\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01759, lr:5.76e-02, fs:0.69767 (r=0.758,p=0.647),  time:34.913, tt:1047.381\n",
      "Ep:30, loss:0.00003, loss_test:0.01738, lr:5.76e-02, fs:0.70093 (r=0.758,p=0.652),  time:34.908, tt:1082.144\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01708, lr:5.76e-02, fs:0.71296 (r=0.778,p=0.658),  time:34.908, tt:1117.072\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01704, lr:5.76e-02, fs:0.70698 (r=0.768,p=0.655),  time:34.917, tt:1152.270\n",
      "Ep:33, loss:0.00002, loss_test:0.01705, lr:5.76e-02, fs:0.72727 (r=0.768,p=0.691),  time:34.896, tt:1186.449\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01702, lr:5.76e-02, fs:0.72464 (r=0.758,p=0.694),  time:34.991, tt:1224.668\n",
      "Ep:35, loss:0.00002, loss_test:0.01690, lr:5.76e-02, fs:0.73786 (r=0.768,p=0.710),  time:34.985, tt:1259.463\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01682, lr:5.76e-02, fs:0.74146 (r=0.768,p=0.717),  time:34.973, tt:1293.989\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01676, lr:5.76e-02, fs:0.74146 (r=0.768,p=0.717),  time:34.980, tt:1329.237\n",
      "Ep:38, loss:0.00002, loss_test:0.01667, lr:5.76e-02, fs:0.74146 (r=0.768,p=0.717),  time:35.012, tt:1365.452\n",
      "Ep:39, loss:0.00002, loss_test:0.01685, lr:5.76e-02, fs:0.75248 (r=0.768,p=0.738),  time:35.019, tt:1400.776\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01670, lr:5.76e-02, fs:0.75248 (r=0.768,p=0.738),  time:35.017, tt:1435.707\n",
      "Ep:41, loss:0.00002, loss_test:0.01653, lr:5.76e-02, fs:0.75248 (r=0.768,p=0.738),  time:35.004, tt:1470.178\n",
      "Ep:42, loss:0.00002, loss_test:0.01687, lr:5.76e-02, fs:0.75000 (r=0.758,p=0.743),  time:35.008, tt:1505.352\n",
      "Ep:43, loss:0.00002, loss_test:0.01676, lr:5.76e-02, fs:0.75622 (r=0.768,p=0.745),  time:35.054, tt:1542.395\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01657, lr:5.76e-02, fs:0.76238 (r=0.778,p=0.748),  time:35.046, tt:1577.067\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01683, lr:5.76e-02, fs:0.76142 (r=0.758,p=0.765),  time:35.055, tt:1612.546\n",
      "Ep:46, loss:0.00002, loss_test:0.01657, lr:5.76e-02, fs:0.77000 (r=0.778,p=0.762),  time:35.067, tt:1648.129\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01701, lr:5.76e-02, fs:0.76142 (r=0.758,p=0.765),  time:35.077, tt:1683.694\n",
      "Ep:48, loss:0.00002, loss_test:0.01672, lr:5.76e-02, fs:0.77157 (r=0.768,p=0.776),  time:35.096, tt:1719.709\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01670, lr:5.76e-02, fs:0.78173 (r=0.778,p=0.786),  time:35.101, tt:1755.033\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01718, lr:5.76e-02, fs:0.76923 (r=0.758,p=0.781),  time:35.123, tt:1791.298\n",
      "Ep:51, loss:0.00001, loss_test:0.01679, lr:5.76e-02, fs:0.77551 (r=0.768,p=0.784),  time:35.096, tt:1824.986\n",
      "Ep:52, loss:0.00001, loss_test:0.01687, lr:5.76e-02, fs:0.78173 (r=0.778,p=0.786),  time:35.138, tt:1862.338\n",
      "Ep:53, loss:0.00001, loss_test:0.01739, lr:5.76e-02, fs:0.76289 (r=0.747,p=0.779),  time:35.158, tt:1898.526\n",
      "Ep:54, loss:0.00001, loss_test:0.01709, lr:5.76e-02, fs:0.76289 (r=0.747,p=0.779),  time:35.189, tt:1935.409\n",
      "Ep:55, loss:0.00001, loss_test:0.01712, lr:5.76e-02, fs:0.78173 (r=0.778,p=0.786),  time:35.188, tt:1970.500\n",
      "Ep:56, loss:0.00001, loss_test:0.01773, lr:5.76e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.177, tt:2005.063\n",
      "Ep:57, loss:0.00001, loss_test:0.01734, lr:5.76e-02, fs:0.76684 (r=0.747,p=0.787),  time:35.204, tt:2041.807\n",
      "Ep:58, loss:0.00001, loss_test:0.01747, lr:5.76e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.227, tt:2078.369\n",
      "Ep:59, loss:0.00001, loss_test:0.01788, lr:5.76e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.240, tt:2114.408\n",
      "Ep:60, loss:0.00001, loss_test:0.01773, lr:5.76e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.242, tt:2149.743\n",
      "Ep:61, loss:0.00001, loss_test:0.01774, lr:5.71e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.256, tt:2185.894\n",
      "Ep:62, loss:0.00001, loss_test:0.01806, lr:5.65e-02, fs:0.76042 (r=0.737,p=0.785),  time:35.252, tt:2220.890\n",
      "Ep:63, loss:0.00001, loss_test:0.01812, lr:5.59e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.292, tt:2258.692\n",
      "Ep:64, loss:0.00001, loss_test:0.01817, lr:5.54e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.293, tt:2294.077\n",
      "Ep:65, loss:0.00001, loss_test:0.01838, lr:5.48e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.306, tt:2330.180\n",
      "Ep:66, loss:0.00001, loss_test:0.01844, lr:5.43e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.297, tt:2364.931\n",
      "Ep:67, loss:0.00001, loss_test:0.01840, lr:5.37e-02, fs:0.75648 (r=0.737,p=0.777),  time:35.289, tt:2399.655\n",
      "Ep:68, loss:0.00001, loss_test:0.01865, lr:5.32e-02, fs:0.75000 (r=0.727,p=0.774),  time:35.297, tt:2435.474\n",
      "Ep:69, loss:0.00001, loss_test:0.01875, lr:5.27e-02, fs:0.75000 (r=0.727,p=0.774),  time:35.299, tt:2470.921\n",
      "Ep:70, loss:0.00001, loss_test:0.01889, lr:5.21e-02, fs:0.75000 (r=0.727,p=0.774),  time:35.311, tt:2507.093\n",
      "Ep:71, loss:0.00001, loss_test:0.01881, lr:5.16e-02, fs:0.75000 (r=0.727,p=0.774),  time:35.292, tt:2541.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.01907, lr:5.11e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.283, tt:2575.664\n",
      "Ep:73, loss:0.00001, loss_test:0.01931, lr:5.06e-02, fs:0.75789 (r=0.727,p=0.791),  time:35.274, tt:2610.274\n",
      "Ep:74, loss:0.00001, loss_test:0.01888, lr:5.01e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.275, tt:2645.609\n",
      "Ep:75, loss:0.00001, loss_test:0.01973, lr:4.96e-02, fs:0.75789 (r=0.727,p=0.791),  time:35.277, tt:2681.032\n",
      "Ep:76, loss:0.00001, loss_test:0.01932, lr:4.91e-02, fs:0.75789 (r=0.727,p=0.791),  time:35.274, tt:2716.082\n",
      "Ep:77, loss:0.00001, loss_test:0.01946, lr:4.86e-02, fs:0.75789 (r=0.727,p=0.791),  time:35.275, tt:2751.426\n",
      "Ep:78, loss:0.00001, loss_test:0.01989, lr:4.81e-02, fs:0.76190 (r=0.727,p=0.800),  time:35.290, tt:2787.877\n",
      "Ep:79, loss:0.00001, loss_test:0.01973, lr:4.76e-02, fs:0.76190 (r=0.727,p=0.800),  time:35.289, tt:2823.140\n",
      "Ep:80, loss:0.00001, loss_test:0.01978, lr:4.71e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.310, tt:2860.112\n",
      "Ep:81, loss:0.00001, loss_test:0.02003, lr:4.67e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.334, tt:2897.419\n",
      "Ep:82, loss:0.00001, loss_test:0.02029, lr:4.62e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.350, tt:2934.019\n",
      "Ep:83, loss:0.00001, loss_test:0.02015, lr:4.57e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.346, tt:2969.030\n",
      "Ep:84, loss:0.00001, loss_test:0.02026, lr:4.53e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.327, tt:3002.772\n",
      "Ep:85, loss:0.00001, loss_test:0.02042, lr:4.48e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.284, tt:3034.415\n",
      "Ep:86, loss:0.00001, loss_test:0.02044, lr:4.44e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.297, tt:3070.795\n",
      "Ep:87, loss:0.00001, loss_test:0.02059, lr:4.39e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.288, tt:3105.342\n",
      "Ep:88, loss:0.00001, loss_test:0.02058, lr:4.35e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.291, tt:3140.885\n",
      "Ep:89, loss:0.00001, loss_test:0.02078, lr:4.31e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.307, tt:3177.634\n",
      "Ep:90, loss:0.00001, loss_test:0.02102, lr:4.26e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.318, tt:3213.941\n",
      "Ep:91, loss:0.00001, loss_test:0.02114, lr:4.22e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.313, tt:3248.814\n",
      "Ep:92, loss:0.00001, loss_test:0.02088, lr:4.18e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.309, tt:3283.755\n",
      "Ep:93, loss:0.00001, loss_test:0.02117, lr:4.14e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.323, tt:3320.353\n",
      "Ep:94, loss:0.00001, loss_test:0.02134, lr:4.10e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.338, tt:3357.077\n",
      "Ep:95, loss:0.00001, loss_test:0.02141, lr:4.05e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.329, tt:3391.627\n",
      "Ep:96, loss:0.00001, loss_test:0.02153, lr:4.01e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.333, tt:3427.291\n",
      "Ep:97, loss:0.00001, loss_test:0.02153, lr:3.97e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.323, tt:3461.672\n",
      "Ep:98, loss:0.00001, loss_test:0.02176, lr:3.93e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.325, tt:3497.136\n",
      "Ep:99, loss:0.00001, loss_test:0.02193, lr:3.89e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.331, tt:3533.132\n",
      "Ep:100, loss:0.00001, loss_test:0.02185, lr:3.86e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.316, tt:3566.959\n",
      "Ep:101, loss:0.00001, loss_test:0.02205, lr:3.82e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.316, tt:3602.199\n",
      "Ep:102, loss:0.00001, loss_test:0.02212, lr:3.78e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.308, tt:3636.722\n",
      "Ep:103, loss:0.00001, loss_test:0.02208, lr:3.74e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.301, tt:3671.325\n",
      "Ep:104, loss:0.00001, loss_test:0.02229, lr:3.70e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.304, tt:3706.880\n",
      "Ep:105, loss:0.00001, loss_test:0.02237, lr:3.67e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.290, tt:3740.792\n",
      "Ep:106, loss:0.00001, loss_test:0.02246, lr:3.63e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.277, tt:3774.643\n",
      "Ep:107, loss:0.00001, loss_test:0.02266, lr:3.59e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.280, tt:3810.278\n",
      "Ep:108, loss:0.00001, loss_test:0.02272, lr:3.56e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.292, tt:3846.777\n",
      "Ep:109, loss:0.00001, loss_test:0.02274, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.301, tt:3883.081\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.02266, lr:3.52e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.308, tt:3919.173\n",
      "Ep:111, loss:0.00001, loss_test:0.02297, lr:3.52e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.311, tt:3954.842\n",
      "Ep:112, loss:0.00001, loss_test:0.02302, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.311, tt:3990.168\n",
      "Ep:113, loss:0.00001, loss_test:0.02322, lr:3.52e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.320, tt:4026.468\n",
      "Ep:114, loss:0.00001, loss_test:0.02318, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.320, tt:4061.778\n",
      "Ep:115, loss:0.00001, loss_test:0.02302, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.310, tt:4095.982\n",
      "Ep:116, loss:0.00001, loss_test:0.02331, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.316, tt:4131.961\n",
      "Ep:117, loss:0.00000, loss_test:0.02347, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.330, tt:4168.903\n",
      "Ep:118, loss:0.00000, loss_test:0.02373, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.324, tt:4203.525\n",
      "Ep:119, loss:0.00000, loss_test:0.02348, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.311, tt:4237.376\n",
      "Ep:120, loss:0.00000, loss_test:0.02372, lr:3.52e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.299, tt:4271.139\n",
      "Ep:121, loss:0.00000, loss_test:0.02381, lr:3.49e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.305, tt:4307.238\n",
      "Ep:122, loss:0.00000, loss_test:0.02395, lr:3.45e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.315, tt:4343.742\n",
      "Ep:123, loss:0.00000, loss_test:0.02379, lr:3.42e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.326, tt:4380.387\n",
      "Ep:124, loss:0.00000, loss_test:0.02407, lr:3.38e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.322, tt:4415.194\n",
      "Ep:125, loss:0.00000, loss_test:0.02429, lr:3.35e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.333, tt:4452.001\n",
      "Ep:126, loss:0.00000, loss_test:0.02419, lr:3.32e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.326, tt:4486.454\n",
      "Ep:127, loss:0.00000, loss_test:0.02443, lr:3.28e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.320, tt:4520.925\n",
      "Ep:128, loss:0.00000, loss_test:0.02439, lr:3.25e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.313, tt:4555.412\n",
      "Ep:129, loss:0.00000, loss_test:0.02470, lr:3.22e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.307, tt:4589.899\n",
      "Ep:130, loss:0.00000, loss_test:0.02463, lr:3.19e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.295, tt:4623.682\n",
      "Ep:131, loss:0.00000, loss_test:0.02472, lr:3.15e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.290, tt:4658.333\n",
      "Ep:132, loss:0.00000, loss_test:0.02488, lr:3.12e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.286, tt:4693.050\n",
      "Ep:133, loss:0.00000, loss_test:0.02478, lr:3.09e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.293, tt:4729.293\n",
      "Ep:134, loss:0.00000, loss_test:0.02513, lr:3.06e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.299, tt:4765.355\n",
      "Ep:135, loss:0.00000, loss_test:0.02488, lr:3.03e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.302, tt:4801.099\n",
      "Ep:136, loss:0.00000, loss_test:0.02515, lr:3.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.308, tt:4837.236\n",
      "Ep:137, loss:0.00000, loss_test:0.02522, lr:2.97e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.321, tt:4874.324\n",
      "Ep:138, loss:0.00000, loss_test:0.02543, lr:2.94e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.323, tt:4909.844\n",
      "Ep:139, loss:0.00000, loss_test:0.02543, lr:2.91e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.328, tt:4945.851\n",
      "Ep:140, loss:0.00000, loss_test:0.02528, lr:2.88e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.330, tt:4981.516\n",
      "Ep:141, loss:0.00000, loss_test:0.02554, lr:2.85e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.332, tt:5017.134\n",
      "Ep:142, loss:0.00000, loss_test:0.02559, lr:2.82e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.330, tt:5052.196\n",
      "Ep:143, loss:0.00000, loss_test:0.02561, lr:2.80e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.334, tt:5088.139\n",
      "Ep:144, loss:0.00000, loss_test:0.02595, lr:2.77e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.335, tt:5123.602\n",
      "Ep:145, loss:0.00000, loss_test:0.02571, lr:2.74e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.341, tt:5159.841\n",
      "Ep:146, loss:0.00000, loss_test:0.02596, lr:2.71e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.346, tt:5195.895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.02606, lr:2.69e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.343, tt:5230.750\n",
      "Ep:148, loss:0.00000, loss_test:0.02594, lr:2.66e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.343, tt:5266.097\n",
      "Ep:149, loss:0.00000, loss_test:0.02612, lr:2.63e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.344, tt:5301.661\n",
      "Ep:150, loss:0.00000, loss_test:0.02630, lr:2.61e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.360, tt:5339.387\n",
      "Ep:151, loss:0.00000, loss_test:0.02637, lr:2.58e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.359, tt:5374.534\n",
      "Ep:152, loss:0.00000, loss_test:0.02627, lr:2.55e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.365, tt:5410.913\n",
      "Ep:153, loss:0.00000, loss_test:0.02640, lr:2.53e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.359, tt:5445.261\n",
      "Ep:154, loss:0.00000, loss_test:0.02646, lr:2.50e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.364, tt:5481.447\n",
      "Ep:155, loss:0.00000, loss_test:0.02665, lr:2.48e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.364, tt:5516.741\n",
      "Ep:156, loss:0.00000, loss_test:0.02654, lr:2.45e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.365, tt:5552.238\n",
      "Ep:157, loss:0.00000, loss_test:0.02668, lr:2.43e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.361, tt:5586.961\n",
      "Ep:158, loss:0.00000, loss_test:0.02678, lr:2.40e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.355, tt:5621.470\n",
      "Ep:159, loss:0.00000, loss_test:0.02686, lr:2.38e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.354, tt:5656.630\n",
      "Ep:160, loss:0.00000, loss_test:0.02687, lr:2.36e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.357, tt:5692.463\n",
      "Ep:161, loss:0.00000, loss_test:0.02690, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.356, tt:5727.652\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00000, loss_test:0.02706, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.362, tt:5763.952\n",
      "Ep:163, loss:0.00000, loss_test:0.02714, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.352, tt:5797.723\n",
      "Ep:164, loss:0.00000, loss_test:0.02725, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.373, tt:5836.487\n",
      "Ep:165, loss:0.00000, loss_test:0.02717, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.365, tt:5870.618\n",
      "Ep:166, loss:0.00000, loss_test:0.02726, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.361, tt:5905.223\n",
      "Ep:167, loss:0.00000, loss_test:0.02726, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.361, tt:5940.565\n",
      "Ep:168, loss:0.00000, loss_test:0.02746, lr:2.33e-02, fs:0.78453 (r=0.717,p=0.866),  time:35.352, tt:5974.421\n",
      "Ep:169, loss:0.00000, loss_test:0.02752, lr:2.33e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.349, tt:6009.335\n",
      "Ep:170, loss:0.00000, loss_test:0.02758, lr:2.33e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.354, tt:6045.471\n",
      "Ep:171, loss:0.00000, loss_test:0.02758, lr:2.33e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.345, tt:6079.362\n",
      "Ep:172, loss:0.00000, loss_test:0.02760, lr:2.33e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.345, tt:6114.770\n",
      "Ep:173, loss:0.00000, loss_test:0.02783, lr:2.31e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.344, tt:6149.933\n",
      "Ep:174, loss:0.00000, loss_test:0.02792, lr:2.29e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.342, tt:6184.936\n",
      "Ep:175, loss:0.00000, loss_test:0.02793, lr:2.26e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.346, tt:6220.912\n",
      "Ep:176, loss:0.00000, loss_test:0.02802, lr:2.24e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.336, tt:6254.525\n",
      "Ep:177, loss:0.00000, loss_test:0.02797, lr:2.22e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.332, tt:6289.114\n",
      "Ep:178, loss:0.00000, loss_test:0.02809, lr:2.20e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.325, tt:6323.217\n",
      "Ep:179, loss:0.00000, loss_test:0.02827, lr:2.17e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.339, tt:6361.030\n",
      "Ep:180, loss:0.00000, loss_test:0.02808, lr:2.15e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.337, tt:6395.981\n",
      "Ep:181, loss:0.00000, loss_test:0.02830, lr:2.13e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.342, tt:6432.159\n",
      "Ep:182, loss:0.00000, loss_test:0.02845, lr:2.11e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.331, tt:6465.651\n",
      "Ep:183, loss:0.00000, loss_test:0.02841, lr:2.09e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.333, tt:6501.246\n",
      "Ep:184, loss:0.00000, loss_test:0.02855, lr:2.07e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.333, tt:6536.539\n",
      "Ep:185, loss:0.00000, loss_test:0.02851, lr:2.05e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.327, tt:6570.878\n",
      "Ep:186, loss:0.00000, loss_test:0.02855, lr:2.03e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.317, tt:6604.269\n",
      "Ep:187, loss:0.00000, loss_test:0.02875, lr:2.01e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.318, tt:6639.772\n",
      "Ep:188, loss:0.00000, loss_test:0.02863, lr:1.99e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.312, tt:6673.964\n",
      "Ep:189, loss:0.00000, loss_test:0.02875, lr:1.97e-02, fs:0.78212 (r=0.707,p=0.875),  time:35.316, tt:6710.079\n",
      "Ep:190, loss:0.00000, loss_test:0.02881, lr:1.95e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.320, tt:6746.193\n",
      "Ep:191, loss:0.00000, loss_test:0.02888, lr:1.93e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.311, tt:6779.641\n",
      "Ep:192, loss:0.00000, loss_test:0.02890, lr:1.91e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.310, tt:6814.812\n",
      "Ep:193, loss:0.00000, loss_test:0.02892, lr:1.89e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.319, tt:6851.907\n",
      "Ep:194, loss:0.00000, loss_test:0.02904, lr:1.87e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.310, tt:6885.402\n",
      "Ep:195, loss:0.00000, loss_test:0.02908, lr:1.85e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.306, tt:6919.953\n",
      "Ep:196, loss:0.00000, loss_test:0.02908, lr:1.83e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.303, tt:6954.693\n",
      "Ep:197, loss:0.00000, loss_test:0.02925, lr:1.81e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.300, tt:6989.469\n",
      "Ep:198, loss:0.00000, loss_test:0.02921, lr:1.80e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.302, tt:7025.175\n",
      "Ep:199, loss:0.00000, loss_test:0.02918, lr:1.78e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.301, tt:7060.224\n",
      "Ep:200, loss:0.00000, loss_test:0.02933, lr:1.76e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.300, tt:7095.386\n",
      "Ep:201, loss:0.00000, loss_test:0.02935, lr:1.74e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.301, tt:7130.782\n",
      "Ep:202, loss:0.00000, loss_test:0.02941, lr:1.73e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.297, tt:7165.377\n",
      "Ep:203, loss:0.00000, loss_test:0.02949, lr:1.71e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.299, tt:7201.095\n",
      "Ep:204, loss:0.00000, loss_test:0.02948, lr:1.69e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.308, tt:7238.222\n",
      "Ep:205, loss:0.00000, loss_test:0.02955, lr:1.67e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.313, tt:7274.460\n",
      "Ep:206, loss:0.00000, loss_test:0.02969, lr:1.66e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.322, tt:7311.596\n",
      "Ep:207, loss:0.00000, loss_test:0.02953, lr:1.64e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.314, tt:7345.293\n",
      "Ep:208, loss:0.00000, loss_test:0.02965, lr:1.62e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.312, tt:7380.301\n",
      "Ep:209, loss:0.00000, loss_test:0.02978, lr:1.61e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.318, tt:7416.688\n",
      "Ep:210, loss:0.00000, loss_test:0.02968, lr:1.59e-02, fs:0.76836 (r=0.687,p=0.872),  time:35.312, tt:7450.800\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13600, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:32.967, tt:32.967\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13190, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:33.708, tt:67.416\n",
      "Ep:2, loss:0.00026, loss_test:0.12622, lr:1.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:33.274, tt:99.822\n",
      "Ep:3, loss:0.00026, loss_test:0.12094, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:32.733, tt:130.934\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11892, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:33.032, tt:165.158\n",
      "Ep:5, loss:0.00024, loss_test:0.11876, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:33.610, tt:201.661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00024, loss_test:0.11891, lr:1.00e-02, fs:0.64655 (r=0.758,p=0.564),  time:33.688, tt:235.814\n",
      "Ep:7, loss:0.00023, loss_test:0.11907, lr:1.00e-02, fs:0.65217 (r=0.758,p=0.573),  time:34.113, tt:272.904\n",
      "Ep:8, loss:0.00023, loss_test:0.11968, lr:1.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:33.985, tt:305.869\n",
      "Ep:9, loss:0.00022, loss_test:0.11966, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:34.324, tt:343.245\n",
      "Ep:10, loss:0.00021, loss_test:0.11908, lr:1.00e-02, fs:0.68519 (r=0.747,p=0.632),  time:34.582, tt:380.404\n",
      "Ep:11, loss:0.00021, loss_test:0.11818, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:34.892, tt:418.703\n",
      "Ep:12, loss:0.00020, loss_test:0.11704, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:34.965, tt:454.545\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.11547, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:35.010, tt:490.146\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.11284, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:35.163, tt:527.442\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10873, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:35.266, tt:564.251\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10653, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:35.438, tt:602.453\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10564, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:35.593, tt:640.673\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10196, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:35.692, tt:678.149\n",
      "Ep:19, loss:0.00016, loss_test:0.10191, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:35.726, tt:714.524\n",
      "Ep:20, loss:0.00016, loss_test:0.09861, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:35.823, tt:752.293\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09877, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:35.872, tt:789.186\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09669, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:35.912, tt:825.986\n",
      "Ep:23, loss:0.00014, loss_test:0.09957, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:35.975, tt:863.390\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09260, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:36.052, tt:901.306\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.09486, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:36.099, tt:938.570\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09385, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:36.152, tt:976.111\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.09039, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:36.201, tt:1013.639\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.09756, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:36.247, tt:1051.168\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08655, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:36.308, tt:1089.235\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.09354, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:36.369, tt:1127.440\n",
      "Ep:31, loss:0.00011, loss_test:0.08839, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:36.451, tt:1166.431\n",
      "Ep:32, loss:0.00010, loss_test:0.08770, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:36.496, tt:1204.362\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.08687, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:36.581, tt:1243.750\n",
      "Ep:34, loss:0.00009, loss_test:0.09251, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:36.588, tt:1280.567\n",
      "Ep:35, loss:0.00009, loss_test:0.08774, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:36.630, tt:1318.682\n",
      "Ep:36, loss:0.00009, loss_test:0.08657, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:36.666, tt:1356.634\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.08375, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.716, tt:1395.216\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.08739, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:36.775, tt:1434.243\n",
      "Ep:39, loss:0.00008, loss_test:0.08372, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:36.787, tt:1471.491\n",
      "Ep:40, loss:0.00008, loss_test:0.08235, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:36.776, tt:1507.803\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08530, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:36.799, tt:1545.550\n",
      "Ep:42, loss:0.00007, loss_test:0.08541, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:36.795, tt:1582.181\n",
      "Ep:43, loss:0.00007, loss_test:0.08765, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:36.796, tt:1619.037\n",
      "Ep:44, loss:0.00007, loss_test:0.08105, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:36.782, tt:1655.188\n",
      "Ep:45, loss:0.00006, loss_test:0.08243, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:36.778, tt:1691.796\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.07690, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:36.786, tt:1728.932\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.08487, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:36.835, tt:1768.092\n",
      "Ep:48, loss:0.00006, loss_test:0.08142, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:36.819, tt:1804.127\n",
      "Ep:49, loss:0.00007, loss_test:0.08474, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:36.840, tt:1842.021\n",
      "Ep:50, loss:0.00008, loss_test:0.09764, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:36.857, tt:1879.712\n",
      "Ep:51, loss:0.00007, loss_test:0.08472, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:36.893, tt:1918.456\n",
      "Ep:52, loss:0.00007, loss_test:0.08641, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:36.872, tt:1954.207\n",
      "Ep:53, loss:0.00006, loss_test:0.08026, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:36.861, tt:1990.508\n",
      "Ep:54, loss:0.00006, loss_test:0.08410, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:36.884, tt:2028.607\n",
      "Ep:55, loss:0.00006, loss_test:0.07764, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:36.875, tt:2064.987\n",
      "Ep:56, loss:0.00005, loss_test:0.08155, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:36.916, tt:2104.194\n",
      "Ep:57, loss:0.00005, loss_test:0.08071, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:36.932, tt:2142.050\n",
      "Ep:58, loss:0.00005, loss_test:0.07941, lr:9.90e-03, fs:0.80874 (r=0.747,p=0.881),  time:36.950, tt:2180.077\n",
      "Ep:59, loss:0.00005, loss_test:0.07388, lr:9.80e-03, fs:0.86911 (r=0.838,p=0.902),  time:36.952, tt:2217.132\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.07839, lr:9.80e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.958, tt:2254.415\n",
      "Ep:61, loss:0.00004, loss_test:0.07522, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:36.972, tt:2292.245\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.07318, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:36.992, tt:2330.510\n",
      "Ep:63, loss:0.00004, loss_test:0.07807, lr:9.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:37.006, tt:2368.360\n",
      "Ep:64, loss:0.00004, loss_test:0.07630, lr:9.80e-03, fs:0.86316 (r=0.828,p=0.901),  time:37.027, tt:2406.724\n",
      "Ep:65, loss:0.00004, loss_test:0.07598, lr:9.80e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.065, tt:2446.290\n",
      "Ep:66, loss:0.00004, loss_test:0.07330, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.103, tt:2485.881\n",
      "Ep:67, loss:0.00004, loss_test:0.07963, lr:9.80e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.093, tt:2522.348\n",
      "Ep:68, loss:0.00003, loss_test:0.07272, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:37.109, tt:2560.551\n",
      "Ep:69, loss:0.00003, loss_test:0.07807, lr:9.80e-03, fs:0.86911 (r=0.838,p=0.902),  time:37.102, tt:2597.110\n",
      "Ep:70, loss:0.00003, loss_test:0.07282, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:37.111, tt:2634.877\n",
      "Ep:71, loss:0.00003, loss_test:0.07634, lr:9.80e-03, fs:0.87234 (r=0.828,p=0.921),  time:37.121, tt:2672.723\n",
      "Ep:72, loss:0.00003, loss_test:0.07478, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:37.108, tt:2708.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00003, loss_test:0.07809, lr:9.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.092, tt:2744.819\n",
      "Ep:74, loss:0.00003, loss_test:0.07284, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:37.097, tt:2782.259\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00003, loss_test:0.08054, lr:9.61e-03, fs:0.86486 (r=0.808,p=0.930),  time:37.094, tt:2819.113\n",
      "Ep:76, loss:0.00003, loss_test:0.07380, lr:9.61e-03, fs:0.89005 (r=0.859,p=0.924),  time:37.089, tt:2855.867\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00003, loss_test:0.07483, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.112, tt:2894.772\n",
      "Ep:78, loss:0.00003, loss_test:0.08252, lr:9.61e-03, fs:0.86772 (r=0.828,p=0.911),  time:37.119, tt:2932.415\n",
      "Ep:79, loss:0.00003, loss_test:0.07691, lr:9.61e-03, fs:0.87701 (r=0.828,p=0.932),  time:37.115, tt:2969.210\n",
      "Ep:80, loss:0.00003, loss_test:0.07431, lr:9.61e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.122, tt:3006.898\n",
      "Ep:81, loss:0.00003, loss_test:0.08091, lr:9.61e-03, fs:0.87701 (r=0.828,p=0.932),  time:37.121, tt:3043.912\n",
      "Ep:82, loss:0.00003, loss_test:0.07163, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:37.110, tt:3080.099\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00003, loss_test:0.08197, lr:9.61e-03, fs:0.82286 (r=0.727,p=0.947),  time:37.100, tt:3116.382\n",
      "Ep:84, loss:0.00003, loss_test:0.07829, lr:9.61e-03, fs:0.84211 (r=0.808,p=0.879),  time:37.102, tt:3153.653\n",
      "Ep:85, loss:0.00003, loss_test:0.07908, lr:9.61e-03, fs:0.86813 (r=0.798,p=0.952),  time:37.099, tt:3190.556\n",
      "Ep:86, loss:0.00003, loss_test:0.07435, lr:9.61e-03, fs:0.83333 (r=0.758,p=0.926),  time:37.088, tt:3226.619\n",
      "Ep:87, loss:0.00003, loss_test:0.08442, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:37.083, tt:3263.262\n",
      "Ep:88, loss:0.00003, loss_test:0.08719, lr:9.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.086, tt:3300.636\n",
      "Ep:89, loss:0.00003, loss_test:0.07142, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:37.073, tt:3336.583\n",
      "Ep:90, loss:0.00003, loss_test:0.07941, lr:9.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:37.058, tt:3372.298\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.08250, lr:9.61e-03, fs:0.85106 (r=0.808,p=0.899),  time:37.031, tt:3406.814\n",
      "Ep:92, loss:0.00003, loss_test:0.07781, lr:9.61e-03, fs:0.88298 (r=0.838,p=0.933),  time:37.009, tt:3441.869\n",
      "Ep:93, loss:0.00003, loss_test:0.08571, lr:9.61e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.996, tt:3477.659\n",
      "Ep:94, loss:0.00002, loss_test:0.07446, lr:9.61e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.999, tt:3514.918\n",
      "Ep:95, loss:0.00002, loss_test:0.07531, lr:9.61e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.975, tt:3549.645\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.08243, lr:9.61e-03, fs:0.85246 (r=0.788,p=0.929),  time:36.973, tt:3586.426\n",
      "Ep:97, loss:0.00002, loss_test:0.07064, lr:9.61e-03, fs:0.90526 (r=0.869,p=0.945),  time:36.956, tt:3621.672\n",
      "Ep:98, loss:0.00002, loss_test:0.08279, lr:9.61e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.944, tt:3657.427\n",
      "Ep:99, loss:0.00002, loss_test:0.07830, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.925, tt:3692.515\n",
      "Ep:100, loss:0.00002, loss_test:0.07380, lr:9.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.906, tt:3727.509\n",
      "Ep:101, loss:0.00002, loss_test:0.08148, lr:9.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.912, tt:3765.055\n",
      "Ep:102, loss:0.00002, loss_test:0.07794, lr:9.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:36.890, tt:3799.714\n",
      "Ep:103, loss:0.00002, loss_test:0.08078, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.894, tt:3837.005\n",
      "Ep:104, loss:0.00002, loss_test:0.08007, lr:9.61e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.898, tt:3874.290\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.07918, lr:9.61e-03, fs:0.87831 (r=0.838,p=0.922),  time:36.876, tt:3908.908\n",
      "Ep:106, loss:0.00002, loss_test:0.07984, lr:9.61e-03, fs:0.89474 (r=0.859,p=0.934),  time:36.876, tt:3945.726\n",
      "Ep:107, loss:0.00002, loss_test:0.07836, lr:9.61e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.864, tt:3981.261\n",
      "Ep:108, loss:0.00002, loss_test:0.08180, lr:9.61e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.866, tt:4018.413\n",
      "Ep:109, loss:0.00002, loss_test:0.07862, lr:9.61e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.859, tt:4054.523\n",
      "Ep:110, loss:0.00002, loss_test:0.07471, lr:9.61e-03, fs:0.89947 (r=0.859,p=0.944),  time:36.858, tt:4091.287\n",
      "Ep:111, loss:0.00002, loss_test:0.08339, lr:9.61e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.851, tt:4127.294\n",
      "Ep:112, loss:0.00001, loss_test:0.07524, lr:9.61e-03, fs:0.91489 (r=0.869,p=0.966),  time:36.853, tt:4164.426\n",
      "Ep:113, loss:0.00001, loss_test:0.08156, lr:9.61e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.854, tt:4201.366\n",
      "Ep:114, loss:0.00002, loss_test:0.07814, lr:9.61e-03, fs:0.87778 (r=0.798,p=0.975),  time:36.835, tt:4235.986\n",
      "Ep:115, loss:0.00002, loss_test:0.07747, lr:9.61e-03, fs:0.90217 (r=0.838,p=0.976),  time:36.840, tt:4273.433\n",
      "Ep:116, loss:0.00001, loss_test:0.08348, lr:9.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.840, tt:4310.264\n",
      "Ep:117, loss:0.00001, loss_test:0.07773, lr:9.41e-03, fs:0.87432 (r=0.808,p=0.952),  time:36.861, tt:4349.606\n",
      "Ep:118, loss:0.00001, loss_test:0.08466, lr:9.32e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.848, tt:4384.868\n",
      "Ep:119, loss:0.00001, loss_test:0.07661, lr:9.23e-03, fs:0.92553 (r=0.879,p=0.978),  time:36.852, tt:4422.200\n",
      "Ep:120, loss:0.00001, loss_test:0.07898, lr:9.14e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.856, tt:4459.536\n",
      "Ep:121, loss:0.00001, loss_test:0.07876, lr:9.04e-03, fs:0.92063 (r=0.879,p=0.967),  time:36.851, tt:4495.774\n",
      "Ep:122, loss:0.00001, loss_test:0.08144, lr:8.95e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.839, tt:4531.257\n",
      "Ep:123, loss:0.00001, loss_test:0.07781, lr:8.86e-03, fs:0.93122 (r=0.889,p=0.978),  time:36.839, tt:4568.091\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.08024, lr:8.86e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.845, tt:4605.604\n",
      "Ep:125, loss:0.00001, loss_test:0.07535, lr:8.86e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.841, tt:4641.946\n",
      "Ep:126, loss:0.00001, loss_test:0.08252, lr:8.86e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.827, tt:4677.001\n",
      "Ep:127, loss:0.00001, loss_test:0.07785, lr:8.86e-03, fs:0.89947 (r=0.859,p=0.944),  time:36.828, tt:4713.920\n",
      "Ep:128, loss:0.00001, loss_test:0.07976, lr:8.86e-03, fs:0.92063 (r=0.879,p=0.967),  time:36.825, tt:4750.411\n",
      "Ep:129, loss:0.00001, loss_test:0.08278, lr:8.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.817, tt:4786.190\n",
      "Ep:130, loss:0.00001, loss_test:0.08121, lr:8.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:36.812, tt:4822.370\n",
      "Ep:131, loss:0.00001, loss_test:0.07829, lr:8.86e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.818, tt:4859.912\n",
      "Ep:132, loss:0.00001, loss_test:0.08188, lr:8.86e-03, fs:0.83429 (r=0.737,p=0.961),  time:36.807, tt:4895.290\n",
      "Ep:133, loss:0.00001, loss_test:0.08099, lr:8.86e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.789, tt:4929.733\n",
      "Ep:134, loss:0.00001, loss_test:0.08169, lr:8.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:36.780, tt:4965.311\n",
      "Ep:135, loss:0.00001, loss_test:0.08081, lr:8.78e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.787, tt:5003.015\n",
      "Ep:136, loss:0.00001, loss_test:0.08483, lr:8.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.789, tt:5040.026\n",
      "Ep:137, loss:0.00001, loss_test:0.08178, lr:8.60e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.787, tt:5076.579\n",
      "Ep:138, loss:0.00001, loss_test:0.08243, lr:8.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.773, tt:5111.429\n",
      "Ep:139, loss:0.00001, loss_test:0.08235, lr:8.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.762, tt:5146.613\n",
      "Ep:140, loss:0.00001, loss_test:0.08172, lr:8.35e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.763, tt:5183.553\n",
      "Ep:141, loss:0.00001, loss_test:0.08299, lr:8.26e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.769, tt:5221.192\n",
      "Ep:142, loss:0.00001, loss_test:0.08361, lr:8.18e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.769, tt:5257.986\n",
      "Ep:143, loss:0.00001, loss_test:0.08489, lr:8.10e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.773, tt:5295.296\n",
      "Ep:144, loss:0.00001, loss_test:0.08109, lr:8.02e-03, fs:0.91979 (r=0.869,p=0.977),  time:36.764, tt:5330.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.08680, lr:7.94e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.753, tt:5365.993\n",
      "Ep:146, loss:0.00001, loss_test:0.07903, lr:7.86e-03, fs:0.91979 (r=0.869,p=0.977),  time:36.756, tt:5403.060\n",
      "Ep:147, loss:0.00001, loss_test:0.08994, lr:7.78e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.753, tt:5439.440\n",
      "Ep:148, loss:0.00001, loss_test:0.08068, lr:7.70e-03, fs:0.89130 (r=0.828,p=0.965),  time:36.744, tt:5474.792\n",
      "Ep:149, loss:0.00001, loss_test:0.08806, lr:7.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.743, tt:5511.407\n",
      "Ep:150, loss:0.00001, loss_test:0.08379, lr:7.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.739, tt:5547.526\n",
      "Ep:151, loss:0.00001, loss_test:0.08217, lr:7.47e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.740, tt:5584.500\n",
      "Ep:152, loss:0.00001, loss_test:0.08889, lr:7.40e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.730, tt:5619.658\n",
      "Ep:153, loss:0.00001, loss_test:0.08171, lr:7.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:36.721, tt:5655.097\n",
      "Ep:154, loss:0.00001, loss_test:0.08585, lr:7.25e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.726, tt:5692.590\n",
      "Ep:155, loss:0.00001, loss_test:0.08611, lr:7.18e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.717, tt:5727.881\n",
      "Ep:156, loss:0.00001, loss_test:0.08630, lr:7.11e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.715, tt:5764.228\n",
      "Ep:157, loss:0.00001, loss_test:0.08622, lr:7.03e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.711, tt:5800.283\n",
      "Ep:158, loss:0.00001, loss_test:0.08426, lr:6.96e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.708, tt:5836.606\n",
      "Ep:159, loss:0.00001, loss_test:0.08975, lr:6.89e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.708, tt:5873.356\n",
      "Ep:160, loss:0.00001, loss_test:0.08494, lr:6.83e-03, fs:0.80000 (r=0.687,p=0.958),  time:36.701, tt:5908.864\n",
      "Ep:161, loss:0.00001, loss_test:0.08562, lr:6.76e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.690, tt:5943.711\n",
      "Ep:162, loss:0.00001, loss_test:0.08863, lr:6.69e-03, fs:0.79290 (r=0.677,p=0.957),  time:36.686, tt:5979.899\n",
      "Ep:163, loss:0.00001, loss_test:0.08592, lr:6.62e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.686, tt:6016.536\n",
      "Ep:164, loss:0.00001, loss_test:0.08729, lr:6.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.689, tt:6053.635\n",
      "Ep:165, loss:0.00001, loss_test:0.08741, lr:6.49e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.687, tt:6090.017\n",
      "Ep:166, loss:0.00001, loss_test:0.08666, lr:6.43e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.680, tt:6125.575\n",
      "Ep:167, loss:0.00001, loss_test:0.08998, lr:6.36e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.678, tt:6161.978\n",
      "Ep:168, loss:0.00001, loss_test:0.08527, lr:6.30e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.680, tt:6198.845\n",
      "Ep:169, loss:0.00001, loss_test:0.08698, lr:6.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.682, tt:6235.948\n",
      "Ep:170, loss:0.00001, loss_test:0.08894, lr:6.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.674, tt:6271.327\n",
      "Ep:171, loss:0.00001, loss_test:0.08691, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.672, tt:6307.507\n",
      "Ep:172, loss:0.00001, loss_test:0.08822, lr:6.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.686, tt:6346.646\n",
      "Ep:173, loss:0.00001, loss_test:0.08835, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.687, tt:6383.585\n",
      "Ep:174, loss:0.00001, loss_test:0.08838, lr:5.93e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.687, tt:6420.190\n",
      "Ep:175, loss:0.00001, loss_test:0.08920, lr:5.87e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.679, tt:6455.466\n",
      "Ep:176, loss:0.00001, loss_test:0.08895, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.672, tt:6490.936\n",
      "Ep:177, loss:0.00001, loss_test:0.08927, lr:5.75e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.668, tt:6526.987\n",
      "Ep:178, loss:0.00001, loss_test:0.08936, lr:5.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.665, tt:6563.037\n",
      "Ep:179, loss:0.00001, loss_test:0.08886, lr:5.64e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.664, tt:6599.556\n",
      "Ep:180, loss:0.00001, loss_test:0.08925, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.663, tt:6635.978\n",
      "Ep:181, loss:0.00001, loss_test:0.08951, lr:5.53e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.665, tt:6672.986\n",
      "Ep:182, loss:0.00001, loss_test:0.08935, lr:5.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.657, tt:6708.303\n",
      "Ep:183, loss:0.00001, loss_test:0.08887, lr:5.42e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.642, tt:6742.209\n",
      "Ep:184, loss:0.00001, loss_test:0.08929, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.640, tt:6778.331\n",
      "Ep:185, loss:0.00001, loss_test:0.08836, lr:5.31e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.641, tt:6815.239\n",
      "Ep:186, loss:0.00001, loss_test:0.09101, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.632, tt:6850.162\n",
      "Ep:187, loss:0.00001, loss_test:0.08800, lr:5.20e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.628, tt:6886.017\n",
      "Ep:188, loss:0.00001, loss_test:0.08921, lr:5.15e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.617, tt:6920.689\n",
      "Ep:189, loss:0.00001, loss_test:0.09041, lr:5.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.612, tt:6956.324\n",
      "Ep:190, loss:0.00001, loss_test:0.08878, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.612, tt:6992.931\n",
      "Ep:191, loss:0.00001, loss_test:0.09012, lr:5.00e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.624, tt:7031.719\n",
      "Ep:192, loss:0.00001, loss_test:0.08985, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.622, tt:7068.028\n",
      "Ep:193, loss:0.00001, loss_test:0.09100, lr:4.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.617, tt:7103.707\n",
      "Ep:194, loss:0.00001, loss_test:0.09124, lr:4.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.609, tt:7138.799\n",
      "Ep:195, loss:0.00001, loss_test:0.09000, lr:4.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.608, tt:7175.138\n",
      "Ep:196, loss:0.00001, loss_test:0.09056, lr:4.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.603, tt:7210.852\n",
      "Ep:197, loss:0.00001, loss_test:0.09041, lr:4.71e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.594, tt:7245.560\n",
      "Ep:198, loss:0.00001, loss_test:0.09148, lr:4.66e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.592, tt:7281.818\n",
      "Ep:199, loss:0.00001, loss_test:0.08992, lr:4.61e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.590, tt:7317.905\n",
      "Ep:200, loss:0.00001, loss_test:0.09224, lr:4.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.592, tt:7355.008\n",
      "Ep:201, loss:0.00001, loss_test:0.09111, lr:4.52e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.590, tt:7391.120\n",
      "Ep:202, loss:0.00001, loss_test:0.09107, lr:4.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.590, tt:7427.826\n",
      "Ep:203, loss:0.00001, loss_test:0.09051, lr:4.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.592, tt:7464.800\n",
      "Ep:204, loss:0.00001, loss_test:0.09133, lr:4.39e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.594, tt:7501.759\n",
      "Ep:205, loss:0.00001, loss_test:0.09112, lr:4.34e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.595, tt:7538.492\n",
      "Ep:206, loss:0.00001, loss_test:0.09140, lr:4.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.601, tt:7576.471\n",
      "Ep:207, loss:0.00001, loss_test:0.09240, lr:4.26e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.598, tt:7612.449\n",
      "Ep:208, loss:0.00001, loss_test:0.09099, lr:4.21e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.581, tt:7645.360\n",
      "Ep:209, loss:0.00001, loss_test:0.09119, lr:4.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.566, tt:7678.871\n",
      "Ep:210, loss:0.00001, loss_test:0.08999, lr:4.13e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.550, tt:7712.001\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02151, lr:6.00e-02, fs:0.63878 (r=0.848,p=0.512),  time:34.202, tt:34.202\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00005, loss_test:0.02492, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.662, tt:63.324\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02663, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.120, tt:90.361\n",
      "Ep:3, loss:0.00005, loss_test:0.02637, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.967, tt:119.868\n",
      "Ep:4, loss:0.00005, loss_test:0.02541, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.780, tt:153.900\n",
      "Ep:5, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:31.393, tt:188.360\n",
      "Ep:6, loss:0.00005, loss_test:0.02212, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:31.478, tt:220.345\n",
      "Ep:7, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:31.125, tt:248.997\n",
      "Ep:8, loss:0.00004, loss_test:0.02073, lr:6.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:31.210, tt:280.889\n",
      "Ep:9, loss:0.00004, loss_test:0.02063, lr:6.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:31.514, tt:315.140\n",
      "Ep:10, loss:0.00004, loss_test:0.02069, lr:6.00e-02, fs:0.64754 (r=0.798,p=0.545),  time:31.848, tt:350.324\n",
      "Ep:11, loss:0.00004, loss_test:0.02090, lr:6.00e-02, fs:0.65354 (r=0.838,p=0.535),  time:32.019, tt:384.222\n",
      "Ep:12, loss:0.00004, loss_test:0.02108, lr:6.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:32.313, tt:420.068\n",
      "Ep:13, loss:0.00004, loss_test:0.02112, lr:5.94e-02, fs:0.67220 (r=0.818,p=0.570),  time:32.472, tt:454.607\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02103, lr:5.94e-02, fs:0.67220 (r=0.818,p=0.570),  time:32.541, tt:488.113\n",
      "Ep:15, loss:0.00004, loss_test:0.02064, lr:5.94e-02, fs:0.65844 (r=0.808,p=0.556),  time:32.655, tt:522.480\n",
      "Ep:16, loss:0.00004, loss_test:0.02011, lr:5.94e-02, fs:0.67206 (r=0.838,p=0.561),  time:32.801, tt:557.610\n",
      "Ep:17, loss:0.00003, loss_test:0.01968, lr:5.94e-02, fs:0.67742 (r=0.848,p=0.564),  time:32.880, tt:591.842\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01925, lr:5.94e-02, fs:0.68293 (r=0.848,p=0.571),  time:32.944, tt:625.937\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01870, lr:5.94e-02, fs:0.69748 (r=0.838,p=0.597),  time:32.988, tt:659.761\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01806, lr:5.94e-02, fs:0.70042 (r=0.838,p=0.601),  time:33.045, tt:693.938\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01748, lr:5.94e-02, fs:0.71186 (r=0.848,p=0.613),  time:33.069, tt:727.508\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01680, lr:5.94e-02, fs:0.70588 (r=0.848,p=0.604),  time:33.136, tt:762.120\n",
      "Ep:23, loss:0.00003, loss_test:0.01630, lr:5.94e-02, fs:0.70886 (r=0.848,p=0.609),  time:33.172, tt:796.138\n",
      "Ep:24, loss:0.00003, loss_test:0.01602, lr:5.94e-02, fs:0.73043 (r=0.848,p=0.641),  time:33.242, tt:831.057\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01577, lr:5.94e-02, fs:0.73778 (r=0.838,p=0.659),  time:33.284, tt:865.372\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01540, lr:5.94e-02, fs:0.74667 (r=0.848,p=0.667),  time:33.327, tt:899.833\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01514, lr:5.94e-02, fs:0.74775 (r=0.838,p=0.675),  time:33.358, tt:934.025\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01499, lr:5.94e-02, fs:0.74654 (r=0.818,p=0.686),  time:33.455, tt:970.197\n",
      "Ep:29, loss:0.00003, loss_test:0.01484, lr:5.94e-02, fs:0.74654 (r=0.818,p=0.686),  time:33.524, tt:1005.721\n",
      "Ep:30, loss:0.00003, loss_test:0.01456, lr:5.94e-02, fs:0.76364 (r=0.848,p=0.694),  time:33.588, tt:1041.239\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01444, lr:5.94e-02, fs:0.77477 (r=0.869,p=0.699),  time:33.560, tt:1073.934\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01430, lr:5.94e-02, fs:0.77828 (r=0.869,p=0.705),  time:33.551, tt:1107.196\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01408, lr:5.94e-02, fs:0.79638 (r=0.889,p=0.721),  time:33.553, tt:1140.805\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01402, lr:5.94e-02, fs:0.79638 (r=0.889,p=0.721),  time:33.540, tt:1173.894\n",
      "Ep:35, loss:0.00002, loss_test:0.01391, lr:5.94e-02, fs:0.80909 (r=0.899,p=0.736),  time:33.546, tt:1207.649\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01377, lr:5.94e-02, fs:0.82192 (r=0.909,p=0.750),  time:33.568, tt:1242.021\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01365, lr:5.94e-02, fs:0.82243 (r=0.889,p=0.765),  time:33.549, tt:1274.853\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01364, lr:5.94e-02, fs:0.82243 (r=0.889,p=0.765),  time:33.512, tt:1306.981\n",
      "Ep:39, loss:0.00002, loss_test:0.01358, lr:5.94e-02, fs:0.82243 (r=0.889,p=0.765),  time:33.521, tt:1340.828\n",
      "Ep:40, loss:0.00002, loss_test:0.01359, lr:5.94e-02, fs:0.82629 (r=0.889,p=0.772),  time:33.488, tt:1373.022\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01367, lr:5.94e-02, fs:0.82629 (r=0.889,p=0.772),  time:33.489, tt:1406.518\n",
      "Ep:42, loss:0.00002, loss_test:0.01351, lr:5.94e-02, fs:0.82629 (r=0.889,p=0.772),  time:33.504, tt:1440.662\n",
      "Ep:43, loss:0.00002, loss_test:0.01350, lr:5.94e-02, fs:0.82629 (r=0.889,p=0.772),  time:33.515, tt:1474.656\n",
      "Ep:44, loss:0.00002, loss_test:0.01357, lr:5.94e-02, fs:0.83019 (r=0.889,p=0.779),  time:33.528, tt:1508.747\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01354, lr:5.94e-02, fs:0.83019 (r=0.889,p=0.779),  time:33.542, tt:1542.912\n",
      "Ep:46, loss:0.00002, loss_test:0.01359, lr:5.94e-02, fs:0.83412 (r=0.889,p=0.786),  time:33.550, tt:1576.847\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01364, lr:5.94e-02, fs:0.83412 (r=0.889,p=0.786),  time:33.567, tt:1611.203\n",
      "Ep:48, loss:0.00002, loss_test:0.01361, lr:5.94e-02, fs:0.82857 (r=0.879,p=0.784),  time:33.588, tt:1645.802\n",
      "Ep:49, loss:0.00002, loss_test:0.01377, lr:5.94e-02, fs:0.82857 (r=0.879,p=0.784),  time:33.614, tt:1680.693\n",
      "Ep:50, loss:0.00001, loss_test:0.01363, lr:5.94e-02, fs:0.82464 (r=0.879,p=0.777),  time:33.616, tt:1714.399\n",
      "Ep:51, loss:0.00001, loss_test:0.01389, lr:5.94e-02, fs:0.83254 (r=0.879,p=0.791),  time:33.640, tt:1749.291\n",
      "Ep:52, loss:0.00001, loss_test:0.01387, lr:5.94e-02, fs:0.83254 (r=0.879,p=0.791),  time:33.635, tt:1782.634\n",
      "Ep:53, loss:0.00001, loss_test:0.01383, lr:5.94e-02, fs:0.82857 (r=0.879,p=0.784),  time:33.679, tt:1818.654\n",
      "Ep:54, loss:0.00001, loss_test:0.01413, lr:5.94e-02, fs:0.83092 (r=0.869,p=0.796),  time:33.671, tt:1851.925\n",
      "Ep:55, loss:0.00001, loss_test:0.01412, lr:5.94e-02, fs:0.83654 (r=0.879,p=0.798),  time:33.703, tt:1887.384\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01420, lr:5.94e-02, fs:0.83654 (r=0.879,p=0.798),  time:33.755, tt:1924.040\n",
      "Ep:57, loss:0.00001, loss_test:0.01424, lr:5.94e-02, fs:0.83495 (r=0.869,p=0.804),  time:33.815, tt:1961.291\n",
      "Ep:58, loss:0.00001, loss_test:0.01442, lr:5.94e-02, fs:0.84878 (r=0.879,p=0.821),  time:33.852, tt:1997.295\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01462, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:33.891, tt:2033.459\n",
      "Ep:60, loss:0.00001, loss_test:0.01436, lr:5.94e-02, fs:0.84466 (r=0.879,p=0.813),  time:33.921, tt:2069.206\n",
      "Ep:61, loss:0.00001, loss_test:0.01454, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:33.933, tt:2103.829\n",
      "Ep:62, loss:0.00001, loss_test:0.01491, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:33.933, tt:2137.784\n",
      "Ep:63, loss:0.00001, loss_test:0.01496, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:33.979, tt:2174.639\n",
      "Ep:64, loss:0.00001, loss_test:0.01483, lr:5.94e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.040, tt:2212.578\n",
      "Ep:65, loss:0.00001, loss_test:0.01505, lr:5.94e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.053, tt:2247.513\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01508, lr:5.94e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.080, tt:2283.357\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.01526, lr:5.94e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.102, tt:2318.939\n",
      "Ep:68, loss:0.00001, loss_test:0.01517, lr:5.94e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.125, tt:2354.649\n",
      "Ep:69, loss:0.00001, loss_test:0.01530, lr:5.94e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.141, tt:2389.861\n",
      "Ep:70, loss:0.00001, loss_test:0.01542, lr:5.94e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.173, tt:2426.269\n",
      "Ep:71, loss:0.00001, loss_test:0.01560, lr:5.94e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.187, tt:2461.436\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01557, lr:5.94e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.232, tt:2498.958\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01578, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.227, tt:2532.795\n",
      "Ep:74, loss:0.00001, loss_test:0.01569, lr:5.94e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.234, tt:2567.570\n",
      "Ep:75, loss:0.00001, loss_test:0.01594, lr:5.94e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.263, tt:2603.981\n",
      "Ep:76, loss:0.00001, loss_test:0.01609, lr:5.94e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.276, tt:2639.255\n",
      "Ep:77, loss:0.00001, loss_test:0.01619, lr:5.94e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.302, tt:2675.545\n",
      "Ep:78, loss:0.00001, loss_test:0.01609, lr:5.94e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.337, tt:2712.651\n",
      "Ep:79, loss:0.00001, loss_test:0.01632, lr:5.94e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.355, tt:2748.430\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01608, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.388, tt:2785.391\n",
      "Ep:81, loss:0.00001, loss_test:0.01640, lr:5.94e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.413, tt:2821.904\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01652, lr:5.94e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.422, tt:2857.064\n",
      "Ep:83, loss:0.00001, loss_test:0.01686, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.438, tt:2892.752\n",
      "Ep:84, loss:0.00001, loss_test:0.01693, lr:5.94e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.463, tt:2929.387\n",
      "Ep:85, loss:0.00001, loss_test:0.01674, lr:5.94e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.482, tt:2965.429\n",
      "Ep:86, loss:0.00001, loss_test:0.01705, lr:5.94e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.471, tt:2998.945\n",
      "Ep:87, loss:0.00001, loss_test:0.01697, lr:5.94e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.471, tt:3033.448\n",
      "Ep:88, loss:0.00001, loss_test:0.01726, lr:5.94e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.498, tt:3070.313\n",
      "Ep:89, loss:0.00001, loss_test:0.01729, lr:5.94e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.512, tt:3106.081\n",
      "Ep:90, loss:0.00001, loss_test:0.01752, lr:5.94e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.509, tt:3140.292\n",
      "Ep:91, loss:0.00001, loss_test:0.01762, lr:5.94e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.508, tt:3174.725\n",
      "Ep:92, loss:0.00001, loss_test:0.01754, lr:5.94e-02, fs:0.86598 (r=0.848,p=0.884),  time:34.524, tt:3210.777\n",
      "Ep:93, loss:0.00001, loss_test:0.01751, lr:5.88e-02, fs:0.86000 (r=0.869,p=0.851),  time:34.554, tt:3248.061\n",
      "Ep:94, loss:0.00001, loss_test:0.01779, lr:5.82e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.570, tt:3284.173\n",
      "Ep:95, loss:0.00001, loss_test:0.01758, lr:5.76e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.585, tt:3320.125\n",
      "Ep:96, loss:0.00001, loss_test:0.01806, lr:5.71e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.586, tt:3354.837\n",
      "Ep:97, loss:0.00001, loss_test:0.01795, lr:5.65e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.589, tt:3389.740\n",
      "Ep:98, loss:0.00001, loss_test:0.01838, lr:5.59e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.604, tt:3425.843\n",
      "Ep:99, loss:0.00000, loss_test:0.01804, lr:5.54e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.617, tt:3461.734\n",
      "Ep:100, loss:0.00001, loss_test:0.01854, lr:5.48e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.629, tt:3497.513\n",
      "Ep:101, loss:0.00000, loss_test:0.01824, lr:5.43e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.641, tt:3533.424\n",
      "Ep:102, loss:0.00000, loss_test:0.01845, lr:5.37e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.648, tt:3568.783\n",
      "Ep:103, loss:0.00000, loss_test:0.01821, lr:5.32e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.655, tt:3604.155\n",
      "Ep:104, loss:0.00000, loss_test:0.01852, lr:5.27e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.681, tt:3641.522\n",
      "Ep:105, loss:0.00000, loss_test:0.01849, lr:5.21e-02, fs:0.84375 (r=0.818,p=0.871),  time:34.692, tt:3677.349\n",
      "Ep:106, loss:0.00000, loss_test:0.01860, lr:5.16e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.704, tt:3713.362\n",
      "Ep:107, loss:0.00000, loss_test:0.01862, lr:5.11e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.724, tt:3750.140\n",
      "Ep:108, loss:0.00000, loss_test:0.01907, lr:5.06e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.736, tt:3786.195\n",
      "Ep:109, loss:0.00000, loss_test:0.01890, lr:5.01e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.748, tt:3822.322\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.01885, lr:5.01e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.779, tt:3860.460\n",
      "Ep:111, loss:0.00000, loss_test:0.01905, lr:5.01e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.804, tt:3898.012\n",
      "Ep:112, loss:0.00000, loss_test:0.01917, lr:5.01e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.832, tt:3936.047\n",
      "Ep:113, loss:0.00000, loss_test:0.01961, lr:5.01e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.834, tt:3971.094\n",
      "Ep:114, loss:0.00000, loss_test:0.01930, lr:5.01e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.842, tt:4006.837\n",
      "Ep:115, loss:0.00000, loss_test:0.01969, lr:5.01e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.856, tt:4043.290\n",
      "Ep:116, loss:0.00000, loss_test:0.01970, lr:5.01e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.880, tt:4081.004\n",
      "Ep:117, loss:0.00000, loss_test:0.01981, lr:5.01e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.891, tt:4117.147\n",
      "Ep:118, loss:0.00000, loss_test:0.01980, lr:5.01e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.902, tt:4153.354\n",
      "Ep:119, loss:0.00000, loss_test:0.02000, lr:5.01e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.922, tt:4190.637\n",
      "Ep:120, loss:0.00000, loss_test:0.02006, lr:5.01e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.935, tt:4227.140\n",
      "Ep:121, loss:0.00000, loss_test:0.02014, lr:4.96e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.944, tt:4263.127\n",
      "Ep:122, loss:0.00000, loss_test:0.02016, lr:4.91e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.936, tt:4297.101\n",
      "Ep:123, loss:0.00000, loss_test:0.02031, lr:4.86e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.938, tt:4332.341\n",
      "Ep:124, loss:0.00000, loss_test:0.02036, lr:4.81e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.937, tt:4367.172\n",
      "Ep:125, loss:0.00000, loss_test:0.02037, lr:4.76e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.945, tt:4403.131\n",
      "Ep:126, loss:0.00000, loss_test:0.02062, lr:4.71e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.971, tt:4441.355\n",
      "Ep:127, loss:0.00000, loss_test:0.02035, lr:4.67e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.972, tt:4476.450\n",
      "Ep:128, loss:0.00000, loss_test:0.02071, lr:4.62e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.976, tt:4511.950\n",
      "Ep:129, loss:0.00000, loss_test:0.02061, lr:4.57e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.983, tt:4547.800\n",
      "Ep:130, loss:0.00000, loss_test:0.02079, lr:4.53e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.997, tt:4584.549\n",
      "Ep:131, loss:0.00000, loss_test:0.02064, lr:4.48e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.996, tt:4619.532\n",
      "Ep:132, loss:0.00000, loss_test:0.02102, lr:4.44e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.013, tt:4656.743\n",
      "Ep:133, loss:0.00000, loss_test:0.02092, lr:4.39e-02, fs:0.84153 (r=0.778,p=0.917),  time:35.017, tt:4692.315\n",
      "Ep:134, loss:0.00000, loss_test:0.02095, lr:4.35e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.012, tt:4726.554\n",
      "Ep:135, loss:0.00000, loss_test:0.02112, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.004, tt:4760.546\n",
      "Ep:136, loss:0.00000, loss_test:0.02111, lr:4.26e-02, fs:0.85870 (r=0.798,p=0.929),  time:35.009, tt:4796.177\n",
      "Ep:137, loss:0.00000, loss_test:0.02101, lr:4.22e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.004, tt:4830.563\n",
      "Ep:138, loss:0.00000, loss_test:0.02146, lr:4.18e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.002, tt:4865.329\n",
      "Ep:139, loss:0.00000, loss_test:0.02120, lr:4.14e-02, fs:0.83333 (r=0.758,p=0.926),  time:35.006, tt:4900.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.02143, lr:4.10e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.997, tt:4934.607\n",
      "Ep:141, loss:0.00000, loss_test:0.02134, lr:4.05e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.990, tt:4968.547\n",
      "Ep:142, loss:0.00000, loss_test:0.02162, lr:4.01e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.996, tt:5004.379\n",
      "Ep:143, loss:0.00000, loss_test:0.02157, lr:3.97e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.989, tt:5038.381\n",
      "Ep:144, loss:0.00000, loss_test:0.02165, lr:3.93e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.973, tt:5071.140\n",
      "Ep:145, loss:0.00000, loss_test:0.02158, lr:3.89e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.971, tt:5105.834\n",
      "Ep:146, loss:0.00000, loss_test:0.02193, lr:3.86e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.968, tt:5140.308\n",
      "Ep:147, loss:0.00000, loss_test:0.02175, lr:3.82e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.959, tt:5173.944\n",
      "Ep:148, loss:0.00000, loss_test:0.02196, lr:3.78e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.958, tt:5208.700\n",
      "Ep:149, loss:0.00000, loss_test:0.02181, lr:3.74e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.961, tt:5244.126\n",
      "Ep:150, loss:0.00000, loss_test:0.02222, lr:3.70e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.945, tt:5276.696\n",
      "Ep:151, loss:0.00000, loss_test:0.02194, lr:3.67e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.937, tt:5310.411\n",
      "Ep:152, loss:0.00000, loss_test:0.02219, lr:3.63e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.929, tt:5344.159\n",
      "Ep:153, loss:0.00000, loss_test:0.02209, lr:3.59e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.925, tt:5378.438\n",
      "Ep:154, loss:0.00000, loss_test:0.02219, lr:3.56e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.918, tt:5412.353\n",
      "Ep:155, loss:0.00000, loss_test:0.02244, lr:3.52e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.908, tt:5445.712\n",
      "Ep:156, loss:0.00000, loss_test:0.02217, lr:3.49e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.899, tt:5479.120\n",
      "Ep:157, loss:0.00000, loss_test:0.02247, lr:3.45e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.893, tt:5513.044\n",
      "Ep:158, loss:0.00000, loss_test:0.02222, lr:3.42e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.894, tt:5548.163\n",
      "Ep:159, loss:0.00000, loss_test:0.02261, lr:3.38e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.887, tt:5581.968\n",
      "Ep:160, loss:0.00000, loss_test:0.02245, lr:3.35e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.876, tt:5614.980\n",
      "Ep:161, loss:0.00000, loss_test:0.02272, lr:3.32e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.879, tt:5650.457\n",
      "Ep:162, loss:0.00000, loss_test:0.02248, lr:3.28e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.875, tt:5684.553\n",
      "Ep:163, loss:0.00000, loss_test:0.02291, lr:3.25e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.863, tt:5717.476\n",
      "Ep:164, loss:0.00000, loss_test:0.02258, lr:3.22e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.857, tt:5751.438\n",
      "Ep:165, loss:0.00000, loss_test:0.02283, lr:3.19e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.868, tt:5788.154\n",
      "Ep:166, loss:0.00000, loss_test:0.02267, lr:3.15e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.870, tt:5823.237\n",
      "Ep:167, loss:0.00000, loss_test:0.02284, lr:3.12e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.861, tt:5856.657\n",
      "Ep:168, loss:0.00000, loss_test:0.02290, lr:3.09e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.855, tt:5890.496\n",
      "Ep:169, loss:0.00000, loss_test:0.02289, lr:3.06e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.850, tt:5924.507\n",
      "Ep:170, loss:0.00000, loss_test:0.02282, lr:3.03e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.844, tt:5958.352\n",
      "Ep:171, loss:0.00000, loss_test:0.02306, lr:3.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.842, tt:5992.832\n",
      "Ep:172, loss:0.00000, loss_test:0.02298, lr:2.97e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.838, tt:6027.001\n",
      "Ep:173, loss:0.00000, loss_test:0.02326, lr:2.94e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.836, tt:6061.429\n",
      "Ep:174, loss:0.00000, loss_test:0.02312, lr:2.91e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.833, tt:6095.708\n",
      "Ep:175, loss:0.00000, loss_test:0.02326, lr:2.88e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.839, tt:6131.692\n",
      "Ep:176, loss:0.00000, loss_test:0.02312, lr:2.85e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.834, tt:6165.620\n",
      "Ep:177, loss:0.00000, loss_test:0.02337, lr:2.82e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.827, tt:6199.214\n",
      "Ep:178, loss:0.00000, loss_test:0.02320, lr:2.80e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.826, tt:6233.941\n",
      "Ep:179, loss:0.00000, loss_test:0.02336, lr:2.77e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.834, tt:6270.155\n",
      "Ep:180, loss:0.00000, loss_test:0.02327, lr:2.74e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.835, tt:6305.086\n",
      "Ep:181, loss:0.00000, loss_test:0.02344, lr:2.71e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.838, tt:6340.465\n",
      "Ep:182, loss:0.00000, loss_test:0.02337, lr:2.69e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.845, tt:6376.600\n",
      "Ep:183, loss:0.00000, loss_test:0.02359, lr:2.66e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.851, tt:6412.664\n",
      "Ep:184, loss:0.00000, loss_test:0.02341, lr:2.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.846, tt:6446.476\n",
      "Ep:185, loss:0.00000, loss_test:0.02362, lr:2.61e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.837, tt:6479.711\n",
      "Ep:186, loss:0.00000, loss_test:0.02351, lr:2.58e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.838, tt:6514.678\n",
      "Ep:187, loss:0.00000, loss_test:0.02372, lr:2.55e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.841, tt:6550.090\n",
      "Ep:188, loss:0.00000, loss_test:0.02361, lr:2.53e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.834, tt:6583.606\n",
      "Ep:189, loss:0.00000, loss_test:0.02372, lr:2.50e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.844, tt:6620.290\n",
      "Ep:190, loss:0.00000, loss_test:0.02379, lr:2.48e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.839, tt:6654.192\n",
      "Ep:191, loss:0.00000, loss_test:0.02383, lr:2.45e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.831, tt:6687.539\n",
      "Ep:192, loss:0.00000, loss_test:0.02375, lr:2.43e-02, fs:0.81818 (r=0.727,p=0.935),  time:34.823, tt:6720.899\n",
      "Ep:193, loss:0.00000, loss_test:0.02377, lr:2.40e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.822, tt:6755.417\n",
      "Ep:194, loss:0.00000, loss_test:0.02385, lr:2.38e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.824, tt:6790.772\n",
      "Ep:195, loss:0.00000, loss_test:0.02389, lr:2.36e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.827, tt:6826.188\n",
      "Ep:196, loss:0.00000, loss_test:0.02402, lr:2.33e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.823, tt:6860.212\n",
      "Ep:197, loss:0.00000, loss_test:0.02395, lr:2.31e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.822, tt:6894.671\n",
      "Ep:198, loss:0.00000, loss_test:0.02399, lr:2.29e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.830, tt:6931.114\n",
      "Ep:199, loss:0.00000, loss_test:0.02400, lr:2.26e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.826, tt:6965.209\n",
      "Ep:200, loss:0.00000, loss_test:0.02397, lr:2.24e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.818, tt:6998.488\n",
      "Ep:201, loss:0.00000, loss_test:0.02409, lr:2.22e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.827, tt:7035.111\n",
      "Ep:202, loss:0.00000, loss_test:0.02400, lr:2.20e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.824, tt:7069.293\n",
      "Ep:203, loss:0.00000, loss_test:0.02414, lr:2.17e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.814, tt:7102.044\n",
      "Ep:204, loss:0.00000, loss_test:0.02410, lr:2.15e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.827, tt:7139.462\n",
      "Ep:205, loss:0.00000, loss_test:0.02414, lr:2.13e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.823, tt:7173.459\n",
      "Ep:206, loss:0.00000, loss_test:0.02406, lr:2.11e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.825, tt:7208.694\n",
      "Ep:207, loss:0.00000, loss_test:0.02426, lr:2.09e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.819, tt:7242.361\n",
      "Ep:208, loss:0.00000, loss_test:0.02416, lr:2.07e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.829, tt:7279.175\n",
      "Ep:209, loss:0.00000, loss_test:0.02426, lr:2.05e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.820, tt:7312.189\n",
      "Ep:210, loss:0.00000, loss_test:0.02431, lr:2.03e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.819, tt:7346.780\n",
      "Ep:211, loss:0.00000, loss_test:0.02421, lr:2.01e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.814, tt:7380.537\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14075, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.908, tt:31.908\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13919, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.275, tt:64.549\n",
      "Ep:2, loss:0.00028, loss_test:0.13628, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:31.849, tt:95.548\n",
      "Ep:3, loss:0.00027, loss_test:0.13161, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:32.616, tt:130.465\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12657, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:33.527, tt:167.637\n",
      "Ep:5, loss:0.00026, loss_test:0.12281, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:33.733, tt:202.400\n",
      "Ep:6, loss:0.00025, loss_test:0.12069, lr:1.00e-02, fs:0.65217 (r=0.758,p=0.573),  time:33.837, tt:236.859\n",
      "Ep:7, loss:0.00025, loss_test:0.11961, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:33.549, tt:268.393\n",
      "Ep:8, loss:0.00024, loss_test:0.11900, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:33.581, tt:302.227\n",
      "Ep:9, loss:0.00024, loss_test:0.11826, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:33.924, tt:339.236\n",
      "Ep:10, loss:0.00023, loss_test:0.11788, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:34.055, tt:374.607\n",
      "Ep:11, loss:0.00023, loss_test:0.11743, lr:1.00e-02, fs:0.66063 (r=0.737,p=0.598),  time:34.249, tt:410.990\n",
      "Ep:12, loss:0.00022, loss_test:0.11620, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:34.289, tt:445.758\n",
      "Ep:13, loss:0.00022, loss_test:0.11485, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:34.174, tt:478.442\n",
      "Ep:14, loss:0.00021, loss_test:0.11344, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:34.462, tt:516.936\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.11166, lr:1.00e-02, fs:0.69231 (r=0.727,p=0.661),  time:34.566, tt:553.056\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.11084, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:34.687, tt:589.675\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10975, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:34.815, tt:626.675\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.10779, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:34.804, tt:661.280\n",
      "Ep:19, loss:0.00018, loss_test:0.10686, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:34.845, tt:696.895\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.10466, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:34.930, tt:733.540\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.10174, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:34.966, tt:769.255\n",
      "Ep:22, loss:0.00017, loss_test:0.10130, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:34.901, tt:802.714\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.09824, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:34.836, tt:836.071\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09846, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.910, tt:872.762\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.09560, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.971, tt:909.241\n",
      "Ep:26, loss:0.00015, loss_test:0.09373, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:35.078, tt:947.093\n",
      "Ep:27, loss:0.00015, loss_test:0.09715, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:35.106, tt:982.969\n",
      "Ep:28, loss:0.00015, loss_test:0.09031, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:35.183, tt:1020.299\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09240, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:35.299, tt:1058.959\n",
      "Ep:30, loss:0.00014, loss_test:0.08950, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:35.291, tt:1094.010\n",
      "Ep:31, loss:0.00013, loss_test:0.09103, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:35.317, tt:1130.133\n",
      "Ep:32, loss:0.00013, loss_test:0.09237, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.374, tt:1167.336\n",
      "Ep:33, loss:0.00013, loss_test:0.08835, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:35.416, tt:1204.158\n",
      "Ep:34, loss:0.00012, loss_test:0.09445, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.408, tt:1239.289\n",
      "Ep:35, loss:0.00012, loss_test:0.08799, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:35.421, tt:1275.148\n",
      "Ep:36, loss:0.00011, loss_test:0.09051, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:35.447, tt:1311.555\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08861, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:35.483, tt:1348.360\n",
      "Ep:38, loss:0.00011, loss_test:0.08790, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:35.523, tt:1385.392\n",
      "Ep:39, loss:0.00010, loss_test:0.09661, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:35.549, tt:1421.972\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08532, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:35.569, tt:1458.311\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.09543, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:35.597, tt:1495.066\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.08469, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:35.586, tt:1530.214\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.08718, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:35.569, tt:1565.018\n",
      "Ep:44, loss:0.00009, loss_test:0.08649, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:35.593, tt:1601.669\n",
      "Ep:45, loss:0.00008, loss_test:0.08543, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:35.603, tt:1637.730\n",
      "Ep:46, loss:0.00008, loss_test:0.08687, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:35.611, tt:1673.705\n",
      "Ep:47, loss:0.00008, loss_test:0.08649, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:35.620, tt:1709.772\n",
      "Ep:48, loss:0.00007, loss_test:0.08529, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:35.648, tt:1746.766\n",
      "Ep:49, loss:0.00007, loss_test:0.08720, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:35.681, tt:1784.074\n",
      "Ep:50, loss:0.00007, loss_test:0.08265, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:35.684, tt:1819.874\n",
      "Ep:51, loss:0.00007, loss_test:0.09329, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.701, tt:1856.456\n",
      "Ep:52, loss:0.00007, loss_test:0.08165, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:35.727, tt:1893.555\n",
      "Ep:53, loss:0.00007, loss_test:0.08437, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.745, tt:1930.247\n",
      "Ep:54, loss:0.00007, loss_test:0.08427, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:35.768, tt:1967.222\n",
      "Ep:55, loss:0.00006, loss_test:0.08150, lr:9.80e-03, fs:0.82292 (r=0.798,p=0.849),  time:35.806, tt:2005.125\n",
      "Ep:56, loss:0.00006, loss_test:0.08120, lr:9.70e-03, fs:0.82587 (r=0.838,p=0.814),  time:35.856, tt:2043.799\n",
      "Ep:57, loss:0.00006, loss_test:0.07819, lr:9.61e-03, fs:0.79793 (r=0.778,p=0.819),  time:35.825, tt:2077.842\n",
      "Ep:58, loss:0.00006, loss_test:0.08713, lr:9.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.831, tt:2114.056\n",
      "Ep:59, loss:0.00006, loss_test:0.07972, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:35.845, tt:2150.725\n",
      "Ep:60, loss:0.00006, loss_test:0.08357, lr:9.32e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.826, tt:2185.369\n",
      "Ep:61, loss:0.00006, loss_test:0.07989, lr:9.23e-03, fs:0.80851 (r=0.768,p=0.854),  time:35.849, tt:2222.611\n",
      "Ep:62, loss:0.00005, loss_test:0.08004, lr:9.14e-03, fs:0.83417 (r=0.838,p=0.830),  time:35.862, tt:2259.307\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.07958, lr:9.14e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.860, tt:2295.065\n",
      "Ep:64, loss:0.00005, loss_test:0.08219, lr:9.14e-03, fs:0.81720 (r=0.768,p=0.874),  time:35.860, tt:2330.922\n",
      "Ep:65, loss:0.00005, loss_test:0.07670, lr:9.14e-03, fs:0.84000 (r=0.848,p=0.832),  time:35.858, tt:2366.617\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.07897, lr:9.14e-03, fs:0.83243 (r=0.778,p=0.895),  time:35.848, tt:2401.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00005, loss_test:0.07554, lr:9.14e-03, fs:0.83598 (r=0.798,p=0.878),  time:35.868, tt:2438.999\n",
      "Ep:68, loss:0.00004, loss_test:0.07883, lr:9.14e-03, fs:0.85279 (r=0.848,p=0.857),  time:35.870, tt:2474.997\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.07628, lr:9.14e-03, fs:0.82105 (r=0.788,p=0.857),  time:35.896, tt:2512.699\n",
      "Ep:70, loss:0.00004, loss_test:0.08254, lr:9.14e-03, fs:0.81720 (r=0.768,p=0.874),  time:35.909, tt:2549.537\n",
      "Ep:71, loss:0.00004, loss_test:0.07806, lr:9.14e-03, fs:0.83000 (r=0.838,p=0.822),  time:35.910, tt:2585.501\n",
      "Ep:72, loss:0.00005, loss_test:0.07832, lr:9.14e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.903, tt:2620.916\n",
      "Ep:73, loss:0.00005, loss_test:0.07367, lr:9.14e-03, fs:0.87310 (r=0.869,p=0.878),  time:35.909, tt:2657.264\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.07345, lr:9.14e-03, fs:0.89340 (r=0.889,p=0.898),  time:35.926, tt:2694.433\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00004, loss_test:0.07537, lr:9.14e-03, fs:0.82105 (r=0.788,p=0.857),  time:35.944, tt:2731.772\n",
      "Ep:76, loss:0.00004, loss_test:0.07440, lr:9.14e-03, fs:0.85279 (r=0.848,p=0.857),  time:35.939, tt:2767.303\n",
      "Ep:77, loss:0.00004, loss_test:0.07616, lr:9.14e-03, fs:0.82796 (r=0.778,p=0.885),  time:35.933, tt:2802.751\n",
      "Ep:78, loss:0.00004, loss_test:0.07331, lr:9.14e-03, fs:0.86294 (r=0.859,p=0.867),  time:35.962, tt:2840.986\n",
      "Ep:79, loss:0.00004, loss_test:0.07579, lr:9.14e-03, fs:0.83243 (r=0.778,p=0.895),  time:35.972, tt:2877.774\n",
      "Ep:80, loss:0.00004, loss_test:0.07379, lr:9.14e-03, fs:0.88442 (r=0.889,p=0.880),  time:35.974, tt:2913.925\n",
      "Ep:81, loss:0.00003, loss_test:0.07320, lr:9.14e-03, fs:0.88889 (r=0.889,p=0.889),  time:35.982, tt:2950.503\n",
      "Ep:82, loss:0.00003, loss_test:0.07340, lr:9.14e-03, fs:0.83158 (r=0.798,p=0.868),  time:35.986, tt:2986.820\n",
      "Ep:83, loss:0.00003, loss_test:0.07541, lr:9.14e-03, fs:0.86598 (r=0.848,p=0.884),  time:35.991, tt:3023.232\n",
      "Ep:84, loss:0.00003, loss_test:0.07213, lr:9.14e-03, fs:0.84375 (r=0.818,p=0.871),  time:35.999, tt:3059.888\n",
      "Ep:85, loss:0.00003, loss_test:0.07495, lr:9.14e-03, fs:0.86598 (r=0.848,p=0.884),  time:35.998, tt:3095.830\n",
      "Ep:86, loss:0.00003, loss_test:0.07196, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:36.010, tt:3132.906\n",
      "Ep:87, loss:0.00003, loss_test:0.07586, lr:8.95e-03, fs:0.86631 (r=0.818,p=0.920),  time:36.014, tt:3169.245\n",
      "Ep:88, loss:0.00003, loss_test:0.07091, lr:8.86e-03, fs:0.87879 (r=0.879,p=0.879),  time:36.015, tt:3205.375\n",
      "Ep:89, loss:0.00003, loss_test:0.07468, lr:8.78e-03, fs:0.88542 (r=0.859,p=0.914),  time:35.991, tt:3239.172\n",
      "Ep:90, loss:0.00003, loss_test:0.07068, lr:8.69e-03, fs:0.88889 (r=0.889,p=0.889),  time:35.961, tt:3272.472\n",
      "Ep:91, loss:0.00003, loss_test:0.07760, lr:8.60e-03, fs:0.84817 (r=0.818,p=0.880),  time:35.951, tt:3307.511\n",
      "Ep:92, loss:0.00003, loss_test:0.07332, lr:8.51e-03, fs:0.89796 (r=0.889,p=0.907),  time:35.955, tt:3343.832\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00003, loss_test:0.07390, lr:8.51e-03, fs:0.88442 (r=0.889,p=0.880),  time:35.962, tt:3380.420\n",
      "Ep:94, loss:0.00003, loss_test:0.07445, lr:8.51e-03, fs:0.90256 (r=0.889,p=0.917),  time:35.959, tt:3416.067\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00003, loss_test:0.07377, lr:8.51e-03, fs:0.89231 (r=0.879,p=0.906),  time:35.959, tt:3452.019\n",
      "Ep:96, loss:0.00003, loss_test:0.07406, lr:8.51e-03, fs:0.89340 (r=0.889,p=0.898),  time:35.958, tt:3487.896\n",
      "Ep:97, loss:0.00002, loss_test:0.07002, lr:8.51e-03, fs:0.88442 (r=0.889,p=0.880),  time:35.964, tt:3524.520\n",
      "Ep:98, loss:0.00002, loss_test:0.07701, lr:8.51e-03, fs:0.86316 (r=0.828,p=0.901),  time:35.976, tt:3561.620\n",
      "Ep:99, loss:0.00002, loss_test:0.07139, lr:8.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:35.993, tt:3599.259\n",
      "Ep:100, loss:0.00002, loss_test:0.07459, lr:8.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.993, tt:3635.249\n",
      "Ep:101, loss:0.00002, loss_test:0.07631, lr:8.51e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.001, tt:3672.121\n",
      "Ep:102, loss:0.00004, loss_test:0.07710, lr:8.51e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.010, tt:3708.989\n",
      "Ep:103, loss:0.00003, loss_test:0.07001, lr:8.51e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.019, tt:3745.952\n",
      "Ep:104, loss:0.00002, loss_test:0.07366, lr:8.51e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.039, tt:3784.114\n",
      "Ep:105, loss:0.00002, loss_test:0.07313, lr:8.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.032, tt:3819.357\n",
      "Ep:106, loss:0.00002, loss_test:0.07199, lr:8.43e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.032, tt:3855.385\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.07019, lr:8.43e-03, fs:0.89691 (r=0.879,p=0.916),  time:36.052, tt:3893.643\n",
      "Ep:108, loss:0.00002, loss_test:0.07167, lr:8.43e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.066, tt:3931.207\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00002, loss_test:0.07302, lr:8.43e-03, fs:0.87234 (r=0.828,p=0.921),  time:36.072, tt:3967.892\n",
      "Ep:110, loss:0.00002, loss_test:0.07087, lr:8.43e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.080, tt:4004.875\n",
      "Ep:111, loss:0.00002, loss_test:0.07406, lr:8.43e-03, fs:0.87701 (r=0.828,p=0.932),  time:36.106, tt:4043.905\n",
      "Ep:112, loss:0.00002, loss_test:0.07150, lr:8.43e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.114, tt:4080.925\n",
      "Ep:113, loss:0.00002, loss_test:0.07355, lr:8.43e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.118, tt:4117.508\n",
      "Ep:114, loss:0.00002, loss_test:0.07096, lr:8.43e-03, fs:0.90155 (r=0.879,p=0.926),  time:36.139, tt:4156.034\n",
      "Ep:115, loss:0.00002, loss_test:0.07254, lr:8.43e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.150, tt:4193.368\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.07241, lr:8.43e-03, fs:0.88889 (r=0.848,p=0.933),  time:36.165, tt:4231.281\n",
      "Ep:117, loss:0.00002, loss_test:0.07303, lr:8.43e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.176, tt:4268.771\n",
      "Ep:118, loss:0.00002, loss_test:0.07313, lr:8.43e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.188, tt:4306.326\n",
      "Ep:119, loss:0.00002, loss_test:0.07574, lr:8.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.190, tt:4342.830\n",
      "Ep:120, loss:0.00002, loss_test:0.07277, lr:8.43e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.204, tt:4380.636\n",
      "Ep:121, loss:0.00002, loss_test:0.07288, lr:8.43e-03, fs:0.90426 (r=0.859,p=0.955),  time:36.211, tt:4417.752\n",
      "Ep:122, loss:0.00002, loss_test:0.07489, lr:8.43e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.230, tt:4456.282\n",
      "Ep:123, loss:0.00002, loss_test:0.07120, lr:8.43e-03, fs:0.88172 (r=0.828,p=0.943),  time:36.248, tt:4494.781\n",
      "Ep:124, loss:0.00002, loss_test:0.07519, lr:8.43e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.258, tt:4532.228\n",
      "Ep:125, loss:0.00002, loss_test:0.07215, lr:8.43e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.270, tt:4570.012\n",
      "Ep:126, loss:0.00002, loss_test:0.07973, lr:8.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.285, tt:4608.248\n",
      "Ep:127, loss:0.00002, loss_test:0.07069, lr:8.35e-03, fs:0.91489 (r=0.869,p=0.966),  time:36.293, tt:4645.558\n",
      "Ep:128, loss:0.00002, loss_test:0.07711, lr:8.26e-03, fs:0.87701 (r=0.828,p=0.932),  time:36.285, tt:4680.785\n",
      "Ep:129, loss:0.00002, loss_test:0.07073, lr:8.18e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.288, tt:4717.469\n",
      "Ep:130, loss:0.00001, loss_test:0.07515, lr:8.10e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.291, tt:4754.141\n",
      "Ep:131, loss:0.00002, loss_test:0.07180, lr:8.02e-03, fs:0.90426 (r=0.859,p=0.955),  time:36.298, tt:4791.332\n",
      "Ep:132, loss:0.00002, loss_test:0.07163, lr:7.94e-03, fs:0.89362 (r=0.848,p=0.944),  time:36.302, tt:4828.103\n",
      "Ep:133, loss:0.00001, loss_test:0.07220, lr:7.86e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.292, tt:4863.166\n",
      "Ep:134, loss:0.00001, loss_test:0.07115, lr:7.78e-03, fs:0.90625 (r=0.879,p=0.935),  time:36.289, tt:4898.950\n",
      "Ep:135, loss:0.00001, loss_test:0.07230, lr:7.70e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.298, tt:4936.546\n",
      "Ep:136, loss:0.00001, loss_test:0.07150, lr:7.62e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.312, tt:4974.795\n",
      "Ep:137, loss:0.00001, loss_test:0.07256, lr:7.55e-03, fs:0.88889 (r=0.848,p=0.933),  time:36.306, tt:5010.200\n",
      "Ep:138, loss:0.00001, loss_test:0.07297, lr:7.47e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.322, tt:5048.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00001, loss_test:0.07089, lr:7.40e-03, fs:0.89474 (r=0.859,p=0.934),  time:36.333, tt:5086.552\n",
      "Ep:140, loss:0.00001, loss_test:0.07327, lr:7.32e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.349, tt:5125.167\n",
      "Ep:141, loss:0.00001, loss_test:0.07090, lr:7.25e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.354, tt:5162.201\n",
      "Ep:142, loss:0.00001, loss_test:0.07227, lr:7.18e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.347, tt:5197.608\n",
      "Ep:143, loss:0.00001, loss_test:0.07284, lr:7.11e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.351, tt:5234.484\n",
      "Ep:144, loss:0.00001, loss_test:0.07127, lr:7.03e-03, fs:0.88172 (r=0.828,p=0.943),  time:36.361, tt:5272.379\n",
      "Ep:145, loss:0.00001, loss_test:0.07218, lr:6.96e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.361, tt:5308.778\n",
      "Ep:146, loss:0.00001, loss_test:0.07243, lr:6.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:36.359, tt:5344.787\n",
      "Ep:147, loss:0.00001, loss_test:0.07121, lr:6.83e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.358, tt:5381.030\n",
      "Ep:148, loss:0.00001, loss_test:0.07313, lr:6.76e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.388, tt:5421.824\n",
      "Ep:149, loss:0.00001, loss_test:0.07179, lr:6.69e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.400, tt:5459.987\n",
      "Ep:150, loss:0.00001, loss_test:0.07269, lr:6.62e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.401, tt:5496.574\n",
      "Ep:151, loss:0.00001, loss_test:0.07212, lr:6.56e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.405, tt:5533.528\n",
      "Ep:152, loss:0.00001, loss_test:0.07330, lr:6.49e-03, fs:0.88649 (r=0.828,p=0.953),  time:36.406, tt:5570.084\n",
      "Ep:153, loss:0.00001, loss_test:0.07308, lr:6.43e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.412, tt:5607.415\n",
      "Ep:154, loss:0.00001, loss_test:0.07168, lr:6.36e-03, fs:0.88172 (r=0.828,p=0.943),  time:36.409, tt:5643.439\n",
      "Ep:155, loss:0.00001, loss_test:0.07281, lr:6.30e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.406, tt:5679.394\n",
      "Ep:156, loss:0.00001, loss_test:0.07210, lr:6.24e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.413, tt:5716.901\n",
      "Ep:157, loss:0.00001, loss_test:0.07225, lr:6.17e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.425, tt:5755.184\n",
      "Ep:158, loss:0.00001, loss_test:0.07321, lr:6.11e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.422, tt:5791.107\n",
      "Ep:159, loss:0.00001, loss_test:0.07139, lr:6.05e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.415, tt:5826.406\n",
      "Ep:160, loss:0.00001, loss_test:0.07388, lr:5.99e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.420, tt:5863.558\n",
      "Ep:161, loss:0.00001, loss_test:0.07361, lr:5.93e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.427, tt:5901.214\n",
      "Ep:162, loss:0.00001, loss_test:0.07144, lr:5.87e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.431, tt:5938.217\n",
      "Ep:163, loss:0.00001, loss_test:0.07375, lr:5.81e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.432, tt:5974.788\n",
      "Ep:164, loss:0.00001, loss_test:0.07264, lr:5.75e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.431, tt:6011.154\n",
      "Ep:165, loss:0.00001, loss_test:0.07260, lr:5.70e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.432, tt:6047.761\n",
      "Ep:166, loss:0.00001, loss_test:0.07273, lr:5.64e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.438, tt:6085.134\n",
      "Ep:167, loss:0.00001, loss_test:0.07352, lr:5.58e-03, fs:0.88649 (r=0.828,p=0.953),  time:36.454, tt:6124.273\n",
      "Ep:168, loss:0.00001, loss_test:0.07275, lr:5.53e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.454, tt:6160.783\n",
      "Ep:169, loss:0.00001, loss_test:0.07346, lr:5.47e-03, fs:0.91099 (r=0.879,p=0.946),  time:36.459, tt:6198.078\n",
      "Ep:170, loss:0.00001, loss_test:0.07217, lr:5.42e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.467, tt:6235.832\n",
      "Ep:171, loss:0.00001, loss_test:0.07260, lr:5.36e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.459, tt:6270.939\n",
      "Ep:172, loss:0.00001, loss_test:0.07322, lr:5.31e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.463, tt:6308.166\n",
      "Ep:173, loss:0.00001, loss_test:0.07258, lr:5.26e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.464, tt:6344.810\n",
      "Ep:174, loss:0.00001, loss_test:0.07260, lr:5.20e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.468, tt:6381.872\n",
      "Ep:175, loss:0.00001, loss_test:0.07293, lr:5.15e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.466, tt:6418.074\n",
      "Ep:176, loss:0.00001, loss_test:0.07255, lr:5.10e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.466, tt:6454.494\n",
      "Ep:177, loss:0.00001, loss_test:0.07334, lr:5.05e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.461, tt:6490.128\n",
      "Ep:178, loss:0.00001, loss_test:0.07240, lr:5.00e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.467, tt:6527.640\n",
      "Ep:179, loss:0.00001, loss_test:0.07279, lr:4.95e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.474, tt:6565.342\n",
      "Ep:180, loss:0.00001, loss_test:0.07422, lr:4.90e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.472, tt:6601.497\n",
      "Ep:181, loss:0.00001, loss_test:0.07179, lr:4.85e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.476, tt:6638.721\n",
      "Ep:182, loss:0.00001, loss_test:0.07409, lr:4.80e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.479, tt:6675.711\n",
      "Ep:183, loss:0.00001, loss_test:0.07347, lr:4.75e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.487, tt:6713.657\n",
      "Ep:184, loss:0.00001, loss_test:0.07354, lr:4.71e-03, fs:0.89840 (r=0.848,p=0.955),  time:36.501, tt:6752.640\n",
      "Ep:185, loss:0.00001, loss_test:0.07338, lr:4.66e-03, fs:0.91667 (r=0.889,p=0.946),  time:36.502, tt:6789.300\n",
      "Ep:186, loss:0.00001, loss_test:0.07321, lr:4.61e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.497, tt:6825.028\n",
      "Ep:187, loss:0.00001, loss_test:0.07333, lr:4.57e-03, fs:0.88649 (r=0.828,p=0.953),  time:36.499, tt:6861.782\n",
      "Ep:188, loss:0.00001, loss_test:0.07293, lr:4.52e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.508, tt:6900.076\n",
      "Ep:189, loss:0.00001, loss_test:0.07374, lr:4.48e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.510, tt:6936.843\n",
      "Ep:190, loss:0.00001, loss_test:0.07203, lr:4.43e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.512, tt:6973.867\n",
      "Ep:191, loss:0.00001, loss_test:0.07449, lr:4.39e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.512, tt:7010.259\n",
      "Ep:192, loss:0.00001, loss_test:0.07341, lr:4.34e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.509, tt:7046.169\n",
      "Ep:193, loss:0.00001, loss_test:0.07285, lr:4.30e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.510, tt:7082.845\n",
      "Ep:194, loss:0.00001, loss_test:0.07304, lr:4.26e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.510, tt:7119.353\n",
      "Ep:195, loss:0.00001, loss_test:0.07340, lr:4.21e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.508, tt:7155.666\n",
      "Ep:196, loss:0.00001, loss_test:0.07225, lr:4.17e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.513, tt:7193.136\n",
      "Ep:197, loss:0.00001, loss_test:0.07453, lr:4.13e-03, fs:0.91579 (r=0.879,p=0.956),  time:36.516, tt:7230.118\n",
      "Ep:198, loss:0.00001, loss_test:0.07338, lr:4.09e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.528, tt:7269.140\n",
      "Ep:199, loss:0.00001, loss_test:0.07248, lr:4.05e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.532, tt:7306.379\n",
      "Ep:200, loss:0.00001, loss_test:0.07354, lr:4.01e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.533, tt:7343.173\n",
      "Ep:201, loss:0.00001, loss_test:0.07336, lr:3.97e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.527, tt:7378.387\n",
      "Ep:202, loss:0.00001, loss_test:0.07269, lr:3.93e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.525, tt:7414.495\n",
      "Ep:203, loss:0.00001, loss_test:0.07328, lr:3.89e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.527, tt:7451.563\n",
      "Ep:204, loss:0.00001, loss_test:0.07306, lr:3.85e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.523, tt:7487.282\n",
      "Ep:205, loss:0.00001, loss_test:0.07366, lr:3.81e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.522, tt:7523.501\n",
      "Ep:206, loss:0.00001, loss_test:0.07343, lr:3.77e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.524, tt:7560.478\n",
      "Ep:207, loss:0.00001, loss_test:0.07347, lr:3.73e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.528, tt:7597.756\n",
      "Ep:208, loss:0.00001, loss_test:0.07315, lr:3.70e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.527, tt:7634.103\n",
      "Ep:209, loss:0.00001, loss_test:0.07289, lr:3.66e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.513, tt:7667.808\n",
      "Ep:210, loss:0.00001, loss_test:0.07350, lr:3.62e-03, fs:0.92147 (r=0.889,p=0.957),  time:36.494, tt:7700.255\n",
      "Ep:211, loss:0.00001, loss_test:0.07357, lr:3.59e-03, fs:0.92632 (r=0.889,p=0.967),  time:36.476, tt:7732.830\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02205, lr:6.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:27.851, tt:27.851\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02156, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:27.524, tt:55.049\n",
      "Ep:2, loss:0.00005, loss_test:0.02466, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.683, tt:86.048\n",
      "Ep:3, loss:0.00005, loss_test:0.02599, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.178, tt:120.711\n",
      "Ep:4, loss:0.00005, loss_test:0.02590, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.666, tt:158.330\n",
      "Ep:5, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.495, tt:194.973\n",
      "Ep:6, loss:0.00005, loss_test:0.02369, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:32.832, tt:229.824\n",
      "Ep:7, loss:0.00005, loss_test:0.02213, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:32.654, tt:261.228\n",
      "Ep:8, loss:0.00004, loss_test:0.02084, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:32.536, tt:292.826\n",
      "Ep:9, loss:0.00004, loss_test:0.02019, lr:6.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:32.787, tt:327.868\n",
      "Ep:10, loss:0.00004, loss_test:0.02006, lr:6.00e-02, fs:0.66942 (r=0.818,p=0.566),  time:32.958, tt:362.535\n",
      "Ep:11, loss:0.00004, loss_test:0.01985, lr:6.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:33.042, tt:396.502\n",
      "Ep:12, loss:0.00004, loss_test:0.01940, lr:5.94e-02, fs:0.65574 (r=0.808,p=0.552),  time:33.240, tt:432.114\n",
      "Ep:13, loss:0.00004, loss_test:0.01902, lr:5.88e-02, fs:0.65600 (r=0.828,p=0.543),  time:33.282, tt:465.950\n",
      "Ep:14, loss:0.00004, loss_test:0.01879, lr:5.82e-02, fs:0.66667 (r=0.859,p=0.545),  time:33.377, tt:500.650\n",
      "Ep:15, loss:0.00004, loss_test:0.01851, lr:5.76e-02, fs:0.66135 (r=0.838,p=0.546),  time:33.551, tt:536.813\n",
      "Ep:16, loss:0.00003, loss_test:0.01824, lr:5.71e-02, fs:0.65844 (r=0.808,p=0.556),  time:33.627, tt:571.665\n",
      "Ep:17, loss:0.00003, loss_test:0.01795, lr:5.65e-02, fs:0.66946 (r=0.808,p=0.571),  time:33.668, tt:606.020\n",
      "Ep:18, loss:0.00003, loss_test:0.01763, lr:5.59e-02, fs:0.66949 (r=0.798,p=0.577),  time:33.668, tt:639.695\n",
      "Ep:19, loss:0.00003, loss_test:0.01719, lr:5.54e-02, fs:0.68696 (r=0.798,p=0.603),  time:33.883, tt:677.664\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01683, lr:5.54e-02, fs:0.70130 (r=0.818,p=0.614),  time:33.920, tt:712.325\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01646, lr:5.54e-02, fs:0.71304 (r=0.828,p=0.626),  time:33.975, tt:747.441\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01619, lr:5.54e-02, fs:0.72566 (r=0.828,p=0.646),  time:34.026, tt:782.598\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01598, lr:5.54e-02, fs:0.73543 (r=0.828,p=0.661),  time:34.082, tt:817.976\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01577, lr:5.54e-02, fs:0.73636 (r=0.818,p=0.669),  time:34.135, tt:853.381\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01555, lr:5.54e-02, fs:0.73303 (r=0.818,p=0.664),  time:34.176, tt:888.580\n",
      "Ep:26, loss:0.00002, loss_test:0.01527, lr:5.54e-02, fs:0.73636 (r=0.818,p=0.669),  time:34.218, tt:923.898\n",
      "Ep:27, loss:0.00002, loss_test:0.01503, lr:5.54e-02, fs:0.72897 (r=0.788,p=0.678),  time:34.250, tt:959.003\n",
      "Ep:28, loss:0.00002, loss_test:0.01489, lr:5.54e-02, fs:0.73239 (r=0.788,p=0.684),  time:34.271, tt:993.871\n",
      "Ep:29, loss:0.00002, loss_test:0.01481, lr:5.54e-02, fs:0.74286 (r=0.788,p=0.703),  time:34.287, tt:1028.622\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01463, lr:5.54e-02, fs:0.74038 (r=0.778,p=0.706),  time:34.350, tt:1064.849\n",
      "Ep:31, loss:0.00002, loss_test:0.01440, lr:5.54e-02, fs:0.73684 (r=0.778,p=0.700),  time:34.412, tt:1101.185\n",
      "Ep:32, loss:0.00002, loss_test:0.01420, lr:5.54e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.456, tt:1137.055\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01412, lr:5.54e-02, fs:0.75362 (r=0.788,p=0.722),  time:34.473, tt:1172.079\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01410, lr:5.54e-02, fs:0.74757 (r=0.778,p=0.720),  time:34.461, tt:1206.152\n",
      "Ep:35, loss:0.00002, loss_test:0.01398, lr:5.54e-02, fs:0.75728 (r=0.788,p=0.729),  time:34.452, tt:1240.287\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01384, lr:5.54e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.505, tt:1276.678\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01373, lr:5.54e-02, fs:0.76699 (r=0.798,p=0.738),  time:34.540, tt:1312.523\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01365, lr:5.54e-02, fs:0.77073 (r=0.798,p=0.745),  time:34.605, tt:1349.612\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01355, lr:5.54e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.572, tt:1382.890\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01350, lr:5.54e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.601, tt:1418.645\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01342, lr:5.54e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.612, tt:1453.724\n",
      "Ep:42, loss:0.00001, loss_test:0.01338, lr:5.54e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.614, tt:1488.399\n",
      "Ep:43, loss:0.00001, loss_test:0.01337, lr:5.54e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.660, tt:1525.058\n",
      "Ep:44, loss:0.00001, loss_test:0.01334, lr:5.54e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.651, tt:1559.279\n",
      "Ep:45, loss:0.00001, loss_test:0.01328, lr:5.54e-02, fs:0.79602 (r=0.808,p=0.784),  time:34.679, tt:1595.218\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01336, lr:5.54e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.691, tt:1630.458\n",
      "Ep:47, loss:0.00001, loss_test:0.01346, lr:5.54e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.653, tt:1663.350\n",
      "Ep:48, loss:0.00001, loss_test:0.01349, lr:5.54e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.667, tt:1698.687\n",
      "Ep:49, loss:0.00001, loss_test:0.01358, lr:5.54e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.693, tt:1734.639\n",
      "Ep:50, loss:0.00001, loss_test:0.01372, lr:5.54e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.682, tt:1768.758\n",
      "Ep:51, loss:0.00001, loss_test:0.01374, lr:5.54e-02, fs:0.77720 (r=0.758,p=0.798),  time:34.693, tt:1804.051\n",
      "Ep:52, loss:0.00001, loss_test:0.01376, lr:5.54e-02, fs:0.78756 (r=0.768,p=0.809),  time:34.682, tt:1838.155\n",
      "Ep:53, loss:0.00001, loss_test:0.01388, lr:5.54e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.715, tt:1874.597\n",
      "Ep:54, loss:0.00001, loss_test:0.01394, lr:5.54e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.710, tt:1909.040\n",
      "Ep:55, loss:0.00001, loss_test:0.01401, lr:5.54e-02, fs:0.78947 (r=0.758,p=0.824),  time:34.736, tt:1945.220\n",
      "Ep:56, loss:0.00001, loss_test:0.01412, lr:5.54e-02, fs:0.78947 (r=0.758,p=0.824),  time:34.728, tt:1979.475\n",
      "Ep:57, loss:0.00001, loss_test:0.01415, lr:5.48e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.719, tt:2013.679\n",
      "Ep:58, loss:0.00001, loss_test:0.01423, lr:5.43e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.691, tt:2046.759\n",
      "Ep:59, loss:0.00001, loss_test:0.01437, lr:5.37e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.660, tt:2079.590\n",
      "Ep:60, loss:0.00001, loss_test:0.01444, lr:5.32e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.645, tt:2113.333\n",
      "Ep:61, loss:0.00001, loss_test:0.01453, lr:5.27e-02, fs:0.77419 (r=0.727,p=0.828),  time:34.644, tt:2147.904\n",
      "Ep:62, loss:0.00001, loss_test:0.01468, lr:5.21e-02, fs:0.76757 (r=0.717,p=0.826),  time:34.649, tt:2182.899\n",
      "Ep:63, loss:0.00001, loss_test:0.01478, lr:5.16e-02, fs:0.76757 (r=0.717,p=0.826),  time:34.642, tt:2217.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01489, lr:5.11e-02, fs:0.76757 (r=0.717,p=0.826),  time:34.657, tt:2252.677\n",
      "Ep:65, loss:0.00001, loss_test:0.01500, lr:5.06e-02, fs:0.77419 (r=0.727,p=0.828),  time:34.658, tt:2287.452\n",
      "Ep:66, loss:0.00001, loss_test:0.01518, lr:5.01e-02, fs:0.75824 (r=0.697,p=0.831),  time:34.653, tt:2321.718\n",
      "Ep:67, loss:0.00001, loss_test:0.01524, lr:4.96e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.701, tt:2359.669\n",
      "Ep:68, loss:0.00001, loss_test:0.01536, lr:4.91e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.701, tt:2394.341\n",
      "Ep:69, loss:0.00001, loss_test:0.01550, lr:4.86e-02, fs:0.77348 (r=0.707,p=0.854),  time:34.704, tt:2429.281\n",
      "Ep:70, loss:0.00001, loss_test:0.01559, lr:4.81e-02, fs:0.78919 (r=0.737,p=0.849),  time:34.720, tt:2465.092\n",
      "Ep:71, loss:0.00001, loss_test:0.01572, lr:4.76e-02, fs:0.76667 (r=0.697,p=0.852),  time:34.714, tt:2499.408\n",
      "Ep:72, loss:0.00001, loss_test:0.01586, lr:4.71e-02, fs:0.76667 (r=0.697,p=0.852),  time:34.691, tt:2532.407\n",
      "Ep:73, loss:0.00001, loss_test:0.01600, lr:4.67e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.701, tt:2567.886\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01615, lr:4.67e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.685, tt:2601.398\n",
      "Ep:75, loss:0.00001, loss_test:0.01626, lr:4.67e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.699, tt:2637.126\n",
      "Ep:76, loss:0.00001, loss_test:0.01638, lr:4.67e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.707, tt:2672.449\n",
      "Ep:77, loss:0.00001, loss_test:0.01646, lr:4.67e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.713, tt:2707.639\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01661, lr:4.67e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.709, tt:2742.035\n",
      "Ep:79, loss:0.00001, loss_test:0.01675, lr:4.67e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.694, tt:2775.531\n",
      "Ep:80, loss:0.00001, loss_test:0.01686, lr:4.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.697, tt:2810.482\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01709, lr:4.67e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.693, tt:2844.826\n",
      "Ep:82, loss:0.00001, loss_test:0.01723, lr:4.67e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.682, tt:2878.610\n",
      "Ep:83, loss:0.00001, loss_test:0.01731, lr:4.67e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.683, tt:2913.365\n",
      "Ep:84, loss:0.00001, loss_test:0.01749, lr:4.67e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.651, tt:2945.365\n",
      "Ep:85, loss:0.00001, loss_test:0.01762, lr:4.67e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.654, tt:2980.205\n",
      "Ep:86, loss:0.00000, loss_test:0.01779, lr:4.67e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.662, tt:3015.623\n",
      "Ep:87, loss:0.00000, loss_test:0.01794, lr:4.67e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.650, tt:3049.242\n",
      "Ep:88, loss:0.00000, loss_test:0.01804, lr:4.67e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.666, tt:3085.250\n",
      "Ep:89, loss:0.00000, loss_test:0.01819, lr:4.67e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.633, tt:3116.960\n",
      "Ep:90, loss:0.00000, loss_test:0.01837, lr:4.67e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.632, tt:3151.469\n",
      "Ep:91, loss:0.00000, loss_test:0.01854, lr:4.67e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.653, tt:3188.106\n",
      "Ep:92, loss:0.00000, loss_test:0.01864, lr:4.62e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.654, tt:3222.808\n",
      "Ep:93, loss:0.00000, loss_test:0.01879, lr:4.57e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.644, tt:3256.580\n",
      "Ep:94, loss:0.00000, loss_test:0.01890, lr:4.53e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.637, tt:3290.544\n",
      "Ep:95, loss:0.00000, loss_test:0.01909, lr:4.48e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.644, tt:3325.855\n",
      "Ep:96, loss:0.00000, loss_test:0.01923, lr:4.44e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.647, tt:3360.710\n",
      "Ep:97, loss:0.00000, loss_test:0.01934, lr:4.39e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.640, tt:3394.700\n",
      "Ep:98, loss:0.00000, loss_test:0.01951, lr:4.35e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.642, tt:3429.551\n",
      "Ep:99, loss:0.00000, loss_test:0.01968, lr:4.31e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.649, tt:3464.910\n",
      "Ep:100, loss:0.00000, loss_test:0.01983, lr:4.26e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.651, tt:3499.729\n",
      "Ep:101, loss:0.00000, loss_test:0.01994, lr:4.22e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.651, tt:3534.354\n",
      "Ep:102, loss:0.00000, loss_test:0.02005, lr:4.18e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.655, tt:3569.462\n",
      "Ep:103, loss:0.00000, loss_test:0.02022, lr:4.14e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.651, tt:3603.685\n",
      "Ep:104, loss:0.00000, loss_test:0.02037, lr:4.10e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.646, tt:3637.844\n",
      "Ep:105, loss:0.00000, loss_test:0.02051, lr:4.05e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.650, tt:3672.920\n",
      "Ep:106, loss:0.00000, loss_test:0.02054, lr:4.01e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.659, tt:3708.507\n",
      "Ep:107, loss:0.00000, loss_test:0.02066, lr:3.97e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.657, tt:3742.919\n",
      "Ep:108, loss:0.00000, loss_test:0.02085, lr:3.93e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.659, tt:3777.847\n",
      "Ep:109, loss:0.00000, loss_test:0.02101, lr:3.89e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.658, tt:3812.337\n",
      "Ep:110, loss:0.00000, loss_test:0.02111, lr:3.86e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.664, tt:3847.680\n",
      "Ep:111, loss:0.00000, loss_test:0.02116, lr:3.82e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.667, tt:3882.651\n",
      "Ep:112, loss:0.00000, loss_test:0.02132, lr:3.78e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.676, tt:3918.437\n",
      "Ep:113, loss:0.00000, loss_test:0.02143, lr:3.74e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.688, tt:3954.381\n",
      "Ep:114, loss:0.00000, loss_test:0.02154, lr:3.70e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.699, tt:3990.363\n",
      "Ep:115, loss:0.00000, loss_test:0.02169, lr:3.67e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.726, tt:4028.270\n",
      "Ep:116, loss:0.00000, loss_test:0.02177, lr:3.63e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.738, tt:4064.376\n",
      "Ep:117, loss:0.00000, loss_test:0.02189, lr:3.59e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.736, tt:4098.813\n",
      "Ep:118, loss:0.00000, loss_test:0.02201, lr:3.56e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.758, tt:4136.142\n",
      "Ep:119, loss:0.00000, loss_test:0.02215, lr:3.52e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.776, tt:4173.121\n",
      "Ep:120, loss:0.00000, loss_test:0.02223, lr:3.49e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.781, tt:4208.457\n",
      "Ep:121, loss:0.00000, loss_test:0.02232, lr:3.45e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.792, tt:4244.633\n",
      "Ep:122, loss:0.00000, loss_test:0.02238, lr:3.42e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.799, tt:4280.285\n",
      "Ep:123, loss:0.00000, loss_test:0.02248, lr:3.38e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.810, tt:4316.415\n",
      "Ep:124, loss:0.00000, loss_test:0.02264, lr:3.35e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.805, tt:4350.607\n",
      "Ep:125, loss:0.00000, loss_test:0.02278, lr:3.32e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.801, tt:4384.866\n",
      "Ep:126, loss:0.00000, loss_test:0.02288, lr:3.28e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.819, tt:4422.057\n",
      "Ep:127, loss:0.00000, loss_test:0.02294, lr:3.25e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.829, tt:4458.099\n",
      "Ep:128, loss:0.00000, loss_test:0.02299, lr:3.22e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.841, tt:4494.462\n",
      "Ep:129, loss:0.00000, loss_test:0.02310, lr:3.19e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.851, tt:4530.583\n",
      "Ep:130, loss:0.00000, loss_test:0.02319, lr:3.15e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.855, tt:4566.066\n",
      "Ep:131, loss:0.00000, loss_test:0.02329, lr:3.12e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.869, tt:4602.765\n",
      "Ep:132, loss:0.00000, loss_test:0.02336, lr:3.09e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.885, tt:4639.699\n",
      "Ep:133, loss:0.00000, loss_test:0.02343, lr:3.06e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.895, tt:4675.971\n",
      "Ep:134, loss:0.00000, loss_test:0.02353, lr:3.03e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.914, tt:4713.374\n",
      "Ep:135, loss:0.00000, loss_test:0.02361, lr:3.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.932, tt:4750.730\n",
      "Ep:136, loss:0.00000, loss_test:0.02365, lr:2.97e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.941, tt:4786.965\n",
      "Ep:137, loss:0.00000, loss_test:0.02375, lr:2.94e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.955, tt:4823.849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.02384, lr:2.91e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.961, tt:4859.517\n",
      "Ep:139, loss:0.00000, loss_test:0.02392, lr:2.88e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.977, tt:4896.740\n",
      "Ep:140, loss:0.00000, loss_test:0.02400, lr:2.85e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.990, tt:4933.596\n",
      "Ep:141, loss:0.00000, loss_test:0.02407, lr:2.82e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.007, tt:4970.923\n",
      "Ep:142, loss:0.00000, loss_test:0.02411, lr:2.80e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.013, tt:5006.882\n",
      "Ep:143, loss:0.00000, loss_test:0.02421, lr:2.77e-02, fs:0.80000 (r=0.707,p=0.921),  time:35.021, tt:5042.964\n",
      "Ep:144, loss:0.00000, loss_test:0.02432, lr:2.74e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.017, tt:5077.423\n",
      "Ep:145, loss:0.00000, loss_test:0.02436, lr:2.71e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.020, tt:5112.918\n",
      "Ep:146, loss:0.00000, loss_test:0.02444, lr:2.69e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.036, tt:5150.329\n",
      "Ep:147, loss:0.00000, loss_test:0.02449, lr:2.66e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.050, tt:5187.356\n",
      "Ep:148, loss:0.00000, loss_test:0.02458, lr:2.63e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.074, tt:5226.034\n",
      "Ep:149, loss:0.00000, loss_test:0.02463, lr:2.61e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.081, tt:5262.147\n",
      "Ep:150, loss:0.00000, loss_test:0.02471, lr:2.58e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.083, tt:5297.494\n",
      "Ep:151, loss:0.00000, loss_test:0.02480, lr:2.55e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.080, tt:5332.159\n",
      "Ep:152, loss:0.00000, loss_test:0.02488, lr:2.53e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.088, tt:5368.540\n",
      "Ep:153, loss:0.00000, loss_test:0.02492, lr:2.50e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.100, tt:5405.370\n",
      "Ep:154, loss:0.00000, loss_test:0.02497, lr:2.48e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.109, tt:5441.841\n",
      "Ep:155, loss:0.00000, loss_test:0.02503, lr:2.45e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.114, tt:5477.850\n",
      "Ep:156, loss:0.00000, loss_test:0.02512, lr:2.43e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.121, tt:5514.016\n",
      "Ep:157, loss:0.00000, loss_test:0.02516, lr:2.40e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.109, tt:5547.195\n",
      "Ep:158, loss:0.00000, loss_test:0.02522, lr:2.38e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.119, tt:5583.993\n",
      "Ep:159, loss:0.00000, loss_test:0.02526, lr:2.36e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.118, tt:5618.804\n",
      "Ep:160, loss:0.00000, loss_test:0.02533, lr:2.33e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.106, tt:5652.050\n",
      "Ep:161, loss:0.00000, loss_test:0.02542, lr:2.31e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.105, tt:5687.056\n",
      "Ep:162, loss:0.00000, loss_test:0.02548, lr:2.29e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.114, tt:5723.522\n",
      "Ep:163, loss:0.00000, loss_test:0.02551, lr:2.26e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.112, tt:5758.402\n",
      "Ep:164, loss:0.00000, loss_test:0.02556, lr:2.24e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.113, tt:5793.664\n",
      "Ep:165, loss:0.00000, loss_test:0.02562, lr:2.22e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.108, tt:5827.876\n",
      "Ep:166, loss:0.00000, loss_test:0.02567, lr:2.20e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.120, tt:5865.072\n",
      "Ep:167, loss:0.00000, loss_test:0.02572, lr:2.17e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.130, tt:5901.795\n",
      "Ep:168, loss:0.00000, loss_test:0.02578, lr:2.15e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.136, tt:5937.916\n",
      "Ep:169, loss:0.00000, loss_test:0.02584, lr:2.13e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.127, tt:5971.615\n",
      "Ep:170, loss:0.00000, loss_test:0.02587, lr:2.11e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.124, tt:6006.243\n",
      "Ep:171, loss:0.00000, loss_test:0.02592, lr:2.09e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.122, tt:6040.958\n",
      "Ep:172, loss:0.00000, loss_test:0.02597, lr:2.07e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.117, tt:6075.243\n",
      "Ep:173, loss:0.00000, loss_test:0.02604, lr:2.05e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.119, tt:6110.678\n",
      "Ep:174, loss:0.00000, loss_test:0.02607, lr:2.03e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.121, tt:6146.144\n",
      "Ep:175, loss:0.00000, loss_test:0.02611, lr:2.01e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.123, tt:6181.672\n",
      "Ep:176, loss:0.00000, loss_test:0.02616, lr:1.99e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.122, tt:6216.535\n",
      "Ep:177, loss:0.00000, loss_test:0.02622, lr:1.97e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.118, tt:6251.023\n",
      "Ep:178, loss:0.00000, loss_test:0.02624, lr:1.95e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.119, tt:6286.341\n",
      "Ep:179, loss:0.00000, loss_test:0.02629, lr:1.93e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.116, tt:6320.816\n",
      "Ep:180, loss:0.00000, loss_test:0.02634, lr:1.91e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.112, tt:6355.328\n",
      "Ep:181, loss:0.00000, loss_test:0.02639, lr:1.89e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.112, tt:6390.377\n",
      "Ep:182, loss:0.00000, loss_test:0.02640, lr:1.87e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.110, tt:6425.188\n",
      "Ep:183, loss:0.00000, loss_test:0.02647, lr:1.85e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.106, tt:6459.574\n",
      "Ep:184, loss:0.00000, loss_test:0.02653, lr:1.83e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.104, tt:6494.285\n",
      "Ep:185, loss:0.00000, loss_test:0.02657, lr:1.81e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.108, tt:6530.067\n",
      "Ep:186, loss:0.00000, loss_test:0.02659, lr:1.80e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.106, tt:6564.798\n",
      "Ep:187, loss:0.00000, loss_test:0.02663, lr:1.78e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.111, tt:6600.865\n",
      "Ep:188, loss:0.00000, loss_test:0.02668, lr:1.76e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.118, tt:6637.236\n",
      "Ep:189, loss:0.00000, loss_test:0.02671, lr:1.74e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.117, tt:6672.154\n",
      "Ep:190, loss:0.00000, loss_test:0.02675, lr:1.73e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.119, tt:6707.789\n",
      "Ep:191, loss:0.00000, loss_test:0.02680, lr:1.71e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.123, tt:6743.571\n",
      "Ep:192, loss:0.00000, loss_test:0.02685, lr:1.69e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.117, tt:6777.630\n",
      "Ep:193, loss:0.00000, loss_test:0.02688, lr:1.67e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.113, tt:6811.968\n",
      "Ep:194, loss:0.00000, loss_test:0.02691, lr:1.66e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.107, tt:6845.915\n",
      "Ep:195, loss:0.00000, loss_test:0.02695, lr:1.64e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.109, tt:6881.278\n",
      "Ep:196, loss:0.00000, loss_test:0.02698, lr:1.62e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.102, tt:6915.173\n",
      "Ep:197, loss:0.00000, loss_test:0.02702, lr:1.61e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.097, tt:6949.129\n",
      "Ep:198, loss:0.00000, loss_test:0.02706, lr:1.59e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.075, tt:6979.869\n",
      "Ep:199, loss:0.00000, loss_test:0.02708, lr:1.58e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.058, tt:7011.631\n",
      "Ep:200, loss:0.00000, loss_test:0.02711, lr:1.56e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.038, tt:7042.586\n",
      "Ep:201, loss:0.00000, loss_test:0.02716, lr:1.54e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.022, tt:7074.482\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12817, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:31.493, tt:31.493\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12657, lr:1.00e-02, fs:0.68148 (r=0.929,p=0.538),  time:31.377, tt:62.754\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12535, lr:1.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:33.009, tt:99.026\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12441, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:34.168, tt:136.673\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12356, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.723, tt:173.614\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00025, loss_test:0.12256, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.374, tt:212.242\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12138, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:35.307, tt:247.146\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12012, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:35.066, tt:280.531\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.11880, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:35.344, tt:318.097\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11723, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:35.452, tt:354.517\n",
      "Ep:10, loss:0.00023, loss_test:0.11569, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:35.580, tt:391.383\n",
      "Ep:11, loss:0.00022, loss_test:0.11446, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:35.722, tt:428.667\n",
      "Ep:12, loss:0.00022, loss_test:0.11336, lr:1.00e-02, fs:0.67532 (r=0.788,p=0.591),  time:35.818, tt:465.629\n",
      "Ep:13, loss:0.00021, loss_test:0.11217, lr:1.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:35.969, tt:503.560\n",
      "Ep:14, loss:0.00021, loss_test:0.11105, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:36.114, tt:541.711\n",
      "Ep:15, loss:0.00020, loss_test:0.10994, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:36.249, tt:579.989\n",
      "Ep:16, loss:0.00019, loss_test:0.10850, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:36.399, tt:618.783\n",
      "Ep:17, loss:0.00019, loss_test:0.10693, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:36.439, tt:655.906\n",
      "Ep:18, loss:0.00018, loss_test:0.10500, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:36.636, tt:696.078\n",
      "Ep:19, loss:0.00018, loss_test:0.10319, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:36.731, tt:734.623\n",
      "Ep:20, loss:0.00017, loss_test:0.10185, lr:9.90e-03, fs:0.71429 (r=0.758,p=0.676),  time:36.865, tt:774.162\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.10038, lr:9.90e-03, fs:0.71154 (r=0.747,p=0.679),  time:36.981, tt:813.585\n",
      "Ep:22, loss:0.00016, loss_test:0.09859, lr:9.90e-03, fs:0.73333 (r=0.778,p=0.694),  time:37.040, tt:851.931\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09652, lr:9.90e-03, fs:0.76142 (r=0.758,p=0.765),  time:37.090, tt:890.154\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09421, lr:9.90e-03, fs:0.78000 (r=0.788,p=0.772),  time:37.105, tt:927.635\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09276, lr:9.90e-03, fs:0.78173 (r=0.778,p=0.786),  time:37.171, tt:966.444\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09129, lr:9.90e-03, fs:0.78125 (r=0.758,p=0.806),  time:37.275, tt:1006.420\n",
      "Ep:27, loss:0.00012, loss_test:0.08948, lr:9.90e-03, fs:0.79381 (r=0.778,p=0.811),  time:37.285, tt:1043.981\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.08849, lr:9.90e-03, fs:0.79793 (r=0.778,p=0.819),  time:37.285, tt:1081.252\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08779, lr:9.90e-03, fs:0.81675 (r=0.788,p=0.848),  time:37.359, tt:1120.759\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08636, lr:9.90e-03, fs:0.79793 (r=0.778,p=0.819),  time:37.392, tt:1159.137\n",
      "Ep:31, loss:0.00010, loss_test:0.08605, lr:9.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:37.433, tt:1197.852\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.08459, lr:9.90e-03, fs:0.81026 (r=0.798,p=0.823),  time:37.457, tt:1236.081\n",
      "Ep:33, loss:0.00009, loss_test:0.08445, lr:9.90e-03, fs:0.81053 (r=0.778,p=0.846),  time:37.474, tt:1274.108\n",
      "Ep:34, loss:0.00009, loss_test:0.08377, lr:9.90e-03, fs:0.81250 (r=0.788,p=0.839),  time:37.517, tt:1313.108\n",
      "Ep:35, loss:0.00008, loss_test:0.08350, lr:9.90e-03, fs:0.81675 (r=0.788,p=0.848),  time:37.506, tt:1350.212\n",
      "Ep:36, loss:0.00008, loss_test:0.08269, lr:9.90e-03, fs:0.82902 (r=0.808,p=0.851),  time:37.490, tt:1387.130\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.08295, lr:9.90e-03, fs:0.81675 (r=0.788,p=0.848),  time:37.467, tt:1423.749\n",
      "Ep:38, loss:0.00007, loss_test:0.08253, lr:9.90e-03, fs:0.80423 (r=0.768,p=0.844),  time:37.496, tt:1462.340\n",
      "Ep:39, loss:0.00007, loss_test:0.08298, lr:9.90e-03, fs:0.79787 (r=0.758,p=0.843),  time:37.539, tt:1501.558\n",
      "Ep:40, loss:0.00007, loss_test:0.08185, lr:9.90e-03, fs:0.80851 (r=0.768,p=0.854),  time:37.505, tt:1537.693\n",
      "Ep:41, loss:0.00006, loss_test:0.08209, lr:9.90e-03, fs:0.79144 (r=0.747,p=0.841),  time:37.471, tt:1573.767\n",
      "Ep:42, loss:0.00006, loss_test:0.08135, lr:9.90e-03, fs:0.80214 (r=0.758,p=0.852),  time:37.464, tt:1610.962\n",
      "Ep:43, loss:0.00006, loss_test:0.08169, lr:9.90e-03, fs:0.78261 (r=0.727,p=0.847),  time:37.465, tt:1648.454\n",
      "Ep:44, loss:0.00006, loss_test:0.08153, lr:9.90e-03, fs:0.77596 (r=0.717,p=0.845),  time:37.464, tt:1685.886\n",
      "Ep:45, loss:0.00006, loss_test:0.08138, lr:9.90e-03, fs:0.76923 (r=0.707,p=0.843),  time:37.448, tt:1722.621\n",
      "Ep:46, loss:0.00005, loss_test:0.08203, lr:9.90e-03, fs:0.76243 (r=0.697,p=0.841),  time:37.441, tt:1759.741\n",
      "Ep:47, loss:0.00005, loss_test:0.08101, lr:9.90e-03, fs:0.76923 (r=0.707,p=0.843),  time:37.449, tt:1797.544\n",
      "Ep:48, loss:0.00005, loss_test:0.08123, lr:9.80e-03, fs:0.76243 (r=0.697,p=0.841),  time:37.455, tt:1835.298\n",
      "Ep:49, loss:0.00005, loss_test:0.08174, lr:9.70e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.435, tt:1871.733\n",
      "Ep:50, loss:0.00005, loss_test:0.08108, lr:9.61e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.450, tt:1909.930\n",
      "Ep:51, loss:0.00004, loss_test:0.08027, lr:9.51e-03, fs:0.76243 (r=0.697,p=0.841),  time:37.448, tt:1947.281\n",
      "Ep:52, loss:0.00004, loss_test:0.08119, lr:9.41e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.495, tt:1987.259\n",
      "Ep:53, loss:0.00004, loss_test:0.07984, lr:9.32e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.507, tt:2025.377\n",
      "Ep:54, loss:0.00004, loss_test:0.08105, lr:9.23e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.511, tt:2063.087\n",
      "Ep:55, loss:0.00004, loss_test:0.08052, lr:9.14e-03, fs:0.76243 (r=0.697,p=0.841),  time:37.527, tt:2101.526\n",
      "Ep:56, loss:0.00004, loss_test:0.08044, lr:9.04e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.542, tt:2139.898\n",
      "Ep:57, loss:0.00004, loss_test:0.08140, lr:8.95e-03, fs:0.76243 (r=0.697,p=0.841),  time:37.536, tt:2177.073\n",
      "Ep:58, loss:0.00004, loss_test:0.08029, lr:8.86e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.538, tt:2214.724\n",
      "Ep:59, loss:0.00004, loss_test:0.08074, lr:8.78e-03, fs:0.76243 (r=0.697,p=0.841),  time:37.552, tt:2253.140\n",
      "Ep:60, loss:0.00003, loss_test:0.08088, lr:8.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.562, tt:2291.303\n",
      "Ep:61, loss:0.00003, loss_test:0.08125, lr:8.60e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.571, tt:2329.413\n",
      "Ep:62, loss:0.00003, loss_test:0.08102, lr:8.51e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.571, tt:2366.951\n",
      "Ep:63, loss:0.00003, loss_test:0.08149, lr:8.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.566, tt:2404.243\n",
      "Ep:64, loss:0.00003, loss_test:0.08200, lr:8.35e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.583, tt:2442.906\n",
      "Ep:65, loss:0.00003, loss_test:0.08067, lr:8.26e-03, fs:0.76667 (r=0.697,p=0.852),  time:37.582, tt:2480.425\n",
      "Ep:66, loss:0.00003, loss_test:0.08043, lr:8.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.590, tt:2518.564\n",
      "Ep:67, loss:0.00003, loss_test:0.08183, lr:8.10e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.591, tt:2556.211\n",
      "Ep:68, loss:0.00003, loss_test:0.08015, lr:8.02e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.581, tt:2593.082\n",
      "Ep:69, loss:0.00003, loss_test:0.08143, lr:7.94e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.562, tt:2629.328\n",
      "Ep:70, loss:0.00003, loss_test:0.08196, lr:7.86e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.540, tt:2665.307\n",
      "Ep:71, loss:0.00003, loss_test:0.07914, lr:7.78e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.524, tt:2701.706\n",
      "Ep:72, loss:0.00003, loss_test:0.08235, lr:7.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.513, tt:2738.445\n",
      "Ep:73, loss:0.00003, loss_test:0.08260, lr:7.62e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.512, tt:2775.872\n",
      "Ep:74, loss:0.00003, loss_test:0.08006, lr:7.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.488, tt:2811.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00003, loss_test:0.08156, lr:7.47e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.511, tt:2850.840\n",
      "Ep:76, loss:0.00002, loss_test:0.08216, lr:7.40e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.510, tt:2888.287\n",
      "Ep:77, loss:0.00002, loss_test:0.08055, lr:7.32e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.511, tt:2925.894\n",
      "Ep:78, loss:0.00002, loss_test:0.08143, lr:7.25e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.477, tt:2960.668\n",
      "Ep:79, loss:0.00002, loss_test:0.08239, lr:7.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.461, tt:2996.875\n",
      "Ep:80, loss:0.00002, loss_test:0.08109, lr:7.11e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.459, tt:3034.219\n",
      "Ep:81, loss:0.00002, loss_test:0.08001, lr:7.03e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.463, tt:3072.002\n",
      "Ep:82, loss:0.00002, loss_test:0.08143, lr:6.96e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.464, tt:3109.473\n",
      "Ep:83, loss:0.00002, loss_test:0.08237, lr:6.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.469, tt:3147.397\n",
      "Ep:84, loss:0.00002, loss_test:0.08168, lr:6.83e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.460, tt:3184.111\n",
      "Ep:85, loss:0.00002, loss_test:0.08067, lr:6.76e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.506, tt:3225.499\n",
      "Ep:86, loss:0.00002, loss_test:0.08235, lr:6.69e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.505, tt:3262.968\n",
      "Ep:87, loss:0.00002, loss_test:0.08348, lr:6.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.515, tt:3301.310\n",
      "Ep:88, loss:0.00002, loss_test:0.08142, lr:6.56e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.529, tt:3340.109\n",
      "Ep:89, loss:0.00002, loss_test:0.08109, lr:6.49e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.555, tt:3379.965\n",
      "Ep:90, loss:0.00002, loss_test:0.08257, lr:6.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.538, tt:3415.928\n",
      "Ep:91, loss:0.00002, loss_test:0.08207, lr:6.36e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.544, tt:3454.042\n",
      "Ep:92, loss:0.00002, loss_test:0.08166, lr:6.30e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.552, tt:3492.332\n",
      "Ep:93, loss:0.00002, loss_test:0.08109, lr:6.24e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.543, tt:3529.076\n",
      "Ep:94, loss:0.00002, loss_test:0.08242, lr:6.17e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.547, tt:3566.990\n",
      "Ep:95, loss:0.00002, loss_test:0.08253, lr:6.11e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.530, tt:3602.884\n",
      "Ep:96, loss:0.00002, loss_test:0.08085, lr:6.05e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.490, tt:3636.547\n",
      "Ep:97, loss:0.00002, loss_test:0.08159, lr:5.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.466, tt:3671.702\n",
      "Ep:98, loss:0.00002, loss_test:0.08205, lr:5.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.459, tt:3708.445\n",
      "Ep:99, loss:0.00002, loss_test:0.08160, lr:5.87e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.460, tt:3746.014\n",
      "Ep:100, loss:0.00002, loss_test:0.08109, lr:5.81e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.449, tt:3782.328\n",
      "Ep:101, loss:0.00002, loss_test:0.08121, lr:5.75e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.437, tt:3818.579\n",
      "Ep:102, loss:0.00002, loss_test:0.08241, lr:5.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.440, tt:3856.333\n",
      "Ep:103, loss:0.00002, loss_test:0.08205, lr:5.64e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.450, tt:3894.777\n",
      "Ep:104, loss:0.00002, loss_test:0.08232, lr:5.58e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.450, tt:3932.204\n",
      "Ep:105, loss:0.00002, loss_test:0.08140, lr:5.53e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.461, tt:3970.819\n",
      "Ep:106, loss:0.00002, loss_test:0.08104, lr:5.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.447, tt:4006.870\n",
      "Ep:107, loss:0.00002, loss_test:0.08264, lr:5.42e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.437, tt:4043.152\n",
      "Ep:108, loss:0.00002, loss_test:0.08172, lr:5.36e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.431, tt:4079.927\n",
      "Ep:109, loss:0.00002, loss_test:0.08072, lr:5.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.430, tt:4117.248\n",
      "Ep:110, loss:0.00002, loss_test:0.08234, lr:5.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.436, tt:4155.406\n",
      "Ep:111, loss:0.00002, loss_test:0.08143, lr:5.20e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.432, tt:4192.385\n",
      "Ep:112, loss:0.00002, loss_test:0.08143, lr:5.15e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.419, tt:4228.324\n",
      "Ep:113, loss:0.00002, loss_test:0.08216, lr:5.10e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.427, tt:4266.668\n",
      "Ep:114, loss:0.00002, loss_test:0.08125, lr:5.05e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.420, tt:4303.278\n",
      "Ep:115, loss:0.00002, loss_test:0.08177, lr:5.00e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.419, tt:4340.625\n",
      "Ep:116, loss:0.00002, loss_test:0.08219, lr:4.95e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.415, tt:4377.586\n",
      "Ep:117, loss:0.00001, loss_test:0.08121, lr:4.90e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.418, tt:4415.266\n",
      "Ep:118, loss:0.00001, loss_test:0.08175, lr:4.85e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.418, tt:4452.694\n",
      "Ep:119, loss:0.00001, loss_test:0.08208, lr:4.80e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.409, tt:4489.086\n",
      "Ep:120, loss:0.00001, loss_test:0.08130, lr:4.75e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.403, tt:4525.715\n",
      "Ep:121, loss:0.00001, loss_test:0.08190, lr:4.71e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.393, tt:4561.990\n",
      "Ep:122, loss:0.00001, loss_test:0.08195, lr:4.66e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.393, tt:4599.304\n",
      "Ep:123, loss:0.00001, loss_test:0.08122, lr:4.61e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.393, tt:4636.707\n",
      "Ep:124, loss:0.00001, loss_test:0.08164, lr:4.57e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.386, tt:4673.251\n",
      "Ep:125, loss:0.00001, loss_test:0.08188, lr:4.52e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.378, tt:4709.641\n",
      "Ep:126, loss:0.00001, loss_test:0.08093, lr:4.48e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.369, tt:4745.913\n",
      "Ep:127, loss:0.00001, loss_test:0.08178, lr:4.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.364, tt:4782.604\n",
      "Ep:128, loss:0.00001, loss_test:0.08225, lr:4.39e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.359, tt:4819.295\n",
      "Ep:129, loss:0.00001, loss_test:0.08136, lr:4.34e-03, fs:0.78409 (r=0.697,p=0.896),  time:37.361, tt:4856.942\n",
      "Ep:130, loss:0.00001, loss_test:0.08197, lr:4.30e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.381, tt:4896.941\n",
      "Ep:131, loss:0.00001, loss_test:0.08220, lr:4.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.390, tt:4935.460\n",
      "Ep:132, loss:0.00001, loss_test:0.08123, lr:4.21e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.384, tt:4972.114\n",
      "Ep:133, loss:0.00001, loss_test:0.08191, lr:4.17e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.386, tt:5009.753\n",
      "Ep:134, loss:0.00001, loss_test:0.08217, lr:4.13e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.391, tt:5047.770\n",
      "Ep:135, loss:0.00001, loss_test:0.08175, lr:4.09e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.384, tt:5084.269\n",
      "Ep:136, loss:0.00001, loss_test:0.08179, lr:4.05e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.386, tt:5121.892\n",
      "Ep:137, loss:0.00001, loss_test:0.08230, lr:4.01e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.392, tt:5160.119\n",
      "Ep:138, loss:0.00001, loss_test:0.08193, lr:3.97e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.403, tt:5199.049\n",
      "Ep:139, loss:0.00001, loss_test:0.08158, lr:3.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.401, tt:5236.137\n",
      "Ep:140, loss:0.00001, loss_test:0.08232, lr:3.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.389, tt:5271.840\n",
      "Ep:141, loss:0.00001, loss_test:0.08162, lr:3.85e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.385, tt:5308.704\n",
      "Ep:142, loss:0.00001, loss_test:0.08193, lr:3.81e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.387, tt:5346.306\n",
      "Ep:143, loss:0.00001, loss_test:0.08240, lr:3.77e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.382, tt:5382.983\n",
      "Ep:144, loss:0.00001, loss_test:0.08158, lr:3.73e-03, fs:0.78409 (r=0.697,p=0.896),  time:37.372, tt:5418.956\n",
      "Ep:145, loss:0.00001, loss_test:0.08199, lr:3.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.371, tt:5456.143\n",
      "Ep:146, loss:0.00001, loss_test:0.08221, lr:3.66e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.363, tt:5492.334\n",
      "Ep:147, loss:0.00001, loss_test:0.08167, lr:3.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.349, tt:5527.649\n",
      "Ep:148, loss:0.00001, loss_test:0.08187, lr:3.59e-03, fs:0.78409 (r=0.697,p=0.896),  time:37.344, tt:5564.250\n",
      "Ep:149, loss:0.00001, loss_test:0.08262, lr:3.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.345, tt:5601.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00001, loss_test:0.08230, lr:3.52e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.325, tt:5636.120\n",
      "Ep:151, loss:0.00001, loss_test:0.08178, lr:3.48e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.314, tt:5671.692\n",
      "Ep:152, loss:0.00001, loss_test:0.08181, lr:3.45e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.296, tt:5706.307\n",
      "Ep:153, loss:0.00001, loss_test:0.08250, lr:3.41e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.290, tt:5742.613\n",
      "Ep:154, loss:0.00001, loss_test:0.08256, lr:3.38e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.292, tt:5780.308\n",
      "Ep:155, loss:0.00001, loss_test:0.08184, lr:3.34e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.290, tt:5817.244\n",
      "Ep:156, loss:0.00001, loss_test:0.08262, lr:3.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.281, tt:5853.127\n",
      "Ep:157, loss:0.00001, loss_test:0.08256, lr:3.28e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.281, tt:5890.468\n",
      "Ep:158, loss:0.00001, loss_test:0.08190, lr:3.24e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.268, tt:5925.567\n",
      "Ep:159, loss:0.00001, loss_test:0.08197, lr:3.21e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.263, tt:5962.030\n",
      "Ep:160, loss:0.00001, loss_test:0.08219, lr:3.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.247, tt:5996.813\n",
      "Ep:161, loss:0.00001, loss_test:0.08237, lr:3.15e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.229, tt:6031.120\n",
      "Ep:162, loss:0.00001, loss_test:0.08229, lr:3.12e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.225, tt:6067.750\n",
      "Ep:163, loss:0.00001, loss_test:0.08220, lr:3.09e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.239, tt:6107.265\n",
      "Ep:164, loss:0.00001, loss_test:0.08230, lr:3.05e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.237, tt:6144.026\n",
      "Ep:165, loss:0.00001, loss_test:0.08283, lr:3.02e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.242, tt:6182.164\n",
      "Ep:166, loss:0.00001, loss_test:0.08210, lr:2.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.242, tt:6219.415\n",
      "Ep:167, loss:0.00001, loss_test:0.08233, lr:2.96e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.249, tt:6257.831\n",
      "Ep:168, loss:0.00001, loss_test:0.08224, lr:2.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.252, tt:6295.522\n",
      "Ep:169, loss:0.00001, loss_test:0.08225, lr:2.90e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.255, tt:6333.305\n",
      "Ep:170, loss:0.00001, loss_test:0.08302, lr:2.88e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.239, tt:6367.824\n",
      "Ep:171, loss:0.00001, loss_test:0.08257, lr:2.85e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.219, tt:6401.751\n",
      "Ep:172, loss:0.00001, loss_test:0.08246, lr:2.82e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.240, tt:6442.523\n",
      "Ep:173, loss:0.00001, loss_test:0.08271, lr:2.79e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.239, tt:6479.658\n",
      "Ep:174, loss:0.00001, loss_test:0.08227, lr:2.76e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.238, tt:6516.649\n",
      "Ep:175, loss:0.00001, loss_test:0.08241, lr:2.73e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.236, tt:6553.623\n",
      "Ep:176, loss:0.00001, loss_test:0.08247, lr:2.71e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.235, tt:6590.650\n",
      "Ep:177, loss:0.00001, loss_test:0.08228, lr:2.68e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.234, tt:6627.599\n",
      "Ep:178, loss:0.00001, loss_test:0.08238, lr:2.65e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.226, tt:6663.379\n",
      "Ep:179, loss:0.00001, loss_test:0.08248, lr:2.63e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.226, tt:6700.595\n",
      "Ep:180, loss:0.00001, loss_test:0.08254, lr:2.60e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.229, tt:6738.435\n",
      "Ep:181, loss:0.00001, loss_test:0.08231, lr:2.57e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.224, tt:6774.858\n",
      "Ep:182, loss:0.00001, loss_test:0.08252, lr:2.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.220, tt:6811.313\n",
      "Ep:183, loss:0.00001, loss_test:0.08252, lr:2.52e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.218, tt:6848.142\n",
      "Ep:184, loss:0.00001, loss_test:0.08250, lr:2.50e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.218, tt:6885.338\n",
      "Ep:185, loss:0.00001, loss_test:0.08244, lr:2.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.215, tt:6922.025\n",
      "Ep:186, loss:0.00001, loss_test:0.08270, lr:2.45e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.217, tt:6959.602\n",
      "Ep:187, loss:0.00001, loss_test:0.08301, lr:2.42e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.214, tt:6996.249\n",
      "Ep:188, loss:0.00001, loss_test:0.08246, lr:2.40e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.216, tt:7033.764\n",
      "Ep:189, loss:0.00001, loss_test:0.08251, lr:2.38e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.210, tt:7069.810\n",
      "Ep:190, loss:0.00001, loss_test:0.08261, lr:2.35e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.227, tt:7110.265\n",
      "Ep:191, loss:0.00001, loss_test:0.08267, lr:2.33e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.229, tt:7147.955\n",
      "Ep:192, loss:0.00001, loss_test:0.08286, lr:2.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.232, tt:7185.714\n",
      "Ep:193, loss:0.00001, loss_test:0.08267, lr:2.28e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.229, tt:7222.476\n",
      "Ep:194, loss:0.00001, loss_test:0.08255, lr:2.26e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.230, tt:7259.942\n",
      "Ep:195, loss:0.00001, loss_test:0.08279, lr:2.24e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.231, tt:7297.374\n",
      "Ep:196, loss:0.00001, loss_test:0.08264, lr:2.21e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.227, tt:7333.740\n",
      "Ep:197, loss:0.00001, loss_test:0.08286, lr:2.19e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.226, tt:7370.667\n",
      "Ep:198, loss:0.00001, loss_test:0.08284, lr:2.17e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.203, tt:7403.340\n",
      "Ep:199, loss:0.00001, loss_test:0.08288, lr:2.15e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.186, tt:7437.218\n",
      "Ep:200, loss:0.00001, loss_test:0.08302, lr:2.13e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.159, tt:7468.993\n",
      "Ep:201, loss:0.00001, loss_test:0.08318, lr:2.11e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.125, tt:7499.224\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02071, lr:6.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:23.188, tt:23.188\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02394, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.237, tt:52.474\n",
      "Ep:2, loss:0.00005, loss_test:0.02604, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.921, tt:83.762\n",
      "Ep:3, loss:0.00005, loss_test:0.02613, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.962, tt:111.849\n",
      "Ep:4, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.162, tt:140.808\n",
      "Ep:5, loss:0.00005, loss_test:0.02349, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:27.832, tt:166.993\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02209, lr:6.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:27.861, tt:195.025\n",
      "Ep:7, loss:0.00004, loss_test:0.02154, lr:6.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:27.600, tt:220.801\n",
      "Ep:8, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:27.626, tt:248.636\n",
      "Ep:9, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:27.636, tt:276.364\n",
      "Ep:10, loss:0.00004, loss_test:0.02165, lr:6.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:27.719, tt:304.911\n",
      "Ep:11, loss:0.00004, loss_test:0.02154, lr:6.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:27.951, tt:335.410\n",
      "Ep:12, loss:0.00004, loss_test:0.02147, lr:6.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:28.122, tt:365.590\n",
      "Ep:13, loss:0.00004, loss_test:0.02143, lr:6.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:28.259, tt:395.629\n",
      "Ep:14, loss:0.00004, loss_test:0.02136, lr:6.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:28.357, tt:425.361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00004, loss_test:0.02119, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:28.408, tt:454.535\n",
      "Ep:16, loss:0.00004, loss_test:0.02090, lr:6.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:28.422, tt:483.179\n",
      "Ep:17, loss:0.00004, loss_test:0.02046, lr:5.94e-02, fs:0.66946 (r=0.808,p=0.571),  time:28.373, tt:510.717\n",
      "Ep:18, loss:0.00003, loss_test:0.01998, lr:5.88e-02, fs:0.66946 (r=0.808,p=0.571),  time:28.406, tt:539.713\n",
      "Ep:19, loss:0.00003, loss_test:0.01952, lr:5.82e-02, fs:0.66109 (r=0.798,p=0.564),  time:28.487, tt:569.733\n",
      "Ep:20, loss:0.00003, loss_test:0.01915, lr:5.76e-02, fs:0.66667 (r=0.798,p=0.572),  time:28.500, tt:598.494\n",
      "Ep:21, loss:0.00003, loss_test:0.01890, lr:5.71e-02, fs:0.67234 (r=0.798,p=0.581),  time:28.502, tt:627.045\n",
      "Ep:22, loss:0.00003, loss_test:0.01876, lr:5.65e-02, fs:0.66953 (r=0.788,p=0.582),  time:28.555, tt:656.763\n",
      "Ep:23, loss:0.00003, loss_test:0.01864, lr:5.59e-02, fs:0.66379 (r=0.778,p=0.579),  time:28.648, tt:687.554\n",
      "Ep:24, loss:0.00003, loss_test:0.01848, lr:5.54e-02, fs:0.67241 (r=0.788,p=0.586),  time:28.710, tt:717.759\n",
      "Ep:25, loss:0.00003, loss_test:0.01819, lr:5.48e-02, fs:0.67241 (r=0.788,p=0.586),  time:28.779, tt:748.262\n",
      "Ep:26, loss:0.00003, loss_test:0.01806, lr:5.43e-02, fs:0.68421 (r=0.788,p=0.605),  time:28.837, tt:778.610\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01807, lr:5.43e-02, fs:0.69912 (r=0.798,p=0.622),  time:28.853, tt:807.897\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01805, lr:5.43e-02, fs:0.70270 (r=0.788,p=0.634),  time:28.921, tt:838.697\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01796, lr:5.43e-02, fs:0.70588 (r=0.788,p=0.639),  time:28.995, tt:869.864\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01798, lr:5.43e-02, fs:0.70270 (r=0.788,p=0.634),  time:29.078, tt:901.422\n",
      "Ep:31, loss:0.00002, loss_test:0.01796, lr:5.43e-02, fs:0.70000 (r=0.778,p=0.636),  time:29.124, tt:931.973\n",
      "Ep:32, loss:0.00002, loss_test:0.01777, lr:5.43e-02, fs:0.70588 (r=0.788,p=0.639),  time:29.118, tt:960.881\n",
      "Ep:33, loss:0.00002, loss_test:0.01758, lr:5.43e-02, fs:0.70588 (r=0.788,p=0.639),  time:29.135, tt:990.593\n",
      "Ep:34, loss:0.00002, loss_test:0.01761, lr:5.43e-02, fs:0.70588 (r=0.788,p=0.639),  time:29.151, tt:1020.270\n",
      "Ep:35, loss:0.00002, loss_test:0.01759, lr:5.43e-02, fs:0.70909 (r=0.788,p=0.645),  time:29.160, tt:1049.771\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01764, lr:5.43e-02, fs:0.70968 (r=0.778,p=0.653),  time:29.207, tt:1080.643\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01758, lr:5.43e-02, fs:0.71296 (r=0.778,p=0.658),  time:29.235, tt:1110.933\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01743, lr:5.43e-02, fs:0.73394 (r=0.808,p=0.672),  time:29.272, tt:1141.591\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01766, lr:5.43e-02, fs:0.72811 (r=0.798,p=0.669),  time:29.262, tt:1170.471\n",
      "Ep:40, loss:0.00002, loss_test:0.01769, lr:5.43e-02, fs:0.73832 (r=0.798,p=0.687),  time:29.253, tt:1199.358\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01784, lr:5.43e-02, fs:0.73333 (r=0.778,p=0.694),  time:29.245, tt:1228.272\n",
      "Ep:42, loss:0.00002, loss_test:0.01795, lr:5.43e-02, fs:0.72727 (r=0.768,p=0.691),  time:29.255, tt:1257.963\n",
      "Ep:43, loss:0.00002, loss_test:0.01806, lr:5.43e-02, fs:0.73430 (r=0.768,p=0.704),  time:29.298, tt:1289.111\n",
      "Ep:44, loss:0.00002, loss_test:0.01831, lr:5.43e-02, fs:0.73430 (r=0.768,p=0.704),  time:29.340, tt:1320.291\n",
      "Ep:45, loss:0.00001, loss_test:0.01827, lr:5.43e-02, fs:0.73786 (r=0.768,p=0.710),  time:29.361, tt:1350.627\n",
      "Ep:46, loss:0.00001, loss_test:0.01842, lr:5.43e-02, fs:0.74146 (r=0.768,p=0.717),  time:29.345, tt:1379.230\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01866, lr:5.43e-02, fs:0.74146 (r=0.768,p=0.717),  time:29.348, tt:1408.705\n",
      "Ep:48, loss:0.00001, loss_test:0.01880, lr:5.43e-02, fs:0.75962 (r=0.798,p=0.725),  time:29.328, tt:1437.069\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01919, lr:5.43e-02, fs:0.74146 (r=0.768,p=0.717),  time:29.310, tt:1465.503\n",
      "Ep:50, loss:0.00001, loss_test:0.01929, lr:5.43e-02, fs:0.75122 (r=0.778,p=0.726),  time:29.291, tt:1493.864\n",
      "Ep:51, loss:0.00001, loss_test:0.01957, lr:5.43e-02, fs:0.75490 (r=0.778,p=0.733),  time:29.275, tt:1522.303\n",
      "Ep:52, loss:0.00001, loss_test:0.01992, lr:5.43e-02, fs:0.75490 (r=0.778,p=0.733),  time:29.270, tt:1551.318\n",
      "Ep:53, loss:0.00001, loss_test:0.01996, lr:5.43e-02, fs:0.76923 (r=0.808,p=0.734),  time:29.250, tt:1579.488\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.02020, lr:5.43e-02, fs:0.77295 (r=0.808,p=0.741),  time:29.258, tt:1609.164\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.02057, lr:5.43e-02, fs:0.76699 (r=0.798,p=0.738),  time:29.284, tt:1639.927\n",
      "Ep:56, loss:0.00001, loss_test:0.02087, lr:5.43e-02, fs:0.77295 (r=0.808,p=0.741),  time:29.305, tt:1670.401\n",
      "Ep:57, loss:0.00001, loss_test:0.02092, lr:5.43e-02, fs:0.76923 (r=0.808,p=0.734),  time:29.302, tt:1699.497\n",
      "Ep:58, loss:0.00001, loss_test:0.02128, lr:5.43e-02, fs:0.77295 (r=0.808,p=0.741),  time:29.294, tt:1728.361\n",
      "Ep:59, loss:0.00001, loss_test:0.02171, lr:5.43e-02, fs:0.75490 (r=0.778,p=0.733),  time:29.295, tt:1757.728\n",
      "Ep:60, loss:0.00001, loss_test:0.02175, lr:5.43e-02, fs:0.78261 (r=0.818,p=0.750),  time:29.284, tt:1786.340\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.02195, lr:5.43e-02, fs:0.78641 (r=0.818,p=0.757),  time:29.288, tt:1815.848\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.02244, lr:5.43e-02, fs:0.76617 (r=0.778,p=0.755),  time:29.288, tt:1845.172\n",
      "Ep:63, loss:0.00001, loss_test:0.02252, lr:5.43e-02, fs:0.78641 (r=0.818,p=0.757),  time:29.275, tt:1873.608\n",
      "Ep:64, loss:0.00001, loss_test:0.02256, lr:5.43e-02, fs:0.79024 (r=0.818,p=0.764),  time:29.262, tt:1902.050\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.02288, lr:5.43e-02, fs:0.79024 (r=0.818,p=0.764),  time:29.255, tt:1930.839\n",
      "Ep:66, loss:0.00001, loss_test:0.02311, lr:5.43e-02, fs:0.79412 (r=0.818,p=0.771),  time:29.256, tt:1960.142\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.02325, lr:5.43e-02, fs:0.79412 (r=0.818,p=0.771),  time:29.281, tt:1991.099\n",
      "Ep:68, loss:0.00001, loss_test:0.02365, lr:5.43e-02, fs:0.76000 (r=0.768,p=0.752),  time:29.285, tt:2020.681\n",
      "Ep:69, loss:0.00001, loss_test:0.02384, lr:5.43e-02, fs:0.78641 (r=0.818,p=0.757),  time:29.284, tt:2049.895\n",
      "Ep:70, loss:0.00001, loss_test:0.02400, lr:5.43e-02, fs:0.77228 (r=0.788,p=0.757),  time:29.272, tt:2078.278\n",
      "Ep:71, loss:0.00001, loss_test:0.02405, lr:5.43e-02, fs:0.79412 (r=0.818,p=0.771),  time:29.265, tt:2107.084\n",
      "Ep:72, loss:0.00001, loss_test:0.02441, lr:5.43e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.258, tt:2135.835\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.02479, lr:5.43e-02, fs:0.79602 (r=0.808,p=0.784),  time:29.267, tt:2165.773\n",
      "Ep:74, loss:0.00001, loss_test:0.02498, lr:5.43e-02, fs:0.80597 (r=0.818,p=0.794),  time:29.286, tt:2196.416\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.02525, lr:5.43e-02, fs:0.80597 (r=0.818,p=0.794),  time:29.291, tt:2226.134\n",
      "Ep:76, loss:0.00001, loss_test:0.02541, lr:5.43e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.299, tt:2255.997\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.02586, lr:5.43e-02, fs:0.80402 (r=0.808,p=0.800),  time:29.302, tt:2285.550\n",
      "Ep:78, loss:0.00001, loss_test:0.02601, lr:5.43e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.290, tt:2313.925\n",
      "Ep:79, loss:0.00001, loss_test:0.02641, lr:5.43e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.290, tt:2343.229\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.02660, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.287, tt:2372.275\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.02690, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.287, tt:2401.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:82, loss:0.00001, loss_test:0.02757, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.278, tt:2430.094\n",
      "Ep:83, loss:0.00001, loss_test:0.02773, lr:5.43e-02, fs:0.79793 (r=0.778,p=0.819),  time:29.288, tt:2460.214\n",
      "Ep:84, loss:0.00001, loss_test:0.02778, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.285, tt:2489.201\n",
      "Ep:85, loss:0.00001, loss_test:0.02806, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:29.281, tt:2518.184\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.02857, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.289, tt:2548.127\n",
      "Ep:87, loss:0.00001, loss_test:0.02887, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.299, tt:2578.282\n",
      "Ep:88, loss:0.00001, loss_test:0.02896, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:29.299, tt:2607.602\n",
      "Ep:89, loss:0.00001, loss_test:0.02935, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:29.310, tt:2637.897\n",
      "Ep:90, loss:0.00001, loss_test:0.02995, lr:5.43e-02, fs:0.82051 (r=0.808,p=0.833),  time:29.319, tt:2668.032\n",
      "Ep:91, loss:0.00001, loss_test:0.03009, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:29.331, tt:2698.447\n",
      "Ep:92, loss:0.00000, loss_test:0.03014, lr:5.43e-02, fs:0.83077 (r=0.818,p=0.844),  time:29.360, tt:2730.478\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00000, loss_test:0.03076, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:29.378, tt:2761.517\n",
      "Ep:94, loss:0.00000, loss_test:0.03059, lr:5.43e-02, fs:0.82902 (r=0.808,p=0.851),  time:29.405, tt:2793.521\n",
      "Ep:95, loss:0.00000, loss_test:0.03154, lr:5.43e-02, fs:0.83077 (r=0.818,p=0.844),  time:29.418, tt:2824.161\n",
      "Ep:96, loss:0.00000, loss_test:0.03131, lr:5.43e-02, fs:0.79348 (r=0.737,p=0.859),  time:29.425, tt:2854.212\n",
      "Ep:97, loss:0.00000, loss_test:0.03199, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:29.437, tt:2884.869\n",
      "Ep:98, loss:0.00000, loss_test:0.03190, lr:5.43e-02, fs:0.78689 (r=0.727,p=0.857),  time:29.445, tt:2915.018\n",
      "Ep:99, loss:0.00000, loss_test:0.03259, lr:5.43e-02, fs:0.83505 (r=0.818,p=0.853),  time:29.453, tt:2945.277\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00000, loss_test:0.03222, lr:5.43e-02, fs:0.79348 (r=0.737,p=0.859),  time:29.464, tt:2975.834\n",
      "Ep:101, loss:0.00000, loss_test:0.03360, lr:5.43e-02, fs:0.83938 (r=0.818,p=0.862),  time:29.477, tt:3006.665\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00000, loss_test:0.03316, lr:5.43e-02, fs:0.81283 (r=0.768,p=0.864),  time:29.491, tt:3037.589\n",
      "Ep:103, loss:0.00000, loss_test:0.03360, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.510, tt:3069.024\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00000, loss_test:0.03398, lr:5.43e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.525, tt:3100.169\n",
      "Ep:105, loss:0.00000, loss_test:0.03441, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.543, tt:3131.528\n",
      "Ep:106, loss:0.00000, loss_test:0.03469, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.539, tt:3160.685\n",
      "Ep:107, loss:0.00000, loss_test:0.03482, lr:5.43e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.545, tt:3190.892\n",
      "Ep:108, loss:0.00000, loss_test:0.03557, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.540, tt:3219.911\n",
      "Ep:109, loss:0.00000, loss_test:0.03542, lr:5.43e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.524, tt:3247.622\n",
      "Ep:110, loss:0.00000, loss_test:0.03590, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:29.534, tt:3278.259\n",
      "Ep:111, loss:0.00000, loss_test:0.03620, lr:5.43e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.564, tt:3311.122\n",
      "Ep:112, loss:0.00000, loss_test:0.03662, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.559, tt:3340.217\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.03688, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.559, tt:3369.756\n",
      "Ep:114, loss:0.00000, loss_test:0.03693, lr:5.43e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.573, tt:3400.862\n",
      "Ep:115, loss:0.00000, loss_test:0.03760, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.569, tt:3430.009\n",
      "Ep:116, loss:0.00000, loss_test:0.03764, lr:5.43e-02, fs:0.82979 (r=0.788,p=0.876),  time:29.575, tt:3460.252\n",
      "Ep:117, loss:0.00000, loss_test:0.03830, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.572, tt:3489.490\n",
      "Ep:118, loss:0.00000, loss_test:0.03803, lr:5.43e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.562, tt:3517.889\n",
      "Ep:119, loss:0.00000, loss_test:0.03909, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.563, tt:3547.615\n",
      "Ep:120, loss:0.00000, loss_test:0.03905, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.584, tt:3579.686\n",
      "Ep:121, loss:0.00000, loss_test:0.03932, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.588, tt:3609.722\n",
      "Ep:122, loss:0.00000, loss_test:0.03974, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.587, tt:3639.196\n",
      "Ep:123, loss:0.00000, loss_test:0.03986, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.592, tt:3669.414\n",
      "Ep:124, loss:0.00000, loss_test:0.04028, lr:5.37e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.591, tt:3698.897\n",
      "Ep:125, loss:0.00000, loss_test:0.04035, lr:5.32e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.604, tt:3730.065\n",
      "Ep:126, loss:0.00000, loss_test:0.04104, lr:5.27e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.621, tt:3761.925\n",
      "Ep:127, loss:0.00000, loss_test:0.04081, lr:5.21e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.623, tt:3791.804\n",
      "Ep:128, loss:0.00000, loss_test:0.04142, lr:5.16e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.639, tt:3823.389\n",
      "Ep:129, loss:0.00000, loss_test:0.04166, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.645, tt:3853.798\n",
      "Ep:130, loss:0.00000, loss_test:0.04163, lr:5.06e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.652, tt:3884.389\n",
      "Ep:131, loss:0.00000, loss_test:0.04228, lr:5.01e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.656, tt:3914.604\n",
      "Ep:132, loss:0.00000, loss_test:0.04250, lr:4.96e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.664, tt:3945.319\n",
      "Ep:133, loss:0.00000, loss_test:0.04241, lr:4.91e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.671, tt:3975.856\n",
      "Ep:134, loss:0.00000, loss_test:0.04327, lr:4.86e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.661, tt:4004.267\n",
      "Ep:135, loss:0.00000, loss_test:0.04287, lr:4.81e-02, fs:0.81720 (r=0.768,p=0.874),  time:29.666, tt:4034.515\n",
      "Ep:136, loss:0.00000, loss_test:0.04360, lr:4.76e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.675, tt:4065.541\n",
      "Ep:137, loss:0.00000, loss_test:0.04303, lr:4.71e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.687, tt:4096.818\n",
      "Ep:138, loss:0.00000, loss_test:0.04443, lr:4.67e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.684, tt:4126.029\n",
      "Ep:139, loss:0.00000, loss_test:0.04362, lr:4.62e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.675, tt:4154.543\n",
      "Ep:140, loss:0.00000, loss_test:0.04431, lr:4.57e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.681, tt:4185.074\n",
      "Ep:141, loss:0.00000, loss_test:0.04415, lr:4.53e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.682, tt:4214.777\n",
      "Ep:142, loss:0.00000, loss_test:0.04510, lr:4.48e-02, fs:0.84817 (r=0.818,p=0.880),  time:29.692, tt:4245.930\n",
      "Ep:143, loss:0.00000, loss_test:0.04459, lr:4.44e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.694, tt:4275.967\n",
      "Ep:144, loss:0.00000, loss_test:0.04523, lr:4.39e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.701, tt:4306.633\n",
      "Ep:145, loss:0.00000, loss_test:0.04532, lr:4.35e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.703, tt:4336.645\n",
      "Ep:146, loss:0.00000, loss_test:0.04573, lr:4.31e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.698, tt:4365.656\n",
      "Ep:147, loss:0.00000, loss_test:0.04563, lr:4.26e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.697, tt:4395.084\n",
      "Ep:148, loss:0.00000, loss_test:0.04595, lr:4.22e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.701, tt:4425.395\n",
      "Ep:149, loss:0.00000, loss_test:0.04629, lr:4.18e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.697, tt:4454.567\n",
      "Ep:150, loss:0.00000, loss_test:0.04621, lr:4.14e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.700, tt:4484.635\n",
      "Ep:151, loss:0.00000, loss_test:0.04633, lr:4.10e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.700, tt:4514.414\n",
      "Ep:152, loss:0.00000, loss_test:0.04693, lr:4.05e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.704, tt:4544.748\n",
      "Ep:153, loss:0.00000, loss_test:0.04674, lr:4.01e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.715, tt:4576.058\n",
      "Ep:154, loss:0.00000, loss_test:0.04687, lr:3.97e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.723, tt:4607.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.04733, lr:3.93e-02, fs:0.82353 (r=0.778,p=0.875),  time:29.722, tt:4636.584\n",
      "Ep:156, loss:0.00000, loss_test:0.04743, lr:3.89e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.717, tt:4665.604\n",
      "Ep:157, loss:0.00000, loss_test:0.04730, lr:3.86e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.726, tt:4696.687\n",
      "Ep:158, loss:0.00000, loss_test:0.04789, lr:3.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.716, tt:4724.816\n",
      "Ep:159, loss:0.00000, loss_test:0.04781, lr:3.78e-02, fs:0.81720 (r=0.768,p=0.874),  time:29.719, tt:4754.983\n",
      "Ep:160, loss:0.00000, loss_test:0.04803, lr:3.74e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.733, tt:4787.019\n",
      "Ep:161, loss:0.00000, loss_test:0.04790, lr:3.70e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.728, tt:4815.998\n",
      "Ep:162, loss:0.00000, loss_test:0.04836, lr:3.67e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.734, tt:4846.705\n",
      "Ep:163, loss:0.00000, loss_test:0.04832, lr:3.63e-02, fs:0.82979 (r=0.788,p=0.876),  time:29.746, tt:4878.348\n",
      "Ep:164, loss:0.00000, loss_test:0.04863, lr:3.59e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.756, tt:4909.683\n",
      "Ep:165, loss:0.00000, loss_test:0.04856, lr:3.56e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.771, tt:4941.999\n",
      "Ep:166, loss:0.00000, loss_test:0.04879, lr:3.52e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.786, tt:4974.258\n",
      "Ep:167, loss:0.00000, loss_test:0.04899, lr:3.49e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.790, tt:5004.647\n",
      "Ep:168, loss:0.00000, loss_test:0.04894, lr:3.45e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.792, tt:5034.905\n",
      "Ep:169, loss:0.00000, loss_test:0.04935, lr:3.42e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.801, tt:5066.184\n",
      "Ep:170, loss:0.00000, loss_test:0.04930, lr:3.38e-02, fs:0.81081 (r=0.758,p=0.872),  time:29.811, tt:5097.639\n",
      "Ep:171, loss:0.00000, loss_test:0.04933, lr:3.35e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.813, tt:5127.812\n",
      "Ep:172, loss:0.00000, loss_test:0.04945, lr:3.32e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.812, tt:5157.560\n",
      "Ep:173, loss:0.00000, loss_test:0.04989, lr:3.28e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.816, tt:5187.939\n",
      "Ep:174, loss:0.00000, loss_test:0.04978, lr:3.25e-02, fs:0.81720 (r=0.768,p=0.874),  time:29.820, tt:5218.466\n",
      "Ep:175, loss:0.00000, loss_test:0.04994, lr:3.22e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.824, tt:5249.093\n",
      "Ep:176, loss:0.00000, loss_test:0.04994, lr:3.19e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.825, tt:5279.069\n",
      "Ep:177, loss:0.00000, loss_test:0.05003, lr:3.15e-02, fs:0.82979 (r=0.788,p=0.876),  time:29.826, tt:5309.109\n",
      "Ep:178, loss:0.00000, loss_test:0.05037, lr:3.12e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.833, tt:5340.040\n",
      "Ep:179, loss:0.00000, loss_test:0.05015, lr:3.09e-02, fs:0.81915 (r=0.778,p=0.865),  time:29.836, tt:5370.520\n",
      "Ep:180, loss:0.00000, loss_test:0.05038, lr:3.06e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.839, tt:5400.930\n",
      "Ep:181, loss:0.00000, loss_test:0.05077, lr:3.03e-02, fs:0.82540 (r=0.788,p=0.867),  time:29.841, tt:5431.006\n",
      "Ep:182, loss:0.00000, loss_test:0.05064, lr:3.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:29.847, tt:5462.020\n",
      "Ep:183, loss:0.00000, loss_test:0.05079, lr:2.97e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.842, tt:5490.936\n",
      "Ep:184, loss:0.00000, loss_test:0.05078, lr:2.94e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.840, tt:5520.400\n",
      "Ep:185, loss:0.00000, loss_test:0.05113, lr:2.91e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.846, tt:5551.407\n",
      "Ep:186, loss:0.00000, loss_test:0.05088, lr:2.88e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.852, tt:5582.337\n",
      "Ep:187, loss:0.00000, loss_test:0.05126, lr:2.85e-02, fs:0.82540 (r=0.788,p=0.867),  time:29.855, tt:5612.779\n",
      "Ep:188, loss:0.00000, loss_test:0.05116, lr:2.82e-02, fs:0.82540 (r=0.788,p=0.867),  time:29.869, tt:5645.233\n",
      "Ep:189, loss:0.00000, loss_test:0.05134, lr:2.80e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.872, tt:5675.664\n",
      "Ep:190, loss:0.00000, loss_test:0.05148, lr:2.77e-02, fs:0.82540 (r=0.788,p=0.867),  time:29.879, tt:5706.803\n",
      "Ep:191, loss:0.00000, loss_test:0.05137, lr:2.74e-02, fs:0.82540 (r=0.788,p=0.867),  time:29.883, tt:5737.467\n",
      "Ep:192, loss:0.00000, loss_test:0.05171, lr:2.71e-02, fs:0.83158 (r=0.798,p=0.868),  time:29.889, tt:5768.510\n",
      "Ep:193, loss:0.00000, loss_test:0.05157, lr:2.69e-02, fs:0.76404 (r=0.687,p=0.861),  time:29.891, tt:5798.861\n",
      "Ep:194, loss:0.00000, loss_test:0.05183, lr:2.66e-02, fs:0.82540 (r=0.788,p=0.867),  time:29.883, tt:5827.169\n",
      "Ep:195, loss:0.00000, loss_test:0.05176, lr:2.63e-02, fs:0.81915 (r=0.778,p=0.865),  time:29.875, tt:5855.495\n",
      "Ep:196, loss:0.00000, loss_test:0.05187, lr:2.61e-02, fs:0.80645 (r=0.758,p=0.862),  time:29.869, tt:5884.194\n",
      "Ep:197, loss:0.00000, loss_test:0.05211, lr:2.58e-02, fs:0.82979 (r=0.788,p=0.876),  time:29.859, tt:5912.007\n",
      "Ep:198, loss:0.00000, loss_test:0.05187, lr:2.55e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.847, tt:5939.510\n",
      "Ep:199, loss:0.00000, loss_test:0.05228, lr:2.53e-02, fs:0.82979 (r=0.788,p=0.876),  time:29.838, tt:5967.673\n",
      "Ep:200, loss:0.00000, loss_test:0.05212, lr:2.50e-02, fs:0.81081 (r=0.758,p=0.872),  time:29.820, tt:5993.732\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13261, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:28.759, tt:28.759\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12860, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:29.969, tt:59.937\n",
      "Ep:2, loss:0.00026, loss_test:0.12444, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:30.823, tt:92.469\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12188, lr:1.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:31.378, tt:125.513\n",
      "Ep:4, loss:0.00025, loss_test:0.12074, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:31.608, tt:158.041\n",
      "Ep:5, loss:0.00025, loss_test:0.11947, lr:1.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:31.261, tt:187.564\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11793, lr:1.00e-02, fs:0.68936 (r=0.818,p=0.596),  time:30.952, tt:216.665\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11656, lr:1.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:30.956, tt:247.651\n",
      "Ep:8, loss:0.00023, loss_test:0.11559, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:31.356, tt:282.202\n",
      "Ep:9, loss:0.00022, loss_test:0.11398, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:31.534, tt:315.342\n",
      "Ep:10, loss:0.00022, loss_test:0.11227, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:31.649, tt:348.141\n",
      "Ep:11, loss:0.00021, loss_test:0.11068, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:31.609, tt:379.304\n",
      "Ep:12, loss:0.00021, loss_test:0.10956, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:31.588, tt:410.643\n",
      "Ep:13, loss:0.00021, loss_test:0.10890, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:31.633, tt:442.862\n",
      "Ep:14, loss:0.00020, loss_test:0.10849, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:31.753, tt:476.297\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10736, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:31.815, tt:509.046\n",
      "Ep:16, loss:0.00020, loss_test:0.10591, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:31.754, tt:539.813\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10479, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:31.789, tt:572.210\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.10404, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:31.708, tt:602.459\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.10351, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:31.746, tt:634.920\n",
      "Ep:20, loss:0.00018, loss_test:0.10248, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:31.825, tt:668.335\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.10167, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:31.837, tt:700.410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00017, loss_test:0.10066, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:31.807, tt:731.558\n",
      "Ep:23, loss:0.00017, loss_test:0.10009, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:31.831, tt:763.953\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09966, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:31.816, tt:795.401\n",
      "Ep:25, loss:0.00016, loss_test:0.09940, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:31.801, tt:826.821\n",
      "Ep:26, loss:0.00016, loss_test:0.09866, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:31.803, tt:858.690\n",
      "Ep:27, loss:0.00015, loss_test:0.09770, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:31.835, tt:891.370\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09732, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:31.878, tt:924.459\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09649, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:31.863, tt:955.898\n",
      "Ep:30, loss:0.00014, loss_test:0.09572, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:31.853, tt:987.429\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09543, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:31.887, tt:1020.387\n",
      "Ep:32, loss:0.00013, loss_test:0.09137, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:31.907, tt:1052.942\n",
      "Ep:33, loss:0.00012, loss_test:0.09473, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:31.898, tt:1084.546\n",
      "Ep:34, loss:0.00012, loss_test:0.08976, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:31.874, tt:1115.582\n",
      "Ep:35, loss:0.00011, loss_test:0.09100, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:31.875, tt:1147.497\n",
      "Ep:36, loss:0.00011, loss_test:0.08934, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:31.879, tt:1179.541\n",
      "Ep:37, loss:0.00010, loss_test:0.08846, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:31.832, tt:1209.604\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.08865, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:31.822, tt:1241.077\n",
      "Ep:39, loss:0.00009, loss_test:0.08990, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:31.840, tt:1273.612\n",
      "Ep:40, loss:0.00009, loss_test:0.08620, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:31.840, tt:1305.439\n",
      "Ep:41, loss:0.00009, loss_test:0.08712, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:31.845, tt:1337.479\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.08960, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:31.840, tt:1369.110\n",
      "Ep:43, loss:0.00009, loss_test:0.08740, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.827, tt:1400.369\n",
      "Ep:44, loss:0.00008, loss_test:0.08036, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:31.814, tt:1431.652\n",
      "Ep:45, loss:0.00008, loss_test:0.09151, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:31.819, tt:1463.667\n",
      "Ep:46, loss:0.00007, loss_test:0.07984, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.804, tt:1494.803\n",
      "Ep:47, loss:0.00007, loss_test:0.07941, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:31.808, tt:1526.786\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.08932, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:31.809, tt:1558.645\n",
      "Ep:49, loss:0.00007, loss_test:0.08110, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.778, tt:1588.903\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.07661, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:31.748, tt:1619.149\n",
      "Ep:51, loss:0.00006, loss_test:0.08993, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:31.737, tt:1650.308\n",
      "Ep:52, loss:0.00006, loss_test:0.07434, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:31.708, tt:1680.527\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.08926, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:31.715, tt:1712.613\n",
      "Ep:54, loss:0.00006, loss_test:0.07814, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:31.727, tt:1745.005\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.08205, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:31.730, tt:1776.854\n",
      "Ep:56, loss:0.00005, loss_test:0.07420, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.722, tt:1808.134\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.07300, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:31.726, tt:1840.103\n",
      "Ep:58, loss:0.00005, loss_test:0.08306, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.707, tt:1870.689\n",
      "Ep:59, loss:0.00004, loss_test:0.07210, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:31.704, tt:1902.265\n",
      "Ep:60, loss:0.00004, loss_test:0.07634, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.712, tt:1934.459\n",
      "Ep:61, loss:0.00004, loss_test:0.07969, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.719, tt:1966.602\n",
      "Ep:62, loss:0.00004, loss_test:0.06929, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.717, tt:1998.197\n",
      "Ep:63, loss:0.00004, loss_test:0.09540, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:31.698, tt:2028.652\n",
      "Ep:64, loss:0.00005, loss_test:0.07681, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:31.692, tt:2059.955\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.07842, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:31.665, tt:2089.920\n",
      "Ep:66, loss:0.00004, loss_test:0.07199, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:31.671, tt:2121.971\n",
      "Ep:67, loss:0.00004, loss_test:0.07436, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:31.661, tt:2152.978\n",
      "Ep:68, loss:0.00003, loss_test:0.07464, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:31.669, tt:2185.186\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00003, loss_test:0.07343, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:31.650, tt:2215.534\n",
      "Ep:70, loss:0.00003, loss_test:0.07270, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.645, tt:2246.817\n",
      "Ep:71, loss:0.00003, loss_test:0.07355, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.637, tt:2277.872\n",
      "Ep:72, loss:0.00003, loss_test:0.07560, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.620, tt:2308.271\n",
      "Ep:73, loss:0.00003, loss_test:0.07237, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.620, tt:2339.847\n",
      "Ep:74, loss:0.00003, loss_test:0.06957, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:31.624, tt:2371.782\n",
      "Ep:75, loss:0.00003, loss_test:0.07708, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.626, tt:2403.549\n",
      "Ep:76, loss:0.00003, loss_test:0.06960, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.610, tt:2433.954\n",
      "Ep:77, loss:0.00003, loss_test:0.07455, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.603, tt:2465.070\n",
      "Ep:78, loss:0.00003, loss_test:0.07670, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.594, tt:2495.917\n",
      "Ep:79, loss:0.00003, loss_test:0.07127, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.586, tt:2526.917\n",
      "Ep:80, loss:0.00002, loss_test:0.06990, lr:9.90e-03, fs:0.87562 (r=0.889,p=0.863),  time:31.586, tt:2558.451\n",
      "Ep:81, loss:0.00002, loss_test:0.07286, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.576, tt:2589.262\n",
      "Ep:82, loss:0.00002, loss_test:0.07014, lr:9.70e-03, fs:0.87000 (r=0.879,p=0.861),  time:31.573, tt:2620.569\n",
      "Ep:83, loss:0.00002, loss_test:0.07348, lr:9.61e-03, fs:0.88083 (r=0.859,p=0.904),  time:31.573, tt:2652.108\n",
      "Ep:84, loss:0.00002, loss_test:0.06984, lr:9.51e-03, fs:0.87437 (r=0.879,p=0.870),  time:31.560, tt:2682.562\n",
      "Ep:85, loss:0.00002, loss_test:0.07185, lr:9.41e-03, fs:0.88660 (r=0.869,p=0.905),  time:31.568, tt:2714.809\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.07636, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:31.570, tt:2746.615\n",
      "Ep:87, loss:0.00002, loss_test:0.06820, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:31.580, tt:2779.001\n",
      "Ep:88, loss:0.00002, loss_test:0.08011, lr:9.41e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.588, tt:2811.292\n",
      "Ep:89, loss:0.00002, loss_test:0.07061, lr:9.41e-03, fs:0.89231 (r=0.879,p=0.906),  time:31.594, tt:2843.478\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.07430, lr:9.41e-03, fs:0.87629 (r=0.859,p=0.895),  time:31.597, tt:2875.342\n",
      "Ep:91, loss:0.00002, loss_test:0.07034, lr:9.41e-03, fs:0.89231 (r=0.879,p=0.906),  time:31.603, tt:2907.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:92, loss:0.00002, loss_test:0.07440, lr:9.41e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.609, tt:2939.617\n",
      "Ep:93, loss:0.00002, loss_test:0.06955, lr:9.41e-03, fs:0.89796 (r=0.889,p=0.907),  time:31.620, tt:2972.308\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.07400, lr:9.41e-03, fs:0.88660 (r=0.869,p=0.905),  time:31.615, tt:3003.445\n",
      "Ep:95, loss:0.00002, loss_test:0.07142, lr:9.41e-03, fs:0.89340 (r=0.889,p=0.898),  time:31.618, tt:3035.321\n",
      "Ep:96, loss:0.00002, loss_test:0.07759, lr:9.41e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.623, tt:3067.440\n",
      "Ep:97, loss:0.00002, loss_test:0.07152, lr:9.41e-03, fs:0.89340 (r=0.889,p=0.898),  time:31.618, tt:3098.595\n",
      "Ep:98, loss:0.00002, loss_test:0.07315, lr:9.41e-03, fs:0.88205 (r=0.869,p=0.896),  time:31.621, tt:3130.443\n",
      "Ep:99, loss:0.00002, loss_test:0.07132, lr:9.41e-03, fs:0.88205 (r=0.869,p=0.896),  time:31.636, tt:3163.551\n",
      "Ep:100, loss:0.00002, loss_test:0.07501, lr:9.41e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.635, tt:3195.109\n",
      "Ep:101, loss:0.00002, loss_test:0.06977, lr:9.41e-03, fs:0.89691 (r=0.879,p=0.916),  time:31.649, tt:3228.241\n",
      "Ep:102, loss:0.00002, loss_test:0.07297, lr:9.41e-03, fs:0.89796 (r=0.889,p=0.907),  time:31.659, tt:3260.834\n",
      "Ep:103, loss:0.00002, loss_test:0.07080, lr:9.41e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.647, tt:3291.238\n",
      "Ep:104, loss:0.00002, loss_test:0.07229, lr:9.41e-03, fs:0.90256 (r=0.889,p=0.917),  time:31.653, tt:3323.600\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.07581, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.656, tt:3355.546\n",
      "Ep:106, loss:0.00002, loss_test:0.06938, lr:9.41e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.658, tt:3387.365\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.08019, lr:9.41e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.667, tt:3420.040\n",
      "Ep:108, loss:0.00002, loss_test:0.07120, lr:9.41e-03, fs:0.90155 (r=0.879,p=0.926),  time:31.660, tt:3450.965\n",
      "Ep:109, loss:0.00002, loss_test:0.07776, lr:9.41e-03, fs:0.89005 (r=0.859,p=0.924),  time:31.656, tt:3482.168\n",
      "Ep:110, loss:0.00002, loss_test:0.07070, lr:9.41e-03, fs:0.89691 (r=0.879,p=0.916),  time:31.656, tt:3513.828\n",
      "Ep:111, loss:0.00002, loss_test:0.07951, lr:9.41e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.670, tt:3547.015\n",
      "Ep:112, loss:0.00002, loss_test:0.07547, lr:9.41e-03, fs:0.89005 (r=0.859,p=0.924),  time:31.678, tt:3579.578\n",
      "Ep:113, loss:0.00001, loss_test:0.07277, lr:9.41e-03, fs:0.90256 (r=0.889,p=0.917),  time:31.677, tt:3611.126\n",
      "Ep:114, loss:0.00001, loss_test:0.07593, lr:9.41e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.682, tt:3643.457\n",
      "Ep:115, loss:0.00001, loss_test:0.07124, lr:9.41e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.681, tt:3674.940\n",
      "Ep:116, loss:0.00001, loss_test:0.07736, lr:9.41e-03, fs:0.88660 (r=0.869,p=0.905),  time:31.680, tt:3706.524\n",
      "Ep:117, loss:0.00001, loss_test:0.07316, lr:9.41e-03, fs:0.89691 (r=0.879,p=0.916),  time:31.705, tt:3741.176\n",
      "Ep:118, loss:0.00001, loss_test:0.07394, lr:9.32e-03, fs:0.90256 (r=0.889,p=0.917),  time:31.707, tt:3773.147\n",
      "Ep:119, loss:0.00001, loss_test:0.07606, lr:9.23e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.703, tt:3804.330\n",
      "Ep:120, loss:0.00001, loss_test:0.07446, lr:9.14e-03, fs:0.90256 (r=0.889,p=0.917),  time:31.705, tt:3836.343\n",
      "Ep:121, loss:0.00001, loss_test:0.07296, lr:9.04e-03, fs:0.90155 (r=0.879,p=0.926),  time:31.704, tt:3867.942\n",
      "Ep:122, loss:0.00001, loss_test:0.07614, lr:8.95e-03, fs:0.88889 (r=0.848,p=0.933),  time:31.707, tt:3899.977\n",
      "Ep:123, loss:0.00001, loss_test:0.07186, lr:8.86e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.710, tt:3932.084\n",
      "Ep:124, loss:0.00001, loss_test:0.07598, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:31.712, tt:3964.041\n",
      "Ep:125, loss:0.00001, loss_test:0.07255, lr:8.69e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.717, tt:3996.392\n",
      "Ep:126, loss:0.00001, loss_test:0.07506, lr:8.60e-03, fs:0.90155 (r=0.879,p=0.926),  time:31.719, tt:4028.300\n",
      "Ep:127, loss:0.00001, loss_test:0.07623, lr:8.51e-03, fs:0.89247 (r=0.838,p=0.954),  time:31.717, tt:4059.719\n",
      "Ep:128, loss:0.00001, loss_test:0.07464, lr:8.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.717, tt:4091.511\n",
      "Ep:129, loss:0.00001, loss_test:0.07549, lr:8.35e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.719, tt:4123.505\n",
      "Ep:130, loss:0.00001, loss_test:0.07640, lr:8.26e-03, fs:0.89005 (r=0.859,p=0.924),  time:31.716, tt:4154.772\n",
      "Ep:131, loss:0.00001, loss_test:0.07256, lr:8.18e-03, fs:0.90722 (r=0.889,p=0.926),  time:31.709, tt:4185.554\n",
      "Ep:132, loss:0.00001, loss_test:0.07623, lr:8.10e-03, fs:0.89362 (r=0.848,p=0.944),  time:31.710, tt:4217.420\n",
      "Ep:133, loss:0.00001, loss_test:0.07608, lr:8.02e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.716, tt:4249.947\n",
      "Ep:134, loss:0.00001, loss_test:0.07263, lr:7.94e-03, fs:0.91099 (r=0.879,p=0.946),  time:31.719, tt:4282.058\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00001, loss_test:0.08009, lr:7.94e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.724, tt:4314.435\n",
      "Ep:136, loss:0.00001, loss_test:0.07429, lr:7.94e-03, fs:0.91099 (r=0.879,p=0.946),  time:31.717, tt:4345.296\n",
      "Ep:137, loss:0.00001, loss_test:0.07684, lr:7.94e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.716, tt:4376.855\n",
      "Ep:138, loss:0.00001, loss_test:0.07710, lr:7.94e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.718, tt:4408.841\n",
      "Ep:139, loss:0.00001, loss_test:0.07439, lr:7.94e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.739, tt:4443.517\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00001, loss_test:0.07752, lr:7.94e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.740, tt:4475.321\n",
      "Ep:141, loss:0.00001, loss_test:0.07636, lr:7.94e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.736, tt:4506.546\n",
      "Ep:142, loss:0.00001, loss_test:0.07597, lr:7.94e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.732, tt:4537.647\n",
      "Ep:143, loss:0.00001, loss_test:0.07641, lr:7.94e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.734, tt:4569.699\n",
      "Ep:144, loss:0.00001, loss_test:0.07719, lr:7.94e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.735, tt:4601.582\n",
      "Ep:145, loss:0.00001, loss_test:0.07584, lr:7.94e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.729, tt:4632.366\n",
      "Ep:146, loss:0.00001, loss_test:0.07670, lr:7.94e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.725, tt:4663.523\n",
      "Ep:147, loss:0.00001, loss_test:0.07622, lr:7.94e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.725, tt:4695.238\n",
      "Ep:148, loss:0.00001, loss_test:0.07908, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.731, tt:4727.914\n",
      "Ep:149, loss:0.00001, loss_test:0.07477, lr:7.94e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.729, tt:4759.389\n",
      "Ep:150, loss:0.00001, loss_test:0.07662, lr:7.94e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.711, tt:4788.305\n",
      "Ep:151, loss:0.00001, loss_test:0.07702, lr:7.86e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.696, tt:4817.861\n",
      "Ep:152, loss:0.00001, loss_test:0.07540, lr:7.78e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.689, tt:4848.489\n",
      "Ep:153, loss:0.00001, loss_test:0.07882, lr:7.70e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.688, tt:4879.956\n",
      "Ep:154, loss:0.00001, loss_test:0.07522, lr:7.62e-03, fs:0.91099 (r=0.879,p=0.946),  time:31.700, tt:4913.468\n",
      "Ep:155, loss:0.00001, loss_test:0.07806, lr:7.55e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.710, tt:4946.771\n",
      "Ep:156, loss:0.00001, loss_test:0.07734, lr:7.47e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.716, tt:4979.376\n",
      "Ep:157, loss:0.00001, loss_test:0.07634, lr:7.40e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.718, tt:5011.479\n",
      "Ep:158, loss:0.00001, loss_test:0.07724, lr:7.32e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.707, tt:5041.434\n",
      "Ep:159, loss:0.00001, loss_test:0.07768, lr:7.25e-03, fs:0.89691 (r=0.879,p=0.916),  time:31.715, tt:5074.342\n",
      "Ep:160, loss:0.00001, loss_test:0.07709, lr:7.18e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.713, tt:5105.829\n",
      "Ep:161, loss:0.00001, loss_test:0.07629, lr:7.11e-03, fs:0.89005 (r=0.859,p=0.924),  time:31.727, tt:5139.781\n",
      "Ep:162, loss:0.00001, loss_test:0.07831, lr:7.03e-03, fs:0.90155 (r=0.879,p=0.926),  time:31.730, tt:5171.940\n",
      "Ep:163, loss:0.00001, loss_test:0.07669, lr:6.96e-03, fs:0.89583 (r=0.869,p=0.925),  time:31.727, tt:5203.228\n",
      "Ep:164, loss:0.00001, loss_test:0.07775, lr:6.89e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.727, tt:5234.896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:165, loss:0.00001, loss_test:0.07719, lr:6.83e-03, fs:0.89583 (r=0.869,p=0.925),  time:31.718, tt:5265.177\n",
      "Ep:166, loss:0.00001, loss_test:0.07773, lr:6.76e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.712, tt:5295.900\n",
      "Ep:167, loss:0.00001, loss_test:0.07805, lr:6.69e-03, fs:0.90052 (r=0.869,p=0.935),  time:31.712, tt:5327.663\n",
      "Ep:168, loss:0.00001, loss_test:0.07816, lr:6.62e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.717, tt:5360.106\n",
      "Ep:169, loss:0.00001, loss_test:0.07736, lr:6.56e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.719, tt:5392.249\n",
      "Ep:170, loss:0.00001, loss_test:0.07749, lr:6.49e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.723, tt:5424.680\n",
      "Ep:171, loss:0.00001, loss_test:0.07763, lr:6.43e-03, fs:0.89005 (r=0.859,p=0.924),  time:31.721, tt:5455.939\n",
      "Ep:172, loss:0.00001, loss_test:0.07696, lr:6.36e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.713, tt:5486.270\n",
      "Ep:173, loss:0.00001, loss_test:0.07752, lr:6.30e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.710, tt:5517.464\n",
      "Ep:174, loss:0.00001, loss_test:0.07753, lr:6.24e-03, fs:0.89583 (r=0.869,p=0.925),  time:31.703, tt:5548.039\n",
      "Ep:175, loss:0.00001, loss_test:0.07680, lr:6.17e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.701, tt:5579.324\n",
      "Ep:176, loss:0.00001, loss_test:0.07907, lr:6.11e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.702, tt:5611.307\n",
      "Ep:177, loss:0.00001, loss_test:0.07773, lr:6.05e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.699, tt:5642.505\n",
      "Ep:178, loss:0.00001, loss_test:0.07797, lr:5.99e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.695, tt:5673.416\n",
      "Ep:179, loss:0.00001, loss_test:0.07853, lr:5.93e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.694, tt:5704.868\n",
      "Ep:180, loss:0.00001, loss_test:0.07708, lr:5.87e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.692, tt:5736.327\n",
      "Ep:181, loss:0.00001, loss_test:0.07849, lr:5.81e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.687, tt:5767.042\n",
      "Ep:182, loss:0.00001, loss_test:0.07920, lr:5.75e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.684, tt:5798.107\n",
      "Ep:183, loss:0.00001, loss_test:0.07768, lr:5.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.688, tt:5830.669\n",
      "Ep:184, loss:0.00001, loss_test:0.07765, lr:5.64e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.680, tt:5860.740\n",
      "Ep:185, loss:0.00001, loss_test:0.07786, lr:5.58e-03, fs:0.89691 (r=0.879,p=0.916),  time:31.676, tt:5891.731\n",
      "Ep:186, loss:0.00001, loss_test:0.07780, lr:5.53e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.678, tt:5923.702\n",
      "Ep:187, loss:0.00001, loss_test:0.07816, lr:5.47e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.664, tt:5952.849\n",
      "Ep:188, loss:0.00001, loss_test:0.07941, lr:5.42e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.660, tt:5983.752\n",
      "Ep:189, loss:0.00001, loss_test:0.07762, lr:5.36e-03, fs:0.90625 (r=0.879,p=0.935),  time:31.658, tt:6015.030\n",
      "Ep:190, loss:0.00001, loss_test:0.07919, lr:5.31e-03, fs:0.88542 (r=0.859,p=0.914),  time:31.654, tt:6045.931\n",
      "Ep:191, loss:0.00001, loss_test:0.07862, lr:5.26e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.655, tt:6077.803\n",
      "Ep:192, loss:0.00001, loss_test:0.07828, lr:5.20e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.651, tt:6108.713\n",
      "Ep:193, loss:0.00001, loss_test:0.07878, lr:5.15e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.644, tt:6138.885\n",
      "Ep:194, loss:0.00001, loss_test:0.07830, lr:5.10e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.645, tt:6170.776\n",
      "Ep:195, loss:0.00001, loss_test:0.07880, lr:5.05e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.634, tt:6200.296\n",
      "Ep:196, loss:0.00001, loss_test:0.07849, lr:5.00e-03, fs:0.89583 (r=0.869,p=0.925),  time:31.622, tt:6229.574\n",
      "Ep:197, loss:0.00001, loss_test:0.07859, lr:4.95e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.603, tt:6257.346\n",
      "Ep:198, loss:0.00001, loss_test:0.07891, lr:4.90e-03, fs:0.86170 (r=0.818,p=0.910),  time:31.588, tt:6286.110\n",
      "Ep:199, loss:0.00001, loss_test:0.07868, lr:4.85e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.575, tt:6315.069\n",
      "Ep:200, loss:0.00001, loss_test:0.07869, lr:4.80e-03, fs:0.91192 (r=0.889,p=0.936),  time:31.545, tt:6340.468\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.01994, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:34.357, tt:34.357\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02346, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.244, tt:74.488\n",
      "Ep:2, loss:0.00005, loss_test:0.02634, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.117, tt:114.351\n",
      "Ep:3, loss:0.00005, loss_test:0.02725, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.794, tt:155.177\n",
      "Ep:4, loss:0.00005, loss_test:0.02707, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.899, tt:194.496\n",
      "Ep:5, loss:0.00005, loss_test:0.02621, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.041, tt:234.248\n",
      "Ep:6, loss:0.00005, loss_test:0.02473, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.670, tt:277.690\n",
      "Ep:7, loss:0.00005, loss_test:0.02281, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:39.649, tt:317.193\n",
      "Ep:8, loss:0.00004, loss_test:0.02090, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:39.905, tt:359.146\n",
      "Ep:9, loss:0.00004, loss_test:0.01959, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:40.134, tt:401.344\n",
      "Ep:10, loss:0.00004, loss_test:0.01929, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:40.237, tt:442.603\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01934, lr:6.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:40.084, tt:481.003\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01894, lr:6.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:40.044, tt:520.577\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01834, lr:6.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:40.199, tt:562.784\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01799, lr:6.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:40.314, tt:604.715\n",
      "Ep:15, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:40.392, tt:646.274\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01749, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:40.412, tt:687.001\n",
      "Ep:17, loss:0.00003, loss_test:0.01724, lr:6.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:40.465, tt:728.364\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:40.450, tt:768.548\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:40.354, tt:807.087\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01665, lr:6.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:40.255, tt:845.349\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:40.261, tt:885.745\n",
      "Ep:22, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:40.334, tt:927.675\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:40.365, tt:968.771\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:40.376, tt:1009.406\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01550, lr:6.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:40.431, tt:1051.206\n",
      "Ep:26, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:40.444, tt:1091.981\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:40.555, tt:1135.531\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:40.631, tt:1178.302\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:40.691, tt:1220.718\n",
      "Ep:30, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:40.708, tt:1261.945\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:40.748, tt:1303.942\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01460, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:40.715, tt:1343.589\n",
      "Ep:33, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:40.713, tt:1384.232\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:40.708, tt:1424.776\n",
      "Ep:35, loss:0.00002, loss_test:0.01437, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:40.721, tt:1465.940\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01427, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:40.675, tt:1504.979\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01419, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:40.702, tt:1546.684\n",
      "Ep:38, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:40.725, tt:1588.270\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:40.819, tt:1632.752\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01414, lr:6.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:40.816, tt:1673.476\n",
      "Ep:41, loss:0.00001, loss_test:0.01410, lr:6.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:40.816, tt:1714.275\n",
      "Ep:42, loss:0.00001, loss_test:0.01410, lr:6.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:40.798, tt:1754.305\n",
      "Ep:43, loss:0.00001, loss_test:0.01409, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:40.804, tt:1795.361\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:40.779, tt:1835.063\n",
      "Ep:45, loss:0.00001, loss_test:0.01407, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.750, tt:1874.506\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01400, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.766, tt:1915.989\n",
      "Ep:47, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.781, tt:1957.501\n",
      "Ep:48, loss:0.00001, loss_test:0.01403, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:40.790, tt:1998.721\n",
      "Ep:49, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:40.764, tt:2038.188\n",
      "Ep:50, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:40.774, tt:2079.491\n",
      "Ep:51, loss:0.00001, loss_test:0.01412, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.767, tt:2119.879\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01416, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.877, tt:2166.456\n",
      "Ep:53, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.907, tt:2208.971\n",
      "Ep:54, loss:0.00001, loss_test:0.01422, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.944, tt:2251.922\n",
      "Ep:55, loss:0.00001, loss_test:0.01423, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.962, tt:2293.849\n",
      "Ep:56, loss:0.00001, loss_test:0.01431, lr:6.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.949, tt:2334.083\n",
      "Ep:57, loss:0.00001, loss_test:0.01434, lr:6.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:40.972, tt:2376.370\n",
      "Ep:58, loss:0.00001, loss_test:0.01437, lr:6.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:40.964, tt:2416.897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01441, lr:6.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:40.954, tt:2457.218\n",
      "Ep:60, loss:0.00001, loss_test:0.01442, lr:6.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:40.947, tt:2497.758\n",
      "Ep:61, loss:0.00001, loss_test:0.01450, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:40.941, tt:2538.338\n",
      "Ep:62, loss:0.00001, loss_test:0.01459, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.927, tt:2578.372\n",
      "Ep:63, loss:0.00001, loss_test:0.01462, lr:5.94e-02, fs:0.84375 (r=0.818,p=0.871),  time:40.955, tt:2621.142\n",
      "Ep:64, loss:0.00001, loss_test:0.01466, lr:5.88e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.918, tt:2659.697\n",
      "Ep:65, loss:0.00001, loss_test:0.01465, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.921, tt:2700.764\n",
      "Ep:66, loss:0.00001, loss_test:0.01473, lr:5.76e-02, fs:0.84211 (r=0.808,p=0.879),  time:40.905, tt:2740.635\n",
      "Ep:67, loss:0.00001, loss_test:0.01481, lr:5.71e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.876, tt:2779.534\n",
      "Ep:68, loss:0.00001, loss_test:0.01490, lr:5.65e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.931, tt:2824.205\n",
      "Ep:69, loss:0.00001, loss_test:0.01499, lr:5.59e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.929, tt:2865.020\n",
      "Ep:70, loss:0.00001, loss_test:0.01500, lr:5.54e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.932, tt:2906.191\n",
      "Ep:71, loss:0.00001, loss_test:0.01502, lr:5.48e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.915, tt:2945.902\n",
      "Ep:72, loss:0.00001, loss_test:0.01505, lr:5.43e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.902, tt:2985.845\n",
      "Ep:73, loss:0.00001, loss_test:0.01512, lr:5.37e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.897, tt:3026.398\n",
      "Ep:74, loss:0.00001, loss_test:0.01525, lr:5.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.874, tt:3065.579\n",
      "Ep:75, loss:0.00001, loss_test:0.01533, lr:5.27e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.854, tt:3104.877\n",
      "Ep:76, loss:0.00001, loss_test:0.01538, lr:5.21e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.849, tt:3145.376\n",
      "Ep:77, loss:0.00001, loss_test:0.01545, lr:5.16e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.858, tt:3186.899\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01553, lr:5.16e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.846, tt:3226.817\n",
      "Ep:79, loss:0.00001, loss_test:0.01557, lr:5.16e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.821, tt:3265.684\n",
      "Ep:80, loss:0.00001, loss_test:0.01564, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:40.841, tt:3308.151\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01568, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:40.868, tt:3351.203\n",
      "Ep:82, loss:0.00001, loss_test:0.01578, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:40.868, tt:3392.034\n",
      "Ep:83, loss:0.00001, loss_test:0.01584, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:40.882, tt:3434.063\n",
      "Ep:84, loss:0.00001, loss_test:0.01590, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:40.876, tt:3474.501\n",
      "Ep:85, loss:0.00001, loss_test:0.01595, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:40.866, tt:3514.512\n",
      "Ep:86, loss:0.00001, loss_test:0.01603, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.861, tt:3554.947\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01606, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.840, tt:3593.955\n",
      "Ep:88, loss:0.00001, loss_test:0.01614, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.864, tt:3636.932\n",
      "Ep:89, loss:0.00001, loss_test:0.01625, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.873, tt:3678.559\n",
      "Ep:90, loss:0.00000, loss_test:0.01635, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.859, tt:3718.126\n",
      "Ep:91, loss:0.00000, loss_test:0.01639, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.845, tt:3757.731\n",
      "Ep:92, loss:0.00000, loss_test:0.01644, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.834, tt:3797.594\n",
      "Ep:93, loss:0.00000, loss_test:0.01653, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.893, tt:3843.954\n",
      "Ep:94, loss:0.00000, loss_test:0.01662, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.892, tt:3884.746\n",
      "Ep:95, loss:0.00000, loss_test:0.01669, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.882, tt:3924.629\n",
      "Ep:96, loss:0.00000, loss_test:0.01677, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.885, tt:3965.820\n",
      "Ep:97, loss:0.00000, loss_test:0.01681, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.876, tt:4005.820\n",
      "Ep:98, loss:0.00000, loss_test:0.01693, lr:5.11e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.895, tt:4048.590\n",
      "Ep:99, loss:0.00000, loss_test:0.01701, lr:5.06e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.903, tt:4090.321\n",
      "Ep:100, loss:0.00000, loss_test:0.01706, lr:5.01e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.874, tt:4128.245\n",
      "Ep:101, loss:0.00000, loss_test:0.01715, lr:4.96e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.872, tt:4168.972\n",
      "Ep:102, loss:0.00000, loss_test:0.01723, lr:4.91e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.876, tt:4210.192\n",
      "Ep:103, loss:0.00000, loss_test:0.01730, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.868, tt:4250.318\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00000, loss_test:0.01739, lr:4.86e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.875, tt:4291.900\n",
      "Ep:105, loss:0.00000, loss_test:0.01745, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.873, tt:4332.519\n",
      "Ep:106, loss:0.00000, loss_test:0.01751, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.856, tt:4371.543\n",
      "Ep:107, loss:0.00000, loss_test:0.01759, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.849, tt:4411.702\n",
      "Ep:108, loss:0.00000, loss_test:0.01768, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.852, tt:4452.846\n",
      "Ep:109, loss:0.00000, loss_test:0.01776, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.824, tt:4490.610\n",
      "Ep:110, loss:0.00000, loss_test:0.01783, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.871, tt:4536.638\n",
      "Ep:111, loss:0.00000, loss_test:0.01794, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.869, tt:4577.276\n",
      "Ep:112, loss:0.00000, loss_test:0.01796, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.859, tt:4617.075\n",
      "Ep:113, loss:0.00000, loss_test:0.01802, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.869, tt:4659.023\n",
      "Ep:114, loss:0.00000, loss_test:0.01814, lr:4.86e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.876, tt:4700.728\n",
      "Ep:115, loss:0.00000, loss_test:0.01819, lr:4.81e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.879, tt:4741.999\n",
      "Ep:116, loss:0.00000, loss_test:0.01823, lr:4.76e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.890, tt:4784.168\n",
      "Ep:117, loss:0.00000, loss_test:0.01832, lr:4.71e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.914, tt:4827.796\n",
      "Ep:118, loss:0.00000, loss_test:0.01844, lr:4.67e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.926, tt:4870.248\n",
      "Ep:119, loss:0.00000, loss_test:0.01848, lr:4.62e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.937, tt:4912.380\n",
      "Ep:120, loss:0.00000, loss_test:0.01853, lr:4.57e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.944, tt:4954.266\n",
      "Ep:121, loss:0.00000, loss_test:0.01858, lr:4.53e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.949, tt:4995.746\n",
      "Ep:122, loss:0.00000, loss_test:0.01866, lr:4.48e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.951, tt:5036.993\n",
      "Ep:123, loss:0.00000, loss_test:0.01872, lr:4.44e-02, fs:0.87568 (r=0.818,p=0.942),  time:40.939, tt:5076.439\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00000, loss_test:0.01876, lr:4.44e-02, fs:0.87568 (r=0.818,p=0.942),  time:40.933, tt:5116.579\n",
      "Ep:125, loss:0.00000, loss_test:0.01883, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.929, tt:5157.087\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.01889, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.948, tt:5200.364\n",
      "Ep:127, loss:0.00000, loss_test:0.01899, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.915, tt:5237.099\n",
      "Ep:128, loss:0.00000, loss_test:0.01908, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.909, tt:5277.254\n",
      "Ep:129, loss:0.00000, loss_test:0.01912, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.907, tt:5317.855\n",
      "Ep:130, loss:0.00000, loss_test:0.01917, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.890, tt:5356.548\n",
      "Ep:131, loss:0.00000, loss_test:0.01924, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.880, tt:5396.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01928, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.887, tt:5437.993\n",
      "Ep:133, loss:0.00000, loss_test:0.01934, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.881, tt:5478.019\n",
      "Ep:134, loss:0.00000, loss_test:0.01936, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.865, tt:5516.830\n",
      "Ep:135, loss:0.00000, loss_test:0.01941, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.865, tt:5557.645\n",
      "Ep:136, loss:0.00000, loss_test:0.01949, lr:4.44e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.853, tt:5596.919\n",
      "Ep:137, loss:0.00000, loss_test:0.01956, lr:4.39e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.843, tt:5636.375\n",
      "Ep:138, loss:0.00000, loss_test:0.01959, lr:4.35e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.851, tt:5678.337\n",
      "Ep:139, loss:0.00000, loss_test:0.01966, lr:4.31e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.851, tt:5719.119\n",
      "Ep:140, loss:0.00000, loss_test:0.01974, lr:4.26e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.846, tt:5759.226\n",
      "Ep:141, loss:0.00000, loss_test:0.01982, lr:4.22e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.821, tt:5796.545\n",
      "Ep:142, loss:0.00000, loss_test:0.01984, lr:4.18e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.823, tt:5837.756\n",
      "Ep:143, loss:0.00000, loss_test:0.01987, lr:4.14e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.826, tt:5878.935\n",
      "Ep:144, loss:0.00000, loss_test:0.01996, lr:4.10e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.812, tt:5917.755\n",
      "Ep:145, loss:0.00000, loss_test:0.02004, lr:4.05e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.796, tt:5956.239\n",
      "Ep:146, loss:0.00000, loss_test:0.02009, lr:4.01e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.777, tt:5994.171\n",
      "Ep:147, loss:0.00000, loss_test:0.02014, lr:3.97e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.776, tt:6034.905\n",
      "Ep:148, loss:0.00000, loss_test:0.02020, lr:3.93e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.773, tt:6075.141\n",
      "Ep:149, loss:0.00000, loss_test:0.02026, lr:3.89e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.761, tt:6114.084\n",
      "Ep:150, loss:0.00000, loss_test:0.02031, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.757, tt:6154.255\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00000, loss_test:0.02033, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.752, tt:6194.304\n",
      "Ep:152, loss:0.00000, loss_test:0.02039, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.734, tt:6232.245\n",
      "Ep:153, loss:0.00000, loss_test:0.02043, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.722, tt:6271.132\n",
      "Ep:154, loss:0.00000, loss_test:0.02048, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.711, tt:6310.239\n",
      "Ep:155, loss:0.00000, loss_test:0.02051, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.696, tt:6348.563\n",
      "Ep:156, loss:0.00000, loss_test:0.02055, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.692, tt:6388.708\n",
      "Ep:157, loss:0.00000, loss_test:0.02060, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.680, tt:6427.507\n",
      "Ep:158, loss:0.00000, loss_test:0.02066, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.669, tt:6466.417\n",
      "Ep:159, loss:0.00000, loss_test:0.02070, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.660, tt:6505.643\n",
      "Ep:160, loss:0.00000, loss_test:0.02072, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.657, tt:6545.836\n",
      "Ep:161, loss:0.00000, loss_test:0.02077, lr:3.86e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.648, tt:6584.998\n",
      "Ep:162, loss:0.00000, loss_test:0.02084, lr:3.82e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.635, tt:6623.543\n",
      "Ep:163, loss:0.00000, loss_test:0.02088, lr:3.78e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.627, tt:6662.796\n",
      "Ep:164, loss:0.00000, loss_test:0.02092, lr:3.74e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.622, tt:6702.635\n",
      "Ep:165, loss:0.00000, loss_test:0.02095, lr:3.70e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.626, tt:6743.849\n",
      "Ep:166, loss:0.00000, loss_test:0.02098, lr:3.67e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.620, tt:6783.483\n",
      "Ep:167, loss:0.00000, loss_test:0.02105, lr:3.63e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.625, tt:6824.990\n",
      "Ep:168, loss:0.00000, loss_test:0.02110, lr:3.59e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.609, tt:6862.853\n",
      "Ep:169, loss:0.00000, loss_test:0.02115, lr:3.56e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.609, tt:6903.604\n",
      "Ep:170, loss:0.00000, loss_test:0.02118, lr:3.52e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.600, tt:6942.675\n",
      "Ep:171, loss:0.00000, loss_test:0.02122, lr:3.49e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.601, tt:6983.423\n",
      "Ep:172, loss:0.00000, loss_test:0.02125, lr:3.45e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.595, tt:7022.874\n",
      "Ep:173, loss:0.00000, loss_test:0.02129, lr:3.42e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.595, tt:7063.461\n",
      "Ep:174, loss:0.00000, loss_test:0.02132, lr:3.38e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.593, tt:7103.785\n",
      "Ep:175, loss:0.00000, loss_test:0.02135, lr:3.35e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.594, tt:7144.507\n",
      "Ep:176, loss:0.00000, loss_test:0.02140, lr:3.32e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.593, tt:7184.937\n",
      "Ep:177, loss:0.00000, loss_test:0.02143, lr:3.28e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.590, tt:7225.059\n",
      "Ep:178, loss:0.00000, loss_test:0.02148, lr:3.25e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.590, tt:7265.558\n",
      "Ep:179, loss:0.00000, loss_test:0.02152, lr:3.22e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.591, tt:7306.334\n",
      "Ep:180, loss:0.00000, loss_test:0.02154, lr:3.19e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.586, tt:7346.010\n",
      "Ep:181, loss:0.00000, loss_test:0.02159, lr:3.15e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.571, tt:7383.945\n",
      "Ep:182, loss:0.00000, loss_test:0.02163, lr:3.12e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.563, tt:7423.053\n",
      "Ep:183, loss:0.00000, loss_test:0.02166, lr:3.09e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.563, tt:7463.568\n",
      "Ep:184, loss:0.00000, loss_test:0.02169, lr:3.06e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.566, tt:7504.770\n",
      "Ep:185, loss:0.00000, loss_test:0.02173, lr:3.03e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.568, tt:7545.614\n",
      "Ep:186, loss:0.00000, loss_test:0.02176, lr:3.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.571, tt:7586.739\n",
      "Ep:187, loss:0.00000, loss_test:0.02177, lr:2.97e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.564, tt:7626.049\n",
      "Ep:188, loss:0.00000, loss_test:0.02181, lr:2.94e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.551, tt:7664.175\n",
      "Ep:189, loss:0.00000, loss_test:0.02184, lr:2.91e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.564, tt:7707.192\n",
      "Ep:190, loss:0.00000, loss_test:0.02187, lr:2.88e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.548, tt:7744.726\n",
      "Ep:191, loss:0.00000, loss_test:0.02190, lr:2.85e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.551, tt:7785.761\n",
      "Ep:192, loss:0.00000, loss_test:0.02194, lr:2.82e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.549, tt:7825.932\n",
      "Ep:193, loss:0.00000, loss_test:0.02197, lr:2.80e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.548, tt:7866.407\n",
      "Ep:194, loss:0.00000, loss_test:0.02200, lr:2.77e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.553, tt:7907.933\n",
      "Ep:195, loss:0.00000, loss_test:0.02202, lr:2.74e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.558, tt:7949.408\n",
      "Ep:196, loss:0.00000, loss_test:0.02206, lr:2.71e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.552, tt:7988.668\n",
      "Ep:197, loss:0.00000, loss_test:0.02208, lr:2.69e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.584, tt:8035.619\n",
      "Ep:198, loss:0.00000, loss_test:0.02210, lr:2.66e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.578, tt:8075.006\n",
      "Ep:199, loss:0.00000, loss_test:0.02213, lr:2.63e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.562, tt:8112.312\n",
      "Ep:200, loss:0.00000, loss_test:0.02217, lr:2.61e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.535, tt:8147.471\n",
      "Ep:201, loss:0.00000, loss_test:0.02219, lr:2.58e-02, fs:0.88525 (r=0.818,p=0.964),  time:40.488, tt:8178.587\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00028, loss_test:0.14058, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.299, tt:41.299\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13930, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:41.132, tt:82.265\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13704, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:40.922, tt:122.765\n",
      "Ep:3, loss:0.00027, loss_test:0.13356, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:40.865, tt:163.461\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12815, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:41.263, tt:206.316\n",
      "Ep:5, loss:0.00025, loss_test:0.12136, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:41.335, tt:248.011\n",
      "Ep:6, loss:0.00024, loss_test:0.11702, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:41.172, tt:288.207\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11469, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:41.178, tt:329.426\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11120, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:41.199, tt:370.791\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10855, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:41.111, tt:411.113\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10606, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:41.208, tt:453.286\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10488, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:41.116, tt:493.390\n",
      "Ep:12, loss:0.00018, loss_test:0.10369, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:41.128, tt:534.660\n",
      "Ep:13, loss:0.00017, loss_test:0.10169, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:41.076, tt:575.067\n",
      "Ep:14, loss:0.00017, loss_test:0.10046, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:41.201, tt:618.008\n",
      "Ep:15, loss:0.00016, loss_test:0.09960, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:41.615, tt:665.843\n",
      "Ep:16, loss:0.00015, loss_test:0.09825, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:41.621, tt:707.556\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09587, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:41.610, tt:748.973\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.09476, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:41.589, tt:790.195\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.09290, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:41.507, tt:830.138\n",
      "Ep:20, loss:0.00012, loss_test:0.09078, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:41.434, tt:870.106\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.08996, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:41.441, tt:911.707\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00011, loss_test:0.08778, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:41.393, tt:952.043\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.08648, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:41.354, tt:992.502\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08617, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:41.309, tt:1032.736\n",
      "Ep:25, loss:0.00009, loss_test:0.08411, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:41.290, tt:1073.549\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.08373, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.358, tt:1116.664\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00008, loss_test:0.08269, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.368, tt:1158.318\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.08137, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:41.339, tt:1198.831\n",
      "Ep:29, loss:0.00007, loss_test:0.08265, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:41.380, tt:1241.402\n",
      "Ep:30, loss:0.00007, loss_test:0.08019, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.368, tt:1282.414\n",
      "Ep:31, loss:0.00007, loss_test:0.08072, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:41.486, tt:1327.549\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.07998, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:41.498, tt:1369.431\n",
      "Ep:33, loss:0.00006, loss_test:0.07873, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:41.525, tt:1411.843\n",
      "Ep:34, loss:0.00006, loss_test:0.07919, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:41.536, tt:1453.757\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.07839, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:41.548, tt:1495.712\n",
      "Ep:36, loss:0.00005, loss_test:0.07850, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:41.490, tt:1535.114\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.07712, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:41.453, tt:1575.203\n",
      "Ep:38, loss:0.00005, loss_test:0.07791, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:41.418, tt:1615.289\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07734, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.431, tt:1657.244\n",
      "Ep:40, loss:0.00004, loss_test:0.07694, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:41.509, tt:1701.867\n",
      "Ep:41, loss:0.00004, loss_test:0.07608, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:41.512, tt:1743.503\n",
      "Ep:42, loss:0.00004, loss_test:0.07628, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.505, tt:1784.732\n",
      "Ep:43, loss:0.00004, loss_test:0.07588, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:41.504, tt:1826.160\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.07565, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:41.491, tt:1867.116\n",
      "Ep:45, loss:0.00004, loss_test:0.07687, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:41.515, tt:1909.676\n",
      "Ep:46, loss:0.00004, loss_test:0.07513, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:41.497, tt:1950.372\n",
      "Ep:47, loss:0.00003, loss_test:0.07644, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:41.540, tt:1993.927\n",
      "Ep:48, loss:0.00003, loss_test:0.07470, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:41.564, tt:2036.643\n",
      "Ep:49, loss:0.00003, loss_test:0.07680, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:41.578, tt:2078.889\n",
      "Ep:50, loss:0.00003, loss_test:0.07566, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:41.598, tt:2121.500\n",
      "Ep:51, loss:0.00003, loss_test:0.07460, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:41.609, tt:2163.688\n",
      "Ep:52, loss:0.00003, loss_test:0.07721, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:41.650, tt:2207.452\n",
      "Ep:53, loss:0.00003, loss_test:0.07355, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:41.661, tt:2249.684\n",
      "Ep:54, loss:0.00003, loss_test:0.07760, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:41.674, tt:2292.084\n",
      "Ep:55, loss:0.00003, loss_test:0.07454, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.680, tt:2334.091\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.07661, lr:9.90e-03, fs:0.86631 (r=0.818,p=0.920),  time:41.673, tt:2375.384\n",
      "Ep:57, loss:0.00002, loss_test:0.07724, lr:9.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.681, tt:2417.490\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.07269, lr:9.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.698, tt:2460.185\n",
      "Ep:59, loss:0.00002, loss_test:0.07632, lr:9.90e-03, fs:0.85263 (r=0.818,p=0.890),  time:41.719, tt:2503.164\n",
      "Ep:60, loss:0.00002, loss_test:0.07387, lr:9.90e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.684, tt:2542.727\n",
      "Ep:61, loss:0.00002, loss_test:0.07548, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.678, tt:2584.054\n",
      "Ep:62, loss:0.00002, loss_test:0.07864, lr:9.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:41.684, tt:2626.087\n",
      "Ep:63, loss:0.00002, loss_test:0.07303, lr:9.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:41.688, tt:2668.002\n",
      "Ep:64, loss:0.00002, loss_test:0.07547, lr:9.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.691, tt:2709.933\n",
      "Ep:65, loss:0.00002, loss_test:0.07806, lr:9.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.683, tt:2751.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.07514, lr:9.90e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.678, tt:2792.440\n",
      "Ep:67, loss:0.00002, loss_test:0.07439, lr:9.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.686, tt:2834.641\n",
      "Ep:68, loss:0.00002, loss_test:0.07630, lr:9.90e-03, fs:0.87568 (r=0.818,p=0.942),  time:41.684, tt:2876.202\n",
      "Ep:69, loss:0.00002, loss_test:0.07482, lr:9.80e-03, fs:0.87568 (r=0.818,p=0.942),  time:41.650, tt:2915.490\n",
      "Ep:70, loss:0.00002, loss_test:0.07430, lr:9.70e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.649, tt:2957.044\n",
      "Ep:71, loss:0.00002, loss_test:0.07645, lr:9.61e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.641, tt:2998.175\n",
      "Ep:72, loss:0.00002, loss_test:0.07518, lr:9.51e-03, fs:0.87568 (r=0.818,p=0.942),  time:41.630, tt:3038.971\n",
      "Ep:73, loss:0.00002, loss_test:0.07395, lr:9.41e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.622, tt:3080.022\n",
      "Ep:74, loss:0.00001, loss_test:0.07659, lr:9.32e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.639, tt:3122.956\n",
      "Ep:75, loss:0.00001, loss_test:0.07487, lr:9.23e-03, fs:0.87568 (r=0.818,p=0.942),  time:41.650, tt:3165.396\n",
      "Ep:76, loss:0.00001, loss_test:0.07399, lr:9.14e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.671, tt:3208.639\n",
      "Ep:77, loss:0.00001, loss_test:0.07557, lr:9.04e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.666, tt:3249.914\n",
      "Ep:78, loss:0.00001, loss_test:0.07577, lr:8.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.663, tt:3291.400\n",
      "Ep:79, loss:0.00001, loss_test:0.07507, lr:8.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.654, tt:3332.339\n",
      "Ep:80, loss:0.00001, loss_test:0.07474, lr:8.78e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.654, tt:3373.979\n",
      "Ep:81, loss:0.00001, loss_test:0.07559, lr:8.69e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.630, tt:3413.679\n",
      "Ep:82, loss:0.00001, loss_test:0.07539, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.668, tt:3458.473\n",
      "Ep:83, loss:0.00001, loss_test:0.07524, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.784, tt:3509.820\n",
      "Ep:84, loss:0.00001, loss_test:0.07535, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.807, tt:3553.614\n",
      "Ep:85, loss:0.00001, loss_test:0.07506, lr:8.35e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.801, tt:3594.907\n",
      "Ep:86, loss:0.00001, loss_test:0.07552, lr:8.26e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.793, tt:3635.954\n",
      "Ep:87, loss:0.00001, loss_test:0.07507, lr:8.18e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.787, tt:3677.229\n",
      "Ep:88, loss:0.00001, loss_test:0.07539, lr:8.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.813, tt:3721.318\n",
      "Ep:89, loss:0.00001, loss_test:0.07556, lr:8.02e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.823, tt:3764.045\n",
      "Ep:90, loss:0.00001, loss_test:0.07619, lr:7.94e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.841, tt:3807.504\n",
      "Ep:91, loss:0.00001, loss_test:0.07589, lr:7.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.867, tt:3851.719\n",
      "Ep:92, loss:0.00001, loss_test:0.07541, lr:7.78e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.883, tt:3895.073\n",
      "Ep:93, loss:0.00001, loss_test:0.07584, lr:7.70e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.894, tt:3938.041\n",
      "Ep:94, loss:0.00001, loss_test:0.07537, lr:7.62e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.886, tt:3979.215\n",
      "Ep:95, loss:0.00001, loss_test:0.07590, lr:7.55e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.893, tt:4021.747\n",
      "Ep:96, loss:0.00001, loss_test:0.07682, lr:7.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.918, tt:4066.082\n",
      "Ep:97, loss:0.00001, loss_test:0.07597, lr:7.40e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.928, tt:4108.901\n",
      "Ep:98, loss:0.00001, loss_test:0.07581, lr:7.32e-03, fs:0.88043 (r=0.818,p=0.953),  time:41.923, tt:4150.360\n",
      "Ep:99, loss:0.00001, loss_test:0.07608, lr:7.25e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.938, tt:4193.794\n",
      "Ep:100, loss:0.00001, loss_test:0.07625, lr:7.18e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.971, tt:4239.097\n",
      "Ep:101, loss:0.00001, loss_test:0.07673, lr:7.11e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.986, tt:4282.616\n",
      "Ep:102, loss:0.00001, loss_test:0.07623, lr:7.03e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.984, tt:4324.390\n",
      "Ep:103, loss:0.00001, loss_test:0.07625, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.996, tt:4367.578\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.07655, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.985, tt:4408.451\n",
      "Ep:105, loss:0.00001, loss_test:0.07667, lr:6.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.971, tt:4448.903\n",
      "Ep:106, loss:0.00001, loss_test:0.07609, lr:6.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:41.991, tt:4493.018\n",
      "Ep:107, loss:0.00001, loss_test:0.07701, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.013, tt:4537.402\n",
      "Ep:108, loss:0.00001, loss_test:0.07690, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.024, tt:4580.663\n",
      "Ep:109, loss:0.00001, loss_test:0.07637, lr:6.96e-03, fs:0.89011 (r=0.818,p=0.976),  time:42.021, tt:4622.278\n",
      "Ep:110, loss:0.00001, loss_test:0.07700, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.005, tt:4662.576\n",
      "Ep:111, loss:0.00001, loss_test:0.07700, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.016, tt:4705.743\n",
      "Ep:112, loss:0.00001, loss_test:0.07709, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.017, tt:4747.882\n",
      "Ep:113, loss:0.00001, loss_test:0.07785, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.008, tt:4788.942\n",
      "Ep:114, loss:0.00001, loss_test:0.07748, lr:6.96e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.017, tt:4831.999\n",
      "Ep:115, loss:0.00001, loss_test:0.07730, lr:6.89e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.995, tt:4871.450\n",
      "Ep:116, loss:0.00001, loss_test:0.07746, lr:6.83e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.015, tt:4915.769\n",
      "Ep:117, loss:0.00001, loss_test:0.07746, lr:6.76e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.037, tt:4960.336\n",
      "Ep:118, loss:0.00001, loss_test:0.07773, lr:6.69e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.043, tt:5003.084\n",
      "Ep:119, loss:0.00001, loss_test:0.07759, lr:6.62e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.055, tt:5046.559\n",
      "Ep:120, loss:0.00001, loss_test:0.07804, lr:6.56e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.052, tt:5088.337\n",
      "Ep:121, loss:0.00001, loss_test:0.07789, lr:6.49e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.058, tt:5131.088\n",
      "Ep:122, loss:0.00001, loss_test:0.07807, lr:6.43e-03, fs:0.90000 (r=0.818,p=1.000),  time:42.074, tt:5175.138\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.07831, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.064, tt:5215.907\n",
      "Ep:124, loss:0.00001, loss_test:0.07861, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.059, tt:5257.374\n",
      "Ep:125, loss:0.00001, loss_test:0.07831, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.057, tt:5299.170\n",
      "Ep:126, loss:0.00001, loss_test:0.07884, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.056, tt:5341.111\n",
      "Ep:127, loss:0.00000, loss_test:0.07930, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.066, tt:5384.407\n",
      "Ep:128, loss:0.00000, loss_test:0.07891, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.037, tt:5422.821\n",
      "Ep:129, loss:0.00000, loss_test:0.07853, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.000, tt:5460.012\n",
      "Ep:130, loss:0.00000, loss_test:0.07904, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.988, tt:5500.428\n",
      "Ep:131, loss:0.00000, loss_test:0.07915, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.972, tt:5540.323\n",
      "Ep:132, loss:0.00000, loss_test:0.07952, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.964, tt:5581.157\n",
      "Ep:133, loss:0.00000, loss_test:0.07988, lr:6.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.964, tt:5623.128\n",
      "Ep:134, loss:0.00000, loss_test:0.07975, lr:6.36e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.953, tt:5663.687\n",
      "Ep:135, loss:0.00000, loss_test:0.07991, lr:6.30e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.946, tt:5704.711\n",
      "Ep:136, loss:0.00000, loss_test:0.08031, lr:6.24e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.940, tt:5745.830\n",
      "Ep:137, loss:0.00000, loss_test:0.08024, lr:6.17e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.922, tt:5785.198\n",
      "Ep:138, loss:0.00000, loss_test:0.07993, lr:6.11e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.956, tt:5831.889\n",
      "Ep:139, loss:0.00000, loss_test:0.08044, lr:6.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.956, tt:5873.827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.08127, lr:5.99e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.947, tt:5914.542\n",
      "Ep:141, loss:0.00000, loss_test:0.08134, lr:5.93e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.952, tt:5957.117\n",
      "Ep:142, loss:0.00000, loss_test:0.08100, lr:5.87e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.948, tt:5998.624\n",
      "Ep:143, loss:0.00000, loss_test:0.08094, lr:5.81e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.953, tt:6041.187\n",
      "Ep:144, loss:0.00000, loss_test:0.08199, lr:5.75e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.951, tt:6082.938\n",
      "Ep:145, loss:0.00000, loss_test:0.08222, lr:5.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.971, tt:6127.792\n",
      "Ep:146, loss:0.00000, loss_test:0.08172, lr:5.64e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.980, tt:6171.016\n",
      "Ep:147, loss:0.00000, loss_test:0.08161, lr:5.58e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.969, tt:6211.451\n",
      "Ep:148, loss:0.00000, loss_test:0.08220, lr:5.53e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.972, tt:6253.819\n",
      "Ep:149, loss:0.00000, loss_test:0.08272, lr:5.47e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.972, tt:6295.766\n",
      "Ep:150, loss:0.00000, loss_test:0.08238, lr:5.42e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.968, tt:6337.212\n",
      "Ep:151, loss:0.00000, loss_test:0.08231, lr:5.36e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.979, tt:6380.799\n",
      "Ep:152, loss:0.00000, loss_test:0.08269, lr:5.31e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.987, tt:6423.950\n",
      "Ep:153, loss:0.00000, loss_test:0.08250, lr:5.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.979, tt:6464.805\n",
      "Ep:154, loss:0.00000, loss_test:0.08258, lr:5.20e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.982, tt:6507.239\n",
      "Ep:155, loss:0.00000, loss_test:0.08214, lr:5.15e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.989, tt:6550.238\n",
      "Ep:156, loss:0.00000, loss_test:0.08252, lr:5.10e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.000, tt:6594.017\n",
      "Ep:157, loss:0.00000, loss_test:0.08355, lr:5.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.992, tt:6634.753\n",
      "Ep:158, loss:0.00000, loss_test:0.08312, lr:5.00e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.001, tt:6678.197\n",
      "Ep:159, loss:0.00000, loss_test:0.08193, lr:4.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.017, tt:6722.792\n",
      "Ep:160, loss:0.00000, loss_test:0.08275, lr:4.90e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.010, tt:6763.617\n",
      "Ep:161, loss:0.00000, loss_test:0.08330, lr:4.85e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.006, tt:6804.969\n",
      "Ep:162, loss:0.00000, loss_test:0.08299, lr:4.80e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.015, tt:6848.424\n",
      "Ep:163, loss:0.00000, loss_test:0.08244, lr:4.75e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.015, tt:6890.458\n",
      "Ep:164, loss:0.00000, loss_test:0.08247, lr:4.71e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.011, tt:6931.796\n",
      "Ep:165, loss:0.00000, loss_test:0.08261, lr:4.66e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.013, tt:6974.178\n",
      "Ep:166, loss:0.00000, loss_test:0.08253, lr:4.61e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.014, tt:7016.286\n",
      "Ep:167, loss:0.00000, loss_test:0.08226, lr:4.57e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.013, tt:7058.137\n",
      "Ep:168, loss:0.00000, loss_test:0.08304, lr:4.52e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.995, tt:7097.099\n",
      "Ep:169, loss:0.00000, loss_test:0.08348, lr:4.48e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.979, tt:7136.417\n",
      "Ep:170, loss:0.00000, loss_test:0.08288, lr:4.43e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.986, tt:7179.667\n",
      "Ep:171, loss:0.00000, loss_test:0.08273, lr:4.39e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.976, tt:7219.863\n",
      "Ep:172, loss:0.00000, loss_test:0.08317, lr:4.34e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.959, tt:7258.879\n",
      "Ep:173, loss:0.00000, loss_test:0.08305, lr:4.30e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.954, tt:7299.978\n",
      "Ep:174, loss:0.00000, loss_test:0.08256, lr:4.26e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.956, tt:7342.252\n",
      "Ep:175, loss:0.00000, loss_test:0.08243, lr:4.21e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.952, tt:7383.611\n",
      "Ep:176, loss:0.00000, loss_test:0.08287, lr:4.17e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.949, tt:7424.938\n",
      "Ep:177, loss:0.00000, loss_test:0.08286, lr:4.13e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.940, tt:7465.262\n",
      "Ep:178, loss:0.00000, loss_test:0.08282, lr:4.09e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.966, tt:7511.872\n",
      "Ep:179, loss:0.00000, loss_test:0.08262, lr:4.05e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.970, tt:7554.687\n",
      "Ep:180, loss:0.00000, loss_test:0.08305, lr:4.01e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.974, tt:7597.239\n",
      "Ep:181, loss:0.00000, loss_test:0.08298, lr:3.97e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.970, tt:7638.593\n",
      "Ep:182, loss:0.00000, loss_test:0.08288, lr:3.93e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.978, tt:7681.888\n",
      "Ep:183, loss:0.00000, loss_test:0.08273, lr:3.89e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.982, tt:7724.757\n",
      "Ep:184, loss:0.00000, loss_test:0.08254, lr:3.85e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.987, tt:7767.655\n",
      "Ep:185, loss:0.00000, loss_test:0.08280, lr:3.81e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.981, tt:7808.515\n",
      "Ep:186, loss:0.00000, loss_test:0.08303, lr:3.77e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.979, tt:7850.009\n",
      "Ep:187, loss:0.00000, loss_test:0.08273, lr:3.73e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.988, tt:7893.708\n",
      "Ep:188, loss:0.00000, loss_test:0.08262, lr:3.70e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.993, tt:7936.763\n",
      "Ep:189, loss:0.00000, loss_test:0.08282, lr:3.66e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.992, tt:7978.419\n",
      "Ep:190, loss:0.00000, loss_test:0.08274, lr:3.62e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.998, tt:8021.589\n",
      "Ep:191, loss:0.00000, loss_test:0.08307, lr:3.59e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.000, tt:8063.925\n",
      "Ep:192, loss:0.00000, loss_test:0.08326, lr:3.55e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.001, tt:8106.212\n",
      "Ep:193, loss:0.00000, loss_test:0.08302, lr:3.52e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.000, tt:8147.975\n",
      "Ep:194, loss:0.00000, loss_test:0.08276, lr:3.48e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.010, tt:8192.046\n",
      "Ep:195, loss:0.00000, loss_test:0.08289, lr:3.45e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.009, tt:8233.800\n",
      "Ep:196, loss:0.00000, loss_test:0.08293, lr:3.41e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.020, tt:8277.907\n",
      "Ep:197, loss:0.00000, loss_test:0.08276, lr:3.38e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.012, tt:8318.462\n",
      "Ep:198, loss:0.00000, loss_test:0.08290, lr:3.34e-03, fs:0.89503 (r=0.818,p=0.988),  time:42.000, tt:8357.928\n",
      "Ep:199, loss:0.00000, loss_test:0.08314, lr:3.31e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.965, tt:8392.966\n",
      "Ep:200, loss:0.00000, loss_test:0.08284, lr:3.28e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.914, tt:8424.649\n",
      "Ep:201, loss:0.00000, loss_test:0.08269, lr:3.24e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.839, tt:8451.452\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01991, lr:6.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:33.545, tt:33.545\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02338, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.076, tt:68.151\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02537, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.583, tt:103.749\n",
      "Ep:3, loss:0.00005, loss_test:0.02547, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.570, tt:138.280\n",
      "Ep:4, loss:0.00005, loss_test:0.02453, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.613, tt:173.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00005, loss_test:0.02277, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.466, tt:206.794\n",
      "Ep:6, loss:0.00004, loss_test:0.02094, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:34.647, tt:242.529\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02032, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:34.646, tt:277.167\n",
      "Ep:8, loss:0.00004, loss_test:0.02116, lr:6.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:34.683, tt:312.146\n",
      "Ep:9, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.64602 (r=0.737,p=0.575),  time:34.564, tt:345.642\n",
      "Ep:10, loss:0.00004, loss_test:0.02049, lr:6.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:34.678, tt:381.456\n",
      "Ep:11, loss:0.00004, loss_test:0.01964, lr:6.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:34.711, tt:416.536\n",
      "Ep:12, loss:0.00003, loss_test:0.01937, lr:6.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:34.697, tt:451.059\n",
      "Ep:13, loss:0.00003, loss_test:0.01908, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:34.768, tt:486.751\n",
      "Ep:14, loss:0.00003, loss_test:0.01874, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:34.710, tt:520.645\n",
      "Ep:15, loss:0.00003, loss_test:0.01870, lr:6.00e-02, fs:0.66946 (r=0.808,p=0.571),  time:34.745, tt:555.916\n",
      "Ep:16, loss:0.00003, loss_test:0.01877, lr:6.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:34.766, tt:591.020\n",
      "Ep:17, loss:0.00003, loss_test:0.01836, lr:6.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:34.763, tt:625.729\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:34.780, tt:660.816\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:34.648, tt:692.960\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:34.661, tt:727.889\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01638, lr:6.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:34.675, tt:762.845\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01638, lr:6.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:34.644, tt:796.814\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:34.606, tt:830.543\n",
      "Ep:24, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:34.590, tt:864.757\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01579, lr:6.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:34.669, tt:901.394\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01562, lr:6.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:34.653, tt:935.638\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01552, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:34.642, tt:969.989\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01553, lr:6.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:34.665, tt:1005.280\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01549, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:34.680, tt:1040.392\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:34.615, tt:1073.070\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01524, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:34.588, tt:1106.809\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:34.573, tt:1140.894\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:34.584, tt:1175.849\n",
      "Ep:34, loss:0.00002, loss_test:0.01508, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.581, tt:1210.321\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01502, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.588, tt:1245.164\n",
      "Ep:36, loss:0.00002, loss_test:0.01493, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:34.605, tt:1280.391\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01487, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:34.598, tt:1314.727\n",
      "Ep:38, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.578, tt:1348.523\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:34.611, tt:1384.440\n",
      "Ep:40, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:34.632, tt:1419.894\n",
      "Ep:41, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:34.651, tt:1455.328\n",
      "Ep:42, loss:0.00001, loss_test:0.01484, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.659, tt:1490.335\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.714, tt:1527.430\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01479, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.704, tt:1561.696\n",
      "Ep:45, loss:0.00001, loss_test:0.01484, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.691, tt:1595.767\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01485, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.656, tt:1628.855\n",
      "Ep:47, loss:0.00001, loss_test:0.01489, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.646, tt:1662.985\n",
      "Ep:48, loss:0.00001, loss_test:0.01497, lr:6.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:34.669, tt:1698.771\n",
      "Ep:49, loss:0.00001, loss_test:0.01504, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:34.683, tt:1734.138\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01511, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.717, tt:1770.581\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01508, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.716, tt:1805.206\n",
      "Ep:52, loss:0.00001, loss_test:0.01507, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:34.727, tt:1840.552\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01516, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.734, tt:1875.651\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01524, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.720, tt:1909.609\n",
      "Ep:55, loss:0.00001, loss_test:0.01534, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.709, tt:1943.687\n",
      "Ep:56, loss:0.00001, loss_test:0.01542, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.689, tt:1977.258\n",
      "Ep:57, loss:0.00001, loss_test:0.01551, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.711, tt:2013.265\n",
      "Ep:58, loss:0.00001, loss_test:0.01550, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.710, tt:2047.869\n",
      "Ep:59, loss:0.00001, loss_test:0.01559, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.696, tt:2081.764\n",
      "Ep:60, loss:0.00001, loss_test:0.01571, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.719, tt:2117.834\n",
      "Ep:61, loss:0.00001, loss_test:0.01580, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.724, tt:2152.858\n",
      "Ep:62, loss:0.00001, loss_test:0.01587, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.722, tt:2187.473\n",
      "Ep:63, loss:0.00001, loss_test:0.01597, lr:6.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.776, tt:2225.655\n",
      "Ep:64, loss:0.00001, loss_test:0.01601, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.781, tt:2260.793\n",
      "Ep:65, loss:0.00001, loss_test:0.01616, lr:5.94e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.781, tt:2295.566\n",
      "Ep:66, loss:0.00001, loss_test:0.01622, lr:5.88e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.778, tt:2330.156\n",
      "Ep:67, loss:0.00001, loss_test:0.01628, lr:5.82e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.788, tt:2365.588\n",
      "Ep:68, loss:0.00001, loss_test:0.01634, lr:5.76e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.806, tt:2401.646\n",
      "Ep:69, loss:0.00001, loss_test:0.01646, lr:5.71e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.797, tt:2435.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00001, loss_test:0.01652, lr:5.65e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.813, tt:2471.744\n",
      "Ep:71, loss:0.00001, loss_test:0.01669, lr:5.59e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.809, tt:2506.267\n",
      "Ep:72, loss:0.00001, loss_test:0.01682, lr:5.54e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.814, tt:2541.426\n",
      "Ep:73, loss:0.00001, loss_test:0.01688, lr:5.48e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.824, tt:2576.974\n",
      "Ep:74, loss:0.00001, loss_test:0.01696, lr:5.43e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.821, tt:2611.545\n",
      "Ep:75, loss:0.00001, loss_test:0.01696, lr:5.37e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.833, tt:2647.284\n",
      "Ep:76, loss:0.00001, loss_test:0.01700, lr:5.32e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.816, tt:2680.843\n",
      "Ep:77, loss:0.00001, loss_test:0.01717, lr:5.27e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.822, tt:2716.094\n",
      "Ep:78, loss:0.00001, loss_test:0.01726, lr:5.21e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.825, tt:2751.201\n",
      "Ep:79, loss:0.00001, loss_test:0.01727, lr:5.16e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.799, tt:2783.901\n",
      "Ep:80, loss:0.00001, loss_test:0.01739, lr:5.11e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.809, tt:2819.508\n",
      "Ep:81, loss:0.00001, loss_test:0.01743, lr:5.06e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.783, tt:2852.207\n",
      "Ep:82, loss:0.00001, loss_test:0.01751, lr:5.01e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.805, tt:2888.850\n",
      "Ep:83, loss:0.00001, loss_test:0.01762, lr:4.96e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.806, tt:2923.709\n",
      "Ep:84, loss:0.00001, loss_test:0.01767, lr:4.91e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.811, tt:2958.953\n",
      "Ep:85, loss:0.00001, loss_test:0.01775, lr:4.86e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.813, tt:2993.953\n",
      "Ep:86, loss:0.00001, loss_test:0.01787, lr:4.81e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.828, tt:3030.046\n",
      "Ep:87, loss:0.00001, loss_test:0.01796, lr:4.76e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.823, tt:3064.458\n",
      "Ep:88, loss:0.00001, loss_test:0.01801, lr:4.71e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.807, tt:3097.793\n",
      "Ep:89, loss:0.00001, loss_test:0.01804, lr:4.67e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.785, tt:3130.628\n",
      "Ep:90, loss:0.00001, loss_test:0.01809, lr:4.62e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.773, tt:3164.339\n",
      "Ep:91, loss:0.00001, loss_test:0.01824, lr:4.57e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.780, tt:3199.722\n",
      "Ep:92, loss:0.00001, loss_test:0.01828, lr:4.53e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.771, tt:3233.725\n",
      "Ep:93, loss:0.00001, loss_test:0.01834, lr:4.48e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.762, tt:3267.671\n",
      "Ep:94, loss:0.00001, loss_test:0.01844, lr:4.44e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.768, tt:3302.986\n",
      "Ep:95, loss:0.00001, loss_test:0.01852, lr:4.39e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.770, tt:3337.934\n",
      "Ep:96, loss:0.00001, loss_test:0.01856, lr:4.35e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.772, tt:3372.862\n",
      "Ep:97, loss:0.00001, loss_test:0.01862, lr:4.31e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.789, tt:3409.309\n",
      "Ep:98, loss:0.00001, loss_test:0.01864, lr:4.26e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.773, tt:3442.545\n",
      "Ep:99, loss:0.00000, loss_test:0.01874, lr:4.22e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.764, tt:3476.364\n",
      "Ep:100, loss:0.00000, loss_test:0.01879, lr:4.18e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.754, tt:3510.139\n",
      "Ep:101, loss:0.00000, loss_test:0.01887, lr:4.14e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.751, tt:3544.615\n",
      "Ep:102, loss:0.00000, loss_test:0.01891, lr:4.10e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.801, tt:3584.543\n",
      "Ep:103, loss:0.00000, loss_test:0.01898, lr:4.05e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.804, tt:3619.606\n",
      "Ep:104, loss:0.00000, loss_test:0.01908, lr:4.01e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.815, tt:3655.605\n",
      "Ep:105, loss:0.00000, loss_test:0.01911, lr:3.97e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.809, tt:3689.760\n",
      "Ep:106, loss:0.00000, loss_test:0.01915, lr:3.93e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.815, tt:3725.187\n",
      "Ep:107, loss:0.00000, loss_test:0.01920, lr:3.89e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.802, tt:3758.659\n",
      "Ep:108, loss:0.00000, loss_test:0.01928, lr:3.86e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.813, tt:3794.632\n",
      "Ep:109, loss:0.00000, loss_test:0.01933, lr:3.82e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.798, tt:3827.750\n",
      "Ep:110, loss:0.00000, loss_test:0.01940, lr:3.78e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.779, tt:3860.461\n",
      "Ep:111, loss:0.00000, loss_test:0.01948, lr:3.74e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.775, tt:3894.824\n",
      "Ep:112, loss:0.00000, loss_test:0.01955, lr:3.70e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.756, tt:3927.403\n",
      "Ep:113, loss:0.00000, loss_test:0.01962, lr:3.67e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.752, tt:3961.727\n",
      "Ep:114, loss:0.00000, loss_test:0.01963, lr:3.63e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.750, tt:3996.304\n",
      "Ep:115, loss:0.00000, loss_test:0.01966, lr:3.59e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.744, tt:4030.249\n",
      "Ep:116, loss:0.00000, loss_test:0.01976, lr:3.56e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.742, tt:4064.780\n",
      "Ep:117, loss:0.00000, loss_test:0.01976, lr:3.52e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.737, tt:4098.982\n",
      "Ep:118, loss:0.00000, loss_test:0.01982, lr:3.49e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.741, tt:4134.209\n",
      "Ep:119, loss:0.00000, loss_test:0.01990, lr:3.45e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.737, tt:4168.492\n",
      "Ep:120, loss:0.00000, loss_test:0.01995, lr:3.42e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.738, tt:4203.279\n",
      "Ep:121, loss:0.00000, loss_test:0.02004, lr:3.38e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.739, tt:4238.179\n",
      "Ep:122, loss:0.00000, loss_test:0.02008, lr:3.35e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.736, tt:4272.567\n",
      "Ep:123, loss:0.00000, loss_test:0.02011, lr:3.32e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.735, tt:4307.162\n",
      "Ep:124, loss:0.00000, loss_test:0.02015, lr:3.28e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.731, tt:4341.409\n",
      "Ep:125, loss:0.00000, loss_test:0.02022, lr:3.25e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.725, tt:4375.349\n",
      "Ep:126, loss:0.00000, loss_test:0.02029, lr:3.22e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.712, tt:4408.381\n",
      "Ep:127, loss:0.00000, loss_test:0.02030, lr:3.19e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.714, tt:4443.341\n",
      "Ep:128, loss:0.00000, loss_test:0.02035, lr:3.15e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.712, tt:4477.784\n",
      "Ep:129, loss:0.00000, loss_test:0.02040, lr:3.12e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.717, tt:4513.247\n",
      "Ep:130, loss:0.00000, loss_test:0.02045, lr:3.09e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.697, tt:4545.356\n",
      "Ep:131, loss:0.00000, loss_test:0.02049, lr:3.06e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.702, tt:4580.664\n",
      "Ep:132, loss:0.00000, loss_test:0.02052, lr:3.03e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.698, tt:4614.792\n",
      "Ep:133, loss:0.00000, loss_test:0.02059, lr:3.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.699, tt:4649.608\n",
      "Ep:134, loss:0.00000, loss_test:0.02070, lr:2.97e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.692, tt:4683.462\n",
      "Ep:135, loss:0.00000, loss_test:0.02071, lr:2.94e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.684, tt:4717.081\n",
      "Ep:136, loss:0.00000, loss_test:0.02076, lr:2.91e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.675, tt:4750.543\n",
      "Ep:137, loss:0.00000, loss_test:0.02082, lr:2.88e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.652, tt:4781.984\n",
      "Ep:138, loss:0.00000, loss_test:0.02083, lr:2.85e-02, fs:0.76301 (r=0.667,p=0.892),  time:34.651, tt:4816.436\n",
      "Ep:139, loss:0.00000, loss_test:0.02085, lr:2.82e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.652, tt:4851.332\n",
      "Ep:140, loss:0.00000, loss_test:0.02090, lr:2.80e-02, fs:0.76301 (r=0.667,p=0.892),  time:34.656, tt:4886.495\n",
      "Ep:141, loss:0.00000, loss_test:0.02098, lr:2.77e-02, fs:0.76301 (r=0.667,p=0.892),  time:34.659, tt:4921.525\n",
      "Ep:142, loss:0.00000, loss_test:0.02101, lr:2.74e-02, fs:0.76301 (r=0.667,p=0.892),  time:34.663, tt:4956.805\n",
      "Ep:143, loss:0.00000, loss_test:0.02104, lr:2.71e-02, fs:0.76301 (r=0.667,p=0.892),  time:34.662, tt:4991.347\n",
      "Ep:144, loss:0.00000, loss_test:0.02104, lr:2.69e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.661, tt:5025.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.02109, lr:2.66e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.658, tt:5060.003\n",
      "Ep:146, loss:0.00000, loss_test:0.02113, lr:2.63e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.660, tt:5095.074\n",
      "Ep:147, loss:0.00000, loss_test:0.02119, lr:2.61e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.671, tt:5131.289\n",
      "Ep:148, loss:0.00000, loss_test:0.02126, lr:2.58e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.675, tt:5166.596\n",
      "Ep:149, loss:0.00000, loss_test:0.02128, lr:2.55e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.673, tt:5200.952\n",
      "Ep:150, loss:0.00000, loss_test:0.02132, lr:2.53e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.668, tt:5234.795\n",
      "Ep:151, loss:0.00000, loss_test:0.02134, lr:2.50e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.654, tt:5267.390\n",
      "Ep:152, loss:0.00000, loss_test:0.02136, lr:2.48e-02, fs:0.75581 (r=0.657,p=0.890),  time:34.655, tt:5302.282\n",
      "Ep:153, loss:0.00000, loss_test:0.02142, lr:2.45e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.660, tt:5337.597\n",
      "Ep:154, loss:0.00000, loss_test:0.02143, lr:2.43e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.657, tt:5371.878\n",
      "Ep:155, loss:0.00000, loss_test:0.02149, lr:2.40e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.661, tt:5407.165\n",
      "Ep:156, loss:0.00000, loss_test:0.02154, lr:2.38e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.685, tt:5445.579\n",
      "Ep:157, loss:0.00000, loss_test:0.02155, lr:2.36e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.691, tt:5481.163\n",
      "Ep:158, loss:0.00000, loss_test:0.02158, lr:2.33e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.683, tt:5514.602\n",
      "Ep:159, loss:0.00000, loss_test:0.02164, lr:2.31e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.691, tt:5550.567\n",
      "Ep:160, loss:0.00000, loss_test:0.02167, lr:2.29e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.692, tt:5585.481\n",
      "Ep:161, loss:0.00000, loss_test:0.02168, lr:2.26e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.692, tt:5620.129\n",
      "Ep:162, loss:0.00000, loss_test:0.02172, lr:2.24e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.694, tt:5655.159\n",
      "Ep:163, loss:0.00000, loss_test:0.02174, lr:2.22e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.694, tt:5689.828\n",
      "Ep:164, loss:0.00000, loss_test:0.02180, lr:2.20e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.692, tt:5724.114\n",
      "Ep:165, loss:0.00000, loss_test:0.02185, lr:2.17e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.690, tt:5758.457\n",
      "Ep:166, loss:0.00000, loss_test:0.02187, lr:2.15e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.695, tt:5794.012\n",
      "Ep:167, loss:0.00000, loss_test:0.02189, lr:2.13e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.701, tt:5829.793\n",
      "Ep:168, loss:0.00000, loss_test:0.02193, lr:2.11e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.699, tt:5864.189\n",
      "Ep:169, loss:0.00000, loss_test:0.02196, lr:2.09e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.703, tt:5899.446\n",
      "Ep:170, loss:0.00000, loss_test:0.02198, lr:2.07e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.702, tt:5934.092\n",
      "Ep:171, loss:0.00000, loss_test:0.02199, lr:2.05e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.705, tt:5969.327\n",
      "Ep:172, loss:0.00000, loss_test:0.02203, lr:2.03e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.705, tt:6003.883\n",
      "Ep:173, loss:0.00000, loss_test:0.02207, lr:2.01e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.708, tt:6039.126\n",
      "Ep:174, loss:0.00000, loss_test:0.02208, lr:1.99e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.704, tt:6073.273\n",
      "Ep:175, loss:0.00000, loss_test:0.02211, lr:1.97e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.702, tt:6107.473\n",
      "Ep:176, loss:0.00000, loss_test:0.02216, lr:1.95e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.715, tt:6144.470\n",
      "Ep:177, loss:0.00000, loss_test:0.02217, lr:1.93e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.713, tt:6178.849\n",
      "Ep:178, loss:0.00000, loss_test:0.02220, lr:1.91e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.720, tt:6214.803\n",
      "Ep:179, loss:0.00000, loss_test:0.02223, lr:1.89e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.719, tt:6249.358\n",
      "Ep:180, loss:0.00000, loss_test:0.02227, lr:1.87e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.723, tt:6284.855\n",
      "Ep:181, loss:0.00000, loss_test:0.02230, lr:1.85e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.719, tt:6318.922\n",
      "Ep:182, loss:0.00000, loss_test:0.02232, lr:1.83e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.717, tt:6353.156\n",
      "Ep:183, loss:0.00000, loss_test:0.02234, lr:1.81e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.716, tt:6387.683\n",
      "Ep:184, loss:0.00000, loss_test:0.02236, lr:1.80e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.712, tt:6421.755\n",
      "Ep:185, loss:0.00000, loss_test:0.02239, lr:1.78e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.716, tt:6457.234\n",
      "Ep:186, loss:0.00000, loss_test:0.02243, lr:1.76e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.724, tt:6493.425\n",
      "Ep:187, loss:0.00000, loss_test:0.02245, lr:1.74e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.730, tt:6529.246\n",
      "Ep:188, loss:0.00000, loss_test:0.02246, lr:1.73e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.726, tt:6563.262\n",
      "Ep:189, loss:0.00000, loss_test:0.02248, lr:1.71e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.728, tt:6598.338\n",
      "Ep:190, loss:0.00000, loss_test:0.02252, lr:1.69e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.725, tt:6632.503\n",
      "Ep:191, loss:0.00000, loss_test:0.02255, lr:1.67e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.723, tt:6666.899\n",
      "Ep:192, loss:0.00000, loss_test:0.02257, lr:1.66e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.726, tt:6702.141\n",
      "Ep:193, loss:0.00000, loss_test:0.02260, lr:1.64e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.729, tt:6737.356\n",
      "Ep:194, loss:0.00000, loss_test:0.02261, lr:1.62e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.726, tt:6771.602\n",
      "Ep:195, loss:0.00000, loss_test:0.02262, lr:1.61e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.726, tt:6806.341\n",
      "Ep:196, loss:0.00000, loss_test:0.02265, lr:1.59e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.716, tt:6839.116\n",
      "Ep:197, loss:0.00000, loss_test:0.02267, lr:1.58e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.702, tt:6871.080\n",
      "Ep:198, loss:0.00000, loss_test:0.02270, lr:1.56e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.681, tt:6901.600\n",
      "Ep:199, loss:0.00000, loss_test:0.02271, lr:1.54e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.653, tt:6930.516\n",
      "Ep:200, loss:0.00000, loss_test:0.02274, lr:1.53e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.628, tt:6960.275\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14366, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.891, tt:33.891\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14279, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.805, tt:69.611\n",
      "Ep:2, loss:0.00028, loss_test:0.14129, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.335, tt:106.006\n",
      "Ep:3, loss:0.00028, loss_test:0.13893, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.654, tt:142.617\n",
      "Ep:4, loss:0.00027, loss_test:0.13509, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:35.625, tt:178.125\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12866, lr:1.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:35.722, tt:214.332\n",
      "Ep:6, loss:0.00024, loss_test:0.12595, lr:1.00e-02, fs:0.63203 (r=0.737,p=0.553),  time:35.694, tt:249.860\n",
      "Ep:7, loss:0.00023, loss_test:0.13082, lr:1.00e-02, fs:0.62911 (r=0.677,p=0.588),  time:35.843, tt:286.744\n",
      "Ep:8, loss:0.00023, loss_test:0.12966, lr:1.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:36.246, tt:326.211\n",
      "Ep:9, loss:0.00022, loss_test:0.12498, lr:1.00e-02, fs:0.62338 (r=0.727,p=0.545),  time:36.227, tt:362.274\n",
      "Ep:10, loss:0.00022, loss_test:0.12214, lr:1.00e-02, fs:0.64629 (r=0.747,p=0.569),  time:36.213, tt:398.348\n",
      "Ep:11, loss:0.00021, loss_test:0.11868, lr:1.00e-02, fs:0.65138 (r=0.717,p=0.597),  time:36.283, tt:435.397\n",
      "Ep:12, loss:0.00020, loss_test:0.11643, lr:1.00e-02, fs:0.67317 (r=0.697,p=0.651),  time:36.312, tt:472.062\n",
      "Ep:13, loss:0.00020, loss_test:0.11434, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:36.453, tt:510.348\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00019, loss_test:0.11178, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:36.523, tt:547.840\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10960, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:36.587, tt:585.392\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.10844, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:36.524, tt:620.909\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10725, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:36.487, tt:656.765\n",
      "Ep:18, loss:0.00016, loss_test:0.10635, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:36.473, tt:692.980\n",
      "Ep:19, loss:0.00015, loss_test:0.10470, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:36.511, tt:730.224\n",
      "Ep:20, loss:0.00015, loss_test:0.10229, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:36.523, tt:766.980\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.10066, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:36.548, tt:804.067\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.09862, lr:1.00e-02, fs:0.75429 (r=0.667,p=0.868),  time:36.558, tt:840.827\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09653, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:36.558, tt:877.397\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.09619, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:36.575, tt:914.370\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.09298, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:36.554, tt:950.413\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.09282, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:36.579, tt:987.622\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.09132, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:36.668, tt:1026.715\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.09227, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:36.664, tt:1063.258\n",
      "Ep:29, loss:0.00009, loss_test:0.09010, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:36.700, tt:1101.009\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.09218, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:36.741, tt:1138.959\n",
      "Ep:31, loss:0.00008, loss_test:0.08877, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:36.728, tt:1175.306\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08983, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:36.756, tt:1212.945\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.08624, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:36.736, tt:1249.015\n",
      "Ep:34, loss:0.00007, loss_test:0.09201, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:36.767, tt:1286.834\n",
      "Ep:35, loss:0.00007, loss_test:0.08395, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:36.795, tt:1324.608\n",
      "Ep:36, loss:0.00007, loss_test:0.09192, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:36.775, tt:1360.668\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.08431, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:36.786, tt:1397.871\n",
      "Ep:38, loss:0.00006, loss_test:0.09009, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.744, tt:1433.009\n",
      "Ep:39, loss:0.00006, loss_test:0.08507, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:36.750, tt:1469.984\n",
      "Ep:40, loss:0.00006, loss_test:0.08703, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.731, tt:1505.982\n",
      "Ep:41, loss:0.00005, loss_test:0.08578, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:36.725, tt:1542.465\n",
      "Ep:42, loss:0.00005, loss_test:0.08535, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:36.742, tt:1579.896\n",
      "Ep:43, loss:0.00005, loss_test:0.08262, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:36.744, tt:1616.735\n",
      "Ep:44, loss:0.00005, loss_test:0.08858, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.739, tt:1653.238\n",
      "Ep:45, loss:0.00004, loss_test:0.08219, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:36.824, tt:1693.918\n",
      "Ep:46, loss:0.00004, loss_test:0.08937, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.938, tt:1736.096\n",
      "Ep:47, loss:0.00004, loss_test:0.08307, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:36.920, tt:1772.143\n",
      "Ep:48, loss:0.00004, loss_test:0.08997, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.886, tt:1807.432\n",
      "Ep:49, loss:0.00004, loss_test:0.08273, lr:9.80e-03, fs:0.82162 (r=0.768,p=0.884),  time:36.877, tt:1843.872\n",
      "Ep:50, loss:0.00004, loss_test:0.09243, lr:9.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.802, tt:1876.927\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.08662, lr:9.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.789, tt:1913.036\n",
      "Ep:52, loss:0.00003, loss_test:0.08619, lr:9.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.793, tt:1950.006\n",
      "Ep:53, loss:0.00003, loss_test:0.08856, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.745, tt:1984.233\n",
      "Ep:54, loss:0.00003, loss_test:0.08542, lr:9.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.721, tt:2019.678\n",
      "Ep:55, loss:0.00003, loss_test:0.08894, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.712, tt:2055.876\n",
      "Ep:56, loss:0.00003, loss_test:0.08743, lr:9.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.699, tt:2091.836\n",
      "Ep:57, loss:0.00003, loss_test:0.08690, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.694, tt:2128.251\n",
      "Ep:58, loss:0.00003, loss_test:0.08770, lr:9.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.679, tt:2164.083\n",
      "Ep:59, loss:0.00003, loss_test:0.08581, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.666, tt:2199.955\n",
      "Ep:60, loss:0.00002, loss_test:0.08954, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.643, tt:2235.238\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.08660, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.615, tt:2270.112\n",
      "Ep:62, loss:0.00002, loss_test:0.09056, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.613, tt:2306.622\n",
      "Ep:63, loss:0.00002, loss_test:0.08913, lr:9.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.603, tt:2342.581\n",
      "Ep:64, loss:0.00002, loss_test:0.08692, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.594, tt:2378.586\n",
      "Ep:65, loss:0.00002, loss_test:0.08866, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.570, tt:2413.612\n",
      "Ep:66, loss:0.00002, loss_test:0.08877, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.548, tt:2448.703\n",
      "Ep:67, loss:0.00002, loss_test:0.08740, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.545, tt:2485.055\n",
      "Ep:68, loss:0.00002, loss_test:0.08890, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.527, tt:2520.331\n",
      "Ep:69, loss:0.00002, loss_test:0.08855, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.518, tt:2556.246\n",
      "Ep:70, loss:0.00002, loss_test:0.08875, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.515, tt:2592.580\n",
      "Ep:71, loss:0.00002, loss_test:0.08808, lr:9.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.497, tt:2627.764\n",
      "Ep:72, loss:0.00002, loss_test:0.08897, lr:9.61e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.467, tt:2662.098\n",
      "Ep:73, loss:0.00002, loss_test:0.09078, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.471, tt:2698.870\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.08961, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.445, tt:2733.372\n",
      "Ep:75, loss:0.00001, loss_test:0.08975, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.426, tt:2768.379\n",
      "Ep:76, loss:0.00001, loss_test:0.08928, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.419, tt:2804.287\n",
      "Ep:77, loss:0.00001, loss_test:0.09026, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.415, tt:2840.342\n",
      "Ep:78, loss:0.00001, loss_test:0.08958, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.402, tt:2875.753\n",
      "Ep:79, loss:0.00001, loss_test:0.09090, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.396, tt:2911.672\n",
      "Ep:80, loss:0.00001, loss_test:0.09238, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.381, tt:2946.860\n",
      "Ep:81, loss:0.00001, loss_test:0.09123, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.367, tt:2982.132\n",
      "Ep:82, loss:0.00001, loss_test:0.09403, lr:9.51e-03, fs:0.85227 (r=0.758,p=0.974),  time:36.349, tt:3016.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.09409, lr:9.51e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.336, tt:3052.207\n",
      "Ep:84, loss:0.00001, loss_test:0.09091, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.316, tt:3086.903\n",
      "Ep:85, loss:0.00001, loss_test:0.09260, lr:9.41e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.303, tt:3122.101\n",
      "Ep:86, loss:0.00001, loss_test:0.09208, lr:9.32e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.277, tt:3156.096\n",
      "Ep:87, loss:0.00001, loss_test:0.09269, lr:9.23e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.229, tt:3188.132\n",
      "Ep:88, loss:0.00001, loss_test:0.09298, lr:9.14e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.209, tt:3222.610\n",
      "Ep:89, loss:0.00001, loss_test:0.09386, lr:9.04e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.191, tt:3257.145\n",
      "Ep:90, loss:0.00001, loss_test:0.09276, lr:8.95e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.162, tt:3290.728\n",
      "Ep:91, loss:0.00001, loss_test:0.09462, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.151, tt:3325.924\n",
      "Ep:92, loss:0.00001, loss_test:0.09384, lr:8.78e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.147, tt:3361.655\n",
      "Ep:93, loss:0.00001, loss_test:0.09326, lr:8.69e-03, fs:0.85227 (r=0.758,p=0.974),  time:36.139, tt:3397.086\n",
      "Ep:94, loss:0.00001, loss_test:0.09498, lr:8.60e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.133, tt:3432.593\n",
      "Ep:95, loss:0.00001, loss_test:0.09386, lr:8.51e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.121, tt:3467.641\n",
      "Ep:96, loss:0.00001, loss_test:0.09584, lr:8.43e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.110, tt:3502.699\n",
      "Ep:97, loss:0.00001, loss_test:0.09444, lr:8.35e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.112, tt:3539.022\n",
      "Ep:98, loss:0.00001, loss_test:0.09704, lr:8.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.118, tt:3575.653\n",
      "Ep:99, loss:0.00001, loss_test:0.09636, lr:8.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.107, tt:3610.718\n",
      "Ep:100, loss:0.00001, loss_test:0.09713, lr:8.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.095, tt:3645.566\n",
      "Ep:101, loss:0.00001, loss_test:0.09818, lr:8.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.082, tt:3680.357\n",
      "Ep:102, loss:0.00001, loss_test:0.09672, lr:7.94e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.082, tt:3716.457\n",
      "Ep:103, loss:0.00001, loss_test:0.09858, lr:7.86e-03, fs:0.78049 (r=0.646,p=0.985),  time:36.071, tt:3751.387\n",
      "Ep:104, loss:0.00001, loss_test:0.09733, lr:7.78e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.068, tt:3787.163\n",
      "Ep:105, loss:0.00001, loss_test:0.09792, lr:7.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.068, tt:3823.183\n",
      "Ep:106, loss:0.00001, loss_test:0.09754, lr:7.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.053, tt:3857.622\n",
      "Ep:107, loss:0.00001, loss_test:0.09556, lr:7.55e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.046, tt:3893.021\n",
      "Ep:108, loss:0.00001, loss_test:0.09881, lr:7.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.036, tt:3927.909\n",
      "Ep:109, loss:0.00001, loss_test:0.09522, lr:7.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.021, tt:3962.336\n",
      "Ep:110, loss:0.00001, loss_test:0.09762, lr:7.32e-03, fs:0.78049 (r=0.646,p=0.985),  time:36.015, tt:3997.717\n",
      "Ep:111, loss:0.00001, loss_test:0.09671, lr:7.25e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.996, tt:4031.560\n",
      "Ep:112, loss:0.00001, loss_test:0.09919, lr:7.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.985, tt:4066.288\n",
      "Ep:113, loss:0.00001, loss_test:0.09742, lr:7.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.968, tt:4100.395\n",
      "Ep:114, loss:0.00001, loss_test:0.09688, lr:7.03e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.929, tt:4131.838\n",
      "Ep:115, loss:0.00001, loss_test:0.10005, lr:6.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:35.873, tt:4161.268\n",
      "Ep:116, loss:0.00001, loss_test:0.09748, lr:6.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.844, tt:4193.784\n",
      "Ep:117, loss:0.00001, loss_test:0.09818, lr:6.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.813, tt:4225.991\n",
      "Ep:118, loss:0.00001, loss_test:0.09778, lr:6.76e-03, fs:0.78049 (r=0.646,p=0.985),  time:35.784, tt:4258.315\n",
      "Ep:119, loss:0.00000, loss_test:0.09583, lr:6.69e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.757, tt:4290.798\n",
      "Ep:120, loss:0.00000, loss_test:0.09963, lr:6.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:35.727, tt:4323.018\n",
      "Ep:121, loss:0.00000, loss_test:0.09753, lr:6.56e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.699, tt:4355.305\n",
      "Ep:122, loss:0.00000, loss_test:0.09765, lr:6.49e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.666, tt:4386.943\n",
      "Ep:123, loss:0.00000, loss_test:0.09957, lr:6.43e-03, fs:0.78049 (r=0.646,p=0.985),  time:35.627, tt:4417.696\n",
      "Ep:124, loss:0.00000, loss_test:0.09774, lr:6.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.602, tt:4450.286\n",
      "Ep:125, loss:0.00000, loss_test:0.09957, lr:6.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.560, tt:4480.624\n",
      "Ep:126, loss:0.00000, loss_test:0.10075, lr:6.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.526, tt:4511.739\n",
      "Ep:127, loss:0.00000, loss_test:0.09701, lr:6.17e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.480, tt:4541.502\n",
      "Ep:128, loss:0.00000, loss_test:0.09939, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.449, tt:4572.967\n",
      "Ep:129, loss:0.00000, loss_test:0.09911, lr:6.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.445, tt:4607.838\n",
      "Ep:130, loss:0.00000, loss_test:0.09771, lr:5.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.424, tt:4640.493\n",
      "Ep:131, loss:0.00000, loss_test:0.09769, lr:5.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.376, tt:4669.632\n",
      "Ep:132, loss:0.00000, loss_test:0.09693, lr:5.87e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.349, tt:4701.371\n",
      "Ep:133, loss:0.00000, loss_test:0.09910, lr:5.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.322, tt:4733.099\n",
      "Ep:134, loss:0.00000, loss_test:0.09894, lr:5.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.290, tt:4764.103\n",
      "Ep:135, loss:0.00000, loss_test:0.09839, lr:5.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.252, tt:4794.306\n",
      "Ep:136, loss:0.00000, loss_test:0.09917, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.221, tt:4825.273\n",
      "Ep:137, loss:0.00000, loss_test:0.09699, lr:5.58e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.196, tt:4857.095\n",
      "Ep:138, loss:0.00000, loss_test:0.10078, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:35.169, tt:4888.538\n",
      "Ep:139, loss:0.00000, loss_test:0.09941, lr:5.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.153, tt:4921.460\n",
      "Ep:140, loss:0.00000, loss_test:0.09817, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.121, tt:4952.007\n",
      "Ep:141, loss:0.00000, loss_test:0.09867, lr:5.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.095, tt:4983.519\n",
      "Ep:142, loss:0.00000, loss_test:0.09764, lr:5.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.089, tt:5017.719\n",
      "Ep:143, loss:0.00000, loss_test:0.09800, lr:5.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.074, tt:5050.726\n",
      "Ep:144, loss:0.00000, loss_test:0.09820, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.051, tt:5082.376\n",
      "Ep:145, loss:0.00000, loss_test:0.09939, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.047, tt:5116.855\n",
      "Ep:146, loss:0.00000, loss_test:0.09986, lr:5.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.025, tt:5148.671\n",
      "Ep:147, loss:0.00000, loss_test:0.09978, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.986, tt:5177.866\n",
      "Ep:148, loss:0.00000, loss_test:0.09853, lr:5.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:34.960, tt:5209.045\n",
      "Ep:149, loss:0.00000, loss_test:0.09872, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.942, tt:5241.239\n",
      "Ep:150, loss:0.00000, loss_test:0.10036, lr:4.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.909, tt:5271.318\n",
      "Ep:151, loss:0.00000, loss_test:0.09989, lr:4.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:34.888, tt:5302.909\n",
      "Ep:152, loss:0.00000, loss_test:0.09755, lr:4.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.863, tt:5334.100\n",
      "Ep:153, loss:0.00000, loss_test:0.10088, lr:4.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.834, tt:5364.411\n",
      "Ep:154, loss:0.00000, loss_test:0.10042, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.807, tt:5395.118\n",
      "Ep:155, loss:0.00000, loss_test:0.09818, lr:4.66e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.775, tt:5424.900\n",
      "Ep:156, loss:0.00000, loss_test:0.09924, lr:4.61e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.752, tt:5456.027\n",
      "Ep:157, loss:0.00000, loss_test:0.09988, lr:4.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.720, tt:5485.739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:158, loss:0.00000, loss_test:0.09950, lr:4.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.697, tt:5516.845\n",
      "Ep:159, loss:0.00000, loss_test:0.09863, lr:4.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.675, tt:5548.080\n",
      "Ep:160, loss:0.00000, loss_test:0.09912, lr:4.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.654, tt:5579.230\n",
      "Ep:161, loss:0.00000, loss_test:0.09923, lr:4.39e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.626, tt:5609.408\n",
      "Ep:162, loss:0.00000, loss_test:0.09890, lr:4.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.599, tt:5639.700\n",
      "Ep:163, loss:0.00000, loss_test:0.10001, lr:4.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.565, tt:5668.705\n",
      "Ep:164, loss:0.00000, loss_test:0.09945, lr:4.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.526, tt:5696.821\n",
      "Ep:165, loss:0.00000, loss_test:0.09907, lr:4.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.486, tt:5724.700\n",
      "Ep:166, loss:0.00000, loss_test:0.09947, lr:4.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.464, tt:5755.437\n",
      "Ep:167, loss:0.00000, loss_test:0.09931, lr:4.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.441, tt:5786.043\n",
      "Ep:168, loss:0.00000, loss_test:0.09890, lr:4.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.422, tt:5817.286\n",
      "Ep:169, loss:0.00000, loss_test:0.09951, lr:4.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.401, tt:5848.227\n",
      "Ep:170, loss:0.00000, loss_test:0.09986, lr:4.01e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.375, tt:5878.133\n",
      "Ep:171, loss:0.00000, loss_test:0.09842, lr:3.97e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.358, tt:5909.600\n",
      "Ep:172, loss:0.00000, loss_test:0.10100, lr:3.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.350, tt:5942.588\n",
      "Ep:173, loss:0.00000, loss_test:0.10096, lr:3.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.329, tt:5973.234\n",
      "Ep:174, loss:0.00000, loss_test:0.09926, lr:3.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.312, tt:6004.553\n",
      "Ep:175, loss:0.00000, loss_test:0.09983, lr:3.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.297, tt:6036.334\n",
      "Ep:176, loss:0.00000, loss_test:0.10008, lr:3.77e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.273, tt:6066.264\n",
      "Ep:177, loss:0.00000, loss_test:0.09923, lr:3.73e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.260, tt:6098.194\n",
      "Ep:178, loss:0.00000, loss_test:0.09963, lr:3.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.244, tt:6129.659\n",
      "Ep:179, loss:0.00000, loss_test:0.10021, lr:3.66e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.223, tt:6160.094\n",
      "Ep:180, loss:0.00000, loss_test:0.09962, lr:3.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.205, tt:6191.034\n",
      "Ep:181, loss:0.00000, loss_test:0.09997, lr:3.59e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.190, tt:6222.585\n",
      "Ep:182, loss:0.00000, loss_test:0.09938, lr:3.55e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.170, tt:6253.147\n",
      "Ep:183, loss:0.00000, loss_test:0.10017, lr:3.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.156, tt:6284.646\n",
      "Ep:184, loss:0.00000, loss_test:0.10113, lr:3.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.139, tt:6315.765\n",
      "Ep:185, loss:0.00000, loss_test:0.09999, lr:3.45e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.126, tt:6347.439\n",
      "Ep:186, loss:0.00000, loss_test:0.09948, lr:3.41e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.120, tt:6380.503\n",
      "Ep:187, loss:0.00000, loss_test:0.09994, lr:3.38e-03, fs:0.78049 (r=0.646,p=0.985),  time:34.106, tt:6411.897\n",
      "Ep:188, loss:0.00000, loss_test:0.10008, lr:3.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.096, tt:6444.067\n",
      "Ep:189, loss:0.00000, loss_test:0.09987, lr:3.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.077, tt:6474.616\n",
      "Ep:190, loss:0.00000, loss_test:0.09995, lr:3.28e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.066, tt:6506.535\n",
      "Ep:191, loss:0.00000, loss_test:0.09979, lr:3.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.054, tt:6538.458\n",
      "Ep:192, loss:0.00000, loss_test:0.10017, lr:3.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.044, tt:6570.521\n",
      "Ep:193, loss:0.00000, loss_test:0.10006, lr:3.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.037, tt:6603.157\n",
      "Ep:194, loss:0.00000, loss_test:0.09976, lr:3.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.035, tt:6636.784\n",
      "Ep:195, loss:0.00000, loss_test:0.09989, lr:3.12e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.005, tt:6664.903\n",
      "Ep:196, loss:0.00000, loss_test:0.10051, lr:3.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.962, tt:6690.446\n",
      "Ep:197, loss:0.00000, loss_test:0.10024, lr:3.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.910, tt:6714.149\n",
      "Ep:198, loss:0.00000, loss_test:0.10014, lr:3.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.861, tt:6738.367\n",
      "Ep:199, loss:0.00000, loss_test:0.10040, lr:2.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.770, tt:6754.036\n",
      "Ep:200, loss:0.00000, loss_test:0.09979, lr:2.96e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.648, tt:6763.248\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01922, lr:6.00e-02, fs:0.65574 (r=0.920,p=0.510),  time:33.143, tt:33.143\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02342, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.606, tt:73.212\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02528, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.687, tt:113.060\n",
      "Ep:3, loss:0.00005, loss_test:0.02535, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.942, tt:151.769\n",
      "Ep:4, loss:0.00005, loss_test:0.02429, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.334, tt:191.668\n",
      "Ep:5, loss:0.00005, loss_test:0.02260, lr:6.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:38.487, tt:230.920\n",
      "Ep:6, loss:0.00005, loss_test:0.02080, lr:6.00e-02, fs:0.66397 (r=0.943,p=0.512),  time:39.151, tt:274.054\n",
      "Ep:7, loss:0.00004, loss_test:0.01935, lr:6.00e-02, fs:0.65272 (r=0.897,p=0.513),  time:39.302, tt:314.414\n",
      "Ep:8, loss:0.00004, loss_test:0.01852, lr:6.00e-02, fs:0.68807 (r=0.862,p=0.573),  time:39.447, tt:355.020\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01780, lr:6.00e-02, fs:0.70531 (r=0.839,p=0.608),  time:39.589, tt:395.891\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01660, lr:6.00e-02, fs:0.72115 (r=0.862,p=0.620),  time:39.571, tt:435.279\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01558, lr:6.00e-02, fs:0.72558 (r=0.897,p=0.609),  time:39.541, tt:474.493\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01509, lr:6.00e-02, fs:0.74107 (r=0.954,p=0.606),  time:39.576, tt:514.488\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01469, lr:6.00e-02, fs:0.75221 (r=0.977,p=0.612),  time:39.536, tt:553.508\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.75926 (r=0.943,p=0.636),  time:39.567, tt:593.510\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01391, lr:6.00e-02, fs:0.77358 (r=0.943,p=0.656),  time:39.577, tt:633.238\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01366, lr:6.00e-02, fs:0.78049 (r=0.920,p=0.678),  time:39.495, tt:671.410\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01343, lr:6.00e-02, fs:0.80788 (r=0.943,p=0.707),  time:39.499, tt:710.985\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01321, lr:6.00e-02, fs:0.80976 (r=0.954,p=0.703),  time:39.425, tt:749.071\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01304, lr:6.00e-02, fs:0.80976 (r=0.954,p=0.703),  time:39.493, tt:789.866\n",
      "Ep:20, loss:0.00003, loss_test:0.01288, lr:6.00e-02, fs:0.81373 (r=0.954,p=0.709),  time:39.528, tt:830.081\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01270, lr:6.00e-02, fs:0.81951 (r=0.966,p=0.712),  time:39.599, tt:871.171\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01251, lr:6.00e-02, fs:0.82353 (r=0.966,p=0.718),  time:39.641, tt:911.749\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01235, lr:6.00e-02, fs:0.82759 (r=0.966,p=0.724),  time:39.935, tt:958.437\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01221, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:40.022, tt:1000.543\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01208, lr:6.00e-02, fs:0.84422 (r=0.966,p=0.750),  time:40.079, tt:1042.050\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01196, lr:6.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:40.156, tt:1084.204\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01186, lr:6.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:40.252, tt:1127.060\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01175, lr:6.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:40.265, tt:1167.676\n",
      "Ep:29, loss:0.00002, loss_test:0.01165, lr:6.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:40.282, tt:1208.467\n",
      "Ep:30, loss:0.00002, loss_test:0.01154, lr:6.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:40.373, tt:1251.554\n",
      "Ep:31, loss:0.00002, loss_test:0.01146, lr:6.00e-02, fs:0.85567 (r=0.954,p=0.776),  time:40.331, tt:1290.605\n",
      "Ep:32, loss:0.00002, loss_test:0.01139, lr:6.00e-02, fs:0.86458 (r=0.954,p=0.790),  time:40.357, tt:1331.794\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01130, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:40.362, tt:1372.314\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:40.368, tt:1412.881\n",
      "Ep:35, loss:0.00002, loss_test:0.01111, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:40.404, tt:1454.560\n",
      "Ep:36, loss:0.00002, loss_test:0.01104, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:40.437, tt:1496.172\n",
      "Ep:37, loss:0.00002, loss_test:0.01096, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:40.490, tt:1538.607\n",
      "Ep:38, loss:0.00002, loss_test:0.01087, lr:6.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:40.494, tt:1579.270\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01079, lr:6.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:40.470, tt:1618.802\n",
      "Ep:40, loss:0.00002, loss_test:0.01076, lr:6.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:40.461, tt:1658.892\n",
      "Ep:41, loss:0.00002, loss_test:0.01071, lr:6.00e-02, fs:0.88660 (r=0.989,p=0.804),  time:40.453, tt:1699.046\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01063, lr:6.00e-02, fs:0.88660 (r=0.989,p=0.804),  time:40.448, tt:1739.249\n",
      "Ep:43, loss:0.00002, loss_test:0.01058, lr:6.00e-02, fs:0.88660 (r=0.989,p=0.804),  time:40.437, tt:1779.247\n",
      "Ep:44, loss:0.00002, loss_test:0.01052, lr:6.00e-02, fs:0.88083 (r=0.977,p=0.802),  time:40.433, tt:1819.467\n",
      "Ep:45, loss:0.00002, loss_test:0.01044, lr:6.00e-02, fs:0.88542 (r=0.977,p=0.810),  time:40.445, tt:1860.489\n",
      "Ep:46, loss:0.00002, loss_test:0.01037, lr:6.00e-02, fs:0.88083 (r=0.977,p=0.802),  time:40.458, tt:1901.541\n",
      "Ep:47, loss:0.00002, loss_test:0.01032, lr:6.00e-02, fs:0.88542 (r=0.977,p=0.810),  time:40.427, tt:1940.501\n",
      "Ep:48, loss:0.00002, loss_test:0.01027, lr:6.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:40.454, tt:1982.264\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01025, lr:6.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:40.423, tt:2021.147\n",
      "Ep:50, loss:0.00001, loss_test:0.01023, lr:6.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:40.444, tt:2062.662\n",
      "Ep:51, loss:0.00001, loss_test:0.01021, lr:6.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:40.395, tt:2100.521\n",
      "Ep:52, loss:0.00001, loss_test:0.01017, lr:6.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:40.362, tt:2139.181\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01016, lr:6.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:40.340, tt:2178.355\n",
      "Ep:54, loss:0.00001, loss_test:0.01012, lr:6.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:40.347, tt:2219.097\n",
      "Ep:55, loss:0.00001, loss_test:0.01007, lr:6.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:40.347, tt:2259.420\n",
      "Ep:56, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:40.352, tt:2300.064\n",
      "Ep:57, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.89947 (r=0.977,p=0.833),  time:40.340, tt:2339.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01002, lr:6.00e-02, fs:0.90426 (r=0.977,p=0.842),  time:40.322, tt:2379.013\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.00999, lr:6.00e-02, fs:0.90426 (r=0.977,p=0.842),  time:40.303, tt:2418.173\n",
      "Ep:60, loss:0.00001, loss_test:0.00996, lr:6.00e-02, fs:0.90909 (r=0.977,p=0.850),  time:40.334, tt:2460.380\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.00993, lr:6.00e-02, fs:0.90909 (r=0.977,p=0.850),  time:40.330, tt:2500.457\n",
      "Ep:62, loss:0.00001, loss_test:0.00992, lr:6.00e-02, fs:0.90909 (r=0.977,p=0.850),  time:40.360, tt:2542.681\n",
      "Ep:63, loss:0.00001, loss_test:0.00989, lr:6.00e-02, fs:0.91398 (r=0.977,p=0.859),  time:40.372, tt:2583.780\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.00988, lr:6.00e-02, fs:0.91398 (r=0.977,p=0.859),  time:40.401, tt:2626.076\n",
      "Ep:65, loss:0.00001, loss_test:0.00985, lr:6.00e-02, fs:0.91398 (r=0.977,p=0.859),  time:40.426, tt:2668.107\n",
      "Ep:66, loss:0.00001, loss_test:0.00981, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.451, tt:2710.214\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.00978, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.471, tt:2752.036\n",
      "Ep:68, loss:0.00001, loss_test:0.00976, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.496, tt:2794.219\n",
      "Ep:69, loss:0.00001, loss_test:0.00975, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.475, tt:2833.230\n",
      "Ep:70, loss:0.00001, loss_test:0.00974, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.481, tt:2874.145\n",
      "Ep:71, loss:0.00001, loss_test:0.00969, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.486, tt:2915.028\n",
      "Ep:72, loss:0.00001, loss_test:0.00968, lr:6.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.502, tt:2956.647\n",
      "Ep:73, loss:0.00001, loss_test:0.00967, lr:6.00e-02, fs:0.92473 (r=0.989,p=0.869),  time:40.531, tt:2999.315\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.00964, lr:6.00e-02, fs:0.92473 (r=0.989,p=0.869),  time:40.526, tt:3039.413\n",
      "Ep:75, loss:0.00001, loss_test:0.00965, lr:6.00e-02, fs:0.92473 (r=0.989,p=0.869),  time:40.545, tt:3081.429\n",
      "Ep:76, loss:0.00001, loss_test:0.00964, lr:6.00e-02, fs:0.92473 (r=0.989,p=0.869),  time:40.552, tt:3122.532\n",
      "Ep:77, loss:0.00001, loss_test:0.00962, lr:6.00e-02, fs:0.92473 (r=0.989,p=0.869),  time:40.551, tt:3162.999\n",
      "Ep:78, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.92973 (r=0.989,p=0.878),  time:40.548, tt:3203.267\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.00959, lr:6.00e-02, fs:0.92973 (r=0.989,p=0.878),  time:40.542, tt:3243.321\n",
      "Ep:80, loss:0.00001, loss_test:0.00958, lr:6.00e-02, fs:0.92973 (r=0.989,p=0.878),  time:40.553, tt:3284.764\n",
      "Ep:81, loss:0.00001, loss_test:0.00955, lr:6.00e-02, fs:0.92973 (r=0.989,p=0.878),  time:40.569, tt:3326.666\n",
      "Ep:82, loss:0.00001, loss_test:0.00956, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.588, tt:3368.809\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.594, tt:3409.886\n",
      "Ep:84, loss:0.00001, loss_test:0.00959, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.596, tt:3450.656\n",
      "Ep:85, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.634, tt:3494.531\n",
      "Ep:86, loss:0.00001, loss_test:0.00960, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.634, tt:3535.132\n",
      "Ep:87, loss:0.00001, loss_test:0.00960, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.627, tt:3575.139\n",
      "Ep:88, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.627, tt:3615.806\n",
      "Ep:89, loss:0.00001, loss_test:0.00956, lr:6.00e-02, fs:0.94565 (r=1.000,p=0.897),  time:40.627, tt:3656.406\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.00955, lr:6.00e-02, fs:0.94565 (r=1.000,p=0.897),  time:40.625, tt:3696.835\n",
      "Ep:91, loss:0.00001, loss_test:0.00959, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.610, tt:3736.106\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.622, tt:3777.876\n",
      "Ep:93, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.623, tt:3818.603\n",
      "Ep:94, loss:0.00001, loss_test:0.00962, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.634, tt:3860.221\n",
      "Ep:95, loss:0.00001, loss_test:0.00964, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.636, tt:3901.059\n",
      "Ep:96, loss:0.00001, loss_test:0.00967, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.626, tt:3940.695\n",
      "Ep:97, loss:0.00001, loss_test:0.00965, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.628, tt:3981.561\n",
      "Ep:98, loss:0.00001, loss_test:0.00965, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.635, tt:4022.876\n",
      "Ep:99, loss:0.00001, loss_test:0.00965, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.628, tt:4062.801\n",
      "Ep:100, loss:0.00001, loss_test:0.00967, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.647, tt:4105.388\n",
      "Ep:101, loss:0.00001, loss_test:0.00969, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.663, tt:4147.618\n",
      "Ep:102, loss:0.00001, loss_test:0.00971, lr:6.00e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.670, tt:4189.033\n",
      "Ep:103, loss:0.00001, loss_test:0.00973, lr:5.94e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.652, tt:4227.829\n",
      "Ep:104, loss:0.00001, loss_test:0.00977, lr:5.88e-02, fs:0.95082 (r=1.000,p=0.906),  time:40.655, tt:4268.792\n",
      "Ep:105, loss:0.00001, loss_test:0.00980, lr:5.82e-02, fs:0.95604 (r=1.000,p=0.916),  time:40.652, tt:4309.160\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.00978, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.664, tt:4351.043\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.00976, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.679, tt:4393.284\n",
      "Ep:108, loss:0.00001, loss_test:0.00977, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.675, tt:4433.535\n",
      "Ep:109, loss:0.00001, loss_test:0.00981, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.670, tt:4473.701\n",
      "Ep:110, loss:0.00001, loss_test:0.00984, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.663, tt:4513.581\n",
      "Ep:111, loss:0.00001, loss_test:0.00986, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.671, tt:4555.164\n",
      "Ep:112, loss:0.00001, loss_test:0.00985, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.677, tt:4596.483\n",
      "Ep:113, loss:0.00001, loss_test:0.00986, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.674, tt:4636.805\n",
      "Ep:114, loss:0.00001, loss_test:0.00988, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.657, tt:4675.513\n",
      "Ep:115, loss:0.00001, loss_test:0.00996, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.667, tt:4717.403\n",
      "Ep:116, loss:0.00001, loss_test:0.01000, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.662, tt:4757.457\n",
      "Ep:117, loss:0.00000, loss_test:0.01001, lr:5.82e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.646, tt:4796.261\n",
      "Ep:118, loss:0.00000, loss_test:0.00999, lr:5.76e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.654, tt:4837.804\n",
      "Ep:119, loss:0.00000, loss_test:0.00998, lr:5.71e-02, fs:0.96133 (r=1.000,p=0.926),  time:40.651, tt:4878.127\n",
      "Ep:120, loss:0.00000, loss_test:0.01005, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.645, tt:4918.022\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00000, loss_test:0.01008, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.642, tt:4958.282\n",
      "Ep:122, loss:0.00000, loss_test:0.01011, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.643, tt:4999.120\n",
      "Ep:123, loss:0.00000, loss_test:0.01010, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.649, tt:5040.504\n",
      "Ep:124, loss:0.00000, loss_test:0.01011, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.654, tt:5081.778\n",
      "Ep:125, loss:0.00000, loss_test:0.01016, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.657, tt:5122.819\n",
      "Ep:126, loss:0.00000, loss_test:0.01018, lr:5.65e-02, fs:0.97207 (r=1.000,p=0.946),  time:40.642, tt:5161.570\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00000, loss_test:0.01020, lr:5.65e-02, fs:0.96667 (r=1.000,p=0.935),  time:40.680, tt:5207.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00000, loss_test:0.01022, lr:5.65e-02, fs:0.96629 (r=0.989,p=0.945),  time:40.684, tt:5248.196\n",
      "Ep:129, loss:0.00000, loss_test:0.01024, lr:5.65e-02, fs:0.94857 (r=0.954,p=0.943),  time:40.684, tt:5288.964\n",
      "Ep:130, loss:0.00000, loss_test:0.01025, lr:5.65e-02, fs:0.94857 (r=0.954,p=0.943),  time:40.675, tt:5328.365\n",
      "Ep:131, loss:0.00000, loss_test:0.01028, lr:5.65e-02, fs:0.94857 (r=0.954,p=0.943),  time:40.690, tt:5371.065\n",
      "Ep:132, loss:0.00000, loss_test:0.01028, lr:5.65e-02, fs:0.94857 (r=0.954,p=0.943),  time:40.704, tt:5413.603\n",
      "Ep:133, loss:0.00000, loss_test:0.01031, lr:5.65e-02, fs:0.94857 (r=0.954,p=0.943),  time:40.709, tt:5455.030\n",
      "Ep:134, loss:0.00000, loss_test:0.01034, lr:5.65e-02, fs:0.94857 (r=0.954,p=0.943),  time:40.706, tt:5495.361\n",
      "Ep:135, loss:0.00000, loss_test:0.01035, lr:5.65e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.685, tt:5533.133\n",
      "Ep:136, loss:0.00000, loss_test:0.01036, lr:5.65e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.681, tt:5573.274\n",
      "Ep:137, loss:0.00000, loss_test:0.01038, lr:5.65e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.681, tt:5613.950\n",
      "Ep:138, loss:0.00000, loss_test:0.01041, lr:5.59e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.676, tt:5653.961\n",
      "Ep:139, loss:0.00000, loss_test:0.01043, lr:5.54e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.677, tt:5694.813\n",
      "Ep:140, loss:0.00000, loss_test:0.01047, lr:5.48e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.681, tt:5736.041\n",
      "Ep:141, loss:0.00000, loss_test:0.01049, lr:5.43e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.668, tt:5774.907\n",
      "Ep:142, loss:0.00000, loss_test:0.01052, lr:5.37e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.675, tt:5816.482\n",
      "Ep:143, loss:0.00000, loss_test:0.01057, lr:5.32e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.677, tt:5857.477\n",
      "Ep:144, loss:0.00000, loss_test:0.01060, lr:5.27e-02, fs:0.93642 (r=0.931,p=0.942),  time:40.683, tt:5898.975\n",
      "Ep:145, loss:0.00000, loss_test:0.01057, lr:5.21e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.671, tt:5937.971\n",
      "Ep:146, loss:0.00000, loss_test:0.01060, lr:5.16e-02, fs:0.93642 (r=0.931,p=0.942),  time:40.680, tt:5979.910\n",
      "Ep:147, loss:0.00000, loss_test:0.01059, lr:5.11e-02, fs:0.93642 (r=0.931,p=0.942),  time:40.682, tt:6020.895\n",
      "Ep:148, loss:0.00000, loss_test:0.01062, lr:5.06e-02, fs:0.94253 (r=0.943,p=0.943),  time:40.718, tt:6066.984\n",
      "Ep:149, loss:0.00000, loss_test:0.01067, lr:5.01e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.720, tt:6108.022\n",
      "Ep:150, loss:0.00000, loss_test:0.01067, lr:4.96e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.715, tt:6147.993\n",
      "Ep:151, loss:0.00000, loss_test:0.01069, lr:4.91e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.730, tt:6190.929\n",
      "Ep:152, loss:0.00000, loss_test:0.01073, lr:4.86e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.731, tt:6231.896\n",
      "Ep:153, loss:0.00000, loss_test:0.01075, lr:4.81e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.721, tt:6271.006\n",
      "Ep:154, loss:0.00000, loss_test:0.01078, lr:4.76e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.729, tt:6312.990\n",
      "Ep:155, loss:0.00000, loss_test:0.01080, lr:4.71e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.735, tt:6354.620\n",
      "Ep:156, loss:0.00000, loss_test:0.01081, lr:4.67e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.743, tt:6396.626\n",
      "Ep:157, loss:0.00000, loss_test:0.01082, lr:4.62e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.746, tt:6437.797\n",
      "Ep:158, loss:0.00000, loss_test:0.01084, lr:4.57e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.749, tt:6479.164\n",
      "Ep:159, loss:0.00000, loss_test:0.01087, lr:4.53e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.755, tt:6520.811\n",
      "Ep:160, loss:0.00000, loss_test:0.01090, lr:4.48e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.761, tt:6562.574\n",
      "Ep:161, loss:0.00000, loss_test:0.01090, lr:4.44e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.770, tt:6604.786\n",
      "Ep:162, loss:0.00000, loss_test:0.01091, lr:4.39e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.781, tt:6647.353\n",
      "Ep:163, loss:0.00000, loss_test:0.01093, lr:4.35e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.784, tt:6688.595\n",
      "Ep:164, loss:0.00000, loss_test:0.01094, lr:4.31e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.784, tt:6729.441\n",
      "Ep:165, loss:0.00000, loss_test:0.01096, lr:4.26e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.782, tt:6769.740\n",
      "Ep:166, loss:0.00000, loss_test:0.01098, lr:4.22e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.772, tt:6808.854\n",
      "Ep:167, loss:0.00000, loss_test:0.01100, lr:4.18e-02, fs:0.93023 (r=0.920,p=0.941),  time:40.775, tt:6850.243\n",
      "Ep:168, loss:0.00000, loss_test:0.01102, lr:4.14e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.785, tt:6892.649\n",
      "Ep:169, loss:0.00000, loss_test:0.01103, lr:4.10e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.826, tt:6940.481\n",
      "Ep:170, loss:0.00000, loss_test:0.01106, lr:4.05e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.834, tt:6982.549\n",
      "Ep:171, loss:0.00000, loss_test:0.01107, lr:4.01e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.837, tt:7023.998\n",
      "Ep:172, loss:0.00000, loss_test:0.01109, lr:3.97e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.837, tt:7064.716\n",
      "Ep:173, loss:0.00000, loss_test:0.01111, lr:3.93e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.839, tt:7105.968\n",
      "Ep:174, loss:0.00000, loss_test:0.01111, lr:3.89e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.842, tt:7147.354\n",
      "Ep:175, loss:0.00000, loss_test:0.01114, lr:3.86e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.840, tt:7187.793\n",
      "Ep:176, loss:0.00000, loss_test:0.01117, lr:3.82e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.833, tt:7227.390\n",
      "Ep:177, loss:0.00000, loss_test:0.01116, lr:3.78e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.830, tt:7267.686\n",
      "Ep:178, loss:0.00000, loss_test:0.01116, lr:3.74e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.824, tt:7307.440\n",
      "Ep:179, loss:0.00000, loss_test:0.01119, lr:3.70e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.806, tt:7345.146\n",
      "Ep:180, loss:0.00000, loss_test:0.01118, lr:3.67e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.807, tt:7386.105\n",
      "Ep:181, loss:0.00000, loss_test:0.01119, lr:3.63e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.808, tt:7427.084\n",
      "Ep:182, loss:0.00000, loss_test:0.01121, lr:3.59e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.802, tt:7466.704\n",
      "Ep:183, loss:0.00000, loss_test:0.01122, lr:3.56e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.803, tt:7507.775\n",
      "Ep:184, loss:0.00000, loss_test:0.01123, lr:3.52e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.804, tt:7548.706\n",
      "Ep:185, loss:0.00000, loss_test:0.01126, lr:3.49e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.802, tt:7589.206\n",
      "Ep:186, loss:0.00000, loss_test:0.01125, lr:3.45e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.804, tt:7630.268\n",
      "Ep:187, loss:0.00000, loss_test:0.01127, lr:3.42e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.803, tt:7670.936\n",
      "Ep:188, loss:0.00000, loss_test:0.01130, lr:3.38e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.802, tt:7711.539\n",
      "Ep:189, loss:0.00000, loss_test:0.01129, lr:3.35e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.796, tt:7751.263\n",
      "Ep:190, loss:0.00000, loss_test:0.01129, lr:3.32e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.790, tt:7790.830\n",
      "Ep:191, loss:0.00000, loss_test:0.01132, lr:3.28e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.783, tt:7830.320\n",
      "Ep:192, loss:0.00000, loss_test:0.01133, lr:3.25e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.774, tt:7869.299\n",
      "Ep:193, loss:0.00000, loss_test:0.01134, lr:3.22e-02, fs:0.93567 (r=0.920,p=0.952),  time:40.762, tt:7907.854\n",
      "Ep:194, loss:0.00000, loss_test:0.01135, lr:3.19e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.758, tt:7947.806\n",
      "Ep:195, loss:0.00000, loss_test:0.01136, lr:3.15e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.742, tt:7985.388\n",
      "Ep:196, loss:0.00000, loss_test:0.01138, lr:3.12e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.738, tt:8025.479\n",
      "Ep:197, loss:0.00000, loss_test:0.01137, lr:3.09e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.741, tt:8066.702\n",
      "Ep:198, loss:0.00000, loss_test:0.01139, lr:3.06e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.727, tt:8104.609\n",
      "Ep:199, loss:0.00000, loss_test:0.01141, lr:3.03e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.727, tt:8145.337\n",
      "Ep:200, loss:0.00000, loss_test:0.01141, lr:3.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.712, tt:8183.200\n",
      "Ep:201, loss:0.00000, loss_test:0.01142, lr:2.97e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.709, tt:8223.122\n",
      "Ep:202, loss:0.00000, loss_test:0.01144, lr:2.94e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.702, tt:8262.410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.01143, lr:2.91e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.700, tt:8302.784\n",
      "Ep:204, loss:0.00000, loss_test:0.01144, lr:2.88e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.691, tt:8341.731\n",
      "Ep:205, loss:0.00000, loss_test:0.01145, lr:2.85e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.688, tt:8381.737\n",
      "Ep:206, loss:0.00000, loss_test:0.01145, lr:2.82e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.681, tt:8421.020\n",
      "Ep:207, loss:0.00000, loss_test:0.01145, lr:2.80e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.676, tt:8460.651\n",
      "Ep:208, loss:0.00000, loss_test:0.01146, lr:2.77e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.667, tt:8499.312\n",
      "Ep:209, loss:0.00000, loss_test:0.01148, lr:2.74e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.667, tt:8540.132\n",
      "Ep:210, loss:0.00000, loss_test:0.01149, lr:2.71e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.643, tt:8575.606\n",
      "Ep:211, loss:0.00000, loss_test:0.01149, lr:2.69e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.627, tt:8612.974\n",
      "Ep:212, loss:0.00000, loss_test:0.01150, lr:2.66e-02, fs:0.94118 (r=0.920,p=0.964),  time:40.593, tt:8646.344\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13894, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.247, tt:32.247\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13669, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.874, tt:61.748\n",
      "Ep:2, loss:0.00028, loss_test:0.13258, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:34.269, tt:102.807\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12525, lr:1.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:36.193, tt:144.772\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11238, lr:1.00e-02, fs:0.68644 (r=0.931,p=0.544),  time:37.216, tt:186.082\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.09583, lr:1.00e-02, fs:0.77249 (r=0.839,p=0.716),  time:37.709, tt:226.255\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.09398, lr:1.00e-02, fs:0.76023 (r=0.747,p=0.774),  time:38.219, tt:267.531\n",
      "Ep:7, loss:0.00022, loss_test:0.09119, lr:1.00e-02, fs:0.78212 (r=0.805,p=0.761),  time:38.654, tt:309.231\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.08927, lr:1.00e-02, fs:0.78495 (r=0.839,p=0.737),  time:39.053, tt:351.475\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.08522, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:39.171, tt:391.707\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.08362, lr:1.00e-02, fs:0.77778 (r=0.805,p=0.753),  time:39.685, tt:436.536\n",
      "Ep:11, loss:0.00019, loss_test:0.08229, lr:1.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:39.713, tt:476.552\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.07969, lr:1.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:39.814, tt:517.584\n",
      "Ep:13, loss:0.00017, loss_test:0.07748, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:40.310, tt:564.339\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.07570, lr:1.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:40.366, tt:605.486\n",
      "Ep:15, loss:0.00016, loss_test:0.07387, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:40.437, tt:646.989\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.07210, lr:1.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:40.453, tt:687.703\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.06937, lr:1.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:40.390, tt:727.015\n",
      "Ep:18, loss:0.00014, loss_test:0.06778, lr:1.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:40.418, tt:767.941\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.06593, lr:1.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:40.536, tt:810.723\n",
      "Ep:20, loss:0.00013, loss_test:0.06434, lr:1.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:40.548, tt:851.514\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.06361, lr:1.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:40.558, tt:892.287\n",
      "Ep:22, loss:0.00012, loss_test:0.06228, lr:1.00e-02, fs:0.87568 (r=0.931,p=0.827),  time:40.577, tt:933.261\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.06180, lr:1.00e-02, fs:0.88136 (r=0.897,p=0.867),  time:40.542, tt:973.011\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.05921, lr:1.00e-02, fs:0.89840 (r=0.966,p=0.840),  time:40.474, tt:1011.854\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.05986, lr:1.00e-02, fs:0.88268 (r=0.908,p=0.859),  time:40.352, tt:1049.144\n",
      "Ep:26, loss:0.00010, loss_test:0.05704, lr:1.00e-02, fs:0.91979 (r=0.989,p=0.860),  time:40.394, tt:1090.628\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.05745, lr:1.00e-02, fs:0.91209 (r=0.954,p=0.874),  time:40.419, tt:1131.719\n",
      "Ep:28, loss:0.00010, loss_test:0.05661, lr:1.00e-02, fs:0.91398 (r=0.977,p=0.859),  time:40.439, tt:1172.727\n",
      "Ep:29, loss:0.00009, loss_test:0.05604, lr:1.00e-02, fs:0.92135 (r=0.943,p=0.901),  time:40.422, tt:1212.670\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.05526, lr:1.00e-02, fs:0.91209 (r=0.954,p=0.874),  time:40.435, tt:1253.480\n",
      "Ep:31, loss:0.00009, loss_test:0.05284, lr:1.00e-02, fs:0.92222 (r=0.954,p=0.892),  time:40.449, tt:1294.357\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.05449, lr:1.00e-02, fs:0.91525 (r=0.931,p=0.900),  time:40.492, tt:1336.229\n",
      "Ep:33, loss:0.00008, loss_test:0.05335, lr:1.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.615, tt:1380.896\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.05365, lr:1.00e-02, fs:0.92045 (r=0.931,p=0.910),  time:40.699, tt:1424.480\n",
      "Ep:35, loss:0.00007, loss_test:0.05291, lr:1.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:40.723, tt:1466.035\n",
      "Ep:36, loss:0.00007, loss_test:0.05300, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:40.767, tt:1508.379\n",
      "Ep:37, loss:0.00007, loss_test:0.05312, lr:1.00e-02, fs:0.92737 (r=0.954,p=0.902),  time:40.765, tt:1549.082\n",
      "Ep:38, loss:0.00006, loss_test:0.05301, lr:1.00e-02, fs:0.92571 (r=0.931,p=0.920),  time:40.822, tt:1592.053\n",
      "Ep:39, loss:0.00006, loss_test:0.05296, lr:1.00e-02, fs:0.93785 (r=0.954,p=0.922),  time:40.846, tt:1633.831\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.05264, lr:1.00e-02, fs:0.91860 (r=0.908,p=0.929),  time:40.913, tt:1677.424\n",
      "Ep:41, loss:0.00006, loss_test:0.05212, lr:1.00e-02, fs:0.93333 (r=0.966,p=0.903),  time:40.902, tt:1717.892\n",
      "Ep:42, loss:0.00005, loss_test:0.05295, lr:1.00e-02, fs:0.89941 (r=0.874,p=0.927),  time:40.915, tt:1759.343\n",
      "Ep:43, loss:0.00005, loss_test:0.05339, lr:1.00e-02, fs:0.91329 (r=0.908,p=0.919),  time:40.944, tt:1801.550\n",
      "Ep:44, loss:0.00005, loss_test:0.05142, lr:1.00e-02, fs:0.94382 (r=0.966,p=0.923),  time:41.060, tt:1847.717\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.05243, lr:1.00e-02, fs:0.90588 (r=0.885,p=0.928),  time:41.102, tt:1890.692\n",
      "Ep:46, loss:0.00004, loss_test:0.05178, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:41.154, tt:1934.216\n",
      "Ep:47, loss:0.00004, loss_test:0.05045, lr:1.00e-02, fs:0.92571 (r=0.931,p=0.920),  time:41.190, tt:1977.117\n",
      "Ep:48, loss:0.00004, loss_test:0.04925, lr:1.00e-02, fs:0.96089 (r=0.989,p=0.935),  time:41.227, tt:2020.109\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.05014, lr:1.00e-02, fs:0.94253 (r=0.943,p=0.943),  time:41.326, tt:2066.284\n",
      "Ep:50, loss:0.00004, loss_test:0.04885, lr:1.00e-02, fs:0.96089 (r=0.989,p=0.935),  time:41.334, tt:2108.055\n",
      "Ep:51, loss:0.00003, loss_test:0.04991, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:41.344, tt:2149.908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00003, loss_test:0.04729, lr:1.00e-02, fs:0.93714 (r=0.943,p=0.932),  time:41.375, tt:2192.859\n",
      "Ep:53, loss:0.00003, loss_test:0.04928, lr:1.00e-02, fs:0.90476 (r=0.874,p=0.938),  time:41.438, tt:2237.660\n",
      "Ep:54, loss:0.00003, loss_test:0.05051, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:41.428, tt:2278.518\n",
      "Ep:55, loss:0.00003, loss_test:0.04686, lr:1.00e-02, fs:0.96667 (r=1.000,p=0.935),  time:41.421, tt:2319.573\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.04979, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:41.432, tt:2361.637\n",
      "Ep:57, loss:0.00003, loss_test:0.05003, lr:1.00e-02, fs:0.88199 (r=0.816,p=0.959),  time:41.430, tt:2402.968\n",
      "Ep:58, loss:0.00003, loss_test:0.04808, lr:1.00e-02, fs:0.96629 (r=0.989,p=0.945),  time:41.444, tt:2445.206\n",
      "Ep:59, loss:0.00003, loss_test:0.04883, lr:1.00e-02, fs:0.89571 (r=0.839,p=0.961),  time:41.437, tt:2486.246\n",
      "Ep:60, loss:0.00002, loss_test:0.04841, lr:1.00e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.475, tt:2529.981\n",
      "Ep:61, loss:0.00002, loss_test:0.04614, lr:1.00e-02, fs:0.89571 (r=0.839,p=0.961),  time:41.440, tt:2569.294\n",
      "Ep:62, loss:0.00002, loss_test:0.04701, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.439, tt:2610.668\n",
      "Ep:63, loss:0.00002, loss_test:0.04902, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.483, tt:2654.928\n",
      "Ep:64, loss:0.00002, loss_test:0.04673, lr:1.00e-02, fs:0.87500 (r=0.805,p=0.959),  time:41.460, tt:2694.893\n",
      "Ep:65, loss:0.00002, loss_test:0.04658, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.487, tt:2738.156\n",
      "Ep:66, loss:0.00002, loss_test:0.04631, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:41.483, tt:2779.378\n",
      "Ep:67, loss:0.00002, loss_test:0.04631, lr:9.90e-03, fs:0.86792 (r=0.793,p=0.958),  time:41.510, tt:2822.699\n",
      "Ep:68, loss:0.00002, loss_test:0.04724, lr:9.80e-03, fs:0.87500 (r=0.805,p=0.959),  time:41.530, tt:2865.582\n",
      "Ep:69, loss:0.00002, loss_test:0.04895, lr:9.70e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.557, tt:2909.001\n",
      "Ep:70, loss:0.00002, loss_test:0.04643, lr:9.61e-03, fs:0.90909 (r=0.862,p=0.962),  time:41.565, tt:2951.127\n",
      "Ep:71, loss:0.00002, loss_test:0.05140, lr:9.51e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.577, tt:2993.571\n",
      "Ep:72, loss:0.00002, loss_test:0.04743, lr:9.41e-03, fs:0.86792 (r=0.793,p=0.958),  time:41.620, tt:3038.223\n",
      "Ep:73, loss:0.00001, loss_test:0.04789, lr:9.32e-03, fs:0.88199 (r=0.816,p=0.959),  time:41.649, tt:3082.019\n",
      "Ep:74, loss:0.00001, loss_test:0.04986, lr:9.23e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.682, tt:3126.135\n",
      "Ep:75, loss:0.00001, loss_test:0.04814, lr:9.14e-03, fs:0.87500 (r=0.805,p=0.959),  time:41.702, tt:3169.323\n",
      "Ep:76, loss:0.00001, loss_test:0.04920, lr:9.04e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.723, tt:3212.688\n",
      "Ep:77, loss:0.00001, loss_test:0.05004, lr:8.95e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.770, tt:3258.097\n",
      "Ep:78, loss:0.00001, loss_test:0.04925, lr:8.86e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.811, tt:3303.072\n",
      "Ep:79, loss:0.00001, loss_test:0.04959, lr:8.78e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.833, tt:3346.647\n",
      "Ep:80, loss:0.00001, loss_test:0.04940, lr:8.69e-03, fs:0.90244 (r=0.851,p=0.961),  time:41.871, tt:3391.558\n",
      "Ep:81, loss:0.00001, loss_test:0.05076, lr:8.60e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.902, tt:3435.987\n",
      "Ep:82, loss:0.00001, loss_test:0.04901, lr:8.51e-03, fs:0.88889 (r=0.828,p=0.960),  time:41.939, tt:3480.914\n",
      "Ep:83, loss:0.00001, loss_test:0.04977, lr:8.43e-03, fs:0.90909 (r=0.862,p=0.962),  time:41.982, tt:3526.450\n",
      "Ep:84, loss:0.00001, loss_test:0.04941, lr:8.35e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.995, tt:3569.581\n",
      "Ep:85, loss:0.00001, loss_test:0.04804, lr:8.26e-03, fs:0.90909 (r=0.862,p=0.962),  time:42.027, tt:3614.359\n",
      "Ep:86, loss:0.00001, loss_test:0.05086, lr:8.18e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.036, tt:3657.109\n",
      "Ep:87, loss:0.00001, loss_test:0.04876, lr:8.10e-03, fs:0.88889 (r=0.828,p=0.960),  time:42.066, tt:3701.848\n",
      "Ep:88, loss:0.00001, loss_test:0.04992, lr:8.02e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.102, tt:3747.107\n",
      "Ep:89, loss:0.00001, loss_test:0.04963, lr:7.94e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.145, tt:3793.021\n",
      "Ep:90, loss:0.00001, loss_test:0.04697, lr:7.86e-03, fs:0.90909 (r=0.862,p=0.962),  time:42.169, tt:3837.339\n",
      "Ep:91, loss:0.00001, loss_test:0.05371, lr:7.78e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.228, tt:3884.968\n",
      "Ep:92, loss:0.00001, loss_test:0.04917, lr:7.70e-03, fs:0.90909 (r=0.862,p=0.962),  time:42.245, tt:3928.797\n",
      "Ep:93, loss:0.00001, loss_test:0.05169, lr:7.62e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.274, tt:3973.717\n",
      "Ep:94, loss:0.00001, loss_test:0.05107, lr:7.55e-03, fs:0.88199 (r=0.816,p=0.959),  time:42.259, tt:4014.568\n",
      "Ep:95, loss:0.00001, loss_test:0.05068, lr:7.47e-03, fs:0.90909 (r=0.862,p=0.962),  time:42.251, tt:4056.134\n",
      "Ep:96, loss:0.00001, loss_test:0.05189, lr:7.40e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.280, tt:4101.116\n",
      "Ep:97, loss:0.00001, loss_test:0.05174, lr:7.32e-03, fs:0.90244 (r=0.851,p=0.961),  time:42.350, tt:4150.278\n",
      "Ep:98, loss:0.00001, loss_test:0.05168, lr:7.25e-03, fs:0.87500 (r=0.805,p=0.959),  time:42.350, tt:4192.665\n",
      "Ep:99, loss:0.00001, loss_test:0.04969, lr:7.18e-03, fs:0.86792 (r=0.793,p=0.958),  time:42.341, tt:4234.080\n",
      "Ep:100, loss:0.00001, loss_test:0.05141, lr:7.11e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.361, tt:4278.499\n",
      "Ep:101, loss:0.00001, loss_test:0.05193, lr:7.03e-03, fs:0.88889 (r=0.828,p=0.960),  time:42.365, tt:4321.210\n",
      "Ep:102, loss:0.00001, loss_test:0.05120, lr:6.96e-03, fs:0.86792 (r=0.793,p=0.958),  time:42.371, tt:4364.222\n",
      "Ep:103, loss:0.00001, loss_test:0.05222, lr:6.89e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.373, tt:4406.765\n",
      "Ep:104, loss:0.00001, loss_test:0.05275, lr:6.83e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.365, tt:4448.312\n",
      "Ep:105, loss:0.00001, loss_test:0.05248, lr:6.76e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.359, tt:4490.092\n",
      "Ep:106, loss:0.00001, loss_test:0.05214, lr:6.69e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.359, tt:4532.384\n",
      "Ep:107, loss:0.00001, loss_test:0.05318, lr:6.62e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.338, tt:4572.554\n",
      "Ep:108, loss:0.00001, loss_test:0.05352, lr:6.56e-03, fs:0.86792 (r=0.793,p=0.958),  time:42.334, tt:4614.365\n",
      "Ep:109, loss:0.00001, loss_test:0.05262, lr:6.49e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.332, tt:4656.472\n",
      "Ep:110, loss:0.00001, loss_test:0.05347, lr:6.43e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.325, tt:4698.019\n",
      "Ep:111, loss:0.00000, loss_test:0.05382, lr:6.36e-03, fs:0.86792 (r=0.793,p=0.958),  time:42.314, tt:4739.174\n",
      "Ep:112, loss:0.00000, loss_test:0.05346, lr:6.30e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.300, tt:4779.885\n",
      "Ep:113, loss:0.00000, loss_test:0.05419, lr:6.24e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.294, tt:4821.560\n",
      "Ep:114, loss:0.00000, loss_test:0.05507, lr:6.17e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.282, tt:4862.418\n",
      "Ep:115, loss:0.00000, loss_test:0.05475, lr:6.11e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.287, tt:4905.259\n",
      "Ep:116, loss:0.00000, loss_test:0.05474, lr:6.05e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.287, tt:4947.614\n",
      "Ep:117, loss:0.00000, loss_test:0.05491, lr:5.99e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.345, tt:4996.757\n",
      "Ep:118, loss:0.00000, loss_test:0.05396, lr:5.93e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.348, tt:5039.456\n",
      "Ep:119, loss:0.00000, loss_test:0.05507, lr:5.87e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.339, tt:5080.679\n",
      "Ep:120, loss:0.00000, loss_test:0.05521, lr:5.81e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.337, tt:5122.797\n",
      "Ep:121, loss:0.00000, loss_test:0.05611, lr:5.75e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.345, tt:5166.129\n",
      "Ep:122, loss:0.00000, loss_test:0.05620, lr:5.70e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.330, tt:5206.576\n",
      "Ep:123, loss:0.00000, loss_test:0.05525, lr:5.64e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.320, tt:5247.677\n",
      "Ep:124, loss:0.00000, loss_test:0.05580, lr:5.58e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.317, tt:5289.599\n",
      "Ep:125, loss:0.00000, loss_test:0.05658, lr:5.53e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.320, tt:5332.274\n",
      "Ep:126, loss:0.00000, loss_test:0.05594, lr:5.47e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.301, tt:5372.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00000, loss_test:0.05548, lr:5.42e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.292, tt:5413.340\n",
      "Ep:128, loss:0.00000, loss_test:0.05588, lr:5.36e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.280, tt:5454.120\n",
      "Ep:129, loss:0.00000, loss_test:0.05633, lr:5.31e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.258, tt:5493.558\n",
      "Ep:130, loss:0.00000, loss_test:0.05625, lr:5.26e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.259, tt:5535.926\n",
      "Ep:131, loss:0.00000, loss_test:0.05679, lr:5.20e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.257, tt:5577.878\n",
      "Ep:132, loss:0.00000, loss_test:0.05624, lr:5.15e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.240, tt:5617.908\n",
      "Ep:133, loss:0.00000, loss_test:0.05579, lr:5.10e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.246, tt:5660.922\n",
      "Ep:134, loss:0.00000, loss_test:0.05698, lr:5.05e-03, fs:0.85350 (r=0.770,p=0.957),  time:42.244, tt:5702.888\n",
      "Ep:135, loss:0.00000, loss_test:0.05660, lr:5.00e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.236, tt:5744.106\n",
      "Ep:136, loss:0.00000, loss_test:0.05666, lr:4.95e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.213, tt:5783.241\n",
      "Ep:137, loss:0.00000, loss_test:0.05651, lr:4.90e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.206, tt:5824.437\n",
      "Ep:138, loss:0.00000, loss_test:0.05663, lr:4.85e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.199, tt:5865.703\n",
      "Ep:139, loss:0.00000, loss_test:0.05688, lr:4.80e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.195, tt:5907.253\n",
      "Ep:140, loss:0.00000, loss_test:0.05663, lr:4.75e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.196, tt:5949.589\n",
      "Ep:141, loss:0.00000, loss_test:0.05655, lr:4.71e-03, fs:0.87500 (r=0.805,p=0.959),  time:42.197, tt:5991.903\n",
      "Ep:142, loss:0.00000, loss_test:0.05803, lr:4.66e-03, fs:0.85161 (r=0.759,p=0.971),  time:42.190, tt:6033.150\n",
      "Ep:143, loss:0.00000, loss_test:0.05734, lr:4.61e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.181, tt:6074.062\n",
      "Ep:144, loss:0.00000, loss_test:0.05715, lr:4.57e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.158, tt:6112.861\n",
      "Ep:145, loss:0.00000, loss_test:0.05853, lr:4.52e-03, fs:0.82119 (r=0.713,p=0.969),  time:42.136, tt:6151.869\n",
      "Ep:146, loss:0.00000, loss_test:0.05786, lr:4.48e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.132, tt:6193.358\n",
      "Ep:147, loss:0.00000, loss_test:0.05690, lr:4.43e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.136, tt:6236.169\n",
      "Ep:148, loss:0.00000, loss_test:0.05765, lr:4.39e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.134, tt:6278.036\n",
      "Ep:149, loss:0.00000, loss_test:0.05789, lr:4.34e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.132, tt:6319.776\n",
      "Ep:150, loss:0.00000, loss_test:0.05710, lr:4.30e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.142, tt:6363.367\n",
      "Ep:151, loss:0.00000, loss_test:0.05772, lr:4.26e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.137, tt:6404.828\n",
      "Ep:152, loss:0.00000, loss_test:0.05842, lr:4.21e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.147, tt:6448.502\n",
      "Ep:153, loss:0.00000, loss_test:0.05776, lr:4.17e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.135, tt:6488.823\n",
      "Ep:154, loss:0.00000, loss_test:0.05768, lr:4.13e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.137, tt:6531.199\n",
      "Ep:155, loss:0.00000, loss_test:0.05837, lr:4.09e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.134, tt:6572.905\n",
      "Ep:156, loss:0.00000, loss_test:0.05754, lr:4.05e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.128, tt:6614.173\n",
      "Ep:157, loss:0.00000, loss_test:0.05725, lr:4.01e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.133, tt:6656.955\n",
      "Ep:158, loss:0.00000, loss_test:0.05861, lr:3.97e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.133, tt:6699.147\n",
      "Ep:159, loss:0.00000, loss_test:0.05837, lr:3.93e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.137, tt:6741.994\n",
      "Ep:160, loss:0.00000, loss_test:0.05781, lr:3.89e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.134, tt:6783.581\n",
      "Ep:161, loss:0.00000, loss_test:0.05836, lr:3.85e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.137, tt:6826.148\n",
      "Ep:162, loss:0.00000, loss_test:0.05857, lr:3.81e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.135, tt:6868.052\n",
      "Ep:163, loss:0.00000, loss_test:0.05797, lr:3.77e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.134, tt:6909.988\n",
      "Ep:164, loss:0.00000, loss_test:0.05781, lr:3.73e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.135, tt:6952.195\n",
      "Ep:165, loss:0.00000, loss_test:0.05859, lr:3.70e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.142, tt:6995.538\n",
      "Ep:166, loss:0.00000, loss_test:0.05862, lr:3.66e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.142, tt:7037.641\n",
      "Ep:167, loss:0.00000, loss_test:0.05785, lr:3.62e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.153, tt:7081.759\n",
      "Ep:168, loss:0.00000, loss_test:0.05834, lr:3.59e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.152, tt:7123.622\n",
      "Ep:169, loss:0.00000, loss_test:0.05838, lr:3.55e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.156, tt:7166.550\n",
      "Ep:170, loss:0.00000, loss_test:0.05792, lr:3.52e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.150, tt:7207.687\n",
      "Ep:171, loss:0.00000, loss_test:0.05842, lr:3.48e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.155, tt:7250.618\n",
      "Ep:172, loss:0.00000, loss_test:0.05917, lr:3.45e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.147, tt:7291.497\n",
      "Ep:173, loss:0.00000, loss_test:0.05844, lr:3.41e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.146, tt:7333.355\n",
      "Ep:174, loss:0.00000, loss_test:0.05837, lr:3.38e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.153, tt:7376.814\n",
      "Ep:175, loss:0.00000, loss_test:0.05844, lr:3.34e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.154, tt:7419.017\n",
      "Ep:176, loss:0.00000, loss_test:0.05850, lr:3.31e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.157, tt:7461.740\n",
      "Ep:177, loss:0.00000, loss_test:0.05915, lr:3.28e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.154, tt:7503.422\n",
      "Ep:178, loss:0.00000, loss_test:0.05897, lr:3.24e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.145, tt:7543.910\n",
      "Ep:179, loss:0.00000, loss_test:0.05863, lr:3.21e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.140, tt:7585.136\n",
      "Ep:180, loss:0.00000, loss_test:0.05862, lr:3.18e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.137, tt:7626.730\n",
      "Ep:181, loss:0.00000, loss_test:0.05879, lr:3.15e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.135, tt:7668.612\n",
      "Ep:182, loss:0.00000, loss_test:0.05868, lr:3.12e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.129, tt:7709.627\n",
      "Ep:183, loss:0.00000, loss_test:0.05899, lr:3.09e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.127, tt:7751.437\n",
      "Ep:184, loss:0.00000, loss_test:0.05939, lr:3.05e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.138, tt:7795.459\n",
      "Ep:185, loss:0.00000, loss_test:0.05922, lr:3.02e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.142, tt:7838.450\n",
      "Ep:186, loss:0.00000, loss_test:0.05874, lr:2.99e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.162, tt:7884.211\n",
      "Ep:187, loss:0.00000, loss_test:0.05907, lr:2.96e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.166, tt:7927.118\n",
      "Ep:188, loss:0.00000, loss_test:0.05914, lr:2.93e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.168, tt:7969.722\n",
      "Ep:189, loss:0.00000, loss_test:0.05894, lr:2.90e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.174, tt:8013.126\n",
      "Ep:190, loss:0.00000, loss_test:0.05916, lr:2.88e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.181, tt:8056.658\n",
      "Ep:191, loss:0.00000, loss_test:0.05938, lr:2.85e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.186, tt:8099.713\n",
      "Ep:192, loss:0.00000, loss_test:0.05912, lr:2.82e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.184, tt:8141.493\n",
      "Ep:193, loss:0.00000, loss_test:0.05903, lr:2.79e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.190, tt:8184.809\n",
      "Ep:194, loss:0.00000, loss_test:0.05926, lr:2.76e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.187, tt:8226.526\n",
      "Ep:195, loss:0.00000, loss_test:0.05923, lr:2.73e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.191, tt:8269.445\n",
      "Ep:196, loss:0.00000, loss_test:0.05917, lr:2.71e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.181, tt:8309.746\n",
      "Ep:197, loss:0.00000, loss_test:0.05924, lr:2.68e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.178, tt:8351.184\n",
      "Ep:198, loss:0.00000, loss_test:0.05968, lr:2.65e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.179, tt:8393.712\n",
      "Ep:199, loss:0.00000, loss_test:0.05937, lr:2.63e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.175, tt:8435.006\n",
      "Ep:200, loss:0.00000, loss_test:0.05891, lr:2.60e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.160, tt:8474.229\n",
      "Ep:201, loss:0.00000, loss_test:0.05928, lr:2.57e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.154, tt:8515.159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00000, loss_test:0.05933, lr:2.55e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.152, tt:8556.826\n",
      "Ep:203, loss:0.00000, loss_test:0.05897, lr:2.52e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.149, tt:8598.407\n",
      "Ep:204, loss:0.00000, loss_test:0.05926, lr:2.50e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.146, tt:8640.022\n",
      "Ep:205, loss:0.00000, loss_test:0.05940, lr:2.47e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.136, tt:8679.915\n",
      "Ep:206, loss:0.00000, loss_test:0.05903, lr:2.45e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.137, tt:8722.334\n",
      "Ep:207, loss:0.00000, loss_test:0.05941, lr:2.42e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.130, tt:8763.053\n",
      "Ep:208, loss:0.00000, loss_test:0.05946, lr:2.40e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.129, tt:8805.032\n",
      "Ep:209, loss:0.00000, loss_test:0.05910, lr:2.38e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.131, tt:8847.427\n",
      "Ep:210, loss:0.00000, loss_test:0.05932, lr:2.35e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.122, tt:8887.742\n",
      "Ep:211, loss:0.00000, loss_test:0.05976, lr:2.33e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.110, tt:8927.381\n",
      "Ep:212, loss:0.00000, loss_test:0.05965, lr:2.31e-03, fs:0.86076 (r=0.782,p=0.958),  time:42.089, tt:8964.932\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01888, lr:6.00e-02, fs:0.64629 (r=0.851,p=0.521),  time:27.379, tt:27.379\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02076, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:27.916, tt:55.832\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02132, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.995, tt:89.984\n",
      "Ep:3, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:32.588, tt:130.351\n",
      "Ep:4, loss:0.00004, loss_test:0.01820, lr:6.00e-02, fs:0.67984 (r=0.989,p=0.518),  time:33.668, tt:168.341\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01665, lr:6.00e-02, fs:0.69528 (r=0.931,p=0.555),  time:35.251, tt:211.508\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01590, lr:6.00e-02, fs:0.71154 (r=0.851,p=0.612),  time:35.985, tt:251.895\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01517, lr:6.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:36.521, tt:292.171\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01438, lr:6.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:37.239, tt:335.151\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01390, lr:6.00e-02, fs:0.79263 (r=0.989,p=0.662),  time:37.714, tt:377.140\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01356, lr:6.00e-02, fs:0.79817 (r=1.000,p=0.664),  time:38.182, tt:420.000\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01318, lr:6.00e-02, fs:0.80184 (r=1.000,p=0.669),  time:38.313, tt:459.757\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01279, lr:6.00e-02, fs:0.81308 (r=1.000,p=0.685),  time:38.503, tt:500.538\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01251, lr:6.00e-02, fs:0.81690 (r=1.000,p=0.690),  time:38.681, tt:541.530\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01230, lr:6.00e-02, fs:0.83254 (r=1.000,p=0.713),  time:38.765, tt:581.474\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01206, lr:6.00e-02, fs:0.82857 (r=1.000,p=0.707),  time:38.791, tt:620.659\n",
      "Ep:16, loss:0.00003, loss_test:0.01182, lr:6.00e-02, fs:0.83254 (r=1.000,p=0.713),  time:38.993, tt:662.885\n",
      "Ep:17, loss:0.00003, loss_test:0.01162, lr:6.00e-02, fs:0.83654 (r=1.000,p=0.719),  time:39.245, tt:706.405\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01144, lr:6.00e-02, fs:0.84878 (r=1.000,p=0.737),  time:39.330, tt:747.274\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01130, lr:6.00e-02, fs:0.84466 (r=1.000,p=0.731),  time:39.478, tt:789.554\n",
      "Ep:20, loss:0.00002, loss_test:0.01118, lr:6.00e-02, fs:0.84878 (r=1.000,p=0.737),  time:39.587, tt:831.325\n",
      "Ep:21, loss:0.00002, loss_test:0.01105, lr:6.00e-02, fs:0.85714 (r=1.000,p=0.750),  time:39.665, tt:872.624\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01092, lr:6.00e-02, fs:0.87000 (r=1.000,p=0.770),  time:39.771, tt:914.738\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01082, lr:6.00e-02, fs:0.87879 (r=1.000,p=0.784),  time:39.810, tt:955.451\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01070, lr:6.00e-02, fs:0.88325 (r=1.000,p=0.791),  time:39.965, tt:999.118\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01061, lr:6.00e-02, fs:0.88776 (r=1.000,p=0.798),  time:39.980, tt:1039.490\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01056, lr:6.00e-02, fs:0.89691 (r=1.000,p=0.813),  time:40.079, tt:1082.143\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01048, lr:6.00e-02, fs:0.89691 (r=1.000,p=0.813),  time:40.097, tt:1122.719\n",
      "Ep:28, loss:0.00002, loss_test:0.01040, lr:6.00e-02, fs:0.89691 (r=1.000,p=0.813),  time:40.124, tt:1163.606\n",
      "Ep:29, loss:0.00002, loss_test:0.01035, lr:6.00e-02, fs:0.90625 (r=1.000,p=0.829),  time:40.161, tt:1204.816\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01033, lr:6.00e-02, fs:0.90625 (r=1.000,p=0.829),  time:40.144, tt:1244.469\n",
      "Ep:31, loss:0.00002, loss_test:0.01024, lr:6.00e-02, fs:0.91099 (r=1.000,p=0.837),  time:40.146, tt:1284.660\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01020, lr:6.00e-02, fs:0.90155 (r=1.000,p=0.821),  time:40.156, tt:1325.150\n",
      "Ep:33, loss:0.00002, loss_test:0.01016, lr:6.00e-02, fs:0.91579 (r=1.000,p=0.845),  time:40.177, tt:1366.006\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01013, lr:6.00e-02, fs:0.91099 (r=1.000,p=0.837),  time:40.189, tt:1406.606\n",
      "Ep:35, loss:0.00002, loss_test:0.01009, lr:6.00e-02, fs:0.91579 (r=1.000,p=0.845),  time:40.181, tt:1446.525\n",
      "Ep:36, loss:0.00002, loss_test:0.01009, lr:6.00e-02, fs:0.91579 (r=1.000,p=0.845),  time:40.195, tt:1487.220\n",
      "Ep:37, loss:0.00002, loss_test:0.01003, lr:6.00e-02, fs:0.92553 (r=1.000,p=0.861),  time:40.191, tt:1527.251\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.00996, lr:6.00e-02, fs:0.92553 (r=1.000,p=0.861),  time:40.194, tt:1567.549\n",
      "Ep:39, loss:0.00002, loss_test:0.00993, lr:6.00e-02, fs:0.92553 (r=1.000,p=0.861),  time:40.193, tt:1607.700\n",
      "Ep:40, loss:0.00001, loss_test:0.00989, lr:6.00e-02, fs:0.92553 (r=1.000,p=0.861),  time:40.269, tt:1651.048\n",
      "Ep:41, loss:0.00001, loss_test:0.00987, lr:6.00e-02, fs:0.92553 (r=1.000,p=0.861),  time:40.308, tt:1692.920\n",
      "Ep:42, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.92063 (r=1.000,p=0.853),  time:40.318, tt:1733.691\n",
      "Ep:43, loss:0.00001, loss_test:0.00983, lr:6.00e-02, fs:0.92553 (r=1.000,p=0.861),  time:40.306, tt:1773.455\n",
      "Ep:44, loss:0.00001, loss_test:0.00984, lr:6.00e-02, fs:0.93048 (r=1.000,p=0.870),  time:40.284, tt:1812.773\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.00983, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.252, tt:1851.587\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.00981, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.231, tt:1890.866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00001, loss_test:0.00977, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.220, tt:1930.562\n",
      "Ep:48, loss:0.00001, loss_test:0.00980, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.171, tt:1968.401\n",
      "Ep:49, loss:0.00001, loss_test:0.00978, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.156, tt:2007.817\n",
      "Ep:50, loss:0.00001, loss_test:0.00979, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.114, tt:2045.836\n",
      "Ep:51, loss:0.00001, loss_test:0.00981, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.120, tt:2086.236\n",
      "Ep:52, loss:0.00001, loss_test:0.00980, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.088, tt:2124.660\n",
      "Ep:53, loss:0.00001, loss_test:0.00977, lr:6.00e-02, fs:0.93548 (r=1.000,p=0.879),  time:40.080, tt:2164.321\n",
      "Ep:54, loss:0.00001, loss_test:0.00976, lr:6.00e-02, fs:0.94054 (r=1.000,p=0.888),  time:40.021, tt:2201.172\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.00986, lr:6.00e-02, fs:0.94054 (r=1.000,p=0.888),  time:39.993, tt:2239.597\n",
      "Ep:56, loss:0.00001, loss_test:0.00987, lr:6.00e-02, fs:0.94054 (r=1.000,p=0.888),  time:39.991, tt:2279.480\n",
      "Ep:57, loss:0.00001, loss_test:0.00985, lr:6.00e-02, fs:0.94054 (r=1.000,p=0.888),  time:39.983, tt:2319.040\n",
      "Ep:58, loss:0.00001, loss_test:0.00987, lr:6.00e-02, fs:0.93478 (r=0.989,p=0.887),  time:39.984, tt:2359.047\n",
      "Ep:59, loss:0.00001, loss_test:0.01003, lr:6.00e-02, fs:0.93989 (r=0.989,p=0.896),  time:39.960, tt:2397.574\n",
      "Ep:60, loss:0.00001, loss_test:0.00998, lr:6.00e-02, fs:0.93989 (r=0.989,p=0.896),  time:39.943, tt:2436.505\n",
      "Ep:61, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.93923 (r=0.977,p=0.904),  time:39.927, tt:2475.491\n",
      "Ep:62, loss:0.00001, loss_test:0.01005, lr:6.00e-02, fs:0.92135 (r=0.943,p=0.901),  time:39.989, tt:2519.326\n",
      "Ep:63, loss:0.00001, loss_test:0.01004, lr:6.00e-02, fs:0.93333 (r=0.966,p=0.903),  time:40.004, tt:2560.281\n",
      "Ep:64, loss:0.00001, loss_test:0.01009, lr:6.00e-02, fs:0.92655 (r=0.943,p=0.911),  time:40.019, tt:2601.263\n",
      "Ep:65, loss:0.00001, loss_test:0.01008, lr:6.00e-02, fs:0.92655 (r=0.943,p=0.911),  time:40.018, tt:2641.212\n",
      "Ep:66, loss:0.00001, loss_test:0.01016, lr:5.94e-02, fs:0.92655 (r=0.943,p=0.911),  time:40.020, tt:2681.312\n",
      "Ep:67, loss:0.00001, loss_test:0.01020, lr:5.88e-02, fs:0.92655 (r=0.943,p=0.911),  time:40.021, tt:2721.440\n",
      "Ep:68, loss:0.00001, loss_test:0.01015, lr:5.82e-02, fs:0.92655 (r=0.943,p=0.911),  time:40.032, tt:2762.190\n",
      "Ep:69, loss:0.00001, loss_test:0.01030, lr:5.76e-02, fs:0.92655 (r=0.943,p=0.911),  time:40.063, tt:2804.421\n",
      "Ep:70, loss:0.00001, loss_test:0.01021, lr:5.71e-02, fs:0.92045 (r=0.931,p=0.910),  time:40.089, tt:2846.316\n",
      "Ep:71, loss:0.00001, loss_test:0.01023, lr:5.65e-02, fs:0.92045 (r=0.931,p=0.910),  time:40.120, tt:2888.607\n",
      "Ep:72, loss:0.00001, loss_test:0.01033, lr:5.59e-02, fs:0.91429 (r=0.920,p=0.909),  time:40.131, tt:2929.538\n",
      "Ep:73, loss:0.00001, loss_test:0.01030, lr:5.54e-02, fs:0.91329 (r=0.908,p=0.919),  time:40.137, tt:2970.136\n",
      "Ep:74, loss:0.00001, loss_test:0.01046, lr:5.48e-02, fs:0.88757 (r=0.862,p=0.915),  time:40.138, tt:3010.367\n",
      "Ep:75, loss:0.00001, loss_test:0.01036, lr:5.43e-02, fs:0.88757 (r=0.862,p=0.915),  time:40.173, tt:3053.165\n",
      "Ep:76, loss:0.00001, loss_test:0.01050, lr:5.37e-02, fs:0.89286 (r=0.862,p=0.926),  time:40.162, tt:3092.488\n",
      "Ep:77, loss:0.00001, loss_test:0.01053, lr:5.32e-02, fs:0.89820 (r=0.862,p=0.938),  time:40.180, tt:3134.056\n",
      "Ep:78, loss:0.00001, loss_test:0.01052, lr:5.27e-02, fs:0.89157 (r=0.851,p=0.937),  time:40.165, tt:3173.071\n",
      "Ep:79, loss:0.00001, loss_test:0.01056, lr:5.21e-02, fs:0.89157 (r=0.851,p=0.937),  time:40.163, tt:3213.078\n",
      "Ep:80, loss:0.00001, loss_test:0.01066, lr:5.16e-02, fs:0.87805 (r=0.828,p=0.935),  time:40.153, tt:3252.413\n",
      "Ep:81, loss:0.00001, loss_test:0.01067, lr:5.11e-02, fs:0.89157 (r=0.851,p=0.937),  time:40.127, tt:3290.402\n",
      "Ep:82, loss:0.00001, loss_test:0.01078, lr:5.06e-02, fs:0.86420 (r=0.805,p=0.933),  time:40.165, tt:3333.685\n",
      "Ep:83, loss:0.00001, loss_test:0.01076, lr:5.01e-02, fs:0.87117 (r=0.816,p=0.934),  time:40.192, tt:3376.088\n",
      "Ep:84, loss:0.00001, loss_test:0.01073, lr:4.96e-02, fs:0.87117 (r=0.816,p=0.934),  time:40.199, tt:3416.887\n",
      "Ep:85, loss:0.00001, loss_test:0.01087, lr:4.91e-02, fs:0.86420 (r=0.805,p=0.933),  time:40.193, tt:3456.563\n",
      "Ep:86, loss:0.00001, loss_test:0.01091, lr:4.86e-02, fs:0.86420 (r=0.805,p=0.933),  time:40.199, tt:3497.310\n",
      "Ep:87, loss:0.00001, loss_test:0.01085, lr:4.81e-02, fs:0.86420 (r=0.805,p=0.933),  time:40.194, tt:3537.080\n",
      "Ep:88, loss:0.00001, loss_test:0.01098, lr:4.76e-02, fs:0.83544 (r=0.759,p=0.930),  time:40.200, tt:3577.758\n",
      "Ep:89, loss:0.00001, loss_test:0.01102, lr:4.71e-02, fs:0.85000 (r=0.782,p=0.932),  time:40.204, tt:3618.353\n",
      "Ep:90, loss:0.00001, loss_test:0.01105, lr:4.67e-02, fs:0.82803 (r=0.747,p=0.929),  time:40.198, tt:3658.037\n",
      "Ep:91, loss:0.00001, loss_test:0.01103, lr:4.62e-02, fs:0.82803 (r=0.747,p=0.929),  time:40.186, tt:3697.068\n",
      "Ep:92, loss:0.00001, loss_test:0.01118, lr:4.57e-02, fs:0.83333 (r=0.747,p=0.942),  time:40.182, tt:3736.899\n",
      "Ep:93, loss:0.00001, loss_test:0.01117, lr:4.53e-02, fs:0.83333 (r=0.747,p=0.942),  time:40.202, tt:3778.999\n",
      "Ep:94, loss:0.00001, loss_test:0.01117, lr:4.48e-02, fs:0.83333 (r=0.747,p=0.942),  time:40.212, tt:3820.170\n",
      "Ep:95, loss:0.00001, loss_test:0.01133, lr:4.44e-02, fs:0.83333 (r=0.747,p=0.942),  time:40.207, tt:3859.880\n",
      "Ep:96, loss:0.00001, loss_test:0.01129, lr:4.39e-02, fs:0.83333 (r=0.747,p=0.942),  time:40.202, tt:3899.612\n",
      "Ep:97, loss:0.00001, loss_test:0.01139, lr:4.35e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.195, tt:3939.120\n",
      "Ep:98, loss:0.00001, loss_test:0.01146, lr:4.31e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.217, tt:3981.438\n",
      "Ep:99, loss:0.00000, loss_test:0.01142, lr:4.26e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.215, tt:4021.521\n",
      "Ep:100, loss:0.00000, loss_test:0.01154, lr:4.22e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.240, tt:4064.291\n",
      "Ep:101, loss:0.00000, loss_test:0.01154, lr:4.18e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.263, tt:4106.865\n",
      "Ep:102, loss:0.00000, loss_test:0.01158, lr:4.14e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.279, tt:4148.740\n",
      "Ep:103, loss:0.00000, loss_test:0.01168, lr:4.10e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.290, tt:4190.174\n",
      "Ep:104, loss:0.00000, loss_test:0.01162, lr:4.05e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.298, tt:4231.240\n",
      "Ep:105, loss:0.00000, loss_test:0.01171, lr:4.01e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.301, tt:4271.946\n",
      "Ep:106, loss:0.00000, loss_test:0.01177, lr:3.97e-02, fs:0.83871 (r=0.747,p=0.956),  time:40.306, tt:4312.761\n",
      "Ep:107, loss:0.00000, loss_test:0.01176, lr:3.93e-02, fs:0.83117 (r=0.736,p=0.955),  time:40.337, tt:4356.404\n",
      "Ep:108, loss:0.00000, loss_test:0.01182, lr:3.89e-02, fs:0.83117 (r=0.736,p=0.955),  time:40.351, tt:4398.219\n",
      "Ep:109, loss:0.00000, loss_test:0.01183, lr:3.86e-02, fs:0.83117 (r=0.736,p=0.955),  time:40.388, tt:4442.682\n",
      "Ep:110, loss:0.00000, loss_test:0.01194, lr:3.82e-02, fs:0.83117 (r=0.736,p=0.955),  time:40.401, tt:4484.516\n",
      "Ep:111, loss:0.00000, loss_test:0.01196, lr:3.78e-02, fs:0.83117 (r=0.736,p=0.955),  time:40.416, tt:4526.546\n",
      "Ep:112, loss:0.00000, loss_test:0.01195, lr:3.74e-02, fs:0.82353 (r=0.724,p=0.955),  time:40.461, tt:4572.140\n",
      "Ep:113, loss:0.00000, loss_test:0.01206, lr:3.70e-02, fs:0.82895 (r=0.724,p=0.969),  time:40.469, tt:4613.499\n",
      "Ep:114, loss:0.00000, loss_test:0.01213, lr:3.67e-02, fs:0.82895 (r=0.724,p=0.969),  time:40.462, tt:4653.174\n",
      "Ep:115, loss:0.00000, loss_test:0.01208, lr:3.63e-02, fs:0.82895 (r=0.724,p=0.969),  time:40.476, tt:4695.173\n",
      "Ep:116, loss:0.00000, loss_test:0.01218, lr:3.59e-02, fs:0.82119 (r=0.713,p=0.969),  time:40.487, tt:4737.015\n",
      "Ep:117, loss:0.00000, loss_test:0.01214, lr:3.56e-02, fs:0.82119 (r=0.713,p=0.969),  time:40.504, tt:4779.506\n",
      "Ep:118, loss:0.00000, loss_test:0.01221, lr:3.52e-02, fs:0.81333 (r=0.701,p=0.968),  time:40.518, tt:4821.673\n",
      "Ep:119, loss:0.00000, loss_test:0.01228, lr:3.49e-02, fs:0.81333 (r=0.701,p=0.968),  time:40.535, tt:4864.156\n",
      "Ep:120, loss:0.00000, loss_test:0.01231, lr:3.45e-02, fs:0.81333 (r=0.701,p=0.968),  time:40.544, tt:4905.820\n",
      "Ep:121, loss:0.00000, loss_test:0.01230, lr:3.42e-02, fs:0.81333 (r=0.701,p=0.968),  time:40.562, tt:4948.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00000, loss_test:0.01236, lr:3.38e-02, fs:0.81333 (r=0.701,p=0.968),  time:40.571, tt:4990.237\n",
      "Ep:123, loss:0.00000, loss_test:0.01239, lr:3.35e-02, fs:0.81333 (r=0.701,p=0.968),  time:40.569, tt:5030.568\n",
      "Ep:124, loss:0.00000, loss_test:0.01242, lr:3.32e-02, fs:0.80537 (r=0.690,p=0.968),  time:40.586, tt:5073.300\n",
      "Ep:125, loss:0.00000, loss_test:0.01246, lr:3.28e-02, fs:0.80537 (r=0.690,p=0.968),  time:40.596, tt:5115.150\n",
      "Ep:126, loss:0.00000, loss_test:0.01251, lr:3.25e-02, fs:0.80537 (r=0.690,p=0.968),  time:40.600, tt:5156.153\n",
      "Ep:127, loss:0.00000, loss_test:0.01252, lr:3.22e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.608, tt:5197.825\n",
      "Ep:128, loss:0.00000, loss_test:0.01257, lr:3.19e-02, fs:0.80537 (r=0.690,p=0.968),  time:40.598, tt:5237.127\n",
      "Ep:129, loss:0.00000, loss_test:0.01263, lr:3.15e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.582, tt:5275.681\n",
      "Ep:130, loss:0.00000, loss_test:0.01265, lr:3.12e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.591, tt:5317.384\n",
      "Ep:131, loss:0.00000, loss_test:0.01267, lr:3.09e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.577, tt:5356.218\n",
      "Ep:132, loss:0.00000, loss_test:0.01268, lr:3.06e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.569, tt:5395.689\n",
      "Ep:133, loss:0.00000, loss_test:0.01274, lr:3.03e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.572, tt:5436.692\n",
      "Ep:134, loss:0.00000, loss_test:0.01275, lr:3.00e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.553, tt:5474.698\n",
      "Ep:135, loss:0.00000, loss_test:0.01277, lr:2.97e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.543, tt:5513.785\n",
      "Ep:136, loss:0.00000, loss_test:0.01284, lr:2.94e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.530, tt:5552.600\n",
      "Ep:137, loss:0.00000, loss_test:0.01283, lr:2.91e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.516, tt:5591.235\n",
      "Ep:138, loss:0.00000, loss_test:0.01284, lr:2.88e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.512, tt:5631.119\n",
      "Ep:139, loss:0.00000, loss_test:0.01294, lr:2.85e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.506, tt:5670.811\n",
      "Ep:140, loss:0.00000, loss_test:0.01296, lr:2.82e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.500, tt:5710.463\n",
      "Ep:141, loss:0.00000, loss_test:0.01295, lr:2.80e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.503, tt:5751.359\n",
      "Ep:142, loss:0.00000, loss_test:0.01301, lr:2.77e-02, fs:0.79730 (r=0.678,p=0.967),  time:40.492, tt:5790.426\n",
      "Ep:143, loss:0.00000, loss_test:0.01305, lr:2.74e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.494, tt:5831.130\n",
      "Ep:144, loss:0.00000, loss_test:0.01305, lr:2.71e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.505, tt:5873.244\n",
      "Ep:145, loss:0.00000, loss_test:0.01306, lr:2.69e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.537, tt:5918.370\n",
      "Ep:146, loss:0.00000, loss_test:0.01314, lr:2.66e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.542, tt:5959.728\n",
      "Ep:147, loss:0.00000, loss_test:0.01315, lr:2.63e-02, fs:0.80272 (r=0.678,p=0.983),  time:40.543, tt:6000.295\n",
      "Ep:148, loss:0.00000, loss_test:0.01317, lr:2.61e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.527, tt:6038.477\n",
      "Ep:149, loss:0.00000, loss_test:0.01323, lr:2.58e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.534, tt:6080.135\n",
      "Ep:150, loss:0.00000, loss_test:0.01323, lr:2.55e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.542, tt:6121.894\n",
      "Ep:151, loss:0.00000, loss_test:0.01329, lr:2.53e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.539, tt:6161.910\n",
      "Ep:152, loss:0.00000, loss_test:0.01329, lr:2.50e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.538, tt:6202.376\n",
      "Ep:153, loss:0.00000, loss_test:0.01332, lr:2.48e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.538, tt:6242.860\n",
      "Ep:154, loss:0.00000, loss_test:0.01336, lr:2.45e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.543, tt:6284.146\n",
      "Ep:155, loss:0.00000, loss_test:0.01336, lr:2.43e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.543, tt:6324.728\n",
      "Ep:156, loss:0.00000, loss_test:0.01338, lr:2.40e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.554, tt:6366.979\n",
      "Ep:157, loss:0.00000, loss_test:0.01345, lr:2.38e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.557, tt:6408.046\n",
      "Ep:158, loss:0.00000, loss_test:0.01341, lr:2.36e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.562, tt:6449.312\n",
      "Ep:159, loss:0.00000, loss_test:0.01347, lr:2.33e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.566, tt:6490.604\n",
      "Ep:160, loss:0.00000, loss_test:0.01352, lr:2.31e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.577, tt:6532.955\n",
      "Ep:161, loss:0.00000, loss_test:0.01352, lr:2.29e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.589, tt:6575.348\n",
      "Ep:162, loss:0.00000, loss_test:0.01355, lr:2.26e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.604, tt:6618.510\n",
      "Ep:163, loss:0.00000, loss_test:0.01359, lr:2.24e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.600, tt:6658.356\n",
      "Ep:164, loss:0.00000, loss_test:0.01359, lr:2.22e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.594, tt:6697.971\n",
      "Ep:165, loss:0.00000, loss_test:0.01360, lr:2.20e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.601, tt:6739.754\n",
      "Ep:166, loss:0.00000, loss_test:0.01365, lr:2.17e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.625, tt:6784.392\n",
      "Ep:167, loss:0.00000, loss_test:0.01365, lr:2.15e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.627, tt:6825.355\n",
      "Ep:168, loss:0.00000, loss_test:0.01367, lr:2.13e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.617, tt:6864.338\n",
      "Ep:169, loss:0.00000, loss_test:0.01372, lr:2.11e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.624, tt:6906.024\n",
      "Ep:170, loss:0.00000, loss_test:0.01371, lr:2.09e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.620, tt:6946.008\n",
      "Ep:171, loss:0.00000, loss_test:0.01372, lr:2.07e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.614, tt:6985.654\n",
      "Ep:172, loss:0.00000, loss_test:0.01381, lr:2.05e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.615, tt:7026.438\n",
      "Ep:173, loss:0.00000, loss_test:0.01382, lr:2.03e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.624, tt:7068.630\n",
      "Ep:174, loss:0.00000, loss_test:0.01379, lr:2.01e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.623, tt:7109.047\n",
      "Ep:175, loss:0.00000, loss_test:0.01385, lr:1.99e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.610, tt:7147.378\n",
      "Ep:176, loss:0.00000, loss_test:0.01388, lr:1.97e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.601, tt:7186.396\n",
      "Ep:177, loss:0.00000, loss_test:0.01388, lr:1.95e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.582, tt:7223.635\n",
      "Ep:178, loss:0.00000, loss_test:0.01391, lr:1.93e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.581, tt:7263.938\n",
      "Ep:179, loss:0.00000, loss_test:0.01391, lr:1.91e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.567, tt:7302.043\n",
      "Ep:180, loss:0.00000, loss_test:0.01395, lr:1.89e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.566, tt:7342.368\n",
      "Ep:181, loss:0.00000, loss_test:0.01398, lr:1.87e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.574, tt:7384.439\n",
      "Ep:182, loss:0.00000, loss_test:0.01395, lr:1.85e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.553, tt:7421.240\n",
      "Ep:183, loss:0.00000, loss_test:0.01401, lr:1.83e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.554, tt:7462.018\n",
      "Ep:184, loss:0.00000, loss_test:0.01404, lr:1.81e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.553, tt:7502.362\n",
      "Ep:185, loss:0.00000, loss_test:0.01405, lr:1.80e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.544, tt:7541.113\n",
      "Ep:186, loss:0.00000, loss_test:0.01407, lr:1.78e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.530, tt:7579.184\n",
      "Ep:187, loss:0.00000, loss_test:0.01408, lr:1.76e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.535, tt:7620.616\n",
      "Ep:188, loss:0.00000, loss_test:0.01411, lr:1.74e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.529, tt:7660.016\n",
      "Ep:189, loss:0.00000, loss_test:0.01412, lr:1.73e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.533, tt:7701.311\n",
      "Ep:190, loss:0.00000, loss_test:0.01415, lr:1.71e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.525, tt:7740.317\n",
      "Ep:191, loss:0.00000, loss_test:0.01416, lr:1.69e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.521, tt:7780.045\n",
      "Ep:192, loss:0.00000, loss_test:0.01417, lr:1.67e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.525, tt:7821.415\n",
      "Ep:193, loss:0.00000, loss_test:0.01420, lr:1.66e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.535, tt:7863.834\n",
      "Ep:194, loss:0.00000, loss_test:0.01419, lr:1.64e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.532, tt:7903.732\n",
      "Ep:195, loss:0.00000, loss_test:0.01423, lr:1.62e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.535, tt:7944.852\n",
      "Ep:196, loss:0.00000, loss_test:0.01425, lr:1.61e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.522, tt:7982.859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.01424, lr:1.59e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.513, tt:8021.593\n",
      "Ep:198, loss:0.00000, loss_test:0.01426, lr:1.58e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.515, tt:8062.400\n",
      "Ep:199, loss:0.00000, loss_test:0.01432, lr:1.56e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.505, tt:8100.907\n",
      "Ep:200, loss:0.00000, loss_test:0.01430, lr:1.54e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.497, tt:8139.898\n",
      "Ep:201, loss:0.00000, loss_test:0.01433, lr:1.53e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.491, tt:8179.200\n",
      "Ep:202, loss:0.00000, loss_test:0.01435, lr:1.51e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.485, tt:8218.523\n",
      "Ep:203, loss:0.00000, loss_test:0.01434, lr:1.50e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.475, tt:8256.949\n",
      "Ep:204, loss:0.00000, loss_test:0.01437, lr:1.48e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.472, tt:8296.671\n",
      "Ep:205, loss:0.00000, loss_test:0.01437, lr:1.47e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.464, tt:8335.502\n",
      "Ep:206, loss:0.00000, loss_test:0.01439, lr:1.45e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.453, tt:8373.736\n",
      "Ep:207, loss:0.00000, loss_test:0.01442, lr:1.44e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.458, tt:8415.159\n",
      "Ep:208, loss:0.00000, loss_test:0.01443, lr:1.43e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.487, tt:8461.693\n",
      "Ep:209, loss:0.00000, loss_test:0.01443, lr:1.41e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.486, tt:8502.007\n",
      "Ep:210, loss:0.00000, loss_test:0.01446, lr:1.40e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.484, tt:8542.153\n",
      "Ep:211, loss:0.00000, loss_test:0.01448, lr:1.38e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.460, tt:8577.568\n",
      "Ep:212, loss:0.00000, loss_test:0.01447, lr:1.37e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.441, tt:8613.904\n",
      "Ep:213, loss:0.00000, loss_test:0.01449, lr:1.36e-02, fs:0.79452 (r=0.667,p=0.983),  time:40.411, tt:8647.884\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14282, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:36.324, tt:36.324\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14162, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:35.995, tt:71.989\n",
      "Ep:2, loss:0.00028, loss_test:0.13951, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:38.187, tt:114.560\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00028, loss_test:0.13610, lr:1.00e-02, fs:0.67451 (r=0.989,p=0.512),  time:38.634, tt:154.536\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13082, lr:1.00e-02, fs:0.65854 (r=0.931,p=0.509),  time:39.197, tt:195.984\n",
      "Ep:5, loss:0.00026, loss_test:0.12407, lr:1.00e-02, fs:0.66383 (r=0.897,p=0.527),  time:39.892, tt:239.351\n",
      "Ep:6, loss:0.00025, loss_test:0.11827, lr:1.00e-02, fs:0.65741 (r=0.816,p=0.550),  time:40.127, tt:280.890\n",
      "Ep:7, loss:0.00024, loss_test:0.11211, lr:1.00e-02, fs:0.67317 (r=0.793,p=0.585),  time:40.222, tt:321.778\n",
      "Ep:8, loss:0.00023, loss_test:0.10557, lr:1.00e-02, fs:0.71000 (r=0.816,p=0.628),  time:40.559, tt:365.029\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10254, lr:1.00e-02, fs:0.71717 (r=0.816,p=0.640),  time:40.447, tt:404.472\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.09942, lr:1.00e-02, fs:0.73404 (r=0.793,p=0.683),  time:40.669, tt:447.357\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09548, lr:1.00e-02, fs:0.75269 (r=0.805,p=0.707),  time:40.714, tt:488.564\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.08887, lr:1.00e-02, fs:0.78212 (r=0.805,p=0.761),  time:40.866, tt:531.261\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.08376, lr:1.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:40.984, tt:573.773\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.08109, lr:1.00e-02, fs:0.81720 (r=0.874,p=0.768),  time:41.113, tt:616.698\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.07754, lr:1.00e-02, fs:0.83243 (r=0.885,p=0.786),  time:41.055, tt:656.876\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.07544, lr:1.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:41.131, tt:699.220\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.07497, lr:1.00e-02, fs:0.86170 (r=0.931,p=0.802),  time:41.198, tt:741.556\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.07185, lr:1.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:41.287, tt:784.460\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.07131, lr:1.00e-02, fs:0.87368 (r=0.954,p=0.806),  time:41.262, tt:825.235\n",
      "Ep:20, loss:0.00015, loss_test:0.07036, lr:1.00e-02, fs:0.87368 (r=0.954,p=0.806),  time:41.386, tt:869.098\n",
      "Ep:21, loss:0.00014, loss_test:0.06854, lr:1.00e-02, fs:0.87701 (r=0.943,p=0.820),  time:41.380, tt:910.361\n",
      "Ep:22, loss:0.00013, loss_test:0.06801, lr:1.00e-02, fs:0.86911 (r=0.954,p=0.798),  time:41.378, tt:951.704\n",
      "Ep:23, loss:0.00013, loss_test:0.06650, lr:1.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:41.337, tt:992.084\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.06601, lr:1.00e-02, fs:0.88770 (r=0.954,p=0.830),  time:41.334, tt:1033.344\n",
      "Ep:25, loss:0.00012, loss_test:0.06498, lr:1.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:41.376, tt:1075.779\n",
      "Ep:26, loss:0.00012, loss_test:0.06422, lr:1.00e-02, fs:0.89247 (r=0.954,p=0.838),  time:41.378, tt:1117.215\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.06292, lr:1.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:41.392, tt:1158.976\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.06238, lr:1.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:41.431, tt:1201.508\n",
      "Ep:29, loss:0.00010, loss_test:0.06091, lr:1.00e-02, fs:0.89730 (r=0.954,p=0.847),  time:41.477, tt:1244.298\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.05953, lr:1.00e-02, fs:0.90217 (r=0.954,p=0.856),  time:41.558, tt:1288.289\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.06143, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:41.530, tt:1328.953\n",
      "Ep:32, loss:0.00009, loss_test:0.05797, lr:1.00e-02, fs:0.89730 (r=0.954,p=0.847),  time:41.536, tt:1370.677\n",
      "Ep:33, loss:0.00009, loss_test:0.05855, lr:1.00e-02, fs:0.88268 (r=0.908,p=0.859),  time:41.562, tt:1413.106\n",
      "Ep:34, loss:0.00009, loss_test:0.05650, lr:1.00e-02, fs:0.90608 (r=0.943,p=0.872),  time:41.623, tt:1456.790\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.05740, lr:1.00e-02, fs:0.89247 (r=0.954,p=0.838),  time:41.584, tt:1497.024\n",
      "Ep:36, loss:0.00008, loss_test:0.05761, lr:1.00e-02, fs:0.88506 (r=0.885,p=0.885),  time:41.591, tt:1538.856\n",
      "Ep:37, loss:0.00008, loss_test:0.05615, lr:1.00e-02, fs:0.90217 (r=0.954,p=0.856),  time:41.637, tt:1582.220\n",
      "Ep:38, loss:0.00007, loss_test:0.05714, lr:1.00e-02, fs:0.89773 (r=0.908,p=0.888),  time:41.690, tt:1625.928\n",
      "Ep:39, loss:0.00007, loss_test:0.05461, lr:1.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:41.699, tt:1667.975\n",
      "Ep:40, loss:0.00007, loss_test:0.05516, lr:1.00e-02, fs:0.89266 (r=0.908,p=0.878),  time:41.761, tt:1712.194\n",
      "Ep:41, loss:0.00007, loss_test:0.05514, lr:1.00e-02, fs:0.88136 (r=0.897,p=0.867),  time:41.787, tt:1755.042\n",
      "Ep:42, loss:0.00006, loss_test:0.05524, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:41.778, tt:1796.453\n",
      "Ep:43, loss:0.00006, loss_test:0.05459, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:41.810, tt:1839.620\n",
      "Ep:44, loss:0.00006, loss_test:0.05321, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:41.799, tt:1880.963\n",
      "Ep:45, loss:0.00006, loss_test:0.05455, lr:1.00e-02, fs:0.90173 (r=0.897,p=0.907),  time:41.798, tt:1922.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00006, loss_test:0.05249, lr:9.90e-03, fs:0.87778 (r=0.908,p=0.849),  time:41.800, tt:1964.593\n",
      "Ep:47, loss:0.00005, loss_test:0.05501, lr:9.80e-03, fs:0.90058 (r=0.885,p=0.917),  time:41.848, tt:2008.708\n",
      "Ep:48, loss:0.00005, loss_test:0.05412, lr:9.70e-03, fs:0.88235 (r=0.862,p=0.904),  time:41.873, tt:2051.760\n",
      "Ep:49, loss:0.00005, loss_test:0.05550, lr:9.61e-03, fs:0.90173 (r=0.897,p=0.907),  time:41.879, tt:2093.939\n",
      "Ep:50, loss:0.00005, loss_test:0.05430, lr:9.51e-03, fs:0.87425 (r=0.839,p=0.912),  time:41.940, tt:2138.950\n",
      "Ep:51, loss:0.00005, loss_test:0.05294, lr:9.41e-03, fs:0.90698 (r=0.897,p=0.918),  time:41.939, tt:2180.825\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.05555, lr:9.41e-03, fs:0.88623 (r=0.851,p=0.925),  time:41.943, tt:2222.998\n",
      "Ep:53, loss:0.00005, loss_test:0.05483, lr:9.41e-03, fs:0.89143 (r=0.897,p=0.886),  time:41.962, tt:2265.930\n",
      "Ep:54, loss:0.00005, loss_test:0.06014, lr:9.41e-03, fs:0.88623 (r=0.851,p=0.925),  time:41.965, tt:2308.087\n",
      "Ep:55, loss:0.00005, loss_test:0.05596, lr:9.41e-03, fs:0.88235 (r=0.862,p=0.904),  time:41.963, tt:2349.922\n",
      "Ep:56, loss:0.00005, loss_test:0.06138, lr:9.41e-03, fs:0.89697 (r=0.851,p=0.949),  time:41.955, tt:2391.433\n",
      "Ep:57, loss:0.00005, loss_test:0.05783, lr:9.41e-03, fs:0.89941 (r=0.874,p=0.927),  time:41.972, tt:2434.350\n",
      "Ep:58, loss:0.00004, loss_test:0.05657, lr:9.41e-03, fs:0.90588 (r=0.885,p=0.928),  time:41.990, tt:2477.412\n",
      "Ep:59, loss:0.00004, loss_test:0.06206, lr:9.41e-03, fs:0.90361 (r=0.862,p=0.949),  time:42.010, tt:2520.607\n",
      "Ep:60, loss:0.00004, loss_test:0.05502, lr:9.41e-03, fs:0.89286 (r=0.862,p=0.926),  time:42.019, tt:2563.140\n",
      "Ep:61, loss:0.00004, loss_test:0.06144, lr:9.41e-03, fs:0.89571 (r=0.839,p=0.961),  time:42.005, tt:2604.279\n",
      "Ep:62, loss:0.00004, loss_test:0.05717, lr:9.41e-03, fs:0.88344 (r=0.828,p=0.947),  time:42.002, tt:2646.102\n",
      "Ep:63, loss:0.00003, loss_test:0.05831, lr:9.32e-03, fs:0.89024 (r=0.839,p=0.948),  time:42.018, tt:2689.135\n",
      "Ep:64, loss:0.00003, loss_test:0.05800, lr:9.23e-03, fs:0.90244 (r=0.851,p=0.961),  time:42.051, tt:2733.301\n",
      "Ep:65, loss:0.00003, loss_test:0.05772, lr:9.14e-03, fs:0.88889 (r=0.828,p=0.960),  time:42.049, tt:2775.265\n",
      "Ep:66, loss:0.00003, loss_test:0.05909, lr:9.04e-03, fs:0.91018 (r=0.874,p=0.950),  time:42.092, tt:2820.144\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00003, loss_test:0.05813, lr:9.04e-03, fs:0.88050 (r=0.805,p=0.972),  time:42.107, tt:2863.263\n",
      "Ep:68, loss:0.00003, loss_test:0.05684, lr:9.04e-03, fs:0.89024 (r=0.839,p=0.948),  time:42.115, tt:2905.942\n",
      "Ep:69, loss:0.00003, loss_test:0.06039, lr:9.04e-03, fs:0.85161 (r=0.759,p=0.971),  time:42.124, tt:2948.677\n",
      "Ep:70, loss:0.00002, loss_test:0.05977, lr:9.04e-03, fs:0.85897 (r=0.770,p=0.971),  time:42.134, tt:2991.532\n",
      "Ep:71, loss:0.00002, loss_test:0.05863, lr:9.04e-03, fs:0.84416 (r=0.747,p=0.970),  time:42.134, tt:3033.652\n",
      "Ep:72, loss:0.00002, loss_test:0.05864, lr:9.04e-03, fs:0.85161 (r=0.759,p=0.971),  time:42.137, tt:3076.035\n",
      "Ep:73, loss:0.00002, loss_test:0.06359, lr:9.04e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.130, tt:3117.601\n",
      "Ep:74, loss:0.00002, loss_test:0.05849, lr:9.04e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.137, tt:3160.280\n",
      "Ep:75, loss:0.00002, loss_test:0.06074, lr:9.04e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.132, tt:3202.023\n",
      "Ep:76, loss:0.00002, loss_test:0.06141, lr:9.04e-03, fs:0.77241 (r=0.644,p=0.966),  time:42.131, tt:3244.075\n",
      "Ep:77, loss:0.00002, loss_test:0.06108, lr:9.04e-03, fs:0.82895 (r=0.724,p=0.969),  time:42.139, tt:3286.833\n",
      "Ep:78, loss:0.00002, loss_test:0.06085, lr:8.95e-03, fs:0.80795 (r=0.701,p=0.953),  time:42.154, tt:3330.144\n",
      "Ep:79, loss:0.00002, loss_test:0.06447, lr:8.86e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.172, tt:3373.785\n",
      "Ep:80, loss:0.00002, loss_test:0.06055, lr:8.78e-03, fs:0.80795 (r=0.701,p=0.953),  time:42.172, tt:3415.937\n",
      "Ep:81, loss:0.00002, loss_test:0.06220, lr:8.69e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.152, tt:3456.440\n",
      "Ep:82, loss:0.00001, loss_test:0.06454, lr:8.60e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.156, tt:3498.966\n",
      "Ep:83, loss:0.00001, loss_test:0.06337, lr:8.51e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.152, tt:3540.769\n",
      "Ep:84, loss:0.00001, loss_test:0.06377, lr:8.43e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.167, tt:3584.196\n",
      "Ep:85, loss:0.00001, loss_test:0.06495, lr:8.35e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.155, tt:3625.294\n",
      "Ep:86, loss:0.00001, loss_test:0.06344, lr:8.26e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.164, tt:3668.266\n",
      "Ep:87, loss:0.00001, loss_test:0.06858, lr:8.18e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.169, tt:3710.872\n",
      "Ep:88, loss:0.00001, loss_test:0.06391, lr:8.10e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.168, tt:3752.939\n",
      "Ep:89, loss:0.00001, loss_test:0.06524, lr:8.02e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.180, tt:3796.190\n",
      "Ep:90, loss:0.00001, loss_test:0.06694, lr:7.94e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.205, tt:3840.616\n",
      "Ep:91, loss:0.00001, loss_test:0.06766, lr:7.86e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.195, tt:3881.903\n",
      "Ep:92, loss:0.00001, loss_test:0.06998, lr:7.78e-03, fs:0.76923 (r=0.632,p=0.982),  time:42.182, tt:3922.885\n",
      "Ep:93, loss:0.00001, loss_test:0.06598, lr:7.70e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.200, tt:3966.838\n",
      "Ep:94, loss:0.00001, loss_test:0.06891, lr:7.62e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.217, tt:4010.654\n",
      "Ep:95, loss:0.00001, loss_test:0.06475, lr:7.55e-03, fs:0.79730 (r=0.678,p=0.967),  time:42.208, tt:4052.012\n",
      "Ep:96, loss:0.00001, loss_test:0.06312, lr:7.47e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.214, tt:4094.770\n",
      "Ep:97, loss:0.00001, loss_test:0.06680, lr:7.40e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.209, tt:4136.469\n",
      "Ep:98, loss:0.00001, loss_test:0.06469, lr:7.32e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.212, tt:4178.984\n",
      "Ep:99, loss:0.00001, loss_test:0.07045, lr:7.25e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.193, tt:4219.253\n",
      "Ep:100, loss:0.00001, loss_test:0.06563, lr:7.18e-03, fs:0.81333 (r=0.701,p=0.968),  time:42.186, tt:4260.788\n",
      "Ep:101, loss:0.00001, loss_test:0.07121, lr:7.11e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.204, tt:4304.826\n",
      "Ep:102, loss:0.00001, loss_test:0.07134, lr:7.03e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.207, tt:4347.285\n",
      "Ep:103, loss:0.00001, loss_test:0.06349, lr:6.96e-03, fs:0.81879 (r=0.701,p=0.984),  time:42.199, tt:4388.717\n",
      "Ep:104, loss:0.00001, loss_test:0.07102, lr:6.89e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.200, tt:4430.984\n",
      "Ep:105, loss:0.00001, loss_test:0.07145, lr:6.83e-03, fs:0.76923 (r=0.632,p=0.982),  time:42.208, tt:4474.016\n",
      "Ep:106, loss:0.00001, loss_test:0.06466, lr:6.76e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.216, tt:4517.118\n",
      "Ep:107, loss:0.00001, loss_test:0.07411, lr:6.69e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.206, tt:4558.233\n",
      "Ep:108, loss:0.00001, loss_test:0.07155, lr:6.62e-03, fs:0.74286 (r=0.598,p=0.981),  time:42.205, tt:4600.375\n",
      "Ep:109, loss:0.00001, loss_test:0.06833, lr:6.56e-03, fs:0.79452 (r=0.667,p=0.983),  time:42.196, tt:4641.569\n",
      "Ep:110, loss:0.00001, loss_test:0.07107, lr:6.49e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.190, tt:4683.041\n",
      "Ep:111, loss:0.00001, loss_test:0.06985, lr:6.43e-03, fs:0.77778 (r=0.644,p=0.982),  time:42.174, tt:4723.460\n",
      "Ep:112, loss:0.00001, loss_test:0.06974, lr:6.36e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.180, tt:4766.373\n",
      "Ep:113, loss:0.00001, loss_test:0.07019, lr:6.30e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.166, tt:4806.953\n",
      "Ep:114, loss:0.00001, loss_test:0.07032, lr:6.24e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.169, tt:4849.492\n",
      "Ep:115, loss:0.00001, loss_test:0.07224, lr:6.17e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.165, tt:4891.102\n",
      "Ep:116, loss:0.00001, loss_test:0.07008, lr:6.11e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.164, tt:4933.162\n",
      "Ep:117, loss:0.00001, loss_test:0.06997, lr:6.05e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.156, tt:4974.461\n",
      "Ep:118, loss:0.00001, loss_test:0.07008, lr:5.99e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.162, tt:5017.280\n",
      "Ep:119, loss:0.00000, loss_test:0.07196, lr:5.93e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.153, tt:5058.390\n",
      "Ep:120, loss:0.00000, loss_test:0.07271, lr:5.87e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.172, tt:5102.824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00000, loss_test:0.07275, lr:5.81e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.156, tt:5143.082\n",
      "Ep:122, loss:0.00000, loss_test:0.07175, lr:5.75e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.143, tt:5183.562\n",
      "Ep:123, loss:0.00000, loss_test:0.07128, lr:5.70e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.142, tt:5225.548\n",
      "Ep:124, loss:0.00000, loss_test:0.07197, lr:5.64e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.141, tt:5267.627\n",
      "Ep:125, loss:0.00000, loss_test:0.07311, lr:5.58e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.130, tt:5308.338\n",
      "Ep:126, loss:0.00000, loss_test:0.07200, lr:5.53e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.120, tt:5349.177\n",
      "Ep:127, loss:0.00000, loss_test:0.07236, lr:5.47e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.113, tt:5390.505\n",
      "Ep:128, loss:0.00000, loss_test:0.07216, lr:5.42e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.117, tt:5433.100\n",
      "Ep:129, loss:0.00000, loss_test:0.07339, lr:5.36e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.095, tt:5472.371\n",
      "Ep:130, loss:0.00000, loss_test:0.07301, lr:5.31e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.097, tt:5514.646\n",
      "Ep:131, loss:0.00000, loss_test:0.07222, lr:5.26e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.086, tt:5555.297\n",
      "Ep:132, loss:0.00000, loss_test:0.07566, lr:5.20e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.084, tt:5597.117\n",
      "Ep:133, loss:0.00000, loss_test:0.07457, lr:5.15e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.074, tt:5637.856\n",
      "Ep:134, loss:0.00000, loss_test:0.07249, lr:5.10e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.070, tt:5679.485\n",
      "Ep:135, loss:0.00000, loss_test:0.07303, lr:5.05e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.081, tt:5723.079\n",
      "Ep:136, loss:0.00000, loss_test:0.07346, lr:5.00e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.089, tt:5766.213\n",
      "Ep:137, loss:0.00000, loss_test:0.07481, lr:4.95e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.071, tt:5805.821\n",
      "Ep:138, loss:0.00000, loss_test:0.07533, lr:4.90e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.069, tt:5847.580\n",
      "Ep:139, loss:0.00000, loss_test:0.07296, lr:4.85e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.073, tt:5890.188\n",
      "Ep:140, loss:0.00000, loss_test:0.07283, lr:4.80e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.070, tt:5931.931\n",
      "Ep:141, loss:0.00000, loss_test:0.07347, lr:4.75e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.054, tt:5971.729\n",
      "Ep:142, loss:0.00000, loss_test:0.07417, lr:4.71e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.049, tt:6013.021\n",
      "Ep:143, loss:0.00000, loss_test:0.07344, lr:4.66e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.051, tt:6055.340\n",
      "Ep:144, loss:0.00000, loss_test:0.07456, lr:4.61e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.050, tt:6097.228\n",
      "Ep:145, loss:0.00000, loss_test:0.07413, lr:4.57e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.048, tt:6139.058\n",
      "Ep:146, loss:0.00000, loss_test:0.07466, lr:4.52e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.047, tt:6180.946\n",
      "Ep:147, loss:0.00000, loss_test:0.07513, lr:4.48e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.082, tt:6228.080\n",
      "Ep:148, loss:0.00000, loss_test:0.07339, lr:4.43e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.070, tt:6268.378\n",
      "Ep:149, loss:0.00000, loss_test:0.07452, lr:4.39e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.069, tt:6310.280\n",
      "Ep:150, loss:0.00000, loss_test:0.07535, lr:4.34e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.063, tt:6351.588\n",
      "Ep:151, loss:0.00000, loss_test:0.07422, lr:4.30e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.055, tt:6392.351\n",
      "Ep:152, loss:0.00000, loss_test:0.07438, lr:4.26e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.057, tt:6434.733\n",
      "Ep:153, loss:0.00000, loss_test:0.07556, lr:4.21e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.067, tt:6478.360\n",
      "Ep:154, loss:0.00000, loss_test:0.07446, lr:4.17e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.071, tt:6521.007\n",
      "Ep:155, loss:0.00000, loss_test:0.07478, lr:4.13e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.068, tt:6562.625\n",
      "Ep:156, loss:0.00000, loss_test:0.07517, lr:4.09e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.068, tt:6604.695\n",
      "Ep:157, loss:0.00000, loss_test:0.07439, lr:4.05e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.071, tt:6647.225\n",
      "Ep:158, loss:0.00000, loss_test:0.07585, lr:4.01e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.058, tt:6687.297\n",
      "Ep:159, loss:0.00000, loss_test:0.07599, lr:3.97e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.053, tt:6728.506\n",
      "Ep:160, loss:0.00000, loss_test:0.07480, lr:3.93e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.050, tt:6770.062\n",
      "Ep:161, loss:0.00000, loss_test:0.07468, lr:3.89e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.042, tt:6810.816\n",
      "Ep:162, loss:0.00000, loss_test:0.07495, lr:3.85e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.042, tt:6852.854\n",
      "Ep:163, loss:0.00000, loss_test:0.07504, lr:3.81e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.044, tt:6895.205\n",
      "Ep:164, loss:0.00000, loss_test:0.07502, lr:3.77e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.044, tt:6937.205\n",
      "Ep:165, loss:0.00000, loss_test:0.07423, lr:3.73e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.044, tt:6979.291\n",
      "Ep:166, loss:0.00000, loss_test:0.07519, lr:3.70e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.055, tt:7023.159\n",
      "Ep:167, loss:0.00000, loss_test:0.07686, lr:3.66e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.080, tt:7069.405\n",
      "Ep:168, loss:0.00000, loss_test:0.07534, lr:3.62e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.079, tt:7111.435\n",
      "Ep:169, loss:0.00000, loss_test:0.07487, lr:3.59e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.078, tt:7153.209\n",
      "Ep:170, loss:0.00000, loss_test:0.07513, lr:3.55e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.078, tt:7195.268\n",
      "Ep:171, loss:0.00000, loss_test:0.07483, lr:3.52e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.083, tt:7238.341\n",
      "Ep:172, loss:0.00000, loss_test:0.07602, lr:3.48e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.088, tt:7281.222\n",
      "Ep:173, loss:0.00000, loss_test:0.07656, lr:3.45e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.092, tt:7323.935\n",
      "Ep:174, loss:0.00000, loss_test:0.07574, lr:3.41e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.093, tt:7366.218\n",
      "Ep:175, loss:0.00000, loss_test:0.07525, lr:3.38e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.091, tt:7407.940\n",
      "Ep:176, loss:0.00000, loss_test:0.07499, lr:3.34e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.092, tt:7450.199\n",
      "Ep:177, loss:0.00000, loss_test:0.07459, lr:3.31e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.098, tt:7493.478\n",
      "Ep:178, loss:0.00000, loss_test:0.07559, lr:3.28e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.103, tt:7536.375\n",
      "Ep:179, loss:0.00000, loss_test:0.07582, lr:3.24e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.104, tt:7578.728\n",
      "Ep:180, loss:0.00000, loss_test:0.07596, lr:3.21e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.100, tt:7620.083\n",
      "Ep:181, loss:0.00000, loss_test:0.07718, lr:3.18e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.101, tt:7662.421\n",
      "Ep:182, loss:0.00000, loss_test:0.07691, lr:3.15e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.103, tt:7704.877\n",
      "Ep:183, loss:0.00000, loss_test:0.07524, lr:3.12e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.104, tt:7747.135\n",
      "Ep:184, loss:0.00000, loss_test:0.07680, lr:3.09e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.094, tt:7787.385\n",
      "Ep:185, loss:0.00000, loss_test:0.07659, lr:3.05e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.082, tt:7827.264\n",
      "Ep:186, loss:0.00000, loss_test:0.07573, lr:3.02e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.077, tt:7868.396\n",
      "Ep:187, loss:0.00000, loss_test:0.07632, lr:2.99e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.080, tt:7910.963\n",
      "Ep:188, loss:0.00000, loss_test:0.07730, lr:2.96e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.084, tt:7953.821\n",
      "Ep:189, loss:0.00000, loss_test:0.07644, lr:2.93e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.088, tt:7996.764\n",
      "Ep:190, loss:0.00000, loss_test:0.07590, lr:2.90e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.093, tt:8039.708\n",
      "Ep:191, loss:0.00000, loss_test:0.07609, lr:2.88e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.091, tt:8081.406\n",
      "Ep:192, loss:0.00000, loss_test:0.07628, lr:2.85e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.081, tt:8121.598\n",
      "Ep:193, loss:0.00000, loss_test:0.07610, lr:2.82e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.087, tt:8164.958\n",
      "Ep:194, loss:0.00000, loss_test:0.07508, lr:2.79e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.083, tt:8206.175\n",
      "Ep:195, loss:0.00000, loss_test:0.07678, lr:2.76e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.088, tt:8249.213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00000, loss_test:0.07864, lr:2.73e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.090, tt:8291.651\n",
      "Ep:197, loss:0.00000, loss_test:0.07785, lr:2.71e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.099, tt:8335.537\n",
      "Ep:198, loss:0.00000, loss_test:0.07629, lr:2.68e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.096, tt:8377.140\n",
      "Ep:199, loss:0.00000, loss_test:0.07582, lr:2.65e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.085, tt:8416.984\n",
      "Ep:200, loss:0.00000, loss_test:0.07641, lr:2.63e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.087, tt:8459.483\n",
      "Ep:201, loss:0.00000, loss_test:0.07642, lr:2.60e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.082, tt:8500.634\n",
      "Ep:202, loss:0.00000, loss_test:0.07633, lr:2.57e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.076, tt:8541.505\n",
      "Ep:203, loss:0.00000, loss_test:0.07628, lr:2.55e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.079, tt:8584.116\n",
      "Ep:204, loss:0.00000, loss_test:0.07651, lr:2.52e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.079, tt:8626.248\n",
      "Ep:205, loss:0.00000, loss_test:0.07635, lr:2.50e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.067, tt:8665.854\n",
      "Ep:206, loss:0.00000, loss_test:0.07651, lr:2.47e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.074, tt:8709.277\n",
      "Ep:207, loss:0.00000, loss_test:0.07672, lr:2.45e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.085, tt:8753.656\n",
      "Ep:208, loss:0.00000, loss_test:0.07708, lr:2.42e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.100, tt:8798.814\n",
      "Ep:209, loss:0.00000, loss_test:0.07740, lr:2.40e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.102, tt:8841.368\n",
      "Ep:210, loss:0.00000, loss_test:0.07713, lr:2.38e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.101, tt:8883.292\n",
      "Ep:211, loss:0.00000, loss_test:0.07770, lr:2.35e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.092, tt:8923.565\n",
      "Ep:212, loss:0.00000, loss_test:0.07747, lr:2.33e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.049, tt:8956.524\n",
      "Ep:213, loss:0.00000, loss_test:0.07719, lr:2.31e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.995, tt:8986.867\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02005, lr:6.00e-02, fs:0.64435 (r=0.885,p=0.507),  time:34.723, tt:34.723\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02257, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.250, tt:72.500\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02338, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.803, tt:113.408\n",
      "Ep:3, loss:0.00005, loss_test:0.02260, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.787, tt:155.149\n",
      "Ep:4, loss:0.00004, loss_test:0.02092, lr:6.00e-02, fs:0.67969 (r=1.000,p=0.515),  time:39.097, tt:195.488\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01924, lr:6.00e-02, fs:0.66116 (r=0.920,p=0.516),  time:39.200, tt:235.202\n",
      "Ep:6, loss:0.00004, loss_test:0.01818, lr:6.00e-02, fs:0.67532 (r=0.897,p=0.542),  time:39.534, tt:276.739\n",
      "Ep:7, loss:0.00004, loss_test:0.01731, lr:6.00e-02, fs:0.68778 (r=0.874,p=0.567),  time:39.999, tt:319.994\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01624, lr:6.00e-02, fs:0.70588 (r=0.897,p=0.582),  time:39.944, tt:359.500\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01562, lr:6.00e-02, fs:0.75325 (r=1.000,p=0.604),  time:40.355, tt:403.552\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01511, lr:6.00e-02, fs:0.74678 (r=1.000,p=0.596),  time:40.639, tt:447.025\n",
      "Ep:11, loss:0.00003, loss_test:0.01452, lr:6.00e-02, fs:0.76444 (r=0.989,p=0.623),  time:40.743, tt:488.917\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01403, lr:6.00e-02, fs:0.79630 (r=0.989,p=0.667),  time:40.957, tt:532.436\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01376, lr:6.00e-02, fs:0.81905 (r=0.989,p=0.699),  time:41.563, tt:581.879\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01361, lr:6.00e-02, fs:0.82464 (r=1.000,p=0.702),  time:41.740, tt:626.106\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01346, lr:6.00e-02, fs:0.82464 (r=1.000,p=0.702),  time:41.761, tt:668.179\n",
      "Ep:16, loss:0.00003, loss_test:0.01331, lr:6.00e-02, fs:0.81132 (r=0.989,p=0.688),  time:41.728, tt:709.371\n",
      "Ep:17, loss:0.00003, loss_test:0.01312, lr:6.00e-02, fs:0.81517 (r=0.989,p=0.694),  time:41.692, tt:750.462\n",
      "Ep:18, loss:0.00003, loss_test:0.01290, lr:6.00e-02, fs:0.80952 (r=0.977,p=0.691),  time:41.687, tt:792.056\n",
      "Ep:19, loss:0.00003, loss_test:0.01272, lr:6.00e-02, fs:0.81517 (r=0.989,p=0.694),  time:41.707, tt:834.135\n",
      "Ep:20, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.82297 (r=0.989,p=0.705),  time:41.766, tt:877.086\n",
      "Ep:21, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.83092 (r=0.989,p=0.717),  time:41.798, tt:919.549\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.83902 (r=0.989,p=0.729),  time:41.811, tt:961.645\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.84314 (r=0.989,p=0.735),  time:41.833, tt:1003.995\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01204, lr:6.00e-02, fs:0.84729 (r=0.989,p=0.741),  time:41.845, tt:1046.120\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01195, lr:6.00e-02, fs:0.84729 (r=0.989,p=0.741),  time:41.917, tt:1089.834\n",
      "Ep:26, loss:0.00002, loss_test:0.01182, lr:6.00e-02, fs:0.84158 (r=0.977,p=0.739),  time:41.902, tt:1131.366\n",
      "Ep:27, loss:0.00002, loss_test:0.01176, lr:6.00e-02, fs:0.85000 (r=0.977,p=0.752),  time:41.898, tt:1173.150\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01169, lr:6.00e-02, fs:0.85000 (r=0.977,p=0.752),  time:41.891, tt:1214.853\n",
      "Ep:29, loss:0.00002, loss_test:0.01165, lr:6.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:41.876, tt:1256.284\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01154, lr:6.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:41.929, tt:1299.788\n",
      "Ep:31, loss:0.00002, loss_test:0.01143, lr:6.00e-02, fs:0.86154 (r=0.966,p=0.778),  time:41.928, tt:1341.712\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01136, lr:6.00e-02, fs:0.86154 (r=0.966,p=0.778),  time:41.913, tt:1383.115\n",
      "Ep:33, loss:0.00002, loss_test:0.01133, lr:6.00e-02, fs:0.86154 (r=0.966,p=0.778),  time:41.931, tt:1425.642\n",
      "Ep:34, loss:0.00002, loss_test:0.01129, lr:6.00e-02, fs:0.86598 (r=0.966,p=0.785),  time:41.895, tt:1466.321\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01124, lr:6.00e-02, fs:0.86598 (r=0.966,p=0.785),  time:41.844, tt:1506.391\n",
      "Ep:36, loss:0.00002, loss_test:0.01121, lr:6.00e-02, fs:0.86010 (r=0.954,p=0.783),  time:41.814, tt:1547.128\n",
      "Ep:37, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.87368 (r=0.954,p=0.806),  time:41.890, tt:1591.808\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01115, lr:6.00e-02, fs:0.86772 (r=0.943,p=0.804),  time:41.869, tt:1632.899\n",
      "Ep:39, loss:0.00002, loss_test:0.01110, lr:6.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:41.908, tt:1676.323\n",
      "Ep:40, loss:0.00002, loss_test:0.01112, lr:6.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:41.842, tt:1715.507\n",
      "Ep:41, loss:0.00001, loss_test:0.01105, lr:6.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:41.832, tt:1756.962\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00001, loss_test:0.01109, lr:6.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:41.857, tt:1799.860\n",
      "Ep:43, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.87568 (r=0.931,p=0.827),  time:41.850, tt:1841.419\n",
      "Ep:44, loss:0.00001, loss_test:0.01106, lr:6.00e-02, fs:0.87568 (r=0.931,p=0.827),  time:41.845, tt:1883.023\n",
      "Ep:45, loss:0.00001, loss_test:0.01102, lr:6.00e-02, fs:0.87568 (r=0.931,p=0.827),  time:41.825, tt:1923.945\n",
      "Ep:46, loss:0.00001, loss_test:0.01109, lr:6.00e-02, fs:0.88525 (r=0.931,p=0.844),  time:41.839, tt:1966.413\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01111, lr:6.00e-02, fs:0.88525 (r=0.931,p=0.844),  time:41.873, tt:2009.908\n",
      "Ep:48, loss:0.00001, loss_test:0.01112, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:41.871, tt:2051.699\n",
      "Ep:49, loss:0.00001, loss_test:0.01110, lr:6.00e-02, fs:0.87912 (r=0.920,p=0.842),  time:41.869, tt:2093.426\n",
      "Ep:50, loss:0.00001, loss_test:0.01119, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:41.844, tt:2134.067\n",
      "Ep:51, loss:0.00001, loss_test:0.01118, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:41.849, tt:2176.130\n",
      "Ep:52, loss:0.00001, loss_test:0.01119, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:41.838, tt:2217.436\n",
      "Ep:53, loss:0.00001, loss_test:0.01121, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:41.820, tt:2258.287\n",
      "Ep:54, loss:0.00001, loss_test:0.01123, lr:6.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:41.772, tt:2297.438\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01126, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:41.761, tt:2338.640\n",
      "Ep:56, loss:0.00001, loss_test:0.01126, lr:6.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:41.741, tt:2379.236\n",
      "Ep:57, loss:0.00001, loss_test:0.01131, lr:6.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:41.748, tt:2421.362\n",
      "Ep:58, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:41.769, tt:2464.354\n",
      "Ep:59, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:41.741, tt:2504.453\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:41.780, tt:2548.584\n",
      "Ep:61, loss:0.00001, loss_test:0.01149, lr:6.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:41.799, tt:2591.516\n",
      "Ep:62, loss:0.00001, loss_test:0.01147, lr:6.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:41.772, tt:2631.662\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:41.800, tt:2675.185\n",
      "Ep:64, loss:0.00001, loss_test:0.01158, lr:6.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:41.789, tt:2716.308\n",
      "Ep:65, loss:0.00001, loss_test:0.01160, lr:6.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:41.780, tt:2757.492\n",
      "Ep:66, loss:0.00001, loss_test:0.01174, lr:6.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:41.789, tt:2799.834\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01168, lr:6.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:41.778, tt:2840.906\n",
      "Ep:68, loss:0.00001, loss_test:0.01180, lr:6.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:41.773, tt:2882.313\n",
      "Ep:69, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:41.744, tt:2922.058\n",
      "Ep:70, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:41.734, tt:2963.088\n",
      "Ep:71, loss:0.00001, loss_test:0.01196, lr:6.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:41.752, tt:3006.127\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.91954 (r=0.920,p=0.920),  time:41.780, tt:3049.974\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01208, lr:6.00e-02, fs:0.91329 (r=0.908,p=0.919),  time:41.792, tt:3092.580\n",
      "Ep:74, loss:0.00001, loss_test:0.01223, lr:6.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:41.793, tt:3134.443\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01232, lr:6.00e-02, fs:0.91228 (r=0.897,p=0.929),  time:41.776, tt:3174.984\n",
      "Ep:76, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.89941 (r=0.874,p=0.927),  time:41.764, tt:3215.835\n",
      "Ep:77, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.90588 (r=0.885,p=0.928),  time:41.730, tt:3254.932\n",
      "Ep:78, loss:0.00001, loss_test:0.01247, lr:6.00e-02, fs:0.89286 (r=0.862,p=0.926),  time:41.707, tt:3294.843\n",
      "Ep:79, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.87273 (r=0.828,p=0.923),  time:41.701, tt:3336.062\n",
      "Ep:80, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:41.683, tt:3376.305\n",
      "Ep:81, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:41.676, tt:3417.413\n",
      "Ep:82, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.686, tt:3459.948\n",
      "Ep:83, loss:0.00001, loss_test:0.01287, lr:6.00e-02, fs:0.87805 (r=0.828,p=0.935),  time:41.658, tt:3499.265\n",
      "Ep:84, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.653, tt:3540.484\n",
      "Ep:85, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.646, tt:3581.567\n",
      "Ep:86, loss:0.00001, loss_test:0.01307, lr:5.94e-02, fs:0.86420 (r=0.805,p=0.933),  time:41.656, tt:3624.030\n",
      "Ep:87, loss:0.00001, loss_test:0.01334, lr:5.88e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.665, tt:3666.560\n",
      "Ep:88, loss:0.00001, loss_test:0.01342, lr:5.82e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.662, tt:3707.890\n",
      "Ep:89, loss:0.00001, loss_test:0.01346, lr:5.76e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.648, tt:3748.296\n",
      "Ep:90, loss:0.00001, loss_test:0.01351, lr:5.71e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.626, tt:3787.931\n",
      "Ep:91, loss:0.00001, loss_test:0.01357, lr:5.65e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.614, tt:3828.479\n",
      "Ep:92, loss:0.00001, loss_test:0.01377, lr:5.59e-02, fs:0.86250 (r=0.793,p=0.945),  time:41.591, tt:3867.921\n",
      "Ep:93, loss:0.00001, loss_test:0.01383, lr:5.54e-02, fs:0.86250 (r=0.793,p=0.945),  time:41.578, tt:3908.360\n",
      "Ep:94, loss:0.00001, loss_test:0.01392, lr:5.48e-02, fs:0.86250 (r=0.793,p=0.945),  time:41.582, tt:3950.304\n",
      "Ep:95, loss:0.00000, loss_test:0.01404, lr:5.43e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.569, tt:3990.668\n",
      "Ep:96, loss:0.00000, loss_test:0.01414, lr:5.37e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.553, tt:4030.677\n",
      "Ep:97, loss:0.00000, loss_test:0.01421, lr:5.32e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.557, tt:4072.580\n",
      "Ep:98, loss:0.00000, loss_test:0.01426, lr:5.27e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.561, tt:4114.535\n",
      "Ep:99, loss:0.00000, loss_test:0.01439, lr:5.21e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.587, tt:4158.685\n",
      "Ep:100, loss:0.00000, loss_test:0.01445, lr:5.16e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.582, tt:4199.746\n",
      "Ep:101, loss:0.00000, loss_test:0.01460, lr:5.11e-02, fs:0.86076 (r=0.782,p=0.958),  time:41.582, tt:4241.352\n",
      "Ep:102, loss:0.00000, loss_test:0.01464, lr:5.06e-02, fs:0.86792 (r=0.793,p=0.958),  time:41.600, tt:4284.843\n",
      "Ep:103, loss:0.00000, loss_test:0.01475, lr:5.01e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.610, tt:4327.481\n",
      "Ep:104, loss:0.00000, loss_test:0.01487, lr:4.96e-02, fs:0.83871 (r=0.747,p=0.956),  time:41.634, tt:4371.528\n",
      "Ep:105, loss:0.00000, loss_test:0.01478, lr:4.91e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.639, tt:4413.783\n",
      "Ep:106, loss:0.00000, loss_test:0.01497, lr:4.86e-02, fs:0.83117 (r=0.736,p=0.955),  time:41.666, tt:4458.278\n",
      "Ep:107, loss:0.00000, loss_test:0.01504, lr:4.81e-02, fs:0.83117 (r=0.736,p=0.955),  time:41.663, tt:4499.573\n",
      "Ep:108, loss:0.00000, loss_test:0.01506, lr:4.76e-02, fs:0.83117 (r=0.736,p=0.955),  time:41.650, tt:4539.875\n",
      "Ep:109, loss:0.00000, loss_test:0.01526, lr:4.71e-02, fs:0.80000 (r=0.690,p=0.952),  time:41.646, tt:4581.090\n",
      "Ep:110, loss:0.00000, loss_test:0.01528, lr:4.67e-02, fs:0.79195 (r=0.678,p=0.952),  time:41.650, tt:4623.150\n",
      "Ep:111, loss:0.00000, loss_test:0.01531, lr:4.62e-02, fs:0.79195 (r=0.678,p=0.952),  time:41.651, tt:4664.949\n",
      "Ep:112, loss:0.00000, loss_test:0.01541, lr:4.57e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.651, tt:4706.512\n",
      "Ep:113, loss:0.00000, loss_test:0.01549, lr:4.53e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.649, tt:4747.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00000, loss_test:0.01552, lr:4.48e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.646, tt:4789.346\n",
      "Ep:115, loss:0.00000, loss_test:0.01567, lr:4.44e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.640, tt:4830.294\n",
      "Ep:116, loss:0.00000, loss_test:0.01567, lr:4.39e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.644, tt:4872.337\n",
      "Ep:117, loss:0.00000, loss_test:0.01572, lr:4.35e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.645, tt:4914.080\n",
      "Ep:118, loss:0.00000, loss_test:0.01579, lr:4.31e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.640, tt:4955.191\n",
      "Ep:119, loss:0.00000, loss_test:0.01588, lr:4.26e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.652, tt:4998.285\n",
      "Ep:120, loss:0.00000, loss_test:0.01580, lr:4.22e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.657, tt:5040.475\n",
      "Ep:121, loss:0.00000, loss_test:0.01605, lr:4.18e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.659, tt:5082.397\n",
      "Ep:122, loss:0.00000, loss_test:0.01601, lr:4.14e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.647, tt:5122.577\n",
      "Ep:123, loss:0.00000, loss_test:0.01600, lr:4.10e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.640, tt:5163.366\n",
      "Ep:124, loss:0.00000, loss_test:0.01616, lr:4.05e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.645, tt:5205.589\n",
      "Ep:125, loss:0.00000, loss_test:0.01616, lr:4.01e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.657, tt:5248.840\n",
      "Ep:126, loss:0.00000, loss_test:0.01623, lr:3.97e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.654, tt:5290.118\n",
      "Ep:127, loss:0.00000, loss_test:0.01630, lr:3.93e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.663, tt:5332.861\n",
      "Ep:128, loss:0.00000, loss_test:0.01638, lr:3.89e-02, fs:0.78378 (r=0.667,p=0.951),  time:41.673, tt:5375.772\n",
      "Ep:129, loss:0.00000, loss_test:0.01641, lr:3.86e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.678, tt:5418.191\n",
      "Ep:130, loss:0.00000, loss_test:0.01647, lr:3.82e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.691, tt:5461.542\n",
      "Ep:131, loss:0.00000, loss_test:0.01655, lr:3.78e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.680, tt:5501.717\n",
      "Ep:132, loss:0.00000, loss_test:0.01661, lr:3.74e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.664, tt:5541.254\n",
      "Ep:133, loss:0.00000, loss_test:0.01662, lr:3.70e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.650, tt:5581.164\n",
      "Ep:134, loss:0.00000, loss_test:0.01670, lr:3.67e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.640, tt:5621.450\n",
      "Ep:135, loss:0.00000, loss_test:0.01668, lr:3.63e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.641, tt:5663.173\n",
      "Ep:136, loss:0.00000, loss_test:0.01679, lr:3.59e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.636, tt:5704.133\n",
      "Ep:137, loss:0.00000, loss_test:0.01682, lr:3.56e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.625, tt:5744.297\n",
      "Ep:138, loss:0.00000, loss_test:0.01686, lr:3.52e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.638, tt:5787.636\n",
      "Ep:139, loss:0.00000, loss_test:0.01688, lr:3.49e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.633, tt:5828.588\n",
      "Ep:140, loss:0.00000, loss_test:0.01698, lr:3.45e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.631, tt:5869.974\n",
      "Ep:141, loss:0.00000, loss_test:0.01697, lr:3.42e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.621, tt:5910.166\n",
      "Ep:142, loss:0.00000, loss_test:0.01707, lr:3.38e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.624, tt:5952.181\n",
      "Ep:143, loss:0.00000, loss_test:0.01710, lr:3.35e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.614, tt:5992.476\n",
      "Ep:144, loss:0.00000, loss_test:0.01709, lr:3.32e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.609, tt:6033.263\n",
      "Ep:145, loss:0.00000, loss_test:0.01717, lr:3.28e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.599, tt:6073.430\n",
      "Ep:146, loss:0.00000, loss_test:0.01723, lr:3.25e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.591, tt:6113.835\n",
      "Ep:147, loss:0.00000, loss_test:0.01720, lr:3.22e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.588, tt:6155.058\n",
      "Ep:148, loss:0.00000, loss_test:0.01727, lr:3.19e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.594, tt:6197.441\n",
      "Ep:149, loss:0.00000, loss_test:0.01742, lr:3.15e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.608, tt:6241.176\n",
      "Ep:150, loss:0.00000, loss_test:0.01732, lr:3.12e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.598, tt:6281.270\n",
      "Ep:151, loss:0.00000, loss_test:0.01741, lr:3.09e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.592, tt:6322.019\n",
      "Ep:152, loss:0.00000, loss_test:0.01756, lr:3.06e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.600, tt:6364.762\n",
      "Ep:153, loss:0.00000, loss_test:0.01747, lr:3.03e-02, fs:0.77852 (r=0.667,p=0.935),  time:41.588, tt:6404.535\n",
      "Ep:154, loss:0.00000, loss_test:0.01752, lr:3.00e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.582, tt:6445.134\n",
      "Ep:155, loss:0.00000, loss_test:0.01763, lr:2.97e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.583, tt:6486.974\n",
      "Ep:156, loss:0.00000, loss_test:0.01759, lr:2.94e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.585, tt:6528.921\n",
      "Ep:157, loss:0.00000, loss_test:0.01764, lr:2.91e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.596, tt:6572.140\n",
      "Ep:158, loss:0.00000, loss_test:0.01768, lr:2.88e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.605, tt:6615.238\n",
      "Ep:159, loss:0.00000, loss_test:0.01770, lr:2.85e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.615, tt:6658.478\n",
      "Ep:160, loss:0.00000, loss_test:0.01773, lr:2.82e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.624, tt:6701.545\n",
      "Ep:161, loss:0.00000, loss_test:0.01780, lr:2.80e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.620, tt:6742.508\n",
      "Ep:162, loss:0.00000, loss_test:0.01779, lr:2.77e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.625, tt:6784.883\n",
      "Ep:163, loss:0.00000, loss_test:0.01783, lr:2.74e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.628, tt:6826.944\n",
      "Ep:164, loss:0.00000, loss_test:0.01788, lr:2.71e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.644, tt:6871.239\n",
      "Ep:165, loss:0.00000, loss_test:0.01786, lr:2.69e-02, fs:0.77027 (r=0.655,p=0.934),  time:41.672, tt:6917.611\n",
      "Ep:166, loss:0.00000, loss_test:0.01792, lr:2.66e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.687, tt:6961.723\n",
      "Ep:167, loss:0.00000, loss_test:0.01796, lr:2.63e-02, fs:0.76190 (r=0.644,p=0.933),  time:41.701, tt:7005.750\n",
      "Ep:168, loss:0.00000, loss_test:0.01800, lr:2.61e-02, fs:0.75342 (r=0.632,p=0.932),  time:41.705, tt:7048.209\n",
      "Ep:169, loss:0.00000, loss_test:0.01802, lr:2.58e-02, fs:0.75342 (r=0.632,p=0.932),  time:41.715, tt:7091.557\n",
      "Ep:170, loss:0.00000, loss_test:0.01801, lr:2.55e-02, fs:0.75862 (r=0.632,p=0.948),  time:41.729, tt:7135.599\n",
      "Ep:171, loss:0.00000, loss_test:0.01808, lr:2.53e-02, fs:0.75862 (r=0.632,p=0.948),  time:41.733, tt:7178.071\n",
      "Ep:172, loss:0.00000, loss_test:0.01810, lr:2.50e-02, fs:0.75862 (r=0.632,p=0.948),  time:41.751, tt:7222.857\n",
      "Ep:173, loss:0.00000, loss_test:0.01805, lr:2.48e-02, fs:0.75342 (r=0.632,p=0.932),  time:41.765, tt:7267.116\n",
      "Ep:174, loss:0.00000, loss_test:0.01811, lr:2.45e-02, fs:0.75862 (r=0.632,p=0.948),  time:41.784, tt:7312.281\n",
      "Ep:175, loss:0.00000, loss_test:0.01820, lr:2.43e-02, fs:0.76389 (r=0.632,p=0.965),  time:41.792, tt:7355.400\n",
      "Ep:176, loss:0.00000, loss_test:0.01820, lr:2.40e-02, fs:0.76389 (r=0.632,p=0.965),  time:41.798, tt:7398.275\n",
      "Ep:177, loss:0.00000, loss_test:0.01821, lr:2.38e-02, fs:0.76389 (r=0.632,p=0.965),  time:41.801, tt:7440.599\n",
      "Ep:178, loss:0.00000, loss_test:0.01825, lr:2.36e-02, fs:0.75524 (r=0.621,p=0.964),  time:41.796, tt:7481.482\n",
      "Ep:179, loss:0.00000, loss_test:0.01826, lr:2.33e-02, fs:0.76389 (r=0.632,p=0.965),  time:41.788, tt:7521.905\n",
      "Ep:180, loss:0.00000, loss_test:0.01829, lr:2.31e-02, fs:0.76389 (r=0.632,p=0.965),  time:41.791, tt:7564.195\n",
      "Ep:181, loss:0.00000, loss_test:0.01832, lr:2.29e-02, fs:0.75524 (r=0.621,p=0.964),  time:41.785, tt:7604.956\n",
      "Ep:182, loss:0.00000, loss_test:0.01836, lr:2.26e-02, fs:0.75524 (r=0.621,p=0.964),  time:41.779, tt:7645.492\n",
      "Ep:183, loss:0.00000, loss_test:0.01834, lr:2.24e-02, fs:0.76389 (r=0.632,p=0.965),  time:41.780, tt:7687.460\n",
      "Ep:184, loss:0.00000, loss_test:0.01838, lr:2.22e-02, fs:0.75524 (r=0.621,p=0.964),  time:41.772, tt:7727.799\n",
      "Ep:185, loss:0.00000, loss_test:0.01842, lr:2.20e-02, fs:0.74648 (r=0.609,p=0.964),  time:41.770, tt:7769.214\n",
      "Ep:186, loss:0.00000, loss_test:0.01844, lr:2.17e-02, fs:0.75524 (r=0.621,p=0.964),  time:41.768, tt:7810.686\n",
      "Ep:187, loss:0.00000, loss_test:0.01843, lr:2.15e-02, fs:0.74648 (r=0.609,p=0.964),  time:41.753, tt:7849.526\n",
      "Ep:188, loss:0.00000, loss_test:0.01847, lr:2.13e-02, fs:0.74648 (r=0.609,p=0.964),  time:41.754, tt:7891.573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:189, loss:0.00000, loss_test:0.01854, lr:2.11e-02, fs:0.74648 (r=0.609,p=0.964),  time:41.748, tt:7932.027\n",
      "Ep:190, loss:0.00000, loss_test:0.01854, lr:2.09e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.743, tt:7972.914\n",
      "Ep:191, loss:0.00000, loss_test:0.01854, lr:2.07e-02, fs:0.74648 (r=0.609,p=0.964),  time:41.751, tt:8016.150\n",
      "Ep:192, loss:0.00000, loss_test:0.01858, lr:2.05e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.750, tt:8057.714\n",
      "Ep:193, loss:0.00000, loss_test:0.01861, lr:2.03e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.748, tt:8099.160\n",
      "Ep:194, loss:0.00000, loss_test:0.01862, lr:2.01e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.748, tt:8140.790\n",
      "Ep:195, loss:0.00000, loss_test:0.01863, lr:1.99e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.752, tt:8183.473\n",
      "Ep:196, loss:0.00000, loss_test:0.01863, lr:1.97e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.750, tt:8224.666\n",
      "Ep:197, loss:0.00000, loss_test:0.01866, lr:1.95e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.743, tt:8265.146\n",
      "Ep:198, loss:0.00000, loss_test:0.01875, lr:1.93e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.739, tt:8306.102\n",
      "Ep:199, loss:0.00000, loss_test:0.01872, lr:1.91e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.741, tt:8348.297\n",
      "Ep:200, loss:0.00000, loss_test:0.01871, lr:1.89e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.740, tt:8389.740\n",
      "Ep:201, loss:0.00000, loss_test:0.01874, lr:1.87e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.738, tt:8431.112\n",
      "Ep:202, loss:0.00000, loss_test:0.01875, lr:1.85e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.748, tt:8474.863\n",
      "Ep:203, loss:0.00000, loss_test:0.01879, lr:1.83e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.751, tt:8517.239\n",
      "Ep:204, loss:0.00000, loss_test:0.01881, lr:1.81e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.754, tt:8559.615\n",
      "Ep:205, loss:0.00000, loss_test:0.01881, lr:1.80e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.753, tt:8601.095\n",
      "Ep:206, loss:0.00000, loss_test:0.01884, lr:1.78e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.756, tt:8643.563\n",
      "Ep:207, loss:0.00000, loss_test:0.01885, lr:1.76e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.777, tt:8689.558\n",
      "Ep:208, loss:0.00000, loss_test:0.01887, lr:1.74e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.773, tt:8730.651\n",
      "Ep:209, loss:0.00000, loss_test:0.01888, lr:1.73e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.774, tt:8772.537\n",
      "Ep:210, loss:0.00000, loss_test:0.01890, lr:1.71e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.769, tt:8813.270\n",
      "Ep:211, loss:0.00000, loss_test:0.01888, lr:1.69e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.766, tt:8854.404\n",
      "Ep:212, loss:0.00000, loss_test:0.01892, lr:1.67e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.752, tt:8893.074\n",
      "Ep:213, loss:0.00000, loss_test:0.01895, lr:1.66e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.704, tt:8924.737\n",
      "Ep:214, loss:0.00000, loss_test:0.01898, lr:1.64e-02, fs:0.73759 (r=0.598,p=0.963),  time:41.677, tt:8960.568\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14386, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.491, tt:37.491\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14283, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.149, tt:76.299\n",
      "Ep:2, loss:0.00028, loss_test:0.14117, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.068, tt:117.204\n",
      "Ep:3, loss:0.00028, loss_test:0.13859, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:39.284, tt:157.137\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13432, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:39.947, tt:199.733\n",
      "Ep:5, loss:0.00026, loss_test:0.12771, lr:1.00e-02, fs:0.65587 (r=0.931,p=0.506),  time:40.303, tt:241.815\n",
      "Ep:6, loss:0.00025, loss_test:0.11816, lr:1.00e-02, fs:0.68122 (r=0.897,p=0.549),  time:40.320, tt:282.239\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10862, lr:1.00e-02, fs:0.70647 (r=0.816,p=0.623),  time:40.563, tt:324.503\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10089, lr:1.00e-02, fs:0.71658 (r=0.770,p=0.670),  time:40.799, tt:367.191\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09774, lr:1.00e-02, fs:0.74872 (r=0.839,p=0.676),  time:40.958, tt:409.579\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09428, lr:1.00e-02, fs:0.78495 (r=0.839,p=0.737),  time:40.955, tt:450.508\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09234, lr:1.00e-02, fs:0.76344 (r=0.816,p=0.717),  time:41.214, tt:494.573\n",
      "Ep:12, loss:0.00020, loss_test:0.08832, lr:1.00e-02, fs:0.77596 (r=0.816,p=0.740),  time:41.357, tt:537.643\n",
      "Ep:13, loss:0.00019, loss_test:0.08389, lr:1.00e-02, fs:0.78212 (r=0.805,p=0.761),  time:41.446, tt:580.238\n",
      "Ep:14, loss:0.00018, loss_test:0.08132, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:41.515, tt:622.729\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.07994, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:41.537, tt:664.594\n",
      "Ep:16, loss:0.00017, loss_test:0.07954, lr:1.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:41.484, tt:705.227\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.07644, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:41.673, tt:750.118\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.07533, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:41.693, tt:792.158\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.07411, lr:1.00e-02, fs:0.82222 (r=0.851,p=0.796),  time:41.648, tt:832.952\n",
      "Ep:20, loss:0.00015, loss_test:0.07311, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:41.673, tt:875.132\n",
      "Ep:21, loss:0.00014, loss_test:0.07139, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:41.675, tt:916.858\n",
      "Ep:22, loss:0.00013, loss_test:0.07068, lr:1.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:41.705, tt:959.222\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.06975, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:41.688, tt:1000.506\n",
      "Ep:24, loss:0.00012, loss_test:0.06828, lr:1.00e-02, fs:0.84153 (r=0.885,p=0.802),  time:41.720, tt:1042.994\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.06890, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:41.793, tt:1086.630\n",
      "Ep:26, loss:0.00011, loss_test:0.06763, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.815, tt:1129.004\n",
      "Ep:27, loss:0.00011, loss_test:0.06772, lr:1.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:41.805, tt:1170.551\n",
      "Ep:28, loss:0.00011, loss_test:0.06788, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:41.863, tt:1214.017\n",
      "Ep:29, loss:0.00010, loss_test:0.06444, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:41.836, tt:1255.087\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.06617, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:41.843, tt:1297.146\n",
      "Ep:31, loss:0.00009, loss_test:0.06677, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:41.900, tt:1340.797\n",
      "Ep:32, loss:0.00009, loss_test:0.06536, lr:1.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:41.925, tt:1383.531\n",
      "Ep:33, loss:0.00009, loss_test:0.06914, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:41.861, tt:1423.274\n",
      "Ep:34, loss:0.00008, loss_test:0.06312, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:41.879, tt:1465.777\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.07012, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:41.867, tt:1507.207\n",
      "Ep:36, loss:0.00008, loss_test:0.06277, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:41.880, tt:1549.551\n",
      "Ep:37, loss:0.00008, loss_test:0.06781, lr:1.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:41.850, tt:1590.290\n",
      "Ep:38, loss:0.00007, loss_test:0.06299, lr:1.00e-02, fs:0.86061 (r=0.816,p=0.910),  time:41.847, tt:1632.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00007, loss_test:0.06944, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:41.851, tt:1674.033\n",
      "Ep:40, loss:0.00007, loss_test:0.06533, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:41.841, tt:1715.484\n",
      "Ep:41, loss:0.00006, loss_test:0.06714, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:41.829, tt:1756.799\n",
      "Ep:42, loss:0.00006, loss_test:0.06838, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:41.828, tt:1798.598\n",
      "Ep:43, loss:0.00006, loss_test:0.06625, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:41.884, tt:1842.876\n",
      "Ep:44, loss:0.00006, loss_test:0.07160, lr:1.00e-02, fs:0.79739 (r=0.701,p=0.924),  time:41.861, tt:1883.767\n",
      "Ep:45, loss:0.00006, loss_test:0.06559, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:41.882, tt:1926.554\n",
      "Ep:46, loss:0.00005, loss_test:0.07622, lr:9.90e-03, fs:0.81290 (r=0.724,p=0.926),  time:41.834, tt:1966.176\n",
      "Ep:47, loss:0.00005, loss_test:0.06737, lr:9.80e-03, fs:0.79268 (r=0.747,p=0.844),  time:41.821, tt:2007.428\n",
      "Ep:48, loss:0.00005, loss_test:0.07047, lr:9.70e-03, fs:0.82803 (r=0.747,p=0.929),  time:41.791, tt:2047.744\n",
      "Ep:49, loss:0.00005, loss_test:0.07025, lr:9.61e-03, fs:0.78481 (r=0.713,p=0.873),  time:41.737, tt:2086.862\n",
      "Ep:50, loss:0.00005, loss_test:0.06973, lr:9.51e-03, fs:0.81529 (r=0.736,p=0.914),  time:41.728, tt:2128.117\n",
      "Ep:51, loss:0.00004, loss_test:0.07125, lr:9.41e-03, fs:0.82051 (r=0.736,p=0.928),  time:41.696, tt:2168.179\n",
      "Ep:52, loss:0.00004, loss_test:0.07194, lr:9.32e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.683, tt:2209.211\n",
      "Ep:53, loss:0.00004, loss_test:0.06612, lr:9.23e-03, fs:0.83544 (r=0.759,p=0.930),  time:41.659, tt:2249.574\n",
      "Ep:54, loss:0.00004, loss_test:0.07098, lr:9.14e-03, fs:0.78981 (r=0.713,p=0.886),  time:41.586, tt:2287.253\n",
      "Ep:55, loss:0.00004, loss_test:0.07069, lr:9.04e-03, fs:0.80000 (r=0.713,p=0.912),  time:41.567, tt:2327.756\n",
      "Ep:56, loss:0.00004, loss_test:0.07388, lr:8.95e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.573, tt:2369.674\n",
      "Ep:57, loss:0.00004, loss_test:0.07782, lr:8.86e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.539, tt:2409.236\n",
      "Ep:58, loss:0.00003, loss_test:0.07256, lr:8.78e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.516, tt:2449.427\n",
      "Ep:59, loss:0.00003, loss_test:0.07941, lr:8.69e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.503, tt:2490.198\n",
      "Ep:60, loss:0.00003, loss_test:0.07564, lr:8.60e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.498, tt:2531.382\n",
      "Ep:61, loss:0.00003, loss_test:0.07250, lr:8.51e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.489, tt:2572.344\n",
      "Ep:62, loss:0.00003, loss_test:0.08489, lr:8.43e-03, fs:0.71831 (r=0.586,p=0.927),  time:41.474, tt:2612.848\n",
      "Ep:63, loss:0.00003, loss_test:0.07078, lr:8.35e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.502, tt:2656.115\n",
      "Ep:64, loss:0.00003, loss_test:0.08350, lr:8.26e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.547, tt:2700.559\n",
      "Ep:65, loss:0.00003, loss_test:0.07710, lr:8.18e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.584, tt:2744.551\n",
      "Ep:66, loss:0.00002, loss_test:0.07954, lr:8.10e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.609, tt:2787.789\n",
      "Ep:67, loss:0.00002, loss_test:0.08036, lr:8.02e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.615, tt:2829.801\n",
      "Ep:68, loss:0.00002, loss_test:0.07757, lr:7.94e-03, fs:0.80263 (r=0.701,p=0.938),  time:41.635, tt:2872.842\n",
      "Ep:69, loss:0.00002, loss_test:0.08067, lr:7.86e-03, fs:0.72857 (r=0.586,p=0.962),  time:41.653, tt:2915.682\n",
      "Ep:70, loss:0.00002, loss_test:0.08933, lr:7.78e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.653, tt:2957.361\n",
      "Ep:71, loss:0.00002, loss_test:0.08131, lr:7.70e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.669, tt:3000.168\n",
      "Ep:72, loss:0.00002, loss_test:0.08286, lr:7.62e-03, fs:0.72222 (r=0.598,p=0.912),  time:41.677, tt:3042.395\n",
      "Ep:73, loss:0.00002, loss_test:0.08166, lr:7.55e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.721, tt:3087.321\n",
      "Ep:74, loss:0.00002, loss_test:0.08598, lr:7.47e-03, fs:0.71831 (r=0.586,p=0.927),  time:41.715, tt:3128.639\n",
      "Ep:75, loss:0.00002, loss_test:0.08912, lr:7.40e-03, fs:0.72857 (r=0.586,p=0.962),  time:41.709, tt:3169.916\n",
      "Ep:76, loss:0.00002, loss_test:0.08827, lr:7.32e-03, fs:0.71831 (r=0.586,p=0.927),  time:41.734, tt:3213.519\n",
      "Ep:77, loss:0.00002, loss_test:0.08270, lr:7.25e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.743, tt:3255.922\n",
      "Ep:78, loss:0.00002, loss_test:0.08787, lr:7.18e-03, fs:0.72857 (r=0.586,p=0.962),  time:41.770, tt:3299.828\n",
      "Ep:79, loss:0.00001, loss_test:0.08205, lr:7.11e-03, fs:0.71831 (r=0.586,p=0.927),  time:41.792, tt:3343.326\n",
      "Ep:80, loss:0.00002, loss_test:0.08232, lr:7.03e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.815, tt:3386.980\n",
      "Ep:81, loss:0.00001, loss_test:0.08473, lr:6.96e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.813, tt:3428.683\n",
      "Ep:82, loss:0.00001, loss_test:0.08744, lr:6.89e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.838, tt:3472.529\n",
      "Ep:83, loss:0.00001, loss_test:0.08335, lr:6.83e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.872, tt:3517.211\n",
      "Ep:84, loss:0.00001, loss_test:0.08935, lr:6.76e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.879, tt:3559.741\n",
      "Ep:85, loss:0.00001, loss_test:0.08791, lr:6.69e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.863, tt:3600.228\n",
      "Ep:86, loss:0.00001, loss_test:0.08839, lr:6.62e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.888, tt:3644.213\n",
      "Ep:87, loss:0.00001, loss_test:0.09133, lr:6.56e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.886, tt:3685.988\n",
      "Ep:88, loss:0.00001, loss_test:0.08570, lr:6.49e-03, fs:0.71831 (r=0.586,p=0.927),  time:41.879, tt:3727.265\n",
      "Ep:89, loss:0.00001, loss_test:0.08679, lr:6.43e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.882, tt:3769.411\n",
      "Ep:90, loss:0.00001, loss_test:0.08986, lr:6.36e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.893, tt:3812.247\n",
      "Ep:91, loss:0.00001, loss_test:0.08491, lr:6.30e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.889, tt:3853.822\n",
      "Ep:92, loss:0.00001, loss_test:0.09099, lr:6.24e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.892, tt:3895.924\n",
      "Ep:93, loss:0.00001, loss_test:0.08671, lr:6.17e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.879, tt:3936.599\n",
      "Ep:94, loss:0.00001, loss_test:0.08816, lr:6.11e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.884, tt:3978.980\n",
      "Ep:95, loss:0.00001, loss_test:0.08936, lr:6.05e-03, fs:0.72857 (r=0.586,p=0.962),  time:41.882, tt:4020.681\n",
      "Ep:96, loss:0.00001, loss_test:0.08966, lr:5.99e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.863, tt:4060.744\n",
      "Ep:97, loss:0.00001, loss_test:0.08795, lr:5.93e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.857, tt:4102.014\n",
      "Ep:98, loss:0.00001, loss_test:0.08916, lr:5.87e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.832, tt:4141.386\n",
      "Ep:99, loss:0.00001, loss_test:0.08661, lr:5.81e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.845, tt:4184.520\n",
      "Ep:100, loss:0.00001, loss_test:0.09053, lr:5.75e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.850, tt:4226.838\n",
      "Ep:101, loss:0.00001, loss_test:0.08824, lr:5.70e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.841, tt:4267.798\n",
      "Ep:102, loss:0.00001, loss_test:0.08901, lr:5.64e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.834, tt:4308.953\n",
      "Ep:103, loss:0.00001, loss_test:0.08966, lr:5.58e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.814, tt:4348.686\n",
      "Ep:104, loss:0.00001, loss_test:0.08757, lr:5.53e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.797, tt:4388.680\n",
      "Ep:105, loss:0.00001, loss_test:0.09106, lr:5.47e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.796, tt:4430.364\n",
      "Ep:106, loss:0.00001, loss_test:0.08875, lr:5.42e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.787, tt:4471.210\n",
      "Ep:107, loss:0.00001, loss_test:0.09274, lr:5.36e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.795, tt:4513.852\n",
      "Ep:108, loss:0.00001, loss_test:0.09115, lr:5.31e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.795, tt:4555.675\n",
      "Ep:109, loss:0.00001, loss_test:0.08845, lr:5.26e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.780, tt:4595.825\n",
      "Ep:110, loss:0.00000, loss_test:0.08999, lr:5.20e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.771, tt:4636.592\n",
      "Ep:111, loss:0.00000, loss_test:0.08799, lr:5.15e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.772, tt:4678.491\n",
      "Ep:112, loss:0.00000, loss_test:0.09093, lr:5.10e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.764, tt:4719.302\n",
      "Ep:113, loss:0.00000, loss_test:0.09055, lr:5.05e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.773, tt:4762.104\n",
      "Ep:114, loss:0.00000, loss_test:0.09017, lr:5.00e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.770, tt:4803.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00000, loss_test:0.08876, lr:4.95e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.767, tt:4844.930\n",
      "Ep:116, loss:0.00000, loss_test:0.09124, lr:4.90e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.753, tt:4885.073\n",
      "Ep:117, loss:0.00000, loss_test:0.09137, lr:4.85e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.734, tt:4924.596\n",
      "Ep:118, loss:0.00000, loss_test:0.08876, lr:4.80e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.722, tt:4964.902\n",
      "Ep:119, loss:0.00000, loss_test:0.09049, lr:4.75e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.709, tt:5005.105\n",
      "Ep:120, loss:0.00000, loss_test:0.09194, lr:4.71e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.717, tt:5047.735\n",
      "Ep:121, loss:0.00000, loss_test:0.09026, lr:4.66e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.706, tt:5088.174\n",
      "Ep:122, loss:0.00000, loss_test:0.08790, lr:4.61e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.688, tt:5127.656\n",
      "Ep:123, loss:0.00000, loss_test:0.09074, lr:4.57e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.687, tt:5169.173\n",
      "Ep:124, loss:0.00000, loss_test:0.08957, lr:4.52e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.665, tt:5208.147\n",
      "Ep:125, loss:0.00000, loss_test:0.08921, lr:4.48e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.644, tt:5247.132\n",
      "Ep:126, loss:0.00000, loss_test:0.09073, lr:4.43e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.643, tt:5288.675\n",
      "Ep:127, loss:0.00000, loss_test:0.08868, lr:4.39e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.628, tt:5328.357\n",
      "Ep:128, loss:0.00000, loss_test:0.08885, lr:4.34e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.623, tt:5369.349\n",
      "Ep:129, loss:0.00000, loss_test:0.08877, lr:4.30e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.605, tt:5408.644\n",
      "Ep:130, loss:0.00000, loss_test:0.08931, lr:4.26e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.606, tt:5450.431\n",
      "Ep:131, loss:0.00000, loss_test:0.08875, lr:4.21e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.607, tt:5492.091\n",
      "Ep:132, loss:0.00000, loss_test:0.09033, lr:4.17e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.636, tt:5537.646\n",
      "Ep:133, loss:0.00000, loss_test:0.08857, lr:4.13e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.628, tt:5578.180\n",
      "Ep:134, loss:0.00000, loss_test:0.08868, lr:4.09e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.635, tt:5620.715\n",
      "Ep:135, loss:0.00000, loss_test:0.08939, lr:4.05e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.644, tt:5663.591\n",
      "Ep:136, loss:0.00000, loss_test:0.08878, lr:4.01e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.634, tt:5703.882\n",
      "Ep:137, loss:0.00000, loss_test:0.08964, lr:3.97e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.626, tt:5744.395\n",
      "Ep:138, loss:0.00000, loss_test:0.08692, lr:3.93e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.616, tt:5784.679\n",
      "Ep:139, loss:0.00000, loss_test:0.08973, lr:3.89e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.615, tt:5826.092\n",
      "Ep:140, loss:0.00000, loss_test:0.08866, lr:3.85e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.619, tt:5868.322\n",
      "Ep:141, loss:0.00000, loss_test:0.08831, lr:3.81e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.628, tt:5911.176\n",
      "Ep:142, loss:0.00000, loss_test:0.09074, lr:3.77e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.611, tt:5950.434\n",
      "Ep:143, loss:0.00000, loss_test:0.08902, lr:3.73e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.603, tt:5990.835\n",
      "Ep:144, loss:0.00000, loss_test:0.08830, lr:3.70e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.584, tt:6029.696\n",
      "Ep:145, loss:0.00000, loss_test:0.08859, lr:3.66e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.602, tt:6073.924\n",
      "Ep:146, loss:0.00000, loss_test:0.09052, lr:3.62e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.601, tt:6115.355\n",
      "Ep:147, loss:0.00000, loss_test:0.09060, lr:3.59e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.602, tt:6157.071\n",
      "Ep:148, loss:0.00000, loss_test:0.08871, lr:3.55e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.599, tt:6198.278\n",
      "Ep:149, loss:0.00000, loss_test:0.08816, lr:3.52e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.596, tt:6239.374\n",
      "Ep:150, loss:0.00000, loss_test:0.08753, lr:3.48e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.588, tt:6279.724\n",
      "Ep:151, loss:0.00000, loss_test:0.09003, lr:3.45e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.591, tt:6321.818\n",
      "Ep:152, loss:0.00000, loss_test:0.08911, lr:3.41e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.593, tt:6363.769\n",
      "Ep:153, loss:0.00000, loss_test:0.08772, lr:3.38e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.618, tt:6409.115\n",
      "Ep:154, loss:0.00000, loss_test:0.08950, lr:3.34e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.607, tt:6449.149\n",
      "Ep:155, loss:0.00000, loss_test:0.08956, lr:3.31e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.615, tt:6491.934\n",
      "Ep:156, loss:0.00000, loss_test:0.08821, lr:3.28e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.613, tt:6533.252\n",
      "Ep:157, loss:0.00000, loss_test:0.08799, lr:3.24e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.613, tt:6574.796\n",
      "Ep:158, loss:0.00000, loss_test:0.08792, lr:3.21e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.624, tt:6618.186\n",
      "Ep:159, loss:0.00000, loss_test:0.08808, lr:3.18e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.630, tt:6660.742\n",
      "Ep:160, loss:0.00000, loss_test:0.08779, lr:3.15e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.615, tt:6699.949\n",
      "Ep:161, loss:0.00000, loss_test:0.08793, lr:3.12e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.623, tt:6742.950\n",
      "Ep:162, loss:0.00000, loss_test:0.08895, lr:3.09e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.626, tt:6784.958\n",
      "Ep:163, loss:0.00000, loss_test:0.08813, lr:3.05e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.636, tt:6828.314\n",
      "Ep:164, loss:0.00000, loss_test:0.08701, lr:3.02e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.637, tt:6870.068\n",
      "Ep:165, loss:0.00000, loss_test:0.08997, lr:2.99e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.641, tt:6912.331\n",
      "Ep:166, loss:0.00000, loss_test:0.08960, lr:2.96e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.642, tt:6954.162\n",
      "Ep:167, loss:0.00000, loss_test:0.08738, lr:2.93e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.643, tt:6995.977\n",
      "Ep:168, loss:0.00000, loss_test:0.08868, lr:2.90e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.650, tt:7038.786\n",
      "Ep:169, loss:0.00000, loss_test:0.08912, lr:2.88e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.643, tt:7079.374\n",
      "Ep:170, loss:0.00000, loss_test:0.08818, lr:2.85e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.641, tt:7120.609\n",
      "Ep:171, loss:0.00000, loss_test:0.08855, lr:2.82e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.629, tt:7160.140\n",
      "Ep:172, loss:0.00000, loss_test:0.08811, lr:2.79e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.630, tt:7201.924\n",
      "Ep:173, loss:0.00000, loss_test:0.08924, lr:2.76e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.653, tt:7247.639\n",
      "Ep:174, loss:0.00000, loss_test:0.08978, lr:2.73e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.652, tt:7289.033\n",
      "Ep:175, loss:0.00000, loss_test:0.08897, lr:2.71e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.654, tt:7331.177\n",
      "Ep:176, loss:0.00000, loss_test:0.08834, lr:2.68e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.644, tt:7371.061\n",
      "Ep:177, loss:0.00000, loss_test:0.08802, lr:2.65e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.657, tt:7414.868\n",
      "Ep:178, loss:0.00000, loss_test:0.08767, lr:2.63e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.657, tt:7456.618\n",
      "Ep:179, loss:0.00000, loss_test:0.08770, lr:2.60e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.666, tt:7499.942\n",
      "Ep:180, loss:0.00000, loss_test:0.08726, lr:2.57e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.665, tt:7541.448\n",
      "Ep:181, loss:0.00000, loss_test:0.08831, lr:2.55e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.666, tt:7583.183\n",
      "Ep:182, loss:0.00000, loss_test:0.08874, lr:2.52e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.668, tt:7625.297\n",
      "Ep:183, loss:0.00000, loss_test:0.08805, lr:2.50e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.675, tt:7668.156\n",
      "Ep:184, loss:0.00000, loss_test:0.08816, lr:2.47e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.673, tt:7709.446\n",
      "Ep:185, loss:0.00000, loss_test:0.08753, lr:2.45e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.682, tt:7752.762\n",
      "Ep:186, loss:0.00000, loss_test:0.08693, lr:2.42e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.680, tt:7794.114\n",
      "Ep:187, loss:0.00000, loss_test:0.08810, lr:2.40e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.674, tt:7834.765\n",
      "Ep:188, loss:0.00000, loss_test:0.08856, lr:2.38e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.676, tt:7876.812\n",
      "Ep:189, loss:0.00000, loss_test:0.08762, lr:2.35e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.683, tt:7919.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.08697, lr:2.33e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.682, tt:7961.241\n",
      "Ep:191, loss:0.00000, loss_test:0.08731, lr:2.31e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.687, tt:8003.866\n",
      "Ep:192, loss:0.00000, loss_test:0.08838, lr:2.28e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.678, tt:8043.800\n",
      "Ep:193, loss:0.00000, loss_test:0.08851, lr:2.26e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.682, tt:8086.395\n",
      "Ep:194, loss:0.00000, loss_test:0.08812, lr:2.24e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.677, tt:8126.919\n",
      "Ep:195, loss:0.00000, loss_test:0.08707, lr:2.21e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.679, tt:8169.178\n",
      "Ep:196, loss:0.00000, loss_test:0.08656, lr:2.19e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.673, tt:8209.498\n",
      "Ep:197, loss:0.00000, loss_test:0.08779, lr:2.17e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.673, tt:8251.156\n",
      "Ep:198, loss:0.00000, loss_test:0.08786, lr:2.15e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.674, tt:8293.202\n",
      "Ep:199, loss:0.00000, loss_test:0.08710, lr:2.13e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.673, tt:8334.525\n",
      "Ep:200, loss:0.00000, loss_test:0.08646, lr:2.11e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.674, tt:8376.569\n",
      "Ep:201, loss:0.00000, loss_test:0.08629, lr:2.08e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.660, tt:8415.260\n",
      "Ep:202, loss:0.00000, loss_test:0.08746, lr:2.06e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.661, tt:8457.234\n",
      "Ep:203, loss:0.00000, loss_test:0.08765, lr:2.04e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.670, tt:8500.581\n",
      "Ep:204, loss:0.00000, loss_test:0.08721, lr:2.02e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.672, tt:8542.852\n",
      "Ep:205, loss:0.00000, loss_test:0.08659, lr:2.00e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.673, tt:8584.565\n",
      "Ep:206, loss:0.00000, loss_test:0.08648, lr:1.98e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.675, tt:8626.768\n",
      "Ep:207, loss:0.00000, loss_test:0.08718, lr:1.96e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.674, tt:8668.234\n",
      "Ep:208, loss:0.00000, loss_test:0.08689, lr:1.94e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.676, tt:8710.383\n",
      "Ep:209, loss:0.00000, loss_test:0.08667, lr:1.92e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.685, tt:8753.903\n",
      "Ep:210, loss:0.00000, loss_test:0.08695, lr:1.90e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.685, tt:8795.548\n",
      "Ep:211, loss:0.00000, loss_test:0.08663, lr:1.89e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.695, tt:8839.284\n",
      "Ep:212, loss:0.00000, loss_test:0.08691, lr:1.87e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.688, tt:8879.456\n",
      "Ep:213, loss:0.00000, loss_test:0.08705, lr:1.85e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.640, tt:8911.035\n",
      "Ep:214, loss:0.00000, loss_test:0.08659, lr:1.83e-03, fs:0.72340 (r=0.586,p=0.944),  time:41.543, tt:8931.704\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02053, lr:6.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:36.619, tt:36.619\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02324, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:38.666, tt:77.332\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.124, tt:117.373\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02297, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.165, tt:156.662\n",
      "Ep:4, loss:0.00004, loss_test:0.02163, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:39.239, tt:196.193\n",
      "Ep:5, loss:0.00004, loss_test:0.02053, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:39.166, tt:234.994\n",
      "Ep:6, loss:0.00004, loss_test:0.02026, lr:6.00e-02, fs:0.64754 (r=0.798,p=0.545),  time:39.216, tt:274.509\n",
      "Ep:7, loss:0.00004, loss_test:0.02044, lr:6.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:39.304, tt:314.429\n",
      "Ep:8, loss:0.00004, loss_test:0.02032, lr:6.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:39.492, tt:355.427\n",
      "Ep:9, loss:0.00004, loss_test:0.02010, lr:6.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:39.385, tt:393.851\n",
      "Ep:10, loss:0.00003, loss_test:0.01994, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:39.424, tt:433.665\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01973, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:39.488, tt:473.852\n",
      "Ep:12, loss:0.00003, loss_test:0.01950, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:39.626, tt:515.136\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01934, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:39.523, tt:553.322\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01906, lr:6.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:39.646, tt:594.692\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01856, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:39.590, tt:633.438\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:39.589, tt:673.011\n",
      "Ep:17, loss:0.00003, loss_test:0.01746, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:39.576, tt:712.375\n",
      "Ep:18, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:39.509, tt:750.670\n",
      "Ep:19, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:39.465, tt:789.295\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:39.307, tt:825.451\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:39.283, tt:864.231\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01629, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:39.268, tt:903.174\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:39.269, tt:942.457\n",
      "Ep:24, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:39.223, tt:980.584\n",
      "Ep:25, loss:0.00002, loss_test:0.01585, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:39.223, tt:1019.799\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:39.191, tt:1058.163\n",
      "Ep:27, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:39.140, tt:1095.912\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01518, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:39.145, tt:1135.205\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01503, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:39.131, tt:1173.916\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:39.096, tt:1211.974\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01489, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:39.109, tt:1251.476\n",
      "Ep:32, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:39.133, tt:1291.375\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:39.199, tt:1332.751\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:39.169, tt:1370.932\n",
      "Ep:35, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:39.168, tt:1410.056\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01440, lr:6.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:39.152, tt:1448.628\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01427, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:39.156, tt:1487.941\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01423, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:39.197, tt:1528.682\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01420, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.249, tt:1569.941\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.296, tt:1611.116\n",
      "Ep:41, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.338, tt:1652.209\n",
      "Ep:42, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.378, tt:1693.269\n",
      "Ep:43, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.405, tt:1733.807\n",
      "Ep:44, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.344, tt:1770.473\n",
      "Ep:45, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.306, tt:1808.097\n",
      "Ep:46, loss:0.00001, loss_test:0.01383, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.336, tt:1848.803\n",
      "Ep:47, loss:0.00001, loss_test:0.01404, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:39.376, tt:1890.037\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01388, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:39.391, tt:1930.154\n",
      "Ep:49, loss:0.00001, loss_test:0.01382, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:39.380, tt:1969.012\n",
      "Ep:50, loss:0.00001, loss_test:0.01393, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:39.361, tt:2007.435\n",
      "Ep:51, loss:0.00001, loss_test:0.01397, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:39.389, tt:2048.230\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01391, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:39.411, tt:2088.795\n",
      "Ep:53, loss:0.00001, loss_test:0.01392, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:39.418, tt:2128.592\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01396, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:39.427, tt:2168.506\n",
      "Ep:55, loss:0.00001, loss_test:0.01391, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:39.425, tt:2207.821\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01402, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:39.428, tt:2247.372\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01406, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:39.473, tt:2289.459\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01400, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:39.491, tt:2329.993\n",
      "Ep:59, loss:0.00001, loss_test:0.01399, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:39.496, tt:2369.733\n",
      "Ep:60, loss:0.00001, loss_test:0.01406, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:39.541, tt:2411.976\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01405, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:39.588, tt:2454.450\n",
      "Ep:62, loss:0.00001, loss_test:0.01405, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:39.617, tt:2495.877\n",
      "Ep:63, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:39.646, tt:2537.313\n",
      "Ep:64, loss:0.00001, loss_test:0.01423, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:39.685, tt:2579.520\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01415, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:39.711, tt:2620.937\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01437, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:39.723, tt:2661.463\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01426, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:39.746, tt:2702.714\n",
      "Ep:68, loss:0.00001, loss_test:0.01432, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:39.751, tt:2742.847\n",
      "Ep:69, loss:0.00001, loss_test:0.01434, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:39.769, tt:2783.851\n",
      "Ep:70, loss:0.00001, loss_test:0.01441, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:39.773, tt:2823.865\n",
      "Ep:71, loss:0.00001, loss_test:0.01442, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:39.764, tt:2863.011\n",
      "Ep:72, loss:0.00001, loss_test:0.01444, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:39.821, tt:2906.955\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01455, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:39.856, tt:2949.363\n",
      "Ep:74, loss:0.00001, loss_test:0.01452, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:39.859, tt:2989.460\n",
      "Ep:75, loss:0.00001, loss_test:0.01458, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:39.881, tt:3030.943\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01465, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:39.874, tt:3070.335\n",
      "Ep:77, loss:0.00001, loss_test:0.01468, lr:6.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:39.905, tt:3112.585\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01458, lr:6.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:39.932, tt:3154.591\n",
      "Ep:79, loss:0.00001, loss_test:0.01481, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:39.966, tt:3197.275\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01474, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:40.006, tt:3240.459\n",
      "Ep:81, loss:0.00001, loss_test:0.01493, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:40.021, tt:3281.742\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01486, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:40.020, tt:3321.682\n",
      "Ep:83, loss:0.00001, loss_test:0.01480, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:40.047, tt:3363.916\n",
      "Ep:84, loss:0.00001, loss_test:0.01501, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:40.057, tt:3404.828\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01502, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:40.123, tt:3450.575\n",
      "Ep:86, loss:0.00001, loss_test:0.01500, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:40.141, tt:3492.241\n",
      "Ep:87, loss:0.00001, loss_test:0.01508, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:40.127, tt:3531.139\n",
      "Ep:88, loss:0.00001, loss_test:0.01505, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:40.128, tt:3571.390\n",
      "Ep:89, loss:0.00001, loss_test:0.01509, lr:6.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:40.129, tt:3611.606\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01529, lr:6.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:40.136, tt:3652.344\n",
      "Ep:91, loss:0.00001, loss_test:0.01528, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.152, tt:3693.986\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01523, lr:6.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:40.159, tt:3734.816\n",
      "Ep:93, loss:0.00001, loss_test:0.01539, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.176, tt:3776.550\n",
      "Ep:94, loss:0.00001, loss_test:0.01551, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.182, tt:3817.333\n",
      "Ep:95, loss:0.00001, loss_test:0.01547, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.177, tt:3856.973\n",
      "Ep:96, loss:0.00001, loss_test:0.01545, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.192, tt:3898.605\n",
      "Ep:97, loss:0.00001, loss_test:0.01543, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.174, tt:3937.060\n",
      "Ep:98, loss:0.00001, loss_test:0.01569, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.159, tt:3975.762\n",
      "Ep:99, loss:0.00001, loss_test:0.01559, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.161, tt:4016.073\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01570, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.178, tt:4057.935\n",
      "Ep:101, loss:0.00001, loss_test:0.01582, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.184, tt:4098.723\n",
      "Ep:102, loss:0.00001, loss_test:0.01579, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.187, tt:4139.244\n",
      "Ep:103, loss:0.00001, loss_test:0.01579, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.179, tt:4178.659\n",
      "Ep:104, loss:0.00001, loss_test:0.01577, lr:6.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:40.175, tt:4218.391\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01599, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.162, tt:4257.216\n",
      "Ep:106, loss:0.00001, loss_test:0.01603, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.208, tt:4302.298\n",
      "Ep:107, loss:0.00000, loss_test:0.01602, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.221, tt:4343.874\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.01600, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:40.229, tt:4384.908\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.01617, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.246, tt:4427.101\n",
      "Ep:110, loss:0.00000, loss_test:0.01620, lr:6.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:40.235, tt:4466.123\n",
      "Ep:111, loss:0.00000, loss_test:0.01624, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.224, tt:4505.124\n",
      "Ep:112, loss:0.00000, loss_test:0.01636, lr:6.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:40.237, tt:4546.775\n",
      "Ep:113, loss:0.00000, loss_test:0.01637, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.243, tt:4587.675\n",
      "Ep:114, loss:0.00000, loss_test:0.01641, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.245, tt:4628.120\n",
      "Ep:115, loss:0.00000, loss_test:0.01657, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.255, tt:4669.595\n",
      "Ep:116, loss:0.00000, loss_test:0.01660, lr:6.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:40.243, tt:4708.465\n",
      "Ep:117, loss:0.00000, loss_test:0.01654, lr:6.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:40.234, tt:4747.606\n",
      "Ep:118, loss:0.00000, loss_test:0.01674, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.235, tt:4788.012\n",
      "Ep:119, loss:0.00000, loss_test:0.01673, lr:6.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.242, tt:4829.006\n",
      "Ep:120, loss:0.00000, loss_test:0.01679, lr:5.94e-02, fs:0.90155 (r=0.879,p=0.926),  time:40.228, tt:4867.561\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00000, loss_test:0.01670, lr:5.94e-02, fs:0.89691 (r=0.879,p=0.916),  time:40.242, tt:4909.495\n",
      "Ep:122, loss:0.00000, loss_test:0.01705, lr:5.94e-02, fs:0.89583 (r=0.869,p=0.925),  time:40.239, tt:4949.401\n",
      "Ep:123, loss:0.00000, loss_test:0.01698, lr:5.94e-02, fs:0.90155 (r=0.879,p=0.926),  time:40.227, tt:4988.130\n",
      "Ep:124, loss:0.00000, loss_test:0.01690, lr:5.94e-02, fs:0.90155 (r=0.879,p=0.926),  time:40.227, tt:5028.387\n",
      "Ep:125, loss:0.00000, loss_test:0.01708, lr:5.94e-02, fs:0.90625 (r=0.879,p=0.935),  time:40.232, tt:5069.228\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00000, loss_test:0.01722, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.222, tt:5108.159\n",
      "Ep:127, loss:0.00000, loss_test:0.01726, lr:5.94e-02, fs:0.90052 (r=0.869,p=0.935),  time:40.211, tt:5146.968\n",
      "Ep:128, loss:0.00000, loss_test:0.01731, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.211, tt:5187.158\n",
      "Ep:129, loss:0.00000, loss_test:0.01736, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.209, tt:5227.185\n",
      "Ep:130, loss:0.00000, loss_test:0.01752, lr:5.94e-02, fs:0.90052 (r=0.869,p=0.935),  time:40.217, tt:5268.405\n",
      "Ep:131, loss:0.00000, loss_test:0.01742, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.219, tt:5308.896\n",
      "Ep:132, loss:0.00000, loss_test:0.01764, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.213, tt:5348.366\n",
      "Ep:133, loss:0.00000, loss_test:0.01759, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.226, tt:5390.344\n",
      "Ep:134, loss:0.00000, loss_test:0.01767, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.235, tt:5431.671\n",
      "Ep:135, loss:0.00000, loss_test:0.01778, lr:5.94e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.236, tt:5472.150\n",
      "Ep:136, loss:0.00000, loss_test:0.01781, lr:5.94e-02, fs:0.89474 (r=0.859,p=0.934),  time:40.231, tt:5511.650\n",
      "Ep:137, loss:0.00000, loss_test:0.01783, lr:5.88e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.235, tt:5552.461\n",
      "Ep:138, loss:0.00000, loss_test:0.01793, lr:5.82e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.230, tt:5591.990\n",
      "Ep:139, loss:0.00000, loss_test:0.01790, lr:5.76e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.236, tt:5633.017\n",
      "Ep:140, loss:0.00000, loss_test:0.01806, lr:5.71e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.235, tt:5673.160\n",
      "Ep:141, loss:0.00000, loss_test:0.01811, lr:5.65e-02, fs:0.87701 (r=0.828,p=0.932),  time:40.239, tt:5713.949\n",
      "Ep:142, loss:0.00000, loss_test:0.01811, lr:5.59e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.233, tt:5753.296\n",
      "Ep:143, loss:0.00000, loss_test:0.01827, lr:5.54e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.229, tt:5792.911\n",
      "Ep:144, loss:0.00000, loss_test:0.01815, lr:5.48e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.240, tt:5834.861\n",
      "Ep:145, loss:0.00000, loss_test:0.01842, lr:5.43e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.247, tt:5876.074\n",
      "Ep:146, loss:0.00000, loss_test:0.01829, lr:5.37e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.251, tt:5916.869\n",
      "Ep:147, loss:0.00000, loss_test:0.01843, lr:5.32e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.257, tt:5958.096\n",
      "Ep:148, loss:0.00000, loss_test:0.01848, lr:5.27e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.265, tt:5999.435\n",
      "Ep:149, loss:0.00000, loss_test:0.01851, lr:5.21e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.265, tt:6039.754\n",
      "Ep:150, loss:0.00000, loss_test:0.01867, lr:5.16e-02, fs:0.86486 (r=0.808,p=0.930),  time:40.267, tt:6080.326\n",
      "Ep:151, loss:0.00000, loss_test:0.01857, lr:5.11e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.275, tt:6121.845\n",
      "Ep:152, loss:0.00000, loss_test:0.01867, lr:5.06e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.284, tt:6163.511\n",
      "Ep:153, loss:0.00000, loss_test:0.01875, lr:5.01e-02, fs:0.85870 (r=0.798,p=0.929),  time:40.273, tt:6202.087\n",
      "Ep:154, loss:0.00000, loss_test:0.01875, lr:4.96e-02, fs:0.87097 (r=0.818,p=0.931),  time:40.279, tt:6243.246\n",
      "Ep:155, loss:0.00000, loss_test:0.01882, lr:4.91e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.279, tt:6283.489\n",
      "Ep:156, loss:0.00000, loss_test:0.01894, lr:4.86e-02, fs:0.84615 (r=0.778,p=0.928),  time:40.286, tt:6324.829\n",
      "Ep:157, loss:0.00000, loss_test:0.01883, lr:4.81e-02, fs:0.85246 (r=0.788,p=0.929),  time:40.285, tt:6364.988\n",
      "Ep:158, loss:0.00000, loss_test:0.01903, lr:4.76e-02, fs:0.84615 (r=0.778,p=0.928),  time:40.282, tt:6404.801\n",
      "Ep:159, loss:0.00000, loss_test:0.01908, lr:4.71e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.288, tt:6446.060\n",
      "Ep:160, loss:0.00000, loss_test:0.01907, lr:4.67e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.301, tt:6488.467\n",
      "Ep:161, loss:0.00000, loss_test:0.01910, lr:4.62e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.292, tt:6527.236\n",
      "Ep:162, loss:0.00000, loss_test:0.01921, lr:4.57e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.301, tt:6569.079\n",
      "Ep:163, loss:0.00000, loss_test:0.01924, lr:4.53e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.298, tt:6608.939\n",
      "Ep:164, loss:0.00000, loss_test:0.01927, lr:4.48e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.299, tt:6649.317\n",
      "Ep:165, loss:0.00000, loss_test:0.01927, lr:4.44e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.300, tt:6689.819\n",
      "Ep:166, loss:0.00000, loss_test:0.01934, lr:4.39e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.301, tt:6730.294\n",
      "Ep:167, loss:0.00000, loss_test:0.01938, lr:4.35e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.298, tt:6770.086\n",
      "Ep:168, loss:0.00000, loss_test:0.01940, lr:4.31e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.298, tt:6810.433\n",
      "Ep:169, loss:0.00000, loss_test:0.01948, lr:4.26e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.311, tt:6852.803\n",
      "Ep:170, loss:0.00000, loss_test:0.01945, lr:4.22e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.310, tt:6893.016\n",
      "Ep:171, loss:0.00000, loss_test:0.01953, lr:4.18e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.312, tt:6933.685\n",
      "Ep:172, loss:0.00000, loss_test:0.01960, lr:4.14e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.309, tt:6973.505\n",
      "Ep:173, loss:0.00000, loss_test:0.01967, lr:4.10e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.298, tt:7011.821\n",
      "Ep:174, loss:0.00000, loss_test:0.01969, lr:4.05e-02, fs:0.83799 (r=0.758,p=0.938),  time:40.293, tt:7051.314\n",
      "Ep:175, loss:0.00000, loss_test:0.01972, lr:4.01e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.289, tt:7090.925\n",
      "Ep:176, loss:0.00000, loss_test:0.01981, lr:3.97e-02, fs:0.83799 (r=0.758,p=0.938),  time:40.287, tt:7130.744\n",
      "Ep:177, loss:0.00000, loss_test:0.01981, lr:3.93e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.333, tt:7179.239\n",
      "Ep:178, loss:0.00000, loss_test:0.01976, lr:3.89e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.336, tt:7220.231\n",
      "Ep:179, loss:0.00000, loss_test:0.01990, lr:3.86e-02, fs:0.83799 (r=0.758,p=0.938),  time:40.339, tt:7261.017\n",
      "Ep:180, loss:0.00000, loss_test:0.01991, lr:3.82e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.356, tt:7304.504\n",
      "Ep:181, loss:0.00000, loss_test:0.01997, lr:3.78e-02, fs:0.81609 (r=0.717,p=0.947),  time:40.368, tt:7346.927\n",
      "Ep:182, loss:0.00000, loss_test:0.01992, lr:3.74e-02, fs:0.83146 (r=0.747,p=0.937),  time:40.377, tt:7388.902\n",
      "Ep:183, loss:0.00000, loss_test:0.02001, lr:3.70e-02, fs:0.81818 (r=0.727,p=0.935),  time:40.381, tt:7430.017\n",
      "Ep:184, loss:0.00000, loss_test:0.02008, lr:3.67e-02, fs:0.81818 (r=0.727,p=0.935),  time:40.376, tt:7469.568\n",
      "Ep:185, loss:0.00000, loss_test:0.02005, lr:3.63e-02, fs:0.81818 (r=0.727,p=0.935),  time:40.382, tt:7511.069\n",
      "Ep:186, loss:0.00000, loss_test:0.02012, lr:3.59e-02, fs:0.80233 (r=0.697,p=0.945),  time:40.389, tt:7552.715\n",
      "Ep:187, loss:0.00000, loss_test:0.02022, lr:3.56e-02, fs:0.79070 (r=0.687,p=0.932),  time:40.397, tt:7594.675\n",
      "Ep:188, loss:0.00000, loss_test:0.02022, lr:3.52e-02, fs:0.76190 (r=0.646,p=0.928),  time:40.407, tt:7636.897\n",
      "Ep:189, loss:0.00000, loss_test:0.02027, lr:3.49e-02, fs:0.77647 (r=0.667,p=0.930),  time:40.417, tt:7679.244\n",
      "Ep:190, loss:0.00000, loss_test:0.02031, lr:3.45e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.411, tt:7718.453\n",
      "Ep:191, loss:0.00000, loss_test:0.02033, lr:3.42e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.421, tt:7760.816\n",
      "Ep:192, loss:0.00000, loss_test:0.02032, lr:3.38e-02, fs:0.76923 (r=0.657,p=0.929),  time:40.419, tt:7800.959\n",
      "Ep:193, loss:0.00000, loss_test:0.02044, lr:3.35e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.429, tt:7843.313\n",
      "Ep:194, loss:0.00000, loss_test:0.02040, lr:3.32e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.431, tt:7884.095\n",
      "Ep:195, loss:0.00000, loss_test:0.02044, lr:3.28e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.439, tt:7926.078\n",
      "Ep:196, loss:0.00000, loss_test:0.02049, lr:3.25e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.442, tt:7967.036\n",
      "Ep:197, loss:0.00000, loss_test:0.02048, lr:3.22e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.447, tt:8008.603\n",
      "Ep:198, loss:0.00000, loss_test:0.02053, lr:3.19e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.445, tt:8048.526\n",
      "Ep:199, loss:0.00000, loss_test:0.02059, lr:3.15e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.446, tt:8089.232\n",
      "Ep:200, loss:0.00000, loss_test:0.02054, lr:3.12e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.455, tt:8131.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:201, loss:0.00000, loss_test:0.02056, lr:3.09e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.448, tt:8170.443\n",
      "Ep:202, loss:0.00000, loss_test:0.02062, lr:3.06e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.453, tt:8212.009\n",
      "Ep:203, loss:0.00000, loss_test:0.02066, lr:3.03e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.453, tt:8252.438\n",
      "Ep:204, loss:0.00000, loss_test:0.02066, lr:3.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.442, tt:8290.709\n",
      "Ep:205, loss:0.00000, loss_test:0.02071, lr:2.97e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.434, tt:8329.372\n",
      "Ep:206, loss:0.00000, loss_test:0.02078, lr:2.94e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.467, tt:8376.678\n",
      "Ep:207, loss:0.00000, loss_test:0.02075, lr:2.91e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.451, tt:8413.813\n",
      "Ep:208, loss:0.00000, loss_test:0.02079, lr:2.88e-02, fs:0.77108 (r=0.646,p=0.955),  time:40.434, tt:8450.723\n",
      "Ep:209, loss:0.00000, loss_test:0.02083, lr:2.85e-02, fs:0.77108 (r=0.646,p=0.955),  time:40.377, tt:8479.117\n",
      "Ep:210, loss:0.00000, loss_test:0.02084, lr:2.82e-02, fs:0.76647 (r=0.646,p=0.941),  time:40.360, tt:8515.944\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14310, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.230, tt:40.230\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14200, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.517, tt:81.034\n",
      "Ep:2, loss:0.00028, loss_test:0.14003, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.944, tt:122.831\n",
      "Ep:3, loss:0.00027, loss_test:0.13661, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.501, tt:166.005\n",
      "Ep:4, loss:0.00027, loss_test:0.13071, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:41.659, tt:208.296\n",
      "Ep:5, loss:0.00026, loss_test:0.12151, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:41.452, tt:248.712\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11558, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:41.380, tt:289.663\n",
      "Ep:7, loss:0.00023, loss_test:0.11595, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:41.304, tt:330.432\n",
      "Ep:8, loss:0.00023, loss_test:0.11558, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:41.306, tt:371.755\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11621, lr:1.00e-02, fs:0.67841 (r=0.778,p=0.602),  time:41.439, tt:414.386\n",
      "Ep:10, loss:0.00021, loss_test:0.11425, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:41.464, tt:456.106\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11426, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:41.321, tt:495.848\n",
      "Ep:12, loss:0.00020, loss_test:0.11218, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:41.384, tt:537.988\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.11010, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:41.353, tt:578.948\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10835, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:41.403, tt:621.039\n",
      "Ep:15, loss:0.00018, loss_test:0.10561, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:41.333, tt:661.330\n",
      "Ep:16, loss:0.00017, loss_test:0.10362, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:41.441, tt:704.501\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10023, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:41.499, tt:746.974\n",
      "Ep:18, loss:0.00016, loss_test:0.09803, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:41.525, tt:788.966\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.09705, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:41.493, tt:829.853\n",
      "Ep:20, loss:0.00015, loss_test:0.09541, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:41.504, tt:871.577\n",
      "Ep:21, loss:0.00014, loss_test:0.09594, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:41.558, tt:914.272\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.09169, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:41.533, tt:955.260\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09249, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:41.542, tt:997.015\n",
      "Ep:24, loss:0.00013, loss_test:0.08856, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:41.474, tt:1036.852\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08881, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:41.474, tt:1078.318\n",
      "Ep:26, loss:0.00012, loss_test:0.08904, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:41.419, tt:1118.315\n",
      "Ep:27, loss:0.00011, loss_test:0.08697, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:41.433, tt:1160.134\n",
      "Ep:28, loss:0.00011, loss_test:0.08818, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:41.545, tt:1204.801\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08527, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:41.593, tt:1247.777\n",
      "Ep:30, loss:0.00010, loss_test:0.08899, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:41.601, tt:1289.635\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.08293, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:41.608, tt:1331.470\n",
      "Ep:32, loss:0.00009, loss_test:0.08514, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:41.616, tt:1373.342\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.08069, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:41.616, tt:1414.946\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.08702, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:41.593, tt:1455.740\n",
      "Ep:35, loss:0.00008, loss_test:0.08046, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:41.540, tt:1495.429\n",
      "Ep:36, loss:0.00008, loss_test:0.08382, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:41.479, tt:1534.720\n",
      "Ep:37, loss:0.00007, loss_test:0.07951, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:41.484, tt:1576.400\n",
      "Ep:38, loss:0.00007, loss_test:0.08395, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.458, tt:1616.879\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.07697, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:41.501, tt:1660.047\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.08095, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.488, tt:1701.011\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.07846, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.427, tt:1739.913\n",
      "Ep:42, loss:0.00006, loss_test:0.07936, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:41.437, tt:1781.791\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.07898, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:41.477, tt:1824.996\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.08325, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:41.496, tt:1867.319\n",
      "Ep:45, loss:0.00005, loss_test:0.07636, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.498, tt:1908.926\n",
      "Ep:46, loss:0.00005, loss_test:0.08036, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:41.473, tt:1949.213\n",
      "Ep:47, loss:0.00005, loss_test:0.07522, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:41.423, tt:1988.316\n",
      "Ep:48, loss:0.00005, loss_test:0.07816, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:41.429, tt:2030.024\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00005, loss_test:0.07512, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:41.443, tt:2072.146\n",
      "Ep:50, loss:0.00005, loss_test:0.08266, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:41.440, tt:2113.416\n",
      "Ep:51, loss:0.00006, loss_test:0.07506, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:41.447, tt:2155.219\n",
      "Ep:52, loss:0.00006, loss_test:0.07733, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:41.423, tt:2195.410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00005, loss_test:0.07305, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:41.445, tt:2238.018\n",
      "Ep:54, loss:0.00005, loss_test:0.07814, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:41.469, tt:2280.821\n",
      "Ep:55, loss:0.00005, loss_test:0.07421, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:41.454, tt:2321.444\n",
      "Ep:56, loss:0.00004, loss_test:0.08126, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.462, tt:2363.319\n",
      "Ep:57, loss:0.00004, loss_test:0.07183, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:41.443, tt:2403.678\n",
      "Ep:58, loss:0.00004, loss_test:0.07528, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.405, tt:2442.896\n",
      "Ep:59, loss:0.00004, loss_test:0.07391, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.388, tt:2483.291\n",
      "Ep:60, loss:0.00004, loss_test:0.07628, lr:9.90e-03, fs:0.86022 (r=0.808,p=0.920),  time:41.436, tt:2527.573\n",
      "Ep:61, loss:0.00004, loss_test:0.07304, lr:9.80e-03, fs:0.84043 (r=0.798,p=0.888),  time:41.409, tt:2567.339\n",
      "Ep:62, loss:0.00003, loss_test:0.07630, lr:9.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.386, tt:2607.297\n",
      "Ep:63, loss:0.00003, loss_test:0.07081, lr:9.61e-03, fs:0.88205 (r=0.869,p=0.896),  time:41.378, tt:2648.179\n",
      "Ep:64, loss:0.00003, loss_test:0.08061, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.391, tt:2690.402\n",
      "Ep:65, loss:0.00003, loss_test:0.07307, lr:9.41e-03, fs:0.88325 (r=0.879,p=0.888),  time:41.363, tt:2729.940\n",
      "Ep:66, loss:0.00003, loss_test:0.07878, lr:9.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:41.338, tt:2769.629\n",
      "Ep:67, loss:0.00003, loss_test:0.07494, lr:9.23e-03, fs:0.83060 (r=0.768,p=0.905),  time:41.316, tt:2809.460\n",
      "Ep:68, loss:0.00002, loss_test:0.07874, lr:9.14e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.331, tt:2851.867\n",
      "Ep:69, loss:0.00002, loss_test:0.07548, lr:9.04e-03, fs:0.81356 (r=0.727,p=0.923),  time:41.322, tt:2892.538\n",
      "Ep:70, loss:0.00002, loss_test:0.07438, lr:8.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:41.335, tt:2934.792\n",
      "Ep:71, loss:0.00002, loss_test:0.07978, lr:8.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.336, tt:2976.200\n",
      "Ep:72, loss:0.00002, loss_test:0.07448, lr:8.78e-03, fs:0.80899 (r=0.727,p=0.911),  time:41.333, tt:3017.319\n",
      "Ep:73, loss:0.00002, loss_test:0.07765, lr:8.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:41.352, tt:3060.022\n",
      "Ep:74, loss:0.00002, loss_test:0.07663, lr:8.60e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.348, tt:3101.073\n",
      "Ep:75, loss:0.00002, loss_test:0.07326, lr:8.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.342, tt:3142.000\n",
      "Ep:76, loss:0.00002, loss_test:0.07897, lr:8.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.366, tt:3185.187\n",
      "Ep:77, loss:0.00002, loss_test:0.07839, lr:8.35e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.377, tt:3227.428\n",
      "Ep:78, loss:0.00002, loss_test:0.07452, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:41.387, tt:3269.571\n",
      "Ep:79, loss:0.00002, loss_test:0.07893, lr:8.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.398, tt:3311.877\n",
      "Ep:80, loss:0.00002, loss_test:0.07494, lr:8.10e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.405, tt:3353.789\n",
      "Ep:81, loss:0.00002, loss_test:0.07639, lr:8.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.416, tt:3396.113\n",
      "Ep:82, loss:0.00001, loss_test:0.07902, lr:7.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.441, tt:3439.644\n",
      "Ep:83, loss:0.00001, loss_test:0.07778, lr:7.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.458, tt:3482.455\n",
      "Ep:84, loss:0.00001, loss_test:0.08246, lr:7.78e-03, fs:0.81609 (r=0.717,p=0.947),  time:41.448, tt:3523.055\n",
      "Ep:85, loss:0.00001, loss_test:0.07667, lr:7.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.449, tt:3564.579\n",
      "Ep:86, loss:0.00001, loss_test:0.07714, lr:7.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.458, tt:3606.840\n",
      "Ep:87, loss:0.00001, loss_test:0.07892, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.478, tt:3650.075\n",
      "Ep:88, loss:0.00001, loss_test:0.07645, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.482, tt:3691.862\n",
      "Ep:89, loss:0.00001, loss_test:0.07771, lr:7.40e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.504, tt:3735.358\n",
      "Ep:90, loss:0.00001, loss_test:0.08005, lr:7.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.539, tt:3780.063\n",
      "Ep:91, loss:0.00001, loss_test:0.07587, lr:7.25e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.555, tt:3823.048\n",
      "Ep:92, loss:0.00001, loss_test:0.08054, lr:7.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.565, tt:3865.588\n",
      "Ep:93, loss:0.00001, loss_test:0.07873, lr:7.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.579, tt:3908.399\n",
      "Ep:94, loss:0.00001, loss_test:0.07671, lr:7.03e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.599, tt:3951.935\n",
      "Ep:95, loss:0.00001, loss_test:0.07882, lr:6.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.620, tt:3995.541\n",
      "Ep:96, loss:0.00001, loss_test:0.07766, lr:6.89e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.643, tt:4039.384\n",
      "Ep:97, loss:0.00001, loss_test:0.07773, lr:6.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.667, tt:4083.354\n",
      "Ep:98, loss:0.00001, loss_test:0.07966, lr:6.76e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.691, tt:4127.408\n",
      "Ep:99, loss:0.00001, loss_test:0.07895, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.708, tt:4170.830\n",
      "Ep:100, loss:0.00001, loss_test:0.07916, lr:6.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.729, tt:4214.634\n",
      "Ep:101, loss:0.00001, loss_test:0.07982, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.749, tt:4258.403\n",
      "Ep:102, loss:0.00001, loss_test:0.08025, lr:6.49e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.772, tt:4302.555\n",
      "Ep:103, loss:0.00001, loss_test:0.07913, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.772, tt:4344.257\n",
      "Ep:104, loss:0.00001, loss_test:0.07955, lr:6.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.757, tt:4384.529\n",
      "Ep:105, loss:0.00001, loss_test:0.08095, lr:6.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.758, tt:4426.304\n",
      "Ep:106, loss:0.00001, loss_test:0.07814, lr:6.24e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.745, tt:4466.733\n",
      "Ep:107, loss:0.00001, loss_test:0.08429, lr:6.17e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.740, tt:4507.892\n",
      "Ep:108, loss:0.00001, loss_test:0.08057, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.748, tt:4550.508\n",
      "Ep:109, loss:0.00001, loss_test:0.07862, lr:6.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.745, tt:4591.953\n",
      "Ep:110, loss:0.00001, loss_test:0.08305, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.750, tt:4634.293\n",
      "Ep:111, loss:0.00001, loss_test:0.08130, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.734, tt:4674.197\n",
      "Ep:112, loss:0.00001, loss_test:0.08006, lr:5.87e-03, fs:0.81395 (r=0.707,p=0.959),  time:41.712, tt:4713.491\n",
      "Ep:113, loss:0.00001, loss_test:0.08081, lr:5.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.720, tt:4756.090\n",
      "Ep:114, loss:0.00001, loss_test:0.08096, lr:5.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.723, tt:4798.197\n",
      "Ep:115, loss:0.00001, loss_test:0.07838, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.715, tt:4838.919\n",
      "Ep:116, loss:0.00001, loss_test:0.07769, lr:5.64e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.714, tt:4880.480\n",
      "Ep:117, loss:0.00001, loss_test:0.08202, lr:5.58e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.698, tt:4920.350\n",
      "Ep:118, loss:0.00001, loss_test:0.08079, lr:5.53e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.689, tt:4961.041\n",
      "Ep:119, loss:0.00001, loss_test:0.07759, lr:5.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.691, tt:5002.980\n",
      "Ep:120, loss:0.00001, loss_test:0.08011, lr:5.42e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.707, tt:5046.607\n",
      "Ep:121, loss:0.00001, loss_test:0.08150, lr:5.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.713, tt:5089.038\n",
      "Ep:122, loss:0.00001, loss_test:0.07900, lr:5.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.707, tt:5129.924\n",
      "Ep:123, loss:0.00001, loss_test:0.08062, lr:5.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.720, tt:5173.219\n",
      "Ep:124, loss:0.00001, loss_test:0.08087, lr:5.20e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.725, tt:5215.619\n",
      "Ep:125, loss:0.00001, loss_test:0.07988, lr:5.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.737, tt:5258.852\n",
      "Ep:126, loss:0.00001, loss_test:0.08039, lr:5.10e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.746, tt:5301.696\n",
      "Ep:127, loss:0.00001, loss_test:0.08128, lr:5.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.731, tt:5341.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00001, loss_test:0.08008, lr:5.00e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.751, tt:5385.882\n",
      "Ep:129, loss:0.00001, loss_test:0.08163, lr:4.95e-03, fs:0.82558 (r=0.717,p=0.973),  time:41.745, tt:5426.913\n",
      "Ep:130, loss:0.00001, loss_test:0.07982, lr:4.90e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.747, tt:5468.877\n",
      "Ep:131, loss:0.00001, loss_test:0.08131, lr:4.85e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.746, tt:5510.497\n",
      "Ep:132, loss:0.00001, loss_test:0.08002, lr:4.80e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.733, tt:5550.485\n",
      "Ep:133, loss:0.00001, loss_test:0.08085, lr:4.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.738, tt:5592.876\n",
      "Ep:134, loss:0.00001, loss_test:0.08145, lr:4.71e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.739, tt:5634.775\n",
      "Ep:135, loss:0.00001, loss_test:0.08055, lr:4.66e-03, fs:0.82558 (r=0.717,p=0.973),  time:41.744, tt:5677.200\n",
      "Ep:136, loss:0.00001, loss_test:0.08062, lr:4.61e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.738, tt:5718.162\n",
      "Ep:137, loss:0.00000, loss_test:0.08084, lr:4.57e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.738, tt:5759.799\n",
      "Ep:138, loss:0.00000, loss_test:0.08099, lr:4.52e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.736, tt:5801.367\n",
      "Ep:139, loss:0.00000, loss_test:0.08153, lr:4.48e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.741, tt:5843.805\n",
      "Ep:140, loss:0.00000, loss_test:0.08123, lr:4.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.776, tt:5890.471\n",
      "Ep:141, loss:0.00000, loss_test:0.08001, lr:4.39e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.787, tt:5933.730\n",
      "Ep:142, loss:0.00000, loss_test:0.08143, lr:4.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.795, tt:5976.645\n",
      "Ep:143, loss:0.00000, loss_test:0.08099, lr:4.30e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.801, tt:6019.307\n",
      "Ep:144, loss:0.00000, loss_test:0.08141, lr:4.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.808, tt:6062.114\n",
      "Ep:145, loss:0.00000, loss_test:0.08262, lr:4.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.809, tt:6104.097\n",
      "Ep:146, loss:0.00000, loss_test:0.08183, lr:4.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.824, tt:6148.083\n",
      "Ep:147, loss:0.00000, loss_test:0.08069, lr:4.13e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.838, tt:6191.963\n",
      "Ep:148, loss:0.00000, loss_test:0.07997, lr:4.09e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.840, tt:6234.181\n",
      "Ep:149, loss:0.00000, loss_test:0.08211, lr:4.05e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.846, tt:6276.917\n",
      "Ep:150, loss:0.00000, loss_test:0.08123, lr:4.01e-03, fs:0.82558 (r=0.717,p=0.973),  time:41.851, tt:6319.539\n",
      "Ep:151, loss:0.00000, loss_test:0.08128, lr:3.97e-03, fs:0.82558 (r=0.717,p=0.973),  time:41.865, tt:6363.427\n",
      "Ep:152, loss:0.00000, loss_test:0.08106, lr:3.93e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.887, tt:6408.753\n",
      "Ep:153, loss:0.00000, loss_test:0.08099, lr:3.89e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.906, tt:6453.540\n",
      "Ep:154, loss:0.00000, loss_test:0.08144, lr:3.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.911, tt:6496.211\n",
      "Ep:155, loss:0.00000, loss_test:0.08096, lr:3.81e-03, fs:0.82558 (r=0.717,p=0.973),  time:41.933, tt:6541.546\n",
      "Ep:156, loss:0.00000, loss_test:0.08136, lr:3.77e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.944, tt:6585.222\n",
      "Ep:157, loss:0.00000, loss_test:0.08112, lr:3.73e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.955, tt:6628.963\n",
      "Ep:158, loss:0.00000, loss_test:0.08203, lr:3.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:41.958, tt:6671.376\n",
      "Ep:159, loss:0.00000, loss_test:0.08115, lr:3.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.960, tt:6713.568\n",
      "Ep:160, loss:0.00000, loss_test:0.08136, lr:3.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.967, tt:6756.700\n",
      "Ep:161, loss:0.00000, loss_test:0.08234, lr:3.59e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.977, tt:6800.296\n",
      "Ep:162, loss:0.00000, loss_test:0.08112, lr:3.55e-03, fs:0.83237 (r=0.727,p=0.973),  time:41.987, tt:6843.827\n",
      "Ep:163, loss:0.00000, loss_test:0.08224, lr:3.52e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.021, tt:6891.412\n",
      "Ep:164, loss:0.00000, loss_test:0.08355, lr:3.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.026, tt:6934.338\n",
      "Ep:165, loss:0.00000, loss_test:0.08204, lr:3.45e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.034, tt:6977.622\n",
      "Ep:166, loss:0.00000, loss_test:0.08091, lr:3.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.032, tt:7019.419\n",
      "Ep:167, loss:0.00000, loss_test:0.08146, lr:3.38e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.040, tt:7062.715\n",
      "Ep:168, loss:0.00000, loss_test:0.08185, lr:3.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:42.054, tt:7107.178\n",
      "Ep:169, loss:0.00000, loss_test:0.08158, lr:3.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.066, tt:7151.190\n",
      "Ep:170, loss:0.00000, loss_test:0.08133, lr:3.28e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.071, tt:7194.109\n",
      "Ep:171, loss:0.00000, loss_test:0.08163, lr:3.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.071, tt:7236.165\n",
      "Ep:172, loss:0.00000, loss_test:0.08229, lr:3.21e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.078, tt:7279.540\n",
      "Ep:173, loss:0.00000, loss_test:0.08226, lr:3.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.081, tt:7322.011\n",
      "Ep:174, loss:0.00000, loss_test:0.08169, lr:3.15e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.080, tt:7363.927\n",
      "Ep:175, loss:0.00000, loss_test:0.08167, lr:3.12e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.087, tt:7407.282\n",
      "Ep:176, loss:0.00000, loss_test:0.08278, lr:3.09e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.094, tt:7450.659\n",
      "Ep:177, loss:0.00000, loss_test:0.08199, lr:3.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.096, tt:7493.030\n",
      "Ep:178, loss:0.00000, loss_test:0.08117, lr:3.02e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.095, tt:7534.989\n",
      "Ep:179, loss:0.00000, loss_test:0.08186, lr:2.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.096, tt:7577.212\n",
      "Ep:180, loss:0.00000, loss_test:0.08274, lr:2.96e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.098, tt:7619.777\n",
      "Ep:181, loss:0.00000, loss_test:0.08221, lr:2.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.113, tt:7664.621\n",
      "Ep:182, loss:0.00000, loss_test:0.08182, lr:2.90e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.123, tt:7708.495\n",
      "Ep:183, loss:0.00000, loss_test:0.08212, lr:2.88e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.131, tt:7752.158\n",
      "Ep:184, loss:0.00000, loss_test:0.08233, lr:2.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.130, tt:7793.977\n",
      "Ep:185, loss:0.00000, loss_test:0.08219, lr:2.82e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.143, tt:7838.629\n",
      "Ep:186, loss:0.00000, loss_test:0.08126, lr:2.79e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.154, tt:7882.776\n",
      "Ep:187, loss:0.00000, loss_test:0.08211, lr:2.76e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.154, tt:7924.986\n",
      "Ep:188, loss:0.00000, loss_test:0.08283, lr:2.73e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.159, tt:7967.998\n",
      "Ep:189, loss:0.00000, loss_test:0.08242, lr:2.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.159, tt:8010.210\n",
      "Ep:190, loss:0.00000, loss_test:0.08178, lr:2.68e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.170, tt:8054.432\n",
      "Ep:191, loss:0.00000, loss_test:0.08161, lr:2.65e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.168, tt:8096.262\n",
      "Ep:192, loss:0.00000, loss_test:0.08260, lr:2.63e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.177, tt:8140.114\n",
      "Ep:193, loss:0.00000, loss_test:0.08311, lr:2.60e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.190, tt:8184.892\n",
      "Ep:194, loss:0.00000, loss_test:0.08208, lr:2.57e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.187, tt:8226.432\n",
      "Ep:195, loss:0.00000, loss_test:0.08217, lr:2.55e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.212, tt:8273.619\n",
      "Ep:196, loss:0.00000, loss_test:0.08242, lr:2.52e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.215, tt:8316.442\n",
      "Ep:197, loss:0.00000, loss_test:0.08199, lr:2.50e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.223, tt:8360.165\n",
      "Ep:198, loss:0.00000, loss_test:0.08161, lr:2.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.220, tt:8401.696\n",
      "Ep:199, loss:0.00000, loss_test:0.08187, lr:2.45e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.225, tt:8444.935\n",
      "Ep:200, loss:0.00000, loss_test:0.08193, lr:2.42e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.241, tt:8490.369\n",
      "Ep:201, loss:0.00000, loss_test:0.08190, lr:2.40e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.241, tt:8532.656\n",
      "Ep:202, loss:0.00000, loss_test:0.08243, lr:2.38e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.254, tt:8577.483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.08271, lr:2.35e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.256, tt:8620.202\n",
      "Ep:204, loss:0.00000, loss_test:0.08217, lr:2.33e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.265, tt:8664.357\n",
      "Ep:205, loss:0.00000, loss_test:0.08205, lr:2.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.274, tt:8708.508\n",
      "Ep:206, loss:0.00000, loss_test:0.08250, lr:2.28e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.289, tt:8753.847\n",
      "Ep:207, loss:0.00000, loss_test:0.08222, lr:2.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.283, tt:8794.811\n",
      "Ep:208, loss:0.00000, loss_test:0.08200, lr:2.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.247, tt:8829.603\n",
      "Ep:209, loss:0.00000, loss_test:0.08215, lr:2.21e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.220, tt:8866.279\n",
      "Ep:210, loss:0.00000, loss_test:0.08175, lr:2.19e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.171, tt:8898.064\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02092, lr:6.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:41.923, tt:41.923\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02379, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.104, tt:86.208\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.149, tt:129.446\n",
      "Ep:3, loss:0.00005, loss_test:0.02448, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.224, tt:172.895\n",
      "Ep:4, loss:0.00005, loss_test:0.02307, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:43.591, tt:217.955\n",
      "Ep:5, loss:0.00004, loss_test:0.02133, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:43.472, tt:260.831\n",
      "Ep:6, loss:0.00004, loss_test:0.02027, lr:6.00e-02, fs:0.64615 (r=0.848,p=0.522),  time:43.486, tt:304.406\n",
      "Ep:7, loss:0.00004, loss_test:0.02042, lr:6.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:43.536, tt:348.288\n",
      "Ep:8, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.67841 (r=0.778,p=0.602),  time:43.491, tt:391.422\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02053, lr:6.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:43.592, tt:435.921\n",
      "Ep:10, loss:0.00004, loss_test:0.02026, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:43.518, tt:478.696\n",
      "Ep:11, loss:0.00003, loss_test:0.01983, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:43.864, tt:526.363\n",
      "Ep:12, loss:0.00003, loss_test:0.01942, lr:6.00e-02, fs:0.65613 (r=0.838,p=0.539),  time:43.890, tt:570.574\n",
      "Ep:13, loss:0.00003, loss_test:0.01912, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:43.867, tt:614.132\n",
      "Ep:14, loss:0.00003, loss_test:0.01893, lr:6.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:43.732, tt:655.974\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01859, lr:6.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:43.553, tt:696.853\n",
      "Ep:16, loss:0.00003, loss_test:0.01807, lr:6.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:43.462, tt:738.847\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:43.498, tt:782.971\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:43.442, tt:825.389\n",
      "Ep:19, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:43.400, tt:868.009\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:43.354, tt:910.437\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01657, lr:6.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:43.267, tt:951.881\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:43.285, tt:995.550\n",
      "Ep:23, loss:0.00002, loss_test:0.01626, lr:6.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:43.256, tt:1038.136\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:43.207, tt:1080.183\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:43.094, tt:1120.432\n",
      "Ep:26, loss:0.00002, loss_test:0.01599, lr:6.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:43.044, tt:1162.194\n",
      "Ep:27, loss:0.00002, loss_test:0.01592, lr:6.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:43.004, tt:1204.118\n",
      "Ep:28, loss:0.00002, loss_test:0.01572, lr:6.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:42.972, tt:1246.185\n",
      "Ep:29, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:42.959, tt:1288.780\n",
      "Ep:30, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:42.925, tt:1330.678\n",
      "Ep:31, loss:0.00002, loss_test:0.01550, lr:6.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:42.924, tt:1373.574\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01546, lr:6.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:42.919, tt:1416.321\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:42.967, tt:1460.880\n",
      "Ep:34, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:42.944, tt:1503.026\n",
      "Ep:35, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:42.954, tt:1546.361\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01536, lr:6.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:42.974, tt:1590.053\n",
      "Ep:37, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:42.976, tt:1633.083\n",
      "Ep:38, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:42.949, tt:1675.010\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:42.930, tt:1717.209\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01525, lr:6.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:42.843, tt:1756.565\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:42.795, tt:1797.374\n",
      "Ep:42, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:42.806, tt:1840.673\n",
      "Ep:43, loss:0.00001, loss_test:0.01533, lr:6.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:42.802, tt:1883.276\n",
      "Ep:44, loss:0.00001, loss_test:0.01535, lr:6.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:42.704, tt:1921.658\n",
      "Ep:45, loss:0.00001, loss_test:0.01538, lr:6.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:42.687, tt:1963.621\n",
      "Ep:46, loss:0.00001, loss_test:0.01551, lr:6.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:42.650, tt:2004.560\n",
      "Ep:47, loss:0.00001, loss_test:0.01552, lr:6.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:42.622, tt:2045.850\n",
      "Ep:48, loss:0.00001, loss_test:0.01549, lr:6.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:42.606, tt:2087.705\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01549, lr:6.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:42.614, tt:2130.721\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01564, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.572, tt:2171.157\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01572, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.574, tt:2213.852\n",
      "Ep:52, loss:0.00001, loss_test:0.01561, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.569, tt:2256.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00001, loss_test:0.01566, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.562, tt:2298.322\n",
      "Ep:54, loss:0.00001, loss_test:0.01577, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.530, tt:2339.128\n",
      "Ep:55, loss:0.00001, loss_test:0.01575, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.506, tt:2380.341\n",
      "Ep:56, loss:0.00001, loss_test:0.01579, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:42.495, tt:2422.244\n",
      "Ep:57, loss:0.00001, loss_test:0.01597, lr:6.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:42.532, tt:2466.847\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01596, lr:6.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:42.527, tt:2509.086\n",
      "Ep:59, loss:0.00001, loss_test:0.01617, lr:6.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:42.540, tt:2552.386\n",
      "Ep:60, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:42.551, tt:2595.617\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01625, lr:6.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:42.550, tt:2638.087\n",
      "Ep:62, loss:0.00001, loss_test:0.01622, lr:6.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:42.567, tt:2681.733\n",
      "Ep:63, loss:0.00001, loss_test:0.01624, lr:6.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:42.572, tt:2724.604\n",
      "Ep:64, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:42.553, tt:2765.962\n",
      "Ep:65, loss:0.00001, loss_test:0.01639, lr:6.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:42.539, tt:2807.564\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01651, lr:6.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:42.532, tt:2849.667\n",
      "Ep:67, loss:0.00001, loss_test:0.01668, lr:6.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:42.556, tt:2893.790\n",
      "Ep:68, loss:0.00001, loss_test:0.01673, lr:6.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:42.554, tt:2936.255\n",
      "Ep:69, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:42.537, tt:2977.610\n",
      "Ep:70, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:42.536, tt:3020.088\n",
      "Ep:71, loss:0.00001, loss_test:0.01679, lr:6.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:42.539, tt:3062.838\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01690, lr:6.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:42.527, tt:3104.445\n",
      "Ep:73, loss:0.00001, loss_test:0.01701, lr:6.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:42.523, tt:3146.680\n",
      "Ep:74, loss:0.00001, loss_test:0.01712, lr:6.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:42.504, tt:3187.827\n",
      "Ep:75, loss:0.00001, loss_test:0.01706, lr:6.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:42.504, tt:3230.302\n",
      "Ep:76, loss:0.00001, loss_test:0.01726, lr:6.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:42.501, tt:3272.541\n",
      "Ep:77, loss:0.00001, loss_test:0.01727, lr:6.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:42.490, tt:3314.256\n",
      "Ep:78, loss:0.00001, loss_test:0.01740, lr:6.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:42.467, tt:3354.863\n",
      "Ep:79, loss:0.00001, loss_test:0.01754, lr:6.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:42.469, tt:3397.487\n",
      "Ep:80, loss:0.00001, loss_test:0.01768, lr:6.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:42.489, tt:3441.590\n",
      "Ep:81, loss:0.00001, loss_test:0.01755, lr:6.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:42.486, tt:3483.814\n",
      "Ep:82, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:42.474, tt:3525.378\n",
      "Ep:83, loss:0.00001, loss_test:0.01780, lr:5.94e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.466, tt:3567.111\n",
      "Ep:84, loss:0.00001, loss_test:0.01794, lr:5.88e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.471, tt:3610.032\n",
      "Ep:85, loss:0.00001, loss_test:0.01795, lr:5.82e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.467, tt:3652.119\n",
      "Ep:86, loss:0.00001, loss_test:0.01794, lr:5.76e-02, fs:0.75429 (r=0.667,p=0.868),  time:42.470, tt:3694.870\n",
      "Ep:87, loss:0.00001, loss_test:0.01801, lr:5.71e-02, fs:0.74713 (r=0.657,p=0.867),  time:42.465, tt:3736.929\n",
      "Ep:88, loss:0.00001, loss_test:0.01814, lr:5.65e-02, fs:0.74713 (r=0.657,p=0.867),  time:42.473, tt:3780.096\n",
      "Ep:89, loss:0.00001, loss_test:0.01825, lr:5.59e-02, fs:0.74713 (r=0.657,p=0.867),  time:42.498, tt:3824.831\n",
      "Ep:90, loss:0.00001, loss_test:0.01831, lr:5.54e-02, fs:0.74854 (r=0.646,p=0.889),  time:42.470, tt:3864.787\n",
      "Ep:91, loss:0.00001, loss_test:0.01829, lr:5.48e-02, fs:0.75145 (r=0.657,p=0.878),  time:42.470, tt:3907.265\n",
      "Ep:92, loss:0.00001, loss_test:0.01852, lr:5.43e-02, fs:0.75581 (r=0.657,p=0.890),  time:42.466, tt:3949.309\n",
      "Ep:93, loss:0.00001, loss_test:0.01842, lr:5.37e-02, fs:0.74556 (r=0.636,p=0.900),  time:42.464, tt:3991.604\n",
      "Ep:94, loss:0.00001, loss_test:0.01862, lr:5.32e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.458, tt:4033.514\n",
      "Ep:95, loss:0.00001, loss_test:0.01878, lr:5.27e-02, fs:0.73810 (r=0.626,p=0.899),  time:42.461, tt:4076.253\n",
      "Ep:96, loss:0.00001, loss_test:0.01873, lr:5.21e-02, fs:0.73810 (r=0.626,p=0.899),  time:42.490, tt:4121.531\n",
      "Ep:97, loss:0.00001, loss_test:0.01877, lr:5.16e-02, fs:0.74556 (r=0.636,p=0.900),  time:42.479, tt:4162.986\n",
      "Ep:98, loss:0.00001, loss_test:0.01892, lr:5.11e-02, fs:0.73810 (r=0.626,p=0.899),  time:42.488, tt:4206.269\n",
      "Ep:99, loss:0.00001, loss_test:0.01902, lr:5.06e-02, fs:0.74251 (r=0.626,p=0.912),  time:42.473, tt:4247.267\n",
      "Ep:100, loss:0.00000, loss_test:0.01898, lr:5.01e-02, fs:0.74251 (r=0.626,p=0.912),  time:42.451, tt:4287.546\n",
      "Ep:101, loss:0.00000, loss_test:0.01908, lr:4.96e-02, fs:0.74251 (r=0.626,p=0.912),  time:42.422, tt:4327.066\n",
      "Ep:102, loss:0.00000, loss_test:0.01914, lr:4.91e-02, fs:0.74251 (r=0.626,p=0.912),  time:42.412, tt:4368.425\n",
      "Ep:103, loss:0.00000, loss_test:0.01929, lr:4.86e-02, fs:0.74251 (r=0.626,p=0.912),  time:42.410, tt:4410.660\n",
      "Ep:104, loss:0.00000, loss_test:0.01929, lr:4.81e-02, fs:0.73494 (r=0.616,p=0.910),  time:42.396, tt:4451.629\n",
      "Ep:105, loss:0.00000, loss_test:0.01934, lr:4.76e-02, fs:0.72727 (r=0.606,p=0.909),  time:42.385, tt:4492.764\n",
      "Ep:106, loss:0.00000, loss_test:0.01944, lr:4.71e-02, fs:0.73494 (r=0.616,p=0.910),  time:42.375, tt:4534.113\n",
      "Ep:107, loss:0.00000, loss_test:0.01958, lr:4.67e-02, fs:0.71166 (r=0.586,p=0.906),  time:42.377, tt:4576.688\n",
      "Ep:108, loss:0.00000, loss_test:0.01957, lr:4.62e-02, fs:0.71951 (r=0.596,p=0.908),  time:42.369, tt:4618.272\n",
      "Ep:109, loss:0.00000, loss_test:0.01957, lr:4.57e-02, fs:0.71166 (r=0.586,p=0.906),  time:42.376, tt:4661.370\n",
      "Ep:110, loss:0.00000, loss_test:0.01970, lr:4.53e-02, fs:0.70370 (r=0.576,p=0.905),  time:42.368, tt:4702.837\n",
      "Ep:111, loss:0.00000, loss_test:0.01983, lr:4.48e-02, fs:0.70370 (r=0.576,p=0.905),  time:42.335, tt:4741.484\n",
      "Ep:112, loss:0.00000, loss_test:0.01986, lr:4.44e-02, fs:0.69565 (r=0.566,p=0.903),  time:42.313, tt:4781.319\n",
      "Ep:113, loss:0.00000, loss_test:0.01993, lr:4.39e-02, fs:0.70807 (r=0.576,p=0.919),  time:42.297, tt:4821.836\n",
      "Ep:114, loss:0.00000, loss_test:0.01993, lr:4.35e-02, fs:0.70807 (r=0.576,p=0.919),  time:42.295, tt:4863.883\n",
      "Ep:115, loss:0.00000, loss_test:0.01998, lr:4.31e-02, fs:0.69565 (r=0.566,p=0.903),  time:42.276, tt:4904.009\n",
      "Ep:116, loss:0.00000, loss_test:0.02014, lr:4.26e-02, fs:0.70807 (r=0.576,p=0.919),  time:42.259, tt:4944.354\n",
      "Ep:117, loss:0.00000, loss_test:0.02025, lr:4.22e-02, fs:0.70807 (r=0.576,p=0.919),  time:42.254, tt:4985.930\n",
      "Ep:118, loss:0.00000, loss_test:0.02026, lr:4.18e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.234, tt:5025.889\n",
      "Ep:119, loss:0.00000, loss_test:0.02030, lr:4.14e-02, fs:0.70000 (r=0.566,p=0.918),  time:42.229, tt:5067.468\n",
      "Ep:120, loss:0.00000, loss_test:0.02035, lr:4.10e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.213, tt:5107.743\n",
      "Ep:121, loss:0.00000, loss_test:0.02040, lr:4.05e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.203, tt:5148.710\n",
      "Ep:122, loss:0.00000, loss_test:0.02045, lr:4.01e-02, fs:0.70000 (r=0.566,p=0.918),  time:42.187, tt:5188.978\n",
      "Ep:123, loss:0.00000, loss_test:0.02055, lr:3.97e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.162, tt:5228.098\n",
      "Ep:124, loss:0.00000, loss_test:0.02064, lr:3.93e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.157, tt:5269.687\n",
      "Ep:125, loss:0.00000, loss_test:0.02061, lr:3.89e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.134, tt:5308.946\n",
      "Ep:126, loss:0.00000, loss_test:0.02062, lr:3.86e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.122, tt:5349.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00000, loss_test:0.02065, lr:3.82e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.122, tt:5391.561\n",
      "Ep:128, loss:0.00000, loss_test:0.02078, lr:3.78e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.114, tt:5432.644\n",
      "Ep:129, loss:0.00000, loss_test:0.02081, lr:3.74e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.101, tt:5473.192\n",
      "Ep:130, loss:0.00000, loss_test:0.02083, lr:3.70e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.090, tt:5513.818\n",
      "Ep:131, loss:0.00000, loss_test:0.02085, lr:3.67e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.086, tt:5555.402\n",
      "Ep:132, loss:0.00000, loss_test:0.02095, lr:3.63e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.067, tt:5594.864\n",
      "Ep:133, loss:0.00000, loss_test:0.02102, lr:3.59e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.070, tt:5637.315\n",
      "Ep:134, loss:0.00000, loss_test:0.02104, lr:3.56e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.066, tt:5678.896\n",
      "Ep:135, loss:0.00000, loss_test:0.02104, lr:3.52e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.054, tt:5719.336\n",
      "Ep:136, loss:0.00000, loss_test:0.02107, lr:3.49e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.036, tt:5758.891\n",
      "Ep:137, loss:0.00000, loss_test:0.02122, lr:3.45e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.029, tt:5799.949\n",
      "Ep:138, loss:0.00000, loss_test:0.02125, lr:3.42e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.016, tt:5840.224\n",
      "Ep:139, loss:0.00000, loss_test:0.02122, lr:3.38e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.007, tt:5880.963\n",
      "Ep:140, loss:0.00000, loss_test:0.02132, lr:3.35e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.005, tt:5922.726\n",
      "Ep:141, loss:0.00000, loss_test:0.02131, lr:3.32e-02, fs:0.69182 (r=0.556,p=0.917),  time:42.006, tt:5964.864\n",
      "Ep:142, loss:0.00000, loss_test:0.02130, lr:3.28e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.988, tt:6004.285\n",
      "Ep:143, loss:0.00000, loss_test:0.02139, lr:3.25e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.982, tt:6045.353\n",
      "Ep:144, loss:0.00000, loss_test:0.02136, lr:3.22e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.969, tt:6085.524\n",
      "Ep:145, loss:0.00000, loss_test:0.02141, lr:3.19e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.969, tt:6127.535\n",
      "Ep:146, loss:0.00000, loss_test:0.02152, lr:3.15e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.961, tt:6168.261\n",
      "Ep:147, loss:0.00000, loss_test:0.02152, lr:3.12e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.956, tt:6209.428\n",
      "Ep:148, loss:0.00000, loss_test:0.02160, lr:3.09e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.940, tt:6249.063\n",
      "Ep:149, loss:0.00000, loss_test:0.02157, lr:3.06e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.941, tt:6291.110\n",
      "Ep:150, loss:0.00000, loss_test:0.02161, lr:3.03e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.922, tt:6330.181\n",
      "Ep:151, loss:0.00000, loss_test:0.02162, lr:3.00e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.912, tt:6370.629\n",
      "Ep:152, loss:0.00000, loss_test:0.02168, lr:2.97e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.903, tt:6411.092\n",
      "Ep:153, loss:0.00000, loss_test:0.02170, lr:2.94e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.903, tt:6453.066\n",
      "Ep:154, loss:0.00000, loss_test:0.02172, lr:2.91e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.934, tt:6499.821\n",
      "Ep:155, loss:0.00000, loss_test:0.02180, lr:2.88e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.929, tt:6540.948\n",
      "Ep:156, loss:0.00000, loss_test:0.02182, lr:2.85e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.924, tt:6582.126\n",
      "Ep:157, loss:0.00000, loss_test:0.02186, lr:2.82e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.926, tt:6624.301\n",
      "Ep:158, loss:0.00000, loss_test:0.02184, lr:2.80e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.919, tt:6665.145\n",
      "Ep:159, loss:0.00000, loss_test:0.02189, lr:2.77e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.918, tt:6706.921\n",
      "Ep:160, loss:0.00000, loss_test:0.02192, lr:2.74e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.902, tt:6746.256\n",
      "Ep:161, loss:0.00000, loss_test:0.02196, lr:2.71e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.893, tt:6786.746\n",
      "Ep:162, loss:0.00000, loss_test:0.02193, lr:2.69e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.885, tt:6827.272\n",
      "Ep:163, loss:0.00000, loss_test:0.02196, lr:2.66e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.868, tt:6866.298\n",
      "Ep:164, loss:0.00000, loss_test:0.02203, lr:2.63e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.861, tt:6907.045\n",
      "Ep:165, loss:0.00000, loss_test:0.02208, lr:2.61e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.853, tt:6947.598\n",
      "Ep:166, loss:0.00000, loss_test:0.02208, lr:2.58e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.849, tt:6988.798\n",
      "Ep:167, loss:0.00000, loss_test:0.02212, lr:2.55e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.840, tt:7029.057\n",
      "Ep:168, loss:0.00000, loss_test:0.02212, lr:2.53e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.822, tt:7067.988\n",
      "Ep:169, loss:0.00000, loss_test:0.02217, lr:2.50e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.816, tt:7108.779\n",
      "Ep:170, loss:0.00000, loss_test:0.02218, lr:2.48e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.815, tt:7150.429\n",
      "Ep:171, loss:0.00000, loss_test:0.02218, lr:2.45e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.806, tt:7190.605\n",
      "Ep:172, loss:0.00000, loss_test:0.02222, lr:2.43e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.793, tt:7230.254\n",
      "Ep:173, loss:0.00000, loss_test:0.02227, lr:2.40e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.781, tt:7269.930\n",
      "Ep:174, loss:0.00000, loss_test:0.02226, lr:2.38e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.767, tt:7309.146\n",
      "Ep:175, loss:0.00000, loss_test:0.02225, lr:2.36e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.772, tt:7351.813\n",
      "Ep:176, loss:0.00000, loss_test:0.02229, lr:2.33e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.764, tt:7392.186\n",
      "Ep:177, loss:0.00000, loss_test:0.02237, lr:2.31e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.750, tt:7431.428\n",
      "Ep:178, loss:0.00000, loss_test:0.02242, lr:2.29e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.744, tt:7472.106\n",
      "Ep:179, loss:0.00000, loss_test:0.02236, lr:2.26e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.727, tt:7510.817\n",
      "Ep:180, loss:0.00000, loss_test:0.02235, lr:2.24e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.718, tt:7551.011\n",
      "Ep:181, loss:0.00000, loss_test:0.02241, lr:2.22e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.696, tt:7588.661\n",
      "Ep:182, loss:0.00000, loss_test:0.02243, lr:2.20e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.690, tt:7629.299\n",
      "Ep:183, loss:0.00000, loss_test:0.02246, lr:2.17e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.684, tt:7669.874\n",
      "Ep:184, loss:0.00000, loss_test:0.02249, lr:2.15e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.690, tt:7712.657\n",
      "Ep:185, loss:0.00000, loss_test:0.02252, lr:2.13e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.685, tt:7753.351\n",
      "Ep:186, loss:0.00000, loss_test:0.02252, lr:2.11e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.681, tt:7794.375\n",
      "Ep:187, loss:0.00000, loss_test:0.02256, lr:2.09e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.673, tt:7834.478\n",
      "Ep:188, loss:0.00000, loss_test:0.02254, lr:2.07e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.666, tt:7874.783\n",
      "Ep:189, loss:0.00000, loss_test:0.02255, lr:2.05e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.659, tt:7915.149\n",
      "Ep:190, loss:0.00000, loss_test:0.02259, lr:2.03e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.648, tt:7954.752\n",
      "Ep:191, loss:0.00000, loss_test:0.02261, lr:2.01e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.644, tt:7995.584\n",
      "Ep:192, loss:0.00000, loss_test:0.02265, lr:1.99e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.643, tt:8037.073\n",
      "Ep:193, loss:0.00000, loss_test:0.02264, lr:1.97e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.643, tt:8078.704\n",
      "Ep:194, loss:0.00000, loss_test:0.02267, lr:1.95e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.645, tt:8120.859\n",
      "Ep:195, loss:0.00000, loss_test:0.02269, lr:1.93e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.640, tt:8161.508\n",
      "Ep:196, loss:0.00000, loss_test:0.02268, lr:1.91e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.656, tt:8206.241\n",
      "Ep:197, loss:0.00000, loss_test:0.02272, lr:1.89e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.645, tt:8245.627\n",
      "Ep:198, loss:0.00000, loss_test:0.02274, lr:1.87e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.632, tt:8284.782\n",
      "Ep:199, loss:0.00000, loss_test:0.02273, lr:1.85e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.615, tt:8323.053\n",
      "Ep:200, loss:0.00000, loss_test:0.02276, lr:1.83e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.595, tt:8360.655\n",
      "Ep:201, loss:0.00000, loss_test:0.02279, lr:1.81e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.590, tt:8401.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00000, loss_test:0.02278, lr:1.80e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.576, tt:8439.877\n",
      "Ep:203, loss:0.00000, loss_test:0.02280, lr:1.78e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.577, tt:8481.638\n",
      "Ep:204, loss:0.00000, loss_test:0.02282, lr:1.76e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.569, tt:8521.573\n",
      "Ep:205, loss:0.00000, loss_test:0.02284, lr:1.74e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.569, tt:8563.117\n",
      "Ep:206, loss:0.00000, loss_test:0.02284, lr:1.73e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.559, tt:8602.796\n",
      "Ep:207, loss:0.00000, loss_test:0.02285, lr:1.71e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.551, tt:8642.712\n",
      "Ep:208, loss:0.00000, loss_test:0.02288, lr:1.69e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.519, tt:8677.394\n",
      "Ep:209, loss:0.00000, loss_test:0.02293, lr:1.67e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.496, tt:8714.257\n",
      "Ep:210, loss:0.00000, loss_test:0.02292, lr:1.66e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.463, tt:8748.784\n",
      "Ep:211, loss:0.00000, loss_test:0.02291, lr:1.64e-02, fs:0.69182 (r=0.556,p=0.917),  time:41.419, tt:8780.821\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14368, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.331, tt:38.331\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14257, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.034, tt:82.068\n",
      "Ep:2, loss:0.00028, loss_test:0.14050, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.069, tt:123.207\n",
      "Ep:3, loss:0.00028, loss_test:0.13703, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:41.102, tt:164.406\n",
      "Ep:4, loss:0.00027, loss_test:0.13150, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:42.357, tt:211.783\n",
      "Ep:5, loss:0.00026, loss_test:0.12322, lr:1.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:42.461, tt:254.767\n",
      "Ep:6, loss:0.00024, loss_test:0.11775, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:42.399, tt:296.791\n",
      "Ep:7, loss:0.00023, loss_test:0.11848, lr:1.00e-02, fs:0.65000 (r=0.657,p=0.644),  time:42.225, tt:337.803\n",
      "Ep:8, loss:0.00023, loss_test:0.11930, lr:1.00e-02, fs:0.68545 (r=0.737,p=0.640),  time:42.302, tt:380.718\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11904, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:42.302, tt:423.018\n",
      "Ep:10, loss:0.00022, loss_test:0.11584, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:42.097, tt:463.063\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11363, lr:1.00e-02, fs:0.68718 (r=0.677,p=0.698),  time:42.249, tt:506.987\n",
      "Ep:12, loss:0.00020, loss_test:0.11088, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:42.193, tt:548.510\n",
      "Ep:13, loss:0.00020, loss_test:0.10789, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:42.135, tt:589.890\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10506, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:42.022, tt:630.326\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10262, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:41.954, tt:671.260\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10001, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:41.911, tt:712.487\n",
      "Ep:17, loss:0.00017, loss_test:0.09787, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:41.899, tt:754.191\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09482, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:41.963, tt:797.302\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09322, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:41.990, tt:839.802\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09118, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:42.041, tt:882.870\n",
      "Ep:21, loss:0.00015, loss_test:0.08945, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:42.041, tt:924.901\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08842, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:42.080, tt:967.839\n",
      "Ep:23, loss:0.00014, loss_test:0.08728, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:42.069, tt:1009.653\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08811, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:42.096, tt:1052.396\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08581, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:42.099, tt:1094.581\n",
      "Ep:26, loss:0.00012, loss_test:0.08653, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:42.096, tt:1136.603\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.08346, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:42.068, tt:1177.904\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00011, loss_test:0.08612, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:42.025, tt:1218.731\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08242, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:41.939, tt:1258.171\n",
      "Ep:30, loss:0.00010, loss_test:0.08217, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:41.922, tt:1299.570\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.08670, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:41.891, tt:1340.510\n",
      "Ep:32, loss:0.00010, loss_test:0.08113, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.869, tt:1381.681\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.08215, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:41.875, tt:1423.736\n",
      "Ep:34, loss:0.00009, loss_test:0.07951, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.912, tt:1466.903\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.08084, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.930, tt:1509.480\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.07783, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:42.059, tt:1556.180\n",
      "Ep:37, loss:0.00008, loss_test:0.08351, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:41.985, tt:1595.446\n",
      "Ep:38, loss:0.00008, loss_test:0.07648, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:41.969, tt:1636.773\n",
      "Ep:39, loss:0.00008, loss_test:0.07999, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:41.961, tt:1678.453\n",
      "Ep:40, loss:0.00007, loss_test:0.07449, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:41.953, tt:1720.065\n",
      "Ep:41, loss:0.00007, loss_test:0.08213, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:41.970, tt:1762.728\n",
      "Ep:42, loss:0.00006, loss_test:0.07350, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:41.970, tt:1804.700\n",
      "Ep:43, loss:0.00006, loss_test:0.07817, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.994, tt:1847.725\n",
      "Ep:44, loss:0.00006, loss_test:0.07470, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.973, tt:1888.792\n",
      "Ep:45, loss:0.00005, loss_test:0.07600, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:41.973, tt:1930.771\n",
      "Ep:46, loss:0.00006, loss_test:0.08010, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:41.967, tt:1972.427\n",
      "Ep:47, loss:0.00006, loss_test:0.07666, lr:9.90e-03, fs:0.81967 (r=0.758,p=0.893),  time:41.974, tt:2014.754\n",
      "Ep:48, loss:0.00005, loss_test:0.07571, lr:9.80e-03, fs:0.84264 (r=0.838,p=0.847),  time:42.007, tt:2058.337\n",
      "Ep:49, loss:0.00005, loss_test:0.07707, lr:9.70e-03, fs:0.85417 (r=0.828,p=0.882),  time:42.014, tt:2100.708\n",
      "Ep:50, loss:0.00005, loss_test:0.07180, lr:9.61e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.968, tt:2140.364\n",
      "Ep:51, loss:0.00005, loss_test:0.08142, lr:9.51e-03, fs:0.79602 (r=0.808,p=0.784),  time:41.952, tt:2181.495\n",
      "Ep:52, loss:0.00005, loss_test:0.07423, lr:9.41e-03, fs:0.80435 (r=0.747,p=0.871),  time:42.001, tt:2226.038\n",
      "Ep:53, loss:0.00005, loss_test:0.07439, lr:9.32e-03, fs:0.83333 (r=0.808,p=0.860),  time:42.001, tt:2268.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00004, loss_test:0.07775, lr:9.23e-03, fs:0.88172 (r=0.828,p=0.943),  time:42.051, tt:2312.785\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.07262, lr:9.23e-03, fs:0.87437 (r=0.879,p=0.870),  time:42.049, tt:2354.730\n",
      "Ep:56, loss:0.00004, loss_test:0.07706, lr:9.23e-03, fs:0.84656 (r=0.808,p=0.889),  time:42.071, tt:2398.060\n",
      "Ep:57, loss:0.00004, loss_test:0.07203, lr:9.23e-03, fs:0.87368 (r=0.838,p=0.912),  time:42.065, tt:2439.746\n",
      "Ep:58, loss:0.00004, loss_test:0.07636, lr:9.23e-03, fs:0.82353 (r=0.778,p=0.875),  time:42.075, tt:2482.418\n",
      "Ep:59, loss:0.00003, loss_test:0.07326, lr:9.23e-03, fs:0.87701 (r=0.828,p=0.932),  time:42.082, tt:2524.913\n",
      "Ep:60, loss:0.00003, loss_test:0.07409, lr:9.23e-03, fs:0.87831 (r=0.838,p=0.922),  time:42.130, tt:2569.912\n",
      "Ep:61, loss:0.00003, loss_test:0.07274, lr:9.23e-03, fs:0.87958 (r=0.848,p=0.913),  time:42.170, tt:2614.515\n",
      "Ep:62, loss:0.00003, loss_test:0.07140, lr:9.23e-03, fs:0.89247 (r=0.838,p=0.954),  time:42.201, tt:2658.635\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.08011, lr:9.23e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.193, tt:2700.354\n",
      "Ep:64, loss:0.00003, loss_test:0.07227, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:42.240, tt:2745.601\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00003, loss_test:0.08227, lr:9.23e-03, fs:0.83516 (r=0.768,p=0.916),  time:42.242, tt:2787.939\n",
      "Ep:66, loss:0.00002, loss_test:0.07109, lr:9.23e-03, fs:0.87500 (r=0.848,p=0.903),  time:42.230, tt:2829.403\n",
      "Ep:67, loss:0.00002, loss_test:0.07931, lr:9.23e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.280, tt:2875.056\n",
      "Ep:68, loss:0.00002, loss_test:0.07386, lr:9.23e-03, fs:0.88889 (r=0.848,p=0.933),  time:42.289, tt:2917.938\n",
      "Ep:69, loss:0.00002, loss_test:0.07349, lr:9.23e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.299, tt:2960.905\n",
      "Ep:70, loss:0.00002, loss_test:0.07616, lr:9.23e-03, fs:0.88770 (r=0.838,p=0.943),  time:42.303, tt:3003.521\n",
      "Ep:71, loss:0.00002, loss_test:0.07544, lr:9.23e-03, fs:0.83696 (r=0.778,p=0.906),  time:42.284, tt:3044.469\n",
      "Ep:72, loss:0.00002, loss_test:0.07476, lr:9.23e-03, fs:0.88043 (r=0.818,p=0.953),  time:42.289, tt:3087.077\n",
      "Ep:73, loss:0.00002, loss_test:0.07497, lr:9.23e-03, fs:0.88770 (r=0.838,p=0.943),  time:42.268, tt:3127.855\n",
      "Ep:74, loss:0.00002, loss_test:0.07432, lr:9.23e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.266, tt:3169.929\n",
      "Ep:75, loss:0.00002, loss_test:0.07559, lr:9.23e-03, fs:0.90217 (r=0.838,p=0.976),  time:42.255, tt:3211.365\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.07579, lr:9.23e-03, fs:0.86517 (r=0.778,p=0.975),  time:42.237, tt:3252.237\n",
      "Ep:77, loss:0.00002, loss_test:0.07685, lr:9.23e-03, fs:0.85556 (r=0.778,p=0.951),  time:42.240, tt:3294.709\n",
      "Ep:78, loss:0.00001, loss_test:0.07870, lr:9.23e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.233, tt:3336.408\n",
      "Ep:79, loss:0.00001, loss_test:0.07495, lr:9.23e-03, fs:0.86034 (r=0.778,p=0.963),  time:42.248, tt:3379.819\n",
      "Ep:80, loss:0.00001, loss_test:0.07745, lr:9.23e-03, fs:0.86517 (r=0.778,p=0.975),  time:42.236, tt:3421.104\n",
      "Ep:81, loss:0.00001, loss_test:0.07974, lr:9.23e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.257, tt:3465.045\n",
      "Ep:82, loss:0.00001, loss_test:0.07642, lr:9.23e-03, fs:0.87151 (r=0.788,p=0.975),  time:42.246, tt:3506.417\n",
      "Ep:83, loss:0.00001, loss_test:0.08141, lr:9.23e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.262, tt:3550.019\n",
      "Ep:84, loss:0.00001, loss_test:0.07920, lr:9.23e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.257, tt:3591.878\n",
      "Ep:85, loss:0.00001, loss_test:0.07883, lr:9.23e-03, fs:0.85057 (r=0.747,p=0.987),  time:42.261, tt:3634.463\n",
      "Ep:86, loss:0.00001, loss_test:0.08262, lr:9.23e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.281, tt:3678.439\n",
      "Ep:87, loss:0.00001, loss_test:0.07809, lr:9.14e-03, fs:0.87006 (r=0.778,p=0.987),  time:42.276, tt:3720.316\n",
      "Ep:88, loss:0.00001, loss_test:0.08357, lr:9.04e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.296, tt:3764.384\n",
      "Ep:89, loss:0.00001, loss_test:0.07895, lr:8.95e-03, fs:0.84571 (r=0.747,p=0.974),  time:42.287, tt:3805.871\n",
      "Ep:90, loss:0.00001, loss_test:0.08083, lr:8.86e-03, fs:0.82353 (r=0.707,p=0.986),  time:42.279, tt:3847.372\n",
      "Ep:91, loss:0.00001, loss_test:0.07868, lr:8.78e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.278, tt:3889.548\n",
      "Ep:92, loss:0.00001, loss_test:0.08075, lr:8.69e-03, fs:0.82353 (r=0.707,p=0.986),  time:42.259, tt:3930.055\n",
      "Ep:93, loss:0.00001, loss_test:0.08113, lr:8.60e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.242, tt:3970.738\n",
      "Ep:94, loss:0.00001, loss_test:0.07854, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.244, tt:4013.190\n",
      "Ep:95, loss:0.00001, loss_test:0.08736, lr:8.43e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.227, tt:4053.830\n",
      "Ep:96, loss:0.00001, loss_test:0.07666, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.228, tt:4096.080\n",
      "Ep:97, loss:0.00001, loss_test:0.08630, lr:8.26e-03, fs:0.83908 (r=0.737,p=0.973),  time:42.233, tt:4138.803\n",
      "Ep:98, loss:0.00001, loss_test:0.07661, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.235, tt:4181.218\n",
      "Ep:99, loss:0.00001, loss_test:0.08608, lr:8.10e-03, fs:0.76829 (r=0.636,p=0.969),  time:42.219, tt:4221.893\n",
      "Ep:100, loss:0.00001, loss_test:0.08007, lr:8.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.194, tt:4261.543\n",
      "Ep:101, loss:0.00001, loss_test:0.08205, lr:7.94e-03, fs:0.74534 (r=0.606,p=0.968),  time:42.176, tt:4301.904\n",
      "Ep:102, loss:0.00001, loss_test:0.08051, lr:7.86e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.178, tt:4344.352\n",
      "Ep:103, loss:0.00001, loss_test:0.08130, lr:7.78e-03, fs:0.85227 (r=0.758,p=0.974),  time:42.180, tt:4386.707\n",
      "Ep:104, loss:0.00001, loss_test:0.08114, lr:7.70e-03, fs:0.83908 (r=0.737,p=0.973),  time:42.201, tt:4431.122\n",
      "Ep:105, loss:0.00001, loss_test:0.08150, lr:7.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.219, tt:4475.196\n",
      "Ep:106, loss:0.00001, loss_test:0.08193, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.211, tt:4516.595\n",
      "Ep:107, loss:0.00000, loss_test:0.08476, lr:7.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.228, tt:4560.594\n",
      "Ep:108, loss:0.00000, loss_test:0.07921, lr:7.40e-03, fs:0.85227 (r=0.758,p=0.974),  time:42.236, tt:4603.769\n",
      "Ep:109, loss:0.00000, loss_test:0.08345, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.243, tt:4646.723\n",
      "Ep:110, loss:0.00000, loss_test:0.08180, lr:7.25e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.251, tt:4689.831\n",
      "Ep:111, loss:0.00000, loss_test:0.08199, lr:7.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.251, tt:4732.158\n",
      "Ep:112, loss:0.00000, loss_test:0.08172, lr:7.11e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.251, tt:4774.316\n",
      "Ep:113, loss:0.00000, loss_test:0.08551, lr:7.03e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.255, tt:4817.083\n",
      "Ep:114, loss:0.00000, loss_test:0.08068, lr:6.96e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.258, tt:4859.703\n",
      "Ep:115, loss:0.00000, loss_test:0.08177, lr:6.89e-03, fs:0.84571 (r=0.747,p=0.974),  time:42.261, tt:4902.219\n",
      "Ep:116, loss:0.00000, loss_test:0.07978, lr:6.83e-03, fs:0.83908 (r=0.737,p=0.973),  time:42.264, tt:4944.865\n",
      "Ep:117, loss:0.00000, loss_test:0.08294, lr:6.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.271, tt:4987.980\n",
      "Ep:118, loss:0.00000, loss_test:0.08182, lr:6.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.271, tt:5030.279\n",
      "Ep:119, loss:0.00000, loss_test:0.08189, lr:6.62e-03, fs:0.82558 (r=0.717,p=0.973),  time:42.260, tt:5071.183\n",
      "Ep:120, loss:0.00000, loss_test:0.08116, lr:6.56e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.245, tt:5111.690\n",
      "Ep:121, loss:0.00000, loss_test:0.08308, lr:6.49e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.247, tt:5154.136\n",
      "Ep:122, loss:0.00000, loss_test:0.08119, lr:6.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.239, tt:5195.407\n",
      "Ep:123, loss:0.00000, loss_test:0.08099, lr:6.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.244, tt:5238.285\n",
      "Ep:124, loss:0.00000, loss_test:0.08103, lr:6.30e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.246, tt:5280.792\n",
      "Ep:125, loss:0.00000, loss_test:0.08211, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.248, tt:5323.262\n",
      "Ep:126, loss:0.00000, loss_test:0.08281, lr:6.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.250, tt:5365.701\n",
      "Ep:127, loss:0.00000, loss_test:0.08172, lr:6.11e-03, fs:0.77844 (r=0.657,p=0.956),  time:42.236, tt:5406.171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00000, loss_test:0.08181, lr:6.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.238, tt:5448.646\n",
      "Ep:129, loss:0.00000, loss_test:0.08061, lr:5.99e-03, fs:0.83908 (r=0.737,p=0.973),  time:42.234, tt:5490.429\n",
      "Ep:130, loss:0.00000, loss_test:0.08193, lr:5.93e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.229, tt:5531.996\n",
      "Ep:131, loss:0.00000, loss_test:0.08204, lr:5.87e-03, fs:0.83908 (r=0.737,p=0.973),  time:42.228, tt:5574.147\n",
      "Ep:132, loss:0.00000, loss_test:0.08240, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.225, tt:5615.873\n",
      "Ep:133, loss:0.00000, loss_test:0.08233, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.223, tt:5657.849\n",
      "Ep:134, loss:0.00000, loss_test:0.08240, lr:5.70e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.206, tt:5697.876\n",
      "Ep:135, loss:0.00000, loss_test:0.08302, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.200, tt:5739.175\n",
      "Ep:136, loss:0.00000, loss_test:0.08391, lr:5.58e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.208, tt:5782.457\n",
      "Ep:137, loss:0.00000, loss_test:0.08193, lr:5.53e-03, fs:0.81395 (r=0.707,p=0.959),  time:42.211, tt:5825.113\n",
      "Ep:138, loss:0.00000, loss_test:0.08324, lr:5.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.205, tt:5866.440\n",
      "Ep:139, loss:0.00000, loss_test:0.08233, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.208, tt:5909.083\n",
      "Ep:140, loss:0.00000, loss_test:0.08221, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.220, tt:5953.022\n",
      "Ep:141, loss:0.00000, loss_test:0.08251, lr:5.31e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.224, tt:5995.860\n",
      "Ep:142, loss:0.00000, loss_test:0.08233, lr:5.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.214, tt:6036.661\n",
      "Ep:143, loss:0.00000, loss_test:0.08528, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.203, tt:6077.210\n",
      "Ep:144, loss:0.00000, loss_test:0.08355, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.197, tt:6118.537\n",
      "Ep:145, loss:0.00000, loss_test:0.08301, lr:5.10e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.236, tt:6166.521\n",
      "Ep:146, loss:0.00000, loss_test:0.08386, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.253, tt:6211.124\n",
      "Ep:147, loss:0.00000, loss_test:0.08271, lr:5.00e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.245, tt:6252.192\n",
      "Ep:148, loss:0.00000, loss_test:0.08631, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.246, tt:6294.634\n",
      "Ep:149, loss:0.00000, loss_test:0.08357, lr:4.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.242, tt:6336.320\n",
      "Ep:150, loss:0.00000, loss_test:0.08339, lr:4.85e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.248, tt:6379.396\n",
      "Ep:151, loss:0.00000, loss_test:0.08408, lr:4.80e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.259, tt:6423.299\n",
      "Ep:152, loss:0.00000, loss_test:0.08278, lr:4.75e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.268, tt:6466.974\n",
      "Ep:153, loss:0.00000, loss_test:0.08344, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.275, tt:6510.292\n",
      "Ep:154, loss:0.00000, loss_test:0.08334, lr:4.66e-03, fs:0.77844 (r=0.657,p=0.956),  time:42.268, tt:6551.530\n",
      "Ep:155, loss:0.00000, loss_test:0.08320, lr:4.61e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.266, tt:6593.441\n",
      "Ep:156, loss:0.00000, loss_test:0.08300, lr:4.57e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.270, tt:6636.331\n",
      "Ep:157, loss:0.00000, loss_test:0.08213, lr:4.52e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.274, tt:6679.328\n",
      "Ep:158, loss:0.00000, loss_test:0.08421, lr:4.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.285, tt:6723.306\n",
      "Ep:159, loss:0.00000, loss_test:0.08360, lr:4.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.278, tt:6764.489\n",
      "Ep:160, loss:0.00000, loss_test:0.08292, lr:4.39e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.283, tt:6807.544\n",
      "Ep:161, loss:0.00000, loss_test:0.08357, lr:4.34e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.280, tt:6849.367\n",
      "Ep:162, loss:0.00000, loss_test:0.08366, lr:4.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.274, tt:6890.719\n",
      "Ep:163, loss:0.00000, loss_test:0.08373, lr:4.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.268, tt:6932.033\n",
      "Ep:164, loss:0.00000, loss_test:0.08294, lr:4.21e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.260, tt:6972.882\n",
      "Ep:165, loss:0.00000, loss_test:0.08318, lr:4.17e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.279, tt:7018.345\n",
      "Ep:166, loss:0.00000, loss_test:0.08289, lr:4.13e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.277, tt:7060.333\n",
      "Ep:167, loss:0.00000, loss_test:0.08257, lr:4.09e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.281, tt:7103.214\n",
      "Ep:168, loss:0.00000, loss_test:0.08217, lr:4.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.281, tt:7145.430\n",
      "Ep:169, loss:0.00000, loss_test:0.08333, lr:4.01e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.279, tt:7187.489\n",
      "Ep:170, loss:0.00000, loss_test:0.08343, lr:3.97e-03, fs:0.78571 (r=0.667,p=0.957),  time:42.281, tt:7230.096\n",
      "Ep:171, loss:0.00000, loss_test:0.08318, lr:3.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.270, tt:7270.409\n",
      "Ep:172, loss:0.00000, loss_test:0.08332, lr:3.89e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.267, tt:7312.181\n",
      "Ep:173, loss:0.00000, loss_test:0.08299, lr:3.85e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.270, tt:7354.925\n",
      "Ep:174, loss:0.00000, loss_test:0.08273, lr:3.81e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.282, tt:7399.367\n",
      "Ep:175, loss:0.00000, loss_test:0.08273, lr:3.77e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.289, tt:7442.921\n",
      "Ep:176, loss:0.00000, loss_test:0.08209, lr:3.73e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.289, tt:7485.196\n",
      "Ep:177, loss:0.00000, loss_test:0.08257, lr:3.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.291, tt:7527.856\n",
      "Ep:178, loss:0.00000, loss_test:0.08292, lr:3.66e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.299, tt:7571.511\n",
      "Ep:179, loss:0.00000, loss_test:0.08248, lr:3.62e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.300, tt:7614.070\n",
      "Ep:180, loss:0.00000, loss_test:0.08242, lr:3.59e-03, fs:0.77844 (r=0.657,p=0.956),  time:42.289, tt:7654.332\n",
      "Ep:181, loss:0.00000, loss_test:0.08321, lr:3.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:42.305, tt:7699.451\n",
      "Ep:182, loss:0.00000, loss_test:0.08275, lr:3.52e-03, fs:0.79290 (r=0.677,p=0.957),  time:42.305, tt:7741.871\n",
      "Ep:183, loss:0.00000, loss_test:0.08259, lr:3.48e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.313, tt:7785.665\n",
      "Ep:184, loss:0.00000, loss_test:0.08330, lr:3.45e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.312, tt:7827.808\n",
      "Ep:185, loss:0.00000, loss_test:0.08303, lr:3.41e-03, fs:0.78571 (r=0.667,p=0.957),  time:42.311, tt:7869.895\n",
      "Ep:186, loss:0.00000, loss_test:0.08204, lr:3.38e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.307, tt:7911.390\n",
      "Ep:187, loss:0.00000, loss_test:0.08275, lr:3.34e-03, fs:0.81395 (r=0.707,p=0.959),  time:42.299, tt:7952.239\n",
      "Ep:188, loss:0.00000, loss_test:0.08264, lr:3.31e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.290, tt:7992.859\n",
      "Ep:189, loss:0.00000, loss_test:0.08236, lr:3.28e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.281, tt:8033.330\n",
      "Ep:190, loss:0.00000, loss_test:0.08365, lr:3.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.267, tt:8073.030\n",
      "Ep:191, loss:0.00000, loss_test:0.08333, lr:3.21e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.259, tt:8113.791\n",
      "Ep:192, loss:0.00000, loss_test:0.08216, lr:3.18e-03, fs:0.78571 (r=0.667,p=0.957),  time:42.256, tt:8155.482\n",
      "Ep:193, loss:0.00000, loss_test:0.08250, lr:3.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:42.291, tt:8204.538\n",
      "Ep:194, loss:0.00000, loss_test:0.08263, lr:3.12e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.283, tt:8245.264\n",
      "Ep:195, loss:0.00000, loss_test:0.08201, lr:3.09e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.273, tt:8285.468\n",
      "Ep:196, loss:0.00000, loss_test:0.08356, lr:3.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.256, tt:8324.463\n",
      "Ep:197, loss:0.00000, loss_test:0.08337, lr:3.02e-03, fs:0.79290 (r=0.677,p=0.957),  time:42.254, tt:8366.279\n",
      "Ep:198, loss:0.00000, loss_test:0.08332, lr:2.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.254, tt:8408.494\n",
      "Ep:199, loss:0.00000, loss_test:0.08371, lr:2.96e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.252, tt:8450.366\n",
      "Ep:200, loss:0.00000, loss_test:0.08320, lr:2.93e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.246, tt:8491.425\n",
      "Ep:201, loss:0.00000, loss_test:0.08231, lr:2.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.241, tt:8532.742\n",
      "Ep:202, loss:0.00000, loss_test:0.08271, lr:2.88e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.229, tt:8572.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.08313, lr:2.85e-03, fs:0.77844 (r=0.657,p=0.956),  time:42.227, tt:8614.241\n",
      "Ep:204, loss:0.00000, loss_test:0.08236, lr:2.82e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.237, tt:8658.592\n",
      "Ep:205, loss:0.00000, loss_test:0.08242, lr:2.79e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.241, tt:8701.691\n",
      "Ep:206, loss:0.00000, loss_test:0.08276, lr:2.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.238, tt:8743.298\n",
      "Ep:207, loss:0.00000, loss_test:0.08230, lr:2.73e-03, fs:0.77844 (r=0.657,p=0.956),  time:42.199, tt:8777.417\n",
      "Ep:208, loss:0.00000, loss_test:0.08174, lr:2.71e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.147, tt:8808.801\n",
      "Ep:209, loss:0.00000, loss_test:0.08277, lr:2.68e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.060, tt:8832.582\n",
      "Ep:210, loss:0.00000, loss_test:0.08289, lr:2.65e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.954, tt:8852.280\n",
      "Ep:211, loss:0.00000, loss_test:0.08222, lr:2.63e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.819, tt:8865.610\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02073, lr:6.00e-02, fs:0.66667 (r=0.874,p=0.539),  time:35.619, tt:35.619\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02110, lr:6.00e-02, fs:0.64822 (r=0.943,p=0.494),  time:37.156, tt:74.311\n",
      "Ep:2, loss:0.00004, loss_test:0.02146, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:37.813, tt:113.438\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02068, lr:6.00e-02, fs:0.65060 (r=0.931,p=0.500),  time:38.098, tt:152.391\n",
      "Ep:4, loss:0.00004, loss_test:0.02033, lr:6.00e-02, fs:0.66383 (r=0.897,p=0.527),  time:38.437, tt:192.187\n",
      "Ep:5, loss:0.00004, loss_test:0.02105, lr:6.00e-02, fs:0.69811 (r=0.851,p=0.592),  time:38.468, tt:230.806\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00003, loss_test:0.02130, lr:6.00e-02, fs:0.71357 (r=0.816,p=0.634),  time:38.409, tt:268.866\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00003, loss_test:0.01978, lr:6.00e-02, fs:0.70874 (r=0.839,p=0.613),  time:38.452, tt:307.615\n",
      "Ep:8, loss:0.00003, loss_test:0.01828, lr:6.00e-02, fs:0.71963 (r=0.885,p=0.606),  time:38.493, tt:346.437\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.73394 (r=0.920,p=0.611),  time:38.524, tt:385.236\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.75117 (r=0.920,p=0.635),  time:38.625, tt:424.877\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.75598 (r=0.908,p=0.648),  time:38.631, tt:463.575\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.76238 (r=0.885,p=0.670),  time:38.680, tt:502.838\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.78218 (r=0.908,p=0.687),  time:38.637, tt:540.915\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.80769 (r=0.966,p=0.694),  time:38.696, tt:580.447\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01563, lr:6.00e-02, fs:0.81340 (r=0.977,p=0.697),  time:38.753, tt:620.050\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.81731 (r=0.977,p=0.702),  time:38.735, tt:658.490\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.81373 (r=0.954,p=0.709),  time:38.787, tt:698.169\n",
      "Ep:18, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.81773 (r=0.954,p=0.716),  time:38.867, tt:738.467\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.82927 (r=0.977,p=0.720),  time:38.880, tt:777.598\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:38.859, tt:816.039\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:38.839, tt:854.461\n",
      "Ep:22, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.83422 (r=0.897,p=0.780),  time:38.843, tt:893.398\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:38.852, tt:932.445\n",
      "Ep:24, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:38.909, tt:972.717\n",
      "Ep:25, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.80682 (r=0.816,p=0.798),  time:38.899, tt:1011.364\n",
      "Ep:26, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:38.878, tt:1049.716\n",
      "Ep:27, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:38.885, tt:1088.767\n",
      "Ep:28, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.79532 (r=0.782,p=0.810),  time:38.872, tt:1127.286\n",
      "Ep:29, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:38.858, tt:1165.741\n",
      "Ep:30, loss:0.00001, loss_test:0.01483, lr:6.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:38.907, tt:1206.116\n",
      "Ep:31, loss:0.00001, loss_test:0.01493, lr:6.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:38.933, tt:1245.851\n",
      "Ep:32, loss:0.00001, loss_test:0.01508, lr:6.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:38.914, tt:1284.166\n",
      "Ep:33, loss:0.00001, loss_test:0.01512, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:38.890, tt:1322.266\n",
      "Ep:34, loss:0.00001, loss_test:0.01526, lr:5.94e-02, fs:0.80247 (r=0.747,p=0.867),  time:38.858, tt:1360.026\n",
      "Ep:35, loss:0.00001, loss_test:0.01523, lr:5.88e-02, fs:0.80247 (r=0.747,p=0.867),  time:38.894, tt:1400.198\n",
      "Ep:36, loss:0.00001, loss_test:0.01535, lr:5.82e-02, fs:0.81988 (r=0.759,p=0.892),  time:38.893, tt:1439.041\n",
      "Ep:37, loss:0.00001, loss_test:0.01547, lr:5.76e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.881, tt:1477.471\n",
      "Ep:38, loss:0.00001, loss_test:0.01552, lr:5.71e-02, fs:0.82500 (r=0.759,p=0.904),  time:38.853, tt:1515.251\n",
      "Ep:39, loss:0.00001, loss_test:0.01555, lr:5.65e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.879, tt:1555.143\n",
      "Ep:40, loss:0.00001, loss_test:0.01573, lr:5.59e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.899, tt:1594.854\n",
      "Ep:41, loss:0.00001, loss_test:0.01587, lr:5.54e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.852, tt:1631.782\n",
      "Ep:42, loss:0.00001, loss_test:0.01590, lr:5.48e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.872, tt:1671.506\n",
      "Ep:43, loss:0.00001, loss_test:0.01603, lr:5.43e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.906, tt:1711.873\n",
      "Ep:44, loss:0.00001, loss_test:0.01614, lr:5.37e-02, fs:0.83019 (r=0.759,p=0.917),  time:38.895, tt:1750.288\n",
      "Ep:45, loss:0.00001, loss_test:0.01627, lr:5.32e-02, fs:0.82278 (r=0.747,p=0.915),  time:38.865, tt:1787.813\n",
      "Ep:46, loss:0.00001, loss_test:0.01646, lr:5.27e-02, fs:0.81529 (r=0.736,p=0.914),  time:38.883, tt:1827.512\n",
      "Ep:47, loss:0.00001, loss_test:0.01653, lr:5.21e-02, fs:0.81529 (r=0.736,p=0.914),  time:38.921, tt:1868.226\n",
      "Ep:48, loss:0.00001, loss_test:0.01669, lr:5.16e-02, fs:0.82051 (r=0.736,p=0.928),  time:38.967, tt:1909.375\n",
      "Ep:49, loss:0.00001, loss_test:0.01671, lr:5.11e-02, fs:0.81529 (r=0.736,p=0.914),  time:38.984, tt:1949.218\n",
      "Ep:50, loss:0.00001, loss_test:0.01682, lr:5.06e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.044, tt:1991.248\n",
      "Ep:51, loss:0.00001, loss_test:0.01692, lr:5.01e-02, fs:0.81818 (r=0.724,p=0.940),  time:39.120, tt:2034.237\n",
      "Ep:52, loss:0.00001, loss_test:0.01702, lr:4.96e-02, fs:0.81818 (r=0.724,p=0.940),  time:39.147, tt:2074.776\n",
      "Ep:53, loss:0.00001, loss_test:0.01718, lr:4.91e-02, fs:0.81046 (r=0.713,p=0.939),  time:39.201, tt:2116.844\n",
      "Ep:54, loss:0.00001, loss_test:0.01737, lr:4.86e-02, fs:0.80263 (r=0.701,p=0.938),  time:39.172, tt:2154.484\n",
      "Ep:55, loss:0.00001, loss_test:0.01742, lr:4.81e-02, fs:0.80263 (r=0.701,p=0.938),  time:39.191, tt:2194.710\n",
      "Ep:56, loss:0.00001, loss_test:0.01760, lr:4.76e-02, fs:0.80263 (r=0.701,p=0.938),  time:39.193, tt:2233.981\n",
      "Ep:57, loss:0.00001, loss_test:0.01777, lr:4.71e-02, fs:0.79470 (r=0.690,p=0.938),  time:39.206, tt:2273.948\n",
      "Ep:58, loss:0.00001, loss_test:0.01788, lr:4.67e-02, fs:0.79470 (r=0.690,p=0.938),  time:39.205, tt:2313.095\n",
      "Ep:59, loss:0.00001, loss_test:0.01792, lr:4.62e-02, fs:0.79470 (r=0.690,p=0.938),  time:39.219, tt:2353.114\n",
      "Ep:60, loss:0.00001, loss_test:0.01817, lr:4.57e-02, fs:0.77027 (r=0.655,p=0.934),  time:39.232, tt:2393.141\n",
      "Ep:61, loss:0.00001, loss_test:0.01816, lr:4.53e-02, fs:0.77852 (r=0.667,p=0.935),  time:39.236, tt:2432.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01828, lr:4.48e-02, fs:0.77852 (r=0.667,p=0.935),  time:39.252, tt:2472.900\n",
      "Ep:63, loss:0.00001, loss_test:0.01850, lr:4.44e-02, fs:0.77027 (r=0.655,p=0.934),  time:39.269, tt:2513.187\n",
      "Ep:64, loss:0.00001, loss_test:0.01867, lr:4.39e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.296, tt:2554.221\n",
      "Ep:65, loss:0.00001, loss_test:0.01876, lr:4.35e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.309, tt:2594.371\n",
      "Ep:66, loss:0.00001, loss_test:0.01897, lr:4.31e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.320, tt:2634.462\n",
      "Ep:67, loss:0.00001, loss_test:0.01910, lr:4.26e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.315, tt:2673.437\n",
      "Ep:68, loss:0.00001, loss_test:0.01917, lr:4.22e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.463, tt:2722.971\n",
      "Ep:69, loss:0.00001, loss_test:0.01940, lr:4.18e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.483, tt:2763.817\n",
      "Ep:70, loss:0.00001, loss_test:0.01954, lr:4.14e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.469, tt:2802.304\n",
      "Ep:71, loss:0.00000, loss_test:0.01948, lr:4.10e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.459, tt:2841.022\n",
      "Ep:72, loss:0.00000, loss_test:0.01967, lr:4.05e-02, fs:0.75862 (r=0.632,p=0.948),  time:39.483, tt:2882.288\n",
      "Ep:73, loss:0.00000, loss_test:0.01989, lr:4.01e-02, fs:0.75862 (r=0.632,p=0.948),  time:39.486, tt:2921.983\n",
      "Ep:74, loss:0.00000, loss_test:0.01995, lr:3.97e-02, fs:0.75862 (r=0.632,p=0.948),  time:39.472, tt:2960.431\n",
      "Ep:75, loss:0.00000, loss_test:0.02002, lr:3.93e-02, fs:0.75862 (r=0.632,p=0.948),  time:39.464, tt:2999.227\n",
      "Ep:76, loss:0.00000, loss_test:0.02013, lr:3.89e-02, fs:0.75862 (r=0.632,p=0.948),  time:39.462, tt:3038.555\n",
      "Ep:77, loss:0.00000, loss_test:0.02026, lr:3.86e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.474, tt:3078.942\n",
      "Ep:78, loss:0.00000, loss_test:0.02045, lr:3.82e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.486, tt:3119.433\n",
      "Ep:79, loss:0.00000, loss_test:0.02047, lr:3.78e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.482, tt:3158.552\n",
      "Ep:80, loss:0.00000, loss_test:0.02067, lr:3.74e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.509, tt:3200.195\n",
      "Ep:81, loss:0.00000, loss_test:0.02078, lr:3.70e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.516, tt:3240.275\n",
      "Ep:82, loss:0.00000, loss_test:0.02087, lr:3.67e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.508, tt:3279.202\n",
      "Ep:83, loss:0.00000, loss_test:0.02093, lr:3.63e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.474, tt:3315.845\n",
      "Ep:84, loss:0.00000, loss_test:0.02100, lr:3.59e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.457, tt:3353.812\n",
      "Ep:85, loss:0.00000, loss_test:0.02113, lr:3.56e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.456, tt:3393.226\n",
      "Ep:86, loss:0.00000, loss_test:0.02128, lr:3.52e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.468, tt:3433.721\n",
      "Ep:87, loss:0.00000, loss_test:0.02135, lr:3.49e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.457, tt:3472.245\n",
      "Ep:88, loss:0.00000, loss_test:0.02142, lr:3.45e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.460, tt:3511.983\n",
      "Ep:89, loss:0.00000, loss_test:0.02153, lr:3.42e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.451, tt:3550.635\n",
      "Ep:90, loss:0.00000, loss_test:0.02164, lr:3.38e-02, fs:0.71942 (r=0.575,p=0.962),  time:39.485, tt:3593.153\n",
      "Ep:91, loss:0.00000, loss_test:0.02174, lr:3.35e-02, fs:0.71942 (r=0.575,p=0.962),  time:39.502, tt:3634.142\n",
      "Ep:92, loss:0.00000, loss_test:0.02178, lr:3.32e-02, fs:0.71942 (r=0.575,p=0.962),  time:39.518, tt:3675.146\n",
      "Ep:93, loss:0.00000, loss_test:0.02189, lr:3.28e-02, fs:0.71942 (r=0.575,p=0.962),  time:39.526, tt:3715.436\n",
      "Ep:94, loss:0.00000, loss_test:0.02197, lr:3.25e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.527, tt:3755.023\n",
      "Ep:95, loss:0.00000, loss_test:0.02212, lr:3.22e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.549, tt:3796.678\n",
      "Ep:96, loss:0.00000, loss_test:0.02217, lr:3.19e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.548, tt:3836.201\n",
      "Ep:97, loss:0.00000, loss_test:0.02223, lr:3.15e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.540, tt:3874.927\n",
      "Ep:98, loss:0.00000, loss_test:0.02231, lr:3.12e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.544, tt:3914.874\n",
      "Ep:99, loss:0.00000, loss_test:0.02235, lr:3.09e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.544, tt:3954.382\n",
      "Ep:100, loss:0.00000, loss_test:0.02239, lr:3.06e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.545, tt:3994.045\n",
      "Ep:101, loss:0.00000, loss_test:0.02241, lr:3.03e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.564, tt:4035.553\n",
      "Ep:102, loss:0.00000, loss_test:0.02258, lr:3.00e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.578, tt:4076.492\n",
      "Ep:103, loss:0.00000, loss_test:0.02271, lr:2.97e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.576, tt:4115.921\n",
      "Ep:104, loss:0.00000, loss_test:0.02270, lr:2.94e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.573, tt:4155.172\n",
      "Ep:105, loss:0.00000, loss_test:0.02284, lr:2.91e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.558, tt:4193.139\n",
      "Ep:106, loss:0.00000, loss_test:0.02291, lr:2.88e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.563, tt:4233.209\n",
      "Ep:107, loss:0.00000, loss_test:0.02299, lr:2.85e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.565, tt:4273.031\n",
      "Ep:108, loss:0.00000, loss_test:0.02305, lr:2.82e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.581, tt:4314.342\n",
      "Ep:109, loss:0.00000, loss_test:0.02315, lr:2.80e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.565, tt:4352.180\n",
      "Ep:110, loss:0.00000, loss_test:0.02318, lr:2.77e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.574, tt:4392.759\n",
      "Ep:111, loss:0.00000, loss_test:0.02322, lr:2.74e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.618, tt:4437.166\n",
      "Ep:112, loss:0.00000, loss_test:0.02335, lr:2.71e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.633, tt:4478.573\n",
      "Ep:113, loss:0.00000, loss_test:0.02339, lr:2.69e-02, fs:0.71014 (r=0.563,p=0.961),  time:39.636, tt:4518.453\n",
      "Ep:114, loss:0.00000, loss_test:0.02346, lr:2.66e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.647, tt:4559.448\n",
      "Ep:115, loss:0.00000, loss_test:0.02353, lr:2.63e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.638, tt:4598.009\n",
      "Ep:116, loss:0.00000, loss_test:0.02360, lr:2.61e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.636, tt:4637.456\n",
      "Ep:117, loss:0.00000, loss_test:0.02360, lr:2.58e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.621, tt:4675.276\n",
      "Ep:118, loss:0.00000, loss_test:0.02372, lr:2.55e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.612, tt:4713.804\n",
      "Ep:119, loss:0.00000, loss_test:0.02378, lr:2.53e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.622, tt:4754.615\n",
      "Ep:120, loss:0.00000, loss_test:0.02381, lr:2.50e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.623, tt:4794.434\n",
      "Ep:121, loss:0.00000, loss_test:0.02390, lr:2.48e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.632, tt:4835.149\n",
      "Ep:122, loss:0.00000, loss_test:0.02393, lr:2.45e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.636, tt:4875.269\n",
      "Ep:123, loss:0.00000, loss_test:0.02406, lr:2.43e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.637, tt:4914.964\n",
      "Ep:124, loss:0.00000, loss_test:0.02410, lr:2.40e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.642, tt:4955.248\n",
      "Ep:125, loss:0.00000, loss_test:0.02412, lr:2.38e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.645, tt:4995.243\n",
      "Ep:126, loss:0.00000, loss_test:0.02420, lr:2.36e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.647, tt:5035.142\n",
      "Ep:127, loss:0.00000, loss_test:0.02424, lr:2.33e-02, fs:0.71533 (r=0.563,p=0.980),  time:39.648, tt:5074.989\n",
      "Ep:128, loss:0.00000, loss_test:0.02432, lr:2.31e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.664, tt:5116.604\n",
      "Ep:129, loss:0.00000, loss_test:0.02436, lr:2.29e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.675, tt:5157.719\n",
      "Ep:130, loss:0.00000, loss_test:0.02445, lr:2.26e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.680, tt:5198.074\n",
      "Ep:131, loss:0.00000, loss_test:0.02448, lr:2.24e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.687, tt:5238.657\n",
      "Ep:132, loss:0.00000, loss_test:0.02452, lr:2.22e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.696, tt:5279.581\n",
      "Ep:133, loss:0.00000, loss_test:0.02458, lr:2.20e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.705, tt:5320.424\n",
      "Ep:134, loss:0.00000, loss_test:0.02463, lr:2.17e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.705, tt:5360.147\n",
      "Ep:135, loss:0.00000, loss_test:0.02464, lr:2.15e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.698, tt:5398.986\n",
      "Ep:136, loss:0.00000, loss_test:0.02468, lr:2.13e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.699, tt:5438.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02477, lr:2.11e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.693, tt:5477.613\n",
      "Ep:138, loss:0.00000, loss_test:0.02481, lr:2.09e-02, fs:0.70588 (r=0.552,p=0.980),  time:39.697, tt:5517.871\n",
      "Ep:139, loss:0.00000, loss_test:0.02485, lr:2.07e-02, fs:0.69630 (r=0.540,p=0.979),  time:39.703, tt:5558.486\n",
      "Ep:140, loss:0.00000, loss_test:0.02493, lr:2.05e-02, fs:0.69630 (r=0.540,p=0.979),  time:39.713, tt:5599.596\n",
      "Ep:141, loss:0.00000, loss_test:0.02497, lr:2.03e-02, fs:0.69630 (r=0.540,p=0.979),  time:39.720, tt:5640.291\n",
      "Ep:142, loss:0.00000, loss_test:0.02501, lr:2.01e-02, fs:0.69630 (r=0.540,p=0.979),  time:39.719, tt:5679.764\n",
      "Ep:143, loss:0.00000, loss_test:0.02506, lr:1.99e-02, fs:0.69630 (r=0.540,p=0.979),  time:39.738, tt:5722.287\n",
      "Ep:144, loss:0.00000, loss_test:0.02507, lr:1.97e-02, fs:0.69630 (r=0.540,p=0.979),  time:39.746, tt:5763.163\n",
      "Ep:145, loss:0.00000, loss_test:0.02512, lr:1.95e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.753, tt:5803.874\n",
      "Ep:146, loss:0.00000, loss_test:0.02516, lr:1.93e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.778, tt:5847.372\n",
      "Ep:147, loss:0.00000, loss_test:0.02518, lr:1.91e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.797, tt:5890.026\n",
      "Ep:148, loss:0.00000, loss_test:0.02523, lr:1.89e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.813, tt:5932.133\n",
      "Ep:149, loss:0.00000, loss_test:0.02526, lr:1.87e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.849, tt:5977.396\n",
      "Ep:150, loss:0.00000, loss_test:0.02528, lr:1.85e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.875, tt:6021.163\n",
      "Ep:151, loss:0.00000, loss_test:0.02535, lr:1.83e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.899, tt:6064.619\n",
      "Ep:152, loss:0.00000, loss_test:0.02538, lr:1.81e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.918, tt:6107.505\n",
      "Ep:153, loss:0.00000, loss_test:0.02541, lr:1.80e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.936, tt:6150.186\n",
      "Ep:154, loss:0.00000, loss_test:0.02543, lr:1.78e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.954, tt:6192.863\n",
      "Ep:155, loss:0.00000, loss_test:0.02550, lr:1.76e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.962, tt:6234.031\n",
      "Ep:156, loss:0.00000, loss_test:0.02555, lr:1.74e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.977, tt:6276.369\n",
      "Ep:157, loss:0.00000, loss_test:0.02554, lr:1.73e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.991, tt:6318.604\n",
      "Ep:158, loss:0.00000, loss_test:0.02555, lr:1.71e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.992, tt:6358.683\n",
      "Ep:159, loss:0.00000, loss_test:0.02562, lr:1.69e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.994, tt:6398.994\n",
      "Ep:160, loss:0.00000, loss_test:0.02566, lr:1.67e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.008, tt:6441.265\n",
      "Ep:161, loss:0.00000, loss_test:0.02571, lr:1.66e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.021, tt:6483.424\n",
      "Ep:162, loss:0.00000, loss_test:0.02572, lr:1.64e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.038, tt:6526.176\n",
      "Ep:163, loss:0.00000, loss_test:0.02577, lr:1.62e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.041, tt:6566.775\n",
      "Ep:164, loss:0.00000, loss_test:0.02580, lr:1.61e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.036, tt:6606.009\n",
      "Ep:165, loss:0.00000, loss_test:0.02584, lr:1.59e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.035, tt:6645.781\n",
      "Ep:166, loss:0.00000, loss_test:0.02587, lr:1.58e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.069, tt:6691.587\n",
      "Ep:167, loss:0.00000, loss_test:0.02590, lr:1.56e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.070, tt:6731.740\n",
      "Ep:168, loss:0.00000, loss_test:0.02595, lr:1.54e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.062, tt:6770.518\n",
      "Ep:169, loss:0.00000, loss_test:0.02598, lr:1.53e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.053, tt:6809.006\n",
      "Ep:170, loss:0.00000, loss_test:0.02599, lr:1.51e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.042, tt:6847.106\n",
      "Ep:171, loss:0.00000, loss_test:0.02602, lr:1.50e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.043, tt:6887.338\n",
      "Ep:172, loss:0.00000, loss_test:0.02605, lr:1.48e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.041, tt:6927.085\n",
      "Ep:173, loss:0.00000, loss_test:0.02607, lr:1.47e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.038, tt:6966.580\n",
      "Ep:174, loss:0.00000, loss_test:0.02610, lr:1.45e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.030, tt:7005.258\n",
      "Ep:175, loss:0.00000, loss_test:0.02613, lr:1.44e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.028, tt:7044.889\n",
      "Ep:176, loss:0.00000, loss_test:0.02616, lr:1.43e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.017, tt:7082.984\n",
      "Ep:177, loss:0.00000, loss_test:0.02616, lr:1.41e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.014, tt:7122.443\n",
      "Ep:178, loss:0.00000, loss_test:0.02619, lr:1.40e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.007, tt:7161.186\n",
      "Ep:179, loss:0.00000, loss_test:0.02624, lr:1.38e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.003, tt:7200.473\n",
      "Ep:180, loss:0.00000, loss_test:0.02627, lr:1.37e-02, fs:0.70149 (r=0.540,p=1.000),  time:40.000, tt:7239.972\n",
      "Ep:181, loss:0.00000, loss_test:0.02629, lr:1.36e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.989, tt:7277.995\n",
      "Ep:182, loss:0.00000, loss_test:0.02633, lr:1.34e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.979, tt:7316.149\n",
      "Ep:183, loss:0.00000, loss_test:0.02635, lr:1.33e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.989, tt:7357.945\n",
      "Ep:184, loss:0.00000, loss_test:0.02638, lr:1.32e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.989, tt:7397.876\n",
      "Ep:185, loss:0.00000, loss_test:0.02641, lr:1.30e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.982, tt:7436.669\n",
      "Ep:186, loss:0.00000, loss_test:0.02645, lr:1.29e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.975, tt:7475.415\n",
      "Ep:187, loss:0.00000, loss_test:0.02649, lr:1.28e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.984, tt:7517.021\n",
      "Ep:188, loss:0.00000, loss_test:0.02648, lr:1.26e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.990, tt:7558.137\n",
      "Ep:189, loss:0.00000, loss_test:0.02651, lr:1.25e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.993, tt:7598.679\n",
      "Ep:190, loss:0.00000, loss_test:0.02656, lr:1.24e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.986, tt:7637.285\n",
      "Ep:191, loss:0.00000, loss_test:0.02658, lr:1.23e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.988, tt:7677.690\n",
      "Ep:192, loss:0.00000, loss_test:0.02662, lr:1.21e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.983, tt:7716.810\n",
      "Ep:193, loss:0.00000, loss_test:0.02665, lr:1.20e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.986, tt:7757.303\n",
      "Ep:194, loss:0.00000, loss_test:0.02667, lr:1.19e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.980, tt:7796.174\n",
      "Ep:195, loss:0.00000, loss_test:0.02669, lr:1.18e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.975, tt:7835.184\n",
      "Ep:196, loss:0.00000, loss_test:0.02673, lr:1.17e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.971, tt:7874.287\n",
      "Ep:197, loss:0.00000, loss_test:0.02676, lr:1.15e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.962, tt:7912.545\n",
      "Ep:198, loss:0.00000, loss_test:0.02676, lr:1.14e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.950, tt:7950.143\n",
      "Ep:199, loss:0.00000, loss_test:0.02677, lr:1.13e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.944, tt:7988.785\n",
      "Ep:200, loss:0.00000, loss_test:0.02681, lr:1.12e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.941, tt:8028.183\n",
      "Ep:201, loss:0.00000, loss_test:0.02682, lr:1.11e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.941, tt:8068.079\n",
      "Ep:202, loss:0.00000, loss_test:0.02685, lr:1.10e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.924, tt:8104.641\n",
      "Ep:203, loss:0.00000, loss_test:0.02686, lr:1.09e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.921, tt:8143.812\n",
      "Ep:204, loss:0.00000, loss_test:0.02688, lr:1.08e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.903, tt:8180.047\n",
      "Ep:205, loss:0.00000, loss_test:0.02689, lr:1.07e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.893, tt:8217.929\n",
      "Ep:206, loss:0.00000, loss_test:0.02690, lr:1.05e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.890, tt:8257.147\n",
      "Ep:207, loss:0.00000, loss_test:0.02694, lr:1.04e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.897, tt:8298.585\n",
      "Ep:208, loss:0.00000, loss_test:0.02697, lr:1.03e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.882, tt:8335.388\n",
      "Ep:209, loss:0.00000, loss_test:0.02699, lr:1.02e-02, fs:0.70149 (r=0.540,p=1.000),  time:39.837, tt:8365.754\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14215, lr:1.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:37.938, tt:37.938\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14054, lr:1.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:39.091, tt:78.183\n",
      "Ep:2, loss:0.00027, loss_test:0.13755, lr:1.00e-02, fs:0.65060 (r=0.931,p=0.500),  time:40.403, tt:121.209\n",
      "Ep:3, loss:0.00025, loss_test:0.13548, lr:1.00e-02, fs:0.67532 (r=0.897,p=0.542),  time:40.505, tt:162.020\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.13737, lr:1.00e-02, fs:0.59898 (r=0.678,p=0.536),  time:40.699, tt:203.493\n",
      "Ep:5, loss:0.00022, loss_test:0.14382, lr:1.00e-02, fs:0.57297 (r=0.609,p=0.541),  time:40.774, tt:244.644\n",
      "Ep:6, loss:0.00022, loss_test:0.14022, lr:1.00e-02, fs:0.58511 (r=0.632,p=0.545),  time:41.738, tt:292.168\n",
      "Ep:7, loss:0.00021, loss_test:0.13425, lr:1.00e-02, fs:0.63590 (r=0.713,p=0.574),  time:41.927, tt:335.412\n",
      "Ep:8, loss:0.00020, loss_test:0.13141, lr:1.00e-02, fs:0.62766 (r=0.678,p=0.584),  time:41.920, tt:377.278\n",
      "Ep:9, loss:0.00019, loss_test:0.12969, lr:1.00e-02, fs:0.63333 (r=0.655,p=0.613),  time:42.087, tt:420.873\n",
      "Ep:10, loss:0.00019, loss_test:0.12745, lr:1.00e-02, fs:0.63333 (r=0.655,p=0.613),  time:41.957, tt:461.532\n",
      "Ep:11, loss:0.00018, loss_test:0.12322, lr:1.00e-02, fs:0.63388 (r=0.667,p=0.604),  time:41.972, tt:503.659\n",
      "Ep:12, loss:0.00017, loss_test:0.12009, lr:1.00e-02, fs:0.64407 (r=0.655,p=0.633),  time:41.921, tt:544.976\n",
      "Ep:13, loss:0.00017, loss_test:0.11667, lr:1.00e-02, fs:0.62428 (r=0.621,p=0.628),  time:41.937, tt:587.115\n",
      "Ep:14, loss:0.00016, loss_test:0.11414, lr:1.00e-02, fs:0.61176 (r=0.598,p=0.627),  time:42.047, tt:630.702\n",
      "Ep:15, loss:0.00015, loss_test:0.10978, lr:9.90e-03, fs:0.62722 (r=0.609,p=0.646),  time:41.964, tt:671.429\n",
      "Ep:16, loss:0.00015, loss_test:0.10813, lr:9.80e-03, fs:0.61818 (r=0.586,p=0.654),  time:41.867, tt:711.732\n",
      "Ep:17, loss:0.00014, loss_test:0.10618, lr:9.70e-03, fs:0.62651 (r=0.598,p=0.658),  time:41.824, tt:752.826\n",
      "Ep:18, loss:0.00014, loss_test:0.10502, lr:9.61e-03, fs:0.68639 (r=0.667,p=0.707),  time:41.856, tt:795.269\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.10214, lr:9.61e-03, fs:0.67456 (r=0.655,p=0.695),  time:41.930, tt:838.603\n",
      "Ep:20, loss:0.00013, loss_test:0.10293, lr:9.61e-03, fs:0.69461 (r=0.667,p=0.725),  time:41.886, tt:879.610\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.10404, lr:9.61e-03, fs:0.69412 (r=0.678,p=0.711),  time:41.861, tt:920.953\n",
      "Ep:22, loss:0.00011, loss_test:0.09975, lr:9.61e-03, fs:0.71006 (r=0.690,p=0.732),  time:41.886, tt:963.380\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.10048, lr:9.61e-03, fs:0.69091 (r=0.655,p=0.731),  time:41.852, tt:1004.450\n",
      "Ep:24, loss:0.00010, loss_test:0.10154, lr:9.61e-03, fs:0.69512 (r=0.655,p=0.740),  time:41.934, tt:1048.346\n",
      "Ep:25, loss:0.00010, loss_test:0.10001, lr:9.61e-03, fs:0.69939 (r=0.655,p=0.750),  time:41.986, tt:1091.642\n",
      "Ep:26, loss:0.00009, loss_test:0.09806, lr:9.61e-03, fs:0.72393 (r=0.678,p=0.776),  time:42.082, tt:1136.219\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.09944, lr:9.61e-03, fs:0.71795 (r=0.644,p=0.812),  time:42.104, tt:1178.917\n",
      "Ep:28, loss:0.00009, loss_test:0.09476, lr:9.61e-03, fs:0.74390 (r=0.701,p=0.792),  time:42.186, tt:1223.401\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.09765, lr:9.61e-03, fs:0.71895 (r=0.632,p=0.833),  time:42.278, tt:1268.350\n",
      "Ep:30, loss:0.00008, loss_test:0.09547, lr:9.61e-03, fs:0.72152 (r=0.655,p=0.803),  time:42.213, tt:1308.616\n",
      "Ep:31, loss:0.00007, loss_test:0.09513, lr:9.61e-03, fs:0.73684 (r=0.644,p=0.862),  time:42.283, tt:1353.051\n",
      "Ep:32, loss:0.00007, loss_test:0.09184, lr:9.61e-03, fs:0.72727 (r=0.644,p=0.836),  time:42.337, tt:1397.107\n",
      "Ep:33, loss:0.00007, loss_test:0.09308, lr:9.61e-03, fs:0.72727 (r=0.644,p=0.836),  time:42.300, tt:1438.193\n",
      "Ep:34, loss:0.00006, loss_test:0.08997, lr:9.61e-03, fs:0.73203 (r=0.644,p=0.848),  time:42.368, tt:1482.888\n",
      "Ep:35, loss:0.00006, loss_test:0.09368, lr:9.61e-03, fs:0.71523 (r=0.621,p=0.844),  time:42.384, tt:1525.807\n",
      "Ep:36, loss:0.00006, loss_test:0.08599, lr:9.61e-03, fs:0.69799 (r=0.598,p=0.839),  time:42.338, tt:1566.510\n",
      "Ep:37, loss:0.00005, loss_test:0.09419, lr:9.61e-03, fs:0.70748 (r=0.598,p=0.867),  time:42.317, tt:1608.046\n",
      "Ep:38, loss:0.00005, loss_test:0.08637, lr:9.61e-03, fs:0.70270 (r=0.598,p=0.852),  time:42.308, tt:1650.021\n",
      "Ep:39, loss:0.00005, loss_test:0.09209, lr:9.61e-03, fs:0.70748 (r=0.598,p=0.867),  time:42.304, tt:1692.145\n",
      "Ep:40, loss:0.00004, loss_test:0.08887, lr:9.51e-03, fs:0.71233 (r=0.598,p=0.881),  time:42.337, tt:1735.815\n",
      "Ep:41, loss:0.00004, loss_test:0.09228, lr:9.41e-03, fs:0.70748 (r=0.598,p=0.867),  time:42.281, tt:1775.812\n",
      "Ep:42, loss:0.00004, loss_test:0.08993, lr:9.32e-03, fs:0.71233 (r=0.598,p=0.881),  time:42.306, tt:1819.155\n",
      "Ep:43, loss:0.00004, loss_test:0.09550, lr:9.23e-03, fs:0.70748 (r=0.598,p=0.867),  time:42.305, tt:1861.414\n",
      "Ep:44, loss:0.00004, loss_test:0.08767, lr:9.14e-03, fs:0.70270 (r=0.598,p=0.852),  time:42.300, tt:1903.478\n",
      "Ep:45, loss:0.00003, loss_test:0.09638, lr:9.04e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.293, tt:1945.479\n",
      "Ep:46, loss:0.00003, loss_test:0.08674, lr:8.95e-03, fs:0.70270 (r=0.598,p=0.852),  time:42.251, tt:1985.814\n",
      "Ep:47, loss:0.00003, loss_test:0.09635, lr:8.86e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.307, tt:2030.726\n",
      "Ep:48, loss:0.00003, loss_test:0.08769, lr:8.78e-03, fs:0.72222 (r=0.598,p=0.912),  time:42.314, tt:2073.386\n",
      "Ep:49, loss:0.00003, loss_test:0.09396, lr:8.69e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.337, tt:2116.843\n",
      "Ep:50, loss:0.00003, loss_test:0.08944, lr:8.60e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.322, tt:2158.445\n",
      "Ep:51, loss:0.00002, loss_test:0.09800, lr:8.51e-03, fs:0.73239 (r=0.598,p=0.945),  time:42.294, tt:2199.272\n",
      "Ep:52, loss:0.00002, loss_test:0.09047, lr:8.43e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.270, tt:2240.306\n",
      "Ep:53, loss:0.00002, loss_test:0.09357, lr:8.35e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.316, tt:2285.052\n",
      "Ep:54, loss:0.00002, loss_test:0.09251, lr:8.26e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.283, tt:2325.590\n",
      "Ep:55, loss:0.00002, loss_test:0.09289, lr:8.18e-03, fs:0.73239 (r=0.598,p=0.945),  time:42.271, tt:2367.154\n",
      "Ep:56, loss:0.00002, loss_test:0.09168, lr:8.10e-03, fs:0.71724 (r=0.598,p=0.897),  time:42.248, tt:2408.110\n",
      "Ep:57, loss:0.00002, loss_test:0.09732, lr:8.02e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.207, tt:2448.016\n",
      "Ep:58, loss:0.00002, loss_test:0.09393, lr:7.94e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.190, tt:2489.226\n",
      "Ep:59, loss:0.00002, loss_test:0.09053, lr:7.86e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.179, tt:2530.727\n",
      "Ep:60, loss:0.00002, loss_test:0.09308, lr:7.78e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.157, tt:2571.563\n",
      "Ep:61, loss:0.00002, loss_test:0.09122, lr:7.70e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.110, tt:2610.824\n",
      "Ep:62, loss:0.00001, loss_test:0.09289, lr:7.62e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.070, tt:2650.407\n",
      "Ep:63, loss:0.00001, loss_test:0.09097, lr:7.55e-03, fs:0.72727 (r=0.598,p=0.929),  time:42.000, tt:2688.014\n",
      "Ep:64, loss:0.00001, loss_test:0.09243, lr:7.47e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.962, tt:2727.512\n",
      "Ep:65, loss:0.00001, loss_test:0.09561, lr:7.40e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.965, tt:2769.683\n",
      "Ep:66, loss:0.00001, loss_test:0.09201, lr:7.32e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.955, tt:2810.970\n",
      "Ep:67, loss:0.00001, loss_test:0.09500, lr:7.25e-03, fs:0.72222 (r=0.598,p=0.912),  time:41.933, tt:2851.416\n",
      "Ep:68, loss:0.00001, loss_test:0.09360, lr:7.18e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.938, tt:2893.756\n",
      "Ep:69, loss:0.00001, loss_test:0.09464, lr:7.11e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.961, tt:2937.296\n",
      "Ep:70, loss:0.00001, loss_test:0.09506, lr:7.03e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.944, tt:2977.999\n",
      "Ep:71, loss:0.00001, loss_test:0.09563, lr:6.96e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.936, tt:3019.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.09623, lr:6.89e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.938, tt:3061.478\n",
      "Ep:73, loss:0.00001, loss_test:0.09656, lr:6.83e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.917, tt:3101.841\n",
      "Ep:74, loss:0.00001, loss_test:0.09568, lr:6.76e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.909, tt:3143.145\n",
      "Ep:75, loss:0.00001, loss_test:0.09860, lr:6.69e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.918, tt:3185.792\n",
      "Ep:76, loss:0.00001, loss_test:0.09464, lr:6.62e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.902, tt:3226.428\n",
      "Ep:77, loss:0.00001, loss_test:0.09858, lr:6.56e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.888, tt:3267.227\n",
      "Ep:78, loss:0.00001, loss_test:0.09311, lr:6.49e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.867, tt:3307.516\n",
      "Ep:79, loss:0.00001, loss_test:0.09819, lr:6.43e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.843, tt:3347.448\n",
      "Ep:80, loss:0.00001, loss_test:0.09453, lr:6.36e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.818, tt:3387.282\n",
      "Ep:81, loss:0.00001, loss_test:0.09747, lr:6.30e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.821, tt:3429.345\n",
      "Ep:82, loss:0.00001, loss_test:0.09453, lr:6.24e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.799, tt:3469.339\n",
      "Ep:83, loss:0.00001, loss_test:0.09738, lr:6.17e-03, fs:0.72727 (r=0.598,p=0.929),  time:41.766, tt:3508.367\n",
      "Ep:84, loss:0.00001, loss_test:0.09567, lr:6.11e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.765, tt:3550.010\n",
      "Ep:85, loss:0.00001, loss_test:0.09671, lr:6.05e-03, fs:0.73239 (r=0.598,p=0.945),  time:41.754, tt:3590.831\n",
      "Ep:86, loss:0.00001, loss_test:0.09565, lr:5.99e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.723, tt:3629.936\n",
      "Ep:87, loss:0.00001, loss_test:0.09844, lr:5.93e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.732, tt:3672.431\n",
      "Ep:88, loss:0.00001, loss_test:0.09438, lr:5.87e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.721, tt:3713.159\n",
      "Ep:89, loss:0.00001, loss_test:0.09873, lr:5.81e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.715, tt:3754.365\n",
      "Ep:90, loss:0.00001, loss_test:0.09592, lr:5.75e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.724, tt:3796.908\n",
      "Ep:91, loss:0.00001, loss_test:0.09808, lr:5.70e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.711, tt:3837.394\n",
      "Ep:92, loss:0.00001, loss_test:0.09773, lr:5.64e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.715, tt:3879.510\n",
      "Ep:93, loss:0.00001, loss_test:0.09586, lr:5.58e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.712, tt:3920.973\n",
      "Ep:94, loss:0.00001, loss_test:0.09662, lr:5.53e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.727, tt:3964.084\n",
      "Ep:95, loss:0.00001, loss_test:0.09642, lr:5.47e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.711, tt:4004.211\n",
      "Ep:96, loss:0.00001, loss_test:0.09591, lr:5.42e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.734, tt:4048.240\n",
      "Ep:97, loss:0.00001, loss_test:0.09720, lr:5.36e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.728, tt:4089.298\n",
      "Ep:98, loss:0.00001, loss_test:0.09693, lr:5.31e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.735, tt:4131.745\n",
      "Ep:99, loss:0.00000, loss_test:0.09675, lr:5.26e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.725, tt:4172.461\n",
      "Ep:100, loss:0.00000, loss_test:0.09657, lr:5.20e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.732, tt:4214.915\n",
      "Ep:101, loss:0.00000, loss_test:0.09769, lr:5.15e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.751, tt:4258.616\n",
      "Ep:102, loss:0.00000, loss_test:0.09762, lr:5.10e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.755, tt:4300.735\n",
      "Ep:103, loss:0.00000, loss_test:0.09667, lr:5.05e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.752, tt:4342.240\n",
      "Ep:104, loss:0.00000, loss_test:0.09722, lr:5.00e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.745, tt:4383.230\n",
      "Ep:105, loss:0.00000, loss_test:0.09601, lr:4.95e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.728, tt:4423.174\n",
      "Ep:106, loss:0.00000, loss_test:0.09816, lr:4.90e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.719, tt:4463.982\n",
      "Ep:107, loss:0.00000, loss_test:0.09607, lr:4.85e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.714, tt:4505.161\n",
      "Ep:108, loss:0.00000, loss_test:0.09745, lr:4.80e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.712, tt:4546.660\n",
      "Ep:109, loss:0.00000, loss_test:0.09773, lr:4.75e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.711, tt:4588.240\n",
      "Ep:110, loss:0.00000, loss_test:0.09612, lr:4.71e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.708, tt:4629.543\n",
      "Ep:111, loss:0.00000, loss_test:0.09620, lr:4.66e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.750, tt:4676.006\n",
      "Ep:112, loss:0.00000, loss_test:0.09859, lr:4.61e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.752, tt:4717.972\n",
      "Ep:113, loss:0.00000, loss_test:0.09693, lr:4.57e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.746, tt:4759.019\n",
      "Ep:114, loss:0.00000, loss_test:0.09680, lr:4.52e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.760, tt:4802.444\n",
      "Ep:115, loss:0.00000, loss_test:0.09806, lr:4.48e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.754, tt:4843.453\n",
      "Ep:116, loss:0.00000, loss_test:0.09605, lr:4.43e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.765, tt:4886.536\n",
      "Ep:117, loss:0.00000, loss_test:0.09738, lr:4.39e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.770, tt:4928.899\n",
      "Ep:118, loss:0.00000, loss_test:0.09617, lr:4.34e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.764, tt:4969.975\n",
      "Ep:119, loss:0.00000, loss_test:0.09707, lr:4.30e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.767, tt:5012.031\n",
      "Ep:120, loss:0.00000, loss_test:0.09667, lr:4.26e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.765, tt:5053.595\n",
      "Ep:121, loss:0.00000, loss_test:0.09777, lr:4.21e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.755, tt:5094.101\n",
      "Ep:122, loss:0.00000, loss_test:0.09655, lr:4.17e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.764, tt:5137.032\n",
      "Ep:123, loss:0.00000, loss_test:0.09675, lr:4.13e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.745, tt:5176.326\n",
      "Ep:124, loss:0.00000, loss_test:0.09659, lr:4.09e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.730, tt:5216.253\n",
      "Ep:125, loss:0.00000, loss_test:0.09725, lr:4.05e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.722, tt:5256.917\n",
      "Ep:126, loss:0.00000, loss_test:0.09771, lr:4.01e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.717, tt:5298.099\n",
      "Ep:127, loss:0.00000, loss_test:0.09679, lr:3.97e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.716, tt:5339.689\n",
      "Ep:128, loss:0.00000, loss_test:0.09684, lr:3.93e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.713, tt:5381.008\n",
      "Ep:129, loss:0.00000, loss_test:0.09652, lr:3.89e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.715, tt:5422.955\n",
      "Ep:130, loss:0.00000, loss_test:0.09720, lr:3.85e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.706, tt:5463.496\n",
      "Ep:131, loss:0.00000, loss_test:0.09871, lr:3.81e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.739, tt:5509.568\n",
      "Ep:132, loss:0.00000, loss_test:0.09687, lr:3.77e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.736, tt:5550.935\n",
      "Ep:133, loss:0.00000, loss_test:0.09680, lr:3.73e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.718, tt:5590.238\n",
      "Ep:134, loss:0.00000, loss_test:0.09692, lr:3.70e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.712, tt:5631.094\n",
      "Ep:135, loss:0.00000, loss_test:0.09646, lr:3.66e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.697, tt:5670.780\n",
      "Ep:136, loss:0.00000, loss_test:0.09660, lr:3.62e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.704, tt:5713.425\n",
      "Ep:137, loss:0.00000, loss_test:0.09678, lr:3.59e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.705, tt:5755.267\n",
      "Ep:138, loss:0.00000, loss_test:0.09652, lr:3.55e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.706, tt:5797.141\n",
      "Ep:139, loss:0.00000, loss_test:0.09590, lr:3.52e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.704, tt:5838.580\n",
      "Ep:140, loss:0.00000, loss_test:0.09742, lr:3.48e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.701, tt:5879.815\n",
      "Ep:141, loss:0.00000, loss_test:0.09795, lr:3.45e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.695, tt:5920.723\n",
      "Ep:142, loss:0.00000, loss_test:0.09623, lr:3.41e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.698, tt:5962.838\n",
      "Ep:143, loss:0.00000, loss_test:0.09694, lr:3.38e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.684, tt:6002.509\n",
      "Ep:144, loss:0.00000, loss_test:0.09708, lr:3.34e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.695, tt:6045.727\n",
      "Ep:145, loss:0.00000, loss_test:0.09641, lr:3.31e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.694, tt:6087.390\n",
      "Ep:146, loss:0.00000, loss_test:0.09697, lr:3.28e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.693, tt:6128.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.09732, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.674, tt:6167.791\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00000, loss_test:0.09692, lr:3.24e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.667, tt:6208.337\n",
      "Ep:149, loss:0.00000, loss_test:0.09604, lr:3.24e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.660, tt:6249.016\n",
      "Ep:150, loss:0.00000, loss_test:0.09722, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.661, tt:6290.823\n",
      "Ep:151, loss:0.00000, loss_test:0.09837, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.656, tt:6331.692\n",
      "Ep:152, loss:0.00000, loss_test:0.09662, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.670, tt:6375.506\n",
      "Ep:153, loss:0.00000, loss_test:0.09635, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.665, tt:6416.425\n",
      "Ep:154, loss:0.00000, loss_test:0.09714, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.638, tt:6453.855\n",
      "Ep:155, loss:0.00000, loss_test:0.09651, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.625, tt:6493.564\n",
      "Ep:156, loss:0.00000, loss_test:0.09648, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.616, tt:6533.716\n",
      "Ep:157, loss:0.00000, loss_test:0.09708, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.615, tt:6575.135\n",
      "Ep:158, loss:0.00000, loss_test:0.09684, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.597, tt:6613.944\n",
      "Ep:159, loss:0.00000, loss_test:0.09607, lr:3.21e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.593, tt:6654.851\n",
      "Ep:160, loss:0.00000, loss_test:0.09792, lr:3.18e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.595, tt:6696.830\n",
      "Ep:161, loss:0.00000, loss_test:0.09751, lr:3.15e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.589, tt:6737.484\n",
      "Ep:162, loss:0.00000, loss_test:0.09672, lr:3.12e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.589, tt:6778.927\n",
      "Ep:163, loss:0.00000, loss_test:0.09725, lr:3.09e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.587, tt:6820.273\n",
      "Ep:164, loss:0.00000, loss_test:0.09733, lr:3.05e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.577, tt:6860.221\n",
      "Ep:165, loss:0.00000, loss_test:0.09679, lr:3.02e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.576, tt:6901.669\n",
      "Ep:166, loss:0.00000, loss_test:0.09704, lr:2.99e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.563, tt:6940.960\n",
      "Ep:167, loss:0.00000, loss_test:0.09681, lr:2.96e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.538, tt:6978.323\n",
      "Ep:168, loss:0.00000, loss_test:0.09632, lr:2.93e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.541, tt:7020.487\n",
      "Ep:169, loss:0.00000, loss_test:0.09742, lr:2.90e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.544, tt:7062.430\n",
      "Ep:170, loss:0.00000, loss_test:0.09679, lr:2.88e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.532, tt:7102.017\n",
      "Ep:171, loss:0.00000, loss_test:0.09687, lr:2.85e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.517, tt:7140.875\n",
      "Ep:172, loss:0.00000, loss_test:0.09725, lr:2.82e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.537, tt:7185.870\n",
      "Ep:173, loss:0.00000, loss_test:0.09695, lr:2.79e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.530, tt:7226.288\n",
      "Ep:174, loss:0.00000, loss_test:0.09627, lr:2.76e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.519, tt:7265.755\n",
      "Ep:175, loss:0.00000, loss_test:0.09737, lr:2.73e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.514, tt:7306.545\n",
      "Ep:176, loss:0.00000, loss_test:0.09712, lr:2.71e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.501, tt:7345.670\n",
      "Ep:177, loss:0.00000, loss_test:0.09699, lr:2.68e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.487, tt:7384.645\n",
      "Ep:178, loss:0.00000, loss_test:0.09712, lr:2.65e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.476, tt:7424.200\n",
      "Ep:179, loss:0.00000, loss_test:0.09749, lr:2.63e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.458, tt:7462.403\n",
      "Ep:180, loss:0.00000, loss_test:0.09706, lr:2.60e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.456, tt:7503.543\n",
      "Ep:181, loss:0.00000, loss_test:0.09718, lr:2.57e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.446, tt:7543.171\n",
      "Ep:182, loss:0.00000, loss_test:0.09715, lr:2.55e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.444, tt:7584.314\n",
      "Ep:183, loss:0.00000, loss_test:0.09719, lr:2.52e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.444, tt:7625.739\n",
      "Ep:184, loss:0.00000, loss_test:0.09744, lr:2.50e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.436, tt:7665.591\n",
      "Ep:185, loss:0.00000, loss_test:0.09681, lr:2.47e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.433, tt:7706.615\n",
      "Ep:186, loss:0.00000, loss_test:0.09745, lr:2.45e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.439, tt:7749.147\n",
      "Ep:187, loss:0.00000, loss_test:0.09749, lr:2.42e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.427, tt:7788.258\n",
      "Ep:188, loss:0.00000, loss_test:0.09667, lr:2.40e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.418, tt:7827.952\n",
      "Ep:189, loss:0.00000, loss_test:0.09760, lr:2.38e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.408, tt:7867.546\n",
      "Ep:190, loss:0.00000, loss_test:0.09783, lr:2.35e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.392, tt:7905.893\n",
      "Ep:191, loss:0.00000, loss_test:0.09710, lr:2.33e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.394, tt:7947.572\n",
      "Ep:192, loss:0.00000, loss_test:0.09717, lr:2.31e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.380, tt:7986.328\n",
      "Ep:193, loss:0.00000, loss_test:0.09735, lr:2.28e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.402, tt:8031.963\n",
      "Ep:194, loss:0.00000, loss_test:0.09683, lr:2.26e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.393, tt:8071.723\n",
      "Ep:195, loss:0.00000, loss_test:0.09658, lr:2.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.387, tt:8111.900\n",
      "Ep:196, loss:0.00000, loss_test:0.09699, lr:2.21e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.391, tt:8153.980\n",
      "Ep:197, loss:0.00000, loss_test:0.09682, lr:2.19e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.393, tt:8195.887\n",
      "Ep:198, loss:0.00000, loss_test:0.09671, lr:2.17e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.397, tt:8237.993\n",
      "Ep:199, loss:0.00000, loss_test:0.09688, lr:2.15e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.394, tt:8278.864\n",
      "Ep:200, loss:0.00000, loss_test:0.09641, lr:2.13e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.392, tt:8319.707\n",
      "Ep:201, loss:0.00000, loss_test:0.09704, lr:2.11e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.399, tt:8362.650\n",
      "Ep:202, loss:0.00000, loss_test:0.09707, lr:2.08e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.391, tt:8402.456\n",
      "Ep:203, loss:0.00000, loss_test:0.09639, lr:2.06e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.393, tt:8444.253\n",
      "Ep:204, loss:0.00000, loss_test:0.09696, lr:2.04e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.358, tt:8478.428\n",
      "Ep:205, loss:0.00000, loss_test:0.09784, lr:2.02e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.340, tt:8516.014\n",
      "Ep:206, loss:0.00000, loss_test:0.09748, lr:2.00e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.305, tt:8550.235\n",
      "Ep:207, loss:0.00000, loss_test:0.09663, lr:1.98e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.290, tt:8588.261\n",
      "Ep:208, loss:0.00000, loss_test:0.09701, lr:1.96e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.271, tt:8625.562\n",
      "Ep:209, loss:0.00000, loss_test:0.09710, lr:1.94e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.177, tt:8647.070\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02160, lr:6.00e-02, fs:0.66972 (r=0.839,p=0.557),  time:19.887, tt:19.887\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02077, lr:6.00e-02, fs:0.65600 (r=0.943,p=0.503),  time:22.804, tt:45.608\n",
      "Ep:2, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:24.690, tt:74.071\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02024, lr:6.00e-02, fs:0.65060 (r=0.931,p=0.500),  time:26.196, tt:104.783\n",
      "Ep:4, loss:0.00004, loss_test:0.01991, lr:6.00e-02, fs:0.68670 (r=0.920,p=0.548),  time:26.662, tt:133.310\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02071, lr:6.00e-02, fs:0.69608 (r=0.816,p=0.607),  time:27.046, tt:162.278\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00003, loss_test:0.02126, lr:6.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:27.572, tt:193.006\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00003, loss_test:0.02026, lr:6.00e-02, fs:0.71429 (r=0.805,p=0.642),  time:27.703, tt:221.626\n",
      "Ep:8, loss:0.00003, loss_test:0.01873, lr:6.00e-02, fs:0.68627 (r=0.805,p=0.598),  time:28.024, tt:252.216\n",
      "Ep:9, loss:0.00003, loss_test:0.01797, lr:6.00e-02, fs:0.72897 (r=0.897,p=0.614),  time:28.107, tt:281.075\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01769, lr:6.00e-02, fs:0.72986 (r=0.885,p=0.621),  time:28.352, tt:311.874\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.74747 (r=0.851,p=0.667),  time:28.556, tt:342.667\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01814, lr:6.00e-02, fs:0.75648 (r=0.839,p=0.689),  time:28.703, tt:373.145\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01791, lr:6.00e-02, fs:0.75897 (r=0.851,p=0.685),  time:28.701, tt:401.808\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.77778 (r=0.885,p=0.694),  time:28.769, tt:431.541\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00002, loss_test:0.01669, lr:6.00e-02, fs:0.78392 (r=0.897,p=0.696),  time:28.965, tt:463.435\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00002, loss_test:0.01633, lr:6.00e-02, fs:0.81818 (r=0.931,p=0.730),  time:29.182, tt:496.100\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.81407 (r=0.931,p=0.723),  time:29.232, tt:526.171\n",
      "Ep:18, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.82234 (r=0.931,p=0.736),  time:29.297, tt:556.636\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01593, lr:6.00e-02, fs:0.82234 (r=0.931,p=0.736),  time:29.255, tt:585.103\n",
      "Ep:20, loss:0.00002, loss_test:0.01579, lr:6.00e-02, fs:0.82234 (r=0.931,p=0.736),  time:29.259, tt:614.432\n",
      "Ep:21, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:29.365, tt:646.024\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.82723 (r=0.908,p=0.760),  time:29.427, tt:676.824\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01553, lr:6.00e-02, fs:0.80214 (r=0.862,p=0.750),  time:29.407, tt:705.770\n",
      "Ep:24, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.78919 (r=0.839,p=0.745),  time:29.427, tt:735.671\n",
      "Ep:25, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.78919 (r=0.839,p=0.745),  time:29.459, tt:765.938\n",
      "Ep:26, loss:0.00002, loss_test:0.01550, lr:6.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:29.571, tt:798.417\n",
      "Ep:27, loss:0.00002, loss_test:0.01551, lr:6.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:29.769, tt:833.544\n",
      "Ep:28, loss:0.00001, loss_test:0.01550, lr:6.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:29.822, tt:864.849\n",
      "Ep:29, loss:0.00001, loss_test:0.01554, lr:6.00e-02, fs:0.76744 (r=0.759,p=0.776),  time:29.826, tt:894.774\n",
      "Ep:30, loss:0.00001, loss_test:0.01566, lr:6.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:29.895, tt:926.739\n",
      "Ep:31, loss:0.00001, loss_test:0.01560, lr:6.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:29.967, tt:958.929\n",
      "Ep:32, loss:0.00001, loss_test:0.01552, lr:6.00e-02, fs:0.75000 (r=0.724,p=0.778),  time:30.043, tt:991.416\n",
      "Ep:33, loss:0.00001, loss_test:0.01563, lr:6.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:30.051, tt:1021.722\n",
      "Ep:34, loss:0.00001, loss_test:0.01573, lr:5.94e-02, fs:0.74390 (r=0.701,p=0.792),  time:30.090, tt:1053.153\n",
      "Ep:35, loss:0.00001, loss_test:0.01568, lr:5.88e-02, fs:0.74074 (r=0.690,p=0.800),  time:30.176, tt:1086.348\n",
      "Ep:36, loss:0.00001, loss_test:0.01576, lr:5.82e-02, fs:0.74074 (r=0.690,p=0.800),  time:30.226, tt:1118.362\n",
      "Ep:37, loss:0.00001, loss_test:0.01602, lr:5.76e-02, fs:0.72152 (r=0.655,p=0.803),  time:30.208, tt:1147.908\n",
      "Ep:38, loss:0.00001, loss_test:0.01593, lr:5.71e-02, fs:0.73418 (r=0.667,p=0.817),  time:30.220, tt:1178.591\n",
      "Ep:39, loss:0.00001, loss_test:0.01593, lr:5.65e-02, fs:0.72611 (r=0.655,p=0.814),  time:30.257, tt:1210.277\n",
      "Ep:40, loss:0.00001, loss_test:0.01608, lr:5.59e-02, fs:0.72258 (r=0.644,p=0.824),  time:30.230, tt:1239.443\n",
      "Ep:41, loss:0.00001, loss_test:0.01618, lr:5.54e-02, fs:0.72727 (r=0.644,p=0.836),  time:30.229, tt:1269.603\n",
      "Ep:42, loss:0.00001, loss_test:0.01623, lr:5.48e-02, fs:0.71895 (r=0.632,p=0.833),  time:30.253, tt:1300.890\n",
      "Ep:43, loss:0.00001, loss_test:0.01622, lr:5.43e-02, fs:0.72368 (r=0.632,p=0.846),  time:30.269, tt:1331.853\n",
      "Ep:44, loss:0.00001, loss_test:0.01622, lr:5.37e-02, fs:0.72368 (r=0.632,p=0.846),  time:30.299, tt:1363.433\n",
      "Ep:45, loss:0.00001, loss_test:0.01635, lr:5.32e-02, fs:0.72368 (r=0.632,p=0.846),  time:30.239, tt:1390.997\n",
      "Ep:46, loss:0.00001, loss_test:0.01653, lr:5.27e-02, fs:0.72368 (r=0.632,p=0.846),  time:30.222, tt:1420.435\n",
      "Ep:47, loss:0.00001, loss_test:0.01661, lr:5.21e-02, fs:0.72368 (r=0.632,p=0.846),  time:30.214, tt:1450.281\n",
      "Ep:48, loss:0.00001, loss_test:0.01676, lr:5.16e-02, fs:0.72848 (r=0.632,p=0.859),  time:30.224, tt:1480.989\n",
      "Ep:49, loss:0.00001, loss_test:0.01679, lr:5.11e-02, fs:0.72973 (r=0.621,p=0.885),  time:30.239, tt:1511.961\n",
      "Ep:50, loss:0.00001, loss_test:0.01691, lr:5.06e-02, fs:0.72973 (r=0.621,p=0.885),  time:30.258, tt:1543.149\n",
      "Ep:51, loss:0.00001, loss_test:0.01711, lr:5.01e-02, fs:0.72973 (r=0.621,p=0.885),  time:30.304, tt:1575.823\n",
      "Ep:52, loss:0.00001, loss_test:0.01719, lr:4.96e-02, fs:0.72973 (r=0.621,p=0.885),  time:30.316, tt:1606.725\n",
      "Ep:53, loss:0.00001, loss_test:0.01727, lr:4.91e-02, fs:0.73469 (r=0.621,p=0.900),  time:30.347, tt:1638.737\n",
      "Ep:54, loss:0.00001, loss_test:0.01738, lr:4.86e-02, fs:0.73469 (r=0.621,p=0.900),  time:30.376, tt:1670.661\n",
      "Ep:55, loss:0.00001, loss_test:0.01745, lr:4.81e-02, fs:0.73469 (r=0.621,p=0.900),  time:30.379, tt:1701.247\n",
      "Ep:56, loss:0.00001, loss_test:0.01750, lr:4.76e-02, fs:0.73469 (r=0.621,p=0.900),  time:30.357, tt:1730.347\n",
      "Ep:57, loss:0.00001, loss_test:0.01768, lr:4.71e-02, fs:0.73469 (r=0.621,p=0.900),  time:30.378, tt:1761.929\n",
      "Ep:58, loss:0.00001, loss_test:0.01782, lr:4.67e-02, fs:0.73973 (r=0.621,p=0.915),  time:30.358, tt:1791.128\n",
      "Ep:59, loss:0.00001, loss_test:0.01791, lr:4.62e-02, fs:0.73103 (r=0.609,p=0.914),  time:30.334, tt:1820.047\n",
      "Ep:60, loss:0.00001, loss_test:0.01803, lr:4.57e-02, fs:0.73103 (r=0.609,p=0.914),  time:30.321, tt:1849.579\n",
      "Ep:61, loss:0.00001, loss_test:0.01813, lr:4.53e-02, fs:0.73103 (r=0.609,p=0.914),  time:30.327, tt:1880.280\n",
      "Ep:62, loss:0.00001, loss_test:0.01821, lr:4.48e-02, fs:0.72727 (r=0.598,p=0.929),  time:30.311, tt:1909.610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01827, lr:4.44e-02, fs:0.71831 (r=0.586,p=0.927),  time:30.312, tt:1939.961\n",
      "Ep:64, loss:0.00001, loss_test:0.01834, lr:4.39e-02, fs:0.71831 (r=0.586,p=0.927),  time:30.259, tt:1966.828\n",
      "Ep:65, loss:0.00000, loss_test:0.01850, lr:4.35e-02, fs:0.70922 (r=0.575,p=0.926),  time:30.252, tt:1996.605\n",
      "Ep:66, loss:0.00000, loss_test:0.01859, lr:4.31e-02, fs:0.71429 (r=0.575,p=0.943),  time:30.246, tt:2026.509\n",
      "Ep:67, loss:0.00000, loss_test:0.01868, lr:4.26e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.227, tt:2055.403\n",
      "Ep:68, loss:0.00000, loss_test:0.01885, lr:4.22e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.189, tt:2083.025\n",
      "Ep:69, loss:0.00000, loss_test:0.01889, lr:4.18e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.195, tt:2113.640\n",
      "Ep:70, loss:0.00000, loss_test:0.01901, lr:4.14e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.196, tt:2143.941\n",
      "Ep:71, loss:0.00000, loss_test:0.01920, lr:4.10e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.218, tt:2175.732\n",
      "Ep:72, loss:0.00000, loss_test:0.01922, lr:4.05e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.232, tt:2206.953\n",
      "Ep:73, loss:0.00000, loss_test:0.01931, lr:4.01e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.218, tt:2236.160\n",
      "Ep:74, loss:0.00000, loss_test:0.01943, lr:3.97e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.210, tt:2265.731\n",
      "Ep:75, loss:0.00000, loss_test:0.01941, lr:3.93e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.213, tt:2296.193\n",
      "Ep:76, loss:0.00000, loss_test:0.01965, lr:3.89e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.190, tt:2324.654\n",
      "Ep:77, loss:0.00000, loss_test:0.01975, lr:3.86e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.194, tt:2355.099\n",
      "Ep:78, loss:0.00000, loss_test:0.01979, lr:3.82e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.180, tt:2384.249\n",
      "Ep:79, loss:0.00000, loss_test:0.01994, lr:3.78e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.145, tt:2411.609\n",
      "Ep:80, loss:0.00000, loss_test:0.01992, lr:3.74e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.120, tt:2439.708\n",
      "Ep:81, loss:0.00000, loss_test:0.01998, lr:3.70e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.065, tt:2465.348\n",
      "Ep:82, loss:0.00000, loss_test:0.02020, lr:3.67e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.049, tt:2494.098\n",
      "Ep:83, loss:0.00000, loss_test:0.02016, lr:3.63e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.042, tt:2523.511\n",
      "Ep:84, loss:0.00000, loss_test:0.02043, lr:3.59e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.039, tt:2553.354\n",
      "Ep:85, loss:0.00000, loss_test:0.02034, lr:3.56e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.044, tt:2583.749\n",
      "Ep:86, loss:0.00000, loss_test:0.02046, lr:3.52e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.027, tt:2612.316\n",
      "Ep:87, loss:0.00000, loss_test:0.02063, lr:3.49e-02, fs:0.70073 (r=0.552,p=0.960),  time:29.993, tt:2639.387\n",
      "Ep:88, loss:0.00000, loss_test:0.02065, lr:3.45e-02, fs:0.70073 (r=0.552,p=0.960),  time:29.992, tt:2669.298\n",
      "Ep:89, loss:0.00000, loss_test:0.02073, lr:3.42e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.002, tt:2700.201\n",
      "Ep:90, loss:0.00000, loss_test:0.02086, lr:3.38e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.023, tt:2732.085\n",
      "Ep:91, loss:0.00000, loss_test:0.02090, lr:3.35e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.022, tt:2761.980\n",
      "Ep:92, loss:0.00000, loss_test:0.02106, lr:3.32e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.031, tt:2792.886\n",
      "Ep:93, loss:0.00000, loss_test:0.02109, lr:3.28e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.029, tt:2822.713\n",
      "Ep:94, loss:0.00000, loss_test:0.02111, lr:3.25e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.071, tt:2856.752\n",
      "Ep:95, loss:0.00000, loss_test:0.02133, lr:3.22e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.065, tt:2886.263\n",
      "Ep:96, loss:0.00000, loss_test:0.02134, lr:3.19e-02, fs:0.70588 (r=0.552,p=0.980),  time:30.065, tt:2916.292\n",
      "Ep:97, loss:0.00000, loss_test:0.02142, lr:3.15e-02, fs:0.70588 (r=0.552,p=0.980),  time:30.053, tt:2945.183\n",
      "Ep:98, loss:0.00000, loss_test:0.02148, lr:3.12e-02, fs:0.70073 (r=0.552,p=0.960),  time:30.039, tt:2973.908\n",
      "Ep:99, loss:0.00000, loss_test:0.02147, lr:3.09e-02, fs:0.70588 (r=0.552,p=0.980),  time:30.036, tt:3003.642\n",
      "Ep:100, loss:0.00000, loss_test:0.02161, lr:3.06e-02, fs:0.70588 (r=0.552,p=0.980),  time:30.056, tt:3035.617\n",
      "Ep:101, loss:0.00000, loss_test:0.02166, lr:3.03e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.065, tt:3066.606\n",
      "Ep:102, loss:0.00000, loss_test:0.02172, lr:3.00e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.058, tt:3095.936\n",
      "Ep:103, loss:0.00000, loss_test:0.02184, lr:2.97e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.063, tt:3126.559\n",
      "Ep:104, loss:0.00000, loss_test:0.02181, lr:2.94e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.080, tt:3158.397\n",
      "Ep:105, loss:0.00000, loss_test:0.02193, lr:2.91e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.082, tt:3188.717\n",
      "Ep:106, loss:0.00000, loss_test:0.02199, lr:2.88e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.101, tt:3220.835\n",
      "Ep:107, loss:0.00000, loss_test:0.02195, lr:2.85e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.100, tt:3250.830\n",
      "Ep:108, loss:0.00000, loss_test:0.02217, lr:2.82e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.107, tt:3281.673\n",
      "Ep:109, loss:0.00000, loss_test:0.02217, lr:2.80e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.091, tt:3309.966\n",
      "Ep:110, loss:0.00000, loss_test:0.02216, lr:2.77e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.092, tt:3340.201\n",
      "Ep:111, loss:0.00000, loss_test:0.02228, lr:2.74e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.078, tt:3368.689\n",
      "Ep:112, loss:0.00000, loss_test:0.02231, lr:2.71e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.096, tt:3400.899\n",
      "Ep:113, loss:0.00000, loss_test:0.02238, lr:2.69e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.112, tt:3432.790\n",
      "Ep:114, loss:0.00000, loss_test:0.02244, lr:2.66e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.127, tt:3464.585\n",
      "Ep:115, loss:0.00000, loss_test:0.02245, lr:2.63e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.127, tt:3494.686\n",
      "Ep:116, loss:0.00000, loss_test:0.02249, lr:2.61e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.148, tt:3527.326\n",
      "Ep:117, loss:0.00000, loss_test:0.02256, lr:2.58e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.158, tt:3558.617\n",
      "Ep:118, loss:0.00000, loss_test:0.02259, lr:2.55e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.170, tt:3590.227\n",
      "Ep:119, loss:0.00000, loss_test:0.02266, lr:2.53e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.171, tt:3620.575\n",
      "Ep:120, loss:0.00000, loss_test:0.02270, lr:2.50e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.189, tt:3652.818\n",
      "Ep:121, loss:0.00000, loss_test:0.02277, lr:2.48e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.240, tt:3689.285\n",
      "Ep:122, loss:0.00000, loss_test:0.02285, lr:2.45e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.254, tt:3721.207\n",
      "Ep:123, loss:0.00000, loss_test:0.02281, lr:2.43e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.257, tt:3751.869\n",
      "Ep:124, loss:0.00000, loss_test:0.02286, lr:2.40e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.267, tt:3783.420\n",
      "Ep:125, loss:0.00000, loss_test:0.02298, lr:2.38e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.273, tt:3814.359\n",
      "Ep:126, loss:0.00000, loss_test:0.02290, lr:2.36e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.289, tt:3846.750\n",
      "Ep:127, loss:0.00000, loss_test:0.02300, lr:2.33e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.306, tt:3879.225\n",
      "Ep:128, loss:0.00000, loss_test:0.02302, lr:2.31e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.322, tt:3911.582\n",
      "Ep:129, loss:0.00000, loss_test:0.02303, lr:2.29e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.322, tt:3941.829\n",
      "Ep:130, loss:0.00000, loss_test:0.02311, lr:2.26e-02, fs:0.69630 (r=0.540,p=0.979),  time:30.345, tt:3975.213\n",
      "Ep:131, loss:0.00000, loss_test:0.02321, lr:2.24e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.349, tt:4006.120\n",
      "Ep:132, loss:0.00000, loss_test:0.02316, lr:2.22e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.357, tt:4037.447\n",
      "Ep:133, loss:0.00000, loss_test:0.02323, lr:2.20e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.373, tt:4070.039\n",
      "Ep:134, loss:0.00000, loss_test:0.02327, lr:2.17e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.385, tt:4101.932\n",
      "Ep:135, loss:0.00000, loss_test:0.02328, lr:2.15e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.381, tt:4131.843\n",
      "Ep:136, loss:0.00000, loss_test:0.02336, lr:2.13e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.391, tt:4163.511\n",
      "Ep:137, loss:0.00000, loss_test:0.02342, lr:2.11e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.393, tt:4194.192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.02340, lr:2.09e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.401, tt:4225.727\n",
      "Ep:139, loss:0.00000, loss_test:0.02346, lr:2.07e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.409, tt:4257.306\n",
      "Ep:140, loss:0.00000, loss_test:0.02348, lr:2.05e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.411, tt:4287.969\n",
      "Ep:141, loss:0.00000, loss_test:0.02353, lr:2.03e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.418, tt:4319.412\n",
      "Ep:142, loss:0.00000, loss_test:0.02357, lr:2.01e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.434, tt:4352.117\n",
      "Ep:143, loss:0.00000, loss_test:0.02360, lr:1.99e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.440, tt:4383.292\n",
      "Ep:144, loss:0.00000, loss_test:0.02366, lr:1.97e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.443, tt:4414.271\n",
      "Ep:145, loss:0.00000, loss_test:0.02365, lr:1.95e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.449, tt:4445.623\n",
      "Ep:146, loss:0.00000, loss_test:0.02367, lr:1.93e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.462, tt:4477.974\n",
      "Ep:147, loss:0.00000, loss_test:0.02372, lr:1.91e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.472, tt:4509.898\n",
      "Ep:148, loss:0.00000, loss_test:0.02373, lr:1.89e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.471, tt:4540.141\n",
      "Ep:149, loss:0.00000, loss_test:0.02376, lr:1.87e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.489, tt:4573.414\n",
      "Ep:150, loss:0.00000, loss_test:0.02381, lr:1.85e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.498, tt:4605.267\n",
      "Ep:151, loss:0.00000, loss_test:0.02382, lr:1.83e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.513, tt:4637.915\n",
      "Ep:152, loss:0.00000, loss_test:0.02384, lr:1.81e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.513, tt:4668.549\n",
      "Ep:153, loss:0.00000, loss_test:0.02387, lr:1.80e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.519, tt:4699.892\n",
      "Ep:154, loss:0.00000, loss_test:0.02391, lr:1.78e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.526, tt:4731.603\n",
      "Ep:155, loss:0.00000, loss_test:0.02392, lr:1.76e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.548, tt:4765.562\n",
      "Ep:156, loss:0.00000, loss_test:0.02394, lr:1.74e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.546, tt:4795.715\n",
      "Ep:157, loss:0.00000, loss_test:0.02396, lr:1.73e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.554, tt:4827.589\n",
      "Ep:158, loss:0.00000, loss_test:0.02400, lr:1.71e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.566, tt:4860.005\n",
      "Ep:159, loss:0.00000, loss_test:0.02403, lr:1.69e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.573, tt:4891.732\n",
      "Ep:160, loss:0.00000, loss_test:0.02407, lr:1.67e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.575, tt:4922.579\n",
      "Ep:161, loss:0.00000, loss_test:0.02408, lr:1.66e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.576, tt:4953.260\n",
      "Ep:162, loss:0.00000, loss_test:0.02409, lr:1.64e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.570, tt:4982.987\n",
      "Ep:163, loss:0.00000, loss_test:0.02410, lr:1.62e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.569, tt:5013.278\n",
      "Ep:164, loss:0.00000, loss_test:0.02413, lr:1.61e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.569, tt:5043.870\n",
      "Ep:165, loss:0.00000, loss_test:0.02418, lr:1.59e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.568, tt:5074.329\n",
      "Ep:166, loss:0.00000, loss_test:0.02419, lr:1.58e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.570, tt:5105.115\n",
      "Ep:167, loss:0.00000, loss_test:0.02422, lr:1.56e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.571, tt:5136.006\n",
      "Ep:168, loss:0.00000, loss_test:0.02419, lr:1.54e-02, fs:0.68657 (r=0.529,p=0.979),  time:30.576, tt:5167.353\n",
      "Ep:169, loss:0.00000, loss_test:0.02428, lr:1.53e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.582, tt:5198.868\n",
      "Ep:170, loss:0.00000, loss_test:0.02425, lr:1.51e-02, fs:0.67669 (r=0.517,p=0.978),  time:30.583, tt:5229.667\n",
      "Ep:171, loss:0.00000, loss_test:0.02427, lr:1.50e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.580, tt:5259.779\n",
      "Ep:172, loss:0.00000, loss_test:0.02434, lr:1.48e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.587, tt:5291.479\n",
      "Ep:173, loss:0.00000, loss_test:0.02434, lr:1.47e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.585, tt:5321.818\n",
      "Ep:174, loss:0.00000, loss_test:0.02435, lr:1.45e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.588, tt:5352.945\n",
      "Ep:175, loss:0.00000, loss_test:0.02438, lr:1.44e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.598, tt:5385.236\n",
      "Ep:176, loss:0.00000, loss_test:0.02439, lr:1.43e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.630, tt:5421.546\n",
      "Ep:177, loss:0.00000, loss_test:0.02440, lr:1.41e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.631, tt:5452.248\n",
      "Ep:178, loss:0.00000, loss_test:0.02442, lr:1.40e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.635, tt:5483.688\n",
      "Ep:179, loss:0.00000, loss_test:0.02443, lr:1.38e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.629, tt:5513.167\n",
      "Ep:180, loss:0.00000, loss_test:0.02446, lr:1.37e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.632, tt:5544.305\n",
      "Ep:181, loss:0.00000, loss_test:0.02449, lr:1.36e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.640, tt:5576.407\n",
      "Ep:182, loss:0.00000, loss_test:0.02451, lr:1.34e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.652, tt:5609.309\n",
      "Ep:183, loss:0.00000, loss_test:0.02451, lr:1.33e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.661, tt:5641.601\n",
      "Ep:184, loss:0.00000, loss_test:0.02453, lr:1.32e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.670, tt:5673.999\n",
      "Ep:185, loss:0.00000, loss_test:0.02452, lr:1.30e-02, fs:0.66667 (r=0.506,p=0.978),  time:30.673, tt:5705.211\n",
      "Ep:186, loss:0.00000, loss_test:0.02458, lr:1.29e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.687, tt:5738.443\n",
      "Ep:187, loss:0.00000, loss_test:0.02457, lr:1.28e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.688, tt:5769.398\n",
      "Ep:188, loss:0.00000, loss_test:0.02458, lr:1.26e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.688, tt:5799.972\n",
      "Ep:189, loss:0.00000, loss_test:0.02466, lr:1.25e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.695, tt:5832.016\n",
      "Ep:190, loss:0.00000, loss_test:0.02465, lr:1.24e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.685, tt:5860.859\n",
      "Ep:191, loss:0.00000, loss_test:0.02468, lr:1.23e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.686, tt:5891.717\n",
      "Ep:192, loss:0.00000, loss_test:0.02467, lr:1.21e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.678, tt:5920.836\n",
      "Ep:193, loss:0.00000, loss_test:0.02469, lr:1.20e-02, fs:0.65649 (r=0.494,p=0.977),  time:30.674, tt:5950.693\n",
      "Ep:194, loss:0.00000, loss_test:0.02470, lr:1.19e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.672, tt:5980.947\n",
      "Ep:195, loss:0.00000, loss_test:0.02471, lr:1.18e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.660, tt:6009.269\n",
      "Ep:196, loss:0.00000, loss_test:0.02472, lr:1.17e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.655, tt:6039.015\n",
      "Ep:197, loss:0.00000, loss_test:0.02475, lr:1.15e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.657, tt:6070.111\n",
      "Ep:198, loss:0.00000, loss_test:0.02474, lr:1.14e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.669, tt:6103.089\n",
      "Ep:199, loss:0.00000, loss_test:0.02474, lr:1.13e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.668, tt:6133.516\n",
      "Ep:200, loss:0.00000, loss_test:0.02480, lr:1.12e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.664, tt:6163.423\n",
      "Ep:201, loss:0.00000, loss_test:0.02481, lr:1.11e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.660, tt:6193.251\n",
      "Ep:202, loss:0.00000, loss_test:0.02483, lr:1.10e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.648, tt:6221.446\n",
      "Ep:203, loss:0.00000, loss_test:0.02485, lr:1.09e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.632, tt:6248.892\n",
      "Ep:204, loss:0.00000, loss_test:0.02486, lr:1.08e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.614, tt:6275.934\n",
      "Ep:205, loss:0.00000, loss_test:0.02486, lr:1.07e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.619, tt:6307.425\n",
      "Ep:206, loss:0.00000, loss_test:0.02487, lr:1.05e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.611, tt:6336.580\n",
      "Ep:207, loss:0.00000, loss_test:0.02490, lr:1.04e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.589, tt:6362.412\n",
      "Ep:208, loss:0.00000, loss_test:0.02491, lr:1.03e-02, fs:0.64615 (r=0.483,p=0.977),  time:30.566, tt:6388.220\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00028, loss_test:0.13950, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.099, tt:25.099\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13683, lr:1.00e-02, fs:0.67704 (r=1.000,p=0.512),  time:24.468, tt:48.935\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13152, lr:1.00e-02, fs:0.65863 (r=0.943,p=0.506),  time:24.854, tt:74.561\n",
      "Ep:3, loss:0.00025, loss_test:0.12428, lr:1.00e-02, fs:0.68468 (r=0.874,p=0.563),  time:25.977, tt:103.909\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.12325, lr:1.00e-02, fs:0.67033 (r=0.701,p=0.642),  time:27.433, tt:137.164\n",
      "Ep:5, loss:0.00022, loss_test:0.12521, lr:1.00e-02, fs:0.68156 (r=0.701,p=0.663),  time:28.308, tt:169.851\n",
      "Ep:6, loss:0.00021, loss_test:0.12004, lr:1.00e-02, fs:0.70968 (r=0.759,p=0.667),  time:28.817, tt:201.719\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00021, loss_test:0.11841, lr:1.00e-02, fs:0.71204 (r=0.782,p=0.654),  time:29.028, tt:232.221\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00020, loss_test:0.11883, lr:1.00e-02, fs:0.70270 (r=0.747,p=0.663),  time:29.285, tt:263.563\n",
      "Ep:9, loss:0.00019, loss_test:0.11728, lr:1.00e-02, fs:0.67778 (r=0.701,p=0.656),  time:29.440, tt:294.398\n",
      "Ep:10, loss:0.00018, loss_test:0.11319, lr:1.00e-02, fs:0.71658 (r=0.770,p=0.670),  time:29.259, tt:321.845\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.11046, lr:1.00e-02, fs:0.72432 (r=0.770,p=0.684),  time:29.759, tt:357.109\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.11020, lr:1.00e-02, fs:0.69274 (r=0.713,p=0.674),  time:29.893, tt:388.609\n",
      "Ep:13, loss:0.00016, loss_test:0.10959, lr:1.00e-02, fs:0.63905 (r=0.621,p=0.659),  time:30.031, tt:420.439\n",
      "Ep:14, loss:0.00016, loss_test:0.10653, lr:1.00e-02, fs:0.65868 (r=0.632,p=0.688),  time:30.046, tt:450.695\n",
      "Ep:15, loss:0.00015, loss_test:0.10320, lr:1.00e-02, fs:0.67456 (r=0.655,p=0.695),  time:30.104, tt:481.666\n",
      "Ep:16, loss:0.00014, loss_test:0.10213, lr:1.00e-02, fs:0.69006 (r=0.678,p=0.702),  time:30.161, tt:512.735\n",
      "Ep:17, loss:0.00014, loss_test:0.10076, lr:1.00e-02, fs:0.69767 (r=0.690,p=0.706),  time:30.092, tt:541.647\n",
      "Ep:18, loss:0.00013, loss_test:0.09921, lr:1.00e-02, fs:0.70115 (r=0.701,p=0.701),  time:30.155, tt:572.947\n",
      "Ep:19, loss:0.00013, loss_test:0.09861, lr:1.00e-02, fs:0.68235 (r=0.667,p=0.699),  time:30.257, tt:605.140\n",
      "Ep:20, loss:0.00012, loss_test:0.09573, lr:1.00e-02, fs:0.69714 (r=0.701,p=0.693),  time:30.267, tt:635.600\n",
      "Ep:21, loss:0.00012, loss_test:0.09692, lr:1.00e-02, fs:0.69136 (r=0.644,p=0.747),  time:30.320, tt:667.048\n",
      "Ep:22, loss:0.00011, loss_test:0.09488, lr:1.00e-02, fs:0.69091 (r=0.655,p=0.731),  time:30.356, tt:698.187\n",
      "Ep:23, loss:0.00011, loss_test:0.09492, lr:9.90e-03, fs:0.69512 (r=0.655,p=0.740),  time:30.414, tt:729.945\n",
      "Ep:24, loss:0.00010, loss_test:0.09480, lr:9.80e-03, fs:0.69512 (r=0.655,p=0.740),  time:30.492, tt:762.289\n",
      "Ep:25, loss:0.00010, loss_test:0.09315, lr:9.70e-03, fs:0.70370 (r=0.655,p=0.760),  time:30.491, tt:792.756\n",
      "Ep:26, loss:0.00009, loss_test:0.09381, lr:9.61e-03, fs:0.71698 (r=0.655,p=0.792),  time:30.517, tt:823.952\n",
      "Ep:27, loss:0.00009, loss_test:0.09254, lr:9.51e-03, fs:0.72611 (r=0.655,p=0.814),  time:30.518, tt:854.505\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.09067, lr:9.51e-03, fs:0.75159 (r=0.678,p=0.843),  time:30.464, tt:883.456\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.08886, lr:9.51e-03, fs:0.74510 (r=0.655,p=0.864),  time:30.462, tt:913.857\n",
      "Ep:30, loss:0.00007, loss_test:0.08885, lr:9.51e-03, fs:0.75949 (r=0.690,p=0.845),  time:30.442, tt:943.702\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.08778, lr:9.51e-03, fs:0.75000 (r=0.655,p=0.877),  time:30.391, tt:972.502\n",
      "Ep:32, loss:0.00007, loss_test:0.08719, lr:9.51e-03, fs:0.77419 (r=0.690,p=0.882),  time:30.412, tt:1003.593\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.08481, lr:9.51e-03, fs:0.75817 (r=0.667,p=0.879),  time:30.444, tt:1035.094\n",
      "Ep:34, loss:0.00006, loss_test:0.08622, lr:9.51e-03, fs:0.77419 (r=0.690,p=0.882),  time:30.517, tt:1068.084\n",
      "Ep:35, loss:0.00006, loss_test:0.08484, lr:9.51e-03, fs:0.76623 (r=0.678,p=0.881),  time:30.541, tt:1099.468\n",
      "Ep:36, loss:0.00005, loss_test:0.08346, lr:9.51e-03, fs:0.77419 (r=0.690,p=0.882),  time:30.547, tt:1130.235\n",
      "Ep:37, loss:0.00005, loss_test:0.08569, lr:9.51e-03, fs:0.78205 (r=0.701,p=0.884),  time:30.500, tt:1159.012\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.08116, lr:9.51e-03, fs:0.78481 (r=0.713,p=0.873),  time:30.609, tt:1193.749\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.08710, lr:9.51e-03, fs:0.75497 (r=0.655,p=0.891),  time:30.628, tt:1225.137\n",
      "Ep:40, loss:0.00004, loss_test:0.08347, lr:9.51e-03, fs:0.77922 (r=0.690,p=0.896),  time:30.690, tt:1258.276\n",
      "Ep:41, loss:0.00004, loss_test:0.08703, lr:9.51e-03, fs:0.75000 (r=0.655,p=0.877),  time:30.733, tt:1290.807\n",
      "Ep:42, loss:0.00004, loss_test:0.08715, lr:9.51e-03, fs:0.79221 (r=0.701,p=0.910),  time:30.729, tt:1321.347\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00004, loss_test:0.08596, lr:9.51e-03, fs:0.77124 (r=0.678,p=0.894),  time:30.740, tt:1352.558\n",
      "Ep:44, loss:0.00004, loss_test:0.08847, lr:9.51e-03, fs:0.78947 (r=0.690,p=0.923),  time:30.812, tt:1386.533\n",
      "Ep:45, loss:0.00003, loss_test:0.08418, lr:9.51e-03, fs:0.77922 (r=0.690,p=0.896),  time:30.790, tt:1416.345\n",
      "Ep:46, loss:0.00003, loss_test:0.09151, lr:9.51e-03, fs:0.74483 (r=0.621,p=0.931),  time:30.816, tt:1448.343\n",
      "Ep:47, loss:0.00003, loss_test:0.08944, lr:9.51e-03, fs:0.78146 (r=0.678,p=0.922),  time:30.799, tt:1478.334\n",
      "Ep:48, loss:0.00003, loss_test:0.09018, lr:9.51e-03, fs:0.77632 (r=0.678,p=0.908),  time:30.770, tt:1507.731\n",
      "Ep:49, loss:0.00003, loss_test:0.08942, lr:9.51e-03, fs:0.74830 (r=0.632,p=0.917),  time:30.814, tt:1540.702\n",
      "Ep:50, loss:0.00003, loss_test:0.08885, lr:9.51e-03, fs:0.78146 (r=0.678,p=0.922),  time:30.802, tt:1570.914\n",
      "Ep:51, loss:0.00003, loss_test:0.09478, lr:9.51e-03, fs:0.77852 (r=0.667,p=0.935),  time:30.763, tt:1599.658\n",
      "Ep:52, loss:0.00002, loss_test:0.08292, lr:9.51e-03, fs:0.78947 (r=0.690,p=0.923),  time:30.742, tt:1629.338\n",
      "Ep:53, loss:0.00002, loss_test:0.10020, lr:9.51e-03, fs:0.66667 (r=0.517,p=0.938),  time:30.726, tt:1659.212\n",
      "Ep:54, loss:0.00002, loss_test:0.08499, lr:9.41e-03, fs:0.78146 (r=0.678,p=0.922),  time:30.723, tt:1689.779\n",
      "Ep:55, loss:0.00002, loss_test:0.09058, lr:9.32e-03, fs:0.78912 (r=0.667,p=0.967),  time:30.764, tt:1722.778\n",
      "Ep:56, loss:0.00002, loss_test:0.08792, lr:9.23e-03, fs:0.77852 (r=0.667,p=0.935),  time:30.744, tt:1752.395\n",
      "Ep:57, loss:0.00002, loss_test:0.09693, lr:9.14e-03, fs:0.69118 (r=0.540,p=0.959),  time:30.701, tt:1780.678\n",
      "Ep:58, loss:0.00002, loss_test:0.08902, lr:9.04e-03, fs:0.72340 (r=0.586,p=0.944),  time:30.667, tt:1809.341\n",
      "Ep:59, loss:0.00002, loss_test:0.08851, lr:8.95e-03, fs:0.79730 (r=0.678,p=0.967),  time:30.685, tt:1841.109\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.09120, lr:8.95e-03, fs:0.66667 (r=0.517,p=0.938),  time:30.724, tt:1874.140\n",
      "Ep:61, loss:0.00001, loss_test:0.08596, lr:8.95e-03, fs:0.79730 (r=0.678,p=0.967),  time:30.736, tt:1905.606\n",
      "Ep:62, loss:0.00001, loss_test:0.08835, lr:8.95e-03, fs:0.73239 (r=0.598,p=0.945),  time:30.820, tt:1941.666\n",
      "Ep:63, loss:0.00001, loss_test:0.08961, lr:8.95e-03, fs:0.78082 (r=0.655,p=0.966),  time:30.898, tt:1977.488\n",
      "Ep:64, loss:0.00001, loss_test:0.08359, lr:8.95e-03, fs:0.79730 (r=0.678,p=0.967),  time:31.014, tt:2015.900\n",
      "Ep:65, loss:0.00001, loss_test:0.09558, lr:8.95e-03, fs:0.69118 (r=0.540,p=0.959),  time:31.050, tt:2049.276\n",
      "Ep:66, loss:0.00001, loss_test:0.08338, lr:8.95e-03, fs:0.78912 (r=0.667,p=0.967),  time:31.110, tt:2084.363\n",
      "Ep:67, loss:0.00001, loss_test:0.09280, lr:8.95e-03, fs:0.72857 (r=0.586,p=0.962),  time:31.173, tt:2119.785\n",
      "Ep:68, loss:0.00001, loss_test:0.08286, lr:8.95e-03, fs:0.78912 (r=0.667,p=0.967),  time:31.215, tt:2153.868\n",
      "Ep:69, loss:0.00001, loss_test:0.09311, lr:8.95e-03, fs:0.69118 (r=0.540,p=0.959),  time:31.283, tt:2189.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00001, loss_test:0.08314, lr:8.95e-03, fs:0.75524 (r=0.621,p=0.964),  time:31.326, tt:2224.137\n",
      "Ep:71, loss:0.00001, loss_test:0.09197, lr:8.86e-03, fs:0.70073 (r=0.552,p=0.960),  time:31.398, tt:2260.628\n",
      "Ep:72, loss:0.00001, loss_test:0.08473, lr:8.78e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.430, tt:2294.367\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.08875, lr:8.78e-03, fs:0.76389 (r=0.632,p=0.965),  time:31.512, tt:2331.853\n",
      "Ep:74, loss:0.00001, loss_test:0.08382, lr:8.78e-03, fs:0.72857 (r=0.586,p=0.962),  time:31.567, tt:2367.520\n",
      "Ep:75, loss:0.00001, loss_test:0.08941, lr:8.78e-03, fs:0.69118 (r=0.540,p=0.959),  time:31.626, tt:2403.605\n",
      "Ep:76, loss:0.00001, loss_test:0.08566, lr:8.78e-03, fs:0.71942 (r=0.575,p=0.962),  time:31.655, tt:2437.468\n",
      "Ep:77, loss:0.00001, loss_test:0.08625, lr:8.78e-03, fs:0.73759 (r=0.598,p=0.963),  time:31.669, tt:2470.217\n",
      "Ep:78, loss:0.00001, loss_test:0.08905, lr:8.78e-03, fs:0.72857 (r=0.586,p=0.962),  time:31.731, tt:2506.755\n",
      "Ep:79, loss:0.00001, loss_test:0.08633, lr:8.78e-03, fs:0.72857 (r=0.586,p=0.962),  time:31.789, tt:2543.131\n",
      "Ep:80, loss:0.00001, loss_test:0.08694, lr:8.78e-03, fs:0.75524 (r=0.621,p=0.964),  time:31.820, tt:2577.423\n",
      "Ep:81, loss:0.00001, loss_test:0.08638, lr:8.78e-03, fs:0.72857 (r=0.586,p=0.962),  time:31.829, tt:2609.939\n",
      "Ep:82, loss:0.00001, loss_test:0.08787, lr:8.78e-03, fs:0.69118 (r=0.540,p=0.959),  time:31.883, tt:2646.316\n",
      "Ep:83, loss:0.00001, loss_test:0.08716, lr:8.78e-03, fs:0.70073 (r=0.552,p=0.960),  time:31.908, tt:2680.240\n",
      "Ep:84, loss:0.00000, loss_test:0.08684, lr:8.69e-03, fs:0.70073 (r=0.552,p=0.960),  time:31.944, tt:2715.275\n",
      "Ep:85, loss:0.00000, loss_test:0.08965, lr:8.60e-03, fs:0.69118 (r=0.540,p=0.959),  time:31.976, tt:2749.976\n",
      "Ep:86, loss:0.00000, loss_test:0.08778, lr:8.51e-03, fs:0.70073 (r=0.552,p=0.960),  time:31.989, tt:2783.084\n",
      "Ep:87, loss:0.00000, loss_test:0.09058, lr:8.43e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.024, tt:2818.076\n",
      "Ep:88, loss:0.00000, loss_test:0.08928, lr:8.35e-03, fs:0.69118 (r=0.540,p=0.959),  time:32.071, tt:2854.330\n",
      "Ep:89, loss:0.00000, loss_test:0.09041, lr:8.26e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.098, tt:2888.810\n",
      "Ep:90, loss:0.00000, loss_test:0.08883, lr:8.18e-03, fs:0.69118 (r=0.540,p=0.959),  time:32.132, tt:2923.973\n",
      "Ep:91, loss:0.00000, loss_test:0.08921, lr:8.10e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.168, tt:2959.464\n",
      "Ep:92, loss:0.00000, loss_test:0.09042, lr:8.02e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.190, tt:2993.686\n",
      "Ep:93, loss:0.00000, loss_test:0.09129, lr:7.94e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.215, tt:3028.166\n",
      "Ep:94, loss:0.00000, loss_test:0.09011, lr:7.86e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.271, tt:3065.721\n",
      "Ep:95, loss:0.00000, loss_test:0.09049, lr:7.78e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.291, tt:3099.980\n",
      "Ep:96, loss:0.00000, loss_test:0.09067, lr:7.70e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.289, tt:3131.987\n",
      "Ep:97, loss:0.00000, loss_test:0.09181, lr:7.62e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.358, tt:3171.062\n",
      "Ep:98, loss:0.00000, loss_test:0.09104, lr:7.55e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.379, tt:3205.534\n",
      "Ep:99, loss:0.00000, loss_test:0.09148, lr:7.47e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.394, tt:3239.369\n",
      "Ep:100, loss:0.00000, loss_test:0.09119, lr:7.40e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.409, tt:3273.333\n",
      "Ep:101, loss:0.00000, loss_test:0.09234, lr:7.32e-03, fs:0.68657 (r=0.529,p=0.979),  time:32.434, tt:3308.245\n",
      "Ep:102, loss:0.00000, loss_test:0.08976, lr:7.25e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.482, tt:3345.635\n",
      "Ep:103, loss:0.00000, loss_test:0.09182, lr:7.18e-03, fs:0.68657 (r=0.529,p=0.979),  time:32.496, tt:3379.573\n",
      "Ep:104, loss:0.00000, loss_test:0.09172, lr:7.11e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.522, tt:3414.781\n",
      "Ep:105, loss:0.00000, loss_test:0.09077, lr:7.03e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.546, tt:3449.849\n",
      "Ep:106, loss:0.00000, loss_test:0.09104, lr:6.96e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.589, tt:3487.023\n",
      "Ep:107, loss:0.00000, loss_test:0.09139, lr:6.89e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.593, tt:3519.994\n",
      "Ep:108, loss:0.00000, loss_test:0.09089, lr:6.83e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.601, tt:3553.502\n",
      "Ep:109, loss:0.00000, loss_test:0.09087, lr:6.76e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.634, tt:3589.722\n",
      "Ep:110, loss:0.00000, loss_test:0.09081, lr:6.69e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.652, tt:3624.329\n",
      "Ep:111, loss:0.00000, loss_test:0.09079, lr:6.62e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.661, tt:3658.082\n",
      "Ep:112, loss:0.00000, loss_test:0.08997, lr:6.56e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.713, tt:3696.527\n",
      "Ep:113, loss:0.00000, loss_test:0.09079, lr:6.49e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.744, tt:3732.846\n",
      "Ep:114, loss:0.00000, loss_test:0.09102, lr:6.43e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.766, tt:3768.145\n",
      "Ep:115, loss:0.00000, loss_test:0.08962, lr:6.36e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.799, tt:3804.628\n",
      "Ep:116, loss:0.00000, loss_test:0.09096, lr:6.30e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.824, tt:3840.431\n",
      "Ep:117, loss:0.00000, loss_test:0.09021, lr:6.24e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.829, tt:3873.863\n",
      "Ep:118, loss:0.00000, loss_test:0.09076, lr:6.17e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.834, tt:3907.301\n",
      "Ep:119, loss:0.00000, loss_test:0.09007, lr:6.11e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.857, tt:3942.884\n",
      "Ep:120, loss:0.00000, loss_test:0.09087, lr:6.05e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.876, tt:3978.048\n",
      "Ep:121, loss:0.00000, loss_test:0.09017, lr:5.99e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.928, tt:4017.178\n",
      "Ep:122, loss:0.00000, loss_test:0.09078, lr:5.93e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.926, tt:4049.927\n",
      "Ep:123, loss:0.00000, loss_test:0.09037, lr:5.87e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.941, tt:4084.745\n",
      "Ep:124, loss:0.00000, loss_test:0.09088, lr:5.81e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.969, tt:4121.129\n",
      "Ep:125, loss:0.00000, loss_test:0.09076, lr:5.75e-03, fs:0.69630 (r=0.540,p=0.979),  time:32.990, tt:4156.797\n",
      "Ep:126, loss:0.00000, loss_test:0.09081, lr:5.70e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.008, tt:4192.038\n",
      "Ep:127, loss:0.00000, loss_test:0.09064, lr:5.64e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.035, tt:4228.525\n",
      "Ep:128, loss:0.00000, loss_test:0.08924, lr:5.58e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.051, tt:4263.555\n",
      "Ep:129, loss:0.00000, loss_test:0.09080, lr:5.53e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.064, tt:4298.350\n",
      "Ep:130, loss:0.00000, loss_test:0.09057, lr:5.47e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.075, tt:4332.876\n",
      "Ep:131, loss:0.00000, loss_test:0.09125, lr:5.42e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.102, tt:4369.486\n",
      "Ep:132, loss:0.00000, loss_test:0.09089, lr:5.36e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.120, tt:4404.934\n",
      "Ep:133, loss:0.00000, loss_test:0.08892, lr:5.31e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.141, tt:4440.949\n",
      "Ep:134, loss:0.00000, loss_test:0.09181, lr:5.26e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.146, tt:4474.645\n",
      "Ep:135, loss:0.00000, loss_test:0.09164, lr:5.20e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.181, tt:4512.583\n",
      "Ep:136, loss:0.00000, loss_test:0.08831, lr:5.15e-03, fs:0.71533 (r=0.563,p=0.980),  time:33.187, tt:4546.643\n",
      "Ep:137, loss:0.00000, loss_test:0.09097, lr:5.10e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.208, tt:4582.732\n",
      "Ep:138, loss:0.00000, loss_test:0.09180, lr:5.05e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.220, tt:4617.603\n",
      "Ep:139, loss:0.00000, loss_test:0.08899, lr:5.00e-03, fs:0.70588 (r=0.552,p=0.980),  time:33.238, tt:4653.285\n",
      "Ep:140, loss:0.00000, loss_test:0.09074, lr:4.95e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.259, tt:4689.552\n",
      "Ep:141, loss:0.00000, loss_test:0.09149, lr:4.90e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.279, tt:4725.636\n",
      "Ep:142, loss:0.00000, loss_test:0.08938, lr:4.85e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.297, tt:4761.422\n",
      "Ep:143, loss:0.00000, loss_test:0.08974, lr:4.80e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.333, tt:4799.964\n",
      "Ep:144, loss:0.00000, loss_test:0.08989, lr:4.75e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.349, tt:4835.539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.08926, lr:4.71e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.362, tt:4870.881\n",
      "Ep:146, loss:0.00000, loss_test:0.08993, lr:4.66e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.378, tt:4906.554\n",
      "Ep:147, loss:0.00000, loss_test:0.08997, lr:4.61e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.392, tt:4942.076\n",
      "Ep:148, loss:0.00000, loss_test:0.08892, lr:4.57e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.418, tt:4979.340\n",
      "Ep:149, loss:0.00000, loss_test:0.08944, lr:4.52e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.434, tt:5015.076\n",
      "Ep:150, loss:0.00000, loss_test:0.08973, lr:4.48e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.448, tt:5050.644\n",
      "Ep:151, loss:0.00000, loss_test:0.08903, lr:4.43e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.469, tt:5087.268\n",
      "Ep:152, loss:0.00000, loss_test:0.09027, lr:4.39e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.488, tt:5123.643\n",
      "Ep:153, loss:0.00000, loss_test:0.08989, lr:4.34e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.499, tt:5158.778\n",
      "Ep:154, loss:0.00000, loss_test:0.08892, lr:4.30e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.516, tt:5194.952\n",
      "Ep:155, loss:0.00000, loss_test:0.08970, lr:4.26e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.527, tt:5230.235\n",
      "Ep:156, loss:0.00000, loss_test:0.08962, lr:4.21e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.526, tt:5263.638\n",
      "Ep:157, loss:0.00000, loss_test:0.08898, lr:4.17e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.545, tt:5300.185\n",
      "Ep:158, loss:0.00000, loss_test:0.09014, lr:4.13e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.568, tt:5337.332\n",
      "Ep:159, loss:0.00000, loss_test:0.09018, lr:4.09e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.584, tt:5373.488\n",
      "Ep:160, loss:0.00000, loss_test:0.08917, lr:4.05e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.603, tt:5410.106\n",
      "Ep:161, loss:0.00000, loss_test:0.08964, lr:4.01e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.620, tt:5446.489\n",
      "Ep:162, loss:0.00000, loss_test:0.09004, lr:3.97e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.652, tt:5485.279\n",
      "Ep:163, loss:0.00000, loss_test:0.08933, lr:3.93e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.659, tt:5520.017\n",
      "Ep:164, loss:0.00000, loss_test:0.08979, lr:3.89e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.666, tt:5554.952\n",
      "Ep:165, loss:0.00000, loss_test:0.09051, lr:3.85e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.669, tt:5589.083\n",
      "Ep:166, loss:0.00000, loss_test:0.08987, lr:3.81e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.677, tt:5624.129\n",
      "Ep:167, loss:0.00000, loss_test:0.08923, lr:3.77e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.701, tt:5661.691\n",
      "Ep:168, loss:0.00000, loss_test:0.08969, lr:3.73e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.718, tt:5698.275\n",
      "Ep:169, loss:0.00000, loss_test:0.08958, lr:3.70e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.722, tt:5732.774\n",
      "Ep:170, loss:0.00000, loss_test:0.08927, lr:3.66e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.735, tt:5768.708\n",
      "Ep:171, loss:0.00000, loss_test:0.08961, lr:3.62e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.749, tt:5804.867\n",
      "Ep:172, loss:0.00000, loss_test:0.08970, lr:3.59e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.774, tt:5842.963\n",
      "Ep:173, loss:0.00000, loss_test:0.08905, lr:3.55e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.778, tt:5877.397\n",
      "Ep:174, loss:0.00000, loss_test:0.08848, lr:3.52e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.795, tt:5914.157\n",
      "Ep:175, loss:0.00000, loss_test:0.09015, lr:3.48e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.816, tt:5951.547\n",
      "Ep:176, loss:0.00000, loss_test:0.09028, lr:3.45e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.833, tt:5988.382\n",
      "Ep:177, loss:0.00000, loss_test:0.08950, lr:3.41e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.842, tt:6023.880\n",
      "Ep:178, loss:0.00000, loss_test:0.08960, lr:3.38e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.863, tt:6061.398\n",
      "Ep:179, loss:0.00000, loss_test:0.08978, lr:3.34e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.873, tt:6097.088\n",
      "Ep:180, loss:0.00000, loss_test:0.08950, lr:3.31e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.881, tt:6132.394\n",
      "Ep:181, loss:0.00000, loss_test:0.08940, lr:3.28e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.884, tt:6166.921\n",
      "Ep:182, loss:0.00000, loss_test:0.08983, lr:3.24e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.891, tt:6202.111\n",
      "Ep:183, loss:0.00000, loss_test:0.08946, lr:3.21e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.901, tt:6237.730\n",
      "Ep:184, loss:0.00000, loss_test:0.08889, lr:3.18e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.917, tt:6274.614\n",
      "Ep:185, loss:0.00000, loss_test:0.08927, lr:3.15e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.929, tt:6310.734\n",
      "Ep:186, loss:0.00000, loss_test:0.08939, lr:3.12e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.938, tt:6346.322\n",
      "Ep:187, loss:0.00000, loss_test:0.08885, lr:3.09e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.955, tt:6383.621\n",
      "Ep:188, loss:0.00000, loss_test:0.08924, lr:3.05e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.961, tt:6418.653\n",
      "Ep:189, loss:0.00000, loss_test:0.08984, lr:3.02e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.964, tt:6453.239\n",
      "Ep:190, loss:0.00000, loss_test:0.08943, lr:2.99e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.977, tt:6489.683\n",
      "Ep:191, loss:0.00000, loss_test:0.08875, lr:2.96e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.001, tt:6528.105\n",
      "Ep:192, loss:0.00000, loss_test:0.08969, lr:2.93e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.023, tt:6566.412\n",
      "Ep:193, loss:0.00000, loss_test:0.08975, lr:2.90e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.027, tt:6601.316\n",
      "Ep:194, loss:0.00000, loss_test:0.08911, lr:2.88e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.041, tt:6638.039\n",
      "Ep:195, loss:0.00000, loss_test:0.08934, lr:2.85e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.048, tt:6673.412\n",
      "Ep:196, loss:0.00000, loss_test:0.08987, lr:2.82e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.065, tt:6710.875\n",
      "Ep:197, loss:0.00000, loss_test:0.08961, lr:2.79e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.069, tt:6745.698\n",
      "Ep:198, loss:0.00000, loss_test:0.08914, lr:2.76e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.085, tt:6782.978\n",
      "Ep:199, loss:0.00000, loss_test:0.08945, lr:2.73e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.072, tt:6814.311\n",
      "Ep:200, loss:0.00000, loss_test:0.08989, lr:2.71e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.077, tt:6849.395\n",
      "Ep:201, loss:0.00000, loss_test:0.08954, lr:2.68e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.094, tt:6886.902\n",
      "Ep:202, loss:0.00000, loss_test:0.08916, lr:2.65e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.092, tt:6920.578\n",
      "Ep:203, loss:0.00000, loss_test:0.08936, lr:2.63e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.093, tt:6954.899\n",
      "Ep:204, loss:0.00000, loss_test:0.08922, lr:2.60e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.079, tt:6986.222\n",
      "Ep:205, loss:0.00000, loss_test:0.08885, lr:2.57e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.043, tt:7012.856\n",
      "Ep:206, loss:0.00000, loss_test:0.08938, lr:2.55e-03, fs:0.69630 (r=0.540,p=0.979),  time:34.007, tt:7039.348\n",
      "Ep:207, loss:0.00000, loss_test:0.08952, lr:2.52e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.961, tt:7063.972\n",
      "Ep:208, loss:0.00000, loss_test:0.08906, lr:2.50e-03, fs:0.69630 (r=0.540,p=0.979),  time:33.889, tt:7082.719\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02154, lr:6.00e-02, fs:0.66977 (r=0.828,p=0.562),  time:31.171, tt:31.171\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02103, lr:6.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:32.838, tt:65.676\n",
      "Ep:2, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:33.269, tt:99.806\n",
      "Ep:3, loss:0.00004, loss_test:0.02120, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:33.630, tt:134.520\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02006, lr:6.00e-02, fs:0.64800 (r=0.931,p=0.497),  time:33.922, tt:169.608\n",
      "Ep:5, loss:0.00004, loss_test:0.01942, lr:6.00e-02, fs:0.66953 (r=0.897,p=0.534),  time:34.099, tt:204.596\n",
      "Ep:6, loss:0.00003, loss_test:0.02021, lr:6.00e-02, fs:0.72549 (r=0.851,p=0.632),  time:34.152, tt:239.067\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00003, loss_test:0.02129, lr:6.00e-02, fs:0.73684 (r=0.805,p=0.680),  time:34.283, tt:274.266\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.02038, lr:6.00e-02, fs:0.73196 (r=0.816,p=0.664),  time:34.278, tt:308.499\n",
      "Ep:9, loss:0.00003, loss_test:0.01875, lr:6.00e-02, fs:0.71569 (r=0.839,p=0.624),  time:34.285, tt:342.851\n",
      "Ep:10, loss:0.00003, loss_test:0.01772, lr:6.00e-02, fs:0.71362 (r=0.874,p=0.603),  time:34.127, tt:375.396\n",
      "Ep:11, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.72222 (r=0.897,p=0.605),  time:34.128, tt:409.532\n",
      "Ep:12, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.73333 (r=0.885,p=0.626),  time:34.216, tt:444.808\n",
      "Ep:13, loss:0.00003, loss_test:0.01755, lr:6.00e-02, fs:0.73892 (r=0.862,p=0.647),  time:34.313, tt:480.384\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01772, lr:6.00e-02, fs:0.73469 (r=0.828,p=0.661),  time:34.161, tt:512.416\n",
      "Ep:15, loss:0.00003, loss_test:0.01735, lr:6.00e-02, fs:0.74747 (r=0.851,p=0.667),  time:34.044, tt:544.705\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.76617 (r=0.885,p=0.675),  time:34.085, tt:579.439\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01626, lr:6.00e-02, fs:0.79808 (r=0.954,p=0.686),  time:34.144, tt:614.587\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.79426 (r=0.954,p=0.680),  time:34.140, tt:648.656\n",
      "Ep:19, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.81773 (r=0.954,p=0.716),  time:34.297, tt:685.947\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01643, lr:6.00e-02, fs:0.85567 (r=0.954,p=0.776),  time:34.391, tt:722.212\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01649, lr:6.00e-02, fs:0.85417 (r=0.943,p=0.781),  time:34.498, tt:758.962\n",
      "Ep:22, loss:0.00002, loss_test:0.01634, lr:6.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:34.502, tt:793.545\n",
      "Ep:23, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.84817 (r=0.931,p=0.779),  time:34.552, tt:829.257\n",
      "Ep:24, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.84656 (r=0.920,p=0.784),  time:34.632, tt:865.807\n",
      "Ep:25, loss:0.00002, loss_test:0.01604, lr:6.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:34.688, tt:901.878\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01618, lr:6.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:34.630, tt:934.998\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.84916 (r=0.874,p=0.826),  time:34.670, tt:970.774\n",
      "Ep:28, loss:0.00002, loss_test:0.01611, lr:6.00e-02, fs:0.84270 (r=0.862,p=0.824),  time:34.691, tt:1006.033\n",
      "Ep:29, loss:0.00002, loss_test:0.01617, lr:6.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:34.729, tt:1041.858\n",
      "Ep:30, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.82081 (r=0.816,p=0.826),  time:34.789, tt:1078.465\n",
      "Ep:31, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:34.815, tt:1114.077\n",
      "Ep:32, loss:0.00001, loss_test:0.01625, lr:6.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:34.863, tt:1150.474\n",
      "Ep:33, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:34.888, tt:1186.194\n",
      "Ep:34, loss:0.00001, loss_test:0.01632, lr:6.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:34.967, tt:1223.837\n",
      "Ep:35, loss:0.00001, loss_test:0.01630, lr:6.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:34.926, tt:1257.322\n",
      "Ep:36, loss:0.00001, loss_test:0.01636, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:34.910, tt:1291.673\n",
      "Ep:37, loss:0.00001, loss_test:0.01653, lr:6.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:34.902, tt:1326.289\n",
      "Ep:38, loss:0.00001, loss_test:0.01679, lr:5.94e-02, fs:0.80519 (r=0.713,p=0.925),  time:34.871, tt:1359.971\n",
      "Ep:39, loss:0.00001, loss_test:0.01681, lr:5.88e-02, fs:0.79739 (r=0.701,p=0.924),  time:34.898, tt:1395.902\n",
      "Ep:40, loss:0.00001, loss_test:0.01685, lr:5.82e-02, fs:0.80263 (r=0.701,p=0.938),  time:34.916, tt:1431.569\n",
      "Ep:41, loss:0.00001, loss_test:0.01693, lr:5.76e-02, fs:0.80263 (r=0.701,p=0.938),  time:34.927, tt:1466.932\n",
      "Ep:42, loss:0.00001, loss_test:0.01697, lr:5.71e-02, fs:0.80000 (r=0.690,p=0.952),  time:35.038, tt:1506.629\n",
      "Ep:43, loss:0.00001, loss_test:0.01712, lr:5.65e-02, fs:0.77551 (r=0.655,p=0.950),  time:35.106, tt:1544.675\n",
      "Ep:44, loss:0.00001, loss_test:0.01726, lr:5.59e-02, fs:0.76712 (r=0.644,p=0.949),  time:35.136, tt:1581.111\n",
      "Ep:45, loss:0.00001, loss_test:0.01729, lr:5.54e-02, fs:0.75862 (r=0.632,p=0.948),  time:35.216, tt:1619.935\n",
      "Ep:46, loss:0.00001, loss_test:0.01737, lr:5.48e-02, fs:0.75862 (r=0.632,p=0.948),  time:35.231, tt:1655.874\n",
      "Ep:47, loss:0.00001, loss_test:0.01754, lr:5.43e-02, fs:0.75862 (r=0.632,p=0.948),  time:35.273, tt:1693.082\n",
      "Ep:48, loss:0.00001, loss_test:0.01769, lr:5.37e-02, fs:0.75862 (r=0.632,p=0.948),  time:35.338, tt:1731.578\n",
      "Ep:49, loss:0.00001, loss_test:0.01769, lr:5.32e-02, fs:0.75862 (r=0.632,p=0.948),  time:35.370, tt:1768.500\n",
      "Ep:50, loss:0.00001, loss_test:0.01780, lr:5.27e-02, fs:0.75862 (r=0.632,p=0.948),  time:35.417, tt:1806.257\n",
      "Ep:51, loss:0.00001, loss_test:0.01797, lr:5.21e-02, fs:0.75524 (r=0.621,p=0.964),  time:35.441, tt:1842.948\n",
      "Ep:52, loss:0.00001, loss_test:0.01816, lr:5.16e-02, fs:0.75524 (r=0.621,p=0.964),  time:35.476, tt:1880.223\n",
      "Ep:53, loss:0.00001, loss_test:0.01820, lr:5.11e-02, fs:0.75524 (r=0.621,p=0.964),  time:35.488, tt:1916.333\n",
      "Ep:54, loss:0.00001, loss_test:0.01830, lr:5.06e-02, fs:0.75524 (r=0.621,p=0.964),  time:35.502, tt:1952.618\n",
      "Ep:55, loss:0.00001, loss_test:0.01839, lr:5.01e-02, fs:0.74648 (r=0.609,p=0.964),  time:35.523, tt:1989.285\n",
      "Ep:56, loss:0.00001, loss_test:0.01847, lr:4.96e-02, fs:0.74648 (r=0.609,p=0.964),  time:35.566, tt:2027.279\n",
      "Ep:57, loss:0.00001, loss_test:0.01863, lr:4.91e-02, fs:0.74648 (r=0.609,p=0.964),  time:35.616, tt:2065.712\n",
      "Ep:58, loss:0.00001, loss_test:0.01869, lr:4.86e-02, fs:0.74648 (r=0.609,p=0.964),  time:35.640, tt:2102.755\n",
      "Ep:59, loss:0.00001, loss_test:0.01877, lr:4.81e-02, fs:0.72857 (r=0.586,p=0.962),  time:35.659, tt:2139.566\n",
      "Ep:60, loss:0.00001, loss_test:0.01887, lr:4.76e-02, fs:0.73381 (r=0.586,p=0.981),  time:35.675, tt:2176.182\n",
      "Ep:61, loss:0.00001, loss_test:0.01904, lr:4.71e-02, fs:0.73381 (r=0.586,p=0.981),  time:35.814, tt:2220.449\n",
      "Ep:62, loss:0.00001, loss_test:0.01924, lr:4.67e-02, fs:0.73381 (r=0.586,p=0.981),  time:35.815, tt:2256.324\n",
      "Ep:63, loss:0.00001, loss_test:0.01931, lr:4.62e-02, fs:0.73381 (r=0.586,p=0.981),  time:35.843, tt:2293.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01942, lr:4.57e-02, fs:0.72464 (r=0.575,p=0.980),  time:35.832, tt:2329.071\n",
      "Ep:65, loss:0.00001, loss_test:0.01957, lr:4.53e-02, fs:0.72464 (r=0.575,p=0.980),  time:35.851, tt:2366.178\n",
      "Ep:66, loss:0.00001, loss_test:0.01977, lr:4.48e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.884, tt:2404.236\n",
      "Ep:67, loss:0.00001, loss_test:0.01989, lr:4.44e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.916, tt:2442.273\n",
      "Ep:68, loss:0.00001, loss_test:0.01992, lr:4.39e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.915, tt:2478.111\n",
      "Ep:69, loss:0.00000, loss_test:0.02008, lr:4.35e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.934, tt:2515.404\n",
      "Ep:70, loss:0.00000, loss_test:0.02015, lr:4.31e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.966, tt:2553.572\n",
      "Ep:71, loss:0.00000, loss_test:0.02028, lr:4.26e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.982, tt:2590.704\n",
      "Ep:72, loss:0.00000, loss_test:0.02046, lr:4.22e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.972, tt:2625.959\n",
      "Ep:73, loss:0.00000, loss_test:0.02067, lr:4.18e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.991, tt:2663.310\n",
      "Ep:74, loss:0.00000, loss_test:0.02079, lr:4.14e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.982, tt:2698.645\n",
      "Ep:75, loss:0.00000, loss_test:0.02085, lr:4.10e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.975, tt:2734.118\n",
      "Ep:76, loss:0.00000, loss_test:0.02097, lr:4.05e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.969, tt:2769.587\n",
      "Ep:77, loss:0.00000, loss_test:0.02115, lr:4.01e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.982, tt:2806.615\n",
      "Ep:78, loss:0.00000, loss_test:0.02122, lr:3.97e-02, fs:0.71533 (r=0.563,p=0.980),  time:35.997, tt:2843.739\n",
      "Ep:79, loss:0.00000, loss_test:0.02134, lr:3.93e-02, fs:0.71533 (r=0.563,p=0.980),  time:36.023, tt:2881.859\n",
      "Ep:80, loss:0.00000, loss_test:0.02151, lr:3.89e-02, fs:0.71533 (r=0.563,p=0.980),  time:36.012, tt:2916.979\n",
      "Ep:81, loss:0.00000, loss_test:0.02165, lr:3.86e-02, fs:0.71533 (r=0.563,p=0.980),  time:36.025, tt:2954.028\n",
      "Ep:82, loss:0.00000, loss_test:0.02172, lr:3.82e-02, fs:0.71533 (r=0.563,p=0.980),  time:36.036, tt:2990.992\n",
      "Ep:83, loss:0.00000, loss_test:0.02183, lr:3.78e-02, fs:0.71533 (r=0.563,p=0.980),  time:36.034, tt:3026.848\n",
      "Ep:84, loss:0.00000, loss_test:0.02198, lr:3.74e-02, fs:0.70588 (r=0.552,p=0.980),  time:36.046, tt:3063.908\n",
      "Ep:85, loss:0.00000, loss_test:0.02207, lr:3.70e-02, fs:0.70588 (r=0.552,p=0.980),  time:36.074, tt:3102.399\n",
      "Ep:86, loss:0.00000, loss_test:0.02218, lr:3.67e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.085, tt:3139.385\n",
      "Ep:87, loss:0.00000, loss_test:0.02231, lr:3.63e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.087, tt:3175.648\n",
      "Ep:88, loss:0.00000, loss_test:0.02237, lr:3.59e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.090, tt:3211.972\n",
      "Ep:89, loss:0.00000, loss_test:0.02249, lr:3.56e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.075, tt:3246.743\n",
      "Ep:90, loss:0.00000, loss_test:0.02263, lr:3.52e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.069, tt:3282.262\n",
      "Ep:91, loss:0.00000, loss_test:0.02272, lr:3.49e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.074, tt:3318.820\n",
      "Ep:92, loss:0.00000, loss_test:0.02285, lr:3.45e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.080, tt:3355.407\n",
      "Ep:93, loss:0.00000, loss_test:0.02294, lr:3.42e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.078, tt:3391.302\n",
      "Ep:94, loss:0.00000, loss_test:0.02303, lr:3.38e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.068, tt:3426.458\n",
      "Ep:95, loss:0.00000, loss_test:0.02318, lr:3.35e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.069, tt:3462.604\n",
      "Ep:96, loss:0.00000, loss_test:0.02326, lr:3.32e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.067, tt:3498.495\n",
      "Ep:97, loss:0.00000, loss_test:0.02335, lr:3.28e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.070, tt:3534.865\n",
      "Ep:98, loss:0.00000, loss_test:0.02338, lr:3.25e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.056, tt:3569.526\n",
      "Ep:99, loss:0.00000, loss_test:0.02345, lr:3.22e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.053, tt:3605.282\n",
      "Ep:100, loss:0.00000, loss_test:0.02349, lr:3.19e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.063, tt:3642.413\n",
      "Ep:101, loss:0.00000, loss_test:0.02361, lr:3.15e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.073, tt:3679.448\n",
      "Ep:102, loss:0.00000, loss_test:0.02365, lr:3.12e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.067, tt:3714.950\n",
      "Ep:103, loss:0.00000, loss_test:0.02375, lr:3.09e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.090, tt:3753.394\n",
      "Ep:104, loss:0.00000, loss_test:0.02392, lr:3.06e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.104, tt:3790.893\n",
      "Ep:105, loss:0.00000, loss_test:0.02395, lr:3.03e-02, fs:0.71111 (r=0.552,p=1.000),  time:36.073, tt:3823.768\n",
      "Ep:106, loss:0.00000, loss_test:0.02409, lr:3.00e-02, fs:0.69173 (r=0.529,p=1.000),  time:36.015, tt:3853.603\n",
      "Ep:107, loss:0.00000, loss_test:0.02425, lr:2.97e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.987, tt:3886.642\n",
      "Ep:108, loss:0.00000, loss_test:0.02429, lr:2.94e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.941, tt:3917.584\n",
      "Ep:109, loss:0.00000, loss_test:0.02437, lr:2.91e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.898, tt:3948.755\n",
      "Ep:110, loss:0.00000, loss_test:0.02448, lr:2.88e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.860, tt:3980.455\n",
      "Ep:111, loss:0.00000, loss_test:0.02458, lr:2.85e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.838, tt:4013.893\n",
      "Ep:112, loss:0.00000, loss_test:0.02467, lr:2.82e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.821, tt:4047.764\n",
      "Ep:113, loss:0.00000, loss_test:0.02471, lr:2.80e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.837, tt:4085.400\n",
      "Ep:114, loss:0.00000, loss_test:0.02479, lr:2.77e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.838, tt:4121.376\n",
      "Ep:115, loss:0.00000, loss_test:0.02487, lr:2.74e-02, fs:0.69173 (r=0.529,p=1.000),  time:35.844, tt:4157.871\n",
      "Ep:116, loss:0.00000, loss_test:0.02492, lr:2.71e-02, fs:0.68182 (r=0.517,p=1.000),  time:35.841, tt:4193.373\n",
      "Ep:117, loss:0.00000, loss_test:0.02504, lr:2.69e-02, fs:0.67176 (r=0.506,p=1.000),  time:35.841, tt:4229.197\n",
      "Ep:118, loss:0.00000, loss_test:0.02506, lr:2.66e-02, fs:0.66154 (r=0.494,p=1.000),  time:35.820, tt:4262.600\n",
      "Ep:119, loss:0.00000, loss_test:0.02514, lr:2.63e-02, fs:0.62992 (r=0.460,p=1.000),  time:35.819, tt:4298.286\n",
      "Ep:120, loss:0.00000, loss_test:0.02526, lr:2.61e-02, fs:0.62992 (r=0.460,p=1.000),  time:35.837, tt:4336.258\n",
      "Ep:121, loss:0.00000, loss_test:0.02528, lr:2.58e-02, fs:0.61905 (r=0.448,p=1.000),  time:35.835, tt:4371.930\n",
      "Ep:122, loss:0.00000, loss_test:0.02529, lr:2.55e-02, fs:0.61905 (r=0.448,p=1.000),  time:35.825, tt:4406.533\n",
      "Ep:123, loss:0.00000, loss_test:0.02539, lr:2.53e-02, fs:0.60800 (r=0.437,p=1.000),  time:35.814, tt:4440.939\n",
      "Ep:124, loss:0.00000, loss_test:0.02544, lr:2.50e-02, fs:0.60800 (r=0.437,p=1.000),  time:35.817, tt:4477.185\n",
      "Ep:125, loss:0.00000, loss_test:0.02551, lr:2.48e-02, fs:0.60800 (r=0.437,p=1.000),  time:35.818, tt:4513.093\n",
      "Ep:126, loss:0.00000, loss_test:0.02562, lr:2.45e-02, fs:0.59677 (r=0.425,p=1.000),  time:35.820, tt:4549.139\n",
      "Ep:127, loss:0.00000, loss_test:0.02570, lr:2.43e-02, fs:0.59677 (r=0.425,p=1.000),  time:35.823, tt:4585.351\n",
      "Ep:128, loss:0.00000, loss_test:0.02570, lr:2.40e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.827, tt:4621.636\n",
      "Ep:129, loss:0.00000, loss_test:0.02579, lr:2.38e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.831, tt:4658.063\n",
      "Ep:130, loss:0.00000, loss_test:0.02587, lr:2.36e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.828, tt:4693.533\n",
      "Ep:131, loss:0.00000, loss_test:0.02590, lr:2.33e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.825, tt:4728.888\n",
      "Ep:132, loss:0.00000, loss_test:0.02598, lr:2.31e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.822, tt:4764.318\n",
      "Ep:133, loss:0.00000, loss_test:0.02606, lr:2.29e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.817, tt:4799.483\n",
      "Ep:134, loss:0.00000, loss_test:0.02606, lr:2.26e-02, fs:0.58537 (r=0.414,p=1.000),  time:35.828, tt:4836.735\n",
      "Ep:135, loss:0.00000, loss_test:0.02611, lr:2.24e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.827, tt:4872.442\n",
      "Ep:136, loss:0.00000, loss_test:0.02622, lr:2.22e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.827, tt:4908.232\n",
      "Ep:137, loss:0.00000, loss_test:0.02625, lr:2.20e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.837, tt:4945.546\n",
      "Ep:138, loss:0.00000, loss_test:0.02629, lr:2.17e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.838, tt:4981.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.02632, lr:2.15e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.844, tt:5018.207\n",
      "Ep:140, loss:0.00000, loss_test:0.02639, lr:2.13e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.857, tt:5055.826\n",
      "Ep:141, loss:0.00000, loss_test:0.02644, lr:2.11e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.871, tt:5093.720\n",
      "Ep:142, loss:0.00000, loss_test:0.02650, lr:2.09e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.868, tt:5129.155\n",
      "Ep:143, loss:0.00000, loss_test:0.02657, lr:2.07e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.862, tt:5164.062\n",
      "Ep:144, loss:0.00000, loss_test:0.02661, lr:2.05e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.857, tt:5199.302\n",
      "Ep:145, loss:0.00000, loss_test:0.02664, lr:2.03e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.857, tt:5235.094\n",
      "Ep:146, loss:0.00000, loss_test:0.02670, lr:2.01e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.856, tt:5270.857\n",
      "Ep:147, loss:0.00000, loss_test:0.02673, lr:1.99e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.872, tt:5309.085\n",
      "Ep:148, loss:0.00000, loss_test:0.02676, lr:1.97e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.882, tt:5346.410\n",
      "Ep:149, loss:0.00000, loss_test:0.02680, lr:1.95e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.876, tt:5381.377\n",
      "Ep:150, loss:0.00000, loss_test:0.02688, lr:1.93e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.876, tt:5417.273\n",
      "Ep:151, loss:0.00000, loss_test:0.02691, lr:1.91e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.881, tt:5453.912\n",
      "Ep:152, loss:0.00000, loss_test:0.02691, lr:1.89e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.886, tt:5490.612\n",
      "Ep:153, loss:0.00000, loss_test:0.02693, lr:1.87e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.886, tt:5526.498\n",
      "Ep:154, loss:0.00000, loss_test:0.02700, lr:1.85e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.889, tt:5562.766\n",
      "Ep:155, loss:0.00000, loss_test:0.02704, lr:1.83e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.894, tt:5599.528\n",
      "Ep:156, loss:0.00000, loss_test:0.02706, lr:1.81e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.889, tt:5634.519\n",
      "Ep:157, loss:0.00000, loss_test:0.02713, lr:1.80e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.895, tt:5671.482\n",
      "Ep:158, loss:0.00000, loss_test:0.02716, lr:1.78e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.892, tt:5706.758\n",
      "Ep:159, loss:0.00000, loss_test:0.02718, lr:1.76e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.886, tt:5741.767\n",
      "Ep:160, loss:0.00000, loss_test:0.02723, lr:1.74e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.887, tt:5777.834\n",
      "Ep:161, loss:0.00000, loss_test:0.02726, lr:1.73e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.873, tt:5811.482\n",
      "Ep:162, loss:0.00000, loss_test:0.02730, lr:1.71e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.870, tt:5846.863\n",
      "Ep:163, loss:0.00000, loss_test:0.02735, lr:1.69e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.870, tt:5882.599\n",
      "Ep:164, loss:0.00000, loss_test:0.02739, lr:1.67e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.868, tt:5918.148\n",
      "Ep:165, loss:0.00000, loss_test:0.02737, lr:1.66e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.866, tt:5953.807\n",
      "Ep:166, loss:0.00000, loss_test:0.02742, lr:1.64e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.871, tt:5990.402\n",
      "Ep:167, loss:0.00000, loss_test:0.02748, lr:1.62e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.863, tt:6024.905\n",
      "Ep:168, loss:0.00000, loss_test:0.02751, lr:1.61e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.868, tt:6061.737\n",
      "Ep:169, loss:0.00000, loss_test:0.02753, lr:1.59e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.867, tt:6097.407\n",
      "Ep:170, loss:0.00000, loss_test:0.02758, lr:1.58e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.867, tt:6133.302\n",
      "Ep:171, loss:0.00000, loss_test:0.02760, lr:1.56e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.873, tt:6170.072\n",
      "Ep:172, loss:0.00000, loss_test:0.02762, lr:1.54e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.878, tt:6206.895\n",
      "Ep:173, loss:0.00000, loss_test:0.02767, lr:1.53e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.891, tt:6244.967\n",
      "Ep:174, loss:0.00000, loss_test:0.02767, lr:1.51e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.890, tt:6280.698\n",
      "Ep:175, loss:0.00000, loss_test:0.02772, lr:1.50e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.893, tt:6317.156\n",
      "Ep:176, loss:0.00000, loss_test:0.02775, lr:1.48e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.903, tt:6354.870\n",
      "Ep:177, loss:0.00000, loss_test:0.02777, lr:1.47e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.910, tt:6391.957\n",
      "Ep:178, loss:0.00000, loss_test:0.02778, lr:1.45e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.912, tt:6428.316\n",
      "Ep:179, loss:0.00000, loss_test:0.02782, lr:1.44e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.917, tt:6464.991\n",
      "Ep:180, loss:0.00000, loss_test:0.02787, lr:1.43e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.921, tt:6501.708\n",
      "Ep:181, loss:0.00000, loss_test:0.02788, lr:1.41e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.919, tt:6537.267\n",
      "Ep:182, loss:0.00000, loss_test:0.02791, lr:1.40e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.926, tt:6574.542\n",
      "Ep:183, loss:0.00000, loss_test:0.02793, lr:1.38e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.921, tt:6609.494\n",
      "Ep:184, loss:0.00000, loss_test:0.02794, lr:1.37e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.916, tt:6644.445\n",
      "Ep:185, loss:0.00000, loss_test:0.02796, lr:1.36e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.925, tt:6682.065\n",
      "Ep:186, loss:0.00000, loss_test:0.02799, lr:1.34e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.927, tt:6718.396\n",
      "Ep:187, loss:0.00000, loss_test:0.02803, lr:1.33e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.931, tt:6755.059\n",
      "Ep:188, loss:0.00000, loss_test:0.02807, lr:1.32e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.968, tt:6797.945\n",
      "Ep:189, loss:0.00000, loss_test:0.02808, lr:1.30e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.970, tt:6834.304\n",
      "Ep:190, loss:0.00000, loss_test:0.02808, lr:1.29e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.973, tt:6870.937\n",
      "Ep:191, loss:0.00000, loss_test:0.02810, lr:1.28e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.974, tt:6907.040\n",
      "Ep:192, loss:0.00000, loss_test:0.02814, lr:1.26e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.983, tt:6944.783\n",
      "Ep:193, loss:0.00000, loss_test:0.02816, lr:1.25e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.983, tt:6980.618\n",
      "Ep:194, loss:0.00000, loss_test:0.02818, lr:1.24e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.977, tt:7015.566\n",
      "Ep:195, loss:0.00000, loss_test:0.02821, lr:1.23e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.986, tt:7053.275\n",
      "Ep:196, loss:0.00000, loss_test:0.02824, lr:1.21e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.980, tt:7088.121\n",
      "Ep:197, loss:0.00000, loss_test:0.02826, lr:1.20e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.979, tt:7123.932\n",
      "Ep:198, loss:0.00000, loss_test:0.02828, lr:1.19e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.987, tt:7161.445\n",
      "Ep:199, loss:0.00000, loss_test:0.02829, lr:1.18e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.989, tt:7197.812\n",
      "Ep:200, loss:0.00000, loss_test:0.02831, lr:1.17e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.990, tt:7234.005\n",
      "Ep:201, loss:0.00000, loss_test:0.02834, lr:1.15e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.992, tt:7270.456\n",
      "Ep:202, loss:0.00000, loss_test:0.02836, lr:1.14e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.992, tt:7306.351\n",
      "Ep:203, loss:0.00000, loss_test:0.02836, lr:1.13e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.995, tt:7342.984\n",
      "Ep:204, loss:0.00000, loss_test:0.02839, lr:1.12e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.973, tt:7374.506\n",
      "Ep:205, loss:0.00000, loss_test:0.02843, lr:1.11e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.954, tt:7406.606\n",
      "Ep:206, loss:0.00000, loss_test:0.02842, lr:1.10e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.946, tt:7440.849\n",
      "Ep:207, loss:0.00000, loss_test:0.02845, lr:1.09e-02, fs:0.57377 (r=0.402,p=1.000),  time:35.928, tt:7473.091\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14302, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.210, tt:37.210\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00028, loss_test:0.14193, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.331, tt:68.663\n",
      "Ep:2, loss:0.00027, loss_test:0.13998, lr:1.00e-02, fs:0.64822 (r=0.943,p=0.494),  time:34.715, tt:104.146\n",
      "Ep:3, loss:0.00027, loss_test:0.13660, lr:1.00e-02, fs:0.65060 (r=0.931,p=0.500),  time:35.188, tt:140.753\n",
      "Ep:4, loss:0.00026, loss_test:0.13275, lr:1.00e-02, fs:0.65560 (r=0.908,p=0.513),  time:35.532, tt:177.660\n",
      "Ep:5, loss:0.00024, loss_test:0.12909, lr:1.00e-02, fs:0.64286 (r=0.724,p=0.578),  time:35.324, tt:211.943\n",
      "Ep:6, loss:0.00022, loss_test:0.13278, lr:1.00e-02, fs:0.59756 (r=0.563,p=0.636),  time:35.393, tt:247.753\n",
      "Ep:7, loss:0.00021, loss_test:0.12992, lr:1.00e-02, fs:0.59756 (r=0.563,p=0.636),  time:35.496, tt:283.971\n",
      "Ep:8, loss:0.00020, loss_test:0.12320, lr:1.00e-02, fs:0.64444 (r=0.667,p=0.624),  time:35.698, tt:321.282\n",
      "Ep:9, loss:0.00019, loss_test:0.12247, lr:1.00e-02, fs:0.62570 (r=0.644,p=0.609),  time:35.825, tt:358.254\n",
      "Ep:10, loss:0.00019, loss_test:0.12364, lr:1.00e-02, fs:0.62069 (r=0.621,p=0.621),  time:35.911, tt:395.017\n",
      "Ep:11, loss:0.00018, loss_test:0.11906, lr:1.00e-02, fs:0.62428 (r=0.621,p=0.628),  time:35.846, tt:430.151\n",
      "Ep:12, loss:0.00017, loss_test:0.11340, lr:9.90e-03, fs:0.66286 (r=0.667,p=0.659),  time:36.177, tt:470.306\n",
      "Ep:13, loss:0.00017, loss_test:0.11108, lr:9.80e-03, fs:0.66279 (r=0.655,p=0.671),  time:36.125, tt:505.750\n",
      "Ep:14, loss:0.00016, loss_test:0.10853, lr:9.70e-03, fs:0.68263 (r=0.655,p=0.713),  time:35.840, tt:537.602\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.10320, lr:9.70e-03, fs:0.73684 (r=0.724,p=0.750),  time:35.859, tt:573.744\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.10134, lr:9.70e-03, fs:0.75294 (r=0.736,p=0.771),  time:35.689, tt:606.717\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09984, lr:9.70e-03, fs:0.76923 (r=0.747,p=0.793),  time:35.669, tt:642.048\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09718, lr:9.70e-03, fs:0.80233 (r=0.793,p=0.812),  time:35.743, tt:679.108\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.09577, lr:9.70e-03, fs:0.80000 (r=0.782,p=0.819),  time:35.753, tt:715.058\n",
      "Ep:20, loss:0.00012, loss_test:0.09460, lr:9.70e-03, fs:0.80000 (r=0.759,p=0.846),  time:35.728, tt:750.281\n",
      "Ep:21, loss:0.00012, loss_test:0.09251, lr:9.70e-03, fs:0.79769 (r=0.793,p=0.802),  time:35.724, tt:785.932\n",
      "Ep:22, loss:0.00011, loss_test:0.09129, lr:9.70e-03, fs:0.80952 (r=0.782,p=0.840),  time:35.719, tt:821.535\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.09193, lr:9.70e-03, fs:0.74214 (r=0.678,p=0.819),  time:35.721, tt:857.310\n",
      "Ep:24, loss:0.00010, loss_test:0.08887, lr:9.70e-03, fs:0.78313 (r=0.747,p=0.823),  time:35.697, tt:892.434\n",
      "Ep:25, loss:0.00010, loss_test:0.08871, lr:9.70e-03, fs:0.77019 (r=0.713,p=0.838),  time:35.727, tt:928.913\n",
      "Ep:26, loss:0.00009, loss_test:0.09054, lr:9.70e-03, fs:0.78788 (r=0.747,p=0.833),  time:35.681, tt:963.387\n",
      "Ep:27, loss:0.00009, loss_test:0.08986, lr:9.70e-03, fs:0.76730 (r=0.701,p=0.847),  time:35.701, tt:999.635\n",
      "Ep:28, loss:0.00008, loss_test:0.09070, lr:9.70e-03, fs:0.77500 (r=0.713,p=0.849),  time:35.656, tt:1034.035\n",
      "Ep:29, loss:0.00008, loss_test:0.09140, lr:9.70e-03, fs:0.77500 (r=0.713,p=0.849),  time:35.611, tt:1068.335\n",
      "Ep:30, loss:0.00008, loss_test:0.09225, lr:9.70e-03, fs:0.76923 (r=0.690,p=0.870),  time:35.586, tt:1103.171\n",
      "Ep:31, loss:0.00007, loss_test:0.09351, lr:9.70e-03, fs:0.78947 (r=0.690,p=0.923),  time:35.531, tt:1136.986\n",
      "Ep:32, loss:0.00007, loss_test:0.09567, lr:9.70e-03, fs:0.79470 (r=0.690,p=0.938),  time:35.467, tt:1170.413\n",
      "Ep:33, loss:0.00006, loss_test:0.09618, lr:9.70e-03, fs:0.77852 (r=0.667,p=0.935),  time:35.522, tt:1207.739\n",
      "Ep:34, loss:0.00006, loss_test:0.09698, lr:9.61e-03, fs:0.77852 (r=0.667,p=0.935),  time:35.566, tt:1244.826\n",
      "Ep:35, loss:0.00006, loss_test:0.09825, lr:9.51e-03, fs:0.76389 (r=0.632,p=0.965),  time:35.620, tt:1282.309\n",
      "Ep:36, loss:0.00005, loss_test:0.10262, lr:9.41e-03, fs:0.75862 (r=0.632,p=0.948),  time:35.645, tt:1318.878\n",
      "Ep:37, loss:0.00005, loss_test:0.09718, lr:9.32e-03, fs:0.76389 (r=0.632,p=0.965),  time:35.629, tt:1353.900\n",
      "Ep:38, loss:0.00005, loss_test:0.10240, lr:9.23e-03, fs:0.75177 (r=0.609,p=0.981),  time:35.660, tt:1390.730\n",
      "Ep:39, loss:0.00004, loss_test:0.10147, lr:9.14e-03, fs:0.75342 (r=0.632,p=0.932),  time:35.660, tt:1426.404\n",
      "Ep:40, loss:0.00004, loss_test:0.10227, lr:9.04e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.654, tt:1461.832\n",
      "Ep:41, loss:0.00004, loss_test:0.10402, lr:8.95e-03, fs:0.74286 (r=0.598,p=0.981),  time:35.665, tt:1497.939\n",
      "Ep:42, loss:0.00004, loss_test:0.10110, lr:8.86e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.630, tt:1532.087\n",
      "Ep:43, loss:0.00003, loss_test:0.10644, lr:8.78e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.679, tt:1569.893\n",
      "Ep:44, loss:0.00003, loss_test:0.09982, lr:8.69e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.720, tt:1607.412\n",
      "Ep:45, loss:0.00003, loss_test:0.10618, lr:8.60e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.701, tt:1642.254\n",
      "Ep:46, loss:0.00003, loss_test:0.10578, lr:8.51e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.716, tt:1678.649\n",
      "Ep:47, loss:0.00003, loss_test:0.10554, lr:8.43e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.738, tt:1715.440\n",
      "Ep:48, loss:0.00003, loss_test:0.10928, lr:8.35e-03, fs:0.73381 (r=0.586,p=0.981),  time:35.771, tt:1752.771\n",
      "Ep:49, loss:0.00002, loss_test:0.10676, lr:8.26e-03, fs:0.72464 (r=0.575,p=0.980),  time:35.785, tt:1789.246\n",
      "Ep:50, loss:0.00002, loss_test:0.11172, lr:8.18e-03, fs:0.71533 (r=0.563,p=0.980),  time:35.704, tt:1820.926\n",
      "Ep:51, loss:0.00002, loss_test:0.10799, lr:8.10e-03, fs:0.64615 (r=0.483,p=0.977),  time:35.667, tt:1854.663\n",
      "Ep:52, loss:0.00002, loss_test:0.11153, lr:8.02e-03, fs:0.72464 (r=0.575,p=0.980),  time:35.669, tt:1890.451\n",
      "Ep:53, loss:0.00002, loss_test:0.11152, lr:7.94e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.677, tt:1926.532\n",
      "Ep:54, loss:0.00002, loss_test:0.11149, lr:7.86e-03, fs:0.63566 (r=0.471,p=0.976),  time:35.668, tt:1961.759\n",
      "Ep:55, loss:0.00002, loss_test:0.11061, lr:7.78e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.603, tt:1993.754\n",
      "Ep:56, loss:0.00002, loss_test:0.11660, lr:7.70e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.560, tt:2026.921\n",
      "Ep:57, loss:0.00002, loss_test:0.11380, lr:7.62e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.556, tt:2062.262\n",
      "Ep:58, loss:0.00001, loss_test:0.11717, lr:7.55e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.546, tt:2097.222\n",
      "Ep:59, loss:0.00001, loss_test:0.11685, lr:7.47e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.508, tt:2130.453\n",
      "Ep:60, loss:0.00001, loss_test:0.11729, lr:7.40e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.488, tt:2164.768\n",
      "Ep:61, loss:0.00001, loss_test:0.11836, lr:7.32e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.451, tt:2197.943\n",
      "Ep:62, loss:0.00001, loss_test:0.11780, lr:7.25e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.461, tt:2234.066\n",
      "Ep:63, loss:0.00001, loss_test:0.12004, lr:7.18e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.463, tt:2269.603\n",
      "Ep:64, loss:0.00001, loss_test:0.11844, lr:7.11e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.453, tt:2304.431\n",
      "Ep:65, loss:0.00001, loss_test:0.12112, lr:7.03e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.465, tt:2340.723\n",
      "Ep:66, loss:0.00001, loss_test:0.11994, lr:6.96e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.460, tt:2375.806\n",
      "Ep:67, loss:0.00001, loss_test:0.11973, lr:6.89e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.431, tt:2409.341\n",
      "Ep:68, loss:0.00001, loss_test:0.12241, lr:6.83e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.451, tt:2446.123\n",
      "Ep:69, loss:0.00001, loss_test:0.12002, lr:6.76e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.467, tt:2482.674\n",
      "Ep:70, loss:0.00001, loss_test:0.12089, lr:6.69e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.414, tt:2514.429\n",
      "Ep:71, loss:0.00001, loss_test:0.12096, lr:6.62e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.371, tt:2546.725\n",
      "Ep:72, loss:0.00001, loss_test:0.12083, lr:6.56e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.379, tt:2582.637\n",
      "Ep:73, loss:0.00001, loss_test:0.12281, lr:6.49e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.346, tt:2615.640\n",
      "Ep:74, loss:0.00001, loss_test:0.12117, lr:6.43e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.355, tt:2651.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00001, loss_test:0.12268, lr:6.36e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.365, tt:2687.734\n",
      "Ep:76, loss:0.00001, loss_test:0.12278, lr:6.30e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.349, tt:2721.842\n",
      "Ep:77, loss:0.00001, loss_test:0.12384, lr:6.24e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.342, tt:2756.658\n",
      "Ep:78, loss:0.00001, loss_test:0.12334, lr:6.17e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.292, tt:2788.086\n",
      "Ep:79, loss:0.00001, loss_test:0.12359, lr:6.11e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.284, tt:2822.728\n",
      "Ep:80, loss:0.00001, loss_test:0.12353, lr:6.05e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.273, tt:2857.099\n",
      "Ep:81, loss:0.00001, loss_test:0.12673, lr:5.99e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.267, tt:2891.862\n",
      "Ep:82, loss:0.00001, loss_test:0.12376, lr:5.93e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.262, tt:2926.736\n",
      "Ep:83, loss:0.00001, loss_test:0.12537, lr:5.87e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.247, tt:2960.787\n",
      "Ep:84, loss:0.00001, loss_test:0.12487, lr:5.81e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.239, tt:2995.315\n",
      "Ep:85, loss:0.00001, loss_test:0.12552, lr:5.75e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.235, tt:3030.246\n",
      "Ep:86, loss:0.00001, loss_test:0.12476, lr:5.70e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.247, tt:3066.521\n",
      "Ep:87, loss:0.00001, loss_test:0.12575, lr:5.64e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.235, tt:3100.675\n",
      "Ep:88, loss:0.00001, loss_test:0.12646, lr:5.58e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.254, tt:3137.580\n",
      "Ep:89, loss:0.00001, loss_test:0.12372, lr:5.53e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.231, tt:3170.834\n",
      "Ep:90, loss:0.00001, loss_test:0.12740, lr:5.47e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.208, tt:3203.884\n",
      "Ep:91, loss:0.00001, loss_test:0.12577, lr:5.42e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.196, tt:3238.067\n",
      "Ep:92, loss:0.00001, loss_test:0.12416, lr:5.36e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.222, tt:3275.687\n",
      "Ep:93, loss:0.00001, loss_test:0.12658, lr:5.31e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.209, tt:3309.671\n",
      "Ep:94, loss:0.00000, loss_test:0.12539, lr:5.26e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.186, tt:3342.668\n",
      "Ep:95, loss:0.00000, loss_test:0.12541, lr:5.20e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.181, tt:3377.402\n",
      "Ep:96, loss:0.00000, loss_test:0.12680, lr:5.15e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.159, tt:3410.469\n",
      "Ep:97, loss:0.00000, loss_test:0.12560, lr:5.10e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.152, tt:3444.852\n",
      "Ep:98, loss:0.00000, loss_test:0.12596, lr:5.05e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.149, tt:3479.788\n",
      "Ep:99, loss:0.00000, loss_test:0.12535, lr:5.00e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.127, tt:3512.742\n",
      "Ep:100, loss:0.00000, loss_test:0.12464, lr:4.95e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.117, tt:3546.821\n",
      "Ep:101, loss:0.00000, loss_test:0.12575, lr:4.90e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.131, tt:3583.356\n",
      "Ep:102, loss:0.00000, loss_test:0.12525, lr:4.85e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.146, tt:3619.999\n",
      "Ep:103, loss:0.00000, loss_test:0.12608, lr:4.80e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.163, tt:3657.001\n",
      "Ep:104, loss:0.00000, loss_test:0.12595, lr:4.75e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.119, tt:3687.530\n",
      "Ep:105, loss:0.00000, loss_test:0.12587, lr:4.71e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.068, tt:3717.197\n",
      "Ep:106, loss:0.00000, loss_test:0.12619, lr:4.66e-03, fs:0.62500 (r=0.460,p=0.976),  time:35.029, tt:3748.079\n",
      "Ep:107, loss:0.00000, loss_test:0.12656, lr:4.61e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.971, tt:3776.827\n",
      "Ep:108, loss:0.00000, loss_test:0.12662, lr:4.57e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.946, tt:3809.138\n",
      "Ep:109, loss:0.00000, loss_test:0.12627, lr:4.52e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.884, tt:3837.280\n",
      "Ep:110, loss:0.00000, loss_test:0.12718, lr:4.48e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.842, tt:3867.410\n",
      "Ep:111, loss:0.00000, loss_test:0.12701, lr:4.43e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.801, tt:3897.692\n",
      "Ep:112, loss:0.00000, loss_test:0.12705, lr:4.39e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.774, tt:3929.457\n",
      "Ep:113, loss:0.00000, loss_test:0.12687, lr:4.34e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.756, tt:3962.128\n",
      "Ep:114, loss:0.00000, loss_test:0.12783, lr:4.30e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.724, tt:3993.206\n",
      "Ep:115, loss:0.00000, loss_test:0.12786, lr:4.26e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.693, tt:4024.397\n",
      "Ep:116, loss:0.00000, loss_test:0.12767, lr:4.21e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.672, tt:4056.593\n",
      "Ep:117, loss:0.00000, loss_test:0.12855, lr:4.17e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.645, tt:4088.132\n",
      "Ep:118, loss:0.00000, loss_test:0.12858, lr:4.13e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.617, tt:4119.456\n",
      "Ep:119, loss:0.00000, loss_test:0.12825, lr:4.09e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.593, tt:4151.139\n",
      "Ep:120, loss:0.00000, loss_test:0.12903, lr:4.05e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.550, tt:4180.597\n",
      "Ep:121, loss:0.00000, loss_test:0.12860, lr:4.01e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.525, tt:4211.996\n",
      "Ep:122, loss:0.00000, loss_test:0.12923, lr:3.97e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.504, tt:4243.941\n",
      "Ep:123, loss:0.00000, loss_test:0.12888, lr:3.93e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.491, tt:4276.943\n",
      "Ep:124, loss:0.00000, loss_test:0.12832, lr:3.89e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.472, tt:4308.958\n",
      "Ep:125, loss:0.00000, loss_test:0.12981, lr:3.85e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.464, tt:4342.409\n",
      "Ep:126, loss:0.00000, loss_test:0.12883, lr:3.81e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.443, tt:4374.290\n",
      "Ep:127, loss:0.00000, loss_test:0.12896, lr:3.77e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.430, tt:4407.097\n",
      "Ep:128, loss:0.00000, loss_test:0.12985, lr:3.73e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.425, tt:4440.847\n",
      "Ep:129, loss:0.00000, loss_test:0.12939, lr:3.70e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.401, tt:4472.154\n",
      "Ep:130, loss:0.00000, loss_test:0.12920, lr:3.66e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.363, tt:4501.608\n",
      "Ep:131, loss:0.00000, loss_test:0.13011, lr:3.62e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.337, tt:4532.532\n",
      "Ep:132, loss:0.00000, loss_test:0.12931, lr:3.59e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.325, tt:4565.249\n",
      "Ep:133, loss:0.00000, loss_test:0.12906, lr:3.55e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.310, tt:4597.516\n",
      "Ep:134, loss:0.00000, loss_test:0.12996, lr:3.52e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.279, tt:4627.648\n",
      "Ep:135, loss:0.00000, loss_test:0.12942, lr:3.48e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.247, tt:4657.659\n",
      "Ep:136, loss:0.00000, loss_test:0.12849, lr:3.45e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.225, tt:4688.777\n",
      "Ep:137, loss:0.00000, loss_test:0.13033, lr:3.41e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.209, tt:4720.872\n",
      "Ep:138, loss:0.00000, loss_test:0.12964, lr:3.38e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.186, tt:4751.835\n",
      "Ep:139, loss:0.00000, loss_test:0.12910, lr:3.34e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.160, tt:4782.446\n",
      "Ep:140, loss:0.00000, loss_test:0.12982, lr:3.31e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.154, tt:4815.649\n",
      "Ep:141, loss:0.00000, loss_test:0.12977, lr:3.28e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.137, tt:4847.420\n",
      "Ep:142, loss:0.00000, loss_test:0.12941, lr:3.24e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.109, tt:4877.626\n",
      "Ep:143, loss:0.00000, loss_test:0.13031, lr:3.21e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.091, tt:4909.061\n",
      "Ep:144, loss:0.00000, loss_test:0.12993, lr:3.18e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.094, tt:4943.661\n",
      "Ep:145, loss:0.00000, loss_test:0.12971, lr:3.15e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.070, tt:4974.271\n",
      "Ep:146, loss:0.00000, loss_test:0.12962, lr:3.12e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.053, tt:5005.861\n",
      "Ep:147, loss:0.00000, loss_test:0.12976, lr:3.09e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.037, tt:5037.488\n",
      "Ep:148, loss:0.00000, loss_test:0.12951, lr:3.05e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.022, tt:5069.279\n",
      "Ep:149, loss:0.00000, loss_test:0.12923, lr:3.02e-03, fs:0.62500 (r=0.460,p=0.976),  time:34.000, tt:5099.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00000, loss_test:0.12942, lr:2.99e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.978, tt:5130.710\n",
      "Ep:151, loss:0.00000, loss_test:0.12955, lr:2.96e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.959, tt:5161.776\n",
      "Ep:152, loss:0.00000, loss_test:0.12920, lr:2.93e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.946, tt:5193.779\n",
      "Ep:153, loss:0.00000, loss_test:0.12920, lr:2.90e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.931, tt:5225.347\n",
      "Ep:154, loss:0.00000, loss_test:0.12949, lr:2.88e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.922, tt:5257.946\n",
      "Ep:155, loss:0.00000, loss_test:0.12875, lr:2.85e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.920, tt:5291.479\n",
      "Ep:156, loss:0.00000, loss_test:0.12867, lr:2.82e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.906, tt:5323.310\n",
      "Ep:157, loss:0.00000, loss_test:0.12939, lr:2.79e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.894, tt:5355.273\n",
      "Ep:158, loss:0.00000, loss_test:0.12932, lr:2.76e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.880, tt:5386.972\n",
      "Ep:159, loss:0.00000, loss_test:0.12894, lr:2.73e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.869, tt:5418.986\n",
      "Ep:160, loss:0.00000, loss_test:0.12912, lr:2.71e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.856, tt:5450.837\n",
      "Ep:161, loss:0.00000, loss_test:0.12935, lr:2.68e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.851, tt:5483.876\n",
      "Ep:162, loss:0.00000, loss_test:0.12943, lr:2.65e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.826, tt:5513.634\n",
      "Ep:163, loss:0.00000, loss_test:0.12895, lr:2.63e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.795, tt:5542.357\n",
      "Ep:164, loss:0.00000, loss_test:0.12858, lr:2.60e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.786, tt:5574.688\n",
      "Ep:165, loss:0.00000, loss_test:0.12898, lr:2.57e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.778, tt:5607.074\n",
      "Ep:166, loss:0.00000, loss_test:0.12899, lr:2.55e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.766, tt:5638.953\n",
      "Ep:167, loss:0.00000, loss_test:0.12841, lr:2.52e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.755, tt:5670.892\n",
      "Ep:168, loss:0.00000, loss_test:0.12858, lr:2.50e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.740, tt:5701.997\n",
      "Ep:169, loss:0.00000, loss_test:0.12882, lr:2.47e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.728, tt:5733.802\n",
      "Ep:170, loss:0.00000, loss_test:0.12852, lr:2.45e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.726, tt:5767.117\n",
      "Ep:171, loss:0.00000, loss_test:0.12861, lr:2.42e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.701, tt:5796.524\n",
      "Ep:172, loss:0.00000, loss_test:0.12892, lr:2.40e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.680, tt:5826.600\n",
      "Ep:173, loss:0.00000, loss_test:0.12841, lr:2.38e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.675, tt:5859.460\n",
      "Ep:174, loss:0.00000, loss_test:0.12825, lr:2.35e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.665, tt:5891.343\n",
      "Ep:175, loss:0.00000, loss_test:0.12874, lr:2.33e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.636, tt:5920.021\n",
      "Ep:176, loss:0.00000, loss_test:0.12838, lr:2.31e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.623, tt:5951.260\n",
      "Ep:177, loss:0.00000, loss_test:0.12792, lr:2.28e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.598, tt:5980.452\n",
      "Ep:178, loss:0.00000, loss_test:0.12768, lr:2.26e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.577, tt:6010.323\n",
      "Ep:179, loss:0.00000, loss_test:0.12798, lr:2.24e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.556, tt:6040.013\n",
      "Ep:180, loss:0.00000, loss_test:0.12803, lr:2.21e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.539, tt:6070.560\n",
      "Ep:181, loss:0.00000, loss_test:0.12745, lr:2.19e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.519, tt:6100.524\n",
      "Ep:182, loss:0.00000, loss_test:0.12757, lr:2.17e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.495, tt:6129.613\n",
      "Ep:183, loss:0.00000, loss_test:0.12838, lr:2.15e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.475, tt:6159.436\n",
      "Ep:184, loss:0.00000, loss_test:0.12815, lr:2.13e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.460, tt:6190.142\n",
      "Ep:185, loss:0.00000, loss_test:0.12763, lr:2.11e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.432, tt:6218.427\n",
      "Ep:186, loss:0.00000, loss_test:0.12798, lr:2.08e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.416, tt:6248.858\n",
      "Ep:187, loss:0.00000, loss_test:0.12778, lr:2.06e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.420, tt:6282.878\n",
      "Ep:188, loss:0.00000, loss_test:0.12712, lr:2.04e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.404, tt:6313.388\n",
      "Ep:189, loss:0.00000, loss_test:0.12727, lr:2.02e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.398, tt:6345.707\n",
      "Ep:190, loss:0.00000, loss_test:0.12775, lr:2.00e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.388, tt:6377.102\n",
      "Ep:191, loss:0.00000, loss_test:0.12807, lr:1.98e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.373, tt:6407.696\n",
      "Ep:192, loss:0.00000, loss_test:0.12761, lr:1.96e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.363, tt:6439.025\n",
      "Ep:193, loss:0.00000, loss_test:0.12722, lr:1.94e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.356, tt:6471.020\n",
      "Ep:194, loss:0.00000, loss_test:0.12759, lr:1.92e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.340, tt:6501.222\n",
      "Ep:195, loss:0.00000, loss_test:0.12735, lr:1.90e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.337, tt:6534.138\n",
      "Ep:196, loss:0.00000, loss_test:0.12705, lr:1.89e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.326, tt:6565.250\n",
      "Ep:197, loss:0.00000, loss_test:0.12727, lr:1.87e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.308, tt:6595.066\n",
      "Ep:198, loss:0.00000, loss_test:0.12762, lr:1.85e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.293, tt:6625.298\n",
      "Ep:199, loss:0.00000, loss_test:0.12723, lr:1.83e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.280, tt:6656.008\n",
      "Ep:200, loss:0.00000, loss_test:0.12684, lr:1.81e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.277, tt:6688.740\n",
      "Ep:201, loss:0.00000, loss_test:0.12722, lr:1.79e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.267, tt:6720.020\n",
      "Ep:202, loss:0.00000, loss_test:0.12706, lr:1.78e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.270, tt:6753.831\n",
      "Ep:203, loss:0.00000, loss_test:0.12720, lr:1.76e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.265, tt:6786.071\n",
      "Ep:204, loss:0.00000, loss_test:0.12704, lr:1.74e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.261, tt:6818.598\n",
      "Ep:205, loss:0.00000, loss_test:0.12704, lr:1.72e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.243, tt:6847.999\n",
      "Ep:206, loss:0.00000, loss_test:0.12682, lr:1.71e-03, fs:0.62500 (r=0.460,p=0.976),  time:33.194, tt:6871.091\n",
      "Ep:207, loss:0.00000, loss_test:0.12693, lr:1.69e-03, fs:0.62992 (r=0.460,p=1.000),  time:33.161, tt:6897.441\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.01988, lr:6.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:34.900, tt:34.900\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02183, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.760, tt:71.519\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02257, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.650, tt:109.951\n",
      "Ep:3, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.779, tt:151.116\n",
      "Ep:4, loss:0.00004, loss_test:0.02052, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:38.221, tt:191.103\n",
      "Ep:5, loss:0.00004, loss_test:0.01949, lr:6.00e-02, fs:0.63736 (r=0.879,p=0.500),  time:38.249, tt:229.496\n",
      "Ep:6, loss:0.00004, loss_test:0.01959, lr:6.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:39.097, tt:273.678\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01995, lr:6.00e-02, fs:0.65455 (r=0.727,p=0.595),  time:39.239, tt:313.915\n",
      "Ep:8, loss:0.00003, loss_test:0.01940, lr:6.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:38.754, tt:348.788\n",
      "Ep:9, loss:0.00003, loss_test:0.01876, lr:6.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:38.416, tt:384.159\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01845, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:38.311, tt:421.426\n",
      "Ep:11, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:37.863, tt:454.358\n",
      "Ep:12, loss:0.00003, loss_test:0.01811, lr:6.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:37.859, tt:492.161\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01827, lr:6.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:37.786, tt:529.009\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01821, lr:6.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:37.761, tt:566.421\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:37.549, tt:600.781\n",
      "Ep:16, loss:0.00003, loss_test:0.01749, lr:6.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:37.383, tt:635.512\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:37.177, tt:669.187\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01712, lr:6.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:37.014, tt:703.258\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01714, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:36.936, tt:738.717\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01712, lr:6.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:36.852, tt:773.888\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01697, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:36.762, tt:808.772\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:36.688, tt:843.819\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01674, lr:6.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:36.561, tt:877.469\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01668, lr:6.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:36.368, tt:909.202\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01661, lr:6.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:36.355, tt:945.221\n",
      "Ep:26, loss:0.00002, loss_test:0.01658, lr:6.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:36.325, tt:980.770\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01660, lr:6.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:36.264, tt:1015.390\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01657, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:36.198, tt:1049.750\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01649, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:36.136, tt:1084.094\n",
      "Ep:30, loss:0.00002, loss_test:0.01651, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:36.086, tt:1118.673\n",
      "Ep:31, loss:0.00002, loss_test:0.01651, lr:6.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:35.997, tt:1151.914\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01649, lr:6.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:35.977, tt:1187.254\n",
      "Ep:33, loss:0.00002, loss_test:0.01659, lr:6.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:35.959, tt:1222.592\n",
      "Ep:34, loss:0.00002, loss_test:0.01656, lr:6.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.939, tt:1257.876\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01662, lr:6.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.962, tt:1294.625\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01667, lr:6.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.985, tt:1331.454\n",
      "Ep:37, loss:0.00002, loss_test:0.01671, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.958, tt:1366.387\n",
      "Ep:38, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.979, tt:1403.178\n",
      "Ep:39, loss:0.00002, loss_test:0.01681, lr:6.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.038, tt:1441.522\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01707, lr:6.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:36.054, tt:1478.195\n",
      "Ep:41, loss:0.00001, loss_test:0.01706, lr:6.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.044, tt:1513.847\n",
      "Ep:42, loss:0.00001, loss_test:0.01705, lr:6.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:36.027, tt:1549.165\n",
      "Ep:43, loss:0.00001, loss_test:0.01721, lr:6.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:35.975, tt:1582.901\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01729, lr:6.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.959, tt:1618.148\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01731, lr:6.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:35.951, tt:1653.731\n",
      "Ep:46, loss:0.00001, loss_test:0.01743, lr:6.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.880, tt:1686.381\n",
      "Ep:47, loss:0.00001, loss_test:0.01762, lr:6.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.763, tt:1716.647\n",
      "Ep:48, loss:0.00001, loss_test:0.01757, lr:6.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.767, tt:1752.594\n",
      "Ep:49, loss:0.00001, loss_test:0.01769, lr:6.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:35.737, tt:1786.834\n",
      "Ep:50, loss:0.00001, loss_test:0.01786, lr:6.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.706, tt:1821.005\n",
      "Ep:51, loss:0.00001, loss_test:0.01789, lr:6.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.656, tt:1854.092\n",
      "Ep:52, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.627, tt:1888.206\n",
      "Ep:53, loss:0.00001, loss_test:0.01806, lr:6.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.604, tt:1922.617\n",
      "Ep:54, loss:0.00001, loss_test:0.01828, lr:6.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.607, tt:1958.359\n",
      "Ep:55, loss:0.00001, loss_test:0.01848, lr:6.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.627, tt:1995.105\n",
      "Ep:56, loss:0.00001, loss_test:0.01833, lr:5.94e-02, fs:0.79121 (r=0.727,p=0.867),  time:35.602, tt:2029.337\n",
      "Ep:57, loss:0.00001, loss_test:0.01841, lr:5.88e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.552, tt:2062.016\n",
      "Ep:58, loss:0.00001, loss_test:0.01861, lr:5.82e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.572, tt:2098.763\n",
      "Ep:59, loss:0.00001, loss_test:0.01853, lr:5.76e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.569, tt:2134.154\n",
      "Ep:60, loss:0.00001, loss_test:0.01862, lr:5.71e-02, fs:0.79558 (r=0.727,p=0.878),  time:35.533, tt:2167.517\n",
      "Ep:61, loss:0.00001, loss_test:0.01889, lr:5.65e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.515, tt:2201.909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01893, lr:5.59e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.469, tt:2234.568\n",
      "Ep:63, loss:0.00001, loss_test:0.01902, lr:5.54e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.452, tt:2268.915\n",
      "Ep:64, loss:0.00001, loss_test:0.01896, lr:5.48e-02, fs:0.78889 (r=0.717,p=0.877),  time:35.428, tt:2302.838\n",
      "Ep:65, loss:0.00001, loss_test:0.01907, lr:5.43e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.418, tt:2337.601\n",
      "Ep:66, loss:0.00001, loss_test:0.01930, lr:5.37e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.353, tt:2368.663\n",
      "Ep:67, loss:0.00001, loss_test:0.01939, lr:5.32e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.352, tt:2403.950\n",
      "Ep:68, loss:0.00001, loss_test:0.01935, lr:5.27e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.385, tt:2441.532\n",
      "Ep:69, loss:0.00001, loss_test:0.01937, lr:5.21e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.384, tt:2476.859\n",
      "Ep:70, loss:0.00001, loss_test:0.01948, lr:5.16e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.397, tt:2513.154\n",
      "Ep:71, loss:0.00001, loss_test:0.01957, lr:5.11e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.393, tt:2548.298\n",
      "Ep:72, loss:0.00001, loss_test:0.01968, lr:5.06e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.361, tt:2581.365\n",
      "Ep:73, loss:0.00001, loss_test:0.01980, lr:5.01e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.357, tt:2616.443\n",
      "Ep:74, loss:0.00001, loss_test:0.01972, lr:4.96e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.326, tt:2649.468\n",
      "Ep:75, loss:0.00001, loss_test:0.01983, lr:4.91e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.322, tt:2684.442\n",
      "Ep:76, loss:0.00001, loss_test:0.01999, lr:4.86e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.284, tt:2716.873\n",
      "Ep:77, loss:0.00001, loss_test:0.02003, lr:4.81e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.241, tt:2748.808\n",
      "Ep:78, loss:0.00001, loss_test:0.02015, lr:4.76e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.233, tt:2783.447\n",
      "Ep:79, loss:0.00001, loss_test:0.02022, lr:4.71e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.219, tt:2817.494\n",
      "Ep:80, loss:0.00001, loss_test:0.02020, lr:4.67e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.197, tt:2850.950\n",
      "Ep:81, loss:0.00001, loss_test:0.02031, lr:4.62e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.175, tt:2884.352\n",
      "Ep:82, loss:0.00001, loss_test:0.02032, lr:4.57e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.166, tt:2918.767\n",
      "Ep:83, loss:0.00001, loss_test:0.02053, lr:4.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.136, tt:2951.452\n",
      "Ep:84, loss:0.00001, loss_test:0.02057, lr:4.48e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.101, tt:2983.575\n",
      "Ep:85, loss:0.00001, loss_test:0.02055, lr:4.44e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.120, tt:3020.290\n",
      "Ep:86, loss:0.00001, loss_test:0.02065, lr:4.39e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.117, tt:3055.184\n",
      "Ep:87, loss:0.00001, loss_test:0.02073, lr:4.35e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.109, tt:3089.591\n",
      "Ep:88, loss:0.00001, loss_test:0.02085, lr:4.31e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.136, tt:3127.081\n",
      "Ep:89, loss:0.00001, loss_test:0.02092, lr:4.26e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.119, tt:3160.712\n",
      "Ep:90, loss:0.00001, loss_test:0.02097, lr:4.22e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.097, tt:3193.859\n",
      "Ep:91, loss:0.00001, loss_test:0.02100, lr:4.18e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.083, tt:3227.634\n",
      "Ep:92, loss:0.00001, loss_test:0.02111, lr:4.14e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.068, tt:3261.353\n",
      "Ep:93, loss:0.00001, loss_test:0.02112, lr:4.10e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.049, tt:3294.614\n",
      "Ep:94, loss:0.00001, loss_test:0.02122, lr:4.05e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.998, tt:3324.839\n",
      "Ep:95, loss:0.00001, loss_test:0.02122, lr:4.01e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.979, tt:3357.993\n",
      "Ep:96, loss:0.00001, loss_test:0.02144, lr:3.97e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.948, tt:3389.961\n",
      "Ep:97, loss:0.00001, loss_test:0.02144, lr:3.93e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.923, tt:3422.416\n",
      "Ep:98, loss:0.00001, loss_test:0.02136, lr:3.89e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.908, tt:3455.934\n",
      "Ep:99, loss:0.00001, loss_test:0.02148, lr:3.86e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.912, tt:3491.249\n",
      "Ep:100, loss:0.00001, loss_test:0.02156, lr:3.82e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.902, tt:3525.082\n",
      "Ep:101, loss:0.00001, loss_test:0.02165, lr:3.78e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.882, tt:3557.976\n",
      "Ep:102, loss:0.00001, loss_test:0.02170, lr:3.74e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.860, tt:3590.588\n",
      "Ep:103, loss:0.00001, loss_test:0.02174, lr:3.70e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.849, tt:3624.256\n",
      "Ep:104, loss:0.00001, loss_test:0.02175, lr:3.67e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.825, tt:3656.630\n",
      "Ep:105, loss:0.00001, loss_test:0.02188, lr:3.63e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.820, tt:3690.902\n",
      "Ep:106, loss:0.00001, loss_test:0.02197, lr:3.59e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.793, tt:3722.821\n",
      "Ep:107, loss:0.00001, loss_test:0.02197, lr:3.56e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.785, tt:3756.788\n",
      "Ep:108, loss:0.00001, loss_test:0.02198, lr:3.52e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.779, tt:3790.876\n",
      "Ep:109, loss:0.00001, loss_test:0.02210, lr:3.49e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.776, tt:3825.414\n",
      "Ep:110, loss:0.00001, loss_test:0.02220, lr:3.45e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.782, tt:3860.759\n",
      "Ep:111, loss:0.00001, loss_test:0.02218, lr:3.42e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.789, tt:3896.318\n",
      "Ep:112, loss:0.00000, loss_test:0.02225, lr:3.38e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.797, tt:3932.041\n",
      "Ep:113, loss:0.00000, loss_test:0.02234, lr:3.35e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.805, tt:3967.785\n",
      "Ep:114, loss:0.00000, loss_test:0.02236, lr:3.32e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.807, tt:4002.788\n",
      "Ep:115, loss:0.00000, loss_test:0.02237, lr:3.28e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.792, tt:4035.889\n",
      "Ep:116, loss:0.00000, loss_test:0.02247, lr:3.25e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.784, tt:4069.772\n",
      "Ep:117, loss:0.00000, loss_test:0.02253, lr:3.22e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.847, tt:4111.955\n",
      "Ep:118, loss:0.00000, loss_test:0.02255, lr:3.19e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.854, tt:4147.634\n",
      "Ep:119, loss:0.00000, loss_test:0.02266, lr:3.15e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.863, tt:4183.533\n",
      "Ep:120, loss:0.00000, loss_test:0.02270, lr:3.12e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.853, tt:4217.237\n",
      "Ep:121, loss:0.00000, loss_test:0.02270, lr:3.09e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.869, tt:4254.012\n",
      "Ep:122, loss:0.00000, loss_test:0.02274, lr:3.06e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.870, tt:4289.055\n",
      "Ep:123, loss:0.00000, loss_test:0.02279, lr:3.03e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.886, tt:4325.864\n",
      "Ep:124, loss:0.00000, loss_test:0.02286, lr:3.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.880, tt:4360.016\n",
      "Ep:125, loss:0.00000, loss_test:0.02290, lr:2.97e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.867, tt:4393.253\n",
      "Ep:126, loss:0.00000, loss_test:0.02289, lr:2.94e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.846, tt:4425.445\n",
      "Ep:127, loss:0.00000, loss_test:0.02290, lr:2.91e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.846, tt:4460.333\n",
      "Ep:128, loss:0.00000, loss_test:0.02302, lr:2.88e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.855, tt:4496.235\n",
      "Ep:129, loss:0.00000, loss_test:0.02305, lr:2.85e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.848, tt:4530.211\n",
      "Ep:130, loss:0.00000, loss_test:0.02302, lr:2.82e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.845, tt:4564.685\n",
      "Ep:131, loss:0.00000, loss_test:0.02310, lr:2.80e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.857, tt:4601.133\n",
      "Ep:132, loss:0.00000, loss_test:0.02314, lr:2.77e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.861, tt:4636.504\n",
      "Ep:133, loss:0.00000, loss_test:0.02322, lr:2.74e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.864, tt:4671.762\n",
      "Ep:134, loss:0.00000, loss_test:0.02321, lr:2.71e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.875, tt:4708.109\n",
      "Ep:135, loss:0.00000, loss_test:0.02332, lr:2.69e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.884, tt:4744.181\n",
      "Ep:136, loss:0.00000, loss_test:0.02336, lr:2.66e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.882, tt:4778.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02333, lr:2.63e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.884, tt:4813.999\n",
      "Ep:138, loss:0.00000, loss_test:0.02337, lr:2.61e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.884, tt:4848.914\n",
      "Ep:139, loss:0.00000, loss_test:0.02343, lr:2.58e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.902, tt:4886.253\n",
      "Ep:140, loss:0.00000, loss_test:0.02345, lr:2.55e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.897, tt:4920.421\n",
      "Ep:141, loss:0.00000, loss_test:0.02354, lr:2.53e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.938, tt:4961.239\n",
      "Ep:142, loss:0.00000, loss_test:0.02354, lr:2.50e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.931, tt:4995.093\n",
      "Ep:143, loss:0.00000, loss_test:0.02351, lr:2.48e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.936, tt:5030.752\n",
      "Ep:144, loss:0.00000, loss_test:0.02356, lr:2.45e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.941, tt:5066.374\n",
      "Ep:145, loss:0.00000, loss_test:0.02362, lr:2.43e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.941, tt:5101.448\n",
      "Ep:146, loss:0.00000, loss_test:0.02363, lr:2.40e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.958, tt:5138.752\n",
      "Ep:147, loss:0.00000, loss_test:0.02367, lr:2.38e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.944, tt:5171.779\n",
      "Ep:148, loss:0.00000, loss_test:0.02378, lr:2.36e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.951, tt:5207.638\n",
      "Ep:149, loss:0.00000, loss_test:0.02380, lr:2.33e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.934, tt:5240.080\n",
      "Ep:150, loss:0.00000, loss_test:0.02379, lr:2.31e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.928, tt:5274.097\n",
      "Ep:151, loss:0.00000, loss_test:0.02386, lr:2.29e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.917, tt:5307.349\n",
      "Ep:152, loss:0.00000, loss_test:0.02387, lr:2.26e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.918, tt:5342.503\n",
      "Ep:153, loss:0.00000, loss_test:0.02387, lr:2.24e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.895, tt:5373.810\n",
      "Ep:154, loss:0.00000, loss_test:0.02390, lr:2.22e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.894, tt:5408.505\n",
      "Ep:155, loss:0.00000, loss_test:0.02392, lr:2.20e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.900, tt:5444.340\n",
      "Ep:156, loss:0.00000, loss_test:0.02400, lr:2.17e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.904, tt:5479.986\n",
      "Ep:157, loss:0.00000, loss_test:0.02399, lr:2.15e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.916, tt:5516.775\n",
      "Ep:158, loss:0.00000, loss_test:0.02404, lr:2.13e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.922, tt:5552.617\n",
      "Ep:159, loss:0.00000, loss_test:0.02415, lr:2.11e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.922, tt:5587.532\n",
      "Ep:160, loss:0.00000, loss_test:0.02416, lr:2.09e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.923, tt:5622.612\n",
      "Ep:161, loss:0.00000, loss_test:0.02415, lr:2.07e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.922, tt:5657.380\n",
      "Ep:162, loss:0.00000, loss_test:0.02420, lr:2.05e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.914, tt:5690.947\n",
      "Ep:163, loss:0.00000, loss_test:0.02424, lr:2.03e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.919, tt:5726.798\n",
      "Ep:164, loss:0.00000, loss_test:0.02425, lr:2.01e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.917, tt:5761.325\n",
      "Ep:165, loss:0.00000, loss_test:0.02427, lr:1.99e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.955, tt:5802.548\n",
      "Ep:166, loss:0.00000, loss_test:0.02430, lr:1.97e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.952, tt:5836.952\n",
      "Ep:167, loss:0.00000, loss_test:0.02433, lr:1.95e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.955, tt:5872.496\n",
      "Ep:168, loss:0.00000, loss_test:0.02435, lr:1.93e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.946, tt:5905.893\n",
      "Ep:169, loss:0.00000, loss_test:0.02437, lr:1.91e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.956, tt:5942.523\n",
      "Ep:170, loss:0.00000, loss_test:0.02442, lr:1.89e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.959, tt:5978.006\n",
      "Ep:171, loss:0.00000, loss_test:0.02444, lr:1.87e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.963, tt:6013.563\n",
      "Ep:172, loss:0.00000, loss_test:0.02444, lr:1.85e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.966, tt:6049.082\n",
      "Ep:173, loss:0.00000, loss_test:0.02446, lr:1.83e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.969, tt:6084.680\n",
      "Ep:174, loss:0.00000, loss_test:0.02451, lr:1.81e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.969, tt:6119.552\n",
      "Ep:175, loss:0.00000, loss_test:0.02454, lr:1.80e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.972, tt:6155.150\n",
      "Ep:176, loss:0.00000, loss_test:0.02458, lr:1.78e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.969, tt:6189.513\n",
      "Ep:177, loss:0.00000, loss_test:0.02460, lr:1.76e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.952, tt:6221.434\n",
      "Ep:178, loss:0.00000, loss_test:0.02461, lr:1.74e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.949, tt:6255.941\n",
      "Ep:179, loss:0.00000, loss_test:0.02463, lr:1.73e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.946, tt:6290.313\n",
      "Ep:180, loss:0.00000, loss_test:0.02467, lr:1.71e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.947, tt:6325.401\n",
      "Ep:181, loss:0.00000, loss_test:0.02471, lr:1.69e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.942, tt:6359.372\n",
      "Ep:182, loss:0.00000, loss_test:0.02474, lr:1.67e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.945, tt:6394.965\n",
      "Ep:183, loss:0.00000, loss_test:0.02475, lr:1.66e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.936, tt:6428.248\n",
      "Ep:184, loss:0.00000, loss_test:0.02475, lr:1.64e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.933, tt:6462.656\n",
      "Ep:185, loss:0.00000, loss_test:0.02476, lr:1.62e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.922, tt:6495.486\n",
      "Ep:186, loss:0.00000, loss_test:0.02482, lr:1.61e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.909, tt:6528.056\n",
      "Ep:187, loss:0.00000, loss_test:0.02486, lr:1.59e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.904, tt:6561.924\n",
      "Ep:188, loss:0.00000, loss_test:0.02487, lr:1.58e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.892, tt:6594.550\n",
      "Ep:189, loss:0.00000, loss_test:0.02488, lr:1.56e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.891, tt:6629.198\n",
      "Ep:190, loss:0.00000, loss_test:0.02490, lr:1.54e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.895, tt:6664.876\n",
      "Ep:191, loss:0.00000, loss_test:0.02494, lr:1.53e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.901, tt:6700.994\n",
      "Ep:192, loss:0.00000, loss_test:0.02494, lr:1.51e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.894, tt:6734.593\n",
      "Ep:193, loss:0.00000, loss_test:0.02494, lr:1.50e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.892, tt:6769.034\n",
      "Ep:194, loss:0.00000, loss_test:0.02498, lr:1.48e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.878, tt:6801.161\n",
      "Ep:195, loss:0.00000, loss_test:0.02501, lr:1.47e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.876, tt:6835.767\n",
      "Ep:196, loss:0.00000, loss_test:0.02503, lr:1.45e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.876, tt:6870.547\n",
      "Ep:197, loss:0.00000, loss_test:0.02507, lr:1.44e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.862, tt:6902.629\n",
      "Ep:198, loss:0.00000, loss_test:0.02509, lr:1.43e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.859, tt:6936.859\n",
      "Ep:199, loss:0.00000, loss_test:0.02510, lr:1.41e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.847, tt:6969.389\n",
      "Ep:200, loss:0.00000, loss_test:0.02511, lr:1.40e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.848, tt:7004.476\n",
      "Ep:201, loss:0.00000, loss_test:0.02516, lr:1.38e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.838, tt:7037.344\n",
      "Ep:202, loss:0.00000, loss_test:0.02517, lr:1.37e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.843, tt:7073.058\n",
      "Ep:203, loss:0.00000, loss_test:0.02517, lr:1.36e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.834, tt:7106.072\n",
      "Ep:204, loss:0.00000, loss_test:0.02518, lr:1.34e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.836, tt:7141.326\n",
      "Ep:205, loss:0.00000, loss_test:0.02521, lr:1.33e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.836, tt:7176.226\n",
      "Ep:206, loss:0.00000, loss_test:0.02522, lr:1.32e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.815, tt:7206.713\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.03470, lr:1.00e-02, fs:0.55901 (r=0.455,p=0.726),  time:34.210, tt:34.210\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.02347, lr:1.00e-02, fs:0.60633 (r=0.677,p=0.549),  time:35.118, tt:70.236\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02125, lr:1.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:35.496, tt:106.489\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02185, lr:1.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:35.580, tt:142.321\n",
      "Ep:4, loss:0.00004, loss_test:0.02283, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:35.747, tt:178.736\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02355, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.845, tt:215.069\n",
      "Ep:6, loss:0.00005, loss_test:0.02389, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.822, tt:250.756\n",
      "Ep:7, loss:0.00005, loss_test:0.02387, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.966, tt:287.727\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00005, loss_test:0.02358, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.944, tt:323.497\n",
      "Ep:9, loss:0.00005, loss_test:0.02309, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.910, tt:359.101\n",
      "Ep:10, loss:0.00005, loss_test:0.02247, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:35.907, tt:394.977\n",
      "Ep:11, loss:0.00004, loss_test:0.02181, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:35.800, tt:429.603\n",
      "Ep:12, loss:0.00004, loss_test:0.02116, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:35.694, tt:464.027\n",
      "Ep:13, loss:0.00004, loss_test:0.02054, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:35.662, tt:499.266\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02000, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:35.625, tt:534.371\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01957, lr:1.00e-02, fs:0.68345 (r=0.960,p=0.531),  time:35.675, tt:570.804\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01922, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:35.615, tt:605.462\n",
      "Ep:17, loss:0.00004, loss_test:0.01897, lr:1.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:35.610, tt:640.974\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01878, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:35.563, tt:675.706\n",
      "Ep:19, loss:0.00004, loss_test:0.01863, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.528, tt:710.565\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01853, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:35.510, tt:745.713\n",
      "Ep:21, loss:0.00004, loss_test:0.01844, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:35.479, tt:780.528\n",
      "Ep:22, loss:0.00004, loss_test:0.01837, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.506, tt:816.649\n",
      "Ep:23, loss:0.00004, loss_test:0.01828, lr:1.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:35.484, tt:851.613\n",
      "Ep:24, loss:0.00004, loss_test:0.01819, lr:1.00e-02, fs:0.66403 (r=0.848,p=0.545),  time:35.444, tt:886.089\n",
      "Ep:25, loss:0.00004, loss_test:0.01811, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:35.415, tt:920.796\n",
      "Ep:26, loss:0.00004, loss_test:0.01802, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:35.398, tt:955.751\n",
      "Ep:27, loss:0.00003, loss_test:0.01792, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.406, tt:991.357\n",
      "Ep:28, loss:0.00003, loss_test:0.01781, lr:1.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:35.356, tt:1025.328\n",
      "Ep:29, loss:0.00003, loss_test:0.01771, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:35.378, tt:1061.340\n",
      "Ep:30, loss:0.00003, loss_test:0.01760, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:35.379, tt:1096.762\n",
      "Ep:31, loss:0.00003, loss_test:0.01750, lr:9.90e-03, fs:0.69388 (r=0.859,p=0.582),  time:35.383, tt:1132.245\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01742, lr:9.90e-03, fs:0.69672 (r=0.859,p=0.586),  time:35.393, tt:1167.973\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01733, lr:9.90e-03, fs:0.70248 (r=0.859,p=0.594),  time:35.372, tt:1202.633\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01726, lr:9.90e-03, fs:0.69959 (r=0.859,p=0.590),  time:35.383, tt:1238.406\n",
      "Ep:35, loss:0.00003, loss_test:0.01720, lr:9.90e-03, fs:0.69959 (r=0.859,p=0.590),  time:35.381, tt:1273.717\n",
      "Ep:36, loss:0.00003, loss_test:0.01714, lr:9.90e-03, fs:0.70833 (r=0.859,p=0.603),  time:35.392, tt:1309.503\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01709, lr:9.90e-03, fs:0.71130 (r=0.859,p=0.607),  time:35.372, tt:1344.140\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01705, lr:9.90e-03, fs:0.71130 (r=0.859,p=0.607),  time:35.370, tt:1379.411\n",
      "Ep:39, loss:0.00003, loss_test:0.01701, lr:9.90e-03, fs:0.70833 (r=0.859,p=0.603),  time:35.441, tt:1417.650\n",
      "Ep:40, loss:0.00003, loss_test:0.01698, lr:9.90e-03, fs:0.70588 (r=0.848,p=0.604),  time:35.434, tt:1452.794\n",
      "Ep:41, loss:0.00003, loss_test:0.01694, lr:9.90e-03, fs:0.70588 (r=0.848,p=0.604),  time:35.454, tt:1489.077\n",
      "Ep:42, loss:0.00003, loss_test:0.01691, lr:9.90e-03, fs:0.70339 (r=0.838,p=0.606),  time:35.455, tt:1524.564\n",
      "Ep:43, loss:0.00003, loss_test:0.01686, lr:9.90e-03, fs:0.71552 (r=0.838,p=0.624),  time:35.489, tt:1561.523\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01683, lr:9.90e-03, fs:0.71552 (r=0.838,p=0.624),  time:35.514, tt:1598.148\n",
      "Ep:45, loss:0.00003, loss_test:0.01679, lr:9.90e-03, fs:0.71861 (r=0.838,p=0.629),  time:35.528, tt:1634.280\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01675, lr:9.90e-03, fs:0.72174 (r=0.838,p=0.634),  time:35.544, tt:1670.584\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01671, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:35.578, tt:1707.764\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01668, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:35.586, tt:1743.726\n",
      "Ep:49, loss:0.00003, loss_test:0.01665, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:35.593, tt:1779.637\n",
      "Ep:50, loss:0.00003, loss_test:0.01662, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:35.594, tt:1815.283\n",
      "Ep:51, loss:0.00003, loss_test:0.01659, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:35.574, tt:1849.845\n",
      "Ep:52, loss:0.00003, loss_test:0.01657, lr:9.90e-03, fs:0.73362 (r=0.848,p=0.646),  time:35.564, tt:1884.916\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01655, lr:9.90e-03, fs:0.73128 (r=0.838,p=0.648),  time:35.574, tt:1921.012\n",
      "Ep:54, loss:0.00003, loss_test:0.01653, lr:9.90e-03, fs:0.73778 (r=0.838,p=0.659),  time:35.555, tt:1955.539\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.01650, lr:9.90e-03, fs:0.73778 (r=0.838,p=0.659),  time:35.544, tt:1990.459\n",
      "Ep:56, loss:0.00003, loss_test:0.01648, lr:9.90e-03, fs:0.73778 (r=0.838,p=0.659),  time:35.554, tt:2026.603\n",
      "Ep:57, loss:0.00003, loss_test:0.01646, lr:9.90e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.513, tt:2059.746\n",
      "Ep:58, loss:0.00003, loss_test:0.01643, lr:9.90e-03, fs:0.73214 (r=0.828,p=0.656),  time:35.474, tt:2092.941\n",
      "Ep:59, loss:0.00003, loss_test:0.01641, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.446, tt:2126.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.01639, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.431, tt:2161.268\n",
      "Ep:61, loss:0.00003, loss_test:0.01637, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.421, tt:2196.082\n",
      "Ep:62, loss:0.00003, loss_test:0.01635, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.393, tt:2229.734\n",
      "Ep:63, loss:0.00003, loss_test:0.01633, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.411, tt:2266.282\n",
      "Ep:64, loss:0.00003, loss_test:0.01631, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.392, tt:2300.493\n",
      "Ep:65, loss:0.00003, loss_test:0.01629, lr:9.90e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.384, tt:2335.361\n",
      "Ep:66, loss:0.00003, loss_test:0.01628, lr:9.80e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.362, tt:2369.245\n",
      "Ep:67, loss:0.00003, loss_test:0.01626, lr:9.70e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.352, tt:2403.920\n",
      "Ep:68, loss:0.00003, loss_test:0.01624, lr:9.61e-03, fs:0.72973 (r=0.818,p=0.659),  time:35.342, tt:2438.591\n",
      "Ep:69, loss:0.00003, loss_test:0.01622, lr:9.51e-03, fs:0.73303 (r=0.818,p=0.664),  time:35.331, tt:2473.163\n",
      "Ep:70, loss:0.00002, loss_test:0.01621, lr:9.41e-03, fs:0.73303 (r=0.818,p=0.664),  time:35.331, tt:2508.467\n",
      "Ep:71, loss:0.00002, loss_test:0.01619, lr:9.32e-03, fs:0.73303 (r=0.818,p=0.664),  time:35.311, tt:2542.358\n",
      "Ep:72, loss:0.00002, loss_test:0.01617, lr:9.23e-03, fs:0.73303 (r=0.818,p=0.664),  time:35.288, tt:2576.040\n",
      "Ep:73, loss:0.00002, loss_test:0.01617, lr:9.14e-03, fs:0.73303 (r=0.818,p=0.664),  time:35.284, tt:2611.034\n",
      "Ep:74, loss:0.00002, loss_test:0.01615, lr:9.04e-03, fs:0.73636 (r=0.818,p=0.669),  time:35.256, tt:2644.201\n",
      "Ep:75, loss:0.00002, loss_test:0.01614, lr:8.95e-03, fs:0.73636 (r=0.818,p=0.669),  time:35.245, tt:2678.603\n",
      "Ep:76, loss:0.00002, loss_test:0.01612, lr:8.86e-03, fs:0.73636 (r=0.818,p=0.669),  time:35.247, tt:2714.006\n",
      "Ep:77, loss:0.00002, loss_test:0.01610, lr:8.78e-03, fs:0.73636 (r=0.818,p=0.669),  time:35.225, tt:2747.549\n",
      "Ep:78, loss:0.00002, loss_test:0.01609, lr:8.69e-03, fs:0.73973 (r=0.818,p=0.675),  time:35.228, tt:2783.007\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.01608, lr:8.69e-03, fs:0.73733 (r=0.808,p=0.678),  time:35.233, tt:2818.615\n",
      "Ep:80, loss:0.00002, loss_test:0.01605, lr:8.69e-03, fs:0.73733 (r=0.808,p=0.678),  time:35.224, tt:2853.159\n",
      "Ep:81, loss:0.00002, loss_test:0.01603, lr:8.69e-03, fs:0.73733 (r=0.808,p=0.678),  time:35.229, tt:2888.787\n",
      "Ep:82, loss:0.00002, loss_test:0.01601, lr:8.69e-03, fs:0.74074 (r=0.808,p=0.684),  time:35.240, tt:2924.926\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.01599, lr:8.69e-03, fs:0.74074 (r=0.808,p=0.684),  time:35.244, tt:2960.535\n",
      "Ep:84, loss:0.00002, loss_test:0.01598, lr:8.69e-03, fs:0.74074 (r=0.808,p=0.684),  time:35.239, tt:2995.318\n",
      "Ep:85, loss:0.00002, loss_test:0.01595, lr:8.69e-03, fs:0.74419 (r=0.808,p=0.690),  time:35.210, tt:3028.027\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01594, lr:8.69e-03, fs:0.74178 (r=0.798,p=0.693),  time:35.205, tt:3062.811\n",
      "Ep:87, loss:0.00002, loss_test:0.01593, lr:8.69e-03, fs:0.74178 (r=0.798,p=0.693),  time:35.204, tt:3097.910\n",
      "Ep:88, loss:0.00002, loss_test:0.01591, lr:8.69e-03, fs:0.74178 (r=0.798,p=0.693),  time:35.192, tt:3132.086\n",
      "Ep:89, loss:0.00002, loss_test:0.01591, lr:8.69e-03, fs:0.74178 (r=0.798,p=0.693),  time:35.184, tt:3166.587\n",
      "Ep:90, loss:0.00002, loss_test:0.01589, lr:8.69e-03, fs:0.74178 (r=0.798,p=0.693),  time:35.191, tt:3202.422\n",
      "Ep:91, loss:0.00002, loss_test:0.01588, lr:8.69e-03, fs:0.74178 (r=0.798,p=0.693),  time:35.174, tt:3236.014\n",
      "Ep:92, loss:0.00002, loss_test:0.01587, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.181, tt:3271.869\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.01586, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.182, tt:3307.144\n",
      "Ep:94, loss:0.00002, loss_test:0.01586, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.184, tt:3342.515\n",
      "Ep:95, loss:0.00002, loss_test:0.01585, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.181, tt:3377.371\n",
      "Ep:96, loss:0.00002, loss_test:0.01583, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.170, tt:3411.534\n",
      "Ep:97, loss:0.00002, loss_test:0.01582, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.166, tt:3446.243\n",
      "Ep:98, loss:0.00002, loss_test:0.01581, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.163, tt:3481.147\n",
      "Ep:99, loss:0.00002, loss_test:0.01581, lr:8.69e-03, fs:0.74882 (r=0.798,p=0.705),  time:35.160, tt:3516.041\n",
      "Ep:100, loss:0.00002, loss_test:0.01581, lr:8.69e-03, fs:0.75238 (r=0.798,p=0.712),  time:35.160, tt:3551.152\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00002, loss_test:0.01581, lr:8.69e-03, fs:0.75598 (r=0.798,p=0.718),  time:35.154, tt:3585.729\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00002, loss_test:0.01579, lr:8.69e-03, fs:0.75598 (r=0.798,p=0.718),  time:35.157, tt:3621.172\n",
      "Ep:103, loss:0.00002, loss_test:0.01579, lr:8.69e-03, fs:0.75598 (r=0.798,p=0.718),  time:35.144, tt:3655.020\n",
      "Ep:104, loss:0.00002, loss_test:0.01578, lr:8.69e-03, fs:0.75598 (r=0.798,p=0.718),  time:35.121, tt:3687.743\n",
      "Ep:105, loss:0.00002, loss_test:0.01576, lr:8.69e-03, fs:0.75598 (r=0.798,p=0.718),  time:35.118, tt:3722.541\n",
      "Ep:106, loss:0.00002, loss_test:0.01575, lr:8.69e-03, fs:0.75962 (r=0.798,p=0.725),  time:35.129, tt:3758.795\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01574, lr:8.69e-03, fs:0.75362 (r=0.788,p=0.722),  time:35.124, tt:3793.446\n",
      "Ep:108, loss:0.00002, loss_test:0.01574, lr:8.69e-03, fs:0.74757 (r=0.778,p=0.720),  time:35.125, tt:3828.597\n",
      "Ep:109, loss:0.00002, loss_test:0.01573, lr:8.69e-03, fs:0.75122 (r=0.778,p=0.726),  time:35.122, tt:3863.428\n",
      "Ep:110, loss:0.00002, loss_test:0.01572, lr:8.69e-03, fs:0.75122 (r=0.778,p=0.726),  time:35.119, tt:3898.167\n",
      "Ep:111, loss:0.00002, loss_test:0.01571, lr:8.69e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.134, tt:3935.027\n",
      "Ep:112, loss:0.00002, loss_test:0.01570, lr:8.69e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.128, tt:3969.501\n",
      "Ep:113, loss:0.00002, loss_test:0.01570, lr:8.69e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.128, tt:4004.648\n",
      "Ep:114, loss:0.00002, loss_test:0.01570, lr:8.69e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.121, tt:4038.927\n",
      "Ep:115, loss:0.00002, loss_test:0.01570, lr:8.69e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.135, tt:4075.694\n",
      "Ep:116, loss:0.00002, loss_test:0.01568, lr:8.69e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.142, tt:4111.625\n",
      "Ep:117, loss:0.00002, loss_test:0.01569, lr:8.69e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.136, tt:4146.039\n",
      "Ep:118, loss:0.00002, loss_test:0.01569, lr:8.60e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.136, tt:4181.125\n",
      "Ep:119, loss:0.00002, loss_test:0.01569, lr:8.51e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.144, tt:4217.323\n",
      "Ep:120, loss:0.00002, loss_test:0.01568, lr:8.43e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.144, tt:4252.378\n",
      "Ep:121, loss:0.00002, loss_test:0.01568, lr:8.35e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.139, tt:4287.017\n",
      "Ep:122, loss:0.00002, loss_test:0.01568, lr:8.26e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.141, tt:4322.301\n",
      "Ep:123, loss:0.00002, loss_test:0.01568, lr:8.18e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.137, tt:4357.037\n",
      "Ep:124, loss:0.00002, loss_test:0.01569, lr:8.10e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.140, tt:4392.516\n",
      "Ep:125, loss:0.00002, loss_test:0.01568, lr:8.02e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.169, tt:4431.299\n",
      "Ep:126, loss:0.00002, loss_test:0.01569, lr:7.94e-03, fs:0.75862 (r=0.778,p=0.740),  time:35.164, tt:4465.821\n",
      "Ep:127, loss:0.00002, loss_test:0.01568, lr:7.86e-03, fs:0.76238 (r=0.778,p=0.748),  time:35.176, tt:4502.500\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00002, loss_test:0.01568, lr:7.86e-03, fs:0.76238 (r=0.778,p=0.748),  time:35.173, tt:4537.268\n",
      "Ep:129, loss:0.00002, loss_test:0.01568, lr:7.86e-03, fs:0.76238 (r=0.778,p=0.748),  time:35.172, tt:4572.333\n",
      "Ep:130, loss:0.00002, loss_test:0.01569, lr:7.86e-03, fs:0.76238 (r=0.778,p=0.748),  time:35.170, tt:4607.335\n",
      "Ep:131, loss:0.00002, loss_test:0.01569, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.177, tt:4643.412\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00002, loss_test:0.01569, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.179, tt:4678.863\n",
      "Ep:133, loss:0.00002, loss_test:0.01569, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.184, tt:4714.693\n",
      "Ep:134, loss:0.00002, loss_test:0.01569, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.189, tt:4750.564\n",
      "Ep:135, loss:0.00002, loss_test:0.01570, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.199, tt:4787.075\n",
      "Ep:136, loss:0.00002, loss_test:0.01571, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.196, tt:4821.807\n",
      "Ep:137, loss:0.00002, loss_test:0.01572, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.202, tt:4857.847\n",
      "Ep:138, loss:0.00002, loss_test:0.01572, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.203, tt:4893.233\n",
      "Ep:139, loss:0.00002, loss_test:0.01571, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.202, tt:4928.320\n",
      "Ep:140, loss:0.00002, loss_test:0.01571, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.200, tt:4963.244\n",
      "Ep:141, loss:0.00002, loss_test:0.01572, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.196, tt:4997.831\n",
      "Ep:142, loss:0.00002, loss_test:0.01573, lr:7.86e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.196, tt:5033.056\n",
      "Ep:143, loss:0.00002, loss_test:0.01573, lr:7.78e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.204, tt:5069.311\n",
      "Ep:144, loss:0.00002, loss_test:0.01572, lr:7.70e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.219, tt:5106.821\n",
      "Ep:145, loss:0.00002, loss_test:0.01572, lr:7.62e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.218, tt:5141.781\n",
      "Ep:146, loss:0.00002, loss_test:0.01572, lr:7.55e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.216, tt:5176.816\n",
      "Ep:147, loss:0.00002, loss_test:0.01572, lr:7.47e-03, fs:0.77228 (r=0.788,p=0.757),  time:35.209, tt:5210.951\n",
      "Ep:148, loss:0.00002, loss_test:0.01572, lr:7.40e-03, fs:0.77612 (r=0.788,p=0.765),  time:35.208, tt:5245.934\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00002, loss_test:0.01572, lr:7.40e-03, fs:0.77612 (r=0.788,p=0.765),  time:35.207, tt:5280.984\n",
      "Ep:150, loss:0.00002, loss_test:0.01572, lr:7.40e-03, fs:0.78000 (r=0.788,p=0.772),  time:35.210, tt:5316.652\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00002, loss_test:0.01572, lr:7.40e-03, fs:0.78000 (r=0.788,p=0.772),  time:35.208, tt:5351.636\n",
      "Ep:152, loss:0.00002, loss_test:0.01571, lr:7.40e-03, fs:0.78000 (r=0.788,p=0.772),  time:35.209, tt:5387.003\n",
      "Ep:153, loss:0.00002, loss_test:0.01571, lr:7.40e-03, fs:0.78000 (r=0.788,p=0.772),  time:35.209, tt:5422.250\n",
      "Ep:154, loss:0.00002, loss_test:0.01571, lr:7.40e-03, fs:0.78392 (r=0.788,p=0.780),  time:35.202, tt:5456.317\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00002, loss_test:0.01571, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.199, tt:5491.115\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00002, loss_test:0.01570, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.205, tt:5527.190\n",
      "Ep:157, loss:0.00002, loss_test:0.01570, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.215, tt:5563.993\n",
      "Ep:158, loss:0.00002, loss_test:0.01568, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.216, tt:5599.299\n",
      "Ep:159, loss:0.00002, loss_test:0.01568, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.231, tt:5636.896\n",
      "Ep:160, loss:0.00002, loss_test:0.01568, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.229, tt:5671.933\n",
      "Ep:161, loss:0.00002, loss_test:0.01569, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.236, tt:5708.264\n",
      "Ep:162, loss:0.00002, loss_test:0.01570, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.235, tt:5743.374\n",
      "Ep:163, loss:0.00002, loss_test:0.01569, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.241, tt:5779.580\n",
      "Ep:164, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.78788 (r=0.788,p=0.788),  time:35.237, tt:5814.153\n",
      "Ep:165, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79188 (r=0.788,p=0.796),  time:35.243, tt:5850.409\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79188 (r=0.788,p=0.796),  time:35.248, tt:5886.452\n",
      "Ep:167, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79188 (r=0.788,p=0.796),  time:35.250, tt:5922.003\n",
      "Ep:168, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79188 (r=0.788,p=0.796),  time:35.250, tt:5957.252\n",
      "Ep:169, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.253, tt:5992.991\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.246, tt:6027.082\n",
      "Ep:171, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.250, tt:6062.949\n",
      "Ep:172, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.254, tt:6098.865\n",
      "Ep:173, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.257, tt:6134.657\n",
      "Ep:174, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.255, tt:6169.684\n",
      "Ep:175, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.251, tt:6204.244\n",
      "Ep:176, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.79592 (r=0.788,p=0.804),  time:35.259, tt:6240.807\n",
      "Ep:177, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.80000 (r=0.788,p=0.812),  time:35.261, tt:6276.418\n",
      "##########Best model found so far##########\n",
      "Ep:178, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.80000 (r=0.788,p=0.812),  time:35.261, tt:6311.768\n",
      "Ep:179, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.80000 (r=0.788,p=0.812),  time:35.263, tt:6347.355\n",
      "Ep:180, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.80000 (r=0.788,p=0.812),  time:35.264, tt:6382.850\n",
      "Ep:181, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.80000 (r=0.788,p=0.812),  time:35.265, tt:6418.194\n",
      "Ep:182, loss:0.00001, loss_test:0.01570, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.265, tt:6453.505\n",
      "##########Best model found so far##########\n",
      "Ep:183, loss:0.00001, loss_test:0.01571, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.269, tt:6489.456\n",
      "Ep:184, loss:0.00001, loss_test:0.01572, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.269, tt:6524.683\n",
      "Ep:185, loss:0.00001, loss_test:0.01572, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.270, tt:6560.263\n",
      "Ep:186, loss:0.00001, loss_test:0.01574, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.278, tt:6596.911\n",
      "Ep:187, loss:0.00001, loss_test:0.01573, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.283, tt:6633.171\n",
      "Ep:188, loss:0.00001, loss_test:0.01573, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.283, tt:6668.487\n",
      "Ep:189, loss:0.00001, loss_test:0.01574, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.288, tt:6704.702\n",
      "Ep:190, loss:0.00001, loss_test:0.01575, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.292, tt:6740.757\n",
      "Ep:191, loss:0.00001, loss_test:0.01576, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.297, tt:6777.036\n",
      "Ep:192, loss:0.00001, loss_test:0.01577, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.298, tt:6812.443\n",
      "Ep:193, loss:0.00001, loss_test:0.01577, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.298, tt:6847.883\n",
      "Ep:194, loss:0.00001, loss_test:0.01578, lr:7.32e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.295, tt:6882.435\n",
      "Ep:195, loss:0.00001, loss_test:0.01579, lr:7.25e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.293, tt:6917.401\n",
      "Ep:196, loss:0.00001, loss_test:0.01579, lr:7.18e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.295, tt:6953.076\n",
      "Ep:197, loss:0.00001, loss_test:0.01580, lr:7.11e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.305, tt:6990.471\n",
      "Ep:198, loss:0.00001, loss_test:0.01581, lr:7.03e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.304, tt:7025.484\n",
      "Ep:199, loss:0.00001, loss_test:0.01581, lr:6.96e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.307, tt:7061.427\n",
      "Ep:200, loss:0.00001, loss_test:0.01582, lr:6.89e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.305, tt:7096.324\n",
      "Ep:201, loss:0.00001, loss_test:0.01583, lr:6.83e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.308, tt:7132.270\n",
      "Ep:202, loss:0.00001, loss_test:0.01583, lr:6.76e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.305, tt:7166.976\n",
      "Ep:203, loss:0.00001, loss_test:0.01583, lr:6.69e-03, fs:0.80829 (r=0.788,p=0.830),  time:35.293, tt:7199.829\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00001, loss_test:0.01582, lr:6.69e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.254, tt:7226.968\n",
      "Ep:205, loss:0.00001, loss_test:0.01584, lr:6.69e-03, fs:0.80412 (r=0.788,p=0.821),  time:35.231, tt:7257.679\n",
      "Ep:206, loss:0.00001, loss_test:0.01585, lr:6.69e-03, fs:0.80829 (r=0.788,p=0.830),  time:35.175, tt:7281.157\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02757, lr:1.00e-02, fs:0.56287 (r=0.475,p=0.691),  time:40.554, tt:40.554\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02194, lr:1.00e-02, fs:0.58447 (r=0.646,p=0.533),  time:40.107, tt:80.214\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02046, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:39.772, tt:119.315\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02073, lr:1.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:39.831, tt:159.322\n",
      "Ep:4, loss:0.00004, loss_test:0.02127, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.580, tt:197.901\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02157, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.368, tt:236.208\n",
      "Ep:6, loss:0.00004, loss_test:0.02159, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.437, tt:276.059\n",
      "Ep:7, loss:0.00004, loss_test:0.02140, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.418, tt:315.342\n",
      "Ep:8, loss:0.00004, loss_test:0.02104, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.355, tt:354.195\n",
      "Ep:9, loss:0.00004, loss_test:0.02061, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.431, tt:394.310\n",
      "Ep:10, loss:0.00004, loss_test:0.02013, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:39.442, tt:433.861\n",
      "Ep:11, loss:0.00004, loss_test:0.01968, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:39.432, tt:473.188\n",
      "Ep:12, loss:0.00004, loss_test:0.01929, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:39.464, tt:513.036\n",
      "Ep:13, loss:0.00004, loss_test:0.01901, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:39.557, tt:553.796\n",
      "Ep:14, loss:0.00004, loss_test:0.01884, lr:1.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:39.619, tt:594.287\n",
      "Ep:15, loss:0.00003, loss_test:0.01875, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:39.673, tt:634.770\n",
      "Ep:16, loss:0.00003, loss_test:0.01872, lr:9.90e-03, fs:0.67460 (r=0.859,p=0.556),  time:39.540, tt:672.185\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01869, lr:9.90e-03, fs:0.65854 (r=0.818,p=0.551),  time:39.612, tt:713.024\n",
      "Ep:18, loss:0.00003, loss_test:0.01863, lr:9.90e-03, fs:0.65854 (r=0.818,p=0.551),  time:39.643, tt:753.212\n",
      "Ep:19, loss:0.00003, loss_test:0.01855, lr:9.90e-03, fs:0.66393 (r=0.818,p=0.559),  time:39.585, tt:791.707\n",
      "Ep:20, loss:0.00003, loss_test:0.01845, lr:9.90e-03, fs:0.66397 (r=0.828,p=0.554),  time:39.588, tt:831.346\n",
      "Ep:21, loss:0.00003, loss_test:0.01833, lr:9.90e-03, fs:0.66935 (r=0.838,p=0.557),  time:39.559, tt:870.306\n",
      "Ep:22, loss:0.00003, loss_test:0.01821, lr:9.90e-03, fs:0.66932 (r=0.848,p=0.553),  time:39.563, tt:909.941\n",
      "Ep:23, loss:0.00003, loss_test:0.01809, lr:9.90e-03, fs:0.67460 (r=0.859,p=0.556),  time:39.526, tt:948.616\n",
      "Ep:24, loss:0.00003, loss_test:0.01797, lr:9.90e-03, fs:0.67194 (r=0.859,p=0.552),  time:39.546, tt:988.639\n",
      "Ep:25, loss:0.00003, loss_test:0.01787, lr:9.90e-03, fs:0.67717 (r=0.869,p=0.555),  time:39.680, tt:1031.682\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01777, lr:9.90e-03, fs:0.68254 (r=0.869,p=0.562),  time:39.723, tt:1072.514\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01767, lr:9.90e-03, fs:0.68254 (r=0.869,p=0.562),  time:39.758, tt:1113.232\n",
      "Ep:28, loss:0.00003, loss_test:0.01757, lr:9.90e-03, fs:0.68254 (r=0.869,p=0.562),  time:39.776, tt:1153.499\n",
      "Ep:29, loss:0.00003, loss_test:0.01749, lr:9.90e-03, fs:0.68800 (r=0.869,p=0.570),  time:39.715, tt:1191.442\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01742, lr:9.90e-03, fs:0.69919 (r=0.869,p=0.585),  time:39.698, tt:1230.645\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01735, lr:9.90e-03, fs:0.70248 (r=0.859,p=0.594),  time:39.707, tt:1270.627\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01728, lr:9.90e-03, fs:0.70539 (r=0.859,p=0.599),  time:39.679, tt:1309.401\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01722, lr:9.90e-03, fs:0.70833 (r=0.859,p=0.603),  time:39.594, tt:1346.190\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01716, lr:9.90e-03, fs:0.70539 (r=0.859,p=0.599),  time:39.507, tt:1382.737\n",
      "Ep:35, loss:0.00003, loss_test:0.01709, lr:9.90e-03, fs:0.70833 (r=0.859,p=0.603),  time:39.500, tt:1421.988\n",
      "Ep:36, loss:0.00003, loss_test:0.01701, lr:9.90e-03, fs:0.71429 (r=0.859,p=0.612),  time:39.484, tt:1460.908\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01693, lr:9.90e-03, fs:0.72574 (r=0.869,p=0.623),  time:39.460, tt:1499.479\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01685, lr:9.90e-03, fs:0.72881 (r=0.869,p=0.628),  time:39.475, tt:1539.529\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01678, lr:9.90e-03, fs:0.73418 (r=0.879,p=0.630),  time:39.434, tt:1577.344\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01670, lr:9.90e-03, fs:0.73418 (r=0.879,p=0.630),  time:39.452, tt:1617.531\n",
      "Ep:41, loss:0.00003, loss_test:0.01663, lr:9.90e-03, fs:0.72881 (r=0.869,p=0.628),  time:39.455, tt:1657.122\n",
      "Ep:42, loss:0.00003, loss_test:0.01657, lr:9.90e-03, fs:0.73191 (r=0.869,p=0.632),  time:39.390, tt:1693.778\n",
      "Ep:43, loss:0.00003, loss_test:0.01651, lr:9.90e-03, fs:0.74138 (r=0.869,p=0.647),  time:39.421, tt:1734.538\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01646, lr:9.90e-03, fs:0.74138 (r=0.869,p=0.647),  time:39.379, tt:1772.077\n",
      "Ep:45, loss:0.00003, loss_test:0.01640, lr:9.90e-03, fs:0.73593 (r=0.859,p=0.644),  time:39.379, tt:1811.435\n",
      "Ep:46, loss:0.00003, loss_test:0.01635, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:39.381, tt:1850.903\n",
      "Ep:47, loss:0.00003, loss_test:0.01630, lr:9.90e-03, fs:0.73362 (r=0.848,p=0.646),  time:39.394, tt:1890.926\n",
      "Ep:48, loss:0.00003, loss_test:0.01626, lr:9.90e-03, fs:0.74009 (r=0.848,p=0.656),  time:39.423, tt:1931.712\n",
      "Ep:49, loss:0.00003, loss_test:0.01622, lr:9.90e-03, fs:0.75556 (r=0.859,p=0.675),  time:39.386, tt:1969.296\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01617, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.348, tt:2006.763\n",
      "Ep:51, loss:0.00003, loss_test:0.01613, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.346, tt:2045.966\n",
      "Ep:52, loss:0.00003, loss_test:0.01609, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.353, tt:2085.685\n",
      "Ep:53, loss:0.00003, loss_test:0.01606, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.348, tt:2124.787\n",
      "Ep:54, loss:0.00003, loss_test:0.01602, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.351, tt:2164.295\n",
      "Ep:55, loss:0.00003, loss_test:0.01599, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.316, tt:2201.682\n",
      "Ep:56, loss:0.00002, loss_test:0.01596, lr:9.90e-03, fs:0.75000 (r=0.848,p=0.672),  time:39.284, tt:2239.172\n",
      "Ep:57, loss:0.00002, loss_test:0.01592, lr:9.90e-03, fs:0.74439 (r=0.838,p=0.669),  time:39.263, tt:2277.267\n",
      "Ep:58, loss:0.00002, loss_test:0.01589, lr:9.90e-03, fs:0.74439 (r=0.838,p=0.669),  time:39.250, tt:2315.735\n",
      "Ep:59, loss:0.00002, loss_test:0.01586, lr:9.90e-03, fs:0.74439 (r=0.838,p=0.669),  time:39.207, tt:2352.442\n",
      "Ep:60, loss:0.00002, loss_test:0.01583, lr:9.90e-03, fs:0.74439 (r=0.838,p=0.669),  time:39.195, tt:2390.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00002, loss_test:0.01580, lr:9.80e-03, fs:0.74439 (r=0.838,p=0.669),  time:39.180, tt:2429.138\n",
      "Ep:62, loss:0.00002, loss_test:0.01578, lr:9.70e-03, fs:0.75336 (r=0.848,p=0.677),  time:39.124, tt:2464.826\n",
      "Ep:63, loss:0.00002, loss_test:0.01575, lr:9.61e-03, fs:0.75336 (r=0.848,p=0.677),  time:39.128, tt:2504.217\n",
      "Ep:64, loss:0.00002, loss_test:0.01573, lr:9.51e-03, fs:0.75336 (r=0.848,p=0.677),  time:39.155, tt:2545.091\n",
      "Ep:65, loss:0.00002, loss_test:0.01570, lr:9.41e-03, fs:0.76018 (r=0.848,p=0.689),  time:39.159, tt:2584.481\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.01567, lr:9.41e-03, fs:0.76018 (r=0.848,p=0.689),  time:39.146, tt:2622.812\n",
      "Ep:67, loss:0.00002, loss_test:0.01566, lr:9.41e-03, fs:0.76364 (r=0.848,p=0.694),  time:39.101, tt:2658.890\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01564, lr:9.41e-03, fs:0.76364 (r=0.848,p=0.694),  time:39.071, tt:2695.933\n",
      "Ep:69, loss:0.00002, loss_test:0.01562, lr:9.41e-03, fs:0.76364 (r=0.848,p=0.694),  time:39.021, tt:2731.472\n",
      "Ep:70, loss:0.00002, loss_test:0.01560, lr:9.41e-03, fs:0.76364 (r=0.848,p=0.694),  time:39.027, tt:2770.915\n",
      "Ep:71, loss:0.00002, loss_test:0.01558, lr:9.41e-03, fs:0.76712 (r=0.848,p=0.700),  time:39.043, tt:2811.065\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.01556, lr:9.41e-03, fs:0.76712 (r=0.848,p=0.700),  time:39.061, tt:2851.420\n",
      "Ep:73, loss:0.00002, loss_test:0.01555, lr:9.41e-03, fs:0.76712 (r=0.848,p=0.700),  time:39.067, tt:2890.961\n",
      "Ep:74, loss:0.00002, loss_test:0.01553, lr:9.41e-03, fs:0.77273 (r=0.859,p=0.702),  time:39.068, tt:2930.078\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.01552, lr:9.41e-03, fs:0.77419 (r=0.848,p=0.712),  time:39.106, tt:2972.059\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.01550, lr:9.41e-03, fs:0.77419 (r=0.848,p=0.712),  time:39.078, tt:3008.992\n",
      "Ep:77, loss:0.00002, loss_test:0.01549, lr:9.41e-03, fs:0.77419 (r=0.848,p=0.712),  time:39.079, tt:3048.132\n",
      "Ep:78, loss:0.00002, loss_test:0.01548, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.102, tt:3089.039\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.01548, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.104, tt:3128.285\n",
      "Ep:80, loss:0.00002, loss_test:0.01546, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.108, tt:3167.741\n",
      "Ep:81, loss:0.00002, loss_test:0.01544, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.138, tt:3209.289\n",
      "Ep:82, loss:0.00002, loss_test:0.01543, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.163, tt:3250.491\n",
      "Ep:83, loss:0.00002, loss_test:0.01542, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.161, tt:3289.526\n",
      "Ep:84, loss:0.00002, loss_test:0.01541, lr:9.41e-03, fs:0.77778 (r=0.848,p=0.718),  time:39.169, tt:3329.345\n",
      "Ep:85, loss:0.00002, loss_test:0.01540, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.169, tt:3368.491\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01539, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.158, tt:3406.723\n",
      "Ep:87, loss:0.00002, loss_test:0.01538, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.165, tt:3446.498\n",
      "Ep:88, loss:0.00002, loss_test:0.01538, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.149, tt:3484.218\n",
      "Ep:89, loss:0.00002, loss_test:0.01537, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.127, tt:3521.475\n",
      "Ep:90, loss:0.00002, loss_test:0.01536, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.119, tt:3559.790\n",
      "Ep:91, loss:0.00002, loss_test:0.01534, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.125, tt:3599.470\n",
      "Ep:92, loss:0.00002, loss_test:0.01534, lr:9.41e-03, fs:0.78140 (r=0.848,p=0.724),  time:39.131, tt:3639.224\n",
      "Ep:93, loss:0.00002, loss_test:0.01533, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.146, tt:3679.712\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.01532, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.177, tt:3721.829\n",
      "Ep:95, loss:0.00002, loss_test:0.01531, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.181, tt:3761.415\n",
      "Ep:96, loss:0.00002, loss_test:0.01531, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.185, tt:3800.943\n",
      "Ep:97, loss:0.00002, loss_test:0.01530, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.190, tt:3840.598\n",
      "Ep:98, loss:0.00002, loss_test:0.01530, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.177, tt:3878.480\n",
      "Ep:99, loss:0.00002, loss_test:0.01529, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.181, tt:3918.056\n",
      "Ep:100, loss:0.00002, loss_test:0.01529, lr:9.41e-03, fs:0.78505 (r=0.848,p=0.730),  time:39.179, tt:3957.063\n",
      "Ep:101, loss:0.00002, loss_test:0.01528, lr:9.41e-03, fs:0.78873 (r=0.848,p=0.737),  time:39.193, tt:3997.698\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00002, loss_test:0.01528, lr:9.41e-03, fs:0.79245 (r=0.848,p=0.743),  time:39.197, tt:4037.285\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00002, loss_test:0.01528, lr:9.41e-03, fs:0.79621 (r=0.848,p=0.750),  time:39.187, tt:4075.418\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.01528, lr:9.41e-03, fs:0.79621 (r=0.848,p=0.750),  time:39.206, tt:4116.595\n",
      "Ep:105, loss:0.00002, loss_test:0.01528, lr:9.41e-03, fs:0.79048 (r=0.838,p=0.748),  time:39.201, tt:4155.353\n",
      "Ep:106, loss:0.00002, loss_test:0.01527, lr:9.41e-03, fs:0.79048 (r=0.838,p=0.748),  time:39.213, tt:4195.837\n",
      "Ep:107, loss:0.00002, loss_test:0.01525, lr:9.41e-03, fs:0.79048 (r=0.838,p=0.748),  time:39.204, tt:4234.018\n",
      "Ep:108, loss:0.00002, loss_test:0.01525, lr:9.41e-03, fs:0.79426 (r=0.838,p=0.755),  time:39.221, tt:4275.064\n",
      "Ep:109, loss:0.00002, loss_test:0.01524, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.225, tt:4314.783\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.01524, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.221, tt:4353.551\n",
      "Ep:111, loss:0.00002, loss_test:0.01523, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.225, tt:4393.151\n",
      "Ep:112, loss:0.00002, loss_test:0.01523, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.219, tt:4431.706\n",
      "Ep:113, loss:0.00002, loss_test:0.01523, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.225, tt:4471.605\n",
      "Ep:114, loss:0.00002, loss_test:0.01523, lr:9.41e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.234, tt:4511.908\n",
      "Ep:115, loss:0.00002, loss_test:0.01523, lr:9.41e-03, fs:0.80383 (r=0.848,p=0.764),  time:39.238, tt:4551.615\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.01523, lr:9.41e-03, fs:0.80383 (r=0.848,p=0.764),  time:39.241, tt:4591.211\n",
      "Ep:117, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.79808 (r=0.838,p=0.761),  time:39.248, tt:4631.290\n",
      "Ep:118, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.79808 (r=0.838,p=0.761),  time:39.255, tt:4671.346\n",
      "Ep:119, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.79808 (r=0.838,p=0.761),  time:39.249, tt:4709.826\n",
      "Ep:120, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.80193 (r=0.838,p=0.769),  time:39.257, tt:4750.145\n",
      "Ep:121, loss:0.00002, loss_test:0.01521, lr:9.41e-03, fs:0.80193 (r=0.838,p=0.769),  time:39.278, tt:4791.888\n",
      "Ep:122, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.80193 (r=0.838,p=0.769),  time:39.285, tt:4832.025\n",
      "Ep:123, loss:0.00002, loss_test:0.01521, lr:9.41e-03, fs:0.80193 (r=0.838,p=0.769),  time:39.278, tt:4870.480\n",
      "Ep:124, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.80583 (r=0.838,p=0.776),  time:39.287, tt:4910.910\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.80976 (r=0.838,p=0.783),  time:39.292, tt:4950.830\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00002, loss_test:0.01521, lr:9.41e-03, fs:0.80976 (r=0.838,p=0.783),  time:39.303, tt:4991.481\n",
      "Ep:127, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.80976 (r=0.838,p=0.783),  time:39.302, tt:5030.709\n",
      "Ep:128, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.80976 (r=0.838,p=0.783),  time:39.325, tt:5072.907\n",
      "Ep:129, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.323, tt:5111.931\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.01519, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.332, tt:5152.503\n",
      "Ep:131, loss:0.00002, loss_test:0.01519, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.331, tt:5191.697\n",
      "Ep:132, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.328, tt:5230.624\n",
      "Ep:133, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.314, tt:5268.138\n",
      "Ep:134, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.320, tt:5308.261\n",
      "Ep:135, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81373 (r=0.838,p=0.790),  time:39.314, tt:5346.668\n",
      "Ep:136, loss:0.00002, loss_test:0.01519, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.320, tt:5386.895\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.314, tt:5425.310\n",
      "Ep:138, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.326, tt:5466.293\n",
      "Ep:139, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.323, tt:5505.211\n",
      "Ep:140, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.328, tt:5545.230\n",
      "Ep:141, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.338, tt:5586.001\n",
      "Ep:142, loss:0.00002, loss_test:0.01520, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.340, tt:5625.684\n",
      "Ep:143, loss:0.00002, loss_test:0.01521, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.339, tt:5664.778\n",
      "Ep:144, loss:0.00002, loss_test:0.01521, lr:9.41e-03, fs:0.81773 (r=0.838,p=0.798),  time:39.344, tt:5704.861\n",
      "Ep:145, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.81592 (r=0.828,p=0.804),  time:39.352, tt:5745.349\n",
      "Ep:146, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.81592 (r=0.828,p=0.804),  time:39.355, tt:5785.124\n",
      "Ep:147, loss:0.00002, loss_test:0.01522, lr:9.41e-03, fs:0.81592 (r=0.828,p=0.804),  time:39.343, tt:5822.739\n",
      "Ep:148, loss:0.00002, loss_test:0.01522, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.346, tt:5862.622\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00002, loss_test:0.01523, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.360, tt:5903.973\n",
      "Ep:150, loss:0.00001, loss_test:0.01524, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.364, tt:5944.038\n",
      "Ep:151, loss:0.00001, loss_test:0.01524, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.371, tt:5984.445\n",
      "Ep:152, loss:0.00001, loss_test:0.01524, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.354, tt:6021.164\n",
      "Ep:153, loss:0.00001, loss_test:0.01525, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.357, tt:6061.023\n",
      "Ep:154, loss:0.00001, loss_test:0.01526, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.362, tt:6101.138\n",
      "Ep:155, loss:0.00001, loss_test:0.01527, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.372, tt:6142.073\n",
      "Ep:156, loss:0.00001, loss_test:0.01527, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.383, tt:6183.064\n",
      "Ep:157, loss:0.00001, loss_test:0.01529, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.386, tt:6222.926\n",
      "Ep:158, loss:0.00001, loss_test:0.01529, lr:9.32e-03, fs:0.82000 (r=0.828,p=0.812),  time:39.369, tt:6259.614\n",
      "Ep:159, loss:0.00001, loss_test:0.01529, lr:9.32e-03, fs:0.82412 (r=0.828,p=0.820),  time:39.362, tt:6298.001\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00001, loss_test:0.01530, lr:9.32e-03, fs:0.81818 (r=0.818,p=0.818),  time:39.366, tt:6337.918\n",
      "Ep:161, loss:0.00001, loss_test:0.01530, lr:9.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:39.367, tt:6377.445\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00001, loss_test:0.01530, lr:9.32e-03, fs:0.81818 (r=0.818,p=0.818),  time:39.363, tt:6416.238\n",
      "Ep:163, loss:0.00001, loss_test:0.01531, lr:9.32e-03, fs:0.82234 (r=0.818,p=0.827),  time:39.362, tt:6455.329\n",
      "Ep:164, loss:0.00001, loss_test:0.01531, lr:9.32e-03, fs:0.82234 (r=0.818,p=0.827),  time:39.369, tt:6495.848\n",
      "Ep:165, loss:0.00001, loss_test:0.01531, lr:9.32e-03, fs:0.82234 (r=0.818,p=0.827),  time:39.368, tt:6535.107\n",
      "Ep:166, loss:0.00001, loss_test:0.01531, lr:9.32e-03, fs:0.82234 (r=0.818,p=0.827),  time:39.373, tt:6575.370\n",
      "Ep:167, loss:0.00001, loss_test:0.01531, lr:9.32e-03, fs:0.82234 (r=0.818,p=0.827),  time:39.369, tt:6613.921\n",
      "Ep:168, loss:0.00001, loss_test:0.01531, lr:9.32e-03, fs:0.82234 (r=0.818,p=0.827),  time:39.366, tt:6652.909\n",
      "Ep:169, loss:0.00001, loss_test:0.01532, lr:9.32e-03, fs:0.82653 (r=0.818,p=0.835),  time:39.369, tt:6692.676\n",
      "Ep:170, loss:0.00001, loss_test:0.01533, lr:9.32e-03, fs:0.82051 (r=0.808,p=0.833),  time:39.367, tt:6731.796\n",
      "Ep:171, loss:0.00001, loss_test:0.01533, lr:9.32e-03, fs:0.82051 (r=0.808,p=0.833),  time:39.369, tt:6771.482\n",
      "Ep:172, loss:0.00001, loss_test:0.01533, lr:9.32e-03, fs:0.81443 (r=0.798,p=0.832),  time:39.376, tt:6812.061\n",
      "Ep:173, loss:0.00001, loss_test:0.01535, lr:9.23e-03, fs:0.81443 (r=0.798,p=0.832),  time:39.387, tt:6853.272\n",
      "Ep:174, loss:0.00001, loss_test:0.01535, lr:9.14e-03, fs:0.81443 (r=0.798,p=0.832),  time:39.395, tt:6894.155\n",
      "Ep:175, loss:0.00001, loss_test:0.01536, lr:9.04e-03, fs:0.81443 (r=0.798,p=0.832),  time:39.417, tt:6937.310\n",
      "Ep:176, loss:0.00001, loss_test:0.01536, lr:8.95e-03, fs:0.81443 (r=0.798,p=0.832),  time:39.422, tt:6977.625\n",
      "Ep:177, loss:0.00001, loss_test:0.01536, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:39.418, tt:7016.371\n",
      "Ep:178, loss:0.00001, loss_test:0.01538, lr:8.78e-03, fs:0.81250 (r=0.788,p=0.839),  time:39.422, tt:7056.539\n",
      "Ep:179, loss:0.00001, loss_test:0.01538, lr:8.69e-03, fs:0.81250 (r=0.788,p=0.839),  time:39.417, tt:7095.053\n",
      "Ep:180, loss:0.00001, loss_test:0.01538, lr:8.60e-03, fs:0.81250 (r=0.788,p=0.839),  time:39.415, tt:7134.143\n",
      "Ep:181, loss:0.00001, loss_test:0.01538, lr:8.51e-03, fs:0.81250 (r=0.788,p=0.839),  time:39.407, tt:7172.137\n",
      "Ep:182, loss:0.00001, loss_test:0.01538, lr:8.43e-03, fs:0.81250 (r=0.788,p=0.839),  time:39.410, tt:7211.983\n",
      "Ep:183, loss:0.00001, loss_test:0.01539, lr:8.35e-03, fs:0.81250 (r=0.788,p=0.839),  time:39.406, tt:7250.776\n",
      "Ep:184, loss:0.00001, loss_test:0.01540, lr:8.26e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.403, tt:7289.578\n",
      "Ep:185, loss:0.00001, loss_test:0.01541, lr:8.18e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.410, tt:7330.306\n",
      "Ep:186, loss:0.00001, loss_test:0.01542, lr:8.10e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.423, tt:7372.193\n",
      "Ep:187, loss:0.00001, loss_test:0.01541, lr:8.02e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.429, tt:7412.569\n",
      "Ep:188, loss:0.00001, loss_test:0.01542, lr:7.94e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.447, tt:7455.433\n",
      "Ep:189, loss:0.00001, loss_test:0.01544, lr:7.86e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.454, tt:7496.290\n",
      "Ep:190, loss:0.00001, loss_test:0.01545, lr:7.78e-03, fs:0.81675 (r=0.788,p=0.848),  time:39.466, tt:7537.989\n",
      "Ep:191, loss:0.00001, loss_test:0.01546, lr:7.70e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.475, tt:7579.216\n",
      "Ep:192, loss:0.00001, loss_test:0.01546, lr:7.62e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.477, tt:7619.133\n",
      "Ep:193, loss:0.00001, loss_test:0.01546, lr:7.55e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.482, tt:7659.443\n",
      "Ep:194, loss:0.00001, loss_test:0.01546, lr:7.47e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.484, tt:7699.425\n",
      "Ep:195, loss:0.00001, loss_test:0.01547, lr:7.40e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.491, tt:7740.169\n",
      "Ep:196, loss:0.00001, loss_test:0.01548, lr:7.32e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.500, tt:7781.491\n",
      "Ep:197, loss:0.00001, loss_test:0.01549, lr:7.25e-03, fs:0.81053 (r=0.778,p=0.846),  time:39.501, tt:7821.174\n",
      "Ep:198, loss:0.00001, loss_test:0.01549, lr:7.18e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.502, tt:7860.900\n",
      "Ep:199, loss:0.00001, loss_test:0.01550, lr:7.11e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.506, tt:7901.199\n",
      "Ep:200, loss:0.00001, loss_test:0.01550, lr:7.03e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.509, tt:7941.263\n",
      "Ep:201, loss:0.00001, loss_test:0.01550, lr:6.96e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.511, tt:7981.142\n",
      "Ep:202, loss:0.00001, loss_test:0.01549, lr:6.89e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.514, tt:8021.408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00001, loss_test:0.01550, lr:6.83e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.505, tt:8059.039\n",
      "Ep:204, loss:0.00001, loss_test:0.01551, lr:6.76e-03, fs:0.80423 (r=0.768,p=0.844),  time:39.456, tt:8088.382\n",
      "Ep:205, loss:0.00001, loss_test:0.01552, lr:6.69e-03, fs:0.79787 (r=0.758,p=0.843),  time:39.419, tt:8120.218\n",
      "Ep:206, loss:0.00001, loss_test:0.01553, lr:6.62e-03, fs:0.79787 (r=0.758,p=0.843),  time:39.403, tt:8156.396\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13932, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.575, tt:34.575\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13718, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:34.598, tt:69.197\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13335, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:34.574, tt:103.722\n",
      "Ep:3, loss:0.00027, loss_test:0.12810, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:35.101, tt:140.405\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12337, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:35.443, tt:177.214\n",
      "Ep:5, loss:0.00025, loss_test:0.12000, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:35.688, tt:214.126\n",
      "Ep:6, loss:0.00025, loss_test:0.11750, lr:1.00e-02, fs:0.63830 (r=0.758,p=0.551),  time:36.272, tt:253.905\n",
      "Ep:7, loss:0.00024, loss_test:0.11545, lr:1.00e-02, fs:0.64000 (r=0.727,p=0.571),  time:36.238, tt:289.901\n",
      "Ep:8, loss:0.00024, loss_test:0.11323, lr:1.00e-02, fs:0.64574 (r=0.727,p=0.581),  time:36.175, tt:325.573\n",
      "Ep:9, loss:0.00023, loss_test:0.11103, lr:1.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:36.162, tt:361.615\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10825, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:36.235, tt:398.580\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10598, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:36.172, tt:434.069\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10382, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:36.229, tt:470.979\n",
      "Ep:13, loss:0.00021, loss_test:0.10131, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:36.126, tt:505.766\n",
      "Ep:14, loss:0.00020, loss_test:0.09909, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:36.143, tt:542.149\n",
      "Ep:15, loss:0.00020, loss_test:0.09680, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:36.124, tt:577.991\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09487, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:36.194, tt:615.295\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09334, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:36.154, tt:650.775\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09194, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:36.123, tt:686.331\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09055, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:36.146, tt:722.915\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08987, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:36.218, tt:760.576\n",
      "Ep:21, loss:0.00016, loss_test:0.08980, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:36.228, tt:797.010\n",
      "Ep:22, loss:0.00016, loss_test:0.08970, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:36.231, tt:833.317\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08872, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:36.226, tt:869.430\n",
      "Ep:24, loss:0.00015, loss_test:0.08846, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:36.243, tt:906.073\n",
      "Ep:25, loss:0.00014, loss_test:0.08829, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:36.270, tt:943.013\n",
      "Ep:26, loss:0.00014, loss_test:0.08848, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:36.288, tt:979.764\n",
      "Ep:27, loss:0.00014, loss_test:0.08854, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:36.277, tt:1015.759\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08732, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:36.357, tt:1054.363\n",
      "Ep:29, loss:0.00013, loss_test:0.08849, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:36.417, tt:1092.518\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08680, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:36.504, tt:1131.622\n",
      "Ep:31, loss:0.00012, loss_test:0.08665, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.553, tt:1169.708\n",
      "Ep:32, loss:0.00011, loss_test:0.08739, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.567, tt:1206.695\n",
      "Ep:33, loss:0.00011, loss_test:0.08440, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:36.580, tt:1243.713\n",
      "Ep:34, loss:0.00011, loss_test:0.08756, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:36.592, tt:1280.713\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08443, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:36.618, tt:1318.257\n",
      "Ep:36, loss:0.00010, loss_test:0.08530, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:36.615, tt:1354.769\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08587, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:36.624, tt:1391.727\n",
      "Ep:38, loss:0.00009, loss_test:0.08192, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:36.669, tt:1430.101\n",
      "Ep:39, loss:0.00009, loss_test:0.08870, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.696, tt:1467.825\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.08150, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.733, tt:1506.073\n",
      "Ep:41, loss:0.00009, loss_test:0.08858, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.734, tt:1542.809\n",
      "Ep:42, loss:0.00009, loss_test:0.08037, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:36.728, tt:1579.313\n",
      "Ep:43, loss:0.00008, loss_test:0.08504, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:36.776, tt:1618.161\n",
      "Ep:44, loss:0.00008, loss_test:0.08290, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:36.777, tt:1654.948\n",
      "Ep:45, loss:0.00008, loss_test:0.08108, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:36.777, tt:1691.755\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.08391, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:36.769, tt:1728.139\n",
      "Ep:47, loss:0.00008, loss_test:0.07897, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:36.754, tt:1764.182\n",
      "Ep:48, loss:0.00007, loss_test:0.08230, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:36.754, tt:1800.928\n",
      "Ep:49, loss:0.00007, loss_test:0.08094, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:36.776, tt:1838.801\n",
      "Ep:50, loss:0.00006, loss_test:0.07780, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:36.801, tt:1876.868\n",
      "Ep:51, loss:0.00007, loss_test:0.07887, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:36.800, tt:1913.583\n",
      "Ep:52, loss:0.00006, loss_test:0.07850, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:36.801, tt:1950.438\n",
      "Ep:53, loss:0.00006, loss_test:0.07804, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:36.785, tt:1986.398\n",
      "Ep:54, loss:0.00006, loss_test:0.07673, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:36.750, tt:2021.251\n",
      "Ep:55, loss:0.00006, loss_test:0.07762, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:36.733, tt:2057.031\n",
      "Ep:56, loss:0.00005, loss_test:0.07740, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:36.767, tt:2095.691\n",
      "Ep:57, loss:0.00005, loss_test:0.07578, lr:9.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.765, tt:2132.369\n",
      "Ep:58, loss:0.00005, loss_test:0.08007, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.789, tt:2170.549\n",
      "Ep:59, loss:0.00005, loss_test:0.07564, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.814, tt:2208.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.07717, lr:9.61e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.822, tt:2246.159\n",
      "Ep:61, loss:0.00005, loss_test:0.07762, lr:9.51e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.853, tt:2284.914\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00005, loss_test:0.07647, lr:9.51e-03, fs:0.84746 (r=0.758,p=0.962),  time:36.879, tt:2323.404\n",
      "Ep:63, loss:0.00005, loss_test:0.07257, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.872, tt:2359.791\n",
      "Ep:64, loss:0.00004, loss_test:0.07740, lr:9.51e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.891, tt:2397.892\n",
      "Ep:65, loss:0.00004, loss_test:0.07317, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:36.899, tt:2435.363\n",
      "Ep:66, loss:0.00004, loss_test:0.07436, lr:9.51e-03, fs:0.86667 (r=0.788,p=0.963),  time:36.894, tt:2471.893\n",
      "Ep:67, loss:0.00004, loss_test:0.07432, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.908, tt:2509.748\n",
      "Ep:68, loss:0.00004, loss_test:0.07368, lr:9.51e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.930, tt:2548.143\n",
      "Ep:69, loss:0.00004, loss_test:0.07702, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:36.943, tt:2586.007\n",
      "Ep:70, loss:0.00004, loss_test:0.07494, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.927, tt:2621.839\n",
      "Ep:71, loss:0.00004, loss_test:0.07653, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.938, tt:2659.555\n",
      "Ep:72, loss:0.00004, loss_test:0.07379, lr:9.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.959, tt:2697.991\n",
      "Ep:73, loss:0.00004, loss_test:0.07598, lr:9.41e-03, fs:0.86034 (r=0.778,p=0.963),  time:36.976, tt:2736.258\n",
      "Ep:74, loss:0.00003, loss_test:0.07331, lr:9.32e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.991, tt:2774.289\n",
      "Ep:75, loss:0.00003, loss_test:0.07486, lr:9.23e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.018, tt:2813.353\n",
      "Ep:76, loss:0.00003, loss_test:0.07608, lr:9.14e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.053, tt:2853.063\n",
      "Ep:77, loss:0.00003, loss_test:0.07228, lr:9.04e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.081, tt:2892.302\n",
      "Ep:78, loss:0.00003, loss_test:0.07675, lr:8.95e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.104, tt:2931.189\n",
      "Ep:79, loss:0.00003, loss_test:0.07182, lr:8.86e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.126, tt:2970.088\n",
      "Ep:80, loss:0.00003, loss_test:0.07428, lr:8.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.144, tt:3008.652\n",
      "Ep:81, loss:0.00003, loss_test:0.07420, lr:8.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.148, tt:3046.149\n",
      "Ep:82, loss:0.00003, loss_test:0.07454, lr:8.60e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.159, tt:3084.222\n",
      "Ep:83, loss:0.00003, loss_test:0.07393, lr:8.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.165, tt:3121.849\n",
      "Ep:84, loss:0.00003, loss_test:0.07620, lr:8.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.161, tt:3158.728\n",
      "Ep:85, loss:0.00003, loss_test:0.07400, lr:8.35e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.178, tt:3197.289\n",
      "Ep:86, loss:0.00003, loss_test:0.07646, lr:8.26e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.192, tt:3235.717\n",
      "Ep:87, loss:0.00003, loss_test:0.07507, lr:8.18e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.212, tt:3274.626\n",
      "Ep:88, loss:0.00003, loss_test:0.07721, lr:8.10e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.217, tt:3312.354\n",
      "Ep:89, loss:0.00003, loss_test:0.07490, lr:8.02e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.218, tt:3349.630\n",
      "Ep:90, loss:0.00003, loss_test:0.07451, lr:7.94e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.236, tt:3388.452\n",
      "Ep:91, loss:0.00003, loss_test:0.07384, lr:7.86e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.234, tt:3425.563\n",
      "Ep:92, loss:0.00003, loss_test:0.07366, lr:7.78e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.249, tt:3464.167\n",
      "Ep:93, loss:0.00002, loss_test:0.07649, lr:7.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.283, tt:3504.615\n",
      "Ep:94, loss:0.00002, loss_test:0.07161, lr:7.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.287, tt:3542.233\n",
      "Ep:95, loss:0.00002, loss_test:0.07632, lr:7.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.274, tt:3578.307\n",
      "Ep:96, loss:0.00002, loss_test:0.07107, lr:7.47e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.273, tt:3615.506\n",
      "Ep:97, loss:0.00002, loss_test:0.07434, lr:7.40e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.266, tt:3652.056\n",
      "Ep:98, loss:0.00002, loss_test:0.07459, lr:7.32e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.259, tt:3688.639\n",
      "Ep:99, loss:0.00002, loss_test:0.07361, lr:7.25e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.254, tt:3725.446\n",
      "Ep:100, loss:0.00002, loss_test:0.07557, lr:7.18e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.252, tt:3762.476\n",
      "Ep:101, loss:0.00002, loss_test:0.07157, lr:7.11e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.252, tt:3799.707\n",
      "Ep:102, loss:0.00002, loss_test:0.07682, lr:7.03e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.234, tt:3835.149\n",
      "Ep:103, loss:0.00002, loss_test:0.07230, lr:6.96e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.224, tt:3871.324\n",
      "Ep:104, loss:0.00002, loss_test:0.07419, lr:6.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.227, tt:3908.784\n",
      "Ep:105, loss:0.00002, loss_test:0.07746, lr:6.83e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.229, tt:3946.297\n",
      "Ep:106, loss:0.00002, loss_test:0.07132, lr:6.76e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.238, tt:3984.424\n",
      "Ep:107, loss:0.00002, loss_test:0.07564, lr:6.69e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.226, tt:4020.461\n",
      "Ep:108, loss:0.00002, loss_test:0.07401, lr:6.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.217, tt:4056.668\n",
      "Ep:109, loss:0.00002, loss_test:0.07121, lr:6.56e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.205, tt:4092.603\n",
      "Ep:110, loss:0.00002, loss_test:0.07435, lr:6.49e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.197, tt:4128.914\n",
      "Ep:111, loss:0.00002, loss_test:0.07297, lr:6.43e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.202, tt:4166.584\n",
      "Ep:112, loss:0.00002, loss_test:0.07324, lr:6.36e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.220, tt:4205.820\n",
      "Ep:113, loss:0.00002, loss_test:0.07302, lr:6.30e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.213, tt:4242.266\n",
      "Ep:114, loss:0.00002, loss_test:0.07302, lr:6.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.197, tt:4277.620\n",
      "Ep:115, loss:0.00002, loss_test:0.07316, lr:6.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.196, tt:4314.679\n",
      "Ep:116, loss:0.00002, loss_test:0.07218, lr:6.11e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.197, tt:4352.023\n",
      "Ep:117, loss:0.00002, loss_test:0.07329, lr:6.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.197, tt:4389.303\n",
      "Ep:118, loss:0.00002, loss_test:0.07290, lr:5.99e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.208, tt:4427.784\n",
      "Ep:119, loss:0.00002, loss_test:0.07347, lr:5.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.204, tt:4464.500\n",
      "Ep:120, loss:0.00002, loss_test:0.07290, lr:5.87e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.194, tt:4500.531\n",
      "Ep:121, loss:0.00002, loss_test:0.07359, lr:5.81e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.190, tt:4537.147\n",
      "Ep:122, loss:0.00002, loss_test:0.07359, lr:5.75e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.194, tt:4574.897\n",
      "Ep:123, loss:0.00002, loss_test:0.07353, lr:5.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.199, tt:4612.715\n",
      "Ep:124, loss:0.00002, loss_test:0.07264, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.203, tt:4650.366\n",
      "Ep:125, loss:0.00002, loss_test:0.07334, lr:5.58e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.206, tt:4687.928\n",
      "Ep:126, loss:0.00002, loss_test:0.07276, lr:5.53e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.216, tt:4726.457\n",
      "Ep:127, loss:0.00002, loss_test:0.07302, lr:5.47e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.224, tt:4764.728\n",
      "Ep:128, loss:0.00002, loss_test:0.07334, lr:5.42e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.216, tt:4800.831\n",
      "Ep:129, loss:0.00002, loss_test:0.07214, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.229, tt:4839.750\n",
      "Ep:130, loss:0.00002, loss_test:0.07329, lr:5.31e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.283, tt:4884.116\n",
      "Ep:131, loss:0.00002, loss_test:0.07168, lr:5.26e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.281, tt:4921.157\n",
      "Ep:132, loss:0.00002, loss_test:0.07349, lr:5.20e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.282, tt:4958.564\n",
      "Ep:133, loss:0.00002, loss_test:0.07286, lr:5.15e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.289, tt:4996.755\n",
      "Ep:134, loss:0.00002, loss_test:0.07315, lr:5.10e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.303, tt:5035.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00002, loss_test:0.07398, lr:5.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.302, tt:5073.063\n",
      "Ep:136, loss:0.00001, loss_test:0.07236, lr:5.00e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.302, tt:5110.330\n",
      "Ep:137, loss:0.00001, loss_test:0.07377, lr:4.95e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.305, tt:5148.029\n",
      "Ep:138, loss:0.00001, loss_test:0.07199, lr:4.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.304, tt:5185.269\n",
      "Ep:139, loss:0.00001, loss_test:0.07219, lr:4.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.307, tt:5223.041\n",
      "Ep:140, loss:0.00001, loss_test:0.07272, lr:4.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.310, tt:5260.667\n",
      "Ep:141, loss:0.00001, loss_test:0.07274, lr:4.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.317, tt:5299.073\n",
      "Ep:142, loss:0.00001, loss_test:0.07315, lr:4.71e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.313, tt:5335.800\n",
      "Ep:143, loss:0.00001, loss_test:0.07260, lr:4.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.309, tt:5372.456\n",
      "Ep:144, loss:0.00001, loss_test:0.07289, lr:4.61e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.304, tt:5409.134\n",
      "Ep:145, loss:0.00001, loss_test:0.07217, lr:4.57e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.305, tt:5446.532\n",
      "Ep:146, loss:0.00001, loss_test:0.07336, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.300, tt:5483.153\n",
      "Ep:147, loss:0.00001, loss_test:0.07287, lr:4.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.292, tt:5519.192\n",
      "Ep:148, loss:0.00001, loss_test:0.07254, lr:4.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.298, tt:5557.456\n",
      "Ep:149, loss:0.00001, loss_test:0.07313, lr:4.39e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.292, tt:5593.784\n",
      "Ep:150, loss:0.00001, loss_test:0.07240, lr:4.34e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.293, tt:5631.190\n",
      "Ep:151, loss:0.00001, loss_test:0.07365, lr:4.30e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.303, tt:5670.016\n",
      "Ep:152, loss:0.00001, loss_test:0.07392, lr:4.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.321, tt:5710.159\n",
      "Ep:153, loss:0.00001, loss_test:0.07239, lr:4.21e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.361, tt:5753.624\n",
      "Ep:154, loss:0.00001, loss_test:0.07361, lr:4.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.362, tt:5791.169\n",
      "Ep:155, loss:0.00001, loss_test:0.07223, lr:4.13e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.365, tt:5828.937\n",
      "Ep:156, loss:0.00001, loss_test:0.07297, lr:4.09e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.366, tt:5866.444\n",
      "Ep:157, loss:0.00001, loss_test:0.07328, lr:4.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.363, tt:5903.331\n",
      "Ep:158, loss:0.00001, loss_test:0.07317, lr:4.01e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.358, tt:5939.890\n",
      "Ep:159, loss:0.00001, loss_test:0.07375, lr:3.97e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.354, tt:5976.597\n",
      "Ep:160, loss:0.00001, loss_test:0.07360, lr:3.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.349, tt:6013.180\n",
      "Ep:161, loss:0.00001, loss_test:0.07176, lr:3.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.343, tt:6049.519\n",
      "Ep:162, loss:0.00001, loss_test:0.07401, lr:3.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.340, tt:6086.355\n",
      "Ep:163, loss:0.00001, loss_test:0.07283, lr:3.81e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.342, tt:6124.114\n",
      "Ep:164, loss:0.00001, loss_test:0.07288, lr:3.77e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.351, tt:6162.945\n",
      "Ep:165, loss:0.00001, loss_test:0.07335, lr:3.73e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.355, tt:6200.888\n",
      "Ep:166, loss:0.00001, loss_test:0.07403, lr:3.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.357, tt:6238.603\n",
      "Ep:167, loss:0.00001, loss_test:0.07283, lr:3.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.364, tt:6277.070\n",
      "Ep:168, loss:0.00001, loss_test:0.07313, lr:3.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.369, tt:6315.434\n",
      "Ep:169, loss:0.00001, loss_test:0.07378, lr:3.59e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.374, tt:6353.547\n",
      "Ep:170, loss:0.00001, loss_test:0.07264, lr:3.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.383, tt:6392.478\n",
      "Ep:171, loss:0.00001, loss_test:0.07326, lr:3.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.385, tt:6430.245\n",
      "Ep:172, loss:0.00001, loss_test:0.07391, lr:3.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.386, tt:6467.774\n",
      "Ep:173, loss:0.00001, loss_test:0.07304, lr:3.45e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.388, tt:6505.505\n",
      "Ep:174, loss:0.00001, loss_test:0.07395, lr:3.41e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.387, tt:6542.766\n",
      "Ep:175, loss:0.00001, loss_test:0.07407, lr:3.38e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.380, tt:6578.929\n",
      "Ep:176, loss:0.00001, loss_test:0.07216, lr:3.34e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.396, tt:6619.051\n",
      "Ep:177, loss:0.00001, loss_test:0.07312, lr:3.31e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.396, tt:6656.483\n",
      "Ep:178, loss:0.00001, loss_test:0.07397, lr:3.28e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.412, tt:6696.778\n",
      "Ep:179, loss:0.00001, loss_test:0.07318, lr:3.24e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.417, tt:6735.093\n",
      "Ep:180, loss:0.00001, loss_test:0.07273, lr:3.21e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.417, tt:6772.528\n",
      "Ep:181, loss:0.00001, loss_test:0.07430, lr:3.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.424, tt:6811.175\n",
      "Ep:182, loss:0.00001, loss_test:0.07311, lr:3.15e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.426, tt:6848.929\n",
      "Ep:183, loss:0.00001, loss_test:0.07364, lr:3.12e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.423, tt:6885.873\n",
      "Ep:184, loss:0.00001, loss_test:0.07359, lr:3.09e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.428, tt:6924.234\n",
      "Ep:185, loss:0.00001, loss_test:0.07411, lr:3.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.429, tt:6961.873\n",
      "Ep:186, loss:0.00001, loss_test:0.07300, lr:3.02e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.426, tt:6998.754\n",
      "Ep:187, loss:0.00001, loss_test:0.07354, lr:2.99e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.437, tt:7038.173\n",
      "Ep:188, loss:0.00001, loss_test:0.07346, lr:2.96e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.443, tt:7076.756\n",
      "Ep:189, loss:0.00001, loss_test:0.07325, lr:2.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.450, tt:7115.501\n",
      "Ep:190, loss:0.00001, loss_test:0.07352, lr:2.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.448, tt:7152.613\n",
      "Ep:191, loss:0.00001, loss_test:0.07366, lr:2.88e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.454, tt:7191.133\n",
      "Ep:192, loss:0.00001, loss_test:0.07357, lr:2.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.457, tt:7229.291\n",
      "Ep:193, loss:0.00001, loss_test:0.07358, lr:2.82e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.463, tt:7267.803\n",
      "Ep:194, loss:0.00001, loss_test:0.07358, lr:2.79e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.472, tt:7306.955\n",
      "Ep:195, loss:0.00001, loss_test:0.07382, lr:2.76e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.481, tt:7346.363\n",
      "Ep:196, loss:0.00001, loss_test:0.07318, lr:2.73e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.487, tt:7384.908\n",
      "Ep:197, loss:0.00001, loss_test:0.07391, lr:2.71e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.490, tt:7423.117\n",
      "Ep:198, loss:0.00001, loss_test:0.07365, lr:2.68e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.496, tt:7461.636\n",
      "Ep:199, loss:0.00001, loss_test:0.07355, lr:2.65e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.508, tt:7501.604\n",
      "Ep:200, loss:0.00001, loss_test:0.07392, lr:2.63e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.518, tt:7541.105\n",
      "Ep:201, loss:0.00001, loss_test:0.07348, lr:2.60e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.522, tt:7579.368\n",
      "Ep:202, loss:0.00001, loss_test:0.07425, lr:2.57e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.515, tt:7615.635\n",
      "Ep:203, loss:0.00001, loss_test:0.07354, lr:2.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.512, tt:7652.357\n",
      "Ep:204, loss:0.00001, loss_test:0.07302, lr:2.52e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.422, tt:7671.524\n",
      "Ep:205, loss:0.00001, loss_test:0.07444, lr:2.50e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.376, tt:7699.499\n",
      "Ep:206, loss:0.00001, loss_test:0.07367, lr:2.47e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.329, tt:7727.202\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14347, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.630, tt:34.630\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14249, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.010, tt:70.020\n",
      "Ep:2, loss:0.00028, loss_test:0.14075, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.470, tt:106.409\n",
      "Ep:3, loss:0.00028, loss_test:0.13783, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.082, tt:144.328\n",
      "Ep:4, loss:0.00027, loss_test:0.13305, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:35.914, tt:179.572\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12538, lr:1.00e-02, fs:0.67883 (r=0.939,p=0.531),  time:36.064, tt:216.385\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11519, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:36.348, tt:254.437\n",
      "Ep:7, loss:0.00023, loss_test:0.11183, lr:1.00e-02, fs:0.63492 (r=0.606,p=0.667),  time:36.483, tt:291.861\n",
      "Ep:8, loss:0.00022, loss_test:0.10914, lr:1.00e-02, fs:0.67016 (r=0.646,p=0.696),  time:36.596, tt:329.367\n",
      "Ep:9, loss:0.00021, loss_test:0.10883, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:36.838, tt:368.383\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10491, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:37.005, tt:407.055\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10338, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:37.027, tt:444.328\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10065, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:36.989, tt:480.851\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09875, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:37.006, tt:518.087\n",
      "Ep:14, loss:0.00017, loss_test:0.09699, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:37.103, tt:556.551\n",
      "Ep:15, loss:0.00016, loss_test:0.09599, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:36.975, tt:591.606\n",
      "Ep:16, loss:0.00016, loss_test:0.09515, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:36.916, tt:627.573\n",
      "Ep:17, loss:0.00015, loss_test:0.09554, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:37.063, tt:667.132\n",
      "Ep:18, loss:0.00014, loss_test:0.09422, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:37.066, tt:704.247\n",
      "Ep:19, loss:0.00014, loss_test:0.09447, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:37.039, tt:740.782\n",
      "Ep:20, loss:0.00013, loss_test:0.09326, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:37.044, tt:777.926\n",
      "Ep:21, loss:0.00013, loss_test:0.09205, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:37.072, tt:815.593\n",
      "Ep:22, loss:0.00012, loss_test:0.09167, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:37.010, tt:851.220\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08954, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:36.946, tt:886.692\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08869, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:37.024, tt:925.589\n",
      "Ep:25, loss:0.00011, loss_test:0.08986, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.003, tt:962.089\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.08630, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:37.022, tt:999.597\n",
      "Ep:27, loss:0.00010, loss_test:0.08753, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.974, tt:1035.285\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.08439, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:37.052, tt:1074.505\n",
      "Ep:29, loss:0.00009, loss_test:0.08618, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:37.090, tt:1112.695\n",
      "Ep:30, loss:0.00009, loss_test:0.08340, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:37.148, tt:1151.598\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08619, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:37.358, tt:1195.470\n",
      "Ep:32, loss:0.00008, loss_test:0.08131, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:37.388, tt:1233.805\n",
      "Ep:33, loss:0.00008, loss_test:0.08537, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:37.404, tt:1271.738\n",
      "Ep:34, loss:0.00008, loss_test:0.08373, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:37.438, tt:1310.329\n",
      "Ep:35, loss:0.00008, loss_test:0.08491, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:37.380, tt:1345.684\n",
      "Ep:36, loss:0.00008, loss_test:0.08267, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:37.379, tt:1383.011\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.08766, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:37.365, tt:1419.860\n",
      "Ep:38, loss:0.00007, loss_test:0.08319, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:37.359, tt:1456.983\n",
      "Ep:39, loss:0.00007, loss_test:0.08235, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:37.380, tt:1495.185\n",
      "Ep:40, loss:0.00006, loss_test:0.08447, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:37.362, tt:1531.857\n",
      "Ep:41, loss:0.00006, loss_test:0.07928, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:37.430, tt:1572.066\n",
      "Ep:42, loss:0.00006, loss_test:0.08931, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:37.448, tt:1610.281\n",
      "Ep:43, loss:0.00006, loss_test:0.07934, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:37.459, tt:1648.192\n",
      "Ep:44, loss:0.00005, loss_test:0.08711, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:37.471, tt:1686.176\n",
      "Ep:45, loss:0.00005, loss_test:0.08238, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:37.624, tt:1730.711\n",
      "Ep:46, loss:0.00005, loss_test:0.08530, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:37.610, tt:1767.661\n",
      "Ep:47, loss:0.00005, loss_test:0.08456, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:37.614, tt:1805.488\n",
      "Ep:48, loss:0.00005, loss_test:0.08159, lr:9.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.662, tt:1845.439\n",
      "Ep:49, loss:0.00004, loss_test:0.08537, lr:9.80e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.607, tt:1880.326\n",
      "Ep:50, loss:0.00004, loss_test:0.07852, lr:9.70e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.619, tt:1918.560\n",
      "Ep:51, loss:0.00004, loss_test:0.08644, lr:9.61e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.636, tt:1957.076\n",
      "Ep:52, loss:0.00004, loss_test:0.08176, lr:9.51e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.690, tt:1997.554\n",
      "Ep:53, loss:0.00004, loss_test:0.08116, lr:9.41e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.720, tt:2036.897\n",
      "Ep:54, loss:0.00004, loss_test:0.08281, lr:9.32e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.739, tt:2075.652\n",
      "Ep:55, loss:0.00004, loss_test:0.07775, lr:9.23e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.708, tt:2111.654\n",
      "Ep:56, loss:0.00003, loss_test:0.08529, lr:9.14e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.726, tt:2150.362\n",
      "Ep:57, loss:0.00003, loss_test:0.07863, lr:9.04e-03, fs:0.80000 (r=0.707,p=0.921),  time:37.706, tt:2186.970\n",
      "Ep:58, loss:0.00003, loss_test:0.08211, lr:8.95e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.712, tt:2224.989\n",
      "Ep:59, loss:0.00003, loss_test:0.08141, lr:8.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.713, tt:2262.780\n",
      "Ep:60, loss:0.00003, loss_test:0.07990, lr:8.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.735, tt:2301.846\n",
      "Ep:61, loss:0.00003, loss_test:0.08366, lr:8.69e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.733, tt:2339.425\n",
      "Ep:62, loss:0.00003, loss_test:0.07974, lr:8.60e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.725, tt:2376.678\n",
      "Ep:63, loss:0.00003, loss_test:0.08151, lr:8.51e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.715, tt:2413.731\n",
      "Ep:64, loss:0.00003, loss_test:0.08181, lr:8.43e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.730, tt:2452.443\n",
      "Ep:65, loss:0.00003, loss_test:0.07682, lr:8.35e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.737, tt:2490.652\n",
      "Ep:66, loss:0.00003, loss_test:0.08456, lr:8.26e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.754, tt:2529.527\n",
      "Ep:67, loss:0.00003, loss_test:0.07713, lr:8.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.745, tt:2566.658\n",
      "Ep:68, loss:0.00002, loss_test:0.08092, lr:8.10e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.722, tt:2602.813\n",
      "Ep:69, loss:0.00002, loss_test:0.08067, lr:8.02e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.696, tt:2638.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00002, loss_test:0.07818, lr:7.94e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.713, tt:2677.592\n",
      "Ep:71, loss:0.00002, loss_test:0.08068, lr:7.86e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.722, tt:2716.000\n",
      "Ep:72, loss:0.00002, loss_test:0.08042, lr:7.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.735, tt:2754.619\n",
      "Ep:73, loss:0.00002, loss_test:0.07771, lr:7.70e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.752, tt:2793.618\n",
      "Ep:74, loss:0.00002, loss_test:0.07997, lr:7.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.762, tt:2832.113\n",
      "Ep:75, loss:0.00002, loss_test:0.07818, lr:7.55e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.768, tt:2870.332\n",
      "Ep:76, loss:0.00002, loss_test:0.08006, lr:7.47e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.791, tt:2909.879\n",
      "Ep:77, loss:0.00002, loss_test:0.07981, lr:7.40e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.800, tt:2948.415\n",
      "Ep:78, loss:0.00002, loss_test:0.07830, lr:7.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.806, tt:2986.657\n",
      "Ep:79, loss:0.00002, loss_test:0.08042, lr:7.25e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.829, tt:3026.305\n",
      "Ep:80, loss:0.00002, loss_test:0.07725, lr:7.18e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.846, tt:3065.504\n",
      "Ep:81, loss:0.00002, loss_test:0.07983, lr:7.11e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.860, tt:3104.501\n",
      "Ep:82, loss:0.00002, loss_test:0.07887, lr:7.03e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.881, tt:3144.100\n",
      "Ep:83, loss:0.00002, loss_test:0.07753, lr:6.96e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.871, tt:3181.140\n",
      "Ep:84, loss:0.00002, loss_test:0.07976, lr:6.89e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.868, tt:3218.739\n",
      "Ep:85, loss:0.00002, loss_test:0.07772, lr:6.83e-03, fs:0.80460 (r=0.707,p=0.933),  time:37.856, tt:3255.590\n",
      "Ep:86, loss:0.00002, loss_test:0.08003, lr:6.76e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.851, tt:3293.014\n",
      "Ep:87, loss:0.00002, loss_test:0.07830, lr:6.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.846, tt:3330.441\n",
      "Ep:88, loss:0.00002, loss_test:0.07908, lr:6.62e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.865, tt:3370.013\n",
      "Ep:89, loss:0.00001, loss_test:0.07739, lr:6.56e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.862, tt:3407.536\n",
      "Ep:90, loss:0.00001, loss_test:0.08003, lr:6.49e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.865, tt:3445.752\n",
      "Ep:91, loss:0.00001, loss_test:0.07834, lr:6.43e-03, fs:0.80925 (r=0.707,p=0.946),  time:37.866, tt:3483.635\n",
      "Ep:92, loss:0.00001, loss_test:0.07921, lr:6.36e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.830, tt:3518.194\n",
      "Ep:93, loss:0.00001, loss_test:0.08008, lr:6.30e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.823, tt:3555.362\n",
      "Ep:94, loss:0.00001, loss_test:0.07972, lr:6.24e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.826, tt:3593.449\n",
      "Ep:95, loss:0.00001, loss_test:0.07973, lr:6.17e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.819, tt:3630.668\n",
      "Ep:96, loss:0.00001, loss_test:0.07993, lr:6.11e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.822, tt:3668.779\n",
      "Ep:97, loss:0.00001, loss_test:0.07958, lr:6.05e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.825, tt:3706.826\n",
      "Ep:98, loss:0.00001, loss_test:0.07927, lr:5.99e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.830, tt:3745.205\n",
      "Ep:99, loss:0.00001, loss_test:0.08093, lr:5.93e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.839, tt:3783.859\n",
      "Ep:100, loss:0.00001, loss_test:0.07925, lr:5.87e-03, fs:0.81395 (r=0.707,p=0.959),  time:37.852, tt:3823.083\n",
      "Ep:101, loss:0.00001, loss_test:0.08074, lr:5.81e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.842, tt:3859.917\n",
      "Ep:102, loss:0.00001, loss_test:0.08095, lr:5.75e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.847, tt:3898.280\n",
      "Ep:103, loss:0.00001, loss_test:0.08026, lr:5.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.853, tt:3936.701\n",
      "Ep:104, loss:0.00001, loss_test:0.07942, lr:5.64e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.827, tt:3971.783\n",
      "Ep:105, loss:0.00001, loss_test:0.08116, lr:5.58e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.813, tt:4008.154\n",
      "Ep:106, loss:0.00001, loss_test:0.08017, lr:5.53e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.791, tt:4043.646\n",
      "Ep:107, loss:0.00001, loss_test:0.08025, lr:5.47e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.783, tt:4080.585\n",
      "Ep:108, loss:0.00001, loss_test:0.08167, lr:5.42e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.779, tt:4117.957\n",
      "Ep:109, loss:0.00001, loss_test:0.08025, lr:5.36e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.767, tt:4154.359\n",
      "Ep:110, loss:0.00001, loss_test:0.08122, lr:5.31e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.761, tt:4191.466\n",
      "Ep:111, loss:0.00001, loss_test:0.08109, lr:5.26e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.768, tt:4230.058\n",
      "Ep:112, loss:0.00001, loss_test:0.08064, lr:5.20e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.768, tt:4267.760\n",
      "Ep:113, loss:0.00001, loss_test:0.08245, lr:5.15e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.768, tt:4305.555\n",
      "Ep:114, loss:0.00001, loss_test:0.08020, lr:5.10e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.764, tt:4342.855\n",
      "Ep:115, loss:0.00001, loss_test:0.07996, lr:5.05e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.750, tt:4379.035\n",
      "Ep:116, loss:0.00001, loss_test:0.08197, lr:5.00e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.784, tt:4420.700\n",
      "Ep:117, loss:0.00001, loss_test:0.08073, lr:4.95e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.782, tt:4458.280\n",
      "Ep:118, loss:0.00001, loss_test:0.08136, lr:4.90e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.791, tt:4497.086\n",
      "Ep:119, loss:0.00001, loss_test:0.08243, lr:4.85e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.796, tt:4535.547\n",
      "Ep:120, loss:0.00001, loss_test:0.08022, lr:4.80e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.797, tt:4573.379\n",
      "Ep:121, loss:0.00001, loss_test:0.08268, lr:4.75e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.800, tt:4611.572\n",
      "Ep:122, loss:0.00001, loss_test:0.08598, lr:4.71e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.788, tt:4647.885\n",
      "Ep:123, loss:0.00001, loss_test:0.08269, lr:4.66e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.792, tt:4686.180\n",
      "Ep:124, loss:0.00001, loss_test:0.08118, lr:4.61e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.771, tt:4721.389\n",
      "Ep:125, loss:0.00001, loss_test:0.08341, lr:4.57e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.762, tt:4757.968\n",
      "Ep:126, loss:0.00001, loss_test:0.08290, lr:4.52e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.767, tt:4796.431\n",
      "Ep:127, loss:0.00001, loss_test:0.08199, lr:4.48e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.763, tt:4833.687\n",
      "Ep:128, loss:0.00001, loss_test:0.08263, lr:4.43e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.770, tt:4872.290\n",
      "Ep:129, loss:0.00001, loss_test:0.08261, lr:4.39e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.772, tt:4910.402\n",
      "Ep:130, loss:0.00001, loss_test:0.08136, lr:4.34e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.773, tt:4948.270\n",
      "Ep:131, loss:0.00001, loss_test:0.08259, lr:4.30e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.748, tt:4982.792\n",
      "Ep:132, loss:0.00001, loss_test:0.08331, lr:4.26e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.730, tt:5018.143\n",
      "Ep:133, loss:0.00001, loss_test:0.08196, lr:4.21e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.732, tt:5056.114\n",
      "Ep:134, loss:0.00001, loss_test:0.08167, lr:4.17e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.734, tt:5094.026\n",
      "Ep:135, loss:0.00001, loss_test:0.08360, lr:4.13e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.724, tt:5130.517\n",
      "Ep:136, loss:0.00001, loss_test:0.08293, lr:4.09e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.722, tt:5167.920\n",
      "Ep:137, loss:0.00001, loss_test:0.08176, lr:4.05e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.694, tt:5201.783\n",
      "Ep:138, loss:0.00001, loss_test:0.08351, lr:4.01e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.687, tt:5238.470\n",
      "Ep:139, loss:0.00001, loss_test:0.08390, lr:3.97e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.669, tt:5273.589\n",
      "Ep:140, loss:0.00001, loss_test:0.08237, lr:3.93e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.670, tt:5311.508\n",
      "Ep:141, loss:0.00001, loss_test:0.08336, lr:3.89e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.673, tt:5349.607\n",
      "Ep:142, loss:0.00001, loss_test:0.08403, lr:3.85e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.670, tt:5386.752\n",
      "Ep:143, loss:0.00001, loss_test:0.08298, lr:3.81e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.672, tt:5424.763\n",
      "Ep:144, loss:0.00001, loss_test:0.08305, lr:3.77e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.662, tt:5460.940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.08500, lr:3.73e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.661, tt:5498.525\n",
      "Ep:146, loss:0.00001, loss_test:0.08456, lr:3.70e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.650, tt:5534.505\n",
      "Ep:147, loss:0.00001, loss_test:0.08260, lr:3.66e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.656, tt:5573.136\n",
      "Ep:148, loss:0.00001, loss_test:0.08449, lr:3.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.660, tt:5611.286\n",
      "Ep:149, loss:0.00001, loss_test:0.08442, lr:3.59e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.659, tt:5648.878\n",
      "Ep:150, loss:0.00001, loss_test:0.08377, lr:3.55e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.647, tt:5684.650\n",
      "Ep:151, loss:0.00001, loss_test:0.08360, lr:3.52e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.640, tt:5721.349\n",
      "Ep:152, loss:0.00001, loss_test:0.08481, lr:3.48e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.630, tt:5757.345\n",
      "Ep:153, loss:0.00001, loss_test:0.08495, lr:3.45e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.648, tt:5797.809\n",
      "Ep:154, loss:0.00001, loss_test:0.08373, lr:3.41e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.642, tt:5834.555\n",
      "Ep:155, loss:0.00001, loss_test:0.08480, lr:3.38e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.648, tt:5873.089\n",
      "Ep:156, loss:0.00001, loss_test:0.08535, lr:3.34e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.654, tt:5911.643\n",
      "Ep:157, loss:0.00001, loss_test:0.08437, lr:3.31e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.661, tt:5950.370\n",
      "Ep:158, loss:0.00001, loss_test:0.08479, lr:3.28e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.643, tt:5985.206\n",
      "Ep:159, loss:0.00001, loss_test:0.08617, lr:3.24e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.641, tt:6022.537\n",
      "Ep:160, loss:0.00001, loss_test:0.08532, lr:3.21e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.640, tt:6060.072\n",
      "Ep:161, loss:0.00001, loss_test:0.08473, lr:3.18e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.641, tt:6097.768\n",
      "Ep:162, loss:0.00001, loss_test:0.08500, lr:3.15e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.635, tt:6134.548\n",
      "Ep:163, loss:0.00001, loss_test:0.08564, lr:3.12e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.633, tt:6171.846\n",
      "Ep:164, loss:0.00001, loss_test:0.08542, lr:3.09e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.630, tt:6208.869\n",
      "Ep:165, loss:0.00001, loss_test:0.08489, lr:3.05e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.637, tt:6247.704\n",
      "Ep:166, loss:0.00001, loss_test:0.08600, lr:3.02e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.624, tt:6283.203\n",
      "Ep:167, loss:0.00001, loss_test:0.08640, lr:2.99e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.622, tt:6320.507\n",
      "Ep:168, loss:0.00001, loss_test:0.08548, lr:2.96e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.626, tt:6358.858\n",
      "Ep:169, loss:0.00001, loss_test:0.08632, lr:2.93e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.628, tt:6396.712\n",
      "Ep:170, loss:0.00001, loss_test:0.08706, lr:2.90e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.635, tt:6435.607\n",
      "Ep:171, loss:0.00001, loss_test:0.08642, lr:2.88e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.642, tt:6474.460\n",
      "Ep:172, loss:0.00001, loss_test:0.08595, lr:2.85e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.650, tt:6513.498\n",
      "Ep:173, loss:0.00001, loss_test:0.08650, lr:2.82e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.653, tt:6551.667\n",
      "Ep:174, loss:0.00001, loss_test:0.08755, lr:2.79e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.660, tt:6590.413\n",
      "Ep:175, loss:0.00001, loss_test:0.08662, lr:2.76e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.648, tt:6626.132\n",
      "Ep:176, loss:0.00001, loss_test:0.08587, lr:2.73e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.647, tt:6663.512\n",
      "Ep:177, loss:0.00001, loss_test:0.08676, lr:2.71e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.643, tt:6700.410\n",
      "Ep:178, loss:0.00001, loss_test:0.08683, lr:2.68e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.634, tt:6736.442\n",
      "Ep:179, loss:0.00001, loss_test:0.08651, lr:2.65e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.639, tt:6774.953\n",
      "Ep:180, loss:0.00001, loss_test:0.08603, lr:2.63e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.637, tt:6812.382\n",
      "Ep:181, loss:0.00001, loss_test:0.08635, lr:2.60e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.650, tt:6852.220\n",
      "Ep:182, loss:0.00001, loss_test:0.08645, lr:2.57e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.654, tt:6890.767\n",
      "Ep:183, loss:0.00001, loss_test:0.08660, lr:2.55e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.664, tt:6930.189\n",
      "Ep:184, loss:0.00001, loss_test:0.08669, lr:2.52e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.678, tt:6970.476\n",
      "Ep:185, loss:0.00001, loss_test:0.08662, lr:2.50e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.673, tt:7007.232\n",
      "Ep:186, loss:0.00001, loss_test:0.08651, lr:2.47e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.683, tt:7046.681\n",
      "Ep:187, loss:0.00001, loss_test:0.08712, lr:2.45e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.671, tt:7082.180\n",
      "Ep:188, loss:0.00001, loss_test:0.08757, lr:2.42e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.677, tt:7120.954\n",
      "Ep:189, loss:0.00001, loss_test:0.08690, lr:2.40e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.683, tt:7159.714\n",
      "Ep:190, loss:0.00001, loss_test:0.08677, lr:2.38e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.680, tt:7196.826\n",
      "Ep:191, loss:0.00001, loss_test:0.08726, lr:2.35e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.685, tt:7235.460\n",
      "Ep:192, loss:0.00001, loss_test:0.08681, lr:2.33e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.687, tt:7273.672\n",
      "Ep:193, loss:0.00001, loss_test:0.08659, lr:2.31e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.690, tt:7311.803\n",
      "Ep:194, loss:0.00001, loss_test:0.08721, lr:2.28e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.688, tt:7349.170\n",
      "Ep:195, loss:0.00001, loss_test:0.08679, lr:2.26e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.675, tt:7384.289\n",
      "Ep:196, loss:0.00001, loss_test:0.08672, lr:2.24e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.684, tt:7423.777\n",
      "Ep:197, loss:0.00001, loss_test:0.08769, lr:2.21e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.680, tt:7460.687\n",
      "Ep:198, loss:0.00001, loss_test:0.08814, lr:2.19e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.676, tt:7497.491\n",
      "Ep:199, loss:0.00000, loss_test:0.08734, lr:2.17e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.681, tt:7536.239\n",
      "Ep:200, loss:0.00000, loss_test:0.08683, lr:2.15e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.683, tt:7574.275\n",
      "Ep:201, loss:0.00000, loss_test:0.08802, lr:2.13e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.682, tt:7611.714\n",
      "Ep:202, loss:0.00000, loss_test:0.08824, lr:2.11e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.678, tt:7648.653\n",
      "Ep:203, loss:0.00000, loss_test:0.08755, lr:2.08e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.679, tt:7686.524\n",
      "Ep:204, loss:0.00000, loss_test:0.08760, lr:2.06e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.615, tt:7711.125\n",
      "Ep:205, loss:0.00000, loss_test:0.08759, lr:2.04e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.506, tt:7726.304\n",
      "Ep:206, loss:0.00000, loss_test:0.08739, lr:2.02e-03, fs:0.82353 (r=0.707,p=0.986),  time:37.389, tt:7739.549\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.01908, lr:1.00e-02, fs:0.68333 (r=0.943,p=0.536),  time:653.331, tt:653.331\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00064, loss_test:0.01719, lr:1.00e-02, fs:0.70485 (r=0.920,p=0.571),  time:658.068, tt:1316.136\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01607, lr:1.00e-02, fs:0.76190 (r=0.920,p=0.650),  time:659.046, tt:1977.139\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01508, lr:1.00e-02, fs:0.75962 (r=0.908,p=0.653),  time:657.112, tt:2628.449\n",
      "Ep:4, loss:0.00044, loss_test:0.01411, lr:1.00e-02, fs:0.78049 (r=0.920,p=0.678),  time:659.739, tt:3298.695\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.01334, lr:1.00e-02, fs:0.82000 (r=0.943,p=0.726),  time:660.054, tt:3960.323\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00036, loss_test:0.01258, lr:1.00e-02, fs:0.84375 (r=0.931,p=0.771),  time:657.929, tt:4605.501\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.01203, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:658.370, tt:5266.958\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.01155, lr:1.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:658.624, tt:5927.618\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00027, loss_test:0.01120, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:658.892, tt:6588.920\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.01088, lr:1.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:658.570, tt:7244.274\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.01071, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:658.492, tt:7901.906\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.01059, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:657.835, tt:8551.861\n",
      "Ep:13, loss:0.00019, loss_test:0.01057, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:657.430, tt:9204.013\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.01042, lr:1.00e-02, fs:0.91429 (r=0.920,p=0.909),  time:656.847, tt:9852.699\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.01051, lr:1.00e-02, fs:0.91429 (r=0.920,p=0.909),  time:656.536, tt:10504.570\n",
      "Ep:16, loss:0.00015, loss_test:0.01069, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:656.273, tt:11156.640\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00013, loss_test:0.01077, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:656.204, tt:11811.671\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.01100, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:656.508, tt:12473.646\n",
      "Ep:19, loss:0.00012, loss_test:0.01118, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:656.801, tt:13136.028\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.01146, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:656.646, tt:13789.572\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.01159, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:656.681, tt:14446.973\n",
      "Ep:22, loss:0.00009, loss_test:0.01172, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:656.734, tt:15104.872\n",
      "Ep:23, loss:0.00009, loss_test:0.01214, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:657.503, tt:15780.078\n",
      "Ep:24, loss:0.00008, loss_test:0.01242, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:657.428, tt:16435.707\n",
      "Ep:25, loss:0.00008, loss_test:0.01263, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:657.877, tt:17104.809\n",
      "Ep:26, loss:0.00007, loss_test:0.01280, lr:1.00e-02, fs:0.94675 (r=0.920,p=0.976),  time:655.839, tt:17707.650\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00082, loss_test:0.01821, lr:1.00e-02, fs:0.70085 (r=0.943,p=0.558),  time:642.156, tt:642.156\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01670, lr:1.00e-02, fs:0.72973 (r=0.931,p=0.600),  time:646.208, tt:1292.417\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.01573, lr:1.00e-02, fs:0.74766 (r=0.920,p=0.630),  time:654.307, tt:1962.920\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.01485, lr:1.00e-02, fs:0.76777 (r=0.931,p=0.653),  time:653.719, tt:2614.875\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00042, loss_test:0.01423, lr:1.00e-02, fs:0.79227 (r=0.943,p=0.683),  time:654.583, tt:3272.914\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.01382, lr:1.00e-02, fs:0.83249 (r=0.943,p=0.745),  time:655.077, tt:3930.460\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.01334, lr:1.00e-02, fs:0.83505 (r=0.931,p=0.757),  time:655.295, tt:4587.063\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.01312, lr:1.00e-02, fs:0.83333 (r=0.920,p=0.762),  time:656.025, tt:5248.198\n",
      "Ep:8, loss:0.00029, loss_test:0.01295, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:656.927, tt:5912.342\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.01278, lr:1.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:657.629, tt:6576.291\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.01265, lr:1.00e-02, fs:0.87432 (r=0.920,p=0.833),  time:657.359, tt:7230.946\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.01256, lr:1.00e-02, fs:0.87912 (r=0.920,p=0.842),  time:657.012, tt:7884.146\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.01249, lr:1.00e-02, fs:0.87912 (r=0.920,p=0.842),  time:657.476, tt:8547.192\n",
      "Ep:13, loss:0.00019, loss_test:0.01245, lr:1.00e-02, fs:0.87432 (r=0.920,p=0.833),  time:656.712, tt:9193.966\n",
      "Ep:14, loss:0.00017, loss_test:0.01257, lr:1.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:657.292, tt:9859.386\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.01262, lr:1.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:657.453, tt:10519.242\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.01292, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:656.782, tt:11165.296\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.01311, lr:1.00e-02, fs:0.91429 (r=0.920,p=0.909),  time:656.588, tt:11818.577\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.01323, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:657.005, tt:12483.085\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.01360, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:657.200, tt:13143.998\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.01387, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:657.133, tt:13799.794\n",
      "Ep:21, loss:0.00010, loss_test:0.01409, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:657.273, tt:14459.995\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00010, loss_test:0.01455, lr:1.00e-02, fs:0.94118 (r=0.920,p=0.964),  time:657.356, tt:15119.194\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.01477, lr:1.00e-02, fs:0.93491 (r=0.908,p=0.963),  time:657.684, tt:15784.419\n",
      "Ep:24, loss:0.00009, loss_test:0.01494, lr:1.00e-02, fs:0.92857 (r=0.897,p=0.963),  time:657.541, tt:16438.523\n",
      "Ep:25, loss:0.00008, loss_test:0.01520, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:657.502, tt:17095.058\n",
      "Ep:26, loss:0.00008, loss_test:0.01551, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:657.202, tt:17744.446\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.01810, lr:1.00e-02, fs:0.67782 (r=0.931,p=0.533),  time:677.669, tt:677.669\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01691, lr:1.00e-02, fs:0.71749 (r=0.920,p=0.588),  time:675.073, tt:1350.146\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01622, lr:1.00e-02, fs:0.73488 (r=0.908,p=0.617),  time:676.015, tt:2028.044\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.01569, lr:1.00e-02, fs:0.75472 (r=0.920,p=0.640),  time:676.559, tt:2706.235\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.01522, lr:1.00e-02, fs:0.78431 (r=0.920,p=0.684),  time:677.153, tt:3385.765\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.01479, lr:1.00e-02, fs:0.77833 (r=0.908,p=0.681),  time:676.456, tt:4058.738\n",
      "Ep:6, loss:0.00042, loss_test:0.01438, lr:1.00e-02, fs:0.80612 (r=0.908,p=0.725),  time:677.660, tt:4743.621\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.01404, lr:1.00e-02, fs:0.82723 (r=0.908,p=0.760),  time:678.385, tt:5427.082\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.01372, lr:1.00e-02, fs:0.83158 (r=0.908,p=0.767),  time:676.550, tt:6088.949\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.01347, lr:1.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:676.723, tt:6767.234\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01325, lr:1.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:677.116, tt:7448.275\n",
      "Ep:11, loss:0.00031, loss_test:0.01313, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:677.729, tt:8132.751\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00029, loss_test:0.01295, lr:1.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:677.593, tt:8808.709\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.01284, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:677.221, tt:9481.094\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00026, loss_test:0.01288, lr:1.00e-02, fs:0.87432 (r=0.920,p=0.833),  time:677.768, tt:10166.522\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.01270, lr:1.00e-02, fs:0.87912 (r=0.920,p=0.842),  time:678.135, tt:10850.156\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.01269, lr:1.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:678.302, tt:11531.134\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.01270, lr:1.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:678.638, tt:12215.491\n",
      "Ep:18, loss:0.00021, loss_test:0.01272, lr:1.00e-02, fs:0.88889 (r=0.920,p=0.860),  time:678.769, tt:12896.617\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.01269, lr:1.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:678.915, tt:13578.307\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.01281, lr:1.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:679.003, tt:14259.066\n",
      "Ep:21, loss:0.00019, loss_test:0.01282, lr:1.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:678.716, tt:14931.750\n",
      "Ep:22, loss:0.00018, loss_test:0.01294, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:678.877, tt:15614.169\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.01301, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:679.207, tt:16300.959\n",
      "Ep:24, loss:0.00016, loss_test:0.01298, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:679.051, tt:16976.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00016, loss_test:0.01317, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:679.276, tt:17661.186\n",
      "Ep:26, loss:0.00015, loss_test:0.01326, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:678.878, tt:18329.709\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00081, loss_test:0.01938, lr:1.00e-02, fs:0.66667 (r=0.977,p=0.506),  time:677.738, tt:677.738\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01776, lr:1.00e-02, fs:0.71053 (r=0.931,p=0.574),  time:672.271, tt:1344.543\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00059, loss_test:0.01730, lr:1.00e-02, fs:0.71366 (r=0.931,p=0.579),  time:675.661, tt:2026.982\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00056, loss_test:0.01683, lr:1.00e-02, fs:0.71429 (r=0.920,p=0.584),  time:677.751, tt:2711.006\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00054, loss_test:0.01640, lr:1.00e-02, fs:0.72072 (r=0.920,p=0.593),  time:677.187, tt:3385.937\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00051, loss_test:0.01602, lr:1.00e-02, fs:0.74074 (r=0.920,p=0.620),  time:677.320, tt:4063.919\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00049, loss_test:0.01565, lr:1.00e-02, fs:0.75117 (r=0.920,p=0.635),  time:679.589, tt:4757.123\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00047, loss_test:0.01530, lr:1.00e-02, fs:0.76555 (r=0.920,p=0.656),  time:686.249, tt:5489.994\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00046, loss_test:0.01501, lr:1.00e-02, fs:0.79024 (r=0.931,p=0.686),  time:686.977, tt:6182.790\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.01473, lr:1.00e-02, fs:0.79412 (r=0.931,p=0.692),  time:686.415, tt:6864.148\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.01449, lr:1.00e-02, fs:0.79803 (r=0.931,p=0.698),  time:685.867, tt:7544.536\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.01427, lr:1.00e-02, fs:0.80000 (r=0.920,p=0.708),  time:685.377, tt:8224.524\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00039, loss_test:0.01405, lr:1.00e-02, fs:0.80612 (r=0.908,p=0.725),  time:686.005, tt:8918.064\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00038, loss_test:0.01388, lr:1.00e-02, fs:0.81443 (r=0.908,p=0.738),  time:685.951, tt:9603.316\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00036, loss_test:0.01370, lr:1.00e-02, fs:0.82051 (r=0.920,p=0.741),  time:686.470, tt:10297.055\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00035, loss_test:0.01359, lr:1.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:686.825, tt:10989.202\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00034, loss_test:0.01347, lr:1.00e-02, fs:0.82902 (r=0.920,p=0.755),  time:686.847, tt:11676.405\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00033, loss_test:0.01339, lr:1.00e-02, fs:0.83770 (r=0.920,p=0.769),  time:686.881, tt:12363.858\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00032, loss_test:0.01331, lr:1.00e-02, fs:0.83770 (r=0.920,p=0.769),  time:687.153, tt:13055.907\n",
      "Ep:19, loss:0.00031, loss_test:0.01326, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:687.072, tt:13741.434\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00030, loss_test:0.01321, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:686.529, tt:14417.099\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00029, loss_test:0.01319, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:686.515, tt:15103.335\n",
      "Ep:22, loss:0.00028, loss_test:0.01313, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:686.476, tt:15788.940\n",
      "Ep:23, loss:0.00027, loss_test:0.01313, lr:1.00e-02, fs:0.86022 (r=0.920,p=0.808),  time:686.162, tt:16467.887\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00026, loss_test:0.01315, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:686.157, tt:17153.928\n",
      "Ep:25, loss:0.00025, loss_test:0.01311, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:686.145, tt:17839.758\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00024, loss_test:0.01313, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:686.221, tt:18527.965\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00074, loss_test:0.01842, lr:1.00e-02, fs:0.68571 (r=0.966,p=0.532),  time:554.904, tt:554.904\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01724, lr:1.00e-02, fs:0.71111 (r=0.920,p=0.580),  time:561.127, tt:1122.254\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01658, lr:1.00e-02, fs:0.73059 (r=0.920,p=0.606),  time:558.999, tt:1676.997\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.01600, lr:1.00e-02, fs:0.74419 (r=0.920,p=0.625),  time:567.281, tt:2269.122\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.01545, lr:1.00e-02, fs:0.77295 (r=0.920,p=0.667),  time:566.522, tt:2832.611\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.01501, lr:1.00e-02, fs:0.79602 (r=0.920,p=0.702),  time:568.717, tt:3412.304\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00043, loss_test:0.01465, lr:1.00e-02, fs:0.79167 (r=0.874,p=0.724),  time:570.811, tt:3995.678\n",
      "Ep:7, loss:0.00040, loss_test:0.01435, lr:1.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:572.545, tt:4580.364\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00038, loss_test:0.01411, lr:1.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:572.910, tt:5156.192\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.01398, lr:1.00e-02, fs:0.83516 (r=0.874,p=0.800),  time:573.462, tt:5734.623\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.01385, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:573.402, tt:6307.418\n",
      "Ep:11, loss:0.00032, loss_test:0.01378, lr:1.00e-02, fs:0.84270 (r=0.862,p=0.824),  time:574.331, tt:6891.968\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.01381, lr:1.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:574.493, tt:7468.413\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.01380, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:574.910, tt:8048.746\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.01382, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:575.130, tt:8626.950\n",
      "Ep:15, loss:0.00026, loss_test:0.01384, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:575.802, tt:9212.824\n",
      "Ep:16, loss:0.00025, loss_test:0.01393, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:576.193, tt:9795.285\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.01397, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:576.758, tt:10381.636\n",
      "Ep:18, loss:0.00022, loss_test:0.01407, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:576.724, tt:10957.758\n",
      "Ep:19, loss:0.00021, loss_test:0.01419, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:576.785, tt:11535.697\n",
      "Ep:20, loss:0.00020, loss_test:0.01434, lr:1.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:576.561, tt:12107.772\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.01448, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:576.722, tt:12687.887\n",
      "Ep:22, loss:0.00019, loss_test:0.01473, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:576.812, tt:13266.687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00018, loss_test:0.01491, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:576.801, tt:13843.233\n",
      "Ep:24, loss:0.00017, loss_test:0.01504, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:576.697, tt:14417.424\n",
      "Ep:25, loss:0.00016, loss_test:0.01510, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:576.499, tt:14988.963\n",
      "Ep:26, loss:0.00016, loss_test:0.01524, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:575.788, tt:15546.269\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00106, loss_test:0.02103, lr:1.00e-02, fs:0.66949 (r=0.908,p=0.530),  time:579.023, tt:579.023\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00072, loss_test:0.01779, lr:1.00e-02, fs:0.70175 (r=0.920,p=0.567),  time:582.732, tt:1165.464\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00057, loss_test:0.01662, lr:1.00e-02, fs:0.75000 (r=0.897,p=0.645),  time:577.903, tt:1733.710\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.01609, lr:1.00e-02, fs:0.78788 (r=0.897,p=0.703),  time:579.243, tt:2316.973\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01516, lr:1.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:582.560, tt:2912.799\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00034, loss_test:0.01465, lr:1.00e-02, fs:0.82353 (r=0.885,p=0.770),  time:582.987, tt:3497.922\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00029, loss_test:0.01398, lr:1.00e-02, fs:0.85870 (r=0.908,p=0.814),  time:583.227, tt:4082.590\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.01375, lr:1.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:583.527, tt:4668.217\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.01424, lr:1.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:583.442, tt:5250.976\n",
      "Ep:9, loss:0.00018, loss_test:0.01442, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:583.784, tt:5837.835\n",
      "Ep:10, loss:0.00015, loss_test:0.01493, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:584.549, tt:6430.037\n",
      "Ep:11, loss:0.00013, loss_test:0.01614, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:585.037, tt:7020.441\n",
      "Ep:12, loss:0.00012, loss_test:0.01677, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:584.838, tt:7602.893\n",
      "Ep:13, loss:0.00010, loss_test:0.01841, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:585.113, tt:8191.577\n",
      "Ep:14, loss:0.00009, loss_test:0.01952, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:585.218, tt:8778.277\n",
      "Ep:15, loss:0.00008, loss_test:0.02063, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:585.126, tt:9362.017\n",
      "Ep:16, loss:0.00007, loss_test:0.02133, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:585.367, tt:9951.244\n",
      "Ep:17, loss:0.00006, loss_test:0.02253, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:585.323, tt:10535.822\n",
      "Ep:18, loss:0.00005, loss_test:0.02381, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:585.307, tt:11120.833\n",
      "Ep:19, loss:0.00005, loss_test:0.02440, lr:9.90e-03, fs:0.87342 (r=0.793,p=0.972),  time:585.289, tt:11705.771\n",
      "Ep:20, loss:0.00004, loss_test:0.02570, lr:9.80e-03, fs:0.87342 (r=0.793,p=0.972),  time:585.049, tt:12286.034\n",
      "Ep:21, loss:0.00004, loss_test:0.02610, lr:9.70e-03, fs:0.87342 (r=0.793,p=0.972),  time:584.973, tt:12869.405\n",
      "Ep:22, loss:0.00004, loss_test:0.02663, lr:9.61e-03, fs:0.87342 (r=0.793,p=0.972),  time:584.519, tt:13443.945\n",
      "Ep:23, loss:0.00003, loss_test:0.02759, lr:9.51e-03, fs:0.87342 (r=0.793,p=0.972),  time:581.845, tt:13964.277\n",
      "Ep:24, loss:0.00003, loss_test:0.02842, lr:9.41e-03, fs:0.87342 (r=0.793,p=0.972),  time:576.068, tt:14401.701\n",
      "Ep:25, loss:0.00003, loss_test:0.02934, lr:9.32e-03, fs:0.87342 (r=0.793,p=0.972),  time:570.901, tt:14843.422\n",
      "Ep:26, loss:0.00003, loss_test:0.02973, lr:9.23e-03, fs:0.87898 (r=0.793,p=0.986),  time:564.143, tt:15231.853\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00070, loss_test:0.01756, lr:1.00e-02, fs:0.70320 (r=0.885,p=0.583),  time:697.359, tt:697.359\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.01658, lr:1.00e-02, fs:0.73733 (r=0.920,p=0.615),  time:675.420, tt:1350.841\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.01574, lr:1.00e-02, fs:0.78261 (r=0.931,p=0.675),  time:669.604, tt:2008.813\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.01509, lr:1.00e-02, fs:0.80402 (r=0.920,p=0.714),  time:668.572, tt:2674.289\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.01452, lr:1.00e-02, fs:0.81218 (r=0.920,p=0.727),  time:666.835, tt:3334.173\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.01408, lr:1.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:664.275, tt:3985.648\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.01370, lr:1.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:663.908, tt:4647.357\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.01343, lr:1.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:661.428, tt:5291.423\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.01334, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:661.724, tt:5955.514\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.01316, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:665.181, tt:6651.811\n",
      "Ep:10, loss:0.00026, loss_test:0.01307, lr:1.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:671.467, tt:7386.137\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.01315, lr:1.00e-02, fs:0.87640 (r=0.897,p=0.857),  time:677.481, tt:8129.778\n",
      "Ep:12, loss:0.00022, loss_test:0.01325, lr:1.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:682.576, tt:8873.490\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.01327, lr:1.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:686.487, tt:9610.822\n",
      "Ep:14, loss:0.00019, loss_test:0.01339, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:689.913, tt:10348.701\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.01353, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:693.506, tt:11096.097\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.01380, lr:1.00e-02, fs:0.91429 (r=0.920,p=0.909),  time:696.061, tt:11833.037\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.01403, lr:1.00e-02, fs:0.90805 (r=0.908,p=0.908),  time:698.484, tt:12572.714\n",
      "Ep:18, loss:0.00015, loss_test:0.01420, lr:1.00e-02, fs:0.91329 (r=0.908,p=0.919),  time:700.824, tt:13315.648\n",
      "Ep:19, loss:0.00014, loss_test:0.01457, lr:1.00e-02, fs:0.91329 (r=0.908,p=0.919),  time:703.206, tt:14064.117\n",
      "Ep:20, loss:0.00013, loss_test:0.01492, lr:1.00e-02, fs:0.91765 (r=0.897,p=0.940),  time:705.139, tt:14807.927\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.01522, lr:1.00e-02, fs:0.91765 (r=0.897,p=0.940),  time:706.472, tt:15542.384\n",
      "Ep:22, loss:0.00012, loss_test:0.01547, lr:1.00e-02, fs:0.91765 (r=0.897,p=0.940),  time:707.939, tt:16282.603\n",
      "Ep:23, loss:0.00011, loss_test:0.01579, lr:1.00e-02, fs:0.91124 (r=0.885,p=0.939),  time:709.214, tt:17021.132\n",
      "Ep:24, loss:0.00010, loss_test:0.01626, lr:1.00e-02, fs:0.92121 (r=0.874,p=0.974),  time:710.352, tt:17758.804\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.01642, lr:1.00e-02, fs:0.90798 (r=0.851,p=0.974),  time:711.725, tt:18504.858\n",
      "Ep:26, loss:0.00009, loss_test:0.01694, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:713.154, tt:19255.165\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14281, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.505, tt:36.505\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14175, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.813, tt:81.626\n",
      "Ep:2, loss:0.00001, loss_test:0.13985, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:42.464, tt:127.392\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00001, loss_test:0.13666, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:43.800, tt:175.200\n",
      "Ep:4, loss:0.00001, loss_test:0.13112, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:44.410, tt:222.051\n",
      "Ep:5, loss:0.00001, loss_test:0.12217, lr:1.00e-02, fs:0.68333 (r=0.943,p=0.536),  time:44.829, tt:268.976\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.11032, lr:1.00e-02, fs:0.71698 (r=0.874,p=0.608),  time:45.159, tt:316.114\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.10549, lr:1.00e-02, fs:0.69189 (r=0.736,p=0.653),  time:45.128, tt:361.021\n",
      "Ep:8, loss:0.00001, loss_test:0.10410, lr:1.00e-02, fs:0.72251 (r=0.793,p=0.663),  time:45.716, tt:411.440\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.10325, lr:1.00e-02, fs:0.71066 (r=0.805,p=0.636),  time:45.833, tt:458.327\n",
      "Ep:10, loss:0.00001, loss_test:0.10003, lr:1.00e-02, fs:0.72251 (r=0.793,p=0.663),  time:45.989, tt:505.874\n",
      "Ep:11, loss:0.00001, loss_test:0.09788, lr:1.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:46.047, tt:552.561\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00001, loss_test:0.09539, lr:1.00e-02, fs:0.75410 (r=0.793,p=0.719),  time:46.340, tt:602.423\n",
      "Ep:13, loss:0.00001, loss_test:0.09317, lr:1.00e-02, fs:0.76757 (r=0.816,p=0.724),  time:46.460, tt:650.447\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.09112, lr:1.00e-02, fs:0.77348 (r=0.805,p=0.745),  time:46.633, tt:699.499\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00001, loss_test:0.08915, lr:1.00e-02, fs:0.80220 (r=0.839,p=0.768),  time:47.221, tt:755.541\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.08747, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:47.328, tt:804.580\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.08588, lr:1.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:47.450, tt:854.094\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.08375, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:47.476, tt:902.050\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.08176, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:47.455, tt:949.109\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.07989, lr:1.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:47.497, tt:997.444\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.07823, lr:1.00e-02, fs:0.84615 (r=0.885,p=0.811),  time:47.481, tt:1044.588\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.07733, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:47.433, tt:1090.951\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.07551, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:47.400, tt:1137.598\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00001, loss_test:0.07363, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:47.371, tt:1184.271\n",
      "Ep:25, loss:0.00001, loss_test:0.07184, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:47.237, tt:1228.171\n",
      "Ep:26, loss:0.00001, loss_test:0.07074, lr:1.00e-02, fs:0.87640 (r=0.897,p=0.857),  time:47.225, tt:1275.083\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.06897, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:47.237, tt:1322.638\n",
      "Ep:28, loss:0.00001, loss_test:0.06769, lr:1.00e-02, fs:0.88636 (r=0.897,p=0.876),  time:47.188, tt:1368.466\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00001, loss_test:0.06619, lr:1.00e-02, fs:0.87640 (r=0.897,p=0.857),  time:47.189, tt:1415.656\n",
      "Ep:30, loss:0.00000, loss_test:0.06566, lr:1.00e-02, fs:0.89266 (r=0.908,p=0.878),  time:47.202, tt:1463.259\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.06353, lr:1.00e-02, fs:0.88764 (r=0.908,p=0.868),  time:47.198, tt:1510.348\n",
      "Ep:32, loss:0.00000, loss_test:0.06313, lr:1.00e-02, fs:0.89773 (r=0.908,p=0.888),  time:47.210, tt:1557.942\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.06166, lr:1.00e-02, fs:0.89385 (r=0.920,p=0.870),  time:47.351, tt:1609.931\n",
      "Ep:34, loss:0.00000, loss_test:0.06117, lr:1.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:47.333, tt:1656.666\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00000, loss_test:0.06040, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:47.380, tt:1705.673\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00000, loss_test:0.05905, lr:1.00e-02, fs:0.89888 (r=0.920,p=0.879),  time:47.419, tt:1754.518\n",
      "Ep:37, loss:0.00000, loss_test:0.05880, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:47.438, tt:1802.637\n",
      "Ep:38, loss:0.00000, loss_test:0.05755, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:47.401, tt:1848.629\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.05771, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:47.430, tt:1897.212\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.05717, lr:1.00e-02, fs:0.91954 (r=0.920,p=0.920),  time:47.384, tt:1942.762\n",
      "Ep:41, loss:0.00000, loss_test:0.05549, lr:1.00e-02, fs:0.91954 (r=0.920,p=0.920),  time:47.376, tt:1989.773\n",
      "Ep:42, loss:0.00000, loss_test:0.05618, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:47.357, tt:2036.368\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.05434, lr:1.00e-02, fs:0.92486 (r=0.920,p=0.930),  time:47.326, tt:2082.327\n",
      "Ep:44, loss:0.00000, loss_test:0.05572, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.330, tt:2129.851\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.05441, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.367, tt:2178.893\n",
      "Ep:46, loss:0.00000, loss_test:0.05468, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.407, tt:2228.125\n",
      "Ep:47, loss:0.00000, loss_test:0.05360, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.411, tt:2275.745\n",
      "Ep:48, loss:0.00000, loss_test:0.05355, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:47.467, tt:2325.903\n",
      "Ep:49, loss:0.00000, loss_test:0.05392, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.502, tt:2375.082\n",
      "Ep:50, loss:0.00000, loss_test:0.05418, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.560, tt:2425.560\n",
      "Ep:51, loss:0.00000, loss_test:0.05545, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.615, tt:2475.965\n",
      "Ep:52, loss:0.00000, loss_test:0.05300, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.627, tt:2524.256\n",
      "Ep:53, loss:0.00000, loss_test:0.05261, lr:1.00e-02, fs:0.93023 (r=0.920,p=0.941),  time:47.638, tt:2572.440\n",
      "Ep:54, loss:0.00000, loss_test:0.05463, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.665, tt:2621.554\n",
      "Ep:55, loss:0.00000, loss_test:0.05397, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:47.675, tt:2669.804\n",
      "Ep:56, loss:0.00000, loss_test:0.05481, lr:9.90e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.711, tt:2719.511\n",
      "Ep:57, loss:0.00000, loss_test:0.05447, lr:9.80e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.717, tt:2767.614\n",
      "Ep:58, loss:0.00000, loss_test:0.05357, lr:9.70e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.749, tt:2817.190\n",
      "Ep:59, loss:0.00000, loss_test:0.05473, lr:9.61e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.726, tt:2863.576\n",
      "Ep:60, loss:0.00000, loss_test:0.05379, lr:9.51e-03, fs:0.93023 (r=0.920,p=0.941),  time:47.721, tt:2910.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00000, loss_test:0.05512, lr:9.41e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.735, tt:2959.583\n",
      "Ep:62, loss:0.00000, loss_test:0.05588, lr:9.32e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.770, tt:3009.503\n",
      "Ep:63, loss:0.00000, loss_test:0.05675, lr:9.23e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.746, tt:3055.746\n",
      "Ep:64, loss:0.00000, loss_test:0.05552, lr:9.14e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.733, tt:3102.618\n",
      "Ep:65, loss:0.00000, loss_test:0.05625, lr:9.04e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.727, tt:3150.000\n",
      "Ep:66, loss:0.00000, loss_test:0.05676, lr:8.95e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.716, tt:3196.970\n",
      "Ep:67, loss:0.00000, loss_test:0.05699, lr:8.86e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.726, tt:3245.389\n",
      "Ep:68, loss:0.00000, loss_test:0.05803, lr:8.78e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.745, tt:3294.435\n",
      "Ep:69, loss:0.00000, loss_test:0.05689, lr:8.69e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.719, tt:3340.311\n",
      "Ep:70, loss:0.00000, loss_test:0.05806, lr:8.60e-03, fs:0.92308 (r=0.897,p=0.951),  time:47.681, tt:3385.333\n",
      "Ep:71, loss:0.00000, loss_test:0.05751, lr:8.51e-03, fs:0.93567 (r=0.920,p=0.952),  time:47.685, tt:3433.336\n",
      "Ep:72, loss:0.00000, loss_test:0.05921, lr:8.43e-03, fs:0.92941 (r=0.908,p=0.952),  time:47.672, tt:3480.072\n",
      "Ep:73, loss:0.00000, loss_test:0.05802, lr:8.35e-03, fs:0.92941 (r=0.908,p=0.952),  time:47.655, tt:3526.437\n",
      "Ep:74, loss:0.00000, loss_test:0.05958, lr:8.26e-03, fs:0.85535 (r=0.782,p=0.944),  time:47.660, tt:3574.480\n",
      "Ep:75, loss:0.00000, loss_test:0.05825, lr:8.18e-03, fs:0.92941 (r=0.908,p=0.952),  time:47.654, tt:3621.734\n",
      "Ep:76, loss:0.00000, loss_test:0.05975, lr:8.10e-03, fs:0.86957 (r=0.805,p=0.946),  time:47.646, tt:3668.713\n",
      "Ep:77, loss:0.00000, loss_test:0.05959, lr:8.02e-03, fs:0.86250 (r=0.793,p=0.945),  time:47.649, tt:3716.600\n",
      "Ep:78, loss:0.00000, loss_test:0.05986, lr:7.94e-03, fs:0.86250 (r=0.793,p=0.945),  time:47.638, tt:3763.410\n",
      "Ep:79, loss:0.00000, loss_test:0.05970, lr:7.86e-03, fs:0.86792 (r=0.793,p=0.958),  time:47.664, tt:3813.096\n",
      "Ep:80, loss:0.00000, loss_test:0.06040, lr:7.78e-03, fs:0.87654 (r=0.816,p=0.947),  time:47.657, tt:3860.242\n",
      "Ep:81, loss:0.00000, loss_test:0.06001, lr:7.70e-03, fs:0.85535 (r=0.782,p=0.944),  time:47.649, tt:3907.207\n",
      "Ep:82, loss:0.00000, loss_test:0.06046, lr:7.62e-03, fs:0.85535 (r=0.782,p=0.944),  time:47.648, tt:3954.762\n",
      "Ep:83, loss:0.00000, loss_test:0.06136, lr:7.55e-03, fs:0.87342 (r=0.793,p=0.972),  time:47.659, tt:4003.397\n",
      "Ep:84, loss:0.00000, loss_test:0.06029, lr:7.47e-03, fs:0.90798 (r=0.851,p=0.974),  time:47.701, tt:4054.570\n",
      "Ep:85, loss:0.00000, loss_test:0.06167, lr:7.40e-03, fs:0.86624 (r=0.782,p=0.971),  time:47.661, tt:4098.880\n",
      "Ep:86, loss:0.00000, loss_test:0.05995, lr:7.32e-03, fs:0.85535 (r=0.782,p=0.944),  time:47.651, tt:4145.676\n",
      "Ep:87, loss:0.00000, loss_test:0.06221, lr:7.25e-03, fs:0.86624 (r=0.782,p=0.971),  time:47.644, tt:4192.635\n",
      "Ep:88, loss:0.00000, loss_test:0.06096, lr:7.18e-03, fs:0.87342 (r=0.793,p=0.972),  time:47.664, tt:4242.120\n",
      "Ep:89, loss:0.00000, loss_test:0.06188, lr:7.11e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.668, tt:4290.116\n",
      "Ep:90, loss:0.00000, loss_test:0.06076, lr:7.03e-03, fs:0.86624 (r=0.782,p=0.971),  time:47.668, tt:4337.770\n",
      "Ep:91, loss:0.00000, loss_test:0.06198, lr:6.96e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.644, tt:4383.256\n",
      "Ep:92, loss:0.00000, loss_test:0.06132, lr:6.89e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.599, tt:4426.730\n",
      "Ep:93, loss:0.00000, loss_test:0.06195, lr:6.83e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.541, tt:4468.867\n",
      "Ep:94, loss:0.00000, loss_test:0.06181, lr:6.76e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.491, tt:4511.674\n",
      "Ep:95, loss:0.00000, loss_test:0.06165, lr:6.69e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.433, tt:4553.581\n",
      "Ep:96, loss:0.00000, loss_test:0.06259, lr:6.62e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.381, tt:4595.967\n",
      "Ep:97, loss:0.00000, loss_test:0.06197, lr:6.56e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.331, tt:4638.410\n",
      "Ep:98, loss:0.00000, loss_test:0.06267, lr:6.49e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.275, tt:4680.221\n",
      "Ep:99, loss:0.00000, loss_test:0.06222, lr:6.43e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.216, tt:4721.615\n",
      "Ep:100, loss:0.00000, loss_test:0.06293, lr:6.36e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.161, tt:4763.242\n",
      "Ep:101, loss:0.00000, loss_test:0.06282, lr:6.30e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.117, tt:4805.969\n",
      "Ep:102, loss:0.00000, loss_test:0.06312, lr:6.24e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.063, tt:4847.448\n",
      "Ep:103, loss:0.00000, loss_test:0.06313, lr:6.17e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.018, tt:4889.884\n",
      "Ep:104, loss:0.00000, loss_test:0.06349, lr:6.11e-03, fs:0.87742 (r=0.782,p=1.000),  time:46.942, tt:4928.896\n",
      "Ep:105, loss:0.00000, loss_test:0.06381, lr:6.05e-03, fs:0.87742 (r=0.782,p=1.000),  time:46.813, tt:4962.227\n",
      "Ep:106, loss:0.00000, loss_test:0.06349, lr:5.99e-03, fs:0.87742 (r=0.782,p=1.000),  time:46.688, tt:4995.660\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.13928, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:42.667, tt:42.667\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.13729, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:44.504, tt:89.008\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00001, loss_test:0.13364, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:44.849, tt:134.546\n",
      "Ep:3, loss:0.00001, loss_test:0.12801, lr:1.00e-02, fs:0.65863 (r=0.943,p=0.506),  time:45.729, tt:182.916\n",
      "Ep:4, loss:0.00001, loss_test:0.11995, lr:1.00e-02, fs:0.68103 (r=0.908,p=0.545),  time:45.980, tt:229.899\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.11310, lr:1.00e-02, fs:0.67010 (r=0.747,p=0.607),  time:45.951, tt:275.703\n",
      "Ep:6, loss:0.00001, loss_test:0.11114, lr:1.00e-02, fs:0.66667 (r=0.678,p=0.656),  time:45.951, tt:321.654\n",
      "Ep:7, loss:0.00001, loss_test:0.11049, lr:1.00e-02, fs:0.69072 (r=0.770,p=0.626),  time:47.215, tt:377.723\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.10964, lr:1.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:47.215, tt:424.939\n",
      "Ep:9, loss:0.00001, loss_test:0.10791, lr:1.00e-02, fs:0.71429 (r=0.747,p=0.684),  time:47.401, tt:474.007\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.10504, lr:1.00e-02, fs:0.70213 (r=0.759,p=0.653),  time:47.383, tt:521.209\n",
      "Ep:11, loss:0.00001, loss_test:0.10299, lr:1.00e-02, fs:0.73298 (r=0.805,p=0.673),  time:47.410, tt:568.921\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00001, loss_test:0.10083, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:47.582, tt:618.571\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.09839, lr:1.00e-02, fs:0.76404 (r=0.782,p=0.747),  time:47.506, tt:665.090\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.09628, lr:1.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:47.478, tt:712.164\n",
      "Ep:15, loss:0.00001, loss_test:0.09372, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:47.498, tt:759.967\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09160, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:47.477, tt:807.101\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.08929, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:47.443, tt:853.978\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.08714, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:47.435, tt:901.273\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.08454, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:47.531, tt:950.620\n",
      "Ep:20, loss:0.00001, loss_test:0.08401, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:47.427, tt:995.972\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.08274, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:47.401, tt:1042.822\n",
      "Ep:22, loss:0.00001, loss_test:0.08218, lr:1.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:47.265, tt:1087.090\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.08068, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:47.365, tt:1136.754\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00001, loss_test:0.07990, lr:1.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:47.379, tt:1184.464\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.07907, lr:1.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:47.451, tt:1233.733\n",
      "Ep:26, loss:0.00001, loss_test:0.07851, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:47.528, tt:1283.249\n",
      "Ep:27, loss:0.00001, loss_test:0.07801, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:47.542, tt:1331.168\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.07786, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:47.525, tt:1378.225\n",
      "Ep:29, loss:0.00000, loss_test:0.07663, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:47.557, tt:1426.716\n",
      "Ep:30, loss:0.00000, loss_test:0.07593, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:47.574, tt:1474.791\n",
      "Ep:31, loss:0.00000, loss_test:0.07566, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:47.522, tt:1520.704\n",
      "Ep:32, loss:0.00000, loss_test:0.07559, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:47.563, tt:1569.594\n",
      "Ep:33, loss:0.00000, loss_test:0.07610, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:47.583, tt:1617.822\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.07484, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:47.584, tt:1665.458\n",
      "Ep:35, loss:0.00000, loss_test:0.07628, lr:1.00e-02, fs:0.86550 (r=0.851,p=0.881),  time:47.570, tt:1712.536\n",
      "Ep:36, loss:0.00000, loss_test:0.07470, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:47.553, tt:1759.479\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.07634, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:47.503, tt:1805.106\n",
      "Ep:38, loss:0.00000, loss_test:0.07617, lr:1.00e-02, fs:0.86747 (r=0.828,p=0.911),  time:47.413, tt:1849.124\n",
      "Ep:39, loss:0.00000, loss_test:0.07530, lr:1.00e-02, fs:0.88095 (r=0.851,p=0.914),  time:47.376, tt:1895.044\n",
      "Ep:40, loss:0.00000, loss_test:0.07745, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:47.381, tt:1942.607\n",
      "Ep:41, loss:0.00000, loss_test:0.07571, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:47.359, tt:1989.086\n",
      "Ep:42, loss:0.00000, loss_test:0.07738, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:47.296, tt:2033.733\n",
      "Ep:43, loss:0.00000, loss_test:0.07747, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:47.192, tt:2076.426\n",
      "Ep:44, loss:0.00000, loss_test:0.07641, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:47.121, tt:2120.456\n",
      "Ep:45, loss:0.00000, loss_test:0.07812, lr:1.00e-02, fs:0.81818 (r=0.724,p=0.940),  time:47.020, tt:2162.919\n",
      "Ep:46, loss:0.00000, loss_test:0.07831, lr:1.00e-02, fs:0.81818 (r=0.724,p=0.940),  time:46.880, tt:2203.342\n",
      "Ep:47, loss:0.00000, loss_test:0.07754, lr:1.00e-02, fs:0.81818 (r=0.724,p=0.940),  time:46.812, tt:2246.965\n",
      "Ep:48, loss:0.00000, loss_test:0.07886, lr:9.90e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.726, tt:2289.564\n",
      "Ep:49, loss:0.00000, loss_test:0.07873, lr:9.80e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.689, tt:2334.434\n",
      "Ep:50, loss:0.00000, loss_test:0.07794, lr:9.70e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.683, tt:2380.854\n",
      "Ep:51, loss:0.00000, loss_test:0.07899, lr:9.61e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.681, tt:2427.428\n",
      "Ep:52, loss:0.00000, loss_test:0.07974, lr:9.51e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.706, tt:2475.435\n",
      "Ep:53, loss:0.00000, loss_test:0.07954, lr:9.41e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.708, tt:2522.259\n",
      "Ep:54, loss:0.00000, loss_test:0.07944, lr:9.32e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.701, tt:2568.538\n",
      "Ep:55, loss:0.00000, loss_test:0.08136, lr:9.23e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.745, tt:2617.704\n",
      "Ep:56, loss:0.00000, loss_test:0.07853, lr:9.14e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.756, tt:2665.081\n",
      "Ep:57, loss:0.00000, loss_test:0.08008, lr:9.04e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.739, tt:2710.850\n",
      "Ep:58, loss:0.00000, loss_test:0.08033, lr:8.95e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.722, tt:2756.623\n",
      "Ep:59, loss:0.00000, loss_test:0.07999, lr:8.86e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.711, tt:2802.657\n",
      "Ep:60, loss:0.00000, loss_test:0.07930, lr:8.78e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.713, tt:2849.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00000, loss_test:0.07849, lr:8.69e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.711, tt:2896.051\n",
      "Ep:62, loss:0.00000, loss_test:0.08132, lr:8.60e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.712, tt:2942.878\n",
      "Ep:63, loss:0.00000, loss_test:0.07908, lr:8.51e-03, fs:0.81290 (r=0.724,p=0.926),  time:46.714, tt:2989.706\n",
      "Ep:64, loss:0.00000, loss_test:0.07877, lr:8.43e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.691, tt:3034.893\n",
      "Ep:65, loss:0.00000, loss_test:0.07970, lr:8.35e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.672, tt:3080.325\n",
      "Ep:66, loss:0.00000, loss_test:0.08130, lr:8.26e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.672, tt:3127.003\n",
      "Ep:67, loss:0.00000, loss_test:0.07974, lr:8.18e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.658, tt:3172.719\n",
      "Ep:68, loss:0.00000, loss_test:0.07974, lr:8.10e-03, fs:0.81818 (r=0.724,p=0.940),  time:46.667, tt:3220.034\n",
      "Ep:69, loss:0.00000, loss_test:0.08155, lr:8.02e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.671, tt:3266.981\n",
      "Ep:70, loss:0.00000, loss_test:0.07721, lr:7.94e-03, fs:0.81290 (r=0.724,p=0.926),  time:46.681, tt:3314.317\n",
      "Ep:71, loss:0.00000, loss_test:0.08213, lr:7.86e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.674, tt:3360.501\n",
      "Ep:72, loss:0.00000, loss_test:0.08051, lr:7.78e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.695, tt:3408.712\n",
      "Ep:73, loss:0.00000, loss_test:0.08139, lr:7.70e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.691, tt:3455.170\n",
      "Ep:74, loss:0.00000, loss_test:0.08104, lr:7.62e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.673, tt:3500.486\n",
      "Ep:75, loss:0.00000, loss_test:0.08058, lr:7.55e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.675, tt:3547.310\n",
      "Ep:76, loss:0.00000, loss_test:0.07942, lr:7.47e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.670, tt:3593.629\n",
      "Ep:77, loss:0.00000, loss_test:0.08231, lr:7.40e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.741, tt:3645.825\n",
      "Ep:78, loss:0.00000, loss_test:0.08093, lr:7.32e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.746, tt:3692.925\n",
      "Ep:79, loss:0.00000, loss_test:0.08070, lr:7.25e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.783, tt:3742.647\n",
      "Ep:80, loss:0.00000, loss_test:0.08206, lr:7.18e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.801, tt:3790.877\n",
      "Ep:81, loss:0.00000, loss_test:0.08049, lr:7.11e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.833, tt:3840.332\n",
      "Ep:82, loss:0.00000, loss_test:0.08317, lr:7.03e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.871, tt:3890.295\n",
      "Ep:83, loss:0.00000, loss_test:0.08119, lr:6.96e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.899, tt:3939.538\n",
      "Ep:84, loss:0.00000, loss_test:0.08141, lr:6.89e-03, fs:0.82353 (r=0.724,p=0.955),  time:46.929, tt:3989.005\n",
      "Ep:85, loss:0.00000, loss_test:0.08179, lr:6.83e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.940, tt:4036.805\n",
      "Ep:86, loss:0.00000, loss_test:0.08249, lr:6.76e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.931, tt:4083.011\n",
      "Ep:87, loss:0.00000, loss_test:0.08060, lr:6.69e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.954, tt:4131.992\n",
      "Ep:88, loss:0.00000, loss_test:0.08236, lr:6.62e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.970, tt:4180.302\n",
      "Ep:89, loss:0.00000, loss_test:0.08201, lr:6.56e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.977, tt:4227.917\n",
      "Ep:90, loss:0.00000, loss_test:0.08194, lr:6.49e-03, fs:0.82895 (r=0.724,p=0.969),  time:46.990, tt:4276.088\n",
      "Ep:91, loss:0.00000, loss_test:0.08230, lr:6.43e-03, fs:0.82895 (r=0.724,p=0.969),  time:47.006, tt:4324.519\n",
      "Ep:92, loss:0.00000, loss_test:0.08265, lr:6.36e-03, fs:0.82895 (r=0.724,p=0.969),  time:47.046, tt:4375.306\n",
      "Ep:93, loss:0.00000, loss_test:0.08156, lr:6.30e-03, fs:0.82895 (r=0.724,p=0.969),  time:47.067, tt:4424.294\n",
      "Ep:94, loss:0.00000, loss_test:0.08294, lr:6.24e-03, fs:0.82895 (r=0.724,p=0.969),  time:47.067, tt:4471.329\n",
      "Ep:95, loss:0.00000, loss_test:0.08140, lr:6.17e-03, fs:0.82895 (r=0.724,p=0.969),  time:47.064, tt:4518.132\n",
      "Ep:96, loss:0.00000, loss_test:0.08244, lr:6.11e-03, fs:0.82895 (r=0.724,p=0.969),  time:47.058, tt:4564.600\n",
      "Ep:97, loss:0.00000, loss_test:0.08199, lr:6.05e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.012, tt:4607.187\n",
      "Ep:98, loss:0.00000, loss_test:0.08246, lr:5.99e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.963, tt:4649.294\n",
      "Ep:99, loss:0.00000, loss_test:0.08239, lr:5.93e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.926, tt:4692.560\n",
      "Ep:100, loss:0.00000, loss_test:0.08263, lr:5.87e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.872, tt:4734.048\n",
      "Ep:101, loss:0.00000, loss_test:0.08265, lr:5.81e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.822, tt:4775.868\n",
      "Ep:102, loss:0.00000, loss_test:0.08265, lr:5.75e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.763, tt:4816.578\n",
      "Ep:103, loss:0.00000, loss_test:0.08294, lr:5.70e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.695, tt:4856.266\n",
      "Ep:104, loss:0.00000, loss_test:0.08254, lr:5.64e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.649, tt:4898.122\n",
      "Ep:105, loss:0.00000, loss_test:0.08333, lr:5.58e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.656, tt:4945.577\n",
      "Ep:106, loss:0.00000, loss_test:0.08232, lr:5.53e-03, fs:0.83444 (r=0.724,p=0.984),  time:46.640, tt:4990.524\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14471, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.459, tt:44.459\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14372, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.524, tt:89.048\n",
      "Ep:2, loss:0.00001, loss_test:0.14195, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:44.866, tt:134.599\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00001, loss_test:0.13918, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:45.156, tt:180.625\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.13482, lr:1.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:45.057, tt:225.286\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.13055, lr:1.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:45.163, tt:270.979\n",
      "Ep:6, loss:0.00001, loss_test:0.13118, lr:1.00e-02, fs:0.66063 (r=0.737,p=0.598),  time:45.028, tt:315.195\n",
      "Ep:7, loss:0.00001, loss_test:0.13071, lr:1.00e-02, fs:0.64762 (r=0.687,p=0.613),  time:45.085, tt:360.682\n",
      "Ep:8, loss:0.00001, loss_test:0.12629, lr:1.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:45.058, tt:405.525\n",
      "Ep:9, loss:0.00001, loss_test:0.12342, lr:1.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:44.978, tt:449.780\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.12179, lr:1.00e-02, fs:0.69231 (r=0.727,p=0.661),  time:44.921, tt:494.135\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00001, loss_test:0.12140, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:45.057, tt:540.688\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00001, loss_test:0.11790, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:45.080, tt:586.043\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.11743, lr:1.00e-02, fs:0.67980 (r=0.697,p=0.663),  time:45.049, tt:630.679\n",
      "Ep:14, loss:0.00001, loss_test:0.12032, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:45.027, tt:675.410\n",
      "Ep:15, loss:0.00001, loss_test:0.11883, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:45.025, tt:720.393\n",
      "Ep:16, loss:0.00001, loss_test:0.11739, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:44.936, tt:763.904\n",
      "Ep:17, loss:0.00001, loss_test:0.11932, lr:1.00e-02, fs:0.64894 (r=0.616,p=0.685),  time:44.856, tt:807.415\n",
      "Ep:18, loss:0.00001, loss_test:0.11876, lr:1.00e-02, fs:0.67021 (r=0.636,p=0.708),  time:44.701, tt:849.314\n",
      "Ep:19, loss:0.00001, loss_test:0.12011, lr:1.00e-02, fs:0.67021 (r=0.636,p=0.708),  time:44.564, tt:891.280\n",
      "Ep:20, loss:0.00001, loss_test:0.12159, lr:1.00e-02, fs:0.64088 (r=0.586,p=0.707),  time:44.547, tt:935.483\n",
      "Ep:21, loss:0.00001, loss_test:0.12120, lr:1.00e-02, fs:0.63388 (r=0.586,p=0.690),  time:44.515, tt:979.324\n",
      "Ep:22, loss:0.00001, loss_test:0.12294, lr:1.00e-02, fs:0.64088 (r=0.586,p=0.707),  time:44.590, tt:1025.559\n",
      "Ep:23, loss:0.00001, loss_test:0.12349, lr:1.00e-02, fs:0.64804 (r=0.586,p=0.725),  time:44.619, tt:1070.846\n",
      "Ep:24, loss:0.00001, loss_test:0.12615, lr:9.90e-03, fs:0.62069 (r=0.545,p=0.720),  time:44.663, tt:1116.573\n",
      "Ep:25, loss:0.00001, loss_test:0.12619, lr:9.80e-03, fs:0.62428 (r=0.545,p=0.730),  time:44.697, tt:1162.128\n",
      "Ep:26, loss:0.00001, loss_test:0.12983, lr:9.70e-03, fs:0.62428 (r=0.545,p=0.730),  time:44.770, tt:1208.791\n",
      "Ep:27, loss:0.00000, loss_test:0.12933, lr:9.61e-03, fs:0.63218 (r=0.556,p=0.733),  time:44.741, tt:1252.758\n",
      "Ep:28, loss:0.00000, loss_test:0.13075, lr:9.51e-03, fs:0.61628 (r=0.535,p=0.726),  time:44.685, tt:1295.873\n",
      "Ep:29, loss:0.00000, loss_test:0.13103, lr:9.41e-03, fs:0.62791 (r=0.545,p=0.740),  time:44.659, tt:1339.757\n",
      "Ep:30, loss:0.00000, loss_test:0.13264, lr:9.32e-03, fs:0.62353 (r=0.535,p=0.746),  time:44.654, tt:1384.280\n",
      "Ep:31, loss:0.00000, loss_test:0.13443, lr:9.23e-03, fs:0.63158 (r=0.545,p=0.750),  time:44.647, tt:1428.691\n",
      "Ep:32, loss:0.00000, loss_test:0.13588, lr:9.14e-03, fs:0.63095 (r=0.535,p=0.768),  time:44.604, tt:1471.926\n",
      "Ep:33, loss:0.00000, loss_test:0.13807, lr:9.04e-03, fs:0.62651 (r=0.525,p=0.776),  time:44.530, tt:1514.033\n",
      "Ep:34, loss:0.00000, loss_test:0.13908, lr:8.95e-03, fs:0.60870 (r=0.495,p=0.790),  time:44.524, tt:1558.353\n",
      "Ep:35, loss:0.00000, loss_test:0.14161, lr:8.86e-03, fs:0.62577 (r=0.515,p=0.797),  time:44.579, tt:1604.844\n",
      "Ep:36, loss:0.00000, loss_test:0.14207, lr:8.78e-03, fs:0.61635 (r=0.495,p=0.817),  time:44.611, tt:1650.623\n",
      "Ep:37, loss:0.00000, loss_test:0.14379, lr:8.69e-03, fs:0.62025 (r=0.495,p=0.831),  time:44.687, tt:1698.095\n",
      "Ep:38, loss:0.00000, loss_test:0.14494, lr:8.60e-03, fs:0.62025 (r=0.495,p=0.831),  time:44.652, tt:1741.446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-85bd63f7a06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m107\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00337, loss_test:0.10322, lr:4.00e-03, fs:0.75676 (r=0.848,p=0.683),  time:566.668, tt:566.668\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00243, loss_test:0.08330, lr:4.00e-03, fs:0.77249 (r=0.737,p=0.811),  time:574.188, tt:1148.376\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00183, loss_test:0.07576, lr:4.00e-03, fs:0.80628 (r=0.778,p=0.837),  time:578.616, tt:1735.849\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00135, loss_test:0.07420, lr:4.00e-03, fs:0.78613 (r=0.687,p=0.919),  time:579.265, tt:2317.062\n",
      "Ep:4, loss:0.00094, loss_test:0.07284, lr:4.00e-03, fs:0.77381 (r=0.657,p=0.942),  time:579.719, tt:2898.597\n",
      "Ep:5, loss:0.00061, loss_test:0.07695, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:582.920, tt:3497.521\n",
      "Ep:6, loss:0.00039, loss_test:0.07463, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:583.967, tt:4087.768\n",
      "Ep:7, loss:0.00026, loss_test:0.07672, lr:4.00e-03, fs:0.79268 (r=0.657,p=1.000),  time:583.827, tt:4670.620\n",
      "Ep:8, loss:0.00017, loss_test:0.08230, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:584.261, tt:5258.345\n",
      "Ep:9, loss:0.00012, loss_test:0.08617, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:584.416, tt:5844.158\n",
      "Ep:10, loss:0.00008, loss_test:0.08736, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:580.728, tt:6388.010\n",
      "Ep:11, loss:0.00006, loss_test:0.09159, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:576.452, tt:6917.418\n",
      "Ep:12, loss:0.00005, loss_test:0.09168, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:572.613, tt:7443.973\n",
      "Ep:13, loss:0.00004, loss_test:0.09213, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:569.199, tt:7968.781\n",
      "Ep:14, loss:0.00003, loss_test:0.09211, lr:3.96e-03, fs:0.74684 (r=0.596,p=1.000),  time:566.487, tt:8497.304\n",
      "Ep:15, loss:0.00003, loss_test:0.09293, lr:3.92e-03, fs:0.74684 (r=0.596,p=1.000),  time:563.546, tt:9016.737\n",
      "Ep:16, loss:0.00002, loss_test:0.09309, lr:3.88e-03, fs:0.74684 (r=0.596,p=1.000),  time:558.253, tt:9490.297\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14379, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:66.248, tt:66.248\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14201, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:75.102, tt:150.205\n",
      "Ep:2, loss:0.00054, loss_test:0.13871, lr:4.00e-03, fs:0.67119 (r=1.000,p=0.505),  time:77.950, tt:233.851\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.13280, lr:4.00e-03, fs:0.66434 (r=0.960,p=0.508),  time:79.721, tt:318.885\n",
      "Ep:4, loss:0.00049, loss_test:0.12477, lr:4.00e-03, fs:0.66932 (r=0.848,p=0.553),  time:80.846, tt:404.228\n",
      "Ep:5, loss:0.00046, loss_test:0.12033, lr:4.00e-03, fs:0.66038 (r=0.707,p=0.619),  time:81.171, tt:487.027\n",
      "Ep:6, loss:0.00044, loss_test:0.11566, lr:4.00e-03, fs:0.67299 (r=0.717,p=0.634),  time:82.237, tt:575.662\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.11103, lr:4.00e-03, fs:0.73451 (r=0.838,p=0.654),  time:82.376, tt:659.006\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00040, loss_test:0.10671, lr:4.00e-03, fs:0.75455 (r=0.838,p=0.686),  time:82.622, tt:743.601\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00038, loss_test:0.10456, lr:4.00e-03, fs:0.74641 (r=0.788,p=0.709),  time:82.669, tt:826.685\n",
      "Ep:10, loss:0.00036, loss_test:0.10143, lr:4.00e-03, fs:0.76056 (r=0.818,p=0.711),  time:82.807, tt:910.876\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00035, loss_test:0.09902, lr:4.00e-03, fs:0.76329 (r=0.798,p=0.731),  time:82.812, tt:993.739\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00033, loss_test:0.09735, lr:4.00e-03, fs:0.76923 (r=0.758,p=0.781),  time:82.936, tt:1078.165\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.09482, lr:4.00e-03, fs:0.78261 (r=0.818,p=0.750),  time:83.241, tt:1165.374\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00031, loss_test:0.09335, lr:4.00e-03, fs:0.78173 (r=0.778,p=0.786),  time:83.160, tt:1247.402\n",
      "Ep:15, loss:0.00029, loss_test:0.09206, lr:4.00e-03, fs:0.78756 (r=0.768,p=0.809),  time:83.173, tt:1330.764\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.09059, lr:4.00e-03, fs:0.78351 (r=0.768,p=0.800),  time:83.169, tt:1413.876\n",
      "Ep:17, loss:0.00027, loss_test:0.08977, lr:4.00e-03, fs:0.79787 (r=0.758,p=0.843),  time:82.709, tt:1488.754\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.08840, lr:4.00e-03, fs:0.80829 (r=0.788,p=0.830),  time:82.428, tt:1566.141\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.08771, lr:4.00e-03, fs:0.81250 (r=0.788,p=0.839),  time:82.422, tt:1648.447\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.08762, lr:4.00e-03, fs:0.80851 (r=0.768,p=0.854),  time:82.670, tt:1736.073\n",
      "Ep:21, loss:0.00023, loss_test:0.08619, lr:4.00e-03, fs:0.81481 (r=0.778,p=0.856),  time:82.866, tt:1823.045\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.08578, lr:4.00e-03, fs:0.81319 (r=0.747,p=0.892),  time:82.937, tt:1907.554\n",
      "Ep:23, loss:0.00021, loss_test:0.08630, lr:4.00e-03, fs:0.79570 (r=0.747,p=0.851),  time:82.976, tt:1991.413\n",
      "Ep:24, loss:0.00020, loss_test:0.08466, lr:4.00e-03, fs:0.81768 (r=0.747,p=0.902),  time:82.964, tt:2074.104\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.08400, lr:4.00e-03, fs:0.80220 (r=0.737,p=0.880),  time:83.059, tt:2159.532\n",
      "Ep:26, loss:0.00019, loss_test:0.08379, lr:4.00e-03, fs:0.80447 (r=0.727,p=0.900),  time:82.997, tt:2240.910\n",
      "Ep:27, loss:0.00018, loss_test:0.08235, lr:4.00e-03, fs:0.80682 (r=0.717,p=0.922),  time:82.798, tt:2318.353\n",
      "Ep:28, loss:0.00017, loss_test:0.08488, lr:4.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:82.893, tt:2403.901\n",
      "Ep:29, loss:0.00016, loss_test:0.08103, lr:4.00e-03, fs:0.81356 (r=0.727,p=0.923),  time:82.929, tt:2487.866\n",
      "Ep:30, loss:0.00015, loss_test:0.08356, lr:4.00e-03, fs:0.77647 (r=0.667,p=0.930),  time:83.054, tt:2574.661\n",
      "Ep:31, loss:0.00015, loss_test:0.08286, lr:4.00e-03, fs:0.78363 (r=0.677,p=0.931),  time:83.142, tt:2660.556\n",
      "Ep:32, loss:0.00014, loss_test:0.08267, lr:4.00e-03, fs:0.79769 (r=0.697,p=0.932),  time:83.217, tt:2746.150\n",
      "Ep:33, loss:0.00013, loss_test:0.08280, lr:4.00e-03, fs:0.79769 (r=0.697,p=0.932),  time:83.225, tt:2829.653\n",
      "Ep:34, loss:0.00013, loss_test:0.08410, lr:4.00e-03, fs:0.79070 (r=0.687,p=0.932),  time:83.251, tt:2913.774\n",
      "Ep:35, loss:0.00012, loss_test:0.08168, lr:4.00e-03, fs:0.80460 (r=0.707,p=0.933),  time:83.260, tt:2997.353\n",
      "Ep:36, loss:0.00011, loss_test:0.08286, lr:3.96e-03, fs:0.79769 (r=0.697,p=0.932),  time:83.258, tt:3080.529\n",
      "Ep:37, loss:0.00011, loss_test:0.08554, lr:3.92e-03, fs:0.79070 (r=0.687,p=0.932),  time:83.275, tt:3164.453\n",
      "Ep:38, loss:0.00010, loss_test:0.08234, lr:3.88e-03, fs:0.80460 (r=0.707,p=0.933),  time:83.252, tt:3246.832\n",
      "Ep:39, loss:0.00010, loss_test:0.08629, lr:3.84e-03, fs:0.79532 (r=0.687,p=0.944),  time:83.277, tt:3331.088\n",
      "Ep:40, loss:0.00009, loss_test:0.08291, lr:3.80e-03, fs:0.81143 (r=0.717,p=0.934),  time:83.306, tt:3415.538\n",
      "Ep:41, loss:0.00009, loss_test:0.08460, lr:3.77e-03, fs:0.81609 (r=0.717,p=0.947),  time:83.311, tt:3499.078\n",
      "Ep:42, loss:0.00008, loss_test:0.08728, lr:3.73e-03, fs:0.80925 (r=0.707,p=0.946),  time:83.380, tt:3585.349\n",
      "Ep:43, loss:0.00008, loss_test:0.08695, lr:3.69e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.386, tt:3668.976\n",
      "Ep:44, loss:0.00008, loss_test:0.08690, lr:3.65e-03, fs:0.81395 (r=0.707,p=0.959),  time:83.411, tt:3753.487\n",
      "Ep:45, loss:0.00007, loss_test:0.08561, lr:3.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:83.405, tt:3836.631\n",
      "Ep:46, loss:0.00007, loss_test:0.08920, lr:3.58e-03, fs:0.81395 (r=0.707,p=0.959),  time:83.387, tt:3919.190\n",
      "Ep:47, loss:0.00007, loss_test:0.09124, lr:3.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.403, tt:4003.341\n",
      "Ep:48, loss:0.00006, loss_test:0.09077, lr:3.51e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.467, tt:4089.875\n",
      "Ep:49, loss:0.00006, loss_test:0.08930, lr:3.47e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.482, tt:4174.080\n",
      "Ep:50, loss:0.00006, loss_test:0.09198, lr:3.44e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.507, tt:4258.848\n",
      "Ep:51, loss:0.00005, loss_test:0.09191, lr:3.41e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.540, tt:4344.071\n",
      "Ep:52, loss:0.00005, loss_test:0.09198, lr:3.37e-03, fs:0.81395 (r=0.707,p=0.959),  time:83.506, tt:4425.836\n",
      "Ep:53, loss:0.00005, loss_test:0.09374, lr:3.34e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.482, tt:4508.042\n",
      "Ep:54, loss:0.00005, loss_test:0.09689, lr:3.30e-03, fs:0.79290 (r=0.677,p=0.957),  time:83.378, tt:4585.813\n",
      "Ep:55, loss:0.00004, loss_test:0.09392, lr:3.27e-03, fs:0.80702 (r=0.697,p=0.958),  time:83.142, tt:4655.953\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"7-7\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00397, loss_test:0.09368, lr:4.00e-03, fs:0.72277 (r=0.737,p=0.709),  time:738.415, tt:738.415\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00270, loss_test:0.07426, lr:4.00e-03, fs:0.85572 (r=0.869,p=0.843),  time:748.576, tt:1497.152\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00199, loss_test:0.06267, lr:4.00e-03, fs:0.88442 (r=0.889,p=0.880),  time:752.441, tt:2257.322\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00145, loss_test:0.05665, lr:4.00e-03, fs:0.93333 (r=0.919,p=0.948),  time:753.543, tt:3014.170\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00104, loss_test:0.05206, lr:4.00e-03, fs:0.93333 (r=0.919,p=0.948),  time:753.089, tt:3765.444\n",
      "Ep:5, loss:0.00074, loss_test:0.05380, lr:4.00e-03, fs:0.94301 (r=0.919,p=0.968),  time:751.139, tt:4506.832\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00053, loss_test:0.05476, lr:4.00e-03, fs:0.94792 (r=0.919,p=0.978),  time:749.027, tt:5243.190\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.05752, lr:4.00e-03, fs:0.95288 (r=0.919,p=0.989),  time:746.832, tt:5974.657\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.06015, lr:4.00e-03, fs:0.95288 (r=0.919,p=0.989),  time:745.340, tt:6708.057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d5eca4375e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"7-7\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00386, loss_test:0.08614, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:740.911, tt:740.911\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00213, loss_test:0.06343, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:746.078, tt:1492.156\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00116, loss_test:0.05643, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:744.345, tt:2233.035\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00054, loss_test:0.06169, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:746.955, tt:2987.818\n",
      "Ep:4, loss:0.00028, loss_test:0.06319, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:746.606, tt:3733.029\n",
      "Ep:5, loss:0.00012, loss_test:0.07015, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:746.659, tt:4479.953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4074ca2cd505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"7-7\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00381, loss_test:0.08453, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:703.204, tt:703.204\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00206, loss_test:0.06562, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:727.592, tt:1455.185\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00105, loss_test:0.06469, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:738.132, tt:2214.395\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.06709, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:745.103, tt:2980.411\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.07531, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:748.397, tt:3741.987\n",
      "Ep:5, loss:0.00013, loss_test:0.07678, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:748.949, tt:4493.695\n",
      "Ep:6, loss:0.00007, loss_test:0.07892, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:747.225, tt:5230.578\n",
      "Ep:7, loss:0.00004, loss_test:0.07867, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:746.543, tt:5972.341\n",
      "Ep:8, loss:0.00003, loss_test:0.08095, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:745.469, tt:6709.217\n",
      "Ep:9, loss:0.00002, loss_test:0.07747, lr:1.00e-02, fs:0.91803 (r=0.848,p=1.000),  time:745.216, tt:7452.155\n",
      "Ep:10, loss:0.00002, loss_test:0.07805, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:744.256, tt:8186.818\n",
      "Ep:11, loss:0.00001, loss_test:0.07865, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:744.510, tt:8934.116\n",
      "Ep:12, loss:0.00001, loss_test:0.07953, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:745.960, tt:9697.479\n",
      "Ep:13, loss:0.00001, loss_test:0.07818, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:746.266, tt:10447.728\n",
      "Ep:14, loss:0.00001, loss_test:0.07767, lr:1.00e-02, fs:0.88764 (r=0.798,p=1.000),  time:747.041, tt:11205.615\n",
      "Ep:15, loss:0.00001, loss_test:0.07791, lr:9.90e-03, fs:0.88764 (r=0.798,p=1.000),  time:748.114, tt:11969.824\n",
      "Ep:16, loss:0.00001, loss_test:0.07693, lr:9.80e-03, fs:0.88764 (r=0.798,p=1.000),  time:749.007, tt:12733.114\n",
      "Ep:17, loss:0.00001, loss_test:0.07725, lr:9.70e-03, fs:0.88764 (r=0.798,p=1.000),  time:749.828, tt:13496.907\n",
      "Ep:18, loss:0.00001, loss_test:0.07642, lr:9.61e-03, fs:0.88764 (r=0.798,p=1.000),  time:750.469, tt:14258.918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14630, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.250, tt:16.250\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14612, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.959, tt:33.917\n",
      "Ep:2, loss:0.00004, loss_test:0.14585, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.428, tt:52.284\n",
      "Ep:3, loss:0.00004, loss_test:0.14547, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.964, tt:71.855\n",
      "Ep:4, loss:0.00004, loss_test:0.14497, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.221, tt:91.106\n",
      "Ep:5, loss:0.00004, loss_test:0.14433, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.409, tt:110.453\n",
      "Ep:6, loss:0.00004, loss_test:0.14354, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.406, tt:128.844\n",
      "Ep:7, loss:0.00004, loss_test:0.14254, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:18.515, tt:148.121\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.14133, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:18.542, tt:166.876\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.13984, lr:1.00e-02, fs:0.63860 (r=0.919,p=0.489),  time:18.646, tt:186.459\n",
      "Ep:10, loss:0.00004, loss_test:0.13803, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:18.803, tt:206.828\n",
      "Ep:11, loss:0.00004, loss_test:0.13609, lr:1.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:18.800, tt:225.596\n",
      "Ep:12, loss:0.00004, loss_test:0.13384, lr:1.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:18.899, tt:245.683\n",
      "Ep:13, loss:0.00003, loss_test:0.13119, lr:1.00e-02, fs:0.62762 (r=0.758,p=0.536),  time:18.992, tt:265.890\n",
      "Ep:14, loss:0.00003, loss_test:0.12882, lr:1.00e-02, fs:0.63594 (r=0.697,p=0.585),  time:19.030, tt:285.446\n",
      "Ep:15, loss:0.00003, loss_test:0.12788, lr:1.00e-02, fs:0.63000 (r=0.636,p=0.624),  time:19.087, tt:305.386\n",
      "Ep:16, loss:0.00003, loss_test:0.12640, lr:1.00e-02, fs:0.64583 (r=0.626,p=0.667),  time:19.200, tt:326.397\n",
      "Ep:17, loss:0.00003, loss_test:0.12358, lr:1.00e-02, fs:0.63212 (r=0.616,p=0.649),  time:19.201, tt:345.621\n",
      "Ep:18, loss:0.00003, loss_test:0.12049, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:19.270, tt:366.136\n",
      "Ep:19, loss:0.00003, loss_test:0.11904, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:19.341, tt:386.828\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.11757, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:19.380, tt:406.980\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.11478, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:19.351, tt:425.728\n",
      "Ep:22, loss:0.00003, loss_test:0.11236, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:19.328, tt:444.535\n",
      "Ep:23, loss:0.00003, loss_test:0.11134, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:19.373, tt:464.954\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.11067, lr:1.00e-02, fs:0.67021 (r=0.636,p=0.708),  time:19.390, tt:484.756\n",
      "Ep:25, loss:0.00003, loss_test:0.10988, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:19.354, tt:503.212\n",
      "Ep:26, loss:0.00003, loss_test:0.10885, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:19.367, tt:522.921\n",
      "Ep:27, loss:0.00003, loss_test:0.10761, lr:1.00e-02, fs:0.69744 (r=0.687,p=0.708),  time:19.362, tt:542.149\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.10595, lr:1.00e-02, fs:0.68718 (r=0.677,p=0.698),  time:19.358, tt:561.373\n",
      "Ep:29, loss:0.00003, loss_test:0.10426, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:19.395, tt:581.841\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.10331, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:19.410, tt:601.714\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.10281, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:19.399, tt:620.763\n",
      "Ep:32, loss:0.00002, loss_test:0.10255, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:19.405, tt:640.362\n",
      "Ep:33, loss:0.00002, loss_test:0.10210, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:19.399, tt:659.569\n",
      "Ep:34, loss:0.00002, loss_test:0.10144, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:19.426, tt:679.913\n",
      "Ep:35, loss:0.00002, loss_test:0.10053, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:19.409, tt:698.724\n",
      "Ep:36, loss:0.00002, loss_test:0.09966, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:19.365, tt:716.508\n",
      "Ep:37, loss:0.00002, loss_test:0.09861, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:19.382, tt:736.515\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.09752, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:19.415, tt:757.194\n",
      "Ep:39, loss:0.00002, loss_test:0.09667, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:19.398, tt:775.938\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.09610, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:19.358, tt:793.680\n",
      "Ep:41, loss:0.00002, loss_test:0.09573, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:19.335, tt:812.088\n",
      "Ep:42, loss:0.00002, loss_test:0.09522, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:19.320, tt:830.756\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.09434, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:19.334, tt:850.689\n",
      "Ep:44, loss:0.00002, loss_test:0.09362, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:19.348, tt:870.666\n",
      "Ep:45, loss:0.00002, loss_test:0.09302, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:19.335, tt:889.429\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.09270, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:19.326, tt:908.304\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.09279, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:19.335, tt:928.084\n",
      "Ep:48, loss:0.00002, loss_test:0.09316, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:19.346, tt:947.935\n",
      "Ep:49, loss:0.00002, loss_test:0.09234, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:19.356, tt:967.779\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.09150, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:19.370, tt:987.846\n",
      "Ep:51, loss:0.00002, loss_test:0.09154, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:19.360, tt:1006.717\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.09140, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:19.362, tt:1026.194\n",
      "Ep:53, loss:0.00002, loss_test:0.09017, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:19.333, tt:1043.968\n",
      "Ep:54, loss:0.00002, loss_test:0.09069, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:19.327, tt:1062.969\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.09018, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:19.318, tt:1081.804\n",
      "Ep:56, loss:0.00001, loss_test:0.08937, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:19.336, tt:1102.131\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.08996, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:19.350, tt:1122.286\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.09066, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:19.325, tt:1140.183\n",
      "Ep:59, loss:0.00001, loss_test:0.08930, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:19.327, tt:1159.646\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.09021, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:19.346, tt:1180.113\n",
      "Ep:61, loss:0.00001, loss_test:0.08920, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:19.345, tt:1199.417\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.08949, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:19.365, tt:1219.986\n",
      "Ep:63, loss:0.00001, loss_test:0.08856, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:19.366, tt:1239.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.09046, lr:1.00e-02, fs:0.75281 (r=0.677,p=0.848),  time:19.392, tt:1260.476\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.08764, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:19.388, tt:1279.579\n",
      "Ep:66, loss:0.00001, loss_test:0.09120, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:19.387, tt:1298.922\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.08830, lr:1.00e-02, fs:0.74860 (r=0.677,p=0.838),  time:19.406, tt:1319.600\n",
      "Ep:68, loss:0.00001, loss_test:0.08560, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:19.402, tt:1338.704\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09355, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:19.478, tt:1363.491\n",
      "Ep:70, loss:0.00001, loss_test:0.09186, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:19.494, tt:1384.101\n",
      "Ep:71, loss:0.00001, loss_test:0.08466, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:19.515, tt:1405.056\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.08878, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:19.543, tt:1426.661\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.09187, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:19.567, tt:1447.924\n",
      "Ep:74, loss:0.00001, loss_test:0.08607, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:19.571, tt:1467.796\n",
      "Ep:75, loss:0.00001, loss_test:0.08428, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:19.586, tt:1488.520\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.09129, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:19.605, tt:1509.555\n",
      "Ep:77, loss:0.00001, loss_test:0.08798, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:19.618, tt:1530.177\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.08231, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:19.621, tt:1550.076\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.09189, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:19.630, tt:1570.434\n",
      "Ep:80, loss:0.00001, loss_test:0.08849, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:19.647, tt:1591.369\n",
      "Ep:81, loss:0.00001, loss_test:0.08054, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:19.663, tt:1612.373\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.08875, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:19.680, tt:1633.446\n",
      "Ep:83, loss:0.00001, loss_test:0.08962, lr:1.00e-02, fs:0.75449 (r=0.636,p=0.926),  time:19.696, tt:1654.474\n",
      "Ep:84, loss:0.00001, loss_test:0.08079, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:19.697, tt:1674.264\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.08233, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:19.685, tt:1692.896\n",
      "Ep:86, loss:0.00001, loss_test:0.08825, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:19.686, tt:1712.640\n",
      "Ep:87, loss:0.00001, loss_test:0.08348, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:19.698, tt:1733.392\n",
      "Ep:88, loss:0.00001, loss_test:0.08045, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:19.717, tt:1754.832\n",
      "Ep:89, loss:0.00001, loss_test:0.08645, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:19.755, tt:1777.990\n",
      "Ep:90, loss:0.00001, loss_test:0.08546, lr:1.00e-02, fs:0.76023 (r=0.657,p=0.903),  time:19.780, tt:1800.018\n",
      "Ep:91, loss:0.00001, loss_test:0.07912, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:19.785, tt:1820.262\n",
      "Ep:92, loss:0.00001, loss_test:0.08562, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:19.794, tt:1840.817\n",
      "Ep:93, loss:0.00001, loss_test:0.08508, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:19.787, tt:1859.983\n",
      "Ep:94, loss:0.00001, loss_test:0.07860, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:19.783, tt:1879.339\n",
      "Ep:95, loss:0.00001, loss_test:0.08234, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:19.794, tt:1900.262\n",
      "Ep:96, loss:0.00001, loss_test:0.08380, lr:9.90e-03, fs:0.74419 (r=0.646,p=0.877),  time:19.803, tt:1920.926\n",
      "Ep:97, loss:0.00001, loss_test:0.07953, lr:9.80e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.815, tt:1941.861\n",
      "Ep:98, loss:0.00001, loss_test:0.07864, lr:9.70e-03, fs:0.79775 (r=0.717,p=0.899),  time:19.795, tt:1959.681\n",
      "Ep:99, loss:0.00001, loss_test:0.08327, lr:9.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.805, tt:1980.500\n",
      "Ep:100, loss:0.00001, loss_test:0.07956, lr:9.51e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.807, tt:2000.502\n",
      "Ep:101, loss:0.00001, loss_test:0.07816, lr:9.41e-03, fs:0.80899 (r=0.727,p=0.911),  time:19.809, tt:2020.478\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.08068, lr:9.41e-03, fs:0.77907 (r=0.677,p=0.918),  time:19.817, tt:2041.173\n",
      "Ep:103, loss:0.00001, loss_test:0.07943, lr:9.41e-03, fs:0.78161 (r=0.687,p=0.907),  time:19.817, tt:2061.011\n",
      "Ep:104, loss:0.00001, loss_test:0.07779, lr:9.41e-03, fs:0.80226 (r=0.717,p=0.910),  time:19.820, tt:2081.105\n",
      "Ep:105, loss:0.00001, loss_test:0.08082, lr:9.41e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.833, tt:2102.260\n",
      "Ep:106, loss:0.00001, loss_test:0.07959, lr:9.41e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.831, tt:2121.888\n",
      "Ep:107, loss:0.00001, loss_test:0.07769, lr:9.41e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.844, tt:2143.152\n",
      "Ep:108, loss:0.00001, loss_test:0.08012, lr:9.41e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.839, tt:2162.425\n",
      "Ep:109, loss:0.00001, loss_test:0.07773, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.839, tt:2182.320\n",
      "Ep:110, loss:0.00001, loss_test:0.07979, lr:9.41e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.832, tt:2201.383\n",
      "Ep:111, loss:0.00001, loss_test:0.07744, lr:9.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:19.823, tt:2220.126\n",
      "Ep:112, loss:0.00001, loss_test:0.08068, lr:9.41e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.809, tt:2238.377\n",
      "Ep:113, loss:0.00001, loss_test:0.07675, lr:9.32e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.797, tt:2256.819\n",
      "Ep:114, loss:0.00000, loss_test:0.07710, lr:9.23e-03, fs:0.77714 (r=0.687,p=0.895),  time:19.792, tt:2276.126\n",
      "Ep:115, loss:0.00000, loss_test:0.07961, lr:9.14e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.827, tt:2299.913\n",
      "Ep:116, loss:0.00000, loss_test:0.07898, lr:9.04e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.807, tt:2317.458\n",
      "Ep:117, loss:0.00000, loss_test:0.07627, lr:8.95e-03, fs:0.77907 (r=0.677,p=0.918),  time:19.805, tt:2336.969\n",
      "Ep:118, loss:0.00000, loss_test:0.07693, lr:8.86e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.795, tt:2355.560\n",
      "Ep:119, loss:0.00000, loss_test:0.07522, lr:8.78e-03, fs:0.80460 (r=0.707,p=0.933),  time:19.783, tt:2373.975\n",
      "Ep:120, loss:0.00000, loss_test:0.08370, lr:8.69e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.789, tt:2394.474\n",
      "Ep:121, loss:0.00000, loss_test:0.07841, lr:8.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.787, tt:2413.969\n",
      "Ep:122, loss:0.00000, loss_test:0.07128, lr:8.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.789, tt:2434.023\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.08825, lr:8.51e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.784, tt:2453.195\n",
      "Ep:124, loss:0.00000, loss_test:0.08998, lr:8.51e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.781, tt:2472.598\n",
      "Ep:125, loss:0.00000, loss_test:0.07670, lr:8.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:19.767, tt:2490.692\n",
      "Ep:126, loss:0.00000, loss_test:0.06984, lr:8.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:19.761, tt:2509.675\n",
      "Ep:127, loss:0.00001, loss_test:0.08824, lr:8.51e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.758, tt:2529.052\n",
      "Ep:128, loss:0.00000, loss_test:0.09827, lr:8.51e-03, fs:0.72393 (r=0.596,p=0.922),  time:19.749, tt:2547.671\n",
      "Ep:129, loss:0.00001, loss_test:0.08892, lr:8.51e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.754, tt:2567.982\n",
      "Ep:130, loss:0.00000, loss_test:0.07140, lr:8.51e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.758, tt:2588.320\n",
      "Ep:131, loss:0.00000, loss_test:0.07284, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:19.744, tt:2606.152\n",
      "Ep:132, loss:0.00000, loss_test:0.08615, lr:8.51e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.745, tt:2626.118\n",
      "Ep:133, loss:0.00000, loss_test:0.09275, lr:8.51e-03, fs:0.77019 (r=0.626,p=1.000),  time:19.737, tt:2644.741\n",
      "Ep:134, loss:0.00000, loss_test:0.08220, lr:8.43e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.731, tt:2663.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.07177, lr:8.35e-03, fs:0.79775 (r=0.717,p=0.899),  time:19.732, tt:2683.522\n",
      "Ep:136, loss:0.00000, loss_test:0.07443, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.734, tt:2703.543\n",
      "Ep:137, loss:0.00000, loss_test:0.08122, lr:8.18e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.723, tt:2721.794\n",
      "Ep:138, loss:0.00000, loss_test:0.08294, lr:8.10e-03, fs:0.76543 (r=0.626,p=0.984),  time:19.721, tt:2741.193\n",
      "Ep:139, loss:0.00000, loss_test:0.07696, lr:8.02e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.714, tt:2759.937\n",
      "Ep:140, loss:0.00000, loss_test:0.07219, lr:7.94e-03, fs:0.80226 (r=0.717,p=0.910),  time:19.708, tt:2778.849\n",
      "Ep:141, loss:0.00000, loss_test:0.07442, lr:7.86e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.708, tt:2798.600\n",
      "Ep:142, loss:0.00000, loss_test:0.07871, lr:7.78e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.716, tt:2819.439\n",
      "Ep:143, loss:0.00000, loss_test:0.07852, lr:7.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.716, tt:2839.070\n",
      "Ep:144, loss:0.00000, loss_test:0.07472, lr:7.62e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.711, tt:2858.082\n",
      "Ep:145, loss:0.00000, loss_test:0.07396, lr:7.55e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.705, tt:2876.893\n",
      "Ep:146, loss:0.00000, loss_test:0.07450, lr:7.47e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.708, tt:2897.043\n",
      "Ep:147, loss:0.00000, loss_test:0.07597, lr:7.40e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.713, tt:2917.509\n",
      "Ep:148, loss:0.00000, loss_test:0.07712, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.744, tt:2941.875\n",
      "Ep:149, loss:0.00000, loss_test:0.07617, lr:7.25e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.750, tt:2962.463\n",
      "Ep:150, loss:0.00000, loss_test:0.07466, lr:7.18e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.756, tt:2983.205\n",
      "Ep:151, loss:0.00000, loss_test:0.07435, lr:7.11e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.753, tt:3002.528\n",
      "Ep:152, loss:0.00000, loss_test:0.07525, lr:7.03e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.756, tt:3022.690\n",
      "Ep:153, loss:0.00000, loss_test:0.07695, lr:6.96e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.756, tt:3042.371\n",
      "Ep:154, loss:0.00000, loss_test:0.07691, lr:6.89e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.766, tt:3063.710\n",
      "Ep:155, loss:0.00000, loss_test:0.07636, lr:6.83e-03, fs:0.74699 (r=0.626,p=0.925),  time:19.768, tt:3083.740\n",
      "Ep:156, loss:0.00000, loss_test:0.07481, lr:6.76e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.771, tt:3104.020\n",
      "Ep:157, loss:0.00000, loss_test:0.07566, lr:6.69e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.762, tt:3122.375\n",
      "Ep:158, loss:0.00000, loss_test:0.07635, lr:6.62e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.763, tt:3142.306\n",
      "Ep:159, loss:0.00000, loss_test:0.07576, lr:6.56e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.767, tt:3162.785\n",
      "Ep:160, loss:0.00000, loss_test:0.07611, lr:6.49e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.767, tt:3182.416\n",
      "Ep:161, loss:0.00000, loss_test:0.07630, lr:6.43e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.767, tt:3202.260\n",
      "Ep:162, loss:0.00000, loss_test:0.07618, lr:6.36e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.766, tt:3221.904\n",
      "Ep:163, loss:0.00000, loss_test:0.07513, lr:6.30e-03, fs:0.74251 (r=0.626,p=0.912),  time:19.766, tt:3241.682\n",
      "Ep:164, loss:0.00000, loss_test:0.07650, lr:6.24e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.774, tt:3262.716\n",
      "Ep:165, loss:0.00000, loss_test:0.07624, lr:6.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.788, tt:3284.747\n",
      "Ep:166, loss:0.00000, loss_test:0.07496, lr:6.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.789, tt:3304.810\n",
      "Ep:167, loss:0.00000, loss_test:0.07618, lr:6.05e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.787, tt:3324.273\n",
      "Ep:168, loss:0.00000, loss_test:0.07463, lr:5.99e-03, fs:0.75294 (r=0.646,p=0.901),  time:19.777, tt:3342.232\n",
      "Ep:169, loss:0.00000, loss_test:0.07601, lr:5.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.768, tt:3360.644\n",
      "Ep:170, loss:0.00000, loss_test:0.07471, lr:5.87e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.766, tt:3380.037\n",
      "Ep:171, loss:0.00000, loss_test:0.07634, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.764, tt:3399.393\n",
      "Ep:172, loss:0.00000, loss_test:0.07595, lr:5.75e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.766, tt:3419.540\n",
      "Ep:173, loss:0.00000, loss_test:0.07517, lr:5.70e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.758, tt:3437.863\n",
      "Ep:174, loss:0.00000, loss_test:0.07746, lr:5.64e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.749, tt:3456.150\n",
      "Ep:175, loss:0.00000, loss_test:0.07658, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.733, tt:3473.066\n",
      "Ep:176, loss:0.00000, loss_test:0.07524, lr:5.53e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.726, tt:3491.413\n",
      "Ep:177, loss:0.00000, loss_test:0.07610, lr:5.47e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.718, tt:3509.805\n",
      "Ep:178, loss:0.00000, loss_test:0.07608, lr:5.42e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.712, tt:3528.389\n",
      "Ep:179, loss:0.00000, loss_test:0.07523, lr:5.36e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.695, tt:3545.160\n",
      "Ep:180, loss:0.00000, loss_test:0.07614, lr:5.31e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.683, tt:3562.625\n",
      "Ep:181, loss:0.00000, loss_test:0.07565, lr:5.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.681, tt:3581.964\n",
      "Ep:182, loss:0.00000, loss_test:0.07521, lr:5.20e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.670, tt:3599.639\n",
      "Ep:183, loss:0.00000, loss_test:0.07683, lr:5.15e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.662, tt:3617.810\n",
      "Ep:184, loss:0.00000, loss_test:0.07586, lr:5.10e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.655, tt:3636.137\n",
      "Ep:185, loss:0.00000, loss_test:0.07623, lr:5.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.649, tt:3654.805\n",
      "Ep:186, loss:0.00000, loss_test:0.07491, lr:5.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.640, tt:3672.624\n",
      "Ep:187, loss:0.00000, loss_test:0.07694, lr:4.95e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.640, tt:3692.378\n",
      "Ep:188, loss:0.00000, loss_test:0.07663, lr:4.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.631, tt:3710.185\n",
      "Ep:189, loss:0.00000, loss_test:0.07571, lr:4.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.621, tt:3728.044\n",
      "Ep:190, loss:0.00000, loss_test:0.07721, lr:4.80e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.614, tt:3746.335\n",
      "Ep:191, loss:0.00000, loss_test:0.07627, lr:4.75e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.606, tt:3764.441\n",
      "Ep:192, loss:0.00000, loss_test:0.07539, lr:4.71e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.597, tt:3782.184\n",
      "Ep:193, loss:0.00000, loss_test:0.07656, lr:4.66e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.583, tt:3799.026\n",
      "Ep:194, loss:0.00000, loss_test:0.07656, lr:4.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.570, tt:3816.138\n",
      "Ep:195, loss:0.00000, loss_test:0.07606, lr:4.57e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.566, tt:3834.913\n",
      "Ep:196, loss:0.00000, loss_test:0.07733, lr:4.52e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.564, tt:3854.121\n",
      "Ep:197, loss:0.00000, loss_test:0.07621, lr:4.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.560, tt:3872.799\n",
      "Ep:198, loss:0.00000, loss_test:0.07479, lr:4.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.554, tt:3891.263\n",
      "Ep:199, loss:0.00000, loss_test:0.07801, lr:4.39e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.556, tt:3911.290\n",
      "Ep:200, loss:0.00000, loss_test:0.07893, lr:4.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.556, tt:3930.733\n",
      "Ep:201, loss:0.00000, loss_test:0.07716, lr:4.30e-03, fs:0.75152 (r=0.626,p=0.939),  time:19.552, tt:3949.444\n",
      "Ep:202, loss:0.00000, loss_test:0.07477, lr:4.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.550, tt:3968.608\n",
      "Ep:203, loss:0.00000, loss_test:0.07710, lr:4.21e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.560, tt:3990.306\n",
      "Ep:204, loss:0.00000, loss_test:0.07804, lr:4.17e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.561, tt:4009.929\n",
      "Ep:205, loss:0.00000, loss_test:0.07684, lr:4.13e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.563, tt:4030.069\n",
      "Ep:206, loss:0.00000, loss_test:0.07534, lr:4.09e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.559, tt:4048.788\n",
      "Ep:207, loss:0.00000, loss_test:0.07680, lr:4.05e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.558, tt:4068.147\n",
      "Ep:208, loss:0.00000, loss_test:0.07823, lr:4.01e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.561, tt:4088.319\n",
      "Ep:209, loss:0.00000, loss_test:0.07807, lr:3.97e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.566, tt:4108.934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.07626, lr:3.93e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.567, tt:4128.667\n",
      "Ep:211, loss:0.00000, loss_test:0.07646, lr:3.89e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.572, tt:4149.240\n",
      "Ep:212, loss:0.00000, loss_test:0.07760, lr:3.85e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.574, tt:4169.316\n",
      "Ep:213, loss:0.00000, loss_test:0.07688, lr:3.81e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.577, tt:4189.446\n",
      "Ep:214, loss:0.00000, loss_test:0.07532, lr:3.77e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.614, tt:4216.998\n",
      "Ep:215, loss:0.00000, loss_test:0.07725, lr:3.73e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.609, tt:4235.538\n",
      "Ep:216, loss:0.00000, loss_test:0.07794, lr:3.70e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.599, tt:4252.991\n",
      "Ep:217, loss:0.00000, loss_test:0.07677, lr:3.66e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.598, tt:4272.394\n",
      "Ep:218, loss:0.00000, loss_test:0.07548, lr:3.62e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:4290.941\n",
      "Ep:219, loss:0.00000, loss_test:0.07721, lr:3.59e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.597, tt:4311.409\n",
      "Ep:220, loss:0.00000, loss_test:0.07764, lr:3.55e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.596, tt:4330.692\n",
      "Ep:221, loss:0.00000, loss_test:0.07637, lr:3.52e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.590, tt:4349.023\n",
      "Ep:222, loss:0.00000, loss_test:0.07670, lr:3.48e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.592, tt:4369.070\n",
      "Ep:223, loss:0.00000, loss_test:0.07684, lr:3.45e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.586, tt:4387.368\n",
      "Ep:224, loss:0.00000, loss_test:0.07660, lr:3.41e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.585, tt:4406.647\n",
      "Ep:225, loss:0.00000, loss_test:0.07776, lr:3.38e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.577, tt:4424.465\n",
      "Ep:226, loss:0.00000, loss_test:0.07726, lr:3.34e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.576, tt:4443.836\n",
      "Ep:227, loss:0.00000, loss_test:0.07578, lr:3.31e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.577, tt:4463.639\n",
      "Ep:228, loss:0.00000, loss_test:0.07767, lr:3.28e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.584, tt:4484.720\n",
      "Ep:229, loss:0.00000, loss_test:0.07811, lr:3.24e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.585, tt:4504.607\n",
      "Ep:230, loss:0.00000, loss_test:0.07738, lr:3.21e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.588, tt:4524.922\n",
      "Ep:231, loss:0.00000, loss_test:0.07675, lr:3.18e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:4545.145\n",
      "Ep:232, loss:0.00000, loss_test:0.07779, lr:3.15e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.590, tt:4564.569\n",
      "Ep:233, loss:0.00000, loss_test:0.07790, lr:3.12e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:4584.842\n",
      "Ep:234, loss:0.00000, loss_test:0.07722, lr:3.09e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:4604.439\n",
      "Ep:235, loss:0.00000, loss_test:0.07643, lr:3.05e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.596, tt:4624.761\n",
      "Ep:236, loss:0.00000, loss_test:0.07775, lr:3.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:4643.941\n",
      "Ep:237, loss:0.00000, loss_test:0.07819, lr:2.99e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.594, tt:4663.379\n",
      "Ep:238, loss:0.00000, loss_test:0.07770, lr:2.96e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:4683.090\n",
      "Ep:239, loss:0.00000, loss_test:0.07669, lr:2.93e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:4702.783\n",
      "Ep:240, loss:0.00000, loss_test:0.07747, lr:2.90e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:4722.371\n",
      "Ep:241, loss:0.00000, loss_test:0.07738, lr:2.88e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.596, tt:4742.179\n",
      "Ep:242, loss:0.00000, loss_test:0.07698, lr:2.85e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:4761.137\n",
      "Ep:243, loss:0.00000, loss_test:0.07720, lr:2.82e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:4780.319\n",
      "Ep:244, loss:0.00000, loss_test:0.07742, lr:2.79e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:4799.697\n",
      "Ep:245, loss:0.00000, loss_test:0.07708, lr:2.76e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.585, tt:4817.825\n",
      "Ep:246, loss:0.00000, loss_test:0.07776, lr:2.73e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.581, tt:4836.409\n",
      "Ep:247, loss:0.00000, loss_test:0.07769, lr:2.71e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.582, tt:4856.420\n",
      "Ep:248, loss:0.00000, loss_test:0.07690, lr:2.68e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.577, tt:4874.641\n",
      "Ep:249, loss:0.00000, loss_test:0.07759, lr:2.65e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.582, tt:4895.439\n",
      "Ep:250, loss:0.00000, loss_test:0.07766, lr:2.63e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.582, tt:4915.090\n",
      "Ep:251, loss:0.00000, loss_test:0.07721, lr:2.60e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.584, tt:4935.159\n",
      "Ep:252, loss:0.00000, loss_test:0.07782, lr:2.57e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.581, tt:4954.076\n",
      "Ep:253, loss:0.00000, loss_test:0.07785, lr:2.55e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.587, tt:4975.107\n",
      "Ep:254, loss:0.00000, loss_test:0.07744, lr:2.52e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.594, tt:4996.534\n",
      "Ep:255, loss:0.00000, loss_test:0.07743, lr:2.50e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.589, tt:5014.859\n",
      "Ep:256, loss:0.00000, loss_test:0.07712, lr:2.47e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.587, tt:5033.778\n",
      "Ep:257, loss:0.00000, loss_test:0.07774, lr:2.45e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.587, tt:5053.493\n",
      "Ep:258, loss:0.00000, loss_test:0.07779, lr:2.42e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.590, tt:5073.819\n",
      "Ep:259, loss:0.00000, loss_test:0.07761, lr:2.40e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.586, tt:5092.323\n",
      "Ep:260, loss:0.00000, loss_test:0.07854, lr:2.38e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.590, tt:5113.081\n",
      "Ep:261, loss:0.00000, loss_test:0.07848, lr:2.35e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:5132.939\n",
      "Ep:262, loss:0.00000, loss_test:0.07772, lr:2.33e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:5153.088\n",
      "Ep:263, loss:0.00000, loss_test:0.07710, lr:2.31e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.597, tt:5173.485\n",
      "Ep:264, loss:0.00000, loss_test:0.07810, lr:2.28e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.598, tt:5193.336\n",
      "Ep:265, loss:0.00000, loss_test:0.07831, lr:2.26e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.599, tt:5213.467\n",
      "Ep:266, loss:0.00000, loss_test:0.07793, lr:2.24e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.594, tt:5231.665\n",
      "Ep:267, loss:0.00000, loss_test:0.07769, lr:2.21e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.596, tt:5251.631\n",
      "Ep:268, loss:0.00000, loss_test:0.07791, lr:2.19e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:5271.159\n",
      "Ep:269, loss:0.00000, loss_test:0.07782, lr:2.17e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.594, tt:5290.482\n",
      "Ep:270, loss:0.00000, loss_test:0.07804, lr:2.15e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:5309.141\n",
      "Ep:271, loss:0.00000, loss_test:0.07806, lr:2.13e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.594, tt:5329.624\n",
      "Ep:272, loss:0.00000, loss_test:0.07773, lr:2.11e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.597, tt:5349.934\n",
      "Ep:273, loss:0.00000, loss_test:0.07830, lr:2.08e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.592, tt:5368.220\n",
      "Ep:274, loss:0.00000, loss_test:0.07812, lr:2.06e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:5387.983\n",
      "Ep:275, loss:0.00000, loss_test:0.07734, lr:2.04e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:5408.250\n",
      "Ep:276, loss:0.00000, loss_test:0.07771, lr:2.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.597, tt:5428.506\n",
      "Ep:277, loss:0.00000, loss_test:0.07828, lr:2.00e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.595, tt:5447.370\n",
      "Ep:278, loss:0.00000, loss_test:0.07859, lr:1.98e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:5466.508\n",
      "Ep:279, loss:0.00000, loss_test:0.07841, lr:1.96e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.594, tt:5486.227\n",
      "Ep:280, loss:0.00000, loss_test:0.07787, lr:1.94e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.590, tt:5504.834\n",
      "Ep:281, loss:0.00000, loss_test:0.07818, lr:1.92e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.589, tt:5524.234\n",
      "Ep:282, loss:0.00000, loss_test:0.07826, lr:1.90e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:5544.360\n",
      "Ep:283, loss:0.00000, loss_test:0.07795, lr:1.89e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.592, tt:5564.084\n",
      "Ep:284, loss:0.00000, loss_test:0.07785, lr:1.87e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:5583.487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:285, loss:0.00000, loss_test:0.07846, lr:1.85e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.593, tt:5603.614\n",
      "Ep:286, loss:0.00000, loss_test:0.07855, lr:1.83e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:5622.625\n",
      "Ep:287, loss:0.00000, loss_test:0.07836, lr:1.81e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.583, tt:5640.007\n",
      "Ep:288, loss:0.00000, loss_test:0.07825, lr:1.79e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.582, tt:5659.294\n",
      "Ep:289, loss:0.00000, loss_test:0.07837, lr:1.78e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.583, tt:5679.057\n",
      "Ep:290, loss:0.00000, loss_test:0.07843, lr:1.76e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.584, tt:5698.853\n",
      "Ep:291, loss:0.00000, loss_test:0.07813, lr:1.74e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.584, tt:5718.581\n",
      "Ep:292, loss:0.00000, loss_test:0.07827, lr:1.72e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.584, tt:5738.049\n",
      "Ep:293, loss:0.00000, loss_test:0.07847, lr:1.71e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.591, tt:5759.724\n",
      "Ep:294, loss:0.00000, loss_test:0.07842, lr:1.69e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.588, tt:5778.378\n",
      "Ep:295, loss:0.00000, loss_test:0.07856, lr:1.67e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.580, tt:5795.790\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14180, lr:1.00e-02, fs:0.64336 (r=0.929,p=0.492),  time:9.387, tt:9.387\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14072, lr:1.00e-02, fs:0.63860 (r=0.919,p=0.489),  time:12.566, tt:25.132\n",
      "Ep:2, loss:0.00004, loss_test:0.13916, lr:1.00e-02, fs:0.64029 (r=0.899,p=0.497),  time:14.264, tt:42.793\n",
      "Ep:3, loss:0.00004, loss_test:0.13713, lr:1.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:15.223, tt:60.894\n",
      "Ep:4, loss:0.00004, loss_test:0.13499, lr:1.00e-02, fs:0.64093 (r=0.838,p=0.519),  time:15.692, tt:78.462\n",
      "Ep:5, loss:0.00003, loss_test:0.13281, lr:1.00e-02, fs:0.61600 (r=0.778,p=0.510),  time:16.150, tt:96.901\n",
      "Ep:6, loss:0.00003, loss_test:0.13142, lr:1.00e-02, fs:0.61411 (r=0.747,p=0.521),  time:16.426, tt:114.980\n",
      "Ep:7, loss:0.00003, loss_test:0.13050, lr:1.00e-02, fs:0.61538 (r=0.727,p=0.533),  time:16.606, tt:132.851\n",
      "Ep:8, loss:0.00003, loss_test:0.12892, lr:1.00e-02, fs:0.64286 (r=0.727,p=0.576),  time:16.859, tt:151.731\n",
      "Ep:9, loss:0.00003, loss_test:0.12687, lr:1.00e-02, fs:0.64286 (r=0.727,p=0.576),  time:17.041, tt:170.410\n",
      "Ep:10, loss:0.00003, loss_test:0.12473, lr:1.00e-02, fs:0.65455 (r=0.727,p=0.595),  time:17.136, tt:188.494\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.12263, lr:1.00e-02, fs:0.65438 (r=0.717,p=0.602),  time:17.307, tt:207.685\n",
      "Ep:12, loss:0.00003, loss_test:0.12033, lr:1.00e-02, fs:0.64815 (r=0.707,p=0.598),  time:17.456, tt:226.934\n",
      "Ep:13, loss:0.00003, loss_test:0.11815, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:17.467, tt:244.533\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.11627, lr:1.00e-02, fs:0.65072 (r=0.687,p=0.618),  time:17.466, tt:261.991\n",
      "Ep:15, loss:0.00003, loss_test:0.11470, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:17.453, tt:279.244\n",
      "Ep:16, loss:0.00003, loss_test:0.11326, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:17.410, tt:295.963\n",
      "Ep:17, loss:0.00003, loss_test:0.11202, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:17.458, tt:314.246\n",
      "Ep:18, loss:0.00003, loss_test:0.11095, lr:1.00e-02, fs:0.66667 (r=0.687,p=0.648),  time:17.508, tt:332.658\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.10999, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:17.547, tt:350.947\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.10903, lr:1.00e-02, fs:0.68657 (r=0.697,p=0.676),  time:17.562, tt:368.797\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.10814, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:17.559, tt:386.306\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10730, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.591, tt:404.590\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10680, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.596, tt:422.299\n",
      "Ep:24, loss:0.00003, loss_test:0.10661, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:17.634, tt:440.858\n",
      "Ep:25, loss:0.00003, loss_test:0.10651, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:17.626, tt:458.286\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.10643, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:17.752, tt:479.298\n",
      "Ep:27, loss:0.00002, loss_test:0.10623, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.742, tt:496.790\n",
      "Ep:28, loss:0.00002, loss_test:0.10603, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:17.781, tt:515.648\n",
      "Ep:29, loss:0.00002, loss_test:0.10604, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:17.809, tt:534.263\n",
      "Ep:30, loss:0.00002, loss_test:0.10623, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:17.818, tt:552.362\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.10645, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:17.809, tt:569.901\n",
      "Ep:32, loss:0.00002, loss_test:0.10654, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:17.831, tt:588.408\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10677, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:17.850, tt:606.910\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.10687, lr:1.00e-02, fs:0.71204 (r=0.687,p=0.739),  time:17.864, tt:625.236\n",
      "Ep:35, loss:0.00002, loss_test:0.10663, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:17.883, tt:643.772\n",
      "Ep:36, loss:0.00002, loss_test:0.10639, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:17.910, tt:662.658\n",
      "Ep:37, loss:0.00002, loss_test:0.10596, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:17.928, tt:681.281\n",
      "Ep:38, loss:0.00002, loss_test:0.10537, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:17.945, tt:699.840\n",
      "Ep:39, loss:0.00002, loss_test:0.10489, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:17.935, tt:717.407\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10448, lr:1.00e-02, fs:0.72340 (r=0.687,p=0.764),  time:17.923, tt:734.859\n",
      "Ep:41, loss:0.00002, loss_test:0.10416, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:17.957, tt:754.194\n",
      "Ep:42, loss:0.00002, loss_test:0.10378, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:17.975, tt:772.905\n",
      "Ep:43, loss:0.00002, loss_test:0.10333, lr:1.00e-02, fs:0.68817 (r=0.646,p=0.736),  time:17.987, tt:791.449\n",
      "Ep:44, loss:0.00002, loss_test:0.10309, lr:1.00e-02, fs:0.69892 (r=0.657,p=0.747),  time:17.998, tt:809.905\n",
      "Ep:45, loss:0.00002, loss_test:0.10280, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:18.008, tt:828.377\n",
      "Ep:46, loss:0.00002, loss_test:0.10241, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:18.045, tt:848.100\n",
      "Ep:47, loss:0.00002, loss_test:0.10237, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:18.028, tt:865.324\n",
      "Ep:48, loss:0.00002, loss_test:0.10261, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:18.045, tt:884.221\n",
      "Ep:49, loss:0.00002, loss_test:0.10265, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:18.056, tt:902.778\n",
      "Ep:50, loss:0.00002, loss_test:0.10240, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:18.093, tt:922.746\n",
      "Ep:51, loss:0.00002, loss_test:0.10230, lr:9.90e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.093, tt:940.853\n",
      "Ep:52, loss:0.00002, loss_test:0.10171, lr:9.80e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.106, tt:959.640\n",
      "Ep:53, loss:0.00002, loss_test:0.10127, lr:9.70e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.126, tt:978.785\n",
      "Ep:54, loss:0.00002, loss_test:0.10131, lr:9.61e-03, fs:0.70968 (r=0.667,p=0.759),  time:18.134, tt:997.372\n",
      "Ep:55, loss:0.00002, loss_test:0.10115, lr:9.51e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.139, tt:1015.802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00002, loss_test:0.10079, lr:9.41e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.131, tt:1033.464\n",
      "Ep:57, loss:0.00002, loss_test:0.10125, lr:9.32e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.101, tt:1049.875\n",
      "Ep:58, loss:0.00001, loss_test:0.10115, lr:9.23e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.101, tt:1067.934\n",
      "Ep:59, loss:0.00001, loss_test:0.10058, lr:9.14e-03, fs:0.72340 (r=0.687,p=0.764),  time:18.096, tt:1085.765\n",
      "Ep:60, loss:0.00001, loss_test:0.10086, lr:9.04e-03, fs:0.72340 (r=0.687,p=0.764),  time:18.074, tt:1102.531\n",
      "Ep:61, loss:0.00001, loss_test:0.10109, lr:8.95e-03, fs:0.72340 (r=0.687,p=0.764),  time:18.063, tt:1119.894\n",
      "Ep:62, loss:0.00001, loss_test:0.10077, lr:8.86e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.042, tt:1136.660\n",
      "Ep:63, loss:0.00001, loss_test:0.10125, lr:8.78e-03, fs:0.72340 (r=0.687,p=0.764),  time:18.028, tt:1153.803\n",
      "Ep:64, loss:0.00001, loss_test:0.10105, lr:8.69e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.024, tt:1171.553\n",
      "Ep:65, loss:0.00001, loss_test:0.10057, lr:8.60e-03, fs:0.72340 (r=0.687,p=0.764),  time:18.018, tt:1189.200\n",
      "Ep:66, loss:0.00001, loss_test:0.10143, lr:8.51e-03, fs:0.70968 (r=0.667,p=0.759),  time:18.010, tt:1206.669\n",
      "Ep:67, loss:0.00001, loss_test:0.10166, lr:8.43e-03, fs:0.70968 (r=0.667,p=0.759),  time:18.022, tt:1225.465\n",
      "Ep:68, loss:0.00001, loss_test:0.10147, lr:8.35e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.019, tt:1243.339\n",
      "Ep:69, loss:0.00001, loss_test:0.10158, lr:8.26e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.008, tt:1260.562\n",
      "Ep:70, loss:0.00001, loss_test:0.10162, lr:8.18e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.015, tt:1279.053\n",
      "Ep:71, loss:0.00001, loss_test:0.10143, lr:8.10e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.008, tt:1296.579\n",
      "Ep:72, loss:0.00001, loss_test:0.10149, lr:8.02e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.014, tt:1314.987\n",
      "Ep:73, loss:0.00001, loss_test:0.10264, lr:7.94e-03, fs:0.71351 (r=0.667,p=0.767),  time:18.015, tt:1333.127\n",
      "Ep:74, loss:0.00001, loss_test:0.10252, lr:7.86e-03, fs:0.70652 (r=0.657,p=0.765),  time:18.006, tt:1350.437\n",
      "Ep:75, loss:0.00001, loss_test:0.10192, lr:7.78e-03, fs:0.70968 (r=0.667,p=0.759),  time:18.005, tt:1368.348\n",
      "Ep:76, loss:0.00001, loss_test:0.10254, lr:7.70e-03, fs:0.71351 (r=0.667,p=0.767),  time:17.996, tt:1385.728\n",
      "Ep:77, loss:0.00001, loss_test:0.10268, lr:7.62e-03, fs:0.70652 (r=0.657,p=0.765),  time:17.992, tt:1403.379\n",
      "Ep:78, loss:0.00001, loss_test:0.10343, lr:7.55e-03, fs:0.70330 (r=0.646,p=0.771),  time:17.998, tt:1421.837\n",
      "Ep:79, loss:0.00001, loss_test:0.10359, lr:7.47e-03, fs:0.69945 (r=0.646,p=0.762),  time:17.999, tt:1439.937\n",
      "Ep:80, loss:0.00001, loss_test:0.10300, lr:7.40e-03, fs:0.70270 (r=0.657,p=0.756),  time:17.998, tt:1457.849\n",
      "Ep:81, loss:0.00001, loss_test:0.10376, lr:7.32e-03, fs:0.69231 (r=0.636,p=0.759),  time:17.997, tt:1475.744\n",
      "Ep:82, loss:0.00001, loss_test:0.10415, lr:7.25e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.981, tt:1492.464\n",
      "Ep:83, loss:0.00001, loss_test:0.10401, lr:7.18e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.977, tt:1510.027\n",
      "Ep:84, loss:0.00001, loss_test:0.10488, lr:7.11e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.979, tt:1528.223\n",
      "Ep:85, loss:0.00001, loss_test:0.10379, lr:7.03e-03, fs:0.69613 (r=0.636,p=0.768),  time:17.986, tt:1546.767\n",
      "Ep:86, loss:0.00001, loss_test:0.10481, lr:6.96e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.985, tt:1564.687\n",
      "Ep:87, loss:0.00001, loss_test:0.10489, lr:6.89e-03, fs:0.69613 (r=0.636,p=0.768),  time:17.975, tt:1581.794\n",
      "Ep:88, loss:0.00001, loss_test:0.10440, lr:6.83e-03, fs:0.69613 (r=0.636,p=0.768),  time:17.962, tt:1598.585\n",
      "Ep:89, loss:0.00001, loss_test:0.10612, lr:6.76e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.947, tt:1615.198\n",
      "Ep:90, loss:0.00001, loss_test:0.10581, lr:6.69e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.948, tt:1633.279\n",
      "Ep:91, loss:0.00001, loss_test:0.10516, lr:6.62e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.945, tt:1650.950\n",
      "Ep:92, loss:0.00001, loss_test:0.10618, lr:6.56e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.946, tt:1668.937\n",
      "Ep:93, loss:0.00001, loss_test:0.10577, lr:6.49e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.930, tt:1685.385\n",
      "Ep:94, loss:0.00001, loss_test:0.10546, lr:6.43e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.920, tt:1702.440\n",
      "Ep:95, loss:0.00001, loss_test:0.10628, lr:6.36e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.899, tt:1718.265\n",
      "Ep:96, loss:0.00001, loss_test:0.10577, lr:6.30e-03, fs:0.68156 (r=0.616,p=0.762),  time:17.891, tt:1735.449\n",
      "Ep:97, loss:0.00001, loss_test:0.10593, lr:6.24e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.885, tt:1752.756\n",
      "Ep:98, loss:0.00001, loss_test:0.10633, lr:6.17e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.880, tt:1770.112\n",
      "Ep:99, loss:0.00001, loss_test:0.10581, lr:6.11e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.891, tt:1789.055\n",
      "Ep:100, loss:0.00001, loss_test:0.10563, lr:6.05e-03, fs:0.68156 (r=0.616,p=0.762),  time:17.884, tt:1806.307\n",
      "Ep:101, loss:0.00001, loss_test:0.10737, lr:5.99e-03, fs:0.65909 (r=0.586,p=0.753),  time:17.867, tt:1822.479\n",
      "Ep:102, loss:0.00001, loss_test:0.10701, lr:5.93e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.861, tt:1839.702\n",
      "Ep:103, loss:0.00001, loss_test:0.10535, lr:5.87e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.858, tt:1857.182\n",
      "Ep:104, loss:0.00001, loss_test:0.10724, lr:5.81e-03, fs:0.66292 (r=0.596,p=0.747),  time:17.856, tt:1874.855\n",
      "Ep:105, loss:0.00001, loss_test:0.10728, lr:5.75e-03, fs:0.65909 (r=0.586,p=0.753),  time:17.869, tt:1894.146\n",
      "Ep:106, loss:0.00001, loss_test:0.10657, lr:5.70e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.854, tt:1910.366\n",
      "Ep:107, loss:0.00001, loss_test:0.10700, lr:5.64e-03, fs:0.65909 (r=0.586,p=0.753),  time:17.845, tt:1927.313\n",
      "Ep:108, loss:0.00001, loss_test:0.10692, lr:5.58e-03, fs:0.65537 (r=0.586,p=0.744),  time:17.846, tt:1945.244\n",
      "Ep:109, loss:0.00001, loss_test:0.10564, lr:5.53e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.846, tt:1963.021\n",
      "Ep:110, loss:0.00001, loss_test:0.10744, lr:5.47e-03, fs:0.65909 (r=0.586,p=0.753),  time:17.838, tt:1980.000\n",
      "Ep:111, loss:0.00001, loss_test:0.10792, lr:5.42e-03, fs:0.64773 (r=0.576,p=0.740),  time:17.847, tt:1998.822\n",
      "Ep:112, loss:0.00001, loss_test:0.10622, lr:5.36e-03, fs:0.65909 (r=0.586,p=0.753),  time:17.852, tt:2017.227\n",
      "Ep:113, loss:0.00001, loss_test:0.10546, lr:5.31e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.849, tt:2034.747\n",
      "Ep:114, loss:0.00001, loss_test:0.10722, lr:5.26e-03, fs:0.65169 (r=0.586,p=0.734),  time:17.848, tt:2052.566\n",
      "Ep:115, loss:0.00001, loss_test:0.10697, lr:5.20e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.845, tt:2070.062\n",
      "Ep:116, loss:0.00001, loss_test:0.10602, lr:5.15e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.843, tt:2087.626\n",
      "Ep:117, loss:0.00001, loss_test:0.10579, lr:5.10e-03, fs:0.68156 (r=0.616,p=0.762),  time:17.850, tt:2106.329\n",
      "Ep:118, loss:0.00001, loss_test:0.10590, lr:5.05e-03, fs:0.67403 (r=0.616,p=0.744),  time:17.851, tt:2124.221\n",
      "Ep:119, loss:0.00001, loss_test:0.10495, lr:5.00e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.849, tt:2141.921\n",
      "Ep:120, loss:0.00001, loss_test:0.10640, lr:4.95e-03, fs:0.65909 (r=0.586,p=0.753),  time:17.856, tt:2160.544\n",
      "Ep:121, loss:0.00001, loss_test:0.10716, lr:4.90e-03, fs:0.65169 (r=0.586,p=0.734),  time:17.862, tt:2179.167\n",
      "Ep:122, loss:0.00001, loss_test:0.10596, lr:4.85e-03, fs:0.65922 (r=0.596,p=0.738),  time:17.873, tt:2198.398\n",
      "Ep:123, loss:0.00001, loss_test:0.10412, lr:4.80e-03, fs:0.69945 (r=0.646,p=0.762),  time:17.883, tt:2217.541\n",
      "Ep:124, loss:0.00001, loss_test:0.10579, lr:4.75e-03, fs:0.66292 (r=0.596,p=0.747),  time:17.888, tt:2236.027\n",
      "Ep:125, loss:0.00001, loss_test:0.10659, lr:4.71e-03, fs:0.65537 (r=0.586,p=0.744),  time:17.890, tt:2254.143\n",
      "Ep:126, loss:0.00001, loss_test:0.10565, lr:4.66e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.894, tt:2272.494\n",
      "Ep:127, loss:0.00001, loss_test:0.10499, lr:4.61e-03, fs:0.69613 (r=0.636,p=0.768),  time:17.894, tt:2290.397\n",
      "Ep:128, loss:0.00001, loss_test:0.10532, lr:4.57e-03, fs:0.68132 (r=0.626,p=0.747),  time:17.912, tt:2310.657\n",
      "Ep:129, loss:0.00001, loss_test:0.10472, lr:4.52e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.919, tt:2329.464\n",
      "Ep:130, loss:0.00001, loss_test:0.10565, lr:4.48e-03, fs:0.66667 (r=0.596,p=0.756),  time:17.917, tt:2347.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.10642, lr:4.43e-03, fs:0.65169 (r=0.586,p=0.734),  time:17.921, tt:2365.626\n",
      "Ep:132, loss:0.00001, loss_test:0.10545, lr:4.39e-03, fs:0.67778 (r=0.616,p=0.753),  time:17.927, tt:2384.266\n",
      "Ep:133, loss:0.00001, loss_test:0.10395, lr:4.34e-03, fs:0.70330 (r=0.646,p=0.771),  time:17.941, tt:2404.106\n",
      "Ep:134, loss:0.00001, loss_test:0.10580, lr:4.30e-03, fs:0.66667 (r=0.606,p=0.741),  time:17.955, tt:2423.926\n",
      "Ep:135, loss:0.00001, loss_test:0.10576, lr:4.26e-03, fs:0.67416 (r=0.606,p=0.759),  time:17.964, tt:2443.138\n",
      "Ep:136, loss:0.00001, loss_test:0.10510, lr:4.21e-03, fs:0.68889 (r=0.626,p=0.765),  time:17.979, tt:2463.093\n",
      "Ep:137, loss:0.00001, loss_test:0.10515, lr:4.17e-03, fs:0.68156 (r=0.616,p=0.762),  time:17.982, tt:2481.552\n",
      "Ep:138, loss:0.00001, loss_test:0.10498, lr:4.13e-03, fs:0.69231 (r=0.636,p=0.759),  time:17.993, tt:2500.980\n",
      "Ep:139, loss:0.00001, loss_test:0.10460, lr:4.09e-03, fs:0.70330 (r=0.646,p=0.771),  time:18.005, tt:2520.747\n",
      "Ep:140, loss:0.00001, loss_test:0.10584, lr:4.05e-03, fs:0.68889 (r=0.626,p=0.765),  time:18.017, tt:2540.331\n",
      "Ep:141, loss:0.00001, loss_test:0.10609, lr:4.01e-03, fs:0.67039 (r=0.606,p=0.750),  time:18.025, tt:2559.515\n",
      "Ep:142, loss:0.00001, loss_test:0.10481, lr:3.97e-03, fs:0.69613 (r=0.636,p=0.768),  time:18.032, tt:2578.605\n",
      "Ep:143, loss:0.00001, loss_test:0.10456, lr:3.93e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.047, tt:2598.795\n",
      "Ep:144, loss:0.00001, loss_test:0.10515, lr:3.89e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.051, tt:2617.418\n",
      "Ep:145, loss:0.00001, loss_test:0.10446, lr:3.85e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.058, tt:2636.467\n",
      "Ep:146, loss:0.00001, loss_test:0.10562, lr:3.81e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.060, tt:2654.787\n",
      "Ep:147, loss:0.00001, loss_test:0.10578, lr:3.77e-03, fs:0.66292 (r=0.596,p=0.747),  time:18.068, tt:2674.071\n",
      "Ep:148, loss:0.00001, loss_test:0.10461, lr:3.73e-03, fs:0.70000 (r=0.636,p=0.778),  time:18.073, tt:2692.933\n",
      "Ep:149, loss:0.00001, loss_test:0.10412, lr:3.70e-03, fs:0.69613 (r=0.636,p=0.768),  time:18.090, tt:2713.519\n",
      "Ep:150, loss:0.00001, loss_test:0.10523, lr:3.66e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.091, tt:2731.817\n",
      "Ep:151, loss:0.00001, loss_test:0.10491, lr:3.62e-03, fs:0.70000 (r=0.636,p=0.778),  time:18.093, tt:2750.105\n",
      "Ep:152, loss:0.00001, loss_test:0.10473, lr:3.59e-03, fs:0.70000 (r=0.636,p=0.778),  time:18.092, tt:2768.059\n",
      "Ep:153, loss:0.00001, loss_test:0.10509, lr:3.55e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.095, tt:2786.602\n",
      "Ep:154, loss:0.00001, loss_test:0.10489, lr:3.52e-03, fs:0.69231 (r=0.636,p=0.759),  time:18.100, tt:2805.518\n",
      "Ep:155, loss:0.00001, loss_test:0.10397, lr:3.48e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.104, tt:2824.268\n",
      "Ep:156, loss:0.00001, loss_test:0.10503, lr:3.45e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.107, tt:2842.779\n",
      "Ep:157, loss:0.00001, loss_test:0.10576, lr:3.41e-03, fs:0.67039 (r=0.606,p=0.750),  time:18.113, tt:2861.803\n",
      "Ep:158, loss:0.00001, loss_test:0.10484, lr:3.38e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.109, tt:2879.363\n",
      "Ep:159, loss:0.00001, loss_test:0.10453, lr:3.34e-03, fs:0.70000 (r=0.636,p=0.778),  time:18.114, tt:2898.314\n",
      "Ep:160, loss:0.00001, loss_test:0.10528, lr:3.31e-03, fs:0.68508 (r=0.626,p=0.756),  time:18.112, tt:2915.973\n",
      "Ep:161, loss:0.00001, loss_test:0.10469, lr:3.28e-03, fs:0.70000 (r=0.636,p=0.778),  time:18.119, tt:2935.223\n",
      "Ep:162, loss:0.00001, loss_test:0.10482, lr:3.24e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.119, tt:2953.402\n",
      "Ep:163, loss:0.00001, loss_test:0.10540, lr:3.21e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.113, tt:2970.538\n",
      "Ep:164, loss:0.00001, loss_test:0.10494, lr:3.18e-03, fs:0.69613 (r=0.636,p=0.768),  time:18.109, tt:2988.045\n",
      "Ep:165, loss:0.00001, loss_test:0.10410, lr:3.15e-03, fs:0.70330 (r=0.646,p=0.771),  time:18.103, tt:3005.039\n",
      "Ep:166, loss:0.00001, loss_test:0.10589, lr:3.12e-03, fs:0.67039 (r=0.606,p=0.750),  time:18.092, tt:3021.440\n",
      "Ep:167, loss:0.00001, loss_test:0.10593, lr:3.09e-03, fs:0.67416 (r=0.606,p=0.759),  time:18.086, tt:3038.368\n",
      "Ep:168, loss:0.00001, loss_test:0.10534, lr:3.05e-03, fs:0.67797 (r=0.606,p=0.769),  time:18.084, tt:3056.178\n",
      "Ep:169, loss:0.00001, loss_test:0.10494, lr:3.02e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.084, tt:3074.305\n",
      "Ep:170, loss:0.00001, loss_test:0.10537, lr:2.99e-03, fs:0.67403 (r=0.616,p=0.744),  time:18.077, tt:3091.109\n",
      "Ep:171, loss:0.00001, loss_test:0.10479, lr:2.96e-03, fs:0.68889 (r=0.626,p=0.765),  time:18.076, tt:3109.145\n",
      "Ep:172, loss:0.00001, loss_test:0.10563, lr:2.93e-03, fs:0.67797 (r=0.606,p=0.769),  time:18.068, tt:3125.714\n",
      "Ep:173, loss:0.00001, loss_test:0.10614, lr:2.90e-03, fs:0.67416 (r=0.606,p=0.759),  time:18.072, tt:3144.465\n",
      "Ep:174, loss:0.00001, loss_test:0.10573, lr:2.88e-03, fs:0.67416 (r=0.606,p=0.759),  time:18.067, tt:3161.756\n",
      "Ep:175, loss:0.00001, loss_test:0.10465, lr:2.85e-03, fs:0.68508 (r=0.626,p=0.756),  time:18.068, tt:3179.914\n",
      "Ep:176, loss:0.00001, loss_test:0.10536, lr:2.82e-03, fs:0.68156 (r=0.616,p=0.762),  time:18.060, tt:3196.561\n",
      "Ep:177, loss:0.00001, loss_test:0.10546, lr:2.79e-03, fs:0.68156 (r=0.616,p=0.762),  time:18.060, tt:3214.693\n",
      "Ep:178, loss:0.00001, loss_test:0.10528, lr:2.76e-03, fs:0.68156 (r=0.616,p=0.762),  time:18.067, tt:3234.055\n",
      "Ep:179, loss:0.00001, loss_test:0.10524, lr:2.73e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.072, tt:3252.951\n",
      "Ep:180, loss:0.00001, loss_test:0.10538, lr:2.71e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.074, tt:3271.306\n",
      "Ep:181, loss:0.00001, loss_test:0.10509, lr:2.68e-03, fs:0.67778 (r=0.616,p=0.753),  time:18.066, tt:3288.092\n",
      "Ep:182, loss:0.00001, loss_test:0.10597, lr:2.65e-03, fs:0.68156 (r=0.616,p=0.762),  time:18.070, tt:3306.808\n",
      "Ep:183, loss:0.00001, loss_test:0.10627, lr:2.63e-03, fs:0.68156 (r=0.616,p=0.762),  time:18.075, tt:3325.838\n",
      "Ep:184, loss:0.00001, loss_test:0.10516, lr:2.60e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.078, tt:3344.429\n",
      "Ep:185, loss:0.00001, loss_test:0.10519, lr:2.57e-03, fs:0.68156 (r=0.616,p=0.762),  time:18.079, tt:3362.750\n",
      "Ep:186, loss:0.00001, loss_test:0.10586, lr:2.55e-03, fs:0.68508 (r=0.626,p=0.756),  time:18.083, tt:3381.580\n",
      "Ep:187, loss:0.00001, loss_test:0.10542, lr:2.52e-03, fs:0.68508 (r=0.626,p=0.756),  time:18.085, tt:3400.004\n",
      "Ep:188, loss:0.00001, loss_test:0.10491, lr:2.50e-03, fs:0.68508 (r=0.626,p=0.756),  time:18.087, tt:3418.432\n",
      "Ep:189, loss:0.00001, loss_test:0.10558, lr:2.47e-03, fs:0.68508 (r=0.626,p=0.756),  time:18.090, tt:3437.075\n",
      "Ep:190, loss:0.00001, loss_test:0.10603, lr:2.45e-03, fs:0.68889 (r=0.626,p=0.765),  time:18.098, tt:3456.646\n",
      "Ep:191, loss:0.00001, loss_test:0.10529, lr:2.42e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.100, tt:3475.227\n",
      "Ep:192, loss:0.00001, loss_test:0.10509, lr:2.40e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.104, tt:3494.042\n",
      "Ep:193, loss:0.00001, loss_test:0.10610, lr:2.38e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.104, tt:3512.206\n",
      "Ep:194, loss:0.00001, loss_test:0.10642, lr:2.35e-03, fs:0.68889 (r=0.626,p=0.765),  time:18.117, tt:3532.809\n",
      "Ep:195, loss:0.00001, loss_test:0.10525, lr:2.33e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.119, tt:3551.241\n",
      "Ep:196, loss:0.00001, loss_test:0.10462, lr:2.31e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.104, tt:3566.461\n",
      "Ep:197, loss:0.00001, loss_test:0.10605, lr:2.28e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.102, tt:3584.164\n",
      "Ep:198, loss:0.00001, loss_test:0.10699, lr:2.26e-03, fs:0.68889 (r=0.626,p=0.765),  time:18.097, tt:3601.266\n",
      "Ep:199, loss:0.00001, loss_test:0.10639, lr:2.24e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.087, tt:3617.400\n",
      "Ep:200, loss:0.00001, loss_test:0.10528, lr:2.21e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.081, tt:3634.233\n",
      "Ep:201, loss:0.00001, loss_test:0.10521, lr:2.19e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.073, tt:3650.679\n",
      "Ep:202, loss:0.00001, loss_test:0.10621, lr:2.17e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.064, tt:3666.918\n",
      "Ep:203, loss:0.00001, loss_test:0.10651, lr:2.15e-03, fs:0.68889 (r=0.626,p=0.765),  time:18.058, tt:3683.805\n",
      "Ep:204, loss:0.00001, loss_test:0.10567, lr:2.13e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.060, tt:3702.306\n",
      "Ep:205, loss:0.00001, loss_test:0.10490, lr:2.11e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.058, tt:3719.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00001, loss_test:0.10581, lr:2.08e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.055, tt:3737.377\n",
      "Ep:207, loss:0.00001, loss_test:0.10658, lr:2.06e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.051, tt:3754.703\n",
      "Ep:208, loss:0.00001, loss_test:0.10637, lr:2.04e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.055, tt:3773.498\n",
      "Ep:209, loss:0.00001, loss_test:0.10551, lr:2.02e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.053, tt:3791.069\n",
      "Ep:210, loss:0.00001, loss_test:0.10515, lr:2.00e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.049, tt:3808.336\n",
      "Ep:211, loss:0.00001, loss_test:0.10594, lr:1.98e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.054, tt:3827.383\n",
      "Ep:212, loss:0.00001, loss_test:0.10641, lr:1.96e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.051, tt:3844.798\n",
      "Ep:213, loss:0.00001, loss_test:0.10630, lr:1.94e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.050, tt:3862.736\n",
      "Ep:214, loss:0.00001, loss_test:0.10589, lr:1.92e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.053, tt:3881.478\n",
      "Ep:215, loss:0.00001, loss_test:0.10553, lr:1.90e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.055, tt:3899.969\n",
      "Ep:216, loss:0.00001, loss_test:0.10596, lr:1.89e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.057, tt:3918.392\n",
      "Ep:217, loss:0.00001, loss_test:0.10631, lr:1.87e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.061, tt:3937.326\n",
      "Ep:218, loss:0.00001, loss_test:0.10612, lr:1.85e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.061, tt:3955.273\n",
      "Ep:219, loss:0.00001, loss_test:0.10583, lr:1.83e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.060, tt:3973.120\n",
      "Ep:220, loss:0.00001, loss_test:0.10609, lr:1.81e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.061, tt:3991.571\n",
      "Ep:221, loss:0.00001, loss_test:0.10632, lr:1.79e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.063, tt:4009.879\n",
      "Ep:222, loss:0.00001, loss_test:0.10587, lr:1.78e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.068, tt:4029.110\n",
      "Ep:223, loss:0.00001, loss_test:0.10587, lr:1.76e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.066, tt:4046.697\n",
      "Ep:224, loss:0.00001, loss_test:0.10629, lr:1.74e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.069, tt:4065.588\n",
      "Ep:225, loss:0.00001, loss_test:0.10649, lr:1.72e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.073, tt:4084.463\n",
      "Ep:226, loss:0.00001, loss_test:0.10574, lr:1.71e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.078, tt:4103.753\n",
      "Ep:227, loss:0.00001, loss_test:0.10550, lr:1.69e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.082, tt:4122.594\n",
      "Ep:228, loss:0.00001, loss_test:0.10638, lr:1.67e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.088, tt:4142.189\n",
      "Ep:229, loss:0.00001, loss_test:0.10692, lr:1.65e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.091, tt:4160.862\n",
      "Ep:230, loss:0.00001, loss_test:0.10648, lr:1.64e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.095, tt:4179.927\n",
      "Ep:231, loss:0.00001, loss_test:0.10588, lr:1.62e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.091, tt:4197.177\n",
      "Ep:232, loss:0.00001, loss_test:0.10568, lr:1.61e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.091, tt:4215.149\n",
      "Ep:233, loss:0.00001, loss_test:0.10611, lr:1.59e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.085, tt:4231.845\n",
      "Ep:234, loss:0.00001, loss_test:0.10648, lr:1.57e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.084, tt:4249.656\n",
      "Ep:235, loss:0.00001, loss_test:0.10611, lr:1.56e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.084, tt:4267.800\n",
      "Ep:236, loss:0.00001, loss_test:0.10584, lr:1.54e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.093, tt:4287.951\n",
      "Ep:237, loss:0.00001, loss_test:0.10632, lr:1.53e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.099, tt:4307.669\n",
      "Ep:238, loss:0.00001, loss_test:0.10675, lr:1.51e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.106, tt:4327.269\n",
      "Ep:239, loss:0.00001, loss_test:0.10656, lr:1.50e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.110, tt:4346.296\n",
      "Ep:240, loss:0.00001, loss_test:0.10579, lr:1.48e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.108, tt:4363.993\n",
      "Ep:241, loss:0.00001, loss_test:0.10557, lr:1.47e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.107, tt:4381.863\n",
      "Ep:242, loss:0.00001, loss_test:0.10648, lr:1.45e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.106, tt:4399.708\n",
      "Ep:243, loss:0.00001, loss_test:0.10698, lr:1.44e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.108, tt:4418.453\n",
      "Ep:244, loss:0.00001, loss_test:0.10666, lr:1.42e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.113, tt:4437.667\n",
      "Ep:245, loss:0.00001, loss_test:0.10628, lr:1.41e-03, fs:0.69663 (r=0.626,p=0.785),  time:18.115, tt:4456.219\n",
      "Ep:246, loss:0.00001, loss_test:0.10609, lr:1.39e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.115, tt:4474.507\n",
      "Ep:247, loss:0.00001, loss_test:0.10616, lr:1.38e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.115, tt:4492.451\n",
      "Ep:248, loss:0.00001, loss_test:0.10641, lr:1.37e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.113, tt:4510.252\n",
      "Ep:249, loss:0.00001, loss_test:0.10641, lr:1.35e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.113, tt:4528.299\n",
      "Ep:250, loss:0.00001, loss_test:0.10634, lr:1.34e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.108, tt:4544.998\n",
      "Ep:251, loss:0.00001, loss_test:0.10633, lr:1.33e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.110, tt:4563.605\n",
      "Ep:252, loss:0.00001, loss_test:0.10650, lr:1.31e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.114, tt:4582.955\n",
      "Ep:253, loss:0.00001, loss_test:0.10669, lr:1.30e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.118, tt:4602.073\n",
      "Ep:254, loss:0.00001, loss_test:0.10666, lr:1.29e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.118, tt:4619.996\n",
      "Ep:255, loss:0.00001, loss_test:0.10618, lr:1.27e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.122, tt:4639.143\n",
      "Ep:256, loss:0.00001, loss_test:0.10623, lr:1.26e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.128, tt:4658.785\n",
      "Ep:257, loss:0.00001, loss_test:0.10668, lr:1.25e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.130, tt:4677.482\n",
      "Ep:258, loss:0.00001, loss_test:0.10691, lr:1.24e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.134, tt:4696.677\n",
      "Ep:259, loss:0.00001, loss_test:0.10662, lr:1.22e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.138, tt:4715.999\n",
      "Ep:260, loss:0.00001, loss_test:0.10646, lr:1.21e-03, fs:0.68539 (r=0.616,p=0.772),  time:18.142, tt:4734.965\n",
      "Ep:261, loss:0.00001, loss_test:0.10650, lr:1.20e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.143, tt:4753.437\n",
      "Ep:262, loss:0.00001, loss_test:0.10667, lr:1.19e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.140, tt:4770.885\n",
      "Ep:263, loss:0.00001, loss_test:0.10653, lr:1.18e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.140, tt:4788.909\n",
      "Ep:264, loss:0.00001, loss_test:0.10635, lr:1.16e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.143, tt:4807.900\n",
      "Ep:265, loss:0.00001, loss_test:0.10643, lr:1.15e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.148, tt:4827.359\n",
      "Ep:266, loss:0.00001, loss_test:0.10669, lr:1.14e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.150, tt:4845.946\n",
      "Ep:267, loss:0.00001, loss_test:0.10660, lr:1.13e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.151, tt:4864.529\n",
      "Ep:268, loss:0.00001, loss_test:0.10642, lr:1.12e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.152, tt:4882.823\n",
      "Ep:269, loss:0.00001, loss_test:0.10649, lr:1.11e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.156, tt:4902.031\n",
      "Ep:270, loss:0.00001, loss_test:0.10669, lr:1.10e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.156, tt:4920.373\n",
      "Ep:271, loss:0.00001, loss_test:0.10631, lr:1.08e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.160, tt:4939.449\n",
      "Ep:272, loss:0.00001, loss_test:0.10654, lr:1.07e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.158, tt:4957.224\n",
      "Ep:273, loss:0.00001, loss_test:0.10687, lr:1.06e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.159, tt:4975.527\n",
      "Ep:274, loss:0.00001, loss_test:0.10686, lr:1.05e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.159, tt:4993.854\n",
      "Ep:275, loss:0.00001, loss_test:0.10626, lr:1.04e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.168, tt:5014.349\n",
      "Ep:276, loss:0.00001, loss_test:0.10608, lr:1.03e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.163, tt:5031.185\n",
      "Ep:277, loss:0.00001, loss_test:0.10658, lr:1.02e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.161, tt:5048.691\n",
      "Ep:278, loss:0.00001, loss_test:0.10682, lr:1.01e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.162, tt:5067.127\n",
      "Ep:279, loss:0.00001, loss_test:0.10645, lr:1.00e-03, fs:0.69274 (r=0.626,p=0.775),  time:18.165, tt:5086.229\n",
      "Ep:280, loss:0.00001, loss_test:0.10609, lr:9.91e-04, fs:0.69663 (r=0.626,p=0.785),  time:18.167, tt:5105.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:281, loss:0.00001, loss_test:0.10629, lr:9.81e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.167, tt:5123.086\n",
      "Ep:282, loss:0.00001, loss_test:0.10652, lr:9.71e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.169, tt:5141.685\n",
      "Ep:283, loss:0.00001, loss_test:0.10650, lr:9.62e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.171, tt:5160.509\n",
      "Ep:284, loss:0.00001, loss_test:0.10602, lr:9.52e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.171, tt:5178.875\n",
      "Ep:285, loss:0.00001, loss_test:0.10619, lr:9.42e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.174, tt:5197.694\n",
      "Ep:286, loss:0.00001, loss_test:0.10664, lr:9.33e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.174, tt:5215.884\n",
      "Ep:287, loss:0.00001, loss_test:0.10684, lr:9.24e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.176, tt:5234.786\n",
      "Ep:288, loss:0.00001, loss_test:0.10670, lr:9.14e-04, fs:0.68539 (r=0.616,p=0.772),  time:18.179, tt:5253.652\n",
      "Ep:289, loss:0.00001, loss_test:0.10628, lr:9.05e-04, fs:0.68539 (r=0.616,p=0.772),  time:18.178, tt:5271.673\n",
      "Ep:290, loss:0.00001, loss_test:0.10606, lr:8.96e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.177, tt:5289.416\n",
      "Ep:291, loss:0.00001, loss_test:0.10636, lr:8.87e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.175, tt:5307.141\n",
      "Ep:292, loss:0.00001, loss_test:0.10654, lr:8.78e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.173, tt:5324.707\n",
      "Ep:293, loss:0.00001, loss_test:0.10634, lr:8.70e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.170, tt:5341.886\n",
      "Ep:294, loss:0.00001, loss_test:0.10622, lr:8.61e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.165, tt:5358.809\n",
      "Ep:295, loss:0.00001, loss_test:0.10655, lr:8.52e-04, fs:0.69274 (r=0.626,p=0.775),  time:18.158, tt:5374.731\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.12438, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:15.611, tt:15.611\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.12386, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:16.780, tt:33.560\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.12321, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:17.136, tt:51.408\n",
      "Ep:3, loss:0.00004, loss_test:0.12261, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:17.503, tt:70.011\n",
      "Ep:4, loss:0.00004, loss_test:0.12209, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:17.758, tt:88.789\n",
      "Ep:5, loss:0.00004, loss_test:0.12160, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:17.751, tt:106.504\n",
      "Ep:6, loss:0.00004, loss_test:0.12118, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:17.787, tt:124.509\n",
      "Ep:7, loss:0.00004, loss_test:0.12084, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:17.789, tt:142.309\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.12052, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:17.830, tt:160.471\n",
      "Ep:9, loss:0.00004, loss_test:0.12022, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:17.940, tt:179.396\n",
      "Ep:10, loss:0.00004, loss_test:0.11993, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:17.986, tt:197.845\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.11966, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:18.021, tt:216.254\n",
      "Ep:12, loss:0.00004, loss_test:0.11939, lr:1.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:18.061, tt:234.788\n",
      "Ep:13, loss:0.00004, loss_test:0.11908, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:18.070, tt:252.984\n",
      "Ep:14, loss:0.00004, loss_test:0.11875, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:18.138, tt:272.070\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.11842, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:18.180, tt:290.887\n",
      "Ep:16, loss:0.00004, loss_test:0.11812, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:18.258, tt:310.378\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.11780, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:18.312, tt:329.611\n",
      "Ep:18, loss:0.00004, loss_test:0.11749, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:18.319, tt:348.062\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.11721, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:18.340, tt:366.804\n",
      "Ep:20, loss:0.00004, loss_test:0.11693, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:18.358, tt:385.524\n",
      "Ep:21, loss:0.00004, loss_test:0.11665, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:18.338, tt:403.443\n",
      "Ep:22, loss:0.00004, loss_test:0.11630, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:18.349, tt:422.032\n",
      "Ep:23, loss:0.00004, loss_test:0.11587, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:18.378, tt:441.076\n",
      "Ep:24, loss:0.00004, loss_test:0.11544, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:18.383, tt:459.586\n",
      "Ep:25, loss:0.00003, loss_test:0.11500, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:18.382, tt:477.935\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.11451, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:18.401, tt:496.833\n",
      "Ep:27, loss:0.00003, loss_test:0.11402, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:18.428, tt:515.993\n",
      "Ep:28, loss:0.00003, loss_test:0.11349, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:18.429, tt:534.442\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.11293, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:18.446, tt:553.383\n",
      "Ep:30, loss:0.00003, loss_test:0.11233, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:18.433, tt:571.416\n",
      "Ep:31, loss:0.00003, loss_test:0.11173, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:18.454, tt:590.536\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.11114, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:18.447, tt:608.759\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.11050, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:18.453, tt:627.404\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.10986, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:18.447, tt:645.639\n",
      "Ep:35, loss:0.00003, loss_test:0.10926, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:18.471, tt:664.956\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.10872, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:18.498, tt:684.438\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.10814, lr:1.00e-02, fs:0.73640 (r=0.889,p=0.629),  time:18.510, tt:703.379\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.10759, lr:1.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:18.521, tt:722.333\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.10707, lr:1.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:18.491, tt:739.645\n",
      "Ep:40, loss:0.00003, loss_test:0.10653, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:18.515, tt:759.097\n",
      "Ep:41, loss:0.00003, loss_test:0.10599, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:18.502, tt:777.071\n",
      "Ep:42, loss:0.00003, loss_test:0.10546, lr:1.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:18.530, tt:796.782\n",
      "Ep:43, loss:0.00003, loss_test:0.10483, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:18.536, tt:815.568\n",
      "Ep:44, loss:0.00003, loss_test:0.10415, lr:1.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:18.551, tt:834.773\n",
      "Ep:45, loss:0.00003, loss_test:0.10355, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:18.576, tt:854.500\n",
      "Ep:46, loss:0.00003, loss_test:0.10298, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:18.580, tt:873.268\n",
      "Ep:47, loss:0.00003, loss_test:0.10240, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:18.592, tt:892.433\n",
      "Ep:48, loss:0.00003, loss_test:0.10190, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:18.592, tt:911.005\n",
      "Ep:49, loss:0.00003, loss_test:0.10144, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:18.592, tt:929.595\n",
      "Ep:50, loss:0.00003, loss_test:0.10097, lr:9.90e-03, fs:0.72321 (r=0.818,p=0.648),  time:18.592, tt:948.169\n",
      "Ep:51, loss:0.00003, loss_test:0.10064, lr:9.80e-03, fs:0.73778 (r=0.838,p=0.659),  time:18.598, tt:967.073\n",
      "Ep:52, loss:0.00003, loss_test:0.10040, lr:9.70e-03, fs:0.73451 (r=0.838,p=0.654),  time:18.606, tt:986.126\n",
      "Ep:53, loss:0.00002, loss_test:0.10015, lr:9.61e-03, fs:0.73128 (r=0.838,p=0.648),  time:18.637, tt:1006.416\n",
      "Ep:54, loss:0.00002, loss_test:0.09998, lr:9.51e-03, fs:0.73543 (r=0.828,p=0.661),  time:18.655, tt:1026.019\n",
      "Ep:55, loss:0.00002, loss_test:0.09983, lr:9.41e-03, fs:0.73543 (r=0.828,p=0.661),  time:18.704, tt:1047.437\n",
      "Ep:56, loss:0.00002, loss_test:0.09967, lr:9.32e-03, fs:0.73214 (r=0.828,p=0.656),  time:18.723, tt:1067.217\n",
      "Ep:57, loss:0.00002, loss_test:0.09949, lr:9.23e-03, fs:0.72973 (r=0.818,p=0.659),  time:18.741, tt:1086.956\n",
      "Ep:58, loss:0.00002, loss_test:0.09937, lr:9.14e-03, fs:0.72646 (r=0.818,p=0.653),  time:18.735, tt:1105.377\n",
      "Ep:59, loss:0.00002, loss_test:0.09930, lr:9.04e-03, fs:0.72072 (r=0.808,p=0.650),  time:18.743, tt:1124.554\n",
      "Ep:60, loss:0.00002, loss_test:0.09924, lr:8.95e-03, fs:0.72646 (r=0.818,p=0.653),  time:18.743, tt:1143.347\n",
      "Ep:61, loss:0.00002, loss_test:0.09910, lr:8.86e-03, fs:0.73214 (r=0.828,p=0.656),  time:18.753, tt:1162.655\n",
      "Ep:62, loss:0.00002, loss_test:0.09893, lr:8.78e-03, fs:0.73543 (r=0.828,p=0.661),  time:18.767, tt:1182.308\n",
      "Ep:63, loss:0.00002, loss_test:0.09887, lr:8.69e-03, fs:0.72646 (r=0.818,p=0.653),  time:18.760, tt:1200.630\n",
      "Ep:64, loss:0.00002, loss_test:0.09887, lr:8.60e-03, fs:0.72646 (r=0.818,p=0.653),  time:18.776, tt:1220.450\n",
      "Ep:65, loss:0.00002, loss_test:0.09881, lr:8.51e-03, fs:0.72646 (r=0.818,p=0.653),  time:18.764, tt:1238.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.09884, lr:8.43e-03, fs:0.72321 (r=0.818,p=0.648),  time:18.771, tt:1257.662\n",
      "Ep:67, loss:0.00002, loss_test:0.09879, lr:8.35e-03, fs:0.71749 (r=0.808,p=0.645),  time:18.761, tt:1275.763\n",
      "Ep:68, loss:0.00002, loss_test:0.09862, lr:8.26e-03, fs:0.72072 (r=0.808,p=0.650),  time:18.770, tt:1295.109\n",
      "Ep:69, loss:0.00002, loss_test:0.09835, lr:8.18e-03, fs:0.72398 (r=0.808,p=0.656),  time:18.788, tt:1315.173\n",
      "Ep:70, loss:0.00002, loss_test:0.09827, lr:8.10e-03, fs:0.71818 (r=0.798,p=0.653),  time:18.797, tt:1334.598\n",
      "Ep:71, loss:0.00002, loss_test:0.09827, lr:8.02e-03, fs:0.71818 (r=0.798,p=0.653),  time:18.801, tt:1353.681\n",
      "Ep:72, loss:0.00002, loss_test:0.09824, lr:7.94e-03, fs:0.72811 (r=0.798,p=0.669),  time:18.805, tt:1372.731\n",
      "Ep:73, loss:0.00002, loss_test:0.09826, lr:7.86e-03, fs:0.72558 (r=0.788,p=0.672),  time:18.810, tt:1391.915\n",
      "Ep:74, loss:0.00002, loss_test:0.09831, lr:7.78e-03, fs:0.72558 (r=0.788,p=0.672),  time:18.810, tt:1410.729\n",
      "Ep:75, loss:0.00002, loss_test:0.09817, lr:7.70e-03, fs:0.71963 (r=0.778,p=0.670),  time:18.823, tt:1430.554\n",
      "Ep:76, loss:0.00002, loss_test:0.09798, lr:7.62e-03, fs:0.71698 (r=0.768,p=0.673),  time:18.830, tt:1449.907\n",
      "Ep:77, loss:0.00002, loss_test:0.09791, lr:7.55e-03, fs:0.69811 (r=0.747,p=0.655),  time:18.833, tt:1468.955\n",
      "Ep:78, loss:0.00002, loss_test:0.09788, lr:7.47e-03, fs:0.70142 (r=0.747,p=0.661),  time:18.836, tt:1488.013\n",
      "Ep:79, loss:0.00002, loss_test:0.09779, lr:7.40e-03, fs:0.71154 (r=0.747,p=0.679),  time:18.840, tt:1507.217\n",
      "Ep:80, loss:0.00002, loss_test:0.09778, lr:7.32e-03, fs:0.71154 (r=0.747,p=0.679),  time:18.841, tt:1526.102\n",
      "Ep:81, loss:0.00002, loss_test:0.09781, lr:7.25e-03, fs:0.71154 (r=0.747,p=0.679),  time:18.835, tt:1544.444\n",
      "Ep:82, loss:0.00002, loss_test:0.09761, lr:7.18e-03, fs:0.71220 (r=0.737,p=0.689),  time:18.847, tt:1564.291\n",
      "Ep:83, loss:0.00002, loss_test:0.09734, lr:7.11e-03, fs:0.71220 (r=0.737,p=0.689),  time:18.886, tt:1586.459\n",
      "Ep:84, loss:0.00002, loss_test:0.09718, lr:7.03e-03, fs:0.71220 (r=0.737,p=0.689),  time:18.888, tt:1605.518\n",
      "Ep:85, loss:0.00001, loss_test:0.09714, lr:6.96e-03, fs:0.71921 (r=0.737,p=0.702),  time:18.881, tt:1623.730\n",
      "Ep:86, loss:0.00001, loss_test:0.09713, lr:6.89e-03, fs:0.71921 (r=0.737,p=0.702),  time:18.877, tt:1642.336\n",
      "Ep:87, loss:0.00001, loss_test:0.09713, lr:6.83e-03, fs:0.71921 (r=0.737,p=0.702),  time:18.877, tt:1661.216\n",
      "Ep:88, loss:0.00001, loss_test:0.09709, lr:6.76e-03, fs:0.72000 (r=0.727,p=0.713),  time:18.872, tt:1679.633\n",
      "Ep:89, loss:0.00001, loss_test:0.09728, lr:6.69e-03, fs:0.72000 (r=0.727,p=0.713),  time:18.873, tt:1698.609\n",
      "Ep:90, loss:0.00001, loss_test:0.09725, lr:6.62e-03, fs:0.71717 (r=0.717,p=0.717),  time:18.874, tt:1717.547\n",
      "Ep:91, loss:0.00001, loss_test:0.09703, lr:6.56e-03, fs:0.71795 (r=0.707,p=0.729),  time:18.868, tt:1735.848\n",
      "Ep:92, loss:0.00001, loss_test:0.09697, lr:6.49e-03, fs:0.71429 (r=0.707,p=0.722),  time:18.856, tt:1753.564\n",
      "Ep:93, loss:0.00001, loss_test:0.09703, lr:6.43e-03, fs:0.70103 (r=0.687,p=0.716),  time:18.852, tt:1772.120\n",
      "Ep:94, loss:0.00001, loss_test:0.09685, lr:6.36e-03, fs:0.70103 (r=0.687,p=0.716),  time:18.852, tt:1790.951\n",
      "Ep:95, loss:0.00001, loss_test:0.09659, lr:6.30e-03, fs:0.70769 (r=0.697,p=0.719),  time:18.855, tt:1810.056\n",
      "Ep:96, loss:0.00001, loss_test:0.09653, lr:6.24e-03, fs:0.71134 (r=0.697,p=0.726),  time:18.847, tt:1828.114\n",
      "Ep:97, loss:0.00001, loss_test:0.09669, lr:6.17e-03, fs:0.70466 (r=0.687,p=0.723),  time:18.843, tt:1846.633\n",
      "Ep:98, loss:0.00001, loss_test:0.09613, lr:6.11e-03, fs:0.71875 (r=0.697,p=0.742),  time:18.842, tt:1865.393\n",
      "Ep:99, loss:0.00001, loss_test:0.09584, lr:6.05e-03, fs:0.71875 (r=0.697,p=0.742),  time:18.838, tt:1883.813\n",
      "Ep:100, loss:0.00001, loss_test:0.09591, lr:5.99e-03, fs:0.71875 (r=0.697,p=0.742),  time:18.839, tt:1902.711\n",
      "Ep:101, loss:0.00001, loss_test:0.09606, lr:5.93e-03, fs:0.71875 (r=0.697,p=0.742),  time:18.836, tt:1921.282\n",
      "Ep:102, loss:0.00001, loss_test:0.09596, lr:5.87e-03, fs:0.71204 (r=0.687,p=0.739),  time:18.834, tt:1939.889\n",
      "Ep:103, loss:0.00001, loss_test:0.09602, lr:5.81e-03, fs:0.71579 (r=0.687,p=0.747),  time:18.837, tt:1959.078\n",
      "Ep:104, loss:0.00001, loss_test:0.09646, lr:5.75e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.838, tt:1978.032\n",
      "Ep:105, loss:0.00001, loss_test:0.09603, lr:5.70e-03, fs:0.71579 (r=0.687,p=0.747),  time:18.850, tt:1998.057\n",
      "Ep:106, loss:0.00001, loss_test:0.09618, lr:5.64e-03, fs:0.70899 (r=0.677,p=0.744),  time:18.852, tt:2017.160\n",
      "Ep:107, loss:0.00001, loss_test:0.09663, lr:5.58e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.848, tt:2035.616\n",
      "Ep:108, loss:0.00001, loss_test:0.09672, lr:5.53e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.842, tt:2053.789\n",
      "Ep:109, loss:0.00001, loss_test:0.09681, lr:5.47e-03, fs:0.70899 (r=0.677,p=0.744),  time:18.841, tt:2072.555\n",
      "Ep:110, loss:0.00001, loss_test:0.09751, lr:5.42e-03, fs:0.70588 (r=0.667,p=0.750),  time:18.831, tt:2090.283\n",
      "Ep:111, loss:0.00001, loss_test:0.09678, lr:5.36e-03, fs:0.71958 (r=0.687,p=0.756),  time:18.832, tt:2109.196\n",
      "Ep:112, loss:0.00001, loss_test:0.09657, lr:5.31e-03, fs:0.71958 (r=0.687,p=0.756),  time:18.832, tt:2127.961\n",
      "Ep:113, loss:0.00001, loss_test:0.09674, lr:5.26e-03, fs:0.72340 (r=0.687,p=0.764),  time:18.831, tt:2146.732\n",
      "Ep:114, loss:0.00001, loss_test:0.09602, lr:5.20e-03, fs:0.71958 (r=0.687,p=0.756),  time:18.838, tt:2166.324\n",
      "Ep:115, loss:0.00001, loss_test:0.09671, lr:5.15e-03, fs:0.72727 (r=0.687,p=0.773),  time:18.848, tt:2186.317\n",
      "Ep:116, loss:0.00001, loss_test:0.09578, lr:5.10e-03, fs:0.71579 (r=0.687,p=0.747),  time:18.846, tt:2205.027\n",
      "Ep:117, loss:0.00001, loss_test:0.09613, lr:5.05e-03, fs:0.72727 (r=0.687,p=0.773),  time:18.847, tt:2223.903\n",
      "Ep:118, loss:0.00001, loss_test:0.09595, lr:5.00e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.840, tt:2241.920\n",
      "Ep:119, loss:0.00001, loss_test:0.09506, lr:4.95e-03, fs:0.70899 (r=0.677,p=0.744),  time:18.842, tt:2261.071\n",
      "Ep:120, loss:0.00001, loss_test:0.09596, lr:4.90e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.846, tt:2280.325\n",
      "Ep:121, loss:0.00001, loss_test:0.09524, lr:4.85e-03, fs:0.71277 (r=0.677,p=0.753),  time:18.838, tt:2298.259\n",
      "Ep:122, loss:0.00001, loss_test:0.09553, lr:4.80e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.832, tt:2316.392\n",
      "Ep:123, loss:0.00001, loss_test:0.09544, lr:4.75e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.828, tt:2334.680\n",
      "Ep:124, loss:0.00001, loss_test:0.09522, lr:4.71e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.826, tt:2353.260\n",
      "Ep:125, loss:0.00001, loss_test:0.09584, lr:4.66e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.830, tt:2372.542\n",
      "Ep:126, loss:0.00001, loss_test:0.09486, lr:4.61e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.829, tt:2391.315\n",
      "Ep:127, loss:0.00001, loss_test:0.09538, lr:4.57e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.826, tt:2409.781\n",
      "Ep:128, loss:0.00001, loss_test:0.09506, lr:4.52e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.829, tt:2428.992\n",
      "Ep:129, loss:0.00001, loss_test:0.09435, lr:4.48e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.825, tt:2447.269\n",
      "Ep:130, loss:0.00001, loss_test:0.09496, lr:4.43e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.819, tt:2465.333\n",
      "Ep:131, loss:0.00001, loss_test:0.09447, lr:4.39e-03, fs:0.72043 (r=0.677,p=0.770),  time:18.820, tt:2484.181\n",
      "Ep:132, loss:0.00001, loss_test:0.09471, lr:4.34e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.817, tt:2502.689\n",
      "Ep:133, loss:0.00001, loss_test:0.09436, lr:4.30e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.807, tt:2520.086\n",
      "Ep:134, loss:0.00001, loss_test:0.09418, lr:4.26e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.806, tt:2538.830\n",
      "Ep:135, loss:0.00001, loss_test:0.09424, lr:4.21e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.814, tt:2558.763\n",
      "Ep:136, loss:0.00001, loss_test:0.09373, lr:4.17e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.817, tt:2577.864\n",
      "Ep:137, loss:0.00001, loss_test:0.09383, lr:4.13e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.819, tt:2597.050\n",
      "Ep:138, loss:0.00001, loss_test:0.09403, lr:4.09e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.818, tt:2615.711\n",
      "Ep:139, loss:0.00001, loss_test:0.09343, lr:4.05e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.819, tt:2634.641\n",
      "Ep:140, loss:0.00001, loss_test:0.09372, lr:4.01e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.819, tt:2653.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.09350, lr:3.97e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.822, tt:2672.731\n",
      "Ep:142, loss:0.00001, loss_test:0.09344, lr:3.93e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.831, tt:2692.844\n",
      "Ep:143, loss:0.00001, loss_test:0.09329, lr:3.89e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.827, tt:2711.125\n",
      "Ep:144, loss:0.00001, loss_test:0.09306, lr:3.85e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.833, tt:2730.740\n",
      "Ep:145, loss:0.00001, loss_test:0.09315, lr:3.81e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.828, tt:2748.932\n",
      "Ep:146, loss:0.00001, loss_test:0.09286, lr:3.77e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.832, tt:2768.280\n",
      "Ep:147, loss:0.00001, loss_test:0.09339, lr:3.73e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.832, tt:2787.070\n",
      "Ep:148, loss:0.00001, loss_test:0.09260, lr:3.70e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.824, tt:2804.786\n",
      "Ep:149, loss:0.00001, loss_test:0.09271, lr:3.66e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.820, tt:2822.982\n",
      "Ep:150, loss:0.00001, loss_test:0.09222, lr:3.62e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.816, tt:2841.227\n",
      "Ep:151, loss:0.00001, loss_test:0.09224, lr:3.59e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.812, tt:2859.482\n",
      "Ep:152, loss:0.00001, loss_test:0.09217, lr:3.55e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.807, tt:2877.543\n",
      "Ep:153, loss:0.00001, loss_test:0.09176, lr:3.52e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.815, tt:2897.451\n",
      "Ep:154, loss:0.00001, loss_test:0.09193, lr:3.48e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.819, tt:2917.009\n",
      "Ep:155, loss:0.00001, loss_test:0.09160, lr:3.45e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.825, tt:2936.752\n",
      "Ep:156, loss:0.00001, loss_test:0.09131, lr:3.41e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.831, tt:2956.425\n",
      "Ep:157, loss:0.00001, loss_test:0.09167, lr:3.38e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.835, tt:2975.937\n",
      "Ep:158, loss:0.00001, loss_test:0.09097, lr:3.34e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.848, tt:2996.823\n",
      "Ep:159, loss:0.00001, loss_test:0.09148, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.848, tt:3015.696\n",
      "##########Best model found so far##########\n",
      "Ep:160, loss:0.00001, loss_test:0.09124, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.848, tt:3034.603\n",
      "Ep:161, loss:0.00001, loss_test:0.09081, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.852, tt:3054.036\n",
      "Ep:162, loss:0.00001, loss_test:0.09129, lr:3.31e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.845, tt:3071.707\n",
      "Ep:163, loss:0.00001, loss_test:0.09076, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.847, tt:3090.876\n",
      "Ep:164, loss:0.00001, loss_test:0.09067, lr:3.31e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.848, tt:3109.931\n",
      "Ep:165, loss:0.00001, loss_test:0.09095, lr:3.31e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.846, tt:3128.456\n",
      "Ep:166, loss:0.00001, loss_test:0.09051, lr:3.31e-03, fs:0.74725 (r=0.687,p=0.819),  time:18.847, tt:3147.382\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00001, loss_test:0.09059, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.850, tt:3166.873\n",
      "Ep:168, loss:0.00001, loss_test:0.09091, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.862, tt:3187.654\n",
      "Ep:169, loss:0.00001, loss_test:0.09096, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.866, tt:3207.177\n",
      "Ep:170, loss:0.00001, loss_test:0.09066, lr:3.31e-03, fs:0.74725 (r=0.687,p=0.819),  time:18.864, tt:3225.762\n",
      "Ep:171, loss:0.00001, loss_test:0.09084, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.866, tt:3245.030\n",
      "Ep:172, loss:0.00001, loss_test:0.09064, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.866, tt:3263.821\n",
      "Ep:173, loss:0.00001, loss_test:0.09073, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.865, tt:3282.521\n",
      "Ep:174, loss:0.00001, loss_test:0.09090, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.869, tt:3302.063\n",
      "Ep:175, loss:0.00001, loss_test:0.09064, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.873, tt:3321.712\n",
      "Ep:176, loss:0.00001, loss_test:0.09069, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.867, tt:3339.507\n",
      "Ep:177, loss:0.00001, loss_test:0.09064, lr:3.31e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.873, tt:3359.352\n",
      "Ep:178, loss:0.00001, loss_test:0.09078, lr:3.28e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.880, tt:3379.472\n",
      "Ep:179, loss:0.00001, loss_test:0.09055, lr:3.24e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.885, tt:3399.327\n",
      "Ep:180, loss:0.00001, loss_test:0.09067, lr:3.21e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.884, tt:3417.957\n",
      "Ep:181, loss:0.00001, loss_test:0.09057, lr:3.18e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.883, tt:3436.791\n",
      "Ep:182, loss:0.00001, loss_test:0.09053, lr:3.15e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.884, tt:3455.803\n",
      "Ep:183, loss:0.00001, loss_test:0.09086, lr:3.12e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.882, tt:3474.310\n",
      "Ep:184, loss:0.00001, loss_test:0.09037, lr:3.09e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.881, tt:3492.965\n",
      "Ep:185, loss:0.00001, loss_test:0.09083, lr:3.05e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.884, tt:3512.406\n",
      "Ep:186, loss:0.00001, loss_test:0.09058, lr:3.02e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.887, tt:3531.894\n",
      "Ep:187, loss:0.00000, loss_test:0.09068, lr:2.99e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.885, tt:3550.411\n",
      "Ep:188, loss:0.00000, loss_test:0.09052, lr:2.96e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.893, tt:3570.778\n",
      "Ep:189, loss:0.00000, loss_test:0.09071, lr:2.93e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.890, tt:3589.192\n",
      "Ep:190, loss:0.00000, loss_test:0.09045, lr:2.90e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.891, tt:3608.206\n",
      "Ep:191, loss:0.00000, loss_test:0.09088, lr:2.88e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.895, tt:3627.819\n",
      "Ep:192, loss:0.00000, loss_test:0.09062, lr:2.85e-03, fs:0.74725 (r=0.687,p=0.819),  time:18.900, tt:3647.747\n",
      "Ep:193, loss:0.00000, loss_test:0.09077, lr:2.82e-03, fs:0.74725 (r=0.687,p=0.819),  time:18.906, tt:3667.728\n",
      "Ep:194, loss:0.00000, loss_test:0.09080, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.910, tt:3687.435\n",
      "##########Best model found so far##########\n",
      "Ep:195, loss:0.00000, loss_test:0.09064, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.935, tt:3711.249\n",
      "Ep:196, loss:0.00000, loss_test:0.09091, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.939, tt:3731.028\n",
      "Ep:197, loss:0.00000, loss_test:0.09064, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.939, tt:3749.877\n",
      "Ep:198, loss:0.00000, loss_test:0.09096, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.941, tt:3769.357\n",
      "Ep:199, loss:0.00000, loss_test:0.09075, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.944, tt:3788.742\n",
      "Ep:200, loss:0.00000, loss_test:0.09108, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.947, tt:3808.372\n",
      "Ep:201, loss:0.00000, loss_test:0.09092, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.948, tt:3827.426\n",
      "Ep:202, loss:0.00000, loss_test:0.09106, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.951, tt:3847.064\n",
      "Ep:203, loss:0.00000, loss_test:0.09111, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.952, tt:3866.262\n",
      "Ep:204, loss:0.00000, loss_test:0.09104, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.957, tt:3886.095\n",
      "Ep:205, loss:0.00000, loss_test:0.09110, lr:2.79e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.956, tt:3905.007\n",
      "Ep:206, loss:0.00000, loss_test:0.09075, lr:2.76e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.959, tt:3924.530\n",
      "Ep:207, loss:0.00000, loss_test:0.09139, lr:2.73e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.959, tt:3943.484\n",
      "Ep:208, loss:0.00000, loss_test:0.09105, lr:2.71e-03, fs:0.75138 (r=0.687,p=0.829),  time:18.962, tt:3963.109\n",
      "Ep:209, loss:0.00000, loss_test:0.09120, lr:2.68e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.968, tt:3983.257\n",
      "Ep:210, loss:0.00000, loss_test:0.09146, lr:2.65e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.968, tt:4002.142\n",
      "Ep:211, loss:0.00000, loss_test:0.09120, lr:2.63e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.971, tt:4021.951\n",
      "Ep:212, loss:0.00000, loss_test:0.09159, lr:2.60e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.974, tt:4041.374\n",
      "Ep:213, loss:0.00000, loss_test:0.09152, lr:2.57e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.976, tt:4060.900\n",
      "Ep:214, loss:0.00000, loss_test:0.09145, lr:2.55e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.980, tt:4080.782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:215, loss:0.00000, loss_test:0.09168, lr:2.52e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.988, tt:4101.391\n",
      "Ep:216, loss:0.00000, loss_test:0.09137, lr:2.50e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.989, tt:4120.581\n",
      "Ep:217, loss:0.00000, loss_test:0.09166, lr:2.47e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.991, tt:4140.146\n",
      "Ep:218, loss:0.00000, loss_test:0.09179, lr:2.45e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.997, tt:4160.404\n",
      "Ep:219, loss:0.00000, loss_test:0.09169, lr:2.42e-03, fs:0.74860 (r=0.677,p=0.838),  time:19.001, tt:4180.176\n",
      "Ep:220, loss:0.00000, loss_test:0.09186, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.002, tt:4199.404\n",
      "##########Best model found so far##########\n",
      "Ep:221, loss:0.00000, loss_test:0.09188, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.007, tt:4219.558\n",
      "Ep:222, loss:0.00000, loss_test:0.09185, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.011, tt:4239.532\n",
      "Ep:223, loss:0.00000, loss_test:0.09205, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.016, tt:4259.636\n",
      "Ep:224, loss:0.00000, loss_test:0.09213, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.021, tt:4279.626\n",
      "Ep:225, loss:0.00000, loss_test:0.09189, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.016, tt:4297.576\n",
      "Ep:226, loss:0.00000, loss_test:0.09212, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.016, tt:4316.709\n",
      "Ep:227, loss:0.00000, loss_test:0.09208, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.020, tt:4336.466\n",
      "Ep:228, loss:0.00000, loss_test:0.09229, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.024, tt:4356.538\n",
      "Ep:229, loss:0.00000, loss_test:0.09229, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.024, tt:4375.627\n",
      "Ep:230, loss:0.00000, loss_test:0.09232, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.023, tt:4394.231\n",
      "Ep:231, loss:0.00000, loss_test:0.09235, lr:2.40e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.024, tt:4413.617\n",
      "Ep:232, loss:0.00000, loss_test:0.09250, lr:2.38e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.025, tt:4432.875\n",
      "Ep:233, loss:0.00000, loss_test:0.09231, lr:2.35e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.019, tt:4450.527\n",
      "Ep:234, loss:0.00000, loss_test:0.09273, lr:2.33e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.015, tt:4468.592\n",
      "Ep:235, loss:0.00000, loss_test:0.09251, lr:2.31e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.020, tt:4488.624\n",
      "Ep:236, loss:0.00000, loss_test:0.09242, lr:2.28e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.018, tt:4507.223\n",
      "Ep:237, loss:0.00000, loss_test:0.09295, lr:2.26e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.016, tt:4525.856\n",
      "Ep:238, loss:0.00000, loss_test:0.09282, lr:2.24e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.013, tt:4544.092\n",
      "Ep:239, loss:0.00000, loss_test:0.09242, lr:2.21e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.013, tt:4563.205\n",
      "Ep:240, loss:0.00000, loss_test:0.09310, lr:2.19e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.013, tt:4582.140\n",
      "Ep:241, loss:0.00000, loss_test:0.09313, lr:2.17e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.016, tt:4601.922\n",
      "Ep:242, loss:0.00000, loss_test:0.09261, lr:2.15e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.016, tt:4620.836\n",
      "Ep:243, loss:0.00000, loss_test:0.09290, lr:2.13e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.017, tt:4640.266\n",
      "Ep:244, loss:0.00000, loss_test:0.09314, lr:2.11e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.020, tt:4659.943\n",
      "Ep:245, loss:0.00000, loss_test:0.09277, lr:2.08e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.022, tt:4679.459\n",
      "Ep:246, loss:0.00000, loss_test:0.09282, lr:2.06e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.024, tt:4698.865\n",
      "Ep:247, loss:0.00000, loss_test:0.09324, lr:2.04e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.023, tt:4717.585\n",
      "Ep:248, loss:0.00000, loss_test:0.09321, lr:2.02e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.023, tt:4736.836\n",
      "Ep:249, loss:0.00000, loss_test:0.09291, lr:2.00e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.025, tt:4756.210\n",
      "Ep:250, loss:0.00000, loss_test:0.09320, lr:1.98e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.025, tt:4775.237\n",
      "Ep:251, loss:0.00000, loss_test:0.09320, lr:1.96e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.022, tt:4793.586\n",
      "Ep:252, loss:0.00000, loss_test:0.09296, lr:1.94e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.026, tt:4813.502\n",
      "Ep:253, loss:0.00000, loss_test:0.09328, lr:1.92e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.020, tt:4831.189\n",
      "Ep:254, loss:0.00000, loss_test:0.09321, lr:1.90e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.019, tt:4849.723\n",
      "Ep:255, loss:0.00000, loss_test:0.09295, lr:1.89e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.018, tt:4868.707\n",
      "Ep:256, loss:0.00000, loss_test:0.09325, lr:1.87e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.017, tt:4887.478\n",
      "Ep:257, loss:0.00000, loss_test:0.09318, lr:1.85e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.018, tt:4906.774\n",
      "Ep:258, loss:0.00000, loss_test:0.09283, lr:1.83e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.018, tt:4925.751\n",
      "Ep:259, loss:0.00000, loss_test:0.09302, lr:1.81e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.018, tt:4944.737\n",
      "Ep:260, loss:0.00000, loss_test:0.09320, lr:1.79e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.018, tt:4963.773\n",
      "Ep:261, loss:0.00000, loss_test:0.09284, lr:1.78e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.017, tt:4982.435\n",
      "Ep:262, loss:0.00000, loss_test:0.09289, lr:1.76e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.020, tt:5002.196\n",
      "Ep:263, loss:0.00000, loss_test:0.09303, lr:1.74e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.024, tt:5022.227\n",
      "Ep:264, loss:0.00000, loss_test:0.09280, lr:1.72e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.022, tt:5040.943\n",
      "Ep:265, loss:0.00000, loss_test:0.09264, lr:1.71e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.022, tt:5059.910\n",
      "Ep:266, loss:0.00000, loss_test:0.09297, lr:1.69e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.025, tt:5079.702\n",
      "Ep:267, loss:0.00000, loss_test:0.09284, lr:1.67e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.030, tt:5099.993\n",
      "Ep:268, loss:0.00000, loss_test:0.09255, lr:1.65e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.026, tt:5117.952\n",
      "Ep:269, loss:0.00000, loss_test:0.09267, lr:1.64e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.025, tt:5136.706\n",
      "Ep:270, loss:0.00000, loss_test:0.09278, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.028, tt:5156.686\n",
      "##########Best model found so far##########\n",
      "Ep:271, loss:0.00000, loss_test:0.09250, lr:1.62e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.030, tt:5176.047\n",
      "Ep:272, loss:0.00000, loss_test:0.09246, lr:1.62e-03, fs:0.75281 (r=0.677,p=0.848),  time:19.028, tt:5194.752\n",
      "Ep:273, loss:0.00000, loss_test:0.09262, lr:1.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:19.024, tt:5212.574\n",
      "##########Best model found so far##########\n",
      "Ep:274, loss:0.00000, loss_test:0.09240, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.019, tt:5230.233\n",
      "Ep:275, loss:0.00000, loss_test:0.09235, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:19.011, tt:5246.955\n",
      "Ep:276, loss:0.00000, loss_test:0.09273, lr:1.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:19.000, tt:5263.119\n",
      "Ep:277, loss:0.00000, loss_test:0.09257, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.994, tt:5280.452\n",
      "Ep:278, loss:0.00000, loss_test:0.09234, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.988, tt:5297.673\n",
      "Ep:279, loss:0.00000, loss_test:0.09242, lr:1.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.984, tt:5315.415\n",
      "Ep:280, loss:0.00000, loss_test:0.09233, lr:1.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.977, tt:5332.532\n",
      "Ep:281, loss:0.00000, loss_test:0.09231, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.973, tt:5350.261\n",
      "Ep:282, loss:0.00000, loss_test:0.09254, lr:1.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.963, tt:5366.415\n",
      "Ep:283, loss:0.00000, loss_test:0.09235, lr:1.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.958, tt:5384.195\n",
      "Ep:284, loss:0.00000, loss_test:0.09201, lr:1.62e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.965, tt:5405.087\n",
      "Ep:285, loss:0.00000, loss_test:0.09226, lr:1.61e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.952, tt:5420.246\n",
      "Ep:286, loss:0.00000, loss_test:0.09225, lr:1.59e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.946, tt:5437.372\n",
      "Ep:287, loss:0.00000, loss_test:0.09211, lr:1.57e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.937, tt:5453.853\n",
      "Ep:288, loss:0.00000, loss_test:0.09249, lr:1.56e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.932, tt:5471.408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:289, loss:0.00000, loss_test:0.09235, lr:1.54e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.930, tt:5489.737\n",
      "Ep:290, loss:0.00000, loss_test:0.09202, lr:1.53e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.924, tt:5506.936\n",
      "Ep:291, loss:0.00000, loss_test:0.09225, lr:1.51e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.919, tt:5524.400\n",
      "Ep:292, loss:0.00000, loss_test:0.09230, lr:1.50e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.916, tt:5542.320\n",
      "Ep:293, loss:0.00000, loss_test:0.09204, lr:1.48e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.915, tt:5560.871\n",
      "Ep:294, loss:0.00000, loss_test:0.09213, lr:1.47e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.907, tt:5577.500\n",
      "Ep:295, loss:0.00000, loss_test:0.09230, lr:1.45e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.887, tt:5590.449\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14197, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.217, tt:13.217\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14173, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.089, tt:28.178\n",
      "Ep:2, loss:0.00004, loss_test:0.14137, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.619, tt:43.858\n",
      "Ep:3, loss:0.00004, loss_test:0.14088, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.907, tt:59.627\n",
      "Ep:4, loss:0.00004, loss_test:0.14026, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.079, tt:75.393\n",
      "Ep:5, loss:0.00004, loss_test:0.13949, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.119, tt:90.712\n",
      "Ep:6, loss:0.00004, loss_test:0.13854, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:15.119, tt:105.836\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.13740, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:15.259, tt:122.070\n",
      "Ep:8, loss:0.00004, loss_test:0.13600, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:15.179, tt:136.610\n",
      "Ep:9, loss:0.00004, loss_test:0.13427, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:15.256, tt:152.565\n",
      "Ep:10, loss:0.00004, loss_test:0.13204, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:15.215, tt:167.366\n",
      "Ep:11, loss:0.00004, loss_test:0.12927, lr:1.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:15.241, tt:182.891\n",
      "Ep:12, loss:0.00004, loss_test:0.12590, lr:1.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:15.485, tt:201.299\n",
      "Ep:13, loss:0.00004, loss_test:0.12164, lr:1.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:15.526, tt:217.369\n",
      "Ep:14, loss:0.00003, loss_test:0.11702, lr:1.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:15.545, tt:233.176\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.11326, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:15.477, tt:247.632\n",
      "Ep:16, loss:0.00003, loss_test:0.11106, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:15.453, tt:262.692\n",
      "Ep:17, loss:0.00003, loss_test:0.11045, lr:1.00e-02, fs:0.65241 (r=0.616,p=0.693),  time:15.439, tt:277.895\n",
      "Ep:18, loss:0.00003, loss_test:0.10942, lr:1.00e-02, fs:0.66310 (r=0.626,p=0.705),  time:15.442, tt:293.406\n",
      "Ep:19, loss:0.00003, loss_test:0.10875, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:15.460, tt:309.193\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.10872, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:15.473, tt:324.925\n",
      "Ep:21, loss:0.00003, loss_test:0.10937, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:15.470, tt:340.347\n",
      "Ep:22, loss:0.00003, loss_test:0.10910, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:15.456, tt:355.486\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10736, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:15.443, tt:370.635\n",
      "Ep:24, loss:0.00003, loss_test:0.10530, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:15.471, tt:386.786\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.10392, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:15.452, tt:401.752\n",
      "Ep:26, loss:0.00003, loss_test:0.10358, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:15.451, tt:417.171\n",
      "Ep:27, loss:0.00003, loss_test:0.10338, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:15.448, tt:432.542\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.10336, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:15.444, tt:447.887\n",
      "Ep:29, loss:0.00003, loss_test:0.10361, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:15.401, tt:462.034\n",
      "Ep:30, loss:0.00003, loss_test:0.10359, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:15.411, tt:477.745\n",
      "Ep:31, loss:0.00003, loss_test:0.10286, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:15.415, tt:493.293\n",
      "Ep:32, loss:0.00003, loss_test:0.10195, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:15.399, tt:508.154\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.10119, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:15.381, tt:522.939\n",
      "Ep:34, loss:0.00003, loss_test:0.10084, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:15.372, tt:538.019\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.10079, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:15.386, tt:553.882\n",
      "Ep:36, loss:0.00002, loss_test:0.10091, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:15.382, tt:569.128\n",
      "Ep:37, loss:0.00002, loss_test:0.10110, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:15.398, tt:585.118\n",
      "Ep:38, loss:0.00002, loss_test:0.10095, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:15.381, tt:599.853\n",
      "Ep:39, loss:0.00002, loss_test:0.10042, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:15.377, tt:615.084\n",
      "Ep:40, loss:0.00002, loss_test:0.09978, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:15.359, tt:629.703\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.09919, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:15.377, tt:645.836\n",
      "Ep:42, loss:0.00002, loss_test:0.09875, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:15.371, tt:660.964\n",
      "Ep:43, loss:0.00002, loss_test:0.09843, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:15.389, tt:677.136\n",
      "Ep:44, loss:0.00002, loss_test:0.09811, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:15.368, tt:691.563\n",
      "Ep:45, loss:0.00002, loss_test:0.09756, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:15.379, tt:707.426\n",
      "Ep:46, loss:0.00002, loss_test:0.09681, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:15.394, tt:723.519\n",
      "Ep:47, loss:0.00002, loss_test:0.09614, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:15.389, tt:738.686\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09560, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:15.405, tt:754.859\n",
      "Ep:49, loss:0.00002, loss_test:0.09529, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:15.427, tt:771.338\n",
      "Ep:50, loss:0.00002, loss_test:0.09512, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:15.436, tt:787.242\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.09488, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:15.440, tt:802.865\n",
      "Ep:52, loss:0.00002, loss_test:0.09456, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:15.446, tt:818.628\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.09425, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:15.433, tt:833.371\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.09394, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:15.415, tt:847.799\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.09370, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:15.409, tt:862.894\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.09350, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:15.409, tt:878.292\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.09329, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:15.408, tt:893.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00002, loss_test:0.09295, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:15.413, tt:909.393\n",
      "Ep:59, loss:0.00002, loss_test:0.09257, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:15.410, tt:924.625\n",
      "Ep:60, loss:0.00002, loss_test:0.09214, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:15.416, tt:940.383\n",
      "Ep:61, loss:0.00002, loss_test:0.09176, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:15.417, tt:955.871\n",
      "Ep:62, loss:0.00002, loss_test:0.09143, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.415, tt:971.141\n",
      "Ep:63, loss:0.00002, loss_test:0.09110, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.423, tt:987.052\n",
      "Ep:64, loss:0.00002, loss_test:0.09077, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.421, tt:1002.353\n",
      "Ep:65, loss:0.00002, loss_test:0.09043, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:15.432, tt:1018.525\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.09017, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:15.433, tt:1034.033\n",
      "Ep:67, loss:0.00002, loss_test:0.08996, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.442, tt:1050.026\n",
      "Ep:68, loss:0.00002, loss_test:0.08972, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.440, tt:1065.349\n",
      "Ep:69, loss:0.00002, loss_test:0.08946, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:15.434, tt:1080.400\n",
      "Ep:70, loss:0.00002, loss_test:0.08923, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:15.423, tt:1095.024\n",
      "Ep:71, loss:0.00002, loss_test:0.08897, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:15.415, tt:1109.854\n",
      "Ep:72, loss:0.00002, loss_test:0.08872, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.392, tt:1123.587\n",
      "Ep:73, loss:0.00002, loss_test:0.08847, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.385, tt:1138.506\n",
      "Ep:74, loss:0.00002, loss_test:0.08821, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:15.385, tt:1153.910\n",
      "Ep:75, loss:0.00002, loss_test:0.08793, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:15.388, tt:1169.488\n",
      "Ep:76, loss:0.00002, loss_test:0.08768, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:15.377, tt:1184.066\n",
      "Ep:77, loss:0.00002, loss_test:0.08748, lr:9.90e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.370, tt:1198.889\n",
      "Ep:78, loss:0.00001, loss_test:0.08728, lr:9.80e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.377, tt:1214.782\n",
      "Ep:79, loss:0.00001, loss_test:0.08705, lr:9.70e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.366, tt:1229.311\n",
      "Ep:80, loss:0.00001, loss_test:0.08677, lr:9.61e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.359, tt:1244.108\n",
      "Ep:81, loss:0.00001, loss_test:0.08648, lr:9.51e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.365, tt:1259.907\n",
      "Ep:82, loss:0.00001, loss_test:0.08622, lr:9.41e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.371, tt:1275.756\n",
      "Ep:83, loss:0.00001, loss_test:0.08603, lr:9.32e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.378, tt:1291.751\n",
      "Ep:84, loss:0.00001, loss_test:0.08583, lr:9.23e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.379, tt:1307.194\n",
      "Ep:85, loss:0.00001, loss_test:0.08566, lr:9.14e-03, fs:0.76847 (r=0.788,p=0.750),  time:15.391, tt:1323.629\n",
      "Ep:86, loss:0.00001, loss_test:0.08551, lr:9.04e-03, fs:0.76617 (r=0.778,p=0.755),  time:15.404, tt:1340.168\n",
      "Ep:87, loss:0.00001, loss_test:0.08534, lr:8.95e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.415, tt:1356.523\n",
      "Ep:88, loss:0.00001, loss_test:0.08513, lr:8.86e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.424, tt:1372.739\n",
      "Ep:89, loss:0.00001, loss_test:0.08494, lr:8.78e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.431, tt:1388.761\n",
      "Ep:90, loss:0.00001, loss_test:0.08471, lr:8.69e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.444, tt:1405.376\n",
      "Ep:91, loss:0.00001, loss_test:0.08446, lr:8.60e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.444, tt:1420.831\n",
      "Ep:92, loss:0.00001, loss_test:0.08424, lr:8.51e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.445, tt:1436.345\n",
      "Ep:93, loss:0.00001, loss_test:0.08407, lr:8.43e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.455, tt:1452.816\n",
      "Ep:94, loss:0.00001, loss_test:0.08389, lr:8.35e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.469, tt:1469.567\n",
      "Ep:95, loss:0.00001, loss_test:0.08370, lr:8.26e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.471, tt:1485.208\n",
      "Ep:96, loss:0.00001, loss_test:0.08358, lr:8.18e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.468, tt:1500.383\n",
      "Ep:97, loss:0.00001, loss_test:0.08351, lr:8.10e-03, fs:0.77612 (r=0.788,p=0.765),  time:15.471, tt:1516.179\n",
      "Ep:98, loss:0.00001, loss_test:0.08347, lr:8.02e-03, fs:0.77612 (r=0.788,p=0.765),  time:15.466, tt:1531.102\n",
      "Ep:99, loss:0.00001, loss_test:0.08341, lr:7.94e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.463, tt:1546.324\n",
      "Ep:100, loss:0.00001, loss_test:0.08329, lr:7.86e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.464, tt:1561.826\n",
      "Ep:101, loss:0.00001, loss_test:0.08317, lr:7.78e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.462, tt:1577.093\n",
      "Ep:102, loss:0.00001, loss_test:0.08303, lr:7.70e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.457, tt:1592.041\n",
      "Ep:103, loss:0.00001, loss_test:0.08289, lr:7.62e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.460, tt:1607.860\n",
      "Ep:104, loss:0.00001, loss_test:0.08278, lr:7.55e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.452, tt:1622.451\n",
      "Ep:105, loss:0.00001, loss_test:0.08272, lr:7.47e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.457, tt:1638.454\n",
      "Ep:106, loss:0.00001, loss_test:0.08264, lr:7.40e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.458, tt:1653.961\n",
      "Ep:107, loss:0.00001, loss_test:0.08255, lr:7.32e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.467, tt:1670.433\n",
      "Ep:108, loss:0.00001, loss_test:0.08249, lr:7.25e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.460, tt:1685.164\n",
      "Ep:109, loss:0.00001, loss_test:0.08246, lr:7.18e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.459, tt:1700.436\n",
      "Ep:110, loss:0.00001, loss_test:0.08248, lr:7.11e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.462, tt:1716.311\n",
      "Ep:111, loss:0.00001, loss_test:0.08245, lr:7.03e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.461, tt:1731.678\n",
      "Ep:112, loss:0.00001, loss_test:0.08240, lr:6.96e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.475, tt:1748.619\n",
      "Ep:113, loss:0.00001, loss_test:0.08236, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.475, tt:1764.198\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00001, loss_test:0.08238, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.476, tt:1779.694\n",
      "Ep:115, loss:0.00001, loss_test:0.08232, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.469, tt:1794.357\n",
      "Ep:116, loss:0.00001, loss_test:0.08218, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.476, tt:1810.672\n",
      "Ep:117, loss:0.00001, loss_test:0.08206, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.480, tt:1826.599\n",
      "Ep:118, loss:0.00001, loss_test:0.08195, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.475, tt:1841.507\n",
      "Ep:119, loss:0.00001, loss_test:0.08183, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.477, tt:1857.254\n",
      "Ep:120, loss:0.00001, loss_test:0.08170, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.480, tt:1873.068\n",
      "Ep:121, loss:0.00001, loss_test:0.08154, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.474, tt:1887.848\n",
      "Ep:122, loss:0.00001, loss_test:0.08139, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.475, tt:1903.395\n",
      "Ep:123, loss:0.00001, loss_test:0.08126, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.466, tt:1917.805\n",
      "Ep:124, loss:0.00001, loss_test:0.08116, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.464, tt:1932.984\n",
      "Ep:125, loss:0.00001, loss_test:0.08107, lr:6.83e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.458, tt:1947.699\n",
      "Ep:126, loss:0.00001, loss_test:0.08101, lr:6.76e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.466, tt:1964.126\n",
      "Ep:127, loss:0.00001, loss_test:0.08097, lr:6.69e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.469, tt:1980.073\n",
      "Ep:128, loss:0.00001, loss_test:0.08082, lr:6.62e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.476, tt:1996.468\n",
      "Ep:129, loss:0.00001, loss_test:0.08073, lr:6.56e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.469, tt:2010.999\n",
      "Ep:130, loss:0.00001, loss_test:0.08074, lr:6.49e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.469, tt:2026.375\n",
      "Ep:131, loss:0.00001, loss_test:0.08069, lr:6.43e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.466, tt:2041.531\n",
      "Ep:132, loss:0.00001, loss_test:0.08056, lr:6.36e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.464, tt:2056.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.08040, lr:6.30e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.460, tt:2071.576\n",
      "Ep:134, loss:0.00001, loss_test:0.08029, lr:6.24e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.468, tt:2088.244\n",
      "Ep:135, loss:0.00001, loss_test:0.08026, lr:6.17e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.461, tt:2102.673\n",
      "Ep:136, loss:0.00001, loss_test:0.08023, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.455, tt:2117.401\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00001, loss_test:0.08015, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.450, tt:2132.056\n",
      "Ep:138, loss:0.00001, loss_test:0.08007, lr:6.11e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.452, tt:2147.840\n",
      "Ep:139, loss:0.00001, loss_test:0.08004, lr:6.11e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.457, tt:2163.998\n",
      "Ep:140, loss:0.00001, loss_test:0.08005, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.461, tt:2180.020\n",
      "Ep:141, loss:0.00001, loss_test:0.08001, lr:6.11e-03, fs:0.78173 (r=0.778,p=0.786),  time:15.462, tt:2195.539\n",
      "Ep:142, loss:0.00001, loss_test:0.07994, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.457, tt:2210.308\n",
      "Ep:143, loss:0.00001, loss_test:0.07987, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.459, tt:2226.051\n",
      "Ep:144, loss:0.00001, loss_test:0.07982, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.451, tt:2240.334\n",
      "Ep:145, loss:0.00001, loss_test:0.07975, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.449, tt:2255.585\n",
      "Ep:146, loss:0.00001, loss_test:0.07967, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.444, tt:2270.342\n",
      "Ep:147, loss:0.00001, loss_test:0.07967, lr:6.11e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.451, tt:2286.733\n",
      "Ep:148, loss:0.00001, loss_test:0.07968, lr:6.05e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.457, tt:2303.048\n",
      "Ep:149, loss:0.00001, loss_test:0.07967, lr:5.99e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.460, tt:2318.963\n",
      "Ep:150, loss:0.00001, loss_test:0.07967, lr:5.93e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.464, tt:2335.063\n",
      "Ep:151, loss:0.00001, loss_test:0.07967, lr:5.87e-03, fs:0.78571 (r=0.778,p=0.794),  time:15.472, tt:2351.722\n",
      "Ep:152, loss:0.00001, loss_test:0.07965, lr:5.81e-03, fs:0.78351 (r=0.768,p=0.800),  time:15.471, tt:2367.040\n",
      "Ep:153, loss:0.00001, loss_test:0.07955, lr:5.75e-03, fs:0.78974 (r=0.778,p=0.802),  time:15.471, tt:2382.604\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00001, loss_test:0.07947, lr:5.75e-03, fs:0.79381 (r=0.778,p=0.811),  time:15.473, tt:2398.376\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.07944, lr:5.75e-03, fs:0.79381 (r=0.778,p=0.811),  time:15.479, tt:2414.784\n",
      "Ep:156, loss:0.00001, loss_test:0.07942, lr:5.75e-03, fs:0.79381 (r=0.778,p=0.811),  time:15.487, tt:2431.419\n",
      "Ep:157, loss:0.00001, loss_test:0.07943, lr:5.75e-03, fs:0.78756 (r=0.768,p=0.809),  time:15.494, tt:2448.037\n",
      "Ep:158, loss:0.00001, loss_test:0.07943, lr:5.75e-03, fs:0.78756 (r=0.768,p=0.809),  time:15.499, tt:2464.289\n",
      "Ep:159, loss:0.00001, loss_test:0.07939, lr:5.75e-03, fs:0.78756 (r=0.768,p=0.809),  time:15.500, tt:2479.930\n",
      "Ep:160, loss:0.00001, loss_test:0.07933, lr:5.75e-03, fs:0.79167 (r=0.768,p=0.817),  time:15.496, tt:2494.929\n",
      "Ep:161, loss:0.00001, loss_test:0.07932, lr:5.75e-03, fs:0.78534 (r=0.758,p=0.815),  time:15.493, tt:2509.896\n",
      "Ep:162, loss:0.00001, loss_test:0.07935, lr:5.75e-03, fs:0.78534 (r=0.758,p=0.815),  time:15.496, tt:2525.922\n",
      "Ep:163, loss:0.00001, loss_test:0.07926, lr:5.75e-03, fs:0.78534 (r=0.758,p=0.815),  time:15.504, tt:2542.609\n",
      "Ep:164, loss:0.00001, loss_test:0.07926, lr:5.75e-03, fs:0.78534 (r=0.758,p=0.815),  time:15.507, tt:2558.697\n",
      "Ep:165, loss:0.00001, loss_test:0.07925, lr:5.75e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.502, tt:2573.346\n",
      "Ep:166, loss:0.00001, loss_test:0.07920, lr:5.70e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.507, tt:2589.646\n",
      "Ep:167, loss:0.00001, loss_test:0.07916, lr:5.64e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.507, tt:2605.214\n",
      "Ep:168, loss:0.00001, loss_test:0.07907, lr:5.58e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.512, tt:2621.576\n",
      "Ep:169, loss:0.00001, loss_test:0.07901, lr:5.53e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.512, tt:2636.999\n",
      "Ep:170, loss:0.00001, loss_test:0.07902, lr:5.47e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.508, tt:2651.840\n",
      "Ep:171, loss:0.00001, loss_test:0.07896, lr:5.42e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.505, tt:2666.903\n",
      "Ep:172, loss:0.00001, loss_test:0.07892, lr:5.36e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.505, tt:2682.374\n",
      "Ep:173, loss:0.00001, loss_test:0.07894, lr:5.31e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.505, tt:2697.907\n",
      "Ep:174, loss:0.00001, loss_test:0.07883, lr:5.26e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.497, tt:2712.032\n",
      "Ep:175, loss:0.00001, loss_test:0.07885, lr:5.20e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.495, tt:2727.115\n",
      "Ep:176, loss:0.00001, loss_test:0.07885, lr:5.15e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.498, tt:2743.133\n",
      "Ep:177, loss:0.00001, loss_test:0.07878, lr:5.10e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.499, tt:2758.884\n",
      "Ep:178, loss:0.00001, loss_test:0.07879, lr:5.05e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.498, tt:2774.083\n",
      "Ep:179, loss:0.00001, loss_test:0.07882, lr:5.00e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.498, tt:2789.558\n",
      "Ep:180, loss:0.00001, loss_test:0.07880, lr:4.95e-03, fs:0.79581 (r=0.768,p=0.826),  time:15.497, tt:2804.938\n",
      "##########Best model found so far##########\n",
      "Ep:181, loss:0.00001, loss_test:0.07875, lr:4.95e-03, fs:0.79581 (r=0.768,p=0.826),  time:15.499, tt:2820.857\n",
      "Ep:182, loss:0.00001, loss_test:0.07877, lr:4.95e-03, fs:0.79581 (r=0.768,p=0.826),  time:15.492, tt:2835.088\n",
      "Ep:183, loss:0.00001, loss_test:0.07873, lr:4.95e-03, fs:0.79581 (r=0.768,p=0.826),  time:15.484, tt:2849.080\n",
      "Ep:184, loss:0.00001, loss_test:0.07868, lr:4.95e-03, fs:0.79581 (r=0.768,p=0.826),  time:15.485, tt:2864.799\n",
      "Ep:185, loss:0.00001, loss_test:0.07867, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.492, tt:2881.523\n",
      "Ep:186, loss:0.00001, loss_test:0.07859, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.492, tt:2896.999\n",
      "Ep:187, loss:0.00001, loss_test:0.07856, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.494, tt:2912.962\n",
      "Ep:188, loss:0.00001, loss_test:0.07859, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.500, tt:2929.490\n",
      "Ep:189, loss:0.00001, loss_test:0.07846, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.500, tt:2944.914\n",
      "Ep:190, loss:0.00001, loss_test:0.07842, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.500, tt:2960.518\n",
      "Ep:191, loss:0.00001, loss_test:0.07849, lr:4.95e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.504, tt:2976.735\n",
      "Ep:192, loss:0.00001, loss_test:0.07840, lr:4.90e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.502, tt:2991.810\n",
      "Ep:193, loss:0.00001, loss_test:0.07836, lr:4.85e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.505, tt:3007.912\n",
      "Ep:194, loss:0.00001, loss_test:0.07847, lr:4.80e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.508, tt:3024.076\n",
      "Ep:195, loss:0.00001, loss_test:0.07843, lr:4.75e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.508, tt:3039.628\n",
      "Ep:196, loss:0.00001, loss_test:0.07837, lr:4.71e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.512, tt:3055.799\n",
      "Ep:197, loss:0.00001, loss_test:0.07842, lr:4.66e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.516, tt:3072.083\n",
      "Ep:198, loss:0.00001, loss_test:0.07836, lr:4.61e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.511, tt:3086.687\n",
      "Ep:199, loss:0.00001, loss_test:0.07828, lr:4.57e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.509, tt:3101.794\n",
      "Ep:200, loss:0.00001, loss_test:0.07839, lr:4.52e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.511, tt:3117.636\n",
      "Ep:201, loss:0.00001, loss_test:0.07842, lr:4.48e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.513, tt:3133.623\n",
      "Ep:202, loss:0.00001, loss_test:0.07827, lr:4.43e-03, fs:0.78947 (r=0.758,p=0.824),  time:15.517, tt:3150.035\n",
      "Ep:203, loss:0.00001, loss_test:0.07827, lr:4.39e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.520, tt:3165.981\n",
      "Ep:204, loss:0.00001, loss_test:0.07836, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.525, tt:3182.625\n",
      "##########Best model found so far##########\n",
      "Ep:205, loss:0.00001, loss_test:0.07829, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.527, tt:3198.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00001, loss_test:0.07815, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.526, tt:3213.887\n",
      "Ep:207, loss:0.00001, loss_test:0.07825, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.530, tt:3230.183\n",
      "Ep:208, loss:0.00001, loss_test:0.07825, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.532, tt:3246.206\n",
      "Ep:209, loss:0.00001, loss_test:0.07812, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.529, tt:3261.130\n",
      "Ep:210, loss:0.00001, loss_test:0.07810, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.525, tt:3275.827\n",
      "Ep:211, loss:0.00001, loss_test:0.07810, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.529, tt:3292.170\n",
      "Ep:212, loss:0.00001, loss_test:0.07802, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.530, tt:3307.968\n",
      "Ep:213, loss:0.00001, loss_test:0.07796, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.536, tt:3324.627\n",
      "Ep:214, loss:0.00001, loss_test:0.07802, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.533, tt:3339.532\n",
      "Ep:215, loss:0.00001, loss_test:0.07795, lr:4.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.532, tt:3354.962\n",
      "Ep:216, loss:0.00001, loss_test:0.07789, lr:4.30e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.535, tt:3371.073\n",
      "Ep:217, loss:0.00001, loss_test:0.07790, lr:4.26e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.536, tt:3386.941\n",
      "Ep:218, loss:0.00001, loss_test:0.07781, lr:4.21e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.544, tt:3404.072\n",
      "Ep:219, loss:0.00001, loss_test:0.07789, lr:4.17e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.549, tt:3420.832\n",
      "Ep:220, loss:0.00001, loss_test:0.07780, lr:4.13e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.550, tt:3436.439\n",
      "Ep:221, loss:0.00001, loss_test:0.07779, lr:4.09e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.555, tt:3453.173\n",
      "Ep:222, loss:0.00001, loss_test:0.07780, lr:4.05e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.557, tt:3469.104\n",
      "Ep:223, loss:0.00001, loss_test:0.07782, lr:4.01e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.558, tt:3484.900\n",
      "Ep:224, loss:0.00001, loss_test:0.07777, lr:3.97e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.557, tt:3500.367\n",
      "Ep:225, loss:0.00001, loss_test:0.07772, lr:3.93e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.558, tt:3516.085\n",
      "Ep:226, loss:0.00001, loss_test:0.07775, lr:3.89e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.560, tt:3532.028\n",
      "Ep:227, loss:0.00001, loss_test:0.07770, lr:3.85e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.562, tt:3548.110\n",
      "Ep:228, loss:0.00001, loss_test:0.07765, lr:3.81e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.560, tt:3563.230\n",
      "Ep:229, loss:0.00001, loss_test:0.07776, lr:3.77e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.563, tt:3579.473\n",
      "Ep:230, loss:0.00001, loss_test:0.07775, lr:3.73e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.567, tt:3595.887\n",
      "Ep:231, loss:0.00001, loss_test:0.07763, lr:3.70e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.570, tt:3612.215\n",
      "Ep:232, loss:0.00001, loss_test:0.07764, lr:3.66e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.570, tt:3627.758\n",
      "Ep:233, loss:0.00001, loss_test:0.07773, lr:3.62e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.571, tt:3643.536\n",
      "Ep:234, loss:0.00001, loss_test:0.07766, lr:3.59e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.570, tt:3658.877\n",
      "Ep:235, loss:0.00001, loss_test:0.07751, lr:3.55e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.573, tt:3675.283\n",
      "Ep:236, loss:0.00001, loss_test:0.07773, lr:3.52e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.584, tt:3693.494\n",
      "Ep:237, loss:0.00001, loss_test:0.07773, lr:3.48e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.587, tt:3709.669\n",
      "Ep:238, loss:0.00001, loss_test:0.07757, lr:3.45e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.590, tt:3726.016\n",
      "Ep:239, loss:0.00001, loss_test:0.07750, lr:3.41e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.585, tt:3740.323\n",
      "Ep:240, loss:0.00001, loss_test:0.07764, lr:3.38e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.582, tt:3755.342\n",
      "Ep:241, loss:0.00001, loss_test:0.07769, lr:3.34e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.581, tt:3770.547\n",
      "Ep:242, loss:0.00001, loss_test:0.07758, lr:3.31e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.580, tt:3786.026\n",
      "Ep:243, loss:0.00001, loss_test:0.07747, lr:3.28e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.582, tt:3802.064\n",
      "Ep:244, loss:0.00001, loss_test:0.07759, lr:3.24e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.581, tt:3817.246\n",
      "Ep:245, loss:0.00001, loss_test:0.07761, lr:3.21e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.581, tt:3832.933\n",
      "Ep:246, loss:0.00001, loss_test:0.07756, lr:3.18e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.581, tt:3848.544\n",
      "Ep:247, loss:0.00001, loss_test:0.07754, lr:3.15e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.581, tt:3864.202\n",
      "Ep:248, loss:0.00001, loss_test:0.07762, lr:3.12e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.575, tt:3878.142\n",
      "Ep:249, loss:0.00000, loss_test:0.07753, lr:3.09e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.573, tt:3893.216\n",
      "Ep:250, loss:0.00000, loss_test:0.07753, lr:3.05e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.576, tt:3909.456\n",
      "Ep:251, loss:0.00000, loss_test:0.07759, lr:3.02e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.576, tt:3925.087\n",
      "Ep:252, loss:0.00000, loss_test:0.07751, lr:2.99e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.578, tt:3941.154\n",
      "Ep:253, loss:0.00000, loss_test:0.07746, lr:2.96e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.578, tt:3956.721\n",
      "Ep:254, loss:0.00000, loss_test:0.07756, lr:2.93e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.578, tt:3972.382\n",
      "Ep:255, loss:0.00000, loss_test:0.07754, lr:2.90e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.577, tt:3987.742\n",
      "Ep:256, loss:0.00000, loss_test:0.07751, lr:2.88e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.576, tt:4002.969\n",
      "Ep:257, loss:0.00000, loss_test:0.07761, lr:2.85e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.576, tt:4018.721\n",
      "Ep:258, loss:0.00000, loss_test:0.07756, lr:2.82e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.576, tt:4034.276\n",
      "Ep:259, loss:0.00000, loss_test:0.07749, lr:2.79e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.575, tt:4049.379\n",
      "Ep:260, loss:0.00000, loss_test:0.07759, lr:2.76e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.571, tt:4064.146\n",
      "Ep:261, loss:0.00000, loss_test:0.07761, lr:2.73e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.573, tt:4080.045\n",
      "Ep:262, loss:0.00000, loss_test:0.07753, lr:2.71e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.570, tt:4094.853\n",
      "Ep:263, loss:0.00000, loss_test:0.07752, lr:2.68e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.570, tt:4110.467\n",
      "Ep:264, loss:0.00000, loss_test:0.07761, lr:2.65e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.569, tt:4125.706\n",
      "Ep:265, loss:0.00000, loss_test:0.07756, lr:2.63e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.571, tt:4141.976\n",
      "Ep:266, loss:0.00000, loss_test:0.07751, lr:2.60e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.570, tt:4157.287\n",
      "Ep:267, loss:0.00000, loss_test:0.07753, lr:2.57e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.576, tt:4174.269\n",
      "Ep:268, loss:0.00000, loss_test:0.07754, lr:2.55e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.576, tt:4189.985\n",
      "Ep:269, loss:0.00000, loss_test:0.07753, lr:2.52e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.578, tt:4205.928\n",
      "Ep:270, loss:0.00000, loss_test:0.07750, lr:2.50e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.577, tt:4221.391\n",
      "Ep:271, loss:0.00000, loss_test:0.07753, lr:2.47e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.579, tt:4237.410\n",
      "Ep:272, loss:0.00000, loss_test:0.07753, lr:2.45e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.586, tt:4254.894\n",
      "Ep:273, loss:0.00000, loss_test:0.07750, lr:2.42e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.589, tt:4271.444\n",
      "Ep:274, loss:0.00000, loss_test:0.07753, lr:2.40e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.591, tt:4287.536\n",
      "Ep:275, loss:0.00000, loss_test:0.07751, lr:2.38e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.591, tt:4303.083\n",
      "Ep:276, loss:0.00000, loss_test:0.07755, lr:2.35e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.598, tt:4320.664\n",
      "Ep:277, loss:0.00000, loss_test:0.07747, lr:2.33e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.601, tt:4336.959\n",
      "Ep:278, loss:0.00000, loss_test:0.07755, lr:2.31e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.599, tt:4352.031\n",
      "Ep:279, loss:0.00000, loss_test:0.07750, lr:2.28e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.598, tt:4367.543\n",
      "Ep:280, loss:0.00000, loss_test:0.07750, lr:2.26e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.598, tt:4383.091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:281, loss:0.00000, loss_test:0.07757, lr:2.24e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.601, tt:4399.607\n",
      "Ep:282, loss:0.00000, loss_test:0.07754, lr:2.21e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.597, tt:4414.045\n",
      "Ep:283, loss:0.00000, loss_test:0.07747, lr:2.19e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.602, tt:4430.987\n",
      "Ep:284, loss:0.00000, loss_test:0.07756, lr:2.17e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.602, tt:4446.651\n",
      "Ep:285, loss:0.00000, loss_test:0.07756, lr:2.15e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.603, tt:4462.378\n",
      "Ep:286, loss:0.00000, loss_test:0.07748, lr:2.13e-03, fs:0.79787 (r=0.758,p=0.843),  time:15.606, tt:4478.872\n",
      "Ep:287, loss:0.00000, loss_test:0.07751, lr:2.11e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.607, tt:4494.857\n",
      "Ep:288, loss:0.00000, loss_test:0.07752, lr:2.08e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.611, tt:4511.595\n",
      "Ep:289, loss:0.00000, loss_test:0.07749, lr:2.06e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.614, tt:4528.138\n",
      "Ep:290, loss:0.00000, loss_test:0.07751, lr:2.04e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.616, tt:4544.202\n",
      "Ep:291, loss:0.00000, loss_test:0.07754, lr:2.02e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.618, tt:4560.379\n",
      "Ep:292, loss:0.00000, loss_test:0.07753, lr:2.00e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.619, tt:4576.338\n",
      "Ep:293, loss:0.00000, loss_test:0.07752, lr:1.98e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.616, tt:4591.244\n",
      "Ep:294, loss:0.00000, loss_test:0.07757, lr:1.96e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.613, tt:4605.865\n",
      "Ep:295, loss:0.00000, loss_test:0.07752, lr:1.94e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.608, tt:4619.881\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14305, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.639, tt:17.639\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14273, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.831, tt:37.661\n",
      "Ep:2, loss:0.00004, loss_test:0.14225, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.814, tt:59.441\n",
      "Ep:3, loss:0.00004, loss_test:0.14157, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.006, tt:80.024\n",
      "Ep:4, loss:0.00004, loss_test:0.14067, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.888, tt:99.439\n",
      "Ep:5, loss:0.00004, loss_test:0.13949, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.130, tt:120.783\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13795, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:20.164, tt:141.149\n",
      "Ep:7, loss:0.00004, loss_test:0.13596, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:20.292, tt:162.336\n",
      "Ep:8, loss:0.00004, loss_test:0.13329, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:20.302, tt:182.715\n",
      "Ep:9, loss:0.00004, loss_test:0.12994, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:20.309, tt:203.085\n",
      "Ep:10, loss:0.00004, loss_test:0.12584, lr:1.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:20.122, tt:221.341\n",
      "Ep:11, loss:0.00004, loss_test:0.12084, lr:1.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:20.083, tt:240.992\n",
      "Ep:12, loss:0.00003, loss_test:0.11559, lr:1.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:20.014, tt:260.177\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.11219, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:20.104, tt:281.449\n",
      "Ep:14, loss:0.00003, loss_test:0.11186, lr:1.00e-02, fs:0.65657 (r=0.657,p=0.657),  time:20.098, tt:301.470\n",
      "Ep:15, loss:0.00003, loss_test:0.11202, lr:1.00e-02, fs:0.64516 (r=0.606,p=0.690),  time:20.065, tt:321.046\n",
      "Ep:16, loss:0.00003, loss_test:0.11093, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:20.073, tt:341.248\n",
      "Ep:17, loss:0.00003, loss_test:0.11015, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:20.034, tt:360.615\n",
      "Ep:18, loss:0.00003, loss_test:0.11006, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:20.081, tt:381.542\n",
      "Ep:19, loss:0.00003, loss_test:0.10928, lr:1.00e-02, fs:0.67619 (r=0.717,p=0.640),  time:20.052, tt:401.038\n",
      "Ep:20, loss:0.00003, loss_test:0.10777, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:20.030, tt:420.640\n",
      "Ep:21, loss:0.00003, loss_test:0.10649, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:20.019, tt:440.409\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10526, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:19.986, tt:459.671\n",
      "Ep:23, loss:0.00003, loss_test:0.10376, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:19.942, tt:478.617\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.10281, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:19.905, tt:497.625\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.10171, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:19.933, tt:518.251\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.10054, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:19.975, tt:539.331\n",
      "Ep:27, loss:0.00002, loss_test:0.09979, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:19.961, tt:558.903\n",
      "Ep:28, loss:0.00002, loss_test:0.09946, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:19.947, tt:578.473\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.09913, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:19.941, tt:598.233\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.09881, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:19.931, tt:617.847\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.09862, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:19.951, tt:638.434\n",
      "Ep:32, loss:0.00002, loss_test:0.09828, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:19.955, tt:658.520\n",
      "Ep:33, loss:0.00002, loss_test:0.09763, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:19.962, tt:678.711\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.09708, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:19.983, tt:699.418\n",
      "Ep:35, loss:0.00002, loss_test:0.09658, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:19.989, tt:719.605\n",
      "Ep:36, loss:0.00002, loss_test:0.09604, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:20.013, tt:740.487\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.09564, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:20.012, tt:760.441\n",
      "Ep:38, loss:0.00002, loss_test:0.09512, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:20.021, tt:780.832\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.09445, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:20.011, tt:800.421\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.09366, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:20.067, tt:822.750\n",
      "Ep:41, loss:0.00002, loss_test:0.09305, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:20.079, tt:843.325\n",
      "Ep:42, loss:0.00002, loss_test:0.09231, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:20.061, tt:862.642\n",
      "Ep:43, loss:0.00002, loss_test:0.09193, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:20.046, tt:882.046\n",
      "Ep:44, loss:0.00002, loss_test:0.09181, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:20.043, tt:901.918\n",
      "Ep:45, loss:0.00002, loss_test:0.09166, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:20.066, tt:923.042\n",
      "Ep:46, loss:0.00002, loss_test:0.09126, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:20.086, tt:944.046\n",
      "Ep:47, loss:0.00002, loss_test:0.09084, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:20.119, tt:965.713\n",
      "Ep:48, loss:0.00002, loss_test:0.09035, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:20.100, tt:984.885\n",
      "Ep:49, loss:0.00002, loss_test:0.08987, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:20.100, tt:1004.989\n",
      "Ep:50, loss:0.00002, loss_test:0.08939, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:20.101, tt:1025.140\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00001, loss_test:0.08913, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:20.118, tt:1046.161\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.08907, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:20.117, tt:1066.189\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.08893, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:20.130, tt:1087.012\n",
      "Ep:54, loss:0.00001, loss_test:0.08844, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:20.128, tt:1107.049\n",
      "Ep:55, loss:0.00001, loss_test:0.08815, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:20.125, tt:1127.022\n",
      "Ep:56, loss:0.00001, loss_test:0.08808, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:20.104, tt:1145.909\n",
      "Ep:57, loss:0.00001, loss_test:0.08793, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:20.085, tt:1164.928\n",
      "Ep:58, loss:0.00001, loss_test:0.08716, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:20.067, tt:1183.951\n",
      "Ep:59, loss:0.00001, loss_test:0.08644, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:20.052, tt:1203.120\n",
      "Ep:60, loss:0.00001, loss_test:0.08639, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:20.027, tt:1221.661\n",
      "Ep:61, loss:0.00001, loss_test:0.08613, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:20.016, tt:1241.018\n",
      "Ep:62, loss:0.00001, loss_test:0.08570, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:20.017, tt:1261.070\n",
      "Ep:63, loss:0.00001, loss_test:0.08541, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:20.000, tt:1279.994\n",
      "Ep:64, loss:0.00001, loss_test:0.08537, lr:9.90e-03, fs:0.79592 (r=0.788,p=0.804),  time:20.011, tt:1300.726\n",
      "Ep:65, loss:0.00001, loss_test:0.08504, lr:9.80e-03, fs:0.79592 (r=0.788,p=0.804),  time:20.001, tt:1320.059\n",
      "Ep:66, loss:0.00001, loss_test:0.08485, lr:9.70e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.990, tt:1339.337\n",
      "Ep:67, loss:0.00001, loss_test:0.08484, lr:9.61e-03, fs:0.80000 (r=0.788,p=0.812),  time:19.976, tt:1358.345\n",
      "Ep:68, loss:0.00001, loss_test:0.08504, lr:9.51e-03, fs:0.80000 (r=0.788,p=0.812),  time:19.949, tt:1376.472\n",
      "Ep:69, loss:0.00001, loss_test:0.08479, lr:9.41e-03, fs:0.80000 (r=0.788,p=0.812),  time:19.940, tt:1395.825\n",
      "Ep:70, loss:0.00001, loss_test:0.08447, lr:9.32e-03, fs:0.80000 (r=0.788,p=0.812),  time:19.922, tt:1414.477\n",
      "Ep:71, loss:0.00001, loss_test:0.08460, lr:9.23e-03, fs:0.80000 (r=0.788,p=0.812),  time:19.916, tt:1433.932\n",
      "Ep:72, loss:0.00001, loss_test:0.08445, lr:9.14e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.904, tt:1452.975\n",
      "Ep:73, loss:0.00001, loss_test:0.08398, lr:9.04e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.900, tt:1472.602\n",
      "Ep:74, loss:0.00001, loss_test:0.08413, lr:8.95e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.902, tt:1492.677\n",
      "Ep:75, loss:0.00001, loss_test:0.08420, lr:8.86e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.912, tt:1513.298\n",
      "Ep:76, loss:0.00001, loss_test:0.08396, lr:8.78e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.903, tt:1532.566\n",
      "Ep:77, loss:0.00001, loss_test:0.08418, lr:8.69e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.909, tt:1552.909\n",
      "Ep:78, loss:0.00001, loss_test:0.08417, lr:8.60e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.884, tt:1570.813\n",
      "Ep:79, loss:0.00001, loss_test:0.08402, lr:8.51e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.877, tt:1590.193\n",
      "Ep:80, loss:0.00001, loss_test:0.08417, lr:8.43e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.898, tt:1611.721\n",
      "Ep:81, loss:0.00001, loss_test:0.08409, lr:8.35e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.878, tt:1629.968\n",
      "Ep:82, loss:0.00001, loss_test:0.08418, lr:8.26e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.875, tt:1649.592\n",
      "Ep:83, loss:0.00001, loss_test:0.08444, lr:8.18e-03, fs:0.78756 (r=0.768,p=0.809),  time:19.866, tt:1668.720\n",
      "Ep:84, loss:0.00001, loss_test:0.08421, lr:8.10e-03, fs:0.78756 (r=0.768,p=0.809),  time:19.843, tt:1686.679\n",
      "Ep:85, loss:0.00001, loss_test:0.08407, lr:8.02e-03, fs:0.79381 (r=0.778,p=0.811),  time:19.849, tt:1707.042\n",
      "Ep:86, loss:0.00001, loss_test:0.08420, lr:7.94e-03, fs:0.80208 (r=0.778,p=0.828),  time:19.840, tt:1726.096\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.08414, lr:7.94e-03, fs:0.79581 (r=0.768,p=0.826),  time:19.840, tt:1745.910\n",
      "Ep:88, loss:0.00001, loss_test:0.08401, lr:7.94e-03, fs:0.79581 (r=0.768,p=0.826),  time:19.833, tt:1765.169\n",
      "Ep:89, loss:0.00001, loss_test:0.08376, lr:7.94e-03, fs:0.80000 (r=0.768,p=0.835),  time:19.835, tt:1785.188\n",
      "Ep:90, loss:0.00001, loss_test:0.08403, lr:7.94e-03, fs:0.79365 (r=0.758,p=0.833),  time:19.820, tt:1803.644\n",
      "Ep:91, loss:0.00001, loss_test:0.08369, lr:7.94e-03, fs:0.79787 (r=0.758,p=0.843),  time:19.819, tt:1823.343\n",
      "Ep:92, loss:0.00001, loss_test:0.08339, lr:7.94e-03, fs:0.79365 (r=0.758,p=0.833),  time:19.807, tt:1842.034\n",
      "Ep:93, loss:0.00001, loss_test:0.08359, lr:7.94e-03, fs:0.80645 (r=0.758,p=0.862),  time:19.799, tt:1861.096\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.08293, lr:7.94e-03, fs:0.80645 (r=0.758,p=0.862),  time:19.785, tt:1879.589\n",
      "Ep:95, loss:0.00001, loss_test:0.08320, lr:7.94e-03, fs:0.80645 (r=0.758,p=0.862),  time:19.771, tt:1898.056\n",
      "Ep:96, loss:0.00001, loss_test:0.08268, lr:7.94e-03, fs:0.80645 (r=0.758,p=0.862),  time:19.753, tt:1916.067\n",
      "Ep:97, loss:0.00001, loss_test:0.08222, lr:7.94e-03, fs:0.80645 (r=0.758,p=0.862),  time:19.755, tt:1935.992\n",
      "Ep:98, loss:0.00001, loss_test:0.08244, lr:7.94e-03, fs:0.81081 (r=0.758,p=0.872),  time:19.742, tt:1954.440\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.08179, lr:7.94e-03, fs:0.81081 (r=0.758,p=0.872),  time:19.738, tt:1973.815\n",
      "Ep:100, loss:0.00001, loss_test:0.08202, lr:7.94e-03, fs:0.81081 (r=0.758,p=0.872),  time:19.733, tt:1992.992\n",
      "Ep:101, loss:0.00001, loss_test:0.08227, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.725, tt:2011.995\n",
      "Ep:102, loss:0.00001, loss_test:0.08182, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.731, tt:2032.318\n",
      "Ep:103, loss:0.00001, loss_test:0.08233, lr:7.94e-03, fs:0.81081 (r=0.758,p=0.872),  time:19.748, tt:2053.767\n",
      "Ep:104, loss:0.00001, loss_test:0.08156, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.740, tt:2072.725\n",
      "Ep:105, loss:0.00001, loss_test:0.08165, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.738, tt:2092.268\n",
      "Ep:106, loss:0.00001, loss_test:0.08175, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.774, tt:2115.848\n",
      "Ep:107, loss:0.00001, loss_test:0.08114, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.768, tt:2134.993\n",
      "Ep:108, loss:0.00001, loss_test:0.08187, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.775, tt:2155.438\n",
      "Ep:109, loss:0.00000, loss_test:0.08110, lr:7.94e-03, fs:0.82162 (r=0.768,p=0.884),  time:19.763, tt:2173.914\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.08071, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.750, tt:2192.217\n",
      "Ep:111, loss:0.00000, loss_test:0.08230, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.740, tt:2210.928\n",
      "Ep:112, loss:0.00000, loss_test:0.08141, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.753, tt:2232.063\n",
      "Ep:113, loss:0.00000, loss_test:0.08003, lr:7.94e-03, fs:0.81522 (r=0.758,p=0.882),  time:19.767, tt:2253.402\n",
      "Ep:114, loss:0.00000, loss_test:0.08151, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.763, tt:2272.768\n",
      "Ep:115, loss:0.00000, loss_test:0.08145, lr:7.94e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.774, tt:2293.811\n",
      "Ep:116, loss:0.00000, loss_test:0.07988, lr:7.94e-03, fs:0.81967 (r=0.758,p=0.893),  time:19.772, tt:2313.272\n",
      "Ep:117, loss:0.00000, loss_test:0.08141, lr:7.94e-03, fs:0.81522 (r=0.758,p=0.882),  time:19.776, tt:2333.588\n",
      "Ep:118, loss:0.00000, loss_test:0.08102, lr:7.94e-03, fs:0.81319 (r=0.747,p=0.892),  time:19.782, tt:2354.103\n",
      "Ep:119, loss:0.00000, loss_test:0.08078, lr:7.94e-03, fs:0.81319 (r=0.747,p=0.892),  time:19.785, tt:2374.218\n",
      "Ep:120, loss:0.00000, loss_test:0.08088, lr:7.94e-03, fs:0.82162 (r=0.768,p=0.884),  time:19.803, tt:2396.161\n",
      "Ep:121, loss:0.00000, loss_test:0.08031, lr:7.86e-03, fs:0.81768 (r=0.747,p=0.902),  time:19.811, tt:2416.912\n",
      "Ep:122, loss:0.00000, loss_test:0.08136, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.807, tt:2436.267\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.08062, lr:7.78e-03, fs:0.81319 (r=0.747,p=0.892),  time:19.810, tt:2456.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00000, loss_test:0.08045, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.809, tt:2476.122\n",
      "Ep:125, loss:0.00000, loss_test:0.08081, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.809, tt:2495.877\n",
      "Ep:126, loss:0.00000, loss_test:0.07955, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.818, tt:2516.832\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00000, loss_test:0.08066, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.814, tt:2536.166\n",
      "Ep:128, loss:0.00000, loss_test:0.07975, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.817, tt:2556.429\n",
      "Ep:129, loss:0.00000, loss_test:0.08075, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.815, tt:2575.917\n",
      "Ep:130, loss:0.00000, loss_test:0.07936, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.814, tt:2595.696\n",
      "Ep:131, loss:0.00000, loss_test:0.08011, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.825, tt:2616.839\n",
      "Ep:132, loss:0.00000, loss_test:0.07951, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.823, tt:2636.415\n",
      "Ep:133, loss:0.00000, loss_test:0.07950, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.823, tt:2656.258\n",
      "Ep:134, loss:0.00000, loss_test:0.07985, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.828, tt:2676.817\n",
      "Ep:135, loss:0.00000, loss_test:0.07943, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.833, tt:2697.261\n",
      "Ep:136, loss:0.00000, loss_test:0.08014, lr:7.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:19.827, tt:2716.236\n",
      "Ep:137, loss:0.00000, loss_test:0.07916, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.828, tt:2736.256\n",
      "Ep:138, loss:0.00000, loss_test:0.08088, lr:7.70e-03, fs:0.82486 (r=0.737,p=0.936),  time:19.831, tt:2756.557\n",
      "Ep:139, loss:0.00000, loss_test:0.07917, lr:7.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:19.842, tt:2777.879\n",
      "Ep:140, loss:0.00000, loss_test:0.08083, lr:7.55e-03, fs:0.83146 (r=0.747,p=0.937),  time:19.848, tt:2798.543\n",
      "##########Best model found so far##########\n",
      "Ep:141, loss:0.00000, loss_test:0.07970, lr:7.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.850, tt:2818.746\n",
      "Ep:142, loss:0.00000, loss_test:0.07884, lr:7.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.854, tt:2839.182\n",
      "Ep:143, loss:0.00000, loss_test:0.08161, lr:7.55e-03, fs:0.82486 (r=0.737,p=0.936),  time:19.855, tt:2859.076\n",
      "Ep:144, loss:0.00000, loss_test:0.07992, lr:7.55e-03, fs:0.83333 (r=0.758,p=0.926),  time:19.857, tt:2879.278\n",
      "##########Best model found so far##########\n",
      "Ep:145, loss:0.00000, loss_test:0.07851, lr:7.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.861, tt:2899.643\n",
      "Ep:146, loss:0.00000, loss_test:0.08193, lr:7.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:19.869, tt:2920.812\n",
      "Ep:147, loss:0.00000, loss_test:0.08054, lr:7.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:19.883, tt:2942.646\n",
      "Ep:148, loss:0.00000, loss_test:0.07916, lr:7.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:19.881, tt:2962.217\n",
      "Ep:149, loss:0.00000, loss_test:0.08090, lr:7.55e-03, fs:0.83146 (r=0.747,p=0.937),  time:19.894, tt:2984.034\n",
      "Ep:150, loss:0.00000, loss_test:0.08048, lr:7.55e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.904, tt:3005.573\n",
      "Ep:151, loss:0.00000, loss_test:0.08126, lr:7.55e-03, fs:0.83146 (r=0.747,p=0.937),  time:19.906, tt:3025.689\n",
      "Ep:152, loss:0.00000, loss_test:0.08013, lr:7.55e-03, fs:0.83978 (r=0.768,p=0.927),  time:19.913, tt:3046.745\n",
      "##########Best model found so far##########\n",
      "Ep:153, loss:0.00000, loss_test:0.07939, lr:7.55e-03, fs:0.80000 (r=0.707,p=0.921),  time:19.908, tt:3065.818\n",
      "Ep:154, loss:0.00000, loss_test:0.08378, lr:7.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:19.903, tt:3084.890\n",
      "Ep:155, loss:0.00000, loss_test:0.08230, lr:7.55e-03, fs:0.82486 (r=0.737,p=0.936),  time:19.908, tt:3105.597\n",
      "Ep:156, loss:0.00000, loss_test:0.07865, lr:7.55e-03, fs:0.83516 (r=0.768,p=0.916),  time:19.913, tt:3126.365\n",
      "Ep:157, loss:0.00000, loss_test:0.08278, lr:7.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:19.915, tt:3146.565\n",
      "Ep:158, loss:0.00000, loss_test:0.08315, lr:7.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:19.911, tt:3165.787\n",
      "Ep:159, loss:0.00000, loss_test:0.08007, lr:7.55e-03, fs:0.82022 (r=0.737,p=0.924),  time:19.900, tt:3184.003\n",
      "Ep:160, loss:0.00000, loss_test:0.08024, lr:7.55e-03, fs:0.82682 (r=0.747,p=0.925),  time:19.901, tt:3204.098\n",
      "Ep:161, loss:0.00000, loss_test:0.08258, lr:7.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.900, tt:3223.753\n",
      "Ep:162, loss:0.00000, loss_test:0.08212, lr:7.55e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.899, tt:3243.579\n",
      "Ep:163, loss:0.00000, loss_test:0.08065, lr:7.55e-03, fs:0.83978 (r=0.768,p=0.927),  time:19.903, tt:3264.139\n",
      "Ep:164, loss:0.00000, loss_test:0.08116, lr:7.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:19.916, tt:3286.103\n",
      "Ep:165, loss:0.00000, loss_test:0.08156, lr:7.40e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.921, tt:3306.886\n",
      "Ep:166, loss:0.00000, loss_test:0.08256, lr:7.32e-03, fs:0.82486 (r=0.737,p=0.936),  time:19.928, tt:3327.934\n",
      "Ep:167, loss:0.00000, loss_test:0.08197, lr:7.25e-03, fs:0.82682 (r=0.747,p=0.925),  time:19.930, tt:3348.254\n",
      "Ep:168, loss:0.00000, loss_test:0.08174, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.929, tt:3368.065\n",
      "Ep:169, loss:0.00000, loss_test:0.08285, lr:7.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.931, tt:3388.198\n",
      "Ep:170, loss:0.00000, loss_test:0.08224, lr:7.03e-03, fs:0.82022 (r=0.737,p=0.924),  time:19.936, tt:3409.029\n",
      "Ep:171, loss:0.00000, loss_test:0.08141, lr:6.96e-03, fs:0.83146 (r=0.747,p=0.937),  time:19.938, tt:3429.415\n",
      "Ep:172, loss:0.00000, loss_test:0.08310, lr:6.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:19.944, tt:3450.346\n",
      "Ep:173, loss:0.00000, loss_test:0.08281, lr:6.83e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.949, tt:3471.060\n",
      "Ep:174, loss:0.00000, loss_test:0.08105, lr:6.76e-03, fs:0.79769 (r=0.697,p=0.932),  time:19.943, tt:3490.080\n",
      "Ep:175, loss:0.00000, loss_test:0.08255, lr:6.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.945, tt:3510.295\n",
      "Ep:176, loss:0.00000, loss_test:0.08364, lr:6.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.950, tt:3531.172\n",
      "Ep:177, loss:0.00000, loss_test:0.08237, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.954, tt:3551.804\n",
      "Ep:178, loss:0.00000, loss_test:0.08141, lr:6.49e-03, fs:0.83146 (r=0.747,p=0.937),  time:19.960, tt:3572.842\n",
      "Ep:179, loss:0.00000, loss_test:0.08282, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.965, tt:3593.680\n",
      "Ep:180, loss:0.00000, loss_test:0.08328, lr:6.36e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.966, tt:3613.811\n",
      "Ep:181, loss:0.00000, loss_test:0.08257, lr:6.30e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.965, tt:3633.559\n",
      "Ep:182, loss:0.00000, loss_test:0.08209, lr:6.24e-03, fs:0.82955 (r=0.737,p=0.948),  time:19.974, tt:3655.221\n",
      "Ep:183, loss:0.00000, loss_test:0.08242, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:19.977, tt:3675.685\n",
      "Ep:184, loss:0.00000, loss_test:0.08347, lr:6.11e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.977, tt:3695.705\n",
      "Ep:185, loss:0.00000, loss_test:0.08271, lr:6.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.976, tt:3715.497\n",
      "Ep:186, loss:0.00000, loss_test:0.08199, lr:5.99e-03, fs:0.81143 (r=0.717,p=0.934),  time:19.973, tt:3734.924\n",
      "Ep:187, loss:0.00000, loss_test:0.08289, lr:5.93e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.979, tt:3756.126\n",
      "Ep:188, loss:0.00000, loss_test:0.08309, lr:5.87e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.982, tt:3776.613\n",
      "Ep:189, loss:0.00000, loss_test:0.08235, lr:5.81e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.981, tt:3796.314\n",
      "Ep:190, loss:0.00000, loss_test:0.08276, lr:5.75e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.980, tt:3816.093\n",
      "Ep:191, loss:0.00000, loss_test:0.08339, lr:5.70e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.978, tt:3835.752\n",
      "Ep:192, loss:0.00000, loss_test:0.08294, lr:5.64e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.979, tt:3855.878\n",
      "Ep:193, loss:0.00000, loss_test:0.08262, lr:5.58e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.975, tt:3875.090\n",
      "Ep:194, loss:0.00000, loss_test:0.08308, lr:5.53e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.978, tt:3895.669\n",
      "Ep:195, loss:0.00000, loss_test:0.08316, lr:5.47e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.981, tt:3916.201\n",
      "Ep:196, loss:0.00000, loss_test:0.08268, lr:5.42e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.984, tt:3936.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.08323, lr:5.36e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.979, tt:3955.814\n",
      "Ep:198, loss:0.00000, loss_test:0.08338, lr:5.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:19.978, tt:3975.584\n",
      "Ep:199, loss:0.00000, loss_test:0.08322, lr:5.26e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.979, tt:3995.814\n",
      "Ep:200, loss:0.00000, loss_test:0.08322, lr:5.20e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.977, tt:4015.318\n",
      "Ep:201, loss:0.00000, loss_test:0.08307, lr:5.15e-03, fs:0.80925 (r=0.707,p=0.946),  time:19.979, tt:4035.706\n",
      "Ep:202, loss:0.00000, loss_test:0.08332, lr:5.10e-03, fs:0.80233 (r=0.697,p=0.945),  time:19.978, tt:4055.436\n",
      "Ep:203, loss:0.00000, loss_test:0.08356, lr:5.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:19.974, tt:4074.636\n",
      "Ep:204, loss:0.00000, loss_test:0.08351, lr:5.00e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.970, tt:4093.845\n",
      "Ep:205, loss:0.00000, loss_test:0.08342, lr:4.95e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.963, tt:4112.278\n",
      "Ep:206, loss:0.00000, loss_test:0.08363, lr:4.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:19.965, tt:4132.781\n",
      "Ep:207, loss:0.00000, loss_test:0.08340, lr:4.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.971, tt:4154.015\n",
      "Ep:208, loss:0.00000, loss_test:0.08378, lr:4.80e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.975, tt:4174.838\n",
      "Ep:209, loss:0.00000, loss_test:0.08375, lr:4.75e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.976, tt:4194.966\n",
      "Ep:210, loss:0.00000, loss_test:0.08350, lr:4.71e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.977, tt:4215.203\n",
      "Ep:211, loss:0.00000, loss_test:0.08384, lr:4.66e-03, fs:0.77844 (r=0.657,p=0.956),  time:19.974, tt:4234.459\n",
      "Ep:212, loss:0.00000, loss_test:0.08385, lr:4.61e-03, fs:0.79290 (r=0.677,p=0.957),  time:19.972, tt:4254.075\n",
      "Ep:213, loss:0.00000, loss_test:0.08381, lr:4.57e-03, fs:0.79532 (r=0.687,p=0.944),  time:19.975, tt:4274.638\n",
      "Ep:214, loss:0.00000, loss_test:0.08395, lr:4.52e-03, fs:0.80000 (r=0.687,p=0.958),  time:19.978, tt:4295.205\n",
      "Ep:215, loss:0.00000, loss_test:0.08370, lr:4.48e-03, fs:0.80000 (r=0.687,p=0.958),  time:19.983, tt:4316.360\n",
      "Ep:216, loss:0.00000, loss_test:0.08424, lr:4.43e-03, fs:0.77844 (r=0.657,p=0.956),  time:19.998, tt:4339.609\n",
      "Ep:217, loss:0.00000, loss_test:0.08378, lr:4.39e-03, fs:0.80000 (r=0.687,p=0.958),  time:20.003, tt:4360.594\n",
      "Ep:218, loss:0.00000, loss_test:0.08392, lr:4.34e-03, fs:0.79290 (r=0.677,p=0.957),  time:20.000, tt:4380.021\n",
      "Ep:219, loss:0.00000, loss_test:0.08397, lr:4.30e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.999, tt:4399.701\n",
      "Ep:220, loss:0.00000, loss_test:0.08414, lr:4.26e-03, fs:0.77844 (r=0.657,p=0.956),  time:19.999, tt:4419.880\n",
      "Ep:221, loss:0.00000, loss_test:0.08374, lr:4.21e-03, fs:0.80000 (r=0.687,p=0.958),  time:20.001, tt:4440.171\n",
      "Ep:222, loss:0.00000, loss_test:0.08399, lr:4.17e-03, fs:0.77844 (r=0.657,p=0.956),  time:20.005, tt:4461.016\n",
      "Ep:223, loss:0.00000, loss_test:0.08412, lr:4.13e-03, fs:0.77108 (r=0.646,p=0.955),  time:20.007, tt:4481.522\n",
      "Ep:224, loss:0.00000, loss_test:0.08391, lr:4.09e-03, fs:0.78571 (r=0.667,p=0.957),  time:20.005, tt:4501.167\n",
      "Ep:225, loss:0.00000, loss_test:0.08393, lr:4.05e-03, fs:0.79290 (r=0.677,p=0.957),  time:20.007, tt:4521.657\n",
      "Ep:226, loss:0.00000, loss_test:0.08439, lr:4.01e-03, fs:0.77108 (r=0.646,p=0.955),  time:20.006, tt:4541.367\n",
      "Ep:227, loss:0.00000, loss_test:0.08409, lr:3.97e-03, fs:0.78571 (r=0.667,p=0.957),  time:20.003, tt:4560.691\n",
      "Ep:228, loss:0.00000, loss_test:0.08360, lr:3.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:20.006, tt:4581.397\n",
      "Ep:229, loss:0.00000, loss_test:0.08465, lr:3.89e-03, fs:0.77108 (r=0.646,p=0.955),  time:20.007, tt:4601.640\n",
      "Ep:230, loss:0.00000, loss_test:0.08478, lr:3.85e-03, fs:0.75610 (r=0.626,p=0.954),  time:20.000, tt:4620.094\n",
      "Ep:231, loss:0.00000, loss_test:0.08409, lr:3.81e-03, fs:0.77844 (r=0.657,p=0.956),  time:20.001, tt:4640.190\n",
      "Ep:232, loss:0.00000, loss_test:0.08412, lr:3.77e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.998, tt:4659.521\n",
      "Ep:233, loss:0.00000, loss_test:0.08466, lr:3.73e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.996, tt:4679.065\n",
      "Ep:234, loss:0.00000, loss_test:0.08449, lr:3.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:19.997, tt:4699.411\n",
      "Ep:235, loss:0.00000, loss_test:0.08419, lr:3.66e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.996, tt:4719.062\n",
      "Ep:236, loss:0.00000, loss_test:0.08456, lr:3.62e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.994, tt:4738.530\n",
      "Ep:237, loss:0.00000, loss_test:0.08456, lr:3.59e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.990, tt:4757.566\n",
      "Ep:238, loss:0.00000, loss_test:0.08436, lr:3.55e-03, fs:0.74074 (r=0.606,p=0.952),  time:19.990, tt:4777.697\n",
      "Ep:239, loss:0.00000, loss_test:0.08487, lr:3.52e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.988, tt:4797.223\n",
      "Ep:240, loss:0.00000, loss_test:0.08468, lr:3.48e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.992, tt:4818.145\n",
      "Ep:241, loss:0.00000, loss_test:0.08435, lr:3.45e-03, fs:0.72500 (r=0.586,p=0.951),  time:19.990, tt:4837.624\n",
      "Ep:242, loss:0.00000, loss_test:0.08485, lr:3.41e-03, fs:0.73292 (r=0.596,p=0.952),  time:19.982, tt:4855.557\n",
      "Ep:243, loss:0.00000, loss_test:0.08494, lr:3.38e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.976, tt:4874.073\n",
      "Ep:244, loss:0.00000, loss_test:0.08441, lr:3.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.971, tt:4892.970\n",
      "Ep:245, loss:0.00000, loss_test:0.08433, lr:3.31e-03, fs:0.72956 (r=0.586,p=0.967),  time:19.972, tt:4913.225\n",
      "Ep:246, loss:0.00000, loss_test:0.08536, lr:3.28e-03, fs:0.72152 (r=0.576,p=0.966),  time:19.972, tt:4933.052\n",
      "Ep:247, loss:0.00000, loss_test:0.08549, lr:3.24e-03, fs:0.73750 (r=0.596,p=0.967),  time:19.972, tt:4953.007\n",
      "Ep:248, loss:0.00000, loss_test:0.08481, lr:3.21e-03, fs:0.71338 (r=0.566,p=0.966),  time:19.963, tt:4970.720\n",
      "Ep:249, loss:0.00000, loss_test:0.08425, lr:3.18e-03, fs:0.74534 (r=0.606,p=0.968),  time:19.963, tt:4990.708\n",
      "Ep:250, loss:0.00000, loss_test:0.08522, lr:3.15e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.964, tt:5010.990\n",
      "Ep:251, loss:0.00000, loss_test:0.08562, lr:3.12e-03, fs:0.72152 (r=0.576,p=0.966),  time:19.969, tt:5032.137\n",
      "Ep:252, loss:0.00000, loss_test:0.08517, lr:3.09e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.966, tt:5051.458\n",
      "Ep:253, loss:0.00000, loss_test:0.08454, lr:3.05e-03, fs:0.72956 (r=0.586,p=0.967),  time:19.967, tt:5071.734\n",
      "Ep:254, loss:0.00000, loss_test:0.08501, lr:3.02e-03, fs:0.73750 (r=0.596,p=0.967),  time:19.970, tt:5092.253\n",
      "Ep:255, loss:0.00000, loss_test:0.08540, lr:2.99e-03, fs:0.71338 (r=0.566,p=0.966),  time:19.975, tt:5113.543\n",
      "Ep:256, loss:0.00000, loss_test:0.08515, lr:2.96e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.973, tt:5133.002\n",
      "Ep:257, loss:0.00000, loss_test:0.08486, lr:2.93e-03, fs:0.71338 (r=0.566,p=0.966),  time:19.973, tt:5153.068\n",
      "Ep:258, loss:0.00000, loss_test:0.08501, lr:2.90e-03, fs:0.73750 (r=0.596,p=0.967),  time:19.975, tt:5173.525\n",
      "Ep:259, loss:0.00000, loss_test:0.08516, lr:2.88e-03, fs:0.72956 (r=0.586,p=0.967),  time:19.976, tt:5193.681\n",
      "Ep:260, loss:0.00000, loss_test:0.08504, lr:2.85e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.976, tt:5213.692\n",
      "Ep:261, loss:0.00000, loss_test:0.08506, lr:2.82e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.980, tt:5234.629\n",
      "Ep:262, loss:0.00000, loss_test:0.08505, lr:2.79e-03, fs:0.72956 (r=0.586,p=0.967),  time:19.976, tt:5253.675\n",
      "Ep:263, loss:0.00000, loss_test:0.08497, lr:2.76e-03, fs:0.73750 (r=0.596,p=0.967),  time:19.976, tt:5273.766\n",
      "Ep:264, loss:0.00000, loss_test:0.08498, lr:2.73e-03, fs:0.71338 (r=0.566,p=0.966),  time:19.978, tt:5294.286\n",
      "Ep:265, loss:0.00000, loss_test:0.08535, lr:2.71e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.978, tt:5314.042\n",
      "Ep:266, loss:0.00000, loss_test:0.08534, lr:2.68e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.974, tt:5333.020\n",
      "Ep:267, loss:0.00000, loss_test:0.08489, lr:2.65e-03, fs:0.72956 (r=0.586,p=0.967),  time:19.969, tt:5351.688\n",
      "Ep:268, loss:0.00000, loss_test:0.08524, lr:2.63e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.967, tt:5371.027\n",
      "Ep:269, loss:0.00000, loss_test:0.08538, lr:2.60e-03, fs:0.70513 (r=0.556,p=0.965),  time:19.968, tt:5391.254\n",
      "Ep:270, loss:0.00000, loss_test:0.08522, lr:2.57e-03, fs:0.71338 (r=0.566,p=0.966),  time:19.966, tt:5410.734\n",
      "Ep:271, loss:0.00000, loss_test:0.08504, lr:2.55e-03, fs:0.72956 (r=0.586,p=0.967),  time:19.964, tt:5430.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:272, loss:0.00000, loss_test:0.08524, lr:2.52e-03, fs:0.71795 (r=0.566,p=0.982),  time:19.964, tt:5450.291\n",
      "Ep:273, loss:0.00000, loss_test:0.08521, lr:2.50e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.963, tt:5469.849\n",
      "Ep:274, loss:0.00000, loss_test:0.08540, lr:2.47e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.962, tt:5489.672\n",
      "Ep:275, loss:0.00000, loss_test:0.08526, lr:2.45e-03, fs:0.71795 (r=0.566,p=0.982),  time:19.955, tt:5507.564\n",
      "Ep:276, loss:0.00000, loss_test:0.08528, lr:2.42e-03, fs:0.71795 (r=0.566,p=0.982),  time:19.951, tt:5526.559\n",
      "Ep:277, loss:0.00000, loss_test:0.08538, lr:2.40e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.948, tt:5545.586\n",
      "Ep:278, loss:0.00000, loss_test:0.08526, lr:2.38e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.946, tt:5564.845\n",
      "Ep:279, loss:0.00000, loss_test:0.08539, lr:2.35e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.942, tt:5583.697\n",
      "Ep:280, loss:0.00000, loss_test:0.08536, lr:2.33e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.944, tt:5604.343\n",
      "Ep:281, loss:0.00000, loss_test:0.08523, lr:2.31e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.942, tt:5623.541\n",
      "Ep:282, loss:0.00000, loss_test:0.08532, lr:2.28e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.940, tt:5642.910\n",
      "Ep:283, loss:0.00000, loss_test:0.08537, lr:2.26e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.937, tt:5661.981\n",
      "Ep:284, loss:0.00000, loss_test:0.08539, lr:2.24e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.937, tt:5682.160\n",
      "Ep:285, loss:0.00000, loss_test:0.08519, lr:2.21e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.937, tt:5701.907\n",
      "Ep:286, loss:0.00000, loss_test:0.08557, lr:2.19e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.934, tt:5721.057\n",
      "Ep:287, loss:0.00000, loss_test:0.08563, lr:2.17e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.934, tt:5741.112\n",
      "Ep:288, loss:0.00000, loss_test:0.08536, lr:2.15e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.932, tt:5760.413\n",
      "Ep:289, loss:0.00000, loss_test:0.08535, lr:2.13e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.925, tt:5778.297\n",
      "Ep:290, loss:0.00000, loss_test:0.08566, lr:2.11e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.921, tt:5797.009\n",
      "Ep:291, loss:0.00000, loss_test:0.08573, lr:2.08e-03, fs:0.70130 (r=0.545,p=0.982),  time:19.918, tt:5816.116\n",
      "Ep:292, loss:0.00000, loss_test:0.08552, lr:2.06e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.915, tt:5834.966\n",
      "Ep:293, loss:0.00000, loss_test:0.08540, lr:2.04e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.913, tt:5854.328\n",
      "Ep:294, loss:0.00000, loss_test:0.08561, lr:2.02e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.912, tt:5874.175\n",
      "Ep:295, loss:0.00000, loss_test:0.08559, lr:2.00e-03, fs:0.70968 (r=0.556,p=0.982),  time:19.900, tt:5890.350\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13664, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:15.702, tt:15.702\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13568, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:16.663, tt:33.325\n",
      "Ep:2, loss:0.00004, loss_test:0.13425, lr:1.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:16.749, tt:50.248\n",
      "Ep:3, loss:0.00004, loss_test:0.13242, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:16.989, tt:67.956\n",
      "Ep:4, loss:0.00004, loss_test:0.13002, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:17.197, tt:85.987\n",
      "Ep:5, loss:0.00004, loss_test:0.12705, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:17.166, tt:102.995\n",
      "Ep:6, loss:0.00004, loss_test:0.12387, lr:1.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:17.049, tt:119.345\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.12125, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:17.007, tt:136.058\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.11915, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:16.989, tt:152.904\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.11739, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:17.030, tt:170.298\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.11607, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:17.028, tt:187.307\n",
      "Ep:11, loss:0.00003, loss_test:0.11455, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:17.014, tt:204.164\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.11293, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:17.033, tt:221.428\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.11149, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:17.105, tt:239.470\n",
      "Ep:14, loss:0.00003, loss_test:0.11025, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:17.181, tt:257.708\n",
      "Ep:15, loss:0.00003, loss_test:0.10925, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:17.223, tt:275.567\n",
      "Ep:16, loss:0.00003, loss_test:0.10837, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:17.168, tt:291.863\n",
      "Ep:17, loss:0.00003, loss_test:0.10727, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:17.168, tt:309.025\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.10594, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:17.292, tt:328.555\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.10472, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:17.321, tt:346.426\n",
      "Ep:20, loss:0.00003, loss_test:0.10365, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:17.332, tt:363.970\n",
      "Ep:21, loss:0.00003, loss_test:0.10270, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:17.331, tt:381.278\n",
      "Ep:22, loss:0.00003, loss_test:0.10171, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:17.312, tt:398.172\n",
      "Ep:23, loss:0.00003, loss_test:0.10058, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:17.281, tt:414.742\n",
      "Ep:24, loss:0.00003, loss_test:0.09947, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:17.321, tt:433.021\n",
      "Ep:25, loss:0.00003, loss_test:0.09854, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:17.327, tt:450.509\n",
      "Ep:26, loss:0.00003, loss_test:0.09769, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:17.337, tt:468.086\n",
      "Ep:27, loss:0.00003, loss_test:0.09687, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:17.351, tt:485.841\n",
      "Ep:28, loss:0.00003, loss_test:0.09609, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:17.383, tt:504.096\n",
      "Ep:29, loss:0.00003, loss_test:0.09525, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:17.373, tt:521.179\n",
      "Ep:30, loss:0.00002, loss_test:0.09444, lr:9.90e-03, fs:0.73934 (r=0.788,p=0.696),  time:17.349, tt:537.821\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.09364, lr:9.90e-03, fs:0.75000 (r=0.788,p=0.716),  time:17.383, tt:556.241\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.09296, lr:9.90e-03, fs:0.75472 (r=0.808,p=0.708),  time:17.376, tt:573.398\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.09239, lr:9.90e-03, fs:0.74882 (r=0.798,p=0.705),  time:17.402, tt:591.684\n",
      "Ep:34, loss:0.00002, loss_test:0.09189, lr:9.90e-03, fs:0.74882 (r=0.798,p=0.705),  time:17.433, tt:610.143\n",
      "Ep:35, loss:0.00002, loss_test:0.09137, lr:9.90e-03, fs:0.75238 (r=0.798,p=0.712),  time:17.449, tt:628.162\n",
      "Ep:36, loss:0.00002, loss_test:0.09082, lr:9.90e-03, fs:0.76190 (r=0.808,p=0.721),  time:17.504, tt:647.643\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.09028, lr:9.90e-03, fs:0.76190 (r=0.808,p=0.721),  time:17.535, tt:666.319\n",
      "Ep:38, loss:0.00002, loss_test:0.08968, lr:9.90e-03, fs:0.76190 (r=0.808,p=0.721),  time:17.557, tt:684.719\n",
      "Ep:39, loss:0.00002, loss_test:0.08902, lr:9.90e-03, fs:0.76555 (r=0.808,p=0.727),  time:17.584, tt:703.350\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.08850, lr:9.90e-03, fs:0.77670 (r=0.808,p=0.748),  time:17.589, tt:721.130\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.08794, lr:9.90e-03, fs:0.78846 (r=0.828,p=0.752),  time:17.635, tt:740.682\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00002, loss_test:0.08735, lr:9.90e-03, fs:0.78846 (r=0.828,p=0.752),  time:17.646, tt:758.768\n",
      "Ep:43, loss:0.00002, loss_test:0.08676, lr:9.90e-03, fs:0.78261 (r=0.818,p=0.750),  time:17.655, tt:776.803\n",
      "Ep:44, loss:0.00002, loss_test:0.08620, lr:9.90e-03, fs:0.78049 (r=0.808,p=0.755),  time:17.695, tt:796.266\n",
      "Ep:45, loss:0.00002, loss_test:0.08582, lr:9.90e-03, fs:0.78641 (r=0.818,p=0.757),  time:17.683, tt:813.396\n",
      "Ep:46, loss:0.00002, loss_test:0.08549, lr:9.90e-03, fs:0.79227 (r=0.828,p=0.759),  time:17.706, tt:832.178\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.08511, lr:9.90e-03, fs:0.79227 (r=0.828,p=0.759),  time:17.742, tt:851.595\n",
      "Ep:48, loss:0.00002, loss_test:0.08466, lr:9.90e-03, fs:0.79227 (r=0.828,p=0.759),  time:17.771, tt:870.775\n",
      "Ep:49, loss:0.00002, loss_test:0.08415, lr:9.90e-03, fs:0.78641 (r=0.818,p=0.757),  time:17.822, tt:891.098\n",
      "Ep:50, loss:0.00002, loss_test:0.08365, lr:9.90e-03, fs:0.78049 (r=0.808,p=0.755),  time:17.859, tt:910.785\n",
      "Ep:51, loss:0.00002, loss_test:0.08322, lr:9.90e-03, fs:0.78049 (r=0.808,p=0.755),  time:17.882, tt:929.872\n",
      "Ep:52, loss:0.00002, loss_test:0.08285, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:17.889, tt:948.138\n",
      "Ep:53, loss:0.00002, loss_test:0.08242, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:17.911, tt:967.173\n",
      "Ep:54, loss:0.00002, loss_test:0.08195, lr:9.90e-03, fs:0.77833 (r=0.798,p=0.760),  time:17.936, tt:986.459\n",
      "Ep:55, loss:0.00002, loss_test:0.08154, lr:9.90e-03, fs:0.77833 (r=0.798,p=0.760),  time:17.978, tt:1006.763\n",
      "Ep:56, loss:0.00002, loss_test:0.08119, lr:9.90e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.004, tt:1026.203\n",
      "Ep:57, loss:0.00002, loss_test:0.08085, lr:9.90e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.014, tt:1044.787\n",
      "Ep:58, loss:0.00002, loss_test:0.08037, lr:9.80e-03, fs:0.76617 (r=0.778,p=0.755),  time:18.023, tt:1063.383\n",
      "Ep:59, loss:0.00002, loss_test:0.07976, lr:9.70e-03, fs:0.76617 (r=0.778,p=0.755),  time:18.033, tt:1081.978\n",
      "Ep:60, loss:0.00001, loss_test:0.07917, lr:9.61e-03, fs:0.76617 (r=0.778,p=0.755),  time:18.050, tt:1101.073\n",
      "Ep:61, loss:0.00001, loss_test:0.07873, lr:9.51e-03, fs:0.77387 (r=0.778,p=0.770),  time:18.068, tt:1120.235\n",
      "Ep:62, loss:0.00001, loss_test:0.07837, lr:9.41e-03, fs:0.77778 (r=0.778,p=0.778),  time:18.084, tt:1139.282\n",
      "Ep:63, loss:0.00001, loss_test:0.07797, lr:9.32e-03, fs:0.77778 (r=0.778,p=0.778),  time:18.091, tt:1157.833\n",
      "Ep:64, loss:0.00001, loss_test:0.07757, lr:9.23e-03, fs:0.78173 (r=0.778,p=0.786),  time:18.106, tt:1176.920\n",
      "Ep:65, loss:0.00001, loss_test:0.07721, lr:9.14e-03, fs:0.77551 (r=0.768,p=0.784),  time:18.107, tt:1195.075\n",
      "Ep:66, loss:0.00001, loss_test:0.07693, lr:9.04e-03, fs:0.77551 (r=0.768,p=0.784),  time:18.119, tt:1213.983\n",
      "Ep:67, loss:0.00001, loss_test:0.07658, lr:8.95e-03, fs:0.77551 (r=0.768,p=0.784),  time:18.130, tt:1232.831\n",
      "Ep:68, loss:0.00001, loss_test:0.07635, lr:8.86e-03, fs:0.77551 (r=0.768,p=0.784),  time:18.136, tt:1251.350\n",
      "Ep:69, loss:0.00001, loss_test:0.07619, lr:8.78e-03, fs:0.77949 (r=0.768,p=0.792),  time:18.138, tt:1269.687\n",
      "Ep:70, loss:0.00001, loss_test:0.07574, lr:8.69e-03, fs:0.77949 (r=0.768,p=0.792),  time:18.142, tt:1288.078\n",
      "Ep:71, loss:0.00001, loss_test:0.07534, lr:8.60e-03, fs:0.77949 (r=0.768,p=0.792),  time:18.149, tt:1306.756\n",
      "Ep:72, loss:0.00001, loss_test:0.07524, lr:8.51e-03, fs:0.78351 (r=0.768,p=0.800),  time:18.152, tt:1325.079\n",
      "Ep:73, loss:0.00001, loss_test:0.07467, lr:8.43e-03, fs:0.78351 (r=0.768,p=0.800),  time:18.165, tt:1344.198\n",
      "Ep:74, loss:0.00001, loss_test:0.07426, lr:8.35e-03, fs:0.78351 (r=0.768,p=0.800),  time:18.159, tt:1361.948\n",
      "Ep:75, loss:0.00001, loss_test:0.07439, lr:8.26e-03, fs:0.78351 (r=0.768,p=0.800),  time:18.186, tt:1382.111\n",
      "Ep:76, loss:0.00001, loss_test:0.07415, lr:8.18e-03, fs:0.78351 (r=0.768,p=0.800),  time:18.185, tt:1400.270\n",
      "Ep:77, loss:0.00001, loss_test:0.07367, lr:8.10e-03, fs:0.78351 (r=0.768,p=0.800),  time:18.196, tt:1419.314\n",
      "Ep:78, loss:0.00001, loss_test:0.07356, lr:8.02e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.176, tt:1435.908\n",
      "Ep:79, loss:0.00001, loss_test:0.07348, lr:7.94e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.193, tt:1455.423\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.07296, lr:7.94e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.210, tt:1475.038\n",
      "Ep:81, loss:0.00001, loss_test:0.07286, lr:7.94e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.217, tt:1493.824\n",
      "Ep:82, loss:0.00001, loss_test:0.07286, lr:7.94e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.229, tt:1513.011\n",
      "Ep:83, loss:0.00001, loss_test:0.07228, lr:7.94e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.231, tt:1531.372\n",
      "Ep:84, loss:0.00001, loss_test:0.07204, lr:7.94e-03, fs:0.79167 (r=0.768,p=0.817),  time:18.242, tt:1550.564\n",
      "Ep:85, loss:0.00001, loss_test:0.07213, lr:7.94e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.258, tt:1570.193\n",
      "Ep:86, loss:0.00001, loss_test:0.07158, lr:7.94e-03, fs:0.79167 (r=0.768,p=0.817),  time:18.268, tt:1589.345\n",
      "Ep:87, loss:0.00001, loss_test:0.07137, lr:7.94e-03, fs:0.79167 (r=0.768,p=0.817),  time:18.276, tt:1608.304\n",
      "Ep:88, loss:0.00001, loss_test:0.07139, lr:7.94e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.280, tt:1626.943\n",
      "Ep:89, loss:0.00001, loss_test:0.07098, lr:7.94e-03, fs:0.79167 (r=0.768,p=0.817),  time:18.288, tt:1645.910\n",
      "Ep:90, loss:0.00001, loss_test:0.07090, lr:7.94e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.294, tt:1664.734\n",
      "Ep:91, loss:0.00001, loss_test:0.07075, lr:7.86e-03, fs:0.80000 (r=0.768,p=0.835),  time:18.297, tt:1683.317\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.07069, lr:7.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.303, tt:1702.210\n",
      "Ep:93, loss:0.00001, loss_test:0.07076, lr:7.86e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.316, tt:1721.681\n",
      "Ep:94, loss:0.00001, loss_test:0.07041, lr:7.86e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.324, tt:1740.784\n",
      "Ep:95, loss:0.00001, loss_test:0.07010, lr:7.86e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.331, tt:1759.740\n",
      "Ep:96, loss:0.00001, loss_test:0.07010, lr:7.86e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.348, tt:1779.747\n",
      "Ep:97, loss:0.00001, loss_test:0.06955, lr:7.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.358, tt:1799.038\n",
      "Ep:98, loss:0.00001, loss_test:0.06949, lr:7.86e-03, fs:0.79365 (r=0.758,p=0.833),  time:18.354, tt:1817.018\n",
      "Ep:99, loss:0.00001, loss_test:0.06900, lr:7.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.354, tt:1835.360\n",
      "Ep:100, loss:0.00001, loss_test:0.06906, lr:7.86e-03, fs:0.79365 (r=0.758,p=0.833),  time:18.360, tt:1854.329\n",
      "Ep:101, loss:0.00001, loss_test:0.06863, lr:7.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.366, tt:1873.284\n",
      "Ep:102, loss:0.00001, loss_test:0.06867, lr:7.86e-03, fs:0.79787 (r=0.758,p=0.843),  time:18.368, tt:1891.943\n",
      "Ep:103, loss:0.00001, loss_test:0.06848, lr:7.78e-03, fs:0.79787 (r=0.758,p=0.843),  time:18.381, tt:1911.610\n",
      "Ep:104, loss:0.00001, loss_test:0.06820, lr:7.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:18.391, tt:1931.086\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.06811, lr:7.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:18.395, tt:1949.866\n",
      "Ep:106, loss:0.00001, loss_test:0.06766, lr:7.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:18.407, tt:1969.581\n",
      "Ep:107, loss:0.00001, loss_test:0.06763, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.408, tt:1988.040\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.06748, lr:7.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:18.409, tt:2006.570\n",
      "Ep:109, loss:0.00001, loss_test:0.06727, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.419, tt:2026.120\n",
      "Ep:110, loss:0.00001, loss_test:0.06705, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.412, tt:2043.720\n",
      "Ep:111, loss:0.00001, loss_test:0.06703, lr:7.70e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.415, tt:2062.424\n",
      "Ep:112, loss:0.00001, loss_test:0.06650, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.411, tt:2080.495\n",
      "Ep:113, loss:0.00001, loss_test:0.06684, lr:7.70e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.414, tt:2099.150\n",
      "Ep:114, loss:0.00001, loss_test:0.06602, lr:7.70e-03, fs:0.81481 (r=0.778,p=0.856),  time:18.414, tt:2117.652\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00001, loss_test:0.06620, lr:7.70e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.416, tt:2136.226\n",
      "Ep:116, loss:0.00001, loss_test:0.06583, lr:7.70e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.416, tt:2154.675\n",
      "Ep:117, loss:0.00001, loss_test:0.06541, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.426, tt:2174.290\n",
      "Ep:118, loss:0.00001, loss_test:0.06587, lr:7.70e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.441, tt:2194.509\n",
      "Ep:119, loss:0.00001, loss_test:0.06515, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.452, tt:2214.217\n",
      "Ep:120, loss:0.00001, loss_test:0.06497, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.470, tt:2234.836\n",
      "Ep:121, loss:0.00001, loss_test:0.06527, lr:7.70e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.483, tt:2254.908\n",
      "Ep:122, loss:0.00001, loss_test:0.06446, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.498, tt:2275.251\n",
      "Ep:123, loss:0.00001, loss_test:0.06487, lr:7.70e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.515, tt:2295.857\n",
      "Ep:124, loss:0.00001, loss_test:0.06436, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.516, tt:2314.446\n",
      "Ep:125, loss:0.00001, loss_test:0.06435, lr:7.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:18.521, tt:2333.636\n",
      "Ep:126, loss:0.00001, loss_test:0.06447, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.537, tt:2354.170\n",
      "Ep:127, loss:0.00001, loss_test:0.06373, lr:7.55e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.542, tt:2373.351\n",
      "Ep:128, loss:0.00001, loss_test:0.06431, lr:7.47e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.547, tt:2392.612\n",
      "Ep:129, loss:0.00001, loss_test:0.06370, lr:7.40e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.558, tt:2412.487\n",
      "Ep:130, loss:0.00001, loss_test:0.06336, lr:7.32e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.560, tt:2431.305\n",
      "Ep:131, loss:0.00001, loss_test:0.06387, lr:7.25e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.565, tt:2450.566\n",
      "Ep:132, loss:0.00001, loss_test:0.06301, lr:7.18e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.569, tt:2469.663\n",
      "Ep:133, loss:0.00001, loss_test:0.06299, lr:7.11e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.566, tt:2487.823\n",
      "Ep:134, loss:0.00001, loss_test:0.06308, lr:7.03e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.563, tt:2505.954\n",
      "Ep:135, loss:0.00001, loss_test:0.06253, lr:6.96e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.562, tt:2524.497\n",
      "Ep:136, loss:0.00001, loss_test:0.06272, lr:6.89e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.559, tt:2542.564\n",
      "Ep:137, loss:0.00001, loss_test:0.06221, lr:6.83e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.567, tt:2562.315\n",
      "Ep:138, loss:0.00001, loss_test:0.06217, lr:6.76e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.571, tt:2581.326\n",
      "Ep:139, loss:0.00001, loss_test:0.06212, lr:6.69e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.575, tt:2600.482\n",
      "Ep:140, loss:0.00001, loss_test:0.06161, lr:6.62e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.573, tt:2618.737\n",
      "Ep:141, loss:0.00001, loss_test:0.06225, lr:6.56e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.570, tt:2636.942\n",
      "Ep:142, loss:0.00001, loss_test:0.06173, lr:6.49e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.570, tt:2655.470\n",
      "Ep:143, loss:0.00001, loss_test:0.06095, lr:6.43e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.568, tt:2673.753\n",
      "Ep:144, loss:0.00001, loss_test:0.06223, lr:6.36e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.565, tt:2691.928\n",
      "Ep:145, loss:0.00001, loss_test:0.06146, lr:6.30e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.562, tt:2710.067\n",
      "Ep:146, loss:0.00001, loss_test:0.06033, lr:6.24e-03, fs:0.81915 (r=0.778,p=0.865),  time:18.567, tt:2729.314\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00001, loss_test:0.06177, lr:6.24e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.564, tt:2747.456\n",
      "Ep:148, loss:0.00001, loss_test:0.06144, lr:6.24e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.558, tt:2765.127\n",
      "Ep:149, loss:0.00001, loss_test:0.06028, lr:6.24e-03, fs:0.81720 (r=0.768,p=0.874),  time:18.554, tt:2783.070\n",
      "Ep:150, loss:0.00001, loss_test:0.06114, lr:6.24e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.549, tt:2800.951\n",
      "Ep:151, loss:0.00000, loss_test:0.06116, lr:6.24e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.550, tt:2819.595\n",
      "Ep:152, loss:0.00000, loss_test:0.06018, lr:6.24e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.549, tt:2838.043\n",
      "Ep:153, loss:0.00000, loss_test:0.06040, lr:6.24e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.545, tt:2855.919\n",
      "Ep:154, loss:0.00000, loss_test:0.06080, lr:6.24e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.548, tt:2874.965\n",
      "Ep:155, loss:0.00000, loss_test:0.06007, lr:6.24e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.549, tt:2893.580\n",
      "Ep:156, loss:0.00000, loss_test:0.05993, lr:6.24e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.543, tt:2911.247\n",
      "Ep:157, loss:0.00000, loss_test:0.06057, lr:6.24e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.547, tt:2930.381\n",
      "Ep:158, loss:0.00000, loss_test:0.05981, lr:6.17e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.541, tt:2948.046\n",
      "Ep:159, loss:0.00000, loss_test:0.05954, lr:6.11e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.534, tt:2965.409\n",
      "Ep:160, loss:0.00000, loss_test:0.06054, lr:6.05e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.522, tt:2982.056\n",
      "Ep:161, loss:0.00000, loss_test:0.05960, lr:5.99e-03, fs:0.81081 (r=0.758,p=0.872),  time:18.514, tt:2999.345\n",
      "Ep:162, loss:0.00000, loss_test:0.05914, lr:5.93e-03, fs:0.81283 (r=0.768,p=0.864),  time:18.523, tt:3019.280\n",
      "Ep:163, loss:0.00000, loss_test:0.06056, lr:5.87e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.520, tt:3037.359\n",
      "Ep:164, loss:0.00000, loss_test:0.05989, lr:5.81e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.521, tt:3055.988\n",
      "Ep:165, loss:0.00000, loss_test:0.05890, lr:5.75e-03, fs:0.81720 (r=0.768,p=0.874),  time:18.522, tt:3074.627\n",
      "Ep:166, loss:0.00000, loss_test:0.06019, lr:5.70e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.524, tt:3093.479\n",
      "Ep:167, loss:0.00000, loss_test:0.06016, lr:5.64e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.528, tt:3112.745\n",
      "Ep:168, loss:0.00000, loss_test:0.05898, lr:5.58e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.526, tt:3130.820\n",
      "Ep:169, loss:0.00000, loss_test:0.05947, lr:5.53e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.531, tt:3150.262\n",
      "Ep:170, loss:0.00000, loss_test:0.06005, lr:5.47e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.534, tt:3169.297\n",
      "Ep:171, loss:0.00000, loss_test:0.05937, lr:5.42e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.536, tt:3188.109\n",
      "Ep:172, loss:0.00000, loss_test:0.05889, lr:5.36e-03, fs:0.80645 (r=0.758,p=0.862),  time:18.537, tt:3206.871\n",
      "Ep:173, loss:0.00000, loss_test:0.06000, lr:5.31e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.539, tt:3225.810\n",
      "Ep:174, loss:0.00000, loss_test:0.06002, lr:5.26e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.539, tt:3244.306\n",
      "Ep:175, loss:0.00000, loss_test:0.05900, lr:5.20e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.541, tt:3263.220\n",
      "Ep:176, loss:0.00000, loss_test:0.05912, lr:5.15e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.536, tt:3280.805\n",
      "Ep:177, loss:0.00000, loss_test:0.05975, lr:5.10e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.536, tt:3299.375\n",
      "Ep:178, loss:0.00000, loss_test:0.05943, lr:5.05e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.533, tt:3317.419\n",
      "Ep:179, loss:0.00000, loss_test:0.05888, lr:5.00e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.536, tt:3336.474\n",
      "Ep:180, loss:0.00000, loss_test:0.05936, lr:4.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.544, tt:3356.374\n",
      "Ep:181, loss:0.00000, loss_test:0.05972, lr:4.90e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.546, tt:3375.329\n",
      "Ep:182, loss:0.00000, loss_test:0.05930, lr:4.85e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.547, tt:3394.129\n",
      "Ep:183, loss:0.00000, loss_test:0.05895, lr:4.80e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.554, tt:3413.975\n",
      "Ep:184, loss:0.00000, loss_test:0.05929, lr:4.75e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.556, tt:3432.950\n",
      "Ep:185, loss:0.00000, loss_test:0.05938, lr:4.71e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.554, tt:3450.979\n",
      "Ep:186, loss:0.00000, loss_test:0.05905, lr:4.66e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.554, tt:3469.605\n",
      "Ep:187, loss:0.00000, loss_test:0.05910, lr:4.61e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.553, tt:3488.052\n",
      "Ep:188, loss:0.00000, loss_test:0.05934, lr:4.57e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.548, tt:3505.613\n",
      "Ep:189, loss:0.00000, loss_test:0.05926, lr:4.52e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.556, tt:3525.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.05905, lr:4.48e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.555, tt:3544.031\n",
      "Ep:191, loss:0.00000, loss_test:0.05906, lr:4.43e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.557, tt:3563.029\n",
      "Ep:192, loss:0.00000, loss_test:0.05926, lr:4.39e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.562, tt:3582.436\n",
      "Ep:193, loss:0.00000, loss_test:0.05914, lr:4.34e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.565, tt:3601.678\n",
      "Ep:194, loss:0.00000, loss_test:0.05902, lr:4.30e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.570, tt:3621.229\n",
      "Ep:195, loss:0.00000, loss_test:0.05911, lr:4.26e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.576, tt:3640.982\n",
      "Ep:196, loss:0.00000, loss_test:0.05916, lr:4.21e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.576, tt:3659.400\n",
      "Ep:197, loss:0.00000, loss_test:0.05906, lr:4.17e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.577, tt:3678.243\n",
      "Ep:198, loss:0.00000, loss_test:0.05896, lr:4.13e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.576, tt:3696.628\n",
      "Ep:199, loss:0.00000, loss_test:0.05926, lr:4.09e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.577, tt:3715.461\n",
      "Ep:200, loss:0.00000, loss_test:0.05919, lr:4.05e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.577, tt:3733.880\n",
      "Ep:201, loss:0.00000, loss_test:0.05899, lr:4.01e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.575, tt:3752.070\n",
      "Ep:202, loss:0.00000, loss_test:0.05923, lr:3.97e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.572, tt:3770.185\n",
      "Ep:203, loss:0.00000, loss_test:0.05912, lr:3.93e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.572, tt:3788.683\n",
      "Ep:204, loss:0.00000, loss_test:0.05903, lr:3.89e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.576, tt:3808.016\n",
      "Ep:205, loss:0.00000, loss_test:0.05912, lr:3.85e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.582, tt:3827.866\n",
      "Ep:206, loss:0.00000, loss_test:0.05921, lr:3.81e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.590, tt:3848.161\n",
      "Ep:207, loss:0.00000, loss_test:0.05921, lr:3.77e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.598, tt:3868.341\n",
      "Ep:208, loss:0.00000, loss_test:0.05908, lr:3.73e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.600, tt:3887.497\n",
      "Ep:209, loss:0.00000, loss_test:0.05900, lr:3.70e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.607, tt:3907.509\n",
      "Ep:210, loss:0.00000, loss_test:0.05923, lr:3.66e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.611, tt:3926.870\n",
      "Ep:211, loss:0.00000, loss_test:0.05910, lr:3.62e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.616, tt:3946.584\n",
      "Ep:212, loss:0.00000, loss_test:0.05906, lr:3.59e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.634, tt:3968.972\n",
      "Ep:213, loss:0.00000, loss_test:0.05927, lr:3.55e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.637, tt:3988.423\n",
      "Ep:214, loss:0.00000, loss_test:0.05918, lr:3.52e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.639, tt:4007.389\n",
      "Ep:215, loss:0.00000, loss_test:0.05913, lr:3.48e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.644, tt:4027.033\n",
      "Ep:216, loss:0.00000, loss_test:0.05915, lr:3.45e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.646, tt:4046.276\n",
      "Ep:217, loss:0.00000, loss_test:0.05908, lr:3.41e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.655, tt:4066.733\n",
      "Ep:218, loss:0.00000, loss_test:0.05905, lr:3.38e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.662, tt:4086.999\n",
      "Ep:219, loss:0.00000, loss_test:0.05915, lr:3.34e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.668, tt:4106.920\n",
      "Ep:220, loss:0.00000, loss_test:0.05909, lr:3.31e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.673, tt:4126.774\n",
      "Ep:221, loss:0.00000, loss_test:0.05904, lr:3.28e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.671, tt:4144.914\n",
      "Ep:222, loss:0.00000, loss_test:0.05909, lr:3.24e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.674, tt:4164.406\n",
      "Ep:223, loss:0.00000, loss_test:0.05905, lr:3.21e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.682, tt:4184.678\n",
      "Ep:224, loss:0.00000, loss_test:0.05891, lr:3.18e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.682, tt:4203.557\n",
      "Ep:225, loss:0.00000, loss_test:0.05911, lr:3.15e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.686, tt:4222.977\n",
      "Ep:226, loss:0.00000, loss_test:0.05911, lr:3.12e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.690, tt:4242.627\n",
      "Ep:227, loss:0.00000, loss_test:0.05896, lr:3.09e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.693, tt:4261.923\n",
      "Ep:228, loss:0.00000, loss_test:0.05903, lr:3.05e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.697, tt:4281.618\n",
      "Ep:229, loss:0.00000, loss_test:0.05910, lr:3.02e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.703, tt:4301.749\n",
      "Ep:230, loss:0.00000, loss_test:0.05899, lr:2.99e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.708, tt:4321.516\n",
      "Ep:231, loss:0.00000, loss_test:0.05903, lr:2.96e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.709, tt:4340.434\n",
      "Ep:232, loss:0.00000, loss_test:0.05897, lr:2.93e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.714, tt:4360.372\n",
      "Ep:233, loss:0.00000, loss_test:0.05888, lr:2.90e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.719, tt:4380.331\n",
      "Ep:234, loss:0.00000, loss_test:0.05898, lr:2.88e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.722, tt:4399.669\n",
      "Ep:235, loss:0.00000, loss_test:0.05895, lr:2.85e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.726, tt:4419.421\n",
      "Ep:236, loss:0.00000, loss_test:0.05890, lr:2.82e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.733, tt:4439.631\n",
      "Ep:237, loss:0.00000, loss_test:0.05904, lr:2.79e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.738, tt:4459.618\n",
      "Ep:238, loss:0.00000, loss_test:0.05894, lr:2.76e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.742, tt:4479.226\n",
      "Ep:239, loss:0.00000, loss_test:0.05898, lr:2.73e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.746, tt:4498.981\n",
      "Ep:240, loss:0.00000, loss_test:0.05894, lr:2.71e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.754, tt:4519.747\n",
      "Ep:241, loss:0.00000, loss_test:0.05892, lr:2.68e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.766, tt:4541.438\n",
      "Ep:242, loss:0.00000, loss_test:0.05901, lr:2.65e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.775, tt:4562.412\n",
      "Ep:243, loss:0.00000, loss_test:0.05892, lr:2.63e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.781, tt:4582.518\n",
      "Ep:244, loss:0.00000, loss_test:0.05887, lr:2.60e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.785, tt:4602.444\n",
      "Ep:245, loss:0.00000, loss_test:0.05890, lr:2.57e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.790, tt:4622.282\n",
      "Ep:246, loss:0.00000, loss_test:0.05887, lr:2.55e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.794, tt:4642.034\n",
      "Ep:247, loss:0.00000, loss_test:0.05892, lr:2.52e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.803, tt:4663.105\n",
      "Ep:248, loss:0.00000, loss_test:0.05885, lr:2.50e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.807, tt:4683.000\n",
      "Ep:249, loss:0.00000, loss_test:0.05885, lr:2.47e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.805, tt:4701.140\n",
      "Ep:250, loss:0.00000, loss_test:0.05894, lr:2.45e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.807, tt:4720.489\n",
      "Ep:251, loss:0.00000, loss_test:0.05883, lr:2.42e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.805, tt:4738.908\n",
      "Ep:252, loss:0.00000, loss_test:0.05874, lr:2.40e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.807, tt:4758.287\n",
      "Ep:253, loss:0.00000, loss_test:0.05901, lr:2.38e-03, fs:0.79781 (r=0.737,p=0.869),  time:18.803, tt:4775.980\n",
      "Ep:254, loss:0.00000, loss_test:0.05900, lr:2.35e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.803, tt:4794.803\n",
      "Ep:255, loss:0.00000, loss_test:0.05878, lr:2.33e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.805, tt:4814.195\n",
      "Ep:256, loss:0.00000, loss_test:0.05893, lr:2.31e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.808, tt:4833.538\n",
      "Ep:257, loss:0.00000, loss_test:0.05897, lr:2.28e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.807, tt:4852.327\n",
      "Ep:258, loss:0.00000, loss_test:0.05885, lr:2.26e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.810, tt:4871.758\n",
      "Ep:259, loss:0.00000, loss_test:0.05876, lr:2.24e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.816, tt:4892.126\n",
      "Ep:260, loss:0.00000, loss_test:0.05890, lr:2.21e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.817, tt:4911.165\n",
      "Ep:261, loss:0.00000, loss_test:0.05895, lr:2.19e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.819, tt:4930.671\n",
      "Ep:262, loss:0.00000, loss_test:0.05879, lr:2.17e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.819, tt:4949.478\n",
      "Ep:263, loss:0.00000, loss_test:0.05866, lr:2.15e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.823, tt:4969.307\n",
      "Ep:264, loss:0.00000, loss_test:0.05888, lr:2.13e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.824, tt:4988.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:265, loss:0.00000, loss_test:0.05901, lr:2.11e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.822, tt:5006.741\n",
      "Ep:266, loss:0.00000, loss_test:0.05891, lr:2.08e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.825, tt:5026.200\n",
      "Ep:267, loss:0.00000, loss_test:0.05876, lr:2.06e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.825, tt:5045.136\n",
      "Ep:268, loss:0.00000, loss_test:0.05883, lr:2.04e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.824, tt:5063.668\n",
      "Ep:269, loss:0.00000, loss_test:0.05895, lr:2.02e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.826, tt:5083.068\n",
      "Ep:270, loss:0.00000, loss_test:0.05895, lr:2.00e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.827, tt:5102.159\n",
      "Ep:271, loss:0.00000, loss_test:0.05877, lr:1.98e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.829, tt:5121.442\n",
      "Ep:272, loss:0.00000, loss_test:0.05865, lr:1.96e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.831, tt:5140.802\n",
      "Ep:273, loss:0.00000, loss_test:0.05884, lr:1.94e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.834, tt:5160.478\n",
      "Ep:274, loss:0.00000, loss_test:0.05901, lr:1.92e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.833, tt:5178.941\n",
      "Ep:275, loss:0.00000, loss_test:0.05892, lr:1.90e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.834, tt:5198.239\n",
      "Ep:276, loss:0.00000, loss_test:0.05872, lr:1.89e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.834, tt:5216.987\n",
      "Ep:277, loss:0.00000, loss_test:0.05869, lr:1.87e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.837, tt:5236.610\n",
      "Ep:278, loss:0.00000, loss_test:0.05883, lr:1.85e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.833, tt:5254.487\n",
      "Ep:279, loss:0.00000, loss_test:0.05890, lr:1.83e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.829, tt:5272.225\n",
      "Ep:280, loss:0.00000, loss_test:0.05879, lr:1.81e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.830, tt:5291.283\n",
      "Ep:281, loss:0.00000, loss_test:0.05875, lr:1.79e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.827, tt:5309.267\n",
      "Ep:282, loss:0.00000, loss_test:0.05878, lr:1.78e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.819, tt:5325.767\n",
      "Ep:283, loss:0.00000, loss_test:0.05885, lr:1.76e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.816, tt:5343.627\n",
      "Ep:284, loss:0.00000, loss_test:0.05879, lr:1.74e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.813, tt:5361.826\n",
      "Ep:285, loss:0.00000, loss_test:0.05872, lr:1.72e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.816, tt:5381.297\n",
      "Ep:286, loss:0.00000, loss_test:0.05873, lr:1.71e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.814, tt:5399.716\n",
      "Ep:287, loss:0.00000, loss_test:0.05882, lr:1.69e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.811, tt:5417.712\n",
      "Ep:288, loss:0.00000, loss_test:0.05880, lr:1.67e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.806, tt:5434.891\n",
      "Ep:289, loss:0.00000, loss_test:0.05868, lr:1.65e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.805, tt:5453.316\n",
      "Ep:290, loss:0.00000, loss_test:0.05871, lr:1.64e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.799, tt:5470.383\n",
      "Ep:291, loss:0.00000, loss_test:0.05880, lr:1.62e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.792, tt:5487.175\n",
      "Ep:292, loss:0.00000, loss_test:0.05881, lr:1.61e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.787, tt:5504.512\n",
      "Ep:293, loss:0.00000, loss_test:0.05869, lr:1.59e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.779, tt:5521.139\n",
      "Ep:294, loss:0.00000, loss_test:0.05866, lr:1.57e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.773, tt:5537.907\n",
      "Ep:295, loss:0.00000, loss_test:0.05869, lr:1.56e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.737, tt:5546.232\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14104, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.332, tt:52.332\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13733, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:57.803, tt:115.606\n",
      "Ep:2, loss:0.00053, loss_test:0.12928, lr:1.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:60.757, tt:182.272\n",
      "Ep:3, loss:0.00050, loss_test:0.11673, lr:1.00e-02, fs:0.64935 (r=0.758,p=0.568),  time:61.441, tt:245.764\n",
      "Ep:4, loss:0.00046, loss_test:0.11070, lr:1.00e-02, fs:0.69159 (r=0.747,p=0.643),  time:62.301, tt:311.507\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.10714, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:62.739, tt:376.437\n",
      "Ep:6, loss:0.00041, loss_test:0.10430, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:63.909, tt:447.364\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09969, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:63.870, tt:510.963\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.09443, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:64.052, tt:576.469\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09169, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:63.893, tt:638.930\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.08844, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:64.042, tt:704.461\n",
      "Ep:11, loss:0.00031, loss_test:0.08749, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:64.219, tt:770.633\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.08437, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:64.306, tt:835.973\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.08332, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:64.266, tt:899.730\n",
      "Ep:14, loss:0.00027, loss_test:0.08224, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:64.152, tt:962.285\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08136, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:64.327, tt:1029.226\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.07995, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:64.458, tt:1095.787\n",
      "Ep:17, loss:0.00024, loss_test:0.07968, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:64.420, tt:1159.558\n",
      "Ep:18, loss:0.00023, loss_test:0.07777, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:64.468, tt:1224.893\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.07584, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:64.449, tt:1288.979\n",
      "Ep:20, loss:0.00021, loss_test:0.07615, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:64.394, tt:1352.273\n",
      "Ep:21, loss:0.00020, loss_test:0.07570, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:64.444, tt:1417.777\n",
      "Ep:22, loss:0.00019, loss_test:0.07365, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:64.492, tt:1483.314\n",
      "Ep:23, loss:0.00018, loss_test:0.07288, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:64.461, tt:1547.053\n",
      "Ep:24, loss:0.00017, loss_test:0.07386, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:64.645, tt:1616.133\n",
      "Ep:25, loss:0.00016, loss_test:0.07254, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:64.636, tt:1680.539\n",
      "Ep:26, loss:0.00016, loss_test:0.07107, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:64.627, tt:1744.926\n",
      "Ep:27, loss:0.00015, loss_test:0.07148, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:64.630, tt:1809.642\n",
      "Ep:28, loss:0.00014, loss_test:0.07127, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:64.566, tt:1872.417\n",
      "Ep:29, loss:0.00014, loss_test:0.07048, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:64.625, tt:1938.748\n",
      "Ep:30, loss:0.00013, loss_test:0.06962, lr:9.90e-03, fs:0.77838 (r=0.727,p=0.837),  time:64.650, tt:2004.135\n",
      "Ep:31, loss:0.00012, loss_test:0.07072, lr:9.80e-03, fs:0.79558 (r=0.727,p=0.878),  time:64.665, tt:2069.291\n",
      "Ep:32, loss:0.00012, loss_test:0.07086, lr:9.70e-03, fs:0.79121 (r=0.727,p=0.867),  time:64.655, tt:2133.610\n",
      "Ep:33, loss:0.00011, loss_test:0.06745, lr:9.61e-03, fs:0.78075 (r=0.737,p=0.830),  time:64.700, tt:2199.802\n",
      "Ep:34, loss:0.00011, loss_test:0.06672, lr:9.51e-03, fs:0.78075 (r=0.737,p=0.830),  time:64.719, tt:2265.164\n",
      "Ep:35, loss:0.00010, loss_test:0.06710, lr:9.41e-03, fs:0.78261 (r=0.727,p=0.847),  time:64.690, tt:2328.837\n",
      "Ep:36, loss:0.00010, loss_test:0.06846, lr:9.32e-03, fs:0.79558 (r=0.727,p=0.878),  time:64.712, tt:2394.340\n",
      "Ep:37, loss:0.00009, loss_test:0.06810, lr:9.23e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.715, tt:2459.155\n",
      "Ep:38, loss:0.00009, loss_test:0.07049, lr:9.14e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.683, tt:2522.646\n",
      "Ep:39, loss:0.00008, loss_test:0.06827, lr:9.04e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.676, tt:2587.055\n",
      "Ep:40, loss:0.00008, loss_test:0.06579, lr:8.95e-03, fs:0.78261 (r=0.727,p=0.847),  time:64.648, tt:2650.555\n",
      "Ep:41, loss:0.00008, loss_test:0.06629, lr:8.86e-03, fs:0.79558 (r=0.727,p=0.878),  time:64.667, tt:2716.010\n",
      "Ep:42, loss:0.00007, loss_test:0.07052, lr:8.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.714, tt:2782.685\n",
      "Ep:43, loss:0.00007, loss_test:0.07157, lr:8.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:64.708, tt:2847.132\n",
      "Ep:44, loss:0.00007, loss_test:0.06585, lr:8.60e-03, fs:0.78261 (r=0.727,p=0.847),  time:64.764, tt:2914.396\n",
      "Ep:45, loss:0.00007, loss_test:0.06741, lr:8.51e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.841, tt:2982.675\n",
      "Ep:46, loss:0.00007, loss_test:0.06845, lr:8.43e-03, fs:0.80447 (r=0.727,p=0.900),  time:64.849, tt:3047.919\n",
      "Ep:47, loss:0.00006, loss_test:0.06824, lr:8.35e-03, fs:0.80447 (r=0.727,p=0.900),  time:64.832, tt:3111.934\n",
      "Ep:48, loss:0.00006, loss_test:0.06466, lr:8.26e-03, fs:0.78261 (r=0.727,p=0.847),  time:64.854, tt:3177.829\n",
      "Ep:49, loss:0.00006, loss_test:0.06643, lr:8.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.861, tt:3243.028\n",
      "Ep:50, loss:0.00006, loss_test:0.06698, lr:8.10e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.868, tt:3308.279\n",
      "Ep:51, loss:0.00005, loss_test:0.06545, lr:8.02e-03, fs:0.79558 (r=0.727,p=0.878),  time:64.859, tt:3372.666\n",
      "Ep:52, loss:0.00005, loss_test:0.06495, lr:7.94e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.855, tt:3437.333\n",
      "Ep:53, loss:0.00005, loss_test:0.06730, lr:7.86e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.840, tt:3501.348\n",
      "Ep:54, loss:0.00005, loss_test:0.06522, lr:7.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:64.884, tt:3568.644\n",
      "Ep:55, loss:0.00005, loss_test:0.06478, lr:7.70e-03, fs:0.79121 (r=0.727,p=0.867),  time:64.938, tt:3636.554\n",
      "Ep:56, loss:0.00005, loss_test:0.06757, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:64.942, tt:3701.705\n",
      "Ep:57, loss:0.00005, loss_test:0.06655, lr:7.55e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.001, tt:3770.080\n",
      "Ep:58, loss:0.00004, loss_test:0.06593, lr:7.47e-03, fs:0.79558 (r=0.727,p=0.878),  time:65.002, tt:3835.119\n",
      "Ep:59, loss:0.00004, loss_test:0.06690, lr:7.40e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.003, tt:3900.187\n",
      "Ep:60, loss:0.00004, loss_test:0.06616, lr:7.32e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.003, tt:3965.185\n",
      "Ep:61, loss:0.00004, loss_test:0.06892, lr:7.25e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.027, tt:4031.672\n",
      "Ep:62, loss:0.00004, loss_test:0.06522, lr:7.18e-03, fs:0.78689 (r=0.727,p=0.857),  time:65.033, tt:4097.107\n",
      "Ep:63, loss:0.00004, loss_test:0.06721, lr:7.11e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.058, tt:4163.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00004, loss_test:0.06774, lr:7.03e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.085, tt:4230.502\n",
      "Ep:65, loss:0.00004, loss_test:0.06558, lr:6.96e-03, fs:0.79558 (r=0.727,p=0.878),  time:65.121, tt:4297.974\n",
      "Ep:66, loss:0.00004, loss_test:0.06883, lr:6.89e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.188, tt:4367.629\n",
      "Ep:67, loss:0.00004, loss_test:0.06707, lr:6.83e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.205, tt:4433.945\n",
      "Ep:68, loss:0.00004, loss_test:0.06628, lr:6.76e-03, fs:0.79121 (r=0.727,p=0.867),  time:65.192, tt:4498.236\n",
      "Ep:69, loss:0.00003, loss_test:0.06872, lr:6.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.171, tt:4561.971\n",
      "Ep:70, loss:0.00003, loss_test:0.06669, lr:6.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.162, tt:4626.507\n",
      "Ep:71, loss:0.00003, loss_test:0.06814, lr:6.56e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.159, tt:4691.427\n",
      "Ep:72, loss:0.00003, loss_test:0.06894, lr:6.49e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.159, tt:4756.602\n",
      "Ep:73, loss:0.00003, loss_test:0.06856, lr:6.43e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.164, tt:4822.146\n",
      "Ep:74, loss:0.00003, loss_test:0.06761, lr:6.36e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.205, tt:4890.403\n",
      "Ep:75, loss:0.00003, loss_test:0.06990, lr:6.30e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.226, tt:4957.151\n",
      "Ep:76, loss:0.00003, loss_test:0.06677, lr:6.24e-03, fs:0.80000 (r=0.727,p=0.889),  time:65.237, tt:5023.230\n",
      "Ep:77, loss:0.00003, loss_test:0.06914, lr:6.17e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.269, tt:5090.962\n",
      "Ep:78, loss:0.00003, loss_test:0.06835, lr:6.11e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.313, tt:5159.740\n",
      "Ep:79, loss:0.00003, loss_test:0.06913, lr:6.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.335, tt:5226.830\n",
      "Ep:80, loss:0.00003, loss_test:0.06875, lr:5.99e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.333, tt:5291.938\n",
      "Ep:81, loss:0.00003, loss_test:0.06916, lr:5.93e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.349, tt:5358.633\n",
      "Ep:82, loss:0.00003, loss_test:0.06938, lr:5.87e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.357, tt:5424.636\n",
      "Ep:83, loss:0.00003, loss_test:0.06790, lr:5.81e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.391, tt:5492.885\n",
      "Ep:84, loss:0.00002, loss_test:0.06875, lr:5.75e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.418, tt:5560.509\n",
      "Ep:85, loss:0.00002, loss_test:0.06891, lr:5.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.425, tt:5626.550\n",
      "Ep:86, loss:0.00002, loss_test:0.06879, lr:5.64e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.452, tt:5694.325\n",
      "Ep:87, loss:0.00002, loss_test:0.06964, lr:5.58e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.477, tt:5762.005\n",
      "Ep:88, loss:0.00002, loss_test:0.06871, lr:5.53e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.457, tt:5825.672\n",
      "Ep:89, loss:0.00002, loss_test:0.06972, lr:5.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.488, tt:5893.904\n",
      "Ep:90, loss:0.00002, loss_test:0.06957, lr:5.42e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.541, tt:5964.243\n",
      "Ep:91, loss:0.00002, loss_test:0.06990, lr:5.36e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.530, tt:6028.796\n",
      "Ep:92, loss:0.00002, loss_test:0.06914, lr:5.31e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.540, tt:6095.262\n",
      "Ep:93, loss:0.00002, loss_test:0.07067, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:65.564, tt:6162.977\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.06980, lr:5.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.568, tt:6228.998\n",
      "Ep:95, loss:0.00002, loss_test:0.07024, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:65.581, tt:6295.801\n",
      "Ep:96, loss:0.00002, loss_test:0.07042, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:65.581, tt:6361.326\n",
      "Ep:97, loss:0.00002, loss_test:0.06897, lr:5.26e-03, fs:0.80447 (r=0.727,p=0.900),  time:65.608, tt:6429.576\n",
      "Ep:98, loss:0.00002, loss_test:0.07063, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:65.607, tt:6495.107\n",
      "Ep:99, loss:0.00002, loss_test:0.07004, lr:5.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.602, tt:6560.244\n",
      "Ep:100, loss:0.00002, loss_test:0.06986, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:65.618, tt:6627.443\n",
      "Ep:101, loss:0.00002, loss_test:0.06965, lr:5.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:65.601, tt:6691.266\n",
      "Ep:102, loss:0.00002, loss_test:0.07093, lr:5.26e-03, fs:0.82286 (r=0.727,p=0.947),  time:65.593, tt:6756.112\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00002, loss_test:0.07015, lr:5.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.545, tt:6816.644\n",
      "Ep:104, loss:0.00002, loss_test:0.07025, lr:5.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:65.508, tt:6878.307\n",
      "Ep:105, loss:0.00002, loss_test:0.07119, lr:5.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:65.438, tt:6936.447\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.13820, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:74.471, tt:74.471\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.12755, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:78.006, tt:156.012\n",
      "Ep:2, loss:0.00049, loss_test:0.11512, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:79.290, tt:237.871\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.11015, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:79.103, tt:316.412\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00042, loss_test:0.10165, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:80.051, tt:400.254\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.09548, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:80.497, tt:482.981\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.08972, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:80.959, tt:566.716\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00033, loss_test:0.08610, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:81.368, tt:650.945\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00031, loss_test:0.08123, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:81.346, tt:732.113\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.07831, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:81.392, tt:813.925\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00026, loss_test:0.07475, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:81.505, tt:896.556\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.07198, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:81.676, tt:980.109\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.06963, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:81.653, tt:1061.489\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.06894, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:81.897, tt:1146.556\n",
      "Ep:14, loss:0.00019, loss_test:0.06559, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:81.811, tt:1227.171\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.06316, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:81.831, tt:1309.298\n",
      "Ep:16, loss:0.00016, loss_test:0.06143, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:81.852, tt:1391.489\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.06086, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:81.844, tt:1473.193\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.06239, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:81.937, tt:1556.801\n",
      "Ep:19, loss:0.00013, loss_test:0.06279, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:81.965, tt:1639.297\n",
      "Ep:20, loss:0.00012, loss_test:0.06080, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:81.908, tt:1720.071\n",
      "Ep:21, loss:0.00011, loss_test:0.06423, lr:1.00e-02, fs:0.86517 (r=0.778,p=0.975),  time:82.030, tt:1804.666\n",
      "Ep:22, loss:0.00010, loss_test:0.05985, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:82.081, tt:1887.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00009, loss_test:0.05720, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:82.173, tt:1972.163\n",
      "Ep:24, loss:0.00008, loss_test:0.05542, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:82.162, tt:2054.057\n",
      "Ep:25, loss:0.00007, loss_test:0.05333, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:82.216, tt:2137.605\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00006, loss_test:0.05353, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:82.330, tt:2222.902\n",
      "Ep:27, loss:0.00006, loss_test:0.05632, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:82.481, tt:2309.481\n",
      "Ep:28, loss:0.00005, loss_test:0.05258, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:82.539, tt:2393.642\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00005, loss_test:0.05469, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:82.521, tt:2475.643\n",
      "Ep:30, loss:0.00004, loss_test:0.05451, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:82.615, tt:2561.054\n",
      "Ep:31, loss:0.00004, loss_test:0.06194, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:82.608, tt:2643.455\n",
      "Ep:32, loss:0.00004, loss_test:0.05565, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:82.673, tt:2728.195\n",
      "Ep:33, loss:0.00003, loss_test:0.05501, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:82.731, tt:2812.853\n",
      "Ep:34, loss:0.00003, loss_test:0.05489, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:82.675, tt:2893.641\n",
      "Ep:35, loss:0.00003, loss_test:0.06002, lr:1.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:82.671, tt:2976.163\n",
      "Ep:36, loss:0.00003, loss_test:0.05495, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:82.583, tt:3055.574\n",
      "Ep:37, loss:0.00002, loss_test:0.05703, lr:1.00e-02, fs:0.80952 (r=0.687,p=0.986),  time:82.625, tt:3139.735\n",
      "Ep:38, loss:0.00002, loss_test:0.05986, lr:1.00e-02, fs:0.83041 (r=0.717,p=0.986),  time:82.600, tt:3221.401\n",
      "Ep:39, loss:0.00002, loss_test:0.05966, lr:1.00e-02, fs:0.80952 (r=0.687,p=0.986),  time:82.667, tt:3306.664\n",
      "Ep:40, loss:0.00002, loss_test:0.06200, lr:9.90e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.658, tt:3388.985\n",
      "Ep:41, loss:0.00002, loss_test:0.06047, lr:9.80e-03, fs:0.80952 (r=0.687,p=0.986),  time:82.699, tt:3473.365\n",
      "Ep:42, loss:0.00002, loss_test:0.06320, lr:9.70e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.799, tt:3560.368\n",
      "Ep:43, loss:0.00001, loss_test:0.06281, lr:9.61e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.746, tt:3640.814\n",
      "Ep:44, loss:0.00001, loss_test:0.06282, lr:9.51e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.755, tt:3723.965\n",
      "Ep:45, loss:0.00001, loss_test:0.06445, lr:9.41e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.772, tt:3807.520\n",
      "Ep:46, loss:0.00001, loss_test:0.06419, lr:9.32e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.808, tt:3891.958\n",
      "Ep:47, loss:0.00001, loss_test:0.06384, lr:9.23e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.867, tt:3977.614\n",
      "Ep:48, loss:0.00001, loss_test:0.06359, lr:9.14e-03, fs:0.80240 (r=0.677,p=0.985),  time:82.887, tt:4061.485\n",
      "Ep:49, loss:0.00001, loss_test:0.06525, lr:9.04e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.956, tt:4147.793\n",
      "Ep:50, loss:0.00001, loss_test:0.06262, lr:8.95e-03, fs:0.82143 (r=0.697,p=1.000),  time:82.957, tt:4230.796\n",
      "Ep:51, loss:0.00001, loss_test:0.06706, lr:8.86e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.976, tt:4314.768\n",
      "Ep:52, loss:0.00001, loss_test:0.06635, lr:8.78e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.963, tt:4397.022\n",
      "Ep:53, loss:0.00001, loss_test:0.06778, lr:8.69e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.948, tt:4479.201\n",
      "Ep:54, loss:0.00001, loss_test:0.06713, lr:8.60e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.908, tt:4559.921\n",
      "Ep:55, loss:0.00001, loss_test:0.06689, lr:8.51e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.942, tt:4644.767\n",
      "Ep:56, loss:0.00001, loss_test:0.06797, lr:8.43e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.917, tt:4726.252\n",
      "Ep:57, loss:0.00001, loss_test:0.06853, lr:8.35e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.915, tt:4809.056\n",
      "Ep:58, loss:0.00000, loss_test:0.06966, lr:8.26e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.868, tt:4889.218\n",
      "Ep:59, loss:0.00000, loss_test:0.06979, lr:8.18e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.884, tt:4973.062\n",
      "Ep:60, loss:0.00000, loss_test:0.06861, lr:8.10e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.904, tt:5057.144\n",
      "Ep:61, loss:0.00000, loss_test:0.06717, lr:8.02e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.899, tt:5139.765\n",
      "Ep:62, loss:0.00000, loss_test:0.07066, lr:7.94e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.935, tt:5224.901\n",
      "Ep:63, loss:0.00000, loss_test:0.07253, lr:7.86e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.912, tt:5306.380\n",
      "Ep:64, loss:0.00000, loss_test:0.07039, lr:7.78e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.866, tt:5386.271\n",
      "Ep:65, loss:0.00000, loss_test:0.06714, lr:7.70e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.880, tt:5470.110\n",
      "Ep:66, loss:0.00000, loss_test:0.06870, lr:7.62e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.896, tt:5554.025\n",
      "Ep:67, loss:0.00000, loss_test:0.07003, lr:7.55e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.930, tt:5639.244\n",
      "Ep:68, loss:0.00000, loss_test:0.07166, lr:7.47e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.935, tt:5722.535\n",
      "Ep:69, loss:0.00000, loss_test:0.07250, lr:7.40e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.926, tt:5804.809\n",
      "Ep:70, loss:0.00000, loss_test:0.06837, lr:7.32e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.937, tt:5888.501\n",
      "Ep:71, loss:0.00000, loss_test:0.07048, lr:7.25e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.965, tt:5973.496\n",
      "Ep:72, loss:0.00000, loss_test:0.07123, lr:7.18e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.969, tt:6056.738\n",
      "Ep:73, loss:0.00000, loss_test:0.06980, lr:7.11e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.997, tt:6141.742\n",
      "Ep:74, loss:0.00000, loss_test:0.06789, lr:7.03e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.028, tt:6227.104\n",
      "Ep:75, loss:0.00000, loss_test:0.07052, lr:6.96e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.037, tt:6310.811\n",
      "Ep:76, loss:0.00000, loss_test:0.06901, lr:6.89e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.099, tt:6398.642\n",
      "Ep:77, loss:0.00000, loss_test:0.07021, lr:6.83e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.071, tt:6479.570\n",
      "Ep:78, loss:0.00000, loss_test:0.06867, lr:6.76e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.126, tt:6566.917\n",
      "Ep:79, loss:0.00000, loss_test:0.07126, lr:6.69e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.149, tt:6651.939\n",
      "Ep:80, loss:0.00000, loss_test:0.06935, lr:6.62e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.110, tt:6731.911\n",
      "Ep:81, loss:0.00000, loss_test:0.06965, lr:6.56e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.136, tt:6817.146\n",
      "Ep:82, loss:0.00000, loss_test:0.06865, lr:6.49e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.122, tt:6899.089\n",
      "Ep:83, loss:0.00000, loss_test:0.06861, lr:6.43e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.135, tt:6983.341\n",
      "Ep:84, loss:0.00000, loss_test:0.07076, lr:6.36e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.151, tt:7067.847\n",
      "Ep:85, loss:0.00000, loss_test:0.06952, lr:6.30e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.141, tt:7150.118\n",
      "Ep:86, loss:0.00000, loss_test:0.07000, lr:6.24e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.162, tt:7235.053\n",
      "Ep:87, loss:0.00000, loss_test:0.06863, lr:6.17e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.195, tt:7321.175\n",
      "Ep:88, loss:0.00000, loss_test:0.06959, lr:6.11e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.185, tt:7403.477\n",
      "Ep:89, loss:0.00000, loss_test:0.07084, lr:6.05e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.181, tt:7486.307\n",
      "Ep:90, loss:0.00000, loss_test:0.06883, lr:5.99e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.167, tt:7568.174\n",
      "Ep:91, loss:0.00000, loss_test:0.06915, lr:5.93e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.166, tt:7651.317\n",
      "Ep:92, loss:0.00000, loss_test:0.06992, lr:5.87e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.181, tt:7735.792\n",
      "Ep:93, loss:0.00000, loss_test:0.06864, lr:5.81e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.188, tt:7819.651\n",
      "Ep:94, loss:0.00000, loss_test:0.07155, lr:5.75e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.212, tt:7905.093\n",
      "Ep:95, loss:0.00000, loss_test:0.06851, lr:5.70e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.210, tt:7988.140\n",
      "Ep:96, loss:0.00000, loss_test:0.06933, lr:5.64e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.212, tt:8071.536\n",
      "Ep:97, loss:0.00000, loss_test:0.06924, lr:5.58e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.222, tt:8155.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:98, loss:0.00000, loss_test:0.07060, lr:5.53e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.227, tt:8239.459\n",
      "Ep:99, loss:0.00000, loss_test:0.06904, lr:5.47e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.247, tt:8324.662\n",
      "Ep:100, loss:0.00000, loss_test:0.06877, lr:5.42e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.236, tt:8406.862\n",
      "Ep:101, loss:0.00000, loss_test:0.07061, lr:5.36e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.221, tt:8488.573\n",
      "Ep:102, loss:0.00000, loss_test:0.06918, lr:5.31e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.149, tt:8564.361\n",
      "Ep:103, loss:0.00000, loss_test:0.06890, lr:5.26e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.110, tt:8643.444\n",
      "Ep:104, loss:0.00000, loss_test:0.07083, lr:5.20e-03, fs:0.80723 (r=0.677,p=1.000),  time:83.055, tt:8720.727\n",
      "Ep:105, loss:0.00000, loss_test:0.06863, lr:5.15e-03, fs:0.80723 (r=0.677,p=1.000),  time:82.951, tt:8792.786\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.13652, lr:1.00e-02, fs:0.68056 (r=0.990,p=0.519),  time:64.907, tt:64.907\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.12991, lr:1.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:69.592, tt:139.184\n",
      "Ep:2, loss:0.00051, loss_test:0.12539, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:71.764, tt:215.293\n",
      "Ep:3, loss:0.00049, loss_test:0.12065, lr:1.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:73.027, tt:292.109\n",
      "Ep:4, loss:0.00047, loss_test:0.11648, lr:1.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:73.274, tt:366.372\n",
      "Ep:5, loss:0.00045, loss_test:0.11044, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:73.643, tt:441.861\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.10614, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:74.094, tt:518.660\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.10222, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:74.386, tt:595.085\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00038, loss_test:0.09905, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:74.275, tt:668.476\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.09516, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:74.105, tt:741.054\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.09164, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:74.232, tt:816.557\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.08908, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:74.359, tt:892.305\n",
      "Ep:12, loss:0.00030, loss_test:0.08618, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:74.426, tt:967.544\n",
      "Ep:13, loss:0.00028, loss_test:0.08420, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:74.492, tt:1042.891\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.08185, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:74.518, tt:1117.763\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.08100, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:74.547, tt:1192.746\n",
      "Ep:16, loss:0.00023, loss_test:0.08079, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:74.536, tt:1267.113\n",
      "Ep:17, loss:0.00022, loss_test:0.07812, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:74.497, tt:1340.945\n",
      "Ep:18, loss:0.00020, loss_test:0.07757, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:74.503, tt:1415.552\n",
      "Ep:19, loss:0.00019, loss_test:0.07823, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:74.450, tt:1489.007\n",
      "Ep:20, loss:0.00018, loss_test:0.07797, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:74.537, tt:1565.271\n",
      "Ep:21, loss:0.00017, loss_test:0.07671, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:74.621, tt:1641.670\n",
      "Ep:22, loss:0.00016, loss_test:0.07500, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:74.623, tt:1716.338\n",
      "Ep:23, loss:0.00015, loss_test:0.07601, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:74.555, tt:1789.325\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07702, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:74.573, tt:1864.326\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07882, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:74.611, tt:1939.882\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07815, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:74.619, tt:2014.716\n",
      "Ep:27, loss:0.00012, loss_test:0.07851, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:74.678, tt:2090.977\n",
      "Ep:28, loss:0.00012, loss_test:0.07404, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:74.677, tt:2165.636\n",
      "Ep:29, loss:0.00011, loss_test:0.07780, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:74.725, tt:2241.748\n",
      "Ep:30, loss:0.00010, loss_test:0.07554, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:74.643, tt:2313.926\n",
      "Ep:31, loss:0.00010, loss_test:0.07751, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:74.556, tt:2385.792\n",
      "Ep:32, loss:0.00010, loss_test:0.07601, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:74.474, tt:2457.634\n",
      "Ep:33, loss:0.00009, loss_test:0.07959, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:74.424, tt:2530.418\n",
      "Ep:34, loss:0.00008, loss_test:0.07527, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:74.383, tt:2603.417\n",
      "Ep:35, loss:0.00008, loss_test:0.07311, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:74.449, tt:2680.160\n",
      "Ep:36, loss:0.00008, loss_test:0.08017, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:74.456, tt:2754.868\n",
      "Ep:37, loss:0.00008, loss_test:0.08304, lr:9.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.444, tt:2828.860\n",
      "Ep:38, loss:0.00007, loss_test:0.08168, lr:9.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.495, tt:2905.295\n",
      "Ep:39, loss:0.00007, loss_test:0.07811, lr:9.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:74.471, tt:2978.828\n",
      "Ep:40, loss:0.00007, loss_test:0.07533, lr:9.61e-03, fs:0.80899 (r=0.727,p=0.911),  time:74.413, tt:3050.936\n",
      "Ep:41, loss:0.00006, loss_test:0.07535, lr:9.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:74.402, tt:3124.903\n",
      "Ep:42, loss:0.00006, loss_test:0.07665, lr:9.41e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.404, tt:3199.384\n",
      "Ep:43, loss:0.00006, loss_test:0.07819, lr:9.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:74.435, tt:3275.161\n",
      "Ep:44, loss:0.00005, loss_test:0.07643, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:74.449, tt:3350.216\n",
      "Ep:45, loss:0.00005, loss_test:0.07759, lr:9.14e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.460, tt:3425.159\n",
      "Ep:46, loss:0.00005, loss_test:0.07645, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:74.390, tt:3496.325\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00005, loss_test:0.07770, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:74.378, tt:3570.162\n",
      "Ep:48, loss:0.00004, loss_test:0.07841, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.349, tt:3643.109\n",
      "Ep:49, loss:0.00004, loss_test:0.08237, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.298, tt:3714.912\n",
      "Ep:50, loss:0.00004, loss_test:0.08117, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.307, tt:3789.643\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.08242, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:74.357, tt:3866.543\n",
      "Ep:52, loss:0.00004, loss_test:0.08107, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.396, tt:3942.986\n",
      "Ep:53, loss:0.00004, loss_test:0.08397, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.448, tt:4020.211\n",
      "Ep:54, loss:0.00004, loss_test:0.08686, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.496, tt:4097.299\n",
      "Ep:55, loss:0.00003, loss_test:0.08397, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:74.508, tt:4172.450\n",
      "Ep:56, loss:0.00003, loss_test:0.08663, lr:9.04e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.584, tt:4251.279\n",
      "Ep:57, loss:0.00003, loss_test:0.08994, lr:9.04e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.609, tt:4327.297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00003, loss_test:0.08722, lr:9.04e-03, fs:0.81609 (r=0.717,p=0.947),  time:74.581, tt:4400.284\n",
      "Ep:59, loss:0.00003, loss_test:0.08212, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:74.527, tt:4471.614\n",
      "Ep:60, loss:0.00003, loss_test:0.08297, lr:9.04e-03, fs:0.81143 (r=0.717,p=0.934),  time:74.472, tt:4542.793\n",
      "Ep:61, loss:0.00002, loss_test:0.08296, lr:9.04e-03, fs:0.81143 (r=0.717,p=0.934),  time:74.517, tt:4620.084\n",
      "Ep:62, loss:0.00002, loss_test:0.08588, lr:8.95e-03, fs:0.78107 (r=0.667,p=0.943),  time:74.515, tt:4694.463\n",
      "Ep:63, loss:0.00002, loss_test:0.08213, lr:8.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.485, tt:4767.028\n",
      "Ep:64, loss:0.00002, loss_test:0.08312, lr:8.78e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.489, tt:4841.784\n",
      "Ep:65, loss:0.00002, loss_test:0.08865, lr:8.69e-03, fs:0.77381 (r=0.657,p=0.942),  time:74.467, tt:4914.811\n",
      "Ep:66, loss:0.00002, loss_test:0.08457, lr:8.60e-03, fs:0.82286 (r=0.727,p=0.947),  time:74.442, tt:4987.601\n",
      "Ep:67, loss:0.00002, loss_test:0.08348, lr:8.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.501, tt:5066.061\n",
      "Ep:68, loss:0.00002, loss_test:0.08317, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.507, tt:5140.949\n",
      "Ep:69, loss:0.00002, loss_test:0.08601, lr:8.35e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.488, tt:5214.180\n",
      "Ep:70, loss:0.00002, loss_test:0.08877, lr:8.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:74.467, tt:5287.187\n",
      "Ep:71, loss:0.00002, loss_test:0.08657, lr:8.18e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.445, tt:5360.011\n",
      "Ep:72, loss:0.00002, loss_test:0.08400, lr:8.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:74.415, tt:5432.322\n",
      "Ep:73, loss:0.00002, loss_test:0.08344, lr:8.02e-03, fs:0.82081 (r=0.717,p=0.959),  time:74.404, tt:5505.870\n",
      "Ep:74, loss:0.00002, loss_test:0.08504, lr:7.94e-03, fs:0.80702 (r=0.697,p=0.958),  time:74.376, tt:5578.224\n",
      "Ep:75, loss:0.00001, loss_test:0.08754, lr:7.86e-03, fs:0.76647 (r=0.646,p=0.941),  time:74.370, tt:5652.124\n",
      "Ep:76, loss:0.00001, loss_test:0.08809, lr:7.78e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.384, tt:5727.595\n",
      "Ep:77, loss:0.00001, loss_test:0.08754, lr:7.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:74.408, tt:5803.825\n",
      "Ep:78, loss:0.00001, loss_test:0.08776, lr:7.62e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.365, tt:5874.856\n",
      "Ep:79, loss:0.00001, loss_test:0.08739, lr:7.55e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.367, tt:5949.332\n",
      "Ep:80, loss:0.00001, loss_test:0.08556, lr:7.47e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.359, tt:6023.063\n",
      "Ep:81, loss:0.00001, loss_test:0.08313, lr:7.40e-03, fs:0.83237 (r=0.727,p=0.973),  time:74.360, tt:6097.517\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.08903, lr:7.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.357, tt:6171.650\n",
      "Ep:83, loss:0.00001, loss_test:0.08910, lr:7.40e-03, fs:0.78049 (r=0.646,p=0.985),  time:74.360, tt:6246.266\n",
      "Ep:84, loss:0.00001, loss_test:0.09017, lr:7.40e-03, fs:0.76647 (r=0.646,p=0.941),  time:74.344, tt:6319.215\n",
      "Ep:85, loss:0.00001, loss_test:0.08759, lr:7.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.330, tt:6392.402\n",
      "Ep:86, loss:0.00001, loss_test:0.08658, lr:7.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.370, tt:6470.213\n",
      "Ep:87, loss:0.00001, loss_test:0.08804, lr:7.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.347, tt:6542.507\n",
      "Ep:88, loss:0.00001, loss_test:0.08885, lr:7.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.387, tt:6620.411\n",
      "Ep:89, loss:0.00001, loss_test:0.08898, lr:7.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:74.386, tt:6694.758\n",
      "Ep:90, loss:0.00001, loss_test:0.08802, lr:7.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.361, tt:6766.819\n",
      "Ep:91, loss:0.00001, loss_test:0.08755, lr:7.40e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.362, tt:6841.333\n",
      "Ep:92, loss:0.00001, loss_test:0.08907, lr:7.40e-03, fs:0.78049 (r=0.646,p=0.985),  time:74.399, tt:6919.139\n",
      "Ep:93, loss:0.00001, loss_test:0.08488, lr:7.32e-03, fs:0.79762 (r=0.677,p=0.971),  time:74.392, tt:6992.863\n",
      "Ep:94, loss:0.00001, loss_test:0.08662, lr:7.25e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.408, tt:7068.753\n",
      "Ep:95, loss:0.00001, loss_test:0.08518, lr:7.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.421, tt:7144.372\n",
      "Ep:96, loss:0.00001, loss_test:0.08580, lr:7.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.415, tt:7218.259\n",
      "Ep:97, loss:0.00001, loss_test:0.08461, lr:7.03e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.439, tt:7295.027\n",
      "Ep:98, loss:0.00001, loss_test:0.08604, lr:6.96e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.464, tt:7371.938\n",
      "Ep:99, loss:0.00001, loss_test:0.08749, lr:6.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.479, tt:7447.882\n",
      "Ep:100, loss:0.00001, loss_test:0.08768, lr:6.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.481, tt:7522.546\n",
      "Ep:101, loss:0.00001, loss_test:0.08669, lr:6.76e-03, fs:0.77576 (r=0.646,p=0.970),  time:74.479, tt:7596.841\n",
      "Ep:102, loss:0.00001, loss_test:0.08544, lr:6.69e-03, fs:0.81176 (r=0.697,p=0.972),  time:74.394, tt:7662.548\n",
      "Ep:103, loss:0.00001, loss_test:0.08486, lr:6.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:74.300, tt:7727.227\n",
      "Ep:104, loss:0.00001, loss_test:0.08412, lr:6.56e-03, fs:0.83237 (r=0.727,p=0.973),  time:74.052, tt:7775.486\n",
      "Ep:105, loss:0.00001, loss_test:0.08668, lr:6.49e-03, fs:0.77576 (r=0.646,p=0.970),  time:73.614, tt:7803.065\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"7-7\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02436, lr:6.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:26.799, tt:26.799\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02454, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:28.979, tt:57.959\n",
      "Ep:2, loss:0.00005, loss_test:0.02683, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.585, tt:91.756\n",
      "Ep:3, loss:0.00005, loss_test:0.02658, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:31.352, tt:125.409\n",
      "Ep:4, loss:0.00005, loss_test:0.02582, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:31.645, tt:158.225\n",
      "Ep:5, loss:0.00005, loss_test:0.02496, lr:6.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:31.997, tt:191.983\n",
      "Ep:6, loss:0.00005, loss_test:0.02409, lr:6.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:32.183, tt:225.284\n",
      "Ep:7, loss:0.00005, loss_test:0.02317, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:32.291, tt:258.331\n",
      "Ep:8, loss:0.00005, loss_test:0.02248, lr:6.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:32.497, tt:292.471\n",
      "Ep:9, loss:0.00005, loss_test:0.02291, lr:6.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:32.573, tt:325.732\n",
      "Ep:10, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:32.694, tt:359.633\n",
      "Ep:11, loss:0.00004, loss_test:0.02228, lr:6.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:32.731, tt:392.777\n",
      "Ep:12, loss:0.00004, loss_test:0.02224, lr:5.94e-02, fs:0.63492 (r=0.808,p=0.523),  time:32.826, tt:426.741\n",
      "Ep:13, loss:0.00004, loss_test:0.02195, lr:5.88e-02, fs:0.63281 (r=0.818,p=0.516),  time:32.889, tt:460.452\n",
      "Ep:14, loss:0.00004, loss_test:0.02141, lr:5.82e-02, fs:0.63813 (r=0.828,p=0.519),  time:32.958, tt:494.377\n",
      "Ep:15, loss:0.00004, loss_test:0.02081, lr:5.76e-02, fs:0.62948 (r=0.798,p=0.520),  time:33.052, tt:528.838\n",
      "Ep:16, loss:0.00004, loss_test:0.02037, lr:5.71e-02, fs:0.64754 (r=0.798,p=0.545),  time:33.140, tt:563.381\n",
      "Ep:17, loss:0.00004, loss_test:0.01993, lr:5.65e-02, fs:0.65844 (r=0.808,p=0.556),  time:33.173, tt:597.118\n",
      "Ep:18, loss:0.00004, loss_test:0.01945, lr:5.59e-02, fs:0.66116 (r=0.808,p=0.559),  time:33.179, tt:630.410\n",
      "Ep:19, loss:0.00004, loss_test:0.01901, lr:5.54e-02, fs:0.67220 (r=0.818,p=0.570),  time:33.194, tt:663.875\n",
      "Ep:20, loss:0.00003, loss_test:0.01872, lr:5.48e-02, fs:0.68103 (r=0.798,p=0.594),  time:33.213, tt:697.464\n",
      "Ep:21, loss:0.00003, loss_test:0.01844, lr:5.43e-02, fs:0.68722 (r=0.788,p=0.609),  time:33.221, tt:730.852\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01817, lr:5.43e-02, fs:0.69027 (r=0.788,p=0.614),  time:33.242, tt:764.556\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01784, lr:5.43e-02, fs:0.69604 (r=0.798,p=0.617),  time:33.296, tt:799.106\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01770, lr:5.43e-02, fs:0.71111 (r=0.808,p=0.635),  time:33.309, tt:832.715\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01760, lr:5.43e-02, fs:0.71233 (r=0.788,p=0.650),  time:33.290, tt:865.544\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01748, lr:5.43e-02, fs:0.70968 (r=0.778,p=0.653),  time:33.297, tt:899.009\n",
      "Ep:27, loss:0.00003, loss_test:0.01721, lr:5.43e-02, fs:0.72897 (r=0.788,p=0.678),  time:33.319, tt:932.938\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01704, lr:5.43e-02, fs:0.74178 (r=0.798,p=0.693),  time:33.330, tt:966.560\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01691, lr:5.43e-02, fs:0.72727 (r=0.768,p=0.691),  time:33.299, tt:998.976\n",
      "Ep:30, loss:0.00003, loss_test:0.01686, lr:5.43e-02, fs:0.73077 (r=0.768,p=0.697),  time:33.320, tt:1032.929\n",
      "Ep:31, loss:0.00002, loss_test:0.01664, lr:5.43e-02, fs:0.73786 (r=0.768,p=0.710),  time:33.316, tt:1066.117\n",
      "Ep:32, loss:0.00002, loss_test:0.01652, lr:5.43e-02, fs:0.73786 (r=0.768,p=0.710),  time:33.297, tt:1098.787\n",
      "Ep:33, loss:0.00002, loss_test:0.01650, lr:5.43e-02, fs:0.75248 (r=0.768,p=0.738),  time:33.321, tt:1132.898\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01624, lr:5.43e-02, fs:0.75622 (r=0.768,p=0.745),  time:33.268, tt:1164.387\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01607, lr:5.43e-02, fs:0.75622 (r=0.768,p=0.745),  time:33.246, tt:1196.864\n",
      "Ep:36, loss:0.00002, loss_test:0.01583, lr:5.43e-02, fs:0.76382 (r=0.768,p=0.760),  time:33.310, tt:1232.453\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01580, lr:5.43e-02, fs:0.75622 (r=0.768,p=0.745),  time:33.321, tt:1266.204\n",
      "Ep:38, loss:0.00002, loss_test:0.01576, lr:5.43e-02, fs:0.75622 (r=0.768,p=0.745),  time:33.306, tt:1298.940\n",
      "Ep:39, loss:0.00002, loss_test:0.01582, lr:5.43e-02, fs:0.76000 (r=0.768,p=0.752),  time:33.350, tt:1333.992\n",
      "Ep:40, loss:0.00002, loss_test:0.01579, lr:5.43e-02, fs:0.76000 (r=0.768,p=0.752),  time:33.363, tt:1367.879\n",
      "Ep:41, loss:0.00002, loss_test:0.01587, lr:5.43e-02, fs:0.77000 (r=0.778,p=0.762),  time:33.375, tt:1401.755\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01609, lr:5.43e-02, fs:0.76617 (r=0.778,p=0.755),  time:33.359, tt:1434.435\n",
      "Ep:43, loss:0.00002, loss_test:0.01635, lr:5.43e-02, fs:0.76768 (r=0.768,p=0.768),  time:33.323, tt:1466.198\n",
      "Ep:44, loss:0.00002, loss_test:0.01623, lr:5.43e-02, fs:0.77778 (r=0.778,p=0.778),  time:33.318, tt:1499.289\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01619, lr:5.43e-02, fs:0.78818 (r=0.808,p=0.769),  time:33.310, tt:1532.256\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01639, lr:5.43e-02, fs:0.77778 (r=0.778,p=0.778),  time:33.330, tt:1566.528\n",
      "Ep:47, loss:0.00001, loss_test:0.01681, lr:5.43e-02, fs:0.78571 (r=0.778,p=0.794),  time:33.296, tt:1598.212\n",
      "Ep:48, loss:0.00001, loss_test:0.01698, lr:5.43e-02, fs:0.78173 (r=0.778,p=0.786),  time:33.291, tt:1631.259\n",
      "Ep:49, loss:0.00001, loss_test:0.01708, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:33.281, tt:1664.031\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01730, lr:5.43e-02, fs:0.78173 (r=0.778,p=0.786),  time:33.278, tt:1697.159\n",
      "Ep:51, loss:0.00001, loss_test:0.01723, lr:5.43e-02, fs:0.78571 (r=0.778,p=0.794),  time:33.288, tt:1730.952\n",
      "Ep:52, loss:0.00001, loss_test:0.01727, lr:5.43e-02, fs:0.80000 (r=0.788,p=0.812),  time:33.288, tt:1764.252\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01761, lr:5.43e-02, fs:0.78571 (r=0.778,p=0.794),  time:33.315, tt:1799.002\n",
      "Ep:54, loss:0.00001, loss_test:0.01758, lr:5.43e-02, fs:0.78974 (r=0.778,p=0.802),  time:33.363, tt:1834.947\n",
      "Ep:55, loss:0.00001, loss_test:0.01810, lr:5.43e-02, fs:0.80829 (r=0.788,p=0.830),  time:33.377, tt:1869.118\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01792, lr:5.43e-02, fs:0.79381 (r=0.778,p=0.811),  time:33.391, tt:1903.277\n",
      "Ep:57, loss:0.00001, loss_test:0.01811, lr:5.43e-02, fs:0.79381 (r=0.778,p=0.811),  time:33.389, tt:1936.573\n",
      "Ep:58, loss:0.00001, loss_test:0.01857, lr:5.43e-02, fs:0.80208 (r=0.778,p=0.828),  time:33.387, tt:1969.860\n",
      "Ep:59, loss:0.00001, loss_test:0.01775, lr:5.43e-02, fs:0.81053 (r=0.778,p=0.846),  time:33.388, tt:2003.270\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01829, lr:5.43e-02, fs:0.80628 (r=0.778,p=0.837),  time:33.392, tt:2036.886\n",
      "Ep:61, loss:0.00001, loss_test:0.01835, lr:5.43e-02, fs:0.81053 (r=0.778,p=0.846),  time:33.415, tt:2071.729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01810, lr:5.43e-02, fs:0.81481 (r=0.778,p=0.856),  time:33.449, tt:2107.273\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01874, lr:5.43e-02, fs:0.80628 (r=0.778,p=0.837),  time:33.480, tt:2142.719\n",
      "Ep:64, loss:0.00001, loss_test:0.01839, lr:5.43e-02, fs:0.82353 (r=0.778,p=0.875),  time:33.534, tt:2179.724\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01884, lr:5.43e-02, fs:0.82353 (r=0.778,p=0.875),  time:33.548, tt:2214.200\n",
      "Ep:66, loss:0.00001, loss_test:0.01951, lr:5.43e-02, fs:0.82796 (r=0.778,p=0.885),  time:33.565, tt:2248.863\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01896, lr:5.43e-02, fs:0.83696 (r=0.778,p=0.906),  time:33.591, tt:2284.155\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.02013, lr:5.43e-02, fs:0.83696 (r=0.778,p=0.906),  time:33.612, tt:2319.215\n",
      "Ep:69, loss:0.00001, loss_test:0.01943, lr:5.43e-02, fs:0.82353 (r=0.778,p=0.875),  time:33.642, tt:2354.931\n",
      "Ep:70, loss:0.00001, loss_test:0.01909, lr:5.43e-02, fs:0.82353 (r=0.778,p=0.875),  time:33.671, tt:2390.658\n",
      "Ep:71, loss:0.00001, loss_test:0.01986, lr:5.43e-02, fs:0.82353 (r=0.778,p=0.875),  time:33.673, tt:2424.438\n",
      "Ep:72, loss:0.00001, loss_test:0.01912, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.683, tt:2458.844\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.02053, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.717, tt:2495.058\n",
      "Ep:74, loss:0.00001, loss_test:0.02033, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.726, tt:2529.452\n",
      "Ep:75, loss:0.00001, loss_test:0.02078, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.736, tt:2563.939\n",
      "Ep:76, loss:0.00001, loss_test:0.02064, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.758, tt:2599.368\n",
      "Ep:77, loss:0.00001, loss_test:0.02080, lr:5.43e-02, fs:0.84375 (r=0.818,p=0.871),  time:33.761, tt:2633.327\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01901, lr:5.43e-02, fs:0.79570 (r=0.747,p=0.851),  time:33.772, tt:2667.997\n",
      "Ep:79, loss:0.00001, loss_test:0.01927, lr:5.43e-02, fs:0.82723 (r=0.798,p=0.859),  time:33.776, tt:2702.073\n",
      "Ep:80, loss:0.00001, loss_test:0.01822, lr:5.43e-02, fs:0.81915 (r=0.778,p=0.865),  time:33.787, tt:2736.769\n",
      "Ep:81, loss:0.00001, loss_test:0.01958, lr:5.43e-02, fs:0.83696 (r=0.778,p=0.906),  time:33.796, tt:2771.277\n",
      "Ep:82, loss:0.00001, loss_test:0.02012, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.791, tt:2804.692\n",
      "Ep:83, loss:0.00001, loss_test:0.01926, lr:5.43e-02, fs:0.82796 (r=0.778,p=0.885),  time:33.786, tt:2838.018\n",
      "Ep:84, loss:0.00001, loss_test:0.02082, lr:5.43e-02, fs:0.83516 (r=0.768,p=0.916),  time:33.802, tt:2873.195\n",
      "Ep:85, loss:0.00001, loss_test:0.02058, lr:5.43e-02, fs:0.84615 (r=0.778,p=0.928),  time:33.798, tt:2906.618\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.02155, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.814, tt:2941.853\n",
      "Ep:87, loss:0.00000, loss_test:0.02142, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.818, tt:2976.010\n",
      "Ep:88, loss:0.00000, loss_test:0.02190, lr:5.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:33.810, tt:3009.114\n",
      "Ep:89, loss:0.00000, loss_test:0.02230, lr:5.43e-02, fs:0.82873 (r=0.758,p=0.915),  time:33.813, tt:3043.154\n",
      "Ep:90, loss:0.00000, loss_test:0.02182, lr:5.43e-02, fs:0.82873 (r=0.758,p=0.915),  time:33.855, tt:3080.802\n",
      "Ep:91, loss:0.00000, loss_test:0.02345, lr:5.43e-02, fs:0.83333 (r=0.758,p=0.926),  time:33.855, tt:3114.689\n",
      "Ep:92, loss:0.00000, loss_test:0.02217, lr:5.43e-02, fs:0.82873 (r=0.758,p=0.915),  time:33.846, tt:3147.668\n",
      "Ep:93, loss:0.00000, loss_test:0.02266, lr:5.43e-02, fs:0.81564 (r=0.737,p=0.912),  time:33.846, tt:3181.519\n",
      "Ep:94, loss:0.00000, loss_test:0.02393, lr:5.43e-02, fs:0.84444 (r=0.768,p=0.938),  time:33.849, tt:3215.618\n",
      "Ep:95, loss:0.00000, loss_test:0.02263, lr:5.43e-02, fs:0.82873 (r=0.758,p=0.915),  time:33.863, tt:3250.862\n",
      "Ep:96, loss:0.00000, loss_test:0.02331, lr:5.43e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.860, tt:3284.385\n",
      "Ep:97, loss:0.00000, loss_test:0.02380, lr:5.37e-02, fs:0.83799 (r=0.758,p=0.938),  time:33.870, tt:3319.268\n",
      "Ep:98, loss:0.00000, loss_test:0.02394, lr:5.32e-02, fs:0.82682 (r=0.747,p=0.925),  time:33.876, tt:3353.700\n",
      "Ep:99, loss:0.00000, loss_test:0.02406, lr:5.27e-02, fs:0.80000 (r=0.707,p=0.921),  time:33.872, tt:3387.222\n",
      "Ep:100, loss:0.00000, loss_test:0.02472, lr:5.21e-02, fs:0.80460 (r=0.707,p=0.933),  time:33.876, tt:3421.457\n",
      "Ep:101, loss:0.00000, loss_test:0.02550, lr:5.16e-02, fs:0.82955 (r=0.737,p=0.948),  time:33.882, tt:3455.976\n",
      "Ep:102, loss:0.00000, loss_test:0.02521, lr:5.11e-02, fs:0.80000 (r=0.707,p=0.921),  time:33.881, tt:3489.782\n",
      "Ep:103, loss:0.00000, loss_test:0.02404, lr:5.06e-02, fs:0.80000 (r=0.707,p=0.921),  time:33.889, tt:3524.493\n",
      "Ep:104, loss:0.00000, loss_test:0.02559, lr:5.01e-02, fs:0.82955 (r=0.737,p=0.948),  time:33.890, tt:3558.468\n",
      "Ep:105, loss:0.00000, loss_test:0.02486, lr:4.96e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.886, tt:3591.964\n",
      "Ep:106, loss:0.00000, loss_test:0.02534, lr:4.91e-02, fs:0.80460 (r=0.707,p=0.933),  time:33.884, tt:3625.635\n",
      "Ep:107, loss:0.00000, loss_test:0.02690, lr:4.86e-02, fs:0.80925 (r=0.707,p=0.946),  time:33.894, tt:3660.506\n",
      "Ep:108, loss:0.00000, loss_test:0.02491, lr:4.81e-02, fs:0.80925 (r=0.707,p=0.946),  time:33.900, tt:3695.116\n",
      "Ep:109, loss:0.00000, loss_test:0.02603, lr:4.76e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.902, tt:3729.271\n",
      "Ep:110, loss:0.00000, loss_test:0.02655, lr:4.71e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.924, tt:3765.527\n",
      "Ep:111, loss:0.00000, loss_test:0.02624, lr:4.67e-02, fs:0.80460 (r=0.707,p=0.933),  time:33.933, tt:3800.513\n",
      "Ep:112, loss:0.00000, loss_test:0.02696, lr:4.62e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.922, tt:3833.241\n",
      "Ep:113, loss:0.00000, loss_test:0.02647, lr:4.57e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.922, tt:3867.113\n",
      "Ep:114, loss:0.00000, loss_test:0.02625, lr:4.53e-02, fs:0.80925 (r=0.707,p=0.946),  time:33.922, tt:3901.050\n",
      "Ep:115, loss:0.00000, loss_test:0.02829, lr:4.48e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.936, tt:3936.548\n",
      "Ep:116, loss:0.00000, loss_test:0.02639, lr:4.44e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.933, tt:3970.190\n",
      "Ep:117, loss:0.00000, loss_test:0.02748, lr:4.39e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.939, tt:4004.825\n",
      "Ep:118, loss:0.00000, loss_test:0.02832, lr:4.35e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.936, tt:4038.441\n",
      "Ep:119, loss:0.00000, loss_test:0.02664, lr:4.31e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.925, tt:4071.053\n",
      "Ep:120, loss:0.00000, loss_test:0.02916, lr:4.26e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.915, tt:4103.762\n",
      "Ep:121, loss:0.00000, loss_test:0.02776, lr:4.22e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.918, tt:4138.005\n",
      "Ep:122, loss:0.00000, loss_test:0.02826, lr:4.18e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.923, tt:4172.524\n",
      "Ep:123, loss:0.00000, loss_test:0.02883, lr:4.14e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.922, tt:4206.298\n",
      "Ep:124, loss:0.00000, loss_test:0.02804, lr:4.10e-02, fs:0.81395 (r=0.707,p=0.959),  time:33.932, tt:4241.481\n",
      "Ep:125, loss:0.00000, loss_test:0.02914, lr:4.05e-02, fs:0.79762 (r=0.677,p=0.971),  time:33.937, tt:4276.014\n",
      "Ep:126, loss:0.00000, loss_test:0.02781, lr:4.01e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.944, tt:4310.904\n",
      "Ep:127, loss:0.00000, loss_test:0.02967, lr:3.97e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.941, tt:4344.497\n",
      "Ep:128, loss:0.00000, loss_test:0.02923, lr:3.93e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.938, tt:4378.003\n",
      "Ep:129, loss:0.00000, loss_test:0.02902, lr:3.89e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.933, tt:4411.341\n",
      "Ep:130, loss:0.00000, loss_test:0.03026, lr:3.86e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.951, tt:4447.529\n",
      "Ep:131, loss:0.00000, loss_test:0.02913, lr:3.82e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.955, tt:4482.104\n",
      "Ep:132, loss:0.00000, loss_test:0.03024, lr:3.78e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.945, tt:4514.717\n",
      "Ep:133, loss:0.00000, loss_test:0.03009, lr:3.74e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.947, tt:4548.856\n",
      "Ep:134, loss:0.00000, loss_test:0.03025, lr:3.70e-02, fs:0.81871 (r=0.707,p=0.972),  time:33.961, tt:4584.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.03098, lr:3.67e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.955, tt:4617.827\n",
      "Ep:136, loss:0.00000, loss_test:0.03042, lr:3.63e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.960, tt:4652.585\n",
      "Ep:137, loss:0.00000, loss_test:0.03092, lr:3.59e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.963, tt:4686.844\n",
      "Ep:138, loss:0.00000, loss_test:0.03058, lr:3.56e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.971, tt:4721.972\n",
      "Ep:139, loss:0.00000, loss_test:0.03129, lr:3.52e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.984, tt:4757.732\n",
      "Ep:140, loss:0.00000, loss_test:0.03133, lr:3.49e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.988, tt:4792.340\n",
      "Ep:141, loss:0.00000, loss_test:0.03132, lr:3.45e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.998, tt:4827.676\n",
      "Ep:142, loss:0.00000, loss_test:0.03156, lr:3.42e-02, fs:0.82353 (r=0.707,p=0.986),  time:33.999, tt:4861.858\n",
      "Ep:143, loss:0.00000, loss_test:0.03122, lr:3.38e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.009, tt:4897.246\n",
      "Ep:144, loss:0.00000, loss_test:0.03217, lr:3.35e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.010, tt:4931.395\n",
      "Ep:145, loss:0.00000, loss_test:0.03176, lr:3.32e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.016, tt:4966.291\n",
      "Ep:146, loss:0.00000, loss_test:0.03175, lr:3.28e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.011, tt:4999.587\n",
      "Ep:147, loss:0.00000, loss_test:0.03207, lr:3.25e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.013, tt:5033.903\n",
      "Ep:148, loss:0.00000, loss_test:0.03205, lr:3.22e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.009, tt:5067.360\n",
      "Ep:149, loss:0.00000, loss_test:0.03274, lr:3.19e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.010, tt:5101.436\n",
      "Ep:150, loss:0.00000, loss_test:0.03204, lr:3.15e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.011, tt:5135.730\n",
      "Ep:151, loss:0.00000, loss_test:0.03262, lr:3.12e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.015, tt:5170.347\n",
      "Ep:152, loss:0.00000, loss_test:0.03295, lr:3.09e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.015, tt:5204.361\n",
      "Ep:153, loss:0.00000, loss_test:0.03231, lr:3.06e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.014, tt:5238.137\n",
      "Ep:154, loss:0.00000, loss_test:0.03284, lr:3.03e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.007, tt:5271.112\n",
      "Ep:155, loss:0.00000, loss_test:0.03298, lr:3.00e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.012, tt:5305.825\n",
      "Ep:156, loss:0.00000, loss_test:0.03309, lr:2.97e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.015, tt:5340.370\n",
      "Ep:157, loss:0.00000, loss_test:0.03332, lr:2.94e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.014, tt:5374.246\n",
      "Ep:158, loss:0.00000, loss_test:0.03294, lr:2.91e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.013, tt:5408.106\n",
      "Ep:159, loss:0.00000, loss_test:0.03365, lr:2.88e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.023, tt:5443.665\n",
      "Ep:160, loss:0.00000, loss_test:0.03328, lr:2.85e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.037, tt:5479.913\n",
      "Ep:161, loss:0.00000, loss_test:0.03328, lr:2.82e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.043, tt:5514.912\n",
      "Ep:162, loss:0.00000, loss_test:0.03385, lr:2.80e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.045, tt:5549.388\n",
      "Ep:163, loss:0.00000, loss_test:0.03342, lr:2.77e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.046, tt:5583.622\n",
      "Ep:164, loss:0.00000, loss_test:0.03400, lr:2.74e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.053, tt:5618.803\n",
      "Ep:165, loss:0.00000, loss_test:0.03367, lr:2.71e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.062, tt:5654.297\n",
      "Ep:166, loss:0.00000, loss_test:0.03430, lr:2.69e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.076, tt:5690.673\n",
      "Ep:167, loss:0.00000, loss_test:0.03357, lr:2.66e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.084, tt:5726.113\n",
      "Ep:168, loss:0.00000, loss_test:0.03418, lr:2.63e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.093, tt:5761.669\n",
      "Ep:169, loss:0.00000, loss_test:0.03407, lr:2.61e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.093, tt:5795.857\n",
      "Ep:170, loss:0.00000, loss_test:0.03445, lr:2.58e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.107, tt:5832.342\n",
      "Ep:171, loss:0.00000, loss_test:0.03380, lr:2.55e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.116, tt:5867.987\n",
      "Ep:172, loss:0.00000, loss_test:0.03470, lr:2.53e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.122, tt:5903.117\n",
      "Ep:173, loss:0.00000, loss_test:0.03406, lr:2.50e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.129, tt:5938.419\n",
      "Ep:174, loss:0.00000, loss_test:0.03502, lr:2.48e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.139, tt:5974.345\n",
      "Ep:175, loss:0.00000, loss_test:0.03395, lr:2.45e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.146, tt:6009.661\n",
      "Ep:176, loss:0.00000, loss_test:0.03505, lr:2.43e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.154, tt:6045.262\n",
      "Ep:177, loss:0.00000, loss_test:0.03432, lr:2.40e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.157, tt:6079.925\n",
      "Ep:178, loss:0.00000, loss_test:0.03500, lr:2.38e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.160, tt:6114.573\n",
      "Ep:179, loss:0.00000, loss_test:0.03446, lr:2.36e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.164, tt:6149.498\n",
      "Ep:180, loss:0.00000, loss_test:0.03506, lr:2.33e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.173, tt:6185.371\n",
      "Ep:181, loss:0.00000, loss_test:0.03491, lr:2.31e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.178, tt:6220.362\n",
      "Ep:182, loss:0.00000, loss_test:0.03519, lr:2.29e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.181, tt:6255.160\n",
      "Ep:183, loss:0.00000, loss_test:0.03480, lr:2.26e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.193, tt:6291.452\n",
      "Ep:184, loss:0.00000, loss_test:0.03515, lr:2.24e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.199, tt:6326.816\n",
      "Ep:185, loss:0.00000, loss_test:0.03527, lr:2.22e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.203, tt:6361.756\n",
      "Ep:186, loss:0.00000, loss_test:0.03526, lr:2.20e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.206, tt:6396.552\n",
      "Ep:187, loss:0.00000, loss_test:0.03525, lr:2.17e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.213, tt:6431.983\n",
      "Ep:188, loss:0.00000, loss_test:0.03530, lr:2.15e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.228, tt:6469.019\n",
      "Ep:189, loss:0.00000, loss_test:0.03545, lr:2.13e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.235, tt:6504.672\n",
      "Ep:190, loss:0.00000, loss_test:0.03548, lr:2.11e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.244, tt:6540.646\n",
      "Ep:191, loss:0.00000, loss_test:0.03547, lr:2.09e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.244, tt:6574.914\n",
      "Ep:192, loss:0.00000, loss_test:0.03556, lr:2.07e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.235, tt:6607.324\n",
      "Ep:193, loss:0.00000, loss_test:0.03557, lr:2.05e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.220, tt:6638.648\n",
      "Ep:194, loss:0.00000, loss_test:0.03574, lr:2.03e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.186, tt:6666.352\n",
      "Ep:195, loss:0.00000, loss_test:0.03578, lr:2.01e-02, fs:0.82353 (r=0.707,p=0.986),  time:34.153, tt:6694.034\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01986, lr:6.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:31.003, tt:31.003\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02229, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.925, tt:61.849\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02427, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.432, tt:94.296\n",
      "Ep:3, loss:0.00005, loss_test:0.02447, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.481, tt:125.923\n",
      "Ep:4, loss:0.00005, loss_test:0.02398, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.488, tt:157.439\n",
      "Ep:5, loss:0.00005, loss_test:0.02282, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.517, tt:189.103\n",
      "Ep:6, loss:0.00004, loss_test:0.02137, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.436, tt:220.055\n",
      "Ep:7, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:31.357, tt:250.854\n",
      "Ep:8, loss:0.00004, loss_test:0.01892, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:31.360, tt:282.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00004, loss_test:0.01867, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:31.369, tt:313.687\n",
      "Ep:10, loss:0.00004, loss_test:0.01889, lr:6.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:31.338, tt:344.718\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01898, lr:6.00e-02, fs:0.66957 (r=0.778,p=0.588),  time:31.277, tt:375.324\n",
      "Ep:12, loss:0.00004, loss_test:0.01876, lr:6.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:31.256, tt:406.328\n",
      "Ep:13, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:31.458, tt:440.415\n",
      "Ep:14, loss:0.00003, loss_test:0.01833, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:31.455, tt:471.818\n",
      "Ep:15, loss:0.00003, loss_test:0.01810, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:31.377, tt:502.029\n",
      "Ep:16, loss:0.00003, loss_test:0.01786, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:31.297, tt:532.056\n",
      "Ep:17, loss:0.00003, loss_test:0.01765, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:31.309, tt:563.563\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01754, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:31.366, tt:595.959\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:31.336, tt:626.720\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:31.300, tt:657.309\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01730, lr:6.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:31.323, tt:689.106\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01713, lr:6.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:31.282, tt:719.484\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.300, tt:751.197\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01691, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:31.310, tt:782.761\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:31.316, tt:814.225\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01677, lr:6.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:31.332, tt:845.977\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:31.279, tt:875.822\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:31.291, tt:907.453\n",
      "Ep:29, loss:0.00003, loss_test:0.01674, lr:6.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:31.280, tt:938.412\n",
      "Ep:30, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:31.293, tt:970.083\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01657, lr:6.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:31.320, tt:1002.227\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01649, lr:6.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:31.285, tt:1032.392\n",
      "Ep:33, loss:0.00002, loss_test:0.01641, lr:6.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:31.273, tt:1063.269\n",
      "Ep:34, loss:0.00002, loss_test:0.01635, lr:6.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:31.230, tt:1093.060\n",
      "Ep:35, loss:0.00002, loss_test:0.01632, lr:6.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:31.292, tt:1126.523\n",
      "Ep:36, loss:0.00002, loss_test:0.01631, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.281, tt:1157.399\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01625, lr:6.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:31.262, tt:1187.973\n",
      "Ep:38, loss:0.00002, loss_test:0.01620, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.249, tt:1218.693\n",
      "Ep:39, loss:0.00002, loss_test:0.01618, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.237, tt:1249.497\n",
      "Ep:40, loss:0.00002, loss_test:0.01617, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.206, tt:1279.437\n",
      "Ep:41, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:31.185, tt:1309.764\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:31.137, tt:1338.887\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:31.124, tt:1369.460\n",
      "Ep:44, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:31.057, tt:1397.566\n",
      "Ep:45, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:31.036, tt:1427.662\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:31.025, tt:1458.181\n",
      "Ep:47, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:31.005, tt:1488.225\n",
      "Ep:48, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:31.003, tt:1519.127\n",
      "Ep:49, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.995, tt:1549.729\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.983, tt:1580.149\n",
      "Ep:51, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:30.987, tt:1611.333\n",
      "Ep:52, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.971, tt:1641.451\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.970, tt:1672.387\n",
      "Ep:54, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.938, tt:1701.614\n",
      "Ep:55, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:30.939, tt:1732.562\n",
      "Ep:56, loss:0.00002, loss_test:0.01612, lr:6.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.935, tt:1763.274\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.971, tt:1796.304\n",
      "Ep:58, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.961, tt:1826.724\n",
      "Ep:59, loss:0.00002, loss_test:0.01631, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.931, tt:1855.863\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01634, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.941, tt:1887.405\n",
      "Ep:61, loss:0.00002, loss_test:0.01635, lr:6.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.933, tt:1917.876\n",
      "Ep:62, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.906, tt:1947.090\n",
      "Ep:63, loss:0.00001, loss_test:0.01642, lr:6.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:30.899, tt:1977.521\n",
      "Ep:64, loss:0.00001, loss_test:0.01643, lr:6.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:30.897, tt:2008.299\n",
      "Ep:65, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.874, tt:2037.678\n",
      "Ep:66, loss:0.00001, loss_test:0.01644, lr:6.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.872, tt:2068.407\n",
      "Ep:67, loss:0.00001, loss_test:0.01654, lr:6.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:30.865, tt:2098.822\n",
      "Ep:68, loss:0.00001, loss_test:0.01663, lr:6.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.854, tt:2128.938\n",
      "Ep:69, loss:0.00001, loss_test:0.01662, lr:6.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.847, tt:2159.257\n",
      "Ep:70, loss:0.00001, loss_test:0.01663, lr:6.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.856, tt:2190.793\n",
      "Ep:71, loss:0.00001, loss_test:0.01666, lr:5.94e-02, fs:0.75258 (r=0.737,p=0.768),  time:30.841, tt:2220.554\n",
      "Ep:72, loss:0.00001, loss_test:0.01667, lr:5.88e-02, fs:0.75897 (r=0.747,p=0.771),  time:30.847, tt:2251.832\n",
      "Ep:73, loss:0.00001, loss_test:0.01670, lr:5.82e-02, fs:0.75258 (r=0.737,p=0.768),  time:30.821, tt:2280.760\n",
      "Ep:74, loss:0.00001, loss_test:0.01675, lr:5.76e-02, fs:0.74611 (r=0.727,p=0.766),  time:30.798, tt:2309.823\n",
      "Ep:75, loss:0.00001, loss_test:0.01682, lr:5.71e-02, fs:0.74611 (r=0.727,p=0.766),  time:30.789, tt:2339.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00001, loss_test:0.01679, lr:5.65e-02, fs:0.74611 (r=0.727,p=0.766),  time:30.768, tt:2369.117\n",
      "Ep:77, loss:0.00001, loss_test:0.01681, lr:5.59e-02, fs:0.74611 (r=0.727,p=0.766),  time:30.758, tt:2399.108\n",
      "Ep:78, loss:0.00001, loss_test:0.01686, lr:5.54e-02, fs:0.75000 (r=0.727,p=0.774),  time:30.757, tt:2429.792\n",
      "Ep:79, loss:0.00001, loss_test:0.01699, lr:5.48e-02, fs:0.75789 (r=0.727,p=0.791),  time:30.753, tt:2460.254\n",
      "Ep:80, loss:0.00001, loss_test:0.01703, lr:5.43e-02, fs:0.75132 (r=0.717,p=0.789),  time:30.726, tt:2488.785\n",
      "Ep:81, loss:0.00001, loss_test:0.01698, lr:5.37e-02, fs:0.75132 (r=0.717,p=0.789),  time:30.719, tt:2518.981\n",
      "Ep:82, loss:0.00001, loss_test:0.01702, lr:5.32e-02, fs:0.74468 (r=0.707,p=0.787),  time:30.712, tt:2549.080\n",
      "Ep:83, loss:0.00001, loss_test:0.01711, lr:5.27e-02, fs:0.74866 (r=0.707,p=0.795),  time:30.717, tt:2580.214\n",
      "Ep:84, loss:0.00001, loss_test:0.01715, lr:5.21e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.707, tt:2610.121\n",
      "Ep:85, loss:0.00001, loss_test:0.01716, lr:5.16e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.687, tt:2639.048\n",
      "Ep:86, loss:0.00001, loss_test:0.01715, lr:5.11e-02, fs:0.74866 (r=0.707,p=0.795),  time:30.678, tt:2668.947\n",
      "Ep:87, loss:0.00001, loss_test:0.01720, lr:5.06e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.670, tt:2698.917\n",
      "Ep:88, loss:0.00001, loss_test:0.01722, lr:5.01e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.657, tt:2728.444\n",
      "Ep:89, loss:0.00001, loss_test:0.01728, lr:4.96e-02, fs:0.74317 (r=0.687,p=0.810),  time:30.660, tt:2759.371\n",
      "Ep:90, loss:0.00001, loss_test:0.01727, lr:4.91e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.647, tt:2788.839\n",
      "Ep:91, loss:0.00001, loss_test:0.01727, lr:4.86e-02, fs:0.75138 (r=0.687,p=0.829),  time:30.643, tt:2819.127\n",
      "Ep:92, loss:0.00001, loss_test:0.01728, lr:4.81e-02, fs:0.75138 (r=0.687,p=0.829),  time:30.645, tt:2849.966\n",
      "Ep:93, loss:0.00001, loss_test:0.01739, lr:4.76e-02, fs:0.75138 (r=0.687,p=0.829),  time:30.642, tt:2880.322\n",
      "Ep:94, loss:0.00001, loss_test:0.01743, lr:4.71e-02, fs:0.75556 (r=0.687,p=0.840),  time:30.636, tt:2910.377\n",
      "Ep:95, loss:0.00001, loss_test:0.01747, lr:4.67e-02, fs:0.75556 (r=0.687,p=0.840),  time:30.642, tt:2941.659\n",
      "Ep:96, loss:0.00001, loss_test:0.01745, lr:4.62e-02, fs:0.76404 (r=0.687,p=0.861),  time:30.637, tt:2971.837\n",
      "Ep:97, loss:0.00001, loss_test:0.01743, lr:4.57e-02, fs:0.75556 (r=0.687,p=0.840),  time:30.627, tt:3001.484\n",
      "Ep:98, loss:0.00001, loss_test:0.01754, lr:4.53e-02, fs:0.76404 (r=0.687,p=0.861),  time:30.626, tt:3032.012\n",
      "Ep:99, loss:0.00001, loss_test:0.01760, lr:4.48e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.637, tt:3063.731\n",
      "Ep:100, loss:0.00001, loss_test:0.01764, lr:4.44e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.629, tt:3093.558\n",
      "Ep:101, loss:0.00001, loss_test:0.01767, lr:4.39e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.630, tt:3124.216\n",
      "Ep:102, loss:0.00001, loss_test:0.01766, lr:4.35e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.645, tt:3156.426\n",
      "Ep:103, loss:0.00001, loss_test:0.01773, lr:4.31e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.648, tt:3187.406\n",
      "Ep:104, loss:0.00001, loss_test:0.01776, lr:4.26e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.645, tt:3217.721\n",
      "Ep:105, loss:0.00001, loss_test:0.01779, lr:4.22e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.645, tt:3248.376\n",
      "Ep:106, loss:0.00001, loss_test:0.01783, lr:4.18e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.640, tt:3278.434\n",
      "Ep:107, loss:0.00001, loss_test:0.01781, lr:4.14e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.633, tt:3308.347\n",
      "Ep:108, loss:0.00001, loss_test:0.01784, lr:4.10e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.628, tt:3338.398\n",
      "Ep:109, loss:0.00001, loss_test:0.01789, lr:4.05e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.620, tt:3368.191\n",
      "Ep:110, loss:0.00001, loss_test:0.01793, lr:4.01e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.613, tt:3397.998\n",
      "Ep:111, loss:0.00001, loss_test:0.01797, lr:3.97e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.611, tt:3428.478\n",
      "Ep:112, loss:0.00001, loss_test:0.01800, lr:3.93e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.606, tt:3458.462\n",
      "Ep:113, loss:0.00001, loss_test:0.01803, lr:3.89e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.595, tt:3487.777\n",
      "Ep:114, loss:0.00001, loss_test:0.01803, lr:3.86e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.594, tt:3518.352\n",
      "Ep:115, loss:0.00001, loss_test:0.01803, lr:3.82e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.594, tt:3548.864\n",
      "Ep:116, loss:0.00001, loss_test:0.01808, lr:3.78e-02, fs:0.74286 (r=0.657,p=0.855),  time:30.610, tt:3581.323\n",
      "Ep:117, loss:0.00001, loss_test:0.01812, lr:3.74e-02, fs:0.75000 (r=0.667,p=0.857),  time:30.599, tt:3610.688\n",
      "Ep:118, loss:0.00001, loss_test:0.01816, lr:3.70e-02, fs:0.75000 (r=0.667,p=0.857),  time:30.596, tt:3640.973\n",
      "Ep:119, loss:0.00001, loss_test:0.01814, lr:3.67e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.594, tt:3671.258\n",
      "Ep:120, loss:0.00001, loss_test:0.01817, lr:3.63e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.597, tt:3702.191\n",
      "Ep:121, loss:0.00001, loss_test:0.01817, lr:3.59e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.594, tt:3732.409\n",
      "Ep:122, loss:0.00001, loss_test:0.01820, lr:3.56e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.597, tt:3763.384\n",
      "Ep:123, loss:0.00001, loss_test:0.01826, lr:3.52e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.599, tt:3794.322\n",
      "Ep:124, loss:0.00001, loss_test:0.01830, lr:3.49e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.609, tt:3826.129\n",
      "Ep:125, loss:0.00001, loss_test:0.01838, lr:3.45e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.608, tt:3856.557\n",
      "Ep:126, loss:0.00001, loss_test:0.01838, lr:3.42e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.601, tt:3886.265\n",
      "Ep:127, loss:0.00001, loss_test:0.01840, lr:3.38e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.601, tt:3916.925\n",
      "Ep:128, loss:0.00001, loss_test:0.01842, lr:3.35e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.590, tt:3946.161\n",
      "Ep:129, loss:0.00001, loss_test:0.01844, lr:3.32e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.586, tt:3976.123\n",
      "Ep:130, loss:0.00001, loss_test:0.01846, lr:3.28e-02, fs:0.75429 (r=0.667,p=0.868),  time:30.592, tt:4007.594\n",
      "Ep:131, loss:0.00001, loss_test:0.01847, lr:3.25e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.597, tt:4038.849\n",
      "Ep:132, loss:0.00001, loss_test:0.01846, lr:3.22e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.595, tt:4069.072\n",
      "Ep:133, loss:0.00001, loss_test:0.01848, lr:3.19e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.593, tt:4099.431\n",
      "Ep:134, loss:0.00001, loss_test:0.01855, lr:3.15e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.591, tt:4129.766\n",
      "Ep:135, loss:0.00001, loss_test:0.01862, lr:3.12e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.594, tt:4160.816\n",
      "Ep:136, loss:0.00001, loss_test:0.01861, lr:3.09e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.588, tt:4190.591\n",
      "Ep:137, loss:0.00001, loss_test:0.01860, lr:3.06e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.584, tt:4220.595\n",
      "Ep:138, loss:0.00001, loss_test:0.01861, lr:3.03e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.579, tt:4250.415\n",
      "Ep:139, loss:0.00001, loss_test:0.01865, lr:3.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.575, tt:4280.478\n",
      "Ep:140, loss:0.00001, loss_test:0.01871, lr:2.97e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.564, tt:4309.561\n",
      "Ep:141, loss:0.00001, loss_test:0.01874, lr:2.94e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.564, tt:4340.117\n",
      "Ep:142, loss:0.00001, loss_test:0.01875, lr:2.91e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.557, tt:4369.638\n",
      "Ep:143, loss:0.00001, loss_test:0.01874, lr:2.88e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.555, tt:4399.876\n",
      "Ep:144, loss:0.00001, loss_test:0.01874, lr:2.85e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.546, tt:4429.130\n",
      "Ep:145, loss:0.00001, loss_test:0.01874, lr:2.82e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.550, tt:4460.267\n",
      "Ep:146, loss:0.00001, loss_test:0.01879, lr:2.80e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.553, tt:4491.271\n",
      "Ep:147, loss:0.00001, loss_test:0.01885, lr:2.77e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.547, tt:4520.988\n",
      "Ep:148, loss:0.00001, loss_test:0.01890, lr:2.74e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.540, tt:4550.453\n",
      "Ep:149, loss:0.00001, loss_test:0.01888, lr:2.71e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.537, tt:4580.521\n",
      "Ep:150, loss:0.00001, loss_test:0.01886, lr:2.69e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.537, tt:4611.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00001, loss_test:0.01890, lr:2.66e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.537, tt:4641.635\n",
      "Ep:152, loss:0.00001, loss_test:0.01889, lr:2.63e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.537, tt:4672.199\n",
      "Ep:153, loss:0.00001, loss_test:0.01891, lr:2.61e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.531, tt:4701.754\n",
      "Ep:154, loss:0.00001, loss_test:0.01894, lr:2.58e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.529, tt:4732.010\n",
      "Ep:155, loss:0.00001, loss_test:0.01898, lr:2.55e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.524, tt:4761.754\n",
      "Ep:156, loss:0.00001, loss_test:0.01899, lr:2.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.519, tt:4791.537\n",
      "Ep:157, loss:0.00001, loss_test:0.01898, lr:2.50e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.517, tt:4821.633\n",
      "Ep:158, loss:0.00001, loss_test:0.01901, lr:2.48e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.511, tt:4851.303\n",
      "Ep:159, loss:0.00001, loss_test:0.01904, lr:2.45e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.506, tt:4880.888\n",
      "Ep:160, loss:0.00001, loss_test:0.01907, lr:2.43e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.503, tt:4910.903\n",
      "Ep:161, loss:0.00001, loss_test:0.01911, lr:2.40e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.516, tt:4943.586\n",
      "Ep:162, loss:0.00001, loss_test:0.01912, lr:2.38e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.517, tt:4974.305\n",
      "Ep:163, loss:0.00001, loss_test:0.01908, lr:2.36e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.521, tt:5005.368\n",
      "Ep:164, loss:0.00001, loss_test:0.01912, lr:2.33e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.529, tt:5037.350\n",
      "Ep:165, loss:0.00001, loss_test:0.01916, lr:2.31e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.533, tt:5068.401\n",
      "Ep:166, loss:0.00001, loss_test:0.01916, lr:2.29e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.528, tt:5098.153\n",
      "Ep:167, loss:0.00001, loss_test:0.01917, lr:2.26e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.521, tt:5127.557\n",
      "Ep:168, loss:0.00001, loss_test:0.01920, lr:2.24e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.512, tt:5156.572\n",
      "Ep:169, loss:0.00001, loss_test:0.01925, lr:2.22e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.511, tt:5186.818\n",
      "Ep:170, loss:0.00001, loss_test:0.01924, lr:2.20e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.511, tt:5217.438\n",
      "Ep:171, loss:0.00001, loss_test:0.01921, lr:2.17e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.512, tt:5247.980\n",
      "Ep:172, loss:0.00001, loss_test:0.01924, lr:2.15e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.507, tt:5277.791\n",
      "Ep:173, loss:0.00001, loss_test:0.01929, lr:2.13e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.507, tt:5308.155\n",
      "Ep:174, loss:0.00001, loss_test:0.01934, lr:2.11e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.503, tt:5337.966\n",
      "Ep:175, loss:0.00001, loss_test:0.01934, lr:2.09e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.504, tt:5368.677\n",
      "Ep:176, loss:0.00001, loss_test:0.01933, lr:2.07e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.502, tt:5398.940\n",
      "Ep:177, loss:0.00001, loss_test:0.01933, lr:2.05e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.499, tt:5428.795\n",
      "Ep:178, loss:0.00001, loss_test:0.01935, lr:2.03e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.502, tt:5459.921\n",
      "Ep:179, loss:0.00001, loss_test:0.01935, lr:2.01e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.503, tt:5490.523\n",
      "Ep:180, loss:0.00001, loss_test:0.01937, lr:1.99e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.501, tt:5520.754\n",
      "Ep:181, loss:0.00001, loss_test:0.01941, lr:1.97e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.499, tt:5550.813\n",
      "Ep:182, loss:0.00001, loss_test:0.01943, lr:1.95e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.503, tt:5581.973\n",
      "Ep:183, loss:0.00001, loss_test:0.01943, lr:1.93e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.506, tt:5613.099\n",
      "Ep:184, loss:0.00001, loss_test:0.01943, lr:1.91e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.509, tt:5644.123\n",
      "Ep:185, loss:0.00001, loss_test:0.01946, lr:1.89e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.516, tt:5676.067\n",
      "Ep:186, loss:0.00001, loss_test:0.01946, lr:1.87e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.514, tt:5706.166\n",
      "Ep:187, loss:0.00001, loss_test:0.01948, lr:1.85e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.517, tt:5737.220\n",
      "Ep:188, loss:0.00001, loss_test:0.01948, lr:1.83e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.511, tt:5766.554\n",
      "Ep:189, loss:0.00001, loss_test:0.01952, lr:1.81e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.507, tt:5796.251\n",
      "Ep:190, loss:0.00001, loss_test:0.01953, lr:1.80e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.506, tt:5826.703\n",
      "Ep:191, loss:0.00001, loss_test:0.01954, lr:1.78e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.505, tt:5856.985\n",
      "Ep:192, loss:0.00001, loss_test:0.01955, lr:1.76e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.502, tt:5886.960\n",
      "Ep:193, loss:0.00001, loss_test:0.01956, lr:1.74e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.505, tt:5918.015\n",
      "Ep:194, loss:0.00001, loss_test:0.01957, lr:1.73e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.450, tt:5937.844\n",
      "Ep:195, loss:0.00001, loss_test:0.01958, lr:1.71e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.396, tt:5957.571\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01999, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:37.783, tt:37.783\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02370, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.136, tt:74.272\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02480, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.864, tt:113.593\n",
      "Ep:3, loss:0.00005, loss_test:0.02436, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.892, tt:151.569\n",
      "Ep:4, loss:0.00005, loss_test:0.02297, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.049, tt:190.243\n",
      "Ep:5, loss:0.00004, loss_test:0.02103, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:38.134, tt:228.802\n",
      "Ep:6, loss:0.00004, loss_test:0.01947, lr:6.00e-02, fs:0.68345 (r=0.960,p=0.531),  time:37.864, tt:265.050\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01884, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:37.533, tt:300.262\n",
      "Ep:8, loss:0.00004, loss_test:0.01891, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:37.483, tt:337.347\n",
      "Ep:9, loss:0.00004, loss_test:0.01873, lr:6.00e-02, fs:0.67521 (r=0.798,p=0.585),  time:37.600, tt:376.002\n",
      "Ep:10, loss:0.00004, loss_test:0.01836, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:37.674, tt:414.416\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01804, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:37.803, tt:453.631\n",
      "Ep:12, loss:0.00003, loss_test:0.01775, lr:6.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:37.870, tt:492.306\n",
      "Ep:13, loss:0.00003, loss_test:0.01742, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:37.791, tt:529.074\n",
      "Ep:14, loss:0.00003, loss_test:0.01715, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:37.819, tt:567.292\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:37.872, tt:605.948\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01677, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:37.918, tt:644.603\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:37.902, tt:682.227\n",
      "Ep:18, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:37.879, tt:719.698\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:37.898, tt:757.970\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:37.923, tt:796.393\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:37.894, tt:833.666\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:37.826, tt:869.991\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:37.848, tt:908.349\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:37.957, tt:948.933\n",
      "Ep:25, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:37.928, tt:986.140\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:37.892, tt:1023.079\n",
      "Ep:27, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:37.888, tt:1060.866\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:37.866, tt:1098.119\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:37.940, tt:1138.198\n",
      "Ep:30, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:37.898, tt:1174.852\n",
      "Ep:31, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:37.909, tt:1213.091\n",
      "Ep:32, loss:0.00002, loss_test:0.01501, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:37.875, tt:1249.866\n",
      "Ep:33, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:37.859, tt:1287.205\n",
      "Ep:34, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:37.796, tt:1322.850\n",
      "Ep:35, loss:0.00002, loss_test:0.01488, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:37.780, tt:1360.078\n",
      "Ep:36, loss:0.00002, loss_test:0.01489, lr:6.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:37.801, tt:1398.641\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:37.787, tt:1435.922\n",
      "Ep:38, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:37.787, tt:1473.685\n",
      "Ep:39, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:37.752, tt:1510.081\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:37.693, tt:1545.393\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:37.729, tt:1584.634\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.826, tt:1626.500\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01485, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.847, tt:1665.261\n",
      "Ep:44, loss:0.00001, loss_test:0.01486, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.888, tt:1704.960\n",
      "Ep:45, loss:0.00001, loss_test:0.01484, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:37.913, tt:1744.003\n",
      "Ep:46, loss:0.00001, loss_test:0.01488, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:37.939, tt:1783.125\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01496, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.928, tt:1820.555\n",
      "Ep:48, loss:0.00001, loss_test:0.01492, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:37.904, tt:1857.306\n",
      "Ep:49, loss:0.00001, loss_test:0.01510, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.903, tt:1895.149\n",
      "Ep:50, loss:0.00001, loss_test:0.01513, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.869, tt:1931.296\n",
      "Ep:51, loss:0.00001, loss_test:0.01516, lr:6.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:37.887, tt:1970.128\n",
      "Ep:52, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:37.882, tt:2007.755\n",
      "Ep:53, loss:0.00001, loss_test:0.01516, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:37.915, tt:2047.395\n",
      "Ep:54, loss:0.00001, loss_test:0.01528, lr:6.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:37.922, tt:2085.686\n",
      "Ep:55, loss:0.00001, loss_test:0.01536, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:37.917, tt:2123.378\n",
      "Ep:56, loss:0.00001, loss_test:0.01547, lr:6.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:37.920, tt:2161.446\n",
      "Ep:57, loss:0.00001, loss_test:0.01548, lr:6.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:37.923, tt:2199.522\n",
      "Ep:58, loss:0.00001, loss_test:0.01550, lr:5.94e-02, fs:0.83158 (r=0.798,p=0.868),  time:37.936, tt:2238.217\n",
      "Ep:59, loss:0.00001, loss_test:0.01555, lr:5.88e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.953, tt:2277.157\n",
      "Ep:60, loss:0.00001, loss_test:0.01565, lr:5.82e-02, fs:0.81481 (r=0.778,p=0.856),  time:37.957, tt:2315.385\n",
      "Ep:61, loss:0.00001, loss_test:0.01573, lr:5.76e-02, fs:0.81283 (r=0.768,p=0.864),  time:37.975, tt:2354.472\n",
      "Ep:62, loss:0.00001, loss_test:0.01572, lr:5.71e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.949, tt:2390.764\n",
      "Ep:63, loss:0.00001, loss_test:0.01593, lr:5.65e-02, fs:0.80645 (r=0.758,p=0.862),  time:37.976, tt:2430.472\n",
      "Ep:64, loss:0.00001, loss_test:0.01605, lr:5.59e-02, fs:0.79348 (r=0.737,p=0.859),  time:37.973, tt:2468.243\n",
      "Ep:65, loss:0.00001, loss_test:0.01610, lr:5.54e-02, fs:0.78022 (r=0.717,p=0.855),  time:37.959, tt:2505.317\n",
      "Ep:66, loss:0.00001, loss_test:0.01613, lr:5.48e-02, fs:0.78689 (r=0.727,p=0.857),  time:37.974, tt:2544.224\n",
      "Ep:67, loss:0.00001, loss_test:0.01622, lr:5.43e-02, fs:0.78022 (r=0.717,p=0.855),  time:37.978, tt:2582.482\n",
      "Ep:68, loss:0.00001, loss_test:0.01624, lr:5.37e-02, fs:0.78022 (r=0.717,p=0.855),  time:37.974, tt:2620.213\n",
      "Ep:69, loss:0.00001, loss_test:0.01635, lr:5.32e-02, fs:0.78022 (r=0.717,p=0.855),  time:37.987, tt:2659.081\n",
      "Ep:70, loss:0.00001, loss_test:0.01643, lr:5.27e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.009, tt:2698.612\n",
      "Ep:71, loss:0.00001, loss_test:0.01661, lr:5.21e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.006, tt:2736.429\n",
      "Ep:72, loss:0.00001, loss_test:0.01657, lr:5.16e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.073, tt:2779.352\n",
      "Ep:73, loss:0.00001, loss_test:0.01656, lr:5.11e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.080, tt:2817.905\n",
      "Ep:74, loss:0.00001, loss_test:0.01673, lr:5.06e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.084, tt:2856.264\n",
      "Ep:75, loss:0.00001, loss_test:0.01678, lr:5.01e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.106, tt:2896.026\n",
      "Ep:76, loss:0.00001, loss_test:0.01677, lr:4.96e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.114, tt:2934.753\n",
      "Ep:77, loss:0.00001, loss_test:0.01688, lr:4.91e-02, fs:0.78022 (r=0.717,p=0.855),  time:38.114, tt:2972.864\n",
      "Ep:78, loss:0.00001, loss_test:0.01693, lr:4.86e-02, fs:0.78689 (r=0.727,p=0.857),  time:38.114, tt:3011.039\n",
      "Ep:79, loss:0.00001, loss_test:0.01701, lr:4.81e-02, fs:0.79121 (r=0.727,p=0.867),  time:38.091, tt:3047.296\n",
      "Ep:80, loss:0.00001, loss_test:0.01717, lr:4.76e-02, fs:0.79121 (r=0.727,p=0.867),  time:38.099, tt:3086.046\n",
      "Ep:81, loss:0.00001, loss_test:0.01715, lr:4.71e-02, fs:0.79121 (r=0.727,p=0.867),  time:38.108, tt:3124.893\n",
      "Ep:82, loss:0.00001, loss_test:0.01719, lr:4.67e-02, fs:0.78453 (r=0.717,p=0.866),  time:38.118, tt:3163.760\n",
      "Ep:83, loss:0.00001, loss_test:0.01731, lr:4.62e-02, fs:0.78453 (r=0.717,p=0.866),  time:38.135, tt:3203.363\n",
      "Ep:84, loss:0.00001, loss_test:0.01742, lr:4.57e-02, fs:0.77778 (r=0.707,p=0.864),  time:38.149, tt:3242.703\n",
      "Ep:85, loss:0.00001, loss_test:0.01744, lr:4.53e-02, fs:0.77778 (r=0.707,p=0.864),  time:38.157, tt:3281.526\n",
      "Ep:86, loss:0.00001, loss_test:0.01746, lr:4.48e-02, fs:0.77778 (r=0.707,p=0.864),  time:38.165, tt:3320.334\n",
      "Ep:87, loss:0.00001, loss_test:0.01756, lr:4.44e-02, fs:0.77778 (r=0.707,p=0.864),  time:38.166, tt:3358.613\n",
      "Ep:88, loss:0.00001, loss_test:0.01761, lr:4.39e-02, fs:0.77778 (r=0.707,p=0.864),  time:38.180, tt:3398.052\n",
      "Ep:89, loss:0.00001, loss_test:0.01770, lr:4.35e-02, fs:0.77095 (r=0.697,p=0.863),  time:38.185, tt:3436.636\n",
      "Ep:90, loss:0.00001, loss_test:0.01764, lr:4.31e-02, fs:0.77778 (r=0.707,p=0.864),  time:38.169, tt:3473.371\n",
      "Ep:91, loss:0.00001, loss_test:0.01773, lr:4.26e-02, fs:0.75706 (r=0.677,p=0.859),  time:38.179, tt:3512.430\n",
      "Ep:92, loss:0.00001, loss_test:0.01785, lr:4.22e-02, fs:0.75706 (r=0.677,p=0.859),  time:38.176, tt:3550.414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00001, loss_test:0.01795, lr:4.18e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.198, tt:3590.601\n",
      "Ep:94, loss:0.00001, loss_test:0.01791, lr:4.14e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.210, tt:3629.941\n",
      "Ep:95, loss:0.00001, loss_test:0.01792, lr:4.10e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.196, tt:3666.780\n",
      "Ep:96, loss:0.00001, loss_test:0.01811, lr:4.05e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.185, tt:3703.918\n",
      "Ep:97, loss:0.00001, loss_test:0.01812, lr:4.01e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.189, tt:3742.526\n",
      "Ep:98, loss:0.00001, loss_test:0.01813, lr:3.97e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.204, tt:3782.193\n",
      "Ep:99, loss:0.00001, loss_test:0.01817, lr:3.93e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.221, tt:3822.125\n",
      "Ep:100, loss:0.00001, loss_test:0.01827, lr:3.89e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.218, tt:3859.995\n",
      "Ep:101, loss:0.00001, loss_test:0.01827, lr:3.86e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.206, tt:3896.969\n",
      "Ep:102, loss:0.00001, loss_test:0.01830, lr:3.82e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.209, tt:3935.529\n",
      "Ep:103, loss:0.00001, loss_test:0.01840, lr:3.78e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.220, tt:3974.896\n",
      "Ep:104, loss:0.00001, loss_test:0.01839, lr:3.74e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.222, tt:4013.340\n",
      "Ep:105, loss:0.00001, loss_test:0.01846, lr:3.70e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.220, tt:4051.335\n",
      "Ep:106, loss:0.00001, loss_test:0.01853, lr:3.67e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.234, tt:4091.079\n",
      "Ep:107, loss:0.00001, loss_test:0.01855, lr:3.63e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.225, tt:4128.334\n",
      "Ep:108, loss:0.00000, loss_test:0.01859, lr:3.59e-02, fs:0.76136 (r=0.677,p=0.870),  time:38.219, tt:4165.897\n",
      "Ep:109, loss:0.00000, loss_test:0.01866, lr:3.56e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.221, tt:4204.304\n",
      "Ep:110, loss:0.00000, loss_test:0.01873, lr:3.52e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.215, tt:4241.852\n",
      "Ep:111, loss:0.00000, loss_test:0.01874, lr:3.49e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.216, tt:4280.165\n",
      "Ep:112, loss:0.00000, loss_test:0.01875, lr:3.45e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.202, tt:4316.832\n",
      "Ep:113, loss:0.00000, loss_test:0.01878, lr:3.42e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.189, tt:4353.498\n",
      "Ep:114, loss:0.00000, loss_test:0.01881, lr:3.38e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.185, tt:4391.229\n",
      "Ep:115, loss:0.00000, loss_test:0.01885, lr:3.35e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.191, tt:4430.139\n",
      "Ep:116, loss:0.00000, loss_test:0.01887, lr:3.32e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.189, tt:4468.117\n",
      "Ep:117, loss:0.00000, loss_test:0.01898, lr:3.28e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.194, tt:4506.908\n",
      "Ep:118, loss:0.00000, loss_test:0.01899, lr:3.25e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.199, tt:4545.719\n",
      "Ep:119, loss:0.00000, loss_test:0.01906, lr:3.22e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.201, tt:4584.151\n",
      "Ep:120, loss:0.00000, loss_test:0.01908, lr:3.19e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.204, tt:4622.698\n",
      "Ep:121, loss:0.00000, loss_test:0.01914, lr:3.15e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.208, tt:4661.357\n",
      "Ep:122, loss:0.00000, loss_test:0.01913, lr:3.12e-02, fs:0.76571 (r=0.677,p=0.882),  time:38.213, tt:4700.228\n",
      "Ep:123, loss:0.00000, loss_test:0.01918, lr:3.09e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.215, tt:4738.603\n",
      "Ep:124, loss:0.00000, loss_test:0.01918, lr:3.06e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.240, tt:4780.018\n",
      "Ep:125, loss:0.00000, loss_test:0.01923, lr:3.03e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.241, tt:4818.425\n",
      "Ep:126, loss:0.00000, loss_test:0.01929, lr:3.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.234, tt:4855.668\n",
      "Ep:127, loss:0.00000, loss_test:0.01935, lr:2.97e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.225, tt:4892.844\n",
      "Ep:128, loss:0.00000, loss_test:0.01931, lr:2.94e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.221, tt:4930.494\n",
      "Ep:129, loss:0.00000, loss_test:0.01937, lr:2.91e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.224, tt:4969.160\n",
      "Ep:130, loss:0.00000, loss_test:0.01947, lr:2.88e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.229, tt:5007.948\n",
      "Ep:131, loss:0.00000, loss_test:0.01946, lr:2.85e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.243, tt:5048.122\n",
      "Ep:132, loss:0.00000, loss_test:0.01946, lr:2.82e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.232, tt:5084.890\n",
      "Ep:133, loss:0.00000, loss_test:0.01946, lr:2.80e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.229, tt:5122.646\n",
      "Ep:134, loss:0.00000, loss_test:0.01953, lr:2.77e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.223, tt:5160.113\n",
      "Ep:135, loss:0.00000, loss_test:0.01956, lr:2.74e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.222, tt:5198.173\n",
      "Ep:136, loss:0.00000, loss_test:0.01960, lr:2.71e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.222, tt:5236.412\n",
      "Ep:137, loss:0.00000, loss_test:0.01962, lr:2.69e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.214, tt:5273.530\n",
      "Ep:138, loss:0.00000, loss_test:0.01966, lr:2.66e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.211, tt:5311.317\n",
      "Ep:139, loss:0.00000, loss_test:0.01967, lr:2.63e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.220, tt:5350.748\n",
      "Ep:140, loss:0.00000, loss_test:0.01968, lr:2.61e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.223, tt:5389.447\n",
      "Ep:141, loss:0.00000, loss_test:0.01974, lr:2.58e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.227, tt:5428.287\n",
      "Ep:142, loss:0.00000, loss_test:0.01978, lr:2.55e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.235, tt:5467.631\n",
      "Ep:143, loss:0.00000, loss_test:0.01977, lr:2.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.236, tt:5505.974\n",
      "Ep:144, loss:0.00000, loss_test:0.01983, lr:2.50e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.241, tt:5544.917\n",
      "Ep:145, loss:0.00000, loss_test:0.01991, lr:2.48e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.240, tt:5583.096\n",
      "Ep:146, loss:0.00000, loss_test:0.01989, lr:2.45e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.263, tt:5624.593\n",
      "Ep:147, loss:0.00000, loss_test:0.01988, lr:2.43e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.264, tt:5663.091\n",
      "Ep:148, loss:0.00000, loss_test:0.01991, lr:2.40e-02, fs:0.77011 (r=0.677,p=0.893),  time:38.266, tt:5701.661\n",
      "Ep:149, loss:0.00000, loss_test:0.01997, lr:2.38e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.255, tt:5738.196\n",
      "Ep:150, loss:0.00000, loss_test:0.01997, lr:2.36e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.249, tt:5775.627\n",
      "Ep:151, loss:0.00000, loss_test:0.02002, lr:2.33e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.243, tt:5812.999\n",
      "Ep:152, loss:0.00000, loss_test:0.02004, lr:2.31e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.247, tt:5851.742\n",
      "Ep:153, loss:0.00000, loss_test:0.02008, lr:2.29e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.252, tt:5890.733\n",
      "Ep:154, loss:0.00000, loss_test:0.02010, lr:2.26e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.249, tt:5928.584\n",
      "Ep:155, loss:0.00000, loss_test:0.02010, lr:2.24e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.252, tt:5967.352\n",
      "Ep:156, loss:0.00000, loss_test:0.02015, lr:2.22e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.253, tt:6005.758\n",
      "Ep:157, loss:0.00000, loss_test:0.02021, lr:2.20e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.257, tt:6044.573\n",
      "Ep:158, loss:0.00000, loss_test:0.02022, lr:2.17e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.252, tt:6082.057\n",
      "Ep:159, loss:0.00000, loss_test:0.02019, lr:2.15e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.261, tt:6121.704\n",
      "Ep:160, loss:0.00000, loss_test:0.02021, lr:2.13e-02, fs:0.76301 (r=0.667,p=0.892),  time:38.256, tt:6159.171\n",
      "Ep:161, loss:0.00000, loss_test:0.02026, lr:2.11e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.254, tt:6197.210\n",
      "Ep:162, loss:0.00000, loss_test:0.02031, lr:2.09e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.250, tt:6234.793\n",
      "Ep:163, loss:0.00000, loss_test:0.02031, lr:2.07e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.256, tt:6273.912\n",
      "Ep:164, loss:0.00000, loss_test:0.02032, lr:2.05e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.249, tt:6311.060\n",
      "Ep:165, loss:0.00000, loss_test:0.02034, lr:2.03e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.247, tt:6348.988\n",
      "Ep:166, loss:0.00000, loss_test:0.02037, lr:2.01e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.249, tt:6387.522\n",
      "Ep:167, loss:0.00000, loss_test:0.02040, lr:1.99e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.240, tt:6424.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00000, loss_test:0.02043, lr:1.97e-02, fs:0.76023 (r=0.657,p=0.903),  time:38.250, tt:6464.275\n",
      "Ep:169, loss:0.00000, loss_test:0.02043, lr:1.95e-02, fs:0.76023 (r=0.657,p=0.903),  time:38.248, tt:6502.121\n",
      "Ep:170, loss:0.00000, loss_test:0.02043, lr:1.93e-02, fs:0.76023 (r=0.657,p=0.903),  time:38.256, tt:6541.692\n",
      "Ep:171, loss:0.00000, loss_test:0.02049, lr:1.91e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.254, tt:6579.751\n",
      "Ep:172, loss:0.00000, loss_test:0.02050, lr:1.89e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.257, tt:6618.491\n",
      "Ep:173, loss:0.00000, loss_test:0.02051, lr:1.87e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.264, tt:6657.883\n",
      "Ep:174, loss:0.00000, loss_test:0.02051, lr:1.85e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.260, tt:6695.534\n",
      "Ep:175, loss:0.00000, loss_test:0.02056, lr:1.83e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.258, tt:6733.444\n",
      "Ep:176, loss:0.00000, loss_test:0.02058, lr:1.81e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.260, tt:6771.931\n",
      "Ep:177, loss:0.00000, loss_test:0.02061, lr:1.80e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.262, tt:6810.602\n",
      "Ep:178, loss:0.00000, loss_test:0.02063, lr:1.78e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.259, tt:6848.325\n",
      "Ep:179, loss:0.00000, loss_test:0.02065, lr:1.76e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.256, tt:6886.013\n",
      "Ep:180, loss:0.00000, loss_test:0.02065, lr:1.74e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.267, tt:6926.388\n",
      "Ep:181, loss:0.00000, loss_test:0.02067, lr:1.73e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.277, tt:6966.371\n",
      "Ep:182, loss:0.00000, loss_test:0.02071, lr:1.71e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.285, tt:7006.090\n",
      "Ep:183, loss:0.00000, loss_test:0.02071, lr:1.69e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.284, tt:7044.285\n",
      "Ep:184, loss:0.00000, loss_test:0.02073, lr:1.67e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.290, tt:7083.588\n",
      "Ep:185, loss:0.00000, loss_test:0.02074, lr:1.66e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.292, tt:7122.323\n",
      "Ep:186, loss:0.00000, loss_test:0.02074, lr:1.64e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.295, tt:7161.191\n",
      "Ep:187, loss:0.00000, loss_test:0.02080, lr:1.62e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.303, tt:7200.931\n",
      "Ep:188, loss:0.00000, loss_test:0.02082, lr:1.61e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.308, tt:7240.159\n",
      "Ep:189, loss:0.00000, loss_test:0.02084, lr:1.59e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.312, tt:7279.242\n",
      "Ep:190, loss:0.00000, loss_test:0.02083, lr:1.58e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.314, tt:7318.022\n",
      "Ep:191, loss:0.00000, loss_test:0.02086, lr:1.56e-02, fs:0.73494 (r=0.616,p=0.910),  time:38.313, tt:7356.034\n",
      "Ep:192, loss:0.00000, loss_test:0.02086, lr:1.54e-02, fs:0.73494 (r=0.616,p=0.910),  time:38.312, tt:7394.129\n",
      "Ep:193, loss:0.00000, loss_test:0.02089, lr:1.53e-02, fs:0.72727 (r=0.606,p=0.909),  time:38.293, tt:7428.852\n",
      "Ep:194, loss:0.00000, loss_test:0.02090, lr:1.51e-02, fs:0.71951 (r=0.596,p=0.908),  time:38.287, tt:7465.995\n",
      "Ep:195, loss:0.00000, loss_test:0.02092, lr:1.50e-02, fs:0.71951 (r=0.596,p=0.908),  time:38.206, tt:7488.311\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02141, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:33.848, tt:33.848\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02614, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.351, tt:64.701\n",
      "Ep:2, loss:0.00005, loss_test:0.02861, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.474, tt:100.421\n",
      "Ep:3, loss:0.00006, loss_test:0.02913, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.475, tt:133.901\n",
      "Ep:4, loss:0.00006, loss_test:0.02871, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.877, tt:169.387\n",
      "Ep:5, loss:0.00006, loss_test:0.02753, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.078, tt:204.470\n",
      "Ep:6, loss:0.00005, loss_test:0.02592, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:34.394, tt:240.757\n",
      "Ep:7, loss:0.00005, loss_test:0.02425, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:34.368, tt:274.947\n",
      "Ep:8, loss:0.00005, loss_test:0.02285, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:34.397, tt:309.570\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00005, loss_test:0.02193, lr:6.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:34.450, tt:344.499\n",
      "Ep:10, loss:0.00005, loss_test:0.02143, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:34.445, tt:378.890\n",
      "Ep:11, loss:0.00004, loss_test:0.02106, lr:6.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:34.526, tt:414.315\n",
      "Ep:12, loss:0.00004, loss_test:0.02069, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:34.540, tt:449.018\n",
      "Ep:13, loss:0.00004, loss_test:0.02028, lr:6.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:34.428, tt:481.992\n",
      "Ep:14, loss:0.00004, loss_test:0.02004, lr:6.00e-02, fs:0.63529 (r=0.818,p=0.519),  time:34.404, tt:516.054\n",
      "Ep:15, loss:0.00004, loss_test:0.02003, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:34.376, tt:550.014\n",
      "Ep:16, loss:0.00004, loss_test:0.02004, lr:6.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:34.314, tt:583.342\n",
      "Ep:17, loss:0.00004, loss_test:0.01996, lr:6.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:34.408, tt:619.337\n",
      "Ep:18, loss:0.00004, loss_test:0.01980, lr:6.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:34.439, tt:654.345\n",
      "Ep:19, loss:0.00003, loss_test:0.01957, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:34.463, tt:689.269\n",
      "Ep:20, loss:0.00003, loss_test:0.01929, lr:5.94e-02, fs:0.66390 (r=0.808,p=0.563),  time:34.428, tt:722.980\n",
      "Ep:21, loss:0.00003, loss_test:0.01898, lr:5.88e-02, fs:0.66667 (r=0.808,p=0.567),  time:34.425, tt:757.344\n",
      "Ep:22, loss:0.00003, loss_test:0.01868, lr:5.82e-02, fs:0.66667 (r=0.808,p=0.567),  time:34.437, tt:792.046\n",
      "Ep:23, loss:0.00003, loss_test:0.01839, lr:5.76e-02, fs:0.68936 (r=0.818,p=0.596),  time:34.418, tt:826.021\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01814, lr:5.76e-02, fs:0.68696 (r=0.798,p=0.603),  time:34.359, tt:858.987\n",
      "Ep:25, loss:0.00003, loss_test:0.01792, lr:5.76e-02, fs:0.67841 (r=0.778,p=0.602),  time:34.366, tt:893.524\n",
      "Ep:26, loss:0.00003, loss_test:0.01777, lr:5.76e-02, fs:0.67556 (r=0.768,p=0.603),  time:34.345, tt:927.304\n",
      "Ep:27, loss:0.00003, loss_test:0.01764, lr:5.76e-02, fs:0.66667 (r=0.758,p=0.595),  time:34.376, tt:962.536\n",
      "Ep:28, loss:0.00003, loss_test:0.01757, lr:5.76e-02, fs:0.68750 (r=0.778,p=0.616),  time:34.386, tt:997.191\n",
      "Ep:29, loss:0.00003, loss_test:0.01756, lr:5.76e-02, fs:0.68161 (r=0.768,p=0.613),  time:34.348, tt:1030.444\n",
      "Ep:30, loss:0.00003, loss_test:0.01741, lr:5.76e-02, fs:0.68468 (r=0.768,p=0.618),  time:34.320, tt:1063.931\n",
      "Ep:31, loss:0.00003, loss_test:0.01726, lr:5.76e-02, fs:0.68807 (r=0.758,p=0.630),  time:34.294, tt:1097.402\n",
      "Ep:32, loss:0.00003, loss_test:0.01717, lr:5.76e-02, fs:0.70968 (r=0.778,p=0.653),  time:34.289, tt:1131.536\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01695, lr:5.76e-02, fs:0.71233 (r=0.788,p=0.650),  time:34.273, tt:1165.270\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01681, lr:5.76e-02, fs:0.72558 (r=0.788,p=0.672),  time:34.251, tt:1198.777\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01669, lr:5.76e-02, fs:0.73585 (r=0.788,p=0.690),  time:34.236, tt:1232.497\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01669, lr:5.76e-02, fs:0.71498 (r=0.747,p=0.685),  time:34.231, tt:1266.561\n",
      "Ep:37, loss:0.00002, loss_test:0.01666, lr:5.76e-02, fs:0.71498 (r=0.747,p=0.685),  time:34.205, tt:1299.784\n",
      "Ep:38, loss:0.00002, loss_test:0.01658, lr:5.76e-02, fs:0.71845 (r=0.747,p=0.692),  time:34.206, tt:1334.039\n",
      "Ep:39, loss:0.00002, loss_test:0.01659, lr:5.76e-02, fs:0.71845 (r=0.747,p=0.692),  time:34.228, tt:1369.134\n",
      "Ep:40, loss:0.00002, loss_test:0.01650, lr:5.76e-02, fs:0.72195 (r=0.747,p=0.698),  time:34.230, tt:1403.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00002, loss_test:0.01642, lr:5.76e-02, fs:0.72464 (r=0.758,p=0.694),  time:34.197, tt:1436.289\n",
      "Ep:42, loss:0.00002, loss_test:0.01642, lr:5.76e-02, fs:0.72816 (r=0.758,p=0.701),  time:34.174, tt:1469.463\n",
      "Ep:43, loss:0.00002, loss_test:0.01656, lr:5.76e-02, fs:0.72549 (r=0.747,p=0.705),  time:34.155, tt:1502.806\n",
      "Ep:44, loss:0.00002, loss_test:0.01652, lr:5.76e-02, fs:0.73267 (r=0.747,p=0.718),  time:34.141, tt:1536.354\n",
      "Ep:45, loss:0.00002, loss_test:0.01639, lr:5.76e-02, fs:0.73267 (r=0.747,p=0.718),  time:34.118, tt:1569.449\n",
      "Ep:46, loss:0.00002, loss_test:0.01634, lr:5.76e-02, fs:0.73892 (r=0.758,p=0.721),  time:34.118, tt:1603.560\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01655, lr:5.76e-02, fs:0.73267 (r=0.747,p=0.718),  time:34.135, tt:1638.467\n",
      "Ep:48, loss:0.00002, loss_test:0.01654, lr:5.76e-02, fs:0.73267 (r=0.747,p=0.718),  time:34.191, tt:1675.342\n",
      "Ep:49, loss:0.00002, loss_test:0.01650, lr:5.76e-02, fs:0.73632 (r=0.747,p=0.725),  time:34.143, tt:1707.161\n",
      "Ep:50, loss:0.00002, loss_test:0.01656, lr:5.76e-02, fs:0.73632 (r=0.747,p=0.725),  time:34.140, tt:1741.148\n",
      "Ep:51, loss:0.00002, loss_test:0.01674, lr:5.76e-02, fs:0.73632 (r=0.747,p=0.725),  time:34.166, tt:1776.628\n",
      "Ep:52, loss:0.00002, loss_test:0.01672, lr:5.76e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.135, tt:1809.159\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01665, lr:5.76e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.129, tt:1842.953\n",
      "Ep:54, loss:0.00001, loss_test:0.01666, lr:5.76e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.109, tt:1876.006\n",
      "Ep:55, loss:0.00001, loss_test:0.01688, lr:5.76e-02, fs:0.73096 (r=0.727,p=0.735),  time:34.077, tt:1908.327\n",
      "Ep:56, loss:0.00001, loss_test:0.01687, lr:5.76e-02, fs:0.73737 (r=0.737,p=0.737),  time:34.050, tt:1940.830\n",
      "Ep:57, loss:0.00001, loss_test:0.01691, lr:5.76e-02, fs:0.73096 (r=0.727,p=0.735),  time:34.027, tt:1973.579\n",
      "Ep:58, loss:0.00001, loss_test:0.01698, lr:5.76e-02, fs:0.72727 (r=0.727,p=0.727),  time:34.025, tt:2007.502\n",
      "Ep:59, loss:0.00001, loss_test:0.01700, lr:5.76e-02, fs:0.72449 (r=0.717,p=0.732),  time:34.008, tt:2040.477\n",
      "Ep:60, loss:0.00001, loss_test:0.01698, lr:5.76e-02, fs:0.73096 (r=0.727,p=0.735),  time:33.993, tt:2073.589\n",
      "Ep:61, loss:0.00001, loss_test:0.01698, lr:5.76e-02, fs:0.73846 (r=0.727,p=0.750),  time:34.011, tt:2108.684\n",
      "Ep:62, loss:0.00001, loss_test:0.01717, lr:5.76e-02, fs:0.73846 (r=0.727,p=0.750),  time:34.020, tt:2143.262\n",
      "Ep:63, loss:0.00001, loss_test:0.01743, lr:5.76e-02, fs:0.73298 (r=0.707,p=0.761),  time:34.016, tt:2177.018\n",
      "Ep:64, loss:0.00001, loss_test:0.01710, lr:5.71e-02, fs:0.73846 (r=0.727,p=0.750),  time:33.996, tt:2209.737\n",
      "Ep:65, loss:0.00001, loss_test:0.01765, lr:5.65e-02, fs:0.71958 (r=0.687,p=0.756),  time:33.996, tt:2243.728\n",
      "Ep:66, loss:0.00001, loss_test:0.01749, lr:5.59e-02, fs:0.74227 (r=0.727,p=0.758),  time:33.994, tt:2277.567\n",
      "Ep:67, loss:0.00001, loss_test:0.01760, lr:5.54e-02, fs:0.73575 (r=0.717,p=0.755),  time:33.977, tt:2310.470\n",
      "Ep:68, loss:0.00001, loss_test:0.01775, lr:5.48e-02, fs:0.72251 (r=0.697,p=0.750),  time:33.962, tt:2343.381\n",
      "Ep:69, loss:0.00001, loss_test:0.01748, lr:5.43e-02, fs:0.73575 (r=0.717,p=0.755),  time:33.926, tt:2374.831\n",
      "Ep:70, loss:0.00001, loss_test:0.01814, lr:5.37e-02, fs:0.72340 (r=0.687,p=0.764),  time:33.942, tt:2409.911\n",
      "Ep:71, loss:0.00001, loss_test:0.01751, lr:5.32e-02, fs:0.72632 (r=0.697,p=0.758),  time:33.939, tt:2443.610\n",
      "Ep:72, loss:0.00001, loss_test:0.01815, lr:5.27e-02, fs:0.72727 (r=0.687,p=0.773),  time:33.952, tt:2478.485\n",
      "Ep:73, loss:0.00001, loss_test:0.01806, lr:5.21e-02, fs:0.73404 (r=0.697,p=0.775),  time:33.956, tt:2512.721\n",
      "Ep:74, loss:0.00001, loss_test:0.01785, lr:5.16e-02, fs:0.72632 (r=0.697,p=0.758),  time:33.956, tt:2546.676\n",
      "Ep:75, loss:0.00001, loss_test:0.01837, lr:5.11e-02, fs:0.73514 (r=0.687,p=0.791),  time:33.959, tt:2580.856\n",
      "Ep:76, loss:0.00001, loss_test:0.01786, lr:5.06e-02, fs:0.73684 (r=0.707,p=0.769),  time:33.968, tt:2615.575\n",
      "Ep:77, loss:0.00001, loss_test:0.01882, lr:5.01e-02, fs:0.73626 (r=0.677,p=0.807),  time:33.946, tt:2647.818\n",
      "Ep:78, loss:0.00001, loss_test:0.01796, lr:4.96e-02, fs:0.74468 (r=0.707,p=0.787),  time:33.957, tt:2682.633\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01901, lr:4.96e-02, fs:0.74317 (r=0.687,p=0.810),  time:33.947, tt:2715.737\n",
      "Ep:80, loss:0.00001, loss_test:0.01842, lr:4.96e-02, fs:0.75000 (r=0.697,p=0.812),  time:33.925, tt:2747.933\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01882, lr:4.96e-02, fs:0.74317 (r=0.687,p=0.810),  time:33.910, tt:2780.599\n",
      "Ep:82, loss:0.00001, loss_test:0.01865, lr:4.96e-02, fs:0.74317 (r=0.687,p=0.810),  time:33.920, tt:2815.326\n",
      "Ep:83, loss:0.00001, loss_test:0.01866, lr:4.96e-02, fs:0.75410 (r=0.697,p=0.821),  time:33.895, tt:2847.169\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01927, lr:4.96e-02, fs:0.73626 (r=0.677,p=0.807),  time:33.893, tt:2880.896\n",
      "Ep:85, loss:0.00001, loss_test:0.01877, lr:4.96e-02, fs:0.73626 (r=0.677,p=0.807),  time:33.893, tt:2914.811\n",
      "Ep:86, loss:0.00001, loss_test:0.01886, lr:4.96e-02, fs:0.72928 (r=0.667,p=0.805),  time:33.905, tt:2949.776\n",
      "Ep:87, loss:0.00001, loss_test:0.01914, lr:4.96e-02, fs:0.74033 (r=0.677,p=0.817),  time:33.914, tt:2984.445\n",
      "Ep:88, loss:0.00001, loss_test:0.01917, lr:4.96e-02, fs:0.73333 (r=0.667,p=0.815),  time:33.906, tt:3017.637\n",
      "Ep:89, loss:0.00001, loss_test:0.01906, lr:4.96e-02, fs:0.73333 (r=0.667,p=0.815),  time:33.918, tt:3052.581\n",
      "Ep:90, loss:0.00001, loss_test:0.01947, lr:4.96e-02, fs:0.73333 (r=0.667,p=0.815),  time:33.942, tt:3088.680\n",
      "Ep:91, loss:0.00001, loss_test:0.01935, lr:4.96e-02, fs:0.72928 (r=0.667,p=0.805),  time:33.943, tt:3122.752\n",
      "Ep:92, loss:0.00001, loss_test:0.01964, lr:4.96e-02, fs:0.73333 (r=0.667,p=0.815),  time:33.935, tt:3155.996\n",
      "Ep:93, loss:0.00001, loss_test:0.01985, lr:4.96e-02, fs:0.72316 (r=0.646,p=0.821),  time:33.952, tt:3191.527\n",
      "Ep:94, loss:0.00001, loss_test:0.01995, lr:4.96e-02, fs:0.72626 (r=0.657,p=0.812),  time:33.971, tt:3227.198\n",
      "Ep:95, loss:0.00001, loss_test:0.01965, lr:4.91e-02, fs:0.71508 (r=0.646,p=0.800),  time:33.996, tt:3263.576\n",
      "Ep:96, loss:0.00001, loss_test:0.02010, lr:4.86e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.012, tt:3299.119\n",
      "Ep:97, loss:0.00001, loss_test:0.01992, lr:4.81e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.023, tt:3334.234\n",
      "Ep:98, loss:0.00001, loss_test:0.02019, lr:4.76e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.036, tt:3369.533\n",
      "Ep:99, loss:0.00001, loss_test:0.01994, lr:4.71e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.074, tt:3407.388\n",
      "Ep:100, loss:0.00001, loss_test:0.02045, lr:4.67e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.090, tt:3443.052\n",
      "Ep:101, loss:0.00001, loss_test:0.02040, lr:4.62e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.111, tt:3479.336\n",
      "Ep:102, loss:0.00001, loss_test:0.02001, lr:4.57e-02, fs:0.72316 (r=0.646,p=0.821),  time:34.130, tt:3515.364\n",
      "Ep:103, loss:0.00001, loss_test:0.02086, lr:4.53e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.135, tt:3549.991\n",
      "Ep:104, loss:0.00001, loss_test:0.02003, lr:4.48e-02, fs:0.71508 (r=0.646,p=0.800),  time:34.160, tt:3586.824\n",
      "Ep:105, loss:0.00001, loss_test:0.02091, lr:4.44e-02, fs:0.71264 (r=0.626,p=0.827),  time:34.176, tt:3622.635\n",
      "Ep:106, loss:0.00001, loss_test:0.02045, lr:4.39e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.178, tt:3657.039\n",
      "Ep:107, loss:0.00001, loss_test:0.02082, lr:4.35e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.196, tt:3693.133\n",
      "Ep:108, loss:0.00001, loss_test:0.02120, lr:4.31e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.204, tt:3728.206\n",
      "Ep:109, loss:0.00001, loss_test:0.02049, lr:4.26e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.206, tt:3762.701\n",
      "Ep:110, loss:0.00001, loss_test:0.02132, lr:4.22e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.207, tt:3797.014\n",
      "Ep:111, loss:0.00001, loss_test:0.02072, lr:4.18e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.220, tt:3832.681\n",
      "Ep:112, loss:0.00001, loss_test:0.02174, lr:4.14e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.219, tt:3866.706\n",
      "Ep:113, loss:0.00001, loss_test:0.02105, lr:4.10e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.224, tt:3901.488\n",
      "Ep:114, loss:0.00000, loss_test:0.02170, lr:4.05e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.241, tt:3937.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00000, loss_test:0.02135, lr:4.01e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.250, tt:3973.039\n",
      "Ep:116, loss:0.00000, loss_test:0.02146, lr:3.97e-02, fs:0.70115 (r=0.616,p=0.813),  time:34.261, tt:4008.530\n",
      "Ep:117, loss:0.00000, loss_test:0.02217, lr:3.93e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.278, tt:4044.829\n",
      "Ep:118, loss:0.00000, loss_test:0.02133, lr:3.89e-02, fs:0.70520 (r=0.616,p=0.824),  time:34.294, tt:4081.032\n",
      "Ep:119, loss:0.00000, loss_test:0.02204, lr:3.86e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.309, tt:4117.035\n",
      "Ep:120, loss:0.00000, loss_test:0.02177, lr:3.82e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.327, tt:4153.517\n",
      "Ep:121, loss:0.00000, loss_test:0.02206, lr:3.78e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.334, tt:4188.740\n",
      "Ep:122, loss:0.00000, loss_test:0.02186, lr:3.74e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.327, tt:4222.213\n",
      "Ep:123, loss:0.00000, loss_test:0.02242, lr:3.70e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.326, tt:4256.457\n",
      "Ep:124, loss:0.00000, loss_test:0.02219, lr:3.67e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.323, tt:4290.376\n",
      "Ep:125, loss:0.00000, loss_test:0.02254, lr:3.63e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.328, tt:4325.290\n",
      "Ep:126, loss:0.00000, loss_test:0.02242, lr:3.59e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.340, tt:4361.184\n",
      "Ep:127, loss:0.00000, loss_test:0.02267, lr:3.56e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.334, tt:4394.691\n",
      "Ep:128, loss:0.00000, loss_test:0.02266, lr:3.52e-02, fs:0.69767 (r=0.606,p=0.822),  time:34.335, tt:4429.259\n",
      "Ep:129, loss:0.00000, loss_test:0.02268, lr:3.49e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.325, tt:4462.236\n",
      "Ep:130, loss:0.00000, loss_test:0.02302, lr:3.45e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.327, tt:4496.836\n",
      "Ep:131, loss:0.00000, loss_test:0.02272, lr:3.42e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.335, tt:4532.163\n",
      "Ep:132, loss:0.00000, loss_test:0.02311, lr:3.38e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.341, tt:4567.306\n",
      "Ep:133, loss:0.00000, loss_test:0.02304, lr:3.35e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.346, tt:4602.392\n",
      "Ep:134, loss:0.00000, loss_test:0.02319, lr:3.32e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.351, tt:4637.451\n",
      "Ep:135, loss:0.00000, loss_test:0.02331, lr:3.28e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.357, tt:4672.568\n",
      "Ep:136, loss:0.00000, loss_test:0.02324, lr:3.25e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.356, tt:4706.728\n",
      "Ep:137, loss:0.00000, loss_test:0.02333, lr:3.22e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.344, tt:4739.415\n",
      "Ep:138, loss:0.00000, loss_test:0.02347, lr:3.19e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.338, tt:4773.014\n",
      "Ep:139, loss:0.00000, loss_test:0.02330, lr:3.15e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.336, tt:4807.034\n",
      "Ep:140, loss:0.00000, loss_test:0.02368, lr:3.12e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.326, tt:4839.910\n",
      "Ep:141, loss:0.00000, loss_test:0.02347, lr:3.09e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.312, tt:4872.312\n",
      "Ep:142, loss:0.00000, loss_test:0.02390, lr:3.06e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.306, tt:4905.787\n",
      "Ep:143, loss:0.00000, loss_test:0.02371, lr:3.03e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.309, tt:4940.486\n",
      "Ep:144, loss:0.00000, loss_test:0.02388, lr:3.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.316, tt:4975.861\n",
      "Ep:145, loss:0.00000, loss_test:0.02384, lr:2.97e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.318, tt:5010.464\n",
      "Ep:146, loss:0.00000, loss_test:0.02396, lr:2.94e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.314, tt:5044.195\n",
      "Ep:147, loss:0.00000, loss_test:0.02415, lr:2.91e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.316, tt:5078.766\n",
      "Ep:148, loss:0.00000, loss_test:0.02403, lr:2.88e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.308, tt:5111.930\n",
      "Ep:149, loss:0.00000, loss_test:0.02409, lr:2.85e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.313, tt:5146.947\n",
      "Ep:150, loss:0.00000, loss_test:0.02404, lr:2.82e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.313, tt:5181.276\n",
      "Ep:151, loss:0.00000, loss_test:0.02449, lr:2.80e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.314, tt:5215.663\n",
      "Ep:152, loss:0.00000, loss_test:0.02412, lr:2.77e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.307, tt:5249.022\n",
      "Ep:153, loss:0.00000, loss_test:0.02459, lr:2.74e-02, fs:0.70588 (r=0.606,p=0.845),  time:34.296, tt:5281.597\n",
      "Ep:154, loss:0.00000, loss_test:0.02429, lr:2.71e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.296, tt:5315.911\n",
      "Ep:155, loss:0.00000, loss_test:0.02477, lr:2.69e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.295, tt:5349.958\n",
      "Ep:156, loss:0.00000, loss_test:0.02424, lr:2.66e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.298, tt:5384.725\n",
      "Ep:157, loss:0.00000, loss_test:0.02491, lr:2.63e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.308, tt:5420.672\n",
      "Ep:158, loss:0.00000, loss_test:0.02444, lr:2.61e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.314, tt:5455.915\n",
      "Ep:159, loss:0.00000, loss_test:0.02512, lr:2.58e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.316, tt:5490.515\n",
      "Ep:160, loss:0.00000, loss_test:0.02456, lr:2.55e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.318, tt:5525.213\n",
      "Ep:161, loss:0.00000, loss_test:0.02495, lr:2.53e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.312, tt:5558.588\n",
      "Ep:162, loss:0.00000, loss_test:0.02489, lr:2.50e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.311, tt:5592.739\n",
      "Ep:163, loss:0.00000, loss_test:0.02504, lr:2.48e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.308, tt:5626.489\n",
      "Ep:164, loss:0.00000, loss_test:0.02506, lr:2.45e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.287, tt:5657.421\n",
      "Ep:165, loss:0.00000, loss_test:0.02500, lr:2.43e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.293, tt:5692.556\n",
      "Ep:166, loss:0.00000, loss_test:0.02531, lr:2.40e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.289, tt:5726.256\n",
      "Ep:167, loss:0.00000, loss_test:0.02506, lr:2.38e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.285, tt:5759.853\n",
      "Ep:168, loss:0.00000, loss_test:0.02532, lr:2.36e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.288, tt:5794.705\n",
      "Ep:169, loss:0.00000, loss_test:0.02534, lr:2.33e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.310, tt:5832.660\n",
      "Ep:170, loss:0.00000, loss_test:0.02521, lr:2.31e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.311, tt:5867.186\n",
      "Ep:171, loss:0.00000, loss_test:0.02563, lr:2.29e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.320, tt:5903.073\n",
      "Ep:172, loss:0.00000, loss_test:0.02554, lr:2.26e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.329, tt:5938.943\n",
      "Ep:173, loss:0.00000, loss_test:0.02547, lr:2.24e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.339, tt:5974.915\n",
      "Ep:174, loss:0.00000, loss_test:0.02566, lr:2.22e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.355, tt:6012.042\n",
      "Ep:175, loss:0.00000, loss_test:0.02563, lr:2.20e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.363, tt:6047.969\n",
      "Ep:176, loss:0.00000, loss_test:0.02567, lr:2.17e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.372, tt:6083.828\n",
      "Ep:177, loss:0.00000, loss_test:0.02556, lr:2.15e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.390, tt:6121.501\n",
      "Ep:178, loss:0.00000, loss_test:0.02615, lr:2.13e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.397, tt:6157.006\n",
      "Ep:179, loss:0.00000, loss_test:0.02564, lr:2.11e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.409, tt:6193.581\n",
      "Ep:180, loss:0.00000, loss_test:0.02606, lr:2.09e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.415, tt:6229.126\n",
      "Ep:181, loss:0.00000, loss_test:0.02592, lr:2.07e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.427, tt:6265.736\n",
      "Ep:182, loss:0.00000, loss_test:0.02591, lr:2.05e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.441, tt:6302.760\n",
      "Ep:183, loss:0.00000, loss_test:0.02609, lr:2.03e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.443, tt:6337.544\n",
      "Ep:184, loss:0.00000, loss_test:0.02614, lr:2.01e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.452, tt:6373.660\n",
      "Ep:185, loss:0.00000, loss_test:0.02616, lr:1.99e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.457, tt:6409.012\n",
      "Ep:186, loss:0.00000, loss_test:0.02616, lr:1.97e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.469, tt:6445.699\n",
      "Ep:187, loss:0.00000, loss_test:0.02640, lr:1.95e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.473, tt:6481.009\n",
      "Ep:188, loss:0.00000, loss_test:0.02612, lr:1.93e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.512, tt:6522.849\n",
      "Ep:189, loss:0.00000, loss_test:0.02636, lr:1.91e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.517, tt:6558.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.02647, lr:1.89e-02, fs:0.71006 (r=0.606,p=0.857),  time:34.519, tt:6593.127\n",
      "Ep:191, loss:0.00000, loss_test:0.02646, lr:1.87e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.523, tt:6628.467\n",
      "Ep:192, loss:0.00000, loss_test:0.02648, lr:1.85e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.530, tt:6664.296\n",
      "Ep:193, loss:0.00000, loss_test:0.02646, lr:1.83e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.532, tt:6699.263\n",
      "Ep:194, loss:0.00000, loss_test:0.02657, lr:1.81e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.530, tt:6733.386\n",
      "Ep:195, loss:0.00000, loss_test:0.02660, lr:1.80e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.531, tt:6768.013\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"7-7\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00025, loss_test:0.12962, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:28.358, tt:28.358\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00025, loss_test:0.12421, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:30.721, tt:61.442\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00024, loss_test:0.11763, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:31.542, tt:94.627\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00023, loss_test:0.11155, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:34.129, tt:136.516\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.10966, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:35.558, tt:177.788\n",
      "Ep:5, loss:0.00022, loss_test:0.10871, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:36.560, tt:219.360\n",
      "Ep:6, loss:0.00021, loss_test:0.10816, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:37.735, tt:264.148\n",
      "Ep:7, loss:0.00021, loss_test:0.10798, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:38.020, tt:304.164\n",
      "Ep:8, loss:0.00020, loss_test:0.10732, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:38.287, tt:344.585\n",
      "Ep:9, loss:0.00019, loss_test:0.10876, lr:1.00e-02, fs:0.67857 (r=0.768,p=0.608),  time:38.576, tt:385.761\n",
      "Ep:10, loss:0.00019, loss_test:0.10774, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:38.799, tt:426.788\n",
      "Ep:11, loss:0.00019, loss_test:0.10967, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:38.911, tt:466.928\n",
      "Ep:12, loss:0.00018, loss_test:0.10962, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:39.168, tt:509.178\n",
      "Ep:13, loss:0.00018, loss_test:0.11044, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:39.350, tt:550.896\n",
      "Ep:14, loss:0.00018, loss_test:0.11055, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:39.550, tt:593.245\n",
      "Ep:15, loss:0.00017, loss_test:0.11072, lr:9.90e-03, fs:0.67290 (r=0.727,p=0.626),  time:39.670, tt:634.728\n",
      "Ep:16, loss:0.00017, loss_test:0.11066, lr:9.80e-03, fs:0.68837 (r=0.747,p=0.638),  time:39.769, tt:676.074\n",
      "Ep:17, loss:0.00017, loss_test:0.11125, lr:9.70e-03, fs:0.66038 (r=0.707,p=0.619),  time:39.879, tt:717.822\n",
      "Ep:18, loss:0.00016, loss_test:0.11215, lr:9.61e-03, fs:0.67619 (r=0.717,p=0.640),  time:39.951, tt:759.078\n",
      "Ep:19, loss:0.00016, loss_test:0.11343, lr:9.51e-03, fs:0.66667 (r=0.707,p=0.631),  time:40.111, tt:802.210\n",
      "Ep:20, loss:0.00016, loss_test:0.11202, lr:9.41e-03, fs:0.68545 (r=0.737,p=0.640),  time:40.204, tt:844.276\n",
      "Ep:21, loss:0.00016, loss_test:0.11398, lr:9.32e-03, fs:0.69524 (r=0.737,p=0.658),  time:40.206, tt:884.531\n",
      "Ep:22, loss:0.00015, loss_test:0.11254, lr:9.23e-03, fs:0.68868 (r=0.737,p=0.646),  time:40.368, tt:928.459\n",
      "Ep:23, loss:0.00015, loss_test:0.11603, lr:9.14e-03, fs:0.67000 (r=0.677,p=0.663),  time:40.393, tt:969.440\n",
      "Ep:24, loss:0.00015, loss_test:0.11460, lr:9.04e-03, fs:0.66986 (r=0.707,p=0.636),  time:40.455, tt:1011.365\n",
      "Ep:25, loss:0.00015, loss_test:0.11879, lr:8.95e-03, fs:0.65657 (r=0.657,p=0.657),  time:40.571, tt:1054.857\n",
      "Ep:26, loss:0.00014, loss_test:0.11582, lr:8.86e-03, fs:0.67647 (r=0.697,p=0.657),  time:40.608, tt:1096.421\n",
      "Ep:27, loss:0.00014, loss_test:0.12155, lr:8.78e-03, fs:0.66667 (r=0.667,p=0.667),  time:40.598, tt:1136.748\n",
      "Ep:28, loss:0.00014, loss_test:0.11901, lr:8.69e-03, fs:0.69000 (r=0.697,p=0.683),  time:40.641, tt:1178.583\n",
      "Ep:29, loss:0.00013, loss_test:0.12110, lr:8.60e-03, fs:0.67677 (r=0.677,p=0.677),  time:40.692, tt:1220.748\n",
      "Ep:30, loss:0.00013, loss_test:0.11794, lr:8.51e-03, fs:0.68657 (r=0.697,p=0.676),  time:40.753, tt:1263.342\n",
      "Ep:31, loss:0.00013, loss_test:0.11809, lr:8.43e-03, fs:0.67337 (r=0.677,p=0.670),  time:40.748, tt:1303.948\n",
      "Ep:32, loss:0.00013, loss_test:0.12595, lr:8.35e-03, fs:0.64211 (r=0.616,p=0.670),  time:40.823, tt:1347.156\n",
      "Ep:33, loss:0.00013, loss_test:0.12305, lr:8.26e-03, fs:0.68041 (r=0.667,p=0.695),  time:40.842, tt:1388.644\n",
      "Ep:34, loss:0.00012, loss_test:0.12467, lr:8.18e-03, fs:0.64921 (r=0.626,p=0.674),  time:40.844, tt:1429.542\n",
      "Ep:35, loss:0.00012, loss_test:0.12225, lr:8.10e-03, fs:0.66321 (r=0.646,p=0.681),  time:40.812, tt:1469.244\n",
      "Ep:36, loss:0.00012, loss_test:0.12704, lr:8.02e-03, fs:0.63830 (r=0.606,p=0.674),  time:40.860, tt:1511.831\n",
      "Ep:37, loss:0.00012, loss_test:0.12545, lr:7.94e-03, fs:0.63830 (r=0.606,p=0.674),  time:40.876, tt:1553.281\n",
      "Ep:38, loss:0.00011, loss_test:0.11663, lr:7.86e-03, fs:0.67327 (r=0.687,p=0.660),  time:40.933, tt:1596.391\n",
      "Ep:39, loss:0.00011, loss_test:0.13303, lr:7.78e-03, fs:0.63830 (r=0.606,p=0.674),  time:40.980, tt:1639.214\n",
      "Ep:40, loss:0.00012, loss_test:0.12637, lr:7.70e-03, fs:0.65241 (r=0.616,p=0.693),  time:40.971, tt:1679.814\n",
      "Ep:41, loss:0.00012, loss_test:0.11928, lr:7.62e-03, fs:0.67347 (r=0.667,p=0.680),  time:40.994, tt:1721.733\n",
      "Ep:42, loss:0.00011, loss_test:0.13290, lr:7.55e-03, fs:0.64171 (r=0.606,p=0.682),  time:41.033, tt:1764.403\n",
      "Ep:43, loss:0.00011, loss_test:0.11637, lr:7.47e-03, fs:0.67662 (r=0.687,p=0.667),  time:41.031, tt:1805.367\n",
      "Ep:44, loss:0.00011, loss_test:0.13387, lr:7.40e-03, fs:0.63388 (r=0.586,p=0.690),  time:41.026, tt:1846.162\n",
      "Ep:45, loss:0.00010, loss_test:0.11830, lr:7.32e-03, fs:0.66667 (r=0.667,p=0.667),  time:41.021, tt:1886.945\n",
      "Ep:46, loss:0.00010, loss_test:0.13742, lr:7.25e-03, fs:0.62222 (r=0.566,p=0.691),  time:41.039, tt:1928.832\n",
      "Ep:47, loss:0.00010, loss_test:0.11751, lr:7.18e-03, fs:0.66321 (r=0.646,p=0.681),  time:41.059, tt:1970.811\n",
      "Ep:48, loss:0.00010, loss_test:0.13527, lr:7.11e-03, fs:0.62295 (r=0.576,p=0.679),  time:41.100, tt:2013.921\n",
      "Ep:49, loss:0.00010, loss_test:0.12491, lr:7.03e-03, fs:0.63333 (r=0.576,p=0.704),  time:41.114, tt:2055.681\n",
      "Ep:50, loss:0.00010, loss_test:0.12749, lr:6.96e-03, fs:0.64773 (r=0.576,p=0.740),  time:41.180, tt:2100.164\n",
      "Ep:51, loss:0.00009, loss_test:0.12978, lr:6.89e-03, fs:0.65217 (r=0.606,p=0.706),  time:41.194, tt:2142.087\n",
      "Ep:52, loss:0.00009, loss_test:0.12273, lr:6.83e-03, fs:0.63736 (r=0.586,p=0.699),  time:41.206, tt:2183.920\n",
      "Ep:53, loss:0.00009, loss_test:0.13365, lr:6.76e-03, fs:0.65909 (r=0.586,p=0.753),  time:41.241, tt:2226.996\n",
      "Ep:54, loss:0.00008, loss_test:0.12305, lr:6.69e-03, fs:0.64088 (r=0.586,p=0.707),  time:41.204, tt:2266.216\n",
      "Ep:55, loss:0.00008, loss_test:0.13841, lr:6.62e-03, fs:0.65556 (r=0.596,p=0.728),  time:41.227, tt:2308.713\n",
      "Ep:56, loss:0.00008, loss_test:0.12299, lr:6.56e-03, fs:0.65556 (r=0.596,p=0.728),  time:41.228, tt:2349.994\n",
      "Ep:57, loss:0.00008, loss_test:0.13629, lr:6.49e-03, fs:0.65909 (r=0.586,p=0.753),  time:41.240, tt:2391.941\n",
      "Ep:58, loss:0.00008, loss_test:0.12661, lr:6.43e-03, fs:0.65922 (r=0.596,p=0.738),  time:41.225, tt:2432.300\n",
      "Ep:59, loss:0.00007, loss_test:0.12894, lr:6.36e-03, fs:0.65909 (r=0.586,p=0.753),  time:41.234, tt:2474.016\n",
      "Ep:60, loss:0.00007, loss_test:0.13611, lr:6.30e-03, fs:0.67816 (r=0.596,p=0.787),  time:41.226, tt:2514.759\n",
      "Ep:61, loss:0.00007, loss_test:0.12255, lr:6.24e-03, fs:0.67416 (r=0.606,p=0.759),  time:41.203, tt:2554.582\n",
      "Ep:62, loss:0.00006, loss_test:0.13795, lr:6.17e-03, fs:0.68927 (r=0.616,p=0.782),  time:41.220, tt:2596.860\n",
      "Ep:63, loss:0.00006, loss_test:0.13083, lr:6.11e-03, fs:0.68208 (r=0.596,p=0.797),  time:41.235, tt:2639.072\n",
      "Ep:64, loss:0.00006, loss_test:0.12822, lr:6.05e-03, fs:0.69274 (r=0.626,p=0.775),  time:41.261, tt:2681.987\n",
      "Ep:65, loss:0.00006, loss_test:0.13589, lr:5.99e-03, fs:0.68571 (r=0.606,p=0.789),  time:41.291, tt:2725.212\n",
      "Ep:66, loss:0.00006, loss_test:0.13074, lr:5.93e-03, fs:0.69006 (r=0.596,p=0.819),  time:41.296, tt:2766.828\n",
      "Ep:67, loss:0.00005, loss_test:0.13672, lr:5.87e-03, fs:0.67816 (r=0.596,p=0.787),  time:41.326, tt:2810.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00005, loss_test:0.13455, lr:5.81e-03, fs:0.68605 (r=0.596,p=0.808),  time:41.339, tt:2852.384\n",
      "Ep:69, loss:0.00005, loss_test:0.12891, lr:5.75e-03, fs:0.69714 (r=0.616,p=0.803),  time:41.355, tt:2894.819\n",
      "Ep:70, loss:0.00005, loss_test:0.13678, lr:5.70e-03, fs:0.70455 (r=0.626,p=0.805),  time:41.374, tt:2937.542\n",
      "Ep:71, loss:0.00005, loss_test:0.12772, lr:5.64e-03, fs:0.71186 (r=0.636,p=0.808),  time:41.419, tt:2982.196\n",
      "Ep:72, loss:0.00005, loss_test:0.13337, lr:5.58e-03, fs:0.68966 (r=0.606,p=0.800),  time:41.418, tt:3023.518\n",
      "Ep:73, loss:0.00004, loss_test:0.13656, lr:5.53e-03, fs:0.68966 (r=0.606,p=0.800),  time:41.411, tt:3064.436\n",
      "Ep:74, loss:0.00004, loss_test:0.13224, lr:5.47e-03, fs:0.70520 (r=0.616,p=0.824),  time:41.413, tt:3105.937\n",
      "Ep:75, loss:0.00004, loss_test:0.13174, lr:5.42e-03, fs:0.72316 (r=0.646,p=0.821),  time:41.422, tt:3148.067\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.13681, lr:5.42e-03, fs:0.69006 (r=0.596,p=0.819),  time:41.427, tt:3189.872\n",
      "Ep:77, loss:0.00004, loss_test:0.14048, lr:5.42e-03, fs:0.68235 (r=0.586,p=0.817),  time:41.428, tt:3231.396\n",
      "Ep:78, loss:0.00004, loss_test:0.13162, lr:5.42e-03, fs:0.73143 (r=0.646,p=0.842),  time:41.450, tt:3274.564\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.13014, lr:5.42e-03, fs:0.73143 (r=0.646,p=0.842),  time:41.466, tt:3317.294\n",
      "Ep:80, loss:0.00004, loss_test:0.14155, lr:5.42e-03, fs:0.67836 (r=0.586,p=0.806),  time:41.477, tt:3359.629\n",
      "Ep:81, loss:0.00004, loss_test:0.13523, lr:5.42e-03, fs:0.70175 (r=0.606,p=0.833),  time:41.493, tt:3402.443\n",
      "Ep:82, loss:0.00003, loss_test:0.12932, lr:5.42e-03, fs:0.72727 (r=0.646,p=0.831),  time:41.501, tt:3444.581\n",
      "Ep:83, loss:0.00004, loss_test:0.14472, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.492, tt:3485.327\n",
      "Ep:84, loss:0.00004, loss_test:0.13551, lr:5.42e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.506, tt:3528.038\n",
      "Ep:85, loss:0.00003, loss_test:0.13228, lr:5.42e-03, fs:0.69006 (r=0.596,p=0.819),  time:41.521, tt:3570.807\n",
      "Ep:86, loss:0.00003, loss_test:0.14130, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.536, tt:3613.597\n",
      "Ep:87, loss:0.00003, loss_test:0.12927, lr:5.42e-03, fs:0.69364 (r=0.606,p=0.811),  time:41.535, tt:3655.118\n",
      "Ep:88, loss:0.00003, loss_test:0.14032, lr:5.42e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.554, tt:3698.271\n",
      "Ep:89, loss:0.00003, loss_test:0.14041, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.572, tt:3741.515\n",
      "Ep:90, loss:0.00003, loss_test:0.13124, lr:5.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:41.584, tt:3784.161\n",
      "Ep:91, loss:0.00003, loss_test:0.13369, lr:5.31e-03, fs:0.68235 (r=0.586,p=0.817),  time:41.567, tt:3824.183\n",
      "Ep:92, loss:0.00003, loss_test:0.13903, lr:5.26e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.547, tt:3863.840\n",
      "Ep:93, loss:0.00003, loss_test:0.12893, lr:5.20e-03, fs:0.73446 (r=0.657,p=0.833),  time:41.573, tt:3907.886\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00003, loss_test:0.14512, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.559, tt:3948.063\n",
      "Ep:95, loss:0.00003, loss_test:0.13030, lr:5.20e-03, fs:0.68639 (r=0.586,p=0.829),  time:41.560, tt:3989.803\n",
      "Ep:96, loss:0.00003, loss_test:0.13616, lr:5.20e-03, fs:0.69822 (r=0.596,p=0.843),  time:41.545, tt:4029.832\n",
      "Ep:97, loss:0.00003, loss_test:0.13508, lr:5.20e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.550, tt:4071.936\n",
      "Ep:98, loss:0.00002, loss_test:0.13490, lr:5.20e-03, fs:0.70588 (r=0.606,p=0.845),  time:41.567, tt:4115.102\n",
      "Ep:99, loss:0.00002, loss_test:0.13593, lr:5.20e-03, fs:0.68639 (r=0.586,p=0.829),  time:41.575, tt:4157.486\n",
      "Ep:100, loss:0.00002, loss_test:0.13446, lr:5.20e-03, fs:0.71006 (r=0.606,p=0.857),  time:41.560, tt:4197.596\n",
      "Ep:101, loss:0.00002, loss_test:0.13478, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.572, tt:4240.300\n",
      "Ep:102, loss:0.00002, loss_test:0.13459, lr:5.20e-03, fs:0.69822 (r=0.596,p=0.843),  time:41.586, tt:4283.307\n",
      "Ep:103, loss:0.00002, loss_test:0.13463, lr:5.20e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.587, tt:4325.047\n",
      "Ep:104, loss:0.00002, loss_test:0.13997, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.591, tt:4367.019\n",
      "Ep:105, loss:0.00002, loss_test:0.13258, lr:5.15e-03, fs:0.70588 (r=0.606,p=0.845),  time:41.591, tt:4408.643\n",
      "Ep:106, loss:0.00002, loss_test:0.13796, lr:5.10e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.597, tt:4450.844\n",
      "Ep:107, loss:0.00002, loss_test:0.13528, lr:5.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.615, tt:4494.456\n",
      "Ep:108, loss:0.00002, loss_test:0.13644, lr:5.00e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.622, tt:4536.770\n",
      "Ep:109, loss:0.00002, loss_test:0.14001, lr:4.95e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.646, tt:4581.043\n",
      "Ep:110, loss:0.00002, loss_test:0.13498, lr:4.90e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.640, tt:4622.034\n",
      "Ep:111, loss:0.00002, loss_test:0.13358, lr:4.85e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.636, tt:4663.235\n",
      "Ep:112, loss:0.00002, loss_test:0.14017, lr:4.80e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.625, tt:4703.597\n",
      "Ep:113, loss:0.00002, loss_test:0.13439, lr:4.75e-03, fs:0.70238 (r=0.596,p=0.855),  time:41.619, tt:4744.597\n",
      "Ep:114, loss:0.00002, loss_test:0.13974, lr:4.71e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.630, tt:4787.496\n",
      "Ep:115, loss:0.00002, loss_test:0.13432, lr:4.66e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.645, tt:4830.796\n",
      "Ep:116, loss:0.00002, loss_test:0.13958, lr:4.61e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.657, tt:4873.825\n",
      "Ep:117, loss:0.00002, loss_test:0.13599, lr:4.57e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.650, tt:4914.691\n",
      "Ep:118, loss:0.00002, loss_test:0.13316, lr:4.52e-03, fs:0.74713 (r=0.657,p=0.867),  time:41.672, tt:4958.918\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.14010, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.672, tt:5000.641\n",
      "Ep:120, loss:0.00002, loss_test:0.13585, lr:4.52e-03, fs:0.71006 (r=0.606,p=0.857),  time:41.688, tt:5044.202\n",
      "Ep:121, loss:0.00001, loss_test:0.13657, lr:4.52e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.682, tt:5085.185\n",
      "Ep:122, loss:0.00001, loss_test:0.13776, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.678, tt:5126.437\n",
      "Ep:123, loss:0.00001, loss_test:0.13588, lr:4.52e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.666, tt:5166.550\n",
      "Ep:124, loss:0.00001, loss_test:0.13930, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.685, tt:5210.623\n",
      "Ep:125, loss:0.00001, loss_test:0.13623, lr:4.52e-03, fs:0.69048 (r=0.586,p=0.841),  time:41.681, tt:5251.860\n",
      "Ep:126, loss:0.00001, loss_test:0.14005, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.661, tt:5290.912\n",
      "Ep:127, loss:0.00001, loss_test:0.13851, lr:4.52e-03, fs:0.68675 (r=0.576,p=0.851),  time:41.650, tt:5331.244\n",
      "Ep:128, loss:0.00001, loss_test:0.14255, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.685, tt:5377.301\n",
      "Ep:129, loss:0.00001, loss_test:0.13986, lr:4.52e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.709, tt:5422.192\n",
      "Ep:130, loss:0.00001, loss_test:0.14129, lr:4.48e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.722, tt:5465.572\n",
      "Ep:131, loss:0.00001, loss_test:0.14114, lr:4.43e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.732, tt:5508.619\n",
      "Ep:132, loss:0.00001, loss_test:0.14075, lr:4.39e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.721, tt:5548.854\n",
      "Ep:133, loss:0.00001, loss_test:0.14222, lr:4.34e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.721, tt:5590.551\n",
      "Ep:134, loss:0.00001, loss_test:0.14032, lr:4.30e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.728, tt:5633.287\n",
      "Ep:135, loss:0.00001, loss_test:0.13986, lr:4.26e-03, fs:0.68263 (r=0.576,p=0.838),  time:41.747, tt:5677.616\n",
      "Ep:136, loss:0.00001, loss_test:0.14539, lr:4.21e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.735, tt:5717.631\n",
      "Ep:137, loss:0.00001, loss_test:0.13837, lr:4.17e-03, fs:0.68263 (r=0.576,p=0.838),  time:41.723, tt:5757.821\n",
      "Ep:138, loss:0.00001, loss_test:0.14418, lr:4.13e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.707, tt:5797.318\n",
      "Ep:139, loss:0.00001, loss_test:0.13910, lr:4.09e-03, fs:0.68263 (r=0.576,p=0.838),  time:41.722, tt:5841.086\n",
      "Ep:140, loss:0.00001, loss_test:0.14090, lr:4.05e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.721, tt:5882.641\n",
      "Ep:141, loss:0.00001, loss_test:0.14094, lr:4.01e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.721, tt:5924.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.14081, lr:3.97e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.719, tt:5965.882\n",
      "Ep:143, loss:0.00001, loss_test:0.14010, lr:3.93e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.722, tt:6008.011\n",
      "Ep:144, loss:0.00001, loss_test:0.14182, lr:3.89e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.723, tt:6049.823\n",
      "Ep:145, loss:0.00001, loss_test:0.14147, lr:3.85e-03, fs:0.70303 (r=0.586,p=0.879),  time:41.723, tt:6091.547\n",
      "Ep:146, loss:0.00001, loss_test:0.14050, lr:3.81e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.748, tt:6136.970\n",
      "Ep:147, loss:0.00001, loss_test:0.14090, lr:3.77e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.746, tt:6178.406\n",
      "Ep:148, loss:0.00001, loss_test:0.13978, lr:3.73e-03, fs:0.69461 (r=0.586,p=0.853),  time:41.747, tt:6220.273\n",
      "Ep:149, loss:0.00001, loss_test:0.14139, lr:3.70e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.752, tt:6262.730\n",
      "Ep:150, loss:0.00001, loss_test:0.14210, lr:3.66e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.746, tt:6303.690\n",
      "Ep:151, loss:0.00001, loss_test:0.14215, lr:3.62e-03, fs:0.69512 (r=0.576,p=0.877),  time:41.756, tt:6346.859\n",
      "Ep:152, loss:0.00001, loss_test:0.14152, lr:3.59e-03, fs:0.69880 (r=0.586,p=0.866),  time:41.765, tt:6389.995\n",
      "Ep:153, loss:0.00001, loss_test:0.14256, lr:3.55e-03, fs:0.69091 (r=0.576,p=0.864),  time:41.774, tt:6433.209\n",
      "Ep:154, loss:0.00001, loss_test:0.14061, lr:3.52e-03, fs:0.68675 (r=0.576,p=0.851),  time:41.778, tt:6475.552\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13447, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:17.449, tt:17.449\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13421, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:16.542, tt:33.084\n",
      "Ep:2, loss:0.00026, loss_test:0.13363, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:17.049, tt:51.148\n",
      "Ep:3, loss:0.00025, loss_test:0.13284, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:17.300, tt:69.199\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13161, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:17.161, tt:85.806\n",
      "Ep:5, loss:0.00025, loss_test:0.13025, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:16.921, tt:101.523\n",
      "Ep:6, loss:0.00025, loss_test:0.12883, lr:1.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:17.294, tt:121.059\n",
      "Ep:7, loss:0.00024, loss_test:0.12734, lr:1.00e-02, fs:0.65272 (r=0.788,p=0.557),  time:17.242, tt:137.936\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12564, lr:1.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:17.536, tt:157.828\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.12353, lr:1.00e-02, fs:0.64979 (r=0.778,p=0.558),  time:17.815, tt:178.149\n",
      "Ep:10, loss:0.00024, loss_test:0.12074, lr:1.00e-02, fs:0.65254 (r=0.778,p=0.562),  time:17.954, tt:197.492\n",
      "Ep:11, loss:0.00023, loss_test:0.11808, lr:1.00e-02, fs:0.65254 (r=0.778,p=0.562),  time:17.882, tt:214.582\n",
      "Ep:12, loss:0.00023, loss_test:0.11501, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:17.915, tt:232.899\n",
      "Ep:13, loss:0.00022, loss_test:0.11147, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:17.903, tt:250.641\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.10913, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:17.875, tt:268.125\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.10627, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:18.169, tt:290.710\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.10360, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:18.237, tt:310.021\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.10323, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:18.183, tt:327.299\n",
      "Ep:18, loss:0.00020, loss_test:0.10047, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:18.159, tt:345.016\n",
      "Ep:19, loss:0.00019, loss_test:0.10090, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:18.118, tt:362.363\n",
      "Ep:20, loss:0.00019, loss_test:0.09879, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:18.056, tt:379.174\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09772, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:18.035, tt:396.779\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.09610, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:18.101, tt:416.325\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.09570, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:18.067, tt:433.613\n",
      "Ep:24, loss:0.00017, loss_test:0.09570, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:18.031, tt:450.777\n",
      "Ep:25, loss:0.00016, loss_test:0.09395, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:17.996, tt:467.894\n",
      "Ep:26, loss:0.00016, loss_test:0.09257, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:17.893, tt:483.098\n",
      "Ep:27, loss:0.00015, loss_test:0.09262, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:17.895, tt:501.073\n",
      "Ep:28, loss:0.00015, loss_test:0.09218, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:17.964, tt:520.951\n",
      "Ep:29, loss:0.00014, loss_test:0.09206, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:17.959, tt:538.777\n",
      "Ep:30, loss:0.00014, loss_test:0.09340, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:17.902, tt:554.959\n",
      "Ep:31, loss:0.00013, loss_test:0.09277, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:17.928, tt:573.698\n",
      "Ep:32, loss:0.00013, loss_test:0.09203, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:17.963, tt:592.782\n",
      "Ep:33, loss:0.00012, loss_test:0.09530, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:17.990, tt:611.646\n",
      "Ep:34, loss:0.00012, loss_test:0.09415, lr:9.90e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.046, tt:631.614\n",
      "Ep:35, loss:0.00011, loss_test:0.09205, lr:9.80e-03, fs:0.74510 (r=0.768,p=0.724),  time:18.012, tt:648.425\n",
      "Ep:36, loss:0.00011, loss_test:0.09783, lr:9.70e-03, fs:0.71658 (r=0.677,p=0.761),  time:17.967, tt:664.769\n",
      "Ep:37, loss:0.00010, loss_test:0.09443, lr:9.61e-03, fs:0.70051 (r=0.697,p=0.704),  time:17.952, tt:682.182\n",
      "Ep:38, loss:0.00010, loss_test:0.09259, lr:9.51e-03, fs:0.71154 (r=0.747,p=0.679),  time:17.919, tt:698.858\n",
      "Ep:39, loss:0.00010, loss_test:0.09411, lr:9.41e-03, fs:0.72727 (r=0.687,p=0.773),  time:17.947, tt:717.890\n",
      "Ep:40, loss:0.00010, loss_test:0.08984, lr:9.32e-03, fs:0.73298 (r=0.707,p=0.761),  time:17.949, tt:735.909\n",
      "Ep:41, loss:0.00009, loss_test:0.09292, lr:9.23e-03, fs:0.67429 (r=0.596,p=0.776),  time:17.896, tt:751.643\n",
      "Ep:42, loss:0.00008, loss_test:0.09277, lr:9.14e-03, fs:0.65574 (r=0.606,p=0.714),  time:17.889, tt:769.242\n",
      "Ep:43, loss:0.00008, loss_test:0.09406, lr:9.04e-03, fs:0.68108 (r=0.636,p=0.733),  time:17.927, tt:788.804\n",
      "Ep:44, loss:0.00008, loss_test:0.09606, lr:8.95e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.962, tt:808.279\n",
      "Ep:45, loss:0.00007, loss_test:0.09401, lr:8.86e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.974, tt:826.802\n",
      "Ep:46, loss:0.00007, loss_test:0.09440, lr:8.78e-03, fs:0.67816 (r=0.596,p=0.787),  time:17.995, tt:845.787\n",
      "Ep:47, loss:0.00006, loss_test:0.09509, lr:8.69e-03, fs:0.67052 (r=0.586,p=0.784),  time:17.958, tt:861.995\n",
      "Ep:48, loss:0.00006, loss_test:0.09261, lr:8.60e-03, fs:0.68966 (r=0.606,p=0.800),  time:17.978, tt:880.899\n",
      "Ep:49, loss:0.00006, loss_test:0.09846, lr:8.51e-03, fs:0.67816 (r=0.596,p=0.787),  time:17.958, tt:897.892\n",
      "Ep:50, loss:0.00005, loss_test:0.09578, lr:8.43e-03, fs:0.68605 (r=0.596,p=0.808),  time:17.934, tt:914.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00005, loss_test:0.09342, lr:8.35e-03, fs:0.69613 (r=0.636,p=0.768),  time:17.885, tt:930.043\n",
      "Ep:52, loss:0.00005, loss_test:0.08908, lr:8.26e-03, fs:0.71795 (r=0.707,p=0.729),  time:17.912, tt:949.347\n",
      "Ep:53, loss:0.00006, loss_test:0.10340, lr:8.18e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.914, tt:967.369\n",
      "Ep:54, loss:0.00005, loss_test:0.09846, lr:8.10e-03, fs:0.69006 (r=0.596,p=0.819),  time:17.916, tt:985.390\n",
      "Ep:55, loss:0.00005, loss_test:0.09885, lr:8.02e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.913, tt:1003.113\n",
      "Ep:56, loss:0.00004, loss_test:0.09812, lr:7.94e-03, fs:0.67052 (r=0.586,p=0.784),  time:17.967, tt:1024.139\n",
      "Ep:57, loss:0.00004, loss_test:0.10194, lr:7.86e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.988, tt:1043.313\n",
      "Ep:58, loss:0.00004, loss_test:0.10052, lr:7.78e-03, fs:0.68235 (r=0.586,p=0.817),  time:18.023, tt:1063.375\n",
      "Ep:59, loss:0.00004, loss_test:0.10354, lr:7.70e-03, fs:0.66286 (r=0.586,p=0.763),  time:18.053, tt:1083.158\n",
      "Ep:60, loss:0.00004, loss_test:0.10101, lr:7.62e-03, fs:0.67442 (r=0.586,p=0.795),  time:18.043, tt:1100.638\n",
      "Ep:61, loss:0.00003, loss_test:0.10611, lr:7.55e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.045, tt:1118.815\n",
      "Ep:62, loss:0.00003, loss_test:0.09948, lr:7.47e-03, fs:0.66667 (r=0.586,p=0.773),  time:18.035, tt:1136.205\n",
      "Ep:63, loss:0.00003, loss_test:0.10529, lr:7.40e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.033, tt:1154.080\n",
      "Ep:64, loss:0.00003, loss_test:0.10308, lr:7.32e-03, fs:0.71765 (r=0.616,p=0.859),  time:18.017, tt:1171.119\n",
      "Ep:65, loss:0.00003, loss_test:0.09699, lr:7.25e-03, fs:0.66667 (r=0.586,p=0.773),  time:18.010, tt:1188.656\n",
      "Ep:66, loss:0.00003, loss_test:0.11141, lr:7.18e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.996, tt:1205.755\n",
      "Ep:67, loss:0.00003, loss_test:0.10220, lr:7.11e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.969, tt:1221.886\n",
      "Ep:68, loss:0.00003, loss_test:0.10200, lr:7.03e-03, fs:0.66667 (r=0.586,p=0.773),  time:17.962, tt:1239.405\n",
      "Ep:69, loss:0.00003, loss_test:0.10561, lr:6.96e-03, fs:0.70659 (r=0.596,p=0.868),  time:17.935, tt:1255.441\n",
      "Ep:70, loss:0.00003, loss_test:0.10309, lr:6.89e-03, fs:0.67442 (r=0.586,p=0.795),  time:17.908, tt:1271.483\n",
      "Ep:71, loss:0.00003, loss_test:0.10307, lr:6.83e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.917, tt:1290.038\n",
      "Ep:72, loss:0.00003, loss_test:0.10598, lr:6.76e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.909, tt:1307.379\n",
      "Ep:73, loss:0.00003, loss_test:0.10640, lr:6.69e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.903, tt:1324.858\n",
      "Ep:74, loss:0.00002, loss_test:0.10132, lr:6.62e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.887, tt:1341.562\n",
      "Ep:75, loss:0.00003, loss_test:0.10314, lr:6.56e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.869, tt:1358.062\n",
      "Ep:76, loss:0.00002, loss_test:0.10612, lr:6.49e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.853, tt:1374.695\n",
      "Ep:77, loss:0.00002, loss_test:0.10529, lr:6.43e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.852, tt:1392.489\n",
      "Ep:78, loss:0.00002, loss_test:0.10608, lr:6.36e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.848, tt:1409.955\n",
      "Ep:79, loss:0.00002, loss_test:0.10632, lr:6.30e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.820, tt:1425.579\n",
      "Ep:80, loss:0.00002, loss_test:0.10672, lr:6.24e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.822, tt:1443.566\n",
      "Ep:81, loss:0.00002, loss_test:0.10495, lr:6.17e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.820, tt:1461.273\n",
      "Ep:82, loss:0.00002, loss_test:0.10314, lr:6.11e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.811, tt:1478.346\n",
      "Ep:83, loss:0.00002, loss_test:0.10506, lr:6.05e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.801, tt:1495.277\n",
      "Ep:84, loss:0.00002, loss_test:0.10526, lr:5.99e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.792, tt:1512.305\n",
      "Ep:85, loss:0.00002, loss_test:0.10228, lr:5.93e-03, fs:0.67836 (r=0.586,p=0.806),  time:17.774, tt:1528.555\n",
      "Ep:86, loss:0.00002, loss_test:0.10482, lr:5.87e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.765, tt:1545.534\n",
      "Ep:87, loss:0.00002, loss_test:0.10632, lr:5.81e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.763, tt:1563.177\n",
      "Ep:88, loss:0.00002, loss_test:0.10291, lr:5.75e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.760, tt:1580.658\n",
      "Ep:89, loss:0.00002, loss_test:0.10727, lr:5.70e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.717, tt:1594.574\n",
      "Ep:90, loss:0.00001, loss_test:0.10468, lr:5.64e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.672, tt:1608.188\n",
      "Ep:91, loss:0.00001, loss_test:0.10441, lr:5.58e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.617, tt:1620.775\n",
      "Ep:92, loss:0.00001, loss_test:0.10626, lr:5.53e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.585, tt:1635.446\n",
      "Ep:93, loss:0.00001, loss_test:0.10571, lr:5.47e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.572, tt:1651.744\n",
      "Ep:94, loss:0.00001, loss_test:0.10592, lr:5.42e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.561, tt:1668.252\n",
      "Ep:95, loss:0.00001, loss_test:0.10498, lr:5.36e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.535, tt:1683.343\n",
      "Ep:96, loss:0.00001, loss_test:0.10479, lr:5.31e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.498, tt:1697.310\n",
      "Ep:97, loss:0.00001, loss_test:0.10541, lr:5.26e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.451, tt:1710.155\n",
      "Ep:98, loss:0.00001, loss_test:0.10505, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.429, tt:1725.468\n",
      "Ep:99, loss:0.00001, loss_test:0.10489, lr:5.15e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.427, tt:1742.692\n",
      "Ep:100, loss:0.00001, loss_test:0.10430, lr:5.10e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.422, tt:1759.650\n",
      "Ep:101, loss:0.00001, loss_test:0.10676, lr:5.05e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.411, tt:1775.961\n",
      "Ep:102, loss:0.00001, loss_test:0.10325, lr:5.00e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.405, tt:1792.729\n",
      "Ep:103, loss:0.00001, loss_test:0.10501, lr:4.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.412, tt:1810.835\n",
      "Ep:104, loss:0.00001, loss_test:0.10375, lr:4.90e-03, fs:0.68235 (r=0.586,p=0.817),  time:17.401, tt:1827.116\n",
      "Ep:105, loss:0.00001, loss_test:0.10741, lr:4.85e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.400, tt:1844.385\n",
      "Ep:106, loss:0.00001, loss_test:0.10538, lr:4.80e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.404, tt:1862.187\n",
      "Ep:107, loss:0.00001, loss_test:0.10312, lr:4.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.390, tt:1878.102\n",
      "Ep:108, loss:0.00001, loss_test:0.10890, lr:4.71e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.391, tt:1895.569\n",
      "Ep:109, loss:0.00001, loss_test:0.10553, lr:4.66e-03, fs:0.68639 (r=0.586,p=0.829),  time:17.399, tt:1913.921\n",
      "Ep:110, loss:0.00001, loss_test:0.10717, lr:4.61e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.400, tt:1931.402\n",
      "Ep:111, loss:0.00001, loss_test:0.10481, lr:4.57e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.393, tt:1948.038\n",
      "Ep:112, loss:0.00001, loss_test:0.10548, lr:4.52e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.399, tt:1966.103\n",
      "Ep:113, loss:0.00001, loss_test:0.10508, lr:4.48e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.387, tt:1982.090\n",
      "Ep:114, loss:0.00001, loss_test:0.10487, lr:4.43e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.388, tt:1999.622\n",
      "Ep:115, loss:0.00001, loss_test:0.10605, lr:4.39e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.388, tt:2016.958\n",
      "Ep:116, loss:0.00001, loss_test:0.10347, lr:4.34e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.371, tt:2032.430\n",
      "Ep:117, loss:0.00001, loss_test:0.10633, lr:4.30e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.375, tt:2050.200\n",
      "Ep:118, loss:0.00001, loss_test:0.10524, lr:4.26e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.389, tt:2069.308\n",
      "Ep:119, loss:0.00001, loss_test:0.10588, lr:4.21e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.364, tt:2083.697\n",
      "Ep:120, loss:0.00001, loss_test:0.10698, lr:4.17e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.369, tt:2101.628\n",
      "Ep:121, loss:0.00001, loss_test:0.10472, lr:4.13e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.371, tt:2119.265\n",
      "Ep:122, loss:0.00001, loss_test:0.10557, lr:4.09e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.369, tt:2136.371\n",
      "Ep:123, loss:0.00001, loss_test:0.10485, lr:4.05e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.358, tt:2152.333\n",
      "Ep:124, loss:0.00001, loss_test:0.10528, lr:4.01e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.344, tt:2167.948\n",
      "Ep:125, loss:0.00001, loss_test:0.10503, lr:3.97e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.346, tt:2185.546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00001, loss_test:0.10466, lr:3.93e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.329, tt:2200.770\n",
      "Ep:127, loss:0.00001, loss_test:0.10651, lr:3.89e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.318, tt:2216.689\n",
      "Ep:128, loss:0.00001, loss_test:0.10478, lr:3.85e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.323, tt:2234.656\n",
      "Ep:129, loss:0.00001, loss_test:0.10554, lr:3.81e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.304, tt:2249.560\n",
      "Ep:130, loss:0.00001, loss_test:0.10491, lr:3.77e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.306, tt:2267.022\n",
      "Ep:131, loss:0.00001, loss_test:0.10559, lr:3.73e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.323, tt:2286.646\n",
      "Ep:132, loss:0.00001, loss_test:0.10719, lr:3.70e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.310, tt:2302.218\n",
      "Ep:133, loss:0.00001, loss_test:0.10415, lr:3.66e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.318, tt:2320.579\n",
      "Ep:134, loss:0.00001, loss_test:0.10672, lr:3.62e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.335, tt:2340.176\n",
      "Ep:135, loss:0.00001, loss_test:0.10552, lr:3.59e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.319, tt:2355.400\n",
      "Ep:136, loss:0.00001, loss_test:0.10500, lr:3.55e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.314, tt:2372.010\n",
      "Ep:137, loss:0.00001, loss_test:0.10639, lr:3.52e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.331, tt:2391.637\n",
      "Ep:138, loss:0.00001, loss_test:0.10586, lr:3.48e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.318, tt:2407.137\n",
      "Ep:139, loss:0.00001, loss_test:0.10656, lr:3.45e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.312, tt:2423.635\n",
      "Ep:140, loss:0.00001, loss_test:0.10630, lr:3.41e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.328, tt:2443.216\n",
      "Ep:141, loss:0.00001, loss_test:0.10525, lr:3.38e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.330, tt:2460.812\n",
      "Ep:142, loss:0.00001, loss_test:0.10635, lr:3.34e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.320, tt:2476.821\n",
      "Ep:143, loss:0.00001, loss_test:0.10584, lr:3.31e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.330, tt:2495.476\n",
      "Ep:144, loss:0.00001, loss_test:0.10558, lr:3.28e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.332, tt:2513.094\n",
      "Ep:145, loss:0.00001, loss_test:0.10620, lr:3.24e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.329, tt:2530.104\n",
      "Ep:146, loss:0.00001, loss_test:0.10583, lr:3.21e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.328, tt:2547.281\n",
      "Ep:147, loss:0.00001, loss_test:0.10644, lr:3.18e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.329, tt:2564.689\n",
      "Ep:148, loss:0.00001, loss_test:0.10584, lr:3.15e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.344, tt:2584.216\n",
      "Ep:149, loss:0.00001, loss_test:0.10559, lr:3.12e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.353, tt:2602.994\n",
      "Ep:150, loss:0.00001, loss_test:0.10592, lr:3.09e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.361, tt:2621.469\n",
      "Ep:151, loss:0.00001, loss_test:0.10489, lr:3.05e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.360, tt:2638.652\n",
      "Ep:152, loss:0.00001, loss_test:0.10616, lr:3.02e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.371, tt:2657.721\n",
      "Ep:153, loss:0.00001, loss_test:0.10684, lr:2.99e-03, fs:0.69461 (r=0.586,p=0.853),  time:17.384, tt:2677.152\n",
      "Ep:154, loss:0.00001, loss_test:0.10568, lr:2.96e-03, fs:0.69048 (r=0.586,p=0.841),  time:17.373, tt:2692.774\n",
      "Ep:155, loss:0.00001, loss_test:0.10788, lr:2.93e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.382, tt:2711.543\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13944, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:21.372, tt:21.372\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13901, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:20.724, tt:41.449\n",
      "Ep:2, loss:0.00026, loss_test:0.13821, lr:1.00e-02, fs:0.62745 (r=0.808,p=0.513),  time:21.297, tt:63.891\n",
      "Ep:3, loss:0.00025, loss_test:0.13681, lr:1.00e-02, fs:0.63241 (r=0.808,p=0.519),  time:20.302, tt:81.209\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13510, lr:1.00e-02, fs:0.63454 (r=0.798,p=0.527),  time:19.633, tt:98.167\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.13382, lr:1.00e-02, fs:0.62857 (r=0.778,p=0.527),  time:19.825, tt:118.948\n",
      "Ep:6, loss:0.00024, loss_test:0.13228, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:19.821, tt:138.747\n",
      "Ep:7, loss:0.00023, loss_test:0.13024, lr:1.00e-02, fs:0.62500 (r=0.758,p=0.532),  time:20.091, tt:160.728\n",
      "Ep:8, loss:0.00023, loss_test:0.12799, lr:1.00e-02, fs:0.62393 (r=0.737,p=0.541),  time:20.228, tt:182.050\n",
      "Ep:9, loss:0.00022, loss_test:0.12187, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:20.078, tt:200.779\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.11818, lr:1.00e-02, fs:0.63850 (r=0.687,p=0.596),  time:20.052, tt:220.577\n",
      "Ep:11, loss:0.00019, loss_test:0.11642, lr:1.00e-02, fs:0.61836 (r=0.646,p=0.593),  time:19.977, tt:239.719\n",
      "Ep:12, loss:0.00018, loss_test:0.11196, lr:1.00e-02, fs:0.62827 (r=0.606,p=0.652),  time:19.952, tt:259.370\n",
      "Ep:13, loss:0.00017, loss_test:0.10814, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:19.935, tt:279.084\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.10702, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:19.948, tt:299.223\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.10237, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:20.042, tt:320.666\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.09886, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:20.099, tt:341.682\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09919, lr:1.00e-02, fs:0.66667 (r=0.606,p=0.741),  time:20.004, tt:360.072\n",
      "Ep:18, loss:0.00013, loss_test:0.09562, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:20.082, tt:381.549\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.09753, lr:1.00e-02, fs:0.68927 (r=0.616,p=0.782),  time:20.055, tt:401.090\n",
      "Ep:20, loss:0.00011, loss_test:0.09104, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:19.977, tt:419.518\n",
      "Ep:21, loss:0.00011, loss_test:0.10101, lr:1.00e-02, fs:0.65868 (r=0.556,p=0.809),  time:19.952, tt:438.942\n",
      "Ep:22, loss:0.00010, loss_test:0.08880, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:19.882, tt:457.295\n",
      "Ep:23, loss:0.00009, loss_test:0.09191, lr:1.00e-02, fs:0.70732 (r=0.586,p=0.892),  time:19.914, tt:477.938\n",
      "Ep:24, loss:0.00009, loss_test:0.09062, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:19.974, tt:499.360\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00008, loss_test:0.08895, lr:1.00e-02, fs:0.71084 (r=0.596,p=0.881),  time:19.959, tt:518.945\n",
      "Ep:26, loss:0.00008, loss_test:0.09065, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:19.957, tt:538.837\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00008, loss_test:0.09426, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:19.885, tt:556.786\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.08455, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:19.909, tt:577.375\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00007, loss_test:0.09112, lr:1.00e-02, fs:0.71856 (r=0.606,p=0.882),  time:19.965, tt:598.960\n",
      "Ep:30, loss:0.00006, loss_test:0.08944, lr:1.00e-02, fs:0.68639 (r=0.586,p=0.829),  time:19.965, tt:618.910\n",
      "Ep:31, loss:0.00006, loss_test:0.08512, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:20.044, tt:641.422\n",
      "Ep:32, loss:0.00005, loss_test:0.07989, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:20.058, tt:661.911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00005, loss_test:0.08798, lr:1.00e-02, fs:0.72414 (r=0.636,p=0.840),  time:20.000, tt:680.016\n",
      "Ep:34, loss:0.00006, loss_test:0.08354, lr:1.00e-02, fs:0.76023 (r=0.657,p=0.903),  time:19.979, tt:699.274\n",
      "Ep:35, loss:0.00005, loss_test:0.08600, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:19.970, tt:718.936\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.09600, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:19.990, tt:739.646\n",
      "Ep:37, loss:0.00005, loss_test:0.08291, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:20.013, tt:760.492\n",
      "Ep:38, loss:0.00005, loss_test:0.08750, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:20.024, tt:780.919\n",
      "Ep:39, loss:0.00004, loss_test:0.08636, lr:1.00e-02, fs:0.70175 (r=0.606,p=0.833),  time:20.042, tt:801.688\n",
      "Ep:40, loss:0.00004, loss_test:0.08258, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:20.084, tt:823.424\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00004, loss_test:0.08317, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:20.082, tt:843.423\n",
      "Ep:42, loss:0.00004, loss_test:0.07651, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:20.095, tt:864.086\n",
      "Ep:43, loss:0.00003, loss_test:0.08996, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:20.107, tt:884.688\n",
      "Ep:44, loss:0.00003, loss_test:0.07544, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:20.140, tt:906.293\n",
      "Ep:45, loss:0.00003, loss_test:0.08669, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:20.191, tt:928.765\n",
      "Ep:46, loss:0.00003, loss_test:0.07959, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:20.175, tt:948.241\n",
      "Ep:47, loss:0.00003, loss_test:0.07813, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:20.201, tt:969.630\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.08390, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:20.198, tt:989.708\n",
      "Ep:49, loss:0.00003, loss_test:0.07569, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:20.258, tt:1012.925\n",
      "Ep:50, loss:0.00002, loss_test:0.08473, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:20.251, tt:1032.789\n",
      "Ep:51, loss:0.00002, loss_test:0.07748, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:20.265, tt:1053.774\n",
      "Ep:52, loss:0.00002, loss_test:0.08153, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:20.301, tt:1075.934\n",
      "Ep:53, loss:0.00002, loss_test:0.08097, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:20.319, tt:1097.203\n",
      "Ep:54, loss:0.00002, loss_test:0.07518, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:20.347, tt:1119.087\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.08516, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:20.410, tt:1142.952\n",
      "Ep:56, loss:0.00003, loss_test:0.08089, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.426, tt:1164.254\n",
      "Ep:57, loss:0.00003, loss_test:0.08277, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:20.439, tt:1185.442\n",
      "Ep:58, loss:0.00003, loss_test:0.08786, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:20.465, tt:1207.455\n",
      "Ep:59, loss:0.00003, loss_test:0.07028, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:20.476, tt:1228.546\n",
      "Ep:60, loss:0.00003, loss_test:0.08859, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:20.468, tt:1248.559\n",
      "Ep:61, loss:0.00002, loss_test:0.07612, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.443, tt:1267.486\n",
      "Ep:62, loss:0.00002, loss_test:0.07387, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:20.431, tt:1287.167\n",
      "Ep:63, loss:0.00002, loss_test:0.09174, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:20.432, tt:1307.637\n",
      "Ep:64, loss:0.00002, loss_test:0.07187, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:20.403, tt:1326.165\n",
      "Ep:65, loss:0.00002, loss_test:0.08452, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:20.408, tt:1346.952\n",
      "Ep:66, loss:0.00001, loss_test:0.07728, lr:9.90e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.421, tt:1368.199\n",
      "Ep:67, loss:0.00001, loss_test:0.07599, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.415, tt:1388.187\n",
      "Ep:68, loss:0.00001, loss_test:0.07837, lr:9.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:20.431, tt:1409.733\n",
      "Ep:69, loss:0.00001, loss_test:0.07541, lr:9.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:20.411, tt:1428.784\n",
      "Ep:70, loss:0.00001, loss_test:0.07871, lr:9.51e-03, fs:0.77844 (r=0.657,p=0.956),  time:20.417, tt:1449.641\n",
      "Ep:71, loss:0.00001, loss_test:0.07439, lr:9.41e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.422, tt:1470.350\n",
      "Ep:72, loss:0.00001, loss_test:0.07950, lr:9.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.413, tt:1490.115\n",
      "Ep:73, loss:0.00001, loss_test:0.07948, lr:9.23e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.438, tt:1512.375\n",
      "Ep:74, loss:0.00001, loss_test:0.07459, lr:9.14e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.454, tt:1534.038\n",
      "Ep:75, loss:0.00001, loss_test:0.08094, lr:9.04e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.472, tt:1555.891\n",
      "Ep:76, loss:0.00001, loss_test:0.07513, lr:8.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.470, tt:1576.175\n",
      "Ep:77, loss:0.00001, loss_test:0.07920, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.459, tt:1595.813\n",
      "Ep:78, loss:0.00001, loss_test:0.07993, lr:8.78e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.500, tt:1619.481\n",
      "Ep:79, loss:0.00001, loss_test:0.07637, lr:8.69e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.490, tt:1639.233\n",
      "Ep:80, loss:0.00001, loss_test:0.08050, lr:8.60e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.473, tt:1658.314\n",
      "Ep:81, loss:0.00001, loss_test:0.07782, lr:8.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.472, tt:1678.734\n",
      "Ep:82, loss:0.00001, loss_test:0.08189, lr:8.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.483, tt:1700.054\n",
      "Ep:83, loss:0.00001, loss_test:0.07668, lr:8.35e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.498, tt:1721.860\n",
      "Ep:84, loss:0.00001, loss_test:0.07970, lr:8.26e-03, fs:0.75152 (r=0.626,p=0.939),  time:20.514, tt:1743.682\n",
      "Ep:85, loss:0.00001, loss_test:0.08219, lr:8.18e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.507, tt:1763.608\n",
      "Ep:86, loss:0.00001, loss_test:0.08198, lr:8.10e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.507, tt:1784.108\n",
      "Ep:87, loss:0.00000, loss_test:0.08231, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.494, tt:1803.507\n",
      "Ep:88, loss:0.00000, loss_test:0.08251, lr:7.94e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.517, tt:1825.968\n",
      "Ep:89, loss:0.00000, loss_test:0.08138, lr:7.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.508, tt:1845.706\n",
      "Ep:90, loss:0.00000, loss_test:0.08356, lr:7.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.498, tt:1865.349\n",
      "Ep:91, loss:0.00000, loss_test:0.08238, lr:7.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.495, tt:1885.537\n",
      "Ep:92, loss:0.00000, loss_test:0.08241, lr:7.62e-03, fs:0.75449 (r=0.636,p=0.926),  time:20.478, tt:1904.486\n",
      "Ep:93, loss:0.00000, loss_test:0.08294, lr:7.55e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.479, tt:1925.065\n",
      "Ep:94, loss:0.00000, loss_test:0.08587, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.482, tt:1945.756\n",
      "Ep:95, loss:0.00000, loss_test:0.08373, lr:7.40e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.462, tt:1964.312\n",
      "Ep:96, loss:0.00000, loss_test:0.08213, lr:7.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:20.449, tt:1983.584\n",
      "Ep:97, loss:0.00000, loss_test:0.08627, lr:7.25e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.442, tt:2003.361\n",
      "Ep:98, loss:0.00000, loss_test:0.08244, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.427, tt:2022.242\n",
      "Ep:99, loss:0.00000, loss_test:0.08606, lr:7.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.442, tt:2044.164\n",
      "Ep:100, loss:0.00000, loss_test:0.08381, lr:7.03e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.429, tt:2063.323\n",
      "Ep:101, loss:0.00000, loss_test:0.08614, lr:6.96e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.431, tt:2083.926\n",
      "Ep:102, loss:0.00000, loss_test:0.08293, lr:6.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:20.420, tt:2103.279\n",
      "Ep:103, loss:0.00000, loss_test:0.08636, lr:6.83e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.396, tt:2121.144\n",
      "Ep:104, loss:0.00000, loss_test:0.08391, lr:6.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.410, tt:2143.100\n",
      "Ep:105, loss:0.00000, loss_test:0.08569, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.415, tt:2163.995\n",
      "Ep:106, loss:0.00000, loss_test:0.08389, lr:6.62e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.414, tt:2184.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:107, loss:0.00000, loss_test:0.08545, lr:6.56e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.422, tt:2205.549\n",
      "Ep:108, loss:0.00000, loss_test:0.08382, lr:6.49e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.420, tt:2225.833\n",
      "Ep:109, loss:0.00000, loss_test:0.08571, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.433, tt:2247.634\n",
      "Ep:110, loss:0.00000, loss_test:0.08349, lr:6.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.436, tt:2268.424\n",
      "Ep:111, loss:0.00000, loss_test:0.08521, lr:6.30e-03, fs:0.80460 (r=0.707,p=0.933),  time:20.438, tt:2289.009\n",
      "Ep:112, loss:0.00000, loss_test:0.08548, lr:6.24e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.454, tt:2311.306\n",
      "Ep:113, loss:0.00000, loss_test:0.08412, lr:6.17e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.441, tt:2330.281\n",
      "Ep:114, loss:0.00000, loss_test:0.08440, lr:6.11e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.445, tt:2351.127\n",
      "Ep:115, loss:0.00000, loss_test:0.08446, lr:6.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.448, tt:2371.947\n",
      "Ep:116, loss:0.00000, loss_test:0.08458, lr:5.99e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.437, tt:2391.165\n",
      "Ep:117, loss:0.00000, loss_test:0.08457, lr:5.93e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.451, tt:2413.195\n",
      "Ep:118, loss:0.00000, loss_test:0.08505, lr:5.87e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.440, tt:2432.378\n",
      "Ep:119, loss:0.00000, loss_test:0.08463, lr:5.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.426, tt:2451.068\n",
      "Ep:120, loss:0.00000, loss_test:0.08415, lr:5.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.439, tt:2473.150\n",
      "Ep:121, loss:0.00000, loss_test:0.08413, lr:5.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.435, tt:2493.066\n",
      "Ep:122, loss:0.00000, loss_test:0.08552, lr:5.64e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.474, tt:2518.328\n",
      "Ep:123, loss:0.00000, loss_test:0.08439, lr:5.58e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.469, tt:2538.102\n",
      "Ep:124, loss:0.00000, loss_test:0.08567, lr:5.53e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.454, tt:2556.761\n",
      "Ep:125, loss:0.00000, loss_test:0.08482, lr:5.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.470, tt:2579.268\n",
      "Ep:126, loss:0.00000, loss_test:0.08498, lr:5.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.472, tt:2599.897\n",
      "Ep:127, loss:0.00000, loss_test:0.08485, lr:5.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.464, tt:2619.450\n",
      "Ep:128, loss:0.00000, loss_test:0.08624, lr:5.31e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.466, tt:2640.121\n",
      "Ep:129, loss:0.00000, loss_test:0.08447, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.470, tt:2661.050\n",
      "Ep:130, loss:0.00000, loss_test:0.08556, lr:5.20e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.490, tt:2684.196\n",
      "Ep:131, loss:0.00000, loss_test:0.08631, lr:5.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.491, tt:2704.788\n",
      "Ep:132, loss:0.00000, loss_test:0.08464, lr:5.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.501, tt:2726.616\n",
      "Ep:133, loss:0.00000, loss_test:0.08501, lr:5.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.492, tt:2745.863\n",
      "Ep:134, loss:0.00000, loss_test:0.08523, lr:5.00e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.482, tt:2765.058\n",
      "Ep:135, loss:0.00000, loss_test:0.08505, lr:4.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.494, tt:2787.160\n",
      "Ep:136, loss:0.00000, loss_test:0.08455, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.495, tt:2807.873\n",
      "Ep:137, loss:0.00000, loss_test:0.08618, lr:4.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.489, tt:2827.471\n",
      "Ep:138, loss:0.00000, loss_test:0.08569, lr:4.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.510, tt:2850.850\n",
      "Ep:139, loss:0.00000, loss_test:0.08621, lr:4.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.520, tt:2872.862\n",
      "Ep:140, loss:0.00000, loss_test:0.08499, lr:4.71e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.547, tt:2897.161\n",
      "Ep:141, loss:0.00000, loss_test:0.08638, lr:4.66e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.548, tt:2917.774\n",
      "Ep:142, loss:0.00000, loss_test:0.08536, lr:4.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.547, tt:2938.185\n",
      "Ep:143, loss:0.00000, loss_test:0.08601, lr:4.57e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.550, tt:2959.175\n",
      "Ep:144, loss:0.00000, loss_test:0.08599, lr:4.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.553, tt:2980.128\n",
      "Ep:145, loss:0.00000, loss_test:0.08531, lr:4.48e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.546, tt:2999.688\n",
      "Ep:146, loss:0.00000, loss_test:0.08583, lr:4.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.543, tt:3019.890\n",
      "Ep:147, loss:0.00000, loss_test:0.08570, lr:4.39e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.542, tt:3040.262\n",
      "Ep:148, loss:0.00000, loss_test:0.08508, lr:4.34e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.559, tt:3063.280\n",
      "Ep:149, loss:0.00000, loss_test:0.08537, lr:4.30e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.552, tt:3082.775\n",
      "Ep:150, loss:0.00000, loss_test:0.08687, lr:4.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.553, tt:3103.505\n",
      "Ep:151, loss:0.00000, loss_test:0.08528, lr:4.21e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.545, tt:3122.846\n",
      "Ep:152, loss:0.00000, loss_test:0.08569, lr:4.17e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.531, tt:3141.280\n",
      "Ep:153, loss:0.00000, loss_test:0.08655, lr:4.13e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.542, tt:3163.414\n",
      "Ep:154, loss:0.00000, loss_test:0.08583, lr:4.09e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.530, tt:3182.092\n",
      "Ep:155, loss:0.00000, loss_test:0.08559, lr:4.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.522, tt:3201.364\n",
      "Ep:156, loss:0.00000, loss_test:0.08508, lr:4.01e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.537, tt:3224.287\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14521, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.779, tt:37.779\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14429, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.068, tt:76.135\n",
      "Ep:2, loss:0.00028, loss_test:0.14265, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.150, tt:114.449\n",
      "Ep:3, loss:0.00027, loss_test:0.13997, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.113, tt:156.452\n",
      "Ep:4, loss:0.00027, loss_test:0.13553, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:39.662, tt:198.311\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12811, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:40.228, tt:241.366\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11745, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:40.290, tt:282.030\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11194, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:40.193, tt:321.541\n",
      "Ep:8, loss:0.00022, loss_test:0.11217, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:40.510, tt:364.592\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11136, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:40.716, tt:407.157\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10979, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:40.857, tt:449.430\n",
      "Ep:11, loss:0.00020, loss_test:0.10844, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:40.821, tt:489.852\n",
      "Ep:12, loss:0.00020, loss_test:0.10897, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:40.793, tt:530.309\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10907, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:40.799, tt:571.180\n",
      "Ep:14, loss:0.00019, loss_test:0.10801, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:40.843, tt:612.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00018, loss_test:0.10773, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:40.897, tt:654.358\n",
      "Ep:16, loss:0.00018, loss_test:0.10867, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:40.893, tt:695.173\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10897, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:40.925, tt:736.648\n",
      "Ep:18, loss:0.00017, loss_test:0.10892, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:40.909, tt:777.271\n",
      "Ep:19, loss:0.00017, loss_test:0.10913, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:41.048, tt:820.967\n",
      "Ep:20, loss:0.00016, loss_test:0.10923, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:40.989, tt:860.780\n",
      "Ep:21, loss:0.00016, loss_test:0.10961, lr:1.00e-02, fs:0.65946 (r=0.616,p=0.709),  time:40.967, tt:901.267\n",
      "Ep:22, loss:0.00015, loss_test:0.10914, lr:1.00e-02, fs:0.65946 (r=0.616,p=0.709),  time:40.983, tt:942.603\n",
      "Ep:23, loss:0.00015, loss_test:0.10917, lr:1.00e-02, fs:0.67033 (r=0.616,p=0.735),  time:40.928, tt:982.278\n",
      "Ep:24, loss:0.00015, loss_test:0.10958, lr:1.00e-02, fs:0.67033 (r=0.616,p=0.735),  time:41.033, tt:1025.818\n",
      "Ep:25, loss:0.00014, loss_test:0.10995, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:41.066, tt:1067.723\n",
      "Ep:26, loss:0.00014, loss_test:0.11055, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:41.069, tt:1108.868\n",
      "Ep:27, loss:0.00014, loss_test:0.11049, lr:1.00e-02, fs:0.67403 (r=0.616,p=0.744),  time:41.080, tt:1150.244\n",
      "Ep:28, loss:0.00014, loss_test:0.11190, lr:9.90e-03, fs:0.67778 (r=0.616,p=0.753),  time:41.013, tt:1189.387\n",
      "Ep:29, loss:0.00013, loss_test:0.11174, lr:9.80e-03, fs:0.67403 (r=0.616,p=0.744),  time:40.991, tt:1229.735\n",
      "Ep:30, loss:0.00013, loss_test:0.11167, lr:9.70e-03, fs:0.67033 (r=0.616,p=0.735),  time:40.970, tt:1270.055\n",
      "Ep:31, loss:0.00013, loss_test:0.11388, lr:9.61e-03, fs:0.68182 (r=0.606,p=0.779),  time:40.971, tt:1311.070\n",
      "Ep:32, loss:0.00012, loss_test:0.11340, lr:9.51e-03, fs:0.66667 (r=0.606,p=0.741),  time:40.975, tt:1352.161\n",
      "Ep:33, loss:0.00012, loss_test:0.11413, lr:9.41e-03, fs:0.67416 (r=0.606,p=0.759),  time:40.948, tt:1392.218\n",
      "Ep:34, loss:0.00012, loss_test:0.11501, lr:9.32e-03, fs:0.68182 (r=0.606,p=0.779),  time:41.006, tt:1435.222\n",
      "Ep:35, loss:0.00012, loss_test:0.11361, lr:9.23e-03, fs:0.67416 (r=0.606,p=0.759),  time:40.991, tt:1475.664\n",
      "Ep:36, loss:0.00011, loss_test:0.11723, lr:9.14e-03, fs:0.67442 (r=0.586,p=0.795),  time:40.982, tt:1516.326\n",
      "Ep:37, loss:0.00011, loss_test:0.11328, lr:9.04e-03, fs:0.66667 (r=0.596,p=0.756),  time:40.975, tt:1557.049\n",
      "Ep:38, loss:0.00011, loss_test:0.11650, lr:8.95e-03, fs:0.67052 (r=0.586,p=0.784),  time:40.975, tt:1598.023\n",
      "Ep:39, loss:0.00011, loss_test:0.11751, lr:8.86e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.999, tt:1639.942\n",
      "Ep:40, loss:0.00011, loss_test:0.11396, lr:8.78e-03, fs:0.67045 (r=0.596,p=0.766),  time:40.977, tt:1680.050\n",
      "Ep:41, loss:0.00010, loss_test:0.11892, lr:8.69e-03, fs:0.66272 (r=0.566,p=0.800),  time:40.964, tt:1720.501\n",
      "Ep:42, loss:0.00010, loss_test:0.11540, lr:8.60e-03, fs:0.65909 (r=0.586,p=0.753),  time:40.941, tt:1760.484\n",
      "Ep:43, loss:0.00010, loss_test:0.11822, lr:8.51e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.882, tt:1798.823\n",
      "Ep:44, loss:0.00010, loss_test:0.11636, lr:8.43e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.890, tt:1840.034\n",
      "Ep:45, loss:0.00010, loss_test:0.11828, lr:8.35e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.912, tt:1881.929\n",
      "Ep:46, loss:0.00009, loss_test:0.11902, lr:8.26e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.877, tt:1921.208\n",
      "Ep:47, loss:0.00009, loss_test:0.11556, lr:8.18e-03, fs:0.65497 (r=0.566,p=0.778),  time:40.874, tt:1961.963\n",
      "Ep:48, loss:0.00009, loss_test:0.11974, lr:8.10e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.913, tt:2004.731\n",
      "Ep:49, loss:0.00009, loss_test:0.11831, lr:8.02e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.943, tt:2047.170\n",
      "Ep:50, loss:0.00009, loss_test:0.11719, lr:7.94e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.961, tt:2089.033\n",
      "Ep:51, loss:0.00009, loss_test:0.11892, lr:7.86e-03, fs:0.66272 (r=0.566,p=0.800),  time:40.959, tt:2129.890\n",
      "Ep:52, loss:0.00008, loss_test:0.11747, lr:7.78e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.945, tt:2170.074\n",
      "Ep:53, loss:0.00008, loss_test:0.12008, lr:7.70e-03, fs:0.66272 (r=0.566,p=0.800),  time:40.984, tt:2213.122\n",
      "Ep:54, loss:0.00008, loss_test:0.11936, lr:7.62e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.978, tt:2253.765\n",
      "Ep:55, loss:0.00008, loss_test:0.11835, lr:7.55e-03, fs:0.65882 (r=0.566,p=0.789),  time:40.948, tt:2293.068\n",
      "Ep:56, loss:0.00008, loss_test:0.12096, lr:7.47e-03, fs:0.67470 (r=0.566,p=0.836),  time:40.952, tt:2334.253\n",
      "Ep:57, loss:0.00008, loss_test:0.11783, lr:7.40e-03, fs:0.66279 (r=0.576,p=0.781),  time:40.949, tt:2375.021\n",
      "Ep:58, loss:0.00008, loss_test:0.12076, lr:7.32e-03, fs:0.67470 (r=0.566,p=0.836),  time:40.930, tt:2414.893\n",
      "Ep:59, loss:0.00008, loss_test:0.11970, lr:7.25e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.957, tt:2457.425\n",
      "Ep:60, loss:0.00008, loss_test:0.11911, lr:7.18e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.940, tt:2497.313\n",
      "Ep:61, loss:0.00007, loss_test:0.12603, lr:7.11e-03, fs:0.67470 (r=0.566,p=0.836),  time:40.943, tt:2538.458\n",
      "Ep:62, loss:0.00007, loss_test:0.11869, lr:7.03e-03, fs:0.67059 (r=0.576,p=0.803),  time:40.953, tt:2580.042\n",
      "Ep:63, loss:0.00007, loss_test:0.12222, lr:6.96e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.969, tt:2622.037\n",
      "Ep:64, loss:0.00007, loss_test:0.12379, lr:6.89e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.967, tt:2662.825\n",
      "Ep:65, loss:0.00007, loss_test:0.11772, lr:6.83e-03, fs:0.67059 (r=0.576,p=0.803),  time:40.957, tt:2703.152\n",
      "Ep:66, loss:0.00007, loss_test:0.12275, lr:6.76e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.923, tt:2741.846\n",
      "Ep:67, loss:0.00007, loss_test:0.12268, lr:6.69e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.937, tt:2783.685\n",
      "Ep:68, loss:0.00007, loss_test:0.11893, lr:6.62e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.921, tt:2823.577\n",
      "Ep:69, loss:0.00007, loss_test:0.12322, lr:6.56e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.921, tt:2864.485\n",
      "Ep:70, loss:0.00006, loss_test:0.12382, lr:6.49e-03, fs:0.66667 (r=0.566,p=0.812),  time:40.969, tt:2908.776\n",
      "Ep:71, loss:0.00006, loss_test:0.11784, lr:6.43e-03, fs:0.67059 (r=0.576,p=0.803),  time:40.968, tt:2949.710\n",
      "Ep:72, loss:0.00006, loss_test:0.12770, lr:6.36e-03, fs:0.66258 (r=0.545,p=0.844),  time:40.972, tt:2990.927\n",
      "Ep:73, loss:0.00006, loss_test:0.11934, lr:6.30e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.965, tt:3031.421\n",
      "Ep:74, loss:0.00006, loss_test:0.12365, lr:6.24e-03, fs:0.67066 (r=0.566,p=0.824),  time:40.946, tt:3070.953\n",
      "Ep:75, loss:0.00006, loss_test:0.12593, lr:6.17e-03, fs:0.67066 (r=0.566,p=0.824),  time:40.951, tt:3112.269\n",
      "Ep:76, loss:0.00006, loss_test:0.12033, lr:6.11e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.939, tt:3152.323\n",
      "Ep:77, loss:0.00006, loss_test:0.12723, lr:6.05e-03, fs:0.65455 (r=0.545,p=0.818),  time:40.943, tt:3193.586\n",
      "Ep:78, loss:0.00006, loss_test:0.12461, lr:5.99e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.968, tt:3236.489\n",
      "Ep:79, loss:0.00006, loss_test:0.12254, lr:5.93e-03, fs:0.66667 (r=0.566,p=0.812),  time:41.019, tt:3281.508\n",
      "Ep:80, loss:0.00006, loss_test:0.12686, lr:5.87e-03, fs:0.67066 (r=0.566,p=0.824),  time:41.015, tt:3322.211\n",
      "Ep:81, loss:0.00006, loss_test:0.12642, lr:5.81e-03, fs:0.67857 (r=0.576,p=0.826),  time:41.037, tt:3365.015\n",
      "Ep:82, loss:0.00005, loss_test:0.12411, lr:5.75e-03, fs:0.66667 (r=0.566,p=0.812),  time:41.042, tt:3406.475\n",
      "Ep:83, loss:0.00005, loss_test:0.12596, lr:5.70e-03, fs:0.66667 (r=0.566,p=0.812),  time:41.052, tt:3448.404\n",
      "Ep:84, loss:0.00005, loss_test:0.12663, lr:5.64e-03, fs:0.66265 (r=0.556,p=0.821),  time:41.058, tt:3489.916\n",
      "Ep:85, loss:0.00005, loss_test:0.12298, lr:5.58e-03, fs:0.67456 (r=0.576,p=0.814),  time:41.060, tt:3531.136\n",
      "Ep:86, loss:0.00005, loss_test:0.12945, lr:5.53e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.054, tt:3571.695\n",
      "Ep:87, loss:0.00005, loss_test:0.12387, lr:5.47e-03, fs:0.67456 (r=0.576,p=0.814),  time:41.059, tt:3613.155\n",
      "Ep:88, loss:0.00005, loss_test:0.12712, lr:5.42e-03, fs:0.65868 (r=0.556,p=0.809),  time:41.084, tt:3656.518\n",
      "Ep:89, loss:0.00005, loss_test:0.12810, lr:5.36e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.002, tt:3690.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00005, loss_test:0.12453, lr:5.31e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.989, tt:3730.045\n",
      "Ep:91, loss:0.00005, loss_test:0.12859, lr:5.26e-03, fs:0.65455 (r=0.545,p=0.818),  time:40.949, tt:3767.314\n",
      "Ep:92, loss:0.00005, loss_test:0.12825, lr:5.20e-03, fs:0.65455 (r=0.545,p=0.818),  time:40.966, tt:3809.810\n",
      "Ep:93, loss:0.00005, loss_test:0.12484, lr:5.15e-03, fs:0.67456 (r=0.576,p=0.814),  time:40.996, tt:3853.595\n",
      "Ep:94, loss:0.00005, loss_test:0.12984, lr:5.10e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.017, tt:3896.577\n",
      "Ep:95, loss:0.00005, loss_test:0.12618, lr:5.05e-03, fs:0.67066 (r=0.566,p=0.824),  time:41.022, tt:3938.112\n",
      "Ep:96, loss:0.00005, loss_test:0.12863, lr:5.00e-03, fs:0.64634 (r=0.535,p=0.815),  time:41.053, tt:3982.121\n",
      "Ep:97, loss:0.00005, loss_test:0.12947, lr:4.95e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.045, tt:4022.372\n",
      "Ep:98, loss:0.00005, loss_test:0.12821, lr:4.90e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.053, tt:4064.241\n",
      "Ep:99, loss:0.00005, loss_test:0.12808, lr:4.85e-03, fs:0.65854 (r=0.545,p=0.831),  time:41.083, tt:4108.264\n",
      "Ep:100, loss:0.00004, loss_test:0.13073, lr:4.80e-03, fs:0.65854 (r=0.545,p=0.831),  time:41.096, tt:4150.744\n",
      "Ep:101, loss:0.00004, loss_test:0.12778, lr:4.75e-03, fs:0.65455 (r=0.545,p=0.818),  time:41.104, tt:4192.581\n",
      "Ep:102, loss:0.00004, loss_test:0.12673, lr:4.71e-03, fs:0.66265 (r=0.556,p=0.821),  time:41.117, tt:4235.056\n",
      "Ep:103, loss:0.00004, loss_test:0.13174, lr:4.66e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.129, tt:4277.435\n",
      "Ep:104, loss:0.00004, loss_test:0.12805, lr:4.61e-03, fs:0.67066 (r=0.566,p=0.824),  time:41.143, tt:4319.966\n",
      "Ep:105, loss:0.00004, loss_test:0.12915, lr:4.57e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.172, tt:4364.229\n",
      "Ep:106, loss:0.00004, loss_test:0.13116, lr:4.52e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.174, tt:4405.618\n",
      "Ep:107, loss:0.00004, loss_test:0.12888, lr:4.48e-03, fs:0.66258 (r=0.545,p=0.844),  time:41.188, tt:4448.269\n",
      "Ep:108, loss:0.00004, loss_test:0.12974, lr:4.43e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.196, tt:4490.317\n",
      "Ep:109, loss:0.00004, loss_test:0.13064, lr:4.39e-03, fs:0.65432 (r=0.535,p=0.841),  time:41.195, tt:4531.462\n",
      "Ep:110, loss:0.00004, loss_test:0.13123, lr:4.34e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.214, tt:4574.710\n",
      "Ep:111, loss:0.00004, loss_test:0.12811, lr:4.30e-03, fs:0.66667 (r=0.556,p=0.833),  time:41.239, tt:4618.758\n",
      "Ep:112, loss:0.00004, loss_test:0.13031, lr:4.26e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.247, tt:4660.899\n",
      "Ep:113, loss:0.00004, loss_test:0.13131, lr:4.21e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.305, tt:4708.795\n",
      "Ep:114, loss:0.00004, loss_test:0.12991, lr:4.17e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.317, tt:4751.497\n",
      "Ep:115, loss:0.00004, loss_test:0.12987, lr:4.13e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.350, tt:4796.655\n",
      "Ep:116, loss:0.00004, loss_test:0.13185, lr:4.09e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.360, tt:4839.090\n",
      "Ep:117, loss:0.00004, loss_test:0.12963, lr:4.05e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.369, tt:4881.597\n",
      "Ep:118, loss:0.00004, loss_test:0.12916, lr:4.01e-03, fs:0.64596 (r=0.525,p=0.839),  time:41.377, tt:4923.872\n",
      "Ep:119, loss:0.00004, loss_test:0.13127, lr:3.97e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.396, tt:4967.566\n",
      "Ep:120, loss:0.00004, loss_test:0.12967, lr:3.93e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.413, tt:5010.953\n",
      "Ep:121, loss:0.00004, loss_test:0.13057, lr:3.89e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.420, tt:5053.201\n",
      "Ep:122, loss:0.00004, loss_test:0.13195, lr:3.85e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.435, tt:5096.521\n",
      "Ep:123, loss:0.00004, loss_test:0.13113, lr:3.81e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.455, tt:5140.361\n",
      "Ep:124, loss:0.00004, loss_test:0.13082, lr:3.77e-03, fs:0.65000 (r=0.525,p=0.852),  time:41.467, tt:5183.353\n",
      "Ep:125, loss:0.00004, loss_test:0.13201, lr:3.73e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.470, tt:5225.187\n",
      "Ep:126, loss:0.00004, loss_test:0.13172, lr:3.70e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.475, tt:5267.314\n",
      "Ep:127, loss:0.00003, loss_test:0.13032, lr:3.66e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.485, tt:5310.069\n",
      "Ep:128, loss:0.00003, loss_test:0.13163, lr:3.62e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.488, tt:5351.944\n",
      "Ep:129, loss:0.00003, loss_test:0.13254, lr:3.59e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.504, tt:5395.482\n",
      "Ep:130, loss:0.00003, loss_test:0.13183, lr:3.55e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.507, tt:5437.357\n",
      "Ep:131, loss:0.00003, loss_test:0.13147, lr:3.52e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.509, tt:5479.168\n",
      "Ep:132, loss:0.00003, loss_test:0.13267, lr:3.48e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.517, tt:5521.740\n",
      "Ep:133, loss:0.00003, loss_test:0.13174, lr:3.45e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.528, tt:5564.727\n",
      "Ep:134, loss:0.00003, loss_test:0.13149, lr:3.41e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.526, tt:5605.964\n",
      "Ep:135, loss:0.00003, loss_test:0.13523, lr:3.38e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.537, tt:5649.034\n",
      "Ep:136, loss:0.00003, loss_test:0.13167, lr:3.34e-03, fs:0.65409 (r=0.525,p=0.867),  time:41.548, tt:5692.100\n",
      "Ep:137, loss:0.00003, loss_test:0.13138, lr:3.31e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.571, tt:5736.860\n",
      "Ep:138, loss:0.00003, loss_test:0.13424, lr:3.28e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.578, tt:5779.411\n",
      "Ep:139, loss:0.00003, loss_test:0.13364, lr:3.24e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.592, tt:5822.939\n",
      "Ep:140, loss:0.00003, loss_test:0.13129, lr:3.21e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.603, tt:5865.995\n",
      "Ep:141, loss:0.00003, loss_test:0.13323, lr:3.18e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.616, tt:5909.534\n",
      "Ep:142, loss:0.00003, loss_test:0.13534, lr:3.15e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.619, tt:5951.519\n",
      "Ep:143, loss:0.00003, loss_test:0.13273, lr:3.12e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.621, tt:5993.471\n",
      "Ep:144, loss:0.00003, loss_test:0.13354, lr:3.09e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.631, tt:6036.485\n",
      "Ep:145, loss:0.00003, loss_test:0.13507, lr:3.05e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.645, tt:6080.197\n",
      "Ep:146, loss:0.00003, loss_test:0.13286, lr:3.02e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.648, tt:6122.312\n",
      "Ep:147, loss:0.00003, loss_test:0.13375, lr:2.99e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.653, tt:6164.654\n",
      "Ep:148, loss:0.00003, loss_test:0.13519, lr:2.96e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.660, tt:6207.338\n",
      "Ep:149, loss:0.00003, loss_test:0.13379, lr:2.93e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.672, tt:6250.862\n",
      "Ep:150, loss:0.00003, loss_test:0.13373, lr:2.90e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.693, tt:6295.593\n",
      "Ep:151, loss:0.00003, loss_test:0.13553, lr:2.88e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.693, tt:6337.408\n",
      "Ep:152, loss:0.00003, loss_test:0.13462, lr:2.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.694, tt:6379.151\n",
      "Ep:153, loss:0.00003, loss_test:0.13335, lr:2.82e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.686, tt:6419.591\n",
      "Ep:154, loss:0.00003, loss_test:0.13517, lr:2.79e-03, fs:0.64557 (r=0.515,p=0.864),  time:41.687, tt:6461.496\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14426, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.590, tt:16.590\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14377, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.850, tt:33.699\n",
      "Ep:2, loss:0.00028, loss_test:0.14296, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.001, tt:51.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00028, loss_test:0.14172, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.622, tt:66.490\n",
      "Ep:4, loss:0.00028, loss_test:0.13978, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:16.348, tt:81.742\n",
      "Ep:5, loss:0.00027, loss_test:0.13684, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:16.154, tt:96.926\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.13230, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:16.233, tt:113.630\n",
      "Ep:7, loss:0.00025, loss_test:0.12594, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:16.277, tt:130.214\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.12074, lr:1.00e-02, fs:0.64865 (r=0.727,p=0.585),  time:16.361, tt:147.247\n",
      "Ep:9, loss:0.00023, loss_test:0.11900, lr:1.00e-02, fs:0.62376 (r=0.636,p=0.612),  time:16.506, tt:165.065\n",
      "Ep:10, loss:0.00022, loss_test:0.11633, lr:1.00e-02, fs:0.64486 (r=0.697,p=0.600),  time:16.716, tt:183.873\n",
      "Ep:11, loss:0.00022, loss_test:0.11581, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:16.760, tt:201.123\n",
      "Ep:12, loss:0.00022, loss_test:0.11233, lr:1.00e-02, fs:0.63158 (r=0.667,p=0.600),  time:16.831, tt:218.805\n",
      "Ep:13, loss:0.00021, loss_test:0.11028, lr:1.00e-02, fs:0.63212 (r=0.616,p=0.649),  time:16.773, tt:234.821\n",
      "Ep:14, loss:0.00020, loss_test:0.10809, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:16.764, tt:251.455\n",
      "Ep:15, loss:0.00019, loss_test:0.10600, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:16.789, tt:268.626\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10275, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:16.866, tt:286.723\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10001, lr:1.00e-02, fs:0.67760 (r=0.626,p=0.738),  time:16.986, tt:305.741\n",
      "Ep:18, loss:0.00018, loss_test:0.09911, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:16.956, tt:322.157\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09756, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:16.920, tt:338.403\n",
      "Ep:20, loss:0.00017, loss_test:0.09632, lr:1.00e-02, fs:0.71823 (r=0.657,p=0.793),  time:16.926, tt:355.453\n",
      "Ep:21, loss:0.00016, loss_test:0.09537, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:16.919, tt:372.216\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09400, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:16.958, tt:390.030\n",
      "Ep:23, loss:0.00015, loss_test:0.09234, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:16.837, tt:404.080\n",
      "Ep:24, loss:0.00015, loss_test:0.09215, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:16.753, tt:418.820\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09143, lr:1.00e-02, fs:0.71591 (r=0.636,p=0.818),  time:16.774, tt:436.120\n",
      "Ep:26, loss:0.00014, loss_test:0.09014, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:16.798, tt:453.554\n",
      "Ep:27, loss:0.00014, loss_test:0.08952, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.688, tt:467.278\n",
      "Ep:28, loss:0.00013, loss_test:0.08890, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:16.638, tt:482.489\n",
      "Ep:29, loss:0.00013, loss_test:0.08850, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:16.595, tt:497.837\n",
      "Ep:30, loss:0.00013, loss_test:0.08765, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.616, tt:515.082\n",
      "Ep:31, loss:0.00012, loss_test:0.08754, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.671, tt:533.463\n",
      "Ep:32, loss:0.00012, loss_test:0.08699, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:16.735, tt:552.261\n",
      "Ep:33, loss:0.00012, loss_test:0.08624, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:16.782, tt:570.580\n",
      "Ep:34, loss:0.00011, loss_test:0.08602, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:16.838, tt:589.333\n",
      "Ep:35, loss:0.00011, loss_test:0.08496, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:16.844, tt:606.384\n",
      "Ep:36, loss:0.00011, loss_test:0.08558, lr:9.90e-03, fs:0.73626 (r=0.677,p=0.807),  time:16.874, tt:624.326\n",
      "Ep:37, loss:0.00010, loss_test:0.08495, lr:9.80e-03, fs:0.75000 (r=0.697,p=0.812),  time:16.880, tt:641.441\n",
      "Ep:38, loss:0.00010, loss_test:0.08447, lr:9.70e-03, fs:0.75138 (r=0.687,p=0.829),  time:16.884, tt:658.492\n",
      "Ep:39, loss:0.00010, loss_test:0.08455, lr:9.61e-03, fs:0.75281 (r=0.677,p=0.848),  time:16.895, tt:675.791\n",
      "Ep:40, loss:0.00010, loss_test:0.08444, lr:9.51e-03, fs:0.72414 (r=0.636,p=0.840),  time:16.903, tt:693.012\n",
      "Ep:41, loss:0.00010, loss_test:0.08408, lr:9.41e-03, fs:0.73864 (r=0.657,p=0.844),  time:16.890, tt:709.379\n",
      "Ep:42, loss:0.00009, loss_test:0.08455, lr:9.32e-03, fs:0.71006 (r=0.606,p=0.857),  time:16.920, tt:727.558\n",
      "Ep:43, loss:0.00009, loss_test:0.08384, lr:9.23e-03, fs:0.72093 (r=0.626,p=0.849),  time:16.938, tt:745.269\n",
      "Ep:44, loss:0.00009, loss_test:0.08465, lr:9.14e-03, fs:0.71951 (r=0.596,p=0.908),  time:16.959, tt:763.159\n",
      "Ep:45, loss:0.00009, loss_test:0.08327, lr:9.04e-03, fs:0.72414 (r=0.636,p=0.840),  time:16.948, tt:779.620\n",
      "Ep:46, loss:0.00008, loss_test:0.08373, lr:8.95e-03, fs:0.71084 (r=0.596,p=0.881),  time:16.957, tt:796.960\n",
      "Ep:47, loss:0.00008, loss_test:0.08310, lr:8.86e-03, fs:0.71429 (r=0.606,p=0.870),  time:16.972, tt:814.641\n",
      "Ep:48, loss:0.00008, loss_test:0.08310, lr:8.78e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.007, tt:833.320\n",
      "Ep:49, loss:0.00008, loss_test:0.08309, lr:8.69e-03, fs:0.70303 (r=0.586,p=0.879),  time:17.018, tt:850.914\n",
      "Ep:50, loss:0.00008, loss_test:0.08242, lr:8.60e-03, fs:0.70238 (r=0.596,p=0.855),  time:17.010, tt:867.521\n",
      "Ep:51, loss:0.00008, loss_test:0.08310, lr:8.51e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.007, tt:884.384\n",
      "Ep:52, loss:0.00007, loss_test:0.08294, lr:8.43e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.015, tt:901.812\n",
      "Ep:53, loss:0.00007, loss_test:0.08347, lr:8.35e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.033, tt:919.763\n",
      "Ep:54, loss:0.00007, loss_test:0.08282, lr:8.26e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.054, tt:937.976\n",
      "Ep:55, loss:0.00007, loss_test:0.08263, lr:8.18e-03, fs:0.69880 (r=0.586,p=0.866),  time:17.054, tt:954.999\n",
      "Ep:56, loss:0.00007, loss_test:0.08305, lr:8.10e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.027, tt:970.567\n",
      "Ep:57, loss:0.00007, loss_test:0.08239, lr:8.02e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.026, tt:987.486\n",
      "Ep:58, loss:0.00007, loss_test:0.08306, lr:7.94e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.028, tt:1004.641\n",
      "Ep:59, loss:0.00006, loss_test:0.08250, lr:7.86e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.074, tt:1024.448\n",
      "Ep:60, loss:0.00006, loss_test:0.08392, lr:7.78e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.084, tt:1042.097\n",
      "Ep:61, loss:0.00006, loss_test:0.08215, lr:7.70e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.064, tt:1057.987\n",
      "Ep:62, loss:0.00006, loss_test:0.08317, lr:7.62e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.059, tt:1074.745\n",
      "Ep:63, loss:0.00006, loss_test:0.08316, lr:7.55e-03, fs:0.68712 (r=0.566,p=0.875),  time:17.037, tt:1090.366\n",
      "Ep:64, loss:0.00006, loss_test:0.08262, lr:7.47e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.050, tt:1108.262\n",
      "Ep:65, loss:0.00006, loss_test:0.08388, lr:7.40e-03, fs:0.70000 (r=0.566,p=0.918),  time:17.074, tt:1126.898\n",
      "Ep:66, loss:0.00006, loss_test:0.08225, lr:7.32e-03, fs:0.69512 (r=0.576,p=0.877),  time:17.065, tt:1143.329\n",
      "Ep:67, loss:0.00006, loss_test:0.08263, lr:7.25e-03, fs:0.70370 (r=0.576,p=0.905),  time:17.071, tt:1160.812\n",
      "Ep:68, loss:0.00005, loss_test:0.08204, lr:7.18e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.066, tt:1177.523\n",
      "Ep:69, loss:0.00005, loss_test:0.08308, lr:7.11e-03, fs:0.70000 (r=0.566,p=0.918),  time:17.075, tt:1195.273\n",
      "Ep:70, loss:0.00005, loss_test:0.08203, lr:7.03e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.107, tt:1214.628\n",
      "Ep:71, loss:0.00005, loss_test:0.08171, lr:6.96e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.114, tt:1232.243\n",
      "Ep:72, loss:0.00005, loss_test:0.08318, lr:6.89e-03, fs:0.69136 (r=0.566,p=0.889),  time:17.117, tt:1249.536\n",
      "Ep:73, loss:0.00005, loss_test:0.08153, lr:6.83e-03, fs:0.69939 (r=0.576,p=0.891),  time:17.107, tt:1265.887\n",
      "Ep:74, loss:0.00005, loss_test:0.08209, lr:6.76e-03, fs:0.69136 (r=0.566,p=0.889),  time:17.097, tt:1282.311\n",
      "Ep:75, loss:0.00005, loss_test:0.08271, lr:6.69e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.099, tt:1299.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00005, loss_test:0.08175, lr:6.62e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.103, tt:1316.925\n",
      "Ep:77, loss:0.00005, loss_test:0.08236, lr:6.56e-03, fs:0.69565 (r=0.566,p=0.903),  time:17.109, tt:1334.539\n",
      "Ep:78, loss:0.00005, loss_test:0.08308, lr:6.49e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.122, tt:1352.629\n",
      "Ep:79, loss:0.00004, loss_test:0.08123, lr:6.43e-03, fs:0.71515 (r=0.596,p=0.894),  time:17.117, tt:1369.336\n",
      "Ep:80, loss:0.00004, loss_test:0.08419, lr:6.36e-03, fs:0.70000 (r=0.566,p=0.918),  time:17.116, tt:1386.399\n",
      "Ep:81, loss:0.00004, loss_test:0.08192, lr:6.30e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.116, tt:1403.550\n",
      "Ep:82, loss:0.00004, loss_test:0.08272, lr:6.24e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.116, tt:1420.614\n",
      "Ep:83, loss:0.00004, loss_test:0.08217, lr:6.17e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.113, tt:1437.453\n",
      "Ep:84, loss:0.00004, loss_test:0.08243, lr:6.11e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.112, tt:1454.542\n",
      "Ep:85, loss:0.00004, loss_test:0.08296, lr:6.05e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.123, tt:1472.587\n",
      "Ep:86, loss:0.00004, loss_test:0.08136, lr:5.99e-03, fs:0.70732 (r=0.586,p=0.892),  time:17.127, tt:1490.008\n",
      "Ep:87, loss:0.00004, loss_test:0.08368, lr:5.93e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.126, tt:1507.126\n",
      "Ep:88, loss:0.00004, loss_test:0.08233, lr:5.87e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.115, tt:1523.205\n",
      "Ep:89, loss:0.00004, loss_test:0.08251, lr:5.81e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.107, tt:1539.661\n",
      "Ep:90, loss:0.00004, loss_test:0.08305, lr:5.75e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.097, tt:1555.804\n",
      "Ep:91, loss:0.00004, loss_test:0.08257, lr:5.70e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.093, tt:1572.549\n",
      "Ep:92, loss:0.00004, loss_test:0.08266, lr:5.64e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.097, tt:1590.028\n",
      "Ep:93, loss:0.00004, loss_test:0.08266, lr:5.58e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.092, tt:1606.669\n",
      "Ep:94, loss:0.00004, loss_test:0.08205, lr:5.53e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.085, tt:1623.088\n",
      "Ep:95, loss:0.00004, loss_test:0.08304, lr:5.47e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.087, tt:1640.318\n",
      "Ep:96, loss:0.00003, loss_test:0.08367, lr:5.42e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.093, tt:1658.069\n",
      "Ep:97, loss:0.00003, loss_test:0.08144, lr:5.36e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.103, tt:1676.124\n",
      "Ep:98, loss:0.00003, loss_test:0.08377, lr:5.31e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.100, tt:1692.908\n",
      "Ep:99, loss:0.00003, loss_test:0.08194, lr:5.26e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.103, tt:1710.256\n",
      "Ep:100, loss:0.00003, loss_test:0.08241, lr:5.20e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.098, tt:1726.940\n",
      "Ep:101, loss:0.00003, loss_test:0.08290, lr:5.15e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.103, tt:1744.471\n",
      "Ep:102, loss:0.00003, loss_test:0.08193, lr:5.10e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.106, tt:1761.958\n",
      "Ep:103, loss:0.00003, loss_test:0.08309, lr:5.05e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.100, tt:1778.374\n",
      "Ep:104, loss:0.00003, loss_test:0.08290, lr:5.00e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.094, tt:1794.841\n",
      "Ep:105, loss:0.00003, loss_test:0.08171, lr:4.95e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.082, tt:1810.713\n",
      "Ep:106, loss:0.00003, loss_test:0.08332, lr:4.90e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.073, tt:1826.857\n",
      "Ep:107, loss:0.00003, loss_test:0.08146, lr:4.85e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.085, tt:1845.146\n",
      "Ep:108, loss:0.00003, loss_test:0.08288, lr:4.80e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.083, tt:1862.100\n",
      "Ep:109, loss:0.00003, loss_test:0.08338, lr:4.75e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.096, tt:1880.561\n",
      "Ep:110, loss:0.00003, loss_test:0.08061, lr:4.71e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.105, tt:1898.625\n",
      "Ep:111, loss:0.00003, loss_test:0.08446, lr:4.66e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.097, tt:1914.896\n",
      "Ep:112, loss:0.00003, loss_test:0.08310, lr:4.61e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.094, tt:1931.598\n",
      "Ep:113, loss:0.00003, loss_test:0.08089, lr:4.57e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.094, tt:1948.759\n",
      "Ep:114, loss:0.00003, loss_test:0.08395, lr:4.52e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.102, tt:1966.746\n",
      "Ep:115, loss:0.00003, loss_test:0.08181, lr:4.48e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.101, tt:1983.668\n",
      "Ep:116, loss:0.00003, loss_test:0.08173, lr:4.43e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.093, tt:1999.923\n",
      "Ep:117, loss:0.00003, loss_test:0.08294, lr:4.39e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.094, tt:2017.133\n",
      "Ep:118, loss:0.00003, loss_test:0.08250, lr:4.34e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.094, tt:2034.181\n",
      "Ep:119, loss:0.00003, loss_test:0.08165, lr:4.30e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.095, tt:2051.383\n",
      "Ep:120, loss:0.00003, loss_test:0.08302, lr:4.26e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.093, tt:2068.309\n",
      "Ep:121, loss:0.00003, loss_test:0.08162, lr:4.21e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.087, tt:2084.647\n",
      "Ep:122, loss:0.00003, loss_test:0.08239, lr:4.17e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.079, tt:2100.742\n",
      "Ep:123, loss:0.00003, loss_test:0.08176, lr:4.13e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.081, tt:2118.014\n",
      "Ep:124, loss:0.00003, loss_test:0.08248, lr:4.09e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.082, tt:2135.289\n",
      "Ep:125, loss:0.00003, loss_test:0.08198, lr:4.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.087, tt:2152.899\n",
      "Ep:126, loss:0.00003, loss_test:0.08216, lr:4.01e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.079, tt:2168.991\n",
      "Ep:127, loss:0.00002, loss_test:0.08195, lr:3.97e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.075, tt:2185.654\n",
      "Ep:128, loss:0.00002, loss_test:0.08213, lr:3.93e-03, fs:0.71166 (r=0.586,p=0.906),  time:17.086, tt:2204.153\n",
      "Ep:129, loss:0.00002, loss_test:0.08179, lr:3.89e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.087, tt:2221.368\n",
      "Ep:130, loss:0.00002, loss_test:0.08201, lr:3.85e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.085, tt:2238.099\n",
      "Ep:131, loss:0.00002, loss_test:0.08159, lr:3.81e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.079, tt:2254.427\n",
      "Ep:132, loss:0.00002, loss_test:0.08253, lr:3.77e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.069, tt:2270.174\n",
      "Ep:133, loss:0.00002, loss_test:0.08174, lr:3.73e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.077, tt:2288.293\n",
      "Ep:134, loss:0.00002, loss_test:0.08201, lr:3.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.078, tt:2305.542\n",
      "Ep:135, loss:0.00002, loss_test:0.08191, lr:3.66e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.082, tt:2323.102\n",
      "Ep:136, loss:0.00002, loss_test:0.08189, lr:3.62e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.079, tt:2339.798\n",
      "Ep:137, loss:0.00002, loss_test:0.08237, lr:3.59e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.072, tt:2355.960\n",
      "Ep:138, loss:0.00002, loss_test:0.08148, lr:3.55e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.073, tt:2373.148\n",
      "Ep:139, loss:0.00002, loss_test:0.08253, lr:3.52e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.073, tt:2390.182\n",
      "Ep:140, loss:0.00002, loss_test:0.08159, lr:3.48e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.081, tt:2408.460\n",
      "Ep:141, loss:0.00002, loss_test:0.08227, lr:3.45e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.078, tt:2425.135\n",
      "Ep:142, loss:0.00002, loss_test:0.08293, lr:3.41e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.073, tt:2441.478\n",
      "Ep:143, loss:0.00002, loss_test:0.08128, lr:3.38e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.075, tt:2458.728\n",
      "Ep:144, loss:0.00002, loss_test:0.08259, lr:3.34e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.074, tt:2475.660\n",
      "Ep:145, loss:0.00002, loss_test:0.08173, lr:3.31e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.076, tt:2493.163\n",
      "Ep:146, loss:0.00002, loss_test:0.08181, lr:3.28e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.081, tt:2510.902\n",
      "Ep:147, loss:0.00002, loss_test:0.08211, lr:3.24e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.094, tt:2529.944\n",
      "Ep:148, loss:0.00002, loss_test:0.08180, lr:3.21e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.091, tt:2546.579\n",
      "Ep:149, loss:0.00002, loss_test:0.08221, lr:3.18e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.097, tt:2564.490\n",
      "Ep:150, loss:0.00002, loss_test:0.08140, lr:3.15e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.093, tt:2581.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00002, loss_test:0.08236, lr:3.12e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.090, tt:2597.684\n",
      "Ep:152, loss:0.00002, loss_test:0.08154, lr:3.09e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.083, tt:2613.659\n",
      "Ep:153, loss:0.00002, loss_test:0.08199, lr:3.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.092, tt:2632.210\n",
      "Ep:154, loss:0.00002, loss_test:0.08204, lr:3.02e-03, fs:0.72050 (r=0.586,p=0.935),  time:17.100, tt:2650.458\n",
      "Ep:155, loss:0.00002, loss_test:0.08143, lr:2.99e-03, fs:0.71605 (r=0.586,p=0.921),  time:17.101, tt:2667.777\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14116, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:19.454, tt:19.454\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13989, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:19.982, tt:39.963\n",
      "Ep:2, loss:0.00027, loss_test:0.13810, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:19.504, tt:58.513\n",
      "Ep:3, loss:0.00026, loss_test:0.13644, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:18.975, tt:75.901\n",
      "Ep:4, loss:0.00026, loss_test:0.13544, lr:1.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:18.486, tt:92.429\n",
      "Ep:5, loss:0.00025, loss_test:0.13430, lr:1.00e-02, fs:0.62651 (r=0.788,p=0.520),  time:18.528, tt:111.168\n",
      "Ep:6, loss:0.00025, loss_test:0.13278, lr:1.00e-02, fs:0.61475 (r=0.758,p=0.517),  time:18.826, tt:131.783\n",
      "Ep:7, loss:0.00024, loss_test:0.13107, lr:1.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:19.093, tt:152.748\n",
      "Ep:8, loss:0.00024, loss_test:0.12941, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:19.242, tt:173.177\n",
      "Ep:9, loss:0.00024, loss_test:0.12769, lr:1.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:19.221, tt:192.213\n",
      "Ep:10, loss:0.00023, loss_test:0.12579, lr:1.00e-02, fs:0.62338 (r=0.727,p=0.545),  time:19.361, tt:212.966\n",
      "Ep:11, loss:0.00023, loss_test:0.12354, lr:1.00e-02, fs:0.61751 (r=0.677,p=0.568),  time:19.498, tt:233.972\n",
      "Ep:12, loss:0.00022, loss_test:0.12096, lr:9.90e-03, fs:0.62264 (r=0.667,p=0.584),  time:19.548, tt:254.128\n",
      "Ep:13, loss:0.00022, loss_test:0.11788, lr:9.80e-03, fs:0.64220 (r=0.707,p=0.588),  time:19.683, tt:275.559\n",
      "Ep:14, loss:0.00021, loss_test:0.11562, lr:9.70e-03, fs:0.65438 (r=0.717,p=0.602),  time:19.798, tt:296.963\n",
      "Ep:15, loss:0.00021, loss_test:0.11324, lr:9.61e-03, fs:0.66351 (r=0.707,p=0.625),  time:19.859, tt:317.748\n",
      "Ep:16, loss:0.00020, loss_test:0.11142, lr:9.51e-03, fs:0.68900 (r=0.727,p=0.655),  time:19.934, tt:338.876\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10964, lr:9.51e-03, fs:0.69565 (r=0.727,p=0.667),  time:19.980, tt:359.641\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.10748, lr:9.51e-03, fs:0.72195 (r=0.747,p=0.698),  time:20.061, tt:381.152\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.10530, lr:9.51e-03, fs:0.71357 (r=0.717,p=0.710),  time:20.095, tt:401.896\n",
      "Ep:20, loss:0.00018, loss_test:0.10374, lr:9.51e-03, fs:0.68449 (r=0.646,p=0.727),  time:20.052, tt:421.091\n",
      "Ep:21, loss:0.00017, loss_test:0.10279, lr:9.51e-03, fs:0.70526 (r=0.677,p=0.736),  time:20.025, tt:440.554\n",
      "Ep:22, loss:0.00017, loss_test:0.10190, lr:9.51e-03, fs:0.70833 (r=0.687,p=0.731),  time:20.081, tt:461.866\n",
      "Ep:23, loss:0.00016, loss_test:0.10123, lr:9.51e-03, fs:0.71204 (r=0.687,p=0.739),  time:20.068, tt:481.625\n",
      "Ep:24, loss:0.00016, loss_test:0.10028, lr:9.51e-03, fs:0.72632 (r=0.697,p=0.758),  time:20.093, tt:502.315\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.09912, lr:9.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:20.078, tt:522.024\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.09873, lr:9.51e-03, fs:0.73913 (r=0.687,p=0.800),  time:20.052, tt:541.393\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09848, lr:9.51e-03, fs:0.74611 (r=0.727,p=0.766),  time:20.023, tt:560.642\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09714, lr:9.51e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.997, tt:579.915\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09605, lr:9.51e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.974, tt:599.211\n",
      "Ep:30, loss:0.00014, loss_test:0.09485, lr:9.51e-03, fs:0.75393 (r=0.727,p=0.783),  time:19.950, tt:618.455\n",
      "Ep:31, loss:0.00014, loss_test:0.09525, lr:9.51e-03, fs:0.73514 (r=0.687,p=0.791),  time:19.936, tt:637.950\n",
      "Ep:32, loss:0.00013, loss_test:0.09460, lr:9.51e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.957, tt:658.565\n",
      "Ep:33, loss:0.00013, loss_test:0.09364, lr:9.51e-03, fs:0.76087 (r=0.707,p=0.824),  time:20.010, tt:680.328\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.09215, lr:9.51e-03, fs:0.76596 (r=0.727,p=0.809),  time:20.010, tt:700.341\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.09272, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.975, tt:719.116\n",
      "Ep:36, loss:0.00012, loss_test:0.09320, lr:9.51e-03, fs:0.75978 (r=0.687,p=0.850),  time:19.971, tt:738.926\n",
      "Ep:37, loss:0.00012, loss_test:0.09070, lr:9.51e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.992, tt:759.684\n",
      "Ep:38, loss:0.00012, loss_test:0.08972, lr:9.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.996, tt:779.858\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08930, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:19.992, tt:799.686\n",
      "Ep:40, loss:0.00011, loss_test:0.08912, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:20.031, tt:821.289\n",
      "Ep:41, loss:0.00011, loss_test:0.08867, lr:9.51e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.032, tt:841.357\n",
      "Ep:42, loss:0.00011, loss_test:0.08786, lr:9.51e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.087, tt:863.730\n",
      "Ep:43, loss:0.00010, loss_test:0.08683, lr:9.51e-03, fs:0.78652 (r=0.707,p=0.886),  time:20.065, tt:882.856\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.08674, lr:9.51e-03, fs:0.78857 (r=0.697,p=0.908),  time:20.057, tt:902.579\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.08621, lr:9.51e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.075, tt:923.434\n",
      "Ep:46, loss:0.00010, loss_test:0.08607, lr:9.51e-03, fs:0.77011 (r=0.677,p=0.893),  time:20.089, tt:944.197\n",
      "Ep:47, loss:0.00009, loss_test:0.08593, lr:9.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:20.111, tt:965.317\n",
      "Ep:48, loss:0.00009, loss_test:0.08535, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.023, tt:981.119\n",
      "Ep:49, loss:0.00009, loss_test:0.08590, lr:9.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.951, tt:997.533\n",
      "Ep:50, loss:0.00009, loss_test:0.08486, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.935, tt:1016.671\n",
      "Ep:51, loss:0.00009, loss_test:0.08497, lr:9.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.863, tt:1032.887\n",
      "Ep:52, loss:0.00008, loss_test:0.08406, lr:9.51e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.790, tt:1048.878\n",
      "Ep:53, loss:0.00008, loss_test:0.08404, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:19.725, tt:1065.144\n",
      "Ep:54, loss:0.00008, loss_test:0.08359, lr:9.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.728, tt:1085.036\n",
      "Ep:55, loss:0.00008, loss_test:0.08355, lr:9.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.747, tt:1105.831\n",
      "Ep:56, loss:0.00008, loss_test:0.08449, lr:9.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.744, tt:1125.382\n",
      "Ep:57, loss:0.00008, loss_test:0.08364, lr:9.32e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.721, tt:1143.806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00007, loss_test:0.08218, lr:9.23e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.723, tt:1163.666\n",
      "Ep:59, loss:0.00007, loss_test:0.08473, lr:9.14e-03, fs:0.76364 (r=0.636,p=0.955),  time:19.727, tt:1183.644\n",
      "Ep:60, loss:0.00007, loss_test:0.08291, lr:9.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.739, tt:1204.065\n",
      "Ep:61, loss:0.00007, loss_test:0.08176, lr:8.95e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.722, tt:1222.752\n",
      "Ep:62, loss:0.00007, loss_test:0.08535, lr:8.86e-03, fs:0.75610 (r=0.626,p=0.954),  time:19.710, tt:1241.706\n",
      "Ep:63, loss:0.00007, loss_test:0.08189, lr:8.78e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.701, tt:1260.890\n",
      "Ep:64, loss:0.00007, loss_test:0.08229, lr:8.69e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.733, tt:1282.625\n",
      "Ep:65, loss:0.00006, loss_test:0.08615, lr:8.60e-03, fs:0.76074 (r=0.626,p=0.969),  time:19.735, tt:1302.539\n",
      "Ep:66, loss:0.00006, loss_test:0.08056, lr:8.51e-03, fs:0.77714 (r=0.687,p=0.895),  time:19.733, tt:1322.087\n",
      "Ep:67, loss:0.00006, loss_test:0.08312, lr:8.43e-03, fs:0.75449 (r=0.636,p=0.926),  time:19.739, tt:1342.221\n",
      "Ep:68, loss:0.00006, loss_test:0.08535, lr:8.35e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.752, tt:1362.916\n",
      "Ep:69, loss:0.00006, loss_test:0.08070, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.761, tt:1383.271\n",
      "Ep:70, loss:0.00006, loss_test:0.08217, lr:8.18e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.785, tt:1404.756\n",
      "Ep:71, loss:0.00006, loss_test:0.08445, lr:8.10e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.801, tt:1425.682\n",
      "Ep:72, loss:0.00006, loss_test:0.08063, lr:8.02e-03, fs:0.77457 (r=0.677,p=0.905),  time:19.805, tt:1445.777\n",
      "Ep:73, loss:0.00006, loss_test:0.08145, lr:7.94e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.813, tt:1466.164\n",
      "Ep:74, loss:0.00005, loss_test:0.08509, lr:7.86e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.793, tt:1484.469\n",
      "Ep:75, loss:0.00005, loss_test:0.08080, lr:7.78e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.799, tt:1504.708\n",
      "Ep:76, loss:0.00005, loss_test:0.08086, lr:7.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.803, tt:1524.839\n",
      "Ep:77, loss:0.00005, loss_test:0.08475, lr:7.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.798, tt:1544.270\n",
      "Ep:78, loss:0.00005, loss_test:0.08052, lr:7.55e-03, fs:0.78363 (r=0.677,p=0.931),  time:19.793, tt:1563.653\n",
      "Ep:79, loss:0.00005, loss_test:0.08054, lr:7.47e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.793, tt:1583.431\n",
      "Ep:80, loss:0.00005, loss_test:0.08349, lr:7.40e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.792, tt:1603.163\n",
      "Ep:81, loss:0.00005, loss_test:0.08092, lr:7.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.811, tt:1624.463\n",
      "Ep:82, loss:0.00005, loss_test:0.08066, lr:7.25e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.809, tt:1644.114\n",
      "Ep:83, loss:0.00005, loss_test:0.08244, lr:7.18e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.825, tt:1665.337\n",
      "Ep:84, loss:0.00005, loss_test:0.08044, lr:7.11e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.831, tt:1685.606\n",
      "Ep:85, loss:0.00004, loss_test:0.08089, lr:7.03e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.846, tt:1706.789\n",
      "Ep:86, loss:0.00004, loss_test:0.08145, lr:6.96e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.863, tt:1728.083\n",
      "Ep:87, loss:0.00004, loss_test:0.08109, lr:6.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.879, tt:1749.395\n",
      "Ep:88, loss:0.00004, loss_test:0.08125, lr:6.83e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.885, tt:1769.784\n",
      "Ep:89, loss:0.00004, loss_test:0.08123, lr:6.76e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.884, tt:1789.550\n",
      "Ep:90, loss:0.00004, loss_test:0.08023, lr:6.69e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.859, tt:1807.152\n",
      "Ep:91, loss:0.00004, loss_test:0.08139, lr:6.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.865, tt:1827.619\n",
      "Ep:92, loss:0.00004, loss_test:0.08073, lr:6.56e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.877, tt:1848.598\n",
      "Ep:93, loss:0.00004, loss_test:0.08101, lr:6.49e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.884, tt:1869.132\n",
      "Ep:94, loss:0.00004, loss_test:0.08077, lr:6.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.889, tt:1889.486\n",
      "Ep:95, loss:0.00004, loss_test:0.08066, lr:6.36e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.876, tt:1908.095\n",
      "Ep:96, loss:0.00004, loss_test:0.08033, lr:6.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.871, tt:1927.442\n",
      "Ep:97, loss:0.00004, loss_test:0.08068, lr:6.24e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.882, tt:1948.393\n",
      "Ep:98, loss:0.00004, loss_test:0.08164, lr:6.17e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.892, tt:1969.345\n",
      "Ep:99, loss:0.00004, loss_test:0.07970, lr:6.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.891, tt:1989.140\n",
      "Ep:100, loss:0.00004, loss_test:0.08102, lr:6.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.886, tt:2008.459\n",
      "Ep:101, loss:0.00004, loss_test:0.08092, lr:5.99e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.875, tt:2027.270\n",
      "Ep:102, loss:0.00004, loss_test:0.08082, lr:5.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.875, tt:2047.166\n",
      "Ep:103, loss:0.00003, loss_test:0.08031, lr:5.87e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.877, tt:2067.200\n",
      "Ep:104, loss:0.00003, loss_test:0.08029, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.875, tt:2086.871\n",
      "Ep:105, loss:0.00003, loss_test:0.08091, lr:5.75e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.855, tt:2104.641\n",
      "Ep:106, loss:0.00003, loss_test:0.08087, lr:5.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.850, tt:2123.912\n",
      "Ep:107, loss:0.00003, loss_test:0.08061, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.849, tt:2143.678\n",
      "Ep:108, loss:0.00003, loss_test:0.08085, lr:5.58e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.869, tt:2165.674\n",
      "Ep:109, loss:0.00003, loss_test:0.08044, lr:5.53e-03, fs:0.76647 (r=0.646,p=0.941),  time:19.863, tt:2184.925\n",
      "Ep:110, loss:0.00003, loss_test:0.08007, lr:5.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.871, tt:2205.668\n",
      "Ep:111, loss:0.00003, loss_test:0.08174, lr:5.42e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.864, tt:2224.774\n",
      "Ep:112, loss:0.00003, loss_test:0.08030, lr:5.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.862, tt:2244.430\n",
      "Ep:113, loss:0.00003, loss_test:0.07995, lr:5.31e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.859, tt:2263.964\n",
      "Ep:114, loss:0.00003, loss_test:0.08115, lr:5.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:19.867, tt:2284.735\n",
      "Ep:115, loss:0.00003, loss_test:0.08086, lr:5.20e-03, fs:0.76190 (r=0.646,p=0.928),  time:19.868, tt:2304.723\n",
      "Ep:116, loss:0.00003, loss_test:0.08077, lr:5.15e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.855, tt:2322.982\n",
      "Ep:117, loss:0.00003, loss_test:0.08024, lr:5.10e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.843, tt:2341.489\n",
      "Ep:118, loss:0.00003, loss_test:0.08101, lr:5.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.844, tt:2361.436\n",
      "Ep:119, loss:0.00003, loss_test:0.08064, lr:5.00e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.853, tt:2382.382\n",
      "Ep:120, loss:0.00003, loss_test:0.08099, lr:4.95e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.851, tt:2402.013\n",
      "Ep:121, loss:0.00003, loss_test:0.08050, lr:4.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.849, tt:2421.548\n",
      "Ep:122, loss:0.00003, loss_test:0.08071, lr:4.85e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.846, tt:2441.075\n",
      "Ep:123, loss:0.00003, loss_test:0.08088, lr:4.80e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.861, tt:2462.802\n",
      "Ep:124, loss:0.00003, loss_test:0.08055, lr:4.75e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.868, tt:2483.533\n",
      "Ep:125, loss:0.00003, loss_test:0.08080, lr:4.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.864, tt:2502.850\n",
      "Ep:126, loss:0.00003, loss_test:0.08098, lr:4.66e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.855, tt:2521.602\n",
      "Ep:127, loss:0.00003, loss_test:0.08080, lr:4.61e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.848, tt:2540.597\n",
      "Ep:128, loss:0.00003, loss_test:0.08078, lr:4.57e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.854, tt:2561.159\n",
      "Ep:129, loss:0.00003, loss_test:0.08098, lr:4.52e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.856, tt:2581.274\n",
      "Ep:130, loss:0.00003, loss_test:0.08065, lr:4.48e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.853, tt:2600.714\n",
      "Ep:131, loss:0.00003, loss_test:0.08111, lr:4.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.855, tt:2620.845\n",
      "Ep:132, loss:0.00003, loss_test:0.08103, lr:4.39e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.849, tt:2639.860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00003, loss_test:0.08111, lr:4.34e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.865, tt:2661.883\n",
      "Ep:134, loss:0.00003, loss_test:0.08109, lr:4.30e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.862, tt:2681.366\n",
      "Ep:135, loss:0.00002, loss_test:0.08077, lr:4.26e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.871, tt:2702.501\n",
      "Ep:136, loss:0.00002, loss_test:0.08130, lr:4.21e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.878, tt:2723.319\n",
      "Ep:137, loss:0.00002, loss_test:0.08130, lr:4.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:19.872, tt:2742.306\n",
      "Ep:138, loss:0.00002, loss_test:0.08133, lr:4.13e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.867, tt:2761.527\n",
      "Ep:139, loss:0.00002, loss_test:0.08187, lr:4.09e-03, fs:0.77844 (r=0.657,p=0.956),  time:19.870, tt:2781.740\n",
      "Ep:140, loss:0.00002, loss_test:0.08088, lr:4.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2801.628\n",
      "Ep:141, loss:0.00002, loss_test:0.08120, lr:4.01e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.872, tt:2821.836\n",
      "Ep:142, loss:0.00002, loss_test:0.08230, lr:3.97e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2841.434\n",
      "Ep:143, loss:0.00002, loss_test:0.08094, lr:3.93e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.873, tt:2861.750\n",
      "Ep:144, loss:0.00002, loss_test:0.08119, lr:3.89e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2881.156\n",
      "Ep:145, loss:0.00002, loss_test:0.08182, lr:3.85e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.870, tt:2901.066\n",
      "Ep:146, loss:0.00002, loss_test:0.08191, lr:3.81e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.865, tt:2920.188\n",
      "Ep:147, loss:0.00002, loss_test:0.08205, lr:3.77e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.863, tt:2939.715\n",
      "Ep:148, loss:0.00002, loss_test:0.08156, lr:3.73e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.863, tt:2959.593\n",
      "Ep:149, loss:0.00002, loss_test:0.08187, lr:3.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.853, tt:2978.017\n",
      "Ep:150, loss:0.00002, loss_test:0.08187, lr:3.66e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.857, tt:2998.344\n",
      "Ep:151, loss:0.00002, loss_test:0.08100, lr:3.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.862, tt:3019.004\n",
      "Ep:152, loss:0.00002, loss_test:0.08223, lr:3.59e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.859, tt:3038.373\n",
      "Ep:153, loss:0.00002, loss_test:0.08151, lr:3.55e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.857, tt:3058.045\n",
      "Ep:154, loss:0.00002, loss_test:0.08159, lr:3.52e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.855, tt:3077.477\n",
      "Ep:155, loss:0.00002, loss_test:0.08179, lr:3.48e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.852, tt:3096.956\n",
      "Ep:156, loss:0.00002, loss_test:0.08166, lr:3.45e-03, fs:0.77381 (r=0.657,p=0.942),  time:19.859, tt:3117.923\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14450, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.033, tt:49.033\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14312, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.821, tt:97.641\n",
      "Ep:2, loss:0.00027, loss_test:0.14038, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.768, tt:152.304\n",
      "Ep:3, loss:0.00027, loss_test:0.13512, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:51.368, tt:205.472\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12535, lr:1.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:51.787, tt:258.933\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11365, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:52.223, tt:313.340\n",
      "Ep:6, loss:0.00022, loss_test:0.11197, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:52.563, tt:367.944\n",
      "Ep:7, loss:0.00021, loss_test:0.11221, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:52.654, tt:421.231\n",
      "Ep:8, loss:0.00021, loss_test:0.11162, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:52.934, tt:476.405\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10940, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:52.877, tt:528.770\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10718, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:52.764, tt:580.406\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10630, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:52.719, tt:632.623\n",
      "Ep:12, loss:0.00018, loss_test:0.10519, lr:1.00e-02, fs:0.69231 (r=0.727,p=0.661),  time:52.919, tt:687.952\n",
      "Ep:13, loss:0.00017, loss_test:0.10481, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:52.948, tt:741.275\n",
      "Ep:14, loss:0.00017, loss_test:0.10349, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:52.841, tt:792.621\n",
      "Ep:15, loss:0.00016, loss_test:0.10251, lr:1.00e-02, fs:0.69072 (r=0.677,p=0.705),  time:52.937, tt:846.985\n",
      "Ep:16, loss:0.00016, loss_test:0.10214, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:52.986, tt:900.766\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10256, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:53.019, tt:954.342\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10317, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:52.949, tt:1006.033\n",
      "Ep:19, loss:0.00015, loss_test:0.10283, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:52.956, tt:1059.126\n",
      "Ep:20, loss:0.00014, loss_test:0.10186, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:53.010, tt:1113.213\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.10305, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:53.099, tt:1168.183\n",
      "Ep:22, loss:0.00013, loss_test:0.10477, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:53.066, tt:1220.512\n",
      "Ep:23, loss:0.00013, loss_test:0.10614, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:53.196, tt:1276.704\n",
      "Ep:24, loss:0.00013, loss_test:0.10466, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:53.244, tt:1331.106\n",
      "Ep:25, loss:0.00012, loss_test:0.10705, lr:1.00e-02, fs:0.72527 (r=0.667,p=0.795),  time:53.248, tt:1384.442\n",
      "Ep:26, loss:0.00012, loss_test:0.10434, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:53.217, tt:1436.848\n",
      "Ep:27, loss:0.00012, loss_test:0.11067, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:53.168, tt:1488.698\n",
      "Ep:28, loss:0.00012, loss_test:0.10625, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:53.191, tt:1542.536\n",
      "Ep:29, loss:0.00011, loss_test:0.11010, lr:1.00e-02, fs:0.71264 (r=0.626,p=0.827),  time:53.214, tt:1596.420\n",
      "Ep:30, loss:0.00011, loss_test:0.10585, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:52.992, tt:1642.755\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.10792, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:52.844, tt:1691.001\n",
      "Ep:32, loss:0.00010, loss_test:0.10762, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:52.895, tt:1745.545\n",
      "Ep:33, loss:0.00010, loss_test:0.10776, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:52.957, tt:1800.542\n",
      "Ep:34, loss:0.00010, loss_test:0.11174, lr:1.00e-02, fs:0.72316 (r=0.646,p=0.821),  time:52.941, tt:1852.926\n",
      "Ep:35, loss:0.00009, loss_test:0.10429, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:52.995, tt:1907.809\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.11496, lr:1.00e-02, fs:0.71676 (r=0.626,p=0.838),  time:53.000, tt:1961.013\n",
      "Ep:37, loss:0.00009, loss_test:0.10778, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:53.013, tt:2014.501\n",
      "Ep:38, loss:0.00009, loss_test:0.10782, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:53.127, tt:2071.961\n",
      "Ep:39, loss:0.00008, loss_test:0.11051, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:53.168, tt:2126.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00008, loss_test:0.10830, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:53.157, tt:2179.455\n",
      "Ep:41, loss:0.00008, loss_test:0.11061, lr:1.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:53.147, tt:2232.167\n",
      "Ep:42, loss:0.00007, loss_test:0.10697, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:53.136, tt:2284.868\n",
      "Ep:43, loss:0.00007, loss_test:0.11241, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:53.176, tt:2339.736\n",
      "Ep:44, loss:0.00007, loss_test:0.10834, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:53.165, tt:2392.420\n",
      "Ep:45, loss:0.00007, loss_test:0.10762, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:53.135, tt:2444.204\n",
      "Ep:46, loss:0.00007, loss_test:0.10962, lr:1.00e-02, fs:0.73446 (r=0.657,p=0.833),  time:53.113, tt:2496.288\n",
      "Ep:47, loss:0.00007, loss_test:0.11202, lr:9.90e-03, fs:0.73988 (r=0.646,p=0.865),  time:53.168, tt:2552.067\n",
      "Ep:48, loss:0.00006, loss_test:0.10667, lr:9.80e-03, fs:0.74317 (r=0.687,p=0.810),  time:53.204, tt:2606.995\n",
      "Ep:49, loss:0.00006, loss_test:0.11521, lr:9.70e-03, fs:0.72619 (r=0.616,p=0.884),  time:53.219, tt:2660.943\n",
      "Ep:50, loss:0.00006, loss_test:0.10487, lr:9.61e-03, fs:0.72928 (r=0.667,p=0.805),  time:53.206, tt:2713.519\n",
      "Ep:51, loss:0.00006, loss_test:0.11969, lr:9.51e-03, fs:0.71951 (r=0.596,p=0.908),  time:53.181, tt:2765.410\n",
      "Ep:52, loss:0.00006, loss_test:0.10370, lr:9.41e-03, fs:0.73034 (r=0.657,p=0.823),  time:53.164, tt:2817.701\n",
      "Ep:53, loss:0.00006, loss_test:0.11595, lr:9.32e-03, fs:0.73810 (r=0.626,p=0.899),  time:53.177, tt:2871.534\n",
      "Ep:54, loss:0.00005, loss_test:0.10730, lr:9.23e-03, fs:0.74713 (r=0.657,p=0.867),  time:53.143, tt:2922.866\n",
      "Ep:55, loss:0.00005, loss_test:0.11291, lr:9.14e-03, fs:0.72941 (r=0.626,p=0.873),  time:53.163, tt:2977.110\n",
      "Ep:56, loss:0.00005, loss_test:0.11099, lr:9.04e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.192, tt:3031.963\n",
      "Ep:57, loss:0.00005, loss_test:0.11038, lr:8.95e-03, fs:0.74854 (r=0.646,p=0.889),  time:53.191, tt:3085.074\n",
      "Ep:58, loss:0.00005, loss_test:0.11187, lr:8.86e-03, fs:0.73373 (r=0.626,p=0.886),  time:53.202, tt:3138.909\n",
      "Ep:59, loss:0.00004, loss_test:0.10947, lr:8.78e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.202, tt:3192.105\n",
      "Ep:60, loss:0.00004, loss_test:0.11654, lr:8.69e-03, fs:0.73054 (r=0.616,p=0.897),  time:53.218, tt:3246.329\n",
      "Ep:61, loss:0.00004, loss_test:0.10842, lr:8.60e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.208, tt:3298.912\n",
      "Ep:62, loss:0.00004, loss_test:0.11907, lr:8.51e-03, fs:0.70732 (r=0.586,p=0.892),  time:53.237, tt:3353.914\n",
      "Ep:63, loss:0.00004, loss_test:0.10761, lr:8.43e-03, fs:0.75145 (r=0.657,p=0.878),  time:53.212, tt:3405.565\n",
      "Ep:64, loss:0.00004, loss_test:0.11828, lr:8.35e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.227, tt:3459.738\n",
      "Ep:65, loss:0.00004, loss_test:0.10668, lr:8.26e-03, fs:0.74713 (r=0.657,p=0.867),  time:53.226, tt:3512.899\n",
      "Ep:66, loss:0.00003, loss_test:0.12314, lr:8.18e-03, fs:0.67089 (r=0.535,p=0.898),  time:53.224, tt:3565.991\n",
      "Ep:67, loss:0.00004, loss_test:0.10905, lr:8.10e-03, fs:0.73256 (r=0.636,p=0.863),  time:53.206, tt:3617.974\n",
      "Ep:68, loss:0.00003, loss_test:0.11614, lr:8.02e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.193, tt:3670.340\n",
      "Ep:69, loss:0.00003, loss_test:0.11046, lr:7.94e-03, fs:0.72189 (r=0.616,p=0.871),  time:53.193, tt:3723.542\n",
      "Ep:70, loss:0.00003, loss_test:0.11689, lr:7.86e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.202, tt:3777.354\n",
      "Ep:71, loss:0.00003, loss_test:0.11246, lr:7.78e-03, fs:0.71515 (r=0.596,p=0.894),  time:53.198, tt:3830.291\n",
      "Ep:72, loss:0.00003, loss_test:0.11531, lr:7.70e-03, fs:0.66250 (r=0.535,p=0.869),  time:53.171, tt:3881.483\n",
      "Ep:73, loss:0.00003, loss_test:0.11166, lr:7.62e-03, fs:0.71515 (r=0.596,p=0.894),  time:53.157, tt:3933.649\n",
      "Ep:74, loss:0.00003, loss_test:0.11383, lr:7.55e-03, fs:0.70303 (r=0.586,p=0.879),  time:53.172, tt:3987.897\n",
      "Ep:75, loss:0.00003, loss_test:0.11104, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:53.152, tt:4039.559\n",
      "Ep:76, loss:0.00003, loss_test:0.11190, lr:7.40e-03, fs:0.70732 (r=0.586,p=0.892),  time:53.155, tt:4092.920\n",
      "Ep:77, loss:0.00003, loss_test:0.11483, lr:7.32e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.166, tt:4146.951\n",
      "Ep:78, loss:0.00002, loss_test:0.11450, lr:7.25e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.179, tt:4201.113\n",
      "Ep:79, loss:0.00002, loss_test:0.10884, lr:7.18e-03, fs:0.71084 (r=0.596,p=0.881),  time:53.153, tt:4252.235\n",
      "Ep:80, loss:0.00002, loss_test:0.11583, lr:7.11e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.151, tt:4305.240\n",
      "Ep:81, loss:0.00002, loss_test:0.11307, lr:7.03e-03, fs:0.69136 (r=0.566,p=0.889),  time:53.135, tt:4357.094\n",
      "Ep:82, loss:0.00002, loss_test:0.11417, lr:6.96e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.130, tt:4409.802\n",
      "Ep:83, loss:0.00002, loss_test:0.11385, lr:6.89e-03, fs:0.66250 (r=0.535,p=0.869),  time:53.149, tt:4464.494\n",
      "Ep:84, loss:0.00002, loss_test:0.10858, lr:6.83e-03, fs:0.69512 (r=0.576,p=0.877),  time:53.170, tt:4519.461\n",
      "Ep:85, loss:0.00002, loss_test:0.11793, lr:6.76e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.199, tt:4575.148\n",
      "Ep:86, loss:0.00002, loss_test:0.11026, lr:6.69e-03, fs:0.69512 (r=0.576,p=0.877),  time:53.182, tt:4626.803\n",
      "Ep:87, loss:0.00002, loss_test:0.11284, lr:6.62e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.206, tt:4682.123\n",
      "Ep:88, loss:0.00002, loss_test:0.11035, lr:6.56e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.212, tt:4735.823\n",
      "Ep:89, loss:0.00002, loss_test:0.11509, lr:6.49e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.194, tt:4787.454\n",
      "Ep:90, loss:0.00002, loss_test:0.11310, lr:6.43e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.184, tt:4839.758\n",
      "Ep:91, loss:0.00002, loss_test:0.11239, lr:6.36e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.177, tt:4892.258\n",
      "Ep:92, loss:0.00002, loss_test:0.11153, lr:6.30e-03, fs:0.64968 (r=0.515,p=0.879),  time:53.167, tt:4944.550\n",
      "Ep:93, loss:0.00002, loss_test:0.11226, lr:6.24e-03, fs:0.69939 (r=0.576,p=0.891),  time:53.167, tt:4997.665\n",
      "Ep:94, loss:0.00002, loss_test:0.11302, lr:6.17e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.185, tt:5052.586\n",
      "Ep:95, loss:0.00002, loss_test:0.11204, lr:6.11e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.190, tt:5106.277\n",
      "Ep:96, loss:0.00002, loss_test:0.11193, lr:6.05e-03, fs:0.65823 (r=0.525,p=0.881),  time:53.206, tt:5161.003\n",
      "Ep:97, loss:0.00002, loss_test:0.11419, lr:5.99e-03, fs:0.68323 (r=0.556,p=0.887),  time:53.206, tt:5214.226\n",
      "Ep:98, loss:0.00002, loss_test:0.11165, lr:5.93e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.213, tt:5268.125\n",
      "Ep:99, loss:0.00002, loss_test:0.11413, lr:5.87e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.213, tt:5321.282\n",
      "Ep:100, loss:0.00002, loss_test:0.11393, lr:5.81e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.212, tt:5374.458\n",
      "Ep:101, loss:0.00002, loss_test:0.11202, lr:5.75e-03, fs:0.65823 (r=0.525,p=0.881),  time:53.201, tt:5426.538\n",
      "Ep:102, loss:0.00002, loss_test:0.11468, lr:5.70e-03, fs:0.64103 (r=0.505,p=0.877),  time:53.166, tt:5476.131\n",
      "Ep:103, loss:0.00001, loss_test:0.11207, lr:5.64e-03, fs:0.67500 (r=0.545,p=0.885),  time:53.072, tt:5519.523\n",
      "Ep:104, loss:0.00001, loss_test:0.11404, lr:5.58e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.937, tt:5558.356\n",
      "Ep:105, loss:0.00001, loss_test:0.11007, lr:5.53e-03, fs:0.69136 (r=0.566,p=0.889),  time:52.849, tt:5602.024\n",
      "Ep:106, loss:0.00001, loss_test:0.11751, lr:5.47e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.858, tt:5655.855\n",
      "Ep:107, loss:0.00001, loss_test:0.11334, lr:5.42e-03, fs:0.67500 (r=0.545,p=0.885),  time:52.858, tt:5708.654\n",
      "Ep:108, loss:0.00001, loss_test:0.11115, lr:5.36e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.834, tt:5758.894\n",
      "Ep:109, loss:0.00001, loss_test:0.11329, lr:5.31e-03, fs:0.65385 (r=0.515,p=0.895),  time:52.818, tt:5810.034\n",
      "Ep:110, loss:0.00001, loss_test:0.11279, lr:5.26e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.810, tt:5861.966\n",
      "Ep:111, loss:0.00001, loss_test:0.11218, lr:5.20e-03, fs:0.67925 (r=0.545,p=0.900),  time:52.816, tt:5915.337\n",
      "Ep:112, loss:0.00001, loss_test:0.11275, lr:5.15e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.817, tt:5968.275\n",
      "Ep:113, loss:0.00001, loss_test:0.11297, lr:5.10e-03, fs:0.65385 (r=0.515,p=0.895),  time:52.796, tt:6018.781\n",
      "Ep:114, loss:0.00001, loss_test:0.11308, lr:5.05e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.773, tt:6068.905\n",
      "Ep:115, loss:0.00001, loss_test:0.11448, lr:5.00e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.797, tt:6124.452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00001, loss_test:0.11208, lr:4.95e-03, fs:0.64103 (r=0.505,p=0.877),  time:52.799, tt:6177.515\n",
      "Ep:117, loss:0.00001, loss_test:0.11329, lr:4.90e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.797, tt:6230.046\n",
      "Ep:118, loss:0.00001, loss_test:0.11362, lr:4.85e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.808, tt:6284.193\n",
      "Ep:119, loss:0.00001, loss_test:0.11246, lr:4.80e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.799, tt:6335.933\n",
      "Ep:120, loss:0.00001, loss_test:0.11333, lr:4.75e-03, fs:0.66667 (r=0.525,p=0.912),  time:52.786, tt:6387.071\n",
      "Ep:121, loss:0.00001, loss_test:0.11442, lr:4.71e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.768, tt:6437.664\n",
      "Ep:122, loss:0.00001, loss_test:0.11252, lr:4.66e-03, fs:0.64516 (r=0.505,p=0.893),  time:52.777, tt:6491.560\n",
      "Ep:123, loss:0.00001, loss_test:0.11525, lr:4.61e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.774, tt:6544.005\n",
      "Ep:124, loss:0.00001, loss_test:0.11359, lr:4.57e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.773, tt:6596.626\n",
      "Ep:125, loss:0.00001, loss_test:0.11161, lr:4.52e-03, fs:0.65806 (r=0.515,p=0.911),  time:52.779, tt:6650.171\n",
      "Ep:126, loss:0.00001, loss_test:0.11518, lr:4.48e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.786, tt:6703.862\n",
      "Ep:127, loss:0.00001, loss_test:0.11257, lr:4.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.794, tt:6757.650\n",
      "Ep:128, loss:0.00001, loss_test:0.11335, lr:4.39e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.774, tt:6807.854\n",
      "Ep:129, loss:0.00001, loss_test:0.11451, lr:4.34e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.765, tt:6859.393\n",
      "Ep:130, loss:0.00001, loss_test:0.11209, lr:4.30e-03, fs:0.66667 (r=0.525,p=0.912),  time:52.762, tt:6911.767\n",
      "Ep:131, loss:0.00001, loss_test:0.11480, lr:4.26e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.745, tt:6962.331\n",
      "Ep:132, loss:0.00001, loss_test:0.11322, lr:4.21e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.731, tt:7013.286\n",
      "Ep:133, loss:0.00001, loss_test:0.11388, lr:4.17e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.736, tt:7066.624\n",
      "Ep:134, loss:0.00001, loss_test:0.11542, lr:4.13e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.737, tt:7119.552\n",
      "Ep:135, loss:0.00001, loss_test:0.11131, lr:4.09e-03, fs:0.64935 (r=0.505,p=0.909),  time:52.725, tt:7170.611\n",
      "Ep:136, loss:0.00001, loss_test:0.11618, lr:4.05e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.729, tt:7223.910\n",
      "Ep:137, loss:0.00001, loss_test:0.11478, lr:4.01e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.743, tt:7278.589\n",
      "Ep:138, loss:0.00001, loss_test:0.11261, lr:3.97e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.738, tt:7330.616\n",
      "Ep:139, loss:0.00001, loss_test:0.11448, lr:3.93e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.729, tt:7382.011\n",
      "Ep:140, loss:0.00001, loss_test:0.11445, lr:3.89e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.738, tt:7436.035\n",
      "Ep:141, loss:0.00001, loss_test:0.11313, lr:3.85e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.728, tt:7487.342\n",
      "Ep:142, loss:0.00001, loss_test:0.11297, lr:3.81e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.732, tt:7540.731\n",
      "Ep:143, loss:0.00001, loss_test:0.11366, lr:3.77e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.723, tt:7592.043\n",
      "Ep:144, loss:0.00001, loss_test:0.11193, lr:3.73e-03, fs:0.65359 (r=0.505,p=0.926),  time:52.692, tt:7640.339\n",
      "Ep:145, loss:0.00001, loss_test:0.11538, lr:3.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.701, tt:7694.342\n",
      "Ep:146, loss:0.00001, loss_test:0.11526, lr:3.66e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.699, tt:7746.733\n",
      "Ep:147, loss:0.00001, loss_test:0.11250, lr:3.62e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.698, tt:7799.327\n",
      "Ep:148, loss:0.00001, loss_test:0.11489, lr:3.59e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.683, tt:7849.788\n",
      "Ep:149, loss:0.00001, loss_test:0.11432, lr:3.55e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.676, tt:7901.471\n",
      "Ep:150, loss:0.00001, loss_test:0.11492, lr:3.52e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.677, tt:7954.171\n",
      "Ep:151, loss:0.00001, loss_test:0.11513, lr:3.48e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.673, tt:8006.327\n",
      "Ep:152, loss:0.00001, loss_test:0.11260, lr:3.45e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.669, tt:8058.303\n",
      "Ep:153, loss:0.00001, loss_test:0.11493, lr:3.41e-03, fs:0.66225 (r=0.505,p=0.962),  time:52.657, tt:8109.165\n",
      "Ep:154, loss:0.00001, loss_test:0.11504, lr:3.38e-03, fs:0.65789 (r=0.505,p=0.943),  time:52.644, tt:8159.796\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14395, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.111, tt:19.111\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14305, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.968, tt:39.936\n",
      "Ep:2, loss:0.00028, loss_test:0.14143, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.555, tt:58.665\n",
      "Ep:3, loss:0.00028, loss_test:0.13857, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:19.090, tt:76.361\n",
      "Ep:4, loss:0.00027, loss_test:0.13402, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:19.485, tt:97.424\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12745, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:19.641, tt:117.844\n",
      "Ep:6, loss:0.00024, loss_test:0.11849, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:19.800, tt:138.597\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11629, lr:1.00e-02, fs:0.58511 (r=0.556,p=0.618),  time:19.731, tt:157.849\n",
      "Ep:8, loss:0.00022, loss_test:0.11467, lr:1.00e-02, fs:0.59140 (r=0.556,p=0.632),  time:19.869, tt:178.822\n",
      "Ep:9, loss:0.00022, loss_test:0.11233, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:19.862, tt:198.618\n",
      "Ep:10, loss:0.00021, loss_test:0.10961, lr:1.00e-02, fs:0.64921 (r=0.626,p=0.674),  time:20.078, tt:220.862\n",
      "Ep:11, loss:0.00020, loss_test:0.10812, lr:1.00e-02, fs:0.65217 (r=0.606,p=0.706),  time:19.831, tt:237.974\n",
      "Ep:12, loss:0.00019, loss_test:0.10518, lr:1.00e-02, fs:0.65672 (r=0.667,p=0.647),  time:19.896, tt:258.649\n",
      "Ep:13, loss:0.00018, loss_test:0.10323, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:19.760, tt:276.641\n",
      "Ep:14, loss:0.00017, loss_test:0.10224, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:19.904, tt:298.557\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09897, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:19.907, tt:318.515\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09906, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:19.989, tt:339.818\n",
      "Ep:17, loss:0.00015, loss_test:0.09689, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:20.045, tt:360.814\n",
      "Ep:18, loss:0.00015, loss_test:0.09626, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:20.021, tt:380.402\n",
      "Ep:19, loss:0.00014, loss_test:0.09547, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:20.086, tt:401.717\n",
      "Ep:20, loss:0.00014, loss_test:0.09402, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:20.107, tt:422.252\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09462, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:20.141, tt:443.094\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.09155, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:20.111, tt:462.546\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.09562, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:20.142, tt:483.414\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.09057, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:20.079, tt:501.985\n",
      "Ep:25, loss:0.00011, loss_test:0.09419, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:20.144, tt:523.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00010, loss_test:0.08946, lr:1.00e-02, fs:0.70213 (r=0.667,p=0.742),  time:20.102, tt:542.759\n",
      "Ep:27, loss:0.00010, loss_test:0.09214, lr:1.00e-02, fs:0.70520 (r=0.616,p=0.824),  time:20.068, tt:561.909\n",
      "Ep:28, loss:0.00009, loss_test:0.08751, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:19.996, tt:579.890\n",
      "Ep:29, loss:0.00009, loss_test:0.08938, lr:1.00e-02, fs:0.71591 (r=0.636,p=0.818),  time:20.115, tt:603.458\n",
      "Ep:30, loss:0.00008, loss_test:0.08929, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:20.091, tt:622.835\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.08668, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:20.140, tt:644.487\n",
      "Ep:32, loss:0.00008, loss_test:0.09111, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:20.157, tt:665.187\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.08617, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:20.136, tt:684.630\n",
      "Ep:34, loss:0.00007, loss_test:0.09375, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:20.141, tt:704.946\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.08588, lr:1.00e-02, fs:0.73034 (r=0.657,p=0.823),  time:20.094, tt:723.368\n",
      "Ep:36, loss:0.00006, loss_test:0.09608, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:20.114, tt:744.232\n",
      "Ep:37, loss:0.00006, loss_test:0.08676, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:20.053, tt:762.017\n",
      "Ep:38, loss:0.00006, loss_test:0.09462, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:20.108, tt:784.209\n",
      "Ep:39, loss:0.00006, loss_test:0.08884, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:20.093, tt:803.700\n",
      "Ep:40, loss:0.00005, loss_test:0.09351, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:20.144, tt:825.896\n",
      "Ep:41, loss:0.00005, loss_test:0.09154, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:20.139, tt:845.837\n",
      "Ep:42, loss:0.00005, loss_test:0.09155, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:20.152, tt:866.524\n",
      "Ep:43, loss:0.00005, loss_test:0.09396, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:20.152, tt:886.675\n",
      "Ep:44, loss:0.00004, loss_test:0.09304, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:20.164, tt:907.393\n",
      "Ep:45, loss:0.00004, loss_test:0.08961, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:20.172, tt:927.922\n",
      "Ep:46, loss:0.00004, loss_test:0.09814, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.168, tt:947.901\n",
      "Ep:47, loss:0.00004, loss_test:0.09021, lr:9.80e-03, fs:0.76023 (r=0.657,p=0.903),  time:20.156, tt:967.503\n",
      "Ep:48, loss:0.00003, loss_test:0.10145, lr:9.70e-03, fs:0.71605 (r=0.586,p=0.921),  time:20.144, tt:987.055\n",
      "Ep:49, loss:0.00003, loss_test:0.08880, lr:9.61e-03, fs:0.74854 (r=0.646,p=0.889),  time:20.143, tt:1007.146\n",
      "Ep:50, loss:0.00003, loss_test:0.10051, lr:9.51e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.144, tt:1027.341\n",
      "Ep:51, loss:0.00003, loss_test:0.09025, lr:9.41e-03, fs:0.73373 (r=0.626,p=0.886),  time:20.173, tt:1048.976\n",
      "Ep:52, loss:0.00003, loss_test:0.10184, lr:9.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.166, tt:1068.792\n",
      "Ep:53, loss:0.00003, loss_test:0.09302, lr:9.23e-03, fs:0.75000 (r=0.636,p=0.913),  time:20.188, tt:1090.170\n",
      "Ep:54, loss:0.00003, loss_test:0.09626, lr:9.14e-03, fs:0.74251 (r=0.626,p=0.912),  time:20.180, tt:1109.909\n",
      "Ep:55, loss:0.00003, loss_test:0.09362, lr:9.04e-03, fs:0.74699 (r=0.626,p=0.925),  time:20.176, tt:1129.829\n",
      "Ep:56, loss:0.00002, loss_test:0.09151, lr:8.95e-03, fs:0.73939 (r=0.616,p=0.924),  time:20.174, tt:1149.917\n",
      "Ep:57, loss:0.00002, loss_test:0.09417, lr:8.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.183, tt:1170.588\n",
      "Ep:58, loss:0.00002, loss_test:0.09137, lr:8.78e-03, fs:0.72727 (r=0.606,p=0.909),  time:20.166, tt:1189.792\n",
      "Ep:59, loss:0.00002, loss_test:0.09347, lr:8.69e-03, fs:0.75449 (r=0.636,p=0.926),  time:20.168, tt:1210.108\n",
      "Ep:60, loss:0.00002, loss_test:0.09300, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.184, tt:1231.205\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.09114, lr:8.60e-03, fs:0.73171 (r=0.606,p=0.923),  time:20.159, tt:1249.861\n",
      "Ep:62, loss:0.00002, loss_test:0.09246, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.183, tt:1271.549\n",
      "Ep:63, loss:0.00002, loss_test:0.09231, lr:8.60e-03, fs:0.74390 (r=0.616,p=0.938),  time:20.153, tt:1289.804\n",
      "Ep:64, loss:0.00002, loss_test:0.09062, lr:8.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.165, tt:1310.721\n",
      "Ep:65, loss:0.00002, loss_test:0.09581, lr:8.60e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.172, tt:1331.333\n",
      "Ep:66, loss:0.00002, loss_test:0.09206, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:20.185, tt:1352.372\n",
      "Ep:67, loss:0.00002, loss_test:0.09842, lr:8.60e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.169, tt:1371.493\n",
      "Ep:68, loss:0.00002, loss_test:0.09425, lr:8.60e-03, fs:0.73620 (r=0.606,p=0.938),  time:20.172, tt:1391.860\n",
      "Ep:69, loss:0.00002, loss_test:0.09763, lr:8.60e-03, fs:0.71605 (r=0.586,p=0.921),  time:20.156, tt:1410.942\n",
      "Ep:70, loss:0.00002, loss_test:0.10136, lr:8.60e-03, fs:0.73292 (r=0.596,p=0.952),  time:20.143, tt:1430.161\n",
      "Ep:71, loss:0.00001, loss_test:0.09076, lr:8.60e-03, fs:0.72393 (r=0.596,p=0.922),  time:20.147, tt:1450.618\n",
      "Ep:72, loss:0.00001, loss_test:0.10098, lr:8.51e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.130, tt:1469.483\n",
      "Ep:73, loss:0.00001, loss_test:0.09360, lr:8.43e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.143, tt:1490.600\n",
      "Ep:74, loss:0.00001, loss_test:0.09568, lr:8.35e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.145, tt:1510.860\n",
      "Ep:75, loss:0.00001, loss_test:0.09542, lr:8.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.176, tt:1533.391\n",
      "Ep:76, loss:0.00001, loss_test:0.09245, lr:8.18e-03, fs:0.72393 (r=0.596,p=0.922),  time:20.196, tt:1555.075\n",
      "Ep:77, loss:0.00001, loss_test:0.09854, lr:8.10e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.207, tt:1576.178\n",
      "Ep:78, loss:0.00001, loss_test:0.09544, lr:8.02e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.259, tt:1600.445\n",
      "Ep:79, loss:0.00001, loss_test:0.09751, lr:7.94e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.275, tt:1622.010\n",
      "Ep:80, loss:0.00001, loss_test:0.09994, lr:7.86e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.277, tt:1642.402\n",
      "Ep:81, loss:0.00001, loss_test:0.09259, lr:7.78e-03, fs:0.72840 (r=0.596,p=0.937),  time:20.297, tt:1664.393\n",
      "Ep:82, loss:0.00001, loss_test:0.09488, lr:7.70e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.294, tt:1684.391\n",
      "Ep:83, loss:0.00001, loss_test:0.09534, lr:7.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.294, tt:1704.726\n",
      "Ep:84, loss:0.00001, loss_test:0.09656, lr:7.55e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.290, tt:1724.631\n",
      "Ep:85, loss:0.00001, loss_test:0.09605, lr:7.47e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.296, tt:1745.487\n",
      "Ep:86, loss:0.00001, loss_test:0.09694, lr:7.40e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.310, tt:1766.991\n",
      "Ep:87, loss:0.00001, loss_test:0.09902, lr:7.32e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.304, tt:1786.726\n",
      "Ep:88, loss:0.00001, loss_test:0.09541, lr:7.25e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.304, tt:1807.071\n",
      "Ep:89, loss:0.00001, loss_test:0.09760, lr:7.18e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.297, tt:1826.731\n",
      "Ep:90, loss:0.00001, loss_test:0.09619, lr:7.11e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.291, tt:1846.504\n",
      "Ep:91, loss:0.00001, loss_test:0.09898, lr:7.03e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.311, tt:1868.568\n",
      "Ep:92, loss:0.00001, loss_test:0.10019, lr:6.96e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.316, tt:1889.344\n",
      "Ep:93, loss:0.00001, loss_test:0.09356, lr:6.89e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.326, tt:1910.688\n",
      "Ep:94, loss:0.00001, loss_test:0.10064, lr:6.83e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.331, tt:1931.471\n",
      "Ep:95, loss:0.00001, loss_test:0.09735, lr:6.76e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.329, tt:1951.624\n",
      "Ep:96, loss:0.00001, loss_test:0.09519, lr:6.69e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.334, tt:1972.434\n",
      "Ep:97, loss:0.00001, loss_test:0.09952, lr:6.62e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.331, tt:1992.405\n",
      "Ep:98, loss:0.00001, loss_test:0.09616, lr:6.56e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.320, tt:2011.727\n",
      "Ep:99, loss:0.00001, loss_test:0.09627, lr:6.49e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.319, tt:2031.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00001, loss_test:0.09899, lr:6.43e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.309, tt:2051.164\n",
      "Ep:101, loss:0.00001, loss_test:0.09567, lr:6.36e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.300, tt:2070.554\n",
      "Ep:102, loss:0.00001, loss_test:0.09864, lr:6.30e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.331, tt:2094.045\n",
      "Ep:103, loss:0.00001, loss_test:0.10006, lr:6.24e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.327, tt:2114.021\n",
      "Ep:104, loss:0.00001, loss_test:0.09566, lr:6.17e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.343, tt:2136.028\n",
      "Ep:105, loss:0.00001, loss_test:0.09954, lr:6.11e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.337, tt:2155.761\n",
      "Ep:106, loss:0.00001, loss_test:0.09696, lr:6.05e-03, fs:0.72050 (r=0.586,p=0.935),  time:20.360, tt:2178.492\n",
      "Ep:107, loss:0.00001, loss_test:0.09763, lr:5.99e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.371, tt:2200.085\n",
      "Ep:108, loss:0.00001, loss_test:0.09886, lr:5.93e-03, fs:0.72500 (r=0.586,p=0.951),  time:20.371, tt:2220.397\n",
      "Ep:109, loss:0.00001, loss_test:0.09759, lr:5.87e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.379, tt:2241.656\n",
      "Ep:110, loss:0.00000, loss_test:0.09636, lr:5.81e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.373, tt:2261.425\n",
      "Ep:111, loss:0.00000, loss_test:0.09820, lr:5.75e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.375, tt:2281.955\n",
      "Ep:112, loss:0.00000, loss_test:0.09939, lr:5.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.352, tt:2299.828\n",
      "Ep:113, loss:0.00000, loss_test:0.09778, lr:5.64e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.345, tt:2319.352\n",
      "Ep:114, loss:0.00000, loss_test:0.09942, lr:5.58e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.339, tt:2339.033\n",
      "Ep:115, loss:0.00000, loss_test:0.09957, lr:5.53e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.335, tt:2358.864\n",
      "Ep:116, loss:0.00000, loss_test:0.09688, lr:5.47e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.318, tt:2377.209\n",
      "Ep:117, loss:0.00000, loss_test:0.09937, lr:5.42e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.329, tt:2398.780\n",
      "Ep:118, loss:0.00000, loss_test:0.09923, lr:5.36e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.327, tt:2418.924\n",
      "Ep:119, loss:0.00000, loss_test:0.09702, lr:5.31e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.345, tt:2441.432\n",
      "Ep:120, loss:0.00000, loss_test:0.10109, lr:5.26e-03, fs:0.70440 (r=0.566,p=0.933),  time:20.346, tt:2461.887\n",
      "Ep:121, loss:0.00000, loss_test:0.10394, lr:5.20e-03, fs:0.70440 (r=0.566,p=0.933),  time:20.362, tt:2484.197\n",
      "Ep:122, loss:0.00000, loss_test:0.09799, lr:5.15e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.363, tt:2504.706\n",
      "Ep:123, loss:0.00000, loss_test:0.10054, lr:5.10e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.377, tt:2526.784\n",
      "Ep:124, loss:0.00000, loss_test:0.10287, lr:5.05e-03, fs:0.71698 (r=0.576,p=0.950),  time:20.376, tt:2547.059\n",
      "Ep:125, loss:0.00000, loss_test:0.10005, lr:5.00e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.370, tt:2566.664\n",
      "Ep:126, loss:0.00000, loss_test:0.10028, lr:4.95e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.370, tt:2586.935\n",
      "Ep:127, loss:0.00000, loss_test:0.10222, lr:4.90e-03, fs:0.70064 (r=0.556,p=0.948),  time:20.363, tt:2606.448\n",
      "Ep:128, loss:0.00000, loss_test:0.10091, lr:4.85e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.361, tt:2626.527\n",
      "Ep:129, loss:0.00000, loss_test:0.09880, lr:4.80e-03, fs:0.71250 (r=0.576,p=0.934),  time:20.349, tt:2645.423\n",
      "Ep:130, loss:0.00000, loss_test:0.10036, lr:4.75e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.340, tt:2664.563\n",
      "Ep:131, loss:0.00000, loss_test:0.10062, lr:4.71e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.337, tt:2684.522\n",
      "Ep:132, loss:0.00000, loss_test:0.10057, lr:4.66e-03, fs:0.70064 (r=0.556,p=0.948),  time:20.357, tt:2707.463\n",
      "Ep:133, loss:0.00000, loss_test:0.09965, lr:4.61e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.357, tt:2727.887\n",
      "Ep:134, loss:0.00000, loss_test:0.09991, lr:4.57e-03, fs:0.69620 (r=0.556,p=0.932),  time:20.380, tt:2751.278\n",
      "Ep:135, loss:0.00000, loss_test:0.09966, lr:4.52e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.381, tt:2771.816\n",
      "Ep:136, loss:0.00000, loss_test:0.10026, lr:4.48e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.391, tt:2793.590\n",
      "Ep:137, loss:0.00000, loss_test:0.10108, lr:4.43e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.389, tt:2813.626\n",
      "Ep:138, loss:0.00000, loss_test:0.10081, lr:4.39e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.395, tt:2834.930\n",
      "Ep:139, loss:0.00000, loss_test:0.10008, lr:4.34e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.401, tt:2856.141\n",
      "Ep:140, loss:0.00000, loss_test:0.10058, lr:4.30e-03, fs:0.68790 (r=0.545,p=0.931),  time:20.411, tt:2877.892\n",
      "Ep:141, loss:0.00000, loss_test:0.10018, lr:4.26e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.410, tt:2898.283\n",
      "Ep:142, loss:0.00000, loss_test:0.09960, lr:4.21e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.420, tt:2920.032\n",
      "Ep:143, loss:0.00000, loss_test:0.10162, lr:4.17e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.433, tt:2942.383\n",
      "Ep:144, loss:0.00000, loss_test:0.10286, lr:4.13e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.435, tt:2963.094\n",
      "Ep:145, loss:0.00000, loss_test:0.10122, lr:4.09e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.431, tt:2982.959\n",
      "Ep:146, loss:0.00000, loss_test:0.10004, lr:4.05e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.420, tt:3001.769\n",
      "Ep:147, loss:0.00000, loss_test:0.10122, lr:4.01e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.419, tt:3022.000\n",
      "Ep:148, loss:0.00000, loss_test:0.10160, lr:3.97e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.416, tt:3042.023\n",
      "Ep:149, loss:0.00000, loss_test:0.10115, lr:3.93e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.420, tt:3063.010\n",
      "Ep:150, loss:0.00000, loss_test:0.10106, lr:3.89e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.423, tt:3083.923\n",
      "Ep:151, loss:0.00000, loss_test:0.10158, lr:3.85e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.423, tt:3104.290\n",
      "Ep:152, loss:0.00000, loss_test:0.10123, lr:3.81e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.424, tt:3124.910\n",
      "Ep:153, loss:0.00000, loss_test:0.10123, lr:3.77e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.428, tt:3145.847\n",
      "Ep:154, loss:0.00000, loss_test:0.10162, lr:3.73e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.434, tt:3167.293\n",
      "Ep:155, loss:0.00000, loss_test:0.10222, lr:3.70e-03, fs:0.67949 (r=0.535,p=0.930),  time:20.443, tt:3189.131\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14024, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:26.035, tt:26.035\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13716, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:23.427, tt:46.854\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13425, lr:1.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:23.145, tt:69.435\n",
      "Ep:3, loss:0.00025, loss_test:0.13271, lr:1.00e-02, fs:0.60177 (r=0.687,p=0.535),  time:23.007, tt:92.027\n",
      "Ep:4, loss:0.00024, loss_test:0.12929, lr:1.00e-02, fs:0.59259 (r=0.646,p=0.547),  time:23.231, tt:116.154\n",
      "Ep:5, loss:0.00023, loss_test:0.12536, lr:1.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:23.022, tt:138.133\n",
      "Ep:6, loss:0.00023, loss_test:0.12311, lr:1.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:24.111, tt:168.776\n",
      "Ep:7, loss:0.00022, loss_test:0.12075, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:23.955, tt:191.637\n",
      "Ep:8, loss:0.00021, loss_test:0.11782, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:23.901, tt:215.110\n",
      "Ep:9, loss:0.00020, loss_test:0.11576, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:23.781, tt:237.813\n",
      "Ep:10, loss:0.00019, loss_test:0.11159, lr:1.00e-02, fs:0.64516 (r=0.606,p=0.690),  time:23.744, tt:261.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00018, loss_test:0.10814, lr:1.00e-02, fs:0.66667 (r=0.636,p=0.700),  time:23.703, tt:284.437\n",
      "Ep:12, loss:0.00017, loss_test:0.10569, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:23.780, tt:309.142\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.10361, lr:1.00e-02, fs:0.67027 (r=0.626,p=0.721),  time:23.845, tt:333.831\n",
      "Ep:14, loss:0.00016, loss_test:0.10212, lr:1.00e-02, fs:0.69149 (r=0.657,p=0.730),  time:23.745, tt:356.178\n",
      "Ep:15, loss:0.00015, loss_test:0.10038, lr:1.00e-02, fs:0.69892 (r=0.657,p=0.747),  time:23.889, tt:382.221\n",
      "Ep:16, loss:0.00014, loss_test:0.10004, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:23.882, tt:406.001\n",
      "Ep:17, loss:0.00014, loss_test:0.09925, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:24.046, tt:432.827\n",
      "Ep:18, loss:0.00013, loss_test:0.09886, lr:1.00e-02, fs:0.69613 (r=0.636,p=0.768),  time:24.002, tt:456.034\n",
      "Ep:19, loss:0.00013, loss_test:0.09811, lr:1.00e-02, fs:0.71111 (r=0.646,p=0.790),  time:24.185, tt:483.698\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.09750, lr:1.00e-02, fs:0.70000 (r=0.636,p=0.778),  time:24.256, tt:509.378\n",
      "Ep:21, loss:0.00011, loss_test:0.09851, lr:1.00e-02, fs:0.66279 (r=0.576,p=0.781),  time:24.222, tt:532.894\n",
      "Ep:22, loss:0.00011, loss_test:0.09666, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:24.200, tt:556.594\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.09970, lr:1.00e-02, fs:0.66667 (r=0.556,p=0.833),  time:24.139, tt:579.326\n",
      "Ep:24, loss:0.00010, loss_test:0.09482, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:24.143, tt:603.569\n",
      "Ep:25, loss:0.00010, loss_test:0.09875, lr:1.00e-02, fs:0.67073 (r=0.556,p=0.846),  time:24.160, tt:628.172\n",
      "Ep:26, loss:0.00009, loss_test:0.09395, lr:1.00e-02, fs:0.67442 (r=0.586,p=0.795),  time:24.179, tt:652.820\n",
      "Ep:27, loss:0.00009, loss_test:0.09503, lr:1.00e-02, fs:0.67470 (r=0.566,p=0.836),  time:24.198, tt:677.552\n",
      "Ep:28, loss:0.00008, loss_test:0.09551, lr:1.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:24.168, tt:700.861\n",
      "Ep:29, loss:0.00008, loss_test:0.09189, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:24.186, tt:725.580\n",
      "Ep:30, loss:0.00008, loss_test:0.09561, lr:1.00e-02, fs:0.69565 (r=0.566,p=0.903),  time:24.150, tt:748.656\n",
      "Ep:31, loss:0.00007, loss_test:0.09108, lr:1.00e-02, fs:0.70455 (r=0.626,p=0.805),  time:24.129, tt:772.144\n",
      "Ep:32, loss:0.00007, loss_test:0.09551, lr:1.00e-02, fs:0.69565 (r=0.566,p=0.903),  time:24.140, tt:796.609\n",
      "Ep:33, loss:0.00007, loss_test:0.09097, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:24.058, tt:817.965\n",
      "Ep:34, loss:0.00006, loss_test:0.09231, lr:9.90e-03, fs:0.73054 (r=0.616,p=0.897),  time:23.961, tt:838.646\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.08758, lr:9.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:23.847, tt:858.484\n",
      "Ep:36, loss:0.00006, loss_test:0.09460, lr:9.90e-03, fs:0.71951 (r=0.596,p=0.908),  time:23.726, tt:877.864\n",
      "Ep:37, loss:0.00006, loss_test:0.08867, lr:9.90e-03, fs:0.73684 (r=0.636,p=0.875),  time:23.590, tt:896.424\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.09217, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:23.564, tt:919.013\n",
      "Ep:39, loss:0.00005, loss_test:0.08932, lr:9.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:23.597, tt:943.872\n",
      "Ep:40, loss:0.00005, loss_test:0.08930, lr:9.90e-03, fs:0.72289 (r=0.606,p=0.896),  time:23.570, tt:966.364\n",
      "Ep:41, loss:0.00005, loss_test:0.08958, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:23.641, tt:992.940\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.08805, lr:9.90e-03, fs:0.73373 (r=0.626,p=0.886),  time:23.646, tt:1016.774\n",
      "Ep:43, loss:0.00004, loss_test:0.08640, lr:9.90e-03, fs:0.74251 (r=0.626,p=0.912),  time:23.646, tt:1040.435\n",
      "Ep:44, loss:0.00004, loss_test:0.08873, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:23.654, tt:1064.419\n",
      "Ep:45, loss:0.00004, loss_test:0.08586, lr:9.90e-03, fs:0.74854 (r=0.646,p=0.889),  time:23.662, tt:1088.463\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.08969, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:23.641, tt:1111.107\n",
      "Ep:47, loss:0.00004, loss_test:0.08685, lr:9.90e-03, fs:0.74118 (r=0.636,p=0.887),  time:23.629, tt:1134.203\n",
      "Ep:48, loss:0.00003, loss_test:0.08778, lr:9.90e-03, fs:0.73810 (r=0.626,p=0.899),  time:23.658, tt:1159.260\n",
      "Ep:49, loss:0.00003, loss_test:0.08749, lr:9.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:23.659, tt:1182.975\n",
      "Ep:50, loss:0.00003, loss_test:0.08503, lr:9.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:23.667, tt:1207.039\n",
      "Ep:51, loss:0.00003, loss_test:0.08788, lr:9.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:23.625, tt:1228.518\n",
      "Ep:52, loss:0.00003, loss_test:0.08447, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:23.629, tt:1252.341\n",
      "Ep:53, loss:0.00003, loss_test:0.08648, lr:9.90e-03, fs:0.75904 (r=0.636,p=0.940),  time:23.642, tt:1276.692\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.08678, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:23.673, tt:1302.012\n",
      "Ep:55, loss:0.00003, loss_test:0.08422, lr:9.90e-03, fs:0.73171 (r=0.606,p=0.923),  time:23.695, tt:1326.924\n",
      "Ep:56, loss:0.00003, loss_test:0.08649, lr:9.90e-03, fs:0.75610 (r=0.626,p=0.954),  time:23.723, tt:1352.183\n",
      "Ep:57, loss:0.00002, loss_test:0.08455, lr:9.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:23.753, tt:1377.670\n",
      "Ep:58, loss:0.00002, loss_test:0.08504, lr:9.90e-03, fs:0.77381 (r=0.657,p=0.942),  time:23.747, tt:1401.045\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.08643, lr:9.90e-03, fs:0.69620 (r=0.556,p=0.932),  time:23.771, tt:1426.265\n",
      "Ep:60, loss:0.00002, loss_test:0.08165, lr:9.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:23.741, tt:1448.213\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.08513, lr:9.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:23.765, tt:1473.437\n",
      "Ep:62, loss:0.00002, loss_test:0.08370, lr:9.90e-03, fs:0.74074 (r=0.606,p=0.952),  time:23.806, tt:1499.748\n",
      "Ep:63, loss:0.00002, loss_test:0.08251, lr:9.90e-03, fs:0.74390 (r=0.616,p=0.938),  time:23.789, tt:1522.498\n",
      "Ep:64, loss:0.00002, loss_test:0.08435, lr:9.90e-03, fs:0.73292 (r=0.596,p=0.952),  time:23.792, tt:1546.482\n",
      "Ep:65, loss:0.00002, loss_test:0.08131, lr:9.90e-03, fs:0.78107 (r=0.667,p=0.943),  time:23.765, tt:1568.502\n",
      "Ep:66, loss:0.00002, loss_test:0.08446, lr:9.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:23.767, tt:1592.379\n",
      "Ep:67, loss:0.00002, loss_test:0.08281, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:23.750, tt:1615.020\n",
      "Ep:68, loss:0.00002, loss_test:0.08428, lr:9.90e-03, fs:0.73292 (r=0.596,p=0.952),  time:23.770, tt:1640.118\n",
      "Ep:69, loss:0.00002, loss_test:0.08301, lr:9.90e-03, fs:0.74847 (r=0.616,p=0.953),  time:23.749, tt:1662.407\n",
      "Ep:70, loss:0.00001, loss_test:0.08448, lr:9.90e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.767, tt:1687.478\n",
      "Ep:71, loss:0.00001, loss_test:0.08331, lr:9.90e-03, fs:0.70440 (r=0.566,p=0.933),  time:23.794, tt:1713.174\n",
      "Ep:72, loss:0.00001, loss_test:0.08164, lr:9.80e-03, fs:0.73292 (r=0.596,p=0.952),  time:23.769, tt:1735.141\n",
      "Ep:73, loss:0.00001, loss_test:0.08504, lr:9.70e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.807, tt:1761.741\n",
      "Ep:74, loss:0.00001, loss_test:0.08376, lr:9.61e-03, fs:0.72500 (r=0.586,p=0.951),  time:23.810, tt:1785.741\n",
      "Ep:75, loss:0.00001, loss_test:0.08165, lr:9.51e-03, fs:0.70440 (r=0.566,p=0.933),  time:23.814, tt:1809.856\n",
      "Ep:76, loss:0.00001, loss_test:0.08539, lr:9.41e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.807, tt:1833.165\n",
      "Ep:77, loss:0.00001, loss_test:0.08290, lr:9.32e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.821, tt:1858.038\n",
      "Ep:78, loss:0.00001, loss_test:0.08407, lr:9.23e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.838, tt:1883.240\n",
      "Ep:79, loss:0.00001, loss_test:0.08349, lr:9.14e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.829, tt:1906.355\n",
      "Ep:80, loss:0.00001, loss_test:0.08454, lr:9.04e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.831, tt:1930.324\n",
      "Ep:81, loss:0.00001, loss_test:0.08354, lr:8.95e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.857, tt:1956.307\n",
      "Ep:82, loss:0.00001, loss_test:0.08255, lr:8.86e-03, fs:0.71698 (r=0.576,p=0.950),  time:23.876, tt:1981.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.08430, lr:8.78e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.857, tt:2003.981\n",
      "Ep:84, loss:0.00001, loss_test:0.08245, lr:8.69e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.857, tt:2027.877\n",
      "Ep:85, loss:0.00001, loss_test:0.08488, lr:8.60e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.846, tt:2050.736\n",
      "Ep:86, loss:0.00001, loss_test:0.08289, lr:8.51e-03, fs:0.71698 (r=0.576,p=0.950),  time:23.862, tt:2075.963\n",
      "Ep:87, loss:0.00001, loss_test:0.08561, lr:8.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.885, tt:2101.855\n",
      "Ep:88, loss:0.00001, loss_test:0.08656, lr:8.35e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.886, tt:2125.815\n",
      "Ep:89, loss:0.00001, loss_test:0.08420, lr:8.26e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.897, tt:2150.716\n",
      "Ep:90, loss:0.00001, loss_test:0.08596, lr:8.18e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.877, tt:2172.794\n",
      "Ep:91, loss:0.00001, loss_test:0.08448, lr:8.10e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.893, tt:2198.195\n",
      "Ep:92, loss:0.00001, loss_test:0.08542, lr:8.02e-03, fs:0.70064 (r=0.556,p=0.948),  time:23.876, tt:2220.423\n",
      "Ep:93, loss:0.00001, loss_test:0.08501, lr:7.94e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.889, tt:2245.531\n",
      "Ep:94, loss:0.00001, loss_test:0.08496, lr:7.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.879, tt:2268.530\n",
      "Ep:95, loss:0.00001, loss_test:0.08534, lr:7.78e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.882, tt:2292.655\n",
      "Ep:96, loss:0.00001, loss_test:0.08546, lr:7.70e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.888, tt:2317.095\n",
      "Ep:97, loss:0.00001, loss_test:0.08639, lr:7.62e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.875, tt:2339.747\n",
      "Ep:98, loss:0.00001, loss_test:0.08522, lr:7.55e-03, fs:0.70886 (r=0.566,p=0.949),  time:23.875, tt:2363.598\n",
      "Ep:99, loss:0.00001, loss_test:0.08629, lr:7.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.870, tt:2386.990\n",
      "Ep:100, loss:0.00001, loss_test:0.08808, lr:7.40e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.884, tt:2412.284\n",
      "Ep:101, loss:0.00001, loss_test:0.08758, lr:7.32e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.870, tt:2434.756\n",
      "Ep:102, loss:0.00001, loss_test:0.08597, lr:7.25e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.875, tt:2459.129\n",
      "Ep:103, loss:0.00001, loss_test:0.08739, lr:7.18e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.865, tt:2481.913\n",
      "Ep:104, loss:0.00001, loss_test:0.08973, lr:7.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.880, tt:2507.440\n",
      "Ep:105, loss:0.00001, loss_test:0.08711, lr:7.03e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.892, tt:2532.510\n",
      "Ep:106, loss:0.00001, loss_test:0.08705, lr:6.96e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.879, tt:2555.015\n",
      "Ep:107, loss:0.00001, loss_test:0.08760, lr:6.89e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.882, tt:2579.237\n",
      "Ep:108, loss:0.00001, loss_test:0.08583, lr:6.83e-03, fs:0.69231 (r=0.545,p=0.947),  time:23.878, tt:2602.750\n",
      "Ep:109, loss:0.00001, loss_test:0.08781, lr:6.76e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.893, tt:2628.185\n",
      "Ep:110, loss:0.00000, loss_test:0.08775, lr:6.69e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.887, tt:2651.487\n",
      "Ep:111, loss:0.00000, loss_test:0.08672, lr:6.62e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.894, tt:2676.176\n",
      "Ep:112, loss:0.00000, loss_test:0.08589, lr:6.56e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.885, tt:2698.986\n",
      "Ep:113, loss:0.00000, loss_test:0.08693, lr:6.49e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.886, tt:2723.060\n",
      "Ep:114, loss:0.00000, loss_test:0.08777, lr:6.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.893, tt:2747.638\n",
      "Ep:115, loss:0.00000, loss_test:0.08639, lr:6.36e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.895, tt:2771.790\n",
      "Ep:116, loss:0.00000, loss_test:0.08792, lr:6.30e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.898, tt:2796.015\n",
      "Ep:117, loss:0.00000, loss_test:0.08884, lr:6.24e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.891, tt:2819.179\n",
      "Ep:118, loss:0.00000, loss_test:0.08660, lr:6.17e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.908, tt:2845.110\n",
      "Ep:119, loss:0.00000, loss_test:0.08705, lr:6.11e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.898, tt:2867.703\n",
      "Ep:120, loss:0.00000, loss_test:0.08818, lr:6.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.922, tt:2894.587\n",
      "Ep:121, loss:0.00000, loss_test:0.08671, lr:5.99e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.911, tt:2917.106\n",
      "Ep:122, loss:0.00000, loss_test:0.08722, lr:5.93e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.928, tt:2943.146\n",
      "Ep:123, loss:0.00000, loss_test:0.08713, lr:5.87e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.930, tt:2967.374\n",
      "Ep:124, loss:0.00000, loss_test:0.08764, lr:5.81e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.925, tt:2990.634\n",
      "Ep:125, loss:0.00000, loss_test:0.08660, lr:5.75e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.935, tt:3015.833\n",
      "Ep:126, loss:0.00000, loss_test:0.08615, lr:5.70e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.927, tt:3038.782\n",
      "Ep:127, loss:0.00000, loss_test:0.08785, lr:5.64e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.943, tt:3064.749\n",
      "Ep:128, loss:0.00000, loss_test:0.08687, lr:5.58e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.949, tt:3089.465\n",
      "Ep:129, loss:0.00000, loss_test:0.08815, lr:5.53e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.971, tt:3116.168\n",
      "Ep:130, loss:0.00000, loss_test:0.08799, lr:5.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.968, tt:3139.812\n",
      "Ep:131, loss:0.00000, loss_test:0.08688, lr:5.42e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.957, tt:3162.261\n",
      "Ep:132, loss:0.00000, loss_test:0.08790, lr:5.36e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.959, tt:3186.520\n",
      "Ep:133, loss:0.00000, loss_test:0.08729, lr:5.31e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.945, tt:3208.578\n",
      "Ep:134, loss:0.00000, loss_test:0.08638, lr:5.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.958, tt:3234.305\n",
      "Ep:135, loss:0.00000, loss_test:0.08855, lr:5.20e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.945, tt:3256.514\n",
      "Ep:136, loss:0.00000, loss_test:0.08833, lr:5.15e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.955, tt:3281.857\n",
      "Ep:137, loss:0.00000, loss_test:0.08773, lr:5.10e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.961, tt:3306.552\n",
      "Ep:138, loss:0.00000, loss_test:0.08787, lr:5.05e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.967, tt:3331.393\n",
      "Ep:139, loss:0.00000, loss_test:0.08741, lr:5.00e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.956, tt:3353.799\n",
      "Ep:140, loss:0.00000, loss_test:0.08759, lr:4.95e-03, fs:0.68831 (r=0.535,p=0.964),  time:23.960, tt:3378.335\n",
      "Ep:141, loss:0.00000, loss_test:0.08862, lr:4.90e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.965, tt:3403.054\n",
      "Ep:142, loss:0.00000, loss_test:0.08872, lr:4.85e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.967, tt:3427.325\n",
      "Ep:143, loss:0.00000, loss_test:0.08819, lr:4.80e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.967, tt:3451.260\n",
      "Ep:144, loss:0.00000, loss_test:0.08791, lr:4.75e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.952, tt:3473.012\n",
      "Ep:145, loss:0.00000, loss_test:0.08802, lr:4.71e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.962, tt:3498.401\n",
      "Ep:146, loss:0.00000, loss_test:0.08841, lr:4.66e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.962, tt:3522.419\n",
      "Ep:147, loss:0.00000, loss_test:0.08859, lr:4.61e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.971, tt:3547.754\n",
      "Ep:148, loss:0.00000, loss_test:0.08863, lr:4.57e-03, fs:0.68831 (r=0.535,p=0.964),  time:23.973, tt:3571.952\n",
      "Ep:149, loss:0.00000, loss_test:0.08731, lr:4.52e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.972, tt:3595.732\n",
      "Ep:150, loss:0.00000, loss_test:0.08843, lr:4.48e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.984, tt:3621.632\n",
      "Ep:151, loss:0.00000, loss_test:0.08864, lr:4.43e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.968, tt:3643.108\n",
      "Ep:152, loss:0.00000, loss_test:0.08755, lr:4.39e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.977, tt:3668.528\n",
      "Ep:153, loss:0.00000, loss_test:0.08824, lr:4.34e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.973, tt:3691.851\n",
      "Ep:154, loss:0.00000, loss_test:0.08804, lr:4.30e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.989, tt:3718.369\n",
      "Ep:155, loss:0.00000, loss_test:0.08803, lr:4.26e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.980, tt:3740.854\n",
      "Ep:156, loss:0.00000, loss_test:0.08852, lr:4.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:23.990, tt:3766.356\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14504, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:40.494, tt:40.494\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14392, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:41.806, tt:83.612\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.14182, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:42.290, tt:126.870\n",
      "Ep:3, loss:0.00027, loss_test:0.13835, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:42.056, tt:168.225\n",
      "Ep:4, loss:0.00027, loss_test:0.13303, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:42.040, tt:210.201\n",
      "Ep:5, loss:0.00026, loss_test:0.12483, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:42.479, tt:254.876\n",
      "Ep:6, loss:0.00024, loss_test:0.11488, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:42.441, tt:297.086\n",
      "Ep:7, loss:0.00022, loss_test:0.11165, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:42.688, tt:341.508\n",
      "Ep:8, loss:0.00021, loss_test:0.11296, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:42.847, tt:385.626\n",
      "Ep:9, loss:0.00021, loss_test:0.11226, lr:1.00e-02, fs:0.65700 (r=0.687,p=0.630),  time:43.014, tt:430.140\n",
      "Ep:10, loss:0.00020, loss_test:0.11004, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:43.012, tt:473.128\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10817, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:43.118, tt:517.412\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10562, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:43.061, tt:559.797\n",
      "Ep:13, loss:0.00018, loss_test:0.10467, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:43.020, tt:602.284\n",
      "Ep:14, loss:0.00018, loss_test:0.10419, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:43.047, tt:645.702\n",
      "Ep:15, loss:0.00017, loss_test:0.10353, lr:1.00e-02, fs:0.68394 (r=0.667,p=0.702),  time:43.094, tt:689.509\n",
      "Ep:16, loss:0.00017, loss_test:0.10305, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:43.067, tt:732.144\n",
      "Ep:17, loss:0.00017, loss_test:0.10294, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:43.025, tt:774.448\n",
      "Ep:18, loss:0.00016, loss_test:0.10324, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:42.880, tt:814.727\n",
      "Ep:19, loss:0.00016, loss_test:0.10261, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:42.858, tt:857.153\n",
      "Ep:20, loss:0.00015, loss_test:0.10266, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:42.884, tt:900.564\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.10207, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:42.886, tt:943.502\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.10158, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:42.911, tt:986.948\n",
      "Ep:23, loss:0.00014, loss_test:0.10327, lr:1.00e-02, fs:0.67742 (r=0.636,p=0.724),  time:42.790, tt:1026.949\n",
      "Ep:24, loss:0.00014, loss_test:0.10307, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:42.696, tt:1067.393\n",
      "Ep:25, loss:0.00014, loss_test:0.10218, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:42.694, tt:1110.040\n",
      "Ep:26, loss:0.00013, loss_test:0.10307, lr:1.00e-02, fs:0.65608 (r=0.626,p=0.689),  time:42.639, tt:1151.243\n",
      "Ep:27, loss:0.00013, loss_test:0.10082, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:42.692, tt:1195.368\n",
      "Ep:28, loss:0.00013, loss_test:0.10239, lr:1.00e-02, fs:0.66667 (r=0.606,p=0.741),  time:42.669, tt:1237.392\n",
      "Ep:29, loss:0.00012, loss_test:0.10095, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:42.652, tt:1279.572\n",
      "Ep:30, loss:0.00012, loss_test:0.10152, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:42.626, tt:1321.400\n",
      "Ep:31, loss:0.00012, loss_test:0.10209, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:42.591, tt:1362.915\n",
      "Ep:32, loss:0.00011, loss_test:0.10353, lr:1.00e-02, fs:0.67816 (r=0.596,p=0.787),  time:42.601, tt:1405.847\n",
      "Ep:33, loss:0.00011, loss_test:0.10140, lr:9.90e-03, fs:0.68852 (r=0.636,p=0.750),  time:42.516, tt:1445.538\n",
      "Ep:34, loss:0.00011, loss_test:0.10484, lr:9.80e-03, fs:0.68571 (r=0.606,p=0.789),  time:42.500, tt:1487.502\n",
      "Ep:35, loss:0.00011, loss_test:0.10522, lr:9.70e-03, fs:0.67778 (r=0.616,p=0.753),  time:42.475, tt:1529.098\n",
      "Ep:36, loss:0.00011, loss_test:0.10190, lr:9.61e-03, fs:0.71111 (r=0.646,p=0.790),  time:42.494, tt:1572.272\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.10848, lr:9.61e-03, fs:0.68571 (r=0.606,p=0.789),  time:42.438, tt:1612.643\n",
      "Ep:38, loss:0.00010, loss_test:0.10221, lr:9.61e-03, fs:0.71038 (r=0.657,p=0.774),  time:42.364, tt:1652.196\n",
      "Ep:39, loss:0.00010, loss_test:0.10831, lr:9.61e-03, fs:0.69412 (r=0.596,p=0.831),  time:42.345, tt:1693.819\n",
      "Ep:40, loss:0.00010, loss_test:0.10504, lr:9.61e-03, fs:0.69663 (r=0.626,p=0.785),  time:42.407, tt:1738.683\n",
      "Ep:41, loss:0.00009, loss_test:0.10736, lr:9.61e-03, fs:0.70588 (r=0.606,p=0.845),  time:42.421, tt:1781.682\n",
      "Ep:42, loss:0.00009, loss_test:0.10621, lr:9.61e-03, fs:0.70857 (r=0.626,p=0.816),  time:42.438, tt:1824.816\n",
      "Ep:43, loss:0.00009, loss_test:0.10494, lr:9.61e-03, fs:0.69767 (r=0.606,p=0.822),  time:42.386, tt:1864.986\n",
      "Ep:44, loss:0.00009, loss_test:0.10738, lr:9.61e-03, fs:0.69412 (r=0.596,p=0.831),  time:42.311, tt:1904.009\n",
      "Ep:45, loss:0.00009, loss_test:0.10475, lr:9.61e-03, fs:0.70455 (r=0.626,p=0.805),  time:42.356, tt:1948.392\n",
      "Ep:46, loss:0.00008, loss_test:0.10837, lr:9.61e-03, fs:0.68571 (r=0.606,p=0.789),  time:42.374, tt:1991.571\n",
      "Ep:47, loss:0.00009, loss_test:0.10668, lr:9.61e-03, fs:0.69822 (r=0.596,p=0.843),  time:42.386, tt:2034.515\n",
      "Ep:48, loss:0.00008, loss_test:0.10456, lr:9.51e-03, fs:0.70455 (r=0.626,p=0.805),  time:42.361, tt:2075.670\n",
      "Ep:49, loss:0.00008, loss_test:0.10773, lr:9.41e-03, fs:0.70659 (r=0.596,p=0.868),  time:42.314, tt:2115.699\n",
      "Ep:50, loss:0.00008, loss_test:0.10518, lr:9.32e-03, fs:0.68927 (r=0.616,p=0.782),  time:42.292, tt:2156.912\n",
      "Ep:51, loss:0.00007, loss_test:0.10882, lr:9.23e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.270, tt:2198.054\n",
      "Ep:52, loss:0.00008, loss_test:0.10618, lr:9.14e-03, fs:0.70857 (r=0.626,p=0.816),  time:42.287, tt:2241.197\n",
      "Ep:53, loss:0.00007, loss_test:0.11248, lr:9.04e-03, fs:0.66265 (r=0.556,p=0.821),  time:42.248, tt:2281.393\n",
      "Ep:54, loss:0.00007, loss_test:0.10388, lr:8.95e-03, fs:0.69318 (r=0.616,p=0.792),  time:42.197, tt:2320.813\n",
      "Ep:55, loss:0.00007, loss_test:0.10902, lr:8.86e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.136, tt:2359.628\n",
      "Ep:56, loss:0.00007, loss_test:0.10877, lr:8.78e-03, fs:0.69364 (r=0.606,p=0.811),  time:42.106, tt:2400.036\n",
      "Ep:57, loss:0.00007, loss_test:0.10760, lr:8.69e-03, fs:0.69880 (r=0.586,p=0.866),  time:42.096, tt:2441.595\n",
      "Ep:58, loss:0.00007, loss_test:0.10896, lr:8.60e-03, fs:0.66667 (r=0.566,p=0.812),  time:42.071, tt:2482.178\n",
      "Ep:59, loss:0.00007, loss_test:0.10758, lr:8.51e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.059, tt:2523.568\n",
      "Ep:60, loss:0.00006, loss_test:0.10938, lr:8.43e-03, fs:0.67857 (r=0.576,p=0.826),  time:42.041, tt:2564.507\n",
      "Ep:61, loss:0.00006, loss_test:0.11047, lr:8.35e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.012, tt:2604.763\n",
      "Ep:62, loss:0.00006, loss_test:0.10567, lr:8.26e-03, fs:0.70520 (r=0.616,p=0.824),  time:41.994, tt:2645.606\n",
      "Ep:63, loss:0.00006, loss_test:0.11275, lr:8.18e-03, fs:0.65854 (r=0.545,p=0.831),  time:42.017, tt:2689.057\n",
      "Ep:64, loss:0.00006, loss_test:0.10811, lr:8.10e-03, fs:0.68263 (r=0.576,p=0.838),  time:42.044, tt:2732.872\n",
      "Ep:65, loss:0.00006, loss_test:0.11131, lr:8.02e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.064, tt:2776.233\n",
      "Ep:66, loss:0.00006, loss_test:0.11067, lr:7.94e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.049, tt:2817.279\n",
      "Ep:67, loss:0.00005, loss_test:0.10915, lr:7.86e-03, fs:0.68675 (r=0.576,p=0.851),  time:42.046, tt:2859.102\n",
      "Ep:68, loss:0.00005, loss_test:0.10985, lr:7.78e-03, fs:0.67066 (r=0.566,p=0.824),  time:42.054, tt:2901.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00005, loss_test:0.10963, lr:7.70e-03, fs:0.69091 (r=0.576,p=0.864),  time:42.091, tt:2946.398\n",
      "Ep:70, loss:0.00006, loss_test:0.11033, lr:7.62e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.101, tt:2989.200\n",
      "Ep:71, loss:0.00005, loss_test:0.11094, lr:7.55e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.102, tt:3031.343\n",
      "Ep:72, loss:0.00005, loss_test:0.11368, lr:7.47e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.109, tt:3073.938\n",
      "Ep:73, loss:0.00005, loss_test:0.10983, lr:7.40e-03, fs:0.67470 (r=0.566,p=0.836),  time:42.133, tt:3117.823\n",
      "Ep:74, loss:0.00005, loss_test:0.11364, lr:7.32e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.166, tt:3162.441\n",
      "Ep:75, loss:0.00005, loss_test:0.11469, lr:7.25e-03, fs:0.65031 (r=0.535,p=0.828),  time:42.161, tt:3204.240\n",
      "Ep:76, loss:0.00005, loss_test:0.11035, lr:7.18e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.159, tt:3246.236\n",
      "Ep:77, loss:0.00005, loss_test:0.11709, lr:7.11e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.183, tt:3290.243\n",
      "Ep:78, loss:0.00004, loss_test:0.11285, lr:7.03e-03, fs:0.67879 (r=0.566,p=0.848),  time:42.199, tt:3333.747\n",
      "Ep:79, loss:0.00004, loss_test:0.11207, lr:6.96e-03, fs:0.67073 (r=0.556,p=0.846),  time:42.249, tt:3379.954\n",
      "Ep:80, loss:0.00004, loss_test:0.11555, lr:6.89e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.287, tt:3425.286\n",
      "Ep:81, loss:0.00004, loss_test:0.11368, lr:6.83e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.302, tt:3468.799\n",
      "Ep:82, loss:0.00004, loss_test:0.11291, lr:6.76e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.301, tt:3510.984\n",
      "Ep:83, loss:0.00004, loss_test:0.11431, lr:6.69e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.336, tt:3556.189\n",
      "Ep:84, loss:0.00004, loss_test:0.11412, lr:6.62e-03, fs:0.65432 (r=0.535,p=0.841),  time:42.368, tt:3601.263\n",
      "Ep:85, loss:0.00004, loss_test:0.11200, lr:6.56e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.330, tt:3640.373\n",
      "Ep:86, loss:0.00004, loss_test:0.11663, lr:6.49e-03, fs:0.64198 (r=0.525,p=0.825),  time:42.311, tt:3681.029\n",
      "Ep:87, loss:0.00004, loss_test:0.11305, lr:6.43e-03, fs:0.67901 (r=0.556,p=0.873),  time:42.238, tt:3716.936\n",
      "Ep:88, loss:0.00004, loss_test:0.11340, lr:6.36e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.283, tt:3763.196\n",
      "Ep:89, loss:0.00004, loss_test:0.11248, lr:6.30e-03, fs:0.67073 (r=0.556,p=0.846),  time:42.329, tt:3809.630\n",
      "Ep:90, loss:0.00004, loss_test:0.11352, lr:6.24e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.348, tt:3853.650\n",
      "Ep:91, loss:0.00004, loss_test:0.11239, lr:6.17e-03, fs:0.66258 (r=0.545,p=0.844),  time:42.387, tt:3899.636\n",
      "Ep:92, loss:0.00004, loss_test:0.11655, lr:6.11e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.415, tt:3944.612\n",
      "Ep:93, loss:0.00004, loss_test:0.11319, lr:6.05e-03, fs:0.67485 (r=0.556,p=0.859),  time:42.420, tt:3987.464\n",
      "Ep:94, loss:0.00004, loss_test:0.11450, lr:5.99e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.434, tt:4031.272\n",
      "Ep:95, loss:0.00004, loss_test:0.11483, lr:5.93e-03, fs:0.64151 (r=0.515,p=0.850),  time:42.468, tt:4076.920\n",
      "Ep:96, loss:0.00003, loss_test:0.11456, lr:5.87e-03, fs:0.66667 (r=0.545,p=0.857),  time:42.486, tt:4121.185\n",
      "Ep:97, loss:0.00003, loss_test:0.11624, lr:5.81e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.513, tt:4166.289\n",
      "Ep:98, loss:0.00003, loss_test:0.11464, lr:5.75e-03, fs:0.65432 (r=0.535,p=0.841),  time:42.539, tt:4211.408\n",
      "Ep:99, loss:0.00003, loss_test:0.11666, lr:5.70e-03, fs:0.64968 (r=0.515,p=0.879),  time:42.563, tt:4256.327\n",
      "Ep:100, loss:0.00003, loss_test:0.11584, lr:5.64e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.600, tt:4302.638\n",
      "Ep:101, loss:0.00003, loss_test:0.11577, lr:5.58e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.627, tt:4347.938\n",
      "Ep:102, loss:0.00003, loss_test:0.11749, lr:5.53e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.661, tt:4394.097\n",
      "Ep:103, loss:0.00003, loss_test:0.11494, lr:5.47e-03, fs:0.65432 (r=0.535,p=0.841),  time:42.689, tt:4439.660\n",
      "Ep:104, loss:0.00003, loss_test:0.11507, lr:5.42e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.701, tt:4483.640\n",
      "Ep:105, loss:0.00003, loss_test:0.11629, lr:5.36e-03, fs:0.65000 (r=0.525,p=0.852),  time:42.733, tt:4529.700\n",
      "Ep:106, loss:0.00003, loss_test:0.11445, lr:5.31e-03, fs:0.67081 (r=0.545,p=0.871),  time:42.743, tt:4573.463\n",
      "Ep:107, loss:0.00003, loss_test:0.11552, lr:5.26e-03, fs:0.65000 (r=0.525,p=0.852),  time:42.769, tt:4619.026\n",
      "Ep:108, loss:0.00003, loss_test:0.11539, lr:5.20e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.785, tt:4663.517\n",
      "Ep:109, loss:0.00003, loss_test:0.11541, lr:5.15e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.811, tt:4709.228\n",
      "Ep:110, loss:0.00003, loss_test:0.11573, lr:5.10e-03, fs:0.65000 (r=0.525,p=0.852),  time:42.845, tt:4755.847\n",
      "Ep:111, loss:0.00003, loss_test:0.11478, lr:5.05e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.868, tt:4801.195\n",
      "Ep:112, loss:0.00003, loss_test:0.11634, lr:5.00e-03, fs:0.64596 (r=0.525,p=0.839),  time:42.884, tt:4845.930\n",
      "Ep:113, loss:0.00003, loss_test:0.11494, lr:4.95e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.892, tt:4889.705\n",
      "Ep:114, loss:0.00003, loss_test:0.11530, lr:4.90e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.904, tt:4933.988\n",
      "Ep:115, loss:0.00003, loss_test:0.11658, lr:4.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:42.923, tt:4979.051\n",
      "Ep:116, loss:0.00003, loss_test:0.11576, lr:4.80e-03, fs:0.65839 (r=0.535,p=0.855),  time:42.941, tt:5024.058\n",
      "Ep:117, loss:0.00003, loss_test:0.11450, lr:4.75e-03, fs:0.66250 (r=0.535,p=0.869),  time:42.973, tt:5070.818\n",
      "Ep:118, loss:0.00003, loss_test:0.11716, lr:4.71e-03, fs:0.65409 (r=0.525,p=0.867),  time:42.999, tt:5116.910\n",
      "Ep:119, loss:0.00003, loss_test:0.11651, lr:4.66e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.025, tt:5163.023\n",
      "Ep:120, loss:0.00003, loss_test:0.11537, lr:4.61e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.032, tt:5206.837\n",
      "Ep:121, loss:0.00003, loss_test:0.11683, lr:4.57e-03, fs:0.63694 (r=0.505,p=0.862),  time:43.058, tt:5253.132\n",
      "Ep:122, loss:0.00003, loss_test:0.11514, lr:4.52e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.071, tt:5297.677\n",
      "Ep:123, loss:0.00003, loss_test:0.11646, lr:4.48e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.078, tt:5341.659\n",
      "Ep:124, loss:0.00003, loss_test:0.11666, lr:4.43e-03, fs:0.64968 (r=0.515,p=0.879),  time:43.092, tt:5386.528\n",
      "Ep:125, loss:0.00003, loss_test:0.11476, lr:4.39e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.112, tt:5432.154\n",
      "Ep:126, loss:0.00002, loss_test:0.11631, lr:4.34e-03, fs:0.64968 (r=0.515,p=0.879),  time:43.132, tt:5477.742\n",
      "Ep:127, loss:0.00002, loss_test:0.11672, lr:4.30e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.158, tt:5524.257\n",
      "Ep:128, loss:0.00002, loss_test:0.11607, lr:4.26e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.172, tt:5569.239\n",
      "Ep:129, loss:0.00002, loss_test:0.11632, lr:4.21e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.183, tt:5613.807\n",
      "Ep:130, loss:0.00002, loss_test:0.11611, lr:4.17e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.225, tt:5662.468\n",
      "Ep:131, loss:0.00002, loss_test:0.11607, lr:4.13e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.236, tt:5707.216\n",
      "Ep:132, loss:0.00002, loss_test:0.11723, lr:4.09e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.233, tt:5749.995\n",
      "Ep:133, loss:0.00002, loss_test:0.11687, lr:4.05e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.240, tt:5794.132\n",
      "Ep:134, loss:0.00002, loss_test:0.11693, lr:4.01e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.255, tt:5839.484\n",
      "Ep:135, loss:0.00002, loss_test:0.11779, lr:3.97e-03, fs:0.63694 (r=0.505,p=0.862),  time:43.278, tt:5885.823\n",
      "Ep:136, loss:0.00002, loss_test:0.11780, lr:3.93e-03, fs:0.64557 (r=0.515,p=0.864),  time:43.306, tt:5932.959\n",
      "Ep:137, loss:0.00002, loss_test:0.11605, lr:3.89e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.304, tt:5975.972\n",
      "Ep:138, loss:0.00002, loss_test:0.11725, lr:3.85e-03, fs:0.64557 (r=0.515,p=0.864),  time:43.325, tt:6022.160\n",
      "Ep:139, loss:0.00002, loss_test:0.11764, lr:3.81e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.337, tt:6067.227\n",
      "Ep:140, loss:0.00002, loss_test:0.11653, lr:3.77e-03, fs:0.65839 (r=0.535,p=0.855),  time:43.362, tt:6114.102\n",
      "Ep:141, loss:0.00002, loss_test:0.11812, lr:3.73e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.371, tt:6158.690\n",
      "Ep:142, loss:0.00002, loss_test:0.11642, lr:3.70e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.378, tt:6203.022\n",
      "Ep:143, loss:0.00002, loss_test:0.11702, lr:3.66e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.383, tt:6247.190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00002, loss_test:0.11695, lr:3.62e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.381, tt:6290.261\n",
      "Ep:145, loss:0.00002, loss_test:0.11722, lr:3.59e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.404, tt:6336.937\n",
      "Ep:146, loss:0.00002, loss_test:0.11645, lr:3.55e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.410, tt:6381.268\n",
      "Ep:147, loss:0.00002, loss_test:0.11709, lr:3.52e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.428, tt:6427.383\n",
      "Ep:148, loss:0.00002, loss_test:0.11751, lr:3.48e-03, fs:0.64968 (r=0.515,p=0.879),  time:43.419, tt:6469.449\n",
      "Ep:149, loss:0.00002, loss_test:0.11706, lr:3.45e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.422, tt:6513.319\n",
      "Ep:150, loss:0.00002, loss_test:0.11638, lr:3.41e-03, fs:0.66250 (r=0.535,p=0.869),  time:43.414, tt:6555.442\n",
      "Ep:151, loss:0.00002, loss_test:0.11781, lr:3.38e-03, fs:0.64103 (r=0.505,p=0.877),  time:43.420, tt:6599.798\n",
      "Ep:152, loss:0.00002, loss_test:0.11742, lr:3.34e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.412, tt:6641.986\n",
      "Ep:153, loss:0.00002, loss_test:0.11624, lr:3.31e-03, fs:0.65823 (r=0.525,p=0.881),  time:43.421, tt:6686.813\n",
      "Ep:154, loss:0.00002, loss_test:0.11657, lr:3.28e-03, fs:0.66667 (r=0.535,p=0.883),  time:43.438, tt:6732.851\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13769, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:14.894, tt:14.894\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13468, lr:1.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:15.473, tt:30.945\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13105, lr:1.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:16.484, tt:49.451\n",
      "Ep:3, loss:0.00025, loss_test:0.12813, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:17.784, tt:71.135\n",
      "Ep:4, loss:0.00025, loss_test:0.12516, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:17.897, tt:89.483\n",
      "Ep:5, loss:0.00024, loss_test:0.12281, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:17.837, tt:107.021\n",
      "Ep:6, loss:0.00024, loss_test:0.11954, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:17.982, tt:125.872\n",
      "Ep:7, loss:0.00023, loss_test:0.11559, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:17.919, tt:143.352\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11232, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:17.841, tt:160.567\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10963, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:17.788, tt:177.882\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10734, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:17.766, tt:195.426\n",
      "Ep:11, loss:0.00020, loss_test:0.10434, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:18.101, tt:217.213\n",
      "Ep:12, loss:0.00020, loss_test:0.10215, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:18.011, tt:234.149\n",
      "Ep:13, loss:0.00019, loss_test:0.09978, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:18.225, tt:255.152\n",
      "Ep:14, loss:0.00019, loss_test:0.09807, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:18.232, tt:273.479\n",
      "Ep:15, loss:0.00018, loss_test:0.09682, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:18.155, tt:290.475\n",
      "Ep:16, loss:0.00018, loss_test:0.09604, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:18.148, tt:308.523\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09400, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:18.234, tt:328.203\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09290, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:18.178, tt:345.379\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09262, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:18.226, tt:364.528\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09243, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:18.160, tt:381.354\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09198, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:18.251, tt:401.523\n",
      "Ep:22, loss:0.00015, loss_test:0.09142, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:18.358, tt:422.243\n",
      "Ep:23, loss:0.00015, loss_test:0.09053, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:18.290, tt:438.967\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09053, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:18.244, tt:456.091\n",
      "Ep:25, loss:0.00014, loss_test:0.08964, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:18.191, tt:472.962\n",
      "Ep:26, loss:0.00013, loss_test:0.08829, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:18.211, tt:491.685\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08779, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:18.215, tt:510.034\n",
      "Ep:28, loss:0.00012, loss_test:0.08794, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:18.279, tt:530.089\n",
      "Ep:29, loss:0.00012, loss_test:0.08652, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:18.227, tt:546.802\n",
      "Ep:30, loss:0.00012, loss_test:0.08523, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:18.280, tt:566.678\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08477, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:18.320, tt:586.235\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08421, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:18.396, tt:607.078\n",
      "Ep:33, loss:0.00010, loss_test:0.08425, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:18.480, tt:628.333\n",
      "Ep:34, loss:0.00010, loss_test:0.08259, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:18.537, tt:648.785\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08243, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:18.532, tt:667.141\n",
      "Ep:36, loss:0.00010, loss_test:0.08276, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:18.521, tt:685.288\n",
      "Ep:37, loss:0.00009, loss_test:0.08191, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:18.567, tt:705.535\n",
      "Ep:38, loss:0.00009, loss_test:0.08327, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:18.627, tt:726.443\n",
      "Ep:39, loss:0.00009, loss_test:0.08045, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:18.683, tt:747.311\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.08410, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:18.729, tt:767.871\n",
      "Ep:41, loss:0.00008, loss_test:0.07910, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:18.775, tt:788.531\n",
      "Ep:42, loss:0.00008, loss_test:0.08137, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:18.824, tt:809.438\n",
      "Ep:43, loss:0.00008, loss_test:0.07909, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:18.905, tt:831.812\n",
      "Ep:44, loss:0.00007, loss_test:0.08100, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:18.883, tt:849.752\n",
      "Ep:45, loss:0.00007, loss_test:0.08013, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:18.923, tt:870.452\n",
      "Ep:46, loss:0.00007, loss_test:0.07925, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:18.956, tt:890.931\n",
      "Ep:47, loss:0.00007, loss_test:0.07835, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:18.917, tt:907.993\n",
      "Ep:48, loss:0.00006, loss_test:0.07875, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:18.908, tt:926.488\n",
      "Ep:49, loss:0.00006, loss_test:0.07905, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:18.906, tt:945.320\n",
      "Ep:50, loss:0.00006, loss_test:0.07843, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:18.875, tt:962.641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00006, loss_test:0.07977, lr:9.90e-03, fs:0.75000 (r=0.667,p=0.857),  time:18.883, tt:981.940\n",
      "Ep:52, loss:0.00006, loss_test:0.07806, lr:9.80e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.870, tt:1000.087\n",
      "Ep:53, loss:0.00005, loss_test:0.07797, lr:9.70e-03, fs:0.75706 (r=0.677,p=0.859),  time:18.861, tt:1018.493\n",
      "Ep:54, loss:0.00005, loss_test:0.07845, lr:9.61e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.815, tt:1034.845\n",
      "Ep:55, loss:0.00005, loss_test:0.07866, lr:9.51e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.809, tt:1053.288\n",
      "Ep:56, loss:0.00005, loss_test:0.07875, lr:9.41e-03, fs:0.73684 (r=0.636,p=0.875),  time:18.784, tt:1070.680\n",
      "Ep:57, loss:0.00005, loss_test:0.07842, lr:9.32e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.803, tt:1090.550\n",
      "Ep:58, loss:0.00005, loss_test:0.07827, lr:9.23e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.787, tt:1108.424\n",
      "Ep:59, loss:0.00005, loss_test:0.07754, lr:9.14e-03, fs:0.73864 (r=0.657,p=0.844),  time:18.770, tt:1126.199\n",
      "Ep:60, loss:0.00004, loss_test:0.07776, lr:9.04e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.764, tt:1144.575\n",
      "Ep:61, loss:0.00004, loss_test:0.07787, lr:8.95e-03, fs:0.72515 (r=0.626,p=0.861),  time:18.756, tt:1162.878\n",
      "Ep:62, loss:0.00004, loss_test:0.07715, lr:8.86e-03, fs:0.73684 (r=0.636,p=0.875),  time:18.764, tt:1182.111\n",
      "Ep:63, loss:0.00004, loss_test:0.07759, lr:8.78e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.773, tt:1201.446\n",
      "Ep:64, loss:0.00004, loss_test:0.07758, lr:8.69e-03, fs:0.73988 (r=0.646,p=0.865),  time:18.790, tt:1221.349\n",
      "Ep:65, loss:0.00004, loss_test:0.07830, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.832, tt:1242.912\n",
      "Ep:66, loss:0.00004, loss_test:0.07800, lr:8.51e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.881, tt:1264.996\n",
      "Ep:67, loss:0.00004, loss_test:0.07883, lr:8.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.869, tt:1283.092\n",
      "Ep:68, loss:0.00004, loss_test:0.07714, lr:8.35e-03, fs:0.73373 (r=0.626,p=0.886),  time:18.851, tt:1300.690\n",
      "Ep:69, loss:0.00004, loss_test:0.07689, lr:8.26e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.859, tt:1320.141\n",
      "Ep:70, loss:0.00003, loss_test:0.07775, lr:8.18e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.889, tt:1341.109\n",
      "Ep:71, loss:0.00003, loss_test:0.07858, lr:8.10e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.898, tt:1360.620\n",
      "Ep:72, loss:0.00003, loss_test:0.07667, lr:8.02e-03, fs:0.73810 (r=0.626,p=0.899),  time:18.896, tt:1379.439\n",
      "Ep:73, loss:0.00003, loss_test:0.07584, lr:7.94e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.891, tt:1397.955\n",
      "Ep:74, loss:0.00003, loss_test:0.07798, lr:7.86e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.894, tt:1417.082\n",
      "Ep:75, loss:0.00003, loss_test:0.07592, lr:7.78e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.913, tt:1437.373\n",
      "Ep:76, loss:0.00003, loss_test:0.07690, lr:7.70e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.932, tt:1457.757\n",
      "Ep:77, loss:0.00003, loss_test:0.07697, lr:7.62e-03, fs:0.74556 (r=0.636,p=0.900),  time:18.976, tt:1480.137\n",
      "Ep:78, loss:0.00003, loss_test:0.07647, lr:7.55e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.990, tt:1500.196\n",
      "Ep:79, loss:0.00003, loss_test:0.07764, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:18.973, tt:1517.804\n",
      "Ep:80, loss:0.00003, loss_test:0.07648, lr:7.40e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.959, tt:1535.706\n",
      "Ep:81, loss:0.00003, loss_test:0.07775, lr:7.32e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.960, tt:1554.703\n",
      "Ep:82, loss:0.00003, loss_test:0.07766, lr:7.25e-03, fs:0.75294 (r=0.646,p=0.901),  time:18.961, tt:1573.790\n",
      "Ep:83, loss:0.00003, loss_test:0.07698, lr:7.18e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.936, tt:1590.642\n",
      "Ep:84, loss:0.00003, loss_test:0.07814, lr:7.11e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.952, tt:1610.913\n",
      "Ep:85, loss:0.00003, loss_test:0.07673, lr:7.03e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.998, tt:1633.829\n",
      "Ep:86, loss:0.00003, loss_test:0.07689, lr:6.96e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.007, tt:1653.649\n",
      "Ep:87, loss:0.00003, loss_test:0.07783, lr:6.89e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.999, tt:1671.927\n",
      "Ep:88, loss:0.00002, loss_test:0.07654, lr:6.83e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.993, tt:1690.404\n",
      "Ep:89, loss:0.00002, loss_test:0.07744, lr:6.76e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.994, tt:1709.447\n",
      "Ep:90, loss:0.00002, loss_test:0.07847, lr:6.69e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.006, tt:1729.559\n",
      "Ep:91, loss:0.00002, loss_test:0.07561, lr:6.62e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.979, tt:1746.032\n",
      "Ep:92, loss:0.00002, loss_test:0.07835, lr:6.56e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.965, tt:1763.706\n",
      "Ep:93, loss:0.00002, loss_test:0.07624, lr:6.49e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.960, tt:1782.245\n",
      "Ep:94, loss:0.00002, loss_test:0.07822, lr:6.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.940, tt:1799.293\n",
      "Ep:95, loss:0.00002, loss_test:0.07800, lr:6.36e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.933, tt:1817.569\n",
      "Ep:96, loss:0.00002, loss_test:0.07707, lr:6.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.929, tt:1836.108\n",
      "Ep:97, loss:0.00002, loss_test:0.07751, lr:6.24e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.911, tt:1853.250\n",
      "Ep:98, loss:0.00002, loss_test:0.07696, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.894, tt:1870.542\n",
      "Ep:99, loss:0.00002, loss_test:0.07744, lr:6.11e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.865, tt:1886.521\n",
      "Ep:100, loss:0.00002, loss_test:0.07758, lr:6.05e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.852, tt:1904.041\n",
      "Ep:101, loss:0.00002, loss_test:0.08041, lr:5.99e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.845, tt:1922.153\n",
      "Ep:102, loss:0.00002, loss_test:0.07732, lr:5.93e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.818, tt:1938.204\n",
      "Ep:103, loss:0.00002, loss_test:0.07840, lr:5.87e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.824, tt:1957.724\n",
      "Ep:104, loss:0.00002, loss_test:0.07802, lr:5.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.828, tt:1976.935\n",
      "Ep:105, loss:0.00002, loss_test:0.07735, lr:5.75e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.813, tt:1994.209\n",
      "Ep:106, loss:0.00002, loss_test:0.07902, lr:5.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.825, tt:2014.292\n",
      "Ep:107, loss:0.00002, loss_test:0.07704, lr:5.64e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.815, tt:2032.031\n",
      "Ep:108, loss:0.00002, loss_test:0.07825, lr:5.58e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.834, tt:2052.906\n",
      "Ep:109, loss:0.00002, loss_test:0.07925, lr:5.53e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.826, tt:2070.894\n",
      "Ep:110, loss:0.00002, loss_test:0.07893, lr:5.47e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.812, tt:2088.085\n",
      "Ep:111, loss:0.00002, loss_test:0.07816, lr:5.42e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.803, tt:2105.977\n",
      "Ep:112, loss:0.00002, loss_test:0.07920, lr:5.36e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.837, tt:2128.573\n",
      "Ep:113, loss:0.00002, loss_test:0.07747, lr:5.31e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.863, tt:2150.416\n",
      "Ep:114, loss:0.00002, loss_test:0.07872, lr:5.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.883, tt:2171.512\n",
      "Ep:115, loss:0.00002, loss_test:0.07891, lr:5.20e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.881, tt:2190.251\n",
      "Ep:116, loss:0.00002, loss_test:0.07808, lr:5.15e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.890, tt:2210.072\n",
      "Ep:117, loss:0.00002, loss_test:0.07901, lr:5.10e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.901, tt:2230.367\n",
      "Ep:118, loss:0.00002, loss_test:0.07838, lr:5.05e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.914, tt:2250.820\n",
      "Ep:119, loss:0.00002, loss_test:0.07857, lr:5.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.928, tt:2271.304\n",
      "Ep:120, loss:0.00002, loss_test:0.07899, lr:4.95e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.913, tt:2288.474\n",
      "Ep:121, loss:0.00002, loss_test:0.07867, lr:4.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.902, tt:2306.059\n",
      "Ep:122, loss:0.00002, loss_test:0.07709, lr:4.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.888, tt:2323.201\n",
      "Ep:123, loss:0.00002, loss_test:0.07895, lr:4.80e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.905, tt:2344.280\n",
      "Ep:124, loss:0.00002, loss_test:0.07820, lr:4.75e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.895, tt:2361.844\n",
      "Ep:125, loss:0.00002, loss_test:0.07811, lr:4.71e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.886, tt:2379.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00002, loss_test:0.07819, lr:4.66e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.876, tt:2397.234\n",
      "Ep:127, loss:0.00002, loss_test:0.07816, lr:4.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.876, tt:2416.126\n",
      "Ep:128, loss:0.00001, loss_test:0.07810, lr:4.57e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.887, tt:2436.439\n",
      "Ep:129, loss:0.00001, loss_test:0.07736, lr:4.52e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.889, tt:2455.567\n",
      "Ep:130, loss:0.00001, loss_test:0.07943, lr:4.48e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.891, tt:2474.778\n",
      "Ep:131, loss:0.00001, loss_test:0.07764, lr:4.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.900, tt:2494.859\n",
      "Ep:132, loss:0.00001, loss_test:0.07810, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.891, tt:2512.538\n",
      "Ep:133, loss:0.00001, loss_test:0.07812, lr:4.34e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.899, tt:2532.442\n",
      "Ep:134, loss:0.00001, loss_test:0.07786, lr:4.30e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.888, tt:2549.942\n",
      "Ep:135, loss:0.00001, loss_test:0.07788, lr:4.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.902, tt:2570.732\n",
      "Ep:136, loss:0.00001, loss_test:0.07872, lr:4.21e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.912, tt:2590.986\n",
      "Ep:137, loss:0.00001, loss_test:0.07846, lr:4.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.897, tt:2607.830\n",
      "Ep:138, loss:0.00001, loss_test:0.07831, lr:4.13e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.858, tt:2621.225\n",
      "Ep:139, loss:0.00001, loss_test:0.07824, lr:4.09e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.819, tt:2634.693\n",
      "Ep:140, loss:0.00001, loss_test:0.07846, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.815, tt:2652.966\n",
      "Ep:141, loss:0.00001, loss_test:0.07876, lr:4.01e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.810, tt:2671.008\n",
      "Ep:142, loss:0.00001, loss_test:0.07713, lr:3.97e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.775, tt:2684.893\n",
      "Ep:143, loss:0.00001, loss_test:0.07888, lr:3.93e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.732, tt:2697.421\n",
      "Ep:144, loss:0.00001, loss_test:0.07791, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.700, tt:2711.430\n",
      "Ep:145, loss:0.00001, loss_test:0.07723, lr:3.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.687, tt:2728.355\n",
      "Ep:146, loss:0.00001, loss_test:0.07740, lr:3.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.677, tt:2745.550\n",
      "Ep:147, loss:0.00001, loss_test:0.07789, lr:3.77e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.681, tt:2764.771\n",
      "Ep:148, loss:0.00001, loss_test:0.07787, lr:3.73e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.680, tt:2783.265\n",
      "Ep:149, loss:0.00001, loss_test:0.07730, lr:3.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.680, tt:2802.008\n",
      "Ep:150, loss:0.00001, loss_test:0.07831, lr:3.66e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.662, tt:2818.024\n",
      "Ep:151, loss:0.00001, loss_test:0.07756, lr:3.62e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.647, tt:2834.387\n",
      "Ep:152, loss:0.00001, loss_test:0.07784, lr:3.59e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.640, tt:2851.894\n",
      "Ep:153, loss:0.00001, loss_test:0.07842, lr:3.55e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.636, tt:2869.985\n",
      "Ep:154, loss:0.00001, loss_test:0.07741, lr:3.52e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.632, tt:2887.908\n",
      "Ep:155, loss:0.00001, loss_test:0.07804, lr:3.48e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.617, tt:2904.247\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14193, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:18.757, tt:18.757\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14029, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:19.251, tt:38.501\n",
      "Ep:2, loss:0.00027, loss_test:0.13766, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:20.772, tt:62.317\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13675, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:21.229, tt:84.918\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13663, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:21.104, tt:105.519\n",
      "Ep:5, loss:0.00025, loss_test:0.13452, lr:1.00e-02, fs:0.62551 (r=0.768,p=0.528),  time:21.484, tt:128.902\n",
      "Ep:6, loss:0.00024, loss_test:0.13083, lr:1.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:21.291, tt:149.038\n",
      "Ep:7, loss:0.00024, loss_test:0.12835, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:21.131, tt:169.046\n",
      "Ep:8, loss:0.00023, loss_test:0.12648, lr:1.00e-02, fs:0.60684 (r=0.717,p=0.526),  time:21.060, tt:189.540\n",
      "Ep:9, loss:0.00022, loss_test:0.12565, lr:1.00e-02, fs:0.60360 (r=0.677,p=0.545),  time:21.053, tt:210.533\n",
      "Ep:10, loss:0.00022, loss_test:0.12082, lr:1.00e-02, fs:0.63348 (r=0.707,p=0.574),  time:21.072, tt:231.797\n",
      "Ep:11, loss:0.00021, loss_test:0.11668, lr:1.00e-02, fs:0.63964 (r=0.717,p=0.577),  time:21.004, tt:252.047\n",
      "Ep:12, loss:0.00020, loss_test:0.11445, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:20.878, tt:271.420\n",
      "Ep:13, loss:0.00019, loss_test:0.11341, lr:1.00e-02, fs:0.65366 (r=0.677,p=0.632),  time:20.892, tt:292.484\n",
      "Ep:14, loss:0.00019, loss_test:0.11075, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:20.905, tt:313.580\n",
      "Ep:15, loss:0.00018, loss_test:0.10827, lr:9.90e-03, fs:0.68000 (r=0.687,p=0.673),  time:20.888, tt:334.211\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10707, lr:9.90e-03, fs:0.66667 (r=0.667,p=0.667),  time:21.004, tt:357.073\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"1-1\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
