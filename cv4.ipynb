{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number = \"31-40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24239, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.527, tt:16.527\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.23844, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:18.684, tt:37.368\n",
      "Ep:2, loss:0.00056, loss_test:0.22887, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:21.992, tt:65.975\n",
      "Ep:3, loss:0.00050, loss_test:0.21215, lr:9.41e-03, fs:0.66894 (r=0.990,p=0.505),  time:24.077, tt:96.307\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.20093, lr:9.22e-03, fs:0.68165 (r=0.919,p=0.542),  time:26.101, tt:130.505\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00034, loss_test:0.19771, lr:9.04e-03, fs:0.68504 (r=0.879,p=0.561),  time:27.374, tt:164.246\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.19539, lr:8.86e-03, fs:0.69106 (r=0.859,p=0.578),  time:28.313, tt:198.188\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.19175, lr:8.68e-03, fs:0.69456 (r=0.838,p=0.593),  time:29.070, tt:232.558\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.18457, lr:8.51e-03, fs:0.70732 (r=0.879,p=0.592),  time:29.588, tt:266.288\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00029, loss_test:0.17976, lr:8.34e-03, fs:0.73029 (r=0.889,p=0.620),  time:30.147, tt:301.470\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.17702, lr:8.17e-03, fs:0.71730 (r=0.859,p=0.616),  time:30.391, tt:334.297\n",
      "Ep:11, loss:0.00027, loss_test:0.17377, lr:8.01e-03, fs:0.74262 (r=0.889,p=0.638),  time:30.650, tt:367.796\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.17128, lr:7.85e-03, fs:0.71730 (r=0.859,p=0.616),  time:30.896, tt:401.654\n",
      "Ep:13, loss:0.00026, loss_test:0.16862, lr:7.69e-03, fs:0.74678 (r=0.879,p=0.649),  time:31.072, tt:435.013\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.16784, lr:7.54e-03, fs:0.74678 (r=0.879,p=0.649),  time:31.313, tt:469.698\n",
      "Ep:15, loss:0.00025, loss_test:0.16532, lr:7.39e-03, fs:0.74561 (r=0.859,p=0.659),  time:31.465, tt:503.438\n",
      "Ep:16, loss:0.00024, loss_test:0.16316, lr:7.24e-03, fs:0.75000 (r=0.879,p=0.654),  time:31.607, tt:537.317\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.15942, lr:7.09e-03, fs:0.76522 (r=0.889,p=0.672),  time:31.703, tt:570.659\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.15761, lr:6.95e-03, fs:0.77193 (r=0.889,p=0.682),  time:31.750, tt:603.257\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.15412, lr:6.81e-03, fs:0.78261 (r=0.909,p=0.687),  time:31.870, tt:637.410\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.15306, lr:6.68e-03, fs:0.78261 (r=0.909,p=0.687),  time:32.045, tt:672.939\n",
      "Ep:21, loss:0.00021, loss_test:0.15373, lr:6.54e-03, fs:0.78924 (r=0.889,p=0.710),  time:32.069, tt:705.514\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.15062, lr:6.41e-03, fs:0.77533 (r=0.889,p=0.688),  time:32.105, tt:738.426\n",
      "Ep:23, loss:0.00020, loss_test:0.14904, lr:6.28e-03, fs:0.79295 (r=0.909,p=0.703),  time:32.184, tt:772.415\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.14948, lr:6.16e-03, fs:0.77876 (r=0.889,p=0.693),  time:32.299, tt:807.480\n",
      "Ep:25, loss:0.00019, loss_test:0.14511, lr:6.03e-03, fs:0.79130 (r=0.919,p=0.695),  time:32.396, tt:842.292\n",
      "Ep:26, loss:0.00019, loss_test:0.14455, lr:5.91e-03, fs:0.78414 (r=0.899,p=0.695),  time:32.418, tt:875.294\n",
      "Ep:27, loss:0.00018, loss_test:0.14385, lr:5.80e-03, fs:0.79130 (r=0.919,p=0.695),  time:32.502, tt:910.049\n",
      "Ep:28, loss:0.00017, loss_test:0.14255, lr:5.68e-03, fs:0.80000 (r=0.909,p=0.714),  time:32.539, tt:943.644\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.14301, lr:5.57e-03, fs:0.79821 (r=0.899,p=0.718),  time:32.552, tt:976.553\n",
      "Ep:30, loss:0.00017, loss_test:0.13863, lr:5.45e-03, fs:0.82353 (r=0.919,p=0.746),  time:32.601, tt:1010.617\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00017, loss_test:0.13884, lr:5.35e-03, fs:0.80909 (r=0.899,p=0.736),  time:32.665, tt:1045.286\n",
      "Ep:32, loss:0.00016, loss_test:0.13810, lr:5.24e-03, fs:0.80000 (r=0.929,p=0.702),  time:32.675, tt:1078.277\n",
      "Ep:33, loss:0.00016, loss_test:0.13542, lr:5.13e-03, fs:0.82727 (r=0.919,p=0.752),  time:32.736, tt:1113.028\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.13228, lr:5.03e-03, fs:0.83105 (r=0.919,p=0.758),  time:32.762, tt:1146.658\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00015, loss_test:0.13291, lr:4.93e-03, fs:0.83486 (r=0.919,p=0.765),  time:32.782, tt:1180.151\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00015, loss_test:0.13336, lr:4.83e-03, fs:0.82727 (r=0.919,p=0.752),  time:32.841, tt:1215.116\n",
      "Ep:37, loss:0.00015, loss_test:0.12900, lr:4.74e-03, fs:0.82511 (r=0.929,p=0.742),  time:32.903, tt:1250.303\n",
      "Ep:38, loss:0.00014, loss_test:0.13038, lr:4.64e-03, fs:0.83486 (r=0.919,p=0.765),  time:32.917, tt:1283.780\n",
      "Ep:39, loss:0.00014, loss_test:0.13273, lr:4.55e-03, fs:0.85047 (r=0.919,p=0.791),  time:32.917, tt:1316.675\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.12721, lr:4.46e-03, fs:0.84404 (r=0.929,p=0.773),  time:32.960, tt:1351.362\n",
      "Ep:41, loss:0.00013, loss_test:0.12644, lr:4.37e-03, fs:0.85981 (r=0.929,p=0.800),  time:33.000, tt:1386.010\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00013, loss_test:0.12869, lr:4.28e-03, fs:0.85581 (r=0.929,p=0.793),  time:33.030, tt:1420.282\n",
      "Ep:43, loss:0.00012, loss_test:0.12756, lr:4.19e-03, fs:0.87204 (r=0.929,p=0.821),  time:33.063, tt:1454.790\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00012, loss_test:0.12693, lr:4.11e-03, fs:0.84404 (r=0.929,p=0.773),  time:33.117, tt:1490.255\n",
      "Ep:45, loss:0.00012, loss_test:0.12602, lr:4.03e-03, fs:0.84404 (r=0.929,p=0.773),  time:33.125, tt:1523.763\n",
      "Ep:46, loss:0.00012, loss_test:0.12232, lr:3.95e-03, fs:0.85981 (r=0.929,p=0.800),  time:33.164, tt:1558.706\n",
      "Ep:47, loss:0.00012, loss_test:0.12288, lr:3.87e-03, fs:0.85981 (r=0.929,p=0.800),  time:33.166, tt:1591.961\n",
      "Ep:48, loss:0.00011, loss_test:0.12253, lr:3.79e-03, fs:0.85981 (r=0.929,p=0.800),  time:33.150, tt:1624.332\n",
      "Ep:49, loss:0.00011, loss_test:0.12197, lr:3.72e-03, fs:0.85981 (r=0.929,p=0.800),  time:33.171, tt:1658.571\n",
      "Ep:50, loss:0.00011, loss_test:0.12235, lr:3.64e-03, fs:0.86667 (r=0.919,p=0.820),  time:33.158, tt:1691.054\n",
      "Ep:51, loss:0.00011, loss_test:0.12221, lr:3.57e-03, fs:0.85581 (r=0.929,p=0.793),  time:33.168, tt:1724.747\n",
      "Ep:52, loss:0.00011, loss_test:0.12467, lr:3.50e-03, fs:0.87923 (r=0.919,p=0.843),  time:33.146, tt:1756.718\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00010, loss_test:0.11865, lr:3.43e-03, fs:0.88462 (r=0.929,p=0.844),  time:33.163, tt:1790.776\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00010, loss_test:0.11653, lr:3.36e-03, fs:0.86792 (r=0.929,p=0.814),  time:33.139, tt:1822.653\n",
      "Ep:55, loss:0.00009, loss_test:0.11798, lr:3.29e-03, fs:0.87324 (r=0.939,p=0.816),  time:33.121, tt:1854.786\n",
      "Ep:56, loss:0.00010, loss_test:0.11957, lr:3.23e-03, fs:0.89855 (r=0.939,p=0.861),  time:33.120, tt:1887.833\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00010, loss_test:0.11983, lr:3.16e-03, fs:0.88889 (r=0.929,p=0.852),  time:33.134, tt:1921.780\n",
      "Ep:58, loss:0.00009, loss_test:0.11744, lr:3.10e-03, fs:0.87736 (r=0.939,p=0.823),  time:33.133, tt:1954.830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00009, loss_test:0.11321, lr:3.04e-03, fs:0.88995 (r=0.939,p=0.845),  time:33.119, tt:1987.125\n",
      "Ep:60, loss:0.00009, loss_test:0.11723, lr:2.98e-03, fs:0.88462 (r=0.929,p=0.844),  time:33.124, tt:2020.537\n",
      "Ep:61, loss:0.00009, loss_test:0.11902, lr:2.92e-03, fs:0.88038 (r=0.929,p=0.836),  time:33.109, tt:2052.775\n",
      "Ep:62, loss:0.00009, loss_test:0.11532, lr:2.86e-03, fs:0.88995 (r=0.939,p=0.845),  time:33.132, tt:2087.338\n",
      "Ep:63, loss:0.00008, loss_test:0.11531, lr:2.80e-03, fs:0.88995 (r=0.939,p=0.845),  time:33.134, tt:2120.601\n",
      "Ep:64, loss:0.00008, loss_test:0.11876, lr:2.74e-03, fs:0.88462 (r=0.929,p=0.844),  time:33.154, tt:2155.008\n",
      "Ep:65, loss:0.00008, loss_test:0.11743, lr:2.69e-03, fs:0.89756 (r=0.929,p=0.868),  time:33.169, tt:2189.148\n",
      "Ep:66, loss:0.00008, loss_test:0.11725, lr:2.64e-03, fs:0.90196 (r=0.929,p=0.876),  time:33.175, tt:2222.711\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00008, loss_test:0.11885, lr:2.58e-03, fs:0.89756 (r=0.929,p=0.868),  time:33.206, tt:2257.995\n",
      "Ep:68, loss:0.00008, loss_test:0.11714, lr:2.53e-03, fs:0.88780 (r=0.919,p=0.858),  time:33.236, tt:2293.286\n",
      "Ep:69, loss:0.00008, loss_test:0.11441, lr:2.48e-03, fs:0.89756 (r=0.929,p=0.868),  time:33.220, tt:2325.385\n",
      "Ep:70, loss:0.00008, loss_test:0.11735, lr:2.43e-03, fs:0.90196 (r=0.929,p=0.876),  time:33.219, tt:2358.531\n",
      "Ep:71, loss:0.00007, loss_test:0.12083, lr:2.38e-03, fs:0.89655 (r=0.919,p=0.875),  time:33.230, tt:2392.535\n",
      "Ep:72, loss:0.00007, loss_test:0.11726, lr:2.33e-03, fs:0.90732 (r=0.939,p=0.877),  time:33.211, tt:2424.430\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00007, loss_test:0.11206, lr:2.29e-03, fs:0.90291 (r=0.939,p=0.869),  time:33.208, tt:2457.376\n",
      "Ep:74, loss:0.00007, loss_test:0.11294, lr:2.24e-03, fs:0.90732 (r=0.939,p=0.877),  time:33.210, tt:2490.760\n",
      "Ep:75, loss:0.00007, loss_test:0.12038, lr:2.20e-03, fs:0.90099 (r=0.919,p=0.883),  time:33.214, tt:2524.276\n",
      "Ep:76, loss:0.00007, loss_test:0.12109, lr:2.15e-03, fs:0.89552 (r=0.909,p=0.882),  time:33.219, tt:2557.844\n",
      "Ep:77, loss:0.00007, loss_test:0.11481, lr:2.11e-03, fs:0.90196 (r=0.929,p=0.876),  time:33.239, tt:2592.672\n",
      "Ep:78, loss:0.00007, loss_test:0.11461, lr:2.07e-03, fs:0.89216 (r=0.919,p=0.867),  time:33.240, tt:2625.940\n",
      "Ep:79, loss:0.00006, loss_test:0.11984, lr:2.03e-03, fs:0.88119 (r=0.899,p=0.864),  time:33.256, tt:2660.471\n",
      "Ep:80, loss:0.00006, loss_test:0.12149, lr:1.99e-03, fs:0.89000 (r=0.899,p=0.881),  time:33.283, tt:2695.905\n",
      "Ep:81, loss:0.00006, loss_test:0.11920, lr:1.95e-03, fs:0.89552 (r=0.909,p=0.882),  time:33.278, tt:2728.824\n",
      "Ep:82, loss:0.00006, loss_test:0.11759, lr:1.91e-03, fs:0.88557 (r=0.899,p=0.873),  time:33.275, tt:2761.843\n",
      "Ep:83, loss:0.00006, loss_test:0.11743, lr:1.87e-03, fs:0.89655 (r=0.919,p=0.875),  time:33.302, tt:2797.402\n",
      "Ep:84, loss:0.00006, loss_test:0.11853, lr:1.83e-03, fs:0.91000 (r=0.919,p=0.901),  time:33.300, tt:2830.540\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00006, loss_test:0.12043, lr:1.80e-03, fs:0.89899 (r=0.899,p=0.899),  time:33.317, tt:2865.303\n",
      "Ep:86, loss:0.00006, loss_test:0.12074, lr:1.76e-03, fs:0.89552 (r=0.909,p=0.882),  time:33.271, tt:2894.598\n",
      "Ep:87, loss:0.00005, loss_test:0.11792, lr:1.72e-03, fs:0.90099 (r=0.919,p=0.883),  time:33.279, tt:2928.530\n",
      "Ep:88, loss:0.00006, loss_test:0.11618, lr:1.69e-03, fs:0.91089 (r=0.929,p=0.893),  time:33.262, tt:2960.306\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00006, loss_test:0.11756, lr:1.66e-03, fs:0.91000 (r=0.919,p=0.901),  time:33.250, tt:2992.510\n",
      "Ep:90, loss:0.00005, loss_test:0.11926, lr:1.62e-03, fs:0.89655 (r=0.919,p=0.875),  time:33.262, tt:3026.870\n",
      "Ep:91, loss:0.00005, loss_test:0.11877, lr:1.59e-03, fs:0.89552 (r=0.909,p=0.882),  time:33.270, tt:3060.809\n",
      "Ep:92, loss:0.00005, loss_test:0.11745, lr:1.56e-03, fs:0.90000 (r=0.909,p=0.891),  time:33.280, tt:3095.023\n",
      "Ep:93, loss:0.00006, loss_test:0.11657, lr:1.53e-03, fs:0.89552 (r=0.909,p=0.882),  time:33.282, tt:3128.482\n",
      "Ep:94, loss:0.00005, loss_test:0.11902, lr:1.50e-03, fs:0.89109 (r=0.909,p=0.874),  time:33.278, tt:3161.439\n",
      "Ep:95, loss:0.00005, loss_test:0.12108, lr:1.47e-03, fs:0.88889 (r=0.889,p=0.889),  time:33.283, tt:3195.171\n",
      "Ep:96, loss:0.00005, loss_test:0.11941, lr:1.44e-03, fs:0.90547 (r=0.919,p=0.892),  time:33.291, tt:3229.254\n",
      "Ep:97, loss:0.00005, loss_test:0.11791, lr:1.41e-03, fs:0.90099 (r=0.919,p=0.883),  time:33.301, tt:3263.489\n",
      "Ep:98, loss:0.00005, loss_test:0.11874, lr:1.38e-03, fs:0.90000 (r=0.909,p=0.891),  time:33.312, tt:3297.874\n",
      "Ep:99, loss:0.00005, loss_test:0.12053, lr:1.35e-03, fs:0.88889 (r=0.889,p=0.889),  time:33.333, tt:3333.265\n",
      "Ep:100, loss:0.00005, loss_test:0.12032, lr:1.33e-03, fs:0.89447 (r=0.899,p=0.890),  time:33.353, tt:3368.638\n",
      "Ep:101, loss:0.00005, loss_test:0.12067, lr:1.30e-03, fs:0.89899 (r=0.899,p=0.899),  time:33.380, tt:3404.714\n",
      "Ep:102, loss:0.00005, loss_test:0.12121, lr:1.27e-03, fs:0.90355 (r=0.899,p=0.908),  time:33.391, tt:3439.268\n",
      "Ep:103, loss:0.00005, loss_test:0.11968, lr:1.25e-03, fs:0.90452 (r=0.909,p=0.900),  time:33.408, tt:3474.388\n",
      "Ep:104, loss:0.00004, loss_test:0.11967, lr:1.22e-03, fs:0.90000 (r=0.909,p=0.891),  time:33.424, tt:3509.559\n",
      "Ep:105, loss:0.00005, loss_test:0.11938, lr:1.20e-03, fs:0.89000 (r=0.899,p=0.881),  time:33.437, tt:3544.294\n",
      "Ep:106, loss:0.00005, loss_test:0.11904, lr:1.17e-03, fs:0.89899 (r=0.899,p=0.899),  time:33.453, tt:3579.457\n",
      "Ep:107, loss:0.00005, loss_test:0.11803, lr:1.15e-03, fs:0.90452 (r=0.909,p=0.900),  time:33.477, tt:3615.496\n",
      "Ep:108, loss:0.00005, loss_test:0.11933, lr:1.13e-03, fs:0.90452 (r=0.909,p=0.900),  time:33.505, tt:3652.048\n",
      "Ep:109, loss:0.00004, loss_test:0.12098, lr:1.11e-03, fs:0.89340 (r=0.889,p=0.898),  time:33.509, tt:3686.023\n",
      "Ep:110, loss:0.00004, loss_test:0.12237, lr:1.08e-03, fs:0.88889 (r=0.889,p=0.889),  time:33.523, tt:3721.069\n",
      "Ep:111, loss:0.00004, loss_test:0.12220, lr:1.06e-03, fs:0.90355 (r=0.899,p=0.908),  time:33.532, tt:3755.601\n",
      "Ep:112, loss:0.00004, loss_test:0.12083, lr:1.04e-03, fs:0.90355 (r=0.899,p=0.908),  time:33.543, tt:3790.369\n",
      "Ep:113, loss:0.00004, loss_test:0.11879, lr:1.02e-03, fs:0.90452 (r=0.909,p=0.900),  time:33.569, tt:3826.924\n",
      "Ep:114, loss:0.00004, loss_test:0.11816, lr:9.99e-04, fs:0.90547 (r=0.919,p=0.892),  time:33.594, tt:3863.283\n",
      "Ep:115, loss:0.00004, loss_test:0.11819, lr:9.79e-04, fs:0.90000 (r=0.909,p=0.891),  time:33.599, tt:3897.491\n",
      "Ep:116, loss:0.00004, loss_test:0.12069, lr:9.60e-04, fs:0.88776 (r=0.879,p=0.897),  time:33.615, tt:3932.942\n",
      "Ep:117, loss:0.00004, loss_test:0.12322, lr:9.41e-04, fs:0.88083 (r=0.859,p=0.904),  time:33.631, tt:3968.494\n",
      "Ep:118, loss:0.00004, loss_test:0.12345, lr:9.22e-04, fs:0.88660 (r=0.869,p=0.905),  time:33.635, tt:4002.617\n",
      "Ep:119, loss:0.00004, loss_test:0.12185, lr:9.03e-04, fs:0.88776 (r=0.879,p=0.897),  time:33.650, tt:4037.948\n",
      "Ep:120, loss:0.00004, loss_test:0.12102, lr:8.85e-04, fs:0.88889 (r=0.889,p=0.889),  time:33.656, tt:4072.395\n",
      "Ep:121, loss:0.00004, loss_test:0.12163, lr:8.68e-04, fs:0.88325 (r=0.879,p=0.888),  time:33.641, tt:4104.171\n",
      "Ep:122, loss:0.00004, loss_test:0.12392, lr:8.50e-04, fs:0.88660 (r=0.869,p=0.905),  time:33.641, tt:4137.782\n",
      "Ep:123, loss:0.00004, loss_test:0.12421, lr:8.33e-04, fs:0.88083 (r=0.859,p=0.904),  time:33.650, tt:4172.601\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.23786, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.813, tt:32.813\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.23195, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.844, tt:65.688\n",
      "Ep:2, loss:0.00056, loss_test:0.21945, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.904, tt:95.711\n",
      "Ep:3, loss:0.00050, loss_test:0.19977, lr:9.41e-03, fs:0.66901 (r=0.960,p=0.514),  time:32.185, tt:128.738\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00041, loss_test:0.19114, lr:9.22e-03, fs:0.68504 (r=0.879,p=0.561),  time:31.988, tt:159.941\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00034, loss_test:0.19486, lr:9.04e-03, fs:0.68936 (r=0.818,p=0.596),  time:32.520, tt:195.119\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.18866, lr:8.86e-03, fs:0.70886 (r=0.848,p=0.609),  time:32.746, tt:229.220\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.18302, lr:8.68e-03, fs:0.70130 (r=0.818,p=0.614),  time:32.979, tt:263.830\n",
      "Ep:8, loss:0.00030, loss_test:0.17990, lr:8.51e-03, fs:0.73214 (r=0.828,p=0.656),  time:33.188, tt:298.693\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.17582, lr:8.34e-03, fs:0.73043 (r=0.848,p=0.641),  time:33.298, tt:332.975\n",
      "Ep:10, loss:0.00029, loss_test:0.17375, lr:8.17e-03, fs:0.72973 (r=0.818,p=0.659),  time:33.391, tt:367.303\n",
      "Ep:11, loss:0.00027, loss_test:0.16744, lr:8.01e-03, fs:0.75109 (r=0.869,p=0.662),  time:33.295, tt:399.539\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.16292, lr:7.85e-03, fs:0.76724 (r=0.899,p=0.669),  time:33.252, tt:432.273\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.16376, lr:7.69e-03, fs:0.74208 (r=0.828,p=0.672),  time:33.353, tt:466.943\n",
      "Ep:14, loss:0.00025, loss_test:0.16171, lr:7.54e-03, fs:0.76018 (r=0.848,p=0.689),  time:33.417, tt:501.259\n",
      "Ep:15, loss:0.00024, loss_test:0.15912, lr:7.39e-03, fs:0.76786 (r=0.869,p=0.688),  time:33.436, tt:534.983\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.15592, lr:7.24e-03, fs:0.77477 (r=0.869,p=0.699),  time:33.477, tt:569.101\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.15341, lr:7.09e-03, fs:0.78733 (r=0.879,p=0.713),  time:33.485, tt:602.731\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.15316, lr:6.95e-03, fs:0.77477 (r=0.869,p=0.699),  time:33.507, tt:636.625\n",
      "Ep:19, loss:0.00022, loss_test:0.14784, lr:6.81e-03, fs:0.78070 (r=0.899,p=0.690),  time:33.525, tt:670.505\n",
      "Ep:20, loss:0.00022, loss_test:0.14512, lr:6.68e-03, fs:0.79111 (r=0.899,p=0.706),  time:33.544, tt:704.417\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.14767, lr:6.54e-03, fs:0.79817 (r=0.879,p=0.731),  time:33.583, tt:738.827\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.14988, lr:6.41e-03, fs:0.80374 (r=0.869,p=0.748),  time:33.594, tt:772.664\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.14502, lr:6.28e-03, fs:0.80000 (r=0.889,p=0.727),  time:33.638, tt:807.318\n",
      "Ep:24, loss:0.00019, loss_test:0.14114, lr:6.16e-03, fs:0.80851 (r=0.960,p=0.699),  time:33.658, tt:841.445\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.14222, lr:6.03e-03, fs:0.80930 (r=0.879,p=0.750),  time:33.658, tt:875.115\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.13742, lr:5.91e-03, fs:0.82969 (r=0.960,p=0.731),  time:33.660, tt:908.817\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.13955, lr:5.80e-03, fs:0.83486 (r=0.919,p=0.765),  time:33.732, tt:944.492\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.14039, lr:5.68e-03, fs:0.82353 (r=0.919,p=0.746),  time:33.780, tt:979.618\n",
      "Ep:29, loss:0.00017, loss_test:0.13809, lr:5.57e-03, fs:0.84211 (r=0.970,p=0.744),  time:33.763, tt:1012.877\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.13421, lr:5.45e-03, fs:0.85088 (r=0.980,p=0.752),  time:33.783, tt:1047.283\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.13320, lr:5.35e-03, fs:0.85202 (r=0.960,p=0.766),  time:33.842, tt:1082.959\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00016, loss_test:0.13331, lr:5.24e-03, fs:0.84211 (r=0.970,p=0.744),  time:33.907, tt:1118.927\n",
      "Ep:33, loss:0.00016, loss_test:0.12888, lr:5.13e-03, fs:0.84956 (r=0.970,p=0.756),  time:33.918, tt:1153.225\n",
      "Ep:34, loss:0.00015, loss_test:0.13143, lr:5.03e-03, fs:0.86878 (r=0.970,p=0.787),  time:33.955, tt:1188.417\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00015, loss_test:0.13211, lr:4.93e-03, fs:0.85714 (r=0.939,p=0.788),  time:34.010, tt:1224.373\n",
      "Ep:36, loss:0.00014, loss_test:0.12723, lr:4.83e-03, fs:0.84120 (r=0.990,p=0.731),  time:34.066, tt:1260.454\n",
      "Ep:37, loss:0.00014, loss_test:0.13427, lr:4.74e-03, fs:0.81690 (r=0.879,p=0.763),  time:34.110, tt:1296.194\n",
      "Ep:38, loss:0.00014, loss_test:0.13471, lr:4.64e-03, fs:0.82075 (r=0.879,p=0.770),  time:34.084, tt:1329.286\n",
      "Ep:39, loss:0.00013, loss_test:0.13166, lr:4.55e-03, fs:0.79630 (r=0.869,p=0.735),  time:34.072, tt:1362.889\n",
      "Ep:40, loss:0.00012, loss_test:0.13090, lr:4.46e-03, fs:0.82464 (r=0.879,p=0.777),  time:34.013, tt:1394.513\n",
      "Ep:41, loss:0.00012, loss_test:0.13003, lr:4.37e-03, fs:0.83568 (r=0.899,p=0.781),  time:34.021, tt:1428.892\n",
      "Ep:42, loss:0.00012, loss_test:0.13321, lr:4.28e-03, fs:0.80000 (r=0.869,p=0.741),  time:34.006, tt:1462.272\n",
      "Ep:43, loss:0.00012, loss_test:0.13076, lr:4.19e-03, fs:0.80000 (r=0.848,p=0.757),  time:33.967, tt:1494.555\n",
      "Ep:44, loss:0.00011, loss_test:0.12998, lr:4.11e-03, fs:0.79439 (r=0.859,p=0.739),  time:33.963, tt:1528.318\n",
      "Ep:45, loss:0.00011, loss_test:0.12784, lr:4.03e-03, fs:0.81308 (r=0.879,p=0.757),  time:33.946, tt:1561.509\n",
      "Ep:46, loss:0.00011, loss_test:0.12994, lr:3.95e-03, fs:0.80976 (r=0.838,p=0.783),  time:33.960, tt:1596.109\n",
      "Ep:47, loss:0.00010, loss_test:0.12680, lr:3.87e-03, fs:0.80374 (r=0.869,p=0.748),  time:33.925, tt:1628.400\n",
      "Ep:48, loss:0.00010, loss_test:0.13081, lr:3.79e-03, fs:0.80193 (r=0.838,p=0.769),  time:33.933, tt:1662.699\n",
      "Ep:49, loss:0.00010, loss_test:0.13104, lr:3.72e-03, fs:0.80788 (r=0.828,p=0.788),  time:33.938, tt:1696.918\n",
      "Ep:50, loss:0.00009, loss_test:0.12811, lr:3.64e-03, fs:0.79227 (r=0.828,p=0.759),  time:33.914, tt:1729.598\n",
      "Ep:51, loss:0.00010, loss_test:0.12675, lr:3.57e-03, fs:0.81159 (r=0.848,p=0.778),  time:33.889, tt:1762.253\n",
      "Ep:52, loss:0.00009, loss_test:0.12908, lr:3.50e-03, fs:0.81373 (r=0.838,p=0.790),  time:33.860, tt:1794.588\n",
      "Ep:53, loss:0.00009, loss_test:0.13315, lr:3.43e-03, fs:0.78607 (r=0.798,p=0.775),  time:33.873, tt:1829.135\n",
      "Ep:54, loss:0.00008, loss_test:0.12638, lr:3.36e-03, fs:0.81308 (r=0.879,p=0.757),  time:33.855, tt:1862.034\n",
      "Ep:55, loss:0.00008, loss_test:0.13005, lr:3.29e-03, fs:0.80193 (r=0.838,p=0.769),  time:33.830, tt:1894.501\n",
      "Ep:56, loss:0.00008, loss_test:0.12797, lr:3.23e-03, fs:0.81000 (r=0.818,p=0.802),  time:33.827, tt:1928.161\n",
      "Ep:57, loss:0.00008, loss_test:0.12530, lr:3.16e-03, fs:0.81159 (r=0.848,p=0.778),  time:33.815, tt:1961.280\n",
      "Ep:58, loss:0.00007, loss_test:0.13009, lr:3.10e-03, fs:0.79024 (r=0.818,p=0.764),  time:33.805, tt:1994.467\n",
      "Ep:59, loss:0.00007, loss_test:0.12921, lr:3.04e-03, fs:0.80198 (r=0.818,p=0.786),  time:33.779, tt:2026.763\n",
      "Ep:60, loss:0.00007, loss_test:0.12346, lr:2.98e-03, fs:0.80569 (r=0.859,p=0.759),  time:33.804, tt:2062.030\n",
      "Ep:61, loss:0.00007, loss_test:0.12455, lr:2.92e-03, fs:0.80392 (r=0.828,p=0.781),  time:33.797, tt:2095.394\n",
      "Ep:62, loss:0.00007, loss_test:0.12646, lr:2.86e-03, fs:0.83417 (r=0.838,p=0.830),  time:33.815, tt:2130.365\n",
      "Ep:63, loss:0.00007, loss_test:0.12451, lr:2.80e-03, fs:0.78049 (r=0.808,p=0.755),  time:33.829, tt:2165.080\n",
      "Ep:64, loss:0.00007, loss_test:0.12031, lr:2.74e-03, fs:0.84314 (r=0.869,p=0.819),  time:33.825, tt:2198.655\n",
      "Ep:65, loss:0.00007, loss_test:0.12688, lr:2.69e-03, fs:0.83333 (r=0.808,p=0.860),  time:33.826, tt:2232.532\n",
      "Ep:66, loss:0.00006, loss_test:0.12567, lr:2.64e-03, fs:0.81865 (r=0.798,p=0.840),  time:33.824, tt:2266.227\n",
      "Ep:67, loss:0.00006, loss_test:0.12300, lr:2.58e-03, fs:0.81633 (r=0.808,p=0.825),  time:33.820, tt:2299.782\n",
      "Ep:68, loss:0.00006, loss_test:0.12472, lr:2.53e-03, fs:0.83077 (r=0.818,p=0.844),  time:33.836, tt:2334.652\n",
      "Ep:69, loss:0.00006, loss_test:0.12279, lr:2.48e-03, fs:0.83838 (r=0.838,p=0.838),  time:33.801, tt:2366.060\n",
      "Ep:70, loss:0.00006, loss_test:0.12594, lr:2.43e-03, fs:0.82723 (r=0.798,p=0.859),  time:33.824, tt:2401.484\n",
      "Ep:71, loss:0.00005, loss_test:0.12348, lr:2.38e-03, fs:0.81865 (r=0.798,p=0.840),  time:33.812, tt:2434.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00006, loss_test:0.12385, lr:2.33e-03, fs:0.83770 (r=0.808,p=0.870),  time:33.812, tt:2468.255\n",
      "Ep:73, loss:0.00005, loss_test:0.12490, lr:2.29e-03, fs:0.84375 (r=0.818,p=0.871),  time:33.810, tt:2501.977\n",
      "Ep:74, loss:0.00005, loss_test:0.12445, lr:2.24e-03, fs:0.83158 (r=0.798,p=0.868),  time:33.813, tt:2535.956\n",
      "Ep:75, loss:0.00005, loss_test:0.12121, lr:2.20e-03, fs:0.83838 (r=0.838,p=0.838),  time:33.821, tt:2570.372\n",
      "Ep:76, loss:0.00005, loss_test:0.12382, lr:2.15e-03, fs:0.84422 (r=0.848,p=0.840),  time:33.823, tt:2604.347\n",
      "Ep:77, loss:0.00005, loss_test:0.12680, lr:2.11e-03, fs:0.83158 (r=0.798,p=0.868),  time:33.829, tt:2638.691\n",
      "Ep:78, loss:0.00005, loss_test:0.12354, lr:2.07e-03, fs:0.83505 (r=0.818,p=0.853),  time:33.833, tt:2672.825\n",
      "Ep:79, loss:0.00004, loss_test:0.12326, lr:2.03e-03, fs:0.85417 (r=0.828,p=0.882),  time:33.832, tt:2706.540\n",
      "Ep:80, loss:0.00005, loss_test:0.12650, lr:1.99e-03, fs:0.83422 (r=0.788,p=0.886),  time:33.816, tt:2739.059\n",
      "Ep:81, loss:0.00005, loss_test:0.12203, lr:1.95e-03, fs:0.82474 (r=0.808,p=0.842),  time:33.792, tt:2770.965\n",
      "Ep:82, loss:0.00004, loss_test:0.11924, lr:1.91e-03, fs:0.84848 (r=0.848,p=0.848),  time:33.797, tt:2805.141\n",
      "Ep:83, loss:0.00004, loss_test:0.12018, lr:1.87e-03, fs:0.85263 (r=0.818,p=0.890),  time:33.778, tt:2837.388\n",
      "Ep:84, loss:0.00004, loss_test:0.12354, lr:1.83e-03, fs:0.82979 (r=0.788,p=0.876),  time:33.778, tt:2871.108\n",
      "Ep:85, loss:0.00004, loss_test:0.12357, lr:1.80e-03, fs:0.84656 (r=0.808,p=0.889),  time:33.759, tt:2903.311\n",
      "Ep:86, loss:0.00004, loss_test:0.12360, lr:1.76e-03, fs:0.85106 (r=0.808,p=0.899),  time:33.760, tt:2937.128\n",
      "Ep:87, loss:0.00004, loss_test:0.12234, lr:1.72e-03, fs:0.86010 (r=0.838,p=0.883),  time:33.742, tt:2969.284\n",
      "Ep:88, loss:0.00004, loss_test:0.12052, lr:1.69e-03, fs:0.85279 (r=0.848,p=0.857),  time:33.749, tt:3003.666\n",
      "Ep:89, loss:0.00004, loss_test:0.12564, lr:1.66e-03, fs:0.83243 (r=0.778,p=0.895),  time:33.750, tt:3037.459\n",
      "Ep:90, loss:0.00004, loss_test:0.11868, lr:1.62e-03, fs:0.84817 (r=0.818,p=0.880),  time:33.755, tt:3071.694\n",
      "Ep:91, loss:0.00004, loss_test:0.11967, lr:1.59e-03, fs:0.85417 (r=0.828,p=0.882),  time:33.755, tt:3105.461\n",
      "Ep:92, loss:0.00004, loss_test:0.12062, lr:1.56e-03, fs:0.84375 (r=0.818,p=0.871),  time:33.760, tt:3139.636\n",
      "Ep:93, loss:0.00004, loss_test:0.12026, lr:1.53e-03, fs:0.83158 (r=0.798,p=0.868),  time:33.762, tt:3173.626\n",
      "Ep:94, loss:0.00003, loss_test:0.11964, lr:1.50e-03, fs:0.84817 (r=0.818,p=0.880),  time:33.767, tt:3207.825\n",
      "Ep:95, loss:0.00003, loss_test:0.12158, lr:1.47e-03, fs:0.83598 (r=0.798,p=0.878),  time:33.769, tt:3241.824\n",
      "Ep:96, loss:0.00004, loss_test:0.12208, lr:1.44e-03, fs:0.84946 (r=0.798,p=0.908),  time:33.773, tt:3275.938\n",
      "Ep:97, loss:0.00003, loss_test:0.12249, lr:1.41e-03, fs:0.84946 (r=0.798,p=0.908),  time:33.770, tt:3309.461\n",
      "Ep:98, loss:0.00003, loss_test:0.12352, lr:1.38e-03, fs:0.87047 (r=0.848,p=0.894),  time:33.768, tt:3343.012\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00004, loss_test:0.12610, lr:1.35e-03, fs:0.84043 (r=0.798,p=0.888),  time:33.768, tt:3376.843\n",
      "Ep:100, loss:0.00003, loss_test:0.12650, lr:1.33e-03, fs:0.82162 (r=0.768,p=0.884),  time:33.773, tt:3411.076\n",
      "Ep:101, loss:0.00003, loss_test:0.12509, lr:1.30e-03, fs:0.84946 (r=0.798,p=0.908),  time:33.782, tt:3445.740\n",
      "Ep:102, loss:0.00003, loss_test:0.12023, lr:1.27e-03, fs:0.86598 (r=0.848,p=0.884),  time:33.768, tt:3478.095\n",
      "Ep:103, loss:0.00003, loss_test:0.12073, lr:1.25e-03, fs:0.84043 (r=0.798,p=0.888),  time:33.780, tt:3513.106\n",
      "Ep:104, loss:0.00003, loss_test:0.12080, lr:1.22e-03, fs:0.83598 (r=0.798,p=0.878),  time:33.779, tt:3546.845\n",
      "Ep:105, loss:0.00003, loss_test:0.11926, lr:1.20e-03, fs:0.85561 (r=0.808,p=0.909),  time:33.768, tt:3579.389\n",
      "Ep:106, loss:0.00003, loss_test:0.11660, lr:1.17e-03, fs:0.87629 (r=0.859,p=0.895),  time:33.755, tt:3611.836\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00003, loss_test:0.11728, lr:1.15e-03, fs:0.87047 (r=0.848,p=0.894),  time:33.741, tt:3644.080\n",
      "Ep:108, loss:0.00003, loss_test:0.12382, lr:1.13e-03, fs:0.83243 (r=0.778,p=0.895),  time:33.746, tt:3678.271\n",
      "Ep:109, loss:0.00003, loss_test:0.12671, lr:1.11e-03, fs:0.83696 (r=0.778,p=0.906),  time:33.734, tt:3710.694\n",
      "Ep:110, loss:0.00003, loss_test:0.12615, lr:1.08e-03, fs:0.83516 (r=0.768,p=0.916),  time:33.733, tt:3744.413\n",
      "Ep:111, loss:0.00003, loss_test:0.12320, lr:1.06e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.738, tt:3778.692\n",
      "Ep:112, loss:0.00003, loss_test:0.12168, lr:1.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:33.732, tt:3811.716\n",
      "Ep:113, loss:0.00003, loss_test:0.12307, lr:1.02e-03, fs:0.86772 (r=0.828,p=0.911),  time:33.718, tt:3843.795\n",
      "Ep:114, loss:0.00003, loss_test:0.12206, lr:9.99e-04, fs:0.87047 (r=0.848,p=0.894),  time:33.705, tt:3876.115\n",
      "Ep:115, loss:0.00003, loss_test:0.12263, lr:9.79e-04, fs:0.84783 (r=0.788,p=0.918),  time:33.703, tt:3909.546\n",
      "Ep:116, loss:0.00003, loss_test:0.12537, lr:9.60e-04, fs:0.83978 (r=0.768,p=0.927),  time:33.692, tt:3941.990\n",
      "Ep:117, loss:0.00002, loss_test:0.12585, lr:9.41e-04, fs:0.85246 (r=0.788,p=0.929),  time:33.695, tt:3975.997\n",
      "Ep:118, loss:0.00003, loss_test:0.12449, lr:9.22e-04, fs:0.84946 (r=0.798,p=0.908),  time:33.685, tt:4008.524\n",
      "Ep:119, loss:0.00003, loss_test:0.12371, lr:9.03e-04, fs:0.85561 (r=0.808,p=0.909),  time:33.677, tt:4041.199\n",
      "Ep:120, loss:0.00003, loss_test:0.12465, lr:8.85e-04, fs:0.83696 (r=0.778,p=0.906),  time:33.665, tt:4073.498\n",
      "Ep:121, loss:0.00003, loss_test:0.12635, lr:8.68e-04, fs:0.83516 (r=0.768,p=0.916),  time:33.658, tt:4106.246\n",
      "Ep:122, loss:0.00003, loss_test:0.12711, lr:8.50e-04, fs:0.82418 (r=0.758,p=0.904),  time:33.618, tt:4134.981\n",
      "Ep:123, loss:0.00003, loss_test:0.12575, lr:8.33e-04, fs:0.83516 (r=0.768,p=0.916),  time:33.622, tt:4169.084\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 32\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24686, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.484, tt:31.484\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.24479, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.087, tt:64.174\n",
      "Ep:2, loss:0.00056, loss_test:0.24033, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:30.241, tt:90.722\n",
      "Ep:3, loss:0.00048, loss_test:0.23008, lr:9.41e-03, fs:0.63194 (r=0.919,p=0.481),  time:30.221, tt:120.886\n",
      "Ep:4, loss:0.00040, loss_test:0.22362, lr:9.22e-03, fs:0.66403 (r=0.848,p=0.545),  time:30.396, tt:151.982\n",
      "Ep:5, loss:0.00033, loss_test:0.22846, lr:9.04e-03, fs:0.63717 (r=0.727,p=0.567),  time:30.191, tt:181.149\n",
      "Ep:6, loss:0.00031, loss_test:0.22871, lr:8.86e-03, fs:0.61538 (r=0.687,p=0.557),  time:30.384, tt:212.689\n",
      "Ep:7, loss:0.00030, loss_test:0.22831, lr:8.68e-03, fs:0.64186 (r=0.697,p=0.595),  time:30.485, tt:243.880\n",
      "Ep:8, loss:0.00029, loss_test:0.22116, lr:8.51e-03, fs:0.63256 (r=0.687,p=0.586),  time:30.783, tt:277.051\n",
      "Ep:9, loss:0.00028, loss_test:0.22126, lr:8.34e-03, fs:0.62857 (r=0.667,p=0.595),  time:31.022, tt:310.219\n",
      "Ep:10, loss:0.00026, loss_test:0.21449, lr:8.17e-03, fs:0.62326 (r=0.677,p=0.578),  time:31.131, tt:342.438\n",
      "Ep:11, loss:0.00026, loss_test:0.20834, lr:8.01e-03, fs:0.64516 (r=0.707,p=0.593),  time:31.236, tt:374.837\n",
      "Ep:12, loss:0.00026, loss_test:0.20562, lr:7.85e-03, fs:0.63927 (r=0.707,p=0.583),  time:31.390, tt:408.066\n",
      "Ep:13, loss:0.00025, loss_test:0.20412, lr:7.69e-03, fs:0.66364 (r=0.737,p=0.603),  time:31.727, tt:444.173\n",
      "Ep:14, loss:0.00025, loss_test:0.20113, lr:7.54e-03, fs:0.65753 (r=0.727,p=0.600),  time:31.821, tt:477.322\n",
      "Ep:15, loss:0.00024, loss_test:0.20231, lr:7.39e-03, fs:0.66019 (r=0.687,p=0.636),  time:32.005, tt:512.082\n",
      "Ep:16, loss:0.00023, loss_test:0.19848, lr:7.24e-03, fs:0.69767 (r=0.758,p=0.647),  time:32.136, tt:546.306\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.19353, lr:7.09e-03, fs:0.71171 (r=0.798,p=0.642),  time:32.277, tt:580.980\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00022, loss_test:0.19888, lr:6.95e-03, fs:0.69951 (r=0.717,p=0.683),  time:32.216, tt:612.097\n",
      "Ep:19, loss:0.00021, loss_test:0.19377, lr:6.81e-03, fs:0.71362 (r=0.768,p=0.667),  time:32.372, tt:647.432\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.19067, lr:6.68e-03, fs:0.72222 (r=0.788,p=0.667),  time:32.424, tt:680.898\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.19212, lr:6.54e-03, fs:0.70755 (r=0.758,p=0.664),  time:32.541, tt:715.902\n",
      "Ep:22, loss:0.00020, loss_test:0.18999, lr:6.41e-03, fs:0.72549 (r=0.747,p=0.705),  time:32.567, tt:749.045\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.18483, lr:6.28e-03, fs:0.72558 (r=0.788,p=0.672),  time:32.597, tt:782.331\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.19011, lr:6.16e-03, fs:0.73077 (r=0.768,p=0.697),  time:32.625, tt:815.613\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.18603, lr:6.03e-03, fs:0.68932 (r=0.717,p=0.664),  time:32.465, tt:844.095\n",
      "Ep:26, loss:0.00018, loss_test:0.18174, lr:5.91e-03, fs:0.72477 (r=0.798,p=0.664),  time:32.006, tt:864.149\n",
      "Ep:27, loss:0.00018, loss_test:0.18384, lr:5.80e-03, fs:0.67943 (r=0.717,p=0.645),  time:31.665, tt:886.607\n",
      "Ep:28, loss:0.00017, loss_test:0.18900, lr:5.68e-03, fs:0.69000 (r=0.697,p=0.683),  time:31.303, tt:907.799\n",
      "Ep:29, loss:0.00017, loss_test:0.18259, lr:5.57e-03, fs:0.73394 (r=0.808,p=0.672),  time:30.966, tt:928.969\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00017, loss_test:0.17884, lr:5.45e-03, fs:0.69811 (r=0.747,p=0.655),  time:30.659, tt:950.425\n",
      "Ep:31, loss:0.00016, loss_test:0.18813, lr:5.35e-03, fs:0.69307 (r=0.707,p=0.680),  time:30.352, tt:971.255\n",
      "Ep:32, loss:0.00016, loss_test:0.17885, lr:5.24e-03, fs:0.73733 (r=0.808,p=0.678),  time:30.030, tt:991.006\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.17245, lr:5.13e-03, fs:0.72889 (r=0.828,p=0.651),  time:29.753, tt:1011.596\n",
      "Ep:34, loss:0.00015, loss_test:0.18176, lr:5.03e-03, fs:0.71569 (r=0.737,p=0.695),  time:29.508, tt:1032.762\n",
      "Ep:35, loss:0.00014, loss_test:0.17853, lr:4.93e-03, fs:0.71287 (r=0.727,p=0.699),  time:29.265, tt:1053.545\n",
      "Ep:36, loss:0.00014, loss_test:0.17233, lr:4.83e-03, fs:0.71889 (r=0.788,p=0.661),  time:29.028, tt:1074.038\n",
      "Ep:37, loss:0.00014, loss_test:0.17448, lr:4.74e-03, fs:0.71429 (r=0.758,p=0.676),  time:28.777, tt:1093.523\n",
      "Ep:38, loss:0.00014, loss_test:0.18103, lr:4.64e-03, fs:0.71717 (r=0.717,p=0.717),  time:28.556, tt:1113.691\n",
      "Ep:39, loss:0.00013, loss_test:0.17657, lr:4.55e-03, fs:0.72464 (r=0.758,p=0.694),  time:28.370, tt:1134.810\n",
      "Ep:40, loss:0.00013, loss_test:0.17326, lr:4.46e-03, fs:0.73333 (r=0.778,p=0.694),  time:28.170, tt:1154.952\n",
      "Ep:41, loss:0.00013, loss_test:0.17649, lr:4.37e-03, fs:0.71000 (r=0.717,p=0.703),  time:27.984, tt:1175.331\n",
      "Ep:42, loss:0.00012, loss_test:0.17288, lr:4.28e-03, fs:0.69565 (r=0.727,p=0.667),  time:27.806, tt:1195.672\n",
      "Ep:43, loss:0.00012, loss_test:0.16918, lr:4.19e-03, fs:0.75598 (r=0.798,p=0.718),  time:27.631, tt:1215.756\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00012, loss_test:0.17238, lr:4.11e-03, fs:0.70352 (r=0.707,p=0.700),  time:27.512, tt:1238.045\n",
      "Ep:45, loss:0.00011, loss_test:0.17170, lr:4.03e-03, fs:0.72115 (r=0.758,p=0.688),  time:27.375, tt:1259.257\n",
      "Ep:46, loss:0.00011, loss_test:0.17462, lr:3.95e-03, fs:0.70297 (r=0.717,p=0.689),  time:27.264, tt:1281.425\n",
      "Ep:47, loss:0.00011, loss_test:0.17477, lr:3.87e-03, fs:0.70352 (r=0.707,p=0.700),  time:27.157, tt:1303.516\n",
      "Ep:48, loss:0.00010, loss_test:0.17259, lr:3.79e-03, fs:0.73267 (r=0.747,p=0.718),  time:27.049, tt:1325.419\n",
      "Ep:49, loss:0.00010, loss_test:0.17359, lr:3.72e-03, fs:0.70352 (r=0.707,p=0.700),  time:26.963, tt:1348.144\n",
      "Ep:50, loss:0.00009, loss_test:0.17207, lr:3.64e-03, fs:0.70000 (r=0.707,p=0.693),  time:26.890, tt:1371.372\n",
      "Ep:51, loss:0.00009, loss_test:0.17595, lr:3.57e-03, fs:0.69744 (r=0.687,p=0.708),  time:26.781, tt:1392.619\n",
      "Ep:52, loss:0.00010, loss_test:0.17526, lr:3.50e-03, fs:0.71875 (r=0.697,p=0.742),  time:26.715, tt:1415.872\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-072c7752a036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,124,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24122, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.959, tt:28.959\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.23664, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.094, tt:62.188\n",
      "Ep:2, loss:0.00055, loss_test:0.22595, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.584, tt:97.751\n",
      "Ep:3, loss:0.00047, loss_test:0.20525, lr:9.70e-03, fs:0.67596 (r=0.980,p=0.516),  time:34.751, tt:139.006\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00037, loss_test:0.19737, lr:9.61e-03, fs:0.69373 (r=0.949,p=0.547),  time:35.817, tt:179.087\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.19652, lr:9.51e-03, fs:0.67500 (r=0.818,p=0.574),  time:36.368, tt:218.208\n",
      "Ep:6, loss:0.00032, loss_test:0.18966, lr:9.41e-03, fs:0.69076 (r=0.869,p=0.573),  time:36.842, tt:257.896\n",
      "Ep:7, loss:0.00030, loss_test:0.18848, lr:9.32e-03, fs:0.68996 (r=0.798,p=0.608),  time:37.927, tt:303.415\n",
      "Ep:8, loss:0.00029, loss_test:0.18536, lr:9.23e-03, fs:0.69643 (r=0.788,p=0.624),  time:38.625, tt:347.622\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.17941, lr:9.14e-03, fs:0.70435 (r=0.818,p=0.618),  time:39.081, tt:390.812\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.17621, lr:9.04e-03, fs:0.71111 (r=0.808,p=0.635),  time:39.671, tt:436.377\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.17110, lr:8.95e-03, fs:0.72103 (r=0.848,p=0.627),  time:39.648, tt:475.775\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.16675, lr:8.86e-03, fs:0.74262 (r=0.889,p=0.638),  time:39.744, tt:516.666\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.16782, lr:8.78e-03, fs:0.74886 (r=0.828,p=0.683),  time:39.841, tt:557.776\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.16221, lr:8.69e-03, fs:0.76724 (r=0.899,p=0.669),  time:39.860, tt:597.893\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.16190, lr:8.60e-03, fs:0.75214 (r=0.889,p=0.652),  time:39.895, tt:638.315\n",
      "Ep:16, loss:0.00024, loss_test:0.16273, lr:8.51e-03, fs:0.72803 (r=0.879,p=0.621),  time:39.818, tt:676.904\n",
      "Ep:17, loss:0.00022, loss_test:0.15761, lr:8.43e-03, fs:0.75000 (r=0.879,p=0.654),  time:40.063, tt:721.127\n",
      "Ep:18, loss:0.00022, loss_test:0.15604, lr:8.35e-03, fs:0.77533 (r=0.889,p=0.688),  time:40.202, tt:763.838\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.15429, lr:8.26e-03, fs:0.74477 (r=0.899,p=0.636),  time:40.400, tt:807.995\n",
      "Ep:20, loss:0.00021, loss_test:0.14982, lr:8.18e-03, fs:0.77586 (r=0.909,p=0.677),  time:40.425, tt:848.922\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.14959, lr:8.10e-03, fs:0.77273 (r=0.859,p=0.702),  time:40.378, tt:888.313\n",
      "Ep:22, loss:0.00020, loss_test:0.14719, lr:8.02e-03, fs:0.77130 (r=0.869,p=0.694),  time:40.373, tt:928.576\n",
      "Ep:23, loss:0.00019, loss_test:0.14952, lr:7.94e-03, fs:0.77333 (r=0.879,p=0.690),  time:40.360, tt:968.643\n",
      "Ep:24, loss:0.00019, loss_test:0.14330, lr:7.86e-03, fs:0.78070 (r=0.899,p=0.690),  time:40.297, tt:1007.413\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.13873, lr:7.78e-03, fs:0.79661 (r=0.949,p=0.686),  time:40.185, tt:1044.814\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.14101, lr:7.70e-03, fs:0.79476 (r=0.919,p=0.700),  time:40.209, tt:1085.646\n",
      "Ep:27, loss:0.00017, loss_test:0.13479, lr:7.62e-03, fs:0.79295 (r=0.909,p=0.703),  time:40.263, tt:1127.361\n",
      "Ep:28, loss:0.00017, loss_test:0.13650, lr:7.55e-03, fs:0.81448 (r=0.909,p=0.738),  time:40.296, tt:1168.597\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.13385, lr:7.47e-03, fs:0.80169 (r=0.960,p=0.688),  time:40.338, tt:1210.149\n",
      "Ep:30, loss:0.00016, loss_test:0.13674, lr:7.40e-03, fs:0.81818 (r=0.909,p=0.744),  time:40.319, tt:1249.900\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.12872, lr:7.32e-03, fs:0.82819 (r=0.949,p=0.734),  time:40.277, tt:1288.865\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.12668, lr:7.25e-03, fs:0.83408 (r=0.939,p=0.750),  time:40.218, tt:1327.183\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.13244, lr:7.18e-03, fs:0.87442 (r=0.949,p=0.810),  time:40.230, tt:1367.803\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.12617, lr:7.11e-03, fs:0.84071 (r=0.960,p=0.748),  time:40.194, tt:1406.789\n",
      "Ep:35, loss:0.00013, loss_test:0.12336, lr:7.03e-03, fs:0.87442 (r=0.949,p=0.810),  time:40.157, tt:1445.652\n",
      "Ep:36, loss:0.00013, loss_test:0.12050, lr:6.96e-03, fs:0.82969 (r=0.960,p=0.731),  time:40.202, tt:1487.478\n",
      "Ep:37, loss:0.00012, loss_test:0.12202, lr:6.89e-03, fs:0.82819 (r=0.949,p=0.734),  time:40.248, tt:1529.430\n",
      "Ep:38, loss:0.00012, loss_test:0.11940, lr:6.83e-03, fs:0.89423 (r=0.939,p=0.853),  time:40.315, tt:1572.296\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.11842, lr:6.76e-03, fs:0.85586 (r=0.960,p=0.772),  time:40.348, tt:1613.913\n",
      "Ep:40, loss:0.00011, loss_test:0.11782, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:40.317, tt:1653.009\n",
      "Ep:41, loss:0.00011, loss_test:0.12248, lr:6.62e-03, fs:0.88152 (r=0.939,p=0.830),  time:40.336, tt:1694.096\n",
      "Ep:42, loss:0.00010, loss_test:0.11954, lr:6.56e-03, fs:0.87037 (r=0.949,p=0.803),  time:40.304, tt:1733.059\n",
      "Ep:43, loss:0.00009, loss_test:0.11405, lr:6.49e-03, fs:0.87558 (r=0.960,p=0.805),  time:40.290, tt:1772.741\n",
      "Ep:44, loss:0.00010, loss_test:0.11847, lr:6.43e-03, fs:0.88785 (r=0.960,p=0.826),  time:40.248, tt:1811.172\n",
      "Ep:45, loss:0.00009, loss_test:0.10990, lr:6.36e-03, fs:0.88372 (r=0.960,p=0.819),  time:40.189, tt:1848.711\n",
      "Ep:46, loss:0.00008, loss_test:0.11642, lr:6.30e-03, fs:0.90385 (r=0.949,p=0.862),  time:40.200, tt:1889.390\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.10431, lr:6.24e-03, fs:0.89623 (r=0.960,p=0.841),  time:40.238, tt:1931.446\n",
      "Ep:48, loss:0.00007, loss_test:0.09894, lr:6.17e-03, fs:0.90476 (r=0.960,p=0.856),  time:40.250, tt:1972.234\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.10509, lr:6.11e-03, fs:0.88995 (r=0.939,p=0.845),  time:40.268, tt:2013.407\n",
      "Ep:50, loss:0.00007, loss_test:0.10190, lr:6.05e-03, fs:0.90476 (r=0.960,p=0.856),  time:40.241, tt:2052.310\n",
      "Ep:51, loss:0.00006, loss_test:0.09630, lr:5.99e-03, fs:0.89952 (r=0.949,p=0.855),  time:40.227, tt:2091.790\n",
      "Ep:52, loss:0.00006, loss_test:0.10444, lr:5.93e-03, fs:0.89100 (r=0.949,p=0.839),  time:40.173, tt:2129.149\n",
      "Ep:53, loss:0.00005, loss_test:0.12462, lr:5.87e-03, fs:0.88660 (r=0.869,p=0.905),  time:40.153, tt:2168.268\n",
      "Ep:54, loss:0.00006, loss_test:0.09445, lr:5.81e-03, fs:0.90047 (r=0.960,p=0.848),  time:40.153, tt:2208.426\n",
      "Ep:55, loss:0.00005, loss_test:0.12297, lr:5.75e-03, fs:0.86432 (r=0.869,p=0.860),  time:40.102, tt:2245.696\n",
      "Ep:56, loss:0.00006, loss_test:0.11555, lr:5.70e-03, fs:0.86700 (r=0.889,p=0.846),  time:40.141, tt:2288.063\n",
      "Ep:57, loss:0.00005, loss_test:0.10676, lr:5.64e-03, fs:0.92683 (r=0.960,p=0.896),  time:40.222, tt:2332.851\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.12172, lr:5.58e-03, fs:0.88442 (r=0.889,p=0.880),  time:40.239, tt:2374.116\n",
      "Ep:59, loss:0.00005, loss_test:0.11539, lr:5.53e-03, fs:0.90821 (r=0.949,p=0.870),  time:40.305, tt:2418.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.09805, lr:5.47e-03, fs:0.92157 (r=0.949,p=0.895),  time:40.330, tt:2460.142\n",
      "Ep:61, loss:0.00004, loss_test:0.11319, lr:5.42e-03, fs:0.88235 (r=0.909,p=0.857),  time:40.358, tt:2502.206\n",
      "Ep:62, loss:0.00004, loss_test:0.09964, lr:5.36e-03, fs:0.93000 (r=0.939,p=0.921),  time:40.366, tt:2543.061\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.12334, lr:5.31e-03, fs:0.90155 (r=0.879,p=0.926),  time:40.395, tt:2585.274\n",
      "Ep:64, loss:0.00004, loss_test:0.12291, lr:5.26e-03, fs:0.88000 (r=0.889,p=0.871),  time:40.358, tt:2623.301\n",
      "Ep:65, loss:0.00003, loss_test:0.11320, lr:5.20e-03, fs:0.92683 (r=0.960,p=0.896),  time:40.377, tt:2664.864\n",
      "Ep:66, loss:0.00003, loss_test:0.11601, lr:5.15e-03, fs:0.88442 (r=0.889,p=0.880),  time:40.443, tt:2709.684\n",
      "Ep:67, loss:0.00003, loss_test:0.11683, lr:5.10e-03, fs:0.93596 (r=0.960,p=0.913),  time:40.475, tt:2752.323\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.12170, lr:5.05e-03, fs:0.88889 (r=0.889,p=0.889),  time:40.528, tt:2796.431\n",
      "Ep:69, loss:0.00003, loss_test:0.13391, lr:5.00e-03, fs:0.87179 (r=0.859,p=0.885),  time:40.553, tt:2838.722\n",
      "Ep:70, loss:0.00002, loss_test:0.11576, lr:4.95e-03, fs:0.85263 (r=0.818,p=0.890),  time:40.568, tt:2880.349\n",
      "Ep:71, loss:0.00002, loss_test:0.11444, lr:4.90e-03, fs:0.91837 (r=0.909,p=0.928),  time:40.574, tt:2921.352\n",
      "Ep:72, loss:0.00002, loss_test:0.11328, lr:4.85e-03, fs:0.89340 (r=0.889,p=0.898),  time:40.569, tt:2961.560\n",
      "Ep:73, loss:0.00002, loss_test:0.12396, lr:4.80e-03, fs:0.88083 (r=0.859,p=0.904),  time:40.563, tt:3001.686\n",
      "Ep:74, loss:0.00002, loss_test:0.12779, lr:4.75e-03, fs:0.90355 (r=0.899,p=0.908),  time:40.553, tt:3041.449\n",
      "Ep:75, loss:0.00002, loss_test:0.12345, lr:4.71e-03, fs:0.85263 (r=0.818,p=0.890),  time:40.561, tt:3082.632\n",
      "Ep:76, loss:0.00002, loss_test:0.11925, lr:4.66e-03, fs:0.85567 (r=0.838,p=0.874),  time:40.629, tt:3128.404\n",
      "Ep:77, loss:0.00002, loss_test:0.10971, lr:4.61e-03, fs:0.92308 (r=0.909,p=0.938),  time:40.653, tt:3170.911\n",
      "Ep:78, loss:0.00002, loss_test:0.12334, lr:4.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:40.670, tt:3212.892\n",
      "Ep:79, loss:0.00002, loss_test:0.12273, lr:4.48e-03, fs:0.89796 (r=0.889,p=0.907),  time:40.674, tt:3253.931\n",
      "Ep:80, loss:0.00002, loss_test:0.11607, lr:4.39e-03, fs:0.90052 (r=0.869,p=0.935),  time:40.659, tt:3293.419\n",
      "Ep:81, loss:0.00002, loss_test:0.12447, lr:4.30e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.625, tt:3331.234\n",
      "Ep:82, loss:0.00001, loss_test:0.11490, lr:4.21e-03, fs:0.87234 (r=0.828,p=0.921),  time:40.609, tt:3370.533\n",
      "Ep:83, loss:0.00001, loss_test:0.11330, lr:4.13e-03, fs:0.92386 (r=0.919,p=0.929),  time:40.602, tt:3410.556\n",
      "Ep:84, loss:0.00001, loss_test:0.12331, lr:4.05e-03, fs:0.86316 (r=0.828,p=0.901),  time:40.589, tt:3450.087\n",
      "Ep:85, loss:0.00001, loss_test:0.12022, lr:3.97e-03, fs:0.86772 (r=0.828,p=0.911),  time:40.624, tt:3493.702\n",
      "Ep:86, loss:0.00001, loss_test:0.11759, lr:3.89e-03, fs:0.85405 (r=0.798,p=0.919),  time:40.639, tt:3535.618\n",
      "Ep:87, loss:0.00001, loss_test:0.12188, lr:3.81e-03, fs:0.87831 (r=0.838,p=0.922),  time:40.666, tt:3578.633\n",
      "Ep:88, loss:0.00001, loss_test:0.13055, lr:3.73e-03, fs:0.85870 (r=0.798,p=0.929),  time:40.696, tt:3621.900\n",
      "Ep:89, loss:0.00001, loss_test:0.13190, lr:3.66e-03, fs:0.80874 (r=0.747,p=0.881),  time:40.672, tt:3660.445\n",
      "Ep:90, loss:0.00001, loss_test:0.12788, lr:3.59e-03, fs:0.85870 (r=0.798,p=0.929),  time:40.680, tt:3701.874\n",
      "Ep:91, loss:0.00001, loss_test:0.13073, lr:3.52e-03, fs:0.83978 (r=0.768,p=0.927),  time:40.677, tt:3742.279\n",
      "Ep:92, loss:0.00001, loss_test:0.13032, lr:3.45e-03, fs:0.84783 (r=0.788,p=0.918),  time:40.668, tt:3782.122\n",
      "Ep:93, loss:0.00001, loss_test:0.12325, lr:3.38e-03, fs:0.87831 (r=0.838,p=0.922),  time:40.659, tt:3821.909\n",
      "Ep:94, loss:0.00001, loss_test:0.12322, lr:3.31e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.663, tt:3863.033\n",
      "Ep:95, loss:0.00001, loss_test:0.12781, lr:3.24e-03, fs:0.89947 (r=0.859,p=0.944),  time:40.680, tt:3905.279\n",
      "Ep:96, loss:0.00001, loss_test:0.12794, lr:3.18e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.742, tt:3952.018\n",
      "Ep:97, loss:0.00001, loss_test:0.12998, lr:3.12e-03, fs:0.86772 (r=0.828,p=0.911),  time:40.794, tt:3997.778\n",
      "Ep:98, loss:0.00001, loss_test:0.12828, lr:3.05e-03, fs:0.82222 (r=0.747,p=0.914),  time:40.816, tt:4040.749\n",
      "Ep:99, loss:0.00001, loss_test:0.12583, lr:2.99e-03, fs:0.83799 (r=0.758,p=0.938),  time:40.812, tt:4081.248\n",
      "Ep:100, loss:0.00001, loss_test:0.13357, lr:2.93e-03, fs:0.85714 (r=0.788,p=0.940),  time:40.806, tt:4121.438\n",
      "Ep:101, loss:0.00000, loss_test:0.13464, lr:2.88e-03, fs:0.86486 (r=0.808,p=0.930),  time:40.804, tt:4161.993\n",
      "Ep:102, loss:0.00001, loss_test:0.13215, lr:2.82e-03, fs:0.83333 (r=0.758,p=0.926),  time:40.794, tt:4201.733\n",
      "Ep:103, loss:0.00000, loss_test:0.12954, lr:2.76e-03, fs:0.86316 (r=0.828,p=0.901),  time:40.781, tt:4241.184\n",
      "Ep:104, loss:0.00001, loss_test:0.12674, lr:2.71e-03, fs:0.89005 (r=0.859,p=0.924),  time:40.773, tt:4281.160\n",
      "Ep:105, loss:0.00001, loss_test:0.12984, lr:2.65e-03, fs:0.88542 (r=0.859,p=0.914),  time:40.781, tt:4322.789\n",
      "Ep:106, loss:0.00000, loss_test:0.13024, lr:2.60e-03, fs:0.85870 (r=0.798,p=0.929),  time:40.797, tt:4365.257\n",
      "Ep:107, loss:0.00000, loss_test:0.12961, lr:2.55e-03, fs:0.84153 (r=0.778,p=0.917),  time:40.816, tt:4408.092\n",
      "Ep:108, loss:0.00000, loss_test:0.13143, lr:2.50e-03, fs:0.88172 (r=0.828,p=0.943),  time:40.842, tt:4451.731\n",
      "Ep:109, loss:0.00000, loss_test:0.13097, lr:2.45e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.837, tt:4492.103\n",
      "Ep:110, loss:0.00001, loss_test:0.13004, lr:2.40e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.849, tt:4534.218\n",
      "Ep:111, loss:0.00000, loss_test:0.12836, lr:2.35e-03, fs:0.86631 (r=0.818,p=0.920),  time:40.853, tt:4575.590\n",
      "Ep:112, loss:0.00000, loss_test:0.12730, lr:2.31e-03, fs:0.84946 (r=0.798,p=0.908),  time:40.862, tt:4617.454\n",
      "Ep:113, loss:0.00000, loss_test:0.12683, lr:2.26e-03, fs:0.87701 (r=0.828,p=0.932),  time:40.853, tt:4657.275\n",
      "Ep:114, loss:0.00000, loss_test:0.12971, lr:2.21e-03, fs:0.87701 (r=0.828,p=0.932),  time:40.862, tt:4699.158\n",
      "Ep:115, loss:0.00000, loss_test:0.12918, lr:2.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:40.899, tt:4744.234\n",
      "Ep:116, loss:0.00000, loss_test:0.12861, lr:2.13e-03, fs:0.84444 (r=0.768,p=0.938),  time:40.937, tt:4789.673\n",
      "Ep:117, loss:0.00000, loss_test:0.12762, lr:2.08e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.955, tt:4832.672\n",
      "Ep:118, loss:0.00000, loss_test:0.12632, lr:2.04e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.924, tt:4869.927\n",
      "Ep:119, loss:0.00000, loss_test:0.12516, lr:2.00e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.936, tt:4912.347\n",
      "Ep:120, loss:0.00000, loss_test:0.12594, lr:1.96e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.941, tt:4953.922\n",
      "Ep:121, loss:0.00000, loss_test:0.12713, lr:1.92e-03, fs:0.86631 (r=0.818,p=0.920),  time:40.953, tt:4996.309\n",
      "Ep:122, loss:0.00000, loss_test:0.12806, lr:1.89e-03, fs:0.82682 (r=0.747,p=0.925),  time:40.965, tt:5038.661\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.23747, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.617, tt:37.617\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.23098, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.658, tt:77.316\n",
      "Ep:2, loss:0.00055, loss_test:0.21614, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.204, tt:120.612\n",
      "Ep:3, loss:0.00048, loss_test:0.19097, lr:9.70e-03, fs:0.68613 (r=0.949,p=0.537),  time:41.333, tt:165.331\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00038, loss_test:0.18737, lr:9.61e-03, fs:0.69880 (r=0.879,p=0.580),  time:41.369, tt:206.847\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00033, loss_test:0.18992, lr:9.51e-03, fs:0.70435 (r=0.818,p=0.618),  time:41.145, tt:246.867\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00032, loss_test:0.18733, lr:9.41e-03, fs:0.70485 (r=0.808,p=0.625),  time:40.862, tt:286.033\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.18446, lr:9.32e-03, fs:0.71053 (r=0.818,p=0.628),  time:40.651, tt:325.208\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.18045, lr:9.23e-03, fs:0.72973 (r=0.818,p=0.659),  time:40.572, tt:365.148\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.17715, lr:9.14e-03, fs:0.73973 (r=0.818,p=0.675),  time:40.537, tt:405.366\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.17391, lr:9.04e-03, fs:0.75962 (r=0.798,p=0.725),  time:40.530, tt:445.828\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.16613, lr:8.95e-03, fs:0.76106 (r=0.869,p=0.677),  time:41.014, tt:492.172\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.16715, lr:8.86e-03, fs:0.78673 (r=0.838,p=0.741),  time:41.196, tt:535.546\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.16523, lr:8.78e-03, fs:0.78673 (r=0.838,p=0.741),  time:41.493, tt:580.899\n",
      "Ep:14, loss:0.00025, loss_test:0.15990, lr:8.69e-03, fs:0.78704 (r=0.859,p=0.726),  time:41.586, tt:623.795\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.15625, lr:8.60e-03, fs:0.81690 (r=0.879,p=0.763),  time:41.481, tt:663.692\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.15463, lr:8.51e-03, fs:0.81132 (r=0.869,p=0.761),  time:41.485, tt:705.245\n",
      "Ep:17, loss:0.00023, loss_test:0.15422, lr:8.43e-03, fs:0.82297 (r=0.869,p=0.782),  time:41.394, tt:745.097\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.14948, lr:8.35e-03, fs:0.79263 (r=0.869,p=0.729),  time:41.305, tt:784.794\n",
      "Ep:19, loss:0.00022, loss_test:0.15081, lr:8.26e-03, fs:0.81690 (r=0.879,p=0.763),  time:41.206, tt:824.125\n",
      "Ep:20, loss:0.00021, loss_test:0.14535, lr:8.18e-03, fs:0.81106 (r=0.889,p=0.746),  time:41.353, tt:868.412\n",
      "Ep:21, loss:0.00020, loss_test:0.14299, lr:8.10e-03, fs:0.81081 (r=0.909,p=0.732),  time:41.481, tt:912.575\n",
      "Ep:22, loss:0.00020, loss_test:0.14235, lr:8.02e-03, fs:0.83495 (r=0.869,p=0.804),  time:41.527, tt:955.110\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.13658, lr:7.94e-03, fs:0.81057 (r=0.929,p=0.719),  time:41.687, tt:1000.483\n",
      "Ep:24, loss:0.00018, loss_test:0.13939, lr:7.86e-03, fs:0.83019 (r=0.889,p=0.779),  time:41.635, tt:1040.886\n",
      "Ep:25, loss:0.00018, loss_test:0.13191, lr:7.78e-03, fs:0.80889 (r=0.919,p=0.722),  time:41.640, tt:1082.637\n",
      "Ep:26, loss:0.00017, loss_test:0.13661, lr:7.70e-03, fs:0.85714 (r=0.909,p=0.811),  time:41.589, tt:1122.912\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.12975, lr:7.62e-03, fs:0.81938 (r=0.939,p=0.727),  time:41.589, tt:1164.496\n",
      "Ep:28, loss:0.00015, loss_test:0.13695, lr:7.55e-03, fs:0.83412 (r=0.889,p=0.786),  time:41.502, tt:1203.553\n",
      "Ep:29, loss:0.00015, loss_test:0.12735, lr:7.47e-03, fs:0.82143 (r=0.929,p=0.736),  time:41.503, tt:1245.092\n",
      "Ep:30, loss:0.00014, loss_test:0.13047, lr:7.40e-03, fs:0.86256 (r=0.919,p=0.812),  time:41.575, tt:1288.816\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.12831, lr:7.32e-03, fs:0.85455 (r=0.949,p=0.777),  time:41.626, tt:1332.033\n",
      "Ep:32, loss:0.00013, loss_test:0.12884, lr:7.25e-03, fs:0.85714 (r=0.909,p=0.811),  time:41.784, tt:1378.888\n",
      "Ep:33, loss:0.00013, loss_test:0.12606, lr:7.18e-03, fs:0.86512 (r=0.939,p=0.802),  time:41.786, tt:1420.719\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.12896, lr:7.11e-03, fs:0.83744 (r=0.859,p=0.817),  time:41.754, tt:1461.380\n",
      "Ep:35, loss:0.00012, loss_test:0.13216, lr:7.03e-03, fs:0.81188 (r=0.828,p=0.796),  time:41.748, tt:1502.929\n",
      "Ep:36, loss:0.00011, loss_test:0.12539, lr:6.96e-03, fs:0.85308 (r=0.909,p=0.804),  time:41.759, tt:1545.097\n",
      "Ep:37, loss:0.00011, loss_test:0.12784, lr:6.89e-03, fs:0.87179 (r=0.859,p=0.885),  time:41.689, tt:1584.174\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.12991, lr:6.83e-03, fs:0.84375 (r=0.818,p=0.871),  time:41.631, tt:1623.614\n",
      "Ep:39, loss:0.00010, loss_test:0.12157, lr:6.76e-03, fs:0.84058 (r=0.879,p=0.806),  time:41.695, tt:1667.817\n",
      "Ep:40, loss:0.00009, loss_test:0.13180, lr:6.69e-03, fs:0.79793 (r=0.778,p=0.819),  time:41.722, tt:1710.600\n",
      "Ep:41, loss:0.00009, loss_test:0.12911, lr:6.62e-03, fs:0.83598 (r=0.798,p=0.878),  time:41.809, tt:1755.971\n",
      "Ep:42, loss:0.00009, loss_test:0.12168, lr:6.56e-03, fs:0.86735 (r=0.859,p=0.876),  time:41.887, tt:1801.137\n",
      "Ep:43, loss:0.00008, loss_test:0.12885, lr:6.49e-03, fs:0.82796 (r=0.778,p=0.885),  time:41.869, tt:1842.244\n",
      "Ep:44, loss:0.00007, loss_test:0.12641, lr:6.43e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.851, tt:1883.283\n",
      "Ep:45, loss:0.00007, loss_test:0.12186, lr:6.36e-03, fs:0.79803 (r=0.818,p=0.779),  time:41.835, tt:1924.426\n",
      "Ep:46, loss:0.00007, loss_test:0.12778, lr:6.30e-03, fs:0.81481 (r=0.778,p=0.856),  time:41.823, tt:1965.679\n",
      "Ep:47, loss:0.00007, loss_test:0.11772, lr:6.24e-03, fs:0.84264 (r=0.838,p=0.847),  time:41.771, tt:2005.030\n",
      "Ep:48, loss:0.00007, loss_test:0.13213, lr:6.17e-03, fs:0.83243 (r=0.778,p=0.895),  time:41.735, tt:2045.022\n",
      "Ep:49, loss:0.00006, loss_test:0.11878, lr:6.05e-03, fs:0.79581 (r=0.768,p=0.826),  time:41.781, tt:2089.031\n",
      "Ep:50, loss:0.00005, loss_test:0.11773, lr:5.93e-03, fs:0.82353 (r=0.778,p=0.875),  time:41.815, tt:2132.586\n",
      "Ep:51, loss:0.00005, loss_test:0.12383, lr:5.81e-03, fs:0.83516 (r=0.768,p=0.916),  time:41.893, tt:2178.460\n",
      "Ep:52, loss:0.00005, loss_test:0.12858, lr:5.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:41.978, tt:2224.847\n",
      "Ep:53, loss:0.00004, loss_test:0.12402, lr:5.58e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.960, tt:2265.858\n",
      "Ep:54, loss:0.00004, loss_test:0.11351, lr:5.47e-03, fs:0.82105 (r=0.788,p=0.857),  time:41.925, tt:2305.860\n",
      "Ep:55, loss:0.00004, loss_test:0.12269, lr:5.36e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.924, tt:2347.731\n",
      "Ep:56, loss:0.00004, loss_test:0.12183, lr:5.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.934, tt:2390.210\n",
      "Ep:57, loss:0.00003, loss_test:0.12218, lr:5.15e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.934, tt:2432.197\n",
      "Ep:58, loss:0.00003, loss_test:0.12086, lr:5.05e-03, fs:0.83871 (r=0.788,p=0.897),  time:41.977, tt:2476.667\n",
      "Ep:59, loss:0.00003, loss_test:0.11954, lr:4.95e-03, fs:0.83696 (r=0.778,p=0.906),  time:42.042, tt:2522.503\n",
      "Ep:60, loss:0.00003, loss_test:0.12220, lr:4.85e-03, fs:0.81657 (r=0.697,p=0.986),  time:42.117, tt:2569.106\n",
      "Ep:61, loss:0.00003, loss_test:0.11945, lr:4.75e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.164, tt:2614.197\n",
      "Ep:62, loss:0.00002, loss_test:0.11900, lr:4.66e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.212, tt:2659.378\n",
      "Ep:63, loss:0.00002, loss_test:0.11348, lr:4.57e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.220, tt:2702.078\n",
      "Ep:64, loss:0.00002, loss_test:0.12224, lr:4.48e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.208, tt:2743.512\n",
      "Ep:65, loss:0.00002, loss_test:0.11608, lr:4.39e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.205, tt:2785.552\n",
      "Ep:66, loss:0.00002, loss_test:0.11696, lr:4.30e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.206, tt:2827.771\n",
      "Ep:67, loss:0.00002, loss_test:0.12170, lr:4.21e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.203, tt:2869.830\n",
      "Ep:68, loss:0.00002, loss_test:0.11882, lr:4.13e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.211, tt:2912.533\n",
      "Ep:69, loss:0.00002, loss_test:0.11659, lr:4.05e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.259, tt:2958.160\n",
      "Ep:70, loss:0.00002, loss_test:0.11502, lr:3.97e-03, fs:0.85556 (r=0.778,p=0.951),  time:42.265, tt:3000.810\n",
      "Ep:71, loss:0.00002, loss_test:0.11916, lr:3.89e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.306, tt:3046.037\n",
      "Ep:72, loss:0.00002, loss_test:0.12739, lr:3.81e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.287, tt:3086.983\n",
      "Ep:73, loss:0.00001, loss_test:0.12123, lr:3.73e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.278, tt:3128.551\n",
      "Ep:74, loss:0.00001, loss_test:0.12103, lr:3.66e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.272, tt:3170.417\n",
      "Ep:75, loss:0.00001, loss_test:0.12616, lr:3.59e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.265, tt:3212.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:76, loss:0.00001, loss_test:0.12220, lr:3.52e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.252, tt:3253.380\n",
      "Ep:77, loss:0.00001, loss_test:0.11902, lr:3.45e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.226, tt:3293.639\n",
      "Ep:78, loss:0.00001, loss_test:0.12767, lr:3.38e-03, fs:0.79310 (r=0.697,p=0.920),  time:42.236, tt:3336.670\n",
      "Ep:79, loss:0.00001, loss_test:0.11614, lr:3.31e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.263, tt:3381.054\n",
      "Ep:80, loss:0.00001, loss_test:0.11730, lr:3.24e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.295, tt:3425.883\n",
      "Ep:81, loss:0.00001, loss_test:0.12441, lr:3.18e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.319, tt:3470.169\n",
      "Ep:82, loss:0.00001, loss_test:0.11986, lr:3.12e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.301, tt:3510.974\n",
      "Ep:83, loss:0.00001, loss_test:0.11492, lr:3.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.274, tt:3551.026\n",
      "Ep:84, loss:0.00001, loss_test:0.12056, lr:2.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:42.244, tt:3590.705\n",
      "Ep:85, loss:0.00001, loss_test:0.12249, lr:2.93e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.209, tt:3630.012\n",
      "Ep:86, loss:0.00001, loss_test:0.12352, lr:2.88e-03, fs:0.82682 (r=0.747,p=0.925),  time:42.169, tt:3668.703\n",
      "Ep:87, loss:0.00001, loss_test:0.12257, lr:2.82e-03, fs:0.84571 (r=0.747,p=0.974),  time:42.140, tt:3708.307\n",
      "Ep:88, loss:0.00001, loss_test:0.12183, lr:2.76e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.119, tt:3748.633\n",
      "Ep:89, loss:0.00001, loss_test:0.12085, lr:2.71e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.100, tt:3789.040\n",
      "Ep:90, loss:0.00001, loss_test:0.12526, lr:2.65e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.080, tt:3829.284\n",
      "Ep:91, loss:0.00001, loss_test:0.12753, lr:2.60e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.072, tt:3870.639\n",
      "Ep:92, loss:0.00001, loss_test:0.12175, lr:2.55e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.046, tt:3910.310\n",
      "Ep:93, loss:0.00001, loss_test:0.11955, lr:2.50e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.025, tt:3950.326\n",
      "Ep:94, loss:0.00001, loss_test:0.12261, lr:2.45e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.998, tt:3989.845\n",
      "Ep:95, loss:0.00001, loss_test:0.12583, lr:2.40e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.998, tt:4031.799\n",
      "Ep:96, loss:0.00001, loss_test:0.12164, lr:2.35e-03, fs:0.84091 (r=0.747,p=0.961),  time:41.982, tt:4072.284\n",
      "Ep:97, loss:0.00001, loss_test:0.11865, lr:2.31e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.952, tt:4111.259\n",
      "Ep:98, loss:0.00001, loss_test:0.11818, lr:2.26e-03, fs:0.84783 (r=0.788,p=0.918),  time:41.938, tt:4151.846\n",
      "Ep:99, loss:0.00001, loss_test:0.11972, lr:2.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.938, tt:4193.822\n",
      "Ep:100, loss:0.00001, loss_test:0.12321, lr:2.17e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.929, tt:4234.820\n",
      "Ep:101, loss:0.00001, loss_test:0.12353, lr:2.13e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.908, tt:4274.652\n",
      "Ep:102, loss:0.00001, loss_test:0.11971, lr:2.08e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.886, tt:4314.255\n",
      "Ep:103, loss:0.00001, loss_test:0.11900, lr:2.04e-03, fs:0.85246 (r=0.788,p=0.929),  time:41.884, tt:4355.922\n",
      "Ep:104, loss:0.00001, loss_test:0.12158, lr:2.00e-03, fs:0.84091 (r=0.747,p=0.961),  time:41.868, tt:4396.115\n",
      "Ep:105, loss:0.00001, loss_test:0.12421, lr:1.96e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.842, tt:4435.206\n",
      "Ep:106, loss:0.00001, loss_test:0.12586, lr:1.92e-03, fs:0.81395 (r=0.707,p=0.959),  time:41.819, tt:4474.626\n",
      "Ep:107, loss:0.00001, loss_test:0.12147, lr:1.89e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.783, tt:4512.580\n",
      "Ep:108, loss:0.00001, loss_test:0.12015, lr:1.85e-03, fs:0.84783 (r=0.788,p=0.918),  time:41.753, tt:4551.051\n",
      "Ep:109, loss:0.00001, loss_test:0.11940, lr:1.81e-03, fs:0.84783 (r=0.788,p=0.918),  time:41.722, tt:4589.431\n",
      "Ep:110, loss:0.00001, loss_test:0.12087, lr:1.78e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.690, tt:4627.630\n",
      "Ep:111, loss:0.00001, loss_test:0.12435, lr:1.74e-03, fs:0.84091 (r=0.747,p=0.961),  time:41.656, tt:4665.424\n",
      "Ep:112, loss:0.00001, loss_test:0.12543, lr:1.71e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.629, tt:4704.064\n",
      "Ep:113, loss:0.00001, loss_test:0.12210, lr:1.67e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.593, tt:4741.616\n",
      "Ep:114, loss:0.00001, loss_test:0.11900, lr:1.64e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.570, tt:4780.519\n",
      "Ep:115, loss:0.00001, loss_test:0.12262, lr:1.61e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.535, tt:4818.103\n",
      "Ep:116, loss:0.00001, loss_test:0.12713, lr:1.57e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.510, tt:4856.721\n",
      "Ep:117, loss:0.00001, loss_test:0.12733, lr:1.54e-03, fs:0.79310 (r=0.697,p=0.920),  time:41.458, tt:4892.012\n",
      "Ep:118, loss:0.00001, loss_test:0.12536, lr:1.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.431, tt:4930.255\n",
      "Ep:119, loss:0.00001, loss_test:0.12329, lr:1.48e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.405, tt:4968.550\n",
      "Ep:120, loss:0.00001, loss_test:0.12099, lr:1.45e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.385, tt:5007.541\n",
      "Ep:121, loss:0.00001, loss_test:0.12035, lr:1.42e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.375, tt:5047.740\n",
      "Ep:122, loss:0.00001, loss_test:0.12201, lr:1.39e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.334, tt:5084.038\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 32\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24433, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.568, tt:33.568\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.24111, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:35.078, tt:70.155\n",
      "Ep:2, loss:0.00055, loss_test:0.23320, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:37.032, tt:111.095\n",
      "Ep:3, loss:0.00046, loss_test:0.21770, lr:9.70e-03, fs:0.64260 (r=0.899,p=0.500),  time:38.008, tt:152.032\n",
      "Ep:4, loss:0.00035, loss_test:0.21923, lr:9.61e-03, fs:0.66667 (r=0.828,p=0.558),  time:38.565, tt:192.827\n",
      "Ep:5, loss:0.00032, loss_test:0.22149, lr:9.51e-03, fs:0.64286 (r=0.727,p=0.576),  time:38.641, tt:231.846\n",
      "Ep:6, loss:0.00031, loss_test:0.22114, lr:9.41e-03, fs:0.64220 (r=0.707,p=0.588),  time:38.448, tt:269.133\n",
      "Ep:7, loss:0.00029, loss_test:0.21878, lr:9.32e-03, fs:0.62727 (r=0.697,p=0.570),  time:38.535, tt:308.280\n",
      "Ep:8, loss:0.00028, loss_test:0.21877, lr:9.23e-03, fs:0.63507 (r=0.677,p=0.598),  time:38.613, tt:347.519\n",
      "Ep:9, loss:0.00028, loss_test:0.21643, lr:9.14e-03, fs:0.62264 (r=0.667,p=0.584),  time:38.500, tt:385.003\n",
      "Ep:10, loss:0.00027, loss_test:0.21507, lr:9.04e-03, fs:0.64390 (r=0.667,p=0.623),  time:38.637, tt:425.009\n",
      "Ep:11, loss:0.00025, loss_test:0.20764, lr:8.95e-03, fs:0.64840 (r=0.717,p=0.592),  time:38.705, tt:464.464\n",
      "Ep:12, loss:0.00026, loss_test:0.20819, lr:8.78e-03, fs:0.64390 (r=0.667,p=0.623),  time:38.762, tt:503.911\n",
      "Ep:13, loss:0.00024, loss_test:0.20207, lr:8.60e-03, fs:0.65025 (r=0.667,p=0.635),  time:38.830, tt:543.623\n",
      "Ep:14, loss:0.00024, loss_test:0.19537, lr:8.43e-03, fs:0.68837 (r=0.747,p=0.638),  time:38.771, tt:581.562\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.19703, lr:8.35e-03, fs:0.69000 (r=0.697,p=0.683),  time:38.863, tt:621.814\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.19559, lr:8.26e-03, fs:0.68657 (r=0.697,p=0.676),  time:38.913, tt:661.519\n",
      "Ep:17, loss:0.00023, loss_test:0.18860, lr:8.18e-03, fs:0.69903 (r=0.727,p=0.673),  time:38.922, tt:700.588\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.18449, lr:8.10e-03, fs:0.69565 (r=0.727,p=0.667),  time:38.915, tt:739.392\n",
      "Ep:19, loss:0.00021, loss_test:0.19124, lr:8.02e-03, fs:0.70000 (r=0.707,p=0.693),  time:38.877, tt:777.548\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.18741, lr:7.94e-03, fs:0.69652 (r=0.707,p=0.686),  time:38.892, tt:816.740\n",
      "Ep:21, loss:0.00020, loss_test:0.18106, lr:7.86e-03, fs:0.68599 (r=0.717,p=0.657),  time:38.855, tt:854.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00019, loss_test:0.18111, lr:7.78e-03, fs:0.71717 (r=0.717,p=0.717),  time:38.867, tt:893.930\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.17802, lr:7.70e-03, fs:0.74641 (r=0.788,p=0.709),  time:38.802, tt:931.238\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.18024, lr:7.62e-03, fs:0.75377 (r=0.758,p=0.750),  time:38.751, tt:968.773\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.17687, lr:7.55e-03, fs:0.74000 (r=0.747,p=0.733),  time:38.786, tt:1008.429\n",
      "Ep:26, loss:0.00017, loss_test:0.17017, lr:7.47e-03, fs:0.72222 (r=0.788,p=0.667),  time:38.781, tt:1047.097\n",
      "Ep:27, loss:0.00016, loss_test:0.18475, lr:7.40e-03, fs:0.70213 (r=0.667,p=0.742),  time:38.725, tt:1084.300\n",
      "Ep:28, loss:0.00016, loss_test:0.16838, lr:7.32e-03, fs:0.72477 (r=0.798,p=0.664),  time:38.741, tt:1123.483\n",
      "Ep:29, loss:0.00016, loss_test:0.17135, lr:7.25e-03, fs:0.73632 (r=0.747,p=0.725),  time:38.692, tt:1160.750\n",
      "Ep:30, loss:0.00015, loss_test:0.16923, lr:7.18e-03, fs:0.75377 (r=0.758,p=0.750),  time:38.756, tt:1201.437\n",
      "Ep:31, loss:0.00014, loss_test:0.16533, lr:7.11e-03, fs:0.74877 (r=0.768,p=0.731),  time:38.753, tt:1240.110\n",
      "Ep:32, loss:0.00013, loss_test:0.16910, lr:7.03e-03, fs:0.73846 (r=0.727,p=0.750),  time:38.673, tt:1276.205\n",
      "Ep:33, loss:0.00013, loss_test:0.16534, lr:6.96e-03, fs:0.75622 (r=0.768,p=0.745),  time:38.678, tt:1315.064\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.16020, lr:6.89e-03, fs:0.78818 (r=0.808,p=0.769),  time:38.641, tt:1352.428\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.16135, lr:6.83e-03, fs:0.77670 (r=0.808,p=0.748),  time:38.629, tt:1390.640\n",
      "Ep:36, loss:0.00012, loss_test:0.15866, lr:6.76e-03, fs:0.76190 (r=0.808,p=0.721),  time:38.609, tt:1428.539\n",
      "Ep:37, loss:0.00012, loss_test:0.17405, lr:6.69e-03, fs:0.74468 (r=0.707,p=0.787),  time:38.628, tt:1467.867\n",
      "Ep:38, loss:0.00011, loss_test:0.15863, lr:6.62e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.564, tt:1504.012\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.17531, lr:6.56e-03, fs:0.72251 (r=0.697,p=0.750),  time:38.572, tt:1542.893\n",
      "Ep:40, loss:0.00010, loss_test:0.15544, lr:6.49e-03, fs:0.80000 (r=0.889,p=0.727),  time:38.568, tt:1581.288\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.17924, lr:6.43e-03, fs:0.76503 (r=0.707,p=0.833),  time:38.528, tt:1618.161\n",
      "Ep:42, loss:0.00010, loss_test:0.15953, lr:6.36e-03, fs:0.80392 (r=0.828,p=0.781),  time:38.482, tt:1654.731\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.17926, lr:6.30e-03, fs:0.69231 (r=0.636,p=0.759),  time:38.501, tt:1694.038\n",
      "Ep:44, loss:0.00009, loss_test:0.16198, lr:6.24e-03, fs:0.78469 (r=0.828,p=0.745),  time:38.517, tt:1733.257\n",
      "Ep:45, loss:0.00008, loss_test:0.16601, lr:6.17e-03, fs:0.72251 (r=0.697,p=0.750),  time:38.491, tt:1770.608\n",
      "Ep:46, loss:0.00008, loss_test:0.18162, lr:6.11e-03, fs:0.72515 (r=0.626,p=0.861),  time:38.561, tt:1812.377\n",
      "Ep:47, loss:0.00008, loss_test:0.16093, lr:6.05e-03, fs:0.75758 (r=0.758,p=0.758),  time:38.541, tt:1849.977\n",
      "Ep:48, loss:0.00007, loss_test:0.16450, lr:5.99e-03, fs:0.74074 (r=0.707,p=0.778),  time:38.552, tt:1889.072\n",
      "Ep:49, loss:0.00007, loss_test:0.15995, lr:5.93e-03, fs:0.76684 (r=0.747,p=0.787),  time:38.578, tt:1928.908\n",
      "Ep:50, loss:0.00006, loss_test:0.16462, lr:5.87e-03, fs:0.76344 (r=0.717,p=0.816),  time:38.616, tt:1969.391\n",
      "Ep:51, loss:0.00006, loss_test:0.16635, lr:5.81e-03, fs:0.74468 (r=0.707,p=0.787),  time:38.631, tt:2008.791\n",
      "Ep:52, loss:0.00006, loss_test:0.16410, lr:5.75e-03, fs:0.74866 (r=0.707,p=0.795),  time:38.655, tt:2048.696\n",
      "Ep:53, loss:0.00005, loss_test:0.17473, lr:5.70e-03, fs:0.74468 (r=0.707,p=0.787),  time:38.659, tt:2087.571\n",
      "Ep:54, loss:0.00005, loss_test:0.16981, lr:5.58e-03, fs:0.70968 (r=0.667,p=0.759),  time:38.689, tt:2127.914\n",
      "Ep:55, loss:0.00005, loss_test:0.16389, lr:5.47e-03, fs:0.75410 (r=0.697,p=0.821),  time:38.667, tt:2165.342\n",
      "Ep:56, loss:0.00004, loss_test:0.16462, lr:5.36e-03, fs:0.75132 (r=0.717,p=0.789),  time:38.653, tt:2203.198\n",
      "Ep:57, loss:0.00004, loss_test:0.17845, lr:5.26e-03, fs:0.70455 (r=0.626,p=0.805),  time:38.657, tt:2242.132\n",
      "Ep:58, loss:0.00004, loss_test:0.17163, lr:5.15e-03, fs:0.73034 (r=0.657,p=0.823),  time:38.632, tt:2279.311\n",
      "Ep:59, loss:0.00004, loss_test:0.16960, lr:5.05e-03, fs:0.73743 (r=0.667,p=0.825),  time:38.644, tt:2318.645\n",
      "Ep:60, loss:0.00004, loss_test:0.17926, lr:4.95e-03, fs:0.68208 (r=0.596,p=0.797),  time:38.621, tt:2355.885\n",
      "Ep:61, loss:0.00003, loss_test:0.16845, lr:4.85e-03, fs:0.75132 (r=0.717,p=0.789),  time:38.626, tt:2394.832\n",
      "Ep:62, loss:0.00003, loss_test:0.17360, lr:4.75e-03, fs:0.73743 (r=0.667,p=0.825),  time:38.621, tt:2433.129\n",
      "Ep:63, loss:0.00003, loss_test:0.17033, lr:4.66e-03, fs:0.76289 (r=0.747,p=0.779),  time:38.613, tt:2471.217\n",
      "Ep:64, loss:0.00003, loss_test:0.18521, lr:4.57e-03, fs:0.65031 (r=0.535,p=0.828),  time:38.618, tt:2510.175\n",
      "Ep:65, loss:0.00003, loss_test:0.18509, lr:4.48e-03, fs:0.72000 (r=0.636,p=0.829),  time:38.610, tt:2548.234\n",
      "Ep:66, loss:0.00002, loss_test:0.17017, lr:4.39e-03, fs:0.73514 (r=0.687,p=0.791),  time:38.588, tt:2585.394\n",
      "Ep:67, loss:0.00003, loss_test:0.18216, lr:4.30e-03, fs:0.70115 (r=0.616,p=0.813),  time:38.613, tt:2625.709\n",
      "Ep:68, loss:0.00003, loss_test:0.18105, lr:4.21e-03, fs:0.63905 (r=0.545,p=0.771),  time:38.605, tt:2663.711\n",
      "Ep:69, loss:0.00002, loss_test:0.16712, lr:4.13e-03, fs:0.75393 (r=0.727,p=0.783),  time:38.635, tt:2704.481\n",
      "Ep:70, loss:0.00002, loss_test:0.17663, lr:4.05e-03, fs:0.69318 (r=0.616,p=0.792),  time:38.609, tt:2741.248\n",
      "Ep:71, loss:0.00002, loss_test:0.18795, lr:3.97e-03, fs:0.63291 (r=0.505,p=0.847),  time:38.616, tt:2780.351\n",
      "Ep:72, loss:0.00002, loss_test:0.17487, lr:3.89e-03, fs:0.72432 (r=0.677,p=0.779),  time:38.644, tt:2821.027\n",
      "Ep:73, loss:0.00002, loss_test:0.18419, lr:3.81e-03, fs:0.67836 (r=0.586,p=0.806),  time:38.642, tt:2859.538\n",
      "Ep:74, loss:0.00002, loss_test:0.19773, lr:3.73e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.625, tt:2896.893\n",
      "Ep:75, loss:0.00002, loss_test:0.17952, lr:3.66e-03, fs:0.69091 (r=0.576,p=0.864),  time:38.659, tt:2938.083\n",
      "Ep:76, loss:0.00002, loss_test:0.17972, lr:3.59e-03, fs:0.65476 (r=0.556,p=0.797),  time:38.697, tt:2979.689\n",
      "Ep:77, loss:0.00002, loss_test:0.19360, lr:3.52e-03, fs:0.65432 (r=0.535,p=0.841),  time:38.719, tt:3020.069\n",
      "Ep:78, loss:0.00002, loss_test:0.19861, lr:3.45e-03, fs:0.65839 (r=0.535,p=0.855),  time:38.735, tt:3060.041\n",
      "Ep:79, loss:0.00002, loss_test:0.17906, lr:3.38e-03, fs:0.68208 (r=0.596,p=0.797),  time:38.747, tt:3099.758\n",
      "Ep:80, loss:0.00002, loss_test:0.18318, lr:3.31e-03, fs:0.69939 (r=0.576,p=0.891),  time:38.751, tt:3138.813\n",
      "Ep:81, loss:0.00002, loss_test:0.19080, lr:3.24e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.764, tt:3178.668\n",
      "Ep:82, loss:0.00001, loss_test:0.17935, lr:3.18e-03, fs:0.67816 (r=0.596,p=0.787),  time:38.782, tt:3218.892\n",
      "Ep:83, loss:0.00002, loss_test:0.18202, lr:3.12e-03, fs:0.65823 (r=0.525,p=0.881),  time:38.804, tt:3259.562\n",
      "Ep:84, loss:0.00001, loss_test:0.18093, lr:3.05e-03, fs:0.69512 (r=0.576,p=0.877),  time:38.827, tt:3300.334\n",
      "Ep:85, loss:0.00001, loss_test:0.18650, lr:2.99e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.833, tt:3339.652\n",
      "Ep:86, loss:0.00001, loss_test:0.18321, lr:2.93e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.831, tt:3378.264\n",
      "Ep:87, loss:0.00001, loss_test:0.17717, lr:2.88e-03, fs:0.67059 (r=0.576,p=0.803),  time:38.824, tt:3416.478\n",
      "Ep:88, loss:0.00001, loss_test:0.17658, lr:2.82e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.835, tt:3456.281\n",
      "Ep:89, loss:0.00001, loss_test:0.17995, lr:2.76e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.835, tt:3495.177\n",
      "Ep:90, loss:0.00001, loss_test:0.18614, lr:2.71e-03, fs:0.65143 (r=0.576,p=0.750),  time:38.837, tt:3534.137\n",
      "Ep:91, loss:0.00001, loss_test:0.18273, lr:2.65e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.856, tt:3574.732\n",
      "Ep:92, loss:0.00001, loss_test:0.18009, lr:2.60e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.844, tt:3612.515\n",
      "Ep:93, loss:0.00001, loss_test:0.17499, lr:2.55e-03, fs:0.69318 (r=0.616,p=0.792),  time:38.852, tt:3652.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:94, loss:0.00001, loss_test:0.17913, lr:2.50e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.852, tt:3690.929\n",
      "Ep:95, loss:0.00001, loss_test:0.18173, lr:2.45e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.855, tt:3730.123\n",
      "Ep:96, loss:0.00001, loss_test:0.18166, lr:2.40e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.864, tt:3769.782\n",
      "Ep:97, loss:0.00001, loss_test:0.18265, lr:2.35e-03, fs:0.69091 (r=0.576,p=0.864),  time:38.887, tt:3810.913\n",
      "Ep:98, loss:0.00001, loss_test:0.17810, lr:2.31e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.904, tt:3851.492\n",
      "Ep:99, loss:0.00001, loss_test:0.17691, lr:2.26e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.928, tt:3892.787\n",
      "Ep:100, loss:0.00001, loss_test:0.18332, lr:2.21e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.953, tt:3934.227\n",
      "Ep:101, loss:0.00001, loss_test:0.18901, lr:2.17e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.969, tt:3974.882\n",
      "Ep:102, loss:0.00001, loss_test:0.18431, lr:2.13e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.975, tt:4014.421\n",
      "Ep:103, loss:0.00001, loss_test:0.17802, lr:2.08e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.981, tt:4054.073\n",
      "Ep:104, loss:0.00001, loss_test:0.18123, lr:2.04e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.957, tt:4090.477\n",
      "Ep:105, loss:0.00001, loss_test:0.18728, lr:2.00e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.948, tt:4128.464\n",
      "Ep:106, loss:0.00001, loss_test:0.19262, lr:1.96e-03, fs:0.67059 (r=0.576,p=0.803),  time:38.942, tt:4166.759\n",
      "Ep:107, loss:0.00001, loss_test:0.19046, lr:1.92e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.919, tt:4203.270\n",
      "Ep:108, loss:0.00001, loss_test:0.18118, lr:1.89e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.935, tt:4243.970\n",
      "Ep:109, loss:0.00001, loss_test:0.17536, lr:1.85e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.929, tt:4282.147\n",
      "Ep:110, loss:0.00001, loss_test:0.18056, lr:1.81e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.909, tt:4318.954\n",
      "Ep:111, loss:0.00001, loss_test:0.18764, lr:1.78e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.919, tt:4358.910\n",
      "Ep:112, loss:0.00001, loss_test:0.19042, lr:1.74e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.919, tt:4397.898\n",
      "Ep:113, loss:0.00001, loss_test:0.18520, lr:1.71e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.913, tt:4436.072\n",
      "Ep:114, loss:0.00001, loss_test:0.17668, lr:1.67e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.912, tt:4474.924\n",
      "Ep:115, loss:0.00001, loss_test:0.17314, lr:1.64e-03, fs:0.67059 (r=0.576,p=0.803),  time:38.922, tt:4515.007\n",
      "Ep:116, loss:0.00001, loss_test:0.17971, lr:1.61e-03, fs:0.67456 (r=0.576,p=0.814),  time:38.874, tt:4548.257\n",
      "Ep:117, loss:0.00001, loss_test:0.18663, lr:1.57e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.870, tt:4586.690\n",
      "Ep:118, loss:0.00001, loss_test:0.18714, lr:1.54e-03, fs:0.69091 (r=0.576,p=0.864),  time:38.875, tt:4626.176\n",
      "Ep:119, loss:0.00001, loss_test:0.18610, lr:1.51e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.876, tt:4665.129\n",
      "Ep:120, loss:0.00001, loss_test:0.18379, lr:1.48e-03, fs:0.67857 (r=0.576,p=0.826),  time:38.881, tt:4704.548\n",
      "Ep:121, loss:0.00001, loss_test:0.18270, lr:1.45e-03, fs:0.68263 (r=0.576,p=0.838),  time:38.839, tt:4738.362\n",
      "Ep:122, loss:0.00001, loss_test:0.18342, lr:1.42e-03, fs:0.68675 (r=0.576,p=0.851),  time:38.847, tt:4778.213\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 33\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.23973, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.243, tt:33.243\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.23487, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:35.279, tt:70.557\n",
      "Ep:2, loss:0.00055, loss_test:0.22374, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:36.929, tt:110.788\n",
      "Ep:3, loss:0.00047, loss_test:0.20555, lr:9.70e-03, fs:0.65233 (r=0.919,p=0.506),  time:37.256, tt:149.023\n",
      "Ep:4, loss:0.00036, loss_test:0.19729, lr:9.61e-03, fs:0.68702 (r=0.909,p=0.552),  time:37.784, tt:188.922\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00032, loss_test:0.19591, lr:9.51e-03, fs:0.69528 (r=0.818,p=0.604),  time:38.028, tt:228.169\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00030, loss_test:0.19449, lr:9.41e-03, fs:0.69748 (r=0.838,p=0.597),  time:38.024, tt:266.169\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.20141, lr:9.32e-03, fs:0.67873 (r=0.758,p=0.615),  time:38.384, tt:307.071\n",
      "Ep:8, loss:0.00029, loss_test:0.19133, lr:9.23e-03, fs:0.68670 (r=0.808,p=0.597),  time:38.532, tt:346.790\n",
      "Ep:9, loss:0.00029, loss_test:0.18990, lr:9.14e-03, fs:0.70852 (r=0.798,p=0.637),  time:38.622, tt:386.218\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.19232, lr:9.04e-03, fs:0.68868 (r=0.737,p=0.646),  time:38.627, tt:424.900\n",
      "Ep:11, loss:0.00027, loss_test:0.17879, lr:8.95e-03, fs:0.72807 (r=0.838,p=0.643),  time:38.750, tt:464.999\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.17464, lr:8.86e-03, fs:0.75676 (r=0.848,p=0.683),  time:38.879, tt:505.428\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.17685, lr:8.78e-03, fs:0.72146 (r=0.798,p=0.658),  time:39.020, tt:546.278\n",
      "Ep:14, loss:0.00024, loss_test:0.17235, lr:8.69e-03, fs:0.72477 (r=0.798,p=0.664),  time:39.090, tt:586.353\n",
      "Ep:15, loss:0.00023, loss_test:0.17117, lr:8.60e-03, fs:0.71889 (r=0.788,p=0.661),  time:39.158, tt:626.536\n",
      "Ep:16, loss:0.00023, loss_test:0.17231, lr:8.51e-03, fs:0.75229 (r=0.828,p=0.689),  time:39.127, tt:665.167\n",
      "Ep:17, loss:0.00023, loss_test:0.16232, lr:8.43e-03, fs:0.77477 (r=0.869,p=0.699),  time:39.140, tt:704.519\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.15844, lr:8.35e-03, fs:0.80000 (r=0.869,p=0.741),  time:39.133, tt:743.533\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.16329, lr:8.26e-03, fs:0.79812 (r=0.859,p=0.746),  time:39.119, tt:782.378\n",
      "Ep:20, loss:0.00021, loss_test:0.15545, lr:8.18e-03, fs:0.79091 (r=0.879,p=0.719),  time:39.191, tt:823.019\n",
      "Ep:21, loss:0.00020, loss_test:0.15487, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:39.253, tt:863.558\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.14909, lr:8.02e-03, fs:0.83412 (r=0.889,p=0.786),  time:39.135, tt:900.111\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.15234, lr:7.94e-03, fs:0.82524 (r=0.859,p=0.794),  time:39.089, tt:938.127\n",
      "Ep:24, loss:0.00018, loss_test:0.14786, lr:7.86e-03, fs:0.82028 (r=0.899,p=0.754),  time:39.069, tt:976.718\n",
      "Ep:25, loss:0.00018, loss_test:0.14994, lr:7.78e-03, fs:0.83568 (r=0.899,p=0.781),  time:39.101, tt:1016.624\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.14899, lr:7.70e-03, fs:0.83810 (r=0.889,p=0.793),  time:38.926, tt:1051.004\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.13857, lr:7.62e-03, fs:0.82727 (r=0.919,p=0.752),  time:38.967, tt:1091.077\n",
      "Ep:28, loss:0.00016, loss_test:0.14412, lr:7.55e-03, fs:0.85167 (r=0.899,p=0.809),  time:38.920, tt:1128.677\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.13920, lr:7.47e-03, fs:0.85849 (r=0.919,p=0.805),  time:38.886, tt:1166.578\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.14216, lr:7.40e-03, fs:0.84466 (r=0.879,p=0.813),  time:38.920, tt:1206.533\n",
      "Ep:31, loss:0.00015, loss_test:0.14132, lr:7.32e-03, fs:0.84729 (r=0.869,p=0.827),  time:38.924, tt:1245.569\n",
      "Ep:32, loss:0.00014, loss_test:0.13349, lr:7.25e-03, fs:0.85714 (r=0.909,p=0.811),  time:38.927, tt:1284.585\n",
      "Ep:33, loss:0.00014, loss_test:0.13077, lr:7.18e-03, fs:0.86239 (r=0.949,p=0.790),  time:38.976, tt:1325.190\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.13546, lr:7.11e-03, fs:0.87255 (r=0.899,p=0.848),  time:38.967, tt:1363.847\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.12447, lr:7.03e-03, fs:0.86758 (r=0.960,p=0.792),  time:38.943, tt:1401.964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00012, loss_test:0.12945, lr:6.96e-03, fs:0.88038 (r=0.929,p=0.836),  time:38.901, tt:1439.343\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.13591, lr:6.89e-03, fs:0.84000 (r=0.848,p=0.832),  time:38.886, tt:1477.675\n",
      "Ep:38, loss:0.00011, loss_test:0.13086, lr:6.83e-03, fs:0.86239 (r=0.949,p=0.790),  time:38.885, tt:1516.502\n",
      "Ep:39, loss:0.00010, loss_test:0.13368, lr:6.76e-03, fs:0.87000 (r=0.879,p=0.861),  time:38.864, tt:1554.566\n",
      "Ep:40, loss:0.00010, loss_test:0.12146, lr:6.69e-03, fs:0.86256 (r=0.919,p=0.812),  time:38.836, tt:1592.285\n",
      "Ep:41, loss:0.00009, loss_test:0.13329, lr:6.62e-03, fs:0.86869 (r=0.869,p=0.869),  time:38.824, tt:1630.597\n",
      "Ep:42, loss:0.00009, loss_test:0.12986, lr:6.56e-03, fs:0.88038 (r=0.929,p=0.836),  time:38.808, tt:1668.748\n",
      "Ep:43, loss:0.00008, loss_test:0.11590, lr:6.49e-03, fs:0.85577 (r=0.899,p=0.817),  time:38.821, tt:1708.110\n",
      "Ep:44, loss:0.00008, loss_test:0.13165, lr:6.43e-03, fs:0.87619 (r=0.929,p=0.829),  time:38.814, tt:1746.642\n",
      "Ep:45, loss:0.00008, loss_test:0.12881, lr:6.36e-03, fs:0.87755 (r=0.869,p=0.887),  time:38.821, tt:1785.778\n",
      "Ep:46, loss:0.00008, loss_test:0.12662, lr:6.30e-03, fs:0.86275 (r=0.889,p=0.838),  time:38.812, tt:1824.162\n",
      "Ep:47, loss:0.00007, loss_test:0.13156, lr:6.24e-03, fs:0.86869 (r=0.869,p=0.869),  time:38.736, tt:1859.305\n",
      "Ep:48, loss:0.00007, loss_test:0.13056, lr:6.11e-03, fs:0.88205 (r=0.869,p=0.896),  time:38.687, tt:1895.644\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.13088, lr:6.05e-03, fs:0.87629 (r=0.859,p=0.895),  time:38.626, tt:1931.320\n",
      "Ep:50, loss:0.00006, loss_test:0.12698, lr:5.99e-03, fs:0.87179 (r=0.859,p=0.885),  time:38.563, tt:1966.731\n",
      "Ep:51, loss:0.00006, loss_test:0.12625, lr:5.93e-03, fs:0.86598 (r=0.848,p=0.884),  time:38.472, tt:2000.552\n",
      "Ep:52, loss:0.00006, loss_test:0.13486, lr:5.87e-03, fs:0.86598 (r=0.848,p=0.884),  time:38.413, tt:2035.863\n",
      "Ep:53, loss:0.00006, loss_test:0.12678, lr:5.81e-03, fs:0.88442 (r=0.889,p=0.880),  time:38.365, tt:2071.697\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.12749, lr:5.75e-03, fs:0.88776 (r=0.879,p=0.897),  time:38.338, tt:2108.594\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.12719, lr:5.70e-03, fs:0.87129 (r=0.889,p=0.854),  time:38.302, tt:2144.918\n",
      "Ep:56, loss:0.00005, loss_test:0.13103, lr:5.64e-03, fs:0.88776 (r=0.879,p=0.897),  time:38.263, tt:2180.986\n",
      "Ep:57, loss:0.00004, loss_test:0.12911, lr:5.58e-03, fs:0.88000 (r=0.889,p=0.871),  time:38.227, tt:2217.157\n",
      "Ep:58, loss:0.00004, loss_test:0.14100, lr:5.53e-03, fs:0.85263 (r=0.818,p=0.890),  time:38.190, tt:2253.181\n",
      "Ep:59, loss:0.00004, loss_test:0.12551, lr:5.47e-03, fs:0.87562 (r=0.889,p=0.863),  time:38.163, tt:2289.800\n",
      "Ep:60, loss:0.00004, loss_test:0.12296, lr:5.42e-03, fs:0.88889 (r=0.889,p=0.889),  time:38.144, tt:2326.779\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.12957, lr:5.36e-03, fs:0.87047 (r=0.848,p=0.894),  time:38.105, tt:2362.487\n",
      "Ep:62, loss:0.00004, loss_test:0.13702, lr:5.31e-03, fs:0.86598 (r=0.848,p=0.884),  time:38.081, tt:2399.106\n",
      "Ep:63, loss:0.00004, loss_test:0.12170, lr:5.26e-03, fs:0.89796 (r=0.889,p=0.907),  time:38.029, tt:2433.845\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.13866, lr:5.20e-03, fs:0.85567 (r=0.838,p=0.874),  time:37.992, tt:2469.449\n",
      "Ep:65, loss:0.00003, loss_test:0.12971, lr:5.15e-03, fs:0.88442 (r=0.889,p=0.880),  time:37.960, tt:2505.359\n",
      "Ep:66, loss:0.00003, loss_test:0.13051, lr:5.10e-03, fs:0.86598 (r=0.848,p=0.884),  time:37.934, tt:2541.586\n",
      "Ep:67, loss:0.00003, loss_test:0.14332, lr:5.05e-03, fs:0.81283 (r=0.768,p=0.864),  time:37.897, tt:2576.965\n",
      "Ep:68, loss:0.00003, loss_test:0.13509, lr:5.00e-03, fs:0.85567 (r=0.838,p=0.874),  time:37.849, tt:2611.595\n",
      "Ep:69, loss:0.00003, loss_test:0.13625, lr:4.95e-03, fs:0.81720 (r=0.768,p=0.874),  time:37.826, tt:2647.834\n",
      "Ep:70, loss:0.00003, loss_test:0.12760, lr:4.90e-03, fs:0.89119 (r=0.869,p=0.915),  time:37.789, tt:2683.028\n",
      "Ep:71, loss:0.00003, loss_test:0.14065, lr:4.85e-03, fs:0.81967 (r=0.758,p=0.893),  time:37.759, tt:2718.679\n",
      "Ep:72, loss:0.00003, loss_test:0.13893, lr:4.80e-03, fs:0.86772 (r=0.828,p=0.911),  time:37.723, tt:2753.790\n",
      "Ep:73, loss:0.00002, loss_test:0.13426, lr:4.75e-03, fs:0.88542 (r=0.859,p=0.914),  time:37.689, tt:2789.006\n",
      "Ep:74, loss:0.00003, loss_test:0.14232, lr:4.71e-03, fs:0.79121 (r=0.727,p=0.867),  time:37.648, tt:2823.613\n",
      "Ep:75, loss:0.00002, loss_test:0.14106, lr:4.61e-03, fs:0.81319 (r=0.747,p=0.892),  time:37.605, tt:2858.016\n",
      "Ep:76, loss:0.00002, loss_test:0.14264, lr:4.52e-03, fs:0.81967 (r=0.758,p=0.893),  time:37.605, tt:2895.612\n",
      "Ep:77, loss:0.00002, loss_test:0.14256, lr:4.43e-03, fs:0.80000 (r=0.727,p=0.889),  time:37.589, tt:2931.908\n",
      "Ep:78, loss:0.00002, loss_test:0.14297, lr:4.34e-03, fs:0.88421 (r=0.848,p=0.923),  time:37.557, tt:2967.035\n",
      "Ep:79, loss:0.00002, loss_test:0.14368, lr:4.26e-03, fs:0.82796 (r=0.778,p=0.885),  time:37.549, tt:3003.884\n",
      "Ep:80, loss:0.00002, loss_test:0.14467, lr:4.17e-03, fs:0.80000 (r=0.727,p=0.889),  time:37.564, tt:3042.715\n",
      "Ep:81, loss:0.00002, loss_test:0.13945, lr:4.09e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.587, tt:3082.102\n",
      "Ep:82, loss:0.00002, loss_test:0.14109, lr:4.01e-03, fs:0.82486 (r=0.737,p=0.936),  time:37.655, tt:3125.361\n",
      "Ep:83, loss:0.00002, loss_test:0.14308, lr:3.93e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.735, tt:3169.704\n",
      "Ep:84, loss:0.00002, loss_test:0.14727, lr:3.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:37.789, tt:3212.071\n",
      "Ep:85, loss:0.00001, loss_test:0.14563, lr:3.77e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.829, tt:3253.334\n",
      "Ep:86, loss:0.00002, loss_test:0.14039, lr:3.70e-03, fs:0.84946 (r=0.798,p=0.908),  time:37.900, tt:3297.266\n",
      "Ep:87, loss:0.00001, loss_test:0.14311, lr:3.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:37.956, tt:3340.101\n",
      "Ep:88, loss:0.00002, loss_test:0.13848, lr:3.55e-03, fs:0.88770 (r=0.838,p=0.943),  time:37.971, tt:3379.436\n",
      "Ep:89, loss:0.00001, loss_test:0.14347, lr:3.48e-03, fs:0.81818 (r=0.727,p=0.935),  time:37.995, tt:3419.575\n",
      "Ep:90, loss:0.00001, loss_test:0.14667, lr:3.41e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.046, tt:3462.182\n",
      "Ep:91, loss:0.00001, loss_test:0.14408, lr:3.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:38.105, tt:3505.638\n",
      "Ep:92, loss:0.00001, loss_test:0.14671, lr:3.28e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.162, tt:3549.065\n",
      "Ep:93, loss:0.00001, loss_test:0.14756, lr:3.21e-03, fs:0.81818 (r=0.727,p=0.935),  time:38.218, tt:3592.459\n",
      "Ep:94, loss:0.00001, loss_test:0.13845, lr:3.15e-03, fs:0.87831 (r=0.838,p=0.922),  time:38.275, tt:3636.134\n",
      "Ep:95, loss:0.00001, loss_test:0.14600, lr:3.09e-03, fs:0.81818 (r=0.727,p=0.935),  time:38.324, tt:3679.058\n",
      "Ep:96, loss:0.00001, loss_test:0.15166, lr:3.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:38.358, tt:3720.705\n",
      "Ep:97, loss:0.00001, loss_test:0.14417, lr:2.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:38.417, tt:3764.848\n",
      "Ep:98, loss:0.00001, loss_test:0.13821, lr:2.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:38.468, tt:3808.367\n",
      "Ep:99, loss:0.00001, loss_test:0.14619, lr:2.85e-03, fs:0.84444 (r=0.768,p=0.938),  time:38.513, tt:3851.270\n",
      "Ep:100, loss:0.00001, loss_test:0.14666, lr:2.79e-03, fs:0.81818 (r=0.727,p=0.935),  time:38.547, tt:3893.285\n",
      "Ep:101, loss:0.00001, loss_test:0.14511, lr:2.73e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.599, tt:3937.119\n",
      "Ep:102, loss:0.00001, loss_test:0.14171, lr:2.68e-03, fs:0.81818 (r=0.727,p=0.935),  time:38.652, tt:3981.173\n",
      "Ep:103, loss:0.00001, loss_test:0.13807, lr:2.63e-03, fs:0.82222 (r=0.747,p=0.914),  time:38.687, tt:4023.480\n",
      "Ep:104, loss:0.00001, loss_test:0.14048, lr:2.57e-03, fs:0.82682 (r=0.747,p=0.925),  time:38.731, tt:4066.731\n",
      "Ep:105, loss:0.00001, loss_test:0.15036, lr:2.52e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.743, tt:4106.757\n",
      "Ep:106, loss:0.00001, loss_test:0.14752, lr:2.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.786, tt:4150.069\n",
      "Ep:107, loss:0.00001, loss_test:0.13834, lr:2.42e-03, fs:0.87958 (r=0.848,p=0.913),  time:38.828, tt:4193.373\n",
      "Ep:108, loss:0.00001, loss_test:0.14564, lr:2.38e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.877, tt:4237.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00001, loss_test:0.15322, lr:2.33e-03, fs:0.82286 (r=0.727,p=0.947),  time:38.918, tt:4281.024\n",
      "Ep:110, loss:0.00001, loss_test:0.14748, lr:2.28e-03, fs:0.81818 (r=0.727,p=0.935),  time:38.947, tt:4323.167\n",
      "Ep:111, loss:0.00001, loss_test:0.14026, lr:2.24e-03, fs:0.87701 (r=0.828,p=0.932),  time:38.989, tt:4366.721\n",
      "Ep:112, loss:0.00001, loss_test:0.14018, lr:2.19e-03, fs:0.82955 (r=0.737,p=0.948),  time:39.004, tt:4407.502\n",
      "Ep:113, loss:0.00001, loss_test:0.14141, lr:2.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:39.028, tt:4449.222\n",
      "Ep:114, loss:0.00001, loss_test:0.14134, lr:2.11e-03, fs:0.81818 (r=0.727,p=0.935),  time:39.046, tt:4490.278\n",
      "Ep:115, loss:0.00001, loss_test:0.14181, lr:2.06e-03, fs:0.81818 (r=0.727,p=0.935),  time:39.041, tt:4528.802\n",
      "Ep:116, loss:0.00001, loss_test:0.14484, lr:2.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:39.051, tt:4569.017\n",
      "Ep:117, loss:0.00001, loss_test:0.14486, lr:1.98e-03, fs:0.81818 (r=0.727,p=0.935),  time:39.080, tt:4611.436\n",
      "Ep:118, loss:0.00001, loss_test:0.14322, lr:1.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:39.025, tt:4643.970\n",
      "Ep:119, loss:0.00001, loss_test:0.14309, lr:1.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:38.982, tt:4677.816\n",
      "Ep:120, loss:0.00001, loss_test:0.14003, lr:1.87e-03, fs:0.83333 (r=0.758,p=0.926),  time:38.939, tt:4711.599\n",
      "Ep:121, loss:0.00001, loss_test:0.13978, lr:1.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:38.860, tt:4740.877\n",
      "Ep:122, loss:0.00001, loss_test:0.14098, lr:1.79e-03, fs:0.85083 (r=0.778,p=0.939),  time:38.796, tt:4771.859\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 34\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1230bd3a7753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,123,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00060, loss_test:0.24177, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:23.479, tt:23.479\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00059, loss_test:0.23841, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:25.825, tt:51.650\n",
      "Ep:2, loss:0.00057, loss_test:0.23113, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:26.310, tt:78.929\n",
      "Ep:3, loss:0.00052, loss_test:0.21781, lr:8.00e-03, fs:0.66892 (r=1.000,p=0.503),  time:29.482, tt:117.929\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.20529, lr:8.00e-03, fs:0.67870 (r=0.949,p=0.528),  time:31.084, tt:155.419\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00035, loss_test:0.20131, lr:8.00e-03, fs:0.68679 (r=0.919,p=0.548),  time:32.155, tt:192.928\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.19555, lr:8.00e-03, fs:0.69919 (r=0.869,p=0.585),  time:32.907, tt:230.349\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.19329, lr:8.00e-03, fs:0.69636 (r=0.869,p=0.581),  time:33.824, tt:270.591\n",
      "Ep:8, loss:0.00031, loss_test:0.18747, lr:8.00e-03, fs:0.69732 (r=0.919,p=0.562),  time:34.583, tt:311.251\n",
      "Ep:9, loss:0.00029, loss_test:0.18197, lr:8.00e-03, fs:0.69919 (r=0.869,p=0.585),  time:35.179, tt:351.793\n",
      "Ep:10, loss:0.00028, loss_test:0.17651, lr:8.00e-03, fs:0.72803 (r=0.879,p=0.621),  time:35.688, tt:392.565\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00027, loss_test:0.17531, lr:8.00e-03, fs:0.74359 (r=0.879,p=0.644),  time:35.793, tt:429.519\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.17373, lr:8.00e-03, fs:0.73171 (r=0.909,p=0.612),  time:35.882, tt:466.467\n",
      "Ep:13, loss:0.00025, loss_test:0.16831, lr:8.00e-03, fs:0.74167 (r=0.899,p=0.631),  time:35.885, tt:502.387\n",
      "Ep:14, loss:0.00025, loss_test:0.16869, lr:8.00e-03, fs:0.75214 (r=0.889,p=0.652),  time:35.967, tt:539.500\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.16599, lr:8.00e-03, fs:0.73333 (r=0.889,p=0.624),  time:36.000, tt:576.005\n",
      "Ep:16, loss:0.00024, loss_test:0.16184, lr:8.00e-03, fs:0.74890 (r=0.859,p=0.664),  time:36.053, tt:612.904\n",
      "Ep:17, loss:0.00023, loss_test:0.15845, lr:8.00e-03, fs:0.75893 (r=0.859,p=0.680),  time:36.403, tt:655.252\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.15372, lr:8.00e-03, fs:0.76349 (r=0.929,p=0.648),  time:36.597, tt:695.340\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.15464, lr:8.00e-03, fs:0.76279 (r=0.828,p=0.707),  time:36.780, tt:735.591\n",
      "Ep:20, loss:0.00021, loss_test:0.14746, lr:8.00e-03, fs:0.79012 (r=0.970,p=0.667),  time:36.798, tt:772.755\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.14955, lr:8.00e-03, fs:0.78378 (r=0.879,p=0.707),  time:36.768, tt:808.892\n",
      "Ep:22, loss:0.00021, loss_test:0.14571, lr:8.00e-03, fs:0.78788 (r=0.919,p=0.689),  time:36.732, tt:844.834\n",
      "Ep:23, loss:0.00020, loss_test:0.14059, lr:8.00e-03, fs:0.79832 (r=0.960,p=0.683),  time:36.739, tt:881.739\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.14378, lr:8.00e-03, fs:0.80184 (r=0.879,p=0.737),  time:36.788, tt:919.688\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.13551, lr:8.00e-03, fs:0.79184 (r=0.980,p=0.664),  time:36.836, tt:957.748\n",
      "Ep:26, loss:0.00019, loss_test:0.13869, lr:8.00e-03, fs:0.84545 (r=0.939,p=0.769),  time:36.983, tt:998.529\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.13379, lr:8.00e-03, fs:0.80519 (r=0.939,p=0.705),  time:37.187, tt:1041.247\n",
      "Ep:28, loss:0.00017, loss_test:0.13190, lr:8.00e-03, fs:0.84545 (r=0.939,p=0.769),  time:37.300, tt:1081.687\n",
      "Ep:29, loss:0.00017, loss_test:0.12863, lr:8.00e-03, fs:0.84545 (r=0.939,p=0.769),  time:37.367, tt:1121.006\n",
      "Ep:30, loss:0.00016, loss_test:0.12508, lr:8.00e-03, fs:0.82203 (r=0.980,p=0.708),  time:37.332, tt:1157.306\n",
      "Ep:31, loss:0.00015, loss_test:0.12885, lr:8.00e-03, fs:0.85185 (r=0.929,p=0.786),  time:37.289, tt:1193.233\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.12035, lr:8.00e-03, fs:0.82759 (r=0.970,p=0.722),  time:37.266, tt:1229.770\n",
      "Ep:33, loss:0.00014, loss_test:0.12066, lr:8.00e-03, fs:0.86512 (r=0.939,p=0.802),  time:37.287, tt:1267.745\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.11687, lr:8.00e-03, fs:0.86099 (r=0.970,p=0.774),  time:37.260, tt:1304.092\n",
      "Ep:35, loss:0.00013, loss_test:0.11658, lr:8.00e-03, fs:0.85973 (r=0.960,p=0.779),  time:37.253, tt:1341.123\n",
      "Ep:36, loss:0.00012, loss_test:0.11704, lr:8.00e-03, fs:0.87619 (r=0.929,p=0.829),  time:37.380, tt:1383.052\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.11215, lr:8.00e-03, fs:0.84932 (r=0.939,p=0.775),  time:37.505, tt:1425.193\n",
      "Ep:38, loss:0.00012, loss_test:0.10711, lr:8.00e-03, fs:0.86239 (r=0.949,p=0.790),  time:37.539, tt:1464.029\n",
      "Ep:39, loss:0.00011, loss_test:0.12480, lr:8.00e-03, fs:0.88442 (r=0.889,p=0.880),  time:37.626, tt:1505.028\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00012, loss_test:0.11689, lr:8.00e-03, fs:0.85217 (r=0.990,p=0.748),  time:37.638, tt:1543.166\n",
      "Ep:41, loss:0.00011, loss_test:0.10576, lr:8.00e-03, fs:0.88584 (r=0.980,p=0.808),  time:37.641, tt:1580.917\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.10758, lr:8.00e-03, fs:0.86364 (r=0.960,p=0.785),  time:37.727, tt:1622.282\n",
      "Ep:43, loss:0.00011, loss_test:0.10066, lr:8.00e-03, fs:0.84685 (r=0.949,p=0.764),  time:37.802, tt:1663.272\n",
      "Ep:44, loss:0.00010, loss_test:0.12272, lr:8.00e-03, fs:0.84163 (r=0.939,p=0.762),  time:37.845, tt:1703.023\n",
      "Ep:45, loss:0.00010, loss_test:0.10626, lr:8.00e-03, fs:0.86916 (r=0.939,p=0.809),  time:37.888, tt:1742.866\n",
      "Ep:46, loss:0.00009, loss_test:0.10305, lr:8.00e-03, fs:0.90640 (r=0.929,p=0.885),  time:38.040, tt:1787.881\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.12331, lr:8.00e-03, fs:0.80000 (r=0.970,p=0.681),  time:38.144, tt:1830.912\n",
      "Ep:48, loss:0.00014, loss_test:0.11988, lr:8.00e-03, fs:0.84211 (r=0.889,p=0.800),  time:38.226, tt:1873.063\n",
      "Ep:49, loss:0.00012, loss_test:0.12433, lr:8.00e-03, fs:0.80000 (r=0.990,p=0.671),  time:38.371, tt:1918.526\n",
      "Ep:50, loss:0.00014, loss_test:0.11941, lr:8.00e-03, fs:0.78571 (r=1.000,p=0.647),  time:38.408, tt:1958.825\n",
      "Ep:51, loss:0.00018, loss_test:0.13764, lr:8.00e-03, fs:0.80335 (r=0.970,p=0.686),  time:38.468, tt:2000.336\n",
      "Ep:52, loss:0.00020, loss_test:0.15301, lr:8.00e-03, fs:0.78070 (r=0.899,p=0.690),  time:38.523, tt:2041.703\n",
      "Ep:53, loss:0.00019, loss_test:0.13763, lr:8.00e-03, fs:0.79184 (r=0.980,p=0.664),  time:38.577, tt:2083.141\n",
      "Ep:54, loss:0.00017, loss_test:0.13436, lr:8.00e-03, fs:0.73846 (r=0.970,p=0.596),  time:38.611, tt:2123.579\n",
      "Ep:55, loss:0.00017, loss_test:0.12375, lr:8.00e-03, fs:0.81579 (r=0.939,p=0.721),  time:38.647, tt:2164.253\n",
      "Ep:56, loss:0.00014, loss_test:0.10895, lr:8.00e-03, fs:0.85185 (r=0.929,p=0.786),  time:38.725, tt:2207.304\n",
      "Ep:57, loss:0.00013, loss_test:0.10537, lr:7.92e-03, fs:0.87500 (r=0.990,p=0.784),  time:38.839, tt:2252.635\n",
      "Ep:58, loss:0.00011, loss_test:0.11548, lr:7.84e-03, fs:0.87619 (r=0.929,p=0.829),  time:38.911, tt:2295.772\n",
      "Ep:59, loss:0.00010, loss_test:0.09511, lr:7.76e-03, fs:0.89202 (r=0.960,p=0.833),  time:38.972, tt:2338.331\n",
      "Ep:60, loss:0.00010, loss_test:0.09380, lr:7.76e-03, fs:0.89623 (r=0.960,p=0.841),  time:39.000, tt:2378.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00014, loss_test:0.20063, lr:7.76e-03, fs:0.67347 (r=1.000,p=0.508),  time:39.009, tt:2418.565\n",
      "Ep:62, loss:0.00042, loss_test:0.17966, lr:7.76e-03, fs:0.67119 (r=1.000,p=0.505),  time:39.004, tt:2457.236\n",
      "Ep:63, loss:0.00030, loss_test:0.16319, lr:7.76e-03, fs:0.75591 (r=0.970,p=0.619),  time:39.044, tt:2498.793\n",
      "Ep:64, loss:0.00022, loss_test:0.15025, lr:7.76e-03, fs:0.80184 (r=0.879,p=0.737),  time:39.058, tt:2538.762\n",
      "Ep:65, loss:0.00019, loss_test:0.14689, lr:7.76e-03, fs:0.76113 (r=0.949,p=0.635),  time:39.087, tt:2579.709\n",
      "Ep:66, loss:0.00022, loss_test:0.14118, lr:7.76e-03, fs:0.77869 (r=0.960,p=0.655),  time:39.142, tt:2622.518\n",
      "Ep:67, loss:0.00020, loss_test:0.14304, lr:7.76e-03, fs:0.81818 (r=0.909,p=0.744),  time:39.204, tt:2665.859\n",
      "Ep:68, loss:0.00018, loss_test:0.14421, lr:7.76e-03, fs:0.78715 (r=0.990,p=0.653),  time:39.243, tt:2707.798\n",
      "Ep:69, loss:0.00019, loss_test:0.14191, lr:7.76e-03, fs:0.80508 (r=0.960,p=0.693),  time:39.302, tt:2751.142\n",
      "Ep:70, loss:0.00017, loss_test:0.14047, lr:7.76e-03, fs:0.83408 (r=0.939,p=0.750),  time:39.300, tt:2790.292\n",
      "Ep:71, loss:0.00015, loss_test:0.13215, lr:7.76e-03, fs:0.79184 (r=0.980,p=0.664),  time:39.290, tt:2828.867\n",
      "Ep:72, loss:0.00015, loss_test:0.12465, lr:7.68e-03, fs:0.81614 (r=0.919,p=0.734),  time:39.274, tt:2866.981\n",
      "Ep:73, loss:0.00013, loss_test:0.14713, lr:7.61e-03, fs:0.78222 (r=0.889,p=0.698),  time:39.282, tt:2906.860\n",
      "Ep:74, loss:0.00018, loss_test:0.16431, lr:7.53e-03, fs:0.72727 (r=0.848,p=0.636),  time:39.283, tt:2946.188\n",
      "Ep:75, loss:0.00019, loss_test:0.13957, lr:7.46e-03, fs:0.73729 (r=0.879,p=0.635),  time:39.312, tt:2987.720\n",
      "Ep:76, loss:0.00019, loss_test:0.16747, lr:7.38e-03, fs:0.72308 (r=0.949,p=0.584),  time:39.377, tt:3032.040\n",
      "Ep:77, loss:0.00026, loss_test:0.17627, lr:7.31e-03, fs:0.69343 (r=0.960,p=0.543),  time:39.413, tt:3074.211\n",
      "Ep:78, loss:0.00025, loss_test:0.15957, lr:7.24e-03, fs:0.74615 (r=0.980,p=0.602),  time:39.443, tt:3116.034\n",
      "Ep:79, loss:0.00022, loss_test:0.14159, lr:7.16e-03, fs:0.76190 (r=0.970,p=0.627),  time:39.462, tt:3156.993\n",
      "Ep:80, loss:0.00018, loss_test:0.13809, lr:7.09e-03, fs:0.74897 (r=0.919,p=0.632),  time:39.482, tt:3198.041\n",
      "Ep:81, loss:0.00018, loss_test:0.13179, lr:7.02e-03, fs:0.77333 (r=0.879,p=0.690),  time:39.469, tt:3236.460\n",
      "Ep:82, loss:0.00015, loss_test:0.13838, lr:6.95e-03, fs:0.75949 (r=0.909,p=0.652),  time:39.465, tt:3275.587\n",
      "Ep:83, loss:0.00014, loss_test:0.11649, lr:6.88e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.429, tt:3312.030\n",
      "Ep:84, loss:0.00015, loss_test:0.13507, lr:6.81e-03, fs:0.78008 (r=0.949,p=0.662),  time:39.445, tt:3352.817\n",
      "Ep:85, loss:0.00020, loss_test:0.13206, lr:6.74e-03, fs:0.79464 (r=0.899,p=0.712),  time:39.482, tt:3395.440\n",
      "Ep:86, loss:0.00017, loss_test:0.11942, lr:6.68e-03, fs:0.80498 (r=0.980,p=0.683),  time:39.535, tt:3439.574\n",
      "Ep:87, loss:0.00019, loss_test:0.13224, lr:6.61e-03, fs:0.79130 (r=0.919,p=0.695),  time:39.581, tt:3483.149\n",
      "Ep:88, loss:0.00017, loss_test:0.13203, lr:6.54e-03, fs:0.78603 (r=0.909,p=0.692),  time:39.601, tt:3524.466\n",
      "Ep:89, loss:0.00016, loss_test:0.11638, lr:6.48e-03, fs:0.79646 (r=0.909,p=0.709),  time:39.610, tt:3564.876\n",
      "Ep:90, loss:0.00016, loss_test:0.14115, lr:6.41e-03, fs:0.80189 (r=0.859,p=0.752),  time:39.609, tt:3604.430\n",
      "Ep:91, loss:0.00019, loss_test:0.12443, lr:6.35e-03, fs:0.78400 (r=0.990,p=0.649),  time:39.611, tt:3644.189\n",
      "Ep:92, loss:0.00021, loss_test:0.15923, lr:6.29e-03, fs:0.71028 (r=0.768,p=0.661),  time:39.617, tt:3684.337\n",
      "Ep:93, loss:0.00019, loss_test:0.14627, lr:6.22e-03, fs:0.78226 (r=0.980,p=0.651),  time:39.636, tt:3725.819\n",
      "Ep:94, loss:0.00019, loss_test:0.14502, lr:6.16e-03, fs:0.78543 (r=0.980,p=0.655),  time:39.659, tt:3767.591\n",
      "Ep:95, loss:0.00018, loss_test:0.13963, lr:6.10e-03, fs:0.77876 (r=0.889,p=0.693),  time:39.685, tt:3809.773\n",
      "Ep:96, loss:0.00015, loss_test:0.14341, lr:6.04e-03, fs:0.72868 (r=0.949,p=0.591),  time:39.723, tt:3853.125\n",
      "Ep:97, loss:0.00015, loss_test:0.13802, lr:5.98e-03, fs:0.79646 (r=0.909,p=0.709),  time:39.756, tt:3896.052\n",
      "Ep:98, loss:0.00013, loss_test:0.13910, lr:5.92e-03, fs:0.78027 (r=0.879,p=0.702),  time:39.809, tt:3941.075\n",
      "Ep:99, loss:0.00012, loss_test:0.11906, lr:5.86e-03, fs:0.79498 (r=0.960,p=0.679),  time:39.820, tt:3982.019\n",
      "Ep:100, loss:0.00012, loss_test:0.12483, lr:5.80e-03, fs:0.81778 (r=0.929,p=0.730),  time:39.834, tt:4023.283\n",
      "Ep:101, loss:0.00012, loss_test:0.12256, lr:5.74e-03, fs:0.80889 (r=0.919,p=0.722),  time:39.846, tt:4064.266\n",
      "Ep:102, loss:0.00011, loss_test:0.11381, lr:5.68e-03, fs:0.80180 (r=0.899,p=0.724),  time:39.852, tt:4104.734\n",
      "Ep:103, loss:0.00011, loss_test:0.10912, lr:5.63e-03, fs:0.79167 (r=0.960,p=0.674),  time:39.851, tt:4144.465\n",
      "Ep:104, loss:0.00011, loss_test:0.11922, lr:5.57e-03, fs:0.83761 (r=0.990,p=0.726),  time:39.843, tt:4183.555\n",
      "Ep:105, loss:0.00011, loss_test:0.13514, lr:5.52e-03, fs:0.83036 (r=0.939,p=0.744),  time:39.873, tt:4226.550\n",
      "Ep:106, loss:0.00009, loss_test:0.09891, lr:5.46e-03, fs:0.83186 (r=0.949,p=0.740),  time:39.908, tt:4270.148\n",
      "Ep:107, loss:0.00010, loss_test:0.09177, lr:5.41e-03, fs:0.85714 (r=0.939,p=0.788),  time:39.949, tt:4314.542\n",
      "Ep:108, loss:0.00009, loss_test:0.11417, lr:5.41e-03, fs:0.82243 (r=0.889,p=0.765),  time:39.985, tt:4358.417\n",
      "Ep:109, loss:0.00009, loss_test:0.11710, lr:5.41e-03, fs:0.84259 (r=0.919,p=0.778),  time:39.977, tt:4397.480\n",
      "Ep:110, loss:0.00008, loss_test:0.11693, lr:5.41e-03, fs:0.82407 (r=0.899,p=0.761),  time:39.971, tt:4436.739\n",
      "Ep:111, loss:0.00007, loss_test:0.11433, lr:5.41e-03, fs:0.83929 (r=0.949,p=0.752),  time:39.951, tt:4474.481\n",
      "Ep:112, loss:0.00007, loss_test:0.12774, lr:5.41e-03, fs:0.83784 (r=0.939,p=0.756),  time:39.932, tt:4512.363\n",
      "Ep:113, loss:0.00007, loss_test:0.11782, lr:5.41e-03, fs:0.83258 (r=0.929,p=0.754),  time:39.924, tt:4551.342\n",
      "Ep:114, loss:0.00007, loss_test:0.09340, lr:5.41e-03, fs:0.85446 (r=0.919,p=0.798),  time:39.915, tt:4590.262\n",
      "Ep:115, loss:0.00006, loss_test:0.10307, lr:5.41e-03, fs:0.80952 (r=0.859,p=0.766),  time:39.939, tt:4632.878\n",
      "Ep:116, loss:0.00006, loss_test:0.10300, lr:5.41e-03, fs:0.84259 (r=0.919,p=0.778),  time:39.955, tt:4674.684\n",
      "Ep:117, loss:0.00005, loss_test:0.11039, lr:5.41e-03, fs:0.79808 (r=0.838,p=0.761),  time:39.970, tt:4716.499\n",
      "Ep:118, loss:0.00005, loss_test:0.10028, lr:5.41e-03, fs:0.83000 (r=0.838,p=0.822),  time:39.995, tt:4759.402\n",
      "Ep:119, loss:0.00006, loss_test:0.09309, lr:5.35e-03, fs:0.85854 (r=0.889,p=0.830),  time:39.935, tt:4792.181\n",
      "Ep:120, loss:0.00006, loss_test:0.10145, lr:5.30e-03, fs:0.83333 (r=0.859,p=0.810),  time:39.864, tt:4823.579\n",
      "Ep:121, loss:0.00006, loss_test:0.11305, lr:5.25e-03, fs:0.81592 (r=0.828,p=0.804),  time:39.764, tt:4851.166\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-355502d63c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mdeserialized_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mtypename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,122,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09182, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:51.959, tt:51.959\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.08766, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:62.256, tt:124.512\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00033, loss_test:0.08170, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:65.268, tt:195.803\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00031, loss_test:0.07961, lr:1.00e-02, fs:0.70677 (r=0.949,p=0.563),  time:67.501, tt:270.004\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00030, loss_test:0.07710, lr:1.00e-02, fs:0.69118 (r=0.949,p=0.543),  time:68.570, tt:342.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.07443, lr:1.00e-02, fs:0.70370 (r=0.960,p=0.556),  time:69.348, tt:416.090\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.07156, lr:1.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:70.315, tt:492.208\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.06919, lr:1.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:71.230, tt:569.842\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00025, loss_test:0.06718, lr:1.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:72.018, tt:648.165\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00024, loss_test:0.06517, lr:1.00e-02, fs:0.74809 (r=0.990,p=0.601),  time:72.645, tt:726.454\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.06385, lr:1.00e-02, fs:0.74525 (r=0.990,p=0.598),  time:73.155, tt:804.704\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06300, lr:1.00e-02, fs:0.75573 (r=1.000,p=0.607),  time:73.526, tt:882.310\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.06186, lr:1.00e-02, fs:0.76744 (r=1.000,p=0.623),  time:73.776, tt:959.092\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06081, lr:1.00e-02, fs:0.76154 (r=1.000,p=0.615),  time:73.632, tt:1030.845\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.05957, lr:1.00e-02, fs:0.76863 (r=0.990,p=0.628),  time:73.686, tt:1105.284\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.05869, lr:1.00e-02, fs:0.78571 (r=1.000,p=0.647),  time:73.614, tt:1177.817\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00019, loss_test:0.05757, lr:1.00e-02, fs:0.78571 (r=1.000,p=0.647),  time:73.957, tt:1257.265\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.05685, lr:1.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:74.175, tt:1335.146\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.05597, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:74.393, tt:1413.467\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.05504, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:74.715, tt:1494.295\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.05465, lr:1.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:74.914, tt:1573.195\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05431, lr:1.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:75.201, tt:1654.415\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.05295, lr:1.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:75.036, tt:1725.828\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.05273, lr:1.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:74.942, tt:1798.607\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.05136, lr:1.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:74.833, tt:1870.821\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.05113, lr:1.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:74.831, tt:1945.595\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.05095, lr:1.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:74.986, tt:2024.609\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.04999, lr:1.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:75.200, tt:2105.612\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.05007, lr:1.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:75.284, tt:2183.229\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00012, loss_test:0.04868, lr:1.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:75.361, tt:2260.825\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.04849, lr:1.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:75.469, tt:2339.553\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.04833, lr:1.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:75.479, tt:2415.330\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.04832, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:75.379, tt:2487.511\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.04731, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:75.343, tt:2561.648\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00010, loss_test:0.04753, lr:1.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:75.289, tt:2635.106\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.04651, lr:1.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:75.380, tt:2713.696\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.04722, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:75.462, tt:2792.084\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00009, loss_test:0.04651, lr:1.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:75.589, tt:2872.370\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.04706, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:75.652, tt:2950.446\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.04546, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:75.773, tt:3030.910\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00008, loss_test:0.04677, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:75.854, tt:3110.013\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.04612, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:75.777, tt:3182.636\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.04555, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:75.722, tt:3256.059\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00007, loss_test:0.04530, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:75.670, tt:3329.475\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00007, loss_test:0.04646, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:75.675, tt:3405.378\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.04394, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:75.760, tt:3484.978\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.04699, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:75.857, tt:3565.265\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.04491, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:75.973, tt:3646.718\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.04541, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:76.030, tt:3725.453\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.04518, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:76.084, tt:3804.192\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.04471, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:76.059, tt:3879.000\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.04453, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:75.953, tt:3949.542\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.04393, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:75.927, tt:4024.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.04474, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:75.833, tt:4094.982\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.04469, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:75.863, tt:4172.480\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00005, loss_test:0.04370, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:75.886, tt:4249.599\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.04531, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:75.961, tt:4329.758\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.04372, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:76.002, tt:4408.127\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.04477, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:76.045, tt:4486.626\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.04514, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:76.135, tt:4568.118\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.04531, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:76.084, tt:4641.130\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.04437, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:76.028, tt:4713.744\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00004, loss_test:0.04491, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:75.957, tt:4785.319\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.04416, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:75.919, tt:4858.801\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.04539, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:76.007, tt:4940.428\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.04484, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:76.047, tt:5019.128\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.04480, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:76.094, tt:5098.275\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.04377, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:76.186, tt:5180.655\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.04559, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:76.236, tt:5260.295\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.04462, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:76.264, tt:5338.475\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00003, loss_test:0.04561, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:76.207, tt:5410.722\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.04459, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:76.160, tt:5483.529\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.04522, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:76.158, tt:5559.532\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.04576, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.200, tt:5638.793\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00003, loss_test:0.04519, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:76.231, tt:5717.347\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.04520, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.251, tt:5795.065\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.04547, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.306, tt:5875.544\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.04550, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.345, tt:5954.931\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.04573, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:76.394, tt:6035.122\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.04619, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.383, tt:6110.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.04579, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.343, tt:6183.784\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.04588, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.310, tt:6257.460\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.04581, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.262, tt:6329.742\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.04715, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.257, tt:6405.626\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.04579, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:76.301, tt:6485.609\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.04553, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.321, tt:6563.645\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.04667, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.365, tt:6643.716\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00002, loss_test:0.04681, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.425, tt:6725.439\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00002, loss_test:0.04666, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.470, tt:6805.813\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00002, loss_test:0.04589, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.438, tt:6879.425\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00002, loss_test:0.04687, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.402, tt:6952.622\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00002, loss_test:0.04713, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.375, tt:7026.462\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.04723, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.416, tt:7106.678\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.04534, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:76.456, tt:7186.885\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.04737, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.494, tt:7266.967\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.04693, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.536, tt:7347.445\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.04746, lr:9.90e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.564, tt:7426.671\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.04779, lr:9.80e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.589, tt:7505.765\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.04606, lr:9.70e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.586, tt:7582.048\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.04753, lr:9.61e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.554, tt:7655.395\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.04759, lr:9.51e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.530, tt:7729.494\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.04807, lr:9.41e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.516, tt:7804.674\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.04730, lr:9.32e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.544, tt:7883.985\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.04752, lr:9.23e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.579, tt:7964.196\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.04789, lr:9.14e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.629, tt:8046.063\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.04766, lr:9.04e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.660, tt:8125.986\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.04790, lr:8.95e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.715, tt:8208.534\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.04835, lr:8.86e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.720, tt:8285.710\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.04788, lr:8.78e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.673, tt:8357.340\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.04869, lr:8.69e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.641, tt:8430.558\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.04873, lr:8.60e-03, fs:0.86294 (r=0.859,p=0.867),  time:76.615, tt:8504.230\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.04786, lr:8.51e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.598, tt:8578.967\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.04933, lr:8.43e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.628, tt:8658.938\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.05014, lr:8.35e-03, fs:0.86294 (r=0.859,p=0.867),  time:76.648, tt:8737.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.04983, lr:8.26e-03, fs:0.86294 (r=0.859,p=0.867),  time:76.684, tt:8818.708\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.04879, lr:8.18e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.699, tt:8897.027\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00001, loss_test:0.04937, lr:8.10e-03, fs:0.88557 (r=0.899,p=0.873),  time:76.708, tt:8974.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00001, loss_test:0.05024, lr:8.02e-03, fs:0.85714 (r=0.848,p=0.866),  time:76.692, tt:9049.679\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00001, loss_test:0.05000, lr:7.94e-03, fs:0.89000 (r=0.899,p=0.881),  time:76.646, tt:9120.842\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00001, loss_test:0.04939, lr:7.86e-03, fs:0.88557 (r=0.899,p=0.873),  time:76.617, tt:9194.088\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.05009, lr:7.78e-03, fs:0.83770 (r=0.808,p=0.870),  time:76.586, tt:9266.954\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.08768, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:62.653, tt:62.653\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00036, loss_test:0.08272, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:70.226, tt:140.451\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00033, loss_test:0.07777, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:73.547, tt:220.641\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.07700, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:74.650, tt:298.599\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00030, loss_test:0.07371, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:75.380, tt:376.901\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.07075, lr:1.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:75.277, tt:451.663\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.06871, lr:1.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:74.569, tt:521.985\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.06629, lr:1.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:74.297, tt:594.379\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.06429, lr:1.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:73.690, tt:663.207\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.06282, lr:1.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:74.324, tt:743.241\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.06109, lr:1.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:74.667, tt:821.338\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.05970, lr:1.00e-02, fs:0.76800 (r=0.970,p=0.636),  time:74.971, tt:899.657\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.05825, lr:1.00e-02, fs:0.76800 (r=0.970,p=0.636),  time:75.183, tt:977.384\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.05703, lr:1.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:75.391, tt:1055.475\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.05604, lr:1.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:75.563, tt:1133.449\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.05506, lr:1.00e-02, fs:0.79032 (r=0.990,p=0.658),  time:75.222, tt:1203.555\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.05426, lr:1.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:75.013, tt:1275.221\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.05324, lr:1.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:74.905, tt:1348.288\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.05236, lr:1.00e-02, fs:0.80488 (r=1.000,p=0.673),  time:74.868, tt:1422.500\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.05194, lr:1.00e-02, fs:0.81148 (r=1.000,p=0.683),  time:74.970, tt:1499.405\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.05138, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:75.320, tt:1581.712\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05095, lr:1.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:75.487, tt:1660.713\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.05069, lr:1.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:75.674, tt:1740.491\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.05009, lr:1.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:75.850, tt:1820.411\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.04964, lr:1.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:75.777, tt:1894.421\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00014, loss_test:0.04911, lr:1.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:75.616, tt:1966.019\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.04808, lr:1.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:75.426, tt:2036.490\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.04853, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:75.255, tt:2107.129\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.04792, lr:1.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:75.268, tt:2182.773\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.04806, lr:1.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:75.358, tt:2260.728\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.04687, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:75.481, tt:2339.901\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.04789, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:75.586, tt:2418.765\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.04675, lr:1.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:75.666, tt:2496.984\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.04722, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:75.765, tt:2576.007\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.04675, lr:1.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:75.732, tt:2650.632\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.04671, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:75.582, tt:2720.939\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.04630, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:75.467, tt:2792.266\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00009, loss_test:0.04569, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:75.377, tt:2864.315\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.04574, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:75.388, tt:2940.118\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.04599, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:75.498, tt:3019.937\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00008, loss_test:0.04543, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:75.581, tt:3098.801\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.04566, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.646, tt:3177.152\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.04530, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.666, tt:3253.652\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.04541, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.714, tt:3331.427\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00007, loss_test:0.04478, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.547, tt:3399.630\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.04451, lr:1.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:75.474, tt:3471.784\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.04464, lr:1.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:75.383, tt:3543.021\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.04439, lr:1.00e-02, fs:0.89302 (r=0.970,p=0.828),  time:75.396, tt:3619.028\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00006, loss_test:0.04398, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:75.468, tt:3697.910\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.04349, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:75.537, tt:3776.850\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.04383, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:75.557, tt:3853.425\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.04364, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:75.607, tt:3931.540\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.04382, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:75.621, tt:4007.936\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00005, loss_test:0.04348, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:75.635, tt:4084.279\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00005, loss_test:0.04511, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:75.552, tt:4155.354\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00005, loss_test:0.04351, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:75.443, tt:4224.797\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.04325, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:75.442, tt:4300.208\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.04373, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:75.509, tt:4379.540\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.04276, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:75.583, tt:4459.411\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.04334, lr:1.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:75.641, tt:4538.479\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00004, loss_test:0.04328, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:75.685, tt:4616.758\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00004, loss_test:0.04280, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:75.724, tt:4694.900\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00004, loss_test:0.04398, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:75.750, tt:4772.257\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.04294, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:75.692, tt:4844.309\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.04328, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:75.630, tt:4915.976\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.04409, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:75.605, tt:4989.903\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.04413, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:75.587, tt:5064.318\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.04369, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:75.637, tt:5143.317\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.04316, lr:1.00e-02, fs:0.92891 (r=0.990,p=0.875),  time:75.666, tt:5220.931\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.04485, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:75.704, tt:5299.271\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00003, loss_test:0.04403, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:75.741, tt:5377.595\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00003, loss_test:0.04345, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:75.757, tt:5454.471\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00003, loss_test:0.04432, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:75.725, tt:5527.947\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00003, loss_test:0.04407, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:75.685, tt:5600.705\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00003, loss_test:0.04310, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:75.617, tt:5671.310\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.04462, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:75.566, tt:5743.005\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.04368, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:75.580, tt:5819.693\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.04519, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:75.600, tt:5896.780\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.04533, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:75.598, tt:5972.220\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.04463, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:75.607, tt:6048.527\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.04526, lr:9.90e-03, fs:0.85263 (r=0.818,p=0.890),  time:75.638, tt:6126.678\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.04556, lr:9.80e-03, fs:0.85106 (r=0.808,p=0.899),  time:75.656, tt:6203.793\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.04554, lr:9.70e-03, fs:0.85714 (r=0.818,p=0.900),  time:75.638, tt:6277.960\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00002, loss_test:0.04546, lr:9.61e-03, fs:0.84817 (r=0.818,p=0.880),  time:75.570, tt:6347.849\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.04577, lr:9.51e-03, fs:0.86458 (r=0.838,p=0.892),  time:75.483, tt:6416.032\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00002, loss_test:0.04551, lr:9.41e-03, fs:0.84492 (r=0.798,p=0.898),  time:75.431, tt:6487.074\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00002, loss_test:0.04797, lr:9.32e-03, fs:0.84324 (r=0.788,p=0.907),  time:75.448, tt:6564.001\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00002, loss_test:0.04638, lr:9.23e-03, fs:0.84043 (r=0.798,p=0.888),  time:75.465, tt:6640.876\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00002, loss_test:0.04638, lr:9.14e-03, fs:0.84492 (r=0.798,p=0.898),  time:75.502, tt:6719.723\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00002, loss_test:0.04653, lr:9.04e-03, fs:0.84492 (r=0.798,p=0.898),  time:75.535, tt:6798.138\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00002, loss_test:0.04740, lr:8.95e-03, fs:0.84946 (r=0.798,p=0.908),  time:75.565, tt:6876.397\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00002, loss_test:0.04607, lr:8.86e-03, fs:0.84817 (r=0.818,p=0.880),  time:75.589, tt:6954.200\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.04703, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:75.533, tt:7024.566\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.04722, lr:8.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:75.483, tt:7095.374\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.04686, lr:8.60e-03, fs:0.85106 (r=0.808,p=0.899),  time:75.440, tt:7166.776\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.04728, lr:8.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:75.439, tt:7242.103\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.04707, lr:8.43e-03, fs:0.84656 (r=0.808,p=0.889),  time:75.479, tt:7321.431\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.04802, lr:8.35e-03, fs:0.84324 (r=0.788,p=0.907),  time:75.472, tt:7396.220\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.04718, lr:8.26e-03, fs:0.84211 (r=0.808,p=0.879),  time:75.476, tt:7472.130\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.04858, lr:8.18e-03, fs:0.84324 (r=0.788,p=0.907),  time:75.513, tt:7551.268\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.04743, lr:8.10e-03, fs:0.85263 (r=0.818,p=0.890),  time:75.575, tt:7633.091\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.04814, lr:8.02e-03, fs:0.84153 (r=0.778,p=0.917),  time:75.563, tt:7707.426\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.04735, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:75.510, tt:7777.489\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.04880, lr:7.86e-03, fs:0.84324 (r=0.788,p=0.907),  time:75.469, tt:7848.820\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.04789, lr:7.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:75.442, tt:7921.431\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.04863, lr:7.70e-03, fs:0.83696 (r=0.778,p=0.906),  time:75.459, tt:7998.693\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00001, loss_test:0.04793, lr:7.62e-03, fs:0.85106 (r=0.808,p=0.899),  time:75.486, tt:8076.988\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.04831, lr:7.55e-03, fs:0.85714 (r=0.818,p=0.900),  time:75.510, tt:8155.084\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.04844, lr:7.47e-03, fs:0.84043 (r=0.798,p=0.888),  time:75.540, tt:8233.819\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00001, loss_test:0.04820, lr:7.40e-03, fs:0.84492 (r=0.798,p=0.898),  time:75.568, tt:8312.435\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00001, loss_test:0.04823, lr:7.32e-03, fs:0.85106 (r=0.808,p=0.899),  time:75.615, tt:8393.274\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00001, loss_test:0.04816, lr:7.25e-03, fs:0.84656 (r=0.808,p=0.889),  time:75.596, tt:8466.740\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00001, loss_test:0.04880, lr:7.18e-03, fs:0.83871 (r=0.788,p=0.897),  time:75.541, tt:8536.078\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00001, loss_test:0.04882, lr:7.11e-03, fs:0.83871 (r=0.788,p=0.897),  time:75.529, tt:8610.294\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00001, loss_test:0.04801, lr:7.03e-03, fs:0.85864 (r=0.828,p=0.891),  time:75.554, tt:8688.665\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00001, loss_test:0.04844, lr:6.96e-03, fs:0.84492 (r=0.798,p=0.898),  time:75.557, tt:8764.652\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00001, loss_test:0.04882, lr:6.89e-03, fs:0.85561 (r=0.808,p=0.909),  time:75.592, tt:8844.271\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00001, loss_test:0.04869, lr:6.83e-03, fs:0.84656 (r=0.808,p=0.889),  time:75.580, tt:8918.454\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00001, loss_test:0.04844, lr:6.76e-03, fs:0.85714 (r=0.818,p=0.900),  time:75.625, tt:8999.427\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00001, loss_test:0.04829, lr:6.69e-03, fs:0.85714 (r=0.818,p=0.900),  time:75.645, tt:9077.452\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.04834, lr:6.62e-03, fs:0.85714 (r=0.818,p=0.900),  time:75.633, tt:9151.610\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 32\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09628, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.975, tt:45.975\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.09350, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:54.442, tt:108.885\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00032, loss_test:0.09011, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:61.837, tt:185.512\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00030, loss_test:0.08926, lr:1.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:66.085, tt:264.338\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00030, loss_test:0.08527, lr:1.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:68.025, tt:340.125\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00028, loss_test:0.08336, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:69.871, tt:419.224\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00026, loss_test:0.08302, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:71.256, tt:498.793\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00025, loss_test:0.08005, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:72.125, tt:577.002\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00024, loss_test:0.07869, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:72.199, tt:649.793\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00024, loss_test:0.07805, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:71.993, tt:719.927\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00023, loss_test:0.07647, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:71.926, tt:791.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00022, loss_test:0.07556, lr:1.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:72.160, tt:865.921\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00021, loss_test:0.07489, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:72.592, tt:943.693\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00020, loss_test:0.07470, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:73.102, tt:1023.426\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00020, loss_test:0.07466, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:73.396, tt:1100.937\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00019, loss_test:0.07336, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:73.521, tt:1176.342\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00019, loss_test:0.07363, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:73.843, tt:1255.325\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00018, loss_test:0.07220, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:73.959, tt:1331.259\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00017, loss_test:0.07207, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:73.765, tt:1401.535\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00017, loss_test:0.07172, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:73.581, tt:1471.610\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.07136, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:73.393, tt:1541.258\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00016, loss_test:0.06967, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:73.521, tt:1617.465\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.07053, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:73.775, tt:1696.815\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00015, loss_test:0.06956, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:73.838, tt:1772.103\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.06914, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:74.037, tt:1850.926\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00014, loss_test:0.06770, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:74.282, tt:1931.337\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.06774, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:74.459, tt:2010.392\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00013, loss_test:0.06693, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:74.445, tt:2084.473\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.06757, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:74.373, tt:2156.828\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.06656, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:74.341, tt:2230.221\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.06681, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:74.316, tt:2303.785\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.06559, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:74.496, tt:2383.884\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.06608, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:74.623, tt:2462.564\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.06545, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:74.804, tt:2543.332\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00010, loss_test:0.06442, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:74.956, tt:2623.476\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.06556, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:75.108, tt:2703.882\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.06387, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:75.151, tt:2780.579\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00009, loss_test:0.06366, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:75.109, tt:2854.142\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.06488, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:75.057, tt:2927.205\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.06356, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:75.046, tt:3001.831\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00008, loss_test:0.06445, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:75.090, tt:3078.699\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.06281, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:75.234, tt:3159.833\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.06347, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:75.341, tt:3239.677\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.06462, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:75.412, tt:3318.116\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.06339, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:75.484, tt:3396.778\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.06323, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:75.579, tt:3476.642\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.06419, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:75.556, tt:3551.137\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.06432, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:75.476, tt:3622.829\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00006, loss_test:0.06234, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:75.438, tt:3696.485\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.06336, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:75.427, tt:3771.353\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00006, loss_test:0.06339, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:75.558, tt:3853.447\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.06276, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:75.646, tt:3933.614\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.06419, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:75.778, tt:4016.236\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.06182, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:75.804, tt:4093.443\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00005, loss_test:0.06322, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:75.879, tt:4173.371\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.06431, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:75.947, tt:4253.042\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.06374, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:75.895, tt:4326.023\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.06468, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:75.807, tt:4396.790\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.06323, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:75.711, tt:4466.965\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.06382, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:75.737, tt:4544.232\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.06380, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:75.792, tt:4623.307\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.06185, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:75.879, tt:4704.511\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00004, loss_test:0.06398, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:75.909, tt:4782.294\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.06171, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:75.899, tt:4857.522\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.06366, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:75.979, tt:4938.645\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.06350, lr:9.90e-03, fs:0.78756 (r=0.768,p=0.809),  time:76.022, tt:5017.453\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.06279, lr:9.90e-03, fs:0.77949 (r=0.768,p=0.792),  time:75.971, tt:5090.039\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.06404, lr:9.90e-03, fs:0.79167 (r=0.768,p=0.817),  time:75.923, tt:5162.773\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.06121, lr:9.90e-03, fs:0.77949 (r=0.768,p=0.792),  time:75.884, tt:5236.029\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.06592, lr:9.90e-03, fs:0.80214 (r=0.758,p=0.852),  time:75.918, tt:5314.252\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.06218, lr:9.90e-03, fs:0.78351 (r=0.768,p=0.800),  time:75.969, tt:5393.789\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.06465, lr:9.90e-03, fs:0.79167 (r=0.768,p=0.817),  time:76.022, tt:5473.613\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.06262, lr:9.90e-03, fs:0.77720 (r=0.758,p=0.798),  time:76.079, tt:5553.739\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00003, loss_test:0.06460, lr:9.90e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.136, tt:5634.042\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00003, loss_test:0.06225, lr:9.90e-03, fs:0.80000 (r=0.788,p=0.812),  time:76.175, tt:5713.129\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.06596, lr:9.90e-03, fs:0.79787 (r=0.758,p=0.843),  time:76.114, tt:5784.688\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.06319, lr:9.90e-03, fs:0.78947 (r=0.758,p=0.824),  time:76.067, tt:5857.127\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.06443, lr:9.90e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.019, tt:5929.507\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.06419, lr:9.90e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.038, tt:6006.990\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.06441, lr:9.90e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.092, tt:6087.349\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.06616, lr:9.90e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.138, tt:6167.176\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.06405, lr:9.90e-03, fs:0.79365 (r=0.758,p=0.833),  time:76.200, tt:6248.411\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.06531, lr:9.90e-03, fs:0.80214 (r=0.758,p=0.852),  time:76.222, tt:6326.397\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.06423, lr:9.90e-03, fs:0.80423 (r=0.768,p=0.844),  time:76.248, tt:6404.872\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.06431, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.264, tt:6482.479\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.06486, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.237, tt:6556.378\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.06380, lr:9.90e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.212, tt:6630.410\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00002, loss_test:0.06582, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.205, tt:6706.073\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.06381, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.242, tt:6785.513\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00002, loss_test:0.06511, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.303, tt:6867.262\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.06667, lr:9.90e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.359, tt:6948.625\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00002, loss_test:0.06571, lr:9.90e-03, fs:0.80874 (r=0.747,p=0.881),  time:76.417, tt:7030.399\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.06536, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.446, tt:7109.474\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.06541, lr:9.70e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.475, tt:7188.610\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.06625, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.449, tt:7262.689\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.06643, lr:9.61e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.416, tt:7335.900\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.06418, lr:9.61e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.387, tt:7409.507\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.06672, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.400, tt:7487.240\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.06591, lr:9.61e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.438, tt:7567.384\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.06510, lr:9.61e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.462, tt:7646.239\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.06583, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.508, tt:7727.314\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.06429, lr:9.61e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.551, tt:7808.217\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.06667, lr:9.61e-03, fs:0.82873 (r=0.758,p=0.915),  time:76.583, tt:7888.057\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.06556, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.613, tt:7967.724\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.06690, lr:9.61e-03, fs:0.82418 (r=0.758,p=0.904),  time:76.586, tt:8041.487\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.06599, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.585, tt:8117.997\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.06764, lr:9.61e-03, fs:0.82873 (r=0.758,p=0.915),  time:76.559, tt:8191.761\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.06761, lr:9.61e-03, fs:0.82873 (r=0.758,p=0.915),  time:76.578, tt:8270.380\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.06635, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.597, tt:8349.021\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.06696, lr:9.61e-03, fs:0.82873 (r=0.758,p=0.915),  time:76.647, tt:8431.220\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.06667, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.675, tt:8510.872\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00001, loss_test:0.06645, lr:9.61e-03, fs:0.82418 (r=0.758,p=0.904),  time:76.707, tt:8591.199\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00001, loss_test:0.06514, lr:9.61e-03, fs:0.82418 (r=0.758,p=0.904),  time:76.725, tt:8669.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00001, loss_test:0.06676, lr:9.61e-03, fs:0.82418 (r=0.758,p=0.904),  time:76.692, tt:8742.906\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00001, loss_test:0.06588, lr:9.51e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.667, tt:8816.717\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00001, loss_test:0.06700, lr:9.41e-03, fs:0.82162 (r=0.768,p=0.884),  time:76.657, tt:8892.157\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00001, loss_test:0.06567, lr:9.32e-03, fs:0.81967 (r=0.758,p=0.893),  time:76.628, tt:8965.488\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00001, loss_test:0.06759, lr:9.23e-03, fs:0.83333 (r=0.758,p=0.926),  time:76.659, tt:9045.759\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00001, loss_test:0.06626, lr:9.23e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.689, tt:9125.972\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00001, loss_test:0.06675, lr:9.23e-03, fs:0.81522 (r=0.758,p=0.882),  time:76.698, tt:9203.795\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.06740, lr:9.23e-03, fs:0.82873 (r=0.758,p=0.915),  time:76.740, tt:9285.523\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 33\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09022, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:54.013, tt:54.013\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.08568, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:59.689, tt:119.379\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00033, loss_test:0.08001, lr:1.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:64.591, tt:193.773\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00031, loss_test:0.07795, lr:1.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:67.471, tt:269.886\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00030, loss_test:0.07610, lr:1.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:68.966, tt:344.828\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.07343, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:70.767, tt:424.599\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00027, loss_test:0.07043, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:72.395, tt:506.762\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00026, loss_test:0.06762, lr:1.00e-02, fs:0.70943 (r=0.949,p=0.566),  time:73.027, tt:584.216\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00025, loss_test:0.06578, lr:1.00e-02, fs:0.72180 (r=0.970,p=0.575),  time:74.052, tt:666.470\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00024, loss_test:0.06388, lr:1.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:74.486, tt:744.860\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.06219, lr:1.00e-02, fs:0.75781 (r=0.980,p=0.618),  time:74.766, tt:822.425\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06051, lr:1.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:74.741, tt:896.895\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.05959, lr:1.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:74.544, tt:969.072\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.05814, lr:1.00e-02, fs:0.77419 (r=0.970,p=0.644),  time:74.509, tt:1043.128\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.05738, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:75.100, tt:1126.493\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.05611, lr:1.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:75.338, tt:1205.404\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.05508, lr:1.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:75.676, tt:1286.491\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.05522, lr:1.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:75.860, tt:1365.484\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.05395, lr:1.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:75.969, tt:1443.411\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.05383, lr:1.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:76.155, tt:1523.091\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.05282, lr:1.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:76.039, tt:1596.822\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05129, lr:1.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:75.907, tt:1669.952\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.05100, lr:1.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:75.676, tt:1740.540\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.05106, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:75.676, tt:1816.233\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.04928, lr:1.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:75.812, tt:1895.298\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00014, loss_test:0.04931, lr:1.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:75.928, tt:1974.116\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.04927, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:75.989, tt:2051.692\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.04781, lr:1.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:76.065, tt:2129.807\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.04875, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:76.164, tt:2208.745\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00012, loss_test:0.04777, lr:1.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:76.079, tt:2282.372\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.04812, lr:1.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:75.977, tt:2355.285\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00011, loss_test:0.04786, lr:1.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:75.869, tt:2427.818\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.04592, lr:1.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:75.735, tt:2499.247\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.04744, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:75.765, tt:2576.010\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00010, loss_test:0.04668, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:75.839, tt:2654.367\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.04706, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:75.921, tt:2733.155\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00009, loss_test:0.04604, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:76.005, tt:2812.183\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00009, loss_test:0.04690, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:76.104, tt:2891.954\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.04745, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:76.257, tt:2974.006\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.04734, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:76.142, tt:3045.673\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00008, loss_test:0.04526, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:76.064, tt:3118.640\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.04638, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:75.957, tt:3190.195\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.04652, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:75.989, tt:3267.535\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00007, loss_test:0.04707, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:76.051, tt:3346.264\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00007, loss_test:0.04544, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:76.114, tt:3425.111\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:45, loss:0.00007, loss_test:0.04587, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:76.198, tt:3505.126\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.04662, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:76.240, tt:3583.257\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.04704, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:76.328, tt:3663.757\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00006, loss_test:0.04512, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:76.293, tt:3738.343\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.04685, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:76.181, tt:3809.062\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.04626, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:76.110, tt:3881.589\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.04497, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:76.050, tt:3954.600\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.04512, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:76.108, tt:4033.734\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00005, loss_test:0.04554, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.155, tt:4112.352\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00005, loss_test:0.04588, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.214, tt:4191.763\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00005, loss_test:0.04514, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:76.261, tt:4270.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.04560, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.297, tt:4348.945\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.04418, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.328, tt:4427.020\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.04695, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:76.262, tt:4499.463\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00004, loss_test:0.04489, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:76.189, tt:4571.358\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00004, loss_test:0.04468, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:76.137, tt:4644.378\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00004, loss_test:0.04657, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.088, tt:4717.437\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00004, loss_test:0.04569, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.161, tt:4798.151\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.04467, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.208, tt:4877.304\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.04779, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.280, tt:4958.207\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.04517, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.336, tt:5038.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.04579, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.397, tt:5118.602\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.04678, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.403, tt:5195.394\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.04552, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.338, tt:5267.350\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.04628, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.268, tt:5338.745\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00003, loss_test:0.04644, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.205, tt:5410.577\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00003, loss_test:0.04604, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.226, tt:5488.285\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00003, loss_test:0.04721, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.259, tt:5566.942\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00003, loss_test:0.04654, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.284, tt:5645.018\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00003, loss_test:0.04688, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.328, tt:5724.636\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.04638, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:76.374, tt:5804.424\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.04630, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:76.394, tt:5882.356\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.04730, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.364, tt:5956.411\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.04694, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:76.307, tt:6028.255\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.04732, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:76.294, tt:6103.490\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.04936, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.253, tt:6176.516\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.04708, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:76.298, tt:6256.419\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.04653, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.363, tt:6338.147\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.04637, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.406, tt:6418.107\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00002, loss_test:0.04817, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:76.446, tt:6497.949\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00002, loss_test:0.04707, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.439, tt:6573.745\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00002, loss_test:0.04763, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:76.454, tt:6651.476\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00002, loss_test:0.04720, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:76.420, tt:6724.997\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00002, loss_test:0.04851, lr:9.90e-03, fs:0.90099 (r=0.919,p=0.883),  time:76.405, tt:6800.085\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00002, loss_test:0.04693, lr:9.80e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.353, tt:6871.802\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00002, loss_test:0.04856, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.379, tt:6950.498\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00002, loss_test:0.04742, lr:9.70e-03, fs:0.89655 (r=0.919,p=0.875),  time:76.395, tt:7028.366\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.04882, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.404, tt:7105.569\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.04919, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.418, tt:7183.290\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.04846, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.440, tt:7261.785\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.04766, lr:9.70e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.475, tt:7341.600\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.04879, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.433, tt:7414.016\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.04934, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.388, tt:7486.003\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.04915, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.352, tt:7558.833\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.04837, lr:9.70e-03, fs:0.89109 (r=0.909,p=0.874),  time:76.321, tt:7632.092\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.04870, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.348, tt:7711.188\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.05109, lr:9.70e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.384, tt:7791.208\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.04907, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.418, tt:7871.066\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.04909, lr:9.70e-03, fs:0.91000 (r=0.919,p=0.901),  time:76.452, tt:7950.990\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.04917, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.489, tt:8031.352\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.05215, lr:9.70e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.506, tt:8109.584\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.04928, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.484, tt:8183.756\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.04979, lr:9.70e-03, fs:0.91000 (r=0.919,p=0.901),  time:76.461, tt:8257.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.04876, lr:9.70e-03, fs:0.90547 (r=0.919,p=0.892),  time:76.418, tt:8329.606\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00001, loss_test:0.04979, lr:9.70e-03, fs:0.91457 (r=0.919,p=0.910),  time:76.436, tt:8408.001\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00001, loss_test:0.05086, lr:9.70e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.479, tt:8489.184\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.05128, lr:9.70e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.507, tt:8568.812\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00001, loss_test:0.05176, lr:9.70e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.542, tt:8649.195\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00001, loss_test:0.04849, lr:9.61e-03, fs:0.91000 (r=0.919,p=0.901),  time:76.576, tt:8729.707\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00001, loss_test:0.05062, lr:9.51e-03, fs:0.91457 (r=0.919,p=0.910),  time:76.586, tt:8807.403\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00001, loss_test:0.05155, lr:9.41e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.532, tt:8877.693\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00001, loss_test:0.05123, lr:9.32e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.514, tt:8952.176\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00001, loss_test:0.04991, lr:9.23e-03, fs:0.91457 (r=0.919,p=0.910),  time:76.499, tt:9026.868\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00001, loss_test:0.05057, lr:9.14e-03, fs:0.91457 (r=0.919,p=0.910),  time:76.478, tt:9100.886\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00001, loss_test:0.05150, lr:9.04e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.493, tt:9179.117\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.05069, lr:8.95e-03, fs:0.91919 (r=0.919,p=0.919),  time:76.504, tt:9256.973\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 34\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09323, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:59.198, tt:59.198\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.08853, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:61.934, tt:123.868\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00033, loss_test:0.08361, lr:1.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:67.773, tt:203.320\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00031, loss_test:0.08290, lr:1.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:68.286, tt:273.143\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00030, loss_test:0.07862, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:68.710, tt:343.552\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.07554, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:68.897, tt:413.385\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00027, loss_test:0.07363, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:68.929, tt:482.506\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00026, loss_test:0.07187, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:68.849, tt:550.792\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00025, loss_test:0.07011, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:68.826, tt:619.430\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00024, loss_test:0.06831, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:68.756, tt:687.558\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00023, loss_test:0.06661, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:69.075, tt:759.820\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06528, lr:1.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:68.951, tt:827.416\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.06402, lr:1.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:69.013, tt:897.169\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00021, loss_test:0.06332, lr:1.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:69.122, tt:967.713\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00020, loss_test:0.06247, lr:1.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:69.182, tt:1037.731\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.06139, lr:1.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:69.188, tt:1107.009\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00019, loss_test:0.06032, lr:1.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:69.321, tt:1178.458\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.05943, lr:1.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:69.300, tt:1247.397\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.05853, lr:1.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:69.322, tt:1317.122\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00017, loss_test:0.05773, lr:1.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:69.373, tt:1387.460\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.05725, lr:1.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:69.380, tt:1456.989\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05679, lr:1.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:69.319, tt:1525.018\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.05592, lr:1.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:69.377, tt:1595.663\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.05616, lr:1.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:69.331, tt:1663.948\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.05544, lr:1.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:69.406, tt:1735.156\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00014, loss_test:0.05494, lr:1.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:69.492, tt:1806.804\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.05432, lr:1.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:69.467, tt:1875.599\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.05384, lr:1.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:69.535, tt:1946.988\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.05377, lr:1.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:69.565, tt:2017.398\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.05353, lr:1.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:69.603, tt:2088.077\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.05296, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:69.607, tt:2157.816\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.05220, lr:1.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:69.599, tt:2227.152\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.05248, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:69.592, tt:2296.537\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.05207, lr:1.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:69.659, tt:2368.406\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.05218, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:69.690, tt:2439.136\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.05103, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:69.743, tt:2510.748\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.05205, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:69.759, tt:2581.091\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.05001, lr:1.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:69.840, tt:2653.926\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.05144, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:69.901, tt:2726.128\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.05011, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:69.970, tt:2798.788\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.05071, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:69.922, tt:2866.799\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.05008, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:69.947, tt:2937.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.04950, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:69.986, tt:3009.402\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.05041, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:69.989, tt:3079.534\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.04951, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:70.012, tt:3150.541\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.04924, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:70.034, tt:3221.568\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.04885, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:70.086, tt:3294.048\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.04904, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:70.073, tt:3363.527\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.04897, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:70.063, tt:3433.089\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.04856, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:70.100, tt:3505.001\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.04940, lr:9.90e-03, fs:0.82857 (r=0.879,p=0.784),  time:70.116, tt:3575.911\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.04861, lr:9.80e-03, fs:0.83654 (r=0.879,p=0.798),  time:70.147, tt:3647.663\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.04848, lr:9.70e-03, fs:0.83254 (r=0.879,p=0.791),  time:70.142, tt:3717.542\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.04833, lr:9.61e-03, fs:0.82464 (r=0.879,p=0.777),  time:70.151, tt:3788.138\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.04868, lr:9.51e-03, fs:0.85294 (r=0.879,p=0.829),  time:70.132, tt:3857.244\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.04856, lr:9.51e-03, fs:0.84878 (r=0.879,p=0.821),  time:70.134, tt:3927.489\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.04847, lr:9.51e-03, fs:0.84314 (r=0.869,p=0.819),  time:70.100, tt:3995.681\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.04745, lr:9.51e-03, fs:0.82075 (r=0.879,p=0.770),  time:70.124, tt:4067.196\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.04840, lr:9.51e-03, fs:0.84058 (r=0.879,p=0.806),  time:70.135, tt:4137.946\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.04828, lr:9.51e-03, fs:0.84058 (r=0.879,p=0.806),  time:70.154, tt:4209.229\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.04850, lr:9.51e-03, fs:0.84878 (r=0.879,p=0.821),  time:70.147, tt:4278.991\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.04804, lr:9.51e-03, fs:0.84878 (r=0.879,p=0.821),  time:70.202, tt:4352.511\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.04811, lr:9.51e-03, fs:0.85294 (r=0.879,p=0.829),  time:70.219, tt:4423.818\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.04875, lr:9.51e-03, fs:0.86139 (r=0.879,p=0.845),  time:70.217, tt:4493.869\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.04753, lr:9.51e-03, fs:0.85294 (r=0.879,p=0.829),  time:70.284, tt:4568.466\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.04844, lr:9.51e-03, fs:0.87000 (r=0.879,p=0.861),  time:70.299, tt:4639.729\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.04772, lr:9.51e-03, fs:0.84466 (r=0.879,p=0.813),  time:70.318, tt:4711.306\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.04808, lr:9.51e-03, fs:0.87437 (r=0.879,p=0.870),  time:70.328, tt:4782.305\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.04840, lr:9.51e-03, fs:0.86567 (r=0.879,p=0.853),  time:70.345, tt:4853.833\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.04913, lr:9.51e-03, fs:0.87437 (r=0.879,p=0.870),  time:70.323, tt:4922.625\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0307a213a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,121,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 50\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:0, loss:0.00007, loss_test:0.02377, lr:1.00e-02, fs:0.56579 (r=0.434,p=0.811),  time:82.351, tt:82.351\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:1, loss:0.00004, loss_test:0.01313, lr:1.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:83.396, tt:166.793\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:2, loss:0.00003, loss_test:0.00994, lr:1.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:82.964, tt:248.891\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:3, loss:0.00003, loss_test:0.00919, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:81.381, tt:325.526\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:4, loss:0.00003, loss_test:0.00915, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:80.155, tt:400.777\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:5, loss:0.00003, loss_test:0.00948, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:79.116, tt:474.695\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:6, loss:0.00003, loss_test:0.01009, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:78.653, tt:550.571\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:7, loss:0.00003, loss_test:0.01076, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:78.581, tt:628.650\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:8, loss:0.00003, loss_test:0.01122, lr:1.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:77.955, tt:701.595\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:9, loss:0.00003, loss_test:0.01137, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:77.452, tt:774.522\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:10, loss:0.00003, loss_test:0.01127, lr:1.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:77.629, tt:853.915\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:11, loss:0.00003, loss_test:0.01106, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:77.496, tt:929.949\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:12, loss:0.00003, loss_test:0.01085, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:77.146, tt:1002.897\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:13, loss:0.00003, loss_test:0.01072, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:76.988, tt:1077.837\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:14, loss:0.00002, loss_test:0.01067, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:76.875, tt:1153.120\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:15, loss:0.00002, loss_test:0.01066, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:76.742, tt:1227.867\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:16, loss:0.00002, loss_test:0.01067, lr:1.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:76.542, tt:1301.211\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:17, loss:0.00002, loss_test:0.01070, lr:1.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:76.539, tt:1377.708\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:18, loss:0.00002, loss_test:0.01071, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.606, tt:1455.506\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:19, loss:0.00002, loss_test:0.01071, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.526, tt:1530.524\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:20, loss:0.00002, loss_test:0.01070, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.320, tt:1602.715\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:21, loss:0.00002, loss_test:0.01067, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.389, tt:1680.566\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:22, loss:0.00002, loss_test:0.01066, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.494, tt:1759.366\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:23, loss:0.00002, loss_test:0.01066, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.441, tt:1834.589\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:24, loss:0.00002, loss_test:0.01066, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.520, tt:1912.996\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:25, loss:0.00002, loss_test:0.01065, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.531, tt:1989.799\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:26, loss:0.00002, loss_test:0.01063, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.641, tt:2069.295\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n",
      "Ep:27, loss:0.00002, loss_test:0.01062, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:76.884, tt:2152.757\n",
      "1040\n",
      "1060\n",
      "1045\n",
      "1030\n",
      "265\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-25ad571cf3fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.2+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"51-51\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.2+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"51-51\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 50\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:0, loss:0.00056, loss_test:0.10403, lr:1.00e-02, fs:0.59394 (r=0.495,p=0.742),  time:80.220, tt:80.220\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:1, loss:0.00024, loss_test:0.10706, lr:1.00e-02, fs:0.59756 (r=0.495,p=0.754),  time:84.111, tt:168.221\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:2, loss:0.00022, loss_test:0.09037, lr:1.00e-02, fs:0.69792 (r=0.677,p=0.720),  time:87.793, tt:263.379\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:3, loss:0.00021, loss_test:0.09169, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:89.652, tt:358.609\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:4, loss:0.00020, loss_test:0.08707, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:87.822, tt:439.111\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:5, loss:0.00019, loss_test:0.09272, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:86.835, tt:521.008\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:6, loss:0.00018, loss_test:0.08617, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:87.978, tt:615.846\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:7, loss:0.00018, loss_test:0.09660, lr:1.00e-02, fs:0.69274 (r=0.626,p=0.775),  time:89.005, tt:712.043\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:8, loss:0.00017, loss_test:0.08880, lr:1.00e-02, fs:0.72222 (r=0.657,p=0.802),  time:89.001, tt:801.010\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:9, loss:0.00016, loss_test:0.08921, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:88.146, tt:881.456\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:10, loss:0.00014, loss_test:0.08806, lr:1.00e-02, fs:0.72414 (r=0.636,p=0.840),  time:87.843, tt:966.271\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:11, loss:0.00014, loss_test:0.08518, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:88.639, tt:1063.666\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:12, loss:0.00013, loss_test:0.08055, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:88.996, tt:1156.944\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:13, loss:0.00012, loss_test:0.08078, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:88.349, tt:1236.881\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:14, loss:0.00012, loss_test:0.08492, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:88.179, tt:1322.687\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:15, loss:0.00011, loss_test:0.08839, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:88.636, tt:1418.176\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:16, loss:0.00011, loss_test:0.08863, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:89.084, tt:1514.428\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:17, loss:0.00010, loss_test:0.08919, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:88.724, tt:1597.035\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:18, loss:0.00010, loss_test:0.08800, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:88.407, tt:1679.730\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:19, loss:0.00010, loss_test:0.08465, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:88.274, tt:1765.473\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:20, loss:0.00009, loss_test:0.08192, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:88.543, tt:1859.407\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:21, loss:0.00009, loss_test:0.07763, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:88.746, tt:1952.403\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:22, loss:0.00008, loss_test:0.07589, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:88.431, tt:2033.918\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:23, loss:0.00008, loss_test:0.07712, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:89.195, tt:2140.691\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:24, loss:0.00008, loss_test:0.08071, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:91.177, tt:2279.422\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:25, loss:0.00007, loss_test:0.08048, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:93.042, tt:2419.100\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:26, loss:0.00007, loss_test:0.08408, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:94.340, tt:2547.191\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:27, loss:0.00007, loss_test:0.08488, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:95.442, tt:2672.374\n",
      "##########Best model found so far##########\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:28, loss:0.00007, loss_test:0.08477, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:96.651, tt:2802.882\n",
      "1116\n",
      "1134\n",
      "1026\n",
      "1035\n",
      "1062\n",
      "1026\n",
      "1062\n",
      "531\n",
      "Ep:29, loss:0.00007, loss_test:0.07640, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:98.073, tt:2942.205\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,\"51-51\",8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:0, loss:0.00044, loss_test:0.08617, lr:1.00e-02, fs:0.61739 (r=0.717,p=0.542),  time:66.483, tt:66.483\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:1, loss:0.00025, loss_test:0.08958, lr:1.00e-02, fs:0.63054 (r=0.646,p=0.615),  time:80.186, tt:160.373\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:2, loss:0.00022, loss_test:0.08711, lr:1.00e-02, fs:0.63636 (r=0.636,p=0.636),  time:81.696, tt:245.089\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:3, loss:0.00020, loss_test:0.08556, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:84.300, tt:337.199\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:4, loss:0.00020, loss_test:0.07995, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:85.130, tt:425.649\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:5, loss:0.00019, loss_test:0.08026, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:86.930, tt:521.582\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:6, loss:0.00018, loss_test:0.07758, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:88.424, tt:618.968\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:7, loss:0.00017, loss_test:0.07501, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:89.802, tt:718.418\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:8, loss:0.00017, loss_test:0.07647, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:90.641, tt:815.768\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:9, loss:0.00016, loss_test:0.07347, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:90.617, tt:906.166\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:10, loss:0.00015, loss_test:0.07287, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:90.510, tt:995.613\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:11, loss:0.00015, loss_test:0.07102, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:90.226, tt:1082.708\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:12, loss:0.00014, loss_test:0.07012, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:90.569, tt:1177.394\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:13, loss:0.00014, loss_test:0.07136, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:90.957, tt:1273.398\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:14, loss:0.00013, loss_test:0.06755, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:91.259, tt:1368.884\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:15, loss:0.00013, loss_test:0.06798, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:91.457, tt:1463.309\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:16, loss:0.00012, loss_test:0.07048, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:91.456, tt:1554.758\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:17, loss:0.00012, loss_test:0.06413, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:91.421, tt:1645.581\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:18, loss:0.00012, loss_test:0.06754, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:91.411, tt:1736.804\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:19, loss:0.00012, loss_test:0.06357, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:91.843, tt:1836.853\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:20, loss:0.00011, loss_test:0.06702, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:92.089, tt:1933.878\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:21, loss:0.00011, loss_test:0.06281, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:92.350, tt:2031.694\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:22, loss:0.00010, loss_test:0.06277, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:92.268, tt:2122.173\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:23, loss:0.00010, loss_test:0.06337, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:92.216, tt:2213.194\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:24, loss:0.00010, loss_test:0.05861, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:92.123, tt:2303.063\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:25, loss:0.00009, loss_test:0.06170, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:92.283, tt:2399.368\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:26, loss:0.00009, loss_test:0.06261, lr:1.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:92.480, tt:2496.961\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:27, loss:0.00009, loss_test:0.05718, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:92.522, tt:2590.630\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:28, loss:0.00009, loss_test:0.06269, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:92.726, tt:2689.062\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:29, loss:0.00009, loss_test:0.05662, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:92.577, tt:2777.313\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:30, loss:0.00008, loss_test:0.05980, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:92.473, tt:2866.657\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:31, loss:0.00008, loss_test:0.05542, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:92.351, tt:2955.228\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:32, loss:0.00008, loss_test:0.05903, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:92.485, tt:3051.992\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:33, loss:0.00007, loss_test:0.05503, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:92.663, tt:3150.539\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:34, loss:0.00007, loss_test:0.05731, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:92.846, tt:3249.623\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:35, loss:0.00007, loss_test:0.05503, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:93.032, tt:3349.140\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:36, loss:0.00007, loss_test:0.05607, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:92.955, tt:3439.327\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:37, loss:0.00007, loss_test:0.05470, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:92.881, tt:3529.485\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:38, loss:0.00006, loss_test:0.05555, lr:9.90e-03, fs:0.90640 (r=0.929,p=0.885),  time:92.847, tt:3621.046\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:39, loss:0.00006, loss_test:0.05270, lr:9.80e-03, fs:0.88995 (r=0.939,p=0.845),  time:93.026, tt:3721.036\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:40, loss:0.00006, loss_test:0.05454, lr:9.70e-03, fs:0.90732 (r=0.939,p=0.877),  time:93.084, tt:3816.431\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:41, loss:0.00006, loss_test:0.05211, lr:9.61e-03, fs:0.89100 (r=0.949,p=0.839),  time:93.149, tt:3912.240\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:42, loss:0.00006, loss_test:0.05393, lr:9.51e-03, fs:0.90640 (r=0.929,p=0.885),  time:93.147, tt:4005.315\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:43, loss:0.00006, loss_test:0.05096, lr:9.41e-03, fs:0.89100 (r=0.949,p=0.839),  time:93.058, tt:4094.571\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:44, loss:0.00006, loss_test:0.05379, lr:9.32e-03, fs:0.89756 (r=0.929,p=0.868),  time:92.953, tt:4182.870\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:45, loss:0.00005, loss_test:0.05227, lr:9.23e-03, fs:0.90385 (r=0.949,p=0.862),  time:92.865, tt:4271.802\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:46, loss:0.00005, loss_test:0.05296, lr:9.14e-03, fs:0.90196 (r=0.929,p=0.876),  time:92.980, tt:4370.078\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:47, loss:0.00005, loss_test:0.05026, lr:9.04e-03, fs:0.90909 (r=0.960,p=0.864),  time:93.075, tt:4467.582\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:48, loss:0.00005, loss_test:0.05351, lr:8.95e-03, fs:0.89756 (r=0.929,p=0.868),  time:93.162, tt:4564.939\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:49, loss:0.00005, loss_test:0.05011, lr:8.86e-03, fs:0.92233 (r=0.960,p=0.888),  time:93.111, tt:4655.560\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:50, loss:0.00005, loss_test:0.05170, lr:8.86e-03, fs:0.89423 (r=0.939,p=0.853),  time:93.047, tt:4745.386\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:51, loss:0.00005, loss_test:0.04995, lr:8.86e-03, fs:0.89623 (r=0.960,p=0.841),  time:92.930, tt:4832.385\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:52, loss:0.00005, loss_test:0.05328, lr:8.86e-03, fs:0.90099 (r=0.919,p=0.883),  time:92.884, tt:4922.864\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:53, loss:0.00005, loss_test:0.04854, lr:8.86e-03, fs:0.88372 (r=0.960,p=0.819),  time:93.002, tt:5022.114\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:54, loss:0.00005, loss_test:0.05325, lr:8.86e-03, fs:0.89655 (r=0.919,p=0.875),  time:93.038, tt:5117.081\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:55, loss:0.00004, loss_test:0.04834, lr:8.86e-03, fs:0.89202 (r=0.960,p=0.833),  time:93.113, tt:5214.319\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:56, loss:0.00004, loss_test:0.05297, lr:8.86e-03, fs:0.89216 (r=0.919,p=0.867),  time:93.054, tt:5304.103\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:57, loss:0.00004, loss_test:0.04880, lr:8.86e-03, fs:0.91346 (r=0.960,p=0.872),  time:93.014, tt:5394.821\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:58, loss:0.00004, loss_test:0.05197, lr:8.86e-03, fs:0.89320 (r=0.929,p=0.860),  time:92.946, tt:5483.824\n",
      "1080\n",
      "1040\n",
      "1040\n",
      "1045\n",
      "235\n",
      "Ep:59, loss:0.00004, loss_test:0.04988, lr:8.86e-03, fs:0.91787 (r=0.960,p=0.880),  time:92.766, tt:5565.942\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:0, loss:0.00045, loss_test:0.08551, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:82.896, tt:82.896\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:1, loss:0.00024, loss_test:0.08944, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:88.797, tt:177.594\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:2, loss:0.00022, loss_test:0.09037, lr:1.00e-02, fs:0.62105 (r=0.596,p=0.648),  time:91.845, tt:275.536\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:3, loss:0.00020, loss_test:0.08571, lr:1.00e-02, fs:0.65306 (r=0.646,p=0.660),  time:92.029, tt:368.117\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:4, loss:0.00020, loss_test:0.08483, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:91.445, tt:457.224\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:5, loss:0.00019, loss_test:0.08411, lr:1.00e-02, fs:0.66667 (r=0.646,p=0.688),  time:90.961, tt:545.763\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:6, loss:0.00018, loss_test:0.07924, lr:1.00e-02, fs:0.68966 (r=0.707,p=0.673),  time:92.059, tt:644.410\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:7, loss:0.00017, loss_test:0.08139, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:92.635, tt:741.084\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:8, loss:0.00016, loss_test:0.07685, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:93.308, tt:839.769\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:9, loss:0.00016, loss_test:0.07736, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:93.152, tt:931.518\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:10, loss:0.00015, loss_test:0.07726, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:93.038, tt:1023.421\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:11, loss:0.00015, loss_test:0.07416, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:92.951, tt:1115.415\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:12, loss:0.00014, loss_test:0.07429, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:93.198, tt:1211.572\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:13, loss:0.00014, loss_test:0.07241, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:93.666, tt:1311.330\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:14, loss:0.00013, loss_test:0.07172, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:93.821, tt:1407.322\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:15, loss:0.00013, loss_test:0.07208, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:94.140, tt:1506.234\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:16, loss:0.00012, loss_test:0.06986, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:93.873, tt:1595.833\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:17, loss:0.00012, loss_test:0.06947, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:93.608, tt:1684.941\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:18, loss:0.00012, loss_test:0.06841, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:93.325, tt:1773.181\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:19, loss:0.00011, loss_test:0.06777, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:93.375, tt:1867.500\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:20, loss:0.00011, loss_test:0.06663, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:93.558, tt:1964.720\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:21, loss:0.00011, loss_test:0.06589, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:93.699, tt:2061.388\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:22, loss:0.00010, loss_test:0.06658, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:94.022, tt:2162.511\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:23, loss:0.00010, loss_test:0.06513, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:93.868, tt:2252.828\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:24, loss:0.00010, loss_test:0.06424, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:93.754, tt:2343.849\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:25, loss:0.00009, loss_test:0.06560, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:93.790, tt:2438.542\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:26, loss:0.00009, loss_test:0.06324, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:94.052, tt:2539.401\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:27, loss:0.00009, loss_test:0.06342, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:94.178, tt:2636.979\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:28, loss:0.00008, loss_test:0.06332, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:94.357, tt:2736.355\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:29, loss:0.00008, loss_test:0.06133, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:94.444, tt:2833.320\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:30, loss:0.00008, loss_test:0.06259, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:94.321, tt:2923.942\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:31, loss:0.00008, loss_test:0.06133, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:94.223, tt:3015.147\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:32, loss:0.00008, loss_test:0.05990, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:94.112, tt:3105.703\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:33, loss:0.00007, loss_test:0.06235, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:94.393, tt:3209.369\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:34, loss:0.00007, loss_test:0.06070, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:94.549, tt:3309.212\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:35, loss:0.00007, loss_test:0.05777, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:94.721, tt:3409.964\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:36, loss:0.00007, loss_test:0.06010, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:94.804, tt:3507.748\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:37, loss:0.00007, loss_test:0.06092, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:94.758, tt:3600.811\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:38, loss:0.00006, loss_test:0.05670, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:94.731, tt:3694.525\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:39, loss:0.00006, loss_test:0.05755, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:94.740, tt:3789.595\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:40, loss:0.00006, loss_test:0.05955, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:94.838, tt:3888.371\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:41, loss:0.00006, loss_test:0.05543, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:94.897, tt:3985.654\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:42, loss:0.00006, loss_test:0.05762, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:94.951, tt:4082.882\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:43, loss:0.00005, loss_test:0.05621, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:94.874, tt:4174.455\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:44, loss:0.00005, loss_test:0.05635, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:94.806, tt:4266.260\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:45, loss:0.00005, loss_test:0.05553, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:94.708, tt:4356.576\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:46, loss:0.00005, loss_test:0.05474, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:94.786, tt:4454.959\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:47, loss:0.00005, loss_test:0.05639, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:94.888, tt:4554.614\n",
      "##########Best model found so far##########\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:48, loss:0.00005, loss_test:0.05693, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:94.951, tt:4652.619\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:49, loss:0.00005, loss_test:0.05386, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:95.046, tt:4752.275\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:50, loss:0.00005, loss_test:0.05417, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:94.937, tt:4841.779\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:51, loss:0.00004, loss_test:0.05413, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:94.888, tt:4934.183\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:52, loss:0.00004, loss_test:0.05263, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:94.789, tt:5023.834\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:53, loss:0.00004, loss_test:0.05493, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:94.818, tt:5120.170\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:54, loss:0.00004, loss_test:0.05254, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:94.899, tt:5219.440\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:55, loss:0.00004, loss_test:0.05208, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:94.944, tt:5316.859\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:56, loss:0.00004, loss_test:0.05438, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:94.889, tt:5408.694\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:57, loss:0.00004, loss_test:0.05132, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:94.850, tt:5501.290\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:58, loss:0.00004, loss_test:0.05310, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:94.775, tt:5591.701\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1025\n",
      "325\n",
      "Ep:59, loss:0.00004, loss_test:0.05270, lr:9.90e-03, fs:0.84103 (r=0.828,p=0.854),  time:94.506, tt:5670.364\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 32\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1040\n",
      "1025\n",
      "1055\n",
      "1025\n",
      "295\n",
      "Ep:0, loss:0.00044, loss_test:0.09736, lr:1.00e-02, fs:0.60000 (r=0.636,p=0.568),  time:86.726, tt:86.726\n",
      "##########Best model found so far##########\n",
      "1040\n",
      "1025\n",
      "1055\n",
      "1025\n",
      "295\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e897897f90e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_ran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"isolation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for CV out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;31m#         train_batch = shuffle_splits_ns(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m \u001b[0;31m#         np.random.shuffle(train_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;31m#         train_batch = np.array_split(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:0, loss:0.00030, loss_test:0.08850, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:38.671, tt:38.671\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:1, loss:0.00025, loss_test:0.08838, lr:1.00e-02, fs:0.64407 (r=0.768,p=0.555),  time:45.044, tt:90.089\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:2, loss:0.00021, loss_test:0.08902, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:49.211, tt:147.632\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:3, loss:0.00020, loss_test:0.08267, lr:1.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:51.675, tt:206.700\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:4, loss:0.00020, loss_test:0.08258, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:52.982, tt:264.911\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:5, loss:0.00019, loss_test:0.08133, lr:1.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:53.527, tt:321.163\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:6, loss:0.00018, loss_test:0.07506, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:54.044, tt:378.308\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:7, loss:0.00018, loss_test:0.07475, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:54.626, tt:437.004\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:8, loss:0.00017, loss_test:0.07470, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:55.037, tt:495.329\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:9, loss:0.00016, loss_test:0.07167, lr:1.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:55.314, tt:553.138\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:10, loss:0.00016, loss_test:0.07168, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:55.598, tt:611.580\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:11, loss:0.00015, loss_test:0.07073, lr:1.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:55.668, tt:668.012\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:12, loss:0.00015, loss_test:0.06899, lr:1.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:55.411, tt:720.338\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:13, loss:0.00015, loss_test:0.06972, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:55.245, tt:773.434\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:14, loss:0.00014, loss_test:0.06719, lr:1.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:55.017, tt:825.251\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:15, loss:0.00014, loss_test:0.06830, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:54.769, tt:876.311\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:16, loss:0.00013, loss_test:0.06621, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:54.822, tt:931.976\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:17, loss:0.00013, loss_test:0.06673, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:54.825, tt:986.844\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:18, loss:0.00013, loss_test:0.06575, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:54.698, tt:1039.271\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:19, loss:0.00012, loss_test:0.06469, lr:1.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:54.592, tt:1091.850\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:20, loss:0.00012, loss_test:0.06471, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:54.422, tt:1142.851\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:21, loss:0.00012, loss_test:0.06219, lr:1.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:54.339, tt:1195.448\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:22, loss:0.00011, loss_test:0.06425, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:54.111, tt:1244.547\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:23, loss:0.00011, loss_test:0.06100, lr:1.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:54.069, tt:1297.656\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:24, loss:0.00010, loss_test:0.06227, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:54.091, tt:1352.282\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:25, loss:0.00010, loss_test:0.06054, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:54.076, tt:1405.963\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:26, loss:0.00010, loss_test:0.06045, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:54.033, tt:1458.879\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:27, loss:0.00010, loss_test:0.05928, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:53.996, tt:1511.875\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:28, loss:0.00009, loss_test:0.05945, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:54.025, tt:1566.737\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:29, loss:0.00009, loss_test:0.05847, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:54.014, tt:1620.424\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:30, loss:0.00009, loss_test:0.05878, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:53.932, tt:1671.891\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:31, loss:0.00009, loss_test:0.05708, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:53.920, tt:1725.428\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:32, loss:0.00008, loss_test:0.05695, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:53.876, tt:1777.891\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:33, loss:0.00008, loss_test:0.05809, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:53.893, tt:1832.350\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:34, loss:0.00008, loss_test:0.05668, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:53.843, tt:1884.509\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:35, loss:0.00008, loss_test:0.05655, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:53.804, tt:1936.929\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:36, loss:0.00007, loss_test:0.05567, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:53.785, tt:1990.042\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:37, loss:0.00007, loss_test:0.05601, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:53.774, tt:2043.417\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:38, loss:0.00007, loss_test:0.05462, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:53.750, tt:2096.261\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:39, loss:0.00007, loss_test:0.05656, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:53.682, tt:2147.273\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:40, loss:0.00007, loss_test:0.05408, lr:1.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:53.634, tt:2198.987\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:41, loss:0.00006, loss_test:0.05587, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:53.643, tt:2253.002\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:42, loss:0.00006, loss_test:0.05385, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:53.607, tt:2305.081\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:43, loss:0.00006, loss_test:0.05494, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:53.583, tt:2357.657\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:44, loss:0.00006, loss_test:0.05456, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:53.564, tt:2410.390\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:45, loss:0.00006, loss_test:0.05365, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:53.585, tt:2464.908\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:46, loss:0.00006, loss_test:0.05487, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:53.642, tt:2521.191\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:47, loss:0.00005, loss_test:0.05280, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:53.675, tt:2576.383\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:48, loss:0.00005, loss_test:0.05410, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:53.657, tt:2629.210\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:49, loss:0.00005, loss_test:0.05434, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:53.653, tt:2682.672\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:50, loss:0.00005, loss_test:0.05428, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:53.662, tt:2736.740\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:51, loss:0.00005, loss_test:0.05311, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:53.674, tt:2791.044\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:52, loss:0.00005, loss_test:0.05491, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:53.676, tt:2844.807\n",
      "1029\n",
      "1035\n",
      "600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00005, loss_test:0.05206, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:53.681, tt:2898.791\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:54, loss:0.00004, loss_test:0.05348, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:53.655, tt:2950.999\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:55, loss:0.00004, loss_test:0.05287, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:53.690, tt:3006.630\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:56, loss:0.00004, loss_test:0.05315, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:53.708, tt:3061.373\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:57, loss:0.00004, loss_test:0.05403, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:53.729, tt:3116.256\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:58, loss:0.00004, loss_test:0.05168, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:53.758, tt:3171.740\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:59, loss:0.00004, loss_test:0.05368, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:53.737, tt:3224.243\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:60, loss:0.00004, loss_test:0.05310, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:53.732, tt:3277.639\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:61, loss:0.00004, loss_test:0.05234, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:53.766, tt:3333.503\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:62, loss:0.00004, loss_test:0.05270, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:53.808, tt:3389.882\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:63, loss:0.00004, loss_test:0.05295, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:53.779, tt:3441.854\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:64, loss:0.00003, loss_test:0.05181, lr:1.00e-02, fs:0.90047 (r=0.960,p=0.848),  time:53.781, tt:3495.769\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:65, loss:0.00003, loss_test:0.05292, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:53.803, tt:3551.010\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:66, loss:0.00003, loss_test:0.05247, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:53.849, tt:3607.861\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:67, loss:0.00003, loss_test:0.05299, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:53.839, tt:3661.084\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:68, loss:0.00003, loss_test:0.05253, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:53.842, tt:3715.096\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:69, loss:0.00003, loss_test:0.05238, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:53.844, tt:3769.075\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:70, loss:0.00003, loss_test:0.05181, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:53.861, tt:3824.115\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:71, loss:0.00003, loss_test:0.05387, lr:9.90e-03, fs:0.87879 (r=0.879,p=0.879),  time:53.850, tt:3877.214\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:72, loss:0.00003, loss_test:0.05110, lr:9.80e-03, fs:0.89623 (r=0.960,p=0.841),  time:53.857, tt:3931.597\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:73, loss:0.00003, loss_test:0.05290, lr:9.70e-03, fs:0.86154 (r=0.848,p=0.875),  time:53.864, tt:3985.972\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:74, loss:0.00003, loss_test:0.05169, lr:9.61e-03, fs:0.91346 (r=0.960,p=0.872),  time:53.874, tt:4040.572\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:75, loss:0.00003, loss_test:0.05196, lr:9.51e-03, fs:0.86294 (r=0.859,p=0.867),  time:53.863, tt:4093.621\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:76, loss:0.00003, loss_test:0.05280, lr:9.41e-03, fs:0.89000 (r=0.899,p=0.881),  time:53.899, tt:4150.216\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:77, loss:0.00003, loss_test:0.05179, lr:9.32e-03, fs:0.90821 (r=0.949,p=0.870),  time:53.906, tt:4204.663\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:78, loss:0.00003, loss_test:0.05322, lr:9.23e-03, fs:0.86010 (r=0.838,p=0.883),  time:53.891, tt:4257.422\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:79, loss:0.00003, loss_test:0.05257, lr:9.14e-03, fs:0.89552 (r=0.909,p=0.882),  time:53.872, tt:4309.798\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:80, loss:0.00003, loss_test:0.05335, lr:9.04e-03, fs:0.85128 (r=0.838,p=0.865),  time:53.851, tt:4361.893\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:81, loss:0.00003, loss_test:0.05246, lr:8.95e-03, fs:0.86294 (r=0.859,p=0.867),  time:53.852, tt:4415.844\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:82, loss:0.00002, loss_test:0.05380, lr:8.86e-03, fs:0.85128 (r=0.838,p=0.865),  time:53.844, tt:4469.088\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:83, loss:0.00002, loss_test:0.05125, lr:8.78e-03, fs:0.86000 (r=0.869,p=0.851),  time:53.842, tt:4522.722\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:84, loss:0.00002, loss_test:0.05296, lr:8.69e-03, fs:0.86154 (r=0.848,p=0.875),  time:53.819, tt:4574.619\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:85, loss:0.00002, loss_test:0.05299, lr:8.60e-03, fs:0.87047 (r=0.848,p=0.894),  time:53.800, tt:4626.810\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:86, loss:0.00002, loss_test:0.05176, lr:8.51e-03, fs:0.84694 (r=0.838,p=0.856),  time:53.797, tt:4680.372\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:87, loss:0.00002, loss_test:0.05323, lr:8.43e-03, fs:0.87047 (r=0.848,p=0.894),  time:53.791, tt:4733.636\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:88, loss:0.00002, loss_test:0.05101, lr:8.35e-03, fs:0.89855 (r=0.939,p=0.861),  time:53.794, tt:4787.661\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:89, loss:0.00002, loss_test:0.05233, lr:8.26e-03, fs:0.86735 (r=0.859,p=0.876),  time:53.787, tt:4840.866\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:90, loss:0.00002, loss_test:0.05304, lr:8.18e-03, fs:0.87047 (r=0.848,p=0.894),  time:53.784, tt:4894.317\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:91, loss:0.00002, loss_test:0.05160, lr:8.10e-03, fs:0.84694 (r=0.838,p=0.856),  time:53.751, tt:4945.088\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:92, loss:0.00002, loss_test:0.05248, lr:8.02e-03, fs:0.87047 (r=0.848,p=0.894),  time:53.747, tt:4998.443\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:93, loss:0.00002, loss_test:0.05302, lr:7.94e-03, fs:0.86458 (r=0.838,p=0.892),  time:53.736, tt:5051.182\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:94, loss:0.00002, loss_test:0.05178, lr:7.86e-03, fs:0.85714 (r=0.848,p=0.866),  time:53.757, tt:5106.889\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:95, loss:0.00002, loss_test:0.05194, lr:7.78e-03, fs:0.86154 (r=0.848,p=0.875),  time:53.784, tt:5163.276\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:96, loss:0.00002, loss_test:0.05166, lr:7.70e-03, fs:0.87000 (r=0.879,p=0.861),  time:53.783, tt:5216.999\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:97, loss:0.00002, loss_test:0.05250, lr:7.62e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.794, tt:5271.802\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:98, loss:0.00002, loss_test:0.05248, lr:7.55e-03, fs:0.86010 (r=0.838,p=0.883),  time:53.782, tt:5324.394\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:99, loss:0.00002, loss_test:0.05265, lr:7.47e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.788, tt:5378.789\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:100, loss:0.00002, loss_test:0.05181, lr:7.40e-03, fs:0.85714 (r=0.848,p=0.866),  time:53.803, tt:5434.116\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:101, loss:0.00002, loss_test:0.05190, lr:7.32e-03, fs:0.84694 (r=0.838,p=0.856),  time:53.802, tt:5487.755\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:102, loss:0.00002, loss_test:0.05266, lr:7.25e-03, fs:0.86458 (r=0.838,p=0.892),  time:53.793, tt:5540.711\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:103, loss:0.00002, loss_test:0.05182, lr:7.18e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.805, tt:5595.760\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:104, loss:0.00002, loss_test:0.05300, lr:7.11e-03, fs:0.86010 (r=0.838,p=0.883),  time:53.800, tt:5648.967\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:105, loss:0.00002, loss_test:0.05330, lr:7.03e-03, fs:0.86458 (r=0.838,p=0.892),  time:53.813, tt:5704.184\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:106, loss:0.00002, loss_test:0.05292, lr:6.96e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.814, tt:5758.106\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:107, loss:0.00002, loss_test:0.05287, lr:6.89e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.796, tt:5809.990\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:108, loss:0.00002, loss_test:0.05311, lr:6.83e-03, fs:0.86010 (r=0.838,p=0.883),  time:53.820, tt:5866.333\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:109, loss:0.00002, loss_test:0.05311, lr:6.76e-03, fs:0.86010 (r=0.838,p=0.883),  time:53.814, tt:5919.577\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:110, loss:0.00002, loss_test:0.05264, lr:6.69e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.830, tt:5975.100\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:111, loss:0.00002, loss_test:0.05349, lr:6.62e-03, fs:0.86458 (r=0.838,p=0.892),  time:53.841, tt:6030.166\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:112, loss:0.00002, loss_test:0.05266, lr:6.56e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.817, tt:6081.272\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:113, loss:0.00002, loss_test:0.05256, lr:6.49e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.791, tt:6132.211\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:114, loss:0.00002, loss_test:0.05310, lr:6.43e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.773, tt:6183.943\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:115, loss:0.00001, loss_test:0.05249, lr:6.36e-03, fs:0.85128 (r=0.838,p=0.865),  time:53.767, tt:6236.931\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:116, loss:0.00002, loss_test:0.05269, lr:6.30e-03, fs:0.86458 (r=0.838,p=0.892),  time:53.754, tt:6289.219\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:117, loss:0.00001, loss_test:0.05306, lr:6.24e-03, fs:0.86010 (r=0.838,p=0.883),  time:53.748, tt:6342.275\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:118, loss:0.00002, loss_test:0.05229, lr:6.17e-03, fs:0.85128 (r=0.838,p=0.865),  time:53.720, tt:6392.711\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:119, loss:0.00001, loss_test:0.05305, lr:6.11e-03, fs:0.85567 (r=0.838,p=0.874),  time:53.643, tt:6437.127\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:0, loss:0.00030, loss_test:0.08301, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:42.722, tt:42.722\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:1, loss:0.00024, loss_test:0.08591, lr:1.00e-02, fs:0.65455 (r=0.727,p=0.595),  time:42.156, tt:84.312\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:2, loss:0.00021, loss_test:0.08772, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:44.809, tt:134.428\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:3, loss:0.00021, loss_test:0.07872, lr:1.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:46.669, tt:186.678\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:4, loss:0.00020, loss_test:0.08322, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:47.758, tt:238.789\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:5, loss:0.00019, loss_test:0.08111, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:48.291, tt:289.747\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:6, loss:0.00018, loss_test:0.07419, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:49.088, tt:343.613\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:7, loss:0.00017, loss_test:0.07513, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:49.367, tt:394.938\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:8, loss:0.00017, loss_test:0.07233, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:49.691, tt:447.223\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:9, loss:0.00016, loss_test:0.07123, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:49.921, tt:499.213\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:10, loss:0.00016, loss_test:0.07199, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:50.001, tt:550.010\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:11, loss:0.00015, loss_test:0.06901, lr:1.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:50.119, tt:601.433\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:12, loss:0.00015, loss_test:0.06796, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:50.472, tt:656.139\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:13, loss:0.00015, loss_test:0.06719, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:50.684, tt:709.573\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:14, loss:0.00014, loss_test:0.06618, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:50.651, tt:759.765\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:15, loss:0.00014, loss_test:0.06506, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:50.705, tt:811.283\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:16, loss:0.00014, loss_test:0.06340, lr:1.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:50.836, tt:864.215\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:17, loss:0.00013, loss_test:0.06396, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:50.953, tt:917.156\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:18, loss:0.00013, loss_test:0.06210, lr:1.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:51.145, tt:971.748\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:19, loss:0.00012, loss_test:0.06232, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:51.241, tt:1024.822\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:20, loss:0.00012, loss_test:0.06144, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:51.343, tt:1078.207\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:21, loss:0.00012, loss_test:0.06065, lr:1.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:51.557, tt:1134.255\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:22, loss:0.00012, loss_test:0.06067, lr:1.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:51.790, tt:1191.172\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:23, loss:0.00011, loss_test:0.06017, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:52.037, tt:1248.898\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:24, loss:0.00011, loss_test:0.05928, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:52.233, tt:1305.828\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:25, loss:0.00011, loss_test:0.05893, lr:1.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:52.541, tt:1366.055\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:26, loss:0.00010, loss_test:0.05744, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:52.706, tt:1423.058\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:27, loss:0.00010, loss_test:0.05728, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:52.693, tt:1475.401\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:28, loss:0.00010, loss_test:0.05646, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:52.683, tt:1527.819\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:29, loss:0.00009, loss_test:0.05458, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:52.649, tt:1579.475\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:30, loss:0.00009, loss_test:0.05649, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:52.694, tt:1633.518\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:31, loss:0.00009, loss_test:0.05406, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:52.835, tt:1690.725\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:32, loss:0.00009, loss_test:0.05537, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:52.963, tt:1747.775\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:33, loss:0.00008, loss_test:0.05419, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:53.140, tt:1806.770\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:34, loss:0.00008, loss_test:0.05395, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:53.231, tt:1863.094\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:35, loss:0.00008, loss_test:0.05373, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:53.368, tt:1921.233\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:36, loss:0.00008, loss_test:0.05355, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:53.408, tt:1976.096\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:37, loss:0.00008, loss_test:0.05360, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:53.378, tt:2028.355\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:38, loss:0.00007, loss_test:0.05338, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:53.280, tt:2077.930\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:39, loss:0.00007, loss_test:0.05272, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:53.271, tt:2130.853\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:40, loss:0.00007, loss_test:0.05177, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:53.251, tt:2183.276\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:41, loss:0.00007, loss_test:0.05290, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:53.369, tt:2241.515\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:42, loss:0.00007, loss_test:0.05039, lr:9.90e-03, fs:0.82243 (r=0.889,p=0.765),  time:53.530, tt:2301.802\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:43, loss:0.00006, loss_test:0.05157, lr:9.80e-03, fs:0.83902 (r=0.869,p=0.811),  time:53.639, tt:2360.133\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:44, loss:0.00006, loss_test:0.05006, lr:9.70e-03, fs:0.83254 (r=0.879,p=0.791),  time:53.732, tt:2417.941\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:45, loss:0.00006, loss_test:0.05062, lr:9.61e-03, fs:0.84729 (r=0.869,p=0.827),  time:53.803, tt:2474.935\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:46, loss:0.00006, loss_test:0.04966, lr:9.61e-03, fs:0.82692 (r=0.869,p=0.789),  time:53.856, tt:2531.248\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:47, loss:0.00006, loss_test:0.04976, lr:9.61e-03, fs:0.84314 (r=0.869,p=0.819),  time:53.822, tt:2583.451\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:48, loss:0.00006, loss_test:0.04890, lr:9.61e-03, fs:0.83495 (r=0.869,p=0.804),  time:53.791, tt:2635.756\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:49, loss:0.00005, loss_test:0.04983, lr:9.61e-03, fs:0.85572 (r=0.869,p=0.843),  time:53.749, tt:2687.467\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:50, loss:0.00005, loss_test:0.04811, lr:9.61e-03, fs:0.83254 (r=0.879,p=0.791),  time:53.725, tt:2739.994\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:51, loss:0.00005, loss_test:0.04934, lr:9.61e-03, fs:0.85572 (r=0.869,p=0.843),  time:53.743, tt:2794.647\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:52, loss:0.00005, loss_test:0.04825, lr:9.61e-03, fs:0.83902 (r=0.869,p=0.811),  time:53.817, tt:2852.323\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:53, loss:0.00005, loss_test:0.04801, lr:9.61e-03, fs:0.84729 (r=0.869,p=0.827),  time:53.912, tt:2911.270\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:54, loss:0.00005, loss_test:0.04854, lr:9.61e-03, fs:0.85149 (r=0.869,p=0.835),  time:53.974, tt:2968.575\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:55, loss:0.00005, loss_test:0.04829, lr:9.61e-03, fs:0.85572 (r=0.869,p=0.843),  time:54.052, tt:3026.930\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:56, loss:0.00005, loss_test:0.04715, lr:9.61e-03, fs:0.84878 (r=0.879,p=0.821),  time:54.068, tt:3081.877\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:57, loss:0.00004, loss_test:0.04776, lr:9.61e-03, fs:0.86000 (r=0.869,p=0.851),  time:54.080, tt:3136.668\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00004, loss_test:0.04697, lr:9.61e-03, fs:0.84878 (r=0.879,p=0.821),  time:54.054, tt:3189.187\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:59, loss:0.00004, loss_test:0.04698, lr:9.61e-03, fs:0.85854 (r=0.889,p=0.830),  time:54.050, tt:3243.027\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:60, loss:0.00004, loss_test:0.04788, lr:9.61e-03, fs:0.87437 (r=0.879,p=0.870),  time:54.015, tt:3294.927\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:61, loss:0.00004, loss_test:0.04575, lr:9.61e-03, fs:0.84878 (r=0.879,p=0.821),  time:54.064, tt:3351.992\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:62, loss:0.00004, loss_test:0.04800, lr:9.61e-03, fs:0.86869 (r=0.869,p=0.869),  time:54.125, tt:3409.903\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:63, loss:0.00004, loss_test:0.04561, lr:9.61e-03, fs:0.84466 (r=0.879,p=0.813),  time:54.183, tt:3467.690\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:64, loss:0.00004, loss_test:0.04752, lr:9.61e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.239, tt:3525.557\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:65, loss:0.00004, loss_test:0.04625, lr:9.61e-03, fs:0.87437 (r=0.879,p=0.870),  time:54.291, tt:3583.174\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:66, loss:0.00004, loss_test:0.04495, lr:9.61e-03, fs:0.86275 (r=0.889,p=0.838),  time:54.308, tt:3638.616\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:67, loss:0.00004, loss_test:0.04772, lr:9.61e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.282, tt:3691.183\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:68, loss:0.00003, loss_test:0.04521, lr:9.61e-03, fs:0.85714 (r=0.879,p=0.837),  time:54.245, tt:3742.878\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:69, loss:0.00003, loss_test:0.04677, lr:9.61e-03, fs:0.87000 (r=0.879,p=0.861),  time:54.230, tt:3796.080\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:70, loss:0.00003, loss_test:0.04560, lr:9.61e-03, fs:0.87000 (r=0.879,p=0.861),  time:54.207, tt:3848.664\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:71, loss:0.00003, loss_test:0.04721, lr:9.61e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.252, tt:3906.123\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:72, loss:0.00003, loss_test:0.04522, lr:9.61e-03, fs:0.86567 (r=0.879,p=0.853),  time:54.312, tt:3964.754\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:73, loss:0.00003, loss_test:0.04524, lr:9.61e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.363, tt:4022.841\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:74, loss:0.00003, loss_test:0.04557, lr:9.61e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.437, tt:4082.788\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:75, loss:0.00003, loss_test:0.04427, lr:9.61e-03, fs:0.87129 (r=0.889,p=0.854),  time:54.476, tt:4140.143\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:76, loss:0.00003, loss_test:0.04747, lr:9.51e-03, fs:0.89691 (r=0.879,p=0.916),  time:54.509, tt:4197.218\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:77, loss:0.00003, loss_test:0.04380, lr:9.51e-03, fs:0.86700 (r=0.889,p=0.846),  time:54.499, tt:4250.921\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:78, loss:0.00003, loss_test:0.04573, lr:9.51e-03, fs:0.88083 (r=0.859,p=0.904),  time:54.498, tt:4305.358\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:79, loss:0.00003, loss_test:0.04473, lr:9.51e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.465, tt:4357.220\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:80, loss:0.00003, loss_test:0.04411, lr:9.51e-03, fs:0.88442 (r=0.889,p=0.880),  time:54.440, tt:4409.635\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:81, loss:0.00003, loss_test:0.04463, lr:9.51e-03, fs:0.88325 (r=0.879,p=0.888),  time:54.492, tt:4468.330\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:82, loss:0.00003, loss_test:0.04517, lr:9.51e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.538, tt:4526.678\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:83, loss:0.00002, loss_test:0.04437, lr:9.51e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.589, tt:4585.495\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:84, loss:0.00002, loss_test:0.04423, lr:9.51e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.640, tt:4644.365\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:85, loss:0.00002, loss_test:0.04510, lr:9.51e-03, fs:0.88325 (r=0.879,p=0.888),  time:54.669, tt:4701.512\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:86, loss:0.00002, loss_test:0.04451, lr:9.51e-03, fs:0.89231 (r=0.879,p=0.906),  time:54.698, tt:4758.696\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:87, loss:0.00002, loss_test:0.04432, lr:9.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:54.659, tt:4810.012\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:88, loss:0.00002, loss_test:0.04376, lr:9.41e-03, fs:0.87879 (r=0.879,p=0.879),  time:54.645, tt:4863.375\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:89, loss:0.00002, loss_test:0.04429, lr:9.32e-03, fs:0.88325 (r=0.879,p=0.888),  time:54.621, tt:4915.858\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:90, loss:0.00002, loss_test:0.04443, lr:9.23e-03, fs:0.89691 (r=0.879,p=0.916),  time:54.603, tt:4968.840\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:91, loss:0.00002, loss_test:0.04392, lr:9.14e-03, fs:0.87437 (r=0.879,p=0.870),  time:54.660, tt:5028.716\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:92, loss:0.00002, loss_test:0.04520, lr:9.04e-03, fs:0.89231 (r=0.879,p=0.906),  time:54.719, tt:5088.895\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:93, loss:0.00002, loss_test:0.04389, lr:8.95e-03, fs:0.88325 (r=0.879,p=0.888),  time:54.747, tt:5146.218\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:94, loss:0.00002, loss_test:0.04390, lr:8.86e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.786, tt:5204.625\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:95, loss:0.00002, loss_test:0.04395, lr:8.78e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.819, tt:5262.608\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:96, loss:0.00002, loss_test:0.04458, lr:8.69e-03, fs:0.89231 (r=0.879,p=0.906),  time:54.810, tt:5316.559\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:97, loss:0.00002, loss_test:0.04407, lr:8.60e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.800, tt:5370.409\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:98, loss:0.00002, loss_test:0.04403, lr:8.51e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.803, tt:5425.509\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:99, loss:0.00002, loss_test:0.04429, lr:8.43e-03, fs:0.89231 (r=0.879,p=0.906),  time:54.801, tt:5480.136\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:101, loss:0.00002, loss_test:0.04437, lr:8.26e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.866, tt:5596.289\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:102, loss:0.00002, loss_test:0.04431, lr:8.18e-03, fs:0.89796 (r=0.889,p=0.907),  time:54.904, tt:5655.073\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:103, loss:0.00002, loss_test:0.04366, lr:8.18e-03, fs:0.88325 (r=0.879,p=0.888),  time:54.939, tt:5713.612\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:104, loss:0.00002, loss_test:0.04433, lr:8.18e-03, fs:0.88776 (r=0.879,p=0.897),  time:54.972, tt:5772.042\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:105, loss:0.00002, loss_test:0.04409, lr:8.18e-03, fs:0.90155 (r=0.879,p=0.926),  time:55.003, tt:5830.345\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:106, loss:0.00002, loss_test:0.04300, lr:8.18e-03, fs:0.89340 (r=0.889,p=0.898),  time:55.021, tt:5887.256\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:107, loss:0.00002, loss_test:0.04479, lr:8.18e-03, fs:0.89691 (r=0.879,p=0.916),  time:55.020, tt:5942.114\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:108, loss:0.00002, loss_test:0.04214, lr:8.18e-03, fs:0.88000 (r=0.889,p=0.871),  time:55.029, tt:5998.130\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:109, loss:0.00002, loss_test:0.04436, lr:8.18e-03, fs:0.89691 (r=0.879,p=0.916),  time:55.004, tt:6050.452\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:110, loss:0.00002, loss_test:0.04361, lr:8.18e-03, fs:0.89231 (r=0.879,p=0.906),  time:54.980, tt:6102.791\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:111, loss:0.00002, loss_test:0.04364, lr:8.18e-03, fs:0.89231 (r=0.879,p=0.906),  time:55.018, tt:6161.966\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:112, loss:0.00002, loss_test:0.04356, lr:8.18e-03, fs:0.89231 (r=0.879,p=0.906),  time:55.055, tt:6221.224\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:113, loss:0.00002, loss_test:0.04318, lr:8.18e-03, fs:0.88776 (r=0.879,p=0.897),  time:55.105, tt:6281.980\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:114, loss:0.00002, loss_test:0.04465, lr:8.18e-03, fs:0.90155 (r=0.879,p=0.926),  time:55.133, tt:6340.331\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:115, loss:0.00002, loss_test:0.04321, lr:8.18e-03, fs:0.89231 (r=0.879,p=0.906),  time:55.165, tt:6399.171\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:116, loss:0.00001, loss_test:0.04385, lr:8.18e-03, fs:0.88776 (r=0.879,p=0.897),  time:55.179, tt:6455.939\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:117, loss:0.00001, loss_test:0.04423, lr:8.10e-03, fs:0.89231 (r=0.879,p=0.906),  time:55.172, tt:6510.344\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:118, loss:0.00001, loss_test:0.04356, lr:8.02e-03, fs:0.89691 (r=0.879,p=0.916),  time:55.163, tt:6564.379\n",
      "1029\n",
      "1035\n",
      "600\n",
      "Ep:119, loss:0.00001, loss_test:0.04461, lr:7.94e-03, fs:0.89691 (r=0.879,p=0.916),  time:55.114, tt:6613.659\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 32\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n",
      "1041\n",
      "588\n",
      "Ep:0, loss:0.00030, loss_test:0.09264, lr:1.00e-02, fs:0.63668 (r=0.929,p=0.484),  time:58.289, tt:58.289\n",
      "##########Best model found so far##########\n",
      "1035\n",
      "1041\n",
      "588\n",
      "Ep:1, loss:0.00024, loss_test:0.09789, lr:1.00e-02, fs:0.61818 (r=0.687,p=0.562),  time:52.615, tt:105.231\n",
      "1035\n",
      "1041\n",
      "588\n",
      "Ep:2, loss:0.00020, loss_test:0.10228, lr:1.00e-02, fs:0.60952 (r=0.646,p=0.577),  time:53.547, tt:160.642\n",
      "1035\n",
      "1041\n",
      "588\n",
      "Ep:3, loss:0.00020, loss_test:0.08987, lr:1.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:54.717, tt:218.867\n",
      "##########Best model found so far##########\n",
      "1035\n",
      "1041\n",
      "588\n",
      "Ep:4, loss:0.00020, loss_test:0.09585, lr:1.00e-02, fs:0.62264 (r=0.667,p=0.584),  time:55.221, tt:276.106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9884dd7af360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m## create batchs and shuffle data for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_splits_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;31m#         train_batch = shuffle_splits_ns(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mshuffle_splits_ns\u001b[0;34m(train_mask, n, ns)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mfilter_node_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_pos\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mns_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_node_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0mfilter_node_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_neg\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_node_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mpartial_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_node_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mfilter_node_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_pos\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mns_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_node_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0mfilter_node_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_neg\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_node_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mpartial_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_node_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00018, loss_test:0.09144, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:9.603, tt:9.603\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00018, loss_test:0.09027, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:9.527, tt:19.054\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00018, loss_test:0.08840, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:9.418, tt:28.255\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00017, loss_test:0.08602, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:9.389, tt:37.556\n",
      "Ep:4, loss:0.00016, loss_test:0.08406, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:9.373, tt:46.865\n",
      "Ep:5, loss:0.00016, loss_test:0.08277, lr:1.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:9.389, tt:56.337\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00016, loss_test:0.08134, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:9.406, tt:65.845\n",
      "Ep:7, loss:0.00015, loss_test:0.07922, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:9.390, tt:75.121\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00015, loss_test:0.07793, lr:1.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:9.389, tt:84.498\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00015, loss_test:0.07724, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:9.373, tt:93.727\n",
      "Ep:10, loss:0.00014, loss_test:0.07570, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:9.386, tt:103.243\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00014, loss_test:0.07467, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:9.403, tt:112.835\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00014, loss_test:0.07370, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:9.423, tt:122.497\n",
      "Ep:13, loss:0.00013, loss_test:0.07252, lr:1.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:9.433, tt:132.065\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00013, loss_test:0.07134, lr:1.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:9.439, tt:141.578\n",
      "Ep:15, loss:0.00013, loss_test:0.07018, lr:1.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:9.452, tt:151.240\n",
      "Ep:16, loss:0.00013, loss_test:0.06912, lr:1.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:9.456, tt:160.759\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00012, loss_test:0.06853, lr:1.00e-02, fs:0.71815 (r=0.939,p=0.581),  time:9.466, tt:170.396\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00012, loss_test:0.06831, lr:1.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:9.467, tt:179.881\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.06774, lr:1.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:9.474, tt:189.484\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.06685, lr:1.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:9.481, tt:199.098\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00011, loss_test:0.06608, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:9.487, tt:208.712\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00011, loss_test:0.06548, lr:1.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:9.492, tt:218.313\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.06500, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:9.493, tt:227.827\n",
      "Ep:24, loss:0.00011, loss_test:0.06465, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:9.495, tt:237.374\n",
      "Ep:25, loss:0.00010, loss_test:0.06425, lr:1.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:9.503, tt:247.069\n",
      "Ep:26, loss:0.00010, loss_test:0.06378, lr:1.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:9.504, tt:256.607\n",
      "Ep:27, loss:0.00010, loss_test:0.06331, lr:1.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:9.509, tt:266.258\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.06299, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:9.510, tt:275.780\n",
      "Ep:29, loss:0.00010, loss_test:0.06270, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:9.511, tt:285.341\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.06273, lr:1.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:9.513, tt:294.894\n",
      "Ep:31, loss:0.00009, loss_test:0.06242, lr:1.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:9.517, tt:304.559\n",
      "Ep:32, loss:0.00009, loss_test:0.06230, lr:1.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:9.521, tt:314.199\n",
      "Ep:33, loss:0.00009, loss_test:0.06221, lr:1.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:9.524, tt:323.821\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.06167, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:9.528, tt:333.484\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06119, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:9.529, tt:343.029\n",
      "Ep:36, loss:0.00008, loss_test:0.06121, lr:1.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:9.531, tt:352.664\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.06066, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:9.549, tt:362.877\n",
      "Ep:38, loss:0.00008, loss_test:0.06038, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:9.551, tt:372.485\n",
      "Ep:39, loss:0.00008, loss_test:0.06075, lr:1.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:9.549, tt:381.978\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.06009, lr:1.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:9.550, tt:391.565\n",
      "Ep:41, loss:0.00008, loss_test:0.05972, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:9.550, tt:401.117\n",
      "Ep:42, loss:0.00008, loss_test:0.05972, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:9.554, tt:410.807\n",
      "Ep:43, loss:0.00008, loss_test:0.05958, lr:1.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:9.556, tt:420.448\n",
      "Ep:44, loss:0.00007, loss_test:0.05911, lr:1.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:9.558, tt:430.115\n",
      "Ep:45, loss:0.00007, loss_test:0.05913, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:9.558, tt:439.653\n",
      "Ep:46, loss:0.00007, loss_test:0.05902, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:9.557, tt:449.159\n",
      "Ep:47, loss:0.00007, loss_test:0.05852, lr:1.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:9.557, tt:458.747\n",
      "Ep:48, loss:0.00007, loss_test:0.05907, lr:1.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:9.559, tt:468.383\n",
      "Ep:49, loss:0.00007, loss_test:0.05854, lr:1.00e-02, fs:0.77119 (r=0.919,p=0.664),  time:9.560, tt:478.021\n",
      "Ep:50, loss:0.00007, loss_test:0.05809, lr:1.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:9.562, tt:487.638\n",
      "Ep:51, loss:0.00007, loss_test:0.05850, lr:9.90e-03, fs:0.78112 (r=0.919,p=0.679),  time:9.559, tt:497.074\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.05847, lr:9.90e-03, fs:0.77778 (r=0.919,p=0.674),  time:9.562, tt:506.807\n",
      "Ep:53, loss:0.00006, loss_test:0.05766, lr:9.90e-03, fs:0.76151 (r=0.919,p=0.650),  time:9.564, tt:516.456\n",
      "Ep:54, loss:0.00006, loss_test:0.05817, lr:9.90e-03, fs:0.77922 (r=0.909,p=0.682),  time:9.565, tt:526.065\n",
      "Ep:55, loss:0.00006, loss_test:0.05799, lr:9.90e-03, fs:0.78261 (r=0.909,p=0.687),  time:9.566, tt:535.677\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.05754, lr:9.90e-03, fs:0.76271 (r=0.909,p=0.657),  time:9.564, tt:545.134\n",
      "Ep:57, loss:0.00006, loss_test:0.05825, lr:9.90e-03, fs:0.78414 (r=0.899,p=0.695),  time:9.563, tt:554.664\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.05768, lr:9.90e-03, fs:0.77391 (r=0.899,p=0.679),  time:9.563, tt:564.233\n",
      "Ep:59, loss:0.00006, loss_test:0.05774, lr:9.90e-03, fs:0.77391 (r=0.899,p=0.679),  time:9.564, tt:573.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00006, loss_test:0.05795, lr:9.90e-03, fs:0.78414 (r=0.899,p=0.695),  time:9.565, tt:583.451\n",
      "Ep:61, loss:0.00006, loss_test:0.05785, lr:9.90e-03, fs:0.77729 (r=0.899,p=0.685),  time:9.565, tt:593.017\n",
      "Ep:62, loss:0.00006, loss_test:0.05831, lr:9.90e-03, fs:0.79821 (r=0.899,p=0.718),  time:9.564, tt:602.544\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.05778, lr:9.90e-03, fs:0.77056 (r=0.899,p=0.674),  time:9.565, tt:612.142\n",
      "Ep:64, loss:0.00005, loss_test:0.05804, lr:9.90e-03, fs:0.79111 (r=0.899,p=0.706),  time:9.566, tt:621.790\n",
      "Ep:65, loss:0.00005, loss_test:0.05802, lr:9.90e-03, fs:0.78414 (r=0.899,p=0.695),  time:9.568, tt:631.482\n",
      "Ep:66, loss:0.00005, loss_test:0.05846, lr:9.90e-03, fs:0.79464 (r=0.899,p=0.712),  time:9.568, tt:641.082\n",
      "Ep:67, loss:0.00005, loss_test:0.05869, lr:9.90e-03, fs:0.78733 (r=0.879,p=0.713),  time:9.568, tt:650.623\n",
      "Ep:68, loss:0.00005, loss_test:0.05772, lr:9.90e-03, fs:0.77729 (r=0.899,p=0.685),  time:9.569, tt:660.285\n",
      "Ep:69, loss:0.00005, loss_test:0.05887, lr:9.90e-03, fs:0.78539 (r=0.869,p=0.717),  time:9.569, tt:669.854\n",
      "Ep:70, loss:0.00005, loss_test:0.05911, lr:9.90e-03, fs:0.78899 (r=0.869,p=0.723),  time:9.569, tt:679.415\n",
      "Ep:71, loss:0.00005, loss_test:0.05760, lr:9.90e-03, fs:0.76522 (r=0.889,p=0.672),  time:9.571, tt:689.147\n",
      "Ep:72, loss:0.00005, loss_test:0.05925, lr:9.90e-03, fs:0.78704 (r=0.859,p=0.726),  time:9.571, tt:698.667\n",
      "Ep:73, loss:0.00005, loss_test:0.05845, lr:9.90e-03, fs:0.77828 (r=0.869,p=0.705),  time:9.572, tt:708.332\n",
      "Ep:74, loss:0.00005, loss_test:0.05836, lr:9.80e-03, fs:0.76786 (r=0.869,p=0.688),  time:9.573, tt:717.956\n",
      "Ep:75, loss:0.00005, loss_test:0.05958, lr:9.70e-03, fs:0.78704 (r=0.859,p=0.726),  time:9.573, tt:727.577\n",
      "Ep:76, loss:0.00004, loss_test:0.05874, lr:9.61e-03, fs:0.76786 (r=0.869,p=0.688),  time:9.573, tt:737.129\n",
      "Ep:77, loss:0.00004, loss_test:0.05961, lr:9.51e-03, fs:0.78341 (r=0.859,p=0.720),  time:9.574, tt:746.793\n",
      "Ep:78, loss:0.00004, loss_test:0.05957, lr:9.41e-03, fs:0.77570 (r=0.838,p=0.722),  time:9.575, tt:756.401\n",
      "Ep:79, loss:0.00004, loss_test:0.05894, lr:9.32e-03, fs:0.76577 (r=0.859,p=0.691),  time:9.575, tt:765.986\n",
      "Ep:80, loss:0.00004, loss_test:0.05939, lr:9.23e-03, fs:0.78140 (r=0.848,p=0.724),  time:9.577, tt:775.702\n",
      "Ep:81, loss:0.00004, loss_test:0.05900, lr:9.14e-03, fs:0.77064 (r=0.848,p=0.706),  time:9.577, tt:785.326\n",
      "Ep:82, loss:0.00004, loss_test:0.05976, lr:9.04e-03, fs:0.76636 (r=0.828,p=0.713),  time:9.576, tt:794.844\n",
      "Ep:83, loss:0.00004, loss_test:0.05957, lr:8.95e-03, fs:0.76636 (r=0.828,p=0.713),  time:9.577, tt:804.443\n",
      "Ep:84, loss:0.00004, loss_test:0.05855, lr:8.86e-03, fs:0.77477 (r=0.869,p=0.699),  time:9.577, tt:814.069\n",
      "Ep:85, loss:0.00004, loss_test:0.06003, lr:8.78e-03, fs:0.77725 (r=0.828,p=0.732),  time:9.578, tt:823.713\n",
      "Ep:86, loss:0.00004, loss_test:0.05945, lr:8.69e-03, fs:0.76636 (r=0.828,p=0.713),  time:9.577, tt:833.194\n",
      "Ep:87, loss:0.00004, loss_test:0.05894, lr:8.60e-03, fs:0.76498 (r=0.838,p=0.703),  time:9.577, tt:842.753\n",
      "Ep:88, loss:0.00004, loss_test:0.05996, lr:8.51e-03, fs:0.77725 (r=0.828,p=0.732),  time:9.578, tt:852.410\n",
      "Ep:89, loss:0.00004, loss_test:0.05926, lr:8.43e-03, fs:0.75926 (r=0.828,p=0.701),  time:9.577, tt:861.944\n",
      "Ep:90, loss:0.00004, loss_test:0.05982, lr:8.35e-03, fs:0.76995 (r=0.828,p=0.719),  time:9.578, tt:871.615\n",
      "Ep:91, loss:0.00004, loss_test:0.05982, lr:8.26e-03, fs:0.76636 (r=0.828,p=0.713),  time:9.579, tt:881.299\n",
      "Ep:92, loss:0.00004, loss_test:0.05944, lr:8.18e-03, fs:0.76636 (r=0.828,p=0.713),  time:9.579, tt:890.880\n",
      "Ep:93, loss:0.00004, loss_test:0.06072, lr:8.10e-03, fs:0.78469 (r=0.828,p=0.745),  time:9.581, tt:900.598\n",
      "Ep:94, loss:0.00003, loss_test:0.05959, lr:8.02e-03, fs:0.76636 (r=0.828,p=0.713),  time:9.581, tt:910.198\n",
      "Ep:95, loss:0.00003, loss_test:0.05960, lr:7.94e-03, fs:0.76995 (r=0.828,p=0.719),  time:9.581, tt:919.822\n",
      "Ep:96, loss:0.00003, loss_test:0.06027, lr:7.86e-03, fs:0.78095 (r=0.828,p=0.739),  time:9.582, tt:929.410\n",
      "Ep:97, loss:0.00003, loss_test:0.06022, lr:7.78e-03, fs:0.77358 (r=0.828,p=0.726),  time:9.582, tt:939.038\n",
      "Ep:98, loss:0.00003, loss_test:0.06037, lr:7.70e-03, fs:0.77358 (r=0.828,p=0.726),  time:9.582, tt:948.608\n",
      "Ep:99, loss:0.00003, loss_test:0.05984, lr:7.62e-03, fs:0.78095 (r=0.828,p=0.739),  time:9.583, tt:958.330\n",
      "Ep:100, loss:0.00003, loss_test:0.06025, lr:7.55e-03, fs:0.77358 (r=0.828,p=0.726),  time:9.584, tt:968.013\n",
      "Ep:101, loss:0.00003, loss_test:0.06067, lr:7.47e-03, fs:0.77725 (r=0.828,p=0.732),  time:9.585, tt:977.658\n",
      "Ep:102, loss:0.00003, loss_test:0.05993, lr:7.40e-03, fs:0.76995 (r=0.828,p=0.719),  time:9.585, tt:987.281\n",
      "Ep:103, loss:0.00003, loss_test:0.06064, lr:7.32e-03, fs:0.77725 (r=0.828,p=0.732),  time:9.585, tt:996.883\n",
      "Ep:104, loss:0.00003, loss_test:0.05977, lr:7.25e-03, fs:0.76995 (r=0.828,p=0.719),  time:9.585, tt:1006.460\n",
      "Ep:105, loss:0.00003, loss_test:0.06092, lr:7.18e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.586, tt:1016.120\n",
      "Ep:106, loss:0.00003, loss_test:0.06097, lr:7.11e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.587, tt:1025.779\n",
      "Ep:107, loss:0.00003, loss_test:0.05977, lr:7.03e-03, fs:0.76995 (r=0.828,p=0.719),  time:9.586, tt:1035.297\n",
      "Ep:108, loss:0.00003, loss_test:0.06088, lr:6.96e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1044.866\n",
      "Ep:109, loss:0.00003, loss_test:0.06035, lr:6.89e-03, fs:0.77725 (r=0.828,p=0.732),  time:9.587, tt:1054.527\n",
      "Ep:110, loss:0.00003, loss_test:0.06087, lr:6.83e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1064.123\n",
      "Ep:111, loss:0.00003, loss_test:0.06124, lr:6.76e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.587, tt:1073.719\n",
      "Ep:112, loss:0.00003, loss_test:0.06008, lr:6.69e-03, fs:0.76995 (r=0.828,p=0.719),  time:9.587, tt:1083.281\n",
      "Ep:113, loss:0.00003, loss_test:0.06111, lr:6.62e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1092.826\n",
      "Ep:114, loss:0.00003, loss_test:0.06032, lr:6.56e-03, fs:0.77143 (r=0.818,p=0.730),  time:9.586, tt:1102.392\n",
      "Ep:115, loss:0.00003, loss_test:0.06097, lr:6.49e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1111.993\n",
      "Ep:116, loss:0.00003, loss_test:0.06096, lr:6.43e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1121.644\n",
      "Ep:117, loss:0.00003, loss_test:0.06015, lr:6.36e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1131.180\n",
      "Ep:118, loss:0.00003, loss_test:0.06087, lr:6.30e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1140.730\n",
      "Ep:119, loss:0.00003, loss_test:0.06067, lr:6.24e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1150.346\n",
      "Ep:120, loss:0.00003, loss_test:0.06043, lr:6.17e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1159.932\n",
      "Ep:121, loss:0.00003, loss_test:0.06067, lr:6.11e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1169.572\n",
      "Ep:122, loss:0.00003, loss_test:0.06057, lr:6.05e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1179.116\n",
      "Ep:123, loss:0.00003, loss_test:0.06053, lr:5.99e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1188.713\n",
      "Ep:124, loss:0.00003, loss_test:0.06031, lr:5.93e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1198.371\n",
      "Ep:125, loss:0.00003, loss_test:0.06049, lr:5.87e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1207.981\n",
      "Ep:126, loss:0.00002, loss_test:0.06030, lr:5.81e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1217.608\n",
      "Ep:127, loss:0.00002, loss_test:0.06036, lr:5.75e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1227.240\n",
      "Ep:128, loss:0.00002, loss_test:0.06064, lr:5.70e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1236.808\n",
      "Ep:129, loss:0.00002, loss_test:0.06050, lr:5.64e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1246.380\n",
      "Ep:130, loss:0.00002, loss_test:0.06031, lr:5.58e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1255.948\n",
      "Ep:131, loss:0.00002, loss_test:0.06087, lr:5.53e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1265.587\n",
      "Ep:132, loss:0.00002, loss_test:0.06064, lr:5.47e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1275.153\n",
      "Ep:133, loss:0.00002, loss_test:0.06024, lr:5.42e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1284.786\n",
      "Ep:134, loss:0.00002, loss_test:0.06103, lr:5.36e-03, fs:0.76329 (r=0.798,p=0.731),  time:9.588, tt:1294.405\n",
      "Ep:135, loss:0.00002, loss_test:0.05993, lr:5.31e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1303.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00002, loss_test:0.06076, lr:5.26e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.588, tt:1313.494\n",
      "Ep:137, loss:0.00002, loss_test:0.06099, lr:5.20e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.587, tt:1323.016\n",
      "Ep:138, loss:0.00002, loss_test:0.05976, lr:5.15e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.587, tt:1332.609\n",
      "Ep:139, loss:0.00002, loss_test:0.06094, lr:5.10e-03, fs:0.76329 (r=0.798,p=0.731),  time:9.587, tt:1342.195\n",
      "Ep:140, loss:0.00002, loss_test:0.06129, lr:5.05e-03, fs:0.77451 (r=0.798,p=0.752),  time:9.586, tt:1351.674\n",
      "Ep:141, loss:0.00002, loss_test:0.05989, lr:5.00e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1361.202\n",
      "Ep:142, loss:0.00002, loss_test:0.06014, lr:4.95e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.585, tt:1370.678\n",
      "Ep:143, loss:0.00002, loss_test:0.06072, lr:4.90e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.586, tt:1380.318\n",
      "Ep:144, loss:0.00002, loss_test:0.06007, lr:4.85e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1389.898\n",
      "Ep:145, loss:0.00002, loss_test:0.06007, lr:4.80e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.585, tt:1399.446\n",
      "Ep:146, loss:0.00002, loss_test:0.06080, lr:4.75e-03, fs:0.75728 (r=0.788,p=0.729),  time:9.584, tt:1408.918\n",
      "Ep:147, loss:0.00002, loss_test:0.06015, lr:4.71e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.584, tt:1418.472\n",
      "Ep:148, loss:0.00002, loss_test:0.05955, lr:4.66e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.585, tt:1428.095\n",
      "Ep:149, loss:0.00002, loss_test:0.06061, lr:4.61e-03, fs:0.75728 (r=0.788,p=0.729),  time:9.585, tt:1437.814\n",
      "Ep:150, loss:0.00002, loss_test:0.06003, lr:4.57e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.584, tt:1447.254\n",
      "Ep:151, loss:0.00002, loss_test:0.06003, lr:4.52e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.586, tt:1457.010\n",
      "Ep:152, loss:0.00002, loss_test:0.06022, lr:4.48e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.585, tt:1466.569\n",
      "Ep:153, loss:0.00002, loss_test:0.05978, lr:4.43e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.585, tt:1476.069\n",
      "Ep:154, loss:0.00002, loss_test:0.06007, lr:4.39e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.584, tt:1485.577\n",
      "Ep:155, loss:0.00002, loss_test:0.06007, lr:4.34e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.584, tt:1495.047\n",
      "Ep:156, loss:0.00002, loss_test:0.05988, lr:4.30e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.582, tt:1504.410\n",
      "Ep:157, loss:0.00002, loss_test:0.06025, lr:4.26e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.582, tt:1513.878\n",
      "Ep:158, loss:0.00002, loss_test:0.05976, lr:4.21e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.581, tt:1523.421\n",
      "Ep:159, loss:0.00002, loss_test:0.05994, lr:4.17e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.580, tt:1532.832\n",
      "Ep:160, loss:0.00002, loss_test:0.05990, lr:4.13e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.579, tt:1542.187\n",
      "Ep:161, loss:0.00002, loss_test:0.05981, lr:4.09e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.578, tt:1551.715\n",
      "Ep:162, loss:0.00002, loss_test:0.05998, lr:4.05e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.578, tt:1561.211\n",
      "Ep:163, loss:0.00002, loss_test:0.05971, lr:4.01e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.577, tt:1570.591\n",
      "Ep:164, loss:0.00002, loss_test:0.06007, lr:3.97e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.577, tt:1580.210\n",
      "Ep:165, loss:0.00002, loss_test:0.05995, lr:3.93e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.577, tt:1589.786\n",
      "Ep:166, loss:0.00002, loss_test:0.05965, lr:3.89e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.577, tt:1599.282\n",
      "Ep:167, loss:0.00002, loss_test:0.06021, lr:3.85e-03, fs:0.77295 (r=0.808,p=0.741),  time:9.575, tt:1608.642\n",
      "Ep:168, loss:0.00002, loss_test:0.06040, lr:3.81e-03, fs:0.77295 (r=0.808,p=0.741),  time:9.574, tt:1618.034\n",
      "Ep:169, loss:0.00002, loss_test:0.05935, lr:3.77e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.574, tt:1627.541\n",
      "Ep:170, loss:0.00002, loss_test:0.05988, lr:3.73e-03, fs:0.76923 (r=0.808,p=0.734),  time:9.574, tt:1637.080\n",
      "Ep:171, loss:0.00002, loss_test:0.06077, lr:3.70e-03, fs:0.77228 (r=0.788,p=0.757),  time:9.573, tt:1646.564\n",
      "Ep:172, loss:0.00002, loss_test:0.05981, lr:3.66e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.573, tt:1656.064\n",
      "Ep:173, loss:0.00002, loss_test:0.05907, lr:3.62e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.572, tt:1665.498\n",
      "Ep:174, loss:0.00002, loss_test:0.06015, lr:3.59e-03, fs:0.77670 (r=0.808,p=0.748),  time:9.571, tt:1674.998\n",
      "Ep:175, loss:0.00002, loss_test:0.06064, lr:3.55e-03, fs:0.77228 (r=0.788,p=0.757),  time:9.570, tt:1684.382\n",
      "Ep:176, loss:0.00002, loss_test:0.05964, lr:3.52e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.569, tt:1693.661\n",
      "Ep:177, loss:0.00002, loss_test:0.05912, lr:3.48e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.568, tt:1703.155\n",
      "Ep:178, loss:0.00002, loss_test:0.06010, lr:3.45e-03, fs:0.78049 (r=0.808,p=0.755),  time:9.568, tt:1712.675\n",
      "Ep:179, loss:0.00002, loss_test:0.06020, lr:3.41e-03, fs:0.76847 (r=0.788,p=0.750),  time:9.568, tt:1722.163\n",
      "Ep:180, loss:0.00002, loss_test:0.05934, lr:3.38e-03, fs:0.77512 (r=0.818,p=0.736),  time:9.567, tt:1731.622\n",
      "Ep:181, loss:0.00002, loss_test:0.05942, lr:3.34e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.567, tt:1741.169\n",
      "Ep:182, loss:0.00002, loss_test:0.05960, lr:3.31e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.567, tt:1750.713\n",
      "Ep:183, loss:0.00002, loss_test:0.05950, lr:3.28e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.566, tt:1760.212\n",
      "Ep:184, loss:0.00002, loss_test:0.05949, lr:3.24e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.566, tt:1769.745\n",
      "Ep:185, loss:0.00002, loss_test:0.05947, lr:3.21e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.565, tt:1779.173\n",
      "Ep:186, loss:0.00002, loss_test:0.05958, lr:3.18e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.565, tt:1788.567\n",
      "Ep:187, loss:0.00002, loss_test:0.05945, lr:3.15e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.564, tt:1798.051\n",
      "Ep:188, loss:0.00002, loss_test:0.05936, lr:3.12e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.563, tt:1807.340\n",
      "Ep:189, loss:0.00002, loss_test:0.05934, lr:3.09e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.562, tt:1816.819\n",
      "Ep:190, loss:0.00002, loss_test:0.05949, lr:3.05e-03, fs:0.77670 (r=0.808,p=0.748),  time:9.562, tt:1826.360\n",
      "Ep:191, loss:0.00002, loss_test:0.05954, lr:3.02e-03, fs:0.77670 (r=0.808,p=0.748),  time:9.561, tt:1835.804\n",
      "Ep:192, loss:0.00002, loss_test:0.05955, lr:2.99e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.561, tt:1845.211\n",
      "Ep:193, loss:0.00002, loss_test:0.05918, lr:2.96e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.560, tt:1854.647\n",
      "Ep:194, loss:0.00002, loss_test:0.05953, lr:2.93e-03, fs:0.77670 (r=0.808,p=0.748),  time:9.559, tt:1864.098\n",
      "Ep:195, loss:0.00002, loss_test:0.05966, lr:2.90e-03, fs:0.78049 (r=0.808,p=0.755),  time:9.559, tt:1873.614\n",
      "Ep:196, loss:0.00002, loss_test:0.05900, lr:2.88e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.564, tt:1884.177\n",
      "Ep:197, loss:0.00002, loss_test:0.05940, lr:2.85e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.569, tt:1894.685\n",
      "Ep:198, loss:0.00002, loss_test:0.05982, lr:2.82e-03, fs:0.77451 (r=0.798,p=0.752),  time:9.575, tt:1905.374\n",
      "Ep:199, loss:0.00002, loss_test:0.05935, lr:2.79e-03, fs:0.78049 (r=0.808,p=0.755),  time:9.580, tt:1915.961\n",
      "Ep:200, loss:0.00002, loss_test:0.05888, lr:2.76e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.585, tt:1926.495\n",
      "Ep:201, loss:0.00002, loss_test:0.05945, lr:2.73e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.590, tt:1937.167\n",
      "Ep:202, loss:0.00002, loss_test:0.05976, lr:2.71e-03, fs:0.78049 (r=0.808,p=0.755),  time:9.595, tt:1947.722\n",
      "Ep:203, loss:0.00002, loss_test:0.05923, lr:2.68e-03, fs:0.78261 (r=0.818,p=0.750),  time:9.599, tt:1958.183\n",
      "Ep:204, loss:0.00002, loss_test:0.05895, lr:2.65e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.603, tt:1968.707\n",
      "Ep:205, loss:0.00002, loss_test:0.05945, lr:2.63e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.607, tt:1979.134\n",
      "Ep:206, loss:0.00002, loss_test:0.05954, lr:2.60e-03, fs:0.78049 (r=0.808,p=0.755),  time:9.612, tt:1989.786\n",
      "Ep:207, loss:0.00002, loss_test:0.05905, lr:2.57e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.617, tt:2000.250\n",
      "Ep:208, loss:0.00002, loss_test:0.05926, lr:2.55e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.620, tt:2010.594\n",
      "Ep:209, loss:0.00002, loss_test:0.05964, lr:2.52e-03, fs:0.78431 (r=0.808,p=0.762),  time:9.624, tt:2021.102\n",
      "Ep:210, loss:0.00002, loss_test:0.05910, lr:2.50e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.629, tt:2031.617\n",
      "Ep:211, loss:0.00002, loss_test:0.05899, lr:2.47e-03, fs:0.77885 (r=0.818,p=0.743),  time:9.633, tt:2042.115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00002, loss_test:0.05958, lr:2.45e-03, fs:0.78049 (r=0.808,p=0.755),  time:9.636, tt:2052.543\n",
      "Ep:213, loss:0.00002, loss_test:0.05952, lr:2.42e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.640, tt:2063.036\n",
      "Ep:214, loss:0.00002, loss_test:0.05906, lr:2.40e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.645, tt:2073.636\n",
      "Ep:215, loss:0.00002, loss_test:0.05907, lr:2.38e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.650, tt:2084.323\n",
      "Ep:216, loss:0.00002, loss_test:0.05925, lr:2.35e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.653, tt:2094.706\n",
      "Ep:217, loss:0.00002, loss_test:0.05916, lr:2.33e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.657, tt:2105.170\n",
      "Ep:218, loss:0.00002, loss_test:0.05907, lr:2.31e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.661, tt:2115.734\n",
      "Ep:219, loss:0.00002, loss_test:0.05918, lr:2.28e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.665, tt:2126.242\n",
      "Ep:220, loss:0.00002, loss_test:0.05916, lr:2.26e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.669, tt:2136.866\n",
      "Ep:221, loss:0.00002, loss_test:0.05923, lr:2.24e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.673, tt:2147.410\n",
      "Ep:222, loss:0.00002, loss_test:0.05901, lr:2.21e-03, fs:0.78261 (r=0.818,p=0.750),  time:9.676, tt:2157.857\n",
      "Ep:223, loss:0.00002, loss_test:0.05915, lr:2.19e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.680, tt:2168.420\n",
      "Ep:224, loss:0.00002, loss_test:0.05905, lr:2.17e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.684, tt:2178.948\n",
      "Ep:225, loss:0.00002, loss_test:0.05910, lr:2.15e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.688, tt:2189.400\n",
      "Ep:226, loss:0.00002, loss_test:0.05905, lr:2.13e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.693, tt:2200.267\n",
      "Ep:227, loss:0.00002, loss_test:0.05908, lr:2.11e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.697, tt:2210.882\n",
      "Ep:228, loss:0.00002, loss_test:0.05904, lr:2.08e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.700, tt:2221.383\n",
      "Ep:229, loss:0.00002, loss_test:0.05903, lr:2.06e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.704, tt:2231.966\n",
      "Ep:230, loss:0.00002, loss_test:0.05898, lr:2.04e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.708, tt:2242.454\n",
      "Ep:231, loss:0.00002, loss_test:0.05893, lr:2.02e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.711, tt:2252.969\n",
      "Ep:232, loss:0.00002, loss_test:0.05897, lr:2.00e-03, fs:0.78641 (r=0.818,p=0.757),  time:9.715, tt:2263.497\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits4\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,233,\"1-1\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1398\n",
      "1360\n",
      "1172\n",
      "1132\n",
      "1170\n",
      "1170\n",
      "1134\n",
      "1024\n",
      "1286\n",
      "1246\n",
      "1362\n",
      "1439\n",
      "1438\n",
      "1248\n",
      "1742\n",
      "1322\n",
      "1287\n",
      "1286\n",
      "1476\n",
      "1096\n",
      "1058\n",
      "1288\n",
      "1288\n",
      "1288\n",
      "1322\n",
      "1134\n",
      "1060\n",
      "1248\n",
      "1286\n",
      "1326\n",
      "1134\n",
      "1210\n",
      "1554\n",
      "1170\n",
      "1436\n",
      "1438\n",
      "1362\n",
      "1094\n",
      "1324\n",
      "1475\n",
      "1134\n",
      "1475\n",
      "1327\n",
      "1056\n",
      "1361\n",
      "1251\n",
      "1287\n",
      "1134\n",
      "1136\n",
      "264\n",
      "Ep:0, loss:0.00398, loss_test:0.09277, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:263.492, tt:263.492\n",
      "##########Best model found so far##########\n",
      "1286\n",
      "1362\n",
      "1132\n",
      "1058\n",
      "1094\n",
      "1132\n",
      "1436\n",
      "1210\n",
      "1137\n",
      "1136\n",
      "1172\n",
      "1398\n",
      "1249\n",
      "1058\n",
      "1400\n",
      "1626\n",
      "1289\n",
      "1130\n",
      "1211\n",
      "1324\n",
      "1322\n",
      "1514\n",
      "1174\n",
      "1173\n",
      "1096\n",
      "1360\n",
      "1400\n",
      "1588\n",
      "1136\n",
      "1136\n",
      "1702\n",
      "1172\n",
      "1136\n",
      "1134\n",
      "1284\n",
      "1286\n",
      "1667\n",
      "1096\n",
      "1134\n",
      "1250\n",
      "1477\n",
      "1287\n",
      "1134\n",
      "1514\n",
      "1097\n",
      "1210\n",
      "1474\n",
      "1288\n",
      "1211\n",
      "416\n",
      "Ep:1, loss:0.00350, loss_test:0.08874, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:264.527, tt:529.054\n",
      "##########Best model found so far##########\n",
      "1363\n",
      "1398\n",
      "1098\n",
      "1553\n",
      "1248\n",
      "1248\n",
      "1590\n",
      "1360\n",
      "1246\n",
      "1060\n",
      "1171\n",
      "1284\n",
      "1172\n",
      "1441\n",
      "1137\n",
      "1326\n",
      "1474\n",
      "1324\n",
      "1096\n",
      "1286\n",
      "1058\n",
      "1058\n",
      "1248\n",
      "1170\n",
      "1057\n",
      "1324\n",
      "1514\n",
      "1474\n",
      "1551\n",
      "1249\n",
      "1170\n",
      "1094\n",
      "1210\n",
      "1134\n",
      "1284\n",
      "1208\n",
      "1248\n",
      "1096\n",
      "1400\n",
      "1438\n",
      "1362\n",
      "1247\n",
      "1327\n",
      "1058\n",
      "1742\n",
      "1286\n",
      "1590\n",
      "1667\n",
      "569\n",
      "Ep:2, loss:0.00277, loss_test:0.08213, lr:1.00e-02, fs:0.63396 (r=0.848,p=0.506),  time:261.872, tt:785.615\n",
      "1058\n",
      "1666\n",
      "1705\n",
      "1058\n",
      "1666\n",
      "1134\n",
      "1096\n",
      "1324\n",
      "1134\n",
      "1059\n",
      "1098\n",
      "1173\n",
      "1249\n",
      "1058\n",
      "1171\n",
      "1248\n",
      "1058\n",
      "1741\n",
      "1250\n",
      "1056\n",
      "1208\n",
      "1286\n",
      "1284\n",
      "1136\n",
      "1324\n",
      "1173\n",
      "1058\n",
      "1172\n",
      "1172\n",
      "1289\n",
      "1248\n",
      "1058\n",
      "1096\n",
      "1324\n",
      "1472\n",
      "1174\n",
      "1096\n",
      "1096\n",
      "1208\n",
      "1624\n",
      "1705\n",
      "1324\n",
      "1438\n",
      "1174\n",
      "1286\n",
      "1552\n",
      "1097\n",
      "1096\n",
      "1590\n",
      "946\n",
      "Ep:3, loss:0.00262, loss_test:0.08651, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:262.652, tt:1050.607\n",
      "1136\n",
      "1246\n",
      "1245\n",
      "1136\n",
      "1096\n",
      "1362\n",
      "1170\n",
      "1097\n",
      "1436\n",
      "1061\n",
      "1208\n",
      "1173\n",
      "1742\n",
      "1628\n",
      "1096\n",
      "1060\n",
      "1551\n",
      "1362\n",
      "1439\n",
      "1325\n",
      "1440\n",
      "1246\n",
      "1096\n",
      "1172\n",
      "1287\n",
      "1134\n",
      "1210\n",
      "1287\n",
      "1324\n",
      "1476\n",
      "1324\n",
      "1362\n",
      "1439\n",
      "1286\n",
      "1094\n",
      "1510\n",
      "1212\n",
      "1134\n",
      "1172\n",
      "1094\n",
      "1322\n",
      "1744\n",
      "1208\n",
      "1284\n",
      "1588\n",
      "1590\n",
      "1590\n",
      "1514\n",
      "Ep:4, loss:0.00210, loss_test:0.07374, lr:1.00e-02, fs:0.64490 (r=0.798,p=0.541),  time:257.657, tt:1288.284\n",
      "1325\n",
      "1136\n",
      "1210\n",
      "1324\n",
      "1210\n",
      "1208\n",
      "1436\n",
      "1132\n",
      "1362\n",
      "1136\n",
      "1284\n",
      "1282\n",
      "1358\n",
      "1136\n",
      "1361\n",
      "1212\n",
      "1286\n",
      "1096\n",
      "1552\n",
      "1322\n",
      "1439\n",
      "1286\n",
      "1211\n",
      "1134\n",
      "1289\n",
      "1134\n",
      "1289\n",
      "1248\n",
      "1172\n",
      "1286\n",
      "1173\n",
      "1248\n",
      "1096\n",
      "1474\n",
      "1324\n",
      "1137\n",
      "1057\n",
      "1286\n",
      "1590\n",
      "1174\n",
      "1250\n",
      "1058\n",
      "1552\n",
      "1056\n",
      "1363\n",
      "1170\n",
      "1060\n",
      "1287\n",
      "1250\n",
      "1247\n",
      "Ep:5, loss:0.00184, loss_test:0.09251, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:251.316, tt:1507.898\n",
      "1664\n",
      "1361\n",
      "1325\n",
      "1137\n",
      "1250\n",
      "1664\n",
      "1550\n",
      "1136\n",
      "1210\n",
      "1096\n",
      "1438\n",
      "1288\n",
      "1246\n",
      "1210\n",
      "1094\n",
      "1212\n",
      "1327\n",
      "1363\n",
      "1398\n",
      "1096\n",
      "1324\n",
      "1362\n",
      "1289\n",
      "1322\n",
      "1170\n",
      "1060\n",
      "1248\n",
      "1096\n",
      "1248\n",
      "1284\n",
      "1058\n",
      "1172\n",
      "1172\n",
      "1096\n",
      "1060\n",
      "1133\n",
      "1134\n",
      "1210\n",
      "1476\n",
      "1286\n",
      "1588\n",
      "1438\n",
      "1289\n",
      "1322\n",
      "1246\n",
      "1060\n",
      "1175\n",
      "1286\n",
      "1094\n",
      "945\n",
      "Ep:6, loss:0.00171, loss_test:0.08554, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:248.632, tt:1740.421\n",
      "##########Best model found so far##########\n",
      "1326\n",
      "1250\n",
      "1667\n",
      "1060\n",
      "1136\n",
      "1246\n",
      "1362\n",
      "1438\n",
      "1132\n",
      "1134\n",
      "1740\n",
      "1096\n",
      "1286\n",
      "1325\n",
      "1210\n",
      "1132\n",
      "1172\n",
      "1360\n",
      "1136\n",
      "1098\n",
      "1284\n",
      "1134\n",
      "1097\n",
      "1322\n",
      "1284\n",
      "1587\n",
      "1174\n",
      "1436\n",
      "1397\n",
      "1212\n",
      "1322\n",
      "1170\n",
      "1172\n",
      "1210\n",
      "1170\n",
      "1250\n",
      "1401\n",
      "1059\n",
      "1096\n",
      "1248\n",
      "1438\n",
      "1326\n",
      "1172\n",
      "1289\n",
      "1363\n",
      "1667\n",
      "1170\n",
      "1324\n",
      "1628\n",
      "Ep:7, loss:0.00132, loss_test:0.08141, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:246.155, tt:1969.244\n",
      "1058\n",
      "1249\n",
      "1172\n",
      "1400\n",
      "1136\n",
      "1362\n",
      "1173\n",
      "1286\n",
      "1246\n",
      "1137\n",
      "1172\n",
      "1208\n",
      "1170\n",
      "1096\n",
      "1514\n",
      "1248\n",
      "1438\n",
      "1058\n",
      "1058\n",
      "1248\n",
      "1361\n",
      "1250\n",
      "1247\n",
      "1137\n",
      "1096\n",
      "1058\n",
      "1552\n",
      "1362\n",
      "1172\n",
      "1324\n",
      "1172\n",
      "1398\n",
      "1321\n",
      "1248\n",
      "1095\n",
      "1324\n",
      "1174\n",
      "1134\n",
      "1137\n",
      "1058\n",
      "1514\n",
      "1134\n",
      "1058\n",
      "1248\n",
      "1211\n",
      "1212\n",
      "1286\n",
      "1137\n",
      "1061\n",
      "1702\n",
      "1096\n",
      "Ep:8, loss:0.00112, loss_test:0.10268, lr:1.00e-02, fs:0.71345 (r=0.616,p=0.847),  time:246.013, tt:2214.121\n",
      "1060\n",
      "1741\n",
      "1250\n",
      "1628\n",
      "1441\n",
      "1134\n",
      "1590\n",
      "1438\n",
      "1324\n",
      "1286\n",
      "1248\n",
      "1438\n",
      "1132\n",
      "1061\n",
      "1472\n",
      "1056\n",
      "1172\n",
      "1244\n",
      "1170\n",
      "1136\n",
      "1477\n",
      "1286\n",
      "1134\n",
      "1288\n",
      "1210\n",
      "1172\n",
      "1096\n",
      "1325\n",
      "1174\n",
      "1058\n",
      "1095\n",
      "1514\n",
      "1210\n",
      "1742\n",
      "1286\n",
      "1134\n",
      "1248\n",
      "1550\n",
      "1096\n",
      "1174\n",
      "1170\n",
      "1058\n",
      "1137\n",
      "1134\n",
      "1058\n",
      "1516\n",
      "1209\n",
      "1060\n",
      "1094\n",
      "982\n",
      "Ep:9, loss:0.00095, loss_test:0.10145, lr:1.00e-02, fs:0.71264 (r=0.626,p=0.827),  time:245.894, tt:2458.945\n",
      "1210\n",
      "1173\n",
      "1175\n",
      "1098\n",
      "1134\n",
      "1515\n",
      "1363\n",
      "1134\n",
      "1096\n",
      "1588\n",
      "1248\n",
      "1208\n",
      "1173\n",
      "1284\n",
      "1132\n",
      "1285\n",
      "1289\n",
      "1132\n",
      "1477\n",
      "1210\n",
      "1550\n",
      "1362\n",
      "1248\n",
      "1096\n",
      "1589\n",
      "1286\n",
      "1286\n",
      "1248\n",
      "1553\n",
      "1514\n",
      "1248\n",
      "1248\n",
      "1553\n",
      "1136\n",
      "1060\n",
      "1248\n",
      "1134\n",
      "1172\n",
      "1436\n",
      "1058\n",
      "1285\n",
      "1512\n",
      "1246\n",
      "1250\n",
      "1248\n",
      "1096\n",
      "1058\n",
      "1288\n",
      "1096\n",
      "680\n",
      "Ep:10, loss:0.00086, loss_test:0.12300, lr:1.00e-02, fs:0.73620 (r=0.606,p=0.938),  time:247.588, tt:2723.465\n",
      "1170\n",
      "1174\n",
      "1248\n",
      "1170\n",
      "1172\n",
      "1286\n",
      "1172\n",
      "1441\n",
      "1249\n",
      "1287\n",
      "1474\n",
      "1624\n",
      "1284\n",
      "1172\n",
      "1172\n",
      "1246\n",
      "1288\n",
      "1289\n",
      "1248\n",
      "1210\n",
      "1287\n",
      "1174\n",
      "1212\n",
      "1058\n",
      "1360\n",
      "1248\n",
      "1362\n",
      "1098\n",
      "1208\n",
      "1437\n",
      "1094\n",
      "1058\n",
      "1667\n",
      "1400\n",
      "1362\n",
      "1248\n",
      "1095\n",
      "1210\n",
      "1170\n",
      "1208\n",
      "1362\n",
      "1743\n",
      "1096\n",
      "1174\n",
      "1249\n",
      "1553\n",
      "1628\n",
      "1434\n",
      "1137\n",
      "Ep:11, loss:0.00064, loss_test:0.11702, lr:1.00e-02, fs:0.71429 (r=0.606,p=0.870),  time:248.475, tt:2981.696\n",
      "1286\n",
      "1327\n",
      "1398\n",
      "1136\n",
      "1324\n",
      "1438\n",
      "1135\n",
      "1325\n",
      "1248\n",
      "1060\n",
      "1363\n",
      "1058\n",
      "1246\n",
      "1210\n",
      "1172\n",
      "1362\n",
      "1400\n",
      "1628\n",
      "1743\n",
      "1170\n",
      "1096\n",
      "1326\n",
      "1287\n",
      "1210\n",
      "1474\n",
      "1058\n",
      "1210\n",
      "1172\n",
      "1208\n",
      "1208\n",
      "1137\n",
      "1322\n",
      "1400\n",
      "1438\n",
      "1512\n",
      "1286\n",
      "1398\n",
      "1132\n",
      "1171\n",
      "1096\n",
      "1362\n",
      "1474\n",
      "1664\n",
      "1514\n",
      "1096\n",
      "1553\n",
      "1246\n",
      "1629\n",
      "Ep:12, loss:0.00052, loss_test:0.12022, lr:1.00e-02, fs:0.72289 (r=0.606,p=0.896),  time:249.093, tt:3238.210\n",
      "1322\n",
      "1284\n",
      "1326\n",
      "1289\n",
      "1096\n",
      "1322\n",
      "1705\n",
      "1211\n",
      "1400\n",
      "1514\n",
      "1170\n",
      "1170\n",
      "1137\n",
      "1591\n",
      "1136\n",
      "1286\n",
      "1286\n",
      "1208\n",
      "1058\n",
      "1136\n",
      "1246\n",
      "1514\n",
      "1210\n",
      "1212\n",
      "1551\n",
      "1705\n",
      "1058\n",
      "1320\n",
      "1667\n",
      "1553\n",
      "1286\n",
      "1629\n",
      "1400\n",
      "1058\n",
      "1096\n",
      "1246\n",
      "1174\n",
      "1132\n",
      "1324\n",
      "1247\n",
      "1284\n",
      "1362\n",
      "1094\n",
      "1208\n",
      "1287\n",
      "1058\n",
      "1398\n",
      "1136\n",
      "606\n",
      "Ep:13, loss:0.00053, loss_test:0.12676, lr:1.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:249.737, tt:3496.318\n",
      "1248\n",
      "1398\n",
      "1327\n",
      "1172\n",
      "1591\n",
      "1248\n",
      "1477\n",
      "1362\n",
      "1134\n",
      "1134\n",
      "1282\n",
      "1060\n",
      "1363\n",
      "1362\n",
      "1210\n",
      "1326\n",
      "1058\n",
      "1058\n",
      "1477\n",
      "1134\n",
      "1472\n",
      "1208\n",
      "1246\n",
      "1590\n",
      "1094\n",
      "1058\n",
      "1134\n",
      "1173\n",
      "1362\n",
      "1324\n",
      "1588\n",
      "1286\n",
      "1325\n",
      "1098\n",
      "1288\n",
      "1134\n",
      "1248\n",
      "1135\n",
      "1360\n",
      "1663\n",
      "1136\n",
      "1284\n",
      "1324\n",
      "1136\n",
      "1248\n",
      "1210\n",
      "1135\n",
      "1210\n",
      "1364\n",
      "454\n",
      "Ep:14, loss:0.00047, loss_test:0.11975, lr:1.00e-02, fs:0.69048 (r=0.586,p=0.841),  time:250.890, tt:3763.346\n",
      "1436\n",
      "1210\n",
      "1284\n",
      "1590\n",
      "1096\n",
      "1284\n",
      "1324\n",
      "1251\n",
      "1248\n",
      "1627\n",
      "1061\n",
      "1094\n",
      "1400\n",
      "1058\n",
      "1591\n",
      "1324\n",
      "1058\n",
      "1324\n",
      "1664\n",
      "1362\n",
      "1248\n",
      "1438\n",
      "1136\n",
      "1513\n",
      "1362\n",
      "1208\n",
      "1441\n",
      "1172\n",
      "1326\n",
      "1058\n",
      "1210\n",
      "1324\n",
      "1058\n",
      "1096\n",
      "1137\n",
      "1400\n",
      "1097\n",
      "1361\n",
      "1322\n",
      "1246\n",
      "1250\n",
      "1514\n",
      "1056\n",
      "1133\n",
      "1096\n",
      "1550\n",
      "1398\n",
      "1060\n",
      "1212\n",
      "Ep:15, loss:0.00049, loss_test:0.11398, lr:1.00e-02, fs:0.65868 (r=0.556,p=0.809),  time:251.415, tt:4022.645\n",
      "1060\n",
      "1287\n",
      "1058\n",
      "1512\n",
      "1172\n",
      "1136\n",
      "1134\n",
      "1436\n",
      "1284\n",
      "1360\n",
      "1588\n",
      "1247\n",
      "1322\n",
      "1210\n",
      "1250\n",
      "1173\n",
      "1248\n",
      "1327\n",
      "1550\n",
      "1134\n",
      "1136\n",
      "1325\n",
      "1248\n",
      "1058\n",
      "1210\n",
      "1246\n",
      "1553\n",
      "1438\n",
      "1096\n",
      "1060\n",
      "1137\n",
      "1627\n",
      "1173\n",
      "1096\n",
      "1476\n",
      "1096\n",
      "1248\n",
      "1287\n",
      "1210\n",
      "1474\n",
      "1208\n",
      "1248\n",
      "1172\n",
      "1362\n",
      "1134\n",
      "1172\n",
      "1363\n",
      "1097\n",
      "1362\n",
      "908\n",
      "Ep:16, loss:0.00053, loss_test:0.12580, lr:1.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:252.248, tt:4288.215\n",
      "1288\n",
      "1172\n",
      "1665\n",
      "1740\n",
      "1171\n",
      "1058\n",
      "1438\n",
      "1284\n",
      "1251\n",
      "1060\n",
      "1170\n",
      "1514\n",
      "1246\n",
      "1324\n",
      "1211\n",
      "1286\n",
      "1398\n",
      "1326\n",
      "1552\n",
      "1286\n",
      "1170\n",
      "1056\n",
      "1059\n",
      "1251\n",
      "1550\n",
      "1363\n",
      "1286\n",
      "1211\n",
      "1210\n",
      "1362\n",
      "1210\n",
      "1284\n",
      "1284\n",
      "1326\n",
      "1060\n",
      "1174\n",
      "1210\n",
      "1591\n",
      "1284\n",
      "1362\n",
      "1476\n",
      "1094\n",
      "1212\n",
      "1246\n",
      "1058\n",
      "1282\n",
      "1175\n",
      "1742\n",
      "680\n",
      "Ep:17, loss:0.00036, loss_test:0.13807, lr:1.00e-02, fs:0.68750 (r=0.556,p=0.902),  time:252.669, tt:4548.042\n",
      "1287\n",
      "1132\n",
      "1210\n",
      "1211\n",
      "1628\n",
      "1058\n",
      "1284\n",
      "1476\n",
      "1095\n",
      "1438\n",
      "1174\n",
      "1134\n",
      "1132\n",
      "1287\n",
      "1059\n",
      "1096\n",
      "1134\n",
      "1552\n",
      "1060\n",
      "1175\n",
      "1173\n",
      "1362\n",
      "1286\n",
      "1210\n",
      "1248\n",
      "1289\n",
      "1324\n",
      "1096\n",
      "1514\n",
      "1058\n",
      "1060\n",
      "1326\n",
      "1136\n",
      "1058\n",
      "1324\n",
      "1400\n",
      "1438\n",
      "1286\n",
      "1096\n",
      "1132\n",
      "1094\n",
      "1060\n",
      "1134\n",
      "1135\n",
      "1289\n",
      "1208\n",
      "1287\n",
      "1475\n",
      "1170\n",
      "1208\n",
      "1210\n",
      "Ep:18, loss:0.00027, loss_test:0.13725, lr:9.90e-03, fs:0.67089 (r=0.535,p=0.898),  time:253.575, tt:4817.922\n",
      "1210\n",
      "1173\n",
      "1475\n",
      "1096\n",
      "1284\n",
      "1210\n",
      "1628\n",
      "1096\n",
      "1246\n",
      "1172\n",
      "1360\n",
      "1324\n",
      "1175\n",
      "1400\n",
      "1174\n",
      "1400\n",
      "1094\n",
      "1438\n",
      "1098\n",
      "1358\n",
      "1474\n",
      "1326\n",
      "1056\n",
      "1134\n",
      "1210\n",
      "1058\n",
      "1211\n",
      "1024\n",
      "1248\n",
      "1360\n",
      "1248\n",
      "1060\n",
      "1248\n",
      "1250\n",
      "1289\n",
      "1096\n",
      "1173\n",
      "1210\n",
      "1588\n",
      "1326\n",
      "1058\n",
      "1172\n",
      "1135\n",
      "1441\n",
      "1400\n",
      "1324\n",
      "1474\n",
      "1436\n",
      "1286\n",
      "982\n",
      "Ep:19, loss:0.00020, loss_test:0.15183, lr:9.80e-03, fs:0.60274 (r=0.444,p=0.936),  time:253.993, tt:5079.858\n",
      "1326\n",
      "1172\n",
      "1322\n",
      "1361\n",
      "1132\n",
      "1136\n",
      "1629\n",
      "1363\n",
      "1170\n",
      "1136\n",
      "1058\n",
      "1134\n",
      "1208\n",
      "1477\n",
      "1249\n",
      "1248\n",
      "1246\n",
      "1438\n",
      "1137\n",
      "1096\n",
      "1743\n",
      "1248\n",
      "1096\n",
      "1249\n",
      "1210\n",
      "1174\n",
      "1327\n",
      "1436\n",
      "1398\n",
      "1208\n",
      "1136\n",
      "1172\n",
      "1246\n",
      "1248\n",
      "1476\n",
      "1590\n",
      "1208\n",
      "1096\n",
      "1096\n",
      "1172\n",
      "1207\n",
      "1363\n",
      "1438\n",
      "1172\n",
      "1440\n",
      "1362\n",
      "1249\n",
      "1666\n",
      "1244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00019, loss_test:0.14324, lr:9.70e-03, fs:0.67532 (r=0.525,p=0.945),  time:254.156, tt:5337.284\n",
      "1324\n",
      "1211\n",
      "1060\n",
      "1061\n",
      "1058\n",
      "1212\n",
      "1058\n",
      "1136\n",
      "1174\n",
      "1173\n",
      "1247\n",
      "1248\n",
      "1058\n",
      "1135\n",
      "1288\n",
      "1438\n",
      "1249\n",
      "1476\n",
      "1136\n",
      "1284\n",
      "1060\n",
      "1436\n",
      "1437\n",
      "1246\n",
      "1134\n",
      "1246\n",
      "1134\n",
      "1172\n",
      "1700\n",
      "1249\n",
      "1436\n",
      "1514\n",
      "1515\n",
      "1208\n",
      "1551\n",
      "1548\n",
      "1137\n",
      "1094\n",
      "1514\n",
      "1284\n",
      "1400\n",
      "1327\n",
      "1208\n",
      "1248\n",
      "1172\n",
      "1208\n",
      "1362\n",
      "1742\n",
      "1400\n",
      "Ep:21, loss:0.00018, loss_test:0.13437, lr:9.61e-03, fs:0.65385 (r=0.515,p=0.895),  time:253.044, tt:5566.960\n",
      "1742\n",
      "1208\n",
      "1248\n",
      "1058\n",
      "1248\n",
      "1665\n",
      "1287\n",
      "1172\n",
      "1288\n",
      "1098\n",
      "1322\n",
      "1286\n",
      "1326\n",
      "1286\n",
      "1362\n",
      "1096\n",
      "1210\n",
      "1172\n",
      "1324\n",
      "1208\n",
      "1439\n",
      "1094\n",
      "1135\n",
      "1740\n",
      "1096\n",
      "1058\n",
      "1208\n",
      "1059\n",
      "1058\n",
      "1173\n",
      "1174\n",
      "1286\n",
      "1287\n",
      "1172\n",
      "1701\n",
      "1362\n",
      "1286\n",
      "1438\n",
      "1478\n",
      "1286\n",
      "1172\n",
      "1172\n",
      "1436\n",
      "1515\n",
      "1400\n",
      "1058\n",
      "1327\n",
      "1244\n",
      "1248\n",
      "Ep:22, loss:0.00017, loss_test:0.15083, lr:9.51e-03, fs:0.65806 (r=0.515,p=0.911),  time:252.024, tt:5796.560\n",
      "1552\n",
      "1553\n",
      "1284\n",
      "1286\n",
      "1438\n",
      "1248\n",
      "1246\n",
      "1326\n",
      "1172\n",
      "1058\n",
      "1248\n",
      "1324\n",
      "1288\n",
      "1175\n",
      "1208\n",
      "1401\n",
      "1172\n",
      "1248\n",
      "1136\n",
      "1094\n",
      "1210\n",
      "1324\n",
      "1324\n",
      "1286\n",
      "1286\n",
      "1170\n",
      "1362\n",
      "1059\n",
      "1323\n",
      "1362\n",
      "1170\n",
      "1286\n",
      "1665\n",
      "1096\n",
      "1251\n",
      "1058\n",
      "1437\n",
      "1363\n",
      "1058\n",
      "1248\n",
      "1097\n",
      "1322\n",
      "1208\n",
      "1588\n",
      "1400\n",
      "1627\n",
      "1134\n",
      "1136\n",
      "1098\n",
      "303\n",
      "Ep:23, loss:0.00013, loss_test:0.13501, lr:9.41e-03, fs:0.65385 (r=0.515,p=0.895),  time:251.298, tt:6031.153\n",
      "1210\n",
      "1094\n",
      "1135\n",
      "1401\n",
      "1248\n",
      "1248\n",
      "1436\n",
      "1248\n",
      "1060\n",
      "1400\n",
      "1436\n",
      "1590\n",
      "1588\n",
      "1058\n",
      "1362\n",
      "1248\n",
      "1172\n",
      "1250\n",
      "1287\n",
      "1132\n",
      "1210\n",
      "1514\n",
      "1172\n",
      "1362\n",
      "1248\n",
      "1172\n",
      "1212\n",
      "1629\n",
      "1320\n",
      "1249\n",
      "1132\n",
      "1514\n",
      "1250\n",
      "1058\n",
      "1097\n",
      "1324\n",
      "1438\n",
      "1210\n",
      "1436\n",
      "1172\n",
      "1250\n",
      "1170\n",
      "1400\n",
      "1210\n",
      "1246\n",
      "1173\n",
      "1210\n",
      "1477\n",
      "1250\n",
      "Ep:24, loss:0.00013, loss_test:0.15144, lr:9.32e-03, fs:0.61224 (r=0.455,p=0.938),  time:250.450, tt:6261.246\n",
      "1286\n",
      "1441\n",
      "1059\n",
      "1248\n",
      "1137\n",
      "1322\n",
      "1288\n",
      "1134\n",
      "1134\n",
      "1210\n",
      "1135\n",
      "1210\n",
      "1476\n",
      "1061\n",
      "1136\n",
      "1174\n",
      "1248\n",
      "1172\n",
      "1058\n",
      "1058\n",
      "1286\n",
      "1248\n",
      "1172\n",
      "1248\n",
      "1324\n",
      "1136\n",
      "1210\n",
      "1246\n",
      "1362\n",
      "1552\n",
      "1476\n",
      "1058\n",
      "1250\n",
      "1210\n",
      "1208\n",
      "1475\n",
      "1400\n",
      "1210\n",
      "1172\n",
      "1058\n",
      "1134\n",
      "1173\n",
      "1097\n",
      "1246\n",
      "1284\n",
      "1287\n",
      "1591\n",
      "1398\n",
      "1170\n",
      "1474\n",
      "566\n",
      "Ep:25, loss:0.00010, loss_test:0.14561, lr:9.23e-03, fs:0.63576 (r=0.485,p=0.923),  time:250.000, tt:6500.006\n",
      "1398\n",
      "1096\n",
      "1665\n",
      "1436\n",
      "1209\n",
      "1477\n",
      "1396\n",
      "1208\n",
      "1137\n",
      "1286\n",
      "1249\n",
      "1436\n",
      "1287\n",
      "1094\n",
      "1667\n",
      "1056\n",
      "1362\n",
      "1136\n",
      "1362\n",
      "1210\n",
      "1134\n",
      "1436\n",
      "1512\n",
      "1288\n",
      "1059\n",
      "1286\n",
      "1362\n",
      "1096\n",
      "1134\n",
      "1400\n",
      "1212\n",
      "1743\n",
      "1134\n",
      "1246\n",
      "1250\n",
      "1248\n",
      "1134\n",
      "1401\n",
      "1590\n",
      "1211\n",
      "1284\n",
      "1436\n",
      "1060\n",
      "1134\n",
      "1477\n",
      "1324\n",
      "1362\n",
      "1172\n",
      "416\n",
      "Ep:26, loss:0.00007, loss_test:0.16310, lr:9.14e-03, fs:0.60274 (r=0.444,p=0.936),  time:249.271, tt:6730.324\n",
      "1399\n",
      "1246\n",
      "1096\n",
      "1327\n",
      "1172\n",
      "1326\n",
      "1058\n",
      "1362\n",
      "1208\n",
      "1363\n",
      "1208\n",
      "1098\n",
      "1288\n",
      "1513\n",
      "1134\n",
      "1248\n",
      "1058\n",
      "1059\n",
      "1320\n",
      "1170\n",
      "1208\n",
      "1362\n",
      "1286\n",
      "1248\n",
      "1248\n",
      "1286\n",
      "1588\n",
      "1740\n",
      "1210\n",
      "1438\n",
      "1401\n",
      "1512\n",
      "1327\n",
      "1286\n",
      "1399\n",
      "1398\n",
      "1438\n",
      "1327\n",
      "1096\n",
      "1096\n",
      "1058\n",
      "1096\n",
      "1326\n",
      "1363\n",
      "1474\n",
      "1136\n",
      "1513\n",
      "1477\n",
      "718\n",
      "Ep:27, loss:0.00006, loss_test:0.15385, lr:9.04e-03, fs:0.60690 (r=0.444,p=0.957),  time:248.571, tt:6959.984\n",
      "1743\n",
      "1058\n",
      "1060\n",
      "1360\n",
      "1132\n",
      "1325\n",
      "1212\n",
      "1398\n",
      "1210\n",
      "1438\n",
      "1249\n",
      "1666\n",
      "1286\n",
      "1096\n",
      "1134\n",
      "1476\n",
      "1058\n",
      "1060\n",
      "1362\n",
      "1360\n",
      "1515\n",
      "1210\n",
      "1210\n",
      "1665\n",
      "1210\n",
      "1322\n",
      "1061\n",
      "1741\n",
      "1590\n",
      "1438\n",
      "1134\n",
      "1134\n",
      "1171\n",
      "1132\n",
      "1551\n",
      "1172\n",
      "1172\n",
      "1170\n",
      "1246\n",
      "1363\n",
      "1284\n",
      "1248\n",
      "1362\n",
      "1134\n",
      "1437\n",
      "1172\n",
      "1288\n",
      "1553\n",
      "340\n",
      "Ep:28, loss:0.00005, loss_test:0.15278, lr:8.95e-03, fs:0.60690 (r=0.444,p=0.957),  time:247.931, tt:7189.985\n",
      "1286\n",
      "1325\n",
      "1324\n",
      "1172\n",
      "1629\n",
      "1248\n",
      "1326\n",
      "1362\n",
      "1210\n",
      "1247\n",
      "1288\n",
      "1515\n",
      "1098\n",
      "1136\n",
      "1322\n",
      "1285\n",
      "1438\n",
      "1320\n",
      "1246\n",
      "1248\n",
      "1059\n",
      "1137\n",
      "1439\n",
      "1132\n",
      "1553\n",
      "1172\n",
      "1248\n",
      "1398\n",
      "1246\n",
      "1172\n",
      "1286\n",
      "1552\n",
      "1094\n",
      "1326\n",
      "1322\n",
      "1170\n",
      "1285\n",
      "1360\n",
      "1248\n",
      "1287\n",
      "1436\n",
      "1136\n",
      "1476\n",
      "1248\n",
      "1286\n",
      "1094\n",
      "1438\n",
      "1362\n",
      "721\n",
      "Ep:29, loss:0.00005, loss_test:0.14819, lr:8.86e-03, fs:0.61644 (r=0.455,p=0.957),  time:247.368, tt:7421.053\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,\"8-8\",0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 30\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14880, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.920, tt:26.920\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14837, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.378, tt:64.757\n",
      "Ep:2, loss:0.00055, loss_test:0.14747, lr:1.00e-02, fs:0.65306 (r=0.970,p=0.492),  time:40.795, tt:122.385\n",
      "Ep:3, loss:0.00053, loss_test:0.14555, lr:1.00e-02, fs:0.63538 (r=0.889,p=0.494),  time:45.632, tt:182.528\n",
      "Ep:4, loss:0.00048, loss_test:0.14266, lr:1.00e-02, fs:0.58874 (r=0.687,p=0.515),  time:48.553, tt:242.766\n",
      "Ep:5, loss:0.00045, loss_test:0.14166, lr:1.00e-02, fs:0.53125 (r=0.515,p=0.548),  time:50.047, tt:300.283\n",
      "Ep:6, loss:0.00043, loss_test:0.13293, lr:1.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:51.604, tt:361.226\n",
      "Ep:7, loss:0.00040, loss_test:0.12959, lr:1.00e-02, fs:0.61165 (r=0.636,p=0.589),  time:52.668, tt:421.342\n",
      "Ep:8, loss:0.00038, loss_test:0.12654, lr:1.00e-02, fs:0.63107 (r=0.657,p=0.607),  time:53.618, tt:482.561\n",
      "Ep:9, loss:0.00036, loss_test:0.12464, lr:1.00e-02, fs:0.65025 (r=0.667,p=0.635),  time:54.210, tt:542.096\n",
      "Ep:10, loss:0.00034, loss_test:0.12197, lr:1.00e-02, fs:0.65657 (r=0.657,p=0.657),  time:54.698, tt:601.683\n",
      "Ep:11, loss:0.00032, loss_test:0.11959, lr:1.00e-02, fs:0.65327 (r=0.657,p=0.650),  time:55.110, tt:661.322\n",
      "Ep:12, loss:0.00031, loss_test:0.11719, lr:9.90e-03, fs:0.65969 (r=0.636,p=0.685),  time:55.626, tt:723.133\n",
      "Ep:13, loss:0.00030, loss_test:0.11586, lr:9.80e-03, fs:0.64550 (r=0.616,p=0.678),  time:56.013, tt:784.184\n",
      "Ep:14, loss:0.00028, loss_test:0.11432, lr:9.70e-03, fs:0.65969 (r=0.636,p=0.685),  time:56.372, tt:845.587\n",
      "Ep:15, loss:0.00027, loss_test:0.11406, lr:9.61e-03, fs:0.67358 (r=0.657,p=0.691),  time:56.592, tt:905.475\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.11242, lr:9.61e-03, fs:0.68063 (r=0.657,p=0.707),  time:56.802, tt:965.638\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.11204, lr:9.61e-03, fs:0.68063 (r=0.657,p=0.707),  time:57.092, tt:1027.648\n",
      "Ep:18, loss:0.00024, loss_test:0.11078, lr:9.61e-03, fs:0.68085 (r=0.646,p=0.719),  time:57.289, tt:1088.491\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.11086, lr:9.61e-03, fs:0.67742 (r=0.636,p=0.724),  time:57.566, tt:1151.321\n",
      "Ep:20, loss:0.00022, loss_test:0.11028, lr:9.61e-03, fs:0.68108 (r=0.636,p=0.733),  time:57.705, tt:1211.797\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.11112, lr:9.61e-03, fs:0.69565 (r=0.646,p=0.753),  time:57.811, tt:1271.838\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.11003, lr:9.61e-03, fs:0.68108 (r=0.636,p=0.733),  time:57.913, tt:1332.009\n",
      "Ep:23, loss:0.00019, loss_test:0.10936, lr:9.61e-03, fs:0.69565 (r=0.646,p=0.753),  time:58.021, tt:1392.492\n",
      "Ep:24, loss:0.00018, loss_test:0.11013, lr:9.61e-03, fs:0.70652 (r=0.657,p=0.765),  time:58.136, tt:1453.406\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.10858, lr:9.61e-03, fs:0.69189 (r=0.646,p=0.744),  time:58.263, tt:1514.848\n",
      "Ep:26, loss:0.00017, loss_test:0.11012, lr:9.61e-03, fs:0.70652 (r=0.657,p=0.765),  time:58.341, tt:1575.195\n",
      "Ep:27, loss:0.00016, loss_test:0.11027, lr:9.61e-03, fs:0.69613 (r=0.636,p=0.768),  time:58.487, tt:1637.637\n",
      "Ep:28, loss:0.00015, loss_test:0.10833, lr:9.61e-03, fs:0.71038 (r=0.657,p=0.774),  time:58.536, tt:1697.557\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.10955, lr:9.61e-03, fs:0.68852 (r=0.636,p=0.750),  time:58.655, tt:1759.663\n",
      "Ep:30, loss:0.00014, loss_test:0.10732, lr:9.61e-03, fs:0.70270 (r=0.657,p=0.756),  time:58.785, tt:1822.330\n",
      "Ep:31, loss:0.00014, loss_test:0.10983, lr:9.61e-03, fs:0.71186 (r=0.636,p=0.808),  time:58.882, tt:1884.224\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.10977, lr:9.61e-03, fs:0.72928 (r=0.667,p=0.805),  time:59.069, tt:1949.289\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.11499, lr:9.61e-03, fs:0.72093 (r=0.626,p=0.849),  time:59.120, tt:2010.065\n",
      "Ep:34, loss:0.00013, loss_test:0.10572, lr:9.61e-03, fs:0.70968 (r=0.667,p=0.759),  time:59.238, tt:2073.316\n",
      "Ep:35, loss:0.00012, loss_test:0.11059, lr:9.61e-03, fs:0.72222 (r=0.657,p=0.802),  time:59.334, tt:2136.027\n",
      "Ep:36, loss:0.00011, loss_test:0.11086, lr:9.61e-03, fs:0.71508 (r=0.646,p=0.800),  time:59.395, tt:2197.599\n",
      "Ep:37, loss:0.00011, loss_test:0.11004, lr:9.61e-03, fs:0.71591 (r=0.636,p=0.818),  time:59.427, tt:2258.208\n",
      "Ep:38, loss:0.00010, loss_test:0.11012, lr:9.61e-03, fs:0.72316 (r=0.646,p=0.821),  time:59.533, tt:2321.803\n",
      "Ep:39, loss:0.00010, loss_test:0.11272, lr:9.61e-03, fs:0.72316 (r=0.646,p=0.821),  time:59.651, tt:2386.042\n",
      "Ep:40, loss:0.00010, loss_test:0.11154, lr:9.61e-03, fs:0.73143 (r=0.646,p=0.842),  time:59.784, tt:2451.157\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.10931, lr:9.61e-03, fs:0.71508 (r=0.646,p=0.800),  time:59.697, tt:2507.282\n",
      "Ep:42, loss:0.00009, loss_test:0.11289, lr:9.61e-03, fs:0.73143 (r=0.646,p=0.842),  time:59.681, tt:2566.293\n",
      "Ep:43, loss:0.00008, loss_test:0.11449, lr:9.61e-03, fs:0.71345 (r=0.616,p=0.847),  time:59.632, tt:2623.788\n",
      "Ep:44, loss:0.00008, loss_test:0.11470, lr:9.61e-03, fs:0.68235 (r=0.586,p=0.817),  time:59.669, tt:2685.120\n",
      "Ep:45, loss:0.00008, loss_test:0.11618, lr:9.61e-03, fs:0.71084 (r=0.596,p=0.881),  time:59.620, tt:2742.498\n",
      "Ep:46, loss:0.00007, loss_test:0.11592, lr:9.61e-03, fs:0.70659 (r=0.596,p=0.868),  time:59.585, tt:2800.501\n",
      "Ep:47, loss:0.00007, loss_test:0.11333, lr:9.61e-03, fs:0.73256 (r=0.636,p=0.863),  time:59.585, tt:2860.092\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.11116, lr:9.61e-03, fs:0.73563 (r=0.646,p=0.853),  time:59.567, tt:2918.769\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.11559, lr:9.61e-03, fs:0.72515 (r=0.626,p=0.861),  time:59.529, tt:2976.461\n",
      "Ep:50, loss:0.00007, loss_test:0.11713, lr:9.61e-03, fs:0.68293 (r=0.566,p=0.862),  time:59.501, tt:3034.540\n",
      "Ep:51, loss:0.00006, loss_test:0.11601, lr:9.61e-03, fs:0.70238 (r=0.596,p=0.855),  time:59.508, tt:3094.435\n",
      "Ep:52, loss:0.00006, loss_test:0.11728, lr:9.61e-03, fs:0.67879 (r=0.566,p=0.848),  time:59.557, tt:3156.539\n",
      "Ep:53, loss:0.00006, loss_test:0.11570, lr:9.61e-03, fs:0.69461 (r=0.586,p=0.853),  time:59.604, tt:3218.611\n",
      "Ep:54, loss:0.00006, loss_test:0.11731, lr:9.61e-03, fs:0.68293 (r=0.566,p=0.862),  time:59.609, tt:3278.518\n",
      "Ep:55, loss:0.00005, loss_test:0.11609, lr:9.61e-03, fs:0.69461 (r=0.586,p=0.853),  time:59.606, tt:3337.961\n",
      "Ep:56, loss:0.00005, loss_test:0.11416, lr:9.61e-03, fs:0.73256 (r=0.636,p=0.863),  time:59.723, tt:3404.211\n",
      "Ep:57, loss:0.00005, loss_test:0.11549, lr:9.61e-03, fs:0.69461 (r=0.586,p=0.853),  time:59.774, tt:3466.871\n",
      "Ep:58, loss:0.00005, loss_test:0.11885, lr:9.61e-03, fs:0.68293 (r=0.566,p=0.862),  time:59.806, tt:3528.561\n",
      "Ep:59, loss:0.00005, loss_test:0.11761, lr:9.61e-03, fs:0.68712 (r=0.566,p=0.875),  time:59.902, tt:3594.113\n",
      "Ep:60, loss:0.00005, loss_test:0.12178, lr:9.51e-03, fs:0.68712 (r=0.566,p=0.875),  time:59.987, tt:3659.192\n",
      "Ep:61, loss:0.00005, loss_test:0.11557, lr:9.41e-03, fs:0.69461 (r=0.586,p=0.853),  time:60.001, tt:3720.065\n",
      "Ep:62, loss:0.00005, loss_test:0.11689, lr:9.32e-03, fs:0.68293 (r=0.566,p=0.862),  time:60.071, tt:3784.456\n",
      "Ep:63, loss:0.00004, loss_test:0.11761, lr:9.23e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.156, tt:3849.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00004, loss_test:0.12005, lr:9.14e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.150, tt:3909.726\n",
      "Ep:65, loss:0.00004, loss_test:0.11763, lr:9.04e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.153, tt:3970.076\n",
      "Ep:66, loss:0.00004, loss_test:0.11882, lr:8.95e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.162, tt:4030.867\n",
      "Ep:67, loss:0.00004, loss_test:0.11876, lr:8.86e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.170, tt:4091.551\n",
      "Ep:68, loss:0.00004, loss_test:0.11844, lr:8.78e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.134, tt:4149.234\n",
      "Ep:69, loss:0.00004, loss_test:0.11719, lr:8.69e-03, fs:0.68293 (r=0.566,p=0.862),  time:60.133, tt:4209.288\n",
      "Ep:70, loss:0.00004, loss_test:0.11967, lr:8.60e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.169, tt:4271.964\n",
      "Ep:71, loss:0.00004, loss_test:0.12109, lr:8.51e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.214, tt:4335.427\n",
      "Ep:72, loss:0.00004, loss_test:0.11931, lr:8.43e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.234, tt:4397.074\n",
      "Ep:73, loss:0.00004, loss_test:0.11743, lr:8.35e-03, fs:0.68293 (r=0.566,p=0.862),  time:60.271, tt:4460.018\n",
      "Ep:74, loss:0.00003, loss_test:0.12059, lr:8.26e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.305, tt:4522.861\n",
      "Ep:75, loss:0.00003, loss_test:0.11779, lr:8.18e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.320, tt:4584.299\n",
      "Ep:76, loss:0.00003, loss_test:0.12243, lr:8.10e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.316, tt:4644.354\n",
      "Ep:77, loss:0.00003, loss_test:0.11776, lr:8.02e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.302, tt:4703.521\n",
      "Ep:78, loss:0.00003, loss_test:0.12111, lr:7.94e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.301, tt:4763.796\n",
      "Ep:79, loss:0.00003, loss_test:0.11898, lr:7.86e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.297, tt:4823.745\n",
      "Ep:80, loss:0.00003, loss_test:0.12153, lr:7.78e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.307, tt:4884.891\n",
      "Ep:81, loss:0.00003, loss_test:0.11626, lr:7.70e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.308, tt:4945.239\n",
      "Ep:82, loss:0.00003, loss_test:0.12095, lr:7.62e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.297, tt:5004.658\n",
      "Ep:83, loss:0.00003, loss_test:0.11899, lr:7.55e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.281, tt:5063.624\n",
      "Ep:84, loss:0.00003, loss_test:0.11976, lr:7.47e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.300, tt:5125.458\n",
      "Ep:85, loss:0.00003, loss_test:0.11992, lr:7.40e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.297, tt:5185.533\n",
      "Ep:86, loss:0.00003, loss_test:0.11879, lr:7.32e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.302, tt:5246.242\n",
      "Ep:87, loss:0.00003, loss_test:0.11816, lr:7.25e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.291, tt:5305.585\n",
      "Ep:88, loss:0.00003, loss_test:0.11979, lr:7.18e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.321, tt:5368.608\n",
      "Ep:89, loss:0.00003, loss_test:0.11945, lr:7.11e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.339, tt:5430.515\n",
      "Ep:90, loss:0.00003, loss_test:0.11869, lr:7.03e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.355, tt:5492.310\n",
      "Ep:91, loss:0.00003, loss_test:0.11909, lr:6.96e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.379, tt:5554.892\n",
      "Ep:92, loss:0.00003, loss_test:0.11941, lr:6.89e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.378, tt:5615.170\n",
      "Ep:93, loss:0.00003, loss_test:0.11797, lr:6.83e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.409, tt:5678.469\n",
      "Ep:94, loss:0.00002, loss_test:0.11999, lr:6.76e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.404, tt:5738.336\n",
      "Ep:95, loss:0.00002, loss_test:0.11916, lr:6.69e-03, fs:0.69136 (r=0.566,p=0.889),  time:60.422, tt:5800.522\n",
      "Ep:96, loss:0.00002, loss_test:0.11890, lr:6.62e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.433, tt:5861.961\n",
      "Ep:97, loss:0.00002, loss_test:0.12059, lr:6.56e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.414, tt:5920.540\n",
      "Ep:98, loss:0.00002, loss_test:0.11943, lr:6.49e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.401, tt:5979.745\n",
      "Ep:99, loss:0.00002, loss_test:0.11912, lr:6.43e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.399, tt:6039.887\n",
      "Ep:100, loss:0.00002, loss_test:0.11938, lr:6.36e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.408, tt:6101.202\n",
      "Ep:101, loss:0.00002, loss_test:0.11891, lr:6.30e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.377, tt:6158.464\n",
      "Ep:102, loss:0.00002, loss_test:0.11924, lr:6.24e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.388, tt:6220.000\n",
      "Ep:103, loss:0.00002, loss_test:0.11873, lr:6.17e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.409, tt:6282.487\n",
      "Ep:104, loss:0.00002, loss_test:0.11899, lr:6.11e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.434, tt:6345.522\n",
      "Ep:105, loss:0.00002, loss_test:0.12005, lr:6.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.469, tt:6409.724\n",
      "Ep:106, loss:0.00002, loss_test:0.11858, lr:5.99e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.470, tt:6470.251\n",
      "Ep:107, loss:0.00002, loss_test:0.12003, lr:5.93e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.488, tt:6532.699\n",
      "Ep:108, loss:0.00002, loss_test:0.11995, lr:5.87e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.501, tt:6594.610\n",
      "Ep:109, loss:0.00002, loss_test:0.11879, lr:5.81e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.516, tt:6656.709\n",
      "Ep:110, loss:0.00002, loss_test:0.12081, lr:5.75e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.502, tt:6715.752\n",
      "Ep:111, loss:0.00002, loss_test:0.11842, lr:5.70e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.502, tt:6776.215\n",
      "Ep:112, loss:0.00002, loss_test:0.11857, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.497, tt:6836.110\n",
      "Ep:113, loss:0.00002, loss_test:0.12002, lr:5.58e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.488, tt:6895.629\n",
      "Ep:114, loss:0.00002, loss_test:0.11874, lr:5.53e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.481, tt:6955.320\n",
      "Ep:115, loss:0.00002, loss_test:0.12025, lr:5.47e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.505, tt:7018.591\n",
      "Ep:116, loss:0.00002, loss_test:0.11873, lr:5.42e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.511, tt:7079.766\n",
      "Ep:117, loss:0.00002, loss_test:0.11908, lr:5.36e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.512, tt:7140.363\n",
      "Ep:118, loss:0.00002, loss_test:0.11933, lr:5.31e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.528, tt:7202.803\n",
      "Ep:119, loss:0.00002, loss_test:0.11948, lr:5.26e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.525, tt:7263.054\n",
      "Ep:120, loss:0.00002, loss_test:0.11823, lr:5.20e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.533, tt:7324.463\n",
      "Ep:121, loss:0.00002, loss_test:0.12053, lr:5.15e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.535, tt:7385.286\n",
      "Ep:122, loss:0.00002, loss_test:0.11855, lr:5.10e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.534, tt:7445.726\n",
      "Ep:123, loss:0.00002, loss_test:0.11945, lr:5.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.540, tt:7506.904\n",
      "Ep:124, loss:0.00002, loss_test:0.11801, lr:5.00e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.544, tt:7567.964\n",
      "Ep:125, loss:0.00002, loss_test:0.11884, lr:4.95e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.540, tt:7628.014\n",
      "Ep:126, loss:0.00002, loss_test:0.11865, lr:4.90e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.538, tt:7688.338\n",
      "Ep:127, loss:0.00002, loss_test:0.11858, lr:4.85e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.541, tt:7749.252\n",
      "Ep:128, loss:0.00002, loss_test:0.11842, lr:4.80e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.535, tt:7808.975\n",
      "Ep:129, loss:0.00002, loss_test:0.11933, lr:4.75e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.528, tt:7868.630\n",
      "Ep:130, loss:0.00002, loss_test:0.11848, lr:4.71e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.543, tt:7931.084\n",
      "Ep:131, loss:0.00002, loss_test:0.11884, lr:4.66e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.537, tt:7990.931\n",
      "Ep:132, loss:0.00002, loss_test:0.11851, lr:4.61e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.553, tt:8053.614\n",
      "Ep:133, loss:0.00002, loss_test:0.11813, lr:4.57e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.565, tt:8115.741\n",
      "Ep:134, loss:0.00002, loss_test:0.11894, lr:4.52e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.562, tt:8175.820\n",
      "Ep:135, loss:0.00002, loss_test:0.11863, lr:4.48e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.569, tt:8237.366\n",
      "Ep:136, loss:0.00002, loss_test:0.11955, lr:4.43e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.557, tt:8296.241\n",
      "Ep:137, loss:0.00002, loss_test:0.11804, lr:4.39e-03, fs:0.69565 (r=0.566,p=0.903),  time:60.572, tt:8358.951\n",
      "Ep:138, loss:0.00002, loss_test:0.11931, lr:4.34e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.587, tt:8421.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00002, loss_test:0.11792, lr:4.30e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.602, tt:8484.266\n",
      "Ep:140, loss:0.00002, loss_test:0.11888, lr:4.26e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.606, tt:8545.453\n",
      "Ep:141, loss:0.00002, loss_test:0.11772, lr:4.21e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.618, tt:8607.788\n",
      "Ep:142, loss:0.00002, loss_test:0.11871, lr:4.17e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.630, tt:8670.059\n",
      "Ep:143, loss:0.00002, loss_test:0.11860, lr:4.13e-03, fs:0.70000 (r=0.566,p=0.918),  time:60.655, tt:8734.295\n",
      "Ep:144, loss:0.00002, loss_test:0.11836, lr:4.09e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.667, tt:8796.745\n",
      "Ep:145, loss:0.00001, loss_test:0.11864, lr:4.05e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.673, tt:8858.272\n",
      "Ep:146, loss:0.00001, loss_test:0.11827, lr:4.01e-03, fs:0.70886 (r=0.566,p=0.949),  time:60.699, tt:8922.784\n",
      "Ep:147, loss:0.00001, loss_test:0.11834, lr:3.97e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.727, tt:8987.619\n",
      "Ep:148, loss:0.00001, loss_test:0.11832, lr:3.93e-03, fs:0.70886 (r=0.566,p=0.949),  time:60.727, tt:9048.327\n",
      "Ep:149, loss:0.00001, loss_test:0.11837, lr:3.89e-03, fs:0.70440 (r=0.566,p=0.933),  time:60.694, tt:9104.105\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 31\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14446, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.303, tt:58.303\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14282, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.211, tt:106.421\n",
      "Ep:2, loss:0.00056, loss_test:0.13975, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:56.239, tt:168.716\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00054, loss_test:0.13386, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:57.763, tt:231.050\n",
      "Ep:4, loss:0.00051, loss_test:0.12521, lr:1.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:58.589, tt:292.945\n",
      "Ep:5, loss:0.00047, loss_test:0.12117, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:59.592, tt:357.553\n",
      "Ep:6, loss:0.00044, loss_test:0.12018, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:60.595, tt:424.168\n",
      "Ep:7, loss:0.00041, loss_test:0.11815, lr:1.00e-02, fs:0.66332 (r=0.667,p=0.660),  time:61.198, tt:489.582\n",
      "Ep:8, loss:0.00039, loss_test:0.11600, lr:1.00e-02, fs:0.65241 (r=0.616,p=0.693),  time:61.414, tt:552.726\n",
      "Ep:9, loss:0.00037, loss_test:0.11395, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:61.685, tt:616.853\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.11136, lr:1.00e-02, fs:0.67027 (r=0.626,p=0.721),  time:61.901, tt:680.911\n",
      "Ep:11, loss:0.00033, loss_test:0.10964, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:61.947, tt:743.370\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.10897, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:62.061, tt:806.790\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.10718, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:62.101, tt:869.420\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.10606, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:62.474, tt:937.106\n",
      "Ep:15, loss:0.00028, loss_test:0.10568, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:62.588, tt:1001.404\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.10624, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:62.643, tt:1064.934\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.10599, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:62.634, tt:1127.415\n",
      "Ep:18, loss:0.00025, loss_test:0.10678, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:62.725, tt:1191.771\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.10551, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:62.826, tt:1256.524\n",
      "Ep:20, loss:0.00023, loss_test:0.10508, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:62.942, tt:1321.783\n",
      "Ep:21, loss:0.00022, loss_test:0.10894, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:63.007, tt:1386.158\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.10617, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:63.065, tt:1450.491\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.10663, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:63.150, tt:1515.603\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.10846, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:63.206, tt:1580.147\n",
      "Ep:25, loss:0.00018, loss_test:0.10539, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:63.280, tt:1645.275\n",
      "Ep:26, loss:0.00018, loss_test:0.11193, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:63.396, tt:1711.698\n",
      "Ep:27, loss:0.00017, loss_test:0.10842, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:63.381, tt:1774.657\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.10631, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:63.419, tt:1839.150\n",
      "Ep:29, loss:0.00015, loss_test:0.11328, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:63.460, tt:1903.796\n",
      "Ep:30, loss:0.00014, loss_test:0.10952, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:63.509, tt:1968.791\n",
      "Ep:31, loss:0.00013, loss_test:0.10561, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:63.494, tt:2031.823\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.11313, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:63.690, tt:2101.785\n",
      "Ep:33, loss:0.00012, loss_test:0.11147, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:63.660, tt:2164.435\n",
      "Ep:34, loss:0.00011, loss_test:0.10753, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:63.692, tt:2229.206\n",
      "Ep:35, loss:0.00010, loss_test:0.11462, lr:1.00e-02, fs:0.74847 (r=0.616,p=0.953),  time:63.733, tt:2294.382\n",
      "Ep:36, loss:0.00010, loss_test:0.10855, lr:1.00e-02, fs:0.75294 (r=0.646,p=0.901),  time:63.725, tt:2357.833\n",
      "Ep:37, loss:0.00009, loss_test:0.10867, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:63.733, tt:2421.836\n",
      "Ep:38, loss:0.00009, loss_test:0.10875, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:63.784, tt:2487.574\n",
      "Ep:39, loss:0.00008, loss_test:0.11111, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:63.759, tt:2550.357\n",
      "Ep:40, loss:0.00008, loss_test:0.10940, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:63.721, tt:2612.573\n",
      "Ep:41, loss:0.00008, loss_test:0.11043, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:63.681, tt:2674.604\n",
      "Ep:42, loss:0.00008, loss_test:0.11160, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:63.722, tt:2740.064\n",
      "Ep:43, loss:0.00007, loss_test:0.10592, lr:9.90e-03, fs:0.75610 (r=0.626,p=0.954),  time:63.731, tt:2804.180\n",
      "Ep:44, loss:0.00007, loss_test:0.10698, lr:9.80e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.756, tt:2869.003\n",
      "Ep:45, loss:0.00007, loss_test:0.10689, lr:9.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.747, tt:2932.363\n",
      "Ep:46, loss:0.00006, loss_test:0.10878, lr:9.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.781, tt:2997.722\n",
      "Ep:47, loss:0.00006, loss_test:0.10679, lr:9.51e-03, fs:0.77576 (r=0.646,p=0.970),  time:63.802, tt:3062.501\n",
      "Ep:48, loss:0.00006, loss_test:0.10942, lr:9.41e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.753, tt:3123.888\n",
      "Ep:49, loss:0.00006, loss_test:0.10861, lr:9.32e-03, fs:0.76829 (r=0.636,p=0.969),  time:63.828, tt:3191.388\n",
      "Ep:50, loss:0.00006, loss_test:0.10771, lr:9.23e-03, fs:0.77576 (r=0.646,p=0.970),  time:63.860, tt:3256.864\n",
      "Ep:51, loss:0.00005, loss_test:0.10727, lr:9.14e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.900, tt:3322.799\n",
      "Ep:52, loss:0.00005, loss_test:0.10845, lr:9.04e-03, fs:0.75309 (r=0.616,p=0.968),  time:63.988, tt:3391.340\n",
      "Ep:53, loss:0.00005, loss_test:0.10675, lr:8.95e-03, fs:0.76074 (r=0.626,p=0.969),  time:64.001, tt:3456.031\n",
      "Ep:54, loss:0.00005, loss_test:0.10978, lr:8.86e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.974, tt:3518.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00005, loss_test:0.10842, lr:8.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:63.982, tt:3583.016\n",
      "Ep:56, loss:0.00004, loss_test:0.10651, lr:8.69e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.010, tt:3648.543\n",
      "Ep:57, loss:0.00004, loss_test:0.10867, lr:8.60e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.049, tt:3714.850\n",
      "Ep:58, loss:0.00004, loss_test:0.10941, lr:8.51e-03, fs:0.76074 (r=0.626,p=0.969),  time:64.085, tt:3781.031\n",
      "Ep:59, loss:0.00004, loss_test:0.11038, lr:8.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.101, tt:3846.053\n",
      "Ep:60, loss:0.00004, loss_test:0.10637, lr:8.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:64.143, tt:3912.725\n",
      "Ep:61, loss:0.00004, loss_test:0.11097, lr:8.26e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.128, tt:3975.961\n",
      "Ep:62, loss:0.00004, loss_test:0.10920, lr:8.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.138, tt:4040.686\n",
      "Ep:63, loss:0.00004, loss_test:0.11023, lr:8.10e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.181, tt:4107.581\n",
      "Ep:64, loss:0.00003, loss_test:0.10816, lr:8.02e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.192, tt:4172.488\n",
      "Ep:65, loss:0.00003, loss_test:0.11156, lr:7.94e-03, fs:0.76829 (r=0.636,p=0.969),  time:64.206, tt:4237.579\n",
      "Ep:66, loss:0.00003, loss_test:0.10863, lr:7.86e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.251, tt:4304.798\n",
      "Ep:67, loss:0.00003, loss_test:0.10994, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:64.241, tt:4368.369\n",
      "Ep:68, loss:0.00003, loss_test:0.10899, lr:7.70e-03, fs:0.76829 (r=0.636,p=0.969),  time:64.218, tt:4431.067\n",
      "Ep:69, loss:0.00003, loss_test:0.11093, lr:7.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.209, tt:4494.611\n",
      "Ep:70, loss:0.00003, loss_test:0.10897, lr:7.55e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.208, tt:4558.798\n",
      "Ep:71, loss:0.00003, loss_test:0.11118, lr:7.47e-03, fs:0.76829 (r=0.636,p=0.969),  time:64.208, tt:4623.001\n",
      "Ep:72, loss:0.00003, loss_test:0.10951, lr:7.40e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.187, tt:4685.676\n",
      "Ep:73, loss:0.00003, loss_test:0.11126, lr:7.32e-03, fs:0.72956 (r=0.586,p=0.967),  time:64.204, tt:4751.064\n",
      "Ep:74, loss:0.00003, loss_test:0.11002, lr:7.25e-03, fs:0.76829 (r=0.636,p=0.969),  time:64.167, tt:4812.516\n",
      "Ep:75, loss:0.00003, loss_test:0.11047, lr:7.18e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.162, tt:4876.292\n",
      "Ep:76, loss:0.00003, loss_test:0.10984, lr:7.11e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.175, tt:4941.464\n",
      "Ep:77, loss:0.00003, loss_test:0.11139, lr:7.03e-03, fs:0.74534 (r=0.606,p=0.968),  time:64.164, tt:5004.785\n",
      "Ep:78, loss:0.00003, loss_test:0.10970, lr:6.96e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.147, tt:5067.576\n",
      "Ep:79, loss:0.00002, loss_test:0.11245, lr:6.89e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.141, tt:5131.304\n",
      "Ep:80, loss:0.00002, loss_test:0.11101, lr:6.83e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.124, tt:5194.059\n",
      "Ep:81, loss:0.00002, loss_test:0.11261, lr:6.76e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.083, tt:5254.810\n",
      "Ep:82, loss:0.00002, loss_test:0.11009, lr:6.69e-03, fs:0.76074 (r=0.626,p=0.969),  time:64.074, tt:5318.110\n",
      "Ep:83, loss:0.00002, loss_test:0.11152, lr:6.62e-03, fs:0.74534 (r=0.606,p=0.968),  time:64.082, tt:5382.873\n",
      "Ep:84, loss:0.00002, loss_test:0.10992, lr:6.56e-03, fs:0.76074 (r=0.626,p=0.969),  time:64.085, tt:5447.256\n",
      "Ep:85, loss:0.00002, loss_test:0.11211, lr:6.49e-03, fs:0.73750 (r=0.596,p=0.967),  time:64.063, tt:5509.396\n",
      "Ep:86, loss:0.00002, loss_test:0.11083, lr:6.43e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.052, tt:5572.554\n",
      "Ep:87, loss:0.00002, loss_test:0.11024, lr:6.36e-03, fs:0.75309 (r=0.616,p=0.968),  time:64.053, tt:5636.662\n",
      "Ep:88, loss:0.00002, loss_test:0.11229, lr:6.30e-03, fs:0.72956 (r=0.586,p=0.967),  time:64.053, tt:5700.737\n",
      "Ep:89, loss:0.00002, loss_test:0.11167, lr:6.24e-03, fs:0.72956 (r=0.586,p=0.967),  time:64.061, tt:5765.526\n",
      "Ep:90, loss:0.00002, loss_test:0.11072, lr:6.17e-03, fs:0.74534 (r=0.606,p=0.968),  time:64.044, tt:5828.006\n",
      "Ep:91, loss:0.00002, loss_test:0.11193, lr:6.11e-03, fs:0.73750 (r=0.596,p=0.967),  time:64.052, tt:5892.826\n",
      "Ep:92, loss:0.00002, loss_test:0.11294, lr:6.05e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.038, tt:5955.505\n",
      "Ep:93, loss:0.00002, loss_test:0.11110, lr:5.99e-03, fs:0.73750 (r=0.596,p=0.967),  time:64.047, tt:6020.436\n",
      "Ep:94, loss:0.00002, loss_test:0.11383, lr:5.93e-03, fs:0.70886 (r=0.566,p=0.949),  time:64.061, tt:6085.834\n",
      "Ep:95, loss:0.00002, loss_test:0.11148, lr:5.87e-03, fs:0.72956 (r=0.586,p=0.967),  time:64.068, tt:6150.485\n",
      "Ep:96, loss:0.00002, loss_test:0.11321, lr:5.81e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.091, tt:6216.812\n",
      "Ep:97, loss:0.00002, loss_test:0.11204, lr:5.75e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.086, tt:6280.404\n",
      "Ep:98, loss:0.00002, loss_test:0.11228, lr:5.70e-03, fs:0.73750 (r=0.596,p=0.967),  time:64.098, tt:6345.661\n",
      "Ep:99, loss:0.00002, loss_test:0.11307, lr:5.64e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.118, tt:6411.776\n",
      "Ep:100, loss:0.00002, loss_test:0.11186, lr:5.58e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.123, tt:6476.435\n",
      "Ep:101, loss:0.00002, loss_test:0.11248, lr:5.53e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.124, tt:6540.662\n",
      "Ep:102, loss:0.00002, loss_test:0.11265, lr:5.47e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.117, tt:6604.050\n",
      "Ep:103, loss:0.00002, loss_test:0.11221, lr:5.42e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.117, tt:6668.168\n",
      "Ep:104, loss:0.00001, loss_test:0.11297, lr:5.36e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.141, tt:6734.759\n",
      "Ep:105, loss:0.00001, loss_test:0.11230, lr:5.31e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.140, tt:6798.834\n",
      "Ep:106, loss:0.00001, loss_test:0.11297, lr:5.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.129, tt:6861.758\n",
      "Ep:107, loss:0.00001, loss_test:0.11321, lr:5.20e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.128, tt:6925.789\n",
      "Ep:108, loss:0.00001, loss_test:0.11271, lr:5.15e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.126, tt:6989.724\n",
      "Ep:109, loss:0.00001, loss_test:0.11327, lr:5.10e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.119, tt:7053.079\n",
      "Ep:110, loss:0.00001, loss_test:0.11279, lr:5.05e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.118, tt:7117.082\n",
      "Ep:111, loss:0.00001, loss_test:0.11394, lr:5.00e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.102, tt:7179.458\n",
      "Ep:112, loss:0.00001, loss_test:0.11279, lr:4.95e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.099, tt:7243.188\n",
      "Ep:113, loss:0.00001, loss_test:0.11394, lr:4.90e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.079, tt:7304.988\n",
      "Ep:114, loss:0.00001, loss_test:0.11307, lr:4.85e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.060, tt:7366.936\n",
      "Ep:115, loss:0.00001, loss_test:0.11354, lr:4.80e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.056, tt:7430.455\n",
      "Ep:116, loss:0.00001, loss_test:0.11375, lr:4.75e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.039, tt:7492.586\n",
      "Ep:117, loss:0.00001, loss_test:0.11353, lr:4.71e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.045, tt:7557.333\n",
      "Ep:118, loss:0.00001, loss_test:0.11335, lr:4.66e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.015, tt:7617.804\n",
      "Ep:119, loss:0.00001, loss_test:0.11379, lr:4.61e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.988, tt:7678.579\n",
      "Ep:120, loss:0.00001, loss_test:0.11356, lr:4.57e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.991, tt:7742.878\n",
      "Ep:121, loss:0.00001, loss_test:0.11296, lr:4.52e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.013, tt:7809.572\n",
      "Ep:122, loss:0.00001, loss_test:0.11362, lr:4.48e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.990, tt:7870.738\n",
      "Ep:123, loss:0.00001, loss_test:0.11337, lr:4.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.975, tt:7932.895\n",
      "Ep:124, loss:0.00001, loss_test:0.11378, lr:4.39e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.956, tt:7994.442\n",
      "Ep:125, loss:0.00001, loss_test:0.11332, lr:4.34e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.942, tt:8056.641\n",
      "Ep:126, loss:0.00001, loss_test:0.11447, lr:4.30e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.922, tt:8118.154\n",
      "Ep:127, loss:0.00001, loss_test:0.11337, lr:4.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.910, tt:8180.458\n",
      "Ep:128, loss:0.00001, loss_test:0.11398, lr:4.21e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.897, tt:8242.713\n",
      "Ep:129, loss:0.00001, loss_test:0.11428, lr:4.17e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.873, tt:8303.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00001, loss_test:0.11375, lr:4.13e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.859, tt:8365.468\n",
      "Ep:131, loss:0.00001, loss_test:0.11416, lr:4.09e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.867, tt:8430.485\n",
      "Ep:132, loss:0.00001, loss_test:0.11386, lr:4.05e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.857, tt:8492.924\n",
      "Ep:133, loss:0.00001, loss_test:0.11473, lr:4.01e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.839, tt:8554.424\n",
      "Ep:134, loss:0.00001, loss_test:0.11368, lr:3.97e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.837, tt:8618.015\n",
      "Ep:135, loss:0.00001, loss_test:0.11538, lr:3.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.816, tt:8678.935\n",
      "Ep:136, loss:0.00001, loss_test:0.11403, lr:3.89e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.800, tt:8740.645\n",
      "Ep:137, loss:0.00001, loss_test:0.11562, lr:3.85e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.772, tt:8800.569\n",
      "Ep:138, loss:0.00001, loss_test:0.11374, lr:3.81e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.764, tt:8863.204\n",
      "Ep:139, loss:0.00001, loss_test:0.11558, lr:3.77e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.754, tt:8925.527\n",
      "Ep:140, loss:0.00001, loss_test:0.11419, lr:3.73e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.728, tt:8985.591\n",
      "Ep:141, loss:0.00001, loss_test:0.11518, lr:3.70e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.721, tt:9048.409\n",
      "Ep:142, loss:0.00001, loss_test:0.11448, lr:3.66e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.700, tt:9109.064\n",
      "Ep:143, loss:0.00001, loss_test:0.11507, lr:3.62e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.681, tt:9170.066\n",
      "Ep:144, loss:0.00001, loss_test:0.11494, lr:3.59e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.663, tt:9231.134\n",
      "Ep:145, loss:0.00001, loss_test:0.11491, lr:3.55e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.650, tt:9292.965\n",
      "Ep:146, loss:0.00001, loss_test:0.11464, lr:3.52e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.621, tt:9352.240\n",
      "Ep:147, loss:0.00001, loss_test:0.11512, lr:3.48e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.616, tt:9415.220\n",
      "Ep:148, loss:0.00001, loss_test:0.11513, lr:3.45e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.591, tt:9475.079\n",
      "Ep:149, loss:0.00001, loss_test:0.11587, lr:3.41e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.571, tt:9535.650\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 32\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14599, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.604, tt:58.604\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14468, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.895, tt:115.790\n",
      "Ep:2, loss:0.00056, loss_test:0.14233, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.544, tt:169.633\n",
      "Ep:3, loss:0.00054, loss_test:0.13804, lr:1.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:58.192, tt:232.768\n",
      "Ep:4, loss:0.00051, loss_test:0.13006, lr:1.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:58.982, tt:294.912\n",
      "Ep:5, loss:0.00047, loss_test:0.12639, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:59.564, tt:357.386\n",
      "Ep:6, loss:0.00044, loss_test:0.12394, lr:1.00e-02, fs:0.62559 (r=0.667,p=0.589),  time:60.132, tt:420.926\n",
      "Ep:7, loss:0.00042, loss_test:0.12053, lr:1.00e-02, fs:0.63889 (r=0.697,p=0.590),  time:60.294, tt:482.349\n",
      "Ep:8, loss:0.00040, loss_test:0.11697, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:60.482, tt:544.337\n",
      "Ep:9, loss:0.00038, loss_test:0.11320, lr:1.00e-02, fs:0.65094 (r=0.697,p=0.611),  time:60.876, tt:608.760\n",
      "Ep:10, loss:0.00036, loss_test:0.11101, lr:1.00e-02, fs:0.65686 (r=0.677,p=0.638),  time:60.942, tt:670.365\n",
      "Ep:11, loss:0.00034, loss_test:0.10940, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:61.210, tt:734.520\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00033, loss_test:0.10788, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:61.434, tt:798.646\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.10526, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:61.655, tt:863.172\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.10408, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:61.690, tt:925.349\n",
      "Ep:15, loss:0.00029, loss_test:0.10272, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:61.877, tt:990.037\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.10063, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:61.958, tt:1053.290\n",
      "Ep:17, loss:0.00027, loss_test:0.09976, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:62.111, tt:1118.003\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.09843, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:62.230, tt:1182.365\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.09791, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:62.273, tt:1245.462\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.09794, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:62.294, tt:1308.180\n",
      "Ep:21, loss:0.00023, loss_test:0.09596, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:62.299, tt:1370.587\n",
      "Ep:22, loss:0.00022, loss_test:0.09805, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:62.277, tt:1432.374\n",
      "Ep:23, loss:0.00021, loss_test:0.09559, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:62.375, tt:1497.009\n",
      "Ep:24, loss:0.00020, loss_test:0.09692, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:62.455, tt:1561.367\n",
      "Ep:25, loss:0.00019, loss_test:0.09786, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:62.469, tt:1624.194\n",
      "Ep:26, loss:0.00018, loss_test:0.09687, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:62.547, tt:1688.781\n",
      "Ep:27, loss:0.00017, loss_test:0.09541, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:62.527, tt:1750.752\n",
      "Ep:28, loss:0.00016, loss_test:0.09801, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:62.531, tt:1813.395\n",
      "Ep:29, loss:0.00015, loss_test:0.09627, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:62.478, tt:1874.342\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09811, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:62.524, tt:1938.251\n",
      "Ep:31, loss:0.00013, loss_test:0.09630, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:62.567, tt:2002.154\n",
      "Ep:32, loss:0.00012, loss_test:0.09834, lr:1.00e-02, fs:0.69613 (r=0.636,p=0.768),  time:62.528, tt:2063.430\n",
      "Ep:33, loss:0.00012, loss_test:0.09918, lr:1.00e-02, fs:0.65517 (r=0.576,p=0.760),  time:62.537, tt:2126.273\n",
      "Ep:34, loss:0.00011, loss_test:0.09893, lr:1.00e-02, fs:0.64368 (r=0.566,p=0.747),  time:62.599, tt:2190.953\n",
      "Ep:35, loss:0.00011, loss_test:0.09816, lr:1.00e-02, fs:0.69274 (r=0.626,p=0.775),  time:62.714, tt:2257.700\n",
      "Ep:36, loss:0.00010, loss_test:0.10045, lr:1.00e-02, fs:0.65517 (r=0.576,p=0.760),  time:62.789, tt:2323.203\n",
      "Ep:37, loss:0.00010, loss_test:0.10014, lr:1.00e-02, fs:0.63953 (r=0.556,p=0.753),  time:62.882, tt:2389.502\n",
      "Ep:38, loss:0.00009, loss_test:0.10346, lr:1.00e-02, fs:0.63415 (r=0.525,p=0.800),  time:62.913, tt:2453.621\n",
      "Ep:39, loss:0.00009, loss_test:0.09975, lr:1.00e-02, fs:0.66667 (r=0.596,p=0.756),  time:62.949, tt:2517.977\n",
      "Ep:40, loss:0.00008, loss_test:0.10342, lr:1.00e-02, fs:0.62275 (r=0.525,p=0.765),  time:63.012, tt:2583.479\n",
      "Ep:41, loss:0.00008, loss_test:0.10338, lr:9.90e-03, fs:0.63030 (r=0.525,p=0.788),  time:63.038, tt:2647.610\n",
      "Ep:42, loss:0.00008, loss_test:0.10204, lr:9.80e-03, fs:0.64286 (r=0.545,p=0.783),  time:63.093, tt:2713.001\n",
      "Ep:43, loss:0.00007, loss_test:0.10688, lr:9.70e-03, fs:0.64151 (r=0.515,p=0.850),  time:63.147, tt:2778.448\n",
      "Ep:44, loss:0.00007, loss_test:0.10373, lr:9.61e-03, fs:0.62651 (r=0.525,p=0.776),  time:63.199, tt:2843.972\n",
      "Ep:45, loss:0.00007, loss_test:0.10264, lr:9.51e-03, fs:0.63473 (r=0.535,p=0.779),  time:63.225, tt:2908.331\n",
      "Ep:46, loss:0.00007, loss_test:0.10685, lr:9.41e-03, fs:0.64198 (r=0.525,p=0.825),  time:63.267, tt:2973.550\n",
      "Ep:47, loss:0.00006, loss_test:0.10477, lr:9.32e-03, fs:0.65031 (r=0.535,p=0.828),  time:63.283, tt:3037.601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00006, loss_test:0.10583, lr:9.23e-03, fs:0.63804 (r=0.525,p=0.812),  time:63.273, tt:3100.385\n",
      "Ep:49, loss:0.00006, loss_test:0.10743, lr:9.14e-03, fs:0.63030 (r=0.525,p=0.788),  time:63.312, tt:3165.625\n",
      "Ep:50, loss:0.00006, loss_test:0.10471, lr:9.04e-03, fs:0.64242 (r=0.535,p=0.803),  time:63.325, tt:3229.551\n",
      "Ep:51, loss:0.00005, loss_test:0.10896, lr:8.95e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.352, tt:3294.318\n",
      "Ep:52, loss:0.00005, loss_test:0.10746, lr:8.86e-03, fs:0.65031 (r=0.535,p=0.828),  time:63.354, tt:3357.741\n",
      "Ep:53, loss:0.00005, loss_test:0.10636, lr:8.78e-03, fs:0.64242 (r=0.535,p=0.803),  time:63.358, tt:3421.332\n",
      "Ep:54, loss:0.00005, loss_test:0.10711, lr:8.69e-03, fs:0.65031 (r=0.535,p=0.828),  time:63.353, tt:3484.427\n",
      "Ep:55, loss:0.00005, loss_test:0.10829, lr:8.60e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.359, tt:3548.123\n",
      "Ep:56, loss:0.00005, loss_test:0.10842, lr:8.51e-03, fs:0.64634 (r=0.535,p=0.815),  time:63.347, tt:3610.766\n",
      "Ep:57, loss:0.00004, loss_test:0.10864, lr:8.43e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.341, tt:3673.805\n",
      "Ep:58, loss:0.00004, loss_test:0.10797, lr:8.35e-03, fs:0.65031 (r=0.535,p=0.828),  time:63.291, tt:3734.180\n",
      "Ep:59, loss:0.00004, loss_test:0.10801, lr:8.26e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.260, tt:3795.575\n",
      "Ep:60, loss:0.00004, loss_test:0.10963, lr:8.18e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.249, tt:3858.187\n",
      "Ep:61, loss:0.00004, loss_test:0.11215, lr:8.10e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.233, tt:3920.415\n",
      "Ep:62, loss:0.00004, loss_test:0.11045, lr:8.02e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.232, tt:3983.638\n",
      "Ep:63, loss:0.00004, loss_test:0.10908, lr:7.94e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.259, tt:4048.605\n",
      "Ep:64, loss:0.00004, loss_test:0.11098, lr:7.86e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.273, tt:4112.769\n",
      "Ep:65, loss:0.00004, loss_test:0.10984, lr:7.78e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.285, tt:4176.796\n",
      "Ep:66, loss:0.00003, loss_test:0.10918, lr:7.70e-03, fs:0.65432 (r=0.535,p=0.841),  time:63.291, tt:4240.527\n",
      "Ep:67, loss:0.00003, loss_test:0.11202, lr:7.62e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.273, tt:4302.578\n",
      "Ep:68, loss:0.00003, loss_test:0.11080, lr:7.55e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.264, tt:4365.241\n",
      "Ep:69, loss:0.00003, loss_test:0.10917, lr:7.47e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.255, tt:4427.816\n",
      "Ep:70, loss:0.00003, loss_test:0.11282, lr:7.40e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.216, tt:4488.347\n",
      "Ep:71, loss:0.00003, loss_test:0.11100, lr:7.32e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.205, tt:4550.766\n",
      "Ep:72, loss:0.00003, loss_test:0.11018, lr:7.25e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.184, tt:4612.429\n",
      "Ep:73, loss:0.00003, loss_test:0.11322, lr:7.18e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.188, tt:4675.888\n",
      "Ep:74, loss:0.00003, loss_test:0.10925, lr:7.11e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.198, tt:4739.815\n",
      "Ep:75, loss:0.00003, loss_test:0.11374, lr:7.03e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.217, tt:4804.486\n",
      "Ep:76, loss:0.00003, loss_test:0.11232, lr:6.96e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.209, tt:4867.093\n",
      "Ep:77, loss:0.00003, loss_test:0.11133, lr:6.89e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.215, tt:4930.752\n",
      "Ep:78, loss:0.00003, loss_test:0.11440, lr:6.83e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.215, tt:4993.996\n",
      "Ep:79, loss:0.00003, loss_test:0.11011, lr:6.76e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.214, tt:5057.111\n",
      "Ep:80, loss:0.00003, loss_test:0.11310, lr:6.69e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.198, tt:5119.011\n",
      "Ep:81, loss:0.00002, loss_test:0.11144, lr:6.62e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.200, tt:5182.408\n",
      "Ep:82, loss:0.00002, loss_test:0.11116, lr:6.56e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.177, tt:5243.670\n",
      "Ep:83, loss:0.00002, loss_test:0.11341, lr:6.49e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.169, tt:5306.197\n",
      "Ep:84, loss:0.00002, loss_test:0.11049, lr:6.43e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.154, tt:5368.099\n",
      "Ep:85, loss:0.00002, loss_test:0.11367, lr:6.36e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.144, tt:5430.418\n",
      "Ep:86, loss:0.00002, loss_test:0.11152, lr:6.30e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.168, tt:5495.606\n",
      "Ep:87, loss:0.00002, loss_test:0.11280, lr:6.24e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.168, tt:5558.746\n",
      "Ep:88, loss:0.00002, loss_test:0.11034, lr:6.17e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.136, tt:5619.113\n",
      "Ep:89, loss:0.00002, loss_test:0.11331, lr:6.11e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.132, tt:5681.904\n",
      "Ep:90, loss:0.00002, loss_test:0.11223, lr:6.05e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.125, tt:5744.415\n",
      "Ep:91, loss:0.00002, loss_test:0.11232, lr:5.99e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.153, tt:5810.038\n",
      "Ep:92, loss:0.00002, loss_test:0.11375, lr:5.93e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.171, tt:5874.873\n",
      "Ep:93, loss:0.00002, loss_test:0.11056, lr:5.87e-03, fs:0.65839 (r=0.535,p=0.855),  time:63.174, tt:5938.360\n",
      "Ep:94, loss:0.00002, loss_test:0.11291, lr:5.81e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.176, tt:6001.722\n",
      "Ep:95, loss:0.00002, loss_test:0.11259, lr:5.75e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.165, tt:6063.869\n",
      "Ep:96, loss:0.00002, loss_test:0.11214, lr:5.70e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.176, tt:6128.061\n",
      "Ep:97, loss:0.00002, loss_test:0.11190, lr:5.64e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.182, tt:6191.868\n",
      "Ep:98, loss:0.00002, loss_test:0.11249, lr:5.58e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.188, tt:6255.567\n",
      "Ep:99, loss:0.00002, loss_test:0.11363, lr:5.53e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.190, tt:6318.969\n",
      "Ep:100, loss:0.00002, loss_test:0.11291, lr:5.47e-03, fs:0.66250 (r=0.535,p=0.869),  time:63.207, tt:6383.915\n",
      "Ep:101, loss:0.00002, loss_test:0.11310, lr:5.42e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.207, tt:6447.151\n",
      "Ep:102, loss:0.00002, loss_test:0.11268, lr:5.36e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.200, tt:6509.550\n",
      "Ep:103, loss:0.00002, loss_test:0.11193, lr:5.31e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.208, tt:6573.674\n",
      "Ep:104, loss:0.00002, loss_test:0.11327, lr:5.26e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.218, tt:6637.878\n",
      "Ep:105, loss:0.00002, loss_test:0.11238, lr:5.20e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.212, tt:6700.449\n",
      "Ep:106, loss:0.00002, loss_test:0.11483, lr:5.15e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.207, tt:6763.108\n",
      "Ep:107, loss:0.00002, loss_test:0.11292, lr:5.10e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.201, tt:6825.683\n",
      "Ep:108, loss:0.00002, loss_test:0.11411, lr:5.05e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.197, tt:6888.458\n",
      "Ep:109, loss:0.00002, loss_test:0.11298, lr:5.00e-03, fs:0.66667 (r=0.535,p=0.883),  time:63.189, tt:6950.821\n",
      "Ep:110, loss:0.00002, loss_test:0.11278, lr:4.95e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.176, tt:7012.538\n",
      "Ep:111, loss:0.00002, loss_test:0.11474, lr:4.90e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.184, tt:7076.584\n",
      "Ep:112, loss:0.00002, loss_test:0.11249, lr:4.85e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.179, tt:7139.211\n",
      "Ep:113, loss:0.00002, loss_test:0.11320, lr:4.80e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.177, tt:7202.194\n",
      "Ep:114, loss:0.00001, loss_test:0.11390, lr:4.75e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.173, tt:7264.912\n",
      "Ep:115, loss:0.00001, loss_test:0.11291, lr:4.71e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.175, tt:7328.279\n",
      "Ep:116, loss:0.00001, loss_test:0.11402, lr:4.66e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.155, tt:7389.093\n",
      "Ep:117, loss:0.00001, loss_test:0.11220, lr:4.61e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.144, tt:7450.972\n",
      "Ep:118, loss:0.00001, loss_test:0.11460, lr:4.57e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.141, tt:7513.727\n",
      "Ep:119, loss:0.00001, loss_test:0.11271, lr:4.52e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.134, tt:7576.119\n",
      "Ep:120, loss:0.00001, loss_test:0.11378, lr:4.48e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.149, tt:7641.003\n",
      "Ep:121, loss:0.00001, loss_test:0.11340, lr:4.43e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.142, tt:7703.278\n",
      "Ep:122, loss:0.00001, loss_test:0.11344, lr:4.39e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.135, tt:7765.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00001, loss_test:0.11381, lr:4.34e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.126, tt:7827.668\n",
      "Ep:124, loss:0.00001, loss_test:0.11328, lr:4.30e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.123, tt:7890.315\n",
      "Ep:125, loss:0.00001, loss_test:0.11373, lr:4.26e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.106, tt:7951.417\n",
      "Ep:126, loss:0.00001, loss_test:0.11404, lr:4.21e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.105, tt:8014.352\n",
      "Ep:127, loss:0.00001, loss_test:0.11429, lr:4.17e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.105, tt:8077.475\n",
      "Ep:128, loss:0.00001, loss_test:0.11403, lr:4.13e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.096, tt:8139.366\n",
      "Ep:129, loss:0.00001, loss_test:0.11410, lr:4.09e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.086, tt:8201.222\n",
      "Ep:130, loss:0.00001, loss_test:0.11404, lr:4.05e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.087, tt:8264.349\n",
      "Ep:131, loss:0.00001, loss_test:0.11386, lr:4.01e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.087, tt:8327.451\n",
      "Ep:132, loss:0.00001, loss_test:0.11389, lr:3.97e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.090, tt:8390.927\n",
      "Ep:133, loss:0.00001, loss_test:0.11365, lr:3.93e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.075, tt:8452.037\n",
      "Ep:134, loss:0.00001, loss_test:0.11382, lr:3.89e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.058, tt:8512.824\n",
      "Ep:135, loss:0.00001, loss_test:0.11407, lr:3.85e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.057, tt:8575.691\n",
      "Ep:136, loss:0.00001, loss_test:0.11463, lr:3.81e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.051, tt:8638.026\n",
      "Ep:137, loss:0.00001, loss_test:0.11357, lr:3.77e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.087, tt:8705.969\n",
      "Ep:138, loss:0.00001, loss_test:0.11562, lr:3.73e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.108, tt:8772.071\n",
      "Ep:139, loss:0.00001, loss_test:0.11343, lr:3.70e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.119, tt:8836.709\n",
      "Ep:140, loss:0.00001, loss_test:0.11491, lr:3.66e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.119, tt:8899.751\n",
      "Ep:141, loss:0.00001, loss_test:0.11413, lr:3.62e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.127, tt:8963.994\n",
      "Ep:142, loss:0.00001, loss_test:0.11460, lr:3.59e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.144, tt:9029.641\n",
      "Ep:143, loss:0.00001, loss_test:0.11448, lr:3.55e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.170, tt:9096.412\n",
      "Ep:144, loss:0.00001, loss_test:0.11474, lr:3.52e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.179, tt:9160.951\n",
      "Ep:145, loss:0.00001, loss_test:0.11485, lr:3.48e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.201, tt:9227.281\n",
      "Ep:146, loss:0.00001, loss_test:0.11464, lr:3.45e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.211, tt:9291.983\n",
      "Ep:147, loss:0.00001, loss_test:0.11461, lr:3.41e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.196, tt:9353.074\n",
      "Ep:148, loss:0.00001, loss_test:0.11480, lr:3.38e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.213, tt:9418.768\n",
      "Ep:149, loss:0.00001, loss_test:0.11469, lr:3.34e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.156, tt:9473.439\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 33\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14854, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.484, tt:57.484\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14771, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.787, tt:115.574\n",
      "Ep:2, loss:0.00055, loss_test:0.14608, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.958, tt:176.873\n",
      "Ep:3, loss:0.00053, loss_test:0.14235, lr:1.00e-02, fs:0.63415 (r=0.919,p=0.484),  time:60.222, tt:240.889\n",
      "Ep:4, loss:0.00050, loss_test:0.13295, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:61.391, tt:306.957\n",
      "Ep:5, loss:0.00045, loss_test:0.12936, lr:1.00e-02, fs:0.62000 (r=0.626,p=0.614),  time:62.287, tt:373.720\n",
      "Ep:6, loss:0.00043, loss_test:0.12497, lr:1.00e-02, fs:0.64186 (r=0.697,p=0.595),  time:62.962, tt:440.731\n",
      "Ep:7, loss:0.00041, loss_test:0.12084, lr:1.00e-02, fs:0.66667 (r=0.717,p=0.623),  time:63.743, tt:509.946\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.11794, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:63.950, tt:575.551\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.11422, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:63.887, tt:638.865\n",
      "Ep:10, loss:0.00035, loss_test:0.11054, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:63.999, tt:703.984\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.10857, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:63.674, tt:764.089\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.10712, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:63.334, tt:823.347\n",
      "Ep:13, loss:0.00031, loss_test:0.10652, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:63.086, tt:883.203\n",
      "Ep:14, loss:0.00030, loss_test:0.10411, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:62.939, tt:944.088\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.10327, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:62.819, tt:1005.101\n",
      "Ep:16, loss:0.00027, loss_test:0.10307, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:62.741, tt:1066.592\n",
      "Ep:17, loss:0.00026, loss_test:0.10140, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:62.741, tt:1129.346\n",
      "Ep:18, loss:0.00025, loss_test:0.10206, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:62.686, tt:1191.025\n",
      "Ep:19, loss:0.00024, loss_test:0.10025, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:62.806, tt:1256.120\n",
      "Ep:20, loss:0.00023, loss_test:0.10272, lr:1.00e-02, fs:0.70391 (r=0.636,p=0.787),  time:62.761, tt:1317.991\n",
      "Ep:21, loss:0.00022, loss_test:0.10073, lr:1.00e-02, fs:0.70330 (r=0.646,p=0.771),  time:62.810, tt:1381.830\n",
      "Ep:22, loss:0.00021, loss_test:0.10004, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:62.885, tt:1446.352\n",
      "Ep:23, loss:0.00020, loss_test:0.10050, lr:1.00e-02, fs:0.71111 (r=0.646,p=0.790),  time:62.992, tt:1511.800\n",
      "Ep:24, loss:0.00019, loss_test:0.10001, lr:1.00e-02, fs:0.70000 (r=0.636,p=0.778),  time:62.996, tt:1574.910\n",
      "Ep:25, loss:0.00018, loss_test:0.09942, lr:1.00e-02, fs:0.71910 (r=0.646,p=0.810),  time:63.029, tt:1638.761\n",
      "Ep:26, loss:0.00017, loss_test:0.10102, lr:9.90e-03, fs:0.70930 (r=0.616,p=0.836),  time:63.049, tt:1702.325\n",
      "Ep:27, loss:0.00016, loss_test:0.10244, lr:9.80e-03, fs:0.71429 (r=0.606,p=0.870),  time:63.081, tt:1766.278\n",
      "Ep:28, loss:0.00016, loss_test:0.10130, lr:9.70e-03, fs:0.70238 (r=0.596,p=0.855),  time:63.156, tt:1831.513\n",
      "Ep:29, loss:0.00015, loss_test:0.10143, lr:9.61e-03, fs:0.70238 (r=0.596,p=0.855),  time:63.122, tt:1893.649\n",
      "Ep:30, loss:0.00014, loss_test:0.10016, lr:9.51e-03, fs:0.69822 (r=0.596,p=0.843),  time:63.191, tt:1958.908\n",
      "Ep:31, loss:0.00014, loss_test:0.10204, lr:9.41e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.184, tt:2021.883\n",
      "Ep:32, loss:0.00013, loss_test:0.10087, lr:9.32e-03, fs:0.71856 (r=0.606,p=0.882),  time:63.236, tt:2086.802\n",
      "Ep:33, loss:0.00012, loss_test:0.10334, lr:9.23e-03, fs:0.69939 (r=0.576,p=0.891),  time:63.211, tt:2149.161\n",
      "Ep:34, loss:0.00012, loss_test:0.10420, lr:9.14e-03, fs:0.64557 (r=0.515,p=0.864),  time:63.231, tt:2213.076\n",
      "Ep:35, loss:0.00011, loss_test:0.10373, lr:9.04e-03, fs:0.67089 (r=0.535,p=0.898),  time:63.267, tt:2277.616\n",
      "Ep:36, loss:0.00011, loss_test:0.10016, lr:8.95e-03, fs:0.70303 (r=0.586,p=0.879),  time:63.289, tt:2341.694\n",
      "Ep:37, loss:0.00010, loss_test:0.10149, lr:8.86e-03, fs:0.70807 (r=0.576,p=0.919),  time:63.292, tt:2405.089\n",
      "Ep:38, loss:0.00010, loss_test:0.10244, lr:8.78e-03, fs:0.68354 (r=0.545,p=0.915),  time:63.321, tt:2469.515\n",
      "Ep:39, loss:0.00009, loss_test:0.10257, lr:8.69e-03, fs:0.67949 (r=0.535,p=0.930),  time:63.352, tt:2534.066\n",
      "Ep:40, loss:0.00009, loss_test:0.10414, lr:8.60e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.368, tt:2598.098\n",
      "Ep:41, loss:0.00009, loss_test:0.10226, lr:8.51e-03, fs:0.66242 (r=0.525,p=0.897),  time:63.435, tt:2664.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00008, loss_test:0.10292, lr:8.43e-03, fs:0.67516 (r=0.535,p=0.914),  time:63.399, tt:2726.171\n",
      "Ep:43, loss:0.00008, loss_test:0.10367, lr:8.35e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.419, tt:2790.438\n",
      "Ep:44, loss:0.00008, loss_test:0.10322, lr:8.26e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.410, tt:2853.456\n",
      "Ep:45, loss:0.00007, loss_test:0.10351, lr:8.18e-03, fs:0.65806 (r=0.515,p=0.911),  time:63.444, tt:2918.435\n",
      "Ep:46, loss:0.00007, loss_test:0.10572, lr:8.10e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.455, tt:2982.378\n",
      "Ep:47, loss:0.00007, loss_test:0.10250, lr:8.02e-03, fs:0.67949 (r=0.535,p=0.930),  time:63.449, tt:3045.562\n",
      "Ep:48, loss:0.00007, loss_test:0.10505, lr:7.94e-03, fs:0.69677 (r=0.545,p=0.964),  time:63.429, tt:3108.035\n",
      "Ep:49, loss:0.00007, loss_test:0.10671, lr:7.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:63.447, tt:3172.367\n",
      "Ep:50, loss:0.00006, loss_test:0.10325, lr:7.78e-03, fs:0.64474 (r=0.495,p=0.925),  time:63.460, tt:3236.454\n",
      "Ep:51, loss:0.00006, loss_test:0.10767, lr:7.70e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.475, tt:3300.701\n",
      "Ep:52, loss:0.00006, loss_test:0.10562, lr:7.62e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.482, tt:3364.552\n",
      "Ep:53, loss:0.00006, loss_test:0.10600, lr:7.55e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.529, tt:3430.564\n",
      "Ep:54, loss:0.00006, loss_test:0.10604, lr:7.47e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.539, tt:3494.667\n",
      "Ep:55, loss:0.00005, loss_test:0.10564, lr:7.40e-03, fs:0.66667 (r=0.515,p=0.944),  time:63.558, tt:3559.225\n",
      "Ep:56, loss:0.00005, loss_test:0.10588, lr:7.32e-03, fs:0.67105 (r=0.515,p=0.962),  time:63.548, tt:3622.245\n",
      "Ep:57, loss:0.00005, loss_test:0.10703, lr:7.25e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.541, tt:3685.355\n",
      "Ep:58, loss:0.00005, loss_test:0.10578, lr:7.18e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.557, tt:3749.890\n",
      "Ep:59, loss:0.00005, loss_test:0.10614, lr:7.11e-03, fs:0.67532 (r=0.525,p=0.945),  time:63.542, tt:3812.518\n",
      "Ep:60, loss:0.00005, loss_test:0.10774, lr:7.03e-03, fs:0.65772 (r=0.495,p=0.980),  time:63.525, tt:3875.005\n",
      "Ep:61, loss:0.00005, loss_test:0.10750, lr:6.96e-03, fs:0.64474 (r=0.495,p=0.925),  time:63.558, tt:3940.570\n",
      "Ep:62, loss:0.00005, loss_test:0.10731, lr:6.89e-03, fs:0.64000 (r=0.485,p=0.941),  time:63.568, tt:4004.809\n",
      "Ep:63, loss:0.00004, loss_test:0.10792, lr:6.83e-03, fs:0.68831 (r=0.535,p=0.964),  time:63.583, tt:4069.304\n",
      "Ep:64, loss:0.00004, loss_test:0.10895, lr:6.76e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.632, tt:4136.111\n",
      "Ep:65, loss:0.00004, loss_test:0.10724, lr:6.69e-03, fs:0.64901 (r=0.495,p=0.942),  time:63.641, tt:4200.302\n",
      "Ep:66, loss:0.00004, loss_test:0.10965, lr:6.62e-03, fs:0.67974 (r=0.525,p=0.963),  time:63.651, tt:4264.605\n",
      "Ep:67, loss:0.00004, loss_test:0.10797, lr:6.56e-03, fs:0.64000 (r=0.485,p=0.941),  time:63.639, tt:4327.481\n",
      "Ep:68, loss:0.00004, loss_test:0.11081, lr:6.49e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.643, tt:4391.399\n",
      "Ep:69, loss:0.00004, loss_test:0.10855, lr:6.43e-03, fs:0.67550 (r=0.515,p=0.981),  time:63.645, tt:4455.119\n",
      "Ep:70, loss:0.00004, loss_test:0.10964, lr:6.36e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.669, tt:4520.523\n",
      "Ep:71, loss:0.00004, loss_test:0.10960, lr:6.30e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.691, tt:4585.722\n",
      "Ep:72, loss:0.00004, loss_test:0.11000, lr:6.24e-03, fs:0.66667 (r=0.505,p=0.980),  time:63.678, tt:4648.506\n",
      "Ep:73, loss:0.00004, loss_test:0.10930, lr:6.17e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.714, tt:4714.869\n",
      "Ep:74, loss:0.00003, loss_test:0.11018, lr:6.11e-03, fs:0.65772 (r=0.495,p=0.980),  time:63.719, tt:4778.935\n",
      "Ep:75, loss:0.00003, loss_test:0.11102, lr:6.05e-03, fs:0.68421 (r=0.525,p=0.981),  time:63.746, tt:4844.663\n",
      "Ep:76, loss:0.00003, loss_test:0.11089, lr:5.99e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.748, tt:4908.591\n",
      "Ep:77, loss:0.00003, loss_test:0.11222, lr:5.93e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.755, tt:4972.883\n",
      "Ep:78, loss:0.00003, loss_test:0.11112, lr:5.87e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.773, tt:5038.105\n",
      "Ep:79, loss:0.00003, loss_test:0.11242, lr:5.81e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.784, tt:5102.736\n",
      "Ep:80, loss:0.00003, loss_test:0.11109, lr:5.75e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.790, tt:5167.012\n",
      "Ep:81, loss:0.00003, loss_test:0.11256, lr:5.70e-03, fs:0.64865 (r=0.485,p=0.980),  time:63.816, tt:5232.919\n",
      "Ep:82, loss:0.00003, loss_test:0.11088, lr:5.64e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.811, tt:5296.294\n",
      "Ep:83, loss:0.00003, loss_test:0.11239, lr:5.58e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.855, tt:5363.805\n",
      "Ep:84, loss:0.00003, loss_test:0.11220, lr:5.53e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.862, tt:5428.264\n",
      "Ep:85, loss:0.00003, loss_test:0.11211, lr:5.47e-03, fs:0.64865 (r=0.485,p=0.980),  time:63.904, tt:5495.726\n",
      "Ep:86, loss:0.00003, loss_test:0.11158, lr:5.42e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.923, tt:5561.266\n",
      "Ep:87, loss:0.00003, loss_test:0.11393, lr:5.36e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.953, tt:5627.886\n",
      "Ep:88, loss:0.00003, loss_test:0.11179, lr:5.31e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.970, tt:5693.368\n",
      "Ep:89, loss:0.00003, loss_test:0.11360, lr:5.26e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.960, tt:5756.390\n",
      "Ep:90, loss:0.00003, loss_test:0.11185, lr:5.20e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.951, tt:5819.584\n",
      "Ep:91, loss:0.00002, loss_test:0.11454, lr:5.15e-03, fs:0.64865 (r=0.485,p=0.980),  time:63.942, tt:5882.675\n",
      "Ep:92, loss:0.00002, loss_test:0.11239, lr:5.10e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.942, tt:5946.627\n",
      "Ep:93, loss:0.00002, loss_test:0.11458, lr:5.05e-03, fs:0.64865 (r=0.485,p=0.980),  time:63.948, tt:6011.092\n",
      "Ep:94, loss:0.00002, loss_test:0.11321, lr:5.00e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.963, tt:6076.475\n",
      "Ep:95, loss:0.00002, loss_test:0.11427, lr:4.95e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.949, tt:6139.087\n",
      "Ep:96, loss:0.00002, loss_test:0.11378, lr:4.90e-03, fs:0.64865 (r=0.485,p=0.980),  time:63.967, tt:6204.802\n",
      "Ep:97, loss:0.00002, loss_test:0.11411, lr:4.85e-03, fs:0.64430 (r=0.485,p=0.960),  time:63.991, tt:6271.084\n",
      "Ep:98, loss:0.00002, loss_test:0.11374, lr:4.80e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.004, tt:6336.415\n",
      "Ep:99, loss:0.00002, loss_test:0.11473, lr:4.75e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.017, tt:6401.654\n",
      "Ep:100, loss:0.00002, loss_test:0.11489, lr:4.71e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.010, tt:6465.001\n",
      "Ep:101, loss:0.00002, loss_test:0.11444, lr:4.66e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.034, tt:6531.432\n",
      "Ep:102, loss:0.00002, loss_test:0.11558, lr:4.61e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.034, tt:6595.528\n",
      "Ep:103, loss:0.00002, loss_test:0.11490, lr:4.57e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.014, tt:6657.479\n",
      "Ep:104, loss:0.00002, loss_test:0.11485, lr:4.52e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.009, tt:6720.979\n",
      "Ep:105, loss:0.00002, loss_test:0.11492, lr:4.48e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.032, tt:6787.438\n",
      "Ep:106, loss:0.00002, loss_test:0.11513, lr:4.43e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.036, tt:6851.810\n",
      "Ep:107, loss:0.00002, loss_test:0.11506, lr:4.39e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.052, tt:6917.605\n",
      "Ep:108, loss:0.00002, loss_test:0.11583, lr:4.34e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.067, tt:6983.354\n",
      "Ep:109, loss:0.00002, loss_test:0.11475, lr:4.30e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.089, tt:7049.757\n",
      "Ep:110, loss:0.00002, loss_test:0.11587, lr:4.26e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.103, tt:7115.419\n",
      "Ep:111, loss:0.00002, loss_test:0.11680, lr:4.21e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.098, tt:7178.930\n",
      "Ep:112, loss:0.00002, loss_test:0.11508, lr:4.17e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.101, tt:7243.381\n",
      "Ep:113, loss:0.00002, loss_test:0.11770, lr:4.13e-03, fs:0.64865 (r=0.485,p=0.980),  time:64.119, tt:7309.543\n",
      "Ep:114, loss:0.00002, loss_test:0.11616, lr:4.09e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.106, tt:7372.167\n",
      "Ep:115, loss:0.00002, loss_test:0.11716, lr:4.05e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.118, tt:7437.641\n",
      "Ep:116, loss:0.00002, loss_test:0.11678, lr:4.01e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.121, tt:7502.144\n",
      "Ep:117, loss:0.00002, loss_test:0.11665, lr:3.97e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.109, tt:7564.836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:118, loss:0.00002, loss_test:0.11761, lr:3.93e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.126, tt:7631.043\n",
      "Ep:119, loss:0.00002, loss_test:0.11724, lr:3.89e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.131, tt:7695.699\n",
      "Ep:120, loss:0.00002, loss_test:0.11722, lr:3.85e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.148, tt:7761.871\n",
      "Ep:121, loss:0.00002, loss_test:0.11780, lr:3.81e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.156, tt:7826.995\n",
      "Ep:122, loss:0.00002, loss_test:0.11720, lr:3.77e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.193, tt:7895.762\n",
      "Ep:123, loss:0.00002, loss_test:0.11805, lr:3.73e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.216, tt:7962.814\n",
      "Ep:124, loss:0.00002, loss_test:0.11815, lr:3.70e-03, fs:0.64865 (r=0.485,p=0.980),  time:64.219, tt:8027.382\n",
      "Ep:125, loss:0.00002, loss_test:0.11764, lr:3.66e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.237, tt:8093.877\n",
      "Ep:126, loss:0.00002, loss_test:0.11872, lr:3.62e-03, fs:0.64865 (r=0.485,p=0.980),  time:64.231, tt:8157.392\n",
      "Ep:127, loss:0.00002, loss_test:0.11806, lr:3.59e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.239, tt:8222.568\n",
      "Ep:128, loss:0.00002, loss_test:0.11835, lr:3.55e-03, fs:0.64865 (r=0.485,p=0.980),  time:64.219, tt:8284.246\n",
      "Ep:129, loss:0.00002, loss_test:0.11854, lr:3.52e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.223, tt:8348.941\n",
      "Ep:130, loss:0.00001, loss_test:0.11912, lr:3.48e-03, fs:0.64865 (r=0.485,p=0.980),  time:64.219, tt:8412.713\n",
      "Ep:131, loss:0.00001, loss_test:0.11851, lr:3.45e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.218, tt:8476.747\n",
      "Ep:132, loss:0.00001, loss_test:0.11937, lr:3.41e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.227, tt:8542.138\n",
      "Ep:133, loss:0.00001, loss_test:0.11821, lr:3.38e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.212, tt:8604.470\n",
      "Ep:134, loss:0.00001, loss_test:0.11917, lr:3.34e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.219, tt:8669.596\n",
      "Ep:136, loss:0.00001, loss_test:0.11861, lr:3.28e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.189, tt:8793.835\n",
      "Ep:137, loss:0.00001, loss_test:0.11876, lr:3.24e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.190, tt:8858.250\n",
      "Ep:138, loss:0.00001, loss_test:0.11817, lr:3.21e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.187, tt:8921.980\n",
      "Ep:139, loss:0.00001, loss_test:0.11952, lr:3.18e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.172, tt:8984.123\n",
      "Ep:140, loss:0.00001, loss_test:0.11853, lr:3.15e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.167, tt:9047.590\n",
      "Ep:141, loss:0.00001, loss_test:0.11976, lr:3.12e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.153, tt:9109.694\n",
      "Ep:142, loss:0.00001, loss_test:0.11918, lr:3.09e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.146, tt:9172.944\n",
      "Ep:143, loss:0.00001, loss_test:0.11898, lr:3.05e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.147, tt:9237.097\n",
      "Ep:144, loss:0.00001, loss_test:0.11971, lr:3.02e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.147, tt:9301.344\n",
      "Ep:145, loss:0.00001, loss_test:0.11954, lr:2.99e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.151, tt:9366.067\n",
      "Ep:146, loss:0.00001, loss_test:0.11999, lr:2.96e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.115, tt:9424.922\n",
      "Ep:148, loss:0.00001, loss_test:0.11981, lr:2.90e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.104, tt:9551.445\n",
      "Ep:149, loss:0.00001, loss_test:0.11938, lr:2.88e-03, fs:0.64430 (r=0.485,p=0.960),  time:64.043, tt:9606.491\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 34\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14332, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:55.745, tt:55.745\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14145, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.823, tt:115.647\n",
      "Ep:2, loss:0.00056, loss_test:0.13811, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.422, tt:172.266\n",
      "Ep:3, loss:0.00054, loss_test:0.13148, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:59.027, tt:236.110\n",
      "Ep:4, loss:0.00051, loss_test:0.12062, lr:1.00e-02, fs:0.66397 (r=0.828,p=0.554),  time:60.362, tt:301.812\n",
      "Ep:5, loss:0.00047, loss_test:0.11583, lr:1.00e-02, fs:0.70297 (r=0.717,p=0.689),  time:60.999, tt:365.996\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.11267, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:61.539, tt:430.774\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.10878, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:61.673, tt:493.384\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.10641, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:61.998, tt:557.979\n",
      "Ep:9, loss:0.00037, loss_test:0.10293, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:62.147, tt:621.474\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.10319, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:62.340, tt:685.734\n",
      "Ep:11, loss:0.00033, loss_test:0.10342, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:62.325, tt:747.894\n",
      "Ep:12, loss:0.00032, loss_test:0.10301, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:62.683, tt:814.880\n",
      "Ep:13, loss:0.00030, loss_test:0.10389, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:62.682, tt:877.544\n",
      "Ep:14, loss:0.00029, loss_test:0.10373, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:62.745, tt:941.173\n",
      "Ep:15, loss:0.00028, loss_test:0.10536, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:62.835, tt:1005.352\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.10448, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:62.880, tt:1068.962\n",
      "Ep:17, loss:0.00025, loss_test:0.10474, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:62.864, tt:1131.551\n",
      "Ep:18, loss:0.00024, loss_test:0.10551, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:63.104, tt:1198.974\n",
      "Ep:19, loss:0.00023, loss_test:0.10721, lr:1.00e-02, fs:0.71038 (r=0.657,p=0.774),  time:63.081, tt:1261.629\n",
      "Ep:20, loss:0.00022, loss_test:0.10692, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:63.078, tt:1324.631\n",
      "Ep:21, loss:0.00022, loss_test:0.10503, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:63.080, tt:1387.754\n",
      "Ep:22, loss:0.00021, loss_test:0.10414, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:63.112, tt:1451.570\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.10982, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:63.169, tt:1516.062\n",
      "Ep:24, loss:0.00019, loss_test:0.10582, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:63.122, tt:1578.061\n",
      "Ep:25, loss:0.00018, loss_test:0.10721, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:63.089, tt:1640.311\n",
      "Ep:26, loss:0.00017, loss_test:0.11019, lr:1.00e-02, fs:0.67797 (r=0.606,p=0.769),  time:63.169, tt:1705.562\n",
      "Ep:27, loss:0.00016, loss_test:0.10675, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:63.167, tt:1768.680\n",
      "Ep:28, loss:0.00015, loss_test:0.10838, lr:1.00e-02, fs:0.70391 (r=0.636,p=0.787),  time:63.198, tt:1832.739\n",
      "Ep:29, loss:0.00014, loss_test:0.10973, lr:1.00e-02, fs:0.69318 (r=0.616,p=0.792),  time:63.154, tt:1894.626\n",
      "Ep:30, loss:0.00014, loss_test:0.10733, lr:1.00e-02, fs:0.70391 (r=0.636,p=0.787),  time:63.257, tt:1960.974\n",
      "Ep:31, loss:0.00013, loss_test:0.10778, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:63.348, tt:2027.133\n",
      "Ep:32, loss:0.00012, loss_test:0.11305, lr:1.00e-02, fs:0.64242 (r=0.535,p=0.803),  time:63.321, tt:2089.584\n",
      "Ep:33, loss:0.00012, loss_test:0.10464, lr:1.00e-02, fs:0.71823 (r=0.657,p=0.793),  time:63.398, tt:2155.520\n",
      "Ep:34, loss:0.00011, loss_test:0.10718, lr:9.90e-03, fs:0.69663 (r=0.626,p=0.785),  time:63.362, tt:2217.687\n",
      "Ep:35, loss:0.00011, loss_test:0.11006, lr:9.80e-03, fs:0.65060 (r=0.545,p=0.806),  time:63.433, tt:2283.586\n",
      "Ep:36, loss:0.00010, loss_test:0.10634, lr:9.70e-03, fs:0.71591 (r=0.636,p=0.818),  time:63.423, tt:2346.633\n",
      "Ep:37, loss:0.00010, loss_test:0.11116, lr:9.61e-03, fs:0.61818 (r=0.515,p=0.773),  time:63.481, tt:2412.272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00009, loss_test:0.11019, lr:9.51e-03, fs:0.63804 (r=0.525,p=0.812),  time:63.480, tt:2475.727\n",
      "Ep:39, loss:0.00009, loss_test:0.10506, lr:9.41e-03, fs:0.71910 (r=0.646,p=0.810),  time:63.509, tt:2540.346\n",
      "Ep:40, loss:0.00008, loss_test:0.11231, lr:9.32e-03, fs:0.66258 (r=0.545,p=0.844),  time:63.541, tt:2605.181\n",
      "Ep:41, loss:0.00008, loss_test:0.10798, lr:9.23e-03, fs:0.64286 (r=0.545,p=0.783),  time:63.488, tt:2666.485\n",
      "Ep:42, loss:0.00008, loss_test:0.10824, lr:9.14e-03, fs:0.65868 (r=0.556,p=0.809),  time:63.486, tt:2729.909\n",
      "Ep:43, loss:0.00007, loss_test:0.10958, lr:9.04e-03, fs:0.64198 (r=0.525,p=0.825),  time:63.531, tt:2795.384\n",
      "Ep:44, loss:0.00007, loss_test:0.11177, lr:8.95e-03, fs:0.60000 (r=0.485,p=0.787),  time:63.561, tt:2860.259\n",
      "Ep:45, loss:0.00007, loss_test:0.11010, lr:8.86e-03, fs:0.60000 (r=0.485,p=0.787),  time:63.570, tt:2924.238\n",
      "Ep:46, loss:0.00006, loss_test:0.11308, lr:8.78e-03, fs:0.61538 (r=0.485,p=0.842),  time:63.593, tt:2988.881\n",
      "Ep:47, loss:0.00006, loss_test:0.10823, lr:8.69e-03, fs:0.62577 (r=0.515,p=0.797),  time:63.617, tt:3053.593\n",
      "Ep:48, loss:0.00006, loss_test:0.11141, lr:8.60e-03, fs:0.62500 (r=0.505,p=0.820),  time:63.639, tt:3118.308\n",
      "Ep:49, loss:0.00006, loss_test:0.11032, lr:8.51e-03, fs:0.61728 (r=0.505,p=0.794),  time:63.672, tt:3183.603\n",
      "Ep:50, loss:0.00006, loss_test:0.10972, lr:8.43e-03, fs:0.60870 (r=0.495,p=0.790),  time:63.623, tt:3244.770\n",
      "Ep:51, loss:0.00005, loss_test:0.11220, lr:8.35e-03, fs:0.60377 (r=0.485,p=0.800),  time:63.632, tt:3308.857\n",
      "Ep:52, loss:0.00005, loss_test:0.11429, lr:8.26e-03, fs:0.60377 (r=0.485,p=0.800),  time:63.642, tt:3373.003\n",
      "Ep:53, loss:0.00005, loss_test:0.10931, lr:8.18e-03, fs:0.61250 (r=0.495,p=0.803),  time:63.652, tt:3437.223\n",
      "Ep:54, loss:0.00005, loss_test:0.11107, lr:8.10e-03, fs:0.62500 (r=0.505,p=0.820),  time:63.657, tt:3501.127\n",
      "Ep:55, loss:0.00005, loss_test:0.10978, lr:8.02e-03, fs:0.62112 (r=0.505,p=0.806),  time:63.654, tt:3564.602\n",
      "Ep:56, loss:0.00005, loss_test:0.11429, lr:7.94e-03, fs:0.61146 (r=0.485,p=0.828),  time:63.668, tt:3629.102\n",
      "Ep:57, loss:0.00004, loss_test:0.11286, lr:7.86e-03, fs:0.59873 (r=0.475,p=0.810),  time:63.651, tt:3691.734\n",
      "Ep:58, loss:0.00004, loss_test:0.11075, lr:7.78e-03, fs:0.61250 (r=0.495,p=0.803),  time:63.666, tt:3756.316\n",
      "Ep:59, loss:0.00004, loss_test:0.11347, lr:7.70e-03, fs:0.61146 (r=0.485,p=0.828),  time:63.672, tt:3820.327\n",
      "Ep:60, loss:0.00004, loss_test:0.11103, lr:7.62e-03, fs:0.60870 (r=0.495,p=0.790),  time:63.638, tt:3881.903\n",
      "Ep:61, loss:0.00004, loss_test:0.11591, lr:7.55e-03, fs:0.59873 (r=0.475,p=0.810),  time:63.637, tt:3945.486\n",
      "Ep:62, loss:0.00004, loss_test:0.11160, lr:7.47e-03, fs:0.60377 (r=0.485,p=0.800),  time:63.621, tt:4008.101\n",
      "Ep:63, loss:0.00004, loss_test:0.11367, lr:7.40e-03, fs:0.60759 (r=0.485,p=0.814),  time:63.651, tt:4073.696\n",
      "Ep:64, loss:0.00004, loss_test:0.11299, lr:7.32e-03, fs:0.61146 (r=0.485,p=0.828),  time:63.665, tt:4138.212\n",
      "Ep:65, loss:0.00004, loss_test:0.11187, lr:7.25e-03, fs:0.62025 (r=0.495,p=0.831),  time:63.666, tt:4201.983\n",
      "Ep:66, loss:0.00004, loss_test:0.11338, lr:7.18e-03, fs:0.60759 (r=0.485,p=0.814),  time:63.653, tt:4264.751\n",
      "Ep:67, loss:0.00003, loss_test:0.11197, lr:7.11e-03, fs:0.61146 (r=0.485,p=0.828),  time:63.676, tt:4329.997\n",
      "Ep:68, loss:0.00003, loss_test:0.11300, lr:7.03e-03, fs:0.61146 (r=0.485,p=0.828),  time:63.734, tt:4397.661\n",
      "Ep:69, loss:0.00003, loss_test:0.11458, lr:6.96e-03, fs:0.60256 (r=0.475,p=0.825),  time:63.776, tt:4464.344\n",
      "Ep:70, loss:0.00003, loss_test:0.11412, lr:6.89e-03, fs:0.60645 (r=0.475,p=0.839),  time:63.790, tt:4529.056\n",
      "Ep:71, loss:0.00003, loss_test:0.11070, lr:6.83e-03, fs:0.62112 (r=0.505,p=0.806),  time:63.823, tt:4595.256\n",
      "Ep:72, loss:0.00003, loss_test:0.11457, lr:6.76e-03, fs:0.60256 (r=0.475,p=0.825),  time:63.908, tt:4665.312\n",
      "Ep:73, loss:0.00003, loss_test:0.11274, lr:6.69e-03, fs:0.61039 (r=0.475,p=0.855),  time:63.965, tt:4733.383\n",
      "Ep:74, loss:0.00003, loss_test:0.11402, lr:6.62e-03, fs:0.60645 (r=0.475,p=0.839),  time:64.075, tt:4805.594\n",
      "Ep:75, loss:0.00003, loss_test:0.11415, lr:6.56e-03, fs:0.60645 (r=0.475,p=0.839),  time:64.175, tt:4877.325\n",
      "Ep:76, loss:0.00003, loss_test:0.11323, lr:6.49e-03, fs:0.60645 (r=0.475,p=0.839),  time:64.272, tt:4948.950\n",
      "Ep:77, loss:0.00003, loss_test:0.11494, lr:6.43e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.342, tt:5018.713\n",
      "Ep:78, loss:0.00003, loss_test:0.11447, lr:6.36e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.382, tt:5086.160\n",
      "Ep:79, loss:0.00003, loss_test:0.11293, lr:6.30e-03, fs:0.61438 (r=0.475,p=0.870),  time:64.439, tt:5155.147\n",
      "Ep:80, loss:0.00003, loss_test:0.11479, lr:6.24e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.467, tt:5221.790\n",
      "Ep:81, loss:0.00003, loss_test:0.11301, lr:6.17e-03, fs:0.60645 (r=0.475,p=0.839),  time:64.491, tt:5288.242\n",
      "Ep:82, loss:0.00002, loss_test:0.11385, lr:6.11e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.537, tt:5356.557\n",
      "Ep:83, loss:0.00002, loss_test:0.11458, lr:6.05e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.595, tt:5425.957\n",
      "Ep:84, loss:0.00002, loss_test:0.11228, lr:5.99e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.595, tt:5490.584\n",
      "Ep:85, loss:0.00002, loss_test:0.11520, lr:5.93e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.619, tt:5557.204\n",
      "Ep:86, loss:0.00002, loss_test:0.11357, lr:5.87e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.643, tt:5623.942\n",
      "Ep:87, loss:0.00002, loss_test:0.11333, lr:5.81e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.663, tt:5690.305\n",
      "Ep:88, loss:0.00002, loss_test:0.11588, lr:5.75e-03, fs:0.61438 (r=0.475,p=0.870),  time:64.691, tt:5757.472\n",
      "Ep:89, loss:0.00002, loss_test:0.11293, lr:5.70e-03, fs:0.61438 (r=0.475,p=0.870),  time:64.725, tt:5825.227\n",
      "Ep:90, loss:0.00002, loss_test:0.11579, lr:5.64e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.768, tt:5893.853\n",
      "Ep:91, loss:0.00002, loss_test:0.11367, lr:5.58e-03, fs:0.61438 (r=0.475,p=0.870),  time:64.816, tt:5963.068\n",
      "Ep:92, loss:0.00002, loss_test:0.11474, lr:5.53e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.849, tt:6030.949\n",
      "Ep:93, loss:0.00002, loss_test:0.11440, lr:5.47e-03, fs:0.61039 (r=0.475,p=0.855),  time:64.893, tt:6099.953\n",
      "Ep:94, loss:0.00002, loss_test:0.11405, lr:5.42e-03, fs:0.61438 (r=0.475,p=0.870),  time:64.912, tt:6166.670\n",
      "Ep:95, loss:0.00002, loss_test:0.11509, lr:5.36e-03, fs:0.61842 (r=0.475,p=0.887),  time:64.940, tt:6234.261\n",
      "Ep:96, loss:0.00002, loss_test:0.11550, lr:5.31e-03, fs:0.61842 (r=0.475,p=0.887),  time:64.964, tt:6301.469\n",
      "Ep:97, loss:0.00002, loss_test:0.11435, lr:5.26e-03, fs:0.61842 (r=0.475,p=0.887),  time:64.987, tt:6368.713\n",
      "Ep:98, loss:0.00002, loss_test:0.11602, lr:5.20e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.029, tt:6437.864\n",
      "Ep:99, loss:0.00002, loss_test:0.11544, lr:5.15e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.063, tt:6506.267\n",
      "Ep:100, loss:0.00002, loss_test:0.11598, lr:5.10e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.111, tt:6576.188\n",
      "Ep:101, loss:0.00002, loss_test:0.11499, lr:5.05e-03, fs:0.61842 (r=0.475,p=0.887),  time:65.108, tt:6640.983\n",
      "Ep:102, loss:0.00002, loss_test:0.11573, lr:5.00e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.139, tt:6709.358\n",
      "Ep:103, loss:0.00002, loss_test:0.11541, lr:4.95e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.191, tt:6779.865\n",
      "Ep:104, loss:0.00002, loss_test:0.11500, lr:4.90e-03, fs:0.61842 (r=0.475,p=0.887),  time:65.240, tt:6850.199\n",
      "Ep:105, loss:0.00002, loss_test:0.11587, lr:4.85e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.263, tt:6917.917\n",
      "Ep:106, loss:0.00002, loss_test:0.11636, lr:4.80e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.291, tt:6986.112\n",
      "Ep:107, loss:0.00002, loss_test:0.11507, lr:4.75e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.306, tt:7053.051\n",
      "Ep:108, loss:0.00002, loss_test:0.11688, lr:4.71e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.355, tt:7123.674\n",
      "Ep:109, loss:0.00002, loss_test:0.11531, lr:4.66e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.369, tt:7190.546\n",
      "Ep:110, loss:0.00002, loss_test:0.11617, lr:4.61e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.413, tt:7260.860\n",
      "Ep:111, loss:0.00002, loss_test:0.11648, lr:4.57e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.447, tt:7330.103\n",
      "Ep:112, loss:0.00001, loss_test:0.11534, lr:4.52e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.490, tt:7400.318\n",
      "Ep:113, loss:0.00001, loss_test:0.11748, lr:4.48e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.527, tt:7470.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00001, loss_test:0.11535, lr:4.43e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.567, tt:7540.204\n",
      "Ep:115, loss:0.00001, loss_test:0.11655, lr:4.39e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.593, tt:7608.743\n",
      "Ep:116, loss:0.00001, loss_test:0.11677, lr:4.34e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.635, tt:7679.345\n",
      "Ep:117, loss:0.00001, loss_test:0.11659, lr:4.30e-03, fs:0.61039 (r=0.475,p=0.855),  time:65.667, tt:7748.744\n",
      "Ep:118, loss:0.00001, loss_test:0.11779, lr:4.26e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.681, tt:7816.020\n",
      "Ep:119, loss:0.00001, loss_test:0.11666, lr:4.21e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.700, tt:7883.972\n",
      "Ep:120, loss:0.00001, loss_test:0.11664, lr:4.17e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.731, tt:7953.447\n",
      "Ep:121, loss:0.00001, loss_test:0.11735, lr:4.13e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.782, tt:8025.378\n",
      "Ep:122, loss:0.00001, loss_test:0.11749, lr:4.09e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.812, tt:8094.845\n",
      "Ep:123, loss:0.00001, loss_test:0.11670, lr:4.05e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.827, tt:8162.581\n",
      "Ep:124, loss:0.00001, loss_test:0.11796, lr:4.01e-03, fs:0.61039 (r=0.475,p=0.855),  time:65.862, tt:8232.713\n",
      "Ep:125, loss:0.00001, loss_test:0.11786, lr:3.97e-03, fs:0.61842 (r=0.475,p=0.887),  time:65.899, tt:8303.332\n",
      "Ep:126, loss:0.00001, loss_test:0.11784, lr:3.93e-03, fs:0.61039 (r=0.475,p=0.855),  time:65.915, tt:8371.212\n",
      "Ep:127, loss:0.00001, loss_test:0.11787, lr:3.89e-03, fs:0.61438 (r=0.475,p=0.870),  time:65.962, tt:8443.195\n",
      "Ep:128, loss:0.00001, loss_test:0.11809, lr:3.85e-03, fs:0.61039 (r=0.475,p=0.855),  time:66.001, tt:8514.127\n",
      "Ep:129, loss:0.00001, loss_test:0.11824, lr:3.81e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.047, tt:8586.146\n",
      "Ep:130, loss:0.00001, loss_test:0.11747, lr:3.77e-03, fs:0.61039 (r=0.475,p=0.855),  time:66.073, tt:8655.601\n",
      "Ep:131, loss:0.00001, loss_test:0.11856, lr:3.73e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.120, tt:8727.817\n",
      "Ep:132, loss:0.00001, loss_test:0.11819, lr:3.70e-03, fs:0.61039 (r=0.475,p=0.855),  time:66.152, tt:8798.249\n",
      "Ep:133, loss:0.00001, loss_test:0.11840, lr:3.66e-03, fs:0.61842 (r=0.475,p=0.887),  time:66.209, tt:8872.008\n",
      "Ep:134, loss:0.00001, loss_test:0.11879, lr:3.62e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.249, tt:8943.597\n",
      "Ep:135, loss:0.00001, loss_test:0.11803, lr:3.59e-03, fs:0.61039 (r=0.475,p=0.855),  time:66.281, tt:9014.169\n",
      "Ep:138, loss:0.00001, loss_test:0.11850, lr:3.48e-03, fs:0.61039 (r=0.475,p=0.855),  time:66.378, tt:9226.608\n",
      "Ep:139, loss:0.00001, loss_test:0.11927, lr:3.45e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.410, tt:9297.350\n",
      "Ep:140, loss:0.00001, loss_test:0.11872, lr:3.41e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.442, tt:9368.265\n",
      "Ep:141, loss:0.00001, loss_test:0.11955, lr:3.38e-03, fs:0.62252 (r=0.475,p=0.904),  time:66.475, tt:9439.487\n",
      "Ep:142, loss:0.00001, loss_test:0.11892, lr:3.34e-03, fs:0.61842 (r=0.475,p=0.887),  time:66.502, tt:9509.723\n",
      "Ep:143, loss:0.00001, loss_test:0.11952, lr:3.31e-03, fs:0.62252 (r=0.475,p=0.904),  time:66.523, tt:9579.282\n",
      "Ep:144, loss:0.00001, loss_test:0.11947, lr:3.28e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.560, tt:9651.152\n",
      "Ep:145, loss:0.00001, loss_test:0.11975, lr:3.24e-03, fs:0.62667 (r=0.475,p=0.922),  time:66.566, tt:9718.681\n",
      "Ep:146, loss:0.00001, loss_test:0.11975, lr:3.21e-03, fs:0.61438 (r=0.475,p=0.870),  time:66.591, tt:9788.875\n",
      "Ep:147, loss:0.00001, loss_test:0.11966, lr:3.18e-03, fs:0.62667 (r=0.475,p=0.922),  time:66.601, tt:9856.970\n",
      "Ep:148, loss:0.00001, loss_test:0.11976, lr:3.15e-03, fs:0.61842 (r=0.475,p=0.887),  time:66.642, tt:9929.664\n",
      "Ep:149, loss:0.00001, loss_test:0.12103, lr:3.12e-03, fs:0.62667 (r=0.475,p=0.922),  time:66.611, tt:9991.719\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 35\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14510, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.032, tt:57.032\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14359, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.437, tt:118.874\n",
      "Ep:2, loss:0.00055, loss_test:0.14069, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:57.566, tt:172.698\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.13469, lr:1.00e-02, fs:0.64057 (r=0.909,p=0.495),  time:59.173, tt:236.694\n",
      "Ep:4, loss:0.00050, loss_test:0.12637, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:59.845, tt:299.225\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.12646, lr:1.00e-02, fs:0.57292 (r=0.556,p=0.591),  time:60.588, tt:363.525\n",
      "Ep:6, loss:0.00043, loss_test:0.12243, lr:1.00e-02, fs:0.61538 (r=0.606,p=0.625),  time:61.155, tt:428.084\n",
      "Ep:7, loss:0.00041, loss_test:0.11855, lr:1.00e-02, fs:0.62245 (r=0.616,p=0.629),  time:61.500, tt:491.999\n",
      "Ep:8, loss:0.00039, loss_test:0.11534, lr:1.00e-02, fs:0.62887 (r=0.616,p=0.642),  time:61.736, tt:555.622\n",
      "Ep:9, loss:0.00037, loss_test:0.11041, lr:1.00e-02, fs:0.65672 (r=0.667,p=0.647),  time:62.094, tt:620.940\n",
      "Ep:10, loss:0.00035, loss_test:0.10912, lr:1.00e-02, fs:0.64286 (r=0.636,p=0.649),  time:62.093, tt:683.027\n",
      "Ep:11, loss:0.00034, loss_test:0.10617, lr:1.00e-02, fs:0.68627 (r=0.707,p=0.667),  time:62.433, tt:749.202\n",
      "Ep:12, loss:0.00033, loss_test:0.10581, lr:1.00e-02, fs:0.68687 (r=0.687,p=0.687),  time:62.444, tt:811.772\n",
      "Ep:13, loss:0.00031, loss_test:0.10371, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:62.507, tt:875.103\n",
      "Ep:14, loss:0.00030, loss_test:0.10296, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:62.274, tt:934.105\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.10288, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:62.328, tt:997.250\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.10154, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:62.521, tt:1062.858\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.10108, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:62.595, tt:1126.711\n",
      "Ep:18, loss:0.00025, loss_test:0.10115, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:62.522, tt:1187.919\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.09964, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:62.921, tt:1258.420\n",
      "Ep:20, loss:0.00023, loss_test:0.09703, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:63.065, tt:1324.359\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.10024, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:63.071, tt:1387.572\n",
      "Ep:22, loss:0.00021, loss_test:0.09710, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:63.193, tt:1453.440\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.09559, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:63.197, tt:1516.720\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.09581, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:63.001, tt:1575.026\n",
      "Ep:25, loss:0.00018, loss_test:0.09468, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:62.679, tt:1629.656\n",
      "Ep:26, loss:0.00017, loss_test:0.09451, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:62.270, tt:1681.286\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.09603, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:61.944, tt:1734.427\n",
      "Ep:28, loss:0.00016, loss_test:0.09419, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:61.641, tt:1787.578\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.09228, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:61.398, tt:1841.927\n",
      "Ep:30, loss:0.00014, loss_test:0.09114, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:61.258, tt:1898.990\n",
      "Ep:31, loss:0.00014, loss_test:0.09167, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:61.175, tt:1957.605\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00013, loss_test:0.09326, lr:1.00e-02, fs:0.75145 (r=0.657,p=0.878),  time:61.053, tt:2014.754\n",
      "Ep:33, loss:0.00012, loss_test:0.09178, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:60.914, tt:2071.062\n",
      "Ep:34, loss:0.00012, loss_test:0.08972, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:60.846, tt:2129.595\n",
      "Ep:35, loss:0.00011, loss_test:0.08956, lr:1.00e-02, fs:0.70807 (r=0.576,p=0.919),  time:60.791, tt:2188.460\n",
      "Ep:36, loss:0.00011, loss_test:0.08839, lr:1.00e-02, fs:0.73939 (r=0.616,p=0.924),  time:60.687, tt:2245.419\n",
      "Ep:37, loss:0.00010, loss_test:0.09266, lr:1.00e-02, fs:0.68387 (r=0.535,p=0.946),  time:60.661, tt:2305.110\n",
      "Ep:38, loss:0.00010, loss_test:0.08909, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:60.609, tt:2363.761\n",
      "Ep:39, loss:0.00009, loss_test:0.08821, lr:1.00e-02, fs:0.70807 (r=0.576,p=0.919),  time:60.580, tt:2423.205\n",
      "Ep:40, loss:0.00009, loss_test:0.09197, lr:1.00e-02, fs:0.68387 (r=0.535,p=0.946),  time:60.521, tt:2481.380\n",
      "Ep:41, loss:0.00008, loss_test:0.09301, lr:1.00e-02, fs:0.68387 (r=0.535,p=0.946),  time:60.512, tt:2541.483\n",
      "Ep:42, loss:0.00008, loss_test:0.08987, lr:1.00e-02, fs:0.70886 (r=0.566,p=0.949),  time:60.532, tt:2602.854\n",
      "Ep:43, loss:0.00008, loss_test:0.08846, lr:9.90e-03, fs:0.69620 (r=0.556,p=0.932),  time:60.513, tt:2662.590\n",
      "Ep:44, loss:0.00007, loss_test:0.09305, lr:9.80e-03, fs:0.66667 (r=0.515,p=0.944),  time:60.433, tt:2719.503\n",
      "Ep:45, loss:0.00007, loss_test:0.09131, lr:9.70e-03, fs:0.67532 (r=0.525,p=0.945),  time:60.352, tt:2776.207\n",
      "Ep:46, loss:0.00007, loss_test:0.09123, lr:9.61e-03, fs:0.69231 (r=0.545,p=0.947),  time:60.276, tt:2832.978\n",
      "Ep:47, loss:0.00006, loss_test:0.09277, lr:9.51e-03, fs:0.68387 (r=0.535,p=0.946),  time:60.196, tt:2889.389\n",
      "Ep:48, loss:0.00006, loss_test:0.09158, lr:9.41e-03, fs:0.68387 (r=0.535,p=0.946),  time:60.131, tt:2946.396\n",
      "Ep:49, loss:0.00006, loss_test:0.09398, lr:9.32e-03, fs:0.67532 (r=0.525,p=0.945),  time:60.098, tt:3004.907\n",
      "Ep:50, loss:0.00006, loss_test:0.09112, lr:9.23e-03, fs:0.70064 (r=0.556,p=0.948),  time:60.063, tt:3063.229\n",
      "Ep:51, loss:0.00005, loss_test:0.09364, lr:9.14e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.998, tt:3119.903\n",
      "Ep:52, loss:0.00005, loss_test:0.09363, lr:9.04e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.998, tt:3179.868\n",
      "Ep:53, loss:0.00005, loss_test:0.09514, lr:8.95e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.935, tt:3236.464\n",
      "Ep:54, loss:0.00005, loss_test:0.09285, lr:8.86e-03, fs:0.70064 (r=0.556,p=0.948),  time:59.898, tt:3294.378\n",
      "Ep:55, loss:0.00005, loss_test:0.09652, lr:8.78e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.873, tt:3352.890\n",
      "Ep:56, loss:0.00005, loss_test:0.09072, lr:8.69e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.824, tt:3409.961\n",
      "Ep:57, loss:0.00004, loss_test:0.09717, lr:8.60e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.806, tt:3468.768\n",
      "Ep:58, loss:0.00004, loss_test:0.09473, lr:8.51e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.752, tt:3525.356\n",
      "Ep:59, loss:0.00004, loss_test:0.09569, lr:8.43e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.731, tt:3583.890\n",
      "Ep:60, loss:0.00004, loss_test:0.09325, lr:8.35e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.649, tt:3638.569\n",
      "Ep:61, loss:0.00004, loss_test:0.09788, lr:8.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.600, tt:3695.196\n",
      "Ep:62, loss:0.00004, loss_test:0.09539, lr:8.18e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.551, tt:3751.727\n",
      "Ep:63, loss:0.00004, loss_test:0.09649, lr:8.10e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.514, tt:3808.883\n",
      "Ep:64, loss:0.00004, loss_test:0.09870, lr:8.02e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.486, tt:3866.610\n",
      "Ep:65, loss:0.00003, loss_test:0.09652, lr:7.94e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.474, tt:3925.298\n",
      "Ep:66, loss:0.00003, loss_test:0.09686, lr:7.86e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.425, tt:3981.476\n",
      "Ep:67, loss:0.00003, loss_test:0.09951, lr:7.78e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.414, tt:4040.139\n",
      "Ep:68, loss:0.00003, loss_test:0.09554, lr:7.70e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.439, tt:4101.289\n",
      "Ep:69, loss:0.00003, loss_test:0.10026, lr:7.62e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.425, tt:4159.732\n",
      "Ep:70, loss:0.00003, loss_test:0.09786, lr:7.55e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.378, tt:4215.862\n",
      "Ep:71, loss:0.00003, loss_test:0.09984, lr:7.47e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.393, tt:4276.301\n",
      "Ep:72, loss:0.00003, loss_test:0.09624, lr:7.40e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.370, tt:4334.036\n",
      "Ep:73, loss:0.00003, loss_test:0.09977, lr:7.32e-03, fs:0.70513 (r=0.556,p=0.965),  time:59.368, tt:4393.242\n",
      "Ep:74, loss:0.00003, loss_test:0.09757, lr:7.25e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.354, tt:4451.577\n",
      "Ep:75, loss:0.00003, loss_test:0.09995, lr:7.18e-03, fs:0.70513 (r=0.556,p=0.965),  time:59.323, tt:4508.516\n",
      "Ep:76, loss:0.00003, loss_test:0.10128, lr:7.11e-03, fs:0.70513 (r=0.556,p=0.965),  time:59.276, tt:4564.214\n",
      "Ep:77, loss:0.00003, loss_test:0.09946, lr:7.03e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.265, tt:4622.677\n",
      "Ep:78, loss:0.00002, loss_test:0.09916, lr:6.96e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.226, tt:4678.882\n",
      "Ep:79, loss:0.00002, loss_test:0.09980, lr:6.89e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.230, tt:4738.429\n",
      "Ep:80, loss:0.00002, loss_test:0.09890, lr:6.83e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.195, tt:4794.820\n",
      "Ep:81, loss:0.00002, loss_test:0.10082, lr:6.76e-03, fs:0.70513 (r=0.556,p=0.965),  time:59.201, tt:4854.519\n",
      "Ep:82, loss:0.00002, loss_test:0.10012, lr:6.69e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.209, tt:4914.374\n",
      "Ep:83, loss:0.00002, loss_test:0.09947, lr:6.62e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.212, tt:4973.837\n",
      "Ep:84, loss:0.00002, loss_test:0.09922, lr:6.56e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.199, tt:5031.901\n",
      "Ep:85, loss:0.00002, loss_test:0.10002, lr:6.49e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.215, tt:5092.505\n",
      "Ep:86, loss:0.00002, loss_test:0.10017, lr:6.43e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.186, tt:5149.168\n",
      "Ep:87, loss:0.00002, loss_test:0.09920, lr:6.36e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.175, tt:5207.442\n",
      "Ep:88, loss:0.00002, loss_test:0.09962, lr:6.30e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.183, tt:5267.311\n",
      "Ep:89, loss:0.00002, loss_test:0.09930, lr:6.24e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.153, tt:5323.750\n",
      "Ep:90, loss:0.00002, loss_test:0.09851, lr:6.17e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.151, tt:5382.738\n",
      "Ep:91, loss:0.00002, loss_test:0.09980, lr:6.11e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.123, tt:5439.316\n",
      "Ep:92, loss:0.00002, loss_test:0.09847, lr:6.05e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.127, tt:5498.772\n",
      "Ep:93, loss:0.00002, loss_test:0.09949, lr:5.99e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.114, tt:5556.715\n",
      "Ep:94, loss:0.00002, loss_test:0.10116, lr:5.93e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.106, tt:5615.090\n",
      "Ep:95, loss:0.00002, loss_test:0.09762, lr:5.87e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.098, tt:5673.422\n",
      "Ep:96, loss:0.00002, loss_test:0.10093, lr:5.81e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.081, tt:5730.824\n",
      "Ep:97, loss:0.00002, loss_test:0.10037, lr:5.75e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.068, tt:5788.703\n",
      "Ep:98, loss:0.00002, loss_test:0.09911, lr:5.70e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.055, tt:5846.399\n",
      "Ep:99, loss:0.00002, loss_test:0.10064, lr:5.64e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.052, tt:5905.178\n",
      "Ep:100, loss:0.00002, loss_test:0.09928, lr:5.58e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.034, tt:5962.422\n",
      "Ep:101, loss:0.00002, loss_test:0.09929, lr:5.53e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.054, tt:6023.530\n",
      "Ep:102, loss:0.00002, loss_test:0.10028, lr:5.47e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.058, tt:6082.995\n",
      "Ep:103, loss:0.00002, loss_test:0.09820, lr:5.42e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.070, tt:6143.318\n",
      "Ep:104, loss:0.00002, loss_test:0.10010, lr:5.36e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.075, tt:6202.840\n",
      "Ep:105, loss:0.00002, loss_test:0.09888, lr:5.31e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.037, tt:6257.923\n",
      "Ep:106, loss:0.00002, loss_test:0.09994, lr:5.26e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.027, tt:6315.915\n",
      "Ep:107, loss:0.00001, loss_test:0.10097, lr:5.20e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.045, tt:6376.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00001, loss_test:0.09851, lr:5.15e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.033, tt:6434.624\n",
      "Ep:109, loss:0.00001, loss_test:0.09955, lr:5.10e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.029, tt:6493.180\n",
      "Ep:110, loss:0.00001, loss_test:0.09964, lr:5.05e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.026, tt:6551.863\n",
      "Ep:111, loss:0.00001, loss_test:0.09931, lr:5.00e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.025, tt:6610.778\n",
      "Ep:112, loss:0.00001, loss_test:0.10024, lr:4.95e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.011, tt:6668.290\n",
      "Ep:113, loss:0.00001, loss_test:0.09923, lr:4.90e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.043, tt:6730.917\n",
      "Ep:114, loss:0.00001, loss_test:0.09886, lr:4.85e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.054, tt:6791.261\n",
      "Ep:115, loss:0.00001, loss_test:0.09901, lr:4.80e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.057, tt:6850.655\n",
      "Ep:116, loss:0.00001, loss_test:0.09972, lr:4.75e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.039, tt:6907.570\n",
      "Ep:117, loss:0.00001, loss_test:0.09857, lr:4.71e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.040, tt:6966.685\n",
      "Ep:118, loss:0.00001, loss_test:0.10062, lr:4.66e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.054, tt:7027.440\n",
      "Ep:119, loss:0.00001, loss_test:0.10017, lr:4.61e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.029, tt:7083.483\n",
      "Ep:120, loss:0.00001, loss_test:0.10011, lr:4.57e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.024, tt:7141.949\n",
      "Ep:121, loss:0.00001, loss_test:0.10001, lr:4.52e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.021, tt:7200.512\n",
      "Ep:122, loss:0.00001, loss_test:0.09927, lr:4.48e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.023, tt:7259.783\n",
      "Ep:123, loss:0.00001, loss_test:0.09953, lr:4.43e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.010, tt:7317.220\n",
      "Ep:124, loss:0.00001, loss_test:0.10067, lr:4.39e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.011, tt:7376.407\n",
      "Ep:125, loss:0.00001, loss_test:0.09881, lr:4.34e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.015, tt:7435.922\n",
      "Ep:126, loss:0.00001, loss_test:0.09946, lr:4.30e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.003, tt:7493.409\n",
      "Ep:127, loss:0.00001, loss_test:0.09957, lr:4.26e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.001, tt:7552.065\n",
      "Ep:128, loss:0.00001, loss_test:0.09992, lr:4.21e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.008, tt:7612.036\n",
      "Ep:129, loss:0.00001, loss_test:0.09967, lr:4.17e-03, fs:0.71795 (r=0.566,p=0.982),  time:59.010, tt:7671.311\n",
      "Ep:130, loss:0.00001, loss_test:0.09965, lr:4.13e-03, fs:0.67550 (r=0.515,p=0.981),  time:59.018, tt:7731.382\n",
      "Ep:131, loss:0.00001, loss_test:0.10104, lr:4.09e-03, fs:0.71795 (r=0.566,p=0.982),  time:59.018, tt:7790.324\n",
      "Ep:132, loss:0.00001, loss_test:0.09820, lr:4.05e-03, fs:0.67550 (r=0.515,p=0.981),  time:59.008, tt:7848.052\n",
      "Ep:133, loss:0.00001, loss_test:0.10198, lr:4.01e-03, fs:0.71795 (r=0.566,p=0.982),  time:59.008, tt:7907.071\n",
      "Ep:134, loss:0.00001, loss_test:0.09868, lr:3.97e-03, fs:0.66667 (r=0.505,p=0.980),  time:59.021, tt:7967.838\n",
      "Ep:135, loss:0.00001, loss_test:0.10166, lr:3.93e-03, fs:0.67550 (r=0.515,p=0.981),  time:59.009, tt:8025.274\n",
      "Ep:136, loss:0.00001, loss_test:0.10062, lr:3.89e-03, fs:0.66667 (r=0.505,p=0.980),  time:59.013, tt:8084.816\n",
      "Ep:137, loss:0.00001, loss_test:0.09946, lr:3.85e-03, fs:0.70130 (r=0.545,p=0.982),  time:59.022, tt:8145.031\n",
      "Ep:138, loss:0.00001, loss_test:0.10176, lr:3.81e-03, fs:0.67550 (r=0.515,p=0.981),  time:59.017, tt:8203.326\n",
      "Ep:139, loss:0.00001, loss_test:0.09804, lr:3.77e-03, fs:0.70130 (r=0.545,p=0.982),  time:59.016, tt:8262.226\n",
      "Ep:140, loss:0.00001, loss_test:0.10209, lr:3.73e-03, fs:0.68000 (r=0.515,p=1.000),  time:58.994, tt:8318.145\n",
      "Ep:141, loss:0.00001, loss_test:0.09929, lr:3.70e-03, fs:0.71795 (r=0.566,p=0.982),  time:58.986, tt:8376.073\n",
      "Ep:142, loss:0.00001, loss_test:0.10023, lr:3.66e-03, fs:0.67550 (r=0.515,p=0.981),  time:58.986, tt:8434.975\n",
      "Ep:143, loss:0.00001, loss_test:0.09938, lr:3.62e-03, fs:0.72258 (r=0.566,p=1.000),  time:58.984, tt:8493.759\n",
      "Ep:144, loss:0.00001, loss_test:0.09941, lr:3.59e-03, fs:0.67114 (r=0.505,p=1.000),  time:58.976, tt:8551.529\n",
      "Ep:145, loss:0.00001, loss_test:0.09985, lr:3.55e-03, fs:0.73077 (r=0.576,p=1.000),  time:58.956, tt:8607.555\n",
      "Ep:146, loss:0.00001, loss_test:0.09883, lr:3.52e-03, fs:0.68000 (r=0.515,p=1.000),  time:58.959, tt:8666.913\n",
      "Ep:147, loss:0.00001, loss_test:0.09980, lr:3.48e-03, fs:0.71429 (r=0.556,p=1.000),  time:58.942, tt:8723.418\n",
      "Ep:148, loss:0.00001, loss_test:0.09932, lr:3.45e-03, fs:0.68000 (r=0.515,p=1.000),  time:58.932, tt:8780.938\n",
      "Ep:149, loss:0.00001, loss_test:0.09940, lr:3.41e-03, fs:0.72258 (r=0.566,p=1.000),  time:58.837, tt:8825.480\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 36\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14566, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.258, tt:50.258\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14452, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.072, tt:104.144\n",
      "Ep:2, loss:0.00055, loss_test:0.14235, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:50.808, tt:152.424\n",
      "Ep:3, loss:0.00054, loss_test:0.13819, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:52.350, tt:209.398\n",
      "Ep:4, loss:0.00051, loss_test:0.12893, lr:1.00e-02, fs:0.64093 (r=0.838,p=0.519),  time:53.618, tt:268.088\n",
      "Ep:5, loss:0.00046, loss_test:0.12195, lr:1.00e-02, fs:0.62439 (r=0.646,p=0.604),  time:54.262, tt:325.575\n",
      "Ep:6, loss:0.00044, loss_test:0.11848, lr:1.00e-02, fs:0.63551 (r=0.687,p=0.591),  time:55.103, tt:385.718\n",
      "Ep:7, loss:0.00042, loss_test:0.11453, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:55.396, tt:443.169\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.11214, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:55.740, tt:501.660\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.11014, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:56.096, tt:560.964\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.10711, lr:1.00e-02, fs:0.66310 (r=0.626,p=0.705),  time:56.101, tt:617.114\n",
      "Ep:11, loss:0.00033, loss_test:0.10637, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:56.471, tt:677.649\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.10416, lr:1.00e-02, fs:0.68817 (r=0.646,p=0.736),  time:56.752, tt:737.779\n",
      "Ep:13, loss:0.00030, loss_test:0.10348, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:56.788, tt:795.030\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.10269, lr:1.00e-02, fs:0.70968 (r=0.667,p=0.759),  time:56.981, tt:854.712\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.10232, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:57.139, tt:914.225\n",
      "Ep:16, loss:0.00027, loss_test:0.10144, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:57.128, tt:971.182\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.10216, lr:1.00e-02, fs:0.69231 (r=0.636,p=0.759),  time:57.228, tt:1030.099\n",
      "Ep:18, loss:0.00025, loss_test:0.10068, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:57.267, tt:1088.082\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.09958, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:57.276, tt:1145.520\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.10154, lr:1.00e-02, fs:0.70391 (r=0.636,p=0.787),  time:57.447, tt:1206.379\n",
      "Ep:21, loss:0.00022, loss_test:0.09949, lr:1.00e-02, fs:0.72832 (r=0.636,p=0.851),  time:57.451, tt:1263.930\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.09879, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:57.532, tt:1323.238\n",
      "Ep:23, loss:0.00020, loss_test:0.09967, lr:1.00e-02, fs:0.70930 (r=0.616,p=0.836),  time:57.651, tt:1383.622\n",
      "Ep:24, loss:0.00020, loss_test:0.09909, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:57.722, tt:1443.041\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00019, loss_test:0.09711, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:57.597, tt:1497.519\n",
      "Ep:26, loss:0.00018, loss_test:0.09999, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:57.586, tt:1554.826\n",
      "Ep:27, loss:0.00017, loss_test:0.09626, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:57.643, tt:1614.006\n",
      "Ep:28, loss:0.00016, loss_test:0.09850, lr:1.00e-02, fs:0.73939 (r=0.616,p=0.924),  time:57.714, tt:1673.696\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.09790, lr:1.00e-02, fs:0.74251 (r=0.626,p=0.912),  time:57.819, tt:1734.579\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09650, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:57.878, tt:1794.210\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09810, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:57.905, tt:1852.971\n",
      "Ep:32, loss:0.00013, loss_test:0.09833, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:57.950, tt:1912.346\n",
      "Ep:33, loss:0.00012, loss_test:0.09734, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:58.020, tt:1972.674\n",
      "Ep:34, loss:0.00012, loss_test:0.09435, lr:1.00e-02, fs:0.75449 (r=0.636,p=0.926),  time:58.033, tt:2031.146\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.09693, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:58.013, tt:2088.461\n",
      "Ep:36, loss:0.00011, loss_test:0.09642, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:58.022, tt:2146.816\n",
      "Ep:37, loss:0.00010, loss_test:0.09885, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:58.017, tt:2204.630\n",
      "Ep:38, loss:0.00010, loss_test:0.09430, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.069, tt:2264.675\n",
      "Ep:39, loss:0.00009, loss_test:0.09634, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.081, tt:2323.250\n",
      "Ep:40, loss:0.00009, loss_test:0.09895, lr:1.00e-02, fs:0.74847 (r=0.616,p=0.953),  time:58.109, tt:2382.486\n",
      "Ep:41, loss:0.00008, loss_test:0.09696, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.123, tt:2441.161\n",
      "Ep:42, loss:0.00008, loss_test:0.09798, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.101, tt:2498.330\n",
      "Ep:43, loss:0.00008, loss_test:0.09631, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:58.121, tt:2557.336\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.09911, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:58.163, tt:2617.343\n",
      "Ep:45, loss:0.00007, loss_test:0.09391, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:58.155, tt:2675.114\n",
      "Ep:46, loss:0.00007, loss_test:0.09902, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:58.162, tt:2733.633\n",
      "Ep:47, loss:0.00006, loss_test:0.09658, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:58.195, tt:2793.343\n",
      "Ep:48, loss:0.00006, loss_test:0.09949, lr:1.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:58.208, tt:2852.171\n",
      "Ep:49, loss:0.00006, loss_test:0.09800, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:58.206, tt:2910.289\n",
      "Ep:50, loss:0.00006, loss_test:0.09569, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.179, tt:2967.116\n",
      "Ep:51, loss:0.00006, loss_test:0.09759, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.201, tt:3026.456\n",
      "Ep:52, loss:0.00005, loss_test:0.09915, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.226, tt:3085.987\n",
      "Ep:53, loss:0.00005, loss_test:0.09662, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.216, tt:3143.690\n",
      "Ep:54, loss:0.00005, loss_test:0.09905, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:58.224, tt:3202.324\n",
      "Ep:55, loss:0.00005, loss_test:0.09782, lr:9.90e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.262, tt:3262.694\n",
      "Ep:56, loss:0.00005, loss_test:0.09787, lr:9.80e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.187, tt:3316.645\n",
      "Ep:57, loss:0.00004, loss_test:0.10282, lr:9.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:58.184, tt:3374.644\n",
      "Ep:58, loss:0.00004, loss_test:0.09958, lr:9.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.211, tt:3434.475\n",
      "Ep:59, loss:0.00004, loss_test:0.09963, lr:9.51e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.179, tt:3490.727\n",
      "Ep:60, loss:0.00004, loss_test:0.10148, lr:9.41e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.128, tt:3545.806\n",
      "Ep:61, loss:0.00004, loss_test:0.09873, lr:9.32e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.118, tt:3603.346\n",
      "Ep:62, loss:0.00004, loss_test:0.09766, lr:9.23e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.147, tt:3663.266\n",
      "Ep:63, loss:0.00004, loss_test:0.10078, lr:9.14e-03, fs:0.73620 (r=0.606,p=0.938),  time:58.166, tt:3722.649\n",
      "Ep:64, loss:0.00004, loss_test:0.10244, lr:9.04e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.165, tt:3780.714\n",
      "Ep:65, loss:0.00004, loss_test:0.09833, lr:8.95e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.130, tt:3836.613\n",
      "Ep:66, loss:0.00003, loss_test:0.10345, lr:8.86e-03, fs:0.73292 (r=0.596,p=0.952),  time:58.108, tt:3893.259\n",
      "Ep:67, loss:0.00003, loss_test:0.09991, lr:8.78e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.111, tt:3951.531\n",
      "Ep:68, loss:0.00003, loss_test:0.10262, lr:8.69e-03, fs:0.74074 (r=0.606,p=0.952),  time:58.126, tt:4010.726\n",
      "Ep:69, loss:0.00003, loss_test:0.10357, lr:8.60e-03, fs:0.74074 (r=0.606,p=0.952),  time:58.132, tt:4069.228\n",
      "Ep:70, loss:0.00003, loss_test:0.10361, lr:8.51e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.123, tt:4126.738\n",
      "Ep:71, loss:0.00003, loss_test:0.10003, lr:8.43e-03, fs:0.75152 (r=0.626,p=0.939),  time:58.100, tt:4183.177\n",
      "Ep:72, loss:0.00003, loss_test:0.10033, lr:8.35e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.103, tt:4241.493\n",
      "Ep:73, loss:0.00003, loss_test:0.09976, lr:8.26e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.115, tt:4300.480\n",
      "Ep:74, loss:0.00003, loss_test:0.10477, lr:8.18e-03, fs:0.74534 (r=0.606,p=0.968),  time:58.124, tt:4359.327\n",
      "Ep:75, loss:0.00003, loss_test:0.10047, lr:8.10e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.133, tt:4418.142\n",
      "Ep:76, loss:0.00003, loss_test:0.10208, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.139, tt:4476.681\n",
      "Ep:77, loss:0.00003, loss_test:0.10105, lr:7.94e-03, fs:0.75610 (r=0.626,p=0.954),  time:58.157, tt:4536.268\n",
      "Ep:78, loss:0.00002, loss_test:0.10294, lr:7.86e-03, fs:0.74534 (r=0.606,p=0.968),  time:58.183, tt:4596.440\n",
      "Ep:79, loss:0.00002, loss_test:0.10065, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.202, tt:4656.135\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.10357, lr:7.78e-03, fs:0.74534 (r=0.606,p=0.968),  time:58.213, tt:4715.269\n",
      "Ep:81, loss:0.00002, loss_test:0.10072, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.221, tt:4774.142\n",
      "Ep:82, loss:0.00002, loss_test:0.10340, lr:7.78e-03, fs:0.73750 (r=0.596,p=0.967),  time:58.241, tt:4833.969\n",
      "Ep:83, loss:0.00002, loss_test:0.10062, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.241, tt:4892.224\n",
      "Ep:84, loss:0.00002, loss_test:0.10113, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.219, tt:4948.603\n",
      "Ep:85, loss:0.00002, loss_test:0.10380, lr:7.78e-03, fs:0.73750 (r=0.596,p=0.967),  time:58.208, tt:5005.850\n",
      "Ep:86, loss:0.00002, loss_test:0.10183, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.211, tt:5064.376\n",
      "Ep:87, loss:0.00002, loss_test:0.10224, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.188, tt:5120.516\n",
      "Ep:88, loss:0.00002, loss_test:0.10329, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.194, tt:5179.260\n",
      "Ep:89, loss:0.00002, loss_test:0.10368, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.186, tt:5236.712\n",
      "Ep:90, loss:0.00002, loss_test:0.10403, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.182, tt:5294.562\n",
      "Ep:91, loss:0.00002, loss_test:0.10036, lr:7.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.180, tt:5352.572\n",
      "Ep:92, loss:0.00002, loss_test:0.10591, lr:7.62e-03, fs:0.67105 (r=0.515,p=0.962),  time:58.202, tt:5412.795\n",
      "Ep:93, loss:0.00002, loss_test:0.10500, lr:7.55e-03, fs:0.74534 (r=0.606,p=0.968),  time:58.200, tt:5470.763\n",
      "Ep:94, loss:0.00002, loss_test:0.11102, lr:7.47e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.189, tt:5527.960\n",
      "Ep:95, loss:0.00002, loss_test:0.10212, lr:7.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.187, tt:5585.915\n",
      "Ep:96, loss:0.00002, loss_test:0.10524, lr:7.32e-03, fs:0.66225 (r=0.505,p=0.962),  time:58.186, tt:5644.075\n",
      "Ep:97, loss:0.00002, loss_test:0.10560, lr:7.25e-03, fs:0.73750 (r=0.596,p=0.967),  time:58.199, tt:5703.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:98, loss:0.00002, loss_test:0.10450, lr:7.18e-03, fs:0.71795 (r=0.566,p=0.982),  time:58.211, tt:5762.854\n",
      "Ep:99, loss:0.00002, loss_test:0.10678, lr:7.11e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.246, tt:5824.580\n",
      "Ep:100, loss:0.00002, loss_test:0.10491, lr:7.03e-03, fs:0.73750 (r=0.596,p=0.967),  time:58.262, tt:5884.495\n",
      "Ep:101, loss:0.00002, loss_test:0.10527, lr:6.96e-03, fs:0.69281 (r=0.535,p=0.981),  time:58.284, tt:5944.998\n",
      "Ep:102, loss:0.00001, loss_test:0.10744, lr:6.89e-03, fs:0.70513 (r=0.556,p=0.965),  time:58.320, tt:6007.009\n",
      "Ep:103, loss:0.00001, loss_test:0.10665, lr:6.83e-03, fs:0.66225 (r=0.505,p=0.962),  time:58.330, tt:6066.292\n",
      "Ep:104, loss:0.00001, loss_test:0.10338, lr:6.76e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.337, tt:6125.413\n",
      "Ep:105, loss:0.00001, loss_test:0.10654, lr:6.69e-03, fs:0.67974 (r=0.525,p=0.963),  time:58.339, tt:6183.948\n",
      "Ep:106, loss:0.00001, loss_test:0.10449, lr:6.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.342, tt:6242.639\n",
      "Ep:107, loss:0.00001, loss_test:0.10515, lr:6.56e-03, fs:0.70968 (r=0.556,p=0.982),  time:58.347, tt:6301.458\n",
      "Ep:108, loss:0.00001, loss_test:0.10719, lr:6.49e-03, fs:0.72152 (r=0.576,p=0.966),  time:58.355, tt:6360.641\n",
      "Ep:109, loss:0.00001, loss_test:0.10836, lr:6.43e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.346, tt:6418.077\n",
      "Ep:110, loss:0.00001, loss_test:0.10315, lr:6.36e-03, fs:0.76074 (r=0.626,p=0.969),  time:58.357, tt:6477.608\n",
      "Ep:111, loss:0.00001, loss_test:0.10700, lr:6.30e-03, fs:0.66225 (r=0.505,p=0.962),  time:58.356, tt:6535.866\n",
      "Ep:112, loss:0.00001, loss_test:0.10558, lr:6.24e-03, fs:0.72956 (r=0.586,p=0.967),  time:58.371, tt:6595.903\n",
      "Ep:113, loss:0.00001, loss_test:0.10696, lr:6.17e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.375, tt:6654.714\n",
      "Ep:114, loss:0.00001, loss_test:0.10595, lr:6.11e-03, fs:0.67974 (r=0.525,p=0.963),  time:58.383, tt:6714.086\n",
      "Ep:115, loss:0.00001, loss_test:0.10821, lr:6.05e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.390, tt:6773.279\n",
      "Ep:116, loss:0.00001, loss_test:0.10446, lr:5.99e-03, fs:0.72611 (r=0.576,p=0.983),  time:58.363, tt:6828.422\n",
      "Ep:117, loss:0.00001, loss_test:0.10667, lr:5.93e-03, fs:0.67105 (r=0.515,p=0.962),  time:58.368, tt:6887.382\n",
      "Ep:118, loss:0.00001, loss_test:0.10711, lr:5.87e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.354, tt:6944.141\n",
      "Ep:119, loss:0.00001, loss_test:0.10518, lr:5.81e-03, fs:0.71338 (r=0.566,p=0.966),  time:58.356, tt:7002.688\n",
      "Ep:120, loss:0.00001, loss_test:0.10656, lr:5.75e-03, fs:0.66225 (r=0.505,p=0.962),  time:58.364, tt:7062.019\n",
      "Ep:121, loss:0.00001, loss_test:0.10580, lr:5.70e-03, fs:0.68421 (r=0.525,p=0.981),  time:58.337, tt:7117.087\n",
      "Ep:122, loss:0.00001, loss_test:0.10678, lr:5.64e-03, fs:0.66225 (r=0.505,p=0.962),  time:58.318, tt:7173.102\n",
      "Ep:123, loss:0.00001, loss_test:0.10605, lr:5.58e-03, fs:0.69281 (r=0.535,p=0.981),  time:58.323, tt:7232.036\n",
      "Ep:124, loss:0.00001, loss_test:0.10559, lr:5.53e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.335, tt:7291.834\n",
      "Ep:125, loss:0.00001, loss_test:0.10630, lr:5.47e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.346, tt:7351.621\n",
      "Ep:126, loss:0.00001, loss_test:0.10637, lr:5.42e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.354, tt:7410.931\n",
      "Ep:127, loss:0.00001, loss_test:0.10540, lr:5.36e-03, fs:0.67550 (r=0.515,p=0.981),  time:58.329, tt:7466.083\n",
      "Ep:128, loss:0.00001, loss_test:0.10720, lr:5.31e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.338, tt:7525.645\n",
      "Ep:129, loss:0.00001, loss_test:0.10590, lr:5.26e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.342, tt:7584.512\n",
      "Ep:130, loss:0.00001, loss_test:0.10617, lr:5.20e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.332, tt:7641.475\n",
      "Ep:131, loss:0.00001, loss_test:0.10600, lr:5.15e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.323, tt:7698.598\n",
      "Ep:132, loss:0.00001, loss_test:0.10622, lr:5.10e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.327, tt:7757.474\n",
      "Ep:133, loss:0.00001, loss_test:0.10669, lr:5.05e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.313, tt:7813.878\n",
      "Ep:134, loss:0.00001, loss_test:0.10672, lr:5.00e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.288, tt:7868.853\n",
      "Ep:135, loss:0.00001, loss_test:0.10615, lr:4.95e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.293, tt:7927.794\n",
      "Ep:136, loss:0.00001, loss_test:0.10624, lr:4.90e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.312, tt:7988.697\n",
      "Ep:137, loss:0.00001, loss_test:0.10683, lr:4.85e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.310, tt:8046.815\n",
      "Ep:138, loss:0.00001, loss_test:0.10597, lr:4.80e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.300, tt:8103.743\n",
      "Ep:139, loss:0.00001, loss_test:0.10680, lr:4.75e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.306, tt:8162.838\n",
      "Ep:140, loss:0.00001, loss_test:0.10637, lr:4.71e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.304, tt:8220.885\n",
      "Ep:141, loss:0.00001, loss_test:0.10797, lr:4.66e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.300, tt:8278.627\n",
      "Ep:142, loss:0.00001, loss_test:0.10619, lr:4.61e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.297, tt:8336.543\n",
      "Ep:143, loss:0.00001, loss_test:0.10650, lr:4.57e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.288, tt:8393.425\n",
      "Ep:144, loss:0.00001, loss_test:0.10632, lr:4.52e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.251, tt:8446.360\n",
      "Ep:145, loss:0.00001, loss_test:0.10619, lr:4.48e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.242, tt:8503.351\n",
      "Ep:146, loss:0.00001, loss_test:0.10653, lr:4.43e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.237, tt:8560.850\n",
      "Ep:147, loss:0.00001, loss_test:0.10610, lr:4.39e-03, fs:0.66225 (r=0.505,p=0.962),  time:58.239, tt:8619.376\n",
      "Ep:148, loss:0.00001, loss_test:0.10683, lr:4.34e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.229, tt:8676.171\n",
      "Ep:149, loss:0.00001, loss_test:0.10657, lr:4.30e-03, fs:0.66667 (r=0.505,p=0.980),  time:58.186, tt:8727.938\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 37\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14560, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.855, tt:50.855\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14428, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:54.273, tt:108.546\n",
      "Ep:2, loss:0.00055, loss_test:0.14187, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.157, tt:159.471\n",
      "Ep:3, loss:0.00054, loss_test:0.13678, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:53.189, tt:212.756\n",
      "Ep:4, loss:0.00050, loss_test:0.12661, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:54.027, tt:270.136\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00047, loss_test:0.11922, lr:1.00e-02, fs:0.60870 (r=0.636,p=0.583),  time:54.885, tt:329.310\n",
      "Ep:6, loss:0.00044, loss_test:0.11323, lr:1.00e-02, fs:0.66038 (r=0.707,p=0.619),  time:55.203, tt:386.423\n",
      "Ep:7, loss:0.00042, loss_test:0.10930, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:55.328, tt:442.622\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.10647, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:55.424, tt:498.819\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00038, loss_test:0.10423, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:55.798, tt:557.982\n",
      "Ep:10, loss:0.00036, loss_test:0.10184, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:55.969, tt:615.657\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.09896, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:56.111, tt:673.327\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00033, loss_test:0.09694, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:56.331, tt:732.308\n",
      "Ep:13, loss:0.00032, loss_test:0.09476, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:56.417, tt:789.832\n",
      "Ep:14, loss:0.00030, loss_test:0.09380, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:56.550, tt:848.251\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.09187, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:56.691, tt:907.048\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00028, loss_test:0.09250, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:56.900, tt:967.308\n",
      "Ep:17, loss:0.00027, loss_test:0.08981, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:56.887, tt:1023.967\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.09047, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:56.898, tt:1081.069\n",
      "Ep:19, loss:0.00025, loss_test:0.08918, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:56.894, tt:1137.878\n",
      "Ep:20, loss:0.00024, loss_test:0.08887, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:56.924, tt:1195.401\n",
      "Ep:21, loss:0.00023, loss_test:0.08960, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:56.857, tt:1250.853\n",
      "Ep:22, loss:0.00022, loss_test:0.08980, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:56.949, tt:1309.823\n",
      "Ep:23, loss:0.00021, loss_test:0.08840, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:56.894, tt:1365.457\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.08794, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:56.830, tt:1420.755\n",
      "Ep:25, loss:0.00019, loss_test:0.08829, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:56.780, tt:1476.271\n",
      "Ep:26, loss:0.00018, loss_test:0.09051, lr:1.00e-02, fs:0.73446 (r=0.657,p=0.833),  time:56.845, tt:1534.803\n",
      "Ep:27, loss:0.00017, loss_test:0.08762, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:56.794, tt:1590.239\n",
      "Ep:28, loss:0.00017, loss_test:0.08827, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:56.842, tt:1648.419\n",
      "Ep:29, loss:0.00016, loss_test:0.08714, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:56.755, tt:1702.658\n",
      "Ep:30, loss:0.00015, loss_test:0.09006, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:56.714, tt:1758.122\n",
      "Ep:31, loss:0.00015, loss_test:0.09072, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:56.684, tt:1813.889\n",
      "Ep:32, loss:0.00013, loss_test:0.08820, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:56.684, tt:1870.565\n",
      "Ep:33, loss:0.00013, loss_test:0.08751, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:56.637, tt:1925.657\n",
      "Ep:34, loss:0.00012, loss_test:0.08436, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:56.677, tt:1983.707\n",
      "Ep:35, loss:0.00011, loss_test:0.08606, lr:9.90e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.681, tt:2040.516\n",
      "Ep:36, loss:0.00011, loss_test:0.08407, lr:9.80e-03, fs:0.78261 (r=0.727,p=0.847),  time:56.674, tt:2096.930\n",
      "Ep:37, loss:0.00010, loss_test:0.08638, lr:9.70e-03, fs:0.79775 (r=0.717,p=0.899),  time:56.662, tt:2153.150\n",
      "Ep:38, loss:0.00010, loss_test:0.08544, lr:9.61e-03, fs:0.78689 (r=0.727,p=0.857),  time:56.650, tt:2209.345\n",
      "Ep:39, loss:0.00009, loss_test:0.08530, lr:9.51e-03, fs:0.78261 (r=0.727,p=0.847),  time:56.657, tt:2266.276\n",
      "Ep:40, loss:0.00009, loss_test:0.08534, lr:9.41e-03, fs:0.78689 (r=0.727,p=0.857),  time:56.672, tt:2323.539\n",
      "Ep:41, loss:0.00009, loss_test:0.08417, lr:9.32e-03, fs:0.77596 (r=0.717,p=0.845),  time:56.618, tt:2377.961\n",
      "Ep:42, loss:0.00008, loss_test:0.08532, lr:9.23e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.638, tt:2435.452\n",
      "Ep:43, loss:0.00008, loss_test:0.08397, lr:9.14e-03, fs:0.79121 (r=0.727,p=0.867),  time:56.671, tt:2493.535\n",
      "Ep:44, loss:0.00007, loss_test:0.08547, lr:9.04e-03, fs:0.78689 (r=0.727,p=0.857),  time:56.640, tt:2548.783\n",
      "Ep:45, loss:0.00007, loss_test:0.08628, lr:8.95e-03, fs:0.80447 (r=0.727,p=0.900),  time:56.616, tt:2604.330\n",
      "Ep:46, loss:0.00007, loss_test:0.08341, lr:8.86e-03, fs:0.78261 (r=0.727,p=0.847),  time:56.580, tt:2659.237\n",
      "Ep:47, loss:0.00007, loss_test:0.08479, lr:8.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.545, tt:2714.141\n",
      "Ep:48, loss:0.00006, loss_test:0.08501, lr:8.69e-03, fs:0.78261 (r=0.727,p=0.847),  time:56.544, tt:2770.648\n",
      "Ep:49, loss:0.00006, loss_test:0.08534, lr:8.60e-03, fs:0.79121 (r=0.727,p=0.867),  time:56.586, tt:2829.275\n",
      "Ep:50, loss:0.00006, loss_test:0.08590, lr:8.51e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.591, tt:2886.134\n",
      "Ep:51, loss:0.00006, loss_test:0.08395, lr:8.43e-03, fs:0.78689 (r=0.727,p=0.857),  time:56.655, tt:2946.057\n",
      "Ep:52, loss:0.00006, loss_test:0.08620, lr:8.35e-03, fs:0.78453 (r=0.717,p=0.866),  time:56.712, tt:3005.740\n",
      "Ep:53, loss:0.00005, loss_test:0.08517, lr:8.26e-03, fs:0.80447 (r=0.727,p=0.900),  time:56.747, tt:3064.319\n",
      "Ep:54, loss:0.00005, loss_test:0.08793, lr:8.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.730, tt:3120.169\n",
      "Ep:55, loss:0.00005, loss_test:0.08736, lr:8.10e-03, fs:0.78261 (r=0.727,p=0.847),  time:56.765, tt:3178.848\n",
      "Ep:56, loss:0.00005, loss_test:0.08655, lr:8.02e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.782, tt:3236.587\n",
      "Ep:57, loss:0.00005, loss_test:0.08568, lr:7.94e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.795, tt:3294.137\n",
      "Ep:58, loss:0.00005, loss_test:0.08904, lr:7.86e-03, fs:0.77273 (r=0.687,p=0.883),  time:56.798, tt:3351.085\n",
      "Ep:59, loss:0.00005, loss_test:0.08578, lr:7.78e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.797, tt:3407.803\n",
      "Ep:60, loss:0.00004, loss_test:0.08638, lr:7.70e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.822, tt:3466.163\n",
      "Ep:61, loss:0.00004, loss_test:0.08679, lr:7.62e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.829, tt:3523.370\n",
      "Ep:62, loss:0.00004, loss_test:0.08677, lr:7.55e-03, fs:0.78453 (r=0.717,p=0.866),  time:56.811, tt:3579.081\n",
      "Ep:63, loss:0.00004, loss_test:0.08569, lr:7.47e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.808, tt:3635.702\n",
      "Ep:64, loss:0.00004, loss_test:0.08718, lr:7.40e-03, fs:0.78212 (r=0.707,p=0.875),  time:56.792, tt:3691.474\n",
      "Ep:65, loss:0.00004, loss_test:0.08774, lr:7.32e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.800, tt:3748.808\n",
      "Ep:66, loss:0.00004, loss_test:0.08662, lr:7.25e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.810, tt:3806.276\n",
      "Ep:67, loss:0.00004, loss_test:0.08745, lr:7.18e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.821, tt:3863.859\n",
      "Ep:68, loss:0.00003, loss_test:0.08846, lr:7.11e-03, fs:0.78889 (r=0.717,p=0.877),  time:56.842, tt:3922.109\n",
      "Ep:69, loss:0.00003, loss_test:0.08705, lr:7.03e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.868, tt:3980.789\n",
      "Ep:70, loss:0.00003, loss_test:0.08851, lr:6.96e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.864, tt:4037.377\n",
      "Ep:71, loss:0.00003, loss_test:0.08775, lr:6.89e-03, fs:0.79558 (r=0.727,p=0.878),  time:56.862, tt:4094.048\n",
      "Ep:72, loss:0.00003, loss_test:0.08873, lr:6.83e-03, fs:0.80000 (r=0.727,p=0.889),  time:56.840, tt:4149.292\n",
      "Ep:73, loss:0.00003, loss_test:0.08876, lr:6.76e-03, fs:0.75862 (r=0.667,p=0.880),  time:56.831, tt:4205.514\n",
      "Ep:74, loss:0.00003, loss_test:0.08911, lr:6.69e-03, fs:0.77273 (r=0.687,p=0.883),  time:56.782, tt:4258.686\n",
      "Ep:75, loss:0.00003, loss_test:0.08941, lr:6.62e-03, fs:0.77714 (r=0.687,p=0.895),  time:56.752, tt:4313.134\n",
      "Ep:76, loss:0.00003, loss_test:0.08871, lr:6.56e-03, fs:0.75862 (r=0.667,p=0.880),  time:56.744, tt:4369.325\n",
      "Ep:77, loss:0.00003, loss_test:0.09066, lr:6.49e-03, fs:0.75862 (r=0.667,p=0.880),  time:56.767, tt:4427.796\n",
      "Ep:78, loss:0.00003, loss_test:0.08887, lr:6.43e-03, fs:0.75862 (r=0.667,p=0.880),  time:56.762, tt:4484.220\n",
      "Ep:79, loss:0.00003, loss_test:0.08963, lr:6.36e-03, fs:0.76571 (r=0.677,p=0.882),  time:56.795, tt:4543.567\n",
      "Ep:80, loss:0.00003, loss_test:0.08935, lr:6.30e-03, fs:0.77528 (r=0.697,p=0.873),  time:56.798, tt:4600.618\n",
      "Ep:81, loss:0.00003, loss_test:0.09036, lr:6.24e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.817, tt:4659.032\n",
      "Ep:82, loss:0.00003, loss_test:0.08955, lr:6.17e-03, fs:0.75145 (r=0.657,p=0.878),  time:56.835, tt:4717.323\n",
      "Ep:83, loss:0.00003, loss_test:0.09044, lr:6.11e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.842, tt:4774.731\n",
      "Ep:84, loss:0.00003, loss_test:0.08967, lr:6.05e-03, fs:0.77714 (r=0.687,p=0.895),  time:56.853, tt:4832.499\n",
      "Ep:85, loss:0.00002, loss_test:0.08939, lr:5.99e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.865, tt:4890.406\n",
      "Ep:86, loss:0.00002, loss_test:0.09117, lr:5.93e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.872, tt:4947.828\n",
      "Ep:87, loss:0.00002, loss_test:0.09041, lr:5.87e-03, fs:0.75862 (r=0.667,p=0.880),  time:56.874, tt:5004.881\n",
      "Ep:88, loss:0.00002, loss_test:0.09127, lr:5.81e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.883, tt:5062.584\n",
      "Ep:89, loss:0.00002, loss_test:0.09154, lr:5.75e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.868, tt:5118.101\n",
      "Ep:90, loss:0.00002, loss_test:0.09096, lr:5.70e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.884, tt:5176.461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:91, loss:0.00002, loss_test:0.09082, lr:5.64e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.875, tt:5232.456\n",
      "Ep:92, loss:0.00002, loss_test:0.09130, lr:5.58e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.900, tt:5291.659\n",
      "Ep:93, loss:0.00002, loss_test:0.09142, lr:5.53e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.901, tt:5348.670\n",
      "Ep:94, loss:0.00002, loss_test:0.09076, lr:5.47e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.893, tt:5404.841\n",
      "Ep:95, loss:0.00002, loss_test:0.09152, lr:5.42e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.884, tt:5460.865\n",
      "Ep:96, loss:0.00002, loss_test:0.09094, lr:5.36e-03, fs:0.74419 (r=0.646,p=0.877),  time:56.884, tt:5517.772\n",
      "Ep:97, loss:0.00002, loss_test:0.09162, lr:5.31e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.914, tt:5577.535\n",
      "Ep:98, loss:0.00002, loss_test:0.09138, lr:5.26e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.936, tt:5636.672\n",
      "Ep:99, loss:0.00002, loss_test:0.09252, lr:5.20e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.943, tt:5694.301\n",
      "Ep:100, loss:0.00002, loss_test:0.09166, lr:5.15e-03, fs:0.76023 (r=0.657,p=0.903),  time:56.924, tt:5749.368\n",
      "Ep:101, loss:0.00002, loss_test:0.09223, lr:5.10e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.930, tt:5806.879\n",
      "Ep:102, loss:0.00002, loss_test:0.09249, lr:5.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:56.931, tt:5863.881\n",
      "Ep:103, loss:0.00002, loss_test:0.09244, lr:5.00e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.932, tt:5920.976\n",
      "Ep:104, loss:0.00002, loss_test:0.09163, lr:4.95e-03, fs:0.75294 (r=0.646,p=0.901),  time:56.929, tt:5977.559\n",
      "Ep:105, loss:0.00002, loss_test:0.09288, lr:4.90e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.933, tt:6034.946\n",
      "Ep:106, loss:0.00002, loss_test:0.09159, lr:4.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:56.947, tt:6093.314\n",
      "Ep:107, loss:0.00002, loss_test:0.09231, lr:4.80e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.937, tt:6149.194\n",
      "Ep:108, loss:0.00002, loss_test:0.09274, lr:4.75e-03, fs:0.75294 (r=0.646,p=0.901),  time:56.951, tt:6207.675\n",
      "Ep:109, loss:0.00002, loss_test:0.09163, lr:4.71e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.952, tt:6264.694\n",
      "Ep:110, loss:0.00002, loss_test:0.09242, lr:4.66e-03, fs:0.75294 (r=0.646,p=0.901),  time:56.975, tt:6324.186\n",
      "Ep:111, loss:0.00002, loss_test:0.09199, lr:4.61e-03, fs:0.74854 (r=0.646,p=0.889),  time:56.992, tt:6383.113\n",
      "Ep:112, loss:0.00002, loss_test:0.09268, lr:4.57e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.020, tt:6443.276\n",
      "Ep:113, loss:0.00002, loss_test:0.09268, lr:4.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.050, tt:6503.700\n",
      "Ep:114, loss:0.00002, loss_test:0.09319, lr:4.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.073, tt:6563.417\n",
      "Ep:115, loss:0.00002, loss_test:0.09314, lr:4.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.086, tt:6621.940\n",
      "Ep:116, loss:0.00002, loss_test:0.09282, lr:4.39e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.101, tt:6680.806\n",
      "Ep:117, loss:0.00002, loss_test:0.09352, lr:4.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.104, tt:6738.301\n",
      "Ep:118, loss:0.00002, loss_test:0.09237, lr:4.30e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.118, tt:6796.996\n",
      "Ep:119, loss:0.00001, loss_test:0.09309, lr:4.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.136, tt:6856.295\n",
      "Ep:120, loss:0.00001, loss_test:0.09294, lr:4.21e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.174, tt:6918.083\n",
      "Ep:121, loss:0.00001, loss_test:0.09317, lr:4.17e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.176, tt:6975.430\n",
      "Ep:122, loss:0.00001, loss_test:0.09274, lr:4.13e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.189, tt:7034.201\n",
      "Ep:123, loss:0.00001, loss_test:0.09349, lr:4.09e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.201, tt:7092.931\n",
      "Ep:124, loss:0.00001, loss_test:0.09466, lr:4.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:57.200, tt:7150.023\n",
      "Ep:125, loss:0.00001, loss_test:0.09271, lr:4.01e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.198, tt:7206.974\n",
      "Ep:126, loss:0.00001, loss_test:0.09445, lr:3.97e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.205, tt:7264.977\n",
      "Ep:127, loss:0.00001, loss_test:0.09314, lr:3.93e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.207, tt:7322.492\n",
      "Ep:128, loss:0.00001, loss_test:0.09365, lr:3.89e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.225, tt:7382.060\n",
      "Ep:129, loss:0.00001, loss_test:0.09375, lr:3.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.253, tt:7442.855\n",
      "Ep:130, loss:0.00001, loss_test:0.09363, lr:3.81e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.263, tt:7501.418\n",
      "Ep:131, loss:0.00001, loss_test:0.09416, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.270, tt:7559.637\n",
      "Ep:132, loss:0.00001, loss_test:0.09350, lr:3.73e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.283, tt:7618.696\n",
      "Ep:133, loss:0.00001, loss_test:0.09382, lr:3.70e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.306, tt:7679.043\n",
      "Ep:134, loss:0.00001, loss_test:0.09442, lr:3.66e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.310, tt:7736.819\n",
      "Ep:135, loss:0.00001, loss_test:0.09438, lr:3.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.324, tt:7796.050\n",
      "Ep:136, loss:0.00001, loss_test:0.09435, lr:3.59e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.318, tt:7852.525\n",
      "Ep:137, loss:0.00001, loss_test:0.09414, lr:3.55e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.325, tt:7910.826\n",
      "Ep:138, loss:0.00001, loss_test:0.09454, lr:3.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.346, tt:7971.053\n",
      "Ep:139, loss:0.00001, loss_test:0.09388, lr:3.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.355, tt:8029.659\n",
      "Ep:140, loss:0.00001, loss_test:0.09487, lr:3.45e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.367, tt:8088.729\n",
      "Ep:141, loss:0.00001, loss_test:0.09404, lr:3.41e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.402, tt:8151.100\n",
      "Ep:142, loss:0.00001, loss_test:0.09488, lr:3.38e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.421, tt:8211.219\n",
      "Ep:143, loss:0.00001, loss_test:0.09410, lr:3.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.444, tt:8271.946\n",
      "Ep:144, loss:0.00001, loss_test:0.09480, lr:3.31e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.439, tt:8328.656\n",
      "Ep:145, loss:0.00001, loss_test:0.09423, lr:3.28e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.466, tt:8389.996\n",
      "Ep:146, loss:0.00001, loss_test:0.09524, lr:3.24e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.461, tt:8446.823\n",
      "Ep:147, loss:0.00001, loss_test:0.09458, lr:3.21e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.462, tt:8504.398\n",
      "Ep:148, loss:0.00001, loss_test:0.09507, lr:3.18e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.427, tt:8556.617\n",
      "Ep:149, loss:0.00001, loss_test:0.09493, lr:3.15e-03, fs:0.75294 (r=0.646,p=0.901),  time:57.433, tt:8614.959\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 38\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14578, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.566, tt:53.566\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14440, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:55.280, tt:110.561\n",
      "Ep:2, loss:0.00056, loss_test:0.14183, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:55.829, tt:167.488\n",
      "Ep:3, loss:0.00055, loss_test:0.13658, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:55.272, tt:221.088\n",
      "Ep:4, loss:0.00052, loss_test:0.12584, lr:1.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:56.253, tt:281.267\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00048, loss_test:0.11308, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:57.043, tt:342.255\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00045, loss_test:0.10799, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:58.313, tt:408.193\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00043, loss_test:0.10468, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:58.426, tt:467.404\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00040, loss_test:0.10100, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:58.803, tt:529.229\n",
      "Ep:9, loss:0.00038, loss_test:0.09997, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:58.668, tt:586.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00036, loss_test:0.09743, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:59.010, tt:649.108\n",
      "Ep:11, loss:0.00034, loss_test:0.09463, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:59.217, tt:710.608\n",
      "Ep:12, loss:0.00033, loss_test:0.09232, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:59.459, tt:772.968\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.09053, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:59.328, tt:830.591\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.08939, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:59.278, tt:889.165\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.08829, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:59.319, tt:949.104\n",
      "Ep:16, loss:0.00027, loss_test:0.08706, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:59.438, tt:1010.451\n",
      "Ep:17, loss:0.00026, loss_test:0.08488, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:59.429, tt:1069.719\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.08525, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:59.500, tt:1130.493\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.08224, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:59.639, tt:1192.778\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.08190, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:59.561, tt:1250.774\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.08163, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:59.582, tt:1310.811\n",
      "Ep:22, loss:0.00021, loss_test:0.08110, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:59.622, tt:1371.306\n",
      "Ep:23, loss:0.00020, loss_test:0.08018, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:59.656, tt:1431.753\n",
      "Ep:24, loss:0.00018, loss_test:0.07993, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:59.718, tt:1492.944\n",
      "Ep:25, loss:0.00017, loss_test:0.07928, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:59.746, tt:1553.399\n",
      "Ep:26, loss:0.00016, loss_test:0.08116, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:59.725, tt:1612.563\n",
      "Ep:27, loss:0.00016, loss_test:0.07880, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:59.712, tt:1671.950\n",
      "Ep:28, loss:0.00015, loss_test:0.08244, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:59.805, tt:1734.333\n",
      "Ep:29, loss:0.00014, loss_test:0.07799, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:59.889, tt:1796.683\n",
      "Ep:30, loss:0.00013, loss_test:0.07946, lr:1.00e-02, fs:0.76829 (r=0.636,p=0.969),  time:59.887, tt:1856.487\n",
      "Ep:31, loss:0.00012, loss_test:0.07893, lr:1.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:59.918, tt:1917.367\n",
      "Ep:32, loss:0.00012, loss_test:0.07706, lr:9.90e-03, fs:0.76647 (r=0.646,p=0.941),  time:59.943, tt:1978.116\n",
      "Ep:33, loss:0.00011, loss_test:0.07984, lr:9.80e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.973, tt:2039.071\n",
      "Ep:34, loss:0.00011, loss_test:0.07778, lr:9.70e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.943, tt:2098.010\n",
      "Ep:35, loss:0.00010, loss_test:0.07619, lr:9.61e-03, fs:0.78571 (r=0.667,p=0.957),  time:59.915, tt:2156.929\n",
      "Ep:36, loss:0.00010, loss_test:0.07877, lr:9.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.897, tt:2216.192\n",
      "Ep:37, loss:0.00009, loss_test:0.07604, lr:9.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.938, tt:2277.636\n",
      "Ep:38, loss:0.00009, loss_test:0.07664, lr:9.32e-03, fs:0.77844 (r=0.657,p=0.956),  time:59.977, tt:2339.100\n",
      "Ep:39, loss:0.00009, loss_test:0.07683, lr:9.23e-03, fs:0.78107 (r=0.667,p=0.943),  time:60.001, tt:2400.048\n",
      "Ep:40, loss:0.00008, loss_test:0.07583, lr:9.14e-03, fs:0.77844 (r=0.657,p=0.956),  time:59.973, tt:2458.898\n",
      "Ep:41, loss:0.00008, loss_test:0.07631, lr:9.04e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.993, tt:2519.725\n",
      "Ep:42, loss:0.00008, loss_test:0.07591, lr:8.95e-03, fs:0.77108 (r=0.646,p=0.955),  time:59.982, tt:2579.220\n",
      "Ep:43, loss:0.00007, loss_test:0.07631, lr:8.86e-03, fs:0.76364 (r=0.636,p=0.955),  time:60.036, tt:2641.587\n",
      "Ep:44, loss:0.00007, loss_test:0.07773, lr:8.78e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.150, tt:2706.771\n",
      "Ep:45, loss:0.00007, loss_test:0.07827, lr:8.69e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.166, tt:2767.647\n",
      "Ep:46, loss:0.00007, loss_test:0.07789, lr:8.60e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.146, tt:2826.878\n",
      "Ep:47, loss:0.00006, loss_test:0.07484, lr:8.51e-03, fs:0.76364 (r=0.636,p=0.955),  time:60.160, tt:2887.702\n",
      "Ep:48, loss:0.00006, loss_test:0.07682, lr:8.43e-03, fs:0.75904 (r=0.636,p=0.940),  time:60.096, tt:2944.696\n",
      "Ep:49, loss:0.00006, loss_test:0.07650, lr:8.35e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.044, tt:3002.195\n",
      "Ep:50, loss:0.00006, loss_test:0.07643, lr:8.26e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.054, tt:3062.761\n",
      "Ep:51, loss:0.00006, loss_test:0.07535, lr:8.18e-03, fs:0.76364 (r=0.636,p=0.955),  time:60.087, tt:3124.529\n",
      "Ep:52, loss:0.00006, loss_test:0.07646, lr:8.10e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.099, tt:3185.263\n",
      "Ep:53, loss:0.00005, loss_test:0.07494, lr:8.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:60.112, tt:3246.055\n",
      "Ep:54, loss:0.00005, loss_test:0.07685, lr:7.94e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.110, tt:3306.050\n",
      "Ep:55, loss:0.00005, loss_test:0.07684, lr:7.86e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.140, tt:3367.863\n",
      "Ep:56, loss:0.00005, loss_test:0.07494, lr:7.78e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.170, tt:3429.701\n",
      "Ep:57, loss:0.00005, loss_test:0.07912, lr:7.70e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.170, tt:3489.837\n",
      "Ep:58, loss:0.00005, loss_test:0.07401, lr:7.62e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.178, tt:3550.477\n",
      "Ep:59, loss:0.00005, loss_test:0.07686, lr:7.55e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.163, tt:3609.785\n",
      "Ep:60, loss:0.00004, loss_test:0.07821, lr:7.47e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.149, tt:3669.115\n",
      "Ep:61, loss:0.00004, loss_test:0.07673, lr:7.40e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.146, tt:3729.035\n",
      "Ep:62, loss:0.00004, loss_test:0.07667, lr:7.32e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.122, tt:3787.710\n",
      "Ep:63, loss:0.00004, loss_test:0.07763, lr:7.25e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.060, tt:3843.850\n",
      "Ep:64, loss:0.00004, loss_test:0.07655, lr:7.18e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.994, tt:3899.618\n",
      "Ep:65, loss:0.00004, loss_test:0.07887, lr:7.11e-03, fs:0.77019 (r=0.626,p=1.000),  time:59.980, tt:3958.674\n",
      "Ep:66, loss:0.00004, loss_test:0.07677, lr:7.03e-03, fs:0.77576 (r=0.646,p=0.970),  time:59.952, tt:4016.804\n",
      "Ep:67, loss:0.00004, loss_test:0.07650, lr:6.96e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.939, tt:4075.823\n",
      "Ep:68, loss:0.00004, loss_test:0.07781, lr:6.89e-03, fs:0.77019 (r=0.626,p=1.000),  time:59.949, tt:4136.514\n",
      "Ep:69, loss:0.00004, loss_test:0.07650, lr:6.83e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.002, tt:4200.169\n",
      "Ep:70, loss:0.00004, loss_test:0.07837, lr:6.76e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.043, tt:4263.036\n",
      "Ep:71, loss:0.00004, loss_test:0.07734, lr:6.69e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.041, tt:4322.987\n",
      "Ep:72, loss:0.00003, loss_test:0.07665, lr:6.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:60.027, tt:4381.950\n",
      "Ep:73, loss:0.00003, loss_test:0.07849, lr:6.56e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.005, tt:4440.397\n",
      "Ep:74, loss:0.00003, loss_test:0.07701, lr:6.49e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.963, tt:4497.214\n",
      "Ep:75, loss:0.00003, loss_test:0.07824, lr:6.43e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.940, tt:4555.472\n",
      "Ep:76, loss:0.00003, loss_test:0.07726, lr:6.36e-03, fs:0.77778 (r=0.636,p=1.000),  time:60.039, tt:4622.981\n",
      "Ep:77, loss:0.00003, loss_test:0.07805, lr:6.30e-03, fs:0.77778 (r=0.636,p=1.000),  time:60.032, tt:4682.532\n",
      "Ep:78, loss:0.00003, loss_test:0.07744, lr:6.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.008, tt:4740.668\n",
      "Ep:79, loss:0.00003, loss_test:0.07770, lr:6.17e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.026, tt:4802.064\n",
      "Ep:80, loss:0.00003, loss_test:0.07897, lr:6.11e-03, fs:0.77778 (r=0.636,p=1.000),  time:60.054, tt:4864.363\n",
      "Ep:81, loss:0.00003, loss_test:0.07717, lr:6.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:60.066, tt:4925.419\n",
      "Ep:82, loss:0.00003, loss_test:0.07902, lr:5.99e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.073, tt:4986.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00003, loss_test:0.07790, lr:5.93e-03, fs:0.77778 (r=0.636,p=1.000),  time:60.074, tt:5046.176\n",
      "Ep:84, loss:0.00003, loss_test:0.07828, lr:5.87e-03, fs:0.78788 (r=0.657,p=0.985),  time:60.067, tt:5105.682\n",
      "Ep:85, loss:0.00003, loss_test:0.07929, lr:5.81e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.054, tt:5164.685\n",
      "Ep:86, loss:0.00003, loss_test:0.07839, lr:5.75e-03, fs:0.78528 (r=0.646,p=1.000),  time:60.058, tt:5225.059\n",
      "Ep:87, loss:0.00003, loss_test:0.07835, lr:5.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.054, tt:5284.782\n",
      "Ep:88, loss:0.00003, loss_test:0.07863, lr:5.64e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.048, tt:5344.315\n",
      "Ep:89, loss:0.00003, loss_test:0.07883, lr:5.58e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.035, tt:5403.154\n",
      "Ep:90, loss:0.00003, loss_test:0.07926, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.024, tt:5462.149\n",
      "Ep:91, loss:0.00003, loss_test:0.07788, lr:5.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.058, tt:5525.356\n",
      "Ep:92, loss:0.00002, loss_test:0.07891, lr:5.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.077, tt:5587.182\n",
      "Ep:93, loss:0.00002, loss_test:0.08038, lr:5.36e-03, fs:0.77019 (r=0.626,p=1.000),  time:60.066, tt:5646.202\n",
      "Ep:94, loss:0.00002, loss_test:0.07880, lr:5.31e-03, fs:0.78788 (r=0.657,p=0.985),  time:60.070, tt:5706.622\n",
      "Ep:95, loss:0.00002, loss_test:0.08005, lr:5.26e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.089, tt:5768.525\n",
      "Ep:96, loss:0.00002, loss_test:0.07989, lr:5.20e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.065, tt:5826.348\n",
      "Ep:97, loss:0.00002, loss_test:0.07881, lr:5.15e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.058, tt:5885.699\n",
      "Ep:98, loss:0.00002, loss_test:0.08086, lr:5.10e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.050, tt:5944.974\n",
      "Ep:99, loss:0.00002, loss_test:0.07917, lr:5.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:60.020, tt:6001.988\n",
      "Ep:100, loss:0.00002, loss_test:0.08043, lr:5.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.989, tt:6058.871\n",
      "Ep:101, loss:0.00002, loss_test:0.07965, lr:4.95e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.961, tt:6116.072\n",
      "Ep:102, loss:0.00002, loss_test:0.07980, lr:4.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.944, tt:6174.266\n",
      "Ep:103, loss:0.00002, loss_test:0.08102, lr:4.85e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.935, tt:6233.237\n",
      "Ep:104, loss:0.00002, loss_test:0.07904, lr:4.80e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.912, tt:6290.724\n",
      "Ep:105, loss:0.00002, loss_test:0.08125, lr:4.75e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.919, tt:6351.427\n",
      "Ep:106, loss:0.00002, loss_test:0.07998, lr:4.71e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.889, tt:6408.096\n",
      "Ep:107, loss:0.00002, loss_test:0.08134, lr:4.66e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.901, tt:6469.312\n",
      "Ep:108, loss:0.00002, loss_test:0.07983, lr:4.61e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.915, tt:6530.708\n",
      "Ep:109, loss:0.00002, loss_test:0.08229, lr:4.57e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.921, tt:6591.342\n",
      "Ep:110, loss:0.00002, loss_test:0.08007, lr:4.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:59.911, tt:6650.172\n",
      "Ep:111, loss:0.00002, loss_test:0.08194, lr:4.48e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.915, tt:6710.508\n",
      "Ep:112, loss:0.00002, loss_test:0.08034, lr:4.43e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.975, tt:6777.124\n",
      "Ep:113, loss:0.00002, loss_test:0.08147, lr:4.39e-03, fs:0.77301 (r=0.636,p=0.984),  time:59.987, tt:6838.463\n",
      "Ep:114, loss:0.00002, loss_test:0.08073, lr:4.34e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.032, tt:6903.709\n",
      "Ep:115, loss:0.00002, loss_test:0.08229, lr:4.30e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.080, tt:6969.244\n",
      "Ep:116, loss:0.00002, loss_test:0.08118, lr:4.26e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.135, tt:7035.842\n",
      "Ep:117, loss:0.00002, loss_test:0.08179, lr:4.21e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.176, tt:7100.818\n",
      "Ep:118, loss:0.00002, loss_test:0.08184, lr:4.17e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.227, tt:7167.002\n",
      "Ep:119, loss:0.00002, loss_test:0.08165, lr:4.13e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.267, tt:7232.098\n",
      "Ep:120, loss:0.00002, loss_test:0.08111, lr:4.09e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.330, tt:7299.881\n",
      "Ep:121, loss:0.00002, loss_test:0.08217, lr:4.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.356, tt:7363.403\n",
      "Ep:122, loss:0.00002, loss_test:0.08070, lr:4.01e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.386, tt:7427.506\n",
      "Ep:123, loss:0.00002, loss_test:0.08322, lr:3.97e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.421, tt:7492.245\n",
      "Ep:124, loss:0.00002, loss_test:0.08081, lr:3.93e-03, fs:0.77301 (r=0.636,p=0.984),  time:60.469, tt:7558.668\n",
      "Ep:125, loss:0.00002, loss_test:0.08245, lr:3.89e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.493, tt:7622.083\n",
      "Ep:126, loss:0.00002, loss_test:0.08110, lr:3.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:60.501, tt:7683.586\n",
      "Ep:127, loss:0.00002, loss_test:0.08252, lr:3.81e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.538, tt:7748.903\n",
      "Ep:128, loss:0.00002, loss_test:0.08148, lr:3.77e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.586, tt:7815.618\n",
      "Ep:129, loss:0.00001, loss_test:0.08167, lr:3.73e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.616, tt:7880.069\n",
      "Ep:130, loss:0.00001, loss_test:0.08245, lr:3.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.647, tt:7944.820\n",
      "Ep:131, loss:0.00001, loss_test:0.08186, lr:3.66e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.681, tt:8009.860\n",
      "Ep:132, loss:0.00001, loss_test:0.08167, lr:3.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.722, tt:8076.044\n",
      "Ep:133, loss:0.00001, loss_test:0.08240, lr:3.59e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.757, tt:8141.501\n",
      "Ep:134, loss:0.00001, loss_test:0.08257, lr:3.55e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.795, tt:8207.313\n",
      "Ep:135, loss:0.00001, loss_test:0.08182, lr:3.52e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.827, tt:8272.472\n",
      "Ep:136, loss:0.00001, loss_test:0.08304, lr:3.48e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.861, tt:8337.935\n",
      "Ep:137, loss:0.00001, loss_test:0.08161, lr:3.45e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.890, tt:8402.882\n",
      "Ep:138, loss:0.00001, loss_test:0.08385, lr:3.41e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.917, tt:8467.402\n",
      "Ep:139, loss:0.00001, loss_test:0.08149, lr:3.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:60.939, tt:8531.498\n",
      "Ep:140, loss:0.00001, loss_test:0.08442, lr:3.34e-03, fs:0.76543 (r=0.626,p=0.984),  time:60.986, tt:8599.049\n",
      "Ep:141, loss:0.00001, loss_test:0.08208, lr:3.31e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.017, tt:8664.432\n",
      "Ep:142, loss:0.00001, loss_test:0.08366, lr:3.28e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.032, tt:8727.584\n",
      "Ep:143, loss:0.00001, loss_test:0.08227, lr:3.24e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.071, tt:8794.271\n",
      "Ep:144, loss:0.00001, loss_test:0.08370, lr:3.21e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.088, tt:8857.698\n",
      "Ep:145, loss:0.00001, loss_test:0.08230, lr:3.18e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.103, tt:8921.108\n",
      "Ep:146, loss:0.00001, loss_test:0.08357, lr:3.15e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.132, tt:8986.432\n",
      "Ep:147, loss:0.00001, loss_test:0.08300, lr:3.12e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.133, tt:9047.712\n",
      "Ep:148, loss:0.00001, loss_test:0.08332, lr:3.09e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.152, tt:9111.719\n",
      "Ep:149, loss:0.00001, loss_test:0.08325, lr:3.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:61.130, tt:9169.534\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 39\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14363, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:62.344, tt:62.344\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14173, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:63.277, tt:126.555\n",
      "Ep:2, loss:0.00056, loss_test:0.13816, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:62.539, tt:187.618\n",
      "Ep:3, loss:0.00054, loss_test:0.13122, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:62.147, tt:248.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00051, loss_test:0.11862, lr:1.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:62.995, tt:314.973\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00047, loss_test:0.11246, lr:1.00e-02, fs:0.67647 (r=0.697,p=0.657),  time:63.373, tt:380.239\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00045, loss_test:0.10797, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:63.952, tt:447.661\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00042, loss_test:0.10497, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:64.042, tt:512.338\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00040, loss_test:0.10261, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:64.583, tt:581.244\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.10061, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:64.427, tt:644.274\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.09891, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:64.643, tt:711.075\n",
      "Ep:11, loss:0.00034, loss_test:0.09727, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:64.823, tt:777.878\n",
      "Ep:12, loss:0.00032, loss_test:0.09631, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:65.091, tt:846.186\n",
      "Ep:13, loss:0.00031, loss_test:0.09605, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:65.228, tt:913.186\n",
      "Ep:14, loss:0.00030, loss_test:0.09583, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:65.265, tt:978.976\n",
      "Ep:15, loss:0.00029, loss_test:0.09506, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:65.370, tt:1045.912\n",
      "Ep:16, loss:0.00028, loss_test:0.09644, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:65.438, tt:1112.444\n",
      "Ep:17, loss:0.00027, loss_test:0.09320, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:65.424, tt:1177.626\n",
      "Ep:18, loss:0.00026, loss_test:0.09307, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:65.402, tt:1242.629\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.09298, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:65.409, tt:1308.170\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.09039, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:65.490, tt:1375.284\n",
      "Ep:21, loss:0.00022, loss_test:0.09236, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:65.527, tt:1441.587\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.08968, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:65.472, tt:1505.864\n",
      "Ep:23, loss:0.00020, loss_test:0.09123, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:65.476, tt:1571.424\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.09134, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:65.426, tt:1635.650\n",
      "Ep:25, loss:0.00019, loss_test:0.09005, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:65.522, tt:1703.581\n",
      "Ep:26, loss:0.00018, loss_test:0.09098, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:65.591, tt:1770.964\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.08775, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:65.659, tt:1838.446\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.09082, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:65.657, tt:1904.049\n",
      "Ep:29, loss:0.00015, loss_test:0.08893, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:65.713, tt:1971.381\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.08827, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:65.677, tt:2035.982\n",
      "Ep:31, loss:0.00013, loss_test:0.08683, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:65.729, tt:2103.326\n",
      "Ep:32, loss:0.00012, loss_test:0.08787, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:65.722, tt:2168.838\n",
      "Ep:33, loss:0.00012, loss_test:0.08824, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:65.783, tt:2236.624\n",
      "Ep:34, loss:0.00011, loss_test:0.08782, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:65.729, tt:2300.531\n",
      "Ep:35, loss:0.00011, loss_test:0.08892, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:65.763, tt:2367.453\n",
      "Ep:36, loss:0.00010, loss_test:0.08683, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:65.752, tt:2432.834\n",
      "Ep:37, loss:0.00010, loss_test:0.08678, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:65.693, tt:2496.334\n",
      "Ep:38, loss:0.00009, loss_test:0.09375, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:65.677, tt:2561.393\n",
      "Ep:39, loss:0.00009, loss_test:0.08855, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:65.683, tt:2627.304\n",
      "Ep:40, loss:0.00009, loss_test:0.09145, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:65.697, tt:2693.588\n",
      "Ep:41, loss:0.00008, loss_test:0.09202, lr:9.90e-03, fs:0.79545 (r=0.707,p=0.909),  time:65.737, tt:2760.951\n",
      "Ep:42, loss:0.00008, loss_test:0.09154, lr:9.80e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.754, tt:2827.411\n",
      "Ep:43, loss:0.00008, loss_test:0.09223, lr:9.70e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.725, tt:2891.882\n",
      "Ep:44, loss:0.00007, loss_test:0.09021, lr:9.61e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.727, tt:2957.720\n",
      "Ep:45, loss:0.00007, loss_test:0.09600, lr:9.51e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.677, tt:3021.156\n",
      "Ep:46, loss:0.00007, loss_test:0.09091, lr:9.41e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.683, tt:3087.095\n",
      "Ep:47, loss:0.00007, loss_test:0.09726, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.670, tt:3152.166\n",
      "Ep:48, loss:0.00006, loss_test:0.09290, lr:9.23e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.666, tt:3217.617\n",
      "Ep:49, loss:0.00006, loss_test:0.09472, lr:9.14e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.673, tt:3283.656\n",
      "Ep:50, loss:0.00006, loss_test:0.09508, lr:9.04e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.686, tt:3350.002\n",
      "Ep:51, loss:0.00005, loss_test:0.09747, lr:8.95e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.690, tt:3415.897\n",
      "Ep:52, loss:0.00005, loss_test:0.09419, lr:8.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.652, tt:3479.541\n",
      "Ep:53, loss:0.00005, loss_test:0.09745, lr:8.78e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.671, tt:3546.249\n",
      "Ep:54, loss:0.00005, loss_test:0.09584, lr:8.69e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.690, tt:3612.975\n",
      "Ep:55, loss:0.00005, loss_test:0.09742, lr:8.60e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.697, tt:3679.046\n",
      "Ep:56, loss:0.00004, loss_test:0.09815, lr:8.51e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.693, tt:3744.529\n",
      "Ep:57, loss:0.00004, loss_test:0.09761, lr:8.43e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.700, tt:3810.608\n",
      "Ep:58, loss:0.00004, loss_test:0.09917, lr:8.35e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.721, tt:3877.523\n",
      "Ep:59, loss:0.00004, loss_test:0.09809, lr:8.26e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.748, tt:3944.890\n",
      "Ep:60, loss:0.00004, loss_test:0.09955, lr:8.18e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.715, tt:4008.613\n",
      "Ep:61, loss:0.00004, loss_test:0.09710, lr:8.10e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.708, tt:4073.876\n",
      "Ep:62, loss:0.00004, loss_test:0.09962, lr:8.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.713, tt:4139.931\n",
      "Ep:63, loss:0.00004, loss_test:0.09981, lr:7.94e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.678, tt:4203.402\n",
      "Ep:64, loss:0.00003, loss_test:0.09910, lr:7.86e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.684, tt:4269.490\n",
      "Ep:65, loss:0.00003, loss_test:0.09974, lr:7.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.713, tt:4337.049\n",
      "Ep:66, loss:0.00003, loss_test:0.09897, lr:7.70e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.715, tt:4402.921\n",
      "Ep:67, loss:0.00003, loss_test:0.10006, lr:7.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.715, tt:4468.644\n",
      "Ep:68, loss:0.00003, loss_test:0.09936, lr:7.55e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.689, tt:4532.527\n",
      "Ep:69, loss:0.00003, loss_test:0.09975, lr:7.47e-03, fs:0.80925 (r=0.707,p=0.946),  time:65.686, tt:4598.022\n",
      "Ep:70, loss:0.00003, loss_test:0.10038, lr:7.40e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.688, tt:4663.848\n",
      "Ep:71, loss:0.00003, loss_test:0.09994, lr:7.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.687, tt:4729.434\n",
      "Ep:72, loss:0.00003, loss_test:0.10063, lr:7.25e-03, fs:0.81871 (r=0.707,p=0.972),  time:65.673, tt:4794.137\n",
      "Ep:73, loss:0.00003, loss_test:0.10129, lr:7.18e-03, fs:0.81871 (r=0.707,p=0.972),  time:65.651, tt:4858.177\n",
      "Ep:74, loss:0.00003, loss_test:0.09994, lr:7.11e-03, fs:0.81395 (r=0.707,p=0.959),  time:65.642, tt:4923.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00002, loss_test:0.10154, lr:7.03e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.646, tt:4989.120\n",
      "Ep:76, loss:0.00002, loss_test:0.10103, lr:6.96e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.634, tt:5053.822\n",
      "Ep:77, loss:0.00002, loss_test:0.10143, lr:6.89e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.642, tt:5120.046\n",
      "Ep:78, loss:0.00002, loss_test:0.10218, lr:6.83e-03, fs:0.81657 (r=0.697,p=0.986),  time:65.600, tt:5182.397\n",
      "Ep:79, loss:0.00002, loss_test:0.09952, lr:6.76e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.522, tt:5241.762\n",
      "Ep:80, loss:0.00002, loss_test:0.10405, lr:6.69e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.462, tt:5302.450\n",
      "Ep:81, loss:0.00002, loss_test:0.10168, lr:6.62e-03, fs:0.81871 (r=0.707,p=0.972),  time:65.375, tt:5360.733\n",
      "Ep:82, loss:0.00002, loss_test:0.10285, lr:6.56e-03, fs:0.81657 (r=0.697,p=0.986),  time:65.301, tt:5419.948\n",
      "Ep:83, loss:0.00002, loss_test:0.10253, lr:6.49e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.260, tt:5481.818\n",
      "Ep:84, loss:0.00002, loss_test:0.10222, lr:6.43e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.175, tt:5539.853\n",
      "Ep:85, loss:0.00002, loss_test:0.10213, lr:6.36e-03, fs:0.81657 (r=0.697,p=0.986),  time:65.102, tt:5598.808\n",
      "Ep:86, loss:0.00002, loss_test:0.10198, lr:6.30e-03, fs:0.82353 (r=0.707,p=0.986),  time:65.050, tt:5659.343\n",
      "Ep:87, loss:0.00002, loss_test:0.10330, lr:6.24e-03, fs:0.80240 (r=0.677,p=0.985),  time:64.993, tt:5719.419\n",
      "Ep:88, loss:0.00002, loss_test:0.10163, lr:6.17e-03, fs:0.82353 (r=0.707,p=0.986),  time:64.907, tt:5776.740\n",
      "Ep:89, loss:0.00002, loss_test:0.10285, lr:6.11e-03, fs:0.81657 (r=0.697,p=0.986),  time:64.866, tt:5837.958\n",
      "Ep:90, loss:0.00002, loss_test:0.10194, lr:6.05e-03, fs:0.82353 (r=0.707,p=0.986),  time:64.794, tt:5896.245\n",
      "Ep:91, loss:0.00002, loss_test:0.10184, lr:5.99e-03, fs:0.80240 (r=0.677,p=0.985),  time:64.731, tt:5955.236\n",
      "Ep:92, loss:0.00002, loss_test:0.10245, lr:5.93e-03, fs:0.81657 (r=0.697,p=0.986),  time:64.665, tt:6013.874\n",
      "Ep:93, loss:0.00002, loss_test:0.10251, lr:5.87e-03, fs:0.82353 (r=0.707,p=0.986),  time:64.589, tt:6071.377\n",
      "Ep:94, loss:0.00002, loss_test:0.10233, lr:5.81e-03, fs:0.79518 (r=0.667,p=0.985),  time:64.535, tt:6130.779\n",
      "Ep:95, loss:0.00002, loss_test:0.10269, lr:5.75e-03, fs:0.82353 (r=0.707,p=0.986),  time:64.487, tt:6190.718\n",
      "Ep:96, loss:0.00002, loss_test:0.10306, lr:5.70e-03, fs:0.80240 (r=0.677,p=0.985),  time:64.410, tt:6247.749\n",
      "Ep:97, loss:0.00002, loss_test:0.10271, lr:5.64e-03, fs:0.80240 (r=0.677,p=0.985),  time:64.347, tt:6305.975\n",
      "Ep:98, loss:0.00002, loss_test:0.10244, lr:5.58e-03, fs:0.80952 (r=0.687,p=0.986),  time:64.291, tt:6364.854\n",
      "Ep:99, loss:0.00002, loss_test:0.10303, lr:5.53e-03, fs:0.80240 (r=0.677,p=0.985),  time:64.245, tt:6424.470\n",
      "Ep:100, loss:0.00001, loss_test:0.10253, lr:5.47e-03, fs:0.78788 (r=0.657,p=0.985),  time:64.198, tt:6483.960\n",
      "Ep:101, loss:0.00001, loss_test:0.10321, lr:5.42e-03, fs:0.80952 (r=0.687,p=0.986),  time:64.172, tt:6545.527\n",
      "Ep:102, loss:0.00001, loss_test:0.10329, lr:5.36e-03, fs:0.78788 (r=0.657,p=0.985),  time:64.136, tt:6605.963\n",
      "Ep:103, loss:0.00001, loss_test:0.10221, lr:5.31e-03, fs:0.80952 (r=0.687,p=0.986),  time:64.091, tt:6665.416\n",
      "Ep:104, loss:0.00001, loss_test:0.10378, lr:5.26e-03, fs:0.79518 (r=0.667,p=0.985),  time:64.052, tt:6725.501\n",
      "Ep:105, loss:0.00001, loss_test:0.10231, lr:5.20e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.983, tt:6782.193\n",
      "Ep:106, loss:0.00001, loss_test:0.10370, lr:5.15e-03, fs:0.81657 (r=0.697,p=0.986),  time:63.951, tt:6842.725\n",
      "Ep:107, loss:0.00001, loss_test:0.10349, lr:5.10e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.892, tt:6900.288\n",
      "Ep:108, loss:0.00001, loss_test:0.10272, lr:5.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:63.853, tt:6959.995\n",
      "Ep:109, loss:0.00001, loss_test:0.10514, lr:5.00e-03, fs:0.79518 (r=0.667,p=0.985),  time:63.799, tt:7017.854\n",
      "Ep:110, loss:0.00001, loss_test:0.10294, lr:4.95e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.791, tt:7080.757\n",
      "Ep:111, loss:0.00001, loss_test:0.10456, lr:4.90e-03, fs:0.78788 (r=0.657,p=0.985),  time:63.758, tt:7140.925\n",
      "Ep:112, loss:0.00001, loss_test:0.10370, lr:4.85e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.706, tt:7198.828\n",
      "Ep:113, loss:0.00001, loss_test:0.10415, lr:4.80e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.685, tt:7260.042\n",
      "Ep:114, loss:0.00001, loss_test:0.10415, lr:4.75e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.664, tt:7321.351\n",
      "Ep:115, loss:0.00001, loss_test:0.10389, lr:4.71e-03, fs:0.78049 (r=0.646,p=0.985),  time:63.616, tt:7379.473\n",
      "Ep:116, loss:0.00001, loss_test:0.10394, lr:4.66e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.605, tt:7441.756\n",
      "Ep:117, loss:0.00001, loss_test:0.10400, lr:4.61e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.567, tt:7500.929\n",
      "Ep:118, loss:0.00001, loss_test:0.10421, lr:4.57e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.537, tt:7560.953\n",
      "Ep:119, loss:0.00001, loss_test:0.10460, lr:4.52e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.490, tt:7618.744\n",
      "Ep:120, loss:0.00001, loss_test:0.10404, lr:4.48e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.475, tt:7680.443\n",
      "Ep:121, loss:0.00001, loss_test:0.10472, lr:4.43e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.446, tt:7740.402\n",
      "Ep:122, loss:0.00001, loss_test:0.10408, lr:4.39e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.412, tt:7799.705\n",
      "Ep:123, loss:0.00001, loss_test:0.10437, lr:4.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:63.375, tt:7858.472\n",
      "Ep:124, loss:0.00001, loss_test:0.10497, lr:4.30e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.341, tt:7917.659\n",
      "Ep:125, loss:0.00001, loss_test:0.10503, lr:4.26e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.279, tt:7973.194\n",
      "Ep:126, loss:0.00001, loss_test:0.10491, lr:4.21e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.264, tt:8034.589\n",
      "Ep:127, loss:0.00001, loss_test:0.10515, lr:4.17e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.246, tt:8095.492\n",
      "Ep:128, loss:0.00001, loss_test:0.10487, lr:4.13e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.213, tt:8154.455\n",
      "Ep:129, loss:0.00001, loss_test:0.10451, lr:4.09e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.176, tt:8212.942\n",
      "Ep:130, loss:0.00001, loss_test:0.10519, lr:4.05e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.150, tt:8272.669\n",
      "Ep:131, loss:0.00001, loss_test:0.10452, lr:4.01e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.136, tt:8333.988\n",
      "Ep:132, loss:0.00001, loss_test:0.10556, lr:3.97e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.104, tt:8392.825\n",
      "Ep:133, loss:0.00001, loss_test:0.10519, lr:3.93e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.076, tt:8452.169\n",
      "Ep:134, loss:0.00001, loss_test:0.10603, lr:3.89e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.052, tt:8511.976\n",
      "Ep:135, loss:0.00001, loss_test:0.10590, lr:3.85e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.038, tt:8573.207\n",
      "Ep:136, loss:0.00001, loss_test:0.10528, lr:3.81e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.024, tt:8634.274\n",
      "Ep:137, loss:0.00001, loss_test:0.10607, lr:3.77e-03, fs:0.77301 (r=0.636,p=0.984),  time:63.012, tt:8695.666\n",
      "Ep:138, loss:0.00001, loss_test:0.10595, lr:3.73e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.978, tt:8753.969\n",
      "Ep:139, loss:0.00001, loss_test:0.10577, lr:3.70e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.957, tt:8813.956\n",
      "Ep:140, loss:0.00001, loss_test:0.10594, lr:3.66e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.927, tt:8872.687\n",
      "Ep:141, loss:0.00001, loss_test:0.10634, lr:3.62e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.853, tt:8925.162\n",
      "Ep:142, loss:0.00001, loss_test:0.10556, lr:3.59e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.773, tt:8976.502\n",
      "Ep:143, loss:0.00001, loss_test:0.10641, lr:3.55e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.703, tt:9029.173\n",
      "Ep:144, loss:0.00001, loss_test:0.10525, lr:3.52e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.620, tt:9079.831\n",
      "Ep:145, loss:0.00001, loss_test:0.10601, lr:3.48e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.550, tt:9132.254\n",
      "Ep:146, loss:0.00001, loss_test:0.10625, lr:3.45e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.437, tt:9178.243\n",
      "Ep:147, loss:0.00001, loss_test:0.10569, lr:3.41e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.315, tt:9222.566\n",
      "Ep:148, loss:0.00001, loss_test:0.10652, lr:3.38e-03, fs:0.77301 (r=0.636,p=0.984),  time:62.128, tt:9257.099\n",
      "Ep:149, loss:0.00001, loss_test:0.10594, lr:3.34e-03, fs:0.77301 (r=0.636,p=0.984),  time:61.879, tt:9281.810\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14459, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.984, tt:8.984\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14442, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.198, tt:20.396\n",
      "Ep:2, loss:0.00000, loss_test:0.14417, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.201, tt:33.603\n",
      "Ep:3, loss:0.00000, loss_test:0.14382, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.873, tt:47.491\n",
      "Ep:4, loss:0.00000, loss_test:0.14339, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.534, tt:62.669\n",
      "Ep:5, loss:0.00000, loss_test:0.14287, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.244, tt:79.466\n",
      "Ep:6, loss:0.00000, loss_test:0.14225, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.849, tt:96.945\n",
      "Ep:7, loss:0.00000, loss_test:0.14151, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.306, tt:114.452\n",
      "Ep:8, loss:0.00000, loss_test:0.14064, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.750, tt:132.747\n",
      "Ep:9, loss:0.00000, loss_test:0.13957, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.924, tt:149.243\n",
      "Ep:10, loss:0.00000, loss_test:0.13829, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:15.039, tt:165.424\n",
      "Ep:11, loss:0.00000, loss_test:0.13686, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:15.123, tt:181.475\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00000, loss_test:0.13516, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:15.252, tt:198.278\n",
      "Ep:13, loss:0.00000, loss_test:0.13310, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:15.361, tt:215.050\n",
      "Ep:14, loss:0.00000, loss_test:0.13082, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:15.523, tt:232.841\n",
      "Ep:15, loss:0.00000, loss_test:0.12844, lr:1.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:15.634, tt:250.150\n",
      "Ep:16, loss:0.00000, loss_test:0.12586, lr:1.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:15.725, tt:267.318\n",
      "Ep:17, loss:0.00000, loss_test:0.12290, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:15.793, tt:284.270\n",
      "Ep:18, loss:0.00000, loss_test:0.12037, lr:1.00e-02, fs:0.66667 (r=0.717,p=0.623),  time:15.894, tt:301.989\n",
      "Ep:19, loss:0.00000, loss_test:0.11867, lr:1.00e-02, fs:0.65700 (r=0.687,p=0.630),  time:15.976, tt:319.521\n",
      "Ep:20, loss:0.00000, loss_test:0.11741, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:16.014, tt:336.299\n",
      "Ep:21, loss:0.00000, loss_test:0.11597, lr:1.00e-02, fs:0.65366 (r=0.677,p=0.632),  time:16.092, tt:354.031\n",
      "Ep:22, loss:0.00000, loss_test:0.11442, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:16.145, tt:371.327\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.11358, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:16.200, tt:388.796\n",
      "Ep:24, loss:0.00000, loss_test:0.11263, lr:1.00e-02, fs:0.67857 (r=0.768,p=0.608),  time:16.258, tt:406.447\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00000, loss_test:0.11088, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:16.343, tt:424.927\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00000, loss_test:0.10825, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:16.379, tt:442.241\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00000, loss_test:0.10566, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:16.452, tt:460.654\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00000, loss_test:0.10410, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:16.487, tt:478.131\n",
      "Ep:29, loss:0.00000, loss_test:0.10297, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:16.541, tt:496.242\n",
      "Ep:30, loss:0.00000, loss_test:0.10188, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:16.613, tt:515.016\n",
      "Ep:31, loss:0.00000, loss_test:0.10081, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:16.650, tt:532.816\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.10014, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:16.663, tt:549.889\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.09933, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:16.689, tt:567.416\n",
      "Ep:34, loss:0.00000, loss_test:0.09845, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:16.711, tt:584.901\n",
      "Ep:35, loss:0.00000, loss_test:0.09764, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:16.744, tt:602.771\n",
      "Ep:36, loss:0.00000, loss_test:0.09717, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:16.756, tt:619.979\n",
      "Ep:37, loss:0.00000, loss_test:0.09682, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:16.770, tt:637.268\n",
      "Ep:38, loss:0.00000, loss_test:0.09620, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:16.785, tt:654.611\n",
      "Ep:39, loss:0.00000, loss_test:0.09563, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.821, tt:672.851\n",
      "Ep:40, loss:0.00000, loss_test:0.09500, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.833, tt:690.143\n",
      "Ep:41, loss:0.00000, loss_test:0.09425, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:16.860, tt:708.107\n",
      "Ep:42, loss:0.00000, loss_test:0.09372, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:16.884, tt:726.030\n",
      "Ep:43, loss:0.00000, loss_test:0.09343, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:16.911, tt:744.074\n",
      "Ep:44, loss:0.00000, loss_test:0.09305, lr:9.90e-03, fs:0.72637 (r=0.737,p=0.716),  time:16.934, tt:762.017\n",
      "Ep:45, loss:0.00000, loss_test:0.09250, lr:9.80e-03, fs:0.73267 (r=0.747,p=0.718),  time:16.952, tt:779.793\n",
      "Ep:46, loss:0.00000, loss_test:0.09189, lr:9.70e-03, fs:0.73529 (r=0.758,p=0.714),  time:16.985, tt:798.281\n",
      "Ep:47, loss:0.00000, loss_test:0.09138, lr:9.61e-03, fs:0.74146 (r=0.768,p=0.717),  time:17.000, tt:816.009\n",
      "Ep:48, loss:0.00000, loss_test:0.09092, lr:9.51e-03, fs:0.73529 (r=0.758,p=0.714),  time:17.014, tt:833.704\n",
      "Ep:49, loss:0.00000, loss_test:0.09058, lr:9.41e-03, fs:0.72637 (r=0.737,p=0.716),  time:17.043, tt:852.158\n",
      "Ep:50, loss:0.00000, loss_test:0.09030, lr:9.32e-03, fs:0.73000 (r=0.737,p=0.723),  time:17.038, tt:868.913\n",
      "Ep:51, loss:0.00000, loss_test:0.08993, lr:9.23e-03, fs:0.74257 (r=0.758,p=0.728),  time:17.045, tt:886.330\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00000, loss_test:0.08948, lr:9.23e-03, fs:0.73892 (r=0.758,p=0.721),  time:17.063, tt:904.351\n",
      "Ep:53, loss:0.00000, loss_test:0.08902, lr:9.23e-03, fs:0.73892 (r=0.758,p=0.721),  time:17.062, tt:921.341\n",
      "Ep:54, loss:0.00000, loss_test:0.08859, lr:9.23e-03, fs:0.73892 (r=0.758,p=0.721),  time:17.071, tt:938.881\n",
      "Ep:55, loss:0.00000, loss_test:0.08821, lr:9.23e-03, fs:0.74000 (r=0.747,p=0.733),  time:17.084, tt:956.712\n",
      "Ep:56, loss:0.00000, loss_test:0.08786, lr:9.23e-03, fs:0.74000 (r=0.747,p=0.733),  time:17.080, tt:973.541\n",
      "Ep:57, loss:0.00000, loss_test:0.08747, lr:9.23e-03, fs:0.74000 (r=0.747,p=0.733),  time:17.097, tt:991.605\n",
      "Ep:58, loss:0.00000, loss_test:0.08699, lr:9.23e-03, fs:0.74000 (r=0.747,p=0.733),  time:17.089, tt:1008.261\n",
      "Ep:59, loss:0.00000, loss_test:0.08650, lr:9.23e-03, fs:0.73632 (r=0.747,p=0.725),  time:17.112, tt:1026.707\n",
      "Ep:60, loss:0.00000, loss_test:0.08610, lr:9.23e-03, fs:0.74000 (r=0.747,p=0.733),  time:17.135, tt:1045.239\n",
      "Ep:61, loss:0.00000, loss_test:0.08582, lr:9.23e-03, fs:0.74372 (r=0.747,p=0.740),  time:17.153, tt:1063.498\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00000, loss_test:0.08557, lr:9.23e-03, fs:0.74372 (r=0.747,p=0.740),  time:17.157, tt:1080.912\n",
      "Ep:63, loss:0.00000, loss_test:0.08523, lr:9.23e-03, fs:0.73737 (r=0.737,p=0.737),  time:17.174, tt:1099.163\n",
      "Ep:64, loss:0.00000, loss_test:0.08481, lr:9.23e-03, fs:0.74372 (r=0.747,p=0.740),  time:17.183, tt:1116.906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00000, loss_test:0.08433, lr:9.23e-03, fs:0.75000 (r=0.758,p=0.743),  time:17.174, tt:1133.510\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00000, loss_test:0.08387, lr:9.23e-03, fs:0.75622 (r=0.768,p=0.745),  time:17.177, tt:1150.888\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00000, loss_test:0.08347, lr:9.23e-03, fs:0.75622 (r=0.768,p=0.745),  time:17.165, tt:1167.213\n",
      "Ep:68, loss:0.00000, loss_test:0.08312, lr:9.23e-03, fs:0.75622 (r=0.768,p=0.745),  time:17.160, tt:1184.068\n",
      "Ep:69, loss:0.00000, loss_test:0.08275, lr:9.23e-03, fs:0.76238 (r=0.778,p=0.748),  time:17.166, tt:1201.611\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00000, loss_test:0.08230, lr:9.23e-03, fs:0.76238 (r=0.778,p=0.748),  time:17.169, tt:1219.011\n",
      "Ep:71, loss:0.00000, loss_test:0.08189, lr:9.23e-03, fs:0.76617 (r=0.778,p=0.755),  time:17.183, tt:1237.191\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00000, loss_test:0.08162, lr:9.23e-03, fs:0.77833 (r=0.798,p=0.760),  time:17.184, tt:1254.442\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00000, loss_test:0.08142, lr:9.23e-03, fs:0.77833 (r=0.798,p=0.760),  time:17.198, tt:1272.652\n",
      "Ep:74, loss:0.00000, loss_test:0.08118, lr:9.23e-03, fs:0.77833 (r=0.798,p=0.760),  time:17.202, tt:1290.123\n",
      "Ep:75, loss:0.00000, loss_test:0.08090, lr:9.23e-03, fs:0.78431 (r=0.808,p=0.762),  time:17.194, tt:1306.734\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00000, loss_test:0.08060, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.194, tt:1323.915\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00000, loss_test:0.08036, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.206, tt:1342.050\n",
      "Ep:78, loss:0.00000, loss_test:0.08015, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.205, tt:1359.221\n",
      "Ep:79, loss:0.00000, loss_test:0.07992, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.210, tt:1376.812\n",
      "Ep:80, loss:0.00000, loss_test:0.07965, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.212, tt:1394.195\n",
      "Ep:81, loss:0.00000, loss_test:0.07933, lr:9.23e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.212, tt:1411.410\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00000, loss_test:0.07901, lr:9.23e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.219, tt:1429.137\n",
      "Ep:83, loss:0.00000, loss_test:0.07879, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.225, tt:1446.934\n",
      "Ep:84, loss:0.00000, loss_test:0.07859, lr:9.23e-03, fs:0.80000 (r=0.828,p=0.774),  time:17.230, tt:1464.557\n",
      "Ep:85, loss:0.00000, loss_test:0.07831, lr:9.23e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.245, tt:1483.111\n",
      "Ep:86, loss:0.00000, loss_test:0.07796, lr:9.23e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.263, tt:1501.875\n",
      "Ep:87, loss:0.00000, loss_test:0.07769, lr:9.23e-03, fs:0.80976 (r=0.838,p=0.783),  time:17.265, tt:1519.282\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00000, loss_test:0.07755, lr:9.23e-03, fs:0.80976 (r=0.838,p=0.783),  time:17.264, tt:1536.529\n",
      "Ep:89, loss:0.00000, loss_test:0.07735, lr:9.23e-03, fs:0.80976 (r=0.838,p=0.783),  time:17.272, tt:1554.480\n",
      "Ep:90, loss:0.00000, loss_test:0.07702, lr:9.23e-03, fs:0.81773 (r=0.838,p=0.798),  time:17.274, tt:1571.955\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00000, loss_test:0.07673, lr:9.23e-03, fs:0.81773 (r=0.838,p=0.798),  time:17.271, tt:1588.969\n",
      "Ep:92, loss:0.00000, loss_test:0.07652, lr:9.23e-03, fs:0.81188 (r=0.828,p=0.796),  time:17.279, tt:1606.977\n",
      "Ep:93, loss:0.00000, loss_test:0.07638, lr:9.23e-03, fs:0.82000 (r=0.828,p=0.812),  time:17.273, tt:1623.696\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00000, loss_test:0.07624, lr:9.23e-03, fs:0.82000 (r=0.828,p=0.812),  time:17.282, tt:1641.756\n",
      "Ep:95, loss:0.00000, loss_test:0.07605, lr:9.23e-03, fs:0.82412 (r=0.828,p=0.820),  time:17.284, tt:1659.235\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00000, loss_test:0.07584, lr:9.23e-03, fs:0.82412 (r=0.828,p=0.820),  time:17.286, tt:1676.695\n",
      "Ep:97, loss:0.00000, loss_test:0.07558, lr:9.23e-03, fs:0.82412 (r=0.828,p=0.820),  time:17.291, tt:1694.503\n",
      "Ep:98, loss:0.00000, loss_test:0.07524, lr:9.23e-03, fs:0.83000 (r=0.838,p=0.822),  time:17.284, tt:1711.086\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00000, loss_test:0.07497, lr:9.23e-03, fs:0.83000 (r=0.838,p=0.822),  time:17.278, tt:1727.771\n",
      "Ep:100, loss:0.00000, loss_test:0.07492, lr:9.23e-03, fs:0.83000 (r=0.838,p=0.822),  time:17.270, tt:1744.258\n",
      "Ep:101, loss:0.00000, loss_test:0.07490, lr:9.23e-03, fs:0.83000 (r=0.838,p=0.822),  time:17.271, tt:1761.654\n",
      "Ep:102, loss:0.00000, loss_test:0.07481, lr:9.23e-03, fs:0.83000 (r=0.838,p=0.822),  time:17.270, tt:1778.861\n",
      "Ep:103, loss:0.00000, loss_test:0.07463, lr:9.23e-03, fs:0.83000 (r=0.838,p=0.822),  time:17.266, tt:1795.652\n",
      "Ep:104, loss:0.00000, loss_test:0.07435, lr:9.23e-03, fs:0.83417 (r=0.838,p=0.830),  time:17.258, tt:1812.119\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.07413, lr:9.23e-03, fs:0.83417 (r=0.838,p=0.830),  time:17.262, tt:1829.746\n",
      "Ep:106, loss:0.00000, loss_test:0.07403, lr:9.23e-03, fs:0.83417 (r=0.838,p=0.830),  time:17.260, tt:1846.802\n",
      "Ep:107, loss:0.00000, loss_test:0.07388, lr:9.23e-03, fs:0.83417 (r=0.838,p=0.830),  time:17.251, tt:1863.157\n",
      "Ep:108, loss:0.00000, loss_test:0.07364, lr:9.23e-03, fs:0.83417 (r=0.838,p=0.830),  time:17.240, tt:1879.173\n",
      "Ep:109, loss:0.00000, loss_test:0.07357, lr:9.23e-03, fs:0.83838 (r=0.838,p=0.838),  time:17.236, tt:1895.996\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.07362, lr:9.23e-03, fs:0.83838 (r=0.838,p=0.838),  time:17.230, tt:1912.536\n",
      "Ep:111, loss:0.00000, loss_test:0.07364, lr:9.23e-03, fs:0.83838 (r=0.838,p=0.838),  time:17.218, tt:1928.371\n",
      "Ep:112, loss:0.00000, loss_test:0.07361, lr:9.23e-03, fs:0.83838 (r=0.838,p=0.838),  time:17.206, tt:1944.306\n",
      "Ep:113, loss:0.00000, loss_test:0.07351, lr:9.23e-03, fs:0.84264 (r=0.838,p=0.847),  time:17.199, tt:1960.665\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00000, loss_test:0.07344, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.195, tt:1977.473\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00000, loss_test:0.07328, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.189, tt:1993.944\n",
      "Ep:116, loss:0.00000, loss_test:0.07314, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.187, tt:2010.867\n",
      "Ep:117, loss:0.00000, loss_test:0.07310, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.193, tt:2028.800\n",
      "Ep:118, loss:0.00000, loss_test:0.07310, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.189, tt:2045.518\n",
      "Ep:119, loss:0.00000, loss_test:0.07300, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.195, tt:2063.353\n",
      "Ep:120, loss:0.00000, loss_test:0.07284, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.194, tt:2080.432\n",
      "Ep:121, loss:0.00000, loss_test:0.07284, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.197, tt:2098.027\n",
      "Ep:122, loss:0.00000, loss_test:0.07279, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.201, tt:2115.751\n",
      "Ep:123, loss:0.00000, loss_test:0.07270, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.207, tt:2133.620\n",
      "Ep:124, loss:0.00000, loss_test:0.07269, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.202, tt:2150.307\n",
      "Ep:125, loss:0.00000, loss_test:0.07267, lr:9.23e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.206, tt:2168.013\n",
      "Ep:126, loss:0.00000, loss_test:0.07249, lr:9.14e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.203, tt:2184.733\n",
      "Ep:127, loss:0.00000, loss_test:0.07227, lr:9.04e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.201, tt:2201.721\n",
      "Ep:128, loss:0.00000, loss_test:0.07214, lr:8.95e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.206, tt:2219.516\n",
      "Ep:129, loss:0.00000, loss_test:0.07208, lr:8.86e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.199, tt:2235.891\n",
      "Ep:130, loss:0.00000, loss_test:0.07192, lr:8.78e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.202, tt:2253.510\n",
      "Ep:131, loss:0.00000, loss_test:0.07174, lr:8.69e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.209, tt:2271.537\n",
      "Ep:132, loss:0.00000, loss_test:0.07177, lr:8.60e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.208, tt:2288.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.07179, lr:8.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:17.212, tt:2306.415\n",
      "Ep:134, loss:0.00000, loss_test:0.07163, lr:8.43e-03, fs:0.84103 (r=0.828,p=0.854),  time:17.216, tt:2324.096\n",
      "Ep:135, loss:0.00000, loss_test:0.07142, lr:8.35e-03, fs:0.85714 (r=0.848,p=0.866),  time:17.222, tt:2342.131\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.07133, lr:8.35e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.232, tt:2360.782\n",
      "Ep:137, loss:0.00000, loss_test:0.07135, lr:8.35e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.236, tt:2378.600\n",
      "Ep:138, loss:0.00000, loss_test:0.07127, lr:8.35e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.242, tt:2396.695\n",
      "Ep:139, loss:0.00000, loss_test:0.07120, lr:8.35e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.248, tt:2414.782\n",
      "Ep:140, loss:0.00000, loss_test:0.07116, lr:8.35e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.250, tt:2432.289\n",
      "Ep:141, loss:0.00000, loss_test:0.07108, lr:8.35e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.250, tt:2449.564\n",
      "Ep:142, loss:0.00000, loss_test:0.07087, lr:8.35e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.252, tt:2467.046\n",
      "Ep:143, loss:0.00000, loss_test:0.07080, lr:8.35e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.257, tt:2485.077\n",
      "Ep:144, loss:0.00000, loss_test:0.07078, lr:8.35e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.262, tt:2503.029\n",
      "Ep:145, loss:0.00000, loss_test:0.07076, lr:8.35e-03, fs:0.83938 (r=0.818,p=0.862),  time:17.274, tt:2522.069\n",
      "Ep:146, loss:0.00000, loss_test:0.07068, lr:8.35e-03, fs:0.83938 (r=0.818,p=0.862),  time:17.275, tt:2539.404\n",
      "Ep:147, loss:0.00000, loss_test:0.07062, lr:8.26e-03, fs:0.83938 (r=0.818,p=0.862),  time:17.276, tt:2556.879\n",
      "Ep:148, loss:0.00000, loss_test:0.07060, lr:8.18e-03, fs:0.83938 (r=0.818,p=0.862),  time:17.276, tt:2574.062\n",
      "Ep:149, loss:0.00000, loss_test:0.07051, lr:8.10e-03, fs:0.83938 (r=0.818,p=0.862),  time:17.285, tt:2592.719\n",
      "Ep:150, loss:0.00000, loss_test:0.07037, lr:8.02e-03, fs:0.83938 (r=0.818,p=0.862),  time:17.289, tt:2610.578\n",
      "Ep:151, loss:0.00000, loss_test:0.07029, lr:7.94e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.291, tt:2628.182\n",
      "Ep:152, loss:0.00000, loss_test:0.07027, lr:7.86e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.296, tt:2646.256\n",
      "Ep:153, loss:0.00000, loss_test:0.07028, lr:7.78e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.298, tt:2663.860\n",
      "Ep:154, loss:0.00000, loss_test:0.07013, lr:7.70e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.306, tt:2682.483\n",
      "Ep:155, loss:0.00000, loss_test:0.06996, lr:7.62e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.317, tt:2701.429\n",
      "Ep:156, loss:0.00000, loss_test:0.06990, lr:7.55e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.323, tt:2719.775\n",
      "Ep:157, loss:0.00000, loss_test:0.06988, lr:7.47e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.326, tt:2737.495\n",
      "Ep:158, loss:0.00000, loss_test:0.06973, lr:7.40e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.334, tt:2756.104\n",
      "Ep:159, loss:0.00000, loss_test:0.06955, lr:7.32e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.338, tt:2774.153\n",
      "Ep:160, loss:0.00000, loss_test:0.06952, lr:7.25e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.349, tt:2793.247\n",
      "Ep:161, loss:0.00000, loss_test:0.06953, lr:7.18e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.352, tt:2811.022\n",
      "Ep:162, loss:0.00000, loss_test:0.06948, lr:7.11e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.355, tt:2828.793\n",
      "Ep:163, loss:0.00000, loss_test:0.06939, lr:7.03e-03, fs:0.86010 (r=0.838,p=0.883),  time:17.355, tt:2846.284\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00000, loss_test:0.06935, lr:7.03e-03, fs:0.86010 (r=0.838,p=0.883),  time:17.358, tt:2864.102\n",
      "Ep:165, loss:0.00000, loss_test:0.06932, lr:7.03e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.365, tt:2882.620\n",
      "Ep:166, loss:0.00000, loss_test:0.06921, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.364, tt:2899.851\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00000, loss_test:0.06906, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.369, tt:2918.022\n",
      "Ep:168, loss:0.00000, loss_test:0.06897, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.375, tt:2936.314\n",
      "Ep:169, loss:0.00000, loss_test:0.06886, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.374, tt:2953.624\n",
      "Ep:170, loss:0.00000, loss_test:0.06868, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.384, tt:2972.739\n",
      "Ep:171, loss:0.00000, loss_test:0.06853, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.387, tt:2990.619\n",
      "Ep:172, loss:0.00000, loss_test:0.06857, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.391, tt:3008.647\n",
      "Ep:173, loss:0.00000, loss_test:0.06862, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.397, tt:3027.103\n",
      "Ep:174, loss:0.00000, loss_test:0.06858, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.402, tt:3045.434\n",
      "Ep:175, loss:0.00000, loss_test:0.06850, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.404, tt:3063.076\n",
      "Ep:176, loss:0.00000, loss_test:0.06847, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.404, tt:3080.513\n",
      "Ep:177, loss:0.00000, loss_test:0.06848, lr:7.03e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.404, tt:3097.848\n",
      "Ep:178, loss:0.00000, loss_test:0.06846, lr:6.96e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.409, tt:3116.132\n",
      "Ep:179, loss:0.00000, loss_test:0.06841, lr:6.89e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.408, tt:3133.430\n",
      "Ep:180, loss:0.00000, loss_test:0.06840, lr:6.83e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.409, tt:3150.975\n",
      "Ep:181, loss:0.00000, loss_test:0.06840, lr:6.76e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.415, tt:3169.487\n",
      "Ep:182, loss:0.00000, loss_test:0.06833, lr:6.69e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.418, tt:3187.494\n",
      "Ep:183, loss:0.00000, loss_test:0.06828, lr:6.62e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.425, tt:3206.133\n",
      "Ep:184, loss:0.00000, loss_test:0.06832, lr:6.56e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.426, tt:3223.800\n",
      "Ep:185, loss:0.00000, loss_test:0.06838, lr:6.49e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.430, tt:3242.036\n",
      "Ep:186, loss:0.00000, loss_test:0.06833, lr:6.43e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.429, tt:3259.275\n",
      "Ep:187, loss:0.00000, loss_test:0.06830, lr:6.36e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.430, tt:3276.815\n",
      "Ep:188, loss:0.00000, loss_test:0.06833, lr:6.30e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.428, tt:3293.881\n",
      "Ep:189, loss:0.00000, loss_test:0.06836, lr:6.24e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.428, tt:3311.245\n",
      "Ep:190, loss:0.00000, loss_test:0.06829, lr:6.17e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.432, tt:3329.545\n",
      "Ep:191, loss:0.00000, loss_test:0.06818, lr:6.11e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.435, tt:3347.556\n",
      "Ep:192, loss:0.00000, loss_test:0.06815, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.431, tt:3364.271\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00000, loss_test:0.06817, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.428, tt:3381.050\n",
      "Ep:194, loss:0.00000, loss_test:0.06813, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.425, tt:3397.939\n",
      "Ep:195, loss:0.00000, loss_test:0.06808, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.424, tt:3415.107\n",
      "Ep:196, loss:0.00000, loss_test:0.06809, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.419, tt:3431.603\n",
      "Ep:197, loss:0.00000, loss_test:0.06808, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.416, tt:3448.298\n",
      "Ep:198, loss:0.00000, loss_test:0.06802, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.414, tt:3465.453\n",
      "Ep:199, loss:0.00000, loss_test:0.06799, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.413, tt:3482.548\n",
      "Ep:200, loss:0.00000, loss_test:0.06797, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.409, tt:3499.300\n",
      "Ep:201, loss:0.00000, loss_test:0.06797, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.406, tt:3515.949\n",
      "Ep:202, loss:0.00000, loss_test:0.06796, lr:6.05e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.408, tt:3533.868\n",
      "Ep:203, loss:0.00000, loss_test:0.06794, lr:6.05e-03, fs:0.86911 (r=0.838,p=0.902),  time:17.409, tt:3551.429\n",
      "Ep:204, loss:0.00000, loss_test:0.06790, lr:5.99e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.415, tt:3570.040\n",
      "Ep:205, loss:0.00000, loss_test:0.06787, lr:5.93e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.409, tt:3586.223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.06785, lr:5.87e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.409, tt:3603.698\n",
      "Ep:207, loss:0.00000, loss_test:0.06783, lr:5.81e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.413, tt:3621.943\n",
      "Ep:208, loss:0.00000, loss_test:0.06776, lr:5.75e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.417, tt:3640.251\n",
      "Ep:209, loss:0.00000, loss_test:0.06769, lr:5.70e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.418, tt:3657.878\n",
      "Ep:210, loss:0.00000, loss_test:0.06764, lr:5.64e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.422, tt:3676.000\n",
      "Ep:211, loss:0.00000, loss_test:0.06761, lr:5.58e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.428, tt:3694.712\n",
      "Ep:212, loss:0.00000, loss_test:0.06757, lr:5.53e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.429, tt:3712.431\n",
      "Ep:213, loss:0.00000, loss_test:0.06758, lr:5.47e-03, fs:0.86911 (r=0.838,p=0.902),  time:17.430, tt:3730.106\n",
      "Ep:214, loss:0.00000, loss_test:0.06761, lr:5.42e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.435, tt:3748.626\n",
      "Ep:215, loss:0.00000, loss_test:0.06760, lr:5.36e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.438, tt:3766.633\n",
      "Ep:216, loss:0.00000, loss_test:0.06759, lr:5.31e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.442, tt:3784.868\n",
      "Ep:217, loss:0.00000, loss_test:0.06760, lr:5.26e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.443, tt:3802.660\n",
      "Ep:218, loss:0.00000, loss_test:0.06759, lr:5.20e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.447, tt:3820.876\n",
      "Ep:219, loss:0.00000, loss_test:0.06760, lr:5.15e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.450, tt:3839.071\n",
      "Ep:220, loss:0.00000, loss_test:0.06761, lr:5.10e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.455, tt:3857.503\n",
      "Ep:221, loss:0.00000, loss_test:0.06761, lr:5.05e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.452, tt:3874.438\n",
      "Ep:222, loss:0.00000, loss_test:0.06757, lr:5.00e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.450, tt:3891.357\n",
      "Ep:223, loss:0.00000, loss_test:0.06748, lr:4.95e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.457, tt:3910.432\n",
      "Ep:224, loss:0.00000, loss_test:0.06740, lr:4.90e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.458, tt:3928.016\n",
      "Ep:225, loss:0.00000, loss_test:0.06742, lr:4.85e-03, fs:0.83871 (r=0.788,p=0.897),  time:17.452, tt:3944.187\n",
      "Ep:226, loss:0.00000, loss_test:0.06746, lr:4.80e-03, fs:0.83871 (r=0.788,p=0.897),  time:17.453, tt:3961.810\n",
      "Ep:227, loss:0.00000, loss_test:0.06744, lr:4.75e-03, fs:0.83871 (r=0.788,p=0.897),  time:17.450, tt:3978.650\n",
      "Ep:228, loss:0.00000, loss_test:0.06742, lr:4.71e-03, fs:0.83871 (r=0.788,p=0.897),  time:17.448, tt:3995.545\n",
      "Ep:229, loss:0.00000, loss_test:0.06744, lr:4.66e-03, fs:0.82609 (r=0.768,p=0.894),  time:17.447, tt:4012.744\n",
      "Ep:230, loss:0.00000, loss_test:0.06747, lr:4.61e-03, fs:0.82609 (r=0.768,p=0.894),  time:17.442, tt:4029.179\n",
      "Ep:231, loss:0.00000, loss_test:0.06745, lr:4.57e-03, fs:0.82609 (r=0.768,p=0.894),  time:17.439, tt:4045.839\n",
      "Ep:232, loss:0.00000, loss_test:0.06737, lr:4.52e-03, fs:0.82609 (r=0.768,p=0.894),  time:17.436, tt:4062.543\n",
      "Ep:233, loss:0.00000, loss_test:0.06733, lr:4.48e-03, fs:0.83243 (r=0.778,p=0.895),  time:17.435, tt:4079.857\n",
      "Ep:234, loss:0.00000, loss_test:0.06734, lr:4.43e-03, fs:0.82609 (r=0.768,p=0.894),  time:17.434, tt:4097.052\n",
      "Ep:235, loss:0.00000, loss_test:0.06737, lr:4.39e-03, fs:0.81967 (r=0.758,p=0.893),  time:17.432, tt:4113.926\n",
      "Ep:236, loss:0.00000, loss_test:0.06739, lr:4.34e-03, fs:0.81319 (r=0.747,p=0.892),  time:17.433, tt:4131.525\n",
      "Ep:237, loss:0.00000, loss_test:0.06739, lr:4.30e-03, fs:0.81319 (r=0.747,p=0.892),  time:17.432, tt:4148.911\n",
      "Ep:238, loss:0.00000, loss_test:0.06739, lr:4.26e-03, fs:0.81319 (r=0.747,p=0.892),  time:17.429, tt:4165.483\n",
      "Ep:239, loss:0.00000, loss_test:0.06737, lr:4.21e-03, fs:0.81319 (r=0.747,p=0.892),  time:17.424, tt:4181.675\n",
      "Ep:240, loss:0.00000, loss_test:0.06735, lr:4.17e-03, fs:0.81319 (r=0.747,p=0.892),  time:17.421, tt:4198.442\n",
      "Ep:241, loss:0.00000, loss_test:0.06735, lr:4.13e-03, fs:0.80663 (r=0.737,p=0.890),  time:17.417, tt:4214.986\n",
      "Ep:242, loss:0.00000, loss_test:0.06739, lr:4.09e-03, fs:0.80663 (r=0.737,p=0.890),  time:17.412, tt:4231.020\n",
      "Ep:243, loss:0.00000, loss_test:0.06739, lr:4.05e-03, fs:0.80663 (r=0.737,p=0.890),  time:17.413, tt:4248.732\n",
      "Ep:244, loss:0.00000, loss_test:0.06738, lr:4.01e-03, fs:0.81111 (r=0.737,p=0.901),  time:17.411, tt:4265.647\n",
      "Ep:245, loss:0.00000, loss_test:0.06738, lr:3.97e-03, fs:0.81111 (r=0.737,p=0.901),  time:17.411, tt:4283.014\n",
      "Ep:246, loss:0.00000, loss_test:0.06740, lr:3.93e-03, fs:0.81111 (r=0.737,p=0.901),  time:17.408, tt:4299.824\n",
      "Ep:247, loss:0.00000, loss_test:0.06737, lr:3.89e-03, fs:0.80447 (r=0.727,p=0.900),  time:17.407, tt:4316.883\n",
      "Ep:248, loss:0.00000, loss_test:0.06733, lr:3.85e-03, fs:0.80447 (r=0.727,p=0.900),  time:17.404, tt:4333.614\n",
      "Ep:249, loss:0.00000, loss_test:0.06731, lr:3.81e-03, fs:0.80447 (r=0.727,p=0.900),  time:17.403, tt:4350.630\n",
      "Ep:250, loss:0.00000, loss_test:0.06736, lr:3.77e-03, fs:0.80447 (r=0.727,p=0.900),  time:17.397, tt:4366.764\n",
      "Ep:251, loss:0.00000, loss_test:0.06743, lr:3.73e-03, fs:0.80447 (r=0.727,p=0.900),  time:17.394, tt:4383.324\n",
      "Ep:252, loss:0.00000, loss_test:0.06745, lr:3.70e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.389, tt:4399.451\n",
      "Ep:253, loss:0.00000, loss_test:0.06743, lr:3.66e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.386, tt:4415.974\n",
      "Ep:254, loss:0.00000, loss_test:0.06739, lr:3.62e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.386, tt:4433.457\n",
      "Ep:255, loss:0.00000, loss_test:0.06737, lr:3.59e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.387, tt:4451.024\n",
      "Ep:256, loss:0.00000, loss_test:0.06738, lr:3.55e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.389, tt:4469.053\n",
      "Ep:257, loss:0.00000, loss_test:0.06738, lr:3.52e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.391, tt:4486.768\n",
      "Ep:258, loss:0.00000, loss_test:0.06740, lr:3.48e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.393, tt:4504.816\n",
      "Ep:259, loss:0.00000, loss_test:0.06744, lr:3.45e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.397, tt:4523.123\n",
      "Ep:260, loss:0.00000, loss_test:0.06748, lr:3.41e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.400, tt:4541.301\n",
      "Ep:261, loss:0.00000, loss_test:0.06750, lr:3.38e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.402, tt:4559.372\n",
      "Ep:262, loss:0.00000, loss_test:0.06749, lr:3.34e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.407, tt:4577.996\n",
      "Ep:263, loss:0.00000, loss_test:0.06746, lr:3.31e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.412, tt:4596.672\n",
      "Ep:264, loss:0.00000, loss_test:0.06746, lr:3.28e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.416, tt:4615.207\n",
      "Ep:265, loss:0.00000, loss_test:0.06750, lr:3.24e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.418, tt:4633.150\n",
      "Ep:266, loss:0.00000, loss_test:0.06753, lr:3.21e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.419, tt:4650.965\n",
      "Ep:267, loss:0.00000, loss_test:0.06753, lr:3.18e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.420, tt:4668.532\n",
      "Ep:268, loss:0.00000, loss_test:0.06751, lr:3.15e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.428, tt:4688.239\n",
      "Ep:269, loss:0.00000, loss_test:0.06749, lr:3.12e-03, fs:0.79775 (r=0.717,p=0.899),  time:17.429, tt:4705.854\n",
      "Ep:270, loss:0.00000, loss_test:0.06747, lr:3.09e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.435, tt:4724.870\n",
      "Ep:271, loss:0.00000, loss_test:0.06746, lr:3.05e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.440, tt:4743.702\n",
      "Ep:272, loss:0.00000, loss_test:0.06747, lr:3.02e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.447, tt:4762.942\n",
      "Ep:273, loss:0.00000, loss_test:0.06749, lr:2.99e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.452, tt:4781.945\n",
      "Ep:274, loss:0.00000, loss_test:0.06751, lr:2.96e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.459, tt:4801.348\n",
      "Ep:275, loss:0.00000, loss_test:0.06749, lr:2.93e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.458, tt:4818.443\n",
      "Ep:276, loss:0.00000, loss_test:0.06748, lr:2.90e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.454, tt:4834.766\n",
      "Ep:277, loss:0.00000, loss_test:0.06747, lr:2.88e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.453, tt:4851.925\n",
      "Ep:278, loss:0.00000, loss_test:0.06749, lr:2.85e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.453, tt:4869.251\n",
      "Ep:279, loss:0.00000, loss_test:0.06752, lr:2.82e-03, fs:0.80226 (r=0.717,p=0.910),  time:17.448, tt:4885.562\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14695, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.546, tt:14.546\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14682, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.608, tt:31.216\n",
      "Ep:2, loss:0.00000, loss_test:0.14663, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.398, tt:46.195\n",
      "Ep:3, loss:0.00000, loss_test:0.14635, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.083, tt:64.334\n",
      "Ep:4, loss:0.00000, loss_test:0.14601, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.724, tt:83.618\n",
      "Ep:5, loss:0.00000, loss_test:0.14561, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.269, tt:103.617\n",
      "Ep:6, loss:0.00000, loss_test:0.14511, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.493, tt:122.452\n",
      "Ep:7, loss:0.00000, loss_test:0.14451, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.697, tt:141.576\n",
      "Ep:8, loss:0.00000, loss_test:0.14379, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:17.862, tt:160.760\n",
      "Ep:9, loss:0.00000, loss_test:0.14289, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:17.960, tt:179.602\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00000, loss_test:0.14181, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:18.026, tt:198.285\n",
      "Ep:11, loss:0.00000, loss_test:0.14060, lr:1.00e-02, fs:0.64057 (r=0.909,p=0.495),  time:18.105, tt:217.257\n",
      "Ep:12, loss:0.00000, loss_test:0.13918, lr:1.00e-02, fs:0.63538 (r=0.889,p=0.494),  time:18.185, tt:236.404\n",
      "Ep:13, loss:0.00000, loss_test:0.13772, lr:1.00e-02, fs:0.63235 (r=0.869,p=0.497),  time:18.244, tt:255.415\n",
      "Ep:14, loss:0.00000, loss_test:0.13644, lr:1.00e-02, fs:0.62548 (r=0.818,p=0.506),  time:18.313, tt:274.699\n",
      "Ep:15, loss:0.00000, loss_test:0.13512, lr:1.00e-02, fs:0.62857 (r=0.778,p=0.527),  time:18.354, tt:293.657\n",
      "Ep:16, loss:0.00000, loss_test:0.13368, lr:1.00e-02, fs:0.62222 (r=0.707,p=0.556),  time:18.384, tt:312.524\n",
      "Ep:17, loss:0.00000, loss_test:0.13360, lr:1.00e-02, fs:0.60697 (r=0.616,p=0.598),  time:18.447, tt:332.054\n",
      "Ep:18, loss:0.00000, loss_test:0.13465, lr:1.00e-02, fs:0.61376 (r=0.586,p=0.644),  time:18.466, tt:350.861\n",
      "Ep:19, loss:0.00000, loss_test:0.13516, lr:1.00e-02, fs:0.59140 (r=0.556,p=0.632),  time:18.475, tt:369.505\n",
      "Ep:20, loss:0.00000, loss_test:0.13399, lr:1.00e-02, fs:0.58511 (r=0.556,p=0.618),  time:18.485, tt:388.176\n",
      "Ep:21, loss:0.00000, loss_test:0.13180, lr:9.90e-03, fs:0.59898 (r=0.596,p=0.602),  time:18.477, tt:406.489\n",
      "Ep:22, loss:0.00000, loss_test:0.12976, lr:9.80e-03, fs:0.60784 (r=0.626,p=0.590),  time:18.494, tt:425.352\n",
      "Ep:23, loss:0.00000, loss_test:0.12843, lr:9.70e-03, fs:0.62201 (r=0.657,p=0.591),  time:18.519, tt:444.467\n",
      "Ep:24, loss:0.00000, loss_test:0.12715, lr:9.61e-03, fs:0.63317 (r=0.636,p=0.630),  time:18.517, tt:462.922\n",
      "Ep:25, loss:0.00000, loss_test:0.12640, lr:9.51e-03, fs:0.63492 (r=0.606,p=0.667),  time:18.499, tt:480.977\n",
      "Ep:26, loss:0.00000, loss_test:0.12653, lr:9.41e-03, fs:0.62032 (r=0.586,p=0.659),  time:18.495, tt:499.376\n",
      "Ep:27, loss:0.00000, loss_test:0.12681, lr:9.32e-03, fs:0.60571 (r=0.535,p=0.697),  time:18.505, tt:518.139\n",
      "Ep:28, loss:0.00000, loss_test:0.12658, lr:9.23e-03, fs:0.58621 (r=0.515,p=0.680),  time:18.497, tt:536.417\n",
      "Ep:29, loss:0.00000, loss_test:0.12541, lr:9.14e-03, fs:0.61798 (r=0.556,p=0.696),  time:18.489, tt:554.664\n",
      "Ep:30, loss:0.00000, loss_test:0.12391, lr:9.04e-03, fs:0.62295 (r=0.576,p=0.679),  time:18.483, tt:572.987\n",
      "Ep:31, loss:0.00000, loss_test:0.12277, lr:8.95e-03, fs:0.63830 (r=0.606,p=0.674),  time:18.499, tt:591.958\n",
      "Ep:32, loss:0.00000, loss_test:0.12212, lr:8.86e-03, fs:0.63492 (r=0.606,p=0.667),  time:18.486, tt:610.037\n",
      "Ep:33, loss:0.00000, loss_test:0.12182, lr:8.78e-03, fs:0.63102 (r=0.596,p=0.670),  time:18.500, tt:628.989\n",
      "Ep:34, loss:0.00000, loss_test:0.12189, lr:8.69e-03, fs:0.61957 (r=0.576,p=0.671),  time:18.500, tt:647.509\n",
      "Ep:35, loss:0.00000, loss_test:0.12213, lr:8.60e-03, fs:0.62637 (r=0.576,p=0.687),  time:18.487, tt:665.527\n",
      "Ep:36, loss:0.00000, loss_test:0.12222, lr:8.51e-03, fs:0.61453 (r=0.556,p=0.688),  time:18.502, tt:684.573\n",
      "Ep:37, loss:0.00000, loss_test:0.12208, lr:8.43e-03, fs:0.61798 (r=0.556,p=0.696),  time:18.503, tt:703.133\n",
      "Ep:38, loss:0.00000, loss_test:0.12168, lr:8.35e-03, fs:0.62921 (r=0.566,p=0.709),  time:18.511, tt:721.929\n",
      "Ep:39, loss:0.00000, loss_test:0.12120, lr:8.26e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.509, tt:740.353\n",
      "Ep:40, loss:0.00000, loss_test:0.12078, lr:8.18e-03, fs:0.65193 (r=0.596,p=0.720),  time:18.501, tt:758.539\n",
      "Ep:41, loss:0.00000, loss_test:0.12055, lr:8.10e-03, fs:0.64444 (r=0.586,p=0.716),  time:18.497, tt:776.857\n",
      "Ep:42, loss:0.00000, loss_test:0.12042, lr:8.02e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.500, tt:795.496\n",
      "Ep:43, loss:0.00000, loss_test:0.12043, lr:7.94e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.501, tt:814.027\n",
      "Ep:44, loss:0.00000, loss_test:0.12044, lr:7.86e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.498, tt:832.403\n",
      "Ep:45, loss:0.00000, loss_test:0.12026, lr:7.78e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.491, tt:850.566\n",
      "Ep:46, loss:0.00000, loss_test:0.11990, lr:7.70e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.482, tt:868.673\n",
      "Ep:47, loss:0.00000, loss_test:0.11954, lr:7.62e-03, fs:0.64740 (r=0.566,p=0.757),  time:18.495, tt:887.776\n",
      "Ep:48, loss:0.00000, loss_test:0.11925, lr:7.55e-03, fs:0.64368 (r=0.566,p=0.747),  time:18.518, tt:907.380\n",
      "Ep:49, loss:0.00000, loss_test:0.11909, lr:7.47e-03, fs:0.63158 (r=0.545,p=0.750),  time:18.506, tt:925.323\n",
      "Ep:50, loss:0.00000, loss_test:0.11911, lr:7.40e-03, fs:0.63529 (r=0.545,p=0.761),  time:18.502, tt:943.586\n",
      "Ep:51, loss:0.00000, loss_test:0.11923, lr:7.32e-03, fs:0.63905 (r=0.545,p=0.771),  time:18.491, tt:961.533\n",
      "Ep:52, loss:0.00000, loss_test:0.11934, lr:7.25e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.483, tt:979.605\n",
      "Ep:53, loss:0.00000, loss_test:0.11936, lr:7.18e-03, fs:0.63855 (r=0.535,p=0.791),  time:18.482, tt:998.054\n",
      "Ep:54, loss:0.00000, loss_test:0.11928, lr:7.11e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.493, tt:1017.125\n",
      "Ep:55, loss:0.00000, loss_test:0.11909, lr:7.03e-03, fs:0.64286 (r=0.545,p=0.783),  time:18.508, tt:1036.424\n",
      "Ep:56, loss:0.00000, loss_test:0.11882, lr:6.96e-03, fs:0.64286 (r=0.545,p=0.783),  time:18.507, tt:1054.892\n",
      "Ep:57, loss:0.00000, loss_test:0.11859, lr:6.89e-03, fs:0.64286 (r=0.545,p=0.783),  time:18.510, tt:1073.575\n",
      "Ep:58, loss:0.00000, loss_test:0.11847, lr:6.83e-03, fs:0.64286 (r=0.545,p=0.783),  time:18.518, tt:1092.586\n",
      "Ep:59, loss:0.00000, loss_test:0.11841, lr:6.76e-03, fs:0.64286 (r=0.545,p=0.783),  time:18.533, tt:1111.998\n",
      "Ep:60, loss:0.00000, loss_test:0.11837, lr:6.69e-03, fs:0.64286 (r=0.545,p=0.783),  time:18.536, tt:1130.701\n",
      "Ep:61, loss:0.00000, loss_test:0.11831, lr:6.62e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.534, tt:1149.130\n",
      "Ep:62, loss:0.00000, loss_test:0.11818, lr:6.56e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.542, tt:1168.145\n",
      "Ep:63, loss:0.00000, loss_test:0.11798, lr:6.49e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.541, tt:1186.604\n",
      "Ep:64, loss:0.00000, loss_test:0.11772, lr:6.43e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.545, tt:1205.428\n",
      "Ep:65, loss:0.00000, loss_test:0.11746, lr:6.36e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.540, tt:1223.663\n",
      "Ep:66, loss:0.00000, loss_test:0.11727, lr:6.30e-03, fs:0.64671 (r=0.545,p=0.794),  time:18.542, tt:1242.295\n",
      "Ep:67, loss:0.00000, loss_test:0.11712, lr:6.24e-03, fs:0.65455 (r=0.545,p=0.818),  time:18.545, tt:1261.091\n",
      "Ep:68, loss:0.00000, loss_test:0.11697, lr:6.17e-03, fs:0.65455 (r=0.545,p=0.818),  time:18.541, tt:1279.335\n",
      "Ep:69, loss:0.00000, loss_test:0.11679, lr:6.11e-03, fs:0.65455 (r=0.545,p=0.818),  time:18.540, tt:1297.822\n",
      "Ep:70, loss:0.00000, loss_test:0.11656, lr:6.05e-03, fs:0.65455 (r=0.545,p=0.818),  time:18.551, tt:1317.121\n",
      "Ep:71, loss:0.00000, loss_test:0.11633, lr:5.99e-03, fs:0.67066 (r=0.566,p=0.824),  time:18.556, tt:1336.014\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00000, loss_test:0.11614, lr:5.99e-03, fs:0.67857 (r=0.576,p=0.826),  time:18.559, tt:1354.776\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00000, loss_test:0.11599, lr:5.99e-03, fs:0.67857 (r=0.576,p=0.826),  time:18.564, tt:1373.752\n",
      "Ep:74, loss:0.00000, loss_test:0.11588, lr:5.99e-03, fs:0.68263 (r=0.576,p=0.838),  time:18.570, tt:1392.743\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00000, loss_test:0.11577, lr:5.99e-03, fs:0.67879 (r=0.566,p=0.848),  time:18.583, tt:1412.343\n",
      "Ep:76, loss:0.00000, loss_test:0.11562, lr:5.99e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.589, tt:1431.335\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00000, loss_test:0.11544, lr:5.99e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.603, tt:1450.998\n",
      "Ep:78, loss:0.00000, loss_test:0.11527, lr:5.99e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.609, tt:1470.109\n",
      "Ep:79, loss:0.00000, loss_test:0.11517, lr:5.99e-03, fs:0.68293 (r=0.566,p=0.862),  time:18.605, tt:1488.417\n",
      "Ep:80, loss:0.00000, loss_test:0.11512, lr:5.99e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.610, tt:1507.445\n",
      "Ep:81, loss:0.00000, loss_test:0.11509, lr:5.99e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.614, tt:1526.335\n",
      "Ep:82, loss:0.00000, loss_test:0.11505, lr:5.99e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.605, tt:1544.245\n",
      "Ep:83, loss:0.00000, loss_test:0.11496, lr:5.99e-03, fs:0.67901 (r=0.556,p=0.873),  time:18.612, tt:1563.393\n",
      "Ep:84, loss:0.00000, loss_test:0.11484, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.609, tt:1581.754\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00000, loss_test:0.11471, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.613, tt:1600.685\n",
      "Ep:86, loss:0.00000, loss_test:0.11462, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.606, tt:1618.707\n",
      "Ep:87, loss:0.00000, loss_test:0.11454, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.612, tt:1637.841\n",
      "Ep:88, loss:0.00000, loss_test:0.11446, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.615, tt:1656.725\n",
      "Ep:89, loss:0.00000, loss_test:0.11441, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.616, tt:1675.404\n",
      "Ep:90, loss:0.00000, loss_test:0.11441, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.619, tt:1694.343\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00000, loss_test:0.11443, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.623, tt:1713.299\n",
      "Ep:92, loss:0.00000, loss_test:0.11445, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.628, tt:1732.451\n",
      "Ep:93, loss:0.00000, loss_test:0.11444, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.635, tt:1751.730\n",
      "Ep:94, loss:0.00000, loss_test:0.11438, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.631, tt:1769.967\n",
      "Ep:95, loss:0.00000, loss_test:0.11428, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.636, tt:1789.047\n",
      "Ep:96, loss:0.00000, loss_test:0.11418, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.643, tt:1808.400\n",
      "Ep:97, loss:0.00000, loss_test:0.11420, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.649, tt:1827.608\n",
      "Ep:98, loss:0.00000, loss_test:0.11429, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.653, tt:1846.644\n",
      "Ep:99, loss:0.00000, loss_test:0.11436, lr:5.99e-03, fs:0.68712 (r=0.566,p=0.875),  time:18.655, tt:1865.483\n",
      "Ep:100, loss:0.00000, loss_test:0.11435, lr:5.99e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.651, tt:1883.709\n",
      "Ep:101, loss:0.00000, loss_test:0.11426, lr:5.99e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.644, tt:1901.712\n",
      "Ep:102, loss:0.00000, loss_test:0.11414, lr:5.93e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.652, tt:1921.152\n",
      "Ep:103, loss:0.00000, loss_test:0.11404, lr:5.87e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.664, tt:1941.070\n",
      "Ep:104, loss:0.00000, loss_test:0.11404, lr:5.81e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.674, tt:1960.809\n",
      "Ep:105, loss:0.00000, loss_test:0.11419, lr:5.75e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.679, tt:1979.944\n",
      "Ep:106, loss:0.00000, loss_test:0.11438, lr:5.70e-03, fs:0.69136 (r=0.566,p=0.889),  time:18.681, tt:1998.831\n",
      "Ep:107, loss:0.00000, loss_test:0.11448, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.684, tt:2017.926\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.11451, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.686, tt:2036.794\n",
      "Ep:109, loss:0.00000, loss_test:0.11448, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.688, tt:2055.693\n",
      "Ep:110, loss:0.00000, loss_test:0.11445, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.687, tt:2074.268\n",
      "Ep:111, loss:0.00000, loss_test:0.11445, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.692, tt:2093.495\n",
      "Ep:112, loss:0.00000, loss_test:0.11446, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.697, tt:2112.795\n",
      "Ep:113, loss:0.00000, loss_test:0.11448, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.694, tt:2131.073\n",
      "Ep:114, loss:0.00000, loss_test:0.11453, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.688, tt:2149.120\n",
      "Ep:115, loss:0.00000, loss_test:0.11458, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.676, tt:2166.427\n",
      "Ep:116, loss:0.00000, loss_test:0.11462, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.678, tt:2185.380\n",
      "Ep:117, loss:0.00000, loss_test:0.11469, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.674, tt:2203.494\n",
      "Ep:118, loss:0.00000, loss_test:0.11479, lr:5.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.660, tt:2220.505\n",
      "Ep:119, loss:0.00000, loss_test:0.11487, lr:5.58e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.658, tt:2238.934\n",
      "Ep:120, loss:0.00000, loss_test:0.11489, lr:5.53e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.653, tt:2257.009\n",
      "Ep:121, loss:0.00000, loss_test:0.11483, lr:5.47e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.669, tt:2277.564\n",
      "Ep:122, loss:0.00000, loss_test:0.11470, lr:5.42e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.671, tt:2296.501\n",
      "Ep:123, loss:0.00000, loss_test:0.11462, lr:5.36e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.680, tt:2316.264\n",
      "Ep:124, loss:0.00000, loss_test:0.11468, lr:5.31e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.688, tt:2336.006\n",
      "Ep:125, loss:0.00000, loss_test:0.11486, lr:5.26e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.688, tt:2354.706\n",
      "Ep:126, loss:0.00000, loss_test:0.11506, lr:5.20e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.691, tt:2373.698\n",
      "Ep:127, loss:0.00000, loss_test:0.11521, lr:5.15e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.687, tt:2391.925\n",
      "Ep:128, loss:0.00000, loss_test:0.11529, lr:5.10e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.684, tt:2410.256\n",
      "Ep:129, loss:0.00000, loss_test:0.11537, lr:5.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.681, tt:2428.499\n",
      "Ep:130, loss:0.00000, loss_test:0.11547, lr:5.00e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.682, tt:2447.326\n",
      "Ep:131, loss:0.00000, loss_test:0.11566, lr:4.95e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.671, tt:2464.581\n",
      "Ep:132, loss:0.00000, loss_test:0.11590, lr:4.90e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.666, tt:2482.557\n",
      "Ep:133, loss:0.00000, loss_test:0.11606, lr:4.85e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.656, tt:2499.876\n",
      "Ep:134, loss:0.00000, loss_test:0.11609, lr:4.80e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.653, tt:2518.179\n",
      "Ep:135, loss:0.00000, loss_test:0.11603, lr:4.75e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.648, tt:2536.187\n",
      "Ep:136, loss:0.00000, loss_test:0.11597, lr:4.71e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.646, tt:2554.566\n",
      "Ep:137, loss:0.00000, loss_test:0.11601, lr:4.66e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.649, tt:2573.537\n",
      "Ep:138, loss:0.00000, loss_test:0.11619, lr:4.61e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.644, tt:2591.547\n",
      "Ep:139, loss:0.00000, loss_test:0.11644, lr:4.57e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.639, tt:2609.429\n",
      "Ep:140, loss:0.00000, loss_test:0.11668, lr:4.52e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.636, tt:2627.677\n",
      "Ep:141, loss:0.00000, loss_test:0.11681, lr:4.48e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.629, tt:2645.373\n",
      "Ep:142, loss:0.00000, loss_test:0.11678, lr:4.43e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.630, tt:2664.084\n",
      "Ep:143, loss:0.00000, loss_test:0.11672, lr:4.39e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.625, tt:2682.068\n",
      "Ep:144, loss:0.00000, loss_test:0.11672, lr:4.34e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.620, tt:2699.882\n",
      "Ep:145, loss:0.00000, loss_test:0.11679, lr:4.30e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.611, tt:2717.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.11688, lr:4.26e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.614, tt:2736.222\n",
      "Ep:147, loss:0.00000, loss_test:0.11697, lr:4.21e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.618, tt:2755.394\n",
      "Ep:148, loss:0.00000, loss_test:0.11704, lr:4.17e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.620, tt:2774.363\n",
      "Ep:149, loss:0.00000, loss_test:0.11713, lr:4.13e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.618, tt:2792.766\n",
      "Ep:150, loss:0.00000, loss_test:0.11720, lr:4.09e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.621, tt:2811.734\n",
      "Ep:151, loss:0.00000, loss_test:0.11725, lr:4.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.622, tt:2830.566\n",
      "Ep:152, loss:0.00000, loss_test:0.11730, lr:4.01e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.621, tt:2849.037\n",
      "Ep:153, loss:0.00000, loss_test:0.11738, lr:3.97e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.629, tt:2868.801\n",
      "Ep:154, loss:0.00000, loss_test:0.11746, lr:3.93e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.624, tt:2886.645\n",
      "Ep:155, loss:0.00000, loss_test:0.11750, lr:3.89e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.630, tt:2906.232\n",
      "Ep:156, loss:0.00000, loss_test:0.11754, lr:3.85e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.626, tt:2924.357\n",
      "Ep:157, loss:0.00000, loss_test:0.11760, lr:3.81e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.625, tt:2942.719\n",
      "Ep:158, loss:0.00000, loss_test:0.11772, lr:3.77e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.623, tt:2961.098\n",
      "Ep:159, loss:0.00000, loss_test:0.11791, lr:3.73e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.627, tt:2980.333\n",
      "Ep:160, loss:0.00000, loss_test:0.11808, lr:3.70e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.626, tt:2998.788\n",
      "Ep:161, loss:0.00000, loss_test:0.11821, lr:3.66e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.620, tt:3016.475\n",
      "Ep:162, loss:0.00000, loss_test:0.11830, lr:3.62e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.619, tt:3034.951\n",
      "Ep:163, loss:0.00000, loss_test:0.11834, lr:3.59e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.619, tt:3053.460\n",
      "Ep:164, loss:0.00000, loss_test:0.11841, lr:3.55e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.625, tt:3073.153\n",
      "Ep:165, loss:0.00000, loss_test:0.11853, lr:3.52e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.631, tt:3092.785\n",
      "Ep:166, loss:0.00000, loss_test:0.11865, lr:3.48e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.636, tt:3112.160\n",
      "Ep:167, loss:0.00000, loss_test:0.11876, lr:3.45e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.638, tt:3131.204\n",
      "Ep:168, loss:0.00000, loss_test:0.11886, lr:3.41e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.643, tt:3150.599\n",
      "Ep:169, loss:0.00000, loss_test:0.11899, lr:3.38e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.646, tt:3169.790\n",
      "Ep:170, loss:0.00000, loss_test:0.11911, lr:3.34e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.649, tt:3189.037\n",
      "Ep:171, loss:0.00000, loss_test:0.11923, lr:3.31e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.642, tt:3206.356\n",
      "Ep:172, loss:0.00000, loss_test:0.11935, lr:3.28e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.635, tt:3223.784\n",
      "Ep:173, loss:0.00000, loss_test:0.11946, lr:3.24e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.626, tt:3240.895\n",
      "Ep:174, loss:0.00000, loss_test:0.11956, lr:3.21e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.620, tt:3258.529\n",
      "Ep:175, loss:0.00000, loss_test:0.11965, lr:3.18e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.607, tt:3274.749\n",
      "Ep:176, loss:0.00000, loss_test:0.11973, lr:3.15e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.595, tt:3291.381\n",
      "Ep:177, loss:0.00000, loss_test:0.11980, lr:3.12e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.596, tt:3310.070\n",
      "Ep:178, loss:0.00000, loss_test:0.11988, lr:3.09e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.585, tt:3326.701\n",
      "Ep:179, loss:0.00000, loss_test:0.11997, lr:3.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.577, tt:3343.928\n",
      "Ep:180, loss:0.00000, loss_test:0.12008, lr:3.02e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.566, tt:3360.415\n",
      "Ep:181, loss:0.00000, loss_test:0.12019, lr:2.99e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.558, tt:3377.558\n",
      "Ep:182, loss:0.00000, loss_test:0.12031, lr:2.96e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.549, tt:3394.477\n",
      "Ep:183, loss:0.00000, loss_test:0.12041, lr:2.93e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.537, tt:3410.796\n",
      "Ep:184, loss:0.00000, loss_test:0.12049, lr:2.90e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.525, tt:3427.201\n",
      "Ep:185, loss:0.00000, loss_test:0.12057, lr:2.88e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.515, tt:3443.833\n",
      "Ep:186, loss:0.00000, loss_test:0.12065, lr:2.85e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.505, tt:3460.359\n",
      "Ep:187, loss:0.00000, loss_test:0.12076, lr:2.82e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.495, tt:3477.037\n",
      "Ep:188, loss:0.00000, loss_test:0.12086, lr:2.79e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.482, tt:3493.129\n",
      "Ep:189, loss:0.00000, loss_test:0.12095, lr:2.76e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.472, tt:3509.612\n",
      "Ep:190, loss:0.00000, loss_test:0.12103, lr:2.73e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.459, tt:3525.623\n",
      "Ep:191, loss:0.00000, loss_test:0.12112, lr:2.71e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.445, tt:3541.514\n",
      "Ep:192, loss:0.00000, loss_test:0.12122, lr:2.68e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.433, tt:3557.533\n",
      "Ep:193, loss:0.00000, loss_test:0.12130, lr:2.65e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.417, tt:3572.916\n",
      "Ep:194, loss:0.00000, loss_test:0.12136, lr:2.63e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.406, tt:3589.094\n",
      "Ep:195, loss:0.00000, loss_test:0.12140, lr:2.60e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.397, tt:3605.841\n",
      "Ep:196, loss:0.00000, loss_test:0.12143, lr:2.57e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.385, tt:3621.756\n",
      "Ep:197, loss:0.00000, loss_test:0.12145, lr:2.55e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.373, tt:3637.804\n",
      "Ep:198, loss:0.00000, loss_test:0.12147, lr:2.52e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.364, tt:3654.368\n",
      "Ep:199, loss:0.00000, loss_test:0.12149, lr:2.50e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.353, tt:3670.641\n",
      "Ep:200, loss:0.00000, loss_test:0.12150, lr:2.47e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.346, tt:3687.609\n",
      "Ep:201, loss:0.00000, loss_test:0.12153, lr:2.45e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.339, tt:3704.476\n",
      "Ep:202, loss:0.00000, loss_test:0.12159, lr:2.42e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.333, tt:3721.615\n",
      "Ep:203, loss:0.00000, loss_test:0.12167, lr:2.40e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.327, tt:3738.747\n",
      "Ep:204, loss:0.00000, loss_test:0.12176, lr:2.38e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.321, tt:3755.807\n",
      "Ep:205, loss:0.00000, loss_test:0.12185, lr:2.35e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.315, tt:3772.955\n",
      "Ep:206, loss:0.00000, loss_test:0.12192, lr:2.33e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.309, tt:3790.047\n",
      "Ep:207, loss:0.00000, loss_test:0.12200, lr:2.31e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.307, tt:3807.822\n",
      "Ep:208, loss:0.00000, loss_test:0.12210, lr:2.28e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.305, tt:3825.828\n",
      "Ep:209, loss:0.00000, loss_test:0.12220, lr:2.26e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.301, tt:3843.283\n",
      "Ep:210, loss:0.00000, loss_test:0.12228, lr:2.24e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.293, tt:3859.790\n",
      "Ep:211, loss:0.00000, loss_test:0.12236, lr:2.21e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.289, tt:3877.189\n",
      "Ep:212, loss:0.00000, loss_test:0.12243, lr:2.19e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.285, tt:3894.812\n",
      "Ep:213, loss:0.00000, loss_test:0.12251, lr:2.17e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.278, tt:3911.543\n",
      "Ep:214, loss:0.00000, loss_test:0.12261, lr:2.15e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.274, tt:3929.014\n",
      "Ep:215, loss:0.00000, loss_test:0.12270, lr:2.13e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.272, tt:3946.857\n",
      "Ep:216, loss:0.00000, loss_test:0.12277, lr:2.11e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.271, tt:3964.796\n",
      "Ep:217, loss:0.00000, loss_test:0.12282, lr:2.08e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.268, tt:3982.321\n",
      "Ep:218, loss:0.00000, loss_test:0.12285, lr:2.06e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.268, tt:4000.728\n",
      "Ep:219, loss:0.00000, loss_test:0.12287, lr:2.04e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.268, tt:4018.876\n",
      "Ep:220, loss:0.00000, loss_test:0.12289, lr:2.02e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.264, tt:4036.431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:221, loss:0.00000, loss_test:0.12294, lr:2.00e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.263, tt:4054.290\n",
      "Ep:222, loss:0.00000, loss_test:0.12300, lr:1.98e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.260, tt:4071.889\n",
      "Ep:223, loss:0.00000, loss_test:0.12306, lr:1.96e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.254, tt:4088.820\n",
      "Ep:224, loss:0.00000, loss_test:0.12311, lr:1.94e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.244, tt:4104.937\n",
      "Ep:225, loss:0.00000, loss_test:0.12314, lr:1.92e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.237, tt:4121.597\n",
      "Ep:226, loss:0.00000, loss_test:0.12318, lr:1.90e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.226, tt:4137.274\n",
      "Ep:227, loss:0.00000, loss_test:0.12323, lr:1.89e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.219, tt:4153.973\n",
      "Ep:228, loss:0.00000, loss_test:0.12328, lr:1.87e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.211, tt:4170.404\n",
      "Ep:229, loss:0.00000, loss_test:0.12332, lr:1.85e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.209, tt:4188.103\n",
      "Ep:230, loss:0.00000, loss_test:0.12335, lr:1.83e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.201, tt:4204.538\n",
      "Ep:231, loss:0.00000, loss_test:0.12338, lr:1.81e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.196, tt:4221.489\n",
      "Ep:232, loss:0.00000, loss_test:0.12343, lr:1.79e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.192, tt:4238.811\n",
      "Ep:233, loss:0.00000, loss_test:0.12349, lr:1.78e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.193, tt:4257.130\n",
      "Ep:234, loss:0.00000, loss_test:0.12355, lr:1.76e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.186, tt:4273.727\n",
      "Ep:235, loss:0.00000, loss_test:0.12362, lr:1.74e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.182, tt:4290.843\n",
      "Ep:236, loss:0.00000, loss_test:0.12369, lr:1.72e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.183, tt:4309.294\n",
      "Ep:237, loss:0.00000, loss_test:0.12374, lr:1.71e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.182, tt:4327.381\n",
      "Ep:238, loss:0.00000, loss_test:0.12379, lr:1.69e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.180, tt:4345.011\n",
      "Ep:239, loss:0.00000, loss_test:0.12383, lr:1.67e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.183, tt:4363.926\n",
      "Ep:240, loss:0.00000, loss_test:0.12386, lr:1.65e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.186, tt:4382.759\n",
      "Ep:241, loss:0.00000, loss_test:0.12391, lr:1.64e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.189, tt:4401.622\n",
      "Ep:242, loss:0.00000, loss_test:0.12396, lr:1.62e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.189, tt:4419.869\n",
      "Ep:243, loss:0.00000, loss_test:0.12403, lr:1.61e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.187, tt:4437.606\n",
      "Ep:244, loss:0.00000, loss_test:0.12408, lr:1.59e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.186, tt:4455.553\n",
      "Ep:245, loss:0.00000, loss_test:0.12413, lr:1.57e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.186, tt:4473.728\n",
      "Ep:246, loss:0.00000, loss_test:0.12417, lr:1.56e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.184, tt:4491.535\n",
      "Ep:247, loss:0.00000, loss_test:0.12422, lr:1.54e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.184, tt:4509.663\n",
      "Ep:248, loss:0.00000, loss_test:0.12426, lr:1.53e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.185, tt:4528.170\n",
      "Ep:249, loss:0.00000, loss_test:0.12430, lr:1.51e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.186, tt:4546.400\n",
      "Ep:250, loss:0.00000, loss_test:0.12434, lr:1.50e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.188, tt:4565.096\n",
      "Ep:251, loss:0.00000, loss_test:0.12438, lr:1.48e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.186, tt:4582.873\n",
      "Ep:252, loss:0.00000, loss_test:0.12443, lr:1.47e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.189, tt:4601.709\n",
      "Ep:253, loss:0.00000, loss_test:0.12449, lr:1.45e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.199, tt:4622.549\n",
      "Ep:254, loss:0.00000, loss_test:0.12454, lr:1.44e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.205, tt:4642.300\n",
      "Ep:255, loss:0.00000, loss_test:0.12459, lr:1.42e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.209, tt:4661.520\n",
      "Ep:256, loss:0.00000, loss_test:0.12465, lr:1.41e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.215, tt:4681.203\n",
      "Ep:257, loss:0.00000, loss_test:0.12471, lr:1.39e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.222, tt:4701.259\n",
      "Ep:258, loss:0.00000, loss_test:0.12477, lr:1.38e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.225, tt:4720.246\n",
      "Ep:259, loss:0.00000, loss_test:0.12485, lr:1.37e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.230, tt:4739.886\n",
      "Ep:260, loss:0.00000, loss_test:0.12491, lr:1.35e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.234, tt:4759.145\n",
      "Ep:261, loss:0.00000, loss_test:0.12497, lr:1.34e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.237, tt:4778.188\n",
      "Ep:262, loss:0.00000, loss_test:0.12503, lr:1.33e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.243, tt:4797.903\n",
      "Ep:263, loss:0.00000, loss_test:0.12508, lr:1.31e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.247, tt:4817.149\n",
      "Ep:264, loss:0.00000, loss_test:0.12512, lr:1.30e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.249, tt:4835.998\n",
      "Ep:265, loss:0.00000, loss_test:0.12515, lr:1.29e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.250, tt:4854.589\n",
      "Ep:266, loss:0.00000, loss_test:0.12517, lr:1.27e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.254, tt:4873.872\n",
      "Ep:267, loss:0.00000, loss_test:0.12519, lr:1.26e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.255, tt:4892.395\n",
      "Ep:268, loss:0.00000, loss_test:0.12521, lr:1.25e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.256, tt:4910.947\n",
      "Ep:269, loss:0.00000, loss_test:0.12523, lr:1.24e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.259, tt:4929.832\n",
      "Ep:270, loss:0.00000, loss_test:0.12524, lr:1.22e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.264, tt:4949.499\n",
      "Ep:271, loss:0.00000, loss_test:0.12525, lr:1.21e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.269, tt:4969.046\n",
      "Ep:272, loss:0.00000, loss_test:0.12526, lr:1.20e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.275, tt:4989.161\n",
      "Ep:273, loss:0.00000, loss_test:0.12527, lr:1.19e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.281, tt:5008.869\n",
      "Ep:274, loss:0.00000, loss_test:0.12528, lr:1.18e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.279, tt:5026.752\n",
      "Ep:275, loss:0.00000, loss_test:0.12530, lr:1.16e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.279, tt:5044.919\n",
      "Ep:276, loss:0.00000, loss_test:0.12531, lr:1.15e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.280, tt:5063.650\n",
      "Ep:277, loss:0.00000, loss_test:0.12533, lr:1.14e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.277, tt:5080.917\n",
      "Ep:278, loss:0.00000, loss_test:0.12535, lr:1.13e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.265, tt:5095.852\n",
      "Ep:279, loss:0.00000, loss_test:0.12536, lr:1.12e-03, fs:0.69565 (r=0.566,p=0.903),  time:18.250, tt:5109.919\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"7-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=40000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,280,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 18\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 512: \n",
      "Ep:0, loss:0.00112, loss_test:0.14692, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:22.330, tt:22.330\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00112, loss_test:0.14645, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:22.303, tt:44.607\n",
      "Ep:2, loss:0.00110, loss_test:0.14566, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:22.394, tt:67.181\n",
      "Ep:3, loss:0.00108, loss_test:0.14451, lr:4.00e-03, fs:0.67347 (r=1.000,p=0.508),  time:22.320, tt:89.279\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00105, loss_test:0.14287, lr:4.00e-03, fs:0.66197 (r=0.949,p=0.508),  time:22.367, tt:111.833\n",
      "Ep:5, loss:0.00099, loss_test:0.14196, lr:4.00e-03, fs:0.61157 (r=0.747,p=0.517),  time:22.448, tt:134.689\n",
      "Ep:6, loss:0.00094, loss_test:0.14291, lr:4.00e-03, fs:0.53202 (r=0.545,p=0.519),  time:22.426, tt:156.982\n",
      "Ep:7, loss:0.00090, loss_test:0.14715, lr:4.00e-03, fs:0.50279 (r=0.455,p=0.562),  time:22.365, tt:178.917\n",
      "Ep:8, loss:0.00087, loss_test:0.14778, lr:4.00e-03, fs:0.47399 (r=0.414,p=0.554),  time:22.409, tt:201.685\n",
      "Ep:9, loss:0.00084, loss_test:0.14619, lr:4.00e-03, fs:0.44706 (r=0.384,p=0.535),  time:22.408, tt:224.078\n",
      "Ep:10, loss:0.00082, loss_test:0.14517, lr:4.00e-03, fs:0.46154 (r=0.394,p=0.557),  time:22.432, tt:246.753\n",
      "Ep:11, loss:0.00079, loss_test:0.14499, lr:4.00e-03, fs:0.50000 (r=0.424,p=0.609),  time:22.467, tt:269.608\n",
      "Ep:12, loss:0.00077, loss_test:0.14610, lr:4.00e-03, fs:0.48780 (r=0.404,p=0.615),  time:22.517, tt:292.715\n",
      "Ep:13, loss:0.00074, loss_test:0.14559, lr:4.00e-03, fs:0.49697 (r=0.414,p=0.621),  time:22.547, tt:315.657\n",
      "Ep:14, loss:0.00072, loss_test:0.14422, lr:4.00e-03, fs:0.50299 (r=0.424,p=0.618),  time:22.535, tt:338.019\n",
      "Ep:15, loss:0.00070, loss_test:0.14494, lr:3.96e-03, fs:0.50909 (r=0.424,p=0.636),  time:22.521, tt:360.342\n",
      "Ep:16, loss:0.00068, loss_test:0.14458, lr:3.92e-03, fs:0.52121 (r=0.434,p=0.652),  time:22.536, tt:383.117\n",
      "Ep:17, loss:0.00067, loss_test:0.14434, lr:3.88e-03, fs:0.51807 (r=0.434,p=0.642),  time:22.572, tt:406.289\n",
      "Ep:18, loss:0.00065, loss_test:0.14424, lr:3.84e-03, fs:0.52121 (r=0.434,p=0.652),  time:22.572, tt:428.865\n",
      "Ep:19, loss:0.00064, loss_test:0.14332, lr:3.80e-03, fs:0.54217 (r=0.455,p=0.672),  time:22.560, tt:451.191\n",
      "Ep:20, loss:0.00062, loss_test:0.14452, lr:3.77e-03, fs:0.51852 (r=0.424,p=0.667),  time:22.549, tt:473.529\n",
      "Ep:21, loss:0.00061, loss_test:0.14553, lr:3.73e-03, fs:0.52174 (r=0.424,p=0.677),  time:22.550, tt:496.110\n",
      "Ep:22, loss:0.00060, loss_test:0.14349, lr:3.69e-03, fs:0.54217 (r=0.455,p=0.672),  time:22.531, tt:518.204\n",
      "Ep:23, loss:0.00059, loss_test:0.14550, lr:3.65e-03, fs:0.51852 (r=0.424,p=0.667),  time:22.508, tt:540.199\n",
      "Ep:24, loss:0.00058, loss_test:0.14544, lr:3.62e-03, fs:0.53086 (r=0.434,p=0.683),  time:22.508, tt:562.693\n",
      "Ep:25, loss:0.00057, loss_test:0.14506, lr:3.58e-03, fs:0.53659 (r=0.444,p=0.677),  time:22.515, tt:585.380\n",
      "Ep:26, loss:0.00056, loss_test:0.14555, lr:3.55e-03, fs:0.53086 (r=0.434,p=0.683),  time:22.515, tt:607.896\n",
      "Ep:27, loss:0.00055, loss_test:0.14648, lr:3.51e-03, fs:0.52174 (r=0.424,p=0.677),  time:22.517, tt:630.476\n",
      "Ep:28, loss:0.00054, loss_test:0.14487, lr:3.47e-03, fs:0.51852 (r=0.424,p=0.667),  time:22.513, tt:652.888\n",
      "Ep:29, loss:0.00053, loss_test:0.14518, lr:3.44e-03, fs:0.52174 (r=0.424,p=0.677),  time:22.508, tt:675.238\n",
      "Ep:30, loss:0.00052, loss_test:0.14591, lr:3.41e-03, fs:0.53165 (r=0.424,p=0.712),  time:22.533, tt:698.518\n",
      "Ep:31, loss:0.00052, loss_test:0.14550, lr:3.37e-03, fs:0.53165 (r=0.424,p=0.712),  time:22.556, tt:721.789\n",
      "Ep:32, loss:0.00051, loss_test:0.14465, lr:3.34e-03, fs:0.53165 (r=0.424,p=0.712),  time:22.551, tt:744.196\n",
      "Ep:33, loss:0.00050, loss_test:0.14573, lr:3.30e-03, fs:0.53846 (r=0.424,p=0.737),  time:22.546, tt:766.576\n",
      "Ep:34, loss:0.00049, loss_test:0.14557, lr:3.27e-03, fs:0.53595 (r=0.414,p=0.759),  time:22.551, tt:789.276\n",
      "Ep:35, loss:0.00049, loss_test:0.14447, lr:3.24e-03, fs:0.54194 (r=0.424,p=0.750),  time:22.552, tt:811.875\n",
      "Ep:36, loss:0.00048, loss_test:0.14475, lr:3.21e-03, fs:0.54545 (r=0.424,p=0.764),  time:22.556, tt:834.558\n",
      "Ep:37, loss:0.00048, loss_test:0.14362, lr:3.17e-03, fs:0.54545 (r=0.424,p=0.764),  time:22.558, tt:857.189\n",
      "Ep:38, loss:0.00047, loss_test:0.14537, lr:3.14e-03, fs:0.53333 (r=0.404,p=0.784),  time:22.559, tt:879.809\n",
      "Ep:39, loss:0.00046, loss_test:0.14482, lr:3.11e-03, fs:0.54902 (r=0.424,p=0.778),  time:22.568, tt:902.716\n",
      "Ep:40, loss:0.00046, loss_test:0.14373, lr:3.08e-03, fs:0.55629 (r=0.424,p=0.808),  time:22.570, tt:925.390\n",
      "Ep:41, loss:0.00045, loss_test:0.14512, lr:3.05e-03, fs:0.54667 (r=0.414,p=0.804),  time:22.585, tt:948.559\n",
      "Ep:42, loss:0.00044, loss_test:0.14410, lr:3.02e-03, fs:0.54667 (r=0.414,p=0.804),  time:22.596, tt:971.638\n",
      "Ep:43, loss:0.00044, loss_test:0.14348, lr:2.99e-03, fs:0.55629 (r=0.424,p=0.808),  time:22.594, tt:994.154\n",
      "Ep:44, loss:0.00043, loss_test:0.14361, lr:2.96e-03, fs:0.53691 (r=0.404,p=0.800),  time:22.588, tt:1016.448\n",
      "Ep:45, loss:0.00043, loss_test:0.14276, lr:2.93e-03, fs:0.55629 (r=0.424,p=0.808),  time:22.597, tt:1039.480\n",
      "Ep:46, loss:0.00042, loss_test:0.14368, lr:2.90e-03, fs:0.54054 (r=0.404,p=0.816),  time:22.603, tt:1062.359\n",
      "Ep:47, loss:0.00042, loss_test:0.14302, lr:2.87e-03, fs:0.54667 (r=0.414,p=0.804),  time:22.594, tt:1084.501\n",
      "Ep:48, loss:0.00041, loss_test:0.14271, lr:2.84e-03, fs:0.54054 (r=0.404,p=0.816),  time:22.594, tt:1107.103\n",
      "Ep:49, loss:0.00041, loss_test:0.14204, lr:2.81e-03, fs:0.55405 (r=0.414,p=0.837),  time:22.608, tt:1130.423\n",
      "Ep:50, loss:0.00040, loss_test:0.14280, lr:2.79e-03, fs:0.54054 (r=0.404,p=0.816),  time:22.603, tt:1152.747\n",
      "Ep:51, loss:0.00040, loss_test:0.14226, lr:2.76e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.608, tt:1175.614\n",
      "Ep:52, loss:0.00039, loss_test:0.14182, lr:2.73e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.621, tt:1198.920\n",
      "Ep:53, loss:0.00039, loss_test:0.14351, lr:2.70e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.624, tt:1221.698\n",
      "Ep:54, loss:0.00038, loss_test:0.14307, lr:2.68e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.651, tt:1245.822\n",
      "Ep:55, loss:0.00038, loss_test:0.14206, lr:2.65e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.656, tt:1268.729\n",
      "Ep:56, loss:0.00037, loss_test:0.14264, lr:2.62e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.677, tt:1292.602\n",
      "Ep:57, loss:0.00037, loss_test:0.14345, lr:2.60e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.685, tt:1315.708\n",
      "Ep:58, loss:0.00037, loss_test:0.14254, lr:2.57e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.680, tt:1338.132\n",
      "Ep:59, loss:0.00036, loss_test:0.14194, lr:2.54e-03, fs:0.54422 (r=0.404,p=0.833),  time:22.680, tt:1360.778\n",
      "Ep:60, loss:0.00036, loss_test:0.14296, lr:2.52e-03, fs:0.52414 (r=0.384,p=0.826),  time:22.681, tt:1383.538\n",
      "Ep:61, loss:0.00035, loss_test:0.14186, lr:2.49e-03, fs:0.53425 (r=0.394,p=0.830),  time:22.682, tt:1406.271\n",
      "Ep:62, loss:0.00035, loss_test:0.14251, lr:2.47e-03, fs:0.52414 (r=0.384,p=0.826),  time:22.688, tt:1429.349\n",
      "Ep:63, loss:0.00034, loss_test:0.14242, lr:2.44e-03, fs:0.52414 (r=0.384,p=0.826),  time:22.710, tt:1453.411\n",
      "Ep:64, loss:0.00034, loss_test:0.14248, lr:2.42e-03, fs:0.52414 (r=0.384,p=0.826),  time:22.709, tt:1476.086\n",
      "Ep:65, loss:0.00033, loss_test:0.14245, lr:2.40e-03, fs:0.52414 (r=0.384,p=0.826),  time:22.712, tt:1498.993\n",
      "Ep:66, loss:0.00033, loss_test:0.14287, lr:2.37e-03, fs:0.51389 (r=0.374,p=0.822),  time:22.710, tt:1521.545\n",
      "Ep:67, loss:0.00033, loss_test:0.14227, lr:2.35e-03, fs:0.52055 (r=0.384,p=0.809),  time:22.710, tt:1544.255\n",
      "Ep:68, loss:0.00032, loss_test:0.14124, lr:2.32e-03, fs:0.51389 (r=0.374,p=0.822),  time:22.714, tt:1567.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00032, loss_test:0.14353, lr:2.30e-03, fs:0.51748 (r=0.374,p=0.841),  time:22.709, tt:1589.618\n",
      "Ep:70, loss:0.00032, loss_test:0.14062, lr:2.28e-03, fs:0.51034 (r=0.374,p=0.804),  time:22.712, tt:1612.575\n",
      "Ep:71, loss:0.00031, loss_test:0.14223, lr:2.26e-03, fs:0.51429 (r=0.364,p=0.878),  time:22.720, tt:1635.855\n",
      "Ep:72, loss:0.00031, loss_test:0.14226, lr:2.23e-03, fs:0.51034 (r=0.374,p=0.804),  time:22.726, tt:1659.010\n",
      "Ep:73, loss:0.00030, loss_test:0.14108, lr:2.21e-03, fs:0.50704 (r=0.364,p=0.837),  time:22.748, tt:1683.333\n",
      "Ep:74, loss:0.00030, loss_test:0.14278, lr:2.19e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.748, tt:1706.129\n",
      "Ep:75, loss:0.00030, loss_test:0.14067, lr:2.17e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.753, tt:1729.244\n",
      "Ep:76, loss:0.00029, loss_test:0.14139, lr:2.15e-03, fs:0.52113 (r=0.374,p=0.860),  time:22.751, tt:1751.860\n",
      "Ep:77, loss:0.00029, loss_test:0.14274, lr:2.12e-03, fs:0.50000 (r=0.354,p=0.854),  time:22.756, tt:1775.003\n",
      "Ep:78, loss:0.00029, loss_test:0.14143, lr:2.10e-03, fs:0.50704 (r=0.364,p=0.837),  time:22.759, tt:1797.987\n",
      "Ep:79, loss:0.00028, loss_test:0.14173, lr:2.08e-03, fs:0.50000 (r=0.354,p=0.854),  time:22.767, tt:1821.370\n",
      "Ep:80, loss:0.00028, loss_test:0.14193, lr:2.06e-03, fs:0.50000 (r=0.354,p=0.854),  time:22.771, tt:1844.425\n",
      "Ep:81, loss:0.00028, loss_test:0.14133, lr:2.04e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.772, tt:1867.290\n",
      "Ep:82, loss:0.00028, loss_test:0.14166, lr:2.02e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.769, tt:1889.844\n",
      "Ep:83, loss:0.00027, loss_test:0.14155, lr:2.00e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.771, tt:1912.781\n",
      "Ep:84, loss:0.00027, loss_test:0.14248, lr:1.98e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.770, tt:1935.435\n",
      "Ep:85, loss:0.00027, loss_test:0.14174, lr:1.96e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.773, tt:1958.478\n",
      "Ep:86, loss:0.00026, loss_test:0.14219, lr:1.94e-03, fs:0.51429 (r=0.364,p=0.878),  time:22.766, tt:1980.678\n",
      "Ep:87, loss:0.00026, loss_test:0.14236, lr:1.92e-03, fs:0.48921 (r=0.343,p=0.850),  time:22.767, tt:2003.529\n",
      "Ep:88, loss:0.00026, loss_test:0.14015, lr:1.90e-03, fs:0.51064 (r=0.364,p=0.857),  time:22.774, tt:2026.889\n",
      "Ep:89, loss:0.00026, loss_test:0.14167, lr:1.88e-03, fs:0.48921 (r=0.343,p=0.850),  time:22.775, tt:2049.709\n",
      "Ep:90, loss:0.00025, loss_test:0.14140, lr:1.86e-03, fs:0.50360 (r=0.354,p=0.875),  time:22.775, tt:2072.521\n",
      "Ep:91, loss:0.00025, loss_test:0.14070, lr:1.84e-03, fs:0.50000 (r=0.354,p=0.854),  time:22.775, tt:2095.320\n",
      "Ep:92, loss:0.00025, loss_test:0.14123, lr:1.83e-03, fs:0.48921 (r=0.343,p=0.850),  time:22.783, tt:2118.847\n",
      "Ep:93, loss:0.00025, loss_test:0.14086, lr:1.81e-03, fs:0.50000 (r=0.354,p=0.854),  time:22.788, tt:2142.042\n",
      "Ep:94, loss:0.00024, loss_test:0.14084, lr:1.79e-03, fs:0.48921 (r=0.343,p=0.850),  time:22.790, tt:2165.052\n",
      "Ep:95, loss:0.00024, loss_test:0.14093, lr:1.77e-03, fs:0.48921 (r=0.343,p=0.850),  time:22.786, tt:2187.409\n",
      "Ep:96, loss:0.00024, loss_test:0.14111, lr:1.75e-03, fs:0.48921 (r=0.343,p=0.850),  time:22.788, tt:2210.456\n",
      "Ep:97, loss:0.00024, loss_test:0.14086, lr:1.74e-03, fs:0.49275 (r=0.343,p=0.872),  time:22.763, tt:2230.801\n",
      "Ep:98, loss:0.00023, loss_test:0.14108, lr:1.72e-03, fs:0.49275 (r=0.343,p=0.872),  time:22.718, tt:2249.041\n",
      "Ep:99, loss:0.00023, loss_test:0.14105, lr:1.70e-03, fs:0.49275 (r=0.343,p=0.872),  time:22.640, tt:2263.997\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"19-19\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=512 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 18\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14838, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:10.888, tt:10.888\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14812, lr:8.00e-03, fs:0.66216 (r=0.990,p=0.497),  time:10.891, tt:21.781\n",
      "Ep:2, loss:0.00027, loss_test:0.14779, lr:8.00e-03, fs:0.66212 (r=0.980,p=0.500),  time:10.684, tt:32.053\n",
      "Ep:3, loss:0.00026, loss_test:0.14753, lr:8.00e-03, fs:0.65035 (r=0.939,p=0.497),  time:10.882, tt:43.529\n",
      "Ep:4, loss:0.00025, loss_test:0.14727, lr:8.00e-03, fs:0.61940 (r=0.838,p=0.491),  time:10.968, tt:54.842\n",
      "Ep:5, loss:0.00024, loss_test:0.14761, lr:8.00e-03, fs:0.60331 (r=0.737,p=0.510),  time:10.961, tt:65.765\n",
      "Ep:6, loss:0.00024, loss_test:0.14935, lr:8.00e-03, fs:0.55660 (r=0.596,p=0.522),  time:10.981, tt:76.870\n",
      "Ep:7, loss:0.00023, loss_test:0.15382, lr:8.00e-03, fs:0.46875 (r=0.455,p=0.484),  time:10.957, tt:87.654\n",
      "Ep:8, loss:0.00022, loss_test:0.15499, lr:8.00e-03, fs:0.44681 (r=0.424,p=0.472),  time:11.009, tt:99.086\n",
      "Ep:9, loss:0.00022, loss_test:0.15327, lr:8.00e-03, fs:0.43158 (r=0.414,p=0.451),  time:11.014, tt:110.140\n",
      "Ep:10, loss:0.00021, loss_test:0.15075, lr:8.00e-03, fs:0.48731 (r=0.485,p=0.490),  time:11.080, tt:121.881\n",
      "Ep:11, loss:0.00021, loss_test:0.15025, lr:8.00e-03, fs:0.47423 (r=0.465,p=0.484),  time:11.172, tt:134.060\n",
      "Ep:12, loss:0.00020, loss_test:0.15147, lr:7.92e-03, fs:0.47872 (r=0.455,p=0.506),  time:11.294, tt:146.827\n",
      "Ep:13, loss:0.00019, loss_test:0.15288, lr:7.84e-03, fs:0.49724 (r=0.455,p=0.549),  time:11.536, tt:161.505\n",
      "Ep:14, loss:0.00019, loss_test:0.15197, lr:7.76e-03, fs:0.50000 (r=0.455,p=0.556),  time:12.183, tt:182.740\n",
      "Ep:15, loss:0.00018, loss_test:0.14961, lr:7.68e-03, fs:0.50000 (r=0.455,p=0.556),  time:12.807, tt:204.919\n",
      "Ep:16, loss:0.00018, loss_test:0.14824, lr:7.61e-03, fs:0.51111 (r=0.465,p=0.568),  time:13.353, tt:226.994\n",
      "Ep:17, loss:0.00017, loss_test:0.14723, lr:7.53e-03, fs:0.53333 (r=0.485,p=0.593),  time:13.848, tt:249.265\n",
      "Ep:18, loss:0.00017, loss_test:0.14721, lr:7.46e-03, fs:0.53714 (r=0.475,p=0.618),  time:14.256, tt:270.865\n",
      "Ep:19, loss:0.00017, loss_test:0.14688, lr:7.38e-03, fs:0.54237 (r=0.485,p=0.615),  time:14.733, tt:294.663\n",
      "Ep:20, loss:0.00016, loss_test:0.14560, lr:7.31e-03, fs:0.56667 (r=0.515,p=0.630),  time:15.233, tt:319.898\n",
      "Ep:21, loss:0.00016, loss_test:0.14465, lr:7.24e-03, fs:0.57143 (r=0.525,p=0.627),  time:15.673, tt:344.796\n",
      "Ep:22, loss:0.00016, loss_test:0.14536, lr:7.16e-03, fs:0.58101 (r=0.525,p=0.650),  time:16.218, tt:373.019\n",
      "Ep:23, loss:0.00015, loss_test:0.14660, lr:7.09e-03, fs:0.56322 (r=0.495,p=0.653),  time:16.792, tt:403.006\n",
      "Ep:24, loss:0.00015, loss_test:0.14644, lr:7.02e-03, fs:0.55491 (r=0.485,p=0.649),  time:17.296, tt:432.389\n",
      "Ep:25, loss:0.00015, loss_test:0.14623, lr:6.95e-03, fs:0.55866 (r=0.505,p=0.625),  time:17.772, tt:462.060\n",
      "Ep:26, loss:0.00015, loss_test:0.14587, lr:6.88e-03, fs:0.57459 (r=0.525,p=0.634),  time:18.095, tt:488.560\n",
      "Ep:27, loss:0.00014, loss_test:0.14613, lr:6.81e-03, fs:0.58101 (r=0.525,p=0.650),  time:18.464, tt:516.996\n",
      "Ep:28, loss:0.00014, loss_test:0.14638, lr:6.74e-03, fs:0.57143 (r=0.505,p=0.658),  time:18.847, tt:546.551\n",
      "Ep:29, loss:0.00014, loss_test:0.14602, lr:6.68e-03, fs:0.59091 (r=0.525,p=0.675),  time:19.154, tt:574.622\n",
      "Ep:30, loss:0.00014, loss_test:0.14656, lr:6.61e-03, fs:0.57471 (r=0.505,p=0.667),  time:19.464, tt:603.377\n",
      "Ep:31, loss:0.00013, loss_test:0.14649, lr:6.54e-03, fs:0.56647 (r=0.495,p=0.662),  time:19.782, tt:633.025\n",
      "Ep:32, loss:0.00013, loss_test:0.14583, lr:6.48e-03, fs:0.60920 (r=0.535,p=0.707),  time:20.028, tt:660.926\n",
      "Ep:33, loss:0.00013, loss_test:0.14645, lr:6.41e-03, fs:0.59649 (r=0.515,p=0.708),  time:20.275, tt:689.341\n",
      "Ep:34, loss:0.00013, loss_test:0.14692, lr:6.35e-03, fs:0.57988 (r=0.495,p=0.700),  time:20.563, tt:719.713\n",
      "Ep:35, loss:0.00013, loss_test:0.14698, lr:6.29e-03, fs:0.57143 (r=0.485,p=0.696),  time:20.818, tt:749.452\n",
      "Ep:36, loss:0.00012, loss_test:0.14673, lr:6.22e-03, fs:0.59172 (r=0.505,p=0.714),  time:21.050, tt:778.835\n",
      "Ep:37, loss:0.00012, loss_test:0.14641, lr:6.16e-03, fs:0.61628 (r=0.535,p=0.726),  time:21.240, tt:807.123\n",
      "Ep:38, loss:0.00012, loss_test:0.14642, lr:6.10e-03, fs:0.60465 (r=0.525,p=0.712),  time:21.384, tt:833.974\n",
      "Ep:39, loss:0.00012, loss_test:0.14641, lr:6.04e-03, fs:0.59172 (r=0.505,p=0.714),  time:21.556, tt:862.224\n",
      "Ep:40, loss:0.00012, loss_test:0.14549, lr:5.98e-03, fs:0.60819 (r=0.525,p=0.722),  time:21.751, tt:891.791\n",
      "Ep:41, loss:0.00012, loss_test:0.14548, lr:5.92e-03, fs:0.61988 (r=0.535,p=0.736),  time:21.897, tt:919.687\n",
      "Ep:42, loss:0.00011, loss_test:0.14663, lr:5.86e-03, fs:0.58333 (r=0.495,p=0.710),  time:22.032, tt:947.385\n",
      "Ep:43, loss:0.00011, loss_test:0.14626, lr:5.80e-03, fs:0.58683 (r=0.495,p=0.721),  time:22.147, tt:974.488\n",
      "Ep:44, loss:0.00011, loss_test:0.14518, lr:5.74e-03, fs:0.62353 (r=0.535,p=0.746),  time:22.299, tt:1003.465\n",
      "Ep:45, loss:0.00011, loss_test:0.14556, lr:5.68e-03, fs:0.61905 (r=0.525,p=0.754),  time:22.425, tt:1031.548\n",
      "Ep:46, loss:0.00011, loss_test:0.14591, lr:5.63e-03, fs:0.59756 (r=0.495,p=0.754),  time:22.529, tt:1058.875\n",
      "Ep:47, loss:0.00011, loss_test:0.14550, lr:5.57e-03, fs:0.61446 (r=0.515,p=0.761),  time:22.652, tt:1087.287\n",
      "Ep:48, loss:0.00011, loss_test:0.14498, lr:5.52e-03, fs:0.62275 (r=0.525,p=0.765),  time:22.799, tt:1117.127\n",
      "Ep:49, loss:0.00010, loss_test:0.14642, lr:5.46e-03, fs:0.57143 (r=0.465,p=0.742),  time:22.904, tt:1145.197\n",
      "Ep:50, loss:0.00010, loss_test:0.14642, lr:5.41e-03, fs:0.60123 (r=0.495,p=0.766),  time:23.055, tt:1175.788\n",
      "Ep:51, loss:0.00010, loss_test:0.14576, lr:5.35e-03, fs:0.57143 (r=0.465,p=0.742),  time:23.169, tt:1204.785\n",
      "Ep:52, loss:0.00010, loss_test:0.14549, lr:5.30e-03, fs:0.57143 (r=0.465,p=0.742),  time:23.253, tt:1232.416\n",
      "Ep:53, loss:0.00010, loss_test:0.14531, lr:5.25e-03, fs:0.57143 (r=0.465,p=0.742),  time:23.353, tt:1261.072\n",
      "Ep:54, loss:0.00010, loss_test:0.14494, lr:5.19e-03, fs:0.60123 (r=0.495,p=0.766),  time:23.462, tt:1290.407\n",
      "Ep:55, loss:0.00010, loss_test:0.14555, lr:5.14e-03, fs:0.57500 (r=0.465,p=0.754),  time:23.543, tt:1318.390\n",
      "Ep:56, loss:0.00009, loss_test:0.14465, lr:5.09e-03, fs:0.59259 (r=0.485,p=0.762),  time:23.648, tt:1347.959\n",
      "Ep:57, loss:0.00009, loss_test:0.14385, lr:5.04e-03, fs:0.61818 (r=0.515,p=0.773),  time:23.724, tt:1376.010\n",
      "Ep:58, loss:0.00009, loss_test:0.14540, lr:4.99e-03, fs:0.55346 (r=0.444,p=0.733),  time:23.784, tt:1403.285\n",
      "Ep:59, loss:0.00009, loss_test:0.14567, lr:4.94e-03, fs:0.56051 (r=0.444,p=0.759),  time:23.888, tt:1433.293\n",
      "Ep:60, loss:0.00009, loss_test:0.14387, lr:4.89e-03, fs:0.62195 (r=0.515,p=0.785),  time:23.994, tt:1463.632\n",
      "Ep:61, loss:0.00009, loss_test:0.14435, lr:4.84e-03, fs:0.56962 (r=0.455,p=0.763),  time:24.080, tt:1492.983\n",
      "Ep:62, loss:0.00009, loss_test:0.14458, lr:4.79e-03, fs:0.56051 (r=0.444,p=0.759),  time:24.166, tt:1522.478\n",
      "Ep:63, loss:0.00009, loss_test:0.14347, lr:4.74e-03, fs:0.60377 (r=0.485,p=0.800),  time:24.242, tt:1551.513\n",
      "Ep:64, loss:0.00009, loss_test:0.14284, lr:4.70e-03, fs:0.58750 (r=0.475,p=0.770),  time:24.324, tt:1581.060\n",
      "Ep:65, loss:0.00008, loss_test:0.14351, lr:4.65e-03, fs:0.56410 (r=0.444,p=0.772),  time:24.410, tt:1611.076\n",
      "Ep:66, loss:0.00008, loss_test:0.14378, lr:4.60e-03, fs:0.57516 (r=0.444,p=0.815),  time:24.485, tt:1640.524\n",
      "Ep:67, loss:0.00008, loss_test:0.14273, lr:4.56e-03, fs:0.58599 (r=0.465,p=0.793),  time:24.533, tt:1668.211\n",
      "Ep:68, loss:0.00008, loss_test:0.14230, lr:4.51e-03, fs:0.59119 (r=0.475,p=0.783),  time:24.595, tt:1697.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00008, loss_test:0.14231, lr:4.47e-03, fs:0.60256 (r=0.475,p=0.825),  time:24.652, tt:1725.628\n",
      "Ep:70, loss:0.00008, loss_test:0.14271, lr:4.42e-03, fs:0.56579 (r=0.434,p=0.811),  time:24.701, tt:1753.764\n",
      "Ep:71, loss:0.00008, loss_test:0.14161, lr:4.38e-03, fs:0.60256 (r=0.475,p=0.825),  time:24.764, tt:1783.031\n",
      "Ep:72, loss:0.00008, loss_test:0.14174, lr:4.33e-03, fs:0.61146 (r=0.485,p=0.828),  time:24.830, tt:1812.578\n",
      "Ep:73, loss:0.00008, loss_test:0.14193, lr:4.29e-03, fs:0.56579 (r=0.434,p=0.811),  time:24.879, tt:1841.042\n",
      "Ep:74, loss:0.00007, loss_test:0.14111, lr:4.25e-03, fs:0.61538 (r=0.485,p=0.842),  time:24.942, tt:1870.637\n",
      "Ep:75, loss:0.00007, loss_test:0.14094, lr:4.20e-03, fs:0.61538 (r=0.485,p=0.842),  time:24.985, tt:1898.833\n",
      "Ep:76, loss:0.00007, loss_test:0.14110, lr:4.16e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.044, tt:1928.352\n",
      "Ep:77, loss:0.00007, loss_test:0.14060, lr:4.12e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.081, tt:1956.321\n",
      "Ep:78, loss:0.00007, loss_test:0.14118, lr:4.08e-03, fs:0.57895 (r=0.444,p=0.830),  time:25.128, tt:1985.140\n",
      "Ep:79, loss:0.00007, loss_test:0.13997, lr:4.04e-03, fs:0.61146 (r=0.485,p=0.828),  time:25.164, tt:2013.147\n",
      "Ep:80, loss:0.00007, loss_test:0.14080, lr:4.00e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.218, tt:2042.638\n",
      "Ep:81, loss:0.00007, loss_test:0.14048, lr:3.96e-03, fs:0.57895 (r=0.444,p=0.830),  time:25.265, tt:2071.706\n",
      "Ep:82, loss:0.00007, loss_test:0.13959, lr:3.92e-03, fs:0.61146 (r=0.485,p=0.828),  time:25.320, tt:2101.569\n",
      "Ep:83, loss:0.00007, loss_test:0.14061, lr:3.88e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.351, tt:2129.516\n",
      "Ep:84, loss:0.00007, loss_test:0.14015, lr:3.84e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.363, tt:2155.863\n",
      "Ep:85, loss:0.00007, loss_test:0.13891, lr:3.80e-03, fs:0.61146 (r=0.485,p=0.828),  time:25.394, tt:2183.914\n",
      "Ep:86, loss:0.00007, loss_test:0.13983, lr:3.76e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.437, tt:2212.978\n",
      "Ep:87, loss:0.00006, loss_test:0.14006, lr:3.73e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.479, tt:2242.160\n",
      "Ep:88, loss:0.00006, loss_test:0.13854, lr:3.69e-03, fs:0.61146 (r=0.485,p=0.828),  time:25.503, tt:2269.799\n",
      "Ep:89, loss:0.00006, loss_test:0.13898, lr:3.65e-03, fs:0.61146 (r=0.485,p=0.828),  time:25.539, tt:2298.514\n",
      "Ep:90, loss:0.00006, loss_test:0.13952, lr:3.62e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.581, tt:2327.902\n",
      "Ep:91, loss:0.00006, loss_test:0.13877, lr:3.58e-03, fs:0.61146 (r=0.485,p=0.828),  time:25.635, tt:2358.405\n",
      "Ep:92, loss:0.00006, loss_test:0.13833, lr:3.54e-03, fs:0.62025 (r=0.495,p=0.831),  time:25.672, tt:2387.516\n",
      "Ep:93, loss:0.00006, loss_test:0.13853, lr:3.51e-03, fs:0.59355 (r=0.465,p=0.821),  time:25.695, tt:2415.332\n",
      "Ep:94, loss:0.00006, loss_test:0.13808, lr:3.47e-03, fs:0.63226 (r=0.495,p=0.875),  time:25.719, tt:2443.275\n",
      "Ep:95, loss:0.00006, loss_test:0.13808, lr:3.44e-03, fs:0.62420 (r=0.495,p=0.845),  time:25.740, tt:2471.032\n",
      "Ep:96, loss:0.00006, loss_test:0.13834, lr:3.40e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.773, tt:2499.947\n",
      "Ep:97, loss:0.00006, loss_test:0.13767, lr:3.37e-03, fs:0.62420 (r=0.495,p=0.845),  time:25.812, tt:2529.595\n",
      "Ep:98, loss:0.00006, loss_test:0.13819, lr:3.34e-03, fs:0.62420 (r=0.495,p=0.845),  time:25.842, tt:2558.329\n",
      "Ep:99, loss:0.00006, loss_test:0.13803, lr:3.30e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.864, tt:2586.413\n",
      "Ep:100, loss:0.00006, loss_test:0.13730, lr:3.27e-03, fs:0.62420 (r=0.495,p=0.845),  time:25.896, tt:2615.501\n",
      "Ep:101, loss:0.00006, loss_test:0.13808, lr:3.24e-03, fs:0.63636 (r=0.495,p=0.891),  time:25.932, tt:2645.031\n",
      "Ep:102, loss:0.00006, loss_test:0.13780, lr:3.21e-03, fs:0.63636 (r=0.495,p=0.891),  time:25.971, tt:2675.058\n",
      "Ep:103, loss:0.00006, loss_test:0.13747, lr:3.17e-03, fs:0.63226 (r=0.495,p=0.875),  time:26.015, tt:2705.545\n",
      "Ep:104, loss:0.00006, loss_test:0.13746, lr:3.14e-03, fs:0.63636 (r=0.495,p=0.891),  time:26.031, tt:2733.204\n",
      "Ep:105, loss:0.00005, loss_test:0.13723, lr:3.11e-03, fs:0.63636 (r=0.495,p=0.891),  time:26.049, tt:2761.160\n",
      "Ep:106, loss:0.00005, loss_test:0.13762, lr:3.08e-03, fs:0.64052 (r=0.495,p=0.907),  time:26.067, tt:2789.182\n",
      "Ep:107, loss:0.00005, loss_test:0.13699, lr:3.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.103, tt:2819.093\n",
      "Ep:108, loss:0.00005, loss_test:0.13663, lr:3.02e-03, fs:0.64516 (r=0.505,p=0.893),  time:26.144, tt:2849.647\n",
      "Ep:109, loss:0.00005, loss_test:0.13691, lr:2.99e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.184, tt:2880.294\n",
      "Ep:110, loss:0.00005, loss_test:0.13655, lr:2.96e-03, fs:0.66667 (r=0.525,p=0.912),  time:26.203, tt:2908.487\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00005, loss_test:0.13648, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.223, tt:2937.024\n",
      "Ep:112, loss:0.00005, loss_test:0.13583, lr:2.96e-03, fs:0.66667 (r=0.525,p=0.912),  time:26.254, tt:2966.711\n",
      "Ep:113, loss:0.00005, loss_test:0.13623, lr:2.96e-03, fs:0.65806 (r=0.515,p=0.911),  time:26.281, tt:2996.055\n",
      "Ep:114, loss:0.00005, loss_test:0.13600, lr:2.96e-03, fs:0.66667 (r=0.525,p=0.912),  time:26.304, tt:3024.966\n",
      "Ep:115, loss:0.00005, loss_test:0.13573, lr:2.96e-03, fs:0.67516 (r=0.535,p=0.914),  time:26.329, tt:3054.177\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00005, loss_test:0.13606, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.344, tt:3082.197\n",
      "Ep:117, loss:0.00005, loss_test:0.13633, lr:2.96e-03, fs:0.65359 (r=0.505,p=0.926),  time:26.379, tt:3112.744\n",
      "Ep:118, loss:0.00005, loss_test:0.13569, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.410, tt:3142.731\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00005, loss_test:0.13560, lr:2.96e-03, fs:0.65359 (r=0.505,p=0.926),  time:26.434, tt:3172.058\n",
      "Ep:120, loss:0.00005, loss_test:0.13560, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.452, tt:3200.633\n",
      "Ep:121, loss:0.00005, loss_test:0.13573, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.475, tt:3229.948\n",
      "Ep:122, loss:0.00005, loss_test:0.13580, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.504, tt:3259.983\n",
      "Ep:123, loss:0.00005, loss_test:0.13538, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.536, tt:3290.437\n",
      "Ep:124, loss:0.00005, loss_test:0.13537, lr:2.96e-03, fs:0.69620 (r=0.556,p=0.932),  time:26.549, tt:3318.616\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00005, loss_test:0.13565, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.565, tt:3347.175\n",
      "Ep:126, loss:0.00005, loss_test:0.13542, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.592, tt:3377.190\n",
      "Ep:127, loss:0.00005, loss_test:0.13531, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.607, tt:3405.729\n",
      "Ep:128, loss:0.00005, loss_test:0.13565, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.639, tt:3436.449\n",
      "Ep:129, loss:0.00005, loss_test:0.13544, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.656, tt:3465.273\n",
      "Ep:130, loss:0.00005, loss_test:0.13487, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.673, tt:3494.199\n",
      "Ep:131, loss:0.00005, loss_test:0.13545, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.687, tt:3522.646\n",
      "Ep:132, loss:0.00005, loss_test:0.13526, lr:2.96e-03, fs:0.68790 (r=0.545,p=0.931),  time:26.703, tt:3551.481\n",
      "Ep:133, loss:0.00004, loss_test:0.13473, lr:2.96e-03, fs:0.67516 (r=0.535,p=0.914),  time:26.731, tt:3581.951\n",
      "Ep:134, loss:0.00004, loss_test:0.13493, lr:2.96e-03, fs:0.65806 (r=0.515,p=0.911),  time:26.756, tt:3612.094\n",
      "Ep:135, loss:0.00004, loss_test:0.13476, lr:2.96e-03, fs:0.67949 (r=0.535,p=0.930),  time:26.772, tt:3640.942\n",
      "Ep:136, loss:0.00004, loss_test:0.13438, lr:2.93e-03, fs:0.68354 (r=0.545,p=0.915),  time:26.788, tt:3669.973\n",
      "Ep:137, loss:0.00004, loss_test:0.13471, lr:2.90e-03, fs:0.67516 (r=0.535,p=0.914),  time:26.810, tt:3699.713\n",
      "Ep:138, loss:0.00004, loss_test:0.13516, lr:2.87e-03, fs:0.68790 (r=0.545,p=0.931),  time:26.826, tt:3728.812\n",
      "Ep:139, loss:0.00004, loss_test:0.13458, lr:2.84e-03, fs:0.69620 (r=0.556,p=0.932),  time:26.835, tt:3756.884\n",
      "Ep:140, loss:0.00004, loss_test:0.13426, lr:2.81e-03, fs:0.65806 (r=0.515,p=0.911),  time:26.855, tt:3786.531\n",
      "Ep:141, loss:0.00004, loss_test:0.13444, lr:2.78e-03, fs:0.70440 (r=0.566,p=0.933),  time:26.859, tt:3813.978\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00004, loss_test:0.13460, lr:2.78e-03, fs:0.70440 (r=0.566,p=0.933),  time:26.873, tt:3842.812\n",
      "Ep:143, loss:0.00004, loss_test:0.13422, lr:2.78e-03, fs:0.67516 (r=0.535,p=0.914),  time:26.894, tt:3872.756\n",
      "Ep:144, loss:0.00004, loss_test:0.13412, lr:2.78e-03, fs:0.70000 (r=0.566,p=0.918),  time:26.922, tt:3903.692\n",
      "Ep:145, loss:0.00004, loss_test:0.13469, lr:2.78e-03, fs:0.70000 (r=0.566,p=0.918),  time:26.937, tt:3932.780\n",
      "Ep:146, loss:0.00004, loss_test:0.13480, lr:2.78e-03, fs:0.64935 (r=0.505,p=0.909),  time:26.955, tt:3962.355\n",
      "Ep:147, loss:0.00004, loss_test:0.13385, lr:2.78e-03, fs:0.68750 (r=0.556,p=0.902),  time:26.964, tt:3990.690\n",
      "Ep:148, loss:0.00004, loss_test:0.13413, lr:2.78e-03, fs:0.70440 (r=0.566,p=0.933),  time:26.979, tt:4019.918\n",
      "Ep:149, loss:0.00004, loss_test:0.13452, lr:2.78e-03, fs:0.67516 (r=0.535,p=0.914),  time:27.002, tt:4050.297\n",
      "Ep:150, loss:0.00004, loss_test:0.13399, lr:2.78e-03, fs:0.69620 (r=0.556,p=0.932),  time:27.024, tt:4080.680\n",
      "Ep:151, loss:0.00004, loss_test:0.13377, lr:2.78e-03, fs:0.69182 (r=0.556,p=0.917),  time:27.027, tt:4108.167\n",
      "Ep:152, loss:0.00004, loss_test:0.13432, lr:2.78e-03, fs:0.68354 (r=0.545,p=0.915),  time:27.027, tt:4135.094\n",
      "Ep:153, loss:0.00004, loss_test:0.13406, lr:2.76e-03, fs:0.69182 (r=0.556,p=0.917),  time:27.038, tt:4163.789\n",
      "Ep:154, loss:0.00004, loss_test:0.13391, lr:2.73e-03, fs:0.68750 (r=0.556,p=0.902),  time:27.066, tt:4195.272\n",
      "Ep:155, loss:0.00004, loss_test:0.13399, lr:2.70e-03, fs:0.69620 (r=0.556,p=0.932),  time:27.071, tt:4223.055\n",
      "Ep:156, loss:0.00004, loss_test:0.13416, lr:2.68e-03, fs:0.68354 (r=0.545,p=0.915),  time:27.068, tt:4249.666\n",
      "Ep:157, loss:0.00004, loss_test:0.13391, lr:2.65e-03, fs:0.67925 (r=0.545,p=0.900),  time:27.087, tt:4279.762\n",
      "Ep:158, loss:0.00004, loss_test:0.13382, lr:2.62e-03, fs:0.70440 (r=0.566,p=0.933),  time:27.100, tt:4308.937\n",
      "Ep:159, loss:0.00004, loss_test:0.13408, lr:2.60e-03, fs:0.67516 (r=0.535,p=0.914),  time:27.116, tt:4338.500\n",
      "Ep:160, loss:0.00004, loss_test:0.13430, lr:2.57e-03, fs:0.66667 (r=0.525,p=0.912),  time:27.132, tt:4368.284\n",
      "Ep:161, loss:0.00004, loss_test:0.13394, lr:2.54e-03, fs:0.70440 (r=0.566,p=0.933),  time:27.140, tt:4396.723\n",
      "Ep:162, loss:0.00004, loss_test:0.13392, lr:2.52e-03, fs:0.68750 (r=0.556,p=0.902),  time:27.161, tt:4427.308\n",
      "Ep:163, loss:0.00004, loss_test:0.13411, lr:2.49e-03, fs:0.67089 (r=0.535,p=0.898),  time:27.180, tt:4457.576\n",
      "Ep:164, loss:0.00004, loss_test:0.13373, lr:2.47e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.206, tt:4488.960\n",
      "Ep:165, loss:0.00004, loss_test:0.13395, lr:2.44e-03, fs:0.67925 (r=0.545,p=0.900),  time:27.229, tt:4520.053\n",
      "Ep:166, loss:0.00004, loss_test:0.13395, lr:2.42e-03, fs:0.67089 (r=0.535,p=0.898),  time:27.249, tt:4550.542\n",
      "Ep:167, loss:0.00004, loss_test:0.13348, lr:2.40e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.271, tt:4581.508\n",
      "Ep:168, loss:0.00004, loss_test:0.13363, lr:2.37e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.273, tt:4609.107\n",
      "Ep:169, loss:0.00004, loss_test:0.13388, lr:2.35e-03, fs:0.68354 (r=0.545,p=0.915),  time:27.275, tt:4636.807\n",
      "Ep:170, loss:0.00004, loss_test:0.13360, lr:2.32e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.289, tt:4666.402\n",
      "Ep:171, loss:0.00004, loss_test:0.13351, lr:2.30e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.302, tt:4695.917\n",
      "Ep:172, loss:0.00004, loss_test:0.13378, lr:2.28e-03, fs:0.67925 (r=0.545,p=0.900),  time:27.302, tt:4723.331\n",
      "Ep:173, loss:0.00004, loss_test:0.13360, lr:2.25e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.307, tt:4751.422\n",
      "Ep:174, loss:0.00004, loss_test:0.13328, lr:2.23e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.324, tt:4781.785\n",
      "Ep:175, loss:0.00004, loss_test:0.13349, lr:2.21e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.344, tt:4812.513\n",
      "Ep:176, loss:0.00004, loss_test:0.13372, lr:2.19e-03, fs:0.69182 (r=0.556,p=0.917),  time:27.352, tt:4841.367\n",
      "Ep:177, loss:0.00004, loss_test:0.13334, lr:2.17e-03, fs:0.69565 (r=0.566,p=0.903),  time:27.366, tt:4871.123\n",
      "Ep:178, loss:0.00003, loss_test:0.13354, lr:2.14e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.352, tt:4895.962\n",
      "Ep:179, loss:0.00003, loss_test:0.13346, lr:2.12e-03, fs:0.70000 (r=0.566,p=0.918),  time:27.307, tt:4915.273\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"19-19\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14549, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.060, tt:15.060\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14515, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.367, tt:34.735\n",
      "Ep:2, loss:0.00028, loss_test:0.14461, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.973, tt:59.918\n",
      "Ep:3, loss:0.00028, loss_test:0.14381, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.190, tt:88.761\n",
      "Ep:4, loss:0.00028, loss_test:0.14267, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.146, tt:120.732\n",
      "Ep:5, loss:0.00028, loss_test:0.14109, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:25.146, tt:150.875\n",
      "Ep:6, loss:0.00027, loss_test:0.13880, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:26.049, tt:182.341\n",
      "Ep:7, loss:0.00027, loss_test:0.13538, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:26.716, tt:213.732\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.13016, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:27.097, tt:243.873\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12401, lr:1.00e-02, fs:0.61983 (r=0.758,p=0.524),  time:27.483, tt:274.826\n",
      "Ep:10, loss:0.00023, loss_test:0.12109, lr:1.00e-02, fs:0.62136 (r=0.646,p=0.598),  time:27.825, tt:306.070\n",
      "Ep:11, loss:0.00023, loss_test:0.12138, lr:1.00e-02, fs:0.60606 (r=0.606,p=0.606),  time:28.134, tt:337.613\n",
      "Ep:12, loss:0.00022, loss_test:0.12019, lr:1.00e-02, fs:0.61616 (r=0.616,p=0.616),  time:28.186, tt:366.416\n",
      "Ep:13, loss:0.00022, loss_test:0.11757, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:28.374, tt:397.241\n",
      "Ep:14, loss:0.00022, loss_test:0.11560, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:28.662, tt:429.936\n",
      "Ep:15, loss:0.00021, loss_test:0.11387, lr:1.00e-02, fs:0.64975 (r=0.646,p=0.653),  time:28.913, tt:462.603\n",
      "Ep:16, loss:0.00020, loss_test:0.11257, lr:1.00e-02, fs:0.63542 (r=0.616,p=0.656),  time:28.916, tt:491.571\n",
      "Ep:17, loss:0.00020, loss_test:0.11109, lr:1.00e-02, fs:0.64249 (r=0.626,p=0.660),  time:29.047, tt:522.854\n",
      "Ep:18, loss:0.00019, loss_test:0.10986, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:29.049, tt:551.930\n",
      "Ep:19, loss:0.00019, loss_test:0.10834, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:29.173, tt:583.461\n",
      "Ep:20, loss:0.00019, loss_test:0.10693, lr:9.90e-03, fs:0.68020 (r=0.677,p=0.684),  time:29.313, tt:615.576\n",
      "Ep:21, loss:0.00018, loss_test:0.10627, lr:9.80e-03, fs:0.66316 (r=0.636,p=0.692),  time:29.426, tt:647.379\n",
      "Ep:22, loss:0.00018, loss_test:0.10583, lr:9.70e-03, fs:0.66316 (r=0.636,p=0.692),  time:29.489, tt:678.238\n",
      "Ep:23, loss:0.00017, loss_test:0.10474, lr:9.61e-03, fs:0.67010 (r=0.657,p=0.684),  time:29.618, tt:710.822\n",
      "Ep:24, loss:0.00017, loss_test:0.10346, lr:9.51e-03, fs:0.67692 (r=0.667,p=0.688),  time:29.711, tt:742.767\n",
      "Ep:25, loss:0.00017, loss_test:0.10241, lr:9.41e-03, fs:0.68421 (r=0.657,p=0.714),  time:29.752, tt:773.539\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.10167, lr:9.41e-03, fs:0.69110 (r=0.667,p=0.717),  time:29.866, tt:806.384\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.10090, lr:9.41e-03, fs:0.69110 (r=0.667,p=0.717),  time:29.949, tt:838.558\n",
      "Ep:28, loss:0.00016, loss_test:0.09982, lr:9.41e-03, fs:0.69474 (r=0.667,p=0.725),  time:29.988, tt:869.642\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.09892, lr:9.41e-03, fs:0.68783 (r=0.657,p=0.722),  time:30.075, tt:902.244\n",
      "Ep:30, loss:0.00015, loss_test:0.09826, lr:9.41e-03, fs:0.68783 (r=0.657,p=0.722),  time:30.157, tt:934.867\n",
      "Ep:31, loss:0.00015, loss_test:0.09782, lr:9.41e-03, fs:0.68449 (r=0.646,p=0.727),  time:30.160, tt:965.127\n",
      "Ep:32, loss:0.00015, loss_test:0.09714, lr:9.41e-03, fs:0.68449 (r=0.646,p=0.727),  time:30.224, tt:997.398\n",
      "Ep:33, loss:0.00015, loss_test:0.09680, lr:9.41e-03, fs:0.68108 (r=0.636,p=0.733),  time:30.264, tt:1028.981\n",
      "Ep:34, loss:0.00014, loss_test:0.09590, lr:9.41e-03, fs:0.68108 (r=0.636,p=0.733),  time:30.246, tt:1058.617\n",
      "Ep:35, loss:0.00014, loss_test:0.09525, lr:9.41e-03, fs:0.68478 (r=0.636,p=0.741),  time:30.271, tt:1089.753\n",
      "Ep:36, loss:0.00014, loss_test:0.09409, lr:9.41e-03, fs:0.69892 (r=0.657,p=0.747),  time:30.217, tt:1118.033\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00014, loss_test:0.09383, lr:9.41e-03, fs:0.70330 (r=0.646,p=0.771),  time:30.247, tt:1149.373\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.09366, lr:9.41e-03, fs:0.70000 (r=0.636,p=0.778),  time:30.294, tt:1181.477\n",
      "Ep:39, loss:0.00013, loss_test:0.09220, lr:9.41e-03, fs:0.70652 (r=0.657,p=0.765),  time:30.311, tt:1212.443\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.09220, lr:9.41e-03, fs:0.70391 (r=0.636,p=0.787),  time:30.367, tt:1245.031\n",
      "Ep:41, loss:0.00012, loss_test:0.09221, lr:9.41e-03, fs:0.70455 (r=0.626,p=0.805),  time:30.376, tt:1275.778\n",
      "Ep:42, loss:0.00012, loss_test:0.09098, lr:9.41e-03, fs:0.70391 (r=0.636,p=0.787),  time:30.429, tt:1308.462\n",
      "Ep:43, loss:0.00012, loss_test:0.09070, lr:9.41e-03, fs:0.70455 (r=0.626,p=0.805),  time:30.444, tt:1339.521\n",
      "Ep:44, loss:0.00012, loss_test:0.09075, lr:9.41e-03, fs:0.70455 (r=0.626,p=0.805),  time:30.469, tt:1371.119\n",
      "Ep:45, loss:0.00011, loss_test:0.08942, lr:9.41e-03, fs:0.70787 (r=0.636,p=0.797),  time:30.527, tt:1404.242\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00011, loss_test:0.08901, lr:9.41e-03, fs:0.71910 (r=0.646,p=0.810),  time:30.561, tt:1436.368\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00011, loss_test:0.08968, lr:9.41e-03, fs:0.71591 (r=0.636,p=0.818),  time:30.594, tt:1468.507\n",
      "Ep:48, loss:0.00011, loss_test:0.08755, lr:9.41e-03, fs:0.71508 (r=0.646,p=0.800),  time:30.606, tt:1499.675\n",
      "Ep:49, loss:0.00010, loss_test:0.08782, lr:9.41e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.618, tt:1530.887\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00010, loss_test:0.08746, lr:9.41e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.630, tt:1562.131\n",
      "Ep:51, loss:0.00010, loss_test:0.08645, lr:9.41e-03, fs:0.71591 (r=0.636,p=0.818),  time:30.658, tt:1594.239\n",
      "Ep:52, loss:0.00010, loss_test:0.08774, lr:9.41e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.667, tt:1625.359\n",
      "Ep:53, loss:0.00010, loss_test:0.08540, lr:9.41e-03, fs:0.71591 (r=0.636,p=0.818),  time:30.678, tt:1656.605\n",
      "Ep:54, loss:0.00009, loss_test:0.08523, lr:9.41e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.645, tt:1685.492\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00009, loss_test:0.08519, lr:9.41e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.631, tt:1715.348\n",
      "Ep:56, loss:0.00009, loss_test:0.08456, lr:9.41e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.623, tt:1745.520\n",
      "Ep:57, loss:0.00009, loss_test:0.08446, lr:9.41e-03, fs:0.71186 (r=0.636,p=0.808),  time:30.615, tt:1775.671\n",
      "Ep:58, loss:0.00009, loss_test:0.08371, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.626, tt:1806.950\n",
      "Ep:59, loss:0.00008, loss_test:0.08418, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.608, tt:1836.509\n",
      "Ep:60, loss:0.00008, loss_test:0.08341, lr:9.41e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.611, tt:1867.268\n",
      "Ep:61, loss:0.00008, loss_test:0.08336, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.630, tt:1899.032\n",
      "Ep:62, loss:0.00008, loss_test:0.08147, lr:9.41e-03, fs:0.72414 (r=0.636,p=0.840),  time:30.627, tt:1929.496\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00008, loss_test:0.08366, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.634, tt:1960.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00007, loss_test:0.08115, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.659, tt:1992.806\n",
      "Ep:65, loss:0.00007, loss_test:0.08169, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.656, tt:2023.269\n",
      "Ep:66, loss:0.00007, loss_test:0.08046, lr:9.41e-03, fs:0.72832 (r=0.636,p=0.851),  time:30.655, tt:2053.876\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00007, loss_test:0.08245, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.652, tt:2084.369\n",
      "Ep:68, loss:0.00007, loss_test:0.07939, lr:9.41e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.652, tt:2115.012\n",
      "Ep:69, loss:0.00007, loss_test:0.08165, lr:9.41e-03, fs:0.72189 (r=0.616,p=0.871),  time:30.666, tt:2146.627\n",
      "Ep:70, loss:0.00007, loss_test:0.07942, lr:9.41e-03, fs:0.73143 (r=0.646,p=0.842),  time:30.669, tt:2177.494\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00006, loss_test:0.08017, lr:9.41e-03, fs:0.71765 (r=0.616,p=0.859),  time:30.696, tt:2210.097\n",
      "Ep:72, loss:0.00006, loss_test:0.07860, lr:9.41e-03, fs:0.74286 (r=0.657,p=0.855),  time:30.710, tt:2241.856\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00006, loss_test:0.08050, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.709, tt:2272.497\n",
      "Ep:74, loss:0.00006, loss_test:0.07775, lr:9.41e-03, fs:0.74286 (r=0.657,p=0.855),  time:30.742, tt:2305.656\n",
      "Ep:75, loss:0.00006, loss_test:0.08032, lr:9.41e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.754, tt:2337.316\n",
      "Ep:76, loss:0.00006, loss_test:0.07792, lr:9.41e-03, fs:0.75000 (r=0.667,p=0.857),  time:30.773, tt:2369.511\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00006, loss_test:0.08032, lr:9.41e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.774, tt:2400.391\n",
      "Ep:78, loss:0.00006, loss_test:0.07798, lr:9.41e-03, fs:0.74286 (r=0.657,p=0.855),  time:30.760, tt:2430.051\n",
      "Ep:79, loss:0.00005, loss_test:0.07870, lr:9.41e-03, fs:0.73563 (r=0.646,p=0.853),  time:30.761, tt:2460.895\n",
      "Ep:80, loss:0.00005, loss_test:0.07821, lr:9.41e-03, fs:0.75706 (r=0.677,p=0.859),  time:30.758, tt:2491.385\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.07771, lr:9.41e-03, fs:0.75706 (r=0.677,p=0.859),  time:30.766, tt:2522.824\n",
      "Ep:82, loss:0.00005, loss_test:0.07864, lr:9.41e-03, fs:0.73563 (r=0.646,p=0.853),  time:30.782, tt:2554.878\n",
      "Ep:83, loss:0.00005, loss_test:0.07661, lr:9.41e-03, fs:0.77095 (r=0.697,p=0.863),  time:30.790, tt:2586.398\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00005, loss_test:0.07964, lr:9.41e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.784, tt:2616.658\n",
      "Ep:85, loss:0.00005, loss_test:0.07752, lr:9.41e-03, fs:0.75706 (r=0.677,p=0.859),  time:30.798, tt:2648.666\n",
      "Ep:86, loss:0.00005, loss_test:0.07921, lr:9.41e-03, fs:0.72189 (r=0.616,p=0.871),  time:30.797, tt:2679.350\n",
      "Ep:87, loss:0.00005, loss_test:0.07907, lr:9.41e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.800, tt:2710.430\n",
      "Ep:88, loss:0.00005, loss_test:0.07735, lr:9.41e-03, fs:0.76136 (r=0.677,p=0.870),  time:30.781, tt:2739.537\n",
      "Ep:89, loss:0.00004, loss_test:0.08005, lr:9.41e-03, fs:0.72189 (r=0.616,p=0.871),  time:30.768, tt:2769.144\n",
      "Ep:90, loss:0.00004, loss_test:0.07621, lr:9.41e-03, fs:0.76404 (r=0.687,p=0.861),  time:30.783, tt:2801.251\n",
      "Ep:91, loss:0.00004, loss_test:0.08013, lr:9.41e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.779, tt:2831.651\n",
      "Ep:92, loss:0.00004, loss_test:0.07671, lr:9.41e-03, fs:0.76404 (r=0.687,p=0.861),  time:30.790, tt:2863.506\n",
      "Ep:93, loss:0.00004, loss_test:0.07914, lr:9.41e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.787, tt:2893.970\n",
      "Ep:94, loss:0.00004, loss_test:0.07742, lr:9.41e-03, fs:0.75429 (r=0.667,p=0.868),  time:30.774, tt:2923.561\n",
      "Ep:95, loss:0.00004, loss_test:0.07861, lr:9.32e-03, fs:0.72619 (r=0.616,p=0.884),  time:30.770, tt:2953.879\n",
      "Ep:96, loss:0.00004, loss_test:0.07888, lr:9.23e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.781, tt:2985.791\n",
      "Ep:97, loss:0.00004, loss_test:0.07678, lr:9.14e-03, fs:0.76571 (r=0.677,p=0.882),  time:30.801, tt:3018.489\n",
      "Ep:98, loss:0.00004, loss_test:0.07953, lr:9.04e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.813, tt:3050.533\n",
      "Ep:99, loss:0.00004, loss_test:0.07626, lr:8.95e-03, fs:0.76136 (r=0.677,p=0.870),  time:30.823, tt:3082.327\n",
      "Ep:100, loss:0.00004, loss_test:0.07825, lr:8.86e-03, fs:0.75294 (r=0.646,p=0.901),  time:30.838, tt:3114.666\n",
      "Ep:101, loss:0.00004, loss_test:0.07851, lr:8.78e-03, fs:0.73810 (r=0.626,p=0.899),  time:30.848, tt:3146.465\n",
      "Ep:102, loss:0.00003, loss_test:0.07698, lr:8.69e-03, fs:0.77011 (r=0.677,p=0.893),  time:30.859, tt:3178.440\n",
      "Ep:103, loss:0.00003, loss_test:0.07844, lr:8.60e-03, fs:0.73810 (r=0.626,p=0.899),  time:30.860, tt:3209.395\n",
      "Ep:104, loss:0.00003, loss_test:0.07634, lr:8.51e-03, fs:0.76571 (r=0.677,p=0.882),  time:30.865, tt:3240.810\n",
      "Ep:105, loss:0.00003, loss_test:0.07865, lr:8.43e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.862, tt:3271.337\n",
      "Ep:106, loss:0.00003, loss_test:0.07617, lr:8.35e-03, fs:0.77011 (r=0.677,p=0.893),  time:30.849, tt:3300.884\n",
      "Ep:107, loss:0.00003, loss_test:0.07766, lr:8.26e-03, fs:0.74556 (r=0.636,p=0.900),  time:30.851, tt:3331.900\n",
      "Ep:108, loss:0.00003, loss_test:0.07706, lr:8.18e-03, fs:0.76744 (r=0.667,p=0.904),  time:30.860, tt:3363.727\n",
      "Ep:109, loss:0.00003, loss_test:0.07618, lr:8.10e-03, fs:0.77457 (r=0.677,p=0.905),  time:30.861, tt:3394.744\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00003, loss_test:0.07763, lr:8.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.866, tt:3426.091\n",
      "Ep:111, loss:0.00003, loss_test:0.07686, lr:8.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.862, tt:3456.522\n",
      "Ep:112, loss:0.00003, loss_test:0.07679, lr:8.10e-03, fs:0.77457 (r=0.677,p=0.905),  time:30.862, tt:3487.374\n",
      "Ep:113, loss:0.00003, loss_test:0.07685, lr:8.10e-03, fs:0.78363 (r=0.677,p=0.931),  time:30.858, tt:3517.869\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00003, loss_test:0.07630, lr:8.10e-03, fs:0.78613 (r=0.687,p=0.919),  time:30.851, tt:3547.918\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00003, loss_test:0.07766, lr:8.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.859, tt:3579.615\n",
      "Ep:116, loss:0.00003, loss_test:0.07700, lr:8.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.869, tt:3611.662\n",
      "Ep:117, loss:0.00003, loss_test:0.07707, lr:8.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.876, tt:3643.417\n",
      "Ep:118, loss:0.00003, loss_test:0.07910, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.885, tt:3675.295\n",
      "Ep:119, loss:0.00003, loss_test:0.07608, lr:8.10e-03, fs:0.78613 (r=0.687,p=0.919),  time:30.886, tt:3706.362\n",
      "Ep:120, loss:0.00003, loss_test:0.07863, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.895, tt:3738.245\n",
      "Ep:121, loss:0.00003, loss_test:0.07714, lr:8.10e-03, fs:0.75000 (r=0.636,p=0.913),  time:30.883, tt:3767.716\n",
      "Ep:122, loss:0.00003, loss_test:0.07767, lr:8.10e-03, fs:0.78363 (r=0.677,p=0.931),  time:30.878, tt:3797.942\n",
      "Ep:123, loss:0.00003, loss_test:0.07929, lr:8.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.872, tt:3828.149\n",
      "Ep:124, loss:0.00002, loss_test:0.07640, lr:8.10e-03, fs:0.78613 (r=0.687,p=0.919),  time:30.865, tt:3858.148\n",
      "Ep:125, loss:0.00002, loss_test:0.07833, lr:8.10e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.861, tt:3888.539\n",
      "Ep:126, loss:0.00002, loss_test:0.07774, lr:8.02e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.853, tt:3918.286\n",
      "Ep:127, loss:0.00002, loss_test:0.07704, lr:7.94e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.857, tt:3949.661\n",
      "Ep:128, loss:0.00002, loss_test:0.07865, lr:7.86e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.861, tt:3981.060\n",
      "Ep:129, loss:0.00002, loss_test:0.07754, lr:7.78e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.870, tt:4013.100\n",
      "Ep:130, loss:0.00002, loss_test:0.07871, lr:7.70e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.877, tt:4044.869\n",
      "Ep:131, loss:0.00002, loss_test:0.07848, lr:7.62e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.879, tt:4075.964\n",
      "Ep:132, loss:0.00002, loss_test:0.07739, lr:7.55e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.873, tt:4106.062\n",
      "Ep:133, loss:0.00002, loss_test:0.07853, lr:7.47e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.873, tt:4137.015\n",
      "Ep:134, loss:0.00002, loss_test:0.07802, lr:7.40e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.871, tt:4167.538\n",
      "Ep:135, loss:0.00002, loss_test:0.07858, lr:7.32e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.874, tt:4198.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00002, loss_test:0.07720, lr:7.25e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.876, tt:4229.978\n",
      "Ep:137, loss:0.00002, loss_test:0.07836, lr:7.18e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.889, tt:4262.704\n",
      "Ep:138, loss:0.00002, loss_test:0.07868, lr:7.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.896, tt:4294.499\n",
      "Ep:139, loss:0.00002, loss_test:0.07762, lr:7.03e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.885, tt:4323.883\n",
      "Ep:140, loss:0.00002, loss_test:0.07851, lr:6.96e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.891, tt:4355.591\n",
      "Ep:141, loss:0.00002, loss_test:0.07729, lr:6.89e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.893, tt:4386.758\n",
      "Ep:142, loss:0.00002, loss_test:0.07835, lr:6.83e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.896, tt:4418.189\n",
      "Ep:143, loss:0.00002, loss_test:0.07821, lr:6.76e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.888, tt:4447.849\n",
      "Ep:144, loss:0.00002, loss_test:0.07760, lr:6.69e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.885, tt:4478.277\n",
      "Ep:145, loss:0.00002, loss_test:0.07769, lr:6.62e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.876, tt:4507.920\n",
      "Ep:146, loss:0.00002, loss_test:0.07882, lr:6.56e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.869, tt:4537.723\n",
      "Ep:147, loss:0.00002, loss_test:0.07767, lr:6.49e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.857, tt:4566.790\n",
      "Ep:148, loss:0.00002, loss_test:0.07867, lr:6.43e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.847, tt:4596.141\n",
      "Ep:149, loss:0.00002, loss_test:0.07761, lr:6.36e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.836, tt:4625.473\n",
      "Ep:150, loss:0.00002, loss_test:0.07812, lr:6.30e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.832, tt:4655.629\n",
      "Ep:151, loss:0.00002, loss_test:0.07818, lr:6.24e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.824, tt:4685.244\n",
      "Ep:152, loss:0.00002, loss_test:0.07785, lr:6.17e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.829, tt:4716.904\n",
      "Ep:153, loss:0.00002, loss_test:0.07783, lr:6.11e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.830, tt:4747.793\n",
      "Ep:154, loss:0.00002, loss_test:0.07786, lr:6.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.833, tt:4779.156\n",
      "Ep:155, loss:0.00002, loss_test:0.07850, lr:5.99e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.825, tt:4808.692\n",
      "Ep:156, loss:0.00002, loss_test:0.07794, lr:5.93e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.824, tt:4839.394\n",
      "Ep:157, loss:0.00002, loss_test:0.07840, lr:5.87e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.825, tt:4870.397\n",
      "Ep:158, loss:0.00002, loss_test:0.07807, lr:5.81e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.825, tt:4901.216\n",
      "Ep:159, loss:0.00002, loss_test:0.07811, lr:5.75e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.835, tt:4933.563\n",
      "Ep:160, loss:0.00002, loss_test:0.07841, lr:5.70e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.818, tt:4961.691\n",
      "Ep:161, loss:0.00002, loss_test:0.07803, lr:5.64e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.812, tt:4991.547\n",
      "Ep:162, loss:0.00002, loss_test:0.07801, lr:5.58e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.819, tt:5023.415\n",
      "Ep:163, loss:0.00002, loss_test:0.07831, lr:5.53e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.819, tt:5054.382\n",
      "Ep:164, loss:0.00002, loss_test:0.07775, lr:5.47e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.818, tt:5084.897\n",
      "Ep:165, loss:0.00002, loss_test:0.07804, lr:5.42e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.804, tt:5113.504\n",
      "Ep:166, loss:0.00002, loss_test:0.07811, lr:5.36e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.802, tt:5144.018\n",
      "Ep:167, loss:0.00001, loss_test:0.07792, lr:5.31e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.810, tt:5176.024\n",
      "Ep:168, loss:0.00001, loss_test:0.07873, lr:5.26e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.814, tt:5207.630\n",
      "Ep:169, loss:0.00001, loss_test:0.07761, lr:5.20e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.817, tt:5238.867\n",
      "Ep:170, loss:0.00001, loss_test:0.07842, lr:5.15e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.809, tt:5268.278\n",
      "Ep:171, loss:0.00001, loss_test:0.07872, lr:5.10e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.813, tt:5299.801\n",
      "Ep:172, loss:0.00001, loss_test:0.07752, lr:5.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.816, tt:5331.150\n",
      "Ep:173, loss:0.00001, loss_test:0.07950, lr:5.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.818, tt:5362.293\n",
      "Ep:174, loss:0.00001, loss_test:0.07773, lr:4.95e-03, fs:0.77647 (r=0.667,p=0.930),  time:30.815, tt:5392.616\n",
      "Ep:175, loss:0.00001, loss_test:0.07825, lr:4.90e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.813, tt:5423.114\n",
      "Ep:176, loss:0.00001, loss_test:0.07933, lr:4.85e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.823, tt:5455.698\n",
      "Ep:177, loss:0.00001, loss_test:0.07792, lr:4.80e-03, fs:0.79070 (r=0.687,p=0.932),  time:30.818, tt:5485.537\n",
      "##########Best model found so far##########\n",
      "Ep:178, loss:0.00001, loss_test:0.07856, lr:4.80e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.808, tt:5514.560\n",
      "Ep:179, loss:0.00001, loss_test:0.07863, lr:4.80e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.813, tt:5546.258\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14400, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.599, tt:27.599\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14351, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.233, tt:56.465\n",
      "Ep:2, loss:0.00028, loss_test:0.14271, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.659, tt:79.977\n",
      "Ep:3, loss:0.00028, loss_test:0.14151, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.193, tt:108.771\n",
      "Ep:4, loss:0.00028, loss_test:0.13984, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.806, tt:139.030\n",
      "Ep:5, loss:0.00028, loss_test:0.13754, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.412, tt:170.471\n",
      "Ep:6, loss:0.00027, loss_test:0.13419, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.801, tt:201.606\n",
      "Ep:7, loss:0.00027, loss_test:0.12914, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:29.043, tt:232.341\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.12143, lr:1.00e-02, fs:0.69039 (r=0.980,p=0.533),  time:29.331, tt:263.976\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.11132, lr:1.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:29.433, tt:294.330\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.10402, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:29.576, tt:325.332\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10208, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:29.794, tt:357.533\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.10097, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:29.885, tt:388.499\n",
      "Ep:13, loss:0.00022, loss_test:0.10146, lr:1.00e-02, fs:0.75536 (r=0.889,p=0.657),  time:29.992, tt:419.882\n",
      "Ep:14, loss:0.00021, loss_test:0.10103, lr:1.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:30.174, tt:452.605\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.09812, lr:1.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:30.250, tt:483.995\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09575, lr:1.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:30.350, tt:515.944\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.09505, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.495, tt:548.915\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.09403, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:30.520, tt:579.884\n",
      "Ep:19, loss:0.00019, loss_test:0.09330, lr:1.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:30.617, tt:612.334\n",
      "Ep:20, loss:0.00018, loss_test:0.09183, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.662, tt:643.904\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09104, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:30.731, tt:676.085\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00018, loss_test:0.09110, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:30.734, tt:706.872\n",
      "Ep:23, loss:0.00017, loss_test:0.09057, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:30.741, tt:737.788\n",
      "Ep:24, loss:0.00017, loss_test:0.08936, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:30.769, tt:769.219\n",
      "Ep:25, loss:0.00017, loss_test:0.08817, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.798, tt:800.758\n",
      "Ep:26, loss:0.00016, loss_test:0.08777, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:30.799, tt:831.578\n",
      "Ep:27, loss:0.00016, loss_test:0.08792, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:30.828, tt:863.193\n",
      "Ep:28, loss:0.00016, loss_test:0.08728, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.844, tt:894.465\n",
      "Ep:29, loss:0.00015, loss_test:0.08613, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.866, tt:925.984\n",
      "Ep:30, loss:0.00015, loss_test:0.08539, lr:1.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.824, tt:955.532\n",
      "Ep:31, loss:0.00015, loss_test:0.08532, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.786, tt:985.158\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.08488, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.836, tt:1017.600\n",
      "Ep:33, loss:0.00014, loss_test:0.08383, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:30.809, tt:1047.503\n",
      "Ep:34, loss:0.00014, loss_test:0.08328, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.834, tt:1079.174\n",
      "Ep:35, loss:0.00014, loss_test:0.08317, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:30.837, tt:1110.119\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.08225, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:30.889, tt:1142.901\n",
      "Ep:37, loss:0.00013, loss_test:0.08101, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:30.870, tt:1173.069\n",
      "Ep:38, loss:0.00013, loss_test:0.08067, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:30.916, tt:1205.717\n",
      "Ep:39, loss:0.00012, loss_test:0.08024, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:30.907, tt:1236.277\n",
      "Ep:40, loss:0.00012, loss_test:0.07908, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:30.915, tt:1267.513\n",
      "Ep:41, loss:0.00012, loss_test:0.07829, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:30.962, tt:1300.404\n",
      "Ep:42, loss:0.00012, loss_test:0.07824, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:30.988, tt:1332.475\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.07744, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:31.025, tt:1365.116\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00011, loss_test:0.07659, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:31.056, tt:1397.541\n",
      "Ep:45, loss:0.00011, loss_test:0.07638, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:31.070, tt:1429.236\n",
      "Ep:46, loss:0.00011, loss_test:0.07576, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:31.069, tt:1460.255\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.07518, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:31.065, tt:1491.100\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00010, loss_test:0.07421, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:31.097, tt:1523.757\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00010, loss_test:0.07382, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:31.130, tt:1556.505\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00010, loss_test:0.07376, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:31.146, tt:1588.429\n",
      "Ep:51, loss:0.00009, loss_test:0.07339, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:31.128, tt:1618.664\n",
      "Ep:52, loss:0.00009, loss_test:0.07204, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:31.123, tt:1649.496\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.07257, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:31.084, tt:1678.550\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00009, loss_test:0.07278, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:31.098, tt:1710.372\n",
      "Ep:55, loss:0.00008, loss_test:0.07163, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:31.076, tt:1740.244\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00008, loss_test:0.07157, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:31.066, tt:1770.765\n",
      "Ep:57, loss:0.00008, loss_test:0.07144, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:31.068, tt:1801.952\n",
      "Ep:58, loss:0.00008, loss_test:0.07043, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:31.072, tt:1833.273\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00008, loss_test:0.07102, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:31.074, tt:1864.436\n",
      "Ep:60, loss:0.00007, loss_test:0.07091, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:31.096, tt:1896.884\n",
      "Ep:61, loss:0.00007, loss_test:0.07084, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.101, tt:1928.252\n",
      "Ep:62, loss:0.00007, loss_test:0.07158, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.105, tt:1959.646\n",
      "Ep:63, loss:0.00007, loss_test:0.06937, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:31.122, tt:1991.812\n",
      "Ep:64, loss:0.00007, loss_test:0.07148, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:31.143, tt:2024.318\n",
      "Ep:65, loss:0.00006, loss_test:0.06964, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:31.156, tt:2056.321\n",
      "Ep:66, loss:0.00006, loss_test:0.07000, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:31.169, tt:2088.323\n",
      "Ep:67, loss:0.00006, loss_test:0.07054, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.156, tt:2118.599\n",
      "Ep:68, loss:0.00006, loss_test:0.06966, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:31.164, tt:2150.287\n",
      "Ep:69, loss:0.00006, loss_test:0.06995, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:31.175, tt:2182.262\n",
      "Ep:70, loss:0.00006, loss_test:0.06902, lr:9.90e-03, fs:0.85859 (r=0.859,p=0.859),  time:31.180, tt:2213.766\n",
      "Ep:71, loss:0.00006, loss_test:0.07107, lr:9.80e-03, fs:0.83505 (r=0.818,p=0.853),  time:31.165, tt:2243.909\n",
      "Ep:72, loss:0.00005, loss_test:0.07082, lr:9.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.149, tt:2273.864\n",
      "Ep:73, loss:0.00005, loss_test:0.06962, lr:9.61e-03, fs:0.85279 (r=0.848,p=0.857),  time:31.150, tt:2305.071\n",
      "Ep:74, loss:0.00005, loss_test:0.07076, lr:9.51e-03, fs:0.82902 (r=0.808,p=0.851),  time:31.144, tt:2335.807\n",
      "Ep:75, loss:0.00005, loss_test:0.07052, lr:9.41e-03, fs:0.83770 (r=0.808,p=0.870),  time:31.138, tt:2366.505\n",
      "Ep:76, loss:0.00005, loss_test:0.07054, lr:9.32e-03, fs:0.83505 (r=0.818,p=0.853),  time:31.133, tt:2397.212\n",
      "Ep:77, loss:0.00005, loss_test:0.07096, lr:9.23e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.125, tt:2427.745\n",
      "Ep:78, loss:0.00005, loss_test:0.07089, lr:9.14e-03, fs:0.81481 (r=0.778,p=0.856),  time:31.116, tt:2458.186\n",
      "Ep:79, loss:0.00005, loss_test:0.07101, lr:9.04e-03, fs:0.82474 (r=0.808,p=0.842),  time:31.139, tt:2491.117\n",
      "Ep:80, loss:0.00005, loss_test:0.07032, lr:8.95e-03, fs:0.80628 (r=0.778,p=0.837),  time:31.145, tt:2522.770\n",
      "Ep:81, loss:0.00005, loss_test:0.07155, lr:8.86e-03, fs:0.80214 (r=0.758,p=0.852),  time:31.144, tt:2553.772\n",
      "Ep:82, loss:0.00005, loss_test:0.07009, lr:8.78e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.154, tt:2585.812\n",
      "Ep:83, loss:0.00004, loss_test:0.07075, lr:8.69e-03, fs:0.82723 (r=0.798,p=0.859),  time:31.161, tt:2617.543\n",
      "Ep:84, loss:0.00004, loss_test:0.07207, lr:8.60e-03, fs:0.79787 (r=0.758,p=0.843),  time:31.182, tt:2650.478\n",
      "Ep:85, loss:0.00004, loss_test:0.07012, lr:8.51e-03, fs:0.82902 (r=0.808,p=0.851),  time:31.166, tt:2680.253\n",
      "Ep:86, loss:0.00004, loss_test:0.07184, lr:8.43e-03, fs:0.80214 (r=0.758,p=0.852),  time:31.157, tt:2710.672\n",
      "Ep:87, loss:0.00004, loss_test:0.07179, lr:8.35e-03, fs:0.79365 (r=0.758,p=0.833),  time:31.170, tt:2742.955\n",
      "Ep:88, loss:0.00004, loss_test:0.07125, lr:8.26e-03, fs:0.80214 (r=0.758,p=0.852),  time:31.181, tt:2775.086\n",
      "Ep:89, loss:0.00004, loss_test:0.07099, lr:8.18e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.176, tt:2805.821\n",
      "Ep:90, loss:0.00004, loss_test:0.07152, lr:8.10e-03, fs:0.79787 (r=0.758,p=0.843),  time:31.170, tt:2836.483\n",
      "Ep:91, loss:0.00004, loss_test:0.07116, lr:8.02e-03, fs:0.81053 (r=0.778,p=0.846),  time:31.157, tt:2866.465\n",
      "Ep:92, loss:0.00004, loss_test:0.07255, lr:7.94e-03, fs:0.79144 (r=0.747,p=0.841),  time:31.140, tt:2896.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00004, loss_test:0.07093, lr:7.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:31.128, tt:2925.988\n",
      "Ep:94, loss:0.00004, loss_test:0.07151, lr:7.78e-03, fs:0.79787 (r=0.758,p=0.843),  time:31.112, tt:2955.668\n",
      "Ep:95, loss:0.00004, loss_test:0.07261, lr:7.70e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.109, tt:2986.439\n",
      "Ep:96, loss:0.00004, loss_test:0.07151, lr:7.62e-03, fs:0.79144 (r=0.747,p=0.841),  time:31.111, tt:3017.743\n",
      "Ep:97, loss:0.00003, loss_test:0.07241, lr:7.55e-03, fs:0.79144 (r=0.747,p=0.841),  time:31.101, tt:3047.922\n",
      "Ep:98, loss:0.00003, loss_test:0.07247, lr:7.47e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.079, tt:3076.773\n",
      "Ep:99, loss:0.00003, loss_test:0.07163, lr:7.40e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.079, tt:3107.865\n",
      "Ep:100, loss:0.00003, loss_test:0.07287, lr:7.32e-03, fs:0.79144 (r=0.747,p=0.841),  time:31.080, tt:3139.097\n",
      "Ep:101, loss:0.00003, loss_test:0.07230, lr:7.25e-03, fs:0.79144 (r=0.747,p=0.841),  time:31.069, tt:3169.020\n",
      "Ep:102, loss:0.00003, loss_test:0.07277, lr:7.18e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.036, tt:3196.683\n",
      "Ep:103, loss:0.00003, loss_test:0.07274, lr:7.11e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.034, tt:3227.574\n",
      "Ep:104, loss:0.00003, loss_test:0.07249, lr:7.03e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.040, tt:3259.169\n",
      "Ep:105, loss:0.00003, loss_test:0.07299, lr:6.96e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.009, tt:3286.952\n",
      "Ep:106, loss:0.00003, loss_test:0.07204, lr:6.89e-03, fs:0.78495 (r=0.737,p=0.839),  time:30.999, tt:3316.932\n",
      "Ep:107, loss:0.00003, loss_test:0.07312, lr:6.83e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.009, tt:3348.983\n",
      "Ep:108, loss:0.00003, loss_test:0.07258, lr:6.76e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.007, tt:3379.747\n",
      "Ep:109, loss:0.00003, loss_test:0.07390, lr:6.69e-03, fs:0.78919 (r=0.737,p=0.849),  time:31.019, tt:3412.114\n",
      "Ep:110, loss:0.00003, loss_test:0.07250, lr:6.62e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.017, tt:3442.864\n",
      "Ep:111, loss:0.00003, loss_test:0.07325, lr:6.56e-03, fs:0.78919 (r=0.737,p=0.849),  time:31.011, tt:3473.222\n",
      "Ep:112, loss:0.00003, loss_test:0.07338, lr:6.49e-03, fs:0.78495 (r=0.737,p=0.839),  time:31.007, tt:3503.781\n",
      "Ep:113, loss:0.00003, loss_test:0.07343, lr:6.43e-03, fs:0.78919 (r=0.737,p=0.849),  time:31.006, tt:3534.692\n",
      "Ep:114, loss:0.00003, loss_test:0.07286, lr:6.36e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.996, tt:3564.587\n",
      "Ep:115, loss:0.00003, loss_test:0.07277, lr:6.30e-03, fs:0.78495 (r=0.737,p=0.839),  time:30.994, tt:3595.355\n",
      "Ep:116, loss:0.00003, loss_test:0.07414, lr:6.24e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.989, tt:3625.750\n",
      "Ep:117, loss:0.00003, loss_test:0.07252, lr:6.17e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.989, tt:3656.689\n",
      "Ep:118, loss:0.00003, loss_test:0.07379, lr:6.11e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.980, tt:3686.640\n",
      "Ep:119, loss:0.00003, loss_test:0.07339, lr:6.05e-03, fs:0.78495 (r=0.737,p=0.839),  time:30.991, tt:3718.952\n",
      "Ep:120, loss:0.00003, loss_test:0.07391, lr:5.99e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.990, tt:3749.824\n",
      "Ep:121, loss:0.00003, loss_test:0.07255, lr:5.93e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.987, tt:3780.431\n",
      "Ep:122, loss:0.00003, loss_test:0.07348, lr:5.87e-03, fs:0.78495 (r=0.737,p=0.839),  time:30.979, tt:3810.415\n",
      "Ep:123, loss:0.00003, loss_test:0.07387, lr:5.81e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.973, tt:3840.694\n",
      "Ep:124, loss:0.00003, loss_test:0.07283, lr:5.75e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.964, tt:3870.480\n",
      "Ep:125, loss:0.00003, loss_test:0.07389, lr:5.70e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.943, tt:3898.878\n",
      "Ep:126, loss:0.00003, loss_test:0.07299, lr:5.64e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.946, tt:3930.141\n",
      "Ep:127, loss:0.00002, loss_test:0.07429, lr:5.58e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.948, tt:3961.300\n",
      "Ep:128, loss:0.00002, loss_test:0.07362, lr:5.53e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.949, tt:3992.380\n",
      "Ep:129, loss:0.00002, loss_test:0.07352, lr:5.47e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.941, tt:4022.359\n",
      "Ep:130, loss:0.00002, loss_test:0.07367, lr:5.42e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.940, tt:4053.167\n",
      "Ep:131, loss:0.00002, loss_test:0.07341, lr:5.36e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.933, tt:4083.182\n",
      "Ep:132, loss:0.00002, loss_test:0.07438, lr:5.31e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.930, tt:4113.714\n",
      "Ep:133, loss:0.00002, loss_test:0.07315, lr:5.26e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.933, tt:4144.961\n",
      "Ep:134, loss:0.00002, loss_test:0.07419, lr:5.20e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.924, tt:4174.722\n",
      "Ep:135, loss:0.00002, loss_test:0.07425, lr:5.15e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.921, tt:4205.197\n",
      "Ep:136, loss:0.00002, loss_test:0.07286, lr:5.10e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.922, tt:4236.320\n",
      "Ep:137, loss:0.00002, loss_test:0.07361, lr:5.05e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.925, tt:4267.687\n",
      "Ep:138, loss:0.00002, loss_test:0.07396, lr:5.00e-03, fs:0.78919 (r=0.737,p=0.849),  time:30.916, tt:4297.326\n",
      "Ep:139, loss:0.00002, loss_test:0.07485, lr:4.95e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.913, tt:4327.820\n",
      "Ep:140, loss:0.00002, loss_test:0.07310, lr:4.90e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.921, tt:4359.927\n",
      "Ep:141, loss:0.00002, loss_test:0.07406, lr:4.85e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.915, tt:4389.954\n",
      "Ep:142, loss:0.00002, loss_test:0.07431, lr:4.80e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.915, tt:4420.814\n",
      "Ep:143, loss:0.00002, loss_test:0.07321, lr:4.75e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.904, tt:4450.177\n",
      "Ep:144, loss:0.00002, loss_test:0.07427, lr:4.71e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.902, tt:4480.784\n",
      "Ep:145, loss:0.00002, loss_test:0.07451, lr:4.66e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.898, tt:4511.103\n",
      "Ep:146, loss:0.00002, loss_test:0.07367, lr:4.61e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.898, tt:4542.054\n",
      "Ep:147, loss:0.00002, loss_test:0.07383, lr:4.57e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.909, tt:4574.497\n",
      "Ep:148, loss:0.00002, loss_test:0.07381, lr:4.52e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.903, tt:4604.577\n",
      "Ep:149, loss:0.00002, loss_test:0.07463, lr:4.48e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.889, tt:4633.316\n",
      "Ep:150, loss:0.00002, loss_test:0.07355, lr:4.43e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.882, tt:4663.189\n",
      "Ep:151, loss:0.00002, loss_test:0.07445, lr:4.39e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.884, tt:4694.304\n",
      "Ep:152, loss:0.00002, loss_test:0.07472, lr:4.34e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.893, tt:4726.651\n",
      "Ep:153, loss:0.00002, loss_test:0.07377, lr:4.30e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.891, tt:4757.231\n",
      "Ep:154, loss:0.00002, loss_test:0.07399, lr:4.26e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.894, tt:4788.586\n",
      "Ep:155, loss:0.00002, loss_test:0.07477, lr:4.21e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.900, tt:4820.394\n",
      "Ep:156, loss:0.00002, loss_test:0.07487, lr:4.17e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.899, tt:4851.100\n",
      "Ep:157, loss:0.00002, loss_test:0.07355, lr:4.13e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.901, tt:4882.431\n",
      "Ep:158, loss:0.00002, loss_test:0.07493, lr:4.09e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.907, tt:4914.194\n",
      "Ep:159, loss:0.00002, loss_test:0.07440, lr:4.05e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.908, tt:4945.349\n",
      "Ep:160, loss:0.00002, loss_test:0.07449, lr:4.01e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.901, tt:4975.069\n",
      "Ep:161, loss:0.00002, loss_test:0.07393, lr:3.97e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.902, tt:5006.112\n",
      "Ep:162, loss:0.00002, loss_test:0.07404, lr:3.93e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.893, tt:5035.571\n",
      "Ep:163, loss:0.00002, loss_test:0.07477, lr:3.89e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.893, tt:5066.443\n",
      "Ep:164, loss:0.00002, loss_test:0.07402, lr:3.85e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.891, tt:5096.974\n",
      "Ep:165, loss:0.00002, loss_test:0.07429, lr:3.81e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.892, tt:5128.034\n",
      "Ep:166, loss:0.00002, loss_test:0.07448, lr:3.77e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.892, tt:5158.909\n",
      "Ep:167, loss:0.00002, loss_test:0.07461, lr:3.73e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.895, tt:5190.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00002, loss_test:0.07397, lr:3.70e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.891, tt:5220.657\n",
      "Ep:169, loss:0.00002, loss_test:0.07466, lr:3.66e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.884, tt:5250.328\n",
      "Ep:170, loss:0.00002, loss_test:0.07493, lr:3.62e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.876, tt:5279.735\n",
      "Ep:171, loss:0.00002, loss_test:0.07449, lr:3.59e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.878, tt:5310.995\n",
      "Ep:172, loss:0.00002, loss_test:0.07434, lr:3.55e-03, fs:0.79348 (r=0.737,p=0.859),  time:30.879, tt:5342.014\n",
      "Ep:173, loss:0.00002, loss_test:0.07498, lr:3.52e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.878, tt:5372.766\n",
      "Ep:174, loss:0.00002, loss_test:0.07495, lr:3.48e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.871, tt:5402.402\n",
      "Ep:175, loss:0.00002, loss_test:0.07429, lr:3.45e-03, fs:0.79781 (r=0.737,p=0.869),  time:30.869, tt:5433.019\n",
      "Ep:176, loss:0.00002, loss_test:0.07494, lr:3.41e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.862, tt:5462.633\n",
      "Ep:177, loss:0.00002, loss_test:0.07494, lr:3.38e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.854, tt:5491.980\n",
      "Ep:178, loss:0.00002, loss_test:0.07466, lr:3.34e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.845, tt:5521.340\n",
      "Ep:179, loss:0.00002, loss_test:0.07449, lr:3.31e-03, fs:0.78689 (r=0.727,p=0.857),  time:30.851, tt:5553.106\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14364, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.243, tt:53.243\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13889, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:53.933, tt:107.866\n",
      "Ep:2, loss:0.00052, loss_test:0.12646, lr:1.00e-02, fs:0.62903 (r=0.788,p=0.523),  time:56.303, tt:168.909\n",
      "Ep:3, loss:0.00047, loss_test:0.12205, lr:1.00e-02, fs:0.63317 (r=0.636,p=0.630),  time:58.969, tt:235.874\n",
      "Ep:4, loss:0.00045, loss_test:0.11873, lr:1.00e-02, fs:0.66359 (r=0.727,p=0.610),  time:60.337, tt:301.686\n",
      "Ep:5, loss:0.00043, loss_test:0.11464, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:61.058, tt:366.346\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.11162, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:61.674, tt:431.719\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.10780, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:61.932, tt:495.452\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.10352, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:62.125, tt:559.122\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.10029, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:62.470, tt:624.700\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.09756, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:62.710, tt:689.810\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.09611, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:62.854, tt:754.252\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.09443, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:62.998, tt:818.970\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.09287, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:63.064, tt:882.896\n",
      "Ep:14, loss:0.00028, loss_test:0.09168, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:63.101, tt:946.514\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.09071, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:63.147, tt:1010.349\n",
      "Ep:16, loss:0.00025, loss_test:0.08987, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:63.340, tt:1076.784\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.08761, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:63.410, tt:1141.382\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.08689, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:63.546, tt:1207.376\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.08667, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:63.637, tt:1272.733\n",
      "Ep:20, loss:0.00021, loss_test:0.08481, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:63.717, tt:1338.062\n",
      "Ep:21, loss:0.00020, loss_test:0.08183, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:63.822, tt:1404.073\n",
      "Ep:22, loss:0.00019, loss_test:0.08368, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:63.835, tt:1468.212\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.08605, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:63.866, tt:1532.786\n",
      "Ep:24, loss:0.00017, loss_test:0.08192, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:63.857, tt:1596.428\n",
      "Ep:25, loss:0.00016, loss_test:0.07867, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:63.901, tt:1661.431\n",
      "Ep:26, loss:0.00015, loss_test:0.07918, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:63.902, tt:1725.342\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08282, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:63.933, tt:1790.120\n",
      "Ep:28, loss:0.00013, loss_test:0.07831, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:63.957, tt:1854.760\n",
      "Ep:29, loss:0.00013, loss_test:0.07629, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:63.965, tt:1918.943\n",
      "Ep:30, loss:0.00012, loss_test:0.07791, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:63.969, tt:1983.038\n",
      "Ep:31, loss:0.00011, loss_test:0.07792, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:63.909, tt:2045.073\n",
      "Ep:32, loss:0.00011, loss_test:0.07756, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:63.991, tt:2111.699\n",
      "Ep:33, loss:0.00010, loss_test:0.07960, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:64.017, tt:2176.587\n",
      "Ep:34, loss:0.00010, loss_test:0.07701, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:64.031, tt:2241.094\n",
      "Ep:35, loss:0.00009, loss_test:0.07494, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:64.052, tt:2305.859\n",
      "Ep:36, loss:0.00009, loss_test:0.07770, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:64.063, tt:2370.326\n",
      "Ep:37, loss:0.00008, loss_test:0.07837, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:64.100, tt:2435.810\n",
      "Ep:38, loss:0.00008, loss_test:0.07439, lr:9.90e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.152, tt:2501.921\n",
      "Ep:39, loss:0.00008, loss_test:0.07255, lr:9.80e-03, fs:0.81564 (r=0.737,p=0.912),  time:64.150, tt:2565.989\n",
      "Ep:40, loss:0.00008, loss_test:0.07741, lr:9.70e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.174, tt:2631.136\n",
      "Ep:41, loss:0.00007, loss_test:0.07868, lr:9.61e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.174, tt:2695.287\n",
      "Ep:42, loss:0.00007, loss_test:0.07522, lr:9.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:64.179, tt:2759.714\n",
      "Ep:43, loss:0.00006, loss_test:0.07404, lr:9.41e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.164, tt:2823.208\n",
      "Ep:44, loss:0.00006, loss_test:0.07762, lr:9.32e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.159, tt:2887.140\n",
      "Ep:45, loss:0.00006, loss_test:0.07584, lr:9.23e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.154, tt:2951.068\n",
      "Ep:46, loss:0.00006, loss_test:0.07578, lr:9.14e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.185, tt:3016.715\n",
      "Ep:47, loss:0.00005, loss_test:0.07521, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.245, tt:3083.782\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.07717, lr:9.04e-03, fs:0.82486 (r=0.737,p=0.936),  time:64.276, tt:3149.547\n",
      "Ep:49, loss:0.00005, loss_test:0.07880, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.299, tt:3214.975\n",
      "Ep:50, loss:0.00005, loss_test:0.07831, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.341, tt:3281.406\n",
      "Ep:51, loss:0.00005, loss_test:0.07494, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.329, tt:3345.082\n",
      "Ep:52, loss:0.00005, loss_test:0.07438, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.298, tt:3407.794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00004, loss_test:0.07435, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.285, tt:3471.397\n",
      "Ep:54, loss:0.00004, loss_test:0.07536, lr:9.04e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.275, tt:3535.139\n",
      "Ep:55, loss:0.00004, loss_test:0.07425, lr:9.04e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.308, tt:3601.230\n",
      "Ep:56, loss:0.00004, loss_test:0.07495, lr:9.04e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.336, tt:3667.137\n",
      "Ep:57, loss:0.00004, loss_test:0.07468, lr:9.04e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.294, tt:3729.069\n",
      "Ep:58, loss:0.00004, loss_test:0.07438, lr:9.04e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.287, tt:3792.961\n",
      "Ep:59, loss:0.00004, loss_test:0.07574, lr:8.95e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.294, tt:3857.632\n",
      "Ep:60, loss:0.00003, loss_test:0.07466, lr:8.86e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.289, tt:3921.624\n",
      "Ep:61, loss:0.00003, loss_test:0.07604, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.302, tt:3986.707\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00003, loss_test:0.07575, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.291, tt:4050.303\n",
      "Ep:63, loss:0.00003, loss_test:0.07651, lr:8.78e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.237, tt:4111.169\n",
      "Ep:64, loss:0.00003, loss_test:0.07525, lr:8.78e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.270, tt:4177.568\n",
      "Ep:65, loss:0.00003, loss_test:0.07462, lr:8.78e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.300, tt:4243.779\n",
      "Ep:66, loss:0.00003, loss_test:0.07495, lr:8.78e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.299, tt:4308.006\n",
      "Ep:67, loss:0.00003, loss_test:0.07396, lr:8.78e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.310, tt:4373.106\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00003, loss_test:0.07504, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.274, tt:4434.932\n",
      "Ep:69, loss:0.00003, loss_test:0.07807, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.264, tt:4498.455\n",
      "Ep:70, loss:0.00003, loss_test:0.07851, lr:8.78e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.254, tt:4562.063\n",
      "Ep:71, loss:0.00003, loss_test:0.07681, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.235, tt:4624.950\n",
      "Ep:72, loss:0.00003, loss_test:0.07525, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.237, tt:4689.265\n",
      "Ep:73, loss:0.00002, loss_test:0.07367, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.251, tt:4754.552\n",
      "Ep:74, loss:0.00002, loss_test:0.07624, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.270, tt:4820.243\n",
      "Ep:75, loss:0.00002, loss_test:0.07853, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.264, tt:4884.050\n",
      "Ep:76, loss:0.00002, loss_test:0.08036, lr:8.78e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.285, tt:4949.970\n",
      "Ep:77, loss:0.00002, loss_test:0.07751, lr:8.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.292, tt:5014.813\n",
      "Ep:78, loss:0.00002, loss_test:0.07496, lr:8.78e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.301, tt:5079.816\n",
      "Ep:79, loss:0.00002, loss_test:0.07845, lr:8.69e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.331, tt:5146.500\n",
      "Ep:80, loss:0.00002, loss_test:0.07952, lr:8.60e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.358, tt:5213.007\n",
      "Ep:81, loss:0.00002, loss_test:0.07996, lr:8.51e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.338, tt:5275.753\n",
      "Ep:82, loss:0.00002, loss_test:0.08030, lr:8.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:64.352, tt:5341.241\n",
      "Ep:83, loss:0.00002, loss_test:0.07737, lr:8.35e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.359, tt:5406.116\n",
      "Ep:84, loss:0.00002, loss_test:0.07651, lr:8.26e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.349, tt:5469.639\n",
      "Ep:85, loss:0.00002, loss_test:0.07979, lr:8.18e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.348, tt:5533.966\n",
      "Ep:86, loss:0.00002, loss_test:0.07934, lr:8.10e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.349, tt:5598.349\n",
      "Ep:87, loss:0.00002, loss_test:0.07807, lr:8.02e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.341, tt:5662.016\n",
      "Ep:88, loss:0.00002, loss_test:0.07767, lr:7.94e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.341, tt:5726.372\n",
      "Ep:89, loss:0.00002, loss_test:0.07936, lr:7.86e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.350, tt:5791.516\n",
      "Ep:90, loss:0.00002, loss_test:0.08035, lr:7.78e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.341, tt:5855.003\n",
      "Ep:91, loss:0.00001, loss_test:0.07802, lr:7.70e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.353, tt:5920.454\n",
      "Ep:92, loss:0.00001, loss_test:0.07792, lr:7.62e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.358, tt:5985.318\n",
      "Ep:93, loss:0.00001, loss_test:0.08104, lr:7.55e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.371, tt:6050.845\n",
      "Ep:94, loss:0.00001, loss_test:0.07818, lr:7.47e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.368, tt:6114.949\n",
      "Ep:95, loss:0.00001, loss_test:0.07827, lr:7.40e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.373, tt:6179.855\n",
      "Ep:96, loss:0.00001, loss_test:0.07977, lr:7.32e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.375, tt:6244.378\n",
      "Ep:97, loss:0.00001, loss_test:0.07923, lr:7.25e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.392, tt:6310.415\n",
      "Ep:98, loss:0.00001, loss_test:0.07902, lr:7.18e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.400, tt:6375.606\n",
      "Ep:99, loss:0.00001, loss_test:0.07849, lr:7.11e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.403, tt:6440.265\n",
      "Ep:100, loss:0.00001, loss_test:0.07972, lr:7.03e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.414, tt:6505.788\n",
      "Ep:101, loss:0.00001, loss_test:0.07986, lr:6.96e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.429, tt:6571.752\n",
      "Ep:102, loss:0.00001, loss_test:0.07870, lr:6.89e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.438, tt:6637.076\n",
      "Ep:103, loss:0.00001, loss_test:0.07978, lr:6.83e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.430, tt:6700.668\n",
      "Ep:104, loss:0.00001, loss_test:0.07997, lr:6.76e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.443, tt:6766.513\n",
      "Ep:105, loss:0.00001, loss_test:0.07932, lr:6.69e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.466, tt:6833.391\n",
      "Ep:106, loss:0.00001, loss_test:0.07814, lr:6.62e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.466, tt:6897.879\n",
      "Ep:107, loss:0.00001, loss_test:0.08106, lr:6.56e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.471, tt:6962.866\n",
      "Ep:108, loss:0.00001, loss_test:0.07989, lr:6.49e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.463, tt:7026.421\n",
      "Ep:109, loss:0.00001, loss_test:0.07993, lr:6.43e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.468, tt:7091.454\n",
      "Ep:110, loss:0.00001, loss_test:0.07868, lr:6.36e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.465, tt:7155.574\n",
      "Ep:111, loss:0.00001, loss_test:0.07930, lr:6.30e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.458, tt:7219.249\n",
      "Ep:112, loss:0.00001, loss_test:0.07987, lr:6.24e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.473, tt:7285.425\n",
      "Ep:113, loss:0.00001, loss_test:0.08007, lr:6.17e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.458, tt:7348.165\n",
      "Ep:114, loss:0.00001, loss_test:0.08002, lr:6.11e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.475, tt:7414.612\n",
      "Ep:115, loss:0.00001, loss_test:0.07947, lr:6.05e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.485, tt:7480.316\n",
      "Ep:116, loss:0.00001, loss_test:0.08027, lr:5.99e-03, fs:0.84884 (r=0.737,p=1.000),  time:64.489, tt:7545.220\n",
      "Ep:117, loss:0.00001, loss_test:0.08027, lr:5.93e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.470, tt:7607.512\n",
      "Ep:118, loss:0.00001, loss_test:0.08093, lr:5.87e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.444, tt:7668.883\n",
      "Ep:119, loss:0.00001, loss_test:0.08043, lr:5.81e-03, fs:0.84393 (r=0.737,p=0.986),  time:64.448, tt:7733.714\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14231, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.080, tt:58.080\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13748, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:55.954, tt:111.907\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.13031, lr:1.00e-02, fs:0.66667 (r=0.788,p=0.578),  time:56.750, tt:170.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00046, loss_test:0.13049, lr:1.00e-02, fs:0.59596 (r=0.596,p=0.596),  time:59.722, tt:238.889\n",
      "Ep:4, loss:0.00044, loss_test:0.12150, lr:1.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:60.754, tt:303.772\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00042, loss_test:0.12237, lr:1.00e-02, fs:0.62745 (r=0.646,p=0.610),  time:61.647, tt:369.882\n",
      "Ep:6, loss:0.00040, loss_test:0.11743, lr:1.00e-02, fs:0.68269 (r=0.717,p=0.651),  time:62.253, tt:435.774\n",
      "Ep:7, loss:0.00038, loss_test:0.11355, lr:1.00e-02, fs:0.66341 (r=0.687,p=0.642),  time:62.545, tt:500.362\n",
      "Ep:8, loss:0.00036, loss_test:0.11160, lr:1.00e-02, fs:0.67692 (r=0.667,p=0.688),  time:62.868, tt:565.814\n",
      "Ep:9, loss:0.00034, loss_test:0.11022, lr:1.00e-02, fs:0.65625 (r=0.636,p=0.677),  time:62.954, tt:629.542\n",
      "Ep:10, loss:0.00032, loss_test:0.10868, lr:1.00e-02, fs:0.68041 (r=0.667,p=0.695),  time:63.088, tt:693.966\n",
      "Ep:11, loss:0.00031, loss_test:0.10929, lr:1.00e-02, fs:0.68783 (r=0.657,p=0.722),  time:63.166, tt:757.996\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.10717, lr:1.00e-02, fs:0.70466 (r=0.687,p=0.723),  time:63.480, tt:825.246\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.10649, lr:1.00e-02, fs:0.67760 (r=0.626,p=0.738),  time:63.643, tt:891.001\n",
      "Ep:14, loss:0.00027, loss_test:0.10592, lr:1.00e-02, fs:0.68132 (r=0.626,p=0.747),  time:63.786, tt:956.795\n",
      "Ep:15, loss:0.00026, loss_test:0.10561, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:63.873, tt:1021.963\n",
      "Ep:16, loss:0.00024, loss_test:0.10546, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:63.956, tt:1087.250\n",
      "Ep:17, loss:0.00023, loss_test:0.10915, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:64.004, tt:1152.065\n",
      "Ep:18, loss:0.00022, loss_test:0.10872, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:64.031, tt:1216.580\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.10673, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:64.160, tt:1283.205\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.10947, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:64.258, tt:1349.419\n",
      "Ep:21, loss:0.00019, loss_test:0.10785, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:64.238, tt:1413.226\n",
      "Ep:22, loss:0.00017, loss_test:0.11088, lr:1.00e-02, fs:0.71186 (r=0.636,p=0.808),  time:64.254, tt:1477.846\n",
      "Ep:23, loss:0.00016, loss_test:0.11139, lr:1.00e-02, fs:0.71111 (r=0.646,p=0.790),  time:64.345, tt:1544.273\n",
      "Ep:24, loss:0.00016, loss_test:0.11188, lr:1.00e-02, fs:0.70588 (r=0.606,p=0.845),  time:64.323, tt:1608.069\n",
      "Ep:25, loss:0.00015, loss_test:0.11270, lr:1.00e-02, fs:0.70175 (r=0.606,p=0.833),  time:64.356, tt:1673.262\n",
      "Ep:26, loss:0.00014, loss_test:0.10981, lr:1.00e-02, fs:0.71264 (r=0.626,p=0.827),  time:64.463, tt:1740.492\n",
      "Ep:27, loss:0.00013, loss_test:0.11671, lr:1.00e-02, fs:0.59740 (r=0.465,p=0.836),  time:64.443, tt:1804.391\n",
      "Ep:28, loss:0.00013, loss_test:0.11305, lr:1.00e-02, fs:0.66250 (r=0.535,p=0.869),  time:64.526, tt:1871.247\n",
      "Ep:29, loss:0.00012, loss_test:0.11344, lr:1.00e-02, fs:0.67485 (r=0.556,p=0.859),  time:64.544, tt:1936.318\n",
      "Ep:30, loss:0.00011, loss_test:0.11397, lr:1.00e-02, fs:0.70238 (r=0.596,p=0.855),  time:64.564, tt:2001.478\n",
      "Ep:31, loss:0.00011, loss_test:0.11145, lr:9.90e-03, fs:0.69880 (r=0.586,p=0.866),  time:64.557, tt:2065.813\n",
      "Ep:32, loss:0.00010, loss_test:0.11715, lr:9.80e-03, fs:0.58442 (r=0.455,p=0.818),  time:64.589, tt:2131.421\n",
      "Ep:33, loss:0.00009, loss_test:0.11164, lr:9.70e-03, fs:0.67879 (r=0.566,p=0.848),  time:64.565, tt:2195.214\n",
      "Ep:34, loss:0.00009, loss_test:0.11283, lr:9.61e-03, fs:0.66667 (r=0.545,p=0.857),  time:64.612, tt:2261.418\n",
      "Ep:35, loss:0.00009, loss_test:0.11483, lr:9.51e-03, fs:0.61146 (r=0.485,p=0.828),  time:64.636, tt:2326.889\n",
      "Ep:36, loss:0.00008, loss_test:0.11208, lr:9.41e-03, fs:0.69091 (r=0.576,p=0.864),  time:64.661, tt:2392.440\n",
      "Ep:37, loss:0.00008, loss_test:0.11119, lr:9.32e-03, fs:0.71765 (r=0.616,p=0.859),  time:64.671, tt:2457.504\n",
      "Ep:38, loss:0.00008, loss_test:0.11330, lr:9.23e-03, fs:0.63354 (r=0.515,p=0.823),  time:64.640, tt:2520.968\n",
      "Ep:39, loss:0.00007, loss_test:0.11717, lr:9.14e-03, fs:0.61842 (r=0.475,p=0.887),  time:64.591, tt:2583.659\n",
      "Ep:40, loss:0.00007, loss_test:0.11310, lr:9.04e-03, fs:0.65409 (r=0.525,p=0.867),  time:64.492, tt:2644.179\n",
      "Ep:41, loss:0.00006, loss_test:0.11819, lr:8.95e-03, fs:0.53425 (r=0.394,p=0.830),  time:64.531, tt:2710.307\n",
      "Ep:42, loss:0.00006, loss_test:0.11849, lr:8.86e-03, fs:0.53425 (r=0.394,p=0.830),  time:64.559, tt:2776.041\n",
      "Ep:43, loss:0.00006, loss_test:0.11569, lr:8.78e-03, fs:0.54422 (r=0.404,p=0.833),  time:64.519, tt:2838.847\n",
      "Ep:44, loss:0.00006, loss_test:0.11654, lr:8.69e-03, fs:0.56757 (r=0.424,p=0.857),  time:64.540, tt:2904.314\n",
      "Ep:45, loss:0.00005, loss_test:0.11860, lr:8.60e-03, fs:0.52113 (r=0.374,p=0.860),  time:64.524, tt:2968.109\n",
      "Ep:46, loss:0.00005, loss_test:0.11411, lr:8.51e-03, fs:0.61842 (r=0.475,p=0.887),  time:64.542, tt:3033.473\n",
      "Ep:47, loss:0.00005, loss_test:0.11834, lr:8.43e-03, fs:0.51748 (r=0.374,p=0.841),  time:64.488, tt:3095.412\n",
      "Ep:48, loss:0.00005, loss_test:0.12169, lr:8.35e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.503, tt:3160.648\n",
      "Ep:49, loss:0.00005, loss_test:0.11682, lr:8.26e-03, fs:0.51064 (r=0.364,p=0.857),  time:64.511, tt:3225.539\n",
      "Ep:50, loss:0.00004, loss_test:0.11807, lr:8.18e-03, fs:0.51064 (r=0.364,p=0.857),  time:64.550, tt:3292.038\n",
      "Ep:51, loss:0.00004, loss_test:0.11661, lr:8.10e-03, fs:0.52113 (r=0.374,p=0.860),  time:64.583, tt:3358.295\n",
      "Ep:52, loss:0.00004, loss_test:0.12192, lr:8.02e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.632, tt:3425.472\n",
      "Ep:53, loss:0.00004, loss_test:0.12117, lr:7.94e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.654, tt:3491.331\n",
      "Ep:54, loss:0.00004, loss_test:0.11626, lr:7.86e-03, fs:0.52113 (r=0.374,p=0.860),  time:64.677, tt:3557.263\n",
      "Ep:55, loss:0.00004, loss_test:0.11880, lr:7.78e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.706, tt:3623.529\n",
      "Ep:56, loss:0.00004, loss_test:0.12016, lr:7.70e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.711, tt:3688.517\n",
      "Ep:57, loss:0.00004, loss_test:0.12179, lr:7.62e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.733, tt:3754.524\n",
      "Ep:58, loss:0.00003, loss_test:0.11753, lr:7.55e-03, fs:0.52113 (r=0.374,p=0.860),  time:64.741, tt:3819.711\n",
      "Ep:59, loss:0.00003, loss_test:0.11976, lr:7.47e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.737, tt:3884.215\n",
      "Ep:60, loss:0.00003, loss_test:0.12172, lr:7.40e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.750, tt:3949.722\n",
      "Ep:61, loss:0.00003, loss_test:0.12101, lr:7.32e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.747, tt:4014.333\n",
      "Ep:62, loss:0.00003, loss_test:0.11848, lr:7.25e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.738, tt:4078.468\n",
      "Ep:63, loss:0.00003, loss_test:0.12250, lr:7.18e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.733, tt:4142.943\n",
      "Ep:64, loss:0.00003, loss_test:0.12019, lr:7.11e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.751, tt:4208.825\n",
      "Ep:65, loss:0.00003, loss_test:0.12197, lr:7.03e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.743, tt:4273.069\n",
      "Ep:66, loss:0.00003, loss_test:0.12232, lr:6.96e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.707, tt:4335.340\n",
      "Ep:67, loss:0.00003, loss_test:0.12302, lr:6.89e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.682, tt:4398.375\n",
      "Ep:68, loss:0.00003, loss_test:0.12263, lr:6.83e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.690, tt:4463.638\n",
      "Ep:69, loss:0.00002, loss_test:0.12104, lr:6.76e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.684, tt:4527.861\n",
      "Ep:70, loss:0.00002, loss_test:0.12456, lr:6.69e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.691, tt:4593.036\n",
      "Ep:71, loss:0.00002, loss_test:0.12106, lr:6.62e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.706, tt:4658.808\n",
      "Ep:72, loss:0.00002, loss_test:0.12355, lr:6.56e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.717, tt:4724.360\n",
      "Ep:73, loss:0.00002, loss_test:0.12456, lr:6.49e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.742, tt:4790.893\n",
      "Ep:74, loss:0.00002, loss_test:0.12336, lr:6.43e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.725, tt:4854.348\n",
      "Ep:75, loss:0.00002, loss_test:0.12404, lr:6.36e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.700, tt:4917.179\n",
      "Ep:76, loss:0.00002, loss_test:0.12437, lr:6.30e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.706, tt:4982.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00002, loss_test:0.12428, lr:6.24e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.703, tt:5046.862\n",
      "Ep:78, loss:0.00002, loss_test:0.12508, lr:6.17e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.718, tt:5112.698\n",
      "Ep:79, loss:0.00002, loss_test:0.12414, lr:6.11e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.698, tt:5175.842\n",
      "Ep:80, loss:0.00002, loss_test:0.12592, lr:6.05e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.680, tt:5239.061\n",
      "Ep:81, loss:0.00002, loss_test:0.12351, lr:5.99e-03, fs:0.50000 (r=0.354,p=0.854),  time:64.675, tt:5303.377\n",
      "Ep:82, loss:0.00002, loss_test:0.12604, lr:5.93e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.695, tt:5369.689\n",
      "Ep:83, loss:0.00002, loss_test:0.12602, lr:5.87e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.712, tt:5435.845\n",
      "Ep:84, loss:0.00002, loss_test:0.12442, lr:5.81e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.715, tt:5500.803\n",
      "Ep:85, loss:0.00002, loss_test:0.12802, lr:5.75e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.701, tt:5564.246\n",
      "Ep:86, loss:0.00002, loss_test:0.12510, lr:5.70e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.701, tt:5628.985\n",
      "Ep:87, loss:0.00002, loss_test:0.12670, lr:5.64e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.703, tt:5693.892\n",
      "Ep:88, loss:0.00002, loss_test:0.12561, lr:5.58e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.682, tt:5756.672\n",
      "Ep:89, loss:0.00002, loss_test:0.12581, lr:5.53e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.678, tt:5820.990\n",
      "Ep:90, loss:0.00002, loss_test:0.12560, lr:5.47e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.696, tt:5887.318\n",
      "Ep:91, loss:0.00002, loss_test:0.12742, lr:5.42e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.667, tt:5949.353\n",
      "Ep:92, loss:0.00002, loss_test:0.12689, lr:5.36e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.683, tt:6015.528\n",
      "Ep:93, loss:0.00002, loss_test:0.12648, lr:5.31e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.681, tt:6080.059\n",
      "Ep:94, loss:0.00002, loss_test:0.12818, lr:5.26e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.689, tt:6145.431\n",
      "Ep:95, loss:0.00001, loss_test:0.12767, lr:5.20e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.696, tt:6210.782\n",
      "Ep:96, loss:0.00001, loss_test:0.12784, lr:5.15e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.711, tt:6276.926\n",
      "Ep:97, loss:0.00001, loss_test:0.12681, lr:5.10e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.707, tt:6341.318\n",
      "Ep:98, loss:0.00001, loss_test:0.12796, lr:5.05e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.704, tt:6405.713\n",
      "Ep:99, loss:0.00001, loss_test:0.12773, lr:5.00e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.696, tt:6469.616\n",
      "Ep:100, loss:0.00001, loss_test:0.12809, lr:4.95e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.710, tt:6535.703\n",
      "Ep:101, loss:0.00001, loss_test:0.12765, lr:4.90e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.703, tt:6599.754\n",
      "Ep:102, loss:0.00001, loss_test:0.12812, lr:4.85e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.725, tt:6666.666\n",
      "Ep:103, loss:0.00001, loss_test:0.12769, lr:4.80e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.712, tt:6730.045\n",
      "Ep:104, loss:0.00001, loss_test:0.12900, lr:4.75e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.698, tt:6793.275\n",
      "Ep:105, loss:0.00001, loss_test:0.12691, lr:4.71e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.711, tt:6859.402\n",
      "Ep:106, loss:0.00001, loss_test:0.12956, lr:4.66e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.691, tt:6921.949\n",
      "Ep:107, loss:0.00001, loss_test:0.12785, lr:4.61e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.705, tt:6988.174\n",
      "Ep:108, loss:0.00001, loss_test:0.12869, lr:4.57e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.711, tt:7053.493\n",
      "Ep:109, loss:0.00001, loss_test:0.12873, lr:4.52e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.701, tt:7117.068\n",
      "Ep:110, loss:0.00001, loss_test:0.12824, lr:4.48e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.685, tt:7180.073\n",
      "Ep:111, loss:0.00001, loss_test:0.12824, lr:4.43e-03, fs:0.50360 (r=0.354,p=0.875),  time:64.671, tt:7243.155\n",
      "Ep:112, loss:0.00001, loss_test:0.12961, lr:4.39e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.681, tt:7308.907\n",
      "Ep:113, loss:0.00001, loss_test:0.12838, lr:4.34e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.676, tt:7373.070\n",
      "Ep:114, loss:0.00001, loss_test:0.12902, lr:4.30e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.662, tt:7436.117\n",
      "Ep:115, loss:0.00001, loss_test:0.12898, lr:4.26e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.666, tt:7501.236\n",
      "Ep:116, loss:0.00001, loss_test:0.12880, lr:4.21e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.652, tt:7564.338\n",
      "Ep:117, loss:0.00001, loss_test:0.12948, lr:4.17e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.636, tt:7627.097\n",
      "Ep:118, loss:0.00001, loss_test:0.12921, lr:4.13e-03, fs:0.51095 (r=0.354,p=0.921),  time:64.602, tt:7687.633\n",
      "Ep:119, loss:0.00001, loss_test:0.12895, lr:4.09e-03, fs:0.50725 (r=0.354,p=0.897),  time:64.588, tt:7750.572\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00082, loss_test:0.13752, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:86.932, tt:86.932\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00076, loss_test:0.12435, lr:1.00e-02, fs:0.59048 (r=0.626,p=0.559),  time:89.631, tt:179.262\n",
      "Ep:2, loss:0.00069, loss_test:0.11653, lr:1.00e-02, fs:0.60317 (r=0.576,p=0.633),  time:91.759, tt:275.278\n",
      "Ep:3, loss:0.00065, loss_test:0.11206, lr:1.00e-02, fs:0.65946 (r=0.616,p=0.709),  time:93.996, tt:375.985\n",
      "Ep:4, loss:0.00061, loss_test:0.10620, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:95.282, tt:476.412\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00056, loss_test:0.09982, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:95.804, tt:574.826\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00053, loss_test:0.09602, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:96.454, tt:675.176\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00050, loss_test:0.09323, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:96.830, tt:774.639\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00047, loss_test:0.09093, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:97.521, tt:877.688\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.08912, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:97.924, tt:979.243\n",
      "Ep:10, loss:0.00041, loss_test:0.08878, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:98.125, tt:1079.370\n",
      "Ep:11, loss:0.00039, loss_test:0.08715, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:98.000, tt:1175.996\n",
      "Ep:12, loss:0.00036, loss_test:0.08720, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:97.973, tt:1273.644\n",
      "Ep:13, loss:0.00034, loss_test:0.08777, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:98.004, tt:1372.059\n",
      "Ep:14, loss:0.00031, loss_test:0.08774, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:98.047, tt:1470.706\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.08677, lr:1.00e-02, fs:0.77193 (r=0.667,p=0.917),  time:98.170, tt:1570.720\n",
      "Ep:16, loss:0.00027, loss_test:0.08759, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:98.240, tt:1670.087\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.08781, lr:1.00e-02, fs:0.75581 (r=0.657,p=0.890),  time:98.351, tt:1770.313\n",
      "Ep:18, loss:0.00023, loss_test:0.08709, lr:1.00e-02, fs:0.73684 (r=0.636,p=0.875),  time:98.502, tt:1871.535\n",
      "Ep:19, loss:0.00021, loss_test:0.08622, lr:1.00e-02, fs:0.76023 (r=0.657,p=0.903),  time:98.600, tt:1972.006\n",
      "Ep:20, loss:0.00020, loss_test:0.08399, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:98.658, tt:2071.825\n",
      "Ep:21, loss:0.00018, loss_test:0.08565, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:98.612, tt:2169.473\n",
      "Ep:22, loss:0.00017, loss_test:0.08245, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:98.673, tt:2269.489\n",
      "Ep:23, loss:0.00015, loss_test:0.08381, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:98.693, tt:2368.626\n",
      "Ep:24, loss:0.00014, loss_test:0.08418, lr:1.00e-02, fs:0.72393 (r=0.596,p=0.922),  time:98.610, tt:2465.261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00013, loss_test:0.08286, lr:1.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:98.617, tt:2564.053\n",
      "Ep:26, loss:0.00012, loss_test:0.08212, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:98.544, tt:2660.680\n",
      "Ep:27, loss:0.00012, loss_test:0.08183, lr:1.00e-02, fs:0.71951 (r=0.596,p=0.908),  time:98.473, tt:2757.248\n",
      "Ep:28, loss:0.00011, loss_test:0.08218, lr:9.90e-03, fs:0.72393 (r=0.596,p=0.922),  time:98.363, tt:2852.519\n",
      "Ep:29, loss:0.00010, loss_test:0.08516, lr:9.80e-03, fs:0.70807 (r=0.576,p=0.919),  time:98.369, tt:2951.069\n",
      "Ep:30, loss:0.00010, loss_test:0.08346, lr:9.70e-03, fs:0.72393 (r=0.596,p=0.922),  time:98.334, tt:3048.361\n",
      "Ep:31, loss:0.00009, loss_test:0.08671, lr:9.61e-03, fs:0.70886 (r=0.566,p=0.949),  time:98.319, tt:3146.216\n",
      "Ep:32, loss:0.00008, loss_test:0.08702, lr:9.51e-03, fs:0.71698 (r=0.576,p=0.950),  time:98.264, tt:3242.703\n",
      "Ep:33, loss:0.00008, loss_test:0.08359, lr:9.41e-03, fs:0.73292 (r=0.596,p=0.952),  time:98.294, tt:3341.986\n",
      "Ep:34, loss:0.00008, loss_test:0.08330, lr:9.32e-03, fs:0.73292 (r=0.596,p=0.952),  time:98.340, tt:3441.898\n",
      "Ep:35, loss:0.00007, loss_test:0.08532, lr:9.23e-03, fs:0.73292 (r=0.596,p=0.952),  time:98.310, tt:3539.148\n",
      "Ep:36, loss:0.00007, loss_test:0.08635, lr:9.14e-03, fs:0.73292 (r=0.596,p=0.952),  time:98.246, tt:3635.084\n",
      "Ep:37, loss:0.00006, loss_test:0.08582, lr:9.04e-03, fs:0.72500 (r=0.586,p=0.951),  time:98.325, tt:3736.336\n",
      "Ep:38, loss:0.00006, loss_test:0.08395, lr:8.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:98.428, tt:3838.677\n",
      "Ep:39, loss:0.00006, loss_test:0.08671, lr:8.86e-03, fs:0.71698 (r=0.576,p=0.950),  time:98.361, tt:3934.432\n",
      "Ep:40, loss:0.00006, loss_test:0.08605, lr:8.78e-03, fs:0.70886 (r=0.566,p=0.949),  time:98.324, tt:4031.264\n",
      "Ep:41, loss:0.00006, loss_test:0.08974, lr:8.69e-03, fs:0.71338 (r=0.566,p=0.966),  time:98.368, tt:4131.471\n",
      "Ep:42, loss:0.00005, loss_test:0.08533, lr:8.60e-03, fs:0.73750 (r=0.596,p=0.967),  time:98.367, tt:4229.781\n",
      "Ep:43, loss:0.00005, loss_test:0.08611, lr:8.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:98.340, tt:4326.944\n",
      "Ep:44, loss:0.00005, loss_test:0.08705, lr:8.43e-03, fs:0.74534 (r=0.606,p=0.968),  time:98.340, tt:4425.279\n",
      "Ep:45, loss:0.00005, loss_test:0.08648, lr:8.35e-03, fs:0.75309 (r=0.616,p=0.968),  time:98.330, tt:4523.170\n",
      "Ep:46, loss:0.00005, loss_test:0.08769, lr:8.26e-03, fs:0.74534 (r=0.606,p=0.968),  time:98.294, tt:4619.835\n",
      "Ep:47, loss:0.00004, loss_test:0.09007, lr:8.18e-03, fs:0.71338 (r=0.566,p=0.966),  time:98.294, tt:4718.098\n",
      "Ep:48, loss:0.00004, loss_test:0.09104, lr:8.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:98.271, tt:4815.301\n",
      "Ep:49, loss:0.00004, loss_test:0.09204, lr:8.02e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.264, tt:4913.192\n",
      "Ep:50, loss:0.00004, loss_test:0.09020, lr:7.94e-03, fs:0.72152 (r=0.576,p=0.966),  time:98.207, tt:5008.563\n",
      "Ep:51, loss:0.00004, loss_test:0.09104, lr:7.86e-03, fs:0.71338 (r=0.566,p=0.966),  time:98.223, tt:5107.583\n",
      "Ep:52, loss:0.00004, loss_test:0.09071, lr:7.78e-03, fs:0.71338 (r=0.566,p=0.966),  time:98.204, tt:5204.828\n",
      "Ep:53, loss:0.00004, loss_test:0.09270, lr:7.70e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.208, tt:5303.256\n",
      "Ep:54, loss:0.00003, loss_test:0.09222, lr:7.62e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.222, tt:5402.223\n",
      "Ep:55, loss:0.00003, loss_test:0.09370, lr:7.55e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.252, tt:5502.139\n",
      "Ep:56, loss:0.00003, loss_test:0.09419, lr:7.47e-03, fs:0.68387 (r=0.535,p=0.946),  time:98.229, tt:5599.050\n",
      "Ep:57, loss:0.00003, loss_test:0.09537, lr:7.40e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.265, tt:5699.368\n",
      "Ep:58, loss:0.00003, loss_test:0.09372, lr:7.32e-03, fs:0.70513 (r=0.556,p=0.965),  time:98.256, tt:5797.092\n",
      "Ep:59, loss:0.00003, loss_test:0.09532, lr:7.25e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.272, tt:5896.307\n",
      "Ep:60, loss:0.00003, loss_test:0.09433, lr:7.18e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.288, tt:5995.599\n",
      "Ep:61, loss:0.00003, loss_test:0.09334, lr:7.11e-03, fs:0.70513 (r=0.556,p=0.965),  time:98.274, tt:6093.015\n",
      "Ep:62, loss:0.00003, loss_test:0.09299, lr:7.03e-03, fs:0.69677 (r=0.545,p=0.964),  time:98.262, tt:6190.506\n",
      "Ep:63, loss:0.00003, loss_test:0.09325, lr:6.96e-03, fs:0.68831 (r=0.535,p=0.964),  time:98.241, tt:6287.405\n",
      "Ep:64, loss:0.00002, loss_test:0.09536, lr:6.89e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.223, tt:6384.476\n",
      "Ep:65, loss:0.00002, loss_test:0.09446, lr:6.83e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.187, tt:6480.348\n",
      "Ep:66, loss:0.00002, loss_test:0.09413, lr:6.76e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.208, tt:6579.928\n",
      "Ep:67, loss:0.00002, loss_test:0.09419, lr:6.69e-03, fs:0.70968 (r=0.556,p=0.982),  time:98.190, tt:6676.943\n",
      "Ep:68, loss:0.00002, loss_test:0.09523, lr:6.62e-03, fs:0.70130 (r=0.545,p=0.982),  time:98.177, tt:6774.183\n",
      "Ep:69, loss:0.00002, loss_test:0.09621, lr:6.56e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.155, tt:6870.863\n",
      "Ep:70, loss:0.00002, loss_test:0.09707, lr:6.49e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.120, tt:6966.490\n",
      "Ep:71, loss:0.00002, loss_test:0.09583, lr:6.43e-03, fs:0.70130 (r=0.545,p=0.982),  time:98.180, tt:7068.985\n",
      "Ep:72, loss:0.00002, loss_test:0.09583, lr:6.36e-03, fs:0.71795 (r=0.566,p=0.982),  time:98.168, tt:7166.256\n",
      "Ep:73, loss:0.00002, loss_test:0.09482, lr:6.30e-03, fs:0.70968 (r=0.556,p=0.982),  time:98.152, tt:7263.235\n",
      "Ep:74, loss:0.00002, loss_test:0.09693, lr:6.24e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.166, tt:7362.474\n",
      "Ep:75, loss:0.00002, loss_test:0.09797, lr:6.17e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.140, tt:7458.654\n",
      "Ep:76, loss:0.00002, loss_test:0.09769, lr:6.11e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.112, tt:7554.597\n",
      "Ep:77, loss:0.00002, loss_test:0.09735, lr:6.05e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.096, tt:7651.499\n",
      "Ep:78, loss:0.00002, loss_test:0.09549, lr:5.99e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.092, tt:7749.247\n",
      "Ep:79, loss:0.00002, loss_test:0.09733, lr:5.93e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.104, tt:7848.342\n",
      "Ep:80, loss:0.00002, loss_test:0.09847, lr:5.87e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.087, tt:7945.082\n",
      "Ep:81, loss:0.00002, loss_test:0.09852, lr:5.81e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.081, tt:8042.637\n",
      "Ep:82, loss:0.00002, loss_test:0.09895, lr:5.75e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.042, tt:8137.525\n",
      "Ep:83, loss:0.00002, loss_test:0.09778, lr:5.70e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.077, tt:8238.448\n",
      "Ep:84, loss:0.00001, loss_test:0.09654, lr:5.64e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.062, tt:8335.303\n",
      "Ep:85, loss:0.00001, loss_test:0.09799, lr:5.58e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.050, tt:8432.274\n",
      "Ep:86, loss:0.00001, loss_test:0.09847, lr:5.53e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.017, tt:8527.514\n",
      "Ep:87, loss:0.00001, loss_test:0.09782, lr:5.47e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.024, tt:8626.146\n",
      "Ep:88, loss:0.00001, loss_test:0.09906, lr:5.42e-03, fs:0.69281 (r=0.535,p=0.981),  time:98.003, tt:8722.243\n",
      "Ep:89, loss:0.00001, loss_test:0.09797, lr:5.36e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.993, tt:8819.372\n",
      "Ep:90, loss:0.00001, loss_test:0.09944, lr:5.31e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.986, tt:8916.732\n",
      "Ep:91, loss:0.00001, loss_test:0.09898, lr:5.26e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.967, tt:9012.947\n",
      "Ep:92, loss:0.00001, loss_test:0.09915, lr:5.20e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.969, tt:9111.130\n",
      "Ep:93, loss:0.00001, loss_test:0.09924, lr:5.15e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.970, tt:9209.182\n",
      "Ep:94, loss:0.00001, loss_test:0.09962, lr:5.10e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.967, tt:9306.892\n",
      "Ep:95, loss:0.00001, loss_test:0.09995, lr:5.05e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.998, tt:9407.840\n",
      "Ep:96, loss:0.00001, loss_test:0.09990, lr:5.00e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.997, tt:9505.732\n",
      "Ep:97, loss:0.00001, loss_test:0.09985, lr:4.95e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.992, tt:9603.263\n",
      "Ep:98, loss:0.00001, loss_test:0.10048, lr:4.90e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.930, tt:9695.030\n",
      "Ep:99, loss:0.00001, loss_test:0.10006, lr:4.85e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.951, tt:9795.094\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00083, loss_test:0.13672, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:76.999, tt:76.999\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00077, loss_test:0.12187, lr:1.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:81.199, tt:162.398\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00069, loss_test:0.11640, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:86.628, tt:259.884\n",
      "Ep:3, loss:0.00065, loss_test:0.11233, lr:1.00e-02, fs:0.67980 (r=0.697,p=0.663),  time:89.783, tt:359.131\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00060, loss_test:0.10784, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:91.725, tt:458.625\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00056, loss_test:0.10379, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:92.759, tt:556.551\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00053, loss_test:0.09970, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:93.455, tt:654.187\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00050, loss_test:0.09660, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:94.094, tt:752.749\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00047, loss_test:0.09351, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:94.717, tt:852.456\n",
      "Ep:9, loss:0.00044, loss_test:0.09121, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:95.172, tt:951.722\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00041, loss_test:0.08869, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:95.689, tt:1052.581\n",
      "Ep:11, loss:0.00039, loss_test:0.08630, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:95.811, tt:1149.736\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00036, loss_test:0.08424, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:96.037, tt:1248.486\n",
      "Ep:13, loss:0.00034, loss_test:0.08408, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:96.219, tt:1347.069\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00032, loss_test:0.08283, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:96.362, tt:1445.437\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.08137, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:96.473, tt:1543.561\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.08006, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:96.483, tt:1640.206\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.07860, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:96.547, tt:1737.839\n",
      "Ep:18, loss:0.00024, loss_test:0.07851, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:96.598, tt:1835.358\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.07699, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:96.596, tt:1931.924\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.07819, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:96.670, tt:2030.074\n",
      "Ep:21, loss:0.00019, loss_test:0.07457, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:96.588, tt:2124.931\n",
      "Ep:22, loss:0.00018, loss_test:0.07302, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:96.723, tt:2224.626\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.07500, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:96.820, tt:2323.691\n",
      "Ep:24, loss:0.00015, loss_test:0.07332, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:96.824, tt:2420.602\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07416, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:96.859, tt:2518.340\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07531, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:96.854, tt:2615.052\n",
      "Ep:27, loss:0.00013, loss_test:0.07391, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:96.762, tt:2709.347\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07333, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:96.808, tt:2807.443\n",
      "Ep:29, loss:0.00011, loss_test:0.07256, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:96.822, tt:2904.654\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.07209, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:96.791, tt:3000.531\n",
      "Ep:31, loss:0.00010, loss_test:0.07289, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:96.876, tt:3100.027\n",
      "Ep:32, loss:0.00009, loss_test:0.07136, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:96.857, tt:3196.277\n",
      "Ep:33, loss:0.00009, loss_test:0.07354, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:96.908, tt:3294.865\n",
      "Ep:34, loss:0.00008, loss_test:0.07569, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:97.009, tt:3395.308\n",
      "Ep:35, loss:0.00008, loss_test:0.07666, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:97.021, tt:3492.739\n",
      "Ep:36, loss:0.00007, loss_test:0.07474, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:97.020, tt:3589.750\n",
      "Ep:37, loss:0.00007, loss_test:0.07815, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:97.042, tt:3687.601\n",
      "Ep:38, loss:0.00007, loss_test:0.08087, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:97.079, tt:3786.084\n",
      "Ep:39, loss:0.00007, loss_test:0.07943, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:97.048, tt:3881.903\n",
      "Ep:40, loss:0.00006, loss_test:0.07593, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:97.089, tt:3980.658\n",
      "Ep:41, loss:0.00006, loss_test:0.07767, lr:9.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:97.205, tt:4082.609\n",
      "Ep:42, loss:0.00005, loss_test:0.07717, lr:9.80e-03, fs:0.83146 (r=0.747,p=0.937),  time:97.235, tt:4181.100\n",
      "Ep:43, loss:0.00005, loss_test:0.07737, lr:9.70e-03, fs:0.83146 (r=0.747,p=0.937),  time:97.335, tt:4282.735\n",
      "Ep:44, loss:0.00005, loss_test:0.07920, lr:9.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:97.344, tt:4380.467\n",
      "Ep:45, loss:0.00005, loss_test:0.07907, lr:9.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:97.360, tt:4478.559\n",
      "Ep:46, loss:0.00004, loss_test:0.07778, lr:9.41e-03, fs:0.83146 (r=0.747,p=0.937),  time:97.410, tt:4578.290\n",
      "Ep:47, loss:0.00004, loss_test:0.07901, lr:9.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:97.428, tt:4676.521\n",
      "Ep:48, loss:0.00004, loss_test:0.07946, lr:9.23e-03, fs:0.81143 (r=0.717,p=0.934),  time:97.407, tt:4772.937\n",
      "Ep:49, loss:0.00004, loss_test:0.07824, lr:9.14e-03, fs:0.83146 (r=0.747,p=0.937),  time:97.390, tt:4869.480\n",
      "Ep:50, loss:0.00004, loss_test:0.08263, lr:9.04e-03, fs:0.80702 (r=0.697,p=0.958),  time:97.414, tt:4968.120\n",
      "Ep:51, loss:0.00003, loss_test:0.08338, lr:8.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:97.399, tt:5064.763\n",
      "Ep:52, loss:0.00003, loss_test:0.07973, lr:8.86e-03, fs:0.83616 (r=0.747,p=0.949),  time:97.365, tt:5160.359\n",
      "Ep:53, loss:0.00003, loss_test:0.08245, lr:8.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:97.390, tt:5259.039\n",
      "Ep:54, loss:0.00003, loss_test:0.08421, lr:8.69e-03, fs:0.77844 (r=0.657,p=0.956),  time:97.356, tt:5354.555\n",
      "Ep:55, loss:0.00003, loss_test:0.08553, lr:8.60e-03, fs:0.79042 (r=0.667,p=0.971),  time:97.401, tt:5454.459\n",
      "Ep:56, loss:0.00003, loss_test:0.08534, lr:8.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:97.420, tt:5552.964\n",
      "Ep:57, loss:0.00003, loss_test:0.08496, lr:8.43e-03, fs:0.75610 (r=0.626,p=0.954),  time:97.390, tt:5648.607\n",
      "Ep:58, loss:0.00003, loss_test:0.08531, lr:8.35e-03, fs:0.75610 (r=0.626,p=0.954),  time:97.470, tt:5750.751\n",
      "Ep:59, loss:0.00002, loss_test:0.08706, lr:8.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:97.494, tt:5849.611\n",
      "Ep:60, loss:0.00002, loss_test:0.08608, lr:8.18e-03, fs:0.76074 (r=0.626,p=0.969),  time:97.495, tt:5947.198\n",
      "Ep:61, loss:0.00002, loss_test:0.08522, lr:8.10e-03, fs:0.76074 (r=0.626,p=0.969),  time:97.538, tt:6047.382\n",
      "Ep:62, loss:0.00002, loss_test:0.08390, lr:8.02e-03, fs:0.75610 (r=0.626,p=0.954),  time:97.526, tt:6144.113\n",
      "Ep:63, loss:0.00002, loss_test:0.08607, lr:7.94e-03, fs:0.76074 (r=0.626,p=0.969),  time:97.557, tt:6243.648\n",
      "Ep:64, loss:0.00002, loss_test:0.08712, lr:7.86e-03, fs:0.76074 (r=0.626,p=0.969),  time:97.565, tt:6341.732\n",
      "Ep:65, loss:0.00002, loss_test:0.08558, lr:7.78e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.577, tt:6440.070\n",
      "Ep:66, loss:0.00002, loss_test:0.08781, lr:7.70e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.638, tt:6541.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00002, loss_test:0.08681, lr:7.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.632, tt:6638.960\n",
      "Ep:68, loss:0.00002, loss_test:0.08777, lr:7.55e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.692, tt:6740.744\n",
      "Ep:69, loss:0.00002, loss_test:0.08772, lr:7.47e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.674, tt:6837.207\n",
      "Ep:70, loss:0.00002, loss_test:0.08947, lr:7.40e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.696, tt:6936.442\n",
      "Ep:71, loss:0.00002, loss_test:0.08889, lr:7.32e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.705, tt:7034.794\n",
      "Ep:72, loss:0.00001, loss_test:0.08908, lr:7.25e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.706, tt:7132.529\n",
      "Ep:73, loss:0.00001, loss_test:0.08804, lr:7.18e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.741, tt:7232.800\n",
      "Ep:74, loss:0.00001, loss_test:0.08861, lr:7.11e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.758, tt:7331.824\n",
      "Ep:75, loss:0.00001, loss_test:0.08787, lr:7.03e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.752, tt:7429.123\n",
      "Ep:76, loss:0.00001, loss_test:0.09008, lr:6.96e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.737, tt:7525.714\n",
      "Ep:77, loss:0.00001, loss_test:0.08836, lr:6.89e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.772, tt:7626.239\n",
      "Ep:78, loss:0.00001, loss_test:0.08801, lr:6.83e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.786, tt:7725.094\n",
      "Ep:79, loss:0.00001, loss_test:0.08849, lr:6.76e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.784, tt:7822.753\n",
      "Ep:80, loss:0.00001, loss_test:0.08896, lr:6.69e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.816, tt:7923.069\n",
      "Ep:81, loss:0.00001, loss_test:0.08998, lr:6.62e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.851, tt:8023.756\n",
      "Ep:82, loss:0.00001, loss_test:0.08916, lr:6.56e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.834, tt:8120.191\n",
      "Ep:83, loss:0.00001, loss_test:0.08974, lr:6.49e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.854, tt:8219.719\n",
      "Ep:84, loss:0.00001, loss_test:0.09021, lr:6.43e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.839, tt:8316.326\n",
      "Ep:85, loss:0.00001, loss_test:0.08942, lr:6.36e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.838, tt:8414.105\n",
      "Ep:86, loss:0.00001, loss_test:0.08910, lr:6.30e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.841, tt:8512.133\n",
      "Ep:87, loss:0.00001, loss_test:0.08931, lr:6.24e-03, fs:0.77019 (r=0.626,p=1.000),  time:97.846, tt:8610.461\n",
      "Ep:88, loss:0.00001, loss_test:0.08892, lr:6.17e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.847, tt:8708.355\n",
      "Ep:89, loss:0.00001, loss_test:0.08853, lr:6.11e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.838, tt:8805.443\n",
      "Ep:90, loss:0.00001, loss_test:0.08908, lr:6.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.845, tt:8903.906\n",
      "Ep:91, loss:0.00001, loss_test:0.08904, lr:5.99e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.862, tt:9003.289\n",
      "Ep:92, loss:0.00001, loss_test:0.08968, lr:5.93e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.884, tt:9103.240\n",
      "Ep:93, loss:0.00001, loss_test:0.08957, lr:5.87e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.883, tt:9201.024\n",
      "Ep:94, loss:0.00001, loss_test:0.08971, lr:5.81e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.886, tt:9299.184\n",
      "Ep:95, loss:0.00001, loss_test:0.08910, lr:5.75e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.891, tt:9397.535\n",
      "Ep:96, loss:0.00001, loss_test:0.08983, lr:5.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.881, tt:9494.419\n",
      "Ep:97, loss:0.00001, loss_test:0.08935, lr:5.64e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.828, tt:9587.154\n",
      "Ep:98, loss:0.00001, loss_test:0.09058, lr:5.58e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.827, tt:9684.922\n",
      "Ep:99, loss:0.00001, loss_test:0.08989, lr:5.53e-03, fs:0.76543 (r=0.626,p=0.984),  time:97.840, tt:9783.953\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14261, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:95.076, tt:95.076\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00093, loss_test:0.13178, lr:1.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:102.917, tt:205.834\n",
      "Ep:2, loss:0.00081, loss_test:0.12266, lr:1.00e-02, fs:0.61224 (r=0.606,p=0.619),  time:106.772, tt:320.317\n",
      "Ep:3, loss:0.00074, loss_test:0.11918, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:108.036, tt:432.144\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00067, loss_test:0.11330, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:109.903, tt:549.516\n",
      "Ep:5, loss:0.00062, loss_test:0.11277, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:110.493, tt:662.960\n",
      "Ep:6, loss:0.00058, loss_test:0.10982, lr:1.00e-02, fs:0.68293 (r=0.707,p=0.660),  time:110.916, tt:776.415\n",
      "Ep:7, loss:0.00054, loss_test:0.10842, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:111.269, tt:890.153\n",
      "Ep:8, loss:0.00050, loss_test:0.10677, lr:1.00e-02, fs:0.67980 (r=0.697,p=0.663),  time:111.564, tt:1004.073\n",
      "Ep:9, loss:0.00046, loss_test:0.10365, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:112.011, tt:1120.108\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00043, loss_test:0.10227, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:112.245, tt:1234.690\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.09979, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:112.507, tt:1350.087\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00037, loss_test:0.10131, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:112.765, tt:1465.945\n",
      "Ep:13, loss:0.00034, loss_test:0.10014, lr:1.00e-02, fs:0.70056 (r=0.626,p=0.795),  time:112.921, tt:1580.896\n",
      "Ep:14, loss:0.00031, loss_test:0.09823, lr:1.00e-02, fs:0.73333 (r=0.667,p=0.815),  time:112.794, tt:1691.912\n",
      "Ep:15, loss:0.00028, loss_test:0.10071, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:113.009, tt:1808.139\n",
      "Ep:16, loss:0.00025, loss_test:0.10352, lr:1.00e-02, fs:0.72000 (r=0.636,p=0.829),  time:113.165, tt:1923.799\n",
      "Ep:17, loss:0.00023, loss_test:0.10066, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:113.197, tt:2037.554\n",
      "Ep:18, loss:0.00021, loss_test:0.10451, lr:1.00e-02, fs:0.70930 (r=0.616,p=0.836),  time:113.308, tt:2152.858\n",
      "Ep:19, loss:0.00019, loss_test:0.10227, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:113.449, tt:2268.974\n",
      "Ep:20, loss:0.00017, loss_test:0.09957, lr:1.00e-02, fs:0.71345 (r=0.616,p=0.847),  time:113.570, tt:2384.974\n",
      "Ep:21, loss:0.00016, loss_test:0.10261, lr:1.00e-02, fs:0.71765 (r=0.616,p=0.859),  time:113.686, tt:2501.093\n",
      "Ep:22, loss:0.00015, loss_test:0.10240, lr:1.00e-02, fs:0.71856 (r=0.606,p=0.882),  time:113.902, tt:2619.757\n",
      "Ep:23, loss:0.00014, loss_test:0.09818, lr:9.90e-03, fs:0.71345 (r=0.616,p=0.847),  time:113.974, tt:2735.381\n",
      "Ep:24, loss:0.00013, loss_test:0.10167, lr:9.80e-03, fs:0.72619 (r=0.616,p=0.884),  time:113.980, tt:2849.496\n",
      "Ep:25, loss:0.00012, loss_test:0.10160, lr:9.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:113.997, tt:2963.923\n",
      "Ep:26, loss:0.00011, loss_test:0.10010, lr:9.61e-03, fs:0.73494 (r=0.616,p=0.910),  time:113.861, tt:3074.254\n",
      "Ep:27, loss:0.00010, loss_test:0.10266, lr:9.51e-03, fs:0.73054 (r=0.616,p=0.897),  time:113.773, tt:3185.638\n",
      "Ep:28, loss:0.00009, loss_test:0.10153, lr:9.41e-03, fs:0.73054 (r=0.616,p=0.897),  time:113.881, tt:3302.537\n",
      "Ep:29, loss:0.00009, loss_test:0.10104, lr:9.32e-03, fs:0.73054 (r=0.616,p=0.897),  time:114.056, tt:3421.684\n",
      "Ep:30, loss:0.00008, loss_test:0.09997, lr:9.23e-03, fs:0.73939 (r=0.616,p=0.924),  time:114.052, tt:3535.603\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.10014, lr:9.23e-03, fs:0.72727 (r=0.606,p=0.909),  time:114.116, tt:3651.702\n",
      "Ep:32, loss:0.00007, loss_test:0.09924, lr:9.23e-03, fs:0.72727 (r=0.606,p=0.909),  time:114.117, tt:3765.861\n",
      "Ep:33, loss:0.00007, loss_test:0.09827, lr:9.23e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.116, tt:3879.940\n",
      "Ep:34, loss:0.00007, loss_test:0.10111, lr:9.23e-03, fs:0.73054 (r=0.616,p=0.897),  time:114.132, tt:3994.635\n",
      "Ep:35, loss:0.00006, loss_test:0.10485, lr:9.23e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.237, tt:4112.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00006, loss_test:0.09957, lr:9.23e-03, fs:0.73171 (r=0.606,p=0.923),  time:114.362, tt:4231.377\n",
      "Ep:37, loss:0.00006, loss_test:0.10161, lr:9.23e-03, fs:0.72727 (r=0.606,p=0.909),  time:114.415, tt:4347.788\n",
      "Ep:38, loss:0.00005, loss_test:0.09926, lr:9.23e-03, fs:0.73939 (r=0.616,p=0.924),  time:114.420, tt:4462.387\n",
      "Ep:39, loss:0.00005, loss_test:0.10043, lr:9.23e-03, fs:0.72050 (r=0.586,p=0.935),  time:114.458, tt:4578.338\n",
      "Ep:40, loss:0.00005, loss_test:0.10189, lr:9.23e-03, fs:0.72840 (r=0.596,p=0.937),  time:114.489, tt:4694.049\n",
      "Ep:41, loss:0.00005, loss_test:0.10075, lr:9.23e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.568, tt:4811.837\n",
      "Ep:42, loss:0.00004, loss_test:0.10169, lr:9.14e-03, fs:0.73620 (r=0.606,p=0.938),  time:114.505, tt:4923.724\n",
      "Ep:43, loss:0.00004, loss_test:0.10041, lr:9.04e-03, fs:0.73292 (r=0.596,p=0.952),  time:114.496, tt:5037.803\n",
      "Ep:44, loss:0.00004, loss_test:0.10315, lr:8.95e-03, fs:0.73292 (r=0.596,p=0.952),  time:114.502, tt:5152.574\n",
      "Ep:45, loss:0.00004, loss_test:0.10237, lr:8.86e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.532, tt:5268.478\n",
      "Ep:46, loss:0.00004, loss_test:0.10224, lr:8.78e-03, fs:0.72500 (r=0.586,p=0.951),  time:114.468, tt:5379.989\n",
      "Ep:47, loss:0.00004, loss_test:0.10217, lr:8.69e-03, fs:0.73292 (r=0.596,p=0.952),  time:114.501, tt:5496.044\n",
      "Ep:48, loss:0.00003, loss_test:0.10466, lr:8.60e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.559, tt:5613.399\n",
      "Ep:49, loss:0.00003, loss_test:0.10246, lr:8.51e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.575, tt:5728.743\n",
      "Ep:50, loss:0.00003, loss_test:0.10432, lr:8.43e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.545, tt:5841.790\n",
      "Ep:51, loss:0.00003, loss_test:0.10357, lr:8.35e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.579, tt:5958.085\n",
      "Ep:52, loss:0.00003, loss_test:0.10496, lr:8.26e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.570, tt:6072.204\n",
      "Ep:53, loss:0.00003, loss_test:0.10481, lr:8.18e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.574, tt:6187.018\n",
      "Ep:54, loss:0.00003, loss_test:0.10457, lr:8.10e-03, fs:0.72956 (r=0.586,p=0.967),  time:114.608, tt:6303.453\n",
      "Ep:55, loss:0.00002, loss_test:0.10376, lr:8.02e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.644, tt:6420.060\n",
      "Ep:56, loss:0.00002, loss_test:0.10776, lr:7.94e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.626, tt:6533.688\n",
      "Ep:57, loss:0.00002, loss_test:0.10501, lr:7.86e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.673, tt:6651.039\n",
      "Ep:58, loss:0.00002, loss_test:0.10620, lr:7.78e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.626, tt:6762.963\n",
      "Ep:59, loss:0.00002, loss_test:0.10515, lr:7.70e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.628, tt:6877.694\n",
      "Ep:60, loss:0.00002, loss_test:0.10561, lr:7.62e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.635, tt:6992.713\n",
      "Ep:61, loss:0.00002, loss_test:0.10439, lr:7.55e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.675, tt:7109.835\n",
      "Ep:62, loss:0.00002, loss_test:0.10497, lr:7.47e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.695, tt:7225.795\n",
      "Ep:63, loss:0.00002, loss_test:0.10620, lr:7.40e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.707, tt:7341.226\n",
      "Ep:64, loss:0.00002, loss_test:0.10606, lr:7.32e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.725, tt:7457.146\n",
      "Ep:65, loss:0.00002, loss_test:0.10538, lr:7.25e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.692, tt:7569.677\n",
      "Ep:66, loss:0.00002, loss_test:0.10557, lr:7.18e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.681, tt:7683.644\n",
      "Ep:67, loss:0.00002, loss_test:0.10650, lr:7.11e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.712, tt:7800.391\n",
      "Ep:68, loss:0.00002, loss_test:0.10939, lr:7.03e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.721, tt:7915.741\n",
      "Ep:69, loss:0.00002, loss_test:0.10826, lr:6.96e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.693, tt:8028.529\n",
      "Ep:70, loss:0.00002, loss_test:0.10663, lr:6.89e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.705, tt:8144.082\n",
      "Ep:71, loss:0.00001, loss_test:0.10667, lr:6.83e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.712, tt:8259.261\n",
      "Ep:72, loss:0.00001, loss_test:0.10851, lr:6.76e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.672, tt:8371.049\n",
      "Ep:73, loss:0.00001, loss_test:0.10658, lr:6.69e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.672, tt:8485.757\n",
      "Ep:74, loss:0.00001, loss_test:0.10595, lr:6.62e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.726, tt:8604.464\n",
      "Ep:75, loss:0.00001, loss_test:0.10731, lr:6.56e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.727, tt:8719.275\n",
      "Ep:76, loss:0.00001, loss_test:0.10765, lr:6.49e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.715, tt:8833.079\n",
      "Ep:77, loss:0.00001, loss_test:0.10817, lr:6.43e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.757, tt:8951.018\n",
      "Ep:78, loss:0.00001, loss_test:0.10704, lr:6.36e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.709, tt:9061.993\n",
      "Ep:79, loss:0.00001, loss_test:0.10785, lr:6.30e-03, fs:0.73418 (r=0.586,p=0.983),  time:114.727, tt:9178.124\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14262, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:98.151, tt:98.151\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00094, loss_test:0.13047, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:106.777, tt:213.554\n",
      "Ep:2, loss:0.00082, loss_test:0.11418, lr:1.00e-02, fs:0.66310 (r=0.626,p=0.705),  time:109.709, tt:329.128\n",
      "Ep:3, loss:0.00074, loss_test:0.10504, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:111.977, tt:447.908\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00067, loss_test:0.10006, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:112.378, tt:561.890\n",
      "Ep:5, loss:0.00062, loss_test:0.09740, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:112.939, tt:677.633\n",
      "Ep:6, loss:0.00058, loss_test:0.09363, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:113.462, tt:794.234\n",
      "Ep:7, loss:0.00055, loss_test:0.09134, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:114.009, tt:912.074\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00051, loss_test:0.08977, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:113.967, tt:1025.707\n",
      "Ep:9, loss:0.00048, loss_test:0.08780, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:114.348, tt:1143.483\n",
      "Ep:10, loss:0.00044, loss_test:0.08848, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:114.368, tt:1258.053\n",
      "Ep:11, loss:0.00041, loss_test:0.08335, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:114.285, tt:1371.417\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00038, loss_test:0.08285, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:114.377, tt:1486.905\n",
      "Ep:13, loss:0.00035, loss_test:0.08193, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:114.247, tt:1599.457\n",
      "Ep:14, loss:0.00032, loss_test:0.08328, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:114.178, tt:1712.664\n",
      "Ep:15, loss:0.00029, loss_test:0.08191, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:114.303, tt:1828.848\n",
      "Ep:16, loss:0.00026, loss_test:0.07773, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:114.287, tt:1942.876\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.07946, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:114.282, tt:2057.081\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.07998, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:114.209, tt:2169.962\n",
      "Ep:19, loss:0.00020, loss_test:0.07736, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:114.253, tt:2285.066\n",
      "Ep:20, loss:0.00018, loss_test:0.07370, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:114.285, tt:2399.977\n",
      "Ep:21, loss:0.00017, loss_test:0.07410, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:114.229, tt:2513.031\n",
      "Ep:22, loss:0.00016, loss_test:0.07550, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:114.271, tt:2628.231\n",
      "Ep:23, loss:0.00015, loss_test:0.07683, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:114.266, tt:2742.383\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00014, loss_test:0.07650, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:114.255, tt:2856.372\n",
      "Ep:25, loss:0.00013, loss_test:0.07414, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:114.183, tt:2968.759\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.07416, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:114.167, tt:3082.517\n",
      "Ep:27, loss:0.00011, loss_test:0.07381, lr:1.00e-02, fs:0.79042 (r=0.667,p=0.971),  time:114.160, tt:3196.484\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07575, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:114.117, tt:3309.385\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.07820, lr:1.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:114.092, tt:3422.749\n",
      "Ep:30, loss:0.00009, loss_test:0.07690, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:114.109, tt:3537.376\n",
      "Ep:31, loss:0.00008, loss_test:0.07722, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:114.132, tt:3652.227\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07790, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:114.111, tt:3765.657\n",
      "Ep:33, loss:0.00007, loss_test:0.07951, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:114.176, tt:3881.973\n",
      "Ep:34, loss:0.00007, loss_test:0.07916, lr:1.00e-02, fs:0.79290 (r=0.677,p=0.957),  time:114.148, tt:3995.184\n",
      "Ep:35, loss:0.00006, loss_test:0.07778, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:114.067, tt:4106.409\n",
      "Ep:36, loss:0.00006, loss_test:0.07852, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:114.096, tt:4221.561\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.07944, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:114.140, tt:4337.329\n",
      "Ep:38, loss:0.00005, loss_test:0.08103, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:114.230, tt:4454.952\n",
      "Ep:39, loss:0.00005, loss_test:0.08054, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:114.242, tt:4569.678\n",
      "Ep:40, loss:0.00005, loss_test:0.08060, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:114.227, tt:4683.293\n",
      "Ep:41, loss:0.00005, loss_test:0.08018, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:114.260, tt:4798.940\n",
      "Ep:42, loss:0.00004, loss_test:0.08113, lr:1.00e-02, fs:0.84091 (r=0.747,p=0.961),  time:114.190, tt:4910.190\n",
      "Ep:43, loss:0.00004, loss_test:0.08216, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:114.210, tt:5025.226\n",
      "Ep:44, loss:0.00004, loss_test:0.08147, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:114.264, tt:5141.866\n",
      "Ep:45, loss:0.00004, loss_test:0.08331, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:114.350, tt:5260.109\n",
      "Ep:46, loss:0.00004, loss_test:0.08125, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:114.403, tt:5376.918\n",
      "Ep:47, loss:0.00003, loss_test:0.08011, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:114.374, tt:5489.953\n",
      "Ep:48, loss:0.00003, loss_test:0.08307, lr:9.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:114.380, tt:5604.604\n",
      "Ep:49, loss:0.00003, loss_test:0.08339, lr:9.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:114.396, tt:5719.819\n",
      "Ep:50, loss:0.00003, loss_test:0.08483, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:114.356, tt:5832.174\n",
      "Ep:51, loss:0.00003, loss_test:0.08481, lr:9.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:114.344, tt:5945.869\n",
      "Ep:52, loss:0.00003, loss_test:0.08521, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:114.304, tt:6058.135\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.08526, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:114.307, tt:6172.567\n",
      "Ep:54, loss:0.00002, loss_test:0.08626, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:114.308, tt:6286.966\n",
      "Ep:55, loss:0.00002, loss_test:0.08691, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:114.290, tt:6400.217\n",
      "Ep:56, loss:0.00002, loss_test:0.08748, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:114.263, tt:6512.996\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.08754, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:114.252, tt:6626.589\n",
      "Ep:58, loss:0.00002, loss_test:0.08832, lr:9.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:114.264, tt:6741.604\n",
      "Ep:59, loss:0.00002, loss_test:0.08728, lr:9.51e-03, fs:0.85057 (r=0.747,p=0.987),  time:114.272, tt:6856.291\n",
      "Ep:60, loss:0.00002, loss_test:0.08669, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:114.251, tt:6969.337\n",
      "Ep:61, loss:0.00002, loss_test:0.08771, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:114.222, tt:7081.792\n",
      "Ep:62, loss:0.00002, loss_test:0.08893, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:114.224, tt:7196.083\n",
      "Ep:63, loss:0.00002, loss_test:0.08839, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:114.258, tt:7312.523\n",
      "Ep:64, loss:0.00002, loss_test:0.08873, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.322, tt:7430.937\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.08778, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.379, tt:7549.019\n",
      "Ep:66, loss:0.00001, loss_test:0.08810, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.403, tt:7665.012\n",
      "Ep:67, loss:0.00001, loss_test:0.08942, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.415, tt:7780.240\n",
      "Ep:68, loss:0.00001, loss_test:0.08828, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.376, tt:7891.959\n",
      "Ep:69, loss:0.00001, loss_test:0.08864, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.363, tt:8005.435\n",
      "Ep:70, loss:0.00001, loss_test:0.08871, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.376, tt:8120.714\n",
      "Ep:71, loss:0.00001, loss_test:0.08854, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.361, tt:8233.977\n",
      "Ep:72, loss:0.00001, loss_test:0.08916, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.375, tt:8349.344\n",
      "Ep:73, loss:0.00001, loss_test:0.08934, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.406, tt:8466.040\n",
      "Ep:74, loss:0.00001, loss_test:0.08906, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.442, tt:8583.150\n",
      "Ep:75, loss:0.00001, loss_test:0.08940, lr:9.51e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.479, tt:8700.399\n",
      "Ep:76, loss:0.00001, loss_test:0.08960, lr:9.41e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.501, tt:8816.576\n",
      "Ep:77, loss:0.00001, loss_test:0.09052, lr:9.32e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.513, tt:8932.009\n",
      "Ep:78, loss:0.00001, loss_test:0.08978, lr:9.23e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.521, tt:9047.143\n",
      "Ep:79, loss:0.00001, loss_test:0.09068, lr:9.14e-03, fs:0.86857 (r=0.768,p=1.000),  time:114.482, tt:9158.547\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00123, loss_test:0.13158, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:128.948, tt:128.948\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00106, loss_test:0.11703, lr:1.00e-02, fs:0.64516 (r=0.707,p=0.593),  time:139.161, tt:278.322\n",
      "Ep:2, loss:0.00093, loss_test:0.10673, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:142.934, tt:428.803\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00082, loss_test:0.10130, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:144.698, tt:578.790\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00073, loss_test:0.09904, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:145.615, tt:728.076\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00065, loss_test:0.09574, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:146.360, tt:878.161\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00059, loss_test:0.09360, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:147.030, tt:1029.212\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00053, loss_test:0.09297, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:147.198, tt:1177.582\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00046, loss_test:0.09018, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:147.509, tt:1327.584\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00041, loss_test:0.08941, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:147.844, tt:1478.442\n",
      "Ep:10, loss:0.00037, loss_test:0.08884, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:148.059, tt:1628.649\n",
      "Ep:11, loss:0.00033, loss_test:0.08963, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:148.292, tt:1779.508\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00029, loss_test:0.09134, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:148.032, tt:1924.413\n",
      "Ep:13, loss:0.00026, loss_test:0.09020, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:148.081, tt:2073.140\n",
      "Ep:14, loss:0.00022, loss_test:0.08687, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:147.996, tt:2219.933\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.08687, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:148.236, tt:2371.775\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08823, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:148.321, tt:2521.465\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08700, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:148.301, tt:2669.427\n",
      "Ep:18, loss:0.00014, loss_test:0.08763, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:147.987, tt:2811.754\n",
      "Ep:19, loss:0.00013, loss_test:0.09177, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:147.672, tt:2953.445\n",
      "Ep:20, loss:0.00011, loss_test:0.09335, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:147.345, tt:3094.237\n",
      "Ep:21, loss:0.00010, loss_test:0.09283, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:147.185, tt:3238.068\n",
      "Ep:22, loss:0.00009, loss_test:0.09307, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:147.155, tt:3384.563\n",
      "Ep:23, loss:0.00008, loss_test:0.09034, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:147.170, tt:3532.074\n",
      "Ep:24, loss:0.00007, loss_test:0.09301, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:147.185, tt:3679.634\n",
      "Ep:25, loss:0.00006, loss_test:0.09223, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:147.210, tt:3827.472\n",
      "Ep:26, loss:0.00006, loss_test:0.09151, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:147.200, tt:3974.408\n",
      "Ep:27, loss:0.00005, loss_test:0.09268, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:147.288, tt:4124.069\n",
      "Ep:28, loss:0.00005, loss_test:0.09391, lr:9.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:147.167, tt:4267.833\n",
      "Ep:29, loss:0.00005, loss_test:0.09164, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.191, tt:4415.724\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.09395, lr:9.80e-03, fs:0.85876 (r=0.768,p=0.974),  time:147.284, tt:4565.799\n",
      "Ep:31, loss:0.00004, loss_test:0.09461, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.401, tt:4716.820\n",
      "Ep:32, loss:0.00003, loss_test:0.09522, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.411, tt:4864.576\n",
      "Ep:33, loss:0.00003, loss_test:0.09364, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.404, tt:5011.723\n",
      "Ep:35, loss:0.00003, loss_test:0.09501, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.574, tt:5312.674\n",
      "Ep:36, loss:0.00002, loss_test:0.09565, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.702, tt:5464.972\n",
      "Ep:37, loss:0.00002, loss_test:0.09518, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.736, tt:5613.971\n",
      "Ep:38, loss:0.00002, loss_test:0.09634, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.855, tt:5766.342\n",
      "Ep:39, loss:0.00002, loss_test:0.09476, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.915, tt:5916.609\n",
      "Ep:40, loss:0.00002, loss_test:0.09556, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.897, tt:6063.795\n",
      "Ep:41, loss:0.00002, loss_test:0.09700, lr:9.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.845, tt:6209.503\n",
      "Ep:42, loss:0.00002, loss_test:0.09639, lr:9.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.759, tt:6353.629\n",
      "Ep:43, loss:0.00002, loss_test:0.09491, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.764, tt:6501.612\n",
      "Ep:44, loss:0.00001, loss_test:0.09752, lr:9.41e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.804, tt:6651.168\n",
      "Ep:45, loss:0.00001, loss_test:0.09761, lr:9.32e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.783, tt:6798.019\n",
      "Ep:46, loss:0.00001, loss_test:0.09728, lr:9.23e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.864, tt:6949.618\n",
      "Ep:47, loss:0.00001, loss_test:0.09571, lr:9.14e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.955, tt:7101.850\n",
      "Ep:48, loss:0.00001, loss_test:0.09542, lr:9.04e-03, fs:0.85876 (r=0.768,p=0.974),  time:147.944, tt:7249.249\n",
      "Ep:49, loss:0.00001, loss_test:0.09735, lr:8.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.921, tt:7396.072\n",
      "Ep:50, loss:0.00001, loss_test:0.09640, lr:8.86e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.911, tt:7543.484\n",
      "Ep:51, loss:0.00001, loss_test:0.09697, lr:8.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.939, tt:7692.806\n",
      "Ep:52, loss:0.00001, loss_test:0.09793, lr:8.69e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.966, tt:7842.197\n",
      "Ep:53, loss:0.00001, loss_test:0.09803, lr:8.60e-03, fs:0.86364 (r=0.768,p=0.987),  time:148.010, tt:7992.545\n",
      "Ep:54, loss:0.00001, loss_test:0.09864, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.991, tt:8139.495\n",
      "Ep:55, loss:0.00001, loss_test:0.09782, lr:8.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.969, tt:8286.286\n",
      "Ep:56, loss:0.00001, loss_test:0.09715, lr:8.35e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.952, tt:8433.241\n",
      "Ep:57, loss:0.00001, loss_test:0.09834, lr:8.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.971, tt:8582.296\n",
      "Ep:58, loss:0.00001, loss_test:0.09931, lr:8.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.880, tt:8724.937\n",
      "Ep:59, loss:0.00001, loss_test:0.09895, lr:8.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:147.798, tt:8867.893\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00122, loss_test:0.13921, lr:1.00e-02, fs:0.60674 (r=0.818,p=0.482),  time:131.254, tt:131.254\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00103, loss_test:0.12440, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:138.732, tt:277.465\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00091, loss_test:0.11671, lr:1.00e-02, fs:0.67943 (r=0.717,p=0.645),  time:141.382, tt:424.147\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00081, loss_test:0.10755, lr:1.00e-02, fs:0.66667 (r=0.677,p=0.657),  time:144.282, tt:577.130\n",
      "Ep:4, loss:0.00073, loss_test:0.10297, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:145.386, tt:726.929\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00067, loss_test:0.09881, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:146.203, tt:877.219\n",
      "Ep:6, loss:0.00061, loss_test:0.09488, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:146.084, tt:1022.591\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00055, loss_test:0.08835, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:145.958, tt:1167.661\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00050, loss_test:0.08447, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:146.510, tt:1318.594\n",
      "Ep:9, loss:0.00045, loss_test:0.08299, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:146.980, tt:1469.797\n",
      "Ep:10, loss:0.00040, loss_test:0.08365, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:146.943, tt:1616.377\n",
      "Ep:11, loss:0.00036, loss_test:0.07918, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:147.324, tt:1767.885\n",
      "Ep:12, loss:0.00032, loss_test:0.07774, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:147.210, tt:1913.724\n",
      "Ep:13, loss:0.00028, loss_test:0.07776, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:147.440, tt:2064.153\n",
      "Ep:14, loss:0.00025, loss_test:0.07547, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:147.304, tt:2209.552\n",
      "Ep:15, loss:0.00022, loss_test:0.07697, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:147.300, tt:2356.808\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00019, loss_test:0.07633, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:147.272, tt:2503.624\n",
      "Ep:17, loss:0.00017, loss_test:0.07869, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:147.297, tt:2651.340\n",
      "Ep:18, loss:0.00015, loss_test:0.07657, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:147.289, tt:2798.487\n",
      "Ep:19, loss:0.00013, loss_test:0.08039, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:147.466, tt:2949.322\n",
      "Ep:20, loss:0.00012, loss_test:0.07523, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:147.469, tt:3096.847\n",
      "Ep:21, loss:0.00011, loss_test:0.07869, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:147.394, tt:3242.674\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00010, loss_test:0.07721, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:147.439, tt:3391.104\n",
      "Ep:23, loss:0.00009, loss_test:0.07712, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:147.551, tt:3541.228\n",
      "Ep:24, loss:0.00008, loss_test:0.07654, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:147.545, tt:3688.616\n",
      "Ep:25, loss:0.00007, loss_test:0.07735, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:147.615, tt:3838.003\n",
      "Ep:26, loss:0.00007, loss_test:0.07959, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:147.502, tt:3982.554\n",
      "Ep:27, loss:0.00006, loss_test:0.07894, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:147.649, tt:4134.184\n",
      "Ep:28, loss:0.00006, loss_test:0.08087, lr:1.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:147.677, tt:4282.635\n",
      "Ep:29, loss:0.00005, loss_test:0.08344, lr:1.00e-02, fs:0.79042 (r=0.667,p=0.971),  time:147.646, tt:4429.391\n",
      "Ep:30, loss:0.00005, loss_test:0.07962, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:147.567, tt:4574.590\n",
      "Ep:31, loss:0.00005, loss_test:0.07965, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:147.432, tt:4717.810\n",
      "Ep:32, loss:0.00004, loss_test:0.08241, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:147.556, tt:4869.346\n",
      "Ep:33, loss:0.00004, loss_test:0.08086, lr:9.90e-03, fs:0.77844 (r=0.657,p=0.956),  time:147.499, tt:5014.977\n",
      "Ep:34, loss:0.00003, loss_test:0.08234, lr:9.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:147.452, tt:5160.808\n",
      "Ep:35, loss:0.00003, loss_test:0.08391, lr:9.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.497, tt:5309.879\n",
      "Ep:36, loss:0.00003, loss_test:0.08169, lr:9.61e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.502, tt:5457.590\n",
      "Ep:37, loss:0.00003, loss_test:0.08443, lr:9.51e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.535, tt:5606.313\n",
      "Ep:38, loss:0.00002, loss_test:0.08310, lr:9.41e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.510, tt:5752.888\n",
      "Ep:39, loss:0.00002, loss_test:0.08282, lr:9.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.550, tt:5902.016\n",
      "Ep:40, loss:0.00002, loss_test:0.08448, lr:9.23e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.554, tt:6049.707\n",
      "Ep:41, loss:0.00002, loss_test:0.08385, lr:9.14e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.558, tt:6197.431\n",
      "Ep:42, loss:0.00002, loss_test:0.08298, lr:9.04e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.569, tt:6345.469\n",
      "Ep:43, loss:0.00002, loss_test:0.08331, lr:8.95e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.621, tt:6495.344\n",
      "Ep:44, loss:0.00002, loss_test:0.08466, lr:8.86e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.657, tt:6644.567\n",
      "Ep:45, loss:0.00002, loss_test:0.08450, lr:8.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.718, tt:6795.046\n",
      "Ep:46, loss:0.00001, loss_test:0.08372, lr:8.69e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.631, tt:6938.645\n",
      "Ep:47, loss:0.00001, loss_test:0.08444, lr:8.60e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.629, tt:7086.189\n",
      "Ep:48, loss:0.00001, loss_test:0.08501, lr:8.51e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.594, tt:7232.092\n",
      "Ep:49, loss:0.00001, loss_test:0.08524, lr:8.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.624, tt:7381.200\n",
      "Ep:50, loss:0.00001, loss_test:0.08322, lr:8.35e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.635, tt:7529.407\n",
      "Ep:51, loss:0.00001, loss_test:0.08440, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.638, tt:7677.186\n",
      "Ep:52, loss:0.00001, loss_test:0.08460, lr:8.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.677, tt:7826.865\n",
      "Ep:53, loss:0.00001, loss_test:0.08385, lr:8.10e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.725, tt:7977.145\n",
      "Ep:54, loss:0.00001, loss_test:0.08528, lr:8.02e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.734, tt:8125.368\n",
      "Ep:55, loss:0.00001, loss_test:0.08514, lr:7.94e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.737, tt:8273.252\n",
      "Ep:56, loss:0.00001, loss_test:0.08571, lr:7.86e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.731, tt:8420.691\n",
      "Ep:57, loss:0.00001, loss_test:0.08409, lr:7.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.733, tt:8568.487\n",
      "Ep:58, loss:0.00001, loss_test:0.08547, lr:7.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.717, tt:8715.314\n",
      "Ep:59, loss:0.00001, loss_test:0.08539, lr:7.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:147.655, tt:8859.301\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00383, loss_test:0.09935, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:550.764, tt:550.764\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00246, loss_test:0.08537, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:555.245, tt:1110.489\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00165, loss_test:0.07942, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:559.256, tt:1677.768\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00113, loss_test:0.07428, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:558.400, tt:2233.602\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00079, loss_test:0.07494, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:560.729, tt:2803.646\n",
      "Ep:5, loss:0.00055, loss_test:0.07513, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:561.645, tt:3369.873\n",
      "Ep:6, loss:0.00039, loss_test:0.07913, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:562.693, tt:3938.848\n",
      "Ep:7, loss:0.00030, loss_test:0.07865, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:563.499, tt:4507.991\n",
      "Ep:8, loss:0.00022, loss_test:0.08308, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:564.107, tt:5076.959\n",
      "Ep:9, loss:0.00017, loss_test:0.08309, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:564.076, tt:5640.758\n",
      "Ep:10, loss:0.00013, loss_test:0.08590, lr:1.00e-02, fs:0.81657 (r=0.697,p=0.986),  time:564.415, tt:6208.566\n",
      "Ep:11, loss:0.00011, loss_test:0.08956, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:564.900, tt:6778.801\n",
      "Ep:12, loss:0.00008, loss_test:0.09260, lr:1.00e-02, fs:0.81657 (r=0.697,p=0.986),  time:565.142, tt:7346.844\n",
      "Ep:13, loss:0.00006, loss_test:0.09327, lr:1.00e-02, fs:0.81176 (r=0.697,p=0.972),  time:564.600, tt:7904.395\n",
      "Ep:14, loss:0.00005, loss_test:0.09151, lr:1.00e-02, fs:0.81176 (r=0.697,p=0.972),  time:564.538, tt:8468.063\n",
      "Ep:15, loss:0.00004, loss_test:0.09161, lr:9.90e-03, fs:0.81657 (r=0.697,p=0.986),  time:564.295, tt:9028.722\n",
      "Ep:16, loss:0.00003, loss_test:0.09112, lr:9.80e-03, fs:0.81657 (r=0.697,p=0.986),  time:563.769, tt:9584.066\n",
      "Ep:17, loss:0.00003, loss_test:0.09165, lr:9.70e-03, fs:0.81657 (r=0.697,p=0.986),  time:563.279, tt:10139.021\n",
      "Ep:18, loss:0.00002, loss_test:0.09200, lr:9.61e-03, fs:0.81657 (r=0.697,p=0.986),  time:562.742, tt:10692.104\n",
      "Ep:19, loss:0.00002, loss_test:0.09186, lr:9.51e-03, fs:0.81176 (r=0.697,p=0.972),  time:562.281, tt:11245.621\n",
      "Ep:20, loss:0.00002, loss_test:0.09161, lr:9.41e-03, fs:0.81657 (r=0.697,p=0.986),  time:562.127, tt:11804.660\n",
      "Ep:21, loss:0.00002, loss_test:0.09123, lr:9.32e-03, fs:0.81657 (r=0.697,p=0.986),  time:561.948, tt:12362.860\n",
      "Ep:22, loss:0.00001, loss_test:0.09179, lr:9.23e-03, fs:0.81657 (r=0.697,p=0.986),  time:562.124, tt:12928.855\n",
      "Ep:23, loss:0.00001, loss_test:0.09178, lr:9.14e-03, fs:0.80240 (r=0.677,p=0.985),  time:561.763, tt:13482.318\n",
      "Ep:24, loss:0.00001, loss_test:0.09273, lr:9.04e-03, fs:0.78049 (r=0.646,p=0.985),  time:561.841, tt:14046.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00001, loss_test:0.09190, lr:8.95e-03, fs:0.78049 (r=0.646,p=0.985),  time:561.582, tt:14601.144\n",
      "Ep:26, loss:0.00001, loss_test:0.09142, lr:8.86e-03, fs:0.78049 (r=0.646,p=0.985),  time:561.410, tt:15158.075\n",
      "Ep:27, loss:0.00001, loss_test:0.09187, lr:8.78e-03, fs:0.78049 (r=0.646,p=0.985),  time:560.795, tt:15702.272\n",
      "Ep:28, loss:0.00001, loss_test:0.09088, lr:8.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:560.583, tt:16256.902\n",
      "Ep:29, loss:0.00001, loss_test:0.09127, lr:8.60e-03, fs:0.78049 (r=0.646,p=0.985),  time:559.605, tt:16788.162\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00369, loss_test:0.12391, lr:1.00e-02, fs:0.59091 (r=0.525,p=0.675),  time:547.224, tt:547.224\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00231, loss_test:0.11852, lr:1.00e-02, fs:0.67879 (r=0.566,p=0.848),  time:555.854, tt:1111.708\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00158, loss_test:0.12279, lr:1.00e-02, fs:0.64968 (r=0.515,p=0.879),  time:554.062, tt:1662.185\n",
      "Ep:3, loss:0.00113, loss_test:0.12972, lr:1.00e-02, fs:0.66667 (r=0.525,p=0.912),  time:551.015, tt:2204.060\n",
      "Ep:4, loss:0.00084, loss_test:0.13412, lr:1.00e-02, fs:0.62667 (r=0.475,p=0.922),  time:551.840, tt:2759.199\n",
      "Ep:5, loss:0.00063, loss_test:0.13839, lr:1.00e-02, fs:0.61111 (r=0.444,p=0.978),  time:554.572, tt:3327.430\n",
      "Ep:6, loss:0.00046, loss_test:0.13937, lr:1.00e-02, fs:0.61538 (r=0.444,p=1.000),  time:555.204, tt:3886.429\n",
      "Ep:7, loss:0.00034, loss_test:0.14758, lr:1.00e-02, fs:0.61111 (r=0.444,p=0.978),  time:554.541, tt:4436.328\n",
      "Ep:8, loss:0.00026, loss_test:0.15069, lr:1.00e-02, fs:0.61538 (r=0.444,p=1.000),  time:553.754, tt:4983.787\n",
      "Ep:9, loss:0.00020, loss_test:0.15340, lr:1.00e-02, fs:0.61538 (r=0.444,p=1.000),  time:553.223, tt:5532.227\n",
      "Ep:10, loss:0.00016, loss_test:0.15852, lr:1.00e-02, fs:0.50000 (r=0.333,p=1.000),  time:552.151, tt:6073.666\n",
      "Ep:11, loss:0.00013, loss_test:0.15835, lr:1.00e-02, fs:0.57554 (r=0.404,p=1.000),  time:551.854, tt:6622.249\n",
      "Ep:12, loss:0.00010, loss_test:0.16108, lr:1.00e-02, fs:0.45313 (r=0.293,p=1.000),  time:551.368, tt:7167.784\n",
      "Ep:13, loss:0.00009, loss_test:0.15963, lr:9.90e-03, fs:0.53333 (r=0.364,p=1.000),  time:551.229, tt:7717.202\n",
      "Ep:14, loss:0.00007, loss_test:0.16130, lr:9.80e-03, fs:0.53333 (r=0.364,p=1.000),  time:551.304, tt:8269.562\n",
      "Ep:15, loss:0.00005, loss_test:0.16271, lr:9.70e-03, fs:0.45313 (r=0.293,p=1.000),  time:550.857, tt:8813.709\n",
      "Ep:16, loss:0.00004, loss_test:0.16151, lr:9.61e-03, fs:0.45313 (r=0.293,p=1.000),  time:550.628, tt:9360.672\n",
      "Ep:17, loss:0.00004, loss_test:0.16181, lr:9.51e-03, fs:0.45313 (r=0.293,p=1.000),  time:550.446, tt:9908.020\n",
      "Ep:18, loss:0.00003, loss_test:0.16508, lr:9.41e-03, fs:0.45313 (r=0.293,p=1.000),  time:550.243, tt:10454.623\n",
      "Ep:19, loss:0.00003, loss_test:0.16399, lr:9.32e-03, fs:0.45313 (r=0.293,p=1.000),  time:550.428, tt:11008.565\n",
      "Ep:20, loss:0.00002, loss_test:0.16319, lr:9.23e-03, fs:0.45313 (r=0.293,p=1.000),  time:550.132, tt:11552.777\n",
      "Ep:21, loss:0.00002, loss_test:0.16463, lr:9.14e-03, fs:0.45313 (r=0.293,p=1.000),  time:549.627, tt:12091.784\n",
      "Ep:22, loss:0.00002, loss_test:0.16317, lr:9.04e-03, fs:0.44961 (r=0.293,p=0.967),  time:549.391, tt:12635.992\n",
      "Ep:23, loss:0.00002, loss_test:0.16303, lr:8.95e-03, fs:0.44961 (r=0.293,p=0.967),  time:549.515, tt:13188.353\n",
      "Ep:24, loss:0.00002, loss_test:0.16303, lr:8.86e-03, fs:0.44961 (r=0.293,p=0.967),  time:549.517, tt:13737.935\n",
      "Ep:25, loss:0.00001, loss_test:0.16300, lr:8.78e-03, fs:0.44961 (r=0.293,p=0.967),  time:549.397, tt:14284.322\n",
      "Ep:26, loss:0.00001, loss_test:0.16242, lr:8.69e-03, fs:0.44961 (r=0.293,p=0.967),  time:549.091, tt:14825.455\n",
      "Ep:27, loss:0.00001, loss_test:0.16186, lr:8.60e-03, fs:0.44961 (r=0.293,p=0.967),  time:548.896, tt:15369.091\n",
      "Ep:28, loss:0.00001, loss_test:0.16119, lr:8.51e-03, fs:0.44961 (r=0.293,p=0.967),  time:548.636, tt:15910.434\n",
      "Ep:29, loss:0.00001, loss_test:0.16074, lr:8.43e-03, fs:0.44961 (r=0.293,p=0.967),  time:546.022, tt:16380.669\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,6,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,80,cv_number,8,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,10,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,0,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 6\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14520, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.739, tt:13.739\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14460, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.399, tt:26.798\n",
      "Ep:2, loss:0.00028, loss_test:0.14355, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.599, tt:43.797\n",
      "Ep:3, loss:0.00027, loss_test:0.14188, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.030, tt:64.121\n",
      "Ep:4, loss:0.00027, loss_test:0.13912, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:18.184, tt:90.920\n",
      "Ep:5, loss:0.00026, loss_test:0.13432, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:19.525, tt:117.152\n",
      "Ep:6, loss:0.00025, loss_test:0.12766, lr:1.00e-02, fs:0.64567 (r=0.828,p=0.529),  time:20.710, tt:144.967\n",
      "Ep:7, loss:0.00023, loss_test:0.12380, lr:1.00e-02, fs:0.63111 (r=0.717,p=0.563),  time:21.548, tt:172.387\n",
      "Ep:8, loss:0.00022, loss_test:0.12122, lr:1.00e-02, fs:0.65025 (r=0.667,p=0.635),  time:22.259, tt:200.334\n",
      "Ep:9, loss:0.00022, loss_test:0.11824, lr:1.00e-02, fs:0.65049 (r=0.677,p=0.626),  time:22.810, tt:228.105\n",
      "Ep:10, loss:0.00021, loss_test:0.11599, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:23.113, tt:254.240\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11355, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:23.337, tt:280.040\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10942, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:23.676, tt:307.785\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10645, lr:1.00e-02, fs:0.68718 (r=0.677,p=0.698),  time:23.896, tt:334.550\n",
      "Ep:14, loss:0.00019, loss_test:0.10487, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:24.242, tt:363.628\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10360, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:24.396, tt:390.331\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10157, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:24.583, tt:417.908\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09977, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:24.671, tt:444.070\n",
      "Ep:18, loss:0.00017, loss_test:0.09825, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:24.910, tt:473.290\n",
      "Ep:19, loss:0.00016, loss_test:0.09708, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:25.075, tt:501.501\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09561, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:25.131, tt:527.742\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09436, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:25.208, tt:554.571\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09294, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:25.319, tt:582.345\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09201, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:25.312, tt:607.497\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09111, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:25.373, tt:634.313\n",
      "Ep:25, loss:0.00014, loss_test:0.09045, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:25.454, tt:661.802\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08965, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.460, tt:687.422\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08908, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:25.533, tt:714.916\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08889, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.598, tt:742.344\n",
      "Ep:29, loss:0.00013, loss_test:0.08872, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:25.639, tt:769.159\n",
      "Ep:30, loss:0.00013, loss_test:0.08817, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:25.618, tt:794.146\n",
      "Ep:31, loss:0.00012, loss_test:0.08733, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:25.726, tt:823.229\n",
      "Ep:32, loss:0.00012, loss_test:0.08656, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:25.810, tt:851.726\n",
      "Ep:33, loss:0.00012, loss_test:0.08605, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:25.871, tt:879.606\n",
      "Ep:34, loss:0.00011, loss_test:0.08540, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:25.943, tt:908.001\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.08449, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:25.996, tt:935.854\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08403, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:26.068, tt:964.504\n",
      "Ep:37, loss:0.00011, loss_test:0.08354, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:26.115, tt:992.380\n",
      "Ep:38, loss:0.00010, loss_test:0.08271, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:26.169, tt:1020.572\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.08255, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:26.250, tt:1049.991\n",
      "Ep:40, loss:0.00010, loss_test:0.08245, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:26.327, tt:1079.413\n",
      "Ep:41, loss:0.00010, loss_test:0.08210, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:26.387, tt:1108.244\n",
      "Ep:42, loss:0.00010, loss_test:0.08177, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:26.443, tt:1137.028\n",
      "Ep:43, loss:0.00009, loss_test:0.08125, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:26.496, tt:1165.804\n",
      "Ep:44, loss:0.00009, loss_test:0.08097, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:26.518, tt:1193.299\n",
      "Ep:45, loss:0.00009, loss_test:0.08042, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:26.568, tt:1222.118\n",
      "Ep:46, loss:0.00009, loss_test:0.08000, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:26.592, tt:1249.803\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.07959, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:26.600, tt:1276.778\n",
      "Ep:48, loss:0.00008, loss_test:0.07993, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:26.627, tt:1304.721\n",
      "Ep:49, loss:0.00008, loss_test:0.07997, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:26.654, tt:1332.724\n",
      "Ep:50, loss:0.00008, loss_test:0.07985, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:26.664, tt:1359.876\n",
      "Ep:51, loss:0.00008, loss_test:0.07895, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:26.693, tt:1388.038\n",
      "Ep:52, loss:0.00008, loss_test:0.07839, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:26.710, tt:1415.634\n",
      "Ep:53, loss:0.00008, loss_test:0.07963, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:26.754, tt:1444.701\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07836, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:26.781, tt:1472.979\n",
      "Ep:55, loss:0.00007, loss_test:0.07801, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:26.799, tt:1500.755\n",
      "Ep:56, loss:0.00007, loss_test:0.07859, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:26.820, tt:1528.758\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.07803, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:26.853, tt:1557.479\n",
      "Ep:58, loss:0.00007, loss_test:0.07796, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:26.874, tt:1585.578\n",
      "Ep:59, loss:0.00007, loss_test:0.07713, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:26.904, tt:1614.262\n",
      "Ep:60, loss:0.00006, loss_test:0.07788, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:26.902, tt:1641.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.07780, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:26.920, tt:1669.045\n",
      "Ep:62, loss:0.00006, loss_test:0.07722, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:26.951, tt:1697.944\n",
      "Ep:63, loss:0.00006, loss_test:0.07709, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:26.969, tt:1725.996\n",
      "Ep:64, loss:0.00006, loss_test:0.07729, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:26.991, tt:1754.395\n",
      "Ep:65, loss:0.00006, loss_test:0.07751, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:27.017, tt:1783.122\n",
      "Ep:66, loss:0.00006, loss_test:0.07761, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:27.039, tt:1811.638\n",
      "Ep:67, loss:0.00006, loss_test:0.07668, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:27.079, tt:1841.355\n",
      "Ep:68, loss:0.00005, loss_test:0.07767, lr:9.90e-03, fs:0.80423 (r=0.768,p=0.844),  time:27.101, tt:1869.969\n",
      "Ep:69, loss:0.00005, loss_test:0.07639, lr:9.80e-03, fs:0.80423 (r=0.768,p=0.844),  time:27.115, tt:1898.060\n",
      "Ep:70, loss:0.00005, loss_test:0.07701, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:27.122, tt:1925.678\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00005, loss_test:0.07597, lr:9.70e-03, fs:0.80628 (r=0.778,p=0.837),  time:27.135, tt:1953.715\n",
      "Ep:72, loss:0.00005, loss_test:0.07755, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:27.148, tt:1981.797\n",
      "Ep:73, loss:0.00005, loss_test:0.07741, lr:9.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:27.162, tt:2009.981\n",
      "Ep:74, loss:0.00005, loss_test:0.07614, lr:9.70e-03, fs:0.80000 (r=0.768,p=0.835),  time:27.162, tt:2037.184\n",
      "Ep:75, loss:0.00005, loss_test:0.07704, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:27.161, tt:2064.268\n",
      "Ep:76, loss:0.00005, loss_test:0.07516, lr:9.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:27.185, tt:2093.249\n",
      "Ep:77, loss:0.00004, loss_test:0.07688, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:27.197, tt:2121.331\n",
      "Ep:78, loss:0.00004, loss_test:0.07595, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:27.196, tt:2148.522\n",
      "Ep:79, loss:0.00004, loss_test:0.07593, lr:9.70e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.208, tt:2176.674\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00004, loss_test:0.07653, lr:9.70e-03, fs:0.80214 (r=0.758,p=0.852),  time:27.213, tt:2204.215\n",
      "Ep:81, loss:0.00004, loss_test:0.07583, lr:9.70e-03, fs:0.81522 (r=0.758,p=0.882),  time:27.237, tt:2233.398\n",
      "Ep:82, loss:0.00004, loss_test:0.07779, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.269, tt:2263.326\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00004, loss_test:0.07689, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:27.277, tt:2291.226\n",
      "Ep:84, loss:0.00004, loss_test:0.07547, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:27.276, tt:2318.498\n",
      "Ep:85, loss:0.00004, loss_test:0.07738, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.296, tt:2347.486\n",
      "Ep:86, loss:0.00004, loss_test:0.07518, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:27.294, tt:2374.621\n",
      "Ep:87, loss:0.00004, loss_test:0.07714, lr:9.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.301, tt:2402.452\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00004, loss_test:0.07621, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.308, tt:2430.404\n",
      "Ep:89, loss:0.00004, loss_test:0.07640, lr:9.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.297, tt:2456.722\n",
      "Ep:90, loss:0.00003, loss_test:0.07716, lr:9.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.296, tt:2483.905\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00003, loss_test:0.07500, lr:9.70e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.317, tt:2513.124\n",
      "Ep:92, loss:0.00003, loss_test:0.07762, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.331, tt:2541.752\n",
      "Ep:93, loss:0.00003, loss_test:0.07561, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:27.328, tt:2568.863\n",
      "Ep:94, loss:0.00003, loss_test:0.07687, lr:9.70e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.346, tt:2597.846\n",
      "Ep:95, loss:0.00003, loss_test:0.07550, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.341, tt:2624.718\n",
      "Ep:96, loss:0.00003, loss_test:0.07754, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.346, tt:2652.589\n",
      "Ep:97, loss:0.00003, loss_test:0.07673, lr:9.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.343, tt:2679.588\n",
      "Ep:98, loss:0.00003, loss_test:0.07665, lr:9.70e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.339, tt:2706.603\n",
      "Ep:99, loss:0.00003, loss_test:0.07811, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.345, tt:2734.487\n",
      "Ep:100, loss:0.00003, loss_test:0.07523, lr:9.70e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.341, tt:2761.406\n",
      "Ep:101, loss:0.00003, loss_test:0.07878, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.331, tt:2787.768\n",
      "Ep:102, loss:0.00003, loss_test:0.07464, lr:9.61e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.329, tt:2814.920\n",
      "Ep:103, loss:0.00003, loss_test:0.07834, lr:9.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.333, tt:2842.599\n",
      "Ep:104, loss:0.00003, loss_test:0.07596, lr:9.41e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.339, tt:2870.638\n",
      "Ep:105, loss:0.00003, loss_test:0.07763, lr:9.32e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.327, tt:2896.673\n",
      "Ep:106, loss:0.00003, loss_test:0.07648, lr:9.23e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.318, tt:2923.073\n",
      "Ep:107, loss:0.00002, loss_test:0.07541, lr:9.14e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.322, tt:2950.732\n",
      "Ep:108, loss:0.00002, loss_test:0.07807, lr:9.04e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.327, tt:2978.672\n",
      "Ep:109, loss:0.00002, loss_test:0.07557, lr:8.95e-03, fs:0.81967 (r=0.758,p=0.893),  time:27.336, tt:3006.985\n",
      "Ep:110, loss:0.00002, loss_test:0.07774, lr:8.86e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.328, tt:3033.386\n",
      "Ep:111, loss:0.00002, loss_test:0.07590, lr:8.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:27.327, tt:3060.573\n",
      "Ep:112, loss:0.00002, loss_test:0.07652, lr:8.69e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.335, tt:3088.856\n",
      "Ep:113, loss:0.00002, loss_test:0.07700, lr:8.60e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.340, tt:3116.783\n",
      "Ep:114, loss:0.00002, loss_test:0.07775, lr:8.51e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.369, tt:3147.414\n",
      "Ep:115, loss:0.00002, loss_test:0.07603, lr:8.43e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.394, tt:3177.713\n",
      "Ep:116, loss:0.00002, loss_test:0.07751, lr:8.35e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.431, tt:3209.420\n",
      "Ep:117, loss:0.00002, loss_test:0.07735, lr:8.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.481, tt:3242.713\n",
      "Ep:118, loss:0.00002, loss_test:0.07562, lr:8.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.517, tt:3274.473\n",
      "Ep:119, loss:0.00002, loss_test:0.07797, lr:8.10e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.555, tt:3306.608\n",
      "Ep:120, loss:0.00002, loss_test:0.07596, lr:8.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.597, tt:3339.267\n",
      "Ep:121, loss:0.00002, loss_test:0.07651, lr:7.94e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.625, tt:3370.206\n",
      "Ep:122, loss:0.00002, loss_test:0.07702, lr:7.86e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.658, tt:3401.917\n",
      "Ep:123, loss:0.00002, loss_test:0.07648, lr:7.78e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.683, tt:3432.708\n",
      "Ep:124, loss:0.00002, loss_test:0.07708, lr:7.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.715, tt:3464.408\n",
      "Ep:125, loss:0.00002, loss_test:0.07589, lr:7.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.732, tt:3494.252\n",
      "Ep:126, loss:0.00002, loss_test:0.07828, lr:7.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.765, tt:3526.163\n",
      "Ep:127, loss:0.00002, loss_test:0.07628, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.792, tt:3557.342\n",
      "Ep:128, loss:0.00002, loss_test:0.07720, lr:7.40e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.810, tt:3587.479\n",
      "Ep:129, loss:0.00002, loss_test:0.07681, lr:7.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.833, tt:3618.318\n",
      "Ep:130, loss:0.00002, loss_test:0.07703, lr:7.25e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.871, tt:3651.050\n",
      "Ep:131, loss:0.00002, loss_test:0.07746, lr:7.18e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.888, tt:3681.231\n",
      "Ep:132, loss:0.00002, loss_test:0.07667, lr:7.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:27.889, tt:3709.217\n",
      "Ep:133, loss:0.00002, loss_test:0.07812, lr:7.03e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.917, tt:3740.916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.07738, lr:6.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.937, tt:3771.471\n",
      "Ep:135, loss:0.00002, loss_test:0.07632, lr:6.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.960, tt:3802.549\n",
      "Ep:136, loss:0.00002, loss_test:0.07783, lr:6.83e-03, fs:0.82873 (r=0.758,p=0.915),  time:27.985, tt:3833.995\n",
      "Ep:137, loss:0.00002, loss_test:0.07750, lr:6.76e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.988, tt:3862.326\n",
      "Ep:138, loss:0.00002, loss_test:0.07659, lr:6.69e-03, fs:0.82873 (r=0.758,p=0.915),  time:28.014, tt:3894.001\n",
      "Ep:139, loss:0.00002, loss_test:0.07761, lr:6.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:28.032, tt:3924.485\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 7\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14511, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.488, tt:29.488\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14455, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.323, tt:60.645\n",
      "Ep:2, loss:0.00028, loss_test:0.14364, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.267, tt:90.801\n",
      "Ep:3, loss:0.00028, loss_test:0.14218, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.796, tt:119.185\n",
      "Ep:4, loss:0.00027, loss_test:0.13976, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.752, tt:143.760\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.13601, lr:1.00e-02, fs:0.67832 (r=0.980,p=0.519),  time:29.231, tt:175.386\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.13120, lr:1.00e-02, fs:0.66667 (r=0.879,p=0.537),  time:29.729, tt:208.100\n",
      "Ep:7, loss:0.00024, loss_test:0.12803, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:30.086, tt:240.687\n",
      "Ep:8, loss:0.00023, loss_test:0.12633, lr:1.00e-02, fs:0.60697 (r=0.616,p=0.598),  time:30.326, tt:272.934\n",
      "Ep:9, loss:0.00022, loss_test:0.12389, lr:1.00e-02, fs:0.63366 (r=0.646,p=0.621),  time:30.453, tt:304.526\n",
      "Ep:10, loss:0.00022, loss_test:0.12163, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:30.692, tt:337.617\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11958, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:30.876, tt:370.510\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.11571, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:30.915, tt:401.895\n",
      "Ep:13, loss:0.00020, loss_test:0.11278, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:30.988, tt:433.833\n",
      "Ep:14, loss:0.00019, loss_test:0.11073, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:31.111, tt:466.664\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10821, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:31.121, tt:497.934\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10540, lr:1.00e-02, fs:0.69841 (r=0.667,p=0.733),  time:31.205, tt:530.487\n",
      "Ep:17, loss:0.00018, loss_test:0.10390, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:31.231, tt:562.155\n",
      "Ep:18, loss:0.00017, loss_test:0.10308, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:31.330, tt:595.270\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10174, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:31.350, tt:627.008\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10049, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:31.344, tt:658.215\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09906, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:31.438, tt:691.636\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09780, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:31.523, tt:725.040\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09682, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:31.536, tt:756.858\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09606, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:31.571, tt:789.264\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09518, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:31.589, tt:821.314\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09419, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:31.669, tt:855.055\n",
      "Ep:27, loss:0.00014, loss_test:0.09357, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:31.696, tt:887.487\n",
      "Ep:28, loss:0.00013, loss_test:0.09285, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.739, tt:920.431\n",
      "Ep:29, loss:0.00013, loss_test:0.09279, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:31.735, tt:952.050\n",
      "Ep:30, loss:0.00013, loss_test:0.09194, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:31.739, tt:983.909\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09133, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:31.777, tt:1016.850\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.09080, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:31.795, tt:1049.251\n",
      "Ep:33, loss:0.00012, loss_test:0.09007, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.814, tt:1081.673\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08926, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.790, tt:1112.664\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.08839, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.773, tt:1143.818\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08707, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:31.735, tt:1174.203\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08648, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.762, tt:1206.960\n",
      "Ep:38, loss:0.00011, loss_test:0.08542, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:31.718, tt:1237.011\n",
      "Ep:39, loss:0.00010, loss_test:0.08604, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:31.717, tt:1268.675\n",
      "Ep:40, loss:0.00010, loss_test:0.08460, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:31.735, tt:1301.119\n",
      "Ep:41, loss:0.00010, loss_test:0.08451, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.747, tt:1333.386\n",
      "Ep:42, loss:0.00010, loss_test:0.08319, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:31.770, tt:1366.115\n",
      "Ep:43, loss:0.00010, loss_test:0.08374, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:31.784, tt:1398.481\n",
      "Ep:44, loss:0.00009, loss_test:0.08293, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.803, tt:1431.148\n",
      "Ep:45, loss:0.00009, loss_test:0.08208, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:31.779, tt:1461.855\n",
      "Ep:46, loss:0.00009, loss_test:0.08218, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:31.795, tt:1494.382\n",
      "Ep:47, loss:0.00009, loss_test:0.08111, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:31.794, tt:1526.122\n",
      "Ep:48, loss:0.00009, loss_test:0.08230, lr:9.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.802, tt:1558.314\n",
      "Ep:49, loss:0.00008, loss_test:0.08091, lr:9.80e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.816, tt:1590.806\n",
      "Ep:50, loss:0.00008, loss_test:0.08159, lr:9.70e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.824, tt:1623.045\n",
      "Ep:51, loss:0.00008, loss_test:0.08039, lr:9.61e-03, fs:0.88205 (r=0.869,p=0.896),  time:31.830, tt:1655.141\n",
      "Ep:52, loss:0.00008, loss_test:0.08135, lr:9.51e-03, fs:0.84324 (r=0.788,p=0.907),  time:31.830, tt:1686.992\n",
      "Ep:53, loss:0.00008, loss_test:0.08175, lr:9.41e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.842, tt:1719.475\n",
      "Ep:54, loss:0.00008, loss_test:0.07982, lr:9.32e-03, fs:0.87310 (r=0.869,p=0.878),  time:31.821, tt:1750.138\n",
      "Ep:55, loss:0.00007, loss_test:0.08186, lr:9.23e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.809, tt:1781.293\n",
      "Ep:56, loss:0.00007, loss_test:0.07934, lr:9.14e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.818, tt:1813.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00007, loss_test:0.07946, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:31.833, tt:1846.308\n",
      "Ep:58, loss:0.00007, loss_test:0.08087, lr:8.95e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.818, tt:1877.284\n",
      "Ep:59, loss:0.00007, loss_test:0.07904, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:31.817, tt:1909.035\n",
      "Ep:60, loss:0.00007, loss_test:0.08081, lr:8.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.816, tt:1940.782\n",
      "Ep:61, loss:0.00007, loss_test:0.07937, lr:8.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.821, tt:1972.901\n",
      "Ep:62, loss:0.00006, loss_test:0.07933, lr:8.60e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.838, tt:2005.800\n",
      "Ep:63, loss:0.00006, loss_test:0.08083, lr:8.51e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.861, tt:2039.124\n",
      "Ep:64, loss:0.00006, loss_test:0.07889, lr:8.43e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.877, tt:2071.979\n",
      "Ep:65, loss:0.00006, loss_test:0.08023, lr:8.35e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.888, tt:2104.578\n",
      "Ep:66, loss:0.00006, loss_test:0.08057, lr:8.26e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.899, tt:2137.206\n",
      "Ep:67, loss:0.00006, loss_test:0.07901, lr:8.18e-03, fs:0.81967 (r=0.758,p=0.893),  time:31.913, tt:2170.117\n",
      "Ep:68, loss:0.00006, loss_test:0.07981, lr:8.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:31.919, tt:2202.428\n",
      "Ep:69, loss:0.00006, loss_test:0.08008, lr:8.02e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.943, tt:2235.979\n",
      "Ep:70, loss:0.00005, loss_test:0.07916, lr:7.94e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.961, tt:2269.251\n",
      "Ep:71, loss:0.00005, loss_test:0.08051, lr:7.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.956, tt:2300.862\n",
      "Ep:72, loss:0.00005, loss_test:0.07882, lr:7.78e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.973, tt:2333.993\n",
      "Ep:73, loss:0.00005, loss_test:0.07977, lr:7.70e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.963, tt:2365.280\n",
      "Ep:74, loss:0.00005, loss_test:0.08038, lr:7.62e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.971, tt:2397.856\n",
      "Ep:75, loss:0.00005, loss_test:0.07910, lr:7.55e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.978, tt:2430.303\n",
      "Ep:76, loss:0.00005, loss_test:0.07933, lr:7.47e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.957, tt:2460.668\n",
      "Ep:77, loss:0.00005, loss_test:0.07925, lr:7.40e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.957, tt:2492.640\n",
      "Ep:78, loss:0.00005, loss_test:0.07935, lr:7.32e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.976, tt:2526.140\n",
      "Ep:79, loss:0.00005, loss_test:0.07949, lr:7.25e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.972, tt:2557.784\n",
      "Ep:80, loss:0.00005, loss_test:0.07947, lr:7.18e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.971, tt:2589.683\n",
      "Ep:81, loss:0.00005, loss_test:0.07925, lr:7.11e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.974, tt:2621.850\n",
      "Ep:82, loss:0.00004, loss_test:0.07901, lr:7.03e-03, fs:0.79775 (r=0.717,p=0.899),  time:31.973, tt:2653.769\n",
      "Ep:83, loss:0.00004, loss_test:0.08057, lr:6.96e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.960, tt:2684.668\n",
      "Ep:84, loss:0.00004, loss_test:0.07875, lr:6.89e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.950, tt:2715.748\n",
      "Ep:85, loss:0.00004, loss_test:0.07892, lr:6.83e-03, fs:0.79775 (r=0.717,p=0.899),  time:31.950, tt:2747.663\n",
      "Ep:86, loss:0.00004, loss_test:0.08042, lr:6.76e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.946, tt:2779.297\n",
      "Ep:87, loss:0.00004, loss_test:0.07870, lr:6.69e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.946, tt:2811.250\n",
      "Ep:88, loss:0.00004, loss_test:0.07927, lr:6.62e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.938, tt:2842.486\n",
      "Ep:89, loss:0.00004, loss_test:0.07854, lr:6.56e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.942, tt:2874.789\n",
      "Ep:90, loss:0.00004, loss_test:0.07938, lr:6.49e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.933, tt:2905.908\n",
      "Ep:91, loss:0.00004, loss_test:0.07871, lr:6.43e-03, fs:0.79096 (r=0.707,p=0.897),  time:31.910, tt:2935.692\n",
      "Ep:92, loss:0.00004, loss_test:0.07933, lr:6.36e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.905, tt:2967.207\n",
      "Ep:93, loss:0.00004, loss_test:0.07875, lr:6.30e-03, fs:0.79330 (r=0.717,p=0.887),  time:31.889, tt:2997.579\n",
      "Ep:94, loss:0.00004, loss_test:0.07899, lr:6.24e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.889, tt:3029.443\n",
      "Ep:95, loss:0.00004, loss_test:0.07999, lr:6.17e-03, fs:0.78161 (r=0.687,p=0.907),  time:31.884, tt:3060.818\n",
      "Ep:96, loss:0.00004, loss_test:0.07811, lr:6.11e-03, fs:0.79330 (r=0.717,p=0.887),  time:31.879, tt:3092.226\n",
      "Ep:97, loss:0.00004, loss_test:0.07967, lr:6.05e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.865, tt:3122.817\n",
      "Ep:98, loss:0.00004, loss_test:0.07894, lr:5.99e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.866, tt:3154.700\n",
      "Ep:99, loss:0.00004, loss_test:0.07851, lr:5.93e-03, fs:0.78652 (r=0.707,p=0.886),  time:31.870, tt:3186.995\n",
      "Ep:100, loss:0.00004, loss_test:0.07919, lr:5.87e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.872, tt:3219.053\n",
      "Ep:101, loss:0.00004, loss_test:0.07891, lr:5.81e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.865, tt:3250.280\n",
      "Ep:102, loss:0.00003, loss_test:0.07902, lr:5.75e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.867, tt:3282.263\n",
      "Ep:103, loss:0.00003, loss_test:0.07874, lr:5.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.864, tt:3313.818\n",
      "Ep:104, loss:0.00003, loss_test:0.07916, lr:5.64e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.879, tt:3347.256\n",
      "Ep:105, loss:0.00003, loss_test:0.07860, lr:5.58e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.887, tt:3380.047\n",
      "Ep:106, loss:0.00003, loss_test:0.07926, lr:5.53e-03, fs:0.78363 (r=0.677,p=0.931),  time:31.903, tt:3413.658\n",
      "Ep:107, loss:0.00003, loss_test:0.07965, lr:5.47e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.913, tt:3446.641\n",
      "Ep:108, loss:0.00003, loss_test:0.07911, lr:5.42e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.918, tt:3479.032\n",
      "Ep:109, loss:0.00003, loss_test:0.07885, lr:5.36e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.908, tt:3509.912\n",
      "Ep:110, loss:0.00003, loss_test:0.07933, lr:5.31e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.908, tt:3541.763\n",
      "Ep:111, loss:0.00003, loss_test:0.07990, lr:5.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.893, tt:3571.969\n",
      "Ep:112, loss:0.00003, loss_test:0.07895, lr:5.20e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.898, tt:3604.484\n",
      "Ep:113, loss:0.00003, loss_test:0.07963, lr:5.15e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.887, tt:3635.152\n",
      "Ep:114, loss:0.00003, loss_test:0.07922, lr:5.10e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.902, tt:3668.735\n",
      "Ep:115, loss:0.00003, loss_test:0.07941, lr:5.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.874, tt:3697.430\n",
      "Ep:116, loss:0.00003, loss_test:0.07952, lr:5.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.882, tt:3730.169\n",
      "Ep:117, loss:0.00003, loss_test:0.07964, lr:4.95e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.893, tt:3763.381\n",
      "Ep:118, loss:0.00003, loss_test:0.07929, lr:4.90e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.878, tt:3793.436\n",
      "Ep:119, loss:0.00003, loss_test:0.07964, lr:4.85e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.860, tt:3823.251\n",
      "Ep:120, loss:0.00003, loss_test:0.07949, lr:4.80e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.845, tt:3853.246\n",
      "Ep:121, loss:0.00003, loss_test:0.07961, lr:4.75e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.844, tt:3884.910\n",
      "Ep:122, loss:0.00003, loss_test:0.07974, lr:4.71e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.843, tt:3916.691\n",
      "Ep:123, loss:0.00003, loss_test:0.07900, lr:4.66e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.851, tt:3949.494\n",
      "Ep:124, loss:0.00003, loss_test:0.08057, lr:4.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.852, tt:3981.438\n",
      "Ep:125, loss:0.00003, loss_test:0.08041, lr:4.57e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.843, tt:4012.214\n",
      "Ep:126, loss:0.00003, loss_test:0.07902, lr:4.52e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.836, tt:4043.171\n",
      "Ep:127, loss:0.00003, loss_test:0.08052, lr:4.48e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.846, tt:4076.263\n",
      "Ep:128, loss:0.00003, loss_test:0.08025, lr:4.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.835, tt:4106.774\n",
      "Ep:129, loss:0.00003, loss_test:0.07961, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.836, tt:4138.633\n",
      "Ep:130, loss:0.00003, loss_test:0.07978, lr:4.34e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.823, tt:4168.787\n",
      "Ep:131, loss:0.00003, loss_test:0.08012, lr:4.30e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.827, tt:4201.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00003, loss_test:0.08025, lr:4.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.837, tt:4234.254\n",
      "Ep:133, loss:0.00003, loss_test:0.07988, lr:4.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.842, tt:4266.873\n",
      "Ep:134, loss:0.00003, loss_test:0.08000, lr:4.17e-03, fs:0.77907 (r=0.677,p=0.918),  time:31.853, tt:4300.105\n",
      "Ep:135, loss:0.00003, loss_test:0.08088, lr:4.13e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.855, tt:4332.313\n",
      "Ep:136, loss:0.00003, loss_test:0.08007, lr:4.09e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.868, tt:4365.917\n",
      "Ep:137, loss:0.00003, loss_test:0.08007, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.850, tt:4395.244\n",
      "Ep:138, loss:0.00003, loss_test:0.08070, lr:4.01e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.827, tt:4423.974\n",
      "Ep:139, loss:0.00002, loss_test:0.08010, lr:3.97e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.784, tt:4449.693\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"7-8\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,140,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00191, loss_test:0.13267, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:198.691, tt:198.691\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00155, loss_test:0.12580, lr:1.00e-02, fs:0.60104 (r=0.586,p=0.617),  time:219.320, tt:438.641\n",
      "Ep:2, loss:0.00128, loss_test:0.12512, lr:1.00e-02, fs:0.58378 (r=0.545,p=0.628),  time:225.824, tt:677.472\n",
      "Ep:3, loss:0.00111, loss_test:0.12094, lr:1.00e-02, fs:0.56471 (r=0.485,p=0.676),  time:227.970, tt:911.879\n",
      "Ep:4, loss:0.00097, loss_test:0.12586, lr:1.00e-02, fs:0.54545 (r=0.424,p=0.764),  time:229.386, tt:1146.930\n",
      "Ep:5, loss:0.00085, loss_test:0.12477, lr:1.00e-02, fs:0.54545 (r=0.424,p=0.764),  time:230.092, tt:1380.553\n",
      "Ep:6, loss:0.00073, loss_test:0.12736, lr:1.00e-02, fs:0.55128 (r=0.434,p=0.754),  time:230.621, tt:1614.344\n",
      "Ep:7, loss:0.00062, loss_test:0.13851, lr:1.00e-02, fs:0.49315 (r=0.364,p=0.766),  time:231.113, tt:1848.907\n",
      "Ep:8, loss:0.00052, loss_test:0.13296, lr:1.00e-02, fs:0.50000 (r=0.364,p=0.800),  time:231.465, tt:2083.184\n",
      "Ep:9, loss:0.00044, loss_test:0.14631, lr:1.00e-02, fs:0.50000 (r=0.354,p=0.854),  time:231.848, tt:2318.475\n",
      "Ep:10, loss:0.00037, loss_test:0.14475, lr:1.00e-02, fs:0.49645 (r=0.354,p=0.833),  time:232.539, tt:2557.931\n",
      "Ep:11, loss:0.00031, loss_test:0.14112, lr:1.00e-02, fs:0.50340 (r=0.374,p=0.771),  time:232.888, tt:2794.662\n",
      "Ep:12, loss:0.00026, loss_test:0.14275, lr:9.90e-03, fs:0.51034 (r=0.374,p=0.804),  time:233.336, tt:3033.371\n",
      "Ep:13, loss:0.00023, loss_test:0.14827, lr:9.80e-03, fs:0.51748 (r=0.374,p=0.841),  time:233.535, tt:3269.488\n",
      "Ep:14, loss:0.00021, loss_test:0.15289, lr:9.70e-03, fs:0.51389 (r=0.374,p=0.822),  time:233.651, tt:3504.758\n",
      "Ep:15, loss:0.00019, loss_test:0.14153, lr:9.61e-03, fs:0.52482 (r=0.374,p=0.881),  time:233.950, tt:3743.193\n",
      "Ep:16, loss:0.00017, loss_test:0.15571, lr:9.51e-03, fs:0.52857 (r=0.374,p=0.902),  time:234.075, tt:3979.277\n",
      "Ep:17, loss:0.00014, loss_test:0.15311, lr:9.41e-03, fs:0.52482 (r=0.374,p=0.881),  time:234.211, tt:4215.796\n",
      "Ep:18, loss:0.00013, loss_test:0.15578, lr:9.32e-03, fs:0.51389 (r=0.374,p=0.822),  time:234.318, tt:4452.046\n",
      "Ep:19, loss:0.00012, loss_test:0.15417, lr:9.23e-03, fs:0.52482 (r=0.374,p=0.881),  time:233.236, tt:4664.729\n",
      "Ep:20, loss:0.00011, loss_test:0.15271, lr:9.14e-03, fs:0.51799 (r=0.364,p=0.900),  time:232.269, tt:4877.641\n",
      "Ep:21, loss:0.00009, loss_test:0.15561, lr:9.04e-03, fs:0.51429 (r=0.364,p=0.878),  time:231.364, tt:5090.000\n",
      "Ep:22, loss:0.00008, loss_test:0.15895, lr:8.95e-03, fs:0.47059 (r=0.323,p=0.865),  time:230.756, tt:5307.381\n",
      "Ep:23, loss:0.00008, loss_test:0.15923, lr:8.86e-03, fs:0.45926 (r=0.313,p=0.861),  time:229.897, tt:5517.536\n",
      "Ep:24, loss:0.00007, loss_test:0.16145, lr:8.78e-03, fs:0.45926 (r=0.313,p=0.861),  time:229.264, tt:5731.591\n",
      "Ep:25, loss:0.00006, loss_test:0.16116, lr:8.69e-03, fs:0.43939 (r=0.293,p=0.879),  time:228.552, tt:5942.348\n",
      "Ep:26, loss:0.00006, loss_test:0.15748, lr:8.60e-03, fs:0.37795 (r=0.242,p=0.857),  time:227.912, tt:6153.612\n",
      "Ep:27, loss:0.00005, loss_test:0.16341, lr:8.51e-03, fs:0.41538 (r=0.273,p=0.871),  time:227.404, tt:6367.323\n",
      "Ep:28, loss:0.00005, loss_test:0.16409, lr:8.43e-03, fs:0.39062 (r=0.253,p=0.862),  time:226.881, tt:6579.550\n",
      "Ep:29, loss:0.00005, loss_test:0.16504, lr:8.35e-03, fs:0.36508 (r=0.232,p=0.852),  time:226.220, tt:6786.590\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=16,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,16,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00096, loss_test:0.13423, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:88.498, tt:88.498\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00088, loss_test:0.11322, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:101.930, tt:203.861\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00079, loss_test:0.10532, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:106.568, tt:319.703\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00072, loss_test:0.09565, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:109.331, tt:437.325\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00066, loss_test:0.09066, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:111.282, tt:556.411\n",
      "Ep:5, loss:0.00061, loss_test:0.08681, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:111.909, tt:671.454\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00056, loss_test:0.08255, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:112.703, tt:788.924\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00053, loss_test:0.07822, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:113.545, tt:908.357\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00049, loss_test:0.07671, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:113.966, tt:1025.691\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00045, loss_test:0.07566, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:114.276, tt:1142.760\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.07048, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:114.400, tt:1258.402\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00038, loss_test:0.06842, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:114.572, tt:1374.860\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00035, loss_test:0.06864, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:114.719, tt:1491.345\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00032, loss_test:0.06554, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:114.708, tt:1605.911\n",
      "Ep:14, loss:0.00029, loss_test:0.06554, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:114.859, tt:1722.890\n",
      "Ep:15, loss:0.00026, loss_test:0.06551, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:114.755, tt:1836.078\n",
      "Ep:16, loss:0.00024, loss_test:0.06135, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:114.759, tt:1950.906\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.06186, lr:1.00e-02, fs:0.86517 (r=0.778,p=0.975),  time:114.909, tt:2068.360\n",
      "Ep:18, loss:0.00020, loss_test:0.06081, lr:1.00e-02, fs:0.87640 (r=0.788,p=0.987),  time:115.066, tt:2186.255\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.06231, lr:1.00e-02, fs:0.83721 (r=0.727,p=0.986),  time:115.236, tt:2304.728\n",
      "Ep:20, loss:0.00017, loss_test:0.06181, lr:1.00e-02, fs:0.87006 (r=0.778,p=0.987),  time:115.199, tt:2419.171\n",
      "Ep:21, loss:0.00015, loss_test:0.06277, lr:1.00e-02, fs:0.84393 (r=0.737,p=0.986),  time:115.210, tt:2534.616\n",
      "Ep:22, loss:0.00014, loss_test:0.06163, lr:1.00e-02, fs:0.85057 (r=0.747,p=0.987),  time:115.375, tt:2653.619\n",
      "Ep:23, loss:0.00013, loss_test:0.05941, lr:1.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:115.408, tt:2769.786\n",
      "Ep:24, loss:0.00012, loss_test:0.06347, lr:1.00e-02, fs:0.84393 (r=0.737,p=0.986),  time:115.472, tt:2886.806\n",
      "Ep:25, loss:0.00011, loss_test:0.06014, lr:1.00e-02, fs:0.84393 (r=0.737,p=0.986),  time:115.518, tt:3003.472\n",
      "Ep:26, loss:0.00010, loss_test:0.06168, lr:1.00e-02, fs:0.84393 (r=0.737,p=0.986),  time:115.564, tt:3120.232\n",
      "Ep:27, loss:0.00009, loss_test:0.06089, lr:1.00e-02, fs:0.85057 (r=0.747,p=0.987),  time:115.612, tt:3237.131\n",
      "Ep:28, loss:0.00008, loss_test:0.06027, lr:1.00e-02, fs:0.84393 (r=0.737,p=0.986),  time:115.761, tt:3357.067\n",
      "Ep:29, loss:0.00008, loss_test:0.06096, lr:1.00e-02, fs:0.84393 (r=0.737,p=0.986),  time:115.783, tt:3473.500\n",
      "Ep:30, loss:0.00007, loss_test:0.06144, lr:9.90e-03, fs:0.84393 (r=0.737,p=0.986),  time:115.843, tt:3591.139\n",
      "Ep:31, loss:0.00007, loss_test:0.06175, lr:9.80e-03, fs:0.84884 (r=0.737,p=1.000),  time:115.868, tt:3707.772\n",
      "Ep:32, loss:0.00006, loss_test:0.06281, lr:9.70e-03, fs:0.84884 (r=0.737,p=1.000),  time:115.935, tt:3825.871\n",
      "Ep:33, loss:0.00006, loss_test:0.06206, lr:9.61e-03, fs:0.84884 (r=0.737,p=1.000),  time:115.870, tt:3939.570\n",
      "Ep:34, loss:0.00006, loss_test:0.06285, lr:9.51e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.829, tt:4054.005\n",
      "Ep:35, loss:0.00005, loss_test:0.06309, lr:9.41e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.917, tt:4173.004\n",
      "Ep:36, loss:0.00005, loss_test:0.06211, lr:9.32e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.935, tt:4289.591\n",
      "Ep:37, loss:0.00005, loss_test:0.06336, lr:9.23e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.943, tt:4405.838\n",
      "Ep:38, loss:0.00005, loss_test:0.06391, lr:9.14e-03, fs:0.83721 (r=0.727,p=0.986),  time:115.949, tt:4522.008\n",
      "Ep:39, loss:0.00004, loss_test:0.06704, lr:9.04e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.886, tt:4635.454\n",
      "Ep:40, loss:0.00004, loss_test:0.06259, lr:8.95e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.899, tt:4751.869\n",
      "Ep:41, loss:0.00004, loss_test:0.06582, lr:8.86e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.851, tt:4865.724\n",
      "Ep:43, loss:0.00003, loss_test:0.06595, lr:8.69e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.773, tt:5094.016\n",
      "Ep:44, loss:0.00003, loss_test:0.06483, lr:8.60e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.736, tt:5208.141\n",
      "Ep:45, loss:0.00003, loss_test:0.06427, lr:8.51e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.706, tt:5322.456\n",
      "Ep:46, loss:0.00003, loss_test:0.06728, lr:8.43e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.720, tt:5438.820\n",
      "Ep:47, loss:0.00003, loss_test:0.06586, lr:8.35e-03, fs:0.84211 (r=0.727,p=1.000),  time:115.755, tt:5556.244\n",
      "Ep:48, loss:0.00003, loss_test:0.06558, lr:8.26e-03, fs:0.83721 (r=0.727,p=0.986),  time:115.791, tt:5673.745\n",
      "Ep:49, loss:0.00003, loss_test:0.06651, lr:8.18e-03, fs:0.83721 (r=0.727,p=0.986),  time:115.677, tt:5783.854\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 4096: \n",
      "Ep:0, loss:0.00007, loss_test:0.14362, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.971, tt:18.971\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.14304, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.176, tt:42.353\n",
      "Ep:2, loss:0.00007, loss_test:0.14213, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.281, tt:72.843\n",
      "Ep:3, loss:0.00007, loss_test:0.14077, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.259, tt:105.038\n",
      "Ep:4, loss:0.00007, loss_test:0.13885, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:27.767, tt:138.835\n",
      "Ep:5, loss:0.00007, loss_test:0.13611, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.049, tt:174.294\n",
      "Ep:6, loss:0.00007, loss_test:0.13216, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:29.442, tt:206.093\n",
      "Ep:7, loss:0.00007, loss_test:0.12661, lr:1.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:29.698, tt:237.585\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00006, loss_test:0.11901, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:29.682, tt:267.141\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00006, loss_test:0.11309, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:29.831, tt:298.307\n",
      "Ep:10, loss:0.00006, loss_test:0.11169, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:30.041, tt:330.450\n",
      "Ep:11, loss:0.00006, loss_test:0.10957, lr:1.00e-02, fs:0.69856 (r=0.737,p=0.664),  time:30.044, tt:360.530\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00006, loss_test:0.10766, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:30.228, tt:392.960\n",
      "Ep:13, loss:0.00006, loss_test:0.10615, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:30.307, tt:424.303\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00005, loss_test:0.10423, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:30.452, tt:456.786\n",
      "Ep:15, loss:0.00005, loss_test:0.10185, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:30.629, tt:490.061\n",
      "Ep:16, loss:0.00005, loss_test:0.09929, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:30.711, tt:522.083\n",
      "Ep:17, loss:0.00005, loss_test:0.09704, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:30.743, tt:553.378\n",
      "Ep:18, loss:0.00005, loss_test:0.09520, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:30.878, tt:586.684\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00005, loss_test:0.09364, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:30.976, tt:619.515\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00005, loss_test:0.09188, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:31.024, tt:651.502\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.09034, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:31.075, tt:683.640\n",
      "Ep:22, loss:0.00004, loss_test:0.08921, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:31.142, tt:716.255\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.08812, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:31.157, tt:747.769\n",
      "Ep:24, loss:0.00004, loss_test:0.08626, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:31.204, tt:780.104\n",
      "Ep:25, loss:0.00004, loss_test:0.08463, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:31.247, tt:812.423\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.08377, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:31.328, tt:845.857\n",
      "Ep:27, loss:0.00004, loss_test:0.08257, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:31.355, tt:877.948\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.08103, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:31.378, tt:909.949\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.08046, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:31.380, tt:941.410\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.07935, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:31.327, tt:971.144\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.07797, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:31.299, tt:1001.577\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00004, loss_test:0.07713, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:31.221, tt:1030.291\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.07639, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:31.134, tt:1058.557\n",
      "Ep:34, loss:0.00003, loss_test:0.07531, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:31.055, tt:1086.922\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.07473, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.919, tt:1113.080\n",
      "Ep:36, loss:0.00003, loss_test:0.07403, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:30.889, tt:1142.901\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.07287, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:30.848, tt:1172.222\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.07269, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:30.780, tt:1200.410\n",
      "Ep:39, loss:0.00003, loss_test:0.07121, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:30.695, tt:1227.782\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.07033, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:30.683, tt:1258.023\n",
      "Ep:41, loss:0.00003, loss_test:0.07006, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.610, tt:1285.624\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.06881, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.584, tt:1315.118\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.06829, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.499, tt:1341.956\n",
      "Ep:44, loss:0.00003, loss_test:0.06765, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.457, tt:1370.556\n",
      "Ep:45, loss:0.00003, loss_test:0.06752, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.440, tt:1400.243\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.06682, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.402, tt:1428.872\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.06641, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.379, tt:1458.188\n",
      "Ep:48, loss:0.00003, loss_test:0.06590, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.346, tt:1486.959\n",
      "Ep:49, loss:0.00002, loss_test:0.06541, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.210, tt:1510.507\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=4096 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 6400 Test samples: 198\n",
      "Train positive samples: 3200 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00099, loss_test:0.14303, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:74.149, tt:74.149\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00094, loss_test:0.13259, lr:1.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:93.875, tt:187.751\n",
      "Ep:2, loss:0.00082, loss_test:0.12330, lr:1.00e-02, fs:0.61538 (r=0.646,p=0.587),  time:101.325, tt:303.974\n",
      "Ep:3, loss:0.00074, loss_test:0.11598, lr:1.00e-02, fs:0.65072 (r=0.687,p=0.618),  time:105.285, tt:421.142\n",
      "Ep:4, loss:0.00068, loss_test:0.10913, lr:1.00e-02, fs:0.66667 (r=0.758,p=0.595),  time:107.332, tt:536.660\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00063, loss_test:0.10324, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:108.849, tt:653.094\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00059, loss_test:0.09781, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:109.719, tt:768.033\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00055, loss_test:0.09281, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:110.297, tt:882.375\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00052, loss_test:0.08862, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:111.073, tt:999.657\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00048, loss_test:0.08614, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:111.337, tt:1113.375\n",
      "Ep:10, loss:0.00045, loss_test:0.08165, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:111.649, tt:1228.139\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.07914, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:111.951, tt:1343.409\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00039, loss_test:0.07596, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:112.128, tt:1457.667\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00036, loss_test:0.07359, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:112.251, tt:1571.509\n",
      "Ep:14, loss:0.00033, loss_test:0.07159, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:112.426, tt:1686.396\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00030, loss_test:0.07118, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:112.642, tt:1802.278\n",
      "Ep:16, loss:0.00028, loss_test:0.06985, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:112.759, tt:1916.911\n",
      "Ep:17, loss:0.00025, loss_test:0.07006, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:112.884, tt:2031.918\n",
      "Ep:18, loss:0.00022, loss_test:0.06555, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:112.967, tt:2146.376\n",
      "Ep:19, loss:0.00020, loss_test:0.06668, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:113.177, tt:2263.537\n",
      "Ep:20, loss:0.00019, loss_test:0.06478, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:113.386, tt:2381.108\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.06189, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:113.471, tt:2496.372\n",
      "Ep:22, loss:0.00016, loss_test:0.05990, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:113.570, tt:2612.117\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.05853, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:113.674, tt:2728.187\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.06000, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:113.657, tt:2841.426\n",
      "Ep:25, loss:0.00012, loss_test:0.05848, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:113.669, tt:2955.382\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.06121, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:113.810, tt:3072.883\n",
      "Ep:27, loss:0.00010, loss_test:0.05992, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:113.839, tt:3187.482\n",
      "Ep:28, loss:0.00009, loss_test:0.05818, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:113.836, tt:3301.249\n",
      "Ep:29, loss:0.00008, loss_test:0.05843, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:113.775, tt:3413.236\n",
      "Ep:30, loss:0.00008, loss_test:0.05786, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:113.884, tt:3530.399\n",
      "Ep:31, loss:0.00007, loss_test:0.05687, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:113.919, tt:3645.410\n",
      "Ep:32, loss:0.00007, loss_test:0.05820, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:113.906, tt:3758.893\n",
      "Ep:33, loss:0.00006, loss_test:0.05646, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:113.960, tt:3874.625\n",
      "Ep:34, loss:0.00006, loss_test:0.05522, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:114.016, tt:3990.552\n",
      "Ep:35, loss:0.00006, loss_test:0.05720, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:113.967, tt:4102.800\n",
      "Ep:36, loss:0.00005, loss_test:0.05640, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:113.999, tt:4217.955\n",
      "Ep:37, loss:0.00005, loss_test:0.05511, lr:9.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:114.075, tt:4334.867\n",
      "Ep:38, loss:0.00005, loss_test:0.05734, lr:9.80e-03, fs:0.88298 (r=0.838,p=0.933),  time:114.145, tt:4451.674\n",
      "Ep:39, loss:0.00004, loss_test:0.05674, lr:9.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:114.212, tt:4568.478\n",
      "Ep:40, loss:0.00004, loss_test:0.05681, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:114.180, tt:4681.369\n",
      "Ep:41, loss:0.00004, loss_test:0.05602, lr:9.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:114.207, tt:4796.702\n",
      "Ep:42, loss:0.00004, loss_test:0.05727, lr:9.41e-03, fs:0.79070 (r=0.687,p=0.932),  time:114.259, tt:4913.149\n",
      "Ep:43, loss:0.00003, loss_test:0.05838, lr:9.32e-03, fs:0.87097 (r=0.818,p=0.931),  time:114.327, tt:5030.388\n",
      "Ep:44, loss:0.00003, loss_test:0.05567, lr:9.23e-03, fs:0.80682 (r=0.717,p=0.922),  time:114.409, tt:5148.399\n",
      "Ep:45, loss:0.00003, loss_test:0.05720, lr:9.14e-03, fs:0.80000 (r=0.707,p=0.921),  time:114.438, tt:5264.167\n",
      "Ep:46, loss:0.00003, loss_test:0.05682, lr:9.04e-03, fs:0.79769 (r=0.697,p=0.932),  time:114.428, tt:5378.102\n",
      "Ep:47, loss:0.00003, loss_test:0.05737, lr:8.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:114.445, tt:5493.374\n",
      "Ep:48, loss:0.00003, loss_test:0.05589, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:114.430, tt:5607.074\n",
      "Ep:49, loss:0.00003, loss_test:0.05812, lr:8.78e-03, fs:0.80233 (r=0.697,p=0.945),  time:114.153, tt:5707.661\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14091, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.501, tt:19.501\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.13943, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.107, tt:44.215\n",
      "Ep:2, loss:0.00014, loss_test:0.13675, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.800, tt:74.401\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00013, loss_test:0.13249, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:26.610, tt:106.439\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00013, loss_test:0.12618, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:28.000, tt:140.001\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00012, loss_test:0.11728, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:28.501, tt:171.008\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00012, loss_test:0.10977, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:29.205, tt:204.438\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00011, loss_test:0.10785, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:29.579, tt:236.628\n",
      "Ep:8, loss:0.00011, loss_test:0.10914, lr:1.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:29.982, tt:269.836\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00011, loss_test:0.10634, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:30.254, tt:302.543\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00010, loss_test:0.10182, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:30.535, tt:335.888\n",
      "Ep:11, loss:0.00010, loss_test:0.10026, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:30.683, tt:368.192\n",
      "Ep:12, loss:0.00010, loss_test:0.10102, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:30.848, tt:401.028\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00009, loss_test:0.09781, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:30.974, tt:433.633\n",
      "Ep:14, loss:0.00009, loss_test:0.09625, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:31.105, tt:466.568\n",
      "Ep:15, loss:0.00009, loss_test:0.09517, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:31.192, tt:499.068\n",
      "Ep:16, loss:0.00008, loss_test:0.09348, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:31.342, tt:532.815\n",
      "Ep:17, loss:0.00008, loss_test:0.09171, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:31.349, tt:564.274\n",
      "Ep:18, loss:0.00008, loss_test:0.09053, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:31.491, tt:598.325\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.08919, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:31.504, tt:630.086\n",
      "Ep:20, loss:0.00007, loss_test:0.08783, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:31.590, tt:663.389\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00007, loss_test:0.08660, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:31.652, tt:696.347\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00007, loss_test:0.08502, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:31.698, tt:729.047\n",
      "Ep:23, loss:0.00007, loss_test:0.08387, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:31.667, tt:760.003\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00007, loss_test:0.08252, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:31.709, tt:792.736\n",
      "Ep:25, loss:0.00007, loss_test:0.08131, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:31.792, tt:826.584\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00006, loss_test:0.08075, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:31.826, tt:859.300\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00006, loss_test:0.07983, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.879, tt:892.614\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00006, loss_test:0.07893, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:31.925, tt:925.815\n",
      "Ep:29, loss:0.00006, loss_test:0.07796, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:31.989, tt:959.662\n",
      "Ep:30, loss:0.00006, loss_test:0.07691, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:32.015, tt:992.456\n",
      "Ep:31, loss:0.00006, loss_test:0.07674, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:32.052, tt:1025.671\n",
      "Ep:32, loss:0.00005, loss_test:0.07556, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:32.087, tt:1058.862\n",
      "Ep:33, loss:0.00005, loss_test:0.07549, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:32.160, tt:1093.425\n",
      "Ep:34, loss:0.00005, loss_test:0.07420, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:32.209, tt:1127.301\n",
      "Ep:35, loss:0.00005, loss_test:0.07444, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:32.229, tt:1160.260\n",
      "Ep:36, loss:0.00005, loss_test:0.07317, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:32.252, tt:1193.305\n",
      "Ep:37, loss:0.00005, loss_test:0.07243, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:32.288, tt:1226.960\n",
      "Ep:38, loss:0.00005, loss_test:0.07219, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:32.302, tt:1259.783\n",
      "Ep:39, loss:0.00004, loss_test:0.07164, lr:9.90e-03, fs:0.78756 (r=0.768,p=0.809),  time:32.317, tt:1292.687\n",
      "Ep:40, loss:0.00004, loss_test:0.07099, lr:9.80e-03, fs:0.78571 (r=0.778,p=0.794),  time:32.342, tt:1326.007\n",
      "Ep:41, loss:0.00004, loss_test:0.07092, lr:9.70e-03, fs:0.79793 (r=0.778,p=0.819),  time:32.350, tt:1358.703\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00004, loss_test:0.07024, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.359, tt:1391.447\n",
      "Ep:43, loss:0.00004, loss_test:0.06970, lr:9.70e-03, fs:0.79793 (r=0.778,p=0.819),  time:32.364, tt:1424.025\n",
      "Ep:44, loss:0.00004, loss_test:0.07054, lr:9.70e-03, fs:0.80000 (r=0.768,p=0.835),  time:32.364, tt:1456.373\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.06881, lr:9.70e-03, fs:0.79167 (r=0.768,p=0.817),  time:32.382, tt:1489.586\n",
      "Ep:46, loss:0.00004, loss_test:0.06961, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.385, tt:1522.113\n",
      "Ep:47, loss:0.00004, loss_test:0.06911, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.391, tt:1554.786\n",
      "Ep:48, loss:0.00004, loss_test:0.06822, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.407, tt:1587.948\n",
      "Ep:49, loss:0.00004, loss_test:0.06941, lr:9.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:32.423, tt:1621.156\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.06762, lr:9.70e-03, fs:0.79793 (r=0.778,p=0.819),  time:32.414, tt:1653.120\n",
      "Ep:51, loss:0.00003, loss_test:0.06989, lr:9.70e-03, fs:0.79787 (r=0.758,p=0.843),  time:32.419, tt:1685.800\n",
      "Ep:52, loss:0.00003, loss_test:0.06680, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.463, tt:1720.547\n",
      "Ep:53, loss:0.00003, loss_test:0.06872, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:32.500, tt:1755.026\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.06826, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:32.548, tt:1790.132\n",
      "Ep:55, loss:0.00003, loss_test:0.06677, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:32.571, tt:1823.967\n",
      "Ep:56, loss:0.00003, loss_test:0.06910, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.604, tt:1858.423\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.06597, lr:9.70e-03, fs:0.81053 (r=0.778,p=0.846),  time:32.626, tt:1892.297\n",
      "Ep:58, loss:0.00003, loss_test:0.06784, lr:9.70e-03, fs:0.81283 (r=0.768,p=0.864),  time:32.640, tt:1925.764\n",
      "Ep:59, loss:0.00003, loss_test:0.06591, lr:9.70e-03, fs:0.81283 (r=0.768,p=0.864),  time:32.682, tt:1960.928\n",
      "Ep:60, loss:0.00003, loss_test:0.06758, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.687, tt:1993.882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.06585, lr:9.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:32.651, tt:2024.393\n",
      "Ep:62, loss:0.00003, loss_test:0.06620, lr:9.70e-03, fs:0.81915 (r=0.778,p=0.865),  time:32.659, tt:2057.520\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.06604, lr:9.70e-03, fs:0.80851 (r=0.768,p=0.854),  time:32.674, tt:2091.133\n",
      "Ep:64, loss:0.00003, loss_test:0.06722, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.688, tt:2124.713\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.06606, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.670, tt:2156.207\n",
      "Ep:66, loss:0.00002, loss_test:0.06601, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.666, tt:2188.643\n",
      "Ep:67, loss:0.00002, loss_test:0.06703, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.683, tt:2222.455\n",
      "Ep:68, loss:0.00002, loss_test:0.06504, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.704, tt:2256.586\n",
      "Ep:69, loss:0.00002, loss_test:0.06707, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.724, tt:2290.650\n",
      "Ep:70, loss:0.00002, loss_test:0.06538, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.723, tt:2323.338\n",
      "Ep:71, loss:0.00002, loss_test:0.06627, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.723, tt:2356.061\n",
      "Ep:72, loss:0.00002, loss_test:0.06628, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.757, tt:2391.268\n",
      "Ep:73, loss:0.00002, loss_test:0.06493, lr:9.70e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.751, tt:2423.583\n",
      "Ep:74, loss:0.00002, loss_test:0.06620, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.735, tt:2455.152\n",
      "Ep:75, loss:0.00002, loss_test:0.06515, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.741, tt:2488.286\n",
      "Ep:76, loss:0.00002, loss_test:0.06579, lr:9.61e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.738, tt:2520.853\n",
      "Ep:77, loss:0.00002, loss_test:0.06547, lr:9.51e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.738, tt:2553.553\n",
      "Ep:78, loss:0.00002, loss_test:0.06551, lr:9.41e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.743, tt:2586.664\n",
      "Ep:79, loss:0.00002, loss_test:0.06615, lr:9.32e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.743, tt:2619.420\n",
      "Ep:80, loss:0.00002, loss_test:0.06508, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:32.742, tt:2652.062\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.06659, lr:9.23e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.749, tt:2685.422\n",
      "Ep:82, loss:0.00002, loss_test:0.06608, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.756, tt:2718.785\n",
      "Ep:83, loss:0.00002, loss_test:0.06488, lr:9.23e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.762, tt:2751.980\n",
      "Ep:84, loss:0.00002, loss_test:0.06734, lr:9.23e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.761, tt:2784.680\n",
      "Ep:85, loss:0.00002, loss_test:0.06451, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.761, tt:2817.403\n",
      "Ep:86, loss:0.00002, loss_test:0.06664, lr:9.23e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.761, tt:2850.166\n",
      "Ep:87, loss:0.00002, loss_test:0.06512, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.763, tt:2883.170\n",
      "Ep:88, loss:0.00002, loss_test:0.06542, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.751, tt:2914.833\n",
      "Ep:89, loss:0.00002, loss_test:0.06734, lr:9.23e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.750, tt:2947.519\n",
      "Ep:90, loss:0.00002, loss_test:0.06498, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.743, tt:2979.582\n",
      "Ep:91, loss:0.00001, loss_test:0.06790, lr:9.23e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.730, tt:3011.138\n",
      "Ep:92, loss:0.00001, loss_test:0.06556, lr:9.14e-03, fs:0.82162 (r=0.768,p=0.884),  time:32.718, tt:3042.817\n",
      "Ep:93, loss:0.00001, loss_test:0.06579, lr:9.04e-03, fs:0.82609 (r=0.768,p=0.894),  time:32.717, tt:3075.428\n",
      "Ep:94, loss:0.00001, loss_test:0.06823, lr:8.95e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.726, tt:3108.999\n",
      "Ep:95, loss:0.00001, loss_test:0.06450, lr:8.86e-03, fs:0.82609 (r=0.768,p=0.894),  time:32.732, tt:3142.251\n",
      "Ep:96, loss:0.00001, loss_test:0.06869, lr:8.78e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.749, tt:3176.663\n",
      "Ep:97, loss:0.00001, loss_test:0.06645, lr:8.69e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.753, tt:3209.770\n",
      "Ep:98, loss:0.00001, loss_test:0.06646, lr:8.60e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.752, tt:3242.444\n",
      "Ep:99, loss:0.00001, loss_test:0.06854, lr:8.51e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.752, tt:3275.179\n",
      "Ep:100, loss:0.00001, loss_test:0.06572, lr:8.43e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.746, tt:3307.307\n",
      "Ep:101, loss:0.00001, loss_test:0.06671, lr:8.35e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.747, tt:3340.150\n",
      "Ep:102, loss:0.00001, loss_test:0.06721, lr:8.26e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.743, tt:3372.504\n",
      "Ep:103, loss:0.00001, loss_test:0.06562, lr:8.18e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.728, tt:3403.763\n",
      "Ep:104, loss:0.00001, loss_test:0.06779, lr:8.10e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.733, tt:3436.979\n",
      "Ep:105, loss:0.00001, loss_test:0.06674, lr:8.02e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.727, tt:3469.046\n",
      "Ep:106, loss:0.00001, loss_test:0.06615, lr:7.94e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.726, tt:3501.674\n",
      "Ep:107, loss:0.00001, loss_test:0.06677, lr:7.86e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.711, tt:3532.825\n",
      "Ep:108, loss:0.00001, loss_test:0.06626, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.718, tt:3566.253\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00001, loss_test:0.06716, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.714, tt:3598.550\n",
      "Ep:110, loss:0.00001, loss_test:0.06612, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.724, tt:3632.324\n",
      "Ep:111, loss:0.00001, loss_test:0.06712, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.723, tt:3664.975\n",
      "Ep:112, loss:0.00001, loss_test:0.06643, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.721, tt:3697.514\n",
      "Ep:113, loss:0.00001, loss_test:0.06710, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.737, tt:3731.999\n",
      "Ep:114, loss:0.00001, loss_test:0.06657, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.739, tt:3765.019\n",
      "Ep:115, loss:0.00001, loss_test:0.06608, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.732, tt:3796.889\n",
      "Ep:116, loss:0.00001, loss_test:0.06675, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.755, tt:3832.341\n",
      "Ep:117, loss:0.00001, loss_test:0.06660, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.760, tt:3865.706\n",
      "Ep:118, loss:0.00001, loss_test:0.06697, lr:7.78e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.762, tt:3898.700\n",
      "Ep:119, loss:0.00001, loss_test:0.06779, lr:7.78e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.766, tt:3931.884\n",
      "Ep:120, loss:0.00001, loss_test:0.06707, lr:7.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.771, tt:3965.313\n",
      "Ep:121, loss:0.00001, loss_test:0.06851, lr:7.62e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.767, tt:3997.569\n",
      "Ep:122, loss:0.00001, loss_test:0.06740, lr:7.55e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.765, tt:4030.094\n",
      "Ep:123, loss:0.00001, loss_test:0.06740, lr:7.47e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.754, tt:4061.553\n",
      "Ep:124, loss:0.00001, loss_test:0.06783, lr:7.40e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.757, tt:4094.640\n",
      "Ep:125, loss:0.00001, loss_test:0.06722, lr:7.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:32.769, tt:4128.919\n",
      "Ep:126, loss:0.00001, loss_test:0.06664, lr:7.25e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.769, tt:4161.710\n",
      "Ep:127, loss:0.00001, loss_test:0.06721, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.772, tt:4194.791\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.06762, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.770, tt:4227.335\n",
      "Ep:129, loss:0.00001, loss_test:0.06618, lr:7.18e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.757, tt:4258.371\n",
      "Ep:130, loss:0.00001, loss_test:0.06769, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.753, tt:4290.652\n",
      "Ep:131, loss:0.00001, loss_test:0.06673, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.751, tt:4323.167\n",
      "Ep:132, loss:0.00001, loss_test:0.06660, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.751, tt:4355.906\n",
      "Ep:133, loss:0.00001, loss_test:0.06800, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.751, tt:4388.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.06570, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.746, tt:4420.747\n",
      "Ep:135, loss:0.00001, loss_test:0.06764, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.743, tt:4453.062\n",
      "Ep:136, loss:0.00001, loss_test:0.06688, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.741, tt:4485.581\n",
      "Ep:137, loss:0.00001, loss_test:0.06651, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.738, tt:4517.789\n",
      "Ep:138, loss:0.00001, loss_test:0.06744, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.730, tt:4549.488\n",
      "Ep:139, loss:0.00001, loss_test:0.06587, lr:7.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.741, tt:4583.759\n",
      "Ep:140, loss:0.00001, loss_test:0.06694, lr:7.03e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.743, tt:4616.786\n",
      "Ep:141, loss:0.00001, loss_test:0.06643, lr:6.96e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.747, tt:4650.109\n",
      "Ep:142, loss:0.00001, loss_test:0.06757, lr:6.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.749, tt:4683.072\n",
      "Ep:143, loss:0.00001, loss_test:0.06581, lr:6.83e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.747, tt:4715.529\n",
      "Ep:144, loss:0.00001, loss_test:0.06714, lr:6.76e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.744, tt:4747.832\n",
      "Ep:145, loss:0.00001, loss_test:0.06639, lr:6.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.738, tt:4779.707\n",
      "Ep:146, loss:0.00001, loss_test:0.06661, lr:6.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.739, tt:4812.603\n",
      "Ep:147, loss:0.00001, loss_test:0.06609, lr:6.56e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.741, tt:4845.729\n",
      "Ep:148, loss:0.00001, loss_test:0.06761, lr:6.49e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.753, tt:4880.256\n",
      "Ep:149, loss:0.00001, loss_test:0.06615, lr:6.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.754, tt:4913.143\n",
      "Ep:150, loss:0.00001, loss_test:0.06665, lr:6.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.760, tt:4946.826\n",
      "Ep:151, loss:0.00001, loss_test:0.06686, lr:6.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.764, tt:4980.109\n",
      "Ep:152, loss:0.00001, loss_test:0.06647, lr:6.24e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.765, tt:5013.092\n",
      "Ep:153, loss:0.00001, loss_test:0.06661, lr:6.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.768, tt:5046.224\n",
      "Ep:154, loss:0.00001, loss_test:0.06605, lr:6.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.770, tt:5079.366\n",
      "Ep:155, loss:0.00001, loss_test:0.06651, lr:6.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.771, tt:5112.246\n",
      "Ep:156, loss:0.00001, loss_test:0.06606, lr:5.99e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.771, tt:5145.020\n",
      "Ep:157, loss:0.00001, loss_test:0.06704, lr:5.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.767, tt:5177.213\n",
      "Ep:158, loss:0.00001, loss_test:0.06570, lr:5.87e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.771, tt:5210.648\n",
      "Ep:159, loss:0.00001, loss_test:0.06667, lr:5.81e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.779, tt:5244.619\n",
      "Ep:160, loss:0.00001, loss_test:0.06663, lr:5.75e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.786, tt:5278.562\n",
      "Ep:161, loss:0.00001, loss_test:0.06593, lr:5.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.784, tt:5310.957\n",
      "Ep:162, loss:0.00001, loss_test:0.06686, lr:5.64e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.778, tt:5342.880\n",
      "Ep:163, loss:0.00001, loss_test:0.06620, lr:5.58e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.781, tt:5376.126\n",
      "Ep:164, loss:0.00001, loss_test:0.06646, lr:5.53e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.776, tt:5408.086\n",
      "Ep:165, loss:0.00001, loss_test:0.06644, lr:5.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.777, tt:5440.957\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00001, loss_test:0.06649, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.776, tt:5473.656\n",
      "Ep:167, loss:0.00001, loss_test:0.06629, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.779, tt:5506.839\n",
      "Ep:168, loss:0.00001, loss_test:0.06654, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.774, tt:5538.762\n",
      "Ep:169, loss:0.00001, loss_test:0.06638, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.769, tt:5570.665\n",
      "Ep:170, loss:0.00000, loss_test:0.06622, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.763, tt:5602.443\n",
      "Ep:171, loss:0.00000, loss_test:0.06619, lr:5.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.762, tt:5635.146\n",
      "Ep:172, loss:0.00000, loss_test:0.06668, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.764, tt:5668.157\n",
      "Ep:173, loss:0.00000, loss_test:0.06605, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.768, tt:5701.599\n",
      "Ep:174, loss:0.00000, loss_test:0.06652, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.774, tt:5735.506\n",
      "Ep:175, loss:0.00000, loss_test:0.06627, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.777, tt:5768.677\n",
      "Ep:176, loss:0.00000, loss_test:0.06642, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.777, tt:5801.536\n",
      "Ep:177, loss:0.00000, loss_test:0.06663, lr:5.42e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.779, tt:5834.746\n",
      "Ep:178, loss:0.00000, loss_test:0.06652, lr:5.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.775, tt:5866.645\n",
      "Ep:179, loss:0.00000, loss_test:0.06658, lr:5.31e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.778, tt:5900.049\n",
      "Ep:180, loss:0.00000, loss_test:0.06713, lr:5.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.766, tt:5930.693\n",
      "Ep:181, loss:0.00000, loss_test:0.06667, lr:5.20e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.770, tt:5964.192\n",
      "Ep:182, loss:0.00000, loss_test:0.06686, lr:5.15e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.773, tt:5997.439\n",
      "Ep:183, loss:0.00000, loss_test:0.06691, lr:5.10e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.776, tt:6030.762\n",
      "Ep:184, loss:0.00000, loss_test:0.06675, lr:5.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.779, tt:6064.154\n",
      "Ep:185, loss:0.00000, loss_test:0.06651, lr:5.00e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.778, tt:6096.717\n",
      "Ep:186, loss:0.00000, loss_test:0.06681, lr:4.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.786, tt:6130.947\n",
      "Ep:187, loss:0.00000, loss_test:0.06740, lr:4.90e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.794, tt:6165.335\n",
      "Ep:188, loss:0.00000, loss_test:0.06649, lr:4.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.803, tt:6199.829\n",
      "Ep:189, loss:0.00000, loss_test:0.06673, lr:4.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.811, tt:6234.072\n",
      "Ep:190, loss:0.00000, loss_test:0.06732, lr:4.75e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.816, tt:6267.814\n",
      "Ep:191, loss:0.00000, loss_test:0.06688, lr:4.71e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.809, tt:6299.305\n",
      "Ep:192, loss:0.00000, loss_test:0.06693, lr:4.66e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.812, tt:6332.740\n",
      "Ep:193, loss:0.00000, loss_test:0.06656, lr:4.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.815, tt:6366.169\n",
      "Ep:194, loss:0.00000, loss_test:0.06723, lr:4.57e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.829, tt:6401.576\n",
      "Ep:195, loss:0.00000, loss_test:0.06672, lr:4.52e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.832, tt:6435.144\n",
      "Ep:196, loss:0.00000, loss_test:0.06669, lr:4.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.832, tt:6467.811\n",
      "Ep:197, loss:0.00000, loss_test:0.06753, lr:4.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.832, tt:6500.755\n",
      "Ep:198, loss:0.00000, loss_test:0.06646, lr:4.39e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.831, tt:6533.299\n",
      "Ep:199, loss:0.00000, loss_test:0.06710, lr:4.34e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.830, tt:6566.058\n",
      "Ep:200, loss:0.00000, loss_test:0.06727, lr:4.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.824, tt:6597.682\n",
      "Ep:201, loss:0.00000, loss_test:0.06679, lr:4.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.818, tt:6629.257\n",
      "Ep:202, loss:0.00000, loss_test:0.06704, lr:4.21e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.799, tt:6658.104\n",
      "Ep:203, loss:0.00000, loss_test:0.06702, lr:4.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.776, tt:6686.351\n",
      "Ep:204, loss:0.00000, loss_test:0.06732, lr:4.13e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.759, tt:6715.658\n",
      "Ep:205, loss:0.00000, loss_test:0.06692, lr:4.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.739, tt:6744.226\n",
      "Ep:206, loss:0.00000, loss_test:0.06701, lr:4.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.696, tt:6768.151\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14636, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.524, tt:22.524\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14579, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.003, tt:54.006\n",
      "Ep:2, loss:0.00014, loss_test:0.14480, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:28.278, tt:84.834\n",
      "Ep:3, loss:0.00014, loss_test:0.14312, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:29.455, tt:117.821\n",
      "Ep:4, loss:0.00013, loss_test:0.14021, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:29.897, tt:149.484\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00013, loss_test:0.13593, lr:1.00e-02, fs:0.64260 (r=0.899,p=0.500),  time:30.206, tt:181.238\n",
      "Ep:6, loss:0.00012, loss_test:0.13095, lr:1.00e-02, fs:0.62602 (r=0.778,p=0.524),  time:30.426, tt:212.981\n",
      "Ep:7, loss:0.00012, loss_test:0.12583, lr:1.00e-02, fs:0.56716 (r=0.576,p=0.559),  time:30.584, tt:244.676\n",
      "Ep:8, loss:0.00012, loss_test:0.12255, lr:1.00e-02, fs:0.56995 (r=0.556,p=0.585),  time:30.884, tt:277.956\n",
      "Ep:9, loss:0.00011, loss_test:0.12029, lr:1.00e-02, fs:0.63462 (r=0.667,p=0.606),  time:31.119, tt:311.192\n",
      "Ep:10, loss:0.00011, loss_test:0.11885, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:31.220, tt:343.423\n",
      "Ep:11, loss:0.00011, loss_test:0.11598, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:31.325, tt:375.903\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00010, loss_test:0.11390, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:31.357, tt:407.640\n",
      "Ep:13, loss:0.00010, loss_test:0.11268, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:31.509, tt:441.128\n",
      "Ep:14, loss:0.00010, loss_test:0.11142, lr:1.00e-02, fs:0.69036 (r=0.687,p=0.694),  time:31.514, tt:472.712\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00009, loss_test:0.10932, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:31.554, tt:504.859\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00009, loss_test:0.10720, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:31.633, tt:537.764\n",
      "Ep:17, loss:0.00009, loss_test:0.10555, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:31.685, tt:570.334\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.10452, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:31.689, tt:602.096\n",
      "Ep:19, loss:0.00008, loss_test:0.10346, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:31.716, tt:634.327\n",
      "Ep:20, loss:0.00008, loss_test:0.10188, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:31.760, tt:666.958\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.10061, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:31.786, tt:699.302\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.09994, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:31.817, tt:731.799\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00008, loss_test:0.09916, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:31.842, tt:764.213\n",
      "Ep:24, loss:0.00007, loss_test:0.09964, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:31.852, tt:796.292\n",
      "Ep:25, loss:0.00007, loss_test:0.09967, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:31.864, tt:828.467\n",
      "Ep:26, loss:0.00007, loss_test:0.09745, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:31.874, tt:860.586\n",
      "Ep:27, loss:0.00007, loss_test:0.09888, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:31.918, tt:893.702\n",
      "Ep:28, loss:0.00007, loss_test:0.09779, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:31.908, tt:925.324\n",
      "Ep:29, loss:0.00006, loss_test:0.09668, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:31.928, tt:957.843\n",
      "Ep:30, loss:0.00006, loss_test:0.09698, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:31.917, tt:989.442\n",
      "Ep:31, loss:0.00006, loss_test:0.09596, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:31.974, tt:1023.169\n",
      "Ep:32, loss:0.00006, loss_test:0.09598, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:31.992, tt:1055.740\n",
      "Ep:33, loss:0.00006, loss_test:0.09608, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:32.040, tt:1089.358\n",
      "Ep:34, loss:0.00006, loss_test:0.09396, lr:9.90e-03, fs:0.74074 (r=0.707,p=0.778),  time:32.047, tt:1121.648\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.09478, lr:9.90e-03, fs:0.72043 (r=0.677,p=0.770),  time:32.104, tt:1155.745\n",
      "Ep:36, loss:0.00005, loss_test:0.09425, lr:9.90e-03, fs:0.72043 (r=0.677,p=0.770),  time:32.129, tt:1188.788\n",
      "Ep:37, loss:0.00005, loss_test:0.09271, lr:9.90e-03, fs:0.73684 (r=0.707,p=0.769),  time:32.128, tt:1220.872\n",
      "Ep:38, loss:0.00005, loss_test:0.09487, lr:9.90e-03, fs:0.70330 (r=0.646,p=0.771),  time:32.138, tt:1253.392\n",
      "Ep:39, loss:0.00005, loss_test:0.09369, lr:9.90e-03, fs:0.72826 (r=0.677,p=0.788),  time:32.169, tt:1286.763\n",
      "Ep:40, loss:0.00005, loss_test:0.09245, lr:9.90e-03, fs:0.74468 (r=0.707,p=0.787),  time:32.204, tt:1320.346\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.09466, lr:9.90e-03, fs:0.72626 (r=0.657,p=0.812),  time:32.225, tt:1353.446\n",
      "Ep:42, loss:0.00005, loss_test:0.09096, lr:9.90e-03, fs:0.76190 (r=0.727,p=0.800),  time:32.258, tt:1387.081\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.09312, lr:9.90e-03, fs:0.74725 (r=0.687,p=0.819),  time:32.263, tt:1419.577\n",
      "Ep:44, loss:0.00005, loss_test:0.09295, lr:9.90e-03, fs:0.74033 (r=0.677,p=0.817),  time:32.283, tt:1452.752\n",
      "Ep:45, loss:0.00004, loss_test:0.09066, lr:9.90e-03, fs:0.75269 (r=0.707,p=0.805),  time:32.307, tt:1486.132\n",
      "Ep:46, loss:0.00004, loss_test:0.09274, lr:9.90e-03, fs:0.74033 (r=0.677,p=0.817),  time:32.372, tt:1521.483\n",
      "Ep:47, loss:0.00004, loss_test:0.09120, lr:9.90e-03, fs:0.74725 (r=0.687,p=0.819),  time:32.392, tt:1554.808\n",
      "Ep:48, loss:0.00004, loss_test:0.09167, lr:9.90e-03, fs:0.74444 (r=0.677,p=0.827),  time:32.422, tt:1588.672\n",
      "Ep:49, loss:0.00004, loss_test:0.09206, lr:9.90e-03, fs:0.74725 (r=0.687,p=0.819),  time:32.455, tt:1622.769\n",
      "Ep:50, loss:0.00004, loss_test:0.09071, lr:9.90e-03, fs:0.75410 (r=0.697,p=0.821),  time:32.476, tt:1656.260\n",
      "Ep:51, loss:0.00004, loss_test:0.09204, lr:9.90e-03, fs:0.74860 (r=0.677,p=0.838),  time:32.501, tt:1690.032\n",
      "Ep:52, loss:0.00004, loss_test:0.09111, lr:9.90e-03, fs:0.74860 (r=0.677,p=0.838),  time:32.518, tt:1723.461\n",
      "Ep:53, loss:0.00004, loss_test:0.09218, lr:9.90e-03, fs:0.74157 (r=0.667,p=0.835),  time:32.567, tt:1758.625\n",
      "Ep:54, loss:0.00004, loss_test:0.09136, lr:9.80e-03, fs:0.74860 (r=0.677,p=0.838),  time:32.583, tt:1792.047\n",
      "Ep:55, loss:0.00003, loss_test:0.09277, lr:9.70e-03, fs:0.73864 (r=0.657,p=0.844),  time:32.582, tt:1824.594\n",
      "Ep:56, loss:0.00003, loss_test:0.09122, lr:9.61e-03, fs:0.74576 (r=0.667,p=0.846),  time:32.616, tt:1859.109\n",
      "Ep:57, loss:0.00003, loss_test:0.09279, lr:9.51e-03, fs:0.73864 (r=0.657,p=0.844),  time:32.638, tt:1892.985\n",
      "Ep:58, loss:0.00003, loss_test:0.09237, lr:9.41e-03, fs:0.74286 (r=0.657,p=0.855),  time:32.635, tt:1925.456\n",
      "Ep:59, loss:0.00003, loss_test:0.09298, lr:9.32e-03, fs:0.74286 (r=0.657,p=0.855),  time:32.615, tt:1956.875\n",
      "Ep:60, loss:0.00003, loss_test:0.09317, lr:9.23e-03, fs:0.72832 (r=0.636,p=0.851),  time:32.627, tt:1990.266\n",
      "Ep:61, loss:0.00003, loss_test:0.09159, lr:9.14e-03, fs:0.74286 (r=0.657,p=0.855),  time:32.626, tt:2022.794\n",
      "Ep:62, loss:0.00003, loss_test:0.09455, lr:9.04e-03, fs:0.71765 (r=0.616,p=0.859),  time:32.649, tt:2056.897\n",
      "Ep:63, loss:0.00003, loss_test:0.09243, lr:8.95e-03, fs:0.73563 (r=0.646,p=0.853),  time:32.641, tt:2089.036\n",
      "Ep:64, loss:0.00003, loss_test:0.09439, lr:8.86e-03, fs:0.71765 (r=0.616,p=0.859),  time:32.631, tt:2121.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00003, loss_test:0.09519, lr:8.78e-03, fs:0.71765 (r=0.616,p=0.859),  time:32.623, tt:2153.123\n",
      "Ep:66, loss:0.00003, loss_test:0.09303, lr:8.69e-03, fs:0.72093 (r=0.626,p=0.849),  time:32.616, tt:2185.282\n",
      "Ep:67, loss:0.00003, loss_test:0.09496, lr:8.60e-03, fs:0.71765 (r=0.616,p=0.859),  time:32.618, tt:2218.037\n",
      "Ep:68, loss:0.00003, loss_test:0.09518, lr:8.51e-03, fs:0.71765 (r=0.616,p=0.859),  time:32.623, tt:2250.984\n",
      "Ep:69, loss:0.00002, loss_test:0.09551, lr:8.43e-03, fs:0.71765 (r=0.616,p=0.859),  time:32.635, tt:2284.460\n",
      "Ep:70, loss:0.00002, loss_test:0.09482, lr:8.35e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.632, tt:2316.876\n",
      "Ep:71, loss:0.00002, loss_test:0.09707, lr:8.26e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.639, tt:2349.994\n",
      "Ep:72, loss:0.00002, loss_test:0.09392, lr:8.18e-03, fs:0.74118 (r=0.636,p=0.887),  time:32.646, tt:2383.132\n",
      "Ep:73, loss:0.00002, loss_test:0.09710, lr:8.10e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.646, tt:2415.819\n",
      "Ep:74, loss:0.00002, loss_test:0.09432, lr:8.02e-03, fs:0.73373 (r=0.626,p=0.886),  time:32.657, tt:2449.295\n",
      "Ep:75, loss:0.00002, loss_test:0.09756, lr:7.94e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.673, tt:2483.174\n",
      "Ep:76, loss:0.00002, loss_test:0.09452, lr:7.86e-03, fs:0.72619 (r=0.616,p=0.884),  time:32.693, tt:2517.397\n",
      "Ep:77, loss:0.00002, loss_test:0.09767, lr:7.78e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.701, tt:2550.664\n",
      "Ep:78, loss:0.00002, loss_test:0.09648, lr:7.70e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.719, tt:2584.810\n",
      "Ep:79, loss:0.00002, loss_test:0.09664, lr:7.62e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.724, tt:2617.929\n",
      "Ep:80, loss:0.00002, loss_test:0.09557, lr:7.55e-03, fs:0.72619 (r=0.616,p=0.884),  time:32.738, tt:2651.742\n",
      "Ep:81, loss:0.00002, loss_test:0.09945, lr:7.47e-03, fs:0.69512 (r=0.576,p=0.877),  time:32.717, tt:2682.793\n",
      "Ep:82, loss:0.00002, loss_test:0.09576, lr:7.40e-03, fs:0.72619 (r=0.616,p=0.884),  time:32.719, tt:2715.639\n",
      "Ep:83, loss:0.00002, loss_test:0.09785, lr:7.32e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.733, tt:2749.543\n",
      "Ep:84, loss:0.00002, loss_test:0.09700, lr:7.25e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.746, tt:2783.430\n",
      "Ep:85, loss:0.00002, loss_test:0.09764, lr:7.18e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.762, tt:2817.571\n",
      "Ep:86, loss:0.00002, loss_test:0.09686, lr:7.11e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.765, tt:2850.594\n",
      "Ep:87, loss:0.00002, loss_test:0.09776, lr:7.03e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.754, tt:2882.349\n",
      "Ep:88, loss:0.00002, loss_test:0.09747, lr:6.96e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.756, tt:2915.328\n",
      "Ep:89, loss:0.00002, loss_test:0.09735, lr:6.89e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.757, tt:2948.094\n",
      "Ep:90, loss:0.00002, loss_test:0.09839, lr:6.83e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.742, tt:2979.566\n",
      "Ep:91, loss:0.00002, loss_test:0.09687, lr:6.76e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.727, tt:3010.920\n",
      "Ep:92, loss:0.00002, loss_test:0.09867, lr:6.69e-03, fs:0.70303 (r=0.586,p=0.879),  time:32.729, tt:3043.751\n",
      "Ep:93, loss:0.00002, loss_test:0.09756, lr:6.62e-03, fs:0.72619 (r=0.616,p=0.884),  time:32.732, tt:3076.806\n",
      "Ep:94, loss:0.00002, loss_test:0.09975, lr:6.56e-03, fs:0.70732 (r=0.586,p=0.892),  time:32.725, tt:3108.917\n",
      "Ep:95, loss:0.00002, loss_test:0.09733, lr:6.49e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.708, tt:3139.924\n",
      "Ep:96, loss:0.00002, loss_test:0.09841, lr:6.43e-03, fs:0.71084 (r=0.596,p=0.881),  time:32.700, tt:3171.906\n",
      "Ep:97, loss:0.00002, loss_test:0.09729, lr:6.36e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.681, tt:3202.713\n",
      "Ep:98, loss:0.00002, loss_test:0.09998, lr:6.30e-03, fs:0.69939 (r=0.576,p=0.891),  time:32.681, tt:3235.415\n",
      "Ep:99, loss:0.00002, loss_test:0.09757, lr:6.24e-03, fs:0.71856 (r=0.606,p=0.882),  time:32.671, tt:3267.129\n",
      "Ep:100, loss:0.00001, loss_test:0.09991, lr:6.17e-03, fs:0.71515 (r=0.596,p=0.894),  time:32.662, tt:3298.820\n",
      "Ep:101, loss:0.00001, loss_test:0.09717, lr:6.11e-03, fs:0.73373 (r=0.626,p=0.886),  time:32.657, tt:3330.971\n",
      "Ep:102, loss:0.00001, loss_test:0.10089, lr:6.05e-03, fs:0.71166 (r=0.586,p=0.906),  time:32.639, tt:3361.826\n",
      "Ep:103, loss:0.00001, loss_test:0.09743, lr:5.99e-03, fs:0.73810 (r=0.626,p=0.899),  time:32.634, tt:3393.886\n",
      "Ep:104, loss:0.00001, loss_test:0.10014, lr:5.93e-03, fs:0.71166 (r=0.586,p=0.906),  time:32.631, tt:3426.271\n",
      "Ep:105, loss:0.00001, loss_test:0.09928, lr:5.87e-03, fs:0.72289 (r=0.606,p=0.896),  time:32.662, tt:3462.148\n",
      "Ep:106, loss:0.00001, loss_test:0.09860, lr:5.81e-03, fs:0.72727 (r=0.606,p=0.909),  time:32.657, tt:3494.341\n",
      "Ep:107, loss:0.00001, loss_test:0.10145, lr:5.75e-03, fs:0.71605 (r=0.586,p=0.921),  time:32.665, tt:3527.833\n",
      "Ep:108, loss:0.00001, loss_test:0.09732, lr:5.70e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.670, tt:3561.064\n",
      "Ep:109, loss:0.00001, loss_test:0.10166, lr:5.64e-03, fs:0.70807 (r=0.576,p=0.919),  time:32.665, tt:3593.146\n",
      "Ep:110, loss:0.00001, loss_test:0.09790, lr:5.58e-03, fs:0.74556 (r=0.636,p=0.900),  time:32.658, tt:3625.009\n",
      "Ep:111, loss:0.00001, loss_test:0.10085, lr:5.53e-03, fs:0.71605 (r=0.586,p=0.921),  time:32.645, tt:3656.207\n",
      "Ep:112, loss:0.00001, loss_test:0.09926, lr:5.47e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.648, tt:3689.234\n",
      "Ep:113, loss:0.00001, loss_test:0.10022, lr:5.42e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.635, tt:3720.443\n",
      "Ep:114, loss:0.00001, loss_test:0.09975, lr:5.36e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.639, tt:3753.502\n",
      "Ep:115, loss:0.00001, loss_test:0.09968, lr:5.31e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.651, tt:3787.460\n",
      "Ep:116, loss:0.00001, loss_test:0.10042, lr:5.26e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.657, tt:3820.847\n",
      "Ep:117, loss:0.00001, loss_test:0.10030, lr:5.20e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.669, tt:3854.911\n",
      "Ep:118, loss:0.00001, loss_test:0.10104, lr:5.15e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.662, tt:3886.823\n",
      "Ep:119, loss:0.00001, loss_test:0.09902, lr:5.10e-03, fs:0.75449 (r=0.636,p=0.926),  time:32.658, tt:3918.947\n",
      "Ep:120, loss:0.00001, loss_test:0.10115, lr:5.05e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.655, tt:3951.209\n",
      "Ep:121, loss:0.00001, loss_test:0.09970, lr:5.00e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.646, tt:3982.839\n",
      "Ep:122, loss:0.00001, loss_test:0.10103, lr:4.95e-03, fs:0.71605 (r=0.586,p=0.921),  time:32.637, tt:4014.358\n",
      "Ep:123, loss:0.00001, loss_test:0.10005, lr:4.90e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.637, tt:4046.985\n",
      "Ep:124, loss:0.00001, loss_test:0.10115, lr:4.85e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.637, tt:4079.597\n",
      "Ep:125, loss:0.00001, loss_test:0.10029, lr:4.80e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.640, tt:4112.625\n",
      "Ep:126, loss:0.00001, loss_test:0.10028, lr:4.75e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.640, tt:4145.324\n",
      "Ep:127, loss:0.00001, loss_test:0.10057, lr:4.71e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.644, tt:4178.410\n",
      "Ep:128, loss:0.00001, loss_test:0.10025, lr:4.66e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.638, tt:4210.305\n",
      "Ep:129, loss:0.00001, loss_test:0.10075, lr:4.61e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.639, tt:4243.012\n",
      "Ep:130, loss:0.00001, loss_test:0.10009, lr:4.57e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.642, tt:4276.083\n",
      "Ep:131, loss:0.00001, loss_test:0.10074, lr:4.52e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.647, tt:4309.439\n",
      "Ep:132, loss:0.00001, loss_test:0.10066, lr:4.48e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.642, tt:4341.350\n",
      "Ep:133, loss:0.00001, loss_test:0.09995, lr:4.43e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.654, tt:4375.638\n",
      "Ep:134, loss:0.00001, loss_test:0.10103, lr:4.39e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.646, tt:4407.214\n",
      "Ep:135, loss:0.00001, loss_test:0.10084, lr:4.34e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.646, tt:4439.873\n",
      "Ep:136, loss:0.00001, loss_test:0.10073, lr:4.30e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.645, tt:4472.320\n",
      "Ep:137, loss:0.00001, loss_test:0.10057, lr:4.26e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.650, tt:4505.731\n",
      "Ep:138, loss:0.00001, loss_test:0.10128, lr:4.21e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.654, tt:4538.946\n",
      "Ep:139, loss:0.00001, loss_test:0.10098, lr:4.17e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.662, tt:4572.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.09979, lr:4.13e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.665, tt:4605.828\n",
      "Ep:141, loss:0.00001, loss_test:0.10195, lr:4.09e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.674, tt:4639.661\n",
      "Ep:142, loss:0.00001, loss_test:0.10014, lr:4.05e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.684, tt:4673.844\n",
      "Ep:143, loss:0.00001, loss_test:0.10147, lr:4.01e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.697, tt:4708.420\n",
      "Ep:144, loss:0.00001, loss_test:0.10135, lr:3.97e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.692, tt:4740.395\n",
      "Ep:145, loss:0.00001, loss_test:0.10041, lr:3.93e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.697, tt:4773.761\n",
      "Ep:146, loss:0.00001, loss_test:0.10194, lr:3.89e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.692, tt:4805.684\n",
      "Ep:147, loss:0.00001, loss_test:0.10023, lr:3.85e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.709, tt:4840.871\n",
      "Ep:148, loss:0.00001, loss_test:0.10169, lr:3.81e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.716, tt:4874.667\n",
      "Ep:149, loss:0.00001, loss_test:0.10064, lr:3.77e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.723, tt:4908.490\n",
      "Ep:150, loss:0.00001, loss_test:0.10160, lr:3.73e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.729, tt:4942.040\n",
      "Ep:151, loss:0.00001, loss_test:0.10133, lr:3.70e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.765, tt:4980.268\n",
      "Ep:152, loss:0.00001, loss_test:0.10086, lr:3.66e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.757, tt:5011.817\n",
      "Ep:153, loss:0.00001, loss_test:0.10174, lr:3.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.764, tt:5045.677\n",
      "Ep:154, loss:0.00001, loss_test:0.10048, lr:3.59e-03, fs:0.75449 (r=0.636,p=0.926),  time:32.773, tt:5079.876\n",
      "Ep:155, loss:0.00001, loss_test:0.10174, lr:3.55e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.778, tt:5113.324\n",
      "Ep:156, loss:0.00001, loss_test:0.10106, lr:3.52e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.782, tt:5146.778\n",
      "Ep:157, loss:0.00001, loss_test:0.10072, lr:3.48e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.786, tt:5180.170\n",
      "Ep:158, loss:0.00001, loss_test:0.10127, lr:3.45e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.794, tt:5214.201\n",
      "Ep:159, loss:0.00001, loss_test:0.10081, lr:3.41e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.785, tt:5245.619\n",
      "Ep:160, loss:0.00001, loss_test:0.10084, lr:3.38e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.786, tt:5278.498\n",
      "Ep:161, loss:0.00001, loss_test:0.10151, lr:3.34e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.781, tt:5310.533\n",
      "Ep:162, loss:0.00001, loss_test:0.10069, lr:3.31e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.778, tt:5342.872\n",
      "Ep:163, loss:0.00001, loss_test:0.10124, lr:3.28e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.776, tt:5375.344\n",
      "Ep:164, loss:0.00001, loss_test:0.10100, lr:3.24e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.786, tt:5409.711\n",
      "Ep:165, loss:0.00001, loss_test:0.10163, lr:3.21e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.784, tt:5442.097\n",
      "Ep:166, loss:0.00001, loss_test:0.10105, lr:3.18e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.781, tt:5474.448\n",
      "Ep:167, loss:0.00001, loss_test:0.10150, lr:3.15e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.773, tt:5505.784\n",
      "Ep:168, loss:0.00001, loss_test:0.10120, lr:3.12e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.773, tt:5538.674\n",
      "Ep:169, loss:0.00001, loss_test:0.10145, lr:3.09e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.771, tt:5571.114\n",
      "Ep:170, loss:0.00001, loss_test:0.10213, lr:3.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.775, tt:5604.538\n",
      "Ep:171, loss:0.00001, loss_test:0.10121, lr:3.02e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.786, tt:5639.202\n",
      "Ep:172, loss:0.00001, loss_test:0.10156, lr:2.99e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.794, tt:5673.289\n",
      "Ep:173, loss:0.00001, loss_test:0.10083, lr:2.96e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.800, tt:5707.128\n",
      "Ep:174, loss:0.00001, loss_test:0.10177, lr:2.93e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.814, tt:5742.430\n",
      "Ep:175, loss:0.00001, loss_test:0.10126, lr:2.90e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.813, tt:5775.170\n",
      "Ep:176, loss:0.00001, loss_test:0.10124, lr:2.88e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.819, tt:5808.978\n",
      "Ep:177, loss:0.00001, loss_test:0.10143, lr:2.85e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.826, tt:5842.961\n",
      "Ep:178, loss:0.00001, loss_test:0.10141, lr:2.82e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.830, tt:5876.600\n",
      "Ep:179, loss:0.00001, loss_test:0.10125, lr:2.79e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.841, tt:5911.331\n",
      "Ep:180, loss:0.00001, loss_test:0.10183, lr:2.76e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.847, tt:5945.322\n",
      "Ep:181, loss:0.00001, loss_test:0.10127, lr:2.73e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.841, tt:5977.055\n",
      "Ep:182, loss:0.00001, loss_test:0.10140, lr:2.71e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.843, tt:6010.281\n",
      "Ep:183, loss:0.00001, loss_test:0.10201, lr:2.68e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.835, tt:6041.568\n",
      "Ep:184, loss:0.00001, loss_test:0.10131, lr:2.65e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.835, tt:6074.472\n",
      "Ep:185, loss:0.00001, loss_test:0.10164, lr:2.63e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.841, tt:6108.334\n",
      "Ep:186, loss:0.00001, loss_test:0.10177, lr:2.60e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.834, tt:6140.028\n",
      "Ep:187, loss:0.00001, loss_test:0.10099, lr:2.57e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.837, tt:6173.338\n",
      "Ep:188, loss:0.00001, loss_test:0.10194, lr:2.55e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.841, tt:6206.946\n",
      "Ep:189, loss:0.00001, loss_test:0.10138, lr:2.52e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.843, tt:6240.161\n",
      "Ep:190, loss:0.00001, loss_test:0.10142, lr:2.50e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.828, tt:6270.232\n",
      "Ep:191, loss:0.00001, loss_test:0.10194, lr:2.47e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.831, tt:6303.627\n",
      "Ep:192, loss:0.00001, loss_test:0.10137, lr:2.45e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.857, tt:6341.374\n",
      "Ep:193, loss:0.00001, loss_test:0.10180, lr:2.42e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.854, tt:6373.736\n",
      "Ep:194, loss:0.00001, loss_test:0.10180, lr:2.40e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.854, tt:6406.475\n",
      "Ep:195, loss:0.00001, loss_test:0.10136, lr:2.38e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.853, tt:6439.170\n",
      "Ep:196, loss:0.00001, loss_test:0.10182, lr:2.35e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.855, tt:6472.348\n",
      "Ep:197, loss:0.00001, loss_test:0.10164, lr:2.33e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.853, tt:6504.823\n",
      "Ep:198, loss:0.00001, loss_test:0.10173, lr:2.31e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.849, tt:6536.967\n",
      "Ep:199, loss:0.00001, loss_test:0.10147, lr:2.28e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.843, tt:6568.543\n",
      "Ep:200, loss:0.00001, loss_test:0.10146, lr:2.26e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.835, tt:6599.885\n",
      "Ep:201, loss:0.00001, loss_test:0.10156, lr:2.24e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.826, tt:6630.813\n",
      "Ep:202, loss:0.00001, loss_test:0.10203, lr:2.21e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.825, tt:6663.548\n",
      "Ep:203, loss:0.00001, loss_test:0.10168, lr:2.19e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.821, tt:6695.383\n",
      "Ep:204, loss:0.00001, loss_test:0.10178, lr:2.17e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.824, tt:6728.942\n",
      "Ep:205, loss:0.00001, loss_test:0.10185, lr:2.15e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.809, tt:6758.601\n",
      "Ep:206, loss:0.00001, loss_test:0.10169, lr:2.13e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.767, tt:6782.789\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14268, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:53.075, tt:53.075\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13789, lr:1.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:60.078, tt:120.157\n",
      "Ep:2, loss:0.00051, loss_test:0.12824, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:61.911, tt:185.732\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00048, loss_test:0.11929, lr:1.00e-02, fs:0.61856 (r=0.606,p=0.632),  time:63.139, tt:252.558\n",
      "Ep:4, loss:0.00046, loss_test:0.11509, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:63.560, tt:317.801\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.11250, lr:1.00e-02, fs:0.68317 (r=0.697,p=0.670),  time:63.878, tt:383.270\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.11024, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:64.115, tt:448.804\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.10817, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:64.454, tt:515.633\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.10741, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:64.774, tt:582.963\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.10678, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:64.909, tt:649.093\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.10670, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:65.064, tt:715.699\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.10590, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:65.148, tt:781.776\n",
      "Ep:12, loss:0.00029, loss_test:0.10427, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:65.251, tt:848.262\n",
      "Ep:13, loss:0.00028, loss_test:0.10672, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:65.345, tt:914.830\n",
      "Ep:14, loss:0.00027, loss_test:0.10386, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:65.417, tt:981.257\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.10170, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:65.415, tt:1046.641\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.10524, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:65.520, tt:1113.836\n",
      "Ep:17, loss:0.00023, loss_test:0.10231, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:65.547, tt:1179.848\n",
      "Ep:18, loss:0.00022, loss_test:0.10253, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:65.642, tt:1247.201\n",
      "Ep:19, loss:0.00021, loss_test:0.10318, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:65.685, tt:1313.705\n",
      "Ep:20, loss:0.00020, loss_test:0.10173, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:65.747, tt:1380.696\n",
      "Ep:21, loss:0.00019, loss_test:0.10129, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:65.731, tt:1446.083\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.10042, lr:1.00e-02, fs:0.74194 (r=0.697,p=0.793),  time:65.786, tt:1513.081\n",
      "Ep:23, loss:0.00017, loss_test:0.10290, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:65.816, tt:1579.579\n",
      "Ep:24, loss:0.00016, loss_test:0.10087, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:65.865, tt:1646.618\n",
      "Ep:25, loss:0.00016, loss_test:0.09964, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:65.793, tt:1710.616\n",
      "Ep:26, loss:0.00015, loss_test:0.10149, lr:1.00e-02, fs:0.72626 (r=0.657,p=0.812),  time:65.773, tt:1775.865\n",
      "Ep:27, loss:0.00014, loss_test:0.10243, lr:1.00e-02, fs:0.70520 (r=0.616,p=0.824),  time:65.766, tt:1841.445\n",
      "Ep:28, loss:0.00014, loss_test:0.10461, lr:1.00e-02, fs:0.66667 (r=0.556,p=0.833),  time:65.829, tt:1909.040\n",
      "Ep:29, loss:0.00013, loss_test:0.10133, lr:1.00e-02, fs:0.69767 (r=0.606,p=0.822),  time:65.829, tt:1974.872\n",
      "Ep:30, loss:0.00012, loss_test:0.09924, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:65.756, tt:2038.431\n",
      "Ep:31, loss:0.00012, loss_test:0.09708, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:65.717, tt:2102.946\n",
      "Ep:32, loss:0.00011, loss_test:0.10249, lr:1.00e-02, fs:0.65455 (r=0.545,p=0.818),  time:65.751, tt:2169.774\n",
      "Ep:33, loss:0.00011, loss_test:0.10530, lr:9.90e-03, fs:0.64596 (r=0.525,p=0.839),  time:65.746, tt:2235.360\n",
      "Ep:34, loss:0.00010, loss_test:0.10488, lr:9.80e-03, fs:0.64151 (r=0.515,p=0.850),  time:65.830, tt:2304.045\n",
      "Ep:35, loss:0.00010, loss_test:0.09631, lr:9.70e-03, fs:0.71676 (r=0.626,p=0.838),  time:65.808, tt:2369.077\n",
      "Ep:36, loss:0.00009, loss_test:0.10373, lr:9.61e-03, fs:0.64103 (r=0.505,p=0.877),  time:65.771, tt:2433.518\n",
      "Ep:37, loss:0.00009, loss_test:0.10778, lr:9.51e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.808, tt:2500.701\n",
      "Ep:38, loss:0.00009, loss_test:0.10303, lr:9.41e-03, fs:0.62500 (r=0.505,p=0.820),  time:65.883, tt:2569.421\n",
      "Ep:39, loss:0.00008, loss_test:0.09907, lr:9.32e-03, fs:0.65854 (r=0.545,p=0.831),  time:65.922, tt:2636.887\n",
      "Ep:40, loss:0.00008, loss_test:0.10411, lr:9.23e-03, fs:0.64103 (r=0.505,p=0.877),  time:65.865, tt:2700.458\n",
      "Ep:41, loss:0.00007, loss_test:0.10270, lr:9.14e-03, fs:0.63291 (r=0.505,p=0.847),  time:65.857, tt:2766.009\n",
      "Ep:42, loss:0.00007, loss_test:0.10299, lr:9.04e-03, fs:0.64151 (r=0.515,p=0.850),  time:65.898, tt:2833.629\n",
      "Ep:43, loss:0.00007, loss_test:0.10733, lr:8.95e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.904, tt:2899.784\n",
      "Ep:44, loss:0.00006, loss_test:0.10641, lr:8.86e-03, fs:0.64103 (r=0.505,p=0.877),  time:65.898, tt:2965.399\n",
      "Ep:45, loss:0.00006, loss_test:0.09816, lr:8.78e-03, fs:0.65432 (r=0.535,p=0.841),  time:65.926, tt:3032.591\n",
      "Ep:46, loss:0.00006, loss_test:0.10551, lr:8.69e-03, fs:0.63291 (r=0.505,p=0.847),  time:65.937, tt:3099.025\n",
      "Ep:47, loss:0.00006, loss_test:0.10904, lr:8.60e-03, fs:0.65359 (r=0.505,p=0.926),  time:65.978, tt:3166.964\n",
      "Ep:48, loss:0.00006, loss_test:0.10137, lr:8.51e-03, fs:0.63291 (r=0.505,p=0.847),  time:65.997, tt:3233.863\n",
      "Ep:49, loss:0.00005, loss_test:0.10319, lr:8.43e-03, fs:0.64103 (r=0.505,p=0.877),  time:66.009, tt:3300.474\n",
      "Ep:50, loss:0.00005, loss_test:0.10929, lr:8.35e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.006, tt:3366.290\n",
      "Ep:51, loss:0.00005, loss_test:0.10712, lr:8.26e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.027, tt:3433.390\n",
      "Ep:52, loss:0.00005, loss_test:0.10670, lr:8.18e-03, fs:0.63694 (r=0.505,p=0.862),  time:66.014, tt:3498.749\n",
      "Ep:53, loss:0.00005, loss_test:0.10927, lr:8.10e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.038, tt:3566.038\n",
      "Ep:54, loss:0.00004, loss_test:0.10889, lr:8.02e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.988, tt:3629.352\n",
      "Ep:55, loss:0.00004, loss_test:0.10488, lr:7.94e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.999, tt:3695.952\n",
      "Ep:56, loss:0.00004, loss_test:0.10635, lr:7.86e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.031, tt:3763.787\n",
      "Ep:57, loss:0.00004, loss_test:0.11076, lr:7.78e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.010, tt:3828.587\n",
      "Ep:58, loss:0.00004, loss_test:0.10676, lr:7.70e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.058, tt:3897.434\n",
      "Ep:59, loss:0.00004, loss_test:0.10832, lr:7.62e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.140, tt:3968.421\n",
      "Ep:60, loss:0.00004, loss_test:0.10917, lr:7.55e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.110, tt:4032.740\n",
      "Ep:61, loss:0.00003, loss_test:0.11002, lr:7.47e-03, fs:0.64935 (r=0.505,p=0.909),  time:66.092, tt:4097.675\n",
      "Ep:62, loss:0.00003, loss_test:0.10525, lr:7.40e-03, fs:0.64103 (r=0.505,p=0.877),  time:66.108, tt:4164.794\n",
      "Ep:63, loss:0.00003, loss_test:0.11218, lr:7.32e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.092, tt:4229.864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00003, loss_test:0.11407, lr:7.25e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.104, tt:4296.775\n",
      "Ep:65, loss:0.00003, loss_test:0.10806, lr:7.18e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.117, tt:4363.710\n",
      "Ep:66, loss:0.00003, loss_test:0.10915, lr:7.11e-03, fs:0.64103 (r=0.505,p=0.877),  time:66.096, tt:4428.438\n",
      "Ep:67, loss:0.00003, loss_test:0.11487, lr:7.03e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.126, tt:4496.596\n",
      "Ep:68, loss:0.00003, loss_test:0.10755, lr:6.96e-03, fs:0.64103 (r=0.505,p=0.877),  time:66.145, tt:4564.027\n",
      "Ep:69, loss:0.00003, loss_test:0.11067, lr:6.89e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.154, tt:4630.782\n",
      "Ep:70, loss:0.00003, loss_test:0.11272, lr:6.83e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.166, tt:4697.810\n",
      "Ep:71, loss:0.00003, loss_test:0.10905, lr:6.76e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.182, tt:4765.072\n",
      "Ep:72, loss:0.00003, loss_test:0.10984, lr:6.69e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.202, tt:4832.740\n",
      "Ep:73, loss:0.00003, loss_test:0.10850, lr:6.62e-03, fs:0.64516 (r=0.505,p=0.893),  time:66.225, tt:4900.623\n",
      "Ep:74, loss:0.00002, loss_test:0.11052, lr:6.56e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.264, tt:4969.802\n",
      "Ep:75, loss:0.00002, loss_test:0.11053, lr:6.49e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.289, tt:5037.929\n",
      "Ep:76, loss:0.00002, loss_test:0.10959, lr:6.43e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.282, tt:5103.716\n",
      "Ep:77, loss:0.00002, loss_test:0.11088, lr:6.36e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.267, tt:5168.845\n",
      "Ep:78, loss:0.00002, loss_test:0.11092, lr:6.30e-03, fs:0.64935 (r=0.505,p=0.909),  time:66.284, tt:5236.464\n",
      "Ep:79, loss:0.00002, loss_test:0.11164, lr:6.24e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.277, tt:5302.150\n",
      "Ep:80, loss:0.00002, loss_test:0.10898, lr:6.17e-03, fs:0.64935 (r=0.505,p=0.909),  time:66.294, tt:5369.845\n",
      "Ep:81, loss:0.00002, loss_test:0.11280, lr:6.11e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.303, tt:5436.817\n",
      "Ep:82, loss:0.00002, loss_test:0.11094, lr:6.05e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.313, tt:5503.972\n",
      "Ep:83, loss:0.00002, loss_test:0.11053, lr:5.99e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.297, tt:5568.939\n",
      "Ep:84, loss:0.00002, loss_test:0.11304, lr:5.93e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.269, tt:5632.899\n",
      "Ep:85, loss:0.00002, loss_test:0.11345, lr:5.87e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.259, tt:5698.262\n",
      "Ep:86, loss:0.00002, loss_test:0.11109, lr:5.81e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.263, tt:5764.902\n",
      "Ep:87, loss:0.00002, loss_test:0.11301, lr:5.75e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.261, tt:5830.981\n",
      "Ep:88, loss:0.00002, loss_test:0.11148, lr:5.70e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.229, tt:5894.347\n",
      "Ep:89, loss:0.00002, loss_test:0.11288, lr:5.64e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.226, tt:5960.314\n",
      "Ep:90, loss:0.00002, loss_test:0.11337, lr:5.58e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.225, tt:6026.488\n",
      "Ep:91, loss:0.00002, loss_test:0.11249, lr:5.53e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.230, tt:6093.140\n",
      "Ep:92, loss:0.00002, loss_test:0.11290, lr:5.47e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.230, tt:6159.379\n",
      "Ep:93, loss:0.00002, loss_test:0.11399, lr:5.42e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.215, tt:6224.246\n",
      "Ep:94, loss:0.00002, loss_test:0.11090, lr:5.36e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.210, tt:6289.908\n",
      "Ep:95, loss:0.00002, loss_test:0.11494, lr:5.31e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.205, tt:6355.681\n",
      "Ep:96, loss:0.00002, loss_test:0.11143, lr:5.26e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.189, tt:6420.301\n",
      "Ep:97, loss:0.00002, loss_test:0.11482, lr:5.20e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.195, tt:6487.155\n",
      "Ep:98, loss:0.00002, loss_test:0.11292, lr:5.15e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.181, tt:6551.876\n",
      "Ep:99, loss:0.00002, loss_test:0.11724, lr:5.10e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.181, tt:6618.063\n",
      "Ep:100, loss:0.00002, loss_test:0.11154, lr:5.05e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.172, tt:6683.390\n",
      "Ep:101, loss:0.00002, loss_test:0.11724, lr:5.00e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.181, tt:6750.428\n",
      "Ep:102, loss:0.00001, loss_test:0.11402, lr:4.95e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.169, tt:6815.392\n",
      "Ep:103, loss:0.00001, loss_test:0.11578, lr:4.90e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.156, tt:6880.176\n",
      "Ep:104, loss:0.00001, loss_test:0.11483, lr:4.85e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.170, tt:6947.804\n",
      "Ep:105, loss:0.00001, loss_test:0.11410, lr:4.80e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.161, tt:7013.063\n",
      "Ep:106, loss:0.00001, loss_test:0.11542, lr:4.75e-03, fs:0.65359 (r=0.505,p=0.926),  time:66.105, tt:7073.287\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14416, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.644, tt:9.644\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14398, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.078, tt:24.157\n",
      "Ep:2, loss:0.00014, loss_test:0.14372, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.795, tt:38.384\n",
      "Ep:3, loss:0.00014, loss_test:0.14336, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.147, tt:52.587\n",
      "Ep:4, loss:0.00014, loss_test:0.14289, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.624, tt:68.120\n",
      "Ep:5, loss:0.00014, loss_test:0.14229, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.815, tt:82.891\n",
      "Ep:6, loss:0.00014, loss_test:0.14157, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.091, tt:98.635\n",
      "Ep:7, loss:0.00014, loss_test:0.14074, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.309, tt:114.470\n",
      "Ep:8, loss:0.00014, loss_test:0.13976, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.303, tt:128.731\n",
      "Ep:9, loss:0.00014, loss_test:0.13857, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:14.382, tt:143.822\n",
      "Ep:10, loss:0.00014, loss_test:0.13717, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:14.339, tt:157.725\n",
      "Ep:11, loss:0.00013, loss_test:0.13546, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:14.417, tt:173.005\n",
      "Ep:12, loss:0.00013, loss_test:0.13333, lr:9.90e-03, fs:0.65972 (r=0.960,p=0.503),  time:14.665, tt:190.651\n",
      "Ep:13, loss:0.00013, loss_test:0.13090, lr:9.80e-03, fs:0.65248 (r=0.929,p=0.503),  time:14.684, tt:205.582\n",
      "Ep:14, loss:0.00013, loss_test:0.12818, lr:9.70e-03, fs:0.66423 (r=0.919,p=0.520),  time:14.704, tt:220.562\n",
      "Ep:15, loss:0.00012, loss_test:0.12528, lr:9.61e-03, fs:0.66929 (r=0.859,p=0.548),  time:14.732, tt:235.705\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00012, loss_test:0.12216, lr:9.61e-03, fs:0.68595 (r=0.838,p=0.580),  time:14.773, tt:251.138\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00012, loss_test:0.11945, lr:9.61e-03, fs:0.64840 (r=0.717,p=0.592),  time:14.647, tt:263.642\n",
      "Ep:18, loss:0.00011, loss_test:0.11869, lr:9.61e-03, fs:0.63810 (r=0.677,p=0.604),  time:14.641, tt:278.181\n",
      "Ep:19, loss:0.00011, loss_test:0.11820, lr:9.61e-03, fs:0.63415 (r=0.657,p=0.613),  time:14.649, tt:292.980\n",
      "Ep:20, loss:0.00011, loss_test:0.11774, lr:9.61e-03, fs:0.63682 (r=0.646,p=0.627),  time:14.679, tt:308.263\n",
      "Ep:21, loss:0.00011, loss_test:0.11717, lr:9.61e-03, fs:0.64078 (r=0.667,p=0.617),  time:14.732, tt:324.113\n",
      "Ep:22, loss:0.00011, loss_test:0.11659, lr:9.61e-03, fs:0.65094 (r=0.697,p=0.611),  time:14.718, tt:338.508\n",
      "Ep:23, loss:0.00011, loss_test:0.11623, lr:9.61e-03, fs:0.65116 (r=0.707,p=0.603),  time:14.757, tt:354.167\n",
      "Ep:24, loss:0.00010, loss_test:0.11585, lr:9.61e-03, fs:0.66972 (r=0.737,p=0.613),  time:14.762, tt:369.051\n",
      "Ep:25, loss:0.00010, loss_test:0.11511, lr:9.61e-03, fs:0.67580 (r=0.747,p=0.617),  time:14.808, tt:385.011\n",
      "Ep:26, loss:0.00010, loss_test:0.11391, lr:9.61e-03, fs:0.67580 (r=0.747,p=0.617),  time:14.776, tt:398.942\n",
      "Ep:27, loss:0.00010, loss_test:0.11250, lr:9.61e-03, fs:0.66977 (r=0.727,p=0.621),  time:14.789, tt:414.101\n",
      "Ep:28, loss:0.00010, loss_test:0.11137, lr:9.51e-03, fs:0.66667 (r=0.717,p=0.623),  time:14.832, tt:430.116\n",
      "Ep:29, loss:0.00010, loss_test:0.11060, lr:9.41e-03, fs:0.68269 (r=0.717,p=0.651),  time:14.837, tt:445.111\n",
      "Ep:30, loss:0.00010, loss_test:0.11002, lr:9.32e-03, fs:0.69268 (r=0.717,p=0.670),  time:14.811, tt:459.134\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.10944, lr:9.32e-03, fs:0.68966 (r=0.707,p=0.673),  time:14.817, tt:474.151\n",
      "Ep:32, loss:0.00009, loss_test:0.10879, lr:9.32e-03, fs:0.68293 (r=0.707,p=0.660),  time:14.822, tt:489.125\n",
      "Ep:33, loss:0.00009, loss_test:0.10804, lr:9.32e-03, fs:0.67961 (r=0.707,p=0.654),  time:14.817, tt:503.792\n",
      "Ep:34, loss:0.00009, loss_test:0.10733, lr:9.32e-03, fs:0.67633 (r=0.707,p=0.648),  time:14.788, tt:517.579\n",
      "Ep:35, loss:0.00009, loss_test:0.10660, lr:9.32e-03, fs:0.69194 (r=0.737,p=0.652),  time:14.789, tt:532.390\n",
      "Ep:36, loss:0.00009, loss_test:0.10585, lr:9.32e-03, fs:0.69524 (r=0.737,p=0.658),  time:14.744, tt:545.533\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.10515, lr:9.32e-03, fs:0.69524 (r=0.737,p=0.658),  time:14.724, tt:559.499\n",
      "Ep:38, loss:0.00009, loss_test:0.10450, lr:9.32e-03, fs:0.69903 (r=0.727,p=0.673),  time:14.718, tt:573.994\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.10391, lr:9.32e-03, fs:0.69608 (r=0.717,p=0.676),  time:14.696, tt:587.855\n",
      "Ep:40, loss:0.00008, loss_test:0.10325, lr:9.32e-03, fs:0.70647 (r=0.717,p=0.696),  time:14.703, tt:602.805\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.10239, lr:9.32e-03, fs:0.70647 (r=0.717,p=0.696),  time:14.682, tt:616.648\n",
      "Ep:42, loss:0.00008, loss_test:0.10150, lr:9.32e-03, fs:0.71921 (r=0.737,p=0.702),  time:14.662, tt:630.456\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.10065, lr:9.32e-03, fs:0.71921 (r=0.737,p=0.702),  time:14.643, tt:644.279\n",
      "Ep:44, loss:0.00008, loss_test:0.09998, lr:9.32e-03, fs:0.71921 (r=0.737,p=0.702),  time:14.613, tt:657.585\n",
      "Ep:45, loss:0.00008, loss_test:0.09936, lr:9.32e-03, fs:0.72277 (r=0.737,p=0.709),  time:14.627, tt:672.824\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.09879, lr:9.32e-03, fs:0.71000 (r=0.717,p=0.703),  time:14.634, tt:687.817\n",
      "Ep:47, loss:0.00008, loss_test:0.09830, lr:9.32e-03, fs:0.72000 (r=0.727,p=0.713),  time:14.623, tt:701.907\n",
      "Ep:48, loss:0.00008, loss_test:0.09787, lr:9.32e-03, fs:0.73632 (r=0.747,p=0.725),  time:14.642, tt:717.470\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.09741, lr:9.32e-03, fs:0.74257 (r=0.758,p=0.728),  time:14.642, tt:732.087\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.09691, lr:9.32e-03, fs:0.74000 (r=0.747,p=0.733),  time:14.641, tt:746.688\n",
      "Ep:51, loss:0.00007, loss_test:0.09636, lr:9.32e-03, fs:0.74372 (r=0.747,p=0.740),  time:14.660, tt:762.307\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.09575, lr:9.32e-03, fs:0.74372 (r=0.747,p=0.740),  time:14.657, tt:776.804\n",
      "Ep:53, loss:0.00007, loss_test:0.09519, lr:9.32e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.677, tt:792.571\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.09459, lr:9.32e-03, fs:0.75377 (r=0.758,p=0.750),  time:14.695, tt:808.250\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.09404, lr:9.32e-03, fs:0.75248 (r=0.768,p=0.738),  time:14.692, tt:822.728\n",
      "Ep:56, loss:0.00007, loss_test:0.09365, lr:9.32e-03, fs:0.75248 (r=0.768,p=0.738),  time:14.678, tt:836.672\n",
      "Ep:57, loss:0.00007, loss_test:0.09340, lr:9.32e-03, fs:0.75622 (r=0.768,p=0.745),  time:14.696, tt:852.351\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.09316, lr:9.32e-03, fs:0.75000 (r=0.758,p=0.743),  time:14.704, tt:867.565\n",
      "Ep:59, loss:0.00006, loss_test:0.09287, lr:9.32e-03, fs:0.74747 (r=0.747,p=0.747),  time:14.717, tt:883.048\n",
      "Ep:60, loss:0.00006, loss_test:0.09247, lr:9.32e-03, fs:0.76142 (r=0.758,p=0.765),  time:14.706, tt:897.088\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.09193, lr:9.32e-03, fs:0.76289 (r=0.747,p=0.779),  time:14.705, tt:911.739\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.09139, lr:9.32e-03, fs:0.76289 (r=0.747,p=0.779),  time:14.720, tt:927.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.09087, lr:9.32e-03, fs:0.76289 (r=0.747,p=0.779),  time:14.729, tt:942.654\n",
      "Ep:64, loss:0.00006, loss_test:0.09040, lr:9.32e-03, fs:0.77551 (r=0.768,p=0.784),  time:14.733, tt:957.621\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.08994, lr:9.32e-03, fs:0.77551 (r=0.768,p=0.784),  time:14.746, tt:973.237\n",
      "Ep:66, loss:0.00006, loss_test:0.08958, lr:9.32e-03, fs:0.76923 (r=0.758,p=0.781),  time:14.736, tt:987.324\n",
      "Ep:67, loss:0.00006, loss_test:0.08929, lr:9.32e-03, fs:0.76923 (r=0.758,p=0.781),  time:14.757, tt:1003.463\n",
      "Ep:68, loss:0.00006, loss_test:0.08906, lr:9.32e-03, fs:0.76923 (r=0.758,p=0.781),  time:14.753, tt:1017.959\n",
      "Ep:69, loss:0.00006, loss_test:0.08887, lr:9.32e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.762, tt:1033.354\n",
      "Ep:70, loss:0.00006, loss_test:0.08861, lr:9.32e-03, fs:0.76531 (r=0.758,p=0.773),  time:14.784, tt:1049.673\n",
      "Ep:71, loss:0.00006, loss_test:0.08822, lr:9.32e-03, fs:0.76531 (r=0.758,p=0.773),  time:14.815, tt:1066.657\n",
      "Ep:72, loss:0.00006, loss_test:0.08780, lr:9.32e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.825, tt:1082.241\n",
      "Ep:73, loss:0.00005, loss_test:0.08742, lr:9.32e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.829, tt:1097.316\n",
      "Ep:74, loss:0.00005, loss_test:0.08714, lr:9.32e-03, fs:0.77778 (r=0.778,p=0.778),  time:14.834, tt:1112.545\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.08688, lr:9.32e-03, fs:0.77778 (r=0.778,p=0.778),  time:14.848, tt:1128.465\n",
      "Ep:76, loss:0.00005, loss_test:0.08663, lr:9.32e-03, fs:0.77778 (r=0.778,p=0.778),  time:14.857, tt:1144.000\n",
      "Ep:77, loss:0.00005, loss_test:0.08642, lr:9.32e-03, fs:0.77551 (r=0.768,p=0.784),  time:14.860, tt:1159.088\n",
      "Ep:78, loss:0.00005, loss_test:0.08617, lr:9.32e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.868, tt:1174.546\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00005, loss_test:0.08582, lr:9.32e-03, fs:0.78571 (r=0.778,p=0.794),  time:14.888, tt:1191.053\n",
      "Ep:80, loss:0.00005, loss_test:0.08560, lr:9.32e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.897, tt:1206.640\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00005, loss_test:0.08552, lr:9.32e-03, fs:0.79381 (r=0.778,p=0.811),  time:14.898, tt:1221.622\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00005, loss_test:0.08538, lr:9.32e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.916, tt:1238.060\n",
      "Ep:83, loss:0.00005, loss_test:0.08513, lr:9.32e-03, fs:0.78351 (r=0.768,p=0.800),  time:14.920, tt:1253.239\n",
      "Ep:84, loss:0.00005, loss_test:0.08489, lr:9.32e-03, fs:0.78351 (r=0.768,p=0.800),  time:14.920, tt:1268.164\n",
      "Ep:85, loss:0.00005, loss_test:0.08475, lr:9.32e-03, fs:0.79381 (r=0.778,p=0.811),  time:14.924, tt:1283.460\n",
      "Ep:86, loss:0.00005, loss_test:0.08450, lr:9.32e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.929, tt:1298.799\n",
      "Ep:87, loss:0.00005, loss_test:0.08415, lr:9.32e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.928, tt:1313.629\n",
      "Ep:88, loss:0.00005, loss_test:0.08367, lr:9.32e-03, fs:0.78974 (r=0.778,p=0.802),  time:14.936, tt:1329.336\n",
      "Ep:89, loss:0.00004, loss_test:0.08346, lr:9.32e-03, fs:0.79381 (r=0.778,p=0.811),  time:14.943, tt:1344.871\n",
      "Ep:90, loss:0.00004, loss_test:0.08327, lr:9.32e-03, fs:0.79381 (r=0.778,p=0.811),  time:14.951, tt:1360.518\n",
      "Ep:91, loss:0.00004, loss_test:0.08328, lr:9.32e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.947, tt:1375.134\n",
      "Ep:92, loss:0.00004, loss_test:0.08324, lr:9.32e-03, fs:0.79167 (r=0.768,p=0.817),  time:14.937, tt:1389.145\n",
      "Ep:93, loss:0.00004, loss_test:0.08301, lr:9.23e-03, fs:0.78351 (r=0.768,p=0.800),  time:14.947, tt:1405.037\n",
      "Ep:94, loss:0.00004, loss_test:0.08303, lr:9.14e-03, fs:0.79581 (r=0.768,p=0.826),  time:14.964, tt:1421.568\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00004, loss_test:0.08284, lr:9.14e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.975, tt:1437.564\n",
      "Ep:96, loss:0.00004, loss_test:0.08260, lr:9.14e-03, fs:0.78571 (r=0.778,p=0.794),  time:14.984, tt:1453.491\n",
      "Ep:97, loss:0.00004, loss_test:0.08243, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:14.985, tt:1468.487\n",
      "Ep:98, loss:0.00004, loss_test:0.08216, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:14.989, tt:1483.937\n",
      "Ep:99, loss:0.00004, loss_test:0.08198, lr:9.14e-03, fs:0.78756 (r=0.768,p=0.809),  time:14.993, tt:1499.252\n",
      "Ep:100, loss:0.00004, loss_test:0.08192, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:14.990, tt:1514.024\n",
      "Ep:101, loss:0.00004, loss_test:0.08181, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:14.991, tt:1529.070\n",
      "Ep:102, loss:0.00004, loss_test:0.08160, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:14.999, tt:1544.889\n",
      "Ep:103, loss:0.00004, loss_test:0.08149, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:15.011, tt:1561.093\n",
      "Ep:104, loss:0.00004, loss_test:0.08156, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:15.019, tt:1577.033\n",
      "Ep:105, loss:0.00004, loss_test:0.08155, lr:9.14e-03, fs:0.79167 (r=0.768,p=0.817),  time:15.032, tt:1593.365\n",
      "Ep:106, loss:0.00004, loss_test:0.08149, lr:9.04e-03, fs:0.79167 (r=0.768,p=0.817),  time:15.039, tt:1609.136\n",
      "Ep:107, loss:0.00004, loss_test:0.08152, lr:8.95e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.042, tt:1624.588\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00004, loss_test:0.08147, lr:8.95e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.034, tt:1638.678\n",
      "Ep:109, loss:0.00004, loss_test:0.08135, lr:8.95e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.036, tt:1653.997\n",
      "Ep:110, loss:0.00004, loss_test:0.08126, lr:8.95e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.038, tt:1669.226\n",
      "Ep:111, loss:0.00004, loss_test:0.08125, lr:8.95e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.044, tt:1684.962\n",
      "Ep:112, loss:0.00004, loss_test:0.08110, lr:8.95e-03, fs:0.80000 (r=0.768,p=0.835),  time:15.047, tt:1700.290\n",
      "Ep:113, loss:0.00003, loss_test:0.08120, lr:8.95e-03, fs:0.80423 (r=0.768,p=0.844),  time:15.055, tt:1716.252\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00003, loss_test:0.08104, lr:8.95e-03, fs:0.80423 (r=0.768,p=0.844),  time:15.051, tt:1730.906\n",
      "Ep:115, loss:0.00003, loss_test:0.08101, lr:8.95e-03, fs:0.80423 (r=0.768,p=0.844),  time:15.057, tt:1746.647\n",
      "Ep:116, loss:0.00003, loss_test:0.08105, lr:8.95e-03, fs:0.80851 (r=0.768,p=0.854),  time:15.058, tt:1761.747\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00003, loss_test:0.08107, lr:8.95e-03, fs:0.80851 (r=0.768,p=0.854),  time:15.058, tt:1776.833\n",
      "Ep:118, loss:0.00003, loss_test:0.08087, lr:8.95e-03, fs:0.80851 (r=0.768,p=0.854),  time:15.065, tt:1792.736\n",
      "Ep:119, loss:0.00003, loss_test:0.08109, lr:8.95e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.080, tt:1809.546\n",
      "Ep:120, loss:0.00003, loss_test:0.08086, lr:8.95e-03, fs:0.80851 (r=0.768,p=0.854),  time:15.083, tt:1825.061\n",
      "Ep:121, loss:0.00003, loss_test:0.08080, lr:8.95e-03, fs:0.81283 (r=0.768,p=0.864),  time:15.082, tt:1839.948\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00003, loss_test:0.08136, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.080, tt:1854.880\n",
      "Ep:123, loss:0.00003, loss_test:0.08107, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.089, tt:1871.063\n",
      "Ep:124, loss:0.00003, loss_test:0.08074, lr:8.95e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.086, tt:1885.807\n",
      "Ep:125, loss:0.00003, loss_test:0.08111, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.088, tt:1901.078\n",
      "Ep:126, loss:0.00003, loss_test:0.08144, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.087, tt:1916.037\n",
      "Ep:127, loss:0.00003, loss_test:0.08111, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.085, tt:1930.880\n",
      "Ep:128, loss:0.00003, loss_test:0.08091, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.092, tt:1946.883\n",
      "Ep:129, loss:0.00003, loss_test:0.08075, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.100, tt:1962.942\n",
      "Ep:130, loss:0.00003, loss_test:0.08070, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.100, tt:1978.077\n",
      "Ep:131, loss:0.00003, loss_test:0.08067, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.101, tt:1993.293\n",
      "Ep:132, loss:0.00003, loss_test:0.08103, lr:8.95e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.092, tt:2007.292\n",
      "Ep:133, loss:0.00003, loss_test:0.08068, lr:8.86e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.094, tt:2022.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00003, loss_test:0.08049, lr:8.78e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.104, tt:2039.020\n",
      "Ep:135, loss:0.00003, loss_test:0.08132, lr:8.69e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.108, tt:2054.691\n",
      "Ep:136, loss:0.00003, loss_test:0.08155, lr:8.60e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.108, tt:2069.762\n",
      "Ep:137, loss:0.00003, loss_test:0.08077, lr:8.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.102, tt:2084.013\n",
      "Ep:138, loss:0.00003, loss_test:0.08060, lr:8.43e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.103, tt:2099.292\n",
      "Ep:139, loss:0.00003, loss_test:0.08112, lr:8.35e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.103, tt:2114.430\n",
      "Ep:140, loss:0.00003, loss_test:0.08101, lr:8.26e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.100, tt:2129.065\n",
      "Ep:141, loss:0.00003, loss_test:0.08050, lr:8.18e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.095, tt:2143.554\n",
      "Ep:142, loss:0.00003, loss_test:0.08057, lr:8.10e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.094, tt:2158.432\n",
      "Ep:143, loss:0.00003, loss_test:0.08124, lr:8.02e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.092, tt:2173.203\n",
      "Ep:144, loss:0.00003, loss_test:0.08112, lr:7.94e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.134, tt:2194.426\n",
      "Ep:145, loss:0.00003, loss_test:0.08050, lr:7.86e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.138, tt:2210.081\n",
      "Ep:146, loss:0.00003, loss_test:0.08071, lr:7.78e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.136, tt:2224.964\n",
      "Ep:147, loss:0.00003, loss_test:0.08204, lr:7.70e-03, fs:0.80874 (r=0.747,p=0.881),  time:15.134, tt:2239.840\n",
      "Ep:148, loss:0.00003, loss_test:0.08209, lr:7.62e-03, fs:0.81319 (r=0.747,p=0.892),  time:15.128, tt:2254.067\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00003, loss_test:0.08054, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.114, tt:2267.087\n",
      "Ep:150, loss:0.00002, loss_test:0.08038, lr:7.62e-03, fs:0.79144 (r=0.747,p=0.841),  time:15.095, tt:2279.375\n",
      "Ep:151, loss:0.00002, loss_test:0.08097, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.090, tt:2293.716\n",
      "Ep:152, loss:0.00002, loss_test:0.08171, lr:7.62e-03, fs:0.81319 (r=0.747,p=0.892),  time:15.079, tt:2307.083\n",
      "Ep:153, loss:0.00002, loss_test:0.08089, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.070, tt:2320.756\n",
      "Ep:154, loss:0.00002, loss_test:0.08045, lr:7.62e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.059, tt:2334.212\n",
      "Ep:155, loss:0.00002, loss_test:0.08067, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.052, tt:2348.048\n",
      "Ep:156, loss:0.00002, loss_test:0.08147, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.036, tt:2360.654\n",
      "Ep:157, loss:0.00002, loss_test:0.08114, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.023, tt:2373.602\n",
      "Ep:158, loss:0.00002, loss_test:0.08035, lr:7.62e-03, fs:0.80000 (r=0.747,p=0.860),  time:15.015, tt:2387.420\n",
      "Ep:159, loss:0.00002, loss_test:0.08059, lr:7.62e-03, fs:0.79570 (r=0.747,p=0.851),  time:15.001, tt:2400.175\n",
      "Ep:160, loss:0.00002, loss_test:0.08120, lr:7.55e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.986, tt:2412.730\n",
      "Ep:161, loss:0.00002, loss_test:0.08106, lr:7.47e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.971, tt:2425.261\n",
      "Ep:162, loss:0.00002, loss_test:0.08036, lr:7.40e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.955, tt:2437.596\n",
      "Ep:163, loss:0.00002, loss_test:0.08045, lr:7.32e-03, fs:0.79570 (r=0.747,p=0.851),  time:14.935, tt:2449.399\n",
      "Ep:164, loss:0.00002, loss_test:0.08102, lr:7.25e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.921, tt:2462.001\n",
      "Ep:165, loss:0.00002, loss_test:0.08112, lr:7.18e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.900, tt:2473.412\n",
      "Ep:166, loss:0.00002, loss_test:0.08037, lr:7.11e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.891, tt:2486.811\n",
      "Ep:167, loss:0.00002, loss_test:0.08028, lr:7.03e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.875, tt:2498.935\n",
      "Ep:168, loss:0.00002, loss_test:0.08076, lr:6.96e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.865, tt:2512.257\n",
      "Ep:169, loss:0.00002, loss_test:0.08080, lr:6.89e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.850, tt:2524.557\n",
      "Ep:170, loss:0.00002, loss_test:0.08027, lr:6.83e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.838, tt:2537.238\n",
      "Ep:171, loss:0.00002, loss_test:0.08032, lr:6.76e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.825, tt:2549.951\n",
      "Ep:172, loss:0.00002, loss_test:0.08090, lr:6.69e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.816, tt:2563.214\n",
      "Ep:173, loss:0.00002, loss_test:0.08052, lr:6.62e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.804, tt:2575.978\n",
      "Ep:174, loss:0.00002, loss_test:0.08010, lr:6.56e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.792, tt:2588.657\n",
      "Ep:175, loss:0.00002, loss_test:0.08044, lr:6.49e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.781, tt:2601.500\n",
      "Ep:176, loss:0.00002, loss_test:0.08101, lr:6.43e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.764, tt:2613.228\n",
      "Ep:177, loss:0.00002, loss_test:0.08063, lr:6.36e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.758, tt:2626.944\n",
      "Ep:178, loss:0.00002, loss_test:0.08051, lr:6.30e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.738, tt:2638.121\n",
      "Ep:179, loss:0.00002, loss_test:0.08053, lr:6.24e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.733, tt:2652.025\n",
      "Ep:180, loss:0.00002, loss_test:0.08009, lr:6.17e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.725, tt:2665.209\n",
      "Ep:181, loss:0.00002, loss_test:0.08014, lr:6.11e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.723, tt:2679.571\n",
      "Ep:182, loss:0.00002, loss_test:0.08082, lr:6.05e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.722, tt:2694.082\n",
      "Ep:183, loss:0.00002, loss_test:0.08057, lr:5.99e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.720, tt:2708.509\n",
      "Ep:184, loss:0.00002, loss_test:0.07984, lr:5.93e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.716, tt:2722.432\n",
      "Ep:185, loss:0.00002, loss_test:0.08012, lr:5.87e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.709, tt:2735.887\n",
      "Ep:186, loss:0.00002, loss_test:0.08092, lr:5.81e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.708, tt:2750.325\n",
      "Ep:187, loss:0.00002, loss_test:0.08075, lr:5.75e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.702, tt:2763.892\n",
      "Ep:188, loss:0.00002, loss_test:0.07999, lr:5.70e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.693, tt:2777.024\n",
      "Ep:189, loss:0.00002, loss_test:0.08006, lr:5.64e-03, fs:0.80000 (r=0.747,p=0.860),  time:14.685, tt:2790.203\n",
      "Ep:190, loss:0.00002, loss_test:0.08046, lr:5.58e-03, fs:0.80874 (r=0.747,p=0.881),  time:14.693, tt:2806.363\n",
      "Ep:191, loss:0.00002, loss_test:0.08048, lr:5.53e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.683, tt:2819.162\n",
      "Ep:192, loss:0.00002, loss_test:0.08018, lr:5.47e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.675, tt:2832.346\n",
      "Ep:193, loss:0.00002, loss_test:0.08009, lr:5.42e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.669, tt:2845.749\n",
      "Ep:194, loss:0.00002, loss_test:0.07994, lr:5.36e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.657, tt:2858.101\n",
      "Ep:195, loss:0.00002, loss_test:0.07991, lr:5.31e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.653, tt:2871.964\n",
      "Ep:196, loss:0.00002, loss_test:0.08028, lr:5.26e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.642, tt:2884.453\n",
      "Ep:197, loss:0.00002, loss_test:0.08045, lr:5.20e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.630, tt:2896.712\n",
      "Ep:198, loss:0.00002, loss_test:0.08008, lr:5.15e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.614, tt:2908.156\n",
      "Ep:199, loss:0.00002, loss_test:0.07979, lr:5.10e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.604, tt:2920.807\n",
      "Ep:200, loss:0.00002, loss_test:0.08033, lr:5.05e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.597, tt:2933.912\n",
      "Ep:201, loss:0.00002, loss_test:0.08050, lr:5.00e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.585, tt:2946.227\n",
      "Ep:202, loss:0.00002, loss_test:0.08000, lr:4.95e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.572, tt:2958.118\n",
      "Ep:203, loss:0.00002, loss_test:0.07976, lr:4.90e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.561, tt:2970.433\n",
      "Ep:204, loss:0.00002, loss_test:0.08007, lr:4.85e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.545, tt:2981.744\n",
      "Ep:205, loss:0.00002, loss_test:0.08009, lr:4.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.518, tt:2990.651\n",
      "Ep:206, loss:0.00002, loss_test:0.08031, lr:4.75e-03, fs:0.80435 (r=0.747,p=0.871),  time:14.492, tt:2999.780\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14564, lr:1.00e-02, fs:0.67081 (r=1.000,p=0.505),  time:22.136, tt:22.136\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14474, lr:1.00e-02, fs:0.66250 (r=0.981,p=0.500),  time:26.149, tt:52.298\n",
      "Ep:2, loss:0.00027, loss_test:0.14282, lr:1.00e-02, fs:0.64968 (r=0.944,p=0.495),  time:28.209, tt:84.626\n",
      "Ep:3, loss:0.00026, loss_test:0.13951, lr:1.00e-02, fs:0.64052 (r=0.907,p=0.495),  time:29.106, tt:116.426\n",
      "Ep:4, loss:0.00025, loss_test:0.13548, lr:1.00e-02, fs:0.64179 (r=0.796,p=0.537),  time:29.759, tt:148.797\n",
      "Ep:5, loss:0.00024, loss_test:0.13180, lr:1.00e-02, fs:0.57407 (r=0.574,p=0.574),  time:29.785, tt:178.713\n",
      "Ep:6, loss:0.00023, loss_test:0.13027, lr:1.00e-02, fs:0.58252 (r=0.556,p=0.612),  time:29.917, tt:209.416\n",
      "Ep:7, loss:0.00022, loss_test:0.12663, lr:1.00e-02, fs:0.57944 (r=0.574,p=0.585),  time:30.243, tt:241.945\n",
      "Ep:8, loss:0.00022, loss_test:0.12513, lr:1.00e-02, fs:0.62069 (r=0.667,p=0.581),  time:30.496, tt:274.460\n",
      "Ep:9, loss:0.00021, loss_test:0.12342, lr:1.00e-02, fs:0.57143 (r=0.556,p=0.588),  time:30.808, tt:308.075\n",
      "Ep:10, loss:0.00020, loss_test:0.12408, lr:1.00e-02, fs:0.57732 (r=0.519,p=0.651),  time:31.026, tt:341.286\n",
      "Ep:11, loss:0.00020, loss_test:0.12039, lr:1.00e-02, fs:0.61111 (r=0.611,p=0.611),  time:31.026, tt:372.318\n",
      "Ep:12, loss:0.00019, loss_test:0.11734, lr:9.90e-03, fs:0.64286 (r=0.667,p=0.621),  time:31.038, tt:403.493\n",
      "Ep:13, loss:0.00019, loss_test:0.11553, lr:9.80e-03, fs:0.63636 (r=0.648,p=0.625),  time:31.165, tt:436.304\n",
      "Ep:14, loss:0.00018, loss_test:0.11504, lr:9.70e-03, fs:0.62745 (r=0.593,p=0.667),  time:31.206, tt:468.091\n",
      "Ep:15, loss:0.00018, loss_test:0.11210, lr:9.61e-03, fs:0.65421 (r=0.648,p=0.660),  time:31.304, tt:500.870\n",
      "Ep:16, loss:0.00017, loss_test:0.10999, lr:9.51e-03, fs:0.70175 (r=0.741,p=0.667),  time:31.296, tt:532.034\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10972, lr:9.51e-03, fs:0.66667 (r=0.648,p=0.686),  time:31.394, tt:565.084\n",
      "Ep:18, loss:0.00017, loss_test:0.10809, lr:9.51e-03, fs:0.68519 (r=0.685,p=0.685),  time:31.360, tt:595.831\n",
      "Ep:19, loss:0.00016, loss_test:0.10578, lr:9.51e-03, fs:0.69725 (r=0.704,p=0.691),  time:31.411, tt:628.210\n",
      "Ep:20, loss:0.00016, loss_test:0.10447, lr:9.51e-03, fs:0.69159 (r=0.685,p=0.698),  time:31.461, tt:660.689\n",
      "Ep:21, loss:0.00015, loss_test:0.10320, lr:9.51e-03, fs:0.69159 (r=0.685,p=0.698),  time:31.533, tt:693.725\n",
      "Ep:22, loss:0.00015, loss_test:0.10099, lr:9.51e-03, fs:0.72727 (r=0.741,p=0.714),  time:31.574, tt:726.193\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09944, lr:9.51e-03, fs:0.72897 (r=0.722,p=0.736),  time:31.631, tt:759.147\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09783, lr:9.51e-03, fs:0.74074 (r=0.741,p=0.741),  time:31.661, tt:791.519\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09537, lr:9.51e-03, fs:0.77477 (r=0.796,p=0.754),  time:31.677, tt:823.594\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09397, lr:9.51e-03, fs:0.77477 (r=0.796,p=0.754),  time:31.706, tt:856.053\n",
      "Ep:27, loss:0.00013, loss_test:0.09297, lr:9.51e-03, fs:0.77778 (r=0.778,p=0.778),  time:31.697, tt:887.514\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09022, lr:9.51e-03, fs:0.78571 (r=0.815,p=0.759),  time:31.708, tt:919.527\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08953, lr:9.51e-03, fs:0.78899 (r=0.796,p=0.782),  time:31.717, tt:951.499\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08756, lr:9.51e-03, fs:0.78899 (r=0.796,p=0.782),  time:31.729, tt:983.603\n",
      "Ep:31, loss:0.00012, loss_test:0.08532, lr:9.51e-03, fs:0.77477 (r=0.796,p=0.754),  time:31.723, tt:1015.146\n",
      "Ep:32, loss:0.00012, loss_test:0.08551, lr:9.51e-03, fs:0.80374 (r=0.796,p=0.811),  time:31.728, tt:1047.028\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08220, lr:9.51e-03, fs:0.80374 (r=0.796,p=0.811),  time:31.764, tt:1079.978\n",
      "Ep:34, loss:0.00012, loss_test:0.08022, lr:9.51e-03, fs:0.78899 (r=0.796,p=0.782),  time:31.779, tt:1112.272\n",
      "Ep:35, loss:0.00011, loss_test:0.08018, lr:9.51e-03, fs:0.81132 (r=0.796,p=0.827),  time:31.804, tt:1144.939\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07805, lr:9.51e-03, fs:0.80734 (r=0.815,p=0.800),  time:31.818, tt:1177.264\n",
      "Ep:37, loss:0.00011, loss_test:0.07680, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.846, tt:1210.166\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.07598, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.825, tt:1241.191\n",
      "Ep:39, loss:0.00010, loss_test:0.07410, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.836, tt:1273.429\n",
      "Ep:40, loss:0.00010, loss_test:0.07389, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.856, tt:1306.113\n",
      "Ep:41, loss:0.00010, loss_test:0.07179, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.873, tt:1338.674\n",
      "Ep:42, loss:0.00010, loss_test:0.07089, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.889, tt:1371.221\n",
      "Ep:43, loss:0.00010, loss_test:0.06933, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.873, tt:1402.397\n",
      "Ep:44, loss:0.00009, loss_test:0.06863, lr:9.51e-03, fs:0.82243 (r=0.815,p=0.830),  time:31.882, tt:1434.704\n",
      "Ep:45, loss:0.00009, loss_test:0.06753, lr:9.51e-03, fs:0.83333 (r=0.833,p=0.833),  time:31.899, tt:1467.355\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.06651, lr:9.51e-03, fs:0.84112 (r=0.833,p=0.849),  time:31.903, tt:1499.461\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.06591, lr:9.51e-03, fs:0.84112 (r=0.833,p=0.849),  time:31.951, tt:1533.658\n",
      "Ep:48, loss:0.00009, loss_test:0.06411, lr:9.51e-03, fs:0.83333 (r=0.833,p=0.833),  time:31.931, tt:1564.608\n",
      "Ep:49, loss:0.00008, loss_test:0.06512, lr:9.51e-03, fs:0.83019 (r=0.815,p=0.846),  time:31.967, tt:1598.371\n",
      "Ep:50, loss:0.00008, loss_test:0.06241, lr:9.51e-03, fs:0.84112 (r=0.833,p=0.849),  time:31.990, tt:1631.490\n",
      "Ep:51, loss:0.00008, loss_test:0.06180, lr:9.51e-03, fs:0.84112 (r=0.833,p=0.849),  time:32.009, tt:1664.489\n",
      "Ep:52, loss:0.00008, loss_test:0.06173, lr:9.51e-03, fs:0.83810 (r=0.815,p=0.863),  time:32.016, tt:1696.825\n",
      "Ep:53, loss:0.00008, loss_test:0.06008, lr:9.51e-03, fs:0.84112 (r=0.833,p=0.849),  time:32.028, tt:1729.493\n",
      "Ep:54, loss:0.00008, loss_test:0.06041, lr:9.51e-03, fs:0.83810 (r=0.815,p=0.863),  time:32.036, tt:1761.993\n",
      "Ep:55, loss:0.00007, loss_test:0.05866, lr:9.51e-03, fs:0.85981 (r=0.852,p=0.868),  time:32.038, tt:1794.137\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.05846, lr:9.51e-03, fs:0.83810 (r=0.815,p=0.863),  time:32.034, tt:1825.953\n",
      "Ep:57, loss:0.00007, loss_test:0.05743, lr:9.51e-03, fs:0.87037 (r=0.870,p=0.870),  time:32.053, tt:1859.084\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.05751, lr:9.51e-03, fs:0.84906 (r=0.833,p=0.865),  time:32.013, tt:1888.743\n",
      "Ep:59, loss:0.00007, loss_test:0.05564, lr:9.51e-03, fs:0.88073 (r=0.889,p=0.873),  time:32.028, tt:1921.671\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00007, loss_test:0.05616, lr:9.51e-03, fs:0.84906 (r=0.833,p=0.865),  time:32.035, tt:1954.114\n",
      "Ep:61, loss:0.00007, loss_test:0.05416, lr:9.51e-03, fs:0.87037 (r=0.870,p=0.870),  time:32.026, tt:1985.621\n",
      "Ep:62, loss:0.00006, loss_test:0.05377, lr:9.51e-03, fs:0.87037 (r=0.870,p=0.870),  time:32.025, tt:2017.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.05386, lr:9.51e-03, fs:0.86792 (r=0.852,p=0.885),  time:32.022, tt:2049.376\n",
      "Ep:64, loss:0.00006, loss_test:0.05185, lr:9.51e-03, fs:0.88073 (r=0.889,p=0.873),  time:32.038, tt:2082.464\n",
      "Ep:65, loss:0.00006, loss_test:0.05228, lr:9.51e-03, fs:0.87850 (r=0.870,p=0.887),  time:32.055, tt:2115.648\n",
      "Ep:66, loss:0.00006, loss_test:0.05054, lr:9.51e-03, fs:0.89091 (r=0.907,p=0.875),  time:32.077, tt:2149.188\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00006, loss_test:0.05057, lr:9.51e-03, fs:0.87850 (r=0.870,p=0.887),  time:32.062, tt:2180.222\n",
      "Ep:68, loss:0.00006, loss_test:0.04982, lr:9.51e-03, fs:0.88073 (r=0.889,p=0.873),  time:32.059, tt:2212.105\n",
      "Ep:69, loss:0.00006, loss_test:0.04845, lr:9.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:32.039, tt:2242.728\n",
      "Ep:70, loss:0.00005, loss_test:0.04789, lr:9.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:32.026, tt:2273.873\n",
      "Ep:71, loss:0.00005, loss_test:0.04702, lr:9.51e-03, fs:0.89908 (r=0.907,p=0.891),  time:32.016, tt:2305.153\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.04672, lr:9.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:32.003, tt:2336.254\n",
      "Ep:73, loss:0.00005, loss_test:0.04610, lr:9.51e-03, fs:0.89908 (r=0.907,p=0.891),  time:32.014, tt:2369.058\n",
      "Ep:74, loss:0.00005, loss_test:0.04504, lr:9.51e-03, fs:0.89908 (r=0.907,p=0.891),  time:32.020, tt:2401.522\n",
      "Ep:75, loss:0.00005, loss_test:0.04485, lr:9.51e-03, fs:0.89908 (r=0.907,p=0.891),  time:32.038, tt:2434.895\n",
      "Ep:76, loss:0.00005, loss_test:0.04427, lr:9.51e-03, fs:0.90741 (r=0.907,p=0.907),  time:32.049, tt:2467.810\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.04321, lr:9.51e-03, fs:0.90909 (r=0.926,p=0.893),  time:32.044, tt:2499.443\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00005, loss_test:0.04296, lr:9.51e-03, fs:0.90741 (r=0.907,p=0.907),  time:32.045, tt:2531.559\n",
      "Ep:79, loss:0.00005, loss_test:0.04200, lr:9.51e-03, fs:0.90909 (r=0.926,p=0.893),  time:32.042, tt:2563.358\n",
      "Ep:80, loss:0.00004, loss_test:0.04176, lr:9.51e-03, fs:0.92453 (r=0.907,p=0.942),  time:32.035, tt:2594.827\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00004, loss_test:0.04076, lr:9.51e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.017, tt:2625.398\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00004, loss_test:0.04040, lr:9.51e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.034, tt:2658.843\n",
      "Ep:83, loss:0.00004, loss_test:0.03956, lr:9.51e-03, fs:0.92593 (r=0.926,p=0.926),  time:32.033, tt:2690.809\n",
      "Ep:84, loss:0.00004, loss_test:0.03854, lr:9.51e-03, fs:0.92727 (r=0.944,p=0.911),  time:32.042, tt:2723.576\n",
      "Ep:85, loss:0.00004, loss_test:0.03853, lr:9.51e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.056, tt:2756.775\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00004, loss_test:0.03783, lr:9.51e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.068, tt:2789.910\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00004, loss_test:0.03746, lr:9.51e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.089, tt:2823.814\n",
      "Ep:88, loss:0.00004, loss_test:0.03658, lr:9.51e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.098, tt:2856.752\n",
      "Ep:89, loss:0.00004, loss_test:0.03616, lr:9.51e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.096, tt:2888.600\n",
      "Ep:90, loss:0.00004, loss_test:0.03552, lr:9.51e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.114, tt:2922.391\n",
      "Ep:91, loss:0.00004, loss_test:0.03475, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.117, tt:2954.758\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.03429, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.127, tt:2987.777\n",
      "Ep:93, loss:0.00003, loss_test:0.03382, lr:9.51e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.153, tt:3022.385\n",
      "Ep:94, loss:0.00003, loss_test:0.03325, lr:9.51e-03, fs:0.93578 (r=0.944,p=0.927),  time:32.151, tt:3054.368\n",
      "Ep:95, loss:0.00003, loss_test:0.03324, lr:9.51e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.155, tt:3086.879\n",
      "Ep:96, loss:0.00003, loss_test:0.03212, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.194, tt:3122.830\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00003, loss_test:0.03188, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.224, tt:3157.997\n",
      "Ep:98, loss:0.00003, loss_test:0.03135, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.243, tt:3192.103\n",
      "Ep:99, loss:0.00003, loss_test:0.03108, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.256, tt:3225.590\n",
      "Ep:100, loss:0.00003, loss_test:0.03039, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.265, tt:3258.804\n",
      "Ep:101, loss:0.00003, loss_test:0.03023, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.280, tt:3292.520\n",
      "Ep:102, loss:0.00003, loss_test:0.02951, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.264, tt:3323.230\n",
      "Ep:103, loss:0.00003, loss_test:0.02978, lr:9.51e-03, fs:0.94444 (r=0.944,p=0.944),  time:32.283, tt:3357.484\n",
      "Ep:104, loss:0.00003, loss_test:0.02888, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.290, tt:3390.471\n",
      "Ep:105, loss:0.00003, loss_test:0.02912, lr:9.51e-03, fs:0.93458 (r=0.926,p=0.943),  time:32.286, tt:3422.305\n",
      "Ep:106, loss:0.00003, loss_test:0.02853, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.278, tt:3453.733\n",
      "Ep:107, loss:0.00003, loss_test:0.02841, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.269, tt:3485.009\n",
      "Ep:108, loss:0.00003, loss_test:0.02793, lr:9.41e-03, fs:0.95327 (r=0.944,p=0.962),  time:32.280, tt:3518.562\n",
      "Ep:109, loss:0.00003, loss_test:0.02657, lr:9.32e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.284, tt:3551.194\n",
      "Ep:110, loss:0.00003, loss_test:0.02739, lr:9.23e-03, fs:0.95327 (r=0.944,p=0.962),  time:32.293, tt:3584.558\n",
      "Ep:111, loss:0.00003, loss_test:0.02669, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.308, tt:3618.533\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00002, loss_test:0.02680, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.318, tt:3651.990\n",
      "Ep:113, loss:0.00002, loss_test:0.02699, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.326, tt:3685.204\n",
      "Ep:114, loss:0.00002, loss_test:0.02524, lr:9.14e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.324, tt:3717.236\n",
      "Ep:115, loss:0.00002, loss_test:0.02580, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.326, tt:3749.836\n",
      "Ep:116, loss:0.00002, loss_test:0.02488, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.322, tt:3781.671\n",
      "Ep:117, loss:0.00002, loss_test:0.02415, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.302, tt:3811.626\n",
      "Ep:118, loss:0.00002, loss_test:0.02426, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.285, tt:3841.941\n",
      "Ep:119, loss:0.00002, loss_test:0.02355, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.278, tt:3873.387\n",
      "Ep:120, loss:0.00002, loss_test:0.02327, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.268, tt:3904.398\n",
      "Ep:121, loss:0.00002, loss_test:0.02342, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.264, tt:3936.165\n",
      "Ep:122, loss:0.00002, loss_test:0.02281, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.261, tt:3968.075\n",
      "Ep:123, loss:0.00002, loss_test:0.02261, lr:9.04e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.248, tt:3998.778\n",
      "Ep:124, loss:0.00002, loss_test:0.02235, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.237, tt:4029.658\n",
      "Ep:125, loss:0.00002, loss_test:0.02227, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.236, tt:4061.729\n",
      "Ep:126, loss:0.00002, loss_test:0.02196, lr:8.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.228, tt:4092.940\n",
      "Ep:127, loss:0.00002, loss_test:0.02148, lr:8.69e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.228, tt:4125.124\n",
      "Ep:128, loss:0.00002, loss_test:0.02131, lr:8.60e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.225, tt:4156.974\n",
      "Ep:129, loss:0.00002, loss_test:0.02127, lr:8.51e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.198, tt:4185.778\n",
      "Ep:130, loss:0.00002, loss_test:0.02066, lr:8.43e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.197, tt:4217.797\n",
      "Ep:131, loss:0.00002, loss_test:0.02056, lr:8.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.206, tt:4251.242\n",
      "Ep:132, loss:0.00002, loss_test:0.02007, lr:8.26e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.199, tt:4282.458\n",
      "Ep:133, loss:0.00002, loss_test:0.02063, lr:8.18e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.198, tt:4314.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.01971, lr:8.10e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.197, tt:4346.628\n",
      "Ep:135, loss:0.00002, loss_test:0.01961, lr:8.02e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.193, tt:4378.279\n",
      "Ep:136, loss:0.00002, loss_test:0.01968, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.193, tt:4410.498\n",
      "Ep:137, loss:0.00002, loss_test:0.01939, lr:7.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.193, tt:4442.631\n",
      "Ep:138, loss:0.00002, loss_test:0.01906, lr:7.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.195, tt:4475.138\n",
      "Ep:139, loss:0.00002, loss_test:0.01910, lr:7.70e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.193, tt:4507.073\n",
      "Ep:140, loss:0.00002, loss_test:0.01884, lr:7.62e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.199, tt:4540.024\n",
      "Ep:141, loss:0.00001, loss_test:0.01859, lr:7.55e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.190, tt:4570.932\n",
      "Ep:142, loss:0.00001, loss_test:0.01875, lr:7.47e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.199, tt:4604.451\n",
      "Ep:143, loss:0.00001, loss_test:0.01841, lr:7.40e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.193, tt:4635.751\n",
      "Ep:144, loss:0.00001, loss_test:0.01846, lr:7.32e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.194, tt:4668.098\n",
      "Ep:145, loss:0.00001, loss_test:0.01788, lr:7.25e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.184, tt:4698.868\n",
      "Ep:146, loss:0.00001, loss_test:0.01812, lr:7.18e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.184, tt:4730.991\n",
      "Ep:147, loss:0.00001, loss_test:0.01793, lr:7.11e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.180, tt:4762.618\n",
      "Ep:148, loss:0.00001, loss_test:0.01743, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.182, tt:4795.157\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00001, loss_test:0.01830, lr:7.03e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.171, tt:4825.599\n",
      "Ep:150, loss:0.00001, loss_test:0.01737, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.173, tt:4858.053\n",
      "Ep:151, loss:0.00001, loss_test:0.01741, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.161, tt:4888.511\n",
      "Ep:152, loss:0.00001, loss_test:0.01782, lr:7.03e-03, fs:0.96296 (r=0.963,p=0.963),  time:32.165, tt:4921.241\n",
      "Ep:153, loss:0.00001, loss_test:0.01685, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.163, tt:4953.044\n",
      "Ep:154, loss:0.00001, loss_test:0.01741, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.160, tt:4984.795\n",
      "Ep:155, loss:0.00001, loss_test:0.01709, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.162, tt:5017.303\n",
      "Ep:156, loss:0.00001, loss_test:0.01659, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.163, tt:5049.658\n",
      "Ep:157, loss:0.00001, loss_test:0.01703, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.170, tt:5082.887\n",
      "Ep:158, loss:0.00001, loss_test:0.01680, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.195, tt:5119.002\n",
      "Ep:159, loss:0.00001, loss_test:0.01642, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.183, tt:5149.349\n",
      "Ep:160, loss:0.00001, loss_test:0.01663, lr:6.96e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.184, tt:5181.620\n",
      "Ep:161, loss:0.00001, loss_test:0.01623, lr:6.89e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.185, tt:5213.969\n",
      "Ep:162, loss:0.00001, loss_test:0.01603, lr:6.83e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.183, tt:5245.904\n",
      "Ep:163, loss:0.00001, loss_test:0.01621, lr:6.76e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.189, tt:5278.971\n",
      "Ep:164, loss:0.00001, loss_test:0.01582, lr:6.69e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.187, tt:5310.783\n",
      "Ep:165, loss:0.00001, loss_test:0.01601, lr:6.62e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.185, tt:5342.714\n",
      "Ep:166, loss:0.00001, loss_test:0.01601, lr:6.56e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.187, tt:5375.169\n",
      "Ep:167, loss:0.00001, loss_test:0.01549, lr:6.49e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.180, tt:5406.276\n",
      "Ep:168, loss:0.00001, loss_test:0.01579, lr:6.43e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.184, tt:5439.164\n",
      "Ep:169, loss:0.00001, loss_test:0.01564, lr:6.36e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.197, tt:5473.411\n",
      "Ep:170, loss:0.00001, loss_test:0.01538, lr:6.30e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.205, tt:5507.045\n",
      "Ep:171, loss:0.00001, loss_test:0.01558, lr:6.24e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.209, tt:5539.972\n",
      "Ep:172, loss:0.00001, loss_test:0.01534, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.208, tt:5571.938\n",
      "##########Best model found so far##########\n",
      "Ep:173, loss:0.00001, loss_test:0.01514, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.206, tt:5603.919\n",
      "Ep:174, loss:0.00001, loss_test:0.01518, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.210, tt:5636.701\n",
      "Ep:175, loss:0.00001, loss_test:0.01519, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.209, tt:5668.840\n",
      "Ep:176, loss:0.00001, loss_test:0.01513, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.215, tt:5701.969\n",
      "Ep:177, loss:0.00001, loss_test:0.01489, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.223, tt:5735.621\n",
      "Ep:178, loss:0.00001, loss_test:0.01501, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.219, tt:5767.172\n",
      "Ep:179, loss:0.00001, loss_test:0.01479, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.207, tt:5797.321\n",
      "Ep:180, loss:0.00001, loss_test:0.01478, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.203, tt:5828.796\n",
      "Ep:181, loss:0.00001, loss_test:0.01465, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.200, tt:5860.387\n",
      "Ep:182, loss:0.00001, loss_test:0.01446, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.192, tt:5891.083\n",
      "Ep:183, loss:0.00001, loss_test:0.01449, lr:6.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.196, tt:5924.026\n",
      "Ep:184, loss:0.00001, loss_test:0.01458, lr:6.11e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.210, tt:5958.779\n",
      "Ep:185, loss:0.00001, loss_test:0.01448, lr:6.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.203, tt:5989.717\n",
      "Ep:186, loss:0.00001, loss_test:0.01426, lr:5.99e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.197, tt:6020.765\n",
      "Ep:187, loss:0.00001, loss_test:0.01437, lr:5.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.187, tt:6051.067\n",
      "Ep:188, loss:0.00001, loss_test:0.01435, lr:5.87e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.187, tt:6083.388\n",
      "Ep:189, loss:0.00001, loss_test:0.01408, lr:5.81e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.185, tt:6115.092\n",
      "Ep:190, loss:0.00001, loss_test:0.01415, lr:5.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.183, tt:6146.950\n",
      "Ep:191, loss:0.00001, loss_test:0.01412, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.180, tt:6178.477\n",
      "Ep:192, loss:0.00001, loss_test:0.01420, lr:5.64e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.170, tt:6208.885\n",
      "Ep:193, loss:0.00001, loss_test:0.01403, lr:5.58e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.170, tt:6241.048\n",
      "Ep:194, loss:0.00001, loss_test:0.01394, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.167, tt:6272.615\n",
      "Ep:195, loss:0.00001, loss_test:0.01404, lr:5.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.162, tt:6303.823\n",
      "Ep:196, loss:0.00001, loss_test:0.01393, lr:5.42e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.162, tt:6335.958\n",
      "Ep:197, loss:0.00001, loss_test:0.01375, lr:5.36e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.166, tt:6368.809\n",
      "Ep:198, loss:0.00001, loss_test:0.01372, lr:5.31e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.158, tt:6399.375\n",
      "Ep:199, loss:0.00001, loss_test:0.01362, lr:5.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.153, tt:6430.666\n",
      "Ep:200, loss:0.00001, loss_test:0.01364, lr:5.20e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.155, tt:6463.117\n",
      "Ep:201, loss:0.00001, loss_test:0.01359, lr:5.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.156, tt:6495.441\n",
      "Ep:202, loss:0.00001, loss_test:0.01361, lr:5.10e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.158, tt:6528.040\n",
      "Ep:203, loss:0.00001, loss_test:0.01358, lr:5.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.159, tt:6560.475\n",
      "Ep:204, loss:0.00001, loss_test:0.01330, lr:5.00e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.164, tt:6593.602\n",
      "Ep:205, loss:0.00001, loss_test:0.01336, lr:4.95e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.162, tt:6625.461\n",
      "Ep:206, loss:0.00001, loss_test:0.01333, lr:4.90e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.137, tt:6652.368\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14691, lr:1.00e-02, fs:0.64103 (r=0.926,p=0.490),  time:23.266, tt:23.266\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14590, lr:1.00e-02, fs:0.64474 (r=0.907,p=0.500),  time:26.684, tt:53.368\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.14406, lr:1.00e-02, fs:0.64430 (r=0.889,p=0.505),  time:30.143, tt:90.430\n",
      "Ep:3, loss:0.00026, loss_test:0.14337, lr:1.00e-02, fs:0.63448 (r=0.852,p=0.505),  time:31.698, tt:126.793\n",
      "Ep:4, loss:0.00025, loss_test:0.14210, lr:1.00e-02, fs:0.62222 (r=0.778,p=0.519),  time:32.858, tt:164.288\n",
      "Ep:5, loss:0.00025, loss_test:0.13940, lr:1.00e-02, fs:0.61654 (r=0.759,p=0.519),  time:33.408, tt:200.451\n",
      "Ep:6, loss:0.00024, loss_test:0.13632, lr:1.00e-02, fs:0.63768 (r=0.815,p=0.524),  time:33.913, tt:237.390\n",
      "Ep:7, loss:0.00024, loss_test:0.13377, lr:1.00e-02, fs:0.64234 (r=0.815,p=0.530),  time:34.126, tt:273.010\n",
      "Ep:8, loss:0.00023, loss_test:0.13121, lr:1.00e-02, fs:0.66667 (r=0.815,p=0.564),  time:34.460, tt:310.141\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.12808, lr:1.00e-02, fs:0.68217 (r=0.815,p=0.587),  time:34.960, tt:349.598\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.12424, lr:1.00e-02, fs:0.66129 (r=0.759,p=0.586),  time:35.164, tt:386.803\n",
      "Ep:11, loss:0.00021, loss_test:0.12116, lr:1.00e-02, fs:0.67200 (r=0.778,p=0.592),  time:35.289, tt:423.470\n",
      "Ep:12, loss:0.00021, loss_test:0.11877, lr:1.00e-02, fs:0.66667 (r=0.759,p=0.594),  time:35.339, tt:459.410\n",
      "Ep:13, loss:0.00020, loss_test:0.11674, lr:1.00e-02, fs:0.67769 (r=0.759,p=0.612),  time:35.486, tt:496.810\n",
      "Ep:14, loss:0.00019, loss_test:0.11342, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:35.662, tt:534.937\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11003, lr:1.00e-02, fs:0.70690 (r=0.759,p=0.661),  time:35.777, tt:572.431\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10733, lr:1.00e-02, fs:0.69027 (r=0.722,p=0.661),  time:35.823, tt:608.992\n",
      "Ep:17, loss:0.00017, loss_test:0.10429, lr:1.00e-02, fs:0.71304 (r=0.759,p=0.672),  time:35.894, tt:646.091\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10231, lr:1.00e-02, fs:0.71429 (r=0.741,p=0.690),  time:35.930, tt:682.672\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.10037, lr:1.00e-02, fs:0.72072 (r=0.741,p=0.702),  time:35.988, tt:719.761\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09818, lr:1.00e-02, fs:0.72727 (r=0.741,p=0.714),  time:36.090, tt:757.892\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09710, lr:1.00e-02, fs:0.73394 (r=0.741,p=0.727),  time:36.179, tt:795.947\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09445, lr:1.00e-02, fs:0.73214 (r=0.759,p=0.707),  time:36.205, tt:832.722\n",
      "Ep:23, loss:0.00015, loss_test:0.09402, lr:1.00e-02, fs:0.72727 (r=0.741,p=0.714),  time:36.231, tt:869.549\n",
      "Ep:24, loss:0.00014, loss_test:0.09123, lr:1.00e-02, fs:0.72566 (r=0.759,p=0.695),  time:36.290, tt:907.252\n",
      "Ep:25, loss:0.00014, loss_test:0.08953, lr:1.00e-02, fs:0.73874 (r=0.759,p=0.719),  time:36.305, tt:943.924\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08722, lr:1.00e-02, fs:0.76786 (r=0.796,p=0.741),  time:36.340, tt:981.168\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08527, lr:1.00e-02, fs:0.75000 (r=0.778,p=0.724),  time:36.429, tt:1020.005\n",
      "Ep:28, loss:0.00013, loss_test:0.08344, lr:1.00e-02, fs:0.76106 (r=0.796,p=0.729),  time:36.381, tt:1055.061\n",
      "Ep:29, loss:0.00012, loss_test:0.08076, lr:1.00e-02, fs:0.78947 (r=0.833,p=0.750),  time:36.388, tt:1091.645\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07877, lr:1.00e-02, fs:0.80702 (r=0.852,p=0.767),  time:36.469, tt:1130.541\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07603, lr:1.00e-02, fs:0.81416 (r=0.852,p=0.780),  time:36.444, tt:1166.204\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07423, lr:1.00e-02, fs:0.83636 (r=0.852,p=0.821),  time:36.493, tt:1204.285\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07301, lr:1.00e-02, fs:0.82883 (r=0.852,p=0.807),  time:36.475, tt:1240.143\n",
      "Ep:34, loss:0.00011, loss_test:0.07103, lr:1.00e-02, fs:0.83636 (r=0.852,p=0.821),  time:36.493, tt:1277.256\n",
      "Ep:35, loss:0.00011, loss_test:0.06965, lr:1.00e-02, fs:0.83186 (r=0.870,p=0.797),  time:36.514, tt:1314.487\n",
      "Ep:36, loss:0.00010, loss_test:0.06781, lr:1.00e-02, fs:0.84685 (r=0.870,p=0.825),  time:36.519, tt:1351.187\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.06678, lr:1.00e-02, fs:0.84404 (r=0.852,p=0.836),  time:36.496, tt:1386.861\n",
      "Ep:38, loss:0.00010, loss_test:0.06424, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:36.521, tt:1424.304\n",
      "Ep:39, loss:0.00010, loss_test:0.06322, lr:1.00e-02, fs:0.86486 (r=0.889,p=0.842),  time:36.500, tt:1459.983\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.06204, lr:1.00e-02, fs:0.87273 (r=0.889,p=0.857),  time:36.499, tt:1496.464\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.06049, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:36.484, tt:1532.336\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.05920, lr:1.00e-02, fs:0.89091 (r=0.907,p=0.875),  time:36.487, tt:1568.920\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.05770, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:36.530, tt:1607.304\n",
      "Ep:44, loss:0.00009, loss_test:0.05618, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:36.515, tt:1643.180\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.05496, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:36.502, tt:1679.082\n",
      "Ep:46, loss:0.00008, loss_test:0.05348, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.533, tt:1717.072\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.05290, lr:1.00e-02, fs:0.91892 (r=0.944,p=0.895),  time:36.540, tt:1753.943\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.05181, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.554, tt:1791.163\n",
      "Ep:49, loss:0.00008, loss_test:0.05039, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:36.543, tt:1827.135\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.05115, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:36.538, tt:1863.441\n",
      "Ep:51, loss:0.00007, loss_test:0.04818, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.535, tt:1899.808\n",
      "Ep:52, loss:0.00007, loss_test:0.04898, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:36.504, tt:1934.703\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.04590, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:36.511, tt:1971.603\n",
      "Ep:54, loss:0.00007, loss_test:0.04745, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.509, tt:2007.978\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.04412, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.498, tt:2043.877\n",
      "Ep:56, loss:0.00007, loss_test:0.04321, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:36.488, tt:2079.824\n",
      "Ep:57, loss:0.00006, loss_test:0.04434, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.435, tt:2113.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00006, loss_test:0.04130, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.428, tt:2149.254\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.04173, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.418, tt:2257.894\n",
      "Ep:62, loss:0.00006, loss_test:0.03862, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.412, tt:2293.952\n",
      "Ep:63, loss:0.00006, loss_test:0.03839, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.396, tt:2329.330\n",
      "Ep:64, loss:0.00005, loss_test:0.03969, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.369, tt:2363.961\n",
      "Ep:65, loss:0.00005, loss_test:0.03685, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.340, tt:2398.460\n",
      "Ep:66, loss:0.00005, loss_test:0.03697, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.358, tt:2435.963\n",
      "Ep:67, loss:0.00005, loss_test:0.03802, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.371, tt:2473.206\n",
      "Ep:68, loss:0.00005, loss_test:0.03532, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.381, tt:2510.308\n",
      "Ep:69, loss:0.00005, loss_test:0.03624, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:36.382, tt:2546.727\n",
      "Ep:70, loss:0.00005, loss_test:0.03496, lr:9.90e-03, fs:0.94643 (r=0.981,p=0.914),  time:36.387, tt:2583.495\n",
      "Ep:71, loss:0.00005, loss_test:0.03374, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:36.378, tt:2619.235\n",
      "Ep:72, loss:0.00004, loss_test:0.03684, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.396, tt:2656.933\n",
      "Ep:73, loss:0.00004, loss_test:0.03262, lr:9.61e-03, fs:0.94643 (r=0.981,p=0.914),  time:36.399, tt:2693.505\n",
      "Ep:74, loss:0.00004, loss_test:0.03313, lr:9.51e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.387, tt:2729.017\n",
      "Ep:75, loss:0.00004, loss_test:0.03391, lr:9.41e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.400, tt:2766.388\n",
      "Ep:76, loss:0.00004, loss_test:0.03191, lr:9.32e-03, fs:0.94643 (r=0.981,p=0.914),  time:36.391, tt:2802.145\n",
      "Ep:77, loss:0.00004, loss_test:0.03112, lr:9.23e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.423, tt:2840.980\n",
      "Ep:78, loss:0.00004, loss_test:0.03370, lr:9.14e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.431, tt:2878.034\n",
      "Ep:79, loss:0.00004, loss_test:0.03001, lr:9.04e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.457, tt:2916.569\n",
      "Ep:80, loss:0.00004, loss_test:0.03168, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.484, tt:2955.239\n",
      "Ep:81, loss:0.00004, loss_test:0.03369, lr:8.86e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.491, tt:2992.262\n",
      "Ep:82, loss:0.00004, loss_test:0.03063, lr:8.78e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.474, tt:3027.360\n",
      "Ep:83, loss:0.00004, loss_test:0.03576, lr:8.69e-03, fs:0.92727 (r=0.944,p=0.911),  time:36.483, tt:3064.600\n",
      "Ep:84, loss:0.00004, loss_test:0.02957, lr:8.60e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.493, tt:3101.930\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.02999, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.506, tt:3139.521\n",
      "Ep:86, loss:0.00003, loss_test:0.02914, lr:8.60e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.511, tt:3176.493\n",
      "Ep:87, loss:0.00003, loss_test:0.02971, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.517, tt:3213.460\n",
      "Ep:88, loss:0.00003, loss_test:0.02899, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.527, tt:3250.924\n",
      "Ep:89, loss:0.00003, loss_test:0.02850, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.516, tt:3286.480\n",
      "Ep:90, loss:0.00003, loss_test:0.02752, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.510, tt:3322.378\n",
      "Ep:91, loss:0.00003, loss_test:0.02774, lr:8.60e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.528, tt:3360.605\n",
      "Ep:92, loss:0.00003, loss_test:0.02790, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.525, tt:3396.840\n",
      "Ep:93, loss:0.00003, loss_test:0.02766, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.535, tt:3434.287\n",
      "Ep:94, loss:0.00003, loss_test:0.02888, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.538, tt:3471.119\n",
      "Ep:95, loss:0.00003, loss_test:0.02687, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.548, tt:3508.610\n",
      "Ep:96, loss:0.00003, loss_test:0.02637, lr:8.51e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.556, tt:3545.941\n",
      "Ep:97, loss:0.00003, loss_test:0.02705, lr:8.43e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.566, tt:3583.498\n",
      "Ep:98, loss:0.00003, loss_test:0.02572, lr:8.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.574, tt:3620.801\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00003, loss_test:0.02796, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.583, tt:3658.295\n",
      "Ep:100, loss:0.00003, loss_test:0.02542, lr:8.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.585, tt:3695.051\n",
      "Ep:101, loss:0.00003, loss_test:0.02611, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.599, tt:3733.126\n",
      "Ep:102, loss:0.00003, loss_test:0.02464, lr:8.35e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.602, tt:3769.970\n",
      "Ep:103, loss:0.00002, loss_test:0.02490, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.601, tt:3806.488\n",
      "Ep:104, loss:0.00002, loss_test:0.02503, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.614, tt:3844.479\n",
      "Ep:105, loss:0.00002, loss_test:0.02423, lr:8.35e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.604, tt:3880.047\n",
      "Ep:106, loss:0.00002, loss_test:0.02559, lr:8.35e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.619, tt:3918.226\n",
      "Ep:107, loss:0.00002, loss_test:0.02464, lr:8.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.618, tt:3954.748\n",
      "Ep:108, loss:0.00002, loss_test:0.02516, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.635, tt:3993.163\n",
      "Ep:109, loss:0.00002, loss_test:0.02341, lr:8.35e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.634, tt:4029.774\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.02309, lr:8.35e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.613, tt:4064.049\n",
      "Ep:111, loss:0.00002, loss_test:0.02290, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.605, tt:4099.749\n",
      "Ep:112, loss:0.00002, loss_test:0.02363, lr:8.35e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.598, tt:4135.576\n",
      "Ep:113, loss:0.00002, loss_test:0.02354, lr:8.35e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.612, tt:4173.815\n",
      "Ep:114, loss:0.00002, loss_test:0.02242, lr:8.35e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.610, tt:4210.138\n",
      "Ep:115, loss:0.00002, loss_test:0.02312, lr:8.35e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.603, tt:4245.921\n",
      "Ep:116, loss:0.00002, loss_test:0.02440, lr:8.35e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.599, tt:4282.137\n",
      "Ep:117, loss:0.00002, loss_test:0.02254, lr:8.35e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.604, tt:4319.312\n",
      "Ep:118, loss:0.00002, loss_test:0.02369, lr:8.35e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.617, tt:4357.382\n",
      "Ep:119, loss:0.00002, loss_test:0.02250, lr:8.35e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.606, tt:4392.666\n",
      "Ep:120, loss:0.00002, loss_test:0.02209, lr:8.35e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.657, tt:4435.462\n",
      "Ep:121, loss:0.00002, loss_test:0.02488, lr:8.26e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.637, tt:4469.679\n",
      "Ep:122, loss:0.00002, loss_test:0.02159, lr:8.18e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.625, tt:4504.817\n",
      "Ep:123, loss:0.00002, loss_test:0.02256, lr:8.10e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.612, tt:4539.909\n",
      "Ep:124, loss:0.00002, loss_test:0.02150, lr:8.02e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.601, tt:4575.146\n",
      "Ep:125, loss:0.00002, loss_test:0.02069, lr:7.94e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.589, tt:4610.182\n",
      "Ep:126, loss:0.00002, loss_test:0.02209, lr:7.86e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.575, tt:4645.021\n",
      "Ep:127, loss:0.00002, loss_test:0.02076, lr:7.78e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.584, tt:4682.758\n",
      "Ep:128, loss:0.00002, loss_test:0.02123, lr:7.70e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.583, tt:4719.186\n",
      "Ep:129, loss:0.00002, loss_test:0.02059, lr:7.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.588, tt:4756.448\n",
      "Ep:130, loss:0.00002, loss_test:0.02013, lr:7.55e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.591, tt:4793.454\n",
      "Ep:131, loss:0.00002, loss_test:0.01992, lr:7.47e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.597, tt:4830.831\n",
      "Ep:132, loss:0.00002, loss_test:0.02055, lr:7.40e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.597, tt:4867.352\n",
      "Ep:133, loss:0.00002, loss_test:0.01999, lr:7.32e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.605, tt:4905.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.01969, lr:7.25e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.603, tt:4941.465\n",
      "Ep:135, loss:0.00002, loss_test:0.02036, lr:7.18e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.600, tt:4977.640\n",
      "Ep:136, loss:0.00002, loss_test:0.01977, lr:7.11e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.612, tt:5015.867\n",
      "Ep:137, loss:0.00002, loss_test:0.02057, lr:7.03e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.616, tt:5053.042\n",
      "Ep:138, loss:0.00002, loss_test:0.01997, lr:6.96e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.623, tt:5090.572\n",
      "Ep:139, loss:0.00002, loss_test:0.01959, lr:6.89e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.621, tt:5126.934\n",
      "Ep:140, loss:0.00001, loss_test:0.01999, lr:6.83e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.617, tt:5162.985\n",
      "Ep:141, loss:0.00001, loss_test:0.01942, lr:6.76e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.614, tt:5199.256\n",
      "Ep:142, loss:0.00001, loss_test:0.02019, lr:6.69e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.627, tt:5237.723\n",
      "Ep:143, loss:0.00001, loss_test:0.01936, lr:6.62e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.623, tt:5273.706\n",
      "Ep:144, loss:0.00001, loss_test:0.02027, lr:6.56e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.616, tt:5309.345\n",
      "Ep:145, loss:0.00001, loss_test:0.01873, lr:6.49e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.619, tt:5346.335\n",
      "Ep:146, loss:0.00001, loss_test:0.01929, lr:6.43e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.616, tt:5382.550\n",
      "Ep:147, loss:0.00001, loss_test:0.01868, lr:6.36e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.609, tt:5418.186\n",
      "Ep:148, loss:0.00001, loss_test:0.01945, lr:6.30e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.589, tt:5451.740\n",
      "Ep:149, loss:0.00001, loss_test:0.01878, lr:6.24e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.578, tt:5486.724\n",
      "Ep:150, loss:0.00001, loss_test:0.01886, lr:6.17e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.568, tt:5521.704\n",
      "Ep:151, loss:0.00001, loss_test:0.01871, lr:6.11e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.556, tt:5556.542\n",
      "Ep:152, loss:0.00001, loss_test:0.01883, lr:6.05e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.560, tt:5593.705\n",
      "Ep:153, loss:0.00001, loss_test:0.01866, lr:5.99e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.556, tt:5629.648\n",
      "Ep:154, loss:0.00001, loss_test:0.01834, lr:5.93e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.558, tt:5666.436\n",
      "Ep:155, loss:0.00001, loss_test:0.01875, lr:5.87e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.570, tt:5704.876\n",
      "Ep:156, loss:0.00001, loss_test:0.01873, lr:5.81e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.578, tt:5742.731\n",
      "Ep:157, loss:0.00001, loss_test:0.01851, lr:5.75e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.599, tt:5782.694\n",
      "Ep:158, loss:0.00001, loss_test:0.01889, lr:5.70e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.596, tt:5818.738\n",
      "Ep:159, loss:0.00001, loss_test:0.01833, lr:5.64e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.610, tt:5857.589\n",
      "Ep:160, loss:0.00001, loss_test:0.01848, lr:5.58e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.604, tt:5893.274\n",
      "Ep:161, loss:0.00001, loss_test:0.01884, lr:5.53e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.607, tt:5930.341\n",
      "Ep:162, loss:0.00001, loss_test:0.01821, lr:5.47e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.607, tt:5966.901\n",
      "Ep:163, loss:0.00001, loss_test:0.01855, lr:5.42e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.612, tt:6004.295\n",
      "Ep:164, loss:0.00001, loss_test:0.01805, lr:5.36e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.619, tt:6042.198\n",
      "Ep:165, loss:0.00001, loss_test:0.01821, lr:5.31e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.619, tt:6078.697\n",
      "Ep:166, loss:0.00001, loss_test:0.01795, lr:5.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.621, tt:6115.684\n",
      "Ep:167, loss:0.00001, loss_test:0.01790, lr:5.20e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.616, tt:6151.419\n",
      "Ep:168, loss:0.00001, loss_test:0.01836, lr:5.15e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.620, tt:6188.829\n",
      "Ep:169, loss:0.00001, loss_test:0.01769, lr:5.10e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.623, tt:6225.837\n",
      "Ep:170, loss:0.00001, loss_test:0.01823, lr:5.05e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.621, tt:6262.180\n",
      "Ep:171, loss:0.00001, loss_test:0.01760, lr:5.00e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.622, tt:6299.036\n",
      "Ep:172, loss:0.00001, loss_test:0.01805, lr:4.95e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.625, tt:6336.103\n",
      "Ep:173, loss:0.00001, loss_test:0.01787, lr:4.90e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.630, tt:6373.602\n",
      "Ep:174, loss:0.00001, loss_test:0.01770, lr:4.85e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.633, tt:6410.765\n",
      "Ep:175, loss:0.00001, loss_test:0.01781, lr:4.80e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.629, tt:6446.763\n",
      "Ep:176, loss:0.00001, loss_test:0.01758, lr:4.75e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.642, tt:6485.550\n",
      "Ep:177, loss:0.00001, loss_test:0.01786, lr:4.71e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.638, tt:6521.650\n",
      "Ep:178, loss:0.00001, loss_test:0.01755, lr:4.66e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.643, tt:6559.153\n",
      "Ep:179, loss:0.00001, loss_test:0.01775, lr:4.61e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.635, tt:6594.233\n",
      "Ep:180, loss:0.00001, loss_test:0.01747, lr:4.57e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.628, tt:6629.632\n",
      "Ep:181, loss:0.00001, loss_test:0.01768, lr:4.52e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.623, tt:6665.475\n",
      "Ep:182, loss:0.00001, loss_test:0.01742, lr:4.48e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.621, tt:6701.658\n",
      "Ep:183, loss:0.00001, loss_test:0.01716, lr:4.43e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.628, tt:6739.577\n",
      "Ep:184, loss:0.00001, loss_test:0.01781, lr:4.39e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.619, tt:6774.573\n",
      "Ep:185, loss:0.00001, loss_test:0.01706, lr:4.34e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.627, tt:6812.644\n",
      "Ep:186, loss:0.00001, loss_test:0.01783, lr:4.30e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.618, tt:6847.475\n",
      "Ep:187, loss:0.00001, loss_test:0.01708, lr:4.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.609, tt:6882.518\n",
      "Ep:188, loss:0.00001, loss_test:0.01745, lr:4.21e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.606, tt:6918.609\n",
      "Ep:189, loss:0.00001, loss_test:0.01728, lr:4.17e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.599, tt:6953.885\n",
      "Ep:190, loss:0.00001, loss_test:0.01703, lr:4.13e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.585, tt:6987.809\n",
      "Ep:191, loss:0.00001, loss_test:0.01754, lr:4.09e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.581, tt:7023.528\n",
      "Ep:192, loss:0.00001, loss_test:0.01702, lr:4.05e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.583, tt:7060.476\n",
      "Ep:193, loss:0.00001, loss_test:0.01734, lr:4.01e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.591, tt:7098.719\n",
      "Ep:194, loss:0.00001, loss_test:0.01734, lr:3.97e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.587, tt:7134.515\n",
      "Ep:195, loss:0.00001, loss_test:0.01687, lr:3.93e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.583, tt:7170.267\n",
      "Ep:196, loss:0.00001, loss_test:0.01735, lr:3.89e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.584, tt:7206.994\n",
      "Ep:197, loss:0.00001, loss_test:0.01705, lr:3.85e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.585, tt:7243.889\n",
      "Ep:198, loss:0.00001, loss_test:0.01700, lr:3.81e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.585, tt:7280.416\n",
      "Ep:199, loss:0.00001, loss_test:0.01717, lr:3.77e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.595, tt:7319.053\n",
      "Ep:200, loss:0.00001, loss_test:0.01684, lr:3.73e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.593, tt:7355.267\n",
      "Ep:201, loss:0.00001, loss_test:0.01709, lr:3.70e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.592, tt:7391.598\n",
      "Ep:202, loss:0.00001, loss_test:0.01698, lr:3.66e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.583, tt:7426.341\n",
      "Ep:203, loss:0.00001, loss_test:0.01690, lr:3.62e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.575, tt:7461.248\n",
      "Ep:204, loss:0.00001, loss_test:0.01692, lr:3.59e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.577, tt:7498.231\n",
      "Ep:205, loss:0.00001, loss_test:0.01679, lr:3.55e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.577, tt:7534.781\n",
      "Ep:206, loss:0.00001, loss_test:0.01688, lr:3.52e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.562, tt:7568.420\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02855, lr:6.00e-02, fs:0.61765 (r=0.778,p=0.512),  time:32.673, tt:32.673\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02733, lr:6.00e-02, fs:0.64557 (r=0.944,p=0.490),  time:32.453, tt:64.905\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02941, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.006, tt:99.018\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00006, loss_test:0.02952, lr:6.00e-02, fs:0.65839 (r=0.981,p=0.495),  time:33.414, tt:133.658\n",
      "Ep:4, loss:0.00006, loss_test:0.02866, lr:6.00e-02, fs:0.64968 (r=0.944,p=0.495),  time:33.453, tt:167.266\n",
      "Ep:5, loss:0.00005, loss_test:0.02752, lr:6.00e-02, fs:0.64474 (r=0.907,p=0.500),  time:33.226, tt:199.358\n",
      "Ep:6, loss:0.00005, loss_test:0.02700, lr:6.00e-02, fs:0.63514 (r=0.870,p=0.500),  time:32.689, tt:228.823\n",
      "Ep:7, loss:0.00005, loss_test:0.02672, lr:6.00e-02, fs:0.63514 (r=0.870,p=0.500),  time:32.580, tt:260.643\n",
      "Ep:8, loss:0.00005, loss_test:0.02636, lr:6.00e-02, fs:0.63946 (r=0.870,p=0.505),  time:32.678, tt:294.103\n",
      "Ep:9, loss:0.00005, loss_test:0.02600, lr:6.00e-02, fs:0.64865 (r=0.889,p=0.511),  time:32.988, tt:329.883\n",
      "Ep:10, loss:0.00005, loss_test:0.02583, lr:6.00e-02, fs:0.64865 (r=0.889,p=0.511),  time:33.151, tt:364.665\n",
      "Ep:11, loss:0.00005, loss_test:0.02554, lr:6.00e-02, fs:0.64865 (r=0.889,p=0.511),  time:33.298, tt:399.581\n",
      "Ep:12, loss:0.00005, loss_test:0.02515, lr:6.00e-02, fs:0.63946 (r=0.870,p=0.505),  time:33.396, tt:434.148\n",
      "Ep:13, loss:0.00005, loss_test:0.02483, lr:6.00e-02, fs:0.63946 (r=0.870,p=0.505),  time:33.619, tt:470.666\n",
      "Ep:14, loss:0.00005, loss_test:0.02431, lr:5.94e-02, fs:0.63946 (r=0.870,p=0.505),  time:33.709, tt:505.635\n",
      "Ep:15, loss:0.00004, loss_test:0.02377, lr:5.88e-02, fs:0.64865 (r=0.889,p=0.511),  time:33.829, tt:541.263\n",
      "Ep:16, loss:0.00004, loss_test:0.02334, lr:5.82e-02, fs:0.65306 (r=0.889,p=0.516),  time:33.910, tt:576.468\n",
      "Ep:17, loss:0.00004, loss_test:0.02303, lr:5.76e-02, fs:0.66197 (r=0.870,p=0.534),  time:34.050, tt:612.908\n",
      "Ep:18, loss:0.00004, loss_test:0.02279, lr:5.71e-02, fs:0.65248 (r=0.852,p=0.529),  time:34.080, tt:647.515\n",
      "Ep:19, loss:0.00004, loss_test:0.02243, lr:5.65e-02, fs:0.65248 (r=0.852,p=0.529),  time:34.125, tt:682.499\n",
      "Ep:20, loss:0.00004, loss_test:0.02205, lr:5.59e-02, fs:0.64789 (r=0.852,p=0.523),  time:34.158, tt:717.313\n",
      "Ep:21, loss:0.00004, loss_test:0.02169, lr:5.54e-02, fs:0.65248 (r=0.852,p=0.529),  time:34.147, tt:751.224\n",
      "Ep:22, loss:0.00004, loss_test:0.02143, lr:5.48e-02, fs:0.64286 (r=0.833,p=0.523),  time:34.248, tt:787.700\n",
      "Ep:23, loss:0.00004, loss_test:0.02120, lr:5.43e-02, fs:0.64748 (r=0.833,p=0.529),  time:34.318, tt:823.629\n",
      "Ep:24, loss:0.00004, loss_test:0.02094, lr:5.37e-02, fs:0.65693 (r=0.833,p=0.542),  time:34.275, tt:856.886\n",
      "Ep:25, loss:0.00004, loss_test:0.02066, lr:5.32e-02, fs:0.66176 (r=0.833,p=0.549),  time:34.283, tt:891.362\n",
      "Ep:26, loss:0.00004, loss_test:0.02041, lr:5.27e-02, fs:0.67153 (r=0.852,p=0.554),  time:34.334, tt:927.032\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.02017, lr:5.27e-02, fs:0.67647 (r=0.852,p=0.561),  time:34.334, tt:961.363\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01986, lr:5.27e-02, fs:0.67647 (r=0.852,p=0.561),  time:34.345, tt:995.995\n",
      "Ep:29, loss:0.00003, loss_test:0.01956, lr:5.27e-02, fs:0.68148 (r=0.852,p=0.568),  time:34.375, tt:1031.260\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01932, lr:5.27e-02, fs:0.69697 (r=0.852,p=0.590),  time:34.367, tt:1065.393\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01904, lr:5.27e-02, fs:0.69767 (r=0.833,p=0.600),  time:34.388, tt:1100.430\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01872, lr:5.27e-02, fs:0.69291 (r=0.815,p=0.603),  time:34.381, tt:1134.577\n",
      "Ep:33, loss:0.00003, loss_test:0.01839, lr:5.27e-02, fs:0.69841 (r=0.815,p=0.611),  time:34.417, tt:1170.169\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01807, lr:5.27e-02, fs:0.69841 (r=0.815,p=0.611),  time:34.401, tt:1204.022\n",
      "Ep:35, loss:0.00003, loss_test:0.01772, lr:5.27e-02, fs:0.72581 (r=0.833,p=0.643),  time:34.450, tt:1240.218\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01734, lr:5.27e-02, fs:0.70968 (r=0.815,p=0.629),  time:34.483, tt:1275.876\n",
      "Ep:37, loss:0.00003, loss_test:0.01706, lr:5.27e-02, fs:0.73171 (r=0.833,p=0.652),  time:34.500, tt:1310.992\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01675, lr:5.27e-02, fs:0.72581 (r=0.833,p=0.643),  time:34.512, tt:1345.971\n",
      "Ep:39, loss:0.00003, loss_test:0.01632, lr:5.27e-02, fs:0.73600 (r=0.852,p=0.648),  time:34.510, tt:1380.412\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01603, lr:5.27e-02, fs:0.72581 (r=0.833,p=0.643),  time:34.506, tt:1414.763\n",
      "Ep:41, loss:0.00003, loss_test:0.01574, lr:5.27e-02, fs:0.73600 (r=0.852,p=0.648),  time:34.546, tt:1450.935\n",
      "Ep:42, loss:0.00003, loss_test:0.01544, lr:5.27e-02, fs:0.73600 (r=0.852,p=0.648),  time:34.572, tt:1486.604\n",
      "Ep:43, loss:0.00003, loss_test:0.01513, lr:5.27e-02, fs:0.73600 (r=0.852,p=0.648),  time:34.581, tt:1521.582\n",
      "Ep:44, loss:0.00003, loss_test:0.01484, lr:5.27e-02, fs:0.73600 (r=0.852,p=0.648),  time:34.589, tt:1556.497\n",
      "Ep:45, loss:0.00002, loss_test:0.01455, lr:5.27e-02, fs:0.74194 (r=0.852,p=0.657),  time:34.597, tt:1591.453\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01419, lr:5.27e-02, fs:0.75806 (r=0.870,p=0.671),  time:34.579, tt:1625.199\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01387, lr:5.27e-02, fs:0.76423 (r=0.870,p=0.681),  time:34.591, tt:1660.350\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01361, lr:5.27e-02, fs:0.76423 (r=0.870,p=0.681),  time:34.569, tt:1693.882\n",
      "Ep:49, loss:0.00002, loss_test:0.01331, lr:5.27e-02, fs:0.76423 (r=0.870,p=0.681),  time:34.578, tt:1728.882\n",
      "Ep:50, loss:0.00002, loss_test:0.01289, lr:5.27e-02, fs:0.77049 (r=0.870,p=0.691),  time:34.604, tt:1764.825\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02700, lr:6.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:16.391, tt:16.391\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02757, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:19.092, tt:38.184\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02996, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:22.209, tt:66.627\n",
      "Ep:3, loss:0.00006, loss_test:0.03047, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:24.133, tt:96.534\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00006, loss_test:0.03046, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:25.669, tt:128.344\n",
      "Ep:5, loss:0.00006, loss_test:0.03025, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:26.582, tt:159.493\n",
      "Ep:6, loss:0.00005, loss_test:0.02963, lr:6.00e-02, fs:0.64260 (r=0.899,p=0.500),  time:27.361, tt:191.528\n",
      "Ep:7, loss:0.00005, loss_test:0.02902, lr:6.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:27.922, tt:223.376\n",
      "Ep:8, loss:0.00005, loss_test:0.02855, lr:6.00e-02, fs:0.63736 (r=0.879,p=0.500),  time:28.196, tt:253.765\n",
      "Ep:9, loss:0.00005, loss_test:0.02821, lr:6.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:28.445, tt:284.454\n",
      "Ep:10, loss:0.00005, loss_test:0.02792, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:28.750, tt:316.249\n",
      "Ep:11, loss:0.00005, loss_test:0.02770, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:28.966, tt:347.587\n",
      "Ep:12, loss:0.00005, loss_test:0.02744, lr:6.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:29.185, tt:379.399\n",
      "Ep:13, loss:0.00005, loss_test:0.02706, lr:6.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:29.401, tt:411.617\n",
      "Ep:14, loss:0.00005, loss_test:0.02664, lr:6.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:29.576, tt:443.634\n",
      "Ep:15, loss:0.00005, loss_test:0.02622, lr:5.94e-02, fs:0.65693 (r=0.909,p=0.514),  time:29.682, tt:474.911\n",
      "Ep:16, loss:0.00005, loss_test:0.02572, lr:5.88e-02, fs:0.65934 (r=0.909,p=0.517),  time:29.823, tt:506.983\n",
      "Ep:17, loss:0.00005, loss_test:0.02534, lr:5.82e-02, fs:0.65693 (r=0.909,p=0.514),  time:29.891, tt:538.038\n",
      "Ep:18, loss:0.00005, loss_test:0.02485, lr:5.76e-02, fs:0.66667 (r=0.919,p=0.523),  time:29.968, tt:569.399\n",
      "Ep:19, loss:0.00005, loss_test:0.02424, lr:5.71e-02, fs:0.66667 (r=0.899,p=0.530),  time:29.975, tt:599.501\n",
      "Ep:20, loss:0.00005, loss_test:0.02360, lr:5.65e-02, fs:0.67669 (r=0.909,p=0.539),  time:29.981, tt:629.609\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00005, loss_test:0.02303, lr:5.65e-02, fs:0.68148 (r=0.929,p=0.538),  time:30.061, tt:661.350\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.02245, lr:5.65e-02, fs:0.68401 (r=0.929,p=0.541),  time:30.113, tt:692.591\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.02184, lr:5.65e-02, fs:0.67925 (r=0.909,p=0.542),  time:30.166, tt:723.979\n",
      "Ep:24, loss:0.00004, loss_test:0.02124, lr:5.65e-02, fs:0.68182 (r=0.909,p=0.545),  time:30.217, tt:755.422\n",
      "Ep:25, loss:0.00004, loss_test:0.02069, lr:5.65e-02, fs:0.68401 (r=0.929,p=0.541),  time:30.245, tt:786.358\n",
      "Ep:26, loss:0.00004, loss_test:0.02013, lr:5.65e-02, fs:0.68165 (r=0.919,p=0.542),  time:30.246, tt:816.650\n",
      "Ep:27, loss:0.00004, loss_test:0.01945, lr:5.65e-02, fs:0.68939 (r=0.919,p=0.552),  time:30.239, tt:846.690\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01880, lr:5.65e-02, fs:0.69202 (r=0.919,p=0.555),  time:30.279, tt:878.090\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01826, lr:5.65e-02, fs:0.70189 (r=0.939,p=0.560),  time:30.325, tt:909.749\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.01779, lr:5.65e-02, fs:0.70677 (r=0.949,p=0.563),  time:30.391, tt:942.121\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.01729, lr:5.65e-02, fs:0.71970 (r=0.960,p=0.576),  time:30.413, tt:973.208\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00004, loss_test:0.01684, lr:5.65e-02, fs:0.71264 (r=0.939,p=0.574),  time:30.427, tt:1004.095\n",
      "Ep:33, loss:0.00004, loss_test:0.01643, lr:5.65e-02, fs:0.73359 (r=0.960,p=0.594),  time:30.431, tt:1034.657\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01613, lr:5.65e-02, fs:0.73930 (r=0.960,p=0.601),  time:30.453, tt:1065.845\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01588, lr:5.65e-02, fs:0.73518 (r=0.939,p=0.604),  time:30.488, tt:1097.566\n",
      "Ep:36, loss:0.00003, loss_test:0.01569, lr:5.65e-02, fs:0.73810 (r=0.939,p=0.608),  time:30.471, tt:1127.444\n",
      "Ep:37, loss:0.00003, loss_test:0.01548, lr:5.65e-02, fs:0.74016 (r=0.949,p=0.606),  time:30.526, tt:1159.974\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01529, lr:5.65e-02, fs:0.74603 (r=0.949,p=0.614),  time:30.588, tt:1192.917\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01514, lr:5.65e-02, fs:0.74699 (r=0.939,p=0.620),  time:30.622, tt:1224.898\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01498, lr:5.65e-02, fs:0.75610 (r=0.939,p=0.633),  time:30.640, tt:1256.239\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01497, lr:5.65e-02, fs:0.75304 (r=0.939,p=0.628),  time:30.685, tt:1288.777\n",
      "Ep:42, loss:0.00003, loss_test:0.01481, lr:5.65e-02, fs:0.74699 (r=0.939,p=0.620),  time:30.681, tt:1319.293\n",
      "Ep:43, loss:0.00003, loss_test:0.01442, lr:5.65e-02, fs:0.76033 (r=0.929,p=0.643),  time:30.685, tt:1350.125\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01426, lr:5.65e-02, fs:0.75519 (r=0.919,p=0.641),  time:30.704, tt:1381.693\n",
      "Ep:45, loss:0.00003, loss_test:0.01408, lr:5.65e-02, fs:0.76543 (r=0.939,p=0.646),  time:30.703, tt:1412.354\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01397, lr:5.65e-02, fs:0.77119 (r=0.919,p=0.664),  time:30.698, tt:1442.790\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01379, lr:5.65e-02, fs:0.76349 (r=0.929,p=0.648),  time:30.707, tt:1473.941\n",
      "Ep:48, loss:0.00003, loss_test:0.01353, lr:5.65e-02, fs:0.78112 (r=0.919,p=0.679),  time:30.717, tt:1505.134\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01361, lr:5.65e-02, fs:0.78112 (r=0.919,p=0.679),  time:30.716, tt:1535.781\n",
      "Ep:50, loss:0.00002, loss_test:0.01342, lr:5.65e-02, fs:0.79310 (r=0.929,p=0.692),  time:30.734, tt:1567.453\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01325, lr:5.65e-02, fs:0.79130 (r=0.919,p=0.695),  time:30.739, tt:1598.403\n",
      "Ep:52, loss:0.00002, loss_test:0.01328, lr:5.65e-02, fs:0.78970 (r=0.929,p=0.687),  time:30.738, tt:1629.098\n",
      "Ep:53, loss:0.00002, loss_test:0.01331, lr:5.65e-02, fs:0.80687 (r=0.949,p=0.701),  time:30.783, tt:1662.277\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01310, lr:5.65e-02, fs:0.80176 (r=0.919,p=0.711),  time:30.771, tt:1692.417\n",
      "Ep:55, loss:0.00002, loss_test:0.01323, lr:5.65e-02, fs:0.81938 (r=0.939,p=0.727),  time:30.768, tt:1723.005\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01350, lr:5.65e-02, fs:0.81614 (r=0.919,p=0.734),  time:30.758, tt:1753.203\n",
      "Ep:57, loss:0.00002, loss_test:0.01344, lr:5.65e-02, fs:0.80889 (r=0.919,p=0.722),  time:30.746, tt:1783.252\n",
      "Ep:58, loss:0.00002, loss_test:0.01331, lr:5.65e-02, fs:0.83036 (r=0.939,p=0.744),  time:30.686, tt:1810.503\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00002, loss_test:0.01305, lr:5.65e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.704, tt:1842.253\n",
      "Ep:60, loss:0.00002, loss_test:0.01325, lr:5.65e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.737, tt:1874.938\n",
      "Ep:61, loss:0.00002, loss_test:0.01371, lr:5.65e-02, fs:0.83105 (r=0.919,p=0.758),  time:30.738, tt:1905.763\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01356, lr:5.65e-02, fs:0.84932 (r=0.939,p=0.775),  time:30.750, tt:1937.266\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01352, lr:5.65e-02, fs:0.83636 (r=0.929,p=0.760),  time:30.758, tt:1968.538\n",
      "Ep:64, loss:0.00001, loss_test:0.01393, lr:5.65e-02, fs:0.83178 (r=0.899,p=0.774),  time:30.757, tt:1999.177\n",
      "Ep:65, loss:0.00002, loss_test:0.01483, lr:5.65e-02, fs:0.80000 (r=0.889,p=0.727),  time:30.750, tt:2029.481\n",
      "Ep:66, loss:0.00002, loss_test:0.01353, lr:5.65e-02, fs:0.83178 (r=0.899,p=0.774),  time:30.760, tt:2060.943\n",
      "Ep:67, loss:0.00002, loss_test:0.01363, lr:5.65e-02, fs:0.82629 (r=0.889,p=0.772),  time:30.776, tt:2092.745\n",
      "Ep:68, loss:0.00002, loss_test:0.01343, lr:5.65e-02, fs:0.81818 (r=0.909,p=0.744),  time:30.759, tt:2122.385\n",
      "Ep:69, loss:0.00001, loss_test:0.01462, lr:5.65e-02, fs:0.80000 (r=0.848,p=0.757),  time:30.773, tt:2154.096\n",
      "Ep:70, loss:0.00001, loss_test:0.01339, lr:5.65e-02, fs:0.82407 (r=0.899,p=0.761),  time:30.784, tt:2185.688\n",
      "Ep:71, loss:0.00001, loss_test:0.01334, lr:5.65e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.784, tt:2216.476\n",
      "Ep:72, loss:0.00001, loss_test:0.01378, lr:5.65e-02, fs:0.81340 (r=0.859,p=0.773),  time:30.780, tt:2246.925\n",
      "Ep:73, loss:0.00001, loss_test:0.01349, lr:5.65e-02, fs:0.81340 (r=0.859,p=0.773),  time:30.776, tt:2277.414\n",
      "Ep:74, loss:0.00001, loss_test:0.01482, lr:5.59e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.774, tt:2308.084\n",
      "Ep:75, loss:0.00001, loss_test:0.01407, lr:5.54e-02, fs:0.81553 (r=0.848,p=0.785),  time:30.772, tt:2338.691\n",
      "Ep:76, loss:0.00001, loss_test:0.01459, lr:5.48e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.786, tt:2370.487\n",
      "Ep:77, loss:0.00001, loss_test:0.01549, lr:5.43e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.790, tt:2401.613\n",
      "Ep:78, loss:0.00001, loss_test:0.01479, lr:5.37e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.758, tt:2429.908\n",
      "Ep:79, loss:0.00001, loss_test:0.01553, lr:5.32e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.763, tt:2461.028\n",
      "Ep:80, loss:0.00001, loss_test:0.01479, lr:5.27e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.775, tt:2492.800\n",
      "Ep:81, loss:0.00001, loss_test:0.01588, lr:5.21e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.764, tt:2522.638\n",
      "Ep:82, loss:0.00001, loss_test:0.01620, lr:5.16e-02, fs:0.80203 (r=0.798,p=0.806),  time:30.758, tt:2552.889\n",
      "Ep:83, loss:0.00001, loss_test:0.01664, lr:5.11e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.763, tt:2584.052\n",
      "Ep:84, loss:0.00001, loss_test:0.01674, lr:5.06e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.742, tt:2613.097\n",
      "Ep:85, loss:0.00001, loss_test:0.01497, lr:5.01e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.770, tt:2646.186\n",
      "Ep:86, loss:0.00001, loss_test:0.01661, lr:4.96e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.760, tt:2676.111\n",
      "Ep:87, loss:0.00001, loss_test:0.01714, lr:4.91e-02, fs:0.77895 (r=0.747,p=0.813),  time:30.790, tt:2709.549\n",
      "Ep:88, loss:0.00001, loss_test:0.01808, lr:4.86e-02, fs:0.75269 (r=0.707,p=0.805),  time:30.793, tt:2740.616\n",
      "Ep:89, loss:0.00001, loss_test:0.01751, lr:4.81e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.793, tt:2771.407\n",
      "Ep:90, loss:0.00001, loss_test:0.01767, lr:4.76e-02, fs:0.76923 (r=0.707,p=0.843),  time:30.804, tt:2803.169\n",
      "Ep:91, loss:0.00001, loss_test:0.01712, lr:4.71e-02, fs:0.78495 (r=0.737,p=0.839),  time:30.809, tt:2834.421\n",
      "Ep:92, loss:0.00001, loss_test:0.01661, lr:4.67e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.827, tt:2866.909\n",
      "Ep:93, loss:0.00001, loss_test:0.01867, lr:4.62e-02, fs:0.79381 (r=0.778,p=0.811),  time:30.828, tt:2897.845\n",
      "Ep:94, loss:0.00001, loss_test:0.01611, lr:4.57e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.841, tt:2929.868\n",
      "Ep:95, loss:0.00001, loss_test:0.01650, lr:4.53e-02, fs:0.81026 (r=0.798,p=0.823),  time:30.840, tt:2960.612\n",
      "Ep:96, loss:0.00001, loss_test:0.01732, lr:4.48e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.837, tt:2991.226\n",
      "Ep:97, loss:0.00001, loss_test:0.01651, lr:4.44e-02, fs:0.81250 (r=0.788,p=0.839),  time:30.843, tt:3022.655\n",
      "Ep:98, loss:0.00001, loss_test:0.01964, lr:4.39e-02, fs:0.76087 (r=0.707,p=0.824),  time:30.850, tt:3054.134\n",
      "Ep:99, loss:0.00001, loss_test:0.01749, lr:4.35e-02, fs:0.78022 (r=0.717,p=0.855),  time:30.856, tt:3085.605\n",
      "Ep:100, loss:0.00001, loss_test:0.01862, lr:4.31e-02, fs:0.78919 (r=0.737,p=0.849),  time:30.854, tt:3116.260\n",
      "Ep:101, loss:0.00001, loss_test:0.01973, lr:4.26e-02, fs:0.78022 (r=0.717,p=0.855),  time:30.866, tt:3148.323\n",
      "Ep:102, loss:0.00001, loss_test:0.01779, lr:4.22e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.867, tt:3179.343\n",
      "Ep:103, loss:0.00001, loss_test:0.01907, lr:4.18e-02, fs:0.78453 (r=0.717,p=0.866),  time:30.871, tt:3210.576\n",
      "Ep:104, loss:0.00001, loss_test:0.01937, lr:4.14e-02, fs:0.76243 (r=0.697,p=0.841),  time:30.865, tt:3240.788\n",
      "Ep:105, loss:0.00001, loss_test:0.01980, lr:4.10e-02, fs:0.76404 (r=0.687,p=0.861),  time:30.872, tt:3272.396\n",
      "Ep:106, loss:0.00001, loss_test:0.01873, lr:4.05e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.886, tt:3304.755\n",
      "Ep:107, loss:0.00000, loss_test:0.02107, lr:4.01e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.891, tt:3336.223\n",
      "Ep:108, loss:0.00001, loss_test:0.01895, lr:3.97e-02, fs:0.77528 (r=0.697,p=0.873),  time:30.898, tt:3367.917\n",
      "Ep:109, loss:0.00001, loss_test:0.02015, lr:3.93e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.912, tt:3400.297\n",
      "Ep:110, loss:0.00000, loss_test:0.02077, lr:3.89e-02, fs:0.72832 (r=0.636,p=0.851),  time:30.912, tt:3431.195\n",
      "Ep:111, loss:0.00000, loss_test:0.02022, lr:3.86e-02, fs:0.73988 (r=0.646,p=0.865),  time:30.929, tt:3464.064\n",
      "Ep:112, loss:0.00000, loss_test:0.02123, lr:3.82e-02, fs:0.68263 (r=0.576,p=0.838),  time:30.939, tt:3496.130\n",
      "Ep:113, loss:0.00000, loss_test:0.02102, lr:3.78e-02, fs:0.67073 (r=0.556,p=0.846),  time:30.940, tt:3527.158\n",
      "Ep:114, loss:0.00000, loss_test:0.02140, lr:3.74e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.949, tt:3559.136\n",
      "Ep:115, loss:0.00000, loss_test:0.02160, lr:3.70e-02, fs:0.69048 (r=0.586,p=0.841),  time:30.962, tt:3591.609\n",
      "Ep:116, loss:0.00000, loss_test:0.02245, lr:3.67e-02, fs:0.68675 (r=0.576,p=0.851),  time:30.973, tt:3623.875\n",
      "Ep:117, loss:0.00000, loss_test:0.02188, lr:3.63e-02, fs:0.70303 (r=0.586,p=0.879),  time:30.983, tt:3655.978\n",
      "Ep:118, loss:0.00000, loss_test:0.02225, lr:3.59e-02, fs:0.68675 (r=0.576,p=0.851),  time:30.986, tt:3687.360\n",
      "Ep:119, loss:0.00000, loss_test:0.02304, lr:3.56e-02, fs:0.67485 (r=0.556,p=0.859),  time:30.998, tt:3719.720\n",
      "Ep:120, loss:0.00000, loss_test:0.02198, lr:3.52e-02, fs:0.71856 (r=0.606,p=0.882),  time:31.002, tt:3751.231\n",
      "Ep:121, loss:0.00000, loss_test:0.02353, lr:3.49e-02, fs:0.69461 (r=0.586,p=0.853),  time:31.003, tt:3782.409\n",
      "Ep:122, loss:0.00000, loss_test:0.02333, lr:3.45e-02, fs:0.67485 (r=0.556,p=0.859),  time:31.006, tt:3813.767\n",
      "Ep:123, loss:0.00000, loss_test:0.02193, lr:3.42e-02, fs:0.72289 (r=0.606,p=0.896),  time:31.009, tt:3845.121\n",
      "Ep:124, loss:0.00000, loss_test:0.02434, lr:3.38e-02, fs:0.71084 (r=0.596,p=0.881),  time:31.007, tt:3875.908\n",
      "Ep:125, loss:0.00000, loss_test:0.02248, lr:3.35e-02, fs:0.71515 (r=0.596,p=0.894),  time:31.013, tt:3907.663\n",
      "Ep:126, loss:0.00000, loss_test:0.02350, lr:3.32e-02, fs:0.68323 (r=0.556,p=0.887),  time:31.007, tt:3937.870\n",
      "Ep:127, loss:0.00000, loss_test:0.02325, lr:3.28e-02, fs:0.70303 (r=0.586,p=0.879),  time:31.006, tt:3968.745\n",
      "Ep:128, loss:0.00000, loss_test:0.02347, lr:3.25e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.008, tt:4000.015\n",
      "Ep:129, loss:0.00000, loss_test:0.02423, lr:3.22e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.002, tt:4030.298\n",
      "Ep:130, loss:0.00000, loss_test:0.02401, lr:3.19e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.013, tt:4062.666\n",
      "Ep:131, loss:0.00000, loss_test:0.02455, lr:3.15e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.007, tt:4092.945\n",
      "Ep:132, loss:0.00000, loss_test:0.02510, lr:3.12e-02, fs:0.68323 (r=0.556,p=0.887),  time:31.016, tt:4125.157\n",
      "Ep:133, loss:0.00000, loss_test:0.02548, lr:3.09e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.019, tt:4156.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.02454, lr:3.06e-02, fs:0.71166 (r=0.586,p=0.906),  time:31.030, tt:4189.036\n",
      "Ep:135, loss:0.00000, loss_test:0.02560, lr:3.03e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.042, tt:4221.678\n",
      "Ep:136, loss:0.00000, loss_test:0.02542, lr:3.00e-02, fs:0.68323 (r=0.556,p=0.887),  time:31.052, tt:4254.132\n",
      "Ep:137, loss:0.00000, loss_test:0.02489, lr:2.97e-02, fs:0.69565 (r=0.566,p=0.903),  time:31.054, tt:4285.407\n",
      "Ep:138, loss:0.00000, loss_test:0.02593, lr:2.94e-02, fs:0.68323 (r=0.556,p=0.887),  time:31.053, tt:4316.401\n",
      "Ep:139, loss:0.00000, loss_test:0.02550, lr:2.91e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.053, tt:4347.458\n",
      "Ep:140, loss:0.00000, loss_test:0.02603, lr:2.88e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.056, tt:4378.919\n",
      "Ep:141, loss:0.00000, loss_test:0.02629, lr:2.85e-02, fs:0.68323 (r=0.556,p=0.887),  time:31.059, tt:4410.389\n",
      "Ep:142, loss:0.00000, loss_test:0.02628, lr:2.82e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.045, tt:4439.450\n",
      "Ep:143, loss:0.00000, loss_test:0.02586, lr:2.80e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.036, tt:4469.157\n",
      "Ep:144, loss:0.00000, loss_test:0.02696, lr:2.77e-02, fs:0.68323 (r=0.556,p=0.887),  time:31.022, tt:4498.121\n",
      "Ep:145, loss:0.00000, loss_test:0.02626, lr:2.74e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.014, tt:4528.087\n",
      "Ep:146, loss:0.00000, loss_test:0.02668, lr:2.71e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.013, tt:4558.969\n",
      "Ep:147, loss:0.00000, loss_test:0.02712, lr:2.69e-02, fs:0.68750 (r=0.556,p=0.902),  time:31.009, tt:4589.314\n",
      "Ep:148, loss:0.00000, loss_test:0.02682, lr:2.66e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.991, tt:4617.714\n",
      "Ep:149, loss:0.00000, loss_test:0.02708, lr:2.63e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.983, tt:4647.398\n",
      "Ep:150, loss:0.00000, loss_test:0.02813, lr:2.61e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.971, tt:4676.579\n",
      "Ep:151, loss:0.00000, loss_test:0.02712, lr:2.58e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.969, tt:4707.347\n",
      "Ep:152, loss:0.00000, loss_test:0.02758, lr:2.55e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.972, tt:4738.788\n",
      "Ep:153, loss:0.00000, loss_test:0.02800, lr:2.53e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.956, tt:4767.197\n",
      "Ep:154, loss:0.00000, loss_test:0.02688, lr:2.50e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.947, tt:4796.805\n",
      "Ep:155, loss:0.00000, loss_test:0.02839, lr:2.48e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.943, tt:4827.064\n",
      "Ep:156, loss:0.00000, loss_test:0.02754, lr:2.45e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.939, tt:4857.416\n",
      "Ep:157, loss:0.00000, loss_test:0.02756, lr:2.43e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.943, tt:4889.032\n",
      "Ep:158, loss:0.00000, loss_test:0.02913, lr:2.40e-02, fs:0.70000 (r=0.566,p=0.918),  time:30.943, tt:4919.912\n",
      "Ep:159, loss:0.00000, loss_test:0.02650, lr:2.38e-02, fs:0.71605 (r=0.586,p=0.921),  time:30.934, tt:4949.500\n",
      "Ep:160, loss:0.00000, loss_test:0.02920, lr:2.36e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.929, tt:4979.636\n",
      "Ep:161, loss:0.00000, loss_test:0.02704, lr:2.33e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.934, tt:5011.287\n",
      "Ep:162, loss:0.00000, loss_test:0.02793, lr:2.31e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.937, tt:5042.770\n",
      "Ep:163, loss:0.00000, loss_test:0.02806, lr:2.29e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.949, tt:5075.609\n",
      "Ep:164, loss:0.00000, loss_test:0.02832, lr:2.26e-02, fs:0.68750 (r=0.556,p=0.902),  time:30.956, tt:5107.757\n",
      "Ep:165, loss:0.00000, loss_test:0.02827, lr:2.24e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.964, tt:5139.970\n",
      "Ep:166, loss:0.00000, loss_test:0.02861, lr:2.22e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.967, tt:5171.478\n",
      "Ep:167, loss:0.00000, loss_test:0.02914, lr:2.20e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.979, tt:5204.505\n",
      "Ep:168, loss:0.00000, loss_test:0.02899, lr:2.17e-02, fs:0.69620 (r=0.556,p=0.932),  time:30.985, tt:5236.511\n",
      "Ep:169, loss:0.00000, loss_test:0.02899, lr:2.15e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.994, tt:5268.910\n",
      "Ep:170, loss:0.00000, loss_test:0.02953, lr:2.13e-02, fs:0.69182 (r=0.556,p=0.917),  time:30.996, tt:5300.278\n",
      "Ep:171, loss:0.00000, loss_test:0.02921, lr:2.11e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.007, tt:5333.214\n",
      "Ep:172, loss:0.00000, loss_test:0.02975, lr:2.09e-02, fs:0.69182 (r=0.556,p=0.917),  time:31.017, tt:5365.950\n",
      "Ep:173, loss:0.00000, loss_test:0.02970, lr:2.07e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.019, tt:5397.326\n",
      "Ep:174, loss:0.00000, loss_test:0.02991, lr:2.05e-02, fs:0.69182 (r=0.556,p=0.917),  time:31.038, tt:5431.636\n",
      "Ep:175, loss:0.00000, loss_test:0.02977, lr:2.03e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.040, tt:5463.113\n",
      "Ep:176, loss:0.00000, loss_test:0.02998, lr:2.01e-02, fs:0.69182 (r=0.556,p=0.917),  time:31.045, tt:5494.950\n",
      "Ep:177, loss:0.00000, loss_test:0.03016, lr:1.99e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.058, tt:5528.293\n",
      "Ep:178, loss:0.00000, loss_test:0.03016, lr:1.97e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.063, tt:5560.189\n",
      "Ep:179, loss:0.00000, loss_test:0.03036, lr:1.95e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.061, tt:5590.975\n",
      "Ep:180, loss:0.00000, loss_test:0.03025, lr:1.93e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.070, tt:5623.608\n",
      "Ep:181, loss:0.00000, loss_test:0.03069, lr:1.91e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.074, tt:5655.534\n",
      "Ep:182, loss:0.00000, loss_test:0.03047, lr:1.89e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.079, tt:5687.510\n",
      "Ep:183, loss:0.00000, loss_test:0.03084, lr:1.87e-02, fs:0.69182 (r=0.556,p=0.917),  time:31.083, tt:5719.251\n",
      "Ep:184, loss:0.00000, loss_test:0.03040, lr:1.85e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.086, tt:5750.989\n",
      "Ep:185, loss:0.00000, loss_test:0.03097, lr:1.83e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.090, tt:5782.799\n",
      "Ep:186, loss:0.00000, loss_test:0.03089, lr:1.81e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.091, tt:5813.969\n",
      "Ep:187, loss:0.00000, loss_test:0.03103, lr:1.80e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.099, tt:5846.586\n",
      "Ep:188, loss:0.00000, loss_test:0.03108, lr:1.78e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.103, tt:5878.396\n",
      "Ep:189, loss:0.00000, loss_test:0.03129, lr:1.76e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.098, tt:5908.688\n",
      "Ep:190, loss:0.00000, loss_test:0.03132, lr:1.74e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.100, tt:5940.062\n",
      "Ep:191, loss:0.00000, loss_test:0.03113, lr:1.73e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.106, tt:5972.268\n",
      "Ep:192, loss:0.00000, loss_test:0.03162, lr:1.71e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.105, tt:6003.307\n",
      "Ep:193, loss:0.00000, loss_test:0.03127, lr:1.69e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.115, tt:6036.235\n",
      "Ep:194, loss:0.00000, loss_test:0.03160, lr:1.67e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.114, tt:6067.273\n",
      "Ep:195, loss:0.00000, loss_test:0.03155, lr:1.66e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.113, tt:6098.157\n",
      "Ep:196, loss:0.00000, loss_test:0.03172, lr:1.64e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.134, tt:6133.438\n",
      "Ep:197, loss:0.00000, loss_test:0.03190, lr:1.62e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.137, tt:6165.043\n",
      "Ep:198, loss:0.00000, loss_test:0.03176, lr:1.61e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.130, tt:6194.788\n",
      "Ep:199, loss:0.00000, loss_test:0.03193, lr:1.59e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.128, tt:6225.660\n",
      "Ep:200, loss:0.00000, loss_test:0.03210, lr:1.58e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.122, tt:6255.617\n",
      "Ep:201, loss:0.00000, loss_test:0.03189, lr:1.56e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.122, tt:6286.729\n",
      "Ep:202, loss:0.00000, loss_test:0.03224, lr:1.54e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.117, tt:6316.670\n",
      "Ep:203, loss:0.00000, loss_test:0.03209, lr:1.53e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.102, tt:6344.903\n",
      "Ep:204, loss:0.00000, loss_test:0.03239, lr:1.51e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.102, tt:6375.923\n",
      "Ep:205, loss:0.00000, loss_test:0.03227, lr:1.50e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.084, tt:6403.307\n",
      "Ep:206, loss:0.00000, loss_test:0.03227, lr:1.48e-02, fs:0.69620 (r=0.556,p=0.932),  time:31.049, tt:6427.137\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13156, lr:1.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:31.353, tt:31.353\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13113, lr:1.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:25.498, tt:50.996\n",
      "Ep:2, loss:0.00026, loss_test:0.13069, lr:1.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:26.556, tt:79.668\n",
      "Ep:3, loss:0.00026, loss_test:0.12991, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:27.268, tt:109.071\n",
      "Ep:4, loss:0.00026, loss_test:0.12930, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:27.521, tt:137.606\n",
      "Ep:5, loss:0.00025, loss_test:0.12871, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:28.388, tt:170.330\n",
      "Ep:6, loss:0.00025, loss_test:0.12826, lr:1.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:28.908, tt:202.356\n",
      "Ep:7, loss:0.00025, loss_test:0.12748, lr:1.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:29.088, tt:232.700\n",
      "Ep:8, loss:0.00025, loss_test:0.12636, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:29.460, tt:265.140\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12515, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.656, tt:296.557\n",
      "Ep:10, loss:0.00025, loss_test:0.12351, lr:1.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:29.870, tt:328.569\n",
      "Ep:11, loss:0.00024, loss_test:0.12211, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:29.963, tt:359.559\n",
      "Ep:12, loss:0.00024, loss_test:0.12127, lr:1.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:30.042, tt:390.551\n",
      "Ep:13, loss:0.00024, loss_test:0.12114, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:30.048, tt:420.672\n",
      "Ep:14, loss:0.00024, loss_test:0.12004, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:30.203, tt:453.052\n",
      "Ep:15, loss:0.00023, loss_test:0.11840, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:30.331, tt:485.300\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.11646, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:30.495, tt:518.410\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.11544, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:30.512, tt:549.222\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.11408, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:30.360, tt:576.847\n",
      "Ep:19, loss:0.00022, loss_test:0.11014, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:30.315, tt:606.298\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10822, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:30.354, tt:637.438\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10504, lr:1.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:30.357, tt:667.856\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.10141, lr:1.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:30.431, tt:699.903\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.09944, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:30.418, tt:730.042\n",
      "Ep:24, loss:0.00019, loss_test:0.09718, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:30.398, tt:759.954\n",
      "Ep:25, loss:0.00018, loss_test:0.09426, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:30.375, tt:789.739\n",
      "Ep:26, loss:0.00017, loss_test:0.09189, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:30.398, tt:820.739\n",
      "Ep:27, loss:0.00017, loss_test:0.09001, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:30.369, tt:850.335\n",
      "Ep:28, loss:0.00016, loss_test:0.08947, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:30.356, tt:880.338\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.08908, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:30.376, tt:911.275\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.08759, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:30.377, tt:941.688\n",
      "Ep:31, loss:0.00015, loss_test:0.08640, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:30.368, tt:971.767\n",
      "Ep:32, loss:0.00014, loss_test:0.08575, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:30.358, tt:1001.824\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08437, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:30.335, tt:1031.396\n",
      "Ep:34, loss:0.00013, loss_test:0.08345, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:30.298, tt:1060.415\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.07993, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.304, tt:1090.929\n",
      "Ep:36, loss:0.00012, loss_test:0.08107, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:30.318, tt:1121.770\n",
      "Ep:37, loss:0.00011, loss_test:0.08102, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:30.321, tt:1152.188\n",
      "Ep:38, loss:0.00010, loss_test:0.07520, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.372, tt:1184.494\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07617, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.419, tt:1216.762\n",
      "Ep:40, loss:0.00009, loss_test:0.07144, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:30.436, tt:1247.875\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07528, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.496, tt:1280.841\n",
      "Ep:42, loss:0.00009, loss_test:0.06938, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:30.533, tt:1312.910\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.07278, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.626, tt:1347.543\n",
      "Ep:44, loss:0.00008, loss_test:0.07308, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.608, tt:1377.341\n",
      "Ep:45, loss:0.00008, loss_test:0.07263, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:30.622, tt:1408.630\n",
      "Ep:46, loss:0.00008, loss_test:0.07241, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:30.635, tt:1439.830\n",
      "Ep:47, loss:0.00009, loss_test:0.06755, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.623, tt:1469.888\n",
      "Ep:48, loss:0.00007, loss_test:0.07090, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.642, tt:1501.464\n",
      "Ep:49, loss:0.00007, loss_test:0.07460, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:30.681, tt:1534.055\n",
      "Ep:50, loss:0.00006, loss_test:0.06845, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.729, tt:1567.159\n",
      "Ep:51, loss:0.00006, loss_test:0.07408, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.766, tt:1599.823\n",
      "Ep:52, loss:0.00005, loss_test:0.06044, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.798, tt:1632.314\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06561, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.830, tt:1664.802\n",
      "Ep:54, loss:0.00005, loss_test:0.06692, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.869, tt:1697.780\n",
      "Ep:55, loss:0.00005, loss_test:0.07154, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.899, tt:1730.339\n",
      "Ep:56, loss:0.00005, loss_test:0.07131, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:30.925, tt:1762.740\n",
      "Ep:57, loss:0.00008, loss_test:0.06503, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.924, tt:1793.570\n",
      "Ep:58, loss:0.00006, loss_test:0.06866, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.944, tt:1825.690\n",
      "Ep:59, loss:0.00005, loss_test:0.07127, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.978, tt:1858.690\n",
      "Ep:60, loss:0.00005, loss_test:0.07377, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.029, tt:1892.746\n",
      "Ep:61, loss:0.00005, loss_test:0.06801, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.059, tt:1925.630\n",
      "Ep:62, loss:0.00004, loss_test:0.08404, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:31.075, tt:1957.742\n",
      "Ep:63, loss:0.00005, loss_test:0.06994, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.084, tt:1989.398\n",
      "Ep:64, loss:0.00005, loss_test:0.08181, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.093, tt:2021.022\n",
      "Ep:65, loss:0.00004, loss_test:0.06965, lr:9.80e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.112, tt:2053.389\n",
      "Ep:66, loss:0.00004, loss_test:0.06924, lr:9.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.135, tt:2086.040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00003, loss_test:0.07271, lr:9.61e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.153, tt:2118.373\n",
      "Ep:68, loss:0.00003, loss_test:0.08039, lr:9.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.140, tt:2148.650\n",
      "Ep:69, loss:0.00003, loss_test:0.06932, lr:9.41e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.159, tt:2181.127\n",
      "Ep:70, loss:0.00003, loss_test:0.07116, lr:9.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.176, tt:2213.463\n",
      "Ep:71, loss:0.00003, loss_test:0.07674, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.180, tt:2244.939\n",
      "Ep:72, loss:0.00003, loss_test:0.07029, lr:9.14e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.172, tt:2275.559\n",
      "Ep:73, loss:0.00003, loss_test:0.07002, lr:9.04e-03, fs:0.82979 (r=0.788,p=0.876),  time:31.170, tt:2306.568\n",
      "Ep:74, loss:0.00003, loss_test:0.07041, lr:8.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.170, tt:2337.724\n",
      "Ep:75, loss:0.00002, loss_test:0.07183, lr:8.86e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.188, tt:2370.323\n",
      "Ep:76, loss:0.00002, loss_test:0.07984, lr:8.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.213, tt:2403.369\n",
      "Ep:77, loss:0.00002, loss_test:0.08057, lr:8.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.232, tt:2436.133\n",
      "Ep:78, loss:0.00002, loss_test:0.06824, lr:8.60e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.213, tt:2465.840\n",
      "Ep:79, loss:0.00002, loss_test:0.07549, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.235, tt:2498.799\n",
      "Ep:80, loss:0.00002, loss_test:0.07135, lr:8.43e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.244, tt:2530.783\n",
      "Ep:81, loss:0.00002, loss_test:0.07772, lr:8.35e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.237, tt:2561.431\n",
      "Ep:82, loss:0.00001, loss_test:0.07836, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.237, tt:2592.703\n",
      "Ep:83, loss:0.00001, loss_test:0.07527, lr:8.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.246, tt:2624.643\n",
      "Ep:84, loss:0.00001, loss_test:0.06871, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.268, tt:2657.765\n",
      "Ep:85, loss:0.00001, loss_test:0.07690, lr:8.02e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.262, tt:2688.544\n",
      "Ep:86, loss:0.00001, loss_test:0.07591, lr:7.94e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.280, tt:2721.403\n",
      "Ep:87, loss:0.00001, loss_test:0.07259, lr:7.86e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.279, tt:2752.556\n",
      "Ep:88, loss:0.00001, loss_test:0.07432, lr:7.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.293, tt:2785.042\n",
      "Ep:89, loss:0.00001, loss_test:0.07682, lr:7.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.318, tt:2818.611\n",
      "Ep:90, loss:0.00001, loss_test:0.07586, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.341, tt:2852.022\n",
      "Ep:91, loss:0.00001, loss_test:0.07239, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.384, tt:2887.360\n",
      "Ep:92, loss:0.00001, loss_test:0.07768, lr:7.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.414, tt:2921.529\n",
      "Ep:93, loss:0.00001, loss_test:0.07017, lr:7.40e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.467, tt:2957.864\n",
      "Ep:94, loss:0.00001, loss_test:0.08109, lr:7.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.506, tt:2993.072\n",
      "Ep:95, loss:0.00001, loss_test:0.07742, lr:7.25e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.554, tt:3029.147\n",
      "Ep:96, loss:0.00001, loss_test:0.07373, lr:7.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.595, tt:3064.701\n",
      "Ep:97, loss:0.00001, loss_test:0.07775, lr:7.11e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.636, tt:3100.324\n",
      "Ep:98, loss:0.00001, loss_test:0.07743, lr:7.03e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.682, tt:3136.535\n",
      "Ep:99, loss:0.00001, loss_test:0.07638, lr:6.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.728, tt:3172.754\n",
      "Ep:100, loss:0.00001, loss_test:0.07658, lr:6.89e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.761, tt:3207.842\n",
      "Ep:101, loss:0.00001, loss_test:0.07493, lr:6.83e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.788, tt:3242.362\n",
      "Ep:102, loss:0.00001, loss_test:0.07909, lr:6.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.820, tt:3277.512\n",
      "Ep:103, loss:0.00001, loss_test:0.07472, lr:6.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.851, tt:3312.545\n",
      "Ep:104, loss:0.00001, loss_test:0.07956, lr:6.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.869, tt:3346.240\n",
      "Ep:105, loss:0.00001, loss_test:0.07766, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:31.907, tt:3382.148\n",
      "Ep:106, loss:0.00001, loss_test:0.07860, lr:6.49e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.941, tt:3417.740\n",
      "Ep:107, loss:0.00001, loss_test:0.07515, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.964, tt:3452.078\n",
      "Ep:108, loss:0.00001, loss_test:0.07976, lr:6.36e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.995, tt:3487.413\n",
      "Ep:109, loss:0.00001, loss_test:0.07334, lr:6.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.015, tt:3521.646\n",
      "Ep:110, loss:0.00001, loss_test:0.08017, lr:6.24e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.043, tt:3556.819\n",
      "Ep:111, loss:0.00001, loss_test:0.07832, lr:6.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.076, tt:3592.475\n",
      "Ep:112, loss:0.00001, loss_test:0.07964, lr:6.11e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.116, tt:3629.106\n",
      "Ep:113, loss:0.00000, loss_test:0.07637, lr:6.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.143, tt:3664.287\n",
      "Ep:114, loss:0.00000, loss_test:0.07960, lr:5.99e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.172, tt:3699.823\n",
      "Ep:115, loss:0.00000, loss_test:0.07580, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.228, tt:3738.423\n",
      "Ep:116, loss:0.00000, loss_test:0.08008, lr:5.87e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.263, tt:3774.722\n",
      "Ep:117, loss:0.00000, loss_test:0.07798, lr:5.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.292, tt:3810.422\n",
      "Ep:118, loss:0.00000, loss_test:0.07786, lr:5.75e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.345, tt:3849.040\n",
      "Ep:119, loss:0.00000, loss_test:0.07702, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.372, tt:3884.602\n",
      "Ep:120, loss:0.00000, loss_test:0.08195, lr:5.64e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.401, tt:3920.505\n",
      "Ep:121, loss:0.00000, loss_test:0.07681, lr:5.58e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.432, tt:3956.682\n",
      "Ep:122, loss:0.00000, loss_test:0.07782, lr:5.53e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.464, tt:3993.075\n",
      "Ep:123, loss:0.00000, loss_test:0.07715, lr:5.47e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.483, tt:4027.872\n",
      "Ep:124, loss:0.00000, loss_test:0.07949, lr:5.42e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.505, tt:4063.188\n",
      "Ep:125, loss:0.00000, loss_test:0.07708, lr:5.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.529, tt:4098.696\n",
      "Ep:126, loss:0.00000, loss_test:0.08422, lr:5.31e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.549, tt:4133.760\n",
      "Ep:127, loss:0.00000, loss_test:0.07753, lr:5.26e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.570, tt:4168.987\n",
      "Ep:128, loss:0.00000, loss_test:0.08267, lr:5.20e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.590, tt:4204.072\n",
      "Ep:129, loss:0.00000, loss_test:0.07629, lr:5.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.610, tt:4239.266\n",
      "Ep:130, loss:0.00000, loss_test:0.08430, lr:5.10e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.637, tt:4275.473\n",
      "Ep:131, loss:0.00000, loss_test:0.07581, lr:5.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.663, tt:4311.469\n",
      "Ep:132, loss:0.00000, loss_test:0.08012, lr:5.00e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.689, tt:4347.600\n",
      "Ep:133, loss:0.00000, loss_test:0.08244, lr:4.95e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.715, tt:4383.749\n",
      "Ep:134, loss:0.00000, loss_test:0.07850, lr:4.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.742, tt:4420.127\n",
      "Ep:135, loss:0.00000, loss_test:0.08020, lr:4.85e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.768, tt:4456.457\n",
      "Ep:136, loss:0.00000, loss_test:0.07999, lr:4.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.793, tt:4492.674\n",
      "Ep:137, loss:0.00000, loss_test:0.08094, lr:4.75e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.821, tt:4529.300\n",
      "Ep:138, loss:0.00000, loss_test:0.08104, lr:4.71e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.834, tt:4563.993\n",
      "Ep:139, loss:0.00000, loss_test:0.07992, lr:4.66e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.857, tt:4599.988\n",
      "Ep:140, loss:0.00000, loss_test:0.08122, lr:4.61e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.886, tt:4636.934\n",
      "Ep:141, loss:0.00000, loss_test:0.08016, lr:4.57e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.905, tt:4672.442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.08129, lr:4.52e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.928, tt:4708.685\n",
      "Ep:143, loss:0.00000, loss_test:0.08153, lr:4.48e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.959, tt:4746.113\n",
      "Ep:144, loss:0.00000, loss_test:0.08242, lr:4.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.980, tt:4782.028\n",
      "Ep:145, loss:0.00000, loss_test:0.07849, lr:4.39e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.999, tt:4817.820\n",
      "Ep:146, loss:0.00000, loss_test:0.08162, lr:4.34e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.015, tt:4853.218\n",
      "Ep:147, loss:0.00000, loss_test:0.08053, lr:4.30e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.032, tt:4888.769\n",
      "Ep:148, loss:0.00000, loss_test:0.08195, lr:4.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.051, tt:4924.552\n",
      "Ep:149, loss:0.00000, loss_test:0.07833, lr:4.21e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.075, tt:4961.252\n",
      "Ep:150, loss:0.00000, loss_test:0.08416, lr:4.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.100, tt:4998.133\n",
      "Ep:151, loss:0.00000, loss_test:0.08199, lr:4.13e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.118, tt:5033.890\n",
      "Ep:152, loss:0.00000, loss_test:0.07871, lr:4.09e-03, fs:0.82759 (r=0.727,p=0.960),  time:33.147, tt:5071.542\n",
      "Ep:153, loss:0.00000, loss_test:0.08367, lr:4.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.164, tt:5107.311\n",
      "Ep:154, loss:0.00000, loss_test:0.08083, lr:4.01e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.180, tt:5142.928\n",
      "Ep:155, loss:0.00000, loss_test:0.08140, lr:3.97e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.194, tt:5178.261\n",
      "Ep:156, loss:0.00000, loss_test:0.08227, lr:3.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.220, tt:5215.466\n",
      "Ep:157, loss:0.00000, loss_test:0.07897, lr:3.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.251, tt:5253.714\n",
      "Ep:158, loss:0.00000, loss_test:0.08112, lr:3.85e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.271, tt:5290.152\n",
      "Ep:159, loss:0.00000, loss_test:0.08189, lr:3.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.285, tt:5325.533\n",
      "Ep:160, loss:0.00000, loss_test:0.07959, lr:3.77e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.307, tt:5362.347\n",
      "Ep:161, loss:0.00000, loss_test:0.08308, lr:3.73e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.332, tt:5399.799\n",
      "Ep:162, loss:0.00000, loss_test:0.08275, lr:3.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.353, tt:5436.463\n",
      "Ep:163, loss:0.00000, loss_test:0.08065, lr:3.66e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.384, tt:5474.980\n",
      "Ep:164, loss:0.00000, loss_test:0.08117, lr:3.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.408, tt:5512.252\n",
      "Ep:165, loss:0.00000, loss_test:0.08083, lr:3.59e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.428, tt:5549.121\n",
      "Ep:166, loss:0.00000, loss_test:0.08126, lr:3.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.451, tt:5586.286\n",
      "Ep:167, loss:0.00000, loss_test:0.08063, lr:3.52e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.467, tt:5622.442\n",
      "Ep:168, loss:0.00000, loss_test:0.08053, lr:3.48e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.486, tt:5659.071\n",
      "Ep:169, loss:0.00000, loss_test:0.08173, lr:3.45e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.510, tt:5696.773\n",
      "Ep:170, loss:0.00000, loss_test:0.08161, lr:3.41e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.534, tt:5734.260\n",
      "Ep:171, loss:0.00000, loss_test:0.08098, lr:3.38e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.558, tt:5772.051\n",
      "Ep:172, loss:0.00000, loss_test:0.08069, lr:3.34e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.568, tt:5807.320\n",
      "Ep:173, loss:0.00000, loss_test:0.08002, lr:3.31e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.589, tt:5844.517\n",
      "Ep:174, loss:0.00000, loss_test:0.07934, lr:3.28e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.592, tt:5878.642\n",
      "Ep:175, loss:0.00000, loss_test:0.08050, lr:3.24e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.609, tt:5915.182\n",
      "Ep:176, loss:0.00000, loss_test:0.08182, lr:3.21e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.623, tt:5951.274\n",
      "Ep:177, loss:0.00000, loss_test:0.08177, lr:3.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.644, tt:5988.638\n",
      "Ep:178, loss:0.00000, loss_test:0.08067, lr:3.15e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.665, tt:6026.114\n",
      "Ep:179, loss:0.00000, loss_test:0.08111, lr:3.12e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.684, tt:6063.111\n",
      "Ep:180, loss:0.00000, loss_test:0.08235, lr:3.09e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.702, tt:6100.079\n",
      "Ep:181, loss:0.00000, loss_test:0.08135, lr:3.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.716, tt:6136.234\n",
      "Ep:182, loss:0.00000, loss_test:0.08169, lr:3.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.728, tt:6172.268\n",
      "Ep:183, loss:0.00000, loss_test:0.08064, lr:2.99e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.740, tt:6208.245\n",
      "Ep:184, loss:0.00000, loss_test:0.08059, lr:2.96e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.751, tt:6243.936\n",
      "Ep:185, loss:0.00000, loss_test:0.08047, lr:2.93e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.765, tt:6280.293\n",
      "Ep:186, loss:0.00000, loss_test:0.08031, lr:2.90e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.782, tt:6317.233\n",
      "Ep:187, loss:0.00000, loss_test:0.07982, lr:2.88e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.789, tt:6352.386\n",
      "Ep:188, loss:0.00000, loss_test:0.08101, lr:2.85e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.810, tt:6390.151\n",
      "Ep:189, loss:0.00000, loss_test:0.07998, lr:2.82e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.830, tt:6427.640\n",
      "Ep:190, loss:0.00000, loss_test:0.08134, lr:2.79e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.843, tt:6463.979\n",
      "Ep:191, loss:0.00000, loss_test:0.08218, lr:2.76e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.854, tt:6499.992\n",
      "Ep:192, loss:0.00000, loss_test:0.07934, lr:2.73e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.864, tt:6535.757\n",
      "Ep:193, loss:0.00000, loss_test:0.08110, lr:2.71e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.888, tt:6574.253\n",
      "Ep:194, loss:0.00000, loss_test:0.08126, lr:2.68e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.898, tt:6610.153\n",
      "Ep:195, loss:0.00000, loss_test:0.07967, lr:2.65e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.908, tt:6646.034\n",
      "Ep:196, loss:0.00000, loss_test:0.08175, lr:2.63e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.920, tt:6682.227\n",
      "Ep:197, loss:0.00000, loss_test:0.08202, lr:2.60e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.940, tt:6720.191\n",
      "Ep:198, loss:0.00000, loss_test:0.07938, lr:2.57e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.961, tt:6758.239\n",
      "Ep:199, loss:0.00000, loss_test:0.08096, lr:2.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.973, tt:6794.580\n",
      "Ep:200, loss:0.00000, loss_test:0.08135, lr:2.52e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.991, tt:6832.195\n",
      "Ep:201, loss:0.00000, loss_test:0.08007, lr:2.50e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.006, tt:6869.141\n",
      "Ep:202, loss:0.00000, loss_test:0.08181, lr:2.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.022, tt:6906.497\n",
      "Ep:203, loss:0.00000, loss_test:0.08159, lr:2.45e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.031, tt:6942.301\n",
      "Ep:204, loss:0.00000, loss_test:0.07993, lr:2.42e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.041, tt:6978.398\n",
      "Ep:205, loss:0.00000, loss_test:0.08063, lr:2.40e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.050, tt:7014.382\n",
      "Ep:206, loss:0.00000, loss_test:0.08090, lr:2.38e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.045, tt:7047.330\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02778, lr:6.00e-02, fs:0.61818 (r=0.687,p=0.562),  time:27.308, tt:27.308\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02513, lr:6.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:26.857, tt:53.714\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00005, loss_test:0.02708, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:27.857, tt:83.572\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02709, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:29.091, tt:116.364\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02721, lr:6.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:30.531, tt:152.655\n",
      "Ep:5, loss:0.00005, loss_test:0.02713, lr:6.00e-02, fs:0.64945 (r=0.889,p=0.512),  time:31.411, tt:188.465\n",
      "Ep:6, loss:0.00005, loss_test:0.02660, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:31.938, tt:223.563\n",
      "Ep:7, loss:0.00005, loss_test:0.02587, lr:6.00e-02, fs:0.64419 (r=0.869,p=0.512),  time:32.334, tt:258.671\n",
      "Ep:8, loss:0.00005, loss_test:0.02499, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:32.724, tt:294.516\n",
      "Ep:9, loss:0.00005, loss_test:0.02417, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:32.989, tt:329.894\n",
      "Ep:10, loss:0.00004, loss_test:0.02347, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:33.246, tt:365.709\n",
      "Ep:11, loss:0.00004, loss_test:0.02280, lr:6.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:33.404, tt:400.852\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.68657 (r=0.929,p=0.544),  time:33.449, tt:434.831\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02201, lr:6.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:33.487, tt:468.817\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02172, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:33.573, tt:503.601\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02154, lr:6.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:33.666, tt:538.661\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02140, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:33.784, tt:574.329\n",
      "Ep:17, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:33.891, tt:610.042\n",
      "Ep:18, loss:0.00004, loss_test:0.02053, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:34.113, tt:648.148\n",
      "Ep:19, loss:0.00004, loss_test:0.02009, lr:6.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:34.098, tt:681.964\n",
      "Ep:20, loss:0.00004, loss_test:0.01972, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:34.135, tt:716.832\n",
      "Ep:21, loss:0.00004, loss_test:0.01935, lr:6.00e-02, fs:0.70992 (r=0.939,p=0.571),  time:34.182, tt:751.996\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01882, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.199, tt:786.574\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01826, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:34.273, tt:822.550\n",
      "Ep:24, loss:0.00003, loss_test:0.01777, lr:6.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:34.304, tt:857.599\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:34.352, tt:893.164\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:34.395, tt:928.672\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:34.450, tt:964.605\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:34.490, tt:1000.222\n",
      "Ep:29, loss:0.00003, loss_test:0.01589, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:34.515, tt:1035.461\n",
      "Ep:30, loss:0.00003, loss_test:0.01570, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:34.538, tt:1070.692\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:34.551, tt:1105.641\n",
      "Ep:32, loss:0.00003, loss_test:0.01535, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:34.598, tt:1141.726\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:34.655, tt:1178.264\n",
      "Ep:34, loss:0.00003, loss_test:0.01495, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:34.696, tt:1214.366\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:34.744, tt:1250.770\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.77366 (r=0.949,p=0.653),  time:34.753, tt:1285.874\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.754, tt:1320.642\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:34.820, tt:1357.978\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:34.839, tt:1393.556\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:34.836, tt:1428.292\n",
      "Ep:41, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:34.851, tt:1463.738\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01298, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.840, tt:1498.110\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01267, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:34.872, tt:1534.353\n",
      "Ep:44, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:34.895, tt:1570.265\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01229, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:34.943, tt:1607.391\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01198, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:34.949, tt:1642.614\n",
      "Ep:47, loss:0.00002, loss_test:0.01191, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:34.930, tt:1676.625\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01174, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:34.937, tt:1711.922\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01135, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:34.931, tt:1746.554\n",
      "Ep:50, loss:0.00002, loss_test:0.01131, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:34.946, tt:1782.246\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01221, lr:6.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:34.943, tt:1817.017\n",
      "Ep:52, loss:0.00002, loss_test:0.01100, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:34.953, tt:1852.505\n",
      "Ep:53, loss:0.00002, loss_test:0.01098, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.963, tt:1888.023\n",
      "Ep:54, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:34.976, tt:1923.686\n",
      "Ep:55, loss:0.00002, loss_test:0.01089, lr:6.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:34.981, tt:1958.954\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01172, lr:6.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:34.989, tt:1994.384\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01103, lr:6.00e-02, fs:0.85841 (r=0.980,p=0.764),  time:35.058, tt:2033.389\n",
      "Ep:58, loss:0.00001, loss_test:0.01113, lr:6.00e-02, fs:0.87783 (r=0.980,p=0.795),  time:35.052, tt:2068.057\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01053, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:35.044, tt:2102.667\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01050, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:35.041, tt:2137.525\n",
      "Ep:61, loss:0.00001, loss_test:0.01073, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:35.041, tt:2172.540\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01026, lr:6.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:35.014, tt:2205.875\n",
      "Ep:63, loss:0.00001, loss_test:0.01166, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:35.010, tt:2240.640\n",
      "Ep:64, loss:0.00001, loss_test:0.00999, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:35.017, tt:2276.077\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.01081, lr:6.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:35.020, tt:2311.339\n",
      "Ep:66, loss:0.00001, loss_test:0.01085, lr:6.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:35.011, tt:2345.708\n",
      "Ep:67, loss:0.00001, loss_test:0.01128, lr:6.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:35.007, tt:2380.465\n",
      "Ep:68, loss:0.00001, loss_test:0.01014, lr:6.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:35.018, tt:2416.270\n",
      "Ep:69, loss:0.00001, loss_test:0.01117, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:35.002, tt:2450.138\n",
      "Ep:70, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:34.998, tt:2484.832\n",
      "Ep:71, loss:0.00001, loss_test:0.01007, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:35.012, tt:2520.889\n",
      "Ep:72, loss:0.00001, loss_test:0.01345, lr:6.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.012, tt:2555.877\n",
      "Ep:73, loss:0.00001, loss_test:0.01021, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:35.015, tt:2591.110\n",
      "Ep:74, loss:0.00001, loss_test:0.01287, lr:6.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.025, tt:2626.886\n",
      "Ep:75, loss:0.00001, loss_test:0.00920, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:35.010, tt:2660.789\n",
      "Ep:76, loss:0.00001, loss_test:0.01358, lr:5.94e-02, fs:0.80829 (r=0.788,p=0.830),  time:35.018, tt:2696.424\n",
      "Ep:77, loss:0.00001, loss_test:0.01030, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:35.042, tt:2733.299\n",
      "Ep:78, loss:0.00001, loss_test:0.01218, lr:5.82e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.045, tt:2768.544\n",
      "Ep:79, loss:0.00001, loss_test:0.01132, lr:5.76e-02, fs:0.86869 (r=0.869,p=0.869),  time:35.043, tt:2803.450\n",
      "Ep:80, loss:0.00001, loss_test:0.01307, lr:5.71e-02, fs:0.82292 (r=0.798,p=0.849),  time:35.061, tt:2839.939\n",
      "Ep:81, loss:0.00001, loss_test:0.01104, lr:5.65e-02, fs:0.86294 (r=0.859,p=0.867),  time:35.059, tt:2874.814\n",
      "Ep:82, loss:0.00001, loss_test:0.01263, lr:5.59e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.040, tt:2908.307\n",
      "Ep:83, loss:0.00001, loss_test:0.01198, lr:5.54e-02, fs:0.85417 (r=0.828,p=0.882),  time:35.040, tt:2943.323\n",
      "Ep:84, loss:0.00001, loss_test:0.01183, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:35.029, tt:2977.455\n",
      "Ep:85, loss:0.00001, loss_test:0.01455, lr:5.43e-02, fs:0.80645 (r=0.758,p=0.862),  time:35.004, tt:3010.353\n",
      "Ep:86, loss:0.00001, loss_test:0.01135, lr:5.37e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.998, tt:3044.857\n",
      "Ep:87, loss:0.00001, loss_test:0.01346, lr:5.32e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.027, tt:3082.397\n",
      "Ep:88, loss:0.00001, loss_test:0.01338, lr:5.27e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.023, tt:3117.030\n",
      "Ep:89, loss:0.00001, loss_test:0.01324, lr:5.21e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.026, tt:3152.325\n",
      "Ep:90, loss:0.00001, loss_test:0.01358, lr:5.16e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.039, tt:3188.559\n",
      "Ep:91, loss:0.00001, loss_test:0.01162, lr:5.11e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.053, tt:3224.913\n",
      "Ep:92, loss:0.00001, loss_test:0.01370, lr:5.06e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.050, tt:3259.646\n",
      "Ep:93, loss:0.00001, loss_test:0.01419, lr:5.01e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.069, tt:3296.499\n",
      "Ep:94, loss:0.00001, loss_test:0.01306, lr:4.96e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.059, tt:3330.578\n",
      "Ep:95, loss:0.00001, loss_test:0.01188, lr:4.91e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.050, tt:3364.786\n",
      "Ep:96, loss:0.00001, loss_test:0.01472, lr:4.86e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.053, tt:3400.158\n",
      "Ep:97, loss:0.00000, loss_test:0.01288, lr:4.81e-02, fs:0.85561 (r=0.808,p=0.909),  time:35.048, tt:3434.678\n",
      "Ep:98, loss:0.00000, loss_test:0.01349, lr:4.76e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.048, tt:3469.787\n",
      "Ep:99, loss:0.00000, loss_test:0.01547, lr:4.71e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.029, tt:3502.887\n",
      "Ep:100, loss:0.00000, loss_test:0.01288, lr:4.67e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.010, tt:3535.963\n",
      "Ep:101, loss:0.00000, loss_test:0.01575, lr:4.62e-02, fs:0.85405 (r=0.798,p=0.919),  time:35.009, tt:3570.943\n",
      "Ep:102, loss:0.00000, loss_test:0.01430, lr:4.57e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.001, tt:3605.059\n",
      "Ep:103, loss:0.00000, loss_test:0.01459, lr:4.53e-02, fs:0.86022 (r=0.808,p=0.920),  time:35.007, tt:3640.714\n",
      "Ep:104, loss:0.00000, loss_test:0.01529, lr:4.48e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.993, tt:3674.298\n",
      "Ep:105, loss:0.00000, loss_test:0.01450, lr:4.44e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.977, tt:3707.557\n",
      "Ep:106, loss:0.00000, loss_test:0.01646, lr:4.39e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.966, tt:3741.327\n",
      "Ep:107, loss:0.00000, loss_test:0.01420, lr:4.35e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.951, tt:3774.733\n",
      "Ep:108, loss:0.00000, loss_test:0.01514, lr:4.31e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.958, tt:3810.437\n",
      "Ep:109, loss:0.00000, loss_test:0.01647, lr:4.26e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.967, tt:3846.424\n",
      "Ep:110, loss:0.00000, loss_test:0.01552, lr:4.22e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.968, tt:3881.438\n",
      "Ep:111, loss:0.00000, loss_test:0.01629, lr:4.18e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.966, tt:3916.189\n",
      "Ep:112, loss:0.00000, loss_test:0.01633, lr:4.14e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.979, tt:3952.674\n",
      "Ep:113, loss:0.00000, loss_test:0.01557, lr:4.10e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.973, tt:3986.946\n",
      "Ep:114, loss:0.00000, loss_test:0.01679, lr:4.05e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.973, tt:4021.942\n",
      "Ep:115, loss:0.00000, loss_test:0.01644, lr:4.01e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.969, tt:4056.451\n",
      "Ep:116, loss:0.00000, loss_test:0.01746, lr:3.97e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.970, tt:4091.544\n",
      "Ep:117, loss:0.00000, loss_test:0.01684, lr:3.93e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.962, tt:4125.460\n",
      "Ep:118, loss:0.00000, loss_test:0.01700, lr:3.89e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.950, tt:4158.993\n",
      "Ep:119, loss:0.00000, loss_test:0.01710, lr:3.86e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.948, tt:4193.768\n",
      "Ep:120, loss:0.00000, loss_test:0.01723, lr:3.82e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.943, tt:4228.147\n",
      "Ep:121, loss:0.00000, loss_test:0.01716, lr:3.78e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.962, tt:4265.363\n",
      "Ep:122, loss:0.00000, loss_test:0.01742, lr:3.74e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.947, tt:4298.454\n",
      "Ep:123, loss:0.00000, loss_test:0.01816, lr:3.70e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.942, tt:4332.857\n",
      "Ep:124, loss:0.00000, loss_test:0.01676, lr:3.67e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.929, tt:4366.163\n",
      "Ep:125, loss:0.00000, loss_test:0.01798, lr:3.63e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.926, tt:4400.618\n",
      "Ep:126, loss:0.00000, loss_test:0.01794, lr:3.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.924, tt:4435.328\n",
      "Ep:127, loss:0.00000, loss_test:0.01704, lr:3.56e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.921, tt:4469.908\n",
      "Ep:128, loss:0.00000, loss_test:0.01828, lr:3.52e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.914, tt:4503.920\n",
      "Ep:129, loss:0.00000, loss_test:0.01782, lr:3.49e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.918, tt:4539.368\n",
      "Ep:130, loss:0.00000, loss_test:0.01823, lr:3.45e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.923, tt:4574.971\n",
      "Ep:131, loss:0.00000, loss_test:0.01859, lr:3.42e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.917, tt:4609.009\n",
      "Ep:132, loss:0.00000, loss_test:0.01792, lr:3.38e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.918, tt:4644.077\n",
      "Ep:133, loss:0.00000, loss_test:0.01848, lr:3.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.912, tt:4678.225\n",
      "Ep:134, loss:0.00000, loss_test:0.01845, lr:3.32e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.910, tt:4712.906\n",
      "Ep:135, loss:0.00000, loss_test:0.01845, lr:3.28e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.904, tt:4746.949\n",
      "Ep:136, loss:0.00000, loss_test:0.01828, lr:3.25e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.914, tt:4783.184\n",
      "Ep:137, loss:0.00000, loss_test:0.01888, lr:3.22e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.911, tt:4817.697\n",
      "Ep:138, loss:0.00000, loss_test:0.01850, lr:3.19e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.913, tt:4852.945\n",
      "Ep:139, loss:0.00000, loss_test:0.01891, lr:3.15e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.916, tt:4888.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.01892, lr:3.12e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.927, tt:4924.659\n",
      "Ep:141, loss:0.00000, loss_test:0.01852, lr:3.09e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.924, tt:4959.234\n",
      "Ep:142, loss:0.00000, loss_test:0.01938, lr:3.06e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.929, tt:4994.846\n",
      "Ep:143, loss:0.00000, loss_test:0.01909, lr:3.03e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.919, tt:5028.317\n",
      "Ep:144, loss:0.00000, loss_test:0.01871, lr:3.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.917, tt:5062.960\n",
      "Ep:145, loss:0.00000, loss_test:0.01956, lr:2.97e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.919, tt:5098.166\n",
      "Ep:146, loss:0.00000, loss_test:0.01876, lr:2.94e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.925, tt:5133.933\n",
      "Ep:147, loss:0.00000, loss_test:0.01952, lr:2.91e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.925, tt:5168.830\n",
      "Ep:148, loss:0.00000, loss_test:0.01916, lr:2.88e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.920, tt:5203.074\n",
      "Ep:149, loss:0.00000, loss_test:0.01939, lr:2.85e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.913, tt:5236.967\n",
      "Ep:150, loss:0.00000, loss_test:0.01972, lr:2.82e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.913, tt:5271.856\n",
      "Ep:151, loss:0.00000, loss_test:0.01930, lr:2.80e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.922, tt:5308.168\n",
      "Ep:152, loss:0.00000, loss_test:0.01959, lr:2.77e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.919, tt:5342.556\n",
      "Ep:153, loss:0.00000, loss_test:0.01976, lr:2.74e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.926, tt:5378.558\n",
      "Ep:154, loss:0.00000, loss_test:0.01943, lr:2.71e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.927, tt:5413.672\n",
      "Ep:155, loss:0.00000, loss_test:0.01980, lr:2.69e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.929, tt:5448.931\n",
      "Ep:156, loss:0.00000, loss_test:0.01989, lr:2.66e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.938, tt:5485.297\n",
      "Ep:157, loss:0.00000, loss_test:0.01991, lr:2.63e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.935, tt:5519.806\n",
      "Ep:158, loss:0.00000, loss_test:0.01988, lr:2.61e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.946, tt:5556.490\n",
      "Ep:159, loss:0.00000, loss_test:0.02008, lr:2.58e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.945, tt:5591.235\n",
      "Ep:160, loss:0.00000, loss_test:0.01985, lr:2.55e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.956, tt:5627.924\n",
      "Ep:161, loss:0.00000, loss_test:0.02007, lr:2.53e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.969, tt:5664.909\n",
      "Ep:162, loss:0.00000, loss_test:0.02003, lr:2.50e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.975, tt:5700.970\n",
      "Ep:163, loss:0.00000, loss_test:0.02017, lr:2.48e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.981, tt:5736.926\n",
      "Ep:164, loss:0.00000, loss_test:0.01998, lr:2.45e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.983, tt:5772.144\n",
      "Ep:165, loss:0.00000, loss_test:0.02021, lr:2.43e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.982, tt:5807.036\n",
      "Ep:166, loss:0.00000, loss_test:0.02024, lr:2.40e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.979, tt:5841.437\n",
      "Ep:167, loss:0.00000, loss_test:0.02034, lr:2.38e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.980, tt:5876.662\n",
      "Ep:168, loss:0.00000, loss_test:0.02043, lr:2.36e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.984, tt:5912.216\n",
      "Ep:169, loss:0.00000, loss_test:0.02036, lr:2.33e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.988, tt:5947.939\n",
      "Ep:170, loss:0.00000, loss_test:0.02041, lr:2.31e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.985, tt:5982.491\n",
      "Ep:171, loss:0.00000, loss_test:0.02050, lr:2.29e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.989, tt:6018.031\n",
      "Ep:172, loss:0.00000, loss_test:0.02035, lr:2.26e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.986, tt:6052.587\n",
      "Ep:173, loss:0.00000, loss_test:0.02066, lr:2.24e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.990, tt:6088.184\n",
      "Ep:174, loss:0.00000, loss_test:0.02045, lr:2.22e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.998, tt:6124.644\n",
      "Ep:175, loss:0.00000, loss_test:0.02071, lr:2.20e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.997, tt:6159.391\n",
      "Ep:176, loss:0.00000, loss_test:0.02052, lr:2.17e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.998, tt:6194.679\n",
      "Ep:177, loss:0.00000, loss_test:0.02067, lr:2.15e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.000, tt:6230.015\n",
      "Ep:178, loss:0.00000, loss_test:0.02087, lr:2.13e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.002, tt:6265.397\n",
      "Ep:179, loss:0.00000, loss_test:0.02046, lr:2.11e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.005, tt:6300.824\n",
      "Ep:180, loss:0.00000, loss_test:0.02105, lr:2.09e-02, fs:0.84444 (r=0.768,p=0.938),  time:35.004, tt:6335.732\n",
      "Ep:181, loss:0.00000, loss_test:0.02045, lr:2.07e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.000, tt:6369.954\n",
      "Ep:182, loss:0.00000, loss_test:0.02103, lr:2.05e-02, fs:0.84444 (r=0.768,p=0.938),  time:35.001, tt:6405.125\n",
      "Ep:183, loss:0.00000, loss_test:0.02068, lr:2.03e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.006, tt:6441.069\n",
      "Ep:184, loss:0.00000, loss_test:0.02083, lr:2.01e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.016, tt:6477.881\n",
      "Ep:185, loss:0.00000, loss_test:0.02120, lr:1.99e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.016, tt:6512.981\n",
      "Ep:186, loss:0.00000, loss_test:0.02068, lr:1.97e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.020, tt:6548.789\n",
      "Ep:187, loss:0.00000, loss_test:0.02144, lr:1.95e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.020, tt:6583.781\n",
      "Ep:188, loss:0.00000, loss_test:0.02074, lr:1.93e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.025, tt:6619.734\n",
      "Ep:189, loss:0.00000, loss_test:0.02117, lr:1.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:35.033, tt:6656.247\n",
      "Ep:190, loss:0.00000, loss_test:0.02092, lr:1.89e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.033, tt:6691.282\n",
      "Ep:191, loss:0.00000, loss_test:0.02127, lr:1.87e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.039, tt:6727.522\n",
      "Ep:192, loss:0.00000, loss_test:0.02091, lr:1.85e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.041, tt:6762.877\n",
      "Ep:193, loss:0.00000, loss_test:0.02161, lr:1.83e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.046, tt:6798.962\n",
      "Ep:194, loss:0.00000, loss_test:0.02088, lr:1.81e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.046, tt:6833.902\n",
      "Ep:195, loss:0.00000, loss_test:0.02139, lr:1.80e-02, fs:0.84444 (r=0.768,p=0.938),  time:35.043, tt:6868.374\n",
      "Ep:196, loss:0.00000, loss_test:0.02115, lr:1.78e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.042, tt:6903.253\n",
      "Ep:197, loss:0.00000, loss_test:0.02126, lr:1.76e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.044, tt:6938.784\n",
      "Ep:198, loss:0.00000, loss_test:0.02095, lr:1.74e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.045, tt:6973.960\n",
      "Ep:199, loss:0.00000, loss_test:0.02152, lr:1.73e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.045, tt:7009.020\n",
      "Ep:200, loss:0.00000, loss_test:0.02108, lr:1.71e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.058, tt:7046.643\n",
      "Ep:201, loss:0.00000, loss_test:0.02141, lr:1.69e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.051, tt:7080.248\n",
      "Ep:202, loss:0.00000, loss_test:0.02133, lr:1.67e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.053, tt:7115.844\n",
      "Ep:203, loss:0.00000, loss_test:0.02151, lr:1.66e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.053, tt:7150.709\n",
      "Ep:204, loss:0.00000, loss_test:0.02133, lr:1.64e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.051, tt:7185.399\n",
      "Ep:205, loss:0.00000, loss_test:0.02145, lr:1.62e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.051, tt:7220.595\n",
      "Ep:206, loss:0.00000, loss_test:0.02146, lr:1.61e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.050, tt:7255.296\n",
      "Ep:207, loss:0.00000, loss_test:0.02161, lr:1.59e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.054, tt:7291.171\n",
      "Ep:208, loss:0.00000, loss_test:0.02147, lr:1.58e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.056, tt:7326.629\n",
      "Ep:209, loss:0.00000, loss_test:0.02153, lr:1.56e-02, fs:0.86957 (r=0.808,p=0.941),  time:35.057, tt:7361.973\n",
      "Ep:210, loss:0.00000, loss_test:0.02170, lr:1.54e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.041, tt:7393.688\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13105, lr:1.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:31.843, tt:31.843\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13013, lr:1.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:30.747, tt:61.493\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12937, lr:1.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:30.951, tt:92.854\n",
      "Ep:3, loss:0.00025, loss_test:0.12883, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:32.624, tt:130.496\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12868, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:33.668, tt:168.339\n",
      "Ep:5, loss:0.00025, loss_test:0.12835, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.198, tt:205.190\n",
      "Ep:6, loss:0.00025, loss_test:0.12717, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:34.546, tt:241.822\n",
      "Ep:7, loss:0.00025, loss_test:0.12596, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:34.966, tt:279.731\n",
      "Ep:8, loss:0.00025, loss_test:0.12536, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.379, tt:318.411\n",
      "Ep:9, loss:0.00024, loss_test:0.12513, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.389, tt:353.887\n",
      "Ep:10, loss:0.00024, loss_test:0.12499, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.570, tt:391.273\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.12382, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:35.610, tt:427.325\n",
      "Ep:12, loss:0.00024, loss_test:0.12314, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.559, tt:462.267\n",
      "Ep:13, loss:0.00024, loss_test:0.12184, lr:1.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:35.587, tt:498.212\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.12076, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:35.633, tt:534.493\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.11939, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:35.576, tt:569.209\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.11887, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:35.551, tt:604.375\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.11702, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:35.611, tt:641.006\n",
      "Ep:18, loss:0.00022, loss_test:0.11535, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:35.590, tt:676.209\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.11448, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:35.680, tt:713.600\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.11306, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:35.670, tt:749.073\n",
      "Ep:21, loss:0.00021, loss_test:0.11204, lr:1.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:35.696, tt:785.313\n",
      "Ep:22, loss:0.00020, loss_test:0.10984, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:35.605, tt:818.926\n",
      "Ep:23, loss:0.00019, loss_test:0.10890, lr:1.00e-02, fs:0.68421 (r=0.788,p=0.605),  time:35.580, tt:853.910\n",
      "Ep:24, loss:0.00019, loss_test:0.10518, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:35.583, tt:889.585\n",
      "Ep:25, loss:0.00018, loss_test:0.10360, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:35.609, tt:925.830\n",
      "Ep:26, loss:0.00018, loss_test:0.10121, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:35.642, tt:962.331\n",
      "Ep:27, loss:0.00017, loss_test:0.09886, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:35.706, tt:999.769\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.09877, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:35.689, tt:1034.981\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.09488, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:35.732, tt:1071.953\n",
      "Ep:30, loss:0.00015, loss_test:0.09332, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:35.768, tt:1108.799\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09166, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:35.803, tt:1145.711\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.09045, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:35.831, tt:1182.418\n",
      "Ep:33, loss:0.00013, loss_test:0.08962, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:35.826, tt:1218.091\n",
      "Ep:34, loss:0.00013, loss_test:0.08797, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:35.804, tt:1253.130\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08733, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:35.853, tt:1290.726\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.08572, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:35.879, tt:1327.514\n",
      "Ep:37, loss:0.00011, loss_test:0.08478, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:35.886, tt:1363.671\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.08308, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:35.910, tt:1400.482\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08090, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:35.929, tt:1437.155\n",
      "Ep:40, loss:0.00010, loss_test:0.08349, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:35.947, tt:1473.807\n",
      "Ep:41, loss:0.00010, loss_test:0.08341, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:35.956, tt:1510.135\n",
      "Ep:42, loss:0.00009, loss_test:0.08327, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:35.954, tt:1546.003\n",
      "Ep:43, loss:0.00009, loss_test:0.08597, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:35.961, tt:1582.284\n",
      "Ep:44, loss:0.00009, loss_test:0.07806, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:35.945, tt:1617.535\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.08373, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:35.959, tt:1654.123\n",
      "Ep:46, loss:0.00008, loss_test:0.08281, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:35.971, tt:1690.622\n",
      "Ep:47, loss:0.00009, loss_test:0.09239, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:35.963, tt:1726.221\n",
      "Ep:48, loss:0.00009, loss_test:0.07302, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:35.953, tt:1761.709\n",
      "Ep:49, loss:0.00008, loss_test:0.07968, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:35.937, tt:1796.867\n",
      "Ep:50, loss:0.00007, loss_test:0.07404, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.955, tt:1833.705\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.07887, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:35.953, tt:1869.572\n",
      "Ep:52, loss:0.00007, loss_test:0.08441, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:36.000, tt:1908.021\n",
      "Ep:53, loss:0.00007, loss_test:0.07656, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:36.028, tt:1945.506\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07647, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.055, tt:1983.019\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.08732, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:36.081, tt:2020.518\n",
      "Ep:56, loss:0.00006, loss_test:0.07271, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:36.069, tt:2055.950\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.07781, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.057, tt:2091.286\n",
      "Ep:58, loss:0.00005, loss_test:0.07409, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:36.036, tt:2126.105\n",
      "Ep:59, loss:0.00005, loss_test:0.08025, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:36.033, tt:2161.980\n",
      "Ep:60, loss:0.00005, loss_test:0.06953, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:36.042, tt:2198.547\n",
      "Ep:61, loss:0.00005, loss_test:0.07806, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.033, tt:2234.021\n",
      "Ep:62, loss:0.00005, loss_test:0.08290, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:36.031, tt:2269.952\n",
      "Ep:63, loss:0.00004, loss_test:0.06970, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.050, tt:2307.210\n",
      "Ep:64, loss:0.00004, loss_test:0.07629, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:36.041, tt:2342.675\n",
      "Ep:65, loss:0.00005, loss_test:0.07640, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:36.048, tt:2379.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00005, loss_test:0.07775, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:36.089, tt:2417.991\n",
      "Ep:67, loss:0.00005, loss_test:0.07561, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.100, tt:2454.769\n",
      "Ep:68, loss:0.00005, loss_test:0.08411, lr:9.90e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.084, tt:2489.821\n",
      "Ep:69, loss:0.00005, loss_test:0.07404, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:36.083, tt:2525.825\n",
      "Ep:70, loss:0.00004, loss_test:0.07641, lr:9.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.077, tt:2561.470\n",
      "Ep:71, loss:0.00004, loss_test:0.07571, lr:9.61e-03, fs:0.80663 (r=0.737,p=0.890),  time:36.096, tt:2598.902\n",
      "Ep:72, loss:0.00004, loss_test:0.07467, lr:9.51e-03, fs:0.81283 (r=0.768,p=0.864),  time:36.108, tt:2635.869\n",
      "Ep:73, loss:0.00004, loss_test:0.09000, lr:9.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:36.102, tt:2671.513\n",
      "Ep:74, loss:0.00004, loss_test:0.08167, lr:9.32e-03, fs:0.81768 (r=0.747,p=0.902),  time:36.088, tt:2706.571\n",
      "Ep:75, loss:0.00003, loss_test:0.08250, lr:9.23e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.092, tt:2743.002\n",
      "Ep:76, loss:0.00003, loss_test:0.08140, lr:9.14e-03, fs:0.82162 (r=0.768,p=0.884),  time:36.076, tt:2777.885\n",
      "Ep:77, loss:0.00003, loss_test:0.07700, lr:9.04e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.089, tt:2814.925\n",
      "Ep:78, loss:0.00003, loss_test:0.07479, lr:8.95e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.094, tt:2851.459\n",
      "Ep:79, loss:0.00003, loss_test:0.07941, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.081, tt:2886.520\n",
      "Ep:80, loss:0.00002, loss_test:0.07955, lr:8.78e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.089, tt:2923.180\n",
      "Ep:81, loss:0.00002, loss_test:0.08042, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.122, tt:2962.000\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.08140, lr:8.69e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.155, tt:3000.861\n",
      "Ep:83, loss:0.00002, loss_test:0.07381, lr:8.69e-03, fs:0.82222 (r=0.747,p=0.914),  time:36.176, tt:3038.753\n",
      "Ep:84, loss:0.00002, loss_test:0.08226, lr:8.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.175, tt:3074.898\n",
      "Ep:85, loss:0.00002, loss_test:0.08121, lr:8.69e-03, fs:0.82222 (r=0.747,p=0.914),  time:36.176, tt:3111.168\n",
      "Ep:86, loss:0.00002, loss_test:0.07908, lr:8.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.180, tt:3147.626\n",
      "Ep:87, loss:0.00002, loss_test:0.07954, lr:8.69e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.174, tt:3183.326\n",
      "Ep:88, loss:0.00002, loss_test:0.08127, lr:8.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.162, tt:3218.461\n",
      "Ep:89, loss:0.00002, loss_test:0.08334, lr:8.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.117, tt:3250.536\n",
      "Ep:90, loss:0.00002, loss_test:0.07538, lr:8.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.085, tt:3283.745\n",
      "Ep:91, loss:0.00001, loss_test:0.08169, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.088, tt:3320.053\n",
      "Ep:92, loss:0.00001, loss_test:0.08966, lr:8.69e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.094, tt:3356.761\n",
      "Ep:93, loss:0.00001, loss_test:0.08323, lr:8.60e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.093, tt:3392.705\n",
      "Ep:94, loss:0.00001, loss_test:0.08036, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.094, tt:3428.909\n",
      "Ep:95, loss:0.00001, loss_test:0.08312, lr:8.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.121, tt:3467.589\n",
      "Ep:96, loss:0.00001, loss_test:0.08808, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.133, tt:3504.893\n",
      "Ep:97, loss:0.00001, loss_test:0.08495, lr:8.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.134, tt:3541.169\n",
      "Ep:98, loss:0.00001, loss_test:0.08748, lr:8.18e-03, fs:0.83146 (r=0.747,p=0.937),  time:36.147, tt:3578.552\n",
      "Ep:99, loss:0.00001, loss_test:0.08208, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.166, tt:3616.620\n",
      "Ep:100, loss:0.00001, loss_test:0.08981, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.179, tt:3654.051\n",
      "Ep:101, loss:0.00001, loss_test:0.09270, lr:7.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.186, tt:3690.974\n",
      "Ep:102, loss:0.00001, loss_test:0.09462, lr:7.86e-03, fs:0.80000 (r=0.687,p=0.958),  time:36.198, tt:3728.443\n",
      "Ep:103, loss:0.00001, loss_test:0.08548, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.188, tt:3763.559\n",
      "Ep:104, loss:0.00001, loss_test:0.09650, lr:7.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.196, tt:3800.622\n",
      "Ep:105, loss:0.00001, loss_test:0.09517, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.187, tt:3835.855\n",
      "Ep:106, loss:0.00001, loss_test:0.09088, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.182, tt:3871.494\n",
      "Ep:107, loss:0.00001, loss_test:0.09453, lr:7.47e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.197, tt:3909.233\n",
      "Ep:108, loss:0.00001, loss_test:0.08815, lr:7.40e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.197, tt:3945.509\n",
      "Ep:109, loss:0.00001, loss_test:0.09481, lr:7.32e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.192, tt:3981.173\n",
      "Ep:110, loss:0.00001, loss_test:0.09408, lr:7.25e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.199, tt:4018.123\n",
      "Ep:111, loss:0.00001, loss_test:0.09065, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.190, tt:4053.332\n",
      "Ep:112, loss:0.00001, loss_test:0.10200, lr:7.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.182, tt:4088.615\n",
      "Ep:113, loss:0.00001, loss_test:0.08801, lr:7.03e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.178, tt:4124.281\n",
      "Ep:114, loss:0.00001, loss_test:0.09883, lr:6.96e-03, fs:0.79518 (r=0.667,p=0.985),  time:36.167, tt:4159.229\n",
      "Ep:115, loss:0.00001, loss_test:0.08652, lr:6.89e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.157, tt:4194.197\n",
      "Ep:116, loss:0.00001, loss_test:0.09774, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.143, tt:4228.720\n",
      "Ep:117, loss:0.00001, loss_test:0.09270, lr:6.76e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.155, tt:4266.283\n",
      "Ep:118, loss:0.00001, loss_test:0.09310, lr:6.69e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.141, tt:4300.835\n",
      "Ep:119, loss:0.00001, loss_test:0.09557, lr:6.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.144, tt:4337.299\n",
      "Ep:120, loss:0.00001, loss_test:0.09300, lr:6.56e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.143, tt:4373.287\n",
      "Ep:121, loss:0.00001, loss_test:0.09283, lr:6.49e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.136, tt:4408.601\n",
      "Ep:122, loss:0.00001, loss_test:0.09415, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.130, tt:4444.002\n",
      "Ep:123, loss:0.00001, loss_test:0.09622, lr:6.36e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.129, tt:4479.979\n",
      "Ep:124, loss:0.00001, loss_test:0.09453, lr:6.30e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.120, tt:4514.999\n",
      "Ep:125, loss:0.00001, loss_test:0.10210, lr:6.24e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.106, tt:4549.364\n",
      "Ep:126, loss:0.00001, loss_test:0.09788, lr:6.17e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.100, tt:4584.741\n",
      "Ep:127, loss:0.00001, loss_test:0.10418, lr:6.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.098, tt:4620.518\n",
      "Ep:128, loss:0.00001, loss_test:0.09320, lr:6.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.098, tt:4656.669\n",
      "Ep:129, loss:0.00001, loss_test:0.09744, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.091, tt:4691.805\n",
      "Ep:130, loss:0.00000, loss_test:0.09700, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.082, tt:4726.807\n",
      "Ep:131, loss:0.00000, loss_test:0.09958, lr:5.87e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.086, tt:4763.287\n",
      "Ep:132, loss:0.00000, loss_test:0.09610, lr:5.81e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.085, tt:4799.241\n",
      "Ep:133, loss:0.00000, loss_test:0.09836, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.085, tt:4835.378\n",
      "Ep:134, loss:0.00000, loss_test:0.09831, lr:5.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.090, tt:4872.193\n",
      "Ep:135, loss:0.00000, loss_test:0.09773, lr:5.64e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.093, tt:4908.685\n",
      "Ep:136, loss:0.00000, loss_test:0.09818, lr:5.58e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.100, tt:4945.637\n",
      "Ep:137, loss:0.00000, loss_test:0.09932, lr:5.53e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.128, tt:4985.641\n",
      "Ep:138, loss:0.00000, loss_test:0.09776, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.134, tt:5022.656\n",
      "Ep:139, loss:0.00000, loss_test:0.10020, lr:5.42e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.139, tt:5059.515\n",
      "Ep:140, loss:0.00000, loss_test:0.09827, lr:5.36e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.149, tt:5097.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.10182, lr:5.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.155, tt:5134.021\n",
      "Ep:142, loss:0.00000, loss_test:0.10301, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.155, tt:5170.117\n",
      "Ep:143, loss:0.00000, loss_test:0.10120, lr:5.20e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.162, tt:5207.265\n",
      "Ep:144, loss:0.00000, loss_test:0.10318, lr:5.15e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.158, tt:5242.917\n",
      "Ep:145, loss:0.00000, loss_test:0.10092, lr:5.10e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.168, tt:5280.505\n",
      "Ep:146, loss:0.00000, loss_test:0.10286, lr:5.05e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.172, tt:5317.249\n",
      "Ep:147, loss:0.00000, loss_test:0.09898, lr:5.00e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.176, tt:5354.044\n",
      "Ep:148, loss:0.00000, loss_test:0.10389, lr:4.95e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.180, tt:5390.862\n",
      "Ep:149, loss:0.00000, loss_test:0.09876, lr:4.90e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.179, tt:5426.886\n",
      "Ep:150, loss:0.00000, loss_test:0.10526, lr:4.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.187, tt:5464.167\n",
      "Ep:151, loss:0.00000, loss_test:0.10099, lr:4.80e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.179, tt:5499.227\n",
      "Ep:152, loss:0.00000, loss_test:0.10282, lr:4.75e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.188, tt:5536.795\n",
      "Ep:153, loss:0.00000, loss_test:0.10289, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.193, tt:5573.673\n",
      "Ep:154, loss:0.00000, loss_test:0.10750, lr:4.66e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.199, tt:5610.848\n",
      "Ep:155, loss:0.00000, loss_test:0.10033, lr:4.61e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.199, tt:5647.052\n",
      "Ep:156, loss:0.00000, loss_test:0.10455, lr:4.57e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.197, tt:5682.921\n",
      "Ep:157, loss:0.00000, loss_test:0.10225, lr:4.52e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.195, tt:5718.822\n",
      "Ep:158, loss:0.00000, loss_test:0.10298, lr:4.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.199, tt:5755.686\n",
      "Ep:159, loss:0.00000, loss_test:0.10190, lr:4.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.208, tt:5793.307\n",
      "Ep:160, loss:0.00000, loss_test:0.10237, lr:4.39e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.214, tt:5830.439\n",
      "Ep:161, loss:0.00000, loss_test:0.10435, lr:4.34e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.210, tt:5865.991\n",
      "Ep:162, loss:0.00000, loss_test:0.10048, lr:4.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.215, tt:5903.123\n",
      "Ep:163, loss:0.00000, loss_test:0.10960, lr:4.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.218, tt:5939.739\n",
      "Ep:164, loss:0.00000, loss_test:0.10341, lr:4.21e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.215, tt:5975.517\n",
      "Ep:165, loss:0.00000, loss_test:0.10618, lr:4.17e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.221, tt:6012.621\n",
      "Ep:166, loss:0.00000, loss_test:0.10465, lr:4.13e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.218, tt:6048.405\n",
      "Ep:167, loss:0.00000, loss_test:0.10316, lr:4.09e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.222, tt:6085.373\n",
      "Ep:168, loss:0.00000, loss_test:0.10459, lr:4.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.221, tt:6121.321\n",
      "Ep:169, loss:0.00000, loss_test:0.10480, lr:4.01e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.226, tt:6158.465\n",
      "Ep:170, loss:0.00000, loss_test:0.10379, lr:3.97e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.237, tt:6196.448\n",
      "Ep:171, loss:0.00000, loss_test:0.10680, lr:3.93e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.238, tt:6232.931\n",
      "Ep:172, loss:0.00000, loss_test:0.10291, lr:3.89e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.244, tt:6270.218\n",
      "Ep:173, loss:0.00000, loss_test:0.10479, lr:3.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.247, tt:6306.916\n",
      "Ep:174, loss:0.00000, loss_test:0.10513, lr:3.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.249, tt:6343.498\n",
      "Ep:175, loss:0.00000, loss_test:0.10211, lr:3.77e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.254, tt:6380.766\n",
      "Ep:176, loss:0.00000, loss_test:0.10480, lr:3.73e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.260, tt:6418.010\n",
      "Ep:177, loss:0.00000, loss_test:0.10644, lr:3.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.265, tt:6455.245\n",
      "Ep:178, loss:0.00000, loss_test:0.10422, lr:3.66e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.269, tt:6492.197\n",
      "Ep:179, loss:0.00000, loss_test:0.10293, lr:3.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.277, tt:6529.909\n",
      "Ep:180, loss:0.00000, loss_test:0.10443, lr:3.59e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.278, tt:6566.345\n",
      "Ep:181, loss:0.00000, loss_test:0.10293, lr:3.55e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.285, tt:6603.803\n",
      "Ep:182, loss:0.00000, loss_test:0.10775, lr:3.52e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.289, tt:6640.964\n",
      "Ep:183, loss:0.00000, loss_test:0.10378, lr:3.48e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.297, tt:6678.613\n",
      "Ep:184, loss:0.00000, loss_test:0.10676, lr:3.45e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.299, tt:6715.306\n",
      "Ep:185, loss:0.00000, loss_test:0.10618, lr:3.41e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.305, tt:6752.669\n",
      "Ep:186, loss:0.00000, loss_test:0.10554, lr:3.38e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.306, tt:6789.229\n",
      "Ep:187, loss:0.00000, loss_test:0.10713, lr:3.34e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.326, tt:6829.322\n",
      "Ep:188, loss:0.00000, loss_test:0.10283, lr:3.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.331, tt:6866.483\n",
      "Ep:189, loss:0.00000, loss_test:0.10752, lr:3.28e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.324, tt:6901.631\n",
      "Ep:190, loss:0.00000, loss_test:0.10308, lr:3.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.322, tt:6937.424\n",
      "Ep:191, loss:0.00000, loss_test:0.10431, lr:3.21e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.322, tt:6973.765\n",
      "Ep:192, loss:0.00000, loss_test:0.10384, lr:3.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.322, tt:7010.129\n",
      "Ep:193, loss:0.00000, loss_test:0.10297, lr:3.15e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.324, tt:7046.948\n",
      "Ep:194, loss:0.00000, loss_test:0.10475, lr:3.12e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.324, tt:7083.223\n",
      "Ep:195, loss:0.00000, loss_test:0.10582, lr:3.09e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.321, tt:7118.929\n",
      "Ep:196, loss:0.00000, loss_test:0.10428, lr:3.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.320, tt:7155.101\n",
      "Ep:197, loss:0.00000, loss_test:0.10345, lr:3.02e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.323, tt:7192.005\n",
      "Ep:198, loss:0.00000, loss_test:0.10299, lr:2.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.321, tt:7227.900\n",
      "Ep:199, loss:0.00000, loss_test:0.10312, lr:2.96e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.322, tt:7264.319\n",
      "Ep:200, loss:0.00000, loss_test:0.10429, lr:2.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.322, tt:7300.622\n",
      "Ep:201, loss:0.00000, loss_test:0.10374, lr:2.90e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.314, tt:7335.498\n",
      "Ep:202, loss:0.00000, loss_test:0.10307, lr:2.88e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.309, tt:7370.673\n",
      "Ep:203, loss:0.00000, loss_test:0.10374, lr:2.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.307, tt:7406.545\n",
      "Ep:204, loss:0.00000, loss_test:0.10270, lr:2.82e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.299, tt:7441.365\n",
      "Ep:205, loss:0.00000, loss_test:0.10227, lr:2.79e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.301, tt:7478.097\n",
      "Ep:206, loss:0.00000, loss_test:0.10347, lr:2.76e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.303, tt:7514.770\n",
      "Ep:207, loss:0.00000, loss_test:0.10393, lr:2.73e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.297, tt:7549.738\n",
      "Ep:208, loss:0.00000, loss_test:0.10316, lr:2.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.297, tt:7586.120\n",
      "Ep:209, loss:0.00000, loss_test:0.10291, lr:2.68e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.299, tt:7622.692\n",
      "Ep:210, loss:0.00000, loss_test:0.10294, lr:2.65e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.270, tt:7653.026\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02698, lr:6.00e-02, fs:0.63203 (r=0.737,p=0.553),  time:26.579, tt:26.579\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02500, lr:6.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:27.347, tt:54.693\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02652, lr:6.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:27.781, tt:83.342\n",
      "Ep:3, loss:0.00005, loss_test:0.02686, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:28.968, tt:115.870\n",
      "Ep:4, loss:0.00005, loss_test:0.02704, lr:6.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:29.905, tt:149.526\n",
      "Ep:5, loss:0.00005, loss_test:0.02716, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:30.750, tt:184.502\n",
      "Ep:6, loss:0.00005, loss_test:0.02699, lr:6.00e-02, fs:0.63670 (r=0.859,p=0.506),  time:31.209, tt:218.466\n",
      "Ep:7, loss:0.00005, loss_test:0.02645, lr:6.00e-02, fs:0.63670 (r=0.859,p=0.506),  time:31.661, tt:253.287\n",
      "Ep:8, loss:0.00005, loss_test:0.02577, lr:6.00e-02, fs:0.64419 (r=0.869,p=0.512),  time:31.988, tt:287.893\n",
      "Ep:9, loss:0.00005, loss_test:0.02511, lr:6.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:32.285, tt:322.848\n",
      "Ep:10, loss:0.00005, loss_test:0.02449, lr:6.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:32.574, tt:358.311\n",
      "Ep:11, loss:0.00004, loss_test:0.02373, lr:6.00e-02, fs:0.66909 (r=0.929,p=0.523),  time:32.880, tt:394.561\n",
      "Ep:12, loss:0.00004, loss_test:0.02303, lr:6.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:33.011, tt:429.142\n",
      "Ep:13, loss:0.00004, loss_test:0.02256, lr:5.94e-02, fs:0.68421 (r=0.919,p=0.545),  time:33.138, tt:463.934\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02211, lr:5.94e-02, fs:0.68679 (r=0.919,p=0.548),  time:33.285, tt:499.271\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02174, lr:5.94e-02, fs:0.68679 (r=0.919,p=0.548),  time:33.289, tt:532.616\n",
      "Ep:16, loss:0.00004, loss_test:0.02143, lr:5.94e-02, fs:0.68914 (r=0.929,p=0.548),  time:33.330, tt:566.618\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02113, lr:5.94e-02, fs:0.70149 (r=0.949,p=0.556),  time:33.383, tt:600.900\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.02095, lr:5.94e-02, fs:0.68914 (r=0.929,p=0.548),  time:33.369, tt:634.006\n",
      "Ep:19, loss:0.00004, loss_test:0.02085, lr:5.94e-02, fs:0.69173 (r=0.929,p=0.551),  time:33.392, tt:667.845\n",
      "Ep:20, loss:0.00004, loss_test:0.02062, lr:5.94e-02, fs:0.69732 (r=0.919,p=0.562),  time:33.409, tt:701.591\n",
      "Ep:21, loss:0.00004, loss_test:0.02025, lr:5.94e-02, fs:0.70455 (r=0.939,p=0.564),  time:33.413, tt:735.094\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01984, lr:5.94e-02, fs:0.69962 (r=0.929,p=0.561),  time:33.420, tt:768.650\n",
      "Ep:23, loss:0.00004, loss_test:0.01946, lr:5.94e-02, fs:0.69732 (r=0.919,p=0.562),  time:33.445, tt:802.686\n",
      "Ep:24, loss:0.00003, loss_test:0.01909, lr:5.94e-02, fs:0.69767 (r=0.909,p=0.566),  time:33.458, tt:836.451\n",
      "Ep:25, loss:0.00003, loss_test:0.01871, lr:5.94e-02, fs:0.70588 (r=0.909,p=0.577),  time:33.513, tt:871.334\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01837, lr:5.94e-02, fs:0.71373 (r=0.919,p=0.583),  time:33.585, tt:906.794\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01801, lr:5.94e-02, fs:0.72656 (r=0.939,p=0.592),  time:33.603, tt:940.881\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01754, lr:5.94e-02, fs:0.72941 (r=0.939,p=0.596),  time:33.641, tt:975.589\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01711, lr:5.94e-02, fs:0.74016 (r=0.949,p=0.606),  time:33.721, tt:1011.637\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01683, lr:5.94e-02, fs:0.74603 (r=0.949,p=0.614),  time:33.766, tt:1046.752\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01651, lr:5.94e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.804, tt:1081.736\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01613, lr:5.94e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.814, tt:1115.856\n",
      "Ep:33, loss:0.00003, loss_test:0.01587, lr:5.94e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.876, tt:1151.774\n",
      "Ep:34, loss:0.00003, loss_test:0.01554, lr:5.94e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.908, tt:1186.794\n",
      "Ep:35, loss:0.00003, loss_test:0.01530, lr:5.94e-02, fs:0.75000 (r=0.939,p=0.624),  time:33.953, tt:1222.304\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01485, lr:5.94e-02, fs:0.76113 (r=0.949,p=0.635),  time:33.999, tt:1257.972\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01470, lr:5.94e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.021, tt:1292.787\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01442, lr:5.94e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.106, tt:1330.131\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01417, lr:5.94e-02, fs:0.76543 (r=0.939,p=0.646),  time:34.142, tt:1365.687\n",
      "Ep:40, loss:0.00002, loss_test:0.01390, lr:5.94e-02, fs:0.77686 (r=0.949,p=0.657),  time:34.159, tt:1400.511\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01367, lr:5.94e-02, fs:0.78008 (r=0.949,p=0.662),  time:34.217, tt:1437.098\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01344, lr:5.94e-02, fs:0.78333 (r=0.949,p=0.667),  time:34.245, tt:1472.555\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01335, lr:5.94e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.271, tt:1507.927\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01327, lr:5.94e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.311, tt:1544.004\n",
      "Ep:45, loss:0.00002, loss_test:0.01324, lr:5.94e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.334, tt:1579.387\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01296, lr:5.94e-02, fs:0.83333 (r=0.960,p=0.736),  time:34.367, tt:1615.242\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01288, lr:5.94e-02, fs:0.81739 (r=0.949,p=0.718),  time:34.368, tt:1649.676\n",
      "Ep:48, loss:0.00002, loss_test:0.01278, lr:5.94e-02, fs:0.84071 (r=0.960,p=0.748),  time:34.390, tt:1685.113\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01381, lr:5.94e-02, fs:0.81651 (r=0.899,p=0.748),  time:34.395, tt:1719.763\n",
      "Ep:50, loss:0.00002, loss_test:0.01279, lr:5.94e-02, fs:0.84071 (r=0.960,p=0.748),  time:34.434, tt:1756.155\n",
      "Ep:51, loss:0.00002, loss_test:0.01253, lr:5.94e-02, fs:0.82667 (r=0.939,p=0.738),  time:34.438, tt:1790.765\n",
      "Ep:52, loss:0.00002, loss_test:0.01234, lr:5.94e-02, fs:0.84444 (r=0.960,p=0.754),  time:34.474, tt:1827.134\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01325, lr:5.94e-02, fs:0.82949 (r=0.909,p=0.763),  time:34.522, tt:1864.193\n",
      "Ep:54, loss:0.00001, loss_test:0.01348, lr:5.94e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.528, tt:1899.060\n",
      "Ep:55, loss:0.00001, loss_test:0.01317, lr:5.94e-02, fs:0.83258 (r=0.929,p=0.754),  time:34.547, tt:1934.609\n",
      "Ep:56, loss:0.00001, loss_test:0.01242, lr:5.94e-02, fs:0.84163 (r=0.939,p=0.762),  time:34.558, tt:1969.810\n",
      "Ep:57, loss:0.00002, loss_test:0.01649, lr:5.94e-02, fs:0.75000 (r=0.879,p=0.654),  time:34.570, tt:2005.032\n",
      "Ep:58, loss:0.00003, loss_test:0.01811, lr:5.94e-02, fs:0.74107 (r=0.838,p=0.664),  time:34.611, tt:2042.070\n",
      "Ep:59, loss:0.00003, loss_test:0.01300, lr:5.94e-02, fs:0.77824 (r=0.939,p=0.664),  time:34.636, tt:2078.178\n",
      "Ep:60, loss:0.00002, loss_test:0.01422, lr:5.94e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.652, tt:2113.762\n",
      "Ep:61, loss:0.00002, loss_test:0.01265, lr:5.94e-02, fs:0.79167 (r=0.960,p=0.674),  time:34.664, tt:2149.176\n",
      "Ep:62, loss:0.00002, loss_test:0.01280, lr:5.94e-02, fs:0.78838 (r=0.960,p=0.669),  time:34.686, tt:2185.225\n",
      "Ep:63, loss:0.00002, loss_test:0.01217, lr:5.94e-02, fs:0.80169 (r=0.960,p=0.688),  time:34.674, tt:2219.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00002, loss_test:0.01215, lr:5.88e-02, fs:0.83929 (r=0.949,p=0.752),  time:34.667, tt:2253.341\n",
      "Ep:65, loss:0.00002, loss_test:0.01230, lr:5.82e-02, fs:0.84545 (r=0.939,p=0.769),  time:34.653, tt:2287.127\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.01209, lr:5.82e-02, fs:0.84444 (r=0.960,p=0.754),  time:34.660, tt:2322.243\n",
      "Ep:67, loss:0.00001, loss_test:0.01277, lr:5.82e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.664, tt:2357.174\n",
      "Ep:68, loss:0.00001, loss_test:0.01261, lr:5.82e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.660, tt:2391.517\n",
      "Ep:69, loss:0.00001, loss_test:0.01483, lr:5.82e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.642, tt:2424.941\n",
      "Ep:70, loss:0.00001, loss_test:0.01240, lr:5.82e-02, fs:0.87037 (r=0.949,p=0.803),  time:34.639, tt:2459.346\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01561, lr:5.82e-02, fs:0.81592 (r=0.828,p=0.804),  time:34.610, tt:2491.896\n",
      "Ep:72, loss:0.00001, loss_test:0.01289, lr:5.82e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.589, tt:2525.010\n",
      "Ep:73, loss:0.00001, loss_test:0.01452, lr:5.82e-02, fs:0.83333 (r=0.859,p=0.810),  time:34.581, tt:2559.023\n",
      "Ep:74, loss:0.00001, loss_test:0.01506, lr:5.82e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.564, tt:2592.329\n",
      "Ep:75, loss:0.00001, loss_test:0.01455, lr:5.82e-02, fs:0.83744 (r=0.859,p=0.817),  time:34.542, tt:2625.159\n",
      "Ep:76, loss:0.00001, loss_test:0.01628, lr:5.82e-02, fs:0.83000 (r=0.838,p=0.822),  time:34.518, tt:2657.875\n",
      "Ep:77, loss:0.00001, loss_test:0.01575, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.493, tt:2690.467\n",
      "Ep:78, loss:0.00001, loss_test:0.01681, lr:5.82e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.475, tt:2723.500\n",
      "Ep:79, loss:0.00001, loss_test:0.01611, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.472, tt:2757.751\n",
      "Ep:80, loss:0.00001, loss_test:0.01452, lr:5.82e-02, fs:0.87805 (r=0.909,p=0.849),  time:34.464, tt:2791.619\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01394, lr:5.82e-02, fs:0.88571 (r=0.939,p=0.838),  time:34.458, tt:2825.590\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01859, lr:5.82e-02, fs:0.80829 (r=0.788,p=0.830),  time:34.483, tt:2862.069\n",
      "Ep:83, loss:0.00001, loss_test:0.02322, lr:5.82e-02, fs:0.74194 (r=0.697,p=0.793),  time:34.477, tt:2896.084\n",
      "Ep:84, loss:0.00001, loss_test:0.02180, lr:5.82e-02, fs:0.75676 (r=0.707,p=0.814),  time:34.468, tt:2929.812\n",
      "Ep:85, loss:0.00001, loss_test:0.01441, lr:5.82e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.446, tt:2962.391\n",
      "Ep:86, loss:0.00001, loss_test:0.01867, lr:5.82e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.426, tt:2995.080\n",
      "Ep:87, loss:0.00001, loss_test:0.02130, lr:5.82e-02, fs:0.76344 (r=0.717,p=0.816),  time:34.436, tt:3030.355\n",
      "Ep:88, loss:0.00001, loss_test:0.01596, lr:5.82e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.426, tt:3063.926\n",
      "Ep:89, loss:0.00001, loss_test:0.01758, lr:5.82e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.431, tt:3098.783\n",
      "Ep:90, loss:0.00001, loss_test:0.02134, lr:5.82e-02, fs:0.77174 (r=0.717,p=0.835),  time:34.433, tt:3133.367\n",
      "Ep:91, loss:0.00001, loss_test:0.02193, lr:5.82e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.424, tt:3166.966\n",
      "Ep:92, loss:0.00001, loss_test:0.01847, lr:5.82e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.412, tt:3200.330\n",
      "Ep:93, loss:0.00001, loss_test:0.01639, lr:5.76e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.409, tt:3234.487\n",
      "Ep:94, loss:0.00001, loss_test:0.01830, lr:5.71e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.407, tt:3268.646\n",
      "Ep:95, loss:0.00001, loss_test:0.02430, lr:5.65e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.406, tt:3302.964\n",
      "Ep:96, loss:0.00001, loss_test:0.01911, lr:5.59e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.402, tt:3336.949\n",
      "Ep:97, loss:0.00001, loss_test:0.01838, lr:5.54e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.423, tt:3373.418\n",
      "Ep:98, loss:0.00001, loss_test:0.02392, lr:5.48e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.429, tt:3408.497\n",
      "Ep:99, loss:0.00001, loss_test:0.02326, lr:5.43e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.454, tt:3445.428\n",
      "Ep:100, loss:0.00000, loss_test:0.02134, lr:5.37e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.471, tt:3481.561\n",
      "Ep:101, loss:0.00000, loss_test:0.02247, lr:5.32e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.476, tt:3516.561\n",
      "Ep:102, loss:0.00000, loss_test:0.02422, lr:5.27e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.485, tt:3551.987\n",
      "Ep:103, loss:0.00000, loss_test:0.02643, lr:5.21e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.506, tt:3588.616\n",
      "Ep:104, loss:0.00000, loss_test:0.02700, lr:5.16e-02, fs:0.75000 (r=0.667,p=0.857),  time:34.516, tt:3624.190\n",
      "Ep:105, loss:0.00000, loss_test:0.02350, lr:5.11e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.535, tt:3660.763\n",
      "Ep:106, loss:0.00000, loss_test:0.02148, lr:5.06e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.538, tt:3695.553\n",
      "Ep:107, loss:0.00000, loss_test:0.02354, lr:5.01e-02, fs:0.74286 (r=0.657,p=0.855),  time:34.561, tt:3732.580\n",
      "Ep:108, loss:0.00000, loss_test:0.02524, lr:4.96e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.580, tt:3769.241\n",
      "Ep:109, loss:0.00000, loss_test:0.02740, lr:4.91e-02, fs:0.73563 (r=0.646,p=0.853),  time:34.596, tt:3805.518\n",
      "Ep:110, loss:0.00000, loss_test:0.02680, lr:4.86e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.622, tt:3843.017\n",
      "Ep:111, loss:0.00000, loss_test:0.02375, lr:4.81e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.652, tt:3881.041\n",
      "Ep:112, loss:0.00000, loss_test:0.02482, lr:4.76e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.672, tt:3917.896\n",
      "Ep:113, loss:0.00000, loss_test:0.02798, lr:4.71e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.690, tt:3954.698\n",
      "Ep:114, loss:0.00000, loss_test:0.03138, lr:4.67e-02, fs:0.72515 (r=0.626,p=0.861),  time:34.726, tt:3993.492\n",
      "Ep:115, loss:0.00001, loss_test:0.03037, lr:4.62e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.743, tt:4030.208\n",
      "Ep:116, loss:0.00000, loss_test:0.02434, lr:4.57e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.761, tt:4067.070\n",
      "Ep:117, loss:0.00000, loss_test:0.02511, lr:4.53e-02, fs:0.73988 (r=0.646,p=0.865),  time:34.783, tt:4104.341\n",
      "Ep:118, loss:0.00000, loss_test:0.03077, lr:4.48e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.796, tt:4140.750\n",
      "Ep:119, loss:0.00000, loss_test:0.02648, lr:4.44e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.802, tt:4176.298\n",
      "Ep:120, loss:0.00000, loss_test:0.02481, lr:4.39e-02, fs:0.72941 (r=0.626,p=0.873),  time:34.818, tt:4213.026\n",
      "Ep:121, loss:0.00000, loss_test:0.02961, lr:4.35e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.856, tt:4252.427\n",
      "Ep:122, loss:0.00000, loss_test:0.02771, lr:4.31e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.881, tt:4290.342\n",
      "Ep:123, loss:0.00000, loss_test:0.02630, lr:4.26e-02, fs:0.72941 (r=0.626,p=0.873),  time:34.890, tt:4326.325\n",
      "Ep:124, loss:0.00000, loss_test:0.03167, lr:4.22e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.911, tt:4363.892\n",
      "Ep:125, loss:0.00000, loss_test:0.02947, lr:4.18e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.922, tt:4400.192\n",
      "Ep:126, loss:0.00000, loss_test:0.02631, lr:4.14e-02, fs:0.72941 (r=0.626,p=0.873),  time:34.916, tt:4434.332\n",
      "Ep:127, loss:0.00000, loss_test:0.03052, lr:4.10e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.912, tt:4468.722\n",
      "Ep:128, loss:0.00000, loss_test:0.03030, lr:4.05e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.895, tt:4501.429\n",
      "Ep:129, loss:0.00000, loss_test:0.02871, lr:4.01e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.879, tt:4534.243\n",
      "Ep:130, loss:0.00000, loss_test:0.03062, lr:3.97e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.856, tt:4566.127\n",
      "Ep:131, loss:0.00000, loss_test:0.03078, lr:3.93e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.848, tt:4599.970\n",
      "Ep:132, loss:0.00000, loss_test:0.03051, lr:3.89e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.845, tt:4634.445\n",
      "Ep:133, loss:0.00000, loss_test:0.03210, lr:3.86e-02, fs:0.72619 (r=0.616,p=0.884),  time:34.844, tt:4669.094\n",
      "Ep:134, loss:0.00000, loss_test:0.03017, lr:3.82e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.840, tt:4703.418\n",
      "Ep:135, loss:0.00000, loss_test:0.02953, lr:3.78e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.842, tt:4738.538\n",
      "Ep:136, loss:0.00000, loss_test:0.03350, lr:3.74e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.841, tt:4773.183\n",
      "Ep:137, loss:0.00000, loss_test:0.03113, lr:3.70e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.837, tt:4807.467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.02941, lr:3.67e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.839, tt:4842.655\n",
      "Ep:139, loss:0.00000, loss_test:0.03345, lr:3.63e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.835, tt:4876.835\n",
      "Ep:140, loss:0.00000, loss_test:0.03272, lr:3.59e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.841, tt:4912.643\n",
      "Ep:141, loss:0.00000, loss_test:0.03015, lr:3.56e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.829, tt:4945.705\n",
      "Ep:142, loss:0.00000, loss_test:0.03449, lr:3.52e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.823, tt:4979.753\n",
      "Ep:143, loss:0.00000, loss_test:0.03195, lr:3.49e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.820, tt:5014.014\n",
      "Ep:144, loss:0.00000, loss_test:0.03050, lr:3.45e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.816, tt:5048.295\n",
      "Ep:145, loss:0.00000, loss_test:0.03519, lr:3.42e-02, fs:0.71084 (r=0.596,p=0.881),  time:34.820, tt:5083.687\n",
      "Ep:146, loss:0.00000, loss_test:0.03087, lr:3.38e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.818, tt:5118.193\n",
      "Ep:147, loss:0.00000, loss_test:0.03261, lr:3.35e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.819, tt:5153.173\n",
      "Ep:148, loss:0.00000, loss_test:0.03474, lr:3.32e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.817, tt:5187.718\n",
      "Ep:149, loss:0.00000, loss_test:0.03097, lr:3.28e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.806, tt:5220.945\n",
      "Ep:150, loss:0.00000, loss_test:0.03361, lr:3.25e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.798, tt:5254.491\n",
      "Ep:151, loss:0.00000, loss_test:0.03385, lr:3.22e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.797, tt:5289.167\n",
      "Ep:152, loss:0.00000, loss_test:0.03153, lr:3.19e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.794, tt:5323.520\n",
      "Ep:153, loss:0.00000, loss_test:0.03455, lr:3.15e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.789, tt:5357.519\n",
      "Ep:154, loss:0.00000, loss_test:0.03290, lr:3.12e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.792, tt:5392.810\n",
      "Ep:155, loss:0.00000, loss_test:0.03374, lr:3.09e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.791, tt:5427.455\n",
      "Ep:156, loss:0.00000, loss_test:0.03402, lr:3.06e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.805, tt:5464.448\n",
      "Ep:157, loss:0.00000, loss_test:0.03336, lr:3.03e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.819, tt:5501.332\n",
      "Ep:158, loss:0.00000, loss_test:0.03475, lr:3.00e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.821, tt:5536.474\n",
      "Ep:159, loss:0.00000, loss_test:0.03398, lr:2.97e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.821, tt:5571.317\n",
      "Ep:160, loss:0.00000, loss_test:0.03437, lr:2.94e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.820, tt:5606.015\n",
      "Ep:161, loss:0.00000, loss_test:0.03528, lr:2.91e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.836, tt:5643.394\n",
      "Ep:162, loss:0.00000, loss_test:0.03376, lr:2.88e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.843, tt:5679.444\n",
      "Ep:163, loss:0.00000, loss_test:0.03524, lr:2.85e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.855, tt:5716.228\n",
      "Ep:164, loss:0.00000, loss_test:0.03404, lr:2.82e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.872, tt:5753.799\n",
      "Ep:165, loss:0.00000, loss_test:0.03483, lr:2.80e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.880, tt:5790.041\n",
      "Ep:166, loss:0.00000, loss_test:0.03575, lr:2.77e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.888, tt:5826.238\n",
      "Ep:167, loss:0.00000, loss_test:0.03390, lr:2.74e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.898, tt:5862.938\n",
      "Ep:168, loss:0.00000, loss_test:0.03663, lr:2.71e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.909, tt:5899.562\n",
      "Ep:169, loss:0.00000, loss_test:0.03382, lr:2.69e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.905, tt:5933.859\n",
      "Ep:170, loss:0.00000, loss_test:0.03615, lr:2.66e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.916, tt:5970.599\n",
      "Ep:171, loss:0.00000, loss_test:0.03562, lr:2.63e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.926, tt:6007.288\n",
      "Ep:172, loss:0.00000, loss_test:0.03470, lr:2.61e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.932, tt:6043.229\n",
      "Ep:173, loss:0.00000, loss_test:0.03636, lr:2.58e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.937, tt:6079.072\n",
      "Ep:174, loss:0.00000, loss_test:0.03452, lr:2.55e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.941, tt:6114.650\n",
      "Ep:175, loss:0.00000, loss_test:0.03620, lr:2.53e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.942, tt:6149.708\n",
      "Ep:176, loss:0.00000, loss_test:0.03511, lr:2.50e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.949, tt:6185.954\n",
      "Ep:177, loss:0.00000, loss_test:0.03639, lr:2.48e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.949, tt:6220.868\n",
      "Ep:178, loss:0.00000, loss_test:0.03536, lr:2.45e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.952, tt:6256.428\n",
      "Ep:179, loss:0.00000, loss_test:0.03634, lr:2.43e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.953, tt:6291.629\n",
      "Ep:180, loss:0.00000, loss_test:0.03557, lr:2.40e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.959, tt:6327.509\n",
      "Ep:181, loss:0.00000, loss_test:0.03651, lr:2.38e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.963, tt:6363.281\n",
      "Ep:182, loss:0.00000, loss_test:0.03609, lr:2.36e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.972, tt:6399.851\n",
      "Ep:183, loss:0.00000, loss_test:0.03644, lr:2.33e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.974, tt:6435.301\n",
      "Ep:184, loss:0.00000, loss_test:0.03619, lr:2.31e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.986, tt:6472.450\n",
      "Ep:185, loss:0.00000, loss_test:0.03685, lr:2.29e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.996, tt:6509.217\n",
      "Ep:186, loss:0.00000, loss_test:0.03651, lr:2.26e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.998, tt:6544.593\n",
      "Ep:187, loss:0.00000, loss_test:0.03649, lr:2.24e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.999, tt:6579.818\n",
      "Ep:188, loss:0.00000, loss_test:0.03715, lr:2.22e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.002, tt:6615.358\n",
      "Ep:189, loss:0.00000, loss_test:0.03614, lr:2.20e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.998, tt:6649.606\n",
      "Ep:190, loss:0.00000, loss_test:0.03741, lr:2.17e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.981, tt:6681.376\n",
      "Ep:191, loss:0.00000, loss_test:0.03631, lr:2.15e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.970, tt:6714.181\n",
      "Ep:192, loss:0.00000, loss_test:0.03730, lr:2.13e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.966, tt:6748.365\n",
      "Ep:193, loss:0.00000, loss_test:0.03677, lr:2.11e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.961, tt:6782.355\n",
      "Ep:194, loss:0.00000, loss_test:0.03727, lr:2.09e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.954, tt:6816.014\n",
      "Ep:195, loss:0.00000, loss_test:0.03695, lr:2.07e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.946, tt:6849.437\n",
      "Ep:196, loss:0.00000, loss_test:0.03721, lr:2.05e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.939, tt:6882.934\n",
      "Ep:197, loss:0.00000, loss_test:0.03725, lr:2.03e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.929, tt:6915.940\n",
      "Ep:198, loss:0.00000, loss_test:0.03750, lr:2.01e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.927, tt:6950.541\n",
      "Ep:199, loss:0.00000, loss_test:0.03726, lr:1.99e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.918, tt:6983.665\n",
      "Ep:200, loss:0.00000, loss_test:0.03751, lr:1.97e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.903, tt:7015.549\n",
      "Ep:201, loss:0.00000, loss_test:0.03740, lr:1.95e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.897, tt:7049.155\n",
      "Ep:202, loss:0.00000, loss_test:0.03786, lr:1.93e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.883, tt:7081.231\n",
      "Ep:203, loss:0.00000, loss_test:0.03744, lr:1.91e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.872, tt:7113.876\n",
      "Ep:204, loss:0.00000, loss_test:0.03782, lr:1.89e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.861, tt:7146.580\n",
      "Ep:205, loss:0.00000, loss_test:0.03764, lr:1.87e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.854, tt:7180.023\n",
      "Ep:206, loss:0.00000, loss_test:0.03783, lr:1.85e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.847, tt:7213.347\n",
      "Ep:207, loss:0.00000, loss_test:0.03769, lr:1.83e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.841, tt:7246.895\n",
      "Ep:208, loss:0.00000, loss_test:0.03812, lr:1.81e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.812, tt:7275.735\n",
      "Ep:209, loss:0.00000, loss_test:0.03782, lr:1.80e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.798, tt:7307.636\n",
      "Ep:210, loss:0.00000, loss_test:0.03794, lr:1.78e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.789, tt:7340.432\n",
      "Ep:211, loss:0.00000, loss_test:0.03818, lr:1.76e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.767, tt:7370.589\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13425, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:30.723, tt:30.723\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13426, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:31.112, tt:62.224\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13470, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:31.990, tt:95.970\n",
      "Ep:3, loss:0.00026, loss_test:0.13445, lr:1.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:32.535, tt:130.139\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.13350, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:32.806, tt:164.031\n",
      "Ep:5, loss:0.00025, loss_test:0.13148, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:33.336, tt:200.016\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.13015, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:33.716, tt:236.010\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12964, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:33.939, tt:271.511\n",
      "Ep:8, loss:0.00025, loss_test:0.12948, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:34.198, tt:307.785\n",
      "Ep:9, loss:0.00025, loss_test:0.13017, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:34.364, tt:343.637\n",
      "Ep:10, loss:0.00024, loss_test:0.12944, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:34.518, tt:379.698\n",
      "Ep:11, loss:0.00024, loss_test:0.12741, lr:1.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:34.668, tt:416.022\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.12593, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.852, tt:453.079\n",
      "Ep:13, loss:0.00024, loss_test:0.12535, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:35.075, tt:491.046\n",
      "Ep:14, loss:0.00023, loss_test:0.12538, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:34.992, tt:524.878\n",
      "Ep:15, loss:0.00023, loss_test:0.12342, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:35.098, tt:561.569\n",
      "Ep:16, loss:0.00023, loss_test:0.12149, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:35.107, tt:596.823\n",
      "Ep:17, loss:0.00022, loss_test:0.12118, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:35.159, tt:632.867\n",
      "Ep:18, loss:0.00022, loss_test:0.12017, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:35.193, tt:668.673\n",
      "Ep:19, loss:0.00022, loss_test:0.11711, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:35.225, tt:704.494\n",
      "Ep:20, loss:0.00021, loss_test:0.11688, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.264, tt:740.553\n",
      "Ep:21, loss:0.00021, loss_test:0.11648, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.304, tt:776.682\n",
      "Ep:22, loss:0.00020, loss_test:0.11399, lr:1.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:35.338, tt:812.783\n",
      "Ep:23, loss:0.00020, loss_test:0.11263, lr:9.90e-03, fs:0.67521 (r=0.798,p=0.585),  time:35.417, tt:850.001\n",
      "Ep:24, loss:0.00019, loss_test:0.11129, lr:9.80e-03, fs:0.67532 (r=0.788,p=0.591),  time:35.464, tt:886.608\n",
      "Ep:25, loss:0.00018, loss_test:0.10698, lr:9.70e-03, fs:0.66964 (r=0.758,p=0.600),  time:35.604, tt:925.701\n",
      "Ep:26, loss:0.00018, loss_test:0.10623, lr:9.61e-03, fs:0.69528 (r=0.818,p=0.604),  time:35.667, tt:963.017\n",
      "Ep:27, loss:0.00017, loss_test:0.10261, lr:9.51e-03, fs:0.66981 (r=0.717,p=0.628),  time:35.693, tt:999.392\n",
      "Ep:28, loss:0.00017, loss_test:0.10075, lr:9.41e-03, fs:0.70588 (r=0.788,p=0.639),  time:35.701, tt:1035.323\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.09786, lr:9.41e-03, fs:0.72072 (r=0.808,p=0.650),  time:35.708, tt:1071.227\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.09668, lr:9.41e-03, fs:0.70192 (r=0.737,p=0.670),  time:35.700, tt:1106.688\n",
      "Ep:31, loss:0.00015, loss_test:0.09630, lr:9.41e-03, fs:0.74667 (r=0.848,p=0.667),  time:35.753, tt:1144.085\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.09088, lr:9.41e-03, fs:0.73171 (r=0.758,p=0.708),  time:35.804, tt:1181.528\n",
      "Ep:33, loss:0.00014, loss_test:0.09223, lr:9.41e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.848, tt:1218.848\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.08526, lr:9.41e-03, fs:0.77570 (r=0.838,p=0.722),  time:35.868, tt:1255.372\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.08492, lr:9.41e-03, fs:0.78873 (r=0.848,p=0.737),  time:35.870, tt:1291.335\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.08178, lr:9.41e-03, fs:0.80909 (r=0.899,p=0.736),  time:35.858, tt:1326.738\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.08234, lr:9.41e-03, fs:0.78846 (r=0.828,p=0.752),  time:35.880, tt:1363.438\n",
      "Ep:38, loss:0.00012, loss_test:0.08143, lr:9.41e-03, fs:0.80717 (r=0.909,p=0.726),  time:35.922, tt:1400.950\n",
      "Ep:39, loss:0.00012, loss_test:0.07821, lr:9.41e-03, fs:0.80788 (r=0.828,p=0.788),  time:35.965, tt:1438.590\n",
      "Ep:40, loss:0.00011, loss_test:0.08112, lr:9.41e-03, fs:0.80734 (r=0.889,p=0.739),  time:36.006, tt:1476.246\n",
      "Ep:41, loss:0.00011, loss_test:0.07312, lr:9.41e-03, fs:0.81308 (r=0.879,p=0.757),  time:36.026, tt:1513.112\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.06983, lr:9.41e-03, fs:0.84259 (r=0.919,p=0.778),  time:36.032, tt:1549.361\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.07758, lr:9.41e-03, fs:0.80383 (r=0.848,p=0.764),  time:36.021, tt:1584.932\n",
      "Ep:44, loss:0.00010, loss_test:0.06766, lr:9.41e-03, fs:0.83962 (r=0.899,p=0.788),  time:36.054, tt:1622.423\n",
      "Ep:45, loss:0.00010, loss_test:0.07018, lr:9.41e-03, fs:0.83871 (r=0.919,p=0.771),  time:36.070, tt:1659.230\n",
      "Ep:46, loss:0.00009, loss_test:0.07258, lr:9.41e-03, fs:0.82178 (r=0.838,p=0.806),  time:36.071, tt:1695.332\n",
      "Ep:47, loss:0.00009, loss_test:0.06792, lr:9.41e-03, fs:0.84360 (r=0.899,p=0.795),  time:36.086, tt:1732.150\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.07152, lr:9.41e-03, fs:0.79167 (r=0.768,p=0.817),  time:36.089, tt:1768.362\n",
      "Ep:49, loss:0.00008, loss_test:0.06541, lr:9.41e-03, fs:0.85577 (r=0.899,p=0.817),  time:36.089, tt:1804.474\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.06786, lr:9.41e-03, fs:0.83333 (r=0.859,p=0.810),  time:36.106, tt:1841.418\n",
      "Ep:51, loss:0.00009, loss_test:0.07362, lr:9.41e-03, fs:0.79381 (r=0.778,p=0.811),  time:36.091, tt:1876.708\n",
      "Ep:52, loss:0.00008, loss_test:0.06841, lr:9.41e-03, fs:0.85308 (r=0.909,p=0.804),  time:36.102, tt:1913.416\n",
      "Ep:53, loss:0.00008, loss_test:0.07774, lr:9.41e-03, fs:0.83333 (r=0.808,p=0.860),  time:36.118, tt:1950.372\n",
      "Ep:54, loss:0.00008, loss_test:0.07050, lr:9.41e-03, fs:0.80788 (r=0.828,p=0.788),  time:36.152, tt:1988.380\n",
      "Ep:55, loss:0.00008, loss_test:0.06926, lr:9.41e-03, fs:0.82902 (r=0.808,p=0.851),  time:36.190, tt:2026.660\n",
      "Ep:56, loss:0.00007, loss_test:0.07008, lr:9.41e-03, fs:0.81443 (r=0.798,p=0.832),  time:36.225, tt:2064.808\n",
      "Ep:57, loss:0.00006, loss_test:0.07514, lr:9.41e-03, fs:0.78974 (r=0.778,p=0.802),  time:36.215, tt:2100.466\n",
      "Ep:58, loss:0.00007, loss_test:0.08161, lr:9.41e-03, fs:0.78125 (r=0.758,p=0.806),  time:36.226, tt:2137.362\n",
      "Ep:59, loss:0.00007, loss_test:0.06523, lr:9.41e-03, fs:0.86000 (r=0.869,p=0.851),  time:36.265, tt:2175.873\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.06934, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.284, tt:2213.304\n",
      "Ep:61, loss:0.00006, loss_test:0.07291, lr:9.41e-03, fs:0.80402 (r=0.808,p=0.800),  time:36.285, tt:2249.667\n",
      "Ep:62, loss:0.00006, loss_test:0.06870, lr:9.41e-03, fs:0.77596 (r=0.717,p=0.845),  time:36.287, tt:2286.075\n",
      "Ep:63, loss:0.00006, loss_test:0.06587, lr:9.41e-03, fs:0.82105 (r=0.788,p=0.857),  time:36.290, tt:2322.579\n",
      "Ep:64, loss:0.00006, loss_test:0.07941, lr:9.41e-03, fs:0.80435 (r=0.747,p=0.871),  time:36.293, tt:2359.040\n",
      "Ep:65, loss:0.00005, loss_test:0.06717, lr:9.41e-03, fs:0.87047 (r=0.848,p=0.894),  time:36.294, tt:2395.420\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.07863, lr:9.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.316, tt:2433.157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00004, loss_test:0.06811, lr:9.41e-03, fs:0.86294 (r=0.859,p=0.867),  time:36.307, tt:2468.881\n",
      "Ep:68, loss:0.00004, loss_test:0.07223, lr:9.41e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.319, tt:2506.028\n",
      "Ep:69, loss:0.00004, loss_test:0.07131, lr:9.41e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.301, tt:2541.075\n",
      "Ep:70, loss:0.00004, loss_test:0.07345, lr:9.41e-03, fs:0.79188 (r=0.788,p=0.796),  time:36.297, tt:2577.059\n",
      "Ep:71, loss:0.00005, loss_test:0.08774, lr:9.41e-03, fs:0.75449 (r=0.636,p=0.926),  time:36.308, tt:2614.164\n",
      "Ep:72, loss:0.00004, loss_test:0.06304, lr:9.41e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.310, tt:2650.597\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00004, loss_test:0.08610, lr:9.41e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.323, tt:2687.892\n",
      "Ep:74, loss:0.00004, loss_test:0.06794, lr:9.41e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.330, tt:2724.779\n",
      "Ep:75, loss:0.00004, loss_test:0.08694, lr:9.41e-03, fs:0.74157 (r=0.667,p=0.835),  time:36.317, tt:2760.096\n",
      "Ep:76, loss:0.00004, loss_test:0.06370, lr:9.41e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.321, tt:2796.721\n",
      "Ep:77, loss:0.00003, loss_test:0.07531, lr:9.41e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.325, tt:2833.321\n",
      "Ep:78, loss:0.00003, loss_test:0.06911, lr:9.41e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.319, tt:2869.240\n",
      "Ep:79, loss:0.00003, loss_test:0.07922, lr:9.41e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.325, tt:2906.027\n",
      "Ep:80, loss:0.00002, loss_test:0.06765, lr:9.41e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.336, tt:2943.177\n",
      "Ep:81, loss:0.00002, loss_test:0.08138, lr:9.41e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.330, tt:2979.077\n",
      "Ep:82, loss:0.00002, loss_test:0.07312, lr:9.41e-03, fs:0.81522 (r=0.758,p=0.882),  time:36.343, tt:3016.438\n",
      "Ep:83, loss:0.00002, loss_test:0.08071, lr:9.41e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.342, tt:3052.743\n",
      "Ep:84, loss:0.00002, loss_test:0.06953, lr:9.32e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.348, tt:3089.576\n",
      "Ep:85, loss:0.00002, loss_test:0.08470, lr:9.23e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.346, tt:3125.719\n",
      "Ep:86, loss:0.00002, loss_test:0.07159, lr:9.14e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.351, tt:3162.563\n",
      "Ep:87, loss:0.00002, loss_test:0.07916, lr:9.04e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.335, tt:3197.451\n",
      "Ep:88, loss:0.00002, loss_test:0.07672, lr:8.95e-03, fs:0.84746 (r=0.758,p=0.962),  time:36.346, tt:3234.802\n",
      "Ep:89, loss:0.00002, loss_test:0.07607, lr:8.86e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.336, tt:3270.222\n",
      "Ep:90, loss:0.00002, loss_test:0.07549, lr:8.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.338, tt:3306.791\n",
      "Ep:91, loss:0.00002, loss_test:0.07947, lr:8.69e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.342, tt:3343.487\n",
      "Ep:92, loss:0.00002, loss_test:0.08222, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.347, tt:3380.295\n",
      "Ep:93, loss:0.00001, loss_test:0.08019, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.347, tt:3416.574\n",
      "Ep:94, loss:0.00001, loss_test:0.08559, lr:8.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.363, tt:3454.478\n",
      "Ep:95, loss:0.00002, loss_test:0.08951, lr:8.35e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.358, tt:3490.338\n",
      "Ep:96, loss:0.00002, loss_test:0.07643, lr:8.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.359, tt:3526.783\n",
      "Ep:97, loss:0.00002, loss_test:0.08302, lr:8.18e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.356, tt:3562.892\n",
      "Ep:98, loss:0.00002, loss_test:0.07490, lr:8.10e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.357, tt:3599.310\n",
      "Ep:99, loss:0.00001, loss_test:0.08082, lr:8.02e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.356, tt:3635.626\n",
      "Ep:100, loss:0.00001, loss_test:0.08123, lr:7.94e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.361, tt:3672.418\n",
      "Ep:101, loss:0.00001, loss_test:0.08340, lr:7.86e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.356, tt:3708.262\n",
      "Ep:102, loss:0.00001, loss_test:0.08963, lr:7.78e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.356, tt:3744.688\n",
      "Ep:103, loss:0.00001, loss_test:0.07601, lr:7.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.352, tt:3780.613\n",
      "Ep:104, loss:0.00001, loss_test:0.08368, lr:7.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.348, tt:3816.544\n",
      "Ep:105, loss:0.00001, loss_test:0.08368, lr:7.55e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.358, tt:3853.996\n",
      "Ep:106, loss:0.00001, loss_test:0.07680, lr:7.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.358, tt:3890.356\n",
      "Ep:107, loss:0.00001, loss_test:0.09394, lr:7.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:36.361, tt:3926.934\n",
      "Ep:108, loss:0.00001, loss_test:0.07851, lr:7.32e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.352, tt:3962.371\n",
      "Ep:109, loss:0.00001, loss_test:0.08174, lr:7.25e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.356, tt:3999.179\n",
      "Ep:110, loss:0.00001, loss_test:0.08268, lr:7.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.340, tt:4033.724\n",
      "Ep:111, loss:0.00001, loss_test:0.08092, lr:7.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.335, tt:4069.467\n",
      "Ep:112, loss:0.00001, loss_test:0.08766, lr:7.03e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.354, tt:4108.050\n",
      "Ep:113, loss:0.00001, loss_test:0.08263, lr:6.96e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.356, tt:4144.608\n",
      "Ep:114, loss:0.00001, loss_test:0.08107, lr:6.89e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.346, tt:4179.836\n",
      "Ep:115, loss:0.00001, loss_test:0.08115, lr:6.83e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.345, tt:4216.039\n",
      "Ep:116, loss:0.00001, loss_test:0.08659, lr:6.76e-03, fs:0.76829 (r=0.636,p=0.969),  time:36.339, tt:4251.688\n",
      "Ep:117, loss:0.00001, loss_test:0.08431, lr:6.69e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.338, tt:4287.931\n",
      "Ep:118, loss:0.00001, loss_test:0.09149, lr:6.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:36.341, tt:4324.564\n",
      "Ep:119, loss:0.00001, loss_test:0.08499, lr:6.56e-03, fs:0.77301 (r=0.636,p=0.984),  time:36.330, tt:4359.620\n",
      "Ep:120, loss:0.00001, loss_test:0.08913, lr:6.49e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.336, tt:4396.635\n",
      "Ep:121, loss:0.00001, loss_test:0.09030, lr:6.43e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.322, tt:4431.243\n",
      "Ep:122, loss:0.00000, loss_test:0.08456, lr:6.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.313, tt:4466.466\n",
      "Ep:123, loss:0.00000, loss_test:0.09011, lr:6.30e-03, fs:0.76543 (r=0.626,p=0.984),  time:36.307, tt:4502.016\n",
      "Ep:124, loss:0.00000, loss_test:0.09031, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.296, tt:4536.992\n",
      "Ep:125, loss:0.00000, loss_test:0.09017, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.280, tt:4571.243\n",
      "Ep:126, loss:0.00000, loss_test:0.09057, lr:6.11e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.280, tt:4607.622\n",
      "Ep:127, loss:0.00000, loss_test:0.09006, lr:6.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.262, tt:4641.593\n",
      "Ep:128, loss:0.00000, loss_test:0.09511, lr:5.99e-03, fs:0.80240 (r=0.677,p=0.985),  time:36.264, tt:4677.997\n",
      "Ep:129, loss:0.00000, loss_test:0.09179, lr:5.93e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.267, tt:4714.722\n",
      "Ep:130, loss:0.00000, loss_test:0.08963, lr:5.87e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.263, tt:4750.488\n",
      "Ep:131, loss:0.00000, loss_test:0.09283, lr:5.81e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.267, tt:4787.252\n",
      "Ep:132, loss:0.00000, loss_test:0.09477, lr:5.75e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.270, tt:4823.923\n",
      "Ep:133, loss:0.00000, loss_test:0.09451, lr:5.70e-03, fs:0.77019 (r=0.626,p=1.000),  time:36.268, tt:4859.900\n",
      "Ep:134, loss:0.00000, loss_test:0.08973, lr:5.64e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.264, tt:4895.697\n",
      "Ep:135, loss:0.00000, loss_test:0.10021, lr:5.58e-03, fs:0.77301 (r=0.636,p=0.984),  time:36.262, tt:4931.695\n",
      "Ep:136, loss:0.00000, loss_test:0.09473, lr:5.53e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.265, tt:4968.349\n",
      "Ep:137, loss:0.00000, loss_test:0.09337, lr:5.47e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.255, tt:5003.202\n",
      "Ep:138, loss:0.00000, loss_test:0.09641, lr:5.42e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.249, tt:5038.673\n",
      "Ep:139, loss:0.00000, loss_test:0.09337, lr:5.36e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.247, tt:5074.570\n",
      "Ep:140, loss:0.00000, loss_test:0.09592, lr:5.31e-03, fs:0.78788 (r=0.657,p=0.985),  time:36.246, tt:5110.621\n",
      "Ep:141, loss:0.00000, loss_test:0.09470, lr:5.26e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.236, tt:5145.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.09323, lr:5.20e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.227, tt:5180.453\n",
      "Ep:143, loss:0.00000, loss_test:0.09253, lr:5.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.236, tt:5218.049\n",
      "Ep:144, loss:0.00000, loss_test:0.09446, lr:5.10e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.243, tt:5255.279\n",
      "Ep:145, loss:0.00000, loss_test:0.09500, lr:5.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.242, tt:5291.301\n",
      "Ep:146, loss:0.00000, loss_test:0.09498, lr:5.00e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.236, tt:5326.728\n",
      "Ep:147, loss:0.00000, loss_test:0.09728, lr:4.95e-03, fs:0.77778 (r=0.636,p=1.000),  time:36.233, tt:5362.460\n",
      "Ep:148, loss:0.00000, loss_test:0.09422, lr:4.90e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.227, tt:5397.808\n",
      "Ep:149, loss:0.00000, loss_test:0.09785, lr:4.85e-03, fs:0.82840 (r=0.707,p=1.000),  time:36.224, tt:5433.584\n",
      "Ep:150, loss:0.00000, loss_test:0.09865, lr:4.80e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.229, tt:5470.507\n",
      "Ep:151, loss:0.00000, loss_test:0.08998, lr:4.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.239, tt:5508.403\n",
      "Ep:152, loss:0.00000, loss_test:0.09422, lr:4.71e-03, fs:0.77778 (r=0.636,p=1.000),  time:36.236, tt:5544.043\n",
      "Ep:153, loss:0.00000, loss_test:0.09772, lr:4.66e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.237, tt:5580.484\n",
      "Ep:154, loss:0.00000, loss_test:0.09553, lr:4.61e-03, fs:0.82840 (r=0.707,p=1.000),  time:36.235, tt:5616.425\n",
      "Ep:155, loss:0.00000, loss_test:0.09182, lr:4.57e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.237, tt:5652.950\n",
      "Ep:156, loss:0.00000, loss_test:0.09207, lr:4.52e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.236, tt:5688.982\n",
      "Ep:157, loss:0.00000, loss_test:0.09381, lr:4.48e-03, fs:0.81437 (r=0.687,p=1.000),  time:36.239, tt:5725.711\n",
      "Ep:158, loss:0.00000, loss_test:0.09173, lr:4.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.235, tt:5761.295\n",
      "Ep:159, loss:0.00000, loss_test:0.09592, lr:4.39e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.234, tt:5797.520\n",
      "Ep:160, loss:0.00000, loss_test:0.09857, lr:4.34e-03, fs:0.77019 (r=0.626,p=1.000),  time:36.233, tt:5833.443\n",
      "Ep:161, loss:0.00000, loss_test:0.08974, lr:4.30e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.233, tt:5869.760\n",
      "Ep:162, loss:0.00000, loss_test:0.09327, lr:4.26e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.219, tt:5903.618\n",
      "Ep:163, loss:0.00000, loss_test:0.09495, lr:4.21e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.210, tt:5938.413\n",
      "Ep:164, loss:0.00000, loss_test:0.09166, lr:4.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.212, tt:5975.015\n",
      "Ep:165, loss:0.00000, loss_test:0.09271, lr:4.13e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.209, tt:6010.763\n",
      "Ep:166, loss:0.00000, loss_test:0.09351, lr:4.09e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.199, tt:6045.183\n",
      "Ep:167, loss:0.00000, loss_test:0.09224, lr:4.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.183, tt:6078.711\n",
      "Ep:168, loss:0.00000, loss_test:0.09408, lr:4.01e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.174, tt:6113.423\n",
      "Ep:169, loss:0.00000, loss_test:0.09503, lr:3.97e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.164, tt:6147.901\n",
      "Ep:170, loss:0.00000, loss_test:0.09367, lr:3.93e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.167, tt:6184.505\n",
      "Ep:171, loss:0.00000, loss_test:0.09225, lr:3.89e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.164, tt:6220.200\n",
      "Ep:172, loss:0.00000, loss_test:0.09470, lr:3.85e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.160, tt:6255.605\n",
      "Ep:173, loss:0.00000, loss_test:0.09322, lr:3.81e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.165, tt:6292.677\n",
      "Ep:174, loss:0.00000, loss_test:0.09161, lr:3.77e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.162, tt:6328.311\n",
      "Ep:175, loss:0.00000, loss_test:0.09259, lr:3.73e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.153, tt:6363.015\n",
      "Ep:176, loss:0.00000, loss_test:0.09418, lr:3.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.147, tt:6397.964\n",
      "Ep:177, loss:0.00000, loss_test:0.09415, lr:3.66e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.137, tt:6432.361\n",
      "Ep:178, loss:0.00000, loss_test:0.09239, lr:3.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.127, tt:6466.729\n",
      "Ep:179, loss:0.00000, loss_test:0.09575, lr:3.59e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.110, tt:6499.757\n",
      "Ep:180, loss:0.00000, loss_test:0.09416, lr:3.55e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.098, tt:6533.775\n",
      "Ep:181, loss:0.00000, loss_test:0.09214, lr:3.52e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.096, tt:6569.387\n",
      "Ep:182, loss:0.00000, loss_test:0.09369, lr:3.48e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.088, tt:6604.136\n",
      "Ep:183, loss:0.00000, loss_test:0.09418, lr:3.45e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.082, tt:6639.147\n",
      "Ep:184, loss:0.00000, loss_test:0.09353, lr:3.41e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.081, tt:6675.018\n",
      "Ep:185, loss:0.00000, loss_test:0.09237, lr:3.38e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.082, tt:6711.183\n",
      "Ep:186, loss:0.00000, loss_test:0.09375, lr:3.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.071, tt:6745.234\n",
      "Ep:187, loss:0.00000, loss_test:0.09293, lr:3.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.062, tt:6779.626\n",
      "Ep:188, loss:0.00000, loss_test:0.09280, lr:3.28e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.046, tt:6812.609\n",
      "Ep:189, loss:0.00000, loss_test:0.09422, lr:3.24e-03, fs:0.83721 (r=0.727,p=0.986),  time:36.031, tt:6845.941\n",
      "Ep:190, loss:0.00000, loss_test:0.09378, lr:3.21e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.019, tt:6879.617\n",
      "Ep:191, loss:0.00000, loss_test:0.09227, lr:3.18e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.011, tt:6914.080\n",
      "Ep:192, loss:0.00000, loss_test:0.09386, lr:3.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.997, tt:6947.462\n",
      "Ep:193, loss:0.00000, loss_test:0.09422, lr:3.12e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.987, tt:6981.459\n",
      "Ep:194, loss:0.00000, loss_test:0.09341, lr:3.09e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.973, tt:7014.699\n",
      "Ep:195, loss:0.00000, loss_test:0.09224, lr:3.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.962, tt:7048.622\n",
      "Ep:196, loss:0.00000, loss_test:0.09216, lr:3.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.947, tt:7081.534\n",
      "Ep:197, loss:0.00000, loss_test:0.09313, lr:2.99e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.935, tt:7115.038\n",
      "Ep:198, loss:0.00000, loss_test:0.09257, lr:2.96e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.928, tt:7149.753\n",
      "Ep:199, loss:0.00000, loss_test:0.09359, lr:2.93e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.916, tt:7183.213\n",
      "Ep:200, loss:0.00000, loss_test:0.09229, lr:2.90e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.910, tt:7217.863\n",
      "Ep:201, loss:0.00000, loss_test:0.09310, lr:2.88e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.898, tt:7251.341\n",
      "Ep:202, loss:0.00000, loss_test:0.09317, lr:2.85e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.883, tt:7284.308\n",
      "Ep:203, loss:0.00000, loss_test:0.09229, lr:2.82e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.879, tt:7319.378\n",
      "Ep:204, loss:0.00000, loss_test:0.09369, lr:2.79e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.878, tt:7354.997\n",
      "Ep:205, loss:0.00000, loss_test:0.09284, lr:2.76e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.868, tt:7388.887\n",
      "Ep:206, loss:0.00000, loss_test:0.09229, lr:2.73e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.851, tt:7421.156\n",
      "Ep:207, loss:0.00000, loss_test:0.09276, lr:2.71e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.838, tt:7454.275\n",
      "Ep:208, loss:0.00000, loss_test:0.09245, lr:2.68e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.825, tt:7487.508\n",
      "Ep:209, loss:0.00000, loss_test:0.09386, lr:2.65e-03, fs:0.83721 (r=0.727,p=0.986),  time:35.786, tt:7515.028\n",
      "Ep:210, loss:0.00000, loss_test:0.09345, lr:2.63e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.740, tt:7541.123\n",
      "Ep:211, loss:0.00000, loss_test:0.09305, lr:2.60e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.709, tt:7570.259\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03093, lr:6.00e-02, fs:0.58333 (r=0.636,p=0.538),  time:29.711, tt:29.711\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02428, lr:6.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:30.744, tt:61.487\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02544, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:31.598, tt:94.793\n",
      "Ep:3, loss:0.00005, loss_test:0.02578, lr:6.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:32.342, tt:129.366\n",
      "Ep:4, loss:0.00005, loss_test:0.02545, lr:6.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:32.570, tt:162.850\n",
      "Ep:5, loss:0.00005, loss_test:0.02577, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:32.989, tt:197.936\n",
      "Ep:6, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:33.672, tt:235.702\n",
      "Ep:7, loss:0.00005, loss_test:0.02567, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:33.843, tt:270.740\n",
      "Ep:8, loss:0.00005, loss_test:0.02551, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:33.881, tt:304.929\n",
      "Ep:9, loss:0.00005, loss_test:0.02525, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:33.824, tt:338.240\n",
      "Ep:10, loss:0.00005, loss_test:0.02479, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:33.869, tt:372.560\n",
      "Ep:11, loss:0.00005, loss_test:0.02425, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:33.838, tt:406.058\n",
      "Ep:12, loss:0.00004, loss_test:0.02367, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:33.790, tt:439.272\n",
      "Ep:13, loss:0.00004, loss_test:0.02306, lr:5.94e-02, fs:0.66154 (r=0.869,p=0.534),  time:33.789, tt:473.046\n",
      "Ep:14, loss:0.00004, loss_test:0.02241, lr:5.88e-02, fs:0.67170 (r=0.899,p=0.536),  time:33.705, tt:505.569\n",
      "Ep:15, loss:0.00004, loss_test:0.02176, lr:5.82e-02, fs:0.65660 (r=0.879,p=0.524),  time:33.691, tt:539.061\n",
      "Ep:16, loss:0.00004, loss_test:0.02116, lr:5.76e-02, fs:0.66165 (r=0.889,p=0.527),  time:33.734, tt:573.470\n",
      "Ep:17, loss:0.00004, loss_test:0.02060, lr:5.71e-02, fs:0.66923 (r=0.879,p=0.540),  time:33.750, tt:607.495\n",
      "Ep:18, loss:0.00004, loss_test:0.02010, lr:5.65e-02, fs:0.67704 (r=0.879,p=0.551),  time:33.799, tt:642.187\n",
      "Ep:19, loss:0.00004, loss_test:0.01963, lr:5.59e-02, fs:0.68217 (r=0.889,p=0.553),  time:33.764, tt:675.285\n",
      "Ep:20, loss:0.00003, loss_test:0.01926, lr:5.54e-02, fs:0.69261 (r=0.899,p=0.563),  time:33.812, tt:710.061\n",
      "Ep:21, loss:0.00003, loss_test:0.01896, lr:5.48e-02, fs:0.70079 (r=0.899,p=0.574),  time:33.804, tt:743.692\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01866, lr:5.48e-02, fs:0.70916 (r=0.899,p=0.586),  time:33.800, tt:777.411\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01832, lr:5.48e-02, fs:0.71713 (r=0.909,p=0.592),  time:33.813, tt:811.512\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01786, lr:5.48e-02, fs:0.72289 (r=0.909,p=0.600),  time:33.859, tt:846.480\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01746, lr:5.48e-02, fs:0.72358 (r=0.899,p=0.605),  time:33.905, tt:881.529\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01713, lr:5.48e-02, fs:0.72727 (r=0.889,p=0.615),  time:33.918, tt:915.788\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01674, lr:5.48e-02, fs:0.73418 (r=0.879,p=0.630),  time:33.920, tt:949.770\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01625, lr:5.48e-02, fs:0.73640 (r=0.889,p=0.629),  time:33.961, tt:984.883\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01578, lr:5.48e-02, fs:0.75000 (r=0.909,p=0.638),  time:34.001, tt:1020.038\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01538, lr:5.48e-02, fs:0.75314 (r=0.909,p=0.643),  time:34.052, tt:1055.601\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01506, lr:5.48e-02, fs:0.75949 (r=0.909,p=0.652),  time:34.022, tt:1088.702\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01468, lr:5.48e-02, fs:0.78298 (r=0.929,p=0.676),  time:34.035, tt:1123.157\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01438, lr:5.48e-02, fs:0.78788 (r=0.919,p=0.689),  time:34.042, tt:1157.430\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01425, lr:5.48e-02, fs:0.79825 (r=0.919,p=0.705),  time:34.079, tt:1192.762\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01405, lr:5.48e-02, fs:0.80889 (r=0.919,p=0.722),  time:34.053, tt:1225.900\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01386, lr:5.48e-02, fs:0.81250 (r=0.919,p=0.728),  time:34.039, tt:1259.433\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01388, lr:5.48e-02, fs:0.81818 (r=0.909,p=0.744),  time:34.080, tt:1295.037\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01391, lr:5.48e-02, fs:0.81651 (r=0.899,p=0.748),  time:34.077, tt:1328.985\n",
      "Ep:39, loss:0.00002, loss_test:0.01392, lr:5.48e-02, fs:0.83721 (r=0.909,p=0.776),  time:34.148, tt:1365.927\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01373, lr:5.48e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.163, tt:1400.681\n",
      "Ep:41, loss:0.00001, loss_test:0.01394, lr:5.48e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.164, tt:1434.877\n",
      "Ep:42, loss:0.00001, loss_test:0.01383, lr:5.48e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.155, tt:1468.661\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01408, lr:5.48e-02, fs:0.80612 (r=0.798,p=0.814),  time:34.204, tt:1504.969\n",
      "Ep:44, loss:0.00001, loss_test:0.01407, lr:5.48e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.213, tt:1539.601\n",
      "Ep:45, loss:0.00001, loss_test:0.01409, lr:5.48e-02, fs:0.79167 (r=0.768,p=0.817),  time:34.237, tt:1574.882\n",
      "Ep:46, loss:0.00001, loss_test:0.01466, lr:5.48e-02, fs:0.78756 (r=0.768,p=0.809),  time:34.258, tt:1610.147\n",
      "Ep:47, loss:0.00001, loss_test:0.01451, lr:5.48e-02, fs:0.79167 (r=0.768,p=0.817),  time:34.267, tt:1644.819\n",
      "Ep:48, loss:0.00001, loss_test:0.01459, lr:5.48e-02, fs:0.79581 (r=0.768,p=0.826),  time:34.287, tt:1680.047\n",
      "Ep:49, loss:0.00001, loss_test:0.01475, lr:5.48e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.305, tt:1715.254\n",
      "Ep:50, loss:0.00001, loss_test:0.01513, lr:5.48e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.316, tt:1750.106\n",
      "Ep:51, loss:0.00001, loss_test:0.01532, lr:5.48e-02, fs:0.76503 (r=0.707,p=0.833),  time:34.339, tt:1785.615\n",
      "Ep:52, loss:0.00001, loss_test:0.01558, lr:5.48e-02, fs:0.74444 (r=0.677,p=0.827),  time:34.380, tt:1822.151\n",
      "Ep:53, loss:0.00001, loss_test:0.01578, lr:5.48e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.405, tt:1857.866\n",
      "Ep:54, loss:0.00001, loss_test:0.01616, lr:5.43e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.417, tt:1892.928\n",
      "Ep:55, loss:0.00001, loss_test:0.01646, lr:5.37e-02, fs:0.72727 (r=0.646,p=0.831),  time:34.438, tt:1928.534\n",
      "Ep:56, loss:0.00001, loss_test:0.01649, lr:5.32e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.441, tt:1963.144\n",
      "Ep:57, loss:0.00001, loss_test:0.01702, lr:5.27e-02, fs:0.72000 (r=0.636,p=0.829),  time:34.471, tt:1999.344\n",
      "Ep:58, loss:0.00001, loss_test:0.01706, lr:5.21e-02, fs:0.72832 (r=0.636,p=0.851),  time:34.494, tt:2035.136\n",
      "Ep:59, loss:0.00001, loss_test:0.01748, lr:5.16e-02, fs:0.72832 (r=0.636,p=0.851),  time:34.506, tt:2070.336\n",
      "Ep:60, loss:0.00001, loss_test:0.01735, lr:5.11e-02, fs:0.72832 (r=0.636,p=0.851),  time:34.510, tt:2105.112\n",
      "Ep:61, loss:0.00001, loss_test:0.01768, lr:5.06e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.519, tt:2140.163\n",
      "Ep:62, loss:0.00001, loss_test:0.01807, lr:5.01e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.531, tt:2175.452\n",
      "Ep:63, loss:0.00001, loss_test:0.01806, lr:4.96e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.544, tt:2210.834\n",
      "Ep:64, loss:0.00001, loss_test:0.01854, lr:4.91e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.560, tt:2246.374\n",
      "Ep:65, loss:0.00001, loss_test:0.01805, lr:4.86e-02, fs:0.76136 (r=0.677,p=0.870),  time:34.566, tt:2281.378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00000, loss_test:0.01920, lr:4.81e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.582, tt:2317.012\n",
      "Ep:67, loss:0.00000, loss_test:0.01876, lr:4.76e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.592, tt:2352.233\n",
      "Ep:68, loss:0.00000, loss_test:0.01930, lr:4.71e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.604, tt:2387.685\n",
      "Ep:69, loss:0.00000, loss_test:0.01956, lr:4.67e-02, fs:0.73373 (r=0.626,p=0.886),  time:34.614, tt:2422.954\n",
      "Ep:70, loss:0.00000, loss_test:0.01922, lr:4.62e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.634, tt:2459.038\n",
      "Ep:71, loss:0.00000, loss_test:0.02039, lr:4.57e-02, fs:0.71515 (r=0.596,p=0.894),  time:34.644, tt:2494.335\n",
      "Ep:72, loss:0.00000, loss_test:0.01977, lr:4.53e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.650, tt:2529.450\n",
      "Ep:73, loss:0.00000, loss_test:0.02067, lr:4.48e-02, fs:0.68323 (r=0.556,p=0.887),  time:34.665, tt:2565.221\n",
      "Ep:74, loss:0.00000, loss_test:0.02058, lr:4.44e-02, fs:0.70370 (r=0.576,p=0.905),  time:34.677, tt:2600.786\n",
      "Ep:75, loss:0.00000, loss_test:0.02102, lr:4.39e-02, fs:0.67925 (r=0.545,p=0.900),  time:34.688, tt:2636.281\n",
      "Ep:76, loss:0.00000, loss_test:0.02107, lr:4.35e-02, fs:0.66667 (r=0.525,p=0.912),  time:34.711, tt:2672.750\n",
      "Ep:77, loss:0.00000, loss_test:0.02150, lr:4.31e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.706, tt:2707.064\n",
      "Ep:78, loss:0.00000, loss_test:0.02172, lr:4.26e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.712, tt:2742.217\n",
      "Ep:79, loss:0.00000, loss_test:0.02169, lr:4.22e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.721, tt:2777.655\n",
      "Ep:80, loss:0.00000, loss_test:0.02226, lr:4.18e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.727, tt:2812.885\n",
      "Ep:81, loss:0.00000, loss_test:0.02190, lr:4.14e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.750, tt:2849.481\n",
      "Ep:82, loss:0.00000, loss_test:0.02243, lr:4.10e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.761, tt:2885.133\n",
      "Ep:83, loss:0.00000, loss_test:0.02238, lr:4.05e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.738, tt:2917.981\n",
      "Ep:84, loss:0.00000, loss_test:0.02277, lr:4.01e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.740, tt:2952.926\n",
      "Ep:85, loss:0.00000, loss_test:0.02278, lr:3.97e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.755, tt:2988.939\n",
      "Ep:86, loss:0.00000, loss_test:0.02304, lr:3.93e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.776, tt:3025.502\n",
      "Ep:87, loss:0.00000, loss_test:0.02316, lr:3.89e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.784, tt:3060.994\n",
      "Ep:88, loss:0.00000, loss_test:0.02319, lr:3.86e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.795, tt:3096.729\n",
      "Ep:89, loss:0.00000, loss_test:0.02366, lr:3.82e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.835, tt:3135.184\n",
      "Ep:90, loss:0.00000, loss_test:0.02339, lr:3.78e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.842, tt:3170.586\n",
      "Ep:91, loss:0.00000, loss_test:0.02377, lr:3.74e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.841, tt:3205.388\n",
      "Ep:92, loss:0.00000, loss_test:0.02386, lr:3.70e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.874, tt:3243.300\n",
      "Ep:93, loss:0.00000, loss_test:0.02402, lr:3.67e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.879, tt:3278.671\n",
      "Ep:94, loss:0.00000, loss_test:0.02423, lr:3.63e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.877, tt:3313.306\n",
      "Ep:95, loss:0.00000, loss_test:0.02429, lr:3.59e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.890, tt:3349.412\n",
      "Ep:96, loss:0.00000, loss_test:0.02445, lr:3.56e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.913, tt:3386.608\n",
      "Ep:97, loss:0.00000, loss_test:0.02459, lr:3.52e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.925, tt:3422.676\n",
      "Ep:98, loss:0.00000, loss_test:0.02462, lr:3.49e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.947, tt:3459.766\n",
      "Ep:99, loss:0.00000, loss_test:0.02493, lr:3.45e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.952, tt:3495.161\n",
      "Ep:100, loss:0.00000, loss_test:0.02490, lr:3.42e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.959, tt:3530.878\n",
      "Ep:101, loss:0.00000, loss_test:0.02508, lr:3.38e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.956, tt:3565.540\n",
      "Ep:102, loss:0.00000, loss_test:0.02530, lr:3.35e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.955, tt:3600.352\n",
      "Ep:103, loss:0.00000, loss_test:0.02525, lr:3.32e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.959, tt:3635.741\n",
      "Ep:104, loss:0.00000, loss_test:0.02552, lr:3.28e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.964, tt:3671.244\n",
      "Ep:105, loss:0.00000, loss_test:0.02559, lr:3.25e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.976, tt:3707.481\n",
      "Ep:106, loss:0.00000, loss_test:0.02569, lr:3.22e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.979, tt:3742.786\n",
      "Ep:107, loss:0.00000, loss_test:0.02598, lr:3.19e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.984, tt:3778.278\n",
      "Ep:108, loss:0.00000, loss_test:0.02582, lr:3.15e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.004, tt:3815.402\n",
      "Ep:109, loss:0.00000, loss_test:0.02612, lr:3.12e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.024, tt:3852.686\n",
      "Ep:110, loss:0.00000, loss_test:0.02629, lr:3.09e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.039, tt:3889.318\n",
      "Ep:111, loss:0.00000, loss_test:0.02610, lr:3.06e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.047, tt:3925.240\n",
      "Ep:112, loss:0.00000, loss_test:0.02646, lr:3.03e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.052, tt:3960.886\n",
      "Ep:113, loss:0.00000, loss_test:0.02637, lr:3.00e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.061, tt:3996.900\n",
      "Ep:114, loss:0.00000, loss_test:0.02658, lr:2.97e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.064, tt:4032.391\n",
      "Ep:115, loss:0.00000, loss_test:0.02667, lr:2.94e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.073, tt:4068.488\n",
      "Ep:116, loss:0.00000, loss_test:0.02657, lr:2.91e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.075, tt:4103.803\n",
      "Ep:117, loss:0.00000, loss_test:0.02693, lr:2.88e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.079, tt:4139.369\n",
      "Ep:118, loss:0.00000, loss_test:0.02686, lr:2.85e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.095, tt:4176.337\n",
      "Ep:119, loss:0.00000, loss_test:0.02694, lr:2.82e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.109, tt:4213.077\n",
      "Ep:120, loss:0.00000, loss_test:0.02699, lr:2.80e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.121, tt:4249.653\n",
      "Ep:121, loss:0.00000, loss_test:0.02699, lr:2.77e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.120, tt:4284.673\n",
      "Ep:122, loss:0.00000, loss_test:0.02733, lr:2.74e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.121, tt:4319.920\n",
      "Ep:123, loss:0.00000, loss_test:0.02716, lr:2.71e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.113, tt:4354.054\n",
      "Ep:124, loss:0.00000, loss_test:0.02748, lr:2.69e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.121, tt:4390.098\n",
      "Ep:125, loss:0.00000, loss_test:0.02745, lr:2.66e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.117, tt:4424.746\n",
      "Ep:126, loss:0.00000, loss_test:0.02743, lr:2.63e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.126, tt:4461.029\n",
      "Ep:127, loss:0.00000, loss_test:0.02766, lr:2.61e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.130, tt:4496.660\n",
      "Ep:128, loss:0.00000, loss_test:0.02762, lr:2.58e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.150, tt:4534.288\n",
      "Ep:129, loss:0.00000, loss_test:0.02781, lr:2.55e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.145, tt:4568.914\n",
      "Ep:130, loss:0.00000, loss_test:0.02778, lr:2.53e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.152, tt:4604.882\n",
      "Ep:131, loss:0.00000, loss_test:0.02786, lr:2.50e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.153, tt:4640.175\n",
      "Ep:132, loss:0.00000, loss_test:0.02797, lr:2.48e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.152, tt:4675.182\n",
      "Ep:133, loss:0.00000, loss_test:0.02805, lr:2.45e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.151, tt:4710.288\n",
      "Ep:134, loss:0.00000, loss_test:0.02812, lr:2.43e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.152, tt:4745.538\n",
      "Ep:135, loss:0.00000, loss_test:0.02816, lr:2.40e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.154, tt:4780.909\n",
      "Ep:136, loss:0.00000, loss_test:0.02822, lr:2.38e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.156, tt:4816.428\n",
      "Ep:137, loss:0.00000, loss_test:0.02827, lr:2.36e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.151, tt:4850.900\n",
      "Ep:138, loss:0.00000, loss_test:0.02841, lr:2.33e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.157, tt:4886.813\n",
      "Ep:139, loss:0.00000, loss_test:0.02833, lr:2.31e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.167, tt:4923.316\n",
      "Ep:140, loss:0.00000, loss_test:0.02850, lr:2.29e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.171, tt:4959.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.02849, lr:2.26e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.174, tt:4994.763\n",
      "Ep:142, loss:0.00000, loss_test:0.02853, lr:2.24e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.182, tt:5031.031\n",
      "Ep:143, loss:0.00000, loss_test:0.02874, lr:2.22e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.187, tt:5066.909\n",
      "Ep:144, loss:0.00000, loss_test:0.02866, lr:2.20e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.197, tt:5103.596\n",
      "Ep:145, loss:0.00000, loss_test:0.02871, lr:2.17e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.200, tt:5139.253\n",
      "Ep:146, loss:0.00000, loss_test:0.02884, lr:2.15e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.196, tt:5173.831\n",
      "Ep:147, loss:0.00000, loss_test:0.02890, lr:2.13e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.198, tt:5209.239\n",
      "Ep:148, loss:0.00000, loss_test:0.02883, lr:2.11e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.206, tt:5245.723\n",
      "Ep:149, loss:0.00000, loss_test:0.02903, lr:2.09e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.213, tt:5281.993\n",
      "Ep:150, loss:0.00000, loss_test:0.02906, lr:2.07e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.206, tt:5316.140\n",
      "Ep:151, loss:0.00000, loss_test:0.02906, lr:2.05e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.210, tt:5351.973\n",
      "Ep:152, loss:0.00000, loss_test:0.02911, lr:2.03e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.204, tt:5386.188\n",
      "Ep:153, loss:0.00000, loss_test:0.02923, lr:2.01e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.198, tt:5420.462\n",
      "Ep:154, loss:0.00000, loss_test:0.02920, lr:1.99e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.186, tt:5453.817\n",
      "Ep:155, loss:0.00000, loss_test:0.02936, lr:1.97e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.177, tt:5487.635\n",
      "Ep:156, loss:0.00000, loss_test:0.02937, lr:1.95e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.173, tt:5522.102\n",
      "Ep:157, loss:0.00000, loss_test:0.02945, lr:1.93e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.172, tt:5557.177\n",
      "Ep:158, loss:0.00000, loss_test:0.02943, lr:1.91e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.171, tt:5592.187\n",
      "Ep:159, loss:0.00000, loss_test:0.02948, lr:1.89e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.157, tt:5625.178\n",
      "Ep:160, loss:0.00000, loss_test:0.02957, lr:1.87e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.152, tt:5659.508\n",
      "Ep:161, loss:0.00000, loss_test:0.02965, lr:1.85e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.143, tt:5693.148\n",
      "Ep:162, loss:0.00000, loss_test:0.02965, lr:1.83e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.148, tt:5729.141\n",
      "Ep:163, loss:0.00000, loss_test:0.02966, lr:1.81e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.144, tt:5763.636\n",
      "Ep:164, loss:0.00000, loss_test:0.02977, lr:1.80e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.140, tt:5798.070\n",
      "Ep:165, loss:0.00000, loss_test:0.02973, lr:1.78e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.137, tt:5832.717\n",
      "Ep:166, loss:0.00000, loss_test:0.02986, lr:1.76e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.137, tt:5867.896\n",
      "Ep:167, loss:0.00000, loss_test:0.02987, lr:1.74e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.141, tt:5903.642\n",
      "Ep:168, loss:0.00000, loss_test:0.02986, lr:1.73e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.130, tt:5937.014\n",
      "Ep:169, loss:0.00000, loss_test:0.03001, lr:1.71e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.123, tt:5970.933\n",
      "Ep:170, loss:0.00000, loss_test:0.02999, lr:1.69e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.123, tt:6006.047\n",
      "Ep:171, loss:0.00000, loss_test:0.02999, lr:1.67e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.121, tt:6040.833\n",
      "Ep:172, loss:0.00000, loss_test:0.03010, lr:1.66e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.121, tt:6075.965\n",
      "Ep:173, loss:0.00000, loss_test:0.03010, lr:1.64e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.118, tt:6110.485\n",
      "Ep:174, loss:0.00000, loss_test:0.03012, lr:1.62e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.110, tt:6144.250\n",
      "Ep:175, loss:0.00000, loss_test:0.03022, lr:1.61e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.095, tt:6176.707\n",
      "Ep:176, loss:0.00000, loss_test:0.03024, lr:1.59e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.087, tt:6210.406\n",
      "Ep:177, loss:0.00000, loss_test:0.03022, lr:1.58e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.084, tt:6244.929\n",
      "Ep:178, loss:0.00000, loss_test:0.03026, lr:1.56e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.086, tt:6280.425\n",
      "Ep:179, loss:0.00000, loss_test:0.03042, lr:1.54e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.080, tt:6314.472\n",
      "Ep:180, loss:0.00000, loss_test:0.03035, lr:1.53e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.081, tt:6349.630\n",
      "Ep:181, loss:0.00000, loss_test:0.03041, lr:1.51e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.080, tt:6384.549\n",
      "Ep:182, loss:0.00000, loss_test:0.03049, lr:1.50e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.085, tt:6420.597\n",
      "Ep:183, loss:0.00000, loss_test:0.03045, lr:1.48e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.084, tt:6455.418\n",
      "Ep:184, loss:0.00000, loss_test:0.03044, lr:1.47e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.091, tt:6491.882\n",
      "Ep:185, loss:0.00000, loss_test:0.03058, lr:1.45e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.080, tt:6524.949\n",
      "Ep:186, loss:0.00000, loss_test:0.03057, lr:1.44e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.093, tt:6562.374\n",
      "Ep:187, loss:0.00000, loss_test:0.03061, lr:1.43e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.105, tt:6599.807\n",
      "Ep:188, loss:0.00000, loss_test:0.03066, lr:1.41e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.128, tt:6639.213\n",
      "Ep:189, loss:0.00000, loss_test:0.03066, lr:1.40e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.147, tt:6677.837\n",
      "Ep:190, loss:0.00000, loss_test:0.03070, lr:1.38e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.166, tt:6716.797\n",
      "Ep:191, loss:0.00000, loss_test:0.03076, lr:1.37e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.164, tt:6751.517\n",
      "Ep:192, loss:0.00000, loss_test:0.03074, lr:1.36e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.158, tt:6785.451\n",
      "Ep:193, loss:0.00000, loss_test:0.03082, lr:1.34e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.161, tt:6821.291\n",
      "Ep:194, loss:0.00000, loss_test:0.03082, lr:1.33e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.168, tt:6857.835\n",
      "Ep:195, loss:0.00000, loss_test:0.03084, lr:1.32e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.172, tt:6893.798\n",
      "Ep:196, loss:0.00000, loss_test:0.03092, lr:1.30e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.172, tt:6928.801\n",
      "Ep:197, loss:0.00000, loss_test:0.03091, lr:1.29e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.172, tt:6963.977\n",
      "Ep:198, loss:0.00000, loss_test:0.03093, lr:1.28e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.161, tt:6997.091\n",
      "Ep:199, loss:0.00000, loss_test:0.03100, lr:1.26e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.136, tt:7027.296\n",
      "Ep:200, loss:0.00000, loss_test:0.03099, lr:1.25e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.112, tt:7057.564\n",
      "Ep:201, loss:0.00000, loss_test:0.03102, lr:1.24e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.102, tt:7090.587\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13158, lr:1.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:30.086, tt:30.086\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13026, lr:1.00e-02, fs:0.70412 (r=0.949,p=0.560),  time:31.630, tt:63.260\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12938, lr:1.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:33.246, tt:99.738\n",
      "Ep:3, loss:0.00026, loss_test:0.12919, lr:1.00e-02, fs:0.69630 (r=0.949,p=0.550),  time:34.418, tt:137.671\n",
      "Ep:4, loss:0.00026, loss_test:0.12938, lr:1.00e-02, fs:0.69630 (r=0.949,p=0.550),  time:35.161, tt:175.806\n",
      "Ep:5, loss:0.00026, loss_test:0.12947, lr:1.00e-02, fs:0.69145 (r=0.939,p=0.547),  time:35.294, tt:211.761\n",
      "Ep:6, loss:0.00026, loss_test:0.12927, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:35.533, tt:248.733\n",
      "Ep:7, loss:0.00026, loss_test:0.12896, lr:1.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:35.588, tt:284.708\n",
      "Ep:8, loss:0.00026, loss_test:0.12831, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:35.487, tt:319.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00025, loss_test:0.12751, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.646, tt:356.457\n",
      "Ep:10, loss:0.00025, loss_test:0.12684, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.639, tt:392.033\n",
      "Ep:11, loss:0.00025, loss_test:0.12628, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.791, tt:429.495\n",
      "Ep:12, loss:0.00025, loss_test:0.12572, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:35.939, tt:467.207\n",
      "Ep:13, loss:0.00025, loss_test:0.12516, lr:9.90e-03, fs:0.69498 (r=0.909,p=0.562),  time:36.169, tt:506.369\n",
      "Ep:14, loss:0.00025, loss_test:0.12456, lr:9.80e-03, fs:0.69498 (r=0.909,p=0.562),  time:36.197, tt:542.957\n",
      "Ep:15, loss:0.00025, loss_test:0.12374, lr:9.70e-03, fs:0.69498 (r=0.909,p=0.562),  time:36.218, tt:579.491\n",
      "Ep:16, loss:0.00024, loss_test:0.12307, lr:9.61e-03, fs:0.69498 (r=0.909,p=0.562),  time:36.241, tt:616.089\n",
      "Ep:17, loss:0.00024, loss_test:0.12218, lr:9.51e-03, fs:0.67969 (r=0.879,p=0.554),  time:36.240, tt:652.314\n",
      "Ep:18, loss:0.00024, loss_test:0.12150, lr:9.41e-03, fs:0.68235 (r=0.879,p=0.558),  time:36.273, tt:689.178\n",
      "Ep:19, loss:0.00024, loss_test:0.12096, lr:9.32e-03, fs:0.69261 (r=0.899,p=0.563),  time:36.254, tt:725.082\n",
      "Ep:20, loss:0.00024, loss_test:0.12018, lr:9.23e-03, fs:0.69531 (r=0.899,p=0.567),  time:36.247, tt:761.193\n",
      "Ep:21, loss:0.00024, loss_test:0.11941, lr:9.14e-03, fs:0.70039 (r=0.909,p=0.570),  time:36.228, tt:797.009\n",
      "Ep:22, loss:0.00023, loss_test:0.11859, lr:9.04e-03, fs:0.70769 (r=0.929,p=0.571),  time:36.186, tt:832.288\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00023, loss_test:0.11764, lr:9.04e-03, fs:0.71264 (r=0.939,p=0.574),  time:36.172, tt:868.139\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00023, loss_test:0.11642, lr:9.04e-03, fs:0.71538 (r=0.939,p=0.578),  time:36.199, tt:904.982\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00023, loss_test:0.11511, lr:9.04e-03, fs:0.72093 (r=0.939,p=0.585),  time:36.192, tt:940.990\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00022, loss_test:0.11286, lr:9.04e-03, fs:0.71595 (r=0.929,p=0.582),  time:36.209, tt:977.646\n",
      "Ep:27, loss:0.00022, loss_test:0.11154, lr:9.04e-03, fs:0.72374 (r=0.939,p=0.589),  time:36.197, tt:1013.519\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00022, loss_test:0.10992, lr:9.04e-03, fs:0.72374 (r=0.939,p=0.589),  time:36.197, tt:1049.704\n",
      "Ep:29, loss:0.00021, loss_test:0.10709, lr:9.04e-03, fs:0.72941 (r=0.939,p=0.596),  time:36.177, tt:1085.298\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00021, loss_test:0.10480, lr:9.04e-03, fs:0.72441 (r=0.929,p=0.594),  time:36.153, tt:1120.742\n",
      "Ep:31, loss:0.00020, loss_test:0.10447, lr:9.04e-03, fs:0.72308 (r=0.949,p=0.584),  time:36.199, tt:1158.365\n",
      "Ep:32, loss:0.00020, loss_test:0.10108, lr:9.04e-03, fs:0.73725 (r=0.949,p=0.603),  time:36.213, tt:1195.026\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00019, loss_test:0.09927, lr:9.04e-03, fs:0.74194 (r=0.929,p=0.617),  time:36.208, tt:1231.082\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00018, loss_test:0.10089, lr:9.04e-03, fs:0.75591 (r=0.970,p=0.619),  time:36.159, tt:1265.562\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00018, loss_test:0.09480, lr:9.04e-03, fs:0.75833 (r=0.919,p=0.645),  time:36.195, tt:1303.027\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00017, loss_test:0.09783, lr:9.04e-03, fs:0.75397 (r=0.960,p=0.621),  time:36.161, tt:1337.955\n",
      "Ep:37, loss:0.00017, loss_test:0.09216, lr:9.04e-03, fs:0.76793 (r=0.919,p=0.659),  time:36.170, tt:1374.456\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00016, loss_test:0.09066, lr:9.04e-03, fs:0.77311 (r=0.929,p=0.662),  time:36.142, tt:1409.527\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00016, loss_test:0.09055, lr:9.04e-03, fs:0.76543 (r=0.939,p=0.646),  time:36.160, tt:1446.395\n",
      "Ep:40, loss:0.00015, loss_test:0.08614, lr:9.04e-03, fs:0.76987 (r=0.929,p=0.657),  time:36.139, tt:1481.686\n",
      "Ep:41, loss:0.00015, loss_test:0.08619, lr:9.04e-03, fs:0.76151 (r=0.919,p=0.650),  time:36.158, tt:1518.626\n",
      "Ep:42, loss:0.00014, loss_test:0.08551, lr:9.04e-03, fs:0.77178 (r=0.939,p=0.655),  time:36.171, tt:1555.346\n",
      "Ep:43, loss:0.00014, loss_test:0.08190, lr:9.04e-03, fs:0.77637 (r=0.929,p=0.667),  time:36.178, tt:1591.817\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00013, loss_test:0.07874, lr:9.04e-03, fs:0.81279 (r=0.899,p=0.742),  time:36.173, tt:1627.777\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00013, loss_test:0.08934, lr:9.04e-03, fs:0.77600 (r=0.980,p=0.642),  time:36.172, tt:1663.893\n",
      "Ep:46, loss:0.00013, loss_test:0.07405, lr:9.04e-03, fs:0.82243 (r=0.889,p=0.765),  time:36.175, tt:1700.233\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00012, loss_test:0.08306, lr:9.04e-03, fs:0.80000 (r=0.990,p=0.671),  time:36.191, tt:1737.188\n",
      "Ep:48, loss:0.00011, loss_test:0.07293, lr:9.04e-03, fs:0.84507 (r=0.909,p=0.789),  time:36.164, tt:1772.032\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00011, loss_test:0.07451, lr:9.04e-03, fs:0.81416 (r=0.929,p=0.724),  time:36.152, tt:1807.592\n",
      "Ep:50, loss:0.00010, loss_test:0.06706, lr:9.04e-03, fs:0.87923 (r=0.919,p=0.843),  time:36.155, tt:1843.885\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.06673, lr:9.04e-03, fs:0.85981 (r=0.929,p=0.800),  time:36.160, tt:1880.303\n",
      "Ep:52, loss:0.00009, loss_test:0.06628, lr:9.04e-03, fs:0.87923 (r=0.919,p=0.843),  time:36.149, tt:1915.890\n",
      "Ep:53, loss:0.00008, loss_test:0.06456, lr:9.04e-03, fs:0.88462 (r=0.929,p=0.844),  time:36.128, tt:1950.898\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.06396, lr:9.04e-03, fs:0.88152 (r=0.939,p=0.830),  time:36.102, tt:1985.604\n",
      "Ep:55, loss:0.00007, loss_test:0.06342, lr:9.04e-03, fs:0.88119 (r=0.899,p=0.864),  time:36.071, tt:2019.960\n",
      "Ep:56, loss:0.00007, loss_test:0.06401, lr:9.04e-03, fs:0.87379 (r=0.909,p=0.841),  time:36.076, tt:2056.338\n",
      "Ep:57, loss:0.00007, loss_test:0.06212, lr:9.04e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.062, tt:2091.613\n",
      "Ep:58, loss:0.00006, loss_test:0.06212, lr:9.04e-03, fs:0.89756 (r=0.929,p=0.868),  time:36.081, tt:2128.803\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.06231, lr:9.04e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.070, tt:2164.187\n",
      "Ep:60, loss:0.00006, loss_test:0.06069, lr:9.04e-03, fs:0.89756 (r=0.929,p=0.868),  time:36.082, tt:2200.977\n",
      "Ep:61, loss:0.00006, loss_test:0.06118, lr:9.04e-03, fs:0.87129 (r=0.889,p=0.854),  time:36.083, tt:2237.162\n",
      "Ep:62, loss:0.00005, loss_test:0.06778, lr:9.04e-03, fs:0.84817 (r=0.818,p=0.880),  time:36.086, tt:2273.434\n",
      "Ep:63, loss:0.00005, loss_test:0.06238, lr:9.04e-03, fs:0.86700 (r=0.889,p=0.846),  time:36.075, tt:2308.810\n",
      "Ep:64, loss:0.00006, loss_test:0.05980, lr:9.04e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.071, tt:2344.591\n",
      "Ep:65, loss:0.00005, loss_test:0.06499, lr:9.04e-03, fs:0.85714 (r=0.848,p=0.866),  time:36.063, tt:2380.154\n",
      "Ep:66, loss:0.00005, loss_test:0.06538, lr:9.04e-03, fs:0.85427 (r=0.859,p=0.850),  time:36.054, tt:2415.643\n",
      "Ep:67, loss:0.00005, loss_test:0.06843, lr:9.04e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.052, tt:2451.548\n",
      "Ep:68, loss:0.00005, loss_test:0.06386, lr:9.04e-03, fs:0.84536 (r=0.828,p=0.863),  time:36.025, tt:2485.739\n",
      "Ep:69, loss:0.00004, loss_test:0.06504, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.026, tt:2521.815\n",
      "Ep:70, loss:0.00004, loss_test:0.06315, lr:8.95e-03, fs:0.85714 (r=0.818,p=0.900),  time:36.010, tt:2556.697\n",
      "Ep:71, loss:0.00004, loss_test:0.06426, lr:8.86e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.010, tt:2592.752\n",
      "Ep:72, loss:0.00003, loss_test:0.06856, lr:8.78e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.008, tt:2628.580\n",
      "Ep:73, loss:0.00003, loss_test:0.06057, lr:8.69e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.001, tt:2664.072\n",
      "Ep:74, loss:0.00003, loss_test:0.06835, lr:8.60e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.995, tt:2699.630\n",
      "Ep:75, loss:0.00003, loss_test:0.06990, lr:8.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.992, tt:2735.387\n",
      "Ep:76, loss:0.00003, loss_test:0.06507, lr:8.43e-03, fs:0.85263 (r=0.818,p=0.890),  time:35.979, tt:2770.353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00003, loss_test:0.06897, lr:8.35e-03, fs:0.85561 (r=0.808,p=0.909),  time:35.960, tt:2804.908\n",
      "Ep:78, loss:0.00002, loss_test:0.06699, lr:8.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:35.972, tt:2841.788\n",
      "Ep:79, loss:0.00002, loss_test:0.06870, lr:8.18e-03, fs:0.85561 (r=0.808,p=0.909),  time:35.959, tt:2876.680\n",
      "Ep:80, loss:0.00002, loss_test:0.05856, lr:8.10e-03, fs:0.87368 (r=0.838,p=0.912),  time:35.957, tt:2912.529\n",
      "Ep:81, loss:0.00002, loss_test:0.06933, lr:8.02e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.952, tt:2948.087\n",
      "Ep:82, loss:0.00002, loss_test:0.06564, lr:7.94e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.943, tt:2983.259\n",
      "Ep:83, loss:0.00002, loss_test:0.06743, lr:7.86e-03, fs:0.85561 (r=0.808,p=0.909),  time:35.939, tt:3018.892\n",
      "Ep:84, loss:0.00002, loss_test:0.06403, lr:7.78e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.944, tt:3055.269\n",
      "Ep:85, loss:0.00002, loss_test:0.06988, lr:7.70e-03, fs:0.80682 (r=0.717,p=0.922),  time:35.956, tt:3092.213\n",
      "Ep:86, loss:0.00002, loss_test:0.06286, lr:7.62e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.946, tt:3127.330\n",
      "Ep:87, loss:0.00002, loss_test:0.06667, lr:7.55e-03, fs:0.86957 (r=0.808,p=0.941),  time:35.942, tt:3162.929\n",
      "Ep:88, loss:0.00002, loss_test:0.06150, lr:7.47e-03, fs:0.87097 (r=0.818,p=0.931),  time:35.930, tt:3197.745\n",
      "Ep:89, loss:0.00002, loss_test:0.07608, lr:7.40e-03, fs:0.79532 (r=0.687,p=0.944),  time:35.937, tt:3234.286\n",
      "Ep:90, loss:0.00002, loss_test:0.06349, lr:7.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:35.947, tt:3271.174\n",
      "Ep:91, loss:0.00002, loss_test:0.06770, lr:7.25e-03, fs:0.86486 (r=0.808,p=0.930),  time:35.971, tt:3309.340\n",
      "Ep:92, loss:0.00001, loss_test:0.06943, lr:7.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:36.004, tt:3348.351\n",
      "Ep:93, loss:0.00001, loss_test:0.07143, lr:7.11e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.023, tt:3386.187\n",
      "Ep:94, loss:0.00001, loss_test:0.06722, lr:7.03e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.042, tt:3423.981\n",
      "Ep:95, loss:0.00001, loss_test:0.06636, lr:6.96e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.041, tt:3459.935\n",
      "Ep:96, loss:0.00001, loss_test:0.07079, lr:6.89e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.031, tt:3494.979\n",
      "Ep:97, loss:0.00001, loss_test:0.06921, lr:6.83e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.037, tt:3531.623\n",
      "Ep:98, loss:0.00001, loss_test:0.06925, lr:6.76e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.055, tt:3569.482\n",
      "Ep:99, loss:0.00001, loss_test:0.06818, lr:6.69e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.094, tt:3609.396\n",
      "Ep:100, loss:0.00001, loss_test:0.07092, lr:6.62e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.113, tt:3647.427\n",
      "Ep:101, loss:0.00001, loss_test:0.06785, lr:6.56e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.140, tt:3686.251\n",
      "Ep:102, loss:0.00001, loss_test:0.07055, lr:6.49e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.154, tt:3723.883\n",
      "Ep:103, loss:0.00001, loss_test:0.06855, lr:6.43e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.170, tt:3761.649\n",
      "Ep:104, loss:0.00001, loss_test:0.07162, lr:6.36e-03, fs:0.87432 (r=0.808,p=0.952),  time:36.191, tt:3800.056\n",
      "Ep:105, loss:0.00001, loss_test:0.06840, lr:6.30e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.196, tt:3836.752\n",
      "Ep:106, loss:0.00001, loss_test:0.07301, lr:6.24e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.197, tt:3873.045\n",
      "Ep:107, loss:0.00001, loss_test:0.06933, lr:6.17e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.191, tt:3908.582\n",
      "Ep:108, loss:0.00001, loss_test:0.07405, lr:6.11e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.178, tt:3943.383\n",
      "Ep:109, loss:0.00001, loss_test:0.07273, lr:6.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.163, tt:3977.959\n",
      "Ep:110, loss:0.00001, loss_test:0.07341, lr:5.99e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.152, tt:4012.887\n",
      "Ep:111, loss:0.00001, loss_test:0.07389, lr:5.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.149, tt:4048.669\n",
      "Ep:112, loss:0.00001, loss_test:0.07176, lr:5.87e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.140, tt:4083.871\n",
      "Ep:113, loss:0.00001, loss_test:0.07370, lr:5.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.126, tt:4118.349\n",
      "Ep:114, loss:0.00001, loss_test:0.07225, lr:5.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.110, tt:4152.705\n",
      "Ep:115, loss:0.00001, loss_test:0.07474, lr:5.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.093, tt:4186.732\n",
      "Ep:116, loss:0.00001, loss_test:0.07391, lr:5.64e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.099, tt:4223.532\n",
      "Ep:117, loss:0.00001, loss_test:0.07460, lr:5.58e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.086, tt:4258.155\n",
      "Ep:118, loss:0.00001, loss_test:0.07515, lr:5.53e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.081, tt:4293.691\n",
      "Ep:119, loss:0.00001, loss_test:0.07419, lr:5.47e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.072, tt:4328.601\n",
      "Ep:120, loss:0.00001, loss_test:0.07820, lr:5.42e-03, fs:0.86339 (r=0.798,p=0.940),  time:36.048, tt:4361.784\n",
      "Ep:121, loss:0.00001, loss_test:0.07456, lr:5.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.048, tt:4397.848\n",
      "Ep:122, loss:0.00001, loss_test:0.07640, lr:5.31e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.040, tt:4432.919\n",
      "Ep:123, loss:0.00001, loss_test:0.07525, lr:5.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:36.034, tt:4468.243\n",
      "Ep:124, loss:0.00001, loss_test:0.07678, lr:5.20e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.021, tt:4502.649\n",
      "Ep:125, loss:0.00001, loss_test:0.07733, lr:5.15e-03, fs:0.86813 (r=0.798,p=0.952),  time:36.021, tt:4538.595\n",
      "Ep:126, loss:0.00001, loss_test:0.07687, lr:5.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:36.011, tt:4573.459\n",
      "Ep:127, loss:0.00001, loss_test:0.07712, lr:5.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.015, tt:4609.955\n",
      "Ep:128, loss:0.00001, loss_test:0.07947, lr:5.00e-03, fs:0.86188 (r=0.788,p=0.951),  time:36.014, tt:4645.768\n",
      "Ep:129, loss:0.00001, loss_test:0.07811, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:36.008, tt:4680.991\n",
      "Ep:130, loss:0.00001, loss_test:0.07755, lr:4.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.999, tt:4715.807\n",
      "Ep:131, loss:0.00001, loss_test:0.07829, lr:4.85e-03, fs:0.86813 (r=0.798,p=0.952),  time:35.994, tt:4751.244\n",
      "Ep:132, loss:0.00001, loss_test:0.07720, lr:4.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.995, tt:4787.373\n",
      "Ep:133, loss:0.00001, loss_test:0.07896, lr:4.75e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.988, tt:4822.448\n",
      "Ep:134, loss:0.00001, loss_test:0.07808, lr:4.71e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.984, tt:4857.893\n",
      "Ep:135, loss:0.00001, loss_test:0.07912, lr:4.66e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.983, tt:4893.709\n",
      "Ep:136, loss:0.00001, loss_test:0.07936, lr:4.61e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.971, tt:4928.084\n",
      "Ep:137, loss:0.00001, loss_test:0.07881, lr:4.57e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.966, tt:4963.288\n",
      "Ep:138, loss:0.00001, loss_test:0.07955, lr:4.52e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.961, tt:4998.564\n",
      "Ep:139, loss:0.00001, loss_test:0.08055, lr:4.48e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.950, tt:5032.959\n",
      "Ep:140, loss:0.00001, loss_test:0.07951, lr:4.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:35.931, tt:5066.202\n",
      "Ep:141, loss:0.00001, loss_test:0.07978, lr:4.39e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.915, tt:5099.938\n",
      "Ep:142, loss:0.00001, loss_test:0.08033, lr:4.34e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.908, tt:5134.786\n",
      "Ep:143, loss:0.00001, loss_test:0.08085, lr:4.30e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.900, tt:5169.607\n",
      "Ep:144, loss:0.00001, loss_test:0.08024, lr:4.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:35.886, tt:5203.515\n",
      "Ep:145, loss:0.00001, loss_test:0.08067, lr:4.21e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.870, tt:5237.066\n",
      "Ep:146, loss:0.00001, loss_test:0.08176, lr:4.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.867, tt:5272.410\n",
      "Ep:147, loss:0.00001, loss_test:0.08168, lr:4.13e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.856, tt:5306.671\n",
      "Ep:148, loss:0.00001, loss_test:0.08198, lr:4.09e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.844, tt:5340.743\n",
      "Ep:149, loss:0.00001, loss_test:0.08129, lr:4.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.836, tt:5375.418\n",
      "Ep:152, loss:0.00001, loss_test:0.08250, lr:3.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.815, tt:5479.666\n",
      "Ep:153, loss:0.00001, loss_test:0.08232, lr:3.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.795, tt:5512.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00001, loss_test:0.08222, lr:3.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.785, tt:5546.733\n",
      "Ep:155, loss:0.00001, loss_test:0.08312, lr:3.81e-03, fs:0.84270 (r=0.758,p=0.949),  time:35.784, tt:5582.281\n",
      "Ep:156, loss:0.00001, loss_test:0.08083, lr:3.77e-03, fs:0.86813 (r=0.798,p=0.952),  time:35.777, tt:5617.041\n",
      "Ep:157, loss:0.00001, loss_test:0.08233, lr:3.73e-03, fs:0.86813 (r=0.798,p=0.952),  time:35.801, tt:5656.589\n",
      "Ep:158, loss:0.00001, loss_test:0.08208, lr:3.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.796, tt:5691.594\n",
      "Ep:159, loss:0.00001, loss_test:0.08221, lr:3.66e-03, fs:0.86813 (r=0.798,p=0.952),  time:35.792, tt:5726.718\n",
      "Ep:160, loss:0.00001, loss_test:0.08263, lr:3.62e-03, fs:0.86813 (r=0.798,p=0.952),  time:35.792, tt:5762.479\n",
      "Ep:161, loss:0.00001, loss_test:0.08260, lr:3.59e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.787, tt:5797.514\n",
      "Ep:162, loss:0.00000, loss_test:0.08358, lr:3.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.780, tt:5832.210\n",
      "Ep:163, loss:0.00000, loss_test:0.08249, lr:3.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.764, tt:5865.264\n",
      "Ep:164, loss:0.00000, loss_test:0.08309, lr:3.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.762, tt:5900.755\n",
      "Ep:165, loss:0.00000, loss_test:0.08442, lr:3.45e-03, fs:0.77381 (r=0.657,p=0.942),  time:35.760, tt:5936.171\n",
      "Ep:166, loss:0.00000, loss_test:0.08259, lr:3.41e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.757, tt:5971.486\n",
      "Ep:167, loss:0.00000, loss_test:0.08487, lr:3.38e-03, fs:0.84270 (r=0.758,p=0.949),  time:35.756, tt:6007.088\n",
      "Ep:168, loss:0.00000, loss_test:0.08381, lr:3.34e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.752, tt:6042.044\n",
      "Ep:169, loss:0.00000, loss_test:0.08508, lr:3.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.752, tt:6077.859\n",
      "Ep:170, loss:0.00000, loss_test:0.08320, lr:3.28e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.757, tt:6114.424\n",
      "Ep:171, loss:0.00000, loss_test:0.08282, lr:3.24e-03, fs:0.87912 (r=0.808,p=0.964),  time:35.756, tt:6150.114\n",
      "Ep:172, loss:0.00000, loss_test:0.08438, lr:3.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.752, tt:6185.096\n",
      "Ep:173, loss:0.00000, loss_test:0.08258, lr:3.18e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.736, tt:6218.123\n",
      "Ep:174, loss:0.00000, loss_test:0.08602, lr:3.15e-03, fs:0.74847 (r=0.616,p=0.953),  time:35.725, tt:6251.917\n",
      "Ep:175, loss:0.00000, loss_test:0.08526, lr:3.12e-03, fs:0.76364 (r=0.636,p=0.955),  time:35.722, tt:6287.051\n",
      "Ep:176, loss:0.00000, loss_test:0.08433, lr:3.09e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.721, tt:6322.702\n",
      "Ep:177, loss:0.00000, loss_test:0.08672, lr:3.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:35.718, tt:6357.758\n",
      "Ep:178, loss:0.00000, loss_test:0.08485, lr:3.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.719, tt:6393.745\n",
      "Ep:179, loss:0.00000, loss_test:0.08480, lr:2.99e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.716, tt:6428.939\n",
      "Ep:180, loss:0.00000, loss_test:0.08662, lr:2.96e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.707, tt:6462.952\n",
      "Ep:181, loss:0.00000, loss_test:0.08343, lr:2.93e-03, fs:0.87293 (r=0.798,p=0.963),  time:35.724, tt:6501.783\n",
      "Ep:182, loss:0.00000, loss_test:0.08744, lr:2.90e-03, fs:0.74074 (r=0.606,p=0.952),  time:35.726, tt:6537.845\n",
      "Ep:183, loss:0.00000, loss_test:0.08523, lr:2.88e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.724, tt:6573.216\n",
      "Ep:184, loss:0.00000, loss_test:0.08580, lr:2.85e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.726, tt:6609.282\n",
      "Ep:185, loss:0.00000, loss_test:0.08738, lr:2.82e-03, fs:0.82081 (r=0.717,p=0.959),  time:35.719, tt:6643.759\n",
      "Ep:186, loss:0.00000, loss_test:0.08663, lr:2.79e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.712, tt:6678.165\n",
      "Ep:187, loss:0.00000, loss_test:0.08691, lr:2.76e-03, fs:0.82081 (r=0.717,p=0.959),  time:35.713, tt:6714.096\n",
      "Ep:188, loss:0.00000, loss_test:0.08624, lr:2.73e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.708, tt:6748.904\n",
      "Ep:189, loss:0.00000, loss_test:0.08699, lr:2.71e-03, fs:0.80702 (r=0.697,p=0.958),  time:35.711, tt:6785.170\n",
      "Ep:190, loss:0.00000, loss_test:0.08508, lr:2.68e-03, fs:0.84746 (r=0.758,p=0.962),  time:35.703, tt:6819.254\n",
      "Ep:191, loss:0.00000, loss_test:0.08690, lr:2.65e-03, fs:0.82081 (r=0.717,p=0.959),  time:35.701, tt:6854.595\n",
      "Ep:192, loss:0.00000, loss_test:0.08710, lr:2.63e-03, fs:0.80000 (r=0.687,p=0.958),  time:35.699, tt:6890.000\n",
      "Ep:193, loss:0.00000, loss_test:0.08601, lr:2.60e-03, fs:0.83908 (r=0.737,p=0.973),  time:35.701, tt:6925.984\n",
      "Ep:194, loss:0.00000, loss_test:0.08666, lr:2.57e-03, fs:0.83429 (r=0.737,p=0.961),  time:35.697, tt:6960.970\n",
      "Ep:195, loss:0.00000, loss_test:0.08724, lr:2.55e-03, fs:0.80000 (r=0.687,p=0.958),  time:35.687, tt:6994.738\n",
      "Ep:196, loss:0.00000, loss_test:0.08611, lr:2.52e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.681, tt:7029.069\n",
      "Ep:197, loss:0.00000, loss_test:0.08663, lr:2.50e-03, fs:0.81871 (r=0.707,p=0.972),  time:35.670, tt:7062.622\n",
      "Ep:198, loss:0.00000, loss_test:0.08753, lr:2.47e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.655, tt:7095.441\n",
      "Ep:199, loss:0.00000, loss_test:0.08690, lr:2.45e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.628, tt:7125.605\n",
      "Ep:200, loss:0.00000, loss_test:0.08655, lr:2.42e-03, fs:0.83908 (r=0.737,p=0.973),  time:35.580, tt:7151.552\n",
      "Ep:201, loss:0.00000, loss_test:0.08768, lr:2.40e-03, fs:0.73750 (r=0.596,p=0.967),  time:35.539, tt:7178.971\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02770, lr:6.00e-02, fs:0.63436 (r=0.727,p=0.562),  time:22.285, tt:22.285\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02423, lr:6.00e-02, fs:0.68116 (r=0.949,p=0.531),  time:24.320, tt:48.641\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02531, lr:6.00e-02, fs:0.68327 (r=0.970,p=0.527),  time:26.239, tt:78.716\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02519, lr:6.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:27.446, tt:109.785\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02547, lr:6.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:28.122, tt:140.611\n",
      "Ep:5, loss:0.00005, loss_test:0.02531, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:28.513, tt:171.076\n",
      "Ep:6, loss:0.00005, loss_test:0.02492, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:28.892, tt:202.241\n",
      "Ep:7, loss:0.00005, loss_test:0.02445, lr:6.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:29.031, tt:232.248\n",
      "Ep:8, loss:0.00005, loss_test:0.02387, lr:6.00e-02, fs:0.68116 (r=0.949,p=0.531),  time:29.053, tt:261.475\n",
      "Ep:9, loss:0.00004, loss_test:0.02331, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:29.208, tt:292.082\n",
      "Ep:10, loss:0.00004, loss_test:0.02281, lr:6.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:29.217, tt:321.384\n",
      "Ep:11, loss:0.00004, loss_test:0.02234, lr:6.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:29.361, tt:352.331\n",
      "Ep:12, loss:0.00004, loss_test:0.02199, lr:6.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:29.485, tt:383.311\n",
      "Ep:13, loss:0.00004, loss_test:0.02177, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:29.467, tt:412.535\n",
      "Ep:14, loss:0.00004, loss_test:0.02153, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:29.562, tt:443.431\n",
      "Ep:15, loss:0.00004, loss_test:0.02117, lr:5.94e-02, fs:0.67407 (r=0.919,p=0.532),  time:29.656, tt:474.504\n",
      "Ep:16, loss:0.00004, loss_test:0.02077, lr:5.88e-02, fs:0.68679 (r=0.919,p=0.548),  time:29.669, tt:504.379\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02046, lr:5.88e-02, fs:0.68679 (r=0.919,p=0.548),  time:29.695, tt:534.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00004, loss_test:0.02038, lr:5.88e-02, fs:0.68401 (r=0.929,p=0.541),  time:29.712, tt:564.535\n",
      "Ep:19, loss:0.00004, loss_test:0.02015, lr:5.88e-02, fs:0.68889 (r=0.939,p=0.544),  time:29.733, tt:594.651\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01976, lr:5.88e-02, fs:0.69697 (r=0.929,p=0.558),  time:29.710, tt:623.920\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01937, lr:5.88e-02, fs:0.70189 (r=0.939,p=0.560),  time:29.724, tt:653.919\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01914, lr:5.88e-02, fs:0.70412 (r=0.949,p=0.560),  time:29.729, tt:683.777\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01886, lr:5.88e-02, fs:0.70896 (r=0.960,p=0.562),  time:29.743, tt:713.833\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01853, lr:5.88e-02, fs:0.70943 (r=0.949,p=0.566),  time:29.751, tt:743.787\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01810, lr:5.88e-02, fs:0.71538 (r=0.939,p=0.578),  time:29.738, tt:773.191\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01786, lr:5.88e-02, fs:0.72243 (r=0.960,p=0.579),  time:29.758, tt:803.476\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01751, lr:5.88e-02, fs:0.71970 (r=0.960,p=0.576),  time:29.798, tt:834.352\n",
      "Ep:28, loss:0.00003, loss_test:0.01716, lr:5.88e-02, fs:0.72519 (r=0.960,p=0.583),  time:29.821, tt:864.814\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01689, lr:5.88e-02, fs:0.73563 (r=0.970,p=0.593),  time:29.838, tt:895.134\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01669, lr:5.88e-02, fs:0.75000 (r=0.970,p=0.611),  time:29.902, tt:926.956\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01653, lr:5.88e-02, fs:0.75294 (r=0.970,p=0.615),  time:29.969, tt:959.021\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01638, lr:5.88e-02, fs:0.75889 (r=0.970,p=0.623),  time:29.975, tt:989.166\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01622, lr:5.88e-02, fs:0.76190 (r=0.970,p=0.627),  time:30.047, tt:1021.604\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01613, lr:5.88e-02, fs:0.74590 (r=0.919,p=0.628),  time:30.087, tt:1053.061\n",
      "Ep:35, loss:0.00002, loss_test:0.01598, lr:5.88e-02, fs:0.75000 (r=0.909,p=0.638),  time:30.110, tt:1083.947\n",
      "Ep:36, loss:0.00002, loss_test:0.01598, lr:5.88e-02, fs:0.73950 (r=0.889,p=0.633),  time:30.105, tt:1113.878\n",
      "Ep:37, loss:0.00002, loss_test:0.01597, lr:5.88e-02, fs:0.73276 (r=0.859,p=0.639),  time:30.120, tt:1144.546\n",
      "Ep:38, loss:0.00002, loss_test:0.01599, lr:5.88e-02, fs:0.74236 (r=0.859,p=0.654),  time:30.123, tt:1174.794\n",
      "Ep:39, loss:0.00002, loss_test:0.01588, lr:5.88e-02, fs:0.74561 (r=0.859,p=0.659),  time:30.122, tt:1204.877\n",
      "Ep:40, loss:0.00002, loss_test:0.01576, lr:5.88e-02, fs:0.74107 (r=0.838,p=0.664),  time:30.205, tt:1238.414\n",
      "Ep:41, loss:0.00002, loss_test:0.01591, lr:5.88e-02, fs:0.73303 (r=0.818,p=0.664),  time:30.197, tt:1268.264\n",
      "Ep:42, loss:0.00002, loss_test:0.01643, lr:5.88e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.192, tt:1298.267\n",
      "Ep:43, loss:0.00002, loss_test:0.01631, lr:5.88e-02, fs:0.70755 (r=0.758,p=0.664),  time:30.192, tt:1328.429\n",
      "Ep:44, loss:0.00002, loss_test:0.01709, lr:5.88e-02, fs:0.69697 (r=0.697,p=0.697),  time:30.194, tt:1358.722\n",
      "Ep:45, loss:0.00002, loss_test:0.01700, lr:5.82e-02, fs:0.68657 (r=0.697,p=0.676),  time:30.204, tt:1389.384\n",
      "Ep:46, loss:0.00002, loss_test:0.01760, lr:5.76e-02, fs:0.69036 (r=0.687,p=0.694),  time:30.200, tt:1419.422\n",
      "Ep:47, loss:0.00001, loss_test:0.01809, lr:5.71e-02, fs:0.70466 (r=0.687,p=0.723),  time:30.212, tt:1450.167\n",
      "Ep:48, loss:0.00001, loss_test:0.01764, lr:5.65e-02, fs:0.69072 (r=0.677,p=0.705),  time:30.258, tt:1482.661\n",
      "Ep:49, loss:0.00001, loss_test:0.01924, lr:5.59e-02, fs:0.68783 (r=0.657,p=0.722),  time:30.241, tt:1512.074\n",
      "Ep:50, loss:0.00001, loss_test:0.02052, lr:5.54e-02, fs:0.67027 (r=0.626,p=0.721),  time:30.262, tt:1543.386\n",
      "Ep:51, loss:0.00001, loss_test:0.01935, lr:5.48e-02, fs:0.68085 (r=0.646,p=0.719),  time:30.267, tt:1573.896\n",
      "Ep:52, loss:0.00001, loss_test:0.02031, lr:5.43e-02, fs:0.67391 (r=0.626,p=0.729),  time:30.260, tt:1603.791\n",
      "Ep:53, loss:0.00001, loss_test:0.02301, lr:5.37e-02, fs:0.67760 (r=0.626,p=0.738),  time:30.251, tt:1633.553\n",
      "Ep:54, loss:0.00001, loss_test:0.02196, lr:5.32e-02, fs:0.68889 (r=0.626,p=0.765),  time:30.226, tt:1662.413\n",
      "Ep:55, loss:0.00001, loss_test:0.02155, lr:5.27e-02, fs:0.68132 (r=0.626,p=0.747),  time:30.232, tt:1693.005\n",
      "Ep:56, loss:0.00001, loss_test:0.02738, lr:5.21e-02, fs:0.68539 (r=0.616,p=0.772),  time:30.249, tt:1724.169\n",
      "Ep:57, loss:0.00001, loss_test:0.02421, lr:5.16e-02, fs:0.69274 (r=0.626,p=0.775),  time:30.234, tt:1753.582\n",
      "Ep:58, loss:0.00001, loss_test:0.01955, lr:5.11e-02, fs:0.69110 (r=0.667,p=0.717),  time:30.245, tt:1784.483\n",
      "Ep:59, loss:0.00001, loss_test:0.03210, lr:5.06e-02, fs:0.67416 (r=0.606,p=0.759),  time:30.242, tt:1814.527\n",
      "Ep:60, loss:0.00001, loss_test:0.02013, lr:5.01e-02, fs:0.67742 (r=0.636,p=0.724),  time:30.241, tt:1844.695\n",
      "Ep:61, loss:0.00001, loss_test:0.03097, lr:4.96e-02, fs:0.67778 (r=0.616,p=0.753),  time:30.215, tt:1873.318\n",
      "Ep:62, loss:0.00001, loss_test:0.02121, lr:4.91e-02, fs:0.67760 (r=0.626,p=0.738),  time:30.216, tt:1903.579\n",
      "Ep:63, loss:0.00001, loss_test:0.03209, lr:4.86e-02, fs:0.67033 (r=0.616,p=0.735),  time:30.222, tt:1934.235\n",
      "Ep:64, loss:0.00001, loss_test:0.02280, lr:4.81e-02, fs:0.68889 (r=0.626,p=0.765),  time:30.225, tt:1964.609\n",
      "Ep:65, loss:0.00001, loss_test:0.03174, lr:4.76e-02, fs:0.70056 (r=0.626,p=0.795),  time:30.247, tt:1996.296\n",
      "Ep:66, loss:0.00001, loss_test:0.02565, lr:4.71e-02, fs:0.69663 (r=0.626,p=0.785),  time:30.236, tt:2025.808\n",
      "Ep:67, loss:0.00001, loss_test:0.03273, lr:4.67e-02, fs:0.69318 (r=0.616,p=0.792),  time:30.206, tt:2054.013\n",
      "Ep:68, loss:0.00001, loss_test:0.02755, lr:4.62e-02, fs:0.70056 (r=0.626,p=0.795),  time:30.211, tt:2084.545\n",
      "Ep:69, loss:0.00001, loss_test:0.03456, lr:4.57e-02, fs:0.70857 (r=0.626,p=0.816),  time:30.217, tt:2115.179\n",
      "Ep:70, loss:0.00001, loss_test:0.02973, lr:4.53e-02, fs:0.70455 (r=0.626,p=0.805),  time:30.210, tt:2144.928\n",
      "Ep:71, loss:0.00001, loss_test:0.03494, lr:4.48e-02, fs:0.70455 (r=0.626,p=0.805),  time:30.212, tt:2175.282\n",
      "Ep:72, loss:0.00001, loss_test:0.03166, lr:4.44e-02, fs:0.70455 (r=0.626,p=0.805),  time:30.209, tt:2205.222\n",
      "Ep:73, loss:0.00001, loss_test:0.03293, lr:4.39e-02, fs:0.70455 (r=0.626,p=0.805),  time:30.211, tt:2235.582\n",
      "Ep:74, loss:0.00001, loss_test:0.03557, lr:4.35e-02, fs:0.70857 (r=0.626,p=0.816),  time:30.201, tt:2265.087\n",
      "Ep:75, loss:0.00001, loss_test:0.03405, lr:4.31e-02, fs:0.70857 (r=0.626,p=0.816),  time:30.198, tt:2295.054\n",
      "Ep:76, loss:0.00001, loss_test:0.03741, lr:4.26e-02, fs:0.70115 (r=0.616,p=0.813),  time:30.207, tt:2325.924\n",
      "Ep:77, loss:0.00001, loss_test:0.03498, lr:4.22e-02, fs:0.71264 (r=0.626,p=0.827),  time:30.210, tt:2356.399\n",
      "Ep:78, loss:0.00001, loss_test:0.03753, lr:4.18e-02, fs:0.70930 (r=0.616,p=0.836),  time:30.212, tt:2386.776\n",
      "Ep:79, loss:0.00001, loss_test:0.03553, lr:4.14e-02, fs:0.71264 (r=0.626,p=0.827),  time:30.209, tt:2416.692\n",
      "Ep:80, loss:0.00001, loss_test:0.03934, lr:4.10e-02, fs:0.70930 (r=0.616,p=0.836),  time:30.190, tt:2445.376\n",
      "Ep:81, loss:0.00001, loss_test:0.03758, lr:4.05e-02, fs:0.71264 (r=0.626,p=0.827),  time:30.185, tt:2475.154\n",
      "Ep:82, loss:0.00000, loss_test:0.03856, lr:4.01e-02, fs:0.71676 (r=0.626,p=0.838),  time:30.218, tt:2508.104\n",
      "Ep:83, loss:0.00000, loss_test:0.03991, lr:3.97e-02, fs:0.70930 (r=0.616,p=0.836),  time:30.224, tt:2538.840\n",
      "Ep:84, loss:0.00000, loss_test:0.03936, lr:3.93e-02, fs:0.71676 (r=0.626,p=0.838),  time:30.229, tt:2569.431\n",
      "Ep:85, loss:0.00000, loss_test:0.04125, lr:3.89e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.232, tt:2599.970\n",
      "Ep:86, loss:0.00000, loss_test:0.03997, lr:3.86e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.231, tt:2630.070\n",
      "Ep:87, loss:0.00000, loss_test:0.04128, lr:3.82e-02, fs:0.72093 (r=0.626,p=0.849),  time:30.223, tt:2659.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:88, loss:0.00000, loss_test:0.04251, lr:3.78e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.223, tt:2689.866\n",
      "Ep:89, loss:0.00000, loss_test:0.04133, lr:3.74e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.223, tt:2720.048\n",
      "Ep:90, loss:0.00000, loss_test:0.04260, lr:3.70e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.234, tt:2751.330\n",
      "Ep:91, loss:0.00000, loss_test:0.04313, lr:3.67e-02, fs:0.72515 (r=0.626,p=0.861),  time:30.229, tt:2781.110\n",
      "Ep:92, loss:0.00000, loss_test:0.04300, lr:3.63e-02, fs:0.71345 (r=0.616,p=0.847),  time:30.238, tt:2812.175\n",
      "Ep:93, loss:0.00000, loss_test:0.04489, lr:3.59e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.234, tt:2841.993\n",
      "Ep:94, loss:0.00000, loss_test:0.04371, lr:3.56e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.242, tt:2873.019\n",
      "Ep:95, loss:0.00000, loss_test:0.04422, lr:3.52e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.256, tt:2904.570\n",
      "Ep:96, loss:0.00000, loss_test:0.04478, lr:3.49e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.247, tt:2933.935\n",
      "Ep:97, loss:0.00000, loss_test:0.04489, lr:3.45e-02, fs:0.71765 (r=0.616,p=0.859),  time:30.248, tt:2964.278\n",
      "Ep:98, loss:0.00000, loss_test:0.04606, lr:3.42e-02, fs:0.72189 (r=0.616,p=0.871),  time:30.251, tt:2994.881\n",
      "Ep:99, loss:0.00000, loss_test:0.04465, lr:3.38e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.259, tt:3025.883\n",
      "Ep:100, loss:0.00000, loss_test:0.04536, lr:3.35e-02, fs:0.71006 (r=0.606,p=0.857),  time:30.262, tt:3056.436\n",
      "Ep:101, loss:0.00000, loss_test:0.04705, lr:3.32e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.273, tt:3087.803\n",
      "Ep:102, loss:0.00000, loss_test:0.04601, lr:3.28e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.272, tt:3118.038\n",
      "Ep:103, loss:0.00000, loss_test:0.04586, lr:3.25e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.280, tt:3149.073\n",
      "Ep:104, loss:0.00000, loss_test:0.04744, lr:3.22e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.281, tt:3179.481\n",
      "Ep:105, loss:0.00000, loss_test:0.04641, lr:3.19e-02, fs:0.70659 (r=0.596,p=0.868),  time:30.291, tt:3210.802\n",
      "Ep:106, loss:0.00000, loss_test:0.04691, lr:3.15e-02, fs:0.69880 (r=0.586,p=0.866),  time:30.300, tt:3242.133\n",
      "Ep:107, loss:0.00000, loss_test:0.04792, lr:3.12e-02, fs:0.69880 (r=0.586,p=0.866),  time:30.306, tt:3273.028\n",
      "Ep:108, loss:0.00000, loss_test:0.04690, lr:3.09e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.303, tt:3303.044\n",
      "Ep:109, loss:0.00000, loss_test:0.04823, lr:3.06e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.312, tt:3334.364\n",
      "Ep:110, loss:0.00000, loss_test:0.04859, lr:3.03e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.306, tt:3363.968\n",
      "Ep:111, loss:0.00000, loss_test:0.04694, lr:3.00e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.306, tt:3394.317\n",
      "Ep:112, loss:0.00000, loss_test:0.04863, lr:2.97e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.315, tt:3425.596\n",
      "Ep:113, loss:0.00000, loss_test:0.04824, lr:2.94e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.324, tt:3456.931\n",
      "Ep:114, loss:0.00000, loss_test:0.04900, lr:2.91e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.329, tt:3487.840\n",
      "Ep:115, loss:0.00000, loss_test:0.04957, lr:2.88e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.338, tt:3519.160\n",
      "Ep:116, loss:0.00000, loss_test:0.04852, lr:2.85e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.332, tt:3548.825\n",
      "Ep:117, loss:0.00000, loss_test:0.04973, lr:2.82e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.334, tt:3579.364\n",
      "Ep:118, loss:0.00000, loss_test:0.04937, lr:2.80e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.336, tt:3609.948\n",
      "Ep:119, loss:0.00000, loss_test:0.04926, lr:2.77e-02, fs:0.69091 (r=0.576,p=0.864),  time:30.332, tt:3639.826\n",
      "Ep:120, loss:0.00000, loss_test:0.05076, lr:2.74e-02, fs:0.69512 (r=0.576,p=0.877),  time:30.337, tt:3670.743\n",
      "Ep:121, loss:0.00000, loss_test:0.04959, lr:2.71e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.338, tt:3701.194\n",
      "Ep:122, loss:0.00000, loss_test:0.05072, lr:2.69e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.345, tt:3732.492\n",
      "Ep:123, loss:0.00000, loss_test:0.05036, lr:2.66e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.349, tt:3763.228\n",
      "Ep:124, loss:0.00000, loss_test:0.04988, lr:2.63e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.352, tt:3794.003\n",
      "Ep:125, loss:0.00000, loss_test:0.05209, lr:2.61e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.345, tt:3823.415\n",
      "Ep:126, loss:0.00000, loss_test:0.04949, lr:2.58e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.358, tt:3855.471\n",
      "Ep:127, loss:0.00000, loss_test:0.05234, lr:2.55e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.360, tt:3886.140\n",
      "Ep:128, loss:0.00000, loss_test:0.04918, lr:2.53e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.369, tt:3917.628\n",
      "Ep:129, loss:0.00000, loss_test:0.05315, lr:2.50e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.380, tt:3949.338\n",
      "Ep:130, loss:0.00000, loss_test:0.04975, lr:2.48e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.379, tt:3979.590\n",
      "Ep:131, loss:0.00000, loss_test:0.05312, lr:2.45e-02, fs:0.69939 (r=0.576,p=0.891),  time:30.389, tt:4011.309\n",
      "Ep:132, loss:0.00000, loss_test:0.05084, lr:2.43e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.396, tt:4042.729\n",
      "Ep:133, loss:0.00000, loss_test:0.05230, lr:2.40e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.410, tt:4074.929\n",
      "Ep:134, loss:0.00000, loss_test:0.05170, lr:2.38e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.420, tt:4106.677\n",
      "Ep:135, loss:0.00000, loss_test:0.05189, lr:2.36e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.435, tt:4139.222\n",
      "Ep:136, loss:0.00000, loss_test:0.05288, lr:2.33e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.435, tt:4169.609\n",
      "Ep:137, loss:0.00000, loss_test:0.05174, lr:2.31e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.437, tt:4200.262\n",
      "Ep:138, loss:0.00000, loss_test:0.05400, lr:2.29e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.444, tt:4231.695\n",
      "Ep:139, loss:0.00000, loss_test:0.05176, lr:2.26e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.452, tt:4263.298\n",
      "Ep:140, loss:0.00000, loss_test:0.05365, lr:2.24e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.454, tt:4294.000\n",
      "Ep:141, loss:0.00000, loss_test:0.05237, lr:2.22e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.465, tt:4325.985\n",
      "Ep:142, loss:0.00000, loss_test:0.05386, lr:2.20e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.476, tt:4358.052\n",
      "Ep:143, loss:0.00000, loss_test:0.05291, lr:2.17e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.482, tt:4389.472\n",
      "Ep:144, loss:0.00000, loss_test:0.05408, lr:2.15e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.491, tt:4421.157\n",
      "Ep:145, loss:0.00000, loss_test:0.05306, lr:2.13e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.494, tt:4452.143\n",
      "Ep:146, loss:0.00000, loss_test:0.05474, lr:2.11e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.507, tt:4484.498\n",
      "Ep:147, loss:0.00000, loss_test:0.05331, lr:2.09e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.541, tt:4520.110\n",
      "Ep:148, loss:0.00000, loss_test:0.05441, lr:2.07e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.551, tt:4552.030\n",
      "Ep:149, loss:0.00000, loss_test:0.05384, lr:2.05e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.548, tt:4582.129\n",
      "Ep:150, loss:0.00000, loss_test:0.05467, lr:2.03e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.558, tt:4614.321\n",
      "Ep:151, loss:0.00000, loss_test:0.05412, lr:2.01e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.559, tt:4644.957\n",
      "Ep:152, loss:0.00000, loss_test:0.05506, lr:1.99e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.554, tt:4674.784\n",
      "Ep:153, loss:0.00000, loss_test:0.05439, lr:1.97e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.548, tt:4704.434\n",
      "Ep:154, loss:0.00000, loss_test:0.05514, lr:1.95e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.543, tt:4734.166\n",
      "Ep:155, loss:0.00000, loss_test:0.05479, lr:1.93e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.537, tt:4763.839\n",
      "Ep:156, loss:0.00000, loss_test:0.05491, lr:1.91e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.537, tt:4794.378\n",
      "Ep:157, loss:0.00000, loss_test:0.05526, lr:1.89e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.537, tt:4824.810\n",
      "Ep:158, loss:0.00000, loss_test:0.05505, lr:1.87e-02, fs:0.70370 (r=0.576,p=0.905),  time:30.531, tt:4854.382\n",
      "Ep:159, loss:0.00000, loss_test:0.05542, lr:1.85e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.537, tt:4885.967\n",
      "Ep:160, loss:0.00000, loss_test:0.05533, lr:1.83e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.535, tt:4916.118\n",
      "Ep:161, loss:0.00000, loss_test:0.05558, lr:1.81e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.539, tt:4947.360\n",
      "Ep:162, loss:0.00000, loss_test:0.05546, lr:1.80e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.540, tt:4977.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00000, loss_test:0.05582, lr:1.78e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.538, tt:5008.210\n",
      "Ep:164, loss:0.00000, loss_test:0.05574, lr:1.76e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.540, tt:5039.058\n",
      "Ep:165, loss:0.00000, loss_test:0.05577, lr:1.74e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.534, tt:5068.719\n",
      "Ep:166, loss:0.00000, loss_test:0.05617, lr:1.73e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.536, tt:5099.546\n",
      "Ep:167, loss:0.00000, loss_test:0.05594, lr:1.71e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.536, tt:5130.039\n",
      "Ep:168, loss:0.00000, loss_test:0.05632, lr:1.69e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.536, tt:5160.578\n",
      "Ep:169, loss:0.00000, loss_test:0.05605, lr:1.67e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.545, tt:5192.583\n",
      "Ep:170, loss:0.00000, loss_test:0.05636, lr:1.66e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.541, tt:5222.456\n",
      "Ep:171, loss:0.00000, loss_test:0.05623, lr:1.64e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.538, tt:5252.496\n",
      "Ep:172, loss:0.00000, loss_test:0.05642, lr:1.62e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.538, tt:5283.052\n",
      "Ep:173, loss:0.00000, loss_test:0.05673, lr:1.61e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.555, tt:5316.544\n",
      "Ep:174, loss:0.00000, loss_test:0.05682, lr:1.59e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.553, tt:5346.840\n",
      "Ep:175, loss:0.00000, loss_test:0.05657, lr:1.58e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.547, tt:5376.256\n",
      "Ep:176, loss:0.00000, loss_test:0.05690, lr:1.56e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.545, tt:5406.524\n",
      "Ep:177, loss:0.00000, loss_test:0.05700, lr:1.54e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.549, tt:5437.781\n",
      "Ep:178, loss:0.00000, loss_test:0.05691, lr:1.53e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.549, tt:5468.278\n",
      "Ep:179, loss:0.00000, loss_test:0.05746, lr:1.51e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.553, tt:5499.549\n",
      "Ep:180, loss:0.00000, loss_test:0.05701, lr:1.50e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.553, tt:5530.082\n",
      "Ep:181, loss:0.00000, loss_test:0.05754, lr:1.48e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.550, tt:5560.146\n",
      "Ep:182, loss:0.00000, loss_test:0.05723, lr:1.47e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.547, tt:5590.117\n",
      "Ep:183, loss:0.00000, loss_test:0.05761, lr:1.45e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.554, tt:5621.961\n",
      "Ep:184, loss:0.00000, loss_test:0.05737, lr:1.44e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.558, tt:5653.179\n",
      "Ep:185, loss:0.00000, loss_test:0.05771, lr:1.43e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.564, tt:5684.828\n",
      "Ep:186, loss:0.00000, loss_test:0.05782, lr:1.41e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.564, tt:5715.529\n",
      "Ep:187, loss:0.00000, loss_test:0.05777, lr:1.40e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.565, tt:5746.221\n",
      "Ep:188, loss:0.00000, loss_test:0.05808, lr:1.38e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.555, tt:5774.930\n",
      "Ep:189, loss:0.00000, loss_test:0.05769, lr:1.37e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.554, tt:5805.287\n",
      "Ep:190, loss:0.00000, loss_test:0.05813, lr:1.36e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.560, tt:5836.924\n",
      "Ep:191, loss:0.00000, loss_test:0.05820, lr:1.34e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.559, tt:5867.326\n",
      "Ep:192, loss:0.00000, loss_test:0.05793, lr:1.33e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.559, tt:5897.874\n",
      "Ep:193, loss:0.00000, loss_test:0.05848, lr:1.32e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.562, tt:5928.963\n",
      "Ep:194, loss:0.00000, loss_test:0.05812, lr:1.30e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.561, tt:5959.461\n",
      "Ep:195, loss:0.00000, loss_test:0.05838, lr:1.29e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.553, tt:5988.375\n",
      "Ep:196, loss:0.00000, loss_test:0.05876, lr:1.28e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.540, tt:6016.317\n",
      "Ep:197, loss:0.00000, loss_test:0.05802, lr:1.26e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.532, tt:6045.326\n",
      "Ep:198, loss:0.00000, loss_test:0.05893, lr:1.25e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.513, tt:6072.134\n",
      "Ep:199, loss:0.00000, loss_test:0.05824, lr:1.24e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.483, tt:6096.654\n",
      "Ep:200, loss:0.00000, loss_test:0.05896, lr:1.23e-02, fs:0.71250 (r=0.576,p=0.934),  time:30.466, tt:6123.676\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13071, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:25.224, tt:25.224\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13000, lr:1.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:27.361, tt:54.722\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13032, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:28.509, tt:85.528\n",
      "Ep:3, loss:0.00026, loss_test:0.13067, lr:1.00e-02, fs:0.68657 (r=0.929,p=0.544),  time:29.244, tt:116.977\n",
      "Ep:4, loss:0.00026, loss_test:0.13028, lr:1.00e-02, fs:0.69145 (r=0.939,p=0.547),  time:29.458, tt:147.288\n",
      "Ep:5, loss:0.00025, loss_test:0.12874, lr:1.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:29.622, tt:177.734\n",
      "Ep:6, loss:0.00025, loss_test:0.12646, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:29.712, tt:207.982\n",
      "Ep:7, loss:0.00025, loss_test:0.12451, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:29.784, tt:238.273\n",
      "Ep:8, loss:0.00025, loss_test:0.12325, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.894, tt:269.046\n",
      "Ep:9, loss:0.00024, loss_test:0.12284, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.961, tt:299.607\n",
      "Ep:10, loss:0.00024, loss_test:0.12304, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:30.253, tt:332.783\n",
      "Ep:11, loss:0.00024, loss_test:0.12258, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:30.354, tt:364.250\n",
      "Ep:12, loss:0.00024, loss_test:0.12076, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:30.342, tt:394.442\n",
      "Ep:13, loss:0.00023, loss_test:0.11828, lr:9.90e-03, fs:0.69355 (r=0.869,p=0.577),  time:30.398, tt:425.571\n",
      "Ep:14, loss:0.00023, loss_test:0.11716, lr:9.80e-03, fs:0.70204 (r=0.869,p=0.589),  time:30.574, tt:458.615\n",
      "Ep:15, loss:0.00023, loss_test:0.11736, lr:9.70e-03, fs:0.71255 (r=0.889,p=0.595),  time:30.549, tt:488.777\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.11746, lr:9.70e-03, fs:0.70400 (r=0.889,p=0.583),  time:30.530, tt:519.012\n",
      "Ep:17, loss:0.00022, loss_test:0.11646, lr:9.70e-03, fs:0.70683 (r=0.889,p=0.587),  time:30.525, tt:549.450\n",
      "Ep:18, loss:0.00022, loss_test:0.11462, lr:9.70e-03, fs:0.71605 (r=0.879,p=0.604),  time:30.496, tt:579.422\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.11459, lr:9.70e-03, fs:0.71020 (r=0.879,p=0.596),  time:30.495, tt:609.894\n",
      "Ep:20, loss:0.00022, loss_test:0.11523, lr:9.70e-03, fs:0.71545 (r=0.889,p=0.599),  time:30.476, tt:639.995\n",
      "Ep:21, loss:0.00021, loss_test:0.11282, lr:9.70e-03, fs:0.71311 (r=0.879,p=0.600),  time:30.406, tt:668.922\n",
      "Ep:22, loss:0.00021, loss_test:0.11062, lr:9.70e-03, fs:0.72199 (r=0.879,p=0.613),  time:30.450, tt:700.348\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.11021, lr:9.70e-03, fs:0.72428 (r=0.889,p=0.611),  time:30.547, tt:733.140\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00021, loss_test:0.11048, lr:9.70e-03, fs:0.72428 (r=0.889,p=0.611),  time:30.583, tt:764.563\n",
      "Ep:25, loss:0.00020, loss_test:0.10871, lr:9.70e-03, fs:0.73029 (r=0.889,p=0.620),  time:30.622, tt:796.172\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00020, loss_test:0.10675, lr:9.70e-03, fs:0.73333 (r=0.889,p=0.624),  time:30.638, tt:827.222\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.10628, lr:9.70e-03, fs:0.74167 (r=0.899,p=0.631),  time:30.659, tt:858.463\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.10606, lr:9.70e-03, fs:0.73770 (r=0.909,p=0.621),  time:30.664, tt:889.259\n",
      "Ep:29, loss:0.00019, loss_test:0.10375, lr:9.70e-03, fs:0.74790 (r=0.899,p=0.640),  time:30.648, tt:919.439\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00019, loss_test:0.10224, lr:9.70e-03, fs:0.74894 (r=0.889,p=0.647),  time:30.642, tt:949.907\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00019, loss_test:0.10135, lr:9.70e-03, fs:0.74477 (r=0.899,p=0.636),  time:30.627, tt:980.071\n",
      "Ep:32, loss:0.00018, loss_test:0.09959, lr:9.70e-03, fs:0.75314 (r=0.909,p=0.643),  time:30.611, tt:1010.165\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00018, loss_test:0.09730, lr:9.70e-03, fs:0.75424 (r=0.899,p=0.650),  time:30.684, tt:1043.254\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.09621, lr:9.70e-03, fs:0.76271 (r=0.909,p=0.657),  time:30.655, tt:1072.929\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00017, loss_test:0.09466, lr:9.70e-03, fs:0.76271 (r=0.909,p=0.657),  time:30.653, tt:1103.505\n",
      "Ep:36, loss:0.00016, loss_test:0.09295, lr:9.70e-03, fs:0.75536 (r=0.889,p=0.657),  time:30.663, tt:1134.533\n",
      "Ep:37, loss:0.00016, loss_test:0.09128, lr:9.70e-03, fs:0.75862 (r=0.889,p=0.662),  time:30.698, tt:1166.521\n",
      "Ep:38, loss:0.00015, loss_test:0.08897, lr:9.70e-03, fs:0.76190 (r=0.889,p=0.667),  time:30.702, tt:1197.372\n",
      "Ep:39, loss:0.00015, loss_test:0.08863, lr:9.70e-03, fs:0.75862 (r=0.889,p=0.662),  time:30.685, tt:1227.410\n",
      "Ep:40, loss:0.00014, loss_test:0.08676, lr:9.70e-03, fs:0.78027 (r=0.879,p=0.702),  time:30.663, tt:1257.167\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00014, loss_test:0.08832, lr:9.70e-03, fs:0.76068 (r=0.899,p=0.659),  time:30.641, tt:1286.902\n",
      "Ep:42, loss:0.00013, loss_test:0.08608, lr:9.70e-03, fs:0.80383 (r=0.848,p=0.764),  time:30.645, tt:1317.720\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00013, loss_test:0.08272, lr:9.70e-03, fs:0.82126 (r=0.859,p=0.787),  time:30.641, tt:1348.219\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00012, loss_test:0.08485, lr:9.70e-03, fs:0.79091 (r=0.879,p=0.719),  time:30.638, tt:1378.729\n",
      "Ep:45, loss:0.00012, loss_test:0.08173, lr:9.70e-03, fs:0.79621 (r=0.848,p=0.750),  time:30.658, tt:1410.269\n",
      "Ep:46, loss:0.00011, loss_test:0.07948, lr:9.70e-03, fs:0.82353 (r=0.848,p=0.800),  time:30.661, tt:1441.077\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00010, loss_test:0.08334, lr:9.70e-03, fs:0.82178 (r=0.838,p=0.806),  time:30.650, tt:1471.208\n",
      "Ep:48, loss:0.00010, loss_test:0.09484, lr:9.70e-03, fs:0.81373 (r=0.838,p=0.790),  time:30.656, tt:1502.159\n",
      "Ep:49, loss:0.00011, loss_test:0.09485, lr:9.70e-03, fs:0.82353 (r=0.848,p=0.800),  time:30.693, tt:1534.659\n",
      "Ep:50, loss:0.00010, loss_test:0.07906, lr:9.70e-03, fs:0.78505 (r=0.848,p=0.730),  time:30.707, tt:1566.074\n",
      "Ep:51, loss:0.00010, loss_test:0.08079, lr:9.70e-03, fs:0.83168 (r=0.848,p=0.816),  time:30.704, tt:1596.631\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00010, loss_test:0.10260, lr:9.70e-03, fs:0.82178 (r=0.838,p=0.806),  time:30.691, tt:1626.615\n",
      "Ep:53, loss:0.00010, loss_test:0.07650, lr:9.70e-03, fs:0.79070 (r=0.859,p=0.733),  time:30.694, tt:1657.459\n",
      "Ep:54, loss:0.00009, loss_test:0.09323, lr:9.70e-03, fs:0.82759 (r=0.848,p=0.808),  time:30.676, tt:1687.172\n",
      "Ep:55, loss:0.00008, loss_test:0.08125, lr:9.70e-03, fs:0.83582 (r=0.848,p=0.824),  time:30.684, tt:1718.279\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00008, loss_test:0.09291, lr:9.70e-03, fs:0.83417 (r=0.838,p=0.830),  time:30.690, tt:1749.344\n",
      "Ep:57, loss:0.00007, loss_test:0.08386, lr:9.70e-03, fs:0.82353 (r=0.848,p=0.800),  time:30.693, tt:1780.216\n",
      "Ep:58, loss:0.00007, loss_test:0.08776, lr:9.70e-03, fs:0.84000 (r=0.848,p=0.832),  time:30.673, tt:1809.734\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00007, loss_test:0.07886, lr:9.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:30.688, tt:1841.259\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.09090, lr:9.70e-03, fs:0.85279 (r=0.848,p=0.857),  time:30.711, tt:1873.396\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.07977, lr:9.70e-03, fs:0.83582 (r=0.848,p=0.824),  time:30.726, tt:1905.012\n",
      "Ep:62, loss:0.00006, loss_test:0.09345, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:30.733, tt:1936.175\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.09078, lr:9.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:30.733, tt:1966.895\n",
      "Ep:64, loss:0.00005, loss_test:0.08264, lr:9.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:30.731, tt:1997.504\n",
      "Ep:65, loss:0.00005, loss_test:0.09576, lr:9.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:30.741, tt:2028.874\n",
      "Ep:66, loss:0.00005, loss_test:0.08274, lr:9.70e-03, fs:0.84422 (r=0.848,p=0.840),  time:30.740, tt:2059.557\n",
      "Ep:67, loss:0.00005, loss_test:0.09766, lr:9.70e-03, fs:0.83938 (r=0.818,p=0.862),  time:30.760, tt:2091.709\n",
      "Ep:68, loss:0.00005, loss_test:0.08887, lr:9.70e-03, fs:0.85279 (r=0.848,p=0.857),  time:30.745, tt:2121.402\n",
      "Ep:69, loss:0.00004, loss_test:0.08605, lr:9.70e-03, fs:0.84848 (r=0.848,p=0.848),  time:30.747, tt:2152.258\n",
      "Ep:70, loss:0.00004, loss_test:0.09941, lr:9.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:30.744, tt:2182.810\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.09125, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:30.746, tt:2213.722\n",
      "Ep:72, loss:0.00004, loss_test:0.09853, lr:9.70e-03, fs:0.82540 (r=0.788,p=0.867),  time:30.732, tt:2243.461\n",
      "Ep:73, loss:0.00004, loss_test:0.09872, lr:9.70e-03, fs:0.86598 (r=0.848,p=0.884),  time:30.751, tt:2275.609\n",
      "Ep:74, loss:0.00004, loss_test:0.10113, lr:9.70e-03, fs:0.78453 (r=0.717,p=0.866),  time:30.767, tt:2307.511\n",
      "Ep:75, loss:0.00003, loss_test:0.09157, lr:9.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:30.765, tt:2338.163\n",
      "Ep:76, loss:0.00003, loss_test:0.11006, lr:9.70e-03, fs:0.72941 (r=0.626,p=0.873),  time:30.753, tt:2367.942\n",
      "Ep:77, loss:0.00004, loss_test:0.11072, lr:9.70e-03, fs:0.75429 (r=0.667,p=0.868),  time:30.753, tt:2398.711\n",
      "Ep:78, loss:0.00004, loss_test:0.09085, lr:9.70e-03, fs:0.78689 (r=0.727,p=0.857),  time:30.767, tt:2430.579\n",
      "Ep:79, loss:0.00004, loss_test:0.08451, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:30.775, tt:2461.991\n",
      "Ep:80, loss:0.00003, loss_test:0.10960, lr:9.70e-03, fs:0.81319 (r=0.747,p=0.892),  time:30.756, tt:2491.256\n",
      "Ep:81, loss:0.00004, loss_test:0.09691, lr:9.70e-03, fs:0.84817 (r=0.818,p=0.880),  time:30.756, tt:2521.969\n",
      "Ep:82, loss:0.00003, loss_test:0.09743, lr:9.61e-03, fs:0.80435 (r=0.747,p=0.871),  time:30.766, tt:2553.539\n",
      "Ep:83, loss:0.00003, loss_test:0.11172, lr:9.51e-03, fs:0.72941 (r=0.626,p=0.873),  time:30.760, tt:2583.799\n",
      "Ep:84, loss:0.00003, loss_test:0.08917, lr:9.41e-03, fs:0.84211 (r=0.808,p=0.879),  time:30.763, tt:2614.826\n",
      "Ep:85, loss:0.00003, loss_test:0.10867, lr:9.32e-03, fs:0.72941 (r=0.626,p=0.873),  time:30.755, tt:2644.890\n",
      "Ep:86, loss:0.00003, loss_test:0.11063, lr:9.23e-03, fs:0.73684 (r=0.636,p=0.875),  time:30.750, tt:2675.275\n",
      "Ep:87, loss:0.00003, loss_test:0.08768, lr:9.14e-03, fs:0.83770 (r=0.808,p=0.870),  time:30.733, tt:2704.467\n",
      "Ep:88, loss:0.00003, loss_test:0.11858, lr:9.04e-03, fs:0.72941 (r=0.626,p=0.873),  time:30.745, tt:2736.331\n",
      "Ep:89, loss:0.00003, loss_test:0.10130, lr:8.95e-03, fs:0.80000 (r=0.727,p=0.889),  time:30.763, tt:2768.682\n",
      "Ep:90, loss:0.00003, loss_test:0.10413, lr:8.86e-03, fs:0.75862 (r=0.667,p=0.880),  time:30.762, tt:2799.305\n",
      "Ep:91, loss:0.00002, loss_test:0.10306, lr:8.78e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.768, tt:2830.688\n",
      "Ep:92, loss:0.00002, loss_test:0.10431, lr:8.69e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.762, tt:2860.889\n",
      "Ep:93, loss:0.00002, loss_test:0.10649, lr:8.60e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.757, tt:2891.117\n",
      "Ep:94, loss:0.00002, loss_test:0.10916, lr:8.51e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.750, tt:2921.273\n",
      "Ep:95, loss:0.00002, loss_test:0.10200, lr:8.43e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.742, tt:2951.240\n",
      "Ep:96, loss:0.00002, loss_test:0.11906, lr:8.35e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.745, tt:2982.308\n",
      "Ep:97, loss:0.00002, loss_test:0.09937, lr:8.26e-03, fs:0.74118 (r=0.636,p=0.887),  time:30.737, tt:3012.203\n",
      "Ep:98, loss:0.00002, loss_test:0.11665, lr:8.18e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.720, tt:3041.291\n",
      "Ep:99, loss:0.00002, loss_test:0.09866, lr:8.10e-03, fs:0.74556 (r=0.636,p=0.900),  time:30.720, tt:3071.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00002, loss_test:0.12182, lr:8.02e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.703, tt:3101.048\n",
      "Ep:101, loss:0.00002, loss_test:0.10723, lr:7.94e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.737, tt:3135.132\n",
      "Ep:102, loss:0.00002, loss_test:0.11942, lr:7.86e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.733, tt:3165.549\n",
      "Ep:103, loss:0.00001, loss_test:0.09761, lr:7.78e-03, fs:0.73684 (r=0.636,p=0.875),  time:30.729, tt:3195.787\n",
      "Ep:104, loss:0.00001, loss_test:0.13176, lr:7.70e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.730, tt:3226.619\n",
      "Ep:105, loss:0.00002, loss_test:0.10515, lr:7.62e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.721, tt:3256.427\n",
      "Ep:106, loss:0.00001, loss_test:0.12128, lr:7.55e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.707, tt:3285.643\n",
      "Ep:107, loss:0.00002, loss_test:0.10080, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:30.697, tt:3315.286\n",
      "Ep:108, loss:0.00001, loss_test:0.12468, lr:7.40e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.683, tt:3344.472\n",
      "Ep:109, loss:0.00001, loss_test:0.10522, lr:7.32e-03, fs:0.76190 (r=0.646,p=0.928),  time:30.670, tt:3373.710\n",
      "Ep:110, loss:0.00001, loss_test:0.12533, lr:7.25e-03, fs:0.72619 (r=0.616,p=0.884),  time:30.657, tt:3402.899\n",
      "Ep:111, loss:0.00001, loss_test:0.09974, lr:7.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:30.644, tt:3432.142\n",
      "Ep:112, loss:0.00001, loss_test:0.12660, lr:7.11e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.658, tt:3464.347\n",
      "Ep:113, loss:0.00001, loss_test:0.10673, lr:7.03e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.658, tt:3495.034\n",
      "Ep:114, loss:0.00001, loss_test:0.11962, lr:6.96e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.660, tt:3525.938\n",
      "Ep:115, loss:0.00001, loss_test:0.11341, lr:6.89e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.672, tt:3557.931\n",
      "Ep:116, loss:0.00001, loss_test:0.11986, lr:6.83e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.671, tt:3588.502\n",
      "Ep:117, loss:0.00001, loss_test:0.12521, lr:6.76e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.676, tt:3619.733\n",
      "Ep:118, loss:0.00001, loss_test:0.11888, lr:6.69e-03, fs:0.73373 (r=0.626,p=0.886),  time:30.667, tt:3649.396\n",
      "Ep:119, loss:0.00001, loss_test:0.11930, lr:6.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.673, tt:3680.764\n",
      "Ep:120, loss:0.00001, loss_test:0.11519, lr:6.56e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.680, tt:3712.265\n",
      "Ep:121, loss:0.00001, loss_test:0.11828, lr:6.49e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.697, tt:3745.057\n",
      "Ep:122, loss:0.00001, loss_test:0.11639, lr:6.43e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.704, tt:3776.610\n",
      "Ep:123, loss:0.00001, loss_test:0.11757, lr:6.36e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.739, tt:3811.662\n",
      "Ep:124, loss:0.00001, loss_test:0.11947, lr:6.30e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.751, tt:3843.849\n",
      "Ep:125, loss:0.00001, loss_test:0.11755, lr:6.24e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.755, tt:3875.131\n",
      "Ep:126, loss:0.00001, loss_test:0.11646, lr:6.17e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.777, tt:3908.643\n",
      "Ep:127, loss:0.00001, loss_test:0.12068, lr:6.11e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.787, tt:3940.699\n",
      "Ep:128, loss:0.00001, loss_test:0.11718, lr:6.05e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.786, tt:3971.331\n",
      "Ep:129, loss:0.00001, loss_test:0.11983, lr:5.99e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.803, tt:4004.360\n",
      "Ep:130, loss:0.00001, loss_test:0.11728, lr:5.93e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.811, tt:4036.224\n",
      "Ep:131, loss:0.00001, loss_test:0.12651, lr:5.87e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.814, tt:4067.436\n",
      "Ep:132, loss:0.00001, loss_test:0.12009, lr:5.81e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.819, tt:4098.872\n",
      "Ep:133, loss:0.00001, loss_test:0.12183, lr:5.75e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.820, tt:4129.859\n",
      "Ep:134, loss:0.00001, loss_test:0.11814, lr:5.70e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.827, tt:4161.628\n",
      "Ep:135, loss:0.00001, loss_test:0.12552, lr:5.64e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.835, tt:4193.573\n",
      "Ep:136, loss:0.00001, loss_test:0.12050, lr:5.58e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.844, tt:4225.621\n",
      "Ep:137, loss:0.00001, loss_test:0.12110, lr:5.53e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.858, tt:4258.453\n",
      "Ep:138, loss:0.00001, loss_test:0.11840, lr:5.47e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.865, tt:4290.249\n",
      "Ep:139, loss:0.00001, loss_test:0.12029, lr:5.42e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.858, tt:4320.189\n",
      "Ep:140, loss:0.00001, loss_test:0.11898, lr:5.36e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.864, tt:4351.833\n",
      "Ep:141, loss:0.00001, loss_test:0.12296, lr:5.31e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.879, tt:4384.854\n",
      "Ep:142, loss:0.00001, loss_test:0.11912, lr:5.26e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.883, tt:4416.327\n",
      "Ep:143, loss:0.00001, loss_test:0.12264, lr:5.20e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.887, tt:4447.718\n",
      "Ep:144, loss:0.00001, loss_test:0.11844, lr:5.15e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.891, tt:4479.208\n",
      "Ep:145, loss:0.00001, loss_test:0.12568, lr:5.10e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.895, tt:4510.610\n",
      "Ep:146, loss:0.00001, loss_test:0.11393, lr:5.05e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.926, tt:4546.069\n",
      "Ep:147, loss:0.00001, loss_test:0.12450, lr:5.00e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.935, tt:4578.350\n",
      "Ep:148, loss:0.00001, loss_test:0.11817, lr:4.95e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.941, tt:4610.172\n",
      "Ep:149, loss:0.00001, loss_test:0.12611, lr:4.90e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.929, tt:4639.341\n",
      "Ep:150, loss:0.00001, loss_test:0.12260, lr:4.85e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.915, tt:4668.093\n",
      "Ep:151, loss:0.00001, loss_test:0.11990, lr:4.80e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.909, tt:4698.163\n",
      "Ep:152, loss:0.00000, loss_test:0.12254, lr:4.75e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.914, tt:4729.786\n",
      "Ep:153, loss:0.00000, loss_test:0.11903, lr:4.71e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.916, tt:4761.028\n",
      "Ep:154, loss:0.00000, loss_test:0.12258, lr:4.66e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.918, tt:4792.327\n",
      "Ep:155, loss:0.00000, loss_test:0.12374, lr:4.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.929, tt:4824.871\n",
      "Ep:156, loss:0.00000, loss_test:0.12220, lr:4.57e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.926, tt:4855.363\n",
      "Ep:157, loss:0.00000, loss_test:0.12010, lr:4.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.932, tt:4887.242\n",
      "Ep:158, loss:0.00000, loss_test:0.12162, lr:4.48e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.934, tt:4918.582\n",
      "Ep:159, loss:0.00000, loss_test:0.12317, lr:4.43e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.942, tt:4950.680\n",
      "Ep:160, loss:0.00000, loss_test:0.12217, lr:4.39e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.946, tt:4982.348\n",
      "Ep:161, loss:0.00000, loss_test:0.12251, lr:4.34e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.948, tt:5013.605\n",
      "Ep:162, loss:0.00000, loss_test:0.12235, lr:4.30e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.952, tt:5045.208\n",
      "Ep:163, loss:0.00000, loss_test:0.11989, lr:4.26e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.953, tt:5076.360\n",
      "Ep:164, loss:0.00000, loss_test:0.12187, lr:4.21e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.965, tt:5109.251\n",
      "Ep:165, loss:0.00000, loss_test:0.12166, lr:4.17e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.971, tt:5141.222\n",
      "Ep:166, loss:0.00000, loss_test:0.12303, lr:4.13e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.978, tt:5173.307\n",
      "Ep:167, loss:0.00000, loss_test:0.12394, lr:4.09e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.982, tt:5205.033\n",
      "Ep:168, loss:0.00000, loss_test:0.12059, lr:4.05e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.009, tt:5240.487\n",
      "Ep:169, loss:0.00000, loss_test:0.12222, lr:4.01e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.006, tt:5271.018\n",
      "Ep:170, loss:0.00000, loss_test:0.12123, lr:3.97e-03, fs:0.74251 (r=0.626,p=0.912),  time:31.002, tt:5301.331\n",
      "Ep:171, loss:0.00000, loss_test:0.12107, lr:3.93e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.006, tt:5333.093\n",
      "Ep:172, loss:0.00000, loss_test:0.12321, lr:3.89e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.005, tt:5363.831\n",
      "Ep:173, loss:0.00000, loss_test:0.12233, lr:3.85e-03, fs:0.75152 (r=0.626,p=0.939),  time:31.001, tt:5394.163\n",
      "Ep:174, loss:0.00000, loss_test:0.12085, lr:3.81e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.997, tt:5424.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:175, loss:0.00000, loss_test:0.12246, lr:3.77e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.986, tt:5453.580\n",
      "Ep:176, loss:0.00000, loss_test:0.12096, lr:3.73e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.984, tt:5484.132\n",
      "Ep:177, loss:0.00000, loss_test:0.12041, lr:3.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.981, tt:5514.564\n",
      "Ep:178, loss:0.00000, loss_test:0.12251, lr:3.66e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.980, tt:5545.400\n",
      "Ep:179, loss:0.00000, loss_test:0.12195, lr:3.62e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.973, tt:5575.161\n",
      "Ep:180, loss:0.00000, loss_test:0.12187, lr:3.59e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.972, tt:5605.891\n",
      "Ep:181, loss:0.00000, loss_test:0.12224, lr:3.55e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.974, tt:5637.201\n",
      "Ep:182, loss:0.00000, loss_test:0.12185, lr:3.52e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.974, tt:5668.225\n",
      "Ep:183, loss:0.00000, loss_test:0.12017, lr:3.48e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.980, tt:5700.385\n",
      "Ep:184, loss:0.00000, loss_test:0.12229, lr:3.45e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.985, tt:5732.185\n",
      "Ep:185, loss:0.00000, loss_test:0.12306, lr:3.41e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.982, tt:5762.568\n",
      "Ep:186, loss:0.00000, loss_test:0.12222, lr:3.38e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.982, tt:5793.573\n",
      "Ep:187, loss:0.00000, loss_test:0.12279, lr:3.34e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.990, tt:5826.173\n",
      "Ep:188, loss:0.00000, loss_test:0.12240, lr:3.31e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.990, tt:5857.044\n",
      "Ep:189, loss:0.00000, loss_test:0.12190, lr:3.28e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.992, tt:5888.508\n",
      "Ep:190, loss:0.00000, loss_test:0.12117, lr:3.24e-03, fs:0.73494 (r=0.616,p=0.910),  time:30.990, tt:5919.179\n",
      "Ep:191, loss:0.00000, loss_test:0.12274, lr:3.21e-03, fs:0.73494 (r=0.616,p=0.910),  time:30.992, tt:5950.391\n",
      "Ep:192, loss:0.00000, loss_test:0.12235, lr:3.18e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.986, tt:5980.258\n",
      "Ep:193, loss:0.00000, loss_test:0.12321, lr:3.15e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.982, tt:6010.451\n",
      "Ep:194, loss:0.00000, loss_test:0.12318, lr:3.12e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.983, tt:6041.663\n",
      "Ep:195, loss:0.00000, loss_test:0.12129, lr:3.09e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.986, tt:6073.236\n",
      "Ep:196, loss:0.00000, loss_test:0.12243, lr:3.05e-03, fs:0.73494 (r=0.616,p=0.910),  time:30.973, tt:6101.696\n",
      "Ep:197, loss:0.00000, loss_test:0.12172, lr:3.02e-03, fs:0.73939 (r=0.616,p=0.924),  time:30.960, tt:6130.151\n",
      "Ep:198, loss:0.00000, loss_test:0.12265, lr:2.99e-03, fs:0.73171 (r=0.606,p=0.923),  time:30.942, tt:6157.447\n",
      "Ep:199, loss:0.00000, loss_test:0.12295, lr:2.96e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.918, tt:6183.571\n",
      "Ep:200, loss:0.00000, loss_test:0.12198, lr:2.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:30.886, tt:6208.062\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02044, lr:6.00e-02, fs:0.63636 (r=0.848,p=0.509),  time:26.322, tt:26.322\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02261, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.414, tt:52.828\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02457, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.981, tt:83.943\n",
      "Ep:3, loss:0.00005, loss_test:0.02507, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.651, tt:114.604\n",
      "Ep:4, loss:0.00005, loss_test:0.02481, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.060, tt:145.300\n",
      "Ep:5, loss:0.00005, loss_test:0.02393, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.286, tt:175.715\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02275, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:29.593, tt:207.152\n",
      "Ep:7, loss:0.00004, loss_test:0.02164, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:29.816, tt:238.527\n",
      "Ep:8, loss:0.00004, loss_test:0.02064, lr:6.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:29.861, tt:268.751\n",
      "Ep:9, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:29.993, tt:299.934\n",
      "Ep:10, loss:0.00004, loss_test:0.01917, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:29.926, tt:329.189\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:29.995, tt:359.941\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01817, lr:6.00e-02, fs:0.71373 (r=0.919,p=0.583),  time:30.055, tt:390.719\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01784, lr:6.00e-02, fs:0.73004 (r=0.970,p=0.585),  time:30.170, tt:422.385\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01756, lr:6.00e-02, fs:0.73563 (r=0.970,p=0.593),  time:30.084, tt:451.259\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01726, lr:6.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:30.021, tt:480.336\n",
      "Ep:16, loss:0.00003, loss_test:0.01695, lr:6.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:30.104, tt:511.771\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:30.117, tt:542.101\n",
      "Ep:18, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:30.082, tt:571.555\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:30.062, tt:601.237\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:29.922, tt:628.359\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01575, lr:6.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:29.837, tt:656.419\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.76680 (r=0.980,p=0.630),  time:29.870, tt:687.008\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.76680 (r=0.980,p=0.630),  time:29.835, tt:716.029\n",
      "Ep:24, loss:0.00003, loss_test:0.01529, lr:6.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:29.823, tt:745.569\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:29.855, tt:776.242\n",
      "Ep:26, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:29.844, tt:805.777\n",
      "Ep:27, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.76800 (r=0.970,p=0.636),  time:29.809, tt:834.657\n",
      "Ep:28, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:29.794, tt:864.029\n",
      "Ep:29, loss:0.00003, loss_test:0.01466, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:29.793, tt:893.803\n",
      "Ep:30, loss:0.00003, loss_test:0.01451, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.789, tt:923.451\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01435, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.815, tt:954.091\n",
      "Ep:32, loss:0.00003, loss_test:0.01420, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:29.812, tt:983.806\n",
      "Ep:33, loss:0.00003, loss_test:0.01407, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:29.821, tt:1013.914\n",
      "Ep:34, loss:0.00003, loss_test:0.01395, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:29.788, tt:1042.589\n",
      "Ep:35, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:29.798, tt:1072.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:29.799, tt:1102.575\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:29.812, tt:1132.856\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:29.843, tt:1163.892\n",
      "Ep:39, loss:0.00002, loss_test:0.01343, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:29.874, tt:1194.956\n",
      "Ep:40, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:29.929, tt:1227.071\n",
      "Ep:41, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:29.944, tt:1257.642\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:30.029, tt:1291.237\n",
      "Ep:43, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:30.051, tt:1322.248\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01292, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:30.061, tt:1352.722\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.81938 (r=0.939,p=0.727),  time:30.094, tt:1384.325\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:30.121, tt:1415.670\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01265, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.159, tt:1447.654\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01256, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.195, tt:1479.550\n",
      "Ep:49, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.209, tt:1510.473\n",
      "Ep:50, loss:0.00002, loss_test:0.01241, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.243, tt:1542.413\n",
      "Ep:51, loss:0.00002, loss_test:0.01234, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:30.257, tt:1573.380\n",
      "Ep:52, loss:0.00002, loss_test:0.01228, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:30.261, tt:1603.806\n",
      "Ep:53, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:30.264, tt:1634.251\n",
      "Ep:54, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:30.351, tt:1669.323\n",
      "Ep:55, loss:0.00002, loss_test:0.01210, lr:6.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:30.380, tt:1701.275\n",
      "Ep:56, loss:0.00002, loss_test:0.01204, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:30.411, tt:1733.442\n",
      "Ep:57, loss:0.00002, loss_test:0.01199, lr:6.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:30.437, tt:1765.344\n",
      "Ep:58, loss:0.00002, loss_test:0.01193, lr:6.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:30.450, tt:1796.526\n",
      "Ep:59, loss:0.00002, loss_test:0.01188, lr:5.94e-02, fs:0.82192 (r=0.909,p=0.750),  time:30.479, tt:1828.748\n",
      "Ep:60, loss:0.00002, loss_test:0.01182, lr:5.88e-02, fs:0.81651 (r=0.899,p=0.748),  time:30.514, tt:1861.362\n",
      "Ep:61, loss:0.00002, loss_test:0.01180, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:30.542, tt:1893.625\n",
      "Ep:62, loss:0.00002, loss_test:0.01176, lr:5.76e-02, fs:0.81481 (r=0.889,p=0.752),  time:30.557, tt:1925.079\n",
      "Ep:63, loss:0.00002, loss_test:0.01169, lr:5.71e-02, fs:0.81481 (r=0.889,p=0.752),  time:30.578, tt:1957.002\n",
      "Ep:64, loss:0.00002, loss_test:0.01163, lr:5.65e-02, fs:0.81481 (r=0.889,p=0.752),  time:30.583, tt:1987.909\n",
      "Ep:65, loss:0.00002, loss_test:0.01158, lr:5.59e-02, fs:0.81481 (r=0.889,p=0.752),  time:30.588, tt:2018.825\n",
      "Ep:66, loss:0.00002, loss_test:0.01157, lr:5.54e-02, fs:0.81860 (r=0.889,p=0.759),  time:30.614, tt:2051.127\n",
      "Ep:67, loss:0.00001, loss_test:0.01154, lr:5.48e-02, fs:0.81860 (r=0.889,p=0.759),  time:30.641, tt:2083.598\n",
      "Ep:68, loss:0.00001, loss_test:0.01151, lr:5.43e-02, fs:0.81308 (r=0.879,p=0.757),  time:30.653, tt:2115.044\n",
      "Ep:69, loss:0.00001, loss_test:0.01147, lr:5.37e-02, fs:0.82075 (r=0.879,p=0.770),  time:30.676, tt:2147.341\n",
      "Ep:70, loss:0.00001, loss_test:0.01144, lr:5.32e-02, fs:0.82075 (r=0.879,p=0.770),  time:30.703, tt:2179.921\n",
      "Ep:71, loss:0.00001, loss_test:0.01141, lr:5.27e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.706, tt:2210.840\n",
      "Ep:72, loss:0.00001, loss_test:0.01138, lr:5.21e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.715, tt:2242.206\n",
      "Ep:73, loss:0.00001, loss_test:0.01137, lr:5.16e-02, fs:0.82857 (r=0.879,p=0.784),  time:30.711, tt:2272.633\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01135, lr:5.16e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.724, tt:2304.331\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01130, lr:5.16e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.733, tt:2335.702\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01128, lr:5.16e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.753, tt:2367.986\n",
      "Ep:77, loss:0.00001, loss_test:0.01125, lr:5.16e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.759, tt:2399.200\n",
      "Ep:78, loss:0.00001, loss_test:0.01124, lr:5.16e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.761, tt:2430.143\n",
      "Ep:79, loss:0.00001, loss_test:0.01123, lr:5.16e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.780, tt:2462.414\n",
      "Ep:80, loss:0.00001, loss_test:0.01122, lr:5.16e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.782, tt:2493.380\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01119, lr:5.16e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.806, tt:2526.063\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01116, lr:5.16e-02, fs:0.84878 (r=0.879,p=0.821),  time:30.813, tt:2557.492\n",
      "Ep:83, loss:0.00001, loss_test:0.01116, lr:5.16e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.821, tt:2588.959\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01115, lr:5.16e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.839, tt:2621.286\n",
      "Ep:85, loss:0.00001, loss_test:0.01113, lr:5.16e-02, fs:0.85294 (r=0.879,p=0.829),  time:30.843, tt:2652.529\n",
      "Ep:86, loss:0.00001, loss_test:0.01112, lr:5.16e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.855, tt:2684.419\n",
      "Ep:87, loss:0.00001, loss_test:0.01110, lr:5.16e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.863, tt:2715.977\n",
      "Ep:88, loss:0.00001, loss_test:0.01109, lr:5.16e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.864, tt:2746.928\n",
      "Ep:89, loss:0.00001, loss_test:0.01107, lr:5.16e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.862, tt:2777.619\n",
      "Ep:90, loss:0.00001, loss_test:0.01103, lr:5.16e-02, fs:0.85149 (r=0.869,p=0.835),  time:30.860, tt:2808.295\n",
      "Ep:91, loss:0.00001, loss_test:0.01103, lr:5.16e-02, fs:0.85149 (r=0.869,p=0.835),  time:30.844, tt:2837.606\n",
      "Ep:92, loss:0.00001, loss_test:0.01104, lr:5.16e-02, fs:0.85149 (r=0.869,p=0.835),  time:30.844, tt:2868.512\n",
      "Ep:93, loss:0.00001, loss_test:0.01105, lr:5.16e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.850, tt:2899.867\n",
      "Ep:94, loss:0.00001, loss_test:0.01104, lr:5.16e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.847, tt:2930.462\n",
      "Ep:95, loss:0.00001, loss_test:0.01099, lr:5.11e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.862, tt:2962.784\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01098, lr:5.11e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.869, tt:2994.308\n",
      "Ep:97, loss:0.00001, loss_test:0.01102, lr:5.11e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.875, tt:3025.751\n",
      "Ep:98, loss:0.00001, loss_test:0.01101, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.883, tt:3057.378\n",
      "Ep:99, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.85427 (r=0.859,p=0.850),  time:30.888, tt:3088.838\n",
      "Ep:100, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.894, tt:3120.281\n",
      "Ep:101, loss:0.00001, loss_test:0.01100, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.895, tt:3151.330\n",
      "Ep:102, loss:0.00001, loss_test:0.01099, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.901, tt:3182.804\n",
      "Ep:103, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.912, tt:3214.808\n",
      "Ep:104, loss:0.00001, loss_test:0.01098, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.901, tt:3244.619\n",
      "Ep:105, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.897, tt:3275.118\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00001, loss_test:0.01100, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.899, tt:3306.167\n",
      "Ep:107, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.895, tt:3336.694\n",
      "Ep:108, loss:0.00001, loss_test:0.01094, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.905, tt:3368.637\n",
      "Ep:109, loss:0.00001, loss_test:0.01093, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.893, tt:3398.260\n",
      "Ep:110, loss:0.00001, loss_test:0.01095, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.902, tt:3430.090\n",
      "Ep:111, loss:0.00001, loss_test:0.01094, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.913, tt:3462.217\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00001, loss_test:0.01094, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.904, tt:3492.133\n",
      "Ep:113, loss:0.00001, loss_test:0.01095, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.920, tt:3524.912\n",
      "Ep:114, loss:0.00001, loss_test:0.01093, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.905, tt:3554.037\n",
      "Ep:115, loss:0.00001, loss_test:0.01095, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.899, tt:3584.271\n",
      "Ep:116, loss:0.00001, loss_test:0.01096, lr:5.11e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.898, tt:3615.044\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.01096, lr:5.11e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.901, tt:3646.335\n",
      "Ep:118, loss:0.00001, loss_test:0.01099, lr:5.11e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.901, tt:3677.208\n",
      "Ep:119, loss:0.00001, loss_test:0.01098, lr:5.11e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.908, tt:3708.926\n",
      "Ep:120, loss:0.00001, loss_test:0.01093, lr:5.11e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.913, tt:3740.493\n",
      "Ep:121, loss:0.00001, loss_test:0.01096, lr:5.11e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.915, tt:3771.603\n",
      "Ep:122, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.922, tt:3803.462\n",
      "Ep:123, loss:0.00001, loss_test:0.01097, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.919, tt:3833.921\n",
      "Ep:124, loss:0.00001, loss_test:0.01096, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.915, tt:3864.427\n",
      "Ep:125, loss:0.00001, loss_test:0.01099, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.919, tt:3895.834\n",
      "Ep:126, loss:0.00001, loss_test:0.01100, lr:5.11e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.927, tt:3927.741\n",
      "Ep:127, loss:0.00001, loss_test:0.01100, lr:5.11e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.918, tt:3957.508\n",
      "Ep:128, loss:0.00001, loss_test:0.01099, lr:5.06e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.917, tt:3988.251\n",
      "Ep:129, loss:0.00001, loss_test:0.01101, lr:5.01e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.903, tt:4017.430\n",
      "Ep:130, loss:0.00001, loss_test:0.01103, lr:4.96e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.900, tt:4047.844\n",
      "Ep:131, loss:0.00001, loss_test:0.01103, lr:4.91e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.903, tt:4079.147\n",
      "Ep:132, loss:0.00001, loss_test:0.01103, lr:4.86e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.891, tt:4108.449\n",
      "Ep:133, loss:0.00001, loss_test:0.01101, lr:4.81e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.871, tt:4136.734\n",
      "Ep:134, loss:0.00001, loss_test:0.01103, lr:4.76e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.854, tt:4165.348\n",
      "Ep:135, loss:0.00001, loss_test:0.01104, lr:4.71e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.877, tt:4199.291\n",
      "Ep:136, loss:0.00001, loss_test:0.01106, lr:4.67e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.880, tt:4230.613\n",
      "Ep:137, loss:0.00001, loss_test:0.01108, lr:4.62e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.878, tt:4261.164\n",
      "Ep:138, loss:0.00001, loss_test:0.01106, lr:4.57e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.881, tt:4292.482\n",
      "Ep:139, loss:0.00001, loss_test:0.01108, lr:4.53e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.885, tt:4323.937\n",
      "Ep:140, loss:0.00001, loss_test:0.01109, lr:4.48e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.872, tt:4352.903\n",
      "Ep:141, loss:0.00001, loss_test:0.01111, lr:4.44e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.851, tt:4380.833\n",
      "Ep:142, loss:0.00001, loss_test:0.01110, lr:4.39e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.853, tt:4411.928\n",
      "Ep:143, loss:0.00001, loss_test:0.01110, lr:4.35e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.855, tt:4443.140\n",
      "Ep:144, loss:0.00001, loss_test:0.01111, lr:4.31e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.848, tt:4472.924\n",
      "Ep:145, loss:0.00001, loss_test:0.01111, lr:4.26e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.847, tt:4503.734\n",
      "Ep:146, loss:0.00001, loss_test:0.01114, lr:4.22e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.835, tt:4532.812\n",
      "Ep:147, loss:0.00001, loss_test:0.01114, lr:4.18e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.835, tt:4563.634\n",
      "Ep:148, loss:0.00001, loss_test:0.01117, lr:4.14e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.845, tt:4595.841\n",
      "Ep:149, loss:0.00001, loss_test:0.01117, lr:4.10e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.847, tt:4627.115\n",
      "Ep:150, loss:0.00001, loss_test:0.01117, lr:4.05e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.844, tt:4657.370\n",
      "Ep:151, loss:0.00001, loss_test:0.01118, lr:4.01e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.840, tt:4687.659\n",
      "Ep:152, loss:0.00001, loss_test:0.01121, lr:3.97e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.838, tt:4718.153\n",
      "Ep:153, loss:0.00001, loss_test:0.01121, lr:3.93e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.838, tt:4749.057\n",
      "Ep:154, loss:0.00001, loss_test:0.01119, lr:3.89e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.832, tt:4778.992\n",
      "Ep:155, loss:0.00001, loss_test:0.01122, lr:3.86e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.841, tt:4811.224\n",
      "Ep:156, loss:0.00001, loss_test:0.01124, lr:3.82e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.830, tt:4840.259\n",
      "Ep:157, loss:0.00001, loss_test:0.01125, lr:3.78e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.836, tt:4872.123\n",
      "Ep:158, loss:0.00001, loss_test:0.01127, lr:3.74e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.840, tt:4903.554\n",
      "Ep:159, loss:0.00001, loss_test:0.01130, lr:3.70e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.844, tt:4934.989\n",
      "Ep:160, loss:0.00001, loss_test:0.01131, lr:3.67e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.844, tt:4965.936\n",
      "Ep:161, loss:0.00001, loss_test:0.01129, lr:3.63e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.845, tt:4996.819\n",
      "Ep:162, loss:0.00001, loss_test:0.01130, lr:3.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.845, tt:5027.771\n",
      "Ep:163, loss:0.00001, loss_test:0.01132, lr:3.56e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.837, tt:5057.243\n",
      "Ep:164, loss:0.00001, loss_test:0.01134, lr:3.52e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.841, tt:5088.847\n",
      "Ep:165, loss:0.00001, loss_test:0.01135, lr:3.49e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.840, tt:5119.382\n",
      "Ep:166, loss:0.00001, loss_test:0.01134, lr:3.45e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.839, tt:5150.064\n",
      "Ep:167, loss:0.00001, loss_test:0.01137, lr:3.42e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.838, tt:5180.723\n",
      "Ep:168, loss:0.00001, loss_test:0.01140, lr:3.38e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.830, tt:5210.326\n",
      "Ep:169, loss:0.00001, loss_test:0.01141, lr:3.35e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.841, tt:5242.997\n",
      "Ep:170, loss:0.00001, loss_test:0.01139, lr:3.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.845, tt:5274.479\n",
      "Ep:171, loss:0.00001, loss_test:0.01141, lr:3.28e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.852, tt:5306.610\n",
      "Ep:172, loss:0.00001, loss_test:0.01142, lr:3.25e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.852, tt:5337.353\n",
      "Ep:173, loss:0.00001, loss_test:0.01144, lr:3.22e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.872, tt:5371.768\n",
      "Ep:174, loss:0.00001, loss_test:0.01141, lr:3.19e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.871, tt:5402.359\n",
      "Ep:175, loss:0.00001, loss_test:0.01141, lr:3.15e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.878, tt:5434.601\n",
      "Ep:176, loss:0.00001, loss_test:0.01144, lr:3.12e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.875, tt:5464.939\n",
      "Ep:177, loss:0.00001, loss_test:0.01148, lr:3.09e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.879, tt:5496.445\n",
      "Ep:178, loss:0.00001, loss_test:0.01149, lr:3.06e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.876, tt:5526.856\n",
      "Ep:179, loss:0.00001, loss_test:0.01146, lr:3.03e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.870, tt:5556.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00001, loss_test:0.01148, lr:3.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.855, tt:5584.823\n",
      "Ep:181, loss:0.00000, loss_test:0.01151, lr:2.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.853, tt:5615.209\n",
      "Ep:182, loss:0.00000, loss_test:0.01152, lr:2.94e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.848, tt:5645.148\n",
      "Ep:183, loss:0.00000, loss_test:0.01152, lr:2.91e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.848, tt:5675.970\n",
      "Ep:184, loss:0.00000, loss_test:0.01151, lr:2.88e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.847, tt:5706.625\n",
      "Ep:185, loss:0.00000, loss_test:0.01153, lr:2.85e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.843, tt:5736.759\n",
      "Ep:186, loss:0.00000, loss_test:0.01155, lr:2.82e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.849, tt:5768.739\n",
      "Ep:187, loss:0.00000, loss_test:0.01157, lr:2.80e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.843, tt:5798.442\n",
      "Ep:188, loss:0.00000, loss_test:0.01157, lr:2.77e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.842, tt:5829.048\n",
      "Ep:189, loss:0.00000, loss_test:0.01156, lr:2.74e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.838, tt:5859.307\n",
      "Ep:190, loss:0.00000, loss_test:0.01156, lr:2.71e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.834, tt:5889.283\n",
      "Ep:191, loss:0.00000, loss_test:0.01159, lr:2.69e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.829, tt:5919.176\n",
      "Ep:192, loss:0.00000, loss_test:0.01161, lr:2.66e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.826, tt:5949.359\n",
      "Ep:193, loss:0.00000, loss_test:0.01161, lr:2.63e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.819, tt:5978.966\n",
      "Ep:194, loss:0.00000, loss_test:0.01161, lr:2.61e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.825, tt:6010.836\n",
      "Ep:195, loss:0.00000, loss_test:0.01162, lr:2.58e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.821, tt:6040.998\n",
      "Ep:196, loss:0.00000, loss_test:0.01162, lr:2.55e-02, fs:0.81111 (r=0.737,p=0.901),  time:30.821, tt:6071.768\n",
      "Ep:197, loss:0.00000, loss_test:0.01163, lr:2.53e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.823, tt:6103.005\n",
      "Ep:198, loss:0.00000, loss_test:0.01164, lr:2.50e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.818, tt:6132.711\n",
      "Ep:199, loss:0.00000, loss_test:0.01164, lr:2.48e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.816, tt:6163.133\n",
      "Ep:200, loss:0.00000, loss_test:0.01166, lr:2.45e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.805, tt:6191.809\n",
      "Ep:201, loss:0.00000, loss_test:0.01167, lr:2.43e-02, fs:0.80000 (r=0.727,p=0.889),  time:30.809, tt:6223.461\n",
      "Ep:202, loss:0.00000, loss_test:0.01169, lr:2.40e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.801, tt:6252.544\n",
      "Ep:203, loss:0.00000, loss_test:0.01169, lr:2.38e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.787, tt:6280.599\n",
      "Ep:204, loss:0.00000, loss_test:0.01169, lr:2.36e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.778, tt:6309.586\n",
      "Ep:205, loss:0.00000, loss_test:0.01170, lr:2.33e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.788, tt:6342.334\n",
      "Ep:206, loss:0.00000, loss_test:0.01170, lr:2.31e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.773, tt:6370.009\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14016, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.354, tt:26.354\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13854, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:29.064, tt:58.127\n",
      "Ep:2, loss:0.00027, loss_test:0.13560, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:29.755, tt:89.266\n",
      "Ep:3, loss:0.00026, loss_test:0.13116, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:29.995, tt:119.980\n",
      "Ep:4, loss:0.00025, loss_test:0.12559, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:30.671, tt:153.354\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12020, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:30.805, tt:184.832\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11625, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:30.932, tt:216.525\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11324, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:31.206, tt:249.646\n",
      "Ep:8, loss:0.00022, loss_test:0.11080, lr:1.00e-02, fs:0.68161 (r=0.768,p=0.613),  time:31.226, tt:281.031\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10751, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:31.338, tt:313.380\n",
      "Ep:10, loss:0.00021, loss_test:0.10568, lr:1.00e-02, fs:0.66341 (r=0.687,p=0.642),  time:31.418, tt:345.603\n",
      "Ep:11, loss:0.00020, loss_test:0.10499, lr:1.00e-02, fs:0.66990 (r=0.697,p=0.645),  time:31.503, tt:378.042\n",
      "Ep:12, loss:0.00020, loss_test:0.10356, lr:1.00e-02, fs:0.66990 (r=0.697,p=0.645),  time:31.616, tt:411.006\n",
      "Ep:13, loss:0.00019, loss_test:0.10116, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:31.654, tt:443.152\n",
      "Ep:14, loss:0.00019, loss_test:0.09904, lr:1.00e-02, fs:0.67677 (r=0.677,p=0.677),  time:31.692, tt:475.384\n",
      "Ep:15, loss:0.00018, loss_test:0.09788, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:31.688, tt:507.012\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09568, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:31.828, tt:541.083\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09354, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:31.890, tt:574.011\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09173, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:31.907, tt:606.237\n",
      "Ep:19, loss:0.00016, loss_test:0.09084, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:31.906, tt:638.128\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08960, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:31.870, tt:669.270\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08815, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:31.944, tt:702.772\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08696, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:31.887, tt:733.401\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08623, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:31.993, tt:767.832\n",
      "Ep:24, loss:0.00014, loss_test:0.08497, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:32.019, tt:800.474\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08437, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:32.030, tt:832.780\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08385, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:32.014, tt:864.389\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08221, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:32.019, tt:896.534\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08101, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:32.044, tt:929.274\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08075, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:31.974, tt:959.226\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07940, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:31.957, tt:990.663\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07873, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:31.961, tt:1022.736\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07828, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:31.978, tt:1055.272\n",
      "Ep:33, loss:0.00011, loss_test:0.07638, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:31.992, tt:1087.720\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.07637, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:32.002, tt:1120.069\n",
      "Ep:35, loss:0.00011, loss_test:0.07513, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:31.998, tt:1151.918\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00011, loss_test:0.07427, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:32.022, tt:1184.809\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07421, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:32.027, tt:1217.028\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07244, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:32.011, tt:1312.470\n",
      "Ep:41, loss:0.00009, loss_test:0.07050, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:31.977, tt:1343.041\n",
      "Ep:42, loss:0.00009, loss_test:0.07209, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.979, tt:1375.093\n",
      "Ep:43, loss:0.00009, loss_test:0.07012, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:31.980, tt:1407.101\n",
      "Ep:44, loss:0.00009, loss_test:0.07041, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.987, tt:1439.409\n",
      "Ep:45, loss:0.00009, loss_test:0.06900, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:32.023, tt:1473.079\n",
      "Ep:46, loss:0.00008, loss_test:0.07005, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:32.017, tt:1504.806\n",
      "Ep:47, loss:0.00008, loss_test:0.06856, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:32.003, tt:1536.153\n",
      "Ep:48, loss:0.00008, loss_test:0.06945, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:32.008, tt:1568.380\n",
      "Ep:49, loss:0.00008, loss_test:0.06692, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:31.973, tt:1598.664\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.06817, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.996, tt:1631.771\n",
      "Ep:51, loss:0.00008, loss_test:0.06681, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:32.013, tt:1664.660\n",
      "Ep:52, loss:0.00007, loss_test:0.06673, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:32.039, tt:1698.086\n",
      "Ep:53, loss:0.00007, loss_test:0.06717, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:32.046, tt:1730.502\n",
      "Ep:54, loss:0.00007, loss_test:0.06459, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:32.022, tt:1761.197\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.06660, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:32.050, tt:1794.812\n",
      "Ep:56, loss:0.00007, loss_test:0.06442, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:32.029, tt:1825.679\n",
      "Ep:57, loss:0.00006, loss_test:0.06575, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:32.038, tt:1858.231\n",
      "Ep:58, loss:0.00006, loss_test:0.06551, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:32.051, tt:1891.031\n",
      "Ep:59, loss:0.00006, loss_test:0.06361, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:32.069, tt:1924.133\n",
      "Ep:60, loss:0.00006, loss_test:0.06579, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:32.076, tt:1956.609\n",
      "Ep:61, loss:0.00006, loss_test:0.06252, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:32.088, tt:1989.477\n",
      "Ep:62, loss:0.00006, loss_test:0.06536, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:32.112, tt:2023.052\n",
      "Ep:63, loss:0.00005, loss_test:0.06289, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:32.118, tt:2055.582\n",
      "Ep:64, loss:0.00005, loss_test:0.06484, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:32.119, tt:2087.726\n",
      "Ep:65, loss:0.00005, loss_test:0.06141, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:32.148, tt:2121.793\n",
      "Ep:66, loss:0.00005, loss_test:0.06365, lr:9.90e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.147, tt:2153.853\n",
      "Ep:67, loss:0.00005, loss_test:0.06340, lr:9.80e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.141, tt:2185.559\n",
      "Ep:68, loss:0.00005, loss_test:0.06316, lr:9.70e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.155, tt:2218.671\n",
      "Ep:69, loss:0.00005, loss_test:0.06184, lr:9.61e-03, fs:0.80874 (r=0.747,p=0.881),  time:32.168, tt:2251.729\n",
      "Ep:70, loss:0.00005, loss_test:0.06246, lr:9.51e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.172, tt:2284.240\n",
      "Ep:71, loss:0.00004, loss_test:0.06317, lr:9.41e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.171, tt:2316.323\n",
      "Ep:72, loss:0.00004, loss_test:0.06152, lr:9.32e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.167, tt:2348.171\n",
      "Ep:73, loss:0.00004, loss_test:0.06302, lr:9.23e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.155, tt:2379.454\n",
      "Ep:74, loss:0.00004, loss_test:0.06189, lr:9.14e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.156, tt:2411.681\n",
      "Ep:75, loss:0.00004, loss_test:0.06182, lr:9.04e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.182, tt:2445.821\n",
      "Ep:76, loss:0.00004, loss_test:0.06185, lr:8.95e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.191, tt:2478.676\n",
      "Ep:77, loss:0.00004, loss_test:0.06111, lr:8.86e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.205, tt:2511.964\n",
      "Ep:78, loss:0.00004, loss_test:0.06098, lr:8.78e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.212, tt:2544.771\n",
      "Ep:79, loss:0.00004, loss_test:0.06062, lr:8.69e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.220, tt:2577.598\n",
      "Ep:80, loss:0.00004, loss_test:0.06036, lr:8.60e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.210, tt:2609.021\n",
      "Ep:81, loss:0.00003, loss_test:0.05954, lr:8.51e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.201, tt:2640.497\n",
      "Ep:82, loss:0.00003, loss_test:0.06080, lr:8.43e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.180, tt:2670.952\n",
      "Ep:83, loss:0.00003, loss_test:0.06012, lr:8.35e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.163, tt:2701.727\n",
      "Ep:84, loss:0.00003, loss_test:0.05942, lr:8.26e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.162, tt:2733.791\n",
      "Ep:85, loss:0.00003, loss_test:0.06045, lr:8.18e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.159, tt:2765.674\n",
      "Ep:86, loss:0.00003, loss_test:0.06024, lr:8.10e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.151, tt:2797.094\n",
      "Ep:87, loss:0.00003, loss_test:0.05991, lr:8.02e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.147, tt:2828.952\n",
      "Ep:88, loss:0.00003, loss_test:0.05900, lr:7.94e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.151, tt:2861.410\n",
      "Ep:89, loss:0.00003, loss_test:0.05852, lr:7.86e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.158, tt:2894.253\n",
      "Ep:90, loss:0.00003, loss_test:0.05916, lr:7.78e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.155, tt:2926.093\n",
      "Ep:91, loss:0.00003, loss_test:0.05723, lr:7.70e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.149, tt:2957.689\n",
      "Ep:92, loss:0.00003, loss_test:0.05908, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.150, tt:2989.984\n",
      "Ep:93, loss:0.00003, loss_test:0.05795, lr:7.55e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.154, tt:3022.449\n",
      "Ep:94, loss:0.00003, loss_test:0.05990, lr:7.47e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.152, tt:3054.400\n",
      "Ep:95, loss:0.00003, loss_test:0.05757, lr:7.40e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.154, tt:3086.829\n",
      "Ep:96, loss:0.00003, loss_test:0.05712, lr:7.32e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.172, tt:3120.653\n",
      "Ep:97, loss:0.00003, loss_test:0.05792, lr:7.25e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.177, tt:3153.313\n",
      "Ep:98, loss:0.00003, loss_test:0.05797, lr:7.18e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.183, tt:3186.151\n",
      "Ep:99, loss:0.00002, loss_test:0.05655, lr:7.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.166, tt:3216.605\n",
      "Ep:100, loss:0.00002, loss_test:0.05851, lr:7.03e-03, fs:0.83616 (r=0.747,p=0.949),  time:32.169, tt:3249.018\n",
      "Ep:101, loss:0.00002, loss_test:0.05647, lr:6.96e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.153, tt:3279.633\n",
      "Ep:102, loss:0.00002, loss_test:0.05928, lr:6.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:32.153, tt:3311.800\n",
      "Ep:103, loss:0.00002, loss_test:0.05686, lr:6.83e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.162, tt:3344.818\n",
      "Ep:104, loss:0.00002, loss_test:0.05730, lr:6.76e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.157, tt:3376.521\n",
      "Ep:105, loss:0.00002, loss_test:0.05710, lr:6.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.147, tt:3407.612\n",
      "Ep:106, loss:0.00002, loss_test:0.05650, lr:6.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.177, tt:3442.923\n",
      "Ep:107, loss:0.00002, loss_test:0.05696, lr:6.56e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.169, tt:3474.271\n",
      "Ep:108, loss:0.00002, loss_test:0.05731, lr:6.49e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.170, tt:3506.578\n",
      "Ep:109, loss:0.00002, loss_test:0.05685, lr:6.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.164, tt:3538.057\n",
      "Ep:110, loss:0.00002, loss_test:0.05611, lr:6.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.141, tt:3567.606\n",
      "Ep:111, loss:0.00002, loss_test:0.05684, lr:6.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.119, tt:3597.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:112, loss:0.00002, loss_test:0.05551, lr:6.24e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.125, tt:3630.134\n",
      "Ep:113, loss:0.00002, loss_test:0.05812, lr:6.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.117, tt:3661.389\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00002, loss_test:0.05699, lr:6.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.106, tt:3692.243\n",
      "Ep:115, loss:0.00002, loss_test:0.05695, lr:6.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.103, tt:3723.978\n",
      "Ep:116, loss:0.00002, loss_test:0.05745, lr:6.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.102, tt:3755.901\n",
      "Ep:117, loss:0.00002, loss_test:0.05623, lr:6.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.094, tt:3787.140\n",
      "Ep:118, loss:0.00002, loss_test:0.05768, lr:6.17e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.100, tt:3819.852\n",
      "Ep:119, loss:0.00002, loss_test:0.05488, lr:6.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.116, tt:3853.945\n",
      "Ep:120, loss:0.00002, loss_test:0.05815, lr:6.17e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.113, tt:3885.684\n",
      "Ep:121, loss:0.00002, loss_test:0.05622, lr:6.17e-03, fs:0.83616 (r=0.747,p=0.949),  time:32.120, tt:3918.591\n",
      "Ep:122, loss:0.00002, loss_test:0.05602, lr:6.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:32.113, tt:3949.954\n",
      "Ep:123, loss:0.00002, loss_test:0.05790, lr:6.17e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.121, tt:3982.997\n",
      "Ep:124, loss:0.00002, loss_test:0.05467, lr:6.17e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.119, tt:4014.862\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00002, loss_test:0.05701, lr:6.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.118, tt:4046.894\n",
      "Ep:126, loss:0.00002, loss_test:0.05702, lr:6.17e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.125, tt:4079.902\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.05568, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.114, tt:4110.561\n",
      "Ep:128, loss:0.00002, loss_test:0.05624, lr:6.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.101, tt:4141.018\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00002, loss_test:0.05494, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.102, tt:4173.241\n",
      "Ep:130, loss:0.00002, loss_test:0.05754, lr:6.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.089, tt:4203.644\n",
      "Ep:131, loss:0.00002, loss_test:0.05450, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.085, tt:4235.272\n",
      "Ep:132, loss:0.00002, loss_test:0.05647, lr:6.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.072, tt:4265.627\n",
      "Ep:133, loss:0.00002, loss_test:0.05573, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.061, tt:4296.142\n",
      "Ep:134, loss:0.00002, loss_test:0.05520, lr:6.17e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.056, tt:4327.521\n",
      "Ep:135, loss:0.00002, loss_test:0.05565, lr:6.17e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.047, tt:4358.374\n",
      "Ep:136, loss:0.00002, loss_test:0.05481, lr:6.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.043, tt:4389.844\n",
      "Ep:137, loss:0.00002, loss_test:0.05511, lr:6.17e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.036, tt:4421.008\n",
      "Ep:138, loss:0.00002, loss_test:0.05527, lr:6.17e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.031, tt:4452.287\n",
      "Ep:139, loss:0.00002, loss_test:0.05492, lr:6.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.016, tt:4482.222\n",
      "Ep:140, loss:0.00001, loss_test:0.05488, lr:6.11e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.027, tt:4515.850\n",
      "Ep:141, loss:0.00001, loss_test:0.05476, lr:6.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.018, tt:4546.597\n",
      "Ep:142, loss:0.00001, loss_test:0.05524, lr:5.99e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.041, tt:4581.918\n",
      "Ep:143, loss:0.00001, loss_test:0.05478, lr:5.93e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.039, tt:4613.681\n",
      "Ep:144, loss:0.00001, loss_test:0.05551, lr:5.87e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.040, tt:4645.787\n",
      "Ep:145, loss:0.00001, loss_test:0.05470, lr:5.81e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.035, tt:4677.049\n",
      "Ep:146, loss:0.00001, loss_test:0.05523, lr:5.75e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.029, tt:4708.279\n",
      "Ep:147, loss:0.00001, loss_test:0.05499, lr:5.70e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.022, tt:4739.299\n",
      "Ep:148, loss:0.00001, loss_test:0.05502, lr:5.64e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.019, tt:4770.759\n",
      "Ep:149, loss:0.00001, loss_test:0.05474, lr:5.58e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.018, tt:4802.726\n",
      "Ep:150, loss:0.00001, loss_test:0.05507, lr:5.53e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.022, tt:4835.294\n",
      "Ep:151, loss:0.00001, loss_test:0.05519, lr:5.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.022, tt:4867.377\n",
      "Ep:152, loss:0.00001, loss_test:0.05434, lr:5.42e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.024, tt:4899.716\n",
      "Ep:153, loss:0.00001, loss_test:0.05541, lr:5.36e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.025, tt:4931.811\n",
      "Ep:154, loss:0.00001, loss_test:0.05461, lr:5.31e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.025, tt:4963.896\n",
      "Ep:155, loss:0.00001, loss_test:0.05455, lr:5.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.032, tt:4996.920\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00001, loss_test:0.05480, lr:5.26e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.036, tt:5029.628\n",
      "Ep:157, loss:0.00001, loss_test:0.05451, lr:5.26e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.036, tt:5061.635\n",
      "Ep:158, loss:0.00001, loss_test:0.05495, lr:5.26e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.027, tt:5092.313\n",
      "Ep:159, loss:0.00001, loss_test:0.05435, lr:5.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.028, tt:5124.408\n",
      "Ep:160, loss:0.00001, loss_test:0.05530, lr:5.26e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.028, tt:5156.480\n",
      "Ep:161, loss:0.00001, loss_test:0.05406, lr:5.26e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.025, tt:5188.023\n",
      "Ep:162, loss:0.00001, loss_test:0.05520, lr:5.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.033, tt:5221.440\n",
      "Ep:163, loss:0.00001, loss_test:0.05465, lr:5.26e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.024, tt:5251.983\n",
      "Ep:164, loss:0.00001, loss_test:0.05437, lr:5.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.024, tt:5284.041\n",
      "Ep:165, loss:0.00001, loss_test:0.05465, lr:5.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.019, tt:5315.188\n",
      "Ep:166, loss:0.00001, loss_test:0.05508, lr:5.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.017, tt:5346.779\n",
      "Ep:167, loss:0.00001, loss_test:0.05450, lr:5.20e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.020, tt:5379.310\n",
      "Ep:168, loss:0.00001, loss_test:0.05472, lr:5.15e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.044, tt:5415.366\n",
      "Ep:169, loss:0.00001, loss_test:0.05414, lr:5.10e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.038, tt:5446.376\n",
      "Ep:170, loss:0.00001, loss_test:0.05517, lr:5.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.032, tt:5477.436\n",
      "Ep:171, loss:0.00001, loss_test:0.05509, lr:5.00e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.031, tt:5509.376\n",
      "Ep:172, loss:0.00001, loss_test:0.05493, lr:4.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.031, tt:5541.406\n",
      "Ep:173, loss:0.00001, loss_test:0.05491, lr:4.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.029, tt:5573.096\n",
      "Ep:174, loss:0.00001, loss_test:0.05456, lr:4.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.036, tt:5606.356\n",
      "Ep:175, loss:0.00001, loss_test:0.05527, lr:4.80e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.040, tt:5639.047\n",
      "Ep:176, loss:0.00001, loss_test:0.05351, lr:4.75e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.046, tt:5672.065\n",
      "Ep:177, loss:0.00001, loss_test:0.05613, lr:4.71e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.052, tt:5705.312\n",
      "Ep:178, loss:0.00001, loss_test:0.05566, lr:4.66e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.053, tt:5737.431\n",
      "Ep:179, loss:0.00001, loss_test:0.05376, lr:4.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.057, tt:5770.183\n",
      "Ep:180, loss:0.00001, loss_test:0.05629, lr:4.57e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.056, tt:5802.217\n",
      "Ep:181, loss:0.00001, loss_test:0.05501, lr:4.52e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.063, tt:5835.439\n",
      "Ep:182, loss:0.00001, loss_test:0.05482, lr:4.48e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.065, tt:5867.895\n",
      "Ep:183, loss:0.00001, loss_test:0.05536, lr:4.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.059, tt:5898.821\n",
      "Ep:184, loss:0.00001, loss_test:0.05490, lr:4.39e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.061, tt:5931.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:185, loss:0.00001, loss_test:0.05455, lr:4.34e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.060, tt:5963.215\n",
      "Ep:186, loss:0.00001, loss_test:0.05476, lr:4.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.062, tt:5995.543\n",
      "Ep:187, loss:0.00001, loss_test:0.05436, lr:4.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.045, tt:6024.446\n",
      "Ep:188, loss:0.00001, loss_test:0.05505, lr:4.21e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.035, tt:6054.573\n",
      "Ep:189, loss:0.00001, loss_test:0.05467, lr:4.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.052, tt:6089.840\n",
      "Ep:190, loss:0.00001, loss_test:0.05413, lr:4.13e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.047, tt:6120.970\n",
      "Ep:191, loss:0.00001, loss_test:0.05549, lr:4.09e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.043, tt:6152.177\n",
      "Ep:192, loss:0.00001, loss_test:0.05465, lr:4.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.040, tt:6183.768\n",
      "Ep:193, loss:0.00001, loss_test:0.05453, lr:4.01e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.044, tt:6216.515\n",
      "Ep:194, loss:0.00001, loss_test:0.05540, lr:3.97e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.045, tt:6248.798\n",
      "Ep:195, loss:0.00001, loss_test:0.05432, lr:3.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.037, tt:6279.293\n",
      "Ep:196, loss:0.00001, loss_test:0.05510, lr:3.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.034, tt:6310.657\n",
      "Ep:197, loss:0.00001, loss_test:0.05456, lr:3.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.034, tt:6342.769\n",
      "Ep:198, loss:0.00001, loss_test:0.05520, lr:3.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.030, tt:6374.028\n",
      "Ep:199, loss:0.00001, loss_test:0.05533, lr:3.77e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.032, tt:6406.447\n",
      "Ep:200, loss:0.00001, loss_test:0.05459, lr:3.73e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.028, tt:6437.574\n",
      "Ep:201, loss:0.00001, loss_test:0.05489, lr:3.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.040, tt:6472.049\n",
      "Ep:202, loss:0.00001, loss_test:0.05469, lr:3.66e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.026, tt:6501.376\n",
      "Ep:203, loss:0.00001, loss_test:0.05562, lr:3.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.008, tt:6529.554\n",
      "Ep:204, loss:0.00001, loss_test:0.05570, lr:3.59e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.990, tt:6557.909\n",
      "Ep:205, loss:0.00001, loss_test:0.05436, lr:3.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.987, tt:6589.349\n",
      "Ep:206, loss:0.00001, loss_test:0.05533, lr:3.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.975, tt:6618.796\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02126, lr:6.00e-02, fs:0.65660 (r=0.879,p=0.524),  time:24.831, tt:24.831\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02397, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.035, tt:50.069\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02571, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.057, tt:78.171\n",
      "Ep:3, loss:0.00005, loss_test:0.02579, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.467, tt:105.870\n",
      "Ep:4, loss:0.00005, loss_test:0.02518, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.844, tt:134.221\n",
      "Ep:5, loss:0.00005, loss_test:0.02415, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:27.066, tt:162.396\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02305, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:27.223, tt:190.561\n",
      "Ep:7, loss:0.00004, loss_test:0.02223, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:27.498, tt:219.987\n",
      "Ep:8, loss:0.00004, loss_test:0.02178, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:27.676, tt:249.080\n",
      "Ep:9, loss:0.00004, loss_test:0.02142, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:27.788, tt:277.884\n",
      "Ep:10, loss:0.00004, loss_test:0.02069, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:27.846, tt:306.303\n",
      "Ep:11, loss:0.00004, loss_test:0.01982, lr:6.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:27.802, tt:333.628\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01909, lr:6.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:27.969, tt:363.602\n",
      "Ep:13, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:28.344, tt:396.817\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01814, lr:6.00e-02, fs:0.70849 (r=0.970,p=0.558),  time:28.429, tt:426.428\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01771, lr:6.00e-02, fs:0.71161 (r=0.960,p=0.565),  time:28.380, tt:454.086\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01735, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:28.464, tt:483.881\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01707, lr:6.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:28.387, tt:510.967\n",
      "Ep:18, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:28.409, tt:539.776\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.72941 (r=0.939,p=0.596),  time:28.455, tt:569.097\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:28.484, tt:598.163\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:28.587, tt:628.921\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:28.602, tt:657.837\n",
      "Ep:23, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:28.565, tt:685.552\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:28.627, tt:715.669\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:28.683, tt:745.751\n",
      "Ep:26, loss:0.00003, loss_test:0.01563, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:28.705, tt:775.043\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01551, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:28.677, tt:802.965\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:28.713, tt:832.690\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:28.708, tt:861.242\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:28.735, tt:890.795\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01504, lr:6.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:28.775, tt:920.785\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:28.784, tt:949.874\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01482, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:28.814, tt:979.687\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01472, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:28.816, tt:1008.556\n",
      "Ep:35, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:28.850, tt:1038.590\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:28.852, tt:1067.538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:37, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:28.903, tt:1098.318\n",
      "Ep:38, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:28.941, tt:1128.694\n",
      "Ep:39, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:29.012, tt:1160.478\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.022, tt:1189.913\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01419, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.046, tt:1219.929\n",
      "Ep:42, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.076, tt:1250.260\n",
      "Ep:43, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.102, tt:1280.507\n",
      "Ep:44, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:29.099, tt:1309.439\n",
      "Ep:45, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:29.094, tt:1338.343\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:29.161, tt:1370.580\n",
      "Ep:47, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:29.182, tt:1400.739\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:29.199, tt:1430.760\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:29.224, tt:1461.215\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:29.241, tt:1491.298\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:29.260, tt:1521.519\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:29.294, tt:1552.587\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:29.322, tt:1583.382\n",
      "Ep:54, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:29.350, tt:1614.274\n",
      "Ep:55, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:29.386, tt:1645.607\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01314, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:29.419, tt:1676.905\n",
      "Ep:57, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:29.462, tt:1708.788\n",
      "Ep:58, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:29.488, tt:1739.763\n",
      "Ep:59, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:29.509, tt:1770.543\n",
      "Ep:60, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:29.504, tt:1799.718\n",
      "Ep:61, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:29.514, tt:1829.845\n",
      "Ep:62, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:29.536, tt:1860.783\n",
      "Ep:63, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:29.549, tt:1891.147\n",
      "Ep:64, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:29.558, tt:1921.262\n",
      "Ep:65, loss:0.00002, loss_test:0.01278, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:29.556, tt:1950.711\n",
      "Ep:66, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:29.567, tt:1980.986\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:29.563, tt:2010.314\n",
      "Ep:68, loss:0.00002, loss_test:0.01267, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:29.560, tt:2039.633\n",
      "Ep:69, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:29.563, tt:2069.417\n",
      "Ep:70, loss:0.00001, loss_test:0.01260, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:29.542, tt:2097.517\n",
      "Ep:71, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:29.545, tt:2127.220\n",
      "Ep:72, loss:0.00001, loss_test:0.01253, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.549, tt:2157.051\n",
      "Ep:73, loss:0.00001, loss_test:0.01252, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.565, tt:2187.819\n",
      "Ep:74, loss:0.00001, loss_test:0.01251, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.554, tt:2216.578\n",
      "Ep:75, loss:0.00001, loss_test:0.01248, lr:6.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.573, tt:2247.553\n",
      "Ep:76, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.595, tt:2278.777\n",
      "Ep:77, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.588, tt:2307.890\n",
      "Ep:78, loss:0.00001, loss_test:0.01241, lr:5.94e-02, fs:0.81279 (r=0.899,p=0.742),  time:29.613, tt:2339.402\n",
      "Ep:79, loss:0.00001, loss_test:0.01238, lr:5.88e-02, fs:0.82407 (r=0.899,p=0.761),  time:29.613, tt:2369.025\n",
      "Ep:80, loss:0.00001, loss_test:0.01235, lr:5.82e-02, fs:0.82407 (r=0.899,p=0.761),  time:29.622, tt:2399.408\n",
      "Ep:81, loss:0.00001, loss_test:0.01232, lr:5.76e-02, fs:0.81690 (r=0.879,p=0.763),  time:29.632, tt:2429.851\n",
      "Ep:82, loss:0.00001, loss_test:0.01234, lr:5.71e-02, fs:0.80569 (r=0.859,p=0.759),  time:29.650, tt:2460.983\n",
      "Ep:83, loss:0.00001, loss_test:0.01232, lr:5.65e-02, fs:0.80569 (r=0.859,p=0.759),  time:29.662, tt:2491.606\n",
      "Ep:84, loss:0.00001, loss_test:0.01225, lr:5.59e-02, fs:0.81905 (r=0.869,p=0.775),  time:29.686, tt:2523.281\n",
      "Ep:85, loss:0.00001, loss_test:0.01227, lr:5.54e-02, fs:0.80769 (r=0.848,p=0.771),  time:29.715, tt:2555.487\n",
      "Ep:86, loss:0.00001, loss_test:0.01232, lr:5.48e-02, fs:0.80769 (r=0.848,p=0.771),  time:29.728, tt:2586.334\n",
      "Ep:87, loss:0.00001, loss_test:0.01229, lr:5.43e-02, fs:0.81159 (r=0.848,p=0.778),  time:29.748, tt:2617.829\n",
      "Ep:88, loss:0.00001, loss_test:0.01227, lr:5.37e-02, fs:0.81159 (r=0.848,p=0.778),  time:29.756, tt:2648.310\n",
      "Ep:89, loss:0.00001, loss_test:0.01220, lr:5.32e-02, fs:0.81159 (r=0.848,p=0.778),  time:29.756, tt:2678.081\n",
      "Ep:90, loss:0.00001, loss_test:0.01221, lr:5.27e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.752, tt:2707.436\n",
      "Ep:91, loss:0.00001, loss_test:0.01222, lr:5.21e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.758, tt:2737.695\n",
      "Ep:92, loss:0.00001, loss_test:0.01219, lr:5.16e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.773, tt:2768.854\n",
      "Ep:93, loss:0.00001, loss_test:0.01217, lr:5.11e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.774, tt:2798.773\n",
      "Ep:94, loss:0.00001, loss_test:0.01221, lr:5.06e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.783, tt:2829.358\n",
      "Ep:95, loss:0.00001, loss_test:0.01221, lr:5.01e-02, fs:0.80392 (r=0.828,p=0.781),  time:29.786, tt:2859.432\n",
      "Ep:96, loss:0.00001, loss_test:0.01219, lr:4.96e-02, fs:0.79803 (r=0.818,p=0.779),  time:29.785, tt:2889.123\n",
      "Ep:97, loss:0.00001, loss_test:0.01225, lr:4.91e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.800, tt:2920.362\n",
      "Ep:98, loss:0.00001, loss_test:0.01223, lr:4.86e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.796, tt:2949.800\n",
      "Ep:99, loss:0.00001, loss_test:0.01218, lr:4.81e-02, fs:0.80198 (r=0.818,p=0.786),  time:29.792, tt:2979.163\n",
      "Ep:100, loss:0.00001, loss_test:0.01221, lr:4.76e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.782, tt:3007.956\n",
      "Ep:101, loss:0.00001, loss_test:0.01218, lr:4.71e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.800, tt:3039.591\n",
      "Ep:102, loss:0.00001, loss_test:0.01212, lr:4.67e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.793, tt:3068.689\n",
      "Ep:103, loss:0.00001, loss_test:0.01217, lr:4.62e-02, fs:0.81000 (r=0.818,p=0.802),  time:29.786, tt:3097.775\n",
      "Ep:104, loss:0.00001, loss_test:0.01221, lr:4.57e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.770, tt:3125.814\n",
      "Ep:105, loss:0.00001, loss_test:0.01218, lr:4.53e-02, fs:0.80612 (r=0.798,p=0.814),  time:29.770, tt:3155.606\n",
      "Ep:106, loss:0.00001, loss_test:0.01223, lr:4.48e-02, fs:0.80612 (r=0.798,p=0.814),  time:29.764, tt:3184.800\n",
      "Ep:107, loss:0.00001, loss_test:0.01225, lr:4.44e-02, fs:0.80612 (r=0.798,p=0.814),  time:29.766, tt:3214.768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00001, loss_test:0.01219, lr:4.39e-02, fs:0.80203 (r=0.798,p=0.806),  time:29.770, tt:3244.950\n",
      "Ep:109, loss:0.00001, loss_test:0.01220, lr:4.35e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.759, tt:3273.442\n",
      "Ep:110, loss:0.00001, loss_test:0.01219, lr:4.31e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.756, tt:3302.947\n",
      "Ep:111, loss:0.00001, loss_test:0.01221, lr:4.26e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.760, tt:3333.147\n",
      "Ep:112, loss:0.00001, loss_test:0.01224, lr:4.22e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.758, tt:3362.617\n",
      "Ep:113, loss:0.00001, loss_test:0.01222, lr:4.18e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.748, tt:3391.305\n",
      "Ep:114, loss:0.00001, loss_test:0.01225, lr:4.14e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.756, tt:3421.940\n",
      "Ep:115, loss:0.00001, loss_test:0.01226, lr:4.10e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.747, tt:3450.635\n",
      "Ep:116, loss:0.00001, loss_test:0.01224, lr:4.05e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.743, tt:3479.877\n",
      "Ep:117, loss:0.00001, loss_test:0.01222, lr:4.01e-02, fs:0.79381 (r=0.778,p=0.811),  time:29.741, tt:3509.477\n",
      "Ep:118, loss:0.00001, loss_test:0.01229, lr:3.97e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.741, tt:3539.184\n",
      "Ep:119, loss:0.00001, loss_test:0.01227, lr:3.93e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.743, tt:3569.102\n",
      "Ep:120, loss:0.00001, loss_test:0.01227, lr:3.89e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.751, tt:3599.925\n",
      "Ep:121, loss:0.00001, loss_test:0.01231, lr:3.86e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.775, tt:3632.521\n",
      "Ep:122, loss:0.00001, loss_test:0.01231, lr:3.82e-02, fs:0.79365 (r=0.758,p=0.833),  time:29.779, tt:3662.809\n",
      "Ep:123, loss:0.00001, loss_test:0.01231, lr:3.78e-02, fs:0.79787 (r=0.758,p=0.843),  time:29.794, tt:3694.408\n",
      "Ep:124, loss:0.00001, loss_test:0.01232, lr:3.74e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.801, tt:3725.130\n",
      "Ep:125, loss:0.00001, loss_test:0.01238, lr:3.70e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.805, tt:3755.418\n",
      "Ep:126, loss:0.00001, loss_test:0.01238, lr:3.67e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.807, tt:3785.494\n",
      "Ep:127, loss:0.00001, loss_test:0.01238, lr:3.63e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.811, tt:3815.852\n",
      "Ep:128, loss:0.00001, loss_test:0.01238, lr:3.59e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.822, tt:3846.992\n",
      "Ep:129, loss:0.00001, loss_test:0.01236, lr:3.56e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.829, tt:3877.786\n",
      "Ep:130, loss:0.00001, loss_test:0.01238, lr:3.52e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.839, tt:3908.897\n",
      "Ep:131, loss:0.00001, loss_test:0.01241, lr:3.49e-02, fs:0.79144 (r=0.747,p=0.841),  time:29.850, tt:3940.243\n",
      "Ep:132, loss:0.00001, loss_test:0.01244, lr:3.45e-02, fs:0.79570 (r=0.747,p=0.851),  time:29.862, tt:3971.659\n",
      "Ep:133, loss:0.00001, loss_test:0.01247, lr:3.42e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.874, tt:4003.170\n",
      "Ep:134, loss:0.00001, loss_test:0.01247, lr:3.38e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.880, tt:4033.769\n",
      "Ep:135, loss:0.00001, loss_test:0.01249, lr:3.35e-02, fs:0.79570 (r=0.747,p=0.851),  time:29.887, tt:4064.633\n",
      "Ep:136, loss:0.00001, loss_test:0.01246, lr:3.32e-02, fs:0.79570 (r=0.747,p=0.851),  time:29.907, tt:4097.220\n",
      "Ep:137, loss:0.00001, loss_test:0.01246, lr:3.28e-02, fs:0.79570 (r=0.747,p=0.851),  time:29.914, tt:4128.143\n",
      "Ep:138, loss:0.00001, loss_test:0.01251, lr:3.25e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.915, tt:4158.150\n",
      "Ep:139, loss:0.00001, loss_test:0.01251, lr:3.22e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.920, tt:4188.771\n",
      "Ep:140, loss:0.00001, loss_test:0.01254, lr:3.19e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.918, tt:4218.492\n",
      "Ep:141, loss:0.00001, loss_test:0.01257, lr:3.15e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.930, tt:4250.054\n",
      "Ep:142, loss:0.00001, loss_test:0.01256, lr:3.12e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.932, tt:4280.212\n",
      "Ep:143, loss:0.00001, loss_test:0.01259, lr:3.09e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.936, tt:4310.851\n",
      "Ep:144, loss:0.00001, loss_test:0.01260, lr:3.06e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.950, tt:4342.707\n",
      "Ep:145, loss:0.00001, loss_test:0.01260, lr:3.03e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.961, tt:4374.286\n",
      "Ep:146, loss:0.00001, loss_test:0.01260, lr:3.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:29.964, tt:4404.742\n",
      "Ep:147, loss:0.00001, loss_test:0.01266, lr:2.97e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.970, tt:4435.582\n",
      "Ep:148, loss:0.00001, loss_test:0.01269, lr:2.94e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.968, tt:4465.306\n",
      "Ep:149, loss:0.00001, loss_test:0.01262, lr:2.91e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.970, tt:4495.441\n",
      "Ep:150, loss:0.00001, loss_test:0.01266, lr:2.88e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.965, tt:4524.786\n",
      "Ep:151, loss:0.00001, loss_test:0.01272, lr:2.85e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.974, tt:4555.984\n",
      "Ep:152, loss:0.00001, loss_test:0.01268, lr:2.82e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.976, tt:4586.372\n",
      "Ep:153, loss:0.00001, loss_test:0.01268, lr:2.80e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.977, tt:4616.399\n",
      "Ep:154, loss:0.00001, loss_test:0.01272, lr:2.77e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.983, tt:4647.341\n",
      "Ep:155, loss:0.00001, loss_test:0.01279, lr:2.74e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.989, tt:4678.334\n",
      "Ep:156, loss:0.00001, loss_test:0.01274, lr:2.71e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.002, tt:4710.236\n",
      "Ep:157, loss:0.00001, loss_test:0.01273, lr:2.69e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.996, tt:4739.315\n",
      "Ep:158, loss:0.00001, loss_test:0.01277, lr:2.66e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.998, tt:4769.742\n",
      "Ep:159, loss:0.00001, loss_test:0.01278, lr:2.63e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.001, tt:4800.185\n",
      "Ep:160, loss:0.00001, loss_test:0.01280, lr:2.61e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.006, tt:4831.021\n",
      "Ep:161, loss:0.00001, loss_test:0.01280, lr:2.58e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.006, tt:4860.896\n",
      "Ep:162, loss:0.00001, loss_test:0.01285, lr:2.55e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.995, tt:4889.187\n",
      "Ep:163, loss:0.00001, loss_test:0.01284, lr:2.53e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.994, tt:4919.074\n",
      "Ep:164, loss:0.00001, loss_test:0.01283, lr:2.50e-02, fs:0.78261 (r=0.727,p=0.847),  time:30.000, tt:4950.037\n",
      "Ep:165, loss:0.00001, loss_test:0.01287, lr:2.48e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.992, tt:4978.719\n",
      "Ep:166, loss:0.00001, loss_test:0.01288, lr:2.45e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.980, tt:5006.658\n",
      "Ep:167, loss:0.00001, loss_test:0.01288, lr:2.43e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.980, tt:5036.682\n",
      "Ep:168, loss:0.00001, loss_test:0.01289, lr:2.40e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.979, tt:5066.441\n",
      "Ep:169, loss:0.00001, loss_test:0.01292, lr:2.38e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.979, tt:5096.351\n",
      "Ep:170, loss:0.00001, loss_test:0.01294, lr:2.36e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.975, tt:5125.650\n",
      "Ep:171, loss:0.00001, loss_test:0.01293, lr:2.33e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.966, tt:5154.201\n",
      "Ep:172, loss:0.00001, loss_test:0.01296, lr:2.31e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.963, tt:5183.678\n",
      "Ep:173, loss:0.00001, loss_test:0.01296, lr:2.29e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.965, tt:5213.833\n",
      "Ep:174, loss:0.00001, loss_test:0.01298, lr:2.26e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.965, tt:5243.903\n",
      "Ep:175, loss:0.00001, loss_test:0.01296, lr:2.24e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.967, tt:5274.189\n",
      "Ep:176, loss:0.00001, loss_test:0.01298, lr:2.22e-02, fs:0.78261 (r=0.727,p=0.847),  time:29.963, tt:5303.475\n",
      "Ep:177, loss:0.00001, loss_test:0.01305, lr:2.20e-02, fs:0.78689 (r=0.727,p=0.857),  time:29.970, tt:5334.699\n",
      "Ep:178, loss:0.00001, loss_test:0.01303, lr:2.17e-02, fs:0.78689 (r=0.727,p=0.857),  time:29.963, tt:5363.433\n",
      "Ep:179, loss:0.00001, loss_test:0.01304, lr:2.15e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.963, tt:5393.256\n",
      "Ep:180, loss:0.00001, loss_test:0.01306, lr:2.13e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.955, tt:5421.879\n",
      "Ep:181, loss:0.00001, loss_test:0.01306, lr:2.11e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.952, tt:5451.301\n",
      "Ep:182, loss:0.00001, loss_test:0.01307, lr:2.09e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.954, tt:5481.599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:183, loss:0.00001, loss_test:0.01308, lr:2.07e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.970, tt:5514.463\n",
      "Ep:184, loss:0.00001, loss_test:0.01308, lr:2.05e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.965, tt:5543.590\n",
      "Ep:185, loss:0.00001, loss_test:0.01312, lr:2.03e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.968, tt:5573.957\n",
      "Ep:186, loss:0.00001, loss_test:0.01313, lr:2.01e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.967, tt:5603.899\n",
      "Ep:187, loss:0.00001, loss_test:0.01313, lr:1.99e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.968, tt:5634.058\n",
      "Ep:188, loss:0.00001, loss_test:0.01316, lr:1.97e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.972, tt:5664.737\n",
      "Ep:189, loss:0.00001, loss_test:0.01313, lr:1.95e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.971, tt:5694.503\n",
      "Ep:190, loss:0.00001, loss_test:0.01316, lr:1.93e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.963, tt:5722.914\n",
      "Ep:191, loss:0.00001, loss_test:0.01316, lr:1.91e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.959, tt:5752.205\n",
      "Ep:192, loss:0.00001, loss_test:0.01319, lr:1.89e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.950, tt:5780.288\n",
      "Ep:193, loss:0.00001, loss_test:0.01321, lr:1.87e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.940, tt:5808.408\n",
      "Ep:194, loss:0.00001, loss_test:0.01321, lr:1.85e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.931, tt:5836.639\n",
      "Ep:195, loss:0.00001, loss_test:0.01321, lr:1.83e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.930, tt:5866.277\n",
      "Ep:196, loss:0.00001, loss_test:0.01324, lr:1.81e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.927, tt:5895.657\n",
      "Ep:197, loss:0.00001, loss_test:0.01324, lr:1.80e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.930, tt:5926.129\n",
      "Ep:198, loss:0.00001, loss_test:0.01321, lr:1.78e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.928, tt:5955.772\n",
      "Ep:199, loss:0.00001, loss_test:0.01325, lr:1.76e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.933, tt:5986.586\n",
      "Ep:200, loss:0.00001, loss_test:0.01329, lr:1.74e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.933, tt:6016.617\n",
      "Ep:201, loss:0.00001, loss_test:0.01328, lr:1.73e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.933, tt:6046.480\n",
      "Ep:202, loss:0.00001, loss_test:0.01328, lr:1.71e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.929, tt:6075.519\n",
      "Ep:203, loss:0.00001, loss_test:0.01333, lr:1.69e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.928, tt:6105.366\n",
      "Ep:204, loss:0.00001, loss_test:0.01334, lr:1.67e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.927, tt:6135.096\n",
      "Ep:205, loss:0.00001, loss_test:0.01330, lr:1.66e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.947, tt:6169.056\n",
      "Ep:206, loss:0.00001, loss_test:0.01333, lr:1.64e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.941, tt:6197.694\n",
      "Ep:207, loss:0.00000, loss_test:0.01337, lr:1.62e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.939, tt:6227.229\n",
      "Ep:208, loss:0.00000, loss_test:0.01338, lr:1.61e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.941, tt:6257.691\n",
      "Ep:209, loss:0.00000, loss_test:0.01338, lr:1.59e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.936, tt:6286.515\n",
      "Ep:210, loss:0.00000, loss_test:0.01338, lr:1.58e-02, fs:0.78022 (r=0.717,p=0.855),  time:29.935, tt:6316.237\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14333, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.256, tt:26.256\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14232, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.061, tt:54.122\n",
      "Ep:2, loss:0.00028, loss_test:0.14071, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.607, tt:79.822\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13815, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:28.177, tt:112.707\n",
      "Ep:4, loss:0.00026, loss_test:0.13462, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:28.645, tt:143.225\n",
      "Ep:5, loss:0.00025, loss_test:0.12986, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:28.684, tt:172.104\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12577, lr:1.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:28.975, tt:202.825\n",
      "Ep:7, loss:0.00023, loss_test:0.12200, lr:1.00e-02, fs:0.64865 (r=0.727,p=0.585),  time:29.253, tt:234.024\n",
      "Ep:8, loss:0.00023, loss_test:0.11878, lr:1.00e-02, fs:0.67841 (r=0.778,p=0.602),  time:29.317, tt:263.855\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11759, lr:1.00e-02, fs:0.68670 (r=0.808,p=0.597),  time:29.363, tt:293.628\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11625, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:29.530, tt:324.826\n",
      "Ep:11, loss:0.00021, loss_test:0.11466, lr:1.00e-02, fs:0.67273 (r=0.747,p=0.612),  time:29.496, tt:353.953\n",
      "Ep:12, loss:0.00021, loss_test:0.11231, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:29.605, tt:384.867\n",
      "Ep:13, loss:0.00020, loss_test:0.10981, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:29.729, tt:416.206\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10672, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:29.905, tt:448.569\n",
      "Ep:15, loss:0.00019, loss_test:0.10436, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:29.967, tt:479.472\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10311, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:30.046, tt:510.790\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10164, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:30.172, tt:543.102\n",
      "Ep:18, loss:0.00018, loss_test:0.09928, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:30.247, tt:574.697\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09718, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:30.347, tt:606.931\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09613, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:30.389, tt:638.159\n",
      "Ep:21, loss:0.00017, loss_test:0.09561, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:30.452, tt:669.950\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09405, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.572, tt:703.156\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09313, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.670, tt:736.070\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09161, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:30.708, tt:767.707\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09069, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:30.720, tt:798.713\n",
      "Ep:26, loss:0.00015, loss_test:0.09004, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:30.781, tt:831.079\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08968, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:30.811, tt:862.712\n",
      "Ep:28, loss:0.00014, loss_test:0.08845, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:30.863, tt:895.040\n",
      "Ep:29, loss:0.00014, loss_test:0.08763, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:30.910, tt:927.288\n",
      "Ep:30, loss:0.00013, loss_test:0.08689, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:30.935, tt:959.000\n",
      "Ep:31, loss:0.00013, loss_test:0.08574, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:31.019, tt:992.599\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08510, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:31.019, tt:1023.641\n",
      "Ep:33, loss:0.00013, loss_test:0.08518, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:31.050, tt:1055.716\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08465, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:31.081, tt:1087.842\n",
      "Ep:35, loss:0.00012, loss_test:0.08336, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:31.109, tt:1119.909\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00012, loss_test:0.08350, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:31.167, tt:1153.193\n",
      "Ep:37, loss:0.00011, loss_test:0.08229, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:31.217, tt:1186.247\n",
      "Ep:38, loss:0.00011, loss_test:0.08140, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:31.248, tt:1218.690\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08170, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:31.302, tt:1252.081\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.08094, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:31.341, tt:1285.001\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.08031, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:31.368, tt:1317.451\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.08138, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:31.407, tt:1350.480\n",
      "Ep:43, loss:0.00010, loss_test:0.08024, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:31.375, tt:1380.508\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.07958, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:31.354, tt:1410.942\n",
      "Ep:45, loss:0.00009, loss_test:0.08040, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:31.382, tt:1443.589\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.07845, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.432, tt:1477.284\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.07993, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:31.425, tt:1508.403\n",
      "Ep:48, loss:0.00009, loss_test:0.07777, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.420, tt:1539.602\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.07872, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.436, tt:1571.818\n",
      "Ep:50, loss:0.00008, loss_test:0.07833, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:31.440, tt:1603.453\n",
      "Ep:51, loss:0.00008, loss_test:0.07917, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.476, tt:1636.744\n",
      "Ep:52, loss:0.00008, loss_test:0.07746, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:31.483, tt:1668.607\n",
      "Ep:53, loss:0.00008, loss_test:0.07740, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:31.469, tt:1699.342\n",
      "Ep:54, loss:0.00008, loss_test:0.07777, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:31.466, tt:1730.656\n",
      "Ep:55, loss:0.00008, loss_test:0.07772, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:31.475, tt:1762.612\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00007, loss_test:0.07810, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:31.467, tt:1793.637\n",
      "Ep:57, loss:0.00007, loss_test:0.07764, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.471, tt:1825.317\n",
      "Ep:58, loss:0.00007, loss_test:0.07611, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:31.468, tt:1856.621\n",
      "Ep:59, loss:0.00007, loss_test:0.07704, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:31.458, tt:1887.459\n",
      "Ep:60, loss:0.00007, loss_test:0.07514, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:31.500, tt:1921.502\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.07811, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:31.528, tt:1954.705\n",
      "Ep:62, loss:0.00006, loss_test:0.07482, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:31.512, tt:1985.254\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.07765, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:31.502, tt:2016.109\n",
      "Ep:64, loss:0.00006, loss_test:0.07709, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:31.491, tt:2046.920\n",
      "Ep:65, loss:0.00006, loss_test:0.07502, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.487, tt:2078.112\n",
      "Ep:66, loss:0.00006, loss_test:0.07636, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:31.503, tt:2110.734\n",
      "Ep:67, loss:0.00006, loss_test:0.07455, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:31.501, tt:2142.094\n",
      "Ep:68, loss:0.00006, loss_test:0.07617, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:31.493, tt:2173.045\n",
      "Ep:69, loss:0.00006, loss_test:0.07193, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:31.500, tt:2204.977\n",
      "Ep:70, loss:0.00005, loss_test:0.07638, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.491, tt:2235.855\n",
      "Ep:71, loss:0.00005, loss_test:0.07100, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:31.497, tt:2267.751\n",
      "Ep:72, loss:0.00005, loss_test:0.07591, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:31.497, tt:2299.246\n",
      "Ep:73, loss:0.00005, loss_test:0.07467, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:31.499, tt:2330.942\n",
      "Ep:74, loss:0.00005, loss_test:0.07180, lr:9.90e-03, fs:0.85859 (r=0.859,p=0.859),  time:31.505, tt:2362.886\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.07499, lr:9.90e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.514, tt:2395.056\n",
      "Ep:76, loss:0.00005, loss_test:0.07037, lr:9.90e-03, fs:0.88442 (r=0.889,p=0.880),  time:31.531, tt:2427.855\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.07443, lr:9.90e-03, fs:0.82234 (r=0.818,p=0.827),  time:31.573, tt:2462.686\n",
      "Ep:78, loss:0.00004, loss_test:0.06983, lr:9.90e-03, fs:0.86911 (r=0.838,p=0.902),  time:31.581, tt:2494.918\n",
      "Ep:79, loss:0.00004, loss_test:0.07388, lr:9.90e-03, fs:0.81283 (r=0.768,p=0.864),  time:31.576, tt:2526.109\n",
      "Ep:80, loss:0.00004, loss_test:0.07062, lr:9.90e-03, fs:0.87755 (r=0.869,p=0.887),  time:31.589, tt:2558.674\n",
      "Ep:81, loss:0.00004, loss_test:0.07281, lr:9.90e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.594, tt:2590.673\n",
      "Ep:82, loss:0.00004, loss_test:0.07113, lr:9.90e-03, fs:0.84211 (r=0.808,p=0.879),  time:31.612, tt:2623.766\n",
      "Ep:83, loss:0.00004, loss_test:0.07275, lr:9.90e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.639, tt:2657.662\n",
      "Ep:84, loss:0.00004, loss_test:0.07057, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.653, tt:2690.542\n",
      "Ep:85, loss:0.00004, loss_test:0.07196, lr:9.90e-03, fs:0.84817 (r=0.818,p=0.880),  time:31.668, tt:2723.489\n",
      "Ep:86, loss:0.00004, loss_test:0.07332, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.670, tt:2755.260\n",
      "Ep:87, loss:0.00004, loss_test:0.07016, lr:9.90e-03, fs:0.87179 (r=0.859,p=0.885),  time:31.681, tt:2787.902\n",
      "Ep:88, loss:0.00004, loss_test:0.07141, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.703, tt:2821.530\n",
      "Ep:89, loss:0.00003, loss_test:0.07001, lr:9.70e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.700, tt:2852.981\n",
      "Ep:90, loss:0.00003, loss_test:0.07135, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.721, tt:2886.632\n",
      "Ep:91, loss:0.00003, loss_test:0.07184, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.734, tt:2919.527\n",
      "Ep:92, loss:0.00003, loss_test:0.07109, lr:9.41e-03, fs:0.85714 (r=0.818,p=0.900),  time:31.732, tt:2951.055\n",
      "Ep:93, loss:0.00003, loss_test:0.07085, lr:9.32e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.756, tt:2985.059\n",
      "Ep:94, loss:0.00003, loss_test:0.07206, lr:9.23e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.760, tt:3017.237\n",
      "Ep:95, loss:0.00003, loss_test:0.06951, lr:9.14e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.776, tt:3050.527\n",
      "Ep:96, loss:0.00003, loss_test:0.07171, lr:9.04e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.799, tt:3084.545\n",
      "Ep:97, loss:0.00003, loss_test:0.07146, lr:8.95e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.794, tt:3115.829\n",
      "Ep:98, loss:0.00003, loss_test:0.07077, lr:8.86e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.807, tt:3148.868\n",
      "Ep:99, loss:0.00003, loss_test:0.07038, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.816, tt:3181.612\n",
      "Ep:100, loss:0.00003, loss_test:0.07165, lr:8.69e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.805, tt:3212.306\n",
      "Ep:101, loss:0.00003, loss_test:0.06940, lr:8.60e-03, fs:0.88205 (r=0.869,p=0.896),  time:31.789, tt:3242.444\n",
      "Ep:102, loss:0.00003, loss_test:0.07357, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.793, tt:3274.634\n",
      "Ep:103, loss:0.00002, loss_test:0.06891, lr:8.43e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.784, tt:3305.586\n",
      "Ep:104, loss:0.00002, loss_test:0.06960, lr:8.35e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.765, tt:3335.288\n",
      "Ep:105, loss:0.00002, loss_test:0.07013, lr:8.26e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.737, tt:3364.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00002, loss_test:0.07128, lr:8.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.736, tt:3395.706\n",
      "Ep:107, loss:0.00002, loss_test:0.06929, lr:8.10e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.724, tt:3426.232\n",
      "Ep:108, loss:0.00002, loss_test:0.07253, lr:8.02e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.727, tt:3458.223\n",
      "Ep:109, loss:0.00002, loss_test:0.06894, lr:7.94e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.731, tt:3490.434\n",
      "Ep:110, loss:0.00002, loss_test:0.07289, lr:7.86e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.733, tt:3522.311\n",
      "Ep:111, loss:0.00002, loss_test:0.06866, lr:7.78e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.731, tt:3553.877\n",
      "Ep:112, loss:0.00002, loss_test:0.07099, lr:7.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.719, tt:3584.260\n",
      "Ep:113, loss:0.00002, loss_test:0.06883, lr:7.62e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.712, tt:3615.200\n",
      "Ep:114, loss:0.00002, loss_test:0.07049, lr:7.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.682, tt:3643.475\n",
      "Ep:115, loss:0.00002, loss_test:0.06957, lr:7.47e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.681, tt:3675.034\n",
      "Ep:116, loss:0.00002, loss_test:0.07198, lr:7.40e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.682, tt:3706.825\n",
      "Ep:117, loss:0.00002, loss_test:0.06922, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.692, tt:3739.653\n",
      "Ep:118, loss:0.00002, loss_test:0.07180, lr:7.25e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.698, tt:3772.015\n",
      "Ep:119, loss:0.00002, loss_test:0.06963, lr:7.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.696, tt:3803.523\n",
      "Ep:120, loss:0.00002, loss_test:0.07137, lr:7.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.698, tt:3835.470\n",
      "Ep:121, loss:0.00002, loss_test:0.06924, lr:7.03e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.688, tt:3865.913\n",
      "Ep:122, loss:0.00002, loss_test:0.07076, lr:6.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.685, tt:3897.260\n",
      "Ep:123, loss:0.00002, loss_test:0.07123, lr:6.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.677, tt:3927.946\n",
      "Ep:124, loss:0.00002, loss_test:0.07042, lr:6.83e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.678, tt:3959.721\n",
      "Ep:125, loss:0.00002, loss_test:0.07199, lr:6.76e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.679, tt:3991.513\n",
      "Ep:126, loss:0.00002, loss_test:0.06946, lr:6.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.672, tt:4022.316\n",
      "Ep:127, loss:0.00002, loss_test:0.07078, lr:6.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.675, tt:4054.347\n",
      "Ep:128, loss:0.00002, loss_test:0.06915, lr:6.56e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.665, tt:4084.770\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.07126, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.663, tt:4116.145\n",
      "Ep:130, loss:0.00001, loss_test:0.06979, lr:6.56e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.658, tt:4147.164\n",
      "Ep:131, loss:0.00001, loss_test:0.07110, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.651, tt:4177.952\n",
      "Ep:132, loss:0.00001, loss_test:0.07057, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.649, tt:4209.269\n",
      "Ep:133, loss:0.00002, loss_test:0.07284, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.650, tt:4241.048\n",
      "Ep:134, loss:0.00002, loss_test:0.07163, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.653, tt:4273.175\n",
      "Ep:135, loss:0.00001, loss_test:0.06986, lr:6.56e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.653, tt:4304.750\n",
      "Ep:136, loss:0.00001, loss_test:0.07279, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.648, tt:4335.821\n",
      "Ep:137, loss:0.00001, loss_test:0.06956, lr:6.56e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.655, tt:4368.383\n",
      "Ep:138, loss:0.00001, loss_test:0.07251, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.658, tt:4400.420\n",
      "Ep:139, loss:0.00001, loss_test:0.06928, lr:6.56e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.654, tt:4431.528\n",
      "Ep:140, loss:0.00001, loss_test:0.07410, lr:6.49e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.655, tt:4463.301\n",
      "Ep:141, loss:0.00001, loss_test:0.07027, lr:6.43e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.650, tt:4494.296\n",
      "Ep:142, loss:0.00001, loss_test:0.07359, lr:6.36e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.652, tt:4526.255\n",
      "Ep:143, loss:0.00001, loss_test:0.07227, lr:6.30e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.667, tt:4560.029\n",
      "Ep:144, loss:0.00001, loss_test:0.07117, lr:6.24e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.673, tt:4592.643\n",
      "Ep:145, loss:0.00001, loss_test:0.07367, lr:6.17e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.677, tt:4624.903\n",
      "Ep:146, loss:0.00001, loss_test:0.07021, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.666, tt:4654.906\n",
      "Ep:147, loss:0.00001, loss_test:0.07188, lr:6.05e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.664, tt:4686.221\n",
      "Ep:148, loss:0.00001, loss_test:0.07065, lr:5.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.653, tt:4716.304\n",
      "Ep:149, loss:0.00001, loss_test:0.07062, lr:5.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.657, tt:4748.523\n",
      "Ep:150, loss:0.00001, loss_test:0.07128, lr:5.87e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.654, tt:4779.778\n",
      "Ep:151, loss:0.00001, loss_test:0.07224, lr:5.81e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.646, tt:4810.147\n",
      "Ep:152, loss:0.00001, loss_test:0.06965, lr:5.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.640, tt:4840.935\n",
      "Ep:153, loss:0.00001, loss_test:0.07450, lr:5.70e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.644, tt:4873.250\n",
      "Ep:154, loss:0.00001, loss_test:0.07053, lr:5.64e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.636, tt:4903.525\n",
      "Ep:155, loss:0.00001, loss_test:0.07130, lr:5.58e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.628, tt:4933.924\n",
      "Ep:156, loss:0.00001, loss_test:0.07251, lr:5.53e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.627, tt:4965.404\n",
      "Ep:157, loss:0.00001, loss_test:0.06939, lr:5.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.630, tt:4997.575\n",
      "Ep:158, loss:0.00001, loss_test:0.07200, lr:5.42e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.626, tt:5028.484\n",
      "Ep:159, loss:0.00001, loss_test:0.07166, lr:5.36e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.623, tt:5059.606\n",
      "Ep:160, loss:0.00001, loss_test:0.07115, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.629, tt:5092.282\n",
      "Ep:161, loss:0.00001, loss_test:0.07097, lr:5.26e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.631, tt:5124.253\n",
      "Ep:162, loss:0.00001, loss_test:0.07015, lr:5.20e-03, fs:0.85714 (r=0.758,p=0.987),  time:31.641, tt:5157.501\n",
      "Ep:163, loss:0.00001, loss_test:0.07272, lr:5.15e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.627, tt:5186.900\n",
      "Ep:164, loss:0.00001, loss_test:0.07282, lr:5.10e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.630, tt:5218.932\n",
      "Ep:165, loss:0.00001, loss_test:0.07054, lr:5.05e-03, fs:0.85714 (r=0.758,p=0.987),  time:31.627, tt:5250.096\n",
      "Ep:166, loss:0.00001, loss_test:0.07093, lr:5.00e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.637, tt:5283.323\n",
      "Ep:167, loss:0.00001, loss_test:0.07102, lr:4.95e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.646, tt:5316.451\n",
      "Ep:168, loss:0.00001, loss_test:0.07083, lr:4.90e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.646, tt:5348.134\n",
      "Ep:169, loss:0.00001, loss_test:0.07184, lr:4.85e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.650, tt:5380.574\n",
      "Ep:170, loss:0.00001, loss_test:0.07063, lr:4.80e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.649, tt:5411.991\n",
      "Ep:171, loss:0.00001, loss_test:0.07065, lr:4.75e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.657, tt:5444.931\n",
      "Ep:172, loss:0.00001, loss_test:0.07182, lr:4.71e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.656, tt:5476.560\n",
      "Ep:173, loss:0.00001, loss_test:0.07028, lr:4.66e-03, fs:0.85057 (r=0.747,p=0.987),  time:31.643, tt:5505.899\n",
      "Ep:174, loss:0.00001, loss_test:0.07173, lr:4.61e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.638, tt:5536.685\n",
      "Ep:175, loss:0.00001, loss_test:0.07090, lr:4.57e-03, fs:0.86207 (r=0.758,p=1.000),  time:31.627, tt:5566.277\n",
      "Ep:176, loss:0.00001, loss_test:0.07100, lr:4.52e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.618, tt:5596.469\n",
      "Ep:177, loss:0.00001, loss_test:0.07191, lr:4.48e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.618, tt:5628.020\n",
      "Ep:178, loss:0.00001, loss_test:0.07047, lr:4.43e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.622, tt:5660.324\n",
      "Ep:179, loss:0.00001, loss_test:0.07070, lr:4.39e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.620, tt:5691.599\n",
      "Ep:180, loss:0.00001, loss_test:0.07125, lr:4.34e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.621, tt:5723.434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:181, loss:0.00001, loss_test:0.07080, lr:4.30e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.627, tt:5756.157\n",
      "Ep:182, loss:0.00001, loss_test:0.07123, lr:4.26e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.618, tt:5786.100\n",
      "Ep:183, loss:0.00001, loss_test:0.07127, lr:4.21e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.606, tt:5815.422\n",
      "Ep:184, loss:0.00001, loss_test:0.07102, lr:4.17e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.608, tt:5847.513\n",
      "Ep:185, loss:0.00001, loss_test:0.07193, lr:4.13e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.603, tt:5878.244\n",
      "Ep:186, loss:0.00001, loss_test:0.07018, lr:4.09e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.609, tt:5910.810\n",
      "Ep:187, loss:0.00001, loss_test:0.07122, lr:4.05e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.636, tt:5947.485\n",
      "Ep:188, loss:0.00001, loss_test:0.07136, lr:4.01e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.632, tt:5978.405\n",
      "Ep:189, loss:0.00001, loss_test:0.07160, lr:3.97e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.627, tt:6009.041\n",
      "Ep:190, loss:0.00001, loss_test:0.07144, lr:3.93e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.628, tt:6040.916\n",
      "Ep:191, loss:0.00001, loss_test:0.07030, lr:3.89e-03, fs:0.85549 (r=0.747,p=1.000),  time:31.631, tt:6073.230\n",
      "Ep:192, loss:0.00001, loss_test:0.07143, lr:3.85e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.626, tt:6103.729\n",
      "Ep:193, loss:0.00001, loss_test:0.07147, lr:3.81e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.624, tt:6135.037\n",
      "Ep:194, loss:0.00001, loss_test:0.07085, lr:3.77e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.622, tt:6166.337\n",
      "Ep:195, loss:0.00001, loss_test:0.07119, lr:3.73e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.624, tt:6198.227\n",
      "Ep:196, loss:0.00001, loss_test:0.07079, lr:3.70e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.631, tt:6231.354\n",
      "Ep:197, loss:0.00001, loss_test:0.07163, lr:3.66e-03, fs:0.84884 (r=0.737,p=1.000),  time:31.628, tt:6262.405\n",
      "Ep:198, loss:0.00001, loss_test:0.07128, lr:3.62e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.630, tt:6294.337\n",
      "Ep:199, loss:0.00001, loss_test:0.07153, lr:3.59e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.631, tt:6326.115\n",
      "Ep:200, loss:0.00001, loss_test:0.07166, lr:3.55e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.629, tt:6357.459\n",
      "Ep:201, loss:0.00001, loss_test:0.07089, lr:3.52e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.628, tt:6388.871\n",
      "Ep:202, loss:0.00001, loss_test:0.07170, lr:3.48e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.635, tt:6421.934\n",
      "Ep:203, loss:0.00001, loss_test:0.07147, lr:3.45e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.638, tt:6454.160\n",
      "Ep:204, loss:0.00001, loss_test:0.07084, lr:3.41e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.646, tt:6487.383\n",
      "Ep:205, loss:0.00001, loss_test:0.07290, lr:3.38e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.650, tt:6519.913\n",
      "Ep:206, loss:0.00001, loss_test:0.07167, lr:3.34e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.655, tt:6552.655\n",
      "Ep:207, loss:0.00001, loss_test:0.07054, lr:3.31e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.649, tt:6583.039\n",
      "Ep:208, loss:0.00001, loss_test:0.07272, lr:3.28e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.663, tt:6617.522\n",
      "Ep:209, loss:0.00001, loss_test:0.07246, lr:3.24e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.651, tt:6646.716\n",
      "Ep:210, loss:0.00001, loss_test:0.07134, lr:3.21e-03, fs:0.84211 (r=0.727,p=1.000),  time:31.641, tt:6676.235\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02171, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:19.497, tt:19.497\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02166, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:20.730, tt:41.460\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02273, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.101, tt:69.302\n",
      "Ep:3, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:25.104, tt:100.417\n",
      "Ep:4, loss:0.00004, loss_test:0.02160, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:26.150, tt:130.751\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02063, lr:6.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:26.608, tt:159.646\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01995, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:27.147, tt:190.032\n",
      "Ep:7, loss:0.00004, loss_test:0.01968, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:27.451, tt:219.609\n",
      "Ep:8, loss:0.00004, loss_test:0.01947, lr:6.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:27.645, tt:248.802\n",
      "Ep:9, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:27.967, tt:279.668\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01851, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:28.009, tt:308.094\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01826, lr:6.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:28.254, tt:339.048\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01817, lr:6.00e-02, fs:0.72180 (r=0.970,p=0.575),  time:28.386, tt:369.016\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01804, lr:6.00e-02, fs:0.71910 (r=0.970,p=0.571),  time:28.461, tt:398.452\n",
      "Ep:14, loss:0.00003, loss_test:0.01784, lr:6.00e-02, fs:0.72453 (r=0.970,p=0.578),  time:28.569, tt:428.527\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.72031 (r=0.949,p=0.580),  time:28.655, tt:458.478\n",
      "Ep:16, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.72157 (r=0.929,p=0.590),  time:28.779, tt:489.250\n",
      "Ep:17, loss:0.00003, loss_test:0.01721, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:28.834, tt:519.010\n",
      "Ep:18, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:28.903, tt:549.161\n",
      "Ep:19, loss:0.00003, loss_test:0.01683, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:28.940, tt:578.796\n",
      "Ep:20, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:29.031, tt:609.643\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01645, lr:6.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:29.111, tt:640.444\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:29.155, tt:670.576\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:29.261, tt:702.269\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01602, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:29.327, tt:733.178\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.379, tt:763.849\n",
      "Ep:26, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:29.344, tt:792.284\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01577, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:29.446, tt:824.478\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:29.571, tt:857.566\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01561, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:29.567, tt:887.017\n",
      "Ep:30, loss:0.00002, loss_test:0.01554, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:29.555, tt:916.204\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:29.579, tt:946.513\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01543, lr:6.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:29.580, tt:976.149\n",
      "Ep:33, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:29.562, tt:1005.096\n",
      "Ep:34, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:29.569, tt:1034.931\n",
      "Ep:35, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:29.577, tt:1064.778\n",
      "Ep:36, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.584, tt:1094.592\n",
      "Ep:37, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.576, tt:1123.885\n",
      "Ep:38, loss:0.00002, loss_test:0.01525, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.581, tt:1153.650\n",
      "Ep:39, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:29.594, tt:1183.769\n",
      "Ep:40, loss:0.00002, loss_test:0.01521, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.624, tt:1214.575\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01518, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.606, tt:1243.456\n",
      "Ep:42, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.609, tt:1273.195\n",
      "Ep:43, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.634, tt:1303.906\n",
      "Ep:44, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.623, tt:1333.024\n",
      "Ep:45, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.636, tt:1363.263\n",
      "Ep:46, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.623, tt:1392.293\n",
      "Ep:47, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:29.630, tt:1422.236\n",
      "Ep:48, loss:0.00002, loss_test:0.01515, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:29.633, tt:1452.023\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01515, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:29.639, tt:1481.950\n",
      "Ep:50, loss:0.00002, loss_test:0.01515, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:29.701, tt:1514.730\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01516, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:29.707, tt:1544.781\n",
      "Ep:52, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:29.717, tt:1575.024\n",
      "Ep:53, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:29.723, tt:1605.035\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01525, lr:6.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:29.730, tt:1635.135\n",
      "Ep:55, loss:0.00002, loss_test:0.01524, lr:6.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:29.753, tt:1666.142\n",
      "Ep:56, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:29.750, tt:1695.769\n",
      "Ep:57, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.775, tt:1726.964\n",
      "Ep:58, loss:0.00002, loss_test:0.01536, lr:6.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:29.795, tt:1757.891\n",
      "Ep:59, loss:0.00002, loss_test:0.01539, lr:6.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:29.807, tt:1788.431\n",
      "Ep:60, loss:0.00002, loss_test:0.01543, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:29.811, tt:1818.466\n",
      "Ep:61, loss:0.00001, loss_test:0.01545, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:29.835, tt:1849.774\n",
      "Ep:62, loss:0.00001, loss_test:0.01548, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:29.825, tt:1878.945\n",
      "Ep:63, loss:0.00001, loss_test:0.01554, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:29.814, tt:1908.084\n",
      "Ep:64, loss:0.00001, loss_test:0.01555, lr:6.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:29.814, tt:1937.928\n",
      "Ep:65, loss:0.00001, loss_test:0.01558, lr:5.94e-02, fs:0.72300 (r=0.778,p=0.675),  time:29.808, tt:1967.352\n",
      "Ep:66, loss:0.00001, loss_test:0.01562, lr:5.88e-02, fs:0.72642 (r=0.778,p=0.681),  time:29.796, tt:1996.359\n",
      "Ep:67, loss:0.00001, loss_test:0.01568, lr:5.82e-02, fs:0.72038 (r=0.768,p=0.679),  time:29.813, tt:2027.291\n",
      "Ep:68, loss:0.00001, loss_test:0.01574, lr:5.76e-02, fs:0.71429 (r=0.758,p=0.676),  time:29.804, tt:2056.505\n",
      "Ep:69, loss:0.00001, loss_test:0.01578, lr:5.71e-02, fs:0.70813 (r=0.747,p=0.673),  time:29.808, tt:2086.557\n",
      "Ep:70, loss:0.00001, loss_test:0.01575, lr:5.65e-02, fs:0.70813 (r=0.747,p=0.673),  time:29.807, tt:2116.305\n",
      "Ep:71, loss:0.00001, loss_test:0.01579, lr:5.59e-02, fs:0.70813 (r=0.747,p=0.673),  time:29.804, tt:2145.859\n",
      "Ep:72, loss:0.00001, loss_test:0.01581, lr:5.54e-02, fs:0.70813 (r=0.747,p=0.673),  time:29.796, tt:2175.122\n",
      "Ep:73, loss:0.00001, loss_test:0.01588, lr:5.48e-02, fs:0.70192 (r=0.737,p=0.670),  time:29.792, tt:2204.587\n",
      "Ep:74, loss:0.00001, loss_test:0.01594, lr:5.43e-02, fs:0.70531 (r=0.737,p=0.676),  time:29.793, tt:2234.473\n",
      "Ep:75, loss:0.00001, loss_test:0.01593, lr:5.37e-02, fs:0.70531 (r=0.737,p=0.676),  time:29.812, tt:2265.708\n",
      "Ep:76, loss:0.00001, loss_test:0.01597, lr:5.32e-02, fs:0.70531 (r=0.737,p=0.676),  time:29.812, tt:2295.535\n",
      "Ep:77, loss:0.00001, loss_test:0.01602, lr:5.27e-02, fs:0.69268 (r=0.717,p=0.670),  time:29.799, tt:2324.358\n",
      "Ep:78, loss:0.00001, loss_test:0.01606, lr:5.21e-02, fs:0.69608 (r=0.717,p=0.676),  time:29.809, tt:2354.940\n",
      "Ep:79, loss:0.00001, loss_test:0.01606, lr:5.16e-02, fs:0.69608 (r=0.717,p=0.676),  time:29.836, tt:2386.883\n",
      "Ep:80, loss:0.00001, loss_test:0.01608, lr:5.11e-02, fs:0.69951 (r=0.717,p=0.683),  time:29.830, tt:2416.210\n",
      "Ep:81, loss:0.00001, loss_test:0.01606, lr:5.06e-02, fs:0.69951 (r=0.717,p=0.683),  time:29.817, tt:2444.961\n",
      "Ep:82, loss:0.00001, loss_test:0.01612, lr:5.01e-02, fs:0.69951 (r=0.717,p=0.683),  time:29.810, tt:2474.212\n",
      "Ep:83, loss:0.00001, loss_test:0.01614, lr:4.96e-02, fs:0.69307 (r=0.707,p=0.680),  time:29.806, tt:2503.718\n",
      "Ep:84, loss:0.00001, loss_test:0.01619, lr:4.91e-02, fs:0.69307 (r=0.707,p=0.680),  time:29.808, tt:2533.662\n",
      "Ep:85, loss:0.00001, loss_test:0.01623, lr:4.86e-02, fs:0.69307 (r=0.707,p=0.680),  time:29.805, tt:2563.258\n",
      "Ep:86, loss:0.00001, loss_test:0.01627, lr:4.81e-02, fs:0.69307 (r=0.707,p=0.680),  time:29.802, tt:2592.757\n",
      "Ep:87, loss:0.00001, loss_test:0.01632, lr:4.76e-02, fs:0.68657 (r=0.697,p=0.676),  time:29.799, tt:2622.348\n",
      "Ep:88, loss:0.00001, loss_test:0.01634, lr:4.71e-02, fs:0.68657 (r=0.697,p=0.676),  time:29.796, tt:2651.856\n",
      "Ep:89, loss:0.00001, loss_test:0.01636, lr:4.67e-02, fs:0.68657 (r=0.697,p=0.676),  time:29.808, tt:2682.712\n",
      "Ep:90, loss:0.00001, loss_test:0.01640, lr:4.62e-02, fs:0.69000 (r=0.697,p=0.683),  time:29.817, tt:2713.390\n",
      "Ep:91, loss:0.00001, loss_test:0.01639, lr:4.57e-02, fs:0.69000 (r=0.697,p=0.683),  time:29.835, tt:2744.814\n",
      "Ep:92, loss:0.00001, loss_test:0.01643, lr:4.53e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.818, tt:2773.085\n",
      "Ep:93, loss:0.00001, loss_test:0.01646, lr:4.48e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.822, tt:2803.264\n",
      "Ep:94, loss:0.00001, loss_test:0.01655, lr:4.44e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.823, tt:2833.228\n",
      "Ep:95, loss:0.00001, loss_test:0.01659, lr:4.39e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.835, tt:2864.198\n",
      "Ep:96, loss:0.00001, loss_test:0.01653, lr:4.35e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.824, tt:2892.892\n",
      "Ep:97, loss:0.00001, loss_test:0.01651, lr:4.31e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.809, tt:2921.247\n",
      "Ep:98, loss:0.00001, loss_test:0.01659, lr:4.26e-02, fs:0.69347 (r=0.697,p=0.690),  time:29.805, tt:2950.669\n",
      "Ep:99, loss:0.00001, loss_test:0.01664, lr:4.22e-02, fs:0.69036 (r=0.687,p=0.694),  time:29.811, tt:2981.130\n",
      "Ep:100, loss:0.00001, loss_test:0.01669, lr:4.18e-02, fs:0.69744 (r=0.687,p=0.708),  time:29.820, tt:3011.848\n",
      "Ep:101, loss:0.00001, loss_test:0.01674, lr:4.14e-02, fs:0.70103 (r=0.687,p=0.716),  time:29.828, tt:3042.451\n",
      "Ep:102, loss:0.00001, loss_test:0.01675, lr:4.10e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.830, tt:3072.497\n",
      "Ep:103, loss:0.00001, loss_test:0.01679, lr:4.05e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.824, tt:3101.672\n",
      "Ep:104, loss:0.00001, loss_test:0.01681, lr:4.01e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.832, tt:3132.364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:105, loss:0.00001, loss_test:0.01686, lr:3.97e-02, fs:0.70466 (r=0.687,p=0.723),  time:29.839, tt:3162.979\n",
      "Ep:106, loss:0.00001, loss_test:0.01686, lr:3.93e-02, fs:0.70833 (r=0.687,p=0.731),  time:29.827, tt:3191.518\n",
      "Ep:107, loss:0.00001, loss_test:0.01692, lr:3.89e-02, fs:0.71204 (r=0.687,p=0.739),  time:29.844, tt:3223.134\n",
      "Ep:108, loss:0.00001, loss_test:0.01696, lr:3.86e-02, fs:0.71204 (r=0.687,p=0.739),  time:29.837, tt:3252.224\n",
      "Ep:109, loss:0.00001, loss_test:0.01701, lr:3.82e-02, fs:0.70526 (r=0.677,p=0.736),  time:29.831, tt:3281.438\n",
      "Ep:110, loss:0.00001, loss_test:0.01701, lr:3.78e-02, fs:0.70899 (r=0.677,p=0.744),  time:29.820, tt:3310.065\n",
      "Ep:111, loss:0.00001, loss_test:0.01701, lr:3.74e-02, fs:0.70899 (r=0.677,p=0.744),  time:29.823, tt:3340.228\n",
      "Ep:112, loss:0.00001, loss_test:0.01707, lr:3.70e-02, fs:0.70899 (r=0.677,p=0.744),  time:29.822, tt:3369.891\n",
      "Ep:113, loss:0.00001, loss_test:0.01713, lr:3.67e-02, fs:0.71277 (r=0.677,p=0.753),  time:29.822, tt:3399.658\n",
      "Ep:114, loss:0.00001, loss_test:0.01712, lr:3.63e-02, fs:0.71277 (r=0.677,p=0.753),  time:29.827, tt:3430.116\n",
      "Ep:115, loss:0.00001, loss_test:0.01717, lr:3.59e-02, fs:0.71658 (r=0.677,p=0.761),  time:29.841, tt:3461.527\n",
      "Ep:116, loss:0.00001, loss_test:0.01722, lr:3.56e-02, fs:0.72043 (r=0.677,p=0.770),  time:29.843, tt:3491.622\n",
      "Ep:117, loss:0.00001, loss_test:0.01727, lr:3.52e-02, fs:0.71658 (r=0.677,p=0.761),  time:29.846, tt:3521.812\n",
      "Ep:118, loss:0.00001, loss_test:0.01725, lr:3.49e-02, fs:0.71658 (r=0.677,p=0.761),  time:29.851, tt:3552.327\n",
      "Ep:119, loss:0.00001, loss_test:0.01725, lr:3.45e-02, fs:0.71658 (r=0.677,p=0.761),  time:29.846, tt:3581.550\n",
      "Ep:120, loss:0.00001, loss_test:0.01731, lr:3.42e-02, fs:0.72432 (r=0.677,p=0.779),  time:29.845, tt:3611.276\n",
      "Ep:121, loss:0.00001, loss_test:0.01739, lr:3.38e-02, fs:0.72432 (r=0.677,p=0.779),  time:29.851, tt:3641.815\n",
      "Ep:122, loss:0.00001, loss_test:0.01739, lr:3.35e-02, fs:0.72432 (r=0.677,p=0.779),  time:29.860, tt:3672.753\n",
      "Ep:123, loss:0.00001, loss_test:0.01741, lr:3.32e-02, fs:0.72432 (r=0.677,p=0.779),  time:29.854, tt:3701.876\n",
      "Ep:124, loss:0.00001, loss_test:0.01747, lr:3.28e-02, fs:0.72432 (r=0.677,p=0.779),  time:29.861, tt:3732.611\n",
      "Ep:125, loss:0.00001, loss_test:0.01751, lr:3.25e-02, fs:0.72432 (r=0.677,p=0.779),  time:29.879, tt:3764.714\n",
      "Ep:126, loss:0.00001, loss_test:0.01752, lr:3.22e-02, fs:0.71739 (r=0.667,p=0.776),  time:29.901, tt:3797.454\n",
      "Ep:127, loss:0.00001, loss_test:0.01752, lr:3.19e-02, fs:0.71739 (r=0.667,p=0.776),  time:29.910, tt:3828.497\n",
      "Ep:128, loss:0.00001, loss_test:0.01757, lr:3.15e-02, fs:0.71739 (r=0.667,p=0.776),  time:29.914, tt:3858.881\n",
      "Ep:129, loss:0.00001, loss_test:0.01764, lr:3.12e-02, fs:0.71739 (r=0.667,p=0.776),  time:29.916, tt:3889.094\n",
      "Ep:130, loss:0.00001, loss_test:0.01765, lr:3.09e-02, fs:0.71739 (r=0.667,p=0.776),  time:29.930, tt:3920.813\n",
      "Ep:131, loss:0.00001, loss_test:0.01767, lr:3.06e-02, fs:0.72131 (r=0.667,p=0.786),  time:29.940, tt:3952.044\n",
      "Ep:132, loss:0.00001, loss_test:0.01771, lr:3.03e-02, fs:0.72131 (r=0.667,p=0.786),  time:29.953, tt:3983.750\n",
      "Ep:133, loss:0.00001, loss_test:0.01778, lr:3.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:29.966, tt:4015.397\n",
      "Ep:134, loss:0.00001, loss_test:0.01780, lr:2.97e-02, fs:0.72131 (r=0.667,p=0.786),  time:29.980, tt:4047.357\n",
      "Ep:135, loss:0.00001, loss_test:0.01782, lr:2.94e-02, fs:0.72131 (r=0.667,p=0.786),  time:29.984, tt:4077.836\n",
      "Ep:136, loss:0.00001, loss_test:0.01780, lr:2.91e-02, fs:0.72131 (r=0.667,p=0.786),  time:29.994, tt:4109.194\n",
      "Ep:137, loss:0.00001, loss_test:0.01782, lr:2.88e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.002, tt:4140.293\n",
      "Ep:138, loss:0.00001, loss_test:0.01786, lr:2.85e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.020, tt:4172.761\n",
      "Ep:139, loss:0.00001, loss_test:0.01790, lr:2.82e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.024, tt:4203.364\n",
      "Ep:140, loss:0.00001, loss_test:0.01795, lr:2.80e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.033, tt:4234.628\n",
      "Ep:141, loss:0.00001, loss_test:0.01796, lr:2.77e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.036, tt:4265.124\n",
      "Ep:142, loss:0.00001, loss_test:0.01801, lr:2.74e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.049, tt:4296.945\n",
      "Ep:143, loss:0.00001, loss_test:0.01803, lr:2.71e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.042, tt:4326.009\n",
      "Ep:144, loss:0.00001, loss_test:0.01808, lr:2.69e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.048, tt:4356.916\n",
      "Ep:145, loss:0.00001, loss_test:0.01811, lr:2.66e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.052, tt:4387.533\n",
      "Ep:146, loss:0.00001, loss_test:0.01813, lr:2.63e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.057, tt:4418.351\n",
      "Ep:147, loss:0.00001, loss_test:0.01813, lr:2.61e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.056, tt:4448.302\n",
      "Ep:148, loss:0.00001, loss_test:0.01816, lr:2.58e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.057, tt:4478.450\n",
      "Ep:149, loss:0.00001, loss_test:0.01821, lr:2.55e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.063, tt:4509.509\n",
      "Ep:150, loss:0.00001, loss_test:0.01824, lr:2.53e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.067, tt:4540.191\n",
      "Ep:151, loss:0.00001, loss_test:0.01824, lr:2.50e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.072, tt:4570.930\n",
      "Ep:152, loss:0.00001, loss_test:0.01825, lr:2.48e-02, fs:0.72131 (r=0.667,p=0.786),  time:30.072, tt:4601.007\n",
      "Ep:153, loss:0.00001, loss_test:0.01830, lr:2.45e-02, fs:0.72527 (r=0.667,p=0.795),  time:30.068, tt:4630.510\n",
      "Ep:154, loss:0.00001, loss_test:0.01833, lr:2.43e-02, fs:0.72527 (r=0.667,p=0.795),  time:30.071, tt:4661.049\n",
      "Ep:155, loss:0.00001, loss_test:0.01836, lr:2.40e-02, fs:0.72527 (r=0.667,p=0.795),  time:30.073, tt:4691.428\n",
      "Ep:156, loss:0.00001, loss_test:0.01838, lr:2.38e-02, fs:0.72527 (r=0.667,p=0.795),  time:30.081, tt:4722.710\n",
      "Ep:157, loss:0.00001, loss_test:0.01840, lr:2.36e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.081, tt:4752.749\n",
      "Ep:158, loss:0.00001, loss_test:0.01843, lr:2.33e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.083, tt:4783.187\n",
      "Ep:159, loss:0.00001, loss_test:0.01844, lr:2.31e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.092, tt:4814.712\n",
      "Ep:160, loss:0.00001, loss_test:0.01846, lr:2.29e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.091, tt:4844.588\n",
      "Ep:161, loss:0.00001, loss_test:0.01853, lr:2.26e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.080, tt:4872.950\n",
      "Ep:162, loss:0.00001, loss_test:0.01855, lr:2.24e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.091, tt:4904.857\n",
      "Ep:163, loss:0.00001, loss_test:0.01855, lr:2.22e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.088, tt:4934.364\n",
      "Ep:164, loss:0.00001, loss_test:0.01856, lr:2.20e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.091, tt:4965.075\n",
      "Ep:165, loss:0.00001, loss_test:0.01859, lr:2.17e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.095, tt:4995.714\n",
      "Ep:166, loss:0.00001, loss_test:0.01863, lr:2.15e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.098, tt:5026.344\n",
      "Ep:167, loss:0.00001, loss_test:0.01866, lr:2.13e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.092, tt:5055.507\n",
      "Ep:168, loss:0.00001, loss_test:0.01867, lr:2.11e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.096, tt:5086.198\n",
      "Ep:169, loss:0.00001, loss_test:0.01872, lr:2.09e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.096, tt:5116.261\n",
      "Ep:170, loss:0.00001, loss_test:0.01874, lr:2.07e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.116, tt:5149.880\n",
      "Ep:171, loss:0.00001, loss_test:0.01875, lr:2.05e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.118, tt:5180.322\n",
      "Ep:172, loss:0.00001, loss_test:0.01880, lr:2.03e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.122, tt:5211.189\n",
      "Ep:173, loss:0.00001, loss_test:0.01882, lr:2.01e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.127, tt:5242.040\n",
      "Ep:174, loss:0.00001, loss_test:0.01884, lr:1.99e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.126, tt:5272.066\n",
      "Ep:175, loss:0.00001, loss_test:0.01885, lr:1.97e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.128, tt:5302.609\n",
      "Ep:176, loss:0.00001, loss_test:0.01886, lr:1.95e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.129, tt:5332.792\n",
      "Ep:177, loss:0.00001, loss_test:0.01889, lr:1.93e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.126, tt:5362.439\n",
      "Ep:178, loss:0.00001, loss_test:0.01892, lr:1.91e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.128, tt:5392.891\n",
      "Ep:179, loss:0.00001, loss_test:0.01894, lr:1.89e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.129, tt:5423.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:180, loss:0.00001, loss_test:0.01896, lr:1.87e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.128, tt:5453.175\n",
      "Ep:181, loss:0.00001, loss_test:0.01899, lr:1.85e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.136, tt:5484.798\n",
      "Ep:182, loss:0.00001, loss_test:0.01902, lr:1.83e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.144, tt:5516.417\n",
      "Ep:183, loss:0.00001, loss_test:0.01906, lr:1.81e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.145, tt:5546.725\n",
      "Ep:184, loss:0.00001, loss_test:0.01906, lr:1.80e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.145, tt:5576.824\n",
      "Ep:185, loss:0.00001, loss_test:0.01905, lr:1.78e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.140, tt:5605.965\n",
      "Ep:186, loss:0.00001, loss_test:0.01909, lr:1.76e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.144, tt:5637.008\n",
      "Ep:187, loss:0.00001, loss_test:0.01910, lr:1.74e-02, fs:0.72928 (r=0.667,p=0.805),  time:30.144, tt:5667.011\n",
      "Ep:188, loss:0.00001, loss_test:0.01914, lr:1.73e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.149, tt:5698.145\n",
      "Ep:189, loss:0.00001, loss_test:0.01915, lr:1.71e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.152, tt:5728.944\n",
      "Ep:190, loss:0.00001, loss_test:0.01918, lr:1.69e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.155, tt:5759.618\n",
      "Ep:191, loss:0.00001, loss_test:0.01919, lr:1.67e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.148, tt:5788.473\n",
      "Ep:192, loss:0.00001, loss_test:0.01921, lr:1.66e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.153, tt:5819.447\n",
      "Ep:193, loss:0.00001, loss_test:0.01922, lr:1.64e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.158, tt:5850.615\n",
      "Ep:194, loss:0.00001, loss_test:0.01923, lr:1.62e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.164, tt:5881.990\n",
      "Ep:195, loss:0.00001, loss_test:0.01926, lr:1.61e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.173, tt:5913.944\n",
      "Ep:196, loss:0.00001, loss_test:0.01928, lr:1.59e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.181, tt:5945.693\n",
      "Ep:197, loss:0.00001, loss_test:0.01929, lr:1.58e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.182, tt:5976.107\n",
      "Ep:198, loss:0.00001, loss_test:0.01933, lr:1.56e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.184, tt:6006.571\n",
      "Ep:199, loss:0.00001, loss_test:0.01935, lr:1.54e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.185, tt:6037.090\n",
      "Ep:200, loss:0.00001, loss_test:0.01937, lr:1.53e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.184, tt:6066.993\n",
      "Ep:201, loss:0.00001, loss_test:0.01936, lr:1.51e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.178, tt:6096.004\n",
      "Ep:202, loss:0.00001, loss_test:0.01938, lr:1.50e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.180, tt:6126.488\n",
      "Ep:203, loss:0.00001, loss_test:0.01939, lr:1.48e-02, fs:0.73333 (r=0.667,p=0.815),  time:30.181, tt:6157.011\n",
      "Ep:204, loss:0.00001, loss_test:0.01943, lr:1.47e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.182, tt:6187.399\n",
      "Ep:205, loss:0.00001, loss_test:0.01944, lr:1.45e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.187, tt:6218.478\n",
      "Ep:206, loss:0.00001, loss_test:0.01947, lr:1.44e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.190, tt:6249.277\n",
      "Ep:207, loss:0.00001, loss_test:0.01947, lr:1.43e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.198, tt:6281.213\n",
      "Ep:208, loss:0.00001, loss_test:0.01948, lr:1.41e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.185, tt:6308.694\n",
      "Ep:209, loss:0.00001, loss_test:0.01951, lr:1.40e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.184, tt:6338.685\n",
      "Ep:210, loss:0.00001, loss_test:0.01953, lr:1.38e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.183, tt:6368.633\n",
      "Ep:211, loss:0.00001, loss_test:0.01954, lr:1.37e-02, fs:0.74157 (r=0.667,p=0.835),  time:30.168, tt:6395.523\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14518, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.161, tt:26.161\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14465, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.459, tt:58.918\n",
      "Ep:2, loss:0.00028, loss_test:0.14380, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.642, tt:88.925\n",
      "Ep:3, loss:0.00028, loss_test:0.14253, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.188, tt:120.751\n",
      "Ep:4, loss:0.00027, loss_test:0.14061, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:30.357, tt:151.787\n",
      "Ep:5, loss:0.00027, loss_test:0.13787, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:30.870, tt:185.219\n",
      "Ep:6, loss:0.00026, loss_test:0.13401, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:30.903, tt:216.318\n",
      "Ep:9, loss:0.00023, loss_test:0.11773, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:31.724, tt:317.238\n",
      "Ep:10, loss:0.00022, loss_test:0.11529, lr:1.00e-02, fs:0.66359 (r=0.727,p=0.610),  time:31.827, tt:350.100\n",
      "Ep:11, loss:0.00022, loss_test:0.11571, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:32.025, tt:384.303\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11599, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:32.117, tt:417.520\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.11545, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:32.236, tt:451.301\n",
      "Ep:14, loss:0.00020, loss_test:0.11440, lr:1.00e-02, fs:0.66029 (r=0.697,p=0.627),  time:32.200, tt:482.997\n",
      "Ep:15, loss:0.00020, loss_test:0.11200, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:32.224, tt:515.584\n",
      "Ep:16, loss:0.00019, loss_test:0.10936, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:32.379, tt:550.436\n",
      "Ep:17, loss:0.00019, loss_test:0.10789, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:32.388, tt:582.991\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10617, lr:1.00e-02, fs:0.69231 (r=0.727,p=0.661),  time:32.297, tt:613.645\n",
      "Ep:19, loss:0.00018, loss_test:0.10467, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:32.290, tt:645.809\n",
      "Ep:20, loss:0.00018, loss_test:0.10240, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:32.276, tt:677.797\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.10151, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:32.252, tt:709.534\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.10041, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:32.208, tt:740.779\n",
      "Ep:23, loss:0.00016, loss_test:0.09887, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:32.207, tt:772.978\n",
      "Ep:24, loss:0.00016, loss_test:0.09689, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:32.179, tt:804.473\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.09565, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:32.174, tt:836.518\n",
      "Ep:26, loss:0.00015, loss_test:0.09389, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:32.190, tt:869.133\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09277, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:32.202, tt:901.657\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09103, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:32.161, tt:932.683\n",
      "Ep:29, loss:0.00014, loss_test:0.08968, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:32.157, tt:964.695\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.08946, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:32.159, tt:996.939\n",
      "Ep:31, loss:0.00014, loss_test:0.08804, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:32.174, tt:1029.567\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08723, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:32.206, tt:1062.812\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08580, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:32.183, tt:1094.213\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.08516, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:32.206, tt:1127.214\n",
      "Ep:35, loss:0.00012, loss_test:0.08477, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:32.182, tt:1158.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00012, loss_test:0.08290, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:32.159, tt:1189.869\n",
      "Ep:37, loss:0.00012, loss_test:0.08260, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:32.161, tt:1222.104\n",
      "Ep:38, loss:0.00011, loss_test:0.08278, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:32.150, tt:1253.855\n",
      "Ep:39, loss:0.00011, loss_test:0.08071, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:32.133, tt:1285.330\n",
      "Ep:40, loss:0.00011, loss_test:0.08104, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:32.129, tt:1317.277\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.07960, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:32.112, tt:1348.716\n",
      "Ep:42, loss:0.00010, loss_test:0.07842, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:32.092, tt:1379.959\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.07784, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:32.062, tt:1410.707\n",
      "Ep:44, loss:0.00010, loss_test:0.07720, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:32.028, tt:1441.238\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.07606, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:32.032, tt:1473.473\n",
      "Ep:46, loss:0.00009, loss_test:0.07627, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:32.022, tt:1505.053\n",
      "Ep:47, loss:0.00009, loss_test:0.07413, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:32.002, tt:1536.084\n",
      "Ep:48, loss:0.00009, loss_test:0.07655, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:32.009, tt:1568.449\n",
      "Ep:49, loss:0.00009, loss_test:0.07248, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.995, tt:1599.764\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00009, loss_test:0.07355, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:31.976, tt:1630.799\n",
      "Ep:51, loss:0.00008, loss_test:0.07323, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.955, tt:1661.658\n",
      "Ep:52, loss:0.00008, loss_test:0.07169, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:31.975, tt:1694.656\n",
      "Ep:53, loss:0.00008, loss_test:0.07113, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:31.952, tt:1725.406\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00008, loss_test:0.07118, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:31.942, tt:1756.814\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.07165, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:31.926, tt:1787.870\n",
      "Ep:56, loss:0.00007, loss_test:0.07100, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.925, tt:1819.724\n",
      "Ep:57, loss:0.00007, loss_test:0.06857, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.922, tt:1851.487\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.07167, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:31.924, tt:1883.538\n",
      "Ep:59, loss:0.00007, loss_test:0.06800, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:31.931, tt:1915.882\n",
      "Ep:60, loss:0.00007, loss_test:0.06910, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.911, tt:1946.593\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00007, loss_test:0.06899, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.890, tt:1977.201\n",
      "Ep:62, loss:0.00006, loss_test:0.06906, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.890, tt:2009.100\n",
      "Ep:63, loss:0.00006, loss_test:0.06737, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.885, tt:2040.664\n",
      "Ep:64, loss:0.00006, loss_test:0.06928, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.891, tt:2072.892\n",
      "Ep:65, loss:0.00006, loss_test:0.06618, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.875, tt:2103.775\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.06764, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.867, tt:2135.091\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00006, loss_test:0.06748, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:31.867, tt:2166.954\n",
      "Ep:68, loss:0.00006, loss_test:0.06550, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.862, tt:2198.477\n",
      "Ep:69, loss:0.00005, loss_test:0.06738, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.856, tt:2229.892\n",
      "Ep:70, loss:0.00005, loss_test:0.06622, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.850, tt:2261.332\n",
      "Ep:71, loss:0.00005, loss_test:0.06855, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.833, tt:2291.962\n",
      "Ep:72, loss:0.00005, loss_test:0.06579, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.855, tt:2325.412\n",
      "Ep:73, loss:0.00005, loss_test:0.06571, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.865, tt:2357.975\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.06684, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.877, tt:2390.809\n",
      "Ep:75, loss:0.00005, loss_test:0.06604, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.890, tt:2423.632\n",
      "Ep:76, loss:0.00005, loss_test:0.06676, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.901, tt:2456.390\n",
      "Ep:77, loss:0.00005, loss_test:0.06406, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:31.913, tt:2489.209\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00004, loss_test:0.06773, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.908, tt:2520.744\n",
      "Ep:79, loss:0.00004, loss_test:0.06456, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.903, tt:2552.208\n",
      "Ep:80, loss:0.00004, loss_test:0.06460, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.928, tt:2586.171\n",
      "Ep:81, loss:0.00004, loss_test:0.06471, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.939, tt:2619.007\n",
      "Ep:82, loss:0.00004, loss_test:0.06503, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:31.943, tt:2651.310\n",
      "Ep:83, loss:0.00004, loss_test:0.06528, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.966, tt:2685.137\n",
      "Ep:84, loss:0.00004, loss_test:0.06498, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:31.967, tt:2717.176\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.06530, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:31.948, tt:2747.499\n",
      "Ep:86, loss:0.00004, loss_test:0.06425, lr:1.00e-02, fs:0.86364 (r=0.768,p=0.987),  time:31.962, tt:2780.706\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00004, loss_test:0.06631, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.953, tt:2811.901\n",
      "Ep:88, loss:0.00004, loss_test:0.06262, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.955, tt:2843.955\n",
      "Ep:89, loss:0.00003, loss_test:0.06705, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:31.951, tt:2875.558\n",
      "Ep:90, loss:0.00003, loss_test:0.06055, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.953, tt:2907.706\n",
      "Ep:91, loss:0.00003, loss_test:0.06742, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.960, tt:2940.306\n",
      "Ep:92, loss:0.00003, loss_test:0.06196, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.948, tt:2971.168\n",
      "Ep:93, loss:0.00003, loss_test:0.06738, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.955, tt:3003.811\n",
      "Ep:94, loss:0.00003, loss_test:0.06248, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.955, tt:3035.698\n",
      "Ep:95, loss:0.00003, loss_test:0.06657, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.961, tt:3068.237\n",
      "Ep:96, loss:0.00003, loss_test:0.06316, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.962, tt:3100.268\n",
      "Ep:97, loss:0.00003, loss_test:0.06423, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.957, tt:3131.771\n",
      "Ep:98, loss:0.00003, loss_test:0.06429, lr:9.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.959, tt:3163.908\n",
      "Ep:99, loss:0.00003, loss_test:0.06321, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.972, tt:3197.231\n",
      "Ep:100, loss:0.00003, loss_test:0.06540, lr:9.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.978, tt:3229.754\n",
      "Ep:101, loss:0.00003, loss_test:0.06344, lr:9.61e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.994, tt:3263.349\n",
      "Ep:102, loss:0.00003, loss_test:0.06403, lr:9.51e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.989, tt:3294.881\n",
      "Ep:103, loss:0.00003, loss_test:0.06542, lr:9.41e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.001, tt:3328.084\n",
      "Ep:104, loss:0.00002, loss_test:0.06195, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.995, tt:3359.459\n",
      "Ep:105, loss:0.00003, loss_test:0.06813, lr:9.23e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.992, tt:3391.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00003, loss_test:0.06270, lr:9.14e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.992, tt:3423.093\n",
      "Ep:107, loss:0.00002, loss_test:0.06491, lr:9.04e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.980, tt:3453.832\n",
      "Ep:108, loss:0.00002, loss_test:0.06482, lr:8.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.986, tt:3486.433\n",
      "Ep:109, loss:0.00002, loss_test:0.06220, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.982, tt:3518.029\n",
      "Ep:110, loss:0.00002, loss_test:0.06331, lr:8.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.989, tt:3550.777\n",
      "Ep:111, loss:0.00002, loss_test:0.06266, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.983, tt:3582.093\n",
      "Ep:112, loss:0.00002, loss_test:0.06151, lr:8.60e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.964, tt:3611.960\n",
      "Ep:113, loss:0.00002, loss_test:0.06496, lr:8.51e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.944, tt:3641.667\n",
      "Ep:114, loss:0.00002, loss_test:0.06233, lr:8.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.950, tt:3674.202\n",
      "Ep:115, loss:0.00002, loss_test:0.06305, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.951, tt:3706.323\n",
      "Ep:116, loss:0.00002, loss_test:0.06237, lr:8.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.949, tt:3738.053\n",
      "Ep:117, loss:0.00002, loss_test:0.06307, lr:8.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.960, tt:3771.335\n",
      "Ep:118, loss:0.00002, loss_test:0.06223, lr:8.10e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.959, tt:3803.153\n",
      "Ep:119, loss:0.00002, loss_test:0.06372, lr:8.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.959, tt:3835.049\n",
      "Ep:120, loss:0.00002, loss_test:0.06178, lr:7.94e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.959, tt:3867.063\n",
      "Ep:121, loss:0.00002, loss_test:0.06364, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.960, tt:3899.123\n",
      "Ep:122, loss:0.00002, loss_test:0.06274, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.971, tt:3932.430\n",
      "Ep:123, loss:0.00002, loss_test:0.06244, lr:7.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.965, tt:3963.710\n",
      "Ep:124, loss:0.00002, loss_test:0.06191, lr:7.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.972, tt:3996.442\n",
      "Ep:125, loss:0.00002, loss_test:0.06209, lr:7.55e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.975, tt:4028.885\n",
      "Ep:126, loss:0.00002, loss_test:0.06144, lr:7.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.978, tt:4061.216\n",
      "Ep:127, loss:0.00002, loss_test:0.06260, lr:7.40e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.974, tt:4092.732\n",
      "Ep:128, loss:0.00002, loss_test:0.06129, lr:7.32e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.974, tt:4124.611\n",
      "Ep:129, loss:0.00002, loss_test:0.06380, lr:7.25e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.976, tt:4156.903\n",
      "Ep:130, loss:0.00002, loss_test:0.06127, lr:7.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.998, tt:4191.789\n",
      "Ep:131, loss:0.00002, loss_test:0.06560, lr:7.11e-03, fs:0.83978 (r=0.768,p=0.927),  time:32.001, tt:4224.194\n",
      "Ep:132, loss:0.00002, loss_test:0.06213, lr:7.03e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.002, tt:4256.273\n",
      "Ep:133, loss:0.00002, loss_test:0.06253, lr:6.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.992, tt:4286.881\n",
      "Ep:134, loss:0.00002, loss_test:0.06502, lr:6.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.988, tt:4318.419\n",
      "Ep:135, loss:0.00002, loss_test:0.06064, lr:6.83e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.991, tt:4350.807\n",
      "Ep:136, loss:0.00002, loss_test:0.06420, lr:6.76e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.987, tt:4382.159\n",
      "Ep:137, loss:0.00002, loss_test:0.06146, lr:6.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.991, tt:4414.826\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00001, loss_test:0.06250, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.993, tt:4446.984\n",
      "Ep:139, loss:0.00001, loss_test:0.06260, lr:6.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:31.993, tt:4479.067\n",
      "Ep:140, loss:0.00001, loss_test:0.06236, lr:6.69e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.997, tt:4511.629\n",
      "Ep:141, loss:0.00001, loss_test:0.06297, lr:6.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.000, tt:4544.068\n",
      "Ep:142, loss:0.00001, loss_test:0.06148, lr:6.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.011, tt:4577.572\n",
      "Ep:143, loss:0.00001, loss_test:0.06246, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.012, tt:4609.707\n",
      "Ep:144, loss:0.00001, loss_test:0.06161, lr:6.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.010, tt:4641.497\n",
      "Ep:145, loss:0.00001, loss_test:0.06433, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.008, tt:4673.176\n",
      "Ep:146, loss:0.00001, loss_test:0.06052, lr:6.69e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.003, tt:4704.407\n",
      "Ep:147, loss:0.00001, loss_test:0.06331, lr:6.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.989, tt:4734.369\n",
      "Ep:148, loss:0.00001, loss_test:0.06188, lr:6.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.988, tt:4766.280\n",
      "Ep:149, loss:0.00001, loss_test:0.06178, lr:6.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:31.991, tt:4798.702\n",
      "Ep:150, loss:0.00001, loss_test:0.06227, lr:6.56e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.000, tt:4832.005\n",
      "Ep:151, loss:0.00001, loss_test:0.06068, lr:6.49e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.001, tt:4864.196\n",
      "Ep:152, loss:0.00001, loss_test:0.06323, lr:6.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.004, tt:4896.627\n",
      "Ep:153, loss:0.00001, loss_test:0.06086, lr:6.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.002, tt:4928.245\n",
      "Ep:154, loss:0.00001, loss_test:0.06172, lr:6.30e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.014, tt:4962.219\n",
      "Ep:155, loss:0.00001, loss_test:0.06260, lr:6.24e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.010, tt:4993.496\n",
      "Ep:156, loss:0.00001, loss_test:0.06134, lr:6.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.021, tt:5027.304\n",
      "Ep:157, loss:0.00001, loss_test:0.06191, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.029, tt:5060.515\n",
      "Ep:158, loss:0.00001, loss_test:0.06174, lr:6.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.029, tt:5092.575\n",
      "Ep:159, loss:0.00001, loss_test:0.06158, lr:5.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.024, tt:5123.890\n",
      "Ep:160, loss:0.00001, loss_test:0.06172, lr:5.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.031, tt:5156.976\n",
      "Ep:161, loss:0.00001, loss_test:0.06174, lr:5.87e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.037, tt:5189.935\n",
      "Ep:162, loss:0.00001, loss_test:0.06149, lr:5.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.040, tt:5222.578\n",
      "Ep:163, loss:0.00001, loss_test:0.06284, lr:5.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.032, tt:5253.327\n",
      "Ep:164, loss:0.00001, loss_test:0.06066, lr:5.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.031, tt:5285.085\n",
      "Ep:165, loss:0.00001, loss_test:0.06252, lr:5.64e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.029, tt:5316.836\n",
      "Ep:166, loss:0.00001, loss_test:0.06403, lr:5.58e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.042, tt:5351.011\n",
      "Ep:167, loss:0.00001, loss_test:0.06089, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.038, tt:5382.393\n",
      "Ep:168, loss:0.00001, loss_test:0.06148, lr:5.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.032, tt:5413.388\n",
      "Ep:169, loss:0.00001, loss_test:0.06239, lr:5.42e-03, fs:0.86857 (r=0.768,p=1.000),  time:32.033, tt:5445.581\n",
      "Ep:170, loss:0.00001, loss_test:0.06083, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.035, tt:5478.003\n",
      "Ep:171, loss:0.00001, loss_test:0.06133, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.041, tt:5510.966\n",
      "Ep:172, loss:0.00001, loss_test:0.06143, lr:5.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.048, tt:5544.314\n",
      "Ep:173, loss:0.00001, loss_test:0.06057, lr:5.20e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.046, tt:5575.937\n",
      "Ep:174, loss:0.00001, loss_test:0.06122, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.044, tt:5607.731\n",
      "Ep:175, loss:0.00001, loss_test:0.06079, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.048, tt:5640.513\n",
      "Ep:176, loss:0.00001, loss_test:0.06118, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.043, tt:5671.675\n",
      "Ep:177, loss:0.00001, loss_test:0.06141, lr:5.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.047, tt:5704.418\n",
      "Ep:178, loss:0.00001, loss_test:0.06025, lr:4.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.050, tt:5736.997\n",
      "Ep:179, loss:0.00001, loss_test:0.06134, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.057, tt:5770.232\n",
      "Ep:180, loss:0.00001, loss_test:0.06078, lr:4.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.063, tt:5803.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:181, loss:0.00001, loss_test:0.06089, lr:4.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.062, tt:5835.322\n",
      "Ep:182, loss:0.00001, loss_test:0.06123, lr:4.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.057, tt:5866.383\n",
      "Ep:183, loss:0.00001, loss_test:0.06107, lr:4.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.063, tt:5899.681\n",
      "Ep:184, loss:0.00001, loss_test:0.06065, lr:4.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.073, tt:5933.501\n",
      "Ep:185, loss:0.00001, loss_test:0.06052, lr:4.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.075, tt:5965.913\n",
      "Ep:186, loss:0.00001, loss_test:0.06030, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.065, tt:5996.217\n",
      "Ep:187, loss:0.00001, loss_test:0.06040, lr:4.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.089, tt:6032.648\n",
      "Ep:188, loss:0.00001, loss_test:0.06107, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.083, tt:6063.722\n",
      "Ep:189, loss:0.00001, loss_test:0.06023, lr:4.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.077, tt:6094.713\n",
      "Ep:190, loss:0.00001, loss_test:0.06109, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.076, tt:6126.509\n",
      "Ep:191, loss:0.00001, loss_test:0.06069, lr:4.34e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.079, tt:6159.172\n",
      "Ep:192, loss:0.00001, loss_test:0.06053, lr:4.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.073, tt:6190.118\n",
      "Ep:193, loss:0.00001, loss_test:0.06081, lr:4.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.072, tt:6221.964\n",
      "Ep:194, loss:0.00001, loss_test:0.06064, lr:4.21e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.074, tt:6254.351\n",
      "Ep:195, loss:0.00001, loss_test:0.06036, lr:4.17e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.069, tt:6285.504\n",
      "Ep:196, loss:0.00001, loss_test:0.06077, lr:4.13e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.063, tt:6316.455\n",
      "Ep:197, loss:0.00001, loss_test:0.06027, lr:4.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.070, tt:6349.920\n",
      "Ep:198, loss:0.00001, loss_test:0.06048, lr:4.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.062, tt:6380.307\n",
      "Ep:199, loss:0.00001, loss_test:0.06035, lr:4.01e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.064, tt:6412.749\n",
      "Ep:200, loss:0.00001, loss_test:0.06051, lr:3.97e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.065, tt:6445.048\n",
      "Ep:201, loss:0.00001, loss_test:0.06032, lr:3.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.066, tt:6477.353\n",
      "Ep:202, loss:0.00001, loss_test:0.06088, lr:3.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.063, tt:6508.818\n",
      "Ep:203, loss:0.00001, loss_test:0.06073, lr:3.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.065, tt:6541.270\n",
      "Ep:204, loss:0.00001, loss_test:0.06070, lr:3.81e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.054, tt:6571.048\n",
      "Ep:205, loss:0.00001, loss_test:0.06082, lr:3.77e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.057, tt:6603.752\n",
      "Ep:206, loss:0.00001, loss_test:0.06095, lr:3.73e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.062, tt:6636.796\n",
      "Ep:207, loss:0.00001, loss_test:0.06016, lr:3.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.052, tt:6666.754\n",
      "Ep:208, loss:0.00001, loss_test:0.06066, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.058, tt:6700.209\n",
      "Ep:209, loss:0.00001, loss_test:0.06113, lr:3.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.057, tt:6732.069\n",
      "Ep:210, loss:0.00001, loss_test:0.05973, lr:3.59e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.040, tt:6760.496\n",
      "Ep:211, loss:0.00001, loss_test:0.06138, lr:3.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:32.010, tt:6786.164\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02038, lr:6.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:28.394, tt:28.394\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02309, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.469, tt:56.938\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02589, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.408, tt:85.224\n",
      "Ep:3, loss:0.00005, loss_test:0.02692, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.593, tt:114.371\n",
      "Ep:4, loss:0.00005, loss_test:0.02706, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.574, tt:142.870\n",
      "Ep:5, loss:0.00005, loss_test:0.02669, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.389, tt:170.331\n",
      "Ep:6, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.261, tt:197.824\n",
      "Ep:7, loss:0.00005, loss_test:0.02476, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.594, tt:228.755\n",
      "Ep:8, loss:0.00005, loss_test:0.02342, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.907, tt:260.161\n",
      "Ep:9, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:29.074, tt:290.744\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02058, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:29.217, tt:321.390\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01972, lr:6.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:29.336, tt:352.028\n",
      "Ep:12, loss:0.00004, loss_test:0.01947, lr:6.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:29.586, tt:384.619\n",
      "Ep:13, loss:0.00004, loss_test:0.01950, lr:6.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:29.759, tt:416.622\n",
      "Ep:14, loss:0.00004, loss_test:0.01926, lr:6.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:29.774, tt:446.609\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01869, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:29.851, tt:477.617\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01812, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:29.917, tt:508.583\n",
      "Ep:17, loss:0.00003, loss_test:0.01777, lr:6.00e-02, fs:0.69373 (r=0.949,p=0.547),  time:30.012, tt:540.215\n",
      "Ep:18, loss:0.00003, loss_test:0.01756, lr:6.00e-02, fs:0.68613 (r=0.949,p=0.537),  time:30.041, tt:570.783\n",
      "Ep:19, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.69818 (r=0.970,p=0.545),  time:30.024, tt:600.486\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:30.031, tt:630.658\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:30.008, tt:660.179\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:30.063, tt:691.460\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:30.111, tt:722.662\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01620, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:30.156, tt:753.891\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01605, lr:6.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:30.218, tt:785.663\n",
      "Ep:26, loss:0.00003, loss_test:0.01589, lr:6.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:30.243, tt:816.562\n",
      "Ep:27, loss:0.00003, loss_test:0.01573, lr:6.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:30.262, tt:847.336\n",
      "Ep:28, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:30.284, tt:878.249\n",
      "Ep:29, loss:0.00002, loss_test:0.01544, lr:6.00e-02, fs:0.75519 (r=0.919,p=0.641),  time:30.312, tt:909.372\n",
      "Ep:30, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:30.358, tt:941.094\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01516, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:30.360, tt:971.519\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:30.377, tt:1002.426\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01492, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:30.383, tt:1033.035\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:30.443, tt:1065.522\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:30.441, tt:1095.859\n",
      "Ep:36, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:30.484, tt:1127.897\n",
      "Ep:37, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:30.511, tt:1159.412\n",
      "Ep:38, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:30.578, tt:1192.554\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01420, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:30.557, tt:1222.284\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.553, tt:1252.679\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.549, tt:1283.064\n",
      "Ep:42, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.565, tt:1314.291\n",
      "Ep:43, loss:0.00002, loss_test:0.01386, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.580, tt:1345.530\n",
      "Ep:44, loss:0.00002, loss_test:0.01379, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.580, tt:1376.117\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.590, tt:1407.140\n",
      "Ep:46, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.594, tt:1437.899\n",
      "Ep:47, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.557, tt:1466.754\n",
      "Ep:48, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:30.541, tt:1496.533\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:30.563, tt:1528.163\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:30.563, tt:1558.692\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:30.569, tt:1589.599\n",
      "Ep:52, loss:0.00001, loss_test:0.01334, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:30.564, tt:1619.893\n",
      "Ep:53, loss:0.00001, loss_test:0.01331, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:30.564, tt:1650.474\n",
      "Ep:54, loss:0.00001, loss_test:0.01326, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:30.538, tt:1679.613\n",
      "Ep:55, loss:0.00001, loss_test:0.01324, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.527, tt:1709.520\n",
      "Ep:56, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:30.506, tt:1738.853\n",
      "Ep:57, loss:0.00001, loss_test:0.01321, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:30.501, tt:1769.068\n",
      "Ep:58, loss:0.00001, loss_test:0.01317, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.498, tt:1799.399\n",
      "Ep:59, loss:0.00001, loss_test:0.01315, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.497, tt:1829.849\n",
      "Ep:60, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.498, tt:1860.404\n",
      "Ep:61, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:30.482, tt:1889.875\n",
      "Ep:62, loss:0.00001, loss_test:0.01310, lr:5.94e-02, fs:0.83962 (r=0.899,p=0.788),  time:30.474, tt:1919.846\n",
      "Ep:63, loss:0.00001, loss_test:0.01310, lr:5.88e-02, fs:0.83962 (r=0.899,p=0.788),  time:30.504, tt:1952.261\n",
      "Ep:64, loss:0.00001, loss_test:0.01310, lr:5.82e-02, fs:0.83810 (r=0.889,p=0.793),  time:30.504, tt:1982.754\n",
      "Ep:65, loss:0.00001, loss_test:0.01310, lr:5.76e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.536, tt:2015.354\n",
      "Ep:66, loss:0.00001, loss_test:0.01308, lr:5.71e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.556, tt:2047.260\n",
      "Ep:67, loss:0.00001, loss_test:0.01309, lr:5.65e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.525, tt:2075.731\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01308, lr:5.65e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.524, tt:2106.185\n",
      "Ep:69, loss:0.00001, loss_test:0.01307, lr:5.65e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.520, tt:2136.376\n",
      "Ep:70, loss:0.00001, loss_test:0.01307, lr:5.65e-02, fs:0.85854 (r=0.889,p=0.830),  time:30.534, tt:2167.889\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01308, lr:5.65e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.542, tt:2198.999\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01308, lr:5.65e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.524, tt:2228.225\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01312, lr:5.65e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.509, tt:2257.685\n",
      "Ep:74, loss:0.00001, loss_test:0.01314, lr:5.65e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.520, tt:2289.032\n",
      "Ep:75, loss:0.00001, loss_test:0.01316, lr:5.65e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.531, tt:2320.334\n",
      "Ep:76, loss:0.00001, loss_test:0.01317, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.531, tt:2350.902\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01317, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.536, tt:2381.781\n",
      "Ep:78, loss:0.00001, loss_test:0.01318, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.533, tt:2412.128\n",
      "Ep:79, loss:0.00001, loss_test:0.01317, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.543, tt:2443.420\n",
      "Ep:80, loss:0.00001, loss_test:0.01319, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.566, tt:2475.844\n",
      "Ep:81, loss:0.00001, loss_test:0.01322, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.567, tt:2506.519\n",
      "Ep:82, loss:0.00001, loss_test:0.01324, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.573, tt:2537.568\n",
      "Ep:83, loss:0.00001, loss_test:0.01325, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.566, tt:2567.575\n",
      "Ep:84, loss:0.00001, loss_test:0.01327, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.573, tt:2598.726\n",
      "Ep:85, loss:0.00001, loss_test:0.01329, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.585, tt:2630.324\n",
      "Ep:86, loss:0.00001, loss_test:0.01332, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.599, tt:2662.071\n",
      "Ep:87, loss:0.00001, loss_test:0.01334, lr:5.65e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.602, tt:2692.999\n",
      "Ep:88, loss:0.00001, loss_test:0.01339, lr:5.59e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.593, tt:2722.793\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01341, lr:5.59e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.599, tt:2753.920\n",
      "Ep:90, loss:0.00001, loss_test:0.01345, lr:5.59e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.594, tt:2784.031\n",
      "Ep:91, loss:0.00001, loss_test:0.01344, lr:5.59e-02, fs:0.87562 (r=0.889,p=0.863),  time:30.575, tt:2812.884\n",
      "Ep:92, loss:0.00001, loss_test:0.01345, lr:5.59e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.578, tt:2843.747\n",
      "Ep:93, loss:0.00001, loss_test:0.01348, lr:5.59e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.570, tt:2873.577\n",
      "Ep:94, loss:0.00001, loss_test:0.01352, lr:5.59e-02, fs:0.87437 (r=0.879,p=0.870),  time:30.568, tt:2903.996\n",
      "Ep:95, loss:0.00001, loss_test:0.01355, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.570, tt:2934.747\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01358, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.573, tt:2965.575\n",
      "Ep:97, loss:0.00001, loss_test:0.01360, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.585, tt:2997.349\n",
      "Ep:98, loss:0.00001, loss_test:0.01362, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.588, tt:3028.226\n",
      "Ep:99, loss:0.00001, loss_test:0.01367, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.592, tt:3059.157\n",
      "Ep:100, loss:0.00001, loss_test:0.01368, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.590, tt:3089.547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00001, loss_test:0.01369, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.583, tt:3119.446\n",
      "Ep:102, loss:0.00001, loss_test:0.01372, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.586, tt:3150.371\n",
      "Ep:103, loss:0.00001, loss_test:0.01378, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.594, tt:3181.826\n",
      "Ep:104, loss:0.00001, loss_test:0.01381, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.595, tt:3212.471\n",
      "Ep:105, loss:0.00001, loss_test:0.01386, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.585, tt:3242.063\n",
      "Ep:106, loss:0.00001, loss_test:0.01390, lr:5.59e-02, fs:0.87879 (r=0.879,p=0.879),  time:30.573, tt:3271.294\n",
      "Ep:107, loss:0.00001, loss_test:0.01394, lr:5.54e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.584, tt:3303.034\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01397, lr:5.54e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.596, tt:3334.944\n",
      "Ep:109, loss:0.00001, loss_test:0.01399, lr:5.54e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.603, tt:3366.295\n",
      "Ep:110, loss:0.00001, loss_test:0.01403, lr:5.54e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.599, tt:3396.531\n",
      "Ep:111, loss:0.00001, loss_test:0.01408, lr:5.54e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.597, tt:3426.815\n",
      "Ep:112, loss:0.00001, loss_test:0.01410, lr:5.54e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.604, tt:3458.219\n",
      "Ep:113, loss:0.00001, loss_test:0.01411, lr:5.54e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.597, tt:3488.087\n",
      "Ep:114, loss:0.00001, loss_test:0.01416, lr:5.54e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.608, tt:3519.896\n",
      "Ep:115, loss:0.00001, loss_test:0.01419, lr:5.54e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.593, tt:3548.767\n",
      "Ep:116, loss:0.00001, loss_test:0.01423, lr:5.54e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.582, tt:3578.078\n",
      "Ep:117, loss:0.00001, loss_test:0.01425, lr:5.54e-02, fs:0.87958 (r=0.848,p=0.913),  time:30.591, tt:3609.697\n",
      "Ep:118, loss:0.00001, loss_test:0.01431, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.589, tt:3640.056\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.01434, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.595, tt:3671.441\n",
      "Ep:120, loss:0.00001, loss_test:0.01438, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.616, tt:3704.568\n",
      "Ep:121, loss:0.00001, loss_test:0.01442, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.627, tt:3736.538\n",
      "Ep:122, loss:0.00001, loss_test:0.01448, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.640, tt:3768.777\n",
      "Ep:123, loss:0.00001, loss_test:0.01451, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.649, tt:3800.440\n",
      "Ep:124, loss:0.00001, loss_test:0.01454, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.652, tt:3831.523\n",
      "Ep:125, loss:0.00001, loss_test:0.01458, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.641, tt:3860.787\n",
      "Ep:126, loss:0.00001, loss_test:0.01461, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.638, tt:3890.974\n",
      "Ep:127, loss:0.00001, loss_test:0.01467, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.633, tt:3921.017\n",
      "Ep:128, loss:0.00001, loss_test:0.01470, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.625, tt:3950.573\n",
      "Ep:129, loss:0.00001, loss_test:0.01472, lr:5.54e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.621, tt:3980.745\n",
      "Ep:130, loss:0.00000, loss_test:0.01475, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.623, tt:4011.580\n",
      "Ep:131, loss:0.00000, loss_test:0.01477, lr:5.43e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.621, tt:4042.011\n",
      "Ep:132, loss:0.00000, loss_test:0.01479, lr:5.37e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.615, tt:4071.733\n",
      "Ep:133, loss:0.00000, loss_test:0.01484, lr:5.32e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.610, tt:4101.686\n",
      "Ep:134, loss:0.00000, loss_test:0.01489, lr:5.27e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.605, tt:4131.720\n",
      "Ep:135, loss:0.00000, loss_test:0.01494, lr:5.21e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.604, tt:4162.176\n",
      "Ep:136, loss:0.00000, loss_test:0.01496, lr:5.16e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.605, tt:4192.927\n",
      "Ep:137, loss:0.00000, loss_test:0.01499, lr:5.11e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.608, tt:4223.897\n",
      "Ep:138, loss:0.00000, loss_test:0.01503, lr:5.06e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.610, tt:4254.736\n",
      "Ep:139, loss:0.00000, loss_test:0.01507, lr:5.01e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.611, tt:4285.594\n",
      "Ep:140, loss:0.00000, loss_test:0.01513, lr:4.96e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.614, tt:4316.605\n",
      "Ep:141, loss:0.00000, loss_test:0.01519, lr:4.91e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.623, tt:4348.445\n",
      "Ep:142, loss:0.00000, loss_test:0.01523, lr:4.86e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.621, tt:4378.800\n",
      "Ep:143, loss:0.00000, loss_test:0.01526, lr:4.81e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.619, tt:4409.201\n",
      "Ep:144, loss:0.00000, loss_test:0.01527, lr:4.76e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.621, tt:4440.069\n",
      "Ep:145, loss:0.00000, loss_test:0.01528, lr:4.71e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.616, tt:4469.877\n",
      "Ep:146, loss:0.00000, loss_test:0.01532, lr:4.67e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.618, tt:4500.829\n",
      "Ep:147, loss:0.00000, loss_test:0.01538, lr:4.62e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.617, tt:4531.373\n",
      "Ep:148, loss:0.00000, loss_test:0.01541, lr:4.57e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.603, tt:4559.874\n",
      "Ep:149, loss:0.00000, loss_test:0.01545, lr:4.53e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.611, tt:4591.684\n",
      "Ep:150, loss:0.00000, loss_test:0.01547, lr:4.48e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.606, tt:4621.572\n",
      "Ep:151, loss:0.00000, loss_test:0.01548, lr:4.44e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.603, tt:4651.672\n",
      "Ep:152, loss:0.00000, loss_test:0.01552, lr:4.39e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.605, tt:4682.625\n",
      "Ep:153, loss:0.00000, loss_test:0.01556, lr:4.35e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.609, tt:4713.819\n",
      "Ep:154, loss:0.00000, loss_test:0.01559, lr:4.31e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.608, tt:4744.274\n",
      "Ep:155, loss:0.00000, loss_test:0.01562, lr:4.26e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.609, tt:4774.966\n",
      "Ep:156, loss:0.00000, loss_test:0.01566, lr:4.22e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.608, tt:4805.436\n",
      "Ep:157, loss:0.00000, loss_test:0.01568, lr:4.18e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.606, tt:4835.670\n",
      "Ep:158, loss:0.00000, loss_test:0.01570, lr:4.14e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.605, tt:4866.124\n",
      "Ep:159, loss:0.00000, loss_test:0.01572, lr:4.10e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.601, tt:4896.200\n",
      "Ep:160, loss:0.00000, loss_test:0.01575, lr:4.05e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.594, tt:4925.630\n",
      "Ep:161, loss:0.00000, loss_test:0.01579, lr:4.01e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.596, tt:4956.624\n",
      "Ep:162, loss:0.00000, loss_test:0.01583, lr:3.97e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.606, tt:4988.807\n",
      "Ep:163, loss:0.00000, loss_test:0.01586, lr:3.93e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.621, tt:5021.787\n",
      "Ep:164, loss:0.00000, loss_test:0.01588, lr:3.89e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.621, tt:5052.523\n",
      "Ep:165, loss:0.00000, loss_test:0.01591, lr:3.86e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.623, tt:5083.456\n",
      "Ep:166, loss:0.00000, loss_test:0.01593, lr:3.82e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.618, tt:5113.186\n",
      "Ep:167, loss:0.00000, loss_test:0.01595, lr:3.78e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.616, tt:5143.461\n",
      "Ep:168, loss:0.00000, loss_test:0.01597, lr:3.74e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.603, tt:5171.980\n",
      "Ep:169, loss:0.00000, loss_test:0.01600, lr:3.70e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.599, tt:5201.873\n",
      "Ep:170, loss:0.00000, loss_test:0.01603, lr:3.67e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.588, tt:5230.623\n",
      "Ep:171, loss:0.00000, loss_test:0.01605, lr:3.63e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.577, tt:5259.274\n",
      "Ep:172, loss:0.00000, loss_test:0.01607, lr:3.59e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.572, tt:5288.985\n",
      "Ep:173, loss:0.00000, loss_test:0.01610, lr:3.56e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.566, tt:5318.500\n",
      "Ep:174, loss:0.00000, loss_test:0.01613, lr:3.52e-02, fs:0.87701 (r=0.828,p=0.932),  time:30.555, tt:5347.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:175, loss:0.00000, loss_test:0.01615, lr:3.49e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.560, tt:5378.570\n",
      "Ep:176, loss:0.00000, loss_test:0.01617, lr:3.45e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.564, tt:5409.745\n",
      "Ep:177, loss:0.00000, loss_test:0.01619, lr:3.42e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.563, tt:5440.264\n",
      "Ep:178, loss:0.00000, loss_test:0.01622, lr:3.38e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.563, tt:5470.827\n",
      "Ep:179, loss:0.00000, loss_test:0.01624, lr:3.35e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.586, tt:5505.535\n",
      "Ep:180, loss:0.00000, loss_test:0.01626, lr:3.32e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.592, tt:5537.087\n",
      "Ep:181, loss:0.00000, loss_test:0.01627, lr:3.28e-02, fs:0.87097 (r=0.818,p=0.931),  time:30.589, tt:5567.126\n",
      "Ep:182, loss:0.00000, loss_test:0.01630, lr:3.25e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.589, tt:5597.714\n",
      "Ep:183, loss:0.00000, loss_test:0.01632, lr:3.22e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.598, tt:5629.968\n",
      "Ep:184, loss:0.00000, loss_test:0.01633, lr:3.19e-02, fs:0.87568 (r=0.818,p=0.942),  time:30.596, tt:5660.220\n",
      "Ep:185, loss:0.00000, loss_test:0.01637, lr:3.15e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.596, tt:5690.895\n",
      "Ep:186, loss:0.00000, loss_test:0.01639, lr:3.12e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.595, tt:5721.338\n",
      "Ep:187, loss:0.00000, loss_test:0.01641, lr:3.09e-02, fs:0.86957 (r=0.808,p=0.941),  time:30.592, tt:5751.207\n",
      "Ep:188, loss:0.00000, loss_test:0.01644, lr:3.06e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.592, tt:5781.951\n",
      "Ep:189, loss:0.00000, loss_test:0.01647, lr:3.03e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.595, tt:5813.106\n",
      "Ep:190, loss:0.00000, loss_test:0.01649, lr:3.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.593, tt:5843.332\n",
      "Ep:191, loss:0.00000, loss_test:0.01650, lr:2.97e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.597, tt:5874.659\n",
      "Ep:192, loss:0.00000, loss_test:0.01651, lr:2.94e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.601, tt:5906.019\n",
      "Ep:193, loss:0.00000, loss_test:0.01652, lr:2.91e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.609, tt:5938.222\n",
      "Ep:194, loss:0.00000, loss_test:0.01655, lr:2.88e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.605, tt:5968.050\n",
      "Ep:195, loss:0.00000, loss_test:0.01657, lr:2.85e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.601, tt:5997.868\n",
      "Ep:196, loss:0.00000, loss_test:0.01659, lr:2.82e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.590, tt:6026.159\n",
      "Ep:197, loss:0.00000, loss_test:0.01661, lr:2.80e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.590, tt:6056.747\n",
      "Ep:198, loss:0.00000, loss_test:0.01665, lr:2.77e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.586, tt:6086.531\n",
      "Ep:199, loss:0.00000, loss_test:0.01667, lr:2.74e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.567, tt:6113.496\n",
      "Ep:200, loss:0.00000, loss_test:0.01667, lr:2.71e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.548, tt:6140.211\n",
      "Ep:201, loss:0.00000, loss_test:0.01669, lr:2.69e-02, fs:0.86188 (r=0.788,p=0.951),  time:30.520, tt:6165.005\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14152, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.352, tt:31.352\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13988, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.303, tt:60.606\n",
      "Ep:2, loss:0.00027, loss_test:0.13712, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:30.582, tt:91.745\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13281, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:31.233, tt:124.931\n",
      "Ep:4, loss:0.00025, loss_test:0.12828, lr:1.00e-02, fs:0.65613 (r=0.838,p=0.539),  time:31.298, tt:156.489\n",
      "Ep:5, loss:0.00024, loss_test:0.12517, lr:1.00e-02, fs:0.63393 (r=0.717,p=0.568),  time:31.083, tt:186.498\n",
      "Ep:6, loss:0.00023, loss_test:0.12393, lr:1.00e-02, fs:0.64975 (r=0.646,p=0.653),  time:31.009, tt:217.061\n",
      "Ep:7, loss:0.00022, loss_test:0.12266, lr:1.00e-02, fs:0.64706 (r=0.667,p=0.629),  time:31.324, tt:250.592\n",
      "Ep:8, loss:0.00022, loss_test:0.12147, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:31.250, tt:281.248\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11940, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:31.258, tt:312.577\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11456, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:31.364, tt:345.003\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.11065, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:31.453, tt:377.440\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10853, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:31.531, tt:409.902\n",
      "Ep:13, loss:0.00018, loss_test:0.10793, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:31.594, tt:442.321\n",
      "Ep:14, loss:0.00018, loss_test:0.10684, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:31.641, tt:474.619\n",
      "Ep:15, loss:0.00017, loss_test:0.10393, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:31.673, tt:506.768\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.10142, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:31.720, tt:539.245\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09986, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:31.751, tt:571.515\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09908, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:31.810, tt:604.385\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.09826, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:31.849, tt:636.978\n",
      "Ep:20, loss:0.00015, loss_test:0.09714, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:31.894, tt:669.774\n",
      "Ep:21, loss:0.00014, loss_test:0.09588, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:31.947, tt:702.841\n",
      "Ep:22, loss:0.00014, loss_test:0.09462, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:31.979, tt:735.520\n",
      "Ep:23, loss:0.00013, loss_test:0.09363, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:31.967, tt:767.200\n",
      "Ep:24, loss:0.00013, loss_test:0.09209, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:31.986, tt:799.644\n",
      "Ep:25, loss:0.00012, loss_test:0.09168, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:31.995, tt:831.883\n",
      "Ep:26, loss:0.00012, loss_test:0.09094, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:31.987, tt:863.639\n",
      "Ep:27, loss:0.00012, loss_test:0.08944, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:31.956, tt:894.754\n",
      "Ep:28, loss:0.00011, loss_test:0.08796, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:31.970, tt:927.118\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08731, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:31.979, tt:959.357\n",
      "Ep:30, loss:0.00011, loss_test:0.08703, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:31.950, tt:990.460\n",
      "Ep:31, loss:0.00010, loss_test:0.08574, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:31.939, tt:1022.042\n",
      "Ep:32, loss:0.00010, loss_test:0.08481, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:31.896, tt:1052.553\n",
      "Ep:33, loss:0.00010, loss_test:0.08453, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:31.884, tt:1084.065\n",
      "Ep:34, loss:0.00009, loss_test:0.08361, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:31.862, tt:1115.180\n",
      "Ep:35, loss:0.00009, loss_test:0.08257, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:31.831, tt:1145.910\n",
      "Ep:36, loss:0.00009, loss_test:0.08114, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:31.791, tt:1176.265\n",
      "Ep:37, loss:0.00009, loss_test:0.08044, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:31.793, tt:1208.151\n",
      "Ep:38, loss:0.00008, loss_test:0.08008, lr:1.00e-02, fs:0.73864 (r=0.657,p=0.844),  time:31.776, tt:1239.267\n",
      "Ep:39, loss:0.00008, loss_test:0.07944, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:31.768, tt:1270.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:40, loss:0.00008, loss_test:0.07860, lr:9.90e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.783, tt:1303.114\n",
      "Ep:41, loss:0.00008, loss_test:0.07816, lr:9.80e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.758, tt:1333.833\n",
      "Ep:42, loss:0.00008, loss_test:0.07736, lr:9.70e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.745, tt:1365.021\n",
      "Ep:43, loss:0.00007, loss_test:0.07696, lr:9.61e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.720, tt:1395.680\n",
      "Ep:44, loss:0.00007, loss_test:0.07637, lr:9.51e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.726, tt:1427.659\n",
      "Ep:45, loss:0.00007, loss_test:0.07532, lr:9.41e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.704, tt:1458.398\n",
      "Ep:46, loss:0.00007, loss_test:0.07621, lr:9.32e-03, fs:0.73743 (r=0.667,p=0.825),  time:31.723, tt:1490.973\n",
      "Ep:47, loss:0.00007, loss_test:0.07595, lr:9.23e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.715, tt:1522.313\n",
      "Ep:48, loss:0.00006, loss_test:0.07433, lr:9.14e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.705, tt:1553.537\n",
      "Ep:49, loss:0.00006, loss_test:0.07481, lr:9.04e-03, fs:0.74157 (r=0.667,p=0.835),  time:31.706, tt:1585.281\n",
      "Ep:50, loss:0.00006, loss_test:0.07475, lr:8.95e-03, fs:0.74576 (r=0.667,p=0.846),  time:31.792, tt:1621.411\n",
      "Ep:51, loss:0.00006, loss_test:0.07351, lr:8.86e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.779, tt:1652.494\n",
      "Ep:52, loss:0.00006, loss_test:0.07356, lr:8.78e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.774, tt:1684.028\n",
      "Ep:53, loss:0.00006, loss_test:0.07395, lr:8.69e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.794, tt:1716.880\n",
      "Ep:54, loss:0.00006, loss_test:0.07324, lr:8.60e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.798, tt:1748.868\n",
      "Ep:55, loss:0.00005, loss_test:0.07272, lr:8.51e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.811, tt:1781.395\n",
      "Ep:56, loss:0.00005, loss_test:0.07304, lr:8.43e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.822, tt:1813.870\n",
      "Ep:57, loss:0.00005, loss_test:0.07261, lr:8.35e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.831, tt:1846.200\n",
      "Ep:58, loss:0.00005, loss_test:0.07210, lr:8.26e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.838, tt:1878.430\n",
      "Ep:59, loss:0.00005, loss_test:0.07238, lr:8.18e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.850, tt:1911.014\n",
      "Ep:60, loss:0.00005, loss_test:0.07237, lr:8.10e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.857, tt:1943.248\n",
      "Ep:61, loss:0.00005, loss_test:0.07212, lr:8.02e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.858, tt:1975.210\n",
      "Ep:62, loss:0.00005, loss_test:0.07186, lr:7.94e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.846, tt:2006.314\n",
      "Ep:63, loss:0.00005, loss_test:0.07163, lr:7.86e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.852, tt:2038.510\n",
      "Ep:64, loss:0.00005, loss_test:0.07174, lr:7.78e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.852, tt:2070.353\n",
      "Ep:65, loss:0.00004, loss_test:0.07221, lr:7.70e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.856, tt:2102.476\n",
      "Ep:66, loss:0.00004, loss_test:0.07146, lr:7.62e-03, fs:0.75000 (r=0.667,p=0.857),  time:31.883, tt:2136.153\n",
      "Ep:67, loss:0.00004, loss_test:0.07146, lr:7.55e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.873, tt:2167.339\n",
      "Ep:68, loss:0.00004, loss_test:0.07136, lr:7.47e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.887, tt:2200.210\n",
      "Ep:69, loss:0.00004, loss_test:0.07149, lr:7.40e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.896, tt:2232.717\n",
      "Ep:70, loss:0.00004, loss_test:0.07114, lr:7.32e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.883, tt:2263.711\n",
      "Ep:71, loss:0.00004, loss_test:0.07137, lr:7.25e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.900, tt:2296.812\n",
      "Ep:72, loss:0.00004, loss_test:0.07113, lr:7.18e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.899, tt:2328.603\n",
      "Ep:73, loss:0.00004, loss_test:0.07111, lr:7.11e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.918, tt:2361.895\n",
      "Ep:74, loss:0.00004, loss_test:0.07049, lr:7.03e-03, fs:0.75429 (r=0.667,p=0.868),  time:31.924, tt:2394.302\n",
      "Ep:75, loss:0.00004, loss_test:0.07114, lr:6.96e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.936, tt:2427.101\n",
      "Ep:76, loss:0.00004, loss_test:0.07105, lr:6.89e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.922, tt:2458.020\n",
      "Ep:77, loss:0.00004, loss_test:0.07047, lr:6.83e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.927, tt:2490.340\n",
      "Ep:78, loss:0.00004, loss_test:0.07091, lr:6.76e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.936, tt:2522.979\n",
      "Ep:79, loss:0.00003, loss_test:0.07112, lr:6.69e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.921, tt:2553.685\n",
      "Ep:80, loss:0.00003, loss_test:0.07074, lr:6.62e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.923, tt:2585.801\n",
      "Ep:81, loss:0.00003, loss_test:0.07058, lr:6.56e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.960, tt:2620.688\n",
      "Ep:82, loss:0.00003, loss_test:0.07061, lr:6.49e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.957, tt:2652.400\n",
      "Ep:83, loss:0.00003, loss_test:0.07067, lr:6.43e-03, fs:0.75862 (r=0.667,p=0.880),  time:31.975, tt:2685.920\n",
      "Ep:84, loss:0.00003, loss_test:0.07115, lr:6.36e-03, fs:0.76301 (r=0.667,p=0.892),  time:31.955, tt:2716.135\n",
      "Ep:85, loss:0.00003, loss_test:0.07027, lr:6.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.959, tt:2748.502\n",
      "Ep:86, loss:0.00003, loss_test:0.07007, lr:6.24e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.972, tt:2781.549\n",
      "Ep:87, loss:0.00003, loss_test:0.07073, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.984, tt:2814.551\n",
      "Ep:88, loss:0.00003, loss_test:0.07054, lr:6.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:31.999, tt:2847.882\n",
      "Ep:89, loss:0.00003, loss_test:0.07035, lr:6.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.019, tt:2881.685\n",
      "Ep:90, loss:0.00003, loss_test:0.07042, lr:5.99e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.024, tt:2914.211\n",
      "Ep:91, loss:0.00003, loss_test:0.07073, lr:5.93e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.028, tt:2946.543\n",
      "Ep:92, loss:0.00003, loss_test:0.07045, lr:5.87e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.000, tt:2976.014\n",
      "Ep:93, loss:0.00003, loss_test:0.07054, lr:5.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.003, tt:3008.304\n",
      "Ep:94, loss:0.00003, loss_test:0.07036, lr:5.75e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.991, tt:3039.150\n",
      "Ep:95, loss:0.00003, loss_test:0.07015, lr:5.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.984, tt:3070.473\n",
      "Ep:96, loss:0.00003, loss_test:0.07067, lr:5.64e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.982, tt:3102.288\n",
      "Ep:97, loss:0.00003, loss_test:0.07024, lr:5.58e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.985, tt:3134.495\n",
      "Ep:98, loss:0.00003, loss_test:0.07049, lr:5.53e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.993, tt:3167.270\n",
      "Ep:99, loss:0.00003, loss_test:0.07072, lr:5.47e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.985, tt:3198.477\n",
      "Ep:100, loss:0.00003, loss_test:0.06989, lr:5.42e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.981, tt:3230.037\n",
      "Ep:101, loss:0.00003, loss_test:0.07072, lr:5.36e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.976, tt:3261.528\n",
      "Ep:102, loss:0.00003, loss_test:0.07088, lr:5.31e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.018, tt:3297.808\n",
      "Ep:103, loss:0.00003, loss_test:0.07006, lr:5.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.015, tt:3329.511\n",
      "Ep:104, loss:0.00003, loss_test:0.07042, lr:5.20e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.017, tt:3361.737\n",
      "Ep:105, loss:0.00002, loss_test:0.07026, lr:5.15e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.013, tt:3393.356\n",
      "Ep:106, loss:0.00002, loss_test:0.07009, lr:5.10e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.003, tt:3424.352\n",
      "Ep:107, loss:0.00002, loss_test:0.07052, lr:5.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.000, tt:3455.975\n",
      "Ep:108, loss:0.00002, loss_test:0.07032, lr:5.00e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.001, tt:3488.062\n",
      "Ep:109, loss:0.00002, loss_test:0.07037, lr:4.95e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.991, tt:3519.054\n",
      "Ep:110, loss:0.00002, loss_test:0.07046, lr:4.90e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.987, tt:3550.573\n",
      "Ep:111, loss:0.00002, loss_test:0.06988, lr:4.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.979, tt:3581.657\n",
      "Ep:112, loss:0.00002, loss_test:0.07048, lr:4.80e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.980, tt:3613.740\n",
      "Ep:113, loss:0.00002, loss_test:0.07079, lr:4.75e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.972, tt:3644.850\n",
      "Ep:114, loss:0.00002, loss_test:0.07003, lr:4.71e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.975, tt:3677.157\n",
      "Ep:115, loss:0.00002, loss_test:0.06968, lr:4.66e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.969, tt:3708.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00002, loss_test:0.07054, lr:4.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.959, tt:3739.237\n",
      "Ep:117, loss:0.00002, loss_test:0.07038, lr:4.57e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.973, tt:3772.760\n",
      "Ep:118, loss:0.00002, loss_test:0.06947, lr:4.52e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.954, tt:3802.475\n",
      "Ep:119, loss:0.00002, loss_test:0.06978, lr:4.48e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.939, tt:3832.629\n",
      "Ep:120, loss:0.00002, loss_test:0.07024, lr:4.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.936, tt:3864.242\n",
      "Ep:121, loss:0.00002, loss_test:0.07006, lr:4.39e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.945, tt:3897.265\n",
      "Ep:122, loss:0.00002, loss_test:0.06982, lr:4.34e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.951, tt:3930.004\n",
      "Ep:123, loss:0.00002, loss_test:0.06984, lr:4.30e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.951, tt:3961.956\n",
      "Ep:124, loss:0.00002, loss_test:0.07014, lr:4.26e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.936, tt:3991.972\n",
      "Ep:125, loss:0.00002, loss_test:0.07012, lr:4.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.934, tt:4023.727\n",
      "Ep:126, loss:0.00002, loss_test:0.06967, lr:4.17e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.933, tt:4055.450\n",
      "Ep:127, loss:0.00002, loss_test:0.06995, lr:4.13e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.924, tt:4086.322\n",
      "Ep:128, loss:0.00002, loss_test:0.06999, lr:4.09e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.933, tt:4119.413\n",
      "Ep:129, loss:0.00002, loss_test:0.06992, lr:4.05e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.938, tt:4151.925\n",
      "Ep:130, loss:0.00002, loss_test:0.06993, lr:4.01e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.937, tt:4183.733\n",
      "Ep:131, loss:0.00002, loss_test:0.06972, lr:3.97e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.923, tt:4213.876\n",
      "Ep:132, loss:0.00002, loss_test:0.06991, lr:3.93e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.922, tt:4245.602\n",
      "Ep:133, loss:0.00002, loss_test:0.06990, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.927, tt:4278.252\n",
      "Ep:134, loss:0.00002, loss_test:0.06984, lr:3.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.931, tt:4310.735\n",
      "Ep:135, loss:0.00002, loss_test:0.06966, lr:3.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.946, tt:4344.722\n",
      "Ep:136, loss:0.00002, loss_test:0.06982, lr:3.77e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.946, tt:4376.562\n",
      "Ep:137, loss:0.00002, loss_test:0.06984, lr:3.73e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.956, tt:4409.953\n",
      "Ep:138, loss:0.00002, loss_test:0.06965, lr:3.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.956, tt:4441.833\n",
      "Ep:139, loss:0.00002, loss_test:0.06953, lr:3.66e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.963, tt:4474.807\n",
      "Ep:140, loss:0.00002, loss_test:0.07000, lr:3.62e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.961, tt:4506.554\n",
      "Ep:141, loss:0.00002, loss_test:0.06960, lr:3.59e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.960, tt:4538.277\n",
      "Ep:142, loss:0.00002, loss_test:0.06970, lr:3.55e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.968, tt:4571.463\n",
      "Ep:143, loss:0.00002, loss_test:0.07006, lr:3.52e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.965, tt:4603.031\n",
      "Ep:144, loss:0.00002, loss_test:0.06963, lr:3.48e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.961, tt:4634.413\n",
      "Ep:145, loss:0.00002, loss_test:0.06947, lr:3.45e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.964, tt:4666.707\n",
      "Ep:146, loss:0.00002, loss_test:0.07009, lr:3.41e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.959, tt:4697.965\n",
      "Ep:147, loss:0.00002, loss_test:0.06980, lr:3.38e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.962, tt:4730.436\n",
      "Ep:148, loss:0.00002, loss_test:0.06917, lr:3.34e-03, fs:0.77193 (r=0.667,p=0.917),  time:31.969, tt:4763.379\n",
      "Ep:149, loss:0.00002, loss_test:0.06965, lr:3.31e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.003, tt:4800.427\n",
      "Ep:150, loss:0.00002, loss_test:0.06942, lr:3.28e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.023, tt:4835.469\n",
      "Ep:151, loss:0.00002, loss_test:0.06948, lr:3.24e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.038, tt:4869.836\n",
      "Ep:152, loss:0.00002, loss_test:0.07009, lr:3.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.038, tt:4901.808\n",
      "##########Best model found so far##########\n",
      "Ep:153, loss:0.00002, loss_test:0.06976, lr:3.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.048, tt:4935.419\n",
      "Ep:154, loss:0.00002, loss_test:0.06944, lr:3.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.043, tt:4966.635\n",
      "Ep:155, loss:0.00002, loss_test:0.06953, lr:3.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.044, tt:4998.842\n",
      "Ep:156, loss:0.00002, loss_test:0.06984, lr:3.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.043, tt:5030.815\n",
      "Ep:157, loss:0.00002, loss_test:0.06950, lr:3.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.034, tt:5061.313\n",
      "Ep:158, loss:0.00002, loss_test:0.06973, lr:3.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.031, tt:5092.874\n",
      "Ep:159, loss:0.00002, loss_test:0.06982, lr:3.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.036, tt:5125.736\n",
      "Ep:160, loss:0.00002, loss_test:0.06951, lr:3.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.027, tt:5156.332\n",
      "Ep:161, loss:0.00002, loss_test:0.06943, lr:3.21e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.030, tt:5188.820\n",
      "Ep:162, loss:0.00002, loss_test:0.06966, lr:3.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.036, tt:5221.807\n",
      "Ep:163, loss:0.00002, loss_test:0.06948, lr:3.21e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.038, tt:5254.190\n",
      "Ep:164, loss:0.00002, loss_test:0.06949, lr:3.18e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.035, tt:5285.837\n",
      "Ep:165, loss:0.00002, loss_test:0.06966, lr:3.15e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.034, tt:5317.640\n",
      "Ep:166, loss:0.00002, loss_test:0.06939, lr:3.12e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.029, tt:5348.918\n",
      "Ep:167, loss:0.00002, loss_test:0.06931, lr:3.09e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.028, tt:5380.766\n",
      "Ep:168, loss:0.00002, loss_test:0.06948, lr:3.05e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.028, tt:5412.721\n",
      "Ep:169, loss:0.00002, loss_test:0.06952, lr:3.02e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.033, tt:5445.668\n",
      "Ep:170, loss:0.00001, loss_test:0.06951, lr:2.99e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.037, tt:5478.304\n",
      "Ep:171, loss:0.00001, loss_test:0.06945, lr:2.96e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.041, tt:5511.064\n",
      "Ep:172, loss:0.00001, loss_test:0.06934, lr:2.93e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.042, tt:5543.240\n",
      "Ep:173, loss:0.00001, loss_test:0.06946, lr:2.90e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.033, tt:5573.759\n",
      "Ep:174, loss:0.00001, loss_test:0.06939, lr:2.88e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.032, tt:5605.658\n",
      "Ep:175, loss:0.00001, loss_test:0.06937, lr:2.85e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.045, tt:5639.990\n",
      "Ep:176, loss:0.00001, loss_test:0.06958, lr:2.82e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.050, tt:5672.888\n",
      "Ep:177, loss:0.00001, loss_test:0.06940, lr:2.79e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.051, tt:5705.006\n",
      "Ep:178, loss:0.00001, loss_test:0.06931, lr:2.76e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.047, tt:5736.452\n",
      "Ep:179, loss:0.00001, loss_test:0.06947, lr:2.73e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.050, tt:5768.977\n",
      "Ep:180, loss:0.00001, loss_test:0.06945, lr:2.71e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.044, tt:5800.045\n",
      "Ep:181, loss:0.00001, loss_test:0.06936, lr:2.68e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.048, tt:5832.712\n",
      "Ep:182, loss:0.00001, loss_test:0.06944, lr:2.65e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.044, tt:5864.133\n",
      "Ep:183, loss:0.00001, loss_test:0.06929, lr:2.63e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.045, tt:5896.301\n",
      "Ep:184, loss:0.00001, loss_test:0.06937, lr:2.60e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.045, tt:5928.301\n",
      "Ep:185, loss:0.00001, loss_test:0.06955, lr:2.57e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.039, tt:5959.247\n",
      "Ep:186, loss:0.00001, loss_test:0.06939, lr:2.55e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.028, tt:5989.179\n",
      "Ep:187, loss:0.00001, loss_test:0.06928, lr:2.52e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.022, tt:6020.163\n",
      "Ep:188, loss:0.00001, loss_test:0.06927, lr:2.50e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.015, tt:6050.834\n",
      "Ep:189, loss:0.00001, loss_test:0.06928, lr:2.47e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.009, tt:6081.628\n",
      "Ep:190, loss:0.00001, loss_test:0.06940, lr:2.45e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.011, tt:6114.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00001, loss_test:0.06936, lr:2.42e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.014, tt:6146.636\n",
      "Ep:192, loss:0.00001, loss_test:0.06921, lr:2.40e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.016, tt:6179.161\n",
      "Ep:193, loss:0.00001, loss_test:0.06940, lr:2.38e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.016, tt:6211.040\n",
      "Ep:194, loss:0.00001, loss_test:0.06948, lr:2.35e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.016, tt:6243.103\n",
      "Ep:195, loss:0.00001, loss_test:0.06924, lr:2.33e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.023, tt:6276.460\n",
      "Ep:196, loss:0.00001, loss_test:0.06922, lr:2.31e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.014, tt:6306.767\n",
      "Ep:197, loss:0.00001, loss_test:0.06936, lr:2.28e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.002, tt:6336.407\n",
      "Ep:198, loss:0.00001, loss_test:0.06949, lr:2.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.977, tt:6363.462\n",
      "Ep:199, loss:0.00001, loss_test:0.06934, lr:2.24e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.951, tt:6390.290\n",
      "Ep:200, loss:0.00001, loss_test:0.06919, lr:2.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.922, tt:6416.314\n",
      "Ep:201, loss:0.00001, loss_test:0.06925, lr:2.19e-03, fs:0.78107 (r=0.667,p=0.943),  time:31.901, tt:6444.069\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02143, lr:6.00e-02, fs:0.63469 (r=0.869,p=0.500),  time:24.146, tt:24.146\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02357, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.291, tt:48.581\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02528, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.056, tt:75.168\n",
      "Ep:3, loss:0.00005, loss_test:0.02583, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.266, tt:101.063\n",
      "Ep:4, loss:0.00005, loss_test:0.02546, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.836, tt:124.179\n",
      "Ep:5, loss:0.00005, loss_test:0.02458, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.595, tt:147.568\n",
      "Ep:6, loss:0.00004, loss_test:0.02347, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:24.552, tt:171.863\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:24.610, tt:196.884\n",
      "Ep:8, loss:0.00004, loss_test:0.02134, lr:6.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:24.725, tt:222.522\n",
      "Ep:9, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:24.831, tt:248.306\n",
      "Ep:10, loss:0.00004, loss_test:0.02056, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:24.897, tt:273.869\n",
      "Ep:11, loss:0.00004, loss_test:0.02034, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:24.866, tt:298.392\n",
      "Ep:12, loss:0.00004, loss_test:0.01997, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:24.912, tt:323.854\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01961, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:24.935, tt:349.085\n",
      "Ep:14, loss:0.00004, loss_test:0.01945, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:24.931, tt:373.972\n",
      "Ep:15, loss:0.00004, loss_test:0.01937, lr:6.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:24.966, tt:399.460\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01917, lr:6.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:24.941, tt:424.004\n",
      "Ep:17, loss:0.00003, loss_test:0.01890, lr:6.00e-02, fs:0.68613 (r=0.949,p=0.537),  time:25.035, tt:450.639\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01861, lr:6.00e-02, fs:0.68889 (r=0.939,p=0.544),  time:25.020, tt:475.379\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01837, lr:6.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:25.024, tt:500.486\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01813, lr:6.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:25.024, tt:525.494\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01788, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:25.037, tt:550.815\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:25.012, tt:575.268\n",
      "Ep:23, loss:0.00003, loss_test:0.01743, lr:6.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:25.017, tt:600.418\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:25.070, tt:626.740\n",
      "Ep:25, loss:0.00003, loss_test:0.01707, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:25.104, tt:652.695\n",
      "Ep:26, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:25.084, tt:677.263\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01673, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:25.093, tt:702.609\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:25.104, tt:728.021\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:25.113, tt:753.381\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01616, lr:6.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:25.135, tt:779.179\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.75630 (r=0.909,p=0.647),  time:25.169, tt:805.421\n",
      "Ep:32, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:25.178, tt:830.868\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:25.158, tt:855.369\n",
      "Ep:34, loss:0.00002, loss_test:0.01552, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:25.155, tt:880.412\n",
      "Ep:35, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:25.183, tt:906.570\n",
      "Ep:36, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:25.246, tt:934.090\n",
      "Ep:37, loss:0.00002, loss_test:0.01507, lr:6.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:25.270, tt:960.245\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01493, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:25.273, tt:985.654\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:25.299, tt:1011.956\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:25.296, tt:1037.117\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:25.298, tt:1062.522\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01443, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:25.311, tt:1088.365\n",
      "Ep:43, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:25.323, tt:1114.219\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:25.342, tt:1140.408\n",
      "Ep:45, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:25.348, tt:1166.011\n",
      "Ep:46, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:25.326, tt:1190.312\n",
      "Ep:47, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:25.304, tt:1214.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:25.325, tt:1240.913\n",
      "Ep:49, loss:0.00002, loss_test:0.01375, lr:6.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:25.333, tt:1266.625\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:25.358, tt:1293.264\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:25.353, tt:1318.341\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:25.365, tt:1344.354\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:25.368, tt:1369.862\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01341, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:25.351, tt:1394.281\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:25.352, tt:1419.717\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:25.360, tt:1445.514\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:25.378, tt:1471.904\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.370, tt:1496.834\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01317, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.378, tt:1522.662\n",
      "Ep:60, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.371, tt:1547.639\n",
      "Ep:61, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:25.376, tt:1573.294\n",
      "Ep:62, loss:0.00001, loss_test:0.01307, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.385, tt:1599.261\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01304, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:25.384, tt:1624.562\n",
      "Ep:64, loss:0.00001, loss_test:0.01301, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.377, tt:1649.481\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01297, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:25.374, tt:1674.713\n",
      "Ep:66, loss:0.00001, loss_test:0.01295, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:25.401, tt:1701.851\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01293, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:25.394, tt:1726.778\n",
      "Ep:68, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:25.390, tt:1751.911\n",
      "Ep:69, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:25.388, tt:1777.162\n",
      "Ep:70, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:25.404, tt:1803.649\n",
      "Ep:71, loss:0.00001, loss_test:0.01292, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:25.405, tt:1829.172\n",
      "Ep:72, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:25.408, tt:1854.803\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01292, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:25.405, tt:1880.006\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01290, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.383, tt:1903.692\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01290, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.361, tt:1927.454\n",
      "Ep:76, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.352, tt:1952.125\n",
      "Ep:77, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.355, tt:1977.716\n",
      "Ep:78, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.365, tt:2003.810\n",
      "Ep:79, loss:0.00001, loss_test:0.01298, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:25.366, tt:2029.281\n",
      "Ep:80, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:25.365, tt:2054.588\n",
      "Ep:81, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:25.366, tt:2079.971\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01305, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:25.370, tt:2105.747\n",
      "Ep:83, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:25.364, tt:2130.584\n",
      "Ep:84, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:25.367, tt:2156.213\n",
      "Ep:85, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:25.367, tt:2181.588\n",
      "Ep:86, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:25.382, tt:2208.217\n",
      "Ep:87, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:25.383, tt:2233.665\n",
      "Ep:88, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:25.395, tt:2260.116\n",
      "Ep:89, loss:0.00001, loss_test:0.01325, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:25.403, tt:2286.274\n",
      "Ep:90, loss:0.00001, loss_test:0.01328, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:25.413, tt:2312.609\n",
      "Ep:91, loss:0.00001, loss_test:0.01330, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:25.418, tt:2338.493\n",
      "Ep:92, loss:0.00001, loss_test:0.01340, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:25.428, tt:2364.772\n",
      "Ep:93, loss:0.00001, loss_test:0.01337, lr:5.94e-02, fs:0.84264 (r=0.838,p=0.847),  time:25.434, tt:2390.765\n",
      "Ep:94, loss:0.00001, loss_test:0.01336, lr:5.88e-02, fs:0.84264 (r=0.838,p=0.847),  time:25.450, tt:2417.716\n",
      "Ep:95, loss:0.00001, loss_test:0.01345, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:25.457, tt:2443.862\n",
      "Ep:96, loss:0.00001, loss_test:0.01357, lr:5.76e-02, fs:0.84103 (r=0.828,p=0.854),  time:25.458, tt:2469.381\n",
      "Ep:97, loss:0.00001, loss_test:0.01356, lr:5.71e-02, fs:0.84103 (r=0.828,p=0.854),  time:25.456, tt:2494.729\n",
      "Ep:98, loss:0.00001, loss_test:0.01359, lr:5.65e-02, fs:0.84536 (r=0.828,p=0.863),  time:25.467, tt:2521.213\n",
      "Ep:99, loss:0.00001, loss_test:0.01363, lr:5.59e-02, fs:0.84536 (r=0.828,p=0.863),  time:25.475, tt:2547.456\n",
      "Ep:100, loss:0.00001, loss_test:0.01369, lr:5.54e-02, fs:0.84536 (r=0.828,p=0.863),  time:25.487, tt:2574.142\n",
      "Ep:101, loss:0.00001, loss_test:0.01375, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.513, tt:2602.374\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01373, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.531, tt:2629.736\n",
      "Ep:103, loss:0.00001, loss_test:0.01381, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.548, tt:2657.027\n",
      "Ep:104, loss:0.00001, loss_test:0.01384, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.554, tt:2683.166\n",
      "Ep:105, loss:0.00001, loss_test:0.01391, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.557, tt:2709.060\n",
      "Ep:106, loss:0.00001, loss_test:0.01394, lr:5.48e-02, fs:0.85417 (r=0.828,p=0.882),  time:25.558, tt:2734.675\n",
      "Ep:107, loss:0.00001, loss_test:0.01401, lr:5.48e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.561, tt:2760.573\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01402, lr:5.48e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.565, tt:2786.570\n",
      "Ep:109, loss:0.00001, loss_test:0.01407, lr:5.48e-02, fs:0.86316 (r=0.828,p=0.901),  time:25.572, tt:2812.906\n",
      "Ep:110, loss:0.00001, loss_test:0.01414, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.576, tt:2838.892\n",
      "Ep:111, loss:0.00001, loss_test:0.01419, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.584, tt:2865.369\n",
      "Ep:112, loss:0.00001, loss_test:0.01416, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.588, tt:2891.497\n",
      "Ep:113, loss:0.00001, loss_test:0.01425, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.591, tt:2917.373\n",
      "Ep:114, loss:0.00001, loss_test:0.01428, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:25.589, tt:2942.789\n",
      "Ep:115, loss:0.00001, loss_test:0.01431, lr:5.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.584, tt:2967.768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00001, loss_test:0.01434, lr:5.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.583, tt:2993.186\n",
      "Ep:117, loss:0.00001, loss_test:0.01443, lr:5.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.594, tt:3020.053\n",
      "Ep:118, loss:0.00001, loss_test:0.01444, lr:5.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.598, tt:3046.208\n",
      "Ep:119, loss:0.00001, loss_test:0.01447, lr:5.43e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.601, tt:3072.062\n",
      "Ep:120, loss:0.00001, loss_test:0.01461, lr:5.37e-02, fs:0.84492 (r=0.798,p=0.898),  time:25.610, tt:3098.755\n",
      "Ep:121, loss:0.00001, loss_test:0.01464, lr:5.32e-02, fs:0.84492 (r=0.798,p=0.898),  time:25.619, tt:3125.534\n",
      "Ep:122, loss:0.00001, loss_test:0.01462, lr:5.27e-02, fs:0.84492 (r=0.798,p=0.898),  time:25.621, tt:3151.383\n",
      "Ep:123, loss:0.00001, loss_test:0.01469, lr:5.21e-02, fs:0.83871 (r=0.788,p=0.897),  time:25.621, tt:3177.030\n",
      "Ep:124, loss:0.00001, loss_test:0.01474, lr:5.16e-02, fs:0.82609 (r=0.768,p=0.894),  time:25.627, tt:3203.317\n",
      "Ep:125, loss:0.00001, loss_test:0.01482, lr:5.11e-02, fs:0.82609 (r=0.768,p=0.894),  time:25.631, tt:3229.485\n",
      "Ep:126, loss:0.00001, loss_test:0.01485, lr:5.06e-02, fs:0.82609 (r=0.768,p=0.894),  time:25.628, tt:3254.785\n",
      "Ep:127, loss:0.00001, loss_test:0.01486, lr:5.01e-02, fs:0.82162 (r=0.768,p=0.884),  time:25.651, tt:3283.357\n",
      "Ep:128, loss:0.00001, loss_test:0.01490, lr:4.96e-02, fs:0.82162 (r=0.768,p=0.884),  time:25.653, tt:3309.188\n",
      "Ep:129, loss:0.00001, loss_test:0.01499, lr:4.91e-02, fs:0.80874 (r=0.747,p=0.881),  time:25.644, tt:3333.693\n",
      "Ep:130, loss:0.00001, loss_test:0.01497, lr:4.86e-02, fs:0.81522 (r=0.758,p=0.882),  time:25.650, tt:3360.148\n",
      "Ep:131, loss:0.00001, loss_test:0.01500, lr:4.81e-02, fs:0.81522 (r=0.758,p=0.882),  time:25.649, tt:3385.632\n",
      "Ep:132, loss:0.00001, loss_test:0.01511, lr:4.76e-02, fs:0.81319 (r=0.747,p=0.892),  time:25.638, tt:3409.866\n",
      "Ep:133, loss:0.00001, loss_test:0.01516, lr:4.71e-02, fs:0.80663 (r=0.737,p=0.890),  time:25.647, tt:3436.701\n",
      "Ep:134, loss:0.00001, loss_test:0.01516, lr:4.67e-02, fs:0.80663 (r=0.737,p=0.890),  time:25.638, tt:3461.079\n",
      "Ep:135, loss:0.00001, loss_test:0.01519, lr:4.62e-02, fs:0.80663 (r=0.737,p=0.890),  time:25.634, tt:3486.231\n",
      "Ep:136, loss:0.00001, loss_test:0.01523, lr:4.57e-02, fs:0.80663 (r=0.737,p=0.890),  time:25.613, tt:3508.966\n",
      "Ep:137, loss:0.00001, loss_test:0.01528, lr:4.53e-02, fs:0.79330 (r=0.717,p=0.887),  time:25.613, tt:3534.652\n",
      "Ep:138, loss:0.00000, loss_test:0.01525, lr:4.48e-02, fs:0.79330 (r=0.717,p=0.887),  time:25.617, tt:3560.750\n",
      "Ep:139, loss:0.00000, loss_test:0.01532, lr:4.44e-02, fs:0.77966 (r=0.697,p=0.885),  time:25.614, tt:3585.928\n",
      "Ep:140, loss:0.00000, loss_test:0.01540, lr:4.39e-02, fs:0.77966 (r=0.697,p=0.885),  time:25.618, tt:3612.203\n",
      "Ep:141, loss:0.00000, loss_test:0.01540, lr:4.35e-02, fs:0.77966 (r=0.697,p=0.885),  time:25.614, tt:3637.246\n",
      "Ep:142, loss:0.00000, loss_test:0.01545, lr:4.31e-02, fs:0.77966 (r=0.697,p=0.885),  time:25.613, tt:3662.629\n",
      "Ep:143, loss:0.00000, loss_test:0.01549, lr:4.26e-02, fs:0.77966 (r=0.697,p=0.885),  time:25.613, tt:3688.234\n",
      "Ep:144, loss:0.00000, loss_test:0.01554, lr:4.22e-02, fs:0.76571 (r=0.677,p=0.882),  time:25.609, tt:3713.317\n",
      "Ep:145, loss:0.00000, loss_test:0.01558, lr:4.18e-02, fs:0.76571 (r=0.677,p=0.882),  time:25.612, tt:3739.312\n",
      "Ep:146, loss:0.00000, loss_test:0.01560, lr:4.14e-02, fs:0.75862 (r=0.667,p=0.880),  time:25.610, tt:3764.722\n",
      "Ep:147, loss:0.00000, loss_test:0.01564, lr:4.10e-02, fs:0.75862 (r=0.667,p=0.880),  time:25.611, tt:3790.372\n",
      "Ep:148, loss:0.00000, loss_test:0.01566, lr:4.05e-02, fs:0.75862 (r=0.667,p=0.880),  time:25.615, tt:3816.676\n",
      "Ep:149, loss:0.00000, loss_test:0.01567, lr:4.01e-02, fs:0.75862 (r=0.667,p=0.880),  time:25.611, tt:3841.644\n",
      "Ep:150, loss:0.00000, loss_test:0.01580, lr:3.97e-02, fs:0.75862 (r=0.667,p=0.880),  time:25.618, tt:3868.291\n",
      "Ep:151, loss:0.00000, loss_test:0.01581, lr:3.93e-02, fs:0.75145 (r=0.657,p=0.878),  time:25.628, tt:3895.511\n",
      "Ep:152, loss:0.00000, loss_test:0.01574, lr:3.89e-02, fs:0.75145 (r=0.657,p=0.878),  time:25.627, tt:3920.888\n",
      "Ep:153, loss:0.00000, loss_test:0.01580, lr:3.86e-02, fs:0.75145 (r=0.657,p=0.878),  time:25.647, tt:3949.696\n",
      "Ep:154, loss:0.00000, loss_test:0.01590, lr:3.82e-02, fs:0.75145 (r=0.657,p=0.878),  time:25.646, tt:3975.148\n",
      "Ep:155, loss:0.00000, loss_test:0.01592, lr:3.78e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.650, tt:4001.467\n",
      "Ep:156, loss:0.00000, loss_test:0.01589, lr:3.74e-02, fs:0.75145 (r=0.657,p=0.878),  time:25.656, tt:4027.920\n",
      "Ep:157, loss:0.00000, loss_test:0.01598, lr:3.70e-02, fs:0.75145 (r=0.657,p=0.878),  time:25.654, tt:4053.339\n",
      "Ep:158, loss:0.00000, loss_test:0.01604, lr:3.67e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.649, tt:4078.167\n",
      "Ep:159, loss:0.00000, loss_test:0.01606, lr:3.63e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.650, tt:4103.922\n",
      "Ep:160, loss:0.00000, loss_test:0.01605, lr:3.59e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.644, tt:4128.757\n",
      "Ep:161, loss:0.00000, loss_test:0.01608, lr:3.56e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.640, tt:4153.745\n",
      "Ep:162, loss:0.00000, loss_test:0.01615, lr:3.52e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.642, tt:4179.600\n",
      "Ep:163, loss:0.00000, loss_test:0.01619, lr:3.49e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.640, tt:4205.011\n",
      "Ep:164, loss:0.00000, loss_test:0.01620, lr:3.45e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.639, tt:4230.446\n",
      "Ep:165, loss:0.00000, loss_test:0.01621, lr:3.42e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.638, tt:4255.961\n",
      "Ep:166, loss:0.00000, loss_test:0.01624, lr:3.38e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.642, tt:4282.161\n",
      "Ep:167, loss:0.00000, loss_test:0.01628, lr:3.35e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.644, tt:4308.189\n",
      "Ep:168, loss:0.00000, loss_test:0.01632, lr:3.32e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.641, tt:4333.376\n",
      "Ep:169, loss:0.00000, loss_test:0.01633, lr:3.28e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.645, tt:4359.711\n",
      "Ep:170, loss:0.00000, loss_test:0.01634, lr:3.25e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.649, tt:4385.938\n",
      "Ep:171, loss:0.00000, loss_test:0.01639, lr:3.22e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.651, tt:4412.039\n",
      "Ep:172, loss:0.00000, loss_test:0.01643, lr:3.19e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.659, tt:4438.941\n",
      "Ep:173, loss:0.00000, loss_test:0.01644, lr:3.15e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.656, tt:4464.078\n",
      "Ep:174, loss:0.00000, loss_test:0.01646, lr:3.12e-02, fs:0.75581 (r=0.657,p=0.890),  time:25.658, tt:4490.192\n",
      "Ep:175, loss:0.00000, loss_test:0.01650, lr:3.09e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.664, tt:4516.831\n",
      "Ep:176, loss:0.00000, loss_test:0.01654, lr:3.06e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.668, tt:4543.308\n",
      "Ep:177, loss:0.00000, loss_test:0.01658, lr:3.03e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.667, tt:4568.702\n",
      "Ep:178, loss:0.00000, loss_test:0.01657, lr:3.00e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.663, tt:4593.645\n",
      "Ep:179, loss:0.00000, loss_test:0.01658, lr:2.97e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.675, tt:4621.440\n",
      "Ep:180, loss:0.00000, loss_test:0.01664, lr:2.94e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.680, tt:4648.158\n",
      "Ep:181, loss:0.00000, loss_test:0.01668, lr:2.91e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.681, tt:4674.028\n",
      "Ep:182, loss:0.00000, loss_test:0.01667, lr:2.88e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.673, tt:4698.192\n",
      "Ep:183, loss:0.00000, loss_test:0.01669, lr:2.85e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.673, tt:4723.815\n",
      "Ep:184, loss:0.00000, loss_test:0.01674, lr:2.82e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.675, tt:4749.790\n",
      "Ep:185, loss:0.00000, loss_test:0.01676, lr:2.80e-02, fs:0.76023 (r=0.657,p=0.903),  time:25.673, tt:4775.192\n",
      "Ep:186, loss:0.00000, loss_test:0.01675, lr:2.77e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.679, tt:4801.983\n",
      "Ep:187, loss:0.00000, loss_test:0.01682, lr:2.74e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.680, tt:4827.841\n",
      "Ep:188, loss:0.00000, loss_test:0.01685, lr:2.71e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.672, tt:4852.062\n",
      "Ep:189, loss:0.00000, loss_test:0.01686, lr:2.69e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.673, tt:4877.942\n",
      "Ep:190, loss:0.00000, loss_test:0.01688, lr:2.66e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.669, tt:4902.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00000, loss_test:0.01690, lr:2.63e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.671, tt:4928.887\n",
      "Ep:192, loss:0.00000, loss_test:0.01692, lr:2.61e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.670, tt:4954.215\n",
      "Ep:193, loss:0.00000, loss_test:0.01693, lr:2.58e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.662, tt:4978.406\n",
      "Ep:194, loss:0.00000, loss_test:0.01696, lr:2.55e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.668, tt:5005.343\n",
      "Ep:195, loss:0.00000, loss_test:0.01699, lr:2.53e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.662, tt:5029.837\n",
      "Ep:196, loss:0.00000, loss_test:0.01703, lr:2.50e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.647, tt:5052.465\n",
      "Ep:197, loss:0.00000, loss_test:0.01701, lr:2.48e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.643, tt:5077.259\n",
      "Ep:198, loss:0.00000, loss_test:0.01702, lr:2.45e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.646, tt:5103.594\n",
      "Ep:199, loss:0.00000, loss_test:0.01706, lr:2.43e-02, fs:0.76471 (r=0.657,p=0.915),  time:25.628, tt:5125.593\n",
      "Ep:200, loss:0.00000, loss_test:0.01709, lr:2.40e-02, fs:0.75740 (r=0.646,p=0.914),  time:25.616, tt:5148.769\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14461, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.197, tt:26.197\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14381, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.179, tt:52.358\n",
      "Ep:2, loss:0.00028, loss_test:0.14249, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.646, tt:79.937\n",
      "Ep:3, loss:0.00027, loss_test:0.14043, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.453, tt:109.811\n",
      "Ep:4, loss:0.00027, loss_test:0.13742, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:27.603, tt:138.014\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.13283, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:27.224, tt:163.341\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12650, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:26.944, tt:188.608\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12283, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:27.109, tt:216.868\n",
      "Ep:8, loss:0.00023, loss_test:0.12053, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:27.178, tt:244.600\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11879, lr:1.00e-02, fs:0.68670 (r=0.808,p=0.597),  time:27.243, tt:272.429\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11981, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:27.119, tt:298.308\n",
      "Ep:11, loss:0.00022, loss_test:0.11802, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:27.096, tt:325.149\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.11496, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:27.098, tt:352.271\n",
      "Ep:13, loss:0.00020, loss_test:0.11336, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:27.174, tt:380.442\n",
      "Ep:14, loss:0.00020, loss_test:0.11255, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:27.141, tt:407.110\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10965, lr:1.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:27.122, tt:433.952\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10624, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:27.159, tt:461.710\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10583, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:27.138, tt:488.476\n",
      "Ep:18, loss:0.00018, loss_test:0.10697, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:27.045, tt:513.859\n",
      "Ep:19, loss:0.00017, loss_test:0.10454, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:27.062, tt:541.237\n",
      "Ep:20, loss:0.00017, loss_test:0.10195, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:27.070, tt:568.461\n",
      "Ep:21, loss:0.00017, loss_test:0.10141, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:27.102, tt:596.240\n",
      "Ep:22, loss:0.00016, loss_test:0.10127, lr:1.00e-02, fs:0.75000 (r=0.848,p=0.672),  time:27.135, tt:624.097\n",
      "Ep:23, loss:0.00016, loss_test:0.09904, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:27.137, tt:651.294\n",
      "Ep:24, loss:0.00015, loss_test:0.09892, lr:1.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:27.105, tt:677.613\n",
      "Ep:25, loss:0.00015, loss_test:0.09710, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:27.088, tt:704.292\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09565, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:27.090, tt:731.434\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09494, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:27.102, tt:758.852\n",
      "Ep:28, loss:0.00014, loss_test:0.09408, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:27.151, tt:787.393\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09302, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:27.158, tt:814.754\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.09139, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:27.168, tt:842.200\n",
      "Ep:31, loss:0.00012, loss_test:0.09023, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:27.213, tt:870.811\n",
      "Ep:32, loss:0.00012, loss_test:0.08965, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:27.184, tt:897.082\n",
      "Ep:33, loss:0.00012, loss_test:0.08836, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:27.175, tt:923.942\n",
      "Ep:34, loss:0.00011, loss_test:0.08774, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:27.176, tt:951.161\n",
      "Ep:35, loss:0.00011, loss_test:0.08654, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:27.150, tt:977.390\n",
      "Ep:36, loss:0.00011, loss_test:0.08587, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:27.139, tt:1004.138\n",
      "Ep:37, loss:0.00010, loss_test:0.08464, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:27.112, tt:1030.273\n",
      "Ep:38, loss:0.00010, loss_test:0.08377, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:27.103, tt:1057.008\n",
      "Ep:39, loss:0.00010, loss_test:0.08117, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:27.088, tt:1083.529\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.08188, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:27.107, tt:1111.400\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07953, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:27.060, tt:1136.517\n",
      "Ep:42, loss:0.00009, loss_test:0.07856, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:27.069, tt:1163.961\n",
      "Ep:43, loss:0.00009, loss_test:0.07991, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:27.080, tt:1191.509\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.07689, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:27.073, tt:1218.283\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.07768, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:27.078, tt:1245.568\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.07571, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:27.066, tt:1272.088\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07424, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:27.055, tt:1298.649\n",
      "Ep:48, loss:0.00007, loss_test:0.07489, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:27.054, tt:1325.641\n",
      "Ep:49, loss:0.00007, loss_test:0.07454, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.071, tt:1353.569\n",
      "Ep:50, loss:0.00007, loss_test:0.07284, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:27.089, tt:1381.532\n",
      "Ep:51, loss:0.00007, loss_test:0.07330, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:27.095, tt:1408.959\n",
      "Ep:52, loss:0.00006, loss_test:0.07244, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:27.115, tt:1437.083\n",
      "Ep:53, loss:0.00006, loss_test:0.07132, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:27.125, tt:1464.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00006, loss_test:0.07126, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:27.133, tt:1492.333\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.07103, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:27.142, tt:1519.973\n",
      "Ep:56, loss:0.00006, loss_test:0.06938, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:27.155, tt:1547.851\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.07241, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.156, tt:1575.027\n",
      "Ep:58, loss:0.00005, loss_test:0.07004, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:27.181, tt:1603.662\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00005, loss_test:0.06926, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:27.164, tt:1629.846\n",
      "Ep:60, loss:0.00005, loss_test:0.07284, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:27.163, tt:1656.933\n",
      "Ep:61, loss:0.00005, loss_test:0.06949, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:27.174, tt:1684.794\n",
      "Ep:62, loss:0.00005, loss_test:0.06952, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:27.204, tt:1713.843\n",
      "Ep:63, loss:0.00005, loss_test:0.07201, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:27.186, tt:1739.886\n",
      "Ep:64, loss:0.00005, loss_test:0.06850, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:27.201, tt:1768.081\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.07044, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:27.210, tt:1795.831\n",
      "Ep:66, loss:0.00004, loss_test:0.07086, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:27.201, tt:1822.498\n",
      "Ep:67, loss:0.00004, loss_test:0.06927, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:27.200, tt:1849.633\n",
      "Ep:68, loss:0.00004, loss_test:0.07104, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:27.193, tt:1876.301\n",
      "Ep:69, loss:0.00004, loss_test:0.07061, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:27.180, tt:1902.568\n",
      "Ep:70, loss:0.00004, loss_test:0.06888, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:27.187, tt:1930.246\n",
      "Ep:71, loss:0.00004, loss_test:0.06898, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:27.172, tt:1956.373\n",
      "Ep:72, loss:0.00004, loss_test:0.07102, lr:1.00e-02, fs:0.86667 (r=0.788,p=0.963),  time:27.185, tt:1984.504\n",
      "Ep:73, loss:0.00004, loss_test:0.06942, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:27.198, tt:2012.671\n",
      "Ep:74, loss:0.00004, loss_test:0.07057, lr:1.00e-02, fs:0.88268 (r=0.798,p=0.988),  time:27.191, tt:2039.342\n",
      "Ep:75, loss:0.00004, loss_test:0.07037, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:27.195, tt:2066.857\n",
      "Ep:76, loss:0.00003, loss_test:0.06878, lr:9.90e-03, fs:0.86188 (r=0.788,p=0.951),  time:27.192, tt:2093.767\n",
      "Ep:77, loss:0.00003, loss_test:0.06974, lr:9.80e-03, fs:0.87151 (r=0.788,p=0.975),  time:27.201, tt:2121.709\n",
      "Ep:78, loss:0.00003, loss_test:0.07041, lr:9.70e-03, fs:0.86813 (r=0.798,p=0.952),  time:27.208, tt:2149.456\n",
      "Ep:79, loss:0.00003, loss_test:0.07001, lr:9.61e-03, fs:0.84746 (r=0.758,p=0.962),  time:27.193, tt:2175.443\n",
      "Ep:80, loss:0.00003, loss_test:0.06886, lr:9.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:27.206, tt:2203.697\n",
      "Ep:81, loss:0.00003, loss_test:0.07082, lr:9.41e-03, fs:0.81657 (r=0.697,p=0.986),  time:27.216, tt:2231.736\n",
      "Ep:82, loss:0.00003, loss_test:0.07167, lr:9.32e-03, fs:0.83799 (r=0.758,p=0.938),  time:27.216, tt:2258.903\n",
      "Ep:83, loss:0.00003, loss_test:0.06937, lr:9.23e-03, fs:0.86034 (r=0.778,p=0.963),  time:27.205, tt:2285.198\n",
      "Ep:84, loss:0.00003, loss_test:0.07016, lr:9.14e-03, fs:0.81871 (r=0.707,p=0.972),  time:27.211, tt:2312.950\n",
      "Ep:85, loss:0.00003, loss_test:0.07129, lr:9.04e-03, fs:0.84270 (r=0.758,p=0.949),  time:27.227, tt:2341.513\n",
      "Ep:86, loss:0.00003, loss_test:0.07102, lr:8.95e-03, fs:0.79518 (r=0.667,p=0.985),  time:27.236, tt:2369.531\n",
      "Ep:87, loss:0.00003, loss_test:0.07024, lr:8.86e-03, fs:0.82955 (r=0.737,p=0.948),  time:27.246, tt:2397.673\n",
      "Ep:88, loss:0.00003, loss_test:0.07175, lr:8.78e-03, fs:0.78049 (r=0.646,p=0.985),  time:27.247, tt:2424.961\n",
      "Ep:89, loss:0.00003, loss_test:0.07148, lr:8.69e-03, fs:0.79042 (r=0.667,p=0.971),  time:27.256, tt:2453.085\n",
      "Ep:90, loss:0.00003, loss_test:0.07107, lr:8.60e-03, fs:0.79290 (r=0.677,p=0.957),  time:27.252, tt:2479.961\n",
      "Ep:91, loss:0.00002, loss_test:0.07256, lr:8.51e-03, fs:0.75610 (r=0.626,p=0.954),  time:27.266, tt:2508.517\n",
      "Ep:92, loss:0.00002, loss_test:0.07191, lr:8.43e-03, fs:0.79042 (r=0.667,p=0.971),  time:27.278, tt:2536.825\n",
      "Ep:93, loss:0.00002, loss_test:0.07181, lr:8.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.277, tt:2563.992\n",
      "Ep:94, loss:0.00002, loss_test:0.07236, lr:8.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.282, tt:2591.783\n",
      "Ep:95, loss:0.00002, loss_test:0.07252, lr:8.18e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.291, tt:2619.954\n",
      "Ep:96, loss:0.00002, loss_test:0.07340, lr:8.10e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.291, tt:2647.245\n",
      "Ep:97, loss:0.00002, loss_test:0.07293, lr:8.02e-03, fs:0.77108 (r=0.646,p=0.955),  time:27.289, tt:2674.356\n",
      "Ep:98, loss:0.00002, loss_test:0.07515, lr:7.94e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.296, tt:2702.351\n",
      "Ep:99, loss:0.00002, loss_test:0.07398, lr:7.86e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.299, tt:2729.854\n",
      "Ep:100, loss:0.00002, loss_test:0.07431, lr:7.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.309, tt:2758.252\n",
      "Ep:101, loss:0.00002, loss_test:0.07507, lr:7.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.307, tt:2785.288\n",
      "Ep:102, loss:0.00002, loss_test:0.07450, lr:7.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.303, tt:2812.170\n",
      "Ep:103, loss:0.00002, loss_test:0.07464, lr:7.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.297, tt:2838.913\n",
      "Ep:104, loss:0.00002, loss_test:0.07460, lr:7.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.286, tt:2864.987\n",
      "Ep:105, loss:0.00002, loss_test:0.07543, lr:7.40e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.285, tt:2892.171\n",
      "Ep:106, loss:0.00002, loss_test:0.07521, lr:7.32e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.292, tt:2920.210\n",
      "Ep:107, loss:0.00002, loss_test:0.07454, lr:7.25e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.281, tt:2946.320\n",
      "Ep:108, loss:0.00002, loss_test:0.07544, lr:7.18e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.280, tt:2973.547\n",
      "Ep:109, loss:0.00002, loss_test:0.07482, lr:7.11e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.281, tt:3000.963\n",
      "Ep:110, loss:0.00002, loss_test:0.07527, lr:7.03e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.282, tt:3028.326\n",
      "Ep:111, loss:0.00002, loss_test:0.07588, lr:6.96e-03, fs:0.76074 (r=0.626,p=0.969),  time:27.285, tt:3055.883\n",
      "Ep:112, loss:0.00002, loss_test:0.07503, lr:6.89e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.284, tt:3083.108\n",
      "Ep:113, loss:0.00002, loss_test:0.07450, lr:6.83e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.279, tt:3109.755\n",
      "Ep:114, loss:0.00002, loss_test:0.07566, lr:6.76e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.286, tt:3137.938\n",
      "Ep:115, loss:0.00002, loss_test:0.07579, lr:6.69e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.305, tt:3167.369\n",
      "Ep:116, loss:0.00002, loss_test:0.07557, lr:6.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.314, tt:3195.749\n",
      "Ep:117, loss:0.00002, loss_test:0.07647, lr:6.56e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.323, tt:3224.069\n",
      "Ep:118, loss:0.00001, loss_test:0.07494, lr:6.49e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.322, tt:3251.367\n",
      "Ep:119, loss:0.00001, loss_test:0.07653, lr:6.43e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.324, tt:3278.879\n",
      "Ep:120, loss:0.00001, loss_test:0.07513, lr:6.36e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.314, tt:3304.972\n",
      "Ep:121, loss:0.00001, loss_test:0.07519, lr:6.30e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.321, tt:3333.125\n",
      "Ep:122, loss:0.00001, loss_test:0.07527, lr:6.24e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.328, tt:3361.377\n",
      "Ep:123, loss:0.00001, loss_test:0.07519, lr:6.17e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.350, tt:3391.446\n",
      "Ep:124, loss:0.00001, loss_test:0.07647, lr:6.11e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.376, tt:3421.956\n",
      "Ep:125, loss:0.00001, loss_test:0.07460, lr:6.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.373, tt:3448.947\n",
      "Ep:126, loss:0.00001, loss_test:0.07580, lr:5.99e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.404, tt:3480.310\n",
      "Ep:127, loss:0.00001, loss_test:0.07565, lr:5.93e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.406, tt:3508.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00001, loss_test:0.07483, lr:5.87e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.410, tt:3535.850\n",
      "Ep:129, loss:0.00001, loss_test:0.07623, lr:5.81e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.399, tt:3561.855\n",
      "Ep:130, loss:0.00001, loss_test:0.07513, lr:5.75e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.404, tt:3589.911\n",
      "Ep:131, loss:0.00001, loss_test:0.07521, lr:5.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.403, tt:3617.204\n",
      "Ep:132, loss:0.00001, loss_test:0.07533, lr:5.64e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.403, tt:3644.607\n",
      "Ep:133, loss:0.00001, loss_test:0.07537, lr:5.58e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.398, tt:3671.302\n",
      "Ep:134, loss:0.00001, loss_test:0.07503, lr:5.53e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.413, tt:3700.810\n",
      "Ep:135, loss:0.00001, loss_test:0.07533, lr:5.47e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.415, tt:3728.416\n",
      "Ep:136, loss:0.00001, loss_test:0.07491, lr:5.42e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.427, tt:3757.491\n",
      "Ep:137, loss:0.00001, loss_test:0.07542, lr:5.36e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.427, tt:3784.982\n",
      "Ep:138, loss:0.00001, loss_test:0.07618, lr:5.31e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.431, tt:3812.873\n",
      "Ep:139, loss:0.00001, loss_test:0.07559, lr:5.26e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.440, tt:3841.559\n",
      "Ep:140, loss:0.00001, loss_test:0.07521, lr:5.20e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.461, tt:3871.944\n",
      "Ep:141, loss:0.00001, loss_test:0.07607, lr:5.15e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.459, tt:3899.219\n",
      "Ep:142, loss:0.00001, loss_test:0.07592, lr:5.10e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.461, tt:3926.919\n",
      "Ep:143, loss:0.00001, loss_test:0.07519, lr:5.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.453, tt:3953.186\n",
      "Ep:144, loss:0.00001, loss_test:0.07602, lr:5.00e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.439, tt:3978.658\n",
      "Ep:145, loss:0.00001, loss_test:0.07678, lr:4.95e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.429, tt:4004.598\n",
      "Ep:146, loss:0.00001, loss_test:0.07551, lr:4.90e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.418, tt:4030.501\n",
      "Ep:147, loss:0.00001, loss_test:0.07587, lr:4.85e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.423, tt:4058.677\n",
      "Ep:148, loss:0.00001, loss_test:0.07667, lr:4.80e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.428, tt:4086.815\n",
      "Ep:149, loss:0.00001, loss_test:0.07608, lr:4.75e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.431, tt:4114.649\n",
      "Ep:150, loss:0.00001, loss_test:0.07558, lr:4.71e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.424, tt:4140.964\n",
      "Ep:151, loss:0.00001, loss_test:0.07556, lr:4.66e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.434, tt:4170.032\n",
      "Ep:152, loss:0.00001, loss_test:0.07776, lr:4.61e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.422, tt:4195.619\n",
      "Ep:153, loss:0.00001, loss_test:0.07644, lr:4.57e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.421, tt:4222.814\n",
      "Ep:154, loss:0.00001, loss_test:0.07532, lr:4.52e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.421, tt:4250.237\n",
      "Ep:155, loss:0.00001, loss_test:0.07670, lr:4.48e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.414, tt:4276.528\n",
      "Ep:156, loss:0.00001, loss_test:0.07652, lr:4.43e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.407, tt:4302.955\n",
      "Ep:157, loss:0.00001, loss_test:0.07540, lr:4.39e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.405, tt:4329.998\n",
      "Ep:158, loss:0.00001, loss_test:0.07634, lr:4.34e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.411, tt:4358.322\n",
      "Ep:159, loss:0.00001, loss_test:0.07734, lr:4.30e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.413, tt:4386.153\n",
      "Ep:160, loss:0.00001, loss_test:0.07673, lr:4.26e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.421, tt:4414.835\n",
      "Ep:161, loss:0.00001, loss_test:0.07590, lr:4.21e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.426, tt:4443.082\n",
      "Ep:162, loss:0.00001, loss_test:0.07574, lr:4.17e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.410, tt:4467.866\n",
      "Ep:163, loss:0.00001, loss_test:0.07686, lr:4.13e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.408, tt:4494.921\n",
      "Ep:164, loss:0.00001, loss_test:0.07632, lr:4.09e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.408, tt:4522.259\n",
      "Ep:165, loss:0.00001, loss_test:0.07592, lr:4.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.403, tt:4548.853\n",
      "Ep:166, loss:0.00001, loss_test:0.07634, lr:4.01e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.400, tt:4575.800\n",
      "Ep:167, loss:0.00001, loss_test:0.07628, lr:3.97e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.396, tt:4602.544\n",
      "Ep:168, loss:0.00001, loss_test:0.07601, lr:3.93e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.389, tt:4628.779\n",
      "Ep:169, loss:0.00001, loss_test:0.07618, lr:3.89e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.391, tt:4656.455\n",
      "Ep:170, loss:0.00001, loss_test:0.07667, lr:3.85e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.395, tt:4684.536\n",
      "Ep:171, loss:0.00001, loss_test:0.07647, lr:3.81e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.393, tt:4711.536\n",
      "Ep:172, loss:0.00001, loss_test:0.07636, lr:3.77e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.391, tt:4738.687\n",
      "Ep:173, loss:0.00001, loss_test:0.07675, lr:3.73e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.390, tt:4765.918\n",
      "Ep:174, loss:0.00001, loss_test:0.07655, lr:3.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.381, tt:4791.674\n",
      "Ep:175, loss:0.00001, loss_test:0.07617, lr:3.66e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.373, tt:4817.641\n",
      "Ep:176, loss:0.00001, loss_test:0.07672, lr:3.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.370, tt:4844.560\n",
      "Ep:177, loss:0.00001, loss_test:0.07698, lr:3.59e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.358, tt:4869.801\n",
      "Ep:178, loss:0.00001, loss_test:0.07637, lr:3.55e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.340, tt:4893.856\n",
      "Ep:179, loss:0.00001, loss_test:0.07634, lr:3.52e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.331, tt:4919.555\n",
      "Ep:180, loss:0.00001, loss_test:0.07672, lr:3.48e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.329, tt:4946.574\n",
      "Ep:181, loss:0.00001, loss_test:0.07677, lr:3.45e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.327, tt:4973.588\n",
      "Ep:182, loss:0.00001, loss_test:0.07642, lr:3.41e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.337, tt:5002.757\n",
      "Ep:183, loss:0.00001, loss_test:0.07693, lr:3.38e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.342, tt:5030.941\n",
      "Ep:184, loss:0.00001, loss_test:0.07750, lr:3.34e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.338, tt:5057.493\n",
      "Ep:185, loss:0.00001, loss_test:0.07701, lr:3.31e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.339, tt:5085.079\n",
      "Ep:186, loss:0.00001, loss_test:0.07691, lr:3.28e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.334, tt:5111.473\n",
      "Ep:187, loss:0.00001, loss_test:0.07720, lr:3.24e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.338, tt:5139.612\n",
      "Ep:188, loss:0.00001, loss_test:0.07642, lr:3.21e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.342, tt:5167.570\n",
      "Ep:189, loss:0.00001, loss_test:0.07714, lr:3.18e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.338, tt:5194.237\n",
      "Ep:190, loss:0.00001, loss_test:0.07736, lr:3.15e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.341, tt:5222.072\n",
      "Ep:191, loss:0.00001, loss_test:0.07685, lr:3.12e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.339, tt:5249.067\n",
      "Ep:192, loss:0.00001, loss_test:0.07695, lr:3.09e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.333, tt:5275.323\n",
      "Ep:193, loss:0.00001, loss_test:0.07653, lr:3.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.325, tt:5300.993\n",
      "Ep:194, loss:0.00001, loss_test:0.07723, lr:3.02e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.315, tt:5326.457\n",
      "Ep:195, loss:0.00001, loss_test:0.07678, lr:2.99e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.312, tt:5353.096\n",
      "Ep:196, loss:0.00001, loss_test:0.07677, lr:2.96e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.294, tt:5376.987\n",
      "Ep:197, loss:0.00001, loss_test:0.07725, lr:2.93e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.271, tt:5399.587\n",
      "Ep:198, loss:0.00001, loss_test:0.07688, lr:2.90e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.256, tt:5424.025\n",
      "Ep:199, loss:0.00001, loss_test:0.07710, lr:2.88e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.237, tt:5447.468\n",
      "Ep:200, loss:0.00001, loss_test:0.07675, lr:2.85e-03, fs:0.76543 (r=0.626,p=0.984),  time:27.207, tt:5468.551\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02278, lr:6.00e-02, fs:0.63636 (r=0.848,p=0.509),  time:31.520, tt:31.520\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02435, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:32.241, tt:64.481\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02591, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.657, tt:97.971\n",
      "Ep:3, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.452, tt:129.807\n",
      "Ep:4, loss:0.00005, loss_test:0.02434, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:32.657, tt:163.286\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02244, lr:6.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:32.787, tt:196.723\n",
      "Ep:6, loss:0.00004, loss_test:0.02080, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:33.078, tt:231.549\n",
      "Ep:7, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:33.195, tt:265.559\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01895, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:33.486, tt:301.378\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01809, lr:6.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:33.589, tt:335.895\n",
      "Ep:10, loss:0.00004, loss_test:0.01767, lr:6.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:33.546, tt:369.001\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01737, lr:6.00e-02, fs:0.71587 (r=0.980,p=0.564),  time:33.649, tt:403.782\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01684, lr:6.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:33.768, tt:438.986\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.75194 (r=0.980,p=0.610),  time:33.806, tt:473.280\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.75591 (r=0.970,p=0.619),  time:33.892, tt:508.384\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:34.005, tt:544.076\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:34.094, tt:579.601\n",
      "Ep:17, loss:0.00003, loss_test:0.01508, lr:6.00e-02, fs:0.77912 (r=0.980,p=0.647),  time:34.001, tt:612.013\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01485, lr:6.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:33.997, tt:645.952\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01456, lr:6.00e-02, fs:0.78088 (r=0.990,p=0.645),  time:34.095, tt:681.897\n",
      "Ep:20, loss:0.00003, loss_test:0.01429, lr:6.00e-02, fs:0.78400 (r=0.990,p=0.649),  time:34.083, tt:715.744\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01403, lr:6.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:34.090, tt:749.989\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01381, lr:6.00e-02, fs:0.80000 (r=0.990,p=0.671),  time:34.069, tt:783.595\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01366, lr:6.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:34.086, tt:818.056\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01351, lr:6.00e-02, fs:0.80992 (r=0.990,p=0.685),  time:34.100, tt:852.511\n",
      "Ep:25, loss:0.00003, loss_test:0.01335, lr:6.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:34.054, tt:885.416\n",
      "Ep:26, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.082, tt:920.219\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01299, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.111, tt:955.117\n",
      "Ep:28, loss:0.00002, loss_test:0.01281, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.070, tt:988.031\n",
      "Ep:29, loss:0.00002, loss_test:0.01264, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:34.046, tt:1021.370\n",
      "Ep:30, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:34.054, tt:1055.676\n",
      "Ep:31, loss:0.00002, loss_test:0.01225, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:34.092, tt:1090.959\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:34.131, tt:1126.335\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01188, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.165, tt:1161.614\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01177, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:34.184, tt:1196.425\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01164, lr:6.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:34.185, tt:1230.657\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01146, lr:6.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:34.181, tt:1264.681\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:34.202, tt:1299.665\n",
      "Ep:38, loss:0.00002, loss_test:0.01123, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:34.181, tt:1333.048\n",
      "Ep:39, loss:0.00002, loss_test:0.01116, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:34.159, tt:1366.348\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01112, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:34.139, tt:1399.681\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01100, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:34.099, tt:1432.141\n",
      "Ep:42, loss:0.00002, loss_test:0.01094, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:34.087, tt:1465.724\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:34.088, tt:1499.871\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01072, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:34.092, tt:1534.148\n",
      "Ep:45, loss:0.00001, loss_test:0.01064, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:34.099, tt:1568.571\n",
      "Ep:46, loss:0.00001, loss_test:0.01060, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:34.070, tt:1601.274\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:34.095, tt:1636.537\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01057, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:34.083, tt:1670.045\n",
      "Ep:49, loss:0.00001, loss_test:0.01051, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.065, tt:1703.228\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01041, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.071, tt:1737.599\n",
      "Ep:51, loss:0.00001, loss_test:0.01036, lr:6.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:34.061, tt:1771.178\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01046, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.068, tt:1805.616\n",
      "Ep:53, loss:0.00001, loss_test:0.01052, lr:6.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:34.063, tt:1839.419\n",
      "Ep:54, loss:0.00001, loss_test:0.01038, lr:6.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:34.040, tt:1872.221\n",
      "Ep:55, loss:0.00001, loss_test:0.01045, lr:6.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:34.005, tt:1904.304\n",
      "Ep:56, loss:0.00001, loss_test:0.01035, lr:6.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:34.011, tt:1938.603\n",
      "Ep:57, loss:0.00001, loss_test:0.01047, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.016, tt:1972.953\n",
      "Ep:58, loss:0.00001, loss_test:0.01039, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.010, tt:2006.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01035, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.010, tt:2040.615\n",
      "Ep:60, loss:0.00001, loss_test:0.01045, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.008, tt:2074.470\n",
      "Ep:61, loss:0.00001, loss_test:0.01039, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.010, tt:2108.605\n",
      "Ep:62, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.000, tt:2142.021\n",
      "Ep:63, loss:0.00001, loss_test:0.01048, lr:5.94e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.005, tt:2176.304\n",
      "Ep:64, loss:0.00001, loss_test:0.01051, lr:5.88e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.035, tt:2212.251\n",
      "Ep:65, loss:0.00001, loss_test:0.01050, lr:5.82e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.025, tt:2245.630\n",
      "Ep:66, loss:0.00001, loss_test:0.01057, lr:5.76e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.055, tt:2281.701\n",
      "Ep:67, loss:0.00001, loss_test:0.01066, lr:5.71e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.058, tt:2315.971\n",
      "Ep:68, loss:0.00001, loss_test:0.01059, lr:5.65e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.071, tt:2350.878\n",
      "Ep:69, loss:0.00001, loss_test:0.01075, lr:5.59e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.071, tt:2384.937\n",
      "Ep:70, loss:0.00001, loss_test:0.01074, lr:5.54e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.078, tt:2419.532\n",
      "Ep:71, loss:0.00001, loss_test:0.01081, lr:5.48e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.098, tt:2455.047\n",
      "Ep:72, loss:0.00001, loss_test:0.01083, lr:5.43e-02, fs:0.86000 (r=0.869,p=0.851),  time:34.097, tt:2489.054\n",
      "Ep:73, loss:0.00001, loss_test:0.01091, lr:5.37e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.108, tt:2524.008\n",
      "Ep:74, loss:0.00001, loss_test:0.01087, lr:5.32e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.139, tt:2560.431\n",
      "Ep:75, loss:0.00001, loss_test:0.01102, lr:5.27e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.167, tt:2596.694\n",
      "Ep:76, loss:0.00001, loss_test:0.01099, lr:5.21e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.171, tt:2631.189\n",
      "Ep:77, loss:0.00001, loss_test:0.01112, lr:5.16e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.189, tt:2666.720\n",
      "Ep:78, loss:0.00001, loss_test:0.01096, lr:5.11e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.216, tt:2703.027\n",
      "Ep:79, loss:0.00001, loss_test:0.01116, lr:5.06e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.224, tt:2737.914\n",
      "Ep:80, loss:0.00001, loss_test:0.01126, lr:5.01e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.249, tt:2774.149\n",
      "Ep:81, loss:0.00001, loss_test:0.01125, lr:4.96e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.264, tt:2809.676\n",
      "Ep:82, loss:0.00001, loss_test:0.01131, lr:4.91e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.285, tt:2845.639\n",
      "Ep:83, loss:0.00001, loss_test:0.01136, lr:4.86e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.299, tt:2881.127\n",
      "Ep:84, loss:0.00001, loss_test:0.01144, lr:4.81e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.319, tt:2917.086\n",
      "Ep:85, loss:0.00001, loss_test:0.01152, lr:4.76e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.324, tt:2951.833\n",
      "Ep:86, loss:0.00001, loss_test:0.01155, lr:4.71e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.316, tt:2985.508\n",
      "Ep:87, loss:0.00001, loss_test:0.01163, lr:4.67e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.337, tt:3021.663\n",
      "Ep:88, loss:0.00001, loss_test:0.01162, lr:4.62e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.342, tt:3056.425\n",
      "Ep:89, loss:0.00001, loss_test:0.01177, lr:4.57e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.317, tt:3088.508\n",
      "Ep:90, loss:0.00001, loss_test:0.01178, lr:4.53e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.333, tt:3124.283\n",
      "Ep:91, loss:0.00001, loss_test:0.01191, lr:4.48e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.353, tt:3160.509\n",
      "Ep:92, loss:0.00001, loss_test:0.01190, lr:4.44e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.349, tt:3194.440\n",
      "Ep:93, loss:0.00001, loss_test:0.01203, lr:4.39e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.372, tt:3230.995\n",
      "Ep:94, loss:0.00000, loss_test:0.01206, lr:4.35e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.375, tt:3265.583\n",
      "Ep:95, loss:0.00000, loss_test:0.01219, lr:4.31e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.386, tt:3301.054\n",
      "Ep:96, loss:0.00000, loss_test:0.01227, lr:4.26e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.387, tt:3335.565\n",
      "Ep:97, loss:0.00000, loss_test:0.01214, lr:4.22e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.394, tt:3370.644\n",
      "Ep:98, loss:0.00000, loss_test:0.01243, lr:4.18e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.416, tt:3407.207\n",
      "Ep:99, loss:0.00000, loss_test:0.01236, lr:4.14e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.426, tt:3442.634\n",
      "Ep:100, loss:0.00000, loss_test:0.01247, lr:4.10e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.434, tt:3477.801\n",
      "Ep:101, loss:0.00000, loss_test:0.01257, lr:4.05e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.425, tt:3511.389\n",
      "Ep:102, loss:0.00000, loss_test:0.01254, lr:4.01e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.430, tt:3546.340\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00000, loss_test:0.01265, lr:4.01e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.438, tt:3581.541\n",
      "Ep:104, loss:0.00000, loss_test:0.01270, lr:4.01e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.453, tt:3617.533\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.01280, lr:4.01e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.444, tt:3651.100\n",
      "Ep:106, loss:0.00000, loss_test:0.01284, lr:4.01e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.430, tt:3683.960\n",
      "Ep:107, loss:0.00000, loss_test:0.01299, lr:4.01e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.428, tt:3718.259\n",
      "Ep:108, loss:0.00000, loss_test:0.01305, lr:4.01e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.425, tt:3752.331\n",
      "Ep:109, loss:0.00000, loss_test:0.01298, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.425, tt:3786.777\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.01313, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.436, tt:3822.378\n",
      "Ep:111, loss:0.00000, loss_test:0.01317, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.438, tt:3857.026\n",
      "Ep:112, loss:0.00000, loss_test:0.01323, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.443, tt:3892.016\n",
      "Ep:113, loss:0.00000, loss_test:0.01337, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.450, tt:3927.290\n",
      "Ep:114, loss:0.00000, loss_test:0.01334, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.443, tt:3960.997\n",
      "Ep:115, loss:0.00000, loss_test:0.01332, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.440, tt:3995.001\n",
      "Ep:116, loss:0.00000, loss_test:0.01361, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.444, tt:4029.944\n",
      "Ep:117, loss:0.00000, loss_test:0.01345, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.457, tt:4065.959\n",
      "Ep:118, loss:0.00000, loss_test:0.01369, lr:4.01e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.453, tt:4099.943\n",
      "Ep:119, loss:0.00000, loss_test:0.01367, lr:4.01e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.461, tt:4135.278\n",
      "Ep:120, loss:0.00000, loss_test:0.01382, lr:4.01e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.460, tt:4169.641\n",
      "Ep:121, loss:0.00000, loss_test:0.01373, lr:3.97e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.452, tt:4203.176\n",
      "Ep:122, loss:0.00000, loss_test:0.01394, lr:3.93e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.447, tt:4236.967\n",
      "Ep:123, loss:0.00000, loss_test:0.01393, lr:3.89e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.444, tt:4271.034\n",
      "Ep:124, loss:0.00000, loss_test:0.01399, lr:3.86e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.449, tt:4306.086\n",
      "Ep:125, loss:0.00000, loss_test:0.01411, lr:3.82e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.436, tt:4338.926\n",
      "Ep:126, loss:0.00000, loss_test:0.01409, lr:3.78e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.440, tt:4373.861\n",
      "Ep:127, loss:0.00000, loss_test:0.01416, lr:3.74e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.442, tt:4408.605\n",
      "Ep:128, loss:0.00000, loss_test:0.01415, lr:3.70e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.476, tt:4447.448\n",
      "Ep:129, loss:0.00000, loss_test:0.01430, lr:3.67e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.459, tt:4479.654\n",
      "Ep:130, loss:0.00000, loss_test:0.01437, lr:3.63e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.456, tt:4513.678\n",
      "Ep:131, loss:0.00000, loss_test:0.01446, lr:3.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.456, tt:4548.201\n",
      "Ep:132, loss:0.00000, loss_test:0.01447, lr:3.56e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.462, tt:4583.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01446, lr:3.52e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.461, tt:4617.736\n",
      "Ep:134, loss:0.00000, loss_test:0.01459, lr:3.49e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.452, tt:4651.011\n",
      "Ep:135, loss:0.00000, loss_test:0.01462, lr:3.45e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.456, tt:4685.990\n",
      "Ep:136, loss:0.00000, loss_test:0.01470, lr:3.42e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.463, tt:4721.420\n",
      "Ep:137, loss:0.00000, loss_test:0.01475, lr:3.38e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.463, tt:4755.872\n",
      "Ep:138, loss:0.00000, loss_test:0.01479, lr:3.35e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.455, tt:4789.299\n",
      "Ep:139, loss:0.00000, loss_test:0.01485, lr:3.32e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.451, tt:4823.185\n",
      "Ep:140, loss:0.00000, loss_test:0.01492, lr:3.28e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.457, tt:4858.432\n",
      "Ep:141, loss:0.00000, loss_test:0.01492, lr:3.25e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.455, tt:4892.623\n",
      "Ep:142, loss:0.00000, loss_test:0.01489, lr:3.22e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.448, tt:4926.086\n",
      "Ep:143, loss:0.00000, loss_test:0.01499, lr:3.19e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.450, tt:4960.764\n",
      "Ep:144, loss:0.00000, loss_test:0.01506, lr:3.15e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.454, tt:4995.810\n",
      "Ep:145, loss:0.00000, loss_test:0.01508, lr:3.12e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.449, tt:5029.591\n",
      "Ep:146, loss:0.00000, loss_test:0.01518, lr:3.09e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.452, tt:5064.395\n",
      "Ep:147, loss:0.00000, loss_test:0.01517, lr:3.06e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.459, tt:5099.994\n",
      "Ep:148, loss:0.00000, loss_test:0.01525, lr:3.03e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.468, tt:5135.805\n",
      "Ep:149, loss:0.00000, loss_test:0.01529, lr:3.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.473, tt:5170.988\n",
      "Ep:150, loss:0.00000, loss_test:0.01532, lr:2.97e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.481, tt:5206.598\n",
      "Ep:151, loss:0.00000, loss_test:0.01534, lr:2.94e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.484, tt:5241.537\n",
      "Ep:152, loss:0.00000, loss_test:0.01539, lr:2.91e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.493, tt:5277.438\n",
      "Ep:153, loss:0.00000, loss_test:0.01552, lr:2.88e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.497, tt:5312.558\n",
      "Ep:154, loss:0.00000, loss_test:0.01550, lr:2.85e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.511, tt:5349.217\n",
      "Ep:155, loss:0.00000, loss_test:0.01557, lr:2.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.525, tt:5385.846\n",
      "Ep:156, loss:0.00000, loss_test:0.01552, lr:2.80e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.529, tt:5421.114\n",
      "Ep:157, loss:0.00000, loss_test:0.01554, lr:2.77e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.553, tt:5459.304\n",
      "Ep:158, loss:0.00000, loss_test:0.01564, lr:2.74e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.559, tt:5494.871\n",
      "Ep:159, loss:0.00000, loss_test:0.01564, lr:2.71e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.572, tt:5531.530\n",
      "Ep:160, loss:0.00000, loss_test:0.01575, lr:2.69e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.573, tt:5566.299\n",
      "Ep:161, loss:0.00000, loss_test:0.01572, lr:2.66e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.578, tt:5601.562\n",
      "Ep:162, loss:0.00000, loss_test:0.01580, lr:2.63e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.579, tt:5636.457\n",
      "Ep:163, loss:0.00000, loss_test:0.01581, lr:2.61e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.594, tt:5673.483\n",
      "Ep:164, loss:0.00000, loss_test:0.01580, lr:2.58e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.594, tt:5707.970\n",
      "Ep:165, loss:0.00000, loss_test:0.01592, lr:2.55e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.591, tt:5742.030\n",
      "Ep:166, loss:0.00000, loss_test:0.01591, lr:2.53e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.595, tt:5777.389\n",
      "Ep:167, loss:0.00000, loss_test:0.01592, lr:2.50e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.601, tt:5812.982\n",
      "Ep:168, loss:0.00000, loss_test:0.01595, lr:2.48e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.611, tt:5849.201\n",
      "Ep:169, loss:0.00000, loss_test:0.01595, lr:2.45e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.609, tt:5883.595\n",
      "Ep:170, loss:0.00000, loss_test:0.01602, lr:2.43e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.611, tt:5918.545\n",
      "Ep:171, loss:0.00000, loss_test:0.01604, lr:2.40e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.620, tt:5954.707\n",
      "Ep:172, loss:0.00000, loss_test:0.01607, lr:2.38e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.618, tt:5988.942\n",
      "Ep:173, loss:0.00000, loss_test:0.01615, lr:2.36e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.617, tt:6023.369\n",
      "Ep:174, loss:0.00000, loss_test:0.01612, lr:2.33e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.619, tt:6058.277\n",
      "Ep:175, loss:0.00000, loss_test:0.01616, lr:2.31e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.619, tt:6092.964\n",
      "Ep:176, loss:0.00000, loss_test:0.01622, lr:2.29e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.623, tt:6128.286\n",
      "Ep:177, loss:0.00000, loss_test:0.01618, lr:2.26e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.629, tt:6164.035\n",
      "Ep:178, loss:0.00000, loss_test:0.01624, lr:2.24e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.628, tt:6198.414\n",
      "Ep:179, loss:0.00000, loss_test:0.01626, lr:2.22e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.627, tt:6232.938\n",
      "Ep:180, loss:0.00000, loss_test:0.01630, lr:2.20e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.626, tt:6267.331\n",
      "Ep:181, loss:0.00000, loss_test:0.01631, lr:2.17e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.660, tt:6308.030\n",
      "Ep:182, loss:0.00000, loss_test:0.01638, lr:2.15e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.667, tt:6343.992\n",
      "Ep:183, loss:0.00000, loss_test:0.01638, lr:2.13e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.673, tt:6379.755\n",
      "Ep:184, loss:0.00000, loss_test:0.01639, lr:2.11e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.667, tt:6413.355\n",
      "Ep:185, loss:0.00000, loss_test:0.01643, lr:2.09e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.662, tt:6447.066\n",
      "Ep:186, loss:0.00000, loss_test:0.01643, lr:2.07e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.662, tt:6481.731\n",
      "Ep:187, loss:0.00000, loss_test:0.01647, lr:2.05e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.663, tt:6516.623\n",
      "Ep:188, loss:0.00000, loss_test:0.01651, lr:2.03e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.663, tt:6551.221\n",
      "Ep:189, loss:0.00000, loss_test:0.01653, lr:2.01e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.665, tt:6586.301\n",
      "Ep:190, loss:0.00000, loss_test:0.01653, lr:1.99e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.668, tt:6621.516\n",
      "Ep:191, loss:0.00000, loss_test:0.01656, lr:1.97e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.679, tt:6658.411\n",
      "Ep:192, loss:0.00000, loss_test:0.01658, lr:1.95e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.670, tt:6691.361\n",
      "Ep:193, loss:0.00000, loss_test:0.01663, lr:1.93e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.668, tt:6725.556\n",
      "Ep:194, loss:0.00000, loss_test:0.01665, lr:1.91e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.667, tt:6760.039\n",
      "Ep:195, loss:0.00000, loss_test:0.01664, lr:1.89e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.669, tt:6795.034\n",
      "Ep:196, loss:0.00000, loss_test:0.01668, lr:1.87e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.673, tt:6830.602\n",
      "Ep:197, loss:0.00000, loss_test:0.01667, lr:1.85e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.670, tt:6864.638\n",
      "Ep:198, loss:0.00000, loss_test:0.01670, lr:1.83e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.666, tt:6898.542\n",
      "Ep:199, loss:0.00000, loss_test:0.01675, lr:1.81e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.663, tt:6932.537\n",
      "Ep:200, loss:0.00000, loss_test:0.01675, lr:1.80e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.656, tt:6965.860\n",
      "Ep:201, loss:0.00000, loss_test:0.01674, lr:1.78e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.646, tt:6998.587\n",
      "Ep:202, loss:0.00000, loss_test:0.01682, lr:1.76e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.637, tt:7031.236\n",
      "Ep:203, loss:0.00000, loss_test:0.01679, lr:1.74e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.609, tt:7060.311\n",
      "Ep:204, loss:0.00000, loss_test:0.01678, lr:1.73e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.610, tt:7094.955\n",
      "Ep:205, loss:0.00000, loss_test:0.01687, lr:1.71e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.601, tt:7127.788\n",
      "Ep:206, loss:0.00000, loss_test:0.01685, lr:1.69e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.594, tt:7160.899\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14238, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:33.163, tt:33.163\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14076, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:33.867, tt:67.733\n",
      "Ep:2, loss:0.00027, loss_test:0.13775, lr:1.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:33.333, tt:99.998\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13404, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:33.075, tt:132.300\n",
      "Ep:4, loss:0.00026, loss_test:0.13050, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:33.745, tt:168.723\n",
      "Ep:5, loss:0.00025, loss_test:0.12658, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:34.184, tt:205.106\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12272, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.486, tt:241.403\n",
      "Ep:7, loss:0.00024, loss_test:0.12004, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:34.656, tt:277.250\n",
      "Ep:8, loss:0.00024, loss_test:0.11769, lr:1.00e-02, fs:0.68595 (r=0.838,p=0.580),  time:34.797, tt:313.174\n",
      "Ep:9, loss:0.00023, loss_test:0.11568, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:35.028, tt:350.281\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.11433, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:35.225, tt:387.477\n",
      "Ep:11, loss:0.00022, loss_test:0.11201, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:35.398, tt:424.773\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.10955, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:35.453, tt:460.894\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.10682, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:35.537, tt:497.520\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10445, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:35.677, tt:535.153\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10177, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:35.720, tt:571.513\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10091, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:35.879, tt:609.940\n",
      "Ep:17, loss:0.00019, loss_test:0.09812, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:35.876, tt:645.763\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09709, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:35.897, tt:682.036\n",
      "Ep:19, loss:0.00018, loss_test:0.09515, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:35.985, tt:719.695\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09336, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:36.018, tt:756.386\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.09212, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:36.125, tt:794.744\n",
      "Ep:22, loss:0.00016, loss_test:0.09090, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:36.167, tt:831.847\n",
      "Ep:23, loss:0.00016, loss_test:0.08943, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:36.205, tt:868.918\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08916, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:36.196, tt:904.907\n",
      "Ep:25, loss:0.00015, loss_test:0.08790, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:36.191, tt:940.974\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08804, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:36.174, tt:976.710\n",
      "Ep:27, loss:0.00014, loss_test:0.08654, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:36.201, tt:1013.615\n",
      "Ep:28, loss:0.00014, loss_test:0.08527, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:36.246, tt:1051.143\n",
      "Ep:29, loss:0.00013, loss_test:0.08636, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:36.271, tt:1088.127\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08422, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:36.311, tt:1125.651\n",
      "Ep:31, loss:0.00012, loss_test:0.08534, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:36.352, tt:1163.266\n",
      "Ep:32, loss:0.00012, loss_test:0.08394, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:36.364, tt:1200.003\n",
      "Ep:33, loss:0.00011, loss_test:0.08607, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:36.358, tt:1236.182\n",
      "Ep:34, loss:0.00011, loss_test:0.08140, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:36.323, tt:1271.293\n",
      "Ep:35, loss:0.00011, loss_test:0.08479, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:36.330, tt:1307.876\n",
      "Ep:36, loss:0.00010, loss_test:0.08138, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:36.339, tt:1344.551\n",
      "Ep:37, loss:0.00010, loss_test:0.08372, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:36.352, tt:1381.371\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08233, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:36.420, tt:1420.377\n",
      "Ep:39, loss:0.00009, loss_test:0.08072, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:36.409, tt:1456.346\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.08292, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:36.404, tt:1492.554\n",
      "Ep:41, loss:0.00008, loss_test:0.07803, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.414, tt:1529.381\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.08262, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:36.379, tt:1564.296\n",
      "Ep:43, loss:0.00008, loss_test:0.08392, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:36.358, tt:1599.751\n",
      "Ep:44, loss:0.00008, loss_test:0.07613, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:36.386, tt:1637.376\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07878, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:36.407, tt:1674.731\n",
      "Ep:46, loss:0.00007, loss_test:0.08914, lr:1.00e-02, fs:0.72727 (r=0.646,p=0.831),  time:36.425, tt:1711.998\n",
      "Ep:47, loss:0.00007, loss_test:0.07095, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.404, tt:1747.391\n",
      "Ep:48, loss:0.00007, loss_test:0.09102, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:36.342, tt:1780.734\n",
      "Ep:49, loss:0.00007, loss_test:0.08217, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:36.332, tt:1816.590\n",
      "Ep:50, loss:0.00006, loss_test:0.07563, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:36.320, tt:1852.325\n",
      "Ep:51, loss:0.00006, loss_test:0.08206, lr:1.00e-02, fs:0.71910 (r=0.646,p=0.810),  time:36.321, tt:1888.670\n",
      "Ep:52, loss:0.00006, loss_test:0.07618, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:36.310, tt:1924.457\n",
      "Ep:53, loss:0.00006, loss_test:0.07596, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:36.317, tt:1961.116\n",
      "Ep:54, loss:0.00006, loss_test:0.08657, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:36.302, tt:1996.590\n",
      "Ep:55, loss:0.00006, loss_test:0.07341, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:36.290, tt:2032.249\n",
      "Ep:56, loss:0.00005, loss_test:0.08703, lr:9.90e-03, fs:0.72832 (r=0.636,p=0.851),  time:36.309, tt:2069.603\n",
      "Ep:57, loss:0.00005, loss_test:0.07433, lr:9.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:36.291, tt:2104.873\n",
      "Ep:58, loss:0.00005, loss_test:0.08272, lr:9.70e-03, fs:0.77273 (r=0.687,p=0.883),  time:36.254, tt:2138.962\n",
      "Ep:59, loss:0.00005, loss_test:0.07348, lr:9.61e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.240, tt:2174.428\n",
      "Ep:60, loss:0.00005, loss_test:0.08174, lr:9.51e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.236, tt:2210.396\n",
      "Ep:61, loss:0.00004, loss_test:0.07265, lr:9.41e-03, fs:0.80874 (r=0.747,p=0.881),  time:36.227, tt:2246.063\n",
      "Ep:62, loss:0.00004, loss_test:0.09068, lr:9.32e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.225, tt:2282.205\n",
      "Ep:63, loss:0.00004, loss_test:0.07250, lr:9.23e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.238, tt:2319.219\n",
      "Ep:64, loss:0.00004, loss_test:0.08645, lr:9.14e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.246, tt:2355.958\n",
      "Ep:65, loss:0.00004, loss_test:0.07555, lr:9.04e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.237, tt:2391.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00004, loss_test:0.07655, lr:8.95e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.227, tt:2427.178\n",
      "Ep:67, loss:0.00004, loss_test:0.08022, lr:8.86e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.203, tt:2461.800\n",
      "Ep:68, loss:0.00004, loss_test:0.07834, lr:8.78e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.232, tt:2500.024\n",
      "Ep:69, loss:0.00004, loss_test:0.07870, lr:8.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.236, tt:2536.543\n",
      "Ep:70, loss:0.00004, loss_test:0.07737, lr:8.60e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.220, tt:2571.608\n",
      "Ep:71, loss:0.00003, loss_test:0.07369, lr:8.51e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.205, tt:2606.778\n",
      "Ep:72, loss:0.00003, loss_test:0.07909, lr:8.43e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.200, tt:2642.629\n",
      "Ep:73, loss:0.00003, loss_test:0.07254, lr:8.35e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.206, tt:2679.270\n",
      "Ep:74, loss:0.00003, loss_test:0.08381, lr:8.26e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.185, tt:2713.877\n",
      "Ep:75, loss:0.00003, loss_test:0.07133, lr:8.18e-03, fs:0.81111 (r=0.737,p=0.901),  time:36.189, tt:2750.340\n",
      "Ep:76, loss:0.00003, loss_test:0.07949, lr:8.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.176, tt:2785.571\n",
      "Ep:77, loss:0.00003, loss_test:0.08053, lr:8.02e-03, fs:0.73684 (r=0.636,p=0.875),  time:36.160, tt:2820.494\n",
      "Ep:78, loss:0.00003, loss_test:0.07004, lr:7.94e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.173, tt:2857.685\n",
      "Ep:79, loss:0.00003, loss_test:0.08656, lr:7.86e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.164, tt:2893.104\n",
      "Ep:80, loss:0.00003, loss_test:0.06889, lr:7.78e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.180, tt:2930.587\n",
      "Ep:81, loss:0.00003, loss_test:0.08708, lr:7.70e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.157, tt:2964.906\n",
      "Ep:82, loss:0.00003, loss_test:0.07269, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.169, tt:3002.025\n",
      "Ep:83, loss:0.00003, loss_test:0.07959, lr:7.55e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.176, tt:3038.777\n",
      "Ep:84, loss:0.00003, loss_test:0.07522, lr:7.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.147, tt:3072.471\n",
      "Ep:85, loss:0.00003, loss_test:0.07767, lr:7.40e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.102, tt:3104.747\n",
      "Ep:86, loss:0.00002, loss_test:0.08146, lr:7.32e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.058, tt:3137.045\n",
      "Ep:87, loss:0.00002, loss_test:0.07326, lr:7.25e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.056, tt:3172.919\n",
      "Ep:88, loss:0.00002, loss_test:0.07777, lr:7.18e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.042, tt:3207.776\n",
      "Ep:89, loss:0.00002, loss_test:0.07671, lr:7.11e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.027, tt:3242.399\n",
      "Ep:90, loss:0.00002, loss_test:0.07279, lr:7.03e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.998, tt:3275.781\n",
      "Ep:91, loss:0.00002, loss_test:0.08285, lr:6.96e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.008, tt:3312.760\n",
      "Ep:92, loss:0.00002, loss_test:0.07652, lr:6.89e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.012, tt:3349.112\n",
      "Ep:93, loss:0.00002, loss_test:0.07541, lr:6.83e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.009, tt:3384.883\n",
      "Ep:94, loss:0.00002, loss_test:0.08448, lr:6.76e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.008, tt:3420.798\n",
      "Ep:95, loss:0.00002, loss_test:0.06931, lr:6.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.993, tt:3455.337\n",
      "Ep:96, loss:0.00002, loss_test:0.08851, lr:6.62e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.982, tt:3490.268\n",
      "Ep:97, loss:0.00002, loss_test:0.07158, lr:6.56e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.988, tt:3526.856\n",
      "Ep:98, loss:0.00002, loss_test:0.08520, lr:6.49e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.988, tt:3562.767\n",
      "Ep:99, loss:0.00002, loss_test:0.08037, lr:6.43e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.983, tt:3598.325\n",
      "Ep:100, loss:0.00002, loss_test:0.07665, lr:6.36e-03, fs:0.77011 (r=0.677,p=0.893),  time:35.980, tt:3633.973\n",
      "Ep:101, loss:0.00002, loss_test:0.07912, lr:6.30e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.973, tt:3669.264\n",
      "Ep:102, loss:0.00002, loss_test:0.07791, lr:6.24e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.963, tt:3704.223\n",
      "Ep:103, loss:0.00002, loss_test:0.07917, lr:6.17e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.955, tt:3739.359\n",
      "Ep:104, loss:0.00002, loss_test:0.08046, lr:6.11e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.968, tt:3776.658\n",
      "Ep:105, loss:0.00002, loss_test:0.07751, lr:6.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.979, tt:3813.734\n",
      "Ep:106, loss:0.00002, loss_test:0.07888, lr:5.99e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.976, tt:3849.412\n",
      "Ep:107, loss:0.00002, loss_test:0.07782, lr:5.93e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.982, tt:3886.020\n",
      "Ep:108, loss:0.00002, loss_test:0.07762, lr:5.87e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.993, tt:3923.239\n",
      "Ep:109, loss:0.00002, loss_test:0.08088, lr:5.81e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.004, tt:3960.415\n",
      "Ep:110, loss:0.00002, loss_test:0.07772, lr:5.75e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.003, tt:3996.353\n",
      "Ep:111, loss:0.00002, loss_test:0.07993, lr:5.70e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.006, tt:4032.624\n",
      "Ep:112, loss:0.00002, loss_test:0.08047, lr:5.64e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.007, tt:4068.758\n",
      "Ep:113, loss:0.00002, loss_test:0.07851, lr:5.58e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.999, tt:4103.922\n",
      "Ep:114, loss:0.00002, loss_test:0.08044, lr:5.53e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.004, tt:4140.429\n",
      "Ep:115, loss:0.00002, loss_test:0.07933, lr:5.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.984, tt:4174.169\n",
      "Ep:116, loss:0.00002, loss_test:0.08032, lr:5.42e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.986, tt:4210.345\n",
      "Ep:117, loss:0.00002, loss_test:0.07917, lr:5.36e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.979, tt:4245.509\n",
      "Ep:118, loss:0.00002, loss_test:0.07965, lr:5.31e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.982, tt:4281.835\n",
      "Ep:119, loss:0.00002, loss_test:0.07921, lr:5.26e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.983, tt:4317.947\n",
      "Ep:120, loss:0.00002, loss_test:0.08007, lr:5.20e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.995, tt:4355.374\n",
      "Ep:121, loss:0.00002, loss_test:0.08247, lr:5.15e-03, fs:0.74118 (r=0.636,p=0.887),  time:35.992, tt:4391.022\n",
      "Ep:122, loss:0.00002, loss_test:0.07759, lr:5.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.990, tt:4426.805\n",
      "Ep:123, loss:0.00002, loss_test:0.08181, lr:5.05e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.985, tt:4462.144\n",
      "Ep:124, loss:0.00002, loss_test:0.07917, lr:5.00e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.978, tt:4497.255\n",
      "Ep:125, loss:0.00002, loss_test:0.08133, lr:4.95e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.983, tt:4533.798\n",
      "Ep:126, loss:0.00002, loss_test:0.07850, lr:4.90e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.978, tt:4569.148\n",
      "Ep:127, loss:0.00002, loss_test:0.08196, lr:4.85e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.970, tt:4604.212\n",
      "Ep:128, loss:0.00002, loss_test:0.07760, lr:4.80e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.978, tt:4641.115\n",
      "Ep:129, loss:0.00002, loss_test:0.08407, lr:4.75e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.979, tt:4677.282\n",
      "Ep:130, loss:0.00001, loss_test:0.07801, lr:4.71e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.976, tt:4712.904\n",
      "Ep:131, loss:0.00001, loss_test:0.08252, lr:4.66e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.979, tt:4749.187\n",
      "Ep:132, loss:0.00001, loss_test:0.07970, lr:4.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.970, tt:4783.982\n",
      "Ep:133, loss:0.00001, loss_test:0.08111, lr:4.57e-03, fs:0.74854 (r=0.646,p=0.889),  time:35.970, tt:4820.042\n",
      "Ep:134, loss:0.00001, loss_test:0.08102, lr:4.52e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.963, tt:4855.068\n",
      "Ep:135, loss:0.00001, loss_test:0.08026, lr:4.48e-03, fs:0.74118 (r=0.636,p=0.887),  time:35.963, tt:4890.968\n",
      "Ep:136, loss:0.00001, loss_test:0.08107, lr:4.43e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.978, tt:4928.963\n",
      "Ep:137, loss:0.00001, loss_test:0.08116, lr:4.39e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.975, tt:4964.614\n",
      "Ep:138, loss:0.00001, loss_test:0.08122, lr:4.34e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.973, tt:5000.284\n",
      "Ep:139, loss:0.00001, loss_test:0.08152, lr:4.30e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.975, tt:5036.451\n",
      "Ep:140, loss:0.00001, loss_test:0.08128, lr:4.26e-03, fs:0.76301 (r=0.667,p=0.892),  time:35.981, tt:5073.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.08041, lr:4.21e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.986, tt:5110.003\n",
      "Ep:142, loss:0.00001, loss_test:0.08145, lr:4.17e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.982, tt:5145.445\n",
      "Ep:143, loss:0.00001, loss_test:0.08050, lr:4.13e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.970, tt:5179.684\n",
      "Ep:144, loss:0.00001, loss_test:0.08079, lr:4.09e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.977, tt:5216.623\n",
      "Ep:145, loss:0.00001, loss_test:0.08153, lr:4.05e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.971, tt:5251.713\n",
      "Ep:146, loss:0.00001, loss_test:0.08080, lr:4.01e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.968, tt:5287.252\n",
      "Ep:147, loss:0.00001, loss_test:0.08135, lr:3.97e-03, fs:0.77011 (r=0.677,p=0.893),  time:35.978, tt:5324.696\n",
      "Ep:148, loss:0.00001, loss_test:0.08030, lr:3.93e-03, fs:0.78409 (r=0.697,p=0.896),  time:35.980, tt:5361.012\n",
      "Ep:149, loss:0.00001, loss_test:0.08197, lr:3.89e-03, fs:0.78409 (r=0.697,p=0.896),  time:35.985, tt:5397.787\n",
      "Ep:150, loss:0.00001, loss_test:0.08216, lr:3.85e-03, fs:0.73373 (r=0.626,p=0.886),  time:35.997, tt:5435.497\n",
      "Ep:151, loss:0.00001, loss_test:0.08069, lr:3.81e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.009, tt:5473.332\n",
      "Ep:152, loss:0.00001, loss_test:0.08384, lr:3.77e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.015, tt:5510.342\n",
      "Ep:153, loss:0.00001, loss_test:0.08203, lr:3.73e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.031, tt:5548.721\n",
      "Ep:154, loss:0.00001, loss_test:0.08042, lr:3.70e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.043, tt:5586.624\n",
      "Ep:155, loss:0.00001, loss_test:0.08258, lr:3.66e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.044, tt:5622.862\n",
      "Ep:156, loss:0.00001, loss_test:0.07996, lr:3.62e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.056, tt:5660.722\n",
      "Ep:157, loss:0.00001, loss_test:0.08201, lr:3.59e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.059, tt:5697.321\n",
      "Ep:158, loss:0.00001, loss_test:0.08055, lr:3.55e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.070, tt:5735.121\n",
      "Ep:159, loss:0.00001, loss_test:0.08290, lr:3.52e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.076, tt:5772.139\n",
      "Ep:160, loss:0.00001, loss_test:0.08063, lr:3.48e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.088, tt:5810.158\n",
      "Ep:161, loss:0.00001, loss_test:0.08163, lr:3.45e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.095, tt:5847.422\n",
      "Ep:162, loss:0.00001, loss_test:0.08373, lr:3.41e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.103, tt:5884.718\n",
      "Ep:163, loss:0.00001, loss_test:0.07980, lr:3.38e-03, fs:0.79775 (r=0.717,p=0.899),  time:36.121, tt:5923.856\n",
      "Ep:164, loss:0.00001, loss_test:0.08311, lr:3.34e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.142, tt:5963.356\n",
      "Ep:165, loss:0.00001, loss_test:0.08134, lr:3.31e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.152, tt:6001.250\n",
      "Ep:166, loss:0.00001, loss_test:0.08083, lr:3.28e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.150, tt:6037.102\n",
      "Ep:167, loss:0.00001, loss_test:0.08272, lr:3.24e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.153, tt:6073.737\n",
      "Ep:168, loss:0.00001, loss_test:0.08058, lr:3.21e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.160, tt:6111.113\n",
      "Ep:169, loss:0.00001, loss_test:0.08277, lr:3.18e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.167, tt:6148.419\n",
      "Ep:170, loss:0.00001, loss_test:0.08356, lr:3.15e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.165, tt:6184.285\n",
      "Ep:171, loss:0.00001, loss_test:0.08088, lr:3.12e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.170, tt:6221.165\n",
      "Ep:172, loss:0.00001, loss_test:0.08222, lr:3.09e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.171, tt:6257.583\n",
      "Ep:173, loss:0.00001, loss_test:0.08239, lr:3.05e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.176, tt:6294.654\n",
      "Ep:174, loss:0.00001, loss_test:0.08014, lr:3.02e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.181, tt:6331.674\n",
      "Ep:175, loss:0.00001, loss_test:0.08227, lr:2.99e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.183, tt:6368.213\n",
      "Ep:176, loss:0.00001, loss_test:0.08262, lr:2.96e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.180, tt:6403.795\n",
      "Ep:177, loss:0.00001, loss_test:0.08073, lr:2.93e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.183, tt:6440.518\n",
      "Ep:178, loss:0.00001, loss_test:0.08205, lr:2.90e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.195, tt:6478.839\n",
      "Ep:179, loss:0.00001, loss_test:0.08253, lr:2.88e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.205, tt:6516.959\n",
      "Ep:180, loss:0.00001, loss_test:0.08077, lr:2.85e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.205, tt:6553.110\n",
      "Ep:181, loss:0.00001, loss_test:0.08204, lr:2.82e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.205, tt:6589.312\n",
      "Ep:182, loss:0.00001, loss_test:0.08241, lr:2.79e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.206, tt:6625.611\n",
      "Ep:183, loss:0.00001, loss_test:0.08126, lr:2.76e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.206, tt:6661.915\n",
      "Ep:184, loss:0.00001, loss_test:0.08155, lr:2.73e-03, fs:0.74118 (r=0.636,p=0.887),  time:36.216, tt:6700.013\n",
      "Ep:185, loss:0.00001, loss_test:0.08207, lr:2.71e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.220, tt:6736.883\n",
      "Ep:186, loss:0.00001, loss_test:0.08169, lr:2.68e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.227, tt:6774.506\n",
      "Ep:187, loss:0.00001, loss_test:0.08165, lr:2.65e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.229, tt:6811.121\n",
      "Ep:188, loss:0.00001, loss_test:0.08297, lr:2.63e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.220, tt:6845.553\n",
      "Ep:189, loss:0.00001, loss_test:0.08140, lr:2.60e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.215, tt:6880.755\n",
      "Ep:190, loss:0.00001, loss_test:0.08180, lr:2.57e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.216, tt:6917.193\n",
      "Ep:191, loss:0.00001, loss_test:0.08260, lr:2.55e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.219, tt:6954.024\n",
      "Ep:192, loss:0.00001, loss_test:0.08135, lr:2.52e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.225, tt:6991.336\n",
      "Ep:193, loss:0.00001, loss_test:0.08189, lr:2.50e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.229, tt:7028.399\n",
      "Ep:194, loss:0.00001, loss_test:0.08191, lr:2.47e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.229, tt:7064.702\n",
      "Ep:195, loss:0.00001, loss_test:0.08204, lr:2.45e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.230, tt:7100.991\n",
      "Ep:196, loss:0.00001, loss_test:0.08238, lr:2.42e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.230, tt:7137.402\n",
      "Ep:197, loss:0.00001, loss_test:0.08151, lr:2.40e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.235, tt:7174.449\n",
      "Ep:198, loss:0.00001, loss_test:0.08237, lr:2.38e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.236, tt:7210.917\n",
      "Ep:199, loss:0.00001, loss_test:0.08165, lr:2.35e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.237, tt:7247.352\n",
      "Ep:200, loss:0.00001, loss_test:0.08184, lr:2.33e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.224, tt:7281.006\n",
      "Ep:201, loss:0.00001, loss_test:0.08221, lr:2.31e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.208, tt:7314.049\n",
      "Ep:202, loss:0.00001, loss_test:0.08244, lr:2.28e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.194, tt:7347.291\n",
      "Ep:203, loss:0.00001, loss_test:0.08267, lr:2.26e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.192, tt:7383.115\n",
      "Ep:204, loss:0.00001, loss_test:0.08126, lr:2.24e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.176, tt:7416.155\n",
      "Ep:205, loss:0.00001, loss_test:0.08310, lr:2.21e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.153, tt:7447.611\n",
      "Ep:206, loss:0.00001, loss_test:0.08328, lr:2.19e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.116, tt:7476.077\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02416, lr:6.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:34.569, tt:34.569\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00005, loss_test:0.02600, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:33.062, tt:66.123\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02792, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.153, tt:102.460\n",
      "Ep:3, loss:0.00005, loss_test:0.02808, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.744, tt:134.975\n",
      "Ep:4, loss:0.00005, loss_test:0.02725, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.650, tt:168.250\n",
      "Ep:5, loss:0.00005, loss_test:0.02583, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:33.761, tt:202.569\n",
      "Ep:6, loss:0.00005, loss_test:0.02438, lr:6.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:34.163, tt:239.139\n",
      "Ep:7, loss:0.00004, loss_test:0.02329, lr:6.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:34.378, tt:275.022\n",
      "Ep:8, loss:0.00004, loss_test:0.02251, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:34.668, tt:312.010\n",
      "Ep:9, loss:0.00004, loss_test:0.02162, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:34.730, tt:347.300\n",
      "Ep:10, loss:0.00004, loss_test:0.02083, lr:6.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:34.841, tt:383.251\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02052, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:34.866, tt:418.396\n",
      "Ep:12, loss:0.00004, loss_test:0.02027, lr:6.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:34.875, tt:453.378\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:34.904, tt:488.653\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:34.759, tt:521.385\n",
      "Ep:15, loss:0.00004, loss_test:0.01926, lr:6.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:34.818, tt:557.092\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01898, lr:6.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:34.814, tt:591.830\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:34.850, tt:627.294\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01802, lr:6.00e-02, fs:0.70498 (r=0.929,p=0.568),  time:34.909, tt:663.271\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:34.974, tt:699.480\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01714, lr:6.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:35.022, tt:735.464\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:35.080, tt:771.749\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:35.094, tt:807.152\n",
      "Ep:23, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:35.109, tt:842.609\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:35.109, tt:877.721\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:35.150, tt:913.907\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01559, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:35.165, tt:949.464\n",
      "Ep:27, loss:0.00003, loss_test:0.01547, lr:6.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:35.111, tt:983.116\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:35.127, tt:1018.673\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01513, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:35.124, tt:1053.714\n",
      "Ep:30, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:35.112, tt:1088.481\n",
      "Ep:31, loss:0.00002, loss_test:0.01480, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:35.161, tt:1125.160\n",
      "Ep:32, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:35.181, tt:1160.971\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:35.226, tt:1197.679\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01425, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:35.240, tt:1233.394\n",
      "Ep:35, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:35.259, tt:1269.308\n",
      "Ep:36, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:35.257, tt:1304.503\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:35.233, tt:1338.862\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01370, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:35.221, tt:1373.614\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:35.233, tt:1409.322\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:35.240, tt:1444.828\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.80498 (r=0.980,p=0.683),  time:35.254, tt:1480.665\n",
      "Ep:42, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:35.281, tt:1517.072\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:35.265, tt:1551.645\n",
      "Ep:44, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:35.267, tt:1587.018\n",
      "Ep:45, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:35.262, tt:1622.045\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01288, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:35.274, tt:1657.887\n",
      "Ep:47, loss:0.00002, loss_test:0.01282, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:35.293, tt:1694.065\n",
      "Ep:48, loss:0.00002, loss_test:0.01265, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:35.299, tt:1729.643\n",
      "Ep:49, loss:0.00002, loss_test:0.01265, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:35.309, tt:1765.438\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01250, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:35.309, tt:1800.769\n",
      "Ep:51, loss:0.00002, loss_test:0.01260, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:35.320, tt:1836.661\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01235, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:35.320, tt:1871.975\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01234, lr:6.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:35.330, tt:1907.802\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01252, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:35.350, tt:1944.275\n",
      "Ep:55, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:35.382, tt:1981.402\n",
      "Ep:56, loss:0.00001, loss_test:0.01243, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:35.371, tt:2016.153\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01222, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:35.371, tt:2051.501\n",
      "Ep:58, loss:0.00001, loss_test:0.01242, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:35.378, tt:2087.304\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01231, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:35.390, tt:2123.394\n",
      "Ep:60, loss:0.00001, loss_test:0.01224, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:35.398, tt:2159.305\n",
      "Ep:61, loss:0.00001, loss_test:0.01231, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:35.428, tt:2196.540\n",
      "Ep:62, loss:0.00001, loss_test:0.01231, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:35.452, tt:2233.503\n",
      "Ep:63, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:35.463, tt:2269.630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01239, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:35.480, tt:2306.217\n",
      "Ep:65, loss:0.00001, loss_test:0.01281, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:35.486, tt:2342.097\n",
      "Ep:66, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:35.497, tt:2378.280\n",
      "Ep:67, loss:0.00001, loss_test:0.01315, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:35.486, tt:2413.072\n",
      "Ep:68, loss:0.00001, loss_test:0.01222, lr:6.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:35.495, tt:2449.134\n",
      "Ep:69, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:35.482, tt:2483.709\n",
      "Ep:70, loss:0.00001, loss_test:0.01228, lr:5.94e-02, fs:0.83962 (r=0.899,p=0.788),  time:35.488, tt:2519.653\n",
      "Ep:71, loss:0.00001, loss_test:0.01327, lr:5.88e-02, fs:0.82000 (r=0.828,p=0.812),  time:35.488, tt:2555.168\n",
      "Ep:72, loss:0.00001, loss_test:0.01288, lr:5.82e-02, fs:0.84058 (r=0.879,p=0.806),  time:35.510, tt:2592.204\n",
      "Ep:73, loss:0.00001, loss_test:0.01272, lr:5.76e-02, fs:0.84058 (r=0.879,p=0.806),  time:35.487, tt:2626.012\n",
      "Ep:74, loss:0.00001, loss_test:0.01366, lr:5.71e-02, fs:0.81818 (r=0.818,p=0.818),  time:35.544, tt:2665.835\n",
      "Ep:75, loss:0.00001, loss_test:0.01287, lr:5.65e-02, fs:0.82927 (r=0.859,p=0.802),  time:35.554, tt:2702.067\n",
      "Ep:76, loss:0.00001, loss_test:0.01389, lr:5.59e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.553, tt:2737.562\n",
      "Ep:77, loss:0.00001, loss_test:0.01319, lr:5.54e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.564, tt:2773.990\n",
      "Ep:78, loss:0.00001, loss_test:0.01347, lr:5.48e-02, fs:0.82000 (r=0.828,p=0.812),  time:35.567, tt:2809.816\n",
      "Ep:79, loss:0.00001, loss_test:0.01416, lr:5.43e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.560, tt:2844.771\n",
      "Ep:80, loss:0.00001, loss_test:0.01288, lr:5.37e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.571, tt:2881.270\n",
      "Ep:81, loss:0.00001, loss_test:0.01538, lr:5.32e-02, fs:0.79381 (r=0.778,p=0.811),  time:35.555, tt:2915.484\n",
      "Ep:82, loss:0.00001, loss_test:0.01332, lr:5.27e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.524, tt:2948.503\n",
      "Ep:83, loss:0.00001, loss_test:0.01457, lr:5.21e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.516, tt:2983.326\n",
      "Ep:84, loss:0.00001, loss_test:0.01401, lr:5.16e-02, fs:0.81633 (r=0.808,p=0.825),  time:35.526, tt:3019.704\n",
      "Ep:85, loss:0.00001, loss_test:0.01389, lr:5.11e-02, fs:0.81633 (r=0.808,p=0.825),  time:35.529, tt:3055.487\n",
      "Ep:86, loss:0.00001, loss_test:0.01529, lr:5.06e-02, fs:0.80000 (r=0.788,p=0.812),  time:35.532, tt:3091.250\n",
      "Ep:87, loss:0.00001, loss_test:0.01396, lr:5.01e-02, fs:0.82234 (r=0.818,p=0.827),  time:35.522, tt:3125.949\n",
      "Ep:88, loss:0.00001, loss_test:0.01492, lr:4.96e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.523, tt:3161.507\n",
      "Ep:89, loss:0.00001, loss_test:0.01456, lr:4.91e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.521, tt:3196.894\n",
      "Ep:90, loss:0.00001, loss_test:0.01503, lr:4.86e-02, fs:0.81675 (r=0.788,p=0.848),  time:35.529, tt:3233.153\n",
      "Ep:91, loss:0.00001, loss_test:0.01520, lr:4.81e-02, fs:0.80628 (r=0.778,p=0.837),  time:35.532, tt:3268.968\n",
      "Ep:92, loss:0.00001, loss_test:0.01483, lr:4.76e-02, fs:0.80829 (r=0.788,p=0.830),  time:35.555, tt:3306.639\n",
      "Ep:93, loss:0.00001, loss_test:0.01599, lr:4.71e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.550, tt:3341.691\n",
      "Ep:94, loss:0.00001, loss_test:0.01488, lr:4.67e-02, fs:0.80208 (r=0.778,p=0.828),  time:35.534, tt:3375.719\n",
      "Ep:95, loss:0.00001, loss_test:0.01576, lr:4.62e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.545, tt:3412.342\n",
      "Ep:96, loss:0.00001, loss_test:0.01613, lr:4.57e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.531, tt:3446.496\n",
      "Ep:97, loss:0.00001, loss_test:0.01537, lr:4.53e-02, fs:0.81675 (r=0.788,p=0.848),  time:35.533, tt:3482.263\n",
      "Ep:98, loss:0.00001, loss_test:0.01674, lr:4.48e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.530, tt:3517.510\n",
      "Ep:99, loss:0.00001, loss_test:0.01509, lr:4.44e-02, fs:0.81250 (r=0.788,p=0.839),  time:35.510, tt:3551.049\n",
      "Ep:100, loss:0.00001, loss_test:0.01741, lr:4.39e-02, fs:0.78022 (r=0.717,p=0.855),  time:35.521, tt:3587.632\n",
      "Ep:101, loss:0.00001, loss_test:0.01561, lr:4.35e-02, fs:0.80423 (r=0.768,p=0.844),  time:35.502, tt:3621.174\n",
      "Ep:102, loss:0.00001, loss_test:0.01663, lr:4.31e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.491, tt:3655.617\n",
      "Ep:103, loss:0.00001, loss_test:0.01640, lr:4.26e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.478, tt:3689.762\n",
      "Ep:104, loss:0.00001, loss_test:0.01608, lr:4.22e-02, fs:0.81675 (r=0.788,p=0.848),  time:35.453, tt:3722.558\n",
      "Ep:105, loss:0.00001, loss_test:0.01723, lr:4.18e-02, fs:0.77348 (r=0.707,p=0.854),  time:35.450, tt:3757.742\n",
      "Ep:106, loss:0.00000, loss_test:0.01600, lr:4.14e-02, fs:0.79144 (r=0.747,p=0.841),  time:35.443, tt:3792.436\n",
      "Ep:107, loss:0.00000, loss_test:0.01725, lr:4.10e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.426, tt:3826.005\n",
      "Ep:108, loss:0.00000, loss_test:0.01651, lr:4.05e-02, fs:0.76503 (r=0.707,p=0.833),  time:35.405, tt:3859.144\n",
      "Ep:109, loss:0.00000, loss_test:0.01743, lr:4.01e-02, fs:0.77348 (r=0.707,p=0.854),  time:35.401, tt:3894.107\n",
      "Ep:110, loss:0.00000, loss_test:0.01682, lr:3.97e-02, fs:0.76923 (r=0.707,p=0.843),  time:35.394, tt:3928.718\n",
      "Ep:111, loss:0.00000, loss_test:0.01783, lr:3.93e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.389, tt:3963.612\n",
      "Ep:112, loss:0.00000, loss_test:0.01741, lr:3.89e-02, fs:0.76667 (r=0.697,p=0.852),  time:35.399, tt:4000.042\n",
      "Ep:113, loss:0.00000, loss_test:0.01739, lr:3.86e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.418, tt:4037.641\n",
      "Ep:114, loss:0.00000, loss_test:0.01802, lr:3.82e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.413, tt:4072.468\n",
      "Ep:115, loss:0.00000, loss_test:0.01709, lr:3.78e-02, fs:0.75556 (r=0.687,p=0.840),  time:35.412, tt:4107.814\n",
      "Ep:116, loss:0.00000, loss_test:0.01846, lr:3.74e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.399, tt:4141.738\n",
      "Ep:117, loss:0.00000, loss_test:0.01748, lr:3.70e-02, fs:0.75978 (r=0.687,p=0.850),  time:35.379, tt:4174.693\n",
      "Ep:118, loss:0.00000, loss_test:0.01859, lr:3.67e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.366, tt:4208.563\n",
      "Ep:119, loss:0.00000, loss_test:0.01749, lr:3.63e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.361, tt:4243.330\n",
      "Ep:120, loss:0.00000, loss_test:0.01870, lr:3.59e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.347, tt:4276.960\n",
      "Ep:121, loss:0.00000, loss_test:0.01794, lr:3.56e-02, fs:0.76571 (r=0.677,p=0.882),  time:35.326, tt:4309.825\n",
      "Ep:122, loss:0.00000, loss_test:0.01862, lr:3.52e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.328, tt:4345.291\n",
      "Ep:123, loss:0.00000, loss_test:0.01861, lr:3.49e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.323, tt:4380.039\n",
      "Ep:124, loss:0.00000, loss_test:0.01818, lr:3.45e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.315, tt:4414.358\n",
      "Ep:125, loss:0.00000, loss_test:0.01935, lr:3.42e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.310, tt:4449.036\n",
      "Ep:126, loss:0.00000, loss_test:0.01819, lr:3.38e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.314, tt:4484.903\n",
      "Ep:127, loss:0.00000, loss_test:0.01945, lr:3.35e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.303, tt:4518.758\n",
      "Ep:128, loss:0.00000, loss_test:0.01864, lr:3.32e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.296, tt:4553.240\n",
      "Ep:129, loss:0.00000, loss_test:0.01926, lr:3.28e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.288, tt:4587.447\n",
      "Ep:130, loss:0.00000, loss_test:0.01878, lr:3.25e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.273, tt:4620.787\n",
      "Ep:131, loss:0.00000, loss_test:0.01979, lr:3.22e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.266, tt:4655.100\n",
      "Ep:132, loss:0.00000, loss_test:0.01887, lr:3.19e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.268, tt:4690.702\n",
      "Ep:133, loss:0.00000, loss_test:0.01983, lr:3.15e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.265, tt:4725.458\n",
      "Ep:134, loss:0.00000, loss_test:0.01897, lr:3.12e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.263, tt:4760.445\n",
      "Ep:135, loss:0.00000, loss_test:0.01980, lr:3.09e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.263, tt:4795.748\n",
      "Ep:136, loss:0.00000, loss_test:0.01939, lr:3.06e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.258, tt:4830.352\n",
      "Ep:137, loss:0.00000, loss_test:0.01955, lr:3.03e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.257, tt:4865.511\n",
      "Ep:138, loss:0.00000, loss_test:0.01994, lr:3.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.247, tt:4899.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.01972, lr:2.97e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.239, tt:4933.445\n",
      "Ep:140, loss:0.00000, loss_test:0.01990, lr:2.94e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.238, tt:4968.515\n",
      "Ep:141, loss:0.00000, loss_test:0.01998, lr:2.91e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.241, tt:5004.242\n",
      "Ep:142, loss:0.00000, loss_test:0.01993, lr:2.88e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.237, tt:5038.838\n",
      "Ep:143, loss:0.00000, loss_test:0.02006, lr:2.85e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.251, tt:5076.166\n",
      "Ep:144, loss:0.00000, loss_test:0.02030, lr:2.82e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.255, tt:5111.937\n",
      "Ep:145, loss:0.00000, loss_test:0.02010, lr:2.80e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.253, tt:5146.956\n",
      "Ep:146, loss:0.00000, loss_test:0.02042, lr:2.77e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.272, tt:5184.931\n",
      "Ep:147, loss:0.00000, loss_test:0.02029, lr:2.74e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.264, tt:5219.106\n",
      "Ep:148, loss:0.00000, loss_test:0.02059, lr:2.71e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.269, tt:5255.105\n",
      "Ep:149, loss:0.00000, loss_test:0.02038, lr:2.69e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.261, tt:5289.164\n",
      "Ep:150, loss:0.00000, loss_test:0.02050, lr:2.66e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.270, tt:5325.703\n",
      "Ep:151, loss:0.00000, loss_test:0.02040, lr:2.63e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.273, tt:5361.478\n",
      "Ep:152, loss:0.00000, loss_test:0.02065, lr:2.61e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.272, tt:5396.625\n",
      "Ep:153, loss:0.00000, loss_test:0.02056, lr:2.58e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.276, tt:5432.477\n",
      "Ep:154, loss:0.00000, loss_test:0.02086, lr:2.55e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.273, tt:5467.345\n",
      "Ep:155, loss:0.00000, loss_test:0.02034, lr:2.53e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.272, tt:5502.361\n",
      "Ep:156, loss:0.00000, loss_test:0.02104, lr:2.50e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.275, tt:5538.213\n",
      "Ep:157, loss:0.00000, loss_test:0.02060, lr:2.48e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.268, tt:5572.288\n",
      "Ep:158, loss:0.00000, loss_test:0.02123, lr:2.45e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.270, tt:5607.989\n",
      "Ep:159, loss:0.00000, loss_test:0.02057, lr:2.43e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.276, tt:5644.201\n",
      "Ep:160, loss:0.00000, loss_test:0.02143, lr:2.40e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.287, tt:5681.251\n",
      "Ep:161, loss:0.00000, loss_test:0.02073, lr:2.38e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.301, tt:5718.725\n",
      "Ep:162, loss:0.00000, loss_test:0.02132, lr:2.36e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.305, tt:5754.744\n",
      "Ep:163, loss:0.00000, loss_test:0.02090, lr:2.33e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.303, tt:5789.666\n",
      "Ep:164, loss:0.00000, loss_test:0.02129, lr:2.31e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.312, tt:5826.501\n",
      "Ep:165, loss:0.00000, loss_test:0.02106, lr:2.29e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.311, tt:5861.590\n",
      "Ep:166, loss:0.00000, loss_test:0.02146, lr:2.26e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.310, tt:5896.793\n",
      "Ep:167, loss:0.00000, loss_test:0.02104, lr:2.24e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.317, tt:5933.324\n",
      "Ep:168, loss:0.00000, loss_test:0.02157, lr:2.22e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.322, tt:5969.488\n",
      "Ep:169, loss:0.00000, loss_test:0.02127, lr:2.20e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.324, tt:6005.019\n",
      "Ep:170, loss:0.00000, loss_test:0.02139, lr:2.17e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.320, tt:6039.637\n",
      "Ep:171, loss:0.00000, loss_test:0.02150, lr:2.15e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.323, tt:6075.560\n",
      "Ep:172, loss:0.00000, loss_test:0.02140, lr:2.13e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.324, tt:6111.004\n",
      "Ep:173, loss:0.00000, loss_test:0.02150, lr:2.11e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.329, tt:6147.327\n",
      "Ep:174, loss:0.00000, loss_test:0.02160, lr:2.09e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.323, tt:6181.490\n",
      "Ep:175, loss:0.00000, loss_test:0.02151, lr:2.07e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.342, tt:6220.250\n",
      "Ep:176, loss:0.00000, loss_test:0.02160, lr:2.05e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.350, tt:6256.941\n",
      "Ep:177, loss:0.00000, loss_test:0.02171, lr:2.03e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.348, tt:6291.971\n",
      "Ep:178, loss:0.00000, loss_test:0.02158, lr:2.01e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.349, tt:6327.401\n",
      "Ep:179, loss:0.00000, loss_test:0.02166, lr:1.99e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.347, tt:6362.488\n",
      "Ep:180, loss:0.00000, loss_test:0.02184, lr:1.97e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.353, tt:6398.900\n",
      "Ep:181, loss:0.00000, loss_test:0.02176, lr:1.95e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.361, tt:6435.763\n",
      "Ep:182, loss:0.00000, loss_test:0.02187, lr:1.93e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.369, tt:6472.494\n",
      "Ep:183, loss:0.00000, loss_test:0.02184, lr:1.91e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.376, tt:6509.213\n",
      "Ep:184, loss:0.00000, loss_test:0.02189, lr:1.89e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.381, tt:6545.560\n",
      "Ep:185, loss:0.00000, loss_test:0.02183, lr:1.87e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.388, tt:6582.144\n",
      "Ep:186, loss:0.00000, loss_test:0.02206, lr:1.85e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.394, tt:6618.631\n",
      "Ep:187, loss:0.00000, loss_test:0.02191, lr:1.83e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.388, tt:6652.867\n",
      "Ep:188, loss:0.00000, loss_test:0.02202, lr:1.81e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.386, tt:6687.944\n",
      "Ep:189, loss:0.00000, loss_test:0.02210, lr:1.80e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.397, tt:6725.377\n",
      "Ep:190, loss:0.00000, loss_test:0.02182, lr:1.78e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.395, tt:6760.397\n",
      "Ep:191, loss:0.00000, loss_test:0.02217, lr:1.76e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.393, tt:6795.433\n",
      "Ep:192, loss:0.00000, loss_test:0.02207, lr:1.74e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.398, tt:6831.722\n",
      "Ep:193, loss:0.00000, loss_test:0.02212, lr:1.73e-02, fs:0.75294 (r=0.646,p=0.901),  time:35.400, tt:6867.621\n",
      "Ep:194, loss:0.00000, loss_test:0.02203, lr:1.71e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.396, tt:6902.204\n",
      "Ep:195, loss:0.00000, loss_test:0.02218, lr:1.69e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.398, tt:6938.092\n",
      "Ep:196, loss:0.00000, loss_test:0.02220, lr:1.67e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.401, tt:6974.030\n",
      "Ep:197, loss:0.00000, loss_test:0.02207, lr:1.66e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.397, tt:7008.646\n",
      "Ep:198, loss:0.00000, loss_test:0.02235, lr:1.64e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.400, tt:7044.582\n",
      "Ep:199, loss:0.00000, loss_test:0.02224, lr:1.62e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.402, tt:7080.486\n",
      "Ep:200, loss:0.00000, loss_test:0.02218, lr:1.61e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.406, tt:7116.645\n",
      "Ep:201, loss:0.00000, loss_test:0.02238, lr:1.59e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.409, tt:7152.526\n",
      "Ep:202, loss:0.00000, loss_test:0.02213, lr:1.58e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.407, tt:7187.696\n",
      "Ep:203, loss:0.00000, loss_test:0.02235, lr:1.56e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.398, tt:7221.267\n",
      "Ep:204, loss:0.00000, loss_test:0.02240, lr:1.54e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.402, tt:7257.406\n",
      "Ep:205, loss:0.00000, loss_test:0.02232, lr:1.53e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.399, tt:7292.164\n",
      "Ep:206, loss:0.00000, loss_test:0.02241, lr:1.51e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.377, tt:7323.131\n",
      "Ep:207, loss:0.00000, loss_test:0.02240, lr:1.50e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.360, tt:7354.810\n",
      "Ep:208, loss:0.00000, loss_test:0.02243, lr:1.48e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.349, tt:7388.020\n",
      "Ep:209, loss:0.00000, loss_test:0.02246, lr:1.47e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.346, tt:7422.715\n",
      "Ep:210, loss:0.00000, loss_test:0.02241, lr:1.45e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.338, tt:7456.422\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14194, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:33.044, tt:33.044\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13992, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:34.423, tt:68.846\n",
      "Ep:2, loss:0.00027, loss_test:0.13705, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:34.261, tt:102.783\n",
      "Ep:3, loss:0.00026, loss_test:0.13449, lr:1.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:34.630, tt:138.522\n",
      "Ep:4, loss:0.00025, loss_test:0.13070, lr:1.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:34.638, tt:173.189\n",
      "Ep:5, loss:0.00025, loss_test:0.12649, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:34.905, tt:209.432\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12281, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:35.313, tt:247.189\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12163, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:35.462, tt:283.693\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.12035, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:35.789, tt:322.105\n",
      "Ep:9, loss:0.00023, loss_test:0.11883, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:35.911, tt:359.108\n",
      "Ep:10, loss:0.00022, loss_test:0.11688, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:35.962, tt:395.584\n",
      "Ep:11, loss:0.00022, loss_test:0.11461, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:36.119, tt:433.428\n",
      "Ep:12, loss:0.00021, loss_test:0.11240, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:36.091, tt:469.187\n",
      "Ep:13, loss:0.00021, loss_test:0.11130, lr:1.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:36.092, tt:505.283\n",
      "Ep:14, loss:0.00020, loss_test:0.10949, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:36.151, tt:542.260\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10718, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:36.210, tt:579.365\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10620, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:36.294, tt:616.992\n",
      "Ep:17, loss:0.00019, loss_test:0.10320, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:36.412, tt:655.420\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10233, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:36.490, tt:693.301\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.10106, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:36.476, tt:729.523\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09855, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:36.545, tt:767.448\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.09687, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:36.607, tt:805.346\n",
      "Ep:22, loss:0.00016, loss_test:0.09612, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:36.619, tt:842.228\n",
      "Ep:23, loss:0.00016, loss_test:0.09458, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:36.692, tt:880.612\n",
      "Ep:24, loss:0.00016, loss_test:0.09256, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:36.725, tt:918.115\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09201, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:36.751, tt:955.515\n",
      "Ep:26, loss:0.00015, loss_test:0.09162, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:36.759, tt:992.486\n",
      "Ep:27, loss:0.00015, loss_test:0.08902, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:36.783, tt:1029.937\n",
      "Ep:28, loss:0.00014, loss_test:0.09163, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:36.839, tt:1068.320\n",
      "Ep:29, loss:0.00014, loss_test:0.08875, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:36.836, tt:1105.088\n",
      "Ep:30, loss:0.00014, loss_test:0.09069, lr:1.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:36.866, tt:1142.844\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08678, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:36.870, tt:1179.852\n",
      "Ep:32, loss:0.00013, loss_test:0.08719, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:36.921, tt:1218.379\n",
      "Ep:33, loss:0.00012, loss_test:0.08611, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:36.899, tt:1254.554\n",
      "Ep:34, loss:0.00012, loss_test:0.08477, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:36.899, tt:1291.469\n",
      "Ep:35, loss:0.00012, loss_test:0.08290, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:36.903, tt:1328.512\n",
      "Ep:36, loss:0.00011, loss_test:0.08269, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:36.919, tt:1365.992\n",
      "Ep:37, loss:0.00011, loss_test:0.08326, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:36.953, tt:1404.207\n",
      "Ep:38, loss:0.00011, loss_test:0.08372, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:37.000, tt:1442.995\n",
      "Ep:39, loss:0.00011, loss_test:0.08114, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:37.004, tt:1480.166\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.08309, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:37.007, tt:1517.297\n",
      "Ep:41, loss:0.00011, loss_test:0.07764, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:37.029, tt:1555.224\n",
      "Ep:42, loss:0.00010, loss_test:0.07887, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:37.014, tt:1591.612\n",
      "Ep:43, loss:0.00009, loss_test:0.08221, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:36.980, tt:1627.115\n",
      "Ep:44, loss:0.00009, loss_test:0.08045, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:36.981, tt:1664.131\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.07895, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:37.071, tt:1705.288\n",
      "Ep:46, loss:0.00009, loss_test:0.08021, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:37.110, tt:1744.192\n",
      "Ep:47, loss:0.00009, loss_test:0.07324, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:37.108, tt:1781.181\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.07976, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:37.111, tt:1818.444\n",
      "Ep:49, loss:0.00008, loss_test:0.07333, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:37.111, tt:1855.539\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.07777, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:37.149, tt:1894.602\n",
      "Ep:51, loss:0.00007, loss_test:0.07296, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:37.169, tt:1932.797\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.07407, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:37.174, tt:1970.219\n",
      "Ep:53, loss:0.00007, loss_test:0.07538, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:37.177, tt:2007.533\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07267, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:37.178, tt:2044.815\n",
      "Ep:55, loss:0.00007, loss_test:0.07234, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:37.195, tt:2082.903\n",
      "Ep:56, loss:0.00006, loss_test:0.07334, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:37.185, tt:2119.567\n",
      "Ep:57, loss:0.00006, loss_test:0.07223, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:37.191, tt:2157.054\n",
      "Ep:58, loss:0.00006, loss_test:0.07474, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:37.182, tt:2193.753\n",
      "Ep:59, loss:0.00006, loss_test:0.06929, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:37.183, tt:2230.952\n",
      "Ep:60, loss:0.00006, loss_test:0.07603, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:37.180, tt:2267.971\n",
      "Ep:61, loss:0.00006, loss_test:0.07243, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:37.173, tt:2304.707\n",
      "Ep:62, loss:0.00006, loss_test:0.07223, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:37.182, tt:2342.486\n",
      "Ep:63, loss:0.00006, loss_test:0.07344, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:37.164, tt:2378.480\n",
      "Ep:64, loss:0.00005, loss_test:0.07560, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:37.158, tt:2415.262\n",
      "Ep:65, loss:0.00005, loss_test:0.07281, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:37.145, tt:2451.574\n",
      "Ep:66, loss:0.00006, loss_test:0.07495, lr:9.80e-03, fs:0.79558 (r=0.727,p=0.878),  time:37.119, tt:2487.001\n",
      "Ep:67, loss:0.00005, loss_test:0.07758, lr:9.70e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.102, tt:2522.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00005, loss_test:0.07305, lr:9.61e-03, fs:0.79121 (r=0.727,p=0.867),  time:37.107, tt:2560.351\n",
      "Ep:69, loss:0.00005, loss_test:0.07234, lr:9.51e-03, fs:0.79121 (r=0.727,p=0.867),  time:37.086, tt:2596.054\n",
      "Ep:70, loss:0.00005, loss_test:0.07328, lr:9.41e-03, fs:0.78689 (r=0.727,p=0.857),  time:37.029, tt:2629.064\n",
      "Ep:71, loss:0.00005, loss_test:0.07453, lr:9.32e-03, fs:0.78534 (r=0.758,p=0.815),  time:37.022, tt:2665.604\n",
      "Ep:72, loss:0.00005, loss_test:0.07794, lr:9.23e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.993, tt:2700.458\n",
      "Ep:73, loss:0.00005, loss_test:0.06647, lr:9.14e-03, fs:0.80645 (r=0.758,p=0.862),  time:36.983, tt:2736.777\n",
      "Ep:74, loss:0.00005, loss_test:0.06881, lr:9.04e-03, fs:0.78919 (r=0.737,p=0.849),  time:36.965, tt:2772.340\n",
      "Ep:75, loss:0.00004, loss_test:0.08079, lr:8.95e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.913, tt:2805.364\n",
      "Ep:76, loss:0.00004, loss_test:0.07266, lr:8.86e-03, fs:0.79781 (r=0.737,p=0.869),  time:36.909, tt:2841.998\n",
      "Ep:77, loss:0.00004, loss_test:0.07536, lr:8.78e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.901, tt:2878.306\n",
      "Ep:78, loss:0.00004, loss_test:0.07404, lr:8.69e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.876, tt:2913.181\n",
      "Ep:79, loss:0.00004, loss_test:0.07552, lr:8.60e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.871, tt:2949.641\n",
      "Ep:80, loss:0.00004, loss_test:0.07125, lr:8.51e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.873, tt:2986.697\n",
      "Ep:81, loss:0.00004, loss_test:0.07809, lr:8.43e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.868, tt:3023.176\n",
      "Ep:82, loss:0.00003, loss_test:0.06821, lr:8.35e-03, fs:0.79781 (r=0.737,p=0.869),  time:36.863, tt:3059.655\n",
      "Ep:83, loss:0.00004, loss_test:0.07856, lr:8.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.847, tt:3095.158\n",
      "Ep:84, loss:0.00004, loss_test:0.07069, lr:8.18e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.846, tt:3131.876\n",
      "Ep:85, loss:0.00003, loss_test:0.07588, lr:8.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.826, tt:3167.001\n",
      "Ep:86, loss:0.00004, loss_test:0.07300, lr:8.02e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.810, tt:3202.484\n",
      "Ep:87, loss:0.00003, loss_test:0.07264, lr:7.94e-03, fs:0.79558 (r=0.727,p=0.878),  time:36.780, tt:3236.655\n",
      "Ep:88, loss:0.00003, loss_test:0.07174, lr:7.86e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.741, tt:3269.906\n",
      "Ep:89, loss:0.00003, loss_test:0.07402, lr:7.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.733, tt:3305.928\n",
      "Ep:90, loss:0.00003, loss_test:0.07108, lr:7.70e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.745, tt:3343.824\n",
      "Ep:91, loss:0.00003, loss_test:0.08357, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:36.736, tt:3379.668\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00003, loss_test:0.06730, lr:7.62e-03, fs:0.79570 (r=0.747,p=0.851),  time:36.738, tt:3416.653\n",
      "Ep:93, loss:0.00003, loss_test:0.08257, lr:7.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.754, tt:3454.909\n",
      "Ep:94, loss:0.00003, loss_test:0.06881, lr:7.62e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.758, tt:3491.963\n",
      "Ep:95, loss:0.00003, loss_test:0.07644, lr:7.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.761, tt:3529.101\n",
      "Ep:96, loss:0.00003, loss_test:0.07452, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.758, tt:3565.564\n",
      "Ep:97, loss:0.00003, loss_test:0.06986, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.751, tt:3601.635\n",
      "Ep:98, loss:0.00003, loss_test:0.07631, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.754, tt:3638.598\n",
      "Ep:99, loss:0.00003, loss_test:0.07240, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.754, tt:3675.385\n",
      "Ep:100, loss:0.00003, loss_test:0.06942, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.750, tt:3711.749\n",
      "Ep:101, loss:0.00003, loss_test:0.07496, lr:7.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.747, tt:3748.233\n",
      "Ep:102, loss:0.00002, loss_test:0.06956, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.742, tt:3784.431\n",
      "Ep:103, loss:0.00002, loss_test:0.07202, lr:7.55e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.745, tt:3821.446\n",
      "Ep:104, loss:0.00002, loss_test:0.07506, lr:7.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.750, tt:3858.736\n",
      "Ep:105, loss:0.00002, loss_test:0.06952, lr:7.40e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.741, tt:3894.543\n",
      "Ep:106, loss:0.00002, loss_test:0.07489, lr:7.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.718, tt:3928.850\n",
      "Ep:107, loss:0.00002, loss_test:0.07339, lr:7.25e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.699, tt:3963.541\n",
      "Ep:108, loss:0.00002, loss_test:0.06754, lr:7.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.693, tt:3999.502\n",
      "Ep:109, loss:0.00002, loss_test:0.07290, lr:7.11e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.689, tt:4035.797\n",
      "Ep:110, loss:0.00002, loss_test:0.07173, lr:7.03e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.676, tt:4070.989\n",
      "Ep:111, loss:0.00002, loss_test:0.07515, lr:6.96e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.651, tt:4104.949\n",
      "Ep:112, loss:0.00002, loss_test:0.07365, lr:6.89e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.653, tt:4141.837\n",
      "Ep:113, loss:0.00002, loss_test:0.06966, lr:6.83e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.660, tt:4179.248\n",
      "Ep:114, loss:0.00002, loss_test:0.07548, lr:6.76e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.653, tt:4215.067\n",
      "Ep:115, loss:0.00002, loss_test:0.07016, lr:6.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.651, tt:4251.490\n",
      "Ep:116, loss:0.00002, loss_test:0.06961, lr:6.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.637, tt:4286.585\n",
      "Ep:117, loss:0.00002, loss_test:0.07235, lr:6.56e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.627, tt:4322.027\n",
      "Ep:118, loss:0.00002, loss_test:0.07141, lr:6.49e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.614, tt:4357.058\n",
      "Ep:119, loss:0.00002, loss_test:0.07104, lr:6.43e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.618, tt:4394.221\n",
      "Ep:120, loss:0.00002, loss_test:0.07100, lr:6.36e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.618, tt:4430.783\n",
      "Ep:121, loss:0.00002, loss_test:0.07024, lr:6.30e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.622, tt:4467.870\n",
      "Ep:122, loss:0.00002, loss_test:0.07164, lr:6.24e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.617, tt:4503.869\n",
      "Ep:123, loss:0.00002, loss_test:0.07049, lr:6.17e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.614, tt:4540.168\n",
      "Ep:124, loss:0.00002, loss_test:0.07104, lr:6.11e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.616, tt:4576.983\n",
      "Ep:125, loss:0.00002, loss_test:0.07264, lr:6.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.623, tt:4614.470\n",
      "Ep:126, loss:0.00002, loss_test:0.06915, lr:5.99e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.615, tt:4650.085\n",
      "Ep:127, loss:0.00002, loss_test:0.07251, lr:5.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.616, tt:4686.811\n",
      "Ep:128, loss:0.00002, loss_test:0.07121, lr:5.87e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.610, tt:4722.640\n",
      "Ep:129, loss:0.00002, loss_test:0.07044, lr:5.81e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.611, tt:4759.400\n",
      "Ep:130, loss:0.00002, loss_test:0.07342, lr:5.75e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.601, tt:4794.679\n",
      "Ep:131, loss:0.00002, loss_test:0.06899, lr:5.70e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.594, tt:4830.394\n",
      "Ep:132, loss:0.00002, loss_test:0.07195, lr:5.64e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.593, tt:4866.884\n",
      "Ep:133, loss:0.00001, loss_test:0.07081, lr:5.58e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.586, tt:4902.483\n",
      "Ep:134, loss:0.00001, loss_test:0.07008, lr:5.53e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.584, tt:4938.855\n",
      "Ep:135, loss:0.00001, loss_test:0.07131, lr:5.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.581, tt:4974.973\n",
      "Ep:136, loss:0.00001, loss_test:0.07004, lr:5.42e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.568, tt:5009.796\n",
      "Ep:137, loss:0.00001, loss_test:0.07105, lr:5.36e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.564, tt:5045.859\n",
      "Ep:138, loss:0.00001, loss_test:0.07147, lr:5.31e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.564, tt:5082.426\n",
      "Ep:139, loss:0.00001, loss_test:0.07052, lr:5.26e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.553, tt:5117.474\n",
      "Ep:140, loss:0.00001, loss_test:0.07161, lr:5.20e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.538, tt:5151.816\n",
      "Ep:141, loss:0.00001, loss_test:0.07176, lr:5.15e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.541, tt:5188.863\n",
      "Ep:142, loss:0.00001, loss_test:0.06968, lr:5.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.541, tt:5225.378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.07144, lr:5.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.536, tt:5261.125\n",
      "Ep:144, loss:0.00001, loss_test:0.07037, lr:5.00e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.527, tt:5296.471\n",
      "Ep:145, loss:0.00001, loss_test:0.06986, lr:4.95e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.525, tt:5332.590\n",
      "Ep:146, loss:0.00001, loss_test:0.07113, lr:4.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.529, tt:5369.826\n",
      "Ep:147, loss:0.00001, loss_test:0.06999, lr:4.85e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.532, tt:5406.768\n",
      "Ep:148, loss:0.00001, loss_test:0.07135, lr:4.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.536, tt:5443.887\n",
      "Ep:149, loss:0.00001, loss_test:0.06967, lr:4.75e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.543, tt:5481.504\n",
      "Ep:150, loss:0.00001, loss_test:0.07169, lr:4.71e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.571, tt:5522.186\n",
      "Ep:151, loss:0.00001, loss_test:0.07028, lr:4.66e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.583, tt:5560.549\n",
      "Ep:152, loss:0.00001, loss_test:0.07104, lr:4.61e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.581, tt:5596.915\n",
      "Ep:153, loss:0.00001, loss_test:0.07013, lr:4.57e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.584, tt:5633.878\n",
      "Ep:154, loss:0.00001, loss_test:0.07097, lr:4.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.590, tt:5671.453\n",
      "Ep:155, loss:0.00001, loss_test:0.07028, lr:4.48e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.602, tt:5709.898\n",
      "Ep:156, loss:0.00001, loss_test:0.07102, lr:4.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.603, tt:5746.745\n",
      "Ep:157, loss:0.00001, loss_test:0.06977, lr:4.39e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.602, tt:5783.164\n",
      "Ep:158, loss:0.00001, loss_test:0.07109, lr:4.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.603, tt:5819.952\n",
      "Ep:159, loss:0.00001, loss_test:0.06980, lr:4.30e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.609, tt:5857.390\n",
      "Ep:160, loss:0.00001, loss_test:0.07095, lr:4.26e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.616, tt:5895.157\n",
      "Ep:161, loss:0.00001, loss_test:0.07033, lr:4.21e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.619, tt:5932.305\n",
      "Ep:162, loss:0.00001, loss_test:0.07055, lr:4.17e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.623, tt:5969.580\n",
      "Ep:163, loss:0.00001, loss_test:0.07008, lr:4.13e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.621, tt:6005.836\n",
      "Ep:164, loss:0.00001, loss_test:0.07000, lr:4.09e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.606, tt:6040.023\n",
      "Ep:165, loss:0.00001, loss_test:0.07012, lr:4.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.607, tt:6076.778\n",
      "Ep:166, loss:0.00001, loss_test:0.07082, lr:4.01e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.595, tt:6111.360\n",
      "Ep:167, loss:0.00001, loss_test:0.07039, lr:3.97e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.584, tt:6146.122\n",
      "Ep:168, loss:0.00001, loss_test:0.07081, lr:3.93e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.576, tt:6181.298\n",
      "Ep:169, loss:0.00001, loss_test:0.07045, lr:3.89e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.568, tt:6216.613\n",
      "Ep:170, loss:0.00001, loss_test:0.07063, lr:3.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.570, tt:6253.403\n",
      "Ep:171, loss:0.00001, loss_test:0.07026, lr:3.81e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.558, tt:6287.994\n",
      "Ep:172, loss:0.00001, loss_test:0.07133, lr:3.77e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.554, tt:6323.842\n",
      "Ep:173, loss:0.00001, loss_test:0.06999, lr:3.73e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.547, tt:6359.202\n",
      "Ep:174, loss:0.00001, loss_test:0.06972, lr:3.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.534, tt:6393.496\n",
      "Ep:175, loss:0.00001, loss_test:0.07032, lr:3.66e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.536, tt:6430.341\n",
      "Ep:176, loss:0.00001, loss_test:0.07089, lr:3.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.537, tt:6466.983\n",
      "Ep:177, loss:0.00001, loss_test:0.06788, lr:3.59e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.534, tt:6503.114\n",
      "Ep:178, loss:0.00001, loss_test:0.07193, lr:3.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.531, tt:6539.005\n",
      "Ep:179, loss:0.00001, loss_test:0.07074, lr:3.52e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.527, tt:6574.848\n",
      "Ep:180, loss:0.00001, loss_test:0.06919, lr:3.48e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.526, tt:6611.206\n",
      "Ep:181, loss:0.00001, loss_test:0.07119, lr:3.45e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.527, tt:6647.910\n",
      "Ep:182, loss:0.00001, loss_test:0.07095, lr:3.41e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.538, tt:6686.512\n",
      "Ep:183, loss:0.00001, loss_test:0.06932, lr:3.38e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.532, tt:6721.815\n",
      "Ep:184, loss:0.00001, loss_test:0.07081, lr:3.34e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.526, tt:6757.309\n",
      "Ep:185, loss:0.00001, loss_test:0.07080, lr:3.31e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.524, tt:6793.464\n",
      "Ep:186, loss:0.00001, loss_test:0.06879, lr:3.28e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.526, tt:6830.327\n",
      "Ep:187, loss:0.00001, loss_test:0.07135, lr:3.24e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.532, tt:6868.004\n",
      "Ep:188, loss:0.00001, loss_test:0.07166, lr:3.21e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.531, tt:6904.306\n",
      "Ep:189, loss:0.00001, loss_test:0.06938, lr:3.18e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.531, tt:6940.845\n",
      "Ep:190, loss:0.00001, loss_test:0.07016, lr:3.15e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.530, tt:6977.314\n",
      "Ep:191, loss:0.00001, loss_test:0.07124, lr:3.12e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.525, tt:7012.886\n",
      "Ep:192, loss:0.00001, loss_test:0.07101, lr:3.09e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.522, tt:7048.733\n",
      "Ep:193, loss:0.00001, loss_test:0.06931, lr:3.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.526, tt:7085.983\n",
      "Ep:194, loss:0.00001, loss_test:0.07323, lr:3.02e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.522, tt:7121.854\n",
      "Ep:195, loss:0.00001, loss_test:0.07039, lr:2.99e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.523, tt:7158.570\n",
      "Ep:196, loss:0.00001, loss_test:0.06996, lr:2.96e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.518, tt:7194.113\n",
      "Ep:197, loss:0.00001, loss_test:0.07204, lr:2.93e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.513, tt:7229.530\n",
      "Ep:198, loss:0.00001, loss_test:0.07024, lr:2.90e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.511, tt:7265.609\n",
      "Ep:199, loss:0.00001, loss_test:0.06954, lr:2.88e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.510, tt:7301.971\n",
      "Ep:200, loss:0.00001, loss_test:0.07032, lr:2.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.506, tt:7337.737\n",
      "Ep:201, loss:0.00001, loss_test:0.07080, lr:2.82e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.502, tt:7373.394\n",
      "Ep:202, loss:0.00001, loss_test:0.06893, lr:2.79e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.503, tt:7410.053\n",
      "Ep:203, loss:0.00001, loss_test:0.07036, lr:2.76e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.496, tt:7445.140\n",
      "Ep:204, loss:0.00001, loss_test:0.07084, lr:2.73e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.483, tt:7478.973\n",
      "Ep:205, loss:0.00001, loss_test:0.06991, lr:2.71e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.473, tt:7513.465\n",
      "Ep:206, loss:0.00001, loss_test:0.06908, lr:2.68e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.460, tt:7547.133\n",
      "Ep:207, loss:0.00001, loss_test:0.07007, lr:2.65e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.447, tt:7581.039\n",
      "Ep:208, loss:0.00001, loss_test:0.07053, lr:2.63e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.428, tt:7613.534\n",
      "Ep:209, loss:0.00001, loss_test:0.06906, lr:2.60e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.402, tt:7644.523\n",
      "Ep:210, loss:0.00001, loss_test:0.07021, lr:2.57e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.390, tt:7678.321\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02361, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:31.528, tt:31.528\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02589, lr:6.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:33.145, tt:66.289\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02763, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.834, tt:98.502\n",
      "Ep:3, loss:0.00005, loss_test:0.02768, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.125, tt:128.501\n",
      "Ep:4, loss:0.00005, loss_test:0.02671, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:32.107, tt:160.536\n",
      "Ep:5, loss:0.00005, loss_test:0.02519, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:32.088, tt:192.527\n",
      "Ep:6, loss:0.00004, loss_test:0.02404, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:32.365, tt:226.554\n",
      "Ep:7, loss:0.00004, loss_test:0.02332, lr:6.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:32.562, tt:260.493\n",
      "Ep:8, loss:0.00004, loss_test:0.02244, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:33.066, tt:297.596\n",
      "Ep:9, loss:0.00004, loss_test:0.02179, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:33.185, tt:331.851\n",
      "Ep:10, loss:0.00004, loss_test:0.02142, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:33.296, tt:366.251\n",
      "Ep:11, loss:0.00004, loss_test:0.02117, lr:6.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:33.401, tt:400.811\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02073, lr:6.00e-02, fs:0.69853 (r=0.960,p=0.549),  time:33.505, tt:435.566\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02022, lr:6.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:33.737, tt:472.314\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01980, lr:6.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:33.829, tt:507.428\n",
      "Ep:15, loss:0.00004, loss_test:0.01948, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:33.898, tt:542.362\n",
      "Ep:16, loss:0.00003, loss_test:0.01902, lr:6.00e-02, fs:0.71483 (r=0.949,p=0.573),  time:33.940, tt:576.973\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01846, lr:6.00e-02, fs:0.72727 (r=0.970,p=0.582),  time:33.988, tt:611.780\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.72727 (r=0.970,p=0.582),  time:34.002, tt:646.036\n",
      "Ep:19, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.73563 (r=0.970,p=0.593),  time:34.066, tt:681.324\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.74419 (r=0.970,p=0.604),  time:34.030, tt:714.638\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:34.053, tt:749.163\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01654, lr:6.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:34.059, tt:783.364\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.76000 (r=0.960,p=0.629),  time:34.088, tt:818.119\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:34.117, tt:852.920\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:34.138, tt:887.578\n",
      "Ep:26, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:34.131, tt:921.545\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:34.223, tt:958.246\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01535, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.258, tt:993.469\n",
      "Ep:29, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.77419 (r=0.970,p=0.644),  time:34.322, tt:1029.648\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.310, tt:1063.595\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.355, tt:1099.354\n",
      "Ep:32, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.341, tt:1133.265\n",
      "Ep:33, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:34.348, tt:1167.846\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:34.365, tt:1202.784\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:34.446, tt:1240.041\n",
      "Ep:36, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:34.451, tt:1274.693\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.80165 (r=0.980,p=0.678),  time:34.478, tt:1310.149\n",
      "Ep:38, loss:0.00002, loss_test:0.01376, lr:6.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:34.501, tt:1345.539\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:34.469, tt:1378.767\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.81328 (r=0.990,p=0.690),  time:34.499, tt:1414.478\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:34.458, tt:1447.221\n",
      "Ep:42, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.80833 (r=0.980,p=0.688),  time:34.473, tt:1482.321\n",
      "Ep:43, loss:0.00002, loss_test:0.01343, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:34.455, tt:1516.037\n",
      "Ep:44, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.453, tt:1550.392\n",
      "Ep:45, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:34.474, tt:1585.795\n",
      "Ep:46, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:34.526, tt:1622.710\n",
      "Ep:47, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.555, tt:1658.646\n",
      "Ep:48, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.557, tt:1693.273\n",
      "Ep:49, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:34.574, tt:1728.679\n",
      "Ep:50, loss:0.00001, loss_test:0.01324, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:34.621, tt:1765.663\n",
      "Ep:51, loss:0.00001, loss_test:0.01321, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:34.633, tt:1800.910\n",
      "Ep:52, loss:0.00001, loss_test:0.01334, lr:5.94e-02, fs:0.78924 (r=0.889,p=0.710),  time:34.675, tt:1837.794\n",
      "Ep:53, loss:0.00001, loss_test:0.01317, lr:5.88e-02, fs:0.79821 (r=0.899,p=0.718),  time:34.709, tt:1874.309\n",
      "Ep:54, loss:0.00001, loss_test:0.01316, lr:5.82e-02, fs:0.80365 (r=0.889,p=0.733),  time:34.736, tt:1910.461\n",
      "Ep:55, loss:0.00001, loss_test:0.01330, lr:5.76e-02, fs:0.80000 (r=0.869,p=0.741),  time:34.753, tt:1946.188\n",
      "Ep:56, loss:0.00001, loss_test:0.01320, lr:5.71e-02, fs:0.79070 (r=0.859,p=0.733),  time:34.775, tt:1982.189\n",
      "Ep:57, loss:0.00001, loss_test:0.01327, lr:5.65e-02, fs:0.79621 (r=0.848,p=0.750),  time:34.810, tt:2018.961\n",
      "Ep:58, loss:0.00001, loss_test:0.01311, lr:5.59e-02, fs:0.79812 (r=0.859,p=0.746),  time:34.801, tt:2053.273\n",
      "Ep:59, loss:0.00001, loss_test:0.01343, lr:5.54e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.796, tt:2087.744\n",
      "Ep:60, loss:0.00001, loss_test:0.01312, lr:5.48e-02, fs:0.78846 (r=0.828,p=0.752),  time:34.801, tt:2122.879\n",
      "Ep:61, loss:0.00001, loss_test:0.01348, lr:5.43e-02, fs:0.76238 (r=0.778,p=0.748),  time:34.863, tt:2161.483\n",
      "Ep:62, loss:0.00001, loss_test:0.01319, lr:5.37e-02, fs:0.78049 (r=0.808,p=0.755),  time:34.868, tt:2196.673\n",
      "Ep:63, loss:0.00001, loss_test:0.01339, lr:5.32e-02, fs:0.78000 (r=0.788,p=0.772),  time:34.903, tt:2233.793\n",
      "Ep:64, loss:0.00001, loss_test:0.01352, lr:5.27e-02, fs:0.76382 (r=0.768,p=0.760),  time:34.905, tt:2268.811\n",
      "Ep:65, loss:0.00001, loss_test:0.01344, lr:5.21e-02, fs:0.76768 (r=0.768,p=0.768),  time:34.904, tt:2303.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00001, loss_test:0.01333, lr:5.16e-02, fs:0.75510 (r=0.747,p=0.763),  time:34.923, tt:2339.827\n",
      "Ep:67, loss:0.00001, loss_test:0.01362, lr:5.11e-02, fs:0.73684 (r=0.707,p=0.769),  time:34.947, tt:2376.394\n",
      "Ep:68, loss:0.00001, loss_test:0.01337, lr:5.06e-02, fs:0.76382 (r=0.768,p=0.760),  time:34.961, tt:2412.326\n",
      "Ep:69, loss:0.00001, loss_test:0.01374, lr:5.01e-02, fs:0.73298 (r=0.707,p=0.761),  time:34.993, tt:2449.518\n",
      "Ep:70, loss:0.00001, loss_test:0.01373, lr:4.96e-02, fs:0.72632 (r=0.697,p=0.758),  time:35.011, tt:2485.770\n",
      "Ep:71, loss:0.00001, loss_test:0.01352, lr:4.91e-02, fs:0.73958 (r=0.717,p=0.763),  time:35.005, tt:2520.353\n",
      "Ep:72, loss:0.00001, loss_test:0.01380, lr:4.86e-02, fs:0.72632 (r=0.697,p=0.758),  time:35.038, tt:2557.805\n",
      "Ep:73, loss:0.00001, loss_test:0.01365, lr:4.81e-02, fs:0.73016 (r=0.697,p=0.767),  time:35.050, tt:2593.672\n",
      "Ep:74, loss:0.00001, loss_test:0.01390, lr:4.76e-02, fs:0.72340 (r=0.687,p=0.764),  time:35.074, tt:2630.564\n",
      "Ep:75, loss:0.00001, loss_test:0.01371, lr:4.71e-02, fs:0.73684 (r=0.707,p=0.769),  time:35.108, tt:2668.192\n",
      "Ep:76, loss:0.00001, loss_test:0.01426, lr:4.67e-02, fs:0.72131 (r=0.667,p=0.786),  time:35.116, tt:2703.939\n",
      "Ep:77, loss:0.00001, loss_test:0.01373, lr:4.62e-02, fs:0.73298 (r=0.707,p=0.761),  time:35.134, tt:2740.420\n",
      "Ep:78, loss:0.00001, loss_test:0.01431, lr:4.57e-02, fs:0.73224 (r=0.677,p=0.798),  time:35.149, tt:2776.768\n",
      "Ep:79, loss:0.00001, loss_test:0.01385, lr:4.53e-02, fs:0.74468 (r=0.707,p=0.787),  time:35.137, tt:2810.975\n",
      "Ep:80, loss:0.00001, loss_test:0.01443, lr:4.48e-02, fs:0.72131 (r=0.667,p=0.786),  time:35.139, tt:2846.290\n",
      "Ep:81, loss:0.00001, loss_test:0.01404, lr:4.44e-02, fs:0.74866 (r=0.707,p=0.795),  time:35.141, tt:2881.549\n",
      "Ep:82, loss:0.00001, loss_test:0.01455, lr:4.39e-02, fs:0.72527 (r=0.667,p=0.795),  time:35.155, tt:2917.828\n",
      "Ep:83, loss:0.00001, loss_test:0.01401, lr:4.35e-02, fs:0.73514 (r=0.687,p=0.791),  time:35.131, tt:2951.039\n",
      "Ep:84, loss:0.00001, loss_test:0.01481, lr:4.31e-02, fs:0.73333 (r=0.667,p=0.815),  time:35.122, tt:2985.410\n",
      "Ep:85, loss:0.00001, loss_test:0.01393, lr:4.26e-02, fs:0.74866 (r=0.707,p=0.795),  time:35.112, tt:3019.596\n",
      "Ep:86, loss:0.00001, loss_test:0.01534, lr:4.22e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.107, tt:3054.319\n",
      "Ep:87, loss:0.00001, loss_test:0.01391, lr:4.18e-02, fs:0.74866 (r=0.707,p=0.795),  time:35.114, tt:3090.063\n",
      "Ep:88, loss:0.00001, loss_test:0.01534, lr:4.14e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.127, tt:3126.269\n",
      "Ep:89, loss:0.00001, loss_test:0.01418, lr:4.10e-02, fs:0.73514 (r=0.687,p=0.791),  time:35.137, tt:3162.296\n",
      "Ep:90, loss:0.00001, loss_test:0.01547, lr:4.05e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.157, tt:3199.333\n",
      "Ep:91, loss:0.00001, loss_test:0.01420, lr:4.01e-02, fs:0.75269 (r=0.707,p=0.805),  time:35.165, tt:3235.163\n",
      "Ep:92, loss:0.00001, loss_test:0.01562, lr:3.97e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.173, tt:3271.050\n",
      "Ep:93, loss:0.00001, loss_test:0.01438, lr:3.93e-02, fs:0.73626 (r=0.677,p=0.807),  time:35.186, tt:3307.510\n",
      "Ep:94, loss:0.00001, loss_test:0.01530, lr:3.89e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.185, tt:3342.570\n",
      "Ep:95, loss:0.00001, loss_test:0.01487, lr:3.86e-02, fs:0.73333 (r=0.667,p=0.815),  time:35.174, tt:3376.694\n",
      "Ep:96, loss:0.00001, loss_test:0.01523, lr:3.82e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.176, tt:3412.070\n",
      "Ep:97, loss:0.00001, loss_test:0.01535, lr:3.78e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.175, tt:3447.108\n",
      "Ep:98, loss:0.00001, loss_test:0.01525, lr:3.74e-02, fs:0.74860 (r=0.677,p=0.838),  time:35.180, tt:3482.780\n",
      "Ep:99, loss:0.00001, loss_test:0.01543, lr:3.70e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.177, tt:3517.679\n",
      "Ep:100, loss:0.00001, loss_test:0.01510, lr:3.67e-02, fs:0.74860 (r=0.677,p=0.838),  time:35.185, tt:3553.706\n",
      "Ep:101, loss:0.00001, loss_test:0.01595, lr:3.63e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.188, tt:3589.128\n",
      "Ep:102, loss:0.00001, loss_test:0.01517, lr:3.59e-02, fs:0.74860 (r=0.677,p=0.838),  time:35.187, tt:3624.299\n",
      "Ep:103, loss:0.00001, loss_test:0.01600, lr:3.56e-02, fs:0.73743 (r=0.667,p=0.825),  time:35.198, tt:3660.630\n",
      "Ep:104, loss:0.00001, loss_test:0.01556, lr:3.52e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.199, tt:3695.878\n",
      "Ep:105, loss:0.00001, loss_test:0.01608, lr:3.49e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.220, tt:3733.350\n",
      "Ep:106, loss:0.00001, loss_test:0.01595, lr:3.45e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.231, tt:3769.669\n",
      "Ep:107, loss:0.00001, loss_test:0.01583, lr:3.42e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.227, tt:3804.505\n",
      "Ep:108, loss:0.00001, loss_test:0.01639, lr:3.38e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.237, tt:3840.871\n",
      "Ep:109, loss:0.00001, loss_test:0.01593, lr:3.35e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.258, tt:3878.419\n",
      "Ep:110, loss:0.00001, loss_test:0.01628, lr:3.32e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.252, tt:3912.925\n",
      "Ep:111, loss:0.00001, loss_test:0.01619, lr:3.28e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.249, tt:3947.865\n",
      "Ep:112, loss:0.00001, loss_test:0.01622, lr:3.25e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.245, tt:3982.638\n",
      "Ep:113, loss:0.00001, loss_test:0.01653, lr:3.22e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.244, tt:4017.777\n",
      "Ep:114, loss:0.00000, loss_test:0.01640, lr:3.19e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.245, tt:4053.196\n",
      "Ep:115, loss:0.00000, loss_test:0.01664, lr:3.15e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.242, tt:4088.023\n",
      "Ep:116, loss:0.00000, loss_test:0.01660, lr:3.12e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.234, tt:4122.329\n",
      "Ep:117, loss:0.00000, loss_test:0.01658, lr:3.09e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.214, tt:4155.193\n",
      "Ep:118, loss:0.00000, loss_test:0.01703, lr:3.06e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.208, tt:4189.784\n",
      "Ep:119, loss:0.00000, loss_test:0.01663, lr:3.03e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.201, tt:4224.112\n",
      "Ep:120, loss:0.00000, loss_test:0.01721, lr:3.00e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.202, tt:4259.483\n",
      "Ep:121, loss:0.00000, loss_test:0.01654, lr:2.97e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.193, tt:4293.497\n",
      "Ep:122, loss:0.00000, loss_test:0.01743, lr:2.94e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.178, tt:4326.852\n",
      "Ep:123, loss:0.00000, loss_test:0.01673, lr:2.91e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.170, tt:4361.075\n",
      "Ep:124, loss:0.00000, loss_test:0.01753, lr:2.88e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.163, tt:4395.401\n",
      "Ep:125, loss:0.00000, loss_test:0.01674, lr:2.85e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.156, tt:4429.686\n",
      "Ep:126, loss:0.00000, loss_test:0.01764, lr:2.82e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.158, tt:4465.049\n",
      "Ep:127, loss:0.00000, loss_test:0.01693, lr:2.80e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.162, tt:4500.697\n",
      "Ep:128, loss:0.00000, loss_test:0.01780, lr:2.77e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.161, tt:4535.713\n",
      "Ep:129, loss:0.00000, loss_test:0.01713, lr:2.74e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.163, tt:4571.207\n",
      "Ep:130, loss:0.00000, loss_test:0.01798, lr:2.71e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.158, tt:4605.702\n",
      "Ep:131, loss:0.00000, loss_test:0.01727, lr:2.69e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.160, tt:4641.173\n",
      "Ep:132, loss:0.00000, loss_test:0.01803, lr:2.66e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.162, tt:4676.517\n",
      "Ep:133, loss:0.00000, loss_test:0.01727, lr:2.63e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.164, tt:4711.912\n",
      "Ep:134, loss:0.00000, loss_test:0.01814, lr:2.61e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.159, tt:4746.403\n",
      "Ep:135, loss:0.00000, loss_test:0.01740, lr:2.58e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.169, tt:4782.993\n",
      "Ep:136, loss:0.00000, loss_test:0.01813, lr:2.55e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.171, tt:4818.432\n",
      "Ep:137, loss:0.00000, loss_test:0.01751, lr:2.53e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.173, tt:4853.843\n",
      "Ep:138, loss:0.00000, loss_test:0.01816, lr:2.50e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.169, tt:4888.498\n",
      "Ep:139, loss:0.00000, loss_test:0.01785, lr:2.48e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.171, tt:4923.932\n",
      "Ep:140, loss:0.00000, loss_test:0.01801, lr:2.45e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.161, tt:4957.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00000, loss_test:0.01823, lr:2.43e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.158, tt:4992.381\n",
      "Ep:142, loss:0.00000, loss_test:0.01800, lr:2.40e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.151, tt:5026.564\n",
      "Ep:143, loss:0.00000, loss_test:0.01825, lr:2.38e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.161, tt:5063.223\n",
      "Ep:144, loss:0.00000, loss_test:0.01830, lr:2.36e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.166, tt:5099.050\n",
      "Ep:145, loss:0.00000, loss_test:0.01822, lr:2.33e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.154, tt:5132.557\n",
      "Ep:146, loss:0.00000, loss_test:0.01857, lr:2.31e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.147, tt:5166.552\n",
      "Ep:147, loss:0.00000, loss_test:0.01821, lr:2.29e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.147, tt:5201.743\n",
      "Ep:148, loss:0.00000, loss_test:0.01868, lr:2.26e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.146, tt:5236.750\n",
      "Ep:149, loss:0.00000, loss_test:0.01833, lr:2.24e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.140, tt:5270.929\n",
      "Ep:150, loss:0.00000, loss_test:0.01872, lr:2.22e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.139, tt:5306.019\n",
      "Ep:151, loss:0.00000, loss_test:0.01848, lr:2.20e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.137, tt:5340.791\n",
      "Ep:152, loss:0.00000, loss_test:0.01858, lr:2.17e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.129, tt:5374.771\n",
      "Ep:153, loss:0.00000, loss_test:0.01865, lr:2.15e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.120, tt:5408.411\n",
      "Ep:154, loss:0.00000, loss_test:0.01878, lr:2.13e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.111, tt:5442.234\n",
      "Ep:155, loss:0.00000, loss_test:0.01872, lr:2.11e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.106, tt:5476.506\n",
      "Ep:156, loss:0.00000, loss_test:0.01887, lr:2.09e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.094, tt:5509.791\n",
      "Ep:157, loss:0.00000, loss_test:0.01878, lr:2.07e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.087, tt:5543.770\n",
      "Ep:158, loss:0.00000, loss_test:0.01893, lr:2.05e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.084, tt:5578.350\n",
      "Ep:159, loss:0.00000, loss_test:0.01894, lr:2.03e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.074, tt:5611.852\n",
      "Ep:160, loss:0.00000, loss_test:0.01907, lr:2.01e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.074, tt:5646.839\n",
      "Ep:161, loss:0.00000, loss_test:0.01909, lr:1.99e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.072, tt:5681.638\n",
      "Ep:162, loss:0.00000, loss_test:0.01907, lr:1.97e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.088, tt:5719.355\n",
      "Ep:163, loss:0.00000, loss_test:0.01914, lr:1.95e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.099, tt:5756.251\n",
      "Ep:164, loss:0.00000, loss_test:0.01915, lr:1.93e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.102, tt:5791.851\n",
      "Ep:165, loss:0.00000, loss_test:0.01927, lr:1.91e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.099, tt:5826.477\n",
      "Ep:166, loss:0.00000, loss_test:0.01922, lr:1.89e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.113, tt:5863.945\n",
      "Ep:167, loss:0.00000, loss_test:0.01932, lr:1.87e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.119, tt:5899.995\n",
      "Ep:168, loss:0.00000, loss_test:0.01926, lr:1.85e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.115, tt:5934.384\n",
      "Ep:169, loss:0.00000, loss_test:0.01928, lr:1.83e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.111, tt:5968.818\n",
      "Ep:170, loss:0.00000, loss_test:0.01939, lr:1.81e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.109, tt:6003.590\n",
      "Ep:171, loss:0.00000, loss_test:0.01938, lr:1.80e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.100, tt:6037.181\n",
      "Ep:172, loss:0.00000, loss_test:0.01952, lr:1.78e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.096, tt:6071.676\n",
      "Ep:173, loss:0.00000, loss_test:0.01940, lr:1.76e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.094, tt:6106.375\n",
      "Ep:174, loss:0.00000, loss_test:0.01958, lr:1.74e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.106, tt:6143.583\n",
      "Ep:175, loss:0.00000, loss_test:0.01946, lr:1.73e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.100, tt:6177.634\n",
      "Ep:176, loss:0.00000, loss_test:0.01971, lr:1.71e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.103, tt:6213.157\n",
      "Ep:177, loss:0.00000, loss_test:0.01951, lr:1.69e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.101, tt:6247.962\n",
      "Ep:178, loss:0.00000, loss_test:0.01964, lr:1.67e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.103, tt:6283.518\n",
      "Ep:179, loss:0.00000, loss_test:0.01979, lr:1.66e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.111, tt:6320.001\n",
      "Ep:180, loss:0.00000, loss_test:0.01953, lr:1.64e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.110, tt:6354.836\n",
      "Ep:181, loss:0.00000, loss_test:0.01987, lr:1.62e-02, fs:0.75429 (r=0.667,p=0.868),  time:35.109, tt:6389.856\n",
      "Ep:182, loss:0.00000, loss_test:0.01970, lr:1.61e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.112, tt:6425.442\n",
      "Ep:183, loss:0.00000, loss_test:0.01986, lr:1.59e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.120, tt:6462.061\n",
      "Ep:184, loss:0.00000, loss_test:0.01984, lr:1.58e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.111, tt:6495.484\n",
      "Ep:185, loss:0.00000, loss_test:0.01989, lr:1.56e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.113, tt:6530.943\n",
      "Ep:186, loss:0.00000, loss_test:0.01989, lr:1.54e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.110, tt:6565.558\n",
      "Ep:187, loss:0.00000, loss_test:0.01991, lr:1.53e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.111, tt:6600.945\n",
      "Ep:188, loss:0.00000, loss_test:0.02007, lr:1.51e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.115, tt:6636.687\n",
      "Ep:189, loss:0.00000, loss_test:0.01989, lr:1.50e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.115, tt:6671.847\n",
      "Ep:190, loss:0.00000, loss_test:0.02005, lr:1.48e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.126, tt:6709.025\n",
      "Ep:191, loss:0.00000, loss_test:0.02010, lr:1.47e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.133, tt:6745.580\n",
      "Ep:192, loss:0.00000, loss_test:0.02006, lr:1.45e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.135, tt:6781.055\n",
      "Ep:193, loss:0.00000, loss_test:0.02012, lr:1.44e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.133, tt:6815.829\n",
      "Ep:194, loss:0.00000, loss_test:0.02018, lr:1.43e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.136, tt:6851.509\n",
      "Ep:195, loss:0.00000, loss_test:0.02014, lr:1.41e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.131, tt:6885.725\n",
      "Ep:196, loss:0.00000, loss_test:0.02027, lr:1.40e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.131, tt:6920.859\n",
      "Ep:197, loss:0.00000, loss_test:0.02015, lr:1.38e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.129, tt:6955.475\n",
      "Ep:198, loss:0.00000, loss_test:0.02026, lr:1.37e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.130, tt:6990.842\n",
      "Ep:199, loss:0.00000, loss_test:0.02033, lr:1.36e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.128, tt:7025.508\n",
      "Ep:200, loss:0.00000, loss_test:0.02026, lr:1.34e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.128, tt:7060.644\n",
      "Ep:201, loss:0.00000, loss_test:0.02040, lr:1.33e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.125, tt:7095.159\n",
      "Ep:202, loss:0.00000, loss_test:0.02036, lr:1.32e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.124, tt:7130.194\n",
      "Ep:203, loss:0.00000, loss_test:0.02044, lr:1.30e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.130, tt:7166.512\n",
      "Ep:204, loss:0.00000, loss_test:0.02046, lr:1.29e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.135, tt:7202.683\n",
      "Ep:205, loss:0.00000, loss_test:0.02043, lr:1.28e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.127, tt:7236.142\n",
      "Ep:206, loss:0.00000, loss_test:0.02054, lr:1.26e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.135, tt:7272.974\n",
      "Ep:207, loss:0.00000, loss_test:0.02051, lr:1.25e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.117, tt:7304.421\n",
      "Ep:208, loss:0.00000, loss_test:0.02048, lr:1.24e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.111, tt:7338.136\n",
      "Ep:209, loss:0.00000, loss_test:0.02058, lr:1.23e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.110, tt:7373.182\n",
      "Ep:210, loss:0.00000, loss_test:0.02051, lr:1.21e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.099, tt:7405.977\n",
      "Ep:211, loss:0.00000, loss_test:0.02063, lr:1.20e-02, fs:0.75862 (r=0.667,p=0.880),  time:35.080, tt:7436.863\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14227, lr:1.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:31.393, tt:31.393\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14041, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:34.185, tt:68.370\n",
      "Ep:2, loss:0.00027, loss_test:0.13839, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:35.364, tt:106.093\n",
      "Ep:3, loss:0.00026, loss_test:0.13600, lr:1.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:35.600, tt:142.400\n",
      "Ep:4, loss:0.00026, loss_test:0.13297, lr:1.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:35.564, tt:177.822\n",
      "Ep:5, loss:0.00025, loss_test:0.12972, lr:1.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:35.213, tt:211.278\n",
      "Ep:6, loss:0.00025, loss_test:0.12670, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:35.085, tt:245.598\n",
      "Ep:7, loss:0.00024, loss_test:0.12445, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:35.306, tt:282.444\n",
      "Ep:8, loss:0.00024, loss_test:0.12329, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:35.471, tt:319.243\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.12102, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:35.504, tt:355.045\n",
      "Ep:10, loss:0.00023, loss_test:0.11920, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:35.437, tt:389.806\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.11714, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:35.539, tt:426.470\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11620, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:35.896, tt:466.643\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.11476, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:35.807, tt:501.304\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.11213, lr:1.00e-02, fs:0.67257 (r=0.768,p=0.598),  time:35.892, tt:538.373\n",
      "Ep:15, loss:0.00020, loss_test:0.11106, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:35.986, tt:575.769\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10881, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:35.984, tt:611.723\n",
      "Ep:17, loss:0.00019, loss_test:0.10711, lr:1.00e-02, fs:0.69333 (r=0.788,p=0.619),  time:35.983, tt:647.700\n",
      "Ep:18, loss:0.00018, loss_test:0.10489, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:36.024, tt:684.456\n",
      "Ep:19, loss:0.00018, loss_test:0.10105, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:36.082, tt:721.647\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.10061, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:36.107, tt:758.239\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.09852, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:36.092, tt:794.035\n",
      "Ep:22, loss:0.00017, loss_test:0.09565, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:36.130, tt:830.984\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09577, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:36.191, tt:868.583\n",
      "Ep:24, loss:0.00016, loss_test:0.09250, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:36.227, tt:905.666\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09157, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:36.203, tt:941.290\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08825, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:36.256, tt:978.900\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.08840, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:36.242, tt:1014.783\n",
      "Ep:28, loss:0.00014, loss_test:0.08500, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:36.226, tt:1050.567\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.08590, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:36.260, tt:1087.795\n",
      "Ep:30, loss:0.00013, loss_test:0.08488, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:36.321, tt:1125.938\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08299, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:36.379, tt:1164.139\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08275, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:36.379, tt:1200.522\n",
      "Ep:33, loss:0.00012, loss_test:0.08189, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:36.392, tt:1237.313\n",
      "Ep:34, loss:0.00012, loss_test:0.08112, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:36.406, tt:1274.193\n",
      "Ep:35, loss:0.00012, loss_test:0.07781, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:36.415, tt:1310.951\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07945, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:36.375, tt:1345.859\n",
      "Ep:37, loss:0.00011, loss_test:0.07633, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:36.381, tt:1382.466\n",
      "Ep:38, loss:0.00011, loss_test:0.07528, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:36.388, tt:1419.114\n",
      "Ep:39, loss:0.00010, loss_test:0.07600, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:36.361, tt:1454.433\n",
      "Ep:40, loss:0.00010, loss_test:0.07343, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.305, tt:1488.489\n",
      "Ep:41, loss:0.00009, loss_test:0.07424, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.282, tt:1523.853\n",
      "Ep:42, loss:0.00009, loss_test:0.07184, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:36.285, tt:1560.237\n",
      "Ep:43, loss:0.00009, loss_test:0.07355, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:36.290, tt:1596.745\n",
      "Ep:44, loss:0.00009, loss_test:0.06921, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:36.320, tt:1634.396\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.07450, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.339, tt:1671.595\n",
      "Ep:46, loss:0.00008, loss_test:0.06912, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:36.322, tt:1707.140\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07197, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.312, tt:1742.991\n",
      "Ep:48, loss:0.00008, loss_test:0.06849, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:36.321, tt:1779.709\n",
      "Ep:49, loss:0.00008, loss_test:0.06834, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.320, tt:1815.988\n",
      "Ep:50, loss:0.00007, loss_test:0.06800, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.328, tt:1852.707\n",
      "Ep:51, loss:0.00007, loss_test:0.06650, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:36.338, tt:1889.582\n",
      "Ep:52, loss:0.00007, loss_test:0.06802, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:36.342, tt:1926.137\n",
      "Ep:53, loss:0.00007, loss_test:0.06620, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:36.293, tt:1959.808\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.06776, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:36.298, tt:1996.382\n",
      "Ep:55, loss:0.00006, loss_test:0.06602, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:36.301, tt:2032.854\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.06996, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.310, tt:2069.681\n",
      "Ep:57, loss:0.00006, loss_test:0.06971, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:36.331, tt:2107.201\n",
      "Ep:58, loss:0.00008, loss_test:0.07993, lr:1.00e-02, fs:0.74286 (r=0.657,p=0.855),  time:36.333, tt:2143.648\n",
      "Ep:59, loss:0.00008, loss_test:0.06794, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:36.331, tt:2179.879\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00007, loss_test:0.07903, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:36.340, tt:2216.710\n",
      "Ep:61, loss:0.00007, loss_test:0.06651, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:36.338, tt:2252.964\n",
      "Ep:62, loss:0.00006, loss_test:0.06988, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:36.354, tt:2290.292\n",
      "Ep:63, loss:0.00006, loss_test:0.06636, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:36.350, tt:2326.422\n",
      "Ep:64, loss:0.00006, loss_test:0.06792, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:36.352, tt:2362.905\n",
      "Ep:65, loss:0.00006, loss_test:0.06345, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:36.368, tt:2400.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00005, loss_test:0.06776, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:36.375, tt:2437.106\n",
      "Ep:67, loss:0.00005, loss_test:0.06395, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:36.393, tt:2474.757\n",
      "Ep:68, loss:0.00005, loss_test:0.06796, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.408, tt:2512.156\n",
      "Ep:69, loss:0.00005, loss_test:0.06877, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:36.404, tt:2548.287\n",
      "Ep:70, loss:0.00005, loss_test:0.06388, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:36.397, tt:2584.186\n",
      "Ep:71, loss:0.00005, loss_test:0.06887, lr:9.90e-03, fs:0.81967 (r=0.758,p=0.893),  time:36.393, tt:2620.265\n",
      "Ep:72, loss:0.00004, loss_test:0.06176, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:36.392, tt:2656.620\n",
      "Ep:73, loss:0.00004, loss_test:0.06927, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:36.364, tt:2690.971\n",
      "Ep:74, loss:0.00004, loss_test:0.06354, lr:9.61e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.351, tt:2726.310\n",
      "Ep:75, loss:0.00004, loss_test:0.06694, lr:9.51e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.364, tt:2763.652\n",
      "Ep:76, loss:0.00004, loss_test:0.06665, lr:9.41e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.371, tt:2800.573\n",
      "Ep:77, loss:0.00004, loss_test:0.06786, lr:9.32e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.379, tt:2837.567\n",
      "Ep:78, loss:0.00004, loss_test:0.06620, lr:9.23e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.377, tt:2873.810\n",
      "Ep:79, loss:0.00004, loss_test:0.06793, lr:9.14e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.378, tt:2910.241\n",
      "Ep:80, loss:0.00004, loss_test:0.06814, lr:9.04e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.371, tt:2946.044\n",
      "Ep:81, loss:0.00004, loss_test:0.06512, lr:8.95e-03, fs:0.81111 (r=0.737,p=0.901),  time:36.373, tt:2982.603\n",
      "Ep:82, loss:0.00004, loss_test:0.06964, lr:8.86e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.361, tt:3018.001\n",
      "Ep:83, loss:0.00004, loss_test:0.06377, lr:8.78e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.371, tt:3055.156\n",
      "Ep:84, loss:0.00003, loss_test:0.07139, lr:8.69e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.369, tt:3091.377\n",
      "Ep:85, loss:0.00003, loss_test:0.06320, lr:8.60e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.362, tt:3127.108\n",
      "Ep:86, loss:0.00003, loss_test:0.06785, lr:8.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.319, tt:3159.742\n",
      "Ep:87, loss:0.00003, loss_test:0.06642, lr:8.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.283, tt:3192.877\n",
      "Ep:88, loss:0.00003, loss_test:0.06819, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:36.248, tt:3226.034\n",
      "Ep:89, loss:0.00003, loss_test:0.06687, lr:8.26e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.238, tt:3261.425\n",
      "Ep:90, loss:0.00003, loss_test:0.06694, lr:8.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.226, tt:3296.576\n",
      "Ep:91, loss:0.00003, loss_test:0.06864, lr:8.10e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.199, tt:3330.267\n",
      "Ep:92, loss:0.00003, loss_test:0.06567, lr:8.02e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.208, tt:3367.350\n",
      "Ep:93, loss:0.00003, loss_test:0.06774, lr:7.94e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.193, tt:3402.101\n",
      "Ep:94, loss:0.00003, loss_test:0.06748, lr:7.86e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.186, tt:3437.653\n",
      "Ep:95, loss:0.00003, loss_test:0.06661, lr:7.78e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.175, tt:3472.836\n",
      "Ep:96, loss:0.00003, loss_test:0.06830, lr:7.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.145, tt:3506.019\n",
      "Ep:97, loss:0.00003, loss_test:0.06767, lr:7.62e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.116, tt:3539.370\n",
      "Ep:98, loss:0.00002, loss_test:0.06646, lr:7.55e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.124, tt:3576.276\n",
      "Ep:99, loss:0.00002, loss_test:0.06728, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.149, tt:3614.875\n",
      "Ep:100, loss:0.00002, loss_test:0.06759, lr:7.40e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.132, tt:3649.350\n",
      "Ep:101, loss:0.00002, loss_test:0.06557, lr:7.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.144, tt:3686.667\n",
      "Ep:102, loss:0.00002, loss_test:0.07087, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.143, tt:3722.714\n",
      "Ep:103, loss:0.00002, loss_test:0.06464, lr:7.18e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.154, tt:3760.044\n",
      "Ep:104, loss:0.00002, loss_test:0.06920, lr:7.11e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.147, tt:3795.468\n",
      "Ep:105, loss:0.00002, loss_test:0.06755, lr:7.03e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.138, tt:3830.664\n",
      "Ep:106, loss:0.00002, loss_test:0.06899, lr:6.96e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.127, tt:3865.583\n",
      "Ep:107, loss:0.00002, loss_test:0.06676, lr:6.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.126, tt:3901.601\n",
      "Ep:108, loss:0.00002, loss_test:0.06802, lr:6.83e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.115, tt:3936.569\n",
      "Ep:109, loss:0.00002, loss_test:0.06758, lr:6.76e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.139, tt:3975.285\n",
      "Ep:110, loss:0.00002, loss_test:0.06885, lr:6.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.141, tt:4011.656\n",
      "Ep:111, loss:0.00002, loss_test:0.06808, lr:6.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.119, tt:4045.299\n",
      "Ep:112, loss:0.00002, loss_test:0.06857, lr:6.56e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.114, tt:4080.877\n",
      "Ep:113, loss:0.00002, loss_test:0.06763, lr:6.49e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.095, tt:4114.838\n",
      "Ep:114, loss:0.00002, loss_test:0.06863, lr:6.43e-03, fs:0.83060 (r=0.768,p=0.905),  time:36.084, tt:4149.629\n",
      "Ep:115, loss:0.00002, loss_test:0.06664, lr:6.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.082, tt:4185.492\n",
      "Ep:116, loss:0.00002, loss_test:0.06984, lr:6.30e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.045, tt:4217.287\n",
      "Ep:117, loss:0.00002, loss_test:0.06640, lr:6.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.028, tt:4251.262\n",
      "Ep:118, loss:0.00002, loss_test:0.06809, lr:6.17e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.024, tt:4286.898\n",
      "Ep:119, loss:0.00002, loss_test:0.06657, lr:6.11e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.014, tt:4321.657\n",
      "Ep:120, loss:0.00002, loss_test:0.06851, lr:6.05e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.010, tt:4357.175\n",
      "Ep:121, loss:0.00002, loss_test:0.06986, lr:5.99e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.997, tt:4391.606\n",
      "Ep:122, loss:0.00002, loss_test:0.06750, lr:5.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.981, tt:4425.673\n",
      "Ep:123, loss:0.00002, loss_test:0.06778, lr:5.87e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.977, tt:4461.097\n",
      "Ep:124, loss:0.00002, loss_test:0.06805, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.991, tt:4498.883\n",
      "Ep:125, loss:0.00002, loss_test:0.06900, lr:5.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.993, tt:4535.099\n",
      "Ep:126, loss:0.00002, loss_test:0.06806, lr:5.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.988, tt:4570.486\n",
      "Ep:127, loss:0.00002, loss_test:0.06798, lr:5.64e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.983, tt:4605.853\n",
      "Ep:128, loss:0.00002, loss_test:0.06855, lr:5.58e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.979, tt:4641.277\n",
      "Ep:129, loss:0.00002, loss_test:0.06793, lr:5.53e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.974, tt:4676.611\n",
      "Ep:130, loss:0.00002, loss_test:0.06892, lr:5.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.968, tt:4711.823\n",
      "Ep:131, loss:0.00002, loss_test:0.06767, lr:5.42e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.954, tt:4745.912\n",
      "Ep:132, loss:0.00001, loss_test:0.06781, lr:5.36e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.949, tt:4781.167\n",
      "Ep:133, loss:0.00001, loss_test:0.07033, lr:5.31e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.946, tt:4816.802\n",
      "Ep:134, loss:0.00001, loss_test:0.06585, lr:5.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.940, tt:4851.899\n",
      "Ep:135, loss:0.00001, loss_test:0.07047, lr:5.20e-03, fs:0.83516 (r=0.768,p=0.916),  time:35.926, tt:4885.886\n",
      "Ep:136, loss:0.00001, loss_test:0.06800, lr:5.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.922, tt:4921.306\n",
      "Ep:137, loss:0.00001, loss_test:0.06918, lr:5.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.907, tt:4955.116\n",
      "Ep:138, loss:0.00001, loss_test:0.06701, lr:5.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.891, tt:4988.785\n",
      "Ep:139, loss:0.00001, loss_test:0.06827, lr:5.00e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.883, tt:5023.608\n",
      "Ep:140, loss:0.00001, loss_test:0.06865, lr:4.95e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.883, tt:5059.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.06737, lr:4.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.886, tt:5095.832\n",
      "Ep:142, loss:0.00001, loss_test:0.06985, lr:4.85e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.870, tt:5129.391\n",
      "Ep:143, loss:0.00001, loss_test:0.06690, lr:4.80e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.858, tt:5163.531\n",
      "Ep:144, loss:0.00001, loss_test:0.06890, lr:4.75e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.860, tt:5199.699\n",
      "Ep:145, loss:0.00001, loss_test:0.06967, lr:4.71e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.848, tt:5233.842\n",
      "Ep:146, loss:0.00001, loss_test:0.06670, lr:4.66e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.873, tt:5273.298\n",
      "Ep:147, loss:0.00001, loss_test:0.06863, lr:4.61e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.867, tt:5308.374\n",
      "Ep:148, loss:0.00001, loss_test:0.06872, lr:4.57e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.860, tt:5343.148\n",
      "Ep:149, loss:0.00001, loss_test:0.06831, lr:4.52e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.850, tt:5377.563\n",
      "Ep:150, loss:0.00001, loss_test:0.06964, lr:4.48e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.842, tt:5412.123\n",
      "Ep:151, loss:0.00001, loss_test:0.06855, lr:4.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.831, tt:5446.318\n",
      "Ep:152, loss:0.00001, loss_test:0.06748, lr:4.39e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.815, tt:5479.653\n",
      "Ep:153, loss:0.00001, loss_test:0.06973, lr:4.34e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.811, tt:5514.916\n",
      "Ep:154, loss:0.00001, loss_test:0.06855, lr:4.30e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.809, tt:5550.363\n",
      "Ep:155, loss:0.00001, loss_test:0.06906, lr:4.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.820, tt:5587.887\n",
      "Ep:156, loss:0.00001, loss_test:0.06891, lr:4.21e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.826, tt:5624.623\n",
      "Ep:157, loss:0.00001, loss_test:0.06887, lr:4.17e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.825, tt:5660.307\n",
      "Ep:158, loss:0.00001, loss_test:0.06879, lr:4.13e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.822, tt:5695.742\n",
      "Ep:159, loss:0.00001, loss_test:0.06968, lr:4.09e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.835, tt:5733.656\n",
      "Ep:160, loss:0.00001, loss_test:0.06771, lr:4.05e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.845, tt:5770.967\n",
      "Ep:161, loss:0.00001, loss_test:0.07033, lr:4.01e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.844, tt:5806.690\n",
      "Ep:162, loss:0.00001, loss_test:0.06783, lr:3.97e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.855, tt:5844.360\n",
      "Ep:163, loss:0.00001, loss_test:0.07009, lr:3.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.868, tt:5882.400\n",
      "Ep:164, loss:0.00001, loss_test:0.06947, lr:3.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.896, tt:5922.847\n",
      "Ep:165, loss:0.00001, loss_test:0.06754, lr:3.85e-03, fs:0.84270 (r=0.758,p=0.949),  time:35.892, tt:5958.099\n",
      "Ep:166, loss:0.00001, loss_test:0.06887, lr:3.81e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.899, tt:5995.055\n",
      "Ep:167, loss:0.00001, loss_test:0.06857, lr:3.77e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.896, tt:6030.519\n",
      "Ep:168, loss:0.00001, loss_test:0.06872, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.892, tt:6065.751\n",
      "Ep:169, loss:0.00001, loss_test:0.06965, lr:3.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.892, tt:6101.677\n",
      "Ep:170, loss:0.00001, loss_test:0.06852, lr:3.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.892, tt:6137.557\n",
      "Ep:171, loss:0.00001, loss_test:0.06976, lr:3.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.895, tt:6173.993\n",
      "Ep:172, loss:0.00001, loss_test:0.06925, lr:3.59e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.895, tt:6209.772\n",
      "Ep:173, loss:0.00001, loss_test:0.06817, lr:3.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.892, tt:6245.223\n",
      "Ep:174, loss:0.00001, loss_test:0.07028, lr:3.52e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.882, tt:6279.415\n",
      "Ep:175, loss:0.00001, loss_test:0.06880, lr:3.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.879, tt:6314.693\n",
      "Ep:176, loss:0.00001, loss_test:0.06797, lr:3.45e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.879, tt:6350.610\n",
      "Ep:177, loss:0.00001, loss_test:0.06993, lr:3.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.886, tt:6387.778\n",
      "Ep:178, loss:0.00001, loss_test:0.06908, lr:3.38e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.883, tt:6423.114\n",
      "Ep:179, loss:0.00001, loss_test:0.06857, lr:3.34e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.888, tt:6459.888\n",
      "Ep:180, loss:0.00001, loss_test:0.07052, lr:3.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.891, tt:6496.359\n",
      "Ep:181, loss:0.00001, loss_test:0.06912, lr:3.28e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.894, tt:6532.672\n",
      "Ep:182, loss:0.00001, loss_test:0.06895, lr:3.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.896, tt:6568.940\n",
      "Ep:183, loss:0.00001, loss_test:0.06969, lr:3.21e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.897, tt:6605.123\n",
      "Ep:184, loss:0.00001, loss_test:0.06861, lr:3.18e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.902, tt:6641.818\n",
      "Ep:185, loss:0.00001, loss_test:0.06848, lr:3.15e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.898, tt:6677.004\n",
      "Ep:186, loss:0.00001, loss_test:0.06890, lr:3.12e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.905, tt:6714.182\n",
      "Ep:187, loss:0.00001, loss_test:0.06943, lr:3.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.906, tt:6750.335\n",
      "Ep:188, loss:0.00001, loss_test:0.06969, lr:3.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.899, tt:6784.845\n",
      "Ep:189, loss:0.00001, loss_test:0.06912, lr:3.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.910, tt:6822.932\n",
      "Ep:190, loss:0.00001, loss_test:0.06934, lr:2.99e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.907, tt:6858.224\n",
      "Ep:191, loss:0.00001, loss_test:0.06909, lr:2.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.902, tt:6893.198\n",
      "Ep:192, loss:0.00001, loss_test:0.06863, lr:2.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.916, tt:6931.730\n",
      "Ep:193, loss:0.00001, loss_test:0.06906, lr:2.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.924, tt:6969.220\n",
      "Ep:194, loss:0.00001, loss_test:0.06929, lr:2.88e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.921, tt:7004.657\n",
      "Ep:195, loss:0.00001, loss_test:0.06931, lr:2.85e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.930, tt:7042.303\n",
      "Ep:196, loss:0.00001, loss_test:0.06929, lr:2.82e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.936, tt:7079.474\n",
      "Ep:197, loss:0.00001, loss_test:0.06938, lr:2.79e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.941, tt:7116.232\n",
      "Ep:198, loss:0.00001, loss_test:0.06923, lr:2.76e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.933, tt:7150.628\n",
      "Ep:199, loss:0.00001, loss_test:0.06948, lr:2.73e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.930, tt:7186.051\n",
      "Ep:200, loss:0.00001, loss_test:0.06943, lr:2.71e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.929, tt:7221.677\n",
      "Ep:201, loss:0.00001, loss_test:0.06852, lr:2.68e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.936, tt:7259.101\n",
      "Ep:202, loss:0.00001, loss_test:0.06960, lr:2.65e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.943, tt:7296.392\n",
      "Ep:203, loss:0.00001, loss_test:0.07027, lr:2.63e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.933, tt:7330.287\n",
      "Ep:204, loss:0.00001, loss_test:0.06910, lr:2.60e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.940, tt:7367.771\n",
      "Ep:205, loss:0.00001, loss_test:0.06969, lr:2.57e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.946, tt:7404.917\n",
      "Ep:206, loss:0.00001, loss_test:0.07047, lr:2.55e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.948, tt:7441.213\n",
      "Ep:207, loss:0.00001, loss_test:0.06885, lr:2.52e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.941, tt:7475.737\n",
      "Ep:208, loss:0.00001, loss_test:0.06966, lr:2.50e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.918, tt:7506.899\n",
      "Ep:209, loss:0.00001, loss_test:0.07008, lr:2.47e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.909, tt:7540.801\n",
      "Ep:210, loss:0.00001, loss_test:0.06944, lr:2.45e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.901, tt:7575.087\n",
      "Ep:211, loss:0.00001, loss_test:0.06909, lr:2.42e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.891, tt:7608.849\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02389, lr:6.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:32.624, tt:32.624\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02357, lr:6.00e-02, fs:0.68056 (r=0.990,p=0.519),  time:33.634, tt:67.269\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02694, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.145, tt:102.434\n",
      "Ep:3, loss:0.00005, loss_test:0.02854, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.238, tt:136.953\n",
      "Ep:4, loss:0.00005, loss_test:0.02893, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.676, tt:168.380\n",
      "Ep:5, loss:0.00006, loss_test:0.02855, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.889, tt:197.337\n",
      "Ep:6, loss:0.00005, loss_test:0.02745, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.838, tt:229.864\n",
      "Ep:7, loss:0.00005, loss_test:0.02604, lr:6.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:33.140, tt:265.119\n",
      "Ep:8, loss:0.00005, loss_test:0.02452, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:33.508, tt:301.570\n",
      "Ep:9, loss:0.00005, loss_test:0.02349, lr:6.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:33.796, tt:337.962\n",
      "Ep:10, loss:0.00004, loss_test:0.02306, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:33.879, tt:372.671\n",
      "Ep:11, loss:0.00004, loss_test:0.02260, lr:6.00e-02, fs:0.64314 (r=0.828,p=0.526),  time:33.920, tt:407.042\n",
      "Ep:12, loss:0.00004, loss_test:0.02184, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:33.947, tt:441.308\n",
      "Ep:13, loss:0.00004, loss_test:0.02114, lr:5.94e-02, fs:0.65649 (r=0.869,p=0.528),  time:34.050, tt:476.703\n",
      "Ep:14, loss:0.00004, loss_test:0.02061, lr:5.88e-02, fs:0.66418 (r=0.899,p=0.527),  time:34.063, tt:510.951\n",
      "Ep:15, loss:0.00004, loss_test:0.02020, lr:5.82e-02, fs:0.67399 (r=0.929,p=0.529),  time:34.190, tt:547.046\n",
      "Ep:16, loss:0.00004, loss_test:0.01970, lr:5.76e-02, fs:0.67647 (r=0.929,p=0.532),  time:34.319, tt:583.429\n",
      "Ep:17, loss:0.00004, loss_test:0.01914, lr:5.71e-02, fs:0.68657 (r=0.929,p=0.544),  time:34.535, tt:621.624\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01862, lr:5.71e-02, fs:0.69962 (r=0.929,p=0.561),  time:34.597, tt:657.351\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01813, lr:5.71e-02, fs:0.71042 (r=0.929,p=0.575),  time:34.623, tt:692.452\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01774, lr:5.71e-02, fs:0.71595 (r=0.929,p=0.582),  time:34.675, tt:728.184\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01741, lr:5.71e-02, fs:0.72374 (r=0.939,p=0.589),  time:34.760, tt:764.729\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01708, lr:5.71e-02, fs:0.72374 (r=0.939,p=0.589),  time:34.803, tt:800.472\n",
      "Ep:23, loss:0.00003, loss_test:0.01677, lr:5.71e-02, fs:0.72093 (r=0.939,p=0.585),  time:34.803, tt:835.267\n",
      "Ep:24, loss:0.00003, loss_test:0.01642, lr:5.71e-02, fs:0.72656 (r=0.939,p=0.592),  time:34.853, tt:871.326\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01603, lr:5.71e-02, fs:0.72941 (r=0.939,p=0.596),  time:34.903, tt:907.483\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01569, lr:5.71e-02, fs:0.74699 (r=0.939,p=0.620),  time:34.906, tt:942.463\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01540, lr:5.71e-02, fs:0.75918 (r=0.939,p=0.637),  time:34.967, tt:979.064\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01513, lr:5.71e-02, fs:0.76230 (r=0.939,p=0.641),  time:34.973, tt:1014.225\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01489, lr:5.71e-02, fs:0.77311 (r=0.929,p=0.662),  time:35.061, tt:1051.834\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01467, lr:5.71e-02, fs:0.78151 (r=0.939,p=0.669),  time:35.070, tt:1087.183\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01446, lr:5.71e-02, fs:0.79149 (r=0.939,p=0.684),  time:35.074, tt:1122.363\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01427, lr:5.71e-02, fs:0.80519 (r=0.939,p=0.705),  time:35.091, tt:1157.994\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01411, lr:5.71e-02, fs:0.81223 (r=0.939,p=0.715),  time:35.133, tt:1194.519\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01398, lr:5.71e-02, fs:0.81416 (r=0.929,p=0.724),  time:35.159, tt:1230.572\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01387, lr:5.71e-02, fs:0.81778 (r=0.929,p=0.730),  time:35.133, tt:1264.775\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01376, lr:5.71e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.167, tt:1301.162\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01368, lr:5.71e-02, fs:0.81982 (r=0.919,p=0.740),  time:35.139, tt:1335.283\n",
      "Ep:38, loss:0.00002, loss_test:0.01363, lr:5.71e-02, fs:0.81982 (r=0.919,p=0.740),  time:35.161, tt:1371.278\n",
      "Ep:39, loss:0.00002, loss_test:0.01360, lr:5.71e-02, fs:0.83105 (r=0.919,p=0.758),  time:35.207, tt:1408.270\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01357, lr:5.71e-02, fs:0.82949 (r=0.909,p=0.763),  time:35.191, tt:1442.822\n",
      "Ep:41, loss:0.00002, loss_test:0.01355, lr:5.71e-02, fs:0.82629 (r=0.889,p=0.772),  time:35.226, tt:1479.493\n",
      "Ep:42, loss:0.00002, loss_test:0.01353, lr:5.71e-02, fs:0.82857 (r=0.879,p=0.784),  time:35.180, tt:1512.751\n",
      "Ep:43, loss:0.00002, loss_test:0.01349, lr:5.71e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.160, tt:1547.043\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01349, lr:5.71e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.174, tt:1582.820\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01355, lr:5.71e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.180, tt:1618.282\n",
      "Ep:46, loss:0.00001, loss_test:0.01361, lr:5.71e-02, fs:0.82000 (r=0.828,p=0.812),  time:35.150, tt:1652.033\n",
      "Ep:47, loss:0.00001, loss_test:0.01367, lr:5.71e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.150, tt:1687.200\n",
      "Ep:48, loss:0.00001, loss_test:0.01373, lr:5.71e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.106, tt:1720.199\n",
      "Ep:49, loss:0.00001, loss_test:0.01385, lr:5.71e-02, fs:0.83249 (r=0.828,p=0.837),  time:35.120, tt:1756.014\n",
      "Ep:50, loss:0.00001, loss_test:0.01385, lr:5.71e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.162, tt:1793.248\n",
      "Ep:51, loss:0.00001, loss_test:0.01392, lr:5.71e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.150, tt:1827.799\n",
      "Ep:52, loss:0.00001, loss_test:0.01397, lr:5.71e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.143, tt:1862.569\n",
      "Ep:53, loss:0.00001, loss_test:0.01406, lr:5.71e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.123, tt:1896.661\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01419, lr:5.71e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.136, tt:1932.462\n",
      "Ep:55, loss:0.00001, loss_test:0.01431, lr:5.71e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.129, tt:1967.196\n",
      "Ep:56, loss:0.00001, loss_test:0.01435, lr:5.71e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.134, tt:2002.631\n",
      "Ep:57, loss:0.00001, loss_test:0.01450, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.134, tt:2037.753\n",
      "Ep:58, loss:0.00001, loss_test:0.01460, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.133, tt:2072.872\n",
      "Ep:59, loss:0.00001, loss_test:0.01471, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.149, tt:2108.939\n",
      "Ep:60, loss:0.00001, loss_test:0.01490, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.133, tt:2143.142\n",
      "Ep:61, loss:0.00001, loss_test:0.01507, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.139, tt:2178.605\n",
      "Ep:62, loss:0.00001, loss_test:0.01531, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.150, tt:2214.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01543, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.157, tt:2250.072\n",
      "Ep:64, loss:0.00001, loss_test:0.01549, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.171, tt:2286.144\n",
      "Ep:65, loss:0.00001, loss_test:0.01569, lr:5.65e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.242, tt:2325.939\n",
      "Ep:66, loss:0.00001, loss_test:0.01583, lr:5.59e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.252, tt:2361.862\n",
      "Ep:67, loss:0.00001, loss_test:0.01597, lr:5.54e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.253, tt:2397.206\n",
      "Ep:68, loss:0.00001, loss_test:0.01623, lr:5.48e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.250, tt:2432.269\n",
      "Ep:69, loss:0.00001, loss_test:0.01633, lr:5.43e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.263, tt:2468.396\n",
      "Ep:70, loss:0.00001, loss_test:0.01652, lr:5.37e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.254, tt:2503.030\n",
      "Ep:71, loss:0.00001, loss_test:0.01663, lr:5.32e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.253, tt:2538.205\n",
      "Ep:72, loss:0.00001, loss_test:0.01684, lr:5.27e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.248, tt:2573.082\n",
      "Ep:73, loss:0.00001, loss_test:0.01704, lr:5.21e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.251, tt:2608.584\n",
      "Ep:74, loss:0.00001, loss_test:0.01712, lr:5.16e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.254, tt:2644.044\n",
      "Ep:75, loss:0.00001, loss_test:0.01738, lr:5.11e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.231, tt:2677.551\n",
      "Ep:76, loss:0.00001, loss_test:0.01750, lr:5.06e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.242, tt:2713.665\n",
      "Ep:77, loss:0.00001, loss_test:0.01767, lr:5.01e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.255, tt:2749.887\n",
      "Ep:78, loss:0.00001, loss_test:0.01792, lr:4.96e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.265, tt:2785.918\n",
      "Ep:79, loss:0.00001, loss_test:0.01796, lr:4.91e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.264, tt:2821.132\n",
      "Ep:80, loss:0.00001, loss_test:0.01821, lr:4.86e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.264, tt:2856.413\n",
      "Ep:81, loss:0.00001, loss_test:0.01829, lr:4.81e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.249, tt:2890.404\n",
      "Ep:82, loss:0.00001, loss_test:0.01847, lr:4.76e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.228, tt:2923.952\n",
      "Ep:83, loss:0.00001, loss_test:0.01861, lr:4.71e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.252, tt:2961.174\n",
      "Ep:84, loss:0.00001, loss_test:0.01884, lr:4.67e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.253, tt:2996.541\n",
      "Ep:85, loss:0.00001, loss_test:0.01901, lr:4.62e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.242, tt:3030.779\n",
      "Ep:86, loss:0.00001, loss_test:0.01914, lr:4.57e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.231, tt:3065.071\n",
      "Ep:87, loss:0.00001, loss_test:0.01925, lr:4.53e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.244, tt:3101.466\n",
      "Ep:88, loss:0.00001, loss_test:0.01936, lr:4.48e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.234, tt:3135.788\n",
      "Ep:89, loss:0.00001, loss_test:0.01957, lr:4.44e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.225, tt:3170.292\n",
      "Ep:90, loss:0.00001, loss_test:0.01968, lr:4.39e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.235, tt:3206.427\n",
      "Ep:91, loss:0.00000, loss_test:0.01979, lr:4.35e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.240, tt:3242.066\n",
      "Ep:92, loss:0.00000, loss_test:0.01983, lr:4.31e-02, fs:0.74556 (r=0.636,p=0.900),  time:35.215, tt:3275.009\n",
      "Ep:93, loss:0.00000, loss_test:0.02014, lr:4.26e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.226, tt:3311.281\n",
      "Ep:94, loss:0.00000, loss_test:0.02027, lr:4.22e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.233, tt:3347.092\n",
      "Ep:95, loss:0.00000, loss_test:0.02013, lr:4.18e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.245, tt:3383.516\n",
      "Ep:96, loss:0.00000, loss_test:0.02055, lr:4.14e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.251, tt:3419.367\n",
      "Ep:97, loss:0.00000, loss_test:0.02055, lr:4.10e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.259, tt:3455.350\n",
      "Ep:98, loss:0.00000, loss_test:0.02047, lr:4.05e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.252, tt:3489.929\n",
      "Ep:99, loss:0.00000, loss_test:0.02089, lr:4.01e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.238, tt:3523.760\n",
      "Ep:100, loss:0.00000, loss_test:0.02096, lr:3.97e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.239, tt:3559.187\n",
      "Ep:101, loss:0.00000, loss_test:0.02080, lr:3.93e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.231, tt:3593.578\n",
      "Ep:102, loss:0.00000, loss_test:0.02122, lr:3.89e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.248, tt:3630.590\n",
      "Ep:103, loss:0.00000, loss_test:0.02125, lr:3.86e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.266, tt:3667.657\n",
      "Ep:104, loss:0.00000, loss_test:0.02115, lr:3.82e-02, fs:0.75000 (r=0.636,p=0.913),  time:35.282, tt:3704.622\n",
      "Ep:105, loss:0.00000, loss_test:0.02148, lr:3.78e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.286, tt:3740.341\n",
      "Ep:106, loss:0.00000, loss_test:0.02158, lr:3.74e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.289, tt:3775.953\n",
      "Ep:107, loss:0.00000, loss_test:0.02152, lr:3.70e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.282, tt:3810.481\n",
      "Ep:108, loss:0.00000, loss_test:0.02161, lr:3.67e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.287, tt:3846.288\n",
      "Ep:109, loss:0.00000, loss_test:0.02184, lr:3.63e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.285, tt:3881.389\n",
      "Ep:110, loss:0.00000, loss_test:0.02191, lr:3.59e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.286, tt:3916.791\n",
      "Ep:111, loss:0.00000, loss_test:0.02187, lr:3.56e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.279, tt:3951.272\n",
      "Ep:112, loss:0.00000, loss_test:0.02206, lr:3.52e-02, fs:0.73939 (r=0.616,p=0.924),  time:35.288, tt:3987.518\n",
      "Ep:113, loss:0.00000, loss_test:0.02213, lr:3.49e-02, fs:0.73939 (r=0.616,p=0.924),  time:35.295, tt:4023.625\n",
      "Ep:114, loss:0.00000, loss_test:0.02209, lr:3.45e-02, fs:0.73939 (r=0.616,p=0.924),  time:35.287, tt:4057.968\n",
      "Ep:115, loss:0.00000, loss_test:0.02226, lr:3.42e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.301, tt:4094.898\n",
      "Ep:116, loss:0.00000, loss_test:0.02233, lr:3.38e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.316, tt:4131.963\n",
      "Ep:117, loss:0.00000, loss_test:0.02233, lr:3.35e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.320, tt:4167.770\n",
      "Ep:118, loss:0.00000, loss_test:0.02248, lr:3.32e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.331, tt:4204.404\n",
      "Ep:119, loss:0.00000, loss_test:0.02254, lr:3.28e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.334, tt:4240.031\n",
      "Ep:120, loss:0.00000, loss_test:0.02254, lr:3.25e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.340, tt:4276.129\n",
      "Ep:121, loss:0.00000, loss_test:0.02270, lr:3.22e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.345, tt:4312.044\n",
      "Ep:122, loss:0.00000, loss_test:0.02272, lr:3.19e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.357, tt:4348.902\n",
      "Ep:123, loss:0.00000, loss_test:0.02268, lr:3.15e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.354, tt:4383.913\n",
      "Ep:124, loss:0.00000, loss_test:0.02289, lr:3.12e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.350, tt:4418.764\n",
      "Ep:125, loss:0.00000, loss_test:0.02295, lr:3.09e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.349, tt:4453.935\n",
      "Ep:126, loss:0.00000, loss_test:0.02289, lr:3.06e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.352, tt:4489.671\n",
      "Ep:127, loss:0.00000, loss_test:0.02298, lr:3.03e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.359, tt:4525.938\n",
      "Ep:128, loss:0.00000, loss_test:0.02314, lr:3.00e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.368, tt:4562.503\n",
      "Ep:129, loss:0.00000, loss_test:0.02314, lr:2.97e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.373, tt:4598.449\n",
      "Ep:130, loss:0.00000, loss_test:0.02315, lr:2.94e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.365, tt:4632.808\n",
      "Ep:131, loss:0.00000, loss_test:0.02328, lr:2.91e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.357, tt:4667.100\n",
      "Ep:132, loss:0.00000, loss_test:0.02335, lr:2.88e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.359, tt:4702.722\n",
      "Ep:133, loss:0.00000, loss_test:0.02326, lr:2.85e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.359, tt:4738.133\n",
      "Ep:134, loss:0.00000, loss_test:0.02334, lr:2.82e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.349, tt:4772.056\n",
      "Ep:135, loss:0.00000, loss_test:0.02354, lr:2.80e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.332, tt:4805.172\n",
      "Ep:136, loss:0.00000, loss_test:0.02351, lr:2.77e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.326, tt:4839.715\n",
      "Ep:137, loss:0.00000, loss_test:0.02347, lr:2.74e-02, fs:0.68354 (r=0.545,p=0.915),  time:35.323, tt:4874.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.02367, lr:2.71e-02, fs:0.68354 (r=0.545,p=0.915),  time:35.316, tt:4908.912\n",
      "Ep:139, loss:0.00000, loss_test:0.02375, lr:2.69e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.313, tt:4943.793\n",
      "Ep:140, loss:0.00000, loss_test:0.02364, lr:2.66e-02, fs:0.67516 (r=0.535,p=0.914),  time:35.314, tt:4979.333\n",
      "Ep:141, loss:0.00000, loss_test:0.02376, lr:2.63e-02, fs:0.67516 (r=0.535,p=0.914),  time:35.308, tt:5013.804\n",
      "Ep:142, loss:0.00000, loss_test:0.02394, lr:2.61e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.310, tt:5049.315\n",
      "Ep:143, loss:0.00000, loss_test:0.02387, lr:2.58e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.316, tt:5085.559\n",
      "Ep:144, loss:0.00000, loss_test:0.02384, lr:2.55e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.322, tt:5121.756\n",
      "Ep:145, loss:0.00000, loss_test:0.02405, lr:2.53e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.321, tt:5156.928\n",
      "Ep:146, loss:0.00000, loss_test:0.02398, lr:2.50e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.310, tt:5190.514\n",
      "Ep:147, loss:0.00000, loss_test:0.02396, lr:2.48e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.303, tt:5224.902\n",
      "Ep:148, loss:0.00000, loss_test:0.02410, lr:2.45e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.299, tt:5259.545\n",
      "Ep:149, loss:0.00000, loss_test:0.02419, lr:2.43e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.293, tt:5293.922\n",
      "Ep:150, loss:0.00000, loss_test:0.02410, lr:2.40e-02, fs:0.66667 (r=0.525,p=0.912),  time:35.287, tt:5328.363\n",
      "Ep:151, loss:0.00000, loss_test:0.02421, lr:2.38e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.294, tt:5364.711\n",
      "Ep:152, loss:0.00000, loss_test:0.02435, lr:2.36e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.293, tt:5399.791\n",
      "Ep:153, loss:0.00000, loss_test:0.02426, lr:2.33e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.295, tt:5435.367\n",
      "Ep:154, loss:0.00000, loss_test:0.02430, lr:2.31e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.299, tt:5471.334\n",
      "Ep:155, loss:0.00000, loss_test:0.02443, lr:2.29e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.285, tt:5504.447\n",
      "Ep:156, loss:0.00000, loss_test:0.02442, lr:2.26e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.294, tt:5541.159\n",
      "Ep:157, loss:0.00000, loss_test:0.02444, lr:2.24e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.300, tt:5577.340\n",
      "Ep:158, loss:0.00000, loss_test:0.02449, lr:2.22e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.302, tt:5612.953\n",
      "Ep:159, loss:0.00000, loss_test:0.02457, lr:2.20e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.314, tt:5650.252\n",
      "Ep:160, loss:0.00000, loss_test:0.02460, lr:2.17e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.317, tt:5686.086\n",
      "Ep:161, loss:0.00000, loss_test:0.02462, lr:2.15e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.333, tt:5723.901\n",
      "Ep:162, loss:0.00000, loss_test:0.02462, lr:2.13e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.336, tt:5759.711\n",
      "Ep:163, loss:0.00000, loss_test:0.02473, lr:2.11e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.349, tt:5797.182\n",
      "Ep:164, loss:0.00000, loss_test:0.02472, lr:2.09e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.351, tt:5832.904\n",
      "Ep:165, loss:0.00000, loss_test:0.02473, lr:2.07e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.353, tt:5868.644\n",
      "Ep:166, loss:0.00000, loss_test:0.02483, lr:2.05e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.364, tt:5905.791\n",
      "Ep:167, loss:0.00000, loss_test:0.02488, lr:2.03e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.373, tt:5942.682\n",
      "Ep:168, loss:0.00000, loss_test:0.02485, lr:2.01e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.377, tt:5978.770\n",
      "Ep:169, loss:0.00000, loss_test:0.02491, lr:1.99e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.384, tt:6015.293\n",
      "Ep:170, loss:0.00000, loss_test:0.02499, lr:1.97e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.388, tt:6051.287\n",
      "Ep:171, loss:0.00000, loss_test:0.02495, lr:1.95e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.396, tt:6088.125\n",
      "Ep:172, loss:0.00000, loss_test:0.02499, lr:1.93e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.400, tt:6124.151\n",
      "Ep:173, loss:0.00000, loss_test:0.02505, lr:1.91e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.401, tt:6159.834\n",
      "Ep:174, loss:0.00000, loss_test:0.02512, lr:1.89e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.399, tt:6194.889\n",
      "Ep:175, loss:0.00000, loss_test:0.02507, lr:1.87e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.409, tt:6231.967\n",
      "Ep:176, loss:0.00000, loss_test:0.02508, lr:1.85e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.413, tt:6268.050\n",
      "Ep:177, loss:0.00000, loss_test:0.02523, lr:1.83e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.413, tt:6303.504\n",
      "Ep:178, loss:0.00000, loss_test:0.02527, lr:1.81e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.419, tt:6339.927\n",
      "Ep:179, loss:0.00000, loss_test:0.02520, lr:1.80e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.420, tt:6375.550\n",
      "Ep:180, loss:0.00000, loss_test:0.02525, lr:1.78e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.424, tt:6411.665\n",
      "Ep:181, loss:0.00000, loss_test:0.02537, lr:1.76e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.423, tt:6447.076\n",
      "Ep:182, loss:0.00000, loss_test:0.02535, lr:1.74e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.432, tt:6483.982\n",
      "Ep:183, loss:0.00000, loss_test:0.02536, lr:1.73e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.439, tt:6520.718\n",
      "Ep:184, loss:0.00000, loss_test:0.02541, lr:1.71e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.444, tt:6557.150\n",
      "Ep:185, loss:0.00000, loss_test:0.02547, lr:1.69e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.439, tt:6591.636\n",
      "Ep:186, loss:0.00000, loss_test:0.02546, lr:1.67e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.447, tt:6628.640\n",
      "Ep:187, loss:0.00000, loss_test:0.02546, lr:1.66e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.453, tt:6665.191\n",
      "Ep:188, loss:0.00000, loss_test:0.02555, lr:1.64e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.456, tt:6701.142\n",
      "Ep:189, loss:0.00000, loss_test:0.02562, lr:1.62e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.463, tt:6737.912\n",
      "Ep:190, loss:0.00000, loss_test:0.02561, lr:1.61e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.466, tt:6773.942\n",
      "Ep:191, loss:0.00000, loss_test:0.02557, lr:1.59e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.464, tt:6809.082\n",
      "Ep:192, loss:0.00000, loss_test:0.02566, lr:1.58e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.456, tt:6843.079\n",
      "Ep:193, loss:0.00000, loss_test:0.02576, lr:1.56e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.455, tt:6878.246\n",
      "Ep:194, loss:0.00000, loss_test:0.02574, lr:1.54e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.456, tt:6913.829\n",
      "Ep:195, loss:0.00000, loss_test:0.02568, lr:1.53e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.454, tt:6949.065\n",
      "Ep:196, loss:0.00000, loss_test:0.02575, lr:1.51e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.453, tt:6984.279\n",
      "Ep:197, loss:0.00000, loss_test:0.02584, lr:1.50e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.442, tt:7017.509\n",
      "Ep:198, loss:0.00000, loss_test:0.02582, lr:1.48e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.436, tt:7051.717\n",
      "Ep:199, loss:0.00000, loss_test:0.02579, lr:1.47e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.427, tt:7085.495\n",
      "Ep:200, loss:0.00000, loss_test:0.02590, lr:1.45e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.423, tt:7120.115\n",
      "Ep:201, loss:0.00000, loss_test:0.02592, lr:1.44e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.415, tt:7153.834\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13037, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:33.162, tt:33.162\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12946, lr:1.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:35.284, tt:70.568\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12854, lr:1.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:36.172, tt:108.516\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12767, lr:1.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:36.250, tt:145.000\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12696, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:36.365, tt:181.825\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00025, loss_test:0.12624, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:36.270, tt:217.618\n",
      "Ep:6, loss:0.00025, loss_test:0.12551, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:36.052, tt:252.367\n",
      "Ep:7, loss:0.00025, loss_test:0.12470, lr:1.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:36.228, tt:289.827\n",
      "Ep:8, loss:0.00024, loss_test:0.12365, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:36.500, tt:328.498\n",
      "Ep:9, loss:0.00024, loss_test:0.12254, lr:1.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:36.731, tt:367.305\n",
      "Ep:10, loss:0.00024, loss_test:0.12153, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:36.996, tt:406.952\n",
      "Ep:11, loss:0.00023, loss_test:0.12057, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:37.117, tt:445.406\n",
      "Ep:12, loss:0.00023, loss_test:0.11952, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:37.217, tt:483.818\n",
      "Ep:13, loss:0.00023, loss_test:0.11807, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:37.193, tt:520.697\n",
      "Ep:14, loss:0.00022, loss_test:0.11637, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:37.340, tt:560.105\n",
      "Ep:15, loss:0.00022, loss_test:0.11460, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:37.340, tt:597.444\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.11259, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:37.409, tt:635.945\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.11035, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:37.431, tt:673.754\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00020, loss_test:0.10792, lr:1.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:37.521, tt:712.904\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.10526, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:37.562, tt:751.245\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.10261, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:37.552, tt:788.590\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.10091, lr:1.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:37.561, tt:826.345\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.09950, lr:1.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:37.629, tt:865.465\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.09778, lr:1.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:37.630, tt:903.111\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09580, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:37.651, tt:941.275\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.09416, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:37.714, tt:980.559\n",
      "Ep:26, loss:0.00015, loss_test:0.09297, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:37.750, tt:1019.242\n",
      "Ep:27, loss:0.00014, loss_test:0.09112, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:37.775, tt:1057.701\n",
      "Ep:28, loss:0.00013, loss_test:0.08914, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:37.823, tt:1096.856\n",
      "Ep:29, loss:0.00013, loss_test:0.08748, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:37.823, tt:1134.697\n",
      "Ep:30, loss:0.00012, loss_test:0.08640, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:37.823, tt:1172.520\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08499, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:37.851, tt:1211.239\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08296, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:37.871, tt:1249.739\n",
      "Ep:33, loss:0.00011, loss_test:0.08392, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:37.894, tt:1288.390\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08094, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:37.846, tt:1324.613\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08079, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:37.843, tt:1362.344\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.08142, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:37.805, tt:1398.803\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07724, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:37.799, tt:1436.357\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.08173, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:37.793, tt:1473.937\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.07590, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:37.789, tt:1511.562\n",
      "Ep:40, loss:0.00008, loss_test:0.08175, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.763, tt:1548.270\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.07489, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:37.734, tt:1584.821\n",
      "Ep:42, loss:0.00007, loss_test:0.07954, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.744, tt:1623.003\n",
      "Ep:43, loss:0.00007, loss_test:0.07547, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:37.746, tt:1660.805\n",
      "Ep:44, loss:0.00007, loss_test:0.07641, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:37.734, tt:1698.029\n",
      "Ep:45, loss:0.00006, loss_test:0.07472, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:37.712, tt:1734.760\n",
      "Ep:46, loss:0.00006, loss_test:0.07940, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:37.703, tt:1772.021\n",
      "Ep:47, loss:0.00006, loss_test:0.07377, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:37.686, tt:1808.912\n",
      "Ep:48, loss:0.00006, loss_test:0.07736, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:37.654, tt:1845.041\n",
      "Ep:49, loss:0.00005, loss_test:0.07601, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:37.654, tt:1882.698\n",
      "Ep:50, loss:0.00005, loss_test:0.07645, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:37.640, tt:1919.642\n",
      "Ep:51, loss:0.00005, loss_test:0.07649, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:37.609, tt:1955.665\n",
      "Ep:52, loss:0.00005, loss_test:0.07700, lr:9.90e-03, fs:0.79570 (r=0.747,p=0.851),  time:37.580, tt:1991.752\n",
      "Ep:53, loss:0.00005, loss_test:0.07477, lr:9.80e-03, fs:0.79348 (r=0.737,p=0.859),  time:37.565, tt:2028.483\n",
      "Ep:54, loss:0.00004, loss_test:0.08006, lr:9.70e-03, fs:0.75556 (r=0.687,p=0.840),  time:37.549, tt:2065.168\n",
      "Ep:55, loss:0.00004, loss_test:0.07439, lr:9.61e-03, fs:0.76923 (r=0.707,p=0.843),  time:37.530, tt:2101.667\n",
      "Ep:56, loss:0.00004, loss_test:0.07793, lr:9.51e-03, fs:0.77348 (r=0.707,p=0.854),  time:37.511, tt:2138.117\n",
      "Ep:57, loss:0.00004, loss_test:0.07626, lr:9.41e-03, fs:0.77778 (r=0.707,p=0.864),  time:37.465, tt:2172.944\n",
      "Ep:58, loss:0.00004, loss_test:0.07781, lr:9.32e-03, fs:0.77348 (r=0.707,p=0.854),  time:37.442, tt:2209.056\n",
      "Ep:59, loss:0.00004, loss_test:0.07644, lr:9.23e-03, fs:0.76836 (r=0.687,p=0.872),  time:37.423, tt:2245.379\n",
      "Ep:60, loss:0.00004, loss_test:0.07688, lr:9.14e-03, fs:0.77778 (r=0.707,p=0.864),  time:37.398, tt:2281.290\n",
      "Ep:61, loss:0.00004, loss_test:0.07660, lr:9.04e-03, fs:0.76136 (r=0.677,p=0.870),  time:37.362, tt:2316.441\n",
      "Ep:62, loss:0.00003, loss_test:0.07638, lr:8.95e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.341, tt:2352.472\n",
      "Ep:63, loss:0.00003, loss_test:0.07725, lr:8.86e-03, fs:0.77011 (r=0.677,p=0.893),  time:37.304, tt:2387.479\n",
      "Ep:64, loss:0.00003, loss_test:0.07591, lr:8.78e-03, fs:0.77348 (r=0.707,p=0.854),  time:37.300, tt:2424.499\n",
      "Ep:65, loss:0.00003, loss_test:0.07669, lr:8.69e-03, fs:0.75429 (r=0.667,p=0.868),  time:37.285, tt:2460.793\n",
      "Ep:66, loss:0.00003, loss_test:0.08165, lr:8.60e-03, fs:0.74556 (r=0.636,p=0.900),  time:37.239, tt:2495.037\n",
      "Ep:67, loss:0.00003, loss_test:0.07360, lr:8.51e-03, fs:0.76923 (r=0.707,p=0.843),  time:37.212, tt:2530.413\n",
      "Ep:68, loss:0.00003, loss_test:0.07772, lr:8.43e-03, fs:0.75145 (r=0.657,p=0.878),  time:37.177, tt:2565.232\n",
      "Ep:69, loss:0.00003, loss_test:0.07589, lr:8.35e-03, fs:0.76404 (r=0.687,p=0.861),  time:37.166, tt:2601.635\n",
      "Ep:70, loss:0.00003, loss_test:0.07703, lr:8.26e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.149, tt:2637.567\n",
      "Ep:71, loss:0.00003, loss_test:0.07711, lr:8.18e-03, fs:0.77095 (r=0.697,p=0.863),  time:37.146, tt:2674.486\n",
      "Ep:72, loss:0.00003, loss_test:0.07630, lr:8.10e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.146, tt:2711.660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00003, loss_test:0.07540, lr:8.02e-03, fs:0.77348 (r=0.707,p=0.854),  time:37.133, tt:2747.879\n",
      "Ep:74, loss:0.00003, loss_test:0.07888, lr:7.94e-03, fs:0.77714 (r=0.687,p=0.895),  time:37.119, tt:2783.926\n",
      "Ep:75, loss:0.00003, loss_test:0.07628, lr:7.86e-03, fs:0.78212 (r=0.707,p=0.875),  time:37.102, tt:2819.773\n",
      "Ep:76, loss:0.00002, loss_test:0.07757, lr:7.78e-03, fs:0.77778 (r=0.707,p=0.864),  time:37.099, tt:2856.605\n",
      "Ep:77, loss:0.00002, loss_test:0.07786, lr:7.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:37.088, tt:2892.844\n",
      "Ep:78, loss:0.00002, loss_test:0.07744, lr:7.62e-03, fs:0.77714 (r=0.687,p=0.895),  time:37.086, tt:2929.789\n",
      "Ep:79, loss:0.00002, loss_test:0.07933, lr:7.55e-03, fs:0.77457 (r=0.677,p=0.905),  time:37.064, tt:2965.158\n",
      "Ep:80, loss:0.00002, loss_test:0.07693, lr:7.47e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.050, tt:3001.056\n",
      "Ep:81, loss:0.00002, loss_test:0.07845, lr:7.40e-03, fs:0.77966 (r=0.697,p=0.885),  time:37.056, tt:3038.595\n",
      "Ep:82, loss:0.00002, loss_test:0.07873, lr:7.32e-03, fs:0.77647 (r=0.667,p=0.930),  time:37.031, tt:3073.578\n",
      "Ep:83, loss:0.00002, loss_test:0.07895, lr:7.25e-03, fs:0.77457 (r=0.677,p=0.905),  time:37.057, tt:3112.782\n",
      "Ep:84, loss:0.00002, loss_test:0.07790, lr:7.18e-03, fs:0.76744 (r=0.667,p=0.904),  time:37.063, tt:3150.329\n",
      "Ep:85, loss:0.00002, loss_test:0.08016, lr:7.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:37.063, tt:3187.424\n",
      "Ep:86, loss:0.00002, loss_test:0.07721, lr:7.03e-03, fs:0.77714 (r=0.687,p=0.895),  time:37.041, tt:3222.576\n",
      "Ep:87, loss:0.00002, loss_test:0.07972, lr:6.96e-03, fs:0.77193 (r=0.667,p=0.917),  time:37.028, tt:3258.478\n",
      "Ep:88, loss:0.00002, loss_test:0.08023, lr:6.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:37.020, tt:3294.793\n",
      "Ep:89, loss:0.00002, loss_test:0.07742, lr:6.83e-03, fs:0.78161 (r=0.687,p=0.907),  time:37.005, tt:3330.480\n",
      "Ep:90, loss:0.00002, loss_test:0.08001, lr:6.76e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.975, tt:3364.700\n",
      "Ep:91, loss:0.00002, loss_test:0.07960, lr:6.69e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.958, tt:3400.147\n",
      "Ep:92, loss:0.00002, loss_test:0.07840, lr:6.62e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.955, tt:3436.849\n",
      "Ep:93, loss:0.00002, loss_test:0.08010, lr:6.56e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.932, tt:3471.585\n",
      "Ep:94, loss:0.00002, loss_test:0.07986, lr:6.49e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.926, tt:3507.933\n",
      "Ep:95, loss:0.00002, loss_test:0.07965, lr:6.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.863, tt:3538.845\n",
      "Ep:96, loss:0.00002, loss_test:0.08013, lr:6.36e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.809, tt:3570.515\n",
      "Ep:97, loss:0.00002, loss_test:0.07992, lr:6.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.782, tt:3604.599\n",
      "Ep:98, loss:0.00002, loss_test:0.07914, lr:6.24e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.758, tt:3639.083\n",
      "Ep:99, loss:0.00002, loss_test:0.08034, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.751, tt:3675.082\n",
      "Ep:100, loss:0.00002, loss_test:0.07921, lr:6.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.715, tt:3708.168\n",
      "Ep:101, loss:0.00002, loss_test:0.08040, lr:6.05e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.705, tt:3743.891\n",
      "Ep:102, loss:0.00002, loss_test:0.08022, lr:5.99e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.700, tt:3780.139\n",
      "Ep:103, loss:0.00002, loss_test:0.07996, lr:5.93e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.694, tt:3816.202\n",
      "Ep:104, loss:0.00002, loss_test:0.08090, lr:5.87e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.687, tt:3852.085\n",
      "Ep:105, loss:0.00002, loss_test:0.08005, lr:5.81e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.683, tt:3888.439\n",
      "Ep:106, loss:0.00002, loss_test:0.08093, lr:5.75e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.683, tt:3925.101\n",
      "Ep:107, loss:0.00002, loss_test:0.07999, lr:5.70e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.682, tt:3961.677\n",
      "Ep:108, loss:0.00002, loss_test:0.08025, lr:5.64e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.677, tt:3997.744\n",
      "Ep:109, loss:0.00002, loss_test:0.08016, lr:5.58e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.671, tt:4033.832\n",
      "Ep:110, loss:0.00001, loss_test:0.08115, lr:5.53e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.673, tt:4070.727\n",
      "Ep:111, loss:0.00001, loss_test:0.08044, lr:5.47e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.656, tt:4105.498\n",
      "Ep:112, loss:0.00001, loss_test:0.08120, lr:5.42e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.646, tt:4141.031\n",
      "Ep:113, loss:0.00001, loss_test:0.08034, lr:5.36e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.644, tt:4177.425\n",
      "Ep:114, loss:0.00001, loss_test:0.08117, lr:5.31e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.647, tt:4214.352\n",
      "Ep:115, loss:0.00001, loss_test:0.08084, lr:5.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.613, tt:4247.150\n",
      "Ep:116, loss:0.00001, loss_test:0.08183, lr:5.20e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.614, tt:4283.838\n",
      "Ep:117, loss:0.00001, loss_test:0.08027, lr:5.15e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.617, tt:4320.846\n",
      "Ep:118, loss:0.00001, loss_test:0.08233, lr:5.10e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.602, tt:4355.633\n",
      "Ep:119, loss:0.00001, loss_test:0.08096, lr:5.05e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.602, tt:4392.275\n",
      "Ep:120, loss:0.00001, loss_test:0.08073, lr:5.00e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.598, tt:4428.390\n",
      "Ep:121, loss:0.00001, loss_test:0.08166, lr:4.95e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.603, tt:4465.589\n",
      "Ep:122, loss:0.00001, loss_test:0.08082, lr:4.90e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.605, tt:4502.420\n",
      "Ep:123, loss:0.00001, loss_test:0.08220, lr:4.85e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.607, tt:4539.244\n",
      "Ep:124, loss:0.00001, loss_test:0.08077, lr:4.80e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.600, tt:4574.946\n",
      "Ep:125, loss:0.00001, loss_test:0.08131, lr:4.75e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.601, tt:4611.706\n",
      "Ep:126, loss:0.00001, loss_test:0.08226, lr:4.71e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.596, tt:4647.744\n",
      "Ep:127, loss:0.00001, loss_test:0.08073, lr:4.66e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.594, tt:4683.999\n",
      "Ep:128, loss:0.00001, loss_test:0.08232, lr:4.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.597, tt:4721.051\n",
      "Ep:129, loss:0.00001, loss_test:0.08239, lr:4.57e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.599, tt:4757.862\n",
      "Ep:130, loss:0.00001, loss_test:0.08120, lr:4.52e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.588, tt:4793.008\n",
      "Ep:131, loss:0.00001, loss_test:0.08275, lr:4.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.591, tt:4830.060\n",
      "Ep:132, loss:0.00001, loss_test:0.08131, lr:4.43e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.599, tt:4867.688\n",
      "Ep:133, loss:0.00001, loss_test:0.08133, lr:4.39e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.606, tt:4905.149\n",
      "Ep:134, loss:0.00001, loss_test:0.08257, lr:4.34e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.604, tt:4941.605\n",
      "Ep:135, loss:0.00001, loss_test:0.08083, lr:4.30e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.598, tt:4977.364\n",
      "Ep:136, loss:0.00001, loss_test:0.08214, lr:4.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.607, tt:5015.216\n",
      "Ep:137, loss:0.00001, loss_test:0.08217, lr:4.21e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.597, tt:5050.408\n",
      "Ep:138, loss:0.00001, loss_test:0.08185, lr:4.17e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.584, tt:5085.140\n",
      "Ep:139, loss:0.00001, loss_test:0.08208, lr:4.13e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.587, tt:5122.218\n",
      "Ep:140, loss:0.00001, loss_test:0.08265, lr:4.09e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.583, tt:5158.202\n",
      "Ep:141, loss:0.00001, loss_test:0.08201, lr:4.05e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.585, tt:5195.005\n",
      "Ep:142, loss:0.00001, loss_test:0.08167, lr:4.01e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.594, tt:5232.871\n",
      "Ep:143, loss:0.00001, loss_test:0.08330, lr:3.97e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.579, tt:5267.355\n",
      "Ep:144, loss:0.00001, loss_test:0.08233, lr:3.93e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.572, tt:5302.994\n",
      "Ep:145, loss:0.00001, loss_test:0.08129, lr:3.89e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.564, tt:5338.292\n",
      "Ep:146, loss:0.00001, loss_test:0.08369, lr:3.85e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.555, tt:5373.648\n",
      "Ep:147, loss:0.00001, loss_test:0.08318, lr:3.81e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.564, tt:5411.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00001, loss_test:0.08126, lr:3.77e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.567, tt:5448.553\n",
      "Ep:149, loss:0.00001, loss_test:0.08295, lr:3.73e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.561, tt:5484.112\n",
      "Ep:150, loss:0.00001, loss_test:0.08333, lr:3.70e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.563, tt:5520.978\n",
      "Ep:151, loss:0.00001, loss_test:0.08190, lr:3.66e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.567, tt:5558.246\n",
      "Ep:152, loss:0.00001, loss_test:0.08290, lr:3.62e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.578, tt:5596.456\n",
      "Ep:153, loss:0.00001, loss_test:0.08285, lr:3.59e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.587, tt:5634.456\n",
      "Ep:154, loss:0.00001, loss_test:0.08256, lr:3.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.592, tt:5671.764\n",
      "Ep:155, loss:0.00001, loss_test:0.08292, lr:3.52e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.590, tt:5708.024\n",
      "Ep:156, loss:0.00001, loss_test:0.08268, lr:3.48e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.588, tt:5744.382\n",
      "Ep:157, loss:0.00001, loss_test:0.08266, lr:3.45e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.593, tt:5781.693\n",
      "Ep:158, loss:0.00001, loss_test:0.08324, lr:3.41e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.596, tt:5818.798\n",
      "Ep:159, loss:0.00001, loss_test:0.08304, lr:3.38e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.588, tt:5854.060\n",
      "Ep:160, loss:0.00001, loss_test:0.08249, lr:3.34e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.592, tt:5891.355\n",
      "Ep:161, loss:0.00001, loss_test:0.08311, lr:3.31e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.586, tt:5926.946\n",
      "Ep:162, loss:0.00001, loss_test:0.08304, lr:3.28e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.589, tt:5964.001\n",
      "Ep:163, loss:0.00001, loss_test:0.08285, lr:3.24e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.580, tt:5999.043\n",
      "Ep:164, loss:0.00001, loss_test:0.08298, lr:3.21e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.585, tt:6036.550\n",
      "Ep:165, loss:0.00001, loss_test:0.08338, lr:3.18e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.588, tt:6073.658\n",
      "Ep:166, loss:0.00001, loss_test:0.08301, lr:3.15e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.586, tt:6109.830\n",
      "Ep:167, loss:0.00001, loss_test:0.08303, lr:3.12e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.593, tt:6147.558\n",
      "Ep:168, loss:0.00001, loss_test:0.08365, lr:3.09e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.598, tt:6185.077\n",
      "Ep:169, loss:0.00001, loss_test:0.08337, lr:3.05e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.597, tt:6221.483\n",
      "Ep:170, loss:0.00001, loss_test:0.08275, lr:3.02e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.607, tt:6259.818\n",
      "Ep:171, loss:0.00001, loss_test:0.08367, lr:2.99e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.618, tt:6298.310\n",
      "Ep:172, loss:0.00001, loss_test:0.08340, lr:2.96e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.619, tt:6335.073\n",
      "Ep:173, loss:0.00001, loss_test:0.08292, lr:2.93e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.620, tt:6371.884\n",
      "Ep:174, loss:0.00001, loss_test:0.08345, lr:2.90e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.627, tt:6409.740\n",
      "Ep:175, loss:0.00001, loss_test:0.08380, lr:2.88e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.628, tt:6446.448\n",
      "Ep:176, loss:0.00001, loss_test:0.08340, lr:2.85e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.631, tt:6483.730\n",
      "Ep:177, loss:0.00001, loss_test:0.08293, lr:2.82e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.636, tt:6521.296\n",
      "Ep:178, loss:0.00001, loss_test:0.08375, lr:2.79e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.639, tt:6558.463\n",
      "Ep:179, loss:0.00001, loss_test:0.08383, lr:2.76e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.634, tt:6594.114\n",
      "Ep:180, loss:0.00001, loss_test:0.08333, lr:2.73e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.633, tt:6630.624\n",
      "Ep:181, loss:0.00001, loss_test:0.08357, lr:2.71e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.631, tt:6666.770\n",
      "Ep:182, loss:0.00001, loss_test:0.08375, lr:2.68e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.629, tt:6703.025\n",
      "Ep:183, loss:0.00001, loss_test:0.08403, lr:2.65e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.623, tt:6738.720\n",
      "Ep:184, loss:0.00001, loss_test:0.08327, lr:2.63e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.619, tt:6774.596\n",
      "Ep:185, loss:0.00001, loss_test:0.08354, lr:2.60e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.619, tt:6811.147\n",
      "Ep:186, loss:0.00001, loss_test:0.08431, lr:2.57e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.614, tt:6846.863\n",
      "Ep:187, loss:0.00001, loss_test:0.08407, lr:2.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.609, tt:6882.586\n",
      "Ep:188, loss:0.00001, loss_test:0.08354, lr:2.52e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.605, tt:6918.310\n",
      "Ep:189, loss:0.00001, loss_test:0.08424, lr:2.50e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.591, tt:6952.317\n",
      "Ep:190, loss:0.00001, loss_test:0.08421, lr:2.47e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.615, tt:6993.410\n",
      "Ep:191, loss:0.00001, loss_test:0.08344, lr:2.45e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.612, tt:7029.504\n",
      "Ep:192, loss:0.00001, loss_test:0.08373, lr:2.42e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.598, tt:7063.352\n",
      "Ep:193, loss:0.00001, loss_test:0.08466, lr:2.40e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.588, tt:7098.058\n",
      "Ep:194, loss:0.00001, loss_test:0.08415, lr:2.38e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.588, tt:7134.677\n",
      "Ep:195, loss:0.00001, loss_test:0.08380, lr:2.35e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.583, tt:7170.253\n",
      "Ep:196, loss:0.00001, loss_test:0.08418, lr:2.33e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.574, tt:7205.065\n",
      "Ep:197, loss:0.00001, loss_test:0.08439, lr:2.31e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.555, tt:7237.904\n",
      "Ep:198, loss:0.00001, loss_test:0.08410, lr:2.28e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.545, tt:7272.498\n",
      "Ep:199, loss:0.00001, loss_test:0.08399, lr:2.26e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.521, tt:7304.182\n",
      "Ep:200, loss:0.00001, loss_test:0.08434, lr:2.24e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.497, tt:7335.925\n",
      "Ep:201, loss:0.00001, loss_test:0.08434, lr:2.21e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.468, tt:7366.577\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02374, lr:6.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:28.108, tt:28.108\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02493, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:28.285, tt:56.569\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02737, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.560, tt:85.680\n",
      "Ep:3, loss:0.00005, loss_test:0.02825, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.929, tt:115.716\n",
      "Ep:4, loss:0.00005, loss_test:0.02801, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.718, tt:143.588\n",
      "Ep:5, loss:0.00005, loss_test:0.02705, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:28.439, tt:170.635\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02571, lr:6.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:27.917, tt:195.416\n",
      "Ep:7, loss:0.00005, loss_test:0.02446, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:27.825, tt:222.602\n",
      "Ep:8, loss:0.00004, loss_test:0.02361, lr:6.00e-02, fs:0.64419 (r=0.869,p=0.512),  time:27.806, tt:250.252\n",
      "Ep:9, loss:0.00004, loss_test:0.02309, lr:6.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:28.080, tt:280.805\n",
      "Ep:10, loss:0.00004, loss_test:0.02246, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:28.368, tt:312.053\n",
      "Ep:11, loss:0.00004, loss_test:0.02181, lr:6.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:28.510, tt:342.117\n",
      "Ep:12, loss:0.00004, loss_test:0.02147, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:28.612, tt:371.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00004, loss_test:0.02118, lr:6.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:28.734, tt:402.278\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:28.838, tt:432.569\n",
      "Ep:15, loss:0.00004, loss_test:0.02025, lr:6.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:28.964, tt:463.420\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02002, lr:6.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:29.141, tt:495.398\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01985, lr:6.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:29.193, tt:525.477\n",
      "Ep:18, loss:0.00004, loss_test:0.01968, lr:6.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:29.267, tt:556.080\n",
      "Ep:19, loss:0.00004, loss_test:0.01941, lr:6.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:29.327, tt:586.547\n",
      "Ep:20, loss:0.00003, loss_test:0.01908, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:29.430, tt:618.024\n",
      "Ep:21, loss:0.00003, loss_test:0.01874, lr:6.00e-02, fs:0.70498 (r=0.929,p=0.568),  time:29.459, tt:648.087\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01848, lr:6.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:29.567, tt:680.047\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01821, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:29.670, tt:712.077\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01790, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:29.748, tt:743.707\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01763, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:29.728, tt:772.917\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01742, lr:6.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:29.715, tt:802.296\n",
      "Ep:27, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:29.811, tt:834.705\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01694, lr:6.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:29.862, tt:866.007\n",
      "Ep:29, loss:0.00003, loss_test:0.01669, lr:6.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:29.953, tt:898.593\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:29.961, tt:928.787\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:30.029, tt:960.918\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01590, lr:6.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:30.035, tt:991.141\n",
      "Ep:33, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:30.031, tt:1021.053\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:30.049, tt:1051.716\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:30.031, tt:1081.107\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01470, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:30.052, tt:1111.917\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01443, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:30.082, tt:1143.126\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:30.063, tt:1172.469\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:30.078, tt:1203.109\n",
      "Ep:40, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:30.061, tt:1232.511\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:30.070, tt:1262.923\n",
      "Ep:42, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:30.090, tt:1293.855\n",
      "Ep:43, loss:0.00002, loss_test:0.01343, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.104, tt:1324.563\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:30.123, tt:1355.535\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01331, lr:6.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:30.154, tt:1387.099\n",
      "Ep:46, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:30.181, tt:1418.502\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01333, lr:6.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:30.197, tt:1449.444\n",
      "Ep:48, loss:0.00001, loss_test:0.01342, lr:6.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:30.186, tt:1479.104\n",
      "Ep:49, loss:0.00001, loss_test:0.01326, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:30.194, tt:1509.683\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01362, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:30.202, tt:1540.287\n",
      "Ep:51, loss:0.00001, loss_test:0.01358, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:30.226, tt:1571.751\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01380, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:30.231, tt:1602.254\n",
      "Ep:53, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:30.239, tt:1632.917\n",
      "Ep:54, loss:0.00001, loss_test:0.01389, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:30.250, tt:1663.737\n",
      "Ep:55, loss:0.00001, loss_test:0.01407, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.244, tt:1693.648\n",
      "Ep:56, loss:0.00001, loss_test:0.01428, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.231, tt:1723.183\n",
      "Ep:57, loss:0.00001, loss_test:0.01425, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.228, tt:1753.234\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01461, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.217, tt:1782.790\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01464, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.196, tt:1811.754\n",
      "Ep:60, loss:0.00001, loss_test:0.01507, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.186, tt:1841.366\n",
      "Ep:61, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.177, tt:1870.977\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01528, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.178, tt:1901.222\n",
      "Ep:63, loss:0.00001, loss_test:0.01526, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.186, tt:1931.902\n",
      "Ep:64, loss:0.00001, loss_test:0.01575, lr:6.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.195, tt:1962.694\n",
      "Ep:65, loss:0.00001, loss_test:0.01544, lr:6.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.191, tt:1992.590\n",
      "Ep:66, loss:0.00001, loss_test:0.01611, lr:6.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:30.184, tt:2022.307\n",
      "Ep:67, loss:0.00001, loss_test:0.01595, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.189, tt:2052.826\n",
      "Ep:68, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.183, tt:2082.610\n",
      "Ep:69, loss:0.00001, loss_test:0.01644, lr:6.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.237, tt:2116.574\n",
      "Ep:70, loss:0.00001, loss_test:0.01665, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.244, tt:2147.340\n",
      "Ep:71, loss:0.00001, loss_test:0.01702, lr:6.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.233, tt:2176.785\n",
      "Ep:72, loss:0.00001, loss_test:0.01676, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.225, tt:2206.447\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01755, lr:6.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.209, tt:2235.466\n",
      "Ep:74, loss:0.00001, loss_test:0.01661, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.208, tt:2265.633\n",
      "Ep:75, loss:0.00001, loss_test:0.01802, lr:6.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.208, tt:2295.790\n",
      "Ep:76, loss:0.00001, loss_test:0.01733, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.202, tt:2325.559\n",
      "Ep:77, loss:0.00001, loss_test:0.01798, lr:6.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.204, tt:2355.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00001, loss_test:0.01777, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.204, tt:2386.155\n",
      "Ep:79, loss:0.00001, loss_test:0.01804, lr:6.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.194, tt:2415.549\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01831, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.192, tt:2445.544\n",
      "Ep:81, loss:0.00001, loss_test:0.01830, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.183, tt:2474.997\n",
      "Ep:82, loss:0.00001, loss_test:0.01849, lr:6.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.178, tt:2504.813\n",
      "Ep:83, loss:0.00001, loss_test:0.01904, lr:6.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.168, tt:2534.112\n",
      "Ep:84, loss:0.00001, loss_test:0.01897, lr:6.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.165, tt:2564.065\n",
      "Ep:85, loss:0.00001, loss_test:0.01924, lr:6.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.160, tt:2593.725\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01916, lr:6.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.145, tt:2622.606\n",
      "Ep:87, loss:0.00001, loss_test:0.01978, lr:6.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.132, tt:2651.578\n",
      "Ep:88, loss:0.00000, loss_test:0.01948, lr:6.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.126, tt:2681.256\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00000, loss_test:0.01988, lr:6.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.128, tt:2711.525\n",
      "Ep:90, loss:0.00000, loss_test:0.02020, lr:6.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.138, tt:2742.532\n",
      "Ep:91, loss:0.00000, loss_test:0.02015, lr:6.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.138, tt:2772.735\n",
      "Ep:92, loss:0.00000, loss_test:0.02017, lr:6.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.140, tt:2803.048\n",
      "Ep:93, loss:0.00000, loss_test:0.02029, lr:6.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:30.152, tt:2834.284\n",
      "Ep:94, loss:0.00000, loss_test:0.02073, lr:6.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.149, tt:2864.192\n",
      "Ep:95, loss:0.00000, loss_test:0.02042, lr:6.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.160, tt:2895.316\n",
      "Ep:96, loss:0.00000, loss_test:0.02100, lr:6.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.158, tt:2925.324\n",
      "Ep:97, loss:0.00000, loss_test:0.02126, lr:6.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.165, tt:2956.187\n",
      "Ep:98, loss:0.00000, loss_test:0.02114, lr:6.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.171, tt:2986.882\n",
      "Ep:99, loss:0.00000, loss_test:0.02136, lr:6.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.170, tt:3017.025\n",
      "Ep:100, loss:0.00000, loss_test:0.02147, lr:5.94e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.175, tt:3047.632\n",
      "Ep:101, loss:0.00000, loss_test:0.02160, lr:5.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:30.185, tt:3078.869\n",
      "Ep:102, loss:0.00000, loss_test:0.02195, lr:5.82e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.191, tt:3109.635\n",
      "Ep:103, loss:0.00000, loss_test:0.02171, lr:5.76e-02, fs:0.80899 (r=0.727,p=0.911),  time:30.199, tt:3140.710\n",
      "Ep:104, loss:0.00000, loss_test:0.02198, lr:5.71e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.201, tt:3171.157\n",
      "Ep:105, loss:0.00000, loss_test:0.02234, lr:5.65e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.204, tt:3201.614\n",
      "Ep:106, loss:0.00000, loss_test:0.02195, lr:5.59e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.207, tt:3232.194\n",
      "Ep:107, loss:0.00000, loss_test:0.02287, lr:5.54e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.211, tt:3262.810\n",
      "Ep:108, loss:0.00000, loss_test:0.02242, lr:5.48e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.191, tt:3290.845\n",
      "Ep:109, loss:0.00000, loss_test:0.02277, lr:5.43e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.187, tt:3320.624\n",
      "Ep:110, loss:0.00000, loss_test:0.02294, lr:5.37e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.177, tt:3349.615\n",
      "Ep:111, loss:0.00000, loss_test:0.02296, lr:5.32e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.177, tt:3379.876\n",
      "Ep:112, loss:0.00000, loss_test:0.02305, lr:5.27e-02, fs:0.80000 (r=0.707,p=0.921),  time:30.180, tt:3410.350\n",
      "Ep:113, loss:0.00000, loss_test:0.02315, lr:5.21e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.182, tt:3440.791\n",
      "Ep:114, loss:0.00000, loss_test:0.02304, lr:5.16e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.190, tt:3471.798\n",
      "Ep:115, loss:0.00000, loss_test:0.02341, lr:5.11e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.182, tt:3501.112\n",
      "Ep:116, loss:0.00000, loss_test:0.02304, lr:5.06e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.180, tt:3531.047\n",
      "Ep:117, loss:0.00000, loss_test:0.02366, lr:5.01e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.175, tt:3560.595\n",
      "Ep:118, loss:0.00000, loss_test:0.02365, lr:4.96e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.169, tt:3590.118\n",
      "Ep:119, loss:0.00000, loss_test:0.02360, lr:4.91e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.167, tt:3620.064\n",
      "Ep:120, loss:0.00000, loss_test:0.02399, lr:4.86e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.169, tt:3650.466\n",
      "Ep:121, loss:0.00000, loss_test:0.02397, lr:4.81e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.156, tt:3678.986\n",
      "Ep:122, loss:0.00000, loss_test:0.02387, lr:4.76e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.144, tt:3707.716\n",
      "Ep:123, loss:0.00000, loss_test:0.02422, lr:4.71e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.133, tt:3736.500\n",
      "Ep:124, loss:0.00000, loss_test:0.02407, lr:4.67e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.127, tt:3765.867\n",
      "Ep:125, loss:0.00000, loss_test:0.02446, lr:4.62e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.119, tt:3795.008\n",
      "Ep:126, loss:0.00000, loss_test:0.02409, lr:4.57e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.126, tt:3825.979\n",
      "Ep:127, loss:0.00000, loss_test:0.02489, lr:4.53e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.124, tt:3855.829\n",
      "Ep:128, loss:0.00000, loss_test:0.02438, lr:4.48e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.126, tt:3886.249\n",
      "Ep:129, loss:0.00000, loss_test:0.02483, lr:4.44e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.126, tt:3916.320\n",
      "Ep:130, loss:0.00000, loss_test:0.02456, lr:4.39e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.117, tt:3945.295\n",
      "Ep:131, loss:0.00000, loss_test:0.02474, lr:4.35e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.119, tt:3975.726\n",
      "Ep:132, loss:0.00000, loss_test:0.02494, lr:4.31e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.115, tt:4005.245\n",
      "Ep:133, loss:0.00000, loss_test:0.02488, lr:4.26e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.107, tt:4034.333\n",
      "Ep:134, loss:0.00000, loss_test:0.02507, lr:4.22e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.107, tt:4064.491\n",
      "Ep:135, loss:0.00000, loss_test:0.02491, lr:4.18e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.104, tt:4094.107\n",
      "Ep:136, loss:0.00000, loss_test:0.02535, lr:4.14e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.105, tt:4124.394\n",
      "Ep:137, loss:0.00000, loss_test:0.02512, lr:4.10e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.112, tt:4155.517\n",
      "Ep:138, loss:0.00000, loss_test:0.02537, lr:4.05e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.112, tt:4185.604\n",
      "Ep:139, loss:0.00000, loss_test:0.02523, lr:4.01e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.107, tt:4214.992\n",
      "Ep:140, loss:0.00000, loss_test:0.02546, lr:3.97e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.102, tt:4244.386\n",
      "Ep:141, loss:0.00000, loss_test:0.02560, lr:3.93e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.096, tt:4273.625\n",
      "Ep:142, loss:0.00000, loss_test:0.02558, lr:3.89e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.089, tt:4302.723\n",
      "Ep:143, loss:0.00000, loss_test:0.02556, lr:3.86e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.080, tt:4331.504\n",
      "Ep:144, loss:0.00000, loss_test:0.02568, lr:3.82e-02, fs:0.81143 (r=0.717,p=0.934),  time:30.085, tt:4362.369\n",
      "Ep:145, loss:0.00000, loss_test:0.02587, lr:3.78e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.086, tt:4392.497\n",
      "Ep:146, loss:0.00000, loss_test:0.02570, lr:3.74e-02, fs:0.81818 (r=0.727,p=0.935),  time:30.079, tt:4421.637\n",
      "Ep:147, loss:0.00000, loss_test:0.02606, lr:3.70e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.073, tt:4450.812\n",
      "Ep:148, loss:0.00000, loss_test:0.02584, lr:3.67e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.076, tt:4481.375\n",
      "Ep:149, loss:0.00000, loss_test:0.02610, lr:3.63e-02, fs:0.80460 (r=0.707,p=0.933),  time:30.088, tt:4513.135\n",
      "Ep:150, loss:0.00000, loss_test:0.02598, lr:3.59e-02, fs:0.82286 (r=0.727,p=0.947),  time:30.078, tt:4541.710\n",
      "Ep:151, loss:0.00000, loss_test:0.02621, lr:3.56e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.078, tt:4571.849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.02611, lr:3.52e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.081, tt:4602.436\n",
      "Ep:153, loss:0.00000, loss_test:0.02643, lr:3.49e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.081, tt:4632.462\n",
      "Ep:154, loss:0.00000, loss_test:0.02631, lr:3.45e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.083, tt:4662.885\n",
      "Ep:155, loss:0.00000, loss_test:0.02618, lr:3.42e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.075, tt:4691.634\n",
      "Ep:156, loss:0.00000, loss_test:0.02633, lr:3.38e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.077, tt:4722.120\n",
      "Ep:157, loss:0.00000, loss_test:0.02652, lr:3.35e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.082, tt:4752.955\n",
      "Ep:158, loss:0.00000, loss_test:0.02632, lr:3.32e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.078, tt:4782.413\n",
      "Ep:159, loss:0.00000, loss_test:0.02666, lr:3.28e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.087, tt:4813.949\n",
      "Ep:160, loss:0.00000, loss_test:0.02642, lr:3.25e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.080, tt:4842.952\n",
      "Ep:161, loss:0.00000, loss_test:0.02672, lr:3.22e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.075, tt:4872.183\n",
      "Ep:162, loss:0.00000, loss_test:0.02657, lr:3.19e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.074, tt:4902.114\n",
      "Ep:163, loss:0.00000, loss_test:0.02661, lr:3.15e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.075, tt:4932.281\n",
      "Ep:164, loss:0.00000, loss_test:0.02678, lr:3.12e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.068, tt:4961.184\n",
      "Ep:165, loss:0.00000, loss_test:0.02671, lr:3.09e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.069, tt:4991.420\n",
      "Ep:166, loss:0.00000, loss_test:0.02687, lr:3.06e-02, fs:0.80233 (r=0.697,p=0.945),  time:30.087, tt:5024.456\n",
      "Ep:167, loss:0.00000, loss_test:0.02668, lr:3.03e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.085, tt:5054.351\n",
      "Ep:168, loss:0.00000, loss_test:0.02695, lr:3.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.094, tt:5085.889\n",
      "Ep:169, loss:0.00000, loss_test:0.02678, lr:2.97e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.095, tt:5116.120\n",
      "Ep:170, loss:0.00000, loss_test:0.02699, lr:2.94e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.098, tt:5146.677\n",
      "Ep:171, loss:0.00000, loss_test:0.02686, lr:2.91e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.105, tt:5178.108\n",
      "Ep:172, loss:0.00000, loss_test:0.02717, lr:2.88e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.104, tt:5208.034\n",
      "Ep:173, loss:0.00000, loss_test:0.02686, lr:2.85e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.105, tt:5238.195\n",
      "Ep:174, loss:0.00000, loss_test:0.02723, lr:2.82e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.095, tt:5266.602\n",
      "Ep:175, loss:0.00000, loss_test:0.02702, lr:2.80e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.096, tt:5296.952\n",
      "Ep:176, loss:0.00000, loss_test:0.02724, lr:2.77e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.105, tt:5328.599\n",
      "Ep:177, loss:0.00000, loss_test:0.02723, lr:2.74e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.102, tt:5358.202\n",
      "Ep:178, loss:0.00000, loss_test:0.02712, lr:2.71e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.098, tt:5387.479\n",
      "Ep:179, loss:0.00000, loss_test:0.02735, lr:2.69e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.102, tt:5418.346\n",
      "Ep:180, loss:0.00000, loss_test:0.02723, lr:2.66e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.105, tt:5449.042\n",
      "Ep:181, loss:0.00000, loss_test:0.02741, lr:2.63e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.114, tt:5480.798\n",
      "Ep:182, loss:0.00000, loss_test:0.02730, lr:2.61e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.116, tt:5511.207\n",
      "Ep:183, loss:0.00000, loss_test:0.02739, lr:2.58e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.118, tt:5541.642\n",
      "Ep:184, loss:0.00000, loss_test:0.02761, lr:2.55e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.118, tt:5571.913\n",
      "Ep:185, loss:0.00000, loss_test:0.02735, lr:2.53e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.129, tt:5603.969\n",
      "Ep:186, loss:0.00000, loss_test:0.02754, lr:2.50e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.127, tt:5633.709\n",
      "Ep:187, loss:0.00000, loss_test:0.02746, lr:2.48e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.127, tt:5663.949\n",
      "Ep:188, loss:0.00000, loss_test:0.02759, lr:2.45e-02, fs:0.80233 (r=0.697,p=0.945),  time:30.123, tt:5693.332\n",
      "Ep:189, loss:0.00000, loss_test:0.02775, lr:2.43e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.146, tt:5727.716\n",
      "Ep:190, loss:0.00000, loss_test:0.02757, lr:2.40e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.151, tt:5758.799\n",
      "Ep:191, loss:0.00000, loss_test:0.02764, lr:2.38e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.154, tt:5789.659\n",
      "Ep:192, loss:0.00000, loss_test:0.02774, lr:2.36e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.154, tt:5819.641\n",
      "Ep:193, loss:0.00000, loss_test:0.02763, lr:2.33e-02, fs:0.81609 (r=0.717,p=0.947),  time:30.155, tt:5850.109\n",
      "Ep:194, loss:0.00000, loss_test:0.02783, lr:2.31e-02, fs:0.77381 (r=0.657,p=0.942),  time:30.153, tt:5879.744\n",
      "Ep:195, loss:0.00000, loss_test:0.02772, lr:2.29e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.140, tt:5907.495\n",
      "Ep:196, loss:0.00000, loss_test:0.02778, lr:2.26e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.135, tt:5936.503\n",
      "Ep:197, loss:0.00000, loss_test:0.02779, lr:2.24e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.138, tt:5967.229\n",
      "Ep:198, loss:0.00000, loss_test:0.02788, lr:2.22e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.121, tt:5994.041\n",
      "Ep:199, loss:0.00000, loss_test:0.02792, lr:2.20e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.099, tt:6019.833\n",
      "Ep:200, loss:0.00000, loss_test:0.02779, lr:2.17e-02, fs:0.80925 (r=0.707,p=0.946),  time:30.088, tt:6047.780\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13465, lr:1.00e-02, fs:0.68085 (r=0.970,p=0.525),  time:27.362, tt:27.362\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13168, lr:1.00e-02, fs:0.68116 (r=0.949,p=0.531),  time:27.884, tt:55.768\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12861, lr:1.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:28.679, tt:86.038\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12651, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:29.144, tt:116.577\n",
      "Ep:4, loss:0.00025, loss_test:0.12553, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:29.516, tt:147.580\n",
      "Ep:5, loss:0.00025, loss_test:0.12471, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:29.550, tt:177.299\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12411, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:29.559, tt:206.911\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12318, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:29.532, tt:236.259\n",
      "Ep:8, loss:0.00023, loss_test:0.12160, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:29.461, tt:265.147\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11985, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:29.535, tt:295.346\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.11827, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:29.659, tt:326.244\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.11713, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:29.690, tt:356.281\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11674, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:29.696, tt:386.045\n",
      "Ep:13, loss:0.00022, loss_test:0.11532, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:29.799, tt:417.181\n",
      "Ep:14, loss:0.00022, loss_test:0.11394, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:29.900, tt:448.505\n",
      "Ep:15, loss:0.00021, loss_test:0.11322, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:29.916, tt:478.653\n",
      "Ep:16, loss:0.00021, loss_test:0.11262, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:29.933, tt:508.864\n",
      "Ep:17, loss:0.00021, loss_test:0.11161, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:29.956, tt:539.200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00020, loss_test:0.11030, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:29.937, tt:568.809\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.10931, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:29.960, tt:599.207\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.10840, lr:1.00e-02, fs:0.73640 (r=0.889,p=0.629),  time:30.021, tt:630.441\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.10705, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:29.992, tt:659.815\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.10599, lr:1.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:29.988, tt:689.713\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.10464, lr:1.00e-02, fs:0.75745 (r=0.899,p=0.654),  time:30.014, tt:720.345\n",
      "Ep:24, loss:0.00018, loss_test:0.10387, lr:1.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:29.988, tt:749.689\n",
      "Ep:25, loss:0.00018, loss_test:0.10225, lr:1.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:29.994, tt:779.837\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.10081, lr:1.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:30.011, tt:810.286\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.09996, lr:1.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:30.028, tt:840.790\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.09846, lr:1.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:30.018, tt:870.513\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.09774, lr:1.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:30.043, tt:901.285\n",
      "Ep:30, loss:0.00016, loss_test:0.09624, lr:1.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:30.082, tt:932.536\n",
      "Ep:31, loss:0.00016, loss_test:0.09463, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:30.078, tt:962.495\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.09346, lr:1.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:30.101, tt:993.346\n",
      "Ep:33, loss:0.00015, loss_test:0.09297, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:30.058, tt:1021.989\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.09255, lr:1.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:30.042, tt:1051.485\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.09160, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.042, tt:1081.529\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.09067, lr:1.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:30.004, tt:1110.142\n",
      "Ep:37, loss:0.00013, loss_test:0.09085, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:29.977, tt:1139.141\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.08969, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:29.982, tt:1169.279\n",
      "Ep:39, loss:0.00012, loss_test:0.08937, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:30.005, tt:1200.200\n",
      "Ep:40, loss:0.00012, loss_test:0.08799, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:30.005, tt:1230.203\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.08825, lr:1.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:30.043, tt:1261.794\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.08770, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:30.070, tt:1293.005\n",
      "Ep:43, loss:0.00010, loss_test:0.08610, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:30.049, tt:1322.168\n",
      "Ep:44, loss:0.00010, loss_test:0.08687, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:30.058, tt:1352.632\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.08573, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.075, tt:1383.437\n",
      "Ep:46, loss:0.00009, loss_test:0.08470, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:30.079, tt:1413.736\n",
      "Ep:47, loss:0.00009, loss_test:0.08753, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:30.105, tt:1445.063\n",
      "Ep:48, loss:0.00009, loss_test:0.08337, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:30.117, tt:1475.710\n",
      "Ep:49, loss:0.00009, loss_test:0.08537, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.131, tt:1506.569\n",
      "Ep:50, loss:0.00008, loss_test:0.08800, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:30.154, tt:1537.846\n",
      "Ep:51, loss:0.00008, loss_test:0.08315, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:30.192, tt:1569.972\n",
      "Ep:52, loss:0.00008, loss_test:0.08674, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:30.207, tt:1600.979\n",
      "Ep:53, loss:0.00007, loss_test:0.08265, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.214, tt:1631.546\n",
      "Ep:54, loss:0.00007, loss_test:0.08370, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.232, tt:1662.742\n",
      "Ep:55, loss:0.00007, loss_test:0.08357, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.259, tt:1694.506\n",
      "Ep:56, loss:0.00007, loss_test:0.08109, lr:9.90e-03, fs:0.80808 (r=0.808,p=0.808),  time:30.274, tt:1725.629\n",
      "Ep:57, loss:0.00006, loss_test:0.08473, lr:9.80e-03, fs:0.78000 (r=0.788,p=0.772),  time:30.302, tt:1757.524\n",
      "Ep:58, loss:0.00006, loss_test:0.07941, lr:9.70e-03, fs:0.81000 (r=0.818,p=0.802),  time:30.334, tt:1789.736\n",
      "Ep:59, loss:0.00006, loss_test:0.08244, lr:9.61e-03, fs:0.77833 (r=0.798,p=0.760),  time:30.355, tt:1821.291\n",
      "Ep:60, loss:0.00006, loss_test:0.07891, lr:9.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:30.371, tt:1852.607\n",
      "Ep:61, loss:0.00005, loss_test:0.08286, lr:9.41e-03, fs:0.77387 (r=0.778,p=0.770),  time:30.364, tt:1882.590\n",
      "Ep:62, loss:0.00005, loss_test:0.07978, lr:9.32e-03, fs:0.78075 (r=0.737,p=0.830),  time:30.391, tt:1914.632\n",
      "Ep:63, loss:0.00005, loss_test:0.08068, lr:9.23e-03, fs:0.78351 (r=0.768,p=0.800),  time:30.388, tt:1944.845\n",
      "Ep:64, loss:0.00005, loss_test:0.07789, lr:9.14e-03, fs:0.80000 (r=0.808,p=0.792),  time:30.409, tt:1976.604\n",
      "Ep:65, loss:0.00005, loss_test:0.08136, lr:9.04e-03, fs:0.77660 (r=0.737,p=0.820),  time:30.407, tt:2006.875\n",
      "Ep:66, loss:0.00005, loss_test:0.07669, lr:8.95e-03, fs:0.80612 (r=0.798,p=0.814),  time:30.411, tt:2037.518\n",
      "Ep:67, loss:0.00004, loss_test:0.07982, lr:8.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:30.400, tt:2067.178\n",
      "Ep:68, loss:0.00005, loss_test:0.07750, lr:8.78e-03, fs:0.76596 (r=0.727,p=0.809),  time:30.380, tt:2096.233\n",
      "Ep:69, loss:0.00004, loss_test:0.07853, lr:8.69e-03, fs:0.77320 (r=0.758,p=0.789),  time:30.359, tt:2125.096\n",
      "Ep:70, loss:0.00004, loss_test:0.07620, lr:8.60e-03, fs:0.81443 (r=0.798,p=0.832),  time:30.371, tt:2156.329\n",
      "Ep:71, loss:0.00004, loss_test:0.07881, lr:8.51e-03, fs:0.77005 (r=0.727,p=0.818),  time:30.382, tt:2187.513\n",
      "Ep:72, loss:0.00004, loss_test:0.07613, lr:8.43e-03, fs:0.77005 (r=0.727,p=0.818),  time:30.390, tt:2218.440\n",
      "Ep:73, loss:0.00004, loss_test:0.07633, lr:8.35e-03, fs:0.76596 (r=0.727,p=0.809),  time:30.402, tt:2249.779\n",
      "Ep:74, loss:0.00004, loss_test:0.07683, lr:8.26e-03, fs:0.78261 (r=0.727,p=0.847),  time:30.409, tt:2280.702\n",
      "Ep:75, loss:0.00004, loss_test:0.07530, lr:8.18e-03, fs:0.77487 (r=0.747,p=0.804),  time:30.445, tt:2313.790\n",
      "Ep:76, loss:0.00004, loss_test:0.07466, lr:8.10e-03, fs:0.77838 (r=0.727,p=0.837),  time:30.459, tt:2345.374\n",
      "Ep:77, loss:0.00004, loss_test:0.07727, lr:8.02e-03, fs:0.78261 (r=0.727,p=0.847),  time:30.473, tt:2376.921\n",
      "Ep:78, loss:0.00003, loss_test:0.07458, lr:7.94e-03, fs:0.80423 (r=0.768,p=0.844),  time:30.475, tt:2407.551\n",
      "Ep:79, loss:0.00003, loss_test:0.07645, lr:7.86e-03, fs:0.77838 (r=0.727,p=0.837),  time:30.476, tt:2438.119\n",
      "Ep:80, loss:0.00003, loss_test:0.07567, lr:7.78e-03, fs:0.78261 (r=0.727,p=0.847),  time:30.479, tt:2468.834\n",
      "Ep:81, loss:0.00003, loss_test:0.07400, lr:7.70e-03, fs:0.77419 (r=0.727,p=0.828),  time:30.459, tt:2497.669\n",
      "Ep:82, loss:0.00003, loss_test:0.07515, lr:7.62e-03, fs:0.77838 (r=0.727,p=0.837),  time:30.456, tt:2527.817\n",
      "Ep:83, loss:0.00003, loss_test:0.07409, lr:7.55e-03, fs:0.78261 (r=0.727,p=0.847),  time:30.463, tt:2558.908\n",
      "Ep:84, loss:0.00003, loss_test:0.07414, lr:7.47e-03, fs:0.78261 (r=0.727,p=0.847),  time:30.453, tt:2588.467\n",
      "Ep:85, loss:0.00003, loss_test:0.07386, lr:7.40e-03, fs:0.78689 (r=0.727,p=0.857),  time:30.455, tt:2619.132\n",
      "Ep:86, loss:0.00003, loss_test:0.07358, lr:7.32e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.445, tt:2648.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:87, loss:0.00003, loss_test:0.07362, lr:7.25e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.450, tt:2679.620\n",
      "Ep:88, loss:0.00003, loss_test:0.07277, lr:7.18e-03, fs:0.77838 (r=0.727,p=0.837),  time:30.448, tt:2709.863\n",
      "Ep:89, loss:0.00003, loss_test:0.07395, lr:7.11e-03, fs:0.78689 (r=0.727,p=0.857),  time:30.460, tt:2741.398\n",
      "Ep:90, loss:0.00003, loss_test:0.07332, lr:7.03e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.456, tt:2771.512\n",
      "Ep:91, loss:0.00003, loss_test:0.07295, lr:6.96e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.460, tt:2802.308\n",
      "Ep:92, loss:0.00003, loss_test:0.07409, lr:6.89e-03, fs:0.78261 (r=0.727,p=0.847),  time:30.460, tt:2832.780\n",
      "Ep:93, loss:0.00003, loss_test:0.07307, lr:6.83e-03, fs:0.80447 (r=0.727,p=0.900),  time:30.459, tt:2863.128\n",
      "Ep:94, loss:0.00003, loss_test:0.07318, lr:6.76e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.452, tt:2892.927\n",
      "Ep:95, loss:0.00002, loss_test:0.07297, lr:6.69e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.462, tt:2924.310\n",
      "Ep:96, loss:0.00002, loss_test:0.07301, lr:6.62e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.491, tt:2957.632\n",
      "Ep:97, loss:0.00002, loss_test:0.07300, lr:6.56e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.501, tt:2989.120\n",
      "Ep:98, loss:0.00002, loss_test:0.07179, lr:6.49e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.507, tt:3020.147\n",
      "Ep:99, loss:0.00002, loss_test:0.07364, lr:6.43e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.515, tt:3051.495\n",
      "Ep:100, loss:0.00002, loss_test:0.07348, lr:6.36e-03, fs:0.80000 (r=0.727,p=0.889),  time:30.522, tt:3082.722\n",
      "Ep:101, loss:0.00002, loss_test:0.07175, lr:6.30e-03, fs:0.81111 (r=0.737,p=0.901),  time:30.526, tt:3113.631\n",
      "Ep:102, loss:0.00002, loss_test:0.07408, lr:6.24e-03, fs:0.79121 (r=0.727,p=0.867),  time:30.540, tt:3145.670\n",
      "Ep:103, loss:0.00002, loss_test:0.07311, lr:6.17e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.550, tt:3177.196\n",
      "Ep:104, loss:0.00002, loss_test:0.07247, lr:6.11e-03, fs:0.80447 (r=0.727,p=0.900),  time:30.574, tt:3210.308\n",
      "Ep:105, loss:0.00002, loss_test:0.07248, lr:6.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.580, tt:3241.511\n",
      "Ep:106, loss:0.00002, loss_test:0.07312, lr:5.99e-03, fs:0.80447 (r=0.727,p=0.900),  time:30.603, tt:3274.470\n",
      "Ep:107, loss:0.00002, loss_test:0.07287, lr:5.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.613, tt:3306.170\n",
      "Ep:108, loss:0.00002, loss_test:0.07235, lr:5.87e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.622, tt:3337.755\n",
      "Ep:109, loss:0.00002, loss_test:0.07303, lr:5.81e-03, fs:0.79558 (r=0.727,p=0.878),  time:30.620, tt:3368.182\n",
      "Ep:110, loss:0.00002, loss_test:0.07213, lr:5.75e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.637, tt:3400.753\n",
      "Ep:111, loss:0.00002, loss_test:0.07221, lr:5.70e-03, fs:0.80000 (r=0.727,p=0.889),  time:30.663, tt:3434.227\n",
      "Ep:112, loss:0.00002, loss_test:0.07254, lr:5.64e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.681, tt:3466.974\n",
      "Ep:113, loss:0.00002, loss_test:0.07184, lr:5.58e-03, fs:0.80447 (r=0.727,p=0.900),  time:30.697, tt:3499.425\n",
      "Ep:114, loss:0.00002, loss_test:0.07228, lr:5.53e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.715, tt:3532.252\n",
      "Ep:115, loss:0.00002, loss_test:0.07252, lr:5.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.728, tt:3564.444\n",
      "Ep:116, loss:0.00002, loss_test:0.07236, lr:5.42e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.737, tt:3596.264\n",
      "Ep:117, loss:0.00002, loss_test:0.07182, lr:5.36e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.752, tt:3628.684\n",
      "Ep:118, loss:0.00002, loss_test:0.07193, lr:5.31e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.779, tt:3662.652\n",
      "Ep:119, loss:0.00002, loss_test:0.07230, lr:5.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.789, tt:3694.727\n",
      "Ep:120, loss:0.00002, loss_test:0.07145, lr:5.20e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.795, tt:3726.218\n",
      "Ep:121, loss:0.00002, loss_test:0.07301, lr:5.15e-03, fs:0.80000 (r=0.727,p=0.889),  time:30.810, tt:3758.877\n",
      "Ep:122, loss:0.00002, loss_test:0.07178, lr:5.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.818, tt:3790.649\n",
      "Ep:123, loss:0.00002, loss_test:0.07226, lr:5.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.829, tt:3822.756\n",
      "Ep:124, loss:0.00002, loss_test:0.07114, lr:5.00e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.843, tt:3855.388\n",
      "Ep:125, loss:0.00002, loss_test:0.07220, lr:4.95e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.847, tt:3886.703\n",
      "Ep:126, loss:0.00002, loss_test:0.07192, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:30.857, tt:3918.886\n",
      "Ep:127, loss:0.00002, loss_test:0.07248, lr:4.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.855, tt:3949.413\n",
      "Ep:128, loss:0.00002, loss_test:0.07200, lr:4.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.860, tt:3980.920\n",
      "Ep:129, loss:0.00002, loss_test:0.07295, lr:4.75e-03, fs:0.80447 (r=0.727,p=0.900),  time:30.860, tt:4011.856\n",
      "Ep:130, loss:0.00002, loss_test:0.07275, lr:4.71e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.871, tt:4044.049\n",
      "Ep:131, loss:0.00002, loss_test:0.07216, lr:4.66e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.869, tt:4074.754\n",
      "Ep:132, loss:0.00002, loss_test:0.07273, lr:4.61e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.870, tt:4105.679\n",
      "Ep:133, loss:0.00002, loss_test:0.07194, lr:4.57e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.870, tt:4136.622\n",
      "Ep:134, loss:0.00001, loss_test:0.07235, lr:4.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.885, tt:4169.453\n",
      "Ep:135, loss:0.00001, loss_test:0.07199, lr:4.48e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.896, tt:4201.917\n",
      "Ep:136, loss:0.00001, loss_test:0.07252, lr:4.43e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.906, tt:4234.070\n",
      "Ep:137, loss:0.00001, loss_test:0.07276, lr:4.39e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.923, tt:4267.381\n",
      "Ep:138, loss:0.00001, loss_test:0.07219, lr:4.34e-03, fs:0.80447 (r=0.727,p=0.900),  time:30.935, tt:4299.937\n",
      "Ep:139, loss:0.00001, loss_test:0.07183, lr:4.30e-03, fs:0.81818 (r=0.727,p=0.935),  time:30.948, tt:4332.651\n",
      "Ep:140, loss:0.00001, loss_test:0.07306, lr:4.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.974, tt:4367.335\n",
      "Ep:141, loss:0.00001, loss_test:0.07196, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.976, tt:4398.655\n",
      "Ep:142, loss:0.00001, loss_test:0.07235, lr:4.17e-03, fs:0.81356 (r=0.727,p=0.923),  time:30.994, tt:4432.070\n",
      "Ep:143, loss:0.00001, loss_test:0.07333, lr:4.13e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.005, tt:4464.729\n",
      "Ep:144, loss:0.00001, loss_test:0.07207, lr:4.09e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.019, tt:4497.698\n",
      "Ep:145, loss:0.00001, loss_test:0.07317, lr:4.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.038, tt:4531.580\n",
      "Ep:146, loss:0.00001, loss_test:0.07254, lr:4.01e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.042, tt:4563.216\n",
      "Ep:147, loss:0.00001, loss_test:0.07233, lr:3.97e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.046, tt:4594.839\n",
      "Ep:148, loss:0.00001, loss_test:0.07331, lr:3.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.058, tt:4627.570\n",
      "Ep:149, loss:0.00001, loss_test:0.07225, lr:3.89e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.059, tt:4658.794\n",
      "Ep:150, loss:0.00001, loss_test:0.07282, lr:3.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.067, tt:4691.141\n",
      "Ep:151, loss:0.00001, loss_test:0.07316, lr:3.81e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.056, tt:4720.506\n",
      "Ep:152, loss:0.00001, loss_test:0.07255, lr:3.77e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.049, tt:4750.441\n",
      "Ep:153, loss:0.00001, loss_test:0.07261, lr:3.73e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.042, tt:4780.426\n",
      "Ep:154, loss:0.00001, loss_test:0.07264, lr:3.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.049, tt:4812.629\n",
      "Ep:155, loss:0.00001, loss_test:0.07294, lr:3.66e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.059, tt:4845.196\n",
      "Ep:156, loss:0.00001, loss_test:0.07278, lr:3.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.063, tt:4876.962\n",
      "Ep:157, loss:0.00001, loss_test:0.07301, lr:3.59e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.068, tt:4908.730\n",
      "Ep:158, loss:0.00001, loss_test:0.07324, lr:3.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.072, tt:4940.426\n",
      "Ep:159, loss:0.00001, loss_test:0.07294, lr:3.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.068, tt:4970.951\n",
      "Ep:160, loss:0.00001, loss_test:0.07297, lr:3.48e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.071, tt:5002.404\n",
      "Ep:161, loss:0.00001, loss_test:0.07294, lr:3.45e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.067, tt:5032.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:162, loss:0.00001, loss_test:0.07331, lr:3.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.064, tt:5063.395\n",
      "Ep:163, loss:0.00001, loss_test:0.07276, lr:3.38e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.064, tt:5094.439\n",
      "Ep:164, loss:0.00001, loss_test:0.07281, lr:3.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.057, tt:5124.356\n",
      "Ep:165, loss:0.00001, loss_test:0.07284, lr:3.31e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.059, tt:5155.755\n",
      "Ep:166, loss:0.00001, loss_test:0.07286, lr:3.28e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.057, tt:5186.533\n",
      "Ep:167, loss:0.00001, loss_test:0.07298, lr:3.24e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.060, tt:5218.145\n",
      "Ep:168, loss:0.00001, loss_test:0.07318, lr:3.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.061, tt:5249.320\n",
      "Ep:169, loss:0.00001, loss_test:0.07296, lr:3.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.055, tt:5279.290\n",
      "Ep:170, loss:0.00001, loss_test:0.07328, lr:3.15e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.049, tt:5309.415\n",
      "Ep:171, loss:0.00001, loss_test:0.07327, lr:3.12e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.048, tt:5340.273\n",
      "Ep:172, loss:0.00001, loss_test:0.07360, lr:3.09e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.040, tt:5369.862\n",
      "Ep:173, loss:0.00001, loss_test:0.07335, lr:3.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.040, tt:5400.998\n",
      "Ep:174, loss:0.00001, loss_test:0.07318, lr:3.02e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.045, tt:5432.831\n",
      "Ep:175, loss:0.00001, loss_test:0.07383, lr:2.99e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.042, tt:5463.431\n",
      "Ep:176, loss:0.00001, loss_test:0.07356, lr:2.96e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.038, tt:5493.769\n",
      "Ep:177, loss:0.00001, loss_test:0.07326, lr:2.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.038, tt:5524.843\n",
      "Ep:178, loss:0.00001, loss_test:0.07405, lr:2.90e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.030, tt:5554.330\n",
      "Ep:179, loss:0.00001, loss_test:0.07333, lr:2.88e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.037, tt:5586.634\n",
      "Ep:180, loss:0.00001, loss_test:0.07361, lr:2.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.033, tt:5616.895\n",
      "Ep:181, loss:0.00001, loss_test:0.07347, lr:2.82e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.019, tt:5645.466\n",
      "Ep:182, loss:0.00001, loss_test:0.07368, lr:2.79e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.017, tt:5676.103\n",
      "Ep:183, loss:0.00001, loss_test:0.07393, lr:2.76e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.028, tt:5709.187\n",
      "Ep:184, loss:0.00001, loss_test:0.07362, lr:2.73e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.030, tt:5740.595\n",
      "Ep:185, loss:0.00001, loss_test:0.07366, lr:2.71e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.025, tt:5770.622\n",
      "Ep:186, loss:0.00001, loss_test:0.07401, lr:2.68e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.024, tt:5801.478\n",
      "Ep:187, loss:0.00001, loss_test:0.07401, lr:2.65e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.022, tt:5832.106\n",
      "Ep:188, loss:0.00001, loss_test:0.07353, lr:2.63e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.030, tt:5864.721\n",
      "Ep:189, loss:0.00001, loss_test:0.07417, lr:2.60e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.033, tt:5896.337\n",
      "Ep:190, loss:0.00001, loss_test:0.07407, lr:2.57e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.038, tt:5928.348\n",
      "Ep:191, loss:0.00001, loss_test:0.07342, lr:2.55e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.041, tt:5959.948\n",
      "Ep:192, loss:0.00001, loss_test:0.07414, lr:2.52e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.046, tt:5991.898\n",
      "Ep:193, loss:0.00001, loss_test:0.07388, lr:2.50e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.050, tt:6023.610\n",
      "Ep:194, loss:0.00001, loss_test:0.07390, lr:2.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.057, tt:6056.206\n",
      "Ep:195, loss:0.00001, loss_test:0.07400, lr:2.45e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.064, tt:6088.598\n",
      "Ep:196, loss:0.00001, loss_test:0.07358, lr:2.42e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.054, tt:6117.691\n",
      "Ep:197, loss:0.00001, loss_test:0.07429, lr:2.40e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.045, tt:6146.989\n",
      "Ep:198, loss:0.00001, loss_test:0.07426, lr:2.38e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.020, tt:6173.043\n",
      "Ep:199, loss:0.00001, loss_test:0.07379, lr:2.35e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.006, tt:6201.201\n",
      "Ep:200, loss:0.00001, loss_test:0.07404, lr:2.33e-03, fs:0.80899 (r=0.727,p=0.911),  time:30.985, tt:6228.045\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02137, lr:6.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:22.769, tt:22.769\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02445, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.642, tt:49.284\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02662, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.831, tt:83.492\n",
      "Ep:3, loss:0.00005, loss_test:0.02692, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.126, tt:124.503\n",
      "Ep:4, loss:0.00005, loss_test:0.02642, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.271, tt:166.354\n",
      "Ep:5, loss:0.00005, loss_test:0.02511, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.597, tt:207.581\n",
      "Ep:6, loss:0.00005, loss_test:0.02336, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:35.340, tt:247.383\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02176, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:35.937, tt:287.497\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02075, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:36.581, tt:329.231\n",
      "Ep:9, loss:0.00004, loss_test:0.02042, lr:6.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:36.953, tt:369.534\n",
      "Ep:10, loss:0.00004, loss_test:0.02002, lr:6.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:37.235, tt:409.589\n",
      "Ep:11, loss:0.00004, loss_test:0.01923, lr:6.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:37.667, tt:452.003\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01857, lr:6.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:38.023, tt:494.295\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01826, lr:6.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:38.343, tt:536.806\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01794, lr:6.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:38.532, tt:577.982\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:38.716, tt:619.455\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01707, lr:6.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:38.831, tt:660.126\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01676, lr:6.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:38.965, tt:701.368\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01653, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:39.009, tt:741.164\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01630, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:39.156, tt:783.116\n",
      "Ep:20, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:39.148, tt:822.115\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:39.134, tt:860.952\n",
      "Ep:22, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.76151 (r=0.919,p=0.650),  time:39.177, tt:901.071\n",
      "Ep:23, loss:0.00002, loss_test:0.01549, lr:6.00e-02, fs:0.76793 (r=0.919,p=0.659),  time:39.263, tt:942.315\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.77778 (r=0.919,p=0.674),  time:39.262, tt:981.561\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:39.317, tt:1022.232\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:39.370, tt:1062.996\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:39.385, tt:1102.791\n",
      "Ep:28, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:39.355, tt:1141.302\n",
      "Ep:29, loss:0.00002, loss_test:0.01466, lr:6.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:39.348, tt:1180.429\n",
      "Ep:30, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:39.380, tt:1220.791\n",
      "Ep:31, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:39.373, tt:1259.943\n",
      "Ep:32, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:39.395, tt:1300.051\n",
      "Ep:33, loss:0.00002, loss_test:0.01451, lr:6.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:39.435, tt:1340.792\n",
      "Ep:34, loss:0.00002, loss_test:0.01448, lr:6.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:39.493, tt:1382.247\n",
      "Ep:35, loss:0.00002, loss_test:0.01446, lr:6.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:39.473, tt:1421.027\n",
      "Ep:36, loss:0.00002, loss_test:0.01448, lr:6.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:39.540, tt:1462.994\n",
      "Ep:37, loss:0.00002, loss_test:0.01448, lr:6.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:39.591, tt:1504.446\n",
      "Ep:38, loss:0.00001, loss_test:0.01452, lr:5.94e-02, fs:0.74757 (r=0.778,p=0.720),  time:39.613, tt:1544.905\n",
      "Ep:39, loss:0.00001, loss_test:0.01456, lr:5.88e-02, fs:0.75362 (r=0.788,p=0.722),  time:39.659, tt:1586.344\n",
      "Ep:40, loss:0.00001, loss_test:0.01458, lr:5.82e-02, fs:0.76098 (r=0.788,p=0.736),  time:39.672, tt:1626.535\n",
      "Ep:41, loss:0.00001, loss_test:0.01462, lr:5.76e-02, fs:0.75490 (r=0.778,p=0.733),  time:39.739, tt:1669.018\n",
      "Ep:42, loss:0.00001, loss_test:0.01466, lr:5.71e-02, fs:0.75862 (r=0.778,p=0.740),  time:39.778, tt:1710.449\n",
      "Ep:43, loss:0.00001, loss_test:0.01470, lr:5.65e-02, fs:0.76238 (r=0.778,p=0.748),  time:39.794, tt:1750.937\n",
      "Ep:44, loss:0.00001, loss_test:0.01476, lr:5.59e-02, fs:0.77000 (r=0.778,p=0.762),  time:39.778, tt:1790.016\n",
      "Ep:45, loss:0.00001, loss_test:0.01482, lr:5.54e-02, fs:0.77000 (r=0.778,p=0.762),  time:39.758, tt:1828.866\n",
      "Ep:46, loss:0.00001, loss_test:0.01489, lr:5.48e-02, fs:0.76768 (r=0.768,p=0.768),  time:39.746, tt:1868.073\n",
      "Ep:47, loss:0.00001, loss_test:0.01493, lr:5.43e-02, fs:0.76768 (r=0.768,p=0.768),  time:39.742, tt:1907.634\n",
      "Ep:48, loss:0.00001, loss_test:0.01493, lr:5.37e-02, fs:0.76768 (r=0.768,p=0.768),  time:39.724, tt:1946.473\n",
      "Ep:49, loss:0.00001, loss_test:0.01501, lr:5.32e-02, fs:0.77157 (r=0.768,p=0.776),  time:39.718, tt:1985.881\n",
      "Ep:50, loss:0.00001, loss_test:0.01508, lr:5.27e-02, fs:0.77551 (r=0.768,p=0.784),  time:39.701, tt:2024.729\n",
      "Ep:51, loss:0.00001, loss_test:0.01516, lr:5.21e-02, fs:0.77949 (r=0.768,p=0.792),  time:39.704, tt:2064.621\n",
      "Ep:52, loss:0.00001, loss_test:0.01522, lr:5.16e-02, fs:0.78351 (r=0.768,p=0.800),  time:39.697, tt:2103.955\n",
      "Ep:53, loss:0.00001, loss_test:0.01529, lr:5.11e-02, fs:0.78351 (r=0.768,p=0.800),  time:39.825, tt:2150.526\n",
      "Ep:54, loss:0.00001, loss_test:0.01540, lr:5.06e-02, fs:0.79581 (r=0.768,p=0.826),  time:39.851, tt:2191.792\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01546, lr:5.06e-02, fs:0.80423 (r=0.768,p=0.844),  time:39.829, tt:2230.446\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01555, lr:5.06e-02, fs:0.80851 (r=0.768,p=0.854),  time:39.796, tt:2268.388\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01561, lr:5.06e-02, fs:0.80851 (r=0.768,p=0.854),  time:39.790, tt:2307.825\n",
      "Ep:58, loss:0.00001, loss_test:0.01569, lr:5.06e-02, fs:0.80851 (r=0.768,p=0.854),  time:39.814, tt:2349.015\n",
      "Ep:59, loss:0.00001, loss_test:0.01576, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.834, tt:2390.010\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01583, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.843, tt:2430.396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01593, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.838, tt:2469.967\n",
      "Ep:62, loss:0.00001, loss_test:0.01602, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.853, tt:2510.753\n",
      "Ep:63, loss:0.00001, loss_test:0.01613, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.884, tt:2552.571\n",
      "Ep:64, loss:0.00001, loss_test:0.01622, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.885, tt:2592.494\n",
      "Ep:65, loss:0.00001, loss_test:0.01632, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.861, tt:2630.811\n",
      "Ep:66, loss:0.00001, loss_test:0.01637, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.849, tt:2669.869\n",
      "Ep:67, loss:0.00001, loss_test:0.01645, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.853, tt:2709.973\n",
      "Ep:68, loss:0.00001, loss_test:0.01660, lr:5.06e-02, fs:0.81283 (r=0.768,p=0.864),  time:39.825, tt:2747.956\n",
      "Ep:69, loss:0.00001, loss_test:0.01669, lr:5.06e-02, fs:0.80645 (r=0.758,p=0.862),  time:39.849, tt:2789.427\n",
      "Ep:70, loss:0.00001, loss_test:0.01676, lr:5.06e-02, fs:0.80645 (r=0.758,p=0.862),  time:39.939, tt:2835.651\n",
      "Ep:71, loss:0.00001, loss_test:0.01685, lr:5.01e-02, fs:0.81081 (r=0.758,p=0.872),  time:39.944, tt:2875.962\n",
      "Ep:72, loss:0.00001, loss_test:0.01697, lr:4.96e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.963, tt:2917.321\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01709, lr:4.96e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.978, tt:2958.397\n",
      "Ep:74, loss:0.00001, loss_test:0.01721, lr:4.96e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.990, tt:2999.219\n",
      "Ep:75, loss:0.00001, loss_test:0.01728, lr:4.96e-02, fs:0.81967 (r=0.758,p=0.893),  time:40.003, tt:3040.206\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01736, lr:4.96e-02, fs:0.80663 (r=0.737,p=0.890),  time:39.984, tt:3078.767\n",
      "Ep:77, loss:0.00001, loss_test:0.01749, lr:4.96e-02, fs:0.80000 (r=0.727,p=0.889),  time:39.989, tt:3119.123\n",
      "Ep:78, loss:0.00001, loss_test:0.01758, lr:4.96e-02, fs:0.80000 (r=0.727,p=0.889),  time:39.984, tt:3158.734\n",
      "Ep:79, loss:0.00001, loss_test:0.01766, lr:4.96e-02, fs:0.78652 (r=0.707,p=0.886),  time:39.994, tt:3199.542\n",
      "Ep:80, loss:0.00001, loss_test:0.01778, lr:4.96e-02, fs:0.78652 (r=0.707,p=0.886),  time:39.993, tt:3239.405\n",
      "Ep:81, loss:0.00001, loss_test:0.01788, lr:4.96e-02, fs:0.76571 (r=0.677,p=0.882),  time:40.000, tt:3279.983\n",
      "Ep:82, loss:0.00001, loss_test:0.01796, lr:4.96e-02, fs:0.76571 (r=0.677,p=0.882),  time:40.014, tt:3321.135\n",
      "Ep:83, loss:0.00001, loss_test:0.01805, lr:4.96e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.000, tt:3359.962\n",
      "Ep:84, loss:0.00001, loss_test:0.01817, lr:4.96e-02, fs:0.74854 (r=0.646,p=0.889),  time:39.982, tt:3398.489\n",
      "Ep:85, loss:0.00001, loss_test:0.01826, lr:4.96e-02, fs:0.74118 (r=0.636,p=0.887),  time:39.979, tt:3438.209\n",
      "Ep:86, loss:0.00001, loss_test:0.01838, lr:4.96e-02, fs:0.74118 (r=0.636,p=0.887),  time:39.981, tt:3478.329\n",
      "Ep:87, loss:0.00001, loss_test:0.01849, lr:4.91e-02, fs:0.74118 (r=0.636,p=0.887),  time:39.974, tt:3517.708\n",
      "Ep:88, loss:0.00001, loss_test:0.01858, lr:4.86e-02, fs:0.73373 (r=0.626,p=0.886),  time:39.977, tt:3557.917\n",
      "Ep:89, loss:0.00001, loss_test:0.01869, lr:4.81e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.000, tt:3600.033\n",
      "Ep:90, loss:0.00001, loss_test:0.01878, lr:4.76e-02, fs:0.73810 (r=0.626,p=0.899),  time:39.990, tt:3639.063\n",
      "Ep:91, loss:0.00000, loss_test:0.01889, lr:4.71e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.012, tt:3681.087\n",
      "Ep:92, loss:0.00000, loss_test:0.01899, lr:4.67e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.024, tt:3722.244\n",
      "Ep:93, loss:0.00000, loss_test:0.01913, lr:4.62e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.025, tt:3762.351\n",
      "Ep:94, loss:0.00000, loss_test:0.01921, lr:4.57e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.037, tt:3803.545\n",
      "Ep:95, loss:0.00000, loss_test:0.01929, lr:4.53e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.074, tt:3847.096\n",
      "Ep:96, loss:0.00000, loss_test:0.01940, lr:4.48e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.070, tt:3886.763\n",
      "Ep:97, loss:0.00000, loss_test:0.01946, lr:4.44e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.081, tt:3927.919\n",
      "Ep:98, loss:0.00000, loss_test:0.01957, lr:4.39e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.078, tt:3967.674\n",
      "Ep:99, loss:0.00000, loss_test:0.01967, lr:4.35e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.092, tt:4009.185\n",
      "Ep:100, loss:0.00000, loss_test:0.01974, lr:4.31e-02, fs:0.73810 (r=0.626,p=0.899),  time:40.080, tt:4048.038\n",
      "Ep:101, loss:0.00000, loss_test:0.01980, lr:4.26e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.093, tt:4089.448\n",
      "Ep:102, loss:0.00000, loss_test:0.01989, lr:4.22e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.097, tt:4130.010\n",
      "Ep:103, loss:0.00000, loss_test:0.02001, lr:4.18e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.102, tt:4170.579\n",
      "Ep:104, loss:0.00000, loss_test:0.02010, lr:4.14e-02, fs:0.74251 (r=0.626,p=0.912),  time:40.089, tt:4209.353\n",
      "Ep:105, loss:0.00000, loss_test:0.02014, lr:4.10e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.095, tt:4250.080\n",
      "Ep:106, loss:0.00000, loss_test:0.02021, lr:4.05e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.098, tt:4290.480\n",
      "Ep:107, loss:0.00000, loss_test:0.02031, lr:4.01e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.108, tt:4331.610\n",
      "Ep:108, loss:0.00000, loss_test:0.02039, lr:3.97e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.103, tt:4371.194\n",
      "Ep:109, loss:0.00000, loss_test:0.02048, lr:3.93e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.112, tt:4412.272\n",
      "Ep:110, loss:0.00000, loss_test:0.02056, lr:3.89e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.094, tt:4450.443\n",
      "Ep:111, loss:0.00000, loss_test:0.02061, lr:3.86e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.109, tt:4492.242\n",
      "Ep:112, loss:0.00000, loss_test:0.02066, lr:3.82e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.103, tt:4531.649\n",
      "Ep:113, loss:0.00000, loss_test:0.02074, lr:3.78e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.095, tt:4570.852\n",
      "Ep:114, loss:0.00000, loss_test:0.02083, lr:3.74e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.099, tt:4611.332\n",
      "Ep:115, loss:0.00000, loss_test:0.02088, lr:3.70e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.110, tt:4652.723\n",
      "Ep:116, loss:0.00000, loss_test:0.02094, lr:3.67e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.117, tt:4693.698\n",
      "Ep:117, loss:0.00000, loss_test:0.02101, lr:3.63e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.129, tt:4735.184\n",
      "Ep:118, loss:0.00000, loss_test:0.02108, lr:3.59e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.128, tt:4775.283\n",
      "Ep:119, loss:0.00000, loss_test:0.02116, lr:3.56e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.137, tt:4816.450\n",
      "Ep:120, loss:0.00000, loss_test:0.02120, lr:3.52e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.140, tt:4856.884\n",
      "Ep:121, loss:0.00000, loss_test:0.02128, lr:3.49e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.165, tt:4900.075\n",
      "Ep:122, loss:0.00000, loss_test:0.02135, lr:3.45e-02, fs:0.74699 (r=0.626,p=0.925),  time:40.168, tt:4940.720\n",
      "Ep:123, loss:0.00000, loss_test:0.02141, lr:3.42e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.182, tt:4982.560\n",
      "Ep:124, loss:0.00000, loss_test:0.02147, lr:3.38e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.199, tt:5024.895\n",
      "Ep:125, loss:0.00000, loss_test:0.02152, lr:3.35e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.182, tt:5062.965\n",
      "Ep:126, loss:0.00000, loss_test:0.02159, lr:3.32e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.175, tt:5102.257\n",
      "Ep:127, loss:0.00000, loss_test:0.02167, lr:3.28e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.154, tt:5139.649\n",
      "Ep:128, loss:0.00000, loss_test:0.02172, lr:3.25e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.160, tt:5180.646\n",
      "Ep:129, loss:0.00000, loss_test:0.02178, lr:3.22e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.141, tt:5218.326\n",
      "Ep:130, loss:0.00000, loss_test:0.02184, lr:3.19e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.140, tt:5258.381\n",
      "Ep:131, loss:0.00000, loss_test:0.02192, lr:3.15e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.144, tt:5299.034\n",
      "Ep:132, loss:0.00000, loss_test:0.02199, lr:3.12e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.145, tt:5339.276\n",
      "Ep:133, loss:0.00000, loss_test:0.02203, lr:3.09e-02, fs:0.75152 (r=0.626,p=0.939),  time:40.145, tt:5379.421\n",
      "Ep:134, loss:0.00000, loss_test:0.02208, lr:3.06e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.135, tt:5418.281\n",
      "Ep:135, loss:0.00000, loss_test:0.02216, lr:3.03e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.137, tt:5458.691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02222, lr:3.00e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.129, tt:5497.646\n",
      "Ep:137, loss:0.00000, loss_test:0.02225, lr:2.97e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.133, tt:5538.384\n",
      "Ep:138, loss:0.00000, loss_test:0.02230, lr:2.94e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.139, tt:5579.301\n",
      "Ep:139, loss:0.00000, loss_test:0.02237, lr:2.91e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.144, tt:5620.159\n",
      "Ep:140, loss:0.00000, loss_test:0.02243, lr:2.88e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.138, tt:5659.393\n",
      "Ep:141, loss:0.00000, loss_test:0.02247, lr:2.85e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.152, tt:5701.625\n",
      "Ep:142, loss:0.00000, loss_test:0.02250, lr:2.82e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.155, tt:5742.187\n",
      "Ep:143, loss:0.00000, loss_test:0.02255, lr:2.80e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.159, tt:5782.946\n",
      "Ep:144, loss:0.00000, loss_test:0.02262, lr:2.77e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.171, tt:5824.749\n",
      "Ep:145, loss:0.00000, loss_test:0.02267, lr:2.74e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.172, tt:5865.058\n",
      "Ep:146, loss:0.00000, loss_test:0.02272, lr:2.71e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.154, tt:5902.665\n",
      "Ep:147, loss:0.00000, loss_test:0.02276, lr:2.69e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.155, tt:5942.912\n",
      "Ep:148, loss:0.00000, loss_test:0.02278, lr:2.66e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.163, tt:5984.307\n",
      "Ep:149, loss:0.00000, loss_test:0.02283, lr:2.63e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.162, tt:6024.318\n",
      "Ep:150, loss:0.00000, loss_test:0.02289, lr:2.61e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.176, tt:6066.621\n",
      "Ep:151, loss:0.00000, loss_test:0.02292, lr:2.58e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.172, tt:6106.199\n",
      "Ep:152, loss:0.00000, loss_test:0.02296, lr:2.55e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.183, tt:6147.978\n",
      "Ep:153, loss:0.00000, loss_test:0.02301, lr:2.53e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.188, tt:6188.964\n",
      "Ep:154, loss:0.00000, loss_test:0.02305, lr:2.50e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.183, tt:6228.338\n",
      "Ep:155, loss:0.00000, loss_test:0.02307, lr:2.48e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.189, tt:6269.493\n",
      "Ep:156, loss:0.00000, loss_test:0.02309, lr:2.45e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.182, tt:6308.637\n",
      "Ep:157, loss:0.00000, loss_test:0.02315, lr:2.43e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.218, tt:6354.404\n",
      "Ep:158, loss:0.00000, loss_test:0.02320, lr:2.40e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.213, tt:6393.864\n",
      "Ep:159, loss:0.00000, loss_test:0.02322, lr:2.38e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.217, tt:6434.786\n",
      "Ep:160, loss:0.00000, loss_test:0.02325, lr:2.36e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.219, tt:6475.238\n",
      "Ep:161, loss:0.00000, loss_test:0.02329, lr:2.33e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.224, tt:6516.209\n",
      "Ep:162, loss:0.00000, loss_test:0.02335, lr:2.31e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.231, tt:6557.668\n",
      "Ep:163, loss:0.00000, loss_test:0.02339, lr:2.29e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.234, tt:6598.347\n",
      "Ep:164, loss:0.00000, loss_test:0.02341, lr:2.26e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.232, tt:6638.319\n",
      "Ep:165, loss:0.00000, loss_test:0.02344, lr:2.24e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.232, tt:6678.573\n",
      "Ep:166, loss:0.00000, loss_test:0.02349, lr:2.22e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.233, tt:6718.915\n",
      "Ep:167, loss:0.00000, loss_test:0.02353, lr:2.20e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.237, tt:6759.755\n",
      "Ep:168, loss:0.00000, loss_test:0.02356, lr:2.17e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.235, tt:6799.774\n",
      "Ep:169, loss:0.00000, loss_test:0.02357, lr:2.15e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.234, tt:6839.834\n",
      "Ep:170, loss:0.00000, loss_test:0.02361, lr:2.13e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.232, tt:6879.718\n",
      "Ep:171, loss:0.00000, loss_test:0.02363, lr:2.11e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.231, tt:6919.753\n",
      "Ep:172, loss:0.00000, loss_test:0.02368, lr:2.09e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.234, tt:6960.479\n",
      "Ep:173, loss:0.00000, loss_test:0.02370, lr:2.07e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.232, tt:7000.314\n",
      "Ep:174, loss:0.00000, loss_test:0.02372, lr:2.05e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.217, tt:7037.894\n",
      "Ep:175, loss:0.00000, loss_test:0.02375, lr:2.03e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.216, tt:7077.964\n",
      "Ep:176, loss:0.00000, loss_test:0.02377, lr:2.01e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.208, tt:7116.739\n",
      "Ep:177, loss:0.00000, loss_test:0.02379, lr:1.99e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.209, tt:7157.210\n",
      "Ep:178, loss:0.00000, loss_test:0.02382, lr:1.97e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.243, tt:7203.541\n",
      "Ep:179, loss:0.00000, loss_test:0.02385, lr:1.95e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.242, tt:7243.568\n",
      "Ep:180, loss:0.00000, loss_test:0.02387, lr:1.93e-02, fs:0.75610 (r=0.626,p=0.954),  time:40.234, tt:7282.311\n",
      "Ep:181, loss:0.00000, loss_test:0.02389, lr:1.91e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.228, tt:7321.501\n",
      "Ep:182, loss:0.00000, loss_test:0.02392, lr:1.89e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.221, tt:7360.364\n",
      "Ep:183, loss:0.00000, loss_test:0.02395, lr:1.87e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.216, tt:7399.747\n",
      "Ep:184, loss:0.00000, loss_test:0.02398, lr:1.85e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.219, tt:7440.563\n",
      "Ep:185, loss:0.00000, loss_test:0.02401, lr:1.83e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.217, tt:7480.269\n",
      "Ep:186, loss:0.00000, loss_test:0.02404, lr:1.81e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.209, tt:7519.037\n",
      "Ep:187, loss:0.00000, loss_test:0.02406, lr:1.80e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.206, tt:7558.731\n",
      "Ep:188, loss:0.00000, loss_test:0.02408, lr:1.78e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.201, tt:7598.009\n",
      "Ep:189, loss:0.00000, loss_test:0.02411, lr:1.76e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.204, tt:7638.700\n",
      "Ep:190, loss:0.00000, loss_test:0.02412, lr:1.74e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.212, tt:7680.508\n",
      "Ep:191, loss:0.00000, loss_test:0.02415, lr:1.73e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.212, tt:7720.659\n",
      "Ep:192, loss:0.00000, loss_test:0.02417, lr:1.71e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.213, tt:7761.099\n",
      "Ep:193, loss:0.00000, loss_test:0.02419, lr:1.69e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.211, tt:7800.946\n",
      "Ep:194, loss:0.00000, loss_test:0.02422, lr:1.67e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.220, tt:7842.909\n",
      "Ep:195, loss:0.00000, loss_test:0.02424, lr:1.66e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.232, tt:7885.465\n",
      "Ep:196, loss:0.00000, loss_test:0.02427, lr:1.64e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.239, tt:7927.163\n",
      "Ep:197, loss:0.00000, loss_test:0.02430, lr:1.62e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.244, tt:7968.250\n",
      "Ep:198, loss:0.00000, loss_test:0.02431, lr:1.61e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.280, tt:8015.665\n",
      "Ep:199, loss:0.00000, loss_test:0.02433, lr:1.59e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.279, tt:8055.758\n",
      "Ep:200, loss:0.00000, loss_test:0.02435, lr:1.58e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.267, tt:8093.602\n",
      "Ep:201, loss:0.00000, loss_test:0.02437, lr:1.56e-02, fs:0.76074 (r=0.626,p=0.969),  time:40.244, tt:8129.293\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14319, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.827, tt:28.827\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14190, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:34.238, tt:68.476\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13960, lr:1.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:37.074, tt:111.223\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13552, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:38.159, tt:152.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00026, loss_test:0.13043, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:38.860, tt:194.302\n",
      "Ep:5, loss:0.00024, loss_test:0.12595, lr:1.00e-02, fs:0.64407 (r=0.768,p=0.555),  time:39.403, tt:236.417\n",
      "Ep:6, loss:0.00024, loss_test:0.12334, lr:1.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:39.696, tt:277.870\n",
      "Ep:7, loss:0.00023, loss_test:0.12161, lr:1.00e-02, fs:0.67265 (r=0.758,p=0.605),  time:40.097, tt:320.778\n",
      "Ep:8, loss:0.00022, loss_test:0.12115, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:40.257, tt:362.311\n",
      "Ep:9, loss:0.00021, loss_test:0.11687, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:40.271, tt:402.707\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11154, lr:1.00e-02, fs:0.70526 (r=0.677,p=0.736),  time:40.202, tt:442.222\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10875, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:40.443, tt:485.317\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10840, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:40.654, tt:528.506\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10230, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:40.646, tt:569.049\n",
      "Ep:14, loss:0.00017, loss_test:0.09956, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:40.807, tt:612.108\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09846, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:40.743, tt:651.893\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09523, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:41.088, tt:698.493\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09283, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:41.085, tt:739.531\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09086, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:41.035, tt:779.669\n",
      "Ep:19, loss:0.00013, loss_test:0.08962, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:41.045, tt:820.897\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.08774, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:41.099, tt:863.082\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.08510, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:41.081, tt:903.787\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00011, loss_test:0.08350, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:41.070, tt:944.604\n",
      "Ep:23, loss:0.00010, loss_test:0.08247, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.059, tt:985.419\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08114, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:41.013, tt:1025.334\n",
      "Ep:25, loss:0.00009, loss_test:0.07935, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.028, tt:1066.725\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.07875, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:41.033, tt:1107.903\n",
      "Ep:27, loss:0.00009, loss_test:0.07824, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.061, tt:1149.714\n",
      "Ep:28, loss:0.00008, loss_test:0.07700, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:41.081, tt:1191.349\n",
      "Ep:29, loss:0.00008, loss_test:0.07643, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:41.121, tt:1233.623\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00007, loss_test:0.07520, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.104, tt:1274.232\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.07395, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.123, tt:1315.927\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.07389, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:41.155, tt:1358.107\n",
      "Ep:33, loss:0.00006, loss_test:0.07319, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.148, tt:1399.031\n",
      "Ep:34, loss:0.00006, loss_test:0.07253, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:41.118, tt:1439.146\n",
      "Ep:35, loss:0.00006, loss_test:0.07180, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.124, tt:1480.465\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00005, loss_test:0.07131, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:41.094, tt:1520.496\n",
      "Ep:37, loss:0.00005, loss_test:0.07179, lr:1.00e-02, fs:0.90426 (r=0.859,p=0.955),  time:41.069, tt:1560.612\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.07136, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.085, tt:1602.311\n",
      "Ep:39, loss:0.00005, loss_test:0.07122, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.114, tt:1644.568\n",
      "Ep:40, loss:0.00004, loss_test:0.07084, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.123, tt:1686.051\n",
      "Ep:41, loss:0.00004, loss_test:0.07127, lr:1.00e-02, fs:0.90426 (r=0.859,p=0.955),  time:41.102, tt:1726.286\n",
      "Ep:42, loss:0.00004, loss_test:0.06998, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.107, tt:1767.585\n",
      "Ep:43, loss:0.00004, loss_test:0.07050, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:41.098, tt:1808.329\n",
      "Ep:44, loss:0.00004, loss_test:0.07154, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:41.090, tt:1849.070\n",
      "Ep:45, loss:0.00004, loss_test:0.06903, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.084, tt:1889.878\n",
      "Ep:46, loss:0.00003, loss_test:0.07203, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:41.067, tt:1930.162\n",
      "Ep:47, loss:0.00003, loss_test:0.07269, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:41.081, tt:1971.881\n",
      "Ep:48, loss:0.00003, loss_test:0.06808, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:41.106, tt:2014.180\n",
      "Ep:49, loss:0.00003, loss_test:0.07323, lr:9.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:41.093, tt:2054.644\n",
      "Ep:50, loss:0.00003, loss_test:0.07033, lr:9.80e-03, fs:0.89474 (r=0.859,p=0.934),  time:41.091, tt:2095.638\n",
      "Ep:51, loss:0.00003, loss_test:0.07011, lr:9.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:41.078, tt:2136.057\n",
      "Ep:52, loss:0.00003, loss_test:0.07077, lr:9.61e-03, fs:0.89474 (r=0.859,p=0.934),  time:41.100, tt:2178.300\n",
      "Ep:53, loss:0.00003, loss_test:0.07012, lr:9.51e-03, fs:0.89474 (r=0.859,p=0.934),  time:41.061, tt:2217.312\n",
      "Ep:54, loss:0.00002, loss_test:0.07078, lr:9.41e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.065, tt:2258.563\n",
      "Ep:55, loss:0.00002, loss_test:0.06882, lr:9.32e-03, fs:0.89583 (r=0.869,p=0.925),  time:41.102, tt:2301.723\n",
      "Ep:56, loss:0.00002, loss_test:0.07300, lr:9.23e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.107, tt:2343.119\n",
      "Ep:57, loss:0.00002, loss_test:0.06971, lr:9.14e-03, fs:0.88889 (r=0.848,p=0.933),  time:41.116, tt:2384.734\n",
      "Ep:58, loss:0.00002, loss_test:0.06988, lr:9.04e-03, fs:0.88421 (r=0.848,p=0.923),  time:41.144, tt:2427.485\n",
      "Ep:59, loss:0.00002, loss_test:0.07215, lr:8.95e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.161, tt:2469.684\n",
      "Ep:60, loss:0.00002, loss_test:0.06914, lr:8.86e-03, fs:0.90052 (r=0.869,p=0.935),  time:41.160, tt:2510.741\n",
      "Ep:61, loss:0.00002, loss_test:0.07194, lr:8.78e-03, fs:0.82486 (r=0.737,p=0.936),  time:41.177, tt:2553.004\n",
      "Ep:62, loss:0.00002, loss_test:0.07264, lr:8.69e-03, fs:0.83908 (r=0.737,p=0.973),  time:41.194, tt:2595.250\n",
      "Ep:63, loss:0.00002, loss_test:0.06825, lr:8.60e-03, fs:0.89583 (r=0.869,p=0.925),  time:41.203, tt:2636.986\n",
      "Ep:64, loss:0.00002, loss_test:0.07180, lr:8.51e-03, fs:0.83429 (r=0.737,p=0.961),  time:41.217, tt:2679.114\n",
      "Ep:65, loss:0.00002, loss_test:0.07146, lr:8.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:41.279, tt:2724.441\n",
      "Ep:66, loss:0.00002, loss_test:0.06853, lr:8.35e-03, fs:0.86631 (r=0.818,p=0.920),  time:41.276, tt:2765.524\n",
      "Ep:67, loss:0.00002, loss_test:0.07112, lr:8.26e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.263, tt:2805.874\n",
      "Ep:68, loss:0.00002, loss_test:0.07148, lr:8.18e-03, fs:0.84393 (r=0.737,p=0.986),  time:41.285, tt:2848.698\n",
      "Ep:69, loss:0.00001, loss_test:0.06847, lr:8.10e-03, fs:0.87234 (r=0.828,p=0.921),  time:41.299, tt:2890.917\n",
      "Ep:70, loss:0.00001, loss_test:0.07131, lr:8.02e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.309, tt:2932.960\n",
      "Ep:71, loss:0.00001, loss_test:0.07059, lr:7.94e-03, fs:0.84571 (r=0.747,p=0.974),  time:41.341, tt:2976.563\n",
      "Ep:72, loss:0.00001, loss_test:0.06837, lr:7.86e-03, fs:0.87234 (r=0.828,p=0.921),  time:41.338, tt:3017.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00001, loss_test:0.07108, lr:7.78e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.345, tt:3059.512\n",
      "Ep:74, loss:0.00001, loss_test:0.07140, lr:7.70e-03, fs:0.85057 (r=0.747,p=0.987),  time:41.346, tt:3100.923\n",
      "Ep:75, loss:0.00001, loss_test:0.06900, lr:7.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:41.369, tt:3144.015\n",
      "Ep:76, loss:0.00001, loss_test:0.07031, lr:7.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.368, tt:3185.345\n",
      "Ep:77, loss:0.00001, loss_test:0.07032, lr:7.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.394, tt:3228.737\n",
      "Ep:78, loss:0.00001, loss_test:0.06901, lr:7.40e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.411, tt:3271.484\n",
      "Ep:79, loss:0.00001, loss_test:0.06938, lr:7.32e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.422, tt:3313.781\n",
      "Ep:80, loss:0.00001, loss_test:0.07072, lr:7.25e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.412, tt:3354.402\n",
      "Ep:81, loss:0.00001, loss_test:0.06935, lr:7.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.427, tt:3397.045\n",
      "Ep:82, loss:0.00001, loss_test:0.06957, lr:7.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.421, tt:3437.928\n",
      "Ep:83, loss:0.00001, loss_test:0.07055, lr:7.03e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.447, tt:3481.562\n",
      "Ep:84, loss:0.00001, loss_test:0.06914, lr:6.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.456, tt:3523.787\n",
      "Ep:85, loss:0.00001, loss_test:0.06891, lr:6.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.526, tt:3571.227\n",
      "Ep:86, loss:0.00001, loss_test:0.06956, lr:6.83e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.551, tt:3614.926\n",
      "Ep:87, loss:0.00001, loss_test:0.06892, lr:6.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.611, tt:3661.783\n",
      "Ep:88, loss:0.00001, loss_test:0.06937, lr:6.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.652, tt:3707.054\n",
      "Ep:89, loss:0.00001, loss_test:0.06887, lr:6.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.710, tt:3753.925\n",
      "Ep:90, loss:0.00001, loss_test:0.06862, lr:6.56e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.770, tt:3801.096\n",
      "Ep:91, loss:0.00001, loss_test:0.06908, lr:6.49e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.797, tt:3845.328\n",
      "Ep:92, loss:0.00001, loss_test:0.06895, lr:6.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.843, tt:3891.391\n",
      "Ep:93, loss:0.00001, loss_test:0.06795, lr:6.36e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.885, tt:3937.182\n",
      "Ep:94, loss:0.00001, loss_test:0.06908, lr:6.30e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.928, tt:3983.145\n",
      "Ep:95, loss:0.00001, loss_test:0.06895, lr:6.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.969, tt:4028.981\n",
      "Ep:96, loss:0.00001, loss_test:0.06823, lr:6.17e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.995, tt:4073.553\n",
      "Ep:97, loss:0.00001, loss_test:0.06859, lr:6.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.032, tt:4119.183\n",
      "Ep:98, loss:0.00001, loss_test:0.06847, lr:6.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.013, tt:4159.302\n",
      "Ep:99, loss:0.00001, loss_test:0.06881, lr:5.99e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.034, tt:4203.399\n",
      "Ep:100, loss:0.00001, loss_test:0.06809, lr:5.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.061, tt:4248.175\n",
      "Ep:101, loss:0.00001, loss_test:0.06869, lr:5.87e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.082, tt:4292.414\n",
      "Ep:102, loss:0.00001, loss_test:0.06841, lr:5.81e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.111, tt:4337.453\n",
      "Ep:103, loss:0.00001, loss_test:0.06834, lr:5.75e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.148, tt:4383.340\n",
      "Ep:104, loss:0.00001, loss_test:0.06815, lr:5.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.222, tt:4433.312\n",
      "Ep:105, loss:0.00001, loss_test:0.06829, lr:5.64e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.239, tt:4477.309\n",
      "Ep:106, loss:0.00001, loss_test:0.06793, lr:5.58e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.251, tt:4520.892\n",
      "Ep:107, loss:0.00001, loss_test:0.06811, lr:5.53e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.264, tt:4564.501\n",
      "Ep:108, loss:0.00001, loss_test:0.06818, lr:5.47e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.283, tt:4608.883\n",
      "Ep:109, loss:0.00001, loss_test:0.06776, lr:5.42e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.305, tt:4653.546\n",
      "Ep:110, loss:0.00001, loss_test:0.06826, lr:5.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.321, tt:4697.605\n",
      "Ep:111, loss:0.00001, loss_test:0.06819, lr:5.31e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.331, tt:4741.043\n",
      "Ep:112, loss:0.00001, loss_test:0.06799, lr:5.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.315, tt:4781.550\n",
      "Ep:113, loss:0.00001, loss_test:0.06774, lr:5.20e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.325, tt:4825.038\n",
      "Ep:114, loss:0.00001, loss_test:0.06843, lr:5.15e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.311, tt:4865.817\n",
      "Ep:115, loss:0.00001, loss_test:0.06839, lr:5.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.309, tt:4907.837\n",
      "Ep:116, loss:0.00001, loss_test:0.06791, lr:5.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.331, tt:4952.708\n",
      "Ep:117, loss:0.00001, loss_test:0.06838, lr:5.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.331, tt:4995.038\n",
      "Ep:118, loss:0.00001, loss_test:0.06792, lr:4.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.340, tt:5038.474\n",
      "Ep:119, loss:0.00001, loss_test:0.06788, lr:4.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.344, tt:5081.309\n",
      "Ep:120, loss:0.00001, loss_test:0.06827, lr:4.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.358, tt:5125.283\n",
      "Ep:121, loss:0.00001, loss_test:0.06847, lr:4.80e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.362, tt:5168.157\n",
      "Ep:122, loss:0.00001, loss_test:0.06764, lr:4.75e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.369, tt:5211.370\n",
      "Ep:123, loss:0.00001, loss_test:0.06769, lr:4.71e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.381, tt:5255.226\n",
      "Ep:124, loss:0.00001, loss_test:0.06871, lr:4.66e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.387, tt:5298.350\n",
      "Ep:125, loss:0.00001, loss_test:0.06880, lr:4.61e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.401, tt:5342.566\n",
      "Ep:126, loss:0.00001, loss_test:0.06761, lr:4.57e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.405, tt:5385.412\n",
      "Ep:127, loss:0.00001, loss_test:0.06796, lr:4.52e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.410, tt:5428.524\n",
      "Ep:128, loss:0.00001, loss_test:0.06864, lr:4.48e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.416, tt:5471.679\n",
      "Ep:129, loss:0.00001, loss_test:0.06781, lr:4.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.394, tt:5511.187\n",
      "Ep:130, loss:0.00000, loss_test:0.06751, lr:4.39e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.377, tt:5551.364\n",
      "Ep:131, loss:0.00000, loss_test:0.06820, lr:4.34e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.348, tt:5589.979\n",
      "Ep:132, loss:0.00000, loss_test:0.06775, lr:4.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.341, tt:5631.353\n",
      "Ep:133, loss:0.00000, loss_test:0.06756, lr:4.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.346, tt:5674.364\n",
      "Ep:134, loss:0.00000, loss_test:0.06809, lr:4.21e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.336, tt:5715.320\n",
      "Ep:135, loss:0.00000, loss_test:0.06775, lr:4.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.335, tt:5757.607\n",
      "Ep:136, loss:0.00000, loss_test:0.06777, lr:4.13e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.325, tt:5798.462\n",
      "Ep:137, loss:0.00000, loss_test:0.06814, lr:4.09e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.327, tt:5841.086\n",
      "Ep:138, loss:0.00000, loss_test:0.06793, lr:4.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.335, tt:5884.563\n",
      "Ep:139, loss:0.00000, loss_test:0.06736, lr:4.01e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.328, tt:5925.934\n",
      "Ep:140, loss:0.00000, loss_test:0.06792, lr:3.97e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.318, tt:5966.863\n",
      "Ep:141, loss:0.00000, loss_test:0.06785, lr:3.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.313, tt:6008.434\n",
      "Ep:142, loss:0.00000, loss_test:0.06745, lr:3.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.312, tt:6050.567\n",
      "Ep:143, loss:0.00000, loss_test:0.06789, lr:3.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.307, tt:6092.199\n",
      "Ep:144, loss:0.00000, loss_test:0.06755, lr:3.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.314, tt:6135.507\n",
      "Ep:145, loss:0.00000, loss_test:0.06729, lr:3.77e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.315, tt:6178.005\n",
      "Ep:146, loss:0.00000, loss_test:0.06784, lr:3.73e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.320, tt:6221.106\n",
      "Ep:147, loss:0.00000, loss_test:0.06782, lr:3.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.318, tt:6263.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00000, loss_test:0.06708, lr:3.66e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.313, tt:6304.697\n",
      "Ep:149, loss:0.00000, loss_test:0.06822, lr:3.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.306, tt:6345.959\n",
      "Ep:150, loss:0.00000, loss_test:0.06857, lr:3.59e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.301, tt:6387.435\n",
      "Ep:151, loss:0.00000, loss_test:0.06788, lr:3.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.299, tt:6429.517\n",
      "Ep:152, loss:0.00000, loss_test:0.06709, lr:3.52e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.286, tt:6469.756\n",
      "Ep:153, loss:0.00000, loss_test:0.06756, lr:3.48e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.290, tt:6512.675\n",
      "Ep:154, loss:0.00000, loss_test:0.06762, lr:3.45e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.278, tt:6553.036\n",
      "Ep:155, loss:0.00000, loss_test:0.06780, lr:3.41e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.284, tt:6596.360\n",
      "Ep:156, loss:0.00000, loss_test:0.06804, lr:3.38e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.284, tt:6638.543\n",
      "Ep:157, loss:0.00000, loss_test:0.06773, lr:3.34e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.282, tt:6680.498\n",
      "Ep:158, loss:0.00000, loss_test:0.06710, lr:3.31e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.279, tt:6722.361\n",
      "Ep:159, loss:0.00000, loss_test:0.06780, lr:3.28e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.280, tt:6764.780\n",
      "Ep:160, loss:0.00000, loss_test:0.06807, lr:3.24e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.284, tt:6807.692\n",
      "Ep:161, loss:0.00000, loss_test:0.06757, lr:3.21e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.281, tt:6849.470\n",
      "Ep:162, loss:0.00000, loss_test:0.06749, lr:3.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.272, tt:6890.297\n",
      "Ep:163, loss:0.00000, loss_test:0.06784, lr:3.15e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.273, tt:6932.840\n",
      "Ep:164, loss:0.00000, loss_test:0.06782, lr:3.12e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.270, tt:6974.540\n",
      "Ep:165, loss:0.00000, loss_test:0.06765, lr:3.09e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.263, tt:7015.631\n",
      "Ep:166, loss:0.00000, loss_test:0.06765, lr:3.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.265, tt:7058.295\n",
      "Ep:167, loss:0.00000, loss_test:0.06756, lr:3.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.253, tt:7098.421\n",
      "Ep:168, loss:0.00000, loss_test:0.06740, lr:2.99e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.253, tt:7140.721\n",
      "Ep:169, loss:0.00000, loss_test:0.06762, lr:2.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.261, tt:7184.441\n",
      "Ep:170, loss:0.00000, loss_test:0.06745, lr:2.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.250, tt:7224.668\n",
      "Ep:171, loss:0.00000, loss_test:0.06737, lr:2.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.248, tt:7266.666\n",
      "Ep:172, loss:0.00000, loss_test:0.06774, lr:2.88e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.239, tt:7307.342\n",
      "Ep:173, loss:0.00000, loss_test:0.06738, lr:2.85e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.232, tt:7348.408\n",
      "Ep:174, loss:0.00000, loss_test:0.06704, lr:2.82e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.225, tt:7389.375\n",
      "Ep:175, loss:0.00000, loss_test:0.06766, lr:2.79e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.231, tt:7432.631\n",
      "Ep:176, loss:0.00000, loss_test:0.06764, lr:2.76e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.225, tt:7473.780\n",
      "Ep:177, loss:0.00000, loss_test:0.06711, lr:2.73e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.215, tt:7514.195\n",
      "Ep:178, loss:0.00000, loss_test:0.06748, lr:2.71e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.209, tt:7555.338\n",
      "Ep:179, loss:0.00000, loss_test:0.06815, lr:2.68e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.212, tt:7598.194\n",
      "Ep:180, loss:0.00000, loss_test:0.06797, lr:2.65e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.204, tt:7638.993\n",
      "Ep:181, loss:0.00000, loss_test:0.06733, lr:2.63e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.203, tt:7680.976\n",
      "Ep:182, loss:0.00000, loss_test:0.06719, lr:2.60e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.194, tt:7721.510\n",
      "Ep:183, loss:0.00000, loss_test:0.06725, lr:2.57e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.200, tt:7764.888\n",
      "Ep:184, loss:0.00000, loss_test:0.06715, lr:2.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.219, tt:7810.464\n",
      "Ep:185, loss:0.00000, loss_test:0.06734, lr:2.52e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.221, tt:7853.095\n",
      "Ep:186, loss:0.00000, loss_test:0.06736, lr:2.50e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.234, tt:7897.731\n",
      "Ep:187, loss:0.00000, loss_test:0.06711, lr:2.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.241, tt:7941.365\n",
      "Ep:188, loss:0.00000, loss_test:0.06720, lr:2.45e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.230, tt:7981.528\n",
      "Ep:189, loss:0.00000, loss_test:0.06726, lr:2.42e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.227, tt:8023.130\n",
      "Ep:190, loss:0.00000, loss_test:0.06721, lr:2.40e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.225, tt:8064.881\n",
      "Ep:191, loss:0.00000, loss_test:0.06710, lr:2.38e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.230, tt:8108.112\n",
      "Ep:192, loss:0.00000, loss_test:0.06716, lr:2.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.230, tt:8150.364\n",
      "Ep:193, loss:0.00000, loss_test:0.06724, lr:2.33e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.242, tt:8194.987\n",
      "Ep:194, loss:0.00000, loss_test:0.06716, lr:2.31e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.250, tt:8238.754\n",
      "Ep:195, loss:0.00000, loss_test:0.06719, lr:2.28e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.257, tt:8282.289\n",
      "Ep:196, loss:0.00000, loss_test:0.06711, lr:2.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.251, tt:8323.412\n",
      "Ep:197, loss:0.00000, loss_test:0.06725, lr:2.24e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.256, tt:8366.703\n",
      "Ep:198, loss:0.00000, loss_test:0.06711, lr:2.21e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.246, tt:8406.976\n",
      "Ep:199, loss:0.00000, loss_test:0.06690, lr:2.19e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.242, tt:8448.383\n",
      "Ep:200, loss:0.00000, loss_test:0.06700, lr:2.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.213, tt:8484.903\n",
      "Ep:201, loss:0.00000, loss_test:0.06708, lr:2.15e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.172, tt:8518.692\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02063, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:25.665, tt:25.665\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02362, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.686, tt:55.371\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02547, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.743, tt:89.228\n",
      "Ep:3, loss:0.00005, loss_test:0.02561, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.131, tt:124.522\n",
      "Ep:4, loss:0.00005, loss_test:0.02446, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.047, tt:160.237\n",
      "Ep:5, loss:0.00005, loss_test:0.02270, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.465, tt:194.792\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02095, lr:6.00e-02, fs:0.68772 (r=0.990,p=0.527),  time:32.695, tt:228.864\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02003, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:32.877, tt:263.018\n",
      "Ep:8, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:33.045, tt:297.401\n",
      "Ep:9, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:33.109, tt:331.092\n",
      "Ep:10, loss:0.00004, loss_test:0.01933, lr:6.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:33.225, tt:365.476\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01917, lr:6.00e-02, fs:0.68841 (r=0.960,p=0.537),  time:33.302, tt:399.619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00004, loss_test:0.01903, lr:6.00e-02, fs:0.69751 (r=0.990,p=0.538),  time:33.369, tt:433.802\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01871, lr:6.00e-02, fs:0.69751 (r=0.990,p=0.538),  time:33.504, tt:469.051\n",
      "Ep:14, loss:0.00003, loss_test:0.01820, lr:6.00e-02, fs:0.70073 (r=0.970,p=0.549),  time:33.583, tt:503.747\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.71756 (r=0.949,p=0.577),  time:33.683, tt:538.932\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01746, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:33.742, tt:573.608\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01720, lr:6.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:33.714, tt:606.861\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.74903 (r=0.980,p=0.606),  time:33.665, tt:639.642\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01676, lr:6.00e-02, fs:0.75096 (r=0.990,p=0.605),  time:33.676, tt:673.526\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.75194 (r=0.980,p=0.610),  time:33.644, tt:706.515\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.75781 (r=0.980,p=0.618),  time:33.686, tt:741.083\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.76800 (r=0.970,p=0.636),  time:33.725, tt:775.675\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01571, lr:6.00e-02, fs:0.77236 (r=0.960,p=0.646),  time:33.752, tt:810.039\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:33.827, tt:845.676\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:33.906, tt:881.544\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:33.932, tt:916.177\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:33.965, tt:951.030\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:33.920, tt:983.674\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01462, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:33.918, tt:1017.552\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:33.941, tt:1052.176\n",
      "Ep:31, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:33.923, tt:1085.529\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:33.961, tt:1120.724\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:33.966, tt:1154.844\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:33.938, tt:1187.822\n",
      "Ep:35, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:33.934, tt:1221.610\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:33.936, tt:1255.645\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:33.938, tt:1289.653\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:33.969, tt:1324.805\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:33.988, tt:1359.530\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:33.966, tt:1392.624\n",
      "Ep:41, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:33.985, tt:1427.384\n",
      "Ep:42, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:34.013, tt:1462.575\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:34.036, tt:1497.587\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:34.062, tt:1532.776\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01264, lr:6.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:34.140, tt:1570.457\n",
      "Ep:46, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.154, tt:1605.241\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01249, lr:6.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:34.145, tt:1638.950\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01245, lr:6.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:34.151, tt:1673.422\n",
      "Ep:49, loss:0.00001, loss_test:0.01243, lr:6.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:34.156, tt:1707.792\n",
      "Ep:50, loss:0.00001, loss_test:0.01237, lr:6.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:34.161, tt:1742.188\n",
      "Ep:51, loss:0.00001, loss_test:0.01235, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.166, tt:1776.649\n",
      "Ep:52, loss:0.00001, loss_test:0.01226, lr:6.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:34.184, tt:1811.761\n",
      "Ep:53, loss:0.00001, loss_test:0.01224, lr:6.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.169, tt:1845.105\n",
      "Ep:54, loss:0.00001, loss_test:0.01224, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.171, tt:1879.428\n",
      "Ep:55, loss:0.00001, loss_test:0.01221, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.177, tt:1913.897\n",
      "Ep:56, loss:0.00001, loss_test:0.01218, lr:6.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.185, tt:1948.536\n",
      "Ep:57, loss:0.00001, loss_test:0.01220, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.202, tt:1983.743\n",
      "Ep:58, loss:0.00001, loss_test:0.01221, lr:6.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.217, tt:2018.801\n",
      "Ep:59, loss:0.00001, loss_test:0.01216, lr:5.94e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.235, tt:2054.116\n",
      "Ep:60, loss:0.00001, loss_test:0.01218, lr:5.88e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.233, tt:2088.211\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01226, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.246, tt:2123.262\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01229, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.245, tt:2157.432\n",
      "Ep:63, loss:0.00001, loss_test:0.01222, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.240, tt:2191.349\n",
      "Ep:64, loss:0.00001, loss_test:0.01222, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.228, tt:2224.789\n",
      "Ep:65, loss:0.00001, loss_test:0.01228, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.246, tt:2260.227\n",
      "Ep:66, loss:0.00001, loss_test:0.01230, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.231, tt:2293.470\n",
      "Ep:67, loss:0.00001, loss_test:0.01227, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:34.255, tt:2329.357\n",
      "Ep:68, loss:0.00001, loss_test:0.01231, lr:5.88e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.246, tt:2363.001\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01243, lr:5.88e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.251, tt:2397.586\n",
      "Ep:70, loss:0.00001, loss_test:0.01244, lr:5.88e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.267, tt:2432.968\n",
      "Ep:71, loss:0.00001, loss_test:0.01242, lr:5.88e-02, fs:0.89340 (r=0.889,p=0.898),  time:34.268, tt:2467.263\n",
      "Ep:72, loss:0.00001, loss_test:0.01250, lr:5.88e-02, fs:0.89231 (r=0.879,p=0.906),  time:34.269, tt:2501.637\n",
      "Ep:73, loss:0.00001, loss_test:0.01257, lr:5.88e-02, fs:0.89231 (r=0.879,p=0.906),  time:34.262, tt:2535.389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00001, loss_test:0.01255, lr:5.88e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.262, tt:2569.636\n",
      "Ep:75, loss:0.00001, loss_test:0.01261, lr:5.88e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.259, tt:2603.680\n",
      "Ep:76, loss:0.00001, loss_test:0.01263, lr:5.88e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.259, tt:2637.932\n",
      "Ep:77, loss:0.00001, loss_test:0.01272, lr:5.88e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.270, tt:2673.062\n",
      "Ep:78, loss:0.00001, loss_test:0.01276, lr:5.88e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.278, tt:2707.950\n",
      "Ep:79, loss:0.00001, loss_test:0.01276, lr:5.88e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.283, tt:2742.668\n",
      "Ep:80, loss:0.00001, loss_test:0.01285, lr:5.82e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.275, tt:2776.307\n",
      "Ep:81, loss:0.00001, loss_test:0.01295, lr:5.76e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.261, tt:2809.390\n",
      "Ep:82, loss:0.00001, loss_test:0.01292, lr:5.71e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.264, tt:2843.891\n",
      "Ep:83, loss:0.00001, loss_test:0.01305, lr:5.65e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.258, tt:2877.650\n",
      "Ep:84, loss:0.00001, loss_test:0.01310, lr:5.59e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.238, tt:2910.249\n",
      "Ep:85, loss:0.00001, loss_test:0.01309, lr:5.54e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.233, tt:2944.004\n",
      "Ep:86, loss:0.00001, loss_test:0.01315, lr:5.48e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.224, tt:2977.504\n",
      "Ep:87, loss:0.00001, loss_test:0.01325, lr:5.43e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.228, tt:3012.073\n",
      "Ep:88, loss:0.00001, loss_test:0.01328, lr:5.37e-02, fs:0.89005 (r=0.859,p=0.924),  time:34.230, tt:3046.479\n",
      "Ep:89, loss:0.00001, loss_test:0.01333, lr:5.32e-02, fs:0.89005 (r=0.859,p=0.924),  time:34.224, tt:3080.149\n",
      "Ep:90, loss:0.00001, loss_test:0.01337, lr:5.27e-02, fs:0.89005 (r=0.859,p=0.924),  time:34.225, tt:3114.486\n",
      "Ep:91, loss:0.00001, loss_test:0.01343, lr:5.21e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.231, tt:3149.293\n",
      "Ep:92, loss:0.00001, loss_test:0.01352, lr:5.16e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.226, tt:3183.000\n",
      "Ep:93, loss:0.00001, loss_test:0.01359, lr:5.11e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.216, tt:3216.274\n",
      "Ep:94, loss:0.00001, loss_test:0.01360, lr:5.06e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.217, tt:3250.652\n",
      "Ep:95, loss:0.00001, loss_test:0.01368, lr:5.01e-02, fs:0.87831 (r=0.838,p=0.922),  time:34.228, tt:3285.896\n",
      "Ep:96, loss:0.00001, loss_test:0.01371, lr:4.96e-02, fs:0.88298 (r=0.838,p=0.933),  time:34.223, tt:3319.595\n",
      "Ep:97, loss:0.00000, loss_test:0.01375, lr:4.91e-02, fs:0.87831 (r=0.838,p=0.922),  time:34.216, tt:3353.170\n",
      "Ep:98, loss:0.00000, loss_test:0.01383, lr:4.86e-02, fs:0.87831 (r=0.838,p=0.922),  time:34.222, tt:3387.965\n",
      "Ep:99, loss:0.00000, loss_test:0.01388, lr:4.81e-02, fs:0.88770 (r=0.838,p=0.943),  time:34.225, tt:3422.519\n",
      "Ep:100, loss:0.00000, loss_test:0.01395, lr:4.76e-02, fs:0.88770 (r=0.838,p=0.943),  time:34.229, tt:3457.119\n",
      "Ep:101, loss:0.00000, loss_test:0.01399, lr:4.71e-02, fs:0.88770 (r=0.838,p=0.943),  time:34.227, tt:3491.165\n",
      "Ep:102, loss:0.00000, loss_test:0.01403, lr:4.67e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.217, tt:3524.300\n",
      "Ep:103, loss:0.00000, loss_test:0.01413, lr:4.62e-02, fs:0.87568 (r=0.818,p=0.942),  time:34.220, tt:3558.902\n",
      "Ep:104, loss:0.00000, loss_test:0.01416, lr:4.57e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.257, tt:3596.990\n",
      "Ep:105, loss:0.00000, loss_test:0.01418, lr:4.53e-02, fs:0.86957 (r=0.808,p=0.941),  time:34.265, tt:3632.128\n",
      "Ep:106, loss:0.00000, loss_test:0.01426, lr:4.48e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.265, tt:3666.383\n",
      "Ep:107, loss:0.00000, loss_test:0.01433, lr:4.44e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.262, tt:3700.243\n",
      "Ep:108, loss:0.00000, loss_test:0.01436, lr:4.39e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.262, tt:3734.610\n",
      "Ep:109, loss:0.00000, loss_test:0.01441, lr:4.35e-02, fs:0.84270 (r=0.758,p=0.949),  time:34.267, tt:3769.337\n",
      "Ep:110, loss:0.00000, loss_test:0.01444, lr:4.31e-02, fs:0.83616 (r=0.747,p=0.949),  time:34.268, tt:3803.768\n",
      "Ep:111, loss:0.00000, loss_test:0.01448, lr:4.26e-02, fs:0.83616 (r=0.747,p=0.949),  time:34.266, tt:3837.791\n",
      "Ep:112, loss:0.00000, loss_test:0.01456, lr:4.22e-02, fs:0.83616 (r=0.747,p=0.949),  time:34.246, tt:3869.824\n",
      "Ep:113, loss:0.00000, loss_test:0.01458, lr:4.18e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.239, tt:3903.295\n",
      "Ep:114, loss:0.00000, loss_test:0.01462, lr:4.14e-02, fs:0.82286 (r=0.727,p=0.947),  time:34.238, tt:3937.393\n",
      "Ep:115, loss:0.00000, loss_test:0.01470, lr:4.10e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.243, tt:3972.159\n",
      "Ep:116, loss:0.00000, loss_test:0.01474, lr:4.05e-02, fs:0.80925 (r=0.707,p=0.946),  time:34.243, tt:4006.418\n",
      "Ep:117, loss:0.00000, loss_test:0.01478, lr:4.01e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.242, tt:4040.553\n",
      "Ep:118, loss:0.00000, loss_test:0.01484, lr:3.97e-02, fs:0.80925 (r=0.707,p=0.946),  time:34.245, tt:4075.164\n",
      "Ep:119, loss:0.00000, loss_test:0.01490, lr:3.93e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.247, tt:4109.649\n",
      "Ep:120, loss:0.00000, loss_test:0.01489, lr:3.89e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.245, tt:4143.689\n",
      "Ep:121, loss:0.00000, loss_test:0.01495, lr:3.86e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.260, tt:4179.720\n",
      "Ep:122, loss:0.00000, loss_test:0.01501, lr:3.82e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.267, tt:4214.788\n",
      "Ep:123, loss:0.00000, loss_test:0.01508, lr:3.78e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.267, tt:4249.127\n",
      "Ep:124, loss:0.00000, loss_test:0.01510, lr:3.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.279, tt:4284.895\n",
      "Ep:125, loss:0.00000, loss_test:0.01512, lr:3.70e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.281, tt:4319.362\n",
      "Ep:126, loss:0.00000, loss_test:0.01516, lr:3.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.288, tt:4354.524\n",
      "Ep:127, loss:0.00000, loss_test:0.01523, lr:3.63e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.302, tt:4390.647\n",
      "Ep:128, loss:0.00000, loss_test:0.01528, lr:3.59e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.316, tt:4426.797\n",
      "Ep:129, loss:0.00000, loss_test:0.01531, lr:3.56e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.325, tt:4462.215\n",
      "Ep:130, loss:0.00000, loss_test:0.01533, lr:3.52e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.321, tt:4496.090\n",
      "Ep:131, loss:0.00000, loss_test:0.01538, lr:3.49e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.335, tt:4532.177\n",
      "Ep:132, loss:0.00000, loss_test:0.01544, lr:3.45e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.340, tt:4567.160\n",
      "Ep:133, loss:0.00000, loss_test:0.01546, lr:3.42e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.345, tt:4602.296\n",
      "Ep:134, loss:0.00000, loss_test:0.01551, lr:3.38e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.386, tt:4642.135\n",
      "Ep:135, loss:0.00000, loss_test:0.01558, lr:3.35e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.382, tt:4675.978\n",
      "Ep:136, loss:0.00000, loss_test:0.01560, lr:3.32e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.395, tt:4712.113\n",
      "Ep:137, loss:0.00000, loss_test:0.01564, lr:3.28e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.401, tt:4747.396\n",
      "Ep:138, loss:0.00000, loss_test:0.01568, lr:3.25e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.405, tt:4782.314\n",
      "Ep:139, loss:0.00000, loss_test:0.01571, lr:3.22e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.404, tt:4816.561\n",
      "Ep:140, loss:0.00000, loss_test:0.01574, lr:3.19e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.412, tt:4852.076\n",
      "Ep:141, loss:0.00000, loss_test:0.01579, lr:3.15e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.407, tt:4885.726\n",
      "Ep:142, loss:0.00000, loss_test:0.01584, lr:3.12e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.414, tt:4921.255\n",
      "Ep:143, loss:0.00000, loss_test:0.01588, lr:3.09e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.427, tt:4957.430\n",
      "Ep:144, loss:0.00000, loss_test:0.01588, lr:3.06e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.426, tt:4991.721\n",
      "Ep:145, loss:0.00000, loss_test:0.01590, lr:3.03e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.432, tt:5027.080\n",
      "Ep:146, loss:0.00000, loss_test:0.01596, lr:3.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.436, tt:5062.033\n",
      "Ep:147, loss:0.00000, loss_test:0.01600, lr:2.97e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.438, tt:5096.751\n",
      "Ep:148, loss:0.00000, loss_test:0.01602, lr:2.94e-02, fs:0.78571 (r=0.667,p=0.957),  time:34.442, tt:5131.915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:149, loss:0.00000, loss_test:0.01607, lr:2.91e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.448, tt:5167.142\n",
      "Ep:150, loss:0.00000, loss_test:0.01609, lr:2.88e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.446, tt:5201.354\n",
      "Ep:151, loss:0.00000, loss_test:0.01611, lr:2.85e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.452, tt:5236.697\n",
      "Ep:152, loss:0.00000, loss_test:0.01615, lr:2.82e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.449, tt:5270.736\n",
      "Ep:153, loss:0.00000, loss_test:0.01616, lr:2.80e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.440, tt:5303.811\n",
      "Ep:154, loss:0.00000, loss_test:0.01621, lr:2.77e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.441, tt:5338.290\n",
      "Ep:155, loss:0.00000, loss_test:0.01623, lr:2.74e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.442, tt:5372.988\n",
      "Ep:156, loss:0.00000, loss_test:0.01628, lr:2.71e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.444, tt:5407.750\n",
      "Ep:157, loss:0.00000, loss_test:0.01631, lr:2.69e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.452, tt:5443.393\n",
      "Ep:158, loss:0.00000, loss_test:0.01633, lr:2.66e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.472, tt:5480.980\n",
      "Ep:159, loss:0.00000, loss_test:0.01638, lr:2.63e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.482, tt:5517.161\n",
      "Ep:160, loss:0.00000, loss_test:0.01639, lr:2.61e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.478, tt:5550.961\n",
      "Ep:161, loss:0.00000, loss_test:0.01642, lr:2.58e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.473, tt:5584.624\n",
      "Ep:162, loss:0.00000, loss_test:0.01645, lr:2.55e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.463, tt:5617.508\n",
      "Ep:163, loss:0.00000, loss_test:0.01649, lr:2.53e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.464, tt:5652.027\n",
      "Ep:164, loss:0.00000, loss_test:0.01652, lr:2.50e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.470, tt:5687.531\n",
      "Ep:165, loss:0.00000, loss_test:0.01652, lr:2.48e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.464, tt:5720.989\n",
      "Ep:166, loss:0.00000, loss_test:0.01653, lr:2.45e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.462, tt:5755.208\n",
      "Ep:167, loss:0.00000, loss_test:0.01659, lr:2.43e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.457, tt:5788.834\n",
      "Ep:168, loss:0.00000, loss_test:0.01663, lr:2.40e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.451, tt:5822.152\n",
      "Ep:169, loss:0.00000, loss_test:0.01664, lr:2.38e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.451, tt:5856.694\n",
      "Ep:170, loss:0.00000, loss_test:0.01664, lr:2.36e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.451, tt:5891.037\n",
      "Ep:171, loss:0.00000, loss_test:0.01669, lr:2.33e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.442, tt:5923.987\n",
      "Ep:172, loss:0.00000, loss_test:0.01670, lr:2.31e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.438, tt:5957.806\n",
      "Ep:173, loss:0.00000, loss_test:0.01672, lr:2.29e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.430, tt:5990.881\n",
      "Ep:174, loss:0.00000, loss_test:0.01676, lr:2.26e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.423, tt:6023.969\n",
      "Ep:175, loss:0.00000, loss_test:0.01677, lr:2.24e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.419, tt:6057.729\n",
      "Ep:176, loss:0.00000, loss_test:0.01679, lr:2.22e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.416, tt:6091.595\n",
      "Ep:177, loss:0.00000, loss_test:0.01684, lr:2.20e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.411, tt:6125.187\n",
      "Ep:178, loss:0.00000, loss_test:0.01686, lr:2.17e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.432, tt:6163.361\n",
      "Ep:179, loss:0.00000, loss_test:0.01687, lr:2.15e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.426, tt:6196.736\n",
      "Ep:180, loss:0.00000, loss_test:0.01690, lr:2.13e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.417, tt:6229.530\n",
      "Ep:181, loss:0.00000, loss_test:0.01692, lr:2.11e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.426, tt:6265.576\n",
      "Ep:182, loss:0.00000, loss_test:0.01694, lr:2.09e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.423, tt:6299.443\n",
      "Ep:183, loss:0.00000, loss_test:0.01697, lr:2.07e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.409, tt:6331.342\n",
      "Ep:184, loss:0.00000, loss_test:0.01698, lr:2.05e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.418, tt:6367.241\n",
      "Ep:185, loss:0.00000, loss_test:0.01699, lr:2.03e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.418, tt:6401.753\n",
      "Ep:186, loss:0.00000, loss_test:0.01702, lr:2.01e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.416, tt:6435.756\n",
      "Ep:187, loss:0.00000, loss_test:0.01705, lr:1.99e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.419, tt:6470.767\n",
      "Ep:188, loss:0.00000, loss_test:0.01707, lr:1.97e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.425, tt:6506.262\n",
      "Ep:189, loss:0.00000, loss_test:0.01708, lr:1.95e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.426, tt:6541.022\n",
      "Ep:190, loss:0.00000, loss_test:0.01710, lr:1.93e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.424, tt:6574.979\n",
      "Ep:191, loss:0.00000, loss_test:0.01711, lr:1.91e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.428, tt:6610.229\n",
      "Ep:192, loss:0.00000, loss_test:0.01713, lr:1.89e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.415, tt:6642.037\n",
      "Ep:193, loss:0.00000, loss_test:0.01716, lr:1.87e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.410, tt:6675.572\n",
      "Ep:194, loss:0.00000, loss_test:0.01717, lr:1.85e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.410, tt:6709.984\n",
      "Ep:195, loss:0.00000, loss_test:0.01720, lr:1.83e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.411, tt:6744.518\n",
      "Ep:196, loss:0.00000, loss_test:0.01721, lr:1.81e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.408, tt:6778.458\n",
      "Ep:197, loss:0.00000, loss_test:0.01724, lr:1.80e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.411, tt:6813.352\n",
      "Ep:198, loss:0.00000, loss_test:0.01727, lr:1.78e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.404, tt:6846.431\n",
      "Ep:199, loss:0.00000, loss_test:0.01728, lr:1.76e-02, fs:0.76364 (r=0.636,p=0.955),  time:34.390, tt:6878.009\n",
      "Ep:200, loss:0.00000, loss_test:0.01730, lr:1.74e-02, fs:0.76364 (r=0.636,p=0.955),  time:34.375, tt:6909.416\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14170, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.036, tt:32.036\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13967, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.789, tt:65.578\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13581, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:33.651, tt:100.954\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12896, lr:1.00e-02, fs:0.67153 (r=0.929,p=0.526),  time:34.380, tt:137.520\n",
      "Ep:4, loss:0.00025, loss_test:0.12180, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:34.754, tt:173.770\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11928, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:34.914, tt:209.486\n",
      "Ep:6, loss:0.00023, loss_test:0.11898, lr:1.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:35.185, tt:246.294\n",
      "Ep:7, loss:0.00022, loss_test:0.11861, lr:1.00e-02, fs:0.67511 (r=0.808,p=0.580),  time:35.330, tt:282.637\n",
      "Ep:8, loss:0.00022, loss_test:0.11590, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:35.457, tt:319.115\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11091, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:35.537, tt:355.372\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11038, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:35.848, tt:394.333\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.11108, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:35.922, tt:431.064\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10627, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:36.024, tt:468.309\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10454, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:36.129, tt:505.806\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10545, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:36.218, tt:543.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00017, loss_test:0.10253, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:36.246, tt:579.929\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09987, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:36.279, tt:616.744\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09895, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:36.354, tt:654.379\n",
      "Ep:18, loss:0.00015, loss_test:0.09732, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:36.360, tt:690.836\n",
      "Ep:19, loss:0.00014, loss_test:0.09556, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:36.349, tt:726.976\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09287, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:36.455, tt:765.553\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09232, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:36.577, tt:804.692\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.09106, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:36.607, tt:841.963\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08921, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:36.663, tt:879.923\n",
      "Ep:24, loss:0.00011, loss_test:0.08740, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:36.735, tt:918.382\n",
      "Ep:25, loss:0.00011, loss_test:0.08680, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:36.720, tt:954.728\n",
      "Ep:26, loss:0.00010, loss_test:0.08524, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:36.736, tt:991.865\n",
      "Ep:27, loss:0.00010, loss_test:0.08325, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:36.731, tt:1028.472\n",
      "Ep:28, loss:0.00009, loss_test:0.08488, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:36.714, tt:1064.700\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.08088, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:36.784, tt:1103.515\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.08398, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:36.792, tt:1140.546\n",
      "Ep:31, loss:0.00008, loss_test:0.07897, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:36.796, tt:1177.463\n",
      "Ep:32, loss:0.00008, loss_test:0.08330, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:36.813, tt:1214.826\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00007, loss_test:0.08003, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.865, tt:1253.418\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.07826, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.852, tt:1289.825\n",
      "Ep:35, loss:0.00006, loss_test:0.08208, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:36.888, tt:1327.984\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.07669, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.894, tt:1365.079\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.08167, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:36.874, tt:1401.226\n",
      "Ep:38, loss:0.00006, loss_test:0.07868, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:36.872, tt:1438.013\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07850, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:36.844, tt:1473.744\n",
      "Ep:40, loss:0.00005, loss_test:0.08385, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:36.846, tt:1510.699\n",
      "Ep:41, loss:0.00005, loss_test:0.07629, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:36.853, tt:1547.814\n",
      "Ep:42, loss:0.00005, loss_test:0.08034, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:36.885, tt:1586.070\n",
      "Ep:43, loss:0.00004, loss_test:0.07889, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:36.894, tt:1623.320\n",
      "Ep:44, loss:0.00004, loss_test:0.07961, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:36.897, tt:1660.347\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.07834, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:36.920, tt:1698.335\n",
      "Ep:46, loss:0.00004, loss_test:0.07803, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:36.932, tt:1735.797\n",
      "Ep:47, loss:0.00004, loss_test:0.08467, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:37.058, tt:1778.771\n",
      "Ep:48, loss:0.00004, loss_test:0.07777, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:37.124, tt:1819.088\n",
      "Ep:49, loss:0.00003, loss_test:0.08064, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:37.118, tt:1855.896\n",
      "Ep:50, loss:0.00003, loss_test:0.07981, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:37.065, tt:1890.297\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00003, loss_test:0.08468, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:37.097, tt:1929.069\n",
      "Ep:52, loss:0.00003, loss_test:0.08351, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:37.057, tt:1964.008\n",
      "Ep:53, loss:0.00003, loss_test:0.08362, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:37.161, tt:2006.701\n",
      "Ep:54, loss:0.00003, loss_test:0.08760, lr:1.00e-02, fs:0.75904 (r=0.636,p=0.940),  time:37.130, tt:2042.131\n",
      "Ep:55, loss:0.00003, loss_test:0.07961, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:37.103, tt:2077.768\n",
      "Ep:56, loss:0.00003, loss_test:0.08256, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:37.077, tt:2113.412\n",
      "Ep:57, loss:0.00003, loss_test:0.08252, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:37.056, tt:2149.265\n",
      "Ep:58, loss:0.00003, loss_test:0.08123, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:37.028, tt:2184.668\n",
      "Ep:59, loss:0.00002, loss_test:0.08031, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:36.997, tt:2219.794\n",
      "Ep:60, loss:0.00002, loss_test:0.08024, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:36.965, tt:2254.878\n",
      "Ep:61, loss:0.00002, loss_test:0.08450, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:36.926, tt:2289.424\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.07941, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:36.908, tt:2325.202\n",
      "Ep:63, loss:0.00002, loss_test:0.08244, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.876, tt:2360.041\n",
      "Ep:64, loss:0.00002, loss_test:0.08492, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:36.875, tt:2396.874\n",
      "Ep:65, loss:0.00002, loss_test:0.07747, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:36.874, tt:2433.705\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.08379, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.868, tt:2470.167\n",
      "Ep:67, loss:0.00002, loss_test:0.08363, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:36.869, tt:2507.101\n",
      "Ep:68, loss:0.00002, loss_test:0.08038, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:36.861, tt:2543.385\n",
      "Ep:69, loss:0.00002, loss_test:0.08605, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:36.860, tt:2580.200\n",
      "Ep:70, loss:0.00002, loss_test:0.07928, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:36.848, tt:2616.215\n",
      "Ep:71, loss:0.00001, loss_test:0.08158, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:36.837, tt:2652.254\n",
      "Ep:72, loss:0.00001, loss_test:0.08296, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:36.823, tt:2688.114\n",
      "Ep:73, loss:0.00001, loss_test:0.08124, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.825, tt:2725.033\n",
      "Ep:74, loss:0.00001, loss_test:0.08201, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:36.816, tt:2761.173\n",
      "Ep:75, loss:0.00001, loss_test:0.08325, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:36.820, tt:2798.337\n",
      "Ep:76, loss:0.00001, loss_test:0.08405, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:36.825, tt:2835.561\n",
      "Ep:77, loss:0.00001, loss_test:0.08323, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.802, tt:2870.573\n",
      "Ep:78, loss:0.00001, loss_test:0.08550, lr:9.80e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.774, tt:2905.172\n",
      "Ep:79, loss:0.00001, loss_test:0.08177, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.742, tt:2939.388\n",
      "Ep:80, loss:0.00001, loss_test:0.08346, lr:9.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.709, tt:2973.407\n",
      "Ep:81, loss:0.00001, loss_test:0.08422, lr:9.51e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.686, tt:3008.257\n",
      "Ep:82, loss:0.00001, loss_test:0.08288, lr:9.41e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.669, tt:3043.543\n",
      "Ep:83, loss:0.00001, loss_test:0.08426, lr:9.32e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.667, tt:3080.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:84, loss:0.00001, loss_test:0.08139, lr:9.23e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.638, tt:3114.221\n",
      "Ep:85, loss:0.00001, loss_test:0.08291, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.628, tt:3150.033\n",
      "Ep:86, loss:0.00001, loss_test:0.08296, lr:9.04e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.602, tt:3184.403\n",
      "Ep:87, loss:0.00001, loss_test:0.08276, lr:8.95e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.595, tt:3220.372\n",
      "Ep:88, loss:0.00001, loss_test:0.08177, lr:8.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.570, tt:3254.724\n",
      "Ep:89, loss:0.00001, loss_test:0.08262, lr:8.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.553, tt:3289.811\n",
      "Ep:90, loss:0.00001, loss_test:0.08275, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.541, tt:3325.236\n",
      "Ep:91, loss:0.00001, loss_test:0.08174, lr:8.60e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.516, tt:3359.497\n",
      "Ep:92, loss:0.00001, loss_test:0.08398, lr:8.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.505, tt:3395.000\n",
      "Ep:93, loss:0.00001, loss_test:0.08342, lr:8.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.488, tt:3429.915\n",
      "Ep:94, loss:0.00001, loss_test:0.08192, lr:8.35e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.465, tt:3464.169\n",
      "Ep:95, loss:0.00001, loss_test:0.08414, lr:8.26e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.452, tt:3499.372\n",
      "Ep:96, loss:0.00001, loss_test:0.08233, lr:8.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.434, tt:3534.075\n",
      "Ep:97, loss:0.00001, loss_test:0.08299, lr:8.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.426, tt:3569.715\n",
      "Ep:98, loss:0.00001, loss_test:0.08252, lr:8.02e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.409, tt:3604.523\n",
      "Ep:99, loss:0.00001, loss_test:0.08526, lr:7.94e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.392, tt:3639.239\n",
      "Ep:100, loss:0.00001, loss_test:0.08606, lr:7.86e-03, fs:0.84746 (r=0.758,p=0.962),  time:36.400, tt:3676.386\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.08326, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.388, tt:3711.580\n",
      "Ep:102, loss:0.00001, loss_test:0.08386, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.372, tt:3746.356\n",
      "Ep:103, loss:0.00001, loss_test:0.08223, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.341, tt:3779.466\n",
      "Ep:104, loss:0.00001, loss_test:0.08339, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.326, tt:3814.206\n",
      "Ep:105, loss:0.00001, loss_test:0.08343, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.306, tt:3848.476\n",
      "Ep:106, loss:0.00001, loss_test:0.08222, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.278, tt:3881.750\n",
      "Ep:107, loss:0.00001, loss_test:0.08454, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.261, tt:3916.206\n",
      "Ep:108, loss:0.00001, loss_test:0.08440, lr:7.86e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.253, tt:3951.525\n",
      "Ep:109, loss:0.00001, loss_test:0.08299, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.224, tt:3984.681\n",
      "Ep:110, loss:0.00000, loss_test:0.08305, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.196, tt:4017.729\n",
      "Ep:111, loss:0.00000, loss_test:0.08392, lr:7.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.176, tt:4051.724\n",
      "Ep:112, loss:0.00000, loss_test:0.08474, lr:7.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.150, tt:4084.927\n",
      "Ep:113, loss:0.00000, loss_test:0.08203, lr:7.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.135, tt:4119.442\n",
      "Ep:114, loss:0.00000, loss_test:0.08539, lr:7.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.118, tt:4153.605\n",
      "Ep:115, loss:0.00000, loss_test:0.08371, lr:7.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.088, tt:4186.157\n",
      "Ep:116, loss:0.00000, loss_test:0.08399, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.034, tt:4215.996\n",
      "Ep:117, loss:0.00000, loss_test:0.08360, lr:7.40e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.983, tt:4246.007\n",
      "Ep:118, loss:0.00000, loss_test:0.08276, lr:7.32e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.932, tt:4275.874\n",
      "Ep:119, loss:0.00000, loss_test:0.08444, lr:7.25e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.870, tt:4304.382\n",
      "Ep:120, loss:0.00000, loss_test:0.08478, lr:7.18e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.827, tt:4335.097\n",
      "Ep:121, loss:0.00000, loss_test:0.08391, lr:7.11e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.776, tt:4364.668\n",
      "Ep:122, loss:0.00000, loss_test:0.08447, lr:7.03e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.736, tt:4395.521\n",
      "Ep:123, loss:0.00000, loss_test:0.08448, lr:6.96e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.696, tt:4426.351\n",
      "Ep:124, loss:0.00000, loss_test:0.08389, lr:6.89e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.661, tt:4457.574\n",
      "Ep:125, loss:0.00000, loss_test:0.08329, lr:6.83e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.621, tt:4488.207\n",
      "Ep:126, loss:0.00000, loss_test:0.08406, lr:6.76e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.591, tt:4520.006\n",
      "Ep:127, loss:0.00000, loss_test:0.08439, lr:6.69e-03, fs:0.82486 (r=0.737,p=0.936),  time:35.555, tt:4551.018\n",
      "Ep:128, loss:0.00000, loss_test:0.08362, lr:6.62e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.533, tt:4583.781\n",
      "Ep:129, loss:0.00000, loss_test:0.08446, lr:6.56e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.497, tt:4614.598\n",
      "Ep:130, loss:0.00000, loss_test:0.08399, lr:6.49e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.461, tt:4645.409\n",
      "Ep:131, loss:0.00000, loss_test:0.08412, lr:6.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.432, tt:4677.064\n",
      "Ep:132, loss:0.00000, loss_test:0.08502, lr:6.36e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.417, tt:4710.462\n",
      "Ep:133, loss:0.00000, loss_test:0.08369, lr:6.30e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.408, tt:4744.715\n",
      "Ep:134, loss:0.00000, loss_test:0.08503, lr:6.24e-03, fs:0.82486 (r=0.737,p=0.936),  time:35.390, tt:4777.647\n",
      "Ep:135, loss:0.00000, loss_test:0.08546, lr:6.17e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.377, tt:4811.227\n",
      "Ep:136, loss:0.00000, loss_test:0.08385, lr:6.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.353, tt:4843.315\n",
      "Ep:137, loss:0.00000, loss_test:0.08460, lr:6.05e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.336, tt:4876.414\n",
      "Ep:138, loss:0.00000, loss_test:0.08431, lr:5.99e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.312, tt:4908.333\n",
      "Ep:139, loss:0.00000, loss_test:0.08531, lr:5.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:35.288, tt:4940.377\n",
      "Ep:140, loss:0.00000, loss_test:0.08608, lr:5.87e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.263, tt:4972.076\n",
      "Ep:141, loss:0.00000, loss_test:0.08509, lr:5.81e-03, fs:0.81609 (r=0.717,p=0.947),  time:35.243, tt:5004.479\n",
      "Ep:142, loss:0.00000, loss_test:0.08462, lr:5.75e-03, fs:0.80925 (r=0.707,p=0.946),  time:35.238, tt:5039.010\n",
      "Ep:143, loss:0.00000, loss_test:0.08491, lr:5.70e-03, fs:0.80925 (r=0.707,p=0.946),  time:35.235, tt:5073.802\n",
      "Ep:144, loss:0.00000, loss_test:0.08440, lr:5.64e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.223, tt:5107.285\n",
      "Ep:145, loss:0.00000, loss_test:0.08477, lr:5.58e-03, fs:0.80925 (r=0.707,p=0.946),  time:35.200, tt:5139.140\n",
      "Ep:146, loss:0.00000, loss_test:0.08443, lr:5.53e-03, fs:0.80925 (r=0.707,p=0.946),  time:35.181, tt:5171.583\n",
      "Ep:147, loss:0.00000, loss_test:0.08440, lr:5.47e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.177, tt:5206.143\n",
      "Ep:148, loss:0.00000, loss_test:0.08495, lr:5.42e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.163, tt:5239.266\n",
      "Ep:149, loss:0.00000, loss_test:0.08444, lr:5.36e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.141, tt:5271.213\n",
      "Ep:150, loss:0.00000, loss_test:0.08524, lr:5.31e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.102, tt:5300.361\n",
      "Ep:151, loss:0.00000, loss_test:0.08495, lr:5.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:35.073, tt:5331.097\n",
      "Ep:152, loss:0.00000, loss_test:0.08477, lr:5.20e-03, fs:0.78107 (r=0.667,p=0.943),  time:35.048, tt:5362.388\n",
      "Ep:153, loss:0.00000, loss_test:0.08564, lr:5.15e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.024, tt:5393.658\n",
      "Ep:154, loss:0.00000, loss_test:0.08540, lr:5.10e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.999, tt:5424.825\n",
      "Ep:155, loss:0.00000, loss_test:0.08524, lr:5.05e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.962, tt:5454.032\n",
      "Ep:156, loss:0.00000, loss_test:0.08535, lr:5.00e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.937, tt:5485.104\n",
      "Ep:157, loss:0.00000, loss_test:0.08566, lr:4.95e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.919, tt:5517.160\n",
      "Ep:158, loss:0.00000, loss_test:0.08561, lr:4.90e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.893, tt:5548.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:159, loss:0.00000, loss_test:0.08513, lr:4.85e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.861, tt:5577.777\n",
      "Ep:160, loss:0.00000, loss_test:0.08544, lr:4.80e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.841, tt:5609.381\n",
      "Ep:161, loss:0.00000, loss_test:0.08569, lr:4.75e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.818, tt:5640.580\n",
      "Ep:162, loss:0.00000, loss_test:0.08575, lr:4.71e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.789, tt:5670.532\n",
      "Ep:163, loss:0.00000, loss_test:0.08535, lr:4.66e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.775, tt:5703.070\n",
      "Ep:164, loss:0.00000, loss_test:0.08607, lr:4.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.762, tt:5735.724\n",
      "Ep:165, loss:0.00000, loss_test:0.08599, lr:4.57e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.749, tt:5768.331\n",
      "Ep:166, loss:0.00000, loss_test:0.08638, lr:4.52e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.739, tt:5801.434\n",
      "Ep:167, loss:0.00000, loss_test:0.08701, lr:4.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.724, tt:5833.640\n",
      "Ep:168, loss:0.00000, loss_test:0.08659, lr:4.43e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.707, tt:5865.447\n",
      "Ep:169, loss:0.00000, loss_test:0.08599, lr:4.39e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.689, tt:5897.054\n",
      "Ep:170, loss:0.00000, loss_test:0.08607, lr:4.34e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.673, tt:5929.029\n",
      "Ep:171, loss:0.00000, loss_test:0.08615, lr:4.30e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.656, tt:5960.800\n",
      "Ep:172, loss:0.00000, loss_test:0.08655, lr:4.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.636, tt:5991.969\n",
      "Ep:173, loss:0.00000, loss_test:0.08619, lr:4.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.623, tt:6024.359\n",
      "Ep:174, loss:0.00000, loss_test:0.08576, lr:4.17e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.607, tt:6056.254\n",
      "Ep:175, loss:0.00000, loss_test:0.08661, lr:4.13e-03, fs:0.78571 (r=0.667,p=0.957),  time:34.597, tt:6089.158\n",
      "Ep:176, loss:0.00000, loss_test:0.08720, lr:4.09e-03, fs:0.78571 (r=0.667,p=0.957),  time:34.577, tt:6120.082\n",
      "Ep:177, loss:0.00000, loss_test:0.08661, lr:4.05e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.546, tt:6149.229\n",
      "Ep:178, loss:0.00000, loss_test:0.08600, lr:4.01e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.527, tt:6180.304\n",
      "Ep:179, loss:0.00000, loss_test:0.08605, lr:3.97e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.508, tt:6211.366\n",
      "Ep:180, loss:0.00000, loss_test:0.08599, lr:3.93e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.490, tt:6242.757\n",
      "Ep:181, loss:0.00000, loss_test:0.08638, lr:3.89e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.481, tt:6275.532\n",
      "Ep:182, loss:0.00000, loss_test:0.08634, lr:3.85e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.472, tt:6308.398\n",
      "Ep:183, loss:0.00000, loss_test:0.08569, lr:3.81e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.458, tt:6340.202\n",
      "Ep:184, loss:0.00000, loss_test:0.08599, lr:3.77e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.440, tt:6371.370\n",
      "Ep:185, loss:0.00000, loss_test:0.08614, lr:3.73e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.432, tt:6404.412\n",
      "Ep:186, loss:0.00000, loss_test:0.08588, lr:3.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.415, tt:6435.534\n",
      "Ep:187, loss:0.00000, loss_test:0.08590, lr:3.66e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.400, tt:6467.186\n",
      "Ep:188, loss:0.00000, loss_test:0.08605, lr:3.62e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.375, tt:6496.885\n",
      "Ep:189, loss:0.00000, loss_test:0.08576, lr:3.59e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.359, tt:6528.256\n",
      "Ep:190, loss:0.00000, loss_test:0.08585, lr:3.55e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.348, tt:6560.439\n",
      "Ep:191, loss:0.00000, loss_test:0.08636, lr:3.52e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.325, tt:6590.467\n",
      "Ep:192, loss:0.00000, loss_test:0.08629, lr:3.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.320, tt:6623.845\n",
      "Ep:193, loss:0.00000, loss_test:0.08587, lr:3.45e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.302, tt:6654.589\n",
      "Ep:194, loss:0.00000, loss_test:0.08586, lr:3.41e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.291, tt:6686.654\n",
      "Ep:195, loss:0.00000, loss_test:0.08592, lr:3.38e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.287, tt:6720.157\n",
      "Ep:196, loss:0.00000, loss_test:0.08604, lr:3.34e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.254, tt:6747.975\n",
      "Ep:197, loss:0.00000, loss_test:0.08675, lr:3.31e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.222, tt:6775.961\n",
      "Ep:198, loss:0.00000, loss_test:0.08665, lr:3.28e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.179, tt:6801.532\n",
      "Ep:199, loss:0.00000, loss_test:0.08620, lr:3.24e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.114, tt:6822.877\n",
      "Ep:200, loss:0.00000, loss_test:0.08590, lr:3.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:34.017, tt:6837.496\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02131, lr:6.00e-02, fs:0.62555 (r=0.816,p=0.507),  time:20.148, tt:20.148\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02299, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.814, tt:47.628\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02380, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.897, tt:83.692\n",
      "Ep:3, loss:0.00005, loss_test:0.02305, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.381, tt:121.523\n",
      "Ep:4, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.63780 (r=0.931,p=0.485),  time:31.973, tt:159.864\n",
      "Ep:5, loss:0.00004, loss_test:0.02092, lr:6.00e-02, fs:0.62447 (r=0.851,p=0.493),  time:33.031, tt:198.187\n",
      "Ep:6, loss:0.00004, loss_test:0.02122, lr:6.00e-02, fs:0.65728 (r=0.805,p=0.556),  time:33.906, tt:237.343\n",
      "Ep:7, loss:0.00004, loss_test:0.02254, lr:6.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:34.700, tt:277.601\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02264, lr:6.00e-02, fs:0.68085 (r=0.736,p=0.634),  time:35.489, tt:319.397\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02128, lr:6.00e-02, fs:0.66321 (r=0.736,p=0.604),  time:35.853, tt:358.532\n",
      "Ep:10, loss:0.00003, loss_test:0.02001, lr:6.00e-02, fs:0.62857 (r=0.759,p=0.537),  time:36.161, tt:397.774\n",
      "Ep:11, loss:0.00003, loss_test:0.01941, lr:6.00e-02, fs:0.61187 (r=0.770,p=0.508),  time:36.461, tt:437.529\n",
      "Ep:12, loss:0.00003, loss_test:0.01906, lr:6.00e-02, fs:0.62673 (r=0.782,p=0.523),  time:36.660, tt:476.581\n",
      "Ep:13, loss:0.00003, loss_test:0.01899, lr:6.00e-02, fs:0.65072 (r=0.782,p=0.557),  time:36.824, tt:515.539\n",
      "Ep:14, loss:0.00003, loss_test:0.01913, lr:6.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:37.108, tt:556.614\n",
      "Ep:15, loss:0.00003, loss_test:0.01917, lr:6.00e-02, fs:0.70270 (r=0.747,p=0.663),  time:37.233, tt:595.730\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01886, lr:6.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:37.338, tt:634.747\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01839, lr:6.00e-02, fs:0.71429 (r=0.747,p=0.684),  time:37.557, tt:676.026\n",
      "Ep:18, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.71658 (r=0.770,p=0.670),  time:37.561, tt:713.661\n",
      "Ep:19, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.74074 (r=0.805,p=0.686),  time:37.696, tt:753.913\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01752, lr:6.00e-02, fs:0.77005 (r=0.828,p=0.720),  time:37.772, tt:793.215\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01757, lr:6.00e-02, fs:0.77348 (r=0.805,p=0.745),  time:37.837, tt:832.403\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01738, lr:6.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:37.948, tt:872.810\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01715, lr:6.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:37.902, tt:909.652\n",
      "Ep:24, loss:0.00002, loss_test:0.01701, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:38.039, tt:950.978\n",
      "Ep:25, loss:0.00002, loss_test:0.01685, lr:6.00e-02, fs:0.79781 (r=0.839,p=0.760),  time:38.144, tt:991.747\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01671, lr:6.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:38.272, tt:1033.357\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01666, lr:6.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:38.287, tt:1072.047\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01646, lr:6.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:38.401, tt:1113.629\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01626, lr:6.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:38.458, tt:1153.748\n",
      "Ep:30, loss:0.00002, loss_test:0.01621, lr:6.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:38.491, tt:1193.211\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:38.564, tt:1234.046\n",
      "Ep:32, loss:0.00002, loss_test:0.01612, lr:6.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:38.635, tt:1274.958\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01617, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:38.685, tt:1315.302\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:38.743, tt:1356.004\n",
      "Ep:35, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:38.817, tt:1397.412\n",
      "Ep:36, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:38.907, tt:1439.561\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:39.076, tt:1484.885\n",
      "Ep:38, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:39.213, tt:1529.311\n",
      "Ep:39, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:39.296, tt:1571.858\n",
      "Ep:40, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:39.331, tt:1612.580\n",
      "Ep:41, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.356, tt:1652.950\n",
      "Ep:42, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.385, tt:1693.548\n",
      "Ep:43, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.371, tt:1732.327\n",
      "Ep:44, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.392, tt:1772.638\n",
      "Ep:45, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.416, tt:1813.147\n",
      "Ep:46, loss:0.00001, loss_test:0.01637, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.438, tt:1853.606\n",
      "Ep:47, loss:0.00001, loss_test:0.01634, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.434, tt:1892.853\n",
      "Ep:48, loss:0.00001, loss_test:0.01641, lr:5.94e-02, fs:0.84706 (r=0.828,p=0.867),  time:39.469, tt:1933.996\n",
      "Ep:49, loss:0.00001, loss_test:0.01663, lr:5.88e-02, fs:0.85207 (r=0.828,p=0.878),  time:39.531, tt:1976.551\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01676, lr:5.88e-02, fs:0.85207 (r=0.828,p=0.878),  time:39.560, tt:2017.541\n",
      "Ep:51, loss:0.00001, loss_test:0.01669, lr:5.88e-02, fs:0.85207 (r=0.828,p=0.878),  time:39.542, tt:2056.206\n",
      "Ep:52, loss:0.00001, loss_test:0.01683, lr:5.88e-02, fs:0.85714 (r=0.828,p=0.889),  time:39.573, tt:2097.365\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01702, lr:5.88e-02, fs:0.85714 (r=0.828,p=0.889),  time:39.575, tt:2137.071\n",
      "Ep:54, loss:0.00001, loss_test:0.01706, lr:5.88e-02, fs:0.85714 (r=0.828,p=0.889),  time:39.561, tt:2175.851\n",
      "Ep:55, loss:0.00001, loss_test:0.01720, lr:5.88e-02, fs:0.85714 (r=0.828,p=0.889),  time:39.582, tt:2216.619\n",
      "Ep:56, loss:0.00001, loss_test:0.01729, lr:5.88e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.585, tt:2256.365\n",
      "Ep:57, loss:0.00001, loss_test:0.01740, lr:5.88e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.594, tt:2296.440\n",
      "Ep:58, loss:0.00001, loss_test:0.01756, lr:5.88e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.612, tt:2337.116\n",
      "Ep:59, loss:0.00001, loss_test:0.01765, lr:5.88e-02, fs:0.85030 (r=0.816,p=0.887),  time:39.636, tt:2378.144\n",
      "Ep:60, loss:0.00001, loss_test:0.01767, lr:5.88e-02, fs:0.83636 (r=0.793,p=0.885),  time:39.658, tt:2419.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01795, lr:5.88e-02, fs:0.83636 (r=0.793,p=0.885),  time:39.639, tt:2457.619\n",
      "Ep:62, loss:0.00001, loss_test:0.01789, lr:5.88e-02, fs:0.83636 (r=0.793,p=0.885),  time:39.660, tt:2498.570\n",
      "Ep:63, loss:0.00001, loss_test:0.01808, lr:5.88e-02, fs:0.83636 (r=0.793,p=0.885),  time:39.691, tt:2540.239\n",
      "Ep:64, loss:0.00001, loss_test:0.01817, lr:5.82e-02, fs:0.83636 (r=0.793,p=0.885),  time:39.696, tt:2580.237\n",
      "Ep:65, loss:0.00001, loss_test:0.01827, lr:5.76e-02, fs:0.83636 (r=0.793,p=0.885),  time:39.686, tt:2619.296\n",
      "Ep:66, loss:0.00001, loss_test:0.01847, lr:5.71e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.688, tt:2659.105\n",
      "Ep:67, loss:0.00001, loss_test:0.01869, lr:5.65e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.684, tt:2698.509\n",
      "Ep:68, loss:0.00001, loss_test:0.01869, lr:5.59e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.658, tt:2736.431\n",
      "Ep:69, loss:0.00001, loss_test:0.01876, lr:5.54e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.659, tt:2776.155\n",
      "Ep:70, loss:0.00001, loss_test:0.01885, lr:5.48e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.657, tt:2815.659\n",
      "Ep:71, loss:0.00001, loss_test:0.01906, lr:5.43e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.668, tt:2856.113\n",
      "Ep:72, loss:0.00001, loss_test:0.01916, lr:5.37e-02, fs:0.82927 (r=0.782,p=0.883),  time:39.669, tt:2895.836\n",
      "Ep:73, loss:0.00001, loss_test:0.01928, lr:5.32e-02, fs:0.82209 (r=0.770,p=0.882),  time:39.668, tt:2935.463\n",
      "Ep:74, loss:0.00001, loss_test:0.01934, lr:5.27e-02, fs:0.82716 (r=0.770,p=0.893),  time:39.695, tt:2977.140\n",
      "Ep:75, loss:0.00001, loss_test:0.01944, lr:5.21e-02, fs:0.81988 (r=0.759,p=0.892),  time:39.699, tt:3017.158\n",
      "Ep:76, loss:0.00001, loss_test:0.01954, lr:5.16e-02, fs:0.82716 (r=0.770,p=0.893),  time:39.694, tt:3056.435\n",
      "Ep:77, loss:0.00001, loss_test:0.01957, lr:5.11e-02, fs:0.83230 (r=0.770,p=0.905),  time:39.682, tt:3095.205\n",
      "Ep:78, loss:0.00001, loss_test:0.01976, lr:5.06e-02, fs:0.83750 (r=0.770,p=0.918),  time:39.658, tt:3132.945\n",
      "Ep:79, loss:0.00001, loss_test:0.01988, lr:5.01e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.659, tt:3172.704\n",
      "Ep:80, loss:0.00001, loss_test:0.01988, lr:4.96e-02, fs:0.82278 (r=0.747,p=0.915),  time:39.650, tt:3211.656\n",
      "Ep:81, loss:0.00001, loss_test:0.01999, lr:4.91e-02, fs:0.82278 (r=0.747,p=0.915),  time:39.638, tt:3250.278\n",
      "Ep:82, loss:0.00001, loss_test:0.02010, lr:4.86e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.634, tt:3289.633\n",
      "Ep:83, loss:0.00001, loss_test:0.02019, lr:4.81e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.637, tt:3329.496\n",
      "Ep:84, loss:0.00001, loss_test:0.02037, lr:4.76e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.623, tt:3367.917\n",
      "Ep:85, loss:0.00001, loss_test:0.02040, lr:4.71e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.648, tt:3409.726\n",
      "Ep:86, loss:0.00001, loss_test:0.02051, lr:4.67e-02, fs:0.82278 (r=0.747,p=0.915),  time:39.645, tt:3449.153\n",
      "Ep:87, loss:0.00001, loss_test:0.02067, lr:4.62e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.713, tt:3494.752\n",
      "Ep:88, loss:0.00001, loss_test:0.02077, lr:4.57e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.724, tt:3535.450\n",
      "Ep:89, loss:0.00001, loss_test:0.02080, lr:4.53e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.735, tt:3576.176\n",
      "Ep:90, loss:0.00001, loss_test:0.02086, lr:4.48e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.725, tt:3614.933\n",
      "Ep:91, loss:0.00001, loss_test:0.02102, lr:4.44e-02, fs:0.81290 (r=0.724,p=0.926),  time:39.742, tt:3656.308\n",
      "Ep:92, loss:0.00001, loss_test:0.02110, lr:4.39e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.755, tt:3697.221\n",
      "Ep:93, loss:0.00001, loss_test:0.02113, lr:4.35e-02, fs:0.81290 (r=0.724,p=0.926),  time:39.769, tt:3738.243\n",
      "Ep:94, loss:0.00001, loss_test:0.02120, lr:4.31e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.774, tt:3778.538\n",
      "Ep:95, loss:0.00001, loss_test:0.02139, lr:4.26e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.779, tt:3818.777\n",
      "Ep:96, loss:0.00001, loss_test:0.02145, lr:4.22e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.785, tt:3859.187\n",
      "Ep:97, loss:0.00001, loss_test:0.02151, lr:4.18e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.775, tt:3897.901\n",
      "Ep:98, loss:0.00001, loss_test:0.02161, lr:4.14e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.788, tt:3938.969\n",
      "Ep:99, loss:0.00001, loss_test:0.02173, lr:4.10e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.817, tt:3981.691\n",
      "Ep:100, loss:0.00001, loss_test:0.02178, lr:4.05e-02, fs:0.79739 (r=0.701,p=0.924),  time:39.800, tt:4019.773\n",
      "Ep:101, loss:0.00001, loss_test:0.02178, lr:4.01e-02, fs:0.79739 (r=0.701,p=0.924),  time:39.812, tt:4060.812\n",
      "Ep:102, loss:0.00001, loss_test:0.02184, lr:3.97e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.830, tt:4102.507\n",
      "Ep:103, loss:0.00001, loss_test:0.02198, lr:3.93e-02, fs:0.80519 (r=0.713,p=0.925),  time:39.850, tt:4144.390\n",
      "Ep:104, loss:0.00001, loss_test:0.02206, lr:3.89e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.863, tt:4185.659\n",
      "Ep:105, loss:0.00001, loss_test:0.02210, lr:3.86e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.873, tt:4226.566\n",
      "Ep:106, loss:0.00001, loss_test:0.02214, lr:3.82e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.900, tt:4269.281\n",
      "Ep:107, loss:0.00001, loss_test:0.02224, lr:3.78e-02, fs:0.78947 (r=0.690,p=0.923),  time:39.910, tt:4310.257\n",
      "Ep:108, loss:0.00001, loss_test:0.02239, lr:3.74e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.916, tt:4350.800\n",
      "Ep:109, loss:0.00001, loss_test:0.02252, lr:3.70e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.924, tt:4391.628\n",
      "Ep:110, loss:0.00000, loss_test:0.02254, lr:3.67e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.938, tt:4433.114\n",
      "Ep:111, loss:0.00000, loss_test:0.02253, lr:3.63e-02, fs:0.78146 (r=0.678,p=0.922),  time:39.969, tt:4476.580\n",
      "Ep:112, loss:0.00000, loss_test:0.02265, lr:3.59e-02, fs:0.77333 (r=0.667,p=0.921),  time:39.985, tt:4518.303\n",
      "Ep:113, loss:0.00000, loss_test:0.02275, lr:3.56e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.009, tt:4561.014\n",
      "Ep:114, loss:0.00000, loss_test:0.02281, lr:3.52e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.016, tt:4601.794\n",
      "Ep:115, loss:0.00000, loss_test:0.02280, lr:3.49e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.024, tt:4642.759\n",
      "Ep:116, loss:0.00000, loss_test:0.02288, lr:3.45e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.039, tt:4684.547\n",
      "Ep:117, loss:0.00000, loss_test:0.02296, lr:3.42e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.054, tt:4726.401\n",
      "Ep:118, loss:0.00000, loss_test:0.02304, lr:3.38e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.051, tt:4766.109\n",
      "Ep:119, loss:0.00000, loss_test:0.02306, lr:3.35e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.058, tt:4806.961\n",
      "Ep:120, loss:0.00000, loss_test:0.02312, lr:3.32e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.067, tt:4848.065\n",
      "Ep:121, loss:0.00000, loss_test:0.02316, lr:3.28e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.060, tt:4887.351\n",
      "Ep:122, loss:0.00000, loss_test:0.02324, lr:3.25e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.072, tt:4928.888\n",
      "Ep:123, loss:0.00000, loss_test:0.02324, lr:3.22e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.074, tt:4969.124\n",
      "Ep:124, loss:0.00000, loss_test:0.02328, lr:3.19e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.097, tt:5012.115\n",
      "Ep:125, loss:0.00000, loss_test:0.02333, lr:3.15e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.107, tt:5053.529\n",
      "Ep:126, loss:0.00000, loss_test:0.02343, lr:3.12e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.131, tt:5096.620\n",
      "Ep:127, loss:0.00000, loss_test:0.02352, lr:3.09e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.133, tt:5136.979\n",
      "Ep:128, loss:0.00000, loss_test:0.02361, lr:3.06e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.206, tt:5186.610\n",
      "Ep:129, loss:0.00000, loss_test:0.02367, lr:3.03e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.219, tt:5228.469\n",
      "Ep:130, loss:0.00000, loss_test:0.02369, lr:3.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.223, tt:5269.215\n",
      "Ep:131, loss:0.00000, loss_test:0.02376, lr:2.97e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.234, tt:5310.947\n",
      "Ep:132, loss:0.00000, loss_test:0.02379, lr:2.94e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.239, tt:5351.843\n",
      "Ep:133, loss:0.00000, loss_test:0.02387, lr:2.91e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.258, tt:5394.530\n",
      "Ep:134, loss:0.00000, loss_test:0.02393, lr:2.88e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.261, tt:5435.239\n",
      "Ep:135, loss:0.00000, loss_test:0.02396, lr:2.85e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.263, tt:5475.707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02402, lr:2.82e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.281, tt:5518.522\n",
      "Ep:137, loss:0.00000, loss_test:0.02407, lr:2.80e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.287, tt:5559.597\n",
      "Ep:138, loss:0.00000, loss_test:0.02411, lr:2.77e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.307, tt:5602.739\n",
      "Ep:139, loss:0.00000, loss_test:0.02416, lr:2.74e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.305, tt:5642.755\n",
      "Ep:140, loss:0.00000, loss_test:0.02421, lr:2.71e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.314, tt:5684.231\n",
      "Ep:141, loss:0.00000, loss_test:0.02423, lr:2.69e-02, fs:0.77333 (r=0.667,p=0.921),  time:40.325, tt:5726.116\n",
      "Ep:142, loss:0.00000, loss_test:0.02432, lr:2.66e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.325, tt:5766.529\n",
      "Ep:143, loss:0.00000, loss_test:0.02439, lr:2.63e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.327, tt:5807.091\n",
      "Ep:144, loss:0.00000, loss_test:0.02436, lr:2.61e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.338, tt:5849.067\n",
      "Ep:145, loss:0.00000, loss_test:0.02440, lr:2.58e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.349, tt:5890.885\n",
      "Ep:146, loss:0.00000, loss_test:0.02447, lr:2.55e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.361, tt:5933.140\n",
      "Ep:147, loss:0.00000, loss_test:0.02453, lr:2.53e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.381, tt:5976.333\n",
      "Ep:148, loss:0.00000, loss_test:0.02452, lr:2.50e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.381, tt:6016.812\n",
      "Ep:149, loss:0.00000, loss_test:0.02455, lr:2.48e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.419, tt:6062.878\n",
      "Ep:150, loss:0.00000, loss_test:0.02462, lr:2.45e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.415, tt:6102.709\n",
      "Ep:151, loss:0.00000, loss_test:0.02466, lr:2.43e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.425, tt:6144.655\n",
      "Ep:152, loss:0.00000, loss_test:0.02470, lr:2.40e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.439, tt:6187.202\n",
      "Ep:153, loss:0.00000, loss_test:0.02476, lr:2.38e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.451, tt:6229.402\n",
      "Ep:154, loss:0.00000, loss_test:0.02484, lr:2.36e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.452, tt:6270.080\n",
      "Ep:155, loss:0.00000, loss_test:0.02484, lr:2.33e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.457, tt:6311.294\n",
      "Ep:156, loss:0.00000, loss_test:0.02484, lr:2.31e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.462, tt:6352.545\n",
      "Ep:157, loss:0.00000, loss_test:0.02487, lr:2.29e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.463, tt:6393.124\n",
      "Ep:158, loss:0.00000, loss_test:0.02493, lr:2.26e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.462, tt:6433.477\n",
      "Ep:159, loss:0.00000, loss_test:0.02494, lr:2.24e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.468, tt:6474.816\n",
      "Ep:160, loss:0.00000, loss_test:0.02499, lr:2.22e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.467, tt:6515.166\n",
      "Ep:161, loss:0.00000, loss_test:0.02501, lr:2.20e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.480, tt:6557.749\n",
      "Ep:162, loss:0.00000, loss_test:0.02508, lr:2.17e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.484, tt:6598.974\n",
      "Ep:163, loss:0.00000, loss_test:0.02517, lr:2.15e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.490, tt:6640.348\n",
      "Ep:164, loss:0.00000, loss_test:0.02516, lr:2.13e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.499, tt:6682.350\n",
      "Ep:165, loss:0.00000, loss_test:0.02517, lr:2.11e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.505, tt:6723.790\n",
      "Ep:166, loss:0.00000, loss_test:0.02525, lr:2.09e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.513, tt:6765.727\n",
      "Ep:167, loss:0.00000, loss_test:0.02529, lr:2.07e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.514, tt:6806.310\n",
      "Ep:168, loss:0.00000, loss_test:0.02530, lr:2.05e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.528, tt:6849.200\n",
      "Ep:169, loss:0.00000, loss_test:0.02534, lr:2.03e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.535, tt:6890.982\n",
      "Ep:170, loss:0.00000, loss_test:0.02541, lr:2.01e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.561, tt:6935.944\n",
      "Ep:171, loss:0.00000, loss_test:0.02541, lr:1.99e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.567, tt:6977.527\n",
      "Ep:172, loss:0.00000, loss_test:0.02541, lr:1.97e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.578, tt:7019.942\n",
      "Ep:173, loss:0.00000, loss_test:0.02542, lr:1.95e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.572, tt:7059.563\n",
      "Ep:174, loss:0.00000, loss_test:0.02546, lr:1.93e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.580, tt:7101.507\n",
      "Ep:175, loss:0.00000, loss_test:0.02550, lr:1.91e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.574, tt:7141.062\n",
      "Ep:176, loss:0.00000, loss_test:0.02552, lr:1.89e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.582, tt:7183.086\n",
      "Ep:177, loss:0.00000, loss_test:0.02555, lr:1.87e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.589, tt:7224.856\n",
      "Ep:178, loss:0.00000, loss_test:0.02561, lr:1.85e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.598, tt:7267.072\n",
      "Ep:179, loss:0.00000, loss_test:0.02561, lr:1.83e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.603, tt:7308.557\n",
      "Ep:180, loss:0.00000, loss_test:0.02564, lr:1.81e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.602, tt:7348.887\n",
      "Ep:181, loss:0.00000, loss_test:0.02571, lr:1.80e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.600, tt:7389.134\n",
      "Ep:182, loss:0.00000, loss_test:0.02573, lr:1.78e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.603, tt:7430.277\n",
      "Ep:183, loss:0.00000, loss_test:0.02569, lr:1.76e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.606, tt:7471.484\n",
      "Ep:184, loss:0.00000, loss_test:0.02573, lr:1.74e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.609, tt:7512.632\n",
      "Ep:185, loss:0.00000, loss_test:0.02578, lr:1.73e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.625, tt:7556.331\n",
      "Ep:186, loss:0.00000, loss_test:0.02582, lr:1.71e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.631, tt:7597.950\n",
      "Ep:187, loss:0.00000, loss_test:0.02584, lr:1.69e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.638, tt:7639.924\n",
      "Ep:188, loss:0.00000, loss_test:0.02587, lr:1.67e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.643, tt:7681.516\n",
      "Ep:189, loss:0.00000, loss_test:0.02589, lr:1.66e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.649, tt:7723.297\n",
      "Ep:190, loss:0.00000, loss_test:0.02591, lr:1.64e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.680, tt:7769.799\n",
      "Ep:191, loss:0.00000, loss_test:0.02595, lr:1.62e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.688, tt:7812.010\n",
      "Ep:192, loss:0.00000, loss_test:0.02596, lr:1.61e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.686, tt:7852.493\n",
      "Ep:193, loss:0.00000, loss_test:0.02597, lr:1.59e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.693, tt:7894.522\n",
      "Ep:194, loss:0.00000, loss_test:0.02604, lr:1.58e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.699, tt:7936.207\n",
      "Ep:195, loss:0.00000, loss_test:0.02607, lr:1.56e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.709, tt:7978.962\n",
      "Ep:196, loss:0.00000, loss_test:0.02607, lr:1.54e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.718, tt:8021.529\n",
      "Ep:197, loss:0.00000, loss_test:0.02607, lr:1.53e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.716, tt:8061.720\n",
      "Ep:198, loss:0.00000, loss_test:0.02608, lr:1.51e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.723, tt:8103.801\n",
      "Ep:199, loss:0.00000, loss_test:0.02612, lr:1.50e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.721, tt:8144.172\n",
      "Ep:200, loss:0.00000, loss_test:0.02615, lr:1.48e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.729, tt:8186.467\n",
      "Ep:201, loss:0.00000, loss_test:0.02618, lr:1.47e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.731, tt:8227.743\n",
      "Ep:202, loss:0.00000, loss_test:0.02620, lr:1.45e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.739, tt:8270.038\n",
      "Ep:203, loss:0.00000, loss_test:0.02621, lr:1.44e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.744, tt:8311.763\n",
      "Ep:204, loss:0.00000, loss_test:0.02622, lr:1.43e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.742, tt:8352.166\n",
      "Ep:205, loss:0.00000, loss_test:0.02626, lr:1.41e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.740, tt:8392.475\n",
      "Ep:206, loss:0.00000, loss_test:0.02628, lr:1.40e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.755, tt:8436.239\n",
      "Ep:207, loss:0.00000, loss_test:0.02629, lr:1.38e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.759, tt:8477.801\n",
      "Ep:208, loss:0.00000, loss_test:0.02632, lr:1.37e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.767, tt:8520.337\n",
      "Ep:209, loss:0.00000, loss_test:0.02634, lr:1.36e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.765, tt:8560.600\n",
      "Ep:210, loss:0.00000, loss_test:0.02636, lr:1.34e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.755, tt:8599.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:211, loss:0.00000, loss_test:0.02637, lr:1.33e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.757, tt:8640.586\n",
      "Ep:212, loss:0.00000, loss_test:0.02640, lr:1.32e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.746, tt:8678.930\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14265, lr:1.00e-02, fs:0.64062 (r=0.943,p=0.485),  time:39.269, tt:39.269\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14046, lr:1.00e-02, fs:0.64314 (r=0.943,p=0.488),  time:32.953, tt:65.906\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13611, lr:1.00e-02, fs:0.62857 (r=0.885,p=0.487),  time:35.749, tt:107.247\n",
      "Ep:3, loss:0.00026, loss_test:0.12879, lr:1.00e-02, fs:0.64035 (r=0.839,p=0.518),  time:37.866, tt:151.462\n",
      "Ep:4, loss:0.00024, loss_test:0.12192, lr:1.00e-02, fs:0.65990 (r=0.747,p=0.591),  time:38.907, tt:194.536\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11908, lr:1.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:39.668, tt:238.007\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.11591, lr:1.00e-02, fs:0.70000 (r=0.644,p=0.767),  time:40.402, tt:282.815\n",
      "Ep:7, loss:0.00021, loss_test:0.11230, lr:1.00e-02, fs:0.70520 (r=0.701,p=0.709),  time:40.808, tt:326.467\n",
      "Ep:8, loss:0.00020, loss_test:0.10823, lr:1.00e-02, fs:0.70370 (r=0.655,p=0.760),  time:40.994, tt:368.946\n",
      "Ep:9, loss:0.00019, loss_test:0.10515, lr:1.00e-02, fs:0.69737 (r=0.609,p=0.815),  time:41.200, tt:412.002\n",
      "Ep:10, loss:0.00019, loss_test:0.10193, lr:1.00e-02, fs:0.70199 (r=0.609,p=0.828),  time:41.290, tt:454.187\n",
      "Ep:11, loss:0.00018, loss_test:0.09822, lr:1.00e-02, fs:0.72611 (r=0.655,p=0.814),  time:41.360, tt:496.319\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.09684, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:41.551, tt:540.161\n",
      "Ep:13, loss:0.00017, loss_test:0.09452, lr:1.00e-02, fs:0.72258 (r=0.644,p=0.824),  time:41.681, tt:583.529\n",
      "Ep:14, loss:0.00016, loss_test:0.09140, lr:1.00e-02, fs:0.74684 (r=0.678,p=0.831),  time:41.865, tt:627.978\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.08968, lr:1.00e-02, fs:0.76250 (r=0.701,p=0.836),  time:41.972, tt:671.555\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08976, lr:1.00e-02, fs:0.77500 (r=0.713,p=0.849),  time:41.988, tt:713.795\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.08663, lr:1.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:42.125, tt:758.255\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08670, lr:1.00e-02, fs:0.78261 (r=0.724,p=0.851),  time:42.167, tt:801.164\n",
      "Ep:19, loss:0.00013, loss_test:0.08435, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:42.212, tt:844.237\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08286, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:42.207, tt:886.348\n",
      "Ep:21, loss:0.00012, loss_test:0.08156, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:42.246, tt:929.419\n",
      "Ep:22, loss:0.00012, loss_test:0.08014, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:42.414, tt:975.523\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.07989, lr:1.00e-02, fs:0.79012 (r=0.736,p=0.853),  time:42.483, tt:1019.599\n",
      "Ep:24, loss:0.00011, loss_test:0.07866, lr:1.00e-02, fs:0.80000 (r=0.759,p=0.846),  time:42.583, tt:1064.587\n",
      "Ep:25, loss:0.00011, loss_test:0.07750, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:42.656, tt:1109.050\n",
      "Ep:26, loss:0.00010, loss_test:0.07905, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:42.700, tt:1152.913\n",
      "Ep:27, loss:0.00010, loss_test:0.07665, lr:1.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:42.689, tt:1195.284\n",
      "Ep:28, loss:0.00010, loss_test:0.07869, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:42.690, tt:1237.995\n",
      "Ep:29, loss:0.00009, loss_test:0.07760, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:42.741, tt:1282.227\n",
      "Ep:30, loss:0.00009, loss_test:0.07457, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:42.750, tt:1325.262\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08370, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:42.739, tt:1367.637\n",
      "Ep:32, loss:0.00008, loss_test:0.07258, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:42.803, tt:1412.513\n",
      "Ep:33, loss:0.00008, loss_test:0.08370, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:42.843, tt:1456.668\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.07426, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:42.883, tt:1500.901\n",
      "Ep:35, loss:0.00008, loss_test:0.08026, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:42.891, tt:1544.087\n",
      "Ep:36, loss:0.00007, loss_test:0.07646, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:42.910, tt:1587.658\n",
      "Ep:37, loss:0.00007, loss_test:0.07732, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:42.907, tt:1630.450\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.08157, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:42.911, tt:1673.536\n",
      "Ep:39, loss:0.00006, loss_test:0.07426, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:42.936, tt:1717.430\n",
      "Ep:40, loss:0.00006, loss_test:0.08125, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:42.948, tt:1760.849\n",
      "Ep:41, loss:0.00006, loss_test:0.07589, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:42.963, tt:1804.427\n",
      "Ep:42, loss:0.00006, loss_test:0.08060, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:42.974, tt:1847.863\n",
      "Ep:43, loss:0.00005, loss_test:0.07610, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:42.969, tt:1890.654\n",
      "Ep:44, loss:0.00005, loss_test:0.07879, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:42.981, tt:1934.133\n",
      "Ep:45, loss:0.00005, loss_test:0.08011, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:43.009, tt:1978.435\n",
      "Ep:46, loss:0.00005, loss_test:0.07721, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:43.039, tt:2022.846\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00005, loss_test:0.08309, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:43.072, tt:2067.473\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.07697, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:43.071, tt:2110.500\n",
      "Ep:49, loss:0.00004, loss_test:0.08585, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:43.042, tt:2152.089\n",
      "Ep:50, loss:0.00004, loss_test:0.07927, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:43.030, tt:2194.516\n",
      "Ep:51, loss:0.00004, loss_test:0.08285, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:43.021, tt:2237.085\n",
      "Ep:52, loss:0.00004, loss_test:0.08345, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:43.039, tt:2281.089\n",
      "Ep:53, loss:0.00004, loss_test:0.07888, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:43.041, tt:2324.215\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00004, loss_test:0.08404, lr:1.00e-02, fs:0.86792 (r=0.793,p=0.958),  time:43.069, tt:2368.769\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.08454, lr:1.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:43.062, tt:2411.495\n",
      "Ep:56, loss:0.00003, loss_test:0.08064, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:43.047, tt:2453.703\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.08462, lr:1.00e-02, fs:0.86792 (r=0.793,p=0.958),  time:43.030, tt:2495.753\n",
      "Ep:58, loss:0.00003, loss_test:0.08170, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:43.046, tt:2539.715\n",
      "Ep:59, loss:0.00003, loss_test:0.08638, lr:1.00e-02, fs:0.86792 (r=0.793,p=0.958),  time:42.999, tt:2579.950\n",
      "Ep:60, loss:0.00003, loss_test:0.08413, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:42.964, tt:2620.805\n",
      "Ep:61, loss:0.00003, loss_test:0.08695, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:42.973, tt:2664.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00003, loss_test:0.08639, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:42.978, tt:2707.635\n",
      "Ep:63, loss:0.00002, loss_test:0.08471, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:42.981, tt:2750.798\n",
      "Ep:64, loss:0.00002, loss_test:0.08414, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:42.979, tt:2793.642\n",
      "Ep:65, loss:0.00002, loss_test:0.08413, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:42.989, tt:2837.246\n",
      "Ep:66, loss:0.00002, loss_test:0.08763, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:43.004, tt:2881.265\n",
      "Ep:67, loss:0.00002, loss_test:0.08430, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:43.029, tt:2925.986\n",
      "Ep:68, loss:0.00002, loss_test:0.08533, lr:9.90e-03, fs:0.87342 (r=0.793,p=0.972),  time:43.009, tt:2967.644\n",
      "Ep:69, loss:0.00002, loss_test:0.08397, lr:9.80e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.016, tt:3011.103\n",
      "Ep:70, loss:0.00002, loss_test:0.08835, lr:9.70e-03, fs:0.87342 (r=0.793,p=0.972),  time:43.021, tt:3054.495\n",
      "Ep:71, loss:0.00002, loss_test:0.08160, lr:9.61e-03, fs:0.87342 (r=0.793,p=0.972),  time:42.996, tt:3095.734\n",
      "Ep:72, loss:0.00002, loss_test:0.09367, lr:9.51e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.002, tt:3139.173\n",
      "Ep:73, loss:0.00002, loss_test:0.08161, lr:9.41e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.025, tt:3183.821\n",
      "Ep:74, loss:0.00002, loss_test:0.09003, lr:9.32e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.023, tt:3226.743\n",
      "Ep:75, loss:0.00002, loss_test:0.08531, lr:9.23e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.023, tt:3269.726\n",
      "Ep:76, loss:0.00002, loss_test:0.08479, lr:9.14e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.046, tt:3314.573\n",
      "Ep:77, loss:0.00002, loss_test:0.08689, lr:9.04e-03, fs:0.85714 (r=0.759,p=0.985),  time:43.104, tt:3362.149\n",
      "Ep:78, loss:0.00002, loss_test:0.08612, lr:8.95e-03, fs:0.85897 (r=0.770,p=0.971),  time:43.156, tt:3409.294\n",
      "Ep:79, loss:0.00001, loss_test:0.08415, lr:8.86e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.169, tt:3453.484\n",
      "Ep:80, loss:0.00001, loss_test:0.08789, lr:8.78e-03, fs:0.85161 (r=0.759,p=0.971),  time:43.175, tt:3497.199\n",
      "Ep:81, loss:0.00001, loss_test:0.08620, lr:8.69e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.174, tt:3540.238\n",
      "Ep:82, loss:0.00001, loss_test:0.08547, lr:8.60e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.185, tt:3584.382\n",
      "Ep:83, loss:0.00001, loss_test:0.08628, lr:8.51e-03, fs:0.84416 (r=0.747,p=0.970),  time:43.230, tt:3631.358\n",
      "Ep:84, loss:0.00001, loss_test:0.08532, lr:8.43e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.250, tt:3676.226\n",
      "Ep:85, loss:0.00001, loss_test:0.08557, lr:8.35e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.277, tt:3721.796\n",
      "Ep:86, loss:0.00001, loss_test:0.08552, lr:8.26e-03, fs:0.84211 (r=0.736,p=0.985),  time:43.278, tt:3765.156\n",
      "Ep:87, loss:0.00001, loss_test:0.08641, lr:8.18e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.291, tt:3809.581\n",
      "Ep:88, loss:0.00001, loss_test:0.08630, lr:8.10e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.297, tt:3853.415\n",
      "Ep:89, loss:0.00001, loss_test:0.08424, lr:8.02e-03, fs:0.83660 (r=0.736,p=0.970),  time:43.320, tt:3898.818\n",
      "Ep:90, loss:0.00001, loss_test:0.08934, lr:7.94e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.342, tt:3944.165\n",
      "Ep:91, loss:0.00001, loss_test:0.08943, lr:7.86e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.357, tt:3988.848\n",
      "Ep:92, loss:0.00001, loss_test:0.08623, lr:7.78e-03, fs:0.84211 (r=0.736,p=0.985),  time:43.323, tt:4029.075\n",
      "Ep:93, loss:0.00001, loss_test:0.08852, lr:7.70e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.335, tt:4073.450\n",
      "Ep:94, loss:0.00001, loss_test:0.08492, lr:7.62e-03, fs:0.84211 (r=0.736,p=0.985),  time:43.336, tt:4116.908\n",
      "Ep:95, loss:0.00001, loss_test:0.08922, lr:7.55e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.332, tt:4159.896\n",
      "Ep:96, loss:0.00001, loss_test:0.08631, lr:7.47e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.330, tt:4203.021\n",
      "Ep:97, loss:0.00001, loss_test:0.08642, lr:7.40e-03, fs:0.84211 (r=0.736,p=0.985),  time:43.351, tt:4248.433\n",
      "Ep:98, loss:0.00001, loss_test:0.08635, lr:7.32e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.336, tt:4290.297\n",
      "Ep:99, loss:0.00001, loss_test:0.08719, lr:7.25e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.302, tt:4330.239\n",
      "Ep:100, loss:0.00001, loss_test:0.08739, lr:7.18e-03, fs:0.84211 (r=0.736,p=0.985),  time:43.276, tt:4370.875\n",
      "Ep:101, loss:0.00001, loss_test:0.08921, lr:7.11e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.247, tt:4411.175\n",
      "Ep:102, loss:0.00001, loss_test:0.08763, lr:7.03e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.200, tt:4449.599\n",
      "Ep:103, loss:0.00001, loss_test:0.08670, lr:6.96e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.194, tt:4492.217\n",
      "Ep:104, loss:0.00001, loss_test:0.09055, lr:6.89e-03, fs:0.84000 (r=0.724,p=1.000),  time:43.182, tt:4534.149\n",
      "Ep:105, loss:0.00001, loss_test:0.08669, lr:6.83e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.170, tt:4575.975\n",
      "Ep:106, loss:0.00001, loss_test:0.08833, lr:6.76e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.158, tt:4617.930\n",
      "Ep:107, loss:0.00001, loss_test:0.08833, lr:6.69e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.156, tt:4660.804\n",
      "Ep:108, loss:0.00001, loss_test:0.08568, lr:6.62e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.154, tt:4703.744\n",
      "Ep:109, loss:0.00001, loss_test:0.08978, lr:6.56e-03, fs:0.83221 (r=0.713,p=1.000),  time:43.146, tt:4746.056\n",
      "Ep:110, loss:0.00001, loss_test:0.08578, lr:6.49e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.134, tt:4787.851\n",
      "Ep:111, loss:0.00001, loss_test:0.08840, lr:6.43e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.114, tt:4828.742\n",
      "Ep:112, loss:0.00001, loss_test:0.08860, lr:6.36e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.108, tt:4871.204\n",
      "Ep:113, loss:0.00001, loss_test:0.08718, lr:6.30e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.092, tt:4912.441\n",
      "Ep:114, loss:0.00001, loss_test:0.08764, lr:6.24e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.080, tt:4954.212\n",
      "Ep:115, loss:0.00001, loss_test:0.08714, lr:6.17e-03, fs:0.84000 (r=0.724,p=1.000),  time:43.060, tt:4995.001\n",
      "Ep:116, loss:0.00001, loss_test:0.08926, lr:6.11e-03, fs:0.80000 (r=0.667,p=1.000),  time:43.063, tt:5038.338\n",
      "Ep:117, loss:0.00001, loss_test:0.08710, lr:6.05e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.097, tt:5085.450\n",
      "Ep:118, loss:0.00001, loss_test:0.08778, lr:5.99e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.082, tt:5126.725\n",
      "Ep:119, loss:0.00001, loss_test:0.08858, lr:5.93e-03, fs:0.81633 (r=0.690,p=1.000),  time:43.067, tt:5167.992\n",
      "Ep:120, loss:0.00001, loss_test:0.08761, lr:5.87e-03, fs:0.81633 (r=0.690,p=1.000),  time:43.057, tt:5209.926\n",
      "Ep:121, loss:0.00001, loss_test:0.08872, lr:5.81e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.048, tt:5251.821\n",
      "Ep:122, loss:0.00001, loss_test:0.08756, lr:5.75e-03, fs:0.84000 (r=0.724,p=1.000),  time:43.033, tt:5293.064\n",
      "Ep:123, loss:0.00000, loss_test:0.08771, lr:5.70e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.033, tt:5336.050\n",
      "Ep:124, loss:0.00000, loss_test:0.08839, lr:5.64e-03, fs:0.83221 (r=0.713,p=1.000),  time:43.018, tt:5377.265\n",
      "Ep:125, loss:0.00000, loss_test:0.08744, lr:5.58e-03, fs:0.84768 (r=0.736,p=1.000),  time:43.013, tt:5419.671\n",
      "Ep:126, loss:0.00000, loss_test:0.08887, lr:5.53e-03, fs:0.84000 (r=0.724,p=1.000),  time:43.005, tt:5461.627\n",
      "Ep:127, loss:0.00000, loss_test:0.08789, lr:5.47e-03, fs:0.83221 (r=0.713,p=1.000),  time:43.000, tt:5504.035\n",
      "Ep:128, loss:0.00000, loss_test:0.08921, lr:5.42e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.982, tt:5544.668\n",
      "Ep:129, loss:0.00000, loss_test:0.08759, lr:5.36e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.959, tt:5584.696\n",
      "Ep:130, loss:0.00000, loss_test:0.08857, lr:5.31e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.947, tt:5626.024\n",
      "Ep:131, loss:0.00000, loss_test:0.08792, lr:5.26e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.933, tt:5667.094\n",
      "Ep:132, loss:0.00000, loss_test:0.08815, lr:5.20e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.920, tt:5708.366\n",
      "Ep:133, loss:0.00000, loss_test:0.08808, lr:5.15e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.915, tt:5750.600\n",
      "Ep:134, loss:0.00000, loss_test:0.08766, lr:5.10e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.893, tt:5790.532\n",
      "Ep:135, loss:0.00000, loss_test:0.08805, lr:5.05e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.876, tt:5831.166\n",
      "Ep:136, loss:0.00000, loss_test:0.08814, lr:5.00e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.874, tt:5873.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.08769, lr:4.95e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.869, tt:5915.924\n",
      "Ep:138, loss:0.00000, loss_test:0.08889, lr:4.90e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.869, tt:5958.750\n",
      "Ep:139, loss:0.00000, loss_test:0.08834, lr:4.85e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.854, tt:5999.508\n",
      "Ep:140, loss:0.00000, loss_test:0.08829, lr:4.80e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.849, tt:6041.639\n",
      "Ep:141, loss:0.00000, loss_test:0.08818, lr:4.75e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.845, tt:6083.921\n",
      "Ep:142, loss:0.00000, loss_test:0.08776, lr:4.71e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.840, tt:6126.075\n",
      "Ep:143, loss:0.00000, loss_test:0.08879, lr:4.66e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.831, tt:6167.726\n",
      "Ep:144, loss:0.00000, loss_test:0.08885, lr:4.61e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.811, tt:6207.646\n",
      "Ep:145, loss:0.00000, loss_test:0.08859, lr:4.57e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.790, tt:6247.376\n",
      "Ep:146, loss:0.00000, loss_test:0.08881, lr:4.52e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.783, tt:6289.135\n",
      "Ep:147, loss:0.00000, loss_test:0.08727, lr:4.48e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.759, tt:6328.394\n",
      "Ep:148, loss:0.00000, loss_test:0.09015, lr:4.43e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.763, tt:6371.677\n",
      "Ep:149, loss:0.00000, loss_test:0.09143, lr:4.39e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.763, tt:6414.444\n",
      "Ep:150, loss:0.00000, loss_test:0.08897, lr:4.34e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.755, tt:6455.987\n",
      "Ep:151, loss:0.00000, loss_test:0.08864, lr:4.30e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.751, tt:6498.086\n",
      "Ep:152, loss:0.00000, loss_test:0.08916, lr:4.26e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.734, tt:6538.273\n",
      "Ep:153, loss:0.00000, loss_test:0.08904, lr:4.21e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.716, tt:6578.223\n",
      "Ep:154, loss:0.00000, loss_test:0.08825, lr:4.17e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.692, tt:6617.211\n",
      "Ep:155, loss:0.00000, loss_test:0.08885, lr:4.13e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.688, tt:6659.367\n",
      "Ep:156, loss:0.00000, loss_test:0.08875, lr:4.09e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.682, tt:6701.061\n",
      "Ep:157, loss:0.00000, loss_test:0.08940, lr:4.05e-03, fs:0.80822 (r=0.678,p=1.000),  time:42.692, tt:6745.262\n",
      "Ep:158, loss:0.00000, loss_test:0.08855, lr:4.01e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.685, tt:6786.899\n",
      "Ep:159, loss:0.00000, loss_test:0.08876, lr:3.97e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.675, tt:6827.922\n",
      "Ep:160, loss:0.00000, loss_test:0.08860, lr:3.93e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.663, tt:6868.737\n",
      "Ep:161, loss:0.00000, loss_test:0.08827, lr:3.89e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.659, tt:6910.767\n",
      "Ep:162, loss:0.00000, loss_test:0.08879, lr:3.85e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.648, tt:6951.634\n",
      "Ep:163, loss:0.00000, loss_test:0.08886, lr:3.81e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.643, tt:6993.496\n",
      "Ep:164, loss:0.00000, loss_test:0.08905, lr:3.77e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.640, tt:7035.654\n",
      "Ep:165, loss:0.00000, loss_test:0.08858, lr:3.73e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.648, tt:7079.517\n",
      "Ep:166, loss:0.00000, loss_test:0.08912, lr:3.70e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.649, tt:7122.372\n",
      "Ep:167, loss:0.00000, loss_test:0.08902, lr:3.66e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.658, tt:7166.510\n",
      "Ep:168, loss:0.00000, loss_test:0.08834, lr:3.62e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.649, tt:7207.670\n",
      "Ep:169, loss:0.00000, loss_test:0.08941, lr:3.59e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.647, tt:7250.060\n",
      "Ep:170, loss:0.00000, loss_test:0.08855, lr:3.55e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.657, tt:7294.270\n",
      "Ep:171, loss:0.00000, loss_test:0.08943, lr:3.52e-03, fs:0.80000 (r=0.667,p=1.000),  time:42.658, tt:7337.162\n",
      "Ep:172, loss:0.00000, loss_test:0.09068, lr:3.48e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.659, tt:7379.950\n",
      "Ep:173, loss:0.00000, loss_test:0.08965, lr:3.45e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.664, tt:7423.573\n",
      "Ep:174, loss:0.00000, loss_test:0.08850, lr:3.41e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.667, tt:7466.763\n",
      "Ep:175, loss:0.00000, loss_test:0.09010, lr:3.38e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.675, tt:7510.738\n",
      "Ep:176, loss:0.00000, loss_test:0.09028, lr:3.34e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.672, tt:7553.009\n",
      "Ep:177, loss:0.00000, loss_test:0.08871, lr:3.31e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.674, tt:7595.888\n",
      "Ep:178, loss:0.00000, loss_test:0.08901, lr:3.28e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.671, tt:7638.116\n",
      "Ep:179, loss:0.00000, loss_test:0.09011, lr:3.24e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.667, tt:7680.046\n",
      "Ep:180, loss:0.00000, loss_test:0.08950, lr:3.21e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.648, tt:7719.335\n",
      "Ep:181, loss:0.00000, loss_test:0.08873, lr:3.18e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.645, tt:7761.392\n",
      "Ep:182, loss:0.00000, loss_test:0.08862, lr:3.15e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.650, tt:7805.011\n",
      "Ep:183, loss:0.00000, loss_test:0.08944, lr:3.12e-03, fs:0.80000 (r=0.667,p=1.000),  time:42.650, tt:7847.649\n",
      "Ep:184, loss:0.00000, loss_test:0.08897, lr:3.09e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.647, tt:7889.732\n",
      "Ep:185, loss:0.00000, loss_test:0.08884, lr:3.05e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.655, tt:7933.859\n",
      "Ep:186, loss:0.00000, loss_test:0.08897, lr:3.02e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.663, tt:7977.913\n",
      "Ep:187, loss:0.00000, loss_test:0.08931, lr:2.99e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.662, tt:8020.496\n",
      "Ep:188, loss:0.00000, loss_test:0.08939, lr:2.96e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.662, tt:8063.074\n",
      "Ep:189, loss:0.00000, loss_test:0.08923, lr:2.93e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.667, tt:8106.789\n",
      "Ep:190, loss:0.00000, loss_test:0.08914, lr:2.90e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.663, tt:8148.613\n",
      "Ep:191, loss:0.00000, loss_test:0.08927, lr:2.88e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.666, tt:8191.816\n",
      "Ep:192, loss:0.00000, loss_test:0.08914, lr:2.85e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.665, tt:8234.351\n",
      "Ep:193, loss:0.00000, loss_test:0.08881, lr:2.82e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.668, tt:8277.629\n",
      "Ep:194, loss:0.00000, loss_test:0.08883, lr:2.79e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.674, tt:8321.389\n",
      "Ep:195, loss:0.00000, loss_test:0.08918, lr:2.76e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.675, tt:8364.369\n",
      "Ep:196, loss:0.00000, loss_test:0.08903, lr:2.73e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.676, tt:8407.210\n",
      "Ep:197, loss:0.00000, loss_test:0.08887, lr:2.71e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.679, tt:8450.502\n",
      "Ep:198, loss:0.00000, loss_test:0.08965, lr:2.68e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.679, tt:8493.142\n",
      "Ep:199, loss:0.00000, loss_test:0.08931, lr:2.65e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.675, tt:8534.996\n",
      "Ep:200, loss:0.00000, loss_test:0.08898, lr:2.63e-03, fs:0.81633 (r=0.690,p=1.000),  time:42.675, tt:8577.732\n",
      "Ep:201, loss:0.00000, loss_test:0.08969, lr:2.60e-03, fs:0.80000 (r=0.667,p=1.000),  time:42.678, tt:8620.927\n",
      "Ep:202, loss:0.00000, loss_test:0.08907, lr:2.57e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.666, tt:8661.257\n",
      "Ep:203, loss:0.00000, loss_test:0.08883, lr:2.55e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.665, tt:8703.577\n",
      "Ep:204, loss:0.00000, loss_test:0.08976, lr:2.52e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.668, tt:8746.899\n",
      "Ep:205, loss:0.00000, loss_test:0.08978, lr:2.50e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.663, tt:8788.608\n",
      "Ep:206, loss:0.00000, loss_test:0.08899, lr:2.47e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.661, tt:8830.761\n",
      "Ep:207, loss:0.00000, loss_test:0.08892, lr:2.45e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.654, tt:8872.056\n",
      "Ep:208, loss:0.00000, loss_test:0.08932, lr:2.42e-03, fs:0.83221 (r=0.713,p=1.000),  time:42.654, tt:8914.591\n",
      "Ep:209, loss:0.00000, loss_test:0.08883, lr:2.40e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.654, tt:8957.429\n",
      "Ep:210, loss:0.00000, loss_test:0.08890, lr:2.38e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.631, tt:8995.093\n",
      "Ep:211, loss:0.00000, loss_test:0.08990, lr:2.35e-03, fs:0.80822 (r=0.678,p=1.000),  time:42.609, tt:9033.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00000, loss_test:0.08975, lr:2.33e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.574, tt:9068.324\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02119, lr:6.00e-02, fs:0.64253 (r=0.816,p=0.530),  time:27.901, tt:27.901\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02214, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:29.869, tt:59.738\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02302, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:32.002, tt:96.007\n",
      "Ep:3, loss:0.00005, loss_test:0.02238, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:34.069, tt:136.275\n",
      "Ep:4, loss:0.00004, loss_test:0.02107, lr:6.00e-02, fs:0.64257 (r=0.920,p=0.494),  time:35.375, tt:176.873\n",
      "Ep:5, loss:0.00004, loss_test:0.02014, lr:6.00e-02, fs:0.66383 (r=0.897,p=0.527),  time:36.282, tt:217.693\n",
      "Ep:6, loss:0.00004, loss_test:0.02014, lr:6.00e-02, fs:0.66972 (r=0.839,p=0.557),  time:36.760, tt:257.321\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.67000 (r=0.770,p=0.593),  time:37.318, tt:298.544\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.66337 (r=0.770,p=0.583),  time:37.730, tt:339.567\n",
      "Ep:9, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.67606 (r=0.828,p=0.571),  time:38.115, tt:381.154\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01792, lr:6.00e-02, fs:0.69027 (r=0.897,p=0.561),  time:38.203, tt:420.228\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.69027 (r=0.897,p=0.561),  time:38.492, tt:461.899\n",
      "Ep:12, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.69725 (r=0.874,p=0.580),  time:38.710, tt:503.231\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.70000 (r=0.805,p=0.619),  time:38.902, tt:544.630\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.69474 (r=0.759,p=0.641),  time:39.086, tt:586.286\n",
      "Ep:15, loss:0.00003, loss_test:0.01677, lr:6.00e-02, fs:0.70157 (r=0.770,p=0.644),  time:39.198, tt:627.170\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.72449 (r=0.816,p=0.651),  time:39.329, tt:668.590\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.72000 (r=0.828,p=0.637),  time:39.478, tt:710.612\n",
      "Ep:18, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.73632 (r=0.851,p=0.649),  time:39.611, tt:752.611\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.73958 (r=0.816,p=0.676),  time:39.621, tt:792.422\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.76344 (r=0.816,p=0.717),  time:39.706, tt:833.836\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01637, lr:6.00e-02, fs:0.75936 (r=0.816,p=0.710),  time:39.814, tt:875.904\n",
      "Ep:22, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.77487 (r=0.851,p=0.712),  time:39.876, tt:917.147\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.78947 (r=0.862,p=0.728),  time:39.920, tt:958.078\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.80214 (r=0.862,p=0.750),  time:40.088, tt:1002.197\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.79570 (r=0.851,p=0.747),  time:40.101, tt:1042.617\n",
      "Ep:26, loss:0.00002, loss_test:0.01602, lr:6.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:40.076, tt:1082.045\n",
      "Ep:27, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.80645 (r=0.862,p=0.758),  time:40.153, tt:1124.272\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01595, lr:6.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:40.162, tt:1164.707\n",
      "Ep:29, loss:0.00002, loss_test:0.01604, lr:6.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:40.233, tt:1206.993\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01602, lr:6.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:40.255, tt:1247.904\n",
      "Ep:31, loss:0.00002, loss_test:0.01597, lr:6.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.260, tt:1288.306\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01595, lr:6.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.243, tt:1328.033\n",
      "Ep:33, loss:0.00002, loss_test:0.01595, lr:6.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:40.316, tt:1370.753\n",
      "Ep:34, loss:0.00002, loss_test:0.01601, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:40.342, tt:1411.953\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.365, tt:1453.136\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:40.358, tt:1493.243\n",
      "Ep:37, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.343, tt:1533.033\n",
      "Ep:38, loss:0.00002, loss_test:0.01611, lr:6.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.281, tt:1570.957\n",
      "Ep:39, loss:0.00002, loss_test:0.01618, lr:6.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:40.260, tt:1610.389\n",
      "Ep:40, loss:0.00002, loss_test:0.01635, lr:6.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.305, tt:1652.497\n",
      "Ep:41, loss:0.00002, loss_test:0.01639, lr:6.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.338, tt:1694.208\n",
      "Ep:42, loss:0.00002, loss_test:0.01633, lr:6.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.327, tt:1734.068\n",
      "Ep:43, loss:0.00001, loss_test:0.01639, lr:6.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.306, tt:1773.455\n",
      "Ep:44, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:40.297, tt:1813.354\n",
      "Ep:45, loss:0.00001, loss_test:0.01646, lr:6.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.298, tt:1853.709\n",
      "Ep:46, loss:0.00001, loss_test:0.01660, lr:6.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:40.334, tt:1895.718\n",
      "Ep:47, loss:0.00001, loss_test:0.01661, lr:5.94e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.376, tt:1938.037\n",
      "Ep:48, loss:0.00001, loss_test:0.01669, lr:5.88e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.410, tt:1980.100\n",
      "Ep:49, loss:0.00001, loss_test:0.01674, lr:5.82e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.407, tt:2020.342\n",
      "Ep:50, loss:0.00001, loss_test:0.01688, lr:5.76e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.463, tt:2063.613\n",
      "Ep:51, loss:0.00001, loss_test:0.01697, lr:5.71e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.440, tt:2102.891\n",
      "Ep:52, loss:0.00001, loss_test:0.01700, lr:5.65e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.419, tt:2142.209\n",
      "Ep:53, loss:0.00001, loss_test:0.01710, lr:5.59e-02, fs:0.83436 (r=0.782,p=0.895),  time:40.424, tt:2182.894\n",
      "Ep:54, loss:0.00001, loss_test:0.01718, lr:5.54e-02, fs:0.84146 (r=0.793,p=0.896),  time:40.412, tt:2222.648\n",
      "Ep:55, loss:0.00001, loss_test:0.01728, lr:5.48e-02, fs:0.84146 (r=0.793,p=0.896),  time:40.413, tt:2263.146\n",
      "Ep:56, loss:0.00001, loss_test:0.01746, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.431, tt:2304.573\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01756, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.416, tt:2344.100\n",
      "Ep:58, loss:0.00001, loss_test:0.01761, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.415, tt:2384.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01771, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.422, tt:2425.334\n",
      "Ep:60, loss:0.00001, loss_test:0.01780, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.408, tt:2464.885\n",
      "Ep:61, loss:0.00001, loss_test:0.01793, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.434, tt:2506.935\n",
      "Ep:62, loss:0.00001, loss_test:0.01799, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.440, tt:2547.738\n",
      "Ep:63, loss:0.00001, loss_test:0.01808, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.461, tt:2589.514\n",
      "Ep:64, loss:0.00001, loss_test:0.01812, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.462, tt:2630.050\n",
      "Ep:65, loss:0.00001, loss_test:0.01831, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.485, tt:2671.977\n",
      "Ep:66, loss:0.00001, loss_test:0.01849, lr:5.43e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.495, tt:2713.153\n",
      "Ep:67, loss:0.00001, loss_test:0.01857, lr:5.43e-02, fs:0.84277 (r=0.770,p=0.931),  time:40.499, tt:2753.941\n",
      "Ep:68, loss:0.00001, loss_test:0.01881, lr:5.37e-02, fs:0.85714 (r=0.793,p=0.932),  time:40.515, tt:2795.531\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01874, lr:5.37e-02, fs:0.84277 (r=0.770,p=0.931),  time:40.523, tt:2836.601\n",
      "Ep:70, loss:0.00001, loss_test:0.01881, lr:5.37e-02, fs:0.83544 (r=0.759,p=0.930),  time:40.528, tt:2877.483\n",
      "Ep:71, loss:0.00001, loss_test:0.01890, lr:5.37e-02, fs:0.83544 (r=0.759,p=0.930),  time:40.540, tt:2918.854\n",
      "Ep:72, loss:0.00001, loss_test:0.01905, lr:5.37e-02, fs:0.80519 (r=0.713,p=0.925),  time:40.550, tt:2960.146\n",
      "Ep:73, loss:0.00001, loss_test:0.01908, lr:5.37e-02, fs:0.82051 (r=0.736,p=0.928),  time:40.561, tt:3001.498\n",
      "Ep:74, loss:0.00001, loss_test:0.01925, lr:5.37e-02, fs:0.79739 (r=0.701,p=0.924),  time:40.566, tt:3042.453\n",
      "Ep:75, loss:0.00001, loss_test:0.01943, lr:5.37e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.579, tt:3084.032\n",
      "Ep:76, loss:0.00001, loss_test:0.01947, lr:5.37e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.592, tt:3125.555\n",
      "Ep:77, loss:0.00001, loss_test:0.01948, lr:5.37e-02, fs:0.78146 (r=0.678,p=0.922),  time:40.592, tt:3166.159\n",
      "Ep:78, loss:0.00001, loss_test:0.01972, lr:5.37e-02, fs:0.78378 (r=0.667,p=0.951),  time:40.579, tt:3205.773\n",
      "Ep:79, loss:0.00001, loss_test:0.01964, lr:5.37e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.578, tt:3246.228\n",
      "Ep:80, loss:0.00001, loss_test:0.01992, lr:5.32e-02, fs:0.76712 (r=0.644,p=0.949),  time:40.559, tt:3285.288\n",
      "Ep:81, loss:0.00001, loss_test:0.02006, lr:5.27e-02, fs:0.75862 (r=0.632,p=0.948),  time:40.568, tt:3326.565\n",
      "Ep:82, loss:0.00001, loss_test:0.02016, lr:5.21e-02, fs:0.74648 (r=0.609,p=0.964),  time:40.567, tt:3367.033\n",
      "Ep:83, loss:0.00001, loss_test:0.02038, lr:5.16e-02, fs:0.74648 (r=0.609,p=0.964),  time:40.564, tt:3407.336\n",
      "Ep:84, loss:0.00001, loss_test:0.02038, lr:5.11e-02, fs:0.73759 (r=0.598,p=0.963),  time:40.560, tt:3447.614\n",
      "Ep:85, loss:0.00001, loss_test:0.02055, lr:5.06e-02, fs:0.73759 (r=0.598,p=0.963),  time:40.553, tt:3487.598\n",
      "Ep:86, loss:0.00001, loss_test:0.02070, lr:5.01e-02, fs:0.73759 (r=0.598,p=0.963),  time:40.544, tt:3527.303\n",
      "Ep:87, loss:0.00001, loss_test:0.02076, lr:4.96e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.527, tt:3566.359\n",
      "Ep:88, loss:0.00001, loss_test:0.02094, lr:4.91e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.547, tt:3608.662\n",
      "Ep:89, loss:0.00001, loss_test:0.02097, lr:4.86e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.546, tt:3649.146\n",
      "Ep:90, loss:0.00001, loss_test:0.02116, lr:4.81e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.564, tt:3691.349\n",
      "Ep:91, loss:0.00001, loss_test:0.02124, lr:4.76e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.566, tt:3732.076\n",
      "Ep:92, loss:0.00001, loss_test:0.02127, lr:4.71e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.544, tt:3770.612\n",
      "Ep:93, loss:0.00001, loss_test:0.02154, lr:4.67e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.528, tt:3809.620\n",
      "Ep:94, loss:0.00001, loss_test:0.02162, lr:4.62e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.517, tt:3849.103\n",
      "Ep:95, loss:0.00001, loss_test:0.02182, lr:4.57e-02, fs:0.74286 (r=0.598,p=0.981),  time:40.526, tt:3890.477\n",
      "Ep:96, loss:0.00001, loss_test:0.02186, lr:4.53e-02, fs:0.73381 (r=0.586,p=0.981),  time:40.535, tt:3931.898\n",
      "Ep:97, loss:0.00001, loss_test:0.02203, lr:4.48e-02, fs:0.73381 (r=0.586,p=0.981),  time:40.543, tt:3973.194\n",
      "Ep:98, loss:0.00001, loss_test:0.02214, lr:4.44e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.527, tt:4012.217\n",
      "Ep:99, loss:0.00001, loss_test:0.02231, lr:4.39e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.523, tt:4052.328\n",
      "Ep:100, loss:0.00001, loss_test:0.02240, lr:4.35e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.537, tt:4094.192\n",
      "Ep:101, loss:0.00001, loss_test:0.02247, lr:4.31e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.545, tt:4135.611\n",
      "Ep:102, loss:0.00001, loss_test:0.02262, lr:4.26e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.522, tt:4173.778\n",
      "Ep:103, loss:0.00001, loss_test:0.02276, lr:4.22e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.530, tt:4215.165\n",
      "Ep:104, loss:0.00001, loss_test:0.02280, lr:4.18e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.534, tt:4256.052\n",
      "Ep:105, loss:0.00001, loss_test:0.02290, lr:4.14e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.526, tt:4295.747\n",
      "Ep:106, loss:0.00001, loss_test:0.02305, lr:4.10e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.531, tt:4336.867\n",
      "Ep:107, loss:0.00001, loss_test:0.02318, lr:4.05e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.539, tt:4378.263\n",
      "Ep:108, loss:0.00001, loss_test:0.02324, lr:4.01e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.526, tt:4417.356\n",
      "Ep:109, loss:0.00000, loss_test:0.02346, lr:3.97e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.523, tt:4457.551\n",
      "Ep:110, loss:0.00000, loss_test:0.02355, lr:3.93e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.528, tt:4498.582\n",
      "Ep:111, loss:0.00000, loss_test:0.02360, lr:3.89e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.531, tt:4539.509\n",
      "Ep:112, loss:0.00000, loss_test:0.02377, lr:3.86e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.534, tt:4580.374\n",
      "Ep:113, loss:0.00000, loss_test:0.02376, lr:3.82e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.581, tt:4626.257\n",
      "Ep:114, loss:0.00000, loss_test:0.02392, lr:3.78e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.572, tt:4665.784\n",
      "Ep:115, loss:0.00000, loss_test:0.02394, lr:3.74e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.572, tt:4706.354\n",
      "Ep:116, loss:0.00000, loss_test:0.02407, lr:3.70e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.579, tt:4747.696\n",
      "Ep:117, loss:0.00000, loss_test:0.02417, lr:3.67e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.586, tt:4789.168\n",
      "Ep:118, loss:0.00000, loss_test:0.02429, lr:3.63e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.590, tt:4830.208\n",
      "Ep:119, loss:0.00000, loss_test:0.02439, lr:3.59e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.599, tt:4871.914\n",
      "Ep:120, loss:0.00000, loss_test:0.02448, lr:3.56e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.608, tt:4913.514\n",
      "Ep:121, loss:0.00000, loss_test:0.02450, lr:3.52e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.611, tt:4954.536\n",
      "Ep:122, loss:0.00000, loss_test:0.02467, lr:3.49e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.621, tt:4996.432\n",
      "Ep:123, loss:0.00000, loss_test:0.02477, lr:3.45e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.630, tt:5038.091\n",
      "Ep:124, loss:0.00000, loss_test:0.02483, lr:3.42e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.640, tt:5079.963\n",
      "Ep:125, loss:0.00000, loss_test:0.02497, lr:3.38e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.647, tt:5121.483\n",
      "Ep:126, loss:0.00000, loss_test:0.02491, lr:3.35e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.662, tt:5164.122\n",
      "Ep:127, loss:0.00000, loss_test:0.02507, lr:3.32e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.665, tt:5205.161\n",
      "Ep:128, loss:0.00000, loss_test:0.02517, lr:3.28e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.662, tt:5245.360\n",
      "Ep:129, loss:0.00000, loss_test:0.02517, lr:3.25e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.660, tt:5285.859\n",
      "Ep:130, loss:0.00000, loss_test:0.02532, lr:3.22e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.685, tt:5329.750\n",
      "Ep:131, loss:0.00000, loss_test:0.02536, lr:3.19e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.692, tt:5371.396\n",
      "Ep:132, loss:0.00000, loss_test:0.02537, lr:3.15e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.706, tt:5413.955\n",
      "Ep:133, loss:0.00000, loss_test:0.02557, lr:3.12e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.715, tt:5455.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.02563, lr:3.09e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.710, tt:5495.811\n",
      "Ep:135, loss:0.00000, loss_test:0.02567, lr:3.06e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.723, tt:5538.385\n",
      "Ep:136, loss:0.00000, loss_test:0.02579, lr:3.03e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.726, tt:5579.506\n",
      "Ep:137, loss:0.00000, loss_test:0.02582, lr:3.00e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.725, tt:5620.071\n",
      "Ep:138, loss:0.00000, loss_test:0.02591, lr:2.97e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.728, tt:5661.126\n",
      "Ep:139, loss:0.00000, loss_test:0.02607, lr:2.94e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.724, tt:5701.306\n",
      "Ep:140, loss:0.00000, loss_test:0.02604, lr:2.91e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.719, tt:5741.380\n",
      "Ep:141, loss:0.00000, loss_test:0.02610, lr:2.88e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.704, tt:5780.011\n",
      "Ep:142, loss:0.00000, loss_test:0.02623, lr:2.85e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.712, tt:5821.874\n",
      "Ep:143, loss:0.00000, loss_test:0.02625, lr:2.82e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.716, tt:5863.141\n",
      "Ep:144, loss:0.00000, loss_test:0.02640, lr:2.80e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.720, tt:5904.412\n",
      "Ep:145, loss:0.00000, loss_test:0.02635, lr:2.77e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.727, tt:5946.143\n",
      "Ep:146, loss:0.00000, loss_test:0.02645, lr:2.74e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.739, tt:5988.606\n",
      "Ep:147, loss:0.00000, loss_test:0.02661, lr:2.71e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.739, tt:6029.307\n",
      "Ep:148, loss:0.00000, loss_test:0.02656, lr:2.69e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.733, tt:6069.291\n",
      "Ep:149, loss:0.00000, loss_test:0.02658, lr:2.66e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.730, tt:6109.450\n",
      "Ep:150, loss:0.00000, loss_test:0.02667, lr:2.63e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.734, tt:6150.777\n",
      "Ep:151, loss:0.00000, loss_test:0.02675, lr:2.61e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.742, tt:6192.752\n",
      "Ep:152, loss:0.00000, loss_test:0.02679, lr:2.58e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.748, tt:6234.471\n",
      "Ep:153, loss:0.00000, loss_test:0.02682, lr:2.55e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.744, tt:6274.638\n",
      "Ep:154, loss:0.00000, loss_test:0.02693, lr:2.53e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.750, tt:6316.300\n",
      "Ep:155, loss:0.00000, loss_test:0.02701, lr:2.50e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.748, tt:6356.654\n",
      "Ep:156, loss:0.00000, loss_test:0.02705, lr:2.48e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.748, tt:6397.369\n",
      "Ep:157, loss:0.00000, loss_test:0.02705, lr:2.45e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.749, tt:6438.420\n",
      "Ep:158, loss:0.00000, loss_test:0.02716, lr:2.43e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.753, tt:6479.751\n",
      "Ep:159, loss:0.00000, loss_test:0.02727, lr:2.40e-02, fs:0.72464 (r=0.575,p=0.980),  time:40.736, tt:6517.730\n",
      "Ep:160, loss:0.00000, loss_test:0.02720, lr:2.38e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.719, tt:6555.829\n",
      "Ep:161, loss:0.00000, loss_test:0.02722, lr:2.36e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.725, tt:6597.468\n",
      "Ep:162, loss:0.00000, loss_test:0.02738, lr:2.33e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.721, tt:6637.533\n",
      "Ep:163, loss:0.00000, loss_test:0.02739, lr:2.31e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.711, tt:6676.672\n",
      "Ep:164, loss:0.00000, loss_test:0.02738, lr:2.29e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.712, tt:6717.458\n",
      "Ep:165, loss:0.00000, loss_test:0.02747, lr:2.26e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.704, tt:6756.937\n",
      "Ep:166, loss:0.00000, loss_test:0.02751, lr:2.24e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.699, tt:6796.740\n",
      "Ep:167, loss:0.00000, loss_test:0.02755, lr:2.22e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.690, tt:6835.958\n",
      "Ep:168, loss:0.00000, loss_test:0.02756, lr:2.20e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.674, tt:6873.869\n",
      "Ep:169, loss:0.00000, loss_test:0.02764, lr:2.17e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.660, tt:6912.286\n",
      "Ep:170, loss:0.00000, loss_test:0.02767, lr:2.15e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.635, tt:6948.554\n",
      "Ep:171, loss:0.00000, loss_test:0.02776, lr:2.13e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.640, tt:6990.002\n",
      "Ep:172, loss:0.00000, loss_test:0.02778, lr:2.11e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.643, tt:7031.264\n",
      "Ep:173, loss:0.00000, loss_test:0.02784, lr:2.09e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.638, tt:7071.000\n",
      "Ep:174, loss:0.00000, loss_test:0.02787, lr:2.07e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.630, tt:7110.247\n",
      "Ep:175, loss:0.00000, loss_test:0.02791, lr:2.05e-02, fs:0.72993 (r=0.575,p=1.000),  time:40.629, tt:7150.622\n",
      "Ep:176, loss:0.00000, loss_test:0.02794, lr:2.03e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.627, tt:7190.901\n",
      "Ep:177, loss:0.00000, loss_test:0.02805, lr:2.01e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.627, tt:7231.523\n",
      "Ep:178, loss:0.00000, loss_test:0.02806, lr:1.99e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.620, tt:7270.914\n",
      "Ep:179, loss:0.00000, loss_test:0.02807, lr:1.97e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.619, tt:7311.472\n",
      "Ep:180, loss:0.00000, loss_test:0.02813, lr:1.95e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.646, tt:7356.896\n",
      "Ep:181, loss:0.00000, loss_test:0.02818, lr:1.93e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.647, tt:7397.684\n",
      "Ep:182, loss:0.00000, loss_test:0.02818, lr:1.91e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.647, tt:7438.383\n",
      "Ep:183, loss:0.00000, loss_test:0.02819, lr:1.89e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.641, tt:7477.943\n",
      "Ep:184, loss:0.00000, loss_test:0.02831, lr:1.87e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.636, tt:7517.641\n",
      "Ep:185, loss:0.00000, loss_test:0.02832, lr:1.85e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.639, tt:7558.796\n",
      "Ep:186, loss:0.00000, loss_test:0.02831, lr:1.83e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.638, tt:7599.300\n",
      "Ep:187, loss:0.00000, loss_test:0.02840, lr:1.81e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.635, tt:7639.455\n",
      "Ep:188, loss:0.00000, loss_test:0.02843, lr:1.80e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.629, tt:7678.886\n",
      "Ep:189, loss:0.00000, loss_test:0.02847, lr:1.78e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.621, tt:7718.037\n",
      "Ep:190, loss:0.00000, loss_test:0.02850, lr:1.76e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.629, tt:7760.195\n",
      "Ep:191, loss:0.00000, loss_test:0.02856, lr:1.74e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.629, tt:7800.783\n",
      "Ep:192, loss:0.00000, loss_test:0.02856, lr:1.73e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.625, tt:7840.718\n",
      "Ep:193, loss:0.00000, loss_test:0.02858, lr:1.71e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.626, tt:7881.382\n",
      "Ep:194, loss:0.00000, loss_test:0.02862, lr:1.69e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.629, tt:7922.595\n",
      "Ep:195, loss:0.00000, loss_test:0.02865, lr:1.67e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.619, tt:7961.327\n",
      "Ep:196, loss:0.00000, loss_test:0.02869, lr:1.66e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.620, tt:8002.186\n",
      "Ep:197, loss:0.00000, loss_test:0.02871, lr:1.64e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.629, tt:8044.458\n",
      "Ep:198, loss:0.00000, loss_test:0.02875, lr:1.62e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.625, tt:8084.334\n",
      "Ep:199, loss:0.00000, loss_test:0.02878, lr:1.61e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.634, tt:8126.804\n",
      "Ep:200, loss:0.00000, loss_test:0.02879, lr:1.59e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.635, tt:8167.715\n",
      "Ep:201, loss:0.00000, loss_test:0.02882, lr:1.58e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.636, tt:8208.510\n",
      "Ep:202, loss:0.00000, loss_test:0.02887, lr:1.56e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.632, tt:8248.232\n",
      "Ep:203, loss:0.00000, loss_test:0.02887, lr:1.54e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.636, tt:8289.646\n",
      "Ep:204, loss:0.00000, loss_test:0.02893, lr:1.53e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.633, tt:8329.673\n",
      "Ep:205, loss:0.00000, loss_test:0.02893, lr:1.51e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.635, tt:8370.748\n",
      "Ep:206, loss:0.00000, loss_test:0.02896, lr:1.50e-02, fs:0.71111 (r=0.552,p=1.000),  time:40.632, tt:8410.890\n",
      "Ep:207, loss:0.00000, loss_test:0.02903, lr:1.48e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.637, tt:8452.396\n",
      "Ep:208, loss:0.00000, loss_test:0.02906, lr:1.47e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.635, tt:8492.702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.02906, lr:1.45e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.651, tt:8536.798\n",
      "Ep:210, loss:0.00000, loss_test:0.02908, lr:1.44e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.651, tt:8577.434\n",
      "Ep:211, loss:0.00000, loss_test:0.02913, lr:1.43e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.652, tt:8618.189\n",
      "Ep:212, loss:0.00000, loss_test:0.02915, lr:1.41e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.627, tt:8653.619\n",
      "Ep:213, loss:0.00000, loss_test:0.02918, lr:1.40e-02, fs:0.69173 (r=0.529,p=1.000),  time:40.609, tt:8690.333\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14133, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.591, tt:34.591\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13920, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:35.870, tt:71.741\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13527, lr:1.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:36.423, tt:109.269\n",
      "Ep:3, loss:0.00026, loss_test:0.12879, lr:1.00e-02, fs:0.65532 (r=0.885,p=0.520),  time:37.095, tt:148.380\n",
      "Ep:4, loss:0.00024, loss_test:0.12169, lr:1.00e-02, fs:0.65094 (r=0.793,p=0.552),  time:37.965, tt:189.827\n",
      "Ep:5, loss:0.00023, loss_test:0.11922, lr:1.00e-02, fs:0.63277 (r=0.644,p=0.622),  time:38.688, tt:232.130\n",
      "Ep:6, loss:0.00022, loss_test:0.11758, lr:1.00e-02, fs:0.63584 (r=0.632,p=0.640),  time:39.111, tt:273.776\n",
      "Ep:7, loss:0.00021, loss_test:0.11592, lr:1.00e-02, fs:0.64045 (r=0.655,p=0.626),  time:39.583, tt:316.668\n",
      "Ep:8, loss:0.00020, loss_test:0.11387, lr:1.00e-02, fs:0.62791 (r=0.621,p=0.635),  time:39.825, tt:358.427\n",
      "Ep:9, loss:0.00020, loss_test:0.11185, lr:1.00e-02, fs:0.63473 (r=0.609,p=0.662),  time:39.968, tt:399.676\n",
      "Ep:10, loss:0.00019, loss_test:0.10944, lr:1.00e-02, fs:0.65517 (r=0.655,p=0.655),  time:40.079, tt:440.867\n",
      "Ep:11, loss:0.00018, loss_test:0.10764, lr:1.00e-02, fs:0.68182 (r=0.690,p=0.674),  time:40.201, tt:482.413\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.10622, lr:1.00e-02, fs:0.67857 (r=0.655,p=0.704),  time:39.992, tt:519.901\n",
      "Ep:13, loss:0.00017, loss_test:0.10472, lr:1.00e-02, fs:0.71006 (r=0.690,p=0.732),  time:40.127, tt:561.772\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.10371, lr:1.00e-02, fs:0.71429 (r=0.690,p=0.741),  time:40.166, tt:602.496\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.10126, lr:1.00e-02, fs:0.72393 (r=0.678,p=0.776),  time:40.514, tt:648.225\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09915, lr:1.00e-02, fs:0.77528 (r=0.793,p=0.758),  time:40.560, tt:689.524\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09657, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:40.657, tt:731.830\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09643, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.740, tt:774.065\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.09454, lr:1.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:40.789, tt:815.773\n",
      "Ep:20, loss:0.00013, loss_test:0.09245, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.826, tt:857.336\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.09107, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.833, tt:898.331\n",
      "Ep:22, loss:0.00012, loss_test:0.08914, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:40.859, tt:939.750\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08852, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:40.903, tt:981.664\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08896, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:40.939, tt:1023.467\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.08729, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:40.932, tt:1064.239\n",
      "Ep:26, loss:0.00010, loss_test:0.08618, lr:1.00e-02, fs:0.87209 (r=0.862,p=0.882),  time:40.886, tt:1103.932\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.08696, lr:1.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:40.934, tt:1146.147\n",
      "Ep:28, loss:0.00009, loss_test:0.08635, lr:1.00e-02, fs:0.86207 (r=0.862,p=0.862),  time:40.928, tt:1186.906\n",
      "Ep:29, loss:0.00009, loss_test:0.08536, lr:1.00e-02, fs:0.87574 (r=0.851,p=0.902),  time:40.871, tt:1226.125\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08433, lr:1.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:40.808, tt:1265.055\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.08611, lr:1.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:40.843, tt:1306.975\n",
      "Ep:32, loss:0.00008, loss_test:0.08572, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.810, tt:1346.718\n",
      "Ep:33, loss:0.00008, loss_test:0.08535, lr:1.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:40.849, tt:1388.865\n",
      "Ep:34, loss:0.00007, loss_test:0.08247, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.870, tt:1430.465\n",
      "Ep:35, loss:0.00007, loss_test:0.08686, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:40.879, tt:1471.640\n",
      "Ep:36, loss:0.00007, loss_test:0.08211, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:40.816, tt:1510.205\n",
      "Ep:37, loss:0.00007, loss_test:0.08747, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:40.775, tt:1549.442\n",
      "Ep:38, loss:0.00006, loss_test:0.07979, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:40.732, tt:1588.539\n",
      "Ep:39, loss:0.00006, loss_test:0.08905, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:40.748, tt:1629.935\n",
      "Ep:40, loss:0.00006, loss_test:0.08514, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:40.711, tt:1669.163\n",
      "Ep:41, loss:0.00006, loss_test:0.08602, lr:1.00e-02, fs:0.79487 (r=0.713,p=0.899),  time:40.699, tt:1709.374\n",
      "Ep:42, loss:0.00006, loss_test:0.07931, lr:9.90e-03, fs:0.80503 (r=0.736,p=0.889),  time:40.680, tt:1749.256\n",
      "Ep:43, loss:0.00005, loss_test:0.08821, lr:9.80e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.683, tt:1790.047\n",
      "Ep:44, loss:0.00005, loss_test:0.08277, lr:9.70e-03, fs:0.78981 (r=0.713,p=0.886),  time:40.698, tt:1831.422\n",
      "Ep:45, loss:0.00005, loss_test:0.08803, lr:9.61e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.740, tt:1874.053\n",
      "Ep:46, loss:0.00005, loss_test:0.08371, lr:9.51e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.760, tt:1915.711\n",
      "Ep:47, loss:0.00004, loss_test:0.08377, lr:9.41e-03, fs:0.80000 (r=0.713,p=0.912),  time:40.766, tt:1956.784\n",
      "Ep:48, loss:0.00004, loss_test:0.08664, lr:9.32e-03, fs:0.85714 (r=0.793,p=0.932),  time:40.783, tt:1998.368\n",
      "Ep:49, loss:0.00004, loss_test:0.08847, lr:9.23e-03, fs:0.80000 (r=0.713,p=0.912),  time:40.800, tt:2040.017\n",
      "Ep:50, loss:0.00004, loss_test:0.07587, lr:9.14e-03, fs:0.77987 (r=0.713,p=0.861),  time:40.796, tt:2080.618\n",
      "Ep:51, loss:0.00004, loss_test:0.08911, lr:9.04e-03, fs:0.84810 (r=0.770,p=0.944),  time:40.795, tt:2121.329\n",
      "Ep:52, loss:0.00004, loss_test:0.07739, lr:8.95e-03, fs:0.79487 (r=0.713,p=0.899),  time:40.751, tt:2159.793\n",
      "Ep:53, loss:0.00004, loss_test:0.08782, lr:8.86e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.766, tt:2201.346\n",
      "Ep:54, loss:0.00004, loss_test:0.08313, lr:8.78e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.762, tt:2241.930\n",
      "Ep:55, loss:0.00003, loss_test:0.08251, lr:8.69e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.753, tt:2282.187\n",
      "Ep:56, loss:0.00003, loss_test:0.08446, lr:8.60e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.737, tt:2321.996\n",
      "Ep:57, loss:0.00003, loss_test:0.08948, lr:8.51e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.737, tt:2362.764\n",
      "Ep:58, loss:0.00003, loss_test:0.07844, lr:8.43e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.746, tt:2404.028\n",
      "Ep:59, loss:0.00003, loss_test:0.08646, lr:8.35e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.744, tt:2444.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.08396, lr:8.26e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.751, tt:2485.781\n",
      "Ep:61, loss:0.00003, loss_test:0.08432, lr:8.18e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.748, tt:2526.368\n",
      "Ep:62, loss:0.00002, loss_test:0.08282, lr:8.10e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.739, tt:2566.581\n",
      "Ep:63, loss:0.00002, loss_test:0.08499, lr:8.02e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.704, tt:2605.075\n",
      "Ep:64, loss:0.00002, loss_test:0.08717, lr:7.94e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.696, tt:2645.270\n",
      "Ep:65, loss:0.00002, loss_test:0.08987, lr:7.86e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.705, tt:2686.505\n",
      "Ep:66, loss:0.00002, loss_test:0.08420, lr:7.78e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.711, tt:2727.638\n",
      "Ep:67, loss:0.00002, loss_test:0.09022, lr:7.70e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.701, tt:2767.677\n",
      "Ep:68, loss:0.00002, loss_test:0.08598, lr:7.62e-03, fs:0.80519 (r=0.713,p=0.925),  time:40.716, tt:2809.420\n",
      "Ep:69, loss:0.00002, loss_test:0.09628, lr:7.55e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.711, tt:2849.746\n",
      "Ep:70, loss:0.00002, loss_test:0.08608, lr:7.47e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.721, tt:2891.165\n",
      "Ep:71, loss:0.00002, loss_test:0.09204, lr:7.40e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.718, tt:2931.697\n",
      "Ep:72, loss:0.00002, loss_test:0.09210, lr:7.32e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.726, tt:2972.972\n",
      "Ep:73, loss:0.00002, loss_test:0.08846, lr:7.25e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.729, tt:3013.971\n",
      "Ep:74, loss:0.00002, loss_test:0.08708, lr:7.18e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.732, tt:3054.866\n",
      "Ep:75, loss:0.00002, loss_test:0.09077, lr:7.11e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.744, tt:3096.541\n",
      "Ep:76, loss:0.00002, loss_test:0.08777, lr:7.03e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.746, tt:3137.421\n",
      "Ep:77, loss:0.00001, loss_test:0.09404, lr:6.96e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.748, tt:3178.381\n",
      "Ep:78, loss:0.00001, loss_test:0.08819, lr:6.89e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.724, tt:3217.225\n",
      "Ep:79, loss:0.00001, loss_test:0.09339, lr:6.83e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.734, tt:3258.683\n",
      "Ep:80, loss:0.00001, loss_test:0.08657, lr:6.76e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.747, tt:3300.510\n",
      "Ep:81, loss:0.00001, loss_test:0.09474, lr:6.69e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.732, tt:3340.001\n",
      "Ep:82, loss:0.00001, loss_test:0.09206, lr:6.62e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.722, tt:3379.968\n",
      "Ep:83, loss:0.00001, loss_test:0.09248, lr:6.56e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.744, tt:3422.483\n",
      "Ep:84, loss:0.00001, loss_test:0.09259, lr:6.49e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.754, tt:3464.082\n",
      "Ep:85, loss:0.00001, loss_test:0.09147, lr:6.43e-03, fs:0.81046 (r=0.713,p=0.939),  time:40.735, tt:3503.190\n",
      "Ep:86, loss:0.00001, loss_test:0.09172, lr:6.36e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.728, tt:3543.348\n",
      "Ep:87, loss:0.00001, loss_test:0.09397, lr:6.30e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.724, tt:3583.747\n",
      "Ep:88, loss:0.00001, loss_test:0.08983, lr:6.24e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.724, tt:3624.398\n",
      "Ep:89, loss:0.00001, loss_test:0.09499, lr:6.17e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.722, tt:3664.961\n",
      "Ep:90, loss:0.00001, loss_test:0.09078, lr:6.11e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.723, tt:3705.782\n",
      "Ep:91, loss:0.00001, loss_test:0.09302, lr:6.05e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.749, tt:3748.897\n",
      "Ep:92, loss:0.00001, loss_test:0.09238, lr:5.99e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.774, tt:3792.005\n",
      "Ep:93, loss:0.00001, loss_test:0.09248, lr:5.93e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.791, tt:3834.369\n",
      "Ep:94, loss:0.00001, loss_test:0.09026, lr:5.87e-03, fs:0.81579 (r=0.713,p=0.954),  time:40.793, tt:3875.379\n",
      "Ep:95, loss:0.00001, loss_test:0.09612, lr:5.81e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.811, tt:3917.837\n",
      "Ep:96, loss:0.00001, loss_test:0.09195, lr:5.75e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.813, tt:3958.851\n",
      "Ep:97, loss:0.00001, loss_test:0.09202, lr:5.70e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.810, tt:3999.410\n",
      "Ep:98, loss:0.00001, loss_test:0.09533, lr:5.64e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.802, tt:4039.414\n",
      "Ep:99, loss:0.00001, loss_test:0.08996, lr:5.58e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.810, tt:4081.012\n",
      "Ep:100, loss:0.00001, loss_test:0.09615, lr:5.53e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.813, tt:4122.148\n",
      "Ep:101, loss:0.00001, loss_test:0.09439, lr:5.47e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.829, tt:4164.582\n",
      "Ep:102, loss:0.00001, loss_test:0.09248, lr:5.42e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.829, tt:4205.397\n",
      "Ep:103, loss:0.00001, loss_test:0.09261, lr:5.36e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.825, tt:4245.796\n",
      "Ep:104, loss:0.00001, loss_test:0.09419, lr:5.31e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.819, tt:4285.943\n",
      "Ep:105, loss:0.00001, loss_test:0.09397, lr:5.26e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.832, tt:4328.223\n",
      "Ep:106, loss:0.00001, loss_test:0.09224, lr:5.20e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.820, tt:4367.727\n",
      "Ep:107, loss:0.00001, loss_test:0.09537, lr:5.15e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.826, tt:4409.155\n",
      "Ep:108, loss:0.00001, loss_test:0.09154, lr:5.10e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.850, tt:4452.610\n",
      "Ep:109, loss:0.00001, loss_test:0.09575, lr:5.05e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.846, tt:4493.039\n",
      "Ep:110, loss:0.00001, loss_test:0.09583, lr:5.00e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.853, tt:4534.665\n",
      "Ep:111, loss:0.00001, loss_test:0.09130, lr:4.95e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.868, tt:4577.180\n",
      "Ep:112, loss:0.00001, loss_test:0.09354, lr:4.90e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.871, tt:4618.425\n",
      "Ep:113, loss:0.00001, loss_test:0.09182, lr:4.85e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.895, tt:4662.003\n",
      "Ep:114, loss:0.00001, loss_test:0.09705, lr:4.80e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.903, tt:4703.829\n",
      "Ep:115, loss:0.00001, loss_test:0.09076, lr:4.75e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.905, tt:4744.936\n",
      "Ep:116, loss:0.00001, loss_test:0.09669, lr:4.71e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.893, tt:4784.490\n",
      "Ep:117, loss:0.00001, loss_test:0.09375, lr:4.66e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.905, tt:4826.841\n",
      "Ep:118, loss:0.00001, loss_test:0.09207, lr:4.61e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.915, tt:4868.884\n",
      "Ep:119, loss:0.00001, loss_test:0.09378, lr:4.57e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.909, tt:4909.063\n",
      "Ep:120, loss:0.00001, loss_test:0.09480, lr:4.52e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.930, tt:4952.562\n",
      "Ep:121, loss:0.00001, loss_test:0.09429, lr:4.48e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.942, tt:4994.956\n",
      "Ep:122, loss:0.00001, loss_test:0.09255, lr:4.43e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.945, tt:5036.260\n",
      "Ep:123, loss:0.00001, loss_test:0.09598, lr:4.39e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.954, tt:5078.340\n",
      "Ep:124, loss:0.00001, loss_test:0.09409, lr:4.34e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.957, tt:5119.605\n",
      "Ep:125, loss:0.00001, loss_test:0.09260, lr:4.30e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.977, tt:5163.059\n",
      "Ep:126, loss:0.00001, loss_test:0.09350, lr:4.26e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.980, tt:5204.509\n",
      "Ep:127, loss:0.00001, loss_test:0.09404, lr:4.21e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.997, tt:5247.559\n",
      "Ep:128, loss:0.00001, loss_test:0.09363, lr:4.17e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.004, tt:5289.562\n",
      "Ep:129, loss:0.00001, loss_test:0.09371, lr:4.13e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.003, tt:5330.362\n",
      "Ep:130, loss:0.00001, loss_test:0.09445, lr:4.09e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.988, tt:5369.480\n",
      "Ep:131, loss:0.00001, loss_test:0.09549, lr:4.05e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.992, tt:5410.947\n",
      "Ep:132, loss:0.00001, loss_test:0.09261, lr:4.01e-03, fs:0.82119 (r=0.713,p=0.969),  time:40.992, tt:5451.906\n",
      "Ep:133, loss:0.00001, loss_test:0.09531, lr:3.97e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.983, tt:5491.743\n",
      "Ep:134, loss:0.00001, loss_test:0.09456, lr:3.93e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.989, tt:5533.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.09452, lr:3.89e-03, fs:0.82667 (r=0.713,p=0.984),  time:40.994, tt:5575.217\n",
      "Ep:136, loss:0.00001, loss_test:0.09465, lr:3.85e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.009, tt:5618.268\n",
      "Ep:137, loss:0.00001, loss_test:0.09382, lr:3.81e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.015, tt:5660.111\n",
      "Ep:138, loss:0.00001, loss_test:0.09450, lr:3.77e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.026, tt:5702.641\n",
      "Ep:139, loss:0.00001, loss_test:0.09315, lr:3.73e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.021, tt:5742.988\n",
      "Ep:140, loss:0.00000, loss_test:0.09490, lr:3.70e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.018, tt:5783.535\n",
      "Ep:141, loss:0.00000, loss_test:0.09462, lr:3.66e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.019, tt:5824.702\n",
      "Ep:142, loss:0.00000, loss_test:0.09456, lr:3.62e-03, fs:0.82119 (r=0.713,p=0.969),  time:41.017, tt:5865.426\n",
      "Ep:143, loss:0.00000, loss_test:0.09494, lr:3.59e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.025, tt:5907.655\n",
      "Ep:144, loss:0.00000, loss_test:0.09401, lr:3.55e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.017, tt:5947.526\n",
      "Ep:145, loss:0.00000, loss_test:0.09386, lr:3.52e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.013, tt:5987.862\n",
      "Ep:146, loss:0.00000, loss_test:0.09512, lr:3.48e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.015, tt:6029.201\n",
      "Ep:147, loss:0.00000, loss_test:0.09452, lr:3.45e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.004, tt:6068.589\n",
      "Ep:148, loss:0.00000, loss_test:0.09399, lr:3.41e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.025, tt:6112.750\n",
      "Ep:149, loss:0.00000, loss_test:0.09478, lr:3.38e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.030, tt:6154.441\n",
      "Ep:150, loss:0.00000, loss_test:0.09487, lr:3.34e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.037, tt:6196.616\n",
      "Ep:151, loss:0.00000, loss_test:0.09587, lr:3.31e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.036, tt:6237.411\n",
      "Ep:152, loss:0.00000, loss_test:0.09663, lr:3.28e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.036, tt:6278.521\n",
      "Ep:153, loss:0.00000, loss_test:0.09275, lr:3.24e-03, fs:0.82119 (r=0.713,p=0.969),  time:41.034, tt:6319.215\n",
      "Ep:154, loss:0.00000, loss_test:0.09681, lr:3.21e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.038, tt:6360.846\n",
      "Ep:155, loss:0.00000, loss_test:0.09559, lr:3.18e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.036, tt:6401.665\n",
      "Ep:156, loss:0.00000, loss_test:0.09346, lr:3.15e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.037, tt:6442.769\n",
      "Ep:157, loss:0.00000, loss_test:0.09637, lr:3.12e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.031, tt:6482.895\n",
      "Ep:158, loss:0.00000, loss_test:0.09533, lr:3.09e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.027, tt:6523.335\n",
      "Ep:159, loss:0.00000, loss_test:0.09385, lr:3.05e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.035, tt:6565.543\n",
      "Ep:160, loss:0.00000, loss_test:0.09554, lr:3.02e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.029, tt:6605.721\n",
      "Ep:161, loss:0.00000, loss_test:0.09429, lr:2.99e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.037, tt:6647.924\n",
      "Ep:162, loss:0.00000, loss_test:0.09384, lr:2.96e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.033, tt:6688.324\n",
      "Ep:163, loss:0.00000, loss_test:0.09564, lr:2.93e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.051, tt:6732.358\n",
      "Ep:164, loss:0.00000, loss_test:0.09452, lr:2.90e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.051, tt:6773.335\n",
      "Ep:165, loss:0.00000, loss_test:0.09371, lr:2.88e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.061, tt:6816.045\n",
      "Ep:166, loss:0.00000, loss_test:0.09504, lr:2.85e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.062, tt:6857.284\n",
      "Ep:167, loss:0.00000, loss_test:0.09565, lr:2.82e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.071, tt:6899.895\n",
      "Ep:168, loss:0.00000, loss_test:0.09415, lr:2.79e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.067, tt:6940.277\n",
      "Ep:169, loss:0.00000, loss_test:0.09556, lr:2.76e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.072, tt:6982.219\n",
      "Ep:170, loss:0.00000, loss_test:0.09552, lr:2.73e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.072, tt:7023.299\n",
      "Ep:171, loss:0.00000, loss_test:0.09466, lr:2.71e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.078, tt:7065.389\n",
      "Ep:172, loss:0.00000, loss_test:0.09498, lr:2.68e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.085, tt:7107.672\n",
      "Ep:173, loss:0.00000, loss_test:0.09506, lr:2.65e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.093, tt:7150.119\n",
      "Ep:174, loss:0.00000, loss_test:0.09482, lr:2.63e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.100, tt:7192.502\n",
      "Ep:175, loss:0.00000, loss_test:0.09528, lr:2.60e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.104, tt:7234.337\n",
      "Ep:176, loss:0.00000, loss_test:0.09427, lr:2.57e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.100, tt:7274.673\n",
      "Ep:177, loss:0.00000, loss_test:0.09487, lr:2.55e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.104, tt:7316.509\n",
      "Ep:178, loss:0.00000, loss_test:0.09536, lr:2.52e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.099, tt:7356.664\n",
      "Ep:179, loss:0.00000, loss_test:0.09550, lr:2.50e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.100, tt:7398.064\n",
      "Ep:180, loss:0.00000, loss_test:0.09460, lr:2.47e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.093, tt:7437.876\n",
      "Ep:181, loss:0.00000, loss_test:0.09568, lr:2.45e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.104, tt:7480.955\n",
      "Ep:182, loss:0.00000, loss_test:0.09487, lr:2.42e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.106, tt:7522.312\n",
      "Ep:183, loss:0.00000, loss_test:0.09489, lr:2.40e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.109, tt:7564.028\n",
      "Ep:184, loss:0.00000, loss_test:0.09548, lr:2.38e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.109, tt:7605.158\n",
      "Ep:185, loss:0.00000, loss_test:0.09529, lr:2.35e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.095, tt:7643.585\n",
      "Ep:186, loss:0.00000, loss_test:0.09517, lr:2.33e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.089, tt:7683.715\n",
      "Ep:187, loss:0.00000, loss_test:0.09590, lr:2.31e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.091, tt:7725.193\n",
      "Ep:188, loss:0.00000, loss_test:0.09569, lr:2.28e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.095, tt:7766.894\n",
      "Ep:189, loss:0.00000, loss_test:0.09466, lr:2.26e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.112, tt:7811.200\n",
      "Ep:190, loss:0.00000, loss_test:0.09538, lr:2.24e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.105, tt:7851.056\n",
      "Ep:191, loss:0.00000, loss_test:0.09578, lr:2.21e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.100, tt:7891.270\n",
      "Ep:192, loss:0.00000, loss_test:0.09558, lr:2.19e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.099, tt:7932.050\n",
      "Ep:193, loss:0.00000, loss_test:0.09545, lr:2.17e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.087, tt:7970.801\n",
      "Ep:194, loss:0.00000, loss_test:0.09537, lr:2.15e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.093, tt:8013.123\n",
      "Ep:195, loss:0.00000, loss_test:0.09578, lr:2.13e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.090, tt:8053.573\n",
      "Ep:196, loss:0.00000, loss_test:0.09650, lr:2.11e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.086, tt:8093.979\n",
      "Ep:197, loss:0.00000, loss_test:0.09557, lr:2.08e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.079, tt:8133.552\n",
      "Ep:198, loss:0.00000, loss_test:0.09561, lr:2.06e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.081, tt:8175.152\n",
      "Ep:199, loss:0.00000, loss_test:0.09576, lr:2.04e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.082, tt:8216.480\n",
      "Ep:200, loss:0.00000, loss_test:0.09550, lr:2.02e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.081, tt:8257.256\n",
      "Ep:201, loss:0.00000, loss_test:0.09626, lr:2.00e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.085, tt:8299.171\n",
      "Ep:202, loss:0.00000, loss_test:0.09586, lr:1.98e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.079, tt:8339.126\n",
      "Ep:203, loss:0.00000, loss_test:0.09533, lr:1.96e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.078, tt:8379.831\n",
      "Ep:204, loss:0.00000, loss_test:0.09563, lr:1.94e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.080, tt:8421.470\n",
      "Ep:205, loss:0.00000, loss_test:0.09600, lr:1.92e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.080, tt:8462.389\n",
      "Ep:206, loss:0.00000, loss_test:0.09578, lr:1.90e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.083, tt:8504.240\n",
      "Ep:207, loss:0.00000, loss_test:0.09653, lr:1.89e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.098, tt:8548.334\n",
      "Ep:208, loss:0.00000, loss_test:0.09581, lr:1.87e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.099, tt:8589.618\n",
      "Ep:209, loss:0.00000, loss_test:0.09533, lr:1.85e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.133, tt:8637.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.09679, lr:1.83e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.129, tt:8678.279\n",
      "Ep:211, loss:0.00000, loss_test:0.09740, lr:1.81e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.132, tt:8719.998\n",
      "Ep:212, loss:0.00000, loss_test:0.09617, lr:1.79e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.126, tt:8759.749\n",
      "Ep:213, loss:0.00000, loss_test:0.09551, lr:1.78e-03, fs:0.82667 (r=0.713,p=0.984),  time:41.092, tt:8793.641\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02078, lr:6.00e-02, fs:0.63158 (r=0.828,p=0.511),  time:29.746, tt:29.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02231, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:31.693, tt:63.387\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02284, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:33.057, tt:99.171\n",
      "Ep:3, loss:0.00004, loss_test:0.02205, lr:6.00e-02, fs:0.64032 (r=0.931,p=0.488),  time:33.587, tt:134.347\n",
      "Ep:4, loss:0.00004, loss_test:0.02094, lr:6.00e-02, fs:0.64463 (r=0.897,p=0.503),  time:34.282, tt:171.410\n",
      "Ep:5, loss:0.00004, loss_test:0.02067, lr:6.00e-02, fs:0.65502 (r=0.862,p=0.528),  time:35.355, tt:212.132\n",
      "Ep:6, loss:0.00004, loss_test:0.02107, lr:6.00e-02, fs:0.64423 (r=0.770,p=0.554),  time:36.133, tt:252.928\n",
      "Ep:7, loss:0.00004, loss_test:0.02092, lr:6.00e-02, fs:0.65657 (r=0.747,p=0.586),  time:36.897, tt:295.177\n",
      "Ep:8, loss:0.00004, loss_test:0.01980, lr:6.00e-02, fs:0.64734 (r=0.770,p=0.558),  time:37.645, tt:338.808\n",
      "Ep:9, loss:0.00003, loss_test:0.01894, lr:6.00e-02, fs:0.65455 (r=0.828,p=0.541),  time:37.988, tt:379.879\n",
      "Ep:10, loss:0.00003, loss_test:0.01850, lr:6.00e-02, fs:0.66964 (r=0.862,p=0.547),  time:38.189, tt:420.082\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01822, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:38.428, tt:461.138\n",
      "Ep:12, loss:0.00003, loss_test:0.01809, lr:6.00e-02, fs:0.66667 (r=0.805,p=0.569),  time:38.581, tt:501.557\n",
      "Ep:13, loss:0.00003, loss_test:0.01811, lr:6.00e-02, fs:0.67327 (r=0.782,p=0.591),  time:38.726, tt:542.168\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01802, lr:6.00e-02, fs:0.68342 (r=0.782,p=0.607),  time:38.963, tt:584.450\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01771, lr:6.00e-02, fs:0.68367 (r=0.770,p=0.615),  time:39.113, tt:625.807\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01735, lr:6.00e-02, fs:0.68657 (r=0.793,p=0.605),  time:39.231, tt:666.924\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01706, lr:6.00e-02, fs:0.70707 (r=0.805,p=0.631),  time:39.335, tt:708.035\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.72251 (r=0.793,p=0.663),  time:39.440, tt:749.365\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01704, lr:6.00e-02, fs:0.74737 (r=0.816,p=0.689),  time:39.427, tt:788.545\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.76842 (r=0.839,p=0.709),  time:39.463, tt:828.733\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01651, lr:6.00e-02, fs:0.78723 (r=0.851,p=0.733),  time:39.472, tt:868.377\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01620, lr:6.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:39.513, tt:908.793\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01612, lr:6.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:39.608, tt:950.592\n",
      "Ep:24, loss:0.00002, loss_test:0.01624, lr:6.00e-02, fs:0.79787 (r=0.862,p=0.743),  time:39.690, tt:992.248\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.79144 (r=0.851,p=0.740),  time:39.808, tt:1035.001\n",
      "Ep:26, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.80645 (r=0.862,p=0.758),  time:39.810, tt:1074.877\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.80645 (r=0.862,p=0.758),  time:39.808, tt:1114.626\n",
      "Ep:28, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:39.865, tt:1156.077\n",
      "Ep:29, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:40.032, tt:1200.955\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:40.080, tt:1242.490\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:40.121, tt:1283.865\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.177, tt:1325.848\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:40.260, tt:1368.839\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:40.313, tt:1410.939\n",
      "Ep:35, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:40.330, tt:1451.882\n",
      "Ep:36, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.364, tt:1493.465\n",
      "Ep:37, loss:0.00002, loss_test:0.01534, lr:6.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.440, tt:1536.724\n",
      "Ep:38, loss:0.00002, loss_test:0.01544, lr:6.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:40.523, tt:1580.411\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01550, lr:6.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:40.661, tt:1626.460\n",
      "Ep:40, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:40.761, tt:1671.211\n",
      "Ep:41, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.774, tt:1712.488\n",
      "Ep:42, loss:0.00001, loss_test:0.01559, lr:6.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:40.810, tt:1754.840\n",
      "Ep:43, loss:0.00001, loss_test:0.01562, lr:6.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.863, tt:1797.962\n",
      "Ep:44, loss:0.00001, loss_test:0.01580, lr:6.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.903, tt:1840.652\n",
      "Ep:45, loss:0.00001, loss_test:0.01593, lr:6.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.949, tt:1883.659\n",
      "Ep:46, loss:0.00001, loss_test:0.01592, lr:6.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.991, tt:1926.570\n",
      "Ep:47, loss:0.00001, loss_test:0.01604, lr:6.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:40.985, tt:1967.277\n",
      "Ep:48, loss:0.00001, loss_test:0.01620, lr:6.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:40.977, tt:2007.887\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01624, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:41.003, tt:2050.172\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:40.984, tt:2090.178\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:40.997, tt:2131.853\n",
      "Ep:52, loss:0.00001, loss_test:0.01648, lr:6.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:41.041, tt:2175.184\n",
      "Ep:53, loss:0.00001, loss_test:0.01659, lr:6.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:41.054, tt:2216.907\n",
      "Ep:54, loss:0.00001, loss_test:0.01682, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.062, tt:2258.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00001, loss_test:0.01681, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.088, tt:2300.935\n",
      "Ep:56, loss:0.00001, loss_test:0.01705, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.128, tt:2344.296\n",
      "Ep:57, loss:0.00001, loss_test:0.01718, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:41.137, tt:2385.922\n",
      "Ep:58, loss:0.00001, loss_test:0.01726, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:41.132, tt:2426.789\n",
      "Ep:59, loss:0.00001, loss_test:0.01732, lr:6.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:41.114, tt:2466.835\n",
      "Ep:60, loss:0.00001, loss_test:0.01748, lr:6.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.135, tt:2509.222\n",
      "Ep:61, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.158, tt:2551.820\n",
      "Ep:62, loss:0.00001, loss_test:0.01779, lr:5.94e-02, fs:0.84615 (r=0.759,p=0.957),  time:41.149, tt:2592.387\n",
      "Ep:63, loss:0.00001, loss_test:0.01789, lr:5.88e-02, fs:0.84615 (r=0.759,p=0.957),  time:41.173, tt:2635.061\n",
      "Ep:64, loss:0.00001, loss_test:0.01815, lr:5.82e-02, fs:0.83871 (r=0.747,p=0.956),  time:41.192, tt:2677.448\n",
      "Ep:65, loss:0.00001, loss_test:0.01823, lr:5.76e-02, fs:0.83871 (r=0.747,p=0.956),  time:41.192, tt:2718.690\n",
      "Ep:66, loss:0.00001, loss_test:0.01854, lr:5.71e-02, fs:0.83117 (r=0.736,p=0.955),  time:41.201, tt:2760.499\n",
      "Ep:67, loss:0.00001, loss_test:0.01830, lr:5.65e-02, fs:0.83117 (r=0.736,p=0.955),  time:41.187, tt:2800.738\n",
      "Ep:68, loss:0.00001, loss_test:0.01855, lr:5.59e-02, fs:0.83117 (r=0.736,p=0.955),  time:41.194, tt:2842.385\n",
      "Ep:69, loss:0.00001, loss_test:0.01869, lr:5.54e-02, fs:0.83660 (r=0.736,p=0.970),  time:41.196, tt:2883.703\n",
      "Ep:70, loss:0.00001, loss_test:0.01867, lr:5.48e-02, fs:0.83660 (r=0.736,p=0.970),  time:41.188, tt:2924.348\n",
      "Ep:71, loss:0.00001, loss_test:0.01905, lr:5.43e-02, fs:0.84211 (r=0.736,p=0.985),  time:41.192, tt:2965.818\n",
      "Ep:72, loss:0.00001, loss_test:0.01908, lr:5.37e-02, fs:0.84211 (r=0.736,p=0.985),  time:41.172, tt:3005.557\n",
      "Ep:73, loss:0.00001, loss_test:0.01915, lr:5.32e-02, fs:0.84211 (r=0.736,p=0.985),  time:41.176, tt:3047.007\n",
      "Ep:74, loss:0.00001, loss_test:0.01943, lr:5.27e-02, fs:0.84211 (r=0.736,p=0.985),  time:41.185, tt:3088.877\n",
      "Ep:75, loss:0.00001, loss_test:0.01941, lr:5.21e-02, fs:0.84211 (r=0.736,p=0.985),  time:41.218, tt:3132.552\n",
      "Ep:76, loss:0.00001, loss_test:0.01941, lr:5.16e-02, fs:0.82667 (r=0.713,p=0.984),  time:41.198, tt:3172.219\n",
      "Ep:77, loss:0.00001, loss_test:0.01978, lr:5.11e-02, fs:0.82667 (r=0.713,p=0.984),  time:41.186, tt:3212.472\n",
      "Ep:78, loss:0.00001, loss_test:0.01983, lr:5.06e-02, fs:0.82667 (r=0.713,p=0.984),  time:41.193, tt:3254.258\n",
      "Ep:79, loss:0.00001, loss_test:0.01974, lr:5.01e-02, fs:0.82667 (r=0.713,p=0.984),  time:41.176, tt:3294.076\n",
      "Ep:80, loss:0.00001, loss_test:0.02013, lr:4.96e-02, fs:0.82667 (r=0.713,p=0.984),  time:41.170, tt:3334.744\n",
      "Ep:81, loss:0.00001, loss_test:0.02026, lr:4.91e-02, fs:0.82667 (r=0.713,p=0.984),  time:41.165, tt:3375.562\n",
      "Ep:82, loss:0.00001, loss_test:0.02030, lr:4.86e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.158, tt:3416.105\n",
      "Ep:83, loss:0.00001, loss_test:0.02057, lr:4.81e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.148, tt:3456.450\n",
      "Ep:84, loss:0.00001, loss_test:0.02069, lr:4.76e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.139, tt:3496.777\n",
      "Ep:85, loss:0.00001, loss_test:0.02075, lr:4.71e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.124, tt:3536.693\n",
      "Ep:86, loss:0.00001, loss_test:0.02097, lr:4.67e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.118, tt:3577.296\n",
      "Ep:87, loss:0.00001, loss_test:0.02107, lr:4.62e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.100, tt:3616.817\n",
      "Ep:88, loss:0.00001, loss_test:0.02113, lr:4.57e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.114, tt:3659.181\n",
      "Ep:89, loss:0.00001, loss_test:0.02134, lr:4.53e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.127, tt:3701.440\n",
      "Ep:90, loss:0.00001, loss_test:0.02141, lr:4.48e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.125, tt:3742.396\n",
      "Ep:91, loss:0.00001, loss_test:0.02152, lr:4.44e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.145, tt:3785.347\n",
      "Ep:92, loss:0.00001, loss_test:0.02170, lr:4.39e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.149, tt:3826.838\n",
      "Ep:93, loss:0.00001, loss_test:0.02181, lr:4.35e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.164, tt:3869.402\n",
      "Ep:94, loss:0.00001, loss_test:0.02184, lr:4.31e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.157, tt:3909.921\n",
      "Ep:95, loss:0.00001, loss_test:0.02220, lr:4.26e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.150, tt:3950.428\n",
      "Ep:96, loss:0.00001, loss_test:0.02222, lr:4.22e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.158, tt:3992.286\n",
      "Ep:97, loss:0.00001, loss_test:0.02224, lr:4.18e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.138, tt:4031.485\n",
      "Ep:98, loss:0.00001, loss_test:0.02234, lr:4.14e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.131, tt:4071.929\n",
      "Ep:99, loss:0.00001, loss_test:0.02242, lr:4.10e-02, fs:0.83221 (r=0.713,p=1.000),  time:41.153, tt:4115.323\n",
      "Ep:100, loss:0.00001, loss_test:0.02274, lr:4.05e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.159, tt:4157.108\n",
      "Ep:101, loss:0.00001, loss_test:0.02259, lr:4.01e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.180, tt:4200.386\n",
      "Ep:102, loss:0.00001, loss_test:0.02288, lr:3.97e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.180, tt:4241.579\n",
      "Ep:103, loss:0.00001, loss_test:0.02311, lr:3.93e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.192, tt:4283.977\n",
      "Ep:104, loss:0.00001, loss_test:0.02311, lr:3.89e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.194, tt:4325.348\n",
      "Ep:105, loss:0.00001, loss_test:0.02322, lr:3.86e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.227, tt:4370.047\n",
      "Ep:106, loss:0.00000, loss_test:0.02335, lr:3.82e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.236, tt:4412.290\n",
      "Ep:107, loss:0.00000, loss_test:0.02350, lr:3.78e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.237, tt:4453.561\n",
      "Ep:108, loss:0.00000, loss_test:0.02341, lr:3.74e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.255, tt:4496.743\n",
      "Ep:109, loss:0.00000, loss_test:0.02361, lr:3.70e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.247, tt:4537.195\n",
      "Ep:110, loss:0.00000, loss_test:0.02378, lr:3.67e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.235, tt:4577.078\n",
      "Ep:111, loss:0.00000, loss_test:0.02376, lr:3.63e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.242, tt:4619.138\n",
      "Ep:112, loss:0.00000, loss_test:0.02384, lr:3.59e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.246, tt:4660.816\n",
      "Ep:113, loss:0.00000, loss_test:0.02399, lr:3.56e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.253, tt:4702.879\n",
      "Ep:114, loss:0.00000, loss_test:0.02395, lr:3.52e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.245, tt:4743.165\n",
      "Ep:115, loss:0.00000, loss_test:0.02419, lr:3.49e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.243, tt:4784.234\n",
      "Ep:116, loss:0.00000, loss_test:0.02442, lr:3.45e-02, fs:0.80000 (r=0.667,p=1.000),  time:41.250, tt:4826.194\n",
      "Ep:117, loss:0.00000, loss_test:0.02441, lr:3.42e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.258, tt:4868.469\n",
      "Ep:118, loss:0.00000, loss_test:0.02442, lr:3.38e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.261, tt:4910.116\n",
      "Ep:119, loss:0.00000, loss_test:0.02453, lr:3.35e-02, fs:0.81633 (r=0.690,p=1.000),  time:41.271, tt:4952.579\n",
      "Ep:120, loss:0.00000, loss_test:0.02465, lr:3.32e-02, fs:0.81633 (r=0.690,p=1.000),  time:41.288, tt:4995.802\n",
      "Ep:121, loss:0.00000, loss_test:0.02476, lr:3.28e-02, fs:0.81633 (r=0.690,p=1.000),  time:41.304, tt:5039.067\n",
      "Ep:122, loss:0.00000, loss_test:0.02481, lr:3.25e-02, fs:0.82432 (r=0.701,p=1.000),  time:41.299, tt:5079.758\n",
      "Ep:123, loss:0.00000, loss_test:0.02504, lr:3.22e-02, fs:0.78322 (r=0.644,p=1.000),  time:41.304, tt:5121.734\n",
      "Ep:124, loss:0.00000, loss_test:0.02499, lr:3.19e-02, fs:0.81633 (r=0.690,p=1.000),  time:41.298, tt:5162.296\n",
      "Ep:125, loss:0.00000, loss_test:0.02514, lr:3.15e-02, fs:0.79167 (r=0.655,p=1.000),  time:41.298, tt:5203.596\n",
      "Ep:126, loss:0.00000, loss_test:0.02534, lr:3.12e-02, fs:0.78322 (r=0.644,p=1.000),  time:41.302, tt:5245.347\n",
      "Ep:127, loss:0.00000, loss_test:0.02527, lr:3.09e-02, fs:0.81633 (r=0.690,p=1.000),  time:41.301, tt:5286.490\n",
      "Ep:128, loss:0.00000, loss_test:0.02534, lr:3.06e-02, fs:0.79167 (r=0.655,p=1.000),  time:41.306, tt:5328.465\n",
      "Ep:129, loss:0.00000, loss_test:0.02544, lr:3.03e-02, fs:0.79167 (r=0.655,p=1.000),  time:41.310, tt:5370.297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.02556, lr:3.00e-02, fs:0.79167 (r=0.655,p=1.000),  time:41.304, tt:5410.865\n",
      "Ep:131, loss:0.00000, loss_test:0.02569, lr:2.97e-02, fs:0.76596 (r=0.621,p=1.000),  time:41.302, tt:5451.799\n",
      "Ep:132, loss:0.00000, loss_test:0.02566, lr:2.94e-02, fs:0.78322 (r=0.644,p=1.000),  time:41.316, tt:5495.082\n",
      "Ep:133, loss:0.00000, loss_test:0.02583, lr:2.91e-02, fs:0.78322 (r=0.644,p=1.000),  time:41.312, tt:5535.813\n",
      "Ep:134, loss:0.00000, loss_test:0.02589, lr:2.88e-02, fs:0.75714 (r=0.609,p=1.000),  time:41.327, tt:5579.169\n",
      "Ep:135, loss:0.00000, loss_test:0.02593, lr:2.85e-02, fs:0.77465 (r=0.632,p=1.000),  time:41.312, tt:5618.400\n",
      "Ep:136, loss:0.00000, loss_test:0.02603, lr:2.82e-02, fs:0.76596 (r=0.621,p=1.000),  time:41.309, tt:5659.363\n",
      "Ep:137, loss:0.00000, loss_test:0.02613, lr:2.80e-02, fs:0.75714 (r=0.609,p=1.000),  time:41.327, tt:5703.058\n",
      "Ep:138, loss:0.00000, loss_test:0.02618, lr:2.77e-02, fs:0.75714 (r=0.609,p=1.000),  time:41.337, tt:5745.777\n",
      "Ep:139, loss:0.00000, loss_test:0.02629, lr:2.74e-02, fs:0.74820 (r=0.598,p=1.000),  time:41.348, tt:5788.657\n",
      "Ep:140, loss:0.00000, loss_test:0.02634, lr:2.71e-02, fs:0.72059 (r=0.563,p=1.000),  time:41.340, tt:5828.988\n",
      "Ep:141, loss:0.00000, loss_test:0.02642, lr:2.69e-02, fs:0.72059 (r=0.563,p=1.000),  time:41.349, tt:5871.513\n",
      "Ep:142, loss:0.00000, loss_test:0.02647, lr:2.66e-02, fs:0.72059 (r=0.563,p=1.000),  time:41.357, tt:5914.121\n",
      "Ep:143, loss:0.00000, loss_test:0.02667, lr:2.63e-02, fs:0.72059 (r=0.563,p=1.000),  time:41.352, tt:5954.628\n",
      "Ep:144, loss:0.00000, loss_test:0.02664, lr:2.61e-02, fs:0.72059 (r=0.563,p=1.000),  time:41.354, tt:5996.330\n",
      "Ep:145, loss:0.00000, loss_test:0.02667, lr:2.58e-02, fs:0.71111 (r=0.552,p=1.000),  time:41.348, tt:6036.761\n",
      "Ep:146, loss:0.00000, loss_test:0.02681, lr:2.55e-02, fs:0.71111 (r=0.552,p=1.000),  time:41.349, tt:6078.376\n",
      "Ep:147, loss:0.00000, loss_test:0.02686, lr:2.53e-02, fs:0.71111 (r=0.552,p=1.000),  time:41.356, tt:6120.646\n",
      "Ep:148, loss:0.00000, loss_test:0.02690, lr:2.50e-02, fs:0.70149 (r=0.540,p=1.000),  time:41.346, tt:6160.492\n",
      "Ep:149, loss:0.00000, loss_test:0.02700, lr:2.48e-02, fs:0.69173 (r=0.529,p=1.000),  time:41.332, tt:6199.818\n",
      "Ep:150, loss:0.00000, loss_test:0.02711, lr:2.45e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.317, tt:6238.930\n",
      "Ep:151, loss:0.00000, loss_test:0.02709, lr:2.43e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.313, tt:6279.641\n",
      "Ep:152, loss:0.00000, loss_test:0.02712, lr:2.40e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.315, tt:6321.172\n",
      "Ep:153, loss:0.00000, loss_test:0.02722, lr:2.38e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.301, tt:6360.307\n",
      "Ep:154, loss:0.00000, loss_test:0.02739, lr:2.36e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.305, tt:6402.318\n",
      "Ep:155, loss:0.00000, loss_test:0.02734, lr:2.33e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.303, tt:6443.326\n",
      "Ep:156, loss:0.00000, loss_test:0.02737, lr:2.31e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.290, tt:6482.589\n",
      "Ep:157, loss:0.00000, loss_test:0.02759, lr:2.29e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.295, tt:6524.581\n",
      "Ep:158, loss:0.00000, loss_test:0.02756, lr:2.26e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.289, tt:6564.996\n",
      "Ep:159, loss:0.00000, loss_test:0.02751, lr:2.24e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.291, tt:6606.584\n",
      "Ep:160, loss:0.00000, loss_test:0.02767, lr:2.22e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.308, tt:6650.650\n",
      "Ep:161, loss:0.00000, loss_test:0.02781, lr:2.20e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.320, tt:6693.802\n",
      "Ep:162, loss:0.00000, loss_test:0.02774, lr:2.17e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.332, tt:6737.196\n",
      "Ep:163, loss:0.00000, loss_test:0.02779, lr:2.15e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.350, tt:6781.419\n",
      "Ep:164, loss:0.00000, loss_test:0.02799, lr:2.13e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.359, tt:6824.206\n",
      "Ep:165, loss:0.00000, loss_test:0.02790, lr:2.11e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.376, tt:6868.453\n",
      "Ep:166, loss:0.00000, loss_test:0.02795, lr:2.09e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.382, tt:6910.729\n",
      "Ep:167, loss:0.00000, loss_test:0.02805, lr:2.07e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.402, tt:6955.458\n",
      "Ep:168, loss:0.00000, loss_test:0.02811, lr:2.05e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.400, tt:6996.625\n",
      "Ep:169, loss:0.00000, loss_test:0.02817, lr:2.03e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.422, tt:7041.677\n",
      "Ep:170, loss:0.00000, loss_test:0.02818, lr:2.01e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.436, tt:7085.481\n",
      "Ep:171, loss:0.00000, loss_test:0.02819, lr:1.99e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.451, tt:7129.533\n",
      "Ep:172, loss:0.00000, loss_test:0.02826, lr:1.97e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.462, tt:7172.987\n",
      "Ep:173, loss:0.00000, loss_test:0.02840, lr:1.95e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.463, tt:7214.499\n",
      "Ep:174, loss:0.00000, loss_test:0.02839, lr:1.93e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.479, tt:7258.899\n",
      "Ep:175, loss:0.00000, loss_test:0.02840, lr:1.91e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.500, tt:7303.931\n",
      "Ep:176, loss:0.00000, loss_test:0.02851, lr:1.89e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.515, tt:7348.196\n",
      "Ep:177, loss:0.00000, loss_test:0.02850, lr:1.87e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.532, tt:7392.692\n",
      "Ep:178, loss:0.00000, loss_test:0.02851, lr:1.85e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.544, tt:7436.368\n",
      "Ep:179, loss:0.00000, loss_test:0.02863, lr:1.83e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.538, tt:7476.766\n",
      "Ep:180, loss:0.00000, loss_test:0.02867, lr:1.81e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.545, tt:7519.597\n",
      "Ep:181, loss:0.00000, loss_test:0.02867, lr:1.80e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.555, tt:7562.944\n",
      "Ep:182, loss:0.00000, loss_test:0.02880, lr:1.78e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.564, tt:7606.194\n",
      "Ep:183, loss:0.00000, loss_test:0.02881, lr:1.76e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.575, tt:7649.821\n",
      "Ep:184, loss:0.00000, loss_test:0.02881, lr:1.74e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.591, tt:7694.255\n",
      "Ep:185, loss:0.00000, loss_test:0.02883, lr:1.73e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.597, tt:7737.085\n",
      "Ep:186, loss:0.00000, loss_test:0.02894, lr:1.71e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.612, tt:7781.500\n",
      "Ep:187, loss:0.00000, loss_test:0.02901, lr:1.69e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.612, tt:7823.119\n",
      "Ep:188, loss:0.00000, loss_test:0.02902, lr:1.67e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.611, tt:7864.402\n",
      "Ep:189, loss:0.00000, loss_test:0.02903, lr:1.66e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.611, tt:7906.086\n",
      "Ep:190, loss:0.00000, loss_test:0.02909, lr:1.64e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.619, tt:7949.315\n",
      "Ep:191, loss:0.00000, loss_test:0.02914, lr:1.62e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.626, tt:7992.102\n",
      "Ep:192, loss:0.00000, loss_test:0.02918, lr:1.61e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.623, tt:8033.231\n",
      "Ep:193, loss:0.00000, loss_test:0.02917, lr:1.59e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.637, tt:8077.561\n",
      "Ep:194, loss:0.00000, loss_test:0.02921, lr:1.58e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.638, tt:8119.396\n",
      "Ep:195, loss:0.00000, loss_test:0.02932, lr:1.56e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.643, tt:8162.046\n",
      "Ep:196, loss:0.00000, loss_test:0.02931, lr:1.54e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.645, tt:8203.982\n",
      "Ep:197, loss:0.00000, loss_test:0.02934, lr:1.53e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.650, tt:8246.785\n",
      "Ep:198, loss:0.00000, loss_test:0.02940, lr:1.51e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.661, tt:8290.466\n",
      "Ep:199, loss:0.00000, loss_test:0.02943, lr:1.50e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.667, tt:8333.449\n",
      "Ep:200, loss:0.00000, loss_test:0.02948, lr:1.48e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.671, tt:8375.852\n",
      "Ep:201, loss:0.00000, loss_test:0.02951, lr:1.47e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.682, tt:8419.842\n",
      "Ep:202, loss:0.00000, loss_test:0.02950, lr:1.45e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.681, tt:8461.188\n",
      "Ep:203, loss:0.00000, loss_test:0.02958, lr:1.44e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.685, tt:8503.652\n",
      "Ep:204, loss:0.00000, loss_test:0.02963, lr:1.43e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.689, tt:8546.237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.02963, lr:1.41e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.685, tt:8587.192\n",
      "Ep:206, loss:0.00000, loss_test:0.02959, lr:1.40e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.701, tt:8632.023\n",
      "Ep:207, loss:0.00000, loss_test:0.02965, lr:1.38e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.710, tt:8675.590\n",
      "Ep:208, loss:0.00000, loss_test:0.02972, lr:1.37e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.714, tt:8718.158\n",
      "Ep:209, loss:0.00000, loss_test:0.02973, lr:1.36e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.750, tt:8767.499\n",
      "Ep:210, loss:0.00000, loss_test:0.02974, lr:1.34e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.750, tt:8809.209\n",
      "Ep:211, loss:0.00000, loss_test:0.02978, lr:1.33e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.753, tt:8851.593\n",
      "Ep:212, loss:0.00000, loss_test:0.02984, lr:1.32e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.754, tt:8893.499\n",
      "Ep:213, loss:0.00000, loss_test:0.02986, lr:1.30e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.749, tt:8934.219\n",
      "Ep:214, loss:0.00000, loss_test:0.02987, lr:1.29e-02, fs:0.68182 (r=0.517,p=1.000),  time:41.742, tt:8974.453\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13980, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.856, tt:33.856\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13622, lr:1.00e-02, fs:0.64822 (r=0.943,p=0.494),  time:35.857, tt:71.715\n",
      "Ep:2, loss:0.00026, loss_test:0.12936, lr:1.00e-02, fs:0.62393 (r=0.839,p=0.497),  time:36.831, tt:110.494\n",
      "Ep:3, loss:0.00025, loss_test:0.12397, lr:1.00e-02, fs:0.65421 (r=0.805,p=0.551),  time:37.237, tt:148.949\n",
      "Ep:4, loss:0.00023, loss_test:0.12153, lr:1.00e-02, fs:0.69519 (r=0.747,p=0.650),  time:38.714, tt:193.572\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11620, lr:1.00e-02, fs:0.70330 (r=0.736,p=0.674),  time:38.735, tt:232.412\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.11272, lr:1.00e-02, fs:0.68508 (r=0.713,p=0.660),  time:39.330, tt:275.307\n",
      "Ep:7, loss:0.00021, loss_test:0.10999, lr:1.00e-02, fs:0.67391 (r=0.713,p=0.639),  time:39.761, tt:318.090\n",
      "Ep:8, loss:0.00020, loss_test:0.10790, lr:1.00e-02, fs:0.64045 (r=0.655,p=0.626),  time:40.332, tt:362.985\n",
      "Ep:9, loss:0.00020, loss_test:0.10716, lr:1.00e-02, fs:0.65497 (r=0.644,p=0.667),  time:40.630, tt:406.296\n",
      "Ep:10, loss:0.00019, loss_test:0.10480, lr:1.00e-02, fs:0.67797 (r=0.690,p=0.667),  time:40.874, tt:449.609\n",
      "Ep:11, loss:0.00018, loss_test:0.10306, lr:1.00e-02, fs:0.68182 (r=0.690,p=0.674),  time:41.070, tt:492.837\n",
      "Ep:12, loss:0.00018, loss_test:0.10155, lr:1.00e-02, fs:0.70238 (r=0.678,p=0.728),  time:41.124, tt:534.608\n",
      "Ep:13, loss:0.00017, loss_test:0.09946, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:41.350, tt:578.899\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.09729, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:41.529, tt:622.939\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09601, lr:1.00e-02, fs:0.76190 (r=0.736,p=0.790),  time:41.623, tt:665.962\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09424, lr:1.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:41.694, tt:708.806\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09229, lr:1.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:41.692, tt:750.462\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09065, lr:1.00e-02, fs:0.81395 (r=0.805,p=0.824),  time:41.854, tt:795.231\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.08873, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:41.913, tt:838.270\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08818, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:41.960, tt:881.166\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08637, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:42.038, tt:924.846\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08554, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.124, tt:968.849\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08455, lr:1.00e-02, fs:0.84524 (r=0.816,p=0.877),  time:42.160, tt:1011.832\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08425, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:42.260, tt:1056.509\n",
      "Ep:25, loss:0.00011, loss_test:0.08170, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.342, tt:1100.899\n",
      "Ep:26, loss:0.00011, loss_test:0.08473, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:42.374, tt:1144.095\n",
      "Ep:27, loss:0.00010, loss_test:0.07912, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:42.423, tt:1187.839\n",
      "Ep:28, loss:0.00010, loss_test:0.08089, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.436, tt:1230.652\n",
      "Ep:29, loss:0.00010, loss_test:0.07727, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:42.454, tt:1273.611\n",
      "Ep:30, loss:0.00009, loss_test:0.07799, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.484, tt:1317.011\n",
      "Ep:31, loss:0.00009, loss_test:0.07770, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:42.436, tt:1357.943\n",
      "Ep:32, loss:0.00009, loss_test:0.07715, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.492, tt:1402.251\n",
      "Ep:33, loss:0.00008, loss_test:0.07775, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:42.564, tt:1447.186\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.07385, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.599, tt:1490.951\n",
      "Ep:35, loss:0.00008, loss_test:0.07634, lr:1.00e-02, fs:0.84524 (r=0.816,p=0.877),  time:42.574, tt:1532.674\n",
      "Ep:36, loss:0.00008, loss_test:0.07558, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:42.629, tt:1577.257\n",
      "Ep:37, loss:0.00007, loss_test:0.07074, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:42.636, tt:1620.155\n",
      "Ep:38, loss:0.00007, loss_test:0.07520, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:42.635, tt:1662.765\n",
      "Ep:39, loss:0.00007, loss_test:0.07015, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:42.642, tt:1705.673\n",
      "Ep:40, loss:0.00007, loss_test:0.07596, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:42.653, tt:1748.772\n",
      "Ep:41, loss:0.00006, loss_test:0.07080, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:42.654, tt:1791.471\n",
      "Ep:42, loss:0.00006, loss_test:0.07411, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:42.636, tt:1833.337\n",
      "Ep:43, loss:0.00006, loss_test:0.06905, lr:1.00e-02, fs:0.81988 (r=0.759,p=0.892),  time:42.627, tt:1875.568\n",
      "Ep:44, loss:0.00006, loss_test:0.07319, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:42.607, tt:1917.299\n",
      "Ep:45, loss:0.00006, loss_test:0.07219, lr:9.90e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.654, tt:1962.090\n",
      "Ep:46, loss:0.00005, loss_test:0.07149, lr:9.80e-03, fs:0.82500 (r=0.759,p=0.904),  time:42.626, tt:2003.409\n",
      "Ep:47, loss:0.00005, loss_test:0.07210, lr:9.70e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.577, tt:2043.703\n",
      "Ep:48, loss:0.00005, loss_test:0.07182, lr:9.61e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.562, tt:2085.522\n",
      "Ep:49, loss:0.00005, loss_test:0.07042, lr:9.51e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.530, tt:2126.521\n",
      "Ep:50, loss:0.00005, loss_test:0.07326, lr:9.41e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.528, tt:2168.940\n",
      "Ep:51, loss:0.00004, loss_test:0.07089, lr:9.32e-03, fs:0.81761 (r=0.747,p=0.903),  time:42.503, tt:2210.168\n",
      "Ep:52, loss:0.00004, loss_test:0.07068, lr:9.23e-03, fs:0.83333 (r=0.747,p=0.942),  time:42.452, tt:2249.955\n",
      "Ep:53, loss:0.00004, loss_test:0.07288, lr:9.14e-03, fs:0.81529 (r=0.736,p=0.914),  time:42.451, tt:2292.359\n",
      "Ep:54, loss:0.00004, loss_test:0.07100, lr:9.04e-03, fs:0.83660 (r=0.736,p=0.970),  time:42.439, tt:2334.122\n",
      "Ep:55, loss:0.00004, loss_test:0.07407, lr:8.95e-03, fs:0.82051 (r=0.736,p=0.928),  time:42.374, tt:2372.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00004, loss_test:0.07369, lr:8.86e-03, fs:0.81081 (r=0.690,p=0.984),  time:42.319, tt:2412.180\n",
      "Ep:57, loss:0.00004, loss_test:0.06844, lr:8.78e-03, fs:0.83750 (r=0.770,p=0.918),  time:42.282, tt:2452.372\n",
      "Ep:58, loss:0.00004, loss_test:0.07634, lr:8.69e-03, fs:0.79452 (r=0.667,p=0.983),  time:42.282, tt:2494.654\n",
      "Ep:59, loss:0.00003, loss_test:0.07144, lr:8.60e-03, fs:0.86452 (r=0.770,p=0.985),  time:42.243, tt:2534.556\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.07541, lr:8.60e-03, fs:0.81081 (r=0.690,p=0.984),  time:42.206, tt:2574.562\n",
      "Ep:61, loss:0.00003, loss_test:0.07855, lr:8.60e-03, fs:0.82667 (r=0.713,p=0.984),  time:42.213, tt:2617.177\n",
      "Ep:62, loss:0.00003, loss_test:0.07477, lr:8.60e-03, fs:0.84967 (r=0.747,p=0.985),  time:42.200, tt:2658.588\n",
      "Ep:63, loss:0.00003, loss_test:0.07543, lr:8.60e-03, fs:0.83444 (r=0.724,p=0.984),  time:42.191, tt:2700.239\n",
      "Ep:64, loss:0.00003, loss_test:0.07529, lr:8.60e-03, fs:0.84211 (r=0.736,p=0.985),  time:42.167, tt:2740.826\n",
      "Ep:65, loss:0.00003, loss_test:0.07323, lr:8.60e-03, fs:0.85714 (r=0.759,p=0.985),  time:42.181, tt:2783.975\n",
      "Ep:66, loss:0.00003, loss_test:0.07337, lr:8.60e-03, fs:0.85714 (r=0.759,p=0.985),  time:42.172, tt:2825.517\n",
      "Ep:67, loss:0.00002, loss_test:0.07639, lr:8.60e-03, fs:0.83444 (r=0.724,p=0.984),  time:42.180, tt:2868.227\n",
      "Ep:68, loss:0.00002, loss_test:0.07169, lr:8.60e-03, fs:0.87898 (r=0.793,p=0.986),  time:42.185, tt:2910.749\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.07607, lr:8.60e-03, fs:0.84211 (r=0.736,p=0.985),  time:42.213, tt:2954.886\n",
      "Ep:70, loss:0.00002, loss_test:0.07868, lr:8.60e-03, fs:0.84967 (r=0.747,p=0.985),  time:42.225, tt:2998.009\n",
      "Ep:71, loss:0.00002, loss_test:0.07104, lr:8.60e-03, fs:0.88462 (r=0.793,p=1.000),  time:42.252, tt:3042.140\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.08278, lr:8.60e-03, fs:0.77778 (r=0.644,p=0.982),  time:42.232, tt:3082.932\n",
      "Ep:73, loss:0.00002, loss_test:0.07303, lr:8.60e-03, fs:0.85714 (r=0.759,p=0.985),  time:42.237, tt:3125.502\n",
      "Ep:74, loss:0.00002, loss_test:0.07819, lr:8.60e-03, fs:0.84211 (r=0.736,p=0.985),  time:42.242, tt:3168.158\n",
      "Ep:75, loss:0.00002, loss_test:0.07640, lr:8.60e-03, fs:0.85161 (r=0.759,p=0.971),  time:42.269, tt:3212.410\n",
      "Ep:76, loss:0.00002, loss_test:0.07808, lr:8.60e-03, fs:0.84000 (r=0.724,p=1.000),  time:42.264, tt:3254.357\n",
      "Ep:77, loss:0.00002, loss_test:0.07565, lr:8.60e-03, fs:0.85714 (r=0.759,p=0.985),  time:42.278, tt:3297.695\n",
      "Ep:78, loss:0.00002, loss_test:0.07737, lr:8.60e-03, fs:0.80822 (r=0.678,p=1.000),  time:42.323, tt:3343.530\n",
      "Ep:79, loss:0.00002, loss_test:0.07274, lr:8.60e-03, fs:0.88462 (r=0.793,p=1.000),  time:42.346, tt:3387.657\n",
      "Ep:80, loss:0.00002, loss_test:0.08001, lr:8.60e-03, fs:0.83444 (r=0.724,p=0.984),  time:42.369, tt:3431.851\n",
      "Ep:81, loss:0.00001, loss_test:0.07559, lr:8.60e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.406, tt:3477.282\n",
      "Ep:82, loss:0.00001, loss_test:0.07648, lr:8.60e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.417, tt:3520.630\n",
      "Ep:83, loss:0.00001, loss_test:0.07711, lr:8.51e-03, fs:0.84211 (r=0.736,p=0.985),  time:42.397, tt:3561.328\n",
      "Ep:84, loss:0.00001, loss_test:0.07678, lr:8.43e-03, fs:0.82432 (r=0.701,p=1.000),  time:42.417, tt:3605.456\n",
      "Ep:85, loss:0.00001, loss_test:0.08031, lr:8.35e-03, fs:0.80000 (r=0.667,p=1.000),  time:42.420, tt:3648.079\n",
      "Ep:86, loss:0.00001, loss_test:0.07686, lr:8.26e-03, fs:0.85714 (r=0.759,p=0.985),  time:42.450, tt:3693.142\n",
      "Ep:87, loss:0.00001, loss_test:0.08043, lr:8.18e-03, fs:0.76596 (r=0.621,p=1.000),  time:42.462, tt:3736.639\n",
      "Ep:88, loss:0.00001, loss_test:0.07511, lr:8.10e-03, fs:0.85526 (r=0.747,p=1.000),  time:42.477, tt:3780.435\n",
      "Ep:89, loss:0.00001, loss_test:0.08142, lr:8.02e-03, fs:0.76596 (r=0.621,p=1.000),  time:42.486, tt:3823.726\n",
      "Ep:90, loss:0.00001, loss_test:0.07745, lr:7.94e-03, fs:0.83444 (r=0.724,p=0.984),  time:42.482, tt:3865.889\n",
      "Ep:91, loss:0.00001, loss_test:0.07826, lr:7.86e-03, fs:0.78322 (r=0.644,p=1.000),  time:42.476, tt:3907.787\n",
      "Ep:92, loss:0.00001, loss_test:0.08009, lr:7.78e-03, fs:0.79167 (r=0.655,p=1.000),  time:42.469, tt:3949.598\n",
      "Ep:93, loss:0.00001, loss_test:0.07612, lr:7.70e-03, fs:0.84768 (r=0.736,p=1.000),  time:42.481, tt:3993.237\n",
      "Ep:94, loss:0.00001, loss_test:0.08296, lr:7.62e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.472, tt:4034.796\n",
      "Ep:95, loss:0.00001, loss_test:0.07913, lr:7.55e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.465, tt:4076.596\n",
      "Ep:96, loss:0.00001, loss_test:0.08383, lr:7.47e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.437, tt:4116.345\n",
      "Ep:97, loss:0.00001, loss_test:0.08419, lr:7.40e-03, fs:0.72059 (r=0.563,p=1.000),  time:42.438, tt:4158.924\n",
      "Ep:98, loss:0.00001, loss_test:0.08058, lr:7.32e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.426, tt:4200.132\n",
      "Ep:99, loss:0.00001, loss_test:0.08391, lr:7.25e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.396, tt:4239.559\n",
      "Ep:100, loss:0.00001, loss_test:0.08149, lr:7.18e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.362, tt:4278.597\n",
      "Ep:101, loss:0.00001, loss_test:0.08229, lr:7.11e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.357, tt:4320.455\n",
      "Ep:102, loss:0.00001, loss_test:0.07886, lr:7.03e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.347, tt:4361.743\n",
      "Ep:103, loss:0.00001, loss_test:0.08736, lr:6.96e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.340, tt:4403.381\n",
      "Ep:104, loss:0.00001, loss_test:0.07791, lr:6.89e-03, fs:0.75714 (r=0.609,p=1.000),  time:42.324, tt:4443.990\n",
      "Ep:105, loss:0.00001, loss_test:0.08872, lr:6.83e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.304, tt:4484.238\n",
      "Ep:106, loss:0.00001, loss_test:0.07909, lr:6.76e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.289, tt:4524.917\n",
      "Ep:107, loss:0.00001, loss_test:0.08818, lr:6.69e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.288, tt:4567.128\n",
      "Ep:108, loss:0.00001, loss_test:0.09110, lr:6.62e-03, fs:0.68182 (r=0.517,p=1.000),  time:42.263, tt:4606.663\n",
      "Ep:109, loss:0.00001, loss_test:0.08042, lr:6.56e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.273, tt:4650.037\n",
      "Ep:110, loss:0.00001, loss_test:0.08332, lr:6.49e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.260, tt:4690.840\n",
      "Ep:111, loss:0.00001, loss_test:0.08187, lr:6.43e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.227, tt:4729.470\n",
      "Ep:112, loss:0.00001, loss_test:0.08179, lr:6.36e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.203, tt:4768.989\n",
      "Ep:113, loss:0.00001, loss_test:0.08334, lr:6.30e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.186, tt:4809.213\n",
      "Ep:114, loss:0.00001, loss_test:0.08230, lr:6.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.183, tt:4851.016\n",
      "Ep:115, loss:0.00001, loss_test:0.08338, lr:6.17e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.168, tt:4891.445\n",
      "Ep:116, loss:0.00001, loss_test:0.08271, lr:6.11e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.165, tt:4933.308\n",
      "Ep:117, loss:0.00001, loss_test:0.08399, lr:6.05e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.158, tt:4974.679\n",
      "Ep:118, loss:0.00001, loss_test:0.08251, lr:5.99e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.160, tt:5017.094\n",
      "Ep:119, loss:0.00001, loss_test:0.08285, lr:5.93e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.151, tt:5058.089\n",
      "Ep:120, loss:0.00000, loss_test:0.08492, lr:5.87e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.136, tt:5098.457\n",
      "Ep:121, loss:0.00000, loss_test:0.08093, lr:5.81e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.124, tt:5139.091\n",
      "Ep:122, loss:0.00000, loss_test:0.08485, lr:5.75e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.115, tt:5180.149\n",
      "Ep:123, loss:0.00000, loss_test:0.08223, lr:5.70e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.115, tt:5222.236\n",
      "Ep:124, loss:0.00000, loss_test:0.08283, lr:5.64e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.118, tt:5264.735\n",
      "Ep:125, loss:0.00000, loss_test:0.08314, lr:5.58e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.110, tt:5305.846\n",
      "Ep:126, loss:0.00000, loss_test:0.08185, lr:5.53e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.101, tt:5346.844\n",
      "Ep:127, loss:0.00000, loss_test:0.08392, lr:5.47e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.084, tt:5386.722\n",
      "Ep:128, loss:0.00000, loss_test:0.08188, lr:5.42e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.078, tt:5428.053\n",
      "Ep:129, loss:0.00000, loss_test:0.08463, lr:5.36e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.084, tt:5470.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.08326, lr:5.31e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.084, tt:5512.979\n",
      "Ep:131, loss:0.00000, loss_test:0.08140, lr:5.26e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.082, tt:5554.847\n",
      "Ep:132, loss:0.00000, loss_test:0.08511, lr:5.20e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.077, tt:5596.221\n",
      "Ep:133, loss:0.00000, loss_test:0.08322, lr:5.15e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.076, tt:5638.205\n",
      "Ep:134, loss:0.00000, loss_test:0.08359, lr:5.10e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.078, tt:5680.541\n",
      "Ep:135, loss:0.00000, loss_test:0.08351, lr:5.05e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.056, tt:5719.635\n",
      "Ep:136, loss:0.00000, loss_test:0.08286, lr:5.00e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.038, tt:5759.148\n",
      "Ep:137, loss:0.00000, loss_test:0.08468, lr:4.95e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.034, tt:5800.698\n",
      "Ep:138, loss:0.00000, loss_test:0.08215, lr:4.90e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.031, tt:5842.289\n",
      "Ep:139, loss:0.00000, loss_test:0.08381, lr:4.85e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.021, tt:5882.952\n",
      "Ep:140, loss:0.00000, loss_test:0.08220, lr:4.80e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.016, tt:5924.239\n",
      "Ep:141, loss:0.00000, loss_test:0.08449, lr:4.75e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.016, tt:5966.262\n",
      "Ep:142, loss:0.00000, loss_test:0.08497, lr:4.71e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.016, tt:6008.352\n",
      "Ep:143, loss:0.00000, loss_test:0.08142, lr:4.66e-03, fs:0.74820 (r=0.598,p=1.000),  time:42.010, tt:6049.442\n",
      "Ep:144, loss:0.00000, loss_test:0.08575, lr:4.61e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.996, tt:6089.388\n",
      "Ep:145, loss:0.00000, loss_test:0.08637, lr:4.57e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.983, tt:6129.495\n",
      "Ep:146, loss:0.00000, loss_test:0.08314, lr:4.52e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.975, tt:6170.377\n",
      "Ep:147, loss:0.00000, loss_test:0.08312, lr:4.48e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.976, tt:6212.431\n",
      "Ep:148, loss:0.00000, loss_test:0.08496, lr:4.43e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.962, tt:6252.287\n",
      "Ep:149, loss:0.00000, loss_test:0.08352, lr:4.39e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.956, tt:6293.473\n",
      "Ep:150, loss:0.00000, loss_test:0.08404, lr:4.34e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.947, tt:6333.952\n",
      "Ep:151, loss:0.00000, loss_test:0.08423, lr:4.30e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.947, tt:6376.013\n",
      "Ep:152, loss:0.00000, loss_test:0.08368, lr:4.26e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.950, tt:6418.302\n",
      "Ep:153, loss:0.00000, loss_test:0.08347, lr:4.21e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.934, tt:6457.866\n",
      "Ep:154, loss:0.00000, loss_test:0.08386, lr:4.17e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.973, tt:6505.810\n",
      "Ep:155, loss:0.00000, loss_test:0.08386, lr:4.13e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.958, tt:6545.485\n",
      "Ep:156, loss:0.00000, loss_test:0.08448, lr:4.09e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.973, tt:6589.795\n",
      "Ep:157, loss:0.00000, loss_test:0.08505, lr:4.05e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.983, tt:6633.350\n",
      "Ep:158, loss:0.00000, loss_test:0.08327, lr:4.01e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.987, tt:6675.989\n",
      "Ep:159, loss:0.00000, loss_test:0.08340, lr:3.97e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.982, tt:6717.091\n",
      "Ep:160, loss:0.00000, loss_test:0.08411, lr:3.93e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.979, tt:6758.572\n",
      "Ep:161, loss:0.00000, loss_test:0.08324, lr:3.89e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.985, tt:6801.557\n",
      "Ep:162, loss:0.00000, loss_test:0.08335, lr:3.85e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.972, tt:6841.472\n",
      "Ep:163, loss:0.00000, loss_test:0.08402, lr:3.81e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.966, tt:6882.454\n",
      "Ep:164, loss:0.00000, loss_test:0.08378, lr:3.77e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.969, tt:6924.900\n",
      "Ep:165, loss:0.00000, loss_test:0.08328, lr:3.73e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.965, tt:6966.182\n",
      "Ep:166, loss:0.00000, loss_test:0.08482, lr:3.70e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.975, tt:7009.877\n",
      "Ep:167, loss:0.00000, loss_test:0.08476, lr:3.66e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.967, tt:7050.401\n",
      "Ep:168, loss:0.00000, loss_test:0.08350, lr:3.62e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.965, tt:7092.067\n",
      "Ep:169, loss:0.00000, loss_test:0.08520, lr:3.59e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.943, tt:7130.382\n",
      "Ep:170, loss:0.00000, loss_test:0.08549, lr:3.55e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.943, tt:7172.316\n",
      "Ep:171, loss:0.00000, loss_test:0.08374, lr:3.52e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.933, tt:7212.490\n",
      "Ep:172, loss:0.00000, loss_test:0.08421, lr:3.48e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.926, tt:7253.261\n",
      "Ep:173, loss:0.00000, loss_test:0.08472, lr:3.45e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.927, tt:7295.224\n",
      "Ep:174, loss:0.00000, loss_test:0.08425, lr:3.41e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.929, tt:7337.532\n",
      "Ep:175, loss:0.00000, loss_test:0.08373, lr:3.38e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.922, tt:7378.222\n",
      "Ep:176, loss:0.00000, loss_test:0.08447, lr:3.34e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.914, tt:7418.704\n",
      "Ep:177, loss:0.00000, loss_test:0.08380, lr:3.31e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.914, tt:7460.747\n",
      "Ep:178, loss:0.00000, loss_test:0.08382, lr:3.28e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.908, tt:7501.466\n",
      "Ep:179, loss:0.00000, loss_test:0.08488, lr:3.24e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.900, tt:7542.064\n",
      "Ep:180, loss:0.00000, loss_test:0.08512, lr:3.21e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.897, tt:7583.271\n",
      "Ep:181, loss:0.00000, loss_test:0.08406, lr:3.18e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.894, tt:7624.789\n",
      "Ep:182, loss:0.00000, loss_test:0.08421, lr:3.15e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.894, tt:7666.653\n",
      "Ep:183, loss:0.00000, loss_test:0.08476, lr:3.12e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.891, tt:7708.023\n",
      "Ep:184, loss:0.00000, loss_test:0.08413, lr:3.09e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.883, tt:7748.274\n",
      "Ep:185, loss:0.00000, loss_test:0.08322, lr:3.05e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.870, tt:7787.769\n",
      "Ep:186, loss:0.00000, loss_test:0.08516, lr:3.02e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.862, tt:7828.244\n",
      "Ep:187, loss:0.00000, loss_test:0.08591, lr:2.99e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.848, tt:7867.403\n",
      "Ep:188, loss:0.00000, loss_test:0.08466, lr:2.96e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.841, tt:7907.955\n",
      "Ep:189, loss:0.00000, loss_test:0.08352, lr:2.93e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.839, tt:7949.410\n",
      "Ep:190, loss:0.00000, loss_test:0.08532, lr:2.90e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.840, tt:7991.480\n",
      "Ep:191, loss:0.00000, loss_test:0.08556, lr:2.88e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.831, tt:8031.495\n",
      "Ep:192, loss:0.00000, loss_test:0.08449, lr:2.85e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.826, tt:8072.393\n",
      "Ep:193, loss:0.00000, loss_test:0.08459, lr:2.82e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.808, tt:8110.660\n",
      "Ep:194, loss:0.00000, loss_test:0.08530, lr:2.79e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.802, tt:8151.332\n",
      "Ep:195, loss:0.00000, loss_test:0.08473, lr:2.76e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.788, tt:8190.481\n",
      "Ep:196, loss:0.00000, loss_test:0.08431, lr:2.73e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.774, tt:8229.547\n",
      "Ep:197, loss:0.00000, loss_test:0.08458, lr:2.71e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.773, tt:8270.995\n",
      "Ep:198, loss:0.00000, loss_test:0.08404, lr:2.68e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.769, tt:8312.083\n",
      "Ep:199, loss:0.00000, loss_test:0.08422, lr:2.65e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.769, tt:8353.805\n",
      "Ep:200, loss:0.00000, loss_test:0.08443, lr:2.63e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.761, tt:8394.005\n",
      "Ep:201, loss:0.00000, loss_test:0.08420, lr:2.60e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.759, tt:8435.369\n",
      "Ep:202, loss:0.00000, loss_test:0.08448, lr:2.57e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.736, tt:8472.440\n",
      "Ep:203, loss:0.00000, loss_test:0.08402, lr:2.55e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.734, tt:8513.784\n",
      "Ep:204, loss:0.00000, loss_test:0.08483, lr:2.52e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.724, tt:8553.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.08464, lr:2.50e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.710, tt:8592.336\n",
      "Ep:206, loss:0.00000, loss_test:0.08427, lr:2.47e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.707, tt:8633.283\n",
      "Ep:207, loss:0.00000, loss_test:0.08435, lr:2.45e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.711, tt:8675.806\n",
      "Ep:208, loss:0.00000, loss_test:0.08456, lr:2.42e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.700, tt:8715.204\n",
      "Ep:209, loss:0.00000, loss_test:0.08459, lr:2.40e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.705, tt:8758.030\n",
      "Ep:210, loss:0.00000, loss_test:0.08459, lr:2.38e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.709, tt:8800.518\n",
      "Ep:211, loss:0.00000, loss_test:0.08431, lr:2.35e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.718, tt:8844.124\n",
      "Ep:212, loss:0.00000, loss_test:0.08487, lr:2.33e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.725, tt:8887.347\n",
      "Ep:213, loss:0.00000, loss_test:0.08528, lr:2.31e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.707, tt:8925.398\n",
      "Ep:214, loss:0.00000, loss_test:0.08465, lr:2.28e-03, fs:0.74820 (r=0.598,p=1.000),  time:41.657, tt:8956.294\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02067, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:27.076, tt:27.076\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02353, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.709, tt:59.419\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02440, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.282, tt:99.846\n",
      "Ep:3, loss:0.00005, loss_test:0.02387, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.251, tt:141.004\n",
      "Ep:4, loss:0.00004, loss_test:0.02261, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:36.661, tt:183.307\n",
      "Ep:5, loss:0.00004, loss_test:0.02127, lr:6.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:37.451, tt:224.707\n",
      "Ep:6, loss:0.00004, loss_test:0.02059, lr:6.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:38.205, tt:267.437\n",
      "Ep:7, loss:0.00004, loss_test:0.02006, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:38.532, tt:308.257\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:38.677, tt:348.089\n",
      "Ep:9, loss:0.00004, loss_test:0.01808, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:38.731, tt:387.308\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01765, lr:6.00e-02, fs:0.72031 (r=0.949,p=0.580),  time:38.894, tt:427.831\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01726, lr:6.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:39.025, tt:468.300\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01694, lr:6.00e-02, fs:0.72587 (r=0.949,p=0.588),  time:39.140, tt:508.816\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.74400 (r=0.939,p=0.616),  time:39.268, tt:549.752\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:39.410, tt:591.142\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:39.462, tt:631.396\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:39.555, tt:672.432\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:39.658, tt:713.837\n",
      "Ep:18, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:39.699, tt:754.280\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01542, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:39.762, tt:795.231\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01531, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:39.861, tt:837.083\n",
      "Ep:21, loss:0.00003, loss_test:0.01525, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:39.891, tt:877.591\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01513, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:39.912, tt:917.975\n",
      "Ep:23, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:39.995, tt:959.879\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:39.939, tt:998.484\n",
      "Ep:25, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:39.881, tt:1036.904\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:39.883, tt:1076.843\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:39.844, tt:1115.629\n",
      "Ep:28, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:39.983, tt:1159.496\n",
      "Ep:29, loss:0.00002, loss_test:0.01421, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:39.977, tt:1199.322\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.82700 (r=0.990,p=0.710),  time:39.987, tt:1239.589\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:39.981, tt:1279.398\n",
      "Ep:32, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:40.020, tt:1320.661\n",
      "Ep:33, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:40.048, tt:1361.623\n",
      "Ep:34, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:40.046, tt:1401.619\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:40.067, tt:1442.406\n",
      "Ep:36, loss:0.00002, loss_test:0.01341, lr:6.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:40.098, tt:1483.619\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:40.142, tt:1525.410\n",
      "Ep:38, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:40.175, tt:1566.836\n",
      "Ep:39, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:40.212, tt:1608.484\n",
      "Ep:40, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:40.260, tt:1650.655\n",
      "Ep:41, loss:0.00002, loss_test:0.01297, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:40.310, tt:1693.000\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:40.309, tt:1733.269\n",
      "Ep:43, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:40.345, tt:1775.188\n",
      "Ep:44, loss:0.00001, loss_test:0.01285, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:40.382, tt:1817.175\n",
      "Ep:45, loss:0.00001, loss_test:0.01280, lr:6.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:40.395, tt:1858.187\n",
      "Ep:46, loss:0.00001, loss_test:0.01282, lr:6.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:40.414, tt:1899.481\n",
      "Ep:47, loss:0.00001, loss_test:0.01276, lr:6.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:40.362, tt:1937.392\n",
      "Ep:48, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:40.416, tt:1980.405\n",
      "Ep:49, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:40.452, tt:2022.595\n",
      "Ep:50, loss:0.00001, loss_test:0.01269, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:40.435, tt:2062.168\n",
      "Ep:51, loss:0.00001, loss_test:0.01262, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:40.449, tt:2103.372\n",
      "Ep:52, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.476, tt:2145.214\n",
      "Ep:53, loss:0.00001, loss_test:0.01265, lr:5.94e-02, fs:0.80751 (r=0.869,p=0.754),  time:40.485, tt:2186.177\n",
      "Ep:54, loss:0.00001, loss_test:0.01255, lr:5.88e-02, fs:0.80751 (r=0.869,p=0.754),  time:40.527, tt:2228.969\n",
      "Ep:55, loss:0.00001, loss_test:0.01251, lr:5.82e-02, fs:0.81517 (r=0.869,p=0.768),  time:40.537, tt:2270.075\n",
      "Ep:56, loss:0.00001, loss_test:0.01261, lr:5.76e-02, fs:0.81517 (r=0.869,p=0.768),  time:40.536, tt:2310.541\n",
      "Ep:57, loss:0.00001, loss_test:0.01256, lr:5.71e-02, fs:0.81905 (r=0.869,p=0.775),  time:40.550, tt:2351.880\n",
      "Ep:58, loss:0.00001, loss_test:0.01260, lr:5.65e-02, fs:0.81340 (r=0.859,p=0.773),  time:40.598, tt:2395.283\n",
      "Ep:59, loss:0.00001, loss_test:0.01260, lr:5.59e-02, fs:0.81905 (r=0.869,p=0.775),  time:40.623, tt:2437.351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01254, lr:5.54e-02, fs:0.81340 (r=0.859,p=0.773),  time:40.639, tt:2478.987\n",
      "Ep:61, loss:0.00001, loss_test:0.01261, lr:5.48e-02, fs:0.81553 (r=0.848,p=0.785),  time:40.697, tt:2523.207\n",
      "Ep:62, loss:0.00001, loss_test:0.01263, lr:5.43e-02, fs:0.81553 (r=0.848,p=0.785),  time:40.680, tt:2562.812\n",
      "Ep:63, loss:0.00001, loss_test:0.01261, lr:5.37e-02, fs:0.81553 (r=0.848,p=0.785),  time:40.720, tt:2606.075\n",
      "Ep:64, loss:0.00001, loss_test:0.01260, lr:5.32e-02, fs:0.81553 (r=0.848,p=0.785),  time:40.702, tt:2645.605\n",
      "Ep:65, loss:0.00001, loss_test:0.01268, lr:5.27e-02, fs:0.82353 (r=0.848,p=0.800),  time:40.708, tt:2686.739\n",
      "Ep:66, loss:0.00001, loss_test:0.01268, lr:5.21e-02, fs:0.82353 (r=0.848,p=0.800),  time:40.702, tt:2727.022\n",
      "Ep:67, loss:0.00001, loss_test:0.01265, lr:5.16e-02, fs:0.82353 (r=0.848,p=0.800),  time:40.718, tt:2768.834\n",
      "Ep:68, loss:0.00001, loss_test:0.01274, lr:5.11e-02, fs:0.82412 (r=0.828,p=0.820),  time:40.745, tt:2811.437\n",
      "Ep:69, loss:0.00001, loss_test:0.01273, lr:5.06e-02, fs:0.82412 (r=0.828,p=0.820),  time:40.778, tt:2854.428\n",
      "Ep:70, loss:0.00001, loss_test:0.01279, lr:5.01e-02, fs:0.81818 (r=0.818,p=0.818),  time:40.812, tt:2897.630\n",
      "Ep:71, loss:0.00001, loss_test:0.01281, lr:4.96e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.811, tt:2938.368\n",
      "Ep:72, loss:0.00001, loss_test:0.01283, lr:4.91e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.807, tt:2978.940\n",
      "Ep:73, loss:0.00001, loss_test:0.01286, lr:4.86e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.802, tt:3019.316\n",
      "Ep:74, loss:0.00001, loss_test:0.01294, lr:4.81e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.859, tt:3064.408\n",
      "Ep:75, loss:0.00001, loss_test:0.01291, lr:4.76e-02, fs:0.78756 (r=0.768,p=0.809),  time:40.844, tt:3104.110\n",
      "Ep:76, loss:0.00001, loss_test:0.01302, lr:4.71e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.818, tt:3143.002\n",
      "Ep:77, loss:0.00001, loss_test:0.01298, lr:4.67e-02, fs:0.78756 (r=0.768,p=0.809),  time:40.814, tt:3183.464\n",
      "Ep:78, loss:0.00001, loss_test:0.01304, lr:4.62e-02, fs:0.79167 (r=0.768,p=0.817),  time:40.793, tt:3222.678\n",
      "Ep:79, loss:0.00001, loss_test:0.01311, lr:4.57e-02, fs:0.77895 (r=0.747,p=0.813),  time:40.777, tt:3262.170\n",
      "Ep:80, loss:0.00001, loss_test:0.01311, lr:4.53e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.780, tt:3303.207\n",
      "Ep:81, loss:0.00001, loss_test:0.01320, lr:4.48e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.754, tt:3341.858\n",
      "Ep:82, loss:0.00001, loss_test:0.01316, lr:4.44e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.748, tt:3382.122\n",
      "Ep:83, loss:0.00001, loss_test:0.01323, lr:4.39e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.739, tt:3422.034\n",
      "Ep:84, loss:0.00001, loss_test:0.01326, lr:4.35e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.697, tt:3459.241\n",
      "Ep:85, loss:0.00001, loss_test:0.01327, lr:4.31e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.679, tt:3498.395\n",
      "Ep:86, loss:0.00001, loss_test:0.01338, lr:4.26e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.682, tt:3539.298\n",
      "Ep:87, loss:0.00001, loss_test:0.01333, lr:4.22e-02, fs:0.77249 (r=0.737,p=0.811),  time:40.673, tt:3579.252\n",
      "Ep:88, loss:0.00001, loss_test:0.01347, lr:4.18e-02, fs:0.77660 (r=0.737,p=0.820),  time:40.666, tt:3619.252\n",
      "Ep:89, loss:0.00001, loss_test:0.01350, lr:4.14e-02, fs:0.78075 (r=0.737,p=0.830),  time:40.665, tt:3659.880\n",
      "Ep:90, loss:0.00001, loss_test:0.01351, lr:4.10e-02, fs:0.77660 (r=0.737,p=0.820),  time:40.655, tt:3699.631\n",
      "Ep:91, loss:0.00001, loss_test:0.01360, lr:4.05e-02, fs:0.78075 (r=0.737,p=0.830),  time:40.639, tt:3738.746\n",
      "Ep:92, loss:0.00001, loss_test:0.01352, lr:4.01e-02, fs:0.77660 (r=0.737,p=0.820),  time:40.620, tt:3777.653\n",
      "Ep:93, loss:0.00001, loss_test:0.01371, lr:3.97e-02, fs:0.76503 (r=0.707,p=0.833),  time:40.639, tt:3820.044\n",
      "Ep:94, loss:0.00001, loss_test:0.01362, lr:3.93e-02, fs:0.76503 (r=0.707,p=0.833),  time:40.645, tt:3861.260\n",
      "Ep:95, loss:0.00001, loss_test:0.01376, lr:3.89e-02, fs:0.76503 (r=0.707,p=0.833),  time:40.679, tt:3905.175\n",
      "Ep:96, loss:0.00001, loss_test:0.01381, lr:3.86e-02, fs:0.76503 (r=0.707,p=0.833),  time:40.680, tt:3945.933\n",
      "Ep:97, loss:0.00001, loss_test:0.01381, lr:3.82e-02, fs:0.75138 (r=0.687,p=0.829),  time:40.673, tt:3985.940\n",
      "Ep:98, loss:0.00001, loss_test:0.01385, lr:3.78e-02, fs:0.75138 (r=0.687,p=0.829),  time:40.663, tt:4025.599\n",
      "Ep:99, loss:0.00001, loss_test:0.01383, lr:3.74e-02, fs:0.75138 (r=0.687,p=0.829),  time:40.660, tt:4065.962\n",
      "Ep:100, loss:0.00001, loss_test:0.01398, lr:3.70e-02, fs:0.75556 (r=0.687,p=0.840),  time:40.648, tt:4105.496\n",
      "Ep:101, loss:0.00001, loss_test:0.01394, lr:3.67e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.631, tt:4144.391\n",
      "Ep:102, loss:0.00001, loss_test:0.01407, lr:3.63e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.615, tt:4183.310\n",
      "Ep:103, loss:0.00001, loss_test:0.01415, lr:3.59e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.595, tt:4221.892\n",
      "Ep:104, loss:0.00001, loss_test:0.01401, lr:3.56e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.582, tt:4261.143\n",
      "Ep:105, loss:0.00001, loss_test:0.01423, lr:3.52e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.571, tt:4300.498\n",
      "Ep:106, loss:0.00001, loss_test:0.01419, lr:3.49e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.555, tt:4339.374\n",
      "Ep:107, loss:0.00001, loss_test:0.01419, lr:3.45e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.570, tt:4381.583\n",
      "Ep:108, loss:0.00001, loss_test:0.01427, lr:3.42e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.579, tt:4423.090\n",
      "Ep:109, loss:0.00001, loss_test:0.01428, lr:3.38e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.551, tt:4460.591\n",
      "Ep:110, loss:0.00001, loss_test:0.01437, lr:3.35e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.554, tt:4501.550\n",
      "Ep:111, loss:0.00001, loss_test:0.01437, lr:3.32e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.553, tt:4541.941\n",
      "Ep:112, loss:0.00000, loss_test:0.01444, lr:3.28e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.545, tt:4581.628\n",
      "Ep:113, loss:0.00000, loss_test:0.01445, lr:3.25e-02, fs:0.74860 (r=0.677,p=0.838),  time:40.524, tt:4619.692\n",
      "Ep:114, loss:0.00000, loss_test:0.01453, lr:3.22e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.507, tt:4658.251\n",
      "Ep:115, loss:0.00000, loss_test:0.01452, lr:3.19e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.495, tt:4697.377\n",
      "Ep:116, loss:0.00000, loss_test:0.01458, lr:3.15e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.497, tt:4738.152\n",
      "Ep:117, loss:0.00000, loss_test:0.01473, lr:3.12e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.485, tt:4777.267\n",
      "Ep:118, loss:0.00000, loss_test:0.01464, lr:3.09e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.487, tt:4817.980\n",
      "Ep:119, loss:0.00000, loss_test:0.01475, lr:3.06e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.497, tt:4859.591\n",
      "Ep:120, loss:0.00000, loss_test:0.01480, lr:3.03e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.498, tt:4900.249\n",
      "Ep:121, loss:0.00000, loss_test:0.01477, lr:3.00e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.481, tt:4938.728\n",
      "Ep:122, loss:0.00000, loss_test:0.01479, lr:2.97e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.476, tt:4978.511\n",
      "Ep:123, loss:0.00000, loss_test:0.01492, lr:2.94e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.476, tt:5018.973\n",
      "Ep:124, loss:0.00000, loss_test:0.01487, lr:2.91e-02, fs:0.75281 (r=0.677,p=0.848),  time:40.469, tt:5058.683\n",
      "Ep:125, loss:0.00000, loss_test:0.01491, lr:2.88e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.462, tt:5098.247\n",
      "Ep:126, loss:0.00000, loss_test:0.01497, lr:2.85e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.448, tt:5136.955\n",
      "Ep:127, loss:0.00000, loss_test:0.01499, lr:2.82e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.431, tt:5175.211\n",
      "Ep:128, loss:0.00000, loss_test:0.01507, lr:2.80e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.448, tt:5217.837\n",
      "Ep:129, loss:0.00000, loss_test:0.01513, lr:2.77e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.455, tt:5259.166\n",
      "Ep:130, loss:0.00000, loss_test:0.01509, lr:2.74e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.435, tt:5297.038\n",
      "Ep:131, loss:0.00000, loss_test:0.01523, lr:2.71e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.390, tt:5331.470\n",
      "Ep:132, loss:0.00000, loss_test:0.01519, lr:2.69e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.381, tt:5370.641\n",
      "Ep:133, loss:0.00000, loss_test:0.01526, lr:2.66e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.385, tt:5411.652\n",
      "Ep:134, loss:0.00000, loss_test:0.01528, lr:2.63e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.386, tt:5452.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.01530, lr:2.61e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.387, tt:5492.615\n",
      "Ep:136, loss:0.00000, loss_test:0.01541, lr:2.58e-02, fs:0.74576 (r=0.667,p=0.846),  time:40.364, tt:5529.819\n",
      "Ep:137, loss:0.00000, loss_test:0.01536, lr:2.55e-02, fs:0.75000 (r=0.667,p=0.857),  time:40.357, tt:5569.202\n",
      "Ep:138, loss:0.00000, loss_test:0.01545, lr:2.53e-02, fs:0.75000 (r=0.667,p=0.857),  time:40.354, tt:5609.189\n",
      "Ep:139, loss:0.00000, loss_test:0.01550, lr:2.50e-02, fs:0.75000 (r=0.667,p=0.857),  time:40.339, tt:5647.405\n",
      "Ep:140, loss:0.00000, loss_test:0.01551, lr:2.48e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.332, tt:5686.761\n",
      "Ep:141, loss:0.00000, loss_test:0.01554, lr:2.45e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.338, tt:5727.989\n",
      "Ep:142, loss:0.00000, loss_test:0.01558, lr:2.43e-02, fs:0.75000 (r=0.667,p=0.857),  time:40.327, tt:5766.730\n",
      "Ep:143, loss:0.00000, loss_test:0.01556, lr:2.40e-02, fs:0.75000 (r=0.667,p=0.857),  time:40.324, tt:5806.634\n",
      "Ep:144, loss:0.00000, loss_test:0.01563, lr:2.38e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.319, tt:5846.301\n",
      "Ep:145, loss:0.00000, loss_test:0.01566, lr:2.36e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.354, tt:5891.749\n",
      "Ep:146, loss:0.00000, loss_test:0.01570, lr:2.33e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.359, tt:5932.748\n",
      "Ep:147, loss:0.00000, loss_test:0.01569, lr:2.31e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.361, tt:5973.380\n",
      "Ep:148, loss:0.00000, loss_test:0.01574, lr:2.29e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.355, tt:6012.901\n",
      "Ep:149, loss:0.00000, loss_test:0.01581, lr:2.26e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.360, tt:6054.008\n",
      "Ep:150, loss:0.00000, loss_test:0.01581, lr:2.24e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.356, tt:6093.807\n",
      "Ep:151, loss:0.00000, loss_test:0.01584, lr:2.22e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.360, tt:6134.742\n",
      "Ep:152, loss:0.00000, loss_test:0.01592, lr:2.20e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.364, tt:6175.741\n",
      "Ep:153, loss:0.00000, loss_test:0.01589, lr:2.17e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.353, tt:6214.430\n",
      "Ep:154, loss:0.00000, loss_test:0.01592, lr:2.15e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.351, tt:6254.464\n",
      "Ep:155, loss:0.00000, loss_test:0.01601, lr:2.13e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.352, tt:6294.917\n",
      "Ep:156, loss:0.00000, loss_test:0.01600, lr:2.11e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.358, tt:6336.195\n",
      "Ep:157, loss:0.00000, loss_test:0.01602, lr:2.09e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.353, tt:6375.827\n",
      "Ep:158, loss:0.00000, loss_test:0.01603, lr:2.07e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.371, tt:6419.054\n",
      "Ep:159, loss:0.00000, loss_test:0.01614, lr:2.05e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.379, tt:6460.653\n",
      "Ep:160, loss:0.00000, loss_test:0.01614, lr:2.03e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.373, tt:6500.090\n",
      "Ep:161, loss:0.00000, loss_test:0.01608, lr:2.01e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.367, tt:6539.378\n",
      "Ep:162, loss:0.00000, loss_test:0.01620, lr:1.99e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.376, tt:6581.361\n",
      "Ep:163, loss:0.00000, loss_test:0.01622, lr:1.97e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.379, tt:6622.184\n",
      "Ep:164, loss:0.00000, loss_test:0.01618, lr:1.95e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.385, tt:6663.604\n",
      "Ep:165, loss:0.00000, loss_test:0.01625, lr:1.93e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.385, tt:6703.892\n",
      "Ep:166, loss:0.00000, loss_test:0.01631, lr:1.91e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.384, tt:6744.167\n",
      "Ep:167, loss:0.00000, loss_test:0.01623, lr:1.89e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.388, tt:6785.177\n",
      "Ep:168, loss:0.00000, loss_test:0.01630, lr:1.87e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.384, tt:6824.913\n",
      "Ep:169, loss:0.00000, loss_test:0.01639, lr:1.85e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.379, tt:6864.433\n",
      "Ep:170, loss:0.00000, loss_test:0.01635, lr:1.83e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.379, tt:6904.887\n",
      "Ep:171, loss:0.00000, loss_test:0.01636, lr:1.81e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.391, tt:6947.319\n",
      "Ep:172, loss:0.00000, loss_test:0.01647, lr:1.80e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.399, tt:6988.987\n",
      "Ep:173, loss:0.00000, loss_test:0.01640, lr:1.78e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.404, tt:7030.246\n",
      "Ep:174, loss:0.00000, loss_test:0.01643, lr:1.76e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.405, tt:7070.837\n",
      "Ep:175, loss:0.00000, loss_test:0.01656, lr:1.74e-02, fs:0.75429 (r=0.667,p=0.868),  time:40.399, tt:7110.145\n",
      "Ep:176, loss:0.00000, loss_test:0.01652, lr:1.73e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.405, tt:7151.637\n",
      "Ep:177, loss:0.00000, loss_test:0.01652, lr:1.71e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.395, tt:7190.386\n",
      "Ep:178, loss:0.00000, loss_test:0.01657, lr:1.69e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.396, tt:7230.813\n",
      "Ep:179, loss:0.00000, loss_test:0.01658, lr:1.67e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.437, tt:7278.695\n",
      "Ep:180, loss:0.00000, loss_test:0.01660, lr:1.66e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.447, tt:7320.829\n",
      "Ep:181, loss:0.00000, loss_test:0.01662, lr:1.64e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.449, tt:7361.711\n",
      "Ep:182, loss:0.00000, loss_test:0.01663, lr:1.62e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.447, tt:7401.763\n",
      "Ep:183, loss:0.00000, loss_test:0.01667, lr:1.61e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.453, tt:7443.329\n",
      "Ep:184, loss:0.00000, loss_test:0.01669, lr:1.59e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.439, tt:7481.229\n",
      "Ep:185, loss:0.00000, loss_test:0.01669, lr:1.58e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.442, tt:7522.278\n",
      "Ep:186, loss:0.00000, loss_test:0.01676, lr:1.56e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.449, tt:7564.020\n",
      "Ep:187, loss:0.00000, loss_test:0.01679, lr:1.54e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.444, tt:7603.450\n",
      "Ep:188, loss:0.00000, loss_test:0.01673, lr:1.53e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.439, tt:7642.992\n",
      "Ep:189, loss:0.00000, loss_test:0.01681, lr:1.51e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.440, tt:7683.583\n",
      "Ep:190, loss:0.00000, loss_test:0.01685, lr:1.50e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.439, tt:7723.781\n",
      "Ep:191, loss:0.00000, loss_test:0.01680, lr:1.48e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.438, tt:7764.006\n",
      "Ep:192, loss:0.00000, loss_test:0.01686, lr:1.47e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.427, tt:7802.368\n",
      "Ep:193, loss:0.00000, loss_test:0.01688, lr:1.45e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.430, tt:7843.342\n",
      "Ep:194, loss:0.00000, loss_test:0.01684, lr:1.44e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.426, tt:7882.974\n",
      "Ep:195, loss:0.00000, loss_test:0.01691, lr:1.43e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.421, tt:7922.601\n",
      "Ep:196, loss:0.00000, loss_test:0.01693, lr:1.41e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.420, tt:7962.803\n",
      "Ep:197, loss:0.00000, loss_test:0.01693, lr:1.40e-02, fs:0.75862 (r=0.667,p=0.880),  time:40.421, tt:8003.378\n",
      "Ep:198, loss:0.00000, loss_test:0.01697, lr:1.38e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.422, tt:8043.896\n",
      "Ep:199, loss:0.00000, loss_test:0.01700, lr:1.37e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.409, tt:8081.790\n",
      "Ep:200, loss:0.00000, loss_test:0.01698, lr:1.36e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.403, tt:8120.929\n",
      "Ep:201, loss:0.00000, loss_test:0.01700, lr:1.34e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.412, tt:8163.320\n",
      "Ep:202, loss:0.00000, loss_test:0.01705, lr:1.33e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.408, tt:8202.918\n",
      "Ep:203, loss:0.00000, loss_test:0.01704, lr:1.32e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.391, tt:8239.811\n",
      "Ep:204, loss:0.00000, loss_test:0.01704, lr:1.30e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.394, tt:8280.714\n",
      "Ep:205, loss:0.00000, loss_test:0.01709, lr:1.29e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.398, tt:8321.900\n",
      "Ep:206, loss:0.00000, loss_test:0.01711, lr:1.28e-02, fs:0.76301 (r=0.667,p=0.892),  time:40.398, tt:8362.440\n",
      "Ep:207, loss:0.00000, loss_test:0.01709, lr:1.26e-02, fs:0.76744 (r=0.667,p=0.904),  time:40.400, tt:8403.104\n",
      "Ep:208, loss:0.00000, loss_test:0.01713, lr:1.25e-02, fs:0.76744 (r=0.667,p=0.904),  time:40.392, tt:8441.979\n",
      "Ep:209, loss:0.00000, loss_test:0.01719, lr:1.24e-02, fs:0.76744 (r=0.667,p=0.904),  time:40.378, tt:8479.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.01713, lr:1.23e-02, fs:0.76744 (r=0.667,p=0.904),  time:40.361, tt:8516.065\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14232, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.580, tt:37.580\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14039, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:34.072, tt:68.144\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13683, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:35.726, tt:107.177\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13202, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:37.201, tt:148.804\n",
      "Ep:4, loss:0.00025, loss_test:0.12648, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:37.835, tt:189.176\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11872, lr:1.00e-02, fs:0.67826 (r=0.788,p=0.595),  time:38.293, tt:229.757\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.11349, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:38.752, tt:271.261\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11254, lr:1.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:38.830, tt:310.640\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.11125, lr:1.00e-02, fs:0.69912 (r=0.798,p=0.622),  time:39.133, tt:352.200\n",
      "Ep:9, loss:0.00020, loss_test:0.11039, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:39.368, tt:393.678\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10543, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:39.524, tt:434.768\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10153, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:39.663, tt:475.954\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10050, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:39.734, tt:516.538\n",
      "Ep:13, loss:0.00017, loss_test:0.09698, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:39.690, tt:555.662\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09354, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:39.909, tt:598.630\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09296, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:40.017, tt:640.266\n",
      "Ep:16, loss:0.00015, loss_test:0.09080, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.109, tt:681.857\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08704, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:40.124, tt:722.224\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08745, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:40.242, tt:764.603\n",
      "Ep:19, loss:0.00014, loss_test:0.08351, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:40.402, tt:808.044\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08518, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:40.456, tt:849.567\n",
      "Ep:21, loss:0.00013, loss_test:0.08309, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:40.517, tt:891.366\n",
      "Ep:22, loss:0.00012, loss_test:0.07882, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:40.550, tt:932.657\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08221, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:40.602, tt:974.450\n",
      "Ep:24, loss:0.00011, loss_test:0.07627, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:40.654, tt:1016.342\n",
      "Ep:25, loss:0.00011, loss_test:0.07779, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:40.683, tt:1057.749\n",
      "Ep:26, loss:0.00010, loss_test:0.07721, lr:1.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:40.797, tt:1101.506\n",
      "Ep:27, loss:0.00011, loss_test:0.07422, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:40.832, tt:1143.284\n",
      "Ep:28, loss:0.00010, loss_test:0.07761, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:40.840, tt:1184.351\n",
      "Ep:29, loss:0.00009, loss_test:0.07154, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:40.860, tt:1225.814\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.07234, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:40.849, tt:1266.326\n",
      "Ep:31, loss:0.00008, loss_test:0.07017, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:40.910, tt:1309.125\n",
      "Ep:32, loss:0.00008, loss_test:0.07176, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:40.966, tt:1351.876\n",
      "Ep:33, loss:0.00008, loss_test:0.06648, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:40.993, tt:1393.771\n",
      "Ep:34, loss:0.00007, loss_test:0.06897, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:41.070, tt:1437.464\n",
      "Ep:35, loss:0.00007, loss_test:0.06512, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.124, tt:1480.460\n",
      "Ep:36, loss:0.00007, loss_test:0.06729, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:41.191, tt:1524.067\n",
      "Ep:37, loss:0.00007, loss_test:0.06519, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:41.187, tt:1565.091\n",
      "Ep:38, loss:0.00006, loss_test:0.06621, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:41.144, tt:1604.615\n",
      "Ep:39, loss:0.00006, loss_test:0.06321, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.140, tt:1645.598\n",
      "Ep:40, loss:0.00006, loss_test:0.06367, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:41.176, tt:1688.201\n",
      "Ep:41, loss:0.00006, loss_test:0.06319, lr:9.90e-03, fs:0.84043 (r=0.798,p=0.888),  time:41.186, tt:1729.806\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06335, lr:9.90e-03, fs:0.82162 (r=0.768,p=0.884),  time:41.153, tt:1769.598\n",
      "Ep:43, loss:0.00005, loss_test:0.06282, lr:9.90e-03, fs:0.83696 (r=0.778,p=0.906),  time:41.168, tt:1811.382\n",
      "Ep:44, loss:0.00005, loss_test:0.06351, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:41.160, tt:1852.202\n",
      "Ep:45, loss:0.00005, loss_test:0.06059, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:41.118, tt:1891.428\n",
      "Ep:46, loss:0.00004, loss_test:0.06726, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:41.159, tt:1934.450\n",
      "Ep:47, loss:0.00004, loss_test:0.05943, lr:9.90e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.156, tt:1975.473\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00004, loss_test:0.06595, lr:9.90e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.196, tt:2018.616\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.06242, lr:9.90e-03, fs:0.83871 (r=0.788,p=0.897),  time:41.166, tt:2058.311\n",
      "Ep:50, loss:0.00004, loss_test:0.06354, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.169, tt:2099.611\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.05978, lr:9.90e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.158, tt:2140.197\n",
      "Ep:52, loss:0.00004, loss_test:0.06222, lr:9.90e-03, fs:0.84615 (r=0.778,p=0.928),  time:41.136, tt:2180.196\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.06282, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.149, tt:2222.050\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.06247, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.157, tt:2263.621\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.05689, lr:9.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:41.142, tt:2303.939\n",
      "Ep:56, loss:0.00003, loss_test:0.06701, lr:9.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.133, tt:2344.593\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.05797, lr:9.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:41.174, tt:2388.068\n",
      "Ep:58, loss:0.00003, loss_test:0.06426, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.205, tt:2431.075\n",
      "Ep:59, loss:0.00003, loss_test:0.06167, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.231, tt:2473.874\n",
      "Ep:60, loss:0.00003, loss_test:0.05814, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.197, tt:2513.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00002, loss_test:0.06285, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.195, tt:2554.114\n",
      "Ep:62, loss:0.00002, loss_test:0.05804, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.277, tt:2600.449\n",
      "Ep:63, loss:0.00002, loss_test:0.06276, lr:9.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.284, tt:2642.162\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.05886, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.254, tt:2681.516\n",
      "Ep:65, loss:0.00002, loss_test:0.05951, lr:9.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.230, tt:2721.150\n",
      "Ep:66, loss:0.00002, loss_test:0.05733, lr:9.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.199, tt:2760.353\n",
      "Ep:67, loss:0.00002, loss_test:0.06096, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.196, tt:2801.356\n",
      "Ep:68, loss:0.00002, loss_test:0.05885, lr:9.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.196, tt:2842.495\n",
      "Ep:69, loss:0.00002, loss_test:0.05793, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.160, tt:2881.190\n",
      "Ep:70, loss:0.00001, loss_test:0.06104, lr:9.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.119, tt:2919.468\n",
      "Ep:71, loss:0.00001, loss_test:0.05851, lr:9.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.133, tt:2961.543\n",
      "Ep:72, loss:0.00001, loss_test:0.05894, lr:9.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.128, tt:3002.335\n",
      "Ep:73, loss:0.00001, loss_test:0.05942, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.131, tt:3043.658\n",
      "Ep:74, loss:0.00001, loss_test:0.05880, lr:9.90e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.113, tt:3083.446\n",
      "Ep:75, loss:0.00001, loss_test:0.05671, lr:9.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.130, tt:3125.885\n",
      "Ep:76, loss:0.00001, loss_test:0.06134, lr:9.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.153, tt:3168.760\n",
      "Ep:77, loss:0.00001, loss_test:0.05847, lr:9.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.155, tt:3210.098\n",
      "Ep:78, loss:0.00001, loss_test:0.05746, lr:9.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.170, tt:3252.456\n",
      "Ep:79, loss:0.00001, loss_test:0.05513, lr:9.41e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.179, tt:3294.360\n",
      "Ep:80, loss:0.00001, loss_test:0.05932, lr:9.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.169, tt:3334.714\n",
      "Ep:81, loss:0.00001, loss_test:0.05816, lr:9.23e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.161, tt:3375.233\n",
      "Ep:82, loss:0.00001, loss_test:0.05889, lr:9.14e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.170, tt:3417.077\n",
      "Ep:83, loss:0.00001, loss_test:0.05825, lr:9.04e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.164, tt:3457.735\n",
      "Ep:84, loss:0.00001, loss_test:0.05738, lr:8.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.175, tt:3499.843\n",
      "Ep:85, loss:0.00001, loss_test:0.06006, lr:8.86e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.184, tt:3541.822\n",
      "Ep:86, loss:0.00001, loss_test:0.05486, lr:8.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.203, tt:3584.628\n",
      "Ep:87, loss:0.00001, loss_test:0.05935, lr:8.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.216, tt:3626.987\n",
      "Ep:88, loss:0.00001, loss_test:0.05485, lr:8.60e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.208, tt:3667.485\n",
      "Ep:89, loss:0.00001, loss_test:0.06034, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.212, tt:3709.076\n",
      "Ep:90, loss:0.00001, loss_test:0.05887, lr:8.43e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.204, tt:3749.530\n",
      "Ep:91, loss:0.00001, loss_test:0.05881, lr:8.35e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.208, tt:3791.136\n",
      "Ep:92, loss:0.00001, loss_test:0.05477, lr:8.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.215, tt:3832.962\n",
      "Ep:93, loss:0.00001, loss_test:0.05798, lr:8.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.235, tt:3876.057\n",
      "Ep:94, loss:0.00001, loss_test:0.05631, lr:8.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.283, tt:3921.839\n",
      "Ep:95, loss:0.00001, loss_test:0.05998, lr:8.02e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.302, tt:3964.974\n",
      "Ep:96, loss:0.00000, loss_test:0.05593, lr:7.94e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.301, tt:4006.242\n",
      "Ep:97, loss:0.00000, loss_test:0.05795, lr:7.86e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.308, tt:4048.221\n",
      "Ep:98, loss:0.00000, loss_test:0.05526, lr:7.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.346, tt:4093.229\n",
      "Ep:99, loss:0.00000, loss_test:0.06178, lr:7.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.350, tt:4134.960\n",
      "Ep:100, loss:0.00000, loss_test:0.05633, lr:7.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.372, tt:4178.615\n",
      "Ep:101, loss:0.00000, loss_test:0.05854, lr:7.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.381, tt:4220.890\n",
      "Ep:102, loss:0.00000, loss_test:0.05667, lr:7.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.405, tt:4264.669\n",
      "Ep:103, loss:0.00000, loss_test:0.05702, lr:7.40e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.407, tt:4306.348\n",
      "Ep:104, loss:0.00000, loss_test:0.05765, lr:7.32e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.406, tt:4347.631\n",
      "Ep:105, loss:0.00000, loss_test:0.05647, lr:7.25e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.411, tt:4389.567\n",
      "Ep:106, loss:0.00000, loss_test:0.05866, lr:7.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.426, tt:4432.606\n",
      "Ep:107, loss:0.00000, loss_test:0.05877, lr:7.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.430, tt:4474.463\n",
      "Ep:108, loss:0.00000, loss_test:0.05669, lr:7.03e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.444, tt:4517.414\n",
      "Ep:109, loss:0.00000, loss_test:0.05815, lr:6.96e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.439, tt:4558.313\n",
      "Ep:110, loss:0.00000, loss_test:0.05860, lr:6.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.438, tt:4599.627\n",
      "Ep:111, loss:0.00000, loss_test:0.05838, lr:6.83e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.447, tt:4642.071\n",
      "Ep:112, loss:0.00000, loss_test:0.05968, lr:6.76e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.465, tt:4685.517\n",
      "Ep:113, loss:0.00000, loss_test:0.06195, lr:6.69e-03, fs:0.86857 (r=0.768,p=1.000),  time:41.475, tt:4728.164\n",
      "Ep:114, loss:0.00000, loss_test:0.05964, lr:6.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.483, tt:4770.515\n",
      "Ep:115, loss:0.00000, loss_test:0.05939, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.502, tt:4814.182\n",
      "Ep:116, loss:0.00000, loss_test:0.05842, lr:6.49e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.503, tt:4855.901\n",
      "Ep:117, loss:0.00000, loss_test:0.05970, lr:6.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.512, tt:4898.466\n",
      "Ep:118, loss:0.00000, loss_test:0.05932, lr:6.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.528, tt:4941.788\n",
      "Ep:119, loss:0.00000, loss_test:0.05948, lr:6.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.548, tt:4985.795\n",
      "Ep:120, loss:0.00000, loss_test:0.06059, lr:6.24e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.574, tt:5030.489\n",
      "Ep:121, loss:0.00000, loss_test:0.05973, lr:6.17e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.578, tt:5072.532\n",
      "Ep:122, loss:0.00000, loss_test:0.05985, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.595, tt:5116.199\n",
      "Ep:123, loss:0.00000, loss_test:0.05971, lr:6.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.614, tt:5160.087\n",
      "Ep:124, loss:0.00000, loss_test:0.05896, lr:5.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.632, tt:5204.034\n",
      "Ep:125, loss:0.00000, loss_test:0.06075, lr:5.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.649, tt:5247.833\n",
      "Ep:126, loss:0.00000, loss_test:0.05965, lr:5.87e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.664, tt:5291.280\n",
      "Ep:127, loss:0.00000, loss_test:0.06010, lr:5.81e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.671, tt:5333.846\n",
      "Ep:128, loss:0.00000, loss_test:0.06055, lr:5.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.692, tt:5378.246\n",
      "Ep:129, loss:0.00000, loss_test:0.06072, lr:5.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.703, tt:5421.438\n",
      "Ep:130, loss:0.00000, loss_test:0.06016, lr:5.64e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.696, tt:5462.233\n",
      "Ep:131, loss:0.00000, loss_test:0.06052, lr:5.58e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.712, tt:5506.011\n",
      "Ep:132, loss:0.00000, loss_test:0.06258, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.742, tt:5551.714\n",
      "Ep:133, loss:0.00000, loss_test:0.06229, lr:5.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.739, tt:5592.983\n",
      "Ep:134, loss:0.00000, loss_test:0.06081, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.751, tt:5636.421\n",
      "Ep:135, loss:0.00000, loss_test:0.06227, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.759, tt:5679.280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.06205, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.761, tt:5721.304\n",
      "Ep:137, loss:0.00000, loss_test:0.06171, lr:5.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.768, tt:5764.012\n",
      "Ep:138, loss:0.00000, loss_test:0.06142, lr:5.20e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.769, tt:5805.855\n",
      "Ep:139, loss:0.00000, loss_test:0.06130, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.778, tt:5848.938\n",
      "Ep:140, loss:0.00000, loss_test:0.06303, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.788, tt:5892.057\n",
      "Ep:141, loss:0.00000, loss_test:0.06285, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.820, tt:5938.464\n",
      "Ep:142, loss:0.00000, loss_test:0.06197, lr:5.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.825, tt:5980.950\n",
      "Ep:143, loss:0.00000, loss_test:0.06199, lr:4.95e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.835, tt:6024.228\n",
      "Ep:144, loss:0.00000, loss_test:0.06224, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.851, tt:6068.447\n",
      "Ep:145, loss:0.00000, loss_test:0.06211, lr:4.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.864, tt:6112.091\n",
      "Ep:146, loss:0.00000, loss_test:0.06119, lr:4.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.861, tt:6153.594\n",
      "Ep:147, loss:0.00000, loss_test:0.06154, lr:4.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.883, tt:6198.750\n",
      "Ep:148, loss:0.00000, loss_test:0.06192, lr:4.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.891, tt:6241.770\n",
      "Ep:149, loss:0.00000, loss_test:0.06115, lr:4.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.897, tt:6284.604\n",
      "Ep:150, loss:0.00000, loss_test:0.06125, lr:4.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.904, tt:6327.520\n",
      "Ep:151, loss:0.00000, loss_test:0.06179, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.918, tt:6371.593\n",
      "Ep:152, loss:0.00000, loss_test:0.06134, lr:4.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.918, tt:6413.530\n",
      "Ep:153, loss:0.00000, loss_test:0.06139, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.926, tt:6456.644\n",
      "Ep:154, loss:0.00000, loss_test:0.06186, lr:4.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.940, tt:6500.723\n",
      "Ep:155, loss:0.00000, loss_test:0.06075, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.952, tt:6544.479\n",
      "Ep:156, loss:0.00000, loss_test:0.06125, lr:4.34e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.966, tt:6588.678\n",
      "Ep:157, loss:0.00000, loss_test:0.06165, lr:4.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.971, tt:6631.406\n",
      "Ep:158, loss:0.00000, loss_test:0.06127, lr:4.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.979, tt:6674.597\n",
      "Ep:159, loss:0.00000, loss_test:0.06217, lr:4.21e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.967, tt:6714.736\n",
      "Ep:160, loss:0.00000, loss_test:0.06240, lr:4.17e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.990, tt:6760.338\n",
      "Ep:161, loss:0.00000, loss_test:0.06113, lr:4.13e-03, fs:0.86364 (r=0.768,p=0.987),  time:41.989, tt:6802.249\n",
      "Ep:162, loss:0.00000, loss_test:0.06103, lr:4.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.007, tt:6847.208\n",
      "Ep:163, loss:0.00000, loss_test:0.06225, lr:4.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.007, tt:6889.154\n",
      "Ep:164, loss:0.00000, loss_test:0.06184, lr:4.01e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.013, tt:6932.085\n",
      "Ep:165, loss:0.00000, loss_test:0.06117, lr:3.97e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.027, tt:6976.561\n",
      "Ep:166, loss:0.00000, loss_test:0.06091, lr:3.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.040, tt:7020.726\n",
      "Ep:167, loss:0.00000, loss_test:0.06087, lr:3.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.033, tt:7061.544\n",
      "Ep:168, loss:0.00000, loss_test:0.06054, lr:3.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.033, tt:7103.563\n",
      "Ep:169, loss:0.00000, loss_test:0.06041, lr:3.81e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.039, tt:7146.642\n",
      "Ep:170, loss:0.00000, loss_test:0.06145, lr:3.77e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.042, tt:7189.116\n",
      "Ep:171, loss:0.00000, loss_test:0.06130, lr:3.73e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.046, tt:7231.888\n",
      "Ep:172, loss:0.00000, loss_test:0.06077, lr:3.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.052, tt:7274.928\n",
      "Ep:173, loss:0.00000, loss_test:0.06123, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.064, tt:7319.088\n",
      "Ep:174, loss:0.00000, loss_test:0.06172, lr:3.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.077, tt:7363.478\n",
      "Ep:175, loss:0.00000, loss_test:0.06106, lr:3.59e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.091, tt:7408.009\n",
      "Ep:176, loss:0.00000, loss_test:0.06049, lr:3.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.095, tt:7450.738\n",
      "Ep:177, loss:0.00000, loss_test:0.06086, lr:3.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.104, tt:7494.519\n",
      "Ep:178, loss:0.00000, loss_test:0.06142, lr:3.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.118, tt:7539.044\n",
      "Ep:179, loss:0.00000, loss_test:0.06116, lr:3.45e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.119, tt:7581.342\n",
      "Ep:180, loss:0.00000, loss_test:0.06076, lr:3.41e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.124, tt:7624.373\n",
      "Ep:181, loss:0.00000, loss_test:0.06080, lr:3.38e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.132, tt:7667.932\n",
      "Ep:182, loss:0.00000, loss_test:0.06083, lr:3.34e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.149, tt:7713.223\n",
      "Ep:183, loss:0.00000, loss_test:0.06106, lr:3.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.156, tt:7756.765\n",
      "Ep:184, loss:0.00000, loss_test:0.06147, lr:3.28e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.177, tt:7802.685\n",
      "Ep:185, loss:0.00000, loss_test:0.06134, lr:3.24e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.184, tt:7846.206\n",
      "Ep:186, loss:0.00000, loss_test:0.06044, lr:3.21e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.199, tt:7891.194\n",
      "Ep:187, loss:0.00000, loss_test:0.06066, lr:3.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.198, tt:7933.313\n",
      "Ep:188, loss:0.00000, loss_test:0.06099, lr:3.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.205, tt:7976.783\n",
      "Ep:189, loss:0.00000, loss_test:0.06145, lr:3.12e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.210, tt:8019.976\n",
      "Ep:190, loss:0.00000, loss_test:0.06146, lr:3.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.216, tt:8063.291\n",
      "Ep:191, loss:0.00000, loss_test:0.06088, lr:3.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.223, tt:8106.754\n",
      "Ep:192, loss:0.00000, loss_test:0.06065, lr:3.02e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.230, tt:8150.413\n",
      "Ep:193, loss:0.00000, loss_test:0.06098, lr:2.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.243, tt:8195.141\n",
      "Ep:194, loss:0.00000, loss_test:0.06096, lr:2.96e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.256, tt:8239.864\n",
      "Ep:195, loss:0.00000, loss_test:0.06088, lr:2.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.263, tt:8283.567\n",
      "Ep:196, loss:0.00000, loss_test:0.06077, lr:2.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.300, tt:8333.089\n",
      "Ep:197, loss:0.00000, loss_test:0.06073, lr:2.88e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.302, tt:8375.880\n",
      "Ep:198, loss:0.00000, loss_test:0.06049, lr:2.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.307, tt:8419.067\n",
      "Ep:199, loss:0.00000, loss_test:0.06020, lr:2.82e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.313, tt:8462.553\n",
      "Ep:200, loss:0.00000, loss_test:0.06049, lr:2.79e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.313, tt:8504.838\n",
      "Ep:201, loss:0.00000, loss_test:0.06099, lr:2.76e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.319, tt:8548.349\n",
      "Ep:202, loss:0.00000, loss_test:0.06086, lr:2.73e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.317, tt:8590.439\n",
      "Ep:203, loss:0.00000, loss_test:0.06020, lr:2.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.319, tt:8633.087\n",
      "Ep:204, loss:0.00000, loss_test:0.06078, lr:2.68e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.340, tt:8679.679\n",
      "Ep:205, loss:0.00000, loss_test:0.06151, lr:2.65e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.358, tt:8725.787\n",
      "Ep:206, loss:0.00000, loss_test:0.06107, lr:2.63e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.365, tt:8769.614\n",
      "Ep:207, loss:0.00000, loss_test:0.06056, lr:2.60e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.380, tt:8814.952\n",
      "Ep:208, loss:0.00000, loss_test:0.06066, lr:2.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.363, tt:8853.802\n",
      "Ep:209, loss:0.00000, loss_test:0.06074, lr:2.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.330, tt:8889.372\n",
      "Ep:210, loss:0.00000, loss_test:0.06075, lr:2.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.302, tt:8925.683\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02095, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:33.851, tt:33.851\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02344, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:36.375, tt:72.750\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02393, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.067, tt:117.200\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02307, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.083, tt:160.331\n",
      "Ep:4, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:41.138, tt:205.691\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02081, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:41.593, tt:249.558\n",
      "Ep:6, loss:0.00004, loss_test:0.02018, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:42.031, tt:294.218\n",
      "Ep:7, loss:0.00004, loss_test:0.01932, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:42.131, tt:337.045\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:42.381, tt:381.429\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01806, lr:6.00e-02, fs:0.71161 (r=0.960,p=0.565),  time:42.466, tt:424.658\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01780, lr:6.00e-02, fs:0.70370 (r=0.960,p=0.556),  time:42.510, tt:467.607\n",
      "Ep:11, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:42.550, tt:510.601\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:43.035, tt:559.449\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01670, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:43.073, tt:603.020\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:43.014, tt:645.212\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.74510 (r=0.960,p=0.609),  time:43.009, tt:688.144\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.75486 (r=0.980,p=0.614),  time:43.061, tt:732.040\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.76378 (r=0.980,p=0.626),  time:43.024, tt:774.440\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.76613 (r=0.960,p=0.638),  time:42.963, tt:816.300\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:42.921, tt:858.417\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01500, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:42.863, tt:900.113\n",
      "Ep:21, loss:0.00003, loss_test:0.01481, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:42.844, tt:942.562\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:42.833, tt:985.154\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01435, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:42.885, tt:1029.248\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01418, lr:6.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:42.845, tt:1071.136\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:42.856, tt:1114.252\n",
      "Ep:26, loss:0.00002, loss_test:0.01387, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:42.790, tt:1155.335\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:42.730, tt:1196.444\n",
      "Ep:28, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:42.697, tt:1238.209\n",
      "Ep:29, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:42.719, tt:1281.576\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:42.748, tt:1325.188\n",
      "Ep:31, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:42.723, tt:1367.135\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:42.752, tt:1410.819\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:42.799, tt:1455.150\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01299, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:42.755, tt:1496.425\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:42.727, tt:1538.190\n",
      "Ep:36, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:42.687, tt:1579.405\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:42.659, tt:1621.052\n",
      "Ep:38, loss:0.00002, loss_test:0.01276, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:42.684, tt:1664.680\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:42.678, tt:1707.112\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:42.605, tt:1746.787\n",
      "Ep:41, loss:0.00002, loss_test:0.01271, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:42.571, tt:1787.983\n",
      "Ep:42, loss:0.00002, loss_test:0.01264, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:42.541, tt:1829.256\n",
      "Ep:43, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:42.531, tt:1871.342\n",
      "Ep:44, loss:0.00001, loss_test:0.01252, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:42.549, tt:1914.685\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01254, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:42.560, tt:1957.739\n",
      "Ep:46, loss:0.00001, loss_test:0.01254, lr:6.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:42.520, tt:1998.449\n",
      "Ep:47, loss:0.00001, loss_test:0.01252, lr:6.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:42.469, tt:2038.523\n",
      "Ep:48, loss:0.00001, loss_test:0.01254, lr:6.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:42.418, tt:2078.498\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01253, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:42.454, tt:2122.689\n",
      "Ep:50, loss:0.00001, loss_test:0.01258, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:42.462, tt:2165.574\n",
      "Ep:51, loss:0.00001, loss_test:0.01251, lr:6.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:42.442, tt:2206.974\n",
      "Ep:52, loss:0.00001, loss_test:0.01257, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:42.435, tt:2249.036\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:42.417, tt:2290.543\n",
      "Ep:54, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:42.412, tt:2332.654\n",
      "Ep:55, loss:0.00001, loss_test:0.01262, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:42.409, tt:2374.912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00001, loss_test:0.01260, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:42.392, tt:2416.332\n",
      "Ep:57, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:42.367, tt:2457.300\n",
      "Ep:58, loss:0.00001, loss_test:0.01274, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:42.385, tt:2500.730\n",
      "Ep:59, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:42.370, tt:2542.177\n",
      "Ep:60, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:42.381, tt:2585.245\n",
      "Ep:61, loss:0.00001, loss_test:0.01281, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:42.406, tt:2629.175\n",
      "Ep:62, loss:0.00001, loss_test:0.01286, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:42.439, tt:2673.655\n",
      "Ep:63, loss:0.00001, loss_test:0.01297, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:42.464, tt:2717.696\n",
      "Ep:64, loss:0.00001, loss_test:0.01288, lr:5.94e-02, fs:0.82927 (r=0.859,p=0.802),  time:42.486, tt:2761.576\n",
      "Ep:65, loss:0.00001, loss_test:0.01307, lr:5.88e-02, fs:0.82353 (r=0.848,p=0.800),  time:42.482, tt:2803.802\n",
      "Ep:66, loss:0.00001, loss_test:0.01300, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:42.474, tt:2845.781\n",
      "Ep:67, loss:0.00001, loss_test:0.01315, lr:5.76e-02, fs:0.80000 (r=0.808,p=0.792),  time:42.499, tt:2889.932\n",
      "Ep:68, loss:0.00001, loss_test:0.01305, lr:5.71e-02, fs:0.81188 (r=0.828,p=0.796),  time:42.500, tt:2932.523\n",
      "Ep:69, loss:0.00001, loss_test:0.01324, lr:5.65e-02, fs:0.79798 (r=0.798,p=0.798),  time:42.506, tt:2975.413\n",
      "Ep:70, loss:0.00001, loss_test:0.01321, lr:5.59e-02, fs:0.80203 (r=0.798,p=0.806),  time:42.531, tt:3019.724\n",
      "Ep:71, loss:0.00001, loss_test:0.01326, lr:5.54e-02, fs:0.81633 (r=0.808,p=0.825),  time:42.509, tt:3060.618\n",
      "Ep:72, loss:0.00001, loss_test:0.01344, lr:5.48e-02, fs:0.81053 (r=0.778,p=0.846),  time:42.514, tt:3103.542\n",
      "Ep:73, loss:0.00001, loss_test:0.01330, lr:5.43e-02, fs:0.81675 (r=0.788,p=0.848),  time:42.501, tt:3145.082\n",
      "Ep:74, loss:0.00001, loss_test:0.01352, lr:5.37e-02, fs:0.81283 (r=0.768,p=0.864),  time:42.474, tt:3185.539\n",
      "Ep:75, loss:0.00001, loss_test:0.01351, lr:5.32e-02, fs:0.81283 (r=0.768,p=0.864),  time:42.480, tt:3228.461\n",
      "Ep:76, loss:0.00001, loss_test:0.01347, lr:5.27e-02, fs:0.82540 (r=0.788,p=0.867),  time:42.434, tt:3267.406\n",
      "Ep:77, loss:0.00001, loss_test:0.01363, lr:5.21e-02, fs:0.81720 (r=0.768,p=0.874),  time:42.429, tt:3309.433\n",
      "Ep:78, loss:0.00001, loss_test:0.01361, lr:5.16e-02, fs:0.81720 (r=0.768,p=0.874),  time:42.433, tt:3352.180\n",
      "Ep:79, loss:0.00001, loss_test:0.01362, lr:5.11e-02, fs:0.81720 (r=0.768,p=0.874),  time:42.433, tt:3394.667\n",
      "Ep:80, loss:0.00001, loss_test:0.01377, lr:5.06e-02, fs:0.81720 (r=0.768,p=0.874),  time:42.427, tt:3436.576\n",
      "Ep:81, loss:0.00001, loss_test:0.01372, lr:5.01e-02, fs:0.82353 (r=0.778,p=0.875),  time:42.419, tt:3478.379\n",
      "Ep:82, loss:0.00001, loss_test:0.01398, lr:4.96e-02, fs:0.82609 (r=0.768,p=0.894),  time:42.422, tt:3520.985\n",
      "Ep:83, loss:0.00001, loss_test:0.01379, lr:4.91e-02, fs:0.82162 (r=0.768,p=0.884),  time:42.433, tt:3564.349\n",
      "Ep:84, loss:0.00001, loss_test:0.01392, lr:4.86e-02, fs:0.82609 (r=0.768,p=0.894),  time:42.436, tt:3607.064\n",
      "Ep:85, loss:0.00001, loss_test:0.01419, lr:4.81e-02, fs:0.82609 (r=0.768,p=0.894),  time:42.472, tt:3652.615\n",
      "Ep:86, loss:0.00001, loss_test:0.01393, lr:4.76e-02, fs:0.83243 (r=0.778,p=0.895),  time:42.477, tt:3695.490\n",
      "Ep:87, loss:0.00001, loss_test:0.01434, lr:4.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:42.476, tt:3737.913\n",
      "Ep:88, loss:0.00001, loss_test:0.01418, lr:4.67e-02, fs:0.83060 (r=0.768,p=0.905),  time:42.476, tt:3780.348\n",
      "Ep:89, loss:0.00001, loss_test:0.01419, lr:4.62e-02, fs:0.83243 (r=0.778,p=0.895),  time:42.461, tt:3821.504\n",
      "Ep:90, loss:0.00001, loss_test:0.01445, lr:4.57e-02, fs:0.83060 (r=0.768,p=0.905),  time:42.471, tt:3864.830\n",
      "Ep:91, loss:0.00001, loss_test:0.01433, lr:4.53e-02, fs:0.83060 (r=0.768,p=0.905),  time:42.455, tt:3905.865\n",
      "Ep:92, loss:0.00001, loss_test:0.01449, lr:4.48e-02, fs:0.83060 (r=0.768,p=0.905),  time:42.445, tt:3947.391\n",
      "Ep:93, loss:0.00001, loss_test:0.01453, lr:4.44e-02, fs:0.82418 (r=0.758,p=0.904),  time:42.437, tt:3989.086\n",
      "Ep:94, loss:0.00001, loss_test:0.01453, lr:4.39e-02, fs:0.82418 (r=0.758,p=0.904),  time:42.421, tt:4029.993\n",
      "Ep:95, loss:0.00001, loss_test:0.01467, lr:4.35e-02, fs:0.81768 (r=0.747,p=0.902),  time:42.409, tt:4071.236\n",
      "Ep:96, loss:0.00001, loss_test:0.01465, lr:4.31e-02, fs:0.81111 (r=0.737,p=0.901),  time:42.384, tt:4111.249\n",
      "Ep:97, loss:0.00001, loss_test:0.01480, lr:4.26e-02, fs:0.82222 (r=0.747,p=0.914),  time:42.369, tt:4152.207\n",
      "Ep:98, loss:0.00001, loss_test:0.01486, lr:4.22e-02, fs:0.81564 (r=0.737,p=0.912),  time:42.365, tt:4194.126\n",
      "Ep:99, loss:0.00001, loss_test:0.01487, lr:4.18e-02, fs:0.82222 (r=0.747,p=0.914),  time:42.350, tt:4235.021\n",
      "Ep:100, loss:0.00001, loss_test:0.01494, lr:4.14e-02, fs:0.81564 (r=0.737,p=0.912),  time:42.339, tt:4276.244\n",
      "Ep:101, loss:0.00001, loss_test:0.01496, lr:4.10e-02, fs:0.81564 (r=0.737,p=0.912),  time:42.307, tt:4315.353\n",
      "Ep:102, loss:0.00000, loss_test:0.01505, lr:4.05e-02, fs:0.81564 (r=0.737,p=0.912),  time:42.315, tt:4358.415\n",
      "Ep:103, loss:0.00000, loss_test:0.01513, lr:4.01e-02, fs:0.78857 (r=0.697,p=0.908),  time:42.290, tt:4398.118\n",
      "Ep:104, loss:0.00000, loss_test:0.01523, lr:3.97e-02, fs:0.78857 (r=0.697,p=0.908),  time:42.262, tt:4437.525\n",
      "Ep:105, loss:0.00000, loss_test:0.01520, lr:3.93e-02, fs:0.78857 (r=0.697,p=0.908),  time:42.247, tt:4478.207\n",
      "Ep:106, loss:0.00000, loss_test:0.01537, lr:3.89e-02, fs:0.76744 (r=0.667,p=0.904),  time:42.222, tt:4517.726\n",
      "Ep:107, loss:0.00000, loss_test:0.01534, lr:3.86e-02, fs:0.76744 (r=0.667,p=0.904),  time:42.205, tt:4558.086\n",
      "Ep:108, loss:0.00000, loss_test:0.01540, lr:3.82e-02, fs:0.76023 (r=0.657,p=0.903),  time:42.179, tt:4597.536\n",
      "Ep:109, loss:0.00000, loss_test:0.01554, lr:3.78e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.168, tt:4638.460\n",
      "Ep:110, loss:0.00000, loss_test:0.01553, lr:3.74e-02, fs:0.76023 (r=0.657,p=0.903),  time:42.139, tt:4677.422\n",
      "Ep:111, loss:0.00000, loss_test:0.01559, lr:3.70e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.124, tt:4717.883\n",
      "Ep:112, loss:0.00000, loss_test:0.01571, lr:3.67e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.094, tt:4756.649\n",
      "Ep:113, loss:0.00000, loss_test:0.01563, lr:3.63e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.074, tt:4796.460\n",
      "Ep:114, loss:0.00000, loss_test:0.01579, lr:3.59e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.046, tt:4835.246\n",
      "Ep:115, loss:0.00000, loss_test:0.01582, lr:3.56e-02, fs:0.75294 (r=0.646,p=0.901),  time:42.023, tt:4874.627\n",
      "Ep:116, loss:0.00000, loss_test:0.01577, lr:3.52e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.989, tt:4912.665\n",
      "Ep:117, loss:0.00000, loss_test:0.01599, lr:3.49e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.960, tt:4951.296\n",
      "Ep:118, loss:0.00000, loss_test:0.01591, lr:3.45e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.947, tt:4991.664\n",
      "Ep:119, loss:0.00000, loss_test:0.01600, lr:3.42e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.930, tt:5031.583\n",
      "Ep:120, loss:0.00000, loss_test:0.01605, lr:3.38e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.929, tt:5073.367\n",
      "Ep:121, loss:0.00000, loss_test:0.01608, lr:3.35e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.918, tt:5114.026\n",
      "Ep:122, loss:0.00000, loss_test:0.01620, lr:3.32e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.902, tt:5153.913\n",
      "Ep:123, loss:0.00000, loss_test:0.01617, lr:3.28e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.884, tt:5193.663\n",
      "Ep:124, loss:0.00000, loss_test:0.01619, lr:3.25e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.858, tt:5232.199\n",
      "Ep:125, loss:0.00000, loss_test:0.01641, lr:3.22e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.848, tt:5272.800\n",
      "Ep:126, loss:0.00000, loss_test:0.01628, lr:3.19e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.837, tt:5313.296\n",
      "Ep:127, loss:0.00000, loss_test:0.01639, lr:3.15e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.814, tt:5352.209\n",
      "Ep:128, loss:0.00000, loss_test:0.01652, lr:3.12e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.789, tt:5390.811\n",
      "Ep:129, loss:0.00000, loss_test:0.01642, lr:3.09e-02, fs:0.75294 (r=0.646,p=0.901),  time:41.791, tt:5432.883\n",
      "Ep:130, loss:0.00000, loss_test:0.01662, lr:3.06e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.793, tt:5474.908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.01659, lr:3.03e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.790, tt:5516.277\n",
      "Ep:132, loss:0.00000, loss_test:0.01655, lr:3.00e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.781, tt:5556.815\n",
      "Ep:133, loss:0.00000, loss_test:0.01677, lr:2.97e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.778, tt:5598.302\n",
      "Ep:134, loss:0.00000, loss_test:0.01666, lr:2.94e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.778, tt:5640.033\n",
      "Ep:135, loss:0.00000, loss_test:0.01670, lr:2.91e-02, fs:0.74556 (r=0.636,p=0.900),  time:41.769, tt:5680.516\n",
      "Ep:136, loss:0.00000, loss_test:0.01685, lr:2.88e-02, fs:0.75000 (r=0.636,p=0.913),  time:41.761, tt:5721.266\n",
      "Ep:137, loss:0.00000, loss_test:0.01679, lr:2.85e-02, fs:0.75000 (r=0.636,p=0.913),  time:41.746, tt:5760.887\n",
      "Ep:138, loss:0.00000, loss_test:0.01682, lr:2.82e-02, fs:0.75000 (r=0.636,p=0.913),  time:41.732, tt:5800.809\n",
      "Ep:139, loss:0.00000, loss_test:0.01699, lr:2.80e-02, fs:0.75000 (r=0.636,p=0.913),  time:41.730, tt:5842.180\n",
      "Ep:140, loss:0.00000, loss_test:0.01697, lr:2.77e-02, fs:0.75000 (r=0.636,p=0.913),  time:41.720, tt:5882.481\n",
      "Ep:141, loss:0.00000, loss_test:0.01694, lr:2.74e-02, fs:0.75000 (r=0.636,p=0.913),  time:41.710, tt:5922.879\n",
      "Ep:142, loss:0.00000, loss_test:0.01710, lr:2.71e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.712, tt:5964.838\n",
      "Ep:143, loss:0.00000, loss_test:0.01705, lr:2.69e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.689, tt:6003.212\n",
      "Ep:144, loss:0.00000, loss_test:0.01708, lr:2.66e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.680, tt:6043.558\n",
      "Ep:145, loss:0.00000, loss_test:0.01722, lr:2.63e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.681, tt:6085.421\n",
      "Ep:146, loss:0.00000, loss_test:0.01714, lr:2.61e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.686, tt:6127.883\n",
      "Ep:147, loss:0.00000, loss_test:0.01722, lr:2.58e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.680, tt:6168.617\n",
      "Ep:148, loss:0.00000, loss_test:0.01732, lr:2.55e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.674, tt:6209.452\n",
      "Ep:149, loss:0.00000, loss_test:0.01727, lr:2.53e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.674, tt:6251.143\n",
      "Ep:150, loss:0.00000, loss_test:0.01738, lr:2.50e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.669, tt:6292.024\n",
      "Ep:151, loss:0.00000, loss_test:0.01730, lr:2.48e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.653, tt:6331.259\n",
      "Ep:152, loss:0.00000, loss_test:0.01739, lr:2.45e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.651, tt:6372.539\n",
      "Ep:153, loss:0.00000, loss_test:0.01748, lr:2.43e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.640, tt:6412.498\n",
      "Ep:154, loss:0.00000, loss_test:0.01750, lr:2.40e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.629, tt:6452.538\n",
      "Ep:155, loss:0.00000, loss_test:0.01748, lr:2.38e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.612, tt:6491.422\n",
      "Ep:156, loss:0.00000, loss_test:0.01752, lr:2.36e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.599, tt:6531.058\n",
      "Ep:157, loss:0.00000, loss_test:0.01762, lr:2.33e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.601, tt:6573.022\n",
      "Ep:158, loss:0.00000, loss_test:0.01761, lr:2.31e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.592, tt:6613.114\n",
      "Ep:159, loss:0.00000, loss_test:0.01760, lr:2.29e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.579, tt:6652.624\n",
      "Ep:160, loss:0.00000, loss_test:0.01767, lr:2.26e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.574, tt:6693.367\n",
      "Ep:161, loss:0.00000, loss_test:0.01769, lr:2.24e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.561, tt:6732.806\n",
      "Ep:162, loss:0.00000, loss_test:0.01772, lr:2.22e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.556, tt:6773.558\n",
      "Ep:163, loss:0.00000, loss_test:0.01779, lr:2.20e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.536, tt:6811.965\n",
      "Ep:164, loss:0.00000, loss_test:0.01780, lr:2.17e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.541, tt:6854.275\n",
      "Ep:165, loss:0.00000, loss_test:0.01779, lr:2.15e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.522, tt:6892.673\n",
      "Ep:166, loss:0.00000, loss_test:0.01790, lr:2.13e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.521, tt:6933.930\n",
      "Ep:167, loss:0.00000, loss_test:0.01786, lr:2.11e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.511, tt:6973.897\n",
      "Ep:168, loss:0.00000, loss_test:0.01787, lr:2.09e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.505, tt:7014.324\n",
      "Ep:169, loss:0.00000, loss_test:0.01801, lr:2.07e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.497, tt:7054.541\n",
      "Ep:170, loss:0.00000, loss_test:0.01793, lr:2.05e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.478, tt:7092.714\n",
      "Ep:171, loss:0.00000, loss_test:0.01791, lr:2.03e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.476, tt:7133.893\n",
      "Ep:172, loss:0.00000, loss_test:0.01808, lr:2.01e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.473, tt:7174.828\n",
      "Ep:173, loss:0.00000, loss_test:0.01806, lr:1.99e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.464, tt:7214.720\n",
      "Ep:174, loss:0.00000, loss_test:0.01798, lr:1.97e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.458, tt:7255.170\n",
      "Ep:175, loss:0.00000, loss_test:0.01810, lr:1.95e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.469, tt:7298.553\n",
      "Ep:176, loss:0.00000, loss_test:0.01816, lr:1.93e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.456, tt:7337.688\n",
      "Ep:177, loss:0.00000, loss_test:0.01811, lr:1.91e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.444, tt:7376.998\n",
      "Ep:178, loss:0.00000, loss_test:0.01816, lr:1.89e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.441, tt:7418.009\n",
      "Ep:179, loss:0.00000, loss_test:0.01821, lr:1.87e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.428, tt:7457.056\n",
      "Ep:180, loss:0.00000, loss_test:0.01820, lr:1.85e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.426, tt:7498.076\n",
      "Ep:181, loss:0.00000, loss_test:0.01822, lr:1.83e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.430, tt:7540.292\n",
      "Ep:182, loss:0.00000, loss_test:0.01827, lr:1.81e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.421, tt:7580.059\n",
      "Ep:183, loss:0.00000, loss_test:0.01827, lr:1.80e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.413, tt:7619.907\n",
      "Ep:184, loss:0.00000, loss_test:0.01829, lr:1.78e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.409, tt:7660.654\n",
      "Ep:185, loss:0.00000, loss_test:0.01836, lr:1.76e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.406, tt:7701.553\n",
      "Ep:186, loss:0.00000, loss_test:0.01833, lr:1.74e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.400, tt:7741.828\n",
      "Ep:187, loss:0.00000, loss_test:0.01837, lr:1.73e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.390, tt:7781.374\n",
      "Ep:188, loss:0.00000, loss_test:0.01843, lr:1.71e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.386, tt:7822.005\n",
      "Ep:189, loss:0.00000, loss_test:0.01842, lr:1.69e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.385, tt:7863.114\n",
      "Ep:190, loss:0.00000, loss_test:0.01842, lr:1.67e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.376, tt:7902.732\n",
      "Ep:191, loss:0.00000, loss_test:0.01848, lr:1.66e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.369, tt:7942.828\n",
      "Ep:192, loss:0.00000, loss_test:0.01849, lr:1.64e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.366, tt:7983.600\n",
      "Ep:193, loss:0.00000, loss_test:0.01847, lr:1.62e-02, fs:0.75449 (r=0.636,p=0.926),  time:41.363, tt:8024.335\n",
      "Ep:194, loss:0.00000, loss_test:0.01853, lr:1.61e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.356, tt:8064.366\n",
      "Ep:195, loss:0.00000, loss_test:0.01855, lr:1.59e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.354, tt:8105.420\n",
      "Ep:196, loss:0.00000, loss_test:0.01854, lr:1.58e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.387, tt:8153.248\n",
      "Ep:197, loss:0.00000, loss_test:0.01856, lr:1.56e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.380, tt:8193.164\n",
      "Ep:198, loss:0.00000, loss_test:0.01860, lr:1.54e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.362, tt:8230.972\n",
      "Ep:199, loss:0.00000, loss_test:0.01862, lr:1.53e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.351, tt:8270.149\n",
      "Ep:200, loss:0.00000, loss_test:0.01862, lr:1.51e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.343, tt:8309.857\n",
      "Ep:201, loss:0.00000, loss_test:0.01866, lr:1.50e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.339, tt:8350.448\n",
      "Ep:202, loss:0.00000, loss_test:0.01866, lr:1.48e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.331, tt:8390.135\n",
      "Ep:203, loss:0.00000, loss_test:0.01868, lr:1.47e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.323, tt:8429.800\n",
      "Ep:204, loss:0.00000, loss_test:0.01872, lr:1.45e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.323, tt:8471.214\n",
      "Ep:205, loss:0.00000, loss_test:0.01872, lr:1.44e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.317, tt:8511.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.01873, lr:1.43e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.307, tt:8550.578\n",
      "Ep:207, loss:0.00000, loss_test:0.01878, lr:1.41e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.303, tt:8590.997\n",
      "Ep:208, loss:0.00000, loss_test:0.01878, lr:1.40e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.292, tt:8629.964\n",
      "Ep:209, loss:0.00000, loss_test:0.01877, lr:1.38e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.267, tt:8666.102\n",
      "Ep:210, loss:0.00000, loss_test:0.01881, lr:1.37e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.243, tt:8702.173\n",
      "Ep:211, loss:0.00000, loss_test:0.01882, lr:1.36e-02, fs:0.75904 (r=0.636,p=0.940),  time:41.201, tt:8734.652\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14343, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.170, tt:36.170\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14179, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.598, tt:79.195\n",
      "Ep:2, loss:0.00027, loss_test:0.13877, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.499, tt:121.498\n",
      "Ep:3, loss:0.00026, loss_test:0.13334, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:40.522, tt:162.089\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12567, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:40.673, tt:203.364\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.12091, lr:1.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:41.017, tt:246.099\n",
      "Ep:6, loss:0.00023, loss_test:0.11728, lr:1.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:41.205, tt:288.438\n",
      "Ep:7, loss:0.00022, loss_test:0.11739, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:41.244, tt:329.955\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11637, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:41.387, tt:372.483\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11313, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:41.325, tt:413.251\n",
      "Ep:10, loss:0.00020, loss_test:0.11085, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:41.390, tt:455.286\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10698, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:41.407, tt:496.886\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10391, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:41.514, tt:539.684\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10170, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:41.478, tt:580.693\n",
      "Ep:14, loss:0.00017, loss_test:0.09959, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:41.474, tt:622.117\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09654, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:41.480, tt:663.677\n",
      "Ep:16, loss:0.00016, loss_test:0.09410, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:41.523, tt:705.884\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09407, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:41.515, tt:747.275\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09074, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:41.453, tt:787.607\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.08813, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:41.520, tt:830.406\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08999, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:41.427, tt:869.961\n",
      "Ep:21, loss:0.00014, loss_test:0.08695, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:41.416, tt:911.161\n",
      "Ep:22, loss:0.00013, loss_test:0.08435, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:41.286, tt:949.582\n",
      "Ep:23, loss:0.00013, loss_test:0.08546, lr:1.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:41.329, tt:991.901\n",
      "Ep:24, loss:0.00012, loss_test:0.08243, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:41.336, tt:1033.412\n",
      "Ep:25, loss:0.00012, loss_test:0.08188, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:41.387, tt:1076.071\n",
      "Ep:26, loss:0.00011, loss_test:0.08180, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:41.443, tt:1118.967\n",
      "Ep:27, loss:0.00011, loss_test:0.07983, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:41.454, tt:1160.706\n",
      "Ep:28, loss:0.00010, loss_test:0.08042, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:41.502, tt:1203.554\n",
      "Ep:29, loss:0.00010, loss_test:0.07935, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:41.448, tt:1243.430\n",
      "Ep:30, loss:0.00010, loss_test:0.07796, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:41.439, tt:1284.622\n",
      "Ep:31, loss:0.00009, loss_test:0.07819, lr:9.90e-03, fs:0.80597 (r=0.818,p=0.794),  time:41.473, tt:1327.128\n",
      "Ep:32, loss:0.00009, loss_test:0.07680, lr:9.80e-03, fs:0.80829 (r=0.788,p=0.830),  time:41.498, tt:1369.431\n",
      "Ep:33, loss:0.00008, loss_test:0.07615, lr:9.70e-03, fs:0.82949 (r=0.909,p=0.763),  time:41.547, tt:1412.598\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.07712, lr:9.70e-03, fs:0.80000 (r=0.788,p=0.812),  time:41.545, tt:1454.077\n",
      "Ep:35, loss:0.00008, loss_test:0.07373, lr:9.70e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.546, tt:1495.661\n",
      "Ep:36, loss:0.00008, loss_test:0.07320, lr:9.70e-03, fs:0.80612 (r=0.798,p=0.814),  time:41.525, tt:1536.436\n",
      "Ep:37, loss:0.00007, loss_test:0.07328, lr:9.70e-03, fs:0.81633 (r=0.808,p=0.825),  time:41.566, tt:1579.519\n",
      "Ep:38, loss:0.00007, loss_test:0.07306, lr:9.70e-03, fs:0.81053 (r=0.778,p=0.846),  time:41.594, tt:1622.159\n",
      "Ep:39, loss:0.00007, loss_test:0.07293, lr:9.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:41.581, tt:1663.254\n",
      "Ep:40, loss:0.00007, loss_test:0.07454, lr:9.70e-03, fs:0.78873 (r=0.848,p=0.737),  time:41.553, tt:1703.665\n",
      "Ep:41, loss:0.00007, loss_test:0.07898, lr:9.70e-03, fs:0.73684 (r=0.636,p=0.875),  time:41.520, tt:1743.828\n",
      "Ep:42, loss:0.00006, loss_test:0.07226, lr:9.70e-03, fs:0.79412 (r=0.818,p=0.771),  time:41.545, tt:1786.438\n",
      "Ep:43, loss:0.00006, loss_test:0.07565, lr:9.70e-03, fs:0.72941 (r=0.626,p=0.873),  time:41.538, tt:1827.679\n",
      "Ep:44, loss:0.00006, loss_test:0.07215, lr:9.70e-03, fs:0.78788 (r=0.788,p=0.788),  time:41.509, tt:1867.926\n",
      "Ep:45, loss:0.00006, loss_test:0.07501, lr:9.61e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.476, tt:1907.885\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.06862, lr:9.61e-03, fs:0.79558 (r=0.727,p=0.878),  time:41.445, tt:1947.910\n",
      "Ep:47, loss:0.00005, loss_test:0.07363, lr:9.61e-03, fs:0.77596 (r=0.717,p=0.845),  time:41.400, tt:1987.214\n",
      "Ep:48, loss:0.00005, loss_test:0.07473, lr:9.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:41.372, tt:2027.208\n",
      "Ep:49, loss:0.00005, loss_test:0.06910, lr:9.61e-03, fs:0.77966 (r=0.697,p=0.885),  time:41.401, tt:2070.040\n",
      "Ep:50, loss:0.00004, loss_test:0.07085, lr:9.61e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.410, tt:2111.928\n",
      "Ep:51, loss:0.00004, loss_test:0.06812, lr:9.61e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.420, tt:2153.842\n",
      "Ep:52, loss:0.00004, loss_test:0.07394, lr:9.61e-03, fs:0.75706 (r=0.677,p=0.859),  time:41.361, tt:2192.141\n",
      "Ep:53, loss:0.00004, loss_test:0.06503, lr:9.61e-03, fs:0.83060 (r=0.768,p=0.905),  time:41.397, tt:2235.428\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00004, loss_test:0.07431, lr:9.61e-03, fs:0.73988 (r=0.646,p=0.865),  time:41.455, tt:2280.023\n",
      "Ep:55, loss:0.00003, loss_test:0.06817, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.441, tt:2320.702\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.07542, lr:9.61e-03, fs:0.75000 (r=0.636,p=0.913),  time:41.440, tt:2362.074\n",
      "Ep:57, loss:0.00003, loss_test:0.06540, lr:9.61e-03, fs:0.82540 (r=0.788,p=0.867),  time:41.468, tt:2405.173\n",
      "Ep:58, loss:0.00003, loss_test:0.08356, lr:9.61e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.491, tt:2447.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.06746, lr:9.61e-03, fs:0.81111 (r=0.737,p=0.901),  time:41.519, tt:2491.144\n",
      "Ep:60, loss:0.00003, loss_test:0.07842, lr:9.61e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.512, tt:2532.212\n",
      "Ep:61, loss:0.00003, loss_test:0.07003, lr:9.61e-03, fs:0.75145 (r=0.657,p=0.878),  time:41.549, tt:2576.068\n",
      "Ep:62, loss:0.00003, loss_test:0.07971, lr:9.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.572, tt:2619.060\n",
      "Ep:63, loss:0.00003, loss_test:0.07142, lr:9.61e-03, fs:0.77193 (r=0.667,p=0.917),  time:41.574, tt:2660.746\n",
      "Ep:64, loss:0.00002, loss_test:0.07480, lr:9.61e-03, fs:0.75904 (r=0.636,p=0.940),  time:41.588, tt:2703.214\n",
      "Ep:65, loss:0.00002, loss_test:0.07004, lr:9.61e-03, fs:0.75000 (r=0.636,p=0.913),  time:41.606, tt:2745.964\n",
      "Ep:66, loss:0.00002, loss_test:0.07597, lr:9.61e-03, fs:0.75449 (r=0.636,p=0.926),  time:41.652, tt:2790.711\n",
      "Ep:67, loss:0.00002, loss_test:0.06872, lr:9.51e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.656, tt:2832.583\n",
      "Ep:68, loss:0.00002, loss_test:0.07504, lr:9.41e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.657, tt:2874.305\n",
      "Ep:69, loss:0.00002, loss_test:0.07388, lr:9.32e-03, fs:0.76364 (r=0.636,p=0.955),  time:41.667, tt:2916.704\n",
      "Ep:70, loss:0.00002, loss_test:0.07250, lr:9.23e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.647, tt:2956.920\n",
      "Ep:71, loss:0.00002, loss_test:0.07325, lr:9.14e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.640, tt:2998.073\n",
      "Ep:72, loss:0.00001, loss_test:0.07128, lr:9.04e-03, fs:0.76364 (r=0.636,p=0.955),  time:41.635, tt:3039.321\n",
      "Ep:73, loss:0.00001, loss_test:0.07123, lr:8.95e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.639, tt:3081.297\n",
      "Ep:74, loss:0.00001, loss_test:0.07113, lr:8.86e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.641, tt:3123.079\n",
      "Ep:75, loss:0.00001, loss_test:0.07191, lr:8.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:41.636, tt:3164.326\n",
      "Ep:76, loss:0.00001, loss_test:0.07345, lr:8.69e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.645, tt:3206.636\n",
      "Ep:77, loss:0.00001, loss_test:0.07313, lr:8.60e-03, fs:0.75904 (r=0.636,p=0.940),  time:41.648, tt:3248.559\n",
      "Ep:78, loss:0.00001, loss_test:0.07508, lr:8.51e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.658, tt:3290.970\n",
      "Ep:79, loss:0.00001, loss_test:0.07707, lr:8.43e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.673, tt:3333.845\n",
      "Ep:80, loss:0.00001, loss_test:0.07488, lr:8.35e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.675, tt:3375.637\n",
      "Ep:81, loss:0.00001, loss_test:0.07673, lr:8.26e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.691, tt:3418.648\n",
      "Ep:82, loss:0.00001, loss_test:0.06999, lr:8.18e-03, fs:0.75904 (r=0.636,p=0.940),  time:41.682, tt:3459.612\n",
      "Ep:83, loss:0.00001, loss_test:0.08094, lr:8.10e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.674, tt:3500.644\n",
      "Ep:84, loss:0.00001, loss_test:0.07150, lr:8.02e-03, fs:0.75449 (r=0.636,p=0.926),  time:41.669, tt:3541.896\n",
      "Ep:85, loss:0.00001, loss_test:0.07955, lr:7.94e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.676, tt:3584.123\n",
      "Ep:86, loss:0.00001, loss_test:0.07302, lr:7.86e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.695, tt:3627.470\n",
      "Ep:87, loss:0.00001, loss_test:0.07297, lr:7.78e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.698, tt:3669.466\n",
      "Ep:88, loss:0.00001, loss_test:0.07628, lr:7.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.704, tt:3711.645\n",
      "Ep:89, loss:0.00001, loss_test:0.07334, lr:7.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.724, tt:3755.185\n",
      "Ep:90, loss:0.00001, loss_test:0.07389, lr:7.55e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.732, tt:3797.624\n",
      "Ep:91, loss:0.00001, loss_test:0.07381, lr:7.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.738, tt:3839.919\n",
      "Ep:92, loss:0.00001, loss_test:0.07421, lr:7.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.739, tt:3881.706\n",
      "Ep:93, loss:0.00001, loss_test:0.07504, lr:7.32e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.717, tt:3921.389\n",
      "Ep:94, loss:0.00001, loss_test:0.07506, lr:7.25e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.685, tt:3960.052\n",
      "Ep:95, loss:0.00001, loss_test:0.07337, lr:7.18e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.689, tt:4002.135\n",
      "Ep:96, loss:0.00001, loss_test:0.07900, lr:7.11e-03, fs:0.77019 (r=0.626,p=1.000),  time:41.694, tt:4044.289\n",
      "Ep:97, loss:0.00001, loss_test:0.07179, lr:7.03e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.699, tt:4086.510\n",
      "Ep:98, loss:0.00001, loss_test:0.07967, lr:6.96e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.715, tt:4129.822\n",
      "Ep:99, loss:0.00001, loss_test:0.07464, lr:6.89e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.717, tt:4171.726\n",
      "Ep:100, loss:0.00001, loss_test:0.07450, lr:6.83e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.731, tt:4214.866\n",
      "Ep:101, loss:0.00000, loss_test:0.07423, lr:6.76e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.747, tt:4258.241\n",
      "Ep:102, loss:0.00000, loss_test:0.07631, lr:6.69e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.740, tt:4299.257\n",
      "Ep:103, loss:0.00000, loss_test:0.07595, lr:6.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.748, tt:4341.806\n",
      "Ep:104, loss:0.00000, loss_test:0.07378, lr:6.56e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.753, tt:4384.029\n",
      "Ep:105, loss:0.00000, loss_test:0.07678, lr:6.49e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.798, tt:4430.611\n",
      "Ep:106, loss:0.00000, loss_test:0.07256, lr:6.43e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.818, tt:4474.482\n",
      "Ep:107, loss:0.00000, loss_test:0.07592, lr:6.36e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.820, tt:4516.570\n",
      "Ep:108, loss:0.00000, loss_test:0.07301, lr:6.30e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.815, tt:4557.794\n",
      "Ep:109, loss:0.00000, loss_test:0.07456, lr:6.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.828, tt:4601.064\n",
      "Ep:110, loss:0.00000, loss_test:0.07794, lr:6.17e-03, fs:0.77019 (r=0.626,p=1.000),  time:41.833, tt:4643.412\n",
      "Ep:111, loss:0.00000, loss_test:0.07265, lr:6.11e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.848, tt:4686.994\n",
      "Ep:112, loss:0.00000, loss_test:0.07480, lr:6.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.856, tt:4729.684\n",
      "Ep:113, loss:0.00000, loss_test:0.07634, lr:5.99e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.876, tt:4773.918\n",
      "Ep:114, loss:0.00000, loss_test:0.07386, lr:5.93e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.878, tt:4815.950\n",
      "Ep:115, loss:0.00000, loss_test:0.07305, lr:5.87e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.868, tt:4856.669\n",
      "Ep:116, loss:0.00000, loss_test:0.07365, lr:5.81e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.866, tt:4898.271\n",
      "Ep:117, loss:0.00000, loss_test:0.07451, lr:5.75e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.871, tt:4940.780\n",
      "Ep:118, loss:0.00000, loss_test:0.07379, lr:5.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.879, tt:4983.651\n",
      "Ep:119, loss:0.00000, loss_test:0.07404, lr:5.64e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.897, tt:5027.651\n",
      "Ep:120, loss:0.00000, loss_test:0.07412, lr:5.58e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.888, tt:5068.494\n",
      "Ep:121, loss:0.00000, loss_test:0.07337, lr:5.53e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.873, tt:5108.510\n",
      "Ep:122, loss:0.00000, loss_test:0.07357, lr:5.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.876, tt:5150.760\n",
      "Ep:123, loss:0.00000, loss_test:0.07445, lr:5.42e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.871, tt:5191.960\n",
      "Ep:124, loss:0.00000, loss_test:0.07336, lr:5.36e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.857, tt:5232.102\n",
      "Ep:125, loss:0.00000, loss_test:0.07367, lr:5.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.854, tt:5273.627\n",
      "Ep:126, loss:0.00000, loss_test:0.07501, lr:5.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.845, tt:5314.332\n",
      "Ep:127, loss:0.00000, loss_test:0.07305, lr:5.20e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.831, tt:5354.429\n",
      "Ep:128, loss:0.00000, loss_test:0.07553, lr:5.15e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.834, tt:5396.531\n",
      "Ep:129, loss:0.00000, loss_test:0.07525, lr:5.10e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.836, tt:5438.675\n",
      "Ep:130, loss:0.00000, loss_test:0.07402, lr:5.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.843, tt:5481.448\n",
      "Ep:131, loss:0.00000, loss_test:0.07454, lr:5.00e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.829, tt:5521.400\n",
      "Ep:132, loss:0.00000, loss_test:0.07390, lr:4.95e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.836, tt:5564.230\n",
      "Ep:133, loss:0.00000, loss_test:0.07425, lr:4.90e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.842, tt:5606.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.07394, lr:4.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.842, tt:5648.694\n",
      "Ep:135, loss:0.00000, loss_test:0.07350, lr:4.80e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.844, tt:5690.829\n",
      "Ep:136, loss:0.00000, loss_test:0.07607, lr:4.75e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.850, tt:5733.449\n",
      "Ep:137, loss:0.00000, loss_test:0.07490, lr:4.71e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.864, tt:5777.275\n",
      "Ep:138, loss:0.00000, loss_test:0.07343, lr:4.66e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.877, tt:5820.942\n",
      "Ep:139, loss:0.00000, loss_test:0.07513, lr:4.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.876, tt:5862.612\n",
      "Ep:140, loss:0.00000, loss_test:0.07570, lr:4.57e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.873, tt:5904.128\n",
      "Ep:141, loss:0.00000, loss_test:0.07446, lr:4.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.855, tt:5943.463\n",
      "Ep:142, loss:0.00000, loss_test:0.07597, lr:4.48e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.856, tt:5985.463\n",
      "Ep:143, loss:0.00000, loss_test:0.07475, lr:4.43e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.861, tt:6027.913\n",
      "Ep:144, loss:0.00000, loss_test:0.07418, lr:4.39e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.870, tt:6071.188\n",
      "Ep:145, loss:0.00000, loss_test:0.07576, lr:4.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.876, tt:6113.927\n",
      "Ep:146, loss:0.00000, loss_test:0.07562, lr:4.30e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.911, tt:6160.874\n",
      "Ep:147, loss:0.00000, loss_test:0.07507, lr:4.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.914, tt:6203.297\n",
      "Ep:148, loss:0.00000, loss_test:0.07561, lr:4.21e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.917, tt:6245.683\n",
      "Ep:149, loss:0.00000, loss_test:0.07522, lr:4.17e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.922, tt:6288.374\n",
      "Ep:150, loss:0.00000, loss_test:0.07445, lr:4.13e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.921, tt:6330.065\n",
      "Ep:151, loss:0.00000, loss_test:0.07615, lr:4.09e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.918, tt:6371.576\n",
      "Ep:152, loss:0.00000, loss_test:0.07690, lr:4.05e-03, fs:0.76543 (r=0.626,p=0.984),  time:41.931, tt:6415.410\n",
      "Ep:153, loss:0.00000, loss_test:0.07493, lr:4.01e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.936, tt:6458.187\n",
      "Ep:154, loss:0.00000, loss_test:0.07507, lr:3.97e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.938, tt:6500.322\n",
      "Ep:155, loss:0.00000, loss_test:0.07522, lr:3.93e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.921, tt:6539.686\n",
      "Ep:156, loss:0.00000, loss_test:0.07423, lr:3.89e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.917, tt:6580.914\n",
      "Ep:157, loss:0.00000, loss_test:0.07544, lr:3.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.914, tt:6622.462\n",
      "Ep:158, loss:0.00000, loss_test:0.07532, lr:3.81e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.915, tt:6664.462\n",
      "Ep:159, loss:0.00000, loss_test:0.07393, lr:3.77e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.907, tt:6705.084\n",
      "Ep:160, loss:0.00000, loss_test:0.07502, lr:3.73e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.903, tt:6746.379\n",
      "Ep:161, loss:0.00000, loss_test:0.07513, lr:3.70e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.908, tt:6789.082\n",
      "Ep:162, loss:0.00000, loss_test:0.07449, lr:3.66e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.919, tt:6832.833\n",
      "Ep:163, loss:0.00000, loss_test:0.07547, lr:3.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.915, tt:6874.120\n",
      "Ep:164, loss:0.00000, loss_test:0.07453, lr:3.59e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.906, tt:6914.443\n",
      "Ep:165, loss:0.00000, loss_test:0.07389, lr:3.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.903, tt:6955.930\n",
      "Ep:166, loss:0.00000, loss_test:0.07502, lr:3.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.917, tt:7000.117\n",
      "Ep:167, loss:0.00000, loss_test:0.07487, lr:3.48e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.912, tt:7041.254\n",
      "Ep:168, loss:0.00000, loss_test:0.07440, lr:3.45e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.920, tt:7084.456\n",
      "Ep:169, loss:0.00000, loss_test:0.07506, lr:3.41e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.922, tt:7126.730\n",
      "Ep:170, loss:0.00000, loss_test:0.07486, lr:3.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.918, tt:7167.928\n",
      "Ep:171, loss:0.00000, loss_test:0.07437, lr:3.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.917, tt:7209.758\n",
      "Ep:172, loss:0.00000, loss_test:0.07474, lr:3.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.923, tt:7252.594\n",
      "Ep:173, loss:0.00000, loss_test:0.07565, lr:3.28e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.921, tt:7294.248\n",
      "Ep:174, loss:0.00000, loss_test:0.07538, lr:3.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.923, tt:7336.502\n",
      "Ep:175, loss:0.00000, loss_test:0.07441, lr:3.21e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.922, tt:7378.214\n",
      "Ep:176, loss:0.00000, loss_test:0.07467, lr:3.18e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.910, tt:7418.028\n",
      "Ep:177, loss:0.00000, loss_test:0.07474, lr:3.15e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.907, tt:7459.458\n",
      "Ep:178, loss:0.00000, loss_test:0.07407, lr:3.12e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.896, tt:7499.412\n",
      "Ep:179, loss:0.00000, loss_test:0.07600, lr:3.09e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.899, tt:7541.802\n",
      "Ep:180, loss:0.00000, loss_test:0.07563, lr:3.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.886, tt:7581.446\n",
      "Ep:181, loss:0.00000, loss_test:0.07455, lr:3.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.887, tt:7623.441\n",
      "Ep:182, loss:0.00000, loss_test:0.07431, lr:2.99e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.896, tt:7667.039\n",
      "Ep:183, loss:0.00000, loss_test:0.07553, lr:2.96e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.895, tt:7708.641\n",
      "Ep:184, loss:0.00000, loss_test:0.07635, lr:2.93e-03, fs:0.77019 (r=0.626,p=1.000),  time:41.893, tt:7750.213\n",
      "Ep:185, loss:0.00000, loss_test:0.07553, lr:2.90e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.891, tt:7791.770\n",
      "Ep:186, loss:0.00000, loss_test:0.07469, lr:2.88e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.886, tt:7832.728\n",
      "Ep:187, loss:0.00000, loss_test:0.07436, lr:2.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.898, tt:7876.757\n",
      "Ep:188, loss:0.00000, loss_test:0.07509, lr:2.82e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.905, tt:7920.052\n",
      "Ep:189, loss:0.00000, loss_test:0.07472, lr:2.79e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.902, tt:7961.415\n",
      "Ep:190, loss:0.00000, loss_test:0.07393, lr:2.76e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.896, tt:8002.164\n",
      "Ep:191, loss:0.00000, loss_test:0.07527, lr:2.73e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.892, tt:8043.172\n",
      "Ep:192, loss:0.00000, loss_test:0.07502, lr:2.71e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.891, tt:8084.868\n",
      "Ep:193, loss:0.00000, loss_test:0.07443, lr:2.68e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.891, tt:8126.823\n",
      "Ep:194, loss:0.00000, loss_test:0.07451, lr:2.65e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.887, tt:8167.883\n",
      "Ep:195, loss:0.00000, loss_test:0.07473, lr:2.63e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.888, tt:8210.114\n",
      "Ep:196, loss:0.00000, loss_test:0.07452, lr:2.60e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.876, tt:8249.625\n",
      "Ep:197, loss:0.00000, loss_test:0.07415, lr:2.57e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.878, tt:8291.843\n",
      "Ep:198, loss:0.00000, loss_test:0.07473, lr:2.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.882, tt:8334.566\n",
      "Ep:199, loss:0.00000, loss_test:0.07471, lr:2.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.889, tt:8377.765\n",
      "Ep:200, loss:0.00000, loss_test:0.07440, lr:2.50e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.890, tt:8419.874\n",
      "Ep:201, loss:0.00000, loss_test:0.07427, lr:2.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.890, tt:8461.733\n",
      "Ep:202, loss:0.00000, loss_test:0.07415, lr:2.45e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.889, tt:8503.485\n",
      "Ep:203, loss:0.00000, loss_test:0.07402, lr:2.42e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.893, tt:8546.143\n",
      "Ep:204, loss:0.00000, loss_test:0.07429, lr:2.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.899, tt:8589.205\n",
      "Ep:205, loss:0.00000, loss_test:0.07424, lr:2.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.894, tt:8630.225\n",
      "Ep:206, loss:0.00000, loss_test:0.07408, lr:2.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.896, tt:8672.459\n",
      "Ep:207, loss:0.00000, loss_test:0.07390, lr:2.33e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.899, tt:8714.918\n",
      "Ep:208, loss:0.00000, loss_test:0.07390, lr:2.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.887, tt:8754.473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.07472, lr:2.28e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.840, tt:8786.340\n",
      "Ep:210, loss:0.00000, loss_test:0.07455, lr:2.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.780, tt:8815.592\n",
      "Ep:211, loss:0.00000, loss_test:0.07411, lr:2.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.671, tt:8834.321\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02030, lr:6.00e-02, fs:0.63559 (r=0.862,p=0.503),  time:25.659, tt:25.659\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02278, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.288, tt:58.576\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02299, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.396, tt:97.189\n",
      "Ep:3, loss:0.00005, loss_test:0.02137, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:34.702, tt:138.809\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01991, lr:6.00e-02, fs:0.67213 (r=0.943,p=0.522),  time:35.788, tt:178.938\n",
      "Ep:5, loss:0.00004, loss_test:0.01966, lr:6.00e-02, fs:0.66964 (r=0.862,p=0.547),  time:36.362, tt:218.170\n",
      "Ep:6, loss:0.00004, loss_test:0.01981, lr:6.00e-02, fs:0.65700 (r=0.782,p=0.567),  time:37.037, tt:259.257\n",
      "Ep:7, loss:0.00004, loss_test:0.01907, lr:6.00e-02, fs:0.66346 (r=0.793,p=0.570),  time:37.375, tt:299.001\n",
      "Ep:8, loss:0.00003, loss_test:0.01797, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:37.409, tt:336.684\n",
      "Ep:9, loss:0.00003, loss_test:0.01733, lr:6.00e-02, fs:0.67811 (r=0.908,p=0.541),  time:37.872, tt:378.719\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01678, lr:6.00e-02, fs:0.69683 (r=0.885,p=0.575),  time:37.776, tt:415.531\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.73077 (r=0.874,p=0.628),  time:37.925, tt:455.100\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.74112 (r=0.839,p=0.664),  time:38.144, tt:495.870\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.73196 (r=0.816,p=0.664),  time:38.095, tt:533.323\n",
      "Ep:14, loss:0.00003, loss_test:0.01509, lr:6.00e-02, fs:0.74112 (r=0.839,p=0.664),  time:38.205, tt:573.070\n",
      "Ep:15, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.75248 (r=0.874,p=0.661),  time:38.284, tt:612.537\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01428, lr:6.00e-02, fs:0.75622 (r=0.874,p=0.667),  time:38.368, tt:652.262\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01410, lr:6.00e-02, fs:0.75897 (r=0.851,p=0.685),  time:38.441, tt:691.938\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.77487 (r=0.851,p=0.712),  time:38.343, tt:728.513\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.77895 (r=0.851,p=0.718),  time:38.337, tt:766.747\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:38.282, tt:803.913\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.80628 (r=0.885,p=0.740),  time:38.287, tt:842.311\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:38.413, tt:883.496\n",
      "Ep:23, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.79787 (r=0.862,p=0.743),  time:38.360, tt:920.639\n",
      "Ep:24, loss:0.00002, loss_test:0.01335, lr:6.00e-02, fs:0.80645 (r=0.862,p=0.758),  time:38.400, tt:959.992\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.81081 (r=0.862,p=0.765),  time:38.468, tt:1000.179\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01326, lr:6.00e-02, fs:0.81081 (r=0.862,p=0.765),  time:38.507, tt:1039.701\n",
      "Ep:27, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:38.566, tt:1079.844\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:38.581, tt:1118.839\n",
      "Ep:29, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:38.633, tt:1158.976\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.01337, lr:6.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:38.589, tt:1196.272\n",
      "Ep:31, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:38.613, tt:1235.607\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00001, loss_test:0.01342, lr:6.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:38.591, tt:1273.497\n",
      "Ep:33, loss:0.00001, loss_test:0.01345, lr:6.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:38.635, tt:1313.588\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00001, loss_test:0.01352, lr:6.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:38.631, tt:1352.077\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00001, loss_test:0.01360, lr:6.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:38.749, tt:1394.951\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00001, loss_test:0.01369, lr:6.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:38.763, tt:1434.248\n",
      "Ep:37, loss:0.00001, loss_test:0.01373, lr:6.00e-02, fs:0.82222 (r=0.851,p=0.796),  time:38.768, tt:1473.175\n",
      "Ep:38, loss:0.00001, loss_test:0.01383, lr:6.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:38.788, tt:1512.721\n",
      "Ep:39, loss:0.00001, loss_test:0.01395, lr:6.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:38.793, tt:1551.728\n",
      "Ep:40, loss:0.00001, loss_test:0.01405, lr:6.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:38.749, tt:1588.715\n",
      "Ep:41, loss:0.00001, loss_test:0.01416, lr:6.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:38.738, tt:1626.997\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01423, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.714, tt:1664.693\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01430, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.721, tt:1703.719\n",
      "Ep:44, loss:0.00001, loss_test:0.01441, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.697, tt:1741.362\n",
      "Ep:45, loss:0.00001, loss_test:0.01451, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.686, tt:1779.570\n",
      "Ep:46, loss:0.00001, loss_test:0.01461, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.684, tt:1818.169\n",
      "Ep:47, loss:0.00001, loss_test:0.01474, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.712, tt:1858.197\n",
      "Ep:48, loss:0.00001, loss_test:0.01486, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:38.732, tt:1897.861\n",
      "Ep:49, loss:0.00001, loss_test:0.01503, lr:6.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:38.744, tt:1937.204\n",
      "Ep:50, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:38.787, tt:1978.126\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01531, lr:6.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:38.782, tt:2016.653\n",
      "Ep:52, loss:0.00001, loss_test:0.01548, lr:6.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:38.804, tt:2056.631\n",
      "Ep:53, loss:0.00001, loss_test:0.01573, lr:6.00e-02, fs:0.84524 (r=0.816,p=0.877),  time:38.797, tt:2095.053\n",
      "Ep:54, loss:0.00001, loss_test:0.01586, lr:6.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:38.799, tt:2133.967\n",
      "Ep:55, loss:0.00001, loss_test:0.01596, lr:6.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:38.777, tt:2171.511\n",
      "Ep:56, loss:0.00001, loss_test:0.01607, lr:6.00e-02, fs:0.85542 (r=0.816,p=0.899),  time:38.771, tt:2209.934\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01633, lr:6.00e-02, fs:0.86061 (r=0.816,p=0.910),  time:38.796, tt:2250.143\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.86585 (r=0.816,p=0.922),  time:38.780, tt:2288.027\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01661, lr:6.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:38.778, tt:2326.706\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01683, lr:6.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:38.773, tt:2365.135\n",
      "Ep:61, loss:0.00001, loss_test:0.01694, lr:6.00e-02, fs:0.86420 (r=0.805,p=0.933),  time:38.779, tt:2404.274\n",
      "Ep:62, loss:0.00000, loss_test:0.01704, lr:6.00e-02, fs:0.86420 (r=0.805,p=0.933),  time:38.800, tt:2444.397\n",
      "Ep:63, loss:0.00000, loss_test:0.01726, lr:6.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:38.800, tt:2483.197\n",
      "Ep:64, loss:0.00000, loss_test:0.01751, lr:6.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:38.779, tt:2520.632\n",
      "Ep:65, loss:0.00000, loss_test:0.01768, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:38.781, tt:2559.533\n",
      "Ep:66, loss:0.00000, loss_test:0.01782, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:38.769, tt:2597.516\n",
      "Ep:67, loss:0.00000, loss_test:0.01804, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:38.795, tt:2638.039\n",
      "Ep:68, loss:0.00000, loss_test:0.01822, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:38.797, tt:2676.990\n",
      "Ep:69, loss:0.00000, loss_test:0.01835, lr:6.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:38.916, tt:2724.089\n",
      "Ep:70, loss:0.00000, loss_test:0.01849, lr:6.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:38.912, tt:2762.719\n",
      "Ep:71, loss:0.00000, loss_test:0.01873, lr:5.94e-02, fs:0.86076 (r=0.782,p=0.958),  time:38.941, tt:2803.746\n",
      "Ep:72, loss:0.00000, loss_test:0.01889, lr:5.88e-02, fs:0.86076 (r=0.782,p=0.958),  time:38.940, tt:2842.647\n",
      "Ep:73, loss:0.00000, loss_test:0.01918, lr:5.82e-02, fs:0.85350 (r=0.770,p=0.957),  time:38.944, tt:2881.867\n",
      "Ep:74, loss:0.00000, loss_test:0.01915, lr:5.76e-02, fs:0.85350 (r=0.770,p=0.957),  time:38.980, tt:2923.508\n",
      "Ep:75, loss:0.00000, loss_test:0.01941, lr:5.71e-02, fs:0.84615 (r=0.759,p=0.957),  time:38.987, tt:2962.975\n",
      "Ep:76, loss:0.00000, loss_test:0.01948, lr:5.65e-02, fs:0.85350 (r=0.770,p=0.957),  time:38.988, tt:3002.080\n",
      "Ep:77, loss:0.00000, loss_test:0.01971, lr:5.59e-02, fs:0.84615 (r=0.759,p=0.957),  time:38.998, tt:3041.832\n",
      "Ep:78, loss:0.00000, loss_test:0.01989, lr:5.54e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.003, tt:3081.269\n",
      "Ep:79, loss:0.00000, loss_test:0.02007, lr:5.48e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.016, tt:3121.285\n",
      "Ep:80, loss:0.00000, loss_test:0.02004, lr:5.43e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.023, tt:3160.893\n",
      "Ep:81, loss:0.00000, loss_test:0.02022, lr:5.37e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.040, tt:3201.305\n",
      "Ep:82, loss:0.00000, loss_test:0.02050, lr:5.32e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.062, tt:3242.112\n",
      "Ep:83, loss:0.00000, loss_test:0.02060, lr:5.27e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.071, tt:3281.936\n",
      "Ep:84, loss:0.00000, loss_test:0.02077, lr:5.21e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.070, tt:3320.934\n",
      "Ep:85, loss:0.00000, loss_test:0.02080, lr:5.16e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.032, tt:3356.724\n",
      "Ep:86, loss:0.00000, loss_test:0.02100, lr:5.11e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.027, tt:3395.309\n",
      "Ep:87, loss:0.00000, loss_test:0.02098, lr:5.06e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.017, tt:3433.487\n",
      "Ep:88, loss:0.00000, loss_test:0.02122, lr:5.01e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.012, tt:3472.074\n",
      "Ep:89, loss:0.00000, loss_test:0.02135, lr:4.96e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.001, tt:3510.099\n",
      "Ep:90, loss:0.00000, loss_test:0.02154, lr:4.91e-02, fs:0.85161 (r=0.759,p=0.971),  time:38.996, tt:3548.628\n",
      "Ep:91, loss:0.00000, loss_test:0.02148, lr:4.86e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.045, tt:3592.150\n",
      "Ep:92, loss:0.00000, loss_test:0.02172, lr:4.81e-02, fs:0.85161 (r=0.759,p=0.971),  time:39.054, tt:3632.012\n",
      "Ep:93, loss:0.00000, loss_test:0.02176, lr:4.76e-02, fs:0.84416 (r=0.747,p=0.970),  time:39.057, tt:3671.390\n",
      "Ep:94, loss:0.00000, loss_test:0.02198, lr:4.71e-02, fs:0.84416 (r=0.747,p=0.970),  time:39.064, tt:3711.116\n",
      "Ep:95, loss:0.00000, loss_test:0.02195, lr:4.67e-02, fs:0.84416 (r=0.747,p=0.970),  time:39.053, tt:3749.075\n",
      "Ep:96, loss:0.00000, loss_test:0.02218, lr:4.62e-02, fs:0.84416 (r=0.747,p=0.970),  time:39.078, tt:3790.603\n",
      "Ep:97, loss:0.00000, loss_test:0.02231, lr:4.57e-02, fs:0.83660 (r=0.736,p=0.970),  time:39.089, tt:3830.706\n",
      "Ep:98, loss:0.00000, loss_test:0.02224, lr:4.53e-02, fs:0.83660 (r=0.736,p=0.970),  time:39.117, tt:3872.584\n",
      "Ep:99, loss:0.00000, loss_test:0.02242, lr:4.48e-02, fs:0.83660 (r=0.736,p=0.970),  time:39.127, tt:3912.723\n",
      "Ep:100, loss:0.00000, loss_test:0.02253, lr:4.44e-02, fs:0.83660 (r=0.736,p=0.970),  time:39.135, tt:3952.654\n",
      "Ep:101, loss:0.00000, loss_test:0.02274, lr:4.39e-02, fs:0.83660 (r=0.736,p=0.970),  time:39.127, tt:3990.994\n",
      "Ep:102, loss:0.00000, loss_test:0.02271, lr:4.35e-02, fs:0.83660 (r=0.736,p=0.970),  time:39.143, tt:4031.775\n",
      "Ep:103, loss:0.00000, loss_test:0.02288, lr:4.31e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.158, tt:4072.458\n",
      "Ep:104, loss:0.00000, loss_test:0.02282, lr:4.26e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.180, tt:4113.878\n",
      "Ep:105, loss:0.00000, loss_test:0.02301, lr:4.22e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.188, tt:4153.889\n",
      "Ep:106, loss:0.00000, loss_test:0.02309, lr:4.18e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.186, tt:4192.853\n",
      "Ep:107, loss:0.00000, loss_test:0.02316, lr:4.14e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.189, tt:4232.389\n",
      "Ep:108, loss:0.00000, loss_test:0.02322, lr:4.10e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.193, tt:4271.984\n",
      "Ep:109, loss:0.00000, loss_test:0.02318, lr:4.05e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.191, tt:4310.987\n",
      "Ep:110, loss:0.00000, loss_test:0.02343, lr:4.01e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.172, tt:4348.082\n",
      "Ep:111, loss:0.00000, loss_test:0.02344, lr:3.97e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.176, tt:4387.669\n",
      "Ep:112, loss:0.00000, loss_test:0.02354, lr:3.93e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.207, tt:4430.339\n",
      "Ep:113, loss:0.00000, loss_test:0.02360, lr:3.89e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.222, tt:4471.350\n",
      "Ep:114, loss:0.00000, loss_test:0.02364, lr:3.86e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.223, tt:4510.668\n",
      "Ep:115, loss:0.00000, loss_test:0.02376, lr:3.82e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.227, tt:4550.327\n",
      "Ep:116, loss:0.00000, loss_test:0.02378, lr:3.78e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.229, tt:4589.762\n",
      "Ep:117, loss:0.00000, loss_test:0.02387, lr:3.74e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.242, tt:4630.604\n",
      "Ep:118, loss:0.00000, loss_test:0.02395, lr:3.70e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.241, tt:4669.681\n",
      "Ep:119, loss:0.00000, loss_test:0.02400, lr:3.67e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.238, tt:4708.542\n",
      "Ep:120, loss:0.00000, loss_test:0.02401, lr:3.63e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.238, tt:4747.743\n",
      "Ep:121, loss:0.00000, loss_test:0.02411, lr:3.59e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.237, tt:4786.955\n",
      "Ep:122, loss:0.00000, loss_test:0.02421, lr:3.56e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.245, tt:4827.077\n",
      "Ep:123, loss:0.00000, loss_test:0.02426, lr:3.52e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.230, tt:4864.544\n",
      "Ep:124, loss:0.00000, loss_test:0.02431, lr:3.49e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.240, tt:4905.035\n",
      "Ep:125, loss:0.00000, loss_test:0.02426, lr:3.45e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.253, tt:4945.910\n",
      "Ep:126, loss:0.00000, loss_test:0.02440, lr:3.42e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.260, tt:4985.956\n",
      "Ep:127, loss:0.00000, loss_test:0.02441, lr:3.38e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.269, tt:5026.461\n",
      "Ep:128, loss:0.00000, loss_test:0.02454, lr:3.35e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.277, tt:5066.748\n",
      "Ep:129, loss:0.00000, loss_test:0.02449, lr:3.32e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.292, tt:5107.928\n",
      "Ep:130, loss:0.00000, loss_test:0.02455, lr:3.28e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.303, tt:5148.635\n",
      "Ep:131, loss:0.00000, loss_test:0.02469, lr:3.25e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.306, tt:5188.390\n",
      "Ep:132, loss:0.00000, loss_test:0.02465, lr:3.22e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.321, tt:5229.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.02475, lr:3.19e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.365, tt:5274.912\n",
      "Ep:134, loss:0.00000, loss_test:0.02478, lr:3.15e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.377, tt:5315.963\n",
      "Ep:135, loss:0.00000, loss_test:0.02485, lr:3.12e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.399, tt:5358.210\n",
      "Ep:136, loss:0.00000, loss_test:0.02485, lr:3.09e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.392, tt:5396.673\n",
      "Ep:137, loss:0.00000, loss_test:0.02487, lr:3.06e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.397, tt:5436.762\n",
      "Ep:138, loss:0.00000, loss_test:0.02503, lr:3.03e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.411, tt:5478.145\n",
      "Ep:139, loss:0.00000, loss_test:0.02501, lr:3.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.418, tt:5518.500\n",
      "Ep:140, loss:0.00000, loss_test:0.02507, lr:2.97e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.417, tt:5557.868\n",
      "Ep:141, loss:0.00000, loss_test:0.02508, lr:2.94e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.427, tt:5598.591\n",
      "Ep:142, loss:0.00000, loss_test:0.02510, lr:2.91e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.424, tt:5637.586\n",
      "Ep:143, loss:0.00000, loss_test:0.02520, lr:2.88e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.437, tt:5678.982\n",
      "Ep:144, loss:0.00000, loss_test:0.02519, lr:2.85e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.437, tt:5718.370\n",
      "Ep:145, loss:0.00000, loss_test:0.02529, lr:2.82e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.452, tt:5759.969\n",
      "Ep:146, loss:0.00000, loss_test:0.02529, lr:2.80e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.470, tt:5802.091\n",
      "Ep:147, loss:0.00000, loss_test:0.02536, lr:2.77e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.490, tt:5844.504\n",
      "Ep:148, loss:0.00000, loss_test:0.02540, lr:2.74e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.517, tt:5887.968\n",
      "Ep:149, loss:0.00000, loss_test:0.02536, lr:2.71e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.542, tt:5931.322\n",
      "Ep:150, loss:0.00000, loss_test:0.02544, lr:2.69e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.585, tt:5977.377\n",
      "Ep:151, loss:0.00000, loss_test:0.02549, lr:2.66e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.592, tt:6017.947\n",
      "Ep:152, loss:0.00000, loss_test:0.02550, lr:2.63e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.629, tt:6063.277\n",
      "Ep:153, loss:0.00000, loss_test:0.02558, lr:2.61e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.653, tt:6106.590\n",
      "Ep:154, loss:0.00000, loss_test:0.02555, lr:2.58e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.668, tt:6148.545\n",
      "Ep:155, loss:0.00000, loss_test:0.02557, lr:2.55e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.702, tt:6193.499\n",
      "Ep:156, loss:0.00000, loss_test:0.02565, lr:2.53e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.721, tt:6236.212\n",
      "Ep:157, loss:0.00000, loss_test:0.02565, lr:2.50e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.738, tt:6278.610\n",
      "Ep:158, loss:0.00000, loss_test:0.02571, lr:2.48e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.763, tt:6322.340\n",
      "Ep:159, loss:0.00000, loss_test:0.02573, lr:2.45e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.772, tt:6363.491\n",
      "Ep:160, loss:0.00000, loss_test:0.02573, lr:2.43e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.787, tt:6405.711\n",
      "Ep:161, loss:0.00000, loss_test:0.02581, lr:2.40e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.799, tt:6447.424\n",
      "Ep:162, loss:0.00000, loss_test:0.02582, lr:2.38e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.817, tt:6490.143\n",
      "Ep:163, loss:0.00000, loss_test:0.02586, lr:2.36e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.829, tt:6531.894\n",
      "Ep:164, loss:0.00000, loss_test:0.02592, lr:2.33e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.828, tt:6571.538\n",
      "Ep:165, loss:0.00000, loss_test:0.02591, lr:2.31e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.833, tt:6612.208\n",
      "Ep:166, loss:0.00000, loss_test:0.02595, lr:2.29e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.845, tt:6654.087\n",
      "Ep:167, loss:0.00000, loss_test:0.02597, lr:2.26e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.875, tt:6698.969\n",
      "Ep:168, loss:0.00000, loss_test:0.02599, lr:2.24e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.879, tt:6739.480\n",
      "Ep:169, loss:0.00000, loss_test:0.02606, lr:2.22e-02, fs:0.83444 (r=0.724,p=0.984),  time:39.880, tt:6779.674\n",
      "Ep:170, loss:0.00000, loss_test:0.02608, lr:2.20e-02, fs:0.82667 (r=0.713,p=0.984),  time:39.890, tt:6821.257\n",
      "Ep:171, loss:0.00000, loss_test:0.02609, lr:2.17e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.897, tt:6862.327\n",
      "Ep:172, loss:0.00000, loss_test:0.02610, lr:2.15e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.906, tt:6903.667\n",
      "Ep:173, loss:0.00000, loss_test:0.02611, lr:2.13e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.903, tt:6943.170\n",
      "Ep:174, loss:0.00000, loss_test:0.02614, lr:2.11e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.903, tt:6983.104\n",
      "Ep:175, loss:0.00000, loss_test:0.02620, lr:2.09e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.904, tt:7023.084\n",
      "Ep:176, loss:0.00000, loss_test:0.02621, lr:2.07e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.912, tt:7064.458\n",
      "Ep:177, loss:0.00000, loss_test:0.02623, lr:2.05e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.910, tt:7103.952\n",
      "Ep:178, loss:0.00000, loss_test:0.02623, lr:2.03e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.903, tt:7142.567\n",
      "Ep:179, loss:0.00000, loss_test:0.02625, lr:2.01e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.909, tt:7183.622\n",
      "Ep:180, loss:0.00000, loss_test:0.02628, lr:1.99e-02, fs:0.81879 (r=0.701,p=0.984),  time:39.900, tt:7221.890\n",
      "Ep:181, loss:0.00000, loss_test:0.02632, lr:1.97e-02, fs:0.81081 (r=0.690,p=0.984),  time:39.905, tt:7262.654\n",
      "Ep:182, loss:0.00000, loss_test:0.02632, lr:1.95e-02, fs:0.81081 (r=0.690,p=0.984),  time:39.909, tt:7303.297\n",
      "Ep:183, loss:0.00000, loss_test:0.02635, lr:1.93e-02, fs:0.81081 (r=0.690,p=0.984),  time:39.916, tt:7344.525\n",
      "Ep:184, loss:0.00000, loss_test:0.02636, lr:1.91e-02, fs:0.81081 (r=0.690,p=0.984),  time:39.921, tt:7385.420\n",
      "Ep:185, loss:0.00000, loss_test:0.02636, lr:1.89e-02, fs:0.80272 (r=0.678,p=0.983),  time:39.920, tt:7425.135\n",
      "Ep:186, loss:0.00000, loss_test:0.02639, lr:1.87e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.931, tt:7467.145\n",
      "Ep:187, loss:0.00000, loss_test:0.02642, lr:1.85e-02, fs:0.80272 (r=0.678,p=0.983),  time:39.941, tt:7508.827\n",
      "Ep:188, loss:0.00000, loss_test:0.02643, lr:1.83e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.955, tt:7551.537\n",
      "Ep:189, loss:0.00000, loss_test:0.02646, lr:1.81e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.954, tt:7591.238\n",
      "Ep:190, loss:0.00000, loss_test:0.02647, lr:1.80e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.956, tt:7631.512\n",
      "Ep:191, loss:0.00000, loss_test:0.02651, lr:1.78e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.955, tt:7671.372\n",
      "Ep:192, loss:0.00000, loss_test:0.02652, lr:1.76e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.955, tt:7711.406\n",
      "Ep:193, loss:0.00000, loss_test:0.02652, lr:1.74e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.963, tt:7752.833\n",
      "Ep:194, loss:0.00000, loss_test:0.02655, lr:1.73e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.963, tt:7792.817\n",
      "Ep:195, loss:0.00000, loss_test:0.02658, lr:1.71e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.958, tt:7831.675\n",
      "Ep:196, loss:0.00000, loss_test:0.02657, lr:1.69e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.981, tt:7876.177\n",
      "Ep:197, loss:0.00000, loss_test:0.02659, lr:1.67e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.977, tt:7915.419\n",
      "Ep:198, loss:0.00000, loss_test:0.02661, lr:1.66e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.973, tt:7954.630\n",
      "Ep:199, loss:0.00000, loss_test:0.02662, lr:1.64e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.966, tt:7993.293\n",
      "Ep:200, loss:0.00000, loss_test:0.02664, lr:1.62e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.969, tt:8033.750\n",
      "Ep:201, loss:0.00000, loss_test:0.02667, lr:1.61e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.968, tt:8073.488\n",
      "Ep:202, loss:0.00000, loss_test:0.02669, lr:1.59e-02, fs:0.78621 (r=0.655,p=0.983),  time:39.973, tt:8114.437\n",
      "Ep:203, loss:0.00000, loss_test:0.02668, lr:1.58e-02, fs:0.79452 (r=0.667,p=0.983),  time:39.966, tt:8152.992\n",
      "Ep:204, loss:0.00000, loss_test:0.02671, lr:1.56e-02, fs:0.78621 (r=0.655,p=0.983),  time:39.977, tt:8195.230\n",
      "Ep:205, loss:0.00000, loss_test:0.02673, lr:1.54e-02, fs:0.78621 (r=0.655,p=0.983),  time:39.969, tt:8233.557\n",
      "Ep:206, loss:0.00000, loss_test:0.02673, lr:1.53e-02, fs:0.77778 (r=0.644,p=0.982),  time:39.971, tt:8273.959\n",
      "Ep:207, loss:0.00000, loss_test:0.02676, lr:1.51e-02, fs:0.77778 (r=0.644,p=0.982),  time:39.970, tt:8313.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.02678, lr:1.50e-02, fs:0.77778 (r=0.644,p=0.982),  time:39.973, tt:8354.260\n",
      "Ep:209, loss:0.00000, loss_test:0.02678, lr:1.48e-02, fs:0.77778 (r=0.644,p=0.982),  time:39.956, tt:8390.810\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14156, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.397, tt:33.397\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14019, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.322, tt:72.644\n",
      "Ep:2, loss:0.00028, loss_test:0.13782, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.498, tt:115.495\n",
      "Ep:3, loss:0.00027, loss_test:0.13396, lr:1.00e-02, fs:0.67188 (r=0.989,p=0.509),  time:39.481, tt:157.923\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.12764, lr:1.00e-02, fs:0.66393 (r=0.931,p=0.516),  time:40.393, tt:201.967\n",
      "Ep:5, loss:0.00026, loss_test:0.11929, lr:1.00e-02, fs:0.66957 (r=0.885,p=0.538),  time:40.684, tt:244.101\n",
      "Ep:6, loss:0.00024, loss_test:0.11233, lr:1.00e-02, fs:0.67337 (r=0.770,p=0.598),  time:40.989, tt:286.926\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10923, lr:1.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:41.088, tt:328.703\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10776, lr:1.00e-02, fs:0.67391 (r=0.713,p=0.639),  time:41.253, tt:371.281\n",
      "Ep:9, loss:0.00021, loss_test:0.10543, lr:1.00e-02, fs:0.69110 (r=0.759,p=0.635),  time:41.447, tt:414.471\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10099, lr:1.00e-02, fs:0.71038 (r=0.747,p=0.677),  time:41.494, tt:456.431\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09948, lr:1.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:41.607, tt:499.278\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09616, lr:1.00e-02, fs:0.73514 (r=0.782,p=0.694),  time:41.675, tt:541.771\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09193, lr:1.00e-02, fs:0.74595 (r=0.793,p=0.704),  time:41.694, tt:583.721\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.08825, lr:1.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:41.727, tt:625.899\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08637, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:41.856, tt:669.693\n",
      "Ep:16, loss:0.00015, loss_test:0.08389, lr:1.00e-02, fs:0.82609 (r=0.874,p=0.784),  time:42.008, tt:714.132\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.08287, lr:1.00e-02, fs:0.83060 (r=0.874,p=0.792),  time:42.110, tt:757.974\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08228, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:42.196, tt:801.722\n",
      "Ep:19, loss:0.00013, loss_test:0.08003, lr:1.00e-02, fs:0.84916 (r=0.874,p=0.826),  time:42.209, tt:844.173\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.07925, lr:1.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:42.238, tt:887.001\n",
      "Ep:21, loss:0.00011, loss_test:0.07624, lr:1.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:42.283, tt:930.217\n",
      "Ep:22, loss:0.00011, loss_test:0.07566, lr:1.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:42.318, tt:973.303\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.07369, lr:1.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:42.369, tt:1016.853\n",
      "Ep:24, loss:0.00010, loss_test:0.07329, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:42.375, tt:1059.380\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.07252, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:42.490, tt:1104.737\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00008, loss_test:0.07061, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:42.650, tt:1151.551\n",
      "Ep:27, loss:0.00008, loss_test:0.07033, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:42.657, tt:1194.402\n",
      "Ep:28, loss:0.00007, loss_test:0.06963, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:42.641, tt:1236.582\n",
      "Ep:29, loss:0.00007, loss_test:0.06801, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:42.738, tt:1282.145\n",
      "Ep:30, loss:0.00007, loss_test:0.06820, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:42.793, tt:1326.573\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.07174, lr:1.00e-02, fs:0.89941 (r=0.874,p=0.927),  time:42.821, tt:1370.262\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.06595, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:42.854, tt:1414.172\n",
      "Ep:33, loss:0.00006, loss_test:0.06879, lr:1.00e-02, fs:0.89941 (r=0.874,p=0.927),  time:42.882, tt:1457.982\n",
      "Ep:34, loss:0.00005, loss_test:0.06607, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:42.851, tt:1499.784\n",
      "Ep:35, loss:0.00005, loss_test:0.06836, lr:1.00e-02, fs:0.89941 (r=0.874,p=0.927),  time:42.867, tt:1543.203\n",
      "Ep:36, loss:0.00004, loss_test:0.06349, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:42.822, tt:1584.417\n",
      "Ep:37, loss:0.00004, loss_test:0.07000, lr:1.00e-02, fs:0.91018 (r=0.874,p=0.950),  time:42.765, tt:1625.077\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00004, loss_test:0.06301, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:42.773, tt:1668.153\n",
      "Ep:39, loss:0.00004, loss_test:0.06928, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.767, tt:1710.664\n",
      "Ep:40, loss:0.00003, loss_test:0.06596, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.763, tt:1753.277\n",
      "Ep:41, loss:0.00003, loss_test:0.06477, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.732, tt:1794.751\n",
      "Ep:42, loss:0.00003, loss_test:0.06383, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.678, tt:1835.163\n",
      "Ep:43, loss:0.00003, loss_test:0.06558, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.661, tt:1877.098\n",
      "Ep:44, loss:0.00003, loss_test:0.06623, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.634, tt:1918.517\n",
      "Ep:45, loss:0.00002, loss_test:0.06373, lr:1.00e-02, fs:0.89820 (r=0.862,p=0.938),  time:42.607, tt:1959.932\n",
      "Ep:46, loss:0.00002, loss_test:0.07019, lr:1.00e-02, fs:0.91463 (r=0.862,p=0.974),  time:42.581, tt:2001.291\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.06458, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.554, tt:2042.575\n",
      "Ep:48, loss:0.00002, loss_test:0.07313, lr:1.00e-02, fs:0.90000 (r=0.828,p=0.986),  time:42.541, tt:2084.509\n",
      "Ep:49, loss:0.00002, loss_test:0.06321, lr:1.00e-02, fs:0.89820 (r=0.862,p=0.938),  time:42.587, tt:2129.357\n",
      "Ep:50, loss:0.00002, loss_test:0.07328, lr:1.00e-02, fs:0.86452 (r=0.770,p=0.985),  time:42.521, tt:2168.567\n",
      "Ep:51, loss:0.00002, loss_test:0.06521, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:42.489, tt:2209.413\n",
      "Ep:52, loss:0.00002, loss_test:0.06873, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:42.462, tt:2250.475\n",
      "Ep:53, loss:0.00002, loss_test:0.06490, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.423, tt:2290.834\n",
      "Ep:54, loss:0.00002, loss_test:0.06833, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:42.443, tt:2334.374\n",
      "Ep:55, loss:0.00002, loss_test:0.07003, lr:1.00e-02, fs:0.88608 (r=0.805,p=0.986),  time:42.421, tt:2375.557\n",
      "Ep:56, loss:0.00001, loss_test:0.06583, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:42.386, tt:2416.020\n",
      "Ep:57, loss:0.00001, loss_test:0.07078, lr:1.00e-02, fs:0.88050 (r=0.805,p=0.972),  time:42.364, tt:2457.096\n",
      "Ep:58, loss:0.00001, loss_test:0.06598, lr:9.90e-03, fs:0.90909 (r=0.862,p=0.962),  time:42.343, tt:2498.230\n",
      "Ep:59, loss:0.00001, loss_test:0.07003, lr:9.80e-03, fs:0.88608 (r=0.805,p=0.986),  time:42.345, tt:2540.713\n",
      "Ep:60, loss:0.00001, loss_test:0.06533, lr:9.70e-03, fs:0.90909 (r=0.862,p=0.962),  time:42.321, tt:2581.601\n",
      "Ep:61, loss:0.00001, loss_test:0.07048, lr:9.61e-03, fs:0.88750 (r=0.816,p=0.973),  time:42.326, tt:2624.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.06915, lr:9.51e-03, fs:0.88750 (r=0.816,p=0.973),  time:42.287, tt:2664.083\n",
      "Ep:63, loss:0.00001, loss_test:0.06904, lr:9.41e-03, fs:0.91463 (r=0.862,p=0.974),  time:42.227, tt:2702.548\n",
      "Ep:64, loss:0.00001, loss_test:0.07191, lr:9.32e-03, fs:0.84416 (r=0.747,p=0.970),  time:42.212, tt:2743.802\n",
      "Ep:65, loss:0.00001, loss_test:0.06771, lr:9.23e-03, fs:0.91463 (r=0.862,p=0.974),  time:42.219, tt:2786.485\n",
      "Ep:66, loss:0.00001, loss_test:0.07048, lr:9.14e-03, fs:0.85897 (r=0.770,p=0.971),  time:42.193, tt:2826.900\n",
      "Ep:67, loss:0.00001, loss_test:0.06960, lr:9.04e-03, fs:0.90123 (r=0.839,p=0.973),  time:42.139, tt:2865.435\n",
      "Ep:68, loss:0.00000, loss_test:0.07027, lr:8.95e-03, fs:0.88750 (r=0.816,p=0.973),  time:42.120, tt:2906.262\n",
      "Ep:69, loss:0.00000, loss_test:0.07238, lr:8.86e-03, fs:0.83444 (r=0.724,p=0.984),  time:42.106, tt:2947.418\n",
      "Ep:70, loss:0.00000, loss_test:0.06965, lr:8.78e-03, fs:0.91463 (r=0.862,p=0.974),  time:42.065, tt:2986.588\n",
      "Ep:71, loss:0.00000, loss_test:0.07214, lr:8.69e-03, fs:0.83444 (r=0.724,p=0.984),  time:42.050, tt:3027.616\n",
      "Ep:72, loss:0.00000, loss_test:0.07027, lr:8.60e-03, fs:0.85161 (r=0.759,p=0.971),  time:42.028, tt:3068.070\n",
      "Ep:73, loss:0.00000, loss_test:0.06959, lr:8.51e-03, fs:0.87179 (r=0.782,p=0.986),  time:42.008, tt:3108.605\n",
      "Ep:74, loss:0.00000, loss_test:0.07040, lr:8.43e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.968, tt:3147.571\n",
      "Ep:75, loss:0.00000, loss_test:0.06994, lr:8.35e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.951, tt:3188.287\n",
      "Ep:76, loss:0.00000, loss_test:0.06992, lr:8.26e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.933, tt:3228.874\n",
      "Ep:77, loss:0.00000, loss_test:0.07073, lr:8.18e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.898, tt:3268.059\n",
      "Ep:78, loss:0.00000, loss_test:0.06972, lr:8.10e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.853, tt:3306.385\n",
      "Ep:79, loss:0.00000, loss_test:0.07037, lr:8.02e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.831, tt:3346.485\n",
      "Ep:80, loss:0.00000, loss_test:0.07004, lr:7.94e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.794, tt:3385.324\n",
      "Ep:81, loss:0.00000, loss_test:0.07061, lr:7.86e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.773, tt:3425.368\n",
      "Ep:82, loss:0.00000, loss_test:0.07064, lr:7.78e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.748, tt:3465.108\n",
      "Ep:83, loss:0.00000, loss_test:0.07022, lr:7.70e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.732, tt:3505.504\n",
      "Ep:84, loss:0.00000, loss_test:0.07092, lr:7.62e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.731, tt:3547.139\n",
      "Ep:85, loss:0.00000, loss_test:0.07036, lr:7.55e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.717, tt:3587.641\n",
      "Ep:86, loss:0.00000, loss_test:0.06993, lr:7.47e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.729, tt:3630.440\n",
      "Ep:87, loss:0.00000, loss_test:0.07047, lr:7.40e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.716, tt:3671.051\n",
      "Ep:88, loss:0.00000, loss_test:0.07036, lr:7.32e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.727, tt:3713.706\n",
      "Ep:89, loss:0.00000, loss_test:0.07029, lr:7.25e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.714, tt:3754.237\n",
      "Ep:90, loss:0.00000, loss_test:0.07061, lr:7.18e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.712, tt:3795.786\n",
      "Ep:91, loss:0.00000, loss_test:0.07008, lr:7.11e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.703, tt:3836.669\n",
      "Ep:92, loss:0.00000, loss_test:0.07022, lr:7.03e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.706, tt:3878.672\n",
      "Ep:93, loss:0.00000, loss_test:0.07066, lr:6.96e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.690, tt:3918.901\n",
      "Ep:94, loss:0.00000, loss_test:0.07035, lr:6.89e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.688, tt:3960.345\n",
      "Ep:95, loss:0.00000, loss_test:0.07084, lr:6.83e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.695, tt:4002.728\n",
      "Ep:96, loss:0.00000, loss_test:0.07087, lr:6.76e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.704, tt:4045.314\n",
      "Ep:97, loss:0.00000, loss_test:0.07055, lr:6.69e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.693, tt:4085.866\n",
      "Ep:98, loss:0.00000, loss_test:0.07083, lr:6.62e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.692, tt:4127.475\n",
      "Ep:99, loss:0.00000, loss_test:0.07054, lr:6.56e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.681, tt:4168.093\n",
      "Ep:100, loss:0.00000, loss_test:0.07061, lr:6.49e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.651, tt:4206.771\n",
      "Ep:101, loss:0.00000, loss_test:0.07066, lr:6.43e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.671, tt:4250.474\n",
      "Ep:102, loss:0.00000, loss_test:0.07079, lr:6.36e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.681, tt:4293.114\n",
      "Ep:103, loss:0.00000, loss_test:0.07080, lr:6.30e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.670, tt:4333.655\n",
      "Ep:104, loss:0.00000, loss_test:0.07157, lr:6.24e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.640, tt:4372.156\n",
      "Ep:105, loss:0.00000, loss_test:0.07139, lr:6.17e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.629, tt:4412.688\n",
      "Ep:106, loss:0.00000, loss_test:0.07097, lr:6.11e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.626, tt:4454.015\n",
      "Ep:107, loss:0.00000, loss_test:0.07165, lr:6.05e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.640, tt:4497.166\n",
      "Ep:108, loss:0.00000, loss_test:0.07145, lr:5.99e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.651, tt:4539.993\n",
      "Ep:109, loss:0.00000, loss_test:0.07070, lr:5.93e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.652, tt:4581.705\n",
      "Ep:110, loss:0.00000, loss_test:0.07137, lr:5.87e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.648, tt:4622.907\n",
      "Ep:111, loss:0.00000, loss_test:0.07142, lr:5.81e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.685, tt:4668.725\n",
      "Ep:112, loss:0.00000, loss_test:0.07098, lr:5.75e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.674, tt:4709.217\n",
      "Ep:113, loss:0.00000, loss_test:0.07152, lr:5.70e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.690, tt:4752.652\n",
      "Ep:114, loss:0.00000, loss_test:0.07148, lr:5.64e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.691, tt:4794.470\n",
      "Ep:115, loss:0.00000, loss_test:0.07134, lr:5.58e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.683, tt:4835.251\n",
      "Ep:116, loss:0.00000, loss_test:0.07147, lr:5.53e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.687, tt:4877.408\n",
      "Ep:117, loss:0.00000, loss_test:0.07137, lr:5.47e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.681, tt:4918.324\n",
      "Ep:118, loss:0.00000, loss_test:0.07153, lr:5.42e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.668, tt:4958.534\n",
      "Ep:119, loss:0.00000, loss_test:0.07164, lr:5.36e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.670, tt:5000.343\n",
      "Ep:120, loss:0.00000, loss_test:0.07130, lr:5.31e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.681, tt:5043.355\n",
      "Ep:121, loss:0.00000, loss_test:0.07173, lr:5.26e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.693, tt:5086.554\n",
      "Ep:122, loss:0.00000, loss_test:0.07193, lr:5.20e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.699, tt:5128.962\n",
      "Ep:123, loss:0.00000, loss_test:0.07170, lr:5.15e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.701, tt:5170.881\n",
      "Ep:124, loss:0.00000, loss_test:0.07152, lr:5.10e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.712, tt:5213.944\n",
      "Ep:125, loss:0.00000, loss_test:0.07186, lr:5.05e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.706, tt:5254.975\n",
      "Ep:126, loss:0.00000, loss_test:0.07202, lr:5.00e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.695, tt:5295.234\n",
      "Ep:127, loss:0.00000, loss_test:0.07192, lr:4.95e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.696, tt:5337.071\n",
      "Ep:128, loss:0.00000, loss_test:0.07199, lr:4.90e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.701, tt:5379.417\n",
      "Ep:129, loss:0.00000, loss_test:0.07210, lr:4.85e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.696, tt:5420.507\n",
      "Ep:130, loss:0.00000, loss_test:0.07199, lr:4.80e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.681, tt:5460.213\n",
      "Ep:131, loss:0.00000, loss_test:0.07189, lr:4.75e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.717, tt:5506.598\n",
      "Ep:132, loss:0.00000, loss_test:0.07152, lr:4.71e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.722, tt:5548.968\n",
      "Ep:133, loss:0.00000, loss_test:0.07160, lr:4.66e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.711, tt:5589.328\n",
      "Ep:134, loss:0.00000, loss_test:0.07185, lr:4.61e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.721, tt:5632.390\n",
      "Ep:135, loss:0.00000, loss_test:0.07152, lr:4.57e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.716, tt:5673.381\n",
      "Ep:136, loss:0.00000, loss_test:0.07180, lr:4.52e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.712, tt:5714.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.07186, lr:4.48e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.702, tt:5754.916\n",
      "Ep:138, loss:0.00000, loss_test:0.07190, lr:4.43e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.694, tt:5795.536\n",
      "Ep:139, loss:0.00000, loss_test:0.07173, lr:4.39e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.702, tt:5838.263\n",
      "Ep:140, loss:0.00000, loss_test:0.07156, lr:4.34e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.695, tt:5879.022\n",
      "Ep:141, loss:0.00000, loss_test:0.07182, lr:4.30e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.690, tt:5920.045\n",
      "Ep:142, loss:0.00000, loss_test:0.07166, lr:4.26e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.677, tt:5959.823\n",
      "Ep:143, loss:0.00000, loss_test:0.07177, lr:4.21e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.688, tt:6003.106\n",
      "Ep:144, loss:0.00000, loss_test:0.07152, lr:4.17e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.696, tt:6045.989\n",
      "Ep:145, loss:0.00000, loss_test:0.07177, lr:4.13e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.698, tt:6087.842\n",
      "Ep:146, loss:0.00000, loss_test:0.07172, lr:4.09e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.693, tt:6128.821\n",
      "Ep:147, loss:0.00000, loss_test:0.07148, lr:4.05e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.695, tt:6170.864\n",
      "Ep:148, loss:0.00000, loss_test:0.07179, lr:4.01e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.682, tt:6210.672\n",
      "Ep:149, loss:0.00000, loss_test:0.07152, lr:3.97e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.689, tt:6253.284\n",
      "Ep:150, loss:0.00000, loss_test:0.07142, lr:3.93e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.672, tt:6292.460\n",
      "Ep:151, loss:0.00000, loss_test:0.07220, lr:3.89e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.662, tt:6332.565\n",
      "Ep:152, loss:0.00000, loss_test:0.07193, lr:3.85e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.663, tt:6374.395\n",
      "Ep:153, loss:0.00000, loss_test:0.07136, lr:3.81e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.652, tt:6414.396\n",
      "Ep:154, loss:0.00000, loss_test:0.07170, lr:3.77e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.653, tt:6456.164\n",
      "Ep:155, loss:0.00000, loss_test:0.07202, lr:3.73e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.648, tt:6497.102\n",
      "Ep:156, loss:0.00000, loss_test:0.07157, lr:3.70e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.634, tt:6536.463\n",
      "Ep:157, loss:0.00000, loss_test:0.07163, lr:3.66e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.627, tt:6577.061\n",
      "Ep:158, loss:0.00000, loss_test:0.07217, lr:3.62e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.617, tt:6617.115\n",
      "Ep:159, loss:0.00000, loss_test:0.07193, lr:3.59e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.608, tt:6657.311\n",
      "Ep:160, loss:0.00000, loss_test:0.07158, lr:3.55e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.590, tt:6695.987\n",
      "Ep:161, loss:0.00000, loss_test:0.07155, lr:3.52e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.587, tt:6737.155\n",
      "Ep:162, loss:0.00000, loss_test:0.07156, lr:3.48e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.582, tt:6777.789\n",
      "Ep:163, loss:0.00000, loss_test:0.07143, lr:3.45e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.573, tt:6818.019\n",
      "Ep:164, loss:0.00000, loss_test:0.07149, lr:3.41e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.569, tt:6858.882\n",
      "Ep:165, loss:0.00000, loss_test:0.07128, lr:3.38e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.562, tt:6899.331\n",
      "Ep:166, loss:0.00000, loss_test:0.07129, lr:3.34e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.556, tt:6939.894\n",
      "Ep:167, loss:0.00000, loss_test:0.07176, lr:3.31e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.543, tt:6979.172\n",
      "Ep:168, loss:0.00000, loss_test:0.07159, lr:3.28e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.541, tt:7020.483\n",
      "Ep:169, loss:0.00000, loss_test:0.07116, lr:3.24e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.542, tt:7062.221\n",
      "Ep:170, loss:0.00000, loss_test:0.07198, lr:3.21e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.529, tt:7101.389\n",
      "Ep:171, loss:0.00000, loss_test:0.07206, lr:3.18e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.518, tt:7141.117\n",
      "Ep:172, loss:0.00000, loss_test:0.07154, lr:3.15e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.547, tt:7187.572\n",
      "Ep:173, loss:0.00000, loss_test:0.07153, lr:3.12e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.549, tt:7229.562\n",
      "Ep:174, loss:0.00000, loss_test:0.07182, lr:3.09e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.554, tt:7272.009\n",
      "Ep:175, loss:0.00000, loss_test:0.07171, lr:3.05e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.537, tt:7310.559\n",
      "Ep:176, loss:0.00000, loss_test:0.07130, lr:3.02e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.542, tt:7353.008\n",
      "Ep:177, loss:0.00000, loss_test:0.07107, lr:2.99e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.537, tt:7393.535\n",
      "Ep:178, loss:0.00000, loss_test:0.07129, lr:2.96e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.532, tt:7434.253\n",
      "Ep:179, loss:0.00000, loss_test:0.07155, lr:2.93e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.529, tt:7475.186\n",
      "Ep:180, loss:0.00000, loss_test:0.07137, lr:2.90e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.528, tt:7516.548\n",
      "Ep:181, loss:0.00000, loss_test:0.07111, lr:2.88e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.530, tt:7558.463\n",
      "Ep:182, loss:0.00000, loss_test:0.07118, lr:2.85e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.526, tt:7599.282\n",
      "Ep:183, loss:0.00000, loss_test:0.07133, lr:2.82e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.531, tt:7641.748\n",
      "Ep:184, loss:0.00000, loss_test:0.07135, lr:2.79e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.524, tt:7681.957\n",
      "Ep:185, loss:0.00000, loss_test:0.07129, lr:2.76e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.527, tt:7724.100\n",
      "Ep:186, loss:0.00000, loss_test:0.07113, lr:2.73e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.522, tt:7764.672\n",
      "Ep:187, loss:0.00000, loss_test:0.07125, lr:2.71e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.516, tt:7804.955\n",
      "Ep:188, loss:0.00000, loss_test:0.07124, lr:2.68e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.514, tt:7846.086\n",
      "Ep:189, loss:0.00000, loss_test:0.07128, lr:2.65e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.520, tt:7888.726\n",
      "Ep:190, loss:0.00000, loss_test:0.07126, lr:2.63e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.528, tt:7931.876\n",
      "Ep:191, loss:0.00000, loss_test:0.07119, lr:2.60e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.532, tt:7974.075\n",
      "Ep:192, loss:0.00000, loss_test:0.07117, lr:2.57e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.560, tt:8021.138\n",
      "Ep:193, loss:0.00000, loss_test:0.07110, lr:2.55e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.572, tt:8064.957\n",
      "Ep:194, loss:0.00000, loss_test:0.07119, lr:2.52e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.578, tt:8107.648\n",
      "Ep:195, loss:0.00000, loss_test:0.07105, lr:2.50e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.592, tt:8152.060\n",
      "Ep:196, loss:0.00000, loss_test:0.07119, lr:2.47e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.602, tt:8195.650\n",
      "Ep:197, loss:0.00000, loss_test:0.07144, lr:2.45e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.608, tt:8238.340\n",
      "Ep:198, loss:0.00000, loss_test:0.07135, lr:2.42e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.614, tt:8281.270\n",
      "Ep:199, loss:0.00000, loss_test:0.07108, lr:2.40e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.617, tt:8323.313\n",
      "Ep:200, loss:0.00000, loss_test:0.07126, lr:2.38e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.620, tt:8365.677\n",
      "Ep:201, loss:0.00000, loss_test:0.07161, lr:2.35e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.633, tt:8409.881\n",
      "Ep:202, loss:0.00000, loss_test:0.07152, lr:2.33e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.636, tt:8452.065\n",
      "Ep:203, loss:0.00000, loss_test:0.07121, lr:2.31e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.619, tt:8490.340\n",
      "Ep:204, loss:0.00000, loss_test:0.07098, lr:2.28e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.599, tt:8527.838\n",
      "Ep:205, loss:0.00000, loss_test:0.07094, lr:2.26e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.578, tt:8565.132\n",
      "Ep:206, loss:0.00000, loss_test:0.07106, lr:2.24e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.558, tt:8602.415\n",
      "Ep:207, loss:0.00000, loss_test:0.07113, lr:2.21e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.532, tt:8638.747\n",
      "Ep:208, loss:0.00000, loss_test:0.07099, lr:2.19e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.443, tt:8661.643\n",
      "Ep:209, loss:0.00000, loss_test:0.07100, lr:2.17e-03, fs:0.82895 (r=0.724,p=0.969),  time:41.319, tt:8677.038\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02043, lr:6.00e-02, fs:0.64957 (r=0.874,p=0.517),  time:20.127, tt:20.127\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02322, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.304, tt:42.608\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02403, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.628, tt:67.884\n",
      "Ep:3, loss:0.00005, loss_test:0.02309, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.960, tt:99.839\n",
      "Ep:4, loss:0.00005, loss_test:0.02150, lr:6.00e-02, fs:0.68235 (r=1.000,p=0.518),  time:25.730, tt:128.648\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.66942 (r=0.931,p=0.523),  time:26.380, tt:158.279\n",
      "Ep:6, loss:0.00004, loss_test:0.01954, lr:6.00e-02, fs:0.67273 (r=0.851,p=0.556),  time:27.025, tt:189.176\n",
      "Ep:7, loss:0.00004, loss_test:0.01960, lr:6.00e-02, fs:0.66667 (r=0.770,p=0.588),  time:27.302, tt:218.416\n",
      "Ep:8, loss:0.00004, loss_test:0.01908, lr:6.00e-02, fs:0.66337 (r=0.770,p=0.583),  time:27.518, tt:247.665\n",
      "Ep:9, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.65385 (r=0.782,p=0.562),  time:27.858, tt:278.579\n",
      "Ep:10, loss:0.00003, loss_test:0.01761, lr:6.00e-02, fs:0.67568 (r=0.862,p=0.556),  time:28.118, tt:309.297\n",
      "Ep:11, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.68750 (r=0.885,p=0.562),  time:28.321, tt:339.852\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.69484 (r=0.851,p=0.587),  time:28.610, tt:371.933\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01623, lr:6.00e-02, fs:0.70531 (r=0.839,p=0.608),  time:28.801, tt:403.220\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.70588 (r=0.828,p=0.615),  time:28.890, tt:433.344\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01556, lr:6.00e-02, fs:0.71642 (r=0.828,p=0.632),  time:29.122, tt:465.947\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.72277 (r=0.839,p=0.635),  time:29.225, tt:496.822\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.73632 (r=0.851,p=0.649),  time:29.356, tt:528.411\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01449, lr:6.00e-02, fs:0.74627 (r=0.862,p=0.658),  time:29.437, tt:559.300\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.75758 (r=0.862,p=0.676),  time:29.405, tt:588.095\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.75897 (r=0.851,p=0.685),  time:29.492, tt:619.326\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.77487 (r=0.851,p=0.712),  time:29.508, tt:649.177\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01383, lr:6.00e-02, fs:0.77895 (r=0.851,p=0.718),  time:29.550, tt:679.652\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01371, lr:6.00e-02, fs:0.77895 (r=0.851,p=0.718),  time:29.527, tt:708.652\n",
      "Ep:24, loss:0.00002, loss_test:0.01370, lr:6.00e-02, fs:0.78307 (r=0.851,p=0.725),  time:29.507, tt:737.664\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.78307 (r=0.851,p=0.725),  time:29.521, tt:767.549\n",
      "Ep:26, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.78723 (r=0.851,p=0.733),  time:29.516, tt:796.936\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.78723 (r=0.851,p=0.733),  time:29.561, tt:827.722\n",
      "Ep:28, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:29.660, tt:860.136\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01356, lr:6.00e-02, fs:0.79144 (r=0.851,p=0.740),  time:29.631, tt:888.915\n",
      "Ep:30, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.79144 (r=0.851,p=0.740),  time:29.625, tt:918.372\n",
      "Ep:31, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.79144 (r=0.851,p=0.740),  time:29.713, tt:950.815\n",
      "Ep:32, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.79570 (r=0.851,p=0.747),  time:29.715, tt:980.589\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:29.710, tt:1010.144\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00001, loss_test:0.01349, lr:6.00e-02, fs:0.80874 (r=0.851,p=0.771),  time:29.634, tt:1037.199\n",
      "Ep:35, loss:0.00001, loss_test:0.01356, lr:6.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:29.645, tt:1067.222\n",
      "Ep:36, loss:0.00001, loss_test:0.01368, lr:6.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.624, tt:1096.093\n",
      "Ep:37, loss:0.00001, loss_test:0.01372, lr:6.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.621, tt:1125.608\n",
      "Ep:38, loss:0.00001, loss_test:0.01368, lr:6.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.523, tt:1151.382\n",
      "Ep:39, loss:0.00001, loss_test:0.01365, lr:6.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:29.484, tt:1179.354\n",
      "Ep:40, loss:0.00001, loss_test:0.01378, lr:6.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:29.485, tt:1208.882\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01396, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.482, tt:1238.252\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01402, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.528, tt:1269.685\n",
      "Ep:43, loss:0.00001, loss_test:0.01399, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.491, tt:1297.586\n",
      "Ep:44, loss:0.00001, loss_test:0.01412, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.460, tt:1325.717\n",
      "Ep:45, loss:0.00001, loss_test:0.01424, lr:6.00e-02, fs:0.81356 (r=0.828,p=0.800),  time:29.488, tt:1356.441\n",
      "Ep:46, loss:0.00001, loss_test:0.01431, lr:6.00e-02, fs:0.82286 (r=0.828,p=0.818),  time:29.539, tt:1388.338\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01443, lr:6.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:29.495, tt:1415.774\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01458, lr:6.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:29.516, tt:1446.274\n",
      "Ep:49, loss:0.00001, loss_test:0.01474, lr:6.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:29.514, tt:1475.693\n",
      "Ep:50, loss:0.00001, loss_test:0.01496, lr:6.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:29.547, tt:1506.871\n",
      "Ep:51, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:29.549, tt:1536.534\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01534, lr:6.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:29.572, tt:1567.297\n",
      "Ep:53, loss:0.00001, loss_test:0.01546, lr:6.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:29.555, tt:1595.990\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01556, lr:6.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:29.564, tt:1626.010\n",
      "Ep:55, loss:0.00001, loss_test:0.01572, lr:6.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:29.560, tt:1655.336\n",
      "Ep:56, loss:0.00001, loss_test:0.01579, lr:6.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:29.586, tt:1686.388\n",
      "Ep:57, loss:0.00001, loss_test:0.01601, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:29.603, tt:1716.975\n",
      "Ep:58, loss:0.00001, loss_test:0.01619, lr:6.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:29.609, tt:1746.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01628, lr:6.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:29.576, tt:1774.567\n",
      "Ep:60, loss:0.00001, loss_test:0.01652, lr:6.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:29.569, tt:1803.686\n",
      "Ep:61, loss:0.00001, loss_test:0.01667, lr:6.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:29.542, tt:1831.603\n",
      "Ep:62, loss:0.00001, loss_test:0.01669, lr:6.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:29.558, tt:1862.166\n",
      "Ep:63, loss:0.00001, loss_test:0.01686, lr:6.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:29.544, tt:1890.820\n",
      "Ep:64, loss:0.00001, loss_test:0.01708, lr:6.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:29.540, tt:1920.099\n",
      "Ep:65, loss:0.00001, loss_test:0.01727, lr:5.94e-02, fs:0.82051 (r=0.736,p=0.928),  time:29.529, tt:1948.946\n",
      "Ep:66, loss:0.00001, loss_test:0.01749, lr:5.88e-02, fs:0.81290 (r=0.724,p=0.926),  time:29.537, tt:1978.990\n",
      "Ep:67, loss:0.00001, loss_test:0.01753, lr:5.82e-02, fs:0.82051 (r=0.736,p=0.928),  time:29.560, tt:2010.099\n",
      "Ep:68, loss:0.00000, loss_test:0.01772, lr:5.76e-02, fs:0.81818 (r=0.724,p=0.940),  time:29.577, tt:2040.790\n",
      "Ep:69, loss:0.00000, loss_test:0.01794, lr:5.71e-02, fs:0.79470 (r=0.690,p=0.938),  time:29.586, tt:2070.993\n",
      "Ep:70, loss:0.00000, loss_test:0.01791, lr:5.65e-02, fs:0.78667 (r=0.678,p=0.937),  time:29.585, tt:2100.547\n",
      "Ep:71, loss:0.00000, loss_test:0.01806, lr:5.59e-02, fs:0.78667 (r=0.678,p=0.937),  time:29.553, tt:2127.799\n",
      "Ep:72, loss:0.00000, loss_test:0.01829, lr:5.54e-02, fs:0.76190 (r=0.644,p=0.933),  time:29.560, tt:2157.859\n",
      "Ep:73, loss:0.00000, loss_test:0.01837, lr:5.48e-02, fs:0.75342 (r=0.632,p=0.932),  time:29.610, tt:2191.131\n",
      "Ep:74, loss:0.00000, loss_test:0.01846, lr:5.43e-02, fs:0.75342 (r=0.632,p=0.932),  time:29.602, tt:2220.132\n",
      "Ep:75, loss:0.00000, loss_test:0.01863, lr:5.37e-02, fs:0.73611 (r=0.609,p=0.930),  time:29.632, tt:2252.043\n",
      "Ep:76, loss:0.00000, loss_test:0.01888, lr:5.32e-02, fs:0.74126 (r=0.609,p=0.946),  time:29.661, tt:2283.862\n",
      "Ep:77, loss:0.00000, loss_test:0.01892, lr:5.27e-02, fs:0.74126 (r=0.609,p=0.946),  time:29.685, tt:2315.418\n",
      "Ep:78, loss:0.00000, loss_test:0.01899, lr:5.21e-02, fs:0.74126 (r=0.609,p=0.946),  time:29.705, tt:2346.681\n",
      "Ep:79, loss:0.00000, loss_test:0.01921, lr:5.16e-02, fs:0.74648 (r=0.609,p=0.964),  time:29.682, tt:2374.598\n",
      "Ep:80, loss:0.00000, loss_test:0.01928, lr:5.11e-02, fs:0.74648 (r=0.609,p=0.964),  time:29.680, tt:2404.074\n",
      "Ep:81, loss:0.00000, loss_test:0.01936, lr:5.06e-02, fs:0.73759 (r=0.598,p=0.963),  time:29.691, tt:2434.677\n",
      "Ep:82, loss:0.00000, loss_test:0.01951, lr:5.01e-02, fs:0.73759 (r=0.598,p=0.963),  time:29.694, tt:2464.638\n",
      "Ep:83, loss:0.00000, loss_test:0.01965, lr:4.96e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.706, tt:2495.317\n",
      "Ep:84, loss:0.00000, loss_test:0.01972, lr:4.91e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.725, tt:2526.604\n",
      "Ep:85, loss:0.00000, loss_test:0.01981, lr:4.86e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.731, tt:2556.838\n",
      "Ep:86, loss:0.00000, loss_test:0.01986, lr:4.81e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.741, tt:2587.466\n",
      "Ep:87, loss:0.00000, loss_test:0.02006, lr:4.76e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.744, tt:2617.493\n",
      "Ep:88, loss:0.00000, loss_test:0.02012, lr:4.71e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.732, tt:2646.128\n",
      "Ep:89, loss:0.00000, loss_test:0.02018, lr:4.67e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.754, tt:2677.887\n",
      "Ep:90, loss:0.00000, loss_test:0.02031, lr:4.62e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.759, tt:2708.058\n",
      "Ep:91, loss:0.00000, loss_test:0.02045, lr:4.57e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.785, tt:2740.190\n",
      "Ep:92, loss:0.00000, loss_test:0.02053, lr:4.53e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.783, tt:2769.826\n",
      "Ep:93, loss:0.00000, loss_test:0.02056, lr:4.48e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.801, tt:2801.278\n",
      "Ep:94, loss:0.00000, loss_test:0.02068, lr:4.44e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.824, tt:2833.267\n",
      "Ep:95, loss:0.00000, loss_test:0.02075, lr:4.39e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.869, tt:2867.418\n",
      "Ep:96, loss:0.00000, loss_test:0.02080, lr:4.35e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.859, tt:2896.359\n",
      "Ep:97, loss:0.00000, loss_test:0.02092, lr:4.31e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.873, tt:2927.507\n",
      "Ep:98, loss:0.00000, loss_test:0.02101, lr:4.26e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.889, tt:2958.980\n",
      "Ep:99, loss:0.00000, loss_test:0.02112, lr:4.22e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.885, tt:2988.505\n",
      "Ep:100, loss:0.00000, loss_test:0.02114, lr:4.18e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.866, tt:3016.474\n",
      "Ep:101, loss:0.00000, loss_test:0.02112, lr:4.14e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.876, tt:3047.380\n",
      "Ep:102, loss:0.00000, loss_test:0.02126, lr:4.10e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.878, tt:3077.478\n",
      "Ep:103, loss:0.00000, loss_test:0.02138, lr:4.05e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.859, tt:3105.317\n",
      "Ep:104, loss:0.00000, loss_test:0.02142, lr:4.01e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.855, tt:3134.733\n",
      "Ep:105, loss:0.00000, loss_test:0.02147, lr:3.97e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.846, tt:3163.648\n",
      "Ep:106, loss:0.00000, loss_test:0.02159, lr:3.93e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.849, tt:3193.803\n",
      "Ep:107, loss:0.00000, loss_test:0.02164, lr:3.89e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.836, tt:3222.336\n",
      "Ep:108, loss:0.00000, loss_test:0.02161, lr:3.86e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.819, tt:3250.264\n",
      "Ep:109, loss:0.00000, loss_test:0.02169, lr:3.82e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.826, tt:3280.871\n",
      "Ep:110, loss:0.00000, loss_test:0.02177, lr:3.78e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.831, tt:3311.262\n",
      "Ep:111, loss:0.00000, loss_test:0.02182, lr:3.74e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.845, tt:3342.590\n",
      "Ep:112, loss:0.00000, loss_test:0.02189, lr:3.70e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.853, tt:3373.386\n",
      "Ep:113, loss:0.00000, loss_test:0.02198, lr:3.67e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.861, tt:3404.196\n",
      "Ep:114, loss:0.00000, loss_test:0.02197, lr:3.63e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.840, tt:3431.649\n",
      "Ep:115, loss:0.00000, loss_test:0.02205, lr:3.59e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.855, tt:3463.224\n",
      "Ep:116, loss:0.00000, loss_test:0.02212, lr:3.56e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.851, tt:3492.536\n",
      "Ep:117, loss:0.00000, loss_test:0.02212, lr:3.52e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.869, tt:3524.534\n",
      "Ep:118, loss:0.00000, loss_test:0.02214, lr:3.49e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.890, tt:3556.965\n",
      "Ep:119, loss:0.00000, loss_test:0.02222, lr:3.45e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.892, tt:3587.033\n",
      "Ep:120, loss:0.00000, loss_test:0.02228, lr:3.42e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.902, tt:3618.187\n",
      "Ep:121, loss:0.00000, loss_test:0.02230, lr:3.38e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.921, tt:3650.358\n",
      "Ep:122, loss:0.00000, loss_test:0.02233, lr:3.35e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.915, tt:3679.593\n",
      "Ep:123, loss:0.00000, loss_test:0.02236, lr:3.32e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.954, tt:3714.310\n",
      "Ep:124, loss:0.00000, loss_test:0.02242, lr:3.28e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.946, tt:3743.210\n",
      "Ep:125, loss:0.00000, loss_test:0.02247, lr:3.25e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.932, tt:3771.422\n",
      "Ep:126, loss:0.00000, loss_test:0.02251, lr:3.22e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.933, tt:3801.541\n",
      "Ep:127, loss:0.00000, loss_test:0.02252, lr:3.19e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.938, tt:3832.087\n",
      "Ep:128, loss:0.00000, loss_test:0.02256, lr:3.15e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.925, tt:3860.305\n",
      "Ep:129, loss:0.00000, loss_test:0.02265, lr:3.12e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.911, tt:3888.417\n",
      "Ep:130, loss:0.00000, loss_test:0.02266, lr:3.09e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.911, tt:3918.347\n",
      "Ep:131, loss:0.00000, loss_test:0.02270, lr:3.06e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.915, tt:3948.758\n",
      "Ep:132, loss:0.00000, loss_test:0.02274, lr:3.03e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.918, tt:3979.089\n",
      "Ep:133, loss:0.00000, loss_test:0.02277, lr:3.00e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.930, tt:4010.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.02279, lr:2.97e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.937, tt:4041.488\n",
      "Ep:135, loss:0.00000, loss_test:0.02282, lr:2.94e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.948, tt:4072.992\n",
      "Ep:136, loss:0.00000, loss_test:0.02282, lr:2.91e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.948, tt:4102.901\n",
      "Ep:137, loss:0.00000, loss_test:0.02287, lr:2.88e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.944, tt:4132.203\n",
      "Ep:138, loss:0.00000, loss_test:0.02291, lr:2.85e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.958, tt:4164.134\n",
      "Ep:139, loss:0.00000, loss_test:0.02297, lr:2.82e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.969, tt:4195.691\n",
      "Ep:140, loss:0.00000, loss_test:0.02298, lr:2.80e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.975, tt:4226.445\n",
      "Ep:141, loss:0.00000, loss_test:0.02300, lr:2.77e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.978, tt:4256.869\n",
      "Ep:142, loss:0.00000, loss_test:0.02304, lr:2.74e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.978, tt:4286.916\n",
      "Ep:143, loss:0.00000, loss_test:0.02306, lr:2.71e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.990, tt:4318.567\n",
      "Ep:144, loss:0.00000, loss_test:0.02306, lr:2.69e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.999, tt:4349.905\n",
      "Ep:145, loss:0.00000, loss_test:0.02312, lr:2.66e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.001, tt:4380.210\n",
      "Ep:146, loss:0.00000, loss_test:0.02316, lr:2.63e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.992, tt:4408.876\n",
      "Ep:147, loss:0.00000, loss_test:0.02316, lr:2.61e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.993, tt:4438.951\n",
      "Ep:148, loss:0.00000, loss_test:0.02318, lr:2.58e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.990, tt:4468.444\n",
      "Ep:149, loss:0.00000, loss_test:0.02321, lr:2.55e-02, fs:0.72857 (r=0.586,p=0.962),  time:29.996, tt:4499.383\n",
      "Ep:150, loss:0.00000, loss_test:0.02324, lr:2.53e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.007, tt:4531.060\n",
      "Ep:151, loss:0.00000, loss_test:0.02323, lr:2.50e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.010, tt:4561.594\n",
      "Ep:152, loss:0.00000, loss_test:0.02324, lr:2.48e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.028, tt:4594.275\n",
      "Ep:153, loss:0.00000, loss_test:0.02327, lr:2.45e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.034, tt:4625.308\n",
      "Ep:154, loss:0.00000, loss_test:0.02332, lr:2.43e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.037, tt:4655.688\n",
      "Ep:155, loss:0.00000, loss_test:0.02334, lr:2.40e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.046, tt:4687.169\n",
      "Ep:156, loss:0.00000, loss_test:0.02339, lr:2.38e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.053, tt:4718.353\n",
      "Ep:157, loss:0.00000, loss_test:0.02340, lr:2.36e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.051, tt:4748.027\n",
      "Ep:158, loss:0.00000, loss_test:0.02344, lr:2.33e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.053, tt:4778.463\n",
      "Ep:159, loss:0.00000, loss_test:0.02346, lr:2.31e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.056, tt:4809.022\n",
      "Ep:160, loss:0.00000, loss_test:0.02347, lr:2.29e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.068, tt:4840.872\n",
      "Ep:161, loss:0.00000, loss_test:0.02348, lr:2.26e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.080, tt:4873.019\n",
      "Ep:162, loss:0.00000, loss_test:0.02350, lr:2.24e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.079, tt:4902.930\n",
      "Ep:163, loss:0.00000, loss_test:0.02354, lr:2.22e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.064, tt:4930.493\n",
      "Ep:164, loss:0.00000, loss_test:0.02354, lr:2.20e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.053, tt:4958.759\n",
      "Ep:165, loss:0.00000, loss_test:0.02357, lr:2.17e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.042, tt:4987.038\n",
      "Ep:166, loss:0.00000, loss_test:0.02361, lr:2.15e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.049, tt:5018.257\n",
      "Ep:167, loss:0.00000, loss_test:0.02364, lr:2.13e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.050, tt:5048.410\n",
      "Ep:168, loss:0.00000, loss_test:0.02364, lr:2.11e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.059, tt:5080.012\n",
      "Ep:169, loss:0.00000, loss_test:0.02365, lr:2.09e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.054, tt:5109.161\n",
      "Ep:170, loss:0.00000, loss_test:0.02368, lr:2.07e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.062, tt:5140.674\n",
      "Ep:171, loss:0.00000, loss_test:0.02367, lr:2.05e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.052, tt:5168.928\n",
      "Ep:172, loss:0.00000, loss_test:0.02369, lr:2.03e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.051, tt:5198.775\n",
      "Ep:173, loss:0.00000, loss_test:0.02372, lr:2.01e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.052, tt:5229.026\n",
      "Ep:174, loss:0.00000, loss_test:0.02374, lr:1.99e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.053, tt:5259.348\n",
      "Ep:175, loss:0.00000, loss_test:0.02373, lr:1.97e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.050, tt:5288.873\n",
      "Ep:176, loss:0.00000, loss_test:0.02376, lr:1.95e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.045, tt:5317.888\n",
      "Ep:177, loss:0.00000, loss_test:0.02377, lr:1.93e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.052, tt:5349.334\n",
      "Ep:178, loss:0.00000, loss_test:0.02378, lr:1.91e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.090, tt:5386.073\n",
      "Ep:179, loss:0.00000, loss_test:0.02380, lr:1.89e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.098, tt:5417.691\n",
      "Ep:180, loss:0.00000, loss_test:0.02380, lr:1.87e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.102, tt:5448.465\n",
      "Ep:181, loss:0.00000, loss_test:0.02382, lr:1.85e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.109, tt:5479.784\n",
      "Ep:182, loss:0.00000, loss_test:0.02385, lr:1.83e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.123, tt:5512.588\n",
      "Ep:183, loss:0.00000, loss_test:0.02387, lr:1.81e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.130, tt:5543.858\n",
      "Ep:184, loss:0.00000, loss_test:0.02387, lr:1.80e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.135, tt:5574.985\n",
      "Ep:185, loss:0.00000, loss_test:0.02388, lr:1.78e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.141, tt:5606.238\n",
      "Ep:186, loss:0.00000, loss_test:0.02389, lr:1.76e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.147, tt:5637.540\n",
      "Ep:187, loss:0.00000, loss_test:0.02391, lr:1.74e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.148, tt:5667.750\n",
      "Ep:188, loss:0.00000, loss_test:0.02392, lr:1.73e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.150, tt:5698.331\n",
      "Ep:189, loss:0.00000, loss_test:0.02394, lr:1.71e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.147, tt:5727.990\n",
      "Ep:190, loss:0.00000, loss_test:0.02394, lr:1.69e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.151, tt:5758.833\n",
      "Ep:191, loss:0.00000, loss_test:0.02395, lr:1.67e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.156, tt:5789.912\n",
      "Ep:192, loss:0.00000, loss_test:0.02396, lr:1.66e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.153, tt:5819.456\n",
      "Ep:193, loss:0.00000, loss_test:0.02397, lr:1.64e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.158, tt:5850.661\n",
      "Ep:194, loss:0.00000, loss_test:0.02399, lr:1.62e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.157, tt:5880.552\n",
      "Ep:195, loss:0.00000, loss_test:0.02401, lr:1.61e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.158, tt:5911.018\n",
      "Ep:196, loss:0.00000, loss_test:0.02402, lr:1.59e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.153, tt:5940.066\n",
      "Ep:197, loss:0.00000, loss_test:0.02403, lr:1.58e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.160, tt:5971.614\n",
      "Ep:198, loss:0.00000, loss_test:0.02404, lr:1.56e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.160, tt:6001.850\n",
      "Ep:199, loss:0.00000, loss_test:0.02405, lr:1.54e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.164, tt:6032.829\n",
      "Ep:200, loss:0.00000, loss_test:0.02406, lr:1.53e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.183, tt:6066.779\n",
      "Ep:201, loss:0.00000, loss_test:0.02407, lr:1.51e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.182, tt:6096.810\n",
      "Ep:202, loss:0.00000, loss_test:0.02409, lr:1.50e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.171, tt:6124.692\n",
      "Ep:203, loss:0.00000, loss_test:0.02409, lr:1.48e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.164, tt:6153.413\n",
      "Ep:204, loss:0.00000, loss_test:0.02411, lr:1.47e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.165, tt:6183.735\n",
      "Ep:205, loss:0.00000, loss_test:0.02415, lr:1.45e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.144, tt:6209.632\n",
      "Ep:206, loss:0.00000, loss_test:0.02416, lr:1.44e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.110, tt:6232.786\n",
      "Ep:207, loss:0.00000, loss_test:0.02416, lr:1.43e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.108, tt:6262.374\n",
      "Ep:208, loss:0.00000, loss_test:0.02416, lr:1.41e-02, fs:0.72857 (r=0.586,p=0.962),  time:30.099, tt:6290.727\n",
      "Model and results saved\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13903, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.387, tt:27.387\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13659, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:26.068, tt:52.135\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13192, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:25.603, tt:76.808\n",
      "Ep:3, loss:0.00026, loss_test:0.12399, lr:1.00e-02, fs:0.66383 (r=0.897,p=0.527),  time:26.035, tt:104.139\n",
      "Ep:4, loss:0.00025, loss_test:0.11623, lr:1.00e-02, fs:0.67308 (r=0.805,p=0.579),  time:26.253, tt:131.263\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11321, lr:1.00e-02, fs:0.67027 (r=0.713,p=0.633),  time:26.857, tt:161.139\n",
      "Ep:6, loss:0.00022, loss_test:0.11195, lr:1.00e-02, fs:0.67778 (r=0.701,p=0.656),  time:27.718, tt:194.023\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00021, loss_test:0.10903, lr:1.00e-02, fs:0.67380 (r=0.724,p=0.630),  time:28.401, tt:227.211\n",
      "Ep:8, loss:0.00020, loss_test:0.10701, lr:1.00e-02, fs:0.69189 (r=0.736,p=0.653),  time:28.486, tt:256.370\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.10504, lr:1.00e-02, fs:0.72414 (r=0.724,p=0.724),  time:28.765, tt:287.647\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00018, loss_test:0.10120, lr:1.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:28.754, tt:316.292\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.09705, lr:1.00e-02, fs:0.77348 (r=0.805,p=0.745),  time:28.921, tt:347.050\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.09495, lr:1.00e-02, fs:0.75862 (r=0.759,p=0.759),  time:29.128, tt:378.662\n",
      "Ep:13, loss:0.00016, loss_test:0.09246, lr:1.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:29.458, tt:412.410\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00015, loss_test:0.09094, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:29.533, tt:442.992\n",
      "Ep:15, loss:0.00014, loss_test:0.08936, lr:1.00e-02, fs:0.78453 (r=0.816,p=0.755),  time:29.672, tt:474.758\n",
      "Ep:16, loss:0.00014, loss_test:0.08796, lr:1.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:29.713, tt:505.124\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00013, loss_test:0.08609, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:29.707, tt:534.721\n",
      "Ep:18, loss:0.00012, loss_test:0.08604, lr:1.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:29.767, tt:565.568\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00011, loss_test:0.08411, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:29.866, tt:597.324\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.08360, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:29.983, tt:629.645\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.08280, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:30.019, tt:660.409\n",
      "Ep:22, loss:0.00010, loss_test:0.08146, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:30.080, tt:691.840\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00009, loss_test:0.07957, lr:1.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:30.182, tt:724.366\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00009, loss_test:0.08010, lr:1.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:30.225, tt:755.614\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00008, loss_test:0.07862, lr:1.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:30.247, tt:786.421\n",
      "Ep:26, loss:0.00008, loss_test:0.07749, lr:1.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:30.326, tt:818.795\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.07896, lr:1.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:30.329, tt:849.203\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.07517, lr:1.00e-02, fs:0.85549 (r=0.851,p=0.860),  time:30.273, tt:877.919\n",
      "Ep:29, loss:0.00007, loss_test:0.07913, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:30.280, tt:908.404\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00006, loss_test:0.07381, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:30.245, tt:937.597\n",
      "Ep:31, loss:0.00006, loss_test:0.07656, lr:1.00e-02, fs:0.89820 (r=0.862,p=0.938),  time:30.311, tt:969.959\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.07387, lr:1.00e-02, fs:0.88623 (r=0.851,p=0.925),  time:30.334, tt:1001.038\n",
      "Ep:33, loss:0.00005, loss_test:0.07357, lr:1.00e-02, fs:0.90173 (r=0.897,p=0.907),  time:30.393, tt:1033.365\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00005, loss_test:0.07527, lr:1.00e-02, fs:0.88889 (r=0.828,p=0.960),  time:30.498, tt:1067.436\n",
      "Ep:35, loss:0.00005, loss_test:0.07379, lr:1.00e-02, fs:0.92308 (r=0.897,p=0.951),  time:30.519, tt:1098.687\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00004, loss_test:0.07451, lr:1.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:30.593, tt:1131.932\n",
      "Ep:37, loss:0.00004, loss_test:0.07738, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:30.655, tt:1164.903\n",
      "Ep:38, loss:0.00004, loss_test:0.07552, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:30.682, tt:1196.604\n",
      "Ep:39, loss:0.00003, loss_test:0.07569, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:30.701, tt:1228.031\n",
      "Ep:40, loss:0.00004, loss_test:0.07403, lr:1.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:30.824, tt:1263.779\n",
      "Ep:41, loss:0.00003, loss_test:0.07854, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:30.771, tt:1292.365\n",
      "Ep:42, loss:0.00004, loss_test:0.07887, lr:1.00e-02, fs:0.81333 (r=0.701,p=0.968),  time:30.775, tt:1323.312\n",
      "Ep:43, loss:0.00003, loss_test:0.07685, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:30.746, tt:1352.810\n",
      "Ep:44, loss:0.00003, loss_test:0.08373, lr:1.00e-02, fs:0.82432 (r=0.701,p=1.000),  time:30.789, tt:1385.526\n",
      "Ep:45, loss:0.00003, loss_test:0.07307, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:30.788, tt:1416.271\n",
      "Ep:46, loss:0.00003, loss_test:0.08920, lr:1.00e-02, fs:0.76056 (r=0.621,p=0.982),  time:30.783, tt:1446.817\n",
      "Ep:47, loss:0.00002, loss_test:0.07465, lr:9.90e-03, fs:0.85161 (r=0.759,p=0.971),  time:30.773, tt:1477.087\n",
      "Ep:48, loss:0.00002, loss_test:0.08383, lr:9.80e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.770, tt:1507.744\n",
      "Ep:49, loss:0.00002, loss_test:0.07743, lr:9.70e-03, fs:0.81818 (r=0.724,p=0.940),  time:30.768, tt:1538.382\n",
      "Ep:50, loss:0.00002, loss_test:0.08074, lr:9.61e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.749, tt:1568.176\n",
      "Ep:51, loss:0.00002, loss_test:0.08239, lr:9.51e-03, fs:0.81081 (r=0.690,p=0.984),  time:30.718, tt:1597.343\n",
      "Ep:52, loss:0.00002, loss_test:0.07969, lr:9.41e-03, fs:0.82119 (r=0.713,p=0.969),  time:30.716, tt:1627.945\n",
      "Ep:53, loss:0.00002, loss_test:0.08215, lr:9.32e-03, fs:0.81879 (r=0.701,p=0.984),  time:30.733, tt:1659.597\n",
      "Ep:54, loss:0.00001, loss_test:0.08193, lr:9.23e-03, fs:0.85714 (r=0.759,p=0.985),  time:30.731, tt:1690.229\n",
      "Ep:55, loss:0.00001, loss_test:0.08149, lr:9.14e-03, fs:0.82119 (r=0.713,p=0.969),  time:30.730, tt:1720.859\n",
      "Ep:56, loss:0.00001, loss_test:0.08538, lr:9.04e-03, fs:0.83444 (r=0.724,p=0.984),  time:30.764, tt:1753.556\n",
      "Ep:57, loss:0.00001, loss_test:0.08228, lr:8.95e-03, fs:0.81879 (r=0.701,p=0.984),  time:30.779, tt:1785.190\n",
      "Ep:58, loss:0.00001, loss_test:0.08477, lr:8.86e-03, fs:0.81081 (r=0.690,p=0.984),  time:30.777, tt:1815.827\n",
      "Ep:59, loss:0.00001, loss_test:0.08670, lr:8.78e-03, fs:0.77778 (r=0.644,p=0.982),  time:30.803, tt:1848.194\n",
      "Ep:60, loss:0.00001, loss_test:0.08546, lr:8.69e-03, fs:0.78912 (r=0.667,p=0.967),  time:30.745, tt:1875.435\n",
      "Ep:61, loss:0.00001, loss_test:0.08622, lr:8.60e-03, fs:0.80272 (r=0.678,p=0.983),  time:30.753, tt:1906.694\n",
      "Ep:62, loss:0.00001, loss_test:0.08530, lr:8.51e-03, fs:0.79452 (r=0.667,p=0.983),  time:30.764, tt:1938.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.08688, lr:8.43e-03, fs:0.77778 (r=0.644,p=0.982),  time:30.757, tt:1968.420\n",
      "Ep:64, loss:0.00001, loss_test:0.08568, lr:8.35e-03, fs:0.79452 (r=0.667,p=0.983),  time:30.862, tt:2006.055\n",
      "Ep:65, loss:0.00001, loss_test:0.09028, lr:8.26e-03, fs:0.79167 (r=0.655,p=1.000),  time:30.955, tt:2043.002\n",
      "Ep:66, loss:0.00001, loss_test:0.08696, lr:8.18e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.048, tt:2080.201\n",
      "Ep:67, loss:0.00001, loss_test:0.08618, lr:8.10e-03, fs:0.84000 (r=0.724,p=1.000),  time:31.135, tt:2117.188\n",
      "Ep:68, loss:0.00001, loss_test:0.08762, lr:8.02e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.194, tt:2152.404\n",
      "Ep:69, loss:0.00001, loss_test:0.08629, lr:7.94e-03, fs:0.80000 (r=0.667,p=1.000),  time:31.250, tt:2187.483\n",
      "Ep:70, loss:0.00001, loss_test:0.08789, lr:7.86e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.333, tt:2224.626\n",
      "Ep:71, loss:0.00001, loss_test:0.09022, lr:7.78e-03, fs:0.77465 (r=0.632,p=1.000),  time:31.403, tt:2261.037\n",
      "Ep:72, loss:0.00000, loss_test:0.08610, lr:7.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.466, tt:2297.030\n",
      "Ep:73, loss:0.00000, loss_test:0.08808, lr:7.62e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.527, tt:2333.016\n",
      "Ep:74, loss:0.00000, loss_test:0.08772, lr:7.55e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.567, tt:2367.495\n",
      "Ep:75, loss:0.00000, loss_test:0.08733, lr:7.47e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.660, tt:2406.174\n",
      "Ep:76, loss:0.00000, loss_test:0.08843, lr:7.40e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.655, tt:2437.437\n",
      "Ep:77, loss:0.00000, loss_test:0.08655, lr:7.32e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.695, tt:2472.233\n",
      "Ep:78, loss:0.00000, loss_test:0.08787, lr:7.25e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.741, tt:2507.578\n",
      "Ep:79, loss:0.00000, loss_test:0.08838, lr:7.18e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.794, tt:2543.513\n",
      "Ep:80, loss:0.00000, loss_test:0.08792, lr:7.11e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.835, tt:2578.656\n",
      "Ep:81, loss:0.00000, loss_test:0.08741, lr:7.03e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.866, tt:2613.038\n",
      "Ep:82, loss:0.00000, loss_test:0.08921, lr:6.96e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.904, tt:2648.071\n",
      "Ep:83, loss:0.00000, loss_test:0.08774, lr:6.89e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.955, tt:2684.191\n",
      "Ep:84, loss:0.00000, loss_test:0.09013, lr:6.83e-03, fs:0.79452 (r=0.667,p=0.983),  time:31.985, tt:2718.729\n",
      "Ep:85, loss:0.00000, loss_test:0.08941, lr:6.76e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.010, tt:2752.819\n",
      "Ep:86, loss:0.00000, loss_test:0.08723, lr:6.69e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.037, tt:2787.189\n",
      "Ep:87, loss:0.00000, loss_test:0.08833, lr:6.62e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.078, tt:2822.856\n",
      "Ep:88, loss:0.00000, loss_test:0.08808, lr:6.56e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.097, tt:2856.650\n",
      "Ep:89, loss:0.00000, loss_test:0.08690, lr:6.49e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.141, tt:2892.734\n",
      "Ep:90, loss:0.00000, loss_test:0.08846, lr:6.43e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.162, tt:2926.745\n",
      "Ep:91, loss:0.00000, loss_test:0.08744, lr:6.36e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.176, tt:2960.204\n",
      "Ep:92, loss:0.00000, loss_test:0.08767, lr:6.30e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.202, tt:2994.794\n",
      "Ep:93, loss:0.00000, loss_test:0.08721, lr:6.24e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.219, tt:3028.560\n",
      "Ep:94, loss:0.00000, loss_test:0.08720, lr:6.17e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.254, tt:3064.123\n",
      "Ep:95, loss:0.00000, loss_test:0.09176, lr:6.11e-03, fs:0.80000 (r=0.667,p=1.000),  time:32.300, tt:3100.757\n",
      "Ep:96, loss:0.00000, loss_test:0.08907, lr:6.05e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.331, tt:3136.108\n",
      "Ep:97, loss:0.00000, loss_test:0.08935, lr:5.99e-03, fs:0.80000 (r=0.667,p=1.000),  time:32.360, tt:3171.299\n",
      "Ep:98, loss:0.00000, loss_test:0.09136, lr:5.93e-03, fs:0.80000 (r=0.667,p=1.000),  time:32.395, tt:3207.074\n",
      "Ep:99, loss:0.00000, loss_test:0.08859, lr:5.87e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.433, tt:3243.300\n",
      "Ep:100, loss:0.00000, loss_test:0.08949, lr:5.81e-03, fs:0.80000 (r=0.667,p=1.000),  time:32.456, tt:3278.087\n",
      "Ep:101, loss:0.00000, loss_test:0.08884, lr:5.75e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.480, tt:3312.987\n",
      "Ep:102, loss:0.00000, loss_test:0.08925, lr:5.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.522, tt:3349.761\n",
      "Ep:103, loss:0.00000, loss_test:0.08894, lr:5.64e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.542, tt:3384.394\n",
      "Ep:104, loss:0.00000, loss_test:0.08844, lr:5.58e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.582, tt:3421.161\n",
      "Ep:105, loss:0.00000, loss_test:0.08892, lr:5.53e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.624, tt:3458.099\n",
      "Ep:106, loss:0.00000, loss_test:0.08797, lr:5.47e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.652, tt:3493.760\n",
      "Ep:107, loss:0.00000, loss_test:0.08934, lr:5.42e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.701, tt:3531.752\n",
      "Ep:108, loss:0.00000, loss_test:0.08966, lr:5.36e-03, fs:0.80000 (r=0.667,p=1.000),  time:32.736, tt:3568.251\n",
      "Ep:109, loss:0.00000, loss_test:0.08739, lr:5.31e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.744, tt:3601.859\n",
      "Ep:110, loss:0.00000, loss_test:0.08794, lr:5.26e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.778, tt:3638.330\n",
      "Ep:111, loss:0.00000, loss_test:0.08852, lr:5.20e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.795, tt:3673.000\n",
      "Ep:112, loss:0.00000, loss_test:0.08766, lr:5.15e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.819, tt:3708.571\n",
      "Ep:113, loss:0.00000, loss_test:0.08748, lr:5.10e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.839, tt:3743.612\n",
      "Ep:114, loss:0.00000, loss_test:0.08710, lr:5.05e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.886, tt:3781.848\n",
      "Ep:115, loss:0.00000, loss_test:0.08799, lr:5.00e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.924, tt:3819.194\n",
      "Ep:116, loss:0.00000, loss_test:0.08794, lr:4.95e-03, fs:0.79452 (r=0.667,p=0.983),  time:32.973, tt:3857.892\n",
      "Ep:117, loss:0.00000, loss_test:0.08689, lr:4.90e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.011, tt:3895.300\n",
      "Ep:118, loss:0.00000, loss_test:0.08648, lr:4.85e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.048, tt:3932.722\n",
      "Ep:119, loss:0.00000, loss_test:0.08833, lr:4.80e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.086, tt:3970.345\n",
      "Ep:120, loss:0.00000, loss_test:0.08731, lr:4.75e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.127, tt:4008.400\n",
      "Ep:121, loss:0.00000, loss_test:0.08710, lr:4.71e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.163, tt:4045.868\n",
      "Ep:122, loss:0.00000, loss_test:0.08791, lr:4.66e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.196, tt:4083.064\n",
      "Ep:123, loss:0.00000, loss_test:0.08732, lr:4.61e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.249, tt:4122.851\n",
      "Ep:124, loss:0.00000, loss_test:0.08686, lr:4.57e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.280, tt:4160.045\n",
      "Ep:125, loss:0.00000, loss_test:0.08700, lr:4.52e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.311, tt:4197.224\n",
      "Ep:126, loss:0.00000, loss_test:0.08703, lr:4.48e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.329, tt:4232.741\n",
      "Ep:127, loss:0.00000, loss_test:0.08678, lr:4.43e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.345, tt:4268.196\n",
      "Ep:128, loss:0.00000, loss_test:0.08672, lr:4.39e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.365, tt:4304.055\n",
      "Ep:129, loss:0.00000, loss_test:0.08676, lr:4.34e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.388, tt:4340.490\n",
      "Ep:130, loss:0.00000, loss_test:0.08676, lr:4.30e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.422, tt:4378.343\n",
      "Ep:131, loss:0.00000, loss_test:0.08651, lr:4.26e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.427, tt:4412.323\n",
      "Ep:132, loss:0.00000, loss_test:0.08668, lr:4.21e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.440, tt:4447.509\n",
      "Ep:133, loss:0.00000, loss_test:0.08712, lr:4.17e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.465, tt:4484.352\n",
      "Ep:134, loss:0.00000, loss_test:0.08683, lr:4.13e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.486, tt:4520.619\n",
      "Ep:135, loss:0.00000, loss_test:0.08706, lr:4.09e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.487, tt:4554.206\n",
      "Ep:136, loss:0.00000, loss_test:0.08712, lr:4.05e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.498, tt:4589.273\n",
      "Ep:137, loss:0.00000, loss_test:0.08631, lr:4.01e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.522, tt:4625.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.08607, lr:3.97e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.532, tt:4660.965\n",
      "Ep:139, loss:0.00000, loss_test:0.08792, lr:3.93e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.540, tt:4695.595\n",
      "Ep:140, loss:0.00000, loss_test:0.08745, lr:3.89e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.548, tt:4730.286\n",
      "Ep:141, loss:0.00000, loss_test:0.08599, lr:3.85e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.564, tt:4766.038\n",
      "Ep:142, loss:0.00000, loss_test:0.08669, lr:3.81e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.564, tt:4799.662\n",
      "Ep:143, loss:0.00000, loss_test:0.08723, lr:3.77e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.568, tt:4833.786\n",
      "Ep:144, loss:0.00000, loss_test:0.08676, lr:3.73e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.584, tt:4869.718\n",
      "Ep:145, loss:0.00000, loss_test:0.08661, lr:3.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.623, tt:4908.957\n",
      "Ep:146, loss:0.00000, loss_test:0.08668, lr:3.66e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.637, tt:4944.648\n",
      "Ep:147, loss:0.00000, loss_test:0.08675, lr:3.62e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.659, tt:4981.503\n",
      "Ep:148, loss:0.00000, loss_test:0.08679, lr:3.59e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.672, tt:5017.190\n",
      "Ep:149, loss:0.00000, loss_test:0.08658, lr:3.55e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.689, tt:5053.293\n",
      "Ep:150, loss:0.00000, loss_test:0.08682, lr:3.52e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.713, tt:5090.720\n",
      "Ep:151, loss:0.00000, loss_test:0.08693, lr:3.48e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.733, tt:5127.353\n",
      "Ep:152, loss:0.00000, loss_test:0.08687, lr:3.45e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.756, tt:5164.596\n",
      "Ep:153, loss:0.00000, loss_test:0.08640, lr:3.41e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.769, tt:5200.475\n",
      "Ep:154, loss:0.00000, loss_test:0.08686, lr:3.38e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.790, tt:5237.427\n",
      "Ep:155, loss:0.00000, loss_test:0.08786, lr:3.34e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.807, tt:5273.890\n",
      "Ep:156, loss:0.00000, loss_test:0.08757, lr:3.31e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.827, tt:5310.832\n",
      "Ep:157, loss:0.00000, loss_test:0.08667, lr:3.28e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.825, tt:5344.411\n",
      "Ep:158, loss:0.00000, loss_test:0.08698, lr:3.24e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.845, tt:5381.355\n",
      "Ep:159, loss:0.00000, loss_test:0.08737, lr:3.21e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.862, tt:5417.963\n",
      "Ep:160, loss:0.00000, loss_test:0.08688, lr:3.18e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.861, tt:5451.574\n",
      "Ep:161, loss:0.00000, loss_test:0.08625, lr:3.15e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.860, tt:5485.393\n",
      "Ep:162, loss:0.00000, loss_test:0.08691, lr:3.12e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.878, tt:5522.134\n",
      "Ep:163, loss:0.00000, loss_test:0.08749, lr:3.09e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.899, tt:5559.508\n",
      "Ep:164, loss:0.00000, loss_test:0.08681, lr:3.05e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.895, tt:5592.720\n",
      "Ep:165, loss:0.00000, loss_test:0.08632, lr:3.02e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.906, tt:5628.388\n",
      "Ep:166, loss:0.00000, loss_test:0.08641, lr:2.99e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.913, tt:5663.497\n",
      "Ep:167, loss:0.00000, loss_test:0.08675, lr:2.96e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.926, tt:5699.532\n",
      "Ep:168, loss:0.00000, loss_test:0.08697, lr:2.93e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.939, tt:5735.717\n",
      "Ep:169, loss:0.00000, loss_test:0.08699, lr:2.90e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.961, tt:5773.305\n",
      "Ep:170, loss:0.00000, loss_test:0.08694, lr:2.88e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.975, tt:5809.737\n",
      "Ep:171, loss:0.00000, loss_test:0.08671, lr:2.85e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.997, tt:5847.490\n",
      "Ep:172, loss:0.00000, loss_test:0.08663, lr:2.82e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.004, tt:5882.685\n",
      "Ep:173, loss:0.00000, loss_test:0.08713, lr:2.79e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.014, tt:5918.403\n",
      "Ep:174, loss:0.00000, loss_test:0.08702, lr:2.76e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.069, tt:5962.086\n",
      "Ep:175, loss:0.00000, loss_test:0.08642, lr:2.73e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.079, tt:5997.957\n",
      "Ep:176, loss:0.00000, loss_test:0.08638, lr:2.71e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.093, tt:6034.489\n",
      "Ep:177, loss:0.00000, loss_test:0.08654, lr:2.68e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.107, tt:6071.029\n",
      "Ep:178, loss:0.00000, loss_test:0.08644, lr:2.65e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.127, tt:6108.762\n",
      "Ep:179, loss:0.00000, loss_test:0.08619, lr:2.63e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.135, tt:6144.213\n",
      "Ep:180, loss:0.00000, loss_test:0.08637, lr:2.60e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.155, tt:6182.103\n",
      "Ep:181, loss:0.00000, loss_test:0.08662, lr:2.57e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.178, tt:6220.459\n",
      "Ep:182, loss:0.00000, loss_test:0.08638, lr:2.55e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.201, tt:6258.736\n",
      "Ep:183, loss:0.00000, loss_test:0.08633, lr:2.52e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.208, tt:6294.327\n",
      "Ep:184, loss:0.00000, loss_test:0.08651, lr:2.50e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.218, tt:6330.275\n",
      "Ep:185, loss:0.00000, loss_test:0.08649, lr:2.47e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.229, tt:6366.545\n",
      "Ep:186, loss:0.00000, loss_test:0.08630, lr:2.45e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.236, tt:6402.184\n",
      "Ep:187, loss:0.00000, loss_test:0.08649, lr:2.42e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.252, tt:6439.339\n",
      "Ep:188, loss:0.00000, loss_test:0.08645, lr:2.40e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.263, tt:6475.694\n",
      "Ep:189, loss:0.00000, loss_test:0.08623, lr:2.38e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.273, tt:6511.917\n",
      "Ep:190, loss:0.00000, loss_test:0.08620, lr:2.35e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.284, tt:6548.260\n",
      "Ep:191, loss:0.00000, loss_test:0.08634, lr:2.33e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.286, tt:6582.838\n",
      "Ep:192, loss:0.00000, loss_test:0.08643, lr:2.31e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.284, tt:6616.830\n",
      "Ep:193, loss:0.00000, loss_test:0.08642, lr:2.28e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.289, tt:6652.000\n",
      "Ep:194, loss:0.00000, loss_test:0.08626, lr:2.26e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.291, tt:6686.782\n",
      "Ep:195, loss:0.00000, loss_test:0.08672, lr:2.24e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.305, tt:6723.857\n",
      "Ep:196, loss:0.00000, loss_test:0.08685, lr:2.21e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.320, tt:6761.134\n",
      "Ep:197, loss:0.00000, loss_test:0.08665, lr:2.19e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.325, tt:6796.346\n",
      "Ep:198, loss:0.00000, loss_test:0.08629, lr:2.17e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.326, tt:6830.832\n",
      "Ep:199, loss:0.00000, loss_test:0.08635, lr:2.15e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.334, tt:6866.797\n",
      "Ep:200, loss:0.00000, loss_test:0.08667, lr:2.13e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.337, tt:6901.721\n",
      "Ep:201, loss:0.00000, loss_test:0.08663, lr:2.11e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.348, tt:6938.274\n",
      "Ep:202, loss:0.00000, loss_test:0.08626, lr:2.08e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.348, tt:6972.628\n",
      "Ep:203, loss:0.00000, loss_test:0.08606, lr:2.06e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.361, tt:7009.578\n",
      "Ep:204, loss:0.00000, loss_test:0.08658, lr:2.04e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.368, tt:7045.488\n",
      "Ep:205, loss:0.00000, loss_test:0.08688, lr:2.02e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.369, tt:7080.011\n",
      "Ep:206, loss:0.00000, loss_test:0.08674, lr:2.00e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.341, tt:7108.638\n",
      "Ep:207, loss:0.00000, loss_test:0.08625, lr:1.98e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.303, tt:7135.030\n",
      "Ep:208, loss:0.00000, loss_test:0.08592, lr:1.96e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.267, tt:7161.861\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01978, lr:6.00e-02, fs:0.64317 (r=0.839,p=0.521),  time:19.917, tt:19.917\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02082, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:22.643, tt:45.286\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02094, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.599, tt:76.797\n",
      "Ep:3, loss:0.00004, loss_test:0.01958, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:28.382, tt:113.528\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01790, lr:6.00e-02, fs:0.68067 (r=0.931,p=0.536),  time:29.608, tt:148.040\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01724, lr:6.00e-02, fs:0.72897 (r=0.897,p=0.614),  time:30.583, tt:183.497\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01715, lr:6.00e-02, fs:0.74112 (r=0.839,p=0.664),  time:31.229, tt:218.606\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00003, loss_test:0.01638, lr:6.00e-02, fs:0.73575 (r=0.816,p=0.670),  time:31.611, tt:252.886\n",
      "Ep:8, loss:0.00003, loss_test:0.01547, lr:6.00e-02, fs:0.73430 (r=0.874,p=0.633),  time:31.892, tt:287.025\n",
      "Ep:9, loss:0.00003, loss_test:0.01511, lr:6.00e-02, fs:0.72811 (r=0.908,p=0.608),  time:32.210, tt:322.103\n",
      "Ep:10, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.74074 (r=0.920,p=0.620),  time:32.587, tt:358.462\n",
      "Ep:11, loss:0.00003, loss_test:0.01454, lr:6.00e-02, fs:0.76923 (r=0.920,p=0.661),  time:32.749, tt:392.988\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01444, lr:6.00e-02, fs:0.81633 (r=0.920,p=0.734),  time:33.001, tt:429.016\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01442, lr:6.00e-02, fs:0.82723 (r=0.908,p=0.760),  time:33.224, tt:465.140\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.81053 (r=0.885,p=0.748),  time:33.329, tt:499.941\n",
      "Ep:15, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.81865 (r=0.908,p=0.745),  time:33.398, tt:534.365\n",
      "Ep:16, loss:0.00002, loss_test:0.01383, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:33.440, tt:568.475\n",
      "Ep:17, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.81675 (r=0.897,p=0.750),  time:33.499, tt:602.983\n",
      "Ep:18, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.82540 (r=0.897,p=0.765),  time:33.567, tt:637.781\n",
      "Ep:19, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:33.644, tt:672.886\n",
      "Ep:20, loss:0.00002, loss_test:0.01331, lr:6.00e-02, fs:0.82609 (r=0.874,p=0.784),  time:33.706, tt:707.824\n",
      "Ep:21, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.82609 (r=0.874,p=0.784),  time:33.725, tt:741.958\n",
      "Ep:22, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.83060 (r=0.874,p=0.792),  time:33.819, tt:777.841\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.83978 (r=0.874,p=0.809),  time:33.841, tt:812.196\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.84444 (r=0.874,p=0.817),  time:33.905, tt:847.633\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.84444 (r=0.874,p=0.817),  time:34.027, tt:884.701\n",
      "Ep:26, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:34.061, tt:919.636\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.01287, lr:6.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:34.160, tt:956.481\n",
      "Ep:28, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.86207 (r=0.862,p=0.862),  time:34.180, tt:991.228\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:34.295, tt:1028.855\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.01297, lr:6.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:34.253, tt:1061.854\n",
      "Ep:31, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:34.328, tt:1098.486\n",
      "Ep:32, loss:0.00001, loss_test:0.01324, lr:6.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:34.448, tt:1136.769\n",
      "Ep:33, loss:0.00001, loss_test:0.01331, lr:6.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:34.542, tt:1174.431\n",
      "Ep:34, loss:0.00001, loss_test:0.01331, lr:6.00e-02, fs:0.86550 (r=0.851,p=0.881),  time:34.589, tt:1210.630\n",
      "Ep:35, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:34.633, tt:1246.802\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00001, loss_test:0.01347, lr:6.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:34.666, tt:1282.657\n",
      "Ep:37, loss:0.00001, loss_test:0.01361, lr:6.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:34.676, tt:1317.680\n",
      "Ep:38, loss:0.00001, loss_test:0.01372, lr:6.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:34.712, tt:1353.750\n",
      "Ep:39, loss:0.00001, loss_test:0.01381, lr:6.00e-02, fs:0.88757 (r=0.862,p=0.915),  time:34.728, tt:1389.124\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01394, lr:6.00e-02, fs:0.88757 (r=0.862,p=0.915),  time:34.747, tt:1424.622\n",
      "Ep:41, loss:0.00001, loss_test:0.01403, lr:6.00e-02, fs:0.89286 (r=0.862,p=0.926),  time:34.746, tt:1459.353\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01417, lr:6.00e-02, fs:0.89286 (r=0.862,p=0.926),  time:34.763, tt:1494.808\n",
      "Ep:43, loss:0.00001, loss_test:0.01430, lr:6.00e-02, fs:0.89157 (r=0.851,p=0.937),  time:34.779, tt:1530.287\n",
      "Ep:44, loss:0.00001, loss_test:0.01446, lr:6.00e-02, fs:0.89157 (r=0.851,p=0.937),  time:34.895, tt:1570.279\n",
      "Ep:45, loss:0.00001, loss_test:0.01455, lr:6.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:34.860, tt:1603.551\n",
      "Ep:46, loss:0.00001, loss_test:0.01473, lr:6.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:34.902, tt:1640.382\n",
      "Ep:47, loss:0.00001, loss_test:0.01483, lr:6.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:34.919, tt:1676.125\n",
      "Ep:48, loss:0.00001, loss_test:0.01499, lr:6.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:34.880, tt:1709.116\n",
      "Ep:49, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:34.914, tt:1745.685\n",
      "Ep:50, loss:0.00001, loss_test:0.01536, lr:6.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:34.932, tt:1781.552\n",
      "Ep:51, loss:0.00001, loss_test:0.01547, lr:6.00e-02, fs:0.87654 (r=0.816,p=0.947),  time:34.910, tt:1815.310\n",
      "Ep:52, loss:0.00001, loss_test:0.01561, lr:6.00e-02, fs:0.86250 (r=0.793,p=0.945),  time:34.917, tt:1850.621\n",
      "Ep:53, loss:0.00001, loss_test:0.01569, lr:5.94e-02, fs:0.86792 (r=0.793,p=0.958),  time:34.936, tt:1886.528\n",
      "Ep:54, loss:0.00001, loss_test:0.01588, lr:5.88e-02, fs:0.86076 (r=0.782,p=0.958),  time:34.915, tt:1920.340\n",
      "Ep:55, loss:0.00001, loss_test:0.01599, lr:5.82e-02, fs:0.86624 (r=0.782,p=0.971),  time:34.937, tt:1956.454\n",
      "Ep:56, loss:0.00001, loss_test:0.01609, lr:5.76e-02, fs:0.85161 (r=0.759,p=0.971),  time:34.867, tt:1987.442\n",
      "Ep:57, loss:0.00000, loss_test:0.01621, lr:5.71e-02, fs:0.84967 (r=0.747,p=0.985),  time:34.897, tt:2024.009\n",
      "Ep:58, loss:0.00000, loss_test:0.01638, lr:5.65e-02, fs:0.81081 (r=0.690,p=0.984),  time:34.900, tt:2059.107\n",
      "Ep:59, loss:0.00000, loss_test:0.01655, lr:5.59e-02, fs:0.80272 (r=0.678,p=0.983),  time:34.919, tt:2095.157\n",
      "Ep:60, loss:0.00000, loss_test:0.01665, lr:5.54e-02, fs:0.79452 (r=0.667,p=0.983),  time:34.919, tt:2130.047\n",
      "Ep:61, loss:0.00000, loss_test:0.01678, lr:5.48e-02, fs:0.79452 (r=0.667,p=0.983),  time:34.919, tt:2164.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00000, loss_test:0.01691, lr:5.43e-02, fs:0.79452 (r=0.667,p=0.983),  time:34.952, tt:2201.974\n",
      "Ep:63, loss:0.00000, loss_test:0.01699, lr:5.37e-02, fs:0.79452 (r=0.667,p=0.983),  time:34.968, tt:2237.936\n",
      "Ep:64, loss:0.00000, loss_test:0.01706, lr:5.32e-02, fs:0.79452 (r=0.667,p=0.983),  time:34.986, tt:2274.063\n",
      "Ep:65, loss:0.00000, loss_test:0.01725, lr:5.27e-02, fs:0.79452 (r=0.667,p=0.983),  time:34.974, tt:2308.315\n",
      "Ep:66, loss:0.00000, loss_test:0.01734, lr:5.21e-02, fs:0.78621 (r=0.655,p=0.983),  time:34.980, tt:2343.684\n",
      "Ep:67, loss:0.00000, loss_test:0.01743, lr:5.16e-02, fs:0.78621 (r=0.655,p=0.983),  time:34.998, tt:2379.862\n",
      "Ep:68, loss:0.00000, loss_test:0.01755, lr:5.11e-02, fs:0.78621 (r=0.655,p=0.983),  time:34.997, tt:2414.821\n",
      "Ep:69, loss:0.00000, loss_test:0.01760, lr:5.06e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.016, tt:2451.149\n",
      "Ep:70, loss:0.00000, loss_test:0.01774, lr:5.01e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.030, tt:2487.140\n",
      "Ep:71, loss:0.00000, loss_test:0.01784, lr:4.96e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.028, tt:2521.992\n",
      "Ep:72, loss:0.00000, loss_test:0.01800, lr:4.91e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.020, tt:2556.439\n",
      "Ep:73, loss:0.00000, loss_test:0.01818, lr:4.86e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.038, tt:2592.831\n",
      "Ep:74, loss:0.00000, loss_test:0.01826, lr:4.81e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.036, tt:2627.730\n",
      "Ep:75, loss:0.00000, loss_test:0.01839, lr:4.76e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.066, tt:2665.042\n",
      "Ep:76, loss:0.00000, loss_test:0.01853, lr:4.71e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.082, tt:2701.341\n",
      "Ep:77, loss:0.00000, loss_test:0.01857, lr:4.67e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.052, tt:2734.045\n",
      "Ep:78, loss:0.00000, loss_test:0.01871, lr:4.62e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.066, tt:2770.212\n",
      "Ep:79, loss:0.00000, loss_test:0.01879, lr:4.57e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.081, tt:2806.467\n",
      "Ep:80, loss:0.00000, loss_test:0.01887, lr:4.53e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.069, tt:2840.557\n",
      "Ep:81, loss:0.00000, loss_test:0.01903, lr:4.48e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.073, tt:2875.955\n",
      "Ep:82, loss:0.00000, loss_test:0.01912, lr:4.44e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.092, tt:2912.653\n",
      "Ep:83, loss:0.00000, loss_test:0.01917, lr:4.39e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.082, tt:2946.928\n",
      "Ep:84, loss:0.00000, loss_test:0.01929, lr:4.35e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.090, tt:2982.688\n",
      "Ep:85, loss:0.00000, loss_test:0.01934, lr:4.31e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.109, tt:3019.336\n",
      "Ep:86, loss:0.00000, loss_test:0.01949, lr:4.26e-02, fs:0.78621 (r=0.655,p=0.983),  time:35.175, tt:3060.244\n",
      "Ep:87, loss:0.00000, loss_test:0.01956, lr:4.22e-02, fs:0.79167 (r=0.655,p=1.000),  time:35.186, tt:3096.396\n",
      "Ep:88, loss:0.00000, loss_test:0.01963, lr:4.18e-02, fs:0.79167 (r=0.655,p=1.000),  time:35.188, tt:3131.771\n",
      "Ep:89, loss:0.00000, loss_test:0.01976, lr:4.14e-02, fs:0.79167 (r=0.655,p=1.000),  time:35.182, tt:3166.386\n",
      "Ep:90, loss:0.00000, loss_test:0.01984, lr:4.10e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.185, tt:3201.846\n",
      "Ep:91, loss:0.00000, loss_test:0.01996, lr:4.05e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.184, tt:3236.905\n",
      "Ep:92, loss:0.00000, loss_test:0.02004, lr:4.01e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.173, tt:3271.099\n",
      "Ep:93, loss:0.00000, loss_test:0.02010, lr:3.97e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.183, tt:3307.215\n",
      "Ep:94, loss:0.00000, loss_test:0.02020, lr:3.93e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.177, tt:3341.801\n",
      "Ep:95, loss:0.00000, loss_test:0.02028, lr:3.89e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.177, tt:3376.946\n",
      "Ep:96, loss:0.00000, loss_test:0.02035, lr:3.86e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.173, tt:3411.826\n",
      "Ep:97, loss:0.00000, loss_test:0.02043, lr:3.82e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.165, tt:3446.141\n",
      "Ep:98, loss:0.00000, loss_test:0.02048, lr:3.78e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.161, tt:3480.983\n",
      "Ep:99, loss:0.00000, loss_test:0.02055, lr:3.74e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.161, tt:3516.078\n",
      "Ep:100, loss:0.00000, loss_test:0.02064, lr:3.70e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.162, tt:3551.406\n",
      "Ep:101, loss:0.00000, loss_test:0.02077, lr:3.67e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.171, tt:3587.453\n",
      "Ep:102, loss:0.00000, loss_test:0.02080, lr:3.63e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.157, tt:3621.205\n",
      "Ep:103, loss:0.00000, loss_test:0.02087, lr:3.59e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.152, tt:3655.799\n",
      "Ep:104, loss:0.00000, loss_test:0.02099, lr:3.56e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.142, tt:3689.902\n",
      "Ep:105, loss:0.00000, loss_test:0.02102, lr:3.52e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.157, tt:3726.617\n",
      "Ep:106, loss:0.00000, loss_test:0.02110, lr:3.49e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.139, tt:3759.890\n",
      "Ep:107, loss:0.00000, loss_test:0.02116, lr:3.45e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.107, tt:3791.526\n",
      "Ep:108, loss:0.00000, loss_test:0.02121, lr:3.42e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.084, tt:3824.185\n",
      "Ep:109, loss:0.00000, loss_test:0.02130, lr:3.38e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.058, tt:3856.385\n",
      "Ep:110, loss:0.00000, loss_test:0.02136, lr:3.35e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.036, tt:3889.004\n",
      "Ep:111, loss:0.00000, loss_test:0.02144, lr:3.32e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.990, tt:3918.913\n",
      "Ep:112, loss:0.00000, loss_test:0.02151, lr:3.28e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.942, tt:3948.421\n",
      "Ep:113, loss:0.00000, loss_test:0.02154, lr:3.25e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.925, tt:3981.440\n",
      "Ep:114, loss:0.00000, loss_test:0.02161, lr:3.22e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.908, tt:4014.392\n",
      "Ep:115, loss:0.00000, loss_test:0.02170, lr:3.19e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.955, tt:4054.752\n",
      "Ep:116, loss:0.00000, loss_test:0.02175, lr:3.15e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.938, tt:4087.696\n",
      "Ep:117, loss:0.00000, loss_test:0.02181, lr:3.12e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.939, tt:4122.795\n",
      "Ep:118, loss:0.00000, loss_test:0.02188, lr:3.09e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.930, tt:4156.655\n",
      "Ep:119, loss:0.00000, loss_test:0.02193, lr:3.06e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.932, tt:4191.899\n",
      "Ep:120, loss:0.00000, loss_test:0.02199, lr:3.03e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.938, tt:4227.477\n",
      "Ep:121, loss:0.00000, loss_test:0.02202, lr:3.00e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.936, tt:4262.177\n",
      "Ep:122, loss:0.00000, loss_test:0.02209, lr:2.97e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.949, tt:4298.712\n",
      "Ep:123, loss:0.00000, loss_test:0.02217, lr:2.94e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.969, tt:4336.103\n",
      "Ep:124, loss:0.00000, loss_test:0.02218, lr:2.91e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.976, tt:4372.035\n",
      "Ep:125, loss:0.00000, loss_test:0.02225, lr:2.88e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.980, tt:4407.500\n",
      "Ep:126, loss:0.00000, loss_test:0.02234, lr:2.85e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.993, tt:4444.055\n",
      "Ep:127, loss:0.00000, loss_test:0.02234, lr:2.82e-02, fs:0.78322 (r=0.644,p=1.000),  time:34.991, tt:4478.831\n",
      "Ep:128, loss:0.00000, loss_test:0.02240, lr:2.80e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.005, tt:4515.662\n",
      "Ep:129, loss:0.00000, loss_test:0.02247, lr:2.77e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.029, tt:4553.762\n",
      "Ep:130, loss:0.00000, loss_test:0.02250, lr:2.74e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.039, tt:4590.073\n",
      "Ep:131, loss:0.00000, loss_test:0.02257, lr:2.71e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.039, tt:4625.212\n",
      "Ep:132, loss:0.00000, loss_test:0.02263, lr:2.69e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.032, tt:4659.320\n",
      "Ep:133, loss:0.00000, loss_test:0.02267, lr:2.66e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.017, tt:4692.245\n",
      "Ep:134, loss:0.00000, loss_test:0.02271, lr:2.63e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.022, tt:4728.031\n",
      "Ep:135, loss:0.00000, loss_test:0.02276, lr:2.61e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.027, tt:4763.703\n",
      "Ep:136, loss:0.00000, loss_test:0.02280, lr:2.58e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.034, tt:4799.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02285, lr:2.55e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.030, tt:4834.098\n",
      "Ep:138, loss:0.00000, loss_test:0.02287, lr:2.53e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.041, tt:4870.742\n",
      "Ep:139, loss:0.00000, loss_test:0.02289, lr:2.50e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.128, tt:4917.888\n",
      "Ep:140, loss:0.00000, loss_test:0.02296, lr:2.48e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.122, tt:4952.220\n",
      "Ep:141, loss:0.00000, loss_test:0.02300, lr:2.45e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.125, tt:4987.731\n",
      "Ep:142, loss:0.00000, loss_test:0.02305, lr:2.43e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.122, tt:5022.510\n",
      "Ep:143, loss:0.00000, loss_test:0.02307, lr:2.40e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.155, tt:5062.285\n",
      "Ep:144, loss:0.00000, loss_test:0.02309, lr:2.38e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.150, tt:5096.692\n",
      "Ep:145, loss:0.00000, loss_test:0.02315, lr:2.36e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.155, tt:5132.653\n",
      "Ep:146, loss:0.00000, loss_test:0.02319, lr:2.33e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.154, tt:5167.568\n",
      "Ep:147, loss:0.00000, loss_test:0.02318, lr:2.31e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.160, tt:5203.643\n",
      "Ep:148, loss:0.00000, loss_test:0.02324, lr:2.29e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.169, tt:5240.197\n",
      "Ep:149, loss:0.00000, loss_test:0.02330, lr:2.26e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.173, tt:5276.007\n",
      "Ep:150, loss:0.00000, loss_test:0.02331, lr:2.24e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.186, tt:5313.013\n",
      "Ep:151, loss:0.00000, loss_test:0.02335, lr:2.22e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.180, tt:5347.428\n",
      "Ep:152, loss:0.00000, loss_test:0.02340, lr:2.20e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.184, tt:5383.163\n",
      "Ep:153, loss:0.00000, loss_test:0.02341, lr:2.17e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.193, tt:5419.683\n",
      "Ep:154, loss:0.00000, loss_test:0.02345, lr:2.15e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.186, tt:5453.886\n",
      "Ep:155, loss:0.00000, loss_test:0.02349, lr:2.13e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.175, tt:5487.312\n",
      "Ep:156, loss:0.00000, loss_test:0.02351, lr:2.11e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.179, tt:5523.118\n",
      "Ep:157, loss:0.00000, loss_test:0.02353, lr:2.09e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.181, tt:5558.522\n",
      "Ep:158, loss:0.00000, loss_test:0.02356, lr:2.07e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.187, tt:5594.676\n",
      "Ep:159, loss:0.00000, loss_test:0.02358, lr:2.05e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.198, tt:5631.699\n",
      "Ep:160, loss:0.00000, loss_test:0.02362, lr:2.03e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.199, tt:5667.054\n",
      "Ep:161, loss:0.00000, loss_test:0.02367, lr:2.01e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.209, tt:5703.922\n",
      "Ep:162, loss:0.00000, loss_test:0.02367, lr:1.99e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.210, tt:5739.284\n",
      "Ep:163, loss:0.00000, loss_test:0.02370, lr:1.97e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.209, tt:5774.327\n",
      "Ep:164, loss:0.00000, loss_test:0.02372, lr:1.95e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.211, tt:5809.795\n",
      "Ep:165, loss:0.00000, loss_test:0.02376, lr:1.93e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.218, tt:5846.254\n",
      "Ep:166, loss:0.00000, loss_test:0.02379, lr:1.91e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.224, tt:5882.349\n",
      "Ep:167, loss:0.00000, loss_test:0.02379, lr:1.89e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.229, tt:5918.535\n",
      "Ep:168, loss:0.00000, loss_test:0.02383, lr:1.87e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.234, tt:5954.570\n",
      "Ep:169, loss:0.00000, loss_test:0.02387, lr:1.85e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.237, tt:5990.284\n",
      "Ep:170, loss:0.00000, loss_test:0.02390, lr:1.83e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.237, tt:6025.591\n",
      "Ep:171, loss:0.00000, loss_test:0.02391, lr:1.81e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.251, tt:6063.172\n",
      "Ep:172, loss:0.00000, loss_test:0.02393, lr:1.80e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.244, tt:6097.254\n",
      "Ep:173, loss:0.00000, loss_test:0.02397, lr:1.78e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.250, tt:6133.569\n",
      "Ep:174, loss:0.00000, loss_test:0.02398, lr:1.76e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.255, tt:6169.577\n",
      "Ep:175, loss:0.00000, loss_test:0.02400, lr:1.74e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.259, tt:6205.605\n",
      "Ep:176, loss:0.00000, loss_test:0.02403, lr:1.73e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.250, tt:6239.333\n",
      "Ep:177, loss:0.00000, loss_test:0.02405, lr:1.71e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.250, tt:6274.471\n",
      "Ep:178, loss:0.00000, loss_test:0.02408, lr:1.69e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.245, tt:6308.886\n",
      "Ep:179, loss:0.00000, loss_test:0.02413, lr:1.67e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.243, tt:6343.677\n",
      "Ep:180, loss:0.00000, loss_test:0.02416, lr:1.66e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.246, tt:6379.452\n",
      "Ep:181, loss:0.00000, loss_test:0.02416, lr:1.64e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.238, tt:6413.274\n",
      "Ep:182, loss:0.00000, loss_test:0.02418, lr:1.62e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.240, tt:6448.968\n",
      "Ep:183, loss:0.00000, loss_test:0.02422, lr:1.61e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.233, tt:6482.831\n",
      "Ep:184, loss:0.00000, loss_test:0.02423, lr:1.59e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.233, tt:6518.040\n",
      "Ep:185, loss:0.00000, loss_test:0.02424, lr:1.58e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.234, tt:6553.460\n",
      "Ep:186, loss:0.00000, loss_test:0.02427, lr:1.56e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.233, tt:6588.646\n",
      "Ep:187, loss:0.00000, loss_test:0.02428, lr:1.54e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.239, tt:6624.906\n",
      "Ep:188, loss:0.00000, loss_test:0.02429, lr:1.53e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.242, tt:6660.707\n",
      "Ep:189, loss:0.00000, loss_test:0.02432, lr:1.51e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.264, tt:6700.123\n",
      "Ep:190, loss:0.00000, loss_test:0.02434, lr:1.50e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.258, tt:6734.273\n",
      "Ep:191, loss:0.00000, loss_test:0.02436, lr:1.48e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.261, tt:6770.132\n",
      "Ep:192, loss:0.00000, loss_test:0.02439, lr:1.47e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.264, tt:6805.979\n",
      "Ep:193, loss:0.00000, loss_test:0.02439, lr:1.45e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.268, tt:6842.038\n",
      "Ep:194, loss:0.00000, loss_test:0.02441, lr:1.44e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.277, tt:6878.942\n",
      "Ep:195, loss:0.00000, loss_test:0.02445, lr:1.43e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.275, tt:6913.865\n",
      "Ep:196, loss:0.00000, loss_test:0.02446, lr:1.41e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.275, tt:6949.109\n",
      "Ep:197, loss:0.00000, loss_test:0.02447, lr:1.40e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.275, tt:6984.404\n",
      "Ep:198, loss:0.00000, loss_test:0.02448, lr:1.38e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.274, tt:7019.592\n",
      "Ep:199, loss:0.00000, loss_test:0.02450, lr:1.37e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.267, tt:7053.400\n",
      "Ep:200, loss:0.00000, loss_test:0.02452, lr:1.36e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.262, tt:7087.564\n",
      "Ep:201, loss:0.00000, loss_test:0.02453, lr:1.34e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.262, tt:7122.875\n",
      "Ep:202, loss:0.00000, loss_test:0.02457, lr:1.33e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.259, tt:7157.542\n",
      "Ep:203, loss:0.00000, loss_test:0.02457, lr:1.32e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.264, tt:7193.773\n",
      "Ep:204, loss:0.00000, loss_test:0.02459, lr:1.30e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.272, tt:7230.746\n",
      "Ep:205, loss:0.00000, loss_test:0.02462, lr:1.29e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.265, tt:7264.501\n",
      "Ep:206, loss:0.00000, loss_test:0.02463, lr:1.28e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.264, tt:7299.716\n",
      "Ep:207, loss:0.00000, loss_test:0.02463, lr:1.26e-02, fs:0.78322 (r=0.644,p=1.000),  time:35.259, tt:7333.924\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00028, loss_test:0.14255, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.451, tt:28.451\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14140, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:31.995, tt:63.989\n",
      "Ep:2, loss:0.00028, loss_test:0.13948, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:31.286, tt:93.858\n",
      "Ep:3, loss:0.00028, loss_test:0.13641, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:32.321, tt:129.285\n",
      "Ep:4, loss:0.00027, loss_test:0.13140, lr:1.00e-02, fs:0.65863 (r=0.943,p=0.506),  time:33.128, tt:165.641\n",
      "Ep:5, loss:0.00026, loss_test:0.12301, lr:1.00e-02, fs:0.68067 (r=0.931,p=0.536),  time:33.719, tt:202.316\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11241, lr:1.00e-02, fs:0.69444 (r=0.862,p=0.581),  time:33.975, tt:237.823\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10778, lr:1.00e-02, fs:0.67760 (r=0.713,p=0.646),  time:34.128, tt:273.021\n",
      "Ep:8, loss:0.00022, loss_test:0.10792, lr:1.00e-02, fs:0.68235 (r=0.667,p=0.699),  time:34.217, tt:307.953\n",
      "Ep:9, loss:0.00022, loss_test:0.10420, lr:1.00e-02, fs:0.70455 (r=0.713,p=0.697),  time:34.194, tt:341.938\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10139, lr:1.00e-02, fs:0.71038 (r=0.747,p=0.677),  time:34.414, tt:378.550\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09859, lr:1.00e-02, fs:0.73034 (r=0.747,p=0.714),  time:34.454, tt:413.451\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09644, lr:1.00e-02, fs:0.74419 (r=0.736,p=0.753),  time:34.447, tt:447.814\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09308, lr:1.00e-02, fs:0.75706 (r=0.770,p=0.744),  time:34.676, tt:485.470\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09001, lr:1.00e-02, fs:0.77966 (r=0.793,p=0.767),  time:34.607, tt:519.102\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08755, lr:1.00e-02, fs:0.80460 (r=0.805,p=0.805),  time:34.591, tt:553.454\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08506, lr:1.00e-02, fs:0.80000 (r=0.805,p=0.795),  time:34.594, tt:588.100\n",
      "Ep:17, loss:0.00015, loss_test:0.08284, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:34.514, tt:621.245\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08159, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:34.608, tt:657.544\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.07946, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:34.660, tt:693.208\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.07802, lr:1.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:34.695, tt:728.602\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.07630, lr:1.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:34.768, tt:764.887\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.07481, lr:1.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:34.611, tt:796.046\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.07345, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:34.732, tt:833.564\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07248, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:34.738, tt:868.439\n",
      "Ep:25, loss:0.00010, loss_test:0.07130, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:34.732, tt:903.034\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07010, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:34.805, tt:939.738\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.06939, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:34.864, tt:976.200\n",
      "Ep:28, loss:0.00009, loss_test:0.06838, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:34.927, tt:1012.879\n",
      "Ep:29, loss:0.00008, loss_test:0.06818, lr:1.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:34.885, tt:1046.546\n",
      "Ep:30, loss:0.00008, loss_test:0.06770, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:34.860, tt:1080.666\n",
      "Ep:31, loss:0.00008, loss_test:0.06777, lr:1.00e-02, fs:0.87719 (r=0.862,p=0.893),  time:34.864, tt:1115.634\n",
      "Ep:32, loss:0.00007, loss_test:0.06631, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:34.829, tt:1149.364\n",
      "Ep:33, loss:0.00007, loss_test:0.06853, lr:1.00e-02, fs:0.90286 (r=0.908,p=0.898),  time:34.854, tt:1185.036\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06727, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:34.887, tt:1221.031\n",
      "Ep:35, loss:0.00006, loss_test:0.06701, lr:1.00e-02, fs:0.90286 (r=0.908,p=0.898),  time:34.928, tt:1257.414\n",
      "Ep:36, loss:0.00006, loss_test:0.06828, lr:1.00e-02, fs:0.89697 (r=0.851,p=0.949),  time:34.976, tt:1294.100\n",
      "Ep:37, loss:0.00006, loss_test:0.06582, lr:1.00e-02, fs:0.89017 (r=0.885,p=0.895),  time:35.007, tt:1330.259\n",
      "Ep:38, loss:0.00005, loss_test:0.06899, lr:1.00e-02, fs:0.90244 (r=0.851,p=0.961),  time:35.035, tt:1366.376\n",
      "Ep:39, loss:0.00005, loss_test:0.06461, lr:1.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:35.098, tt:1403.911\n",
      "Ep:40, loss:0.00005, loss_test:0.06752, lr:1.00e-02, fs:0.89697 (r=0.851,p=0.949),  time:35.057, tt:1437.354\n",
      "Ep:41, loss:0.00004, loss_test:0.06342, lr:1.00e-02, fs:0.88199 (r=0.816,p=0.959),  time:35.051, tt:1472.159\n",
      "Ep:42, loss:0.00004, loss_test:0.06911, lr:1.00e-02, fs:0.89697 (r=0.851,p=0.949),  time:35.060, tt:1507.584\n",
      "Ep:43, loss:0.00004, loss_test:0.06618, lr:1.00e-02, fs:0.87500 (r=0.805,p=0.959),  time:35.043, tt:1541.906\n",
      "Ep:44, loss:0.00003, loss_test:0.06607, lr:1.00e-02, fs:0.90798 (r=0.851,p=0.974),  time:35.071, tt:1578.173\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.06304, lr:1.00e-02, fs:0.90798 (r=0.851,p=0.974),  time:35.084, tt:1613.866\n",
      "Ep:46, loss:0.00003, loss_test:0.06774, lr:1.00e-02, fs:0.91358 (r=0.851,p=0.987),  time:35.122, tt:1650.728\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.06423, lr:1.00e-02, fs:0.90798 (r=0.851,p=0.974),  time:35.167, tt:1687.995\n",
      "Ep:48, loss:0.00003, loss_test:0.07054, lr:1.00e-02, fs:0.88608 (r=0.805,p=0.986),  time:35.208, tt:1725.186\n",
      "Ep:49, loss:0.00003, loss_test:0.06337, lr:1.00e-02, fs:0.90244 (r=0.851,p=0.961),  time:35.241, tt:1762.074\n",
      "Ep:50, loss:0.00002, loss_test:0.06900, lr:1.00e-02, fs:0.88750 (r=0.816,p=0.973),  time:35.280, tt:1799.274\n",
      "Ep:51, loss:0.00002, loss_test:0.06833, lr:1.00e-02, fs:0.88050 (r=0.805,p=0.972),  time:35.316, tt:1836.452\n",
      "Ep:52, loss:0.00002, loss_test:0.06906, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:35.355, tt:1873.815\n",
      "Ep:53, loss:0.00002, loss_test:0.06889, lr:1.00e-02, fs:0.88050 (r=0.805,p=0.972),  time:35.408, tt:1912.046\n",
      "Ep:54, loss:0.00002, loss_test:0.06732, lr:1.00e-02, fs:0.90798 (r=0.851,p=0.974),  time:35.443, tt:1949.353\n",
      "Ep:55, loss:0.00002, loss_test:0.06785, lr:1.00e-02, fs:0.87898 (r=0.793,p=0.986),  time:35.501, tt:1988.046\n",
      "Ep:56, loss:0.00002, loss_test:0.06820, lr:1.00e-02, fs:0.91358 (r=0.851,p=0.987),  time:35.520, tt:2024.657\n",
      "Ep:57, loss:0.00002, loss_test:0.06801, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:35.510, tt:2059.596\n",
      "Ep:58, loss:0.00001, loss_test:0.06732, lr:9.90e-03, fs:0.90000 (r=0.828,p=0.986),  time:35.517, tt:2095.477\n",
      "Ep:59, loss:0.00001, loss_test:0.06986, lr:9.80e-03, fs:0.90683 (r=0.839,p=0.986),  time:35.553, tt:2133.192\n",
      "Ep:60, loss:0.00001, loss_test:0.06964, lr:9.70e-03, fs:0.89308 (r=0.816,p=0.986),  time:35.568, tt:2169.658\n",
      "Ep:61, loss:0.00001, loss_test:0.07082, lr:9.61e-03, fs:0.88608 (r=0.805,p=0.986),  time:35.622, tt:2208.585\n",
      "Ep:62, loss:0.00001, loss_test:0.07130, lr:9.51e-03, fs:0.87179 (r=0.782,p=0.986),  time:35.629, tt:2244.652\n",
      "Ep:63, loss:0.00001, loss_test:0.06964, lr:9.41e-03, fs:0.91358 (r=0.851,p=0.987),  time:35.634, tt:2280.551\n",
      "Ep:64, loss:0.00001, loss_test:0.07148, lr:9.32e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.654, tt:2317.500\n",
      "Ep:65, loss:0.00001, loss_test:0.07137, lr:9.23e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.684, tt:2355.122\n",
      "Ep:66, loss:0.00001, loss_test:0.07122, lr:9.14e-03, fs:0.85714 (r=0.759,p=0.985),  time:35.690, tt:2391.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.07182, lr:9.04e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.664, tt:2425.150\n",
      "Ep:68, loss:0.00001, loss_test:0.07035, lr:8.95e-03, fs:0.90683 (r=0.839,p=0.986),  time:35.646, tt:2459.549\n",
      "Ep:69, loss:0.00001, loss_test:0.07145, lr:8.86e-03, fs:0.86452 (r=0.770,p=0.985),  time:35.679, tt:2497.496\n",
      "Ep:70, loss:0.00001, loss_test:0.07344, lr:8.78e-03, fs:0.77778 (r=0.644,p=0.982),  time:35.679, tt:2533.239\n",
      "Ep:71, loss:0.00001, loss_test:0.07070, lr:8.69e-03, fs:0.85714 (r=0.759,p=0.985),  time:35.674, tt:2568.538\n",
      "Ep:72, loss:0.00001, loss_test:0.07084, lr:8.60e-03, fs:0.84967 (r=0.747,p=0.985),  time:35.656, tt:2602.914\n",
      "Ep:73, loss:0.00001, loss_test:0.07270, lr:8.51e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.677, tt:2640.105\n",
      "Ep:74, loss:0.00001, loss_test:0.07120, lr:8.43e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.657, tt:2674.253\n",
      "Ep:75, loss:0.00001, loss_test:0.07160, lr:8.35e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.665, tt:2710.577\n",
      "Ep:76, loss:0.00000, loss_test:0.07141, lr:8.26e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.652, tt:2745.201\n",
      "Ep:77, loss:0.00000, loss_test:0.07135, lr:8.18e-03, fs:0.79452 (r=0.667,p=0.983),  time:35.659, tt:2781.413\n",
      "Ep:78, loss:0.00000, loss_test:0.07180, lr:8.10e-03, fs:0.79452 (r=0.667,p=0.983),  time:35.629, tt:2814.706\n",
      "Ep:79, loss:0.00000, loss_test:0.07150, lr:8.02e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.646, tt:2851.705\n",
      "Ep:80, loss:0.00000, loss_test:0.07179, lr:7.94e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.659, tt:2888.348\n",
      "Ep:81, loss:0.00000, loss_test:0.07234, lr:7.86e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.657, tt:2923.900\n",
      "Ep:82, loss:0.00000, loss_test:0.07184, lr:7.78e-03, fs:0.80272 (r=0.678,p=0.983),  time:35.653, tt:2959.166\n",
      "Ep:83, loss:0.00000, loss_test:0.07208, lr:7.70e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.685, tt:2997.513\n",
      "Ep:84, loss:0.00000, loss_test:0.07243, lr:7.62e-03, fs:0.78621 (r=0.655,p=0.983),  time:35.695, tt:3034.104\n",
      "Ep:85, loss:0.00000, loss_test:0.07193, lr:7.55e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.697, tt:3069.919\n",
      "Ep:86, loss:0.00000, loss_test:0.07168, lr:7.47e-03, fs:0.81879 (r=0.701,p=0.984),  time:35.716, tt:3107.310\n",
      "Ep:87, loss:0.00000, loss_test:0.07276, lr:7.40e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.725, tt:3143.795\n",
      "Ep:88, loss:0.00000, loss_test:0.07267, lr:7.32e-03, fs:0.77778 (r=0.644,p=0.982),  time:35.748, tt:3181.578\n",
      "Ep:89, loss:0.00000, loss_test:0.07271, lr:7.25e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.725, tt:3215.282\n",
      "Ep:90, loss:0.00000, loss_test:0.07260, lr:7.18e-03, fs:0.77778 (r=0.644,p=0.982),  time:35.735, tt:3251.857\n",
      "Ep:91, loss:0.00000, loss_test:0.07237, lr:7.11e-03, fs:0.81879 (r=0.701,p=0.984),  time:35.723, tt:3286.531\n",
      "Ep:92, loss:0.00000, loss_test:0.07235, lr:7.03e-03, fs:0.81081 (r=0.690,p=0.984),  time:35.718, tt:3321.778\n",
      "Ep:93, loss:0.00000, loss_test:0.07197, lr:6.96e-03, fs:0.80272 (r=0.678,p=0.983),  time:35.692, tt:3355.017\n",
      "Ep:94, loss:0.00000, loss_test:0.07214, lr:6.89e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.671, tt:3388.776\n",
      "Ep:95, loss:0.00000, loss_test:0.07222, lr:6.83e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.655, tt:3422.886\n",
      "Ep:96, loss:0.00000, loss_test:0.07219, lr:6.76e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.651, tt:3458.132\n",
      "Ep:97, loss:0.00000, loss_test:0.07218, lr:6.69e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.643, tt:3492.989\n",
      "Ep:98, loss:0.00000, loss_test:0.07235, lr:6.62e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.655, tt:3529.816\n",
      "Ep:99, loss:0.00000, loss_test:0.07204, lr:6.56e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.643, tt:3564.289\n",
      "Ep:100, loss:0.00000, loss_test:0.07227, lr:6.49e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.632, tt:3598.828\n",
      "Ep:101, loss:0.00000, loss_test:0.07244, lr:6.43e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.587, tt:3629.904\n",
      "Ep:102, loss:0.00000, loss_test:0.07216, lr:6.36e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.556, tt:3662.256\n",
      "Ep:103, loss:0.00000, loss_test:0.07246, lr:6.30e-03, fs:0.80272 (r=0.678,p=0.983),  time:35.532, tt:3695.376\n",
      "Ep:104, loss:0.00000, loss_test:0.07244, lr:6.24e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.537, tt:3731.356\n",
      "Ep:105, loss:0.00000, loss_test:0.07231, lr:6.17e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.478, tt:3760.691\n",
      "Ep:106, loss:0.00000, loss_test:0.07293, lr:6.11e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.426, tt:3790.620\n",
      "Ep:107, loss:0.00000, loss_test:0.07302, lr:6.05e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.389, tt:3822.050\n",
      "Ep:108, loss:0.00000, loss_test:0.07242, lr:5.99e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.339, tt:3851.965\n",
      "Ep:109, loss:0.00000, loss_test:0.07251, lr:5.93e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.299, tt:3882.920\n",
      "Ep:110, loss:0.00000, loss_test:0.07272, lr:5.87e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.267, tt:3914.655\n",
      "Ep:111, loss:0.00000, loss_test:0.07235, lr:5.81e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.209, tt:3943.353\n",
      "Ep:112, loss:0.00000, loss_test:0.07259, lr:5.75e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.187, tt:3976.094\n",
      "Ep:113, loss:0.00000, loss_test:0.07244, lr:5.70e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.139, tt:4005.865\n",
      "Ep:114, loss:0.00000, loss_test:0.07226, lr:5.64e-03, fs:0.83444 (r=0.724,p=0.984),  time:35.093, tt:4035.715\n",
      "Ep:115, loss:0.00000, loss_test:0.07244, lr:5.58e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.059, tt:4066.848\n",
      "Ep:116, loss:0.00000, loss_test:0.07264, lr:5.53e-03, fs:0.82667 (r=0.713,p=0.984),  time:35.039, tt:4099.578\n",
      "Ep:117, loss:0.00000, loss_test:0.07242, lr:5.47e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.991, tt:4128.886\n",
      "Ep:118, loss:0.00000, loss_test:0.07217, lr:5.42e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.948, tt:4158.754\n",
      "Ep:119, loss:0.00000, loss_test:0.07236, lr:5.36e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.909, tt:4189.137\n",
      "Ep:120, loss:0.00000, loss_test:0.07241, lr:5.31e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.867, tt:4218.880\n",
      "Ep:121, loss:0.00000, loss_test:0.07227, lr:5.26e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.839, tt:4250.356\n",
      "Ep:122, loss:0.00000, loss_test:0.07234, lr:5.20e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.797, tt:4280.063\n",
      "Ep:123, loss:0.00000, loss_test:0.07252, lr:5.15e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.765, tt:4310.898\n",
      "Ep:124, loss:0.00000, loss_test:0.07236, lr:5.10e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.712, tt:4339.055\n",
      "Ep:125, loss:0.00000, loss_test:0.07234, lr:5.05e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.677, tt:4369.345\n",
      "Ep:126, loss:0.00000, loss_test:0.07246, lr:5.00e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.636, tt:4398.765\n",
      "Ep:127, loss:0.00000, loss_test:0.07244, lr:4.95e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.599, tt:4428.684\n",
      "Ep:128, loss:0.00000, loss_test:0.07228, lr:4.90e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.577, tt:4460.372\n",
      "Ep:129, loss:0.00000, loss_test:0.07240, lr:4.85e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.560, tt:4492.801\n",
      "Ep:130, loss:0.00000, loss_test:0.07261, lr:4.80e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.546, tt:4525.524\n",
      "Ep:131, loss:0.00000, loss_test:0.07248, lr:4.75e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.532, tt:4558.188\n",
      "Ep:132, loss:0.00000, loss_test:0.07242, lr:4.71e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.515, tt:4590.552\n",
      "Ep:133, loss:0.00000, loss_test:0.07265, lr:4.66e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.498, tt:4622.683\n",
      "Ep:134, loss:0.00000, loss_test:0.07258, lr:4.61e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.484, tt:4655.316\n",
      "Ep:135, loss:0.00000, loss_test:0.07246, lr:4.57e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.471, tt:4688.035\n",
      "Ep:136, loss:0.00000, loss_test:0.07261, lr:4.52e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.457, tt:4720.626\n",
      "Ep:137, loss:0.00000, loss_test:0.07281, lr:4.48e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.428, tt:4751.006\n",
      "Ep:138, loss:0.00000, loss_test:0.07272, lr:4.43e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.422, tt:4784.605\n",
      "Ep:139, loss:0.00000, loss_test:0.07265, lr:4.39e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.394, tt:4815.113\n",
      "Ep:140, loss:0.00000, loss_test:0.07273, lr:4.34e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.379, tt:4847.382\n",
      "Ep:141, loss:0.00000, loss_test:0.07296, lr:4.30e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.377, tt:4881.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.07291, lr:4.26e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.370, tt:4914.851\n",
      "Ep:143, loss:0.00000, loss_test:0.07267, lr:4.21e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.357, tt:4947.359\n",
      "Ep:144, loss:0.00000, loss_test:0.07267, lr:4.17e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.336, tt:4978.659\n",
      "Ep:145, loss:0.00000, loss_test:0.07280, lr:4.13e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.324, tt:5011.305\n",
      "Ep:146, loss:0.00000, loss_test:0.07288, lr:4.09e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.301, tt:5042.220\n",
      "Ep:147, loss:0.00000, loss_test:0.07291, lr:4.05e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.274, tt:5072.527\n",
      "Ep:148, loss:0.00000, loss_test:0.07281, lr:4.01e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.252, tt:5103.619\n",
      "Ep:149, loss:0.00000, loss_test:0.07292, lr:3.97e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.242, tt:5136.326\n",
      "Ep:150, loss:0.00000, loss_test:0.07307, lr:3.93e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.206, tt:5165.091\n",
      "Ep:151, loss:0.00000, loss_test:0.07321, lr:3.89e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.175, tt:5194.618\n",
      "Ep:152, loss:0.00000, loss_test:0.07322, lr:3.85e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.156, tt:5225.918\n",
      "Ep:153, loss:0.00000, loss_test:0.07303, lr:3.81e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.137, tt:5257.034\n",
      "Ep:154, loss:0.00000, loss_test:0.07310, lr:3.77e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.120, tt:5288.642\n",
      "Ep:155, loss:0.00000, loss_test:0.07319, lr:3.73e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.118, tt:5322.378\n",
      "Ep:156, loss:0.00000, loss_test:0.07334, lr:3.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:34.106, tt:5354.601\n",
      "Ep:157, loss:0.00000, loss_test:0.07344, lr:3.66e-03, fs:0.82667 (r=0.713,p=0.984),  time:34.094, tt:5386.895\n",
      "Ep:158, loss:0.00000, loss_test:0.07322, lr:3.62e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.080, tt:5418.679\n",
      "Ep:159, loss:0.00000, loss_test:0.07306, lr:3.59e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.067, tt:5450.719\n",
      "Ep:160, loss:0.00000, loss_test:0.07330, lr:3.55e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.065, tt:5484.537\n",
      "Ep:161, loss:0.00000, loss_test:0.07331, lr:3.52e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.048, tt:5515.729\n",
      "Ep:162, loss:0.00000, loss_test:0.07318, lr:3.48e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.041, tt:5548.619\n",
      "Ep:163, loss:0.00000, loss_test:0.07321, lr:3.45e-03, fs:0.83444 (r=0.724,p=0.984),  time:34.008, tt:5577.379\n",
      "Ep:164, loss:0.00000, loss_test:0.07353, lr:3.41e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.981, tt:5606.946\n",
      "Ep:165, loss:0.00000, loss_test:0.07340, lr:3.38e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.984, tt:5641.321\n",
      "Ep:166, loss:0.00000, loss_test:0.07334, lr:3.34e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.988, tt:5676.024\n",
      "Ep:167, loss:0.00000, loss_test:0.07326, lr:3.31e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.954, tt:5704.307\n",
      "Ep:168, loss:0.00000, loss_test:0.07352, lr:3.28e-03, fs:0.82667 (r=0.713,p=0.984),  time:33.937, tt:5735.274\n",
      "Ep:169, loss:0.00000, loss_test:0.07363, lr:3.24e-03, fs:0.79452 (r=0.667,p=0.983),  time:33.927, tt:5767.568\n",
      "Ep:170, loss:0.00000, loss_test:0.07368, lr:3.21e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.897, tt:5796.347\n",
      "Ep:171, loss:0.00000, loss_test:0.07354, lr:3.18e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.878, tt:5827.058\n",
      "Ep:172, loss:0.00000, loss_test:0.07329, lr:3.15e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.859, tt:5857.602\n",
      "Ep:173, loss:0.00000, loss_test:0.07332, lr:3.12e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.850, tt:5889.853\n",
      "Ep:174, loss:0.00000, loss_test:0.07338, lr:3.09e-03, fs:0.82667 (r=0.713,p=0.984),  time:33.835, tt:5921.170\n",
      "Ep:175, loss:0.00000, loss_test:0.07342, lr:3.05e-03, fs:0.77778 (r=0.644,p=0.982),  time:33.814, tt:5951.327\n",
      "Ep:176, loss:0.00000, loss_test:0.07341, lr:3.02e-03, fs:0.80272 (r=0.678,p=0.983),  time:33.796, tt:5981.907\n",
      "Ep:177, loss:0.00000, loss_test:0.07345, lr:2.99e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.776, tt:6012.078\n",
      "Ep:178, loss:0.00000, loss_test:0.07339, lr:2.96e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.762, tt:6043.373\n",
      "Ep:179, loss:0.00000, loss_test:0.07316, lr:2.93e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.752, tt:6075.311\n",
      "Ep:180, loss:0.00000, loss_test:0.07331, lr:2.90e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.745, tt:6107.755\n",
      "Ep:181, loss:0.00000, loss_test:0.07340, lr:2.88e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.736, tt:6139.888\n",
      "Ep:182, loss:0.00000, loss_test:0.07327, lr:2.85e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.730, tt:6172.607\n",
      "Ep:183, loss:0.00000, loss_test:0.07320, lr:2.82e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.710, tt:6202.595\n",
      "Ep:184, loss:0.00000, loss_test:0.07332, lr:2.79e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.692, tt:6233.042\n",
      "Ep:185, loss:0.00000, loss_test:0.07323, lr:2.76e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.678, tt:6264.058\n",
      "Ep:186, loss:0.00000, loss_test:0.07326, lr:2.73e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.661, tt:6294.545\n",
      "Ep:187, loss:0.00000, loss_test:0.07321, lr:2.71e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.635, tt:6323.298\n",
      "Ep:188, loss:0.00000, loss_test:0.07308, lr:2.68e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.615, tt:6353.183\n",
      "Ep:189, loss:0.00000, loss_test:0.07313, lr:2.65e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.602, tt:6384.457\n",
      "Ep:190, loss:0.00000, loss_test:0.07329, lr:2.63e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.588, tt:6415.341\n",
      "Ep:191, loss:0.00000, loss_test:0.07321, lr:2.60e-03, fs:0.82667 (r=0.713,p=0.984),  time:33.570, tt:6445.452\n",
      "Ep:192, loss:0.00000, loss_test:0.07323, lr:2.57e-03, fs:0.82667 (r=0.713,p=0.984),  time:33.568, tt:6478.535\n",
      "Ep:193, loss:0.00000, loss_test:0.07322, lr:2.55e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.548, tt:6508.238\n",
      "Ep:194, loss:0.00000, loss_test:0.07303, lr:2.52e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.517, tt:6535.778\n",
      "Ep:195, loss:0.00000, loss_test:0.07304, lr:2.50e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.507, tt:6567.335\n",
      "Ep:196, loss:0.00000, loss_test:0.07303, lr:2.47e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.487, tt:6596.907\n",
      "Ep:197, loss:0.00000, loss_test:0.07307, lr:2.45e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.487, tt:6630.518\n",
      "Ep:198, loss:0.00000, loss_test:0.07290, lr:2.42e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.469, tt:6660.429\n",
      "Ep:199, loss:0.00000, loss_test:0.07293, lr:2.40e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.450, tt:6690.053\n",
      "Ep:200, loss:0.00000, loss_test:0.07317, lr:2.38e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.431, tt:6719.682\n",
      "Ep:201, loss:0.00000, loss_test:0.07313, lr:2.35e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.423, tt:6751.541\n",
      "Ep:202, loss:0.00000, loss_test:0.07294, lr:2.33e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.423, tt:6784.896\n",
      "Ep:203, loss:0.00000, loss_test:0.07292, lr:2.31e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.410, tt:6815.595\n",
      "Ep:204, loss:0.00000, loss_test:0.07300, lr:2.28e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.402, tt:6847.511\n",
      "Ep:205, loss:0.00000, loss_test:0.07293, lr:2.26e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.385, tt:6877.218\n",
      "Ep:206, loss:0.00000, loss_test:0.07286, lr:2.24e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.355, tt:6904.517\n",
      "Ep:207, loss:0.00000, loss_test:0.07295, lr:2.21e-03, fs:0.83444 (r=0.724,p=0.984),  time:33.317, tt:6929.887\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02056, lr:6.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:23.830, tt:23.830\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02387, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.050, tt:56.100\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02527, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.469, tt:91.406\n",
      "Ep:3, loss:0.00005, loss_test:0.02494, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.465, tt:125.860\n",
      "Ep:4, loss:0.00005, loss_test:0.02366, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:32.790, tt:163.951\n",
      "Ep:5, loss:0.00004, loss_test:0.02198, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:33.430, tt:200.579\n",
      "Ep:6, loss:0.00004, loss_test:0.02079, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:34.129, tt:238.901\n",
      "Ep:7, loss:0.00004, loss_test:0.02017, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:34.730, tt:277.840\n",
      "Ep:8, loss:0.00004, loss_test:0.01950, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:35.125, tt:316.121\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01866, lr:6.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.976, tt:349.759\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01808, lr:6.00e-02, fs:0.69853 (r=0.960,p=0.549),  time:34.920, tt:384.123\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01766, lr:6.00e-02, fs:0.70803 (r=0.980,p=0.554),  time:34.954, tt:419.449\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01722, lr:6.00e-02, fs:0.72593 (r=0.990,p=0.573),  time:35.131, tt:456.708\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01676, lr:6.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:34.998, tt:489.978\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:34.946, tt:524.196\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01616, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:34.784, tt:556.552\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.742, tt:590.622\n",
      "Ep:17, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:34.678, tt:624.205\n",
      "Ep:18, loss:0.00003, loss_test:0.01554, lr:6.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:34.546, tt:656.372\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:34.527, tt:690.531\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01501, lr:6.00e-02, fs:0.77869 (r=0.960,p=0.655),  time:34.375, tt:721.867\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01477, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:34.485, tt:758.662\n",
      "Ep:22, loss:0.00003, loss_test:0.01458, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:34.557, tt:794.802\n",
      "Ep:23, loss:0.00003, loss_test:0.01437, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:34.527, tt:828.638\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:34.538, tt:863.456\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:34.614, tt:899.975\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01385, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.606, tt:934.362\n",
      "Ep:27, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:34.586, tt:968.417\n",
      "Ep:28, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:34.581, tt:1002.835\n",
      "Ep:29, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:34.619, tt:1038.578\n",
      "Ep:30, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:34.653, tt:1074.241\n",
      "Ep:31, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:34.687, tt:1109.996\n",
      "Ep:32, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:34.704, tt:1145.242\n",
      "Ep:33, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.722, tt:1180.550\n",
      "Ep:34, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:34.722, tt:1215.287\n",
      "Ep:35, loss:0.00002, loss_test:0.01278, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:34.734, tt:1250.419\n",
      "Ep:36, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.696, tt:1283.735\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01256, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.726, tt:1319.600\n",
      "Ep:38, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.764, tt:1355.778\n",
      "Ep:39, loss:0.00002, loss_test:0.01244, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.702, tt:1388.068\n",
      "Ep:40, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:34.711, tt:1423.139\n",
      "Ep:41, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:34.725, tt:1458.469\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.673, tt:1490.923\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.677, tt:1525.770\n",
      "Ep:44, loss:0.00001, loss_test:0.01210, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.689, tt:1561.009\n",
      "Ep:45, loss:0.00001, loss_test:0.01203, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.666, tt:1594.650\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01198, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.673, tt:1629.623\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.612, tt:1661.373\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01192, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.619, tt:1696.351\n",
      "Ep:49, loss:0.00001, loss_test:0.01189, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.629, tt:1731.455\n",
      "Ep:50, loss:0.00001, loss_test:0.01183, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.614, tt:1765.329\n",
      "Ep:51, loss:0.00001, loss_test:0.01180, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:34.600, tt:1799.197\n",
      "Ep:52, loss:0.00001, loss_test:0.01179, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.621, tt:1834.933\n",
      "Ep:53, loss:0.00001, loss_test:0.01176, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.616, tt:1869.280\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.659, tt:1906.251\n",
      "Ep:55, loss:0.00001, loss_test:0.01176, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.653, tt:1940.551\n",
      "Ep:56, loss:0.00001, loss_test:0.01175, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.671, tt:1976.249\n",
      "Ep:57, loss:0.00001, loss_test:0.01175, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.692, tt:2012.164\n",
      "Ep:58, loss:0.00001, loss_test:0.01174, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.703, tt:2047.504\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01174, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.686, tt:2081.185\n",
      "Ep:60, loss:0.00001, loss_test:0.01175, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.693, tt:2116.253\n",
      "Ep:61, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.674, tt:2149.785\n",
      "Ep:62, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.647, tt:2182.732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01171, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.614, tt:2215.288\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01175, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:34.629, tt:2250.907\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01178, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:34.595, tt:2283.269\n",
      "Ep:66, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:34.621, tt:2319.579\n",
      "Ep:67, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.651, tt:2356.274\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.726, tt:2396.112\n",
      "Ep:69, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.716, tt:2430.140\n",
      "Ep:70, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.734, tt:2466.088\n",
      "Ep:71, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.685, tt:2497.315\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01189, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.675, tt:2531.256\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01191, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.678, tt:2566.209\n",
      "Ep:74, loss:0.00001, loss_test:0.01203, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.692, tt:2601.916\n",
      "Ep:75, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.687, tt:2636.248\n",
      "Ep:76, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.691, tt:2671.208\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01211, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.654, tt:2703.034\n",
      "Ep:78, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.640, tt:2736.528\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01221, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.625, tt:2769.972\n",
      "Ep:80, loss:0.00001, loss_test:0.01226, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.629, tt:2804.966\n",
      "Ep:81, loss:0.00001, loss_test:0.01227, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.625, tt:2839.273\n",
      "Ep:82, loss:0.00001, loss_test:0.01236, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.632, tt:2874.460\n",
      "Ep:83, loss:0.00001, loss_test:0.01238, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.615, tt:2907.656\n",
      "Ep:84, loss:0.00001, loss_test:0.01239, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.626, tt:2943.198\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01250, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.662, tt:2980.901\n",
      "Ep:86, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.660, tt:3015.387\n",
      "Ep:87, loss:0.00001, loss_test:0.01257, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.692, tt:3052.908\n",
      "Ep:88, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.688, tt:3087.266\n",
      "Ep:89, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.690, tt:3122.105\n",
      "Ep:90, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.667, tt:3154.655\n",
      "Ep:91, loss:0.00001, loss_test:0.01281, lr:6.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.668, tt:3189.434\n",
      "Ep:92, loss:0.00001, loss_test:0.01284, lr:6.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.655, tt:3222.910\n",
      "Ep:93, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.663, tt:3258.369\n",
      "Ep:94, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.643, tt:3291.120\n",
      "Ep:95, loss:0.00001, loss_test:0.01304, lr:6.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.623, tt:3323.838\n",
      "Ep:96, loss:0.00000, loss_test:0.01309, lr:5.94e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.598, tt:3356.009\n",
      "Ep:97, loss:0.00000, loss_test:0.01313, lr:5.88e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.584, tt:3389.225\n",
      "Ep:98, loss:0.00000, loss_test:0.01324, lr:5.82e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.579, tt:3423.303\n",
      "Ep:99, loss:0.00000, loss_test:0.01324, lr:5.76e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.545, tt:3454.475\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00000, loss_test:0.01333, lr:5.76e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.533, tt:3487.787\n",
      "Ep:101, loss:0.00000, loss_test:0.01331, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.536, tt:3522.690\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00000, loss_test:0.01342, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.549, tt:3558.499\n",
      "Ep:103, loss:0.00000, loss_test:0.01348, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.568, tt:3595.080\n",
      "Ep:104, loss:0.00000, loss_test:0.01347, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.571, tt:3629.955\n",
      "Ep:105, loss:0.00000, loss_test:0.01355, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.569, tt:3664.282\n",
      "Ep:106, loss:0.00000, loss_test:0.01361, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.576, tt:3699.614\n",
      "Ep:107, loss:0.00000, loss_test:0.01363, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.585, tt:3735.229\n",
      "Ep:108, loss:0.00000, loss_test:0.01373, lr:5.76e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.591, tt:3770.411\n",
      "Ep:109, loss:0.00000, loss_test:0.01381, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.587, tt:3804.515\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.01387, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.604, tt:3841.058\n",
      "Ep:111, loss:0.00000, loss_test:0.01392, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.611, tt:3876.460\n",
      "Ep:112, loss:0.00000, loss_test:0.01399, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.614, tt:3911.428\n",
      "Ep:113, loss:0.00000, loss_test:0.01399, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.595, tt:3943.872\n",
      "Ep:114, loss:0.00000, loss_test:0.01399, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.592, tt:3978.134\n",
      "Ep:115, loss:0.00000, loss_test:0.01412, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.558, tt:4008.713\n",
      "Ep:116, loss:0.00000, loss_test:0.01420, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.532, tt:4040.224\n",
      "Ep:117, loss:0.00000, loss_test:0.01421, lr:5.76e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.523, tt:4073.730\n",
      "Ep:118, loss:0.00000, loss_test:0.01434, lr:5.76e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.512, tt:4106.870\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00000, loss_test:0.01433, lr:5.76e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.511, tt:4141.361\n",
      "Ep:120, loss:0.00000, loss_test:0.01437, lr:5.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.508, tt:4175.465\n",
      "Ep:121, loss:0.00000, loss_test:0.01450, lr:5.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.518, tt:4211.232\n",
      "Ep:122, loss:0.00000, loss_test:0.01449, lr:5.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.513, tt:4245.074\n",
      "Ep:123, loss:0.00000, loss_test:0.01461, lr:5.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.508, tt:4279.027\n",
      "Ep:124, loss:0.00000, loss_test:0.01461, lr:5.76e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.505, tt:4313.110\n",
      "Ep:125, loss:0.00000, loss_test:0.01467, lr:5.76e-02, fs:0.88298 (r=0.838,p=0.933),  time:34.496, tt:4346.476\n",
      "Ep:126, loss:0.00000, loss_test:0.01474, lr:5.76e-02, fs:0.87701 (r=0.828,p=0.932),  time:34.500, tt:4381.512\n",
      "Ep:127, loss:0.00000, loss_test:0.01478, lr:5.76e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.480, tt:4413.498\n",
      "Ep:128, loss:0.00000, loss_test:0.01490, lr:5.76e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.476, tt:4447.388\n",
      "Ep:129, loss:0.00000, loss_test:0.01489, lr:5.76e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.455, tt:4479.091\n",
      "Ep:130, loss:0.00000, loss_test:0.01501, lr:5.71e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.453, tt:4513.329\n",
      "Ep:131, loss:0.00000, loss_test:0.01500, lr:5.65e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.436, tt:4545.617\n",
      "Ep:132, loss:0.00000, loss_test:0.01505, lr:5.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.437, tt:4580.181\n",
      "Ep:133, loss:0.00000, loss_test:0.01512, lr:5.54e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.440, tt:4614.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01515, lr:5.48e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.434, tt:4648.653\n",
      "Ep:135, loss:0.00000, loss_test:0.01536, lr:5.43e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.429, tt:4682.282\n",
      "Ep:136, loss:0.00000, loss_test:0.01531, lr:5.37e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.435, tt:4717.528\n",
      "Ep:137, loss:0.00000, loss_test:0.01537, lr:5.32e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.425, tt:4750.676\n",
      "Ep:138, loss:0.00000, loss_test:0.01541, lr:5.27e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.428, tt:4785.444\n",
      "Ep:139, loss:0.00000, loss_test:0.01542, lr:5.21e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.434, tt:4820.807\n",
      "Ep:140, loss:0.00000, loss_test:0.01555, lr:5.16e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.426, tt:4853.999\n",
      "Ep:141, loss:0.00000, loss_test:0.01554, lr:5.11e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.427, tt:4888.589\n",
      "Ep:142, loss:0.00000, loss_test:0.01569, lr:5.06e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.414, tt:4921.138\n",
      "Ep:143, loss:0.00000, loss_test:0.01572, lr:5.01e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.414, tt:4955.558\n",
      "Ep:144, loss:0.00000, loss_test:0.01575, lr:4.96e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.420, tt:4990.920\n",
      "Ep:145, loss:0.00000, loss_test:0.01576, lr:4.91e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.408, tt:5023.608\n",
      "Ep:146, loss:0.00000, loss_test:0.01580, lr:4.86e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.421, tt:5059.911\n",
      "Ep:147, loss:0.00000, loss_test:0.01586, lr:4.81e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.416, tt:5093.621\n",
      "Ep:148, loss:0.00000, loss_test:0.01592, lr:4.76e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.408, tt:5126.720\n",
      "Ep:149, loss:0.00000, loss_test:0.01593, lr:4.71e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.415, tt:5162.300\n",
      "Ep:150, loss:0.00000, loss_test:0.01600, lr:4.67e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.416, tt:5196.809\n",
      "Ep:151, loss:0.00000, loss_test:0.01606, lr:4.62e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.420, tt:5231.853\n",
      "Ep:152, loss:0.00000, loss_test:0.01607, lr:4.57e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.424, tt:5266.923\n",
      "Ep:153, loss:0.00000, loss_test:0.01616, lr:4.53e-02, fs:0.85083 (r=0.778,p=0.939),  time:34.420, tt:5300.674\n",
      "Ep:154, loss:0.00000, loss_test:0.01617, lr:4.48e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.422, tt:5335.333\n",
      "Ep:155, loss:0.00000, loss_test:0.01627, lr:4.44e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.415, tt:5368.793\n",
      "Ep:156, loss:0.00000, loss_test:0.01625, lr:4.39e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.420, tt:5404.012\n",
      "Ep:157, loss:0.00000, loss_test:0.01628, lr:4.35e-02, fs:0.83616 (r=0.747,p=0.949),  time:34.425, tt:5439.071\n",
      "Ep:158, loss:0.00000, loss_test:0.01639, lr:4.31e-02, fs:0.80925 (r=0.707,p=0.946),  time:34.420, tt:5472.802\n",
      "Ep:159, loss:0.00000, loss_test:0.01635, lr:4.26e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.420, tt:5507.261\n",
      "Ep:160, loss:0.00000, loss_test:0.01642, lr:4.22e-02, fs:0.80925 (r=0.707,p=0.946),  time:34.402, tt:5538.714\n",
      "Ep:161, loss:0.00000, loss_test:0.01644, lr:4.18e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.404, tt:5573.421\n",
      "Ep:162, loss:0.00000, loss_test:0.01645, lr:4.14e-02, fs:0.80925 (r=0.707,p=0.946),  time:34.386, tt:5604.973\n",
      "Ep:163, loss:0.00000, loss_test:0.01656, lr:4.10e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.390, tt:5639.926\n",
      "Ep:164, loss:0.00000, loss_test:0.01654, lr:4.05e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.400, tt:5675.949\n",
      "Ep:165, loss:0.00000, loss_test:0.01657, lr:4.01e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.439, tt:5716.841\n",
      "Ep:166, loss:0.00000, loss_test:0.01661, lr:3.97e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.435, tt:5750.718\n",
      "Ep:167, loss:0.00000, loss_test:0.01662, lr:3.93e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.438, tt:5785.520\n",
      "Ep:168, loss:0.00000, loss_test:0.01670, lr:3.89e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.438, tt:5820.051\n",
      "Ep:169, loss:0.00000, loss_test:0.01672, lr:3.86e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.436, tt:5854.061\n",
      "Ep:170, loss:0.00000, loss_test:0.01673, lr:3.82e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.431, tt:5887.737\n",
      "Ep:171, loss:0.00000, loss_test:0.01678, lr:3.78e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.432, tt:5922.228\n",
      "Ep:172, loss:0.00000, loss_test:0.01680, lr:3.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:34.428, tt:5955.958\n",
      "Ep:173, loss:0.00000, loss_test:0.01684, lr:3.70e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.426, tt:5990.065\n",
      "Ep:174, loss:0.00000, loss_test:0.01690, lr:3.67e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.428, tt:6024.923\n",
      "Ep:175, loss:0.00000, loss_test:0.01686, lr:3.63e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.429, tt:6059.553\n",
      "Ep:176, loss:0.00000, loss_test:0.01694, lr:3.59e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.427, tt:6093.639\n",
      "Ep:177, loss:0.00000, loss_test:0.01696, lr:3.56e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.427, tt:6128.051\n",
      "Ep:178, loss:0.00000, loss_test:0.01696, lr:3.52e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.424, tt:6161.965\n",
      "Ep:179, loss:0.00000, loss_test:0.01703, lr:3.49e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.416, tt:6194.897\n",
      "Ep:180, loss:0.00000, loss_test:0.01706, lr:3.45e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.417, tt:6229.394\n",
      "Ep:181, loss:0.00000, loss_test:0.01708, lr:3.42e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.413, tt:6263.114\n",
      "Ep:182, loss:0.00000, loss_test:0.01708, lr:3.38e-02, fs:0.78107 (r=0.667,p=0.943),  time:34.404, tt:6295.945\n",
      "Ep:183, loss:0.00000, loss_test:0.01714, lr:3.35e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.402, tt:6330.025\n",
      "Ep:184, loss:0.00000, loss_test:0.01714, lr:3.32e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.407, tt:6365.335\n",
      "Ep:185, loss:0.00000, loss_test:0.01719, lr:3.28e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.406, tt:6399.437\n",
      "Ep:186, loss:0.00000, loss_test:0.01719, lr:3.25e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.405, tt:6433.820\n",
      "Ep:187, loss:0.00000, loss_test:0.01723, lr:3.22e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.414, tt:6469.803\n",
      "Ep:188, loss:0.00000, loss_test:0.01723, lr:3.19e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.423, tt:6505.994\n",
      "Ep:189, loss:0.00000, loss_test:0.01730, lr:3.15e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.451, tt:6545.628\n",
      "Ep:190, loss:0.00000, loss_test:0.01731, lr:3.12e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.451, tt:6580.125\n",
      "Ep:191, loss:0.00000, loss_test:0.01731, lr:3.09e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.450, tt:6614.447\n",
      "Ep:192, loss:0.00000, loss_test:0.01734, lr:3.06e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.451, tt:6649.030\n",
      "Ep:193, loss:0.00000, loss_test:0.01739, lr:3.03e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.436, tt:6680.517\n",
      "Ep:194, loss:0.00000, loss_test:0.01738, lr:3.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.439, tt:6715.524\n",
      "Ep:195, loss:0.00000, loss_test:0.01743, lr:2.97e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.435, tt:6749.359\n",
      "Ep:196, loss:0.00000, loss_test:0.01746, lr:2.94e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.443, tt:6785.301\n",
      "Ep:197, loss:0.00000, loss_test:0.01745, lr:2.91e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.446, tt:6820.317\n",
      "Ep:198, loss:0.00000, loss_test:0.01749, lr:2.88e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.451, tt:6855.732\n",
      "Ep:199, loss:0.00000, loss_test:0.01752, lr:2.85e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.450, tt:6890.047\n",
      "Ep:200, loss:0.00000, loss_test:0.01752, lr:2.82e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.455, tt:6925.366\n",
      "Ep:201, loss:0.00000, loss_test:0.01755, lr:2.80e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.461, tt:6961.140\n",
      "Ep:202, loss:0.00000, loss_test:0.01760, lr:2.77e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.464, tt:6996.260\n",
      "Ep:203, loss:0.00000, loss_test:0.01760, lr:2.74e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.471, tt:7032.011\n",
      "Ep:204, loss:0.00000, loss_test:0.01759, lr:2.71e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.473, tt:7066.942\n",
      "Ep:205, loss:0.00000, loss_test:0.01766, lr:2.69e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.447, tt:7096.089\n",
      "Ep:206, loss:0.00000, loss_test:0.01768, lr:2.66e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.381, tt:7116.804\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14158, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:11.065, tt:11.065\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13961, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:10.939, tt:21.878\n",
      "Ep:2, loss:0.00027, loss_test:0.13570, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:10.910, tt:32.730\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12892, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:10.888, tt:43.551\n",
      "Ep:4, loss:0.00025, loss_test:0.12068, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:10.855, tt:54.274\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11493, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:10.860, tt:65.158\n",
      "Ep:6, loss:0.00023, loss_test:0.11342, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:10.843, tt:75.902\n",
      "Ep:7, loss:0.00022, loss_test:0.11437, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:10.834, tt:86.670\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10836, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:10.831, tt:97.481\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10484, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:10.841, tt:108.408\n",
      "Ep:10, loss:0.00020, loss_test:0.10219, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:10.841, tt:119.250\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09934, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:10.838, tt:130.058\n",
      "Ep:12, loss:0.00018, loss_test:0.09763, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:10.835, tt:140.849\n",
      "Ep:13, loss:0.00017, loss_test:0.09378, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:10.838, tt:151.727\n",
      "Ep:14, loss:0.00017, loss_test:0.09128, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:10.838, tt:162.570\n",
      "Ep:15, loss:0.00016, loss_test:0.09162, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:10.838, tt:173.409\n",
      "Ep:16, loss:0.00015, loss_test:0.09051, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:10.840, tt:184.280\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08775, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:10.883, tt:195.886\n",
      "Ep:18, loss:0.00014, loss_test:0.08742, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:10.940, tt:207.851\n",
      "Ep:19, loss:0.00014, loss_test:0.08689, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:11.007, tt:220.132\n",
      "Ep:20, loss:0.00013, loss_test:0.08411, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:11.060, tt:232.267\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08418, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:11.115, tt:244.519\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08364, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:11.166, tt:256.824\n",
      "Ep:23, loss:0.00012, loss_test:0.08147, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:11.230, tt:269.516\n",
      "Ep:24, loss:0.00011, loss_test:0.08199, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:11.270, tt:281.748\n",
      "Ep:25, loss:0.00011, loss_test:0.08093, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:11.306, tt:293.957\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.08147, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:11.344, tt:306.283\n",
      "Ep:27, loss:0.00010, loss_test:0.07884, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:11.392, tt:318.969\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07906, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:11.424, tt:331.299\n",
      "Ep:29, loss:0.00009, loss_test:0.07610, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:11.460, tt:343.788\n",
      "Ep:30, loss:0.00009, loss_test:0.07686, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:11.500, tt:356.495\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07720, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:11.529, tt:368.944\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07299, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:11.560, tt:381.488\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.07607, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:11.581, tt:393.768\n",
      "Ep:34, loss:0.00008, loss_test:0.07298, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:11.607, tt:406.249\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.07298, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:11.630, tt:418.690\n",
      "Ep:36, loss:0.00007, loss_test:0.07585, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:11.651, tt:431.092\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.07195, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:11.670, tt:443.461\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.07346, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:11.687, tt:455.796\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.07361, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:11.709, tt:468.350\n",
      "Ep:40, loss:0.00006, loss_test:0.07074, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:11.800, tt:483.802\n",
      "Ep:41, loss:0.00006, loss_test:0.07896, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:11.819, tt:496.387\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.07102, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:11.834, tt:508.854\n",
      "Ep:43, loss:0.00006, loss_test:0.07872, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:11.842, tt:521.055\n",
      "Ep:44, loss:0.00005, loss_test:0.07316, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:11.853, tt:533.394\n",
      "Ep:45, loss:0.00005, loss_test:0.07458, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:11.867, tt:545.860\n",
      "Ep:46, loss:0.00005, loss_test:0.07128, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:11.887, tt:558.679\n",
      "Ep:47, loss:0.00005, loss_test:0.07377, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:11.901, tt:571.269\n",
      "Ep:48, loss:0.00005, loss_test:0.06786, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:11.921, tt:584.111\n",
      "Ep:49, loss:0.00005, loss_test:0.07648, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:11.930, tt:596.498\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.07254, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:11.939, tt:608.904\n",
      "Ep:51, loss:0.00004, loss_test:0.07154, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:11.949, tt:621.330\n",
      "Ep:52, loss:0.00004, loss_test:0.07446, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:11.956, tt:633.646\n",
      "Ep:53, loss:0.00004, loss_test:0.06791, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:11.966, tt:646.142\n",
      "Ep:54, loss:0.00003, loss_test:0.07465, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:11.973, tt:658.500\n",
      "Ep:55, loss:0.00003, loss_test:0.06811, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:11.992, tt:671.530\n",
      "Ep:56, loss:0.00003, loss_test:0.06946, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:11.997, tt:683.819\n",
      "Ep:57, loss:0.00003, loss_test:0.06895, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:12.002, tt:696.096\n",
      "Ep:58, loss:0.00003, loss_test:0.06886, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:12.014, tt:708.851\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.06687, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:12.023, tt:721.372\n",
      "Ep:60, loss:0.00002, loss_test:0.06956, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:12.026, tt:733.595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00002, loss_test:0.06779, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:12.034, tt:746.135\n",
      "Ep:62, loss:0.00002, loss_test:0.06762, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:12.039, tt:758.455\n",
      "Ep:63, loss:0.00002, loss_test:0.06818, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.046, tt:770.927\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.06538, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:12.051, tt:783.288\n",
      "Ep:65, loss:0.00002, loss_test:0.06886, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:12.061, tt:796.010\n",
      "Ep:66, loss:0.00002, loss_test:0.06404, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.066, tt:808.394\n",
      "Ep:67, loss:0.00002, loss_test:0.06655, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.068, tt:820.633\n",
      "Ep:68, loss:0.00002, loss_test:0.06535, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:12.070, tt:832.810\n",
      "Ep:69, loss:0.00002, loss_test:0.06727, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.074, tt:845.147\n",
      "Ep:70, loss:0.00002, loss_test:0.06980, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.078, tt:857.544\n",
      "Ep:71, loss:0.00002, loss_test:0.06382, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:12.079, tt:869.715\n",
      "Ep:72, loss:0.00002, loss_test:0.07099, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.081, tt:881.941\n",
      "Ep:73, loss:0.00002, loss_test:0.06455, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.083, tt:894.123\n",
      "Ep:74, loss:0.00001, loss_test:0.07110, lr:1.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:12.086, tt:906.430\n",
      "Ep:75, loss:0.00001, loss_test:0.06697, lr:9.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.086, tt:918.559\n",
      "Ep:76, loss:0.00001, loss_test:0.06672, lr:9.80e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.090, tt:930.919\n",
      "Ep:77, loss:0.00001, loss_test:0.06878, lr:9.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.091, tt:943.073\n",
      "Ep:78, loss:0.00001, loss_test:0.06670, lr:9.61e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.098, tt:955.711\n",
      "Ep:79, loss:0.00001, loss_test:0.06740, lr:9.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.104, tt:968.346\n",
      "Ep:80, loss:0.00001, loss_test:0.06566, lr:9.41e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.110, tt:980.943\n",
      "Ep:81, loss:0.00001, loss_test:0.06759, lr:9.32e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.113, tt:993.283\n",
      "Ep:82, loss:0.00001, loss_test:0.06707, lr:9.23e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.115, tt:1005.538\n",
      "Ep:83, loss:0.00001, loss_test:0.06920, lr:9.14e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.119, tt:1018.000\n",
      "Ep:84, loss:0.00001, loss_test:0.06773, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.125, tt:1030.602\n",
      "Ep:85, loss:0.00001, loss_test:0.06729, lr:8.95e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.130, tt:1043.213\n",
      "Ep:86, loss:0.00001, loss_test:0.06784, lr:8.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.136, tt:1055.816\n",
      "Ep:87, loss:0.00001, loss_test:0.06602, lr:8.78e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.139, tt:1068.196\n",
      "Ep:88, loss:0.00001, loss_test:0.06931, lr:8.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.143, tt:1080.724\n",
      "Ep:89, loss:0.00001, loss_test:0.06570, lr:8.60e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.146, tt:1093.113\n",
      "Ep:90, loss:0.00001, loss_test:0.06938, lr:8.51e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.147, tt:1105.410\n",
      "Ep:91, loss:0.00001, loss_test:0.06887, lr:8.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.151, tt:1117.921\n",
      "Ep:92, loss:0.00001, loss_test:0.06844, lr:8.35e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.172, tt:1131.980\n",
      "Ep:93, loss:0.00001, loss_test:0.06833, lr:8.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.175, tt:1144.429\n",
      "Ep:94, loss:0.00001, loss_test:0.06850, lr:8.18e-03, fs:0.83721 (r=0.727,p=0.986),  time:12.178, tt:1156.875\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.06723, lr:8.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.181, tt:1169.361\n",
      "Ep:96, loss:0.00001, loss_test:0.06847, lr:8.18e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.185, tt:1181.948\n",
      "Ep:97, loss:0.00001, loss_test:0.06867, lr:8.18e-03, fs:0.83721 (r=0.727,p=0.986),  time:12.190, tt:1194.574\n",
      "Ep:98, loss:0.00001, loss_test:0.06893, lr:8.18e-03, fs:0.83237 (r=0.727,p=0.973),  time:12.193, tt:1207.090\n",
      "Ep:99, loss:0.00001, loss_test:0.06725, lr:8.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:12.196, tt:1219.618\n",
      "Ep:100, loss:0.00001, loss_test:0.07007, lr:8.18e-03, fs:0.81176 (r=0.697,p=0.972),  time:12.200, tt:1232.190\n",
      "Ep:101, loss:0.00001, loss_test:0.06809, lr:8.18e-03, fs:0.82558 (r=0.717,p=0.973),  time:12.202, tt:1244.571\n",
      "Ep:102, loss:0.00001, loss_test:0.06927, lr:8.18e-03, fs:0.80473 (r=0.687,p=0.971),  time:12.204, tt:1257.007\n",
      "Ep:103, loss:0.00001, loss_test:0.07022, lr:8.18e-03, fs:0.80240 (r=0.677,p=0.985),  time:12.208, tt:1269.594\n",
      "Ep:104, loss:0.00001, loss_test:0.06890, lr:8.18e-03, fs:0.81657 (r=0.697,p=0.986),  time:12.211, tt:1282.108\n",
      "Ep:105, loss:0.00001, loss_test:0.07185, lr:8.18e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.212, tt:1294.462\n",
      "Ep:106, loss:0.00001, loss_test:0.06930, lr:8.10e-03, fs:0.78049 (r=0.646,p=0.985),  time:12.212, tt:1306.639\n",
      "Ep:107, loss:0.00001, loss_test:0.07003, lr:8.02e-03, fs:0.80240 (r=0.677,p=0.985),  time:12.213, tt:1319.039\n",
      "Ep:108, loss:0.00001, loss_test:0.06934, lr:7.94e-03, fs:0.76074 (r=0.626,p=0.969),  time:12.216, tt:1331.498\n",
      "Ep:109, loss:0.00001, loss_test:0.07034, lr:7.86e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.218, tt:1343.964\n",
      "Ep:110, loss:0.00001, loss_test:0.07046, lr:7.78e-03, fs:0.75610 (r=0.626,p=0.954),  time:12.221, tt:1356.535\n",
      "Ep:111, loss:0.00000, loss_test:0.07215, lr:7.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.224, tt:1369.135\n",
      "Ep:112, loss:0.00000, loss_test:0.07080, lr:7.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.226, tt:1381.593\n",
      "Ep:113, loss:0.00000, loss_test:0.07085, lr:7.55e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.227, tt:1393.884\n",
      "Ep:114, loss:0.00000, loss_test:0.07253, lr:7.47e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.228, tt:1406.269\n",
      "Ep:115, loss:0.00000, loss_test:0.07054, lr:7.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:12.228, tt:1418.480\n",
      "Ep:116, loss:0.00000, loss_test:0.07128, lr:7.32e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.230, tt:1430.911\n",
      "Ep:117, loss:0.00000, loss_test:0.07187, lr:7.25e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.232, tt:1443.360\n",
      "Ep:118, loss:0.00000, loss_test:0.07137, lr:7.18e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.233, tt:1455.781\n",
      "Ep:119, loss:0.00000, loss_test:0.07326, lr:7.11e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.235, tt:1468.178\n",
      "Ep:120, loss:0.00000, loss_test:0.07318, lr:7.03e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.237, tt:1480.700\n",
      "Ep:121, loss:0.00000, loss_test:0.07182, lr:6.96e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.239, tt:1493.122\n",
      "Ep:122, loss:0.00000, loss_test:0.07250, lr:6.89e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.239, tt:1505.407\n",
      "Ep:123, loss:0.00000, loss_test:0.07374, lr:6.83e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.241, tt:1517.896\n",
      "Ep:124, loss:0.00000, loss_test:0.07295, lr:6.76e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.241, tt:1530.084\n",
      "Ep:125, loss:0.00000, loss_test:0.07348, lr:6.69e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.241, tt:1542.348\n",
      "Ep:126, loss:0.00000, loss_test:0.07446, lr:6.62e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.241, tt:1554.572\n",
      "Ep:127, loss:0.00000, loss_test:0.07340, lr:6.56e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.242, tt:1566.999\n",
      "Ep:128, loss:0.00000, loss_test:0.07379, lr:6.49e-03, fs:0.76074 (r=0.626,p=0.969),  time:12.244, tt:1579.416\n",
      "Ep:129, loss:0.00000, loss_test:0.07563, lr:6.43e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.246, tt:1592.005\n",
      "Ep:130, loss:0.00000, loss_test:0.07534, lr:6.36e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.245, tt:1604.130\n",
      "Ep:131, loss:0.00000, loss_test:0.07496, lr:6.30e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.246, tt:1616.528\n",
      "Ep:132, loss:0.00000, loss_test:0.07659, lr:6.24e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.250, tt:1629.304\n",
      "Ep:133, loss:0.00000, loss_test:0.07628, lr:6.17e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.250, tt:1641.564\n",
      "Ep:134, loss:0.00000, loss_test:0.07656, lr:6.11e-03, fs:0.76543 (r=0.626,p=0.984),  time:12.253, tt:1654.185\n",
      "Ep:135, loss:0.00000, loss_test:0.07746, lr:6.05e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.257, tt:1666.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.07705, lr:5.99e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.259, tt:1679.433\n",
      "Ep:137, loss:0.00000, loss_test:0.07775, lr:5.93e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.259, tt:1691.775\n",
      "Ep:138, loss:0.00000, loss_test:0.07861, lr:5.87e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.259, tt:1704.064\n",
      "Ep:139, loss:0.00000, loss_test:0.07782, lr:5.81e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.260, tt:1716.406\n",
      "Ep:140, loss:0.00000, loss_test:0.07902, lr:5.75e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.260, tt:1728.719\n",
      "Ep:141, loss:0.00000, loss_test:0.07885, lr:5.70e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.262, tt:1741.200\n",
      "Ep:142, loss:0.00000, loss_test:0.07903, lr:5.64e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.262, tt:1753.533\n",
      "Ep:143, loss:0.00000, loss_test:0.07944, lr:5.58e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.282, tt:1768.602\n",
      "Ep:144, loss:0.00000, loss_test:0.08013, lr:5.53e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.283, tt:1780.985\n",
      "Ep:145, loss:0.00000, loss_test:0.07980, lr:5.47e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1793.080\n",
      "Ep:146, loss:0.00000, loss_test:0.08061, lr:5.42e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1805.356\n",
      "Ep:147, loss:0.00000, loss_test:0.08106, lr:5.36e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1817.544\n",
      "Ep:148, loss:0.00000, loss_test:0.08057, lr:5.31e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1829.799\n",
      "Ep:149, loss:0.00000, loss_test:0.08236, lr:5.26e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1842.179\n",
      "Ep:150, loss:0.00000, loss_test:0.08200, lr:5.20e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1854.494\n",
      "Ep:151, loss:0.00000, loss_test:0.08175, lr:5.15e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.281, tt:1866.661\n",
      "Ep:152, loss:0.00000, loss_test:0.08269, lr:5.10e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.282, tt:1879.104\n",
      "Ep:153, loss:0.00000, loss_test:0.08297, lr:5.05e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.283, tt:1891.546\n",
      "Ep:154, loss:0.00000, loss_test:0.08192, lr:5.00e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.284, tt:1903.997\n",
      "Ep:155, loss:0.00000, loss_test:0.08352, lr:4.95e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.282, tt:1916.007\n",
      "Ep:156, loss:0.00000, loss_test:0.08342, lr:4.90e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.282, tt:1928.280\n",
      "Ep:157, loss:0.00000, loss_test:0.08378, lr:4.85e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.282, tt:1940.623\n",
      "Ep:158, loss:0.00000, loss_test:0.08346, lr:4.80e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.285, tt:1953.276\n",
      "Ep:159, loss:0.00000, loss_test:0.08380, lr:4.75e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.284, tt:1965.475\n",
      "Ep:160, loss:0.00000, loss_test:0.08305, lr:4.71e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.285, tt:1977.817\n",
      "Ep:161, loss:0.00000, loss_test:0.08422, lr:4.66e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.286, tt:1990.305\n",
      "Ep:162, loss:0.00000, loss_test:0.08403, lr:4.61e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.286, tt:2002.548\n",
      "Ep:163, loss:0.00000, loss_test:0.08349, lr:4.57e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.285, tt:2014.801\n",
      "Ep:164, loss:0.00000, loss_test:0.08306, lr:4.52e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.285, tt:2026.987\n",
      "Ep:165, loss:0.00000, loss_test:0.08316, lr:4.48e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.285, tt:2039.372\n",
      "Ep:166, loss:0.00000, loss_test:0.08408, lr:4.43e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.286, tt:2051.822\n",
      "Ep:167, loss:0.00000, loss_test:0.08339, lr:4.39e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.288, tt:2064.351\n",
      "Ep:168, loss:0.00000, loss_test:0.08392, lr:4.34e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.290, tt:2076.936\n",
      "Ep:169, loss:0.00000, loss_test:0.08332, lr:4.30e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.289, tt:2089.200\n",
      "Ep:170, loss:0.00000, loss_test:0.08321, lr:4.26e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.289, tt:2101.491\n",
      "Ep:171, loss:0.00000, loss_test:0.08407, lr:4.21e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.289, tt:2113.791\n",
      "Ep:172, loss:0.00000, loss_test:0.08405, lr:4.17e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.289, tt:2126.064\n",
      "Ep:173, loss:0.00000, loss_test:0.08326, lr:4.13e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.290, tt:2138.541\n",
      "Ep:174, loss:0.00000, loss_test:0.08391, lr:4.09e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.291, tt:2150.953\n",
      "Ep:175, loss:0.00000, loss_test:0.08404, lr:4.05e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.291, tt:2163.146\n",
      "Ep:176, loss:0.00000, loss_test:0.08326, lr:4.01e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.290, tt:2175.390\n",
      "Ep:177, loss:0.00000, loss_test:0.08427, lr:3.97e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.290, tt:2187.669\n",
      "Ep:178, loss:0.00000, loss_test:0.08546, lr:3.93e-03, fs:0.74684 (r=0.596,p=1.000),  time:12.292, tt:2200.220\n",
      "Ep:179, loss:0.00000, loss_test:0.08366, lr:3.89e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.292, tt:2212.481\n",
      "Ep:180, loss:0.00000, loss_test:0.08354, lr:3.85e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.292, tt:2224.878\n",
      "Ep:181, loss:0.00000, loss_test:0.08416, lr:3.81e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.291, tt:2237.048\n",
      "Ep:182, loss:0.00000, loss_test:0.08378, lr:3.77e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.296, tt:2250.210\n",
      "Ep:183, loss:0.00000, loss_test:0.08364, lr:3.73e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.297, tt:2262.639\n",
      "Ep:184, loss:0.00000, loss_test:0.08350, lr:3.70e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.297, tt:2274.986\n",
      "Ep:185, loss:0.00000, loss_test:0.08445, lr:3.66e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.299, tt:2287.704\n",
      "Ep:186, loss:0.00000, loss_test:0.08401, lr:3.62e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.300, tt:2300.072\n",
      "Ep:187, loss:0.00000, loss_test:0.08345, lr:3.59e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.300, tt:2312.405\n",
      "Ep:188, loss:0.00000, loss_test:0.08451, lr:3.55e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.301, tt:2324.908\n",
      "Ep:189, loss:0.00000, loss_test:0.08402, lr:3.52e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.303, tt:2337.482\n",
      "Ep:190, loss:0.00000, loss_test:0.08347, lr:3.48e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.302, tt:2349.766\n",
      "Ep:191, loss:0.00000, loss_test:0.08380, lr:3.45e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.303, tt:2362.224\n",
      "Ep:192, loss:0.00000, loss_test:0.08428, lr:3.41e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.304, tt:2374.602\n",
      "Ep:193, loss:0.00000, loss_test:0.08386, lr:3.38e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.306, tt:2387.356\n",
      "Ep:194, loss:0.00000, loss_test:0.08359, lr:3.34e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.308, tt:2400.007\n",
      "Ep:195, loss:0.00000, loss_test:0.08393, lr:3.31e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.308, tt:2412.428\n",
      "Ep:196, loss:0.00000, loss_test:0.08384, lr:3.28e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.310, tt:2424.989\n",
      "Ep:197, loss:0.00000, loss_test:0.08422, lr:3.24e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.311, tt:2437.627\n",
      "Ep:198, loss:0.00000, loss_test:0.08353, lr:3.21e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.313, tt:2450.245\n",
      "Ep:199, loss:0.00000, loss_test:0.08312, lr:3.18e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.314, tt:2462.763\n",
      "Ep:200, loss:0.00000, loss_test:0.08426, lr:3.15e-03, fs:0.75472 (r=0.606,p=1.000),  time:12.314, tt:2475.203\n",
      "Ep:201, loss:0.00000, loss_test:0.08389, lr:3.12e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.321, tt:2488.811\n",
      "Ep:202, loss:0.00000, loss_test:0.08332, lr:3.09e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.322, tt:2501.278\n",
      "Ep:203, loss:0.00000, loss_test:0.08389, lr:3.05e-03, fs:0.77019 (r=0.626,p=1.000),  time:12.322, tt:2513.774\n",
      "Ep:204, loss:0.00000, loss_test:0.08407, lr:3.02e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.324, tt:2526.430\n",
      "Ep:205, loss:0.00000, loss_test:0.08375, lr:2.99e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.325, tt:2539.024\n",
      "Ep:206, loss:0.00000, loss_test:0.08406, lr:2.96e-03, fs:0.76250 (r=0.616,p=1.000),  time:12.326, tt:2551.493\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "#             loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "#             loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "#             loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00087, loss_test:0.02038, lr:1.00e-02, fs:0.66939 (r=0.943,p=0.519),  time:621.383, tt:621.383\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01743, lr:1.00e-02, fs:0.72807 (r=0.954,p=0.589),  time:636.404, tt:1272.809\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.01613, lr:1.00e-02, fs:0.73488 (r=0.908,p=0.617),  time:643.692, tt:1931.077\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.01566, lr:1.00e-02, fs:0.76699 (r=0.908,p=0.664),  time:648.789, tt:2595.157\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.01556, lr:1.00e-02, fs:0.78607 (r=0.908,p=0.693),  time:651.442, tt:3257.211\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.01547, lr:1.00e-02, fs:0.79000 (r=0.908,p=0.699),  time:651.067, tt:3906.405\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.01554, lr:1.00e-02, fs:0.79397 (r=0.908,p=0.705),  time:650.691, tt:4554.837\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.01572, lr:1.00e-02, fs:0.80203 (r=0.908,p=0.718),  time:650.737, tt:5205.896\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.01573, lr:1.00e-02, fs:0.81675 (r=0.897,p=0.750),  time:650.848, tt:5857.629\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.01605, lr:1.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:651.996, tt:6519.957\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.01632, lr:1.00e-02, fs:0.81319 (r=0.851,p=0.779),  time:651.524, tt:7166.763\n",
      "Ep:11, loss:0.00020, loss_test:0.01693, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:651.655, tt:7819.863\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.01710, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:651.316, tt:8467.102\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.01779, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:651.222, tt:9117.113\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00015, loss_test:0.01837, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:650.885, tt:9763.271\n",
      "Ep:15, loss:0.00014, loss_test:0.01891, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:651.218, tt:10419.486\n",
      "Ep:16, loss:0.00013, loss_test:0.01976, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:650.883, tt:11065.004\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00012, loss_test:0.02044, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:650.801, tt:11714.413\n",
      "Ep:18, loss:0.00011, loss_test:0.02095, lr:1.00e-02, fs:0.84967 (r=0.747,p=0.985),  time:651.220, tt:12373.186\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00010, loss_test:0.02170, lr:1.00e-02, fs:0.84967 (r=0.747,p=0.985),  time:651.545, tt:13030.893\n",
      "Ep:20, loss:0.00010, loss_test:0.02253, lr:1.00e-02, fs:0.84967 (r=0.747,p=0.985),  time:651.366, tt:13678.680\n",
      "Ep:21, loss:0.00009, loss_test:0.02339, lr:1.00e-02, fs:0.84967 (r=0.747,p=0.985),  time:651.435, tt:14331.566\n",
      "Ep:22, loss:0.00008, loss_test:0.02407, lr:1.00e-02, fs:0.84967 (r=0.747,p=0.985),  time:651.664, tt:14988.274\n",
      "Ep:23, loss:0.00008, loss_test:0.02479, lr:1.00e-02, fs:0.84967 (r=0.747,p=0.985),  time:651.693, tt:15640.636\n",
      "Ep:24, loss:0.00008, loss_test:0.02564, lr:1.00e-02, fs:0.84211 (r=0.736,p=0.985),  time:651.865, tt:16296.620\n",
      "Ep:25, loss:0.00007, loss_test:0.02631, lr:1.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:652.384, tt:16961.976\n",
      "Ep:26, loss:0.00007, loss_test:0.02683, lr:1.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:652.647, tt:17621.478\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00088, loss_test:0.01959, lr:1.00e-02, fs:0.66667 (r=0.931,p=0.519),  time:633.463, tt:633.463\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00065, loss_test:0.01705, lr:1.00e-02, fs:0.72034 (r=0.977,p=0.570),  time:643.205, tt:1286.411\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01577, lr:1.00e-02, fs:0.75336 (r=0.966,p=0.618),  time:648.564, tt:1945.692\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01503, lr:1.00e-02, fs:0.76364 (r=0.966,p=0.632),  time:651.105, tt:2604.419\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.01457, lr:1.00e-02, fs:0.75598 (r=0.908,p=0.648),  time:653.099, tt:3265.495\n",
      "Ep:5, loss:0.00039, loss_test:0.01434, lr:1.00e-02, fs:0.75829 (r=0.920,p=0.645),  time:654.068, tt:3924.411\n",
      "Ep:6, loss:0.00035, loss_test:0.01429, lr:1.00e-02, fs:0.77670 (r=0.920,p=0.672),  time:655.117, tt:4585.819\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.01420, lr:1.00e-02, fs:0.79208 (r=0.920,p=0.696),  time:655.297, tt:5242.372\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.01420, lr:1.00e-02, fs:0.80808 (r=0.920,p=0.721),  time:656.304, tt:5906.737\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.01428, lr:1.00e-02, fs:0.83333 (r=0.920,p=0.762),  time:656.695, tt:6566.950\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.01432, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:656.137, tt:7217.511\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.01456, lr:1.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:655.572, tt:7866.863\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.01477, lr:1.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:655.596, tt:8522.744\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.01490, lr:1.00e-02, fs:0.86486 (r=0.920,p=0.816),  time:655.511, tt:9177.157\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.01527, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:656.620, tt:9849.299\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.01568, lr:1.00e-02, fs:0.88268 (r=0.908,p=0.859),  time:656.236, tt:10499.770\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.01604, lr:1.00e-02, fs:0.87006 (r=0.885,p=0.856),  time:655.724, tt:11147.307\n",
      "Ep:17, loss:0.00013, loss_test:0.01639, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:656.274, tt:11812.928\n",
      "Ep:18, loss:0.00012, loss_test:0.01686, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:656.739, tt:12478.040\n",
      "Ep:19, loss:0.00011, loss_test:0.01737, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:656.656, tt:13133.120\n",
      "Ep:20, loss:0.00011, loss_test:0.01778, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:656.378, tt:13783.935\n",
      "Ep:21, loss:0.00010, loss_test:0.01841, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:656.466, tt:14442.242\n",
      "Ep:22, loss:0.00009, loss_test:0.01880, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:656.607, tt:15101.966\n",
      "Ep:23, loss:0.00009, loss_test:0.01932, lr:1.00e-02, fs:0.86391 (r=0.839,p=0.890),  time:656.848, tt:15764.364\n",
      "Ep:24, loss:0.00008, loss_test:0.01985, lr:1.00e-02, fs:0.86905 (r=0.839,p=0.901),  time:656.569, tt:16414.220\n",
      "Ep:25, loss:0.00008, loss_test:0.02025, lr:1.00e-02, fs:0.86905 (r=0.839,p=0.901),  time:656.190, tt:17060.929\n",
      "Ep:26, loss:0.00007, loss_test:0.02080, lr:1.00e-02, fs:0.86905 (r=0.839,p=0.901),  time:655.999, tt:17711.963\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00079, loss_test:0.01929, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:677.399, tt:677.399\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01740, lr:1.00e-02, fs:0.72414 (r=0.966,p=0.579),  time:675.124, tt:1350.248\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01661, lr:1.00e-02, fs:0.77064 (r=0.966,p=0.641),  time:679.665, tt:2038.995\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.01614, lr:1.00e-02, fs:0.79048 (r=0.954,p=0.675),  time:679.164, tt:2716.655\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.01583, lr:1.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:682.638, tt:3413.190\n",
      "Ep:5, loss:0.00045, loss_test:0.01568, lr:1.00e-02, fs:0.76382 (r=0.874,p=0.679),  time:685.099, tt:4110.595\n",
      "Ep:6, loss:0.00042, loss_test:0.01559, lr:1.00e-02, fs:0.76142 (r=0.862,p=0.682),  time:687.410, tt:4811.870\n",
      "Ep:7, loss:0.00040, loss_test:0.01559, lr:1.00e-02, fs:0.77720 (r=0.862,p=0.708),  time:688.794, tt:5510.351\n",
      "Ep:8, loss:0.00038, loss_test:0.01555, lr:1.00e-02, fs:0.78947 (r=0.862,p=0.728),  time:688.730, tt:6198.570\n",
      "Ep:9, loss:0.00036, loss_test:0.01562, lr:1.00e-02, fs:0.78947 (r=0.862,p=0.728),  time:690.076, tt:6900.756\n",
      "Ep:10, loss:0.00034, loss_test:0.01571, lr:1.00e-02, fs:0.77660 (r=0.839,p=0.723),  time:690.796, tt:7598.759\n",
      "Ep:11, loss:0.00032, loss_test:0.01568, lr:1.00e-02, fs:0.77660 (r=0.839,p=0.723),  time:692.058, tt:8304.692\n",
      "Ep:12, loss:0.00031, loss_test:0.01571, lr:1.00e-02, fs:0.77660 (r=0.839,p=0.723),  time:691.979, tt:8995.726\n",
      "Ep:13, loss:0.00029, loss_test:0.01577, lr:1.00e-02, fs:0.78495 (r=0.839,p=0.737),  time:692.329, tt:9692.601\n",
      "Ep:14, loss:0.00028, loss_test:0.01585, lr:1.00e-02, fs:0.78919 (r=0.839,p=0.745),  time:692.872, tt:10393.084\n",
      "Ep:15, loss:0.00026, loss_test:0.01599, lr:9.90e-03, fs:0.78919 (r=0.839,p=0.745),  time:693.156, tt:11090.502\n",
      "Ep:16, loss:0.00025, loss_test:0.01600, lr:9.80e-03, fs:0.79348 (r=0.839,p=0.753),  time:693.193, tt:11784.281\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.01612, lr:9.80e-03, fs:0.80663 (r=0.839,p=0.777),  time:692.210, tt:12459.784\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.01619, lr:9.80e-03, fs:0.81111 (r=0.839,p=0.785),  time:691.659, tt:13141.529\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.01624, lr:9.80e-03, fs:0.81111 (r=0.839,p=0.785),  time:692.006, tt:13840.124\n",
      "Ep:20, loss:0.00021, loss_test:0.01637, lr:9.80e-03, fs:0.82022 (r=0.839,p=0.802),  time:692.332, tt:14538.969\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.01642, lr:9.80e-03, fs:0.82955 (r=0.839,p=0.820),  time:691.594, tt:15215.062\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.01659, lr:9.80e-03, fs:0.82759 (r=0.828,p=0.828),  time:691.489, tt:15904.248\n",
      "Ep:23, loss:0.00018, loss_test:0.01666, lr:9.80e-03, fs:0.82558 (r=0.816,p=0.835),  time:690.954, tt:16582.904\n",
      "Ep:24, loss:0.00018, loss_test:0.01676, lr:9.80e-03, fs:0.85030 (r=0.816,p=0.887),  time:690.730, tt:17268.239\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.01682, lr:9.80e-03, fs:0.85030 (r=0.816,p=0.887),  time:690.399, tt:17950.367\n",
      "Ep:26, loss:0.00016, loss_test:0.01708, lr:9.80e-03, fs:0.83636 (r=0.793,p=0.885),  time:689.554, tt:18617.946\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00076, loss_test:0.01951, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:679.912, tt:679.912\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01809, lr:1.00e-02, fs:0.69710 (r=0.966,p=0.545),  time:680.454, tt:1360.908\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00058, loss_test:0.01742, lr:1.00e-02, fs:0.71795 (r=0.966,p=0.571),  time:681.804, tt:2045.413\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00055, loss_test:0.01691, lr:1.00e-02, fs:0.75893 (r=0.977,p=0.620),  time:683.641, tt:2734.563\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00052, loss_test:0.01651, lr:1.00e-02, fs:0.76923 (r=0.977,p=0.634),  time:685.975, tt:3429.876\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00049, loss_test:0.01619, lr:1.00e-02, fs:0.77419 (r=0.966,p=0.646),  time:686.105, tt:4116.631\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00047, loss_test:0.01595, lr:1.00e-02, fs:0.76098 (r=0.897,p=0.661),  time:686.840, tt:4807.878\n",
      "Ep:7, loss:0.00045, loss_test:0.01575, lr:1.00e-02, fs:0.76471 (r=0.897,p=0.667),  time:691.422, tt:5531.376\n",
      "Ep:8, loss:0.00043, loss_test:0.01561, lr:1.00e-02, fs:0.76471 (r=0.897,p=0.667),  time:691.574, tt:6224.162\n",
      "Ep:9, loss:0.00041, loss_test:0.01550, lr:1.00e-02, fs:0.77228 (r=0.897,p=0.678),  time:691.083, tt:6910.829\n",
      "Ep:10, loss:0.00039, loss_test:0.01542, lr:1.00e-02, fs:0.77833 (r=0.908,p=0.681),  time:691.507, tt:7606.575\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00038, loss_test:0.01536, lr:1.00e-02, fs:0.78607 (r=0.908,p=0.693),  time:691.518, tt:8298.214\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00036, loss_test:0.01530, lr:1.00e-02, fs:0.79000 (r=0.908,p=0.699),  time:692.921, tt:9007.968\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00035, loss_test:0.01525, lr:1.00e-02, fs:0.79000 (r=0.908,p=0.699),  time:693.117, tt:9703.644\n",
      "Ep:14, loss:0.00034, loss_test:0.01523, lr:1.00e-02, fs:0.79000 (r=0.908,p=0.699),  time:693.084, tt:10396.257\n",
      "Ep:15, loss:0.00032, loss_test:0.01519, lr:1.00e-02, fs:0.80203 (r=0.908,p=0.718),  time:693.301, tt:11092.811\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00031, loss_test:0.01516, lr:1.00e-02, fs:0.80203 (r=0.908,p=0.718),  time:694.294, tt:11802.998\n",
      "Ep:17, loss:0.00030, loss_test:0.01514, lr:1.00e-02, fs:0.80612 (r=0.908,p=0.725),  time:695.501, tt:12519.019\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00029, loss_test:0.01517, lr:1.00e-02, fs:0.81865 (r=0.908,p=0.745),  time:695.179, tt:13208.398\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00028, loss_test:0.01515, lr:1.00e-02, fs:0.82292 (r=0.908,p=0.752),  time:694.660, tt:13893.203\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00027, loss_test:0.01518, lr:1.00e-02, fs:0.84043 (r=0.908,p=0.782),  time:695.011, tt:14595.221\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00026, loss_test:0.01508, lr:1.00e-02, fs:0.83598 (r=0.908,p=0.775),  time:694.349, tt:15275.674\n",
      "Ep:22, loss:0.00025, loss_test:0.01513, lr:1.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:694.095, tt:15964.181\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00024, loss_test:0.01511, lr:1.00e-02, fs:0.84946 (r=0.908,p=0.798),  time:693.917, tt:16654.010\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00024, loss_test:0.01514, lr:1.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:693.970, tt:17349.241\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00023, loss_test:0.01511, lr:1.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:693.869, tt:18040.592\n",
      "Ep:26, loss:0.00022, loss_test:0.01514, lr:1.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:694.206, tt:18743.571\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00078, loss_test:0.01929, lr:1.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:567.063, tt:567.063\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01774, lr:1.00e-02, fs:0.71130 (r=0.977,p=0.559),  time:559.030, tt:1118.060\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01700, lr:1.00e-02, fs:0.74009 (r=0.966,p=0.600),  time:568.401, tt:1705.202\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.01658, lr:1.00e-02, fs:0.75000 (r=0.931,p=0.628),  time:570.030, tt:2280.119\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01633, lr:1.00e-02, fs:0.73786 (r=0.874,p=0.639),  time:571.167, tt:2855.833\n",
      "Ep:5, loss:0.00046, loss_test:0.01615, lr:1.00e-02, fs:0.74510 (r=0.874,p=0.650),  time:572.056, tt:3432.336\n",
      "Ep:6, loss:0.00044, loss_test:0.01607, lr:1.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:572.281, tt:4005.968\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.01603, lr:1.00e-02, fs:0.77778 (r=0.885,p=0.694),  time:573.287, tt:4586.296\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.01595, lr:1.00e-02, fs:0.78571 (r=0.885,p=0.706),  time:573.119, tt:5158.068\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.01591, lr:1.00e-02, fs:0.78571 (r=0.885,p=0.706),  time:573.879, tt:5738.790\n",
      "Ep:10, loss:0.00035, loss_test:0.01598, lr:1.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:573.928, tt:6313.204\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.01593, lr:1.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:574.277, tt:6891.326\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.01601, lr:1.00e-02, fs:0.80000 (r=0.874,p=0.738),  time:574.843, tt:7472.961\n",
      "Ep:13, loss:0.00030, loss_test:0.01606, lr:1.00e-02, fs:0.80851 (r=0.874,p=0.752),  time:574.586, tt:8044.199\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00028, loss_test:0.01613, lr:1.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:575.145, tt:8627.171\n",
      "Ep:15, loss:0.00027, loss_test:0.01618, lr:1.00e-02, fs:0.80220 (r=0.839,p=0.768),  time:575.626, tt:9210.022\n",
      "Ep:16, loss:0.00026, loss_test:0.01628, lr:1.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:576.689, tt:9803.705\n",
      "Ep:17, loss:0.00024, loss_test:0.01634, lr:1.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:576.704, tt:10380.678\n",
      "Ep:18, loss:0.00023, loss_test:0.01648, lr:1.00e-02, fs:0.81111 (r=0.839,p=0.785),  time:576.548, tt:10954.409\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.01654, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:576.944, tt:11538.883\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.01667, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:576.936, tt:12115.656\n",
      "Ep:21, loss:0.00020, loss_test:0.01674, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:576.933, tt:12692.527\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.01684, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:576.776, tt:13265.840\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.01701, lr:1.00e-02, fs:0.86747 (r=0.828,p=0.911),  time:576.338, tt:13832.116\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.01725, lr:1.00e-02, fs:0.88344 (r=0.828,p=0.947),  time:576.784, tt:14419.598\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.01732, lr:1.00e-02, fs:0.88889 (r=0.828,p=0.960),  time:576.640, tt:14992.636\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.01744, lr:1.00e-02, fs:0.89441 (r=0.828,p=0.973),  time:574.331, tt:15506.943\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00103, loss_test:0.02323, lr:1.00e-02, fs:0.64681 (r=0.874,p=0.514),  time:578.828, tt:578.828\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00073, loss_test:0.01961, lr:1.00e-02, fs:0.71130 (r=0.977,p=0.559),  time:580.337, tt:1160.675\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00060, loss_test:0.01719, lr:1.00e-02, fs:0.70588 (r=0.897,p=0.582),  time:579.746, tt:1739.239\n",
      "Ep:3, loss:0.00050, loss_test:0.01654, lr:1.00e-02, fs:0.75598 (r=0.908,p=0.648),  time:583.098, tt:2332.391\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00042, loss_test:0.01673, lr:1.00e-02, fs:0.77295 (r=0.920,p=0.667),  time:584.094, tt:2920.468\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.01737, lr:1.00e-02, fs:0.79602 (r=0.920,p=0.702),  time:585.187, tt:3511.121\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00030, loss_test:0.01864, lr:1.00e-02, fs:0.83770 (r=0.920,p=0.769),  time:585.842, tt:4100.894\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.01985, lr:1.00e-02, fs:0.85106 (r=0.920,p=0.792),  time:585.334, tt:4682.676\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.02097, lr:1.00e-02, fs:0.84492 (r=0.908,p=0.790),  time:585.376, tt:5268.382\n",
      "Ep:9, loss:0.00018, loss_test:0.02230, lr:1.00e-02, fs:0.84153 (r=0.885,p=0.802),  time:586.066, tt:5860.655\n",
      "Ep:10, loss:0.00016, loss_test:0.02374, lr:1.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:586.837, tt:6455.211\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00014, loss_test:0.02431, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:587.119, tt:7045.423\n",
      "Ep:12, loss:0.00012, loss_test:0.02558, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:587.211, tt:7633.745\n",
      "Ep:13, loss:0.00011, loss_test:0.02710, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:586.866, tt:8216.127\n",
      "Ep:14, loss:0.00010, loss_test:0.02859, lr:1.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:587.207, tt:8808.106\n",
      "Ep:15, loss:0.00009, loss_test:0.03067, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:587.145, tt:9394.325\n",
      "Ep:16, loss:0.00008, loss_test:0.03092, lr:1.00e-02, fs:0.78205 (r=0.701,p=0.884),  time:587.337, tt:9984.734\n",
      "Ep:17, loss:0.00007, loss_test:0.03327, lr:1.00e-02, fs:0.69863 (r=0.586,p=0.864),  time:587.524, tt:10575.426\n",
      "Ep:18, loss:0.00006, loss_test:0.03433, lr:1.00e-02, fs:0.69863 (r=0.586,p=0.864),  time:587.190, tt:11156.618\n",
      "Ep:19, loss:0.00006, loss_test:0.03611, lr:1.00e-02, fs:0.70833 (r=0.586,p=0.895),  time:587.435, tt:11748.692\n",
      "Ep:20, loss:0.00005, loss_test:0.03633, lr:1.00e-02, fs:0.68571 (r=0.552,p=0.906),  time:587.662, tt:12340.904\n",
      "Ep:21, loss:0.00005, loss_test:0.03881, lr:1.00e-02, fs:0.70423 (r=0.575,p=0.909),  time:587.340, tt:12921.490\n",
      "Ep:22, loss:0.00005, loss_test:0.03804, lr:9.90e-03, fs:0.68571 (r=0.552,p=0.906),  time:584.571, tt:13445.144\n",
      "Ep:23, loss:0.00004, loss_test:0.03877, lr:9.80e-03, fs:0.69065 (r=0.552,p=0.923),  time:579.051, tt:13897.222\n",
      "Ep:24, loss:0.00004, loss_test:0.04005, lr:9.70e-03, fs:0.69565 (r=0.552,p=0.941),  time:573.597, tt:14339.926\n",
      "Ep:25, loss:0.00004, loss_test:0.04180, lr:9.61e-03, fs:0.70588 (r=0.552,p=0.980),  time:566.923, tt:14739.992\n",
      "Ep:26, loss:0.00004, loss_test:0.04345, lr:9.51e-03, fs:0.70588 (r=0.552,p=0.980),  time:557.186, tt:15044.020\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00073, loss_test:0.01785, lr:1.00e-02, fs:0.68722 (r=0.897,p=0.557),  time:686.291, tt:686.291\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00057, loss_test:0.01638, lr:1.00e-02, fs:0.73973 (r=0.931,p=0.614),  time:672.124, tt:1344.249\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.01589, lr:1.00e-02, fs:0.72727 (r=0.874,p=0.623),  time:665.715, tt:1997.146\n",
      "Ep:3, loss:0.00045, loss_test:0.01567, lr:1.00e-02, fs:0.73892 (r=0.862,p=0.647),  time:662.426, tt:2649.705\n",
      "Ep:4, loss:0.00041, loss_test:0.01553, lr:1.00e-02, fs:0.76000 (r=0.874,p=0.673),  time:662.388, tt:3311.942\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.01550, lr:1.00e-02, fs:0.77949 (r=0.874,p=0.704),  time:663.097, tt:3978.581\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.01545, lr:1.00e-02, fs:0.78756 (r=0.874,p=0.717),  time:662.350, tt:4636.452\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.01541, lr:1.00e-02, fs:0.80000 (r=0.874,p=0.738),  time:662.151, tt:5297.206\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00030, loss_test:0.01539, lr:1.00e-02, fs:0.81283 (r=0.874,p=0.760),  time:662.030, tt:5958.268\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.01530, lr:1.00e-02, fs:0.84324 (r=0.897,p=0.796),  time:664.790, tt:6647.897\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00026, loss_test:0.01532, lr:1.00e-02, fs:0.83060 (r=0.874,p=0.792),  time:671.141, tt:7382.550\n",
      "Ep:11, loss:0.00024, loss_test:0.01539, lr:1.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:677.516, tt:8130.190\n",
      "Ep:12, loss:0.00022, loss_test:0.01551, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:682.508, tt:8872.608\n",
      "Ep:13, loss:0.00021, loss_test:0.01547, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:686.570, tt:9611.984\n",
      "Ep:14, loss:0.00019, loss_test:0.01564, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:690.314, tt:10354.716\n",
      "Ep:15, loss:0.00018, loss_test:0.01576, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:693.582, tt:11097.318\n",
      "Ep:16, loss:0.00017, loss_test:0.01586, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:696.737, tt:11844.535\n",
      "Ep:17, loss:0.00016, loss_test:0.01597, lr:1.00e-02, fs:0.82635 (r=0.793,p=0.863),  time:699.799, tt:12596.379\n",
      "Ep:18, loss:0.00015, loss_test:0.01631, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:701.947, tt:13336.991\n",
      "Ep:19, loss:0.00014, loss_test:0.01640, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:704.349, tt:14086.978\n",
      "Ep:20, loss:0.00013, loss_test:0.01672, lr:1.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:705.712, tt:14819.946\n",
      "Ep:21, loss:0.00012, loss_test:0.01715, lr:9.90e-03, fs:0.82278 (r=0.747,p=0.915),  time:707.265, tt:15559.831\n",
      "Ep:22, loss:0.00012, loss_test:0.01743, lr:9.80e-03, fs:0.82803 (r=0.747,p=0.929),  time:708.790, tt:16302.171\n",
      "Ep:23, loss:0.00011, loss_test:0.01765, lr:9.70e-03, fs:0.82051 (r=0.736,p=0.928),  time:710.331, tt:17047.949\n",
      "Ep:24, loss:0.00010, loss_test:0.01799, lr:9.61e-03, fs:0.81290 (r=0.724,p=0.926),  time:711.802, tt:17795.061\n",
      "Ep:25, loss:0.00010, loss_test:0.01836, lr:9.51e-03, fs:0.78947 (r=0.690,p=0.923),  time:712.931, tt:18536.203\n",
      "Ep:26, loss:0.00009, loss_test:0.01876, lr:9.41e-03, fs:0.77027 (r=0.655,p=0.934),  time:713.749, tt:19271.231\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14232, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.476, tt:40.476\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14029, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.294, tt:88.589\n",
      "Ep:2, loss:0.00001, loss_test:0.13628, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:46.071, tt:138.212\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00001, loss_test:0.12888, lr:1.00e-02, fs:0.67480 (r=0.954,p=0.522),  time:46.839, tt:187.356\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.12011, lr:1.00e-02, fs:0.68122 (r=0.897,p=0.549),  time:47.002, tt:235.011\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.11336, lr:1.00e-02, fs:0.68041 (r=0.759,p=0.617),  time:46.907, tt:281.442\n",
      "Ep:6, loss:0.00001, loss_test:0.10929, lr:1.00e-02, fs:0.69841 (r=0.759,p=0.647),  time:47.113, tt:329.793\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.10808, lr:1.00e-02, fs:0.75862 (r=0.885,p=0.664),  time:47.462, tt:379.697\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.10587, lr:1.00e-02, fs:0.75622 (r=0.874,p=0.667),  time:47.706, tt:429.353\n",
      "Ep:9, loss:0.00001, loss_test:0.10301, lr:1.00e-02, fs:0.70787 (r=0.724,p=0.692),  time:47.746, tt:477.460\n",
      "Ep:10, loss:0.00001, loss_test:0.10113, lr:1.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:47.761, tt:525.370\n",
      "Ep:11, loss:0.00001, loss_test:0.09867, lr:1.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:47.833, tt:574.001\n",
      "Ep:12, loss:0.00001, loss_test:0.09637, lr:1.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:47.678, tt:619.817\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.09538, lr:1.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:47.694, tt:667.721\n",
      "Ep:14, loss:0.00001, loss_test:0.09437, lr:1.00e-02, fs:0.76667 (r=0.793,p=0.742),  time:48.005, tt:720.077\n",
      "Ep:15, loss:0.00001, loss_test:0.09367, lr:1.00e-02, fs:0.77095 (r=0.793,p=0.750),  time:48.124, tt:769.981\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09311, lr:1.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:48.044, tt:816.742\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09237, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:48.085, tt:865.525\n",
      "Ep:18, loss:0.00001, loss_test:0.09174, lr:1.00e-02, fs:0.78409 (r=0.793,p=0.775),  time:48.137, tt:914.612\n",
      "Ep:19, loss:0.00001, loss_test:0.09071, lr:1.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:48.061, tt:961.219\n",
      "Ep:20, loss:0.00001, loss_test:0.08970, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:48.091, tt:1009.906\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.08924, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:48.094, tt:1058.073\n",
      "Ep:22, loss:0.00001, loss_test:0.08845, lr:1.00e-02, fs:0.79558 (r=0.828,p=0.766),  time:48.055, tt:1105.265\n",
      "Ep:23, loss:0.00001, loss_test:0.08741, lr:1.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:48.078, tt:1153.876\n",
      "Ep:24, loss:0.00001, loss_test:0.08643, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:48.169, tt:1204.219\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.08557, lr:1.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:48.214, tt:1253.553\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.08556, lr:1.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:48.237, tt:1302.388\n",
      "Ep:27, loss:0.00001, loss_test:0.08545, lr:1.00e-02, fs:0.81609 (r=0.816,p=0.816),  time:48.215, tt:1350.019\n",
      "Ep:28, loss:0.00000, loss_test:0.08603, lr:1.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:48.234, tt:1398.799\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.08624, lr:1.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:48.240, tt:1447.198\n",
      "Ep:30, loss:0.00000, loss_test:0.08592, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:48.305, tt:1497.442\n",
      "Ep:31, loss:0.00000, loss_test:0.08551, lr:1.00e-02, fs:0.82143 (r=0.793,p=0.852),  time:48.334, tt:1546.681\n",
      "Ep:32, loss:0.00000, loss_test:0.08543, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:48.480, tt:1599.850\n",
      "Ep:33, loss:0.00000, loss_test:0.08533, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:48.498, tt:1648.929\n",
      "Ep:34, loss:0.00000, loss_test:0.08513, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:48.508, tt:1697.784\n",
      "Ep:35, loss:0.00000, loss_test:0.08456, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:48.500, tt:1745.995\n",
      "Ep:36, loss:0.00000, loss_test:0.08398, lr:1.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:48.545, tt:1796.170\n",
      "Ep:37, loss:0.00000, loss_test:0.08502, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:48.603, tt:1846.929\n",
      "Ep:38, loss:0.00000, loss_test:0.08505, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:48.644, tt:1897.101\n",
      "Ep:39, loss:0.00000, loss_test:0.08549, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:48.685, tt:1947.416\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.08509, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:48.653, tt:1994.780\n",
      "Ep:41, loss:0.00000, loss_test:0.08590, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:48.692, tt:2045.045\n",
      "Ep:42, loss:0.00000, loss_test:0.08675, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:48.647, tt:2091.836\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.08763, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:48.650, tt:2140.592\n",
      "Ep:44, loss:0.00000, loss_test:0.08706, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:48.635, tt:2188.588\n",
      "Ep:45, loss:0.00000, loss_test:0.08785, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:48.611, tt:2236.084\n",
      "Ep:46, loss:0.00000, loss_test:0.08855, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.664, tt:2287.199\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00000, loss_test:0.08766, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:48.703, tt:2337.729\n",
      "Ep:48, loss:0.00000, loss_test:0.08956, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.736, tt:2388.064\n",
      "Ep:49, loss:0.00000, loss_test:0.08919, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.737, tt:2436.831\n",
      "Ep:50, loss:0.00000, loss_test:0.09136, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.753, tt:2486.389\n",
      "Ep:51, loss:0.00000, loss_test:0.09237, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.754, tt:2535.219\n",
      "Ep:52, loss:0.00000, loss_test:0.09073, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.758, tt:2584.182\n",
      "Ep:53, loss:0.00000, loss_test:0.09399, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.780, tt:2634.122\n",
      "Ep:54, loss:0.00000, loss_test:0.09488, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.800, tt:2684.009\n",
      "Ep:55, loss:0.00000, loss_test:0.09593, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.807, tt:2733.183\n",
      "Ep:56, loss:0.00000, loss_test:0.09446, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.829, tt:2783.233\n",
      "Ep:57, loss:0.00000, loss_test:0.09911, lr:1.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:48.838, tt:2832.591\n",
      "Ep:58, loss:0.00000, loss_test:0.09843, lr:9.90e-03, fs:0.83871 (r=0.747,p=0.956),  time:48.869, tt:2883.254\n",
      "Ep:59, loss:0.00000, loss_test:0.10030, lr:9.80e-03, fs:0.82119 (r=0.713,p=0.969),  time:48.879, tt:2932.757\n",
      "Ep:60, loss:0.00000, loss_test:0.09969, lr:9.70e-03, fs:0.84416 (r=0.747,p=0.970),  time:48.871, tt:2981.129\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00000, loss_test:0.10236, lr:9.70e-03, fs:0.80537 (r=0.690,p=0.968),  time:48.887, tt:3031.006\n",
      "Ep:62, loss:0.00000, loss_test:0.10273, lr:9.70e-03, fs:0.77778 (r=0.644,p=0.982),  time:48.900, tt:3080.688\n",
      "Ep:63, loss:0.00000, loss_test:0.10447, lr:9.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:48.903, tt:3129.760\n",
      "Ep:64, loss:0.00000, loss_test:0.10440, lr:9.70e-03, fs:0.81333 (r=0.701,p=0.968),  time:48.894, tt:3178.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00000, loss_test:0.10717, lr:9.70e-03, fs:0.75714 (r=0.609,p=1.000),  time:48.892, tt:3226.855\n",
      "Ep:66, loss:0.00000, loss_test:0.10714, lr:9.70e-03, fs:0.78322 (r=0.644,p=1.000),  time:48.890, tt:3275.606\n",
      "Ep:67, loss:0.00000, loss_test:0.10920, lr:9.70e-03, fs:0.73913 (r=0.586,p=1.000),  time:48.881, tt:3323.937\n",
      "Ep:68, loss:0.00000, loss_test:0.11036, lr:9.70e-03, fs:0.75714 (r=0.609,p=1.000),  time:48.860, tt:3371.364\n",
      "Ep:69, loss:0.00000, loss_test:0.11269, lr:9.70e-03, fs:0.66154 (r=0.494,p=1.000),  time:48.848, tt:3419.350\n",
      "Ep:70, loss:0.00000, loss_test:0.11177, lr:9.70e-03, fs:0.68182 (r=0.517,p=1.000),  time:48.849, tt:3468.308\n",
      "Ep:71, loss:0.00000, loss_test:0.11191, lr:9.70e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.847, tt:3517.002\n",
      "Ep:72, loss:0.00000, loss_test:0.11232, lr:9.61e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.801, tt:3562.496\n",
      "Ep:73, loss:0.00000, loss_test:0.11380, lr:9.51e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.781, tt:3609.767\n",
      "Ep:74, loss:0.00000, loss_test:0.11531, lr:9.41e-03, fs:0.66154 (r=0.494,p=1.000),  time:48.762, tt:3657.118\n",
      "Ep:75, loss:0.00000, loss_test:0.11604, lr:9.32e-03, fs:0.70149 (r=0.540,p=1.000),  time:48.767, tt:3706.323\n",
      "Ep:76, loss:0.00000, loss_test:0.11461, lr:9.23e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.734, tt:3752.520\n",
      "Ep:77, loss:0.00000, loss_test:0.11612, lr:9.14e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.707, tt:3799.122\n",
      "Ep:78, loss:0.00000, loss_test:0.11707, lr:9.04e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.710, tt:3848.073\n",
      "Ep:79, loss:0.00000, loss_test:0.11669, lr:8.95e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.726, tt:3898.109\n",
      "Ep:80, loss:0.00000, loss_test:0.11858, lr:8.86e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.697, tt:3944.444\n",
      "Ep:81, loss:0.00000, loss_test:0.11815, lr:8.78e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.666, tt:3990.639\n",
      "Ep:82, loss:0.00000, loss_test:0.11986, lr:8.69e-03, fs:0.75714 (r=0.609,p=1.000),  time:48.631, tt:4036.386\n",
      "Ep:83, loss:0.00000, loss_test:0.11872, lr:8.60e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.712, tt:4091.792\n",
      "Ep:84, loss:0.00000, loss_test:0.12012, lr:8.51e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.718, tt:4141.055\n",
      "Ep:85, loss:0.00000, loss_test:0.12093, lr:8.43e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.686, tt:4186.979\n",
      "Ep:86, loss:0.00000, loss_test:0.12106, lr:8.35e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.689, tt:4235.961\n",
      "Ep:87, loss:0.00000, loss_test:0.12106, lr:8.26e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.696, tt:4285.244\n",
      "Ep:88, loss:0.00000, loss_test:0.12145, lr:8.18e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.695, tt:4333.828\n",
      "Ep:89, loss:0.00000, loss_test:0.12353, lr:8.10e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.699, tt:4382.876\n",
      "Ep:90, loss:0.00000, loss_test:0.12155, lr:8.02e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.636, tt:4425.836\n",
      "Ep:91, loss:0.00000, loss_test:0.12439, lr:7.94e-03, fs:0.72993 (r=0.575,p=1.000),  time:48.550, tt:4466.566\n",
      "Ep:92, loss:0.00000, loss_test:0.12271, lr:7.86e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.493, tt:4509.829\n",
      "Ep:93, loss:0.00000, loss_test:0.12460, lr:7.78e-03, fs:0.72993 (r=0.575,p=1.000),  time:48.419, tt:4551.365\n",
      "Ep:94, loss:0.00000, loss_test:0.12349, lr:7.70e-03, fs:0.75714 (r=0.609,p=1.000),  time:48.354, tt:4593.657\n",
      "Ep:95, loss:0.00000, loss_test:0.12512, lr:7.62e-03, fs:0.73913 (r=0.586,p=1.000),  time:48.285, tt:4635.356\n",
      "Ep:96, loss:0.00000, loss_test:0.12358, lr:7.55e-03, fs:0.77465 (r=0.632,p=1.000),  time:48.216, tt:4676.939\n",
      "Ep:97, loss:0.00000, loss_test:0.12527, lr:7.47e-03, fs:0.72059 (r=0.563,p=1.000),  time:48.157, tt:4719.429\n",
      "Ep:98, loss:0.00000, loss_test:0.12457, lr:7.40e-03, fs:0.76596 (r=0.621,p=1.000),  time:48.083, tt:4760.208\n",
      "Ep:99, loss:0.00000, loss_test:0.12559, lr:7.32e-03, fs:0.73913 (r=0.586,p=1.000),  time:48.024, tt:4802.354\n",
      "Ep:100, loss:0.00000, loss_test:0.12463, lr:7.25e-03, fs:0.75714 (r=0.609,p=1.000),  time:47.955, tt:4843.447\n",
      "Ep:101, loss:0.00000, loss_test:0.12649, lr:7.18e-03, fs:0.75714 (r=0.609,p=1.000),  time:47.900, tt:4885.770\n",
      "Ep:102, loss:0.00000, loss_test:0.12536, lr:7.11e-03, fs:0.74820 (r=0.598,p=1.000),  time:47.849, tt:4928.454\n",
      "Ep:103, loss:0.00000, loss_test:0.12694, lr:7.03e-03, fs:0.75714 (r=0.609,p=1.000),  time:47.753, tt:4966.277\n",
      "Ep:104, loss:0.00000, loss_test:0.12593, lr:6.96e-03, fs:0.74820 (r=0.598,p=1.000),  time:47.639, tt:5002.070\n",
      "Ep:105, loss:0.00000, loss_test:0.12716, lr:6.89e-03, fs:0.74820 (r=0.598,p=1.000),  time:47.493, tt:5034.285\n",
      "Ep:106, loss:0.00000, loss_test:0.12682, lr:6.83e-03, fs:0.75714 (r=0.609,p=1.000),  time:47.306, tt:5061.694\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14249, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.553, tt:31.553\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14060, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.263, tt:76.527\n",
      "Ep:2, loss:0.00001, loss_test:0.13709, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.033, tt:123.098\n",
      "Ep:3, loss:0.00001, loss_test:0.13094, lr:1.00e-02, fs:0.66397 (r=0.943,p=0.512),  time:42.275, tt:169.100\n",
      "Ep:4, loss:0.00001, loss_test:0.12168, lr:1.00e-02, fs:0.67265 (r=0.862,p=0.551),  time:43.408, tt:217.040\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.11609, lr:1.00e-02, fs:0.67760 (r=0.713,p=0.646),  time:44.052, tt:264.309\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.11412, lr:1.00e-02, fs:0.68508 (r=0.713,p=0.660),  time:44.255, tt:309.786\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.11205, lr:1.00e-02, fs:0.71357 (r=0.816,p=0.634),  time:45.053, tt:360.424\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.10858, lr:1.00e-02, fs:0.75510 (r=0.851,p=0.679),  time:45.270, tt:407.426\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.10631, lr:1.00e-02, fs:0.70175 (r=0.690,p=0.714),  time:45.343, tt:453.432\n",
      "Ep:10, loss:0.00001, loss_test:0.10403, lr:1.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:45.411, tt:499.524\n",
      "Ep:11, loss:0.00001, loss_test:0.10322, lr:1.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:45.627, tt:547.524\n",
      "Ep:12, loss:0.00001, loss_test:0.10258, lr:1.00e-02, fs:0.73743 (r=0.759,p=0.717),  time:45.784, tt:595.188\n",
      "Ep:13, loss:0.00001, loss_test:0.10171, lr:1.00e-02, fs:0.73446 (r=0.747,p=0.722),  time:45.781, tt:640.939\n",
      "Ep:14, loss:0.00001, loss_test:0.10039, lr:1.00e-02, fs:0.74033 (r=0.770,p=0.713),  time:45.822, tt:687.330\n",
      "Ep:15, loss:0.00001, loss_test:0.09986, lr:1.00e-02, fs:0.73563 (r=0.736,p=0.736),  time:45.997, tt:735.953\n",
      "Ep:16, loss:0.00001, loss_test:0.09907, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:46.075, tt:783.281\n",
      "Ep:17, loss:0.00001, loss_test:0.09779, lr:1.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:46.085, tt:829.537\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.09750, lr:1.00e-02, fs:0.77457 (r=0.770,p=0.779),  time:45.976, tt:873.549\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.09665, lr:1.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:46.028, tt:920.555\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.09579, lr:1.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:46.208, tt:970.362\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.09528, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:46.272, tt:1017.990\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.09442, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:46.341, tt:1065.845\n",
      "Ep:23, loss:0.00001, loss_test:0.09504, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:46.466, tt:1115.176\n",
      "Ep:24, loss:0.00001, loss_test:0.09532, lr:1.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:46.504, tt:1162.594\n",
      "Ep:25, loss:0.00001, loss_test:0.09517, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:46.552, tt:1210.345\n",
      "Ep:26, loss:0.00001, loss_test:0.09450, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:46.720, tt:1261.436\n",
      "Ep:27, loss:0.00000, loss_test:0.09373, lr:1.00e-02, fs:0.78313 (r=0.747,p=0.823),  time:46.710, tt:1307.887\n",
      "Ep:28, loss:0.00000, loss_test:0.09353, lr:1.00e-02, fs:0.79042 (r=0.759,p=0.825),  time:46.743, tt:1355.534\n",
      "Ep:29, loss:0.00000, loss_test:0.09288, lr:1.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:46.833, tt:1404.998\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.09272, lr:1.00e-02, fs:0.78481 (r=0.713,p=0.873),  time:46.909, tt:1454.192\n",
      "Ep:31, loss:0.00000, loss_test:0.09211, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:46.984, tt:1503.487\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.09147, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:47.052, tt:1552.728\n",
      "Ep:33, loss:0.00000, loss_test:0.09113, lr:1.00e-02, fs:0.76923 (r=0.690,p=0.870),  time:47.054, tt:1599.853\n",
      "Ep:34, loss:0.00000, loss_test:0.09100, lr:1.00e-02, fs:0.77419 (r=0.690,p=0.882),  time:47.097, tt:1648.380\n",
      "Ep:35, loss:0.00000, loss_test:0.09100, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:47.129, tt:1696.661\n",
      "Ep:36, loss:0.00000, loss_test:0.09081, lr:1.00e-02, fs:0.77124 (r=0.678,p=0.894),  time:47.148, tt:1744.488\n",
      "Ep:37, loss:0.00000, loss_test:0.09043, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:47.204, tt:1793.760\n",
      "Ep:38, loss:0.00000, loss_test:0.09184, lr:1.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:47.228, tt:1841.903\n",
      "Ep:39, loss:0.00000, loss_test:0.09099, lr:1.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:47.274, tt:1890.971\n",
      "Ep:40, loss:0.00000, loss_test:0.09264, lr:1.00e-02, fs:0.77852 (r=0.667,p=0.935),  time:47.267, tt:1937.950\n",
      "Ep:41, loss:0.00000, loss_test:0.09252, lr:1.00e-02, fs:0.77852 (r=0.667,p=0.935),  time:47.276, tt:1985.593\n",
      "Ep:42, loss:0.00000, loss_test:0.09321, lr:1.00e-02, fs:0.77852 (r=0.667,p=0.935),  time:47.284, tt:2033.221\n",
      "Ep:43, loss:0.00000, loss_test:0.09382, lr:9.90e-03, fs:0.79452 (r=0.667,p=0.983),  time:47.252, tt:2079.100\n",
      "Ep:44, loss:0.00000, loss_test:0.09344, lr:9.80e-03, fs:0.79452 (r=0.667,p=0.983),  time:47.218, tt:2124.799\n",
      "Ep:45, loss:0.00000, loss_test:0.09438, lr:9.70e-03, fs:0.79452 (r=0.667,p=0.983),  time:47.096, tt:2166.398\n",
      "Ep:46, loss:0.00000, loss_test:0.09494, lr:9.61e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.035, tt:2210.634\n",
      "Ep:47, loss:0.00000, loss_test:0.09413, lr:9.51e-03, fs:0.79452 (r=0.667,p=0.983),  time:46.976, tt:2254.838\n",
      "Ep:48, loss:0.00000, loss_test:0.09576, lr:9.41e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.912, tt:2298.665\n",
      "Ep:49, loss:0.00000, loss_test:0.09545, lr:9.32e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.910, tt:2345.484\n",
      "Ep:50, loss:0.00000, loss_test:0.09581, lr:9.23e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.914, tt:2392.615\n",
      "Ep:51, loss:0.00000, loss_test:0.09694, lr:9.14e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.927, tt:2440.203\n",
      "Ep:52, loss:0.00000, loss_test:0.09700, lr:9.04e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.911, tt:2486.310\n",
      "Ep:53, loss:0.00000, loss_test:0.09773, lr:8.95e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.905, tt:2532.893\n",
      "Ep:54, loss:0.00000, loss_test:0.09780, lr:8.86e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.916, tt:2580.389\n",
      "Ep:55, loss:0.00000, loss_test:0.09981, lr:8.78e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.941, tt:2628.716\n",
      "Ep:56, loss:0.00000, loss_test:0.09855, lr:8.69e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.957, tt:2676.575\n",
      "Ep:57, loss:0.00000, loss_test:0.09931, lr:8.60e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.965, tt:2723.986\n",
      "Ep:58, loss:0.00000, loss_test:0.10073, lr:8.51e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.984, tt:2772.065\n",
      "Ep:59, loss:0.00000, loss_test:0.09945, lr:8.43e-03, fs:0.80000 (r=0.667,p=1.000),  time:46.999, tt:2819.940\n",
      "Ep:60, loss:0.00000, loss_test:0.10075, lr:8.35e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.019, tt:2868.171\n",
      "Ep:61, loss:0.00000, loss_test:0.10230, lr:8.26e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.040, tt:2916.454\n",
      "Ep:62, loss:0.00000, loss_test:0.10069, lr:8.18e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.099, tt:2967.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00000, loss_test:0.10310, lr:8.10e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.154, tt:3017.835\n",
      "Ep:64, loss:0.00000, loss_test:0.10275, lr:8.02e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.189, tt:3067.293\n",
      "Ep:65, loss:0.00000, loss_test:0.10303, lr:7.94e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.199, tt:3115.156\n",
      "Ep:66, loss:0.00000, loss_test:0.10428, lr:7.86e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.208, tt:3162.943\n",
      "Ep:67, loss:0.00000, loss_test:0.10394, lr:7.78e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.201, tt:3209.688\n",
      "Ep:68, loss:0.00000, loss_test:0.10505, lr:7.70e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.213, tt:3257.690\n",
      "Ep:69, loss:0.00000, loss_test:0.10474, lr:7.62e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.228, tt:3305.925\n",
      "Ep:70, loss:0.00000, loss_test:0.10536, lr:7.55e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.230, tt:3353.356\n",
      "Ep:71, loss:0.00000, loss_test:0.10537, lr:7.47e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.258, tt:3402.594\n",
      "Ep:72, loss:0.00000, loss_test:0.10613, lr:7.40e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.275, tt:3451.062\n",
      "Ep:73, loss:0.00000, loss_test:0.10605, lr:7.32e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.262, tt:3497.353\n",
      "Ep:74, loss:0.00000, loss_test:0.10696, lr:7.25e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.282, tt:3546.151\n",
      "Ep:75, loss:0.00000, loss_test:0.10737, lr:7.18e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.306, tt:3595.283\n",
      "Ep:76, loss:0.00000, loss_test:0.10790, lr:7.11e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.321, tt:3643.750\n",
      "Ep:77, loss:0.00000, loss_test:0.10823, lr:7.03e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.329, tt:3691.685\n",
      "Ep:78, loss:0.00000, loss_test:0.10925, lr:6.96e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.373, tt:3742.492\n",
      "Ep:79, loss:0.00000, loss_test:0.10860, lr:6.89e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.394, tt:3791.519\n",
      "Ep:80, loss:0.00000, loss_test:0.10952, lr:6.83e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.425, tt:3841.410\n",
      "Ep:81, loss:0.00000, loss_test:0.11064, lr:6.76e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.447, tt:3890.678\n",
      "Ep:82, loss:0.00000, loss_test:0.11000, lr:6.69e-03, fs:0.80000 (r=0.667,p=1.000),  time:47.452, tt:3938.557\n",
      "Ep:83, loss:0.00000, loss_test:0.11080, lr:6.62e-03, fs:0.79167 (r=0.655,p=1.000),  time:47.487, tt:3988.941\n",
      "Ep:84, loss:0.00000, loss_test:0.11103, lr:6.56e-03, fs:0.78322 (r=0.644,p=1.000),  time:47.524, tt:4039.532\n",
      "Ep:85, loss:0.00000, loss_test:0.11119, lr:6.49e-03, fs:0.79167 (r=0.655,p=1.000),  time:47.533, tt:4087.827\n",
      "Ep:86, loss:0.00000, loss_test:0.11208, lr:6.43e-03, fs:0.77465 (r=0.632,p=1.000),  time:47.531, tt:4135.194\n",
      "Ep:87, loss:0.00000, loss_test:0.11203, lr:6.36e-03, fs:0.77465 (r=0.632,p=1.000),  time:47.539, tt:4183.435\n",
      "Ep:88, loss:0.00000, loss_test:0.11334, lr:6.30e-03, fs:0.73913 (r=0.586,p=1.000),  time:47.540, tt:4231.022\n",
      "Ep:89, loss:0.00000, loss_test:0.11261, lr:6.24e-03, fs:0.75714 (r=0.609,p=1.000),  time:47.569, tt:4281.251\n",
      "Ep:90, loss:0.00000, loss_test:0.11387, lr:6.17e-03, fs:0.70149 (r=0.540,p=1.000),  time:47.593, tt:4331.006\n",
      "Ep:91, loss:0.00000, loss_test:0.11339, lr:6.11e-03, fs:0.70149 (r=0.540,p=1.000),  time:47.600, tt:4379.216\n",
      "Ep:92, loss:0.00000, loss_test:0.11445, lr:6.05e-03, fs:0.68182 (r=0.517,p=1.000),  time:47.650, tt:4431.403\n",
      "Ep:93, loss:0.00000, loss_test:0.11420, lr:5.99e-03, fs:0.68182 (r=0.517,p=1.000),  time:47.655, tt:4479.588\n",
      "Ep:94, loss:0.00000, loss_test:0.11493, lr:5.93e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.655, tt:4527.265\n",
      "Ep:95, loss:0.00000, loss_test:0.11482, lr:5.87e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.659, tt:4575.221\n",
      "Ep:96, loss:0.00000, loss_test:0.11541, lr:5.81e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.669, tt:4623.859\n",
      "Ep:97, loss:0.00000, loss_test:0.11623, lr:5.75e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.627, tt:4667.470\n",
      "Ep:98, loss:0.00000, loss_test:0.11625, lr:5.70e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.577, tt:4710.165\n",
      "Ep:99, loss:0.00000, loss_test:0.11696, lr:5.64e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.544, tt:4754.408\n",
      "Ep:100, loss:0.00000, loss_test:0.11739, lr:5.58e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.498, tt:4797.323\n",
      "Ep:101, loss:0.00000, loss_test:0.11751, lr:5.53e-03, fs:0.67176 (r=0.506,p=1.000),  time:47.440, tt:4838.901\n",
      "Ep:102, loss:0.00000, loss_test:0.11811, lr:5.47e-03, fs:0.66154 (r=0.494,p=1.000),  time:47.398, tt:4881.992\n",
      "Ep:103, loss:0.00000, loss_test:0.11852, lr:5.42e-03, fs:0.66154 (r=0.494,p=1.000),  time:47.322, tt:4921.479\n",
      "Ep:104, loss:0.00000, loss_test:0.11881, lr:5.36e-03, fs:0.66154 (r=0.494,p=1.000),  time:47.291, tt:4965.599\n",
      "Ep:105, loss:0.00000, loss_test:0.11924, lr:5.31e-03, fs:0.66154 (r=0.494,p=1.000),  time:47.299, tt:5013.678\n",
      "Ep:106, loss:0.00000, loss_test:0.11988, lr:5.26e-03, fs:0.66154 (r=0.494,p=1.000),  time:47.292, tt:5060.265\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00352, loss_test:0.10630, lr:4.00e-03, fs:0.71429 (r=0.758,p=0.676),  time:525.319, tt:525.319\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00257, loss_test:0.08659, lr:4.00e-03, fs:0.78218 (r=0.798,p=0.767),  time:551.333, tt:1102.666\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00194, loss_test:0.08017, lr:4.00e-03, fs:0.79793 (r=0.778,p=0.819),  time:561.059, tt:1683.178\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00148, loss_test:0.07418, lr:4.00e-03, fs:0.87500 (r=0.848,p=0.903),  time:566.923, tt:2267.693\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00107, loss_test:0.07554, lr:4.00e-03, fs:0.80702 (r=0.697,p=0.958),  time:569.986, tt:2849.929\n",
      "Ep:5, loss:0.00073, loss_test:0.07528, lr:4.00e-03, fs:0.78313 (r=0.657,p=0.970),  time:572.083, tt:3432.497\n",
      "Ep:6, loss:0.00048, loss_test:0.07517, lr:4.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:573.257, tt:4012.799\n",
      "Ep:7, loss:0.00031, loss_test:0.07634, lr:4.00e-03, fs:0.75472 (r=0.606,p=1.000),  time:575.034, tt:4600.271\n",
      "Ep:8, loss:0.00021, loss_test:0.07761, lr:4.00e-03, fs:0.77019 (r=0.626,p=1.000),  time:576.237, tt:5186.137\n",
      "Ep:9, loss:0.00014, loss_test:0.07831, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:576.872, tt:5768.721\n",
      "Ep:10, loss:0.00010, loss_test:0.08310, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:575.309, tt:6328.395\n",
      "Ep:11, loss:0.00007, loss_test:0.08519, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:571.585, tt:6859.022\n",
      "Ep:12, loss:0.00006, loss_test:0.08253, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:568.217, tt:7386.815\n",
      "Ep:13, loss:0.00004, loss_test:0.08261, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:565.463, tt:7916.486\n",
      "Ep:14, loss:0.00004, loss_test:0.08624, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:562.910, tt:8443.650\n",
      "Ep:15, loss:0.00003, loss_test:0.08197, lr:3.96e-03, fs:0.74684 (r=0.596,p=1.000),  time:560.382, tt:8966.114\n",
      "Ep:16, loss:0.00003, loss_test:0.08155, lr:3.92e-03, fs:0.74684 (r=0.596,p=1.000),  time:557.964, tt:9485.393\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14449, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:41.247, tt:41.247\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14326, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:53.847, tt:107.695\n",
      "Ep:2, loss:0.00055, loss_test:0.14104, lr:4.00e-03, fs:0.66212 (r=0.980,p=0.500),  time:63.828, tt:191.485\n",
      "Ep:3, loss:0.00053, loss_test:0.13740, lr:4.00e-03, fs:0.66197 (r=0.949,p=0.508),  time:68.381, tt:273.524\n",
      "Ep:4, loss:0.00051, loss_test:0.13266, lr:4.00e-03, fs:0.65399 (r=0.869,p=0.524),  time:71.375, tt:356.875\n",
      "Ep:5, loss:0.00048, loss_test:0.12827, lr:4.00e-03, fs:0.66942 (r=0.818,p=0.566),  time:73.929, tt:443.575\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00046, loss_test:0.12689, lr:4.00e-03, fs:0.63725 (r=0.657,p=0.619),  time:75.334, tt:527.339\n",
      "Ep:7, loss:0.00044, loss_test:0.12393, lr:4.00e-03, fs:0.64356 (r=0.657,p=0.631),  time:76.443, tt:611.543\n",
      "Ep:8, loss:0.00042, loss_test:0.11999, lr:4.00e-03, fs:0.66055 (r=0.727,p=0.605),  time:77.398, tt:696.582\n",
      "Ep:9, loss:0.00041, loss_test:0.11627, lr:4.00e-03, fs:0.67327 (r=0.687,p=0.660),  time:78.325, tt:783.249\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00039, loss_test:0.11384, lr:4.00e-03, fs:0.65979 (r=0.646,p=0.674),  time:78.763, tt:866.388\n",
      "Ep:11, loss:0.00037, loss_test:0.11024, lr:4.00e-03, fs:0.68020 (r=0.677,p=0.684),  time:78.909, tt:946.903\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00035, loss_test:0.10726, lr:4.00e-03, fs:0.70000 (r=0.707,p=0.693),  time:79.269, tt:1030.493\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00034, loss_test:0.10612, lr:4.00e-03, fs:0.68085 (r=0.646,p=0.719),  time:79.586, tt:1114.209\n",
      "Ep:14, loss:0.00032, loss_test:0.10433, lr:4.00e-03, fs:0.69430 (r=0.677,p=0.713),  time:79.935, tt:1199.024\n",
      "Ep:15, loss:0.00031, loss_test:0.10339, lr:4.00e-03, fs:0.73298 (r=0.707,p=0.761),  time:80.281, tt:1284.496\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00030, loss_test:0.10244, lr:4.00e-03, fs:0.74074 (r=0.707,p=0.778),  time:80.567, tt:1369.643\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00029, loss_test:0.10199, lr:4.00e-03, fs:0.75532 (r=0.717,p=0.798),  time:80.801, tt:1454.423\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00028, loss_test:0.10076, lr:4.00e-03, fs:0.74866 (r=0.707,p=0.795),  time:80.849, tt:1536.139\n",
      "Ep:19, loss:0.00027, loss_test:0.10018, lr:4.00e-03, fs:0.75269 (r=0.707,p=0.805),  time:80.665, tt:1613.310\n",
      "Ep:20, loss:0.00026, loss_test:0.10014, lr:4.00e-03, fs:0.74595 (r=0.697,p=0.802),  time:80.648, tt:1693.602\n",
      "Ep:21, loss:0.00025, loss_test:0.09981, lr:4.00e-03, fs:0.74595 (r=0.697,p=0.802),  time:80.906, tt:1779.937\n",
      "Ep:22, loss:0.00024, loss_test:0.09866, lr:4.00e-03, fs:0.74595 (r=0.697,p=0.802),  time:81.055, tt:1864.268\n",
      "Ep:23, loss:0.00023, loss_test:0.09771, lr:4.00e-03, fs:0.75676 (r=0.707,p=0.814),  time:81.078, tt:1945.868\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00022, loss_test:0.09783, lr:4.00e-03, fs:0.75410 (r=0.697,p=0.821),  time:81.157, tt:2028.921\n",
      "Ep:25, loss:0.00022, loss_test:0.09746, lr:4.00e-03, fs:0.75000 (r=0.697,p=0.812),  time:81.318, tt:2114.260\n",
      "Ep:26, loss:0.00021, loss_test:0.09761, lr:4.00e-03, fs:0.74725 (r=0.687,p=0.819),  time:81.324, tt:2195.747\n",
      "Ep:27, loss:0.00020, loss_test:0.09618, lr:4.00e-03, fs:0.75000 (r=0.697,p=0.812),  time:81.323, tt:2277.055\n",
      "Ep:28, loss:0.00019, loss_test:0.09721, lr:4.00e-03, fs:0.75138 (r=0.687,p=0.829),  time:80.999, tt:2348.975\n",
      "Ep:29, loss:0.00019, loss_test:0.09691, lr:4.00e-03, fs:0.75000 (r=0.697,p=0.812),  time:81.056, tt:2431.671\n",
      "Ep:30, loss:0.00018, loss_test:0.09627, lr:4.00e-03, fs:0.75410 (r=0.697,p=0.821),  time:81.200, tt:2517.186\n",
      "Ep:31, loss:0.00017, loss_test:0.09574, lr:4.00e-03, fs:0.74317 (r=0.687,p=0.810),  time:81.403, tt:2604.901\n",
      "Ep:32, loss:0.00017, loss_test:0.09794, lr:4.00e-03, fs:0.74576 (r=0.667,p=0.846),  time:81.480, tt:2688.839\n",
      "Ep:33, loss:0.00016, loss_test:0.09583, lr:4.00e-03, fs:0.74157 (r=0.667,p=0.835),  time:81.581, tt:2773.754\n",
      "Ep:34, loss:0.00015, loss_test:0.09821, lr:4.00e-03, fs:0.74576 (r=0.667,p=0.846),  time:81.640, tt:2857.394\n",
      "Ep:35, loss:0.00015, loss_test:0.09613, lr:3.96e-03, fs:0.75429 (r=0.667,p=0.868),  time:81.720, tt:2941.904\n",
      "Ep:36, loss:0.00014, loss_test:0.09877, lr:3.92e-03, fs:0.75581 (r=0.657,p=0.890),  time:81.779, tt:3025.823\n",
      "Ep:37, loss:0.00014, loss_test:0.09455, lr:3.88e-03, fs:0.73743 (r=0.667,p=0.825),  time:81.813, tt:3108.890\n",
      "Ep:38, loss:0.00013, loss_test:0.09780, lr:3.84e-03, fs:0.74713 (r=0.657,p=0.867),  time:81.926, tt:3195.126\n",
      "Ep:39, loss:0.00013, loss_test:0.09637, lr:3.80e-03, fs:0.75145 (r=0.657,p=0.878),  time:81.994, tt:3279.778\n",
      "Ep:40, loss:0.00012, loss_test:0.09933, lr:3.77e-03, fs:0.74854 (r=0.646,p=0.889),  time:82.036, tt:3363.461\n",
      "Ep:41, loss:0.00012, loss_test:0.09709, lr:3.73e-03, fs:0.74286 (r=0.657,p=0.855),  time:82.134, tt:3449.645\n",
      "Ep:42, loss:0.00011, loss_test:0.09922, lr:3.69e-03, fs:0.75581 (r=0.657,p=0.890),  time:82.198, tt:3534.504\n",
      "Ep:43, loss:0.00011, loss_test:0.09906, lr:3.65e-03, fs:0.74419 (r=0.646,p=0.877),  time:82.211, tt:3617.268\n",
      "Ep:44, loss:0.00010, loss_test:0.09733, lr:3.62e-03, fs:0.74419 (r=0.646,p=0.877),  time:82.309, tt:3703.907\n",
      "Ep:45, loss:0.00010, loss_test:0.10163, lr:3.58e-03, fs:0.75294 (r=0.646,p=0.901),  time:82.353, tt:3788.239\n",
      "Ep:46, loss:0.00010, loss_test:0.09762, lr:3.55e-03, fs:0.74419 (r=0.646,p=0.877),  time:82.335, tt:3869.762\n",
      "Ep:47, loss:0.00009, loss_test:0.10207, lr:3.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:82.389, tt:3954.668\n",
      "Ep:48, loss:0.00009, loss_test:0.09967, lr:3.47e-03, fs:0.74854 (r=0.646,p=0.889),  time:82.414, tt:4038.277\n",
      "Ep:49, loss:0.00009, loss_test:0.10051, lr:3.44e-03, fs:0.75294 (r=0.646,p=0.901),  time:82.446, tt:4122.323\n",
      "Ep:50, loss:0.00008, loss_test:0.10335, lr:3.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:82.461, tt:4205.512\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.10005, lr:3.41e-03, fs:0.75294 (r=0.646,p=0.901),  time:82.522, tt:4291.132\n",
      "Ep:52, loss:0.00008, loss_test:0.10418, lr:3.41e-03, fs:0.76190 (r=0.646,p=0.928),  time:82.601, tt:4377.879\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.10188, lr:3.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:82.628, tt:4461.892\n",
      "Ep:54, loss:0.00007, loss_test:0.10151, lr:3.41e-03, fs:0.76647 (r=0.646,p=0.941),  time:82.650, tt:4545.759\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.10411, lr:3.41e-03, fs:0.71951 (r=0.596,p=0.908),  time:82.558, tt:4623.265\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"4-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00443, loss_test:0.11367, lr:4.00e-03, fs:0.68224 (r=0.737,p=0.635),  time:716.706, tt:716.706\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00314, loss_test:0.09684, lr:4.00e-03, fs:0.73846 (r=0.727,p=0.750),  time:737.649, tt:1475.299\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00234, loss_test:0.08915, lr:4.00e-03, fs:0.76842 (r=0.737,p=0.802),  time:744.355, tt:2233.064\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00176, loss_test:0.08674, lr:4.00e-03, fs:0.76344 (r=0.717,p=0.816),  time:747.001, tt:2988.003\n",
      "Ep:4, loss:0.00134, loss_test:0.08750, lr:4.00e-03, fs:0.75862 (r=0.667,p=0.880),  time:747.917, tt:3739.585\n",
      "Ep:5, loss:0.00100, loss_test:0.09110, lr:4.00e-03, fs:0.71515 (r=0.596,p=0.894),  time:748.299, tt:4489.792\n",
      "Ep:6, loss:0.00071, loss_test:0.08777, lr:4.00e-03, fs:0.71515 (r=0.596,p=0.894),  time:748.324, tt:5238.269\n",
      "Ep:7, loss:0.00050, loss_test:0.09117, lr:4.00e-03, fs:0.71515 (r=0.596,p=0.894),  time:746.070, tt:5968.559\n",
      "Ep:8, loss:0.00036, loss_test:0.09984, lr:4.00e-03, fs:0.72840 (r=0.596,p=0.937),  time:745.088, tt:6705.790\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e9ade06c192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"4-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00369, loss_test:0.10218, lr:1.00e-02, fs:0.68889 (r=0.626,p=0.765),  time:696.756, tt:696.756\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00185, loss_test:0.09090, lr:1.00e-02, fs:0.69412 (r=0.596,p=0.831),  time:724.886, tt:1449.771\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00089, loss_test:0.10451, lr:1.00e-02, fs:0.72050 (r=0.586,p=0.935),  time:729.127, tt:2187.381\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00041, loss_test:0.09395, lr:1.00e-02, fs:0.73292 (r=0.596,p=0.952),  time:736.011, tt:2944.044\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00018, loss_test:0.11073, lr:1.00e-02, fs:0.72956 (r=0.586,p=0.967),  time:738.832, tt:3694.160\n",
      "Ep:5, loss:0.00008, loss_test:0.10917, lr:1.00e-02, fs:0.68421 (r=0.525,p=0.981),  time:740.242, tt:4441.450\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-151b4ceb6fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"4-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00369, loss_test:0.10395, lr:1.00e-02, fs:0.68182 (r=0.606,p=0.779),  time:740.647, tt:740.647\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00187, loss_test:0.11833, lr:1.00e-02, fs:0.67485 (r=0.556,p=0.859),  time:744.650, tt:1489.300\n",
      "Ep:2, loss:0.00100, loss_test:0.11085, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:749.210, tt:2247.630\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00055, loss_test:0.12877, lr:1.00e-02, fs:0.71951 (r=0.596,p=0.908),  time:750.370, tt:3001.480\n",
      "Ep:4, loss:0.00027, loss_test:0.12549, lr:1.00e-02, fs:0.59864 (r=0.444,p=0.917),  time:754.152, tt:3770.761\n",
      "Ep:5, loss:0.00015, loss_test:0.14111, lr:1.00e-02, fs:0.61111 (r=0.444,p=0.978),  time:752.574, tt:4515.443\n",
      "Ep:6, loss:0.00007, loss_test:0.13781, lr:1.00e-02, fs:0.58333 (r=0.424,p=0.933),  time:751.367, tt:5259.566\n",
      "Ep:7, loss:0.00004, loss_test:0.13795, lr:1.00e-02, fs:0.54286 (r=0.384,p=0.927),  time:750.169, tt:6001.348\n",
      "Ep:8, loss:0.00003, loss_test:0.13628, lr:1.00e-02, fs:0.59155 (r=0.424,p=0.977),  time:749.431, tt:6744.878\n",
      "Ep:9, loss:0.00002, loss_test:0.14324, lr:1.00e-02, fs:0.53623 (r=0.374,p=0.949),  time:748.725, tt:7487.246\n",
      "Ep:10, loss:0.00002, loss_test:0.13523, lr:1.00e-02, fs:0.53623 (r=0.374,p=0.949),  time:747.706, tt:8224.765\n",
      "Ep:11, loss:0.00002, loss_test:0.13919, lr:1.00e-02, fs:0.53623 (r=0.374,p=0.949),  time:748.618, tt:8983.412\n",
      "Ep:12, loss:0.00001, loss_test:0.13381, lr:1.00e-02, fs:0.54676 (r=0.384,p=0.950),  time:749.819, tt:9747.647\n",
      "Ep:13, loss:0.00001, loss_test:0.13222, lr:1.00e-02, fs:0.53623 (r=0.374,p=0.949),  time:750.152, tt:10502.126\n",
      "Ep:14, loss:0.00001, loss_test:0.13749, lr:9.90e-03, fs:0.54412 (r=0.374,p=1.000),  time:751.081, tt:11266.209\n",
      "Ep:15, loss:0.00001, loss_test:0.13584, lr:9.80e-03, fs:0.53623 (r=0.374,p=0.949),  time:751.324, tt:12021.185\n",
      "Ep:16, loss:0.00001, loss_test:0.13848, lr:9.70e-03, fs:0.53623 (r=0.374,p=0.949),  time:751.692, tt:12778.756\n",
      "Ep:17, loss:0.00001, loss_test:0.13783, lr:9.61e-03, fs:0.53623 (r=0.374,p=0.949),  time:752.345, tt:13542.216\n",
      "Ep:18, loss:0.00001, loss_test:0.13694, lr:9.51e-03, fs:0.53623 (r=0.374,p=0.949),  time:752.778, tt:14302.775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14730, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.855, tt:12.855\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14710, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.275, tt:30.550\n",
      "Ep:2, loss:0.00004, loss_test:0.14678, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.485, tt:49.453\n",
      "Ep:3, loss:0.00004, loss_test:0.14635, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.055, tt:68.221\n",
      "Ep:4, loss:0.00004, loss_test:0.14577, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.603, tt:88.015\n",
      "Ep:5, loss:0.00004, loss_test:0.14500, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.776, tt:106.657\n",
      "Ep:6, loss:0.00004, loss_test:0.14403, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:18.147, tt:127.028\n",
      "Ep:7, loss:0.00004, loss_test:0.14280, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:18.279, tt:146.229\n",
      "Ep:8, loss:0.00004, loss_test:0.14121, lr:1.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:18.514, tt:166.624\n",
      "Ep:9, loss:0.00004, loss_test:0.13896, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:18.572, tt:185.719\n",
      "Ep:10, loss:0.00003, loss_test:0.13608, lr:1.00e-02, fs:0.61475 (r=0.758,p=0.517),  time:18.710, tt:205.807\n",
      "Ep:11, loss:0.00003, loss_test:0.13397, lr:1.00e-02, fs:0.56744 (r=0.616,p=0.526),  time:19.041, tt:228.490\n",
      "Ep:12, loss:0.00003, loss_test:0.13473, lr:9.90e-03, fs:0.51777 (r=0.515,p=0.520),  time:19.060, tt:247.782\n",
      "Ep:13, loss:0.00003, loss_test:0.13559, lr:9.80e-03, fs:0.51337 (r=0.485,p=0.545),  time:19.164, tt:268.297\n",
      "Ep:14, loss:0.00003, loss_test:0.13406, lr:9.70e-03, fs:0.51337 (r=0.485,p=0.545),  time:19.242, tt:288.631\n",
      "Ep:15, loss:0.00003, loss_test:0.13108, lr:9.61e-03, fs:0.56000 (r=0.566,p=0.554),  time:19.278, tt:308.447\n",
      "Ep:16, loss:0.00003, loss_test:0.12931, lr:9.51e-03, fs:0.58768 (r=0.626,p=0.554),  time:19.269, tt:327.569\n",
      "Ep:17, loss:0.00003, loss_test:0.12803, lr:9.41e-03, fs:0.58605 (r=0.636,p=0.543),  time:19.226, tt:346.060\n",
      "Ep:18, loss:0.00003, loss_test:0.12634, lr:9.32e-03, fs:0.59155 (r=0.636,p=0.553),  time:19.287, tt:366.459\n",
      "Ep:19, loss:0.00003, loss_test:0.12487, lr:9.23e-03, fs:0.60396 (r=0.616,p=0.592),  time:19.346, tt:386.918\n",
      "Ep:20, loss:0.00003, loss_test:0.12442, lr:9.14e-03, fs:0.60109 (r=0.556,p=0.655),  time:19.348, tt:406.303\n",
      "Ep:21, loss:0.00003, loss_test:0.12385, lr:9.04e-03, fs:0.57143 (r=0.505,p=0.658),  time:19.315, tt:424.931\n",
      "Ep:22, loss:0.00003, loss_test:0.12165, lr:8.95e-03, fs:0.59551 (r=0.535,p=0.671),  time:19.318, tt:444.322\n",
      "Ep:23, loss:0.00003, loss_test:0.11904, lr:8.86e-03, fs:0.61702 (r=0.586,p=0.652),  time:19.390, tt:465.350\n",
      "Ep:24, loss:0.00002, loss_test:0.11756, lr:8.78e-03, fs:0.62176 (r=0.606,p=0.638),  time:19.407, tt:485.181\n",
      "Ep:25, loss:0.00002, loss_test:0.11704, lr:8.69e-03, fs:0.59459 (r=0.556,p=0.640),  time:19.419, tt:504.888\n",
      "Ep:26, loss:0.00002, loss_test:0.11676, lr:8.60e-03, fs:0.59218 (r=0.535,p=0.662),  time:19.439, tt:524.843\n",
      "Ep:27, loss:0.00002, loss_test:0.11607, lr:8.51e-03, fs:0.61538 (r=0.566,p=0.675),  time:19.453, tt:544.678\n",
      "Ep:28, loss:0.00002, loss_test:0.11444, lr:8.43e-03, fs:0.63784 (r=0.596,p=0.686),  time:19.467, tt:564.541\n",
      "Ep:29, loss:0.00002, loss_test:0.11272, lr:8.35e-03, fs:0.64894 (r=0.616,p=0.685),  time:19.494, tt:584.824\n",
      "Ep:30, loss:0.00002, loss_test:0.11136, lr:8.26e-03, fs:0.65263 (r=0.626,p=0.681),  time:19.526, tt:605.316\n",
      "Ep:31, loss:0.00002, loss_test:0.11044, lr:8.18e-03, fs:0.63830 (r=0.606,p=0.674),  time:19.609, tt:627.483\n",
      "Ep:32, loss:0.00002, loss_test:0.10949, lr:8.10e-03, fs:0.64171 (r=0.606,p=0.682),  time:19.606, tt:646.991\n",
      "Ep:33, loss:0.00002, loss_test:0.10839, lr:8.02e-03, fs:0.64894 (r=0.616,p=0.685),  time:19.611, tt:666.783\n",
      "Ep:34, loss:0.00002, loss_test:0.10761, lr:7.94e-03, fs:0.65608 (r=0.626,p=0.689),  time:19.608, tt:686.275\n",
      "Ep:35, loss:0.00002, loss_test:0.10731, lr:7.86e-03, fs:0.64894 (r=0.616,p=0.685),  time:19.634, tt:706.822\n",
      "Ep:36, loss:0.00002, loss_test:0.10712, lr:7.78e-03, fs:0.64171 (r=0.606,p=0.682),  time:19.646, tt:726.901\n",
      "Ep:37, loss:0.00002, loss_test:0.10661, lr:7.70e-03, fs:0.64171 (r=0.606,p=0.682),  time:19.611, tt:745.216\n",
      "Ep:38, loss:0.00002, loss_test:0.10588, lr:7.62e-03, fs:0.64894 (r=0.616,p=0.685),  time:19.586, tt:763.858\n",
      "Ep:39, loss:0.00002, loss_test:0.10531, lr:7.55e-03, fs:0.64921 (r=0.626,p=0.674),  time:19.624, tt:784.943\n",
      "Ep:40, loss:0.00002, loss_test:0.10496, lr:7.47e-03, fs:0.65608 (r=0.626,p=0.689),  time:19.608, tt:803.919\n",
      "Ep:41, loss:0.00002, loss_test:0.10438, lr:7.40e-03, fs:0.65957 (r=0.626,p=0.697),  time:19.622, tt:824.134\n",
      "Ep:42, loss:0.00002, loss_test:0.10344, lr:7.32e-03, fs:0.65969 (r=0.636,p=0.685),  time:19.640, tt:844.534\n",
      "Ep:43, loss:0.00002, loss_test:0.10269, lr:7.25e-03, fs:0.65969 (r=0.636,p=0.685),  time:19.634, tt:863.888\n",
      "Ep:44, loss:0.00002, loss_test:0.10228, lr:7.18e-03, fs:0.65969 (r=0.636,p=0.685),  time:19.641, tt:883.851\n",
      "Ep:45, loss:0.00002, loss_test:0.10195, lr:7.11e-03, fs:0.66667 (r=0.636,p=0.700),  time:19.640, tt:903.422\n",
      "Ep:46, loss:0.00002, loss_test:0.10124, lr:7.03e-03, fs:0.66667 (r=0.636,p=0.700),  time:19.626, tt:922.437\n",
      "Ep:47, loss:0.00002, loss_test:0.10053, lr:6.96e-03, fs:0.66316 (r=0.636,p=0.692),  time:19.598, tt:940.691\n",
      "Ep:48, loss:0.00002, loss_test:0.10005, lr:6.89e-03, fs:0.66667 (r=0.636,p=0.700),  time:19.574, tt:959.118\n",
      "Ep:49, loss:0.00002, loss_test:0.09963, lr:6.83e-03, fs:0.67380 (r=0.636,p=0.716),  time:19.572, tt:978.621\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.09927, lr:6.83e-03, fs:0.67380 (r=0.636,p=0.716),  time:19.581, tt:998.649\n",
      "Ep:51, loss:0.00002, loss_test:0.09859, lr:6.83e-03, fs:0.67380 (r=0.636,p=0.716),  time:19.591, tt:1018.731\n",
      "Ep:52, loss:0.00002, loss_test:0.09785, lr:6.83e-03, fs:0.67742 (r=0.636,p=0.724),  time:19.554, tt:1036.350\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.09726, lr:6.83e-03, fs:0.68108 (r=0.636,p=0.733),  time:19.524, tt:1054.286\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.09670, lr:6.83e-03, fs:0.68478 (r=0.636,p=0.741),  time:19.501, tt:1072.548\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.09590, lr:6.83e-03, fs:0.68852 (r=0.636,p=0.750),  time:19.513, tt:1092.704\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.09514, lr:6.83e-03, fs:0.68817 (r=0.646,p=0.736),  time:19.503, tt:1111.658\n",
      "Ep:57, loss:0.00001, loss_test:0.09501, lr:6.83e-03, fs:0.69231 (r=0.636,p=0.759),  time:19.490, tt:1130.440\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.09448, lr:6.83e-03, fs:0.69231 (r=0.636,p=0.759),  time:19.499, tt:1150.415\n",
      "Ep:59, loss:0.00001, loss_test:0.09344, lr:6.83e-03, fs:0.70213 (r=0.667,p=0.742),  time:19.488, tt:1169.250\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.09280, lr:6.83e-03, fs:0.71579 (r=0.687,p=0.747),  time:19.492, tt:1189.012\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.09266, lr:6.83e-03, fs:0.70330 (r=0.646,p=0.771),  time:19.491, tt:1208.437\n",
      "Ep:62, loss:0.00001, loss_test:0.09191, lr:6.83e-03, fs:0.71658 (r=0.677,p=0.761),  time:19.501, tt:1228.570\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.09106, lr:6.83e-03, fs:0.72917 (r=0.707,p=0.753),  time:19.512, tt:1248.770\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.09079, lr:6.83e-03, fs:0.72727 (r=0.687,p=0.773),  time:19.512, tt:1268.308\n",
      "Ep:65, loss:0.00001, loss_test:0.09009, lr:6.83e-03, fs:0.72727 (r=0.687,p=0.773),  time:19.546, tt:1290.059\n",
      "Ep:66, loss:0.00001, loss_test:0.08915, lr:6.83e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.530, tt:1308.510\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.08902, lr:6.83e-03, fs:0.73118 (r=0.687,p=0.782),  time:19.532, tt:1328.192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.08819, lr:6.83e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.544, tt:1348.515\n",
      "Ep:69, loss:0.00001, loss_test:0.08742, lr:6.83e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.540, tt:1367.834\n",
      "Ep:70, loss:0.00001, loss_test:0.08775, lr:6.83e-03, fs:0.72928 (r=0.667,p=0.805),  time:19.575, tt:1389.808\n",
      "Ep:71, loss:0.00001, loss_test:0.08703, lr:6.83e-03, fs:0.74317 (r=0.687,p=0.810),  time:19.587, tt:1410.243\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.08601, lr:6.83e-03, fs:0.74227 (r=0.727,p=0.758),  time:19.595, tt:1430.415\n",
      "Ep:73, loss:0.00001, loss_test:0.08607, lr:6.83e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.617, tt:1451.647\n",
      "Ep:74, loss:0.00001, loss_test:0.08576, lr:6.83e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.630, tt:1472.267\n",
      "Ep:75, loss:0.00001, loss_test:0.08476, lr:6.83e-03, fs:0.75393 (r=0.727,p=0.783),  time:19.650, tt:1493.406\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.08443, lr:6.83e-03, fs:0.74866 (r=0.707,p=0.795),  time:19.654, tt:1513.326\n",
      "Ep:77, loss:0.00001, loss_test:0.08430, lr:6.83e-03, fs:0.72928 (r=0.667,p=0.805),  time:19.666, tt:1533.909\n",
      "Ep:78, loss:0.00001, loss_test:0.08354, lr:6.83e-03, fs:0.73913 (r=0.687,p=0.800),  time:19.661, tt:1553.220\n",
      "Ep:79, loss:0.00001, loss_test:0.08287, lr:6.83e-03, fs:0.75936 (r=0.717,p=0.807),  time:19.666, tt:1573.262\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.08290, lr:6.83e-03, fs:0.74033 (r=0.677,p=0.817),  time:19.677, tt:1593.803\n",
      "Ep:81, loss:0.00001, loss_test:0.08242, lr:6.83e-03, fs:0.74444 (r=0.677,p=0.827),  time:19.702, tt:1615.574\n",
      "Ep:82, loss:0.00001, loss_test:0.08190, lr:6.83e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.728, tt:1637.438\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.08236, lr:6.83e-03, fs:0.74157 (r=0.667,p=0.835),  time:19.740, tt:1658.141\n",
      "Ep:84, loss:0.00001, loss_test:0.08191, lr:6.83e-03, fs:0.74444 (r=0.677,p=0.827),  time:19.761, tt:1679.723\n",
      "Ep:85, loss:0.00001, loss_test:0.08102, lr:6.83e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.783, tt:1701.362\n",
      "Ep:86, loss:0.00001, loss_test:0.08132, lr:6.83e-03, fs:0.74157 (r=0.667,p=0.835),  time:19.785, tt:1721.312\n",
      "Ep:87, loss:0.00001, loss_test:0.08169, lr:6.83e-03, fs:0.72727 (r=0.646,p=0.831),  time:19.781, tt:1740.761\n",
      "Ep:88, loss:0.00001, loss_test:0.08068, lr:6.83e-03, fs:0.74033 (r=0.677,p=0.817),  time:19.791, tt:1761.385\n",
      "Ep:89, loss:0.00001, loss_test:0.08048, lr:6.83e-03, fs:0.74860 (r=0.677,p=0.838),  time:19.796, tt:1781.654\n",
      "Ep:90, loss:0.00001, loss_test:0.08111, lr:6.83e-03, fs:0.73143 (r=0.646,p=0.842),  time:19.806, tt:1802.376\n",
      "Ep:91, loss:0.00001, loss_test:0.08004, lr:6.83e-03, fs:0.73143 (r=0.646,p=0.842),  time:19.828, tt:1824.160\n",
      "Ep:92, loss:0.00001, loss_test:0.07901, lr:6.83e-03, fs:0.75000 (r=0.697,p=0.812),  time:19.838, tt:1844.902\n",
      "Ep:93, loss:0.00001, loss_test:0.07991, lr:6.83e-03, fs:0.73143 (r=0.646,p=0.842),  time:19.845, tt:1865.473\n",
      "Ep:94, loss:0.00001, loss_test:0.07960, lr:6.76e-03, fs:0.73143 (r=0.646,p=0.842),  time:19.857, tt:1886.459\n",
      "Ep:95, loss:0.00001, loss_test:0.07834, lr:6.69e-03, fs:0.76923 (r=0.707,p=0.843),  time:19.871, tt:1907.603\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.07884, lr:6.69e-03, fs:0.73563 (r=0.646,p=0.853),  time:19.884, tt:1928.745\n",
      "Ep:97, loss:0.00001, loss_test:0.07848, lr:6.69e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.898, tt:1950.020\n",
      "Ep:98, loss:0.00001, loss_test:0.07721, lr:6.69e-03, fs:0.75556 (r=0.687,p=0.840),  time:19.897, tt:1969.768\n",
      "Ep:99, loss:0.00001, loss_test:0.07687, lr:6.69e-03, fs:0.75978 (r=0.687,p=0.850),  time:19.898, tt:1989.831\n",
      "Ep:100, loss:0.00001, loss_test:0.07788, lr:6.69e-03, fs:0.73563 (r=0.646,p=0.853),  time:19.903, tt:2010.202\n",
      "Ep:101, loss:0.00001, loss_test:0.07684, lr:6.69e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.896, tt:2029.433\n",
      "Ep:102, loss:0.00001, loss_test:0.07506, lr:6.69e-03, fs:0.76503 (r=0.707,p=0.833),  time:19.901, tt:2049.752\n",
      "Ep:103, loss:0.00001, loss_test:0.07557, lr:6.69e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.891, tt:2068.619\n",
      "Ep:104, loss:0.00001, loss_test:0.07667, lr:6.69e-03, fs:0.73256 (r=0.636,p=0.863),  time:19.892, tt:2088.665\n",
      "Ep:105, loss:0.00001, loss_test:0.07495, lr:6.69e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.883, tt:2107.558\n",
      "Ep:106, loss:0.00001, loss_test:0.07367, lr:6.69e-03, fs:0.77348 (r=0.707,p=0.854),  time:19.917, tt:2131.121\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.07427, lr:6.69e-03, fs:0.74286 (r=0.657,p=0.855),  time:19.928, tt:2152.201\n",
      "Ep:108, loss:0.00001, loss_test:0.07481, lr:6.69e-03, fs:0.73988 (r=0.646,p=0.865),  time:19.929, tt:2172.276\n",
      "Ep:109, loss:0.00001, loss_test:0.07401, lr:6.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.934, tt:2192.687\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.07351, lr:6.69e-03, fs:0.76836 (r=0.687,p=0.872),  time:19.936, tt:2212.940\n",
      "Ep:111, loss:0.00001, loss_test:0.07338, lr:6.69e-03, fs:0.74713 (r=0.657,p=0.867),  time:19.937, tt:2232.894\n",
      "Ep:112, loss:0.00001, loss_test:0.07274, lr:6.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.928, tt:2251.881\n",
      "Ep:113, loss:0.00001, loss_test:0.07358, lr:6.69e-03, fs:0.76136 (r=0.677,p=0.870),  time:19.927, tt:2271.713\n",
      "Ep:114, loss:0.00001, loss_test:0.07345, lr:6.69e-03, fs:0.75429 (r=0.667,p=0.868),  time:19.919, tt:2290.664\n",
      "Ep:115, loss:0.00001, loss_test:0.07287, lr:6.69e-03, fs:0.76836 (r=0.687,p=0.872),  time:19.908, tt:2309.344\n",
      "Ep:116, loss:0.00001, loss_test:0.07289, lr:6.69e-03, fs:0.74713 (r=0.657,p=0.867),  time:19.970, tt:2336.451\n",
      "Ep:117, loss:0.00001, loss_test:0.07221, lr:6.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.972, tt:2356.690\n",
      "Ep:118, loss:0.00001, loss_test:0.07370, lr:6.69e-03, fs:0.73988 (r=0.646,p=0.865),  time:19.976, tt:2377.149\n",
      "Ep:119, loss:0.00001, loss_test:0.07224, lr:6.69e-03, fs:0.76136 (r=0.677,p=0.870),  time:19.986, tt:2398.305\n",
      "Ep:120, loss:0.00001, loss_test:0.07138, lr:6.69e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.989, tt:2418.697\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.07422, lr:6.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:20.001, tt:2440.110\n",
      "Ep:122, loss:0.00001, loss_test:0.07277, lr:6.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:20.008, tt:2460.969\n",
      "Ep:123, loss:0.00001, loss_test:0.07007, lr:6.69e-03, fs:0.81283 (r=0.768,p=0.864),  time:20.017, tt:2482.100\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.07169, lr:6.69e-03, fs:0.75862 (r=0.667,p=0.880),  time:20.020, tt:2502.525\n",
      "Ep:125, loss:0.00001, loss_test:0.07303, lr:6.69e-03, fs:0.74419 (r=0.646,p=0.877),  time:20.024, tt:2523.010\n",
      "Ep:126, loss:0.00001, loss_test:0.07048, lr:6.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:20.023, tt:2542.973\n",
      "Ep:127, loss:0.00001, loss_test:0.07013, lr:6.69e-03, fs:0.76136 (r=0.677,p=0.870),  time:20.029, tt:2563.692\n",
      "Ep:128, loss:0.00001, loss_test:0.07178, lr:6.69e-03, fs:0.75862 (r=0.667,p=0.880),  time:20.045, tt:2585.831\n",
      "Ep:129, loss:0.00001, loss_test:0.07035, lr:6.69e-03, fs:0.80663 (r=0.737,p=0.890),  time:20.055, tt:2607.109\n",
      "Ep:130, loss:0.00000, loss_test:0.07010, lr:6.69e-03, fs:0.76571 (r=0.677,p=0.882),  time:20.044, tt:2625.723\n",
      "Ep:131, loss:0.00000, loss_test:0.07009, lr:6.69e-03, fs:0.79330 (r=0.717,p=0.887),  time:20.043, tt:2645.673\n",
      "Ep:132, loss:0.00000, loss_test:0.06976, lr:6.69e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.055, tt:2667.356\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00000, loss_test:0.07121, lr:6.69e-03, fs:0.75145 (r=0.657,p=0.878),  time:20.056, tt:2687.546\n",
      "Ep:134, loss:0.00000, loss_test:0.07020, lr:6.69e-03, fs:0.75145 (r=0.657,p=0.878),  time:20.049, tt:2706.652\n",
      "Ep:135, loss:0.00000, loss_test:0.06896, lr:6.69e-03, fs:0.83243 (r=0.778,p=0.895),  time:20.051, tt:2726.910\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.07248, lr:6.69e-03, fs:0.74854 (r=0.646,p=0.889),  time:20.045, tt:2746.187\n",
      "Ep:137, loss:0.00000, loss_test:0.07221, lr:6.69e-03, fs:0.74854 (r=0.646,p=0.889),  time:20.039, tt:2765.434\n",
      "Ep:138, loss:0.00000, loss_test:0.06881, lr:6.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.041, tt:2785.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.06908, lr:6.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:20.026, tt:2803.690\n",
      "Ep:140, loss:0.00000, loss_test:0.07257, lr:6.69e-03, fs:0.75581 (r=0.657,p=0.890),  time:20.023, tt:2823.221\n",
      "Ep:141, loss:0.00000, loss_test:0.07230, lr:6.69e-03, fs:0.74854 (r=0.646,p=0.889),  time:20.028, tt:2844.045\n",
      "Ep:142, loss:0.00000, loss_test:0.06916, lr:6.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:20.024, tt:2863.385\n",
      "Ep:143, loss:0.00000, loss_test:0.06826, lr:6.69e-03, fs:0.81319 (r=0.747,p=0.892),  time:20.025, tt:2883.588\n",
      "Ep:144, loss:0.00000, loss_test:0.07140, lr:6.69e-03, fs:0.75294 (r=0.646,p=0.901),  time:20.016, tt:2902.251\n",
      "Ep:145, loss:0.00000, loss_test:0.07209, lr:6.69e-03, fs:0.76023 (r=0.657,p=0.903),  time:20.011, tt:2921.595\n",
      "Ep:146, loss:0.00000, loss_test:0.06897, lr:6.69e-03, fs:0.80663 (r=0.737,p=0.890),  time:20.017, tt:2942.473\n",
      "Ep:147, loss:0.00000, loss_test:0.06918, lr:6.62e-03, fs:0.75862 (r=0.667,p=0.880),  time:20.015, tt:2962.204\n",
      "Ep:148, loss:0.00000, loss_test:0.07008, lr:6.56e-03, fs:0.76301 (r=0.667,p=0.892),  time:20.026, tt:2983.898\n",
      "Ep:149, loss:0.00000, loss_test:0.07016, lr:6.49e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.028, tt:3004.244\n",
      "Ep:150, loss:0.00000, loss_test:0.06978, lr:6.43e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.028, tt:3024.166\n",
      "Ep:151, loss:0.00000, loss_test:0.06946, lr:6.36e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.038, tt:3045.729\n",
      "Ep:152, loss:0.00000, loss_test:0.07013, lr:6.30e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.045, tt:3066.933\n",
      "Ep:153, loss:0.00000, loss_test:0.07005, lr:6.24e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.055, tt:3088.438\n",
      "Ep:154, loss:0.00000, loss_test:0.06923, lr:6.17e-03, fs:0.78409 (r=0.697,p=0.896),  time:20.061, tt:3109.429\n",
      "Ep:155, loss:0.00000, loss_test:0.06994, lr:6.11e-03, fs:0.79096 (r=0.707,p=0.897),  time:20.062, tt:3129.629\n",
      "Ep:156, loss:0.00000, loss_test:0.06983, lr:6.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:20.068, tt:3150.731\n",
      "Ep:157, loss:0.00000, loss_test:0.06925, lr:5.99e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.074, tt:3171.766\n",
      "Ep:158, loss:0.00000, loss_test:0.06863, lr:5.93e-03, fs:0.79775 (r=0.717,p=0.899),  time:20.073, tt:3191.678\n",
      "Ep:159, loss:0.00000, loss_test:0.06913, lr:5.87e-03, fs:0.81111 (r=0.737,p=0.901),  time:20.080, tt:3212.870\n",
      "Ep:160, loss:0.00000, loss_test:0.07111, lr:5.81e-03, fs:0.76023 (r=0.657,p=0.903),  time:20.084, tt:3233.604\n",
      "Ep:161, loss:0.00000, loss_test:0.07006, lr:5.75e-03, fs:0.76023 (r=0.657,p=0.903),  time:20.084, tt:3253.572\n",
      "Ep:162, loss:0.00000, loss_test:0.06866, lr:5.70e-03, fs:0.81111 (r=0.737,p=0.901),  time:20.086, tt:3274.088\n",
      "Ep:163, loss:0.00000, loss_test:0.07071, lr:5.64e-03, fs:0.81564 (r=0.737,p=0.912),  time:20.089, tt:3294.526\n",
      "Ep:164, loss:0.00000, loss_test:0.07009, lr:5.58e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.094, tt:3315.452\n",
      "Ep:165, loss:0.00000, loss_test:0.06780, lr:5.53e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.101, tt:3336.833\n",
      "Ep:166, loss:0.00000, loss_test:0.06760, lr:5.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:20.104, tt:3357.384\n",
      "Ep:167, loss:0.00000, loss_test:0.07183, lr:5.42e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.109, tt:3378.235\n",
      "Ep:168, loss:0.00000, loss_test:0.07292, lr:5.36e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.109, tt:3398.361\n",
      "Ep:169, loss:0.00000, loss_test:0.06894, lr:5.31e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.110, tt:3418.764\n",
      "Ep:170, loss:0.00000, loss_test:0.06662, lr:5.26e-03, fs:0.81768 (r=0.747,p=0.902),  time:20.121, tt:3440.695\n",
      "Ep:171, loss:0.00000, loss_test:0.06881, lr:5.20e-03, fs:0.80000 (r=0.707,p=0.921),  time:20.127, tt:3461.906\n",
      "Ep:172, loss:0.00000, loss_test:0.07168, lr:5.15e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.124, tt:3481.479\n",
      "Ep:173, loss:0.00000, loss_test:0.07081, lr:5.10e-03, fs:0.79096 (r=0.707,p=0.897),  time:20.132, tt:3503.034\n",
      "Ep:174, loss:0.00000, loss_test:0.06806, lr:5.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:20.140, tt:3524.463\n",
      "Ep:175, loss:0.00000, loss_test:0.06708, lr:5.00e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.140, tt:3544.631\n",
      "Ep:176, loss:0.00000, loss_test:0.06937, lr:4.95e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.143, tt:3565.272\n",
      "Ep:177, loss:0.00000, loss_test:0.07111, lr:4.90e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.150, tt:3586.771\n",
      "Ep:178, loss:0.00000, loss_test:0.06923, lr:4.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.156, tt:3607.841\n",
      "Ep:179, loss:0.00000, loss_test:0.06708, lr:4.80e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.155, tt:3627.912\n",
      "Ep:180, loss:0.00000, loss_test:0.06878, lr:4.75e-03, fs:0.78857 (r=0.697,p=0.908),  time:20.158, tt:3648.674\n",
      "Ep:181, loss:0.00000, loss_test:0.07066, lr:4.71e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.165, tt:3669.962\n",
      "Ep:182, loss:0.00000, loss_test:0.06925, lr:4.66e-03, fs:0.79545 (r=0.707,p=0.909),  time:20.166, tt:3690.446\n",
      "Ep:183, loss:0.00000, loss_test:0.06747, lr:4.61e-03, fs:0.80447 (r=0.727,p=0.900),  time:20.171, tt:3711.505\n",
      "Ep:184, loss:0.00000, loss_test:0.06793, lr:4.57e-03, fs:0.80447 (r=0.727,p=0.900),  time:20.176, tt:3732.487\n",
      "Ep:185, loss:0.00000, loss_test:0.06903, lr:4.52e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.175, tt:3752.503\n",
      "Ep:186, loss:0.00000, loss_test:0.06873, lr:4.48e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.181, tt:3773.869\n",
      "##########Best model found so far##########\n",
      "Ep:187, loss:0.00000, loss_test:0.06743, lr:4.48e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.186, tt:3794.891\n",
      "Ep:188, loss:0.00000, loss_test:0.06736, lr:4.48e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.191, tt:3816.073\n",
      "Ep:189, loss:0.00000, loss_test:0.06880, lr:4.48e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.198, tt:3837.692\n",
      "Ep:190, loss:0.00000, loss_test:0.06878, lr:4.48e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.203, tt:3858.820\n",
      "Ep:191, loss:0.00000, loss_test:0.06773, lr:4.48e-03, fs:0.83060 (r=0.768,p=0.905),  time:20.205, tt:3879.289\n",
      "Ep:192, loss:0.00000, loss_test:0.06809, lr:4.48e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.210, tt:3900.488\n",
      "Ep:193, loss:0.00000, loss_test:0.06907, lr:4.48e-03, fs:0.81768 (r=0.747,p=0.902),  time:20.214, tt:3921.423\n",
      "Ep:194, loss:0.00000, loss_test:0.06872, lr:4.48e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.219, tt:3942.726\n",
      "Ep:195, loss:0.00000, loss_test:0.06769, lr:4.48e-03, fs:0.80447 (r=0.727,p=0.900),  time:20.223, tt:3963.685\n",
      "Ep:196, loss:0.00000, loss_test:0.06841, lr:4.48e-03, fs:0.83060 (r=0.768,p=0.905),  time:20.225, tt:3984.277\n",
      "Ep:197, loss:0.00000, loss_test:0.06848, lr:4.48e-03, fs:0.81768 (r=0.747,p=0.902),  time:20.222, tt:4003.990\n",
      "Ep:198, loss:0.00000, loss_test:0.06733, lr:4.43e-03, fs:0.81564 (r=0.737,p=0.912),  time:20.228, tt:4025.386\n",
      "Ep:199, loss:0.00000, loss_test:0.06749, lr:4.39e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.225, tt:4045.044\n",
      "Ep:200, loss:0.00000, loss_test:0.06811, lr:4.34e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.223, tt:4064.899\n",
      "Ep:201, loss:0.00000, loss_test:0.06798, lr:4.30e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.227, tt:4085.793\n",
      "Ep:202, loss:0.00000, loss_test:0.06747, lr:4.26e-03, fs:0.83060 (r=0.768,p=0.905),  time:20.218, tt:4104.344\n",
      "Ep:203, loss:0.00000, loss_test:0.06865, lr:4.21e-03, fs:0.79545 (r=0.707,p=0.909),  time:20.228, tt:4126.492\n",
      "Ep:204, loss:0.00000, loss_test:0.06876, lr:4.17e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.229, tt:4146.896\n",
      "Ep:205, loss:0.00000, loss_test:0.06746, lr:4.13e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.234, tt:4168.131\n",
      "Ep:206, loss:0.00000, loss_test:0.06722, lr:4.09e-03, fs:0.83060 (r=0.768,p=0.905),  time:20.235, tt:4188.593\n",
      "Ep:207, loss:0.00000, loss_test:0.07028, lr:4.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:20.238, tt:4209.416\n",
      "Ep:208, loss:0.00000, loss_test:0.07155, lr:4.01e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.244, tt:4230.904\n",
      "Ep:209, loss:0.00000, loss_test:0.07012, lr:3.97e-03, fs:0.75740 (r=0.646,p=0.914),  time:20.243, tt:4251.046\n",
      "Ep:210, loss:0.00000, loss_test:0.06794, lr:3.93e-03, fs:0.77457 (r=0.677,p=0.905),  time:20.244, tt:4271.500\n",
      "Ep:211, loss:0.00000, loss_test:0.06738, lr:3.89e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.245, tt:4291.879\n",
      "Ep:212, loss:0.00000, loss_test:0.06862, lr:3.85e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.246, tt:4312.489\n",
      "Ep:213, loss:0.00000, loss_test:0.06937, lr:3.81e-03, fs:0.75740 (r=0.646,p=0.914),  time:20.267, tt:4337.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:214, loss:0.00000, loss_test:0.06937, lr:3.77e-03, fs:0.76190 (r=0.646,p=0.928),  time:20.265, tt:4357.004\n",
      "Ep:215, loss:0.00000, loss_test:0.06852, lr:3.73e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.271, tt:4378.543\n",
      "Ep:216, loss:0.00000, loss_test:0.06740, lr:3.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.271, tt:4398.909\n",
      "Ep:217, loss:0.00000, loss_test:0.06711, lr:3.66e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.272, tt:4419.200\n",
      "Ep:218, loss:0.00000, loss_test:0.06805, lr:3.62e-03, fs:0.79310 (r=0.697,p=0.920),  time:20.273, tt:4439.686\n",
      "Ep:219, loss:0.00000, loss_test:0.06839, lr:3.59e-03, fs:0.76471 (r=0.657,p=0.915),  time:20.265, tt:4458.306\n",
      "Ep:220, loss:0.00000, loss_test:0.06841, lr:3.55e-03, fs:0.77193 (r=0.667,p=0.917),  time:20.267, tt:4479.018\n",
      "Ep:221, loss:0.00000, loss_test:0.06823, lr:3.52e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.266, tt:4499.065\n",
      "Ep:222, loss:0.00000, loss_test:0.06782, lr:3.48e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.261, tt:4518.242\n",
      "Ep:223, loss:0.00000, loss_test:0.06782, lr:3.45e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.255, tt:4537.065\n",
      "Ep:224, loss:0.00000, loss_test:0.06803, lr:3.41e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.251, tt:4556.377\n",
      "Ep:225, loss:0.00000, loss_test:0.06814, lr:3.38e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.253, tt:4577.156\n",
      "Ep:226, loss:0.00000, loss_test:0.06770, lr:3.34e-03, fs:0.82682 (r=0.747,p=0.925),  time:20.245, tt:4595.557\n",
      "Ep:227, loss:0.00000, loss_test:0.06686, lr:3.31e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.241, tt:4614.997\n",
      "Ep:228, loss:0.00000, loss_test:0.06749, lr:3.28e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.236, tt:4634.100\n",
      "Ep:229, loss:0.00000, loss_test:0.06784, lr:3.24e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.233, tt:4653.577\n",
      "Ep:230, loss:0.00000, loss_test:0.06752, lr:3.21e-03, fs:0.78857 (r=0.697,p=0.908),  time:20.229, tt:4672.881\n",
      "Ep:231, loss:0.00000, loss_test:0.06757, lr:3.18e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.228, tt:4692.952\n",
      "Ep:232, loss:0.00000, loss_test:0.06730, lr:3.15e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.220, tt:4711.165\n",
      "Ep:233, loss:0.00000, loss_test:0.06722, lr:3.12e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.216, tt:4730.548\n",
      "Ep:234, loss:0.00000, loss_test:0.06760, lr:3.09e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.219, tt:4751.380\n",
      "Ep:235, loss:0.00000, loss_test:0.06759, lr:3.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.221, tt:4772.179\n",
      "Ep:236, loss:0.00000, loss_test:0.06767, lr:3.02e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.223, tt:4792.815\n",
      "Ep:237, loss:0.00000, loss_test:0.06765, lr:2.99e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.223, tt:4812.994\n",
      "Ep:238, loss:0.00000, loss_test:0.06776, lr:2.96e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.219, tt:4832.241\n",
      "Ep:239, loss:0.00000, loss_test:0.06746, lr:2.93e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.220, tt:4852.888\n",
      "Ep:240, loss:0.00000, loss_test:0.06755, lr:2.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.217, tt:4872.407\n",
      "Ep:241, loss:0.00000, loss_test:0.06732, lr:2.88e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.214, tt:4891.730\n",
      "Ep:242, loss:0.00000, loss_test:0.06737, lr:2.85e-03, fs:0.81564 (r=0.737,p=0.912),  time:20.213, tt:4911.710\n",
      "Ep:243, loss:0.00000, loss_test:0.06762, lr:2.82e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.208, tt:4930.827\n",
      "Ep:244, loss:0.00000, loss_test:0.06759, lr:2.79e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.205, tt:4950.230\n",
      "Ep:245, loss:0.00000, loss_test:0.06732, lr:2.76e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.206, tt:4970.610\n",
      "Ep:246, loss:0.00000, loss_test:0.06778, lr:2.73e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.205, tt:4990.681\n",
      "Ep:247, loss:0.00000, loss_test:0.06764, lr:2.71e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.208, tt:5011.592\n",
      "Ep:248, loss:0.00000, loss_test:0.06716, lr:2.68e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.209, tt:5031.956\n",
      "Ep:249, loss:0.00000, loss_test:0.06730, lr:2.65e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.212, tt:5052.898\n",
      "Ep:250, loss:0.00000, loss_test:0.06780, lr:2.63e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.209, tt:5072.384\n",
      "Ep:251, loss:0.00000, loss_test:0.06768, lr:2.60e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.210, tt:5092.951\n",
      "Ep:252, loss:0.00000, loss_test:0.06717, lr:2.57e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.210, tt:5113.030\n",
      "Ep:253, loss:0.00000, loss_test:0.06753, lr:2.55e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.216, tt:5134.897\n",
      "Ep:254, loss:0.00000, loss_test:0.06763, lr:2.52e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.219, tt:5155.855\n",
      "Ep:255, loss:0.00000, loss_test:0.06718, lr:2.50e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.220, tt:5176.238\n",
      "Ep:256, loss:0.00000, loss_test:0.06720, lr:2.47e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.222, tt:5197.064\n",
      "Ep:257, loss:0.00000, loss_test:0.06782, lr:2.45e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.221, tt:5217.048\n",
      "Ep:258, loss:0.00000, loss_test:0.06783, lr:2.42e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.214, tt:5235.536\n",
      "Ep:259, loss:0.00000, loss_test:0.06729, lr:2.40e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.213, tt:5255.393\n",
      "Ep:260, loss:0.00000, loss_test:0.06731, lr:2.38e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.206, tt:5273.863\n",
      "Ep:261, loss:0.00000, loss_test:0.06722, lr:2.35e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.205, tt:5293.725\n",
      "Ep:262, loss:0.00000, loss_test:0.06698, lr:2.33e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.205, tt:5313.895\n",
      "Ep:263, loss:0.00000, loss_test:0.06715, lr:2.31e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.198, tt:5332.271\n",
      "Ep:264, loss:0.00000, loss_test:0.06740, lr:2.28e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.201, tt:5353.266\n",
      "Ep:265, loss:0.00000, loss_test:0.06732, lr:2.26e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.201, tt:5373.412\n",
      "Ep:266, loss:0.00000, loss_test:0.06727, lr:2.24e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.194, tt:5391.752\n",
      "Ep:267, loss:0.00000, loss_test:0.06732, lr:2.21e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.185, tt:5409.712\n",
      "Ep:268, loss:0.00000, loss_test:0.06737, lr:2.19e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.184, tt:5429.514\n",
      "Ep:269, loss:0.00000, loss_test:0.06726, lr:2.17e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.181, tt:5448.854\n",
      "Ep:270, loss:0.00000, loss_test:0.06726, lr:2.15e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.182, tt:5469.195\n",
      "Ep:271, loss:0.00000, loss_test:0.06741, lr:2.13e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.184, tt:5490.133\n",
      "Ep:272, loss:0.00000, loss_test:0.06727, lr:2.11e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.186, tt:5510.854\n",
      "Ep:273, loss:0.00000, loss_test:0.06700, lr:2.08e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.183, tt:5530.244\n",
      "Ep:274, loss:0.00000, loss_test:0.06739, lr:2.06e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.182, tt:5550.066\n",
      "Ep:275, loss:0.00000, loss_test:0.06743, lr:2.04e-03, fs:0.81564 (r=0.737,p=0.912),  time:20.179, tt:5569.506\n",
      "Ep:276, loss:0.00000, loss_test:0.06713, lr:2.02e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.180, tt:5589.916\n",
      "Ep:277, loss:0.00000, loss_test:0.06716, lr:2.00e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.178, tt:5609.583\n",
      "Ep:278, loss:0.00000, loss_test:0.06716, lr:1.98e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.180, tt:5630.329\n",
      "Ep:279, loss:0.00000, loss_test:0.06717, lr:1.96e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.178, tt:5649.772\n",
      "Ep:280, loss:0.00000, loss_test:0.06719, lr:1.94e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.177, tt:5669.833\n",
      "Ep:281, loss:0.00000, loss_test:0.06722, lr:1.92e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.172, tt:5688.553\n",
      "Ep:282, loss:0.00000, loss_test:0.06723, lr:1.90e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.171, tt:5708.300\n",
      "Ep:283, loss:0.00000, loss_test:0.06694, lr:1.89e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.169, tt:5728.070\n",
      "Ep:284, loss:0.00000, loss_test:0.06723, lr:1.87e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.165, tt:5747.102\n",
      "Ep:285, loss:0.00000, loss_test:0.06718, lr:1.85e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.166, tt:5767.573\n",
      "Ep:286, loss:0.00000, loss_test:0.06716, lr:1.83e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.163, tt:5786.684\n",
      "Ep:287, loss:0.00000, loss_test:0.06728, lr:1.81e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.161, tt:5806.401\n",
      "Ep:288, loss:0.00000, loss_test:0.06750, lr:1.79e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.161, tt:5826.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:289, loss:0.00000, loss_test:0.06738, lr:1.78e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.163, tt:5847.181\n",
      "Ep:290, loss:0.00000, loss_test:0.06734, lr:1.76e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.164, tt:5867.777\n",
      "Ep:291, loss:0.00000, loss_test:0.06717, lr:1.74e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.166, tt:5888.433\n",
      "Ep:292, loss:0.00000, loss_test:0.06699, lr:1.72e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.173, tt:5910.769\n",
      "Ep:293, loss:0.00000, loss_test:0.06704, lr:1.71e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.176, tt:5931.851\n",
      "Ep:294, loss:0.00000, loss_test:0.06722, lr:1.69e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.170, tt:5950.178\n",
      "Ep:295, loss:0.00000, loss_test:0.06710, lr:1.67e-03, fs:0.83516 (r=0.768,p=0.916),  time:20.136, tt:5960.133\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14232, lr:1.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:17.176, tt:17.176\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14136, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:17.958, tt:35.917\n",
      "Ep:2, loss:0.00004, loss_test:0.13993, lr:1.00e-02, fs:0.64561 (r=0.929,p=0.495),  time:17.410, tt:52.231\n",
      "Ep:3, loss:0.00004, loss_test:0.13812, lr:1.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:17.317, tt:69.270\n",
      "Ep:4, loss:0.00004, loss_test:0.13601, lr:1.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:17.373, tt:86.865\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.13391, lr:1.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:17.278, tt:103.667\n",
      "Ep:6, loss:0.00004, loss_test:0.13323, lr:1.00e-02, fs:0.64730 (r=0.788,p=0.549),  time:17.467, tt:122.272\n",
      "Ep:7, loss:0.00003, loss_test:0.13324, lr:1.00e-02, fs:0.64167 (r=0.778,p=0.546),  time:17.504, tt:140.034\n",
      "Ep:8, loss:0.00003, loss_test:0.13288, lr:1.00e-02, fs:0.65236 (r=0.768,p=0.567),  time:17.502, tt:157.514\n",
      "Ep:9, loss:0.00003, loss_test:0.13221, lr:1.00e-02, fs:0.64935 (r=0.758,p=0.568),  time:17.557, tt:175.569\n",
      "Ep:10, loss:0.00003, loss_test:0.13126, lr:1.00e-02, fs:0.63158 (r=0.727,p=0.558),  time:17.470, tt:192.168\n",
      "Ep:11, loss:0.00003, loss_test:0.13027, lr:1.00e-02, fs:0.62281 (r=0.717,p=0.550),  time:17.402, tt:208.824\n",
      "Ep:12, loss:0.00003, loss_test:0.12893, lr:1.00e-02, fs:0.61607 (r=0.697,p=0.552),  time:17.397, tt:226.166\n",
      "Ep:13, loss:0.00003, loss_test:0.12741, lr:1.00e-02, fs:0.61607 (r=0.697,p=0.552),  time:17.408, tt:243.715\n",
      "Ep:14, loss:0.00003, loss_test:0.12581, lr:1.00e-02, fs:0.61538 (r=0.687,p=0.557),  time:17.440, tt:261.595\n",
      "Ep:15, loss:0.00003, loss_test:0.12455, lr:1.00e-02, fs:0.61395 (r=0.667,p=0.569),  time:17.419, tt:278.698\n",
      "Ep:16, loss:0.00003, loss_test:0.12351, lr:9.90e-03, fs:0.61682 (r=0.667,p=0.574),  time:17.425, tt:296.225\n",
      "Ep:17, loss:0.00003, loss_test:0.12279, lr:9.80e-03, fs:0.60577 (r=0.636,p=0.578),  time:17.381, tt:312.852\n",
      "Ep:18, loss:0.00003, loss_test:0.12214, lr:9.70e-03, fs:0.60952 (r=0.646,p=0.577),  time:17.359, tt:329.823\n",
      "Ep:19, loss:0.00003, loss_test:0.12121, lr:9.61e-03, fs:0.60577 (r=0.636,p=0.578),  time:17.397, tt:347.947\n",
      "Ep:20, loss:0.00003, loss_test:0.12014, lr:9.51e-03, fs:0.61165 (r=0.636,p=0.589),  time:17.389, tt:365.178\n",
      "Ep:21, loss:0.00003, loss_test:0.11881, lr:9.41e-03, fs:0.60488 (r=0.626,p=0.585),  time:17.429, tt:383.441\n",
      "Ep:22, loss:0.00003, loss_test:0.11728, lr:9.32e-03, fs:0.61765 (r=0.636,p=0.600),  time:17.407, tt:400.355\n",
      "Ep:23, loss:0.00003, loss_test:0.11584, lr:9.23e-03, fs:0.61084 (r=0.626,p=0.596),  time:17.413, tt:417.902\n",
      "Ep:24, loss:0.00003, loss_test:0.11481, lr:9.14e-03, fs:0.60396 (r=0.616,p=0.592),  time:17.542, tt:438.543\n",
      "Ep:25, loss:0.00002, loss_test:0.11407, lr:9.04e-03, fs:0.61084 (r=0.626,p=0.596),  time:17.531, tt:455.810\n",
      "Ep:26, loss:0.00002, loss_test:0.11337, lr:8.95e-03, fs:0.62069 (r=0.636,p=0.606),  time:17.613, tt:475.549\n",
      "Ep:27, loss:0.00002, loss_test:0.11256, lr:8.86e-03, fs:0.61000 (r=0.616,p=0.604),  time:17.595, tt:492.648\n",
      "Ep:28, loss:0.00002, loss_test:0.11161, lr:8.78e-03, fs:0.62000 (r=0.626,p=0.614),  time:17.589, tt:510.079\n",
      "Ep:29, loss:0.00002, loss_test:0.11074, lr:8.69e-03, fs:0.63366 (r=0.646,p=0.621),  time:17.615, tt:528.446\n",
      "Ep:30, loss:0.00002, loss_test:0.10978, lr:8.60e-03, fs:0.65366 (r=0.677,p=0.632),  time:17.596, tt:545.482\n",
      "Ep:31, loss:0.00002, loss_test:0.10884, lr:8.51e-03, fs:0.66010 (r=0.677,p=0.644),  time:17.622, tt:563.893\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.10805, lr:8.51e-03, fs:0.66337 (r=0.677,p=0.650),  time:17.644, tt:582.262\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10748, lr:8.51e-03, fs:0.66667 (r=0.677,p=0.657),  time:17.644, tt:599.904\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.10713, lr:8.51e-03, fs:0.67662 (r=0.687,p=0.667),  time:17.692, tt:619.206\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.10665, lr:8.51e-03, fs:0.68000 (r=0.687,p=0.673),  time:17.723, tt:638.022\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.10592, lr:8.51e-03, fs:0.67000 (r=0.677,p=0.663),  time:17.720, tt:655.637\n",
      "Ep:37, loss:0.00002, loss_test:0.10505, lr:8.51e-03, fs:0.67000 (r=0.677,p=0.663),  time:17.748, tt:674.416\n",
      "Ep:38, loss:0.00002, loss_test:0.10433, lr:8.51e-03, fs:0.68317 (r=0.697,p=0.670),  time:17.742, tt:691.920\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.10388, lr:8.51e-03, fs:0.68657 (r=0.697,p=0.676),  time:17.783, tt:711.307\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10355, lr:8.51e-03, fs:0.68657 (r=0.697,p=0.676),  time:17.795, tt:729.595\n",
      "Ep:41, loss:0.00002, loss_test:0.10306, lr:8.51e-03, fs:0.67692 (r=0.667,p=0.688),  time:17.821, tt:748.491\n",
      "Ep:42, loss:0.00002, loss_test:0.10246, lr:8.51e-03, fs:0.67692 (r=0.667,p=0.688),  time:17.838, tt:767.018\n",
      "Ep:43, loss:0.00002, loss_test:0.10187, lr:8.51e-03, fs:0.70707 (r=0.707,p=0.707),  time:17.853, tt:785.549\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.10146, lr:8.51e-03, fs:0.71000 (r=0.717,p=0.703),  time:17.889, tt:804.992\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.10106, lr:8.51e-03, fs:0.71357 (r=0.717,p=0.710),  time:17.905, tt:823.634\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.10054, lr:8.51e-03, fs:0.70707 (r=0.707,p=0.707),  time:17.934, tt:842.875\n",
      "Ep:47, loss:0.00002, loss_test:0.09989, lr:8.51e-03, fs:0.71357 (r=0.717,p=0.710),  time:17.956, tt:861.906\n",
      "Ep:48, loss:0.00002, loss_test:0.09910, lr:8.51e-03, fs:0.72637 (r=0.737,p=0.716),  time:17.967, tt:880.374\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.09821, lr:8.51e-03, fs:0.72637 (r=0.737,p=0.716),  time:17.971, tt:898.552\n",
      "Ep:50, loss:0.00002, loss_test:0.09745, lr:8.51e-03, fs:0.72000 (r=0.727,p=0.713),  time:17.981, tt:917.007\n",
      "Ep:51, loss:0.00002, loss_test:0.09699, lr:8.51e-03, fs:0.72727 (r=0.727,p=0.727),  time:18.003, tt:936.166\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.09658, lr:8.51e-03, fs:0.72081 (r=0.717,p=0.724),  time:18.023, tt:955.227\n",
      "Ep:53, loss:0.00002, loss_test:0.09617, lr:8.51e-03, fs:0.73096 (r=0.727,p=0.735),  time:18.028, tt:973.515\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.09587, lr:8.51e-03, fs:0.73469 (r=0.727,p=0.742),  time:18.029, tt:991.614\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.09567, lr:8.51e-03, fs:0.73469 (r=0.727,p=0.742),  time:18.055, tt:1011.094\n",
      "Ep:56, loss:0.00001, loss_test:0.09562, lr:8.51e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.081, tt:1030.612\n",
      "Ep:57, loss:0.00001, loss_test:0.09542, lr:8.51e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.088, tt:1049.130\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.09504, lr:8.51e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.095, tt:1067.610\n",
      "Ep:59, loss:0.00001, loss_test:0.09472, lr:8.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:18.116, tt:1086.962\n",
      "Ep:60, loss:0.00001, loss_test:0.09445, lr:8.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:18.140, tt:1106.547\n",
      "Ep:61, loss:0.00001, loss_test:0.09411, lr:8.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:18.156, tt:1125.690\n",
      "Ep:62, loss:0.00001, loss_test:0.09356, lr:8.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:18.178, tt:1145.205\n",
      "Ep:63, loss:0.00001, loss_test:0.09323, lr:8.51e-03, fs:0.72917 (r=0.707,p=0.753),  time:18.185, tt:1163.810\n",
      "Ep:64, loss:0.00001, loss_test:0.09293, lr:8.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.163, tt:1180.624\n",
      "Ep:65, loss:0.00001, loss_test:0.09225, lr:8.51e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.159, tt:1198.492\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.09173, lr:8.51e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.171, tt:1217.471\n",
      "Ep:67, loss:0.00001, loss_test:0.09146, lr:8.51e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.168, tt:1235.433\n",
      "Ep:68, loss:0.00001, loss_test:0.09127, lr:8.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.193, tt:1255.300\n",
      "Ep:69, loss:0.00001, loss_test:0.09090, lr:8.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.204, tt:1274.280\n",
      "Ep:70, loss:0.00001, loss_test:0.09056, lr:8.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.214, tt:1293.199\n",
      "Ep:71, loss:0.00001, loss_test:0.09019, lr:8.51e-03, fs:0.73016 (r=0.697,p=0.767),  time:18.242, tt:1313.393\n",
      "Ep:72, loss:0.00001, loss_test:0.08983, lr:8.51e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.253, tt:1332.488\n",
      "Ep:73, loss:0.00001, loss_test:0.08951, lr:8.51e-03, fs:0.73404 (r=0.697,p=0.775),  time:18.252, tt:1350.624\n",
      "Ep:74, loss:0.00001, loss_test:0.08926, lr:8.51e-03, fs:0.73404 (r=0.697,p=0.775),  time:18.255, tt:1369.132\n",
      "Ep:75, loss:0.00001, loss_test:0.08886, lr:8.51e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.270, tt:1388.503\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.08868, lr:8.51e-03, fs:0.73404 (r=0.697,p=0.775),  time:18.251, tt:1405.290\n",
      "Ep:77, loss:0.00001, loss_test:0.08804, lr:8.51e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.236, tt:1422.409\n",
      "Ep:78, loss:0.00001, loss_test:0.08789, lr:8.51e-03, fs:0.73404 (r=0.697,p=0.775),  time:18.234, tt:1440.472\n",
      "Ep:79, loss:0.00001, loss_test:0.08726, lr:8.51e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.229, tt:1458.355\n",
      "Ep:80, loss:0.00001, loss_test:0.08673, lr:8.51e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.219, tt:1475.770\n",
      "Ep:81, loss:0.00001, loss_test:0.08688, lr:8.51e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.210, tt:1493.206\n",
      "Ep:82, loss:0.00001, loss_test:0.08634, lr:8.51e-03, fs:0.73684 (r=0.707,p=0.769),  time:18.210, tt:1511.465\n",
      "Ep:83, loss:0.00001, loss_test:0.08624, lr:8.51e-03, fs:0.72727 (r=0.687,p=0.773),  time:18.206, tt:1529.280\n",
      "Ep:84, loss:0.00001, loss_test:0.08579, lr:8.51e-03, fs:0.74468 (r=0.707,p=0.787),  time:18.196, tt:1546.647\n",
      "Ep:85, loss:0.00001, loss_test:0.08580, lr:8.51e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.188, tt:1564.125\n",
      "Ep:86, loss:0.00001, loss_test:0.08498, lr:8.51e-03, fs:0.74866 (r=0.707,p=0.795),  time:18.192, tt:1582.724\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.08444, lr:8.51e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.192, tt:1600.917\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.08508, lr:8.51e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.176, tt:1617.677\n",
      "Ep:89, loss:0.00001, loss_test:0.08442, lr:8.51e-03, fs:0.75132 (r=0.717,p=0.789),  time:18.184, tt:1636.584\n",
      "Ep:90, loss:0.00001, loss_test:0.08383, lr:8.51e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.189, tt:1655.221\n",
      "Ep:91, loss:0.00001, loss_test:0.08358, lr:8.51e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.188, tt:1673.254\n",
      "Ep:92, loss:0.00001, loss_test:0.08410, lr:8.51e-03, fs:0.73224 (r=0.677,p=0.798),  time:18.191, tt:1691.761\n",
      "Ep:93, loss:0.00001, loss_test:0.08320, lr:8.51e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.189, tt:1709.761\n",
      "Ep:94, loss:0.00001, loss_test:0.08222, lr:8.51e-03, fs:0.75132 (r=0.717,p=0.789),  time:18.186, tt:1727.632\n",
      "Ep:95, loss:0.00001, loss_test:0.08343, lr:8.51e-03, fs:0.73913 (r=0.687,p=0.800),  time:18.186, tt:1745.831\n",
      "Ep:96, loss:0.00001, loss_test:0.08365, lr:8.51e-03, fs:0.72527 (r=0.667,p=0.795),  time:18.188, tt:1764.279\n",
      "Ep:97, loss:0.00001, loss_test:0.08196, lr:8.51e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.191, tt:1782.728\n",
      "Ep:98, loss:0.00001, loss_test:0.08145, lr:8.51e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.186, tt:1800.375\n",
      "Ep:99, loss:0.00001, loss_test:0.08279, lr:8.43e-03, fs:0.72826 (r=0.677,p=0.788),  time:18.185, tt:1818.486\n",
      "Ep:100, loss:0.00001, loss_test:0.08228, lr:8.35e-03, fs:0.73224 (r=0.677,p=0.798),  time:18.184, tt:1836.626\n",
      "Ep:101, loss:0.00001, loss_test:0.08129, lr:8.26e-03, fs:0.75393 (r=0.727,p=0.783),  time:18.174, tt:1853.789\n",
      "Ep:102, loss:0.00001, loss_test:0.08320, lr:8.18e-03, fs:0.71910 (r=0.646,p=0.810),  time:18.171, tt:1871.602\n",
      "Ep:103, loss:0.00001, loss_test:0.08242, lr:8.10e-03, fs:0.73514 (r=0.687,p=0.791),  time:18.166, tt:1889.282\n",
      "Ep:104, loss:0.00001, loss_test:0.08031, lr:8.02e-03, fs:0.75132 (r=0.717,p=0.789),  time:18.147, tt:1905.468\n",
      "Ep:105, loss:0.00001, loss_test:0.08133, lr:7.94e-03, fs:0.71823 (r=0.657,p=0.793),  time:18.149, tt:1923.774\n",
      "Ep:106, loss:0.00001, loss_test:0.08203, lr:7.86e-03, fs:0.73118 (r=0.687,p=0.782),  time:18.148, tt:1941.881\n",
      "Ep:107, loss:0.00001, loss_test:0.08128, lr:7.78e-03, fs:0.72527 (r=0.667,p=0.795),  time:18.146, tt:1959.796\n",
      "Ep:108, loss:0.00001, loss_test:0.07913, lr:7.70e-03, fs:0.73626 (r=0.677,p=0.807),  time:18.137, tt:1976.927\n",
      "Ep:109, loss:0.00001, loss_test:0.08013, lr:7.62e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.141, tt:1995.525\n",
      "Ep:110, loss:0.00001, loss_test:0.08210, lr:7.55e-03, fs:0.72527 (r=0.667,p=0.795),  time:18.141, tt:2013.634\n",
      "Ep:111, loss:0.00001, loss_test:0.08039, lr:7.47e-03, fs:0.71823 (r=0.657,p=0.793),  time:18.141, tt:2031.776\n",
      "Ep:112, loss:0.00001, loss_test:0.07817, lr:7.40e-03, fs:0.77083 (r=0.747,p=0.796),  time:18.138, tt:2049.543\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00001, loss_test:0.07938, lr:7.40e-03, fs:0.72527 (r=0.667,p=0.795),  time:18.134, tt:2067.300\n",
      "Ep:114, loss:0.00001, loss_test:0.08023, lr:7.40e-03, fs:0.72928 (r=0.667,p=0.805),  time:18.140, tt:2086.099\n",
      "Ep:115, loss:0.00001, loss_test:0.07892, lr:7.40e-03, fs:0.73224 (r=0.677,p=0.798),  time:18.138, tt:2103.966\n",
      "Ep:116, loss:0.00001, loss_test:0.07765, lr:7.40e-03, fs:0.75000 (r=0.697,p=0.812),  time:18.138, tt:2122.170\n",
      "Ep:117, loss:0.00001, loss_test:0.07901, lr:7.40e-03, fs:0.72527 (r=0.667,p=0.795),  time:18.134, tt:2139.813\n",
      "Ep:118, loss:0.00001, loss_test:0.07886, lr:7.40e-03, fs:0.72527 (r=0.667,p=0.795),  time:18.141, tt:2158.743\n",
      "Ep:119, loss:0.00001, loss_test:0.07665, lr:7.40e-03, fs:0.75936 (r=0.717,p=0.807),  time:18.127, tt:2175.233\n",
      "Ep:120, loss:0.00001, loss_test:0.07766, lr:7.40e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.121, tt:2192.684\n",
      "Ep:121, loss:0.00001, loss_test:0.07799, lr:7.40e-03, fs:0.72928 (r=0.667,p=0.805),  time:18.117, tt:2210.226\n",
      "Ep:122, loss:0.00001, loss_test:0.07653, lr:7.40e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.114, tt:2228.061\n",
      "Ep:123, loss:0.00001, loss_test:0.07670, lr:7.40e-03, fs:0.75532 (r=0.717,p=0.798),  time:18.114, tt:2246.149\n",
      "Ep:124, loss:0.00001, loss_test:0.07821, lr:7.32e-03, fs:0.72222 (r=0.657,p=0.802),  time:18.110, tt:2263.775\n",
      "Ep:125, loss:0.00001, loss_test:0.07782, lr:7.25e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.117, tt:2282.701\n",
      "Ep:126, loss:0.00001, loss_test:0.07563, lr:7.18e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.117, tt:2300.810\n",
      "Ep:127, loss:0.00001, loss_test:0.07596, lr:7.11e-03, fs:0.72222 (r=0.657,p=0.802),  time:18.120, tt:2319.413\n",
      "Ep:128, loss:0.00001, loss_test:0.07884, lr:7.03e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.121, tt:2337.584\n",
      "Ep:129, loss:0.00001, loss_test:0.07941, lr:6.96e-03, fs:0.73333 (r=0.667,p=0.815),  time:18.115, tt:2354.915\n",
      "Ep:130, loss:0.00001, loss_test:0.07613, lr:6.89e-03, fs:0.72222 (r=0.657,p=0.802),  time:18.110, tt:2372.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.07390, lr:6.83e-03, fs:0.78125 (r=0.758,p=0.806),  time:18.114, tt:2391.021\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00001, loss_test:0.07693, lr:6.83e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.112, tt:2408.918\n",
      "Ep:133, loss:0.00001, loss_test:0.07852, lr:6.83e-03, fs:0.71910 (r=0.646,p=0.810),  time:18.116, tt:2427.569\n",
      "Ep:134, loss:0.00001, loss_test:0.07532, lr:6.83e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.121, tt:2446.344\n",
      "Ep:135, loss:0.00001, loss_test:0.07319, lr:6.83e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.126, tt:2465.099\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.07565, lr:6.83e-03, fs:0.72626 (r=0.657,p=0.812),  time:18.128, tt:2483.510\n",
      "Ep:137, loss:0.00001, loss_test:0.07680, lr:6.83e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.126, tt:2501.369\n",
      "Ep:138, loss:0.00001, loss_test:0.07433, lr:6.83e-03, fs:0.76503 (r=0.707,p=0.833),  time:18.134, tt:2520.660\n",
      "Ep:139, loss:0.00001, loss_test:0.07257, lr:6.83e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.140, tt:2539.576\n",
      "Ep:140, loss:0.00001, loss_test:0.07475, lr:6.83e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.135, tt:2557.014\n",
      "Ep:141, loss:0.00001, loss_test:0.07628, lr:6.83e-03, fs:0.72626 (r=0.657,p=0.812),  time:18.142, tt:2576.112\n",
      "Ep:142, loss:0.00001, loss_test:0.07395, lr:6.83e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.147, tt:2595.072\n",
      "Ep:143, loss:0.00001, loss_test:0.07238, lr:6.83e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.142, tt:2612.463\n",
      "Ep:144, loss:0.00001, loss_test:0.07456, lr:6.83e-03, fs:0.73333 (r=0.667,p=0.815),  time:18.148, tt:2631.393\n",
      "Ep:145, loss:0.00000, loss_test:0.07511, lr:6.83e-03, fs:0.76087 (r=0.707,p=0.824),  time:18.149, tt:2649.804\n",
      "Ep:146, loss:0.00000, loss_test:0.07351, lr:6.83e-03, fs:0.75676 (r=0.707,p=0.814),  time:18.160, tt:2669.571\n",
      "Ep:147, loss:0.00000, loss_test:0.07211, lr:6.76e-03, fs:0.76087 (r=0.707,p=0.824),  time:18.164, tt:2688.259\n",
      "Ep:148, loss:0.00000, loss_test:0.07405, lr:6.69e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.168, tt:2707.004\n",
      "Ep:149, loss:0.00001, loss_test:0.07587, lr:6.62e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.163, tt:2724.430\n",
      "Ep:150, loss:0.00000, loss_test:0.07440, lr:6.56e-03, fs:0.73446 (r=0.657,p=0.833),  time:18.170, tt:2743.698\n",
      "Ep:151, loss:0.00000, loss_test:0.07269, lr:6.49e-03, fs:0.78571 (r=0.778,p=0.794),  time:18.175, tt:2762.627\n",
      "Ep:152, loss:0.00001, loss_test:0.07341, lr:6.43e-03, fs:0.73743 (r=0.667,p=0.825),  time:18.183, tt:2782.009\n",
      "Ep:153, loss:0.00000, loss_test:0.07508, lr:6.36e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.189, tt:2801.068\n",
      "Ep:154, loss:0.00001, loss_test:0.07386, lr:6.30e-03, fs:0.77487 (r=0.747,p=0.804),  time:18.194, tt:2820.115\n",
      "Ep:155, loss:0.00001, loss_test:0.07309, lr:6.24e-03, fs:0.77660 (r=0.737,p=0.820),  time:18.203, tt:2839.678\n",
      "Ep:156, loss:0.00000, loss_test:0.07379, lr:6.17e-03, fs:0.72222 (r=0.657,p=0.802),  time:18.213, tt:2859.447\n",
      "Ep:157, loss:0.00001, loss_test:0.07279, lr:6.11e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.218, tt:2878.398\n",
      "Ep:158, loss:0.00000, loss_test:0.07323, lr:6.05e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.228, tt:2898.288\n",
      "Ep:159, loss:0.00000, loss_test:0.07381, lr:5.99e-03, fs:0.73446 (r=0.657,p=0.833),  time:18.237, tt:2917.876\n",
      "Ep:160, loss:0.00000, loss_test:0.07370, lr:5.93e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.243, tt:2937.066\n",
      "Ep:161, loss:0.00000, loss_test:0.07291, lr:5.87e-03, fs:0.77720 (r=0.758,p=0.798),  time:18.248, tt:2956.205\n",
      "Ep:162, loss:0.00000, loss_test:0.07249, lr:5.81e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.253, tt:2975.204\n",
      "Ep:163, loss:0.00000, loss_test:0.07292, lr:5.75e-03, fs:0.73446 (r=0.657,p=0.833),  time:18.259, tt:2994.551\n",
      "Ep:164, loss:0.00000, loss_test:0.07243, lr:5.70e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.261, tt:3012.995\n",
      "Ep:165, loss:0.00000, loss_test:0.07200, lr:5.64e-03, fs:0.78307 (r=0.747,p=0.822),  time:18.263, tt:3031.622\n",
      "Ep:166, loss:0.00000, loss_test:0.07172, lr:5.58e-03, fs:0.75556 (r=0.687,p=0.840),  time:18.269, tt:3050.874\n",
      "Ep:167, loss:0.00000, loss_test:0.07202, lr:5.53e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.280, tt:3071.102\n",
      "Ep:168, loss:0.00000, loss_test:0.07180, lr:5.47e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.291, tt:3091.141\n",
      "Ep:169, loss:0.00000, loss_test:0.07154, lr:5.42e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.298, tt:3110.608\n",
      "Ep:170, loss:0.00000, loss_test:0.07133, lr:5.36e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.299, tt:3129.210\n",
      "Ep:171, loss:0.00000, loss_test:0.07147, lr:5.31e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.298, tt:3147.273\n",
      "Ep:172, loss:0.00000, loss_test:0.07111, lr:5.26e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.303, tt:3166.455\n",
      "Ep:173, loss:0.00000, loss_test:0.07073, lr:5.20e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.303, tt:3184.650\n",
      "Ep:174, loss:0.00000, loss_test:0.07174, lr:5.15e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.305, tt:3203.353\n",
      "Ep:175, loss:0.00000, loss_test:0.07174, lr:5.10e-03, fs:0.75410 (r=0.697,p=0.821),  time:18.308, tt:3222.181\n",
      "Ep:176, loss:0.00000, loss_test:0.07045, lr:5.05e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.315, tt:3241.750\n",
      "Ep:177, loss:0.00000, loss_test:0.07026, lr:5.00e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.320, tt:3260.965\n",
      "Ep:178, loss:0.00000, loss_test:0.07120, lr:4.95e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.323, tt:3279.793\n",
      "Ep:179, loss:0.00000, loss_test:0.07107, lr:4.90e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.323, tt:3298.051\n",
      "Ep:180, loss:0.00000, loss_test:0.07043, lr:4.85e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.331, tt:3317.826\n",
      "Ep:181, loss:0.00000, loss_test:0.07077, lr:4.80e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.337, tt:3337.361\n",
      "Ep:182, loss:0.00000, loss_test:0.07061, lr:4.75e-03, fs:0.77174 (r=0.717,p=0.835),  time:18.341, tt:3356.434\n",
      "Ep:183, loss:0.00000, loss_test:0.06993, lr:4.71e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.352, tt:3376.689\n",
      "Ep:184, loss:0.00000, loss_test:0.07051, lr:4.66e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.357, tt:3396.016\n",
      "Ep:185, loss:0.00000, loss_test:0.07050, lr:4.61e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.361, tt:3415.115\n",
      "Ep:186, loss:0.00000, loss_test:0.06967, lr:4.57e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.370, tt:3435.269\n",
      "Ep:187, loss:0.00000, loss_test:0.06992, lr:4.52e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.374, tt:3454.373\n",
      "Ep:188, loss:0.00000, loss_test:0.07079, lr:4.48e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.376, tt:3473.084\n",
      "Ep:189, loss:0.00000, loss_test:0.07046, lr:4.43e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.378, tt:3491.791\n",
      "Ep:190, loss:0.00000, loss_test:0.06998, lr:4.39e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.386, tt:3511.634\n",
      "Ep:191, loss:0.00000, loss_test:0.07058, lr:4.34e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.400, tt:3532.741\n",
      "Ep:192, loss:0.00000, loss_test:0.07066, lr:4.30e-03, fs:0.74860 (r=0.677,p=0.838),  time:18.404, tt:3551.981\n",
      "Ep:193, loss:0.00000, loss_test:0.06973, lr:4.26e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.407, tt:3570.923\n",
      "Ep:194, loss:0.00000, loss_test:0.06933, lr:4.21e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.407, tt:3589.402\n",
      "Ep:195, loss:0.00000, loss_test:0.06993, lr:4.17e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.409, tt:3608.229\n",
      "Ep:196, loss:0.00000, loss_test:0.07011, lr:4.13e-03, fs:0.75978 (r=0.687,p=0.850),  time:18.413, tt:3627.460\n",
      "Ep:197, loss:0.00000, loss_test:0.06953, lr:4.09e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.421, tt:3647.399\n",
      "Ep:198, loss:0.00000, loss_test:0.06901, lr:4.05e-03, fs:0.78075 (r=0.737,p=0.830),  time:18.429, tt:3667.434\n",
      "Ep:199, loss:0.00000, loss_test:0.06932, lr:4.01e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.434, tt:3686.795\n",
      "Ep:200, loss:0.00000, loss_test:0.06967, lr:3.97e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.434, tt:3705.205\n",
      "Ep:201, loss:0.00000, loss_test:0.06942, lr:3.93e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.437, tt:3724.273\n",
      "Ep:202, loss:0.00000, loss_test:0.06891, lr:3.89e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.441, tt:3743.584\n",
      "##########Best model found so far##########\n",
      "Ep:203, loss:0.00000, loss_test:0.06904, lr:3.89e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.451, tt:3763.981\n",
      "Ep:204, loss:0.00000, loss_test:0.06939, lr:3.89e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.453, tt:3782.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.06956, lr:3.89e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.458, tt:3802.370\n",
      "Ep:206, loss:0.00000, loss_test:0.06931, lr:3.89e-03, fs:0.77348 (r=0.707,p=0.854),  time:18.466, tt:3822.434\n",
      "Ep:207, loss:0.00000, loss_test:0.06872, lr:3.89e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.468, tt:3841.386\n",
      "Ep:208, loss:0.00000, loss_test:0.06928, lr:3.89e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.472, tt:3860.558\n",
      "Ep:209, loss:0.00000, loss_test:0.06978, lr:3.89e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.472, tt:3879.140\n",
      "Ep:210, loss:0.00000, loss_test:0.06950, lr:3.89e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.476, tt:3898.449\n",
      "Ep:211, loss:0.00000, loss_test:0.06844, lr:3.89e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.482, tt:3918.133\n",
      "Ep:212, loss:0.00000, loss_test:0.06871, lr:3.89e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.482, tt:3936.643\n",
      "Ep:213, loss:0.00000, loss_test:0.06909, lr:3.89e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.478, tt:3954.199\n",
      "Ep:214, loss:0.00000, loss_test:0.06883, lr:3.85e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.480, tt:3973.262\n",
      "Ep:215, loss:0.00000, loss_test:0.06863, lr:3.81e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.482, tt:3992.133\n",
      "Ep:216, loss:0.00000, loss_test:0.06914, lr:3.77e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.484, tt:4010.992\n",
      "Ep:217, loss:0.00000, loss_test:0.06880, lr:3.73e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.486, tt:4029.983\n",
      "Ep:218, loss:0.00000, loss_test:0.06814, lr:3.70e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.484, tt:4048.019\n",
      "Ep:219, loss:0.00000, loss_test:0.06813, lr:3.66e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.488, tt:4067.330\n",
      "##########Best model found so far##########\n",
      "Ep:220, loss:0.00000, loss_test:0.06899, lr:3.66e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.495, tt:4087.310\n",
      "Ep:221, loss:0.00000, loss_test:0.06902, lr:3.66e-03, fs:0.78495 (r=0.737,p=0.839),  time:18.494, tt:4105.700\n",
      "Ep:222, loss:0.00000, loss_test:0.06852, lr:3.66e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.499, tt:4125.197\n",
      "Ep:223, loss:0.00000, loss_test:0.06796, lr:3.66e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.497, tt:4143.228\n",
      "Ep:224, loss:0.00000, loss_test:0.06893, lr:3.66e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.501, tt:4162.794\n",
      "Ep:225, loss:0.00000, loss_test:0.06910, lr:3.66e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.511, tt:4183.541\n",
      "Ep:226, loss:0.00000, loss_test:0.06841, lr:3.66e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.511, tt:4202.083\n",
      "Ep:227, loss:0.00000, loss_test:0.06769, lr:3.66e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.509, tt:4220.072\n",
      "##########Best model found so far##########\n",
      "Ep:228, loss:0.00000, loss_test:0.06827, lr:3.66e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.512, tt:4239.185\n",
      "Ep:229, loss:0.00000, loss_test:0.06856, lr:3.66e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.514, tt:4258.213\n",
      "Ep:230, loss:0.00000, loss_test:0.06842, lr:3.66e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.515, tt:4276.938\n",
      "Ep:231, loss:0.00000, loss_test:0.06787, lr:3.66e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.516, tt:4295.804\n",
      "Ep:232, loss:0.00000, loss_test:0.06812, lr:3.66e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.521, tt:4315.471\n",
      "Ep:233, loss:0.00000, loss_test:0.06899, lr:3.66e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.527, tt:4335.429\n",
      "Ep:234, loss:0.00000, loss_test:0.06887, lr:3.66e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.530, tt:4354.528\n",
      "Ep:235, loss:0.00000, loss_test:0.06791, lr:3.66e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.532, tt:4373.524\n",
      "Ep:236, loss:0.00000, loss_test:0.06738, lr:3.66e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.534, tt:4392.503\n",
      "Ep:237, loss:0.00000, loss_test:0.06834, lr:3.66e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.534, tt:4411.158\n",
      "Ep:238, loss:0.00000, loss_test:0.06892, lr:3.66e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.540, tt:4431.082\n",
      "Ep:239, loss:0.00000, loss_test:0.06828, lr:3.62e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.540, tt:4449.612\n",
      "Ep:240, loss:0.00000, loss_test:0.06745, lr:3.59e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.540, tt:4468.147\n",
      "Ep:241, loss:0.00000, loss_test:0.06804, lr:3.55e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.539, tt:4486.385\n",
      "Ep:242, loss:0.00000, loss_test:0.06840, lr:3.52e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.532, tt:4503.189\n",
      "Ep:243, loss:0.00000, loss_test:0.06819, lr:3.48e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.533, tt:4521.971\n",
      "Ep:244, loss:0.00000, loss_test:0.06766, lr:3.45e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.526, tt:4538.966\n",
      "Ep:245, loss:0.00000, loss_test:0.06772, lr:3.41e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.527, tt:4557.757\n",
      "Ep:246, loss:0.00000, loss_test:0.06830, lr:3.38e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.528, tt:4576.348\n",
      "Ep:247, loss:0.00000, loss_test:0.06829, lr:3.34e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.525, tt:4594.183\n",
      "Ep:248, loss:0.00000, loss_test:0.06785, lr:3.31e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.524, tt:4612.434\n",
      "Ep:249, loss:0.00000, loss_test:0.06785, lr:3.28e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.520, tt:4629.917\n",
      "Ep:250, loss:0.00000, loss_test:0.06796, lr:3.24e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.512, tt:4646.480\n",
      "Ep:251, loss:0.00000, loss_test:0.06769, lr:3.21e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.504, tt:4663.124\n",
      "##########Best model found so far##########\n",
      "Ep:252, loss:0.00000, loss_test:0.06769, lr:3.21e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.496, tt:4679.536\n",
      "Ep:253, loss:0.00000, loss_test:0.06758, lr:3.21e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.488, tt:4695.826\n",
      "Ep:254, loss:0.00000, loss_test:0.06777, lr:3.21e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.479, tt:4712.218\n",
      "Ep:255, loss:0.00000, loss_test:0.06790, lr:3.21e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.475, tt:4729.622\n",
      "Ep:256, loss:0.00000, loss_test:0.06828, lr:3.21e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.478, tt:4748.843\n",
      "Ep:257, loss:0.00000, loss_test:0.06784, lr:3.21e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.476, tt:4766.682\n",
      "Ep:258, loss:0.00000, loss_test:0.06720, lr:3.21e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.475, tt:4784.925\n",
      "Ep:259, loss:0.00000, loss_test:0.06717, lr:3.21e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.477, tt:4804.061\n",
      "Ep:260, loss:0.00000, loss_test:0.06745, lr:3.21e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.475, tt:4821.992\n",
      "Ep:261, loss:0.00000, loss_test:0.06774, lr:3.21e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.475, tt:4840.522\n",
      "Ep:262, loss:0.00000, loss_test:0.06787, lr:3.21e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.476, tt:4859.193\n",
      "Ep:263, loss:0.00000, loss_test:0.06761, lr:3.18e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.477, tt:4877.908\n",
      "Ep:264, loss:0.00000, loss_test:0.06721, lr:3.15e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.477, tt:4896.346\n",
      "Ep:265, loss:0.00000, loss_test:0.06719, lr:3.12e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.482, tt:4916.241\n",
      "Ep:266, loss:0.00000, loss_test:0.06771, lr:3.09e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.482, tt:4934.813\n",
      "Ep:267, loss:0.00000, loss_test:0.06788, lr:3.05e-03, fs:0.76243 (r=0.697,p=0.841),  time:18.484, tt:4953.684\n",
      "Ep:268, loss:0.00000, loss_test:0.06722, lr:3.02e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.489, tt:4973.543\n",
      "Ep:269, loss:0.00000, loss_test:0.06688, lr:2.99e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.492, tt:4992.715\n",
      "Ep:270, loss:0.00000, loss_test:0.06727, lr:2.96e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.494, tt:5011.765\n",
      "Ep:271, loss:0.00000, loss_test:0.06749, lr:2.93e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.495, tt:5030.509\n",
      "Ep:272, loss:0.00000, loss_test:0.06720, lr:2.90e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.498, tt:5049.999\n",
      "Ep:273, loss:0.00000, loss_test:0.06698, lr:2.88e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.500, tt:5068.994\n",
      "Ep:274, loss:0.00000, loss_test:0.06741, lr:2.85e-03, fs:0.77174 (r=0.717,p=0.835),  time:18.503, tt:5088.365\n",
      "Ep:275, loss:0.00000, loss_test:0.06755, lr:2.82e-03, fs:0.78022 (r=0.717,p=0.855),  time:18.502, tt:5106.629\n",
      "Ep:276, loss:0.00000, loss_test:0.06737, lr:2.79e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.503, tt:5125.398\n",
      "Ep:277, loss:0.00000, loss_test:0.06706, lr:2.76e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.505, tt:5144.454\n",
      "Ep:278, loss:0.00000, loss_test:0.06687, lr:2.73e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.509, tt:5163.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:279, loss:0.00000, loss_test:0.06714, lr:2.71e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.510, tt:5182.859\n",
      "Ep:280, loss:0.00000, loss_test:0.06720, lr:2.68e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.511, tt:5201.453\n",
      "Ep:281, loss:0.00000, loss_test:0.06695, lr:2.65e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.514, tt:5221.087\n",
      "Ep:282, loss:0.00000, loss_test:0.06668, lr:2.63e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.518, tt:5240.690\n",
      "Ep:283, loss:0.00000, loss_test:0.06683, lr:2.60e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.516, tt:5258.606\n",
      "Ep:284, loss:0.00000, loss_test:0.06706, lr:2.57e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.518, tt:5277.773\n",
      "Ep:285, loss:0.00000, loss_test:0.06706, lr:2.55e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.522, tt:5297.241\n",
      "Ep:286, loss:0.00000, loss_test:0.06685, lr:2.52e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.524, tt:5316.472\n",
      "Ep:287, loss:0.00000, loss_test:0.06667, lr:2.50e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.524, tt:5334.910\n",
      "Ep:288, loss:0.00000, loss_test:0.06695, lr:2.47e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.527, tt:5354.201\n",
      "Ep:289, loss:0.00000, loss_test:0.06717, lr:2.45e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.528, tt:5373.237\n",
      "Ep:290, loss:0.00000, loss_test:0.06706, lr:2.42e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.531, tt:5392.399\n",
      "Ep:291, loss:0.00000, loss_test:0.06681, lr:2.40e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.535, tt:5412.183\n",
      "Ep:292, loss:0.00000, loss_test:0.06691, lr:2.38e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.530, tt:5429.184\n",
      "Ep:293, loss:0.00000, loss_test:0.06690, lr:2.35e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.520, tt:5444.824\n",
      "Ep:294, loss:0.00000, loss_test:0.06684, lr:2.33e-03, fs:0.78919 (r=0.737,p=0.849),  time:18.500, tt:5457.376\n",
      "Ep:295, loss:0.00000, loss_test:0.06673, lr:2.31e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.473, tt:5467.971\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13826, lr:1.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:7.177, tt:7.177\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13872, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:9.720, tt:19.440\n",
      "Ep:2, loss:0.00004, loss_test:0.13942, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:12.023, tt:36.070\n",
      "Ep:3, loss:0.00004, loss_test:0.14084, lr:1.00e-02, fs:0.63968 (r=0.798,p=0.534),  time:13.334, tt:53.338\n",
      "Ep:4, loss:0.00004, loss_test:0.14253, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:14.370, tt:71.848\n",
      "Ep:5, loss:0.00004, loss_test:0.14417, lr:1.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:15.078, tt:90.468\n",
      "Ep:6, loss:0.00004, loss_test:0.14562, lr:1.00e-02, fs:0.62551 (r=0.768,p=0.528),  time:15.487, tt:108.407\n",
      "Ep:7, loss:0.00004, loss_test:0.14669, lr:1.00e-02, fs:0.61983 (r=0.758,p=0.524),  time:15.839, tt:126.712\n",
      "Ep:8, loss:0.00004, loss_test:0.14721, lr:1.00e-02, fs:0.61983 (r=0.758,p=0.524),  time:16.071, tt:144.636\n",
      "Ep:9, loss:0.00004, loss_test:0.14719, lr:1.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:16.224, tt:162.240\n",
      "Ep:10, loss:0.00003, loss_test:0.14672, lr:1.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:16.319, tt:179.509\n",
      "Ep:11, loss:0.00003, loss_test:0.14603, lr:1.00e-02, fs:0.62241 (r=0.758,p=0.528),  time:16.435, tt:197.221\n",
      "Ep:12, loss:0.00003, loss_test:0.14518, lr:9.90e-03, fs:0.62810 (r=0.768,p=0.531),  time:16.484, tt:214.289\n",
      "Ep:13, loss:0.00003, loss_test:0.14426, lr:9.80e-03, fs:0.63934 (r=0.788,p=0.538),  time:16.566, tt:231.919\n",
      "Ep:14, loss:0.00003, loss_test:0.14335, lr:9.70e-03, fs:0.63934 (r=0.788,p=0.538),  time:16.674, tt:250.103\n",
      "Ep:15, loss:0.00003, loss_test:0.14274, lr:9.61e-03, fs:0.64198 (r=0.788,p=0.542),  time:16.756, tt:268.091\n",
      "Ep:16, loss:0.00003, loss_test:0.14230, lr:9.51e-03, fs:0.64198 (r=0.788,p=0.542),  time:16.779, tt:285.251\n",
      "Ep:17, loss:0.00003, loss_test:0.14205, lr:9.41e-03, fs:0.64198 (r=0.788,p=0.542),  time:16.821, tt:302.777\n",
      "Ep:18, loss:0.00003, loss_test:0.14208, lr:9.32e-03, fs:0.64198 (r=0.788,p=0.542),  time:16.905, tt:321.193\n",
      "Ep:19, loss:0.00003, loss_test:0.14233, lr:9.23e-03, fs:0.64198 (r=0.788,p=0.542),  time:17.011, tt:340.224\n",
      "Ep:20, loss:0.00003, loss_test:0.14252, lr:9.14e-03, fs:0.63071 (r=0.768,p=0.535),  time:17.104, tt:359.184\n",
      "Ep:21, loss:0.00003, loss_test:0.14255, lr:9.04e-03, fs:0.63071 (r=0.768,p=0.535),  time:17.172, tt:377.775\n",
      "Ep:22, loss:0.00003, loss_test:0.14236, lr:8.95e-03, fs:0.63333 (r=0.768,p=0.539),  time:17.214, tt:395.923\n",
      "Ep:23, loss:0.00003, loss_test:0.14194, lr:8.86e-03, fs:0.63333 (r=0.768,p=0.539),  time:17.302, tt:415.236\n",
      "Ep:24, loss:0.00003, loss_test:0.14130, lr:8.78e-03, fs:0.63333 (r=0.768,p=0.539),  time:17.383, tt:434.577\n",
      "Ep:25, loss:0.00003, loss_test:0.14049, lr:8.69e-03, fs:0.63333 (r=0.768,p=0.539),  time:17.419, tt:452.905\n",
      "Ep:26, loss:0.00003, loss_test:0.13963, lr:8.60e-03, fs:0.63071 (r=0.768,p=0.535),  time:17.486, tt:472.109\n",
      "Ep:27, loss:0.00003, loss_test:0.13878, lr:8.51e-03, fs:0.63071 (r=0.768,p=0.535),  time:17.529, tt:490.811\n",
      "Ep:28, loss:0.00003, loss_test:0.13805, lr:8.43e-03, fs:0.63374 (r=0.778,p=0.535),  time:17.577, tt:509.739\n",
      "Ep:29, loss:0.00003, loss_test:0.13746, lr:8.35e-03, fs:0.63900 (r=0.778,p=0.542),  time:17.583, tt:527.481\n",
      "Ep:30, loss:0.00003, loss_test:0.13700, lr:8.26e-03, fs:0.63900 (r=0.778,p=0.542),  time:17.615, tt:546.065\n",
      "Ep:31, loss:0.00003, loss_test:0.13662, lr:8.18e-03, fs:0.63333 (r=0.768,p=0.539),  time:17.640, tt:564.479\n",
      "Ep:32, loss:0.00003, loss_test:0.13617, lr:8.10e-03, fs:0.62185 (r=0.747,p=0.532),  time:17.671, tt:583.127\n",
      "Ep:33, loss:0.00003, loss_test:0.13562, lr:8.02e-03, fs:0.62979 (r=0.747,p=0.544),  time:17.678, tt:601.065\n",
      "Ep:34, loss:0.00003, loss_test:0.13497, lr:7.94e-03, fs:0.62979 (r=0.747,p=0.544),  time:17.687, tt:619.043\n",
      "Ep:35, loss:0.00003, loss_test:0.13419, lr:7.86e-03, fs:0.62931 (r=0.737,p=0.549),  time:17.701, tt:637.220\n",
      "Ep:36, loss:0.00003, loss_test:0.13341, lr:7.78e-03, fs:0.62931 (r=0.737,p=0.549),  time:17.707, tt:655.169\n",
      "Ep:37, loss:0.00003, loss_test:0.13265, lr:7.70e-03, fs:0.63755 (r=0.737,p=0.562),  time:17.721, tt:673.411\n",
      "Ep:38, loss:0.00003, loss_test:0.13203, lr:7.62e-03, fs:0.65217 (r=0.758,p=0.573),  time:17.730, tt:691.452\n",
      "Ep:39, loss:0.00003, loss_test:0.13160, lr:7.55e-03, fs:0.64629 (r=0.747,p=0.569),  time:17.732, tt:709.299\n",
      "Ep:40, loss:0.00003, loss_test:0.13124, lr:7.47e-03, fs:0.63717 (r=0.727,p=0.567),  time:17.760, tt:728.155\n",
      "Ep:41, loss:0.00003, loss_test:0.13082, lr:7.40e-03, fs:0.64000 (r=0.727,p=0.571),  time:17.790, tt:747.174\n",
      "Ep:42, loss:0.00003, loss_test:0.13045, lr:7.32e-03, fs:0.64000 (r=0.727,p=0.571),  time:17.773, tt:764.222\n",
      "Ep:43, loss:0.00003, loss_test:0.13015, lr:7.25e-03, fs:0.63677 (r=0.717,p=0.573),  time:17.777, tt:782.204\n",
      "Ep:44, loss:0.00003, loss_test:0.12991, lr:7.18e-03, fs:0.63677 (r=0.717,p=0.573),  time:17.770, tt:799.667\n",
      "Ep:45, loss:0.00003, loss_test:0.12970, lr:7.11e-03, fs:0.63393 (r=0.717,p=0.568),  time:17.769, tt:817.393\n",
      "Ep:46, loss:0.00003, loss_test:0.12951, lr:7.03e-03, fs:0.63393 (r=0.717,p=0.568),  time:17.770, tt:835.172\n",
      "Ep:47, loss:0.00003, loss_test:0.12922, lr:6.96e-03, fs:0.63964 (r=0.717,p=0.577),  time:17.750, tt:851.988\n",
      "Ep:48, loss:0.00003, loss_test:0.12887, lr:6.89e-03, fs:0.63964 (r=0.717,p=0.577),  time:17.737, tt:869.119\n",
      "Ep:49, loss:0.00003, loss_test:0.12851, lr:6.83e-03, fs:0.63964 (r=0.717,p=0.577),  time:17.742, tt:887.107\n",
      "Ep:50, loss:0.00003, loss_test:0.12823, lr:6.76e-03, fs:0.63677 (r=0.717,p=0.573),  time:17.743, tt:904.891\n",
      "Ep:51, loss:0.00003, loss_test:0.12795, lr:6.69e-03, fs:0.63677 (r=0.717,p=0.573),  time:17.730, tt:921.937\n",
      "Ep:52, loss:0.00003, loss_test:0.12766, lr:6.62e-03, fs:0.63677 (r=0.717,p=0.573),  time:17.735, tt:939.948\n",
      "Ep:53, loss:0.00003, loss_test:0.12732, lr:6.56e-03, fs:0.63063 (r=0.707,p=0.569),  time:17.735, tt:957.668\n",
      "Ep:54, loss:0.00003, loss_test:0.12697, lr:6.49e-03, fs:0.63063 (r=0.707,p=0.569),  time:17.723, tt:974.768\n",
      "Ep:55, loss:0.00003, loss_test:0.12660, lr:6.43e-03, fs:0.63063 (r=0.707,p=0.569),  time:17.726, tt:992.664\n",
      "Ep:56, loss:0.00003, loss_test:0.12629, lr:6.36e-03, fs:0.63348 (r=0.707,p=0.574),  time:17.734, tt:1010.812\n",
      "Ep:57, loss:0.00003, loss_test:0.12602, lr:6.30e-03, fs:0.63348 (r=0.707,p=0.574),  time:17.753, tt:1029.659\n",
      "Ep:58, loss:0.00003, loss_test:0.12576, lr:6.24e-03, fs:0.63636 (r=0.707,p=0.579),  time:17.750, tt:1047.221\n",
      "Ep:59, loss:0.00003, loss_test:0.12547, lr:6.17e-03, fs:0.63636 (r=0.707,p=0.579),  time:17.725, tt:1063.494\n",
      "Ep:60, loss:0.00002, loss_test:0.12510, lr:6.11e-03, fs:0.63636 (r=0.707,p=0.579),  time:17.736, tt:1081.925\n",
      "Ep:61, loss:0.00002, loss_test:0.12462, lr:6.05e-03, fs:0.64220 (r=0.707,p=0.588),  time:17.732, tt:1099.383\n",
      "Ep:62, loss:0.00002, loss_test:0.12409, lr:5.99e-03, fs:0.64516 (r=0.707,p=0.593),  time:17.752, tt:1118.394\n",
      "Ep:63, loss:0.00002, loss_test:0.12359, lr:5.93e-03, fs:0.64516 (r=0.707,p=0.593),  time:17.781, tt:1137.959\n",
      "Ep:64, loss:0.00002, loss_test:0.12313, lr:5.87e-03, fs:0.64516 (r=0.707,p=0.593),  time:17.799, tt:1156.956\n",
      "Ep:65, loss:0.00002, loss_test:0.12271, lr:5.81e-03, fs:0.63594 (r=0.697,p=0.585),  time:17.821, tt:1176.170\n",
      "Ep:66, loss:0.00002, loss_test:0.12223, lr:5.75e-03, fs:0.63889 (r=0.697,p=0.590),  time:17.829, tt:1194.574\n",
      "Ep:67, loss:0.00002, loss_test:0.12174, lr:5.70e-03, fs:0.63256 (r=0.687,p=0.586),  time:17.857, tt:1214.288\n",
      "Ep:68, loss:0.00002, loss_test:0.12133, lr:5.64e-03, fs:0.63256 (r=0.687,p=0.586),  time:17.869, tt:1232.948\n",
      "Ep:69, loss:0.00002, loss_test:0.12101, lr:5.58e-03, fs:0.63256 (r=0.687,p=0.586),  time:17.891, tt:1252.379\n",
      "Ep:70, loss:0.00002, loss_test:0.12070, lr:5.53e-03, fs:0.63551 (r=0.687,p=0.591),  time:17.915, tt:1271.939\n",
      "Ep:71, loss:0.00002, loss_test:0.12034, lr:5.47e-03, fs:0.63850 (r=0.687,p=0.596),  time:17.933, tt:1291.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00002, loss_test:0.11985, lr:5.42e-03, fs:0.63850 (r=0.687,p=0.596),  time:17.954, tt:1310.674\n",
      "Ep:73, loss:0.00002, loss_test:0.11933, lr:5.36e-03, fs:0.63850 (r=0.687,p=0.596),  time:17.975, tt:1330.136\n",
      "Ep:74, loss:0.00002, loss_test:0.11880, lr:5.31e-03, fs:0.63850 (r=0.687,p=0.596),  time:17.992, tt:1349.380\n",
      "Ep:75, loss:0.00002, loss_test:0.11827, lr:5.26e-03, fs:0.64455 (r=0.687,p=0.607),  time:18.004, tt:1368.286\n",
      "Ep:76, loss:0.00002, loss_test:0.11787, lr:5.20e-03, fs:0.64455 (r=0.687,p=0.607),  time:18.024, tt:1387.818\n",
      "Ep:77, loss:0.00002, loss_test:0.11763, lr:5.15e-03, fs:0.64762 (r=0.687,p=0.613),  time:18.042, tt:1407.264\n",
      "Ep:78, loss:0.00002, loss_test:0.11738, lr:5.10e-03, fs:0.64762 (r=0.687,p=0.613),  time:18.048, tt:1425.818\n",
      "Ep:79, loss:0.00002, loss_test:0.11698, lr:5.05e-03, fs:0.65072 (r=0.687,p=0.618),  time:18.062, tt:1444.955\n",
      "Ep:80, loss:0.00002, loss_test:0.11642, lr:5.00e-03, fs:0.65072 (r=0.687,p=0.618),  time:18.078, tt:1464.335\n",
      "Ep:81, loss:0.00002, loss_test:0.11578, lr:4.95e-03, fs:0.65714 (r=0.697,p=0.622),  time:18.085, tt:1482.952\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.11518, lr:4.95e-03, fs:0.65714 (r=0.697,p=0.622),  time:18.090, tt:1501.495\n",
      "Ep:83, loss:0.00002, loss_test:0.11470, lr:4.95e-03, fs:0.66029 (r=0.697,p=0.627),  time:18.107, tt:1520.981\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.11440, lr:4.95e-03, fs:0.66029 (r=0.697,p=0.627),  time:18.122, tt:1540.356\n",
      "Ep:85, loss:0.00002, loss_test:0.11420, lr:4.95e-03, fs:0.66029 (r=0.697,p=0.627),  time:18.188, tt:1564.207\n",
      "Ep:86, loss:0.00002, loss_test:0.11396, lr:4.95e-03, fs:0.66029 (r=0.697,p=0.627),  time:18.200, tt:1583.384\n",
      "Ep:87, loss:0.00002, loss_test:0.11354, lr:4.95e-03, fs:0.66346 (r=0.697,p=0.633),  time:18.208, tt:1602.277\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.11300, lr:4.95e-03, fs:0.66667 (r=0.697,p=0.639),  time:18.213, tt:1620.975\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00002, loss_test:0.11253, lr:4.95e-03, fs:0.67308 (r=0.707,p=0.642),  time:18.225, tt:1640.221\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.11218, lr:4.95e-03, fs:0.67943 (r=0.717,p=0.645),  time:18.230, tt:1658.961\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.11190, lr:4.95e-03, fs:0.70755 (r=0.758,p=0.664),  time:18.243, tt:1678.314\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.11162, lr:4.95e-03, fs:0.71429 (r=0.758,p=0.676),  time:18.251, tt:1697.318\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.11125, lr:4.95e-03, fs:0.71429 (r=0.758,p=0.676),  time:18.260, tt:1716.429\n",
      "Ep:94, loss:0.00002, loss_test:0.11092, lr:4.95e-03, fs:0.71429 (r=0.758,p=0.676),  time:18.270, tt:1735.698\n",
      "Ep:95, loss:0.00002, loss_test:0.11064, lr:4.95e-03, fs:0.71698 (r=0.768,p=0.673),  time:18.272, tt:1754.106\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.11043, lr:4.95e-03, fs:0.72038 (r=0.768,p=0.679),  time:18.272, tt:1772.408\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.11024, lr:4.95e-03, fs:0.71698 (r=0.768,p=0.673),  time:18.276, tt:1791.047\n",
      "Ep:98, loss:0.00002, loss_test:0.11000, lr:4.95e-03, fs:0.72038 (r=0.768,p=0.679),  time:18.276, tt:1809.312\n",
      "Ep:99, loss:0.00002, loss_test:0.10978, lr:4.95e-03, fs:0.71090 (r=0.758,p=0.670),  time:18.286, tt:1828.603\n",
      "Ep:100, loss:0.00002, loss_test:0.10958, lr:4.95e-03, fs:0.71429 (r=0.758,p=0.676),  time:18.293, tt:1847.606\n",
      "Ep:101, loss:0.00002, loss_test:0.10931, lr:4.95e-03, fs:0.71090 (r=0.758,p=0.670),  time:18.295, tt:1866.073\n",
      "Ep:102, loss:0.00002, loss_test:0.10900, lr:4.95e-03, fs:0.71429 (r=0.758,p=0.676),  time:18.301, tt:1885.031\n",
      "Ep:103, loss:0.00002, loss_test:0.10887, lr:4.95e-03, fs:0.71498 (r=0.747,p=0.685),  time:18.307, tt:1903.974\n",
      "Ep:104, loss:0.00002, loss_test:0.10871, lr:4.95e-03, fs:0.72115 (r=0.758,p=0.688),  time:18.318, tt:1923.433\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.10850, lr:4.95e-03, fs:0.73430 (r=0.768,p=0.704),  time:18.316, tt:1941.458\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.10847, lr:4.95e-03, fs:0.73077 (r=0.768,p=0.697),  time:18.294, tt:1957.480\n",
      "Ep:107, loss:0.00002, loss_test:0.10875, lr:4.95e-03, fs:0.73430 (r=0.768,p=0.704),  time:18.286, tt:1974.879\n",
      "Ep:108, loss:0.00002, loss_test:0.10911, lr:4.95e-03, fs:0.74038 (r=0.778,p=0.706),  time:18.279, tt:1992.450\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00002, loss_test:0.10917, lr:4.95e-03, fs:0.74038 (r=0.778,p=0.706),  time:18.273, tt:2010.073\n",
      "Ep:110, loss:0.00002, loss_test:0.10898, lr:4.95e-03, fs:0.74038 (r=0.778,p=0.706),  time:18.279, tt:2028.965\n",
      "Ep:111, loss:0.00002, loss_test:0.10908, lr:4.95e-03, fs:0.73430 (r=0.768,p=0.704),  time:18.284, tt:2047.774\n",
      "Ep:112, loss:0.00002, loss_test:0.10931, lr:4.95e-03, fs:0.72816 (r=0.758,p=0.701),  time:18.287, tt:2066.410\n",
      "Ep:113, loss:0.00002, loss_test:0.10913, lr:4.95e-03, fs:0.72464 (r=0.758,p=0.694),  time:18.294, tt:2085.478\n",
      "Ep:114, loss:0.00001, loss_test:0.10890, lr:4.95e-03, fs:0.72195 (r=0.747,p=0.698),  time:18.298, tt:2104.237\n",
      "Ep:115, loss:0.00001, loss_test:0.10919, lr:4.95e-03, fs:0.72906 (r=0.747,p=0.712),  time:18.306, tt:2123.514\n",
      "Ep:116, loss:0.00001, loss_test:0.10939, lr:4.95e-03, fs:0.71642 (r=0.727,p=0.706),  time:18.317, tt:2143.100\n",
      "Ep:117, loss:0.00001, loss_test:0.10948, lr:4.95e-03, fs:0.72362 (r=0.727,p=0.720),  time:18.323, tt:2162.172\n",
      "Ep:118, loss:0.00001, loss_test:0.10941, lr:4.95e-03, fs:0.72362 (r=0.727,p=0.720),  time:18.327, tt:2180.868\n",
      "Ep:119, loss:0.00001, loss_test:0.10903, lr:4.95e-03, fs:0.72081 (r=0.717,p=0.724),  time:18.331, tt:2199.701\n",
      "Ep:120, loss:0.00001, loss_test:0.10928, lr:4.90e-03, fs:0.72081 (r=0.717,p=0.724),  time:18.332, tt:2218.180\n",
      "Ep:121, loss:0.00001, loss_test:0.10951, lr:4.85e-03, fs:0.72081 (r=0.717,p=0.724),  time:18.340, tt:2237.537\n",
      "Ep:122, loss:0.00001, loss_test:0.10999, lr:4.80e-03, fs:0.72449 (r=0.717,p=0.732),  time:18.351, tt:2257.191\n",
      "Ep:123, loss:0.00001, loss_test:0.10989, lr:4.75e-03, fs:0.72449 (r=0.717,p=0.732),  time:18.346, tt:2274.893\n",
      "Ep:124, loss:0.00001, loss_test:0.10972, lr:4.71e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.352, tt:2294.037\n",
      "Ep:125, loss:0.00001, loss_test:0.10946, lr:4.66e-03, fs:0.72449 (r=0.717,p=0.732),  time:18.356, tt:2312.913\n",
      "Ep:126, loss:0.00001, loss_test:0.10897, lr:4.61e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.362, tt:2331.944\n",
      "Ep:127, loss:0.00001, loss_test:0.10862, lr:4.57e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.369, tt:2351.196\n",
      "Ep:128, loss:0.00001, loss_test:0.10875, lr:4.52e-03, fs:0.73196 (r=0.717,p=0.747),  time:18.372, tt:2369.965\n",
      "Ep:129, loss:0.00001, loss_test:0.10839, lr:4.48e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.373, tt:2388.529\n",
      "Ep:130, loss:0.00001, loss_test:0.10787, lr:4.43e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.384, tt:2408.317\n",
      "Ep:131, loss:0.00001, loss_test:0.10752, lr:4.39e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.392, tt:2427.753\n",
      "Ep:132, loss:0.00001, loss_test:0.10677, lr:4.34e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.402, tt:2447.495\n",
      "Ep:133, loss:0.00001, loss_test:0.10718, lr:4.30e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.408, tt:2466.609\n",
      "Ep:134, loss:0.00001, loss_test:0.10657, lr:4.26e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.419, tt:2486.630\n",
      "Ep:135, loss:0.00001, loss_test:0.10617, lr:4.21e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.429, tt:2506.369\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00001, loss_test:0.10547, lr:4.21e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.437, tt:2525.812\n",
      "Ep:137, loss:0.00001, loss_test:0.10452, lr:4.21e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.442, tt:2545.020\n",
      "Ep:138, loss:0.00001, loss_test:0.10514, lr:4.21e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.448, tt:2564.317\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00001, loss_test:0.10415, lr:4.21e-03, fs:0.74346 (r=0.717,p=0.772),  time:18.451, tt:2583.203\n",
      "Ep:140, loss:0.00001, loss_test:0.10433, lr:4.21e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.452, tt:2601.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.10393, lr:4.21e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.452, tt:2620.242\n",
      "Ep:142, loss:0.00001, loss_test:0.10341, lr:4.21e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.450, tt:2638.283\n",
      "Ep:143, loss:0.00001, loss_test:0.10406, lr:4.21e-03, fs:0.75936 (r=0.717,p=0.807),  time:18.454, tt:2657.364\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00001, loss_test:0.10270, lr:4.21e-03, fs:0.75936 (r=0.717,p=0.807),  time:18.453, tt:2675.726\n",
      "Ep:145, loss:0.00001, loss_test:0.10237, lr:4.21e-03, fs:0.75936 (r=0.717,p=0.807),  time:18.456, tt:2694.543\n",
      "Ep:146, loss:0.00001, loss_test:0.10216, lr:4.21e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.457, tt:2713.111\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00001, loss_test:0.10177, lr:4.21e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.463, tt:2732.597\n",
      "Ep:148, loss:0.00001, loss_test:0.10184, lr:4.21e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.469, tt:2751.905\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00001, loss_test:0.10088, lr:4.21e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.479, tt:2771.914\n",
      "Ep:150, loss:0.00001, loss_test:0.10066, lr:4.21e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.488, tt:2791.663\n",
      "Ep:151, loss:0.00001, loss_test:0.10066, lr:4.21e-03, fs:0.77005 (r=0.727,p=0.818),  time:18.486, tt:2809.941\n",
      "Ep:152, loss:0.00001, loss_test:0.10006, lr:4.21e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.483, tt:2827.931\n",
      "##########Best model found so far##########\n",
      "Ep:153, loss:0.00001, loss_test:0.09996, lr:4.21e-03, fs:0.77419 (r=0.727,p=0.828),  time:18.488, tt:2847.123\n",
      "Ep:154, loss:0.00001, loss_test:0.09985, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.492, tt:2866.207\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.10000, lr:4.21e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.498, tt:2885.670\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00001, loss_test:0.09936, lr:4.21e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.495, tt:2903.665\n",
      "Ep:157, loss:0.00001, loss_test:0.09948, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.496, tt:2922.379\n",
      "##########Best model found so far##########\n",
      "Ep:158, loss:0.00001, loss_test:0.09845, lr:4.21e-03, fs:0.79121 (r=0.727,p=0.867),  time:18.497, tt:2940.974\n",
      "Ep:159, loss:0.00001, loss_test:0.09982, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.500, tt:2959.961\n",
      "Ep:160, loss:0.00001, loss_test:0.09691, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.527, tt:2982.797\n",
      "Ep:161, loss:0.00001, loss_test:0.09905, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.527, tt:3001.361\n",
      "Ep:162, loss:0.00001, loss_test:0.09657, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.528, tt:3020.064\n",
      "Ep:163, loss:0.00001, loss_test:0.09893, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.533, tt:3039.422\n",
      "Ep:164, loss:0.00001, loss_test:0.09731, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.534, tt:3058.084\n",
      "Ep:165, loss:0.00001, loss_test:0.09686, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.535, tt:3076.810\n",
      "Ep:166, loss:0.00001, loss_test:0.09891, lr:4.21e-03, fs:0.80000 (r=0.727,p=0.889),  time:18.540, tt:3096.130\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00001, loss_test:0.09503, lr:4.21e-03, fs:0.79121 (r=0.727,p=0.867),  time:18.548, tt:3116.121\n",
      "Ep:168, loss:0.00001, loss_test:0.10176, lr:4.21e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.553, tt:3135.455\n",
      "##########Best model found so far##########\n",
      "Ep:169, loss:0.00001, loss_test:0.09378, lr:4.21e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.559, tt:3155.102\n",
      "Ep:170, loss:0.00001, loss_test:0.10569, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.568, tt:3175.205\n",
      "##########Best model found so far##########\n",
      "Ep:171, loss:0.00001, loss_test:0.09284, lr:4.21e-03, fs:0.77838 (r=0.727,p=0.837),  time:18.572, tt:3194.411\n",
      "Ep:172, loss:0.00001, loss_test:0.10346, lr:4.21e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.581, tt:3214.484\n",
      "Ep:173, loss:0.00001, loss_test:0.09747, lr:4.21e-03, fs:0.80000 (r=0.727,p=0.889),  time:18.583, tt:3233.526\n",
      "Ep:174, loss:0.00001, loss_test:0.09223, lr:4.21e-03, fs:0.79121 (r=0.727,p=0.867),  time:18.589, tt:3252.994\n",
      "Ep:175, loss:0.00001, loss_test:0.10801, lr:4.21e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.591, tt:3272.062\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00001, loss_test:0.09237, lr:4.21e-03, fs:0.78689 (r=0.727,p=0.857),  time:18.587, tt:3289.829\n",
      "Ep:177, loss:0.00001, loss_test:0.09900, lr:4.21e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.588, tt:3308.748\n",
      "Ep:178, loss:0.00001, loss_test:0.09973, lr:4.21e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.592, tt:3327.963\n",
      "Ep:179, loss:0.00001, loss_test:0.09164, lr:4.21e-03, fs:0.79121 (r=0.727,p=0.867),  time:18.594, tt:3346.899\n",
      "Ep:180, loss:0.00001, loss_test:0.10486, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.600, tt:3366.574\n",
      "Ep:181, loss:0.00001, loss_test:0.09674, lr:4.21e-03, fs:0.80000 (r=0.727,p=0.889),  time:18.597, tt:3384.621\n",
      "Ep:182, loss:0.00001, loss_test:0.09361, lr:4.21e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.599, tt:3403.659\n",
      "Ep:183, loss:0.00001, loss_test:0.10659, lr:4.21e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.599, tt:3422.184\n",
      "Ep:184, loss:0.00001, loss_test:0.09203, lr:4.21e-03, fs:0.79121 (r=0.727,p=0.867),  time:18.601, tt:3441.186\n",
      "Ep:185, loss:0.00001, loss_test:0.10118, lr:4.21e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.604, tt:3460.388\n",
      "Ep:186, loss:0.00001, loss_test:0.09936, lr:4.21e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.605, tt:3479.156\n",
      "Ep:187, loss:0.00001, loss_test:0.09313, lr:4.17e-03, fs:0.79121 (r=0.727,p=0.867),  time:18.604, tt:3497.623\n",
      "Ep:188, loss:0.00001, loss_test:0.10223, lr:4.13e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.606, tt:3516.550\n",
      "Ep:189, loss:0.00001, loss_test:0.09672, lr:4.09e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.604, tt:3534.841\n",
      "Ep:190, loss:0.00001, loss_test:0.09278, lr:4.05e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.607, tt:3553.908\n",
      "Ep:191, loss:0.00001, loss_test:0.10240, lr:4.01e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.608, tt:3572.777\n",
      "Ep:192, loss:0.00001, loss_test:0.09650, lr:3.97e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.613, tt:3592.403\n",
      "Ep:193, loss:0.00001, loss_test:0.09361, lr:3.93e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.620, tt:3612.346\n",
      "Ep:194, loss:0.00001, loss_test:0.10070, lr:3.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.626, tt:3632.070\n",
      "Ep:195, loss:0.00001, loss_test:0.09605, lr:3.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.634, tt:3652.316\n",
      "Ep:196, loss:0.00001, loss_test:0.09607, lr:3.81e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.637, tt:3671.576\n",
      "Ep:197, loss:0.00001, loss_test:0.10116, lr:3.77e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.661, tt:3694.817\n",
      "Ep:198, loss:0.00001, loss_test:0.09433, lr:3.73e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.668, tt:3714.918\n",
      "Ep:199, loss:0.00001, loss_test:0.09796, lr:3.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.673, tt:3734.611\n",
      "Ep:200, loss:0.00001, loss_test:0.09972, lr:3.66e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.671, tt:3752.917\n",
      "Ep:201, loss:0.00000, loss_test:0.09441, lr:3.62e-03, fs:0.80899 (r=0.727,p=0.911),  time:18.674, tt:3772.129\n",
      "Ep:202, loss:0.00000, loss_test:0.09995, lr:3.59e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.668, tt:3789.581\n",
      "Ep:203, loss:0.00000, loss_test:0.09894, lr:3.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.667, tt:3807.974\n",
      "Ep:204, loss:0.00000, loss_test:0.09306, lr:3.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.671, tt:3827.548\n",
      "Ep:205, loss:0.00000, loss_test:0.10040, lr:3.48e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.678, tt:3847.681\n",
      "Ep:206, loss:0.00000, loss_test:0.09703, lr:3.45e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.684, tt:3867.557\n",
      "Ep:207, loss:0.00000, loss_test:0.09528, lr:3.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.685, tt:3886.557\n",
      "Ep:208, loss:0.00000, loss_test:0.09996, lr:3.38e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.690, tt:3906.301\n",
      "Ep:209, loss:0.00000, loss_test:0.09501, lr:3.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:18.691, tt:3925.168\n",
      "Ep:210, loss:0.00000, loss_test:0.09804, lr:3.31e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.699, tt:3945.582\n",
      "Ep:211, loss:0.00000, loss_test:0.09849, lr:3.28e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.699, tt:3964.196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00000, loss_test:0.09614, lr:3.24e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.704, tt:3983.974\n",
      "Ep:213, loss:0.00000, loss_test:0.09980, lr:3.21e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.708, tt:4003.617\n",
      "Ep:214, loss:0.00000, loss_test:0.09691, lr:3.18e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.714, tt:4023.557\n",
      "Ep:215, loss:0.00000, loss_test:0.09752, lr:3.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.717, tt:4042.877\n",
      "Ep:216, loss:0.00000, loss_test:0.09942, lr:3.12e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.720, tt:4062.189\n",
      "Ep:217, loss:0.00000, loss_test:0.09677, lr:3.09e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.720, tt:4081.037\n",
      "Ep:218, loss:0.00000, loss_test:0.09810, lr:3.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.728, tt:4101.436\n",
      "Ep:219, loss:0.00000, loss_test:0.09892, lr:3.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.727, tt:4120.037\n",
      "Ep:220, loss:0.00000, loss_test:0.09703, lr:2.99e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.732, tt:4139.848\n",
      "Ep:221, loss:0.00000, loss_test:0.09969, lr:2.96e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.735, tt:4159.246\n",
      "Ep:222, loss:0.00000, loss_test:0.09727, lr:2.93e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.734, tt:4177.787\n",
      "Ep:223, loss:0.00000, loss_test:0.09834, lr:2.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.740, tt:4197.727\n",
      "Ep:224, loss:0.00000, loss_test:0.09897, lr:2.88e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.745, tt:4217.575\n",
      "Ep:225, loss:0.00000, loss_test:0.09655, lr:2.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.749, tt:4237.225\n",
      "Ep:226, loss:0.00000, loss_test:0.10034, lr:2.82e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.752, tt:4256.644\n",
      "Ep:227, loss:0.00000, loss_test:0.09744, lr:2.79e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.750, tt:4274.990\n",
      "Ep:228, loss:0.00000, loss_test:0.09831, lr:2.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.753, tt:4294.346\n",
      "Ep:229, loss:0.00000, loss_test:0.09863, lr:2.73e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.751, tt:4312.773\n",
      "Ep:230, loss:0.00000, loss_test:0.09716, lr:2.71e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.754, tt:4332.110\n",
      "Ep:231, loss:0.00000, loss_test:0.09985, lr:2.68e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.756, tt:4351.481\n",
      "Ep:232, loss:0.00000, loss_test:0.09711, lr:2.65e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.756, tt:4370.162\n",
      "Ep:233, loss:0.00000, loss_test:0.09880, lr:2.63e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.756, tt:4388.956\n",
      "Ep:234, loss:0.00000, loss_test:0.09914, lr:2.60e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.761, tt:4408.941\n",
      "Ep:235, loss:0.00000, loss_test:0.09768, lr:2.57e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.764, tt:4428.187\n",
      "Ep:236, loss:0.00000, loss_test:0.09884, lr:2.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.765, tt:4447.261\n",
      "Ep:237, loss:0.00000, loss_test:0.09787, lr:2.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.773, tt:4468.055\n",
      "Ep:238, loss:0.00000, loss_test:0.09844, lr:2.50e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.774, tt:4486.950\n",
      "Ep:239, loss:0.00000, loss_test:0.09864, lr:2.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.773, tt:4505.510\n",
      "Ep:240, loss:0.00000, loss_test:0.09776, lr:2.45e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.774, tt:4524.541\n",
      "Ep:241, loss:0.00000, loss_test:0.09826, lr:2.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.777, tt:4543.940\n",
      "Ep:242, loss:0.00000, loss_test:0.09823, lr:2.40e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.781, tt:4563.722\n",
      "Ep:243, loss:0.00000, loss_test:0.09859, lr:2.38e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.781, tt:4582.679\n",
      "Ep:244, loss:0.00000, loss_test:0.09807, lr:2.35e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.781, tt:4601.371\n",
      "Ep:245, loss:0.00000, loss_test:0.09874, lr:2.33e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.781, tt:4620.086\n",
      "Ep:246, loss:0.00000, loss_test:0.09831, lr:2.31e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.785, tt:4639.866\n",
      "Ep:247, loss:0.00000, loss_test:0.09823, lr:2.28e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.788, tt:4659.499\n",
      "Ep:248, loss:0.00000, loss_test:0.09879, lr:2.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.790, tt:4678.819\n",
      "Ep:249, loss:0.00000, loss_test:0.09810, lr:2.24e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.794, tt:4698.377\n",
      "Ep:250, loss:0.00000, loss_test:0.09952, lr:2.21e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.792, tt:4716.822\n",
      "Ep:251, loss:0.00000, loss_test:0.09781, lr:2.19e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.791, tt:4735.314\n",
      "Ep:252, loss:0.00000, loss_test:0.09929, lr:2.17e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.792, tt:4754.477\n",
      "Ep:253, loss:0.00000, loss_test:0.09908, lr:2.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.796, tt:4774.095\n",
      "Ep:254, loss:0.00000, loss_test:0.09780, lr:2.13e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.792, tt:4791.841\n",
      "Ep:255, loss:0.00000, loss_test:0.09942, lr:2.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.791, tt:4810.379\n",
      "Ep:256, loss:0.00000, loss_test:0.09842, lr:2.08e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.791, tt:4829.265\n",
      "Ep:257, loss:0.00000, loss_test:0.09919, lr:2.06e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.787, tt:4847.103\n",
      "Ep:258, loss:0.00000, loss_test:0.09954, lr:2.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.787, tt:4865.707\n",
      "Ep:259, loss:0.00000, loss_test:0.09846, lr:2.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.785, tt:4884.064\n",
      "Ep:260, loss:0.00000, loss_test:0.09981, lr:2.00e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.785, tt:4902.765\n",
      "Ep:261, loss:0.00000, loss_test:0.09846, lr:1.98e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.785, tt:4921.638\n",
      "Ep:262, loss:0.00000, loss_test:0.09960, lr:1.96e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.786, tt:4940.785\n",
      "Ep:263, loss:0.00000, loss_test:0.09960, lr:1.94e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.791, tt:4960.713\n",
      "Ep:264, loss:0.00000, loss_test:0.09941, lr:1.92e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.798, tt:4981.361\n",
      "Ep:265, loss:0.00000, loss_test:0.09962, lr:1.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.799, tt:5000.450\n",
      "Ep:266, loss:0.00000, loss_test:0.09956, lr:1.89e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.799, tt:5019.322\n",
      "Ep:267, loss:0.00000, loss_test:0.10027, lr:1.87e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.799, tt:5038.170\n",
      "Ep:268, loss:0.00000, loss_test:0.09926, lr:1.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.801, tt:5057.466\n",
      "Ep:269, loss:0.00000, loss_test:0.10024, lr:1.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.801, tt:5076.191\n",
      "Ep:270, loss:0.00000, loss_test:0.09956, lr:1.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.801, tt:5095.157\n",
      "Ep:271, loss:0.00000, loss_test:0.10027, lr:1.79e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.802, tt:5114.233\n",
      "Ep:272, loss:0.00000, loss_test:0.09994, lr:1.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.800, tt:5132.517\n",
      "Ep:273, loss:0.00000, loss_test:0.10015, lr:1.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.802, tt:5151.745\n",
      "Ep:274, loss:0.00000, loss_test:0.10026, lr:1.74e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.804, tt:5170.981\n",
      "Ep:275, loss:0.00000, loss_test:0.10006, lr:1.72e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.806, tt:5190.548\n",
      "Ep:276, loss:0.00000, loss_test:0.10093, lr:1.71e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.803, tt:5208.433\n",
      "Ep:277, loss:0.00000, loss_test:0.09991, lr:1.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.801, tt:5226.753\n",
      "Ep:278, loss:0.00000, loss_test:0.10065, lr:1.67e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.799, tt:5244.911\n",
      "Ep:279, loss:0.00000, loss_test:0.10035, lr:1.65e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.799, tt:5263.705\n",
      "Ep:280, loss:0.00000, loss_test:0.10037, lr:1.64e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.798, tt:5282.153\n",
      "Ep:281, loss:0.00000, loss_test:0.10064, lr:1.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.799, tt:5301.285\n",
      "Ep:282, loss:0.00000, loss_test:0.10020, lr:1.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.804, tt:5321.545\n",
      "Ep:283, loss:0.00000, loss_test:0.10102, lr:1.59e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.808, tt:5341.565\n",
      "Ep:284, loss:0.00000, loss_test:0.10026, lr:1.57e-03, fs:0.81818 (r=0.727,p=0.935),  time:18.810, tt:5360.728\n",
      "Ep:285, loss:0.00000, loss_test:0.10069, lr:1.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.810, tt:5379.685\n",
      "Ep:286, loss:0.00000, loss_test:0.10103, lr:1.54e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.820, tt:5401.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:287, loss:0.00000, loss_test:0.10033, lr:1.53e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.821, tt:5420.373\n",
      "Ep:288, loss:0.00000, loss_test:0.10106, lr:1.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.819, tt:5438.725\n",
      "Ep:289, loss:0.00000, loss_test:0.10051, lr:1.50e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.814, tt:5456.009\n",
      "Ep:290, loss:0.00000, loss_test:0.10077, lr:1.48e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.815, tt:5475.289\n",
      "Ep:291, loss:0.00000, loss_test:0.10116, lr:1.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.815, tt:5494.044\n",
      "Ep:292, loss:0.00000, loss_test:0.10104, lr:1.45e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.813, tt:5512.165\n",
      "Ep:293, loss:0.00000, loss_test:0.10142, lr:1.44e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.808, tt:5529.670\n",
      "Ep:294, loss:0.00000, loss_test:0.10098, lr:1.42e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.810, tt:5548.913\n",
      "Ep:295, loss:0.00000, loss_test:0.10126, lr:1.41e-03, fs:0.82286 (r=0.727,p=0.947),  time:18.808, tt:5567.080\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14513, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.288, tt:10.288\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14495, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.615, tt:19.229\n",
      "Ep:2, loss:0.00004, loss_test:0.14468, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.264, tt:30.793\n",
      "Ep:3, loss:0.00004, loss_test:0.14431, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:11.652, tt:46.608\n",
      "Ep:4, loss:0.00004, loss_test:0.14385, lr:1.00e-02, fs:0.64828 (r=0.949,p=0.492),  time:12.665, tt:63.327\n",
      "Ep:5, loss:0.00004, loss_test:0.14327, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:13.275, tt:79.650\n",
      "Ep:6, loss:0.00004, loss_test:0.14255, lr:1.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:13.757, tt:96.301\n",
      "Ep:7, loss:0.00004, loss_test:0.14162, lr:1.00e-02, fs:0.65493 (r=0.939,p=0.503),  time:13.917, tt:111.333\n",
      "Ep:8, loss:0.00004, loss_test:0.14050, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:14.146, tt:127.312\n",
      "Ep:9, loss:0.00004, loss_test:0.13926, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:14.258, tt:142.584\n",
      "Ep:10, loss:0.00004, loss_test:0.13802, lr:1.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:14.365, tt:158.018\n",
      "Ep:11, loss:0.00004, loss_test:0.13705, lr:1.00e-02, fs:0.62016 (r=0.808,p=0.503),  time:14.443, tt:173.321\n",
      "Ep:12, loss:0.00004, loss_test:0.13613, lr:9.90e-03, fs:0.60331 (r=0.737,p=0.510),  time:14.606, tt:189.883\n",
      "Ep:13, loss:0.00003, loss_test:0.13530, lr:9.80e-03, fs:0.59829 (r=0.707,p=0.519),  time:14.675, tt:205.446\n",
      "Ep:14, loss:0.00003, loss_test:0.13555, lr:9.70e-03, fs:0.59912 (r=0.687,p=0.531),  time:14.970, tt:224.545\n",
      "Ep:15, loss:0.00003, loss_test:0.13601, lr:9.61e-03, fs:0.60829 (r=0.667,p=0.559),  time:15.055, tt:240.885\n",
      "Ep:16, loss:0.00003, loss_test:0.13645, lr:9.51e-03, fs:0.60870 (r=0.636,p=0.583),  time:15.153, tt:257.603\n",
      "Ep:17, loss:0.00003, loss_test:0.13595, lr:9.41e-03, fs:0.61386 (r=0.626,p=0.602),  time:15.277, tt:274.990\n",
      "Ep:18, loss:0.00003, loss_test:0.13491, lr:9.32e-03, fs:0.62312 (r=0.626,p=0.620),  time:15.305, tt:290.802\n",
      "Ep:19, loss:0.00003, loss_test:0.13368, lr:9.23e-03, fs:0.62000 (r=0.626,p=0.614),  time:15.342, tt:306.837\n",
      "Ep:20, loss:0.00003, loss_test:0.13246, lr:9.14e-03, fs:0.61084 (r=0.626,p=0.596),  time:15.405, tt:323.497\n",
      "Ep:21, loss:0.00003, loss_test:0.13130, lr:9.04e-03, fs:0.62802 (r=0.657,p=0.602),  time:15.426, tt:339.368\n",
      "Ep:22, loss:0.00003, loss_test:0.13032, lr:8.95e-03, fs:0.63158 (r=0.667,p=0.600),  time:15.454, tt:355.431\n",
      "Ep:23, loss:0.00003, loss_test:0.12949, lr:8.86e-03, fs:0.63107 (r=0.657,p=0.607),  time:15.484, tt:371.624\n",
      "Ep:24, loss:0.00003, loss_test:0.12885, lr:8.78e-03, fs:0.63054 (r=0.646,p=0.615),  time:15.560, tt:388.997\n",
      "Ep:25, loss:0.00003, loss_test:0.12846, lr:8.69e-03, fs:0.63317 (r=0.636,p=0.630),  time:15.567, tt:404.730\n",
      "Ep:26, loss:0.00003, loss_test:0.12807, lr:8.60e-03, fs:0.62944 (r=0.626,p=0.633),  time:15.608, tt:421.406\n",
      "Ep:27, loss:0.00003, loss_test:0.12747, lr:8.51e-03, fs:0.62500 (r=0.606,p=0.645),  time:15.649, tt:438.162\n",
      "Ep:28, loss:0.00003, loss_test:0.12661, lr:8.43e-03, fs:0.64249 (r=0.626,p=0.660),  time:15.686, tt:454.908\n",
      "Ep:29, loss:0.00003, loss_test:0.12551, lr:8.35e-03, fs:0.64975 (r=0.646,p=0.653),  time:15.659, tt:469.759\n",
      "Ep:30, loss:0.00003, loss_test:0.12439, lr:8.26e-03, fs:0.64322 (r=0.646,p=0.640),  time:15.694, tt:486.526\n",
      "Ep:31, loss:0.00003, loss_test:0.12349, lr:8.18e-03, fs:0.64677 (r=0.657,p=0.637),  time:15.692, tt:502.156\n",
      "Ep:32, loss:0.00003, loss_test:0.12285, lr:8.10e-03, fs:0.65672 (r=0.667,p=0.647),  time:15.691, tt:517.811\n",
      "Ep:33, loss:0.00003, loss_test:0.12246, lr:8.02e-03, fs:0.65641 (r=0.646,p=0.667),  time:15.734, tt:534.970\n",
      "Ep:34, loss:0.00003, loss_test:0.12219, lr:7.94e-03, fs:0.64583 (r=0.626,p=0.667),  time:15.717, tt:550.110\n",
      "Ep:35, loss:0.00002, loss_test:0.12174, lr:7.86e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.731, tt:566.326\n",
      "Ep:36, loss:0.00002, loss_test:0.12107, lr:7.78e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.762, tt:583.205\n",
      "Ep:37, loss:0.00002, loss_test:0.12025, lr:7.70e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.774, tt:599.424\n",
      "Ep:38, loss:0.00002, loss_test:0.11942, lr:7.62e-03, fs:0.64249 (r=0.626,p=0.660),  time:15.783, tt:615.519\n",
      "Ep:39, loss:0.00002, loss_test:0.11855, lr:7.55e-03, fs:0.64249 (r=0.626,p=0.660),  time:15.810, tt:632.407\n",
      "Ep:40, loss:0.00002, loss_test:0.11759, lr:7.47e-03, fs:0.64249 (r=0.626,p=0.660),  time:15.808, tt:648.126\n",
      "Ep:41, loss:0.00002, loss_test:0.11663, lr:7.40e-03, fs:0.64583 (r=0.626,p=0.667),  time:15.826, tt:664.678\n",
      "Ep:42, loss:0.00002, loss_test:0.11572, lr:7.32e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.799, tt:679.368\n",
      "Ep:43, loss:0.00002, loss_test:0.11479, lr:7.25e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.803, tt:695.324\n",
      "Ep:44, loss:0.00002, loss_test:0.11396, lr:7.18e-03, fs:0.64211 (r=0.616,p=0.670),  time:15.834, tt:712.531\n",
      "Ep:45, loss:0.00002, loss_test:0.11306, lr:7.11e-03, fs:0.64583 (r=0.626,p=0.667),  time:15.870, tt:730.012\n",
      "Ep:46, loss:0.00002, loss_test:0.11222, lr:7.03e-03, fs:0.65979 (r=0.646,p=0.674),  time:15.866, tt:745.700\n",
      "Ep:47, loss:0.00002, loss_test:0.11149, lr:6.96e-03, fs:0.66667 (r=0.657,p=0.677),  time:15.864, tt:761.495\n",
      "Ep:48, loss:0.00002, loss_test:0.11088, lr:6.89e-03, fs:0.66667 (r=0.657,p=0.677),  time:15.873, tt:777.758\n",
      "Ep:49, loss:0.00002, loss_test:0.11034, lr:6.83e-03, fs:0.66667 (r=0.657,p=0.677),  time:15.888, tt:794.401\n",
      "Ep:50, loss:0.00002, loss_test:0.10977, lr:6.76e-03, fs:0.66667 (r=0.646,p=0.688),  time:15.895, tt:810.664\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.10913, lr:6.76e-03, fs:0.67016 (r=0.646,p=0.696),  time:15.896, tt:826.613\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.10847, lr:6.76e-03, fs:0.68063 (r=0.657,p=0.707),  time:15.897, tt:842.516\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.10780, lr:6.76e-03, fs:0.68063 (r=0.657,p=0.707),  time:15.908, tt:859.013\n",
      "Ep:54, loss:0.00002, loss_test:0.10715, lr:6.76e-03, fs:0.67368 (r=0.646,p=0.703),  time:15.915, tt:875.316\n",
      "Ep:55, loss:0.00002, loss_test:0.10656, lr:6.76e-03, fs:0.67725 (r=0.646,p=0.711),  time:15.906, tt:890.750\n",
      "Ep:56, loss:0.00002, loss_test:0.10600, lr:6.76e-03, fs:0.69474 (r=0.667,p=0.725),  time:15.920, tt:907.444\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.10544, lr:6.76e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.903, tt:922.365\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.10487, lr:6.76e-03, fs:0.70899 (r=0.677,p=0.744),  time:15.901, tt:938.163\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.10432, lr:6.76e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.902, tt:954.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00002, loss_test:0.10380, lr:6.76e-03, fs:0.71204 (r=0.687,p=0.739),  time:15.899, tt:969.843\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.10327, lr:6.76e-03, fs:0.71204 (r=0.687,p=0.739),  time:15.893, tt:985.385\n",
      "Ep:62, loss:0.00002, loss_test:0.10274, lr:6.76e-03, fs:0.71875 (r=0.697,p=0.742),  time:15.884, tt:1000.705\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.10221, lr:6.76e-03, fs:0.73196 (r=0.717,p=0.747),  time:15.874, tt:1015.949\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.10169, lr:6.76e-03, fs:0.74227 (r=0.727,p=0.758),  time:15.860, tt:1030.912\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.10121, lr:6.76e-03, fs:0.74872 (r=0.737,p=0.760),  time:15.867, tt:1047.213\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.10077, lr:6.76e-03, fs:0.75897 (r=0.747,p=0.771),  time:15.856, tt:1062.344\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.10036, lr:6.76e-03, fs:0.75897 (r=0.747,p=0.771),  time:15.864, tt:1078.775\n",
      "Ep:68, loss:0.00002, loss_test:0.10001, lr:6.76e-03, fs:0.75897 (r=0.747,p=0.771),  time:15.871, tt:1095.118\n",
      "Ep:69, loss:0.00002, loss_test:0.09965, lr:6.76e-03, fs:0.75897 (r=0.747,p=0.771),  time:15.867, tt:1110.669\n",
      "Ep:70, loss:0.00002, loss_test:0.09931, lr:6.76e-03, fs:0.76142 (r=0.758,p=0.765),  time:15.865, tt:1126.428\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.09899, lr:6.76e-03, fs:0.76142 (r=0.758,p=0.765),  time:15.865, tt:1142.245\n",
      "Ep:72, loss:0.00002, loss_test:0.09871, lr:6.76e-03, fs:0.76768 (r=0.768,p=0.768),  time:15.865, tt:1158.130\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.09843, lr:6.76e-03, fs:0.76768 (r=0.768,p=0.768),  time:15.856, tt:1173.360\n",
      "Ep:74, loss:0.00002, loss_test:0.09816, lr:6.76e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.851, tt:1188.839\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.09783, lr:6.76e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.853, tt:1204.821\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.09744, lr:6.76e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.840, tt:1219.716\n",
      "Ep:77, loss:0.00002, loss_test:0.09706, lr:6.76e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.838, tt:1235.355\n",
      "Ep:78, loss:0.00002, loss_test:0.09669, lr:6.76e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.832, tt:1250.766\n",
      "Ep:79, loss:0.00002, loss_test:0.09634, lr:6.76e-03, fs:0.78000 (r=0.788,p=0.772),  time:15.822, tt:1265.786\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.09602, lr:6.76e-03, fs:0.78000 (r=0.788,p=0.772),  time:15.838, tt:1282.853\n",
      "Ep:81, loss:0.00002, loss_test:0.09573, lr:6.76e-03, fs:0.78000 (r=0.788,p=0.772),  time:15.840, tt:1298.864\n",
      "Ep:82, loss:0.00002, loss_test:0.09540, lr:6.76e-03, fs:0.78392 (r=0.788,p=0.780),  time:15.831, tt:1313.972\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.09504, lr:6.76e-03, fs:0.78392 (r=0.788,p=0.780),  time:15.842, tt:1330.701\n",
      "Ep:84, loss:0.00002, loss_test:0.09469, lr:6.76e-03, fs:0.78392 (r=0.788,p=0.780),  time:15.840, tt:1346.382\n",
      "Ep:85, loss:0.00002, loss_test:0.09440, lr:6.76e-03, fs:0.78788 (r=0.788,p=0.788),  time:15.841, tt:1362.353\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.09417, lr:6.76e-03, fs:0.79397 (r=0.798,p=0.790),  time:15.849, tt:1378.859\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00002, loss_test:0.09387, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.862, tt:1395.870\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.09352, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.877, tt:1413.071\n",
      "Ep:89, loss:0.00002, loss_test:0.09322, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.894, tt:1430.474\n",
      "Ep:90, loss:0.00001, loss_test:0.09297, lr:6.76e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.907, tt:1447.501\n",
      "Ep:91, loss:0.00001, loss_test:0.09274, lr:6.76e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.908, tt:1463.561\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.09250, lr:6.76e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.917, tt:1480.260\n",
      "Ep:93, loss:0.00001, loss_test:0.09214, lr:6.76e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.913, tt:1495.867\n",
      "Ep:94, loss:0.00001, loss_test:0.09176, lr:6.76e-03, fs:0.81000 (r=0.818,p=0.802),  time:15.914, tt:1511.810\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.09143, lr:6.76e-03, fs:0.80198 (r=0.818,p=0.786),  time:15.924, tt:1528.684\n",
      "Ep:96, loss:0.00001, loss_test:0.09112, lr:6.76e-03, fs:0.80198 (r=0.818,p=0.786),  time:15.919, tt:1544.155\n",
      "Ep:97, loss:0.00001, loss_test:0.09086, lr:6.76e-03, fs:0.80198 (r=0.818,p=0.786),  time:15.929, tt:1561.090\n",
      "Ep:98, loss:0.00001, loss_test:0.09060, lr:6.76e-03, fs:0.80597 (r=0.818,p=0.794),  time:15.948, tt:1578.832\n",
      "Ep:99, loss:0.00001, loss_test:0.09031, lr:6.76e-03, fs:0.81188 (r=0.828,p=0.796),  time:15.958, tt:1595.816\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.09000, lr:6.76e-03, fs:0.80788 (r=0.828,p=0.788),  time:15.977, tt:1613.638\n",
      "Ep:101, loss:0.00001, loss_test:0.08972, lr:6.76e-03, fs:0.80788 (r=0.828,p=0.788),  time:15.988, tt:1630.737\n",
      "Ep:102, loss:0.00001, loss_test:0.08947, lr:6.76e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.993, tt:1647.244\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.08925, lr:6.76e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.997, tt:1663.700\n",
      "Ep:104, loss:0.00001, loss_test:0.08901, lr:6.76e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.991, tt:1679.051\n",
      "Ep:105, loss:0.00001, loss_test:0.08873, lr:6.76e-03, fs:0.81373 (r=0.838,p=0.790),  time:15.995, tt:1695.514\n",
      "Ep:106, loss:0.00001, loss_test:0.08847, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:15.999, tt:1711.853\n",
      "Ep:107, loss:0.00001, loss_test:0.08826, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:15.998, tt:1727.781\n",
      "Ep:108, loss:0.00001, loss_test:0.08807, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:15.998, tt:1743.816\n",
      "Ep:109, loss:0.00001, loss_test:0.08789, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.000, tt:1760.011\n",
      "Ep:110, loss:0.00001, loss_test:0.08766, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.003, tt:1776.286\n",
      "Ep:111, loss:0.00001, loss_test:0.08744, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.015, tt:1793.679\n",
      "Ep:112, loss:0.00001, loss_test:0.08729, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.013, tt:1809.518\n",
      "Ep:113, loss:0.00001, loss_test:0.08719, lr:6.76e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.023, tt:1826.665\n",
      "Ep:114, loss:0.00001, loss_test:0.08710, lr:6.69e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.028, tt:1843.185\n",
      "Ep:115, loss:0.00001, loss_test:0.08691, lr:6.62e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.027, tt:1859.084\n",
      "Ep:116, loss:0.00001, loss_test:0.08667, lr:6.56e-03, fs:0.80976 (r=0.838,p=0.783),  time:16.026, tt:1875.064\n",
      "Ep:117, loss:0.00001, loss_test:0.08654, lr:6.49e-03, fs:0.81373 (r=0.838,p=0.790),  time:16.029, tt:1891.404\n",
      "Ep:118, loss:0.00001, loss_test:0.08645, lr:6.43e-03, fs:0.81373 (r=0.838,p=0.790),  time:16.035, tt:1908.187\n",
      "Ep:119, loss:0.00001, loss_test:0.08630, lr:6.36e-03, fs:0.81773 (r=0.838,p=0.798),  time:16.040, tt:1924.830\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.08604, lr:6.36e-03, fs:0.81373 (r=0.838,p=0.790),  time:16.033, tt:1940.009\n",
      "Ep:121, loss:0.00001, loss_test:0.08576, lr:6.36e-03, fs:0.81373 (r=0.838,p=0.790),  time:16.033, tt:1956.004\n",
      "Ep:122, loss:0.00001, loss_test:0.08555, lr:6.36e-03, fs:0.81773 (r=0.838,p=0.798),  time:16.025, tt:1971.068\n",
      "Ep:123, loss:0.00001, loss_test:0.08536, lr:6.36e-03, fs:0.82178 (r=0.838,p=0.806),  time:16.016, tt:1986.043\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.08510, lr:6.36e-03, fs:0.82178 (r=0.838,p=0.806),  time:16.016, tt:2001.973\n",
      "Ep:125, loss:0.00001, loss_test:0.08485, lr:6.36e-03, fs:0.82178 (r=0.838,p=0.806),  time:16.011, tt:2017.440\n",
      "Ep:126, loss:0.00001, loss_test:0.08467, lr:6.36e-03, fs:0.82178 (r=0.838,p=0.806),  time:16.007, tt:2032.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00001, loss_test:0.08456, lr:6.36e-03, fs:0.82587 (r=0.838,p=0.814),  time:16.007, tt:2048.850\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.08443, lr:6.36e-03, fs:0.82587 (r=0.838,p=0.814),  time:16.002, tt:2064.253\n",
      "Ep:129, loss:0.00001, loss_test:0.08427, lr:6.36e-03, fs:0.82587 (r=0.838,p=0.814),  time:15.998, tt:2079.805\n",
      "Ep:130, loss:0.00001, loss_test:0.08406, lr:6.36e-03, fs:0.82587 (r=0.838,p=0.814),  time:15.997, tt:2095.627\n",
      "Ep:131, loss:0.00001, loss_test:0.08390, lr:6.36e-03, fs:0.83000 (r=0.838,p=0.822),  time:15.994, tt:2111.158\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00001, loss_test:0.08382, lr:6.36e-03, fs:0.83000 (r=0.838,p=0.822),  time:15.988, tt:2126.382\n",
      "Ep:133, loss:0.00001, loss_test:0.08367, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.989, tt:2142.493\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00001, loss_test:0.08352, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.984, tt:2157.880\n",
      "Ep:135, loss:0.00001, loss_test:0.08336, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.977, tt:2172.847\n",
      "Ep:136, loss:0.00001, loss_test:0.08327, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.970, tt:2187.918\n",
      "Ep:137, loss:0.00001, loss_test:0.08315, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.968, tt:2203.620\n",
      "Ep:138, loss:0.00001, loss_test:0.08302, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.964, tt:2219.038\n",
      "Ep:139, loss:0.00001, loss_test:0.08291, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.952, tt:2233.248\n",
      "Ep:140, loss:0.00001, loss_test:0.08280, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.946, tt:2248.442\n",
      "Ep:141, loss:0.00001, loss_test:0.08264, lr:6.36e-03, fs:0.83417 (r=0.838,p=0.830),  time:15.935, tt:2262.701\n",
      "Ep:142, loss:0.00001, loss_test:0.08259, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.935, tt:2278.699\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00001, loss_test:0.08251, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.932, tt:2294.164\n",
      "Ep:144, loss:0.00001, loss_test:0.08241, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.924, tt:2308.927\n",
      "Ep:145, loss:0.00001, loss_test:0.08227, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.918, tt:2323.958\n",
      "Ep:146, loss:0.00001, loss_test:0.08214, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.914, tt:2339.377\n",
      "Ep:147, loss:0.00001, loss_test:0.08212, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.911, tt:2354.889\n",
      "Ep:148, loss:0.00001, loss_test:0.08209, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.910, tt:2370.548\n",
      "Ep:149, loss:0.00001, loss_test:0.08189, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.905, tt:2385.739\n",
      "Ep:150, loss:0.00001, loss_test:0.08177, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.902, tt:2401.142\n",
      "Ep:151, loss:0.00001, loss_test:0.08166, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.898, tt:2416.548\n",
      "Ep:152, loss:0.00001, loss_test:0.08156, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.896, tt:2432.087\n",
      "Ep:153, loss:0.00001, loss_test:0.08139, lr:6.36e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.893, tt:2447.554\n",
      "Ep:154, loss:0.00001, loss_test:0.08124, lr:6.30e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.893, tt:2463.385\n",
      "Ep:155, loss:0.00001, loss_test:0.08114, lr:6.24e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.893, tt:2479.261\n",
      "Ep:156, loss:0.00001, loss_test:0.08103, lr:6.17e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.899, tt:2496.172\n",
      "Ep:157, loss:0.00001, loss_test:0.08087, lr:6.11e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.892, tt:2510.951\n",
      "Ep:158, loss:0.00001, loss_test:0.08080, lr:6.05e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.888, tt:2526.218\n",
      "Ep:159, loss:0.00001, loss_test:0.08072, lr:5.99e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.878, tt:2540.545\n",
      "Ep:160, loss:0.00001, loss_test:0.08063, lr:5.93e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.873, tt:2555.491\n",
      "Ep:161, loss:0.00001, loss_test:0.08062, lr:5.87e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.867, tt:2570.386\n",
      "Ep:162, loss:0.00001, loss_test:0.08057, lr:5.81e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.864, tt:2585.765\n",
      "Ep:163, loss:0.00001, loss_test:0.08049, lr:5.75e-03, fs:0.84264 (r=0.838,p=0.847),  time:15.857, tt:2600.524\n",
      "Ep:164, loss:0.00001, loss_test:0.08044, lr:5.70e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.855, tt:2616.111\n",
      "##########Best model found so far##########\n",
      "Ep:165, loss:0.00001, loss_test:0.08039, lr:5.70e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.853, tt:2631.650\n",
      "Ep:166, loss:0.00001, loss_test:0.08031, lr:5.70e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.857, tt:2648.049\n",
      "Ep:167, loss:0.00001, loss_test:0.08013, lr:5.70e-03, fs:0.84694 (r=0.838,p=0.856),  time:15.863, tt:2664.924\n",
      "Ep:168, loss:0.00001, loss_test:0.08001, lr:5.70e-03, fs:0.86598 (r=0.848,p=0.884),  time:15.863, tt:2680.820\n",
      "##########Best model found so far##########\n",
      "Ep:169, loss:0.00001, loss_test:0.08000, lr:5.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:15.858, tt:2695.807\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00001, loss_test:0.07997, lr:5.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.860, tt:2712.091\n",
      "##########Best model found so far##########\n",
      "Ep:171, loss:0.00001, loss_test:0.07984, lr:5.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.853, tt:2726.779\n",
      "Ep:172, loss:0.00001, loss_test:0.07975, lr:5.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.853, tt:2742.503\n",
      "Ep:173, loss:0.00001, loss_test:0.07972, lr:5.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.852, tt:2758.237\n",
      "Ep:174, loss:0.00001, loss_test:0.07969, lr:5.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:15.848, tt:2773.405\n",
      "Ep:175, loss:0.00001, loss_test:0.07965, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.850, tt:2789.556\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00001, loss_test:0.07950, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.840, tt:2803.767\n",
      "Ep:177, loss:0.00001, loss_test:0.07938, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.842, tt:2819.794\n",
      "Ep:178, loss:0.00001, loss_test:0.07929, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.838, tt:2835.081\n",
      "Ep:179, loss:0.00001, loss_test:0.07920, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.834, tt:2850.060\n",
      "Ep:180, loss:0.00001, loss_test:0.07910, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.825, tt:2864.390\n",
      "Ep:181, loss:0.00001, loss_test:0.07902, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.830, tt:2880.977\n",
      "Ep:182, loss:0.00001, loss_test:0.07899, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.826, tt:2896.092\n",
      "Ep:183, loss:0.00001, loss_test:0.07892, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.826, tt:2912.055\n",
      "Ep:184, loss:0.00001, loss_test:0.07880, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.826, tt:2927.802\n",
      "Ep:185, loss:0.00001, loss_test:0.07876, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.834, tt:2945.201\n",
      "Ep:186, loss:0.00001, loss_test:0.07872, lr:5.70e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.834, tt:2960.868\n",
      "Ep:187, loss:0.00001, loss_test:0.07866, lr:5.64e-03, fs:0.87958 (r=0.848,p=0.913),  time:15.835, tt:2977.031\n",
      "Ep:188, loss:0.00001, loss_test:0.07858, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.835, tt:2992.726\n",
      "##########Best model found so far##########\n",
      "Ep:189, loss:0.00001, loss_test:0.07850, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.833, tt:3008.282\n",
      "Ep:190, loss:0.00001, loss_test:0.07842, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.834, tt:3024.245\n",
      "Ep:191, loss:0.00001, loss_test:0.07830, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.835, tt:3040.321\n",
      "Ep:192, loss:0.00001, loss_test:0.07820, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.832, tt:3055.660\n",
      "Ep:193, loss:0.00001, loss_test:0.07814, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.832, tt:3071.500\n",
      "Ep:194, loss:0.00001, loss_test:0.07812, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.830, tt:3086.883\n",
      "Ep:195, loss:0.00001, loss_test:0.07797, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.826, tt:3101.961\n",
      "Ep:196, loss:0.00001, loss_test:0.07789, lr:5.58e-03, fs:0.88421 (r=0.848,p=0.923),  time:15.827, tt:3117.909\n",
      "Ep:197, loss:0.00001, loss_test:0.07789, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.826, tt:3133.499\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:198, loss:0.00001, loss_test:0.07784, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.824, tt:3149.052\n",
      "Ep:199, loss:0.00001, loss_test:0.07772, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.823, tt:3164.550\n",
      "Ep:200, loss:0.00001, loss_test:0.07757, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.818, tt:3179.389\n",
      "Ep:201, loss:0.00001, loss_test:0.07759, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.820, tt:3195.708\n",
      "Ep:202, loss:0.00001, loss_test:0.07758, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.819, tt:3211.243\n",
      "Ep:203, loss:0.00001, loss_test:0.07750, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.827, tt:3228.682\n",
      "Ep:204, loss:0.00001, loss_test:0.07746, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.828, tt:3244.808\n",
      "Ep:205, loss:0.00001, loss_test:0.07747, lr:5.58e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.830, tt:3260.919\n",
      "Ep:206, loss:0.00001, loss_test:0.07740, lr:5.58e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.828, tt:3276.406\n",
      "Ep:207, loss:0.00001, loss_test:0.07731, lr:5.58e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.835, tt:3293.672\n",
      "Ep:208, loss:0.00001, loss_test:0.07714, lr:5.58e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.836, tt:3309.627\n",
      "Ep:209, loss:0.00001, loss_test:0.07711, lr:5.53e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.838, tt:3326.046\n",
      "Ep:210, loss:0.00001, loss_test:0.07711, lr:5.47e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.845, tt:3343.234\n",
      "Ep:211, loss:0.00001, loss_test:0.07707, lr:5.42e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.845, tt:3359.150\n",
      "Ep:212, loss:0.00001, loss_test:0.07700, lr:5.36e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.851, tt:3376.193\n",
      "Ep:213, loss:0.00001, loss_test:0.07688, lr:5.31e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.845, tt:3390.866\n",
      "Ep:214, loss:0.00001, loss_test:0.07673, lr:5.26e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.847, tt:3407.073\n",
      "Ep:215, loss:0.00001, loss_test:0.07670, lr:5.20e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.849, tt:3423.413\n",
      "Ep:216, loss:0.00001, loss_test:0.07674, lr:5.15e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.846, tt:3438.504\n",
      "Ep:217, loss:0.00001, loss_test:0.07670, lr:5.10e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.850, tt:3455.272\n",
      "Ep:218, loss:0.00001, loss_test:0.07661, lr:5.05e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.853, tt:3471.815\n",
      "Ep:219, loss:0.00001, loss_test:0.07657, lr:5.00e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.855, tt:3488.015\n",
      "Ep:220, loss:0.00001, loss_test:0.07655, lr:4.95e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.851, tt:3503.147\n",
      "Ep:221, loss:0.00001, loss_test:0.07654, lr:4.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.850, tt:3518.595\n",
      "Ep:222, loss:0.00001, loss_test:0.07655, lr:4.85e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.853, tt:3535.249\n",
      "Ep:223, loss:0.00001, loss_test:0.07653, lr:4.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.855, tt:3551.539\n",
      "Ep:224, loss:0.00001, loss_test:0.07652, lr:4.75e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.855, tt:3567.390\n",
      "Ep:225, loss:0.00001, loss_test:0.07654, lr:4.71e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.856, tt:3583.421\n",
      "Ep:226, loss:0.00001, loss_test:0.07651, lr:4.66e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.857, tt:3599.625\n",
      "Ep:227, loss:0.00001, loss_test:0.07646, lr:4.61e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.857, tt:3615.465\n",
      "Ep:228, loss:0.00001, loss_test:0.07643, lr:4.57e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.861, tt:3632.112\n",
      "Ep:229, loss:0.00001, loss_test:0.07639, lr:4.52e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.863, tt:3648.519\n",
      "Ep:230, loss:0.00001, loss_test:0.07631, lr:4.48e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.860, tt:3663.550\n",
      "Ep:231, loss:0.00001, loss_test:0.07629, lr:4.43e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.858, tt:3679.054\n",
      "Ep:232, loss:0.00001, loss_test:0.07628, lr:4.39e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.853, tt:3693.661\n",
      "Ep:233, loss:0.00001, loss_test:0.07622, lr:4.34e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.849, tt:3708.772\n",
      "Ep:234, loss:0.00001, loss_test:0.07615, lr:4.30e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.844, tt:3723.269\n",
      "Ep:235, loss:0.00001, loss_test:0.07613, lr:4.26e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.837, tt:3737.483\n",
      "Ep:236, loss:0.00001, loss_test:0.07610, lr:4.21e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.830, tt:3751.738\n",
      "Ep:237, loss:0.00001, loss_test:0.07603, lr:4.17e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.832, tt:3768.087\n",
      "Ep:238, loss:0.00001, loss_test:0.07597, lr:4.13e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.831, tt:3783.628\n",
      "Ep:239, loss:0.00001, loss_test:0.07595, lr:4.09e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.822, tt:3797.295\n",
      "Ep:240, loss:0.00001, loss_test:0.07590, lr:4.05e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.819, tt:3812.381\n",
      "Ep:241, loss:0.00001, loss_test:0.07590, lr:4.01e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.809, tt:3825.900\n",
      "Ep:242, loss:0.00001, loss_test:0.07587, lr:3.97e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.803, tt:3840.132\n",
      "Ep:243, loss:0.00001, loss_test:0.07585, lr:3.93e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.801, tt:3855.553\n",
      "Ep:244, loss:0.00001, loss_test:0.07581, lr:3.89e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.798, tt:3870.451\n",
      "Ep:245, loss:0.00001, loss_test:0.07580, lr:3.85e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.794, tt:3885.252\n",
      "Ep:246, loss:0.00001, loss_test:0.07578, lr:3.81e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.793, tt:3900.932\n",
      "Ep:247, loss:0.00001, loss_test:0.07577, lr:3.77e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.790, tt:3915.810\n",
      "Ep:248, loss:0.00001, loss_test:0.07577, lr:3.73e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.786, tt:3930.794\n",
      "Ep:249, loss:0.00001, loss_test:0.07579, lr:3.70e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.785, tt:3946.279\n",
      "Ep:250, loss:0.00001, loss_test:0.07578, lr:3.66e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.781, tt:3961.119\n",
      "Ep:251, loss:0.00001, loss_test:0.07579, lr:3.62e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.780, tt:3976.535\n",
      "Ep:252, loss:0.00001, loss_test:0.07577, lr:3.59e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.773, tt:3990.641\n",
      "Ep:253, loss:0.00001, loss_test:0.07569, lr:3.55e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.772, tt:4006.010\n",
      "Ep:254, loss:0.00001, loss_test:0.07568, lr:3.52e-03, fs:0.88889 (r=0.848,p=0.933),  time:15.763, tt:4019.617\n",
      "Ep:255, loss:0.00001, loss_test:0.07576, lr:3.48e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.757, tt:4033.851\n",
      "Ep:256, loss:0.00001, loss_test:0.07577, lr:3.45e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.756, tt:4049.195\n",
      "Ep:257, loss:0.00001, loss_test:0.07570, lr:3.41e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.754, tt:4064.575\n",
      "Ep:258, loss:0.00001, loss_test:0.07561, lr:3.38e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.750, tt:4079.306\n",
      "Ep:259, loss:0.00001, loss_test:0.07562, lr:3.34e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.749, tt:4094.702\n",
      "Ep:260, loss:0.00001, loss_test:0.07563, lr:3.31e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.747, tt:4110.068\n",
      "Ep:261, loss:0.00001, loss_test:0.07558, lr:3.28e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.744, tt:4125.001\n",
      "Ep:262, loss:0.00001, loss_test:0.07554, lr:3.24e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.737, tt:4138.829\n",
      "Ep:263, loss:0.00000, loss_test:0.07555, lr:3.21e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.734, tt:4153.878\n",
      "Ep:264, loss:0.00000, loss_test:0.07553, lr:3.18e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.730, tt:4168.473\n",
      "Ep:265, loss:0.00000, loss_test:0.07548, lr:3.15e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.725, tt:4182.813\n",
      "Ep:266, loss:0.00000, loss_test:0.07546, lr:3.12e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.721, tt:4197.635\n",
      "Ep:267, loss:0.00000, loss_test:0.07542, lr:3.09e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.722, tt:4213.426\n",
      "Ep:268, loss:0.00000, loss_test:0.07542, lr:3.05e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.720, tt:4228.585\n",
      "Ep:269, loss:0.00000, loss_test:0.07544, lr:3.02e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.716, tt:4243.399\n",
      "Ep:270, loss:0.00000, loss_test:0.07539, lr:2.99e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.713, tt:4258.192\n",
      "Ep:271, loss:0.00000, loss_test:0.07529, lr:2.96e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.711, tt:4273.314\n",
      "Ep:272, loss:0.00000, loss_test:0.07532, lr:2.93e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.707, tt:4287.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:273, loss:0.00000, loss_test:0.07537, lr:2.90e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.705, tt:4303.060\n",
      "Ep:274, loss:0.00000, loss_test:0.07532, lr:2.88e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.701, tt:4317.908\n",
      "Ep:275, loss:0.00000, loss_test:0.07527, lr:2.85e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.698, tt:4332.711\n",
      "Ep:276, loss:0.00000, loss_test:0.07532, lr:2.82e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.696, tt:4347.671\n",
      "Ep:277, loss:0.00000, loss_test:0.07533, lr:2.79e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.704, tt:4365.762\n",
      "Ep:278, loss:0.00000, loss_test:0.07528, lr:2.76e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.699, tt:4380.154\n",
      "Ep:279, loss:0.00000, loss_test:0.07527, lr:2.73e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.696, tt:4394.909\n",
      "Ep:280, loss:0.00000, loss_test:0.07528, lr:2.71e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.698, tt:4411.110\n",
      "Ep:281, loss:0.00000, loss_test:0.07528, lr:2.68e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.698, tt:4426.844\n",
      "Ep:282, loss:0.00000, loss_test:0.07525, lr:2.65e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.694, tt:4441.399\n",
      "Ep:283, loss:0.00000, loss_test:0.07522, lr:2.63e-03, fs:0.89362 (r=0.848,p=0.944),  time:15.691, tt:4456.157\n",
      "Ep:284, loss:0.00000, loss_test:0.07523, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.686, tt:4470.631\n",
      "##########Best model found so far##########\n",
      "Ep:285, loss:0.00000, loss_test:0.07526, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.683, tt:4485.304\n",
      "Ep:286, loss:0.00000, loss_test:0.07522, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.680, tt:4500.129\n",
      "Ep:287, loss:0.00000, loss_test:0.07517, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.674, tt:4514.020\n",
      "Ep:288, loss:0.00000, loss_test:0.07517, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.671, tt:4528.930\n",
      "Ep:289, loss:0.00000, loss_test:0.07520, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.670, tt:4544.236\n",
      "Ep:290, loss:0.00000, loss_test:0.07515, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.669, tt:4559.655\n",
      "Ep:291, loss:0.00000, loss_test:0.07509, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.665, tt:4574.283\n",
      "Ep:292, loss:0.00000, loss_test:0.07509, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.662, tt:4588.907\n",
      "Ep:293, loss:0.00000, loss_test:0.07513, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.657, tt:4603.113\n",
      "Ep:294, loss:0.00000, loss_test:0.07507, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.652, tt:4617.362\n",
      "Ep:295, loss:0.00000, loss_test:0.07499, lr:2.60e-03, fs:0.89840 (r=0.848,p=0.955),  time:15.646, tt:4631.277\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14328, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.919, tt:14.919\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14289, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:16.883, tt:33.765\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.14227, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:18.243, tt:54.730\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.14135, lr:1.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:19.079, tt:76.318\n",
      "Ep:4, loss:0.00004, loss_test:0.14003, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:19.121, tt:95.605\n",
      "Ep:5, loss:0.00004, loss_test:0.13818, lr:1.00e-02, fs:0.65000 (r=0.919,p=0.503),  time:19.327, tt:115.959\n",
      "Ep:6, loss:0.00004, loss_test:0.13624, lr:1.00e-02, fs:0.61423 (r=0.828,p=0.488),  time:19.622, tt:137.353\n",
      "Ep:7, loss:0.00004, loss_test:0.13478, lr:1.00e-02, fs:0.61847 (r=0.778,p=0.513),  time:19.689, tt:157.512\n",
      "Ep:8, loss:0.00003, loss_test:0.13422, lr:1.00e-02, fs:0.58772 (r=0.677,p=0.519),  time:19.804, tt:178.236\n",
      "Ep:9, loss:0.00003, loss_test:0.13630, lr:1.00e-02, fs:0.61972 (r=0.667,p=0.579),  time:19.868, tt:198.679\n",
      "Ep:10, loss:0.00003, loss_test:0.13917, lr:1.00e-02, fs:0.64390 (r=0.667,p=0.623),  time:19.889, tt:218.778\n",
      "Ep:11, loss:0.00003, loss_test:0.14038, lr:1.00e-02, fs:0.64677 (r=0.657,p=0.637),  time:19.954, tt:239.449\n",
      "Ep:12, loss:0.00003, loss_test:0.13943, lr:1.00e-02, fs:0.63415 (r=0.657,p=0.613),  time:20.008, tt:260.105\n",
      "Ep:13, loss:0.00003, loss_test:0.13739, lr:1.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:20.050, tt:280.700\n",
      "Ep:14, loss:0.00003, loss_test:0.13558, lr:9.90e-03, fs:0.62385 (r=0.687,p=0.571),  time:19.977, tt:299.655\n",
      "Ep:15, loss:0.00003, loss_test:0.13419, lr:9.80e-03, fs:0.62100 (r=0.687,p=0.567),  time:20.031, tt:320.494\n",
      "Ep:16, loss:0.00003, loss_test:0.13326, lr:9.70e-03, fs:0.63850 (r=0.687,p=0.596),  time:20.216, tt:343.665\n",
      "Ep:17, loss:0.00003, loss_test:0.13299, lr:9.61e-03, fs:0.65072 (r=0.687,p=0.618),  time:20.213, tt:363.833\n",
      "Ep:18, loss:0.00003, loss_test:0.13319, lr:9.51e-03, fs:0.63054 (r=0.646,p=0.615),  time:20.225, tt:384.276\n",
      "Ep:19, loss:0.00003, loss_test:0.13327, lr:9.41e-03, fs:0.64000 (r=0.646,p=0.634),  time:20.173, tt:403.459\n",
      "Ep:20, loss:0.00003, loss_test:0.13201, lr:9.32e-03, fs:0.63682 (r=0.646,p=0.627),  time:20.192, tt:424.030\n",
      "Ep:21, loss:0.00003, loss_test:0.12979, lr:9.23e-03, fs:0.63054 (r=0.646,p=0.615),  time:20.214, tt:444.701\n",
      "Ep:22, loss:0.00003, loss_test:0.12784, lr:9.14e-03, fs:0.62439 (r=0.646,p=0.604),  time:20.223, tt:465.119\n",
      "Ep:23, loss:0.00003, loss_test:0.12663, lr:9.04e-03, fs:0.62802 (r=0.657,p=0.602),  time:20.228, tt:485.469\n",
      "Ep:24, loss:0.00003, loss_test:0.12599, lr:8.95e-03, fs:0.62439 (r=0.646,p=0.604),  time:20.250, tt:506.261\n",
      "Ep:25, loss:0.00002, loss_test:0.12588, lr:8.86e-03, fs:0.63682 (r=0.646,p=0.627),  time:20.271, tt:527.051\n",
      "Ep:26, loss:0.00002, loss_test:0.12531, lr:8.78e-03, fs:0.64975 (r=0.646,p=0.653),  time:20.297, tt:548.020\n",
      "Ep:27, loss:0.00002, loss_test:0.12400, lr:8.69e-03, fs:0.64975 (r=0.646,p=0.653),  time:20.285, tt:567.977\n",
      "Ep:28, loss:0.00002, loss_test:0.12219, lr:8.60e-03, fs:0.64975 (r=0.646,p=0.653),  time:20.277, tt:588.035\n",
      "Ep:29, loss:0.00002, loss_test:0.12061, lr:8.51e-03, fs:0.64356 (r=0.657,p=0.631),  time:20.216, tt:606.466\n",
      "Ep:30, loss:0.00002, loss_test:0.11960, lr:8.43e-03, fs:0.65000 (r=0.657,p=0.644),  time:20.199, tt:626.169\n",
      "Ep:31, loss:0.00002, loss_test:0.11912, lr:8.35e-03, fs:0.65327 (r=0.657,p=0.650),  time:20.190, tt:646.092\n",
      "Ep:32, loss:0.00002, loss_test:0.11831, lr:8.26e-03, fs:0.65641 (r=0.646,p=0.667),  time:20.169, tt:665.580\n",
      "Ep:33, loss:0.00002, loss_test:0.11666, lr:8.18e-03, fs:0.65641 (r=0.646,p=0.667),  time:20.167, tt:685.690\n",
      "Ep:34, loss:0.00002, loss_test:0.11502, lr:8.10e-03, fs:0.65641 (r=0.646,p=0.667),  time:20.164, tt:705.739\n",
      "Ep:35, loss:0.00002, loss_test:0.11398, lr:8.02e-03, fs:0.65979 (r=0.646,p=0.674),  time:20.156, tt:725.632\n",
      "Ep:36, loss:0.00002, loss_test:0.11337, lr:7.94e-03, fs:0.65979 (r=0.646,p=0.674),  time:20.151, tt:745.595\n",
      "Ep:37, loss:0.00002, loss_test:0.11270, lr:7.86e-03, fs:0.66667 (r=0.646,p=0.688),  time:20.179, tt:766.819\n",
      "Ep:38, loss:0.00002, loss_test:0.11174, lr:7.78e-03, fs:0.67358 (r=0.657,p=0.691),  time:20.153, tt:785.954\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.11052, lr:7.78e-03, fs:0.71642 (r=0.727,p=0.706),  time:20.165, tt:806.617\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10957, lr:7.78e-03, fs:0.72906 (r=0.747,p=0.712),  time:20.146, tt:825.972\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.10881, lr:7.78e-03, fs:0.73632 (r=0.747,p=0.725),  time:20.131, tt:845.508\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10816, lr:7.78e-03, fs:0.74627 (r=0.758,p=0.735),  time:20.116, tt:864.998\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.10717, lr:7.78e-03, fs:0.74627 (r=0.758,p=0.735),  time:20.109, tt:884.801\n",
      "Ep:44, loss:0.00002, loss_test:0.10629, lr:7.78e-03, fs:0.75122 (r=0.778,p=0.726),  time:20.117, tt:905.254\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:45, loss:0.00002, loss_test:0.10569, lr:7.78e-03, fs:0.76098 (r=0.788,p=0.736),  time:20.135, tt:926.220\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.10538, lr:7.78e-03, fs:0.75377 (r=0.758,p=0.750),  time:20.127, tt:945.957\n",
      "Ep:47, loss:0.00002, loss_test:0.10480, lr:7.78e-03, fs:0.75377 (r=0.758,p=0.750),  time:20.117, tt:965.620\n",
      "Ep:48, loss:0.00002, loss_test:0.10397, lr:7.78e-03, fs:0.77612 (r=0.788,p=0.765),  time:20.083, tt:984.068\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.10328, lr:7.78e-03, fs:0.77612 (r=0.788,p=0.765),  time:20.066, tt:1003.318\n",
      "Ep:50, loss:0.00002, loss_test:0.10276, lr:7.78e-03, fs:0.77000 (r=0.778,p=0.762),  time:20.060, tt:1023.040\n",
      "Ep:51, loss:0.00002, loss_test:0.10224, lr:7.78e-03, fs:0.78218 (r=0.798,p=0.767),  time:20.041, tt:1042.135\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.10185, lr:7.78e-03, fs:0.79803 (r=0.818,p=0.779),  time:20.045, tt:1062.377\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.10162, lr:7.78e-03, fs:0.79000 (r=0.798,p=0.782),  time:20.039, tt:1082.122\n",
      "Ep:54, loss:0.00001, loss_test:0.10109, lr:7.78e-03, fs:0.78392 (r=0.788,p=0.780),  time:20.019, tt:1101.049\n",
      "Ep:55, loss:0.00001, loss_test:0.10051, lr:7.78e-03, fs:0.79592 (r=0.788,p=0.804),  time:20.009, tt:1120.499\n",
      "Ep:56, loss:0.00001, loss_test:0.09994, lr:7.78e-03, fs:0.79592 (r=0.788,p=0.804),  time:20.022, tt:1141.257\n",
      "Ep:57, loss:0.00001, loss_test:0.09948, lr:7.78e-03, fs:0.79397 (r=0.798,p=0.790),  time:20.015, tt:1160.857\n",
      "Ep:58, loss:0.00001, loss_test:0.09926, lr:7.78e-03, fs:0.80203 (r=0.798,p=0.806),  time:20.020, tt:1181.205\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.09888, lr:7.78e-03, fs:0.80203 (r=0.798,p=0.806),  time:20.015, tt:1200.918\n",
      "Ep:60, loss:0.00001, loss_test:0.09823, lr:7.78e-03, fs:0.79798 (r=0.798,p=0.798),  time:20.009, tt:1220.534\n",
      "Ep:61, loss:0.00001, loss_test:0.09790, lr:7.78e-03, fs:0.81026 (r=0.798,p=0.823),  time:20.035, tt:1242.172\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.09722, lr:7.78e-03, fs:0.81026 (r=0.798,p=0.823),  time:20.046, tt:1262.883\n",
      "Ep:63, loss:0.00001, loss_test:0.09658, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:20.065, tt:1284.178\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.09657, lr:7.78e-03, fs:0.82474 (r=0.808,p=0.842),  time:20.073, tt:1304.770\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.09641, lr:7.78e-03, fs:0.81865 (r=0.798,p=0.840),  time:20.076, tt:1325.012\n",
      "Ep:66, loss:0.00001, loss_test:0.09569, lr:7.78e-03, fs:0.83673 (r=0.828,p=0.845),  time:20.083, tt:1345.571\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.09522, lr:7.78e-03, fs:0.83673 (r=0.828,p=0.845),  time:20.091, tt:1366.210\n",
      "Ep:68, loss:0.00001, loss_test:0.09495, lr:7.78e-03, fs:0.82292 (r=0.798,p=0.849),  time:20.101, tt:1386.969\n",
      "Ep:69, loss:0.00001, loss_test:0.09451, lr:7.78e-03, fs:0.82902 (r=0.808,p=0.851),  time:20.115, tt:1408.055\n",
      "Ep:70, loss:0.00001, loss_test:0.09410, lr:7.78e-03, fs:0.82902 (r=0.808,p=0.851),  time:20.136, tt:1429.654\n",
      "Ep:71, loss:0.00001, loss_test:0.09438, lr:7.78e-03, fs:0.83770 (r=0.808,p=0.870),  time:20.146, tt:1450.528\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.09412, lr:7.78e-03, fs:0.83770 (r=0.808,p=0.870),  time:20.161, tt:1471.769\n",
      "Ep:73, loss:0.00001, loss_test:0.09348, lr:7.78e-03, fs:0.83333 (r=0.808,p=0.860),  time:20.155, tt:1491.506\n",
      "Ep:74, loss:0.00001, loss_test:0.09369, lr:7.78e-03, fs:0.83158 (r=0.798,p=0.868),  time:20.140, tt:1510.496\n",
      "Ep:75, loss:0.00001, loss_test:0.09358, lr:7.78e-03, fs:0.82979 (r=0.788,p=0.876),  time:20.141, tt:1530.725\n",
      "Ep:76, loss:0.00001, loss_test:0.09316, lr:7.78e-03, fs:0.83333 (r=0.808,p=0.860),  time:20.134, tt:1550.353\n",
      "Ep:77, loss:0.00001, loss_test:0.09318, lr:7.78e-03, fs:0.82540 (r=0.788,p=0.867),  time:20.124, tt:1569.680\n",
      "Ep:78, loss:0.00001, loss_test:0.09305, lr:7.78e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.123, tt:1589.734\n",
      "Ep:79, loss:0.00001, loss_test:0.09306, lr:7.78e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.126, tt:1610.070\n",
      "Ep:80, loss:0.00001, loss_test:0.09308, lr:7.78e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.117, tt:1629.466\n",
      "Ep:81, loss:0.00001, loss_test:0.09312, lr:7.78e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.123, tt:1650.067\n",
      "Ep:82, loss:0.00001, loss_test:0.09314, lr:7.78e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.116, tt:1669.658\n",
      "Ep:83, loss:0.00001, loss_test:0.09343, lr:7.70e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.120, tt:1690.110\n",
      "Ep:84, loss:0.00001, loss_test:0.09356, lr:7.62e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.128, tt:1710.851\n",
      "Ep:85, loss:0.00001, loss_test:0.09372, lr:7.55e-03, fs:0.80220 (r=0.737,p=0.880),  time:20.130, tt:1731.142\n",
      "Ep:86, loss:0.00001, loss_test:0.09374, lr:7.47e-03, fs:0.80220 (r=0.737,p=0.880),  time:20.131, tt:1751.373\n",
      "Ep:87, loss:0.00001, loss_test:0.09400, lr:7.40e-03, fs:0.78889 (r=0.717,p=0.877),  time:20.124, tt:1770.889\n",
      "Ep:88, loss:0.00001, loss_test:0.09437, lr:7.32e-03, fs:0.78652 (r=0.707,p=0.886),  time:20.130, tt:1791.532\n",
      "Ep:89, loss:0.00001, loss_test:0.09418, lr:7.25e-03, fs:0.78212 (r=0.707,p=0.875),  time:20.141, tt:1812.695\n",
      "Ep:90, loss:0.00001, loss_test:0.09414, lr:7.18e-03, fs:0.78212 (r=0.707,p=0.875),  time:20.138, tt:1832.594\n",
      "Ep:91, loss:0.00001, loss_test:0.09440, lr:7.11e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.134, tt:1852.293\n",
      "Ep:92, loss:0.00001, loss_test:0.09440, lr:7.03e-03, fs:0.77528 (r=0.697,p=0.873),  time:20.132, tt:1872.262\n",
      "Ep:93, loss:0.00001, loss_test:0.09486, lr:6.96e-03, fs:0.77273 (r=0.687,p=0.883),  time:20.126, tt:1891.881\n",
      "Ep:94, loss:0.00001, loss_test:0.09455, lr:6.89e-03, fs:0.77273 (r=0.687,p=0.883),  time:20.138, tt:1913.127\n",
      "Ep:95, loss:0.00001, loss_test:0.09484, lr:6.83e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.137, tt:1933.152\n",
      "Ep:96, loss:0.00001, loss_test:0.09489, lr:6.76e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.139, tt:1953.511\n",
      "Ep:97, loss:0.00001, loss_test:0.09392, lr:6.69e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.141, tt:1973.799\n",
      "Ep:98, loss:0.00001, loss_test:0.09564, lr:6.62e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.143, tt:1994.138\n",
      "Ep:99, loss:0.00001, loss_test:0.09406, lr:6.56e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.150, tt:2015.028\n",
      "Ep:100, loss:0.00001, loss_test:0.09340, lr:6.49e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.157, tt:2035.843\n",
      "Ep:101, loss:0.00001, loss_test:0.09511, lr:6.43e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.160, tt:2056.351\n",
      "Ep:102, loss:0.00001, loss_test:0.09414, lr:6.36e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.161, tt:2076.555\n",
      "Ep:103, loss:0.00001, loss_test:0.09264, lr:6.30e-03, fs:0.77714 (r=0.687,p=0.895),  time:20.166, tt:2097.230\n",
      "Ep:104, loss:0.00001, loss_test:0.09505, lr:6.24e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.157, tt:2116.511\n",
      "Ep:105, loss:0.00001, loss_test:0.09444, lr:6.17e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.141, tt:2134.915\n",
      "Ep:106, loss:0.00001, loss_test:0.09237, lr:6.11e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.138, tt:2154.778\n",
      "Ep:107, loss:0.00001, loss_test:0.09512, lr:6.05e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.154, tt:2176.626\n",
      "Ep:108, loss:0.00001, loss_test:0.09460, lr:5.99e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.164, tt:2197.892\n",
      "Ep:109, loss:0.00001, loss_test:0.09264, lr:5.93e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.169, tt:2218.612\n",
      "Ep:110, loss:0.00001, loss_test:0.09523, lr:5.87e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.171, tt:2238.939\n",
      "Ep:111, loss:0.00001, loss_test:0.09483, lr:5.81e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.169, tt:2258.902\n",
      "Ep:112, loss:0.00001, loss_test:0.09287, lr:5.75e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.171, tt:2279.325\n",
      "Ep:113, loss:0.00001, loss_test:0.09446, lr:5.70e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.160, tt:2298.194\n",
      "Ep:114, loss:0.00001, loss_test:0.09432, lr:5.64e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.160, tt:2318.424\n",
      "Ep:115, loss:0.00001, loss_test:0.09290, lr:5.58e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.157, tt:2338.229\n",
      "Ep:116, loss:0.00001, loss_test:0.09410, lr:5.53e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.158, tt:2358.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:117, loss:0.00001, loss_test:0.09409, lr:5.47e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.137, tt:2376.195\n",
      "Ep:118, loss:0.00001, loss_test:0.09287, lr:5.42e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.144, tt:2397.162\n",
      "Ep:119, loss:0.00001, loss_test:0.09365, lr:5.36e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.134, tt:2416.114\n",
      "Ep:120, loss:0.00001, loss_test:0.09328, lr:5.31e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.138, tt:2436.701\n",
      "Ep:121, loss:0.00001, loss_test:0.09269, lr:5.26e-03, fs:0.78161 (r=0.687,p=0.907),  time:20.130, tt:2455.845\n",
      "Ep:122, loss:0.00001, loss_test:0.09361, lr:5.20e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.119, tt:2474.617\n",
      "Ep:123, loss:0.00001, loss_test:0.09290, lr:5.15e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.117, tt:2494.528\n",
      "Ep:124, loss:0.00000, loss_test:0.09299, lr:5.10e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.117, tt:2514.671\n",
      "Ep:125, loss:0.00000, loss_test:0.09326, lr:5.05e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.119, tt:2534.971\n",
      "Ep:126, loss:0.00000, loss_test:0.09233, lr:5.00e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.120, tt:2555.211\n",
      "Ep:127, loss:0.00000, loss_test:0.09303, lr:4.95e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.123, tt:2575.747\n",
      "Ep:128, loss:0.00000, loss_test:0.09277, lr:4.90e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.117, tt:2595.052\n",
      "Ep:129, loss:0.00000, loss_test:0.09234, lr:4.85e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.111, tt:2614.371\n",
      "Ep:130, loss:0.00000, loss_test:0.09309, lr:4.80e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.110, tt:2634.350\n",
      "Ep:131, loss:0.00000, loss_test:0.09272, lr:4.75e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.107, tt:2654.080\n",
      "Ep:132, loss:0.00000, loss_test:0.09215, lr:4.71e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.101, tt:2673.407\n",
      "Ep:133, loss:0.00000, loss_test:0.09290, lr:4.66e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.095, tt:2692.665\n",
      "Ep:134, loss:0.00000, loss_test:0.09237, lr:4.61e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.088, tt:2711.919\n",
      "Ep:135, loss:0.00000, loss_test:0.09228, lr:4.57e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.076, tt:2730.335\n",
      "Ep:136, loss:0.00000, loss_test:0.09237, lr:4.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.070, tt:2749.598\n",
      "Ep:137, loss:0.00000, loss_test:0.09238, lr:4.48e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.067, tt:2769.313\n",
      "Ep:138, loss:0.00000, loss_test:0.09228, lr:4.43e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.063, tt:2788.708\n",
      "Ep:139, loss:0.00000, loss_test:0.09239, lr:4.39e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.075, tt:2810.548\n",
      "Ep:140, loss:0.00000, loss_test:0.09218, lr:4.34e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.078, tt:2830.932\n",
      "Ep:141, loss:0.00000, loss_test:0.09232, lr:4.30e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.073, tt:2850.351\n",
      "Ep:142, loss:0.00000, loss_test:0.09254, lr:4.26e-03, fs:0.79070 (r=0.687,p=0.932),  time:20.066, tt:2869.495\n",
      "Ep:143, loss:0.00000, loss_test:0.09209, lr:4.21e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.066, tt:2889.562\n",
      "Ep:144, loss:0.00000, loss_test:0.09246, lr:4.17e-03, fs:0.78613 (r=0.687,p=0.919),  time:20.069, tt:2909.948\n",
      "Ep:145, loss:0.00000, loss_test:0.09284, lr:4.13e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.068, tt:2929.907\n",
      "Ep:146, loss:0.00000, loss_test:0.09233, lr:4.09e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.065, tt:2949.576\n",
      "Ep:147, loss:0.00000, loss_test:0.09246, lr:4.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.066, tt:2969.735\n",
      "Ep:148, loss:0.00000, loss_test:0.09281, lr:4.01e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.062, tt:2989.234\n",
      "Ep:149, loss:0.00000, loss_test:0.09255, lr:3.97e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.058, tt:3008.710\n",
      "Ep:150, loss:0.00000, loss_test:0.09249, lr:3.93e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.066, tt:3030.037\n",
      "Ep:151, loss:0.00000, loss_test:0.09296, lr:3.89e-03, fs:0.77193 (r=0.667,p=0.917),  time:20.065, tt:3049.848\n",
      "Ep:152, loss:0.00000, loss_test:0.09285, lr:3.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:20.070, tt:3070.708\n",
      "Ep:153, loss:0.00000, loss_test:0.09278, lr:3.81e-03, fs:0.77907 (r=0.677,p=0.918),  time:20.065, tt:3090.068\n",
      "Ep:154, loss:0.00000, loss_test:0.09323, lr:3.77e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.069, tt:3110.642\n",
      "Ep:155, loss:0.00000, loss_test:0.09308, lr:3.73e-03, fs:0.78363 (r=0.677,p=0.931),  time:20.067, tt:3130.437\n",
      "Ep:156, loss:0.00000, loss_test:0.09281, lr:3.70e-03, fs:0.77193 (r=0.667,p=0.917),  time:20.066, tt:3150.415\n",
      "Ep:157, loss:0.00000, loss_test:0.09329, lr:3.66e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.066, tt:3170.442\n",
      "Ep:158, loss:0.00000, loss_test:0.09341, lr:3.62e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.063, tt:3190.017\n",
      "Ep:159, loss:0.00000, loss_test:0.09304, lr:3.59e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.052, tt:3208.240\n",
      "Ep:160, loss:0.00000, loss_test:0.09333, lr:3.55e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.052, tt:3228.346\n",
      "Ep:161, loss:0.00000, loss_test:0.09343, lr:3.52e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.044, tt:3247.137\n",
      "Ep:162, loss:0.00000, loss_test:0.09310, lr:3.48e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.033, tt:3265.409\n",
      "Ep:163, loss:0.00000, loss_test:0.09370, lr:3.45e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.027, tt:3284.355\n",
      "Ep:164, loss:0.00000, loss_test:0.09342, lr:3.41e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.018, tt:3302.919\n",
      "Ep:165, loss:0.00000, loss_test:0.09327, lr:3.38e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.012, tt:3321.958\n",
      "Ep:166, loss:0.00000, loss_test:0.09367, lr:3.34e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.008, tt:3341.284\n",
      "Ep:167, loss:0.00000, loss_test:0.09352, lr:3.31e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.002, tt:3360.339\n",
      "Ep:168, loss:0.00000, loss_test:0.09303, lr:3.28e-03, fs:0.77647 (r=0.667,p=0.930),  time:20.001, tt:3380.171\n",
      "Ep:169, loss:0.00000, loss_test:0.09400, lr:3.24e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.998, tt:3399.687\n",
      "Ep:170, loss:0.00000, loss_test:0.09405, lr:3.21e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.989, tt:3418.134\n",
      "Ep:171, loss:0.00000, loss_test:0.09338, lr:3.18e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.976, tt:3435.885\n",
      "Ep:172, loss:0.00000, loss_test:0.09356, lr:3.15e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.962, tt:3453.417\n",
      "Ep:173, loss:0.00000, loss_test:0.09378, lr:3.12e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.957, tt:3472.536\n",
      "Ep:174, loss:0.00000, loss_test:0.09366, lr:3.09e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.954, tt:3492.023\n",
      "Ep:175, loss:0.00000, loss_test:0.09362, lr:3.05e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.959, tt:3512.854\n",
      "Ep:176, loss:0.00000, loss_test:0.09403, lr:3.02e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.961, tt:3533.173\n",
      "Ep:177, loss:0.00000, loss_test:0.09400, lr:2.99e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.953, tt:3551.583\n",
      "Ep:178, loss:0.00000, loss_test:0.09375, lr:2.96e-03, fs:0.78824 (r=0.677,p=0.944),  time:19.947, tt:3570.428\n",
      "Ep:179, loss:0.00000, loss_test:0.09378, lr:2.93e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.937, tt:3588.635\n",
      "Ep:180, loss:0.00000, loss_test:0.09445, lr:2.90e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.930, tt:3607.335\n",
      "Ep:181, loss:0.00000, loss_test:0.09432, lr:2.88e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.926, tt:3626.478\n",
      "Ep:182, loss:0.00000, loss_test:0.09380, lr:2.85e-03, fs:0.77647 (r=0.667,p=0.930),  time:19.923, tt:3645.878\n",
      "Ep:183, loss:0.00000, loss_test:0.09414, lr:2.82e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.920, tt:3665.198\n",
      "Ep:184, loss:0.00000, loss_test:0.09446, lr:2.79e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.924, tt:3685.861\n",
      "Ep:185, loss:0.00000, loss_test:0.09437, lr:2.76e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.920, tt:3705.151\n",
      "Ep:186, loss:0.00000, loss_test:0.09415, lr:2.73e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.922, tt:3725.418\n",
      "Ep:187, loss:0.00000, loss_test:0.09457, lr:2.71e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.916, tt:3744.286\n",
      "Ep:188, loss:0.00000, loss_test:0.09456, lr:2.68e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.912, tt:3763.452\n",
      "Ep:189, loss:0.00000, loss_test:0.09418, lr:2.65e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.913, tt:3783.396\n",
      "Ep:190, loss:0.00000, loss_test:0.09463, lr:2.63e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.906, tt:3802.056\n",
      "Ep:191, loss:0.00000, loss_test:0.09460, lr:2.60e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.903, tt:3821.367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:192, loss:0.00000, loss_test:0.09422, lr:2.57e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.907, tt:3842.136\n",
      "Ep:193, loss:0.00000, loss_test:0.09467, lr:2.55e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.896, tt:3859.877\n",
      "Ep:194, loss:0.00000, loss_test:0.09463, lr:2.52e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.897, tt:3879.827\n",
      "Ep:195, loss:0.00000, loss_test:0.09419, lr:2.50e-03, fs:0.78107 (r=0.667,p=0.943),  time:19.892, tt:3898.851\n",
      "Ep:196, loss:0.00000, loss_test:0.09479, lr:2.47e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.893, tt:3918.851\n",
      "Ep:197, loss:0.00000, loss_test:0.09482, lr:2.45e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.898, tt:3939.817\n",
      "Ep:198, loss:0.00000, loss_test:0.09435, lr:2.42e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.895, tt:3959.080\n",
      "Ep:199, loss:0.00000, loss_test:0.09461, lr:2.40e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.886, tt:3977.227\n",
      "Ep:200, loss:0.00000, loss_test:0.09472, lr:2.38e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.881, tt:3996.119\n",
      "Ep:201, loss:0.00000, loss_test:0.09436, lr:2.35e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.885, tt:4016.698\n",
      "Ep:202, loss:0.00000, loss_test:0.09455, lr:2.33e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.878, tt:4035.213\n",
      "Ep:203, loss:0.00000, loss_test:0.09476, lr:2.31e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.873, tt:4054.149\n",
      "Ep:204, loss:0.00000, loss_test:0.09444, lr:2.28e-03, fs:0.78571 (r=0.667,p=0.957),  time:19.875, tt:4074.445\n",
      "Ep:205, loss:0.00000, loss_test:0.09484, lr:2.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.869, tt:4093.099\n",
      "Ep:206, loss:0.00000, loss_test:0.09468, lr:2.24e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.857, tt:4110.355\n",
      "Ep:207, loss:0.00000, loss_test:0.09465, lr:2.21e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.857, tt:4130.335\n",
      "Ep:208, loss:0.00000, loss_test:0.09468, lr:2.19e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.861, tt:4151.049\n",
      "Ep:209, loss:0.00000, loss_test:0.09468, lr:2.17e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.869, tt:4172.436\n",
      "Ep:210, loss:0.00000, loss_test:0.09478, lr:2.15e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.870, tt:4192.611\n",
      "Ep:211, loss:0.00000, loss_test:0.09473, lr:2.13e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.873, tt:4213.094\n",
      "Ep:212, loss:0.00000, loss_test:0.09474, lr:2.11e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.874, tt:4233.149\n",
      "Ep:213, loss:0.00000, loss_test:0.09490, lr:2.08e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.872, tt:4252.657\n",
      "Ep:214, loss:0.00000, loss_test:0.09473, lr:2.06e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.872, tt:4272.484\n",
      "Ep:215, loss:0.00000, loss_test:0.09478, lr:2.04e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.874, tt:4292.865\n",
      "Ep:216, loss:0.00000, loss_test:0.09533, lr:2.02e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.876, tt:4313.109\n",
      "Ep:217, loss:0.00000, loss_test:0.09511, lr:2.00e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.892, tt:4336.360\n",
      "Ep:218, loss:0.00000, loss_test:0.09454, lr:1.98e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.896, tt:4357.278\n",
      "Ep:219, loss:0.00000, loss_test:0.09520, lr:1.96e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.897, tt:4377.313\n",
      "Ep:220, loss:0.00000, loss_test:0.09534, lr:1.94e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.896, tt:4396.912\n",
      "Ep:221, loss:0.00000, loss_test:0.09488, lr:1.92e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.893, tt:4416.303\n",
      "Ep:222, loss:0.00000, loss_test:0.09470, lr:1.90e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.894, tt:4436.370\n",
      "Ep:223, loss:0.00000, loss_test:0.09527, lr:1.89e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.895, tt:4456.537\n",
      "Ep:224, loss:0.00000, loss_test:0.09525, lr:1.87e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.891, tt:4475.488\n",
      "Ep:225, loss:0.00000, loss_test:0.09477, lr:1.85e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.893, tt:4495.772\n",
      "Ep:226, loss:0.00000, loss_test:0.09532, lr:1.83e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.896, tt:4516.295\n",
      "Ep:227, loss:0.00000, loss_test:0.09535, lr:1.81e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.903, tt:4537.823\n",
      "Ep:228, loss:0.00000, loss_test:0.09508, lr:1.79e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.902, tt:4557.472\n",
      "Ep:229, loss:0.00000, loss_test:0.09494, lr:1.78e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.903, tt:4577.647\n",
      "Ep:230, loss:0.00000, loss_test:0.09521, lr:1.76e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.905, tt:4598.042\n",
      "Ep:231, loss:0.00000, loss_test:0.09528, lr:1.74e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.896, tt:4615.826\n",
      "Ep:232, loss:0.00000, loss_test:0.09501, lr:1.72e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.894, tt:4635.201\n",
      "Ep:233, loss:0.00000, loss_test:0.09503, lr:1.71e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.893, tt:4654.856\n",
      "Ep:234, loss:0.00000, loss_test:0.09537, lr:1.69e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.894, tt:4675.114\n",
      "Ep:235, loss:0.00000, loss_test:0.09523, lr:1.67e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.897, tt:4695.753\n",
      "Ep:236, loss:0.00000, loss_test:0.09488, lr:1.65e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.895, tt:4715.213\n",
      "Ep:237, loss:0.00000, loss_test:0.09544, lr:1.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.891, tt:4734.111\n",
      "Ep:238, loss:0.00000, loss_test:0.09561, lr:1.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.893, tt:4754.321\n",
      "Ep:239, loss:0.00000, loss_test:0.09540, lr:1.61e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.896, tt:4775.132\n",
      "Ep:240, loss:0.00000, loss_test:0.09507, lr:1.59e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.897, tt:4795.175\n",
      "Ep:241, loss:0.00000, loss_test:0.09525, lr:1.57e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.902, tt:4816.170\n",
      "Ep:242, loss:0.00000, loss_test:0.09547, lr:1.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.904, tt:4836.625\n",
      "Ep:243, loss:0.00000, loss_test:0.09540, lr:1.54e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.904, tt:4856.548\n",
      "Ep:244, loss:0.00000, loss_test:0.09528, lr:1.53e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.905, tt:4876.630\n",
      "Ep:245, loss:0.00000, loss_test:0.09544, lr:1.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.902, tt:4895.914\n",
      "Ep:246, loss:0.00000, loss_test:0.09545, lr:1.50e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.903, tt:4916.007\n",
      "Ep:247, loss:0.00000, loss_test:0.09530, lr:1.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.903, tt:4935.996\n",
      "Ep:248, loss:0.00000, loss_test:0.09538, lr:1.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.905, tt:4956.239\n",
      "Ep:249, loss:0.00000, loss_test:0.09542, lr:1.45e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.917, tt:4979.299\n",
      "Ep:250, loss:0.00000, loss_test:0.09526, lr:1.44e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.910, tt:4997.338\n",
      "Ep:251, loss:0.00000, loss_test:0.09537, lr:1.42e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.906, tt:5016.345\n",
      "Ep:252, loss:0.00000, loss_test:0.09539, lr:1.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.906, tt:5036.112\n",
      "Ep:253, loss:0.00000, loss_test:0.09518, lr:1.39e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.902, tt:5054.984\n",
      "Ep:254, loss:0.00000, loss_test:0.09540, lr:1.38e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.904, tt:5075.634\n",
      "Ep:255, loss:0.00000, loss_test:0.09543, lr:1.37e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.902, tt:5095.012\n",
      "Ep:256, loss:0.00000, loss_test:0.09531, lr:1.35e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.904, tt:5115.310\n",
      "Ep:257, loss:0.00000, loss_test:0.09542, lr:1.34e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.904, tt:5135.262\n",
      "Ep:258, loss:0.00000, loss_test:0.09540, lr:1.33e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.903, tt:5154.864\n",
      "Ep:259, loss:0.00000, loss_test:0.09527, lr:1.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.902, tt:5174.463\n",
      "Ep:260, loss:0.00000, loss_test:0.09539, lr:1.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.905, tt:5195.167\n",
      "Ep:261, loss:0.00000, loss_test:0.09549, lr:1.29e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.904, tt:5214.953\n",
      "Ep:262, loss:0.00000, loss_test:0.09535, lr:1.27e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.898, tt:5233.260\n",
      "Ep:263, loss:0.00000, loss_test:0.09542, lr:1.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.901, tt:5253.811\n",
      "Ep:264, loss:0.00000, loss_test:0.09550, lr:1.25e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.906, tt:5275.002\n",
      "Ep:265, loss:0.00000, loss_test:0.09533, lr:1.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.905, tt:5294.717\n",
      "Ep:266, loss:0.00000, loss_test:0.09548, lr:1.22e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.906, tt:5314.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:267, loss:0.00000, loss_test:0.09552, lr:1.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.904, tt:5334.174\n",
      "Ep:268, loss:0.00000, loss_test:0.09535, lr:1.20e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.905, tt:5354.457\n",
      "Ep:269, loss:0.00000, loss_test:0.09554, lr:1.19e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.904, tt:5374.154\n",
      "Ep:270, loss:0.00000, loss_test:0.09550, lr:1.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.907, tt:5394.814\n",
      "Ep:271, loss:0.00000, loss_test:0.09533, lr:1.16e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.909, tt:5415.281\n",
      "Ep:272, loss:0.00000, loss_test:0.09546, lr:1.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.913, tt:5436.132\n",
      "Ep:273, loss:0.00000, loss_test:0.09559, lr:1.14e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.913, tt:5456.159\n",
      "Ep:274, loss:0.00000, loss_test:0.09544, lr:1.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.912, tt:5475.818\n",
      "Ep:275, loss:0.00000, loss_test:0.09540, lr:1.12e-03, fs:0.77576 (r=0.646,p=0.970),  time:19.916, tt:5496.801\n",
      "Ep:276, loss:0.00000, loss_test:0.09553, lr:1.11e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.918, tt:5517.252\n",
      "Ep:277, loss:0.00000, loss_test:0.09546, lr:1.10e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.916, tt:5536.635\n",
      "Ep:278, loss:0.00000, loss_test:0.09547, lr:1.08e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.914, tt:5556.098\n",
      "Ep:279, loss:0.00000, loss_test:0.09553, lr:1.07e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.913, tt:5575.779\n",
      "Ep:280, loss:0.00000, loss_test:0.09545, lr:1.06e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.912, tt:5595.188\n",
      "Ep:281, loss:0.00000, loss_test:0.09560, lr:1.05e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.927, tt:5619.315\n",
      "Ep:282, loss:0.00000, loss_test:0.09550, lr:1.04e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.927, tt:5639.229\n",
      "Ep:283, loss:0.00000, loss_test:0.09547, lr:1.03e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.929, tt:5659.904\n",
      "Ep:284, loss:0.00000, loss_test:0.09560, lr:1.02e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.930, tt:5680.155\n",
      "Ep:285, loss:0.00000, loss_test:0.09548, lr:1.01e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.933, tt:5700.739\n",
      "Ep:286, loss:0.00000, loss_test:0.09558, lr:1.00e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.932, tt:5720.582\n",
      "Ep:287, loss:0.00000, loss_test:0.09552, lr:9.91e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.932, tt:5740.546\n",
      "Ep:288, loss:0.00000, loss_test:0.09559, lr:9.81e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.937, tt:5761.792\n",
      "Ep:289, loss:0.00000, loss_test:0.09550, lr:9.71e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.939, tt:5782.240\n",
      "Ep:290, loss:0.00000, loss_test:0.09565, lr:9.62e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.939, tt:5802.108\n",
      "Ep:291, loss:0.00000, loss_test:0.09561, lr:9.52e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.937, tt:5821.570\n",
      "Ep:292, loss:0.00000, loss_test:0.09552, lr:9.42e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.939, tt:5842.261\n",
      "Ep:293, loss:0.00000, loss_test:0.09579, lr:9.33e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.940, tt:5862.264\n",
      "Ep:294, loss:0.00000, loss_test:0.09582, lr:9.24e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.939, tt:5882.056\n",
      "Ep:295, loss:0.00000, loss_test:0.09564, lr:9.14e-04, fs:0.76829 (r=0.636,p=0.969),  time:19.931, tt:5899.530\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14092, lr:1.00e-02, fs:0.63768 (r=0.889,p=0.497),  time:9.656, tt:9.656\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14042, lr:1.00e-02, fs:0.63736 (r=0.879,p=0.500),  time:13.233, tt:26.465\n",
      "Ep:2, loss:0.00004, loss_test:0.13977, lr:1.00e-02, fs:0.62921 (r=0.848,p=0.500),  time:14.994, tt:44.981\n",
      "Ep:3, loss:0.00004, loss_test:0.13889, lr:1.00e-02, fs:0.62500 (r=0.808,p=0.510),  time:15.866, tt:63.462\n",
      "Ep:4, loss:0.00004, loss_test:0.13785, lr:1.00e-02, fs:0.62205 (r=0.798,p=0.510),  time:16.452, tt:82.261\n",
      "Ep:5, loss:0.00004, loss_test:0.13755, lr:1.00e-02, fs:0.63200 (r=0.798,p=0.523),  time:16.840, tt:101.043\n",
      "Ep:6, loss:0.00003, loss_test:0.13837, lr:1.00e-02, fs:0.63374 (r=0.778,p=0.535),  time:17.151, tt:120.054\n",
      "Ep:7, loss:0.00003, loss_test:0.13872, lr:1.00e-02, fs:0.63333 (r=0.768,p=0.539),  time:17.313, tt:138.508\n",
      "Ep:8, loss:0.00003, loss_test:0.13944, lr:1.00e-02, fs:0.61947 (r=0.707,p=0.551),  time:17.470, tt:157.227\n",
      "Ep:9, loss:0.00003, loss_test:0.14040, lr:1.00e-02, fs:0.62443 (r=0.697,p=0.566),  time:17.554, tt:175.535\n",
      "Ep:10, loss:0.00003, loss_test:0.14110, lr:1.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:17.488, tt:192.370\n",
      "Ep:11, loss:0.00003, loss_test:0.14134, lr:1.00e-02, fs:0.61538 (r=0.687,p=0.557),  time:17.553, tt:210.641\n",
      "Ep:12, loss:0.00003, loss_test:0.14106, lr:9.90e-03, fs:0.60987 (r=0.687,p=0.548),  time:17.602, tt:228.828\n",
      "Ep:13, loss:0.00003, loss_test:0.14045, lr:9.80e-03, fs:0.60987 (r=0.687,p=0.548),  time:17.707, tt:247.895\n",
      "Ep:14, loss:0.00003, loss_test:0.13957, lr:9.70e-03, fs:0.60714 (r=0.687,p=0.544),  time:17.821, tt:267.313\n",
      "Ep:15, loss:0.00003, loss_test:0.13836, lr:9.61e-03, fs:0.60550 (r=0.667,p=0.555),  time:17.956, tt:287.300\n",
      "Ep:16, loss:0.00003, loss_test:0.13723, lr:9.51e-03, fs:0.60465 (r=0.657,p=0.560),  time:17.974, tt:305.559\n",
      "Ep:17, loss:0.00003, loss_test:0.13626, lr:9.41e-03, fs:0.60664 (r=0.646,p=0.571),  time:18.091, tt:325.642\n",
      "Ep:18, loss:0.00003, loss_test:0.13540, lr:9.32e-03, fs:0.60664 (r=0.646,p=0.571),  time:18.156, tt:344.973\n",
      "Ep:19, loss:0.00003, loss_test:0.13461, lr:9.23e-03, fs:0.60952 (r=0.646,p=0.577),  time:18.211, tt:364.227\n",
      "Ep:20, loss:0.00003, loss_test:0.13393, lr:9.14e-03, fs:0.61321 (r=0.657,p=0.575),  time:18.261, tt:383.490\n",
      "Ep:21, loss:0.00003, loss_test:0.13347, lr:9.04e-03, fs:0.60748 (r=0.657,p=0.565),  time:18.316, tt:402.962\n",
      "Ep:22, loss:0.00003, loss_test:0.13302, lr:8.95e-03, fs:0.60748 (r=0.657,p=0.565),  time:18.402, tt:423.258\n",
      "Ep:23, loss:0.00003, loss_test:0.13254, lr:8.86e-03, fs:0.61033 (r=0.657,p=0.570),  time:18.481, tt:443.545\n",
      "Ep:24, loss:0.00003, loss_test:0.13205, lr:8.78e-03, fs:0.61611 (r=0.657,p=0.580),  time:18.483, tt:462.069\n",
      "Ep:25, loss:0.00003, loss_test:0.13163, lr:8.69e-03, fs:0.61538 (r=0.646,p=0.587),  time:18.542, tt:482.089\n",
      "Ep:26, loss:0.00003, loss_test:0.13106, lr:8.60e-03, fs:0.61165 (r=0.636,p=0.589),  time:18.594, tt:502.048\n",
      "Ep:27, loss:0.00003, loss_test:0.13030, lr:8.51e-03, fs:0.61165 (r=0.636,p=0.589),  time:18.597, tt:520.704\n",
      "Ep:28, loss:0.00003, loss_test:0.12947, lr:8.43e-03, fs:0.61538 (r=0.646,p=0.587),  time:18.631, tt:540.299\n",
      "Ep:29, loss:0.00003, loss_test:0.12844, lr:8.35e-03, fs:0.61905 (r=0.657,p=0.586),  time:18.658, tt:559.747\n",
      "Ep:30, loss:0.00003, loss_test:0.12736, lr:8.26e-03, fs:0.61611 (r=0.657,p=0.580),  time:18.665, tt:578.602\n",
      "Ep:31, loss:0.00003, loss_test:0.12622, lr:8.18e-03, fs:0.61905 (r=0.657,p=0.586),  time:18.694, tt:598.206\n",
      "Ep:32, loss:0.00003, loss_test:0.12509, lr:8.10e-03, fs:0.63158 (r=0.667,p=0.600),  time:18.723, tt:617.850\n",
      "Ep:33, loss:0.00003, loss_test:0.12400, lr:8.02e-03, fs:0.61836 (r=0.646,p=0.593),  time:18.742, tt:637.229\n",
      "Ep:34, loss:0.00003, loss_test:0.12306, lr:7.94e-03, fs:0.63158 (r=0.667,p=0.600),  time:18.775, tt:657.116\n",
      "Ep:35, loss:0.00002, loss_test:0.12217, lr:7.86e-03, fs:0.62857 (r=0.667,p=0.595),  time:18.791, tt:676.464\n",
      "Ep:36, loss:0.00002, loss_test:0.12133, lr:7.78e-03, fs:0.62802 (r=0.657,p=0.602),  time:18.803, tt:695.727\n",
      "Ep:37, loss:0.00002, loss_test:0.12063, lr:7.70e-03, fs:0.61836 (r=0.646,p=0.593),  time:18.824, tt:715.322\n",
      "Ep:38, loss:0.00002, loss_test:0.11991, lr:7.62e-03, fs:0.62500 (r=0.657,p=0.596),  time:18.833, tt:734.474\n",
      "Ep:39, loss:0.00002, loss_test:0.11925, lr:7.55e-03, fs:0.62136 (r=0.646,p=0.598),  time:18.840, tt:753.614\n",
      "Ep:40, loss:0.00002, loss_test:0.11875, lr:7.47e-03, fs:0.62745 (r=0.646,p=0.610),  time:18.834, tt:772.193\n",
      "Ep:41, loss:0.00002, loss_test:0.11818, lr:7.40e-03, fs:0.62745 (r=0.646,p=0.610),  time:18.851, tt:791.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00002, loss_test:0.11755, lr:7.32e-03, fs:0.63054 (r=0.646,p=0.615),  time:18.885, tt:812.064\n",
      "Ep:43, loss:0.00002, loss_test:0.11687, lr:7.25e-03, fs:0.63725 (r=0.657,p=0.619),  time:18.900, tt:831.614\n",
      "Ep:44, loss:0.00002, loss_test:0.11619, lr:7.18e-03, fs:0.63725 (r=0.657,p=0.619),  time:18.900, tt:850.517\n",
      "Ep:45, loss:0.00002, loss_test:0.11552, lr:7.11e-03, fs:0.63725 (r=0.657,p=0.619),  time:18.895, tt:869.189\n",
      "Ep:46, loss:0.00002, loss_test:0.11489, lr:7.03e-03, fs:0.63366 (r=0.646,p=0.621),  time:18.912, tt:888.856\n",
      "Ep:47, loss:0.00002, loss_test:0.11429, lr:6.96e-03, fs:0.64000 (r=0.646,p=0.634),  time:18.911, tt:907.750\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.11369, lr:6.96e-03, fs:0.64322 (r=0.646,p=0.640),  time:18.918, tt:926.959\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.11315, lr:6.96e-03, fs:0.64646 (r=0.646,p=0.646),  time:18.917, tt:945.843\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.11264, lr:6.96e-03, fs:0.65327 (r=0.657,p=0.650),  time:18.941, tt:965.990\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.11214, lr:6.96e-03, fs:0.65327 (r=0.657,p=0.650),  time:18.965, tt:986.174\n",
      "Ep:52, loss:0.00002, loss_test:0.11163, lr:6.96e-03, fs:0.66332 (r=0.667,p=0.660),  time:18.961, tt:1004.917\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.11113, lr:6.96e-03, fs:0.66667 (r=0.667,p=0.667),  time:18.970, tt:1024.355\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.11056, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:18.988, tt:1044.353\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.10998, lr:6.96e-03, fs:0.67677 (r=0.677,p=0.677),  time:18.997, tt:1063.830\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.10947, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.034, tt:1084.919\n",
      "Ep:57, loss:0.00002, loss_test:0.10898, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.055, tt:1105.197\n",
      "Ep:58, loss:0.00002, loss_test:0.10855, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.061, tt:1124.620\n",
      "Ep:59, loss:0.00002, loss_test:0.10809, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.055, tt:1143.275\n",
      "Ep:60, loss:0.00002, loss_test:0.10757, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.049, tt:1161.970\n",
      "Ep:61, loss:0.00002, loss_test:0.10703, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.065, tt:1182.006\n",
      "Ep:62, loss:0.00002, loss_test:0.10650, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.071, tt:1201.502\n",
      "Ep:63, loss:0.00002, loss_test:0.10602, lr:6.96e-03, fs:0.67005 (r=0.667,p=0.673),  time:19.085, tt:1221.469\n",
      "Ep:64, loss:0.00002, loss_test:0.10564, lr:6.96e-03, fs:0.67692 (r=0.667,p=0.688),  time:19.093, tt:1241.059\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.10532, lr:6.96e-03, fs:0.68367 (r=0.677,p=0.691),  time:19.105, tt:1260.942\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.10498, lr:6.96e-03, fs:0.68367 (r=0.677,p=0.691),  time:19.109, tt:1280.292\n",
      "Ep:67, loss:0.00002, loss_test:0.10463, lr:6.96e-03, fs:0.68718 (r=0.677,p=0.698),  time:19.121, tt:1300.213\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.10421, lr:6.96e-03, fs:0.69072 (r=0.677,p=0.705),  time:19.116, tt:1318.995\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.10374, lr:6.96e-03, fs:0.69744 (r=0.687,p=0.708),  time:19.108, tt:1337.531\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.10324, lr:6.96e-03, fs:0.70103 (r=0.687,p=0.716),  time:19.119, tt:1357.424\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.10276, lr:6.96e-03, fs:0.71429 (r=0.707,p=0.722),  time:19.112, tt:1376.052\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.10234, lr:6.96e-03, fs:0.73000 (r=0.737,p=0.723),  time:19.109, tt:1394.955\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.10195, lr:6.96e-03, fs:0.73000 (r=0.737,p=0.723),  time:19.103, tt:1413.613\n",
      "Ep:74, loss:0.00002, loss_test:0.10155, lr:6.96e-03, fs:0.73367 (r=0.737,p=0.730),  time:19.086, tt:1431.437\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.10105, lr:6.96e-03, fs:0.73367 (r=0.737,p=0.730),  time:19.080, tt:1450.109\n",
      "Ep:76, loss:0.00002, loss_test:0.10055, lr:6.96e-03, fs:0.74627 (r=0.758,p=0.735),  time:19.073, tt:1468.596\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.10009, lr:6.96e-03, fs:0.74627 (r=0.758,p=0.735),  time:19.052, tt:1486.057\n",
      "Ep:78, loss:0.00002, loss_test:0.09958, lr:6.96e-03, fs:0.75248 (r=0.768,p=0.738),  time:19.038, tt:1503.976\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.09896, lr:6.96e-03, fs:0.75248 (r=0.768,p=0.738),  time:19.030, tt:1522.379\n",
      "Ep:80, loss:0.00002, loss_test:0.09835, lr:6.96e-03, fs:0.76471 (r=0.788,p=0.743),  time:19.014, tt:1540.151\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.09784, lr:6.96e-03, fs:0.76847 (r=0.788,p=0.750),  time:18.996, tt:1557.632\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.09730, lr:6.96e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.982, tt:1575.522\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.09674, lr:6.96e-03, fs:0.76617 (r=0.778,p=0.755),  time:18.956, tt:1592.296\n",
      "Ep:84, loss:0.00001, loss_test:0.09620, lr:6.96e-03, fs:0.77000 (r=0.778,p=0.762),  time:18.933, tt:1609.264\n",
      "Ep:85, loss:0.00001, loss_test:0.09566, lr:6.96e-03, fs:0.77000 (r=0.778,p=0.762),  time:18.913, tt:1626.503\n",
      "Ep:86, loss:0.00001, loss_test:0.09509, lr:6.96e-03, fs:0.77387 (r=0.778,p=0.770),  time:18.884, tt:1642.943\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.09457, lr:6.96e-03, fs:0.77387 (r=0.778,p=0.770),  time:18.885, tt:1661.912\n",
      "Ep:88, loss:0.00001, loss_test:0.09406, lr:6.96e-03, fs:0.78000 (r=0.788,p=0.772),  time:18.897, tt:1681.820\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.09359, lr:6.96e-03, fs:0.78000 (r=0.788,p=0.772),  time:18.888, tt:1699.930\n",
      "Ep:90, loss:0.00001, loss_test:0.09314, lr:6.96e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.882, tt:1718.267\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.09269, lr:6.96e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.857, tt:1734.862\n",
      "Ep:92, loss:0.00001, loss_test:0.09225, lr:6.96e-03, fs:0.79397 (r=0.798,p=0.790),  time:18.840, tt:1752.148\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.09180, lr:6.96e-03, fs:0.79397 (r=0.798,p=0.790),  time:18.826, tt:1769.646\n",
      "Ep:94, loss:0.00001, loss_test:0.09134, lr:6.96e-03, fs:0.79798 (r=0.798,p=0.798),  time:18.801, tt:1786.078\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.09095, lr:6.96e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.786, tt:1803.499\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.09062, lr:6.96e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.756, tt:1819.373\n",
      "Ep:97, loss:0.00001, loss_test:0.09027, lr:6.96e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.737, tt:1836.208\n",
      "Ep:98, loss:0.00001, loss_test:0.08992, lr:6.96e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.724, tt:1853.626\n",
      "Ep:99, loss:0.00001, loss_test:0.08961, lr:6.96e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.700, tt:1869.989\n",
      "Ep:100, loss:0.00001, loss_test:0.08930, lr:6.96e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.678, tt:1886.484\n",
      "Ep:101, loss:0.00001, loss_test:0.08894, lr:6.96e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.654, tt:1902.676\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.08859, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.628, tt:1918.669\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.08822, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.602, tt:1934.564\n",
      "Ep:104, loss:0.00001, loss_test:0.08790, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.579, tt:1950.803\n",
      "Ep:105, loss:0.00001, loss_test:0.08760, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.547, tt:1966.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:106, loss:0.00001, loss_test:0.08743, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.524, tt:1982.074\n",
      "Ep:107, loss:0.00001, loss_test:0.08717, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.489, tt:1996.831\n",
      "Ep:108, loss:0.00001, loss_test:0.08680, lr:6.96e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.473, tt:2013.608\n",
      "Ep:109, loss:0.00001, loss_test:0.08661, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.467, tt:2031.358\n",
      "Ep:110, loss:0.00001, loss_test:0.08644, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.459, tt:2048.917\n",
      "Ep:111, loss:0.00001, loss_test:0.08603, lr:6.96e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.420, tt:2063.017\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00001, loss_test:0.08584, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.391, tt:2078.215\n",
      "Ep:113, loss:0.00001, loss_test:0.08561, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.372, tt:2094.421\n",
      "Ep:114, loss:0.00001, loss_test:0.08546, lr:6.96e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.366, tt:2112.094\n",
      "Ep:115, loss:0.00001, loss_test:0.08527, lr:6.96e-03, fs:0.81250 (r=0.788,p=0.839),  time:18.353, tt:2128.981\n",
      "Ep:116, loss:0.00001, loss_test:0.08494, lr:6.96e-03, fs:0.81250 (r=0.788,p=0.839),  time:18.352, tt:2147.172\n",
      "Ep:117, loss:0.00001, loss_test:0.08477, lr:6.96e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.331, tt:2163.039\n",
      "Ep:118, loss:0.00001, loss_test:0.08432, lr:6.96e-03, fs:0.82292 (r=0.798,p=0.849),  time:18.328, tt:2181.039\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.08419, lr:6.96e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.325, tt:2198.993\n",
      "Ep:120, loss:0.00001, loss_test:0.08387, lr:6.96e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.314, tt:2216.036\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.08367, lr:6.96e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.306, tt:2233.356\n",
      "Ep:122, loss:0.00001, loss_test:0.08345, lr:6.96e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.296, tt:2250.442\n",
      "Ep:123, loss:0.00001, loss_test:0.08319, lr:6.96e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.290, tt:2267.937\n",
      "Ep:124, loss:0.00001, loss_test:0.08334, lr:6.96e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.288, tt:2286.021\n",
      "Ep:125, loss:0.00001, loss_test:0.08305, lr:6.96e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.284, tt:2303.734\n",
      "Ep:126, loss:0.00001, loss_test:0.08265, lr:6.96e-03, fs:0.83938 (r=0.818,p=0.862),  time:18.280, tt:2321.552\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00001, loss_test:0.08282, lr:6.96e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.276, tt:2339.371\n",
      "Ep:128, loss:0.00001, loss_test:0.08263, lr:6.96e-03, fs:0.82540 (r=0.788,p=0.867),  time:18.261, tt:2355.695\n",
      "Ep:129, loss:0.00001, loss_test:0.08210, lr:6.96e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.258, tt:2373.582\n",
      "Ep:130, loss:0.00001, loss_test:0.08227, lr:6.96e-03, fs:0.82540 (r=0.788,p=0.867),  time:18.256, tt:2391.540\n",
      "Ep:131, loss:0.00001, loss_test:0.08206, lr:6.96e-03, fs:0.82540 (r=0.788,p=0.867),  time:18.255, tt:2409.647\n",
      "Ep:132, loss:0.00001, loss_test:0.08155, lr:6.96e-03, fs:0.82105 (r=0.788,p=0.857),  time:18.258, tt:2428.330\n",
      "Ep:133, loss:0.00001, loss_test:0.08174, lr:6.96e-03, fs:0.82979 (r=0.788,p=0.876),  time:18.259, tt:2446.677\n",
      "Ep:134, loss:0.00001, loss_test:0.08164, lr:6.96e-03, fs:0.82353 (r=0.778,p=0.875),  time:18.264, tt:2465.700\n",
      "Ep:135, loss:0.00001, loss_test:0.08092, lr:6.96e-03, fs:0.82540 (r=0.788,p=0.867),  time:18.267, tt:2484.279\n",
      "Ep:136, loss:0.00001, loss_test:0.08110, lr:6.96e-03, fs:0.82353 (r=0.778,p=0.875),  time:18.265, tt:2502.270\n",
      "Ep:137, loss:0.00001, loss_test:0.08111, lr:6.96e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.266, tt:2520.686\n",
      "Ep:138, loss:0.00001, loss_test:0.08032, lr:6.89e-03, fs:0.81522 (r=0.758,p=0.882),  time:18.261, tt:2538.325\n",
      "Ep:139, loss:0.00001, loss_test:0.08057, lr:6.83e-03, fs:0.81319 (r=0.747,p=0.892),  time:18.260, tt:2556.413\n",
      "Ep:140, loss:0.00001, loss_test:0.08064, lr:6.76e-03, fs:0.81319 (r=0.747,p=0.892),  time:18.257, tt:2574.277\n",
      "Ep:141, loss:0.00001, loss_test:0.07997, lr:6.69e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.254, tt:2592.091\n",
      "Ep:142, loss:0.00001, loss_test:0.08045, lr:6.62e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.248, tt:2609.426\n",
      "Ep:143, loss:0.00001, loss_test:0.08018, lr:6.56e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.247, tt:2627.605\n",
      "Ep:144, loss:0.00001, loss_test:0.07982, lr:6.49e-03, fs:0.80220 (r=0.737,p=0.880),  time:18.247, tt:2645.805\n",
      "Ep:145, loss:0.00001, loss_test:0.07998, lr:6.43e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.254, tt:2665.025\n",
      "Ep:146, loss:0.00001, loss_test:0.07974, lr:6.36e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.260, tt:2684.248\n",
      "Ep:147, loss:0.00001, loss_test:0.07980, lr:6.30e-03, fs:0.78889 (r=0.717,p=0.877),  time:18.268, tt:2703.637\n",
      "Ep:148, loss:0.00001, loss_test:0.07986, lr:6.24e-03, fs:0.79330 (r=0.717,p=0.887),  time:18.269, tt:2722.088\n",
      "Ep:149, loss:0.00001, loss_test:0.07943, lr:6.17e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.271, tt:2740.631\n",
      "Ep:150, loss:0.00001, loss_test:0.07948, lr:6.11e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.283, tt:2760.804\n",
      "Ep:151, loss:0.00001, loss_test:0.07963, lr:6.05e-03, fs:0.78652 (r=0.707,p=0.886),  time:18.278, tt:2778.225\n",
      "Ep:152, loss:0.00001, loss_test:0.07935, lr:5.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.278, tt:2796.546\n",
      "Ep:153, loss:0.00001, loss_test:0.07938, lr:5.93e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.281, tt:2815.317\n",
      "Ep:154, loss:0.00001, loss_test:0.07929, lr:5.87e-03, fs:0.78652 (r=0.707,p=0.886),  time:18.288, tt:2834.689\n",
      "Ep:155, loss:0.00001, loss_test:0.07913, lr:5.81e-03, fs:0.78652 (r=0.707,p=0.886),  time:18.288, tt:2853.004\n",
      "Ep:156, loss:0.00001, loss_test:0.07939, lr:5.75e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.292, tt:2871.807\n",
      "Ep:157, loss:0.00001, loss_test:0.07943, lr:5.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.295, tt:2890.635\n",
      "Ep:158, loss:0.00001, loss_test:0.07908, lr:5.64e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.293, tt:2908.599\n",
      "Ep:159, loss:0.00001, loss_test:0.07928, lr:5.58e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.300, tt:2928.010\n",
      "Ep:160, loss:0.00001, loss_test:0.07923, lr:5.53e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.303, tt:2946.724\n",
      "Ep:161, loss:0.00001, loss_test:0.07900, lr:5.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.301, tt:2964.787\n",
      "Ep:162, loss:0.00001, loss_test:0.07922, lr:5.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:18.311, tt:2984.650\n",
      "Ep:163, loss:0.00001, loss_test:0.07915, lr:5.36e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.316, tt:3003.788\n",
      "Ep:164, loss:0.00001, loss_test:0.07891, lr:5.31e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.319, tt:3022.588\n",
      "Ep:165, loss:0.00001, loss_test:0.07924, lr:5.26e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.319, tt:3040.998\n",
      "Ep:166, loss:0.00001, loss_test:0.07903, lr:5.20e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.322, tt:3059.801\n",
      "Ep:167, loss:0.00001, loss_test:0.07915, lr:5.15e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.325, tt:3078.608\n",
      "Ep:168, loss:0.00001, loss_test:0.07917, lr:5.10e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.332, tt:3098.036\n",
      "Ep:169, loss:0.00001, loss_test:0.07894, lr:5.05e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.334, tt:3116.786\n",
      "Ep:170, loss:0.00001, loss_test:0.07880, lr:5.00e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.343, tt:3136.645\n",
      "Ep:171, loss:0.00001, loss_test:0.07892, lr:4.95e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.347, tt:3155.645\n",
      "Ep:172, loss:0.00001, loss_test:0.07880, lr:4.90e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.349, tt:3174.404\n",
      "Ep:173, loss:0.00001, loss_test:0.07866, lr:4.85e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.350, tt:3192.915\n",
      "Ep:174, loss:0.00001, loss_test:0.07883, lr:4.80e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.351, tt:3211.374\n",
      "Ep:175, loss:0.00001, loss_test:0.07857, lr:4.75e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.356, tt:3230.713\n",
      "Ep:176, loss:0.00001, loss_test:0.07855, lr:4.71e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.356, tt:3248.938\n",
      "Ep:177, loss:0.00001, loss_test:0.07875, lr:4.66e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.358, tt:3267.768\n",
      "Ep:178, loss:0.00001, loss_test:0.07869, lr:4.61e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.360, tt:3286.471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:179, loss:0.00001, loss_test:0.07849, lr:4.57e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.363, tt:3305.419\n",
      "Ep:180, loss:0.00001, loss_test:0.07849, lr:4.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.366, tt:3324.314\n",
      "Ep:181, loss:0.00001, loss_test:0.07838, lr:4.48e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.372, tt:3343.617\n",
      "Ep:182, loss:0.00001, loss_test:0.07854, lr:4.43e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.377, tt:3362.948\n",
      "Ep:183, loss:0.00001, loss_test:0.07825, lr:4.39e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.388, tt:3383.371\n",
      "Ep:184, loss:0.00001, loss_test:0.07809, lr:4.34e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.393, tt:3402.653\n",
      "Ep:185, loss:0.00001, loss_test:0.07842, lr:4.30e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.397, tt:3421.752\n",
      "Ep:186, loss:0.00001, loss_test:0.07783, lr:4.26e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.403, tt:3441.302\n",
      "Ep:187, loss:0.00001, loss_test:0.07811, lr:4.21e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.403, tt:3459.761\n",
      "Ep:188, loss:0.00001, loss_test:0.07827, lr:4.17e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.403, tt:3478.076\n",
      "Ep:189, loss:0.00001, loss_test:0.07761, lr:4.13e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.403, tt:3496.494\n",
      "Ep:190, loss:0.00001, loss_test:0.07803, lr:4.09e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.406, tt:3515.536\n",
      "Ep:191, loss:0.00001, loss_test:0.07809, lr:4.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.408, tt:3534.255\n",
      "Ep:192, loss:0.00001, loss_test:0.07749, lr:4.01e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.413, tt:3553.719\n",
      "Ep:193, loss:0.00001, loss_test:0.07781, lr:3.97e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.419, tt:3573.196\n",
      "Ep:194, loss:0.00001, loss_test:0.07798, lr:3.93e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.415, tt:3590.935\n",
      "Ep:195, loss:0.00001, loss_test:0.07755, lr:3.89e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.420, tt:3610.379\n",
      "Ep:196, loss:0.00001, loss_test:0.07752, lr:3.85e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.425, tt:3629.646\n",
      "Ep:197, loss:0.00001, loss_test:0.07783, lr:3.81e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.422, tt:3647.496\n",
      "Ep:198, loss:0.00001, loss_test:0.07766, lr:3.77e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.421, tt:3665.835\n",
      "Ep:199, loss:0.00001, loss_test:0.07741, lr:3.73e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.428, tt:3685.661\n",
      "Ep:200, loss:0.00001, loss_test:0.07739, lr:3.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.431, tt:3704.565\n",
      "Ep:201, loss:0.00001, loss_test:0.07755, lr:3.66e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.429, tt:3722.697\n",
      "Ep:202, loss:0.00001, loss_test:0.07736, lr:3.62e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.433, tt:3741.867\n",
      "Ep:203, loss:0.00001, loss_test:0.07726, lr:3.59e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.434, tt:3760.597\n",
      "Ep:204, loss:0.00001, loss_test:0.07728, lr:3.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.440, tt:3780.281\n",
      "Ep:205, loss:0.00001, loss_test:0.07722, lr:3.52e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.449, tt:3800.543\n",
      "Ep:206, loss:0.00001, loss_test:0.07717, lr:3.48e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.451, tt:3819.402\n",
      "Ep:207, loss:0.00001, loss_test:0.07722, lr:3.45e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.456, tt:3838.749\n",
      "Ep:208, loss:0.00001, loss_test:0.07703, lr:3.41e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.461, tt:3858.312\n",
      "Ep:209, loss:0.00000, loss_test:0.07714, lr:3.38e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.467, tt:3877.971\n",
      "Ep:210, loss:0.00000, loss_test:0.07703, lr:3.34e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.475, tt:3898.130\n",
      "Ep:211, loss:0.00000, loss_test:0.07706, lr:3.31e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.478, tt:3917.340\n",
      "Ep:212, loss:0.00000, loss_test:0.07712, lr:3.28e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.492, tt:3938.845\n",
      "Ep:213, loss:0.00000, loss_test:0.07687, lr:3.24e-03, fs:0.79070 (r=0.687,p=0.932),  time:18.494, tt:3957.644\n",
      "Ep:214, loss:0.00000, loss_test:0.07708, lr:3.21e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.502, tt:3977.866\n",
      "Ep:215, loss:0.00000, loss_test:0.07690, lr:3.18e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.504, tt:3996.925\n",
      "Ep:216, loss:0.00000, loss_test:0.07684, lr:3.15e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.510, tt:4016.733\n",
      "Ep:217, loss:0.00000, loss_test:0.07691, lr:3.12e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.518, tt:4036.964\n",
      "Ep:218, loss:0.00000, loss_test:0.07669, lr:3.09e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.525, tt:4057.080\n",
      "Ep:219, loss:0.00000, loss_test:0.07688, lr:3.05e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.535, tt:4077.602\n",
      "Ep:220, loss:0.00000, loss_test:0.07672, lr:3.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.539, tt:4097.089\n",
      "Ep:221, loss:0.00000, loss_test:0.07653, lr:2.99e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.540, tt:4115.772\n",
      "Ep:222, loss:0.00000, loss_test:0.07685, lr:2.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.545, tt:4135.435\n",
      "Ep:223, loss:0.00000, loss_test:0.07680, lr:2.93e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.550, tt:4155.275\n",
      "Ep:224, loss:0.00000, loss_test:0.07642, lr:2.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.547, tt:4173.082\n",
      "Ep:225, loss:0.00000, loss_test:0.07664, lr:2.88e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.551, tt:4192.571\n",
      "Ep:226, loss:0.00000, loss_test:0.07674, lr:2.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.547, tt:4210.216\n",
      "Ep:227, loss:0.00000, loss_test:0.07650, lr:2.82e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.556, tt:4230.715\n",
      "Ep:228, loss:0.00000, loss_test:0.07643, lr:2.79e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.565, tt:4251.428\n",
      "Ep:229, loss:0.00000, loss_test:0.07671, lr:2.76e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.571, tt:4271.240\n",
      "Ep:230, loss:0.00000, loss_test:0.07668, lr:2.73e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.577, tt:4291.184\n",
      "Ep:231, loss:0.00000, loss_test:0.07639, lr:2.71e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.579, tt:4310.279\n",
      "Ep:232, loss:0.00000, loss_test:0.07638, lr:2.68e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.584, tt:4330.099\n",
      "Ep:233, loss:0.00000, loss_test:0.07658, lr:2.65e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.587, tt:4349.307\n",
      "Ep:234, loss:0.00000, loss_test:0.07661, lr:2.63e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.590, tt:4368.692\n",
      "Ep:235, loss:0.00000, loss_test:0.07640, lr:2.60e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.599, tt:4389.462\n",
      "Ep:236, loss:0.00000, loss_test:0.07636, lr:2.57e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.602, tt:4408.622\n",
      "Ep:237, loss:0.00000, loss_test:0.07653, lr:2.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.607, tt:4428.502\n",
      "Ep:238, loss:0.00000, loss_test:0.07655, lr:2.52e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.605, tt:4446.588\n",
      "Ep:239, loss:0.00000, loss_test:0.07641, lr:2.50e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.607, tt:4465.631\n",
      "Ep:240, loss:0.00000, loss_test:0.07637, lr:2.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.610, tt:4485.075\n",
      "Ep:241, loss:0.00000, loss_test:0.07653, lr:2.45e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.610, tt:4503.520\n",
      "Ep:242, loss:0.00000, loss_test:0.07649, lr:2.42e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.612, tt:4522.655\n",
      "Ep:243, loss:0.00000, loss_test:0.07630, lr:2.40e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.612, tt:4541.358\n",
      "Ep:244, loss:0.00000, loss_test:0.07629, lr:2.38e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.612, tt:4559.877\n",
      "Ep:245, loss:0.00000, loss_test:0.07647, lr:2.35e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.608, tt:4577.605\n",
      "Ep:246, loss:0.00000, loss_test:0.07641, lr:2.33e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.603, tt:4594.882\n",
      "Ep:247, loss:0.00000, loss_test:0.07631, lr:2.31e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.602, tt:4613.315\n",
      "Ep:248, loss:0.00000, loss_test:0.07632, lr:2.28e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.597, tt:4630.580\n",
      "Ep:249, loss:0.00000, loss_test:0.07626, lr:2.26e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.594, tt:4648.550\n",
      "Ep:250, loss:0.00000, loss_test:0.07629, lr:2.24e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.589, tt:4665.790\n",
      "Ep:251, loss:0.00000, loss_test:0.07629, lr:2.21e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.582, tt:4682.658\n",
      "Ep:252, loss:0.00000, loss_test:0.07628, lr:2.19e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.574, tt:4699.310\n",
      "Ep:253, loss:0.00000, loss_test:0.07627, lr:2.17e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.566, tt:4715.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:254, loss:0.00000, loss_test:0.07625, lr:2.15e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.558, tt:4732.173\n",
      "Ep:255, loss:0.00000, loss_test:0.07624, lr:2.13e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.548, tt:4748.308\n",
      "Ep:256, loss:0.00000, loss_test:0.07626, lr:2.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.539, tt:4764.405\n",
      "Ep:257, loss:0.00000, loss_test:0.07621, lr:2.08e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.530, tt:4780.720\n",
      "Ep:258, loss:0.00000, loss_test:0.07630, lr:2.06e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.518, tt:4796.282\n",
      "Ep:259, loss:0.00000, loss_test:0.07623, lr:2.04e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.510, tt:4812.611\n",
      "Ep:260, loss:0.00000, loss_test:0.07625, lr:2.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.504, tt:4829.427\n",
      "Ep:261, loss:0.00000, loss_test:0.07627, lr:2.00e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.496, tt:4846.066\n",
      "Ep:262, loss:0.00000, loss_test:0.07618, lr:1.98e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.490, tt:4862.998\n",
      "Ep:263, loss:0.00000, loss_test:0.07630, lr:1.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.482, tt:4879.146\n",
      "Ep:264, loss:0.00000, loss_test:0.07620, lr:1.94e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.474, tt:4895.721\n",
      "Ep:265, loss:0.00000, loss_test:0.07617, lr:1.92e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.470, tt:4912.921\n",
      "Ep:266, loss:0.00000, loss_test:0.07628, lr:1.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.466, tt:4930.476\n",
      "Ep:267, loss:0.00000, loss_test:0.07624, lr:1.89e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.469, tt:4949.780\n",
      "Ep:268, loss:0.00000, loss_test:0.07610, lr:1.87e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.465, tt:4967.167\n",
      "Ep:269, loss:0.00000, loss_test:0.07627, lr:1.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.468, tt:4986.479\n",
      "Ep:270, loss:0.00000, loss_test:0.07623, lr:1.83e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.465, tt:5003.893\n",
      "Ep:271, loss:0.00000, loss_test:0.07613, lr:1.81e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.466, tt:5022.856\n",
      "Ep:272, loss:0.00000, loss_test:0.07610, lr:1.79e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.468, tt:5041.833\n",
      "Ep:273, loss:0.00000, loss_test:0.07610, lr:1.78e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.468, tt:5060.180\n",
      "Ep:274, loss:0.00000, loss_test:0.07611, lr:1.76e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.469, tt:5078.871\n",
      "Ep:275, loss:0.00000, loss_test:0.07613, lr:1.74e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.471, tt:5098.034\n",
      "Ep:276, loss:0.00000, loss_test:0.07609, lr:1.72e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.477, tt:5118.219\n",
      "Ep:277, loss:0.00000, loss_test:0.07604, lr:1.71e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.482, tt:5137.893\n",
      "Ep:278, loss:0.00000, loss_test:0.07604, lr:1.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.484, tt:5156.981\n",
      "Ep:279, loss:0.00000, loss_test:0.07600, lr:1.67e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.486, tt:5176.044\n",
      "Ep:280, loss:0.00000, loss_test:0.07597, lr:1.65e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.488, tt:5195.255\n",
      "Ep:281, loss:0.00000, loss_test:0.07598, lr:1.64e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.491, tt:5214.355\n",
      "Ep:282, loss:0.00000, loss_test:0.07595, lr:1.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.491, tt:5232.858\n",
      "Ep:283, loss:0.00000, loss_test:0.07594, lr:1.61e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.490, tt:5251.220\n",
      "Ep:284, loss:0.00000, loss_test:0.07591, lr:1.59e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.490, tt:5269.699\n",
      "Ep:285, loss:0.00000, loss_test:0.07588, lr:1.57e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.491, tt:5288.481\n",
      "Ep:286, loss:0.00000, loss_test:0.07594, lr:1.56e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.488, tt:5305.995\n",
      "Ep:287, loss:0.00000, loss_test:0.07588, lr:1.54e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.486, tt:5323.898\n",
      "Ep:288, loss:0.00000, loss_test:0.07581, lr:1.53e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.485, tt:5342.028\n",
      "Ep:289, loss:0.00000, loss_test:0.07582, lr:1.51e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.486, tt:5360.968\n",
      "Ep:290, loss:0.00000, loss_test:0.07585, lr:1.50e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.491, tt:5380.938\n",
      "Ep:291, loss:0.00000, loss_test:0.07579, lr:1.48e-03, fs:0.79532 (r=0.687,p=0.944),  time:18.492, tt:5399.616\n",
      "Ep:292, loss:0.00000, loss_test:0.07584, lr:1.47e-03, fs:0.80000 (r=0.687,p=0.958),  time:18.492, tt:5418.076\n",
      "Ep:293, loss:0.00000, loss_test:0.07582, lr:1.45e-03, fs:0.80000 (r=0.687,p=0.958),  time:18.495, tt:5437.396\n",
      "Ep:294, loss:0.00000, loss_test:0.07577, lr:1.44e-03, fs:0.80000 (r=0.687,p=0.958),  time:18.471, tt:5448.966\n",
      "Ep:295, loss:0.00000, loss_test:0.07577, lr:1.42e-03, fs:0.80000 (r=0.687,p=0.958),  time:18.429, tt:5454.994\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14269, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.072, tt:28.072\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13914, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:34.204, tt:68.407\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.13047, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:40.243, tt:120.729\n",
      "Ep:3, loss:0.00048, loss_test:0.11829, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:46.501, tt:186.004\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.11435, lr:1.00e-02, fs:0.66327 (r=0.657,p=0.670),  time:50.720, tt:253.601\n",
      "Ep:5, loss:0.00042, loss_test:0.10978, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:53.296, tt:319.776\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.10500, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:54.857, tt:383.998\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09826, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:56.230, tt:449.840\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.09302, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:57.730, tt:519.566\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.08979, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:58.806, tt:588.060\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.08687, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:59.444, tt:653.888\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.08399, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:59.967, tt:719.602\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00029, loss_test:0.08170, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:60.514, tt:786.680\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.08033, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:60.891, tt:852.480\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00026, loss_test:0.07802, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:61.118, tt:916.763\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.07744, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:61.582, tt:985.308\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.07473, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:61.869, tt:1051.776\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.07465, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:62.171, tt:1119.070\n",
      "Ep:18, loss:0.00022, loss_test:0.07301, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:62.446, tt:1186.469\n",
      "Ep:19, loss:0.00021, loss_test:0.07205, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:62.515, tt:1250.300\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.07265, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:62.712, tt:1316.957\n",
      "Ep:21, loss:0.00019, loss_test:0.07548, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:62.911, tt:1384.047\n",
      "Ep:22, loss:0.00018, loss_test:0.07754, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:63.083, tt:1450.898\n",
      "Ep:23, loss:0.00018, loss_test:0.07866, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:63.120, tt:1514.879\n",
      "Ep:24, loss:0.00017, loss_test:0.07077, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:63.274, tt:1581.842\n",
      "Ep:25, loss:0.00016, loss_test:0.06955, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:63.422, tt:1648.974\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.06785, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:63.622, tt:1717.795\n",
      "Ep:27, loss:0.00015, loss_test:0.07499, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:63.736, tt:1784.622\n",
      "Ep:28, loss:0.00014, loss_test:0.07482, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:63.877, tt:1852.442\n",
      "Ep:29, loss:0.00013, loss_test:0.07124, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:63.889, tt:1916.681\n",
      "Ep:30, loss:0.00013, loss_test:0.07385, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:63.901, tt:1980.924\n",
      "Ep:31, loss:0.00012, loss_test:0.06921, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:64.012, tt:2048.370\n",
      "Ep:32, loss:0.00012, loss_test:0.06701, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:64.006, tt:2112.194\n",
      "Ep:33, loss:0.00011, loss_test:0.07247, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:64.071, tt:2178.417\n",
      "Ep:34, loss:0.00010, loss_test:0.07537, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:64.101, tt:2243.519\n",
      "Ep:35, loss:0.00010, loss_test:0.07269, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:64.157, tt:2309.656\n",
      "Ep:36, loss:0.00010, loss_test:0.07162, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:64.180, tt:2374.652\n",
      "Ep:37, loss:0.00009, loss_test:0.07170, lr:9.90e-03, fs:0.80925 (r=0.707,p=0.946),  time:64.179, tt:2438.799\n",
      "Ep:38, loss:0.00009, loss_test:0.07163, lr:9.80e-03, fs:0.78824 (r=0.677,p=0.944),  time:64.281, tt:2506.942\n",
      "Ep:39, loss:0.00009, loss_test:0.07378, lr:9.70e-03, fs:0.79290 (r=0.677,p=0.957),  time:64.356, tt:2574.233\n",
      "Ep:40, loss:0.00008, loss_test:0.07424, lr:9.61e-03, fs:0.81395 (r=0.707,p=0.959),  time:64.414, tt:2640.988\n",
      "Ep:41, loss:0.00008, loss_test:0.07429, lr:9.51e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.375, tt:2703.751\n",
      "Ep:42, loss:0.00007, loss_test:0.07231, lr:9.41e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.401, tt:2769.238\n",
      "Ep:43, loss:0.00007, loss_test:0.07399, lr:9.32e-03, fs:0.79070 (r=0.687,p=0.932),  time:64.440, tt:2835.357\n",
      "Ep:44, loss:0.00007, loss_test:0.07345, lr:9.23e-03, fs:0.78824 (r=0.677,p=0.944),  time:64.498, tt:2902.397\n",
      "Ep:45, loss:0.00007, loss_test:0.07725, lr:9.14e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.496, tt:2966.807\n",
      "Ep:46, loss:0.00007, loss_test:0.07750, lr:9.04e-03, fs:0.79290 (r=0.677,p=0.957),  time:64.518, tt:3032.346\n",
      "Ep:47, loss:0.00006, loss_test:0.07651, lr:8.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:64.474, tt:3094.774\n",
      "Ep:48, loss:0.00006, loss_test:0.07851, lr:8.86e-03, fs:0.74534 (r=0.606,p=0.968),  time:64.491, tt:3160.058\n",
      "Ep:49, loss:0.00006, loss_test:0.07738, lr:8.78e-03, fs:0.74074 (r=0.606,p=0.952),  time:64.554, tt:3227.698\n",
      "Ep:50, loss:0.00006, loss_test:0.07601, lr:8.69e-03, fs:0.80000 (r=0.687,p=0.958),  time:64.569, tt:3293.005\n",
      "Ep:51, loss:0.00006, loss_test:0.08210, lr:8.60e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.574, tt:3357.838\n",
      "Ep:52, loss:0.00005, loss_test:0.07741, lr:8.51e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.548, tt:3421.045\n",
      "Ep:53, loss:0.00005, loss_test:0.08285, lr:8.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.559, tt:3486.212\n",
      "Ep:54, loss:0.00005, loss_test:0.07746, lr:8.35e-03, fs:0.76829 (r=0.636,p=0.969),  time:64.553, tt:3550.411\n",
      "Ep:55, loss:0.00005, loss_test:0.07968, lr:8.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.584, tt:3616.695\n",
      "Ep:56, loss:0.00005, loss_test:0.08095, lr:8.18e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.675, tt:3686.453\n",
      "Ep:57, loss:0.00005, loss_test:0.08306, lr:8.10e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.752, tt:3755.633\n",
      "Ep:58, loss:0.00004, loss_test:0.08143, lr:8.02e-03, fs:0.74534 (r=0.606,p=0.968),  time:64.770, tt:3821.436\n",
      "Ep:59, loss:0.00004, loss_test:0.08258, lr:7.94e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.792, tt:3887.531\n",
      "Ep:60, loss:0.00004, loss_test:0.08126, lr:7.86e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.793, tt:3952.350\n",
      "Ep:61, loss:0.00004, loss_test:0.08155, lr:7.78e-03, fs:0.74534 (r=0.606,p=0.968),  time:64.825, tt:4019.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00004, loss_test:0.08181, lr:7.70e-03, fs:0.71338 (r=0.566,p=0.966),  time:64.811, tt:4083.083\n",
      "Ep:63, loss:0.00004, loss_test:0.08164, lr:7.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.800, tt:4147.190\n",
      "Ep:64, loss:0.00004, loss_test:0.08117, lr:7.55e-03, fs:0.73750 (r=0.596,p=0.967),  time:64.798, tt:4211.857\n",
      "Ep:65, loss:0.00004, loss_test:0.08122, lr:7.47e-03, fs:0.71338 (r=0.566,p=0.966),  time:64.838, tt:4279.293\n",
      "Ep:66, loss:0.00004, loss_test:0.08308, lr:7.40e-03, fs:0.69677 (r=0.545,p=0.964),  time:64.853, tt:4345.167\n",
      "Ep:67, loss:0.00004, loss_test:0.08605, lr:7.32e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.852, tt:4409.962\n",
      "Ep:68, loss:0.00004, loss_test:0.08624, lr:7.25e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.912, tt:4478.949\n",
      "Ep:69, loss:0.00003, loss_test:0.08525, lr:7.18e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.931, tt:4545.203\n",
      "Ep:70, loss:0.00003, loss_test:0.08141, lr:7.11e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.960, tt:4612.142\n",
      "Ep:71, loss:0.00003, loss_test:0.08283, lr:7.03e-03, fs:0.70513 (r=0.556,p=0.965),  time:64.973, tt:4678.038\n",
      "Ep:72, loss:0.00003, loss_test:0.08797, lr:6.96e-03, fs:0.68831 (r=0.535,p=0.964),  time:64.993, tt:4744.517\n",
      "Ep:73, loss:0.00003, loss_test:0.08709, lr:6.89e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.010, tt:4810.772\n",
      "Ep:74, loss:0.00003, loss_test:0.08602, lr:6.83e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.029, tt:4877.139\n",
      "Ep:75, loss:0.00003, loss_test:0.08408, lr:6.76e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.036, tt:4942.758\n",
      "Ep:76, loss:0.00003, loss_test:0.08805, lr:6.69e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.048, tt:5008.733\n",
      "Ep:77, loss:0.00003, loss_test:0.08644, lr:6.62e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.043, tt:5073.375\n",
      "Ep:78, loss:0.00003, loss_test:0.08391, lr:6.56e-03, fs:0.70886 (r=0.566,p=0.949),  time:65.079, tt:5141.202\n",
      "Ep:79, loss:0.00003, loss_test:0.08575, lr:6.49e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.111, tt:5208.869\n",
      "Ep:80, loss:0.00003, loss_test:0.08617, lr:6.43e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.171, tt:5278.844\n",
      "Ep:81, loss:0.00003, loss_test:0.08711, lr:6.36e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.196, tt:5346.075\n",
      "Ep:82, loss:0.00003, loss_test:0.08504, lr:6.30e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.207, tt:5412.185\n",
      "Ep:83, loss:0.00003, loss_test:0.08674, lr:6.24e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.211, tt:5477.721\n",
      "Ep:84, loss:0.00003, loss_test:0.08774, lr:6.17e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.194, tt:5541.480\n",
      "Ep:85, loss:0.00003, loss_test:0.08760, lr:6.11e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.216, tt:5608.608\n",
      "Ep:86, loss:0.00003, loss_test:0.08386, lr:6.05e-03, fs:0.71338 (r=0.566,p=0.966),  time:65.182, tt:5670.858\n",
      "Ep:87, loss:0.00003, loss_test:0.09176, lr:5.99e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.224, tt:5739.730\n",
      "Ep:88, loss:0.00003, loss_test:0.08692, lr:5.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.228, tt:5805.281\n",
      "Ep:89, loss:0.00002, loss_test:0.08634, lr:5.87e-03, fs:0.68387 (r=0.535,p=0.946),  time:65.220, tt:5869.832\n",
      "Ep:90, loss:0.00002, loss_test:0.08670, lr:5.81e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.228, tt:5935.736\n",
      "Ep:91, loss:0.00002, loss_test:0.08988, lr:5.75e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.238, tt:6001.936\n",
      "Ep:92, loss:0.00002, loss_test:0.08685, lr:5.70e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.250, tt:6068.283\n",
      "Ep:93, loss:0.00002, loss_test:0.08665, lr:5.64e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.213, tt:6130.009\n",
      "Ep:94, loss:0.00002, loss_test:0.08798, lr:5.58e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.209, tt:6194.856\n",
      "Ep:95, loss:0.00002, loss_test:0.08765, lr:5.53e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.189, tt:6258.116\n",
      "Ep:96, loss:0.00002, loss_test:0.08641, lr:5.47e-03, fs:0.70064 (r=0.556,p=0.948),  time:65.179, tt:6322.352\n",
      "Ep:97, loss:0.00002, loss_test:0.08783, lr:5.42e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.211, tt:6390.691\n",
      "Ep:98, loss:0.00002, loss_test:0.08869, lr:5.36e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.225, tt:6457.282\n",
      "Ep:99, loss:0.00002, loss_test:0.08719, lr:5.31e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.219, tt:6521.900\n",
      "Ep:100, loss:0.00002, loss_test:0.08781, lr:5.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.206, tt:6585.807\n",
      "Ep:101, loss:0.00002, loss_test:0.08902, lr:5.20e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.220, tt:6652.418\n",
      "Ep:102, loss:0.00002, loss_test:0.08804, lr:5.15e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.217, tt:6717.372\n",
      "Ep:103, loss:0.00002, loss_test:0.08891, lr:5.10e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.179, tt:6778.593\n",
      "Ep:104, loss:0.00002, loss_test:0.08716, lr:5.05e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.199, tt:6845.904\n",
      "Ep:105, loss:0.00002, loss_test:0.08882, lr:5.00e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.176, tt:6908.631\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14208, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:70.188, tt:70.188\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13708, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:72.812, tt:145.625\n",
      "Ep:2, loss:0.00052, loss_test:0.12479, lr:1.00e-02, fs:0.65354 (r=0.838,p=0.535),  time:73.313, tt:219.939\n",
      "Ep:3, loss:0.00048, loss_test:0.11998, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:75.522, tt:302.088\n",
      "Ep:4, loss:0.00044, loss_test:0.11442, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:77.047, tt:385.235\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.10587, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:78.518, tt:471.106\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00037, loss_test:0.09872, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:78.974, tt:552.816\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00035, loss_test:0.09377, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:79.410, tt:635.283\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00032, loss_test:0.08841, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:79.951, tt:719.563\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.08562, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:80.418, tt:804.183\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.08191, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:80.846, tt:889.310\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.07942, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:80.913, tt:970.952\n",
      "Ep:12, loss:0.00024, loss_test:0.07748, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:81.171, tt:1055.227\n",
      "Ep:13, loss:0.00022, loss_test:0.07539, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:81.269, tt:1137.766\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.07639, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:81.479, tt:1222.178\n",
      "Ep:15, loss:0.00019, loss_test:0.07738, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:81.540, tt:1304.635\n",
      "Ep:16, loss:0.00017, loss_test:0.07919, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:81.594, tt:1387.091\n",
      "Ep:17, loss:0.00016, loss_test:0.07894, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:81.472, tt:1466.500\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07684, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:81.598, tt:1550.359\n",
      "Ep:19, loss:0.00014, loss_test:0.06871, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:81.714, tt:1634.287\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.07272, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:81.762, tt:1717.000\n",
      "Ep:21, loss:0.00012, loss_test:0.07340, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:81.765, tt:1798.823\n",
      "Ep:22, loss:0.00011, loss_test:0.07093, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:81.804, tt:1881.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00010, loss_test:0.07496, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:81.870, tt:1964.877\n",
      "Ep:24, loss:0.00009, loss_test:0.08215, lr:1.00e-02, fs:0.83429 (r=0.737,p=0.961),  time:81.951, tt:2048.784\n",
      "Ep:25, loss:0.00009, loss_test:0.07794, lr:1.00e-02, fs:0.84091 (r=0.747,p=0.961),  time:81.978, tt:2131.437\n",
      "Ep:26, loss:0.00009, loss_test:0.07854, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:82.050, tt:2215.341\n",
      "Ep:27, loss:0.00008, loss_test:0.07882, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:82.074, tt:2298.078\n",
      "Ep:28, loss:0.00007, loss_test:0.08194, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:82.137, tt:2381.970\n",
      "Ep:29, loss:0.00007, loss_test:0.08437, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:82.193, tt:2465.777\n",
      "Ep:30, loss:0.00006, loss_test:0.08790, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:82.245, tt:2549.604\n",
      "Ep:31, loss:0.00006, loss_test:0.07659, lr:9.90e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.267, tt:2632.540\n",
      "Ep:32, loss:0.00005, loss_test:0.07523, lr:9.80e-03, fs:0.80925 (r=0.707,p=0.946),  time:82.334, tt:2717.020\n",
      "Ep:33, loss:0.00005, loss_test:0.08425, lr:9.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.387, tt:2801.158\n",
      "Ep:34, loss:0.00005, loss_test:0.08698, lr:9.61e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.450, tt:2885.765\n",
      "Ep:35, loss:0.00004, loss_test:0.08492, lr:9.51e-03, fs:0.83237 (r=0.727,p=0.973),  time:82.404, tt:2966.539\n",
      "Ep:36, loss:0.00004, loss_test:0.08573, lr:9.41e-03, fs:0.81395 (r=0.707,p=0.959),  time:82.409, tt:3049.115\n",
      "Ep:37, loss:0.00004, loss_test:0.08517, lr:9.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:82.342, tt:3128.990\n",
      "Ep:38, loss:0.00004, loss_test:0.08615, lr:9.23e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.344, tt:3211.401\n",
      "Ep:39, loss:0.00003, loss_test:0.08971, lr:9.14e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.334, tt:3293.365\n",
      "Ep:40, loss:0.00003, loss_test:0.08768, lr:9.04e-03, fs:0.79042 (r=0.667,p=0.971),  time:82.386, tt:3377.824\n",
      "Ep:41, loss:0.00003, loss_test:0.08640, lr:8.95e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.407, tt:3461.079\n",
      "Ep:42, loss:0.00003, loss_test:0.08660, lr:8.86e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.369, tt:3541.886\n",
      "Ep:43, loss:0.00003, loss_test:0.09395, lr:8.78e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.508, tt:3630.334\n",
      "Ep:44, loss:0.00003, loss_test:0.09236, lr:8.69e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.455, tt:3710.489\n",
      "Ep:45, loss:0.00003, loss_test:0.09041, lr:8.60e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.446, tt:3792.505\n",
      "Ep:46, loss:0.00002, loss_test:0.09379, lr:8.51e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.415, tt:3873.508\n",
      "Ep:47, loss:0.00002, loss_test:0.09042, lr:8.43e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.370, tt:3953.737\n",
      "Ep:48, loss:0.00002, loss_test:0.09190, lr:8.35e-03, fs:0.79042 (r=0.667,p=0.971),  time:82.376, tt:4036.412\n",
      "Ep:49, loss:0.00002, loss_test:0.09059, lr:8.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:82.371, tt:4118.556\n",
      "Ep:50, loss:0.00002, loss_test:0.09440, lr:8.18e-03, fs:0.81871 (r=0.707,p=0.972),  time:82.382, tt:4201.498\n",
      "Ep:51, loss:0.00002, loss_test:0.09411, lr:8.10e-03, fs:0.79042 (r=0.667,p=0.971),  time:82.343, tt:4281.854\n",
      "Ep:52, loss:0.00002, loss_test:0.09530, lr:8.02e-03, fs:0.78313 (r=0.657,p=0.970),  time:82.311, tt:4362.489\n",
      "Ep:53, loss:0.00002, loss_test:0.09274, lr:7.94e-03, fs:0.78313 (r=0.657,p=0.970),  time:82.270, tt:4442.568\n",
      "Ep:54, loss:0.00002, loss_test:0.09719, lr:7.86e-03, fs:0.79042 (r=0.667,p=0.971),  time:82.267, tt:4524.686\n",
      "Ep:55, loss:0.00002, loss_test:0.10020, lr:7.78e-03, fs:0.78313 (r=0.657,p=0.970),  time:82.281, tt:4607.709\n",
      "Ep:56, loss:0.00002, loss_test:0.09497, lr:7.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:82.335, tt:4693.112\n",
      "Ep:57, loss:0.00001, loss_test:0.09704, lr:7.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.331, tt:4775.199\n",
      "Ep:58, loss:0.00001, loss_test:0.09590, lr:7.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:82.342, tt:4858.195\n",
      "Ep:59, loss:0.00001, loss_test:0.09664, lr:7.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:82.318, tt:4939.057\n",
      "Ep:60, loss:0.00001, loss_test:0.09804, lr:7.40e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.319, tt:5021.481\n",
      "Ep:61, loss:0.00001, loss_test:0.09947, lr:7.32e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.324, tt:5104.057\n",
      "Ep:62, loss:0.00001, loss_test:0.09816, lr:7.25e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.381, tt:5189.981\n",
      "Ep:63, loss:0.00001, loss_test:0.10185, lr:7.18e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.381, tt:5272.389\n",
      "Ep:64, loss:0.00001, loss_test:0.10260, lr:7.11e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.385, tt:5355.027\n",
      "Ep:65, loss:0.00001, loss_test:0.10059, lr:7.03e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.353, tt:5435.326\n",
      "Ep:66, loss:0.00001, loss_test:0.10095, lr:6.96e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.357, tt:5517.938\n",
      "Ep:67, loss:0.00001, loss_test:0.10078, lr:6.89e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.337, tt:5598.944\n",
      "Ep:68, loss:0.00001, loss_test:0.10184, lr:6.83e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.303, tt:5678.896\n",
      "Ep:69, loss:0.00001, loss_test:0.10621, lr:6.76e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.264, tt:5758.448\n",
      "Ep:70, loss:0.00001, loss_test:0.10260, lr:6.69e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.283, tt:5842.083\n",
      "Ep:71, loss:0.00001, loss_test:0.10404, lr:6.62e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.285, tt:5924.553\n",
      "Ep:72, loss:0.00001, loss_test:0.10434, lr:6.56e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.287, tt:6006.922\n",
      "Ep:73, loss:0.00001, loss_test:0.10113, lr:6.49e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.287, tt:6089.273\n",
      "Ep:74, loss:0.00001, loss_test:0.10524, lr:6.43e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.334, tt:6175.023\n",
      "Ep:75, loss:0.00001, loss_test:0.10283, lr:6.36e-03, fs:0.74534 (r=0.606,p=0.968),  time:82.339, tt:6257.762\n",
      "Ep:76, loss:0.00001, loss_test:0.10239, lr:6.30e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.345, tt:6340.570\n",
      "Ep:77, loss:0.00001, loss_test:0.10653, lr:6.24e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.294, tt:6418.961\n",
      "Ep:78, loss:0.00001, loss_test:0.10301, lr:6.17e-03, fs:0.74534 (r=0.606,p=0.968),  time:82.284, tt:6500.423\n",
      "Ep:79, loss:0.00001, loss_test:0.10221, lr:6.11e-03, fs:0.74534 (r=0.606,p=0.968),  time:82.335, tt:6586.810\n",
      "Ep:80, loss:0.00001, loss_test:0.10446, lr:6.05e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.340, tt:6669.577\n",
      "Ep:81, loss:0.00001, loss_test:0.10415, lr:5.99e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.293, tt:6747.998\n",
      "Ep:82, loss:0.00001, loss_test:0.10235, lr:5.93e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.307, tt:6831.442\n",
      "Ep:83, loss:0.00001, loss_test:0.10441, lr:5.87e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.306, tt:6913.689\n",
      "Ep:84, loss:0.00001, loss_test:0.10226, lr:5.81e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.284, tt:6994.128\n",
      "Ep:85, loss:0.00000, loss_test:0.10333, lr:5.75e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.294, tt:7077.261\n",
      "Ep:86, loss:0.00000, loss_test:0.10350, lr:5.70e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.302, tt:7160.280\n",
      "Ep:87, loss:0.00000, loss_test:0.10381, lr:5.64e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.307, tt:7243.059\n",
      "Ep:88, loss:0.00000, loss_test:0.10351, lr:5.58e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.304, tt:7325.066\n",
      "Ep:89, loss:0.00000, loss_test:0.10373, lr:5.53e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.326, tt:7409.325\n",
      "Ep:90, loss:0.00000, loss_test:0.10352, lr:5.47e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.303, tt:7489.595\n",
      "Ep:91, loss:0.00000, loss_test:0.10333, lr:5.42e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.323, tt:7573.695\n",
      "Ep:92, loss:0.00000, loss_test:0.10450, lr:5.36e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.368, tt:7660.234\n",
      "Ep:93, loss:0.00000, loss_test:0.10433, lr:5.31e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.384, tt:7744.069\n",
      "Ep:94, loss:0.00000, loss_test:0.10351, lr:5.26e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.397, tt:7827.761\n",
      "Ep:95, loss:0.00000, loss_test:0.10486, lr:5.20e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.398, tt:7910.256\n",
      "Ep:96, loss:0.00000, loss_test:0.10489, lr:5.15e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.437, tt:7996.364\n",
      "Ep:97, loss:0.00000, loss_test:0.10314, lr:5.10e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.397, tt:8074.911\n",
      "Ep:98, loss:0.00000, loss_test:0.10409, lr:5.05e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.399, tt:8157.542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:99, loss:0.00000, loss_test:0.10336, lr:5.00e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.413, tt:8241.321\n",
      "Ep:100, loss:0.00000, loss_test:0.10436, lr:4.95e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.404, tt:8322.757\n",
      "Ep:101, loss:0.00000, loss_test:0.10319, lr:4.90e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.399, tt:8404.648\n",
      "Ep:102, loss:0.00000, loss_test:0.10279, lr:4.85e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.400, tt:8487.245\n",
      "Ep:103, loss:0.00000, loss_test:0.10392, lr:4.80e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.398, tt:8569.368\n",
      "Ep:104, loss:0.00000, loss_test:0.10368, lr:4.75e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.369, tt:8648.779\n",
      "Ep:105, loss:0.00000, loss_test:0.10427, lr:4.71e-03, fs:0.75000 (r=0.606,p=0.984),  time:82.360, tt:8730.202\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.13266, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:60.183, tt:60.183\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00052, loss_test:0.12260, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:64.634, tt:129.269\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00049, loss_test:0.11678, lr:1.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:64.587, tt:193.761\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.11244, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:67.343, tt:269.371\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.10794, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:69.138, tt:345.692\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00042, loss_test:0.10327, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:70.841, tt:425.045\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00040, loss_test:0.09806, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:71.742, tt:502.194\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09122, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:72.781, tt:582.251\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.08897, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:73.024, tt:657.220\n",
      "Ep:9, loss:0.00034, loss_test:0.08352, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:73.438, tt:734.381\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00032, loss_test:0.08303, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:73.673, tt:810.405\n",
      "Ep:11, loss:0.00031, loss_test:0.08010, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:73.701, tt:884.417\n",
      "Ep:12, loss:0.00029, loss_test:0.07704, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:73.882, tt:960.460\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00027, loss_test:0.07408, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:73.943, tt:1035.208\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.07154, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:74.023, tt:1110.339\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.07008, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:74.172, tt:1186.759\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.06678, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:74.203, tt:1261.453\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.06563, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:74.282, tt:1337.071\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.06471, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:74.339, tt:1412.447\n",
      "Ep:19, loss:0.00018, loss_test:0.06199, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:74.422, tt:1488.439\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.06326, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:74.467, tt:1563.803\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.06293, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:74.567, tt:1640.476\n",
      "Ep:22, loss:0.00016, loss_test:0.06073, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:74.633, tt:1716.569\n",
      "Ep:23, loss:0.00015, loss_test:0.05788, lr:1.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:74.681, tt:1792.349\n",
      "Ep:24, loss:0.00014, loss_test:0.05778, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:74.606, tt:1865.144\n",
      "Ep:25, loss:0.00013, loss_test:0.05875, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:74.676, tt:1941.572\n",
      "Ep:26, loss:0.00013, loss_test:0.05720, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:74.622, tt:2014.791\n",
      "Ep:27, loss:0.00012, loss_test:0.05767, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:74.663, tt:2090.570\n",
      "Ep:28, loss:0.00011, loss_test:0.05575, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:74.594, tt:2163.226\n",
      "Ep:29, loss:0.00010, loss_test:0.05552, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:74.574, tt:2237.233\n",
      "Ep:30, loss:0.00010, loss_test:0.05693, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:74.553, tt:2311.156\n",
      "Ep:31, loss:0.00009, loss_test:0.05800, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:74.527, tt:2384.855\n",
      "Ep:32, loss:0.00009, loss_test:0.05957, lr:9.90e-03, fs:0.86957 (r=0.808,p=0.941),  time:74.617, tt:2462.374\n",
      "Ep:33, loss:0.00008, loss_test:0.05697, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:74.564, tt:2535.187\n",
      "Ep:34, loss:0.00008, loss_test:0.05972, lr:9.70e-03, fs:0.90909 (r=0.859,p=0.966),  time:74.615, tt:2611.513\n",
      "Ep:35, loss:0.00008, loss_test:0.05693, lr:9.61e-03, fs:0.89474 (r=0.859,p=0.934),  time:74.603, tt:2685.710\n",
      "Ep:36, loss:0.00007, loss_test:0.06036, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.535, tt:2757.801\n",
      "Ep:37, loss:0.00007, loss_test:0.06130, lr:9.41e-03, fs:0.87293 (r=0.798,p=0.963),  time:74.538, tt:2832.456\n",
      "Ep:38, loss:0.00006, loss_test:0.06229, lr:9.32e-03, fs:0.86667 (r=0.788,p=0.963),  time:74.469, tt:2904.292\n",
      "Ep:39, loss:0.00006, loss_test:0.06024, lr:9.23e-03, fs:0.87097 (r=0.818,p=0.931),  time:74.497, tt:2979.884\n",
      "Ep:40, loss:0.00006, loss_test:0.06254, lr:9.14e-03, fs:0.87293 (r=0.798,p=0.963),  time:74.443, tt:3052.168\n",
      "Ep:41, loss:0.00006, loss_test:0.06058, lr:9.04e-03, fs:0.91005 (r=0.869,p=0.956),  time:74.503, tt:3129.139\n",
      "Ep:42, loss:0.00005, loss_test:0.06451, lr:8.95e-03, fs:0.86813 (r=0.798,p=0.952),  time:74.523, tt:3204.482\n",
      "Ep:43, loss:0.00005, loss_test:0.06275, lr:8.86e-03, fs:0.88043 (r=0.818,p=0.953),  time:74.549, tt:3280.149\n",
      "Ep:44, loss:0.00005, loss_test:0.06414, lr:8.78e-03, fs:0.87432 (r=0.808,p=0.952),  time:74.529, tt:3353.792\n",
      "Ep:45, loss:0.00005, loss_test:0.06519, lr:8.69e-03, fs:0.86188 (r=0.788,p=0.951),  time:74.510, tt:3427.438\n",
      "Ep:46, loss:0.00005, loss_test:0.06629, lr:8.60e-03, fs:0.87432 (r=0.808,p=0.952),  time:74.517, tt:3502.277\n",
      "Ep:47, loss:0.00005, loss_test:0.06409, lr:8.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:74.520, tt:3576.967\n",
      "Ep:48, loss:0.00005, loss_test:0.06774, lr:8.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.555, tt:3653.186\n",
      "Ep:49, loss:0.00005, loss_test:0.07002, lr:8.35e-03, fs:0.84916 (r=0.768,p=0.950),  time:74.542, tt:3727.108\n",
      "Ep:50, loss:0.00005, loss_test:0.06570, lr:8.26e-03, fs:0.86188 (r=0.788,p=0.951),  time:74.505, tt:3799.739\n",
      "Ep:51, loss:0.00004, loss_test:0.06699, lr:8.18e-03, fs:0.86188 (r=0.788,p=0.951),  time:74.499, tt:3873.933\n",
      "Ep:52, loss:0.00004, loss_test:0.06776, lr:8.10e-03, fs:0.86034 (r=0.778,p=0.963),  time:74.479, tt:3947.373\n",
      "Ep:53, loss:0.00004, loss_test:0.06830, lr:8.02e-03, fs:0.82955 (r=0.737,p=0.948),  time:74.508, tt:4023.427\n",
      "Ep:54, loss:0.00004, loss_test:0.07030, lr:7.94e-03, fs:0.84270 (r=0.758,p=0.949),  time:74.525, tt:4098.883\n",
      "Ep:55, loss:0.00004, loss_test:0.07231, lr:7.86e-03, fs:0.81609 (r=0.717,p=0.947),  time:74.519, tt:4173.073\n",
      "Ep:56, loss:0.00004, loss_test:0.07056, lr:7.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:74.523, tt:4247.804\n",
      "Ep:57, loss:0.00003, loss_test:0.06943, lr:7.70e-03, fs:0.81609 (r=0.717,p=0.947),  time:74.563, tt:4324.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00003, loss_test:0.07081, lr:7.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:74.624, tt:4402.802\n",
      "Ep:59, loss:0.00003, loss_test:0.07077, lr:7.55e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.584, tt:4475.015\n",
      "Ep:60, loss:0.00003, loss_test:0.07082, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.558, tt:4548.018\n",
      "Ep:61, loss:0.00003, loss_test:0.07015, lr:7.40e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.516, tt:4620.004\n",
      "Ep:62, loss:0.00003, loss_test:0.07127, lr:7.32e-03, fs:0.83978 (r=0.768,p=0.927),  time:74.480, tt:4692.248\n",
      "Ep:63, loss:0.00003, loss_test:0.07013, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:74.466, tt:4765.853\n",
      "Ep:64, loss:0.00003, loss_test:0.06989, lr:7.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:74.432, tt:4838.069\n",
      "Ep:65, loss:0.00003, loss_test:0.07050, lr:7.11e-03, fs:0.81143 (r=0.717,p=0.934),  time:74.417, tt:4911.512\n",
      "Ep:66, loss:0.00003, loss_test:0.06878, lr:7.03e-03, fs:0.85870 (r=0.798,p=0.929),  time:74.430, tt:4986.777\n",
      "Ep:67, loss:0.00003, loss_test:0.07083, lr:6.96e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.419, tt:5060.485\n",
      "Ep:68, loss:0.00003, loss_test:0.07132, lr:6.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.419, tt:5134.944\n",
      "Ep:69, loss:0.00002, loss_test:0.07014, lr:6.83e-03, fs:0.83333 (r=0.758,p=0.926),  time:74.428, tt:5209.995\n",
      "Ep:70, loss:0.00002, loss_test:0.07132, lr:6.76e-03, fs:0.82022 (r=0.737,p=0.924),  time:74.410, tt:5283.101\n",
      "Ep:71, loss:0.00002, loss_test:0.07092, lr:6.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:74.426, tt:5358.648\n",
      "Ep:72, loss:0.00002, loss_test:0.06958, lr:6.62e-03, fs:0.85870 (r=0.798,p=0.929),  time:74.419, tt:5432.575\n",
      "Ep:73, loss:0.00002, loss_test:0.07105, lr:6.56e-03, fs:0.82682 (r=0.747,p=0.925),  time:74.447, tt:5509.092\n",
      "Ep:74, loss:0.00002, loss_test:0.07224, lr:6.49e-03, fs:0.83978 (r=0.768,p=0.927),  time:74.465, tt:5584.891\n",
      "Ep:75, loss:0.00002, loss_test:0.07110, lr:6.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:74.455, tt:5658.613\n",
      "Ep:76, loss:0.00002, loss_test:0.07280, lr:6.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:74.428, tt:5730.936\n",
      "Ep:77, loss:0.00002, loss_test:0.07051, lr:6.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:74.437, tt:5806.112\n",
      "Ep:78, loss:0.00002, loss_test:0.07177, lr:6.24e-03, fs:0.80460 (r=0.707,p=0.933),  time:74.436, tt:5880.471\n",
      "Ep:79, loss:0.00002, loss_test:0.07518, lr:6.17e-03, fs:0.84091 (r=0.747,p=0.961),  time:74.488, tt:5959.050\n",
      "Ep:80, loss:0.00002, loss_test:0.07144, lr:6.11e-03, fs:0.78824 (r=0.677,p=0.944),  time:74.490, tt:6033.706\n",
      "Ep:81, loss:0.00002, loss_test:0.07324, lr:6.05e-03, fs:0.76923 (r=0.657,p=0.929),  time:74.481, tt:6107.461\n",
      "Ep:82, loss:0.00002, loss_test:0.07331, lr:5.99e-03, fs:0.77844 (r=0.657,p=0.956),  time:74.451, tt:6179.447\n",
      "Ep:83, loss:0.00002, loss_test:0.07183, lr:5.93e-03, fs:0.81143 (r=0.717,p=0.934),  time:74.455, tt:6254.229\n",
      "Ep:84, loss:0.00002, loss_test:0.07283, lr:5.87e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.440, tt:6327.384\n",
      "Ep:85, loss:0.00002, loss_test:0.07158, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.464, tt:6403.905\n",
      "Ep:86, loss:0.00002, loss_test:0.07324, lr:5.75e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.468, tt:6478.680\n",
      "Ep:87, loss:0.00002, loss_test:0.07351, lr:5.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:74.452, tt:6551.751\n",
      "Ep:88, loss:0.00002, loss_test:0.07156, lr:5.64e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.476, tt:6628.407\n",
      "Ep:89, loss:0.00002, loss_test:0.07393, lr:5.58e-03, fs:0.83146 (r=0.747,p=0.937),  time:74.474, tt:6702.647\n",
      "Ep:90, loss:0.00002, loss_test:0.07303, lr:5.53e-03, fs:0.83616 (r=0.747,p=0.949),  time:74.517, tt:6781.006\n",
      "Ep:91, loss:0.00002, loss_test:0.07260, lr:5.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.529, tt:6856.645\n",
      "Ep:92, loss:0.00002, loss_test:0.07311, lr:5.42e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.517, tt:6930.065\n",
      "Ep:93, loss:0.00002, loss_test:0.07280, lr:5.36e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.537, tt:7006.468\n",
      "Ep:94, loss:0.00002, loss_test:0.07359, lr:5.31e-03, fs:0.77381 (r=0.657,p=0.942),  time:74.521, tt:7079.502\n",
      "Ep:95, loss:0.00002, loss_test:0.07353, lr:5.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.503, tt:7152.329\n",
      "Ep:96, loss:0.00002, loss_test:0.07374, lr:5.20e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.483, tt:7224.808\n",
      "Ep:97, loss:0.00002, loss_test:0.07306, lr:5.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.491, tt:7300.128\n",
      "Ep:98, loss:0.00002, loss_test:0.07485, lr:5.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:74.495, tt:7375.039\n",
      "Ep:99, loss:0.00001, loss_test:0.07325, lr:5.05e-03, fs:0.77844 (r=0.657,p=0.956),  time:74.517, tt:7451.671\n",
      "Ep:100, loss:0.00001, loss_test:0.07514, lr:5.00e-03, fs:0.78313 (r=0.657,p=0.970),  time:74.522, tt:7526.677\n",
      "Ep:101, loss:0.00001, loss_test:0.07381, lr:4.95e-03, fs:0.76923 (r=0.657,p=0.929),  time:74.504, tt:7599.440\n",
      "Ep:102, loss:0.00001, loss_test:0.07413, lr:4.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:74.499, tt:7673.447\n",
      "Ep:103, loss:0.00001, loss_test:0.07438, lr:4.85e-03, fs:0.84444 (r=0.768,p=0.938),  time:74.519, tt:7750.022\n",
      "Ep:104, loss:0.00001, loss_test:0.07381, lr:4.80e-03, fs:0.77647 (r=0.667,p=0.930),  time:74.454, tt:7817.670\n",
      "Ep:105, loss:0.00001, loss_test:0.07459, lr:4.75e-03, fs:0.79070 (r=0.687,p=0.932),  time:74.382, tt:7884.530\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"4-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00017, loss_test:0.02644, lr:6.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:14.106, tt:14.106\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02788, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:19.094, tt:38.188\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.03067, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.394, tt:64.182\n",
      "Ep:3, loss:0.00006, loss_test:0.03130, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.760, tt:95.041\n",
      "Ep:4, loss:0.00006, loss_test:0.03109, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:25.823, tt:129.113\n",
      "Ep:5, loss:0.00006, loss_test:0.03043, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:27.034, tt:162.203\n",
      "Ep:6, loss:0.00006, loss_test:0.02951, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:28.144, tt:197.007\n",
      "Ep:7, loss:0.00005, loss_test:0.02875, lr:6.00e-02, fs:0.64260 (r=0.899,p=0.500),  time:28.962, tt:231.694\n",
      "Ep:8, loss:0.00005, loss_test:0.02813, lr:6.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:29.599, tt:266.388\n",
      "Ep:9, loss:0.00005, loss_test:0.02759, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:30.171, tt:301.709\n",
      "Ep:10, loss:0.00005, loss_test:0.02691, lr:6.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:30.441, tt:334.849\n",
      "Ep:11, loss:0.00005, loss_test:0.02610, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:30.803, tt:369.641\n",
      "Ep:12, loss:0.00005, loss_test:0.02534, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:31.080, tt:404.044\n",
      "Ep:13, loss:0.00005, loss_test:0.02463, lr:5.94e-02, fs:0.66429 (r=0.939,p=0.514),  time:31.294, tt:438.116\n",
      "Ep:14, loss:0.00005, loss_test:0.02391, lr:5.88e-02, fs:0.67143 (r=0.949,p=0.519),  time:31.528, tt:472.917\n",
      "Ep:15, loss:0.00005, loss_test:0.02315, lr:5.82e-02, fs:0.67626 (r=0.949,p=0.525),  time:31.666, tt:506.661\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02245, lr:5.82e-02, fs:0.66667 (r=0.919,p=0.523),  time:31.844, tt:541.346\n",
      "Ep:17, loss:0.00004, loss_test:0.02186, lr:5.82e-02, fs:0.66418 (r=0.899,p=0.527),  time:32.002, tt:576.029\n",
      "Ep:18, loss:0.00004, loss_test:0.02137, lr:5.82e-02, fs:0.67164 (r=0.909,p=0.533),  time:32.178, tt:611.385\n",
      "Ep:19, loss:0.00004, loss_test:0.02096, lr:5.82e-02, fs:0.67669 (r=0.909,p=0.539),  time:32.281, tt:645.613\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.02068, lr:5.82e-02, fs:0.67669 (r=0.909,p=0.539),  time:32.456, tt:681.570\n",
      "Ep:21, loss:0.00004, loss_test:0.02047, lr:5.82e-02, fs:0.68679 (r=0.919,p=0.548),  time:32.538, tt:715.836\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.02018, lr:5.82e-02, fs:0.69434 (r=0.929,p=0.554),  time:32.583, tt:749.401\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01984, lr:5.82e-02, fs:0.70455 (r=0.939,p=0.564),  time:32.622, tt:782.926\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01943, lr:5.82e-02, fs:0.69962 (r=0.929,p=0.561),  time:32.702, tt:817.546\n",
      "Ep:25, loss:0.00004, loss_test:0.01904, lr:5.82e-02, fs:0.70189 (r=0.939,p=0.560),  time:32.727, tt:850.911\n",
      "Ep:26, loss:0.00004, loss_test:0.01873, lr:5.82e-02, fs:0.70000 (r=0.919,p=0.565),  time:32.750, tt:884.253\n",
      "Ep:27, loss:0.00004, loss_test:0.01851, lr:5.82e-02, fs:0.69767 (r=0.909,p=0.566),  time:32.758, tt:917.237\n",
      "Ep:28, loss:0.00004, loss_test:0.01818, lr:5.82e-02, fs:0.70312 (r=0.909,p=0.573),  time:32.785, tt:950.779\n",
      "Ep:29, loss:0.00004, loss_test:0.01784, lr:5.82e-02, fs:0.71094 (r=0.919,p=0.580),  time:32.884, tt:986.532\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00004, loss_test:0.01768, lr:5.82e-02, fs:0.71875 (r=0.929,p=0.586),  time:32.927, tt:1020.745\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.01753, lr:5.82e-02, fs:0.71654 (r=0.919,p=0.587),  time:32.939, tt:1054.044\n",
      "Ep:32, loss:0.00004, loss_test:0.01730, lr:5.82e-02, fs:0.71937 (r=0.919,p=0.591),  time:32.960, tt:1087.680\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01713, lr:5.82e-02, fs:0.73016 (r=0.929,p=0.601),  time:32.946, tt:1120.163\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01703, lr:5.82e-02, fs:0.71875 (r=0.929,p=0.586),  time:32.940, tt:1152.885\n",
      "Ep:35, loss:0.00003, loss_test:0.01693, lr:5.82e-02, fs:0.72656 (r=0.939,p=0.592),  time:32.966, tt:1186.760\n",
      "Ep:36, loss:0.00003, loss_test:0.01679, lr:5.82e-02, fs:0.72727 (r=0.929,p=0.597),  time:32.982, tt:1220.336\n",
      "Ep:37, loss:0.00003, loss_test:0.01670, lr:5.82e-02, fs:0.73518 (r=0.939,p=0.604),  time:32.999, tt:1253.979\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01658, lr:5.82e-02, fs:0.73437 (r=0.949,p=0.599),  time:33.017, tt:1287.666\n",
      "Ep:39, loss:0.00003, loss_test:0.01649, lr:5.82e-02, fs:0.73725 (r=0.949,p=0.603),  time:33.050, tt:1322.007\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01639, lr:5.82e-02, fs:0.74016 (r=0.949,p=0.606),  time:33.080, tt:1356.285\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01627, lr:5.82e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.113, tt:1390.744\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01618, lr:5.82e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.166, tt:1426.148\n",
      "Ep:43, loss:0.00003, loss_test:0.01612, lr:5.82e-02, fs:0.75502 (r=0.949,p=0.627),  time:33.186, tt:1460.186\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01593, lr:5.82e-02, fs:0.75806 (r=0.949,p=0.631),  time:33.189, tt:1493.490\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01574, lr:5.82e-02, fs:0.76113 (r=0.949,p=0.635),  time:33.220, tt:1528.106\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01558, lr:5.82e-02, fs:0.76113 (r=0.949,p=0.635),  time:33.245, tt:1562.511\n",
      "Ep:47, loss:0.00003, loss_test:0.01545, lr:5.82e-02, fs:0.76230 (r=0.939,p=0.641),  time:33.259, tt:1596.429\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01514, lr:5.82e-02, fs:0.76230 (r=0.939,p=0.641),  time:33.313, tt:1632.334\n",
      "Ep:49, loss:0.00003, loss_test:0.01517, lr:5.82e-02, fs:0.75918 (r=0.939,p=0.637),  time:33.313, tt:1665.665\n",
      "Ep:50, loss:0.00003, loss_test:0.01485, lr:5.82e-02, fs:0.75304 (r=0.939,p=0.628),  time:33.318, tt:1699.201\n",
      "Ep:51, loss:0.00002, loss_test:0.01456, lr:5.82e-02, fs:0.75918 (r=0.939,p=0.637),  time:33.322, tt:1732.737\n",
      "Ep:52, loss:0.00002, loss_test:0.01469, lr:5.82e-02, fs:0.76349 (r=0.929,p=0.648),  time:33.304, tt:1765.101\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01444, lr:5.82e-02, fs:0.80000 (r=0.929,p=0.702),  time:33.302, tt:1798.307\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01443, lr:5.82e-02, fs:0.77637 (r=0.929,p=0.667),  time:33.285, tt:1830.678\n",
      "Ep:55, loss:0.00002, loss_test:0.01427, lr:5.82e-02, fs:0.81197 (r=0.960,p=0.704),  time:33.293, tt:1864.418\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01427, lr:5.82e-02, fs:0.81057 (r=0.929,p=0.719),  time:33.292, tt:1897.655\n",
      "Ep:57, loss:0.00002, loss_test:0.01407, lr:5.82e-02, fs:0.81034 (r=0.949,p=0.707),  time:33.309, tt:1931.903\n",
      "Ep:58, loss:0.00002, loss_test:0.01399, lr:5.82e-02, fs:0.81385 (r=0.949,p=0.712),  time:33.333, tt:1966.672\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01412, lr:5.82e-02, fs:0.79325 (r=0.949,p=0.681),  time:33.349, tt:2000.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00002, loss_test:0.01377, lr:5.82e-02, fs:0.82096 (r=0.949,p=0.723),  time:33.370, tt:2035.571\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01453, lr:5.82e-02, fs:0.82667 (r=0.939,p=0.738),  time:33.399, tt:2070.762\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01318, lr:5.82e-02, fs:0.82969 (r=0.960,p=0.731),  time:33.393, tt:2103.772\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01381, lr:5.82e-02, fs:0.78333 (r=0.949,p=0.667),  time:33.385, tt:2136.638\n",
      "Ep:64, loss:0.00002, loss_test:0.01415, lr:5.82e-02, fs:0.80357 (r=0.909,p=0.720),  time:33.376, tt:2169.458\n",
      "Ep:65, loss:0.00002, loss_test:0.01361, lr:5.82e-02, fs:0.78008 (r=0.949,p=0.662),  time:33.406, tt:2204.813\n",
      "Ep:66, loss:0.00002, loss_test:0.01444, lr:5.82e-02, fs:0.81818 (r=0.909,p=0.744),  time:33.416, tt:2238.867\n",
      "Ep:67, loss:0.00002, loss_test:0.01387, lr:5.82e-02, fs:0.79487 (r=0.939,p=0.689),  time:33.426, tt:2272.998\n",
      "Ep:68, loss:0.00002, loss_test:0.01386, lr:5.82e-02, fs:0.84685 (r=0.949,p=0.764),  time:33.463, tt:2308.959\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.01411, lr:5.82e-02, fs:0.84305 (r=0.949,p=0.758),  time:33.481, tt:2343.694\n",
      "Ep:70, loss:0.00002, loss_test:0.01326, lr:5.82e-02, fs:0.81938 (r=0.939,p=0.727),  time:33.471, tt:2376.427\n",
      "Ep:71, loss:0.00002, loss_test:0.01505, lr:5.82e-02, fs:0.81308 (r=0.879,p=0.757),  time:33.490, tt:2411.281\n",
      "Ep:72, loss:0.00002, loss_test:0.01330, lr:5.82e-02, fs:0.81579 (r=0.939,p=0.721),  time:33.481, tt:2444.093\n",
      "Ep:73, loss:0.00002, loss_test:0.01375, lr:5.82e-02, fs:0.85455 (r=0.949,p=0.777),  time:33.496, tt:2478.741\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01345, lr:5.82e-02, fs:0.82819 (r=0.949,p=0.734),  time:33.514, tt:2513.536\n",
      "Ep:75, loss:0.00002, loss_test:0.01315, lr:5.82e-02, fs:0.83036 (r=0.939,p=0.744),  time:33.516, tt:2547.188\n",
      "Ep:76, loss:0.00001, loss_test:0.01560, lr:5.82e-02, fs:0.82464 (r=0.879,p=0.777),  time:33.513, tt:2580.466\n",
      "Ep:77, loss:0.00002, loss_test:0.01286, lr:5.82e-02, fs:0.84821 (r=0.960,p=0.760),  time:33.522, tt:2614.724\n",
      "Ep:78, loss:0.00001, loss_test:0.01325, lr:5.82e-02, fs:0.82301 (r=0.939,p=0.732),  time:33.543, tt:2649.918\n",
      "Ep:79, loss:0.00001, loss_test:0.01537, lr:5.82e-02, fs:0.83254 (r=0.879,p=0.791),  time:33.564, tt:2685.152\n",
      "Ep:80, loss:0.00001, loss_test:0.01380, lr:5.82e-02, fs:0.82192 (r=0.909,p=0.750),  time:33.576, tt:2719.680\n",
      "Ep:81, loss:0.00001, loss_test:0.01416, lr:5.82e-02, fs:0.85185 (r=0.929,p=0.786),  time:33.593, tt:2754.601\n",
      "Ep:82, loss:0.00001, loss_test:0.01438, lr:5.82e-02, fs:0.85167 (r=0.899,p=0.809),  time:33.600, tt:2788.789\n",
      "Ep:83, loss:0.00001, loss_test:0.01468, lr:5.82e-02, fs:0.82028 (r=0.899,p=0.754),  time:33.615, tt:2823.663\n",
      "Ep:84, loss:0.00001, loss_test:0.01426, lr:5.82e-02, fs:0.86256 (r=0.919,p=0.812),  time:33.634, tt:2858.901\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01575, lr:5.82e-02, fs:0.84878 (r=0.879,p=0.821),  time:33.654, tt:2894.218\n",
      "Ep:86, loss:0.00001, loss_test:0.01567, lr:5.82e-02, fs:0.84314 (r=0.869,p=0.819),  time:33.661, tt:2928.508\n",
      "Ep:87, loss:0.00001, loss_test:0.01602, lr:5.82e-02, fs:0.83495 (r=0.869,p=0.804),  time:33.676, tt:2963.510\n",
      "Ep:88, loss:0.00001, loss_test:0.01527, lr:5.82e-02, fs:0.85167 (r=0.899,p=0.809),  time:33.689, tt:2998.296\n",
      "Ep:89, loss:0.00001, loss_test:0.01571, lr:5.82e-02, fs:0.84615 (r=0.889,p=0.807),  time:33.711, tt:3033.993\n",
      "Ep:90, loss:0.00001, loss_test:0.01650, lr:5.82e-02, fs:0.85149 (r=0.869,p=0.835),  time:33.716, tt:3068.184\n",
      "Ep:91, loss:0.00001, loss_test:0.01750, lr:5.82e-02, fs:0.83077 (r=0.818,p=0.844),  time:33.740, tt:3104.043\n",
      "Ep:92, loss:0.00001, loss_test:0.01699, lr:5.82e-02, fs:0.84000 (r=0.848,p=0.832),  time:33.743, tt:3138.067\n",
      "Ep:93, loss:0.00001, loss_test:0.01626, lr:5.82e-02, fs:0.83333 (r=0.859,p=0.810),  time:33.755, tt:3172.968\n",
      "Ep:94, loss:0.00001, loss_test:0.01677, lr:5.82e-02, fs:0.81407 (r=0.818,p=0.810),  time:33.764, tt:3207.553\n",
      "Ep:95, loss:0.00001, loss_test:0.01790, lr:5.82e-02, fs:0.82474 (r=0.808,p=0.842),  time:33.779, tt:3242.740\n",
      "Ep:96, loss:0.00001, loss_test:0.01939, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:33.792, tt:3277.815\n",
      "Ep:97, loss:0.00001, loss_test:0.01733, lr:5.71e-02, fs:0.84000 (r=0.848,p=0.832),  time:33.799, tt:3312.287\n",
      "Ep:98, loss:0.00001, loss_test:0.01726, lr:5.65e-02, fs:0.78788 (r=0.788,p=0.788),  time:33.796, tt:3345.800\n",
      "Ep:99, loss:0.00001, loss_test:0.01863, lr:5.59e-02, fs:0.83077 (r=0.818,p=0.844),  time:33.807, tt:3380.699\n",
      "Ep:100, loss:0.00001, loss_test:0.01902, lr:5.54e-02, fs:0.79167 (r=0.768,p=0.817),  time:33.812, tt:3414.973\n",
      "Ep:101, loss:0.00001, loss_test:0.01799, lr:5.48e-02, fs:0.80000 (r=0.788,p=0.812),  time:33.823, tt:3449.963\n",
      "Ep:102, loss:0.00001, loss_test:0.02045, lr:5.43e-02, fs:0.81720 (r=0.768,p=0.874),  time:33.829, tt:3484.395\n",
      "Ep:103, loss:0.00001, loss_test:0.01954, lr:5.37e-02, fs:0.81481 (r=0.778,p=0.856),  time:33.844, tt:3519.811\n",
      "Ep:104, loss:0.00001, loss_test:0.01982, lr:5.32e-02, fs:0.79381 (r=0.778,p=0.811),  time:33.862, tt:3555.530\n",
      "Ep:105, loss:0.00001, loss_test:0.02141, lr:5.27e-02, fs:0.81081 (r=0.758,p=0.872),  time:33.865, tt:3589.691\n",
      "Ep:106, loss:0.00001, loss_test:0.02177, lr:5.21e-02, fs:0.80000 (r=0.747,p=0.860),  time:33.867, tt:3623.719\n",
      "Ep:107, loss:0.00001, loss_test:0.02150, lr:5.16e-02, fs:0.79365 (r=0.758,p=0.833),  time:33.877, tt:3658.712\n",
      "Ep:108, loss:0.00001, loss_test:0.02066, lr:5.11e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.881, tt:3693.064\n",
      "Ep:109, loss:0.00001, loss_test:0.02279, lr:5.06e-02, fs:0.80435 (r=0.747,p=0.871),  time:33.900, tt:3728.972\n",
      "Ep:110, loss:0.00001, loss_test:0.02292, lr:5.01e-02, fs:0.81081 (r=0.758,p=0.872),  time:33.909, tt:3763.939\n",
      "Ep:111, loss:0.00001, loss_test:0.02369, lr:4.96e-02, fs:0.81081 (r=0.758,p=0.872),  time:33.917, tt:3798.719\n",
      "Ep:112, loss:0.00001, loss_test:0.02348, lr:4.91e-02, fs:0.80220 (r=0.737,p=0.880),  time:33.905, tt:3831.251\n",
      "Ep:113, loss:0.00001, loss_test:0.02400, lr:4.86e-02, fs:0.81081 (r=0.758,p=0.872),  time:33.911, tt:3865.887\n",
      "Ep:114, loss:0.00001, loss_test:0.02273, lr:4.81e-02, fs:0.80851 (r=0.768,p=0.854),  time:33.914, tt:3900.067\n",
      "Ep:115, loss:0.00001, loss_test:0.02307, lr:4.76e-02, fs:0.78022 (r=0.717,p=0.855),  time:33.922, tt:3934.922\n",
      "Ep:116, loss:0.00001, loss_test:0.02350, lr:4.71e-02, fs:0.81081 (r=0.758,p=0.872),  time:33.927, tt:3969.501\n",
      "Ep:117, loss:0.00001, loss_test:0.02488, lr:4.67e-02, fs:0.81967 (r=0.758,p=0.893),  time:33.943, tt:4005.229\n",
      "Ep:118, loss:0.00000, loss_test:0.02439, lr:4.62e-02, fs:0.80645 (r=0.758,p=0.862),  time:33.948, tt:4039.851\n",
      "Ep:119, loss:0.00000, loss_test:0.02512, lr:4.57e-02, fs:0.81319 (r=0.747,p=0.892),  time:33.954, tt:4074.504\n",
      "Ep:120, loss:0.00000, loss_test:0.02515, lr:4.53e-02, fs:0.81967 (r=0.758,p=0.893),  time:33.962, tt:4109.420\n",
      "Ep:121, loss:0.00000, loss_test:0.02639, lr:4.48e-02, fs:0.81319 (r=0.747,p=0.892),  time:33.963, tt:4143.474\n",
      "Ep:122, loss:0.00000, loss_test:0.02530, lr:4.44e-02, fs:0.81081 (r=0.758,p=0.872),  time:33.970, tt:4178.366\n",
      "Ep:123, loss:0.00000, loss_test:0.02675, lr:4.39e-02, fs:0.81319 (r=0.747,p=0.892),  time:33.980, tt:4213.539\n",
      "Ep:124, loss:0.00000, loss_test:0.02660, lr:4.35e-02, fs:0.81564 (r=0.737,p=0.912),  time:33.986, tt:4248.279\n",
      "Ep:125, loss:0.00000, loss_test:0.02735, lr:4.31e-02, fs:0.82418 (r=0.758,p=0.904),  time:33.997, tt:4283.676\n",
      "Ep:126, loss:0.00000, loss_test:0.02613, lr:4.26e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.003, tt:4318.428\n",
      "Ep:127, loss:0.00000, loss_test:0.02710, lr:4.22e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.006, tt:4352.776\n",
      "Ep:128, loss:0.00000, loss_test:0.02687, lr:4.18e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.014, tt:4387.790\n",
      "Ep:129, loss:0.00000, loss_test:0.02866, lr:4.14e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.014, tt:4421.796\n",
      "Ep:130, loss:0.00000, loss_test:0.02604, lr:4.10e-02, fs:0.81081 (r=0.758,p=0.872),  time:34.021, tt:4456.688\n",
      "Ep:131, loss:0.00000, loss_test:0.02800, lr:4.05e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.021, tt:4490.794\n",
      "Ep:132, loss:0.00000, loss_test:0.02810, lr:4.01e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.047, tt:4528.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.02840, lr:3.97e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.051, tt:4562.806\n",
      "Ep:134, loss:0.00000, loss_test:0.02800, lr:3.93e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.044, tt:4596.006\n",
      "Ep:135, loss:0.00000, loss_test:0.02814, lr:3.89e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.050, tt:4630.819\n",
      "Ep:136, loss:0.00000, loss_test:0.02904, lr:3.86e-02, fs:0.81768 (r=0.747,p=0.902),  time:34.051, tt:4664.963\n",
      "Ep:137, loss:0.00000, loss_test:0.02908, lr:3.82e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.055, tt:4699.531\n",
      "Ep:138, loss:0.00000, loss_test:0.02968, lr:3.78e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.054, tt:4733.454\n",
      "Ep:139, loss:0.00000, loss_test:0.02957, lr:3.74e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.059, tt:4768.221\n",
      "Ep:140, loss:0.00000, loss_test:0.03007, lr:3.70e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.070, tt:4803.828\n",
      "Ep:141, loss:0.00000, loss_test:0.02971, lr:3.67e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.088, tt:4840.429\n",
      "Ep:142, loss:0.00000, loss_test:0.03035, lr:3.63e-02, fs:0.81768 (r=0.747,p=0.902),  time:34.092, tt:4875.162\n",
      "Ep:143, loss:0.00000, loss_test:0.03018, lr:3.59e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.091, tt:4909.039\n",
      "Ep:144, loss:0.00000, loss_test:0.03092, lr:3.56e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.096, tt:4943.890\n",
      "Ep:145, loss:0.00000, loss_test:0.02946, lr:3.52e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.099, tt:4978.431\n",
      "Ep:146, loss:0.00000, loss_test:0.03063, lr:3.49e-02, fs:0.77095 (r=0.697,p=0.863),  time:34.101, tt:5012.832\n",
      "Ep:147, loss:0.00000, loss_test:0.03007, lr:3.45e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.090, tt:5045.393\n",
      "Ep:148, loss:0.00000, loss_test:0.03136, lr:3.42e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.098, tt:5080.629\n",
      "Ep:149, loss:0.00000, loss_test:0.03021, lr:3.38e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.099, tt:5114.867\n",
      "Ep:150, loss:0.00000, loss_test:0.03067, lr:3.35e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.100, tt:5149.040\n",
      "Ep:151, loss:0.00000, loss_test:0.03072, lr:3.32e-02, fs:0.76744 (r=0.667,p=0.904),  time:34.103, tt:5183.692\n",
      "Ep:152, loss:0.00000, loss_test:0.03138, lr:3.28e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.105, tt:5217.988\n",
      "Ep:153, loss:0.00000, loss_test:0.03103, lr:3.25e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.101, tt:5251.617\n",
      "Ep:154, loss:0.00000, loss_test:0.03136, lr:3.22e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.097, tt:5284.999\n",
      "Ep:155, loss:0.00000, loss_test:0.03194, lr:3.19e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.097, tt:5319.123\n",
      "Ep:156, loss:0.00000, loss_test:0.03152, lr:3.15e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.094, tt:5352.781\n",
      "Ep:157, loss:0.00000, loss_test:0.03212, lr:3.12e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.100, tt:5387.736\n",
      "Ep:158, loss:0.00000, loss_test:0.03166, lr:3.09e-02, fs:0.76571 (r=0.677,p=0.882),  time:34.111, tt:5423.715\n",
      "Ep:159, loss:0.00000, loss_test:0.03261, lr:3.06e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.125, tt:5459.926\n",
      "Ep:160, loss:0.00000, loss_test:0.03208, lr:3.03e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.134, tt:5495.640\n",
      "Ep:161, loss:0.00000, loss_test:0.03235, lr:3.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.133, tt:5529.563\n",
      "Ep:162, loss:0.00000, loss_test:0.03244, lr:2.97e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.141, tt:5564.937\n",
      "Ep:163, loss:0.00000, loss_test:0.03231, lr:2.94e-02, fs:0.76023 (r=0.657,p=0.903),  time:34.141, tt:5599.169\n",
      "Ep:164, loss:0.00000, loss_test:0.03250, lr:2.91e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.144, tt:5633.802\n",
      "Ep:165, loss:0.00000, loss_test:0.03249, lr:2.88e-02, fs:0.73684 (r=0.636,p=0.875),  time:34.146, tt:5668.233\n",
      "Ep:166, loss:0.00000, loss_test:0.03313, lr:2.85e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.142, tt:5701.660\n",
      "Ep:167, loss:0.00000, loss_test:0.03282, lr:2.82e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.152, tt:5737.492\n",
      "Ep:168, loss:0.00000, loss_test:0.03258, lr:2.80e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.163, tt:5773.524\n",
      "Ep:169, loss:0.00000, loss_test:0.03335, lr:2.77e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.172, tt:5809.273\n",
      "Ep:170, loss:0.00000, loss_test:0.03270, lr:2.74e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.184, tt:5845.394\n",
      "Ep:171, loss:0.00000, loss_test:0.03296, lr:2.71e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.191, tt:5880.786\n",
      "Ep:172, loss:0.00000, loss_test:0.03323, lr:2.69e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.201, tt:5916.742\n",
      "Ep:173, loss:0.00000, loss_test:0.03328, lr:2.66e-02, fs:0.74118 (r=0.636,p=0.887),  time:34.209, tt:5952.396\n",
      "Ep:174, loss:0.00000, loss_test:0.03361, lr:2.63e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.213, tt:5987.234\n",
      "Ep:175, loss:0.00000, loss_test:0.03371, lr:2.61e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.219, tt:6022.585\n",
      "Ep:176, loss:0.00000, loss_test:0.03362, lr:2.58e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.224, tt:6057.684\n",
      "Ep:177, loss:0.00000, loss_test:0.03361, lr:2.55e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.234, tt:6093.712\n",
      "Ep:178, loss:0.00000, loss_test:0.03385, lr:2.53e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.237, tt:6128.513\n",
      "Ep:179, loss:0.00000, loss_test:0.03402, lr:2.50e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.241, tt:6163.440\n",
      "Ep:180, loss:0.00000, loss_test:0.03416, lr:2.48e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.246, tt:6198.587\n",
      "Ep:181, loss:0.00000, loss_test:0.03430, lr:2.45e-02, fs:0.71951 (r=0.596,p=0.908),  time:34.262, tt:6235.702\n",
      "Ep:182, loss:0.00000, loss_test:0.03393, lr:2.43e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.264, tt:6270.319\n",
      "Ep:183, loss:0.00000, loss_test:0.03439, lr:2.40e-02, fs:0.69512 (r=0.576,p=0.877),  time:34.272, tt:6306.035\n",
      "Ep:184, loss:0.00000, loss_test:0.03419, lr:2.38e-02, fs:0.75449 (r=0.636,p=0.926),  time:34.281, tt:6341.955\n",
      "Ep:185, loss:0.00000, loss_test:0.03465, lr:2.36e-02, fs:0.69939 (r=0.576,p=0.891),  time:34.282, tt:6376.394\n",
      "Ep:186, loss:0.00000, loss_test:0.03447, lr:2.33e-02, fs:0.72393 (r=0.596,p=0.922),  time:34.288, tt:6411.835\n",
      "Ep:187, loss:0.00000, loss_test:0.03454, lr:2.31e-02, fs:0.71166 (r=0.586,p=0.906),  time:34.289, tt:6446.273\n",
      "Ep:188, loss:0.00000, loss_test:0.03480, lr:2.29e-02, fs:0.73939 (r=0.616,p=0.924),  time:34.290, tt:6480.875\n",
      "Ep:189, loss:0.00000, loss_test:0.03475, lr:2.26e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.291, tt:6515.235\n",
      "Ep:190, loss:0.00000, loss_test:0.03498, lr:2.24e-02, fs:0.70000 (r=0.566,p=0.918),  time:34.292, tt:6549.807\n",
      "Ep:191, loss:0.00000, loss_test:0.03483, lr:2.22e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.295, tt:6584.603\n",
      "Ep:192, loss:0.00000, loss_test:0.03487, lr:2.20e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.298, tt:6619.534\n",
      "Ep:193, loss:0.00000, loss_test:0.03509, lr:2.17e-02, fs:0.70000 (r=0.566,p=0.918),  time:34.294, tt:6653.115\n",
      "Ep:194, loss:0.00000, loss_test:0.03527, lr:2.15e-02, fs:0.70807 (r=0.576,p=0.919),  time:34.307, tt:6689.903\n",
      "Ep:195, loss:0.00000, loss_test:0.03500, lr:2.13e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.298, tt:6722.312\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02031, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:22.874, tt:22.874\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02063, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:23.895, tt:47.790\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02207, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.590, tt:73.770\n",
      "Ep:3, loss:0.00004, loss_test:0.02237, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.802, tt:103.209\n",
      "Ep:4, loss:0.00004, loss_test:0.02190, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.464, tt:132.321\n",
      "Ep:5, loss:0.00004, loss_test:0.02102, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:26.837, tt:161.024\n",
      "Ep:6, loss:0.00004, loss_test:0.01999, lr:6.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:27.011, tt:189.079\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00004, loss_test:0.01912, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:27.209, tt:217.670\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01852, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:27.584, tt:248.255\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01796, lr:6.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:27.764, tt:277.639\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01735, lr:6.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:27.898, tt:306.874\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:28.014, tt:336.172\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.74131 (r=0.970,p=0.600),  time:28.115, tt:365.489\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.74615 (r=0.980,p=0.602),  time:28.221, tt:395.099\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.75385 (r=0.990,p=0.609),  time:28.358, tt:425.371\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01620, lr:6.00e-02, fs:0.75486 (r=0.980,p=0.614),  time:28.377, tt:454.032\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:28.425, tt:483.225\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01580, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:28.490, tt:512.821\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:28.527, tt:542.007\n",
      "Ep:19, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.77551 (r=0.960,p=0.651),  time:28.645, tt:572.895\n",
      "Ep:20, loss:0.00003, loss_test:0.01516, lr:6.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:28.712, tt:602.959\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01498, lr:6.00e-02, fs:0.79352 (r=0.990,p=0.662),  time:28.845, tt:634.584\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01483, lr:6.00e-02, fs:0.79184 (r=0.980,p=0.664),  time:28.892, tt:664.517\n",
      "Ep:23, loss:0.00003, loss_test:0.01468, lr:6.00e-02, fs:0.79835 (r=0.980,p=0.674),  time:28.862, tt:692.695\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01452, lr:6.00e-02, fs:0.79668 (r=0.970,p=0.676),  time:28.916, tt:722.912\n",
      "Ep:25, loss:0.00003, loss_test:0.01439, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:28.952, tt:752.742\n",
      "Ep:26, loss:0.00003, loss_test:0.01426, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:28.987, tt:782.641\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:29.013, tt:812.370\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01401, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:29.056, tt:842.616\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01391, lr:6.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:29.050, tt:871.505\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:29.123, tt:902.802\n",
      "Ep:31, loss:0.00002, loss_test:0.01371, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:29.187, tt:933.990\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:29.217, tt:964.157\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:29.251, tt:994.533\n",
      "Ep:34, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:29.286, tt:1025.016\n",
      "Ep:35, loss:0.00002, loss_test:0.01328, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:29.322, tt:1055.598\n",
      "Ep:36, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.379, tt:1087.024\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.413, tt:1117.689\n",
      "Ep:38, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.479, tt:1149.699\n",
      "Ep:39, loss:0.00002, loss_test:0.01292, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.502, tt:1180.069\n",
      "Ep:40, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.561, tt:1212.001\n",
      "Ep:41, loss:0.00002, loss_test:0.01278, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.592, tt:1242.858\n",
      "Ep:42, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.616, tt:1273.483\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.657, tt:1304.924\n",
      "Ep:44, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.691, tt:1336.110\n",
      "Ep:45, loss:0.00002, loss_test:0.01244, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.729, tt:1367.517\n",
      "Ep:46, loss:0.00002, loss_test:0.01237, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.780, tt:1399.655\n",
      "Ep:47, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.782, tt:1429.517\n",
      "Ep:48, loss:0.00002, loss_test:0.01223, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.776, tt:1459.012\n",
      "Ep:49, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:29.791, tt:1489.575\n",
      "Ep:50, loss:0.00002, loss_test:0.01211, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.816, tt:1520.610\n",
      "Ep:51, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:29.835, tt:1551.409\n",
      "Ep:52, loss:0.00002, loss_test:0.01200, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:29.849, tt:1581.996\n",
      "Ep:53, loss:0.00002, loss_test:0.01195, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:29.866, tt:1612.763\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01189, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:29.854, tt:1641.952\n",
      "Ep:55, loss:0.00002, loss_test:0.01184, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:29.850, tt:1671.602\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01180, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:29.865, tt:1702.309\n",
      "Ep:57, loss:0.00002, loss_test:0.01173, lr:6.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:29.898, tt:1734.096\n",
      "Ep:58, loss:0.00002, loss_test:0.01170, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:29.890, tt:1763.487\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01166, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:29.875, tt:1792.472\n",
      "Ep:60, loss:0.00001, loss_test:0.01163, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:29.913, tt:1824.702\n",
      "Ep:61, loss:0.00001, loss_test:0.01157, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:29.929, tt:1855.609\n",
      "Ep:62, loss:0.00001, loss_test:0.01152, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:29.939, tt:1886.155\n",
      "Ep:63, loss:0.00001, loss_test:0.01149, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:29.948, tt:1916.691\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01147, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:29.940, tt:1946.082\n",
      "Ep:65, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:29.966, tt:1977.763\n",
      "Ep:66, loss:0.00001, loss_test:0.01136, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:29.979, tt:2008.594\n",
      "Ep:67, loss:0.00001, loss_test:0.01134, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:30.011, tt:2040.734\n",
      "Ep:68, loss:0.00001, loss_test:0.01131, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:30.020, tt:2071.386\n",
      "Ep:69, loss:0.00001, loss_test:0.01126, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:30.025, tt:2101.730\n",
      "Ep:70, loss:0.00001, loss_test:0.01122, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:30.022, tt:2131.570\n",
      "Ep:71, loss:0.00001, loss_test:0.01122, lr:6.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:30.022, tt:2161.613\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.01119, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.064, tt:2194.681\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01112, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.065, tt:2224.777\n",
      "Ep:74, loss:0.00001, loss_test:0.01110, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.072, tt:2255.365\n",
      "Ep:75, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.111, tt:2288.455\n",
      "Ep:76, loss:0.00001, loss_test:0.01105, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.125, tt:2319.610\n",
      "Ep:77, loss:0.00001, loss_test:0.01102, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.140, tt:2350.946\n",
      "Ep:78, loss:0.00001, loss_test:0.01101, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.148, tt:2381.663\n",
      "Ep:79, loss:0.00001, loss_test:0.01099, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.154, tt:2412.299\n",
      "Ep:80, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.162, tt:2443.122\n",
      "Ep:81, loss:0.00001, loss_test:0.01091, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:30.167, tt:2473.732\n",
      "Ep:82, loss:0.00001, loss_test:0.01091, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:30.185, tt:2505.346\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01089, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:30.199, tt:2536.717\n",
      "Ep:84, loss:0.00001, loss_test:0.01089, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:30.216, tt:2568.373\n",
      "Ep:85, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:30.212, tt:2598.201\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01083, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:30.222, tt:2629.282\n",
      "Ep:87, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:30.217, tt:2659.056\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:30.224, tt:2689.948\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:30.233, tt:2720.939\n",
      "Ep:90, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:30.227, tt:2750.686\n",
      "Ep:91, loss:0.00001, loss_test:0.01079, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.231, tt:2781.214\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01073, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.212, tt:2809.713\n",
      "Ep:93, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.209, tt:2839.688\n",
      "Ep:94, loss:0.00001, loss_test:0.01074, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.203, tt:2869.276\n",
      "Ep:95, loss:0.00001, loss_test:0.01076, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:30.194, tt:2898.659\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.183, tt:2927.722\n",
      "Ep:97, loss:0.00001, loss_test:0.01074, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:30.183, tt:2957.969\n",
      "Ep:98, loss:0.00001, loss_test:0.01068, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.195, tt:2989.280\n",
      "Ep:99, loss:0.00001, loss_test:0.01066, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:30.196, tt:3019.587\n",
      "Ep:100, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:30.205, tt:3050.677\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01071, lr:6.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:30.212, tt:3081.638\n",
      "Ep:102, loss:0.00001, loss_test:0.01069, lr:6.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:30.217, tt:3112.325\n",
      "Ep:103, loss:0.00001, loss_test:0.01067, lr:6.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:30.228, tt:3143.713\n",
      "Ep:104, loss:0.00001, loss_test:0.01069, lr:6.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:30.236, tt:3174.816\n",
      "Ep:105, loss:0.00001, loss_test:0.01073, lr:6.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:30.236, tt:3204.982\n",
      "Ep:106, loss:0.00001, loss_test:0.01067, lr:6.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:30.236, tt:3235.241\n",
      "Ep:107, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:30.243, tt:3266.215\n",
      "Ep:108, loss:0.00001, loss_test:0.01071, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:30.251, tt:3297.355\n",
      "Ep:109, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:30.266, tt:3329.255\n",
      "Ep:110, loss:0.00001, loss_test:0.01073, lr:6.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:30.268, tt:3359.757\n",
      "Ep:111, loss:0.00001, loss_test:0.01074, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.264, tt:3389.548\n",
      "Ep:112, loss:0.00001, loss_test:0.01072, lr:5.94e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.264, tt:3419.806\n",
      "Ep:113, loss:0.00001, loss_test:0.01070, lr:5.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:30.263, tt:3449.971\n",
      "Ep:114, loss:0.00001, loss_test:0.01075, lr:5.82e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.270, tt:3481.050\n",
      "Ep:115, loss:0.00001, loss_test:0.01074, lr:5.76e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.268, tt:3511.105\n",
      "Ep:116, loss:0.00001, loss_test:0.01077, lr:5.71e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.282, tt:3543.000\n",
      "Ep:117, loss:0.00001, loss_test:0.01076, lr:5.65e-02, fs:0.89340 (r=0.889,p=0.898),  time:30.286, tt:3573.760\n",
      "Ep:118, loss:0.00001, loss_test:0.01077, lr:5.59e-02, fs:0.89796 (r=0.889,p=0.907),  time:30.298, tt:3605.467\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.01077, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.297, tt:3635.667\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.01076, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.300, tt:3666.303\n",
      "Ep:121, loss:0.00001, loss_test:0.01076, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.297, tt:3696.230\n",
      "Ep:122, loss:0.00001, loss_test:0.01081, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.285, tt:3724.999\n",
      "Ep:123, loss:0.00001, loss_test:0.01080, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.284, tt:3755.258\n",
      "Ep:124, loss:0.00001, loss_test:0.01085, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.277, tt:3784.618\n",
      "Ep:125, loss:0.00001, loss_test:0.01084, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.278, tt:3815.008\n",
      "Ep:126, loss:0.00001, loss_test:0.01085, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.280, tt:3845.534\n",
      "Ep:127, loss:0.00001, loss_test:0.01087, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.276, tt:3875.390\n",
      "Ep:128, loss:0.00001, loss_test:0.01088, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.274, tt:3905.369\n",
      "Ep:129, loss:0.00001, loss_test:0.01088, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.259, tt:3933.707\n",
      "Ep:130, loss:0.00001, loss_test:0.01094, lr:5.59e-02, fs:0.90722 (r=0.889,p=0.926),  time:30.259, tt:3963.865\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.01097, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.265, tt:3994.983\n",
      "Ep:132, loss:0.00001, loss_test:0.01093, lr:5.59e-02, fs:0.90256 (r=0.889,p=0.917),  time:30.263, tt:4024.923\n",
      "Ep:133, loss:0.00001, loss_test:0.01100, lr:5.59e-02, fs:0.90722 (r=0.889,p=0.926),  time:30.268, tt:4055.943\n",
      "Ep:134, loss:0.00001, loss_test:0.01097, lr:5.59e-02, fs:0.90722 (r=0.889,p=0.926),  time:30.258, tt:4084.885\n",
      "Ep:135, loss:0.00001, loss_test:0.01099, lr:5.59e-02, fs:0.90155 (r=0.879,p=0.926),  time:30.260, tt:4115.327\n",
      "Ep:136, loss:0.00001, loss_test:0.01103, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.261, tt:4145.789\n",
      "Ep:137, loss:0.00001, loss_test:0.01100, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.268, tt:4176.932\n",
      "Ep:138, loss:0.00001, loss_test:0.01105, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.258, tt:4205.857\n",
      "Ep:139, loss:0.00001, loss_test:0.01109, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.255, tt:4235.713\n",
      "Ep:140, loss:0.00001, loss_test:0.01110, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.261, tt:4266.840\n",
      "Ep:141, loss:0.00001, loss_test:0.01111, lr:5.59e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.266, tt:4297.806\n",
      "Ep:142, loss:0.00001, loss_test:0.01113, lr:5.54e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.272, tt:4328.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.01113, lr:5.48e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.282, tt:4360.544\n",
      "Ep:144, loss:0.00001, loss_test:0.01115, lr:5.43e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.290, tt:4392.012\n",
      "Ep:145, loss:0.00001, loss_test:0.01120, lr:5.37e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.289, tt:4422.233\n",
      "Ep:146, loss:0.00000, loss_test:0.01121, lr:5.32e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.292, tt:4452.974\n",
      "Ep:147, loss:0.00000, loss_test:0.01122, lr:5.27e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.299, tt:4484.236\n",
      "Ep:148, loss:0.00000, loss_test:0.01124, lr:5.21e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.294, tt:4513.875\n",
      "Ep:149, loss:0.00000, loss_test:0.01128, lr:5.16e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.292, tt:4543.798\n",
      "Ep:150, loss:0.00000, loss_test:0.01130, lr:5.11e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.298, tt:4575.069\n",
      "Ep:151, loss:0.00000, loss_test:0.01126, lr:5.06e-02, fs:0.88421 (r=0.848,p=0.923),  time:30.298, tt:4605.304\n",
      "Ep:152, loss:0.00000, loss_test:0.01127, lr:5.01e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.292, tt:4634.713\n",
      "Ep:153, loss:0.00000, loss_test:0.01133, lr:4.96e-02, fs:0.86631 (r=0.818,p=0.920),  time:30.291, tt:4664.737\n",
      "Ep:154, loss:0.00000, loss_test:0.01131, lr:4.91e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.290, tt:4694.943\n",
      "Ep:155, loss:0.00000, loss_test:0.01136, lr:4.86e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.295, tt:4725.950\n",
      "Ep:156, loss:0.00000, loss_test:0.01137, lr:4.81e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.296, tt:4756.464\n",
      "Ep:157, loss:0.00000, loss_test:0.01137, lr:4.76e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.301, tt:4787.515\n",
      "Ep:158, loss:0.00000, loss_test:0.01140, lr:4.71e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.301, tt:4817.839\n",
      "Ep:159, loss:0.00000, loss_test:0.01144, lr:4.67e-02, fs:0.84783 (r=0.788,p=0.918),  time:30.306, tt:4849.035\n",
      "Ep:160, loss:0.00000, loss_test:0.01146, lr:4.62e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.298, tt:4878.017\n",
      "Ep:161, loss:0.00000, loss_test:0.01149, lr:4.57e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.293, tt:4907.545\n",
      "Ep:162, loss:0.00000, loss_test:0.01150, lr:4.53e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.293, tt:4937.822\n",
      "Ep:163, loss:0.00000, loss_test:0.01150, lr:4.48e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.293, tt:4968.033\n",
      "Ep:164, loss:0.00000, loss_test:0.01150, lr:4.44e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.295, tt:4998.729\n",
      "Ep:165, loss:0.00000, loss_test:0.01155, lr:4.39e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.297, tt:5029.295\n",
      "Ep:166, loss:0.00000, loss_test:0.01155, lr:4.35e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.302, tt:5060.482\n",
      "Ep:167, loss:0.00000, loss_test:0.01156, lr:4.31e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.308, tt:5091.672\n",
      "Ep:168, loss:0.00000, loss_test:0.01161, lr:4.26e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.305, tt:5121.561\n",
      "Ep:169, loss:0.00000, loss_test:0.01158, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.300, tt:5151.040\n",
      "Ep:170, loss:0.00000, loss_test:0.01159, lr:4.18e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.293, tt:5180.187\n",
      "Ep:171, loss:0.00000, loss_test:0.01166, lr:4.14e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.296, tt:5210.825\n",
      "Ep:172, loss:0.00000, loss_test:0.01166, lr:4.10e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.293, tt:5240.684\n",
      "Ep:173, loss:0.00000, loss_test:0.01165, lr:4.05e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.286, tt:5269.776\n",
      "Ep:174, loss:0.00000, loss_test:0.01165, lr:4.01e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.280, tt:5298.954\n",
      "Ep:175, loss:0.00000, loss_test:0.01169, lr:3.97e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.281, tt:5329.389\n",
      "Ep:176, loss:0.00000, loss_test:0.01172, lr:3.93e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.277, tt:5359.023\n",
      "Ep:177, loss:0.00000, loss_test:0.01170, lr:3.89e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.273, tt:5388.538\n",
      "Ep:178, loss:0.00000, loss_test:0.01174, lr:3.86e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.269, tt:5418.168\n",
      "Ep:179, loss:0.00000, loss_test:0.01178, lr:3.82e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.270, tt:5448.688\n",
      "Ep:180, loss:0.00000, loss_test:0.01174, lr:3.78e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.278, tt:5480.407\n",
      "Ep:181, loss:0.00000, loss_test:0.01178, lr:3.74e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.274, tt:5509.956\n",
      "Ep:182, loss:0.00000, loss_test:0.01180, lr:3.70e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.275, tt:5540.288\n",
      "Ep:183, loss:0.00000, loss_test:0.01182, lr:3.67e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.280, tt:5571.519\n",
      "Ep:184, loss:0.00000, loss_test:0.01181, lr:3.63e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.276, tt:5600.974\n",
      "Ep:185, loss:0.00000, loss_test:0.01185, lr:3.59e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.278, tt:5631.648\n",
      "Ep:186, loss:0.00000, loss_test:0.01186, lr:3.56e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.280, tt:5662.335\n",
      "Ep:187, loss:0.00000, loss_test:0.01187, lr:3.52e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.282, tt:5693.058\n",
      "Ep:188, loss:0.00000, loss_test:0.01186, lr:3.49e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.285, tt:5723.847\n",
      "Ep:189, loss:0.00000, loss_test:0.01190, lr:3.45e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.274, tt:5751.974\n",
      "Ep:190, loss:0.00000, loss_test:0.01193, lr:3.42e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.281, tt:5783.675\n",
      "Ep:191, loss:0.00000, loss_test:0.01190, lr:3.38e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.278, tt:5813.343\n",
      "Ep:192, loss:0.00000, loss_test:0.01191, lr:3.35e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.278, tt:5843.629\n",
      "Ep:193, loss:0.00000, loss_test:0.01194, lr:3.32e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.283, tt:5874.926\n",
      "Ep:194, loss:0.00000, loss_test:0.01193, lr:3.28e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.276, tt:5903.733\n",
      "Ep:195, loss:0.00000, loss_test:0.01196, lr:3.25e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.273, tt:5933.544\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02043, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:32.161, tt:32.161\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02294, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.507, tt:69.014\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02373, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.658, tt:106.975\n",
      "Ep:3, loss:0.00005, loss_test:0.02308, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.294, tt:145.174\n",
      "Ep:4, loss:0.00004, loss_test:0.02179, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:36.763, tt:183.813\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02025, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:37.267, tt:223.605\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01908, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:37.557, tt:262.901\n",
      "Ep:7, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:37.779, tt:302.229\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01807, lr:6.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:38.050, tt:342.447\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01736, lr:6.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:38.038, tt:380.384\n",
      "Ep:10, loss:0.00003, loss_test:0.01705, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:38.189, tt:420.079\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01691, lr:6.00e-02, fs:0.72727 (r=0.970,p=0.582),  time:38.169, tt:458.032\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01666, lr:6.00e-02, fs:0.73208 (r=0.980,p=0.584),  time:38.212, tt:496.761\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:38.390, tt:537.460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00003, loss_test:0.01603, lr:6.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:38.495, tt:577.426\n",
      "Ep:15, loss:0.00003, loss_test:0.01579, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:38.505, tt:616.081\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:38.597, tt:656.144\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:38.660, tt:695.875\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:38.674, tt:734.811\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01481, lr:6.00e-02, fs:0.78189 (r=0.960,p=0.660),  time:38.645, tt:772.895\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01462, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:38.626, tt:811.150\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01445, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:38.712, tt:851.663\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01428, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:38.774, tt:891.803\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:38.778, tt:930.663\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:38.790, tt:969.743\n",
      "Ep:25, loss:0.00002, loss_test:0.01370, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:38.846, tt:1009.985\n",
      "Ep:26, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:38.882, tt:1049.804\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:38.940, tt:1090.307\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:38.978, tt:1130.373\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01320, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:38.957, tt:1168.698\n",
      "Ep:30, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:38.981, tt:1208.425\n",
      "Ep:31, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:38.942, tt:1246.152\n",
      "Ep:32, loss:0.00002, loss_test:0.01281, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:38.988, tt:1286.619\n",
      "Ep:33, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:38.976, tt:1325.199\n",
      "Ep:34, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.83333 (r=0.960,p=0.736),  time:38.979, tt:1364.266\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01255, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:38.956, tt:1402.410\n",
      "Ep:36, loss:0.00002, loss_test:0.01247, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:38.981, tt:1442.306\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01237, lr:6.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:38.975, tt:1481.042\n",
      "Ep:38, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:38.943, tt:1518.764\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01223, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:38.907, tt:1556.300\n",
      "Ep:40, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:38.908, tt:1595.227\n",
      "Ep:41, loss:0.00002, loss_test:0.01210, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:38.929, tt:1635.037\n",
      "Ep:42, loss:0.00002, loss_test:0.01203, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:38.889, tt:1672.233\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01195, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:38.921, tt:1712.515\n",
      "Ep:44, loss:0.00002, loss_test:0.01191, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:38.908, tt:1750.859\n",
      "Ep:45, loss:0.00001, loss_test:0.01186, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:38.860, tt:1787.562\n",
      "Ep:46, loss:0.00001, loss_test:0.01181, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:38.815, tt:1824.299\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01176, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:38.767, tt:1860.813\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:38.767, tt:1899.602\n",
      "Ep:49, loss:0.00001, loss_test:0.01167, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:38.754, tt:1937.723\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01161, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:38.759, tt:1976.714\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01160, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:38.775, tt:2016.295\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01157, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:38.723, tt:2052.296\n",
      "Ep:53, loss:0.00001, loss_test:0.01154, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:38.754, tt:2092.702\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01155, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:38.762, tt:2131.920\n",
      "Ep:55, loss:0.00001, loss_test:0.01153, lr:6.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:38.764, tt:2170.792\n",
      "Ep:56, loss:0.00001, loss_test:0.01147, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:38.776, tt:2210.216\n",
      "Ep:57, loss:0.00001, loss_test:0.01146, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:38.753, tt:2247.697\n",
      "Ep:58, loss:0.00001, loss_test:0.01145, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:38.719, tt:2284.403\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01143, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:38.698, tt:2321.890\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01142, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:38.676, tt:2359.259\n",
      "Ep:61, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:38.664, tt:2397.138\n",
      "Ep:62, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:38.663, tt:2435.752\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:38.677, tt:2475.308\n",
      "Ep:64, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:38.670, tt:2513.574\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01135, lr:6.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:38.683, tt:2553.103\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01139, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.683, tt:2591.744\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01140, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.652, tt:2628.351\n",
      "Ep:68, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:38.658, tt:2667.382\n",
      "Ep:69, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.694, tt:2708.549\n",
      "Ep:70, loss:0.00001, loss_test:0.01146, lr:6.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.682, tt:2746.440\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01139, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.674, tt:2784.497\n",
      "Ep:72, loss:0.00001, loss_test:0.01136, lr:6.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.685, tt:2824.020\n",
      "Ep:73, loss:0.00001, loss_test:0.01141, lr:6.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.756, tt:2867.975\n",
      "Ep:74, loss:0.00001, loss_test:0.01146, lr:6.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.764, tt:2907.273\n",
      "Ep:75, loss:0.00001, loss_test:0.01144, lr:6.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.783, tt:2947.507\n",
      "Ep:76, loss:0.00001, loss_test:0.01151, lr:6.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.796, tt:2987.289\n",
      "Ep:77, loss:0.00001, loss_test:0.01147, lr:6.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.807, tt:3026.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00001, loss_test:0.01151, lr:6.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.809, tt:3065.909\n",
      "Ep:79, loss:0.00001, loss_test:0.01154, lr:6.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.806, tt:3104.457\n",
      "Ep:80, loss:0.00001, loss_test:0.01159, lr:6.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.811, tt:3143.695\n",
      "Ep:81, loss:0.00001, loss_test:0.01155, lr:6.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.812, tt:3182.598\n",
      "Ep:82, loss:0.00001, loss_test:0.01162, lr:5.94e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.793, tt:3219.837\n",
      "Ep:83, loss:0.00001, loss_test:0.01164, lr:5.88e-02, fs:0.89552 (r=0.909,p=0.882),  time:38.797, tt:3258.963\n",
      "Ep:84, loss:0.00001, loss_test:0.01165, lr:5.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:38.785, tt:3296.698\n",
      "Ep:85, loss:0.00001, loss_test:0.01173, lr:5.76e-02, fs:0.89552 (r=0.909,p=0.882),  time:38.758, tt:3333.161\n",
      "Ep:86, loss:0.00001, loss_test:0.01173, lr:5.71e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.761, tt:3372.209\n",
      "Ep:87, loss:0.00001, loss_test:0.01177, lr:5.65e-02, fs:0.88776 (r=0.879,p=0.897),  time:38.759, tt:3410.819\n",
      "Ep:88, loss:0.00001, loss_test:0.01181, lr:5.59e-02, fs:0.88205 (r=0.869,p=0.896),  time:38.756, tt:3449.273\n",
      "Ep:89, loss:0.00001, loss_test:0.01183, lr:5.54e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.742, tt:3486.772\n",
      "Ep:90, loss:0.00001, loss_test:0.01187, lr:5.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:38.741, tt:3525.388\n",
      "Ep:91, loss:0.00001, loss_test:0.01188, lr:5.43e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.715, tt:3561.820\n",
      "Ep:92, loss:0.00001, loss_test:0.01194, lr:5.37e-02, fs:0.83871 (r=0.788,p=0.897),  time:38.698, tt:3598.907\n",
      "Ep:93, loss:0.00001, loss_test:0.01198, lr:5.32e-02, fs:0.83243 (r=0.778,p=0.895),  time:38.692, tt:3637.018\n",
      "Ep:94, loss:0.00001, loss_test:0.01204, lr:5.27e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.674, tt:3674.033\n",
      "Ep:95, loss:0.00001, loss_test:0.01206, lr:5.21e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.695, tt:3714.729\n",
      "Ep:96, loss:0.00001, loss_test:0.01210, lr:5.16e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.684, tt:3752.385\n",
      "Ep:97, loss:0.00001, loss_test:0.01215, lr:5.11e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.676, tt:3790.288\n",
      "Ep:98, loss:0.00001, loss_test:0.01214, lr:5.06e-02, fs:0.81319 (r=0.747,p=0.892),  time:38.676, tt:3828.920\n",
      "Ep:99, loss:0.00001, loss_test:0.01219, lr:5.01e-02, fs:0.81768 (r=0.747,p=0.902),  time:38.668, tt:3866.846\n",
      "Ep:100, loss:0.00001, loss_test:0.01227, lr:4.96e-02, fs:0.80447 (r=0.727,p=0.900),  time:38.661, tt:3904.760\n",
      "Ep:101, loss:0.00001, loss_test:0.01225, lr:4.91e-02, fs:0.80447 (r=0.727,p=0.900),  time:38.673, tt:3944.667\n",
      "Ep:102, loss:0.00001, loss_test:0.01234, lr:4.86e-02, fs:0.79775 (r=0.717,p=0.899),  time:38.675, tt:3983.516\n",
      "Ep:103, loss:0.00001, loss_test:0.01235, lr:4.81e-02, fs:0.79775 (r=0.717,p=0.899),  time:38.675, tt:4022.210\n",
      "Ep:104, loss:0.00001, loss_test:0.01240, lr:4.76e-02, fs:0.79775 (r=0.717,p=0.899),  time:38.666, tt:4059.945\n",
      "Ep:105, loss:0.00001, loss_test:0.01242, lr:4.71e-02, fs:0.79775 (r=0.717,p=0.899),  time:38.671, tt:4099.103\n",
      "Ep:106, loss:0.00001, loss_test:0.01247, lr:4.67e-02, fs:0.80226 (r=0.717,p=0.910),  time:38.669, tt:4137.587\n",
      "Ep:107, loss:0.00001, loss_test:0.01250, lr:4.62e-02, fs:0.79775 (r=0.717,p=0.899),  time:38.662, tt:4175.534\n",
      "Ep:108, loss:0.00001, loss_test:0.01251, lr:4.57e-02, fs:0.79096 (r=0.707,p=0.897),  time:38.687, tt:4216.840\n",
      "Ep:109, loss:0.00000, loss_test:0.01256, lr:4.53e-02, fs:0.79096 (r=0.707,p=0.897),  time:38.687, tt:4255.522\n",
      "Ep:110, loss:0.00000, loss_test:0.01262, lr:4.48e-02, fs:0.78409 (r=0.697,p=0.896),  time:38.687, tt:4294.208\n",
      "Ep:111, loss:0.00000, loss_test:0.01261, lr:4.44e-02, fs:0.78161 (r=0.687,p=0.907),  time:38.684, tt:4332.601\n",
      "Ep:112, loss:0.00000, loss_test:0.01265, lr:4.39e-02, fs:0.78161 (r=0.687,p=0.907),  time:38.686, tt:4371.521\n",
      "Ep:113, loss:0.00000, loss_test:0.01273, lr:4.35e-02, fs:0.77457 (r=0.677,p=0.905),  time:38.686, tt:4410.258\n",
      "Ep:114, loss:0.00000, loss_test:0.01271, lr:4.31e-02, fs:0.78161 (r=0.687,p=0.907),  time:38.678, tt:4448.002\n",
      "Ep:115, loss:0.00000, loss_test:0.01272, lr:4.26e-02, fs:0.77457 (r=0.677,p=0.905),  time:38.675, tt:4486.274\n",
      "Ep:116, loss:0.00000, loss_test:0.01279, lr:4.22e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.682, tt:4525.772\n",
      "Ep:117, loss:0.00000, loss_test:0.01280, lr:4.18e-02, fs:0.77193 (r=0.667,p=0.917),  time:38.671, tt:4563.234\n",
      "Ep:118, loss:0.00000, loss_test:0.01282, lr:4.14e-02, fs:0.76744 (r=0.667,p=0.904),  time:38.661, tt:4600.613\n",
      "Ep:119, loss:0.00000, loss_test:0.01288, lr:4.10e-02, fs:0.76023 (r=0.657,p=0.903),  time:38.658, tt:4638.927\n",
      "Ep:120, loss:0.00000, loss_test:0.01291, lr:4.05e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.655, tt:4677.298\n",
      "Ep:121, loss:0.00000, loss_test:0.01294, lr:4.01e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.652, tt:4715.565\n",
      "Ep:122, loss:0.00000, loss_test:0.01297, lr:3.97e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.641, tt:4752.857\n",
      "Ep:123, loss:0.00000, loss_test:0.01299, lr:3.93e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.634, tt:4790.633\n",
      "Ep:124, loss:0.00000, loss_test:0.01305, lr:3.89e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.608, tt:4825.948\n",
      "Ep:125, loss:0.00000, loss_test:0.01303, lr:3.86e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.626, tt:4866.848\n",
      "Ep:126, loss:0.00000, loss_test:0.01303, lr:3.82e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.620, tt:4904.731\n",
      "Ep:127, loss:0.00000, loss_test:0.01311, lr:3.78e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.620, tt:4943.370\n",
      "Ep:128, loss:0.00000, loss_test:0.01311, lr:3.74e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.629, tt:4983.188\n",
      "Ep:129, loss:0.00000, loss_test:0.01311, lr:3.70e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.640, tt:5023.143\n",
      "Ep:130, loss:0.00000, loss_test:0.01319, lr:3.67e-02, fs:0.76471 (r=0.657,p=0.915),  time:38.636, tt:5061.350\n",
      "Ep:131, loss:0.00000, loss_test:0.01318, lr:3.63e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.630, tt:5099.140\n",
      "Ep:132, loss:0.00000, loss_test:0.01322, lr:3.59e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.611, tt:5135.299\n",
      "Ep:133, loss:0.00000, loss_test:0.01324, lr:3.56e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.612, tt:5173.943\n",
      "Ep:134, loss:0.00000, loss_test:0.01327, lr:3.52e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.610, tt:5212.386\n",
      "Ep:135, loss:0.00000, loss_test:0.01331, lr:3.49e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.608, tt:5250.630\n",
      "Ep:136, loss:0.00000, loss_test:0.01332, lr:3.45e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.610, tt:5289.621\n",
      "Ep:137, loss:0.00000, loss_test:0.01338, lr:3.42e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.611, tt:5328.377\n",
      "Ep:138, loss:0.00000, loss_test:0.01336, lr:3.38e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.610, tt:5366.797\n",
      "Ep:139, loss:0.00000, loss_test:0.01337, lr:3.35e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.618, tt:5406.486\n",
      "Ep:140, loss:0.00000, loss_test:0.01341, lr:3.32e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.625, tt:5446.185\n",
      "Ep:141, loss:0.00000, loss_test:0.01343, lr:3.28e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.619, tt:5483.877\n",
      "Ep:142, loss:0.00000, loss_test:0.01343, lr:3.25e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.616, tt:5522.030\n",
      "Ep:143, loss:0.00000, loss_test:0.01344, lr:3.22e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.611, tt:5560.016\n",
      "Ep:144, loss:0.00000, loss_test:0.01348, lr:3.19e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.608, tt:5598.111\n",
      "Ep:145, loss:0.00000, loss_test:0.01351, lr:3.15e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.611, tt:5637.166\n",
      "Ep:146, loss:0.00000, loss_test:0.01351, lr:3.12e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.615, tt:5676.416\n",
      "Ep:147, loss:0.00000, loss_test:0.01357, lr:3.09e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.620, tt:5715.806\n",
      "Ep:148, loss:0.00000, loss_test:0.01355, lr:3.06e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.622, tt:5754.640\n",
      "Ep:149, loss:0.00000, loss_test:0.01359, lr:3.03e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.620, tt:5793.018\n",
      "Ep:150, loss:0.00000, loss_test:0.01364, lr:3.00e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.622, tt:5831.903\n",
      "Ep:151, loss:0.00000, loss_test:0.01363, lr:2.97e-02, fs:0.75740 (r=0.646,p=0.914),  time:38.620, tt:5870.273\n",
      "Ep:152, loss:0.00000, loss_test:0.01367, lr:2.94e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.620, tt:5908.848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00000, loss_test:0.01370, lr:2.91e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.612, tt:5946.219\n",
      "Ep:154, loss:0.00000, loss_test:0.01369, lr:2.88e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.623, tt:5986.585\n",
      "Ep:155, loss:0.00000, loss_test:0.01374, lr:2.85e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.618, tt:6024.388\n",
      "Ep:156, loss:0.00000, loss_test:0.01376, lr:2.82e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.617, tt:6062.903\n",
      "Ep:157, loss:0.00000, loss_test:0.01377, lr:2.80e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.618, tt:6101.613\n",
      "Ep:158, loss:0.00000, loss_test:0.01380, lr:2.77e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.614, tt:6139.585\n",
      "Ep:159, loss:0.00000, loss_test:0.01379, lr:2.74e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.620, tt:6179.141\n",
      "Ep:160, loss:0.00000, loss_test:0.01384, lr:2.71e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.605, tt:6215.475\n",
      "Ep:161, loss:0.00000, loss_test:0.01385, lr:2.69e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.604, tt:6253.898\n",
      "Ep:162, loss:0.00000, loss_test:0.01386, lr:2.66e-02, fs:0.75000 (r=0.636,p=0.913),  time:38.595, tt:6291.048\n",
      "Ep:163, loss:0.00000, loss_test:0.01391, lr:2.63e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.587, tt:6328.241\n",
      "Ep:164, loss:0.00000, loss_test:0.01392, lr:2.61e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.582, tt:6365.983\n",
      "Ep:165, loss:0.00000, loss_test:0.01392, lr:2.58e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.571, tt:6402.786\n",
      "Ep:166, loss:0.00000, loss_test:0.01398, lr:2.55e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.574, tt:6441.915\n",
      "Ep:167, loss:0.00000, loss_test:0.01397, lr:2.53e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.569, tt:6479.626\n",
      "Ep:168, loss:0.00000, loss_test:0.01396, lr:2.50e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.579, tt:6519.905\n",
      "Ep:169, loss:0.00000, loss_test:0.01402, lr:2.48e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.572, tt:6557.269\n",
      "Ep:170, loss:0.00000, loss_test:0.01405, lr:2.45e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.582, tt:6597.532\n",
      "Ep:171, loss:0.00000, loss_test:0.01400, lr:2.43e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.581, tt:6635.856\n",
      "Ep:172, loss:0.00000, loss_test:0.01403, lr:2.40e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.576, tt:6673.588\n",
      "Ep:173, loss:0.00000, loss_test:0.01411, lr:2.38e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.573, tt:6711.704\n",
      "Ep:174, loss:0.00000, loss_test:0.01409, lr:2.36e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.571, tt:6750.006\n",
      "Ep:175, loss:0.00000, loss_test:0.01408, lr:2.33e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.570, tt:6788.348\n",
      "Ep:176, loss:0.00000, loss_test:0.01412, lr:2.31e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.569, tt:6826.707\n",
      "Ep:177, loss:0.00000, loss_test:0.01415, lr:2.29e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.560, tt:6863.677\n",
      "Ep:178, loss:0.00000, loss_test:0.01415, lr:2.26e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.554, tt:6901.105\n",
      "Ep:179, loss:0.00000, loss_test:0.01419, lr:2.24e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.555, tt:6939.964\n",
      "Ep:180, loss:0.00000, loss_test:0.01420, lr:2.22e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.533, tt:6974.507\n",
      "Ep:181, loss:0.00000, loss_test:0.01421, lr:2.20e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.542, tt:7014.683\n",
      "Ep:182, loss:0.00000, loss_test:0.01421, lr:2.17e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.540, tt:7052.793\n",
      "Ep:183, loss:0.00000, loss_test:0.01424, lr:2.15e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.535, tt:7090.446\n",
      "Ep:184, loss:0.00000, loss_test:0.01425, lr:2.13e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.533, tt:7128.517\n",
      "Ep:185, loss:0.00000, loss_test:0.01426, lr:2.11e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.521, tt:7164.997\n",
      "Ep:186, loss:0.00000, loss_test:0.01429, lr:2.09e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.514, tt:7202.108\n",
      "Ep:187, loss:0.00000, loss_test:0.01430, lr:2.07e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.514, tt:7240.670\n",
      "Ep:188, loss:0.00000, loss_test:0.01427, lr:2.05e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.506, tt:7277.696\n",
      "Ep:189, loss:0.00000, loss_test:0.01432, lr:2.03e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.498, tt:7314.710\n",
      "Ep:190, loss:0.00000, loss_test:0.01433, lr:2.01e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.487, tt:7351.073\n",
      "Ep:191, loss:0.00000, loss_test:0.01433, lr:1.99e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.484, tt:7388.919\n",
      "Ep:192, loss:0.00000, loss_test:0.01437, lr:1.97e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.480, tt:7426.650\n",
      "Ep:193, loss:0.00000, loss_test:0.01438, lr:1.95e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.474, tt:7463.881\n",
      "Ep:194, loss:0.00000, loss_test:0.01439, lr:1.93e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.452, tt:7498.074\n",
      "Ep:195, loss:0.00000, loss_test:0.01437, lr:1.91e-02, fs:0.74251 (r=0.626,p=0.912),  time:38.412, tt:7528.807\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02271, lr:6.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:31.659, tt:31.659\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02532, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:33.221, tt:66.441\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02705, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.779, tt:98.337\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02714, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.553, tt:134.211\n",
      "Ep:4, loss:0.00005, loss_test:0.02609, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:33.700, tt:168.502\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02452, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:33.862, tt:203.169\n",
      "Ep:6, loss:0.00005, loss_test:0.02301, lr:6.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:33.923, tt:237.464\n",
      "Ep:7, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:34.054, tt:272.435\n",
      "Ep:8, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:34.151, tt:307.357\n",
      "Ep:9, loss:0.00004, loss_test:0.01972, lr:6.00e-02, fs:0.67176 (r=0.889,p=0.540),  time:34.161, tt:341.607\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01888, lr:6.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:34.229, tt:376.516\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01819, lr:6.00e-02, fs:0.70330 (r=0.970,p=0.552),  time:34.252, tt:411.023\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01753, lr:6.00e-02, fs:0.71111 (r=0.970,p=0.561),  time:34.322, tt:446.192\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01686, lr:6.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:34.336, tt:480.711\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.73643 (r=0.960,p=0.597),  time:34.402, tt:516.030\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:34.463, tt:551.410\n",
      "Ep:16, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:34.529, tt:587.000\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.74419 (r=0.970,p=0.604),  time:34.605, tt:622.885\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01573, lr:6.00e-02, fs:0.75000 (r=0.970,p=0.611),  time:34.612, tt:657.622\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01555, lr:6.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:34.666, tt:693.327\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01535, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:34.729, tt:729.303\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01506, lr:6.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:34.706, tt:763.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00003, loss_test:0.01485, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:34.736, tt:798.927\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01472, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:34.804, tt:835.290\n",
      "Ep:24, loss:0.00003, loss_test:0.01461, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:34.840, tt:871.009\n",
      "Ep:25, loss:0.00003, loss_test:0.01441, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:34.875, tt:906.756\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01422, lr:6.00e-02, fs:0.78333 (r=0.949,p=0.667),  time:34.921, tt:942.870\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01412, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:34.947, tt:978.507\n",
      "Ep:28, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.980, tt:1014.419\n",
      "Ep:29, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:35.004, tt:1050.109\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:35.041, tt:1086.284\n",
      "Ep:31, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:35.017, tt:1120.556\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:35.019, tt:1155.624\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01343, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:34.976, tt:1189.189\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:34.990, tt:1224.668\n",
      "Ep:35, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:34.999, tt:1259.967\n",
      "Ep:36, loss:0.00002, loss_test:0.01298, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:34.973, tt:1293.997\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.954, tt:1328.266\n",
      "Ep:38, loss:0.00002, loss_test:0.01282, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:34.964, tt:1363.585\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:34.949, tt:1397.977\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:34.899, tt:1430.873\n",
      "Ep:41, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:34.854, tt:1463.852\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.851, tt:1498.578\n",
      "Ep:43, loss:0.00002, loss_test:0.01223, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:34.870, tt:1534.287\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:34.899, tt:1570.465\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01213, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:34.908, tt:1605.753\n",
      "Ep:46, loss:0.00001, loss_test:0.01200, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:34.926, tt:1641.500\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01197, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:34.948, tt:1677.510\n",
      "Ep:48, loss:0.00001, loss_test:0.01200, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:34.938, tt:1711.965\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01189, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:34.928, tt:1746.425\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:34.948, tt:1782.365\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:34.933, tt:1816.532\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:34.943, tt:1851.968\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:34.958, tt:1887.747\n",
      "Ep:54, loss:0.00001, loss_test:0.01184, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.939, tt:1921.669\n",
      "Ep:55, loss:0.00001, loss_test:0.01189, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:34.937, tt:1956.496\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:34.939, tt:1991.536\n",
      "Ep:57, loss:0.00001, loss_test:0.01188, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:34.932, tt:2026.055\n",
      "Ep:58, loss:0.00001, loss_test:0.01195, lr:6.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:34.919, tt:2060.201\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01200, lr:6.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:34.898, tt:2093.910\n",
      "Ep:60, loss:0.00001, loss_test:0.01205, lr:6.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:34.893, tt:2128.492\n",
      "Ep:61, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:34.872, tt:2162.087\n",
      "Ep:62, loss:0.00001, loss_test:0.01218, lr:6.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:34.878, tt:2197.293\n",
      "Ep:63, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:34.871, tt:2231.732\n",
      "Ep:64, loss:0.00001, loss_test:0.01231, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.848, tt:2265.111\n",
      "Ep:65, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.837, tt:2299.223\n",
      "Ep:66, loss:0.00001, loss_test:0.01235, lr:6.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.819, tt:2332.842\n",
      "Ep:67, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.813, tt:2367.285\n",
      "Ep:68, loss:0.00001, loss_test:0.01249, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.783, tt:2400.010\n",
      "Ep:69, loss:0.00001, loss_test:0.01252, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.784, tt:2434.860\n",
      "Ep:70, loss:0.00001, loss_test:0.01264, lr:5.94e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.757, tt:2467.748\n",
      "Ep:71, loss:0.00001, loss_test:0.01267, lr:5.88e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.744, tt:2501.573\n",
      "Ep:72, loss:0.00001, loss_test:0.01277, lr:5.82e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.748, tt:2536.635\n",
      "Ep:73, loss:0.00001, loss_test:0.01277, lr:5.76e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.743, tt:2570.969\n",
      "Ep:74, loss:0.00001, loss_test:0.01286, lr:5.71e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.766, tt:2607.486\n",
      "Ep:75, loss:0.00001, loss_test:0.01283, lr:5.65e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.764, tt:2642.061\n",
      "Ep:76, loss:0.00001, loss_test:0.01304, lr:5.59e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.761, tt:2676.632\n",
      "Ep:77, loss:0.00001, loss_test:0.01305, lr:5.54e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.770, tt:2712.042\n",
      "Ep:78, loss:0.00001, loss_test:0.01312, lr:5.48e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.777, tt:2747.375\n",
      "Ep:79, loss:0.00001, loss_test:0.01321, lr:5.43e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.809, tt:2784.734\n",
      "Ep:80, loss:0.00001, loss_test:0.01321, lr:5.37e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.832, tt:2821.382\n",
      "Ep:81, loss:0.00001, loss_test:0.01333, lr:5.32e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.841, tt:2856.969\n",
      "Ep:82, loss:0.00001, loss_test:0.01335, lr:5.27e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.864, tt:2893.703\n",
      "Ep:83, loss:0.00001, loss_test:0.01352, lr:5.21e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.872, tt:2929.257\n",
      "Ep:84, loss:0.00001, loss_test:0.01350, lr:5.16e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.879, tt:2964.696\n",
      "Ep:85, loss:0.00001, loss_test:0.01363, lr:5.11e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.892, tt:3000.731\n",
      "Ep:86, loss:0.00001, loss_test:0.01372, lr:5.06e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.914, tt:3037.562\n",
      "Ep:87, loss:0.00001, loss_test:0.01367, lr:5.01e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.928, tt:3073.700\n",
      "Ep:88, loss:0.00001, loss_test:0.01387, lr:4.96e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.929, tt:3108.671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00001, loss_test:0.01375, lr:4.91e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.935, tt:3144.133\n",
      "Ep:90, loss:0.00001, loss_test:0.01397, lr:4.86e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.935, tt:3179.071\n",
      "Ep:91, loss:0.00001, loss_test:0.01397, lr:4.81e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.946, tt:3215.030\n",
      "Ep:92, loss:0.00000, loss_test:0.01396, lr:4.76e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.957, tt:3250.997\n",
      "Ep:93, loss:0.00000, loss_test:0.01406, lr:4.71e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.961, tt:3286.297\n",
      "Ep:94, loss:0.00000, loss_test:0.01403, lr:4.67e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.977, tt:3322.824\n",
      "Ep:95, loss:0.00000, loss_test:0.01420, lr:4.62e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.980, tt:3358.122\n",
      "Ep:96, loss:0.00000, loss_test:0.01417, lr:4.57e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.995, tt:3394.476\n",
      "Ep:97, loss:0.00000, loss_test:0.01426, lr:4.53e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.005, tt:3430.532\n",
      "Ep:98, loss:0.00000, loss_test:0.01433, lr:4.48e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.021, tt:3467.064\n",
      "Ep:99, loss:0.00000, loss_test:0.01427, lr:4.44e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.029, tt:3502.923\n",
      "Ep:100, loss:0.00000, loss_test:0.01445, lr:4.39e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.030, tt:3537.994\n",
      "Ep:101, loss:0.00000, loss_test:0.01443, lr:4.35e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.036, tt:3573.646\n",
      "Ep:102, loss:0.00000, loss_test:0.01458, lr:4.31e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.053, tt:3610.445\n",
      "Ep:103, loss:0.00000, loss_test:0.01455, lr:4.26e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.065, tt:3646.752\n",
      "Ep:104, loss:0.00000, loss_test:0.01452, lr:4.22e-02, fs:0.79545 (r=0.707,p=0.909),  time:35.071, tt:3682.410\n",
      "Ep:105, loss:0.00000, loss_test:0.01468, lr:4.18e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.077, tt:3718.114\n",
      "Ep:106, loss:0.00000, loss_test:0.01468, lr:4.14e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.076, tt:3753.141\n",
      "Ep:107, loss:0.00000, loss_test:0.01473, lr:4.10e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.091, tt:3789.880\n",
      "Ep:108, loss:0.00000, loss_test:0.01485, lr:4.05e-02, fs:0.76023 (r=0.657,p=0.903),  time:35.104, tt:3826.284\n",
      "Ep:109, loss:0.00000, loss_test:0.01483, lr:4.01e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.116, tt:3862.723\n",
      "Ep:110, loss:0.00000, loss_test:0.01486, lr:3.97e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.130, tt:3899.472\n",
      "Ep:111, loss:0.00000, loss_test:0.01486, lr:3.93e-02, fs:0.77457 (r=0.677,p=0.905),  time:35.141, tt:3935.810\n",
      "Ep:112, loss:0.00000, loss_test:0.01500, lr:3.89e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.139, tt:3970.725\n",
      "Ep:113, loss:0.00000, loss_test:0.01499, lr:3.86e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.137, tt:4005.637\n",
      "Ep:114, loss:0.00000, loss_test:0.01498, lr:3.82e-02, fs:0.78363 (r=0.677,p=0.931),  time:35.160, tt:4043.393\n",
      "Ep:115, loss:0.00000, loss_test:0.01515, lr:3.78e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.168, tt:4079.512\n",
      "Ep:116, loss:0.00000, loss_test:0.01505, lr:3.74e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.165, tt:4114.357\n",
      "Ep:117, loss:0.00000, loss_test:0.01516, lr:3.70e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.170, tt:4150.017\n",
      "Ep:118, loss:0.00000, loss_test:0.01518, lr:3.67e-02, fs:0.76923 (r=0.657,p=0.929),  time:35.178, tt:4186.129\n",
      "Ep:119, loss:0.00000, loss_test:0.01518, lr:3.63e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.180, tt:4221.596\n",
      "Ep:120, loss:0.00000, loss_test:0.01530, lr:3.59e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.179, tt:4256.617\n",
      "Ep:121, loss:0.00000, loss_test:0.01525, lr:3.56e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.184, tt:4292.502\n",
      "Ep:122, loss:0.00000, loss_test:0.01538, lr:3.52e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.179, tt:4327.044\n",
      "Ep:123, loss:0.00000, loss_test:0.01544, lr:3.49e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.178, tt:4362.123\n",
      "Ep:124, loss:0.00000, loss_test:0.01542, lr:3.45e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.172, tt:4396.494\n",
      "Ep:125, loss:0.00000, loss_test:0.01549, lr:3.42e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.173, tt:4431.806\n",
      "Ep:126, loss:0.00000, loss_test:0.01554, lr:3.38e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.186, tt:4468.608\n",
      "Ep:127, loss:0.00000, loss_test:0.01550, lr:3.35e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.171, tt:4501.916\n",
      "Ep:128, loss:0.00000, loss_test:0.01557, lr:3.32e-02, fs:0.75449 (r=0.636,p=0.926),  time:35.164, tt:4536.096\n",
      "Ep:129, loss:0.00000, loss_test:0.01563, lr:3.28e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.161, tt:4570.972\n",
      "Ep:130, loss:0.00000, loss_test:0.01565, lr:3.25e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.157, tt:4605.504\n",
      "Ep:131, loss:0.00000, loss_test:0.01567, lr:3.22e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.149, tt:4639.695\n",
      "Ep:132, loss:0.00000, loss_test:0.01576, lr:3.19e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.161, tt:4676.469\n",
      "Ep:133, loss:0.00000, loss_test:0.01577, lr:3.15e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.154, tt:4710.631\n",
      "Ep:134, loss:0.00000, loss_test:0.01580, lr:3.12e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.149, tt:4745.141\n",
      "Ep:135, loss:0.00000, loss_test:0.01584, lr:3.09e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.148, tt:4780.136\n",
      "Ep:136, loss:0.00000, loss_test:0.01587, lr:3.06e-02, fs:0.71605 (r=0.586,p=0.921),  time:35.144, tt:4814.795\n",
      "Ep:137, loss:0.00000, loss_test:0.01592, lr:3.03e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.142, tt:4849.625\n",
      "Ep:138, loss:0.00000, loss_test:0.01595, lr:3.00e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.139, tt:4884.380\n",
      "Ep:139, loss:0.00000, loss_test:0.01601, lr:2.97e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.133, tt:4918.596\n",
      "Ep:140, loss:0.00000, loss_test:0.01602, lr:2.94e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.136, tt:4954.119\n",
      "Ep:141, loss:0.00000, loss_test:0.01609, lr:2.91e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.138, tt:4989.605\n",
      "Ep:142, loss:0.00000, loss_test:0.01611, lr:2.88e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.125, tt:5022.871\n",
      "Ep:143, loss:0.00000, loss_test:0.01613, lr:2.85e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.120, tt:5057.234\n",
      "Ep:144, loss:0.00000, loss_test:0.01619, lr:2.82e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.117, tt:5092.026\n",
      "Ep:145, loss:0.00000, loss_test:0.01621, lr:2.80e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.115, tt:5126.749\n",
      "Ep:146, loss:0.00000, loss_test:0.01625, lr:2.77e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.118, tt:5162.400\n",
      "Ep:147, loss:0.00000, loss_test:0.01631, lr:2.74e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.113, tt:5196.708\n",
      "Ep:148, loss:0.00000, loss_test:0.01628, lr:2.71e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.109, tt:5231.300\n",
      "Ep:149, loss:0.00000, loss_test:0.01631, lr:2.69e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.108, tt:5266.259\n",
      "Ep:150, loss:0.00000, loss_test:0.01645, lr:2.66e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.106, tt:5300.966\n",
      "Ep:151, loss:0.00000, loss_test:0.01638, lr:2.63e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.111, tt:5336.825\n",
      "Ep:152, loss:0.00000, loss_test:0.01646, lr:2.61e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.107, tt:5371.379\n",
      "Ep:153, loss:0.00000, loss_test:0.01647, lr:2.58e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.114, tt:5407.617\n",
      "Ep:154, loss:0.00000, loss_test:0.01650, lr:2.55e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.111, tt:5442.267\n",
      "Ep:155, loss:0.00000, loss_test:0.01653, lr:2.53e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.109, tt:5477.080\n",
      "Ep:156, loss:0.00000, loss_test:0.01658, lr:2.50e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.108, tt:5511.994\n",
      "Ep:157, loss:0.00000, loss_test:0.01660, lr:2.48e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.110, tt:5547.413\n",
      "Ep:158, loss:0.00000, loss_test:0.01662, lr:2.45e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.114, tt:5583.201\n",
      "Ep:159, loss:0.00000, loss_test:0.01667, lr:2.43e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.118, tt:5618.815\n",
      "Ep:160, loss:0.00000, loss_test:0.01669, lr:2.40e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.118, tt:5653.934\n",
      "Ep:161, loss:0.00000, loss_test:0.01674, lr:2.38e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.113, tt:5688.298\n",
      "Ep:162, loss:0.00000, loss_test:0.01678, lr:2.36e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.114, tt:5723.562\n",
      "Ep:163, loss:0.00000, loss_test:0.01677, lr:2.33e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.122, tt:5760.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:164, loss:0.00000, loss_test:0.01681, lr:2.31e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.124, tt:5795.516\n",
      "Ep:165, loss:0.00000, loss_test:0.01687, lr:2.29e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.115, tt:5829.121\n",
      "Ep:166, loss:0.00000, loss_test:0.01688, lr:2.26e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.128, tt:5866.313\n",
      "Ep:167, loss:0.00000, loss_test:0.01690, lr:2.24e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.129, tt:5901.655\n",
      "Ep:168, loss:0.00000, loss_test:0.01693, lr:2.22e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.132, tt:5937.247\n",
      "Ep:169, loss:0.00000, loss_test:0.01695, lr:2.20e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.131, tt:5972.335\n",
      "Ep:170, loss:0.00000, loss_test:0.01699, lr:2.17e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.133, tt:6007.665\n",
      "Ep:171, loss:0.00000, loss_test:0.01703, lr:2.15e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.144, tt:6044.840\n",
      "Ep:172, loss:0.00000, loss_test:0.01705, lr:2.13e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.151, tt:6081.178\n",
      "Ep:173, loss:0.00000, loss_test:0.01704, lr:2.11e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.152, tt:6116.429\n",
      "Ep:174, loss:0.00000, loss_test:0.01710, lr:2.09e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.163, tt:6153.464\n",
      "Ep:175, loss:0.00000, loss_test:0.01713, lr:2.07e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.170, tt:6189.837\n",
      "Ep:176, loss:0.00000, loss_test:0.01717, lr:2.05e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.170, tt:6225.024\n",
      "Ep:177, loss:0.00000, loss_test:0.01716, lr:2.03e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.177, tt:6261.472\n",
      "Ep:178, loss:0.00000, loss_test:0.01723, lr:2.01e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.178, tt:6296.820\n",
      "Ep:179, loss:0.00000, loss_test:0.01723, lr:1.99e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.177, tt:6331.892\n",
      "Ep:180, loss:0.00000, loss_test:0.01722, lr:1.97e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.170, tt:6365.816\n",
      "Ep:181, loss:0.00000, loss_test:0.01729, lr:1.95e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.176, tt:6402.008\n",
      "Ep:182, loss:0.00000, loss_test:0.01731, lr:1.93e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.177, tt:6437.462\n",
      "Ep:183, loss:0.00000, loss_test:0.01730, lr:1.91e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.178, tt:6472.801\n",
      "Ep:184, loss:0.00000, loss_test:0.01734, lr:1.89e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.173, tt:6507.043\n",
      "Ep:185, loss:0.00000, loss_test:0.01738, lr:1.87e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.185, tt:6544.362\n",
      "Ep:186, loss:0.00000, loss_test:0.01740, lr:1.85e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.198, tt:6582.088\n",
      "Ep:187, loss:0.00000, loss_test:0.01742, lr:1.83e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.198, tt:6617.266\n",
      "Ep:188, loss:0.00000, loss_test:0.01749, lr:1.81e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.197, tt:6652.249\n",
      "Ep:189, loss:0.00000, loss_test:0.01752, lr:1.80e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.192, tt:6686.392\n",
      "Ep:190, loss:0.00000, loss_test:0.01749, lr:1.78e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.196, tt:6722.473\n",
      "Ep:191, loss:0.00000, loss_test:0.01751, lr:1.76e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.200, tt:6758.351\n",
      "Ep:192, loss:0.00000, loss_test:0.01758, lr:1.74e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.208, tt:6795.113\n",
      "Ep:193, loss:0.00000, loss_test:0.01757, lr:1.73e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.141, tt:6817.374\n",
      "Ep:194, loss:0.00000, loss_test:0.01759, lr:1.71e-02, fs:0.71250 (r=0.576,p=0.934),  time:35.036, tt:6832.074\n",
      "Ep:195, loss:0.00000, loss_test:0.01763, lr:1.69e-02, fs:0.71250 (r=0.576,p=0.934),  time:34.925, tt:6845.356\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"4-4\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13050, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:39.485, tt:39.485\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00025, loss_test:0.11720, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:41.110, tt:82.221\n",
      "Ep:2, loss:0.00025, loss_test:0.11197, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:40.780, tt:122.341\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00024, loss_test:0.11020, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:41.090, tt:164.362\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.10549, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:41.283, tt:206.416\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00022, loss_test:0.10130, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:41.289, tt:247.734\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00021, loss_test:0.10001, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:41.512, tt:290.587\n",
      "Ep:7, loss:0.00021, loss_test:0.09749, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:41.655, tt:333.241\n",
      "Ep:8, loss:0.00020, loss_test:0.09591, lr:1.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:41.799, tt:376.193\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.09519, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:41.615, tt:416.145\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.09371, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:41.784, tt:459.626\n",
      "Ep:11, loss:0.00018, loss_test:0.09415, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:41.866, tt:502.387\n",
      "Ep:12, loss:0.00018, loss_test:0.09105, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:41.797, tt:543.363\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09133, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:41.739, tt:584.352\n",
      "Ep:14, loss:0.00017, loss_test:0.09134, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:41.687, tt:625.305\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09043, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:41.582, tt:665.320\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08773, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:41.609, tt:707.348\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08622, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:41.671, tt:750.077\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09295, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:41.744, tt:793.133\n",
      "Ep:19, loss:0.00015, loss_test:0.08298, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.720, tt:834.409\n",
      "Ep:20, loss:0.00015, loss_test:0.08189, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:41.743, tt:876.613\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09976, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:41.819, tt:920.007\n",
      "Ep:22, loss:0.00015, loss_test:0.08398, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:41.813, tt:961.698\n",
      "Ep:23, loss:0.00014, loss_test:0.08978, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:41.810, tt:1003.437\n",
      "Ep:24, loss:0.00014, loss_test:0.09219, lr:1.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:41.823, tt:1045.572\n",
      "Ep:25, loss:0.00013, loss_test:0.08579, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:41.840, tt:1087.828\n",
      "Ep:26, loss:0.00013, loss_test:0.08235, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:41.754, tt:1127.353\n",
      "Ep:27, loss:0.00013, loss_test:0.08583, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:41.708, tt:1167.835\n",
      "Ep:28, loss:0.00012, loss_test:0.09565, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:41.642, tt:1207.624\n",
      "Ep:29, loss:0.00013, loss_test:0.09391, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:41.563, tt:1246.895\n",
      "Ep:30, loss:0.00011, loss_test:0.08627, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:41.600, tt:1289.596\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08321, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:41.566, tt:1330.118\n",
      "Ep:32, loss:0.00011, loss_test:0.10249, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:41.641, tt:1374.168\n",
      "Ep:33, loss:0.00012, loss_test:0.08774, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:41.577, tt:1413.630\n",
      "Ep:34, loss:0.00011, loss_test:0.09219, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:41.649, tt:1457.710\n",
      "Ep:35, loss:0.00011, loss_test:0.08958, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:41.638, tt:1498.972\n",
      "Ep:36, loss:0.00011, loss_test:0.09216, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:41.646, tt:1540.893\n",
      "Ep:37, loss:0.00011, loss_test:0.09073, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.670, tt:1583.444\n",
      "Ep:38, loss:0.00010, loss_test:0.08957, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.636, tt:1623.797\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.08504, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:41.605, tt:1664.188\n",
      "Ep:40, loss:0.00010, loss_test:0.09695, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:41.583, tt:1704.909\n",
      "Ep:41, loss:0.00010, loss_test:0.08073, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:41.586, tt:1746.631\n",
      "Ep:42, loss:0.00008, loss_test:0.08502, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:41.580, tt:1787.954\n",
      "Ep:43, loss:0.00008, loss_test:0.07987, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.587, tt:1829.832\n",
      "Ep:44, loss:0.00008, loss_test:0.07710, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.605, tt:1872.219\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.08182, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:41.572, tt:1912.334\n",
      "Ep:46, loss:0.00007, loss_test:0.08289, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.573, tt:1953.916\n",
      "Ep:47, loss:0.00008, loss_test:0.08051, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:41.572, tt:1995.479\n",
      "Ep:48, loss:0.00007, loss_test:0.07916, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:41.598, tt:2038.279\n",
      "Ep:49, loss:0.00007, loss_test:0.07890, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:41.570, tt:2078.511\n",
      "Ep:50, loss:0.00006, loss_test:0.07843, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:41.571, tt:2120.124\n",
      "Ep:51, loss:0.00006, loss_test:0.07853, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:41.554, tt:2160.790\n",
      "Ep:52, loss:0.00005, loss_test:0.07596, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:41.569, tt:2203.155\n",
      "Ep:53, loss:0.00006, loss_test:0.06933, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:41.551, tt:2243.735\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.07697, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:41.565, tt:2286.081\n",
      "Ep:55, loss:0.00006, loss_test:0.07695, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:41.561, tt:2327.436\n",
      "Ep:56, loss:0.00006, loss_test:0.07925, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:41.622, tt:2372.440\n",
      "Ep:57, loss:0.00006, loss_test:0.08832, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:41.632, tt:2414.644\n",
      "Ep:58, loss:0.00007, loss_test:0.08059, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.626, tt:2455.941\n",
      "Ep:59, loss:0.00006, loss_test:0.08918, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:41.629, tt:2497.715\n",
      "Ep:60, loss:0.00005, loss_test:0.07479, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:41.613, tt:2538.393\n",
      "Ep:61, loss:0.00005, loss_test:0.07677, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:41.636, tt:2581.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00006, loss_test:0.07179, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:41.646, tt:2623.713\n",
      "Ep:63, loss:0.00005, loss_test:0.08412, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:41.669, tt:2666.831\n",
      "Ep:64, loss:0.00005, loss_test:0.07132, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.690, tt:2709.837\n",
      "Ep:65, loss:0.00005, loss_test:0.07516, lr:9.90e-03, fs:0.78889 (r=0.717,p=0.877),  time:41.681, tt:2750.936\n",
      "Ep:66, loss:0.00005, loss_test:0.07594, lr:9.80e-03, fs:0.75532 (r=0.717,p=0.798),  time:41.714, tt:2794.851\n",
      "Ep:67, loss:0.00004, loss_test:0.07194, lr:9.70e-03, fs:0.78495 (r=0.737,p=0.839),  time:41.739, tt:2838.264\n",
      "Ep:68, loss:0.00004, loss_test:0.07640, lr:9.61e-03, fs:0.76596 (r=0.727,p=0.809),  time:41.764, tt:2881.744\n",
      "Ep:69, loss:0.00004, loss_test:0.06835, lr:9.51e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.773, tt:2924.135\n",
      "Ep:70, loss:0.00003, loss_test:0.07479, lr:9.41e-03, fs:0.81283 (r=0.768,p=0.864),  time:41.785, tt:2966.726\n",
      "Ep:71, loss:0.00003, loss_test:0.07866, lr:9.32e-03, fs:0.74872 (r=0.737,p=0.760),  time:41.793, tt:3009.069\n",
      "Ep:72, loss:0.00003, loss_test:0.07662, lr:9.23e-03, fs:0.80208 (r=0.778,p=0.828),  time:41.813, tt:3052.348\n",
      "Ep:73, loss:0.00003, loss_test:0.07109, lr:9.14e-03, fs:0.80208 (r=0.778,p=0.828),  time:41.800, tt:3093.187\n",
      "Ep:74, loss:0.00003, loss_test:0.06722, lr:9.04e-03, fs:0.83422 (r=0.788,p=0.886),  time:41.837, tt:3137.778\n",
      "Ep:75, loss:0.00003, loss_test:0.07141, lr:8.95e-03, fs:0.82796 (r=0.778,p=0.885),  time:41.854, tt:3180.927\n",
      "Ep:76, loss:0.00003, loss_test:0.07756, lr:8.86e-03, fs:0.81915 (r=0.778,p=0.865),  time:41.871, tt:3224.051\n",
      "Ep:77, loss:0.00003, loss_test:0.06966, lr:8.78e-03, fs:0.82979 (r=0.788,p=0.876),  time:41.869, tt:3265.763\n",
      "Ep:78, loss:0.00003, loss_test:0.07176, lr:8.69e-03, fs:0.82540 (r=0.788,p=0.867),  time:41.905, tt:3310.474\n",
      "Ep:79, loss:0.00003, loss_test:0.06864, lr:8.60e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.912, tt:3352.980\n",
      "Ep:80, loss:0.00003, loss_test:0.07414, lr:8.51e-03, fs:0.75556 (r=0.687,p=0.840),  time:41.917, tt:3395.276\n",
      "Ep:81, loss:0.00003, loss_test:0.06817, lr:8.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:41.946, tt:3439.552\n",
      "Ep:82, loss:0.00003, loss_test:0.06442, lr:8.35e-03, fs:0.84615 (r=0.778,p=0.928),  time:41.966, tt:3483.157\n",
      "Ep:83, loss:0.00002, loss_test:0.07372, lr:8.26e-03, fs:0.83243 (r=0.778,p=0.895),  time:41.963, tt:3524.890\n",
      "Ep:84, loss:0.00002, loss_test:0.06781, lr:8.18e-03, fs:0.82162 (r=0.768,p=0.884),  time:41.950, tt:3565.735\n",
      "Ep:85, loss:0.00002, loss_test:0.06960, lr:8.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.950, tt:3607.668\n",
      "Ep:86, loss:0.00002, loss_test:0.06965, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.987, tt:3652.837\n",
      "Ep:87, loss:0.00002, loss_test:0.06742, lr:7.94e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.993, tt:3695.347\n",
      "Ep:88, loss:0.00002, loss_test:0.07123, lr:7.86e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.993, tt:3737.409\n",
      "Ep:89, loss:0.00002, loss_test:0.06692, lr:7.78e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.000, tt:3779.980\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.06825, lr:7.78e-03, fs:0.81967 (r=0.758,p=0.893),  time:42.016, tt:3823.429\n",
      "Ep:91, loss:0.00002, loss_test:0.07342, lr:7.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.043, tt:3867.915\n",
      "Ep:92, loss:0.00002, loss_test:0.06951, lr:7.78e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.062, tt:3911.766\n",
      "Ep:93, loss:0.00002, loss_test:0.07050, lr:7.78e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.080, tt:3955.539\n",
      "Ep:94, loss:0.00001, loss_test:0.07276, lr:7.78e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.076, tt:3997.262\n",
      "Ep:95, loss:0.00001, loss_test:0.07161, lr:7.78e-03, fs:0.83243 (r=0.778,p=0.895),  time:42.059, tt:4037.632\n",
      "Ep:96, loss:0.00001, loss_test:0.07224, lr:7.78e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.052, tt:4079.054\n",
      "Ep:97, loss:0.00001, loss_test:0.07088, lr:7.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.057, tt:4121.599\n",
      "Ep:98, loss:0.00001, loss_test:0.07209, lr:7.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.045, tt:4162.445\n",
      "Ep:99, loss:0.00001, loss_test:0.07351, lr:7.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.056, tt:4205.649\n",
      "Ep:100, loss:0.00001, loss_test:0.07440, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.060, tt:4248.091\n",
      "Ep:101, loss:0.00001, loss_test:0.07361, lr:7.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.044, tt:4288.484\n",
      "Ep:102, loss:0.00001, loss_test:0.07399, lr:7.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.049, tt:4331.035\n",
      "Ep:103, loss:0.00001, loss_test:0.07268, lr:7.55e-03, fs:0.82022 (r=0.737,p=0.924),  time:42.051, tt:4373.253\n",
      "Ep:104, loss:0.00001, loss_test:0.07519, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.053, tt:4415.553\n",
      "Ep:105, loss:0.00001, loss_test:0.07353, lr:7.40e-03, fs:0.82022 (r=0.737,p=0.924),  time:42.065, tt:4458.921\n",
      "Ep:106, loss:0.00001, loss_test:0.07236, lr:7.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:42.066, tt:4501.105\n",
      "Ep:107, loss:0.00001, loss_test:0.07449, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:42.064, tt:4542.934\n",
      "Ep:108, loss:0.00001, loss_test:0.07206, lr:7.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:42.060, tt:4584.512\n",
      "Ep:109, loss:0.00001, loss_test:0.07660, lr:7.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.070, tt:4627.655\n",
      "Ep:110, loss:0.00001, loss_test:0.07278, lr:7.03e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.076, tt:4670.487\n",
      "Ep:111, loss:0.00001, loss_test:0.07532, lr:6.96e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.079, tt:4712.888\n",
      "Ep:112, loss:0.00001, loss_test:0.07350, lr:6.89e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.075, tt:4754.511\n",
      "Ep:113, loss:0.00001, loss_test:0.07501, lr:6.83e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.070, tt:4795.965\n",
      "Ep:114, loss:0.00001, loss_test:0.07543, lr:6.76e-03, fs:0.82486 (r=0.737,p=0.936),  time:42.070, tt:4838.091\n",
      "Ep:115, loss:0.00001, loss_test:0.07685, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.081, tt:4881.341\n",
      "Ep:116, loss:0.00001, loss_test:0.07539, lr:6.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.078, tt:4923.160\n",
      "Ep:117, loss:0.00001, loss_test:0.07363, lr:6.56e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.087, tt:4966.235\n",
      "Ep:118, loss:0.00001, loss_test:0.07497, lr:6.49e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.103, tt:5010.309\n",
      "Ep:119, loss:0.00001, loss_test:0.07110, lr:6.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.101, tt:5052.098\n",
      "Ep:120, loss:0.00001, loss_test:0.07660, lr:6.36e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.089, tt:5092.749\n",
      "Ep:121, loss:0.00001, loss_test:0.07090, lr:6.30e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.073, tt:5132.858\n",
      "Ep:122, loss:0.00001, loss_test:0.07740, lr:6.24e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.070, tt:5174.594\n",
      "Ep:123, loss:0.00001, loss_test:0.07332, lr:6.17e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.085, tt:5218.546\n",
      "Ep:124, loss:0.00001, loss_test:0.07777, lr:6.11e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.089, tt:5261.132\n",
      "Ep:125, loss:0.00001, loss_test:0.07661, lr:6.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:42.121, tt:5307.212\n",
      "Ep:126, loss:0.00001, loss_test:0.07640, lr:5.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.118, tt:5348.974\n",
      "Ep:127, loss:0.00001, loss_test:0.07570, lr:5.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.124, tt:5391.835\n",
      "Ep:128, loss:0.00001, loss_test:0.07531, lr:5.87e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.139, tt:5435.951\n",
      "Ep:129, loss:0.00000, loss_test:0.07529, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.141, tt:5478.305\n",
      "Ep:130, loss:0.00000, loss_test:0.07659, lr:5.75e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.143, tt:5520.743\n",
      "Ep:131, loss:0.00000, loss_test:0.07891, lr:5.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:42.151, tt:5563.929\n",
      "Ep:132, loss:0.00000, loss_test:0.07518, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.138, tt:5604.323\n",
      "Ep:133, loss:0.00000, loss_test:0.07918, lr:5.58e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.123, tt:5644.543\n",
      "Ep:134, loss:0.00000, loss_test:0.07487, lr:5.53e-03, fs:0.79070 (r=0.687,p=0.932),  time:42.107, tt:5684.494\n",
      "Ep:135, loss:0.00000, loss_test:0.07588, lr:5.47e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.115, tt:5727.645\n",
      "Ep:136, loss:0.00000, loss_test:0.07588, lr:5.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:42.110, tt:5769.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.07788, lr:5.36e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.110, tt:5811.162\n",
      "Ep:138, loss:0.00000, loss_test:0.07588, lr:5.31e-03, fs:0.80460 (r=0.707,p=0.933),  time:42.103, tt:5852.278\n",
      "Ep:139, loss:0.00000, loss_test:0.07899, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.099, tt:5893.825\n",
      "Ep:140, loss:0.00000, loss_test:0.07622, lr:5.20e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.104, tt:5936.732\n",
      "Ep:141, loss:0.00000, loss_test:0.07731, lr:5.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.096, tt:5977.645\n",
      "Ep:142, loss:0.00000, loss_test:0.07706, lr:5.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.107, tt:6021.269\n",
      "Ep:143, loss:0.00000, loss_test:0.07717, lr:5.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.097, tt:6062.019\n",
      "Ep:144, loss:0.00000, loss_test:0.07911, lr:5.00e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.108, tt:6105.603\n",
      "Ep:145, loss:0.00000, loss_test:0.07538, lr:4.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.097, tt:6146.111\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00000, loss_test:0.08032, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.101, tt:6188.883\n",
      "Ep:147, loss:0.00000, loss_test:0.07616, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:42.102, tt:6231.113\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00000, loss_test:0.07897, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.105, tt:6273.617\n",
      "Ep:149, loss:0.00000, loss_test:0.07735, lr:4.95e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.097, tt:6314.536\n",
      "Ep:150, loss:0.00000, loss_test:0.07759, lr:4.95e-03, fs:0.83237 (r=0.727,p=0.973),  time:42.090, tt:6355.641\n",
      "Ep:151, loss:0.00000, loss_test:0.07783, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.081, tt:6396.313\n",
      "Ep:152, loss:0.00000, loss_test:0.07637, lr:4.95e-03, fs:0.84571 (r=0.747,p=0.974),  time:42.071, tt:6436.922\n",
      "Ep:153, loss:0.00000, loss_test:0.08072, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.057, tt:6476.746\n",
      "Ep:154, loss:0.00000, loss_test:0.07712, lr:4.95e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.058, tt:6519.052\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12944, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:17.605, tt:17.605\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12686, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:17.075, tt:34.151\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12406, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:17.467, tt:52.402\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12231, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:18.229, tt:72.918\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12138, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:18.100, tt:90.499\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12110, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:18.009, tt:108.055\n",
      "Ep:6, loss:0.00026, loss_test:0.12012, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:18.084, tt:126.586\n",
      "Ep:7, loss:0.00026, loss_test:0.11896, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:18.063, tt:144.503\n",
      "Ep:8, loss:0.00025, loss_test:0.11742, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:18.041, tt:162.367\n",
      "Ep:9, loss:0.00025, loss_test:0.11507, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:18.515, tt:185.147\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.11252, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:18.471, tt:203.176\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11055, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:18.257, tt:219.084\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10877, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:18.216, tt:236.807\n",
      "Ep:13, loss:0.00023, loss_test:0.10679, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:18.170, tt:254.387\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.10492, lr:1.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:18.147, tt:272.212\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.10320, lr:1.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:18.036, tt:288.569\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.10201, lr:1.00e-02, fs:0.74380 (r=0.909,p=0.629),  time:17.984, tt:305.733\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10123, lr:1.00e-02, fs:0.73469 (r=0.909,p=0.616),  time:17.820, tt:320.767\n",
      "Ep:18, loss:0.00021, loss_test:0.09949, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:17.822, tt:338.618\n",
      "Ep:19, loss:0.00020, loss_test:0.09915, lr:1.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:17.850, tt:357.006\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09834, lr:1.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:17.722, tt:372.160\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09679, lr:1.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:17.651, tt:388.329\n",
      "Ep:22, loss:0.00019, loss_test:0.09598, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:17.712, tt:407.371\n",
      "Ep:23, loss:0.00019, loss_test:0.09371, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:17.706, tt:424.954\n",
      "Ep:24, loss:0.00018, loss_test:0.09264, lr:1.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:17.762, tt:444.059\n",
      "Ep:25, loss:0.00018, loss_test:0.09129, lr:1.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:17.886, tt:465.048\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.09024, lr:1.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:17.902, tt:483.355\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.08828, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:17.859, tt:500.049\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.08594, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:17.885, tt:518.657\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.08589, lr:1.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:17.837, tt:535.105\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.08222, lr:1.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:17.783, tt:551.274\n",
      "Ep:31, loss:0.00015, loss_test:0.08303, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:17.795, tt:569.435\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.08003, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:17.862, tt:589.446\n",
      "Ep:33, loss:0.00015, loss_test:0.07750, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:17.894, tt:608.397\n",
      "Ep:34, loss:0.00014, loss_test:0.08360, lr:1.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:17.905, tt:626.690\n",
      "Ep:35, loss:0.00014, loss_test:0.07617, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:17.894, tt:644.175\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.07589, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:17.831, tt:659.744\n",
      "Ep:37, loss:0.00013, loss_test:0.07509, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:17.869, tt:679.040\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.07431, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:17.878, tt:697.236\n",
      "Ep:39, loss:0.00012, loss_test:0.07507, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:17.820, tt:712.818\n",
      "Ep:40, loss:0.00012, loss_test:0.07384, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:17.852, tt:731.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00011, loss_test:0.07547, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:17.824, tt:748.611\n",
      "Ep:42, loss:0.00013, loss_test:0.07925, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:17.802, tt:765.469\n",
      "Ep:43, loss:0.00014, loss_test:0.08387, lr:1.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:17.794, tt:782.918\n",
      "Ep:44, loss:0.00013, loss_test:0.07874, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:17.771, tt:799.689\n",
      "Ep:45, loss:0.00015, loss_test:0.08738, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:17.728, tt:815.466\n",
      "Ep:46, loss:0.00014, loss_test:0.09011, lr:1.00e-02, fs:0.77165 (r=0.990,p=0.632),  time:17.765, tt:834.949\n",
      "Ep:47, loss:0.00015, loss_test:0.07131, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:17.790, tt:853.912\n",
      "Ep:48, loss:0.00012, loss_test:0.07950, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:17.800, tt:872.209\n",
      "Ep:49, loss:0.00012, loss_test:0.07141, lr:9.90e-03, fs:0.82667 (r=0.939,p=0.738),  time:17.819, tt:890.958\n",
      "Ep:50, loss:0.00011, loss_test:0.07135, lr:9.80e-03, fs:0.80734 (r=0.889,p=0.739),  time:17.885, tt:912.127\n",
      "Ep:51, loss:0.00010, loss_test:0.06982, lr:9.70e-03, fs:0.82819 (r=0.949,p=0.734),  time:17.922, tt:931.967\n",
      "Ep:52, loss:0.00010, loss_test:0.06925, lr:9.61e-03, fs:0.85973 (r=0.960,p=0.779),  time:17.963, tt:952.056\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.07019, lr:9.61e-03, fs:0.82969 (r=0.960,p=0.731),  time:18.002, tt:972.119\n",
      "Ep:54, loss:0.00009, loss_test:0.06820, lr:9.61e-03, fs:0.81731 (r=0.859,p=0.780),  time:17.990, tt:989.433\n",
      "Ep:55, loss:0.00009, loss_test:0.06546, lr:9.61e-03, fs:0.84071 (r=0.960,p=0.748),  time:18.027, tt:1009.508\n",
      "Ep:56, loss:0.00008, loss_test:0.06644, lr:9.61e-03, fs:0.79621 (r=0.848,p=0.750),  time:18.029, tt:1027.647\n",
      "Ep:57, loss:0.00007, loss_test:0.06439, lr:9.61e-03, fs:0.86222 (r=0.980,p=0.770),  time:17.988, tt:1043.326\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.06505, lr:9.61e-03, fs:0.82791 (r=0.899,p=0.767),  time:17.989, tt:1061.328\n",
      "Ep:59, loss:0.00007, loss_test:0.06524, lr:9.61e-03, fs:0.83962 (r=0.899,p=0.788),  time:17.990, tt:1079.379\n",
      "Ep:60, loss:0.00007, loss_test:0.06537, lr:9.61e-03, fs:0.82791 (r=0.899,p=0.767),  time:17.969, tt:1096.121\n",
      "Ep:61, loss:0.00006, loss_test:0.06411, lr:9.61e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.954, tt:1113.158\n",
      "Ep:62, loss:0.00006, loss_test:0.06940, lr:9.61e-03, fs:0.81860 (r=0.889,p=0.759),  time:17.938, tt:1130.103\n",
      "Ep:63, loss:0.00006, loss_test:0.06321, lr:9.61e-03, fs:0.81553 (r=0.848,p=0.785),  time:17.922, tt:1146.992\n",
      "Ep:64, loss:0.00006, loss_test:0.06550, lr:9.61e-03, fs:0.83654 (r=0.879,p=0.798),  time:17.922, tt:1164.929\n",
      "Ep:65, loss:0.00005, loss_test:0.06167, lr:9.61e-03, fs:0.85167 (r=0.899,p=0.809),  time:17.925, tt:1183.026\n",
      "Ep:66, loss:0.00005, loss_test:0.06044, lr:9.61e-03, fs:0.84729 (r=0.869,p=0.827),  time:17.896, tt:1199.015\n",
      "Ep:67, loss:0.00005, loss_test:0.06279, lr:9.61e-03, fs:0.82000 (r=0.828,p=0.812),  time:17.875, tt:1215.476\n",
      "Ep:68, loss:0.00005, loss_test:0.06201, lr:9.61e-03, fs:0.84906 (r=0.909,p=0.796),  time:17.861, tt:1232.437\n",
      "Ep:69, loss:0.00005, loss_test:0.06640, lr:9.51e-03, fs:0.84793 (r=0.929,p=0.780),  time:17.838, tt:1248.653\n",
      "Ep:70, loss:0.00006, loss_test:0.05950, lr:9.41e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.836, tt:1266.369\n",
      "Ep:71, loss:0.00005, loss_test:0.06244, lr:9.32e-03, fs:0.85849 (r=0.919,p=0.805),  time:17.865, tt:1286.301\n",
      "Ep:72, loss:0.00005, loss_test:0.06016, lr:9.23e-03, fs:0.84103 (r=0.828,p=0.854),  time:17.860, tt:1303.747\n",
      "Ep:73, loss:0.00005, loss_test:0.06588, lr:9.14e-03, fs:0.80788 (r=0.828,p=0.788),  time:17.859, tt:1321.589\n",
      "Ep:74, loss:0.00005, loss_test:0.05986, lr:9.04e-03, fs:0.84422 (r=0.848,p=0.840),  time:17.879, tt:1340.895\n",
      "Ep:75, loss:0.00005, loss_test:0.06934, lr:8.95e-03, fs:0.79245 (r=0.848,p=0.743),  time:17.867, tt:1357.866\n",
      "Ep:76, loss:0.00005, loss_test:0.05307, lr:8.86e-03, fs:0.91346 (r=0.960,p=0.872),  time:17.850, tt:1374.461\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.06409, lr:8.86e-03, fs:0.82759 (r=0.848,p=0.808),  time:17.847, tt:1392.057\n",
      "Ep:78, loss:0.00005, loss_test:0.06338, lr:8.86e-03, fs:0.80000 (r=0.788,p=0.812),  time:17.838, tt:1409.168\n",
      "Ep:79, loss:0.00004, loss_test:0.06002, lr:8.86e-03, fs:0.84264 (r=0.838,p=0.847),  time:17.814, tt:1425.132\n",
      "Ep:80, loss:0.00004, loss_test:0.05969, lr:8.86e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.820, tt:1443.457\n",
      "Ep:81, loss:0.00004, loss_test:0.06078, lr:8.86e-03, fs:0.83505 (r=0.818,p=0.853),  time:17.818, tt:1461.113\n",
      "Ep:82, loss:0.00004, loss_test:0.05780, lr:8.86e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.794, tt:1476.908\n",
      "Ep:83, loss:0.00003, loss_test:0.05618, lr:8.86e-03, fs:0.87129 (r=0.889,p=0.854),  time:17.775, tt:1493.126\n",
      "Ep:84, loss:0.00003, loss_test:0.05783, lr:8.86e-03, fs:0.86294 (r=0.859,p=0.867),  time:17.733, tt:1507.317\n",
      "Ep:85, loss:0.00003, loss_test:0.05822, lr:8.86e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.694, tt:1521.663\n",
      "Ep:86, loss:0.00003, loss_test:0.05466, lr:8.86e-03, fs:0.85714 (r=0.848,p=0.866),  time:17.656, tt:1536.058\n",
      "Ep:87, loss:0.00003, loss_test:0.05839, lr:8.86e-03, fs:0.86139 (r=0.879,p=0.845),  time:17.655, tt:1553.621\n",
      "Ep:88, loss:0.00003, loss_test:0.05638, lr:8.78e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.646, tt:1570.521\n",
      "Ep:89, loss:0.00003, loss_test:0.05427, lr:8.69e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.609, tt:1584.808\n",
      "Ep:90, loss:0.00003, loss_test:0.05643, lr:8.60e-03, fs:0.86432 (r=0.869,p=0.860),  time:17.590, tt:1600.712\n",
      "Ep:91, loss:0.00003, loss_test:0.05693, lr:8.51e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.553, tt:1614.855\n",
      "Ep:92, loss:0.00003, loss_test:0.05924, lr:8.43e-03, fs:0.85149 (r=0.869,p=0.835),  time:17.542, tt:1631.392\n",
      "Ep:93, loss:0.00003, loss_test:0.05908, lr:8.35e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.563, tt:1650.889\n",
      "Ep:94, loss:0.00002, loss_test:0.05561, lr:8.26e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.557, tt:1667.888\n",
      "Ep:95, loss:0.00002, loss_test:0.06108, lr:8.18e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.557, tt:1685.512\n",
      "Ep:96, loss:0.00002, loss_test:0.05738, lr:8.10e-03, fs:0.87755 (r=0.869,p=0.887),  time:17.569, tt:1704.169\n",
      "Ep:97, loss:0.00002, loss_test:0.05979, lr:8.02e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.550, tt:1719.911\n",
      "Ep:98, loss:0.00002, loss_test:0.05616, lr:7.94e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.540, tt:1736.509\n",
      "Ep:99, loss:0.00002, loss_test:0.05914, lr:7.86e-03, fs:0.87310 (r=0.869,p=0.878),  time:17.552, tt:1755.250\n",
      "Ep:100, loss:0.00002, loss_test:0.05810, lr:7.78e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.530, tt:1770.509\n",
      "Ep:101, loss:0.00002, loss_test:0.05652, lr:7.70e-03, fs:0.87310 (r=0.869,p=0.878),  time:17.501, tt:1785.060\n",
      "Ep:102, loss:0.00002, loss_test:0.05932, lr:7.62e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.505, tt:1802.965\n",
      "Ep:103, loss:0.00002, loss_test:0.06232, lr:7.55e-03, fs:0.87310 (r=0.869,p=0.878),  time:17.512, tt:1821.265\n",
      "Ep:104, loss:0.00002, loss_test:0.05366, lr:7.47e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.509, tt:1838.497\n",
      "Ep:105, loss:0.00002, loss_test:0.06113, lr:7.40e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.523, tt:1857.423\n",
      "Ep:106, loss:0.00002, loss_test:0.06158, lr:7.32e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.519, tt:1874.518\n",
      "Ep:107, loss:0.00002, loss_test:0.05975, lr:7.25e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.509, tt:1890.981\n",
      "Ep:108, loss:0.00002, loss_test:0.05625, lr:7.18e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.499, tt:1907.440\n",
      "Ep:109, loss:0.00002, loss_test:0.06204, lr:7.11e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.498, tt:1924.800\n",
      "Ep:110, loss:0.00002, loss_test:0.05620, lr:7.03e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.504, tt:1942.904\n",
      "Ep:111, loss:0.00002, loss_test:0.05726, lr:6.96e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.501, tt:1960.159\n",
      "Ep:112, loss:0.00002, loss_test:0.05639, lr:6.89e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.505, tt:1978.040\n",
      "Ep:113, loss:0.00002, loss_test:0.06195, lr:6.83e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.516, tt:1996.801\n",
      "Ep:114, loss:0.00002, loss_test:0.06076, lr:6.76e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.508, tt:2013.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00002, loss_test:0.05830, lr:6.69e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.515, tt:2031.757\n",
      "Ep:116, loss:0.00002, loss_test:0.05844, lr:6.62e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.508, tt:2048.404\n",
      "Ep:117, loss:0.00002, loss_test:0.06097, lr:6.56e-03, fs:0.87755 (r=0.869,p=0.887),  time:17.494, tt:2064.236\n",
      "Ep:118, loss:0.00002, loss_test:0.05939, lr:6.49e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.496, tt:2082.080\n",
      "Ep:119, loss:0.00002, loss_test:0.05764, lr:6.43e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.485, tt:2098.159\n",
      "Ep:120, loss:0.00002, loss_test:0.05980, lr:6.36e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.488, tt:2116.021\n",
      "Ep:121, loss:0.00002, loss_test:0.06387, lr:6.30e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.496, tt:2134.550\n",
      "Ep:122, loss:0.00001, loss_test:0.05794, lr:6.24e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.491, tt:2151.435\n",
      "Ep:123, loss:0.00001, loss_test:0.05942, lr:6.17e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.486, tt:2168.314\n",
      "Ep:124, loss:0.00001, loss_test:0.06187, lr:6.11e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.493, tt:2186.674\n",
      "Ep:125, loss:0.00001, loss_test:0.06079, lr:6.05e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.477, tt:2202.068\n",
      "Ep:126, loss:0.00001, loss_test:0.05826, lr:5.99e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.460, tt:2217.433\n",
      "Ep:127, loss:0.00001, loss_test:0.06155, lr:5.93e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.449, tt:2233.420\n",
      "Ep:128, loss:0.00001, loss_test:0.06076, lr:5.87e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.446, tt:2250.481\n",
      "Ep:129, loss:0.00001, loss_test:0.06097, lr:5.81e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.436, tt:2266.653\n",
      "Ep:130, loss:0.00001, loss_test:0.06178, lr:5.75e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.448, tt:2285.653\n",
      "Ep:131, loss:0.00001, loss_test:0.06174, lr:5.70e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.458, tt:2304.456\n",
      "Ep:132, loss:0.00001, loss_test:0.06314, lr:5.64e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.449, tt:2320.755\n",
      "Ep:133, loss:0.00001, loss_test:0.05951, lr:5.58e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.463, tt:2339.988\n",
      "Ep:134, loss:0.00001, loss_test:0.06414, lr:5.53e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.467, tt:2358.053\n",
      "Ep:135, loss:0.00001, loss_test:0.06116, lr:5.47e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.462, tt:2374.787\n",
      "Ep:136, loss:0.00001, loss_test:0.05959, lr:5.42e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.473, tt:2393.776\n",
      "Ep:137, loss:0.00001, loss_test:0.06244, lr:5.36e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.484, tt:2412.752\n",
      "Ep:138, loss:0.00001, loss_test:0.06161, lr:5.31e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.478, tt:2429.497\n",
      "Ep:139, loss:0.00001, loss_test:0.06363, lr:5.26e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.492, tt:2448.870\n",
      "Ep:140, loss:0.00001, loss_test:0.06269, lr:5.20e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.502, tt:2467.793\n",
      "Ep:141, loss:0.00001, loss_test:0.06363, lr:5.15e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.503, tt:2485.459\n",
      "Ep:142, loss:0.00001, loss_test:0.06091, lr:5.10e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.515, tt:2504.689\n",
      "Ep:143, loss:0.00001, loss_test:0.06428, lr:5.05e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.525, tt:2523.549\n",
      "Ep:144, loss:0.00001, loss_test:0.06311, lr:5.00e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.509, tt:2538.799\n",
      "Ep:145, loss:0.00001, loss_test:0.06147, lr:4.95e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.509, tt:2556.277\n",
      "Ep:146, loss:0.00001, loss_test:0.06341, lr:4.90e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.514, tt:2574.534\n",
      "Ep:147, loss:0.00001, loss_test:0.06291, lr:4.85e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.494, tt:2589.137\n",
      "Ep:148, loss:0.00001, loss_test:0.06220, lr:4.80e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.478, tt:2604.170\n",
      "Ep:149, loss:0.00001, loss_test:0.06451, lr:4.75e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.477, tt:2621.496\n",
      "Ep:150, loss:0.00001, loss_test:0.06186, lr:4.71e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.467, tt:2637.496\n",
      "Ep:151, loss:0.00001, loss_test:0.06329, lr:4.66e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.448, tt:2652.082\n",
      "Ep:152, loss:0.00001, loss_test:0.06246, lr:4.61e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.442, tt:2668.552\n",
      "Ep:153, loss:0.00001, loss_test:0.06306, lr:4.57e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.434, tt:2684.888\n",
      "Ep:154, loss:0.00001, loss_test:0.06342, lr:4.52e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.416, tt:2699.465\n",
      "Ep:155, loss:0.00001, loss_test:0.06294, lr:4.48e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.434, tt:2719.699\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12762, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:20.339, tt:20.339\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12562, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:20.173, tt:40.346\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12361, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:20.584, tt:61.753\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12246, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:20.274, tt:81.095\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12137, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:20.668, tt:103.340\n",
      "Ep:5, loss:0.00026, loss_test:0.12030, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:20.450, tt:122.700\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.11884, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:20.225, tt:141.576\n",
      "Ep:7, loss:0.00025, loss_test:0.11666, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:20.466, tt:163.728\n",
      "Ep:8, loss:0.00025, loss_test:0.11398, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:20.374, tt:183.368\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.11238, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:20.196, tt:201.955\n",
      "Ep:10, loss:0.00025, loss_test:0.11087, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:20.241, tt:222.655\n",
      "Ep:11, loss:0.00024, loss_test:0.10871, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:20.196, tt:242.351\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10675, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:20.238, tt:263.089\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.10436, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:20.273, tt:283.826\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.10220, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:20.219, tt:303.278\n",
      "Ep:15, loss:0.00022, loss_test:0.10228, lr:1.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:20.168, tt:322.695\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.09859, lr:1.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:20.198, tt:343.369\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.09707, lr:1.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:20.254, tt:364.579\n",
      "Ep:18, loss:0.00020, loss_test:0.09695, lr:1.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:20.263, tt:384.992\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.09265, lr:1.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:20.190, tt:403.803\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.09176, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:20.234, tt:424.919\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09234, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:20.287, tt:446.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00017, loss_test:0.08547, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:20.277, tt:466.382\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09007, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:20.291, tt:486.986\n",
      "Ep:24, loss:0.00015, loss_test:0.08233, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:20.248, tt:506.202\n",
      "Ep:25, loss:0.00015, loss_test:0.08495, lr:1.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:20.202, tt:525.255\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08159, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:20.252, tt:546.811\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08241, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:20.178, tt:564.993\n",
      "Ep:28, loss:0.00013, loss_test:0.08030, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:20.199, tt:585.775\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08018, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:20.262, tt:607.855\n",
      "Ep:30, loss:0.00012, loss_test:0.08328, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:20.273, tt:628.448\n",
      "Ep:31, loss:0.00012, loss_test:0.08687, lr:1.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:20.255, tt:648.172\n",
      "Ep:32, loss:0.00012, loss_test:0.07251, lr:1.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:20.304, tt:670.043\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08121, lr:1.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:20.348, tt:691.830\n",
      "Ep:34, loss:0.00012, loss_test:0.06970, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:20.328, tt:711.496\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07726, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:20.292, tt:730.527\n",
      "Ep:36, loss:0.00010, loss_test:0.06968, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:20.313, tt:751.588\n",
      "Ep:37, loss:0.00010, loss_test:0.07534, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:20.309, tt:771.745\n",
      "Ep:38, loss:0.00009, loss_test:0.07100, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:20.293, tt:791.428\n",
      "Ep:39, loss:0.00009, loss_test:0.07193, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:20.320, tt:812.792\n",
      "Ep:40, loss:0.00008, loss_test:0.07343, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:20.278, tt:831.379\n",
      "Ep:41, loss:0.00007, loss_test:0.07354, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:20.343, tt:854.415\n",
      "Ep:42, loss:0.00007, loss_test:0.06341, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:20.385, tt:876.543\n",
      "Ep:43, loss:0.00007, loss_test:0.07466, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:20.407, tt:897.922\n",
      "Ep:44, loss:0.00006, loss_test:0.06468, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:20.389, tt:917.482\n",
      "Ep:45, loss:0.00006, loss_test:0.07530, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:20.391, tt:938.002\n",
      "Ep:46, loss:0.00005, loss_test:0.06749, lr:9.90e-03, fs:0.82051 (r=0.808,p=0.833),  time:20.438, tt:960.571\n",
      "Ep:47, loss:0.00005, loss_test:0.07477, lr:9.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:20.455, tt:981.863\n",
      "Ep:48, loss:0.00005, loss_test:0.06840, lr:9.70e-03, fs:0.77895 (r=0.747,p=0.813),  time:20.462, tt:1002.619\n",
      "Ep:49, loss:0.00005, loss_test:0.06386, lr:9.61e-03, fs:0.83770 (r=0.808,p=0.870),  time:20.562, tt:1028.110\n",
      "Ep:50, loss:0.00005, loss_test:0.06398, lr:9.51e-03, fs:0.85427 (r=0.859,p=0.850),  time:20.551, tt:1048.090\n",
      "Ep:51, loss:0.00005, loss_test:0.06316, lr:9.41e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.507, tt:1066.349\n",
      "Ep:52, loss:0.00004, loss_test:0.06926, lr:9.32e-03, fs:0.82292 (r=0.798,p=0.849),  time:20.545, tt:1088.873\n",
      "Ep:53, loss:0.00004, loss_test:0.06039, lr:9.23e-03, fs:0.80829 (r=0.788,p=0.830),  time:20.537, tt:1109.021\n",
      "Ep:54, loss:0.00004, loss_test:0.07371, lr:9.14e-03, fs:0.79144 (r=0.747,p=0.841),  time:20.531, tt:1129.181\n",
      "Ep:55, loss:0.00004, loss_test:0.06191, lr:9.04e-03, fs:0.84211 (r=0.808,p=0.879),  time:20.538, tt:1150.111\n",
      "Ep:56, loss:0.00004, loss_test:0.06254, lr:8.95e-03, fs:0.83249 (r=0.828,p=0.837),  time:20.498, tt:1168.398\n",
      "Ep:57, loss:0.00004, loss_test:0.06202, lr:8.86e-03, fs:0.85561 (r=0.808,p=0.909),  time:20.501, tt:1189.077\n",
      "Ep:58, loss:0.00003, loss_test:0.06815, lr:8.78e-03, fs:0.78534 (r=0.758,p=0.815),  time:20.446, tt:1206.305\n",
      "Ep:59, loss:0.00003, loss_test:0.06256, lr:8.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.446, tt:1226.757\n",
      "Ep:60, loss:0.00003, loss_test:0.06444, lr:8.60e-03, fs:0.80423 (r=0.768,p=0.844),  time:20.440, tt:1246.867\n",
      "Ep:61, loss:0.00003, loss_test:0.06601, lr:8.51e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.410, tt:1265.406\n",
      "Ep:62, loss:0.00003, loss_test:0.06567, lr:8.43e-03, fs:0.79144 (r=0.747,p=0.841),  time:20.419, tt:1286.398\n",
      "Ep:63, loss:0.00003, loss_test:0.06350, lr:8.35e-03, fs:0.81720 (r=0.768,p=0.874),  time:20.417, tt:1306.705\n",
      "Ep:64, loss:0.00003, loss_test:0.06261, lr:8.26e-03, fs:0.81481 (r=0.778,p=0.856),  time:20.391, tt:1325.427\n",
      "Ep:65, loss:0.00003, loss_test:0.06745, lr:8.18e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.391, tt:1345.833\n",
      "Ep:66, loss:0.00003, loss_test:0.06781, lr:8.10e-03, fs:0.79787 (r=0.758,p=0.843),  time:20.364, tt:1364.394\n",
      "Ep:67, loss:0.00003, loss_test:0.06170, lr:8.02e-03, fs:0.82162 (r=0.768,p=0.884),  time:20.352, tt:1383.911\n",
      "Ep:68, loss:0.00003, loss_test:0.07168, lr:7.94e-03, fs:0.79787 (r=0.758,p=0.843),  time:20.368, tt:1405.366\n",
      "Ep:69, loss:0.00003, loss_test:0.06239, lr:7.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:20.364, tt:1425.497\n",
      "Ep:70, loss:0.00002, loss_test:0.06750, lr:7.78e-03, fs:0.80214 (r=0.758,p=0.852),  time:20.380, tt:1446.989\n",
      "Ep:71, loss:0.00002, loss_test:0.06427, lr:7.70e-03, fs:0.82979 (r=0.788,p=0.876),  time:20.369, tt:1466.593\n",
      "Ep:72, loss:0.00002, loss_test:0.06569, lr:7.62e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.383, tt:1487.930\n",
      "Ep:73, loss:0.00002, loss_test:0.06216, lr:7.55e-03, fs:0.81720 (r=0.768,p=0.874),  time:20.410, tt:1510.356\n",
      "Ep:74, loss:0.00002, loss_test:0.06631, lr:7.47e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.372, tt:1527.875\n",
      "Ep:75, loss:0.00002, loss_test:0.06662, lr:7.40e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.394, tt:1549.909\n",
      "Ep:76, loss:0.00002, loss_test:0.06058, lr:7.32e-03, fs:0.81283 (r=0.768,p=0.864),  time:20.420, tt:1572.328\n",
      "Ep:77, loss:0.00002, loss_test:0.06526, lr:7.25e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.428, tt:1593.404\n",
      "Ep:78, loss:0.00002, loss_test:0.06501, lr:7.18e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.459, tt:1616.229\n",
      "Ep:79, loss:0.00002, loss_test:0.06390, lr:7.11e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.459, tt:1636.758\n",
      "Ep:80, loss:0.00002, loss_test:0.06716, lr:7.03e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.482, tt:1659.043\n",
      "Ep:81, loss:0.00002, loss_test:0.06333, lr:6.96e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.471, tt:1678.634\n",
      "Ep:82, loss:0.00002, loss_test:0.06472, lr:6.89e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.456, tt:1697.828\n",
      "Ep:83, loss:0.00002, loss_test:0.06625, lr:6.83e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.485, tt:1720.721\n",
      "Ep:84, loss:0.00002, loss_test:0.06588, lr:6.76e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.468, tt:1739.806\n",
      "Ep:85, loss:0.00002, loss_test:0.06542, lr:6.69e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.438, tt:1757.663\n",
      "Ep:86, loss:0.00002, loss_test:0.06631, lr:6.62e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.441, tt:1778.373\n",
      "Ep:87, loss:0.00002, loss_test:0.06333, lr:6.56e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.433, tt:1798.127\n",
      "Ep:88, loss:0.00002, loss_test:0.06456, lr:6.49e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.431, tt:1818.350\n",
      "Ep:89, loss:0.00002, loss_test:0.06645, lr:6.43e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.448, tt:1840.291\n",
      "Ep:90, loss:0.00002, loss_test:0.06611, lr:6.36e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.425, tt:1858.686\n",
      "Ep:91, loss:0.00002, loss_test:0.06374, lr:6.30e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.416, tt:1878.248\n",
      "Ep:92, loss:0.00002, loss_test:0.06798, lr:6.24e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.395, tt:1896.729\n",
      "Ep:93, loss:0.00002, loss_test:0.06327, lr:6.17e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.391, tt:1916.719\n",
      "Ep:94, loss:0.00002, loss_test:0.06440, lr:6.11e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.389, tt:1936.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00002, loss_test:0.06555, lr:6.05e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.378, tt:1956.326\n",
      "Ep:96, loss:0.00002, loss_test:0.06622, lr:5.99e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.392, tt:1978.026\n",
      "Ep:97, loss:0.00002, loss_test:0.06356, lr:5.93e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.400, tt:1999.182\n",
      "Ep:98, loss:0.00001, loss_test:0.06741, lr:5.87e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.411, tt:2020.710\n",
      "Ep:99, loss:0.00001, loss_test:0.06361, lr:5.81e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.424, tt:2042.389\n",
      "Ep:100, loss:0.00001, loss_test:0.06723, lr:5.75e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.424, tt:2062.805\n",
      "Ep:101, loss:0.00001, loss_test:0.06508, lr:5.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.427, tt:2083.510\n",
      "Ep:102, loss:0.00001, loss_test:0.06462, lr:5.64e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.432, tt:2104.516\n",
      "Ep:103, loss:0.00001, loss_test:0.06621, lr:5.58e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.434, tt:2125.136\n",
      "Ep:104, loss:0.00001, loss_test:0.06556, lr:5.53e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.457, tt:2147.969\n",
      "Ep:105, loss:0.00001, loss_test:0.06595, lr:5.47e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.444, tt:2167.030\n",
      "Ep:106, loss:0.00001, loss_test:0.06616, lr:5.42e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.437, tt:2186.757\n",
      "Ep:107, loss:0.00001, loss_test:0.06441, lr:5.36e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.450, tt:2208.594\n",
      "Ep:108, loss:0.00001, loss_test:0.06621, lr:5.31e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.437, tt:2227.638\n",
      "Ep:109, loss:0.00001, loss_test:0.06385, lr:5.26e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.453, tt:2249.877\n",
      "Ep:110, loss:0.00001, loss_test:0.06811, lr:5.20e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.465, tt:2271.663\n",
      "Ep:111, loss:0.00001, loss_test:0.06380, lr:5.15e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.452, tt:2290.579\n",
      "Ep:112, loss:0.00001, loss_test:0.06723, lr:5.10e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.449, tt:2310.727\n",
      "Ep:113, loss:0.00001, loss_test:0.06733, lr:5.05e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.446, tt:2330.810\n",
      "Ep:114, loss:0.00001, loss_test:0.06392, lr:5.00e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.424, tt:2348.708\n",
      "Ep:115, loss:0.00001, loss_test:0.06617, lr:4.95e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.423, tt:2369.035\n",
      "Ep:116, loss:0.00001, loss_test:0.06661, lr:4.90e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.416, tt:2388.630\n",
      "Ep:117, loss:0.00001, loss_test:0.06581, lr:4.85e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.455, tt:2413.704\n",
      "Ep:118, loss:0.00001, loss_test:0.06478, lr:4.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.449, tt:2433.429\n",
      "Ep:119, loss:0.00001, loss_test:0.06803, lr:4.75e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.432, tt:2451.895\n",
      "Ep:120, loss:0.00001, loss_test:0.06496, lr:4.71e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.453, tt:2474.860\n",
      "Ep:121, loss:0.00001, loss_test:0.06744, lr:4.66e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.466, tt:2496.805\n",
      "Ep:122, loss:0.00001, loss_test:0.06441, lr:4.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.462, tt:2516.806\n",
      "Ep:123, loss:0.00001, loss_test:0.06925, lr:4.57e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.465, tt:2537.605\n",
      "Ep:124, loss:0.00001, loss_test:0.06314, lr:4.52e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.469, tt:2558.600\n",
      "Ep:125, loss:0.00001, loss_test:0.06556, lr:4.48e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.472, tt:2579.424\n",
      "Ep:126, loss:0.00001, loss_test:0.06811, lr:4.43e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.474, tt:2600.210\n",
      "Ep:127, loss:0.00001, loss_test:0.06652, lr:4.39e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.469, tt:2620.013\n",
      "Ep:128, loss:0.00001, loss_test:0.06671, lr:4.34e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.467, tt:2640.202\n",
      "Ep:129, loss:0.00001, loss_test:0.06424, lr:4.30e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.460, tt:2659.862\n",
      "Ep:130, loss:0.00001, loss_test:0.06826, lr:4.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.490, tt:2684.158\n",
      "Ep:131, loss:0.00001, loss_test:0.06450, lr:4.21e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.477, tt:2702.949\n",
      "Ep:132, loss:0.00001, loss_test:0.06535, lr:4.17e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.476, tt:2723.365\n",
      "Ep:133, loss:0.00001, loss_test:0.06625, lr:4.13e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.487, tt:2745.204\n",
      "Ep:134, loss:0.00001, loss_test:0.06457, lr:4.09e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.496, tt:2766.900\n",
      "Ep:135, loss:0.00001, loss_test:0.06574, lr:4.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.517, tt:2790.369\n",
      "Ep:136, loss:0.00001, loss_test:0.06454, lr:4.01e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.533, tt:2813.088\n",
      "Ep:137, loss:0.00001, loss_test:0.06687, lr:3.97e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.527, tt:2832.716\n",
      "Ep:138, loss:0.00001, loss_test:0.06429, lr:3.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.533, tt:2854.099\n",
      "Ep:139, loss:0.00001, loss_test:0.06556, lr:3.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.528, tt:2873.981\n",
      "Ep:140, loss:0.00001, loss_test:0.06610, lr:3.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.537, tt:2895.780\n",
      "Ep:141, loss:0.00001, loss_test:0.06446, lr:3.81e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.540, tt:2916.656\n",
      "Ep:142, loss:0.00001, loss_test:0.06442, lr:3.77e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.537, tt:2936.765\n",
      "Ep:143, loss:0.00001, loss_test:0.06461, lr:3.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.553, tt:2959.641\n",
      "Ep:144, loss:0.00001, loss_test:0.06426, lr:3.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.544, tt:2978.952\n",
      "Ep:145, loss:0.00001, loss_test:0.06393, lr:3.66e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.552, tt:3000.584\n",
      "Ep:146, loss:0.00001, loss_test:0.06420, lr:3.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.554, tt:3021.388\n",
      "Ep:147, loss:0.00001, loss_test:0.06523, lr:3.59e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.544, tt:3040.520\n",
      "Ep:148, loss:0.00001, loss_test:0.06409, lr:3.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:20.549, tt:3061.820\n",
      "Ep:149, loss:0.00001, loss_test:0.06464, lr:3.52e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.549, tt:3082.393\n",
      "Ep:150, loss:0.00001, loss_test:0.06377, lr:3.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:20.535, tt:3100.734\n",
      "Ep:151, loss:0.00001, loss_test:0.06577, lr:3.45e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.533, tt:3121.026\n",
      "Ep:152, loss:0.00001, loss_test:0.06358, lr:3.41e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.520, tt:3139.491\n",
      "Ep:153, loss:0.00001, loss_test:0.06583, lr:3.38e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.504, tt:3157.673\n",
      "Ep:154, loss:0.00001, loss_test:0.06261, lr:3.34e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.492, tt:3176.188\n",
      "Ep:155, loss:0.00001, loss_test:0.06566, lr:3.31e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.473, tt:3193.755\n",
      "Ep:156, loss:0.00001, loss_test:0.06414, lr:3.28e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.476, tt:3214.737\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14545, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.746, tt:41.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14484, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.294, tt:82.588\n",
      "Ep:2, loss:0.00028, loss_test:0.14383, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.570, tt:124.711\n",
      "Ep:3, loss:0.00028, loss_test:0.14220, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.032, tt:168.126\n",
      "Ep:4, loss:0.00027, loss_test:0.13961, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.907, tt:209.537\n",
      "Ep:5, loss:0.00027, loss_test:0.13565, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:41.732, tt:250.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00026, loss_test:0.12940, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:41.663, tt:291.641\n",
      "Ep:7, loss:0.00024, loss_test:0.12084, lr:1.00e-02, fs:0.66946 (r=0.808,p=0.571),  time:41.534, tt:332.269\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11500, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:41.461, tt:373.153\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11334, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:41.441, tt:414.407\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11209, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:41.294, tt:454.237\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11201, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:41.243, tt:494.916\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10914, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:41.164, tt:535.136\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10742, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:41.301, tt:578.208\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10743, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:41.303, tt:619.538\n",
      "Ep:15, loss:0.00019, loss_test:0.10680, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:41.238, tt:659.815\n",
      "Ep:16, loss:0.00019, loss_test:0.10375, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:41.207, tt:700.518\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10237, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:41.168, tt:741.029\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10193, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:41.160, tt:782.034\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10076, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:41.207, tt:824.140\n",
      "Ep:20, loss:0.00017, loss_test:0.09988, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:41.254, tt:866.331\n",
      "Ep:21, loss:0.00017, loss_test:0.09918, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:41.134, tt:904.944\n",
      "Ep:22, loss:0.00016, loss_test:0.09822, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:41.148, tt:946.401\n",
      "Ep:23, loss:0.00016, loss_test:0.09778, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:41.191, tt:988.584\n",
      "Ep:24, loss:0.00016, loss_test:0.09723, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:41.230, tt:1030.751\n",
      "Ep:25, loss:0.00015, loss_test:0.09693, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:41.250, tt:1072.498\n",
      "Ep:26, loss:0.00015, loss_test:0.09675, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:41.262, tt:1114.069\n",
      "Ep:27, loss:0.00015, loss_test:0.09564, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:41.241, tt:1154.735\n",
      "Ep:28, loss:0.00014, loss_test:0.09555, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:41.274, tt:1196.943\n",
      "Ep:29, loss:0.00014, loss_test:0.09550, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:41.296, tt:1238.866\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09433, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.315, tt:1280.774\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09494, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:41.316, tt:1322.124\n",
      "Ep:32, loss:0.00013, loss_test:0.09370, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:41.317, tt:1363.467\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.09330, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:41.257, tt:1402.742\n",
      "Ep:34, loss:0.00013, loss_test:0.09305, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:41.259, tt:1444.075\n",
      "Ep:35, loss:0.00012, loss_test:0.09247, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:41.229, tt:1484.236\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.09231, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.213, tt:1524.869\n",
      "Ep:37, loss:0.00012, loss_test:0.09151, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:41.191, tt:1565.247\n",
      "Ep:38, loss:0.00012, loss_test:0.09165, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:41.179, tt:1605.962\n",
      "Ep:39, loss:0.00012, loss_test:0.09038, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:41.190, tt:1647.614\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.09090, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:41.238, tt:1690.742\n",
      "Ep:41, loss:0.00011, loss_test:0.08974, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:41.230, tt:1731.648\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.08994, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:41.258, tt:1774.078\n",
      "Ep:43, loss:0.00011, loss_test:0.08871, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:41.225, tt:1813.882\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.08901, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:41.226, tt:1855.184\n",
      "Ep:45, loss:0.00010, loss_test:0.08806, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:41.224, tt:1896.296\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.08791, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:41.217, tt:1937.186\n",
      "Ep:47, loss:0.00010, loss_test:0.08705, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:41.227, tt:1978.898\n",
      "Ep:48, loss:0.00010, loss_test:0.08724, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.222, tt:2019.881\n",
      "Ep:49, loss:0.00010, loss_test:0.08585, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:41.240, tt:2062.024\n",
      "Ep:50, loss:0.00009, loss_test:0.08705, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:41.234, tt:2102.943\n",
      "Ep:51, loss:0.00009, loss_test:0.08531, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:41.251, tt:2145.035\n",
      "Ep:52, loss:0.00009, loss_test:0.08619, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:41.242, tt:2185.844\n",
      "Ep:53, loss:0.00009, loss_test:0.08430, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.233, tt:2226.591\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00009, loss_test:0.08618, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:41.260, tt:2269.288\n",
      "Ep:55, loss:0.00009, loss_test:0.08485, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:41.265, tt:2310.836\n",
      "Ep:56, loss:0.00008, loss_test:0.08625, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:41.272, tt:2352.495\n",
      "Ep:57, loss:0.00008, loss_test:0.08485, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:41.252, tt:2392.599\n",
      "Ep:58, loss:0.00008, loss_test:0.08565, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:41.229, tt:2432.500\n",
      "Ep:59, loss:0.00008, loss_test:0.08399, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:41.231, tt:2473.885\n",
      "Ep:60, loss:0.00008, loss_test:0.08471, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.205, tt:2513.490\n",
      "Ep:61, loss:0.00008, loss_test:0.08205, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.186, tt:2553.504\n",
      "Ep:62, loss:0.00008, loss_test:0.08388, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:41.183, tt:2594.556\n",
      "Ep:63, loss:0.00007, loss_test:0.08190, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.171, tt:2634.971\n",
      "Ep:64, loss:0.00007, loss_test:0.08251, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:41.164, tt:2675.663\n",
      "Ep:65, loss:0.00007, loss_test:0.08224, lr:9.90e-03, fs:0.77005 (r=0.727,p=0.818),  time:41.183, tt:2718.060\n",
      "Ep:66, loss:0.00007, loss_test:0.08135, lr:9.80e-03, fs:0.77419 (r=0.727,p=0.828),  time:41.202, tt:2760.535\n",
      "Ep:67, loss:0.00007, loss_test:0.08230, lr:9.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:41.215, tt:2802.627\n",
      "Ep:68, loss:0.00007, loss_test:0.08039, lr:9.61e-03, fs:0.80423 (r=0.768,p=0.844),  time:41.232, tt:2844.981\n",
      "Ep:69, loss:0.00007, loss_test:0.08270, lr:9.51e-03, fs:0.75978 (r=0.687,p=0.850),  time:41.245, tt:2887.147\n",
      "Ep:70, loss:0.00006, loss_test:0.07994, lr:9.41e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.243, tt:2928.262\n",
      "Ep:71, loss:0.00006, loss_test:0.08193, lr:9.32e-03, fs:0.77095 (r=0.697,p=0.863),  time:41.250, tt:2969.978\n",
      "Ep:72, loss:0.00006, loss_test:0.08057, lr:9.23e-03, fs:0.78495 (r=0.737,p=0.839),  time:41.243, tt:3010.732\n",
      "Ep:73, loss:0.00006, loss_test:0.08036, lr:9.14e-03, fs:0.80220 (r=0.737,p=0.880),  time:41.203, tt:3049.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00006, loss_test:0.08222, lr:9.04e-03, fs:0.78889 (r=0.717,p=0.877),  time:41.218, tt:3091.349\n",
      "Ep:75, loss:0.00006, loss_test:0.07869, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:41.198, tt:3131.074\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00006, loss_test:0.08425, lr:8.95e-03, fs:0.74713 (r=0.657,p=0.867),  time:41.226, tt:3174.439\n",
      "Ep:77, loss:0.00006, loss_test:0.07896, lr:8.95e-03, fs:0.78075 (r=0.737,p=0.830),  time:41.220, tt:3215.176\n",
      "Ep:78, loss:0.00006, loss_test:0.08193, lr:8.95e-03, fs:0.78212 (r=0.707,p=0.875),  time:41.217, tt:3256.124\n",
      "Ep:79, loss:0.00006, loss_test:0.07946, lr:8.95e-03, fs:0.77348 (r=0.707,p=0.854),  time:41.226, tt:3298.052\n",
      "Ep:80, loss:0.00006, loss_test:0.08138, lr:8.95e-03, fs:0.79558 (r=0.727,p=0.878),  time:41.239, tt:3340.399\n",
      "Ep:81, loss:0.00006, loss_test:0.07908, lr:8.95e-03, fs:0.78075 (r=0.737,p=0.830),  time:41.255, tt:3382.894\n",
      "Ep:82, loss:0.00005, loss_test:0.08237, lr:8.95e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.249, tt:3423.670\n",
      "Ep:83, loss:0.00005, loss_test:0.08095, lr:8.95e-03, fs:0.78919 (r=0.737,p=0.849),  time:41.246, tt:3464.701\n",
      "Ep:84, loss:0.00005, loss_test:0.08097, lr:8.95e-03, fs:0.78652 (r=0.707,p=0.886),  time:41.266, tt:3507.600\n",
      "Ep:85, loss:0.00005, loss_test:0.07832, lr:8.95e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.249, tt:3547.395\n",
      "Ep:86, loss:0.00005, loss_test:0.08107, lr:8.95e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.212, tt:3585.426\n",
      "Ep:87, loss:0.00005, loss_test:0.07948, lr:8.86e-03, fs:0.78453 (r=0.717,p=0.866),  time:41.165, tt:3622.489\n",
      "Ep:88, loss:0.00005, loss_test:0.07984, lr:8.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.118, tt:3659.537\n",
      "Ep:89, loss:0.00005, loss_test:0.07921, lr:8.69e-03, fs:0.80645 (r=0.758,p=0.862),  time:41.138, tt:3702.390\n",
      "Ep:90, loss:0.00005, loss_test:0.08237, lr:8.60e-03, fs:0.78212 (r=0.707,p=0.875),  time:41.145, tt:3744.222\n",
      "Ep:91, loss:0.00005, loss_test:0.07864, lr:8.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:41.163, tt:3786.984\n",
      "Ep:92, loss:0.00004, loss_test:0.08285, lr:8.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:41.209, tt:3832.480\n",
      "Ep:93, loss:0.00004, loss_test:0.07735, lr:8.35e-03, fs:0.82353 (r=0.778,p=0.875),  time:41.215, tt:3874.256\n",
      "Ep:94, loss:0.00004, loss_test:0.08474, lr:8.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:41.224, tt:3916.327\n",
      "Ep:95, loss:0.00004, loss_test:0.07828, lr:8.18e-03, fs:0.80645 (r=0.758,p=0.862),  time:41.219, tt:3957.002\n",
      "Ep:96, loss:0.00004, loss_test:0.08412, lr:8.10e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.243, tt:4000.540\n",
      "Ep:97, loss:0.00004, loss_test:0.07859, lr:8.02e-03, fs:0.78022 (r=0.717,p=0.855),  time:41.268, tt:4044.250\n",
      "Ep:98, loss:0.00004, loss_test:0.08270, lr:7.94e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.281, tt:4086.849\n",
      "Ep:99, loss:0.00004, loss_test:0.07822, lr:7.86e-03, fs:0.80000 (r=0.747,p=0.860),  time:41.292, tt:4129.228\n",
      "Ep:100, loss:0.00004, loss_test:0.08367, lr:7.78e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.312, tt:4172.515\n",
      "Ep:101, loss:0.00004, loss_test:0.07815, lr:7.70e-03, fs:0.80645 (r=0.758,p=0.862),  time:41.315, tt:4214.119\n",
      "Ep:102, loss:0.00004, loss_test:0.08246, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.323, tt:4256.270\n",
      "Ep:103, loss:0.00004, loss_test:0.07772, lr:7.55e-03, fs:0.81081 (r=0.758,p=0.872),  time:41.317, tt:4296.953\n",
      "Ep:104, loss:0.00004, loss_test:0.08059, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.348, tt:4341.566\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00004, loss_test:0.07753, lr:7.47e-03, fs:0.79558 (r=0.727,p=0.878),  time:41.356, tt:4383.742\n",
      "Ep:106, loss:0.00004, loss_test:0.08144, lr:7.47e-03, fs:0.81522 (r=0.758,p=0.882),  time:41.356, tt:4425.051\n",
      "Ep:107, loss:0.00004, loss_test:0.07874, lr:7.47e-03, fs:0.82609 (r=0.768,p=0.894),  time:41.369, tt:4467.850\n",
      "Ep:108, loss:0.00004, loss_test:0.08171, lr:7.47e-03, fs:0.78889 (r=0.717,p=0.877),  time:41.394, tt:4511.974\n",
      "Ep:109, loss:0.00004, loss_test:0.07724, lr:7.47e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.419, tt:4556.124\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00003, loss_test:0.08080, lr:7.47e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.449, tt:4600.816\n",
      "Ep:111, loss:0.00003, loss_test:0.07962, lr:7.47e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.469, tt:4644.556\n",
      "Ep:112, loss:0.00003, loss_test:0.07918, lr:7.47e-03, fs:0.81967 (r=0.758,p=0.893),  time:41.489, tt:4688.272\n",
      "Ep:113, loss:0.00003, loss_test:0.08098, lr:7.47e-03, fs:0.80226 (r=0.717,p=0.910),  time:41.506, tt:4731.699\n",
      "Ep:114, loss:0.00003, loss_test:0.07717, lr:7.47e-03, fs:0.84492 (r=0.798,p=0.898),  time:41.503, tt:4772.851\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00003, loss_test:0.08012, lr:7.47e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.507, tt:4814.838\n",
      "Ep:116, loss:0.00003, loss_test:0.07930, lr:7.47e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.514, tt:4857.094\n",
      "Ep:117, loss:0.00003, loss_test:0.07793, lr:7.47e-03, fs:0.82162 (r=0.768,p=0.884),  time:41.513, tt:4898.585\n",
      "Ep:118, loss:0.00003, loss_test:0.08051, lr:7.47e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.561, tt:4945.753\n",
      "Ep:119, loss:0.00003, loss_test:0.07718, lr:7.47e-03, fs:0.81522 (r=0.758,p=0.882),  time:41.571, tt:4988.499\n",
      "Ep:120, loss:0.00003, loss_test:0.07999, lr:7.47e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.590, tt:5032.430\n",
      "Ep:121, loss:0.00003, loss_test:0.08025, lr:7.47e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.598, tt:5074.942\n",
      "Ep:122, loss:0.00003, loss_test:0.07715, lr:7.47e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.602, tt:5117.020\n",
      "Ep:123, loss:0.00003, loss_test:0.08089, lr:7.47e-03, fs:0.82486 (r=0.737,p=0.936),  time:41.604, tt:5158.868\n",
      "Ep:124, loss:0.00003, loss_test:0.07730, lr:7.47e-03, fs:0.81967 (r=0.758,p=0.893),  time:41.606, tt:5200.691\n",
      "Ep:125, loss:0.00003, loss_test:0.07963, lr:7.47e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.613, tt:5243.265\n",
      "Ep:126, loss:0.00003, loss_test:0.07846, lr:7.40e-03, fs:0.80874 (r=0.747,p=0.881),  time:41.613, tt:5284.842\n",
      "Ep:127, loss:0.00003, loss_test:0.07746, lr:7.32e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.609, tt:5325.960\n",
      "Ep:128, loss:0.00003, loss_test:0.08022, lr:7.25e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.615, tt:5368.348\n",
      "Ep:129, loss:0.00003, loss_test:0.07745, lr:7.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.624, tt:5411.108\n",
      "Ep:130, loss:0.00003, loss_test:0.08013, lr:7.11e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.652, tt:5456.465\n",
      "Ep:131, loss:0.00003, loss_test:0.07651, lr:7.03e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.655, tt:5498.397\n",
      "Ep:132, loss:0.00003, loss_test:0.07942, lr:6.96e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.671, tt:5542.182\n",
      "Ep:133, loss:0.00003, loss_test:0.07838, lr:6.89e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.667, tt:5583.445\n",
      "Ep:134, loss:0.00003, loss_test:0.07876, lr:6.83e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.692, tt:5628.408\n",
      "Ep:135, loss:0.00002, loss_test:0.07753, lr:6.76e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.700, tt:5671.205\n",
      "Ep:136, loss:0.00002, loss_test:0.07896, lr:6.69e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.716, tt:5715.036\n",
      "Ep:137, loss:0.00002, loss_test:0.07706, lr:6.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.715, tt:5756.675\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00002, loss_test:0.07968, lr:6.62e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.735, tt:5801.220\n",
      "Ep:139, loss:0.00002, loss_test:0.07745, lr:6.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.747, tt:5844.642\n",
      "Ep:140, loss:0.00002, loss_test:0.07738, lr:6.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.760, tt:5888.090\n",
      "Ep:141, loss:0.00002, loss_test:0.08008, lr:6.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.764, tt:5930.438\n",
      "Ep:142, loss:0.00002, loss_test:0.07728, lr:6.62e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.776, tt:5974.039\n",
      "Ep:143, loss:0.00002, loss_test:0.08016, lr:6.62e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.783, tt:6016.774\n",
      "Ep:144, loss:0.00002, loss_test:0.07739, lr:6.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.788, tt:6059.310\n",
      "Ep:145, loss:0.00002, loss_test:0.07899, lr:6.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.797, tt:6102.426\n",
      "Ep:146, loss:0.00002, loss_test:0.07726, lr:6.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.798, tt:6144.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00002, loss_test:0.08010, lr:6.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.811, tt:6188.072\n",
      "Ep:148, loss:0.00002, loss_test:0.07724, lr:6.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.831, tt:6232.859\n",
      "Ep:149, loss:0.00002, loss_test:0.07998, lr:6.56e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.835, tt:6275.234\n",
      "Ep:150, loss:0.00002, loss_test:0.07667, lr:6.49e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.839, tt:6317.762\n",
      "Ep:151, loss:0.00002, loss_test:0.08015, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.838, tt:6359.383\n",
      "Ep:152, loss:0.00002, loss_test:0.07825, lr:6.36e-03, fs:0.81111 (r=0.737,p=0.901),  time:41.826, tt:6399.419\n",
      "Ep:153, loss:0.00002, loss_test:0.07856, lr:6.30e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.819, tt:6440.098\n",
      "Ep:154, loss:0.00002, loss_test:0.07886, lr:6.24e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.832, tt:6483.903\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00029, loss_test:0.14575, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.399, tt:16.399\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14531, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.030, tt:34.059\n",
      "Ep:2, loss:0.00028, loss_test:0.14459, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.052, tt:54.156\n",
      "Ep:3, loss:0.00028, loss_test:0.14354, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:18.055, tt:72.221\n",
      "Ep:4, loss:0.00028, loss_test:0.14196, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:17.718, tt:88.590\n",
      "Ep:5, loss:0.00028, loss_test:0.13960, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:17.623, tt:105.737\n",
      "Ep:6, loss:0.00027, loss_test:0.13600, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:17.405, tt:121.834\n",
      "Ep:7, loss:0.00026, loss_test:0.13008, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:17.522, tt:140.178\n",
      "Ep:8, loss:0.00025, loss_test:0.12192, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:17.450, tt:157.052\n",
      "Ep:9, loss:0.00024, loss_test:0.11491, lr:1.00e-02, fs:0.64253 (r=0.717,p=0.582),  time:17.453, tt:174.534\n",
      "Ep:10, loss:0.00023, loss_test:0.11150, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:17.464, tt:192.109\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10978, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:17.476, tt:209.710\n",
      "Ep:12, loss:0.00022, loss_test:0.10866, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:17.613, tt:228.970\n",
      "Ep:13, loss:0.00021, loss_test:0.10339, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:17.692, tt:247.690\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09872, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.665, tt:264.969\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09695, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:17.614, tt:281.830\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09542, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:17.422, tt:296.171\n",
      "Ep:17, loss:0.00018, loss_test:0.09224, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:17.251, tt:310.527\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09062, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:17.305, tt:328.794\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08909, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:17.315, tt:346.308\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08699, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:17.168, tt:360.518\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08517, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:17.037, tt:374.824\n",
      "Ep:22, loss:0.00016, loss_test:0.08448, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:17.005, tt:391.108\n",
      "Ep:23, loss:0.00015, loss_test:0.08376, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:17.047, tt:409.124\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08203, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:17.075, tt:426.869\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08091, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:17.151, tt:445.931\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08043, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:17.199, tt:464.376\n",
      "Ep:27, loss:0.00014, loss_test:0.07932, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:17.259, tt:483.251\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07828, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:17.258, tt:500.476\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07705, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:17.243, tt:517.294\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.07671, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:17.241, tt:534.467\n",
      "Ep:31, loss:0.00012, loss_test:0.07592, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:17.226, tt:551.229\n",
      "Ep:32, loss:0.00012, loss_test:0.07531, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:17.206, tt:567.809\n",
      "Ep:33, loss:0.00012, loss_test:0.07469, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:17.199, tt:584.774\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.07415, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:17.179, tt:601.248\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07352, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:17.190, tt:618.824\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07300, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:17.159, tt:634.868\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07253, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:17.171, tt:652.501\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.07258, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:17.195, tt:670.614\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07229, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:17.176, tt:687.052\n",
      "Ep:40, loss:0.00010, loss_test:0.07090, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:17.143, tt:702.868\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.07143, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:17.154, tt:720.447\n",
      "Ep:42, loss:0.00009, loss_test:0.07019, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:17.136, tt:736.862\n",
      "Ep:43, loss:0.00009, loss_test:0.07002, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:17.135, tt:753.937\n",
      "Ep:44, loss:0.00009, loss_test:0.06969, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:17.128, tt:770.781\n",
      "Ep:45, loss:0.00009, loss_test:0.07049, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:17.142, tt:788.521\n",
      "Ep:46, loss:0.00009, loss_test:0.06870, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:17.141, tt:805.636\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.06971, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:17.156, tt:823.464\n",
      "Ep:48, loss:0.00008, loss_test:0.06807, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:17.149, tt:840.283\n",
      "Ep:49, loss:0.00008, loss_test:0.06851, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.136, tt:856.785\n",
      "Ep:50, loss:0.00008, loss_test:0.06704, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:17.121, tt:873.169\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00007, loss_test:0.06811, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:17.128, tt:890.682\n",
      "Ep:52, loss:0.00007, loss_test:0.06691, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:17.127, tt:907.724\n",
      "Ep:53, loss:0.00007, loss_test:0.06698, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.107, tt:923.786\n",
      "Ep:54, loss:0.00007, loss_test:0.06638, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:17.113, tt:941.206\n",
      "Ep:55, loss:0.00007, loss_test:0.06724, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:17.120, tt:958.701\n",
      "Ep:56, loss:0.00007, loss_test:0.06659, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:17.129, tt:976.373\n",
      "Ep:57, loss:0.00006, loss_test:0.06580, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:17.131, tt:993.606\n",
      "Ep:58, loss:0.00006, loss_test:0.06759, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:17.128, tt:1010.554\n",
      "Ep:59, loss:0.00006, loss_test:0.06501, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:17.135, tt:1028.075\n",
      "Ep:60, loss:0.00006, loss_test:0.06565, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.141, tt:1045.594\n",
      "Ep:61, loss:0.00006, loss_test:0.06392, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:17.134, tt:1062.310\n",
      "Ep:62, loss:0.00006, loss_test:0.06701, lr:9.90e-03, fs:0.84848 (r=0.848,p=0.848),  time:17.152, tt:1080.550\n",
      "Ep:63, loss:0.00006, loss_test:0.06447, lr:9.80e-03, fs:0.86957 (r=0.909,p=0.833),  time:17.174, tt:1099.158\n",
      "Ep:64, loss:0.00005, loss_test:0.06544, lr:9.70e-03, fs:0.84264 (r=0.838,p=0.847),  time:17.156, tt:1115.146\n",
      "Ep:65, loss:0.00005, loss_test:0.06541, lr:9.61e-03, fs:0.84878 (r=0.879,p=0.821),  time:17.164, tt:1132.849\n",
      "Ep:66, loss:0.00005, loss_test:0.06332, lr:9.51e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.144, tt:1148.668\n",
      "Ep:67, loss:0.00005, loss_test:0.06570, lr:9.41e-03, fs:0.85149 (r=0.869,p=0.835),  time:17.146, tt:1165.957\n",
      "Ep:68, loss:0.00005, loss_test:0.06218, lr:9.32e-03, fs:0.86869 (r=0.869,p=0.869),  time:17.170, tt:1184.737\n",
      "Ep:69, loss:0.00005, loss_test:0.06572, lr:9.23e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.161, tt:1201.304\n",
      "Ep:70, loss:0.00005, loss_test:0.06337, lr:9.14e-03, fs:0.84848 (r=0.848,p=0.848),  time:17.163, tt:1218.579\n",
      "Ep:71, loss:0.00005, loss_test:0.06312, lr:9.04e-03, fs:0.84848 (r=0.848,p=0.848),  time:17.154, tt:1235.122\n",
      "Ep:72, loss:0.00004, loss_test:0.06409, lr:8.95e-03, fs:0.84000 (r=0.848,p=0.832),  time:17.144, tt:1251.478\n",
      "Ep:73, loss:0.00004, loss_test:0.06164, lr:8.86e-03, fs:0.86869 (r=0.869,p=0.869),  time:17.148, tt:1268.949\n",
      "Ep:74, loss:0.00004, loss_test:0.06290, lr:8.78e-03, fs:0.86432 (r=0.869,p=0.860),  time:17.160, tt:1286.980\n",
      "Ep:75, loss:0.00004, loss_test:0.06143, lr:8.69e-03, fs:0.85714 (r=0.848,p=0.866),  time:17.163, tt:1304.373\n",
      "Ep:76, loss:0.00004, loss_test:0.06310, lr:8.60e-03, fs:0.86294 (r=0.859,p=0.867),  time:17.160, tt:1321.355\n",
      "Ep:77, loss:0.00004, loss_test:0.06281, lr:8.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.151, tt:1337.745\n",
      "Ep:78, loss:0.00004, loss_test:0.06164, lr:8.43e-03, fs:0.85279 (r=0.848,p=0.857),  time:17.139, tt:1353.986\n",
      "Ep:79, loss:0.00004, loss_test:0.06225, lr:8.35e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.131, tt:1370.502\n",
      "Ep:80, loss:0.00004, loss_test:0.06092, lr:8.26e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.135, tt:1387.895\n",
      "Ep:81, loss:0.00004, loss_test:0.06194, lr:8.18e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.115, tt:1403.406\n",
      "Ep:82, loss:0.00004, loss_test:0.06099, lr:8.10e-03, fs:0.86010 (r=0.838,p=0.883),  time:17.114, tt:1420.487\n",
      "Ep:83, loss:0.00004, loss_test:0.06080, lr:8.02e-03, fs:0.85567 (r=0.838,p=0.874),  time:17.111, tt:1437.310\n",
      "Ep:84, loss:0.00004, loss_test:0.06193, lr:7.94e-03, fs:0.84974 (r=0.828,p=0.872),  time:17.107, tt:1454.075\n",
      "Ep:85, loss:0.00003, loss_test:0.06070, lr:7.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.097, tt:1470.369\n",
      "Ep:86, loss:0.00003, loss_test:0.05994, lr:7.78e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.085, tt:1486.353\n",
      "Ep:87, loss:0.00003, loss_test:0.06193, lr:7.70e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.099, tt:1504.688\n",
      "Ep:88, loss:0.00003, loss_test:0.05869, lr:7.62e-03, fs:0.86869 (r=0.869,p=0.869),  time:17.094, tt:1521.367\n",
      "Ep:89, loss:0.00003, loss_test:0.06159, lr:7.55e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.095, tt:1538.529\n",
      "Ep:90, loss:0.00003, loss_test:0.05976, lr:7.47e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.094, tt:1555.525\n",
      "Ep:91, loss:0.00003, loss_test:0.06068, lr:7.40e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.084, tt:1571.696\n",
      "Ep:92, loss:0.00003, loss_test:0.05946, lr:7.32e-03, fs:0.87755 (r=0.869,p=0.887),  time:17.072, tt:1587.686\n",
      "Ep:93, loss:0.00003, loss_test:0.06166, lr:7.25e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.064, tt:1603.975\n",
      "Ep:94, loss:0.00003, loss_test:0.05942, lr:7.18e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.064, tt:1621.079\n",
      "Ep:95, loss:0.00003, loss_test:0.06191, lr:7.11e-03, fs:0.84656 (r=0.808,p=0.889),  time:17.082, tt:1639.829\n",
      "Ep:96, loss:0.00003, loss_test:0.06011, lr:7.03e-03, fs:0.86458 (r=0.838,p=0.892),  time:17.086, tt:1657.379\n",
      "Ep:97, loss:0.00003, loss_test:0.06233, lr:6.96e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.081, tt:1673.976\n",
      "Ep:98, loss:0.00003, loss_test:0.06144, lr:6.89e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.074, tt:1690.359\n",
      "Ep:99, loss:0.00003, loss_test:0.05965, lr:6.83e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.080, tt:1707.981\n",
      "Ep:100, loss:0.00003, loss_test:0.06203, lr:6.76e-03, fs:0.84043 (r=0.798,p=0.888),  time:17.085, tt:1725.556\n",
      "Ep:101, loss:0.00003, loss_test:0.05952, lr:6.69e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.084, tt:1742.539\n",
      "Ep:102, loss:0.00003, loss_test:0.06143, lr:6.62e-03, fs:0.84043 (r=0.798,p=0.888),  time:17.093, tt:1760.597\n",
      "Ep:103, loss:0.00003, loss_test:0.05943, lr:6.56e-03, fs:0.87234 (r=0.828,p=0.921),  time:17.088, tt:1777.129\n",
      "Ep:104, loss:0.00003, loss_test:0.06025, lr:6.49e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.084, tt:1793.845\n",
      "Ep:105, loss:0.00003, loss_test:0.05977, lr:6.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.082, tt:1810.742\n",
      "Ep:106, loss:0.00003, loss_test:0.05972, lr:6.36e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.081, tt:1827.643\n",
      "Ep:107, loss:0.00003, loss_test:0.05907, lr:6.30e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.082, tt:1844.883\n",
      "Ep:108, loss:0.00002, loss_test:0.06004, lr:6.24e-03, fs:0.87097 (r=0.818,p=0.931),  time:17.073, tt:1860.986\n",
      "Ep:109, loss:0.00002, loss_test:0.05993, lr:6.17e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.076, tt:1878.326\n",
      "Ep:110, loss:0.00002, loss_test:0.05884, lr:6.11e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.080, tt:1895.875\n",
      "Ep:111, loss:0.00002, loss_test:0.06179, lr:6.05e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.082, tt:1913.173\n",
      "Ep:112, loss:0.00002, loss_test:0.06009, lr:5.99e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.078, tt:1929.820\n",
      "Ep:113, loss:0.00002, loss_test:0.05960, lr:5.93e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.071, tt:1946.091\n",
      "Ep:114, loss:0.00002, loss_test:0.06069, lr:5.87e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.062, tt:1962.107\n",
      "Ep:115, loss:0.00002, loss_test:0.05850, lr:5.81e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.062, tt:1979.154\n",
      "Ep:116, loss:0.00002, loss_test:0.06009, lr:5.75e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.064, tt:1996.476\n",
      "Ep:117, loss:0.00002, loss_test:0.06067, lr:5.70e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.058, tt:2012.871\n",
      "Ep:118, loss:0.00002, loss_test:0.05829, lr:5.64e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.050, tt:2028.987\n",
      "Ep:119, loss:0.00002, loss_test:0.06110, lr:5.58e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.050, tt:2045.950\n",
      "Ep:120, loss:0.00002, loss_test:0.06017, lr:5.53e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.050, tt:2063.012\n",
      "Ep:121, loss:0.00002, loss_test:0.05928, lr:5.47e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.055, tt:2080.695\n",
      "Ep:122, loss:0.00002, loss_test:0.05938, lr:5.42e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.052, tt:2097.365\n",
      "Ep:123, loss:0.00002, loss_test:0.05944, lr:5.36e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.048, tt:2113.950\n",
      "Ep:124, loss:0.00002, loss_test:0.05941, lr:5.31e-03, fs:0.84656 (r=0.808,p=0.889),  time:17.047, tt:2130.905\n",
      "Ep:125, loss:0.00002, loss_test:0.05883, lr:5.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.045, tt:2147.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00002, loss_test:0.05919, lr:5.20e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.050, tt:2165.309\n",
      "Ep:127, loss:0.00002, loss_test:0.05909, lr:5.15e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.055, tt:2183.084\n",
      "Ep:128, loss:0.00002, loss_test:0.05931, lr:5.10e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.049, tt:2199.306\n",
      "Ep:129, loss:0.00002, loss_test:0.05943, lr:5.05e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.042, tt:2215.495\n",
      "Ep:130, loss:0.00002, loss_test:0.05868, lr:5.00e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.040, tt:2232.299\n",
      "Ep:131, loss:0.00002, loss_test:0.05942, lr:4.95e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.034, tt:2248.520\n",
      "Ep:132, loss:0.00002, loss_test:0.05951, lr:4.90e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.025, tt:2264.259\n",
      "Ep:133, loss:0.00002, loss_test:0.05881, lr:4.85e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.026, tt:2281.505\n",
      "Ep:134, loss:0.00002, loss_test:0.05910, lr:4.80e-03, fs:0.84656 (r=0.808,p=0.889),  time:17.023, tt:2298.090\n",
      "Ep:135, loss:0.00002, loss_test:0.06016, lr:4.75e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.020, tt:2314.760\n",
      "Ep:136, loss:0.00002, loss_test:0.05869, lr:4.71e-03, fs:0.86911 (r=0.838,p=0.902),  time:17.023, tt:2332.156\n",
      "Ep:137, loss:0.00002, loss_test:0.05994, lr:4.66e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.026, tt:2349.546\n",
      "Ep:138, loss:0.00002, loss_test:0.06071, lr:4.61e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.022, tt:2366.118\n",
      "Ep:139, loss:0.00002, loss_test:0.05862, lr:4.57e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.022, tt:2383.033\n",
      "Ep:140, loss:0.00002, loss_test:0.06024, lr:4.52e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.034, tt:2401.760\n",
      "Ep:141, loss:0.00002, loss_test:0.05918, lr:4.48e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.029, tt:2418.078\n",
      "Ep:142, loss:0.00002, loss_test:0.05944, lr:4.43e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.025, tt:2434.634\n",
      "Ep:143, loss:0.00002, loss_test:0.05939, lr:4.39e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.021, tt:2451.041\n",
      "Ep:144, loss:0.00002, loss_test:0.05923, lr:4.34e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.015, tt:2467.109\n",
      "Ep:145, loss:0.00002, loss_test:0.05971, lr:4.30e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.017, tt:2484.445\n",
      "Ep:146, loss:0.00002, loss_test:0.05923, lr:4.26e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.027, tt:2502.958\n",
      "Ep:147, loss:0.00002, loss_test:0.05922, lr:4.21e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.046, tt:2522.744\n",
      "Ep:148, loss:0.00002, loss_test:0.05936, lr:4.17e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.054, tt:2540.998\n",
      "Ep:149, loss:0.00002, loss_test:0.05945, lr:4.13e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.046, tt:2556.910\n",
      "Ep:150, loss:0.00002, loss_test:0.05990, lr:4.09e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.033, tt:2572.034\n",
      "Ep:151, loss:0.00002, loss_test:0.05903, lr:4.05e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.017, tt:2586.594\n",
      "Ep:152, loss:0.00002, loss_test:0.05967, lr:4.01e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.005, tt:2601.705\n",
      "Ep:153, loss:0.00002, loss_test:0.06020, lr:3.97e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.010, tt:2619.465\n",
      "Ep:154, loss:0.00002, loss_test:0.05837, lr:3.93e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.013, tt:2637.037\n",
      "Ep:155, loss:0.00002, loss_test:0.05996, lr:3.89e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.006, tt:2652.968\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14170, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.318, tt:18.318\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14076, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.961, tt:37.922\n",
      "Ep:2, loss:0.00028, loss_test:0.13915, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:19.394, tt:58.182\n",
      "Ep:3, loss:0.00027, loss_test:0.13668, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:19.771, tt:79.084\n",
      "Ep:4, loss:0.00027, loss_test:0.13312, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:19.689, tt:98.445\n",
      "Ep:5, loss:0.00026, loss_test:0.12820, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:19.844, tt:119.062\n",
      "Ep:6, loss:0.00026, loss_test:0.12385, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:19.735, tt:138.142\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12093, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:19.624, tt:156.990\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.11843, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:19.523, tt:175.703\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11624, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:19.578, tt:195.779\n",
      "Ep:10, loss:0.00024, loss_test:0.11531, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:19.562, tt:215.182\n",
      "Ep:11, loss:0.00023, loss_test:0.11390, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:19.594, tt:235.125\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11137, lr:1.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:19.662, tt:255.604\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10888, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:19.730, tt:276.218\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10713, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:19.809, tt:297.139\n",
      "Ep:15, loss:0.00020, loss_test:0.10547, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:19.781, tt:316.499\n",
      "Ep:16, loss:0.00020, loss_test:0.10268, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:19.744, tt:335.642\n",
      "Ep:17, loss:0.00019, loss_test:0.10026, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:19.785, tt:356.135\n",
      "Ep:18, loss:0.00018, loss_test:0.09850, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:19.805, tt:376.289\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09743, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:19.824, tt:396.483\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09531, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:19.925, tt:418.432\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.09418, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:19.964, tt:439.214\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09329, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:20.008, tt:460.179\n",
      "Ep:23, loss:0.00016, loss_test:0.09129, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:20.027, tt:480.642\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08980, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:20.035, tt:500.886\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08841, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:20.051, tt:521.330\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08710, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:20.034, tt:540.931\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08612, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:20.077, tt:562.147\n",
      "Ep:28, loss:0.00014, loss_test:0.08432, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:20.057, tt:581.658\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08296, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:20.041, tt:601.226\n",
      "Ep:30, loss:0.00013, loss_test:0.08235, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:20.034, tt:621.045\n",
      "Ep:31, loss:0.00013, loss_test:0.08063, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:20.027, tt:640.855\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00012, loss_test:0.08024, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:20.088, tt:662.909\n",
      "Ep:33, loss:0.00012, loss_test:0.07896, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:20.071, tt:682.413\n",
      "Ep:34, loss:0.00012, loss_test:0.07854, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:20.114, tt:703.996\n",
      "Ep:35, loss:0.00011, loss_test:0.07799, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:20.118, tt:724.255\n",
      "Ep:36, loss:0.00011, loss_test:0.07672, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:20.081, tt:742.993\n",
      "Ep:37, loss:0.00011, loss_test:0.07601, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:20.095, tt:763.620\n",
      "Ep:38, loss:0.00011, loss_test:0.07610, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.072, tt:782.826\n",
      "Ep:39, loss:0.00010, loss_test:0.07507, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:20.055, tt:802.203\n",
      "Ep:40, loss:0.00010, loss_test:0.07506, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:20.083, tt:823.395\n",
      "Ep:41, loss:0.00010, loss_test:0.07465, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:20.093, tt:843.911\n",
      "Ep:42, loss:0.00009, loss_test:0.07441, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:20.063, tt:862.714\n",
      "Ep:43, loss:0.00009, loss_test:0.07472, lr:9.90e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.954, tt:877.998\n",
      "Ep:44, loss:0.00009, loss_test:0.07473, lr:9.80e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.892, tt:895.117\n",
      "Ep:45, loss:0.00009, loss_test:0.07447, lr:9.70e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.904, tt:915.569\n",
      "Ep:46, loss:0.00009, loss_test:0.07417, lr:9.61e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.820, tt:931.560\n",
      "Ep:47, loss:0.00008, loss_test:0.07431, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:19.737, tt:947.353\n",
      "Ep:48, loss:0.00008, loss_test:0.07395, lr:9.41e-03, fs:0.77720 (r=0.758,p=0.798),  time:19.703, tt:965.432\n",
      "Ep:49, loss:0.00008, loss_test:0.07374, lr:9.32e-03, fs:0.79798 (r=0.798,p=0.798),  time:19.690, tt:984.482\n",
      "Ep:50, loss:0.00008, loss_test:0.07379, lr:9.23e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.703, tt:1004.849\n",
      "Ep:51, loss:0.00008, loss_test:0.07347, lr:9.14e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.730, tt:1025.947\n",
      "Ep:52, loss:0.00007, loss_test:0.07318, lr:9.04e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.730, tt:1045.706\n",
      "Ep:53, loss:0.00007, loss_test:0.07281, lr:8.95e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.716, tt:1064.649\n",
      "Ep:54, loss:0.00007, loss_test:0.07350, lr:8.86e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.710, tt:1084.032\n",
      "Ep:55, loss:0.00007, loss_test:0.07291, lr:8.78e-03, fs:0.78125 (r=0.758,p=0.806),  time:19.735, tt:1105.162\n",
      "Ep:56, loss:0.00007, loss_test:0.07269, lr:8.69e-03, fs:0.78756 (r=0.768,p=0.809),  time:19.733, tt:1124.789\n",
      "Ep:57, loss:0.00007, loss_test:0.07320, lr:8.60e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.760, tt:1146.080\n",
      "Ep:58, loss:0.00006, loss_test:0.07185, lr:8.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:19.772, tt:1166.553\n",
      "Ep:59, loss:0.00006, loss_test:0.07345, lr:8.43e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.775, tt:1186.529\n",
      "Ep:60, loss:0.00006, loss_test:0.07194, lr:8.35e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.773, tt:1206.137\n",
      "Ep:61, loss:0.00006, loss_test:0.07259, lr:8.26e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.775, tt:1226.052\n",
      "Ep:62, loss:0.00006, loss_test:0.07269, lr:8.18e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.771, tt:1245.543\n",
      "Ep:63, loss:0.00006, loss_test:0.07172, lr:8.10e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.775, tt:1265.622\n",
      "Ep:64, loss:0.00006, loss_test:0.07227, lr:8.02e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.772, tt:1285.195\n",
      "Ep:65, loss:0.00006, loss_test:0.07181, lr:7.94e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.811, tt:1307.543\n",
      "Ep:66, loss:0.00006, loss_test:0.07202, lr:7.86e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.840, tt:1329.309\n",
      "Ep:67, loss:0.00005, loss_test:0.07162, lr:7.78e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.861, tt:1350.577\n",
      "Ep:68, loss:0.00005, loss_test:0.07089, lr:7.70e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.872, tt:1371.192\n",
      "Ep:69, loss:0.00005, loss_test:0.07208, lr:7.62e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.874, tt:1391.174\n",
      "Ep:70, loss:0.00005, loss_test:0.07090, lr:7.55e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.880, tt:1411.465\n",
      "Ep:71, loss:0.00005, loss_test:0.07070, lr:7.47e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.872, tt:1430.817\n",
      "Ep:72, loss:0.00005, loss_test:0.07229, lr:7.40e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.883, tt:1451.431\n",
      "Ep:73, loss:0.00005, loss_test:0.07018, lr:7.32e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.881, tt:1471.207\n",
      "Ep:74, loss:0.00005, loss_test:0.07017, lr:7.25e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.879, tt:1490.947\n",
      "Ep:75, loss:0.00005, loss_test:0.07088, lr:7.18e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.864, tt:1509.658\n",
      "Ep:76, loss:0.00005, loss_test:0.07053, lr:7.11e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.868, tt:1529.850\n",
      "Ep:77, loss:0.00005, loss_test:0.07043, lr:7.03e-03, fs:0.76440 (r=0.737,p=0.793),  time:19.872, tt:1550.033\n",
      "Ep:78, loss:0.00005, loss_test:0.07005, lr:6.96e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.883, tt:1570.722\n",
      "Ep:79, loss:0.00005, loss_test:0.07065, lr:6.89e-03, fs:0.75532 (r=0.717,p=0.798),  time:19.880, tt:1590.429\n",
      "Ep:80, loss:0.00005, loss_test:0.07056, lr:6.83e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.872, tt:1609.649\n",
      "Ep:81, loss:0.00004, loss_test:0.06960, lr:6.76e-03, fs:0.77005 (r=0.727,p=0.818),  time:19.873, tt:1629.619\n",
      "Ep:82, loss:0.00004, loss_test:0.07026, lr:6.69e-03, fs:0.75393 (r=0.727,p=0.783),  time:19.882, tt:1650.217\n",
      "Ep:83, loss:0.00004, loss_test:0.07015, lr:6.62e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.905, tt:1672.037\n",
      "Ep:84, loss:0.00004, loss_test:0.06968, lr:6.56e-03, fs:0.76596 (r=0.727,p=0.809),  time:19.918, tt:1692.996\n",
      "Ep:85, loss:0.00004, loss_test:0.07006, lr:6.49e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.926, tt:1713.616\n",
      "Ep:86, loss:0.00004, loss_test:0.06954, lr:6.43e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.911, tt:1732.264\n",
      "Ep:87, loss:0.00004, loss_test:0.07004, lr:6.36e-03, fs:0.77005 (r=0.727,p=0.818),  time:19.928, tt:1753.626\n",
      "Ep:88, loss:0.00004, loss_test:0.06960, lr:6.30e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.937, tt:1774.382\n",
      "Ep:89, loss:0.00004, loss_test:0.06949, lr:6.24e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.945, tt:1795.042\n",
      "Ep:90, loss:0.00004, loss_test:0.06990, lr:6.17e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.923, tt:1813.029\n",
      "Ep:91, loss:0.00004, loss_test:0.06977, lr:6.11e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.918, tt:1832.425\n",
      "Ep:92, loss:0.00004, loss_test:0.06918, lr:6.05e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.907, tt:1851.388\n",
      "Ep:93, loss:0.00004, loss_test:0.06922, lr:5.99e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.925, tt:1872.947\n",
      "Ep:94, loss:0.00004, loss_test:0.06948, lr:5.93e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.928, tt:1893.175\n",
      "Ep:95, loss:0.00004, loss_test:0.06914, lr:5.87e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.916, tt:1911.981\n",
      "Ep:96, loss:0.00004, loss_test:0.06962, lr:5.81e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.907, tt:1931.024\n",
      "Ep:97, loss:0.00004, loss_test:0.06928, lr:5.75e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.903, tt:1950.513\n",
      "Ep:98, loss:0.00004, loss_test:0.06893, lr:5.70e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.919, tt:1972.017\n",
      "Ep:99, loss:0.00004, loss_test:0.06979, lr:5.64e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.936, tt:1993.580\n",
      "Ep:100, loss:0.00004, loss_test:0.06894, lr:5.58e-03, fs:0.76440 (r=0.737,p=0.793),  time:19.933, tt:2013.238\n",
      "Ep:101, loss:0.00004, loss_test:0.06911, lr:5.53e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.931, tt:2032.951\n",
      "Ep:102, loss:0.00004, loss_test:0.06902, lr:5.47e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.918, tt:2051.537\n",
      "Ep:103, loss:0.00004, loss_test:0.06883, lr:5.42e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.920, tt:2071.668\n",
      "Ep:104, loss:0.00004, loss_test:0.06912, lr:5.36e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.929, tt:2092.582\n",
      "Ep:105, loss:0.00003, loss_test:0.06942, lr:5.31e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.962, tt:2115.975\n",
      "Ep:106, loss:0.00003, loss_test:0.06893, lr:5.26e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.949, tt:2134.525\n",
      "Ep:107, loss:0.00003, loss_test:0.06924, lr:5.20e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.932, tt:2152.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00003, loss_test:0.06894, lr:5.15e-03, fs:0.77660 (r=0.737,p=0.820),  time:19.924, tt:2171.753\n",
      "Ep:109, loss:0.00003, loss_test:0.06944, lr:5.10e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.938, tt:2193.212\n",
      "Ep:110, loss:0.00003, loss_test:0.06893, lr:5.05e-03, fs:0.77660 (r=0.737,p=0.820),  time:19.959, tt:2215.408\n",
      "Ep:111, loss:0.00003, loss_test:0.06891, lr:5.00e-03, fs:0.77838 (r=0.727,p=0.837),  time:19.951, tt:2234.482\n",
      "Ep:112, loss:0.00003, loss_test:0.06919, lr:4.95e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.936, tt:2252.761\n",
      "Ep:113, loss:0.00003, loss_test:0.06928, lr:4.90e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.925, tt:2271.429\n",
      "Ep:114, loss:0.00003, loss_test:0.06866, lr:4.85e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.924, tt:2291.299\n",
      "Ep:115, loss:0.00003, loss_test:0.06908, lr:4.80e-03, fs:0.76757 (r=0.717,p=0.826),  time:19.928, tt:2311.663\n",
      "Ep:116, loss:0.00003, loss_test:0.06862, lr:4.75e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.926, tt:2331.382\n",
      "Ep:117, loss:0.00003, loss_test:0.06899, lr:4.71e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.912, tt:2349.589\n",
      "Ep:118, loss:0.00003, loss_test:0.06971, lr:4.66e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.913, tt:2369.680\n",
      "Ep:119, loss:0.00003, loss_test:0.06888, lr:4.61e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.926, tt:2391.135\n",
      "Ep:120, loss:0.00003, loss_test:0.06855, lr:4.57e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.921, tt:2410.389\n",
      "Ep:121, loss:0.00003, loss_test:0.06899, lr:4.52e-03, fs:0.76757 (r=0.717,p=0.826),  time:19.922, tt:2430.438\n",
      "Ep:122, loss:0.00003, loss_test:0.06915, lr:4.48e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.920, tt:2450.153\n",
      "Ep:123, loss:0.00003, loss_test:0.06861, lr:4.43e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.907, tt:2468.411\n",
      "Ep:124, loss:0.00003, loss_test:0.06932, lr:4.39e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.907, tt:2488.393\n",
      "Ep:125, loss:0.00003, loss_test:0.06913, lr:4.34e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.913, tt:2509.076\n",
      "Ep:126, loss:0.00003, loss_test:0.06888, lr:4.30e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.928, tt:2530.860\n",
      "Ep:127, loss:0.00003, loss_test:0.06903, lr:4.26e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.926, tt:2550.527\n",
      "Ep:128, loss:0.00003, loss_test:0.06885, lr:4.21e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.924, tt:2570.152\n",
      "Ep:129, loss:0.00003, loss_test:0.06859, lr:4.17e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.926, tt:2590.324\n",
      "Ep:130, loss:0.00003, loss_test:0.06906, lr:4.13e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.920, tt:2609.569\n",
      "Ep:131, loss:0.00003, loss_test:0.06949, lr:4.09e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.919, tt:2629.284\n",
      "Ep:132, loss:0.00003, loss_test:0.06869, lr:4.05e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.916, tt:2648.769\n",
      "Ep:133, loss:0.00003, loss_test:0.06900, lr:4.01e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.907, tt:2667.541\n",
      "Ep:134, loss:0.00003, loss_test:0.06931, lr:3.97e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.901, tt:2686.656\n",
      "Ep:135, loss:0.00003, loss_test:0.06908, lr:3.93e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.902, tt:2706.731\n",
      "Ep:136, loss:0.00003, loss_test:0.06863, lr:3.89e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.910, tt:2727.627\n",
      "Ep:137, loss:0.00003, loss_test:0.06901, lr:3.85e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.919, tt:2748.846\n",
      "Ep:138, loss:0.00003, loss_test:0.06948, lr:3.81e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.912, tt:2767.701\n",
      "Ep:139, loss:0.00003, loss_test:0.06861, lr:3.77e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.918, tt:2788.471\n",
      "Ep:140, loss:0.00003, loss_test:0.06908, lr:3.73e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.918, tt:2808.395\n",
      "Ep:141, loss:0.00003, loss_test:0.06972, lr:3.70e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.923, tt:2829.073\n",
      "Ep:142, loss:0.00003, loss_test:0.06901, lr:3.66e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.920, tt:2848.501\n",
      "Ep:143, loss:0.00003, loss_test:0.06892, lr:3.62e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.917, tt:2868.062\n",
      "Ep:144, loss:0.00003, loss_test:0.06980, lr:3.59e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.917, tt:2887.947\n",
      "Ep:145, loss:0.00003, loss_test:0.06927, lr:3.55e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.920, tt:2908.341\n",
      "Ep:146, loss:0.00003, loss_test:0.06890, lr:3.52e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.920, tt:2928.244\n",
      "Ep:147, loss:0.00003, loss_test:0.06955, lr:3.48e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.918, tt:2947.889\n",
      "Ep:148, loss:0.00003, loss_test:0.06963, lr:3.45e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.912, tt:2966.929\n",
      "Ep:149, loss:0.00003, loss_test:0.06899, lr:3.41e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.914, tt:2987.134\n",
      "Ep:150, loss:0.00003, loss_test:0.06928, lr:3.38e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.917, tt:3007.525\n",
      "Ep:151, loss:0.00003, loss_test:0.06977, lr:3.34e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.922, tt:3028.085\n",
      "Ep:152, loss:0.00003, loss_test:0.06892, lr:3.31e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.911, tt:3046.324\n",
      "Ep:153, loss:0.00003, loss_test:0.06897, lr:3.28e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.893, tt:3063.530\n",
      "Ep:154, loss:0.00003, loss_test:0.06968, lr:3.24e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.876, tt:3080.733\n",
      "Ep:155, loss:0.00003, loss_test:0.06965, lr:3.21e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.863, tt:3098.592\n",
      "Ep:156, loss:0.00003, loss_test:0.06862, lr:3.18e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.848, tt:3116.211\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14372, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.571, tt:53.571\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14188, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.751, tt:107.502\n",
      "Ep:2, loss:0.00027, loss_test:0.13839, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.755, tt:161.265\n",
      "Ep:3, loss:0.00026, loss_test:0.13219, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:53.804, tt:215.216\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12122, lr:1.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:53.603, tt:268.014\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11418, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:53.194, tt:319.164\n",
      "Ep:6, loss:0.00022, loss_test:0.11575, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:53.334, tt:373.338\n",
      "Ep:7, loss:0.00022, loss_test:0.11465, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:53.258, tt:426.062\n",
      "Ep:8, loss:0.00021, loss_test:0.11089, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:53.209, tt:478.877\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10802, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:53.164, tt:531.644\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10613, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:53.201, tt:585.214\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10471, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:53.175, tt:638.094\n",
      "Ep:12, loss:0.00019, loss_test:0.10242, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:52.976, tt:688.686\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10077, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:53.073, tt:743.019\n",
      "Ep:14, loss:0.00018, loss_test:0.09987, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:53.145, tt:797.182\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09651, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:53.094, tt:849.508\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00017, loss_test:0.09520, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:53.033, tt:901.566\n",
      "Ep:17, loss:0.00016, loss_test:0.09485, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:52.964, tt:953.353\n",
      "Ep:18, loss:0.00016, loss_test:0.09254, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:52.914, tt:1005.364\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.09164, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:52.818, tt:1056.356\n",
      "Ep:20, loss:0.00015, loss_test:0.09133, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:52.878, tt:1110.432\n",
      "Ep:21, loss:0.00014, loss_test:0.08951, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:53.021, tt:1166.463\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08931, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:53.095, tt:1221.176\n",
      "Ep:23, loss:0.00014, loss_test:0.08787, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:53.145, tt:1275.472\n",
      "Ep:24, loss:0.00013, loss_test:0.08679, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:53.131, tt:1328.280\n",
      "Ep:25, loss:0.00013, loss_test:0.08499, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:53.092, tt:1380.380\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08498, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:53.147, tt:1434.963\n",
      "Ep:27, loss:0.00012, loss_test:0.08292, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:53.126, tt:1487.539\n",
      "Ep:28, loss:0.00012, loss_test:0.08205, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:52.912, tt:1534.434\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08120, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:52.894, tt:1586.818\n",
      "Ep:30, loss:0.00011, loss_test:0.08007, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:52.850, tt:1638.362\n",
      "Ep:31, loss:0.00010, loss_test:0.08049, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:52.867, tt:1691.734\n",
      "Ep:32, loss:0.00010, loss_test:0.07846, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:52.844, tt:1743.854\n",
      "Ep:33, loss:0.00010, loss_test:0.07893, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:52.934, tt:1799.769\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07652, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:52.940, tt:1852.895\n",
      "Ep:35, loss:0.00009, loss_test:0.07665, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:52.915, tt:1904.957\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07600, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:52.941, tt:1958.825\n",
      "Ep:37, loss:0.00009, loss_test:0.07590, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:52.937, tt:2011.606\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07415, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:52.968, tt:2065.733\n",
      "Ep:39, loss:0.00008, loss_test:0.07510, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:52.968, tt:2118.700\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.07137, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:53.042, tt:2174.720\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.07505, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:53.023, tt:2226.982\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.07122, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:53.007, tt:2279.308\n",
      "Ep:43, loss:0.00007, loss_test:0.07301, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:52.999, tt:2331.976\n",
      "Ep:44, loss:0.00007, loss_test:0.07039, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:52.963, tt:2383.352\n",
      "Ep:45, loss:0.00007, loss_test:0.07067, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:52.962, tt:2436.252\n",
      "Ep:46, loss:0.00007, loss_test:0.07551, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:53.022, tt:2492.052\n",
      "Ep:47, loss:0.00007, loss_test:0.06752, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:53.052, tt:2546.490\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.07288, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:53.044, tt:2599.167\n",
      "Ep:49, loss:0.00006, loss_test:0.06884, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:53.066, tt:2653.316\n",
      "Ep:50, loss:0.00006, loss_test:0.06920, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:53.069, tt:2706.502\n",
      "Ep:51, loss:0.00006, loss_test:0.07345, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:53.042, tt:2758.200\n",
      "Ep:52, loss:0.00006, loss_test:0.06862, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:52.985, tt:2808.210\n",
      "Ep:53, loss:0.00005, loss_test:0.06895, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:52.996, tt:2861.771\n",
      "Ep:54, loss:0.00005, loss_test:0.06920, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:53.017, tt:2915.959\n",
      "Ep:55, loss:0.00005, loss_test:0.07224, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.013, tt:2968.711\n",
      "Ep:56, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:53.004, tt:3021.216\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.06853, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:52.971, tt:3072.301\n",
      "Ep:58, loss:0.00004, loss_test:0.06815, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:52.943, tt:3123.623\n",
      "Ep:59, loss:0.00004, loss_test:0.06824, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:52.937, tt:3176.223\n",
      "Ep:60, loss:0.00004, loss_test:0.06812, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:52.982, tt:3231.899\n",
      "Ep:61, loss:0.00004, loss_test:0.06731, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:52.992, tt:3285.522\n",
      "Ep:62, loss:0.00004, loss_test:0.06457, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:52.985, tt:3338.030\n",
      "Ep:63, loss:0.00004, loss_test:0.06840, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:52.957, tt:3389.249\n",
      "Ep:64, loss:0.00004, loss_test:0.07255, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:52.993, tt:3444.543\n",
      "Ep:65, loss:0.00003, loss_test:0.06330, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:52.981, tt:3496.771\n",
      "Ep:66, loss:0.00003, loss_test:0.06937, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:52.967, tt:3548.796\n",
      "Ep:67, loss:0.00003, loss_test:0.06436, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:52.956, tt:3601.011\n",
      "Ep:68, loss:0.00003, loss_test:0.06610, lr:9.90e-03, fs:0.83978 (r=0.768,p=0.927),  time:52.930, tt:3652.195\n",
      "Ep:69, loss:0.00003, loss_test:0.07118, lr:9.80e-03, fs:0.77011 (r=0.677,p=0.893),  time:52.929, tt:3705.035\n",
      "Ep:70, loss:0.00003, loss_test:0.06579, lr:9.70e-03, fs:0.82222 (r=0.747,p=0.914),  time:52.945, tt:3759.115\n",
      "Ep:71, loss:0.00003, loss_test:0.06883, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:52.951, tt:3812.443\n",
      "Ep:72, loss:0.00003, loss_test:0.07095, lr:9.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:52.976, tt:3867.284\n",
      "Ep:73, loss:0.00003, loss_test:0.06413, lr:9.41e-03, fs:0.84571 (r=0.747,p=0.974),  time:52.953, tt:3918.554\n",
      "Ep:74, loss:0.00003, loss_test:0.07079, lr:9.32e-03, fs:0.79348 (r=0.737,p=0.859),  time:52.950, tt:3971.236\n",
      "Ep:75, loss:0.00003, loss_test:0.07446, lr:9.23e-03, fs:0.75000 (r=0.636,p=0.913),  time:52.965, tt:4025.328\n",
      "Ep:76, loss:0.00003, loss_test:0.06684, lr:9.14e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.979, tt:4079.396\n",
      "Ep:77, loss:0.00003, loss_test:0.07296, lr:9.04e-03, fs:0.74699 (r=0.626,p=0.925),  time:52.975, tt:4132.017\n",
      "Ep:78, loss:0.00003, loss_test:0.06732, lr:8.95e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.966, tt:4184.344\n",
      "Ep:79, loss:0.00002, loss_test:0.06913, lr:8.86e-03, fs:0.79532 (r=0.687,p=0.944),  time:52.985, tt:4238.767\n",
      "Ep:80, loss:0.00003, loss_test:0.06573, lr:8.78e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.974, tt:4290.880\n",
      "Ep:81, loss:0.00002, loss_test:0.07020, lr:8.69e-03, fs:0.77844 (r=0.657,p=0.956),  time:53.007, tt:4346.605\n",
      "Ep:82, loss:0.00002, loss_test:0.06407, lr:8.60e-03, fs:0.80925 (r=0.707,p=0.946),  time:53.011, tt:4399.940\n",
      "Ep:83, loss:0.00002, loss_test:0.07045, lr:8.51e-03, fs:0.75904 (r=0.636,p=0.940),  time:53.040, tt:4455.344\n",
      "Ep:84, loss:0.00002, loss_test:0.06625, lr:8.43e-03, fs:0.80925 (r=0.707,p=0.946),  time:53.021, tt:4506.802\n",
      "Ep:85, loss:0.00002, loss_test:0.06945, lr:8.35e-03, fs:0.74074 (r=0.606,p=0.952),  time:53.022, tt:4559.902\n",
      "Ep:86, loss:0.00002, loss_test:0.06527, lr:8.26e-03, fs:0.80460 (r=0.707,p=0.933),  time:53.036, tt:4614.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:87, loss:0.00002, loss_test:0.07163, lr:8.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:53.032, tt:4666.854\n",
      "Ep:88, loss:0.00002, loss_test:0.06682, lr:8.10e-03, fs:0.78107 (r=0.667,p=0.943),  time:53.048, tt:4721.277\n",
      "Ep:89, loss:0.00002, loss_test:0.07018, lr:8.02e-03, fs:0.74074 (r=0.606,p=0.952),  time:53.060, tt:4775.413\n",
      "Ep:90, loss:0.00002, loss_test:0.07049, lr:7.94e-03, fs:0.74390 (r=0.616,p=0.938),  time:53.075, tt:4829.809\n",
      "Ep:91, loss:0.00001, loss_test:0.06910, lr:7.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:53.059, tt:4881.441\n",
      "Ep:92, loss:0.00001, loss_test:0.07112, lr:7.78e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.063, tt:4934.893\n",
      "Ep:93, loss:0.00001, loss_test:0.06938, lr:7.70e-03, fs:0.75152 (r=0.626,p=0.939),  time:53.054, tt:4987.071\n",
      "Ep:94, loss:0.00001, loss_test:0.07356, lr:7.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.056, tt:5040.345\n",
      "Ep:95, loss:0.00001, loss_test:0.07119, lr:7.55e-03, fs:0.74390 (r=0.616,p=0.938),  time:53.067, tt:5094.426\n",
      "Ep:96, loss:0.00001, loss_test:0.07325, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.071, tt:5147.918\n",
      "Ep:97, loss:0.00001, loss_test:0.07116, lr:7.40e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.059, tt:5199.778\n",
      "Ep:98, loss:0.00001, loss_test:0.07251, lr:7.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.048, tt:5251.774\n",
      "Ep:99, loss:0.00001, loss_test:0.07203, lr:7.25e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.053, tt:5305.282\n",
      "Ep:100, loss:0.00001, loss_test:0.07344, lr:7.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.059, tt:5358.915\n",
      "Ep:101, loss:0.00001, loss_test:0.07366, lr:7.11e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.961, tt:5402.035\n",
      "Ep:102, loss:0.00001, loss_test:0.07280, lr:7.03e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.820, tt:5440.445\n",
      "Ep:103, loss:0.00001, loss_test:0.07512, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.728, tt:5483.705\n",
      "Ep:104, loss:0.00001, loss_test:0.07366, lr:6.89e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.713, tt:5534.833\n",
      "Ep:105, loss:0.00001, loss_test:0.07661, lr:6.83e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.714, tt:5587.725\n",
      "Ep:106, loss:0.00001, loss_test:0.07520, lr:6.76e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.702, tt:5639.061\n",
      "Ep:107, loss:0.00001, loss_test:0.07552, lr:6.69e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.696, tt:5691.140\n",
      "Ep:108, loss:0.00001, loss_test:0.07587, lr:6.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.669, tt:5740.919\n",
      "Ep:109, loss:0.00001, loss_test:0.07568, lr:6.56e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.681, tt:5794.889\n",
      "Ep:110, loss:0.00001, loss_test:0.07775, lr:6.49e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.676, tt:5847.083\n",
      "Ep:111, loss:0.00001, loss_test:0.07423, lr:6.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.668, tt:5898.839\n",
      "Ep:112, loss:0.00001, loss_test:0.07778, lr:6.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.647, tt:5949.066\n",
      "Ep:113, loss:0.00001, loss_test:0.07492, lr:6.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.648, tt:6001.829\n",
      "Ep:114, loss:0.00001, loss_test:0.08077, lr:6.24e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.649, tt:6054.660\n",
      "Ep:115, loss:0.00001, loss_test:0.07499, lr:6.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.635, tt:6105.652\n",
      "Ep:116, loss:0.00001, loss_test:0.07905, lr:6.11e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.658, tt:6160.984\n",
      "Ep:117, loss:0.00001, loss_test:0.07824, lr:6.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.646, tt:6212.245\n",
      "Ep:118, loss:0.00001, loss_test:0.07865, lr:5.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.636, tt:6263.645\n",
      "Ep:119, loss:0.00001, loss_test:0.07869, lr:5.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.625, tt:6314.956\n",
      "Ep:120, loss:0.00001, loss_test:0.07825, lr:5.87e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.629, tt:6368.072\n",
      "Ep:121, loss:0.00001, loss_test:0.07919, lr:5.81e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.624, tt:6420.126\n",
      "Ep:122, loss:0.00001, loss_test:0.07690, lr:5.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.615, tt:6471.685\n",
      "Ep:123, loss:0.00001, loss_test:0.08226, lr:5.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.605, tt:6522.981\n",
      "Ep:124, loss:0.00001, loss_test:0.07778, lr:5.64e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.599, tt:6574.937\n",
      "Ep:125, loss:0.00001, loss_test:0.08104, lr:5.58e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.614, tt:6629.369\n",
      "Ep:126, loss:0.00001, loss_test:0.07923, lr:5.53e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.598, tt:6680.008\n",
      "Ep:127, loss:0.00001, loss_test:0.07846, lr:5.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.592, tt:6731.783\n",
      "Ep:128, loss:0.00001, loss_test:0.08204, lr:5.42e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.584, tt:6783.322\n",
      "Ep:129, loss:0.00001, loss_test:0.07901, lr:5.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.582, tt:6835.696\n",
      "Ep:130, loss:0.00001, loss_test:0.08180, lr:5.31e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.576, tt:6887.495\n",
      "Ep:131, loss:0.00001, loss_test:0.08031, lr:5.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.581, tt:6940.637\n",
      "Ep:132, loss:0.00001, loss_test:0.08121, lr:5.20e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.560, tt:6990.500\n",
      "Ep:133, loss:0.00000, loss_test:0.08016, lr:5.15e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.547, tt:7041.285\n",
      "Ep:134, loss:0.00000, loss_test:0.08011, lr:5.10e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.549, tt:7094.068\n",
      "Ep:135, loss:0.00000, loss_test:0.08044, lr:5.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.541, tt:7145.540\n",
      "Ep:136, loss:0.00000, loss_test:0.08069, lr:5.00e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.549, tt:7199.151\n",
      "Ep:137, loss:0.00000, loss_test:0.08167, lr:4.95e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.539, tt:7250.449\n",
      "Ep:138, loss:0.00000, loss_test:0.08108, lr:4.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.522, tt:7300.503\n",
      "Ep:139, loss:0.00000, loss_test:0.08047, lr:4.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.536, tt:7355.054\n",
      "Ep:140, loss:0.00000, loss_test:0.08257, lr:4.80e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.516, tt:7404.774\n",
      "Ep:141, loss:0.00000, loss_test:0.08140, lr:4.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.528, tt:7458.928\n",
      "Ep:142, loss:0.00000, loss_test:0.08164, lr:4.71e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.502, tt:7507.855\n",
      "Ep:143, loss:0.00000, loss_test:0.08212, lr:4.66e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.496, tt:7559.431\n",
      "Ep:144, loss:0.00000, loss_test:0.08057, lr:4.61e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.488, tt:7610.714\n",
      "Ep:145, loss:0.00000, loss_test:0.08427, lr:4.57e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.479, tt:7661.929\n",
      "Ep:146, loss:0.00000, loss_test:0.08036, lr:4.52e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.474, tt:7713.718\n",
      "Ep:147, loss:0.00000, loss_test:0.08335, lr:4.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.471, tt:7765.702\n",
      "Ep:148, loss:0.00000, loss_test:0.08196, lr:4.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.467, tt:7817.594\n",
      "Ep:149, loss:0.00000, loss_test:0.08493, lr:4.39e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.459, tt:7868.854\n",
      "Ep:150, loss:0.00000, loss_test:0.08464, lr:4.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.450, tt:7920.026\n",
      "Ep:151, loss:0.00000, loss_test:0.08082, lr:4.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.430, tt:7969.359\n",
      "Ep:152, loss:0.00000, loss_test:0.08609, lr:4.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.427, tt:8021.301\n",
      "Ep:153, loss:0.00000, loss_test:0.08314, lr:4.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.418, tt:8072.352\n",
      "Ep:154, loss:0.00000, loss_test:0.08516, lr:4.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.415, tt:8124.379\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00028, loss_test:0.14496, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.559, tt:20.559\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14438, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.518, tt:39.036\n",
      "Ep:2, loss:0.00028, loss_test:0.14341, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.127, tt:60.380\n",
      "Ep:3, loss:0.00028, loss_test:0.14195, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.815, tt:79.262\n",
      "Ep:4, loss:0.00028, loss_test:0.13979, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.216, tt:101.080\n",
      "Ep:5, loss:0.00027, loss_test:0.13632, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:19.897, tt:119.384\n",
      "Ep:6, loss:0.00026, loss_test:0.13053, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:19.957, tt:139.702\n",
      "Ep:7, loss:0.00025, loss_test:0.12069, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:19.875, tt:158.998\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10880, lr:1.00e-02, fs:0.66667 (r=0.727,p=0.615),  time:19.727, tt:177.546\n",
      "Ep:9, loss:0.00023, loss_test:0.10434, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:19.717, tt:197.170\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10678, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:19.834, tt:218.179\n",
      "Ep:11, loss:0.00021, loss_test:0.10455, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:20.071, tt:240.850\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09619, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:19.915, tt:258.894\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09319, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:19.992, tt:279.890\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09199, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:19.818, tt:297.264\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08735, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:19.857, tt:317.710\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08442, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:19.773, tt:336.142\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08296, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:19.920, tt:358.562\n",
      "Ep:18, loss:0.00016, loss_test:0.08007, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:19.868, tt:377.500\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.07778, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:19.927, tt:398.548\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.07693, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:19.906, tt:418.029\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07416, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:19.987, tt:439.715\n",
      "Ep:22, loss:0.00013, loss_test:0.07291, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:20.064, tt:461.482\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.07150, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:20.036, tt:480.853\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07000, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:20.096, tt:502.403\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.06932, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:20.117, tt:523.048\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.06823, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:20.128, tt:543.451\n",
      "Ep:27, loss:0.00011, loss_test:0.06691, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:20.102, tt:562.857\n",
      "Ep:28, loss:0.00010, loss_test:0.06738, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:20.118, tt:583.436\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.06449, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:20.065, tt:601.960\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.06480, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:20.106, tt:623.288\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.06438, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:20.041, tt:641.314\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06407, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:20.089, tt:662.944\n",
      "Ep:33, loss:0.00008, loss_test:0.06342, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:20.080, tt:682.727\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.06128, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:20.089, tt:703.118\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.06132, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:20.110, tt:723.951\n",
      "Ep:36, loss:0.00007, loss_test:0.06120, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:20.062, tt:742.293\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.06058, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:20.094, tt:763.570\n",
      "Ep:38, loss:0.00007, loss_test:0.06140, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:20.088, tt:783.422\n",
      "Ep:39, loss:0.00006, loss_test:0.05988, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:20.114, tt:804.574\n",
      "Ep:40, loss:0.00006, loss_test:0.06139, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:20.113, tt:824.651\n",
      "Ep:41, loss:0.00006, loss_test:0.06004, lr:1.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:20.140, tt:845.859\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06100, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:20.122, tt:865.235\n",
      "Ep:43, loss:0.00005, loss_test:0.06061, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:20.139, tt:886.128\n",
      "Ep:44, loss:0.00005, loss_test:0.06178, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.133, tt:905.975\n",
      "Ep:45, loss:0.00005, loss_test:0.05967, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:20.141, tt:926.508\n",
      "Ep:46, loss:0.00005, loss_test:0.06057, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.127, tt:945.991\n",
      "Ep:47, loss:0.00004, loss_test:0.05818, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.173, tt:968.311\n",
      "Ep:48, loss:0.00004, loss_test:0.06179, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:20.166, tt:988.132\n",
      "Ep:49, loss:0.00004, loss_test:0.06160, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:20.219, tt:1010.951\n",
      "Ep:50, loss:0.00004, loss_test:0.06075, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:20.198, tt:1030.091\n",
      "Ep:51, loss:0.00004, loss_test:0.06326, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.208, tt:1050.816\n",
      "Ep:52, loss:0.00004, loss_test:0.05896, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:20.207, tt:1070.977\n",
      "Ep:53, loss:0.00004, loss_test:0.06284, lr:9.90e-03, fs:0.82682 (r=0.747,p=0.925),  time:20.173, tt:1089.357\n",
      "Ep:54, loss:0.00004, loss_test:0.05866, lr:9.80e-03, fs:0.88660 (r=0.869,p=0.905),  time:20.187, tt:1110.258\n",
      "Ep:55, loss:0.00004, loss_test:0.05992, lr:9.70e-03, fs:0.85405 (r=0.798,p=0.919),  time:20.164, tt:1129.166\n",
      "Ep:56, loss:0.00003, loss_test:0.05931, lr:9.61e-03, fs:0.86911 (r=0.838,p=0.902),  time:20.206, tt:1151.713\n",
      "Ep:57, loss:0.00003, loss_test:0.06326, lr:9.51e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.217, tt:1172.596\n",
      "Ep:58, loss:0.00003, loss_test:0.05807, lr:9.41e-03, fs:0.87047 (r=0.848,p=0.894),  time:20.237, tt:1194.008\n",
      "Ep:59, loss:0.00003, loss_test:0.06712, lr:9.32e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.235, tt:1214.077\n",
      "Ep:60, loss:0.00003, loss_test:0.05950, lr:9.23e-03, fs:0.83871 (r=0.788,p=0.897),  time:20.256, tt:1235.615\n",
      "Ep:61, loss:0.00003, loss_test:0.06299, lr:9.14e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.251, tt:1255.561\n",
      "Ep:62, loss:0.00003, loss_test:0.06145, lr:9.04e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.233, tt:1274.689\n",
      "Ep:63, loss:0.00003, loss_test:0.05902, lr:8.95e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.218, tt:1293.954\n",
      "Ep:64, loss:0.00002, loss_test:0.06321, lr:8.86e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.225, tt:1314.597\n",
      "Ep:65, loss:0.00002, loss_test:0.05942, lr:8.78e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.199, tt:1333.109\n",
      "Ep:66, loss:0.00002, loss_test:0.06177, lr:8.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.191, tt:1352.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00002, loss_test:0.05987, lr:8.60e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.198, tt:1373.435\n",
      "Ep:68, loss:0.00002, loss_test:0.06267, lr:8.51e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.204, tt:1394.053\n",
      "Ep:69, loss:0.00002, loss_test:0.06162, lr:8.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.223, tt:1415.593\n",
      "Ep:70, loss:0.00002, loss_test:0.06001, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:20.219, tt:1435.572\n",
      "Ep:71, loss:0.00002, loss_test:0.06273, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.240, tt:1457.271\n",
      "Ep:72, loss:0.00002, loss_test:0.06239, lr:8.18e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.275, tt:1480.066\n",
      "Ep:73, loss:0.00002, loss_test:0.06143, lr:8.10e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.302, tt:1502.330\n",
      "Ep:74, loss:0.00002, loss_test:0.06353, lr:8.02e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.329, tt:1524.658\n",
      "Ep:75, loss:0.00002, loss_test:0.06099, lr:7.94e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.343, tt:1546.053\n",
      "Ep:76, loss:0.00002, loss_test:0.06250, lr:7.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:1566.424\n",
      "Ep:77, loss:0.00002, loss_test:0.06266, lr:7.78e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.335, tt:1586.116\n",
      "Ep:78, loss:0.00002, loss_test:0.06438, lr:7.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.336, tt:1606.517\n",
      "Ep:79, loss:0.00001, loss_test:0.05957, lr:7.62e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.334, tt:1626.686\n",
      "Ep:80, loss:0.00001, loss_test:0.06780, lr:7.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.312, tt:1645.297\n",
      "Ep:81, loss:0.00001, loss_test:0.06171, lr:7.47e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.329, tt:1666.978\n",
      "Ep:82, loss:0.00001, loss_test:0.06410, lr:7.40e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.324, tt:1686.875\n",
      "Ep:83, loss:0.00001, loss_test:0.06360, lr:7.32e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.324, tt:1707.254\n",
      "Ep:84, loss:0.00001, loss_test:0.06688, lr:7.25e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.330, tt:1728.043\n",
      "Ep:85, loss:0.00001, loss_test:0.06153, lr:7.18e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.323, tt:1747.794\n",
      "Ep:86, loss:0.00001, loss_test:0.06731, lr:7.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.320, tt:1767.821\n",
      "Ep:87, loss:0.00001, loss_test:0.06219, lr:7.03e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.350, tt:1790.767\n",
      "Ep:88, loss:0.00001, loss_test:0.06828, lr:6.96e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.352, tt:1811.294\n",
      "Ep:89, loss:0.00001, loss_test:0.06365, lr:6.89e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.363, tt:1832.697\n",
      "Ep:90, loss:0.00001, loss_test:0.06764, lr:6.83e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.351, tt:1851.904\n",
      "Ep:91, loss:0.00001, loss_test:0.06362, lr:6.76e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:1871.577\n",
      "Ep:92, loss:0.00001, loss_test:0.06526, lr:6.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.328, tt:1890.467\n",
      "Ep:93, loss:0.00001, loss_test:0.06423, lr:6.62e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.324, tt:1910.422\n",
      "Ep:94, loss:0.00001, loss_test:0.06633, lr:6.56e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.309, tt:1929.381\n",
      "Ep:95, loss:0.00001, loss_test:0.06720, lr:6.49e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.296, tt:1948.449\n",
      "Ep:96, loss:0.00001, loss_test:0.06478, lr:6.43e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.284, tt:1967.508\n",
      "Ep:97, loss:0.00001, loss_test:0.06722, lr:6.36e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.272, tt:1986.671\n",
      "Ep:98, loss:0.00001, loss_test:0.06497, lr:6.30e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.317, tt:2011.346\n",
      "Ep:99, loss:0.00001, loss_test:0.06629, lr:6.24e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.318, tt:2031.773\n",
      "Ep:100, loss:0.00001, loss_test:0.06557, lr:6.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.340, tt:2054.317\n",
      "Ep:101, loss:0.00001, loss_test:0.06785, lr:6.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.354, tt:2076.148\n",
      "Ep:102, loss:0.00001, loss_test:0.06652, lr:6.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.367, tt:2097.772\n",
      "Ep:103, loss:0.00001, loss_test:0.06653, lr:5.99e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.369, tt:2118.412\n",
      "Ep:104, loss:0.00001, loss_test:0.06695, lr:5.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.371, tt:2138.927\n",
      "Ep:105, loss:0.00001, loss_test:0.06573, lr:5.87e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.373, tt:2159.494\n",
      "Ep:106, loss:0.00001, loss_test:0.06627, lr:5.81e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.359, tt:2178.421\n",
      "Ep:107, loss:0.00001, loss_test:0.06618, lr:5.75e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.361, tt:2198.963\n",
      "Ep:108, loss:0.00001, loss_test:0.06499, lr:5.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.353, tt:2218.459\n",
      "Ep:109, loss:0.00001, loss_test:0.06830, lr:5.64e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.356, tt:2239.112\n",
      "Ep:110, loss:0.00001, loss_test:0.06569, lr:5.58e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.353, tt:2259.215\n",
      "Ep:111, loss:0.00001, loss_test:0.06711, lr:5.53e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.346, tt:2278.738\n",
      "Ep:112, loss:0.00001, loss_test:0.06577, lr:5.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.338, tt:2298.249\n",
      "Ep:113, loss:0.00001, loss_test:0.06724, lr:5.42e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.339, tt:2318.666\n",
      "Ep:114, loss:0.00001, loss_test:0.06732, lr:5.36e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.330, tt:2337.913\n",
      "Ep:115, loss:0.00001, loss_test:0.06604, lr:5.31e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.346, tt:2360.153\n",
      "Ep:116, loss:0.00001, loss_test:0.06704, lr:5.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.362, tt:2382.393\n",
      "Ep:117, loss:0.00001, loss_test:0.06598, lr:5.20e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.362, tt:2402.709\n",
      "Ep:118, loss:0.00001, loss_test:0.06857, lr:5.15e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.361, tt:2422.960\n",
      "Ep:119, loss:0.00001, loss_test:0.06543, lr:5.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.364, tt:2443.691\n",
      "Ep:120, loss:0.00001, loss_test:0.06723, lr:5.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.361, tt:2463.737\n",
      "Ep:121, loss:0.00001, loss_test:0.06717, lr:5.00e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.354, tt:2483.167\n",
      "Ep:122, loss:0.00001, loss_test:0.06635, lr:4.95e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.345, tt:2502.450\n",
      "Ep:123, loss:0.00001, loss_test:0.06774, lr:4.90e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.334, tt:2521.354\n",
      "Ep:124, loss:0.00001, loss_test:0.06751, lr:4.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.340, tt:2542.477\n",
      "Ep:125, loss:0.00001, loss_test:0.06792, lr:4.80e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.347, tt:2563.736\n",
      "Ep:126, loss:0.00001, loss_test:0.06716, lr:4.75e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.342, tt:2583.384\n",
      "Ep:127, loss:0.00001, loss_test:0.06807, lr:4.71e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.333, tt:2602.579\n",
      "Ep:128, loss:0.00001, loss_test:0.06901, lr:4.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.356, tt:2625.909\n",
      "Ep:129, loss:0.00001, loss_test:0.06610, lr:4.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.350, tt:2645.445\n",
      "Ep:130, loss:0.00001, loss_test:0.06909, lr:4.57e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.362, tt:2667.397\n",
      "Ep:131, loss:0.00001, loss_test:0.06733, lr:4.52e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.353, tt:2686.641\n",
      "Ep:132, loss:0.00001, loss_test:0.06700, lr:4.48e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.344, tt:2705.693\n",
      "Ep:133, loss:0.00001, loss_test:0.06796, lr:4.43e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.339, tt:2725.466\n",
      "Ep:134, loss:0.00001, loss_test:0.06716, lr:4.39e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.335, tt:2745.261\n",
      "Ep:135, loss:0.00001, loss_test:0.06827, lr:4.34e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.333, tt:2765.236\n",
      "Ep:136, loss:0.00001, loss_test:0.06708, lr:4.30e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.336, tt:2786.047\n",
      "Ep:137, loss:0.00001, loss_test:0.06694, lr:4.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:2807.311\n",
      "Ep:138, loss:0.00001, loss_test:0.06856, lr:4.21e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.349, tt:2828.474\n",
      "Ep:139, loss:0.00001, loss_test:0.06764, lr:4.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.359, tt:2850.238\n",
      "Ep:140, loss:0.00001, loss_test:0.06830, lr:4.13e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.357, tt:2870.332\n",
      "Ep:141, loss:0.00001, loss_test:0.06888, lr:4.09e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.357, tt:2890.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.06669, lr:4.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.347, tt:2909.676\n",
      "Ep:143, loss:0.00000, loss_test:0.06860, lr:4.01e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.344, tt:2929.500\n",
      "Ep:144, loss:0.00000, loss_test:0.06811, lr:3.97e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.345, tt:2949.981\n",
      "Ep:145, loss:0.00000, loss_test:0.06766, lr:3.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.348, tt:2970.828\n",
      "Ep:146, loss:0.00000, loss_test:0.06817, lr:3.89e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.345, tt:2990.735\n",
      "Ep:147, loss:0.00000, loss_test:0.06709, lr:3.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:3010.702\n",
      "Ep:148, loss:0.00000, loss_test:0.06937, lr:3.81e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.341, tt:3030.820\n",
      "Ep:149, loss:0.00000, loss_test:0.06958, lr:3.77e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.334, tt:3050.072\n",
      "Ep:150, loss:0.00000, loss_test:0.06728, lr:3.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.335, tt:3070.518\n",
      "Ep:151, loss:0.00000, loss_test:0.06921, lr:3.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.329, tt:3089.942\n",
      "Ep:152, loss:0.00000, loss_test:0.06903, lr:3.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.322, tt:3109.260\n",
      "Ep:153, loss:0.00000, loss_test:0.06721, lr:3.62e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.304, tt:3126.766\n",
      "Ep:154, loss:0.00000, loss_test:0.06897, lr:3.59e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.295, tt:3145.762\n",
      "Ep:155, loss:0.00000, loss_test:0.06800, lr:3.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.292, tt:3165.491\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14235, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:25.796, tt:25.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14072, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:24.250, tt:48.500\n",
      "Ep:2, loss:0.00027, loss_test:0.13771, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:24.311, tt:72.934\n",
      "Ep:3, loss:0.00027, loss_test:0.13296, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:24.136, tt:96.542\n",
      "Ep:4, loss:0.00026, loss_test:0.12804, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:23.915, tt:119.574\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12366, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:23.770, tt:142.620\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11932, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:23.706, tt:165.942\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11565, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:23.641, tt:189.129\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11208, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:23.574, tt:212.167\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10581, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:23.695, tt:236.955\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10330, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:23.650, tt:260.152\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10248, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:23.670, tt:284.042\n",
      "Ep:12, loss:0.00019, loss_test:0.09773, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:23.586, tt:306.622\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09461, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:23.775, tt:332.850\n",
      "Ep:14, loss:0.00017, loss_test:0.09402, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:23.919, tt:358.779\n",
      "Ep:15, loss:0.00017, loss_test:0.09087, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:23.893, tt:382.287\n",
      "Ep:16, loss:0.00016, loss_test:0.08982, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:24.001, tt:408.020\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08575, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:23.927, tt:430.690\n",
      "Ep:18, loss:0.00014, loss_test:0.08379, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:23.967, tt:455.364\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08294, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:23.855, tt:477.091\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08061, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:23.966, tt:503.283\n",
      "Ep:21, loss:0.00013, loss_test:0.07952, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:23.912, tt:526.066\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.07760, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:23.905, tt:549.814\n",
      "Ep:23, loss:0.00012, loss_test:0.07619, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:23.986, tt:575.671\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07490, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:23.922, tt:598.042\n",
      "Ep:25, loss:0.00011, loss_test:0.07338, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:23.954, tt:622.803\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07174, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:23.896, tt:645.190\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07088, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:23.937, tt:670.235\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.07016, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:23.883, tt:692.598\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.06905, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:23.903, tt:717.077\n",
      "Ep:30, loss:0.00009, loss_test:0.06877, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:23.829, tt:738.703\n",
      "Ep:31, loss:0.00008, loss_test:0.06774, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:23.751, tt:760.022\n",
      "Ep:32, loss:0.00008, loss_test:0.06738, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:23.607, tt:779.031\n",
      "Ep:33, loss:0.00008, loss_test:0.06677, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:23.534, tt:800.166\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06574, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:23.374, tt:818.092\n",
      "Ep:35, loss:0.00007, loss_test:0.06638, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:23.267, tt:837.600\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.06505, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:23.192, tt:858.112\n",
      "Ep:37, loss:0.00006, loss_test:0.06572, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:23.216, tt:882.211\n",
      "Ep:38, loss:0.00006, loss_test:0.06400, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:23.272, tt:907.598\n",
      "Ep:39, loss:0.00006, loss_test:0.06449, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:23.239, tt:929.550\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.06279, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:23.244, tt:953.005\n",
      "Ep:41, loss:0.00006, loss_test:0.06285, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:23.258, tt:976.817\n",
      "Ep:42, loss:0.00005, loss_test:0.06220, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:23.334, tt:1003.370\n",
      "Ep:43, loss:0.00005, loss_test:0.06110, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:23.305, tt:1025.440\n",
      "Ep:44, loss:0.00005, loss_test:0.06131, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:23.369, tt:1051.623\n",
      "Ep:45, loss:0.00005, loss_test:0.06041, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:23.364, tt:1074.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00005, loss_test:0.06106, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:23.365, tt:1098.176\n",
      "Ep:47, loss:0.00004, loss_test:0.06019, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:23.378, tt:1122.124\n",
      "Ep:48, loss:0.00004, loss_test:0.06053, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:23.362, tt:1144.721\n",
      "Ep:49, loss:0.00004, loss_test:0.05943, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:23.368, tt:1168.393\n",
      "Ep:50, loss:0.00004, loss_test:0.06046, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:23.365, tt:1191.637\n",
      "Ep:51, loss:0.00004, loss_test:0.05919, lr:9.90e-03, fs:0.84375 (r=0.818,p=0.871),  time:23.406, tt:1217.125\n",
      "Ep:52, loss:0.00004, loss_test:0.05927, lr:9.80e-03, fs:0.83598 (r=0.798,p=0.878),  time:23.426, tt:1241.597\n",
      "Ep:53, loss:0.00004, loss_test:0.05806, lr:9.70e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.414, tt:1264.383\n",
      "Ep:54, loss:0.00004, loss_test:0.05897, lr:9.61e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.393, tt:1286.590\n",
      "Ep:55, loss:0.00003, loss_test:0.05811, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.421, tt:1311.549\n",
      "Ep:56, loss:0.00003, loss_test:0.05785, lr:9.41e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.446, tt:1336.449\n",
      "Ep:57, loss:0.00003, loss_test:0.05814, lr:9.32e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.444, tt:1359.733\n",
      "Ep:58, loss:0.00003, loss_test:0.05733, lr:9.23e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.476, tt:1385.113\n",
      "Ep:59, loss:0.00003, loss_test:0.05732, lr:9.14e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.470, tt:1408.218\n",
      "Ep:60, loss:0.00003, loss_test:0.05822, lr:9.04e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.503, tt:1433.654\n",
      "Ep:61, loss:0.00003, loss_test:0.05800, lr:8.95e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.490, tt:1456.400\n",
      "Ep:62, loss:0.00003, loss_test:0.05712, lr:8.86e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.513, tt:1481.310\n",
      "Ep:63, loss:0.00003, loss_test:0.05807, lr:8.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:23.519, tt:1505.224\n",
      "Ep:64, loss:0.00003, loss_test:0.05669, lr:8.69e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.518, tt:1528.670\n",
      "Ep:65, loss:0.00003, loss_test:0.05662, lr:8.60e-03, fs:0.85106 (r=0.808,p=0.899),  time:23.533, tt:1553.209\n",
      "Ep:66, loss:0.00003, loss_test:0.05733, lr:8.51e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.534, tt:1576.750\n",
      "Ep:67, loss:0.00002, loss_test:0.05542, lr:8.43e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.550, tt:1601.368\n",
      "Ep:68, loss:0.00002, loss_test:0.05533, lr:8.35e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.558, tt:1625.479\n",
      "Ep:69, loss:0.00002, loss_test:0.05714, lr:8.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:23.601, tt:1652.082\n",
      "Ep:70, loss:0.00002, loss_test:0.05511, lr:8.18e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.588, tt:1674.766\n",
      "Ep:71, loss:0.00002, loss_test:0.05620, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.621, tt:1700.705\n",
      "Ep:72, loss:0.00002, loss_test:0.05478, lr:8.02e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.616, tt:1723.983\n",
      "Ep:73, loss:0.00002, loss_test:0.05554, lr:7.94e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.594, tt:1745.957\n",
      "Ep:74, loss:0.00002, loss_test:0.05411, lr:7.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.619, tt:1771.400\n",
      "Ep:75, loss:0.00002, loss_test:0.05422, lr:7.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:23.621, tt:1795.215\n",
      "Ep:76, loss:0.00002, loss_test:0.05453, lr:7.70e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.665, tt:1822.234\n",
      "Ep:77, loss:0.00002, loss_test:0.05368, lr:7.62e-03, fs:0.85714 (r=0.818,p=0.900),  time:23.648, tt:1844.506\n",
      "Ep:78, loss:0.00002, loss_test:0.05422, lr:7.55e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.681, tt:1870.779\n",
      "Ep:79, loss:0.00002, loss_test:0.05445, lr:7.47e-03, fs:0.85263 (r=0.818,p=0.890),  time:23.664, tt:1893.134\n",
      "Ep:80, loss:0.00002, loss_test:0.05342, lr:7.40e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.690, tt:1918.887\n",
      "Ep:81, loss:0.00002, loss_test:0.05497, lr:7.32e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.703, tt:1943.674\n",
      "Ep:82, loss:0.00002, loss_test:0.05337, lr:7.25e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.705, tt:1967.477\n",
      "Ep:83, loss:0.00002, loss_test:0.05438, lr:7.18e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.716, tt:1992.137\n",
      "Ep:84, loss:0.00002, loss_test:0.05398, lr:7.11e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.713, tt:2015.590\n",
      "Ep:85, loss:0.00002, loss_test:0.05382, lr:7.03e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.735, tt:2041.244\n",
      "Ep:86, loss:0.00002, loss_test:0.05422, lr:6.96e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.748, tt:2066.113\n",
      "Ep:87, loss:0.00001, loss_test:0.05421, lr:6.89e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.765, tt:2091.299\n",
      "Ep:88, loss:0.00001, loss_test:0.05360, lr:6.83e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.783, tt:2116.678\n",
      "Ep:89, loss:0.00001, loss_test:0.05454, lr:6.76e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.781, tt:2140.308\n",
      "Ep:90, loss:0.00001, loss_test:0.05439, lr:6.69e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.818, tt:2167.462\n",
      "Ep:91, loss:0.00001, loss_test:0.05328, lr:6.62e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.791, tt:2188.786\n",
      "Ep:92, loss:0.00001, loss_test:0.05444, lr:6.56e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.812, tt:2214.533\n",
      "Ep:93, loss:0.00001, loss_test:0.05352, lr:6.49e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.779, tt:2235.200\n",
      "Ep:94, loss:0.00001, loss_test:0.05453, lr:6.43e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.792, tt:2260.262\n",
      "Ep:95, loss:0.00001, loss_test:0.05434, lr:6.36e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.787, tt:2283.541\n",
      "Ep:96, loss:0.00001, loss_test:0.05332, lr:6.30e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.793, tt:2307.946\n",
      "Ep:97, loss:0.00001, loss_test:0.05440, lr:6.24e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.785, tt:2330.885\n",
      "Ep:98, loss:0.00001, loss_test:0.05320, lr:6.17e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.788, tt:2355.000\n",
      "Ep:99, loss:0.00001, loss_test:0.05452, lr:6.11e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.799, tt:2379.920\n",
      "Ep:100, loss:0.00001, loss_test:0.05431, lr:6.05e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.798, tt:2403.563\n",
      "Ep:101, loss:0.00001, loss_test:0.05394, lr:5.99e-03, fs:0.86170 (r=0.818,p=0.910),  time:23.793, tt:2426.891\n",
      "Ep:102, loss:0.00001, loss_test:0.05431, lr:5.93e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.766, tt:2447.918\n",
      "Ep:103, loss:0.00001, loss_test:0.05462, lr:5.87e-03, fs:0.86170 (r=0.818,p=0.910),  time:23.776, tt:2472.722\n",
      "Ep:104, loss:0.00001, loss_test:0.05316, lr:5.81e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.767, tt:2495.486\n",
      "Ep:105, loss:0.00001, loss_test:0.05455, lr:5.75e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.787, tt:2521.397\n",
      "Ep:106, loss:0.00001, loss_test:0.05479, lr:5.70e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.785, tt:2544.980\n",
      "Ep:107, loss:0.00001, loss_test:0.05407, lr:5.64e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.799, tt:2570.336\n",
      "Ep:108, loss:0.00001, loss_test:0.05373, lr:5.58e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.810, tt:2595.319\n",
      "Ep:109, loss:0.00001, loss_test:0.05458, lr:5.53e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.786, tt:2616.491\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.05411, lr:5.53e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.812, tt:2643.085\n",
      "Ep:111, loss:0.00001, loss_test:0.05439, lr:5.53e-03, fs:0.85561 (r=0.808,p=0.909),  time:23.791, tt:2664.564\n",
      "Ep:112, loss:0.00001, loss_test:0.05439, lr:5.53e-03, fs:0.85561 (r=0.808,p=0.909),  time:23.799, tt:2689.255\n",
      "Ep:113, loss:0.00001, loss_test:0.05373, lr:5.53e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.775, tt:2710.383\n",
      "Ep:114, loss:0.00001, loss_test:0.05485, lr:5.53e-03, fs:0.86022 (r=0.808,p=0.920),  time:23.779, tt:2734.634\n",
      "Ep:115, loss:0.00001, loss_test:0.05362, lr:5.53e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.781, tt:2758.653\n",
      "Ep:116, loss:0.00001, loss_test:0.05478, lr:5.53e-03, fs:0.85561 (r=0.808,p=0.909),  time:23.782, tt:2782.553\n",
      "Ep:117, loss:0.00001, loss_test:0.05464, lr:5.53e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.810, tt:2809.575\n",
      "Ep:118, loss:0.00001, loss_test:0.05442, lr:5.53e-03, fs:0.86631 (r=0.818,p=0.920),  time:23.809, tt:2833.274\n",
      "Ep:119, loss:0.00001, loss_test:0.05474, lr:5.53e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.819, tt:2858.257\n",
      "Ep:120, loss:0.00001, loss_test:0.05484, lr:5.53e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.800, tt:2879.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.05451, lr:5.47e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.798, tt:2903.324\n",
      "Ep:122, loss:0.00001, loss_test:0.05469, lr:5.42e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.797, tt:2927.054\n",
      "Ep:123, loss:0.00001, loss_test:0.05531, lr:5.36e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.811, tt:2952.545\n",
      "Ep:124, loss:0.00001, loss_test:0.05463, lr:5.31e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.808, tt:2976.062\n",
      "Ep:125, loss:0.00001, loss_test:0.05473, lr:5.26e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.808, tt:2999.754\n",
      "Ep:126, loss:0.00001, loss_test:0.05410, lr:5.20e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.806, tt:3023.328\n",
      "Ep:127, loss:0.00001, loss_test:0.05412, lr:5.15e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.802, tt:3046.628\n",
      "Ep:128, loss:0.00001, loss_test:0.05445, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.809, tt:3071.313\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.05495, lr:5.10e-03, fs:0.86957 (r=0.808,p=0.941),  time:23.820, tt:3096.666\n",
      "Ep:130, loss:0.00001, loss_test:0.05468, lr:5.10e-03, fs:0.86957 (r=0.808,p=0.941),  time:23.824, tt:3120.960\n",
      "Ep:131, loss:0.00001, loss_test:0.05468, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.813, tt:3143.290\n",
      "Ep:132, loss:0.00001, loss_test:0.05574, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.827, tt:3168.996\n",
      "Ep:133, loss:0.00001, loss_test:0.05446, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.823, tt:3192.229\n",
      "Ep:134, loss:0.00001, loss_test:0.05525, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.825, tt:3216.334\n",
      "Ep:135, loss:0.00001, loss_test:0.05533, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.822, tt:3239.836\n",
      "Ep:136, loss:0.00001, loss_test:0.05447, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.816, tt:3262.780\n",
      "Ep:137, loss:0.00001, loss_test:0.05531, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.819, tt:3287.082\n",
      "Ep:138, loss:0.00001, loss_test:0.05636, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.815, tt:3310.314\n",
      "Ep:139, loss:0.00001, loss_test:0.05521, lr:5.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:23.830, tt:3336.261\n",
      "Ep:140, loss:0.00001, loss_test:0.05482, lr:5.05e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.830, tt:3360.057\n",
      "Ep:141, loss:0.00001, loss_test:0.05528, lr:5.00e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.840, tt:3385.350\n",
      "Ep:142, loss:0.00001, loss_test:0.05505, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:23.837, tt:3408.763\n",
      "Ep:143, loss:0.00001, loss_test:0.05486, lr:4.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.845, tt:3433.649\n",
      "Ep:144, loss:0.00001, loss_test:0.05462, lr:4.85e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.846, tt:3457.740\n",
      "Ep:145, loss:0.00001, loss_test:0.05526, lr:4.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.833, tt:3479.605\n",
      "Ep:146, loss:0.00001, loss_test:0.05526, lr:4.75e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.846, tt:3505.348\n",
      "Ep:147, loss:0.00001, loss_test:0.05495, lr:4.71e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.834, tt:3527.430\n",
      "Ep:148, loss:0.00001, loss_test:0.05520, lr:4.66e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.840, tt:3552.189\n",
      "Ep:149, loss:0.00000, loss_test:0.05497, lr:4.61e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.838, tt:3575.700\n",
      "Ep:150, loss:0.00000, loss_test:0.05496, lr:4.57e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.838, tt:3599.576\n",
      "Ep:151, loss:0.00000, loss_test:0.05544, lr:4.52e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.843, tt:3624.123\n",
      "Ep:152, loss:0.00000, loss_test:0.05569, lr:4.48e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.848, tt:3648.816\n",
      "Ep:153, loss:0.00000, loss_test:0.05521, lr:4.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.848, tt:3672.534\n",
      "Ep:154, loss:0.00000, loss_test:0.05529, lr:4.39e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.857, tt:3697.838\n",
      "Ep:155, loss:0.00000, loss_test:0.05504, lr:4.34e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.849, tt:3720.459\n",
      "Ep:156, loss:0.00000, loss_test:0.05486, lr:4.30e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.827, tt:3740.841\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14381, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.466, tt:41.466\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14193, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:40.893, tt:81.786\n",
      "Ep:2, loss:0.00027, loss_test:0.13835, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:41.286, tt:123.859\n",
      "Ep:3, loss:0.00027, loss_test:0.13219, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:40.509, tt:162.035\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12165, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:40.536, tt:202.681\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11208, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:40.547, tt:243.282\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10737, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:40.516, tt:283.614\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10704, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:40.402, tt:323.213\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10519, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:40.694, tt:366.250\n",
      "Ep:9, loss:0.00021, loss_test:0.10369, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:40.893, tt:408.925\n",
      "Ep:10, loss:0.00020, loss_test:0.10243, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:40.953, tt:450.488\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10076, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:40.925, tt:491.105\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09958, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:40.935, tt:532.156\n",
      "Ep:13, loss:0.00018, loss_test:0.09877, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:41.047, tt:574.653\n",
      "Ep:14, loss:0.00018, loss_test:0.09721, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:41.087, tt:616.309\n",
      "Ep:15, loss:0.00018, loss_test:0.09619, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:41.033, tt:656.524\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09646, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:41.054, tt:697.920\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09487, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:41.066, tt:739.185\n",
      "Ep:18, loss:0.00016, loss_test:0.09354, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:41.029, tt:779.554\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09378, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:41.004, tt:820.074\n",
      "Ep:20, loss:0.00016, loss_test:0.09294, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:40.925, tt:859.419\n",
      "Ep:21, loss:0.00015, loss_test:0.09298, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:40.934, tt:900.554\n",
      "Ep:22, loss:0.00015, loss_test:0.09125, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:40.880, tt:940.245\n",
      "Ep:23, loss:0.00015, loss_test:0.09154, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.855, tt:980.513\n",
      "Ep:24, loss:0.00014, loss_test:0.09146, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:40.837, tt:1020.928\n",
      "Ep:25, loss:0.00014, loss_test:0.09049, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.843, tt:1061.909\n",
      "Ep:26, loss:0.00014, loss_test:0.09040, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.804, tt:1101.718\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00013, loss_test:0.08848, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:40.813, tt:1142.760\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08966, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:40.854, tt:1184.767\n",
      "Ep:29, loss:0.00013, loss_test:0.08798, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:40.969, tt:1229.057\n",
      "Ep:30, loss:0.00012, loss_test:0.08876, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:40.977, tt:1270.288\n",
      "Ep:31, loss:0.00012, loss_test:0.08654, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:40.951, tt:1310.428\n",
      "Ep:32, loss:0.00012, loss_test:0.08672, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:40.928, tt:1350.620\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08742, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:40.941, tt:1391.991\n",
      "Ep:34, loss:0.00011, loss_test:0.08572, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:41.016, tt:1435.563\n",
      "Ep:35, loss:0.00011, loss_test:0.08571, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:41.002, tt:1476.071\n",
      "Ep:36, loss:0.00011, loss_test:0.08748, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:41.014, tt:1517.535\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08569, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:41.059, tt:1560.249\n",
      "Ep:38, loss:0.00010, loss_test:0.08307, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:41.027, tt:1600.049\n",
      "Ep:39, loss:0.00010, loss_test:0.08470, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.130, tt:1645.206\n",
      "Ep:40, loss:0.00010, loss_test:0.08326, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:41.228, tt:1690.364\n",
      "Ep:41, loss:0.00010, loss_test:0.08446, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:41.237, tt:1731.957\n",
      "Ep:42, loss:0.00010, loss_test:0.08763, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:41.162, tt:1769.945\n",
      "Ep:43, loss:0.00009, loss_test:0.08033, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:41.176, tt:1811.744\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.08549, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:41.177, tt:1852.959\n",
      "Ep:45, loss:0.00009, loss_test:0.08036, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:41.152, tt:1892.973\n",
      "Ep:46, loss:0.00009, loss_test:0.08330, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.139, tt:1933.536\n",
      "Ep:47, loss:0.00009, loss_test:0.07846, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.133, tt:1974.364\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.08053, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:41.164, tt:2017.041\n",
      "Ep:49, loss:0.00008, loss_test:0.08243, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.106, tt:2055.324\n",
      "Ep:50, loss:0.00008, loss_test:0.08456, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:41.075, tt:2094.835\n",
      "Ep:51, loss:0.00008, loss_test:0.08026, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:41.032, tt:2133.671\n",
      "Ep:52, loss:0.00008, loss_test:0.07724, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:41.017, tt:2173.922\n",
      "Ep:53, loss:0.00008, loss_test:0.08058, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.006, tt:2214.312\n",
      "Ep:54, loss:0.00007, loss_test:0.07947, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:40.996, tt:2254.795\n",
      "Ep:55, loss:0.00007, loss_test:0.07728, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:41.018, tt:2297.007\n",
      "Ep:56, loss:0.00007, loss_test:0.07602, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:41.023, tt:2338.302\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.07892, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.000, tt:2377.975\n",
      "Ep:58, loss:0.00007, loss_test:0.08611, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:40.979, tt:2417.734\n",
      "Ep:59, loss:0.00007, loss_test:0.08342, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:40.984, tt:2459.058\n",
      "Ep:60, loss:0.00007, loss_test:0.07415, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.013, tt:2501.803\n",
      "Ep:61, loss:0.00007, loss_test:0.07374, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:41.034, tt:2544.130\n",
      "Ep:62, loss:0.00006, loss_test:0.08484, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.081, tt:2588.118\n",
      "Ep:63, loss:0.00006, loss_test:0.07354, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:41.098, tt:2630.258\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.07596, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:41.119, tt:2672.738\n",
      "Ep:65, loss:0.00006, loss_test:0.08281, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:41.142, tt:2715.386\n",
      "Ep:66, loss:0.00007, loss_test:0.07536, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:41.177, tt:2758.853\n",
      "Ep:67, loss:0.00006, loss_test:0.07256, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:41.172, tt:2799.723\n",
      "Ep:68, loss:0.00007, loss_test:0.08223, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:41.211, tt:2843.542\n",
      "Ep:69, loss:0.00006, loss_test:0.07135, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:41.224, tt:2885.682\n",
      "Ep:70, loss:0.00006, loss_test:0.07230, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:41.258, tt:2929.312\n",
      "Ep:71, loss:0.00005, loss_test:0.07983, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:41.287, tt:2972.635\n",
      "Ep:72, loss:0.00005, loss_test:0.07117, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:41.317, tt:3016.146\n",
      "Ep:73, loss:0.00005, loss_test:0.07775, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:41.328, tt:3058.301\n",
      "Ep:74, loss:0.00005, loss_test:0.07114, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.340, tt:3100.482\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.07368, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:41.401, tt:3146.456\n",
      "Ep:76, loss:0.00005, loss_test:0.07082, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.455, tt:3192.065\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.07034, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:41.490, tt:3236.224\n",
      "Ep:78, loss:0.00005, loss_test:0.07615, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:41.540, tt:3281.670\n",
      "Ep:79, loss:0.00005, loss_test:0.07402, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:41.557, tt:3324.521\n",
      "Ep:80, loss:0.00004, loss_test:0.07194, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.596, tt:3369.309\n",
      "Ep:81, loss:0.00004, loss_test:0.07547, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:41.621, tt:3412.907\n",
      "Ep:82, loss:0.00004, loss_test:0.06783, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.651, tt:3457.052\n",
      "Ep:83, loss:0.00004, loss_test:0.08256, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:41.652, tt:3498.781\n",
      "Ep:84, loss:0.00005, loss_test:0.07140, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:41.620, tt:3537.661\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.06794, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:41.608, tt:3578.250\n",
      "Ep:86, loss:0.00004, loss_test:0.08042, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:41.539, tt:3613.858\n",
      "Ep:87, loss:0.00004, loss_test:0.06633, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:41.582, tt:3659.229\n",
      "Ep:88, loss:0.00004, loss_test:0.07684, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:41.632, tt:3705.249\n",
      "Ep:89, loss:0.00004, loss_test:0.06893, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:41.664, tt:3749.765\n",
      "Ep:90, loss:0.00004, loss_test:0.06911, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:41.707, tt:3795.331\n",
      "Ep:91, loss:0.00004, loss_test:0.07018, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:41.730, tt:3839.156\n",
      "Ep:92, loss:0.00003, loss_test:0.07022, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:41.740, tt:3881.776\n",
      "Ep:93, loss:0.00004, loss_test:0.07026, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.750, tt:3924.463\n",
      "Ep:94, loss:0.00003, loss_test:0.07473, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:41.788, tt:3969.906\n",
      "Ep:95, loss:0.00003, loss_test:0.06597, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:41.818, tt:4014.539\n",
      "Ep:96, loss:0.00003, loss_test:0.07689, lr:9.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:41.839, tt:4058.374\n",
      "Ep:97, loss:0.00003, loss_test:0.06615, lr:9.80e-03, fs:0.88442 (r=0.889,p=0.880),  time:41.887, tt:4104.942\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:98, loss:0.00003, loss_test:0.06492, lr:9.80e-03, fs:0.89119 (r=0.869,p=0.915),  time:41.904, tt:4148.505\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00003, loss_test:0.07578, lr:9.80e-03, fs:0.79144 (r=0.747,p=0.841),  time:41.965, tt:4196.498\n",
      "Ep:100, loss:0.00003, loss_test:0.06520, lr:9.80e-03, fs:0.89119 (r=0.869,p=0.915),  time:41.982, tt:4240.137\n",
      "Ep:101, loss:0.00003, loss_test:0.07843, lr:9.80e-03, fs:0.75138 (r=0.687,p=0.829),  time:42.021, tt:4286.101\n",
      "Ep:102, loss:0.00003, loss_test:0.06723, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:42.039, tt:4330.037\n",
      "Ep:103, loss:0.00003, loss_test:0.07239, lr:9.80e-03, fs:0.79781 (r=0.737,p=0.869),  time:42.063, tt:4374.579\n",
      "Ep:104, loss:0.00003, loss_test:0.06867, lr:9.80e-03, fs:0.88660 (r=0.869,p=0.905),  time:42.080, tt:4418.351\n",
      "Ep:105, loss:0.00003, loss_test:0.06689, lr:9.80e-03, fs:0.89796 (r=0.889,p=0.907),  time:42.097, tt:4462.312\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00003, loss_test:0.07071, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:42.114, tt:4506.199\n",
      "Ep:107, loss:0.00003, loss_test:0.06775, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:42.145, tt:4551.708\n",
      "Ep:108, loss:0.00003, loss_test:0.07168, lr:9.80e-03, fs:0.85128 (r=0.838,p=0.865),  time:42.147, tt:4594.075\n",
      "Ep:109, loss:0.00003, loss_test:0.07166, lr:9.80e-03, fs:0.75145 (r=0.657,p=0.878),  time:42.167, tt:4638.360\n",
      "Ep:110, loss:0.00003, loss_test:0.07361, lr:9.80e-03, fs:0.82979 (r=0.788,p=0.876),  time:42.171, tt:4680.928\n",
      "Ep:111, loss:0.00002, loss_test:0.06822, lr:9.80e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.203, tt:4726.744\n",
      "Ep:112, loss:0.00002, loss_test:0.07811, lr:9.80e-03, fs:0.73034 (r=0.657,p=0.823),  time:42.235, tt:4772.516\n",
      "Ep:113, loss:0.00002, loss_test:0.07074, lr:9.80e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.253, tt:4816.858\n",
      "Ep:114, loss:0.00002, loss_test:0.06992, lr:9.80e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.273, tt:4861.389\n",
      "Ep:115, loss:0.00002, loss_test:0.08026, lr:9.80e-03, fs:0.74444 (r=0.677,p=0.827),  time:42.304, tt:4907.284\n",
      "Ep:116, loss:0.00003, loss_test:0.06861, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:42.334, tt:4953.023\n",
      "Ep:117, loss:0.00003, loss_test:0.06501, lr:9.70e-03, fs:0.90323 (r=0.848,p=0.966),  time:42.369, tt:4999.582\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00003, loss_test:0.08350, lr:9.70e-03, fs:0.77174 (r=0.717,p=0.835),  time:42.383, tt:5043.636\n",
      "Ep:119, loss:0.00002, loss_test:0.06661, lr:9.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:42.406, tt:5088.728\n",
      "Ep:120, loss:0.00002, loss_test:0.08151, lr:9.70e-03, fs:0.76923 (r=0.707,p=0.843),  time:42.410, tt:5131.579\n",
      "Ep:121, loss:0.00002, loss_test:0.07198, lr:9.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:42.415, tt:5174.683\n",
      "Ep:122, loss:0.00002, loss_test:0.07847, lr:9.70e-03, fs:0.81915 (r=0.778,p=0.865),  time:42.430, tt:5218.946\n",
      "Ep:123, loss:0.00002, loss_test:0.07352, lr:9.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.444, tt:5263.007\n",
      "Ep:124, loss:0.00002, loss_test:0.07448, lr:9.70e-03, fs:0.80663 (r=0.737,p=0.890),  time:42.463, tt:5307.861\n",
      "Ep:125, loss:0.00002, loss_test:0.06691, lr:9.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:42.484, tt:5353.003\n",
      "Ep:126, loss:0.00002, loss_test:0.08248, lr:9.70e-03, fs:0.74286 (r=0.657,p=0.855),  time:42.515, tt:5399.366\n",
      "Ep:127, loss:0.00002, loss_test:0.06432, lr:9.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:42.531, tt:5443.907\n",
      "Ep:128, loss:0.00002, loss_test:0.07794, lr:9.70e-03, fs:0.75145 (r=0.657,p=0.878),  time:42.535, tt:5487.078\n",
      "Ep:129, loss:0.00002, loss_test:0.06796, lr:9.61e-03, fs:0.86631 (r=0.818,p=0.920),  time:42.603, tt:5538.382\n",
      "Ep:130, loss:0.00002, loss_test:0.07639, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:42.621, tt:5583.396\n",
      "Ep:131, loss:0.00002, loss_test:0.06799, lr:9.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.641, tt:5628.665\n",
      "Ep:132, loss:0.00002, loss_test:0.07445, lr:9.32e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.643, tt:5671.521\n",
      "Ep:133, loss:0.00002, loss_test:0.07093, lr:9.23e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.652, tt:5715.364\n",
      "Ep:134, loss:0.00002, loss_test:0.07922, lr:9.14e-03, fs:0.74118 (r=0.636,p=0.887),  time:42.681, tt:5761.939\n",
      "Ep:135, loss:0.00002, loss_test:0.06739, lr:9.04e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.697, tt:5806.858\n",
      "Ep:136, loss:0.00002, loss_test:0.07941, lr:8.95e-03, fs:0.74286 (r=0.657,p=0.855),  time:42.703, tt:5850.316\n",
      "Ep:137, loss:0.00002, loss_test:0.06770, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:42.730, tt:5896.748\n",
      "Ep:138, loss:0.00002, loss_test:0.07947, lr:8.78e-03, fs:0.74713 (r=0.657,p=0.867),  time:42.735, tt:5940.211\n",
      "Ep:139, loss:0.00002, loss_test:0.06688, lr:8.69e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.753, tt:5985.376\n",
      "Ep:140, loss:0.00002, loss_test:0.07869, lr:8.60e-03, fs:0.73988 (r=0.646,p=0.865),  time:42.760, tt:6029.158\n",
      "Ep:141, loss:0.00002, loss_test:0.07054, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.773, tt:6073.721\n",
      "Ep:142, loss:0.00002, loss_test:0.07506, lr:8.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:42.775, tt:6116.769\n",
      "Ep:143, loss:0.00002, loss_test:0.06923, lr:8.35e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.774, tt:6159.400\n",
      "Ep:144, loss:0.00002, loss_test:0.07371, lr:8.26e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.788, tt:6204.234\n",
      "Ep:145, loss:0.00002, loss_test:0.07054, lr:8.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:42.792, tt:6247.625\n",
      "Ep:146, loss:0.00002, loss_test:0.07301, lr:8.10e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.804, tt:6292.179\n",
      "Ep:147, loss:0.00001, loss_test:0.07210, lr:8.02e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.780, tt:6331.475\n",
      "Ep:148, loss:0.00001, loss_test:0.07314, lr:7.94e-03, fs:0.74699 (r=0.626,p=0.925),  time:42.778, tt:6373.922\n",
      "Ep:149, loss:0.00001, loss_test:0.07386, lr:7.86e-03, fs:0.77011 (r=0.677,p=0.893),  time:42.755, tt:6413.207\n",
      "Ep:150, loss:0.00001, loss_test:0.07227, lr:7.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:42.774, tt:6458.851\n",
      "Ep:151, loss:0.00001, loss_test:0.07302, lr:7.70e-03, fs:0.75449 (r=0.636,p=0.926),  time:42.777, tt:6502.142\n",
      "Ep:152, loss:0.00001, loss_test:0.07279, lr:7.62e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.781, tt:6545.510\n",
      "Ep:153, loss:0.00001, loss_test:0.07120, lr:7.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.801, tt:6591.301\n",
      "Ep:154, loss:0.00001, loss_test:0.07593, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:42.784, tt:6631.524\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14085, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:19.147, tt:19.147\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13906, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:19.424, tt:38.848\n",
      "Ep:2, loss:0.00027, loss_test:0.13560, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:19.893, tt:59.680\n",
      "Ep:3, loss:0.00026, loss_test:0.13019, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:19.686, tt:78.743\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12377, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:19.598, tt:97.992\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11820, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:19.449, tt:116.694\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11330, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:19.106, tt:133.742\n",
      "Ep:7, loss:0.00024, loss_test:0.10998, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:19.211, tt:153.689\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00023, loss_test:0.10797, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:19.473, tt:175.257\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10531, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:19.755, tt:197.555\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10202, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:19.536, tt:214.897\n",
      "Ep:11, loss:0.00021, loss_test:0.09944, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:19.472, tt:233.660\n",
      "Ep:12, loss:0.00020, loss_test:0.09738, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:19.342, tt:251.452\n",
      "Ep:13, loss:0.00020, loss_test:0.09526, lr:1.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:19.278, tt:269.888\n",
      "Ep:14, loss:0.00019, loss_test:0.09249, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:19.254, tt:288.815\n",
      "Ep:15, loss:0.00018, loss_test:0.09007, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:19.274, tt:308.387\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08803, lr:1.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:19.170, tt:325.891\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08620, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:19.119, tt:344.139\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08422, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:19.048, tt:361.905\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08276, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:19.026, tt:380.514\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08232, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:19.020, tt:399.411\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08066, lr:1.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:18.952, tt:416.936\n",
      "Ep:22, loss:0.00015, loss_test:0.08089, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:18.895, tt:434.576\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07921, lr:1.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:18.888, tt:453.313\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07882, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:18.860, tt:471.488\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07786, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:18.873, tt:490.710\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07622, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:18.865, tt:509.362\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07500, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:18.819, tt:526.930\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07547, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:18.789, tt:544.872\n",
      "Ep:29, loss:0.00012, loss_test:0.07360, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:18.823, tt:564.676\n",
      "Ep:30, loss:0.00012, loss_test:0.07307, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:18.787, tt:582.388\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07279, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:18.775, tt:600.814\n",
      "Ep:32, loss:0.00011, loss_test:0.07136, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:18.856, tt:622.256\n",
      "Ep:33, loss:0.00011, loss_test:0.07201, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:18.898, tt:642.548\n",
      "Ep:34, loss:0.00010, loss_test:0.07083, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:18.928, tt:662.484\n",
      "Ep:35, loss:0.00010, loss_test:0.07105, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:18.909, tt:680.708\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.06841, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:18.914, tt:699.817\n",
      "Ep:37, loss:0.00009, loss_test:0.06786, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:18.970, tt:720.850\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.06725, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:19.026, tt:742.011\n",
      "Ep:39, loss:0.00009, loss_test:0.06644, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:19.089, tt:763.551\n",
      "Ep:40, loss:0.00008, loss_test:0.06591, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:19.110, tt:783.523\n",
      "Ep:41, loss:0.00008, loss_test:0.06470, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:19.177, tt:805.447\n",
      "Ep:42, loss:0.00008, loss_test:0.06537, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:19.155, tt:823.682\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.06415, lr:1.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:19.186, tt:844.165\n",
      "Ep:44, loss:0.00007, loss_test:0.06495, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:19.209, tt:864.420\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.06350, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:19.163, tt:881.483\n",
      "Ep:46, loss:0.00007, loss_test:0.06295, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:19.175, tt:901.247\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.06413, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:19.175, tt:920.416\n",
      "Ep:48, loss:0.00006, loss_test:0.06138, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:19.154, tt:938.547\n",
      "Ep:49, loss:0.00006, loss_test:0.06099, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:19.165, tt:958.251\n",
      "Ep:50, loss:0.00006, loss_test:0.06165, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:19.162, tt:977.286\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.06034, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:19.128, tt:994.648\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.06459, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:19.086, tt:1011.570\n",
      "Ep:53, loss:0.00005, loss_test:0.05941, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:19.080, tt:1030.330\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.06071, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:19.066, tt:1048.603\n",
      "Ep:55, loss:0.00005, loss_test:0.06113, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:19.057, tt:1067.187\n",
      "Ep:56, loss:0.00005, loss_test:0.06035, lr:1.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:19.019, tt:1084.071\n",
      "Ep:57, loss:0.00005, loss_test:0.05767, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:19.039, tt:1104.285\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.05773, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:19.055, tt:1124.269\n",
      "Ep:59, loss:0.00004, loss_test:0.05967, lr:1.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:19.053, tt:1143.188\n",
      "Ep:60, loss:0.00005, loss_test:0.05847, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:19.038, tt:1161.300\n",
      "Ep:61, loss:0.00004, loss_test:0.05685, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:19.039, tt:1180.403\n",
      "Ep:62, loss:0.00004, loss_test:0.05703, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:19.050, tt:1200.168\n",
      "Ep:63, loss:0.00004, loss_test:0.05676, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:19.083, tt:1221.336\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.05458, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:19.137, tt:1243.920\n",
      "Ep:65, loss:0.00004, loss_test:0.05937, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:19.176, tt:1265.620\n",
      "Ep:66, loss:0.00004, loss_test:0.05431, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:19.178, tt:1284.902\n",
      "Ep:67, loss:0.00004, loss_test:0.05687, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:19.170, tt:1303.583\n",
      "Ep:68, loss:0.00004, loss_test:0.05341, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:19.162, tt:1322.173\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.05549, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:19.175, tt:1342.237\n",
      "Ep:70, loss:0.00004, loss_test:0.05333, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:19.187, tt:1362.256\n",
      "Ep:71, loss:0.00003, loss_test:0.05267, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:19.185, tt:1381.319\n",
      "Ep:72, loss:0.00003, loss_test:0.05288, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:19.185, tt:1400.535\n",
      "Ep:73, loss:0.00003, loss_test:0.05495, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:19.182, tt:1419.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00003, loss_test:0.05413, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:19.178, tt:1438.331\n",
      "Ep:75, loss:0.00003, loss_test:0.05210, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:19.206, tt:1459.668\n",
      "Ep:76, loss:0.00003, loss_test:0.05372, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:19.192, tt:1477.761\n",
      "Ep:77, loss:0.00003, loss_test:0.05395, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:19.176, tt:1495.690\n",
      "Ep:78, loss:0.00003, loss_test:0.05193, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:19.157, tt:1513.441\n",
      "Ep:79, loss:0.00003, loss_test:0.05409, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:19.170, tt:1533.585\n",
      "Ep:80, loss:0.00003, loss_test:0.05366, lr:9.90e-03, fs:0.85859 (r=0.859,p=0.859),  time:19.192, tt:1554.514\n",
      "Ep:81, loss:0.00003, loss_test:0.05144, lr:9.80e-03, fs:0.87685 (r=0.899,p=0.856),  time:19.195, tt:1574.015\n",
      "Ep:82, loss:0.00003, loss_test:0.05289, lr:9.70e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.175, tt:1591.567\n",
      "Ep:83, loss:0.00003, loss_test:0.05290, lr:9.61e-03, fs:0.87685 (r=0.899,p=0.856),  time:19.213, tt:1613.887\n",
      "Ep:84, loss:0.00003, loss_test:0.05309, lr:9.51e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.236, tt:1635.054\n",
      "Ep:85, loss:0.00003, loss_test:0.05213, lr:9.41e-03, fs:0.91346 (r=0.960,p=0.872),  time:19.230, tt:1653.760\n",
      "Ep:86, loss:0.00003, loss_test:0.05449, lr:9.32e-03, fs:0.86869 (r=0.869,p=0.869),  time:19.209, tt:1671.192\n",
      "Ep:87, loss:0.00003, loss_test:0.05373, lr:9.23e-03, fs:0.87437 (r=0.879,p=0.870),  time:19.214, tt:1690.859\n",
      "Ep:88, loss:0.00003, loss_test:0.04945, lr:9.14e-03, fs:0.91707 (r=0.949,p=0.887),  time:19.224, tt:1710.956\n",
      "Ep:89, loss:0.00003, loss_test:0.05979, lr:9.04e-03, fs:0.85128 (r=0.838,p=0.865),  time:19.215, tt:1729.384\n",
      "Ep:90, loss:0.00003, loss_test:0.04911, lr:8.95e-03, fs:0.92233 (r=0.960,p=0.888),  time:19.202, tt:1747.383\n",
      "Ep:91, loss:0.00003, loss_test:0.05805, lr:8.86e-03, fs:0.86000 (r=0.869,p=0.851),  time:19.200, tt:1766.418\n",
      "Ep:92, loss:0.00002, loss_test:0.05008, lr:8.78e-03, fs:0.87879 (r=0.879,p=0.879),  time:19.185, tt:1784.223\n",
      "Ep:93, loss:0.00002, loss_test:0.05516, lr:8.69e-03, fs:0.86432 (r=0.869,p=0.860),  time:19.173, tt:1802.240\n",
      "Ep:94, loss:0.00002, loss_test:0.04982, lr:8.60e-03, fs:0.90000 (r=0.909,p=0.891),  time:19.167, tt:1820.889\n",
      "Ep:95, loss:0.00002, loss_test:0.05416, lr:8.51e-03, fs:0.86000 (r=0.869,p=0.851),  time:19.171, tt:1840.424\n",
      "Ep:96, loss:0.00002, loss_test:0.05032, lr:8.43e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.159, tt:1858.383\n",
      "Ep:97, loss:0.00002, loss_test:0.05463, lr:8.35e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.161, tt:1877.825\n",
      "Ep:98, loss:0.00002, loss_test:0.05115, lr:8.26e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.141, tt:1894.916\n",
      "Ep:99, loss:0.00002, loss_test:0.05344, lr:8.18e-03, fs:0.85714 (r=0.848,p=0.866),  time:19.120, tt:1912.019\n",
      "Ep:100, loss:0.00002, loss_test:0.05238, lr:8.10e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.112, tt:1930.346\n",
      "Ep:101, loss:0.00002, loss_test:0.05299, lr:8.02e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.121, tt:1950.390\n",
      "Ep:102, loss:0.00002, loss_test:0.05336, lr:7.94e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.121, tt:1969.496\n",
      "Ep:103, loss:0.00002, loss_test:0.05135, lr:7.86e-03, fs:0.88000 (r=0.889,p=0.871),  time:19.106, tt:1986.975\n",
      "Ep:104, loss:0.00002, loss_test:0.05378, lr:7.78e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.105, tt:2005.987\n",
      "Ep:105, loss:0.00002, loss_test:0.05218, lr:7.70e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.121, tt:2026.854\n",
      "Ep:106, loss:0.00002, loss_test:0.05216, lr:7.62e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.147, tt:2048.781\n",
      "Ep:107, loss:0.00002, loss_test:0.05301, lr:7.55e-03, fs:0.86598 (r=0.848,p=0.884),  time:19.134, tt:2066.462\n",
      "Ep:108, loss:0.00002, loss_test:0.05070, lr:7.47e-03, fs:0.88660 (r=0.869,p=0.905),  time:19.122, tt:2084.276\n",
      "Ep:109, loss:0.00002, loss_test:0.05399, lr:7.40e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.131, tt:2104.391\n",
      "Ep:110, loss:0.00002, loss_test:0.05128, lr:7.32e-03, fs:0.88205 (r=0.869,p=0.896),  time:19.116, tt:2121.916\n",
      "Ep:111, loss:0.00002, loss_test:0.05362, lr:7.25e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.102, tt:2139.432\n",
      "Ep:112, loss:0.00002, loss_test:0.05283, lr:7.18e-03, fs:0.87500 (r=0.848,p=0.903),  time:19.089, tt:2157.042\n",
      "Ep:113, loss:0.00002, loss_test:0.05160, lr:7.11e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.095, tt:2176.786\n",
      "Ep:114, loss:0.00002, loss_test:0.05286, lr:7.03e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.085, tt:2194.827\n",
      "Ep:115, loss:0.00002, loss_test:0.05206, lr:6.96e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.093, tt:2214.841\n",
      "Ep:116, loss:0.00002, loss_test:0.05201, lr:6.89e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.110, tt:2235.844\n",
      "Ep:117, loss:0.00001, loss_test:0.05195, lr:6.83e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.129, tt:2257.250\n",
      "Ep:118, loss:0.00001, loss_test:0.05301, lr:6.76e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.126, tt:2275.986\n",
      "Ep:119, loss:0.00001, loss_test:0.05116, lr:6.69e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.112, tt:2293.434\n",
      "Ep:120, loss:0.00001, loss_test:0.05290, lr:6.62e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.092, tt:2310.129\n",
      "Ep:121, loss:0.00001, loss_test:0.05249, lr:6.56e-03, fs:0.87047 (r=0.848,p=0.894),  time:19.100, tt:2330.244\n",
      "Ep:122, loss:0.00001, loss_test:0.05118, lr:6.49e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.100, tt:2349.344\n",
      "Ep:123, loss:0.00001, loss_test:0.05260, lr:6.43e-03, fs:0.86598 (r=0.848,p=0.884),  time:19.112, tt:2369.843\n",
      "Ep:124, loss:0.00001, loss_test:0.05169, lr:6.36e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.108, tt:2388.537\n",
      "Ep:125, loss:0.00001, loss_test:0.05188, lr:6.30e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.102, tt:2406.861\n",
      "Ep:126, loss:0.00001, loss_test:0.05258, lr:6.24e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.092, tt:2424.668\n",
      "Ep:127, loss:0.00001, loss_test:0.05225, lr:6.17e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.088, tt:2443.236\n",
      "Ep:128, loss:0.00001, loss_test:0.05231, lr:6.11e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.079, tt:2461.179\n",
      "Ep:129, loss:0.00001, loss_test:0.05259, lr:6.05e-03, fs:0.88421 (r=0.848,p=0.923),  time:19.083, tt:2480.841\n",
      "Ep:130, loss:0.00001, loss_test:0.05094, lr:5.99e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.070, tt:2498.177\n",
      "Ep:131, loss:0.00001, loss_test:0.05243, lr:5.93e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.078, tt:2518.252\n",
      "Ep:132, loss:0.00001, loss_test:0.05226, lr:5.87e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.067, tt:2535.871\n",
      "Ep:133, loss:0.00001, loss_test:0.05208, lr:5.81e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.079, tt:2556.567\n",
      "Ep:134, loss:0.00001, loss_test:0.05299, lr:5.75e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.087, tt:2576.734\n",
      "Ep:135, loss:0.00001, loss_test:0.05221, lr:5.70e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.080, tt:2594.901\n",
      "Ep:136, loss:0.00001, loss_test:0.05194, lr:5.64e-03, fs:0.89005 (r=0.859,p=0.924),  time:19.041, tt:2608.614\n",
      "Ep:137, loss:0.00001, loss_test:0.05229, lr:5.58e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.006, tt:2622.884\n",
      "Ep:138, loss:0.00001, loss_test:0.05191, lr:5.53e-03, fs:0.89005 (r=0.859,p=0.924),  time:19.010, tt:2642.401\n",
      "Ep:139, loss:0.00001, loss_test:0.05309, lr:5.47e-03, fs:0.88889 (r=0.848,p=0.933),  time:19.004, tt:2660.607\n",
      "Ep:140, loss:0.00001, loss_test:0.05286, lr:5.42e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.978, tt:2675.900\n",
      "Ep:141, loss:0.00001, loss_test:0.05371, lr:5.36e-03, fs:0.87958 (r=0.848,p=0.913),  time:18.942, tt:2689.822\n",
      "Ep:142, loss:0.00001, loss_test:0.05241, lr:5.31e-03, fs:0.88421 (r=0.848,p=0.923),  time:18.926, tt:2706.431\n",
      "Ep:143, loss:0.00001, loss_test:0.05228, lr:5.26e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.911, tt:2723.229\n",
      "Ep:144, loss:0.00001, loss_test:0.05296, lr:5.20e-03, fs:0.88421 (r=0.848,p=0.923),  time:18.901, tt:2740.689\n",
      "Ep:145, loss:0.00001, loss_test:0.05281, lr:5.15e-03, fs:0.88542 (r=0.859,p=0.914),  time:18.918, tt:2762.029\n",
      "Ep:146, loss:0.00001, loss_test:0.05221, lr:5.10e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.918, tt:2781.013\n",
      "Ep:147, loss:0.00001, loss_test:0.05375, lr:5.05e-03, fs:0.87958 (r=0.848,p=0.913),  time:18.913, tt:2799.172\n",
      "Ep:148, loss:0.00001, loss_test:0.05225, lr:5.00e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.899, tt:2816.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:149, loss:0.00001, loss_test:0.05310, lr:4.95e-03, fs:0.88421 (r=0.848,p=0.923),  time:18.901, tt:2835.169\n",
      "Ep:150, loss:0.00001, loss_test:0.05297, lr:4.90e-03, fs:0.89362 (r=0.848,p=0.944),  time:18.889, tt:2852.276\n",
      "Ep:151, loss:0.00001, loss_test:0.05289, lr:4.85e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.882, tt:2870.138\n",
      "Ep:152, loss:0.00001, loss_test:0.05306, lr:4.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.882, tt:2889.000\n",
      "Ep:153, loss:0.00001, loss_test:0.05318, lr:4.75e-03, fs:0.88421 (r=0.848,p=0.923),  time:18.869, tt:2905.768\n",
      "Ep:154, loss:0.00001, loss_test:0.05325, lr:4.71e-03, fs:0.89005 (r=0.859,p=0.924),  time:18.844, tt:2920.896\n",
      "Ep:155, loss:0.00001, loss_test:0.05325, lr:4.66e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.832, tt:2937.763\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13399, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:20.824, tt:20.824\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12743, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:20.710, tt:41.420\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11929, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:20.744, tt:62.231\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11583, lr:1.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:20.922, tt:83.690\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11432, lr:1.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:20.663, tt:103.317\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11388, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:20.775, tt:124.652\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11127, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:20.690, tt:144.832\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10775, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:20.634, tt:165.071\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10489, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:20.519, tt:184.667\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10310, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:20.479, tt:204.793\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10184, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:20.602, tt:226.623\n",
      "Ep:11, loss:0.00019, loss_test:0.09969, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:20.622, tt:247.466\n",
      "Ep:12, loss:0.00018, loss_test:0.09798, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:20.740, tt:269.625\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09506, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:20.676, tt:289.461\n",
      "Ep:14, loss:0.00017, loss_test:0.09391, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:20.815, tt:312.229\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09140, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:21.053, tt:336.846\n",
      "Ep:16, loss:0.00015, loss_test:0.08993, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:21.092, tt:358.558\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08816, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:21.150, tt:380.699\n",
      "Ep:18, loss:0.00014, loss_test:0.08604, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:21.195, tt:402.707\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08456, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:21.139, tt:422.780\n",
      "Ep:20, loss:0.00013, loss_test:0.08315, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:21.079, tt:442.649\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08058, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:21.075, tt:463.644\n",
      "Ep:22, loss:0.00012, loss_test:0.07978, lr:1.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:21.144, tt:486.321\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07931, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:21.344, tt:512.249\n",
      "Ep:24, loss:0.00011, loss_test:0.07862, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:21.400, tt:535.004\n",
      "Ep:25, loss:0.00011, loss_test:0.07646, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:21.496, tt:558.895\n",
      "Ep:26, loss:0.00010, loss_test:0.07532, lr:1.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:21.563, tt:582.202\n",
      "Ep:27, loss:0.00010, loss_test:0.07360, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:21.575, tt:604.114\n",
      "Ep:28, loss:0.00010, loss_test:0.07458, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:21.560, tt:625.238\n",
      "Ep:29, loss:0.00009, loss_test:0.07258, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:21.574, tt:647.205\n",
      "Ep:30, loss:0.00009, loss_test:0.07034, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:21.639, tt:670.809\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07236, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:21.781, tt:697.005\n",
      "Ep:32, loss:0.00008, loss_test:0.07058, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:21.861, tt:721.424\n",
      "Ep:33, loss:0.00008, loss_test:0.06963, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:21.878, tt:743.858\n",
      "Ep:34, loss:0.00008, loss_test:0.06955, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:21.913, tt:766.949\n",
      "Ep:35, loss:0.00008, loss_test:0.06891, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:21.885, tt:787.853\n",
      "Ep:36, loss:0.00007, loss_test:0.06862, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:21.927, tt:811.281\n",
      "Ep:37, loss:0.00007, loss_test:0.06869, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:21.940, tt:833.728\n",
      "Ep:38, loss:0.00007, loss_test:0.06784, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:21.895, tt:853.924\n",
      "Ep:39, loss:0.00007, loss_test:0.06812, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:21.855, tt:874.212\n",
      "Ep:40, loss:0.00006, loss_test:0.06944, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:21.815, tt:894.423\n",
      "Ep:41, loss:0.00006, loss_test:0.06745, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:21.784, tt:914.944\n",
      "Ep:42, loss:0.00006, loss_test:0.06835, lr:9.90e-03, fs:0.80203 (r=0.798,p=0.806),  time:21.758, tt:935.592\n",
      "Ep:43, loss:0.00006, loss_test:0.06704, lr:9.80e-03, fs:0.81407 (r=0.818,p=0.810),  time:21.738, tt:956.493\n",
      "Ep:44, loss:0.00006, loss_test:0.06925, lr:9.70e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.742, tt:978.413\n",
      "Ep:45, loss:0.00005, loss_test:0.06688, lr:9.61e-03, fs:0.81818 (r=0.818,p=0.818),  time:21.717, tt:998.968\n",
      "Ep:46, loss:0.00005, loss_test:0.06731, lr:9.51e-03, fs:0.81443 (r=0.798,p=0.832),  time:21.784, tt:1023.849\n",
      "Ep:47, loss:0.00005, loss_test:0.06760, lr:9.41e-03, fs:0.81000 (r=0.818,p=0.802),  time:21.738, tt:1043.405\n",
      "Ep:48, loss:0.00005, loss_test:0.06926, lr:9.32e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.709, tt:1063.752\n",
      "Ep:49, loss:0.00005, loss_test:0.06610, lr:9.23e-03, fs:0.80402 (r=0.808,p=0.800),  time:21.709, tt:1085.470\n",
      "Ep:50, loss:0.00005, loss_test:0.06859, lr:9.14e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.702, tt:1106.821\n",
      "Ep:51, loss:0.00005, loss_test:0.06795, lr:9.04e-03, fs:0.80203 (r=0.798,p=0.806),  time:21.683, tt:1127.515\n",
      "Ep:52, loss:0.00005, loss_test:0.06751, lr:8.95e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.687, tt:1149.403\n",
      "Ep:53, loss:0.00004, loss_test:0.06665, lr:8.86e-03, fs:0.80203 (r=0.798,p=0.806),  time:21.653, tt:1169.252\n",
      "Ep:54, loss:0.00004, loss_test:0.06778, lr:8.78e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.654, tt:1190.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00004, loss_test:0.06647, lr:8.69e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.653, tt:1212.561\n",
      "Ep:56, loss:0.00004, loss_test:0.06799, lr:8.60e-03, fs:0.81443 (r=0.798,p=0.832),  time:21.629, tt:1232.830\n",
      "Ep:57, loss:0.00004, loss_test:0.06748, lr:8.51e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.611, tt:1253.428\n",
      "Ep:58, loss:0.00004, loss_test:0.06690, lr:8.43e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.610, tt:1275.012\n",
      "Ep:59, loss:0.00004, loss_test:0.06762, lr:8.35e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.646, tt:1298.779\n",
      "Ep:60, loss:0.00004, loss_test:0.06761, lr:8.26e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.656, tt:1321.023\n",
      "Ep:61, loss:0.00004, loss_test:0.06700, lr:8.18e-03, fs:0.81443 (r=0.798,p=0.832),  time:21.635, tt:1341.379\n",
      "Ep:62, loss:0.00004, loss_test:0.06780, lr:8.10e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.629, tt:1362.611\n",
      "Ep:63, loss:0.00004, loss_test:0.06676, lr:8.02e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.632, tt:1384.430\n",
      "Ep:64, loss:0.00004, loss_test:0.06720, lr:7.94e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.666, tt:1408.282\n",
      "Ep:65, loss:0.00003, loss_test:0.06708, lr:7.86e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.638, tt:1428.087\n",
      "Ep:66, loss:0.00003, loss_test:0.06718, lr:7.78e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.600, tt:1447.193\n",
      "Ep:67, loss:0.00003, loss_test:0.06634, lr:7.70e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.587, tt:1467.908\n",
      "Ep:68, loss:0.00003, loss_test:0.06704, lr:7.62e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.556, tt:1487.373\n",
      "Ep:69, loss:0.00003, loss_test:0.06620, lr:7.55e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.527, tt:1506.883\n",
      "Ep:70, loss:0.00003, loss_test:0.06574, lr:7.47e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.515, tt:1527.578\n",
      "Ep:71, loss:0.00003, loss_test:0.06606, lr:7.40e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.520, tt:1549.459\n",
      "Ep:72, loss:0.00003, loss_test:0.06614, lr:7.32e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.499, tt:1569.402\n",
      "Ep:73, loss:0.00003, loss_test:0.06479, lr:7.25e-03, fs:0.80203 (r=0.798,p=0.806),  time:21.506, tt:1591.452\n",
      "Ep:74, loss:0.00003, loss_test:0.06704, lr:7.18e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.514, tt:1613.550\n",
      "Ep:75, loss:0.00003, loss_test:0.06654, lr:7.11e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.485, tt:1632.853\n",
      "Ep:76, loss:0.00003, loss_test:0.06473, lr:7.03e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.482, tt:1654.133\n",
      "Ep:77, loss:0.00003, loss_test:0.06676, lr:6.96e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.465, tt:1674.263\n",
      "Ep:78, loss:0.00003, loss_test:0.06568, lr:6.89e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.441, tt:1693.819\n",
      "Ep:79, loss:0.00003, loss_test:0.06527, lr:6.83e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.431, tt:1714.456\n",
      "Ep:80, loss:0.00003, loss_test:0.06642, lr:6.76e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.424, tt:1735.305\n",
      "Ep:81, loss:0.00003, loss_test:0.06616, lr:6.69e-03, fs:0.79592 (r=0.788,p=0.804),  time:21.411, tt:1755.728\n",
      "Ep:82, loss:0.00003, loss_test:0.06605, lr:6.62e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.399, tt:1776.109\n",
      "Ep:83, loss:0.00003, loss_test:0.06670, lr:6.56e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.411, tt:1798.535\n",
      "Ep:84, loss:0.00003, loss_test:0.06586, lr:6.49e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.403, tt:1819.258\n",
      "Ep:85, loss:0.00003, loss_test:0.06493, lr:6.43e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.428, tt:1842.826\n",
      "Ep:86, loss:0.00003, loss_test:0.06574, lr:6.36e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.477, tt:1868.512\n",
      "Ep:87, loss:0.00003, loss_test:0.06630, lr:6.30e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.505, tt:1892.440\n",
      "Ep:88, loss:0.00003, loss_test:0.06598, lr:6.24e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.501, tt:1913.547\n",
      "Ep:89, loss:0.00003, loss_test:0.06522, lr:6.17e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.503, tt:1935.238\n",
      "Ep:90, loss:0.00002, loss_test:0.06714, lr:6.11e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.530, tt:1959.269\n",
      "Ep:91, loss:0.00002, loss_test:0.06549, lr:6.05e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.550, tt:1982.624\n",
      "Ep:92, loss:0.00002, loss_test:0.06480, lr:5.99e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.582, tt:2007.143\n",
      "Ep:93, loss:0.00002, loss_test:0.06547, lr:5.93e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.587, tt:2029.188\n",
      "Ep:94, loss:0.00002, loss_test:0.06518, lr:5.87e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.600, tt:2051.956\n",
      "Ep:95, loss:0.00002, loss_test:0.06591, lr:5.81e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.598, tt:2073.404\n",
      "Ep:96, loss:0.00002, loss_test:0.06505, lr:5.75e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.583, tt:2093.552\n",
      "Ep:97, loss:0.00002, loss_test:0.06538, lr:5.70e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.577, tt:2114.536\n",
      "Ep:98, loss:0.00002, loss_test:0.06558, lr:5.64e-03, fs:0.79592 (r=0.788,p=0.804),  time:21.590, tt:2137.419\n",
      "Ep:99, loss:0.00002, loss_test:0.06462, lr:5.58e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.581, tt:2158.131\n",
      "Ep:100, loss:0.00002, loss_test:0.06618, lr:5.53e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.562, tt:2177.786\n",
      "Ep:101, loss:0.00002, loss_test:0.06494, lr:5.47e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.574, tt:2200.505\n",
      "Ep:102, loss:0.00002, loss_test:0.06483, lr:5.42e-03, fs:0.79592 (r=0.788,p=0.804),  time:21.566, tt:2221.268\n",
      "Ep:103, loss:0.00002, loss_test:0.06635, lr:5.36e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.561, tt:2242.321\n",
      "Ep:104, loss:0.00002, loss_test:0.06497, lr:5.31e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.589, tt:2266.871\n",
      "Ep:105, loss:0.00002, loss_test:0.06541, lr:5.26e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.586, tt:2288.100\n",
      "Ep:106, loss:0.00002, loss_test:0.06549, lr:5.20e-03, fs:0.80000 (r=0.788,p=0.812),  time:21.588, tt:2309.955\n",
      "Ep:107, loss:0.00002, loss_test:0.06558, lr:5.15e-03, fs:0.80829 (r=0.788,p=0.830),  time:21.592, tt:2331.913\n",
      "Ep:108, loss:0.00002, loss_test:0.06569, lr:5.10e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.596, tt:2353.948\n",
      "Ep:109, loss:0.00002, loss_test:0.06491, lr:5.05e-03, fs:0.80412 (r=0.788,p=0.821),  time:21.602, tt:2376.172\n",
      "Ep:110, loss:0.00002, loss_test:0.06568, lr:5.00e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.609, tt:2398.564\n",
      "Ep:111, loss:0.00002, loss_test:0.06553, lr:4.95e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.598, tt:2418.938\n",
      "Ep:112, loss:0.00002, loss_test:0.06527, lr:4.90e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.577, tt:2438.190\n",
      "Ep:113, loss:0.00002, loss_test:0.06626, lr:4.85e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.577, tt:2459.761\n",
      "Ep:114, loss:0.00002, loss_test:0.06539, lr:4.80e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.584, tt:2482.164\n",
      "Ep:115, loss:0.00002, loss_test:0.06476, lr:4.75e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.570, tt:2502.080\n",
      "Ep:116, loss:0.00002, loss_test:0.06551, lr:4.71e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.553, tt:2521.739\n",
      "Ep:117, loss:0.00002, loss_test:0.06528, lr:4.66e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.550, tt:2542.878\n",
      "Ep:118, loss:0.00002, loss_test:0.06582, lr:4.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.552, tt:2564.718\n",
      "Ep:119, loss:0.00002, loss_test:0.06560, lr:4.57e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.572, tt:2588.593\n",
      "Ep:120, loss:0.00002, loss_test:0.06462, lr:4.52e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.585, tt:2611.734\n",
      "Ep:121, loss:0.00002, loss_test:0.06573, lr:4.48e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.585, tt:2633.314\n",
      "Ep:122, loss:0.00002, loss_test:0.06600, lr:4.43e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.574, tt:2653.610\n",
      "Ep:123, loss:0.00002, loss_test:0.06463, lr:4.39e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.574, tt:2675.194\n",
      "Ep:124, loss:0.00002, loss_test:0.06599, lr:4.34e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.570, tt:2696.260\n",
      "Ep:125, loss:0.00002, loss_test:0.06545, lr:4.30e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.566, tt:2717.267\n",
      "Ep:126, loss:0.00002, loss_test:0.06491, lr:4.26e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.554, tt:2737.411\n",
      "Ep:127, loss:0.00002, loss_test:0.06555, lr:4.21e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.555, tt:2759.094\n",
      "Ep:128, loss:0.00002, loss_test:0.06486, lr:4.17e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.555, tt:2780.650\n",
      "Ep:129, loss:0.00002, loss_test:0.06537, lr:4.13e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.545, tt:2800.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.06541, lr:4.09e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.535, tt:2821.123\n",
      "Ep:131, loss:0.00002, loss_test:0.06485, lr:4.05e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.539, tt:2843.128\n",
      "Ep:132, loss:0.00002, loss_test:0.06480, lr:4.01e-03, fs:0.81250 (r=0.788,p=0.839),  time:21.555, tt:2866.860\n",
      "Ep:133, loss:0.00002, loss_test:0.06499, lr:3.97e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.550, tt:2887.659\n",
      "Ep:134, loss:0.00002, loss_test:0.06518, lr:3.93e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.542, tt:2908.131\n",
      "Ep:135, loss:0.00002, loss_test:0.06483, lr:3.89e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.551, tt:2930.926\n",
      "Ep:136, loss:0.00002, loss_test:0.06455, lr:3.85e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.551, tt:2952.552\n",
      "Ep:137, loss:0.00002, loss_test:0.06407, lr:3.81e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.545, tt:2973.173\n",
      "Ep:138, loss:0.00002, loss_test:0.06538, lr:3.77e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.519, tt:2991.122\n",
      "Ep:139, loss:0.00002, loss_test:0.06479, lr:3.73e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.483, tt:3007.621\n",
      "Ep:140, loss:0.00002, loss_test:0.06463, lr:3.70e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.482, tt:3028.981\n",
      "Ep:141, loss:0.00002, loss_test:0.06476, lr:3.66e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.496, tt:3052.421\n",
      "Ep:142, loss:0.00002, loss_test:0.06451, lr:3.62e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.508, tt:3075.632\n",
      "Ep:143, loss:0.00002, loss_test:0.06470, lr:3.59e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.492, tt:3094.864\n",
      "Ep:144, loss:0.00002, loss_test:0.06420, lr:3.55e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.494, tt:3116.660\n",
      "Ep:145, loss:0.00001, loss_test:0.06439, lr:3.52e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.483, tt:3136.460\n",
      "Ep:146, loss:0.00001, loss_test:0.06429, lr:3.48e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.493, tt:3159.450\n",
      "Ep:147, loss:0.00001, loss_test:0.06413, lr:3.45e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.504, tt:3182.526\n",
      "Ep:148, loss:0.00001, loss_test:0.06545, lr:3.41e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.514, tt:3205.518\n",
      "Ep:149, loss:0.00001, loss_test:0.06388, lr:3.38e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.534, tt:3230.070\n",
      "Ep:150, loss:0.00001, loss_test:0.06446, lr:3.34e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.543, tt:3252.931\n",
      "Ep:151, loss:0.00001, loss_test:0.06451, lr:3.31e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.544, tt:3274.738\n",
      "Ep:152, loss:0.00001, loss_test:0.06418, lr:3.28e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.536, tt:3294.998\n",
      "Ep:153, loss:0.00001, loss_test:0.06440, lr:3.24e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.541, tt:3317.241\n",
      "Ep:154, loss:0.00001, loss_test:0.06425, lr:3.21e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.540, tt:3338.652\n",
      "Ep:155, loss:0.00001, loss_test:0.06386, lr:3.18e-03, fs:0.81675 (r=0.788,p=0.848),  time:21.526, tt:3358.079\n",
      "Ep:156, loss:0.00001, loss_test:0.06380, lr:3.15e-03, fs:0.82105 (r=0.788,p=0.857),  time:21.496, tt:3374.883\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
