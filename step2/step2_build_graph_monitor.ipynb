{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset and plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "\n",
    "def read_dataset(path,drop_columns=None,keep_columns=None):\n",
    "    #get rid of useless columns\n",
    "    csv_data = pd.read_csv(path,sep=\"~\")\n",
    "    \n",
    "    if keep_columns != None:\n",
    "        #keep only these columns\n",
    "        return csv_data.filter(items=keep_columns)\n",
    "    \n",
    "    if drop_columns!= None:\n",
    "        #drop these and keep the rest\n",
    "        return csv_data.drop(drop_columns, axis=1)\n",
    "    \n",
    "    #finally, didn't drop or filter any column\n",
    "    return csv_data     \n",
    "\n",
    "def plot_graph(g,ds_nodes=[],attribute_nodes=[],feat_nodes=[],lit_nodes=[]):\n",
    "    pos=nx.spring_layout(g)    \n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=ds_nodes,node_color=\"blue\",node_size=900)\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=attribute_nodes,node_color=\"green\",node_size=900)\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=feat_nodes,node_color=\"grey\",node_size=900)\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=lit_nodes,node_color=\"red\",node_size=900)\n",
    "\n",
    "    nx.draw_networkx_edges(g,pos,width=3)\n",
    "    nx.draw_networkx_labels(g,pos,font_size=8)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph  construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_ds_id(data):\n",
    "    return \"DS_\"+data\n",
    "def code_attr_id(data,parent):\n",
    "    return data+\"|\"+parent\n",
    "def code_feat_id(data,parent):\n",
    "    return data+\"|\"+parent\n",
    "def code_literal_id(data,parent):\n",
    "    return \"literal_\"+data+\"|\"+parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_dataset_short(datasets,g=None,wem=\"fasttext\",instances=0):\n",
    "    if g == None:\n",
    "        g = nx.Graph()\n",
    "    \n",
    "    #create nodes and edges at datasetLevel\n",
    "    features = datasets.columns[2:]\n",
    "    \n",
    "    if instances==0:\n",
    "        number_instances = len(datasets)\n",
    "    else:\n",
    "        number_instances = instances\n",
    "    \n",
    "    for r in range(number_instances): \n",
    "        #node id is the openML id which is in the first column\n",
    "#         dataset_id = code_ds_id(str(datasets.iloc[r][0]))\n",
    "        dataset_id = datasets.iloc[r][0]\n",
    "        g.add_node(dataset_id,vector=word_embedding(\"dataset|\"+datasets.iloc[r][1] ,wem),tipo=\"attribute\")\n",
    "        row = datasets.iloc[r][2:]\n",
    "        \n",
    "        if instances == 0:\n",
    "            number_features = len(features)\n",
    "        else:\n",
    "            number_features = min(instances,len(features))\n",
    "            \n",
    "        for i in range (number_features):\n",
    "            feature_dataset_id = code_feat_id(features[i],dataset_id)\n",
    "#             literal_dataset_id = code_literal_id(str(i),dataset_id)\n",
    "            g.add_node(feature_dataset_id,vector=word_embedding(features[i]+\"|\"+str(row[i]) ,wem),tipo=\"feature dataset\")\n",
    "#             g.add_node(literal_dataset_id,vector=word_embedding(row[i],wem),tipo=\"literal dataset\")\n",
    "            g.add_edge(dataset_id,feature_dataset_id)\n",
    "#             g.add_edge(feature_dataset_id,literal_dataset_id)\n",
    "            \n",
    "    return g\n",
    "\n",
    "\n",
    "def graph_attribute_short(datasets,g=None,wem=\"fasttext\",instances=0):\n",
    "    if g == None:\n",
    "        g = nx.Graph()\n",
    "        \n",
    "    #create nodes and edges at datasetLevel\n",
    "    features = datasets.columns[2:]\n",
    "    \n",
    "    if instances==0:\n",
    "        number_instances = len(datasets)\n",
    "    else:\n",
    "        number_instances = min (instances,len(datasets))\n",
    "    \n",
    "    for r in range(number_instances): \n",
    "        #node id is the openML id which is in the first column\n",
    "        #attr name is the 2nd column\n",
    "#         dataset_id = code_ds_id(str(datasets.iloc[r][0]))\n",
    "        dataset_id = datasets.iloc[r][0]\n",
    "        attribute_id = code_ds_id(dataset_id+\"//\"+datasets.iloc[r][1])\n",
    "        row = datasets.iloc[r][2:]\n",
    "        \n",
    "        g.add_node(attribute_id,vector=word_embedding(\"attribute|\"+datasets.iloc[r][1],wem),tipo=\"dataset\")\n",
    "        \n",
    "        #relation of dataset and an attribute\n",
    "        g.add_edge(dataset_id,attribute_id)\n",
    "        \n",
    "        if instances == 0:\n",
    "            number_features = len(features)\n",
    "        else:\n",
    "            number_features = min (instances,len(features))\n",
    "            \n",
    "        for i in range (number_features):\n",
    "            feature_attribute_id = code_feat_id(features[i],attribute_id)\n",
    "#             literal_dataset_id = code_literal_id(str(i),attribute_id)\n",
    "            g.add_node(feature_attribute_id,vector=word_embedding(features[i]+\"|\"+str(row[i]),wem),tipo=\"feature attribute\")\n",
    "#             g.add_node(literal_dataset_id,vector=word_embedding(row[i],wem),tipo=\"literal attribute\")\n",
    "            g.add_edge(attribute_id,feature_attribute_id)\n",
    "#             g.add_edge(feature_attribute_id,literal_dataset_id)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if input is number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    #Returns True is string is a number.\n",
    "    try:\n",
    "        float(s)\n",
    "        if float(s) == float(\"INF\") or float(s) == float(\"NAN\") or s == \"NAN\" or s == \"nan\":\n",
    "            return False\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From numbers to bin tensor vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import bitstring\n",
    "import torch\n",
    "#clean\n",
    "def num2vec(num):\n",
    "    rep_sc = str('{:.11E}'.format(num))\n",
    "#     print(rep_sc)\n",
    "    dec_part = int(rep_sc.split(\"E\")[0].replace(\".\",\"\"))\n",
    "    c = 1\n",
    "    if dec_part <0:\n",
    "        c = -1\n",
    "    dec_part = abs(dec_part)\n",
    "    \n",
    "    exp_part = int(rep_sc.split(\"E\")[1])\n",
    "    if exp_part <0:\n",
    "        exp_pos = 0\n",
    "        exp_neg = exp_part\n",
    "    else:\n",
    "        exp_pos = exp_part\n",
    "        exp_neg = 0\n",
    "\n",
    "    exp_pos = abs(exp_pos)    \n",
    "    exp_neg = abs(exp_neg)\n",
    "    \n",
    "    rep_str = str(\"{:03}{:03}{:012}\".format(exp_pos,exp_neg,dec_part))\n",
    "#     print(rep_str)\n",
    "    \n",
    "#     print(dec_part)\n",
    "    rep_int = int(rep_str) * c\n",
    "    rep_bin = bitstring.Bits(int=rep_int, length=64).bin\n",
    "\n",
    "    bin_tensor = torch.tensor(np.array([float(x) for x in rep_bin]))\n",
    "    return bin_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import fasttext\n",
    "#fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('./resources/fasttext.bin')\n",
    "print(ft.get_dimension())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttex_simple(value):\n",
    "    if is_number(value):\n",
    "        value = str(value)\n",
    "    \n",
    "    values = value.split(\"|\")\n",
    "    out_tensor = torch.zeros(300)\n",
    "    for v in values:\n",
    "        out_tensor = out_tensor + torch.tensor(ft.get_sentence_vector(value))\n",
    "    out_tensor = out_tensor / len(values)\n",
    "    return out_tensor\n",
    "    \n",
    "def fasttex_(value):\n",
    "    value = str(value)\n",
    "    values = value.split(\"|\")\n",
    "    out_tensor = torch.zeros(364)\n",
    "    for v in values:\n",
    "        if is_number(v):\n",
    "            value_f = float(v)\n",
    "            bin_tensor = num2vec(value_f)\n",
    "            out_tensor = out_tensor + torch.cat((torch.zeros(300),bin_tensor.float()))\n",
    "        else:\n",
    "            str_tensor = torch.tensor(ft.get_sentence_vector(value))\n",
    "            out_tensor = out_tensor + torch.cat((str_tensor.float(),torch.zeros(64)))\n",
    "    out_tensor = out_tensor / len(values)\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(data, model):\n",
    "    if model==\"fasttext\":\n",
    "        return fasttex_(data)\n",
    "    if model==\"bert\":\n",
    "        return bert(data)\n",
    "    if model==\"fasttext_simple\":\n",
    "        return fasttex_simple(data)\n",
    "    if model==\"bert_simple\":\n",
    "        return bert_simple(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_monitorfasttext_short2.gpickle\n"
     ]
    }
   ],
   "source": [
    "#build graph\n",
    "word_emb = \"fasttext\"\n",
    "df_dataset = read_dataset(\"./resources/monitor_clean/ds2.csv\");\n",
    "g = g = nx.Graph()\n",
    "g = graph_dataset_short(df_dataset,g,word_emb)\n",
    "df_attributes = read_dataset(\"./resources/monitor_clean/attr_cat2.csv\");\n",
    "g = graph_attribute_short(df_attributes,g,word_emb)\n",
    "df_attributes_numeric = read_dataset(\"./resources/monitor_clean/attr_num2.csv\");\n",
    "g = graph_attribute_short(df_attributes_numeric,g,word_emb)\n",
    "#write graph to file\n",
    "nx.write_gpickle(g, \"../word_embeddings/clean_monitor_\"+word_emb+\"_short2.gpickle\")\n",
    "print(\"clean_monitor\"+word_emb+\"_short2.gpickle\")\n",
    "##clean with older notation\n",
    "##clean 2 with higher numbers that didnt work\n",
    "##clean 3 with exp+,exp-,fraction\n",
    "##clean 4 with +exp+,+exp-,-exp+,-exp-,fraction with sign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read previously created graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read\n",
    "g = nx.read_gpickle(\"../word_embeddings/encoded_bert_v2.gpickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
